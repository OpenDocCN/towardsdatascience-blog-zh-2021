# 使可测量:关于算法的主观性，伽利略没有说什么

> 原文：<https://towardsdatascience.com/make-measurable-what-galileo-didnt-say-about-the-subjectivity-of-algorithms-8d1d324253da?source=collection_archive---------16----------------------->

## [公平和偏见](https://towardsdatascience.com/tagged/fairness-and-bias)

## 关于如何衡量世界的选择意味着，并非所有的数据和算法都像它们看起来那样客观。

![](img/3d328acf2ff0a02a306847de225d61ea.png)

由 [Diana Polekhina](https://unsplash.com/@diana_pole?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄

伽利略的格言“测量能测量的，让不能测量的变得可测量”在今天的几乎每一个算法系统中都有回响。但在这些回声中回荡的是这样一个现实，即“制造”某种可测量的东西从来都不是纯粹客观的:它是主观选择的结果。承认这一点是防止算法造成伤害的关键。

将关于一件事物的“数据”视为它的真实表示似乎很直观。例如，我的身高是 5 英尺 9 英寸，伦敦是英国的首都——这两个数据点反映了现实。但是著名的统计学家 David Spiegelhalter 提醒我们,数据“几乎总是不完美的衡量我们感兴趣的东西”他指出，要数清地球上所有的树，我们必须首先定义什么算一棵树。有多种方法可以做到这一点，但并不是每个人都同意哪种方法是正确的。这是一个很好的提醒:有些人会说我更像 5 英尺 8 英寸半，这取决于你如何拿卷尺，爱丁堡、威尔士和贝尔法斯特呢？它们也都是英国的首都。

换句话说，使事物可测量的过程就是选择如何测量它们的过程。一个现象的哪些方面应该算？如何对这些方面进行分类和量化？将使用哪些指标？这些指标捕捉和反映了或没有捕捉和反映什么质量？这些选择通常会推动一个缩减的过程:将复杂的定性现象压缩成简单的数字数据:这个过程被称为数据化。

数据不是世界的完美反映，这一事实在数据科学中是众所周知的([所有的模型都是错误的，但有些是有用的](https://en.wikipedia.org/wiki/All_models_are_wrong)。)然而，数据是许多算法的基础，这些算法越来越多地渗透并支持我们的数字社会。算法采用数据化的还原产物——关于如何使某些东西可测量的主观选择的产物——并通过固定的过程将它们硬编码成理应客观的输出。未能说明数据化的这种还原性质是许多算法伤害和失败的根本原因。

我们可以从两个例子中看出这一点:数字接触追踪和所谓的情感识别。

## **识别接触和追踪情绪**

第一，数字接触追踪。在应对新冠肺炎疫情疫情时，公共卫生专家很快认识到，追踪接触者是应对病毒传播的关键。然而，手动接触追踪是费力的，需要相当多的时间和人力资源。政府和公共卫生机构想要一种可扩展以应对 Covid 挑战的接触者追踪模型。为了实现这一目标，许多国家寻求数字解决方案。

一系列联系追踪应用很快出现，主要基于蓝牙技术和由 Android 和 iOS 开发者支持的[。每个应用程序的具体工作方式各不相同，但通常用户会下载他们国家的应用程序并处理日常事务。该应用程序记录了所有与它密切接触的其他手机的日志，通过蓝牙信号记录它们的接近程度。如果手机接触到另一个后来新冠肺炎病毒检测呈阳性的人，该应用程序会发送通知，警告用户进行自我隔离并接受检测。](https://www.theverge.com/2020/4/10/21216550/contact-tracing-coronavirus-what-is-tracking-spread-how-it-works)

理论上，这是一个很好的解决方案。不幸的是，数字联系追踪应用程序被证明[不如手动联系追踪](https://www.nature.com/articles/s41467-021-22082-7)有效。这有许多可能的原因，从蓝牙传感器的精度到计算暴露的方式。但另一个主要原因是，这些应用根本没有真正进行联系人追踪。手动追踪接触者是一项[高度复杂的](https://www.who.int/publications/i/item/contact-tracing-in-the-context-of-covid-19)任务，需要训练有素的专业人员通过面谈和其他方式详细绘制感染者的社会联系图。然而，蓝牙联系追踪不能做到这一点。取而代之的是，它只是记录“联系事件”(两部手机在一段设定的时间内彼此靠近，并开着蓝牙)。

换句话说，数字联系追踪应用是一种选择的产物，它将复杂的联系追踪任务简化为一个不完美的量化指标:手机之间的距离。这与对一个人的社会接触的丰富了解相去甚远，详细了解他们有什么互动以及他们之间传播病毒的可能性有多大。所有数字接触追踪应用程序可以测量的是蓝牙信号，而不是病毒传播。依赖这种主观定义的替代物作为接触的客观衡量标准，有可能导致公共卫生响应方面的差距，并转移人工接触者追踪工作的时间和金钱。

忽视数据化主观性风险的另一个例子是所谓的情感识别技术。在这里，危险远远超出了简单的无效，如蓝牙接触追踪，而是开始触及更深层次的社会不公和更广泛的技术科学伦理问题。

情绪识别系统是人工智能驱动的工具，[声称它可以通过分析一个人的面部图像来识别他的情绪。微笑？你有 95%的机会开心。扮鬼脸？85%的几率你会觉得恶心。](https://www.sciencedirect.com/science/article/pii/S1877050917305264)

问题是，这些系统大多是基于可疑的科学,表明人类情感有有限的、普遍的和特定的类别。此外，他们假设你脸上的表情是你内心情绪状态的直接反映，任何曾经笑过哭过的人都知道那不是真的。

当然，这些系统的支持者会争辩说，笑-哭是一种情绪的表达，这些系统只是需要一个能够识别它的类别。但这没有抓住重点。我们在任何时候的情绪状态都反映了我们的基因、我们的教养、我们的文化、我们目前所处的情况、房间里其他人的情绪、我们当时有多饿等等:情绪同时具有深刻的社会性、文化性和心理性。根据一些预先确定的、简单的类别，将所有这些都压缩到一个单一的、定量的概率计算中，这依赖于关于如何解释和分类所有这些定性因素的许多简化的和主观的选择。结果是，这里可测量的不是人类的情感，而是人脸可能形成的特定形状，一个粗糙的、可能有偏见的分类被置于顶部。

像情绪识别这样的算法工具对一些人来说很有吸引力，因为它们声称可以将难以置信的复杂现象变得简单。对其他人来说，吸引力在于这些算法可以提供比人类单独更深入或更真实的世界分析。但事实是，他们通常都不这样做。情感识别算法并不真正“识别”情感，它们只是检测表情并给它们贴上过于简单的标签。这就像把一个粘土十二面体强行穿过一个方孔，并且一直假装它是一个正方形。

在这两种情况下，接触追踪和情感识别，问题不一定是定量的分析方法。任何称职的统计学家或数据科学家都会指出，当对如何使某些东西可测量做出武断或简化的选择时，可能会出现缺陷。

问题是，这些算法系统采用这些简化的指标，并将其固定在一个没有细微差别、异常值或独特背景的技术流程中。他们采用现象，用基于一套主观的、有价值的和潜在偏见的观点的规则来解释它们，但吐出看起来客观的、没有主观性的陈述，因此被认为是真实的:追踪接触；情感确定。

## **选择如何使可测量的**

回到伽利略，现代数据化和算法也使他的陈述成为简化论的受害者:它们侵蚀了“制造”一词的复杂性。正是在“制造”可测量的事物的过程中，价值、选择、偏见、缺陷、错误、疏忽等等悄悄进入数据集。在这种“使”可测量的过程中，事物被转化为量化的度量，这些度量只反映了那些选择所关注的现象的一部分。一旦这些数据集被纳入算法系统，这些选择就会被硬连线到技术成果中。凯西·奥尼尔的一句现代格言很好地描述了这一过程:“算法是嵌入代码中的观点。”

在我们的现代数字社会中，我们不会停止依赖算法。我们也不应该。当它们被精心设计时，它们会非常有效。但是数据科学和算法设计总是需要数据化的元素:使事物可测量总是需要主观选择。

关键是要更加适应这些选择，认识到这些选择是在何时、如何做出的，以及由谁做出这些选择，并承认算法的输入和输出永远不会不受主观性的影响，不管科技公司的营销可能宣称什么。承认算法的这种主观本质是设计它们对人类和社会产生更多积极和更少有害影响的关键。