# GPT 4 号将拥有 100 万亿个参数，是 GPT 3 号的 500 倍

> 原文：<https://towardsdatascience.com/gpt-4-will-have-100-trillion-parameters-500x-the-size-of-gpt-3-582b98d82253?source=collection_archive---------0----------------------->

## 人工智能|新闻

## 大型神经网络有什么限制吗？

![](img/768c145105dbeb1aa8478f5882104484.png)

桑德罗·卡塔琳娜在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

## 更新: [GPT-4 出局](https://thealgorithmicbridge.substack.com/p/gpt-4-in-10-keys)。

OpenAI 的诞生是为了应对实现人工通用智能(AGI)的挑战——一种能够做人类可以做的任何事情的人工智能。

这种技术将改变我们所知的世界。如果使用得当，它可以造福于我们所有人，但如果落入坏人之手，它可能成为最具毁灭性的武器。这就是 OpenAI 接手这个任务的原因。为了确保每个人都能平等受益:“我们的目标是以最有可能造福全人类的方式推进数字智能。”

然而，这个问题的严重性使它成为人类有史以来最大的科研项目。尽管计算机科学和人工智能取得了很大的进步，但没有人知道如何解决这个问题，也不知道什么时候会发生。

一些人认为深度学习不足以实现 AGI。伯克利的计算机科学教授、人工智能先驱 Stuart Russell[认为](https://www.ft.com/content/c96e43be-b4df-11e9-8cb2-799a3a8cf37b)“专注于原始的计算能力完全没有抓住要点[……]我们不知道如何让一台机器变得真正智能——即使它有宇宙那么大。”

相比之下，OpenAI 相信，基于大型数据集并在大型计算机上训练的大型神经网络是实现 AGI 的最佳途径。OpenAI 的首席技术官格雷格·布罗克曼在接受金融时报采访时说:“我们认为谁拥有最大的计算机，谁就能获得最大的利益。”

这就是他们所做的。他们开始训练越来越大的模型，以唤醒深度学习中隐藏的力量。朝着这个方向迈出的第一步是 GPT 和 T2 的发布。这些大型语言模型将为这场秀的主角 [GPT-3](https://arxiv.org/abs/2005.14165) 奠定基础。一个比 GPT-2 大 100 倍的语言模型，有 1750 亿个参数。

GPT-3 是当时创造的最大的神经网络——并且仍然是最大的*密集*神经网络。它的语言专业知识和无数的能力让大多数人感到惊讶。尽管一些专家仍然持怀疑态度，但是大型语言模型已经让人感觉很奇怪了。对于 OpenAI 的研究人员来说，这是一个巨大的飞跃，他们加强了他们的信念，并让我们相信 AGI 是深度学习的一个问题。

# 神圣的三位一体——算法、数据和计算机

OpenAI 相信[缩放假说](https://www.gwern.net/Scaling-hypothesis#scaling-hypothesis)。给定一个可扩展的算法，在这种情况下是变压器——GPT 家族背后的基本架构——可能有一条通往 AGI 的直接路径，包括基于该算法训练越来越大的模型。

但是大型模型只是 AGI 拼图的一部分。训练它们需要大量的数据集和大量的计算能力。

当机器学习社区开始揭示无监督学习的潜力时，数据不再是瓶颈。这与生成语言模型和少量任务转移一起，解决了 OpenAI 的“大数据集”问题。

他们只需要巨大的计算资源来训练和部署他们的模型，他们会很好地去。这也是他们[在 2019 年与微软](https://openai.com/blog/microsoft/)合作的原因。他们授权给这家大型科技公司，这样他们就可以在商业上使用 OpenAI 的一些模型，以换取他们所需的云计算基础设施和强大的 GPU。

但是 GPU 并不是专门为训练神经网络而构建的。游戏行业开发了这些用于图形处理的芯片，而人工智能行业只是利用了它适合并行计算的优势。OpenAI 想要最好的模型和最好的数据集，他们也想要最好的计算机芯片。GPU 是不够的。

许多公司也意识到了这一点，并开始在不损失效率或容量的情况下，构建内部专用芯片来训练神经网络。但是像 OpenAI 这样的纯软件公司，很难做到硬件设计和制作一体化。这就是为什么他们走了另一条路线:使用第三方 AI 专用芯片。

这里是大脑系统进入场景的地方。这家芯片公司已经在 2019 年建造了[有史以来最大的芯片](http://ever)来训练大型神经网络。现在他们又做到了，OpenAI 将很好地利用这一令人惊叹的工程。

# 一个芯片和一个模型——WSE 二号和 GPT 四号

两周前，《连线》杂志[发表了一篇文章](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/)披露了两条重要消息。

首先，脑波强化器又制造了市场上最大的芯片，晶圆级引擎二号(WSE-2)。它每边约 22 厘米，有 2.6 万亿个晶体管。相比之下，特斯拉的[全新](https://youtu.be/j0z4FweCy4M)训练瓦片有 1.25 万亿个晶体管。

脑波强化器找到了一种有效浓缩计算能力的方法，因此 WSE-2 拥有 85 万个核心——计算单元——而典型的 GPU 只有几百个。他们还利用一种新颖的冷却系统解决了加热问题，并成功创建了高效的 I/O 数据流。

像 WSE-2 这样超级专业、超级昂贵、超级强大的芯片没有多少用处。训练大型神经网络就是其中之一。因此脑波强化器与 OpenAI 对话。

下面是第二条新闻。脑波强化器的首席执行官安德鲁·费尔德曼对《连线》说:“从与 OpenAI 的交谈中，GPT-4 将有大约 100 万亿个参数。[……]那要好几年才能准备好。”

自 GPT 3 以来，人们对 OpenAI 及其下一个版本有很多期待。现在我们知道它将在几年后问世，而且会非常大。它的大小将超过 x500 GPT 3 号。你没看错: *x500。*

GPT-4 将比去年震惊世界的语言模型大 500 倍。

# 我们能从 GPT-4 中期待什么？

100 万亿参数很多。为了理解这个数字有多大，让我们把它与我们的大脑进行比较。大脑有大约 800-1000 亿个神经元(GPT-3 的数量级)和大约 100 万亿个突触。

GPT-4 将拥有和大脑拥有的突触一样多的参数。

这样一个神经网络的庞大规模可能会带来我们只能想象的 GPT-3 的质的飞跃。用目前的[提示方法](/software-3-0-how-prompting-will-change-the-rules-of-the-game-a982fbfe1e0)，我们甚至可能无法测试系统的全部潜力。

然而，将人工神经网络与大脑进行比较是一件棘手的事情。这种比较似乎是公平的，但那只是因为我们假设人工神经元至少松散地基于生物神经元。[发表在《神经元》杂志上的一项最新研究](https://www.cell.com/neuron/fulltext/S0896-6273(21)00501-8?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0896627321005018%3Fshowall%3Dtrue)提出了相反的观点。他们发现，至少需要 5 层神经网络来模拟单个生物神经元的行为。每一个生物神经元大约有 1000 个人工神经元。

但是，即使 GPT 4 号没有我们的大脑强大，它肯定会留下一些惊喜。与 GPT-3 不同，它可能不仅仅是一个语言模型。OpenAI 的首席科学家 Ilya Sutskever 在 2020 年 12 月关于多模态的文章中暗示了这一点:

> “2021 年，语言模型将开始意识到视觉世界。光是文字就能表达关于这个世界的大量信息，但它是不完整的，因为我们也生活在一个视觉世界里。”

我们已经用 [DALL E](https://openai.com/blog/dall-e/) 看到了一些，这是 GPT 3(120 亿个参数)的一个较小版本，专门针对文本-图像对进行了训练。OpenAI 当时说，“通过语言操纵视觉概念现在已经触手可及。”

OpenAI 一直在不停地开发 GPT 3 号的隐藏能力。达尔 E 是 GPT-3 的一个特例，非常像[抄本](https://openai.com/blog/openai-codex/)。但它们不是绝对的改进，更像是特例。GPT-4 承诺更多。它承诺像 DALL E(文本图像)和 Codex(编码)这样的专家系统的深度与像 GPT-3(通用语言)这样的通用系统的宽度相结合。

其他类似人类的特征呢，比如推理或常识？在这方面，山姆·奥尔特曼说他们不确定，但他保持“乐观”

问题很多，回答很少。没有人知道 AGI 是否有可能。没有人知道如何建造它。没有人知道更大的神经网络是否会越来越接近它。但有一点是不可否认的:GPT 4 号将是一个值得关注的东西。

*订阅* [**算法桥**](https://thealgorithmicbridge.substack.com/) *。弥合算法和人之间的鸿沟。关于与你生活相关的人工智能的时事通讯。*

*您也可以直接支持我在 Medium 上的工作，并通过使用我的推荐链接* [**这里**](https://albertoromgar.medium.com/membership) 成为会员来获得无限制的访问权限！ *:)*