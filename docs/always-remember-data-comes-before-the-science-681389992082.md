# 永远记住数据先于科学

> 原文：<https://towardsdatascience.com/always-remember-data-comes-before-the-science-681389992082?source=collection_archive---------24----------------------->

## 获取数据的不同方法

![](img/d91d25193592feea379d81805c3f9777.png)

[粘土银行](https://unsplash.com/@claybanks?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 拍摄的照片

没有数据，我们肯定会忘记做科学部分。然而，令我惊讶的是，我们对数据的谈论如此之少——别担心，我不是在指责谁。我也有罪；数据是我们作为数据科学家所做的一切的核心，但这并不像谈论 BERT 如何推动自然语言处理(NLP)任务的边界，或者无论新的最先进的(SOTA)架构是什么那样有趣。

这种对人工智能(AI)和数据科学未来的固有 FOMO(害怕错过)类似于让许多人迷上社交媒体的事情。

> 当我们可以幻想我们的未来可能会有多么美好的时候，谈论现在真正重要的事情并不有趣。

至少这是我的一个小理论，关于为什么在数据领域的人们没有给予真正重要的东西那么多的关注。**数据！**

这听起来可能很疯狂，但您知道工业项目中的大多数瓶颈都是由数据造成的吗？别让我从道德方面说起。

也许我住在岩石下，我不知道。我要说的是，我很少看到数据相关领域的从业者讨论数据的实际获取。这是一个疯狂的观察，因为数据实际上是整个工作流程中最重要的部分之一——如果我一直在错误的地方寻找，我很高兴被指向正确的方向。

> 注:我建议阅读这篇文章的每个人都把编码偏见放在他们的观察清单上——你可以在网飞上找到它。

# 什么是数据采集？

根据 [*维基百科*](https://en.wikipedia.org/wiki/Data_acquisition) 的说法，数据采集被描述为“对测量现实世界物理状况的信号进行采样，并将所得样本转换成可由计算机操纵的数字数值的过程”**来源** : [维基百科](http://Wikipedia)。

在一个理想的世界里，我们应该有所有需要的数据集，这些数据集有足够的数据点来解决我们的问题(实际的数量可能会因项目而异)。在这种情况下，我们不必考虑数据采集。然而，这个世界通常并不理想，因此，在我们考虑将数据转换成可以处理的格式之前，我们必须掌握获取数据的技术。

# 数据采集技术

在我们进行任何数据采集之前，我们需要知道我们希望测量的物理现象是什么(即光强、房价、力等)。).在任何实际活动开始之前，人工智能团队通常会就业务问题是什么、它的不同需求以及他们需要什么类型的数据进行长时间的讨论。

一旦开始工作的号角响起，所有的数据源都需要被拉到一个数据科学家可以访问的位置。

在本文的剩余部分，我将介绍在理想场景没有出现时收集数据的不同方法。

## 公共数据

有时，我们有可能找到公共数据集来完成我们的任务。这里列出了一些可以找到免费公共数据集的地方:

*   [NLP-datasets Github 知识库](https://github.com/niderhoff/nlp-datasets)
*   [Awesome-Project-Ideas Github 知识库](https://github.com/NirantK/awesome-project-ideas)
*   [Awesome-Public-Datasets Github 知识库](https://github.com/awesomedata/awesome-public-datasets)
*   谷歌的专业搜索引擎(数据集)

如果你能找到一个合适的并且与你正在解决的问题相似的数据集，那就太好了！你可以建立一个模型并评估它。

## 数据抓取

如果没有任何公共数据集可供使用，我们很可能会在互联网上找到一些相关的数据源，例如，人们用来与企业互动的 FAQ 或论坛。我们可以抓取这些数据，然后让人类注释者为我们标注。

然而，在许多工业环境中，这种从外部来源收集数据的策略是不够的，因为数据不会包含典型产品的细微差别(即产品名称、产品特定的用户行为)。这意味着我们的外部数据可能与在生产环境中看到的数据非常不同，这是灾难的完美配方。

> **注意**:当你决定从事网络抓取任务时，有几个问题需要注意——在[网络抓取挑战](https://www.octoparse.com/blog/9-web-scraping-challenges)中阅读更多相关信息。此外，您总是希望通过检查您希望抓取的网站的 robots.txt 文件以及使用条款来确保您尊重您抓取的网站(这通常是一个更具限制性的文件，因此检查这一点非常重要)。

## 产品干预

在现实世界中，人工智能模型很少(如果有的话)作为一个单独的行为存在。人工智能模型通常通过产品或功能为用户服务。因此，人工智能团队应该确保他们与产品团队合作，通过为产品开发更好的仪器来收集更多和更丰富的数据。这种策略在技术领域被称为*产品干预*。

一般来说，当涉及到在工业环境中构建人工智能应用时，产品干预会取得胜利。

## 数据扩充

这些技术中的大部分都需要时间，而在企业界，时间就是金钱。举个例子，用仪器测量产品来收集数据。如果我们现在对某些产品进行检测，可能需要 3 到 6 个月的时间来收集足够多的数据集。为了克服这个问题，我们可以在我们的小数据集上执行一些数据扩充技术来创建更多的数据。

数据分析中的数据扩充(Data Augmentation)是一套用于增加数据量的技术，通过添加已有数据的略微修改的副本或从已有数据中新创建的合成数据[ **来源** : [维基百科](https://en.wikipedia.org/wiki/Data_augmentation) ]。

在以后的文章中，我将介绍一些为 NLP 任务增加数据的方法。

## 最后的想法

为了让列出的数据采集技术发挥作用，我们首先必须确保我们有一个干净的数据集，即使它非常小。数据来自异构数据源并不罕见，这可能意味着我们的早期生产模型是使用公共数据集、标记数据集和增强数据集的组合开发的，因为我们在开始时可能没有足够大的数据集用于我们的定制场景。

感谢您的阅读！

通过 [LinkedIn](https://www.linkedin.com/in/kurtispykes/) 和 [Twitter](https://twitter.com/KurtisPykes) 与我联系，了解我关于数据科学、人工智能和自由职业的最新帖子。

## 相关文章

[](/its-about-time-we-broke-up-data-science-dd776ac2bd91) [## 该是我们解散数据科学的时候了

### 为什么我们必须分散数据科学，以及它看起来会是什么样子

towardsdatascience.com](/its-about-time-we-broke-up-data-science-dd776ac2bd91) [](/4-data-related-books-ill-be-reading-in-april-efd06b367e35) [## 我将在四月份阅读的 4 本与数据相关的书

### 一定要看看这些书

towardsdatascience.com](/4-data-related-books-ill-be-reading-in-april-efd06b367e35) [](/deep-learning-may-not-be-the-silver-bullet-for-all-nlp-tasks-just-yet-7e83405b8359) [## 深度学习可能还不是所有 NLP 任务的银弹

### 为什么你仍然应该学习启发式和基于规则的方法

towardsdatascience.com](/deep-learning-may-not-be-the-silver-bullet-for-all-nlp-tasks-just-yet-7e83405b8359)