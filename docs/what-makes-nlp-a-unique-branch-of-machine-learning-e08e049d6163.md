# 是什么让 NLP 成为机器学习的一个独特分支？

> 原文：<https://towardsdatascience.com/what-makes-nlp-a-unique-branch-of-machine-learning-e08e049d6163?source=collection_archive---------50----------------------->

![](img/d36718475ada61f9270add78c1c68d56.png)

[斯科特·格雷厄姆](https://unsplash.com/@homajob?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)在 [Unsplash](https://unsplash.com/s/photos/data-processing?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍照

机器学习时代从分析存储在电子表格、传统数据库甚至 CSV 中的二进制数据开始。随着这些模型的巨大成功，数据科学家将这些技术扩展到文本数据。文本数据与处理二进制数据有什么显著不同？在这篇简短的文章中，我将给出一些令人信服的理由，并给出处理文本数据的完整流程。让我先简单描述一下二进制数据预处理的流水线。

# 二进制数据预处理流水线

存储在传统数据库中的数据很少是干净的。几个数据点可能包含缺失值(空值)，所以您从清理数据开始。数据集可能包含许多相关列-通过消除任何不需要的列来减少列数(要素)。各个列中的数据可能有很大的范围-您将需要缩放这些列。在做了这样的预处理后，你的主要任务是减少特征数；计数越高，训练时间和资源需求就越多。现在，让我们看看文本数据需要什么样的预处理？

# 是什么让文本预处理如此不同？

一个数据库表通常包含几列——这个数字以十为单位。数据库中的每一列都是 ML 算法训练中的潜在候选特征。现在，考虑文本数据的情况。对于文本数据，每个单词或句子都被认为是潜在的特征。为了理解为什么，我们需要考虑我们试图在文本数据上开发的 ML 应用程序。

考虑一下我们都非常熟悉的电子邮件垃圾应用程序。机器学习模型在一封看不见的电子邮件中寻找一些冒犯性的单词，如果找到，则将相应的电子邮件标记为垃圾邮件。注意，我们在寻找单词。因此，对于模型训练，我们将把来自训练数据集的电子邮件文本标记为单词标记。使用监督学习，我们将使模型学习根据某些冒犯性词语的存在对电子邮件进行分类。

现在，考虑这样一种情况，你被要求训练一台机器，让它具有概括小说的能力。你很清楚任何一本书的封底段落。一份出色的总结会促使潜在买家购买。这是一个非常高级的 NLP(自然语言处理)应用程序。你需要将整个小说文本标记成句子，并挑选出最重要的句子作为书的摘要。

这两个例子肯定会让您明白为什么我们需要将文本语料库标记为单词或句子，而不是单个字符。现在，主要问题来了。任何文本段落都会包含成千上万的单词和句子。每个这样的标记都是 ML 模型中一个潜在的候选特征。我们必须大大减少这种特征的数量，以使训练可行。

NLP 的第二个最重要的需求是我们需要对单词和句子进行矢量化。与二进制数据相比，二进制数据已经是机器可读的格式，可以很容易地表示为张量。虽然文本数据中的单个字符是二进制格式(ASCII -机器可读)，但在 NLP 中，我们处理单词和句子。我们需要把这些转换成向量。为此，我们使用 Word2Vec、GloVe 等工具。

为了进一步理解为什么文本处理与处理二进制数据如此不同，我将给出完整的文本预处理管道。

# 文本预处理管道

我们对文本预处理的目的是减少我们的单词词汇量。因此，您可能想做的第一件事是从文本语料库中删除所有标点符号。请注意，标记器很可能会将标点符号作为单词标记。您可以使用正则表达式来删除所有这些不需要的字符。接下来，您将删除类似于"*、*、*、*、*、*、*、*等单词。这些词作为特征没有什么意义。我们称之为停用词。

根据您的应用程序类型，您可能还想删除数字或将其转换为文本。当你的词汇表中只包含独特的单词时，将所有单词小写也有助于减少单词数。单词“ *John* ”和“ *john* ”对于机器学习模型来说意义相同，而记号赋予器为这些单词创建两个不同的记号。

此外，可以通过使用词干化和词汇化来减少词汇量。两者都将屈折词还原为其词根形式，除了词汇化确保词根属于该语言这一事实。词形变化是通过给一个词加上前缀、后缀或中缀来修饰它。例如，单词“*播放*”、“*播放*”、“*播放*”将被简化为常见的词根“*播放*”，这也是英语中的有效单词。词干分析器会将单词“*麻烦的*”简化为“*麻烦的*”，同样，在去掉后缀后，它也会将“*麻烦的*”简化为“*麻烦的*”。在这两种情况下，精简的单词在我们的词典中都不是有效的单词。如果只需要语言中的有效单词，就使用词汇化。

完成文本预处理后，您将标记整个语料库，使其准备好输入到您的机器学习模型中。

所有这些过程都大大减少了字数。我列出了下面的各个步骤，供您快速参考。只要你理解每一步背后的目的，就没有必要按顺序执行这些步骤。

*   删除标点符号
*   删除停用词
*   删除/转换数字
*   下部外壳
*   选择独特的单词
*   词干化和词汇化
*   标记化

对于机器学习算法来说，在运行所有上述过程后，单词计数通常仍然很高。我们认为每个单词都是一个特征，我们必须进一步减少它的数量。根据我们正在开发的 NLP 应用程序的类型，我们将使用更多的技术来减少这个数量。

# 高级加工

文本数据是非结构化的，我们的词汇表中的单词没有固定的长度。机器学习算法需要固定长度的输入。这个向量的长度等于词汇表中的单词数。对于大型文本语料库，这个数字仍然很高。为了使它变得更小，你可以使用一种叫做单词袋的技术。在这项技术中，您将文本语料库中最常用的单词收集到一个包中。它们出现的频率决定了最常见的单词。这个袋子的大小决定了向量的长度。

高频这个词并不意味着它与表示文档中的信息高度相关。像“*这个*”和“*那个*”这样的常用词将具有非常高的频率，但是不携带与文档相关的信息。于是，就有了 tf-idf(词频——逆文档频率)的概念。你也可以使用二元语法和 n 元语法来减少你的特征数。对这些技术的描述超出了本文的范围，但是您现在肯定可以开始理解为什么 NLP 在机器学习中有特殊的待遇。

使用 NLP 进行文本处理的要求不止于此。你需要 NLU(自然语言理解)来开发语言翻译等高级应用程序。像 LSTM RNN 这样的神经网络架构就是为此而开发的。这现在被变压器架构所取代。我们现在有许多像伯特、GPT 等模特。对于使用文本数据类型的高级 NLP 应用程序。

# 结束语

基于二进制数据集的机器学习模型开发是琐碎的，因为数据库表中固有的功能数量有限，并且它们具有机器可读的数据格式。与此相反，在文本数据上开发模型非常具有挑战性。这是因为文本语料库的大小，并且考虑到每个单词都是训练数据集中特征的潜在候选。第二，将标记化的单词和句子表示成机器可读的数字向量格式是另一个巨大的挑战。

正如您在上面看到的，不仅需要详尽的文本预处理来减少特征数量，而且在开发 NLP 应用程序时还需要应用许多高级技术，如 BoW 和 tf-idf。更高级的 NLP 应用需要语言和上下文理解，我们有另一个分支叫做 NLU。你现在会很容易理解为什么 NLP/NLU 在机器学习中需要特别的关注和对待，这不是炒作。因此，作为一名数据科学家或机器学习工程师，你肯定需要获得 NLP 技能来处理文本语料库。

# 信用

<https://medium.com/@poojagramo>**—复制编辑**