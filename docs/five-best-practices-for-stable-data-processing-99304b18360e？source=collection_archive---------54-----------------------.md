# 稳定数据处理的五个最佳实践

> 原文：<https://towardsdatascience.com/five-best-practices-for-stable-data-processing-99304b18360e?source=collection_archive---------54----------------------->

## 在设置 ETL 或 ELT 这样的过程时，您应该记住什么

![](img/e26a65dc44c5a3f4fce14558c65ff7c4.png)

蒂姆·皮特森在 [Unsplash](https://unsplash.com/s/photos/river?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄的照片

以下五点是实现 ELT 或 ETL 等数据过程的基础。

## 防止错误

如果失败，应该执行回滚—类似于 SQL:如果作业因出错而中止，那么所有更改都应该回滚。否则，只有 X%的事务被传输，一部分丢失。你很难找到丢失的数据是什么。

## 公平处理时间

一个作业处理 X 个数据行需要多长时间？这为该过程提供了重要的见解。流程运行的频率和时间？我可以向我的部门保证哪些数据的真实性？当数据必须重新加载时会发生什么？等。

## 数据质量测量作业

我的源系统和目标系统是否兼容？如何确定所有数据都已传输完毕？在这里，我建议建立一个监控。衡量数据质量和快速检测错误总是一个好主意，否则可能会导致消费者缺乏信任。在这里找到一些灵感【1】。

## 交易安全

当在您的流程中使用数据库复制软件(例如 Amazon DMS)而不是系统 A 和 B 之间的直接连接时，您可能会遇到麻烦:我曾经有一个复制作业同时从表 A 和表 B 加载数据。两者都由 ETL 过程进一步处理，但是如果来自表 B 的数据集由于高延迟而不可用，并且来自表 A 的数据集被处理，则来自表 B 的信息丢失。在此，我还建议在此过程中监控或分配过多的附加成分。

## 考虑对其他系统的依赖性

对于源系统，必须考虑各种情况:

可用性:源系统什么时候可用？考虑维护周期、停机时间等。

**高数据负载**:目标系统不得从源系统接收任何不必要的更改(CDC)，例如在高峰时间。因此，按照上述观点，例如，数据传输可以在例如夜间的批处理作业中进行。

**其他系统的不必要行为:**如上所述，数据库复制服务可能会破坏您的 ETL 过程，但也会出现其他问题，例如重复和不一致的数据。在这里，了解源系统及其缺陷是很重要的。

## 结论

对我来说，这是建立稳定和安全的数据流程的五个最重要的组成部分。你应该永远记住，数据质量是一个非常重要的话题。否则，您可能会缺乏用户和业务部门的信任。

## 资料来源和进一步阅读

[1]克里斯蒂安·劳尔，[如何提高你的数据仓库质量](/data-warehouse-quality-matters-188d3ccd303) (2020)