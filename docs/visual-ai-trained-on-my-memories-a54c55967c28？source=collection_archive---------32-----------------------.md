# 根据我的记忆训练的视觉人工智能

> 原文：<https://towardsdatascience.com/visual-ai-trained-on-my-memories-a54c55967c28?source=collection_archive---------32----------------------->

## #MERZmory:借助人工智能探索摄影

![](img/f86d2230798da55153c15e4dcc8472e5.png)

我的 MERZmory 实验的各种完成(StyleGAN +我的照片)//图片作者

我的父亲是一名职业作家和摄影记者。他记录了苏联和俄罗斯的生活和文化。当我们来到德国时，他没有停下来。直到生命的最后几天，他都在拍摄和记录德国。几年前他去世后，留给我一个巨大的照片档案。

重温他的照片档案，我意识到一件事:

> 摄影师拍下他或她当时经历的地方、人物和情景。这位摄影师与一位旁观者分享记忆，他将在未来的某个特定时间凝视这些照片。

## 共享的记忆。

大概父亲的职业成了我的困扰——我开始到处拍照——在家里，在工作中，在去日本的旅途中，我也想与世界分享我的记忆和经历——把它们发布在 [Instagram](https://www.instagram.com/merzmensch_kosmopol/) 上。它们不仅仅是报道我的行踪的图片；我试图与世界交流我的想法和观点。

当我开始深入研究[创造性人工智能](https://medium.com/merzazine/creative-artificial-intelligence-index-1464fb9a8569?sk=1d153c62020ee07bc11a2fcab7475b6f)时，对我来说最迷人的事情之一是一台机器对人类文化遗产的重新诠释。人工智能如何重建我们的想象、梦想和欲望？

已经让我大吃一惊了。

![](img/8c28b94e4857fc8e650e8ab289e20054.png)

图片来自我的文章"[BigGAN as a Creative Engine](https://medium.com/merzazine/biggan-as-a-creative-engine-2d18c61e82b8)"//图片作者

随着 [StyleGAN2](/12-colab-notebooks-that-matter-e14ce1e3bdd0?sk=3cae22488e4bff5f01a1e71fb01975c8) 的出现，在海量数据库上训练(例如 FlickrFacesHQ 等。)，我们已经进入了视觉创意的新领域。

但仍然有一件事让我很困扰。经常使用所有这些数据集(即 ImageNet 等。).但是我的摄影呢，我的内心世界——如果我在作品上训练人工智能，我会认出来吗？

我做到了。

## 我用我的记忆训练人工智能。

有多种方法可以在数据集上训练 StyleGAN2。幸运的是，对于我们中的非编码人员来说，有 [RunwayML](https://medium.com/u/2d612be6e147?source=post_page-----a54c55967c28--------------------------------) (它值得一篇特别的文章[稍后发布])。

在你的照片数据库上训练 AI 的工作流程很简单。你必须:

1.  **在一个文件夹中收集至少 500 张你想用来训练的图片** /我自己用了大约 3000 张 Instagram 图片
2.  使用 [RunwayML](http://runwayml.com) 上传它们
3.  选择您的数据集
4.  选择预先训练的模型和训练步骤

![](img/91d2fab2463f4cde4d60dde38f4b2e57.png)

3)选择数据集(截屏来自 RunwayML，图片由作者提供)

![](img/e9f72070c6fdcefa4c4b5bc2c0aa78da.png)

4)选择预先训练好的模型(截图来自 RunwayML，图片由作者提供)

…然后运行它。

对于我的实验，我使用了各种设置和预先训练的模型。结果令人兴奋。这是我的发现。

# 实验一:抽象记忆

![](img/6151194b386ede5ee7e02b0fa7af4c4f.png)

(截图来自 RunwayML，图片由作者提供)

首先，我采用了预先训练的 StyleGAN2 模型“Flickr Faces HQ”。即使我(最初)不想生成人脸，这种模型的好处是:它具有目前最好的分辨率(1024x1024)，正在对来自 flicker 的大约 70k 高清人脸进行训练(你从“[这个人不存在](/this-item-does-not-exist-2defbac76b39?sk=f444e16f44856396cf97e5939d055211)”中知道他们)

对于训练步骤，我选择了 **4000** 。我想在最初的实验中远离面部图像和特征，从语义上转向 Instagram 数据集的内容。

**这里有一个免责声明:**事情不是这样的。我的 Instagram 数据集由各种风格和流派的照片组成:风景、人像、实验、微距摄影等。StyleGAN2 无法将这种多样性概括为特定的类别。但这不是我想要的。

我想要的是体验，而不是具体的东西。

我已经得到了。

![](img/ce2d9f6c6557aaa8fe1438a6cddcf3f5.png)

作者提供的图片

我有非常抽象的视觉效果和一些可识别的特征。取而代之的是“相同能量”倾向的新图像。

有趣的还有图像的**词源**或**考古学**(在视觉模型的情况下，我们可以使用这两个术语来表示 ***寻找机器完成*** 背后的根源和原件)

![](img/d08cce3bddb2224f36c778a63bf5a26b.png)![](img/83db872190dfbcef8069b2951e6f1942.png)![](img/6387a39131f189c81af2a9f9d697bec6.png)

左:AI 生成的图片/中+右:来自我的 Instagram 数据集的图片//所有图片由作者提供

或者一些微距摄影:

![](img/65fea59c12562caafe44c42ee58ac7ad.png)![](img/44eb35059e1a670fb5e34a6ab937236f.png)![](img/b9ba8121c5c645744dfb6d8995a6e174.png)

左:AI 生成的图片/中+右:来自我的 Instagram 数据集的图片//所有图片由作者提供

![](img/7c40f724e8567d47cd810bff30933288.png)![](img/99e615dfd71f0e156f66cb23a922e2a0.png)![](img/5364cd5f1d947f1e25dff1ed2c23990d.png)

左:AI 生成的图片/中+右:来自我的 Instagram 数据集的图片//所有图片由作者提供

对于了解他的摄影的作者来说，这样的重新发现是鼓舞人心和令人着迷的。

RunwayML 的另一个伟大之处是**矢量/潜在空间浏览器**，在这里你可以精确地找到你要找的东西。通过改变“截断”和“采样距离”，您可以通过寻找具有稍微不同特征的特定图像来微调您的视觉搜索。

![](img/b9017fcad34fe251ad2064552b5ef86b.png)

作者提供的图片

在 4000 步之后，我摄影的紧张和情绪战胜了人工智能预训练的模型。

![](img/11d30c88b2351636567585fc6f101f51.png)![](img/fa8289f6af4297773049a9cd4f6e5c27.png)![](img/ae6cb76b4cf91d9c720857d64f419b47.png)

我第一次实验的几张照片。//图片作者

这是我记忆中的视觉旅程，由人工智能创造:

(图片由我提供，音乐由 AI 模型[点唱机](/jukebox-by-openai-2f73638b3b73?sk=003ba0e0d6416a4456c7a890fddf9461)创作，图片由作者提供)

因此，回顾我的实验，我回顾了我训练的某个地方**600**——预先训练的 StyleGAN2 模型的脸仍然出现在特征中。我的 Instagram 照片无法辨认。这样的面孔可以赢得每一场“被诅咒的形象”比赛。

![](img/d1aee0f636dd50a5bb88e2298f4f738b.png)

作者提供的图片

但现在我看到了一种新的可能性:如果我在 Instagram 图片上稍微训练一下 StyleGAN2，让原始的 FlickrFaces 出现在开头的某个地方，会怎么样？扭曲，但不是令人毛骨悚然的方式？

我做到了。

# 实验二:记忆的面孔

我在我的 Instagram 照片上重新训练了 StyleGAN，采取了更少的步骤(大约 500)。

我所看到的出乎意料的好:

![](img/c923c96ee4c05626f4c3bd3e8c2e450b.png)

是的，的确，许多面孔仍然是你在梦里不喜欢遇到的样子，但许多面孔与 Instagram 数据集功能完美融合。

![](img/014a18fa3e327a57033999ec0296c291.png)![](img/e64157d7878e4c8989a875d1b8292a40.png)![](img/539dd010627e1def6f2c0b9db0f77847.png)

作者提供的图片

这种消失的个性的风格和主题，人工智能驱动的讲故事，以及人类驱动的解释，这种人机合作为美学和叙事带来了新的视角。

使用潜在空间浏览器，你可以找到最有趣的面孔:

![](img/91c71333322027d178d06cde02869c86.png)

RunwayML，作者图片

这里——动态:

# 实验三:你记忆中的物体

在面孔让我相信人工智能的创造力之后，我想在抽象艺术(*实验 1* )和具体的面孔(*实验 2* )之间找到一条中间道路。我选择了另一个数据集，针对不同的对象进行了预训练。

已经走了 500 步之后，我得到了各种各样的主题(即使汽车和其他交通工具应该是数据集中最常见的对象)。

![](img/12d1548009f53938f1af15be6180811b.png)

作者提供的图片

这种模式的缺点是完成尺寸(512x512)，但优点是图像的多样性。

提示:使用各种人工智能方法，你可以将图像放大到你需要的尺寸。

特别是在这里，你需要潜在的浏览器，以避免多余的汽车图像，寻找中间的珍珠和宝石(不是反对车辆，只是多样性是重要的):

![](img/555b2d8e31f2908b31968eeaec046f10.png)

作者提供的图片

这里有一些例子:

![](img/2086f933840be0a6a97d13c3877cc03d.png)![](img/a1516b39c40d455db5f1fcc3eab0be5e.png)![](img/492a8762428b5a1d3536e495c79ef884.png)

作者提供的图片

作为一个短的视觉和音乐装置(音乐是由人工智能模型自动点唱机产生的)

(视觉效果由我制作，音乐由 AI 模型[点唱机](/jukebox-by-openai-2f73638b3b73?sk=003ba0e0d6416a4456c7a890fddf9461)创作)

# 结论

当然，在预先训练好的模型上进行训练并不是什么新鲜事。研究人员和艺术家已经用它进行了几十年的试验(即使机器学习的“几十年”意味着 1-2 年，因为发展正在迅速演变)。

但是仍然有太多的东西需要去发现，去重新诠释，去微调。毕竟，这与技术无关；这是关于我们的想象力。(这仍然可以通过技术来增强)。

是关于人机协作的。

![](img/b9e210adb229f3c21d5a122d9e6f4e49.png)

作者提供的图片