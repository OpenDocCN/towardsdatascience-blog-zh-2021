# 异常检测多样化领域的初学者综合指南

> 原文：<https://towardsdatascience.com/a-comprehensive-beginners-guide-to-the-diverse-field-of-anomaly-detection-8c818d153995?source=collection_archive---------4----------------------->

## [实践教程](https://towardsdatascience.com/tagged/hands-on-tutorials)

## 隔离森林、局部异常因子、一类 SVM、自动编码器、稳健协方差估计和时间序列分析

![](img/a02bf81cfbb166794f66a83f030b83b2.png)

作者图片

*异常*或*异常检测*处理数据中不符合预期行为的模式的检测。这些方法几乎应用于所有行业。众所周知的应用领域是检测信用卡和保险欺诈、网络安全、安全相关系统的监控和军事活动的评估。[Cha09a]

由于我将在本文中使用生产中的一个例子，所以我也不想在这里忽略这个重要的应用领域。智能工厂变得越来越敏捷、灵活、多变，因此也越来越复杂。由于这种不断增长的复杂性，操作人员很难监控过程和识别偏差。问题和故障往往发现得太晚，维护间隔选择不正确[Win15]。用于早期异常检测的智能系统可以通过在早期阶段检测到偏差来提供显著的缓解，并避免生产停工。

本文旨在通过回答以下问题，为您提供异常检测领域和所用技术的概述:

*   **异常的类型有哪些？如何描述它们的特征？**
*   **哪些程序和方法**用于识别数据集中的异常？怎么才能把他们区分开来？
*   **使用了哪些具体的算法，它们是如何工作的？**
    - [稳健协方差估计器](#5bb4)
    - [隔离森林](#800a)
    - [局部离群因子](#d90e)
    - [单类支持向量机](#2751)
    - [自动编码器](#cc5a)
    - [时间序列分析](#36dd)

请不要被术语“*异常值*”和“*异常值*”所混淆，我将两者作为同义词使用。

## 异常的类型

异常在发生时有决定性的不同。基本上，异常可以分为三种类型:

*   *点/全局异常*
*   *集体异常*
*   *上下文异常*

**点异常**

如果能够将单个数据实例归类为*异常*相对于其余数据，它被称为*点*或*全局异常*。这描述了最简单的异常值类型，也是大多数出版物关注的焦点。

在下图中，*点异常*显示为二维空间中的单个异常值。数据集可以清楚地分为 3 个集群。由于被标记的数据点不能被分配给任何一个聚类，必须假设该数据点代表一个*异常*。

![](img/ba2e8ad09ae4c3f5b42c3280a95033d0.png)

二维数据集中点异常的简单示例—作者提供的图像

**上下文异常**

如果一个实例只在特定的上下文中表现为*异常*，则称之为*上下文异常*。上下文由给定数据集的结构决定。[Cha09a]

下面的数据集显示了墨尔本从 1981 年到 1984 年的气温趋势。标记的数据点代表*上下文异常*。因为大约 30 度和零下 5 度的温度本身并不罕见，但在本课程的其余部分，这些情况可以归类为非常不可能。在夏季的几个月里，气温在零下的范围内，在冬季达到 30 度是不太可能的。

![](img/80c9d4485573f17714842fbf78805d9a.png)

气温记录中的上下文异常(数据集:澳大利亚墨尔本的最低日温度[Aus90] —已修改)

**集体异常**

如果相关实例的集合可以被识别为数据集其余部分的异常，这些实例描述了所谓的*集体异常*。将这些实例单独与数据集的其余部分进行比较，这些实例可能不会被识别为异常，但它们在集合中的出现证明了将其指定为异常值的合理性。[Cha09b]

下面的例子用几个月内大致相同水平的温度测量集合来模拟这种情况。

![](img/f9691afa065072331975400d469ab640.png)

气温记录中的集体异常(数据集:澳大利亚墨尔本日最低气温[Aus90] —作者修改)

## 哪些方法用于识别异常？

异常检测领域试图识别数据集的异常实例或与大多数数据显著不同的实例。[Zim18]。这通常是指偏离定义的分布模型的数据。最著名的分布函数是正态分布，它可以用来非常精确地描述许多经济和工程过程的测量值的分布。[Fah16，第 83 页][Zim18]

除了这些概率方法，还有基于决策树、距离/密度方法和重建技术的方法。

**监督方法也能发挥重要作用**

特别是对于带标签的训练数据，基于模型的方法也是一种强大的替代方法。大多数技术过程是循环的，因此由重复出现的信号模式来表示，这些模式可以用回归或时间序列分析来建模。这使得识别与“*正常*过程的微小偏差成为可能。

下图给出了一个例子。它显示了空气中的声音水平记录旁边运行的铣床。在许多自动化过程中，可以检测到循环信号(在这种情况下，大约每 40 秒重复一次)。这种重复信号可以通过时间序列模型高精度地再现。通过简单地比较预测和记录，这种基于模型的方法可以实现比无监督方法明显更高的准确性。如果训练数据集不包含异常值、包含少量异常值或包含已知数量的异常值，那么这无疑是有帮助的。

该图像显示了形成的信号模型。在这个简单的例子中，在机器附近用锤子敲击来模拟偏差。通过比较模型和实际信号，可以清楚地看出这种偏差。这种方法可以扩展为不同的功能，如频率分析。

因此，如果您想要检测重复信号模式的偏差，对信号进行建模通常是一种强有力的方法。

![](img/71ce7fc565690cdd129f8ccce9c747cc.png)

根据模型声压曲线的偏差检测生产过程中的异常——作者的图像

## 所用算法的方法有根本的不同

下面的清单试图对不同的方法进行分类。然而，这不应该被看作是一个严格的分组，因为不同的技术使用来自不同领域的方法。

*   **概率方法**
    这些方法是基于对事件发生的某些概率假设。数据点根据其概率分布进行评估。概率非常低的实例被识别为异常值。(例如*稳健协方差估计器*)【AIG 15，p . 392】【SPE 14】【ott 18】
*   **距离和密度方法**
    无参数方法根据环境考虑和评估数据点。如果在一个数据点周围的区域中有足够多的相似数据点，则该数据被评估为正常。数据的这种相似性通常由数据点之间的距离来表示。 *k 最近邻算法*就是根据这个原理工作的。[第 16 页，第 207 页][第 18 页]
*   **聚类方法**
    这些方法寻找相似对象和结构的分组。实例以这样的方式分组，即一个组内的数据尽可能相似，但是不同分区的数据尽可能彼此不同。不能被分配到任何组的实例被归类为异常值。[Sha13][Hot04]
*   **重建方法**
    这些方法试图检测数据中的模式，目标是能够重建无噪声的信号。属于这些方法的已知算法是*主成分分析(PCA)* 和*复制器神经网络(RNN)* 。

如前所述，大多数方法旨在对特征空间中的区域进行建模，这些区域描述了所考虑过程的正常行为。位于定义区域之外的数据称为异常数据。然而，一些因素对这种相对简单的方法提出了挑战。在实践中，通常不可能清楚地定义正常范围，正常和异常行为之间的界限并不总是清晰的。

正常和异常行为的所有实例的集合可以通过相应的概率分布来描述。只有极少数情况下，这些分布会彼此明确分开，并允许对正常情况和异常情况进行唯一分类。下图显示了大多数用例的情况(左)和目标最佳情况(右)。在左图中，不可能实现 100%的正确分类。

![](img/482000d4d80075ccccf669cf7e3f98c7.png)

根据实例的异常分数
和预定义的阈值将实例指定为正常/异常—图片由作者提供(受[Koi18]启发)

在左图的情况下，只能以最大化真阳性率和最小化假阳性率为目标。右图显示了最佳特征提取的目标。如果以这样的方式选择特征，使得正常和异常情况彼此有很大的不同，则分布曲线没有直接的交点。在这种情况下，可以选择灵敏度，使得真阳性率为 1，假阳性率为 0。

对于已经使用的**声压记录示例**，声学已经提供了一些特征变换的可能性，例如*快速傅立叶变换*。将信号转换到频域有助于更准确地区分*正常*和*异常*事件。

异常检测算法使用异常分数评估各个数据点，作为后续决策的基础。基于预定义的阈值，实例根据其异常分数被分类为正常或异常。

![](img/4295fe6e4127d4346636cdeba3ffca87.png)

异常分数的阈值定义了系统的敏感度——作者的图像

阈值决定了系统对异常情况的敏感程度，代表了一个超参数。虽然在医学中，即使是与正常状态的微小偏差也会产生巨大影响，因此必须将其视为异常[Cha09a][Hod04]，但由于大量的随机扰动，生产环境中系统的灵敏度过高是不合适的。尤其是在所考虑区域的环境中的这些随机影响导致数据中的大的噪声成分，这通常类似于异常并导致错误分类。[Hod04]

对于每个用例，应该对错误分类的后果进行评估。假阳性率(FPR)和真阳性率(TPR)必然是相互权衡的。阈值描述了异常分数的极限值。如果数据点的异常分数超过预定义的阈值，则将其标记为异常。基本上，降低的阈值导致 TPR 和 FPR 的增加。对于大多数用例来说，这是进行权衡的地方。

需要关于该过程的额外知识来确定最佳阈值。在工业中，主要目标是成本最优的阈值。例如，未检测到的异常可能导致设备故障和维修工作。另一方面，具有高假阳性率的系统导致操作员的大量控制努力。为了解释这种权衡，文献经常使用医疗保健的例子。在癌症检测测试中，低阈值是合适的。未能检测到早期疾病会降低患者存活的可能性，而未能检测到健康患者的测试只会导致进一步的测试。因此，高 TPR 的权重高于低 FPR。

## 新奇与异常检测

在异常检测领域，文献区分了新颖性和异常检测[Sci19b]:

**异常值检测**

例如，如果训练数据集包含与其余数据差异很大的实例，则这些实例可能是由于数据采集中的错误造成的。对于模型构建，这些数据点是令人不安的，会对模型产生负面影响。它们应该被预先识别并从训练数据集中移除。[Koi18]

**新颖性检测**

新颖性检测假设训练数据集不包含异常值或包含已知数量的异常值，而是对新实例是否描述异常事件感兴趣。[Koi18]

## 用于异常检测的算法

各种各样的算法、方法和途径被用于异常检测。以下是该领域已确定方法的汇编:

![](img/a347c0370b822588d2c392464ce61f85.png)

异常检测算法概述—图片作者提供

异常检测领域流行的算法有*稳健协方差估计器、**隔离森林、*局部异常因子算法、*单类支持向量机、*，下面将简要介绍。在深度学习领域，主要使用*自动编码器*。在*时间序列*和*回归分析*的帮助下，可以建立模型，该模型可以再现和预测所考虑过程的行为。

## 稳健协方差估计量

许多统计程序需要用协方差矩阵来估计数据的分布。[Sci19a]

*联合概率分布*描述了某些值组合出现的概率。给定一个带有两个*随机变量 X* 和 *Y* 的数据集，结果是一个*二元概率分布*。对于几个随机变量一个所谓的*多元分布*。[Haz02][Fer03]

*稳健协方差估计器*算法通常用于*异常检测*，通过假设数据呈正态分布来检测数据集中的异常值。对于新的数据点，可以基于建模的概率分布来确定测量值的概率。

最常用的分布模型是*多元正态分布* ( *高斯分布*)。下图显示了两个*随机变量 X* 和 *Y，*的二元正态分布，最大值出现在 *x = 0，y = 0* 。测量的数据点离该点越远，该数据点越不可能代表所考虑的过程的正常行为。如果数据点的预测概率低于定义的阈值，则将其标记为异常值。

![](img/af747d460aa0b84f44f55b1c1bb02c68.png)

多元高斯分布—图片由作者提供

## 隔离森林

决策树的创建是通过在所谓的叶节点划分数据来迭代完成的。数据的这种划分从树根开始。在回归和分类任务中，每一步的目标都是最大化*信息增益 IG* 。当在一个节点上以这样一种方式完成数据集的分割时，即实现子节点中杂质的最大减少时，就是这种情况。杂质有不同的定义。例如回归使用*均方误差*，分类使用*熵*或*基尼系数*作为杂质的度量。[Ras18，第 107 页][Has09，第 587 页][Ras18，
第 347 页]

***隔离树*** 则相反，随机分割数据集。创建隔离林包括以下步骤[Har18][Vie19][Liu12]:

1-为了对单个隔离树建模，首先从 d 维特征空间(D ⊂ R^d)中的训练数据集 d 中选择大小为ψ的子集 d’

2 —该部分数据集用于构建*隔离树*T’。对于第一个分区过程，该算法选择一个随机特征 q 和一个分区点 p，其中 p 在数据集中该特征的最大值和最小值之间。

3 —在这个分割点 p，数据集分割成 *D_l* 和 *D_r*

4-重复第二步和第三步，直到每个节点只有一个实例，或者该节点上的所有数据都具有相同的值

下图显示了为二维数据集生长一棵*隔离树*的前两个除法过程。

![](img/5924ea49afda0af935a91f7dfc7adccc.png)

一棵孤树的生长——作者图片

设置隔离树后，该方法计算隔离各个点所需的分割步骤。该算法基于隔离异常值所需的步骤明显减少的假设。离群点检测感兴趣的是单个数据点 *x* 的*异常分数 s(x，ψ)* ，其由隔离数据点的路径长度来描述。

下图显示了此过程的一个简单示例。虽然仅需要两个除法步骤来隔离数据点 1 和 7，但是实例 5 和 3 在四个除法步骤之后被隔离。如果无限频繁地重复*隔离树*的创建，隔离 6 和 7 平均所需的步骤数将显著低于其余数据点。

![](img/dfdd4bcab84a0f30b125cd1a3919c3a7.png)

简单的二维隔离树示例—图片由作者提供

**从隔离树到隔离林**

整个数据集的一部分用于创建每个隔离树。使用 *k-* 创建数据集的不同部分*k-隔离树 T_k* 。隔离森林的结果是各个隔离树的路径长度 h(x)的平均值。

由于单个隔离树的最大大小强烈地依赖于所使用的数据集 D’的大小，因此需要归一化来获得有意义且可比较的结果。为此，引入了归一化因子 c(ψ)，它描述了不成功搜索的平均路径长度[Liu12]:

![](img/7fd2c3feb4e019b8002d18fe603eea4b.png)

然后，异常分数 *s* 可以计算为:

![](img/a4bd2445b81f9d34641e8aecf92da3a3.png)

**随机森林如何工作的更详细描述可以在论文** [**基于隔离的异常检测**](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/tkdd11.pdf) **中找到。【柳 12】**

下图显示了 skicit-learn 隔离森林模块(`sklearn.ensemble.IsolationForest`)对一维数据集的预测输出。该图显示了定义的*决策函数* ( `decision_function = -s — offset_`)的输出，该输出是使用被求反的*异常分数 s* 和定义的*偏移*计算的。在这种情况下，使用默认的偏移值`-0.5`。因此，对数据点的评估如下:值越低，越不正常。负值被声明为异常值，正值被声明为内部值。

![](img/173adab94a4d10240b7486a0b94b7fc1.png)

隔离森林:使用异常分数区分内点和外点——图片由作者提供

## 局部异常因素

局部异常值因子(LOF)算法通过测量给定数据点的局部偏差来查找异常值。该算法基于局部点密度的概念。密度由到 k 个最近邻的距离来描述。通过比较每个实例的密度，可以识别具有相似密度的区域。同时，可以检测到异常值，其显示出明显较低的密度值。

LOF 是*基于密度的聚类*方法之一，它将聚类描述为对象彼此靠近的区域。对于簇中的对象，局部点密度超过给定的阈值。属于同一集群的对象集合在空间上被分组在一起。

该领域中常用的算法是 DBSCAN ( *基于密度的带噪声应用空间聚类*)。DBSCAN 区分*核心点、密度可达点*和*噪声点*。*核心对象 p* 是距离ϵ.至少达到 *minPts* 数据点的所有数据点

![](img/c2a235d6b7ae7ba772bb162df15dd1aa.png)

DBSCAN:识别核心对象—作者提供的图像

*密度可达对象 q* 是没有达到这个密度值，但是从一个核心对象直接可达的对象。这些属性都不适用的数据点称为噪声点，因此不属于该聚类。[Bre00][Zim][Int96][Kir02]

下图显示了核心点、密度可及点和噪声点的逐步识别。

![](img/778deecb38bb2616e44196bac8fd78e2.png)

DBSCAN 算法的功能—图片由作者提供

1.  识别距离ϵ.至少达到 minPts = 6 的所有核心物体
2.  识别密度可达点，该点在ϵ.的距离内到达至少一个核心物体

到目前为止还没有被识别为*核心对象*或*密度可达对象*的实例代表*噪声点*。这些*噪声点*代表发现的*异常值*或*异常数据点*。

下图显示了更真实的数据集的分类。

![](img/2a0a8a0e5af93d101a114f77bf91f2ce.png)

DBSCAN 应用于真实数据集—作者提供的图像

LOF(局部离群因子)算法采用了 DBSCAN 的部分方法。LOF 还引入了可达性距离的概念。所谓的 *k -distance* 是指一个物体到其 k-nearest neighbor 的距离。[Kir02]

![](img/80f917c5b7e6860ca0c50eb823db0432.png)

DBS can:k-最近邻和 k-距离的定义—作者图片

可达性距离由对象 A 和 B 之间的直接距离或对象 B 的*k-距离*定义。距离 k-距离内的对象被评估为等距，从而产生更稳定的结果。

![](img/94d85b2e379019c374a8023b17677d9b.png)

由于多个对象可能具有相同的距离，在 *k 距离*中可达到的值集合可能包含 k 个以上的对象。这组邻居被表示为 *N_k(A)* 。[Als10][Sch14]

对象 A 的*局部可达性密度(lrd)* 计算如下:

![](img/dee0338317df9c7e7574323d83653b53.png)

因此，密度是对象 A 到其邻居的平均可达性距离的倒数。

然后将该局部可达性密度与相邻实例的可达性密度进行比较[Bre00]:

![](img/61e944c94949c9645ea6c2b36118583b.png)

值为 1 的 *LOF_k(A)* 指示所考虑的对象 A 与其邻居相当，即它不是异常值。低于 1 的值表示相邻对象的密度较高，因此是一个*内层*。异常值用大于 1 的值来描述。在这种情况下，密度低于相邻实例的密度，这表明存在异常值。

## 单类支持向量机

支持向量机(SVM)概念将低维数据映射到新的高维特征空间。对转换后的数据执行随后的学习过程。在这个空间中，数据可以更容易地分离和分类。[Kun04]

在所谓的*线性分离*(也称*线性分类*)中，数据被一条直线或平面分成两组，即所谓的*超平面*【Kun 04】。由 Vapnik 于 1963 年首次引入，当 d 维数据集的分离由 *(d-1)维超平面*完成时，线性分类器被称为线性分类器。[jr08][cor 95]

![](img/d194f9d6a19b05f9691d760f1ac2595b.png)

寻找所谓的*最大边缘超平面(MMH)* ，即与最近点`y_i=1`和`y_i = -1`的距离最大的超平面。*超平面*定义为:

![](img/389f95d29fe3ea3c1e1a99ac6c72da1d.png)

SVM:两类数据集的超平面定义——图片由作者提供

在大多数情况下，数据不能通过简单的线性分类来分离。这是使用基于核函数的非线性分类器的地方，这允许算法在变换的、更高维的特征空间中找到 MMH。下图显示了一个不能用简单的线性分隔符分隔的数据集。在该示例中，通过简单的多项式核(z = x 2 + y2)将数据分离到 d + 1 维特征空间中，其中通过线性平面的分离是可能的。

![](img/cc082c5cb8e452214998f938d103a560.png)

SVM:特征变换后二维两类数据集的线性分隔符—图片由作者提供

**一级分类**

schlkopf【Sch01】将 SVM 方法转化为只有一个类别的分类问题。[bou 14][man 01]*schlkopf 的*方法以数据集和原点之间的距离ρ最大的方式设置超平面[Tax01]。

为此，开发了一种算法，该算法返回一个函数 *f* ，该函数在一个尽可能小的范围内取值+1(正常实例的范围),并且在该范围内包括训练数据集的大多数数据点。该策略通过一个*核 k(x，y)* 将初始数据转移到一个更高维的特征空间。在该空间中，数据集与原点分离，使得*距离* ρ最大。

![](img/03ef9c9effc92382d1cc280fe6af800d.png)

一类 SVM:一类支持向量机是如何工作的—图片由作者提供(受[Yan16]、[Gue15]启发)

除了*schlkopf*方法外，还经常使用*税收和关税*方法。这里，*超平面*不采用平面形式，而是用球体【Bou14】包围数据集。

你会发现一个关于一级 SMV 如何工作的更详细的解释。

## 自动编码器

自动编码器是用于学习高效数据编码的神经网络。[Kra91]他们通过几个隐藏层重建输入信号。因此，代码的尺寸受到限制，迫使尺寸减小，并能够识别模式。

自动编码器包括编码器和解码器。编码器通过忽略信号“噪声”将输入转换成编码。解码器将这种新的表示(编码)转换成原始形式。与降维类似，autoencoder 旨在尽可能接近地复制输入数据集。

因为自动编码器的执行受到限制，迫使它学习对其影响最大的数据特征。目标是通过识别数据中的结构和模式对*高维数据*进行*低维* *编码*。因此，自动编码器搜索*编码器函数 f* 和*解码器函数 g* ，在将 *f* 应用于 d 维输入空间 X ⊂ R^d 的任意元素 *x* 然后将 *g* 应用于结果元素 *z* 之后，尽可能精确地产生输出元素 x。[Saa18][Pie12]

因此，自动编码器学习并复制最重要的特征，或者换句话说，最频繁观察到的特征。由于“正常”数据通常在训练数据集中所占的比例要高得多，因此它们的复制性非常好。另一方面，很少出现的“异常”数据不会被复制或者复制得不够好。通过简单地比较输入数据和重构数据，可以识别异常值。[An15]

![](img/abe8dc9ec4f49140d7fa1fc82b43dd33.png)

自动编码器模型架构—图片由作者提供

## 时间序列分析

随时间顺序记录的数据称为时间序列。

![](img/21e088e40a07c4f4e6f35733b85e81bb.png)

如果每个时间点只有一个观察值( *n = 1* )，我们称之为单变量时间序列；如果 *n > 1* ，我们就说多元时间序列。时间序列分析在经济、股票交易和智能电网控制领域非常重要[Mah16]。由于生产过程也具有循环过程的特征，时间序列分析在制造业中的应用越来越多[Bas07][Keo06][Keo02]。预测时间序列为决策提供了重要的信息。

回归方法对目标变量 y 和几个独立变量 x1、x2、.。。，x_n .自变量的值不受其他特征的影响。【BAC 06】*时间序列分析*则局限于一个自变量 x， ***时间*** ，对预测未来目标值感兴趣。这是通过分析过去的数据来完成的。大多数方法旨在识别不同的信号成分:

![](img/ee47825b99cb74cbb925908c5738a012.png)

时间序列的可能组成部分—作者图片

这些分量用于预测没有噪声数据的输出信号。如果预测值和记录信号之间的偏差超过定义的阈值，则历史中的实例或信号部分随后被宣布为异常值/异常。

## 摘要

希望我能给你一个不同的检测异常技术的概述。基本上，异常检测的领域不限于特定的算法。上面列出的方法只是特别经常使用，应该能让你理解一些基本原理。

然而，对于您自己的用例，您不应该感到受到这些的限制。你应该考虑任何可以让你区分正常的和异常的的*统计方法。*

如果您觉得这篇文章很有帮助，您还可以找到一篇关于用于*回归*的概念和算法的类似文章:

[](/7-of-the-most-commonly-used-regression-algorithms-and-how-to-choose-the-right-one-fc3c8890f9e3) [## 7 最常用的回归算法以及如何选择正确的算法

### 线性和多项式回归、RANSAC、决策树、随机森林、高斯过程和支持向量回归

towardsdatascience.com](/7-of-the-most-commonly-used-regression-algorithms-and-how-to-choose-the-right-one-fc3c8890f9e3) 

如果您还不是中级高级会员并打算成为会员，您可以通过以下推荐链接注册来支持我:

[https://dmnkplzr.medium.com/membership](https://dmnkplzr.medium.com/membership)

感谢您的阅读！

## 参考

[Als10] Alshawabkeh，m .张，b；加速入侵检测系统的 GPU 上的局部异常因子算法。2010.

【An15】安，Jinwon 使用重建概率的基于变分自动编码器的异常检测。2015.

【BAC 06】巴克豪斯，k .多元分析方法:一个 anwendungsonoritierte einführung。2006.

巴苏，美国；时间序列的自动异常值检测:传感器数据的应用。2007.

[Bou14] Bounsiar，a；梅登，M. G .赫劳斯盖伯。单类支持向量机。2014.

[Bre00]布留尼格，m；克里格尔；Ng，Raymond，Sander，jrg。LOF:识别基于密度的局部异常值。2000.

钱德拉五世；班纳吉；异常检测。2009.

【cor 95】科尔特斯，c；支持向量网络。1995.

[Dei18]戴斯特勒，m；Scherrer，w . Zeitreihen and station re Prozesse。2018.

[Ert16] Ertel，w . grund kurs küNST liche Intelligenz:一种实践或科学。2016.

[Eur10]未来购买力平价的因素，2010 年。网址[https://op . Europa . eu/de/publication-detail/-/publication/0 F4 eaca 5-05 f1-4532-937 e-f 504441 f73 e 0](https://op.europa.eu/de/publication-detail/-/publication/0f4eaca5-05f1-4532-937e-f504441f73e0)

[Fah16]法赫迈尔湖；霍伊曼角；Künstler，r . Statistik:Weg zur 数据分析。2016.

费尔努尼哈根。gemeinsame Wahrscheinlichkeitsverteilung。2003.

[Gue15] Guerbai，y；奇巴尼 Y 比拉勒·哈德贾吉。基于与书写者无关的参数有效使用一类 SVM 分类器进行手写签名验证。2015.

[Har18]哈里里；用于异常检测的密西西比州隔离林。2018.

【has 09】哈斯蒂，t；蒂布拉尼河；统计学习的要素:数据挖掘、推理和预测。2009.

数学百科全书。2002.

霍奇，V. J。异常值检测方法的调查。2004.

hot 04:hot ho，a .与 Hintergrundwissen 一起群集。2004.

第二届知识发现和数据挖掘国际会议论文集。1996.

[Jr 08]Jr gensen，S. E .生态学百科全书。2008.

基奥，e。洛纳迪，s。在线性时间和空间的
时间序列数据库中发现令人惊讶的模式。2002.

基奥，e。林；李；寻找最不寻常的时间序列子序列:算法与应用。2006.

[kir 02]h .-p .哈普特《KDD 研讨会:集群化》。2002.网址[https://www . DBS . ifi . lmu . de/Lehre/haupt seminar/SS02/KDD 02/Clustering-peer . pdf](https://www.dbs.ifi.lmu.de/Lehre/Hauptseminar/SS02/KDD02/Clustering-Peer.pdf)

[Koi18]小泉，y；斋藤，s。Uematsu，h；川内，y；基于深度学习和 ney man-Pearson 引理的异常声音的无监督检测。2018.

【kra 91】Kramer，Mark A. [“使用自联想神经网络的非线性主成分分析”](https://www.researchgate.net/profile/Abir_Alobaid/post/To_learn_a_probability_density_function_by_using_neural_network_can_we_first_estimate_density_using_nonparametric_methods_then_train_the_network/attachment/59d6450279197b80779a031e/AS:451263696510979@1484601057779/download/NL+PCA+by+using+ANN.pdf) (PDF)。1991.

机器学习研讨会:支持向量机。2004.网址[http://campar . in . tum . de/twiki/pub/Far/machine learning wise 2003/kunze _ ausarbeitung . pdf](http://campar.in.tum.de/twiki/pub/Far/MachineLearningWiSe2003/kunze_ausarbeitung.pdf)

刘；丁敬明；基于隔离的异常检测。
2012 年美国计算机学会数据知识发现汇刊。[https://cs . nju . edu . cn/Zhou zh/Zhou zh . files/publication/tkdd 11 . pdf](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/tkdd11.pdf)

[Mah16] Mahalakshmi，g；南希里黛玉；Rajaram，s .关于时间序列数据预测的调查，2016 年。

马内维茨，法律硕士；用于文档分类的一类支持向量机。2001.

奥托，T. Anomalie-Erkennung 与机器学习。2018.

[Pat18] Patel，A. A .使用 Python 进行实际操作的无监督学习。奥莱利媒体公司，2018。

皮埃尔·巴尔迪。自动编码器、无监督学习和深度架构。2012 年 ICML 无监督学习和迁移学习研讨会会议录。

拉什卡；Mirjalili，v .机器学习与 Python 和 Scikit-Learn 和 tensor flow:Das umfassende Praxis-Handbuch für Data Science，2018 年。

[Saa18] Saalmann，E. Einführung，自动编码器与卷积神经网络。2018.网址[https://dbs.uni-leipzig.de/file/Saalmann_Ausarbeitung.pdf](https://dbs.uni-leipzig.de/file/Saalmann_Ausarbeitung.pdf)

schlkopf，b；j .普拉特；肖-泰勒法官；斯莫拉，美国；估计高维分布的支持。神经计算

[Sch14]舒伯特，e；齐梅克公司；重新考虑局部离群点检测:对局部性的概括观点及其在空间、视频和网络离群点检测中的应用。数据挖掘与知识发现，28，2014。

【Sci19a】2.6。协方差估计-sci kit-learn 0 . 21 . 1 文档，2019 年。

【Sci19b】ScikitLearn。2.7.新颖性和异常值检测-sci kit-learn 0 . 21 . 1 文档，2019 年。网址[https://sci kit-learn . org/stable/modules/outlier _ detection . html](https://scikit-learn.org/stable/modules/outlier_detection.html)

[Sha13] Sharafi，a .数据库中的知识发现。2013 年威斯巴登施普林格法赫梅登。

概率学家 Verfahren，2014 年 12 月 4 日。https://www.spektrum.de/
T4【lexikon/geographie/probabilist scis-verfahren/6232 ren/6232

[Tax01] Tax，D. M. J .一级分类。2001.

[Vie19] Vieira，r .隔离森林简介 Rui Vieira，2019。URL[https://Rui Vieira . github . io/introduction-to-isolation-forests . html](https://ruivieira.github.io/introduction-to-isolation-forests.html)

温德曼；迈尔，a；尼格曼岛；弗雷，c；贝尔纳迪，a；顾；普弗罗默；t .斯特克尔；Krüger，m；制造过程的大数据分析。物理学杂志:会议系列，2015。

[Yan16]杨、金宏；邓，廷全。一种用于稳健异常检测的自适应加权单类 SVM。2015 中国智能系统会议论文集。2016

[Zim] Zimek，a .聚类 Teil 2。网址[https://www . DBS . ifi . lmu . de/Lehre/KDD/SS14/skript/KDD-3-Clustering-2 . pdf](https://www.dbs.ifi.lmu.de/Lehre/KDD/SS14/skript/KDD-3-Clustering-2.pdf)

【Zim18】齐梅克，a；舒伯特，e .离群点检测，2018。