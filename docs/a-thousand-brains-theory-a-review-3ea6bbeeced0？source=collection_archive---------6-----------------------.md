# 一千个大脑理论综述

> 原文：<https://towardsdatascience.com/a-thousand-brains-theory-a-review-3ea6bbeeced0?source=collection_archive---------6----------------------->

![](img/934fd23289dcbf6ad7815c96b394fc4e.png)

未点燃: [**淡淡的**](https://unsplash.com/@halacious)

## *关于智力和大脑皮层如何工作的新理论。*

# 介绍

很长一段时间以来，我一直在关注神经科学家的初创公司 [Numenta](https://numenta.com) ，该公司的目标是了解新皮层，以再现学习算法中的机制。

创始人杰夫·霍金斯写了《一千个大脑:智力新理论》一书。对于热爱神经科学和人工智能的我来说，这个标题很有吸引力。在他的书中，作者讲述了大脑和智力理论的历史。他用轶事和经历解释他是如何得出他的理论的。

他的假设很有趣，改变了我们计算所有实际机器学习算法的方式:

> 我在本章探讨的假设是，大脑使用参照系储存所有知识，思维是一种运动形式。当我们在参照系中激活连续的位置时，思考就发生了。第 71 页

在这篇博客文章中，我将只谈论这本书的前两部分 1) *对大脑的新认识*和 2) *机器智能*。第三部分是关于*人类智力*但是，我不打算解释它。我认为读者应该对这一部分有自己的看法，而不是我提供给他们的偏见。

我们走吧。

# 对大脑的新认识

作者在 Mountcastle (1978)[1]的基础上建立了他的理论。在这篇论文中，他解释说，新大脑皮层是一种皮层算法。Mountcastle 将其描述为一种通用算法，而没有关于*算法*的细节。

新大脑皮层可以被视为一个张量，其相同的计算单位被克隆了十万次。事实上，新大脑皮层包含 150，000 个皮质柱(将其视为包含固定数量神经元的神经层)。每个皮质柱由 100 个迷你柱组成。形象化这种架构的最佳方式是想象一盒意大利面条。盒子是皮质柱，意大利面是迷你柱。

好了，这里你已经掌握了什么是皮层柱。现在，想象这个皮层柱是一个乐高积木，为了构建新皮层，你将许多皮层柱相互靠着放置，并将它们连接起来，以创建一个 3D 网络。这就是美所在。除了一些细节，无论你从哪里看，每一列几乎都是一样的。每一列可以计算任何刺激或感觉(听觉、嗅觉、触觉、味觉和视觉)。

现在，考虑一个单独的列。它可以分析和处理输入信号，不管信号的类型。所以，每一列也可以预测一个输出。这意味着每一瞬间有 150，000 个预测。新大脑皮层**以连续的时间步长预测成千上万的现实**。这是**预判**，意识看不到它，除非它犯了**错误**。你通过分析错误来学习。

但是，大脑学习什么呢？如果所有的信号都被相似地感知。如果大脑区域不容易区分。大脑是如何学习的？

所有信号都在同一位置进行处理和计算。大脑如何确定距离？确定声音来自特定的一侧。它是如何知道到达特定空间抓住一个物体需要给初级大脑哪个信号的？大脑从对现实的感知中学到了什么？

我们学习一个**的世界模型**。

大脑，皮质柱，**预测未来**，对片刻的**逐渐适应**。**学习出现在它所犯的错误**中，并为它的世界模型提供**更新。**

此外，大脑必须对它感知到的东西做出假设。周围没有环境标签。它必须首先假设，以一种*无人监管的方式*，并发出**个假设**，然后用**标签**验证它们。

新大脑皮层会学习物体的形状或总体特征。这将允许识别它们，而不管特征的添加或修改。因此，它学习规则。

它还必须学习检索信息的机制。它学习的信息不可能永久可用。信息流刚刚击落了它。因此它必须通过**关联**来学习。气味会唤起记忆。纹理带回图像等。

因此，新大脑皮层将充当**知识图表**。特定的输入将允许访问与类似事件相关联的存储器。我把它想象成一个理解的数据库。

与当前通用的机器学习方法不同，**大脑必须在**双动态空间**中持续学习**。世界在运动，大脑也在运动。我们可以将其视为**持续强化学习**或**持续探索**。

动力将允许大脑皮层**在事件和感觉之间建立联系**。此外，它将能够学习它产生的动作的**效果**。就是**感觉运动学习**。

大脑需要预测事件的持续时间，以便能够在环境中运动和行动。但是，它需要做两种类型的预测。一个关于环境的。第二，他在环境中的表现。

因此，大脑学习并创建具有**位置**的**参考帧**。参考系就像是环境和物体的**网格**。大脑不会保存每个事物的图像，而是保存兴趣点的表示。这就像你脑子里有一个多重网格的世界。每个皮层列可以学习**上百个**的对象。

世界，对于大脑来说，是一个**记忆序列**(动力学)。需要位置来**关联位置**和**记忆**，因为它允许你找到路并移动。

人工智能领域目前的对等物是 **RNN 家族和注意力机制**。新大脑皮层创建的**世界模型是感官输入、参考框架和位置**的**组合。新大脑皮层并不负责运动和地图的创建。这需要**老脑**来做。主要是*海马*和*内嗅皮层*。**

每个神经元会在数百个之间搜索对应的映射。它在树突的帮助下作为**联想记忆**工作。在引言中提供的引文中。作者假设**知识被编码在参考框架中，位置**，或者连接这些点的能力**创造了思维**。思维是选择相应的皮质柱。这是可能的，因为**参照系学习的是世界的表象，而不仅仅是物体。**该位置允许皮层列选择相应的地图。

理论的名称从何而来？如前所述，新大脑皮层是以基于迷你柱的皮质柱为基础的。这种方法是一种**千脑**万脑**理论**。

在这个理论中，大脑皮层柱相对相似，但只能保留固定大小的知识。所以知识是**传播**在十五万栏里面但是与**重叠**。如果一个零件受伤，信息不会丢失。

但是，这里有一个问题。如果数百列保留相同的信息或信息的一个版本，大脑**如何只感知一件事**？叫做**绑定问题**。

皮质柱如何解决束缚问题？笔者简单的回答是:**通过投票**。对我来说，每一列都会以**的概率**预测一条信息。如果信息达到多数，则选择参考帧。

神奇的是，在皮层列中，提供投票的**神经元**总是同一个**。每次需要投票的时候，**相同的神经元**就会通过皮质柱被激活。**

如果不幸的是，两张地图出现的概率相同，神经元就会达成**共识**。这就是为什么**注意力是强制性的**。

# 机器智能

很棒的标题。但是，人工智能中没有智能。在目前 AI 使用的方法中，只有一个 a。

> 人工智能的未来将基于模仿大脑的原理。第 117 页

为什么？

作为人类，我们不断地学习。我们的大脑每秒更新一次它的世界模型。实际的神经网络需要完全训练一次，并且在重新训练时难以学习更多的东西而不丢失太多的信息(称为**灾难性遗忘**【2】)。一个名为**持续终身学习**【3】【4】的新领域使用连续的数据流来训练神经网络，而不会丢失信息。

但是为什么不是 I 呢？这是因为今天的系统专门做一件事，而人类可以做多件事。人工智能不灵活。

目前，人工智能研究人员无法编写一个接近五岁儿童智力的系统。他们还没有找到创造日常知识的方法。这个问题叫做**知识表示**，被认为是*唯一的问题*。

大脑学习一种知识模型，而不是文字或图像。就像我们在第一部分看到的，大脑学习**类似地图的参考框架**。

那么如何认为一个系统是智能的呢？标准是什么？

作者提供了**四个标准来构成机器智能的基础**。

1.  机器需要**不断学习**(持续终身学习)。机器需要从错误中学习来更新它的世界模型。机器需要创建新的连接来获取新的知识，而不需要替换或删除旧的连接。
2.  机器将需要**通过移动**(称为具体化)来学习。运动导致定位。如果回避，世界表象就会有偏差。
3.  机器需要创建许多模型。新大脑皮层的每个皮层列学习一个上千个对象的模型，解决绑定问题(一个独特的感知)的过程是通过**投票进行的。**一台机器需要获得同样的流程。
4.  机器需要使用参考系来存储知识。思考是一种运动。它是通过连接参考帧中的点而出现的。如果机器不能运动，它就不能思考。
    皮质柱使用类似网格细胞和位置细胞的细胞。

**当机器有意识时**

意识依赖于不断形成我们最近的想法和经历的记忆，以及回放它们的能力。

**觉知**似乎与**意识错综复杂。**记忆和注意力是意识的基础。如果我记得我昨天在做什么，并取代每一个时刻。我知道他们，我有意识。

机器智能需要**目标和动机**。但是，它们按照不同的程序出现，在机器中编码(我们的 DNA 为我们的身体编制了吃饭、呼吸等程序。).或者他们是有学问的。他们还需要安全措施。对我们来说，一个安全措施就是屏住呼吸不死。对于一台机器来说，艾萨克·阿西莫夫的机器人三定律可能是一个好的开始。
目标和动机不是智力的结果，不会自己出现。

# 结论

新大脑皮层的缺点:每个神经元都是有线的，所以如果一个区域在开始时(年轻时)不活跃，它就永远不会活跃。这就是为什么小时候听过多种语言的孩子长大后有更多机会流利地使用多种语言。目标是在机器中避免这种机制。

作者没有谈论大脑中存在的量子过程或量子现象(化学过程或信息的传送)。

越来越强大的量子计算机的出现，很可能会改变我们对大脑的看法。

最后一句话，这是一本很棒的书，我推荐给大家。它为新皮层和我们如何学习提供了一个新的视角。作者的方法非常有趣，并一直引发想法和问题。

我更欣赏的是作者提出了他的观点，他的理论而没有批评那些已经存在的人。即使当他讨论智能机器时，他也只是指出已经建立的限制。

# 参考

*   [1]芒特卡斯尔，弗农，1978 年。*大脑功能的组织原则单元模型和分布式系统*。正念的大脑，7-50。麻省剑桥—麻省理工学院出版社。[http://ni corg . Pb works . com/w/file/fetch/49365852/mount castle % 20 organizing % 20 principle . pdf](http://nicorg.pbworks.com/w/file/fetch/49365852/Mountcastle%20Organizing%20Principle.pdf)
*   [2]迈克尔·麦克洛斯基，尼尔·j·科恩，1989 年。*连接主义网络中的灾难性干扰:顺序学习问题。*学习与动机心理学，学术出版社，第 24 卷，第 109–165 页。[https://doi . org/10.1016/s 0079-7421(08)60536-8](https://doi.org/10.1016/S0079-7421(08)60536-8)
*   [3]詹姆斯·柯克帕特里克和阿尔, 2016.*克服神经网络中的灾难性遗忘*。ArXiv。[http://arxiv.org/abs/1612.00796](http://arxiv.org/abs/1612.00796)
*   [4]德国帕里西等人著，2019 年。*利用神经网络的持续终身学习:综述*。神经网络，第 113 卷，第 54–71 页。[https://doi.org/10.1016/j.neunet.2019.01.012](https://doi.org/10.1016/j.neunet.2019.01.012)
*   [https://en.wikipedia.org/wiki/Three_Laws_of_Robotics](https://en.wikipedia.org/wiki/Three_Laws_of_Robotics)