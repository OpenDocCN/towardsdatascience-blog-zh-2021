# 推荐系统的伦理挑战

> 原文：<https://towardsdatascience.com/ethical-problems-with-recommender-systeems-398198b5a4d2?source=collection_archive---------11----------------------->

## [播客](https://towardsdatascience.com/tagged/tds-podcast)

## Silvia Milano 谈到了我们需要探索的难题，以构建有益的算法

要选择章节，请访问 Youtube 视频[这里](https://youtu.be/Ng13EoLMCS8)。

*编者按:这一集是我们关于数据科学和机器学习新兴问题的播客系列的一部分，由 Jeremie Harris 主持。除了主持播客，Jeremie 还帮助运营一家名为*[*sharpes minds*](http://sharpestminds.com)*的数据科学导师初创公司。可以听下面的播客:*

[苹果](https://podcasts.apple.com/ca/podcast/towards-data-science/id1470952338?mt=2) | [谷歌](https://www.google.com/podcasts?feed=aHR0cHM6Ly9hbmNob3IuZm0vcy8zNmI0ODQ0L3BvZGNhc3QvcnNz) | [SPOTIFY](https://open.spotify.com/show/63diy2DtpHzQfeNVxAPZgU) | [其他](https://anchor.fm/towardsdatascience)

生活在这样一个世界里，我们可能想要的各种数据都唾手可得，其中一个后果就是，我们可用的数据比我们可能查看的要多得多。想知道你应该进入哪个大学项目？你可以访问十万个网站中的任何一个，每个网站都提供有用的见解，或者看看数百所不同大学网站上的一万个不同的项目选项。唯一的障碍是，当你完成那个复习的时候，你可能已经毕业了。

推荐系统允许我们从每天为我们指明方向的信息水龙带中有控制地啜饮一口，从庞大的目录中突出少量特别相关或有价值的项目。虽然它们是非常有价值的技术，但它们也有一些严重的道德失败模式——其中许多是因为公司倾向于建立推荐器来反映用户反馈，而没有考虑这些系统对社会和人类文明的更广泛影响。

这些影响是显著的，并且正在快速增长。Twitter 和谷歌部署的推荐算法定期就我们这个时代的关键道德问题塑造公众舆论——有时是有意的，有时甚至是偶然的。因此，与其让社会被这些强大的算法重塑，也许是时候我们问一些关于我们想要生活在什么样的世界的大问题了，并倒推找出我们的答案对我们评估推荐引擎的方式意味着什么。

这正是我想和本期播客的嘉宾西尔维娅·米兰诺谈谈的原因。Silvia 是推荐系统伦理的专家，也是牛津人类未来研究所和牛津互联网研究所的研究员，她在那里参与了旨在更好地理解推荐算法的隐藏影响以及如何减轻其更负面影响的工作。我们的谈话引导我们思考复杂的问题，包括身份的定义、人权自决权以及政府与科技公司的互动。

以下是我最喜欢的外卖:

*   Silvia 指出了现代推荐系统中的四个利益相关者，每个人都有不同的兴趣和理由关心推荐质量的不同方面。首先是最终用户——直接消费推荐的人(亚马逊购物者、网飞账户持有人和投机者等)。其次是系统本身，它需要平衡即时用户满意度和让用户测试尚未评级的产品的机会(有时亚马逊可能有一个新产品需要评估，它可能会向你推荐，尽管它的算法怀疑另一个选项更有可能更好地满足你的即时需求)。第三，运营这些系统的公司分别关心长期用户满意度，以及可能的其他考虑，如监管压力。最后，基于推荐者影响人们偏好的方式，整个社会会随着时间而改变。因此，Twitter 的用户并不是唯一对 Twitter 推荐系统的完整性和质量感兴趣的人——每个人都是。
*   推荐者对于对他们的用户重要的时间范围做出隐含的选择。例如，Twitter 旨在尽可能长时间地垄断用户的注意力，引诱你去做在很短的时间内让你开心的事情。但是在短期内感觉良好的决定在长期内并不总是感觉良好。当你最终注销时，你可能很容易觉得你的时间被浪费了，即使从一秒到下一秒，你只是在执行你当时“想要”做的动作。其他推荐者有不同的时间范围(例如，亚马逊关心你是否信任它的评论，这要求你购买产品并在留下反馈前进行测试)，但当涉及到决定他们希望评估他们与软件交互的质量时，用户通常没有什么选择。不同的时间范围意味着不同的产品开发选择，所以这是一个非常有影响力的自由度，目前不在消费者自己的手中。
*   在我们希望通过与人工智能系统(如推荐者)的互动来“改进”和“成长”的愿望，以及我们希望保留代理并控制我们成长和改进的轨迹的愿望之间，有一种自然的紧张关系。例如，Twitter 不仅仅向用户提供推荐的文章和帖子，它还主动*塑造*用户的偏好，包括他们对时事的看法。在这个过程中，Twitter 用户转变成了不同的人。如果你在与推荐系统的互动中可以改变自己，你对这种改变的程度和方向有多大的发言权？这仍然是推荐系统伦理中一个悬而未决的问题——也是一个大问题。
*   由于推荐系统的影响远远超出其直接用户群，一个自然的问题是:政府应该在监管中发挥作用吗？不幸的是，每个推荐者都是不同的，政府不太可能有技术能力、理解或带宽来负责任地逐案监管每个推荐者。因此，Silvia 建议，他们的作用可能会变成促进行业规范和标准的形成，并通过玩更多的元游戏进行行业监督，包括通过法律，使监督团体更容易监控和采取行动违反某些道德规范的做法。

你可以[在推特上关注西尔维娅](https://twitter.com/SilviaMilano1)，或者[在推特上关注我](https://twitter.com/jeremiecharris)。

## 播客中引用的链接:

*   人类未来研究所的网站。
*   西尔维娅在牛津互联网研究所的网站，或者[她在人类未来研究所网站上的简介](https://www.philosophy.ox.ac.uk/people/silvia-milano)。

![](img/e28e0e60283836eb7a87669248c0488a.png)

## 章节:

*   0:00 介绍
*   1:13 西尔维娅的背景
*   5:11 推荐系统的伦理限制
*   权利的量化
*   10:02 后果主义评价
*   11:58 结果主义评估的领先替代方案
*   23:06 人格同一性的一般问题
*   27:34 用户、提供商和系统
*   30:34 实施方面的问题
*   37:16 跨期选择
*   39:53 系统设计
*   51:23 政府的作用
*   59:34 总结

## 请查看下面的文字记录:

杰里米(00:00:00):
大家好，杰里米，欢迎回到播客。今天我们与 Silvia Milano 交谈，她是牛津人类未来研究所的研究员，也是牛津互联网研究所的研究员，她在那里从事人工智能伦理学的工作，特别是，她最近一直专注于推荐系统的伦理学。所以我们将会谈论很多关于推荐系统的内容，特别是，我们将会关注的一个关键领域，就是现代推荐系统中的利益相关者是谁的问题。那么，这仅仅是关于最终用户吗？仅仅是关于与 Twitter 应用程序交互的人吗？还是和网飞一起？或者不管是什么？或者，我们是否必须开始缩小一点范围来思考公司、思考系统，甚至思考这些推荐系统及其用户所处的社会和文明？

Jeremie (00:00:45):
西尔维亚的观点是，是的，事实上，我们有。当我们意识到这一事实时，这些问题就变得非常有趣，既道德又实际。因此，我认为可以公平地说，我们正在进行一系列非常有趣的对话，从个人身份到公司和政府在非常强大的推荐系统中的责任。我真的很喜欢这次谈话，希望你也一样。西尔维亚，非常感谢你参加我的播客。

Silvia (00:01:11):
谢谢你邀请我。

Jeremie (00:01:13):
你能来我真的很高兴。我们之前已经简短地谈过一次，但我真的很期待在这里深入一点，特别是关于你在推荐系统方面的工作，这是一个非常热门的话题。推荐系统的伦理问题，我认为是我们仍在努力解决的问题。我们才刚刚开始，真的，但是在我们进入正题之前，我想先问问你。当初是什么让你一头扎进这个领域的？你是如何对推荐系统感兴趣的？你是如何结束你现在所做的研究的？

Silvia (00:01:43):
嗯，这是个好问题。这是多种因素的结合。我对人机交互很感兴趣，对这个领域的普遍兴趣也很感兴趣，我发现我读到的关于推荐系统以及这个系统如何构建我们的在线交互以及我们的数字生活的文章并不多。这就是我第一次意识到这是一个大话题的原因。但是目前有太多的问题没有得到解答，所以我想，我真的想深入研究一下。从认识论的角度来看，这很有趣，因为，嗯，有各种各样的问题。例如，我们如何知道某件事何时与用户相关？我们如何知道某件事是正确的建议？从伦理的角度来看，很明显，推荐东西看起来像是非常私人的、有针对性的个人行为，但实际上有各种各样的社会影响。所以从伦理上来说，我认为尝试去理解和剖析这些东西是非常有趣的，在我们的社会中，推荐系统的功能是什么？

Jeremie (00:03:07):
是的，每次我想到这个问题时，我都会想到，尽管存在所有这些问题，但推荐人显然会一直存在，他们非常重要，真的没有办法绕过他们。我内心的勒德分子想说，“好吧，我们有一些推荐者，可以说他们正在撕裂我们的社会结构，让我们摆脱他们吧。”但实际情况是，无论存在什么问题，普通人都没有时间去收集《纽约时报》级别的新闻报道，我们也没有时间收集这种产品信息，从这个意义上来说，这几乎就像新闻业。看起来我们要解决的就是这件事，对吧？

西尔维亚(00:03:49):
对，没错。我想说不仅仅是一个正常人。任何人，你不可能在每个话题上都是专家。也就是说，在这一点上，我们可以不需要推荐系统，也就是说，我们可以不需要互联网上所有的数据和信息。

Jeremie (00:04:07):
是啊。

西尔维亚(00:04:08):
是的，我们可以。我们做到了。我们过去常常把它留在那个场景中，但显然，它有如此大的价值，我们不想放弃它。而是将所有这些可用的数据和信息转化为实际可用的东西，并与我们的日常生活相关，转化为推理的方式。我们确实需要推荐系统，它能帮助我们克服信息过载，找到一条路，找到一条穿过所有这些信息的路。

Jeremie (00:04:43):
是的，正如你在所有研究中指出的那样，它们的成本很高。我认为很多人几乎都是本能地意识到这种成本是多少。他们已经看到了他们的行为是如何受到与 Twitter，甚至亚马逊上的产品推荐的交互的影响。但是你能不能花一点时间，解释一下你在伦理上对推荐系统可能产生的影响以及它们可能产生的更广泛的外部性的一些具体担忧。

Silvia (00:05:11):
我提出了一个分类法来思考推荐系统的伦理限制。我目前正在建立分类法来回答你提出的这类问题。因此，从这个角度来看，我们应该区分推荐系统对不同利益相关者效用的影响。所以向用户推荐某些商品和信息的结果。这将如何影响效用，比如说，消费商品或信息的用户本身，或编写信息的提供商，系统本身，托管推荐系统的平台或更广泛的社会。所以这就是，我们可以从效用的角度来考虑，或者从这些不同的利益相关者的角度来看，如何评估后果，我们可以这么称呼他们。这是评估的一个方面。

西尔维亚(00:06:19):
如果你愿意，另一个维度可能更符合道义论，与系统本身的行为有关。因此，这些行为是否侵犯了一些权利，例如，用户的权利，是否侵犯了用户自主权，是否侵犯了一些权利，这是我们可能无法根据建议的后果来兑现的事情，但可能行为本身是有问题的。因此，我建议从这两个大的方面来看待[相同的 00:06:50]影响。我马上想到了几个挑战。一旦我们以这种方式看待事物，我们就能立即看到，例如，在效用方面，在结果论的评价方面。

Silvia (00:07:10):
还有其他事情要做，例如，这些建议有多准确，它们是否促进了效用和利润。推荐项目的提供者和用户自己的平台。所以这些是非常广泛的考虑因素。此外，还有更多与公平有关的考虑，这些考虑更多地是在制度层面上。例如，我们是否以某种方式构建推荐系统，比如新闻推荐。一些叙事是否更加前景化，为什么，对我们的社会有什么影响？

Jeremie (00:07:56):
是的，不，我认为右边有很多，这是经常发生的事情。所以我爸爸是一名律师，我实际上，特别是在我读大学的时候，研究定量的东西，我对他描述过程的方式感到非常沮丧，特别是在刑法中，得出关于特定被告有罪或无罪的结论。所以他总是告诉我陪审团显然不应该根据概率来思考。

Jeremie (00:08:29):
有这样一条禁令，如果陪审员认为他们有罪，并且没有合理怀疑，那么他们就会被判有罪。但是当你试图量化它的时候，当你试图说，“好的，这意味着这个概率阈值。”这显然是不，不，至少在英国法律的传统中，我父亲对此很熟悉，因为我们是加拿大人。这总是让我感到沮丧，因为这就像，不知何故，如果我们要在文明中取得进步，感觉我们真的需要能够量化什么是权利。在推荐系统的环境中，这似乎是很难做到的事情。这是…首先，你认为这是一个真实的问题，还是我在这里为自己编造的？第二，在这个问题上有没有潜在的解决办法，或者有没有一些想法？

西尔维亚(00:09:18):
这是一个非常好的问题，很难回答。目前，我对这个问题的想法是，我们真的需要在我们的脑海中有这个前沿，我还没有提出解决方案，但我们真的需要这个前沿。推荐系统实际上是社会基础设施，因此我们需要考虑它们如何影响人们的权利，基础设施如何工作也应该根据它如何促进个人人权或社会的良好运转来评估。

Jeremie (00:09:56):
是的，我想我们还需要定义这些东西是什么。就像-

西尔维亚(00:09:59):
没错，但这很棘手。

耶雷米(00:10:02):
是啊。

Silvia (00:10:02):
接受结果论的评价当然要容易得多，这也是我一直在做的大部分工作，部分原因纯粹是因为实际原因。

Jeremie (00:10:14):
你能详细说明一下吗？所以对于不是哲学家或者没有受过这种训练的人来说。所以你能解释一下结果主义以及它是如何在这种背景下建立起来的吗？

西尔维娅(00:10:25):
结果主义的广义定义是，在评估一个行为时，重要的是它所带来的后果。举个例子，如果你在两个行动 A 和 B 之间有一个选择，对他们的评价重要的是 A 和 B 的结果，这个想法就是结果主义者告诉你要带来最好的结果。所以你根据行为 A 和行为 B 的结果有多好来排序，选择结果最好的行为。

Silvia (00:11:03):
现在，这是一个非常普遍的想法，它必须在我们如何衡量不同结果或状态的优点方面得到体现？因此，有各种各样的事情需要更仔细地处理和定义，但这是一个广泛的想法。在推荐系统的背景下，我们会问，给定一个推荐，让我们看看做出这个推荐对于收到这个推荐的用户以及这个推荐中其他可能的利益相关者会有什么后果。让我们尝试量化这种优点，然后在此基础上，我们可以对不同的可能推荐进行排名，这些是广泛的结果主义方法来评估推荐者。

杰雷米(00:11:58):
我觉得这真的很有趣，因为作为一个有定量机器学习背景的人，结果主义对我来说听起来非常直观，所以我的下一个问题是，如果不是结果主义，我还能使用什么替代框架呢？有哪些领先的替代方案？

Silvia (00:12:19):
伦理学中结果论框架的一个替代方案是本体论框架。在这种传统中，行为的评估不仅仅是根据其结果，而是根据行为本身的质量。举个例子，非常著名的结果主义者当然是康德。他举了一个非常著名的例子，一个杀人犯来到你的门前，敲你的门，寻找他想杀的人。他带着他的武器来了，这些意图是很明显的。你知道吗？你碰巧知道这个人在哪里。所以问题是，你该不该告诉他？著名的康德说，“事实上，你应该永远说实话，这是你的责任。”

西尔维娅(00:13:10):
所以在这种情况下，如果有人在你家门口的谋杀案中问你，他要找的人在哪里，你应该告诉他。很明显，你不能通过评估好的方面来得出这个答案，因为很明显，如果你告诉凶手真相，你可以预见的结果是非常糟糕的，你认识的这个人会被谋杀。所以，这里的想法是，行为的评估不是根据结果，而是根据行为的质量。举个例子，对于康德来说，撒谎是你永远不应该做的事情。不撒谎是你的责任。

耶雷米(00:13:53):
这很有意思，因为我想这非常直观，它把许多关于道德和伦理的宗教信仰放在那个桶里，你会说，“你可以在生活的每个方面都是结果主义者，除了遵守安息日。”所以凡事都有结果论，还要确保你周五晚上休息，周六早上休息，诸如此类。

西尔维亚(00:14:16):
嗯，你可以说你永远不应该故意或者永远不应该欺骗别人或者永远不应该违背诺言，这可能是一种固有的约束。实际上，如果我们考虑推荐系统，例如，在新闻推荐的环境中，这可能是一个相对直观的约束，对吗？

耶雷米(00:14:40):
是的。

西尔维亚(00:14:41):
你永远不应该说谎。

耶雷米(00:14:43):
这本身就很有趣，因为它已经开始引入所有这些最大挑战之一的隐现幽灵，这是我们所拥有的，这种功利主义的结果主义观点似乎是，它几乎好像没有任何固定的东西。不同的人可以对后果做出不同的解释，这取决于社会背景，我们今天认为是好的东西与我们过去认为是好的东西是非常不同的。

Jeremie (00:15:12):
我总是在思考现在版本的我和未来版本的我之间的区别，我与系统的互动会改变谁。如果我有这种结果主义的自由浮动伦理。在某种程度上，这很难描述，但在我使用 Twitter 之前，我的政治观点是一些信仰。在我使用 Twitter 后，我的政治观点变成了一套不同的信仰，我从那次互动中改变了自己。未来版本的我显然认为他们是对的，但过去版本的我认为他们是对的，就好像过去版本的我的权利被以某种怪异的方式侵犯了，或者可能被侵犯了，这取决于我所接触到的东西。但是从结果论的角度来看，每一步，也许都是有意义的。我不确定我是否表达得很清楚，但是-

西尔维娅(00:16:03):
是的，那太棒了。这是一个很好的例子，也是一个很好的问题。因此，我认为，在对推荐系统的大量研究中，至少当我们认为推荐者试图预测用户偏好时，这可能是隐含的东西。偏好可能是潜在的和固定的。所以我们有自己的偏好，我们只是缺乏足够的信息来知道我们在寻找什么。所以推荐者的任务就是帮助我们，因为他们能够收集更多的信息，根据我们的喜好找到与我们相关的商品，对吗？这是思考这个问题的一种自然方式，我认为它有很长的历史。我知道这是经济思想的一个很长的历史，它实际上与经济学中的偏好分析联系在一起。

Silvia (00:17:08):
所以这里的想法是，当你在使用 Twitter 后，根据这些建议改变你的政治信仰时，这将是因为现在你有了更多的信息。在这些额外信息的基础上，你提炼的不是你潜在的偏好，而是它们的表达。现在你有了更多的信息，你缩小了这些偏好的范围。

西尔维亚(00:17:35):
这是看待这个问题的一种方式。但我觉得也很直观。这反映了许多人的经验，事实上，我们的偏好并不是一成不变的。也许你使用 Twitter 和接触不同观点和建议的经验是，实际上这可以影响你的偏好，这可能比我们想象的更有可塑性，并对你拥有的信息做出反应，不仅仅是通过更新你的信仰和给你关于世界的更好的信息，这有助于你缩小偏好的范围，但并没有真正改变你的潜在偏好[听不清 00:18:19]你的潜在偏好也在更新和过程中。这要复杂得多。所以你说的对，这和结果论的评价有些矛盾。因为，当然，如果偏好是固定的，那么我们可以认为，例如，一个系统，随着时间的推移，满足用户的偏好，最大化他们的效用。

耶雷米(00:18:46):
对。

Silvia (00:18:48):
但是，如果偏好发生变化，我们还需要弄清楚随着时间的推移，这将如何影响我们对系统的评估。所以如果我在 T one 给你推荐什么东西，而你在 T one 的偏好是这样那样的，我可能会在那个时间做一个很好的推荐。但是同样的建议在以后当你的偏好发生变化时，部分由于你与系统的互动可能不再效用最大化。是的，我认为这是一个深刻的问题。

西尔维亚(00:19:24):
在哲学中，这是有争议的事情。我只想提一个事实，哲学中有一个悠久的传统，来自女性主义哲学，它指出了这种传统的偏好分析是非常有限的。事实上，人们的偏好受到他们所处的环境以及他们与其他社会角色的互动的影响。这有好有坏。

Silvia (00:19:54):
所以我认为有几种哲学传统可以用来讨论这些特殊的问题。对于计算机科学的研究人员来说，关注这一点并拓宽他们的视野是非常重要的。是的，因为仅仅从个人用户的角度来看待推荐者的问题，假设他们的偏好是固定的，是非常有限的。

耶雷米(00:20:22):
是的，由于一些奇怪的巧合，我正在查阅一些关于身份的哲学文献，而不是从政治角度或类似的角度。就像字面上的意思，你如何通过时间追踪一个人的身份？我真的会被认为是五分钟前的我吗？人们经常说这样的话，“我已经变了，我现在是一个不同的人。”你是说真的吗？在这种情况下，你对之前行为的法律责任是什么？你怎么能为你将来的所作所为负责呢？

Jeremie (00:20:55):
就推荐者而言，这就像是你自己正在进行一场辩论，将你的偏好强加给未来的自己。如果你想说，“听着，如果我身上的某些东西改变了，我会感到厌恶。我绝不会想成为那种喜欢黑色之类颜色的人。”然后你向前看，比如 10 年。如果你有一个神奇的算法可以告诉你，如果你在未来 10 年内与 Twitter 互动，你所有的衣服都将是黑色的，你将把你的公寓涂成黑色，你会爱上它。你有什么权利改变路线？这似乎是一个棘手的问题。你有没有意识到，你提到了一些例子，我猜想，人们思考这个问题的方式，但是这和哲学同一性文献有什么联系吗，可能和这里有关？

西尔维亚(00:21:53):
是的，当然。它只是打开了如此多的问题，他们真的很迷人。我真的很喜欢最近哲学文献中的一些分析，从一个群体代理人的角度来思考改变自我。所以，把你自己想象成一个不同版本的你的集合。问题是，当你在任何时候考虑一个行动时，这个行动的结果对你未来的自己来说是有趣的，对吗？

耶雷米(00:22:30):
是啊。

西尔维娅(00:22:31):
所以这个想法会考虑到你未来自我的利益，你可能会对未来自我的实现有很多不确定性。这实际上也取决于你在这个时间点选择什么行动。所以可能有一些方法来概念化这个问题，给你一些指导，告诉你如何决定你的偏好何时改变，从这个意义上说，你自己不是固定的。所以这是一个我觉得很有意思的看待这个问题的方式。

Silvia (00:23:06):
当然，更普遍的个人身份问题可以追溯到非常古老的时代，古希腊哲学家正确地说，“我们不会两次穿过同一条河。”我想这个想法是，一切都在变化，一切都在改变。从这个意义上说，这是一个非常深奥的问题，也许我们永远也找不到答案，也许一些非常聪明的哲学家会找到。但是我认为我们不需要为了建立好的推荐者而去破解非常非常难的哲学问题，这是一件好事，因为否则我们基本上会被卡住。

耶雷米(00:23:45):
对，是的。不，是真的。区分我们今天面临的问题和 10 年后可能面临的问题总是有用的。随着技术的进步，我们可能会被迫正面面对其中一些问题，幸运的是，目前情况有所好转。但是就这种范式而言，你在研究中提出了多利益相关者框架的想法，这种想法缩小并说，“好吧，我们不再只考虑用户的直接利益。假设我们有一个更广泛的不同参与者和利益相关者的集合。”我认为，你提到了这个模型中的一些利益相关者，但我想，你是否介意对多利益相关者框架进行一些扩展，以及它如何改变你对推荐系统的看法。

Silvia (00:24:32):
这里的想法是，多利益主体推荐系统是一个在制定推荐时考虑多个利益主体利益的系统。这与长期以来作为推荐系统研究中心的 parody 形成对比，parody 只采用我们称之为用户中心的方法，用户本质上是唯一的利益相关者。所以在这个更古老，更传统的范式中。推荐系统的任务是发现好项目，其中好项目是对推荐系统的用户有益的项目。

Silvia (00:25:18):
在多利益相关方版本中，我们不仅仅考虑用户利益，我们还认为有必要考虑其他利益相关方的利益，我认为这至少应该包括其他三个类别。前两个相对来说已经在推荐系统生态系统中，它们是系统本身，也就是项目的平台和提供者。所以让我们在这两个方面展开一点。或许，提供者是使被推荐的项目可用的一方。例如，在一个电子商务网站中，提供者可能是在平台上出售不同商品的卖家。或者在新闻推荐的情况下，它可能是内容生产者，因此无论谁写，例如，博客或文章。或者视频推荐者，可能是制作视频的任何人。

Silvia (00:26:33):
显然，这些提供商对他们的推荐感兴趣。例如，如果你是亚马逊或易贝的卖家，你对推荐的商品感兴趣。不仅如此，你还想把它推荐给合适的人，他们可能会对它感兴趣并购买它。所以很明显，你和这个建议有利害关系。正如我所说，需要考虑的另一个利益相关者是平台或系统本身。所以很明显，为了可行，这个系统本身需要一些回报。举例来说，如果你在运营一个电子商务推荐系统，你希望从中获得一些利润，如果你是一个新闻推荐系统也是如此。否则，这将根本不是一个可行的业务。

耶雷米(00:27:32):
是的。

Silvia (00:27:34):
我们有用户、提供商和系统。我还建议，我们应该把整个社会作为一个利益相关者来考虑。原因是，虽然很难从概念上理解社会对如何推荐感兴趣，但通常，推荐系统的行为会产生更广泛的社会影响。很难将它们与在推荐系统中运行的特定利益相关者的兴趣联系起来。有两个原因。更直接的一点是，因为通常情况下，甚至不在推荐系统上的人和团体也会受到它的选项的影响。因此，举例来说，即使你不使用亚马逊购物，你也可能会受到其受欢迎程度的影响，因为例如，如果你经营一家小企业，那么你可能会真正感受到亚马逊受欢迎程度的影响。因此，即使你不是推荐系统本身的直接利益相关者，你的利益也会受到影响。

Silvia (00:28:51):
从整个社会来看，我们经常会看到这些推荐者的系统性影响，最明显的例子就是新闻推荐者。但这也可能出现在其他情况下，算法以这样或那样的方式被调整的事实导致不同观点的流行和分布，这可能会对例如政治事件或人们的总体想法以及我们网站的功能产生影响。所以这些事情是非常重要的，并且显然与推荐系统的评估非常相关。所以我认为他们应该被考虑在内，而我们能做到这一点的方法是让利益相关者代表社会本身的观点。

Silvia (00:29:44):
好了，现在我们有四个利益相关方。多利益相关者系统的想法是，一旦我们确定了利益相关者，有两件事我们可以做得比我们没有做好。一个是定义推荐系统的更好的评价。那么，我们可以定义什么指标来评估推荐者的影响呢？其次，我们也可以更好地了解我们正在处理的优化问题。那么我们在这里试图最大化的目标是什么呢？在这一定义中，我们可以尝试考虑所有不同的利益相关者可能试图实现的目标。

杰雷米(00:30:34):
是的，从这个角度来看非常迷人，因为它确实揭示了一些深刻而重要的问题，一旦你开始从这个角度来看，我可以想象，当你在建立一个个人项目或公司内部的推荐系统时，专注于以用户为中心的方法会很方便，因为这可以让你快速迭代，对吗？你可以很容易地测量一个数字，比如用户满意度，用户在购物车里放了多少东西？他们看了多少类似的电影？周期时间开始变得越来越长，因为你开始缩小并说，“好吧，那么从公司的角度来看，这个推荐系统有多赚钱？”你必须等着看成本和收益是什么，也许是 1/4 或 1 年摊销，谁知道呢。然后对更广泛的社会来说，这些时间线变得很长。因此，测量过程变得具有挑战性，可能会令人望而却步，这是一个合理的问题吗？现在，下一步将在一段时间内实现这一点。

Silvia (00:31:35):
是的，我喜欢这个问题。我认为这指出了在概念化推荐系统所解决的问题时，我们所称的抽象层次的合理和有用的选择。所以，对于评估来说，一些几乎是抽象的层次的选择，例如，以用户为中心的方法，在你所说的较短的时间内会更自然。而包含社会评价的抽象层次也需要不同的数据，并且很可能需要更长的评价时间。所以这肯定是一个有趣的研究问题。

Jeremie (00:32:23):
是的，这就像是在商业环境中，很有趣的是，数据的可用性与你所说的完全一致。有时候，你需要评估一个特定模型或特定产品的数据是不可用的，所以你最终会寻找代理。这些替代物并不总是如此，它们可能会变得病态。我在播客上举了两次例子，因为我发现在评估人类行为时，这个例子非常有趣，也非常有启发性。

耶雷米(00:32:54):
有人曾经说过，我不记得是谁说的了，“如果你对一个网站进行 AB 测试，并经常迭代，最终，或早或晚，任何网站都会变成色情网站。”这是一个笑话，但我认为它深刻地说明了人类偏好的测量和优化，根据你的时间范围，如果你以用户为中心，你真的专注于满足即时边缘用户的需求或愿望，你最终会得到一个不是很关键，不是很有前瞻性，非常深思熟虑，可能有很多你没有想到的副作用的产品。我真正喜欢多利益主体方法的是，它含蓄地说，“不，不。你现在看到的是这个等式的一个角落，这里有一个更大的术语集要考虑。”

西尔维娅(00:33:42):
是的，是的，我很喜欢你的说法，你的例子非常引人注目。我认为有几件事可以从中吸取教训。一个问题是，当然，你在寻找代理，但是代理到底是什么？对于用户偏好，如果你观察到的用户行为真的是为了揭示他们潜在的偏好，我们能对这样的情况或用户可能有更多考虑过的偏好的情况说些什么呢？那么，如果他们真的知道这个系统是怎样的，这个案例中的测试是如何发现一些偏好的呢？也许他们想改变这种情况？他们会希望有一个控制机构来控制系统如何发展以及如何向他们展示什么吗？他们想按自己的口味行事吗？我认为这是一个非常有趣的问题。当然，还有一个问题是，在这种情况下，以可能违背人们透露的选择行为的方式给他们打分，是否可以接受，或者在伦理上是否合适。

耶雷米(00:35:09):
是啊。

西尔维娅(00:35:10):
你是否认为应该展示更多，比如说你在一个电子商务网站上，展示更多环保、更可持续的选择，即使你的购买行为表明你真的在追求最便宜的产品，而不是关注环境的可持续性？

Jeremie (00:35:32):
你是否认为，从这段对话中，我们提到的参数之一似乎是隐含的时间范围，这似乎是说，如果我从现在开始为自己的幸福进行优化，我将采取一系列行动，这些行动可能会遵循阻力最小的路径。所以我会在每个增量时间步做最简单的事情。如果你在很长一段时间内把这些加起来，最终我会在某个赌场输掉我一生的积蓄。

耶雷米(00:36:09):
从这个意义上来说，它确实遵循了边缘系统。但如果时间范围变长，我开始说，“好吧，我现在对自己有信托义务，从现在起 10 分钟。”好吧。好吧，也许 10 分钟后我会做些不同的事情。当你开始延长时间范围时，很快你就会进入放弃现在的价值而选择未来的价值，等等，并且考虑进去，这几乎就像是在这样做的过程中，你在向以前的自己致敬，是你在很久以前设定了这个行动过程。

Jeremie (00:36:43):
我本科毕业是因为我自己做的一个决定，在我开始攻读学位的四年前，我兑现了这个决定。那个人知道这将是一个痛苦的转变。每一步我都决定说，“是的，有一条阻力最小的路，那就是退出，躺在沙发上。但我不打算朝那个方向走。”这看起来就像这个框架所做的，它开始引入时间范围，我想知道这是否是一个有用的参数，用来参数化不同的推荐系统，并通过每个系统的伦理含义？

Silvia (00:37:16):
这是我目前的情况，可能正在思考这个问题。我认为你触及了跨期选择的深刻问题。再说一次，我们还是以前的我们吗？事实上，推荐系统通常会根据当前的查询或我们与系统的当前交互给出针对我们的推荐，这意味着时间非常非常短。所以这真的是一条阻力最小的路。例如，如果系统对最大化您在平台上花费的时间或优化点击行为感兴趣，这确实可以挖掘阻力最小的路径，这似乎是当前用户最满意的。但实际上，这并不符合用户在更长时间内的最佳利益，也不符合社会最佳利益。

西尔维亚(00:38:27):
我认为这有几个方面。当然，从伦理上来说，有一个问题是选择合适的障碍级别，我们正在为用户的兴趣捕捉真正合适的粒度级别。因此，很短的时间框架似乎是错误的，因为或者至少可能取决于应用程序。但在许多应用中，这似乎是错误的，因为最大化你的即时满足可能意味着你放弃了其他你认为更有价值但需要更多克制的商品。

Silvia (00:39:06):
例如，如果我们试图最大限度地增加你在视频流媒体平台上花费的时间，这可能真的是你现在享受但可能会后悔的事情。但另一方面，选择一个非常非常长的时间范围可能是不切实际的，因为我们没有太多的数据，也更难框定这个问题。而且，这可能是有问题的，因为这意味着我们将对什么对你有益的评估与你当前的观点捆绑在一起，而这可能会随着时间的推移而改变。所以一定有办法找到正确的地点。这是一个非常有趣的问题。

Jeremie (00:39:53):
从系统设计的角度来看，这真的很吸引人。如果你是一家创建推荐系统的初创公司，这意味着什么？让我印象深刻的一件事是，我们有一种方法来解释长期用户偏好，所以我们正在谈论的那种，比如说长 t，长δt 偏好与短 t 偏好。例如，如果你去 Twitter，你可以随时改变你的设置。如果你去亚马逊，我相信你也可以在那里改变你的设置。

Jeremie (00:40:26):
我觉得我们所做的是我们已经抽象出了长期的部分，我们要去的部分，我想让这个平台把我变成什么样的人？我们把它移到设置部分。问题是，我们的互动几乎一成不变，就像我上 Twitter 时，我不是从我的设置页面开始，而是开始淹没在意见和病毒的海洋中。也是这些迷因被四处传播，每个人都试图说服我。我不会从眼前的长远目标开始。但是，我想，从技术上来说，我可以进入设置，开始更广泛地定义我的经历。

杰雷米(00:41:06):
从实际的角度来看，我想知道，这是否可能是对公司的建议的一部分，甚至可以说，“看，设置，也许应该是你更尊重的东西，或者提醒人们定期查看他们的设置，如果他们担心他们的注意力持续时间，他们在平台上的体验，诸如此类的事情。”这看起来像是一个合理的推断吗？

西尔维亚(00:41:31):
看起来很合理。我还认为，虽然平台给你一些选择是非常重要和有价值的，你可以去设置页面，看看系统如何模拟你，你可以在那里做一些改变。这确实有点像家务杂事。所以我不认为问题是我们应该有更多，有更多的访问和对设置有更多的控制会很好。但是拥有它并不一定能解决我们目前面临的许多问题。它需要更靠前、更居中，成为用户体验的一部分。

西尔维娅(00:42:26):
至少我喜欢的一个例子是，一些推荐系统似乎在增强用户能力方面工作得很好，让他们对系统如何为他们工作有更多的自主权和控制权，并与他们一起帮助他们开发他们的推荐，这就是音乐推荐系统。我认为这是一个非常有趣的案例，系统被设计成这样一种方式，用户真的可以与它互动。通过观察它如何响应他们的倾听行为，了解他们自己的口味，也可以了解如何影响他们的建议。

耶雷米(00:43:19):
对。

Silvia (00:43:20):
这可能是人们与 Spotify 或其他平台互动的一种方式。我要说的是，在这种情况下，我们不仅应该有访问控制的能力，而且我们应该有这样做的积极动机，我们应该成为活动的一部分。所以只要是你必须做的事情，比如洗衣服或者做其他事情。这似乎是一个额外的负担，对我们来说并没有什么回报。或者这是我们在网上体验的一个有趣的部分。但这真的可以，这真的可以是一种方式，不仅可以获得令人满意的建议，还可以了解我们自己。我们如何与不同的事物互动，这些事物如何带给我们满足感，以及我们能影响这个过程的感觉。

Silvia (00:44:24):
这非常重要，因为从本质上来说，我真的想强调这一点，推荐系统虽然用户总是最重要的，但他们是社会基础设施。看不到所有这些意味着我们失去了很多关于如何通过这些系统发展社会互动的责任和机构。这一点，我认为非常非常重要。毫无疑问，我认为如果建立推荐系统的公司和开发者在设计时更多地考虑到这一点，这将是一个非常好的消息，这不仅是因为隐私原因或因为这是一个好的实践，而且因为它真的增强了推荐者的体验。

耶雷米(00:45:15):
是的，我真的很想知道，这种行为对长期利润的影响有多大？我们已经看到推特因为各种政治分歧的事情受到攻击，然后在脸书也是一样。似乎通过优化短期偏好，而不是以你在这里描述的方式思考，我们现在得到的是一个生态系统，至少开始以不同的方式来看待。我已经看到人们开始喜欢习惯吸烟的 Instagram 和社交媒体。我们有，不是社交网络，但不管那部电影是什么。总之，网飞的那个大的。

西尔维亚(00:45:56):
社会困境。

Jeremie (00:45:57):
社会困境，谢谢。是的，我们已经开始讨论这些事情了。我认为这将在很长一段时间内影响这些公司的底线，从某种程度上来说，这可能只是善心很多行动基本上他们已经为短期奖励进行了优化，他们认为这是一个很好的措施。他们认为这是需要优化的事情，但他们认识到，实际上，从长远来看，这与可持续性和可持续增长无关。我希望是这样，我的一个担忧是，也许你只是获得了太多的竞争优势，以至于抵消了那些长期影响。不知道大家对此有什么想法？也许这更多的是商业方面的问题，但是-

Silvia (00:46:40):
是的，这肯定更多地涉及到商业方面，我不是这方面的专家，我当然希望这对我们大家都有好处，我们应该摆脱短期展望，努力实现短期收益最大化。我认为即使在推荐系统内部也有相似之处，一些问题甚至被当前的平台所意识到。一个非常突出的事实是，它们可能会产生回音室或不同类型的反馈环路效应。事实上，在几种类型的推荐系统上的一些受欢迎的项目可能具有不成比例的曝光，这可能是受欢迎的东西的循环，它得到更多的推荐。这被广泛认为是一个大问题。

西尔维娅(00:47:52):
我认为导致这类事情的原因之一就是对短期目标的关注。因此，如果你是一个用户，你正在登录，那么对你来说，向你展示流行的东西是一个更安全的赌注，这可能与质量相关。因为你可能认为，实际上，你可以将这个问题形式化，并试图证明如果很多人喜欢这个项目，那么它更有可能具有良好的质量。

Silvia (00:48:32):
但是在推荐系统的情况下，这显然会产生病理效应。因为这种从许多人喜欢的事实中提取价值的群体智慧是有效的，如果每个人都可以访问关于有什么东西的所有信息，如果观察到你喜欢一个项目与它是否被推荐给你无关。但显然，事实并非如此。因此，相反，我们有这样的反馈效应，试图利用一个项目受欢迎的事实，但推断它一定是好质量的，实际上引导我们到这样的例子，即使是质量不好的项目，例如，因为它们是假新闻，或者不是真正相关的东西越来越多地得到推荐，因为它们在过去已经被更多的用户看到和互动。

Silvia (00:49:39):
我认为这也是一个我们必须决定是关注短期利益还是从更长远的角度来看待问题的例子。所以从短期来看，你最好的选择可能是购买热门商品。但是这降低了整个系统的质量。所以现在你选择的东西，你选择只是因为它受欢迎，你的选择并没有真正揭示系统本身和其他用户对你的兴趣，只是加强了一个信号，是的。

Silvia (00:50:17):
那么，我们如何采取更长远的方法来保存信息呢？所以这也可能意味着用户自己需要承担更多的责任。这可能是用户难以接受的事情，或者推荐系统提供商难以解释有时推荐是可能的，因此用户也有责任维护系统本身的质量。你与某件商品互动或可能喜欢某件商品的事实，正在向其他人发送一个信号，并影响着这件商品会被推荐给其他人的人和程度。所以你确实对他人负有某种责任。因此，在推荐和我们如何从用户行为中学习时，需要考虑到这一点。

杰雷米(00:51:23):
平台与平台之间有太多的差异，以 Twitter 为例，机器人似乎占了很大一部分，我和一些人交谈过，他们怀疑大约在 2016 年，他认为 Twitter 上的大部分活动可能是机器人活动，不知道这如何转化为 2020 年的术语。但我想情况只会变得更糟。在这种程度上，你有 Twitter，它有一大堆问题，脸书有另一个，然后你有 Instagram，你有 Snapchat，你有亚马逊。在某种程度上，我想，任何一种政策行动或政府对这些事情的监管的挑战之一是，你需要这样一种快速，深思熟虑的反应，而政府往往没有工具去做，他们只是没有那种技术或道德思想家可以快速反应。所以你认为这是一个基本上全靠公司和个人来扭转局面的领域吗？或者，在试图将系统产生的一些外部性内部化方面，政府可以发挥作用吗？

西尔维亚(00:52:29):
嗯，好问题。我确实认为机构行为者可以发挥作用，原因很简单，把责任推给用户可能不公平，因为用户掌握的信息很少。也几乎没有时间投资于弄清楚它们相互作用的系统的系统效应将如何对社会发挥作用。因此，可能的情况是，用户[can viewers 00:53:12]对如何进行推荐更负责任、更知情。推荐可以变得更加透明，并且这在给予用户对轨迹的更多控制方面可以具有积极的效果。但这并不意味着用户真的有责任监督系统的良好运行。例如，您可以发出信号，表明某个帐户可能是一个机器人，或者可能表现出可疑行为。

Silvia (00:53:47):
但实际上，作为一名用户，你并不适合经常这样做，因为你只能看到该帐户活动的非常有限的一部分。你对这种情况如何会产生负面影响的认识非常有限。另一方面，将所有这些责任交给平台自己解决，显然也有非常非常严重的问题。一是我们可能不希望平台成为什么是好的在线行为的仲裁者。我们可能不希望平台决定审查什么样的账户或什么样的言论。或者我们甚至不希望平台来决定如何构建市场，也许应该有限制。因此，不能指望平台或用户真的承担更多责任，但不能指望他们解决问题。所以，我真的认为机构行为者需要介入。他们可能采取的方式是设计监管，让外部参与者更容易观察到这些平台上正在发生的事情并进行干预。

耶雷米(00:55:11):
好的，这很有趣。我只是想问，如果是这样的话，因为你说的是机构行为者，而不是政府，我认为这很有趣。我知道你在人类未来研究所工作。所以这就像一个有趣的中间地带，它不是政府政策，但也不是私营部门的事情，它介于两者之间。你是否看到了人工智能或不同组织的合作伙伴关系，这些组织可能拥有干预的技术能力和政策智慧，而不一定有行动缓慢的政府的体制包袱？你认为这些是实现这一目标的工具吗？

Silvia (00:55:47):
是的，我认为公民社会应该在管理技术方面发挥更大的作用。现在，我不是一个政治理论家，我可以作为一个哲学家在这里发言。

耶雷米(00:56:06):
是的。

Silvia (00:56:07):
我确实认为公民社会需要更多的评价。有几个原因。因此，政府可以通过设计赋予公民社会更多监督权的监管来帮助实现这一目标。我尤其想到了社交媒体平台，在那里，推荐系统显然对塑造政治话语有着如此大的影响。我们越来越多地看到这种情况，市场也是如此。目前，一个大问题是驱动系统的算法是专有的，无法直接观察到。

耶雷米(00:56:53):
对。

西尔维娅(00:56:54):
正如我们所说，用户对正在发生的事情知之甚少，因为你只能看到整个系统的一小部分。不能指望平台承担全部责任，因为存在利益冲突，也因为它们可能没有合适的能力。但是对于民间社会的介入，我想说的是机构行为者，我想保持中立，不管他们是附属于政府还是更广泛的民间社会，需要能够审计这些系统并观察它们实际上是如何工作的。

Silvia (00:57:36):
通过这种方式，他们还可以让个人用户和其他利益相关者了解他们的在线体验。例如，如果我是一个公民社会组织或一个研究团队，想要研究信息(例如，关于疫苗接种项目的信息)是如何在网上传播的，我可能需要访问，例如，当用户登录他们的社交媒体帐户时，一个社交媒体源会将不同的信息发送给他们。有各种方法可以做到这一点。目前，这些限制非常非常严格。因此，举例来说，要求用户分享他们的数据，并要求用户让外部研究人员访问他们在网上看到的内容，目前是不允许的，部分原因是隐私监管。

西尔维娅(00:58:45):
但如果我们想要有一个整体的了解，并且能够看到提出建议的算法如何影响信息的传播，以及如果我们想要衡量这个算法的社会影响，这是非常重要的。目前，我们只能看到之后的效果，或者我们可以尝试重建它可能的贡献。但这需要以更加透明的方式进行，并以可审计的方式进行。在这一点上，政府的角色实际上是非常重要的，它允许抱歉，通过立法使之成为可能。

Jeremie (00:59:34):
我发现的一件有趣的事情是，无论你从哪个方向看待这些系统，你最终都不可避免地打开了一个蠕虫罐，有问题要问政府，有问题要问哲学家，有问题要问创业者。所以我真的很感谢你能过来分享你对这些事情的迷人观点。如果人们有兴趣跟随你的研究，跟随你的工作和你对此的思考，他们应该去哪里？

Silvia (01:00:01):
这样他们可以访问我的未来研究所网站或我自己的个人网站，了解我工作的最新进展，也可以了解牛津互联网研究所新兴技术治理项目的成果，在该项目中，我与其他研究人员合作，包括 Sandra Mathur 和 Brent Mittelstadt 等人，共同研究推荐系统等新技术的社会影响。

耶雷米(01:00:36):
真棒。非常感谢西尔维娅。我们将确保在博客文章中也包含这些链接，博客文章将在这里与播客一起发布。所以谢谢你的来访，非常感谢。非常有趣的对话。

Silvia (01:00:45):
感谢邀请我。