# NLP 指标变得简单:BLEU 分数

> 原文：<https://towardsdatascience.com/nlp-metrics-made-simple-the-bleu-score-b06b14fbdbc1?source=collection_archive---------5----------------------->

![](img/2bce76442079dfdf0257939f6825b58b.png)

19 世纪雕刻的[罗塞塔石碑](https://en.wikipedia.org/wiki/Rosetta_Stone)(公共领域)

自然语言处理已经成为一个超级热门的话题。NLP 最成功的应用之一是机器翻译(MT)——自动将文本从一种语言翻译成另一种语言的能力。也许最著名的机器翻译应用程序是非常有用的 Google Translate，它能够翻译 100 多种语言。

我们如何评估机器翻译系统的性能？一个显而易见的方法是使用*人工评估*:我们可以并排显示原始句子及其机器翻译，并要求人类评估翻译的准确性。人工评估通常需要精通源语言和目标语言的专家。这既费钱又费时。此外，每次调整模型时，您都需要重新运行评估。如果我们有一种自动的方法来评估机器翻译系统的性能，那不是很好吗？

这就是代表**B**I-**L**in gual**E**evaluation**U**under study 的 BLEU 发挥作用的地方。这是自动测量 MT 型号性能的一种流行且廉价的方法。简而言之，BLEU 将机器的翻译(即所谓的*候选翻译*)与现有的人工生成的翻译(即所谓的*参考翻译)进行比较。*

解释 BLEU 最简单的方法就是举例。为此，我们来看看希伯来圣经中的一句经典格言——וְאָהַבְתָּלְרֵעֲךָכָּמוֹךָ——它用三个词描述了被称为黄金法则的原则:你希望别人如何对待你，你就如何对待别人🤗。我们使用《圣经》,因为它已经被翻译了很多次，被翻译成多种语言，所以很容易找到参考译文。此外，大多数翻译都是公开的。《圣经》事实上是历史上被翻译最多的书(甚至比《哈利·波特》还多！).在我们的案例中，我们从众多的[英文译文](https://www.biblestudytools.com/leviticus/19-18-compare.html)中选择了以下三个参考译文作为我们的格言:

*   R1:但是你应该爱你的邻居如同爱你自己一样
*   R2:但是要像爱自己一样爱你的邻居
*   R3:但是**爱你的邻居就像你爱你自己一样**

这是我们想要计算 BLEU 分数的候选译文:

*   d:但是**爱**其他**爱**朋友对于**爱**自己

正如你所看到的，我们的机器翻译系统不是很好😔…

BLEU 的工作原理是计算精度——候选词中被引用出现或“覆盖”的部分——但有所扭曲。像任何基于精度的指标一样，BLEU 分数的值总是介于 0(最差)和 1(最好)之间。让我们为我们的候选翻译计算 BLEU。在我们的例子中，候选词由 8 个词组成:*但是为了爱你自己而爱其他的朋友*。如果这些词没有出现在任何引用中，那么精度应该是 0/8=0。幸运的是，他们中的大多数出现在参考文献中。很容易看出，8 个单词中的 6 个，*但为了爱自己而爱爱——*也就是说，除了*其他*和*朋友*之外的所有单词——至少出现在一个参考文献中。因此，人们倾向于将精度计算为 6/8 = 0.75。但是如果你仔细观察，你会发现 *love* 这个词在候选人身上出现了 3 次，然而在任何一个单一的引用中*最多出现了两次*(在 R3 出现了两次，在 R1 和 R2 出现了一次)。BLEU 考虑到了这一点——它惩罚那些在候选词中出现的次数比在任何参考文献中出现的次数都多的词。为什么？理由是:既然*爱*在任何参考译文中最多出现*两次*，那么它在候选译文中出现两次也是合理的。因此，多达 2 个*爱*字被覆盖。候选人对 *love* 的任何过度使用都没有意义，因此不被视为涵盖。而且因为第 3 个*爱*没有被覆盖，所以只有 5 个代币被覆盖——*但是爱爱自己*——我们得到的 BLEU 分数是 5/8=0.675。

想象一下，我们没有这种修正；像*爱爱爱爱爱爱爱爱爱*这样的 8 字候选翻译将得到完美的 BLEU 分数 1，因为*爱*出现在参考翻译中。对于 BLEU，我们将认为只有前 2 个*love’*s*被覆盖，并丢弃其他 6 个。在这种情况下，BLEU 分数仅为 2/8 = 0.25，确实表明精度非常低(尽管有很多爱！).*

*让我们更正式地看一下计算。对于候选中每个*唯一*单词 *w* ，我们统计它在候选中出现的次数。让我们称这个数字为 *D(w)* 。在我们的例子中:*

> *D(但是)=1
> D(爱情)=3
> D(其他)=1
> D(朋友)=1
> D(对于)=1
> D(自己)=1*

*对于每个唯一的单词 *w* ，我们还将 *R(w)* 定义为该单词在任何引用中出现的最大次数。我们通过查看 *w* 在每个引用中出现的次数，并取最大值来计算。在我们的例子中:*

> *R(但是)=1
> R(爱情)=2 *【在 R3 出现两次】*
> R(其他)=0
> R(朋友)=0
> R(对于)=2 *【在 R2 出现两次】*
> R(自己)=1*

*我们非常原始和基本的 BLEU 分数—我们称之为 BLEU* —可以计算为覆盖的*候选词与总的 候选词数量的比率:**

> ****BLEU * =承保/总计****

**先说分母 ***总和*** ，计算起来超级简单。是考生的字数。一种奇特的写法是:**

> **总计= D(W1)+D(W2)+…**

**在我们的情况下**

> **总计=D(但是)+D(爱情)+D(其他)+D(朋友)+D(对于)+D(自己)
> = 1+3+1+1+1
> = 8**

**现在对于分子 ***覆盖了*** ，也就是覆盖的总字数。对于每一个唯一的单词 *w* ，候选中的单词数是*D(w)*但是覆盖范围受限于 *R(w)* 。所以如果*D(w)*≤*R(w)*所有的 *D(w)* 单词都被覆盖了。否则只覆盖 *R(w)* 字。每个唯一单词的覆盖单词数 *w* 可以简单地写成 *MIN(R(w)，D(w))* 其中 MIN 是两个值中的最小值。**

**让我们看看这个例子是如何实现的:**

> **MIN(D(but)，R(but))=MIN(1，1)=1
> MIN(D(love)，R(love))=MIN(3，2)=2
> MIN(D(other)，R(other))=MIN(1，0)=0
> MIN(D(friend)，R(friend))=MIN(1，0)=0
> MIN(D(for)，R(for))=MIN(1，2)=1
> MIN(D(yourself)，R(yourself))= MIN(D(yourself)**

**总覆盖率是上述值的总和:**

> **覆盖=1+2+0+0+1+1=5**

**我们最终可以计算候选人的 BLEU*分数:**

> *****BLEU *(T62)=覆盖/总计
> =5/8
> =0.625*****

# **从 BLEU*到真正的 BLEU**

**我上面描述的天真的 BLEU*分数在实践中没有使用，因为它有许多问题，使它非常不准确和不实用。我只是简单地介绍了一下“真实”BLEU 分数背后的概念。**

**以下是天真的布鲁*的一些问题。**

**首先，非常短的翻译——也就是说，单词很少的候选人——可以做得荒谬地好，尽管他们可能是可怕的翻译。试想一下，候选人仅仅是一个字的 ***爱情*** 甚至是两个字的 ***但是对于*** 。这些候选项得到完美的 BLEU*分数 1，因为标记被引用很好地覆盖了。**

**此外，BLEU*指标完全不受词序影响。BLEU*评分为 ***但爱其他爱自己的朋友*** 与 ***完全相同。在语序很重要的语言中(英语和许多其他语言)，这实际上没有意义。*****

**最后，我们只计算了一个句子的 BLEU*分数。要衡量我们的机器翻译模型的性能，不依赖于单个实例是有意义的，而是要检查许多句子的性能，并结合分数以更全面和准确地评估模型。**

**为了纠正这些问题，真实的 BLEU 分数对我的天真的 BLEU*计算进行了一些修正。我会在后续的故事中解释如何计算真实的 BLEU 分数。**

**最后，我写了一些简单的 Python 代码来计算 BLEU*分数。请注意，这仅用于教育目的，不要将其用于工业或学术目的！该代码包括两个分数版本—它们在功能上是等效的，因此它们计算的分数是相同的。第一个(`BLUE_star`)较长，但希望更容易理解。较短的版本(`BLUE_star_compact`)使用(或者甚至滥用)Python 的列表理解，因此更加紧凑。**

**BLEU*的计算方式—仅用于教育目的**

**我希望你喜欢这个初学者的 BLEU 教程。**

**请在下面留下您的反馈。谢谢大家！**