# 理解准确性和可解释性的权衡

> 原文：<https://towardsdatascience.com/accuracy-interpretability-trade-off-8d055ed2e445?source=collection_archive---------16----------------------->

## 讨论机器学习中模型准确性和可解释性之间的权衡

![](img/65ae2b00e9eae9d002447412fb72abd2.png)

Abel Y Costa 在 [Unsplash](https://unsplash.com/s/photos/table?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄的照片

## 介绍

在我之前的一个角色中，我讨论了机器学习环境中参数化和非参数化方法之间的[差异。](/parametric-vs-non-parametric-methods-2cea475da1a)

参数方法对数据和要估计的函数之间的关系做出假设，因此它们通常是不灵活的。例如，我们可以**假设**函数 *f* 是线性的，并使用简单的线性回归，这在只能估计 *f* 的线性形状的意义上可以认为是不灵活的。

另一方面，非参数方法更加灵活，因为它们能够“考虑”函数 *f* 更多可能的形状。

## 模型可解释性

当我们估计一个未知函数 *f* 时，我们最感兴趣的是执行[推理或预测](/inference-vs-prediction-b719da908000)(有时两者都有)。

当在推理设置中工作时，我们通常将模型视为白盒，因为我们试图理解输入 X 和输出变量 y 之间的关系。**不太灵活的方法往往更容易解释，因此更适合进行推理**。

另一方面，**更灵活的方法**(如支持向量机或 Boosting)能够为未知函数 *f* 估计更复杂的形状，但更难解释**。这意味着这种方法可能不太适合推理设置。函数的形状越复杂，就越难理解预测变量(X)和目标变量 y 之间的关系**

## 模型精度

现在，如果我们对执行预测感兴趣，我们需要训练一个能够尽可能准确地预测目标变量的模型。在预测设置中，我们可以将模型视为黑盒，在某种意义上，我们并不真正关心估计的 *f* 的形状，只要它能够导致准确的预测。

在预测设置中，我们并不真正关心模型的可解释性，我们最感兴趣的是模型的性能。因此，更灵活(但更难解释)的方法是**通常是**(这是这里的关键词——在下一节中会有更多的介绍！)更适合这类用例。

## 过度拟合

同样需要强调的是**更灵活的模型并不能保证比相对不复杂的模型更好的结果**。在某些情况下，与更灵活的模型相比，不太灵活的模型可能会产生模型性能。

这是因为更灵活的模型容易出现一种叫做**过度拟合**的现象。当模型过于紧密地跟随训练数据的噪声和误差时，它是过度拟合的，因此它不能很好地推广到新的、看不见的数据点。

## 最后的想法

在今天的文章中，我们讨论了机器学习环境中模型准确性和模型可解释性之间的权衡。

不太灵活的模型更容易解释，因此更适合我们最感兴趣的理解输入和输出之间关系的推理环境。另一方面，更灵活的模型更难解释，但结果可能更准确。

根据我们正在处理的问题，我们可能必须选择最适合我们用例的模型。然而，我们应该记住，在大多数情况下，我们必须在模型准确性和模型可解释性之间找到最佳平衡点。

[**成为会员**](https://gmyrianthous.medium.com/membership) **阅读介质上的每一个故事。你的会员费直接支持我和你看的其他作家。**

**你可能也会喜欢**

</inference-vs-prediction-b719da908000>  </parametric-vs-non-parametric-methods-2cea475da1a>  </supervised-vs-unsupervised-learning-bf2eab13f288> 