# 对深度学习的攻击

> 原文：<https://towardsdatascience.com/an-attack-on-deep-learning-b437bdf3c860?source=collection_archive---------29----------------------->

## [意见](https://towardsdatascience.com/tagged/opinion)

## 是的，但是听我说完！

![](img/e2a3396fd75a702d48ef9d02f6f7e5ec.png)

信用:Pixabay

随着数据科学和机器学习的不可分割的元素，深度学习已经变得无处不在。它塑造了人类与机器的互动方式，也许比迄今为止数学建模的任何其他进步都更重要。随着自动驾驶汽车、计算机在各自的桌面游戏中战胜大师，以及全球任何智能手机都可以进行语言翻译，人们很自然会想知道——*深度学习做不到什么？*

深度学习颠覆了我们的世界；但在这一过程中，它推断并放大了隐藏在训练此类模型所需的真正大规模数据集中的社会偏见。相应地，对算法偏见的批评导致[被高度公开的员工解雇](https://www.wired.com/story/behind-paper-led-google-researchers-firing/) (s)。提出上述批评的主要呼吁是:

> 模型、数据和其中的潜在偏见无法解开，并且这些信息不应该以深度学习产品采用的名义被忽视。*【自己的总结。]*

对基准问答数据集上的模型性能持批评态度的研究人员[指出，如果对问答结构进行小的更改](https://arxiv.org/pdf/1907.07355.pdf)，则*的性能会下降 20%以上*；换句话说，*单词之间的虚假关联*使得模型的表现令人难以置信，*而不是对语言的真正理解*。这一事实构成了深度学习研究的一个核心问题:深度学习的进步和成就是由基准数据集的性能来衡量的——继续基准驱动的研究有双重财务激励&开发: **(A)** 为(监督的)深度学习模型的训练创建数据集*非常*昂贵，而 **(B)** 基准数据集的性能是人工智能价值主张的核心——它表达了进步，这意味着货币价值，这意味着对<插入大型科技公司的影响(我稍后会再回到为什么大型科技公司被激励传播广泛的深度学习热情的另一个原因。)

深度学习是有效的黑盒模式匹配。这些模型很容易在小数据集上过度拟合，但是当样本大小接近人群大小时，泛化能力很好。深度学习模型不会思考(尽管名称如此)，它们只是简单地将输入映射到输出:照片中的人脸、句子中的主题等。模型架构每隔几年就会改变，并且没有得到严格的数学证明来验证为什么这样的设计是最佳配置；更确切地说，它们的更新是为了对用户选择的一些性能指标进行有意义的微调。我们通常称这样的方法为 [*启发式方法*](https://en.wikipedia.org/wiki/Heuristic) ，意思是:

> 任何解决问题的方法……采用一种实用的方法，这种方法不能保证是最佳的、完美的或合理的，但足以达到一个直接的、短期的目标或近似值。

当解释(甚至近似)一个系统的全部复杂性是不可行的时候，启发式方法是一个明智的选择，特别是当我们对系统的行为没有任何假设的时候。作为一种启发式方法，深度学习在非结构化数据任务上表现得非常好，如面部识别，因为我们根本没有办法清晰地说出每一种可以想象的像素配置模式，而*可以*定义一张脸是什么或者不是什么。在这样的背景下，非常需要一个高度灵活的黑盒模式匹配机。

然而，在无数的问题中，我们*确实*有办法提出关于系统如何工作的假设，我们不仅需要准确的结果，还需要*对我们预测的信心*和*增强对系统如何工作的理解。*例如，谷歌研究人员在 2017 年开发的分层/多级贝叶斯模型[，可以用来了解营销渠道支出对销售的影响，包括——投资达到峰值效果的延迟，进一步投资导致回报递减的饱和点，以及每个渠道投资对销售的强度。相比之下，深度学习模型只能进行预测；我们不能带着它的 500 万个参数，带着对系统实际行为的更多理解离开。](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45999.pdf)

贝叶斯方法的优点和缺点是它们把用户放在了驾驶座上。你必须通过描述它们的参数和概率分布来提供关于你的系统如何工作的信念。换句话说，你要让模型符合数据。相比之下，黑盒方法允许用户将数据压缩成适合充分研究的任务的形状，如分类、回归或聚类。确实一个知识渊博的神经网络库用户(PyTorch，TensorFlow/Keras 等。)将能够塑造一个特定于手头任务的深度学习架构；然而，这种架构的有效性完全由性能来判断，并且其中的调整是通过拧动机器的螺母和螺栓直到达到任意的满意阈值来完成的；换句话说，这些调整并不是由您试图建模的系统的知识决定的。

这让我们看到了基于云的机器学习的真正价值主张:谷歌和亚马逊都有各自现成的基于云的深度学习驱动的机器学习产品。[亚马逊网络服务的 SageMaker 允许插件&播放机器算法](https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html)，例如对象检测，而无需对用户强加任何数学知识要求。您采用所述产品的理由在于它们在*基准测试任务中真正非凡的准确性。*然而*，*如果你需要提高你的人类对你的系统如何工作的理解，这些工具对你帮助不大。因此，科技巨头受到激励来传播这样一种信念，即深度学习对于任何可以想象的任务都是完美的，因为它有助于产品的采用。(我保证过我会回到这个话题。)

我在与业务领域专家合作时遇到的一个问题是，当意识到深度学习仅在基准测试任务中非常好，而在其他任务中非常好时，当可用的数据非常大时，他们的期望就会降低。例如，最新的命名实体识别(NER)模型可以检测文本中的人、地点、组织、日期、货币(通常还有更多)。然而，这并不一定保证从简历中提取技能是一项微不足道的任务——你仍然需要大量的训练数据，而获取这些数据的成本很高。这个问题是如此的根深蒂固，以至于亚马逊土耳其机械公司(Amazon Mechanical Turk)为你众包了数据标记(训练数据集准备过程)——在负担得起的情况下，这依赖于人力。

对于深度学习的新任务问题，一个常见的*缓解*是使用迁移学习。在自然语言处理的上下文中，这采取单词嵌入的形式。把迁移学习想象成一张餐馆的优惠券——“订购一份任意大小的比萨饼，就可以得到免费的鸡翅。”鸡翅是一道开胃菜，让你吃得饱饱的，这样你就可以只点一个小号或中号的披萨，而不是大号(或特大号)的。)你还是要为一个披萨买单——只是没那么贵了。数据摄取过程就像比萨饼；当然你需要少一些，但你肯定还是需要一些。因此，由于你的迁移学习(在这个比喻中是水牛翅膀),你可能会得到几十万行，而不是几百万个观察结果。)用一个下午的时间在一百份简历上，甚至用一周的时间在几千份简历上标注技能，然后指望迁移学习来完成剩下的工作，这是不现实的。

我忽略的一个例外是强化学习——无人驾驶汽车和桌上游戏掌握背后的动力。这种形式的机器学习(在这两个例子中是深度学习)不需要训练数据集。然而，*它确实需要一个环境，可以奖励/惩罚一个代理人采取的行动*。然而，一个被设计成游戏的商业系统，适合强化学习，被正式称为[马尔可夫决策过程](https://en.wikipedia.org/wiki/Markov_decision_process)。而这个*确实*需要用户的一些数学知识(它就像贝叶斯方法一样复杂)，并且不太可能在短期内成为基于云的机器学习提供商的现成产品。

我忽略的第二个例外是贝叶斯神经网络。这种设计允许结合先前的信念，这在深度学习上下文中，调整给定参数可以呈现的值。相应地，该方法不太可能在小数据量上过度拟合(一个重大的改进)，并且最重要的是，将返回超过其预测的分布——不仅返回它所相信的，还返回它对其的信心。但这是福也是祸——网络越大，典型的贝叶斯训练方法——MCMC 采样所需的训练时间就越长。这个问题如此棘手，以至于一种新的学习算法正在积极研究中:变分推理。该方法试图初始化一组样本，并迭代地缩小该合成分布和目标分布之间的熵。贝叶斯统计社区中的各种工具都有可用的实现，比如 PyMC3。然而，它的研究时间还没有 MCMC 采样长——所以我们不确定它容易陷入什么陷阱，如何减轻这些风险，等等。考虑到这些限制，代表用户进行大量的贝叶斯神经网络研究工作才能在实践中有所收获。因此，在不久的将来，它们不太可能出现在开箱即用的云 ML 产品中。

说到贝叶斯方法，任何时候你需要了解你的系统实际上是如何运行的，你的首选应该是贝叶斯统计。如今，像 PyMC3 这样的高级 API 抽象掉了许多低级细节，同时允许您保留对参数实际建模的控制。我强烈推荐这本书，Richard McElreath 的《统计学再思考》第二版，[相应的 YouTube 讲座系列](https://www.youtube.com/playlist?list=PLDcUM9US4XdNM4Edgs7weiyIguLSToZRI)，以及[这本书的代码，移植到 GitHub 上的 PyMC3。](https://github.com/pymc-devs/resources/tree/master/Rethinking_2)

总的来说，我不是要哀叹云 ML 解决方案，而是要质疑(A)基准 DL 任务的广泛适用性的假设和(B)在一个新的任务上摄取足够的 DL 性能数据的容易程度。Cloud ML 产品，比如 AWS，使您能够上传 docker 映像，完成任务的特定库需求，大大扩展了您的建模选择，超越了基准(DL)任务。

总之，由于使用了巨大的基准数据集，深度学习在充分研究的任务中是不可思议的；然而，算法偏见的批评者主张不同的研究团队审查数据摄取过程，这增加了本已昂贵的过程的成本。对于研究较少的任务的性能期望需要与非常真实的期望进行校准，即数据摄取非常昂贵和缓慢，可能如此之多，以至于我们不应该排除不会使人类与模型疏远的方法。换句话说，你没有被卖给一个谎言，但你被卖给了一个巧妙的营销活动，歌颂深度学习作为解决你所有数据需求的解决方案的优势，但掩盖其弱点。

我将留给你们柏拉图的[告诫不要写作](https://fs.blog/2013/02/an-old-argument-against-writing/#:~:text=%E2%80%9CTell%20me%20and%20I'll,and%20I'll%20understand.%E2%80%9D&text=From%20Plato's%20Phaedrus%2C%20commenting%20on%20the%20invention%20of%20writing.):

> 他们将停止行使记忆，因为他们依赖于写下的东西，不再从他们自己内部，而是通过外部的标志来唤起记忆。

简而言之——*我们不是为了记忆而写作；我们写信是为了忘记*。书面语言的发明产生了一个无意的后果——通过扩展我们获取信息的途径，我们无意中摆脱了记忆信息的义务。当然，书面语言无疑改善了社会；尽管如此，书面语言对希腊口头传统有着深远的影响。这个例子说明，我们对信息编码方式的改变有隐藏的后果，影响我们访问和操纵这些信息的能力。

当然，自动驾驶汽车和语言翻译模型证明了深度学习所接受的广泛研究是正确的。但是随着*的广泛采用，即任何问题都可以通过深度学习*来解决，我们无意中限制了理解我们希望建模的系统和其中强大技术的价值。