# 培训 vs 测试 vs 验证集

> 原文：<https://towardsdatascience.com/training-vs-testing-vs-validation-sets-a44bed52a0e1?source=collection_archive---------0----------------------->

## 在机器学习的背景下讨论训练、测试和验证数据之间的差异

![](img/0057149013b93d2f1318974677071d02.png)

约翰尼斯·格罗尔在 [Unsplash](https://unsplash.com/s/photos/data?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上的照片

## 介绍

在机器学习项目中，我们通常需要考虑多个模型，然后选择最终用于对现实世界数据进行预测的最终模型。

在这个过程中，我们通常在原始数据集的子集上训练模型，原始数据集是模型用来从数据中学习的数据集。因此，我们需要以某种方式评估哪个候选模型基于特定的度量表现得更好，这些度量是基于项目的性质和我们要解决的问题在开始时确定的。最后，一旦选择了最终模型，我们还需要评估它是否能很好地推广到新的、看不见的数据。

为了能够训练模型、执行模型选择并最终评估最终模型以检查它是否能够很好地泛化，我们通常将原始数据集分成训练集、测试集和验证集。在下面几节中，我们将讨论它们在监督学习环境中的用途。

## 训练集

就规模而言，训练集通常是从原始数据集创建的最大的集，用于确定模型。换句话说，训练集中包含的数据点用于学习感兴趣的模型的参数。

在监督学习的背景下，所有的训练示例应该包括预测变量(即特征)以及相应的输出变量(即标签)。在训练阶段，您可以使用正确的标签来获得训练精度，然后与测试精度(见下文)进行比较，以评估模型是否过度拟合。

## 验证集

现在，在进行超参数调整和模型选择时，验证数据集非常有用。该组中包含的验证示例将用于找到所考虑模型的超参数的最佳值。

使用机器学习模型时，您通常需要使用不同的超参数值测试多个模型，以便找到能够提供最佳性能的最佳值。因此，为了客观地选择“最佳”模型，您需要对每个模型进行评估。

例如，在深度学习中，我们使用验证集来找到最佳的网络层大小、隐藏单元的数量和正则化项。

## 测试设备

现在，您已经通过执行超参数优化调整了模型，您应该最终得到最终模型。测试集用于评估该模型的性能，并确保它可以很好地推广到新的、看不见的数据点。

此时，您还应该将测试精度与训练精度进行比较，以确保模型不会过度拟合。这是两个精度“足够接近”的情况。当训练精度明显超过测试精度时，就很有可能发生过度拟合。

## 为什么我们需要验证集和测试集？

如果没有多个模型可供选择，那么验证集可能是多余的。在这种情况下，您只需要一个训练集和一个分割比为 75:25 的测试集。

但是，如果您需要执行模型选择，但忽略了验证集，最终模型的测试误差将小于实际(或真实)误差。因此，对最终模型的评估将会误导您的模型归纳为新数据点的能力。

当涉及超参数优化时，评估模型的另一种方法是使用 **K 倍交叉验证**。

同样重要的是要提到，一旦您在测试集上评估了模型，您就不应该对最终模型执行任何进一步的调整。如果这是你需要做的事情，那么你也必须再次重复前面的步骤。

## 最后的想法

在今天的文章中，我们讨论了在监督学习的背景下开发和评估机器学习模型时，使用数据集的独立子集的重要性。

总之，训练集通常是从用于模型拟合的原始数据集创建的最大子集。然后，验证集用于评估模型，以便执行模型选择。另一方面，测试集用于评估最终模型(在上一步中选择的)是否能够很好地概括新的、看不见的数据。理想情况下，训练集、验证集和测试集应该包含互斥的数据点。请注意，训练集、验证集和测试集之间的典型**分割比**约为 50:25:25。

如果您对如何在 Python 中将数据集分割成训练和测试子集感兴趣，请务必阅读下面的文章。

[](/how-to-split-a-dataset-into-training-and-testing-sets-b146b1649830) [## 如何用 Python 将数据集分割成训练集和测试集

### 探索从建模数据集创建训练和测试样本的三种方法

towardsdatascience.com](/how-to-split-a-dataset-into-training-and-testing-sets-b146b1649830) 

您可能感兴趣的其他文章:

[](/feature-scaling-and-normalisation-in-a-nutshell-5319af86f89b) [## 简而言之，特征缩放和标准化

### 为什么、如何以及何时调整要素的比例

towardsdatascience.com](/feature-scaling-and-normalisation-in-a-nutshell-5319af86f89b) [](/supervised-vs-unsupervised-learning-bf2eab13f288) [## 监督与非监督学习

### 讨论机器学习中监督学习、非监督学习和半监督学习的主要区别

towardsdatascience.com](/supervised-vs-unsupervised-learning-bf2eab13f288)