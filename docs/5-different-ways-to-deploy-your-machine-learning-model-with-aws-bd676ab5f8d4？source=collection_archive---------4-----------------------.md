# 使用 AWS 部署机器学习模型的 5 种不同方式

> 原文：<https://towardsdatascience.com/5-different-ways-to-deploy-your-machine-learning-model-with-aws-bd676ab5f8d4?source=collection_archive---------4----------------------->

## 让你的模型走向世界的不同方法的利弊。

作为一名数据科学导师，我收到了很多关于机器学习基础设施方面的问题。许多新来者构建他们想要通过 API 向互联网公开的模型，但是即使有大量的可用资源，他们仍然很难做到这一点。其中一个主要原因是，通常不清楚实现目标的“最佳”方式是什么。

![](img/ccc10d3bd3a09ca62ad7be36cdd7f6c3.png)

莱蒂齐亚·博尔多尼在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

正如软件工程中的所有事情一样，有许多不同的方法来完成同样的事情。然而，不同的方法有不同的利弊。服务管理得越好，它提供的现成产品就越多，但有时会以更高的价格或更低的灵活性为代价。较少管理的服务有时更便宜或提供更大的灵活性，但可能需要更多的时间和专业知识来配置。

在这篇文章中，我将重点介绍 5 种常见的方法，您可以使用这些方法将一个简单的实时机器学习 API(如 Flask app)部署到互联网上。虽然这个列表并不详尽，但它应该为您选择适合您的解决方案指明了正确的方向。

# 将其部署在 EC2 实例上

在我看来，将您的模型部署到互联网的最简单(但最不健壮)的方法之一是在 EC2 实例上运行它。这就像在云中获得一个虚拟机，让它可以访问互联网，并在其上启动您的应用程序一样简单。关于这个解决方案的演练，[请看我之前的一篇文章](/the-fastest-way-to-deploy-your-ml-app-on-aws-with-zero-best-practices-df15c09eead7)。

我向需要快速演示或只是临时展示一些东西的用户推荐这个解决方案。如果你的应用足够小，你几乎不需要花费任何东西来托管它，你只需要 5 分钟就可以完成。你甚至不需要熟悉 Docker 这样的工具，只需要 linux 命令行。对于这样的用例，这将是最便宜和最简单的选择。

然而，这种方法需要大量繁琐的手动设置，不适合实际的生产部署。如果你是一个想向朋友炫耀你的应用程序的人，这个解决方案很棒。如果你在寻找可持续发展的长期目标，请继续阅读。

赞成的意见

*   暂且应急的
*   便宜(可能免费)
*   易于安装/拆卸
*   几乎不需要基础设施/网络经验

骗局

*   不太容易扩展
*   非生产级
*   几乎没有自动化
*   对错误不稳健

# 创建 AWS Lambda 函数

AWS Lambda 是用于部署无服务器功能的服务。“无服务器”并不意味着没有服务器，它只是意味着你不关心你的代码的底层基础设施，你只为你使用的东西付费。这通常比供应和管理您自己的机器更可取，这是您在上一步中需要做的事情。

虽然 Lambda 可能无法满足一些更复杂的用例，但对于简单且可重复的代码来说，它是理想的。它是可扩展的，非常便宜和简单。您将需要使用一些其他服务，如 API Gateway，但设置将比将您的应用程序部署到独立的 EC2 机器上更加健壮。对于生产，这可能是最便宜的选择。

然而，它们没有你在 ECS 或 EKS 中看到的纯容器化解决方案灵活。支持的编程语言等功能是有限的。我向使用简单 ML 代码的用户推荐这个解决方案，他们根本不想考虑基础设施*。*

优点:

*   生产等级
*   非常适合简单的小型应用/功能
*   无服务器(非常便宜)

缺点:

*   不如其他解决方案灵活
*   需要其他 AWS 服务的知识

# 将其集装箱化并部署在 EKS 的 Kubernetes

Kubernetes 是当今管理和扩展容器化应用程序的首选之一。Kubernetes 的声明性质有助于自动化许多生产级别的问题，如负载平衡或自动伸缩。与 ECS 等更受管理的容器编排解决方案不同，Kubernetes 提供了对机器学习应用程序的粒度控制。

简单、无状态的机器学习应用程序通常非常适合 Kubernetes。此外，Kubernetes 上有许多成熟的 ML 开源解决方案(如 [Seldon](https://www.seldon.io/) )，它们提供了特定领域的支持，并进一步抽象了基础设施的复杂性。

然而，这是有代价的。与申请部署应用程序的单个实例不同，现在您必须管理整个 Kubernetes 集群。对于新用户来说，部署应用程序*和管理集群*并不是一件简单的任务。

Kubernetes 网络是复杂的，需要大量的经验来深入理解和操作。虽然 Kubernetes 集群可能看起来比管理更好的 ML 解决方案更便宜，但管理不善的集群可能会导致更糟糕的意外货币成本。我向那些绝对需要产品级解决方案、想要细粒度应用程序控制或者只想体验 Kubernetes 的用户推荐这种方法。

优点:

*   非常可扩展
*   良好的自动化程度
*   生产等级
*   大量的社区支持
*   高度灵活
*   体验流行的框架和底层 CS！

缺点:

*   潜在的大量工作
*   对初学者来说有风险
*   在某些情况下，不必要直截了当
*   与托管服务功能对等需要大量设置

# 通过弹性容器服务(ECS)对其进行容器化和部署

像 Kuberenetes 一样，ECS 是一个用于部署应用程序的容器编排服务。区别在于责任的分配。在 Kubernetes 中，用户不必负责一些底层基础设施问题，而是让 AWS 为您完成。ECS 类似于 Lambda，因为它抽象出了基础设施问题。就灵活性而言，它介于 Lambda 和高度灵活的 Kubernetes 之间。

我向没有 Kubernetes 经验但想部署容器化应用程序的个人推荐这个解决方案。如果你独自工作，管理 Kubernetes 上的应用以及管理集群的所有问题可能会很困难。放弃这些责任会更好地利用你的时间，这样你就可以更专注于应用程序本身。如果你不使用 Docker，我会遵从 Lambda。

优点:

*   比 Kubernetes 简单得多的设置
*   开箱即用的更多功能
*   作为个人开发人员更容易管理(有容器经验)
*   对容器化应用的一流支持

缺点:

*   粒度更小的控制
*   潜在成本更高

# 创建 Sagemaker 端点

AWS Sagemaker 是一流的云 ML 工具套件。从托管到 jupyter 笔记本到简单模型端点，Sagemaker 的体验可能会像在您的机器上本地创建部署一样。机器学习特定支持附带了一整套服务，使用户能够构建和部署生产就绪的 ML 应用程序，这些应用程序具有您必须为其他选项手动配置的所有功能。

当然，这种解决方案的高度专用性和可管理性可能会使纸面上的成本更加昂贵。它还减少了用户对底层基础设施的关注。然而，你可能花费的美元很可能会及时收回，因为 Sagemaker 不仅使部署模型变得容易，而且创建了生产级 ML 管道。

我向新的云用户推荐这个解决方案，他们只想学习一种新技术来部署他们的模型，并希望从一开始就满足所有其他 ML 基础设施的考虑。除非你有其他上述技术的经验，否则在 Sagemaker 中进行调查将有可能使你在很少或没有云经验的情况下快速开发。

优点:

*   一流的机器学习支持
*   托管基础架构和环境
*   生产级，可扩展

缺点:

*   可能比其他一些解决方案更昂贵
*   潜在的灵活性较低

# 还有更多…

我敢肯定完整的列表是非常详尽的，当你考虑到其他用例，如批量预测，会变得更加复杂。然而，这些方法和其他云平台上的类似方法是相当常见的方法。根据您的使用情形、应用程序和其他现有基础架构，其中任何一种都可能是最“正确”的。

此外，虽然我在云计算方面做了很多工作，但我承认我并不是每一项服务的专家。如果我错过了什么或者做了你认为应该纠正的假设，请在下面评论，我会解决的！这些权衡是高度主观的，并且机器学习部署在复杂性和实现方面因用例而异。

如果你感到失望，请在 LinkedIn 和 T2 Twitter 上关注我。