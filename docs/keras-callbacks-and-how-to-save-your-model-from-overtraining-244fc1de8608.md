# Keras 回调和如何从过度训练中拯救你的模型

> 原文：<https://towardsdatascience.com/keras-callbacks-and-how-to-save-your-model-from-overtraining-244fc1de8608?source=collection_archive---------6----------------------->

## 回调允许您在训练期间调整设置或保存模型。

![](img/bfb1eae35040428ed356c4894c8d3179.png)

由[卡斯滕·怀恩吉尔](https://unsplash.com/@karsten116?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

在本文中，您将学习如何在 Keras 中使用 ModelCheckpoint 回调来保存训练期间模型的最佳版本。

# 做模特很好玩！

我喜欢建立预测性的深度学习模型。我喜欢观察训练输出，看到损失下降，观察训练集和验证集之间的偏离损失，这表明过度拟合。但是有时一个模型找到了一个很好的解决方案……并保持对一个只适用于训练集的解决方案的训练。现在，如果我在那里，像盯着一个鱼缸一样盯着，我可以在造成太多伤害之前中断训练。但是，谁愿意整天坐在那里盯着模特们训练呢？我的意思是，我做，但我的时间最好花在长时间的训练中做其他工作。

然后我了解了 Keras 回调，特别是 ModelCheckpoint！

# 过度训练

顶尖运动员总是处于过度训练的边缘。正确的训练会优化运动员的表现，但是过度训练会导致受伤和表现下降。深度学习模型也是类似的。适量的训练可以建立一个强大的模型，但是过多的训练会降低新数据的性能。

在训练期间，深度学习模型寻求最小化它们的损失，根据给定的损失函数更精确。然而，他们根据他们正在训练的数据集来判断准确性。想象一下，一个小学生把模拟试题带回家，并记住试题上的每个问题和每个答案。如果他们没有发现潜在的模式，即测试旨在评估的策略，他们将会不知所措，因为模拟测试中的问题都不在考试中！

深度学习模型可以做同样的事情。如果他们在数据集上训练过多，他们可以专门学习该数据集，而不是选择连接要素和标注的底层函数。该模型可能会过度拟合数据。

在预测建模中有许多策略来对抗过度拟合，并且应该在必要时部署这些策略，但是来自过度训练的过度拟合是一种独特的危险。

幸运的是，Keras 以回调的形式为我们提供了一些帮助！在我知道回调之前，我认为我必须猜测训练时期的正确数量，或者使用试错法来调整它们。幸运的是，我们没有！我们可以使用 Keras 回调`keras.callbacks.ModelCheckpoint()`在模型的最佳执行时期保存模型。

# 复试

回调是可以在每个时期后运行的函数。它将纪元编号和模型跟踪的任何指标作为参数。它们可以用来做一些有用的事情，比如安排学习率的降低(我喜欢一个调整良好的衰减学习率，你呢？)，提前停止训练，或者在历元之间保存模型。您甚至可以为自己的特殊目的编写自己的回调函数。

如果您想了解更多关于所有可用回调的信息，请查看这里的 [Keras 文档。](https://keras.io/api/callbacks/)

# 模型检查点

我最喜欢的一个回调是 ModelCheckpoint。我喜欢多任务，经常打开几个 Google Colab 窗口，设置一些深度模型在其中进行训练，然后在本地机器上处理其他任务(我没有像 Google 那样的 GPU 硬件来进行高效的 Tensorflow 模型训练)。我可以将我的模型设置为训练比我认为他们可能需要的时间长一点，然后回来从他们开始过度拟合和在验证集上失去准确性之前的点加载他们。

模型检查点回调可以从 keras.callbacks 加载

```
from keras.callbacks import ModelCheckpoint
```

我们用要保存的文件路径、保存它的条件以及这个过程应该有多透明来初始化类对象。例如，假设我们只想要模型的最佳版本，我们将“最佳”定义为验证损失最低的版本。您可以选择损失函数或编译模型时传递给`metrics`参数的任何指标作为触发器。

我们应该像这样初始化回调函数:

```
checkpoint = ModelCheckpoint(filepath=filepath, 
                             monitor=’val_loss’,
                             verbose=1, 
                             save_best_only=True,
                             mode=’min’)
```

保存多次的一个很酷的技巧是将纪元编号和/或您正在监视的当前度量附加到 filepath，因为纪元将被传递给 ModelCheckpoint 对象。

```
filepath = 'my_best_model.epoch{epoch:02d}-loss{val_loss:.2f}.hdf5'
```

以上内容会将您的模型保存到磁盘，如下所示:

my _ best _ model . epoch _ 01-loss _ 13.31 . HD F5

# 回到回调

Keras 模型将回调列表作为`.fit()`调用中的参数。该参数需要一个列表，即使您只传递一个回调。然而，你可以用各种花哨的回调来装饰你的模型。我最喜欢的组合是 ModelCheckpoint 和 ReduceLROnPlateau。第二种方法监控一个度量标准，当该度量标准达到稳定状态时，将学习速率降低一个给定量。

我们将回调列表传递给`.fit()`方法，如下所示:

```
callbacks = [checkpoint, <other_callbacks_you_want>]
model.fit(X_train,
          y_train,
          epochs=epochs
          callbacks=callbacks)
```

## 保存模型

关于保存模型的注意事项:以. hdf5 格式保存的模型非常好，因为整个模型在一个地方，可以在其他地方加载，比如在部署中。然而，文件会变得很大，并且在每个时期保存模型会很快占用大量存储空间。ModelCheckpoint 回调构造函数中的一个可用选项是`save_weights_only=True`。这将节省空间，但不会保存整个模型架构。为了恢复它，您将重建模型，然后指定保存的权重，而不是只在一个步骤中加载它。

我发现的另一个怪癖是，并不是每个图层都喜欢保存为. hdf5 格式。在以前的博客文章中，我向您展示了如何向 NLP 模型添加文本矢量化层，以作为模型本身的一部分进行预处理。然而，我发现如果我使用那个层，我不能以. hdf5 格式保存我的模型。然而，如果我去掉. hdf5 扩展名，那么 keras 会将模型保存为资产的文件目录，这适用于 TextVectorization 层。

拟合后，我们可以重新加载我们的模型，以便在其最佳执行时期进行评估:

`model = keras.models.load_model(filepath)`

让我们来看看这一切的行动吧！

作者要点

数据由卡内基梅隆大学通过 Statlib 图书馆提供。作者嵌入要点

我希望 Keras 提供的 ModelCheckpoint 和其他回调函数以及您自己设计的回调函数能够帮助您做出最好的预测模型！

# 摘要

在本文中，您了解了如何使用 Tensorflow 的 Keras api 进行深度模型的回调。具体来说，您学习了如何使用 ModelCheckpoint 回调在模型过度训练之前保存模型的最佳版本，以及一些定制回调的方法。

像往常一样，善用你的数据科学能力，尽情享受乐趣吧！请在评论中留下任何问题，评论，或者善意礼貌的反馈。

快乐造型！