# 处理具有高基数的要素

> 原文：<https://towardsdatascience.com/dealing-with-features-that-have-high-cardinality-1c9212d7ff1b?source=collection_archive---------2----------------------->

## [提示和技巧](https://towardsdatascience.com/tagged/tips-and-tricks)

## 一个简单的实用程序，我用来处理具有许多唯一值的分类特征

![](img/01c3b94c1123caa4fb9c14b5541cfce8.png)

照片由[乔治·帕甘三世](https://unsplash.com/@gpthree?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄

# 什么是高基数？

几乎所有的数据集现在都有分类变量。每个分类变量由唯一的值组成。当有太多这样的唯一值时，分类特征被认为具有高基数。在这种情况下，一键编码成为一个大问题，因为我们在分类变量中为每个唯一值(指示其存在或不存在)设置了一个单独的列。这就导致了两个问题，一个是明显的空间消耗，但是这个问题没有第二个问题**维数灾难那么大。**我将更详细地讨论维数灾难，但首先，让我们来看看一键编码前后的数据。

# 一键编码前后我们的分类特征

我们将关注资格特征。因为这些数据是从许多人填写的表格中收集的，所以该列包含许多不同的资格。下面是该列的外观以及它所具有的所有唯一值。

**我们可以看到该特性中有 15 个唯一值，它占用了 316KB 的空间。**让我们用 pandas one _ hot 编码这个特性。

我们现在可以看到我们的原始特性已经变得有多大，存储它所需的空间自然也增加到了 **592KB。**这只是一个特征，如果在训练过程中我们拥有数百个分类变量，我们将最终拥有数百个特征，这在某些情况下不利于模型训练。简单的模型无法处理如此多的变量。但是现在让我们看看另一个主要问题，维数灾难。

# 维度的诅咒

下面是一个简单的总结:

> 随着特征数量的增长，我们需要准确区分这些特征(以便给我们一个预测)并概括我们的模型(学习函数)的数据量呈指数增长**。**

**如果你不想阅读下面的技术细节，请随意跳到下一节。**

**我想用 **Yoshua Bengio 的(是的传说中的 Yoshua Bengio！)quora 回答**更详细的解释一下这个。我强烈建议在这里阅读整个答案[。根据答案，增加一个特征中不同值的数量只是增加了使用输入行(**包含 n 个这样的特征**)可以得到的可能组合的总数。**假设我们有两个特性，每个特性有两个不同的值，这给了我们总共 4 种可能的方法来组合这两个特性。现在，如果其中一个有三个不同的值，我们将有 3X2 =6 种可能的方式来组合它们。**](https://www.quora.com/What-is-the-curse-of-dimensionality)**

**在经典的非参数学习算法(例如最近邻、高斯核 SVM、高斯核高斯过程等)中。)模型需要看到这些组合中的每一个的至少一个例子(或者至少尽可能多的覆盖感兴趣的配置的所有变化)，以便产生正确的答案，该答案不同于其他附近配置所需的目标值。**

**对此有一个解决方法，即即使在缺乏大量训练数据的情况下，该模型也可以辨别未来预测的配置(不在训练集中),只要这些组合中存在某种结构(模式)。**在大多数情况下，高基数使模型难以识别此类模式，因此模型不能很好地推广到训练集之外的示例。****

# **通过使用简单的聚合函数降低基数**

**下面是一个简单的函数，我用它来减少一个特性的基数。想法很简单。让属于高频率值的实例保持原样，并用一个新的类别替换其他实例，我们称之为 ***other。*****

1.  **选择一个阈值**
2.  **按频率对列中的唯一值进行降序排序**
3.  **不断增加这些排序(降序)的唯一值的频率，直到达到阈值。**
4.  **这些是我们将保留的唯一类别，所有其他类别的实例将替换为**“其他”。****

**在浏览代码之前，让我们快速浏览一个例子。假设我们的列颜色有 **100** 个值，我们的阈值是 90%(即 **90** )。我们有 5 种不同的颜色:红色(50)、蓝色(40)、黄色(5)、绿色(3)和橙色(2)。括号中的数字表示该列中有多少个该类别的实例。**

**我们看到红色(50)+蓝色(40)达到我们的阈值 90。在这种情况下，我们只保留 2 个类别(红色、蓝色)，并将其他颜色的所有其他实例标记为“ **Other** ”。**

**因此，我们将基数从 **5 减少到 3(红色、蓝色、其他)****

**这是我写的一个实用函数来帮助实现这一点。这是很好的评论，并完全遵循我上面描述的，所以你不会有问题。我们可以设置一个**自定义阈值**，并且 **return_categories** 选项可选地让我们在减少基数后看到所有唯一值的列表。**

****正如您所看到的，使用这个函数，我们将资格列的基数从 15 减少到了 6！****

# ****结论****

**我们看到了如何通过使用一个简单的函数来减少基数，更重要的是为什么这是必要的(维数灾难)。但是请记住，我们很幸运，我们的列中的值的分布允许我们使用这种方法。如果所有 15 个类别平均分布，我们将无法使用这种方法，在这种情况下，可能需要将 PCA 与数据集的其他特征结合使用，但在其他时间会更多地使用。**

**如果你喜欢这篇文章，这里有更多！**

**</scatter-plots-on-maps-using-plotly-79f16aee17d0>  </regex-essential-for-nlp-ee0336ef988d>  </powerful-text-augmentation-using-nlpaug-5851099b4e97>  </effortless-exploratory-data-analysis-eda-201c99324857>  其他一些项目。可以联系我 [***这里***](https://rajsangani.me/) ***。*** 感谢您的配合！**