# 负责任的人工智能的系统设计思想

> 原文：<https://towardsdatascience.com/systems-design-thinking-for-responsible-ai-a0e51a9a2f97?source=collection_archive---------44----------------------->

![](img/9b772d75c4b52782ee29ca0a5d1b48aa.png)

[UX 店](https://unsplash.com/@uxstore?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)在 [Unsplash](https://unsplash.com/s/photos/design?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍照

很少有裸露的 AI 系统。通常情况下，人工智能功能是作为一个更大的产品或服务提供的子组件。这种产品或服务存在于一个社会生态系统中，那里有特定的文化和背景。

因此，当考虑建立一个人工智能系统以及它可能对社会产生的影响时，重要的是采取系统设计思维方法，尽可能全面地评估影响并提出补救机制。

# 什么是系统设计思维？

本质上，它是考虑系统的组件与环境元素的关系，当系统被部署时，它们将与环境元素交互。这与更封闭的方法形成对比，这种方法从产品/服务将被部署的地方孤立地看待产品/服务。使用系统设计思维方法的目的是，它有助于发现隐藏的反馈循环和外部性，这些反馈循环和外部性可能会以具有道德后果的方式影响人们，如侵犯隐私和面临偏见。

系统设计思维鼓励开发人员和设计人员将系统部署的更大的社会技术背景纳入考虑范围，并规划出他们的产品/服务将如何以及在哪里直接和间接地影响这些元素。

# 负责任的 AI 如何做系统设计思维？

一个很好的起点是承认你不一定拥有所有的信息来将这种方法应用到你正在构建的系统中，无论是在你的团队中，或者甚至是你的组织中。但是，没关系！

解决这个问题的第一步是引入外部专家和利益相关者，比如那些具有领域专家、政策制定者等。谁能帮助你更好地阐述当你试图在目标环境中部署人工智能系统时会出现的一些挑战？那些有经验的人也可以帮助指出各种系统动态和文化特性，它们会影响你的系统的行为。

这可能需要做一些实地工作来收集人们将如何实际使用你的产品/服务的情报，而实验室并不是一个很好的代理。就现实世界中可能发生的事情而言，有太多的变量隐藏在我们的盲点中。

绘制明确包含外部元素的系统图，然后标记强化和平衡反馈循环是另一个步骤，可以帮助您更全面地阐明这些影响。

另外，要注意系统的学习部分。也就是说，注意系统在与外界交互时将学习的所有流程，这对于在系统中建立弹性非常重要，以便从安全和可靠性的角度来看，它不会偏离操作参数太远。

# 有哪些事情需要记住？

尤其重要的是，你要考虑系统对游戏的适应能力。这种系统将被部署在复杂、混乱的环境中，在这种环境中，对手可能会试图利用该系统来获取他们无权获得的好处，或者损害该系统的性能，从而使该系统对最需要它的人来说变得不那么高效。在这种情况下，构建能够适度降级的故障保险非常重要。

最后，牢记系统设计思想的核心思想，强调将影响系统的二阶效应和二阶输入。这些通常很难梳理出来，但是在领域专家和过去实践过这种方法的人的帮助下，您不仅可以提高系统的弹性，还可以提高其整体性能，因为您可以更好地理解您正在解决的问题以及您提出的解决方案将会产生的影响。

> **在这里注册接收更新** [**可操作的人工智能伦理书**](https://actionableaiethics.substack.com/) **！而你可以在这里** **了解更多我的作品** [**！**](https://atg-abhishek.github.io/)
> 
> **您可以通过订阅** [**人工智能伦理简报**](https://brief.montrealethics.ai/) **从** [**蒙特利尔人工智能伦理研究所**](https://montrealethics.ai/) **了解更多这样的见解！**