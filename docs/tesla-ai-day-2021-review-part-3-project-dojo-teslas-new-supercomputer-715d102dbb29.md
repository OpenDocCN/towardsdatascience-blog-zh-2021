# 特斯拉人工智能日 2021 回顾-第 3 部分:项目道场。特斯拉的新超级计算机

> 原文：<https://towardsdatascience.com/tesla-ai-day-2021-review-part-3-project-dojo-teslas-new-supercomputer-715d102dbb29?source=collection_archive---------17----------------------->

## 人工智能|新闻

## AI 专用硬件的出现。

![](img/3d6ea0e59629541304da0d12a7b26659.png)

由 [Kelvin Ang](https://unsplash.com/@kelvin1987?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

本文是 4 部分系列的第三部分:

> 1.[完全自动驾驶汽车的承诺](/tesla-ai-day-2021-review-part-1-the-promise-of-fully-self-driving-cars-8e469265509b)
> 
> 2.[训练数据。汽车是如何学习的？](/tesla-ai-day-2021-review-part-2-training-data-how-does-a-car-learn-e8863ba3f5b0)
> 
> **3。道场项目。特斯拉的新型超级计算机**
> 
> 4.[为什么特斯拉 2022 年不会有自主人形机器人](/tesla-ai-day-2021-review-part-4-why-tesla-wont-have-an-autonomous-humanoid-robot-in-2022-76dff743f885)

# GPU 的发展

早在 20 世纪 70 年代和 80 年代，图形处理器——通常被称为 GPU——开始与游戏产业一起出现。在 90 年代，随着对街机和主机游戏的需求，任天堂、索尼和富士通等公司开始竞相构建改进的 3D 图形硬件。但直到 Nvidia 在 21 世纪初普及了 GPU，并在几年后发布了 [Nvidia GeForce 8 系列](https://en.wikipedia.org/wiki/GeForce_8_series)，它才成为一种通用计算设备，超越了游戏。

如今，GPU 在很多领域都有应用。从游戏到线性代数运算和图像处理，再到机器学习等更新颖的应用。2009 年，来自斯坦福大学的吴恩达和他的同事发表了一篇开创性的论文，其中他们提出了图形处理器作为克服机器学习模型训练中计算限制的手段:“现代图形处理器远远超过多核 CPU 的计算能力，并有可能彻底改变深度无监督学习方法的适用性。”

GPU 不再是从属于 CPU 的特定硬件元素。因此，随着深度学习行业的兴起，公司开始研究特定的计算单元，这些计算单元将利用 GPU 奠定的基础。2016 年，谷歌开创了这一趋势，推出了一款名为[张量处理单元(TPU)](https://en.wikipedia.org/wiki/Tensor_Processing_Unit) 的新计算单元，专门用于神经网络训练。

随着对高性能硬件的需求不断增加，芯片制造商的数量也在不断增加，以满足越来越大的神经网络的要求。SambaNova 成立于 2017 年，是人工智能专用芯片市场的[领导者——甚至与英伟达等公司竞争。他们押注于 VentureBeat 的 Poornima Apte](https://www.statista.com/statistics/1104843/top-ai-chip-startups/) [所说的](https://venturebeat.com/2021/08/11/how-sambanova-systems-is-tackling-dataflow-as-a-service/#:~:text=Genesis%20in%20software-driven%20hardware)“软件驱动的硬件”他们专注于人工智能系统需要什么，并从那里开始。同一条路上的另一家创业公司 Cerebras 最近与知名 AI 公司 OpenAI 进行了对话。他们想用似乎是“有史以来最大的计算机芯片”来驱动下一代 GPT

# 特斯拉转向内部芯片开发

2021 年 6 月，安德烈·卡帕西(Andrej Karpathy)发表了一篇关于特斯拉走向完全自动驾驶汽车的战略的演讲。他详细介绍了他们最新和最大的用于神经网络训练和测试的集群的规格(他们总共有三个集群)。该集群由 720 个节点组成，每个节点由 8 个 Nvidia A100 GPUs 组成，在 FP16 上总共可实现 1.8 EFLOPs 就 FLOPs 而言，它将在世界超级计算机中排名第五。

到目前为止，特斯拉一直都是这样。一方面，他们不想再依赖其他公司的芯片，另一方面，英伟达 GPU 不是专门为处理机器学习训练而设计的，这使得它们对于这项任务来说相对低效——GPU 是最佳选择，直到人工智能行业发展到构建特定硬件变得有利可图。

特斯拉决定跟随潮流，开始制造他们的芯片，并最终制造出一台超级计算机。遵循垂直整合的原则，他们希望自己设计和制造硬件，于是 Dojo 项目诞生了。

# project Dojo——特斯拉的新超级计算机

特斯拉与 Dojo 的目标是“实现最佳的人工智能训练性能。支持更大更复杂的神经网络模型。高能效和经济高效的计算。”这意味着 Dojo 不一定要比他们已经拥有的 GPU 集群更强大或更快。他们也不想让它与最强大的通用超级计算机竞争。主要标准是制造一台比其他任何计算机都更擅长人工智能的计算机——这样他们在未来就再也不需要使用 GPU 了。

构建超级计算机时的一个常见因素是如何在扩展计算能力(容易)同时保持高带宽(困难)和低延迟(非常困难)之间找到一个折中的解决方案。他们在分布式 2D 架构(一个平面)中找到了答案，该架构由强大的芯片和独特的网络结构组成，允许快速通信、高带宽和低延迟。

忠于他们的垂直整合原则，他们想自下而上地构建几乎每一层的元素。从包含最小计算元素的训练节点，到 D1 芯片，到训练瓦片(它们的规模单位)，再到最终将取代其 GPU 堆栈的 ExaPOD 集群。在接下来的几节中，我将一个接一个地解释这些组件，并一如既往地提出一些见解:

1.  训练节点——规模的最小实体
2.  D1 芯片——可与市面上最好的 GPU 相媲美
3.  训练砖——一项伟大的工程
4.  exa pod——特斯拉的新超级星团
5.  洞察力

# 训练节点——规模的最小实体

GPU 由在整个芯片上复制的更小的元素集组成。这些较小的集合是训练节点。它们包含进行大规模计算所需的不同部分——算术和逻辑单元，以及控制单元、SRAM 存储器和其他组件。

Dojo 项目主管 Ganesh Venkataramanan 称训练节点为“规模最小的实体”。它是最小的组件，通过在每个方向放置精确的副本可以进一步扩展。特别是，354 个连接的训练节点构成一个芯片，25 个连接的芯片构成一个训练片，12 个训练片构成一个机柜，10 个机柜构成 ExaPOD。通过从训练节点一路扩展这些元素，有可能达到 EFLOP 的计算性能，但要实现这一壮举，需要解决一些限制。

特别是，有一个问题是[训练节点](https://youtu.be/j0z4FweCy4M?t=6552)的大小是多少。太小会使速度变快，但同步成本太高。太大会使实现变得困难，并且会产生“内存瓶颈”因为他们希望保持低延迟，所以他们设计了测量高时钟周期信号(+2GHz)在 1 个周期(最低延迟)内可以穿越的最远距离的训练节点，并在其周围画了一个框来定义节点的大小。因为他们想保持高带宽，他们在盒子里放满了“到边缘”的电线

然后完成了具有计算元件、内存池和可编程控制核心的[高性能节点](https://youtu.be/j0z4FweCy4M?t=6589)。这些特性的组合在 BF16 时提供 1024 GFLOPs 的计算能力，在 FP32 时则降至 64 GFLOPs(单精度格式更多用于性能测试)。最后，使这些训练节点能够在不降低性能的情况下进行扩展的是它们被设计成高度模块化。也就是说，它们以这样一种方式连接，即计算能力是恒定的，并且它们形成了一个高吞吐量的通信平面。

# D1 芯片——可与市面上最好的 GPU 相媲美

将 354 个训练节点放在一起，FP32 的计算结果为 22.6 TFLOPs 为了进行比较， [Nvidia A100](https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet.pdf) 提供 19.5 TFLOPs——每个方向的片上带宽为 10 TBps。在这组节点周围，他们放置了一系列高速、低功耗通道，以获得每边 4 TBps 的片外 I/O 带宽，这是最先进的网络交换芯片 I/O 带宽的两倍。所有这些构成了特斯拉的 D1 芯片。

与英伟达 A100 等其他芯片相比，D1 芯片完全是为了训练机器学习模型。其独特的设计提供了“GPU 级的计算、CPU 级的灵活性以及两倍于网络芯片级的 I/O 带宽。”[下面是](https://youtu.be/j0z4FweCy4M?t=6828)(片外带宽与计算的 TFLOPs)与最先进的机器学习芯片的比较，包括谷歌的 TPU、现代 GPU 和启动芯片。

芯片可以无缝连接，无需胶水，扩展计算能力和各个方向的通信，同时保持芯片之间的最小延迟。设想中的[计算平面](https://youtu.be/j0z4FweCy4M?t=6878)包括大约 50 万个训练节点和 1500 个 d 1 芯片。但是他们如何集成芯片来创建这样一个计算平台，并将其与[其余的高级组件](https://youtu.be/j0z4FweCy4M?t=6878)——主机系统和接口处理器连接起来呢？

# 训练砖——一项伟大的工程

答案是训练瓷砖。25 个 D1 芯片被集成到一个扇出晶圆工艺中，以保持高带宽。此外，他们在边缘放置连接器，以保留片外 I/O 带宽。由此产生的组件被称为[训练瓦片](https://youtu.be/j0z4FweCy4M?t=6959)，它在 BF16 提供 9 PFLOPs 和 36 TB/s 片外 I/O 带宽。这也许使训练瓦片成为“芯片工业中最大的有机 mcm(多芯片模块)”

他们设计了训练瓦片以满足计算平面上的高带宽和低延迟的标准，但是他们很快意识到他们需要找到新的解决方案来实现其制造。为了给训练瓦片供电，他们创建了一个定制的电压调节器模块，可以直接连接到扇出晶片上。他们还整合了电力、热能和机械部件，创造出一个完全整合的训练瓷砖[。电源和冷却与计算平面正交，允许高性能、高带宽和低延迟。](https://youtu.be/j0z4FweCy4M?t=7055)

CleanTechnica 的 Chanan Bos 说,[训练瓷砖违背了“将晶片切割成碎片”的行业趋势。“这完全是前所未有的。”](https://cleantechnica.com/2021/08/22/teslas-dojo-supercomputer-breaks-all-established-industry-standards-cleantechnica-deep-dive-part-2/#:~:text=What%20Tesla%20is,is%20completely%20unprecedented.)

# exa pod——特斯拉的新超级星团

为了构建集群，他们只需将瓷砖拼在一起。一个 2×3 的瓷砖矩阵形成一个托盘，两个托盘一起形成一个橱柜。ExaPOD 由 10 个机柜组成。但是，考虑到高带宽的必要性，他们“打破了机柜的墙壁”，一个接一个地连接托盘，创建了一个“[无缝训练垫](https://youtu.be/j0z4FweCy4M?t=7188)。"

ExaPOD 在 BF16 时提供 1.1 EFLOPs(120 个训练瓦片、3000 个 D1 芯片和+1M 训练节点)，这使得 Dojo 几乎与 Tesla 现在用于训练其网络的 GPU 集群一样强大。由于高度分布式的模块化设计，可以使用 Dojo 的任何子集——称为 DPUs，Dojo 处理单元——用于训练目的。

高带宽低延迟结构使 Dojo 在相同成本下的性能比任何其他人工智能超级计算机高 4 倍，同时碳足迹减少 5 倍，节省更多能源(每 W 1.3 倍)。

Elon Musk 在演示结束时表示，Dojo 可能会在明年投入使用。如果这还不够，特斯拉已经想到了下一代计划，据称将比第一代 Dojo 计算机提供 10 倍的改进。

从最高层次来看，Dojo 上的演示有两个关键点。首先，在内部构建所有硬件允许特斯拉在训练人工智能模型方面实现无与伦比的性能，并允许完全垂直集成。其次，将所有组件设计为高度模块化有助于保持非常高的带宽和非常低的延迟，这是实现这种性能改进的两个要求。特斯拉再次承诺大，让我们看看他们能提供什么。

# 洞察力

## **公平的比较**

【TOP500 强项目每年两次展示世界上最强大的非分布式超级计算机。今年 6 月刊将第一名让给了日本的 [Fugaku](https://en.wikipedia.org/wiki/Fugaku_(supercomputer)) ，它达到了每秒 442.01 PFLOPs。如果我们将 ExaPOD 的 1.1 EFLOPs 性能与此进行比较，我们肯定会得出结论，特斯拉不仅要建造世界上最快的超级计算机，而且它的功能将是目前排名第一的两倍。

Dojo 不会加冕最快超级计算机的原因有两个。首先，入选 500 强的高性能计算机(HPC)必须能够执行许多不同的任务。Dojo 的特殊性[阻止了它](https://www.techrepublic.com/article/teslas-dojo-is-impressive-but-it-wont-transform-supercomputing/#:~:text=Dojo%27s%20reported%20capabilities%20don%27t%20grant%20it%20true%20high-performance%20computer%20(HPC)%20status%2C%20said%20Gartner%20research%20vice%20president%20Chirag%20Dekate%2C%20largely%20because%20it%20hasn%27t%20been%20tested%20using%20the%20same%20standards%20as%20Fugaku%20and%20other%20supercomputers.%C2%A0)获得 HPC 的资格。

第二，HPC 的性能测试是在单精度或双精度格式上进行的。也就是 FP64 或者 FP32。Dojo 在 BF16 实现 1.1 EFLOPs(脑浮点格式 16。“Brain”是 Google Brain)，它计算的[是 FP32](https://moocaholic.medium.com/fp64-fp32-fp16-bfloat16-tf32-and-other-members-of-the-zoo-a1ca7897d407#:~:text=The%20bfloat16%20format%2C%20being%20a%20truncated%20IEEE%20754%20FP32) 的一半位数。而且它不支持 FP64，而 FP64 是最苛刻的科学计算所需要的。

然而，为了便于说明，我们可以计算 Dojo 每秒可以进行多少次计算。因为 Tesla 公开了 D1 芯片在 BF16 和 FP32 上的性能，所以可以进行转换来计算 Dojo 在 FP32 上的计算能力。(这一过程并不完全正确，因为我们不能简单地从芯片到集群线性扩展性能，但它有助于我们进行粗略的比较。)

D1 芯片在 FP32 时提供 22.6 TFLOPs，在 BF16 时提供 362 TFLOPs。在 BF16 时，ExaPOD 的运算速度为 1.1 EFLOPs。计算一下:Dojo 在 FP32 时的性能= 1.1 EFLOPs(BF16)/362 TFLOPs(BF16)22.6 TFLOPs(FP32)= 68.67 PFLOPs。如果我们假设计算足够准确，那么 Dojo 的功能略低于 Tesla 当前使用的集群，后者提供了 [~90 PFLOPs](https://cleantechnica.com/2021/08/22/teslas-dojo-supercomputer-breaks-all-established-industry-standards-cleantechnica-deep-dive-part-1/#:~:text=Considering%20the%20components,around%2090%20PetaFLOP) 。

无论如何，Dojo 在成本和污染方面效率更高，而且在人工智能训练方面，很长一段时间内没有计算机能打败 Dojo。

## 独特的设计

为了创造一个完全符合人工智能系统需求的系统，特斯拉工程师需要打破一些规则，在行业标准方面进行一些创新。Bos 在这里对这个话题[有一个非常透彻的回顾。](https://cleantechnica.com/2021/08/22/teslas-dojo-supercomputer-breaks-all-established-industry-standards-cleantechnica-deep-dive-part-1/)

特斯拉的 D1 芯片是一种“片上系统”，简称 SoC。作为 SoC 的芯片包括高速缓冲存储器、处理器、图形卡和集成在其中的其他组件。现在大部分芯片都是这样设计的。然而，在 D1 芯片和其他类似的芯片之间，以及在训练瓦片和其他 MCM 之间有一些重要的区别。

任何计算硬件专家都会意识到的第一件事是，特斯拉承诺在训练瓷砖中达到的性能水平通常无法完全确定地事先定义。原因是芯片通常集成到训练瓦片中的方式。

芯片不是由一个个的组件组装而成的。取而代之的是，芯片的元件被集成到一个细长的圆形高质量硅晶片上，称为晶片。然后，该晶片被分解成组成处理器(GPU、SOC 等)的多个部分。

在破碎晶片的过程中，一些芯片可能会变得部分无用。这就是为什么特斯拉能够承诺从训练瓷砖获得完美的性能是不寻常的(按照行业标准，这将是一块破碎的晶片)。当芯片有时不能按预期工作时，他们如何确保 25 个 D1 芯片在训练瓷砖中完全正常工作？

有两种可能。特斯拉的工程师可能已经找到了一种方法，当从更大的晶片中提取芯片时，可以确保 D1 芯片的 5×5 网格完美工作。另一种选择是，训练瓦片本身是整个晶片。无论如何，这都是突破性的创新，因为通过这样做，他们可以从 D1 芯片的设计中保证 ExaPOD 的性能。

第二个很大的区别是，计算机总是在芯片之外有一个 RAM(随机存取存储器)组件，但 Dojo 没有。RAM 有两种类型:SRAM(静态 RAM，例如，高速缓冲存储器是 SRAM)和 DRAM(动态 RAM)。SRAM 的主要优点是存取速度更快，能耗更低。另一方面，DRAM 的密度更大，因此在同样的空间里可以容纳更多的数据。两者通常都是必要的，但特斯拉设计了 Dojo，所以它不需要 DRAM。

每个训练节点有 1.25 MB 的 SRAM。Bos 认为，它可能是速度更快的 SRAM 类型之一，L2 缓存，其响应时间为 3-4 ns(相比之下，DRAM 的响应时间为 60 ns)。通过在每个 D1 芯片中放置 354 个训练节点，它相当于每个芯片 442.5 MB 的缓存，这比其他任何芯片都多。

因此，我们在这里得到的是一个 D1 芯片，它有足够的 SRAM，既不需要外部 DRAM 也不需要共享缓存。Bos 说:“虽然设计听起来很奇怪，但你通常期望在 SoC 中找到的缺失组件可能是不必要的。”“这是一个非常特殊的系统，针对非常特殊的任务进行了微调，而大多数处理器都有更广泛的组件，可以更加灵活地适应各种任务。”

作为结束部分，我想强调 Dojo 的重要性，不仅因为它在创新和性能方面的突破性规格，还因为 Musk 说他们将允许其他公司在未来访问 Dojo 来训练他们的神经网络。

当一名用户问他是否曾将 Dojo 视为一种机器学习培训服务时，马斯克的回答很简单:“是的。”

这不仅仅是训练与车辆自动驾驶相关的网络，而是"[几乎任何机器学习](https://twitter.com/flcnhvy/status/1307829022332719104)"

尽管特斯拉没有取得任何重大的理论突破，比如 OpenAI 或 deep mind——目前没有人可以将他们发明或设计的东西用于研究目的——但很明显他们正在努力押注人工智能的适用性。最终结果如何还不得而知，但值得关注。

*如果你喜欢这篇文章，可以考虑订阅我的免费每周简讯*<https://mindsoftomorrow.ck.page>**！每周都有关于人工智能的新闻、研究和见解！**

**您也可以直接支持我的工作，使用我的推荐链接* [*这里*](https://albertoromgar.medium.com/membership) *成为中级会员，获得无限权限！:)**