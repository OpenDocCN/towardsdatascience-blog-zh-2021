# GitHub Copilot——新一代人工智能程序员

> 原文：<https://towardsdatascience.com/github-copilot-a-new-generation-of-ai-programmers-327e3c7ef3ae?source=collection_archive---------14----------------------->

## 人工智能

## GitHub、微软、OpenAI 都达到了一个新的里程碑。

![](img/70ccfeb2547bdb77affbae7da9f771f5.png)

妮可·沃尔夫在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

当 OpenAI 去年发布 GPT-3 时，人们对它从自然语言提示中生成代码的能力感到惊讶。 [Sharif Shameem](https://twitter.com/sharifshameem/status/1282676454690451457) 和其他人兴奋地分享了他们的发现，很快炒作和担忧就一飞冲天了。但是 GPT 3 号远不是一个伟大的程序员。它能理解英文文本并将其转换成一段代码，这是一个值得注意的壮举，但它的表现平平。

OpenAI 和微软(现在[资助他们的项目](https://openai.com/blog/microsoft/))在 GPT-3 的编码能力中看到了一个非常有前途的商业产品，并很快开始开发另一种语言模型；一个程序员 AI。新的模式将权衡，关于 GPT-3，一般语言技能的编码能力。这个“GPT-3 的后代”，正如 Greg Brockman 所说，被称为 OpenAI Codex，它是该领域最新突破背后的人工智能:GitHub Copilot。

两天前，OpenAI、GitHub 及其母公司微软展示了 [GitHub Copilot](https://copilot.github.com/) ，这是一款由 OpenAI Codex 提供支持的人工智能工具，它可以作为一对程序员，帮助人类开发人员编写代码。这是未来几年将变得无处不在的新一代人工智能程序员中的第一个，也是自 GPT-3 以来该领域最重要的里程碑。这将为软件行业的彻底变革打开大门，但这些变革对劳动力有利或有害的程度仍是未知的。

# GitHub Copilot——人工智能配对程序员

## 事实真相

GitHub Copilot(从现在开始 Copilot)是一个人工智能工具——目前正在技术评审中——它可以在程序员编写代码时向他们提出建议。微软已经在 Visual Studio 代码中实现了它，并将它集成到商业 VS 产品中。目前，它只对少数开发者开放(你可以试试你的运气[这里](https://github.com/features/copilot/signup))。

副驾驶并非同类产品中的首创；Tabnine 和 [Kite](https://www.kite.com/) 是两个涵盖相同功能的流行工具。然而，Copilot 之所以脱颖而出，是因为它由 Codex 提供支持，Codex 是 GPT-3 的后代，它提供了比其他助手更深入的背景理解。Codex 类似于 GPT-3，有一个重要的区别:它接受了来自 GitHub 知识库和其他网站的大量公开编码数据的训练。

Codex 是一种编程语言模型，OpenAI 将在今年夏天将其集成到他们的 API 中。它在这方面的能力大大超过了 GPT-3——或 [GPT-J](/cant-access-gpt-3-here-s-gpt-j-its-open-source-cousin-8af86a638b11) 。正如我在之前的一篇文章中所论述的，类似 GPT 的模型似乎在他们专注于一项任务时释放出一种潜在的力量。GPT-3，万能的杰克，在许多任务上是惊人的。相比之下，Codex 是编码大师。

但是 Codex 和 Copilot 都不是完美的。考虑到那些预先测试它的人的证词，这个工具工作得很好。但是，就像所有由人类编写的代码一样，副驾驶的代码应该经过“[测试、审查和审核](https://copilot.github.com/#faqs)”GitHub 开发人员创建了安全机制来为用户提供最佳体验，但系统“有时可能会产生不希望的输出，包括有偏见的、歧视性的、辱骂性的或攻击性的输出。”Copilot 代码甚至可能无法编译，因为它不会测试输出的代码。简而言之，这是一种新工具的早期版本；它有缺陷，但它的承诺大大超过这些缺陷。

## 它的作用

[在 GitHub 页面](https://copilot.github.com/)上，有 Copilot 惊人表现的例子。它可以完成代码行或编写完整的函数，将描述性注释转换成代码，自动填充重复的代码，或者为您的方法创建单元测试。它可以接受当前行以上的几百行作为输入，但是有一个重要的限制:不能从其他文件中输入代码。

它与 Python、JavaScript、TypeScript、Ruby 和 Go 配合得最好，但它“理解几十种语言”。但是，因为它有时会失败，所以在探索新的库或用未知的编程语言编写时，它可能更有用。否则，审阅 Copilot 的代码可能比自己编写代码要花更多的时间。

Copilot 基于一种类似于 GPT-3 的语言模型，所以它已经适应了它被训练的代码。但是，随着你使用它，它开始“理解”你的风格并适应你。而如果你不喜欢第一个建议，你可以要求它提供 top-k 的解决方案。

# Copilot 的重要含义

## 语言模型的力量

GPT-2，GPT-3，开关变压器，LaMDA，MUM，悟道 2.0…预先训练的语言模型现在是人工智能的蛋糕，该领域的每个主要参与者都在争夺最大的份额。原因是这些模型工作得非常好。GPT-3 是最受欢迎的，这是理所当然的。当 OpenAI 发布 GPT-3 API 时，它让世界得以一窥它的威力，并且它生效了。GPT 3 号如此强大，性能如此之好，人们甚至敢称它为 AGI——其实不然。

然而，因为 GPT-3 是一种通用语言模型，所以可以合理地假设，如果做好充分准备，它可以提高在特定任务中的性能。基线 GPT-3 可以被描绘成一个万事通，而其专业版本将是他们的任务的主人。DALL E 是这种可能性的第一个暗示。OpenAI 在文本-图像对上训练该系统，这使得 DALL E 能够从字幕和更多内容中生成图像，在视觉创意方面表现出色。 [GPT-J](/cant-access-gpt-3-here-s-gpt-j-its-open-source-cousin-8af86a638b11) ，一个比 GPT-3 小 30 倍的类似系统，可以生成更好的代码，因为它在 GitHub 和 StackExchange 数据上进行了大量训练。 [PALMS](/openai-palms-adapting-gpt-3-to-society-49c16ae5e039) ，一种减少 GPT-3 偏差的方法，进一步加强了这个假设。研究人员通过在一个小型精选数据集上进行微调，显著改善了 GPT-3 的行为。

现在，Copilot 与 Codex 合作，已经明确证明了这一想法:语言模型可以专门化，成为它们的贸易大师。Codex 是编程大师，那么一个超级强大的专业语言模型还能掌握哪些领域呢？他们能掌握逻辑或数学等其他形式语言吗？他们能掌握 GPT 3 号的每一项功能吗？一个语言模型能写出莎士比亚、塞万提斯或托尔斯泰水平的小说吗？它能成为今年夏天最热门的歌曲吗？什么是可能的还不清楚。清楚的是，我们还没有发现它们的极限。

## 编码的未来

当 GPT-3 发布时，许多人看到了编码终结的另一个垫脚石；无代码接管的速度比我们想象的要快。现在，Copilot 将担忧提升到了前所未有的程度。顾名思义，它被设计成一个合作伙伴。GitHub 说“你是飞行员”，但是我们怎么能确定这在未来不会改变呢？

它的创造者希望 Copilot“让现有的工程师更有效率，减少手动任务，帮助他们专注于有趣的工作。”然而，在人工智能也能更快、更便宜、更准确地完成这项“有趣的工作”之前，还需要多少时间呢？GitHub 首席执行官 Nat Friedman 说“我们每天解决的问题可能会改变。但总会有问题需要人类去解决，”但也许不是同一批人会准备去解决新的问题。

未来是不可预测的，今天可能会出现两种情况:要么我们与人工智能建立共生关系，为每个人找到一席之地，要么人工智能将接管许多工作。即使它从未达到完美，Copilot 或它的继任者也可以消除程序员的必要性，只留下少数人来“测试、审查和审核”AI 的代码。我们只能希望，如果发生工作岗位的转移或替代，决策者将做出适当的反应，并为受影响的人提供安全网。

## 有用不可靠？

如果 Copilot 不是 100%可靠，它有用吗？到什么程度，在哪些情况下不使用比较好？一个不专业的程序员能利用它吗？或者它更适合专业程序员，他们会花更多的时间来检查代码而不是自己写代码。副驾驶的不可靠性引发了许多与实用性相关的问题。

乔尔·斯波尔斯基(Joel Spolsky)的一句名言现在派上了用场:“阅读代码比编写代码更难。”一个没有经验的程序员可能不知道 Copilot 代码的问题，而一个经验丰富的程序员更喜欢写代码，而不是阅读 Copilot 生成的代码。使用 Copilot 显然是值得的情况很少:一个有经验的程序员想要尝试一个新的库/语言/框架，或者想要基于手工制作的方法编写单元测试(尽管那些也需要被审查)。另一种情况是一个没有经验的程序员开始学习。

然而，还有比 Copilot 写低质量代码更大的问题。来自 GitHub 的常见问题:“世界上有许多公共代码存在不安全的编码模式、错误或对过时 API 或习惯用法的引用。当 GitHub Copilot 基于这些数据合成代码建议时，它也可以合成包含这些不良模式的代码。”一个值得考虑的问题是，Copilot 会减少还是增加这些问题的数量。

## 法律问题

*我不是律师，也绝对不是美国法律专家，*但是 Nat Friedman 开设的 [*黑客新闻*](https://news.ycombinator.com/item?id=27676939) 帖子提出了关于知识产权、许可证和版权侵权的重要问题。GitHub 在 Copilot 常见问题中表示，“大约 0.1%的时间”Copilot 的建议是“逐字来自训练集”。这意味着 Copilot 用户可能会采纳一个建议，该建议包含与项目目的相冲突的受版权保护的代码。这就提出了一个重要的问题:在这种情况下，谁应该承担责任，用户，GitHub/微软，还是拥有该项目的公司？

他们还提到“您应对您在 GitHub Copilot 的帮助下创建的内容负责。我们建议您像对待自己编写的任何代码一样，仔细测试、审查和审核代码。”这是否意味着，如果我们使用了 StackOverflow 提出的 Copilot 建议，而该建议恰好受到 GPL 许可，我们就要对侵权行为负责？怎么才能知道 Copilot 是否抄袭了一大块我们用不到的代码？公司会允许员工使用 Copilot 吗？还是会因为禁止从 StackOverflow 复制代码的原因而禁止使用 Copilot？

另一位用户指出，如果 GitHub 没有将 Copilot 培训限制在“一个合理的许可白名单(mit、BSD、Apache 等)”中，那么使用该工具从事“重要/创收”项目将是一个风险。没有信息表明这是真的还是假的，因此上述问题似乎是合理的。Nat Friedman 表示，关于知识产权和人工智能的辩论将在未来几年内发生，但就目前而言，使用 Copilot 可能会产生更多问题，而不是解决方案。

# 结论

GitHub Copilot 注定要改变全世界很多程序员的日常。尽管我强调了这些问题，但这项技术是一个重要的里程碑，将引领未来走向无代码，这是微软多年来一直追求的目标。

副驾驶感觉像一个拐点，没有人知道事件将如何从这里展开。程序员几年后会开始失业吗？我们会设法找到一个有益的飞行员-副驾驶协同作用吗？它会提供这样一种优势，以至于企业要么不得不适应它，要么就死掉吗？程序员会不得不以职业生存换取隐私吗？

自周二以来，出现了许多问题，还会有更多的问题出现。目前，答案还需要等待。GitHub Copilot 启动。让我们睁大眼睛，看看它将把我们带向何方。

## [***跟我一起旅行到未来***](https://mindsoftomorrow.ck.page/) ***了解更多关于人工智能、哲学和认知科学的内容！还有，可以在评论里随意提问或者在***[***LinkedIn***](https://www.linkedin.com/in/alberromgar/)***或者***[***Twitter***](https://twitter.com/Alber_RomGar)***！:)***

## 推荐阅读

[](/understanding-gpt-3-in-5-minutes-7fe35c3a1e52) [## 五分钟了解 GPT-3

### 有数百篇关于 GPT 3 号的文章。这里有一个 5 分钟的关于它的所有信息的汇编。

towardsdatascience.com](/understanding-gpt-3-in-5-minutes-7fe35c3a1e52) [](/cant-access-gpt-3-here-s-gpt-j-its-open-source-cousin-8af86a638b11) [## 无法进入 GPT 3 号？这是 GPT J——它的开源兄弟

### 类似于 GPT-3，每个人都可以使用它。

towardsdatascience.com](/cant-access-gpt-3-here-s-gpt-j-its-open-source-cousin-8af86a638b11)