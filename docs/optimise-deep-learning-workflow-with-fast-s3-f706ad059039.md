# 利用快速 S3 优化深度学习工作流程

> 原文：<https://towardsdatascience.com/optimise-deep-learning-workflow-with-fast-s3-f706ad059039?source=collection_archive---------27----------------------->

## 以快速 S3 为中心数据和模型库，构建可复制、可扩展的深度学习系统。

我知道大多数数据科学家不关心存储，他们也不应该关心存储。然而，在系统中拥有快速 S3 对象存储肯定会有助于优化我们的深度学习工作流程。让我在这篇博客中解释一下为什么“存储在 DL 中非常重要”。

# 快速 NFS 分布式培训

在我之前的博客中，我解释了为什么以及如何使用 Kubernetes、Horovod 和 FlashBlade NFS 这样的快速 NFS 存储从单节点扩展到分布式多节点训练。下面是我们在博客中讨论的架构:

![](img/15cd3d5636cc4b02879031e4a3ea4740.png)

在 FlashBlade NFS 上使用 Kubernetes 进行深度学习

这是船上分布式培训的第一阶段。虽然存储可能很少出现在 DL 对话中，但构建可扩展的 DL 系统就像建造一座大房子，您需要在屋顶工作之前先构建一个坚实的基础。DL 系统的基础是基础设施，不仅包括 GPU 服务器，还包括存储和网络。在上述体系结构中，如果我们只关注 NFS 存储部分，它带来的好处包括:

*   允许在不适合单个主机的大型数据集上进行训练。
*   允许团队共享昂贵的 GPU 硬件和数据。
*   让机器学习工程师更容易聚合日志、管理检查点和导出模型。

然而，随着系统的升级和扩展以支持更多的机器学习工作和操作，挑战出现了。NFS 对于主机或机架来说是静态的，但是 DL 工作流是非常动态的。因为所有主机/单元都需要装载一个 NFS 卷来访问其中的数据，所以这在大规模应用时会很有挑战性:

*   数据访问控制在主机级别。因此，存在数据集从装载该卷的任何主机上意外删除的风险。
*   由于上述风险，数据集的主副本通常存储在远程存储器中，如 HDFS 或 S3。将数据从 HDFS 或 S3 复制到 NFS 可能会很慢。
*   难以进行可重复的模型训练，这需要对代码和数据进行集中管理。
*   弹性模型服务困难。在大公司中，模型训练和服务通常在不同的环境中由不同的团队管理。特别是，模型服务系统可能会频繁地扩大和缩小，NFS 根本不是最适合的。

这里的解决方案是借用数据工程和 devOps 的最佳实践到我们的 DL 工作流中。我见过的最佳实践之一是使用像 S3 这样的对象存储作为中央数据存储库。

# 利用快速 S3 优化 DL 工作流程

在机器学习和深度学习之前，我在大数据(Hadoop 和 Spark)和 devOps(云，平台即服务)上花了 10 多年时间。我从自己的经历中学到的一件事是，S3 对象存储在这些系统中起着至关重要的作用。这也适用于大规模的 DL 系统。

快速 S3 对象存储如何帮助优化我们的 DL 工作流程？好处来自于使用 S3 作为数据和模型的中央存储库。在以下修改后的体系结构中，我们使用 S3 闪存来存储训练数据集、日志和检查点，而不是 NFS。

![](img/d8140e343fc0aaba3aedddf727ea627c.png)

利用快速 S3 优化 DL 工作流程

我们仍然使用 NFS，但仅用于工作区卷，它仅存储临时数据。我们将训练数据和模型管理集中在快速 S3 对象存储中，与 NFS 不同，它是在存储端而不是每个单独的主机上进行管理的，并且可以从系统中的任何位置进行访问。快速 S3 是动态 DL 工作流的理想选择。

## 在 S3 使用数据集

我们没有将数据集放在 NFS，而是放在了 S3 桶中。这使得能够与数据工程工作流顺利集成。S3 正在成为 Apache Spark 等许多大数据工具的标准存储。我们的数据工程团队可能使用 Spark 来完成繁重的 ETL 工作，并简单地将预处理的输出(例如，拼花文件)放入 S3 桶中。通过使用 S3，我们避免了数据工程和数据科学团队之间额外的数据拷贝。看看我的博客关于如何在 S3 上使用 Apache Spark 和 Kubernetes。一旦预处理完成，输出数据将立即出现在 S3。我们可以使用 JupyterLab 的 S3 浏览器扩展来研究这些数据。

![](img/071636503529353a6473d5b832b84b91.png)

JupyterLab S3 浏览器

然后培训岗位可以选择将数据下载到其工作区 NFS 卷，或者直接在 S3 阅读，进行培训。由于 FlashBlase S3 非常快，因此将 S3 数据直接读入训练迭代是可行的。如果数据集太大而无法下载，这将非常有用。例如，我们可以像这样直接从 TensorFlow 中的 S3 读取数据，而不是下载 20TB 的数据:

```
ds = tf.data.TFRecordDataset(
               s3_filepaths, 
               num_parallel_reads=10, 
               buffer_size=100000000)
```

与下载整个 20TB 数据集相比，上面的代码使用最少的临时存储和内存，可以立即开始，而不必等待下载完成。通过使用像 FlashBlade S3 这样的快速 S3，并调整并行读取的数量和缓冲区大小，可以达到与从快速 NFS 读取相当的性能。

## 使用 S3 进行模型跟踪和服务

在上面的架构中，我们还使用 S3 来存储训练日志、检查点和模型。这使得我们可以很容易地将模型跟踪和服务从训练中分离出来，这对于构建一个可重复和可伸缩的 DL 管道是必不可少的。下面的例子启动了一个指向存储在 S3 的日志的 TensorBoard pod。

```
tensorboard --logdir s3://deephub/models/lstm-sentiment/logs --host 0.0.0.0
```

![](img/7a98ddec2eb9166c043c1110dec5f47d.png)

S3 支持的 TensorBoard

我们还可以在 Kubernetes 上单独部署一个 mlflow 跟踪服务器，并将其指向 S3 桶进行高级模型跟踪。

```
mlflow server \
 --backend-store-uri postgresql://user:password@mypostgres:5432/mlflow \
 --default-artifact-root s3://deephub/mlflow/ \
 --host 0.0.0.0
```

![](img/4b0bb94290e7a3e426f675f2c60b3cd6.png)

使用 S3 后端进行物流跟踪

同样，模特服务也可以得到 S3 的支持。

```
MODEL_BASE_PATH=s3://bucket/models tensorflow/serving
```

模型服务基本上是一个 web 应用程序，它将模型公开为 web APIs。运营和扩展模型服务就像一个典型的 devOps 场景。将原始模型放在 S3，所有的服务 pods 都可以从中读取和缓存，这就像是 devOps 中运行稳定且可伸缩的 web 应用程序的常见做法。

# 摘要

由于所有重要的数据，包括数据集、训练日志、检查点和模型，都存储在 S3，数据和模型管理变得更加容易。S3 存储桶中的数据是黄金记录，被集中起来并受到保护。通过使用 S3 复制和版本控制，我们可以进一步增强我们的数据保护。高级用户还可以在 S3 数据的基础上构建数据治理、质量控制和模型版本控制。

总而言之，使用 S3 作为中央数据存储库有助于从以下几点优化 DL 工作流程:

*   简化的工作流程。涉及的存储操作较少。数据科学家可以简单地下载或直接从 S3 的训练代码中读取数据。
*   简单的数据和模型管理。我们通过将数据放在 S3 作为数据和模型的黄金记录来避免数据孤岛。数据保护、版本控制和跟踪更加容易。所有这些都将有助于可重复的模型训练。
*   易于弹性模型服务。通过分离模型训练、跟踪和服务，深度学习工作流中的每个阶段都可以独立、轻松、快速地扩大和缩小。

下一篇博客再见。