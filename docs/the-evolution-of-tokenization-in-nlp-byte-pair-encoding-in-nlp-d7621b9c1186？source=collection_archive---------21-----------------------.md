# 自然语言处理中标记化的演变——自然语言处理中的字节对编码

> 原文：<https://towardsdatascience.com/the-evolution-of-tokenization-in-nlp-byte-pair-encoding-in-nlp-d7621b9c1186?source=collection_archive---------21----------------------->

## 不同标记化算法介绍

![](img/12473c24ac9bec91e93caa4d1f27b0fd.png)

作者图片

NLP 可能对人工智能的顿悟来说有点晚，但它正在与 Google 这样的组织一起创造奇迹，OpenAI 分别发布了最先进的(SOTA)语言模型，如 BERT 和 GPT-2/3。

GitHub Copilot 和 OpenAI codex 是新闻中非常受欢迎的几个应用程序之一。作为一个对 NLP 了解非常有限的人，我决定将 NLP 作为一个研究领域，接下来的几个博客/视频将是我在剖析 NLP 的一些重要组成部分后分享我所学到的东西。

NLP 系统有三个主要组件来帮助机器理解自然语言:

1.  标记化
2.  把...嵌入
3.  模型架构

像伯特、GPT-2 或 GPT-3 这样的顶级深度学习模型都共享相同的组件，但具有不同的架构，从而将一个模型与另一个模型区分开来。

在这篇时事通讯(以及[笔记本](https://colab.research.google.com/drive/1QLlQx_EjlZzBPsuj_ClrEDC0l8G-JuTn?usp=sharing))中，我们将重点关注 NLP 管道的第一个组件的基础知识，即**令牌化**。一个经常被忽视的概念，但它本身就是一个研究领域。我们已经远远超越了传统的 NLTK 标记化过程。

虽然我们有 SOTA 算法用于标记化，但理解进化轨迹并了解我们是如何到达这里的总是一个很好的实践。

所以，这是我们要讲的内容:

*   什么是标记化？
*   为什么我们需要一个记号赋予器？
*   标记化的类型—单词、字符和子单词。
*   字节对编码算法——这是目前大多数 NLP 模型使用的一个版本。

本教程的下一部分将深入更高级(或增强版的 BPE)的算法:

*   **单字算法**
*   **文字件—伯特变压器**
*   **例句—端到端令牌化器系统**

# 什么是标记化？

记号化是以称为记号的较小单元来表示原始文本的过程。然后，可以将这些标记与数字进行映射，以进一步提供给 NLP 模型。

下面是一个过于简化的例子，说明了记号赋予器的功能:

![](img/0f4370beb39f31024748e1c28c92225f.png)

作者图片

这里，我们简单地将文本中的每个单词映射到一个数字索引。显然，这是一个非常简单的例子，我们没有考虑语法、标点符号、复合词(如 test、test-ify、test-ing 等)。).

因此，我们需要一个更技术性、更准确的标记化定义。为了考虑到每一个标点符号和相关的单词，我们需要从字符层面开始工作。

标记化有多种应用。其中一个用例来自编译器设计，我们需要解析计算机程序，将原始字符转换成编程语言的关键字。

**在深度学习中，**记号化是将字符序列转换为记号序列的过程，记号序列需要进一步转换为神经网络可以处理的数值向量序列。

# 为什么我们需要一个记号赋予器？

对记号赋予器的需求已经从“我们如何让机器阅读”这个问题中凸显出来

![](img/7856a793aa26b878625448c94716882e.png)

作者图片

处理文本数据的一种常见方法是在字典中定义一组规则，然后查找固定的规则字典。但这种方法只能到此为止，我们希望机器从它阅读的文本中学习这些规则。

现在，机器不知道任何语言，也不理解声音或语音。他们需要从零开始学习，以这种方式他们可以阅读任何可能的语言。

很艰巨的任务，对吧？

人类通过把声音和意义联系起来来学习语言，然后我们学习用那种语言读和写。机器做不到这一点，所以它们需要被赋予最基本的文本单元来开始处理它。

这就是标记化发挥作用的地方。将文本分解成更小的单元，称为“记号”。

有不同的方法来标记文本，这就是我们现在要学习的。

# 令牌化策略—令牌化的简单方法

为了使深度学习模型从文本中学习，我们需要一个两步过程:

![](img/30e95380369c8222bdb877659af89334.png)

作者图片

1.  令牌化—决定用于生成令牌的算法。
2.  将记号编码成向量

正如第一步所建议的，我们需要决定如何将文本转换成小的标记。我们大多数人建议的一种简单直接的方法是基于单词的标记，按空格分割文本。

# 单词标记器的问题

*   **训练数据中丢失单词的风险:**使用单词标记，您的模型将无法识别不属于模型训练数据的单词变体。因此，如果您的模型在训练数据中看到了`foot`和`ball`，但最终文本有`football`，则模型将无法识别该单词，并将使用`<UNK>`令牌对其进行处理。类似地，标点符号带来了另一个问题，`let`或`let's`将需要单独的标记，这是一个低效的解决方案。这将需要大量的词汇来确保你拥有这个单词的每一个变体。即使您添加了一个 **lemmatizer** 来解决这个问题，您也在您的处理管道中添加了一个额外的步骤。
*   **处理俚语和缩写-** 另一个问题是如今在文本中俚语和缩写的使用，比如“FOMO”、“LOL”、“TL；”博士等。我们对这些单词做了什么？
*   **语言不使用空格分词怎么办:**对于汉语这样不使用空格分词的语言，这个分词器会彻底失效。

遇到这些问题后，研究人员研究了另一种方法，即将所有字符标记化。

# 基于字符的标记化

为了解决与基于单词的标记化相关联的问题，尝试了一种逐个字符的标记化的替代方法。

这确实解决了遗漏单词的问题，因为现在我们正在处理可以使用 ASCII 或 Unicode 编码的字符，它现在可以为任何单词生成嵌入。

每个字符，无论是空格、撇号还是冒号，现在都可以被赋予一个符号来生成一系列向量。

但是这种方法有它自己的缺点。

# 基于角色的模型的缺点

*   **需要更多的计算:**基于字符的模型将把每个字符视为记号，更多的记号意味着需要更多的输入计算来处理每个记号，这反过来需要更多的计算资源。对于一个 5 个单词的长句，您可能需要处理 30 个标记，而不是 5 个基于单词的标记。
*   **缩小 NLP 任务和应用的数量:**对于长字符序列，只能使用某种类型的神经网络架构。这限制了我们可以执行的 NLP 任务的类型。对于像实体识别或文本分类这样的应用程序，基于字符的编码可能是一种低效的方法。
*   **学习不正确语义的风险:**使用字符可能会产生不正确的单词拼写。此外，没有内在的意义，学习字符就像学习没有意义的语义。

> *令人着迷的是，对于这样一个看似简单的任务，编写了多个算法来寻找最佳的标记化策略。*

在理解了这些标记化方法的优缺点之后，寻找一种提供中间路线的方法是有意义的，即使用有限的词汇来保留语义，这些词汇可以在合并时生成文本中的所有单词。

# 子词标记化

使用基于字符的模型，我们可能会丢失单词的语义特征，而使用基于单词的标记化，我们需要非常大的词汇量来包含每个单词的所有可能的变化。

因此，我们的目标是开发一种算法，它可以:

1.  保留令牌的语义特征，即每个令牌的信息。
2.  标记化，而不需要非常大的词汇量和有限的单词集。

为了解决这个问题，我们可以考虑根据一组前缀和后缀来分解单词。例如，我们可以编写一个基于规则的系统来识别子词，如`"##s"`、`"##ing"`、`"##ify"`、`"un##"`等。，其中双散列的位置表示前缀和后缀。

因此，像`"unhappily"`这样的词是使用子词`"un##"`、`"happ"`和`"##ily"`来标记的。

该模型只学习几个子词，然后将它们放在一起创建其他词。这解决了创建大词汇量的内存需求和努力的问题。

# 此算法的问题:

*   根据定义的规则创建的一些子词可能永远不会出现在您的文本中进行标记，并且可能会占用额外的内存。
*   此外，对于每种语言，我们需要定义不同的规则集来创建子词。

为了缓解这个问题，在实践中，大多数现代记号赋予器具有识别输入语料库中的重复出现的文本并创建新的子词记号的训练阶段。对于罕见的模式，我们坚持使用基于单词的标记。

在这个过程中，另一个起着至关重要作用的重要因素是用户设置的词汇表的大小。较大的词汇表允许对更多的常用单词进行标记，而较小的词汇表需要创建更多的子词来创建文本中的每个单词，而不使用`<UNK>`标记。

在这里，为您的应用取得平衡是关键。

# 字节对编码(BPE)

BPE 最初是一种数据压缩算法，用于通过识别公共字节对来寻找表示数据的最佳方式。现在在 NLP 中使用它来用最少的标记找到文本的最佳表示。

它是这样工作的:

1.  在每个单词的末尾加一个标识符(`</w>`)来标识一个单词的结尾，然后计算在文中的词频。
2.  将单词拆分成字符，然后计算字符频率。
3.  根据字符标记，对于预定义的迭代次数，计算连续字节对的频率，并合并最频繁出现的字节对。
4.  继续迭代，直到达到迭代次数限制(由您设置)或者达到令牌限制。

让我们来看一个示例文本的每个步骤(用代码)。为了编写这段代码，我得到了毛蕾在 BPE 的极简博客的帮助。我鼓励你去看看！

以下是我们的示例文本:

![](img/18ad9a5ff4f0e9f29138924e924e7701.png)

# 第二步:将单词拆分成字符，然后计算字符频率。

![](img/d26e729381fa691f8b0ba42e26b23711.png)

作者图片

# 步骤 3:合并最频繁出现的连续字节对。

![](img/be1984814aa7aac260e94c4574be34fa.png)

作者图片

# 步骤 4-迭代多次以找到要编码的最佳(就频率而言)对，然后连接它们以找到子字。

在这一点上，最好将我们的代码结构转换成函数。这将要求我们执行以下步骤:

1.  在每次迭代中找到最频繁出现的字节对。
2.  合并这些令牌。
3.  添加新的成对编码后，重新计算字符标记频率。
4.  继续这样做，直到没有更多对，或者到达 for 循环的末尾。

详细代码，你可以**查阅我的** [**Colab 笔记本**](https://colab.research.google.com/drive/1QLlQx_EjlZzBPsuj_ClrEDC0l8G-JuTn?usp=sharing) **。**

这是这 4 个步骤的精简输出:

![](img/4a96e6c88f12d3d2dc310f6125f4a2f3.png)

作者图片

因此，当我们迭代每个最佳对时，我们合并(连接)该对，您可以看到，当我们重新计算频率时，原始字符标记频率降低，新的成对标记频率在标记字典中弹出。

如果你看看创建的令牌的数量，它首先增加，因为我们创建了新的配对，但是在多次迭代之后，数量开始减少。

这里，我们从 25 个令牌开始，在第 14 次迭代中增加到 31 个令牌，然后在第 50 次迭代中减少到 16 个令牌。很有趣，对吧？

# BPE 算法的改进范围

BPE 算法是一种贪婪算法，即它试图在每次迭代中找到最佳对。这种贪婪的方法有一些局限性。

因此，BPE 算法也有优点和缺点。

最终的令牌将根据您运行的迭代次数而变化，这也会导致另一个问题。现在，我们可以对一个文本使用不同的标记，从而实现不同的嵌入。

为了解决这个问题，提出了多种解决方案，但最突出的是一个 unigram 语言模型，该模型添加了[子词正则化(一种新的子词分割方法)](https://arxiv.org/pdf/1804.10959.pdf)训练，该训练使用损失函数计算每个子词标记选择最佳选项的概率。在接下来的博客中会有更多的介绍。

# 他们在 BERTs 或 GPTs 中使用 BPE 吗？

像 BERT 或 GPT-2 这样的模型使用某种版本的 BPE 或 unigram 模型来标记输入文本。

BERT 包含了一个新的算法，叫做 WordPiece，它也类似于 BPE，但是增加了一层可能性计算，以决定合并后的令牌是否会最终通过。

# 摘要

你在这个博客中学到的(如果有的话)是机器如何通过将文本分解成非常小的单元来开始理解语言。

现在，有许多方法来分解文本，因此比较一种方法与另一种方法变得很重要。

我们从通过空格分割英语文本来理解标记化开始，但并非每种语言都以相同的方式书写(即使用空格来表示分段)，因此我们研究了通过字符分割来生成字符标记。

字符的问题是从标记中丢失了语义特征，冒着创建不正确的单词表示或嵌入的风险。

为了两全其美，引入了更有前途的子词标记化，然后我们研究了实现子词标记化的 BPE 算法。

更多关于接下来的步骤和高级分词器，如单词块、句子块，以及下周如何使用 HuggingFace 分词器。

# 参考文献和注释

我的帖子实际上是以下论文和博客的积累，我鼓励你阅读:

1.  [具有子词单元的稀有词的神经机器翻译](https://arxiv.org/pdf/1508.07909.pdf) —讨论基于 BPE 压缩算法的不同分割技术的研究论文。
2.  [GitHub repo on Subword NMT(神经机器翻译)](https://github.com/rsennrich/subword-nmt) —上述论文的支持代码。
3.  [毛蕾关于字节对编码的博客](https://leimao.github.io/blog/Byte-Pair-Encoding/)——我自己用他博客里的代码实现并理解了 BPE。
4.  机器如何阅读 Cathal Horan 的博客。

# 和我联系！

如果你正在寻找数据科学或 ML 领域的起点，请查看我的课程数据科学基础[**&ML**](https://www.wiplane.com/p/foundations-for-data-science-ml)。

如果你想看到更多这样的内容，并且你不是订阅者，考虑使用下面的按钮订阅我的时事通讯。

[立即订阅](https://dswharshit.substack.com)

如有任何补充或建议，您可以通过以下方式联系我:

*   [YouTube](https://www.youtube.com/channel/UCH-xwLTKQaABNs2QmGxK2bQ)
*   [推特](https://twitter.com/dswharshit)
*   [领英](https://www.linkedin.com/in/tyagiharshit/)