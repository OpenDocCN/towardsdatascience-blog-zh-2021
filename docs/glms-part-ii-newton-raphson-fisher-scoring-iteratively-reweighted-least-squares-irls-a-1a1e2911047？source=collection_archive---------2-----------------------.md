# GLMs 第二部分:牛顿-拉夫森，费希尔评分，迭代加权最小二乘法(IRLS)-一个严格的概述

> 原文：<https://towardsdatascience.com/glms-part-ii-newton-raphson-fisher-scoring-iteratively-reweighted-least-squares-irls-a-1a1e2911047?source=collection_archive---------2----------------------->

## 用计算机模拟迭代拟合技术的数学推导和实现。

![](img/7b06ac9e76f5cd8cce4313bf7a47a35d.png)

穆罕默德·拉赫马尼在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

# 1:背景和动机

广义线性模型(GLMs)在包括统计学、数据科学、机器学习和其他计算科学在内的领域中起着关键作用。

在本系列的[第一部分中，我们提供了规范和非规范形式的常见 GLMs 的全面的数学概述(带证明)。下一个需要解决的问题是，我们如何让数据符合 GLM 模型？](/generalized-linear-models-a-rigorous-mathematical-formulation-58ac2ec7d9ea)

从历史背景来看 GLMs 时，有三个密切相关的重要数据拟合程序:

*   牛顿-拉夫森
*   费希尔评分
*   迭代加权最小二乘法(IRLS)

我发现这些技术的关系和动机往往很难理解，上面的术语有时会以不正确的方式互换使用。这篇文章提供了这三个重要的迭代数值拟合过程的严格概述，连接它们的历史的讨论，以及在示例规范和非规范 GLMs 上实现这些方法的详细计算模拟。在未来的一篇文章中，我们将通过多阶段递归 GLM 模型的镜头来涵盖神经网络的推导。

这篇文章的目录如下:

![](img/ec0a90e93f2e42e24f9d2ea3141baf6e.png)

作者图片

说到这里，让我们开始吧！

# 2:迭代数值拟合技术的推导

## 2.1:根据数据拟合模型—简介

让我们首先为我们如何思考“用数据拟合模型”以及我们在数学上的含义打下基础。

![](img/28711e3df92702e1e086d0f4617c562b.png)

作者图片

![](img/d4cf0a4048082a1917c478f499f9effa.png)

作者图片

在构建我们的第一个迭代数值拟合过程之前，我们需要首先绕道通过泰勒展开。

## 2.2: **泰勒展开和二阶近似**

在构建我们的第一个迭代数值拟合过程之前，我们首先需要理解泰勒展开的基础。

![](img/06f1bfb7319815568a6621a8af530817.png)

作者图片

![](img/433cf0c624bf72855c89594de4bdf3ab.png)

作者图片

我们现在准备构建我们的三个迭代数值拟合过程，从牛顿-拉夫森开始。

## **2.3:三次迭代数值拟合过程**

**2.3.1:牛顿-拉夫森**

![](img/61879d0eda9eb2b33136a7676045871b.png)

作者图片

![](img/8c176ad7d446d4c17b571340bd9bd2b7.png)

作者图片

![](img/2c3ffea9581a5ff5e53b6c1761adf1d0.png)

作者图片

![](img/fbd39cdf2b5f119b5c38d0719b358270.png)

作者图片

我们现在准备讨论我们的第二个迭代数值拟合过程费希尔评分，以及它与牛顿-拉夫森的联系。

2.3.2:费希尔得分

将牛顿拉夫森应用于我们在*第 2.1 节*中的例子，我们得到:

![](img/162cfbe6ed6c8e53a8d9626e686aa056.png)

作者图片

有没有办法减轻这种计算负担？这就是费希尔得分发挥作用的地方。

![](img/fb88797c6fc5b8441d3f47495d148c68.png)

作者图片

![](img/26944ebda23fca6024dd970b5e55a2e6.png)

作者图片

在这篇文章的后面，我们将看到在 GLMs 可以以标准形式参数化的情况下，Newton-Raphson 和 Fisher 评分在数学上是等价的。

已经讨论了牛顿-拉夫森和费希尔评分，我们准备讨论我们的最后一个迭代数值拟合程序迭代加权最小二乘法(IRLS)。

**2.3.3:迭代加权最小二乘法(IRLS)**

为了理解我们的最后一个迭代数值拟合过程迭代重加权最小二乘(IRLS)及其与费希尔评分的关系，我们需要快速复习一下加权最小二乘(WLS)估计量。

![](img/ed3b57c15efb93660bcb65effe00861e.png)

作者图片

*(更深入的推导有* [*【加权最小二乘(WLS)*](/generalized-least-squares-gls-mathematical-derivations-intuition-2b7466832c2c)*[*【广义最小二乘(GLS)*](/generalized-least-squares-gls-mathematical-derivations-intuition-2b7466832c2c)*[*【普通最小二乘(OLS)*](/ols-linear-regression-gauss-markov-blue-and-understanding-the-math-453d7cc630a5) *估值器，参见我以前的几篇)***

**![](img/27ac9ff92588dd631b87be301c411fa0.png)**

**作者图片**

**你可能会问…**

**“嗯……那很好……但是这和 GLMs 有什么关系呢？为什么我要让我的费希尔评分算法看起来“有点”像 WLS 估计量呢？这有什么意义？？?"**

**为了理解费希尔得分和 WLS 之间的联系，我们需要一些 GLMs 的历史背景。**

**如果你还记得本系列的第一部分，GLMs 是在 20 世纪 70 年代早期作为一个统一理论发展起来的。随着这一理论的发展，从业者希望找到一种方法，用他们可以在计算机上运行的计算软件将他们的数据拟合到 GLM 模型。嗯，20 世纪 70 年代仍然是计算的相对早期，尤其是科学计算。没有唾手可得的线性代数和数值库(例如 python 中的 numpy)。相反，人们必须从头开始编写他们自己的库。说当时的计算机几乎没有内存和硬盘空间是一种保守的说法；与今天相比，20 世纪 70 年代计算机的内存小得可笑。软件必须小心编写，并且必须在内存方面进行高度优化。那时写软件，尤其是科学计算软件，是很困难的。非常非常困难。**

**然而，在 GLM 理论发表之前，该领域的研究人员和从业者已经编写了计算机软件来拟合加权最小二乘估计量。换句话说，他们已经编写了软件来恢复以下估计量的经验估计值:**

**![](img/aeba036f1bba2186ed98648366fde470.png)**

**作者图片**

**因此，随着 GLM 理论的建立和软件使用费希尔评分将数据拟合到 GLMs 的需要，从业者有了一个想法:**

***“你知道……我们费希尔评分算法中的部分术语看起来很像 WLS 估计量。我们已经编写了解决 WLS 估计量的软件，它似乎工作得很好。那么…如果我们不完全从零开始编写费雪评分软件，而是让我们的费雪评分软件成为我们的 WLS 软件的简单包装函数，会怎么样呢！对于费希尔评分算法的每一个迭代步骤，我们可以重新参数化我们的问题，使其看起来像 WLS 估计量，并调用我们的 WLS 软件返回经验值。”***

**换句话说，在我们的费希尔评分算法的每一个迭代步骤中，我们要重新参数化以下内容:**

**![](img/69a63b0fb6755a489af6e6e07b6b36e2.png)**

**作者图片**

**因此，迭代加权最小二乘法(IRLS)诞生了。术语“重新加权”是指在费希尔评分算法的每个迭代步骤中，我们都使用新的更新权重矩阵。**

**在*第 3 节*中，我们将通过计算实例展示如何将牛顿-拉夫森、费希尔评分和 IRLS 用于规范和非规范 GLMs。然而，首先，在拟牛顿法和梯度下降简短的旁白。**

## **2.4: **略论拟牛顿法和梯度下降法****

**在开始执行 GLMs 的三个主要迭代数值拟合过程之前，我想简单提一下另外两类相关的迭代方法，拟牛顿法和梯度下降法。**

**![](img/0d736d415d50dd32575e92c3de5fff49.png)**

**作者图片**

**![](img/81cd6e0c764dc491036907fe0b371726.png)**

**作者图片**

**![](img/fb74f0c1fb69a021e0ee4a73ec76081c.png)**

**作者图片**

**![](img/7ef44f8c915bf73e7b1875fd55e2a803.png)**

**作者图片**

**![](img/507c5ca2b650caab1e4ecb68f5785818.png)**

**作者图片**

# **3: **实施 GLMs 的装配程序****

**我们现在准备探索如何操作牛顿-拉夫森，费希尔评分，IRLS 为规范和非规范 GLMs。让我们先回顾一下 GLM:**

## **3.1: GLM 复习**

**广义线性模型(GLM)有三个主要部分:**

**![](img/4df1150d04027a70b06a71b49667f3fd.png)**

**作者图片**

**现在让我们来研究一下标准和非标准形式的指数离差分布族的概率密度函数(PDF)的参数化。**

**![](img/81a7e63fb700445409c71efc3593eee3.png)**

**作者图片**

**有关更深入的概述，请参见 GLMs 上的本系列文章的[第一部分。](/generalized-linear-models-a-rigorous-mathematical-formulation-58ac2ec7d9ea)**

## **3.2:拟合程序 form 标准形式**

**回想一下，规范 GLMs 具有以下属性:**

**![](img/edd15f45a77bfd5950480dff0eaf4092.png)**

**作者图片**

**我们现在准备展示如何将牛顿-拉夫森、费希尔评分和 IRLS 用于规范 GLMs:**

****3.2.1:牛顿-拉夫森****

**![](img/286f342cd312b2edbae3ef350b0f9f49.png)**

**作者图片**

**![](img/ccb3d9eb4e30f88cd9bac7329869a2a2.png)**

**作者图片**

**![](img/a04b195bb831fcd2ff82e8a8263edf4d.png)**

**作者图片**

**![](img/cf85ba4b9dbc2f0f3358b5cf9fa15589.png)**

**作者图片**

****3.2.2:费希尔得分****

**![](img/5a52daae5153601239733fe8973c86b8.png)**

**作者图片**

**![](img/bb8bf1fbe872fd786de2a24ab361a2bb.png)**

**作者图片**

****3.2.3:迭代加权最小二乘法(IRLS)****

**![](img/2b962bdb884a59a8eebefef33b24020a.png)**

**作者图片**

**![](img/73e72402dc1d6edba8acca2b156916de.png)**

**作者图片**

**![](img/3cf29a2e3a6a7dd22a18f0301456882a.png)**

**作者图片**

## **3.3:拟合程序——GLM 非标准形式**

**![](img/4e76947ceef785216b65bd21df4dfdea.png)**

**作者图片**

**![](img/3d36b7bd1d24088eb41eb41bb58b76d2.png)**

**作者图片**

**![](img/32101d05ea4d09d7d911761d6d48c9d7.png)**

**作者图片**

**![](img/4d5b080b2e3e62cc11f67b682fa1e9ab.png)**

**作者图片**

**![](img/a8478a4f2b936440022245771854a89e.png)**

**作者图片**

**![](img/06aac4980d066bbc740880de1bc766a2.png)**

**作者图片**

****3.3.1:牛顿-拉夫森****

**![](img/a4d05b97672c6d0cbb9bdd88f4b5b486.png)**

**作者图片**

**![](img/5c4453d2dd55c14fefc00ca4340be732.png)**

**作者图片**

**![](img/27c1ad63824204142d29aa804a72d971.png)**

**作者图片**

**![](img/f5d3e16087b30e26ef3ed5a36295e8a7.png)**

**作者图片**

****3.3.2:费希尔评分****

**![](img/1239950193ade170e8317552af93dd95.png)**

**作者图片**

**![](img/123e9e61fd3c684c9abe9e64977904a9.png)**

**作者图片**

****3.3.3:迭代加权最小二乘法(IRLS)****

**![](img/19f4040505d5780e81ee8691b8688084.png)**

**作者图片**

**![](img/b46f5f9e64979d407898ec4d88399827.png)**

**作者图片**

**![](img/5ef33bc5008ce54e18ab693bb0b6f929.png)**

**作者图片**

**![](img/1b47d6efb6f0eee8c4a84a2b1d02cdac.png)**

**作者图片**

## **3.4:派生算法的总结**

**下面是 3.2 节和 3.3 节推导出的算法的总结**

**![](img/adefa2379cf1401f36df9b1efc6a2825.png)**

**作者图片**

**![](img/768e1821f3d663588dabc21a1c7ce45f.png)**

**作者图片**

# **4:计算模拟**

**以下是两个典型 GLMs 的计算模拟:**

*   **逻辑回归**
*   **泊松回归**

**…和一个非规范的 GLM:**

*   **概率单位回归**

**对于每个回归模型，我们使用牛顿-拉夫森法、费希尔评分法和迭代加权最小二乘法(IRLS)将模型拟合到数据。**

**让我们导入我们需要的库:**

**并指定一个函数来模拟不同的建模集:**

**指定我们需要的激活功能:**

**典型 GLMs 的牛顿-拉夫森、费希尔评分和 IRLS 的函数:**

**非规范 GLMs 的牛顿-拉夫森、费希尔评分和 IRLS 的函数:**

## **4.1:逻辑回归**

**回想一下，对于逻辑回归，我们有:**

**![](img/908aec9f716ba0894abf84b43930de78.png)**

**作者图片**

**现在，让我们模拟我们的逻辑回归，使用牛顿-拉夫森、费希尔评分和 IRLS 拟合我们的模型，并将我们的结果与 python 中 Statsmodels 的内置逻辑回归库进行比较:**

**如我们所见，我们的结果与 Statsmodels 库的结果相同**

## **4.2:泊松回归**

**回想一下，对于泊松回归，我们有:**

**![](img/7167ad074b0a71bb2d7c08ab92afd2a2.png)**

**作者图片**

**让我们模拟泊松回归，使用牛顿-拉夫森、费希尔评分和 IRLS 拟合我们的模型，并将我们的结果与 python 中 Statsmodels 的内置泊松回归库进行比较:**

**同样，我们的结果与来自 Statsmodels 库的结果相同**

## **4.3:概率单位回归**

**对于概率单位回归，我们有:**

**![](img/452c3a1d22e4d8643ec45412c2ae921e.png)**

**作者图片**

**使用:**

**![](img/abf4c823ca4b54e24239ea6d012772b2.png)**

**作者图片**

**![](img/a9328c8cb70b5324943934594c3efc17.png)**

**作者图片**

**让我们模拟我们的概率单位回归，使用牛顿-拉夫森、费希尔评分和 IRLS 拟合我们的模型，并将我们的结果与 python 中 Statsmodels 的内置概率单位回归库进行比较:**

**同样，我们的结果与 Statsmodels 库的结果相同**

**以上计算模拟的完整代码/笔记本，请看下面的 [**github 链接**](https://github.com/atrothman/GLMs_Iterative_Fitting_Techniques) 。**

# **5:总结和结论**

**在本系列的[第一部分中，我们提供了规范和非规范形式的常见 GLMs 的全面的数学概述(带证明)。在这篇关于 GLMs 的第二篇文章中，我们提供了对规范和非规范 GLMs 的三个重要迭代数值拟合过程的严格概述:牛顿-拉夫森法、费希尔评分法和迭代加权最小二乘法(IRLS)。还提供了这些方法的详细计算模拟。](/generalized-linear-models-a-rigorous-mathematical-formulation-58ac2ec7d9ea)**

**在未来的一篇文章中，我们将通过多阶段递归 GLM 模型的镜头来涵盖神经网络的推导。**

**希望以上有见地。正如我在以前的一些文章中提到的，我认为没有足够的人花时间去做这些类型的练习。对我来说，这种基于理论的洞察力让我在实践中更容易使用方法。我个人的目标是鼓励该领域的其他人采取类似的方法。我打算在未来写一些基础作品，所以请随时在 [**LinkedIn**](http://www.linkedin.com/in/andrew-rothman-49739630) 上与我联系，并在 Medium 上 [**关注我的更新！**](https://anr248.medium.com/)**