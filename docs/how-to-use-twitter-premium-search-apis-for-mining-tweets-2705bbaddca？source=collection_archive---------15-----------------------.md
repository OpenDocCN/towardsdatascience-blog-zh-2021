# 如何使用 Twitter 高级搜索 API 来挖掘推文

> 原文：<https://towardsdatascience.com/how-to-use-twitter-premium-search-apis-for-mining-tweets-2705bbaddca?source=collection_archive---------15----------------------->

## 一步一步地展示 Twitter 的高级搜索 API，挖掘历史推文数据用于学术研究

![](img/078db4e7fadc6b0d45617c302973ca5c.png)

亚历山大·沙托夫在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

# 介绍

自然语言处理(NLP)对来自 Twitter 等社交媒体平台的高频数据的重要性正在飞速增长。公司正在与他们的客户进行实时反馈。它被用来收集有关新产品发布的情报，监控客户投诉，并分析营销活动的有效性。它还可以用来衡量人们对政府机构所作政策决定的看法/反应。

Twitter 提供不同的 API 来挖掘推文。有三个级别的访问其 API 来挖掘数据——基本、高级和学术。有了基本和提升的访问权限，人们可以挖掘出一周前的推文。然而，它的学术许可证带有两个高级搜索 API—`search_30_day`和`search_full_archive`，允许搜索日期长达 30 天及以上的推文。此外，学术访问允许使用高级搜索运算符进行查询。我们将在这个博客中了解更多。

对于一个学术研究者来说，没有足够的例子可以让他立即开始他的项目。主要问题是 tweet 返回的 json 的结构根据 tweet 的类型而不同。第二个问题是，如果 tweet 超过 140 个字符的限制，搜索结果中的 tweet 文本通常会被截断。第三，twitter 不会一次获取全部数据，而是通过将数据分散到多个页面来优化其有效负载，默认情况下每个页面包含 100 条推文。悬停在这些页面上构成新的请求，并由 twitter 监控。免费学术访问每月仅提供 250 个请求。

Twitter 开发者资源[1]可以被证明是非常详尽的，但同时也是非常耗时的。该博客旨在通过展示一个简单的 python 片段，帮助研究人员通过高级搜索操作符筛选出历史推文的全文，从而节省他们浏览文档和试验 twitter APIs 的时间、精力和精力，从而为研究人员提供一个良好的开端。

在我们继续之前，我假设读者已经可以使用学术访问权限访问 twitter 开发者帐户。在这个演示中，我将使用`Tweepy`库，它是 Twitter API 的包装器。它减少了我们需要编写的代码行数，从而使我们的工作变得更加容易。我们开始吧。

# 2.工作流程

Twitter APIs 被聪明地设计来减少其服务器上的负载，即请求期间的数据传输。在大多数标准 API 中，默认情况下文本会被截断，因此必须使用`extended`模式来提取 API 的完整文本。然而，在 Twitter V2 高级搜索 API 中，`full_text`属性给出了未删节的原始推文，这通常是研究人员想要的，但它深深嵌入了推文的 json 字典中，该字典在所有推文中不遵循一致的模式。使用这些 API 的第二个问题是搜索结果显示在页面上，就像 Google web search 一样。默认情况下，每个页面提供 100 条推文。为了从后续页面访问更多的 tweets，我们需要执行分页。第三，Twitter 允许在其查询中使用搜索操作符来过滤结果，但是，原始 Twitter APIs 和 Tweepy APIs 的查询格式略有不同。我们将看到如何指定使用逻辑(和/或)操作符来微调搜索结果的查询。总而言之，工作流程如下:

*   如何构建 twitter 搜索 API 来提取所有的推文
*   如何避免截断并获得推文的全文
*   如何进行分页
*   如何在查询中指定逻辑和/或参数

# 3.如何构建 Twitter 搜索 API 来提取所有推文

我们将设置 API 构造函数，并使用作为学术许可一部分的证书进行授权。Twitter 沙盒环境将速率限制为每分钟 30 个请求和每秒 10 个请求。Tweepy API 构造函数提供了提及`wait_on_rate_limit`参数的灵活性，当达到 twitter 速率限制时，该参数会在发送新请求之前等待。

现在可以调用高级搜索 API，但它需要首先在 twitter 开发者帐户中创建沙盒环境。我已经将我的沙盒环境标记为`research`。搜索功能强制要求环境标签和查询参数。可选地，还可以提供`fromDate`和`toDate`字段来按时间过滤搜索结果。请注意，日期字段的格式是“YYYYMMDDHHMM”。推文按时间降序排列，即最新的推文排在最前面。对于沙盒开发环境，查询字段的最大长度限制为 256 个字符。默认情况下，构造函数将获取由 100 条 tweet 组成的第一页结果，如前所述，但是可以通过在非沙盒环境中指定 maxResults 参数来增加它，每页最多 500 条 tweet。

```
tweet_results = api.search_30_day(label='research', query="RBI", fromDate="202111100000", toDate="202111300000")
```

如果你尝试打印`tweet_results`，乍一看会显得胡言乱语。它本质上是 100 个状态对象的列表，每个 tweet 数据被打包成一个状态对象。您还可以使用索引来访问每个 tweet 数据，就像数组和列表一样。它会揭示每条推文的 json 结构。尝试用下面的代码打印第一个 tweet 对象。

```
print(json.dumps(tweet_results[0]._json, indent=4, sort_keys=True))
```

# 4.如何避免截断并获得推文的全文

tweet 的核心结构可以在开发者门户找到[2]。如前所述，搜索查询返回的有效载荷结构根据 tweet 的类型而不同。有四种不同类型的推文，即原始推文、转发推文、回复推文和引用推文[3]。我们将根据 tweets 的 json 结构改变我们的挖掘标准。首先，我们编写一个函数来确定 tweet 的类型。

下一步，我们将编写一个解析函数，从 json 列表中提取其他相关属性，并制作我们自己的定制词典。下面提供了示例代码。

# 5.如何用 Tweepy 分页

Tweepy 使分页变得非常简单。所有需要做的就是用`pages()`方法将 api 搜索封装到 Tweepy 的 Cursor 对象中，该方法将结果分成页面[5]。下一步是遍历所有页面，解析每个页面中的 tweets。在测试您的代码时，建议输入一个小数字作为 pages 的参数，因为它将请求的数量限制在这个数字之内。当需要完整的结果时，可以省略该参数。

或者，也可以使用光标对象通过使用`items()`方法获得状态对象列表，然后可以迭代该列表以提取每个 tweet 的单个元素。在测试您的代码时，建议输入一个小数字作为 items 的参数，因为它将 tweets 的数量限制在这个数字以内。当需要完整的结果时，可以省略该参数。需要注意的是，在这两种方法中，使用仪表板中反映的请求数量将是相同的，因为 twitter 将 100 条推文计算为 1 个请求。

# 6.如何在查询中指定逻辑和/或参数

Twitter 搜索 API 还允许在本质上是字符串对象的查询中嵌入逻辑操作符。在这个字符串中，我们可以使用 AND/OR 操作符连接我们的关键字。这里唯一的问题是 twitter API 搜索规则要以 json 格式放置[6，7]。下面是一些说明性的例子:

1.  query = "\"RBI article\ " "，搜索 API 将呈现与短语`RBI article`完全匹配的推文
2.  query = " " RBI article "或" RBI Bulletin "将呈现包含精确短语`RBI article`或`RBI Bulletin`的推文。
3.  query = "\"RBI\" \"Governor\ " "将呈现包含关键字`RBI`和`Governor`的推文，而不考虑它们出现的顺序。

# 7.结论

在这篇博客中，我讨论了研究人员在使用 twitter 高级搜索 API 时遇到的困难。稀缺的文档将这些问题变成了一场耗时的考验，从而将焦点从最初的研究问题转移到如何使用 twitter APIs 以所需的格式获取有关相关 tweets 的所需信息。我们解决了截断、分页和在查询中使用逻辑运算符的困难，并编写了一个代码，研究人员可以在各自的用例中直接部署该代码。

# 在我们结束之前，

我邀请你和我一起参与这个激动人心的数据科学旅程。关注我的[媒体页](https://skantbksc.medium.com)，探索更多关于数据科学的精彩内容。