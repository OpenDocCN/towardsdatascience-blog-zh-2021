# 预测 Strava Kudos

> 原文：<https://towardsdatascience.com/predicting-strava-kudos-1a4ce7a02053?source=collection_archive---------25----------------------->

一个端到端的数据科学项目，从数据收集到模型部署，旨在根据给定活动的属性预测用户对 Strava 活动的交互。

![](img/c53035d73e56bca234be8197f6d44531.png)

由 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的 [Mael BALLAND](https://unsplash.com/@mael_balland?utm_source=medium&utm_medium=referral) 拍摄的照片

Strava 是用于跟踪人类锻炼的服务，其结合了社交网络类型的特征。它主要用于骑自行车和跑步，重点是使用 GPS 数据。下面是我自己的一个典型的 Strava 帖子，我们可以看到它包含了很多信息:距离，移动时间，速度，海拔，天气，GPS 路线，我和谁一起跑，等等。等。

![](img/aa52ec60202e7d015ecfa3d6825f91da.png)

典型的 Strava 活动帖子(图片由作者提供)

现在，Strava 也是一个社交媒体，每个活动都可以获得 kudos，这相当于其他平台上的赞。鉴于我已经在 Strava 上发布了超过 4000 个活动，这是一个开始一个独特的小数据科学项目的好地方。我的目标是根据活动的属性预测每个活动获得的 kudos 数量。

然而，预测荣誉并不一定是一件容易的事情。在从 Strava 提取的数据点中，平均 Kudos 计数为 38，标准偏差为 24。最小值为 0，最大值为 171。数据中有很多可变性…所以希望我们可以创建一些有用的功能来帮助解释这一点！

![](img/bc779d08b746c3702530165e9a5fbc59.png)

荣誉分布(图片由作者提供)

如果你想快进到最终项目，你可以在这里找到成品[。](http://strava-kudos.herokuapp.com/)

# 数据收集

Strava 有一个功能，允许用户下载他们以前的所有数据，但是，这只能每周进行一次。更好的数据收集解决方案是使用 Strava API，它允许您每 15 分钟发出 100 个请求，每天总共发出 1000 个请求，也就是说，对于我们的预期目标来说，这已经足够了。

使用这个 [API](https://developers.strava.com/docs/reference/) ，我能够快速有效地收集我所有的活动数据。很可爱。这个 API 的另一个好处是，它允许我提取我最近的活动，这样我就可以即时预测 kudos，这是这个项目的最终目标之一。下面是我的 Streamlit 应用程序上的实时 Kudos 预测的 GIF 图。

![](img/31c15c9e31ee58621393e117849a2eea.png)

实时 Kudos 预测(GIF 由作者提供)

如果你对开始使用 Strava API 感兴趣，我强烈推荐你从这篇博文[开始。](https://medium.com/r?url=https%3A%2F%2Ftowardsdatascience.com%2Fusing-the-strava-api-and-pandas-to-explore-your-activity-data-d94901d9bfde)

一旦我设置好了东西并有了所需的密钥，获取最近的活动就很容易了！

从 Strava API 获取最近活动的代码(由作者编写)

只需在这段代码中添加一个 while 循环，就可以轻松获得我的项目所需的所有 Strava 数据！

训练数据集的前 8 个条目(由作者编写)

# 探索性数据分析

一旦我有了所有的数据，议程上的下一件事就是一些 EDA。这包括探索数据、查看分布、相关性和关于不同特征的一般信息。我为此创建的笔记本可以在我的 [Github](https://github.com/jackmleitch/StravaKudos) 页面上找到。

一些值得注意的发现包括:

*   获得的荣誉很大程度上取决于我当时有多少追随者。不幸的是，没有办法看到我在每个时间点有多少追随者，所以我无法根据追随者的数量来衡量荣誉。因此，我只能使用我最近的 1125 次活动(从 2019 年 12 月至今)来训练我的模型，因为在此期间，kudos 保持了相当的一致性。

![](img/fc169fb7bb74d8338df333fb4335d467.png)

保留和删除的数据点(图片由作者提供)

*   发现目标变量(Kudos)向右倾斜(也是双峰的),并且有一些超过~100 的极值。当使用某些模型时，例如线性回归，希望在目标变量中看到更多的正态分布。因此，可以使用 BoxCox 变换来查看目标变量中更“正常”的分布(例如，可以通过绘制 q-q 图来检查正态性)。
*   使用[隔离森林模型](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html)来检测异常值，在 800 个训练点中，发现了 17 个异常值。经过进一步调查，这些主要是活动上传，最初设置为私人，但后来切换到公共。这意味着其他用户无法看到该活动或与之互动。这些已从训练集中删除。
*   距离、移动时间和平均速度 mpk 等特征似乎与 kudos count 具有相似的分布。这在查看相关矩阵时得到了证实。
*   照片计数功能在每个非零类别中只有几个不同的数据点，因此我们可以将其更改为包含照片/没有照片的二元功能。
*   锻炼类型似乎与荣誉密切相关，然而，锻炼类型 1(比赛)的数据点并不多。直觉上，我也相信比赛通常会获得更多的荣誉。 [SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html) 因此被用于对该健身程序类型进行过采样，以增强该功能的预测能力，后来发现这降低了 RMSE。
*   通过观察活动之间的时间分布，发现其他跑步快速跟进的跑步往往比当天唯一活动的跑步获得的荣誉少。除此之外，一天中最长的活动往往比当天的其他活动获得更多的荣誉。

# 预处理

## 培训、测试和交叉验证

我首先需要将数据集分成训练集和测试集。我使用 80/20 分割，因为我的数据包含日期，所以我只使用最近 20%的数据作为测试集。我不想随机打乱数据集，因为我创建了一些基于时间的要素。

拥有一个好的交叉验证方案极其重要，在该方案中，验证数据代表训练和真实世界的数据，因为它使您构建的模型具有高度的可推广性。现在，因为我只有少量的训练样本，同时拥有验证集和测试集是不允许的。因此，在训练集上使用交叉验证来模拟验证集。

我使用 Sklearn 的 [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) 将训练集分成 5 份，其中[斯特奇法则](https://www.statology.org/sturges-rule/)用于计算适当的箱数。

创建分层 K 倍交叉验证的代码(由作者编写)

使用这种交叉验证方案，我能够自信地比较不同的模型来选择最有希望的模型，而不用担心验证集过拟合。该方案也用于调节有希望的模型的超参数(尽管在超参数调节之前折叠被重新洗牌)。值得注意的是，在测试集上对模型进行评估的唯一一次是在项目结束时，当时我想获得真实性能的真实度量。

## 缺少值

数据集中没有大量的缺失值，大多数缺失值来自于对 Strava 来说相当新的特性/我不经常使用的特性。例如，workout_type 功能并不总是有“种族”选项(事实证明它有很强的预测能力！).在输入缺失值之前，首先调查缺失值并尝试找出它们缺失的原因总是非常重要的，这可能很重要！

经过一些检查后，我手动输入了一些缺少的值，因为我认为这非常重要，而且一些旧数据没有标签。我选择手动输入值，因为任何简单的插补技术都会将所有缺失值分配到默认的“简单运行”Strava 类别中。也考虑了 KNN 估算，但是没有很多未标记的数据点，所以手动输入更快。

启发式函数也用于填充标题包含比赛位置的活动，例如第 10 或第 1，因为这些活动显然是比赛。这样做是因为种族似乎总是对荣誉有很大的影响。

对整个数据集使用的一般插补方案是:

*   分类特征中的任何缺失值都被赋予一个新的类别“NONE”——在处理缺失类别时，这似乎在大多数情况下都很有效。
*   使用中值策略对数字要素中所有缺失的值进行估算(也尝试了平均值，但中值效果更好)。

## 其他预处理

其他数据准备步骤包括:删除不是 run 的活动，删除没有 Kudos 的活动(主要是因为 run 本来是私有的，然后切换到公共的)，格式化日期时间信息。

# 特征工程

特征工程是建立一个好的机器学习模型的最关键的部分之一。如果我们有有用的功能，模型会表现得更好。

## 基于时间的特征

我们有每个活动的日期和时间数据，所以我们可以很容易地制作一些琐碎的基于时间的特性。这些特征中的一些包括年、年中的星期、月、星期几、一天中的时间、周末等。

从经验来看，我也知道我每天在 Strava 上发布的活动越多，我得到的赞誉就越少，所以我可以试着将这一点融入到一些功能中。我做了一些特征来概括这个:

*   max_run (binary) —该活动是当天距离最长的活动吗？
*   run_per_day (ordinal) —当天完成的总活动数。

我来自英国，但我目前在爱达荷州博伊西学习，所以我的大多数朋友/粉丝都来自英国。为了解释这一点，我制作了一个二进制功能“is_uk_awake ”,用于检查英国在上传活动时是否处于唤醒状态。我通常发现在这个时间窗口之外发布一个活动会导致更少的荣誉。

## 其他功能

*   与使用自定义名称的跑步相比，使用默认名称(如“下午跑步”)的跑步获得的互动较少。这样就创建了一个二进制特征来检查运行是否被命名。
*   我一直有一种直觉，有着非常漂亮的 GPS 痕迹的跑步比没有的跑步更容易受到关注。为了将这一点封装到一个功能中，我使用跑步 GPS 追踪来测试跑步循环所包围的区域(来回跑步将返回值 0)。我的想法是，大圈圈比小圈圈或来回跑获得更多的荣誉。
*   添加了一些其他功能，可以在我在 Github 上的代码中找到。

## 特征编码

One-hot-encoding 用于对分类特征进行编码，而 ordinal encoding 用于对序数特征进行编码(分类特征，其中顺序意味着某些东西)。

锻炼类型的功能似乎与预测能力斗争，即使我知道它是一个非常有用和相关的功能，它可能与类别的不均匀分布有关。所以为了解决这个问题，我使用了目标编码。我们需要非常小心，因为这可能会使模型过拟合。目标编码是一种将给定特性中的每个类别映射到其平均目标值的技术，但这需要始终以交叉验证的方式完成！

针对编码特性的代码(由作者编写)

## 特征缩放

最后，我们需要考虑伸缩性。根据经验，当我们使用 K.N.N 等计算距离的模型或线性回归等假设正态性的模型时，我们需要调整数值特征。通常，我们要么使用[最小-最大缩放](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)要么使用[标准化](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)，要想知道使用哪一种，我们只需同时尝试这两种方法，看看哪一种能产生最佳性能。然而，基于树的模型不是基于距离的，并且可以处理变化范围的特征，因此不需要缩放。

# 数据建模

## 初始模型选择

在这一步中，我构建了几个不同的候选模型，并比较了不同的度量标准，以确定哪一个是部署的最佳模型。使用的模型性能和特征保存在 CSV 文件中，以帮助跟踪哪个模型的性能最好。在比较模型时，以交叉验证的方式进行训练和评估非常重要！

我使用的训练脚本如下所示(注意:一些东西被移除去杂乱，例如，目标编码等。).

测试不同模型的代码(由作者编写)

一些入围的表现不错的车型有: [XGBoost](https://xgboost.readthedocs.io/en/latest/python/python_api.html) 、 [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) 、 [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) 。这些模型然后被带到特征选择阶段。

## 特征选择

然后进行特征选择，以帮助降低数据集的维度，希望这能创建一个更通用的模型，我们都听说过[维度的诅咒](/the-curse-of-dimensionality-50dc6e49aa1e)。

不同的特征选择技术用于不同的模型。例如，我们不需要为套索模型做太多的选择。当试图最小化成本函数时，Lasso 回归将自动选择那些有用的要素，丢弃无用或冗余的要素。因此，我们需要做的就是移除系数等于零的特征。

对于基于树的模型，最终方法使用了 [Shapley 值](/a-novel-approach-to-feature-importance-shapley-additive-explanations-d18af30fc21b)和内置特征重要性值的组合。尽管如此，在从基于树的模型中查看特性重要性时需要小心，您可以在这里[阅读更多相关信息](/be-careful-when-interpreting-your-features-importance-in-xgboost-6e16132588e7)。

PCA 也被测试来帮助对抗维数，但是它没有改善模型性能或泛化能力。一个原因可能是当占方差的 90%时，特征空间仅减少了 2。

选择的最终特征是:距离、平均速度、最大跑步(该跑步是一天中最长的跑步吗)、锻炼类型(+目标编码)、总海拔增量、运动时间、痛苦分数、每天跑步(当天跑步的次数)、最大速度、跑步区域(GPS 跟踪所包围的区域)和英国清醒(发布活动时英国清醒吗？).

![](img/c0b42ea6dfa8ba7344d2f0432a95b6f3.png)

SHAP 特色重要性(图片由作者提供)

## 超参数调谐

Optuna 用于调整所有三个入围的模型，这是一个开源框架，非常容易使用，非常好。特别地，树结构 Parzen 估计器(TPE)被用于对参数空间进行采样，其使用贝叶斯推理来构建代理模型，并且可以使用[期望改进](http://krasserm.github.io/2018/03/21/bayesian-optimization/#:~:text=Expected%20improvement%20is%20defined%20as,if%20%CF%83(x)%3D0)来选择下一个超参数。一个很好的关于用 Optuna 调整超参数的教程可以在[这里](https://medium.com/subex-ai-labs/efficient-hyperparameter-optimization-for-xgboost-model-using-optuna-3ee9a02566b1)找到。

我用来调优 XGB 模型的代码如下所示。

用 Optuna 调优超参数的代码(由作者编写)

下面的优化历史图显示了 TPE 采样器收敛到最佳超参数的速度。另外两个图分别显示了每个超参数和高维参数关系的重要性。

![](img/b56543127696c4dd21d967a540dc9c8c.png)

XGB 型号的 Optuna 优化历史(图片由作者提供)

![](img/4ea2cfa78efb1177280a0c464560c259.png)![](img/a4bc04f5fad096d42e08d21d48213c89.png)

XGB 模型的超参数重要性和平行坐标图(图片由作者提供)

## 型号选择

在执行超参数调优后，发现 XGB 模型始终优于其他两个入围模型。如下表所示，超过 5 次折叠的平均 RMSE 较低。还发现误差的方差较低。由此，我得出结论，根据我所拥有的数据，XGB 模型更有可能更好地概括未见过的数据。

包含模型分数的表格(由作者编写)

然后，使用之前找到的超参数在**整个**训练数据集上训练最终的 XGB 模型。

令人欣慰的是，当这三个模型用于在测试数据集上进行预测时，XGB 模型的表现优于其他两个模型。免责声明:这是(并且需要)在模型选择之后完成的，你不想过度适应测试集！XGB、RF 和 Lasso 的测试集得分分别为 9.78、11.83 和 10.68。

# 部署

该模型以及其他一些特性是使用 Streamlit 和 Heroku 部署的。关于 Streamlit 和 Heroku 的教程可以在[这里](/build-your-first-interactive-data-science-web-app-with-streamlit-d4892cbe4792)和[这里](/a-quick-tutorial-on-how-to-deploy-your-streamlit-app-to-heroku-874e1250dadd)找到。建立了一个界面，你可以在其中根据我的实时 Strava 数据进行预测，探索模型的可解释性，并探索数据集。这个应用程序可以在这里找到(可能需要一分钟左右才能启动，抱歉)。

# 模型可解释性

这个项目的最后一部分是研究这个模型，尝试看看，一般来说，是什么属性导致活动获得更多/更少的荣誉。

众所周知，解释 XGBoost 模型是一项艰巨的任务，但是结合坚实的理论基础和快速实用的算法，SHAP 值是一个非常强大的工具，可以自信地解释基于树的模型。

最终要素的平均 SHAP 值如下所示。

![](img/cc155bd26d34949a2b319b64a92044eb.png)

平均 SHAP 值(图片由作者提供)

我们可以看到，距离功能实际上是最重要的，其次是 max_run 功能(这是我创建的一个功能，非常值得一看！).因为 SHAP 为我们的每一项活动提供了个性化的解释，所以我们能做的不仅仅是做一个条形图。我们可以看到每个特征如何影响最终的 Kudos 值:

![](img/4571ac146c876cfd25e8dd16795df368.png)

特征对模型输出的影响(图片由作者提供)

该图中的颜色代表特征值，红色表示高，蓝色表示低。所以我们可以看到，跑得越长越快获得的荣誉越多。更多的努力(更高的心率和痛苦分数)也会带来更高的声望。另一方面，轻松跑比锻炼、长跑和赛跑获得的荣誉少。

# 结束语

就这样，一个独特而成功的数据科学项目完成了。嗯，有点…仅仅因为我们已经建立了一个好的模型并不意味着这个模型总是好的，它可能会漂移。

模型漂移是指由于数据的变化以及输入和输出变量之间的关系而导致的模型性能退化。因此，重要的是检查每一个，然后看看模型是否仍然在一个适当的水平上执行。也许这是未来博客的主题。

感谢阅读，我希望你喜欢它。如果您有任何意见或问题，请随时在评论中或通过[电子邮件](mailto:jackmleitch@gmail.com)联系我们。

如果你做到了这一步，这里有一些你可能感兴趣的我的其他故事…

[](/building-a-recipe-recommendation-system-297c229dda7b) [## 建立食谱推荐系统

### 使用 Word2Vec、Scikit-Learn 和 Streamlit

towardsdatascience.com](/building-a-recipe-recommendation-system-297c229dda7b) [](/organizing-machine-learning-projects-e4f86f9fdd9c) [## 组织机器学习项目

### 组织机器学习项目的实用指南

towardsdatascience.com](/organizing-machine-learning-projects-e4f86f9fdd9c)