# 在生产中部署人工智能和人工智能模型的成本更高——人工智能碳足迹

> 原文：<https://towardsdatascience.com/theres-greater-cost-of-deploying-ai-and-ml-models-in-production-the-ai-carbon-footprint-49192d5d69d3?source=collection_archive---------43----------------------->

## 将 AI 和 ML 模型部署到生产中的碳足迹

![](img/05de457600dabbe8bedc202e934eaaa9.png)

[图像来源](https://elements.envato.com/robot-holding-earth-globe-in-hand-blue-panorama-ba-52C96QK)

去年年底，我们目睹了一个震惊科技界的故事，并引发了围绕人工智能和人工智能伦理的热烈讨论。也就是说，谷歌道德人工智能团队的前联合负责人蒂姆尼特·格布鲁(Timnit Gebru)与人合著了一篇论文，导致她离开了谷歌。论文中概述的核心风险之一是大型语言模型的开发和部署的人工智能碳足迹。

这篇题为“论随机鹦鹉的危险:语言模型会不会太大？”《麻省理工科技评论》(MIT Technology Reviews)的[写道，将一些与谷歌研究的核心线相关的不方便的事实摆在面前，并提出了可能引起谷歌担忧的关于人工智能的问题。在其重点中，该论文列出了越来越大的语言模型的风险，如 BERT 及其变体，GPT-2/3，其他最近在惊人数量的文本数据上训练的 Switch-C-AI 模型，以及](https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/)[中国的“悟道”AI 模型](https://thenextweb.com/news/china-wu-dao-ai-10x-bigger-than-gpt-3/amp)，它比 GPT-3 大 10 倍。

这篇论文概述的大型语言模型的四个主要风险之一是将人工智能模型部署到生产中的关键风险，这似乎很少在雄心勃勃的人工智能计划中得到第二次考虑——环境和财务成本。

![](img/582475094cc848127c97fd8cbc517b94.png)

[图像来源](https://elements.envato.com/working-on-a-laptop-SXQQ7W4)

Gebru 的论文强调了该行业的苦涩事实:今天每个人都在谈论将人工智能模型部署到生产中，但没有人或没有足够多的人谈论计算能力和维护生产中的 ML 模型的成本。训练人工智能模型消耗大量计算机处理能力，因此也消耗大量电力。此外，随着数据量呈指数级增长，人工智能的碳足迹也在扩大，给环境带来了巨大负担，并影响了气候变化。

难怪人工智能行业经常被与石油和天然气行业相提并论，因为它们在高价值、高利润率和环境影响方面有着惊人的相似之处。

在论文中，Gebru 和她的同事引用了 Emma Strubell 关于大型语言模型的碳排放和财务成本的另一篇[论文，该论文揭示了大型语言模型的能耗和人工智能碳足迹自 2017 年以来一直在爆炸，因为模型被馈送了越来越多的数据。而](https://arxiv.org/abs/1906.02243)[人类世杂志](https://www.anthropocenemagazine.org/2020/11/time-to-talk-about-carbon-footprint-artificial-intelligence/)引用的另一项研究发现，深度学习中使用的计算能力在 2012 年至 2018 年间增长了 30 万倍。如果这种增长速度继续下去，人工智能可能会对气候产生严重影响。

在为训练几种常见的大型人工智能模型进行生命周期评估后，来自马萨诸塞州大学的斯特鲁贝尔和她的同事发现，这个过程可以**排放超过 626，000 磅的二氧化碳当量** - [**几乎是美国普通汽车**](https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/) 一生排放量的五倍(这还包括汽车本身的制造)。

更具体地说，斯特鲁贝尔的论文研究了自然语言处理(NLP)的模型训练过程 Transformer、ELMo、BERT 和 GPT-2——这些模型在过去几年中已经达到了许多突破性的性能里程碑。首先，该研究包括在单个 GPU 上训练每个模型长达一天，以测量其功耗。然后，研究人员使用模型原始文件中列出的训练小时数来计算整个训练过程中消耗的总能量。

值得注意的是，该研究包括对每个模型进行一次训练，而在实践中，模型通常在研发过程中进行多次训练。Strubell 和她的同事发现，训练的计算和环境成本与模型大小成比例增长。结果显示，最昂贵的型号是 BERT，其碳足迹约为 1400 磅二氧化碳当量，接近一个人往返横跨美国的航班。据《人类世界》杂志介绍，最新一代的深度学习模型 GPT-3 旨在产生类似人类的语言，它需要的能量相当于 126 个丹麦家庭一年的消耗量，产生的碳足迹相当于一次培训课程乘坐汽车行驶 70 万公里。

尽管专家们对人工智能的环境影响有一些假设，但没有人想到实际问题会如此严重。

![](img/ad9329799a78ce71384d6e76d1e86621.png)

[图像来源](https://elements.envato.com/woman-managing-server-in-data-center-NBXDVF4)

# 人工智能在气候变化中的双重作用

另一方面，人工智能可以被部署来减少气候变化的影响，例如创建[智能电网设计](https://hyperight.com/creating-smart-energy-systems-with-data-analytics-iot-and-ml/)，[开发低排放基础设施](https://hyperight.com/ai-in-the-energy-sector-how-neural-networks-can-improve-plant-operations/)，以及模拟气候变化预测。

毫无疑问，人工智能的命运是在气候变化中扮演双重角色，但这并不意味着不能采取行动来减轻或减少人工智能的碳足迹。随着部署人工智能模型的碳排放和电力成本问题获得更多关注，它吸引了重要利益相关者的注意。例如，2019 年 9 月，数千人走上街头，加入[全球气候罢工](https://medium.com/@AINowInstitute/ai-and-climate-change-how-theyre-connected-and-what-we-can-do-about-it-6aa8d0f5b32c)，以揭示大科技与化石燃料公司的合作。另一个例子是[技术工人联盟](https://techworkerscoalition.org/climate-strike/)联合亚马逊、谷歌、微软、脸书、推特的员工举行游行，要求他们的雇主承诺到 2030 年将排放量减少到零，停止与化石燃料公司的合同，停止资助气候变化否认者，并停止剥削气候难民和前线社区，自然报道。

![](img/1ff821f20f80b9a2654e6861a3eae272.png)

[图像来源](https://elements.envato.com/robots-hand-typing-on-keyboard-W8CUP4S)

# 量化碳排放

采取主动行动减少人工智能的碳足迹和气候影响的挑战是如何量化能源消耗和碳排放，以及使这些信息透明。《自然》强调，部分问题在于缺乏衡量标准，以及在社会认知中构建复杂人工智能和人工智能系统的成本模糊不清。

为了缩小量化的挑战，研究人员已经在进行一项研究，量化机器学习的碳排放。研究人员发现，在训练神经网络模型期间获得的排放与训练服务器的位置及其使用的能源网格、训练程序的长度以及进行训练的硬件有关。为了帮助其他研究人员和从业者，他们创建了一个[排放计算器](https://mlco2.github.io/impact/)来估计训练 ML 模型的能源使用和相关的环境影响。

除了计算器，其中一名研究人员 Alexandra Luccioni 建议采取几项行动来减少人工智能的碳足迹。“使用可再生能源电网来训练神经网络是可以做出的最大改变。它可以使完全可再生电网和完全燃煤电网之间的排放量相差 40 倍，”Luccioni 说。

然而，为了减少人工智能的污染，它需要成为更多的主流对话，包括研究人员对他们的研究产生了多少二氧化碳保持透明，并重用模型，而不是从头开始训练它们，并使用更高效的 GPU。

![](img/ab5699b423fd63c17751283dedc09d2c.png)

[图片来源](https://elements.envato.com/cheerful-female-scientist-in-data-center-4EXR7YV)

斯坦福大学的另一组研究人员也试图跟踪并获得人工智能碳排放量的精确测量值。首先，他们测量了一个特定人工智能模型的功耗，理清了每个训练会话，并考虑了共享开销功能的功耗，如数据存储和冷却。然后，他们将电力消耗转化为碳排放，这取决于产生电力的可再生燃料和化石燃料的混合。

斯坦福大学的研究表明，人工智能培训课程的地点可能会对其碳排放产生很大影响。例如，斯坦福大学证实，研究人员估计，在主要依赖页岩油的爱沙尼亚举行一次会议，产生的碳量是在主要依赖水力发电的魁北克举行的会议的 30 倍。

然而，要完全掌握人工智能的碳影响，仅仅审视训练大型模型所产生的计算成本是不够的。量化碳排放的一个巨大障碍是，科技公司不愿分享有关其能源组合的数据，以及它们在建设全球数据中心方面无可争议的主导地位。

一个可能的解决方案是向云提供商提供税收激励，让他们在有水电或太阳能的地方开设数据中心，而不是在电网主要以煤为燃料的地区。Alexandra Luccioni 说，这将对减少碳足迹产生巨大影响。

![](img/cc38124b224166341cebe1dad9194e9a.png)

[图像来源](https://elements.envato.com/programmer-working-in-a-software-developing-compan-CXX9WMX)

# 把红色人工智能变成绿色人工智能

近年来，对人工智能创新和性能的更大需求伴随着更强大的计算机能力。使用大规模计算能力来实现更好结果的趋势被命名为“红色人工智能”(red AI)，这是罗伊·施瓦茨(Roy Schwartz)在 2019 年与人合著的一篇论文中引入的一个术语。

Red AI 展示了这样一种实践，即为了实现性能的线性增长，需要一个指数级更大的模型，这可能会增加训练数据的数量或实验的数量，从而增加计算成本，并因此增加碳排放。更糟糕的是，Schwartz 得出结论，他分析的绝大多数论文都将准确性置于效率之上，属于“红色人工智能”类别。

施瓦茨的研究发现，有三个因素将人工智能研究归类为红色:

*   在单个示例上执行模型的成本；
*   训练数据集的大小，它控制模型执行的次数；和
*   超参数实验的次数，控制模型训练的次数。

与此相反，施瓦茨和他的同事倡导“绿色人工智能”，他们将其定义为“在不增加计算成本的情况下产生新结果的人工智能研究，并在理想情况下降低计算成本”，与红色人工智能相反，《自然》肯定了这一点。

至于研究人员可以采取哪些具体行动来提高人工智能的效率和可持续性，哥本哈根能源效率中心表示，环境可持续性应被视为负责任地开发和应用人工智能的原则之一。

该中心负责人加布里埃拉普拉塔迪亚斯(Gabriela Prata Dias)和项目官员小王(Xiao Wang)建议采取几个步骤，实施更清洁、更环保的人工智能实践。

1.  绿色人工智能的定义需要对行业中所有相关的利益相关者都是可操作的，而不是对大多数技术专家来说是一个抽象的概念。
2.  应制定环境标准，以确保减轻环境影响，并可引入绿色人工智能认证，以促进绿色人工智能发展的行业进程。
3.  应该创建一个实用的行业框架和指南，支持人工智能技术的绿色采购，这将支持使用和部署人工智能技术的组织和公司寻找环境友好的人工智能实践。
4.  政府应该考虑建立监管框架和立法的长期影响，这些框架和立法将从法律上解决人工智能发展的透明度和可持续性问题。

[建立数据中心](https://hyperight.com/cloudheat-and-vattenfall-to-provide-environmentally-friendly-cloud-computing-resources/)也是最大限度减少人工智能碳足迹的伟大解决方案，废热被重新部署回电网。但主导市场的企业也应该认真考虑他们选择的数据中心所在地的能源组合。此外，还需要适当的制衡，包括法规，以保留对这些基础设施的某种形式的地方机构，Roel Dobbe 为自然反映。

在更微观的层面上，清洁能源发电公司 Bharat Light & Power (BLP)负责人工智能和人工智能项目的人工智能科学家 Deepika Sandeep 建议明智地利用深度学习。由于训练是消耗大量计算能力的阶段，因此导致更高的碳足迹，Sandeep 说他们已经最小化了他们的训练周期。当模型投入生产时，他们每三到六个月进行一次再培训。最后，她指出，并非所有问题都需要深度神经网络和深度学习架构。相反，选择计算密集型程度较低的人工智能可能会对我们的环境大有帮助。

*原载于 2021 年 6 月 8 日*[*【https://hyperight.com】*](https://hyperight.com/theres-greater-cost-of-deploying-ai-and-ml-models-in-production-the-ai-carbon-footprint/)*。*