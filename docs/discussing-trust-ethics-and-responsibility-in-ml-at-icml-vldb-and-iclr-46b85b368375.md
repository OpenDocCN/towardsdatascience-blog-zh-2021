# 在 ICML、VLDB 和 ICLR 讨论 ML 中的信任、道德和责任

> 原文：<https://towardsdatascience.com/discussing-trust-ethics-and-responsibility-in-ml-at-icml-vldb-and-iclr-46b85b368375?source=collection_archive---------48----------------------->

## 随着人工智能研究中的道德和责任问题开始在全球人工智能社区中引起共鸣，我们来看看今年致力于这项事业的一些研讨会。

![](img/b3d004744c71ed60a17233ef7be9239d.png)

由[安迪·凯利](https://unsplash.com/@askkell?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄

人工智能研究和相关讨论正在如火如荼地进行——这对任何人来说都不奇怪。另一方面,“负责任的人工智能”的说辞还有待改进。根据去年的一项调查，目前只有 25%的公司认为无偏见的人工智能是一个有价值的目标。大型科技公司已经采取措施来改变这种状况，但总的来说，私营部门还没有把负责任的人工智能作为优先事项。

与此同时，当你申请银行贷款时，通常是[机器根据交叉引用年龄、性别、邮政编码和语言等因素的算法来决定你是被批准还是被拒绝](https://www.nature.com/articles/s41599-020-0501-9.pdf)。许多工作申请现在也是这样评估的。当你进入一辆现代汽车，语音识别被使用，你被理解的程度(或者根本不被理解)取决于你的口音。自然，这些因素引起了对 ML 模型如何构建和实现的合理关注。

一些世界领导人非常清楚受控和良好维护的人工智能实践的重要性。例如，去年，欧洲议会发表了一份 100 页的综合报告，内容是关于与不受控制的人工智能发展相关的潜在问题。WEF 和经合组织也公开反对黑箱算法和不道德的数据使用。

显然，ML 科学家今天从事和监督的研究有着深远的影响。这种发展必须为透明管道留出空间，以适应公平和道德的决策，避免歧视和不公正。或者至少没有损坏的数据——这将是第一个危险信号，接下来会有更多的麻烦。

世界各地的许多 ML 研讨会和会议已经开始定期关注这些关键问题，希望有所作为。让我们来看看今年最有趣的三个例子。

**→负责任的人工智能:对公平性、可解释性、安全性、健壮性和超越性之间的实际限制和权衡的跨学科视角**

作为今年 ICLR 会议的一部分，5 月 7 日举行了一次跨学科研讨会。该研讨会聚集了各个人工智能子领域的专家，从学术界和商业到政府-包括研究人员和从业人员。目的是从公平性、安全性和可解释性的角度评估 ML 管道。通过一系列谈话，该活动提出了反映在道德和法律准则和实践中的透明度和偏见(黑盒算法)问题，其中包括刑事司法、医学和教育。

**演讲者**

所有的谈话都被记录下来，可以在[这里](https://iclr.cc/virtual/2021/workshop/2132)找到。

📣这篇题为“负责任的解释:仅有良好的意愿是不够的”的演讲是由谷歌大脑的科学家贝金博士发表的。金从社会责任的角度提出了她对曼梯·里未来的看法。她展示了一系列作品，并重新审视了可解释 ML 中的目标和方法。

📣下一个演讲的题目是“作为一名社会科学家与计算机科学家一起工作的挑战和机遇”，由南加州大学的副教授埃里克·赖斯博士主讲。Eric 讨论了人工智能的当代研究，分享了他对人工智能驱动的干预计划的见解，并介绍了他对无家可归的青少年进行艾滋病毒预防干预的 3 项主要研究结果。

📣另一个题为“创造人们可以使用的模型:来自健康应用的经验”的演讲是由哈佛大学副教授约翰·l·勒布和 T2 的压轴博士多希-维勒兹做的。Finale 讨论了人类受试者实验，这些实验测试了旨在促进人工智能和临床医生在抗抑郁治疗背景下的交互的界面。她揭示了临床医生提出的最常见的改进要求，以及他们对正确和不正确的人工智能建议的反应。

**关于 ICLR**

学习表征国际会议(ICLR)是每年春天举行的国际 ML 会议。第一届 ICLR 会议于 2013 年举行，自那以来已经成为计算机科学家的主要聚会。今年有近 3000 篇论文提交，30%的接受率，今天大会被认为是人工智能和人工智能领域的前三大全球活动。

**→规模化众包数据管理中的信任、道德和卓越**

作为 VLDB 今年第 47 期的一部分，一个群体科学研讨会将在会议的最后一天，即 8 月 20 日举行。该研讨会名为“大规模众包数据管理中的信任、道德和卓越”，将涵盖数据标签众包方法的三个主要问题:大规模数据卓越、人群-人工智能相互作用以及信任和道德。

在研讨会期间，三位主旨发言人将考察众包在大规模研究中的作用，重点是众包工作者的福利和注释数据的可信度。

**扬声器**

📣题为“计算与组织”的第一个研讨会演讲由获奖作者、斯坦福大学副教授迈克尔·伯恩斯坦博士主讲。迈克尔将研究工作和在线平台的未来。他将讨论未来如何组织工作，以及当前的基础设施如何导致权利被剥夺和异化。然后，他将从工程和设计的角度以及政策的角度描述应对这些负面结果的可能对策。

📣第二个演讲的题目是“健康字节:培育群体工作的可持续未来”，由荷兰代尔夫特理工大学助理教授 Ujwal Gadiraju 博士主讲。虽然大多数与众包市场相关的问题和解决方案主要集中在数据质量上，但加迪拉朱博士将研究该领域鲜为人知的问题——大众工作者的福祉。通过使用 MTurk 和 perspective 作为例子，研究人员将从那些完成任务的人的角度剖析微任务众包，包括他们的薪酬和身心健康。将讨论管理众包的合同法的必要性。

📣题为“数字社区驱动的众包”系列的最后一个演讲由[Wuraola oye wus](https://www.datasciencenigeria.org/wuraola-oyewusi/)主讲，他是尼日利亚*数据科学*的研究和创新负责人。演讲者将提供她对众包“人性化”方面的见解，即众包工作者不仅可以与众包平台互动，还可以在全球和区域社区内互动。将讨论众包背景下人与人之间的学习和反馈，并提供新的员工培训模式。

**关于 VLDB**

成立于 1975 年的*超大型数据库国际会议* (VLDB)是致力于数据库管理的研究人员和开发人员最重要的年度聚会之一。由美国 VLDB 基金会组织，每年在不同的国家举行，备受期待的 2021 年 VLDB 奥运会将于 8 月 16 日至 20 日在丹麦哥本哈根举行。

**→社会责任 ML**

作为 ICML 今年第 38 期的一部分，一个虚拟研讨会将于 7 月 24 日举行。该研讨会将汇集理论和应用研究人员，目的是讨论如何建立对社会负责的 ML 管道。在其他主题中，将提出易受安全和隐私攻击、数据泄露以及种族和性别偏见等问题。该研讨会将讨论缺乏透明度的问题，以及它如何导致现实生活中故意或意外的数据扰动。

**关于 ICML**

机器学习国际会议(ICML)是人工智能和人工智能领域的领先全球会议。首次于 1980 年在匹兹堡举行，这一年度活动致力于统计和数据科学，重点是机器视觉，计算生物学，语音识别和机器人技术。这是目前世界上发展最快的人工智能聚会之一。今年的会议日期是 7 月 18 日至 24 日。

**主要外卖**

随着人工智能研究的进展，道德和公平的问题变得日益重要。对透明和建造良好的 ML 管道的需求是这种日益增长的关注的中心。目标是确保新兴技术的明显优势不会被不负责任的人工智能开发带来的问题所掩盖。本文中提到的研讨会详细研究了这些伦理问题，并提供了一些解决方案。