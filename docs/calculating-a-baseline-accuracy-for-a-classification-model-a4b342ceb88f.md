# 为分类模型选择基线精度

> 原文：<https://towardsdatascience.com/calculating-a-baseline-accuracy-for-a-classification-model-a4b342ceb88f?source=collection_archive---------8----------------------->

## 选择一个简单的基线精度来证明您的分类模型在某个问题上有技巧

![](img/809f318b6e391a9338f367f9324a7691.png)

罗伯特·阿纳奇在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

当你评估一个新的机器学习模型，并最终得到一个准确度数字或其他指标时，你需要知道它是否有意义。特别是在不平衡的分类模型中，看起来你的模型并不比猜测好多少。什么样的精度才足以称你的模型有用？

这篇文章只是为了展示你的模型的简单的基线准确性，我发现这很有用。

# 问题是

我创建了一个选举模型，使用经济指标预测了美国所有 3200 多个县(民主党或共和党)的投票习惯。该模型的准确率为 86%。这听起来很棒，直到你意识到美国 84%的县都投票给共和党。这些县碰巧更小，更农村，所以有更多。像许多数据集一样，我有明显的阶级不平衡。

你可以简单地预测所有的县都是共和党的，准确率为 84%。我的模型真的仅仅比猜测每个县的共和党好一点点吗？

# 零速率分类器

我们刚刚描述的模型基线有一个名字。

> ZeroR(或零比率)分类器总是分类到最大的类，换句话说，只是平凡地预测最频繁的类。对于一个两种结果的模型来说，只是随波逐流往往是正确的。

总是选择多数组(ZeroR 分类器)作为基线是有见地的，并且是任何分类模型都应该选择的。对于一个机器学习算法来说，要证明它在某个问题上有技巧，它必须达到比这个零值更好的精度。

对于高度不平衡的问题(如投票分类问题)，一个比 ZeroR 稍高一点的模型精度可能是非常重要的。不管怎样，你的模型必须比 ZeroR 更好才能被认为对问题有用。

# 随机速率分类器(加权猜测)

现在我们将把我们的高中数学运用到工作中。我们可以使用的另一个基线策略是，如果我们猜测每个类的加权百分比，看看我们的准确度会是多少。该值将始终低于 ZeroR 值，因此它不应该是您的下限基线。相反，它可以用来解释和理解您的结果，即您的模型增加了多少价值。

> 随机比率分类器—在进行随机类别分配时应用类别分配的先验知识。

我们将针对几个分类问题研究这两种策略。

## 抛硬币

让我们先来看一个抛硬币模型。50%的结果是反面(0)，50%的结果是正面(1)。

我们的基线策略在这里是如何工作的？：

*   零——猜测所有的头像会给我们 50%的准确率。
*   随机比率——我们凭直觉知道，猜测 0.50 的正面和 0.50 的反面也会给我们 50%的准确率。我们将有一半正面预测和一半反面预测是正确的。

猜测随机速率分类器的半头半尾在数学上是这样工作的:

```
Odds of Guessing Heads Correct: 0.50 * 0.50 = 0.25
Odds of Guessing Tails Correct: 0.50 * 0.50 = 0.25Baseline = 0.50**2 + 0.50**2 = 0.50
```

## 不平衡的结果

现在我们来看一个不是 50/50 的。假设结果是 75/25。我们现在将对猜测进行加权，这样我们可以在 75%的情况下预测大多数结果。这个随机速率猜测策略看起来像这样

```
Odds of Guessing Minority Correct: 0.25 * 0.25 = 0.0625
Odds of Guessing Majority Correct: 0.75 * 0.75 = 0.5625Baseline = 0.25**2 + 0.75**2 = 0.625
```

如果我们以这个速度猜测，我们的正确猜测率只有 62.5%。任何在这个基线上改进的机器学习模型都是增值的，但也必须高于零或 75%的阈值才能用作预测器。

## 我们的投票示例

那么我在本文开头描述的投票模型到底做得怎么样呢？它高于零基线，所以这个模型是有用的。如果我们猜测实际速率，我们还可以找出我们的基线，然后将其与我们的模型准确性进行比较。

```
Odds of Guessing Democratic Correct: 0.16 * 0.16 = 0.0256
Odds of Guessing Republican Correct: 0.84 * 0.84 = 0.7056Baseline = 0.16**2 + 0.84**2 = 0.73
```

所以用随机加权猜测，我们只能预测 73%的县。我们的实际准确率是 86%。这比加权猜测的理论值提高了 13%。这个看起来没什么前途的模型，无疑增加了重要的价值。它也在 ZeroR 基线之上，所以这个模型对这个问题很有用。

## 多类问题

你能为多类问题这样做吗？当然可以。

我最近做了一个 Twitter 情绪分类器，它将一条推文的情绪分为积极、消极或无情绪。这些班级在以下方面不平衡:

```
No emotion toward brand or product    0.593
Positive emotion                      0.328
Negative emotion                      0.080
```

使用我们的猜测策略的理论基线是:

```
0.593**2 + 0.328**2 + 0.080**2 = 0.465633
```

我们的实际准确率是 0.81，所以机器学习给我们的理论基线增加了 34%。这很重要。更重要的是，如果我们对每一个结果都预测了“*无情绪”*，我们的准确度也远高于 0.59 的零值。

# 要点和建议

*   你的模型必须比零规则(ZeroR)做得更好，才能在预测中有用。这是无法回避的。
*   您可以将您的模型与随机猜测的理论基线进行比较，并使用它来评估您的模型的有用性。
*   您可能会发现其他一些有用的基线(统一猜测、随机猜测和一个规则就是其中的几个)。
*   查看[sk learn . dummy . dummy classifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)，它为以下基线策略提供了自动化解决方案:*、【分层】、【最频繁】、【先验】、【统一】、【恒定】。*
*   当评估不平衡分类问题的准确性时，考虑查看 AUC。
*   在构建模型之前创建基线，并建立用于评估最终模型的规则。

此处展示的技术为您的模型性能提供了一个“现实检查”,对于广大观众来说是可以理解和解释的(我可以很容易地用非技术演示来解释这一点)。他们帮助我评估和理解我自己的模型，我希望你也能发现它们有用。