# â€œpandas.read_csv()â€å¹¶ä¸åƒçœ‹ä¸Šå»é‚£æ ·ç®€å•

> åŸæ–‡ï¼š<https://towardsdatascience.com/there-is-more-to-pandas-read-csv-than-meets-the-eye-8654cb2b3a03?source=collection_archive---------12----------------------->

## [*å°çªé—¨*](https://towardsdatascience.com/tagged/tips-and-tricks)

## æ·±å…¥æ¢ç©¶ç†ŠçŒ«çš„`read_csv`åŠŸèƒ½çš„ä¸€äº›å‚æ•°

![](img/4820d8e3b5d44ec4b8ae5b3ebc2b8320.png)

[æ•…äº‹åˆ›é€ çš„æ—¶é—´å‘é‡](https://www.freepik.com/vectors/time)â€”â€”[www.freepik.com](http://www.freepik.com)

Pandas æ˜¯æ•°æ®ç§‘å­¦ç”Ÿæ€ç³»ç»Ÿä¸­ä½¿ç”¨æœ€å¹¿æ³›çš„åº“ä¹‹ä¸€ã€‚è¿™ä¸ªå¤šåŠŸèƒ½çš„åº“ä¸ºæˆ‘ä»¬æä¾›äº†åœ¨ Python ä¸­è¯»å–ã€æ¢ç´¢å’Œæ“ä½œæ•°æ®çš„å·¥å…·ã€‚pandas ä¸­ç”¨äºæ•°æ®å¯¼å…¥çš„ä¸»è¦å·¥å…·æ˜¯`[**read_csv()**](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas.read_csv)**.**`ã€‚è¯¥å‡½æ•°æ¥å—é€—å·åˆ†éš”å€¼çš„æ–‡ä»¶è·¯å¾„ï¼Œå³ CSV æ–‡ä»¶ä½œä¸ºè¾“å…¥ï¼Œå¹¶ç›´æ¥è¿”å› pandas çš„æ•°æ®å¸§ã€‚ä¸€ä¸ª [**é€—å·åˆ†éš”å€¼**](https://en.wikipedia.org/wiki/Comma-separated_values) ( **CSV** ) [æ–‡ä»¶](https://en.wikipedia.org/wiki/Computer_file)æ˜¯ä¸€ä¸ªä½¿ç”¨[é€—å·](https://en.wikipedia.org/wiki/Comma)åˆ†éš”å€¼çš„åˆ†éš”[æ–‡æœ¬æ–‡ä»¶](https://en.wikipedia.org/wiki/Text_file)ã€‚

![](img/1f66615c19317da245a1f851550959f2.png)

CSV æ–‡ä»¶ç¤ºä¾‹|ä½œè€…å›¾ç‰‡

`pandas.read_csv()`æœ‰å¤§çº¦ 50 ä¸ªå¯é€‰çš„è°ƒç”¨å‚æ•°ï¼Œå…è®¸éå¸¸ç²¾ç»†çš„æ•°æ®å¯¼å…¥ã€‚æœ¬æ–‡å°†æ¶‰åŠä¸€äº›é²œä¸ºäººçŸ¥çš„å‚æ•°åŠå…¶åœ¨æ•°æ®åˆ†æä»»åŠ¡ä¸­çš„ç”¨æ³•ã€‚

# pandas.read_csv()å‚æ•°

ä½¿ç”¨é»˜è®¤å‚æ•°åœ¨ pandas ä¸­å¯¼å…¥ CSV æ–‡ä»¶çš„è¯­æ³•å¦‚ä¸‹:

```
 import pandas as pd
df = pd.read_csv(filepath)
```

## 1.å†—é•¿çš„

**è¯¦ç»†**å‚æ•°è®¾ç½®ä¸º`True`æ—¶ï¼Œæ‰“å°è¯»å– CSV æ–‡ä»¶çš„é™„åŠ ä¿¡æ¯ï¼Œå¦‚:

*   ç±»å‹è½¬æ¢ï¼Œ
*   å†…å­˜æ¸…ç†ï¼Œä»¥åŠ
*   ç¬¦å·åŒ–ã€‚

```
import pandas as pd
df = pd.read_csv('fruits.csv',verbose=True)
```

![](img/b05e395eb1e03601f32466d9d25995c9.png)

## 2.å‰ç¼€

æ ‡é¢˜æ˜¯ CSV æ–‡ä»¶ä¸­çš„ä¸€è¡Œï¼ŒåŒ…å«æœ‰å…³æ¯åˆ—å†…å®¹çš„ä¿¡æ¯ã€‚é¡¾åæ€ä¹‰ï¼Œå®ƒå‡ºç°åœ¨æ–‡ä»¶çš„é¡¶éƒ¨ã€‚

![](img/aab84c31cc98fcbe39bdafc55469fc8f.png)

æ–‡ä»¶ä¸­æ ‡é¢˜åˆ—çš„ç¤ºä¾‹|æŒ‰ä½œè€…æ’åˆ—çš„å›¾åƒ

æœ‰æ—¶æ•°æ®é›†ä¸åŒ…å«æ ‡é¢˜ã€‚è¦è¯»å–è¿™æ ·çš„æ–‡ä»¶ï¼Œæˆ‘ä»¬å¿…é¡»æ˜¾å¼åœ°å°†`header`å‚æ•°è®¾ç½®ä¸º none å¦åˆ™ï¼Œç¬¬ä¸€è¡Œå°†è¢«è§†ä¸ºæ ‡é¢˜ã€‚

```
df = pd.read_csv('fruits.csv',header=none)
df
```

![](img/047a0be82d216101dd94454604e043c8.png)

å¾—åˆ°çš„æ•°æ®å¸§ç”±åˆ—å·ä»£æ›¿åˆ—åç»„æˆï¼Œä»é›¶å¼€å§‹ã€‚æˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`**prefix**`å‚æ•°æ¥ç”Ÿæˆè¦æ·»åŠ åˆ°åˆ—å·çš„å‰ç¼€ã€‚

```
df = pd.read_csv('fruits.csv',header=None, prefix = 'Column')
df
```

![](img/0ac5a0564912f4acebd2d3686da0555b.png)

è¯·æ³¨æ„ï¼Œæ‚¨å¯ä»¥æŒ‡å®šè‡ªå·±é€‰æ‹©çš„ä»»ä½•åç§°æ¥ä»£æ›¿`Column`ã€‚

## 3.mangle_dupe_cols

å¦‚æœæ•°æ®å¸§ç”±é‡å¤çš„åˆ—åç»„æˆï¼Œå¦‚â€˜Xâ€™ï¼Œâ€˜Xâ€™ç­‰`mangle_dupe_cols`ä¼šè‡ªåŠ¨å°†åç§°æ›´æ”¹ä¸ºâ€˜Xâ€™ï¼Œâ€˜X1â€™å¹¶åŒºåˆ†é‡å¤çš„åˆ—ã€‚

![](img/f52129f919ca3a068bfb3dd9489a1fbb.png)

ä½œè€…å›¾ç‰‡

```
df = pd.read_csv('file.csv',mangle_dupe_cols=True)
df
```

![](img/3e0a9bb388ec0743258b6b0dafc16f77.png)

ä½œè€…å›¾ç‰‡

dataframe get ä¸­çš„ä¸€ä¸ª`2015`åˆ—è¢«é‡å‘½åä¸º`2015.1`ã€‚

## 4.ç»„å—å¤§å°

`pandas.read_csv()`å‡½æ•°å¸¦æœ‰ä¸€ä¸ª **chunksize** [**å‚æ•°**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html#pandas.read_csv) ï¼Œç”¨äºæ§åˆ¶å—çš„å¤§å°ã€‚è¿™æœ‰åŠ©äºåŠ è½½ç†ŠçŒ«çš„å†…å­˜æ•°æ®é›†ã€‚è¦å¯ç”¨åˆ†å—ï¼Œæˆ‘ä»¬éœ€è¦åœ¨å¼€å¤´å£°æ˜å—çš„å¤§å°ã€‚è¿™å°†è¿”å›ä¸€ä¸ªæˆ‘ä»¬å¯ä»¥è¿­ä»£çš„å¯¹è±¡ã€‚

```
chunk_size=5000
batch_no=1
for chunk in pd.read_csv('yellow_tripdata_2016-02.csv',chunksize=chunk_size):
    chunk.to_csv('chunk'+str(batch_no)+'.csv',index=False)
    batch_no+=1
```

åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬é€‰æ‹©å—å¤§å°ä¸º 5000ï¼Œè¿™æ„å‘³ç€ä¸€æ¬¡åªèƒ½å¯¼å…¥ 5000 è¡Œæ•°æ®ã€‚æˆ‘ä»¬è·å¾—äº† 5000 è¡Œæ•°æ®çš„å¤šä¸ªå—ï¼Œæ¯ä¸ªå—å¯ä»¥å¾ˆå®¹æ˜“åœ°ä½œä¸º pandas æ•°æ®å¸§åŠ è½½ã€‚

```
df1 = pd.read_csv('chunk1.csv')
df1.head()
```

ä½ å¯ä»¥åœ¨ä¸‹é¢æåˆ°çš„æ–‡ç« ä¸­è¯»åˆ°æ›´å¤šå…³äºç»„å—çš„å†…å®¹:

[](/loading-large-datasets-in-pandas-11bdddd36f7b) [## åœ¨ Pandas ä¸­åŠ è½½å¤§å‹æ•°æ®é›†

### æœ‰æ•ˆåœ°ä½¿ç”¨åˆ†å—å’Œ SQL æ¥è¯»å– pandas ä¸­çš„å¤§å‹æ•°æ®é›†ã€‚ğŸ¼

towardsdatascience.com](/loading-large-datasets-in-pandas-11bdddd36f7b) 

## 5.å‹ç¼©

å¾ˆå¤šæ—¶å€™ï¼Œæˆ‘ä»¬ä¼šæ”¶åˆ°å‹ç¼©æ–‡ä»¶ã€‚å—¯ï¼Œ`pandas.read_csv`å¯ä»¥è½»æ¾å¤„ç†è¿™äº›å‹ç¼©æ–‡ä»¶ï¼Œæ— éœ€è§£å‹ç¼©ã€‚å‹ç¼©å‚æ•°é»˜è®¤è®¾ç½®ä¸º`infer,`ï¼Œå¯ä»¥è‡ªåŠ¨ä»æ–‡ä»¶æ‰©å±•åæ¨æ–­å‡ºæ–‡ä»¶çš„ç§ç±»ï¼Œå³`gzip` ã€`zip`ã€`bz2`ã€`xz`ã€‚

```
df = pd.read_csv('sample.zip') or the long form:df = pd.read_csv('sample.zip', compression='zip')
```

## 6.æ•°åƒ

æ¯å½“æ•°æ®é›†ä¸­çš„ä¸€åˆ—åŒ…å«ä¸€ä¸ª**åƒä½**åˆ†éš”ç¬¦æ—¶ï¼Œ`pandas.read_csv()`å°±å°†å…¶ä½œä¸ºä¸€ä¸ªå­—ç¬¦ä¸²è€Œä¸æ˜¯ä¸€ä¸ªæ•´æ•°æ¥è¯»å–ã€‚ä¾‹å¦‚ï¼Œè€ƒè™‘ä¸‹é¢çš„æ•°æ®é›†ï¼Œå…¶ä¸­é”€å”®åˆ—åŒ…å«ä¸€ä¸ªé€—å·åˆ†éš”ç¬¦ã€‚

![](img/56d2031c7d2dd45d785f47a4ca3c59a5.png)

ä½œè€…å›¾ç‰‡

ç°åœ¨ï¼Œå¦‚æœæˆ‘ä»¬å°†ä¸Šé¢çš„æ•°æ®é›†è¯»å…¥ä¸€ä¸ª pandas æ•°æ®å¸§ï¼Œé‚£ä¹ˆç”±äºé€—å·çš„å­˜åœ¨ï¼Œ`Sales`åˆ—å°†è¢«è§†ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²ã€‚

```
df = pd.read_csv('sample.csv')
df.dtypes
```

![](img/64938e5ec5b17a16623fc52718f7350e.png)

ä¸ºäº†é¿å…è¿™ç§æƒ…å†µï¼Œæˆ‘ä»¬éœ€è¦å€ŸåŠ©äº`thousands`å‚æ•°æ˜ç¡®åœ°å‘Šè¯‰ `pandas.read_csv()`å‡½æ•°ï¼Œé€—å·æ˜¯ä¸€ä¸ªåƒä½æŒ‡ç¤ºç¬¦ã€‚

```
df = pd.read_csv('sample.csv',thousands=',')
df.dtypes
```

![](img/90f306a188929760c2b8246a96f40724.png)

## 7. **skip_blank_lines**

å¦‚æœæ•°æ®é›†ä¸­å­˜åœ¨ç©ºè¡Œï¼Œå®ƒä»¬ä¼šè¢«è‡ªåŠ¨è·³è¿‡ã€‚å¦‚æœæ‚¨å¸Œæœ›ç©ºè¡Œè¢«è§£é‡Šä¸º NaNï¼Œè¯·å°†`skip_blank_lines`é€‰é¡¹è®¾ç½®ä¸º Falseã€‚

## 8.è¯»å–å¤šä¸ª CSV æ–‡ä»¶

è¿™ä¸æ˜¯ä¸€ä¸ªå‚æ•°ï¼Œåªæ˜¯ä¸€ä¸ªæœ‰ç”¨çš„æç¤ºã€‚è¦ä½¿ç”¨ pandas è¯»å–å¤šä¸ªæ–‡ä»¶ï¼Œæˆ‘ä»¬é€šå¸¸éœ€è¦å•ç‹¬çš„æ•°æ®å¸§ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬è°ƒç”¨`pd.read_csv()`å‡½æ•°ä¸¤æ¬¡ï¼Œå°†ä¸¤ä¸ªç‹¬ç«‹çš„æ–‡ä»¶è¯»å…¥ä¸¤ä¸ªä¸åŒçš„æ•°æ®å¸§ã€‚

```
df1 = pd.read_csv('dataset1.csv')
df2 = pd.read_csv('dataset2.csv')
```

ä¸€èµ·è¯»å–è¿™äº›æ–‡ä»¶çš„ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨å¾ªç¯ã€‚æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªæ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼Œç„¶åä½¿ç”¨åˆ—è¡¨ç†è§£éå†åˆ—è¡¨ï¼Œå¦‚ä¸‹æ‰€ç¤º:

```
filenames = ['dataset1.csv', 'dataset2,csv']
dataframes = [pd.read_csv(f) for f in filenames]
```

å½“è®¸å¤šæ–‡ä»¶åå…·æœ‰ç›¸ä¼¼çš„æ¨¡å¼æ—¶ï¼ŒPython æ ‡å‡†åº“ä¸­çš„ [**glob**](https://docs.python.org/3/library/glob.html) æ¨¡å—å°±æ´¾ä¸Šäº†ç”¨åœºã€‚æˆ‘ä»¬é¦–å…ˆéœ€è¦ä»å†…ç½®çš„`glob`æ¨¡å—ä¸­å¯¼å…¥`glob`å‡½æ•°ã€‚æˆ‘ä»¬ä½¿ç”¨æ¨¡å¼`NIFTY*.csv` æ¥åŒ¹é…ä»»ä½•ä»¥å‰ç¼€`NIFTY`å¼€å§‹å¹¶ä»¥åç¼€`.CSV.`ç»“æŸçš„å­—ç¬¦ä¸²,`*â€™(asterisk)`æ˜¯ä¸€ä¸ªé€šé…ç¬¦ã€‚å®ƒä»£è¡¨ä»»æ„æ•°é‡çš„æ ‡å‡†å­—ç¬¦ï¼ŒåŒ…æ‹¬é›¶ã€‚

```
import glob
filenames = glob.glob('NIFTY*.csv')
filenames
--------------------------------------------------------------------
['NIFTY PHARMA.csv',
 'NIFTY IT.csv',
 'NIFTY BANK.csv',
 'NIFTY_data_2020.csv',
 'NIFTY FMCG.csv']
```

ä¸Šé¢çš„ä»£ç å¯ä»¥é€‰æ‹©æ‰€æœ‰ä»¥ NIFTY å¼€å¤´çš„ CSV æ–‡ä»¶åã€‚ç°åœ¨ï¼Œä»–ä»¬éƒ½å¯ä»¥ä½¿ç”¨åˆ—è¡¨ç†è§£æˆ–å¾ªç¯ä¸€æ¬¡é˜…è¯»ã€‚

```
dataframes = [pd.read_csv(f) for f in filenames]
```

# ç»“è®º

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº† pandas.read_csv()å‡½æ•°çš„å‡ ä¸ªå‚æ•°ã€‚è¿™æ˜¯ä¸€ä¸ªæœ‰ç›Šçš„åŠŸèƒ½ï¼Œå¸¦æœ‰è®¸å¤šæˆ‘ä»¬å¾ˆå°‘ä½¿ç”¨çš„å†…ç½®å‚æ•°ã€‚ä¸è¿™æ ·åšçš„ä¸»è¦åŸå› ä¹‹ä¸€æ˜¯å› ä¸ºæˆ‘ä»¬å¾ˆå°‘å…³å¿ƒé˜…è¯»æ–‡æ¡£ã€‚è¯¦ç»†ç ”ç©¶æ–‡æ¡£ä»¥å‘æ˜å…¶ä¸­å¯èƒ½åŒ…å«çš„é‡è¦ä¿¡æ¯æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¸»æ„ã€‚

*ğŸ‘‰æœ‰å…´è¶£è‡ªå·±çœ‹å…¶ä»–æ–‡ç« ã€‚è¿™ä¸ª* [*å›è´­*](https://github.com/parulnith/Data-Science-Articles/blob/main/README.md) *åŒ…å«äº†æˆ‘åˆ†ç±»å†™çš„æ‰€æœ‰æ–‡ç« ã€‚*