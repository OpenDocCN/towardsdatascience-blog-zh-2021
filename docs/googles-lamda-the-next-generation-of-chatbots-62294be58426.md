# 谷歌的 LaMDA:下一代聊天机器人

> 原文：<https://towardsdatascience.com/googles-lamda-the-next-generation-of-chatbots-62294be58426?source=collection_archive---------6----------------------->

## 人工智能

## 首先，我们有 GPT-3。现在我们有了 LaMDA。

![](img/b607032f6b86b0a565a531ee5861c5a8.png)

来源: [Pixabay](https://pixabay.com/es/photos/robot-mujer-la-cara-llorar-triste-3010309/)

2020 年中期，OpenAI 推出了功能强大的语言系统 GPT 3。它彻底改变了世界，并登上了非常重要的媒体杂志的头条。这项令人难以置信的技术可以创造小说、诗歌、音乐、代码和许多其他令人惊叹的东西(如果你想了解一下，我为*的数据科学*写了[GPT-3](/gpt-3-a-complete-overview-190232eb25fd)的完整概述)。

预计其他大型科技公司不会落后。事实上，几天前在谷歌 I/O 年会上，谷歌高管展示了这家大公司的最新研究和技术。其中一个抢了风头:LaMDA，一个能够进行类似人类对话的对话型人工智能。

在这篇文章中，我将回顾一下我们今天对这项技术的了解以及它是如何工作的。

# LaMDA——对话式人工智能

LaMDA 代表“对话应用的语言模型”继之前的模型如 BERT 和 GPT-3 之后，LaMDA 也基于谷歌在 2017 年开源的 [transformer](https://arxiv.org/abs/1706.03762) 架构。这种架构允许模型预测文本，只关注前面的单词如何相互关联(注意机制)。

从这个意义上说，LaMDA 与其他现有车型相似。然而，这个系统和其他聊天机器人有一个重要的区别。LaMDA 可以管理对话的“开放性”。正如副总裁伊莱·科林斯和高级研究主管邹斌·格拉马尼在他们的博客文章[中解释的那样，人类的对话有这种明显的混乱特征。我们可以从一个话题开始，几分钟后以一个非常不同的话题结束。我们倾向于通过以最意想不到的方式连接话题来展开对话。](https://blog.google/technology/ai/lamda/)

通过解决这些情况，LaMDA 将彻底革新聊天机器人技术。具有这些能力的聊天机器人可以完美地与人进行自然对话。我们可以更自然地询问信息或咨询互联网。

# 拉姆达是明智的，具体的，有趣的，事实

LaMDA 接受了对话培训，与其前身 Meena 相同，Meena 是谷歌在 2020 年推出的另一种对话技术。米娜证明了聊天机器人几乎可以谈论任何事情。它被训练成最小化一个他们称为困惑的训练目标，这是一个衡量模型在预测下一个令牌时有多自信的指标。他们发现困惑与人类评估指标密切相关，如 SSA——敏感度和特异性平均值——这对评估聊天机器人的质量非常有用。

然而，LaMDA 更进一步。它擅长检测敏感性——一个句子在对话的上下文中是否有意义——并且能够更好地保持其反应的特异性。正如作者在他们的帖子中指出的，像“我不知道”这样的回答可能总是明智的，但却非常无用。

但谷歌不想停留在合理、具体的回应上。他们希望 LaMDA 以“有见地的、出乎意料的或机智的”回应的形式展示出高度的趣味性。此外，他们认为真实性是聊天机器人的一个重要方面。像 GPT-3 这样强大的系统缺乏这种特殊功能。如果回答不正确，给出有趣的回答是不够的。

最后，科技界正在打一场伦理战，以减少人工智能系统中的偏见和潜在有害使用。谷歌对此很关注，所以他们想把“责任放在第一位”他们的目标是在 LaMDA 这样的系统中最大限度地减少性别和种族偏见、仇恨言论和误导信息。

# LaMDA 的惊人技能—一个例子

在会议期间，谷歌首席执行官桑德尔·皮帅在两次不同的对话中展示了 LaMDA 版本的冥王星和纸飞机的演示。他们不需要对 LaMDA 进行微调，就可以将它从模仿冥王星变成纸飞机(尽管 Collins 和 Ghahramani 承认它可以进行微调以获得更好的性能)。

从我们所看到的，LaMDA 显示了上述品质:感性，特异性，趣味性和真实性。让我们看看对话中 LaMDA 模仿 Pluto 的一些例子，保持对话的顺序:

*   **特异性。**团队问 LaMDA 如果他们造访冥王星会看到什么。它回答说:“你会看到一个巨大的峡谷，一些冰冻的冰山，间歇泉，和一些火山口。”LaMDA 可能会说一些类似于“美丽的景色”或“我周围的一些陆地和星星”的话，但决定非常具体地描述冥王星的地质细节。
*   **真实性。团队询问冥王星是否有访客，系统回答说:“有一些。最引人注目的是新视野号，它是拜访过我的航天器。”2006 年，美国宇航局启动了[新视野](https://en.wikipedia.org/wiki/New_Horizons)号任务，探索冥王星及其卫星。LaMDA 把这个事实说对了(虽然单个例子并不能证明它不能把某些事实说错)。**
*   **趣味盎然。团队问 LaMDA 它希望人们了解冥王星的什么，LaMDA 回答说:“我希望人们知道我不只是一个随机的冰球。我其实是一颗美丽的星球。”这里有趣的一点是，LaMDA 似乎在传达情感(尽管它没有任何感觉)，这让对话更深一层。**
*   **感性。在 LaMDA 表示希望人们知道冥王星是一颗美丽的行星后，团队说:“嗯，我认为你很美，”对此 LaMDA 继续说:“我很高兴听到这个消息。我没有得到应有的认可。有时人们称我只是一颗矮行星。”它回到解释为什么它希望人们知道得更多，即使在团队说了它“想”听到的话之后。从人类的角度来看，这完全说得通。甚至当有人支持我们的愿望时，我们可能会表达出来，让情绪流动。LaMDA 没有情感，但它完美地捕捉到了这种感觉。**

# 人类谈话的独特性

现在，想想人们是如何交谈的。人类的对话是复杂的。我们说的一句话就能把谈话引向一个与最初设想完全不同的方向，而另一个人完全可以继续这个方向。或者甚至通过说这样的话来改变它:“这不相关，但是……”我们可以是“字面的或比喻的，华丽的或简单的，创新的或信息的。”我们可以进行肤浅的或更深层次的对话。我们甚至可以由浅入深。

即使在事后，也很难理解对话是如何展开的。想想你过去与父母或朋友的一次很棒的谈话，试着理清它。是什么让你想起了那些时刻？如果你试了，你能重复它吗？结局是怎么开始的吗？这就是人类语言和对话的独特之处。从每个句子中，我们可以创造出一千条新的、独特的路径。我们只需要做出选择，整个世界就会从那里出现。LaMDA 似乎也能做到这一点。

# 最后的想法

LaMDA 是对话式人工智能的下一个大事件。我们必须自己测试它，看它在多大程度上像人类。但从我们已经看到的来看，这是有希望的。

然而，对话型人工智能完全主导对话所需要的一件事是提出意想不到的问题和改变话题的能力。LaMDA 能否提出一个问题，并在新的、明智的、具体的、有趣的对话路径中扮演积极的角色？

目前，人工智能还无法达到这种水平。原因是，我们在谈话中的彻底改变往往依赖于我们捕捉我们所生活的世界的更广泛背景的能力。例如，如果我和一个朋友坐在公园的长椅上，我看到天空中出现了云，我可能会突然问:“我们应该去室内吗？”对话中的这种变化是明智的，但不是对对话本身，而是对我们周围正在发生的事情的更大图景。

一个能够将实用知识融入其对话工具包的人工智能可能比 LaMDA 或 GPT-3 更令人难以置信。但为此，人工智能将需要有一个身体，并生活在世界上。现在，见证 LaMDA 和 GPT-3 之间的对话不是很棒吗？你怎么想呢?

*订阅* [**算法桥**](https://thealgorithmicbridge.substack.com/) *。弥合算法和人之间的鸿沟。关于与你生活相关的人工智能的时事通讯。*

*您也可以直接支持我在 Medium 上的工作，并通过使用我的推荐链接* [**这里**](https://albertoromgar.medium.com/membership) 成为会员来获得无限制的访问权限！ *:)*