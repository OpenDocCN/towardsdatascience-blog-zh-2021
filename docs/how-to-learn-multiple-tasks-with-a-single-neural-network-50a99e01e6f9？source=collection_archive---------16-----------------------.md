# 如何用单个神经网络学习多项任务

> 原文：<https://towardsdatascience.com/how-to-learn-multiple-tasks-with-a-single-neural-network-50a99e01e6f9?source=collection_archive---------16----------------------->

## 灾难性遗忘曾经是一个棘手的问题。最近取得了进展，请继续阅读以了解更多信息。

![](img/89ccaf088d22914668b2a6bdb73c2f66.png)

艾莉娜·格鲁布尼亚克在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

现代神经网络非常擅长学习一件特定的事情。无论是下棋还是折叠蛋白质，只要有足够的数据和时间，神经网络就能取得惊人的结果。不幸的是，网络目前只能胜任一项任务。你可以训练一个网络擅长某件事，但一旦你试图教网络别的东西，它就会忘记在第一项任务中学到了什么。这被称为**灾难性遗忘**。由于智能的标志之一是学习和存储多项任务，因此如何在多项任务上训练神经网络(并解决灾难性遗忘)的问题极其重要。

一个想法是改变训练数据，使得每个任务的训练示例相互交错。例如，假设我们有 3 个任务 A、B 和 C，示例分别标记为 a_i、b_i 和 c_i。这种思想将训练集排序为 a1，B1，C1，a2，B2，C2，a3 等。重点是以同等的重视程度同时训练所有三个任务，希望通过这种方式学习的网络权重将包含关于所有三个任务的信息。在实践中，这个想法是可行的——网络将同时在所有三项任务上慢慢变好，避免灾难性的遗忘。

但是，在我看来这种方法是作弊。真正的智能学习(例如人类)不需要以这种方式交错任务。事实上，通常情况下，任务是在大时间块内连续学习的(我们称之为“块调度”)。典型的学校是这样安排的:首先你学 1 小时数学，然后 1 小时英语，然后再学 1 小时历史，以此类推。你不做一道数学题，写一句作文，然后看一句历史书。那么问题来了:有没有一种方法可以让神经网络用块调度来学习多个任务？

2016 年，Deepmind 的研究人员出了一篇[论文](https://arxiv.org/pdf/1612.00796.pdf)解决了这个问题。我特别喜欢他们的方法，因为它没有那么复杂。他们真正做的只是对网络应用一种特殊类型的正则化。让我们仔细看看。

假设我们有两个任务，A 和 b，block schedule 是先用很多例子训练 A，然后我们切换到训练 b，Deepmind 的研究人员提出先正常训练 A(即正则梯度下降/反向传播)。然后，在 B 块期间，我们保持从 A 学习的权重，并继续梯度下降。唯一的区别是我们现在包括了一个二次正则化项，它对于每个权重都是唯一的。这个想法是使用这个每权重正则化来惩罚远离从 A 学习的权重。被认为对 A 更重要的权重将被惩罚得更重。在数学上，我们在 B 训练块期间的成本函数是 L(θ)= L _ B(θ)+σ(k _ I *(θ_Ai-θ_ I))，其中 I 是所有网络权重的指数，θ_ Ai 是 A 训练块完成后的权重。L_B(θ)是 B 的正态成本函数，可能是平方误差或对数损失。最后，k_i 是权重 I 对于预测 a 的重要性。

还有一种更直观的方式来思考每权重正则化。想象一个物理弹簧。当你拉弹簧时，你拉得越远，弹簧拉回来的力就越大。此外，有些弹簧比其他弹簧更坚固。这和我们的算法有什么关系？你可以想象一个弹簧连接到神经网络中的每个重量。所有弹簧的相对强度是正则化的。某些弹簧(对 A 来说很重要)会特别强，所以在 B 的训练过程中，算法会不鼓励去拉那些强弹簧，对应的权重不会有太大的变化。因此，该算法将改为拉动较弱的弹簧，并且对应于这些弹簧的权重将改变更多。

考虑这个算法的另一种方式是，它是对 L2 正则化的改进。利用 L2 正则化，权重不被鼓励改变太多，其惩罚对应于权重大小的平方和。然而，在 L2 正则化中，**所有的**权重被同等地惩罚。在我们的算法中，**只有重要的权重**被阻止改变。

好的——我们现在直观地理解了这个算法是如何工作的。通过保持 A 的重要权重相对恒定，我们可以在 b 上成功训练的同时保持 A 的性能。但是，我们仍然没有解释如何确定 A 的“重要”权重。所以让我们问一个问题:什么使权重变得重要？一个合理的答案可能是:如果一个权重比其他权重对最终预测的影响更大，那么它就是重要的。更具体地说，如果一个权重相对于最终预测的导数具有比其他权重导数更高的幅度，我们可以说该权重是重要的。但是我们忽略了一件事——因为神经网络中的权重会影响其他权重，它们的导数是相互关联的。换句话说，我们不能只考虑给定权重的导数本身；我们需要查看所有权重导数的**协方差矩阵。一个更正式的版本被称为费希尔信息矩阵，这是研究人员最终使用的。**

因此，总结一下:首先我们正常地训练 A，然后我们用每权重二次正则化训练 B。这些每个权重的正则化依赖于权重对 A 的相对重要性，这可以通过 Fisher 信息矩阵找到。结果是一个对 A 和 b 都很有效的神经网络。研究人员给这种方法起的名字是“**弹性权重合并**”(**EWC**)。

所有这些理论上的讨论都很棒，但实际上有用吗？研究人员在监督学习和强化学习环境中测试了这种新方法，以找出答案。首先，为了测试监督学习，研究人员使用了流行的 MNIST 任务。为了从 MNIST 创建多个任务，他们获取输入的 MNIST 图像，并用几个固定的常数对它们进行排列。这个想法是，在一个排列(MNIST 图像+常数 1)上训练的分类器不会在另一个排列(MNIST 图像+常数 2)上工作，所以实际上，我们有不同的任务。然后，研究人员比较了 EWC、规则梯度下降和 L2 正则化的结果。在第一项任务中(MNIST 图像的第一次排列)，所有三种方法都是可比较的。随着越来越多的任务被引入(其他排列)，EWC 远远比其他人表现得更好。

强化学习也有类似的结果。在这里，实验是学习十种不同的雅达利游戏。游戏的顺序是随机的。同样，在第一场比赛中，代理使用 EWC 和使用基线( [DQN](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf) )获得了相似的性能。随着更多游戏的引入，EWC 在监督学习案例中逐渐退出。

在这篇文章中，我们介绍了灾难性遗忘的问题，并通过 EWC 算法背后的直觉。我个人认为 EWC 是朝着真正智能的正确方向迈出的一步，我很高兴看到接下来会发生什么。请留下任何问题/评论，感谢阅读！