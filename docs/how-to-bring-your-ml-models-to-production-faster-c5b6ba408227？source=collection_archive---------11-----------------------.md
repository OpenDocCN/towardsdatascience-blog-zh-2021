# 如何更快地将您的 ML 模型投入生产

> 原文：<https://towardsdatascience.com/how-to-bring-your-ml-models-to-production-faster-c5b6ba408227?source=collection_archive---------11----------------------->

## 快速部署 ML 模型和创造新竞争优势的简短指南

![](img/c4d114abbdad101a648932815cfc011b.png)

照片由[麦克多比胡](https://unsplash.com/@hjx518756?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)在 [Unsplash](https://unsplash.com/s/photos/tech?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄

在不同的人工智能项目之后，我意识到如何快速地建立和部署高效的机器学习(ML)模型可以成为竞争优势的来源。决策者们认识到，在他们现有的技术体系内收集数据以及管理构建、部署和调试模型的整个生命周期并不简单，而且会带来意想不到的挑战。

根据我的经验，数据科学家通常会花时间分析一个数据集，寻找合适的算法，训练一个新的模型，然后交给数据工程师在生产中运行。

这种情况可能会导致问题，数据科学家看不到在生产中运行模型的挑战，而数据工程师不知道模型是如何构造的。我见过很多次数据科学家编写无法在生产中扩展的应用程序。

对于可能没有数据工程师的小公司来说就更难了。结果，我们最终得到的是构造糟糕的 ML 部署管道，并出现了保持 ML 模型更新和在生产中可靠运行的问题。

> **由于部署复杂、缺乏治理工具和数据问题，只有一小部分机器学习或深度学习项目能够投入生产。**

# **将 ML 模型投入生产**

我意识到许多公司在没有明确生产计划的情况下启动 AI 项目。通常，没有人真正想到概念验证之后会发生什么。当一个团队必须将模型集成到生产环境中时，这种策略的缺乏通常会导致严重的问题。

根据公司规模、管理人工智能项目的经验、预算和团队，决策者可以决定只专注于模型培训，以创建概念证明，而不考虑生产和可扩展性。

在这种情况下，数据科学团队可能会简单地决定将模型包装在 API 后面，并直接交付生产。然而，这可能会导致持续的高支持成本，因为在没有可扩展和可复制的计划来更新和调试生产中的模型的情况下，工程师很难可靠地运行系统。

由于机器学习生命周期中缺乏自动化任务，模型通常会以定制的数据管道和每个模型的部署环境**而告终**。

这种缺乏一致的方法减慢了开发，因为碎片化使得改善生态系统的成本很高。此外，团队通常用他们喜欢的语言(通常是 R 或 Python)创建模型，然后将它们重写为另一种语言以在生产框架上运行(例如 Java/Spark)。

ML 模型由几个元素组成，包括数据集、参数和超参数。所有这些组件都需要在整个开发过程中仔细存储和版本化，以确保可再现性。

# **怎样才能更快地将 ML 模型投入生产**

MLOps 是机器学习领域的一个热门话题。简而言之，MLOps 是一种逻辑方法，旨在标准化和自动化大多数数据科学任务，同时为持续开发 ML 模型和快速部署它们创建一个协作环境。

MLOps 使部署用任何开源语言编写的模型变得容易，并公开了一个生产质量的 REST API 来支持实时预测。软件工程也经历了类似的转变，称为 DevOps。

利用 MLops 解决方案的成功公司已经采用了类似的最佳实践。这些实践通常包括标准化的中央管道，用于数据准备/培训，具有可重复的工作流，可以为未来的部署进行更新。

其次，模型管理解决方案使得跨各种度量比较不同的和新的模型变得容易。最后，MLOps 流程应基于数据和 ML 应用程序的持续集成和交付(CI/CD ),同时支持公司使用的所有框架，例如 Torch 或 Tensorflow。

# **为了更进一步，考虑以下元素:**

*   版本化，以跟踪您使用的所有算法、训练模型、数据集、元数据和超参数。考虑使用容器(Docker、Kubernetes 等。)因为它们提供了一个隔离和版本化模型的好方法。
*   自动保护措施，不再依赖手动或不一致的流程。
*   模型注册中心在一个中央存储库中存储、注释和管理生产就绪模型。这个要素也与**数据科学团队的快速入职有关。**我注意到，人们很难参与进来，看到他们正在做的项目，并确定数据在哪里。
*   对于计算机视觉项目，你可以考虑使用带有预训练模型的 AI 工具包。具体地说，您可以使用自己的数据来微调特定用例的模型。例如，使用 NVIDIA 多功能、生产质量模型中的一种来完成常见的人工智能任务，或者使用 100 多种神经网络架构中的一种，如 ResNet、VGG、FasterRCNN、RetinaNet 和 YOLOv3/v4。
*   用于观察资源管理(GPU/CPU)的仪表板
*   自动监控已部署模型的性能，并在新模型表现不佳时进行回滚。随着时间的推移，许多型号会出现漂移，性能下降。部署的模型需要监控和改装。每个部署的模型都应该记录所有的输入、输出和异常。
*   为模型构建者提供自我部署通过内部模型治理过程批准的模型的能力。
*   在生产中部署之前测试和调试 ML 模型的开发环境。
*   用于测试生产中各种超参数组合的弹性集群..

这些元素将帮助您的公司处理许多重复性的任务，并导致更快的发布周期。ML 开发生命周期的另一个重要方面是什么？数据。

# **数据问题**

对于那些熟悉 ML 项目的人来说，你可能知道手动的数据准备和争论可能会占据 ML 项目 80%的时间。

数据科学家需要数据争论、准备、原型和可视化工具来缩短这一时间。通过利用 MLOps 管道，数据科学团队可以更快、更高效地完成这些任务。**先进的 MLOps 解决方案可以支持从数据选择和注释到模型优化的 ML 项目。**

在计算机视觉项目中，这种对数据优化的需求至关重要。一些公司在 MLOps 管道和培训数据优化方面部署了独特的专业知识。

其他公司已经创建了端到端的训练数据平台，以便数据科学家可以专注于模型选择和评估，同时外包整个训练数据工作流，从新数据选择和注释到模型警戒。

由于高精度的需要，在生产之前必须处理一些边缘情况。一些平台通过预测任务中可能存在的每种类型的错误，并在注释过程开始之前为其分配数字惩罚值，来主动识别边缘情况。这种主动方法使数据科学团队能够创建全面且可行的说明，从而帮助更快地投入生产。

此外，数据科学团队可以根据他们的初始指导方针不断接收样本结果，以帮助他们优先考虑和确定要注释的数据，从而通过迭代指令加快模型开发。

## 部署策略

最后但同样重要的是，我强烈建议公司不要只是将他们的模型投入生产。公司必须探索许多不同的方式来部署基于人工智能的解决方案。正如 Christopher Samiullah 所提到的，“影子模式”和“金丝雀”部署对于 ML 应用程序特别有用。在“影子模式”中，您捕获生产中新模型的输入和预测，而不实际服务于这些预测。相反，您可以自由地分析结果，即使检测到错误，也不会产生重大后果。”

ML 项目不再仅仅基于数据科学。首先要清楚地定义你的目标(例如，可接受的精度水平等。)并完全采用敏捷方法(例如，不断迭代，直到找到正确的算法、模型和准确性)。

公司需要认真考虑将模型投入生产所需的时间。其他公司可以通过更快、更高效地将其模型投入生产来获得竞争优势。

**一旦投入生产，你还必须确保你的模型保持准确；当涉及到模型性能时，对已部署模型的监控可能会导致坏的意外，并且可能需要模型再培训(例如，概念漂移)。**

[***如果你总体上喜欢这篇文章和我的写作，请考虑通过我在这里的推荐链接注册 Medium 来支持我的写作。谢谢！***](https://alexandregonfalonieri.medium.com/membership)