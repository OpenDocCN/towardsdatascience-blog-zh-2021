# CIFAR-100:å›¾åƒè¯†åˆ«ä»»åŠ¡é¢„å¤„ç†

> åŸæ–‡ï¼š<https://towardsdatascience.com/cifar-100-pre-processing-for-image-recognition-task-68015b43d658?source=collection_archive---------9----------------------->

## å¸¸ç”¨å›¾åƒæ•°æ®é›†(CIFAR-100)çš„é¢„å¤„ç†æˆ–æ•°æ®å‡†å¤‡

![](img/6d35df02f251c253f7dbb49cc826504f.png)

åœ¨ [Unsplash](https://unsplash.com/photos/WTThc6UmwEI) ä¸Šç”± [Bacila](https://unsplash.com/@bacila_vlad) æ‹æ‘„çš„ç…§ç‰‡

**å›¾åƒè¯†åˆ«**å¯¹äººç±»æ¥è¯´æ˜¯ä¸€é¡¹ç®€å•çš„ä»»åŠ¡ï¼Œå› ä¸ºæˆ‘ä»¬å¾ˆå®¹æ˜“åŒºåˆ†ä¸åŒçš„ç‰¹å¾ã€‚ä¸çŸ¥ä½•æ•…ï¼Œæˆ‘ä»¬çš„å¤§è„‘åœ¨ä¸çŸ¥ä¸è§‰ä¸­æ¥å—äº†ä¸åŒæˆ–ç›¸ä¼¼ç±»å‹å›¾åƒçš„è®­ç»ƒï¼Œè¿™äº›å›¾åƒå¸®åŠ©æˆ‘ä»¬åœ¨ä¸æŠ•å…¥å¤ªå¤šç²¾åŠ›çš„æƒ…å†µä¸‹åŒºåˆ†ç‰¹å¾(å›¾åƒ)ã€‚ä¾‹å¦‚ï¼Œåœ¨è§è¿‡å‡ åªçŒ«ä¹‹åï¼Œæˆ‘ä»¬å‡ ä¹å¯ä»¥è®¤å‡ºç”Ÿæ´»ä¸­é‡åˆ°çš„æ¯ä¸€ç§ä¸åŒç±»å‹çš„çŒ«ã€‚ğŸ±ç„¶è€Œï¼Œæœºå™¨éœ€è¦å¤§é‡çš„ç‰¹å¾æå–è®­ç»ƒï¼Œç”±äºé«˜è®¡ç®—æˆæœ¬ã€å†…å­˜éœ€æ±‚å’Œå¤„ç†èƒ½åŠ›ï¼Œè¿™æˆä¸ºä¸€ä¸ªæŒ‘æˆ˜ã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºè¿™æ ·ä¸€ä¸ªç”¨ä¾‹çš„é¢„å¤„ç†ã€‚å› æ­¤ï¼Œè®©æˆ‘ä»¬æ›´æ·±å…¥åœ°äº†è§£å¦‚ä½•é¢„å¤„ç†å›¾åƒæ•°æ®é›†æ¥æ„å»ºå·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚ğŸŠğŸ¼

***æ³¨:***

1.  *æˆ‘ä¼šå°½é‡æŠŠå¤§éƒ¨åˆ†æ¦‚å¿µè®²æ¸…æ¥šï¼Œä½†æ˜¯ï¼Œæœ¬æ–‡å‡è®¾å¯¹å·ç§¯ç¥ç»ç½‘ç»œ(CNN)æœ‰ä¸€ä¸ªåŸºæœ¬çš„äº†è§£ã€‚*ğŸ“–
2.  æˆ‘ç”¨ jupyter ç¬”è®°æœ¬æ¥å†™æˆ‘çš„ä»£ç ã€‚

**å·ç§¯ç¥ç»ç½‘ç»œ** **(CNN)** æ˜¯ä¸€ç±»å¸¸ç”¨äºåˆ†æå›¾åƒçš„æ·±åº¦ç¥ç»ç½‘ç»œã€‚å¯ä»¥æ„å»ºå·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œä»¥æ­£ç¡®è¯†åˆ«å¯¹è±¡çš„å½©è‰²å›¾åƒå¹¶å°†å…¶åˆ†ç±»åˆ° CIFAR-100 æ•°æ®é›†çš„ 100 ä¸ªå¯ç”¨ç±»åˆ«ä¹‹ä¸€ã€‚

é‚£ä¹ˆï¼Œæˆ‘ä»¬å¼€å§‹å§ã€‚ğŸƒğŸ»

# CIFAR-100 æ˜¯ä»€ä¹ˆï¼ŸğŸ¤”

**CIFAR-100** æ˜¯ 8000 ä¸‡å¾®å°å›¾åƒæ•°æ®é›†çš„æ ‡è®°å­é›†ï¼Œå…¶ä¸­ [CIFAR](https://cifar.ca/) ä»£è¡¨åŠ æ‹¿å¤§é«˜çº§ç ”ç©¶æ‰€ã€‚è¿™äº›å›¾ç‰‡æ˜¯ç”±äºšå†å…‹æ–¯Â·å…‹é‡Œçƒ­å¤«æ–¯åŸºã€ç»´è¯ºå¾·Â·å¥ˆå°”å’Œæ°å¼—é‡ŒÂ·è¾›é¡¿æ”¶é›†çš„ã€‚è¯¥æ•°æ®é›†ç”± 32 Ã— 32 åƒç´ çš„ 60000 å¹…å½©è‰²å›¾åƒ(50000 å¹…è®­ç»ƒå’Œ 10000 å¹…æµ‹è¯•)ç»„æˆï¼Œåˆ†ä¸º 100 ä¸ªç±»ï¼Œåˆ†ä¸º 20 ä¸ªè¶…ç±»ã€‚æ¯ä¸ªå›¾åƒéƒ½æœ‰ä¸€ä¸ªç»†æ ‡ç­¾(ç±»)å’Œä¸€ä¸ªç²—æ ‡ç­¾(è¶…ç±»)ã€‚

# å¦‚ä½•è·å¾— CIFAR-100 æ•°æ®é›†ï¼ŸğŸ™‹

è¿™ä¸ªæ•°æ®é›†çš„ Python ç‰ˆæœ¬å¯ä»¥ä»å¤šä¼¦å¤šè®¡ç®—æœºç§‘å­¦å¤§å­¦çš„ç½‘ç«™ä¸Šä¸‹è½½ã€‚ä¸‹è½½çš„æ–‡ä»¶æ˜¯ä½¿ç”¨ cPickle ç”Ÿæˆçš„ Python è…Œåˆ¶å¯¹è±¡ã€‚ç°åœ¨ä¸è¦æ‹…å¿ƒè¿™ä¸ªã€‚æˆ‘ä»¬å°†ä¸€èµ·å®Œæˆä½¿ç”¨è¯¥æ•°æ®é›†çš„æ¯ä¸ªæ­¥éª¤ã€‚

# å¦‚ä½•åŠ è½½è¿™ä¸ªæ•°æ®é›†ï¼ŸğŸš›

ä»ç½‘ç«™ä¸‹è½½æ•°æ®é›†åï¼Œæˆ‘ä»¬éœ€è¦å°†å®ƒåŠ è½½åˆ°æˆ‘ä»¬çš„ jupyter ç¬”è®°æœ¬ä¸­ã€‚ä»ç½‘ç«™ä¸Šè·å–çš„æ–‡ä»¶éƒ½æ˜¯ Python è…Œåˆ¶çš„å¯¹è±¡ã€‚è§£å‹ç¼©åçš„æ–‡ä»¶å¤¹ç»“æ„å¦‚ä¸‹æ‰€ç¤º:

![](img/38b05ea281cc709e68a4cb50c748dfc0.png)

ä½œè€…å›¾ç‰‡

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬æœ‰å•ç‹¬çš„åŸ¹è®­å’Œæµ‹è¯•æ–‡ä»¶ï¼Œä»¥åŠä¸€ä¸ªå…ƒæ–‡ä»¶ã€‚

Python Pickle æˆ– cPickle æ¨¡å—å¯ä»¥ç”¨æ¥åºåˆ—åŒ–æˆ–ååºåˆ—åŒ– Python ä¸­çš„å¯¹è±¡ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ç”¨æ³¡èœã€‚Pickle çš„ load()æ–¹æ³•å¯ä»¥ç”¨æ¥è¯»å–è¿™äº›æ–‡ä»¶å¹¶åˆ†æå®ƒä»¬çš„ç»“æ„ã€‚é˜…è¯»[è¿™ç¯‡](https://realpython.com/python-pickle-module/)äº†è§£æ›´å¤šå…³äºè…Œåˆ¶çš„çŸ¥è¯†ã€‚

Pickle éœ€è¦äºŒè¿›åˆ¶æ•°æ®ï¼Œå› æ­¤æˆ‘ä»¬å°†ä»¥â€˜Rbâ€™çš„å½¢å¼æ‰“å¼€æ–‡ä»¶ï¼Œå¹¶ä½¿ç”¨ pickle load()æ–¹æ³•å’Œâ€˜latin1â€™ç¼–ç åŠ è½½å®ƒã€‚

è®©æˆ‘ä»¬é¦–å…ˆå¯¼å…¥æˆ‘ä»¬å°†åœ¨é¢„å¤„ç†ä¸­ä½¿ç”¨çš„åº“ã€‚

```
**import** pickle
**import** pandas **as** pd
**import** numpy **as** np
**import** matplotlib.pyplot **as** **plt**
**from** pylab **import** rcParams
%matplotlib inline
**import** keras **from** keras.utils **import** to_categorical
```

ä¸‹é¢æ˜¯è¯»å–è¿™äº›æ–‡ä»¶çš„ä»£ç ã€‚

```
*#function to read files present in the Python version of the dataset*
**def** unpickle(file):
    **with** open(file, 'rb') **as** fo:
        myDict = pickle.load(fo, encoding='latin1')
    **return** myDict
```

[é˜…è¯»è¿™ä¸ª](https://stackoverflow.com/questions/4792764/why-does-everyone-use-latin1#:~:text=The%20reason%20that%20ISO%208859,set%20for%20internet%20based%20technologies.&text=ISO%208859%2D1%20contains%20256,is%20encoded%20with%20011110112.)å°±çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘ä»¬å¤§å¤šä½¿ç”¨â€˜latin1â€™ä½œä¸ºç¼–ç ã€‚

ç°åœ¨è®©æˆ‘ä»¬åŠ è½½æˆ‘ä»¬çš„è®­ç»ƒé›†ã€‚

```
trainData = unpickle('train')#type of items in each file
**for** item **in** trainData:
    **print**(item, type(trainData[item]))
```

è¾“å‡ºå¦‚ä¸‹æ‰€ç¤º:

```
filenames <class 'list'>
batch_label <class 'str'>
fine_labels <class 'list'>
coarse_labels <class 'list'>
data <class 'numpy.ndarray'>
```

åŸ¹è®­æ–‡ä»¶ä¸­æœ‰ä¸Šè¿°é¡¹ç›®ã€‚coarse_labels å’Œ fine_labels æ˜¯å›¾åƒçš„æ ‡ç­¾(åˆ†åˆ«ä¸º 20ã€100)ï¼Œæ•°æ®æ–‡ä»¶å…·æœ‰ NumPy æ•°ç»„å½¢å¼çš„å›¾åƒæ•°æ®ï¼Œfilenames æ˜¯è¯´æ˜æ–‡ä»¶åçš„åˆ—è¡¨ï¼Œbatch_label æ˜¯æ‰¹æ¬¡çš„æ ‡ç­¾ã€‚

è®©æˆ‘ä»¬æ£€æŸ¥æ•°æ®é›†çš„é•¿åº¦ã€‚

```
**print**(**len**(trainData['data']))
**print**(**len**(trainData['data'][0]))
```

è¾“å‡ºå¦‚ä¸‹æ‰€ç¤º:

```
50000
3072
```

å› æ­¤ï¼Œè®­ç»ƒæ•°æ®é›†ä¸­æœ‰ 50ï¼Œ000 ä¸ªå›¾åƒï¼Œæ¯ä¸ªå›¾åƒéƒ½æ˜¯ 3 é€šé“ 32 Ã— 32 åƒç´ å›¾åƒ(32 Ã— 32 Ã— 3 = 3072)ã€‚

è®©æˆ‘ä»¬æ¥çœ‹çœ‹ç‹¬ç‰¹çš„ç²¾ç¾æ ‡ç­¾ã€‚

```
**print**(**np.unique**(trainData['fine_labels']))
```

è¾“å‡ºå¦‚ä¸‹æ‰€ç¤º:

```
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99]
```

å› æ­¤ï¼Œä» 0 åˆ° 99 çš„å›¾åƒæœ‰ 100 ä¸ªä¸åŒçš„ç²¾ç»†æ ‡ç­¾ã€‚

ç°åœ¨è®©æˆ‘ä»¬æ¥çœ‹çœ‹ç‹¬ç‰¹çš„ç²—æ ‡ç­¾ã€‚

```
**print**(**np.unique**(trainData['coarse_labels']))
```

è¾“å‡ºå¦‚ä¸‹æ‰€ç¤º:

```
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
```

å› æ­¤ï¼Œä» 0 åˆ° 19 çš„å›¾åƒæœ‰ 20 ä¸ªä¸åŒçš„ç²—ç•¥æ ‡ç­¾ã€‚

è®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹ batch_label æ–‡ä»¶ä¸­æœ‰ä»€ä¹ˆã€‚

```
**print**(trainData['batch_label'])
```

è¾“å‡ºå¦‚ä¸‹æ‰€ç¤º:

```
training batch 1 of 1
```

è¿™é‡Œæˆ‘ä»¬åªæœ‰ä¸€ä¸ªæ‰¹å¤„ç†ï¼Œæ‰€ä»¥ batch_label æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚

ç”±äºæˆ‘ä»¬å·²ç»å®Œæˆäº†å¯¹è®­ç»ƒæ•°æ®é›†ä¸­é™¤æ•°æ®æ–‡ä»¶æœ¬èº«ä»¥å¤–çš„ä¸åŒæ–‡ä»¶çš„ç ”ç©¶ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬é¦–å…ˆè§£é™¤å¯¹æµ‹è¯•æ•°æ®é›†å’Œå…ƒæ•°æ®æ–‡ä»¶çš„æ£€æŸ¥ã€‚

```
testData = **unpickle**('test')metaData = **unpickle**('meta')#metaData
**print**("Fine labels:", metaData['fine_label_names'], "\n")
**print**("Coarse labels:", metaData['coarse_label_names'])
```

å…ƒæ–‡ä»¶æœ‰ä¸€ä¸ªç²¾ç»†æ ‡ç­¾å’Œç²—ç³™æ ‡ç­¾çš„å­—å…¸ã€‚ä¸ºäº†æ¸…æ¥šèµ·è§ï¼Œæˆ‘å°†å®ƒä»¬åˆ†å¼€æ‰“å°ã€‚è¿™é‡Œæ˜¯è¾“å‡ºã€‚

```
Fine labels: ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm'] Coarse labels: ['aquatic_mammals', 'fish', 'flowers', 'food_containers', 'fruit_and_vegetables', 'household_electrical_devices', 'household_furniture', 'insects', 'large_carnivores', 'large_man-made_outdoor_things', 'large_natural_outdoor_scenes', 'large_omnivores_and_herbivores', 'medium_mammals', 'non-insect_invertebrates', 'people', 'reptiles', 'small_mammals', 'trees', 'vehicles_1', 'vehicles_2']
```

æˆ‘ä»¬çš„ä»»åŠ¡å°†æ˜¯è¯†åˆ«å›¾åƒï¼Œå¹¶ä¸ºå®ƒä»¬æä¾›è‰¯å¥½çš„æ ‡ç­¾ã€‚

ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨æ ‡ç­¾åˆ›å»ºæ•°æ®å¸§ï¼Œè¿™å°†æœ‰åŠ©äºæˆ‘ä»¬çš„å¯è§†åŒ–ã€‚

```
*#storing coarse labels along with its number code in a dataframe*
category = **pd.DataFrame**(metaData['coarse_label_names'], columns=['SuperClass'])*#storing fine labels along with its number code in a dataframe*
subCategory = **pd.DataFrame**(metaData['fine_label_names'], columns=['SubClass'])**print**(category)
**print**(subCategory)
```

ä¸¤ä¸ªæ•°æ®å¸§çš„ä¸€ç¥:

![](img/b94b6b94889f385e2d608ee37deb9fc9.png)

ä½œè€…å›¾ç‰‡

![](img/6a5b08336f528063c5db405873da2420.png)

ä½œè€…å›¾ç‰‡

ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬çš„æ•°æ®ã€‚

```
X_train = trainData['data']
X_train
```

è¾“å‡ºæ˜¯ä¸€ä¸ª NumPy æ•°ç»„ã€‚

```
array([[255, 255, 255, ...,  10,  59,  79],
       [255, 253, 253, ..., 253, 253, 255],
       [250, 248, 247, ..., 194, 207, 228],
       ...,
       [248, 240, 236, ..., 180, 174, 205],
       [156, 151, 151, ..., 114, 107, 126],
       [ 31,  30,  31, ...,  72,  69,  67]], dtype=uint8)
```

ä¸ºäº†æ‰§è¡Œå›¾åƒè¯†åˆ«å’Œåˆ†ç±»çš„ä»»åŠ¡ï¼Œå¿…é¡»å»ºç«‹å·ç§¯ç¥ç»ç½‘ç»œï¼Œè¯¥ç½‘ç»œéœ€è¦ 4D é˜µåˆ—ä½œä¸ºè¾“å…¥ã€‚å› æ­¤ï¼Œå¿…é¡»å¯¹æ•°æ®è¿›è¡Œè½¬æ¢ï¼Œä»¥è·å¾—è¯¥å½¢çŠ¶ã€‚

ä¾‹å¦‚ï¼Œè®­ç»ƒæ•°æ®é›†æœ‰ 50000 ä¸ªå½¢çŠ¶ä¸º(50000ï¼Œ3072)çš„å›¾åƒï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ä½¿ç”¨ NumPy æ•°ç»„çš„æ•´å½¢å’Œè½¬ç½®æ“ä½œæ¥è½¬æ¢è¿™äº›å›¾åƒï¼Œä»¥è·å¾—ä»¥ä¸‹å½¢çŠ¶:

**(å®ä¾‹æ•°Ã—å®½Ã—é«˜Ã—æ·±)**

å®½åº¦ã€é«˜åº¦å’Œæ·±åº¦æ˜¯å›¾åƒçš„å°ºå¯¸ï¼Œå…¶ä¸­æ·±åº¦åªæ˜¯å›¾åƒä¸­é¢œè‰²é€šé“çš„æ•°é‡ï¼Œåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯ 3ï¼Œå› ä¸ºå›¾åƒæ˜¯ RGBã€‚ä¸‹å›¾è¯´æ˜äº†å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹çš„ 4D è¾“å…¥å½¢å¼ã€‚

![](img/944f7e2686d9e94ac426385ab654cf35.png)

ä½œè€…å›¾ç‰‡

è®©æˆ‘ä»¬ä¸ºè¿™ç§å›¾åƒè½¬æ¢ç¼–å†™ä»£ç ã€‚

```
*#4D array input for building the CNN model using Keras*
X_train = X_train.**reshape**(**len**(X_train),3,32,32).**transpose**(0,2,3,1)
*#X_train*
```

æˆ‘ä»¬ç°åœ¨å·²ç»å®Œæˆäº†è½¬å‹ã€‚è®©æˆ‘ä»¬åˆ›å»ºå¯è§†åŒ–æ¥çœ‹è¿™äº›å›¾åƒã€‚

# å¯è§†åŒ–:

```
*#generating a random number to display a random image from the dataset along with the label's number and name*#setting the figure size
**rcParams**['figure.figsize'] = 2,2#generating a random number
imageId = **np.random.randint**(0, **len**(X_train))#showing the image at that id
**plt**.**imshow**(X_train[imageId])#setting display off for the image
**plt.axis**('off')#displaying the image id
**print**("Image number selected : **{}**".**format**(imageId))#displaying the shape of the image **print**("Shape of image : **{}**".**format**(X_train[imageId].**shape**))#displaying the category number **print**("Image category number: **{}**".**format**(trainData['coarse_labels'][imageId]))#displaying the category name
**print**("Image category name: **{}**".format(category.**iloc**[trainData['coarse_labels'][imageId]][0].**capitalize**()))#displaying the subcategory number
**print**("Image subcategory number: **{}**".**format**(trainData['fine_labels'][imageId]))#displaying the subcategory name
**print**("Image subcategory name: **{}**".format(subCategory.**iloc**[trainData['fine_labels'][imageId]][0].**capitalize**()))
```

è¾“å‡ºå¦‚ä¸‹æ‰€ç¤º:

![](img/48f1dfadc157b332588fad25c23c715e.png)

ä½œè€…å›¾ç‰‡

è®©æˆ‘ä»¬å±•ç¤ºæ›´å¤šçš„å›¾åƒã€‚

```
*#16 random images to display at a time along with their true labels*#setting the figure size
**rcParams**['figure.figsize'] = 8,8#number of columns and rows in which images needs to be displayed
num_row = 4
num_col = 4*#to get 4 * 4 = 16 images together*
imageId = **np.random.randint**(0, **len**(X_train), num_row * num_col)#creating subplots
fig, axes = **plt.subplots**(num_row, num_col)#main title of the plot **plt.suptitle**('Images with True Labels', fontsize=18)#displaying images as subplots
**for** i **in** **range**(0, num_row):
    **for** j **in** **range**(0, num_col):
        k = (i*num_col)+j
        axes[i,j].**imshow**(X_train[imageId[k]])
       axes[i,j].**set_title**(subCategory.**iloc**[trainData['fine_labels'][imageId[k]]][0].**capitalize**())
        axes[i,j].**axis**('off')
```

![](img/904263a645a5cf0f41427166c60d4483.png)

ä½œè€…å›¾ç‰‡

æˆ‘ä»¬å¯ä»¥ä»å¯è§†åŒ–ä¸­çœ‹åˆ°ï¼Œå›¾åƒçš„è´¨é‡å¾ˆä½ï¼Œå¹¶ä¸”å¯¹è±¡åœ¨å›¾åƒä¸­çš„ä½ç½®å˜åŒ–å¾ˆå¤§ã€‚å¾ˆéš¾è®­ç»ƒä¸€ä¸ªæ¨¡å‹æ¥è¯†åˆ«å’Œåˆ†ç±»è¿™æ ·çš„å›¾åƒã€‚ğŸ™†ğŸ»

ç°åœ¨è®©æˆ‘ä»¬æ¥å¤„ç†æµ‹è¯•æ•°æ®é›†ã€‚

```
*#transforming the testing dataset*
X_test = testData['data']
X_test = X_test.**reshape**(**len**(X_test),3,32,32).**transpose**(0,2,3,1)y_train = trainData['fine_labels']
y_test = testData['fine_labels']
```

ä¸ºäº†è¿›è¡Œé¢„æµ‹ï¼Œå›¾åƒçš„æ ‡ç­¾å·²ç»ä»ç°æœ‰çš„ 1D NumPy é˜µåˆ—ç»“æ„è½¬æ¢æˆåˆ†ç±»çŸ©é˜µç»“æ„ã€‚

```
#number of classes in the dataset
n_classes = 100y_train = **to_categorical**(y_train, n_classes)
y_test = **to_categorical**(y_test, n_classes)
```

æˆ‘ä»¬ç°åœ¨å·²ç»å®Œæˆäº†é¢„å¤„ç†ï¼Œæˆ‘ä»¬å°†åœ¨[çš„å¦ä¸€ç¯‡æ–‡ç« ](/cifar-100-transfer-learning-using-efficientnet-ed3ed7b89af2)ä¸­ç ”ç©¶å¦‚ä½•ä¸ºè¿™ä¸ªæ•°æ®é›†æ„å»ºå·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚

è¿™é‡Œæ˜¯åˆ° [GitHub ä»“åº“](https://github.com/chetnakhanna16/CIFAR100_ImageRecognition/blob/master/EffiicientNetB0_CIFAR100.ipynb)çš„é“¾æ¥ï¼Œé‡Œé¢æœ‰æ‰€æœ‰è¿™äº›ä»£ç ã€‚è¯·åœ¨æ‚¨çš„å·¥ä½œä¸­éšæ„ä½¿ç”¨å®ƒæ¥è®­ç»ƒä¸€ä¸ªå¯ä»¥å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»çš„ç»å…¸ CNN æ¨¡å‹ã€‚ğŸ˜Š

**ç›¸å…³æ–‡ç« :**

[](/cifar-100-transfer-learning-using-efficientnet-ed3ed7b89af2) [## CIFAR 100:ä½¿ç”¨ EfficientNet è¿›è¡Œè¿ç§»å­¦ä¹ 

### ä½¿ç”¨æœ€å…ˆè¿›çš„ EfficientNet-B0 è¿›è¡Œè¿ç§»å­¦ä¹ 

towardsdatascience.com](/cifar-100-transfer-learning-using-efficientnet-ed3ed7b89af2) 

è°¢è°¢å¤§å®¶é˜…è¯»è¿™ç¯‡æ–‡ç« ã€‚è¯·åˆ†äº«æ‚¨å¯¹è¿™ç¯‡æ–‡ç« çš„å®è´µåé¦ˆæˆ–å»ºè®®ï¼å¿«ä¹é˜…è¯»ï¼ğŸ“— ğŸ–Œ

[é¢†è‹±](https://www.linkedin.com/in/chetna-khanna/)