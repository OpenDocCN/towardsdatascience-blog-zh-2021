# æ„å»ºæœ´ç´ è´å¶æ–¯æœºå™¨å­¦ä¹ æ¨¡å‹å¯¹æ–‡æœ¬è¿›è¡Œåˆ†ç±»

> åŸæ–‡ï¼š<https://towardsdatascience.com/building-a-naive-bayes-machine-learning-model-to-classify-text-71431ce20844?source=collection_archive---------8----------------------->

## è¿™æ˜¯ä¸€ä¸ªå¿«é€Ÿå…¥é—¨æŒ‡å—ï¼Œå¸®åŠ©æ‚¨ä½¿ç”¨ Python å¯åŠ¨å¹¶è¿è¡Œä¸€ä¸ªç®€å•è€Œé«˜åº¦ç›¸å…³çš„ NLP é¡¹ç›®

![](img/5c11216ee79cb4bbccae08622b521e2e.png)

Python ä¸­çš„æœ´ç´ è´å¶æ–¯(æ‰€æœ‰å›¾ç‰‡ç”±ä½œè€…æä¾›)

# ä»‹ç»

è‡ªç„¶è¯­è¨€å¤„ç†(NLP)æ˜¯ä¸€ä¸ªéå¸¸ä»¤äººå…´å¥‹çš„é¢†åŸŸã€‚å®ƒä½äºè®¡ç®—æœºç§‘å­¦ã€è¯­è¨€å­¦å’Œäººå·¥æ™ºèƒ½çš„äº¤æ±‡ç‚¹ï¼Œå…³æ³¨äººç±»è¯­è¨€å’Œè®¡ç®—æœºä¹‹é—´çš„äº¤äº’ã€‚æ›´å…·ä½“åœ°è¯´:å®ƒçš„ç›®æ ‡æ˜¯ç†è§£å¦‚ä½•ç»™è®¡ç®—æœºç¼–ç¨‹ï¼Œä»¥ç†è§£å’Œè§£é‡Šæˆ‘ä»¬çš„è‡ªç„¶è¯­è¨€ã€‚

ç°åœ¨è¿™æ˜¯ä¸€ä¸ªéå¸¸çƒ­é—¨çš„ç ”ç©¶é¢†åŸŸï¼Œæˆ‘å¾ˆå¹¸è¿èƒ½å¤Ÿåœ¨è¿™ä¸ªç ”ç©¶é¢†åŸŸç»å¯¹å‰æ²¿çš„å¤§å­¦å°±è¯»ã€‚è™½ç„¶ä½œä¸ºä¸€åå‘å¾®çš„æœ¬ç§‘ç”Ÿï¼Œæˆ‘å¹¶ä¸ç»å¸¸æ¥è§¦è¿™ç§å‰æ²¿å·¥ä½œâ€”â€”å¦‚æœæˆ‘æ¥è§¦äº†ï¼Œæˆ‘ä¼šç†è§£çš„ï¼

å°½ç®¡å¦‚æ­¤ï¼Œå»ºç«‹æ¨¡å‹å¯¹è‡ªç„¶è¯­è¨€è¿›è¡Œåˆ†ç±»è¿˜æ˜¯ç›¸å¯¹ç®€å•çš„ã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆé…·çš„ç»ƒä¹ ï¼Œå› ä¸ºå®ƒæ˜¯ç›¸å…³çš„ã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸çœŸå®çš„ ML åº”ç”¨ï¼Œä½ å¯ä»¥åœ¨è‡ªå·±çš„é¡¹ç›®ä¸­ä½¿ç”¨ã€‚

![](img/bc9c8ffd4a5dfad928137df59c00fc98.png)

è´å¶æ–¯å®šç†

# æœ´ç´ è´å¶æ–¯

æœ´ç´ è´å¶æ–¯ç®—æ³•æ˜¯ä¸€ç§æ›´ç®€å•çš„ç›‘ç£è´å¶æ–¯ç½‘ç»œæ¨¡å‹ï¼Œå®ƒæ˜¯ä¸€ç§åŸºäºè´å¶æ–¯å®šç†çš„æ¦‚ç‡åˆ†ç±»å™¨(æ‚¨å¯èƒ½è¿˜è®°å¾—é«˜ä¸­çš„ç»Ÿè®¡æ•°æ®)ã€‚ä½†å®ƒçš„ç®€å•æ€§å¹¶ä¸ä½¿å®ƒæˆä¸ºä¸€ä¸ªç³Ÿç³•çš„é€‰æ‹©ï¼Œå³ä½¿æ•°æ®é›†ä¸æ˜¯å¾ˆå¤§(åªæœ‰å‡ åƒä¸ªæ ·æœ¬)ï¼Œå®ƒä¹Ÿå¯ä»¥äº§ç”Ÿé«˜åº¦å‡†ç¡®çš„é¢„æµ‹ã€‚

å¦‚æœä½ çœŸçš„æ˜¯æœºå™¨å­¦ä¹ çš„æ–°æ‰‹ï¼Œæˆ‘å»ºè®®é˜…è¯»ä¸€äº›å…³äºæ›´åŸºæœ¬ç®—æ³•çš„æ–‡ç« ï¼Œç„¶åå›åˆ°è¿™ä¸€ç¯‡ï¼Œå› ä¸ºæˆ‘å°†å»ºç«‹åœ¨è¿™äº›æ–‡ç« ä¸­è¯¦ç»†è§£é‡Šçš„æ¦‚å¿µä¸Šã€‚

[](/k-means-clustering-for-beginners-ea2256154109) [## é€‚ç”¨äºåˆå­¦è€…çš„ k-å‡å€¼èšç±»

### ä¸€ä¸ªæ·±å…¥çš„è§£é‡Šå’Œä¸€æ­¥ä¸€æ­¥çš„æŒ‡å¯¼è¿™ä¸ªæœ‰è¶£å’Œæœ‰ç”¨çš„æœºå™¨å­¦ä¹ ç®—æ³•åœ¨ Python ä¸­ï¼Œç”±â€¦

towardsdatascience.com](/k-means-clustering-for-beginners-ea2256154109) 

æœ¬è´¨ä¸Šï¼Œä¸¤ä¸ªäº‹ä»¶å‘ç”Ÿçš„æ¡ä»¶æ¦‚ç‡æ˜¯æ ¹æ®æ¯ä¸ªäº‹ä»¶çš„æ¡ä»¶æ¦‚ç‡è®¡ç®—å‡ºæ¥çš„ã€‚å› æ­¤ï¼Œå¯¹äºç»™å®šçš„ä¸€æ®µæ–‡æœ¬ï¼Œè®¡ç®—æ¯ä¸ªæ ‡ç­¾çš„æ¦‚ç‡ï¼Œå¹¶è¾“å‡ºå…·æœ‰æœ€é«˜æ¦‚ç‡çš„æ ‡ç­¾ã€‚

è¿˜æœ‰å…¶ä»–åˆé€‚çš„é€‰æ‹©ï¼Œå¦‚æ”¯æŒå‘é‡æœº(SVM)ï¼Œå®ƒéœ€è¦æ›´å¤šçš„æ—¶é—´å’Œè®¡ç®—èµ„æºæ¥å·¥ä½œï¼Œä½†ä¼šäº§ç”Ÿæ¯”æœ´ç´ è´å¶æ–¯æ›´å‡†ç¡®çš„é¢„æµ‹ã€‚æˆ–è€…ï¼Œæ‚¨å¯ä»¥è€ƒè™‘åŸºäºç¥ç»ç½‘ç»œçš„æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œä½†è¿™å°†éœ€è¦æ›´å¤šçš„è®­ç»ƒæ•°æ®ã€‚

![](img/2bcc7f06abc6828b28732716a6c7ce80.png)

ç±³å¡Â·é²æ¢…æ–¯ç‰¹åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šçš„ç…§ç‰‡

# è¿™ä¸ªä¾‹å­

è¿™æ˜¯ä¸€ç§æ–¹æ³•:

1.  å¯¼å…¥å’Œè®¾ç½®æ•°æ®ã€‚
2.  åšä¸€äº›åˆ†æä»¥äº†è§£æ›´å¤šå…³äºæ•°æ®ç¯å¢ƒçš„ä¿¡æ¯ã€‚
3.  åˆ›å»ºæˆ‘ä»¬çš„å› å˜é‡å’Œè‡ªå˜é‡åˆ—è¡¨ï¼Œç”¨äºè®­ç»ƒå’ŒéªŒè¯ã€‚
4.  ç»™æ ‡ç­¾ç¼–ç ã€‚
5.  ä»æè¿°ä¸­æå–ç‰¹å¾ã€‚
6.  ä½¿æ•°æ®ç¬¦åˆæ¨¡å‹ã€‚
7.  æ£€æŸ¥æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚

è¿™ä¸ªé¡¹ç›®å°†æ¼”ç¤ºå¦‚ä½•æ ¹æ®é“¶è¡Œäº¤æ˜“çš„æè¿°å¯¹å…¶è¿›è¡Œåˆ†ç±»ã€‚æˆ‘çš„æ•°æ®é›†åŒ…å« 12500 ä¸ªæ ·æœ¬ï¼ŒåŒ…æ‹¬äº¤æ˜“é‡‘é¢å’Œäº¤æ˜“ç±»å‹ç­‰å…¶ä»–ç‰¹å¾ï¼Œæ‚¨å¯ä»¥åœ¨æ¨¡å‹ä¸­ä½¿ç”¨ä»»æ„æ•°é‡çš„ç‰¹å¾ï¼Œç”šè‡³å¯ä»¥é€‰æ‹©ä¸€äº›ç‰¹å¾æ¥æŸ¥çœ‹å“ªäº›ç‰¹å¾å¯¹é¢„æµ‹çš„å½±å“æœ€å¤§ï¼Œä½†ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å°†åªä½¿ç”¨æè¿°ã€‚

åœ¨æˆ‘çš„æ•°æ®é›†ä¸­ï¼Œæè¿°æ˜¯è¿™æ ·çš„:

```
citylink
1Jul19 OYSTER
travelodge
6Jul19 RINGGO
SUNDRY DEBIT CONTACTLESS CAMDEN PARKING
stgcoach
trainline
Fin: CMT UK LTD  Cash at Transact
```

## è®¾ç½®

å½“ç„¶ï¼Œä»è¿›å£å¼€å§‹ã€‚

1.  åˆ›å»ºæ•°æ®æ¡†æ¶çš„ç†ŠçŒ«ã€‚
2.  sci kit-äº†è§£æ ‡ç­¾ç¼–ç ã€ç‰¹å¾æå–ã€å»ºæ¨¡å’Œæµ‹é‡æˆåŠŸæŒ‡æ ‡

```
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import CountVectorizer
from sklearn import naive_bayes, metrics
```

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å¤„ç† csv æ–‡ä»¶ï¼Œå¹¶ä¸ºæ¨¡å‹åšå¥½å‡†å¤‡ã€‚(å½“ç„¶ï¼Œä½ å¯èƒ½æ²¡æœ‰å¤„ç† csv æ–‡ä»¶ï¼Œåªæ˜¯æŠŠä½ æ‰€æœ‰çš„æ•°æ®å¯¼å…¥åˆ°ç†ŠçŒ«æ•°æ®æ¡†æ¶ä¸­):

```
features = pd.read_csv("bank_transaction_features.csv")
labels = pd.read_csv("bank_transaction_labels.csv")
```

æˆ‘æœ‰ä¸¤ä¸ªæ•°æ®é›†:ä¸€ä¸ªåŒ…å«è¦ç´ ï¼Œä¸€ä¸ªåŒ…å«æ ‡æ³¨(ç±»åˆ«)ã€‚è¿™äº›æ˜¯å®ƒä»¬å„è‡ªçš„åˆ—:

```
**bank_transaction_features:**
bank_transaction_id, bank_transaction_amount, bank_transaction_type**bank_transaction_labels:**
bank_transaction_id, bank_transaction_category, bank_transaction_dataset
```

å®ƒä»¬æœ‰ä¸€ä¸ªå…±åŒç‚¹ï¼ŒID åˆ—ã€‚å› æ­¤ï¼Œæˆ‘å°†åœ¨è¿™ä¸€åˆ—ä¸­åˆå¹¶å®ƒä»¬ï¼Œå¹¶åˆ é™¤ä»»ä½•å…·æœ‰ç©ºæ¡ç›®çš„è¡Œ(åœ¨æˆ‘çš„æ•°æ®ä¸­å¾ˆå°‘ï¼Œæ‚¨åº”è¯¥è®¡ç®—æœ‰å¤šå°‘ï¼Œå› æ­¤åˆ é™¤å®ƒä»¬å¯¹é¢„æµ‹çš„å½±å“å¯ä»¥å¿½ç•¥ä¸è®¡):

```
combined_df = pd.merge(left=features, right=labels)
combined_df = combined_df.dropna()
```

## æ¢ç´¢æ€§åˆ†æ

æ€»æ˜¯ä»ä¸€äº›æ¢ç´¢æ€§çš„æ•°æ®åˆ†æå¼€å§‹ã€‚æˆ‘çš„æ•°æ®é›†æœ‰æ•°ä»¥åƒè®¡çš„æ ·æœ¬ï¼Œæˆ‘æ— æ³•é€šè¿‡æ‰«æçœ‹åˆ°æ‰€æœ‰çš„ç±»åˆ«ã€‚æˆ‘ä»¬éœ€è¦åšä¸€äº›ç®€å•çš„äº‹æƒ…æ¥æ›´å¥½åœ°ç†è§£æ•°æ®ã€‚

è¯¥æ•°æ®é›†æœ‰ä¸€åˆ—æŒ‡å®šæ ·æœ¬æ˜¯ç”¨äºè®­ç»ƒè¿˜æ˜¯éªŒè¯ã€‚è¿™å°†åœ¨ä»¥åæ´¾ä¸Šç”¨åœºï¼Œå› ä¸ºæˆ‘ä»¬ä¸éœ€è¦åˆ›å»ºæˆ‘ä»¬è‡ªå·±çš„è®­ç»ƒ/éªŒè¯åˆ†å‰²ã€‚ä½†æ˜¯å¯¹äºæ¢ç´¢æ€§åˆ†æï¼Œæˆ‘ä»¬å¯ä»¥åˆ é™¤è¯¥åˆ—(åªä»æˆ‘ä»¬å°†åˆ›å»ºçš„æ–° dataframe å˜é‡ä¸­åˆ é™¤è¯¥åˆ—ï¼Œä¿ç•™åŒ…å«è¯¥åˆ—çš„å˜é‡)ã€‚

```
explore_df = combined_df.drop(labels=['bank_transaction_dataset'], axis=1)
```

æˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°çœ‹åˆ°æ•°æ®ä¸­å­˜åœ¨å“ªäº›ç±»åˆ«ï¼Œä»¥åŠæ¯ä¸ªç±»åˆ«ä¸­æœ‰å¤šå°‘ä¸ªæ ·æœ¬:

```
print(explore_df['bank_transaction_category'].value_counts())
```

ç»“æœæ˜¯:

```
ACCOMMODATION_AND_MEALS    3765
TRAVEL                     3166
BANK_OR_FINANCE_CHARGES    2659
MOTOR_EXPENSES             1609
INSURANCE                  1170
Name: bank_transaction_category, dtype: int64
```

ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹åŸ¹è®­/éªŒè¯åˆ†å‰²æ˜¯ä»€ä¹ˆ(ä½¿ç”¨ä»æœ‰ç›¸å…³åˆ—çš„æ•°æ®å¸§):

```
train_set = combined_df.loc[combined_df["bank_transaction_dataset"] == "TRAIN"]
val_set = combined_df.loc[combined_df["bank_transaction_dataset"] == "VAL"]

len_train = len(train_set)
len_val = len(val_set)
len_whole = len(explore_df)
print('Amount of training data: ', len_train)
print('Amount of validation data: ', len_val)
```

è¾“å‡º:

```
Amount of training data:  9891
Amount of validation data:  2478
```

è¿™ä½¿å¾—è®­ç»ƒ/éªŒè¯çš„æ¯”ä¾‹ä¸º 80/20ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ¯”ä¾‹ï¼Œæ‰€ä»¥æ ¹æœ¬ä¸éœ€è¦è°ƒæ•´ã€‚

## åˆ†ç±»

æœ€åï¼Œæœ‰è¶£çš„éƒ¨åˆ†ã€‚é¦–å…ˆï¼Œåˆ›å»º x å’Œ y è®­ç»ƒå’ŒéªŒè¯å­é›†ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡åˆ›å»ºåªåŒ…å«ç›¸å…³åˆ—ä¸­æ•°æ®çš„åˆ—è¡¨æ¥å®ç°è¿™ä¸€ç‚¹:

```
y_train = train_set['bank_transaction_category'].values
x_train = train_set['bank_transaction_description'].values

y_val = val_set['bank_transaction_category'].values
x_val = val_set['bank_transaction_description'].values
```

ç°åœ¨å˜å¾—éå¸¸æœ‰è¶£äº†ã€‚éœ€è¦è®°ä½çš„æ˜¯ï¼ŒML æ¨¡å‹ä¸â€œç†è§£â€æ–‡æœ¬å’Œå•è¯ã€‚ä»–ä»¬ç†è§£æ•°å­—ã€‚å› æ­¤ï¼Œå‡†å¤‡æ•°æ®ä»¥é€‚åˆæ¨¡å‹çš„ç¬¬ä¸€ä»¶äº‹æ˜¯å¯¹æ ‡ç­¾è¿›è¡Œç¼–ç ã€‚è¿™æ„å‘³ç€ï¼Œç»™æ¯ä¸ªæ ‡ç­¾åˆ†é…ä¸€ä¸ªå·ç ã€‚ä¾‹å¦‚:

```
ACCOMMODATION_AND_MEALS    => 0
TRAVEL                     => 1
BANK_OR_FINANCE_CHARGES    => 2
MOTOR_EXPENSES             => 3
INSURANCE                  => 4
```

è¿™æ˜¯é€šè¿‡åˆ›å»ºä¸€ä¸ª *LabelEncoder* å¯¹è±¡å¹¶å¯¹å› å˜é‡æ•°æ®( *y* )ä½¿ç”¨å…¶ *fit_transform* å‡½æ•°æ¥å®ç°çš„:

```
label_encoder = LabelEncoder()
y_train = label_encoder.fit_transform(y_train)
y_test = label_encoder.fit_transform(y_val)
```

æè¿°æ•°æ®ä¹Ÿæ˜¯å¦‚æ­¤ï¼Œåªæ˜¯è¿™ä¸ªç¨å¾®å¤æ‚ä¸€ç‚¹ã€‚åœ¨ä¸€äº›æ¨¡å‹ä¸­ï¼Œä½ æœ‰ä¸€ç»„ç»Ÿä¸€çš„æè¿°ï¼Œå¹¶ä¸”ä½ çŸ¥é“å®ƒä»¬æ˜¯ä»€ä¹ˆï¼Œä½ å¯ä»¥æŠŠæ¯ä¸€ä¸ªç¼–ç æˆä¸€ä¸ªæ•´æ•°ï¼Œå®ƒä»¬å°±å‡†å¤‡å¥½äº†ã€‚ä½†æ˜¯åœ¨è¿™é‡Œï¼Œæ¯ä¸ªäº‹åŠ¡æè¿°éƒ½å¯èƒ½æ˜¯å”¯ä¸€çš„ã€‚

è§£å†³æ–¹æ¡ˆæ˜¯ä»æ–‡æœ¬ä¸­æå–ç‰¹å¾ï¼Œå¹¶å°†è¿™äº›ç‰¹å¾è½¬åŒ–ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„å‘é‡ã€‚

![](img/84f60785866ddb64a849be931bc0a794.png)

ç‰¹å¾æŠ½å‡º

è™½ç„¶åœ¨æŠ€æœ¯ä¸Šå¾ˆå¤æ‚ï¼Œä½†è¿™å¯ä»¥ç®€å•åœ°å®ç°ï¼Œé€šè¿‡ä½¿ç”¨*è®¡æ•°çŸ¢é‡å™¨*å°†æ–‡æœ¬è½¬æ¢ä¸ºä»¤ç‰ŒçŸ©é˜µï¼Œå¹¶è½¬æ¢è®­ç»ƒå’ŒéªŒè¯ç‹¬ç«‹å˜é‡( *x* ):

```
count_vector = CountVectorizer(analyzer='word', token_pattern=r'\w{1,}')
count_vector.fit(combined_df['bank_transaction_description'])

x_train_count = count_vector.transform(x_train)
x_valid_count = count_vector.transform(x_val)
```

å°±æ˜¯è¿™æ ·ï¼æˆ‘ä»¬å¯ä»¥æ‹Ÿåˆæ•°æ®ã€è®­ç»ƒæ¨¡å‹å¹¶åšå‡ºé¢„æµ‹:

```
classifier = naive_bayes.MultinomialNB()
classifier.fit(x_train_count, y_train)

predictions = classifier.predict(x_valid_count)
```

## å‡†ç¡®(æ€§)

æ‚¨å¯ä»¥ä½¿ç”¨å‡ ä¸ªæŒ‡æ ‡æ¥ç¡®å®šæ¨¡å‹çš„å·¥ä½œæƒ…å†µã€‚æˆ‘ä»¬ä¼šç”¨å‡†ç¡®æ€§ã€‚è¿™å°†å‘Šè¯‰æˆ‘ä»¬æ¨¡å‹æ­£ç¡®é¢„æµ‹é“¶è¡Œäº¤æ˜“ç±»åˆ«çš„é¢‘ç‡:

```
print(metrics.accuracy_score(predictions, y_test))
```

è¯¥æ¨¡å‹çš„ç²¾ç¡®åº¦ä¸º:

```
0.91
```

ä¸€ç‚¹ä¹Ÿä¸å·®ã€‚

# ç»“è®º

è¿™æ˜¯ä¸€ä¸ªæœ‰è¶£çš„ä¾‹å­ï¼Œå› ä¸ºå®ƒæ˜¯æœ‰å½¢çš„ã€‚ä¾‹å¦‚ï¼Œåœ¨ç§»åŠ¨é‡‘èè·Ÿè¸ªåº”ç”¨ç¨‹åºä¸­å°†é“¶è¡Œäº¤æ˜“åˆ†ç±»æ˜¯è¿™ç§ç®—æ³•çš„ä¸€ä¸ªéå¸¸çœŸå®çš„ç”¨ä¾‹ã€‚æˆ‘å¸Œæœ›æ‚¨å¯¹æœ´ç´ è´å¶æ–¯æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œä»¥åŠå¦‚ä½•å®ç°å®ƒå¯¹æ–‡æœ¬è¿›è¡Œåˆ†ç±»æœ‰äº†å¾ˆå¥½çš„ç†è§£ã€‚

å¦‚æœä½ ç¡®å®å­¦åˆ°äº†ä¸€äº›ä¸œè¥¿ï¼Œæœ‰ä»»ä½•é—®é¢˜ï¼Œè®¤ä¸ºæˆ‘é”™è¿‡äº†ä»»ä½•é‡è¦çš„ä¸œè¥¿ï¼Œæˆ–è€…è®¡åˆ’åœ¨ä½ è‡ªå·±çš„é¡¹ç›®ä¸­ä½¿ç”¨è¿™ä¸ªç®—æ³•ï¼Œè¯·é€šè¿‡ç•™ä¸‹å›å¤è®©æˆ‘çŸ¥é“ï¼Œæˆ‘ä»¬å¯ä»¥è®¨è®ºå®ƒã€‚

ç¼–ç å¿«ä¹ï¼

[**è®¢é˜…**](https://medium.com/subscribe/@adenhaus) ğŸ“šä¸ºäº†ä¸é”™è¿‡æˆ‘çš„ä¸€ç¯‡æ–°æ–‡ç« ï¼Œå¦‚æœä½ è¿˜ä¸æ˜¯ä¸€ä¸ªä¸­ç­‰ä¼šå‘˜ï¼Œ[åŠ å…¥](https://medium.com/@adenhaus/membership) ğŸš€å»è¯»æˆ‘æ‰€æœ‰çš„ï¼Œè¿˜æœ‰æˆåƒä¸Šä¸‡çš„å…¶ä»–æ•…äº‹ï¼

# èµ„æº

**Scikit Learn***sk Learn . preprocessing . label encoder*[https://Scikit-Learn . org/stable/modules/generated/sk Learn . preprocessing . label encoder . html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)

**Scikit Learn***sk Learn . feature _ extraction . text . count vectorizer*https://Scikit-Learn . org/stable/modules/generated/sk Learn . feature _ extraction . text . count vectorizer . html

**ç»´åŸºç™¾ç§‘** *è‡ªç„¶è¯­è¨€å¤„ç†*[https://en.wikipedia.org/wiki/Natural_language_processing](https://en.wikipedia.org/wiki/Natural_language_processing)

**MonkeyLearn** *æ–‡æœ¬åˆ†ç±»*ã€https://monkeylearn.com/text-classification/ã€‘T4