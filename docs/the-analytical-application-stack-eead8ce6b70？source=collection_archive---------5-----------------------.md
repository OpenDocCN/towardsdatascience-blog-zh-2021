# 分析应用程序堆栈

> 原文：<https://towardsdatascience.com/the-analytical-application-stack-eead8ce6b70?source=collection_archive---------5----------------------->

## *构建“数据应用”的机遇和挑战*

![](img/62eebe70002c5747df9e33a8499d4342.png)

作者图片

在过去的几年里，数据基础架构发生了巨大的变化。[已经](https://blog.getdbt.com/future-of-the-modern-data-stack/) [被](https://technically.dev/posts/what-your-data-team-is-using) [写成了](https://a16z.com/2020/10/15/the-emerging-architectures-for-modern-data-infrastructure/)关于“现代数据栈”，在这一点上，有大量的创业公司覆盖了数据质量、数据监控、反向 ETL 等领域。

然而，一个不太受关注的领域是构建分析应用程序的堆栈，但这个领域似乎仍然存在巨大的机会。我所说的“分析应用程序”是指**一种面向最终用户的应用程序，其功能本身包含大规模的数据汇总分析**。这有时也被称为“数据应用程序”。

作为一个例子，考虑市场公司。几乎所有的市场都有一个用户界面，让卖家可以看到他们“商店”的汇总数据。许多这样的用户界面允许销售者根据可能与他们相关的各种维度(例如 SKU 或购买者的地理位置)来分割这些数据。在某些情况下，这样的界面还可以提供更丰富的功能，例如诊断为什么销售额在给定的时间范围内发生了变化，或者最近的 SKU 发布会有什么影响。

![](img/be194c59cb6f0a4d0b07764891b4c845.png)

Shopify 的分析仪表板就是“分析应用”的一个例子

随着数据成为我们所做的几乎一切的核心部分，这种类型的产品用例变得越来越普遍。当你点击 Zillow 中的房屋列表时，大量的计算会向你显示他们关于给定房屋列表的所有数据，例如他们的[“zest imate”](https://www.zillow.com/z/zestimate/)。当你与 Wealthfront 的[“路径”](https://blog.wealthfront.com/introducing-path/)功能互动以帮助规划你的财务未来时，一套复杂的[潜在预测和汇总正在引擎盖下发生](https://www.youtube.com/watch?v=x-1lw2bt0cc)。[当您点击“谁查看了我的个人资料？”时，情况也是如此在 LinkedIn](https://engineering.linkedin.com/analytics/real-time-analytics-massive-scale-pinot) 上。 [Stripe 适马](https://stripe.com/sigma)本质上是一款面向商家的嵌入式数据分析工具。

![](img/2a241ef9bd53e5c85ffdb1073c119d9f.png)

Stripe 适马允许商家编写 SQL 并探索他们的业务数据

然而，尽管有越来越多的公司构建这样的产品，但支持它们的工具仍处于萌芽状态。在花了很多时间与应对这一挑战的从业者以及试图解决这一问题的新兴创业公司交谈后，我想概述一下这个市场的现状，以及我认为仍然需要解决的差距。

## **超越嵌入式仪表盘**

乍一看，您可能会问— *“这与嵌入式商业智能仪表板本质上不是一回事吗？上面的 Shopify 例子甚至被称为‘Dashboard’！多年来，我们已经有了解决这个问题的工具。”*

事实上，将分析功能放入应用程序的传统方式是嵌入 BI 工具，如[Looker Embedded Analytics](https://looker.com/product/embedded-analytics)和[Tableau Embedded Analytics](https://www.tableau.com/embedded-analytics)。这些产品非常成功，代表了这些 BI 产品收入的很大一部分(有人估计占 30%)。

然而，与此同时，这些工具几乎普遍不受欢迎，并且对于大多数现代公司的需求来说，它们是非常不充分的解决方案——你很难看到 Stripe 决定围绕嵌入式 Looker 建立 Stripe 适马。

这有几个核心原因。首先，嵌入式分析产品通常以[iframe](https://whatis.techtarget.com/definition/IFrame-Inline-Frame#:~:text=An%20IFrame%20(Inline%20Frame)%20is,advertisement%2C%20into%20a%20Web%20page.)的形式交付。虽然这种方法很简单，但也意味着您对分析应用程序的控制非常有限。从定制的角度来看，这带来了挑战——前端团队无法将定制应用程序逻辑与数据可视化逻辑深度集成——从设计的角度来看，基本上不可能让 iframe 感觉“原生”,从而导致不优雅、低质量的产品体验。

嵌入式分析工具历来以 iframe 为导向，这一事实也说明了困扰这一领域的一个更广泛的问题——传统上，数据科学和分析团队不习惯采用严格的软件工程标准(版本控制、测试、审查、增量推出和回滚等)，但他们一直是嵌入式 iframe 的所有者。产品团队讨厌这一点，因为它经常导致他们很少或根本无法控制的破碎的产品体验。缺乏对精心构建和维护“数据产品”的关注是行业中的一个首要问题，像 [dbt](https://www.getdbt.com/) 这样的工具已经开始在数据基础设施层面上进行改进。然而，这些原理还没有真正应用于分析。简而言之 iframe 不是产品工程和数据团队之间的正确契约。

这些嵌入式解决方案的第二个核心问题是，它们的性能非常差，导致持续的加载障碍和较差的响应能力(很大程度上是因为它们没有利用云数据基础设施中的许多最新进展)。

最后，这些产品最终在交付的最终用户体验方面有很大的局限性——它们看起来和感觉上总是像一个 BI 工具，然而仪表板通常具有有限的效用，并且最有趣的数据用例几乎总是与工作流相关联。

这组约束从根本上与许多现代数据驱动型公司(如 Zillow、Wealthfront、LinkedIn 和上文提到的 Stripe)拥有的用例类型不兼容。因此，在过去的十年里，这些公司中的大多数都不得不自己做一切事情，从数据库优化到 SQL 管理到可视化层，以及这之间的一切。

## 分析应用有独特的限制

对于公司来说，自己构建这一切如此具有挑战性的部分原因是，在许多方面，分析应用程序的约束在数据空间中有些独特，使得很难简单地重新调整传统数据工具的用途。这是以几种方式形成的。

1.  **高并发性** —因为分析应用程序最终服务于最终用户，而不是内部员工或内部系统，所以您必须支持比大多数传统数据工具所设计的数量大得多的并发请求。
2.  **低延迟**—客户通常期望快速、爽快的产品体验。而您的内部数据科学家可能可以等待 5-10 分钟来运行一个查询(尽管可能有点暴躁！)，这对于许多面向用户的应用程序来说是完全行不通的，尤其是当数据分析需要作为产品支持的核心工作流的一部分时。
3.  **软件工程团队成为利益相关者** —让分析应用程序工作需要数据团队(数据平台、数据工程、数据科学)和实际交付产品的产品团队(前端、后端)之间的紧密协作。大多数产品团队对大规模数据基础设施一无所知，他们是大多数数据工具从未设计过的一群用户。此外，这两种角色习惯于完全不同的标准和过程来部署产品——软件团队通常遵循严格的软件开发过程，正如上面在 iframes 的上下文中所讨论的，而像测试、版本控制等技术才刚刚开始在数据中被采用。这会产生很多摩擦。
4.  **分析功能必须是集成的，而不是孤立的—** 最终，分析应用需要数据分析成为产品工作流程的核心组成部分。仅仅展示一些可视化效果是远远不够的——数据分析、可视化和计算需要深入集成到产品本身中。这与大多数数据工具的工作方式截然不同，在大多数数据工具中，笔记本、SQL 编辑器、DBMS 或类似的工具除了分析数据之外什么也不做。举个说明性的例子——在过去十年里，我们看到支付从感觉非常“第三方”(想想当想在易贝购物时被踢出到一个单独的 PayPal 处理网站)，变成深深嵌入结账和电子商务流程的东西(想想 Shopify Pay)。这给用户体验和转化率带来了巨大的好处。同样，数据也不应该被“固定”在产品上。

解决这些约束通常需要跨数据库、缓存层、数据和应用程序之间的“中间件”层以及可视化层进行大量工作。幸运的是，我们开始看到有助于解决这些类别的工具的出现。

![](img/f83352c10a1cfaebfa2616929044363b.png)

剖析分析应用的关键层，以及每层的一些关键人物。还有各种各样的“一体化”工具，旨在简化简单数据应用程序的创建，尽管这些工具在历史上缺乏支持面向外部的应用程序的核心部分所需的性能和灵活性。图片作者。

# 分析应用程序的层

## **数据库层**

在大多数情况下，您不能直接在像雪花这样的数据仓库、像 DataBricks Delta Lake 这样的“湖库”或像 MySQL 这样的传统非列关系数据库上运行分析应用程序。前两个类别主要是为较低的并发性而设计的，您通常会看到与内部商业智能和数据科学工作负载相关的“批处理”操作，而后一个类别更多地是为逐行查询(和写入繁重的工作负载)而不是大规模分析聚合而设计的。

因此，在过去的 3-4 年中，我们已经看到了许多“实时”或“低延迟”内存数据库的出现，它们使权衡更适合于分析应用程序，例如[阿帕奇德鲁伊](https://druid.apache.org/) ( [暗示](https://imply.io/))[阿帕奇皮诺](https://pinot.apache.org/)([StarTree](https://www.startree.ai/))[click house](https://clickhouse.tech/)([alti nity](https://altinity.com/))[Rockset](https://rockset.com/)和[这些工具中有许多是作为公司内部项目出现的，专门处理与构建分析应用程序相关的挑战——例如，Pinot 在 LinkedIn 中作为一种工具出现，用于](https://www.rilldata.com/)[帮助简化“谁查看了我的个人资料？”](https://engineering.linkedin.com/blog/2020/apache-pinot-030-update)。在各种其他架构差异中，这些产品通常针对在内存中保存数据和处理非常高频率的并发查询进行优化，而像雪花这样的数据仓库则针对低成本的磁盘存储进行优化。StarTree 的这篇博客文章很好地深入探讨了面向用户的应用程序的不同方法的优缺点。

值得注意的是，[其中一些产品还强调其产品](https://www.rilldata.com/blog/the-dawn-of-operational-intelligence)的“可操作”或“实时”元素，在这种情况下，它们指的是应用程序以多快的速度读取上游源数据库。在传统的数据仓库设置中，这种传播可能需要几分钟到几小时，但使用这些工具可能只需几秒钟(假设您添加了 Kafka 和 Debezium 等其他技术)。分析应用不一定总是需要这种功能，但在用户必须对世界的变化做出快速反应的特定情况下，这种功能非常重要。

## **缓存和预聚合层**

创建分析应用程序的下一步通常包括构建某种缓存或预聚合层。如果您希望最大限度地减少应用程序面向用户的延迟，这是非常重要的，而且还具有降低成本的优势，因为您可以通过智能缓存显著减少访问数据库的查询数量。虽然前面提到的一些低延迟数据库本身确实包含缓存功能(如 [Rockset](https://rockset.com/blog/elasticsearch-rockset-real-time-analytics-ingestion-indexing/) ，但其他一些则没有(如 [Pinot](https://docs.pinot.apache.org/basics/getting-started/frequent-questions/query-faq#does-pinot-cache-query-results) )。此外，在许多情况下，公司建立或完全依赖低延迟分析数据库是不可行的，在这种情况下，二级缓存层是绝对必要的。这方面的一些例子包括:

1.  您没有数据工程带宽来设置超出雪花的辅助数据存储，但是您希望在雪花或 BigQuery 之上启动一些基本的分析应用程序功能
2.  您的应用程序需要运行在关系数据库之上，而不是像 MySQL 或 Postgres 这样的列数据库之上，但是您的应用程序趋向于包含越来越多的“聚合”查询(而不是纯粹的行级查询),这大大降低了您的应用程序的速度
3.  从成本角度来看，将所有数据保存在内存中的低延迟数据库中是不可行的。在这个“热”环境中，您只能保留过去 24 小时的数据，但是用户有时会运行涉及“更老”数据的查询。

传统上，有几种方法可以解决缓存和预聚合问题，但这些方法都很麻烦，而且通常都不是很好的解决方案。

在数据库方面，一种方法是将预聚合作为附加行存储在数据库中—例如，如果您的数据库存储有关用户页面浏览量的数据，您可以添加辅助行，这些行以一定的频率异步刷新，并表示每个用户的“过去一个月的总页面浏览量”。然后，您可以更新您的查询逻辑，以便在这些聚合值与传入的查询匹配时优先提取它们。不幸的是，这种方法有许多问题，例如维护预聚合和原始数据之间的一致性，在高基数或高维情况下增加大量存储开销，并且通常会增加前端和数据库逻辑的复杂性和维护开销。

在应用程序方面，另一种方法是使用类似于 [Redis](https://redis.io/) 或 [Memcached](http://memcached.org/) 的东西(或这些东西的托管版本，如 AWS ElastiCache)。虽然这种技术允许在应用层创建键值缓存，但它们的缺点是缓存逻辑与前端业务逻辑的耦合非常紧密。这给产品开发带来了巨大的复杂性，因为现在大多数前端的变化都需要前端团队通过像*“我需要更新缓存逻辑吗？这会导致过时读取吗？我需要采用事务并发写入缓存和数据库吗？我何时必须确保直接访问数据库并使缓存失效？”。*

无论您采用哪种方法，另一个挑战是，开发人员最终有责任确定要缓存或预聚合哪些特定内容。这是非常不理想的，因为大多数现代分析应用程序的复杂性和规模是巨大的。哪些维度、值和特征应该被缓存，哪些不应该被缓存，以及部分预聚合的最佳集合是什么，这是一个更适合于机器而不是人类的决定，特别是因为随着时间的推移，在大多数应用程序中查询的性质存在自然漂移和演变。

幸运的是，我们终于开始看到一些大大简化这些问题的工具的出现，如 [Cube.dev](https://cube.dev/) 、 [Polyscale](https://www.polyscale.ai/) 、 [Readyset](https://readyset.io/) 和 [TakeoffDB](https://takeoffdb.com/) 。虽然这些工具在目标堆栈类型、确切功能和技术方法方面略有不同，但它们通常都代表了为现代分析应用解决缓存和预聚合的有趣方式。如果你感兴趣， [Cube 在这里的博客文章](https://cube.dev/blog/introducing-cubestore/)很好地概述了一些不同的缓存和预聚合方法及其相关的权衡，而 [Noria 的论文](https://pdos.csail.mit.edu/papers/noria:osdi18.pdf)也是这一领域很好的进一步阅读材料。

## 中间件层

下一个要解决的问题是——如何让需要将数据集成到应用程序中的产品团队能够方便地访问数据本身？这通常会成为一个特别棘手的问题，因为它涉及到解决数据团队和产品团队之间的接口问题，而这两个团队通常不习惯使用彼此的语言。

这里的第一个问题是创建一个易于产品团队使用的 API。理想情况下，这样的 API 将包括 React 和 Vue 等流行前端框架的 SDK，并消除管理复杂后端 web 服务的需求，只需管理数据库连接(这符合所谓的 [Jamstack](https://jamstack.org/) 的更广泛趋势)。[我之前提到的 Cube.dev](https://cube.dev/) 提供了这方面的功能。Stepzen 是另一家有趣的公司，它使得在所有数据源之上构建 [GraphQL](https://stepzen.com/) 端点变得更加容易。

第二个问题是查询管理。许多数据从业者看到前端团队管理 SQL 查询的方式会感到震惊——通常存在大量重复、大量不正确的逻辑、高度未优化的查询、糟糕的格式，以及普遍缺乏复杂性，导致高实施和可维护性成本。现在围绕“指标层”工具有很多令人兴奋的事情，如 [Minerva](https://medium.com/airbnb-engineering/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70) 和 [Transform](https://transform.co/) ，它们有助于标准化公司中的指标逻辑，在构建分析应用程序的数据团队和产品团队的界面上可能需要类似的功能(我不清楚 Transform 这样的工具是否最终将服务于传统的数据堆栈用例以及分析应用程序用例，或者这两个部分是否会有所不同)。Cube 是我今天看到的唯一一家提供健壮的数据建模和查询管理功能的公司，专门面向分析应用程序。追求[【无头 BI】](https://basecase.vc/blog/headless-bi)的公司也有可能最终解决这个问题。

## 可视化层

最后但同样重要的是，要构建一个分析应用程序，您需要弄清楚如何可视化和创建围绕数据的交互模式。正如已经讨论过的，这种可视化和交互对于产品来说是自然的，并且深深地嵌入到产品中，这是非常重要的。换句话说，数据不能像独立于产品其余部分的一组不相交的仪表板——与数据的交互应该影响产品中的工作流，反之亦然。(这是使用嵌入式 iframes 根本不可能实现的交互类型)

感觉在深入嵌入产品的数据可视化工具中有很大的改进空间。最先进的是各种开源库，比如 [Chart.js](https://www.chartjs.org/) 、 [D3.js](https://d3js.org/) 、 [HighCharts](https://github.com/highcharts/highcharts) 。总的来说，这个领域的工具要么非常简单，但极其有限(难看、弱定制、对图表类型的支持差)，要么非常复杂，但非常强大(难学、难掌握、价值实现时间短、学习曲线高)。事实上，D3 是如此复杂，甚至由 D3 的创造者建立的公司也在它的基础上探索各种抽象来简化 javascript 中的数据可视化工作。

还有各种传统的“BI-esque”产品，如 [Metabase](https://www.metabase.com/) ，它们允许快速创建交互式数据应用，但这些产品实际上是为了解决传统的内部数据探索用例，而不是为现代分析应用提供动力。它们遭遇了我们已经讨论过的关于性能、原生感觉、深入嵌入应用程序以及不支持 SLDC 原则(如测试)的相同问题。

[Topcoat Data](https://www.topcoatdata.com/) 是这个领域中一家有趣的新公司。对于熟悉 DBT 的数据科学家或类似人员来说，Topcoat 使得以高度自助的方式快速创建成熟的嵌入式仪表板变得极其简单。所有的数据建模都是作为 DBT 的扩展完成的，常见的图表库被原生集成，并且可以应用定制的 CSS。这代表了使用类似 Looker Embedded 这样的东西的巨大进步。然而，请注意，到目前为止，这主要停留在“嵌入式仪表板”用例上，而不是允许高度定制的分析应用程序。

# “一体化”工具

虽然我们已经介绍了构建分析应用程序的所有关键方面，以及有助于实现这些方面的各种工具和技术，但在这一领域还有第二类产品值得考虑，它们垂直集成了堆栈中的一些组件，提供了更多简化的“一体化”体验。这些产品中的大多数都旨在尽可能简单地构建一个数据应用程序，对于数据科学家来说，这是一种理想的伪自助服务方式。

这方面的一个例子是 [Plotly Dash](https://github.com/plotly/dash) ，它使得完全基于 python 脚本部署简单的 Flask web 应用程序变得非常容易，该脚本结合了 python 分析功能和 Plotly 的可视化库。 [Streamlit](https://streamlit.io/) 是这一类别中另一款受人喜爱的产品，专注于使任何数据脚本都可以在几秒钟内成为可共享的 web 应用程序，无需了解前端软件工程。 [Observable](https://observablehq.com/) 可以轻松构建基于 javascript 的数据探索笔记本，它还可以作为可共享的交互式网络应用。

也有各种各样的产品出现，它们可以轻松地在数据科学笔记本上创建快速的网络应用程序，例如， [Hex](https://hex.tech/) 和 [Count](https://count.co/) 可以让您将数据科学笔记本变成交互式数据应用程序。

虽然这些产品使用简单，开发人员体验也很棒，但挑战在于，在大多数情况下，它们主要用于快速原型开发和内部协作。快速拼凑一些东西是非常容易的，但是从那里到一个功能完整的网络应用，成为你产品的核心组件，是一个巨大的飞跃。性能将成为一个问题，与更广泛的产品进行更深入的集成也将成为一个问题。因此，虽然这些产品肯定有明确的用例及位置，但它们并没有真正解决构建分析应用程序的问题。也就是说，有一些新兴公司认为他们的架构可以支持更多的“生产级”用例——一个这样的例子是 [BaseTen](https://www.baseten.co/) ，它主要专注于 ML 驱动的应用。

# 市场中的机会和差距

尽管这个市场的工具状态已经比 5 年前好了几个数量级，但在许多方面，它仍然感觉像是处于早期阶段。根据与该领域从业者的多次交谈，我认为以下几点是最严重的棘手问题:

**缓存和预聚合**

现代应用程序团队在处理自主开发的 Redis 和 Memcached 解决方案以及数据库中自定义维护的预聚合时感到非常痛苦。这些解决方案增加了如此多的复杂性，以至于它们经常使应用程序开发慢如蜗牛。虽然基于 Rockset 等较新工具构建的公司通常可以忽略这些问题，但市场上有大量没有低延迟数据库的公司，或者需要在 Postgres 等关系数据库上构建的公司，他们没有很好的解决方案。

**可视化**

作为分析应用程序的一部分，需要有工具在定制可视化工作的简单性和强大性之间更好地穿针引线。然而，从创业的角度来看，这里的挑战是，与较低级别的计算和存储层相比，传统上很难将前端框架货币化。尽管如此，我接触过的许多公司都会非常感谢更好的解决方案。

**数据库的统一(指标基础设施的融合)**

越来越多的人认为，拥有可以服务于更广泛用例的数据库在技术上是可能的，这消除了对 BI 用例、分析应用用例以及其他用例的专门数据存储的一些需求。WePay 的杰出工程师 Chris Riccomini 在这里发了一条有趣的推文。 [Apache Iceberg 也将我们带向这个方向](https://iceberg.apache.org/)，由于更复杂的元数据和索引管理，即使是传统上“缓慢”的数据存储系统，如 S3，也可以获得极快的分析支持。

像 Pinot 或 Druid 这样的工具是否真的能够成为真正的通用工具还有待观察，但这一方向的进步可能会大大减少您在当今许多数据环境中看到的蔓延和复杂性，并使分析应用程序的基础架构更接近其他数据用例。

**原型开发工具的简单性和定制堆栈的强大功能**

像 Hex、Streamlit 和 Plotly 这样的公司已经构建了非常优雅的产品。问题是——我们能不能保持这些工具的简单性，同时在性能和与更广泛的应用程序开发框架的可组合性方面保留“DIY”堆栈的优势。Preset 最近的博客文章触及了这个问题的各个方面——也许一个开源的、面向社区的商业智能平台也能提供一些。

最终，我不清楚像这样的公司是否会尝试向支持成熟的面向用户的应用程序的方向发展，而不是专注于内部协作、原型、仪表板或非关键的面向用户的应用程序。或者，可能会出现新的全栈分析应用公司，这些公司更注重将这些易用性和时间价值原则应用于任务关键型应用。

**解决产品工程与数据之间的摩擦**

我喜欢 Topcoat 方法的一点是，它支持数据科学家完全自助式地部署嵌入式仪表板，但这种方式比嵌入式 BI 工具好得多(不是 iframe，完全可定制，为利用 DBT 而构建，具有清晰的指标层，支持测试和全面的软件开发原则等)，并且可能更受产品团队的欢迎。这不会解决所有的分析应用用例，但它有一个明确的市场。

对此进行扩展，感觉仍然有机会构建工具，继续抽象数据平台和产品工程之间的接口。这些团队越能自我服务，而不需要对其他团队的工具包有实质性的了解，就越好。Cube.dev 是目前在这一领域引领潮流的另一个产品，但可能还有很多需要改进的地方。

最终，随着越来越多的公司将数据作为核心竞争力，越来越多的产品需要将大规模分析处理作为其核心用户工作流的一部分。数据将越来越成为我们与所用产品交互方式的一个不可分割的重要方面，因此，构建此类分析应用程序的工具的重要性将显著增加。此类应用程序需要具有原生的感觉，在规模上具有高性能(高并发性、高频率、低延迟)，与现代云数据堆栈配合良好，以高度可定制的方式充分融合应用程序和数据逻辑，最重要的是，构建起来更加简单。

如果你在这些问题上遇到了困难，或者正在开发一个产品来解决这个领域的任何问题，我很乐意和你谈谈——davis@innovationendeavors.com。

感谢 Artyom Keydunov、Chris Riccomini 和 Jon Natkins 为本文提供反馈。