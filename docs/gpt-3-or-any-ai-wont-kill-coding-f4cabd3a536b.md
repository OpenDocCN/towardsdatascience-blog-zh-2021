# GPT-3(或任何人工智能)不会杀死编码

> 原文：<https://towardsdatascience.com/gpt-3-or-any-ai-wont-kill-coding-f4cabd3a536b?source=collection_archive---------22----------------------->

## 人工智能|数据科学

## 以下是程序员不需要恐慌的原因。

![](img/d5332c892c63fe6ff7ca31f374eb3cc1.png)

肖恩·斯特拉顿在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

OpenAI 在 2020 年 7 月发布了 GPT-3 的测试版 API。此后不久，开发人员开始对该系统进行试验，并大肆宣传，导致人们对 GPT-3 的威力提出强烈质疑。这个系统被认为是“有知觉的”，能够“推理和理解”，甚至是“一般智能”。

[弗雷德里克·巴斯勒](https://medium.com/u/16c852692647?source=post_page-----f4cabd3a536b--------------------------------)写了[一篇文章](/will-gpt-3-kill-coding-630e4518c04d)在*上疯传，走向数据科学*，他在文章中提出了一个重要的问题:GPT-3 能杀死我们所知的编码吗？几年来，我们已经看到了旨在自动化编码或者至少减少人工参与的趋势。

Bussler 提到 No-code 和 AutoML 是扼杀编码工作未来的力量。无代码是一种设计工具(例如 WordPress ),它允许用户不用编程就能构建复杂的应用程序。AutoML 是一个基于 AI 的端到端解决方案，解决机器学习问题。这两种方法都允许非程序员使用他们力所不及的技术。

GPT 3 号遵循同样的方向。它可以从英文指令中生成代码，这是非程序员的终极梦想。有理由关注新一代人工智能，但也有更充分的理由不要恐慌。让我们看看 GPT-3 能做什么，为什么我们仍然可以和人工智能编码员交朋友。

# GPT-3 的编码技巧

人们发现的最令人惊讶的用例之一是 GPT-3 能够按照自然语言提示(提示是我们输入系统的文本块)进行编码。沙里夫·沙米恩创造了[debuild.co](https://debuild.co/)，一个基于 GPT-3 的代码生成器。他[向](https://twitter.com/sharifshameem/status/1282676454690451457)展示了该系统如何从一组简单的英语指令中构建一个简单的 HTML/CSS/JSX 程序。乔丹·辛格建立了[设计器](https://twitter.com/jsngr/status/1284511080715362304)，一个可以为你设计的 Figma 插件。Amjad Masad 构建了 [Replit](https://twitter.com/amasad/status/1285789362647478272) ，一个解释甚至告诉你如何改进代码的应用程序。

GPT-3 编码怎么能从自然语言中输入呢？原因是它的多任务元学习能力。在看过几个例子后，它可以学习执行没有被训练过的文本任务。沙里夫·沙米恩和他的同伴让 GPT-3 学会了这些任务。元学习是一种令人印象深刻的能力，但我们往往会高估获得人类保留技能的人工智能，GPT-3 也不例外。它可以编码，但不能编码一切。这里有三个重要的限制:

## **小上下文窗口**

GPT 3 号记性很差。它只能记住过去的一个小窗口。你可以给它看几百个字，仅此而已。如果你让它学习编码，你就不能让它学习诗歌。你永远不能要求它在一堆代码之外继续运行一个大程序。GPT 3 号在其背景窗口内给人留下了深刻印象。

## **缺乏问责**

GPT-3 可以做很多事情，但它不能评估它的答案是对还是错——它也不在乎。如果你正在解决一个你不知道答案的问题，有时使用 GPT-3 和猜测一样好。由于这个问题，OpenAI 建议不要将该系统用于“高风险类别”。GPT 3 号不值得信任。

## **对不良提示敏感**

GPT-3 善于学习，就像我们善于提示一样。科技博客作者 Gwern Branwen 证明了良好提示的重要性，并捍卫了 GPT-3 的潜力不能通过采样来定义的观点(每次我们提示 GPT-3 并获得结果，我们都在创建一个样本)。如果我们不知道如何与 GPT-3 交谈，它就不会显示出它的真实知识，它就会犯错误。

> “抽样可以证明知识的存在，但不能证明知识的缺失。
> 
> 如果提示写得不好，GPT-3 可能会“失败”。[……]问题不在于一个给定的提示是否有效，而在于任何提示是否 works⁠."
> 
> —格温·布兰文

# 提示 GPT-3 的不确定性

当我们提示 GPT-3 创建代码时，我们正在编写软件 3.0。Gwern 说，提示应该被理解为一种新的编程范式，不同于传统的编码或神经网络。

例如，当我们用 Python 写程序时，我们使用的是正式语言。有许多方法可以达到相同的解决方案，但是每种方法都必须严格遵循语言的语法规则。没有不确定的空间。你写一个程序，计算机以特定的方式运行，没有松散的解释。

促使 GPT-3 写代码是完全不同的。英语——或任何其他口语——不是正式语言；它是一种自然语言。自然语言不是设计出来的。他们和我们一起进化，充满了暧昧。很多时候，意义只有通过语境信息来完成。书面自然语言失去了部分意义，因此可以用不同的方式解释。这造成了不确定性。对此，我们不得不加上与 GPT-3 的模糊内部工作相对应的不确定性。我们无法接近黑盒，更不用说理解它了。

因此，当我们输入一个英语句子到 GPT 3，它吐出一些东西，有一系列的不确定性可能会完美地导致我们想要的和我们得到的之间的灾难性差异。从这个意义上来说，提示 GPT-3 并不像编码。它可以在某些情况下使用，但不可能在短期内取代所有的编码应用程序。原因很简单，因为这两种方法的本质都是为了解决不同的问题。

# 人工智能不会完全杀死编码

我试图反驳一些关于 GPT-3 威胁编码的观点。现在，我将扩展人工智能的一般论点。程序员不需要那么害怕人工智能有三个强有力的理由:

## 其他范例更适合某些任务

当我提到提示是一种新的编程范式(软件 3.0)时，我没有提到其他两种范式:传统编码(软件 1.0)和神经网络(软件 2.0)。几年前，卡帕西在[发表了一篇病毒式帖子](https://karpathy.medium.com/software-2-0-a64152b37c35)，为神经网络应该被设计成一种新形式的软件的观点辩护，并且对于某些任务，它们比传统的编码做得更好。

我在某种程度上同意他的观点。事实证明，神经网络在处理一些传统编码无法胜任的任务方面非常成功。特别是，神经网络非常适合视觉和语言。很明显，对于一些问题，直接从程序中编写我们想要的行为更容易(软件 1.0)，但对于其他问题，收集数据作为我们想要再现的行为的例子(软件 2.0)是首选的解决方案。

软件 3.0 也一样。提示允许用户处理超出以前软件范例能力的任务，但是它不太适合其他情况。构建操作系统、office 软件包、数据库或计算数字阶乘的程序仍将使用传统的编码方式。

## 其他范例成本较低

深度学习的成本往往令人望而却步。许多公司仍然依赖非神经网络机器学习解决方案，因为数据处理、清理和标记将比项目的其余部分包含更高的费用。

即使更新的技术更快或更精确，经济成本在现实世界中总是一个限制。训练 GPT-3 花费了 OpenAI 大约 1200 万美元。有多少公司买得起？你会花几百万创造一个为你写 JSX 的人工智能吗？

即使开发人员可以免费使用 API，也要考虑另一个成本。对地球环境的破坏。GPT-3 太大了，训练它产生的碳足迹大约相当于“[驾驶汽车去月球并返回](https://www.theregister.com/2020/11/04/gpt3_carbon_footprint_estimate/)”有时候越大并不是越好。

## 今天的人工智能有过不去的限制

神经网络每年都在变得越来越聪明，但有些任务甚至不是最聪明、最强大的神经网络所能完成的。GPT-3 在解释书面意见时面临的不确定性是不可避免的。

无实体的人工智能——包括迄今为止几乎所有的人工智能——无法访问单词以外的意思。我们可以用上下文来解释我们周围的世界，因为我们与它互动。我们生活在这个世界上，这就是我们理解语言的原因。我们可以把形式和意义联系起来；我们可以把单词和它们传达的主观体验联系起来。

神经网络无论多么强大，都无法像人类一样掌握语言。正如 Ragnar Fjelland [教授所说](https://www.nature.com/articles/s41599-020-0494-4#Sec1)，“只要计算机不成长，不属于一种文化，不在世界上活动，它们就永远不会获得类似人类的智能。”而且短期内不会发生。

# 最后的想法

不可否认，像 GPT-3 这样的神经网络是一个重要的里程碑，将为 AGI 的下一步打开大门。每次升级后，他们将能够处理更复杂的任务。例如，多模态人工智能是新的标准(MUM 和悟道 2.0 是最新的例子)。

然而，传统的方法和技术对于某些任务来说只是更好的选择。人工智能将吃掉以前属于传统编码领域的大块问题空间，但这发生在每项技术中。然而，新技术很少会让旧技术在任何意义上过时。同时提高效率、成本和可用性不是常规，而是例外。人工智能将触及每个行业，但它也不例外。

[***订阅***](https://mindsoftomorrow.ck.page/) ***获取更多关于 AI、哲学、认知科学的内容！***

## 推荐阅读

</gpt-3-a-complete-overview-190232eb25fd>  </gpt-3-scared-you-meet-wu-dao-2-0-a-monster-of-1-75-trillion-parameters-832cd83db484> [## GPT 三号吓到你了？遇见武道 2.0:1.75 万亿参数的怪兽

towardsdatascience.com](/gpt-3-scared-you-meet-wu-dao-2-0-a-monster-of-1-75-trillion-parameters-832cd83db484)