# 你的人工智能和你的数据质量一样好！

> 原文：<https://towardsdatascience.com/your-ai-is-only-as-good-as-your-data-quality-42be9ab533b9?source=collection_archive---------16----------------------->

数据准备在模型创建过程中的重要性

![](img/86ddd83cb18ac9725788d93cfa700e63.png)

[梁杰森](https://unsplash.com/@ninjason?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

# 介绍

许多人普遍的误解是，人工智能是一个神奇的黑匣子，它可以把你的数据变成黄金！这是部分正确的。人工智能确实能把你的数据变成金子(虽然不是字面上的)，只要你给它提供高质量的数据！但在当今世界，高质量的数据只是虚构的。那么如何克服这一点呢？你如何将“高质量”的数据输入到你的模型中，以便你可以获得人工智能的所有好处？这正是数据准备过程的切入点。但是在我们进入有趣的部分之前，到底什么是“坏数据”？

![](img/113605018f21396546d4a1ddb60e0bc5.png)

照片由[德米特里·维乔科](https://unsplash.com/@vechorko?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 拍摄

现实世界完全是一团糟。它生成的数据也是如此。它有各种形状和形式，从几行文本，可能是名人的推文或愤怒的客户的评论，到几百万行数字，可能是国家人口普查或来自物联网设备的传感器数据。也可能是介于两者之间的任何东西。由于数据源如此庞大，数据被包装和交付的可能性很小。没有。许多不一致的地方出现了。文本中可能会有一些表情符号或一些速记缩写，如 gm、np、lol 等。(感谢 Twitter 上 280 个字符的限制)。调查中也可能存在一些人为错误，因为犯错是我们的天性，不是吗？可能有一些数据丢失，因为一些绅士不想透露他的年龄，或者可能有一些错误的数据，因为一些女士减少了她的年龄几年！所以你看，不一致的数据是常见的，无论何时开始一个数据项目，你都可以预期某种形式的“坏数据”，除非你从 Kaggle 下载一个接近完美的数据集(无意冒犯！).在我们想到准备任何花哨的模型之前，准备好数据是我们的责任。那我们该怎么办？嗯，我们准备数据！

# 数据准备涉及的步骤

![](img/eb8ca9f146705ca4ffe4cc8276243d46.png)

[Bonnie Kittle](https://unsplash.com/@bonniekdesign?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

你可能已经听过一千遍了，但是让我再告诉你一遍。数据准备是任何数据项目中最关键的阶段，占据了项目时间的 70%!但是我们在数据准备方面到底是怎么做的呢？不可能有一根魔杖能神奇地为你准备好数据，对吗？是的，我希望有，但是没有。那么在数据准备阶段会发生什么呢？嗯，在准备数据时，我们需要遵循几个步骤。

# 数据清理

这是数据准备阶段的第一步。在我们考虑下一步之前，我们需要确保数据是干净的。我们不想要任何缺失数据、异常值或有噪声的数据。在这个阶段，我们做的工作包括处理缺失值、处理有噪声的数据和异常值，以及删除任何不需要的数据。这些步骤中的每一步都有自己独立的步骤，并伴随着各自的挑战。让我们逐一了解一下。

# 处理异常值

![](img/433cd40f15a48896ebd00851793ed8bc.png)

威尔·梅尔斯在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍照

在统计学中，离群值是指与数据集中的其他数据观察值显著不同的数据点。异常值可能是由多种原因造成的。然而，正确处理异常值是很重要的，因为它们可能是数据的重要部分，也可能只是收集数据时的一些错误。例如，在收集公司的工资信息时，高级管理人员的工资可能比公司的其他成员高得多。这个数据点显然是一个异常值，因为这样的情况很少。但是这个数据点对于分析是至关重要的，因为它是完全有效的，并且是整个数据的重要部分。在类似的情况下，当收集中学生的身高数据时，55.6 英尺的值。是非常不可能的。它最初可能是 5.56 英尺。但是由于收集数据过程中的一个错误，我们的整个分析将会完全被搞砸！那么我们如何处理离群值呢？有一些技术可以处理异常值。然而，了解域以识别离群值是有效还是无效是很重要的。为了处理异常值，首先识别异常值是很重要的。

可以通过绘制直方图或执行聚类分析来识别异常值。您也可以绘制一个箱线图来找出异常值。通常，当数据点的**大于(1.5 倍 IQR) +第三个四分位数或小于(1.5 倍 IQR)-第一个四分位数时，该数据点被视为异常值。**

现在我们已经确定了异常值，接下来我们做什么？两种常见的做法是要么移除这些异常值，要么使用某种变换函数(如 log 或 box-cox 变换函数)来平滑它们。但是我们在选择删除异常值时应该小心，因为它们可能是数据的有效观察值。一点声音领域的知识有助于在这件事上选择适当的步骤。

# 处理丢失的值

![](img/53d0ebe2048da8aa56dd3113a94d1de7.png)

[伊琳娜](https://unsplash.com/@sofiameli?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

当数据集中没有存储变量的数据值时，就会出现值缺失。就像离群值一样，这些可能是由各种原因造成的。可能是研究人员/勘测人员的错误，或者是用于收集数据的仪器的错误。不管是什么原因，缺少值可能是一个严重的问题，必须解决。为什么？一些最大似然模型不能处理缺失数据。但是与异常值不同，识别缺失值非常简单。但是我们处理这些缺失的值会有所不同。当然有一些处理缺失数据的标准技术，但是在您的情况下选择哪种技术需要一些领域知识(这里，我再说一遍)。事不宜迟，让我们看看这些“标准”技术。

**1。删除缺少值的行**

这是所有其他技术中最简单的。但是只有当缺失值非常低的记录时才是可行的。如果缺少值的记录数量很大，简单地删除它们会导致整个数据集中的大量数据丢失。

**2。用一个全局常数**填充它们

另一种常用于填充缺失值的技术是使用一个全局常数，比如零(0)。只有当无法正确预测缺失值时，才会这样做。当上下文已知时，缺少的值也可以用 0 填充(有时不是将值记录为零，而是将它们记录为空值)。

**3。用平均值或中间值填充缺失值**

这也是准备数据时的常见做法。缺失值用相关特定属性的平均值或中值填充。然而，这种方法的缺点是它忽略了数据集中其他属性的上下文。

**4。使用向前或向后填充**

缺少的值用上一行或下一行的值填充。这种技术称为前向填充(ffil)或后向填充(bfil)。

**5。创建一个模型来填充缺失值**

这是最有效的，但也是最复杂的技术。在这项技术中，创建了一个机器学习模型来从数据中学习模式并预测缺失值。

# 处理数据冗余

![](img/f72495366779d3d10cd0188769f9bba3.png)

约尔根·哈兰在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

在现实世界中，一个数据库包含数百个相互链接的表。此外，在收集所需数据时，通常会使用许多数据源(将在后续步骤中讨论)。在这种情况下，有可能出现数据冗余。但是首先，什么是数据冗余？数据冗余是指相同的信息或数据存储在多个位置的现象。例如，当连接两个表(雇员表和薪水表)时，这两个表都有雇员 ID，可以在结果表中创建相同信息(雇员 ID)的重复列。在这种情况下，必须识别并删除这种冗余数据。相关性分析有助于识别冗余数据。

# 数据集成

![](img/5be7667ad8eca3bae9c0b2b4fd1642eb.png)

照片由[派恩瓦特](https://unsplash.com/@pinewatt?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 拍摄

在这个数字时代，到处都在收集数据。从你的谷歌搜索到你佩戴的健身腕带上的心率，数据无处不在。理想情况下，任何企业都应该拥有来自多个来源的数据。例如，一个电子商务网站可以在自己的数据库中保存客户的详细信息。他们可能会并行地使用 CRM 工具来管理他们的客户与其网站的交互。他们也可能使用不同的工具来提供客户支持。他们将拥有一个用于数字支付的支付网关。从所有这些不同的来源收集不同类型的数据。为了更进一步，你还可以利用 Twitter 的 tweets，在那里有人会提到这家商店。为了全面了解公司的情况，拥有 360 度的数据视图非常重要。虽然您需要的所有数据都已经存在，但并没有统一的视图。在为 ML 模型准备数据时，您通常需要将来自所有这些不同数据源的所有数据集成到一个单一的数据形式中。将不同来源的数据组合起来的数据准备阶段称为数据集成。

# 数据转换

![](img/c9995dfb5e15bd4c25880f502bd3e922.png)

桑迪·米勒在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

在将数据输入 ML 模型之前，进行必要的转换是很重要的。数据转换中也有一些技术或方法。

# 聚合

数据聚合是以汇总格式存储数据的过程。从几个来源收集的数据首先被整合，然后数据聚合将在任何需要的地方执行。这是数据转换过程中的重要一步，因为模型的质量最终取决于数据的质量(这正是本文的标题！).

# [数]离散化

数据被转换成一组有限的间隔。例如，年龄属性可以离散成有限的区间，如(1–13)、(13–19)、(20–30)等。，或(儿童、青少年、年轻人)。宁滨也经常被用作离散化技术。离散化可用于显著提高模型的效率。

# 属性创建

通常，新的数据属性是通过使用数据集中已有的属性来创建的。例如，从现有的出生日期属性派生出*年龄属性*。这需要一段完善的领域知识(啊，我又说了吗？！).

# 正常化

这是数据转换过程的一个关键部分，因为真实世界的数据通常会在不同的尺度上进行测量。举个常见的例子，一个人的高度是用英尺来衡量的，而一条路的长度是用英里或公里来衡量的。对数据集中的所有属性进行规范化的过程称为规范化。然而，所有的规范化需求都不会这么简单。有几种归一化技术，如最小-最大归一化、z 值归一化等。

# 最后的想法

数据准备是创建机器学习或人工智能模型过程中的关键步骤。正如标题所暗示的和上面所讨论的，你的人工智能的质量完全取决于你提供给它的数据的质量。正如本文多次讨论的那样，对领域的扎实知识对于成功准备数据至关重要。

*原载于 2021 年 5 月 14 日 https://praneethvasarla.com**的* [*我的博客*](https://praneethvasarla.com/your-ai-is-only-as-good-as-your-data-quality/)