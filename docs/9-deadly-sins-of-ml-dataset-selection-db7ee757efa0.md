# ML 中数据集选择的 9 大罪

> 原文：<https://towardsdatascience.com/9-deadly-sins-of-ml-dataset-selection-db7ee757efa0?source=collection_archive---------32----------------------->

## 通过预先关注数据集，避免模型调试中的无尽痛苦

让我们从一个显而易见的事实开始:ML 模型只能和用来构建它们的数据集一样好！虽然有很多对 ML 模型构建和算法选择的强调，但团队往往没有足够重视数据集选择！

![](img/68618f01c4194be66cafbf2d1ee33e1d.png)

[去飞溅图像](https://unsplash.com/photos/TcJkdeXgksQ)

> 根据我的经验，前期在数据集选择上投入的时间可以在模型调试和产品展示过程中节省大量时间。

# **九宗罪**的 ML 数据集选择

## **1。没有正确处理数据集中的异常值**

基于正在构建的 ML 模型，离群值可以是忽略的噪声，也可以是必须考虑的重要因素。由收集错误引起的异常值需要被忽略。机器学习算法对离群值的敏感度不同，与 XgBoost 相比，AdaBoost 对离群值更敏感，而 XgBoost 比简单地将离群值视为错误分类的决策树更敏感。正确处理异常值需要了解它们是否可以被忽略，然后根据敏感度选择合适的算法。

## 2.使用归一化而不是标准化来缩放特征值

要使要素具有相同的比例，请在数据均匀分布时使用归一化(最小最大比例),在要素近似为高斯分布时使用标准化(标准比例)。在使用数据集之前，验证 [iid](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) 的属性，静态(不随时间变化)，并确保在训练和测试期间具有相同的分布。季节性经常被忽略，这是对平稳性的典型违背。

## 3.不验证训练数据集中的重复项

通常，我们会被非常高精度的数字所激动。仔细检查通常会发现测试集中的许多示例都是训练集中示例的副本。在这种情况下，模型一般化的度量是不确定的(或无意义的)。一个相关的方面是训练集的随机化——如果没有随机化，我们可能会以训练中的所有秋季数据和测试中的夏季数据结束。这可能导致需要不必要的调试的丢失时期图。

## 4. ***不验证固有数据集偏差:***

从统计学的角度来看，数据集并没有捕捉到最终的真相。他们只捕获应用程序所有者当时为他们的用例所需要的属性。分析数据集的偏差和丢失数据非常重要。理解数据集的背景是至关重要的。数据集通常有一个或多个错误模式。如果这些误差是随机的，那么它们对模型训练的危害较小。但是，如果有一个 bug，比如某一行或某一列被系统地遗漏了，那么就会导致数据集中的偏差。例如，Andriod 用户的用户点击的设备细节由于一个错误而丢失，数据集将偏向 iPhone 用户活动。

## 5. ***没有验证输入数据的单元测试***

在传统的软件开发项目中，编写单元测试来验证代码依赖是一种最佳实践。在 ML 项目中，需要应用类似的最佳实践来连续测试、验证和监控所有的输入数据集。这包括确保测试集产生有统计意义的结果，并代表整个数据集。

## 6.关于数据属性含义的不正确假设

数据属性通常不会被归档。在大数据时代之前，数据在添加到中央数据仓库之前是经过筛选的。这被称为*写模式。*如今，数据湖的方法是首先聚合数据，然后推断数据在消费时的意义。这就是所谓的<https://medium.com/wrong-ml/schema-on-read-curse-of-data-lakes-our-5-antidotes-1386199d262f>**。*一个相关问题是给定业务指标存在多个定义，即缺乏业务指标标准化。即使是最简单的指标，也可能有多种来源的事实和业务定义。例如,“新客户数量”这样的基本指标可以有不同的定义，这取决于它是由销售、财务、市场营销还是客户支持团队计算的。*

## ****7。数据源处不协调的变化****

*源处的模式更改通常与下游处理团队不协调。变化范围从模式变化(破坏现有管道)到难以检测的数据属性的语义变化(当您的模型出乎意料地开始变得疯狂时，情况会非常糟糕！).此外，当业务度量发生变化时，缺少定义的版本控制。*

## *8.使用非代表性数据*

*数据有截止日期。10 年前的客户行为记录可能不具有代表性。此外，确保模型训练的数据是 [IID](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) (独立同分布)，并考虑数据的季节性。此外，数据集也在不断发展。数据分布的分析不是仅在模型创建时需要的一次性活动。相反，需要持续监控数据集的漂移，尤其是对于在线培训。通常，考虑到数据的孤岛性质，不同的数据集由不同的团队管理和编目。大量的部落知识被用来定位数据集。如果没有适当的尽职调查，团队会匆忙使用第一个可用的数据集。他们经常犯一个经典的错误，即假设所有数据集都同样可靠。它们中的一些由源团队非常紧密地更新和管理，而其他数据集被放弃或不定期更新或具有不稳定的 ETL 管道。*

## ***9*。大型数据集内的任意样本选择****

*给定非常大的数据集，采样通常是任意的。通常，团队要么决定使用所有的数据来训练 ***。*** 虽然更多的数据有助于建立准确的模型，但有时数据非常庞大，有数十亿条记录。在更大的数据集上进行训练需要时间和资源。每个训练迭代花费更长的时间，减慢了整个项目的完成。需要有效地使用数据采样。特别注意利用技术，例如[重要性抽样](https://en.wikipedia.org/wiki/Importance_sampling)。*

*总之，请确保在数据集选择中包含此清单。虽然这些步骤增加了工作量，并可能在开始时减慢速度，但它们在 ML 生命周期的后期会为自己付出很多倍的代价！*

****为了保护本博客中列出的人工智能缺陷，*** [***请跟随***](https://medium.com/@modern-cdo) ***获取即将到来的博客“人工智能清单”的通知管理数据+人工智能在生产中的策略，检验*** [***解开数据***](https://www.unraveldata.com/)*