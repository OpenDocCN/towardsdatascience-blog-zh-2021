# 7 条著名的人工智能语录

> 原文：<https://towardsdatascience.com/7-famous-ai-quotes-explained-782dda72d2c5?source=collection_archive---------6----------------------->

## 人工智能

## 人工智能的过去、现在和未来。

![](img/6513e7cfa2186bd7ce0cdbefaa6b5488.png)

照片由[马蒂亚斯·诺斯](https://unsplash.com/@matias_north?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 拍摄

人工智能已经与我们生活的方方面面交织在一起。在过去的 60 年里，无数的科学家和哲学家努力工作，将这个领域发展到今天的样子。几十年来，一些观点、方法和范式指导了人工智能的研究，非常聪明的人表达了他们对人工智能伟大探索的想法和见解:征服智能。

这些洞见以神秘但吸引人的短语的形式出现在我们面前，而这些短语的潜在含义却常常不为我们所知。我们被留在那里，点头同意一个复杂思想的美丽简化。但是把一句话写成一本书需要专业知识和多年的思考。西塞罗说得好，“如果我有更多的时间，我会写一封更短的信。”

在这篇文章中，我从该领域的世界级专家那里挑选了 7 条著名的人工智能语录，并为你解开其中的含义。尽情享受吧！

# 图灵测试

> “如果一台计算机能够欺骗人类，让人类相信它是人类，那么它就应该被称为智能的。”
> 
> —艾伦·图灵

通常被认为是计算机科学之父的艾伦·图灵在 1950 年[发表了一篇论文](https://academic.oup.com/mind/article/LIX/236/433/986238)，他在论文中解释了回答“机器能思考吗？”这个问题的最佳方式就是改变问题本身。他认为询问机器是否能思考是没有用的，因为我们无法正式定义“思考”。

相反，他提出了“模仿游戏”——我们今天称之为图灵测试。模仿游戏是由三个代理人玩的问答式游戏。审讯者(特工 C)向特工 A 或 B 提出如下形式的问题:“请给我写一首关于第四座桥的十四行诗”或“把 34957 加到 70764。”特工 A 的任务是迷惑审讯者，让他误以为是特工 B。例如，如果 A 是个男人，B 是个女人，这个男人必须努力让审讯者相信他就是那个女人。

有了这个框架，图灵提出，原来的问题可以换成“当一台机器在这个游戏中扮演 A 的角色时会发生什么？”代理人 A 可以被换成一台通用的数字计算机来测试它的认知能力，如果这台计算机能够欺骗询问者，使其认为它是人类，那么它就应该被称为智能的。

# 人工智能的未来

> "未来取决于某个对我所说的一切深感怀疑的研究生。"
> 
> —杰弗里·辛顿

现在被称为人工智能“教父”的杰弗里·辛顿(Geoffrey Hinton)最初是作为认知心理学家接受培训的。这就是为什么当几乎没有人工作时，他一直试图让人工神经网络(ANN)工作。当时，专家认为连接主义 AI 是一条死胡同，即使大脑是由生物神经网络组成的。但辛顿一直认为，“为了让人工智能发挥作用，我们必须以类似于人脑的方式进行计算。”

然而，深度学习并不像大脑那样工作。即使人工神经网络的名称来自神经科学，但它们在最基本的意义上不同于生物神经网络。人工神经元是一种超级简化的构造，是在生物神经元的基础上构建的，但假设它们只是基础数学的愚蠢计算器。然而，[已经证明](https://science.sciencemag.org/content/367/6473/83)“单个神经元可能能够计算真正复杂的功能。例如，它本身可能能够识别一个物体。”

纵观全局，辛顿的怀疑是坚定的:计算机视觉和 CNN[不像我们的视觉系统](https://bdtechtalks.com/2020/03/02/geoffrey-hinton-convnets-cnn-limits/)那样工作。深度学习系统需要大量的数据，而[由于先天的大脑结构，人类从稀疏的数据中学习](https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199573776.001.0001/oxfordhb-9780199573776-e-10)。而计算机需要巨大的功率来训练最先进的 AI，而大脑只消耗 20W。Geoffrey Hinton 为深度学习奠定了基础，他知道未来的人工智能将走上一条不同的道路。

# 意识人工智能

> "根本没有人知道如何建造一台有意识的机器."
> 
> —斯图尔特·罗素

有数百本关于意识的书，原因是没有人理解它。正如劳伦斯·克劳斯在接受《诺姆·乔姆斯基》采访时指出的，“一个领域的已知程度和关于这个领域的书籍数量成反比。”

我们对意识知之甚少。人们普遍认为，大脑中的活动产生了心理过程和我们对现实的主观体验。但是我们对它是如何出现的一无所知。生物电信号是如何产生丰富的、无限的思想、感觉和知觉的，这是完全未知的。不了解科学，就认为我们可以创造技术是愚蠢的。

然而，有些人担心我们会建立有意识的人工智能。如果我们真的做到了，其意义将远远大于构建无意识的一般智能。这就是为什么有技术术语来区分这两者:AGI，经常指的是不一定有意识的人类水平的智能——罗素所争论的是人工智能研究的最终目标。另一个术语是强人工智能，这是由约翰·塞尔创造的概念，指的是人类级别的人工智能，也是有意识的。如果我们要构建强大的人工智能，我们需要彻底反思社会。

# 元发明

> “任何可以产生比人类更聪明的智能的东西——以人工智能、脑机接口或基于神经科学的人类智能增强的形式——都毫无疑问地成为最能改变世界的东西。其他的甚至都不在一个联盟里。”
> 
> —埃利泽·尤德科夫斯基

自从我们进化成文化生物，我们就一直在发明东西。早在历史开始之前，技术就已经帮助推动我们的文明向前发展。写作、农业、城市、印刷、电力、互联网、社交媒体……都以这样或那样的方式极大地改变了世界。

但是尤德科夫斯基所说的比人类聪明的智能是一种不同类型的发明；这是一个元发明。农业或印刷是有特定用途的技术，被设计来执行预先定义的任务。通过构建一个通用人工智能，我们已经让*发明了一个* *发明家——*，而不是任何一个发明家；它几乎在所有方面都比我们强。

打个比方，让我们想到电脑。它被设计成一台通用机器，一台可以被编程来执行许多不同设备的任务的机器。在某种意义上，计算机是一种元设备。另一个更近的类比可以用流行的语言模型 GPT-3 来说明，它具有元学习能力。它学会了学习，而不是学会了执行一项特定的任务。AGI 将是我们所能想到的最广泛意义上的元。这提出了一个有趣而又可怕的问题:如果我们设法发明了所有这些东西，那么一个超级强大的发明家能发明什么呢？

# 人工智能的危险

> “全人工智能的发展可能意味着人类的终结。[……]它会自己起飞，以越来越快的速度重新设计自己。受到缓慢生物进化限制的人类无法竞争，并将被取代。”
> 
> ——斯蒂芬·霍金

著名物理学家斯蒂芬·霍金警告我们真正人工智能的危险。他认为一个足够聪明的人工智能将能够摆脱我们的控制。即使我们成功地设计了符合我们价值观的人工智能，最轻微的偏差也可能导致更下游的灾难性后果。有一种观点认为，如果我们可以设计一个全能的人工智能，让它变得仁慈的唯一要求是让它渴望对我们有益的东西，拒绝那些对我们有害的东西。然而，在实践中，我们会发现实现这一目标有许多困难。

最乐观的人认为，如果我们完整地构建人工智能，它不可能在我们精心设定的界限之外表现。但霍金谈到了重新设计，我们不必看得太远就能意识到这一论点值得考虑:人类在几千年的进化之风、随机突变和自然选择中精心打造，直到最近才找到改变我们基础的工具。如果我们设法改变我们的 DNA，我们就成功地克服了进化的限制，进化是我们的主要“设计师”是什么让我们认为像我们一样聪明的机器最终不能做同样的事情？

此外，因为机器已经在各个方面超越了我们——记忆、精度和计算能力等——它们也将通过改变自身在其他任何方面迅速超越我们。我们可能会失去在这种情况下可能出现的任何冲突；我们会被“取代”

# 我们最后的发明

> "机器智能是人类需要创造的最后一项发明."
> 
> —尼克·博斯特罗姆

尼克·博斯特罗姆是牛津大学的一名哲学家，著有《超级智能:路径、危险、策略、T3》一书，他在书中认为超级智能——这个术语指的是那些远远超过 AGI 水平、远在我们之上的人工智能，相比之下，我们再也不能称自己为智能——将会出现，我们应该以各种可能的方式为这一事件做准备。

博斯特罗姆认为，一旦我们到达 AGI，ASI(人工超级智能)终将到来。这种智能将能够做我们所做的一切，甚至更多——多到我们就像试图理清人类文明运作的蚂蚁一样——因此它将能够创造所有其他可以创造的东西(与 Yudkowsky 的观点一致)。

对于博斯特罗姆来说，这种未来可能以两种相反的形式出现:要么 ASI 是仁慈的，对人类有益的，因为我们已经成功地将它与我们完美地结合在一起，要么它不是，也不仅仅是“人类需要做出的最后一项发明”，而是我们将做出的最后一项发明。句号。

# 奇点

> “在几十年内，机器智能将超过人类智能，导致奇点——技术变革如此迅速和深刻，以至于代表着人类历史结构的断裂。”
> 
> —雷·库兹韦尔

世界领先的未来学家之一雷·库兹韦尔(Ray Kurzweil)提出了他所谓的“[加速回报定律](https://en.wikipedia.org/wiki/Accelerating_change#Kurzweil's_The_Law_of_Accelerating_Returns)”，根据该定律，进化系统——包括技术——以指数速度变化。他认为，按照这个想法，我们可以断定[奇点就在](https://www.amazon.com/Singularity-Near-Humans-Transcend-Biology/dp/0143037889)附近。他声称，在 21 世纪末之前，我们将达到这一事件，创造“人类历史结构的断裂。”

人类将与机器完全融合，我们将被永恒地投射成基于软件的生物，人工智能将比人类的总和更加强大，向外扩展其征服宇宙的范围。库兹韦尔认为这将在不到 25 年的时间内开始发生:“我将这个奇点的日期定为 2045 年，这代表着人类能力的一次深刻而具有破坏性的转变。”

然而，对他的想法有很多批评。物理学家保罗·戴维斯[说](http://www.singularity.com/When_computers_take_over.pdf)即使在某些情况下增长是指数级的，但由于缺乏资源，这种增长不会持久。物理学家西奥多·莫迪斯(Theodore Modis)[认为](https://web.archive.org/web/20121030072409/http://www.growth-dynamics.com/articles/Kurzweil.htm)“自然界中没有什么遵循纯指数规律”，相反，增长是典型的逻辑。一开始，这两个功能看起来是一样的，但是逻辑变平了，这就是现实中最终发生的情况。无论是哪种情况，我们都将活着看到库兹韦尔的预测是否会落空。

[***跟我一起旅行到未来***](https://mindsoftomorrow.ck.page/) ***了解更多关于人工智能、哲学和认知科学的内容！如有任何疑问，欢迎在评论中提问或联系***[***LinkedIn***](https://www.linkedin.com/in/alberromgar/)***或***[*Twitter*](https://twitter.com/Alber_RomGar)***！:)***