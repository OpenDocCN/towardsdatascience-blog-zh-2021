# 如何选择数据拆分方法

> 原文：<https://towardsdatascience.com/how-to-select-a-data-splitting-method-4cf6bc6991da?source=collection_archive---------12----------------------->

## 不同数据拆分方法的优缺点及其背后的原因。

![](img/763447e34557ab09b3a7ada709cc83a3.png)

班农·莫里西在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 拍摄的照片

S 分离你现有的数据是有效训练和评估你的模型的一项重要任务。在这里，我将讨论 scikit-learn 中不同的数据分离技术，选择特定的方法，以及一些常见的陷阱。

本文包含供您使用的易用代码块和供参考的快速摘要。 **** *请随意将这篇文章加入书签以备后用。*****

当你第一次学习数据科学时，拆分你的数据是一项次要的任务。

为什么您应该只使用部分数据？让我的模型学习更多的数据不是会产生更好的结果吗？

虽然人们普遍认为，在构建预测模型时，更多的数据会带来更好的模型，但考虑如何使用您的模型也很重要。

在将模型投入使用之前，测试模型在开发过程中是必不可少的。不过，你必须只处理可用的数据，这意味着留出一些数据作为你的“真实”数据。

但是调查你真实的“现实生活”数据是至关重要的。这个问题的答案决定了您应该如何分离您的数据。

# **列车试分裂**

在最简单的数据分离形式中，您随机抽取一部分数据，将其放在一边供以后测试。

## 很简单，但是停下来想想这些假设。

1.  **该方法假设数据来自同一分布**。例如，假设您有逐年变化的数据。假设您主要从最近一年的数据中取样(甚至可能是由于随机选择而偶然取样)。在这种情况下，您的模型可能无法有效处理今年的预测。
2.  **你有足够的数据使你的数据集具有代表性。**如果您有来自相同分布的数据，但只有 100 个实例，选择 10%的数据作为测试集可能会提供不准确的结果。如果这 10 个数据点来自数据中最异常的区域，那么模型的性能会更差。当您有更多的数据实例时，这种情况不太可能发生。
3.  **对于分类问题，是否需要考虑每个类的份额？**假设您有一个高度倾斜的分类问题(根据我的经验，通常都是这样)。在这种情况下，您可能需要考虑对数据集进行分层。这一点几乎落入前一点，测试集可能太小，但在这种情况下，它对于您试图预测的一个类来说太小了。

如果您想要执行内部交叉验证，这种拆分方法是完美的。将数据分为训练和测试，并在训练模型时应用交叉验证方法。对于来自同一分布的足够数据，这种方法是可行的

***对中大型数据集使用 train_test_split，数据来自同一个分布***

```
import numpy as np
from sklearn.model_selection import train_test_split# Update with your data
X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])
y = np.array([1, 2, 3, 4, 5])X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=10)###########################################
#### Add the code for your model here #####
###########################################
```

训练测试分割的一个缺点是，当您进行分割时，有一个决定，即您的测试集中的数据将始终是您的测试数据。

## 这有几个缺点。

1.  **在训练**时，你从不在你的模型中包含测试数据。在您的测试数据中可能有一些实例会使您的模型更加健壮。
2.  **测试数据是固定的。**最后，还有一个微妙的问题，就是过度适应这个测试集。虽然这不像过度训练神经网络来完美地学习数据那样明确，但这种过度拟合仍然是一个问题。一旦这些数据固定下来，您所执行的实验将根据这个测试集进行重复测试。你要寻找在这个场景中表现最好的模型。但是考虑一下预测建模的原始问题。你不知道未来的数据会怎样。通过对固定的测试集进行重复测试，您正在做一些在真实场景中不可能完成的事情。

# **KFold**

作为训练-测试分割的替代方法，K-fold 提供了一种机制，可以将数据集中的所有数据点同时用作训练数据和测试数据。

Kfolds 将数据集分成多组零重叠的索引，从数据集中随机抽取数据集。

这种方法优于以前的训练测试分割，因为每个数据点都可以是模型的一部分和测试集中的一部分。

## 然而，这意味着一些事情。

1.  **您将在每个训练数据集上构建多个模型，并在每个测试数据集上进行测试**。虽然这对于小数据集来说没问题，但是当模型很大，数据集很大时，事情很快变得昂贵。
2.  **测试之间的性能有所不同**。这种性能上的变化是一件好事。您可以计算关于您的表现的统计数据(即，您可以从多次评估中获得标准偏差和平均值)。您还可以更好地了解您的模型在不同场景下的行为。
3.  通常，当使用这种类型的数据分段时，每个测试的平均值给出了一个模型在真实环境中如何表现的更加可靠的解释。外部交叉验证以这种方式创建多个模型，报告所有折叠的平均性能，然后基于所有数据制作最后一个模型。这个最终模型得益于所有数据的使用。但是，在有额外数据之前，无法对其进行测试。因此，在这种情况下，模型性能的平均值被用作该模型的性能。

***当您的数据来自同一个分布*** 时，将 KFold 用于中小型数据集

```
import numpy as np
from sklearn.model_selection import KFold# Update with your data
X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])
y = np.array([1, 2, 3, 4, 5])KF = KFold(n_splits=5)
for train_index, test_index in KF.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index] ###########################################
    #### Add the code for your model here #####
    ###########################################
```

# **时间序列分割**

前面的两种方法都认为你所拥有的数据是可以随机抽样的。**然而，在时间序列数据中，你不能随机抽样数据。**最重要的原因是，没有现实生活中的场景可以用未来的数据训练一个模型来预测过去。

相反，你可以通过时间来分离数据。例如，获取一个数据点之前的所有数据，然后在下一个数据点上测试它，可以确保没有数据泄漏。从这个意义上说，漏损就是用未来的数据来预测以前的数据。

这种分割方法是三种**方法中唯一一种考虑分布随时间变化的方法**。因此，当您有随时间变化的数据时，可以使用它。

***对于时间序列数据或数据分布随时间变化时，使用 TimeSeriesSplit。***

```
import numpy as np
from sklearn.model_selection import TimeSeriesSplit# Update with your data
X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])
y = np.array([1, 2, 3, 4, 5])time_series_cv = TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)for train_index, test_index in time_series_cv.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]###########################################
#### Add the code for your model here #####
###########################################
```

# **总结**

建立模型很有趣。但是，试图提高模型的性能可能是一项无止境的任务。虽然您可能在一组数据上有出色的表现，但考虑如何在现实世界中使用您的模型是否至关重要。不同的拆分方式服务于不同的目的，所以要相应选择。

**记住关注目标问题，而不仅仅是某个测试集的最高性能。**

如果你有兴趣阅读关于新颖的数据科学工具和理解机器学习算法的文章，可以考虑在 Medium 上关注我。

如果你对我的写作感兴趣，想直接支持我，请通过以下链接订阅。这个链接确保我会收到你的会员费的一部分。

<https://zjwarnes.medium.com/membership> 