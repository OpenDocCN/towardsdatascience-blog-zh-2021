# 人工智能监管:不再遥远的未来

> 原文：<https://towardsdatascience.com/ai-regulation-no-longer-a-distant-future-4dc5600c082b?source=collection_archive---------26----------------------->

## 拜登政府将如何改变人工智能领域，你现在应该做什么

![](img/49580d346299d9dd61c07bd3433ad41c.png)

诺亚·多米尼克·西尔维奥在 [Unsplash](https://unsplash.com/s/photos/traffic-lights-speed-limits-cars?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上的照片

随着拜登总统最近做出一些重要任命，有很多[猜测](https://www.technologyreview.com/2021/01/22/1016652/biden-administration-ai-plans-what-to-expect/?utm_source=Sailthru&utm_medium=email&utm_campaign=Issue:%25202021-01-25%2520CIO%2520Dive%2520%255Bissue:32047%255D&utm_term=CIO%2520Dive)我们可以期待他的政府在未来四年里在人工智能/人工智能方面，特别是在监管人工智能应用方面做些什么——让技术更安全、更公平、更公正。

作为信息技术研究集团负责这一领域的分析师，我自然要参加竞选。以下是我的四大预测。

众议院和参议院将快速通过对人工智能的监管

我们可能还没有所有的细节，但方向和速度都相当清楚:我们可以期待监管在联邦一级得到快速跟踪，以补充州一级的法案。该路线图包括最近推出的法案，如 2019 年的[算法问责法案](https://www.congress.gov/bill/116th-congress/house-bill/2231/actions)，以及现有法规的现代化，如民权法案(1964 年)、公平住房(1968 年)和其他涵盖人工智能和算法决策系统的法案。

事实上，算法问责法案背后的驱动力——参议员罗恩·怀登和科里·布克，以及众议员伊薇特·克拉克——正计划今年在参众两院重新提出他们的法案。

总的来说，我们可以期待看到政府追求一个议程，更好地将人工智能/人工智能纳入现有的和新的立法框架，并随着人工智能标准和实践的不断发展，留下足够的灵活性空间。

**道德人工智能标准将快速发展**

为了使监管有效，它需要[由价值观驱动，以证据为依据，以合理的风险模型为基础，并由标准和认证支持](https://www.linkedin.com/pulse/consensus-emerging-ai-regulation-must-global-effort-natalia/?trackingId=OFPn3q2cXRgLyb%252FrokGnqQ%253D%253D)。因此，我们预计，随着政府指导意见的形成，政府机构将很快加强对人工智能的关注。NIST 和其他人将加倍努力，为人工智能技术、算法偏差、可解释性以及人工智能治理和风险管理开发基准、标准和测量框架。

一些工作已经在进行中，例如[面部识别厂商测试](https://www.nist.gov/programs-projects/face-recognition-vendor-test-frvt)和[可解释的人工智能](https://www.nist.gov/news-events/events/2021/01/explainable-ai-workshop)，但是我们可以预计这个计划会很快加速。

**监管者将跨境合作**

在这个相互联系的世界中，任何对技术的监管都不能孤立地进行，尤其是像 AI/ML 这样的技术。有几个迹象表明立法者愿意联合起来互相学习，特别是从那些一开始就把它作为优先事项的国家。(毕竟，如果处理得当，监管不会成为创新的障碍——下面会有更多相关内容。)

在未来四年，我们将看到与欧洲和国际组织以及邻国在人工智能监管、标准、认证和审计方面的合作增加，其中许多国家已经领先于美国同行。更高水平的全球伙伴关系将积极影响在美国和国外建立更全面的立法框架的努力。

**联邦机构将获得更广泛的授权，包括 AI/ML**

法律可以告诉你什么可以做，什么不可以做，但它的力量来自于法院和有权实施处罚和其他监管制裁的监督机构的强制执行。目前，尚不清楚这一权力是什么，以及它是如何在与 AI/ML 相关的各联邦机构之间分配的。

我们预计这种情况将很快得到解决，方法是扩大现有监督机构的授权，以包括人工智能和机器学习驱动的应用程序和系统，以及建立人工智能审计员——特别是人工智能偏见审计员——的培训、认证、认可和监督的指令，类似于食品检查员和消费者安全检查员。

![](img/d36718475ada61f9270add78c1c68d56.png)

[斯科特·格雷厄姆](https://unsplash.com/@homajob?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)在 [Unsplash](https://unsplash.com/s/photos/business?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍照

**这一切对你的组织意味着什么？**

那么，这对你的组织有什么影响，无论你只是在考虑利用 AI/ML 还是已经做了很多年？

我的观点是，监管——以及它的另一面，治理——并不邪恶。如果执行得当，监管可以创造确定性，建立公平的竞争环境，并促进竞争。它还为内部政策、治理和责任提供信息。治理有助于构建关于人工智能货币化的可接受风险和回报的讨论——提高组织的成功几率。

治理(以及监管)也有助于建立和加强信任:在组织内部，但最重要的是，与客户的信任。的确，信任是所有业务的基础。

**你可以赶在任何即将到来的监管变化之前**

不要等到监管成为现实！你可以采取三个简单的步骤来避免意外，并让你的组织做好准备:

不要等 AI 监管来找你！通过[行业协会](https://standards.ieee.org/industry-connections/ecpais.html)、智囊团、公共政策和公民利益团体以及你的众议院代表参与塑造它。

积极地管理你的组织的人工智能驱动的应用程序，在其他人(包括政府)赶上来之前建立你的过程成熟度。企业根本等不起。或者面临部署有偏见的系统的风险，这可能会损害您的客户，从而损害您的声誉和资产负债表。

记录并主动披露您如何以及在何处使用人工智能/机器学习、数据和分析，以及这些系统是如何构建的。[人工智能注册](/ai-registers-finally-a-tool-to-increase-transparency-in-ai-ml-f5694b1e317d)——例如，阿姆斯特丹[和赫尔辛基](https://algoritmeregister.amsterdam.nl/en/ai-register/)和[的城市所利用的——是一种与你的客户分享这些信息并增加他们的信任和忠诚度的直接方式。他们也将为审计师和监管者工作。它们为内部人工智能治理创建了一个最小可行框架的基础。](https://ai.hel.fi/en/ai-register/)

治理和监管真的不是负担。即使要花钱，它们也代表着商业成功的一项重要的增值投资。治理是一种创造价值、将人工智能等新技术货币化以及发展和加强业务(同时监控和降低风险)的机制。更大的风险在于忽视人工智能的潜力，或者让竞争对手捷足先登。