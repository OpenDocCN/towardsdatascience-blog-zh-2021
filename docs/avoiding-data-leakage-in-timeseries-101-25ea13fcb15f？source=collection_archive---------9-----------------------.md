# 避免时间序列中的数据泄漏 101

> 原文：<https://towardsdatascience.com/avoiding-data-leakage-in-timeseries-101-25ea13fcb15f?source=collection_archive---------9----------------------->

![](img/0b6256abb90e63f873ca280717f48208.png)

在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上由 [Aron 视觉](https://unsplash.com/@aronvisuals?utm_source=medium&utm_medium=referral)拍摄的照片

> 你已经做出了选择。你来这里是为了明白你为什么会成功。—神谕，矩阵

时间序列是几乎每天都变得难以建模的极少数数据学科之一。

例如，丰富的数据对于许多其他领域来说是一个好消息。我们可以训练更好的模型并期待更好的结果。但是在时间序列的背景下，大量的数据*经常以不同的形式出现。这通常意味着数据到达的时间间隔越来越短。当这种情况发生时，与其更好地解释这种情况的潜在动力，通常更新的和以前未知的怪癖开始在时间序列中出现。例如，部分季节性或突然变化的趋势。*

对于许多其他学科，建模和预测是齐头并进的。对于时间序列来说，它们通常是大敌。以有效市场假说(EMH)为例。它是金融学的一个理论基础，然而，它曾经(现在仍然)是金融时间序列预测的一个强有力的打击。因为它说，由于市场效率，股票价格只是随机游走。模拟随机漫步非常简单。然而，预测是一种徒劳的尝试(EMH 是否成立是另一回事，许多聪明人拒绝相信 EMH)。

在这篇文章中，我将讨论*数据泄露*，这在很多 ML 任务中很普遍。数据泄漏可能会在您的 ML 生命周期中蔓延，并一直保持沉默，直到您将模型推向生产，一切都将失控。但是什么是数据泄露呢？

维基百科为数据泄露提供了一个恰当的定义。我冒昧地以如下方式对其进行了一点修改:数据泄漏是在模型训练和*验证*期间使用的信息，这些信息在预测阶段是不可用的。就时间序列而言，这种可用性的缺乏可能以多种形式出现，尤其是当预测范围很大时。这可能是由于以下原因:

1.  该功能在未来根本不可用。在交叉验证期间，这种不可用性可能会被忽略，因为我们在数据集上进行交叉验证，而数据集本身是由*过去的观察值*组成的。因此，在生产之前，我们总是可以访问这些特性。这些类型的数据泄露的主要影响是——他们认为花费在特征创建上的时间是没有意义的
2.  为了便于讨论，假设特性*可以在预测范围内通过特性本身的预测/预期而变得可用。在这种情况下，有两个警告:(a)可靠的预测是非常昂贵的(b)预测带有许多不确定性/误差，所以做好准备，看看模型在生产中的性能急剧下降。*

数据泄露的一个常见例子可能是使用库存变动数据来预测某些生产的数量。在交叉验证阶段，股票运动数据可能显示出极好的匀称值，使其成为一个重要的建模特征。但是当涉及到实时预测时，它的效用变得非常小，如果不是绝对无用的话。

在接下来的内容中，我将尝试标准化一些可以用来避免这个陷阱的实践。这里详述的一些实践在 ML 从业者中非常普遍地被接受，为了完整起见，我将提到它们。

**先分裂，后正常化。**

这种做法是众所周知的洗钱从业者。这也与时间序列分析有些关系，特别是当涉及神经网络的技术(例如:AR-Net，NeuralProphet，RNN-LSTM)被应用时。这是因为神经网络很难(如果不是不可能的话)用未标准化的数据集进行训练。

这种做法包括以下步骤:

1.  将数据集分为训练集、验证集和测试集
2.  仅使用训练集计算归一化因子。规范化训练集
3.  使用在前一阶段发现的标准化因子，标准化验证和测试集

如果我们使用整个数据集计算出归一化因子，我们就会在模型训练期间以归一化因子的形式引入数据泄漏。这仅仅是因为归一化因子现在包含了来自验证和测试集的统计数据。

> 有一些重要的警告值得注意。如果被建模的过程不是静态的，那么将归一化因子带到很远的将来(验证+测试)会对模型性能产生不利影响。然而，这是一个不同的讨论。

**直接进入 MVP，稍后交叉验证！**

听起来有点违背直觉，但让我解释一下。

MVP 代表最小可行产品。这基本上是我们正在设计的 ML 系统的精简版本(例如:推荐引擎或预测引擎),能够实时交付端到端的解决方案。它不一定需要被部署。

通常的 ML 实验生命周期有以下步骤:

1.  准备数据集(分割+归一化+要素创建)
2.  快速构建一系列模型
3.  交叉验证，然后进行超参数调整
4.  型号选择/组装
5.  创建一个 MVP

请记住，如果模型中存在数据泄漏，那么您所监控的每个性能指标都会被严重夸大，并且在所有模型中不对称。因此，在模型选择过程中，我们可能会因为一个据说是错误的性能指标而放弃最健壮的模型。或者在组装时，我们可能会给每个模型分配不准确的重量，从而在生产中产生不良的预测。

为了避免所有这些陷阱，让我稍微重组和重新设计一下实验生命周期:

1.  准备数据集(分割+归一化+要素创建)
2.  训练一个简单的模型。为什么不是复杂精密的模型呢？下一步就清楚了。
3.  创建一个 MVP。由于 MVP 是实时预测的(例如，未来 7 天)，因此无法衡量模型的性能。因此，模型复杂性是不相关的。
4.  假设引入数据泄漏的特征被识别，继续进一步迭代(更复杂的模型，模型选择/集合)

这个重新设计的生命周期不仅可以帮助您识别可能引入数据泄漏的特性，还可以让您了解实际上可以包含哪些类型的特性。

**不要解耦模型训练和预测/推理**

对于许多 ML 任务，模型训练和预测/推理可以完全解耦。以所谓的猫分类器为例。人们可以完全分离分类器训练和分类的过程。可以有把握地假设，进行预测所需的特征(像素值数组)的可用性不是时间的函数。

然而，当涉及到时间序列时，情况就完全不同了。在时间序列分析中，建模和预测通过时间关系交织在一起。只有当一个特征是时间的直接/间接函数时，它才能有助于推断。因此，在模型训练期间所做的每一个决定都需要得到这个想法的全面支持。这与其说是一种实践，不如说是思维过程和领域专业知识的结合。自然需要时间来完善。

就我而言，在我的时间序列分析之旅中，我发现上面的实践非常有帮助。我希望也有一些外卖给你。祝你愉快。干杯！