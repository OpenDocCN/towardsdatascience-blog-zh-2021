# GPT 三号吓到你了？遇见武道 2.0:1.75 万亿参数的怪兽

> 原文：<https://towardsdatascience.com/gpt-3-scared-you-meet-wu-dao-2-0-a-monster-of-1-75-trillion-parameters-832cd83db484?source=collection_archive---------0----------------------->

## 人工智能

## 悟道 2.0 比 GPT-3 大 10 倍。想象一下它能做什么。

![](img/deeb53fa8868f31f0549adf73b648ba9.png)

[GR Stocks](https://unsplash.com/@grstocks?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍照

我们生活在人工智能激动人心的时代。一年前，OpenAI 凭借 [GPT-3](/gpt-3-a-complete-overview-190232eb25fd) 震惊了世界。两周前，谷歌展示了 LaMDA 和 MUM ，这两款人工智能将分别彻底改变聊天机器人和搜索引擎。就在几天前，6 月 1 日，北京人工智能研究院(BAAI)发布会上展示了悟道 2.0。

悟道 2.0 现在是有史以来创建的最大的神经网络，可能也是最强大的。它的潜力和局限性尚未完全披露，但人们的期望很高，这是理所当然的。

在这篇文章中，我将回顾关于悟道 2.0 的可用信息:它是什么，它能做什么，以及它的创造者对未来的承诺是什么。尽情享受吧！

# 悟道 2.0:与 GPT 3 相比的主要特点

## 参数和数据

悟道是另一种类似 GPT 的语言模式。OpenAI 的政策主管 Jack Clark 称这种复制 GPT-3 的趋势为“模型扩散”然而，在所有副本中，悟道 2.0 以惊人的 1.75 万亿次参数(10 倍 GPT-3)保持着最大的记录。

[Coco Feng](https://www.scmp.com/tech/tech-war/article/3135764/us-china-tech-war-beijing-funded-ai-researchers-surpass-google-and) 为*南华早报*报道，悟道 2.0 是在 4.9TB 的高质量文本和图像数据上进行训练的，这使得 GPT-3 的训练数据集(570GB)相比之下相形见绌。然而，值得注意的是，OpenAI 的研究人员整理了 45TB 的数据，以提取干净这 570GB。

训练数据分为:

*   武道语料库 1.2TB 中文文本数据。
*   2.5TB 中文图文数据。
*   Pile 数据集中的 1.2TB 英文文本数据。

## 多模态

悟道 2.0 是多模态的。它可以从文本和图像中学习，并处理包含这两种类型数据的任务(这是 GPT 3 号做不到的)。在过去的几年里，我们看到了从专门管理单一信息模式的人工智能系统向多模式的转变。

预计计算机视觉和自然语言处理，传统上是深度学习的两大分支，将在未来的每个人工智能系统中结合起来。世界是多模态的。人类是多感官的。创建模仿这一特征的人工智能是合理的。

## 专家的混合

武道 2.0 是用 FastMoE 训练的，这个系统类似于谷歌的[混合专家](https://arxiv.org/pdf/2101.03961.pdf) (MoE)。这个想法是在一个更大的模型中为每个模态训练不同的模型。选通系统允许较大的模型为每种类型的任务选择参考哪个模型。

与谷歌的 MoE 不同，FastMoE 是开源的，不需要特定的硬件，这使得它更加民主。它让 BAAI 的研究人员解决了阻止 GPT-3 等模型达到 1 万亿参数里程碑的训练瓶颈。他们[在 BAAI 官方微信博客中写道](https://mp.weixin.qq.com/s/NJYINRt_uoKAIgxjNyu4Bw)“【FastMoE】使用简单，灵活，高性能，支持大规模并行训练。”未来的大型 AI 系统一定会经过这些训练框架。

# 悟道 2.0 的神奇功能

## 多任务处理

在为 *VentureBeat* 、[撰写的一篇文章中，Kyle Wiggers](https://venturebeat.com/2021/06/04/ai-weekly-chinas-massive-multimodal-model-highlights-ai-research-gap/) 强调了悟道 2.0 的多模态能力:它拥有“执行自然语言处理、文本生成、图像识别和图像生成任务的能力。[……]以及为图像添加字幕和创作近乎照片级的艺术作品，给出自然语言描述。”

Andrew Tarantola 为 *Engadget* 写道，Wu Dao 2.0“既可以基于静态图像生成替代文本，也可以基于自然语言描述生成近乎照片般逼真的图像。它还可以预测蛋白质的三维结构，比如 DeepMind 的 AlphaFold。

首席研究员唐杰强调了悟道 2.0 在“诗歌创作、对联、文本摘要、人类设置问题和答案、绘画”方面的技能，甚至承认该系统“已经接近突破图灵测试，并与人类竞争。”

悟道 2.0 没有什么好羡慕 GPT-3 或任何其他现有的人工智能模型的。它的多任务能力和多模态特性赋予了它最全能人工智能的称号。这些结果表明，多人工智能将主宰未来。

## 基准成就

正如 BAAI[所报告的](https://mp.weixin.qq.com/s/NJYINRt_uoKAIgxjNyu4Bw)(基准:成就)，悟道 2.0 在 AI 社区广泛认可的 9 个基准任务上达到/超过了最先进(SOTA)的水平。

*   ImageNet(零拍):SOTA，超越 [OpenAI 剪辑](https://openai.com/blog/clip/)。
*   喇嘛(事实和常识):超过[自动提示](https://arxiv.org/abs/2010.15980)。
*   兰巴达(完形填空任务):超越了[微软图灵 NLG](https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/) 。
*   强力胶(少杆):SOTA，超过[GPT-3](https://arxiv.org/abs/2005.14165)。
*   加州大学默塞德分校土地利用(零拍摄):SOTA，超过开放艾剪辑。
*   COCO 女士(文字生成图):超越 [OpenAI DALL E](https://openai.com/blog/dall-e/) 。
*   COCO 女士(英文图文检索):超越了 OpenAI CLIP 和 [Google ALIGN](https://ai.googleblog.com/2021/05/align-scaling-up-visual-and-vision.html) 。
*   COCO 女士(多语言图文检索):超越 [UC](https://arxiv.org/pdf/2104.00332.pdf) (最佳多语言多模态预训练模型)。
*   多 30K(多语种图文检索):超过 UC。

不可否认，这些结果是惊人的。悟道 2.0 在任务和模式的关键基准测试中取得了优异的成绩。然而，在这些基准测试中，缺少武道 2.0 和 SOTA 模型之间的定量比较。在他们发表论文之前，我们只能等着看悟道 2.0 的惊艳程度了。

## 虚拟学生

华，悟道 2.0 的孩子，是中国第一个虚拟学生。她可以不断学习，作曲，画画，以后还会学编码。与 GPT-3 相比，悟道 2.0 可以随着时间的推移学习不同的任务，不会忘记之前所学的内容。这个特性似乎让人工智能更接近人类的记忆和学习机制。

唐杰甚至声称，华冰之有“一些推理和情感互动的能力。”*人民网* [报道](http://en.people.cn/n3/2021/0604/c90000-9857985.html)唐课题组成员彭爽“希望虚拟女孩情商高，能像人一样交流”

当人们开始玩 GPT-3 时，许多人对结果感到疯狂。“有感觉的”、“一般的智力”和能够“理解”是人们赋予 GPT-3 的一些特征。到目前为止，还没有证据证明这是真的。现在，球在悟道 2.0 的球场上，向世界展示它有能力“推理和情感互动”现在，在下结论之前，我会谨慎行事。

# 最后的思考:走向 AGI 的武道 2.0

BAAI 的一些最重要的成员表达了他们对武道 2.0 在通往 AGI(人工通用智能)道路上的作用的想法:

> “人工通用智能的途径是大模型和大计算机。*[……]*我们正在为人工智能的未来建造一座发电站。凭借海量数据、海量计算能力和海量模型，我们可以转变数据，推动未来的人工智能应用。”
> 
> —BAAI 董事长张宏江博士
> 
> “这些在巨大数据集上训练的复杂模型，在用于特定功能时只需要少量新数据，因为它们可以像人类一样，将已经学习的知识转移到新的任务中。[……]大规模预训练模型是当今人工通用智能的最佳捷径之一。”
> 
> — Blake Yan，人工智能研究员
> 
> 悟道 2.0 旨在让机器能够像人类一样思考，实现超越图灵测试的认知能力。"
> 
> —唐杰，悟道 2.0 背后的首席研究员

他们寄希望于 GPT 式的多式联运和多任务模式，以到达 AGI。毫无疑问，悟道 2.0——如同之前的 GPT 3——是迈向 AGI 的重要一步。然而，它能让我们走得更近还存在争议。一些专家认为我们需要混合动力车型才能进入 AGI。其他人则完全捍卫具身人工智能，拒绝传统的无形范例，如神经网络。

没有人知道哪条路是正确的。即使更大的预训练模型是当今的逻辑趋势，我们可能会只见树木不见森林，最终我们可能会达到一个不那么雄心勃勃的上限。唯一清楚的是，如果这个世界不得不遭受环境破坏、T2、有害偏见或 T4 的高额经济成本，那么去 AGI 都不值得。

*订阅* [**算法桥**](https://thealgorithmicbridge.substack.com/) *。弥合算法和人之间的鸿沟。关于与你生活相关的人工智能的时事通讯。*

*您也可以直接支持我在 Medium 上的工作，并通过使用我的推荐链接* [**这里**](https://albertoromgar.medium.com/membership) 成为会员来获得无限制的访问权限！ *:)*