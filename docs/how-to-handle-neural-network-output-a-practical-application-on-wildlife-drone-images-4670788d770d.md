# 如何处理神经网络输出:野生动物无人机图像的实际应用

> 原文：<https://towardsdatascience.com/how-to-handle-neural-network-output-a-practical-application-on-wildlife-drone-images-4670788d770d?source=collection_archive---------22----------------------->

## 处理人工智能训练的输出不一定简单，需要仔细观察数据。

## 通过使用[野生智能实验室](https://wildintelligencelab.com/)提供的航拍图像，我们试图找到一个好的结构，并深入了解[库兹库斯野生动物保护区](https://www.kuzikus-namibia.de/xe_index.html)的土豚洞和枯树。

本文是对主项目中数据科学部分的额外的、更全面的介绍。主要文章已经详细介绍了该项目的起因以及如何训练 Mask RCNN 为我们服务。它可以在这里找到:

<https://wildintelligencelab.com/deadwood-and-aardvark-hole/>  

## 提供机器学习数据

我们开始查看所提供的信息及其出现的形式。从掩模 RCNN 神经网络结构中，我们得到以下输出:

1.  **图像分类**(输入图像的预测内容标签): *dead_tree* 或 *aardvark_hole*
2.  **语义分割**(将输入图像中的像素与来自 1 的适当类别标签相关联)
3.  **物体检测**(通过边界框捕获的图像中物体的位置):*【x 轴，y 轴，宽度，高度】* - >例如【1925，248，1962，271】
4.  **实例分割**(结合对象检测和语义分割以获得检测和精确分割):这输出一个数组，其中每个二进制值表示一个像素是否属于分割遮罩，例如*[[假、假、假、假、假、真、Tr…】*

![](img/da324f3bbd699c36325f6f34fe717d4d.png)

**可视化 1–4 来自**[**stat twiki**](https://wiki.math.uwaterloo.ca/statwiki/index.php?title=Mask_RCNN)

为了在单个图像切片上实现它，我们使用下面的代码。通过改变第 7 行中选定的图像，我们可以看到神经网络生成的结果。

虽然这为我们提供了一个覆盖了分类的图像，但我们现在希望以数字形式详细查看输出。我们可以看到，由于输出 ROI 时的 4 个不同阵列，我们在该图像中检测到了 4 个对象。

```
>>print(r['rois'].shape)
(4, 4)
>>print(r['rois'])
[[ 767  0  801   26]  [ 868   37  891   62]  [ 316 1763  341 1787]  [2004  980 2026 1006]]
>>print(r['masks'].shape)
(2048, 2048, 4)
```

另一方面，遮罩为我们提供了一个二进制数组(图像原始切片的大小)。当绘制它时，我们可以清楚地看到神经网络发现的面具。观察标签和面具的大小，我们可以看到在这个特定的输入图像中有 4 个土豚洞。有可能为每一个单独返回它们的边界框和相应的遮罩。

![](img/eeb5d0eb7e1efee56ceeb3a7aeef3f94.png)

**绘制掩码** // plt.imshow(r["masks"][:，:，0]+r["masks"][:，:，1]+ r["masks"][:，:，2] + r["masks"][:，:，3])

## 数据框架

看到并掌握了掩蔽 RCNN 呈现给我们的新发现的信息，我们现在需要考虑适当地存储数据。但是我们使用的格式很大程度上取决于我们想要得到什么样的内部信息。在第一次头脑风暴中，我们集中讨论了以下一系列模糊的问题:

*   从枯树上估计木头的重量
*   分析枯树的存在
*   一簇簇枯树
*   分析土豚洞的存在
*   某些区域的成簇孔洞
*   土豚洞的大小——与邻居的关系

这是一个困难的情况，因为我们关注每一个单独的物体，但也关注它们与周围环境的关系，从而关注全局。最方便的方式似乎是将每个检测到的对象存储为单独的实例，以便能够例如单独估计大小。我们通过构造一个数据帧并给这个表中每个检测到的对象一个自己的行来做到这一点。最后，我们将有一个填充了所有土豚洞的数据帧和一个检测到所有枯树的数据帧。我们从以下几列开始: **ID** (唯一标识符)**标签**(枯树或土豚洞)**原点**(原始目录)**x 和 y 坐标的 pic 位置**(给我们原始大图中切片的位置)**边界框坐标**，**遮罩数组**及其对应的**遮罩尺寸**。

![](img/11448dde6d39314c92708e94f0af33c9.png)

**直接从屏蔽 RCNN 输出**

这看起来已经比单独查看每张图片要干净得多了。有了这么好的表现，我们甚至可以问一些最初的问题:每个土豚洞/死树的大小是多少。通过对掩码数组中的真值求和，我们得到表示掩码填充的像素总和的掩码大小。在无人机图片的元数据中，我们得到一个像素大约为 4 厘米的信息。因此，我们已经可以向表中添加一个新列，说明以平方米为单位的大小。对于我们的其他问题，我们没有使用掩码数组，并决定放弃它。

## 减少信息

和掩码数组一样，我们现在看看所有其他值，并尝试评估它们给我们带来了什么信息，如果有办法的话，只将它减少到最低限度。拥有所有的像素值使得开始进一步的分析变得困难。所以既然我们已经有了平方米的尺寸，我们就不再需要完整的边界框和它所有的 x 和 y 值了。但是我们需要的是边界框的位置。

![](img/f365cbe5b5a349ccf498bb3c1a52933c.png)

**计算每个包围盒的质心**

因此，我们不使用所有四个值，而是只查看每个边界框的质心。我们通过取宽度和高度的一半，并用边界框的质心的 x 和 y 值生成一个新的数组。从四个点增加到两个点似乎很简单，但是这一步已经使进一步的分析变得更加容易。通过一个点(一维)而不是一个区域(二维)，我们现在可以很容易地计算多个物体之间的距离，并通过散点图非常直观地显示它们。我们现在只需要一个(2，4)数组，而不是像我们对遮罩那样绘制一个(2048，2048，4)数组。四个物体的两个坐标。详细的形状对于聚类分析和距离计算来说是可以忽略的，并且明显比便宜得多的成本更重要。

![](img/e56477072ac03c1068e61522448d0f03.png)

**全无人机拍摄覆盖了所有土豚洞的散点图**

通过使用我们所拥有的关于切片在整个图像中的确切位置的信息，我们还可以以这样的方式改变值，即质心不仅仅代表物体在切片中的位置，而是代表整个拼接在一起的无人机拍摄。我们现在有效地将原始的 11 GB 照片压缩成几 MB。当然，颜色、背景和一些细节都不见了，但是我们想要的信息仍然是完整的。我们甚至可以用散点图覆盖原始背景图像，给我们一个现实生活中物体位置的指示。虽然听起来很强大，但在 python 中，背景图像需要极大地缩小才能做到。因为我们不能保持足够的信息和细节，所以它只能成为一个视觉辅助，我们可以放大到最终的情节。

通过查看代码，我们还可以看到，为了使背景与散点图一致，我们需要在第 1 行中适当地设置 figsize，在第 2 行中适当地设置范围。这主要是一个估计，因此这就是为什么在上面的图中一些点位于背景图像之外的原因。

![](img/6c1a2f96957fa0d1c9a00c10921763e8.png)

**遮罩旁的实际图像**

通过执行这些步骤，我们可以组织模型的输出，并以这样的方式减少输出，这样我们只剩下必要的信息用于进一步的分析。同时，这也给我们带来了好处，我们已经能够很好地估计我们探测到的物体的大小。不幸的是，这并没有为死树估计提供好的结果。土豚洞的大小很简单，它们的深色使得神经网络更容易绘制出准确的面具，而树木的复杂形状则不是这样。

## **感受数据**

![](img/dbf9a5dbd66e2ca17ab3227af55a8e77.png)

**质心分布** //海风显示

在进入高级主题之前，建议花点时间查看数据，并重新评估它是否正确。我们关注土豚洞及其在地形中的分布和大小。重叠散点图不会根据单个孔的大小进行缩放，只有通过丰富的想象力才能发现多个孔的大量集合。

![](img/e141e92c47c3ff4710602815e48ec1a4.png)

**土豚洞的数量根据它们的大小** //直方图绘制

根据大小标绘所有的洞使我们能够看到所有洞的范围和分布。我们的结果表明，平均孔尺寸约为 0.13 平方米，而中位数约为 0.11 平方米。我们可以看到一个钟形曲线，这是我们对自然现象的预期。

## 寻找土豚洞群

土豚以它们的洞穴而闻名，但也以它们的地下隧道系统而闻名。Kuzikus 野生动物保护区提供的研究表明，两个洞之间的隧道可长达 10 米。考虑到这个距离，我们的下一个目标是找到可能相连的洞，形成一个更大的隧道系统。

这是一个非常简单和天真的方法，使用空间中的欧几里德距离来测量两个洞之间的米数。然后，从满足 10m 以下限制的数据帧中构建一个数据帧。但是通常天真的方法是最方便的，因为手头没有额外的数据，我们决定选择这个选项。

在距离矩阵的帮助下，我们可以提取每个洞的“邻居”,并以包括所有可能连接的洞的方式创建聚类。如果 36。和 39。球洞都与 38 号球洞相连，聚类列表包括一组中的所有 3 个球洞。最后，我们在数据框中添加了一个“组”列，为位于同一个集群中的组分配相同的组号。

![](img/0603e9116d1eaa8efe27a0564c34dd22.png)

**包含 10 个土豚洞的最大集群**

应用质心图中的代码并为相应的簇添加连接线，会产生标记所有连接孔的图像。对于未来的可视化，将有可能计算集群的中心点，并围绕它绘制一个半径。目前，我们只尝试了固定半径。根据每个群中的洞的数量使用可变的一个将极大地改善这种可视化。这样一个集群的相应半径，然后可以通过赋予它一个概率增强效应来用于改进人工智能模型。然后，其中的对象将被标记为土豚洞，具有更高的确定性，因为预先存在该区域是聚类的一部分的知识。

![](img/e6a1073fc604cdae9db505ccada17979.png)

**集群投影和半径概念**

## 图象分割法

尽管我们的模型在估算土豚洞的真实尺寸时给了我们非常好的结果，但在处理枯树时却不那么成功。正如我们在上面的可视化中已经看到的，遮罩本身就是问题所在，因为它不够精确。为了获得更好的效果，我们将注意力转移到了边界框和它所包围的物体上。由此看来，对这件作品进行图像分割似乎是合理的。

**K-均值聚类**

用于图像分割的最著名的算法之一。有很多关于这个主题的文章，最好看一看，以便更好地理解底层的过程。我们按照[这篇文章](https://medium.com/swlh/image-segmentation-using-k-means-clustering-46a60488ae71)的思路构建了一个处理裁剪图像的函数。

然后，它输出原始图像旁边的分割图像，并显示图像中存在的颜色和绝对值。

![](img/94040bb9e2ef839b45fb8fbdba4d6859.png)

k-均值分割

我们已经可以看到这里的主要问题。颜色太相似了。很难从背景中分辨出枯树的颜色。在这个特殊的例子中，采用阴影(最暗的颜色)作为尺寸的指示器似乎是有用的，但是它不是一个通用的解决方案，并且对于其他物体是无效的。不幸的是，即使是更大的 K 也不能解决这个问题，因此唯一合理的步骤是更进一步，依靠最新和最先进的聚类和图像分割形式之一。

**自组织映射** ( **SOM):**

[Derrick Mwiti](https://medium.com/u/4b814c3bfc04?source=post_page-----4670788d770d--------------------------------) 用简单明了的方式解释了它的原理:

> “自组织映射是一类用于特征检测的无监督学习神经网络。它们用于产生训练样本的低维空间。因此，它们被用于降维。”

他在 SOMs 上写的文章是进入这个话题的一个很好的入口，非常适用于死树问题。与 Derrick 所做的类似，我们可以将[minicom](https://github.com/JustGlowing/minisom)实现应用到我们自己的输入中。

绘制 *img_som，聚类*和对应的*权重*我们得到如下结果。

![](img/da2a72dc0455aabacb3f2ce8159c0096.png)

**具有 9 种学习颜色的 SOM**

很明显，即使是 SOMs 也不能解决颜色相似的问题。虽然它没有为我们解决任何问题，但我们从图像分割中得到了有价值的知识:现在这是一个死胡同。这可能看起来很烦人，但是提高估计的唯一方法是回到掩码。重新标记数据和更加小心地选择 labelme 中的对象可能看起来远不如应用最先进的技术迷人，但这往往是必要的罪恶。要有好的结果，良好的投入是必要的！

在这个项目中，我与 [Nuray Agaoglu](https://www.linkedin.com/in/nuray-agaoglu-02b4211b9) 一起研究数据科学部分，我衷心感谢她投入的时间。