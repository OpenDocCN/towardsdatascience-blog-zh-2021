# 人工智能盲点—第一部分

> 原文：<https://towardsdatascience.com/ai-blindspots-part-i-shared-responsibility-5e05824c19b4?source=collection_archive---------36----------------------->

# 分担责任

*沙欣·高赫尔博士*

AI 和技术是环境。人工智能也被吹捧为所有企业的灵丹妙药，企业之间开始了巨大的举措，数百万人被投入到创建“人工智能解决方案”中。人工智能嵌入了我们的生活，并以各种方式影响着我们的生活，这些方式在奖励和兴奋与担忧之间摇摆不定。

在这一系列帖子中，我将重点介绍一些 AI 盲点，如何发现它们以及如何避免它们。在*第一部分——分担责任*中，我们将更仔细地看看围绕人工智能中的道德和责任的讨论。在 [*第二部分——感受授权*](https://shaheen2007.medium.com/ai-blindspots-part-ii-feeling-empowered-529ba079e945?source=friends_link&sk=c6c2c959491dc80434da69990a43cc04) 中，我们将讨论 Gartner 报告的导致人工智能计划巨大失败率的陷阱，并分享一些如何避免它们的技巧。在 [*第三部分——团队动力*](https://shaheen2007.medium.com/ai-blindspots-part-iii-team-dynamics-e0b6b6b9b79a?source=friends_link&sk=da6148d24963e7f3b6ea07f3411432de) 中，我们将谈论汤姆·布拉迪和团队合作。

让人工智能负责是最近的热门话题，受到了很多关注[1][2]。我衷心欢迎这些讨论。不可否认人工智能的变革力量，以及它对我们的生活和生计直接、间接甚至悄悄地产生的影响。随着对使用人工智能进行自动决策的负面影响的认识不断增加[3][4[5][6]，人们越来越担心其对弱势群体的过度影响[7][8]。进行这些对话的重要性怎么强调都不为过。围绕算法的公平性和可解释性，有大量的研究正在进行。然而，只关注人工智能只能让我们了解故事的一半。在这篇文章中，我建议将讨论主题从“负责任的人工智能”改为“**负责任地使用人工智能”**。迫切需要通过邀请所有参与人工智能业务的各方——构思、构建、交付、传播和接收——来使对话更具包容性和多样性。拥有合适的讨论主题和所有相关方的参与将有助于我们共同实现负责任和合乎道德地使用人工智能的目标，并能够使用它来改善人类。

![](img/5e892dca514a5c6268d53f1ac203207a.png)

作者图片

尽管它周围有着神奇的光环，但在它的核心，人工智能是一个决策工具。应该像对待任何其他工具一样，以同样的严格性和质量控制期望来对待它。它是一种工具，可以做出预测，然后用来做决定和采取某些行动。我喜欢把人工智能看作是数据驱动的类固醇决策。

让我们休息一会儿，做一个思维实验。看下面三张图。

![](img/99037420951733695326d1b1c709feef.png)

(左)乔纳森·肯珀在 [Unsplash](https://unsplash.com/s/photos/sword?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) |(中)格伦·汉森在 [Unsplash](https://unsplash.com/s/photos/welding?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) |(右)克里斯·阿蒙在 [Unsplash](https://unsplash.com/s/photos/sword?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

在剑造成伤害的情况下，谁应该对造成伤害负责，谁应该为剑伤的身体、精神和情感治疗买单？剑，剑的制造者还是剑的使用者？在现实世界中，造成伤害的责任完全在于挥剑的人。

同样，如果一家企业决定使用人工智能来做决定，而这些决定的结果是有偏见的、歧视性的和有害的，那么不负责任的使用的责任就在于决策者。无论决策是外包给咨询公司还是 AI，客户安全和公平待遇的最终责任完全在于企业。责任由你承担。你是老板。

![](img/273e40bb5c3fca38d559c45f19bb36e8.png)

作者图片

人工智能优化它被告知要优化的东西。关键是你要问正确的问题。你可能会说，“我知道如何经营企业，那是我的工作。我不知道 AI 是怎么工作的。我没有 STEM 学位或博士学位。”这是一个有效的论点，幸运的是你不需要这么做。知道如何使用和知道如何构建是两个不同的需求。汽车是一个很好的类比——我们知道如何驾驶汽车，我们了解交通标志和规则，我们知道如何加油，我们中的一些人甚至可以更换漏气的轮胎！订购汽车并不要求我们知道如何制造汽车，而是要求我们知道如何正确使用汽车。订购一个 AI 模型也是如此。如果你要为你的企业订购重型机械，常识性的清单可以在订购人工智能时重新使用。不要求理解制造机器的机械和电气工程的细微差别，但是您需要问以下问题:

![](img/a7bdcf9be56fccf60b0fbb2d2d577e24.png)

(左上)图为[特洛伊·莫蒂耶](https://unsplash.com/@troyscanon?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)在[上](https://unsplash.com/s/photos/construction-site?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) |(上中)图为[米卡·鲍梅斯特](https://unsplash.com/@mbaumi?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)在[上](https://unsplash.com/s/photos/construction-site?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) |(右上)图为[上](https://unsplash.com/s/photos/heavy-machinery?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)[维奥利塔·彭考斯卡](https://unsplash.com/@wiola3001?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)在上【左下角】图为[特洛伊·莫蒂耶](https://unsplash.com/@troyscanon?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)在[上](https://unsplash.com/s/photos/construction-site?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) |(右下)图为

这台机器是做什么的？它会导致生产率的提高吗？生产率的提高是否证明购买、维护、储存和人员培训的费用是合理的？它符合安全标准吗？它有什么样的安全功能？靠谱吗？操作起来有多复杂，需要多少培训才能最佳地使用它？是否存在任何可能妨碍实际使用的基础设施缺口？几乎是适用于采用任何新工具或产品的标准投资和风险评估活动。

人工智能有潜力改变商业并刺激创新。如果你问正确的问题，并关心你的业务和你的客户，你可以利用人工智能的力量来提高利润和生产力，同时为你的客户提供公平和增强的体验。在这个系列的第二部分，我将分享一些百万美元的问题。毫不夸张地说。提前问这些问题可能会让你避免失败的计划和由此带来的经济损失，潜在的公关灾难，甚至在一些极端情况下的诉讼。敬请关注。

*@Shaheen_Gauher*

观点是我自己的，不反映我过去或现在的工作地点。

如果你发现这篇文章相关，请分享和传播！

[![](img/0da5bc9889c6189860d8726a9eb6939f.png)](https://www.linkedin.com/shareArticle?mini=true&url=https%3A//towardsdatascience.com/ai-blindspots-part-i-shared-responsibility-5e05824c19b4?source=friends_link%26sk=62d5aa86212f9bc06981053463dae886&title=AI%20Blindspots%20%E2%80%94%20Part%20I%20%E2%80%94%20Shared%20Responsibility&summary=In%20Part%201%E2%80%8A%20of%20AI%20Blindspots%20series,%20we%20will%20talk%20about%20using%20AI%20Responsibly%20and%20making%20the%20conversation%20around%20fairness%20and%20bias%20more%20inclusive%20and%20diverse.&source=)[![](img/60cddc28900e73a3a88e1cfadbded152.png)](https://twitter.com/intent/tweet?text=Check%20out%20this%20series%20of%20posts%20on%20%E2%80%9CAI%20Blindspots%E2%80%9D%20by%20%40Shaheen_Gauher%20-%20Part%201%E2%80%8A%20discusses%20Ethics%20and%20Responsibility%20in%20AI.%20Part%20II%20shares%20some%20million-dollar%20questions%20to%20ask%20to%20avoid%20a%20failed%20AI%20initiative.%20Part%20III%E2%80%8A%20talks%20about%20about%20team%20dynamics,%20AI%20quarterback%20and%20Tom%20Brady!%20)

确认:

非常感谢 Mary Wahl、Christy Fletcher 和 Miguel Fierro 的审核和宝贵反馈。

参考资料:

[1][https://www . NIST . gov/news-events/news/2019/07/NIST-releases-draft-plan-federal-engagement-ai-standards-development](https://www.nist.gov/news-events/news/2019/07/nist-releases-draft-plan-federal-engagement-ai-standards-development)

[2][https://digital-strategy . EC . Europa . eu/en/policies/European-approach-artificial-intelligence](https://digital-strategy.ec.europa.eu/en/policies/european-approach-artificial-intelligence)

[3][https://www . nytimes . com/2019/08/20/upshot/housing-discrimina tion-algorithms-hud . html](https://www.nytimes.com/2019/08/20/upshot/housing-discrimination-algorithms-hud.html)

[4][https://www . nytimes . com/2021/03/15/technology/artificial-intelligence-Google-bias . html](https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html)

[5][https://www . Brookings . edu/research/credit-denial-in-the-age-of-ai/](https://www.brookings.edu/research/credit-denial-in-the-age-of-ai/)

[6][https://www . wired . com/story/Google-Microsoft-warn-ai-may-do-dumb-things/](https://www.wired.com/story/google-microsoft-warn-ai-may-do-dumb-things/)

[7][https://ncrc . org/the-Washington-post-racial-bias-in-a-medical-algorithm-favors-white-patients-over-sicker-black-patients/](https://ncrc.org/the-washington-post-racial-bias-in-a-medical-algorithm-favors-white-patients-over-sicker-black-patients/)

[8][https://www . technology review . com/2020/12/04/1013068/algorithms-create-a-poverty-trap-lawyers-fight-back/](https://www.technologyreview.com/2020/12/04/1013068/algorithms-create-a-poverty-trap-lawyers-fight-back/)