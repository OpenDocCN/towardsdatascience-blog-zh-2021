# 产品人员需要知道的关于变形金刚的一切(第三部分:伯特)

> 原文：<https://towardsdatascience.com/everything-product-people-need-to-know-about-transformers-part-3-bert-a1227cead488?source=collection_archive---------13----------------------->

## 确定变压器供电产品范围所需的一切

> 这是面向产品人员的变形金刚系列的第 3 部分。[点击此处查看第一部分](https://yacovlewis.medium.com/everything-product-people-need-to-know-about-transformers-gpt-3-and-huggingface-6a2e8a45316a)。本文依赖于前几篇文章中介绍的概念和信息。如果你对变形金刚和 GPT 不熟悉，建议从第 1 部分开始。

如果你正在读这篇文章，你正在设计、管理或投资技术产品。你也可能只是一个聪明的工程师或数据科学家，他们发现这些文章对于理解新的研究非常有用。那么，你真的需要了解变压器模型吗？我们的变形金刚模型有什么好的吗？

号码

![](img/31e79e7145e8fdbac60f899a5178cefe.png)

这家伙明白了

要打造尖端产品，了解变压器模型。谷歌的产品人员非常了解变形金刚，带领他们[改进他们核心业务的产品线](https://blog.google/products/search/search-language-understanding-bert/):搜索。哼唱查找歌曲—由 BERT 提供支持。特色片段——由 BERT 提供。视频中的关键时刻——由 BERT 提供。这些功能您可能已经很熟悉了:

![](img/0f6220380415f36ac493e0c018d402e7.png)

熟悉的基于变形金刚模型的谷歌特性

要理解变压器模型，就要理解伯特和 GPT。每个都有一个独特的架构，为特定的训练任务进行了优化。虽然我现在可以告诉您每个型号最适合哪些应用，但解释设计选择和型号之间的差异将使您能够识别尚未尝试的新应用。

以下部分将介绍 BERT，这需要了解生成性预培训(GPT)。在[第 2 部分](/everything-product-people-need-to-know-about-transformers-part-2-gpt-34c065ba07bf)中，我深入解释了 GPT 模型架构，我建议在从这里继续之前先阅读那篇文章。警告:如果你还没有阅读第 2 部分，下面的部分会让你困惑，这是你的错。在解释了 BERT 架构之后，我将把这个模型放在我的关于 transformer 模型的更大系列中，以便能够完全识别和评估潜在的应用。

# 伯特解释道

在 OpenAI 推出 GPT 四个月后，谷歌发布了《变形金刚:双向编码器表示》。BERT 利用了预先训练的变压器的能力，同时解决了 GPT 架构带来的一些限制。通过这样做，BERT 极大地扩展了变形金刚可以有效处理的任务集。

我们将从总结**开始，只总结**伯特创新的 GPT 的那些组成部分:

> 1.GPT 的设计方法是从变压器(T-ED)中去掉编码器组件，只保留解码器(T-D)。
> 
> 2.解码器有时被称为生成器，其功能相当于语言模型，这意味着它被优化来预测句子中的下一个单词。
> 
> 3.在这个模型中，注意力的作用是单向的，这意味着该模型在预测下一个单词时只能查看前面的单词，而不能查看将跟随神秘标记的单词。

GPT 是第一个建立在 transformer 架构上的基于微调的语言模型，这意味着它创建了一个使用下一个单词预测训练的可预训练的 transformer。基于下一个单词预测语言建模产生了一个主要的限制:只有先前的上下文可以用来理解意思。伯特的作者指出:

> [单向注意力的局限性]对于句子级任务来说是次优的，并且在将基于微调的方法应用于标记级任务(如问答)时可能是非常有害的，在标记级任务中，从两个方向结合上下文是至关重要的。

本质上，如果需要理解一个句子中的*，那么仅仅依靠句子的第一部分将会太受限制。这里有一个例子可以说明这个问题:“今天，我去**超市**买了一些面包和花生酱。”自动更正有两个潜在的候选者:*， ***流*** 。两者在拼写上同样接近于“strome ”,当只考虑到这一点的句子时，两者都是可信的。建立在 GPT 上的自动更正工具将依赖于文档上下文，直到“strome”作出决定。如果批判性语境直接跟着，我们就不能做得更好吗？**

*Transformer 模型需要双向关注，以便将来自两个方向的上下文合并到模型决策中。变压器-解码器(T-D)适合语言建模，因此预先训练，只有单向注意。双向注意力的预训练需要利用转换器-编码器(T-E)，这是双向注意力在 T-ED 中发生的组件。*

*因此，BERT 架构基于仅保留 T-ED 的编码器组件。与 GPT 的 T-D 相比，伯特是一个 T-E。训练一个 T-E 不如训练一个 T-D 简单，我们会看到。尽管如此，现在是回顾我们在过去三篇文章中看到的不同变压器架构的好时机。简而言之，三个占主导地位的 NLP 模型是:*

1.  *变形金刚:T 型*
2.  *GPT: T-D*
3.  *伯特:T-E*

*而其他型号的名称有 RoBERTa、DistilBert、T5、DialoGPT 等。所有这些模型都具有上述三种架构之一。这就是你需要了解的最高层次的变压器架构。*

# *训练伯特*

*请特别注意这里描述的语言建模任务，因为它们直接决定了这些模型的潜在应用。*

*T-E 花了最长的时间才被发表(几乎比 T-ED 晚了一年)，因为它最不容易被训练。这个问题源于给 T-E 提供单语任务的全文。如果 T-E 被输入了完整的输入句子，你能用什么训练任务来挑战它？如果一开始就给它输入了正确的句子，你怎么能让它决定“流”和“存储”中的哪一个构成正确的句子呢？为了解决这个问题，BERT 发布了两个不同的训练任务。*

*伯特首先被训练成一个蒙面语言模型(MLM)。MLM 需要递给伯特一句话，比如“我坐在椅子上[戴着面具]”，并要求伯特预测这个带面具的单词。下一个单词预测语言建模可以被认为是 MLM 的一个特例，其中句子中的最后一个单词总是被屏蔽的单词。因此，MLM 可以被认为是一种比训练 GPT 的任务更一般化的语言模型。*

*在 MLM 之后，伯特接受了一项名为“下一句话预测”的任务训练。在这个任务中，向 BERT 传递由指示符分隔的句子对。伯特被训练来预测第二句话是否应该跟在第一句话后面，或者实际上是不相关的。一个例子是这样的:*

*![](img/1e863bf3b0e9709f5a1c82dec73699c1.png)*

*训练前的下一句预测任务*

*伯特和你一样，应该预测“低概率”。*

*这两项任务构成了使 BERT 容易适应新任务的预训练。*

# *BERT 的应用*

*理解 BERT 训练任务对于确定其应用是至关重要的。它是这样工作的:如果你能表明你希望你的产品为客户执行的任务可以被框定为这些培训任务中的一个，那么你的任务就是一个可行的应用。让我们看看谷歌的特色片段，并以谷歌产品经理(PM)鲁本为例。*

*鲁本是一名在谷歌搜索工作的项目经理，他对伯特很熟悉。鲁本注意到，许多用户在谷歌搜索栏中输入完整的问题，然后浏览建议的结果来找到他们的答案。他已经确定了一个客户需求:用户有他们需要回答的问题，但他们希望保持他们现有的查询 Google 搜索栏的行为。*

*Reuben 密切跟踪一个用户的会话，并观察到以下行为:他的用户在谷歌搜索中键入以下问题:“美国有多少数据科学家。”用户然后点击第一个网站，看到下面的句子:“根据 Glassdoor 的数据，2019 年至 2020 年，美国数据科学家职位的增长持平，约为 6500 个。”用户复制这句话，并粘贴到他的谷歌文档。*

*考虑到他目前的产品，Reuben 注意到 Google 的解决方案检索了可能包含用户问题答案的文档集。然后，用户需要筛选这些文档来找到答案。用户以这样一句话开始:“美国有多少数据科学家。”然后选择句子:“根据 Glassdoor 的数据，2019 年至 2020 年，美国数据科学家职位的增长持平，约为 6500 个。”鲁本意识到这项任务可以转化为下一句预测的伯特训练任务。他可以使用 BERT 基于句子将“跟随”查询句子的概率来对检索到的语料库中的句子进行排序。*

*实际上，他希望他的 BERT 输出看起来像这样:*

*![](img/d1e2bd01cbc8c7add6e7bae7a1e437e8.png)*

*用于微调的 BERT 问答任务*

*将一个领域特定的任务转化为一个 transformer 培训任务本质上是对您的模型进行微调的过程。为了开发有特色的片段，Reuben 希望对 BERT 进行微调，将它的行为从查找最有可能跟随查询的句子转变为查找最有可能回答用户问题的句子。鲁本可以通过在一组更直接符合这种模式的句子对上进一步训练伯特来做到这一点。*

# *现在都在一起*

*同样的过程可以用来理解变压器模型的一般应用。让我们快速回顾一下我们所涉及的三种模型架构的培训任务及其关注机制:*

1.  *T-ED。任务:翻译。*
2.  *任务:下一个单词的预测。*
3.  *任务:1。MLM。2.下一句预测。*

*在句子中间进行拼写检查:用掩码替换拼错的单词:MLM。将非正式英语转换成正式英语:翻译。建议如何回复短信:下一个单词预测。等等。等等。*

*确定应用与型号选择相关，但并不相同。正如谷歌研究人员在 T5 型号(T-ED)的[发布](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html)中指出的:*

> *我们建议将所有 NLP 任务重新构建为统一的文本到文本格式，其中输入和输出始终是文本字符串…我们甚至可以将 T5 应用于回归任务，通过训练它来预测数字的字符串表示而不是数字本身。*

*正如作者指出的，在某种程度上，所有的任务都可以用文本到文本的格式来组织。也许 T-ED 可以用于所有的任务，而且任何任务都应该适合 T-ED 模型。虽然这在数学上有意义，但在商业上却常常没有意义。你可以把写博士论文框定为一项下一个单词的预测任务，进入 GPT:“这是我关于人工智能的博士论文”，然后等着 GPT 完成剩下的工作。不幸的是，他们最终可能会上交垃圾，让他们的项目失败，然后质疑他们的未来。*

*那么，如何才能知道一个应用程序对于一个 transformer 模型是否真的可行呢？根据经验，应用程序任务越直接转化为训练任务，模型的性能就越好。如上所述，每个下一句预测任务都可以被公式化为一个翻译任务，但是 T-E 会以更低的成本产生更好的结果。*

*总之，请记住，这些模型通过利用在来自训练的大量文本语料库中检测到的模式来确定新的基于文本的任务中最有可能的输出。模型性能受限于训练语料库中包含的内容。变形金刚模型不会有所发现或者搞清楚事情。它们自动执行基于文本的任务，这些任务通过包含在数百万现有文档中的模式变得可预测。尽管如此，他们承诺彻底改革我们所知的人工智能。*

*参考*

*[1]纳亚克，潘杜。“比以往任何时候都更好地理解搜索。”*谷歌*，谷歌，2019 年 10 月 25 日，blog . Google/products/search/search-language-understanding-Bert/。*

*[2] Jacob Devlin、张明蔚、Kenton Lee 和 Kristina Toutanova。Bert:用于语言理解的深度双向转换器的预训练。arXiv 预印本 arXiv:1810.04805，2018。*

*[3]“用 T5 探索迁移学习:文本到文本的迁移转换器。”*谷歌人工智能博客*，2020 年 2 月 24 日，AI . Google Blog . com/2020/02/exploring-transfer-learning-with-t5 . html*

*作者创作的所有图像*