# 人工智能监控和面部识别技术打击犯罪的伦理问题

> 原文：<https://towardsdatascience.com/ethical-concerns-of-combating-crimes-with-artificial-intelligence-surveillance-and-facial-a5eb7a09abb1?source=collection_archive---------19----------------------->

## 在围绕人工智能在打击犯罪中的应用的辩论中，出现了两个突出的问题。独裁政府利用人工智能监控和面部识别技术的偏见。

![](img/3e5eaebc59a2d063356820d8413284e7.png)

[马太·亨利](https://unsplash.com/@matthewhenry?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍照

# **简介**

人工智能(AI)在全球范围内迅速发展，每天都有新的应用被发现。虽然人工智能在许多领域都有应用，但它通常被用于人工智能监控和面部识别技术以打击犯罪。截至 2019 年，全球至少有 75 个国家正在积极使用人工智能技术进行监控，包括智能城市/安全城市平台、面部识别系统和智能警务计划(Feldstein 2019: 1)。然而，以打击犯罪的名义广泛使用 AI 并不是没有代价的；在过去几年中，出现了多种道德问题，这质疑了实施人工智能技术打击犯罪的可行性。本文将研究人工智能在打击犯罪方面的两个突出的伦理问题:面部识别技术的偏见和威权政府以公共安全的名义利用人工智能监控。

# **面部识别技术中的偏见**

![](img/3851703191aa6b34f599bf5ad4c9af10.png)

由 [Perchek Industrie](https://unsplash.com/@perchek_industrie?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

在人工智能新研究的推动下，面部识别技术变得比以往任何时候都更受欢迎；然而，它的发现并不总是准确的。根据国家标准和技术研究所(NIST)的研究杂志*最近进行的一项研究，面部识别软件在种族、年龄和性别方面存在一定的偏见。NIST 计算机科学家 Patrick Grother 领导了这项同类研究中的第一项。格罗特和他的团队评估了来自 99 名开发者的 189 种软件算法，以衡量这些算法是否表现出人口统计学差异，这是一个衡量算法匹配图像的能力是否因不同人口统计学群体而异的术语(NIST 2019)。使用由各个政府机构提供的包含 849 万人的 1827 万张图像的四组照片，该团队评估了这些算法在人口统计因素方面的匹配能力。结果令人震惊；尽管不同算法的误差水平不同，但大多数算法都表现出了人口统计学差异。特别是，格罗特指出，与白种人相比，亚裔、非裔美国人和土著群体被错误识别的可能性要高 10 到 100 倍。此外，算法还难以识别女性与男性的对比，以及老年人与中年人的对比(NIST 2019；Grother，Ngan 和 Hanaoka 2019)。这些发现至关重要，因为它们暴露了面部识别系统中阻碍这些技术安全实施的偏见。美国公民自由联盟(American Civil Liberties Union)的分析师杰伊·斯坦利(Jay Stanley)说:“一次错误的匹配可能导致错过航班、漫长的审讯、监视名单的放置、紧张的警察遭遇、错误的逮捕或更糟，”(Stanley in Singer and Metz，2019)。这种来自固有歧视性人工智能面部识别系统的广泛人口差异的现实仍然是一个需要解决的首要伦理问题。*

# **有缺陷的技术导致不公正**

不幸的是，面部识别技术的偏见已经导致了美国的不公正。第一个已知的例子是罗伯特·威廉的案件，一名非洲裔美国人在面部识别系统错误地将他的照片与一名小偷匹配后被捕(波特 2020)。威廉姆斯最终被拍了面部照片，采集了指纹和 DNA，并被关押了一夜(波特 2020)。当一名侦探向他展示监控录像中的一幅图像时，威廉说:“不，这不是我，你认为所有的黑人看起来都一样吗？”(希尔 2020)。虽然威廉最终被释放，但他的经历一直是创伤性的，他周围的人，包括他五岁的女儿，永远无法看到他被戴上手铐带走(波特 2020)。罗伯特·威廉斯的故事有力地证明了有缺陷的面部识别技术对社会的危害。

# **独裁政府利用人工智能监控**

![](img/488106e4b3f3453f0a9ed53322e285f8.png)

Alec Favale 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

虽然美国等自由民主国家正在努力利用人工智能来进一步保护社会，但在以打击犯罪为名利用人工智能监控的威权政府中，伦理问题也出现了。中国就是这样一个国家；通过“新一代人工智能发展计划”(AIDP)，该国描绘了一个总体目标，即使中国成为人工智能的世界领导者。AIDP 表明中国打算将人工智能用于国防、社会福利和发展道德标准(Robert et al . 2020:1–2)。然而，了解了中国腐败和压制的政治文化，一些人，如《大西洋月刊》的副主编罗斯·安德森，认为中国关于人工智能的声明有着险恶的边缘。安德森认为，中国希望利用人工智能建立一个全方位的社会控制数字系统，这将把中国推向监控的前沿(安德森 2020)。这种由基于人工智能的监控推动的全知系统的可能性提出了伦理问题，因为它以牺牲公民自由为代价授予政府绝对控制权。

# **利用人工智能监控进行种族定性**

![](img/9bb139394023d54bae66e9cc6438d9be.png)

照片由[库扎特阿勒泰](https://unsplash.com/@kuzzat?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄

安德森对政府控制使用全知数字系统的担忧肯定不是没有原因的。根据《纽约时报》驻香港记者 Paul Mozur 的说法，中国政府使用人工智能监控来描述维吾尔人，这是中国的一个主要穆斯林少数群体(Mozur 2019)。根据 Mozur 的说法，这种类型的监控是政府有意使用人工智能进行种族定性的第一个例子。通过人工智能监控，政府专门根据外表寻找维吾尔人，并记录他们的日常活动。这些信息被用来监视中国新疆省的 1100 万维吾尔人。由于人工智能技术的广泛整合，当局已将 100 万名维吾尔人因涉嫌恐怖主义和其他涉嫌犯罪而关进拘留营(Mozur 2019)。乔治城大学法律隐私和技术中心的助理克莱尔·加维(Clare Garvie)指出，人们将使用人工智能技术中最危险的部分:“如果你制造一种可以按照种族对人们进行分类的技术，有人会用它来压制这种种族。”(Mozur 2019 中的 Garvie)。政府采用的大规模人工智能监控的能力和实施仍然是全球人类活动家和领导人面临的一个紧迫的伦理危机。

# **人工智能技术的好处**

![](img/e02d84161c15ae55167fdbb7c1246b75.png)

斯蒂芬·菲利普斯-Hostreviews.co.uk 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

虽然解决人工智能在打击犯罪中的伦理问题至关重要，但承认人工智能带来的一些好处也很重要。根据 *Oliver Wyman Risk Journal，* AI 用于检测员工盗窃、网络欺诈、假发票、洗钱和恐怖分子融资等犯罪(Quest et al. 2018)。这些人工智能应用战胜了金融犯罪。具体来说，银行在利用人工智能驱动的工具跟踪犯罪分子的同时，错误警报减少了 50%(Quest et al . 2018)。此外，如果使用得当，人工智能的应用范围实际上是无限的。未来的应用包括检测和跟踪非法商品、恐怖活动和人口贩运(Quest et al. 2018)。快递公司可以使用人工智能评估包含非法商品的包裹，商店可以使用人工智能识别异常购买，执法部门可以使用人工智能打击人口贩运(Quest et al. 2018)。所有这些人工智能应用都展示了在全球范围内增强社会安全的潜力。

# **结论**

利用人工智能技术打击犯罪所涉及的道德问题仍将是研究人员、政府当局和普通民众争论的一个关键问题。虽然人工智能在打击犯罪和提高全球公民安全方面具有潜力，但不可否认的是，在打击犯罪方面实施人工智能存在伦理问题。关键问题包括极权政权对人工智能监控的滥用，以及任何政府对带有根本性偏见的面部识别系统的使用。作为对人工智能技术新兴问题的回应，近年来发布了多项指导方针。艾伦图灵研究所的大卫莱斯利博士发表了一套这样的指导方针。该报告强调了人工智能道德的重要性，并探讨了负责任地交付人工智能技术的平台(Leslie 2019: 3)。随着人工智能成为一种看门人技术，人类最终可以选择它的发展方向，无论是人类福祉的指数级进步还是重大风险的可能性(Leslie 2019: 73)。人工智能在全球范围内的日益融合不可避免地导致了重大的伦理问题，但如果领导者和研究人员愿意打击不道德的行为，并遵循适当的指导方针，人工智能可以成为走向更美好未来的不可战胜的力量。

[1]:“AI 是数字计算机或计算机控制的机器人执行通常与智能生物相关的任务的能力”(Copeland 2020)。

**参考文献**

安德森河(2020 年 9 月 9 日)。圆形监狱已经在这里了。*大西洋*。[https://www . theatlantic . com/magazine/archive/2020/09/China-ai-surveillance/614197/](https://www.theatlantic.com/magazine/archive/2020/09/china-ai-surveillance/614197/)

人工智能在达特茅斯诞生。(未注明)。达特茅斯。[https://250 . Dartmouth . edu/highlights/artificial-intelligence-ai-coined-Dartmouth](https://250.dartmouth.edu/highlights/artificial-intelligence-ai-coined-dartmouth)

B. J .科普兰(未注明)。人工智能(AI)。*大英百科全书学派*。2020 年 12 月 23 日检索，来自[https://school . EB . com/levels/high/article/artificial-intelligence/9711](https://school.eb.com/levels/high/article/artificial-intelligence/9711)

费尔德斯坦，S. (2019)。人工智能监控的全球扩张。卡内基国际和平基金会。JSTOR。[https://www.jstor.org/stable/resrep20995.1?seq = 1 # metadata _ info _ tab _ contents](https://www.jstor.org/stable/resrep20995.1?seq=1#metadata_info_tab_contents)

Grother，p .，Ngan，m .，& Hanaoka，K. (2019)。人脸识别供应商测试(FRVT)第 3 部分:人口统计学效应。*美国国家标准与技术研究院研究杂志*。https://doi.org/10.6028/NIST.IR.8280

k .希尔(2020 年 6 月 24 日)。被算法错误地指控。*纽约时报*。[https://www . nytimes . com/2020/06/24/technology/face-recognition-arrest . html？登录=电子邮件&验证=登录-电子邮件](https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html?login=email&auth=login-email)

莱斯利博士(2019)。理解人工智能伦理和安全:公共部门负责任的人工智能系统设计和实施指南。艾伦图灵研究所。[https://doi.org/10.5281/zenodo.3240529](https://doi.org/10.5281/zenodo.3240529)

Mozur，P. (2019 年 4 月 14 日)。一个月，500，000 次面部扫描:中国如何使用人工智能描绘少数民族。《纽约时报》。[https://www . nytimes . com/2019/04/14/technology/China-surveillance-artificial-intelligence-race-profiling . html](https://www.nytimes.com/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html)

NIST 研究评估种族、年龄、性别对人脸识别软件的影响。(2019).*美国国家标准与技术研究所研究杂志*。[https://www . NIST . gov/news-events/news/2019/12/NIST-study-evaluates-effects-race-age-sex-face-recognition-software](https://www.nist.gov/news-events/news/2019/12/nist-study-evaluates-effects-race-age-sex-face-recognition-software)

波特，J. (2020 年 6 月 24 日)。一名黑人因为面部识别而被错误逮捕。*濒临绝境*。[https://www . the verge . com/2020/6/24/21301759/面部识别-底特律-警察-错误逮捕-罗伯特-威廉姆斯-人工智能](https://www.theverge.com/2020/6/24/21301759/facial-recognition-detroit-police-wrongful-arrest-robert-williams-artificial-intelligence)

Quest，l .，Charrie，a .，和 Roy，S. (2018 年)。使用人工智能检测犯罪的风险和好处。*奥纬风险杂志*， *8* 。[https://www . Oliver Wyman . com/our-expertise/insights/2018/dec/risk-journal-vol-8/re thinking-tactics/the-risks-and-benefits-of-use-ai-detect-crime . html](https://www.oliverwyman.com/our-expertise/insights/2018/dec/risk-journal-vol-8/rethinking-tactics/the-risks-and-benefits-of-using-ai-to-detect-crime.html)

Roberts，h .，Cowls，j .，Morley，j .，m .，Wang，v .，& Floridi，L. (2020)。人工智能的中国方式:政策、伦理和监管分析。 *AI 与社会*。[https://doi.org/10.1007/s00146-020-00992-2](https://doi.org/10.1007/s00146-020-00992-2)

n . singer & Metz，C. (2019 年 12 月 19 日)。美国研究称，许多面部识别系统存在偏见。《纽约时报》*。[https://www . nytimes . com/2019/12/19/technology/face-recognition-bias . html](https://www.nytimes.com/2019/12/19/technology/facial-recognition-bias.html)*