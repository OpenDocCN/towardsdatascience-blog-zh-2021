# 不，你不需要一个抵制小组

> 原文：<https://towardsdatascience.com/no-you-dont-need-a-holdout-group-ab0995860aca?source=collection_archive---------9----------------------->

## [行业笔记](https://towardsdatascience.com/tagged/notes-from-industry)

## 在评估一项干预措施时，无论是简单的 A/B 测试还是复杂的背景强盗，抵制小组的好处都被高估了。

![](img/0b0b2dc0a3b8c01794c847289a6edf89.png)

来自 [Pexels](https://www.pexels.com/photo/one-black-chess-piece-separated-from-red-pawn-chess-pieces-1679618/) 的 Markus Spiske 的照片。

我是 [Aampe](https://www.aampe.com/) 的联合创始人，在这里，我们将情境学习算法嵌入到移动应用的推送通知中，以了解并适应个人用户的偏好。我们做了大量的测试和实验设计，以及大量的机器学习。这篇文章是关于我们经常从潜在客户那里收到的一个特殊请求:我们提出了一个用户子集，他们既没有 Aampe 学习系统选择的通知内容，也没有选择通知时间。这一要求似乎源于一种错误的信念，即坚持比较在某种程度上是一种固有的“科学”实践。

科学必然涉及到比较，但并不是所有的比较都是科学的。细节很重要，一些细节说明了为什么坚持比较不一定是好的实践。下面，我写了几个问题，这些问题使得使用维持样本来评估 Aampe 学习算法的有效性变得极其困难，但这些原则适用于任何处理扩展的自适应干预的情况，例如 bandit 算法。

# 相似性

似乎不言而喻的是，只有当两个组具有可比性时，我们才应该将拒绝用户的组与测试组进行比较，可比性问题正是我们每次谈论拒绝用户时所回避的问题。我的一位联合创始人萨米·阿鲍德写了[关于随机分配的局限性的文章](https://www.aampe.com/blog/experiments-are-hard):如果我们随机分配一定比例的用户给坚守者，然后把其余的人留在一个“测试组”里，由 Aampe 管理所有的交流，那么完全有可能——实际上很有可能——某些用户属性会不成比例地反映在另一个组里。坚持组将会有不成比例的男性，或者测试组将会有不成比例的新用户。应用程序用户可以选择的方式越多(应用程序是否提供几种不同的产品？它在几个不同的地理区域可用吗？)随机分配本质上是有偏分配的可能性就越大。

在 Aampe，我们坚持[条件分配](https://www.aampe.com/blog/conditioned-experiments)，在这里我们明确衡量用户之间的异同，以确保我们将相似的消息分配给具有不同行为和属性的用户，将不同的消息分配给具有相似行为和属性的用户。这使我们能够在评估我们所做的消息传递选择的影响时，估计和忽略这些基线影响的影响。(你可以在[一个用户故事](https://www.aampe.com/blog/a-user-story)的“用户景观”部分找到关于条件分配的简单解释，或者你可以在这里浏览一下它的图解[。)](https://www.aampe.com/blog/a-walk-through-our-conditioned-experimentation-process)

好吧，那么为什么不使用条件分配来选择维持组呢？这将确保这两个群体具有可比性。是的，会的…但是只有在我们做作业的那一天。大多数应用程序都有很高的流失率——2018 年末对 37，000 个应用程序的一项研究显示，平均而言，超过一半的应用程序用户在下载应用程序的一个月内流失。对于许多应用程序来说，这种流失发生在第一个月的前几天——用户进来，可能四处看看，然后就再也不会来了。这些用户中的许多人会在我们构建的任何一个坚持组中，这意味着坚持组会随着时间的推移而缩小——可能会很快。我们可以用新的用户来填充它，但是这些用户从定义上来说向我们提供了很少的关于他们自己的信息，因为他们是新的。

在与人类打交道时，拒绝合作的群体很难创建，甚至更难维持。如果我们处理数百万的每日活跃用户，那么困难可能会缩小一点——在一个问题上投入大量数据可以创造奇迹——但是困难永远不会消失。尽管面临这些挑战，使用抵制小组是不科学的。只是一厢情愿。

# 伦理学

让我们说，我们可以神奇地让所有上述困难消失，所以不再有一个强有力的分析理由来质疑坚持比较的有效性。我坚信，在大多数情况下，我们仍然不想这样做。

考虑这样一种情况，试验表明有一种药物可以成功治疗一种常见疾病。我们已经有了这种药物起作用的早期迹象，但我们仍然不确定。所以当人们来到药店购买药物时，我们随机选择他们是得到真正的药物还是糖丸。我们不会告诉他们他们参与了一项正在进行的试验——我们只是进行转换并监控发生了什么。这样做显然是不对的。

现在考虑一个稍微不那么令人担忧的情况，我们为在学业上挣扎的学生提供教育支持服务。大多数来为我们的服务付费的学生都得到了我们批准的项目，我们已经花了数年时间把它发展成我们认为真正有效的东西。但是，我们随机分配一定比例的学生，让他们得到平淡无奇的样板材料，这些材料只是用来填充空间，而不是提供教育价值。我们不会告诉学生他们有可能得到假材料——我们只是调换一下，然后观察。这样做显然是不对的。

好了，现在考虑:我们对我们的应用程序的产品和用户体验做出决定，我们认为这些产品和体验更能为我们的用户提供价值。每个用户下载我们的应用都是有目的的，我们花费了大量的时间和资源，试图确保他们能够方便地访问最初带给他们的东西。我们对我们的应用程序进行我们认为是改进的更改。从这些用户中随机抽取一部分，给他们一个我们认为没什么价值的体验，而不告诉他们这是怎么回事，或者给他们一个对实验给予知情同意的选择，这在什么情况下突然变得可以了？

这是不道德的。

在用户付钱给我们为他们提供价值的情况下，这尤其不道德。他们付钱给我们，让我们给他们最好的体验。我们不能仅仅为了在不确定的情况下做决定时感觉好一点，就反悔。

现在，我在这里所说的关于道德的一切都适用于全球抵制群体——我们将这些人排除在所有干预措施之外，以评估这些干预措施的有效性。如果我们进行临时抵制，问题就不大了——随机停止对一定数量用户的干预，比如说，一个月，然后下个月选择一个新的抵制者，下个月又选择一个新的抵制者。这样，每个人都有同等的机会失去某些利益，但损失总是暂时的。但是这仍然没有解决我们之前讨论过的分析问题。不管怎样，这是不必要的，因为我们接下来要讲的。

# 竞争假说

在我看来，许多坚持抵制样本的人认为科学主要是零假设检验(有时也称为“统计显著性”检验)。我对零假设检验没有很高的评价(如果你感兴趣，这里有一个关于最突出问题的很好的总结。)我对这种方法的主要抱怨是，我认为这种方法通常不会产生好的科学。

所有科学的核心(也是最好的)都遵循一个简单的过程:

1.  **编一个似是而非的故事。**这可能是描述性的(“X 和 Y 同时发生”)或解释性的(“X 导致 Y”)，但它仍然只是一个故事。
2.  **尽可能多地编造另类故事。也许 X 和 Y 之间的关系实际上并不十分一致。也许 Y 实际上引起了 X，也许 X 只在 Z 存在时引起 Y。也许 Z 导致 Y，但 X 往往与 Z 同时发生，所以*看起来*像 X 导致 Y。尽可能多地编造故事，如果你最初的故事也是真实的，那么(1)可能是真实的，(2)不可能是真实的。**
3.  **尽量把故事都干掉。这包括你的原创(通常是首选)故事。设定一些条件，在这些条件下，观察结果不应该与故事相符，除非故事真的不仅仅是似是而非。产生较少矛盾的故事比更容易被反驳的故事更值得我们相信。**

那么，根据来自抵制小组的数据，哪些故事是生还是死呢？当然，在 Aampe，我们更喜欢的故事是，如果 Aampe 的学习系统没有管理这种交流，我们就不会看到用户与应用程序互动的方式和程度。有哪些看似合理的替代方案？

*   也许我们什么都不能做。毕竟，如果你什么都不做也能得到同样的结果，为什么还要为通过持续、大规模并行学习来优化用户交流的服务付费呢？这是一个公平的问题，但这不是一个坚持者能够回答的问题。这又回到了我之前提到的可比性挑战。一个完全随机的抵制者几乎肯定会表现出与其他人群的系统性差异，但即使是通过更复杂的实验设计创造的抵制者也会随着年龄的增长而远离其他人群。事实上，通知的自动化管理越成功，我们就越希望不断回填的坚守者包含不成比例的新用户，因为成功的管理会导致更多的新用户成为回头客。
*   也许我们可以手动管理通知。是的，当一个自动化系统为一部分用户管理通知时，你可以为另一部分用户手工制作完美的消息。即使你的信息优于被管理的信息(它们通常不会)，除非你准备永久雇佣整个机构——或者雇佣一个相当于机构的内部人员——来继续烘烤那些手工通知，那么这种比较是没有意义的，因为它是不可持续的。比较不应该是一个学术问题——它应该帮助你在两个行动方案之间做出决定。如果大规模全手工管理通知是可行的，那么会有更多的人成功做到这一点。事实上，没有人成功地做到这一点，这是我们最初创建 Aampe 的主要原因之一。
*   **也许我们可以使用一套触发器和规则。**试着把它分解成你可能会用到的实际规则。也许你想到了一些非常简单的规则，比如“周一下午给每个人发信息”，或者一些更复杂的规则，比如“给购物两天后的顾客发信息，如果他们没有回复，两天后再发信息。”这些规则包含了隐含的假设:“周一下午是给用户发信息的好时间”，“在跟进购买之前等待两天是合适的时间”，等等。坚持样本将所有这些隐含的假设整合成一大捆，你无法从中解开洞见。也许星期一下午很好，但是也许星期二上午很好，或者也许星期三下午，或者星期四晚上。任何像样的自动化系统都应该已经对所有这些假设进行了相互测试。同样的事情也适用于行动后的等待期:也许两天是好的，但也许一天也是好的，也许三天更好。您可能为维持样本采用的任何规则都只是您可以采用的所有规则的一小部分。不要把几个可供选择的故事塞进一个标有“拒绝”的无差别的盒子里，你实际上应该在与所有其他故事的比较中评估每个故事。(而这正是 Aampe 所做的。)

这篇文章的目的不是吹捧 Aampe 的奇迹——我承认我在这一点上有偏见。我试图表明的是，在大多数情况下，拒不合作的团体更像科学的*而不是科学的。拒不接受的样本通常会给测试带来严谨的假象，而不一定会带来严谨。严谨性要求制定和测试替代假设，而不仅仅是无效假设。当涉及到像用户通知这样复杂的事情时，有无数的消息内容和时间的排列，一个零假设并不那么有用。*

*Schaun Wheeler 是 [Aampe](http://aampe.com) 的联合创始人，这是一家将推送通知转化为主动用户界面的软件公司。Schaun 既是一名人类学家，也是一名数据科学家，在安全和情报、旅游、投资、教育、广告和用户体验行业工作过。他最近写了一本儿童读物来解释他公司的算法。你应该读读 https://www.aampe.com/blog/a-user-story 的。*