# 如何开始对音乐实施机器学习

> 原文：<https://towardsdatascience.com/how-to-start-implementing-machine-learning-to-music-4bd2edccce1f?source=collection_archive---------10----------------------->

## 讨论两个丰富领域的交集。

![](img/1f6bfe72a5ec7fbb35bc24cd2a4210e4.png)

阿列克谢·鲁班在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

# 介绍

对于那些从事数据科学和机器学习的人来说，他们未来职业生涯中最重要的决定之一[是追求哪个领域的专业并成为该领域的专家。一些最突出的领域是自然语言处理(NLP)、计算机视觉和量化交易。这些领域正在呈指数级增长，其中的新技术似乎每天都在发展。](/in-data-science-its-specialize-or-die-7ede67a58676)

然而，虽然不是机器学习最赚钱的应用(就当前的盈利能力而言)，但音乐领域已经发展了巨大的洞察力和显著的进步，其中大部分是由于各种机器学习和深度学习应用。

在这篇文章中，我的目标是概述机器学习在音乐应用中的两个主要子领域，进入该领域所需的技能，最佳初学者项目(在我看来)和当前的艺术应用状态。

# 音乐机器学习需要什么？

音乐机器学习主要有两个子领域。第一个是音乐信息检索(MIR ),第二个是生成音乐。这两个子领域并不排斥，几乎每一个与音乐机器学习相关的应用和技术都需要 MIR。然而，一般来说，这两个子字段对整个字段进行了很好的分类。

## 关于音乐信息检索:

MIR 是计算机科学、统计学、音乐学和数字信号处理的交叉领域。所有这些任务结合起来形成了 MIR，因为音乐中的信息并不像看起来那样简单。

表面上有简单的信息，可以从你喜欢的歌曲中理解(即速度、音色、响度等。)这些音乐的表示是相对低级的，并且更容易跨不同流派和风格的歌曲进行计算。然而，能够制定更高层次的解释(或人类更经常感知的概念)，如情绪和灵感，则更难确定。这就是利用低级统计的多元函数可以发挥作用的地方，以便更好地了解我们想要建模的内容。然而，重要的是要知道，人类从音乐中带走的许多概念至今无法完美建模，因为音乐本身之外有太多的因素在它的感知中发挥作用。

尽管孤立的 MIR 最常见的使用案例是基于音乐的推荐系统，但 MIR 本身是机器学习的每个基于音乐的应用的基础。

## 关于再生音乐:

至于生成音乐，名字就比较简单了。这个子领域着眼于将深度学习用于广泛的生成任务，无论是产生新的声音还是全新的歌曲。尽管在音乐机器学习中是一个“独立”的领域，它仍然大量使用 MIR，原因很明显。为了生成音乐，围绕这一代的信息应该是最高质量的。

然而，声音的产生并不一定要严格地以新音乐或声音隔离的形式进行。生成音乐还包括将一种声音转换为另一种声音的行为，甚至能够通过去噪或在其上添加新音乐来重建它，以给歌曲添加更多层，这两种应用我们将在后面看到。从本质上讲，音乐的产生并不等于自动化，有许多生产性的途径来利用音乐的产生，这将在后面讨论。

如果你感兴趣，我已经写了关于完全自动化音乐的可能含义，你可以阅读。

[](/ai-automation-and-music-8b9871dec784) [## 人工智能、自动化和音乐

### 技术对新一代艺术家意味着什么？

towardsdatascience.com](/ai-automation-and-music-8b9871dec784) 

# 音乐机器学习需要哪些技能？

可以说，最重要的技能是数字信号处理(DSP)知识。DSP 是电子工程中的一个领域，它接收物理信号，如我们发出的声音，并将其转换为数字格式，以便对其进行数学处理和转换。

理解 DSP 在音乐机器学习中的作用可能是相当容易的。许多 ML 工程师习惯于通过规范化或标准化对数据进行预处理。然而，对于那些想要从事音乐工作(或者更一般地基于音频)的人来说，机器学习有一个稍微不同的障碍要克服。虽然归一化和标准化在该领域中具有一些效用，但是理解 DSP 的人将知道从波形到频谱图的变换是*预处理的确定方法。你决定使用什么样的声谱图取决于问题本身，这就是你对该领域的理解和你的智慧发挥作用的地方。*

*如果你想开始学习 DSP，我有一系列专门从数据科学角度学习 DSP 的文章，叫做**从音频中学习**。您可以在这里找到 GitHub 笔记本资源库的链接，也可以在 README 中找到 Medium 文章本身的链接。*

*[](https://github.com/theadamsabra/LearningfromAudio) [## theadamsabra/LearningfromAudio

### 从音频中学习是 Adam Sabra 写的一系列媒体文章。它的主要目标是帮助那些在…

github.com](https://github.com/theadamsabra/LearningfromAudio) 

***注:*** *最明显的技能是机器学习和编程，我不打算过多地钻研这个。然而，我将在下面的* ***当前最先进的应用*** *章节中概述一些今天使用的最重要和最有用的模型。** 

# *面向初学者的项目*

*对于这个领域的新手来说，最好的第一个项目是乐器或流派分类。乐器/流派分类是一种分类形式，它利用音频的结构并确定其中的乐器或流派。*

*我在这个项目中交替使用乐器和流派，只是因为总体学习体验是相同的，但是在你决定如何处理音频本身时会有细微的差异，只是因为你可能会寻找不同的模式/结构，各种频谱图可以返回给你。你选择哪一个并不重要，所以对你来说最好的选择是选择你最感兴趣的项目。*

*一旦你建立了这个分类项目，并取得了良好的结果，你就已经完全掌握了基本原理。从那里，你可以开始阅读关于各种先进应用的文献来着手解决。*

## *乐器或流派分类数据集*

*   *[ka ggle 上的乐器数据集](https://www.kaggle.com/yashtiwari1906/musical-instrument-dataset)*
*   *[ka ggle 上的音乐流派分类数据集](https://www.kaggle.com/c/music-genre-classification)*

# *各种先进的应用*

## *音乐源分离*

*我把这个放在第一位，不仅因为这是我目前的论文，而且我还发现这个应用程序非常有用。音乐源分离是一项任务，在这项任务中，机器学习模型学习特定声音的结构，提取它，并将其与它混合的其他声音隔离开来。无论是创作一首歌曲的阿卡贝拉版本，还是提取你最喜欢的低音线，都可以通过神经网络以接近/快于实时的速度完成。*

*此用例的当前艺术应用状态是 Deezer 的 Spleeter。Spleeter 是一个双向 LSTM，它在 MUSDB 数据集上训练，MUSDB 数据集专门用于音乐源分离。*

***Deezer:***

*[](https://github.com/deezer/spleeter) [## 除雾器/分离器

### ⚠️sp leater 2 . 1 . 0 版本引入了一些突破性的变化，包括输入的新 CLI 选项命名，以及

github.com](https://github.com/deezer/spleeter) 

**音乐数据库:**

[](https://sigsep.github.io/datasets/musdb.html) [## MUSDB18 | SigSep

### musdb18 是一个数据集，包含 150 首不同风格的全长音乐曲目(时长约 10 小时),以及它们各自独立的…

sigsep.github.io](https://sigsep.github.io/datasets/musdb.html) 

## 实时伴奏

实时伴奏是处理音乐创作中的创意的更有趣的问题之一。这个问题旨在解决的核心概念是创建一个能够与另一首歌曲一起演奏乐器的生成网络。让我们举个例子来更好地理解这一点。

假设你决定教网络通过钢琴演奏爵士乐( ***旁注:*** *这是非常不可能的，因为它太广泛了。在流派中磨砺将显著提高模型的性能。)*当您在没有钢琴的情况下输入音乐时，它会与其他乐器一起实时演奏，创造出自己的演奏效果！

这一领域有许多先进的应用，因此我将在下面列出几个:

**MuseGAN:用于符号音乐生成和伴奏的多轨道顺序生成对抗网络:**

[](https://paperswithcode.com/paper/musegan-multi-track-sequential-generative) [## 多轨道有序生成的符号对抗网络

### 在 7 个代码库中实现。

paperswithcode.com](https://paperswithcode.com/paper/musegan-multi-track-sequential-generative) 

**音乐渐变:通过低级特征建模基于高级特征的可控音乐生成:**

[](https://paperswithcode.com/paper/music-fadernets-controllable-music-generation) [## 论文与代码-音乐渐变:可控的音乐生成基于高层次的特点，通过…

### 高层次的音乐品质(如情感)往往是抽象的、主观的，难以量化。鉴于这些…

paperswithcode.com](https://paperswithcode.com/paper/music-fadernets-controllable-music-generation) 

## 自动音乐转录

音乐自动转录的问题，顾名思义，目的是转录任何一段音乐。这对那些演奏乐器的人来说非常有用。人们不仅可以输入他们最喜欢的歌曲，并随时随地播放乐谱，而且同一首歌曲还可以转换成 MIDI 文件，以便在计算机上进行编辑。对于那些不知道的人来说，MIDI 代表乐器数字接口。[根据 MIDI 协会](https://www.midi.org/)的说法，它是一种行业标准的音乐技术协议，连接来自许多不同公司的数字乐器、计算机、平板电脑和智能手机。

因此，这些网络不仅允许为几乎任何歌曲的进一步练习和研究而创作乐谱，而且还允许用于操纵、灵感以及新歌创作的数字等价物。

类似于实时伴奏问题，有许多先进的解决方案。这里有几个例子:

**通过回归开始和偏移时间用踏板进行高分辨率钢琴转录:**

[](https://cs.paperswithcode.com/paper/high-resolution-piano-transcription-with-1) [## 论文与代码-高分辨率钢琴转录踏板回归开始和偏移…

### 自动音乐转录(AMT)是将音频记录转录成符号表示的任务，例如…

cs.paperswithcode.com](https://cs.paperswithcode.com/paper/high-resolution-piano-transcription-with-1) 

**走向多乐器鼓转录:**

[](https://paperswithcode.com/paper/towards-multi-instrument-drum-transcription) [## 面向多乐器鼓转录的论文与代码

### 自动鼓转录是更一般的自动音乐转录的子任务，处理提取鼓…

paperswithcode.com](https://paperswithcode.com/paper/towards-multi-instrument-drum-transcription) 

## 这样的例子不胜枚举！

如果这三个应用程序听起来对你都不太感兴趣，但你仍然想进一步研究 MIR 和机器学习的可能性，最好的资源是国际音乐信息检索协会(ISMIR。)

[](https://ismir.net/) [## ISMIR - Home

### 会议交易的 ISMIR 妇女在 MIR 资源关于社会成员社区统计联系…

ismir.net](https://ismir.net/) 

自 2000 年以来举行的所有会议以及提交的会议记录和文件都可以在网站上找到。虽然你们中的大多数人可能会阅读该领域最近几年的资料，但如果你决定继续在该领域工作，这个年度会议仍然是一个值得关注的问题。

# 最后的想法

即使通读了这篇文章，重要的是要知道所有这些信息仍然只是皮毛。还有更多的问题有待发现，不仅仅是迭代当前的 SOTA 解，还有这个领域的未来。

希望这篇文章能为你在这个引人注目的领域开始职业生涯打下基础。参与其中的人越多越好。*