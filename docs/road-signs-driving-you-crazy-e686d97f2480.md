# è·¯æ ‡è®©ä½ ç–¯ç‹‚ï¼Ÿ

> åŸæ–‡ï¼š<https://towardsdatascience.com/road-signs-driving-you-crazy-e686d97f2480?source=collection_archive---------16----------------------->

## ä»¥ä¸‹æ˜¯æˆ‘å¦‚ä½•å»ºç«‹ä¸€ä¸ªç¨‹åºæ¥ä¸ºä½ é˜…è¯»å®ƒä»¬

![](img/ae8d1d04880f4364deb44a6d22402b78.png)

ç½—è¥¿Â·æ–¯è’‚æ ¼å°”æ–¯åœ¨ [Unsplash](https://unsplash.com/s/photos/road-signs?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) ä¸Šçš„ç…§ç‰‡

è·¯æ ‡ã€‚ä¸€å¤§å †ä¸åŒé¢œè‰²çš„ç¬¦å·ï¼Œå®ƒä»¬çš„å½¢çŠ¶ä½ åº”è¯¥èƒ½å¤Ÿæ¨æ–­å‡ºå®ƒä»¬çš„æ„æ€ã€‚å¥‡æ€ªçš„ç¬¦å·ï¼Œä½ å¿…é¡»è°·æ­Œç”šè‡³æ¨¡ç³Šåœ°è®¤è¯†ã€‚è·¯æ ‡ä»¤äººå›°æƒ‘ï¼Œå¾ˆéš¾è®°ä½å®ƒä»¬çš„æ„æ€ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘å»ºç«‹äº†[è¿™ä¸ªç¨‹åº](https://www.kaggle.com/taraprole/roadsignclassifier)æ¥ä¸ºä½ é˜…è¯»å®ƒä»¬ï¼ç»™å®šä¸€å¼ è¶³å¤Ÿæ¸…æ™°ã€è£å‰ªå¾—å½“çš„å›¾åƒï¼Œæˆ‘çš„ CNN å¯ä»¥è¯»å–è·¯æ ‡ä¸­çš„å›¾æ¡ˆï¼Œå¹¶ä½¿ç”¨æ•°å­—åˆ†ç±»ç³»ç»Ÿå¯¹å®ƒä»¬è¿›è¡Œåˆ†ç±»ã€‚æˆ‘å°†å‘ä½ å±•ç¤ºå®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼

# ç›®å½•

å› ä¸ºè¿™æ˜¯ä¸€ç¯‡æœ‰ç‚¹é•¿çš„æ–‡ç« ï¼Œæˆ‘æƒ³æˆ‘åº”è¯¥ç»™ä½ ä¸€ä¸ªç®€çŸ­çš„ç›®å½•ï¼Œä»¥ä¾¿èƒ½å¤Ÿå¿«é€Ÿå¯¼èˆªåˆ°æˆ‘çš„æ–‡ç« çš„ç‰¹å®šéƒ¨åˆ†ã€‚

1.  [***ä¸ºä»€ä¹ˆè¿™ä¸ªå…¶å®æœ‰ç”¨ï¼Ÿ***](#e7b3)
2.  [***CNN***](#4930)
3.  [***å…¥é—¨***](#9795)
4.  [***å‡†å¤‡æ•°æ®***](#f088)
5.  [***åˆ›å»ºç¥ç»ç½‘ç»œ***](#c631)
6.  [***å®šä¹‰åŠŸèƒ½***](#088e)
7.  [***è®­ç»ƒç¥ç»ç½‘ç»œ***](#af7b)
8.  [***æµ‹è¯•å‹å·***](#48c1)

# ä¸ºä»€ä¹ˆè¿™å®é™…ä¸Šæ˜¯æœ‰ç”¨çš„ï¼Ÿ

ä½ å¯èƒ½æƒ³çŸ¥é“è¿™ä¸€åˆ‡æœ‰ä»€ä¹ˆæ„ä¹‰ã€‚å½“æˆ‘ä»¬å¯ä»¥è‡ªå·±çœ‹è·¯æ ‡æ—¶ï¼Œä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦ä¸€å°è®¡ç®—æœºæ¥å¯¹å®ƒä»¬è¿›è¡Œåˆ†ç±»ï¼Ÿ

ç­”æ¡ˆ:**è‡ªåŠ¨é©¾é©¶æ±½è½¦ã€‚**

æ— äººé©¾é©¶æ±½è½¦æ¯å¤©éƒ½å˜å¾—è¶Šæ¥è¶ŠçœŸå®ã€‚è°·æ­Œçš„å§å¦¹å…¬å¸ Waymo å·²ç»åœ¨äºšåˆ©æ¡‘é‚£å·çš„å‡¤å‡°åŸå»ºç«‹äº†å®Œæ•´çš„ç³»ç»Ÿã€‚åŸå¸‚ç‰¹å®šåŒºåŸŸçš„å¸‚æ°‘å¯ä»¥åƒè®¢è´­ä¼˜æ­¥ä¸€æ ·è®¢è´­æ— äººé©¾é©¶æ±½è½¦ï¼ä½†æ˜¯ï¼Œä¸ºäº†è®©è‡ªåŠ¨é©¾é©¶æ±½è½¦ä¸ä½ ä»Šå¤©å¯èƒ½é©¾é©¶çš„æ±½è½¦æ— ç¼é›†æˆï¼Œå®ƒä»¬éœ€è¦èƒ½å¤Ÿåƒäººç±»ä¸€æ ·éµå®ˆé“è·¯è§„åˆ™ã€‚è¿™åŒ…æ‹¬é˜…è¯»è·¯æ ‡ï¼

# CNN

ä½ å¯èƒ½ä¹Ÿæƒ³çŸ¥é“è¿™äº› CNN çš„ä¸œè¥¿æ˜¯ä»€ä¹ˆã€‚åˆ«æ‹…å¿ƒï¼Œæˆ‘å¯ä»¥è§£é‡ŠğŸ˜‰

CNN æ˜¯ä¸€ç§ç‰¹åˆ«æ“…é•¿å›¾åƒåˆ†ç±»çš„ç¥ç»ç½‘ç»œ(é˜…è¯»æˆ‘çš„å…¶ä»–æ–‡ç« æ¥äº†è§£åŸºç¡€çŸ¥è¯†)ã€‚CNN ç”¨äºè®¡ç®—æœºè§†è§‰ï¼Œå› ä¸ºå®ƒä»¬æ“…é•¿æ£€æµ‹å›¾åƒä¸­çš„å›¾æ¡ˆï¼Œå¦‚çº¿æ¡ã€åœ†å½¢å’Œå…¶ä»–å½¢çŠ¶å’Œå›¾æ¡ˆã€‚CNN ä½¿ç”¨å·ç§¯å±‚ï¼Œå®ƒæœ¬è´¨ä¸Šå­¦ä¹ å¯ä»¥æ£€æµ‹å›¾åƒæ¨¡å¼çš„è¿‡æ»¤å™¨ã€‚ä¾‹å¦‚ï¼Œè¿‡æ»¤å™¨å¯ä»¥æ£€æµ‹å‚ç›´çº¿ï¼Œä¹Ÿå¯ä»¥æ£€æµ‹æ°´å¹³çº¿ã€‚

![](img/bb5a85c5982e4181cca273a1f897f373.png)

ä¿¡ç”¨:å¡”æ‹‰æ™®ç½—å°”

è¿™äº›æ»¤æ³¢å™¨åœ¨å›¾åƒä¸Šâ€œå·ç§¯â€,ä»¥å°çš„ 3x3(æˆ–ä»»ä½•å¤§å°çš„æ»¤æ³¢å™¨)å—æ¥è·å¾—æ‰€è¿° 3x3 å—çš„ç‚¹ç§¯ã€‚è¿‡æ»¤å™¨é¦–å…ˆæ£€æŸ¥è¾“å…¥å›¾åƒçš„ç¬¬ä¸€ä¸ª 3x3 åŒºåŸŸï¼Œå¹¶æ‰¾åˆ°è¯¥å—çš„ç‚¹ç§¯ã€‚å®ƒè®°å½•ä¸‹æ¥ï¼Œå¹¶æˆä¸ºä¸‹ä¸€å±‚è¾“å…¥çš„ä¸€éƒ¨åˆ†ã€‚å¯¹äºæ•´ä¸ªå›¾ç‰‡ä¸­çš„æ¯ä¸€ä¸ª 3Ã—3 çš„å—ï¼Œéƒ½ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µï¼Œå¹¶ä¸”åˆ›å»ºä¸€ä¸ªç”¨ç‚¹ç§¯å’Œè¿‡æ»¤å™¨ç®€åŒ–çš„æ–°å›¾ç‰‡ã€‚

![](img/7469231bd2b1a8a80288784f649e46f4.png)

å›¾ç‰‡ç”± Kjell Magne Fauske åœ¨[å…¬å…±é¢†åŸŸ](https://commons.wikimedia.org/wiki/File:2D_Convolution_Animation.gif)å‘å¸ƒ

æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œè¿™ä¸ªè¿‡æ»¤å™¨æŠŠä¸€ä¸ªæ›´å¤§çš„å›¾åƒå˜æˆæ›´å®¹æ˜“ç®¡ç†å’Œè®¡ç®—æœºå¯è¯»çš„ä¸œè¥¿ã€‚è¿‡æ»¤å™¨é€šå¸¸æ£€æµ‹å›¾åƒä¸­æœ€ç›¸å…³å’Œæœ€çªå‡ºçš„ç‰¹å¾â€”â€”å®ƒä»¬å¯ä»¥éå¸¸ç®€å•ï¼Œå¦‚æ£€æµ‹çº¿æ¡å’Œå½¢çŠ¶ï¼Œä¹Ÿå¯ä»¥éå¸¸å¤æ‚ï¼Œå¦‚é¢éƒ¨è¯†åˆ«â€”â€”æˆ–è€…å°±æˆ‘è€Œè¨€ï¼Œæ˜¯è·¯æ ‡ã€‚

å¦‚æœä½ æƒ³çœ‹çœ‹è¿™äº›å·ç§¯å±‚æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œè¯·æŸ¥çœ‹ç‘å°”æ£®å¤§å­¦çš„èµ„æº:

 [## å·ç§¯ç¥ç»ç½‘ç»œçš„ä¸‰ç»´å¯è§†åŒ–

www.cs.ryerson.ca](https://www.cs.ryerson.ca/~aharley/vis/conv/) 

è¿™é‡Œæœ‰ä¸€æ®µæ¥è‡ª DeepLizard çš„è§†é¢‘ï¼Œè®©ä½ äº†è§£æ›´å¤šå…³äº CNN çš„ä¿¡æ¯:

CNN ä¸Šçš„æ·±èœ¥èœ´

# å…¥é—¨æŒ‡å—

ä¸ºäº†åˆ›å»ºæˆ‘è‡ªå·±çš„ CNNï¼Œæˆ‘ä½¿ç”¨äº†ä¸€ä¸ªå«åš [PyTorch](https://pytorch.org/) çš„ Python åº“ã€‚PyTorch æ˜¯ä¸€ä¸ªå¼€æºçš„æœºå™¨å­¦ä¹ æ¡†æ¶ï¼Œå…è®¸ä½ ä»å¤´åˆ°å°¾åˆ›å»ºç¥ç»ç½‘ç»œã€‚é¦–å…ˆï¼Œæˆ‘é€šè¿‡ [Kaggle](https://www.kaggle.com/) åˆ›å»ºäº†ä¸€ä¸ª Jupyter ç¬”è®°æœ¬ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„ç½‘ç«™ï¼Œå…è®¸ä½ ä½¿ç”¨å…è´¹çš„ GPU æ¥è¿è¡Œä½ çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚æˆ‘å¼ºçƒˆå»ºè®®å°†æ‚¨çš„ä»£ç ç§»åˆ°é‚£é‡Œâ€”â€”ä¸€æ—¦æ‚¨æŒæ¡äº†çªé—¨ï¼Œå®ƒéå¸¸ç›´è§‚ä¸”æ˜“äºä½¿ç”¨ã€‚

ç¥ç»ç½‘ç»œåœ¨å¤§å‹æ•°æ®é›†ä¸Šè®­ç»ƒã€‚åœ¨æˆ‘çš„ç¥ç»ç½‘ç»œä¸­ï¼Œæˆ‘ä½¿ç”¨å¾·å›½äº¤é€šæ ‡å¿—è¯†åˆ«åŸºå‡†(GTSRB)æ•°æ®é›†æ¥è®­ç»ƒå’Œæµ‹è¯•ç¥ç»ç½‘ç»œã€‚æˆ‘çš„ç¥ç»ç½‘ç»œå¯¹ä¸€ç»„ 39ï¼Œ209 ä¸ªå¸¦æ ‡ç­¾çš„å›¾åƒè¿›è¡Œäº†è®­ç»ƒï¼Œä»¥å­¦ä¹ ç”¨äºç¡®å®šè·¯æ ‡æ¨¡å¼çš„è¿‡æ»¤å™¨ã€‚ç„¶åï¼Œå®ƒåœ¨ä¸€ç»„ 12ï¼Œ630 å¼ å¸¦æ ‡ç­¾çš„æµ‹è¯•å›¾åƒä¸Šè¿›è¡Œæµ‹è¯•ï¼Œä»¥äº†è§£å®ƒåœ¨çœŸå®ä¸–ç•Œæ•°æ®ä¸Šçš„å‡†ç¡®æ€§ã€‚

ä¸ºäº†å°†æ•°æ®åŠ è½½åˆ°æˆ‘çš„ç¨‹åºä¸­ï¼Œæˆ‘å‰å¾€ GTSRB æ•°æ®é›†çš„ [Kaggle é¡µé¢ï¼Œå¹¶åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„ç¬”è®°æœ¬ã€‚](https://www.kaggle.com/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign)

```
import torch as t 
import torchvision 
from torchvision import transforms 
import torch.utils.data as data 
import torch.optim as optim
import torch.nn as nn 
import time 
import numpy as np
import os 
import matplotlib.pyplot as plt
```

ä¸‹é¢æ˜¯æˆ‘å¯¼å…¥çš„åº“çš„åˆ—è¡¨ï¼Œå®ƒä»¬æ˜¯ä»€ä¹ˆï¼Œä»¥åŠå®ƒä»¬å„è‡ªæ–‡æ¡£çš„é“¾æ¥ã€‚

*   [PyTorch](https://pytorch.org/docs/)
*   [ç«ç‚¬è§†è§‰ã€PyTorch å†…éƒ¨çš„è®¡ç®—æœºè§†è§‰åº“](https://pytorch.org/vision/stable/index.html)
*   [Transforms](https://pytorch.org/vision/stable/transforms.html) -å…è®¸è½¬æ¢è¾“å…¥æ•°æ®ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯ä»å›¾åƒåˆ°å¼ é‡ã€‚è¿˜èƒ½å¤Ÿå¯¹è¾“å…¥æ•°æ®è¿›è¡Œå¤§å°è°ƒæ•´ã€è£å‰ªå’Œå…¶ä»–è½¬æ¢ã€‚
*   [torch.utils.data](https://pytorch.org/docs/stable/data.html) -å¤„ç†æ•°æ®çš„å·¥å…·
*   [torch.optim](https://pytorch.org/docs/stable/optim.html) -ä¼˜åŒ–ç®—æ³•ï¼Œä½¿ç½‘ç»œè¾¾åˆ°æœ€ä½³çŠ¶æ€
*   [torch.nn](https://pytorch.org/docs/stable/nn.html) -ç¥ç»ç½‘ç»œå·¥å…·ï¼Œä¸“é—¨ä¸ºè®­ç»ƒç¥ç»ç½‘ç»œè€Œåˆ¶ä½œ
*   [æ—¶é—´](https://docs.python.org/3/library/time.html) -ç”¨äºè®¡æ—¶æµ‹è¯•å’ŒåŸ¹è®­æ‰€éœ€çš„æ—¶é—´
*   [NumPy](https://numpy.org/)â€”â€”ç”¨äºåˆ¶ä½œå’Œä½¿ç”¨æ•°æ®æ•°ç»„
*   [os](https://docs.python.org/3/library/os.html) -ç”¨äºç®¡ç†æˆ‘ä»¬ç¨‹åºä¸­çš„æ–‡ä»¶
*   matplotlib.pyplot -ç”¨äºæ˜¾ç¤ºæ•´ä¸ªç¨‹åºçš„å›¾å½¢å’Œå›¾åƒ

# å‡†å¤‡æ•°æ®

```
*#Defining the transformation*
data_transforms = transforms.Compose([transforms.Resize([112, 112]), transforms.ToTensor()])
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä¸ºæ•°æ®å®šä¹‰äº†è½¬æ¢ã€‚è¯¥è½¬æ¢å°†è¾“å…¥å›¾åƒçš„å¤§å°è°ƒæ•´ä¸º 112x112ï¼Œå¹¶å°†è¿™äº›å›¾åƒè½¬æ¢ä¸ºå¼ é‡ã€‚

```
*#Defining hyperparameters*

BATCH_SIZE = 256
learning_rate = 0.001
EPOCHS = 7
numClasses = 43
```

ç„¶åæˆ‘å®šä¹‰äº†æ¨¡å‹çš„è¶…å‚æ•°ï¼Œæ¯”å¦‚æ‰¹é‡å¤§å°ã€å­¦ä¹ é€Ÿç‡å’Œæ—¶æœŸæ•°ã€‚æ‰¹é‡å¤§å°æ˜¯æŒ‡ä¸€æ¬¡å¤„ç†çš„å›¾åƒæ•°é‡ã€‚å­¦ä¹ ç‡æ˜¯ç¥ç»ç½‘ç»œæ¯æ¬¡å‡ºé”™æ—¶è°ƒæ•´çš„ç¨‹åº¦ã€‚å†å…ƒæ˜¯è®¡ç®—æœºæ£€æŸ¥æ•´ä¸ªè®­ç»ƒé›†çš„æ¬¡æ•°(å®ƒæŸ¥çœ‹æ¯ä¸ªå›¾åƒ 7 æ¬¡)ã€‚

```
*#path of training data*

train_data_path = '../input/gtsrb-german-traffic-sign/Train'
train_data = torchvision.datasets.ImageFolder(root = train_data_path, transform = data_transforms)

*#Divide data into training and validation (0.8 and 0.2)*
ratio = 0.8
n_train_examples = int(len(train_data) * ratio)
n_val_examples = len(train_data) - n_train_examples

train_data, val_data = data.random_split(train_data, [n_train_examples, n_val_examples])

print(f"Number of training samples = **{**len(train_data)**}**")
print(f"Number of validation samples = **{**len(val_data)**}**")
```

æ¥ä¸‹æ¥ï¼Œæˆ‘å¼€å§‹åˆ›å»ºæˆ‘çš„æ•°æ®é›†ï¼é¦–å…ˆï¼Œæˆ‘å®šä¹‰äº†è®­ç»ƒæ•°æ®çš„æ–‡ä»¶è·¯å¾„ã€‚Kaggle ä½¿å¤åˆ¶å’Œç²˜è´´æ•°æ®è·¯å¾„åœ¨æ‚¨çš„ç¨‹åºä¸­ä½¿ç”¨å˜å¾—å¾ˆå®¹æ˜“â€”â€”åªéœ€å‰å¾€ç•Œé¢çš„å³ä¾§ï¼Œå°†é¼ æ ‡æ‚¬åœåœ¨åŒ…å«æ‚¨çš„åˆ—è½¦æ•°æ®çš„æ–‡ä»¶å¤¹ä¸Šï¼Œç„¶åå•å‡»å¤åˆ¶æŒ‰é’®ã€‚ç„¶åï¼Œæˆ‘ä½¿ç”¨ torchvision çš„ [ImageFolder](https://pytorch.org/vision/stable/datasets.html#torchvision.datasets.VisionDataset) æ•°æ®é›†ç±»å‹ï¼Œä½¿ç”¨ Kaggle æ–‡ä»¶è·¯å¾„å’Œæˆ‘ä¹‹å‰å®šä¹‰çš„è½¬æ¢ï¼Œåˆ›å»ºäº†æˆ‘çš„è®­ç»ƒé›†ã€‚

ç„¶åï¼Œæˆ‘å°†è®­ç»ƒé›†åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‚è®­ç»ƒæ˜¯ç¨‹åºå®é™…è®­ç»ƒçš„å†…å®¹â€”â€”è¿™äº›æ˜¯å®ƒå°†å­¦ä¹ è¯†åˆ«çš„å›¾åƒã€‚éªŒè¯é›†åŸºæœ¬ä¸Šæ˜¯ä¸ºäº†åœ¨è®­ç»ƒæ—¶è¿›è¡Œæµ‹è¯•â€”â€”å®ƒè®©æ‚¨å®æ—¶çœ‹åˆ°æ‚¨çš„æ¨¡å‹åœ¨æ²¡æœ‰è®­ç»ƒçš„æ•°æ®ä¸Šçš„è¡¨ç°ã€‚

```
*#create data loader for training and validation*
trainloader = data.DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)
valloader = data.DataLoader(val_data, shuffle=True, batch_size=BATCH_SIZE)
```

å‡†å¤‡è®­ç»ƒæ•°æ®çš„æœ€åä¸€æ­¥æ˜¯åˆ›å»ºæ•°æ®åŠ è½½å™¨ã€‚è¿™åŸºæœ¬ä¸Šæ˜¯ä¸€ç§è®©ç¨‹åºè½»æ¾è®¿é—®å’Œéå†ä½ å®šä¹‰çš„æ•°æ®é›†çš„æ–¹æ³•ã€‚æˆ‘å·²ç»å°†è¿™äº›åŠ è½½å™¨çš„æ‰¹å¤„ç†å¤§å°è®¾ç½®ä¸º 256(æˆ‘ä¹‹å‰è®¾ç½®çš„å˜é‡),å®ƒä»¬æ¯æ¬¡éƒ½ä¼šæ´—ç‰Œã€‚

```
*# Plot histogram for training and validation data*

train_hist = [0]*numClasses
for i **in** train_data.indices:
    tar = train_data.dataset.targets[i]
    train_hist[tar] += 1

val_hist = [0]*numClasses
for i **in** val_data.indices:
    tar = val_data.dataset.targets[i]
    val_hist[tar] += 1

plt.bar(range(numClasses), train_hist, label="train")
plt.bar(range(numClasses), val_hist, label="val")
legend = plt.legend(loc='upper right', shadow=True)
plt.title("Distribution Plot")
plt.xlabel("Class ID")
plt.ylabel("# of examples")

plt.savefig("train_val_split.png", bbox_inches = 'tight', pad_inches=0.5)
```

ä¸è¿‡ï¼Œåœ¨å¼€å§‹å®é™…è®­ç»ƒç½‘ç»œä¹‹å‰ï¼Œæˆ‘ç”»äº†ä¸€ä¸ªæ•°æ®åˆ†å¸ƒå›¾ã€‚æˆ‘è®¾ç½®å®ƒæ¥æ˜¾ç¤ºæ€»å…±æœ‰å¤šå°‘ä¸ªä¾‹å­ï¼Œä»¥åŠè®­ç»ƒå’ŒéªŒè¯ä¹‹é—´çš„å·®å¼‚ã€‚

![](img/c003703b0a8b6d24616698e6a63726d8.png)

ä¿¡ç”¨:å¡”æ‹‰æ™®ç½—å°”

# åˆ›å»ºç¥ç»ç½‘ç»œ

```
class **NeuralNet**(nn.Module):
    def __init__(self, output_dim):
        super().__init__()

        self.features = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1),
            nn.MaxPool2d(kernel_size=2),
            nn.ReLU(inplace=True),

            nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, padding=1),
            nn.MaxPool2d(kernel_size=2),
            nn.ReLU(inplace=True),

            nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),

            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),

            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.MaxPool2d(kernel_size=2),
            nn.ReLU(inplace=True),
            )

        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(256*7*7, 1000),
            nn.ReLU(inplace=True),

            nn.Dropout(0.5),
            nn.Linear(in_features=1000, out_features=256),
            nn.ReLU(inplace=True),

            nn.Linear(256, output_dim)
            )

    def forward(self, x):
        x = self.features(x)
        h = x.view(x.shape[0], -1)
        x = self.classifier(h)
        return x, h
```

æœ‰è¶£çš„äº‹æƒ…ä»è¿™é‡Œå¼€å§‹ï¼è¿™æ˜¯æˆ‘å®šä¹‰æˆ‘çš„ç¥ç»ç½‘ç»œçš„ä»£ç å—ã€‚è¿™ä¸ªç½‘ç»œéå¸¸ç±»ä¼¼äº AlexNet æ¡†æ¶ï¼Œä½¿ç”¨ 5 ä¸ªå·ç§¯å±‚ï¼Œç„¶åæ˜¯ 3 ä¸ªå…¨è¿æ¥(çº¿æ€§)å±‚ã€‚æ¯ä¸ªå·ç§¯å±‚ä½¿ç”¨æœ€å¤§æ± ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªæ¥è‡ª DeepLizard çš„å…³äº max pooling layers çš„è§†é¢‘ï¼Œæˆ‘è§‰å¾—å®ƒå¾ˆå¥½åœ°è§£é‡Šäº†è¿™ä¸ªä¸»é¢˜ã€‚

æœ€å¤§æ± å±‚æ•°ä¸Šçš„æ·±èœ¥èœ´

æˆ‘è¿˜ä½¿ç”¨äº†[é€€å‡ºæ–¹æ³•](https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/)æ¥å‡å°‘æˆ‘çš„æ¨¡å‹ä¸­çš„è¿‡åº¦æ‹Ÿåˆ(ç½‘ç»œå­¦ä¹ ç‰¹å®šçš„å›¾åƒè€Œä¸æ˜¯æ¨¡å¼)â€”â€”è¿™æ˜¯ä½¿ç”¨ nn å®šä¹‰çš„ã€‚è¾å­¦(0.5)ã€‚

```
*# define optimiser and criterion functions*
optimiser = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)
criterion = nn.CrossEntropyLoss()
```

è¿™é‡Œæˆ‘å®šä¹‰äº†ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°ã€‚ä¼˜åŒ–å™¨æ˜¯åœ¨æ¯ä¸ªè®­ç»ƒæ—¶æœŸä¹‹åè¿”å›å¹¶å›ºå®šæ¨¡å‹çš„å‚æ•°ã€‚æˆ‘è¿˜åœ¨ä¼˜åŒ–å™¨ä¸­è®¾ç½®äº†æƒé‡è¡°å‡ï¼Œè¿™æ„å‘³ç€æƒé‡æ¯æ¬¡éƒ½ä¼šå‡å°‘ä¸€ç‚¹ã€‚è¿™ä¹Ÿæœ‰åŠ©äºå‡å°‘è¿‡åº¦æ‹Ÿåˆã€‚

# å®šä¹‰å‡½æ•°

```
*# Function to perform training of the model*

def train(model, loader, opt, criterion):
    epoch_loss = 0
    epoch_acc = 0

    *# Train the model*
    model.train()

    for (images, labels) **in** loader:
        images = images.cuda()
        labels = labels.cuda()

        output, _ = model(images)
        loss = criterion(output, labels)

        *# Training pass*
        opt.zero_grad()

        *# Backpropagation*
        loss.backward()

        *# Calculate accuracy*
        acc = calculate_accuracy(output, labels)

        *# Optimizing weights*
        opt.step()

        epoch_loss += loss.item()
        epoch_acc += acc.item()

    return epoch_loss / len(loader), epoch_acc / len(loader)
```

æ¥ä¸‹æ¥ï¼Œå®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥è®­ç»ƒæ¨¡å‹ã€‚åŸºæœ¬ä¸Šï¼Œè¯¥å‡½æ•°è¿­ä»£é€šè¿‡è®­ç»ƒ/éªŒè¯åŠ è½½å™¨å¹¶è®­ç»ƒç½‘ç»œã€‚éœ€è¦æ³¨æ„çš„å‡ ä»¶é‡è¦äº‹æƒ…æ˜¯ä¼˜åŒ–å’Œåå‘ä¼ æ’­ã€‚è¯¥å‡½æ•°è¿˜è¿”å›å®ƒæ‰€ä½¿ç”¨çš„æ¯ä¸ªå†å…ƒçš„æŸå¤±å’Œç²¾åº¦(ä¸€ä¸ªå†å…ƒæ˜¯ç¨‹åºå¾ªç¯é€šè¿‡æ‰€æœ‰è®­ç»ƒæ•°æ®çš„æ¬¡æ•°)ã€‚

```
def evaluate(model, loader, opt, criterion):
    epoch_loss = 0
    epoch_acc = 0

    *#evaluate the model*
    model.eval()

    with t.no_grad():
        for (images, labels) **in** loader:

            images = images.cuda()
            labels = labels.cuda()

            output, _ = model(images)
            loss = criterion(output, labels)

            acc = calculate_accuracy(output, labels)

            epoch_loss += loss.item()
            epoch_acc += acc.item()

    return epoch_loss / len(loader), epoch_acc / len(loader)
```

æˆ‘è¿˜å®šä¹‰äº†ä¸€ä¸ªå‡½æ•°æ¥è¯„ä¼°æ¨¡å‹ã€‚ä¸ä½¿ç”¨æ¢¯åº¦ä¸‹é™ï¼Œå®ƒæµ‹è¯•ç½‘ç»œçš„è¡¨ç°å¦‚ä½•ã€‚åƒè®­ç»ƒå‡½æ•°ä¸€æ ·ï¼Œå®ƒè¯„ä¼°ç½‘ç»œçš„æŸè€—å’Œå‡†ç¡®æ€§ã€‚

# è®­ç»ƒç¥ç»ç½‘ç»œ

```
*#TRAINING*

train_loss_list = [0]*EPOCHS
train_acc_list = [0]*EPOCHS
val_loss_list = [0]*EPOCHS
val_acc_list = [0]*EPOCHS

for epoch **in** range(EPOCHS):
    print("Epoch **{}**: ".format(epoch))
    train_start_time=time.monotonic()
    train_loss, train_acc= train(model, trainloader, optimiser, criterion)
    train_end_time = time.monotonic()

    val_start_time = time.monotonic()
    val_loss, val_acc = evaluate(model, valloader, optimiser, criterion)
    val_end_time = time.monotonic()

    train_loss_list[epoch] = train_loss
    train_acc_list[epoch] = train_acc
    val_loss_list[epoch] = val_loss
    val_acc_list[epoch] = val_acc

    print("Training: Loss = **%.4f**, Accuracy = **%.4f**, Time = **%.2f** seconds" %(train_loss, train_acc, train_end_time-train_start_time))
    print("Validation: Loss = **{}**, Accuracy = **{}**, Time = **{}** seconds".format(val_loss, val_acc, val_end_time - val_start_time))
    print("")
```

è¿™å°±æ˜¯:æˆ‘çš„ä»£ç ä¸­æœ€é‡è¦çš„éƒ¨åˆ†ï¼è¿™ä¸ªæ¨¡å—æ˜¯æ‰€æœ‰ç¥ç»ç½‘ç»œè®­ç»ƒå‘ç”Ÿçš„åœ°æ–¹ã€‚å®ƒé¦–å…ˆæ‰“å°å‡ºçºªå…ƒç¼–å·ï¼Œç„¶åä½¿ç”¨è®­ç»ƒé›†åŠ è½½å™¨è®­ç»ƒæ¨¡å‹ã€‚å®ƒè¿˜ä½¿ç”¨ time.monotonic()å‡½æ•°è®¡ç®—è®­ç»ƒæ¨¡å‹æ‰€éœ€çš„æ—¶é—´ã€‚ç„¶åå®ƒå¯¹éªŒè¯é›†åšåŒæ ·çš„äº‹æƒ…ï¼Œé™¤äº†å®ƒä½¿ç”¨ evaluate å‡½æ•°(è¿™é‡Œæ²¡æœ‰è®­ç»ƒ)ã€‚

åœ¨è¿™ä¸€åˆ‡ç»“æŸæ—¶ï¼Œå®ƒæ‰“å°å‡ºæŸè€—ã€ç²¾åº¦å’Œè®­ç»ƒç½‘ç»œæ‰€ç”¨çš„æ—¶é—´ã€‚æˆ‘çœ‹åˆ°äº†æŸå¤±çš„å‡å°‘å’Œç²¾ç¡®åº¦çš„æé«˜â€”â€”è¿™éå¸¸ä»¤äººæ»¡æ„ğŸ˜

![](img/658beb2169e91f7be501d88036dd95e0.png)

å‰ä¸€ä¸ªå—çš„è¾“å‡ºâ€”â€”çœ‹ç€æŸè€—å‡å°‘ï¼Œç²¾åº¦å¢åŠ ï¼

é¡ºä¾¿è¯´ä¸€ä¸‹ï¼Œä½ å¯ä»¥è®¿é—®é¡¹ç›®çš„ Kaggle é¡µé¢æ¥æŸ¥çœ‹è¿™äº›å—çš„æ‰€æœ‰è¾“å‡ºã€‚

```
*# Saving the model*

*# Create folder to save model*
MODEL_FOLDER = "../Model"
if **not** os.path.isdir(MODEL_FOLDER):
    os.mkdir(MODEL_FOLDER)

PATH_TO_MODEL = MODEL_FOLDER + "/pytorch_classification_alexnetTS.pth"
if os.path.exists(PATH_TO_MODEL):
    os.remove(PATH_TO_MODEL)
t.save(model.state_dict(), PATH_TO_MODEL)

print("Model saved at **%s**" %(PATH_TO_MODEL))
```

å½“è®­ç»ƒå®Œæˆæ—¶ï¼Œç¨‹åºä¿å­˜æ¨¡å‹ï¼Œä»¥ä¾¿æˆ‘å¯ä»¥åœ¨ä»¥ååŠ è½½å’Œä½¿ç”¨å®ƒã€‚

```
*# Plot loss and accuracies for training and validation data*

_, axs = plt.subplots(1, 2, figsize=(15, 5))

*# Loss plot*
axs[0].plot(train_loss_list, label="train")
axs[0].plot(val_loss_list, label="val")
axs[0].set_title("Plot - Loss")
axs[0].set_xlabel("Epochs")
axs[0].set_ylabel("Loss")
legend = axs[0].legend(loc='upper right', shadow=False)

*# Accuracy plot*
axs[1].plot(train_acc_list, label="train")
axs[1].plot(val_acc_list, label="val")
axs[1].set_title("Plot - Accuracy")
axs[1].set_xlabel("Epochs")
axs[1].set_ylabel("Accuracy")
legend = axs[1].legend(loc='center right', shadow=True)
```

æµ‹è¯•è¿‡ç¨‹ä¹‹å‰çš„æœ€åä¸€ç‚¹ä»£ç æ˜¯ç»˜åˆ¶ç½‘ç»œçš„æŸè€—å’Œå‡†ç¡®æ€§ã€‚è¿™ä½¿ç”¨ matplotlib åº“æ¥åˆ›å»ºä¸¤ä¸ªç®€å•çš„çº¿å›¾ï¼Œæ˜¾ç¤ºæ¯ä¸ªæ—¶æœŸçš„æŸè€—å’Œæ¯ä¸ªæ—¶æœŸçš„ç²¾åº¦ã€‚æ¯ä¸ªå›¾è¡¨å°†è¿™äº›å…ƒç´ ä¸­çš„ä¸€ä¸ªä¸è®­ç»ƒé›†å’ŒéªŒè¯é›†è¿›è¡Œæ¯”è¾ƒã€‚è®­ç»ƒé›†çš„çº¿æ¡æ˜¯è“è‰²çš„ï¼ŒéªŒè¯é›†çš„çº¿æ¡æ˜¯æ©™è‰²çš„ã€‚çœ‹åˆ°ç½‘ç»œå¦‚ä½•éšç€æ—¶ä»£çš„å‘å±•è€Œè¿›æ­¥çœŸçš„å¾ˆæœ‰è¶£ã€‚

![](img/9c137b5a0d619bbdd29fb3685525b7b6.png)

ä¿¡ç”¨:å¡”æ‹‰æ™®ç½—å°”

# æµ‹è¯•æ¨¡å‹

ç°åœ¨æˆ‘å·²ç»è®­ç»ƒäº†ç¥ç»ç½‘ç»œï¼Œæ˜¯æ—¶å€™çœ‹çœ‹å®ƒåœ¨ä¸€äº›å®ƒä»æœªè§è¿‡çš„æµ‹è¯•æ•°æ®ä¸Šçš„è¡¨ç°äº†ã€‚è¿™æ˜¯å› ä¸ºåœ¨ç°å®ä¸–ç•Œä¸­ï¼Œå¹¶éæ‰€æœ‰çš„è·¯æ ‡éƒ½å¤„äºç›¸åŒçš„è§’åº¦ï¼Œç›¸åŒçš„æ—‹è½¬ï¼Œç›¸åŒçš„èƒŒæ™¯-è®¡ç®—æœºé€šè¿‡è®­ç»ƒé›†å­¦ä¹ äº†è®¸å¤šå˜åŒ–ï¼Œæˆ‘ä»¬éœ€è¦çœ‹çœ‹å®ƒæ˜¯å¦å¯ä»¥åº”ç”¨äºä¸€äº›æ–°çš„ä¾‹å­ã€‚

```
*#Define transformations*

test_transforms = transforms.Compose([
    transforms.Resize([112, 112]),
    transforms.ToTensor()
    ])
```

é¦–å…ˆï¼Œæˆ‘ä¸ºæµ‹è¯•æ•°æ®å®šä¹‰äº†è½¬æ¢ã€‚è¿™ç§è½¬æ¢å°†æµ‹è¯•å›¾åƒè½¬æ¢ä¸º 112 x 112 çš„å›¾ç‰‡ï¼Œç„¶åè½¬æ¢ä¸º PyTorch å¯ä»¥è¯»å–çš„å¼ é‡ã€‚

```
*# Define path of test data*

test_data_path = "../input/gtsrb-test-images/GTSRB/Final_Test"
test_data = torchvision.datasets.ImageFolder(root = test_data_path, transform = test_transforms)
test_loader = data.DataLoader(test_data, batch_size=1, shuffle=False)

numClasses = 43
```

ç„¶åæˆ‘å®šä¹‰äº†æµ‹è¯•æ•°æ®çš„è·¯å¾„ï¼Œå†æ¬¡ä½¿ç”¨ Kaggle æ•°æ®é›†ä¸­çš„å¤åˆ¶ç²˜è´´å‡½æ•°ã€‚å¯¹äºæµ‹è¯•æ•°æ®ï¼Œæˆ‘åœ¨æ•°æ®è¾“å…¥æ–¹é¢æœ‰ä¸€äº›é—®é¢˜ã€‚æˆ‘ä½¿ç”¨çš„ CSV æ–‡ä»¶ä¸­çš„ png æ ¼å¼ï¼Œå›¾åƒæ˜¯ã€‚ppm æ–‡ä»¶ã€‚æˆ‘é€‰æ‹©ä» [GTSRB ç½‘ç«™](https://benchmark.ini.rub.de/gtsrb_dataset.html#Downloads)å•ç‹¬ä¸‹è½½æµ‹è¯•å›¾ç‰‡ï¼Œå¹¶ä¸Šä¼ åˆ° Kaggle ä½œä¸ºè‡ªå®šä¹‰æ•°æ®é›†ã€‚

```
import pandas as pd
*# Read the image labels from the csv file*
*# Note: The labels provided are all numbers, whereas the labels assigned by PyTorch dataloader are strings*

df = pd.read_csv("../input/gtsrb-german-traffic-sign/Test.csv")
numExamples = len(df)
labels_list = list(df.iloc[:,6])

print(numExamples)
```

ä¸ºäº†è®©è®¡ç®—æœºè¯»å–æ¯ä¸ªå›¾åƒï¼Œä½¿ç”¨ CSV æ–‡ä»¶æ¥è·å–æ–‡ä»¶è·¯å¾„å’Œå®ƒä»¬å„è‡ªçš„ç±»ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘å¯¼å…¥äº† Pandas åº“ã€‚æˆ‘ç”¨å®ƒæ¥è¯»å– CSV æ–‡ä»¶ï¼Œè·å–ç¤ºä¾‹æ•°é‡ï¼Œå¹¶ä½¿ç”¨ iloc å‡½æ•°åˆ›å»ºæ ‡ç­¾åˆ—è¡¨ã€‚è¿™å¾—åˆ°äº†æ•´ä¸ªåˆ—(åˆ— 7ï¼ŒæŒ‰ç…§ Python è¯­æ³•ç´¢å¼•ä¸º 6 ),å¹¶å°†å®ƒè½¬æ¢æˆä¸€ä¸ªåˆ—è¡¨ï¼Œæˆ‘å¯ä»¥ç”¨å®ƒæ¥æ ‡è®°æµ‹è¯•å›¾åƒã€‚

```
*#Perform classification*

y_pred_list = []
corr_classified = 0

with t.no_grad():
    model.eval()

    i = 0

    for image, _ **in** test_loader:
        image = image.cuda()

        y_test_pred = model(image)

        y_pred_softmax = t.log_softmax(y_test_pred[0], dim=1)
        _, y_pred_tags = t.max(y_pred_softmax, dim=1)
        y_pred_tags = y_pred_tags.cpu().numpy()

        y_pred = y_pred_tags[0]
        y_pred = labels[y_pred]

        y_pred_list.append(y_pred)

        if labels_list[i] == y_pred:
            corr_classified += 1

        i += 1

print("Correctly classified: **{}**".format(corr_classified))
print("Incorrectly classified: **{}**".format(numExamples - corr_classified))
print("Final accuracy: **{}**".format(corr_classified / numExamples))
```

è¿™æ˜¯ä¸€å¤§æ®µä»£ç ğŸ¤£æ€»çš„æ¥è¯´ï¼Œè¿™ä¸ªæ¨¡å—ä¸ºæ¨¡å‹å¯¹æµ‹è¯•æ•°æ®çš„é¢„æµ‹åˆ›å»ºäº†ä¸€ä¸ªç©ºåˆ—è¡¨ã€‚åœ¨æ²¡æœ‰æ¢¯åº¦ä¸‹é™(æ²¡æœ‰è®­ç»ƒ)çš„æƒ…å†µä¸‹ï¼Œä»£ç å¾ªç¯é€šè¿‡æµ‹è¯•åŠ è½½å™¨ä¸­çš„æ¯ä¸ªå›¾åƒï¼Œå¹¶åœ¨æ¨¡å‹ä¸­è¿è¡Œå®ƒã€‚å®ƒä½¿ç”¨ softmax å’Œ max å‡½æ•°æ¥é¢„æµ‹ç»™å®šå›¾åƒå°†å…·æœ‰å“ªä¸ªæ ‡ç­¾ï¼Œç„¶åå°†è¯¥æ ‡ç­¾æ·»åŠ åˆ°ä¹‹å‰åˆ›å»ºçš„åˆ—è¡¨ä¸­ã€‚

æœ€åï¼Œå®ƒæ‰“å°å‡ºæ­£ç¡®åˆ†ç±»çš„æ•°é‡ï¼Œé”™è¯¯åˆ†ç±»çš„æ•°é‡ï¼Œç„¶åå°†ä¸¤è€…ç›¸é™¤å¾—åˆ°æœ€ç»ˆçš„å‡†ç¡®åº¦ã€‚

```
*# Display first 30 images, along with the actual and predicted classes*
from PIL import Image
fig, axs = plt.subplots(6,5,figsize=(50,75))
*#fig.tight_layout(h_pad = 50)*
for i **in** range(30):
    row = i // 5
    col = i % 5

    imgName = '../input/gtsrb-test-images/GTSRB/Final_Test/' + df.iloc[i,7]
    wrongFolder = str(imgName).replace('/Test', '/Images')
    wrongExtension = wrongFolder.replace('.png', '.ppm')
    img = Image.open(wrongExtension)
    axs[row, col].imshow(img)
    title = "Pred: **%d**, Actual: **%d**" % (y_pred_list[i], labels_list[i])
    axs[row, col].set_title(title, fontsize=50)

plt.savefig("predictions.png", bbox_inches = 'tight', pad_inches=0.5)
```

æœ€åï¼Œæ˜¯æ—¶å€™çœ‹çœ‹ä¸€äº›çœŸå®çš„æ•°æ®å’Œéšä¹‹è€Œæ¥çš„é¢„æµ‹äº†ï¼è¿™æ®µä»£ç æ˜¾ç¤ºäº† 30 ä¸ªæµ‹è¯•å›¾åƒï¼Œé¢„æµ‹å’Œå®é™…æ ‡ç­¾æ˜¾ç¤ºåœ¨æ¯ä¸ªå›¾åƒçš„ä¸Šæ–¹ã€‚

![](img/363282b45cf689f2443f345b8fac9984.png)

ä¿¡ç”¨:å¡”æ‹‰æ™®ç½—å°”

æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œè¯¥æ¨¡å‹åªé¢„æµ‹äº†ä¸€äº›é”™è¯¯çš„å›¾åƒï¼Œå¹¶ä¸”åœ¨å¯¹ä¸€äº›ç¡¬è·¯æ ‡è¿›è¡Œåˆ†ç±»æ–¹é¢åšäº†éå¸¸å‡ºè‰²çš„å·¥ä½œã€‚

> è¿™ä¸ªé¡¹ç›®æ¥è‡ª Suraj Krishnamurthy çš„ GTSRB åˆ†ç±»ç¨‹åºã€‚è¿™é‡Œçœ‹ Github é¡¹ç›®åŸæ–‡:ã€https://github.com/surajmurthy/TSR_PyTorch 

<https://www.linkedin.com/in/taraprole/>  

å¦‚æœä½ æœ‰å…´è¶£çœ‹æ›´å¤šæˆ‘çš„ä½œå“ï¼Œæˆ‘æœ‰ä¸€ä»½æ¯å‘¨æ—¶äº‹é€šè®¯ï¼Œè¯·åœ¨ä¸‹é¢è®¢é˜…ï¼

<https://taraprole.substack.com/subscribe>  

# å‚è€ƒ

**GTSRB æ•°æ®é›†**

*   Johannes Stallkampã€Marc Schlipsingã€Jan Salmen å’Œ Christian Igel
    [äººä¸è®¡ç®—æœº:äº¤é€šæ ‡å¿—è¯†åˆ«çš„åŸºå‡†æœºå™¨å­¦ä¹ ç®—æ³•](https://www.sciencedirect.com/science/article/abs/pii/S0893608012000457)ã€‚ç¥ç»ç½‘ç»œ 32ï¼Œç¬¬ 323â€“332 é¡µï¼Œ2012 å¹´
*   Johannes Stallkampã€Marc Schlipsingã€Jan Salmen å’Œ Christian Igel
    [å¾·å›½äº¤é€šæ ‡å¿—è¯†åˆ«åŸºå‡†:å¤šç±»åˆ«åˆ†ç±»ç«èµ›](https://ieeexplore.ieee.org/document/6033395)ã€‚ç¥ç»ç½‘ç»œå›½é™…è”åˆä¼šè®®(IJCNN 2011)ï¼Œç¬¬ 1453â€“1460 é¡µï¼ŒIEEE å‡ºç‰ˆç¤¾