# 大脑最宝贵的资源

> 原文：<https://towardsdatascience.com/the-brains-most-precious-resource-7341b9fb6369?source=collection_archive---------18----------------------->

## 注意力在神经科学、深度学习和日常生活中的作用

大型强子对撞机(LHC)是人类建造的最复杂的机器之一。当它运行时，每秒钟大约有 10 亿个粒子以接近光速的速度相互碰撞，探索超越当前粒子物理学标准模型边缘的物理学。

在这十亿个粒子的碰撞中会发生很多事情，巨大的探测器被建在 LHC 环的周围以 ***不会错过任何重要的*** 。但是如此大量的碰撞，加上复杂的探测器，产生了大量的数据。说真的， ***数据真多*** 。如果你把所有的数据加起来，大约每秒 1pb，或者 1000 TB，或者 100 万 GB 的碰撞数据。

![](img/ee22ee4256e534d4db836b25290893f9.png)

LHC 周围的阿特拉斯探测器。马克西米利安·布里斯，CC BY-SA 4.0<[https://creativecommons.org/licenses/by-sa/4.0](https://creativecommons.org/licenses/by-sa/4.0)>，通过维基共享

如果你听到这些数字，很明显，用目前的计算设备是不可能 ***分析甚至*** 记录如此疯狂的数据量的。因此， ***在对数据进行任何分析变得可行之前，必须实时丢弃大量数据。***

这就是为什么 LHC 的探测器内置了许多快速、自动的触发和过滤系统，向探测器发出信号，告诉我们值得开始记录一个事件，哪些事件没有告诉我们任何有意义的东西，可以安全地丢弃。

但是，即使通过这些方法实现了数据的大幅减少，LHC 的数据中心每天仍有 1pb 的数据，仅占原始传入数据的 0.001%。

***我们的大脑每天都面临着类似的挑战*** :认知处理和存储，就像计算时间一样，是大脑最宝贵的资源，对于通过进化产生的认知系统来说，节省资源是生存的关键之一。

***所有的认知都可以看作是信息增益和代谢支出的权衡*** 。LHC 可以被视为其自身类型的 ***超人认知系统*** ，以最小的成本探测其环境并从中提取相关信息。

高效提取信息的关键之一是拥有高度优化的 ***传感器，在任何深度处理发生之前，这些传感器会进行自己的快速思考*** 。这些低级过滤器触发哪些事件被记录，哪些事件在花费太多精力之前被丢弃。

它们与科学家的高水平科学抱负相结合，形成了这个超人认知系统的另一部分，即LHC:从传感器流入的关于环境的巨大信息流中，哪些事件看起来足够有趣，值得进一步研究？ ***哪些事件应该引起我们的注意，需要进一步调查*** ？我们的目标(例如发现希格斯玻色子或超对称粒子)如何告知我们从哪里开始寻找，以及我们如何构造过滤器？

## 大脑中的注意力

> “大家都知道什么是关注。它是头脑以清晰而生动的形式，从看似几个同时可能存在的对象或思路中占有一个。”威廉·詹姆斯

尽管威廉·詹姆斯声称每个人都知道注意力是什么，但在这一点上需要强调的是 ***注意力不是一个由坐在松果体内部方向盘上的侏儒控制的同质事物*** ，而是一个复杂的多面现象，最好在几个层面上考虑，并由几个单独的移动部分组成。在我上一篇关于[为什么我们可能会以错误的方式看待大脑的文章中，](/why-we-might-be-looking-at-the-brain-in-the-wrong-way-7c17fb11c259)我讨论了这个经常出现的问题，即 ***应用几个世纪前的术语来描述新的神经科学现象*** (詹姆斯的遗产发挥了自己的作用)，并且通常，依赖古老的术语和古老的直觉会阻碍我们正确理解正在发生的事情。

对于注意力来说尤其如此，日常生活中如此熟悉的东西却同时意味着这么多事情，并且与其他摇摆不定的概念如 [***自由意志***](https://manuel-brenner.medium.com/the-thermodynamics-of-free-will-940cacd02401) ***和意识联系在一起。***

因此，在本文的其余部分，我不想详尽无遗(对于注意力的各种方面的更详细的概述，这篇[评论文章](https://www.frontiersin.org/articles/10.3389/fncom.2020.00029/full)可能是一个很好的起点)，而是说明注意力在大脑和机器学习中的一些有用的关键组成部分和功能。

LHC 很好地展示了在复杂的环境中，注意力如何决定有限的资源应该用在哪里。我相信它也很好地介绍了组成大脑中注意力机制的关键组件:我们的注意力系统可以被认为是由 ***自下而上和自上而下的控制组成，*** 为 ***亚当·加扎利*** 和 ***拉里·罗森*** 在 ***中描述了《分心的大脑:高科技世界中的古代大脑*** 。

**自上而下的机制**试图通过引导我们的注意力来实现我们的高层次目标。假设你的新年目标是减肥:你的大脑皮层将试图说服你的眼睛不要注意沙发旁边那块看起来美味营养的巧克力。自上而下的目标可能被认为是进化的顶点之一:正如我在关于[贝叶斯大脑](/the-bayesian-brain-hypothesis-35b98847d331#362f)的文章中指出的，发现和预测未来提供了巨大的进化优势，我们由死者建造的城市和技术给人留下了深刻的证据。

![](img/59b455e703fbf04998bb70138aba78f4.png)

由[Julia androschuk](https://unsplash.com/@julian13?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

另一方面，自下而上的机制会自动将你的注意力吸引到在我们漫长的进化史中值得注意的事情上。无论是街上发生了巨大的爆炸，黑暗中出现了一辆美洲虎，还是有人在你旁边的桌子上喊你的名字。

自上而下的注意力与我们大脑的执行功能密切相关，其定义是前额叶皮层对大脑其他部分进行自上而下控制的能力，大脑其他部分通过自下而上的注意力抓取进行反作用。例如，眶额皮层试图找出你的情绪是如何被你的目标调节的，并通过边缘系统 ***将抽象的目标转化为身体和行动的语言*** 。

一个有趣的注意是，这大多是通过抑制 ***而不是激活*** 来完成的。生活中有价值的往往是我们没有做的事情，我们没有跟随的冲动，无论是当我们决定早上不躺在舒适的床上去上班，还是当我们阻止自己在拉斯维加斯的晚上赌博输掉退休金。对负责注意力控制的大脑区域受损(或者，在 Phineas Gage 的情况下，铁棒穿过这些相关的大脑区域)的患者进行的研究表明，无法控制冲动和追求长期目标对他们的生活质量是多么有害。[一个类似的观点因米谢尔著名的棉花糖实验](https://www.vincenzoasaro.it/wp-content/uploads/2020/03/book_club_october14.pdf)而流行开来，表明儿童早期延迟满足是长期成功的一个很好的预测。

![](img/096964b2edfb5052048c0d097524fee7.png)

在一次事故中，一根铁棒穿过了菲尼亚斯·盖奇的脑袋，从此他变了一个人。他的许多缺陷都与缺乏冲动控制有关，这反过来又使他无法追求长期目标。通过维基媒体共享的公共领域

因此，控制注意力与控制我们的行为密切相关。我们的大脑可能被视为建立在猴子大脑上的超级计算机，随着超级计算机相对较晚出现，施加认知控制是棘手的，自上而下和自下而上的机制不断争夺大脑最宝贵的资源。

通常，他们之间会有直接的冲突。

你可能意志坚强，但在一整天的工作后，当看到巧克力棒时，唾液在你嘴里以海啸般的强度积聚，你的执行功能很容易被克服，你被证明你不是自己家里的主人。

更普遍的是，注意力分散和注意力不集中可以从目标干扰的角度来看。和大脑中的大多数事物一样，注意力是动态调节的，因此容易受到干扰。保持专注是一个主动的过程，过滤信息，忽略无关的是一个主动的过程，需要时间和精力。目标相互竞争，注意力资源总是相互直接竞争。

这是注意力的另一个重要方面，从进化的角度来看是有意义的，并将我们带回 LHC 的比喻:全球注意力引导我们的传感器到达信息收集景观 中的 ***最大值。这些可以在个人的感觉模式中实现(例如，看向某个方向)，通过在大脑的不同网络之间切换(例如，仔细听与仔细看)或在任务之间切换(阅读报纸而不是观看 Youtube)。在收集了足够的信息后，注意力还会引导我们的记忆来决定在未来的情况下哪些东西值得储存和记忆。***

但是，我们通过注意力频繁启动网络切换的能力可能会被视为一种功能和一种缺陷:由于通常有许多事情需要关注，因此有一个自动化的基础设施是至关重要的，它可以将注意力集中在输入上，并将我们的行动切换到有望获得最多信息的活动上。

在现代高科技社会中，我们不断受到注意力吸引的轰炸。正如 ***分心的大脑*** 中所述，当古代大脑不断试图在指数增长的信息景观中最大化信息时，太多的任务转换机会成为一个巨大的问题，导致持续的分心，多任务处理的失败尝试，不满足感，睡眠剥夺等等。由于复杂的任务通常分布在几个大脑区域，这种转换过程也相对较慢，这就是为什么在不同任务之间转换需要花费大量时间，[这使得我们都经常从事的多任务处理效率非常低](https://manuel-brenner.medium.com/why-you-should-start-paying-more-attention-to-your-attention-b9ee7f2df65c)。

这种现象在年轻一代中尤为明显，应对这些对我们精神生活的高度有害影响应该得到我们集体社会的一致关注(双关语)。

## 深度学习中的注意力(是你所需要的)

总而言之，我们可以将注意力概念化为一个多用途代理人的总体组织原则，他必须在现实世界中同时完成大量任务，并在它们之间进行有意义的导航。这包括跨几个传感器模态的信息收集和通过认知控制实现高级目标。

还不完全清楚如何从这个角度关注人工智能中有用的想法。但是，如果我们将注意力视为减少和引导计算资源的通用工具，它已经在几个机器学习架构中得到了相当成功的使用。

最近，注意力在变形金刚的背景下吸引了深度学习社区的注意，论文“ [***【注意力是你所需要的一切】***](https://arxiv.org/pdf/1706.03762.pdf) ***”成为该领域最有影响力的论文之一，被引用超过 16000 次。***

变形金刚彻底改变了自然语言处理，并允许像 BERT ( *来自变形金刚的双向编码器表示)*这样的架构生成怪异的类似人类的文本。

不用太专业，文本生成是一个连续的任务，由编码器(输入的文本)和解码器(输出的文本)组成。因此，模型的输入和输出由序列组成。序列模型可能非常难以学习，因为输入可能会变得非常大，这需要模型潜在地学习输入中的长期依赖性(参见训练递归神经网络时的爆炸梯度问题，这是由长短期记忆网络部分解决的问题，它有自己的一组问题)。

正如[这篇博文](http://peterbloem.nl/blog/transformers)更详细描述的那样，变形金刚使用的注意力机制试图通过引入所谓的*自我注意力操作*来规避这个问题。该操作在序列的输入向量之间计算，并且可以在生成输出序列时使用。

自我关注是一种找出全局依赖的方式，也是一种划分输入序列的哪一部分属于一起的方式，并且反过来将与输出生成相关。 一个经常被引用的应用是不同语言之间的翻译(例如法语和英语之间的翻译，使用名副其实的 [CamemBERT model](https://github.com/huggingface/transformers) )，意思相同的单词可以在不同语言的句子的不同部分出现。

注意力也有助于避免输入序列过长的问题，因为模型不需要记住整个输入序列(比如当你必须翻译一个很长的句子时……看着你，[马赛尔·普鲁斯特](https://en.wikipedia.org/wiki/In_Search_of_Lost_Time))，但可以更灵活地对输入进行优先排序和批处理，就像人类翻译一样(更详细的解释请参见吴恩达的视频[)。](https://www.youtube.com/watch?v=SysgYptB198)

这有助于 ***有效地减少输入向量*** 的维度，因为模型隐式地选择序列的哪一部分将是相关的，并因此计算出要注意什么。这也很好地将上下文依赖引入到模型中，这对于我们人类理解文本(以及整个世界)是绝对重要的。

虽然这和大脑之间有一些相似之处，但是其中的一些联系在这里可能看起来有点牵强。

我们人类的智能如此令人印象深刻，因为[它在如此广泛的不同任务中发挥作用](https://www.youtube.com/watch?v=7R52wiUgxZI&)，而神经网络架构在很大程度上仍然高度专业化，很难适应它。因此，在多任务学习主体(例如机器人)的背景下，更类似于人类注意力的东西很可能会成为越来越重要的全球组织原则。

[对于新鲜有趣的想法](https://www.frontiersin.org/articles/10.3389/fncom.2020.00029/full#h5)仍然有很大的空间(例如通过[在大脑中自然语言处理的注意力上模拟变形金刚的注意力](https://arxiv.org/abs/1905.11833))，并很好地强调了为什么在未来的道路上，神经科学的概念可能会给机器学习注入一系列有用的新想法，以及为什么这两个学科应该保持密切联系。