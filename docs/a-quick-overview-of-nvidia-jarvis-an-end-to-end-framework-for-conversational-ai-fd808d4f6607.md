# NVIDIA Jarvis 快速概述——对话式人工智能的端到端框架

> 原文：<https://towardsdatascience.com/a-quick-overview-of-nvidia-jarvis-an-end-to-end-framework-for-conversational-ai-fd808d4f6607?source=collection_archive---------27----------------------->

## NVIDIA Jarvis 框架简化了训练和部署对话式 AI 系统的过程，使构建具有自动语音识别、文本到语音转换和自然语言理解功能的应用程序变得更加容易

![](img/403324df8bfc18ce0e5e7a231aed101b.png)

劳拉·穆西康斯基摄于[佩克斯](https://www.pexels.com/photo/white-robot-toy-on-brown-wooden-table-6019019/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)

# 介绍

在过去的几年里，人工智能技术的能力迅速提高。特别是自然语言处理(NLP ),由于 Transformer 体系结构及其衍生产品，已经取得了令人难以置信的进步。当前最先进的系统能够接近人类水平(或者在某些情况下超过人类水平！)在语言生成、文本分类、问答等多项语言任务中的表现。

类似地，当前的语音合成(文本到语音/TTS)模型可以生成与人类语音几乎没有区别的语音。另一方面，自动语音识别(ASR)通常在理解人类语音方面相当成功，即使考虑到嘈杂的背景和不同口音的说话者。可悲的是，我的手机仍然很难识别斯里兰卡的名字，但我真的不能责怪我的手机！然而，当我问路时，我可以相信它能认出我要去的地方的名字(是的，甚至在斯里兰卡！).

总的来说，组成对话式人工智能的不同组件(ASR、语言理解、语言生成和 TTS)已经发展到了这样一个阶段，即该技术不仅是可行的；这几乎是必须的。这可能是千禧一代的我在问，但我真的必须和某人交谈才能预约吗？🙄

特别是由于全球疫情，人类接触受到限制，更多自动化和更少繁琐任务的时机肯定已经成熟！

尽管这些技术取得了进步，但是在将它们用于现实世界时，仍然存在巨大的障碍。例如，训练深度学习模型，这是大多数对话式人工智能技术的基础，需要大量的计算和数据资源。虽然深度学习模型能够*做出令人印象深刻的壮举，但构建和训练实现这种潜力的模型通常需要大量的技术专业知识。除此之外，即使您已经训练了您的模型，将它们投入生产并维护它们是另一个挑战，通常需要完全不同的技术专长。*

NVIDIA Jarvis Framework 旨在解决所有这些问题，并作为构建对话式人工智能系统的端到端工具包。它为各种任务提供预训练模型，重新训练/微调这些模型的能力([转移学习工具包](https://developer.nvidia.com/transfer-learning-toolkit)和/或[尼莫](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/))，以及(自动)优化模型的轻松部署。

迁移学习，或在新任务/领域上微调预训练模型的能力，是深度学习模型(如 BERT)如此成功的重要原因。迁移学习工具包提供了一种方法，使用这种技术来为您的任务或领域调整预先训练的模型，并生成一个可以使用 Jarvis 直接部署的模型。令人印象深刻的是，您可以通过简单地编辑几个配置文件来完成所有这些，而无需编写任何实际的代码。对于那些想要开始使用对话式人工智能，但之前很少或没有训练和部署深度学习模型的经验的人来说，这应该特别有用。

我目前正在编写一份指南，使用 TLT 来微调一种新语言的 ASR 模型！ASR 对我来说是一个相对较新的领域，到目前为止这个过程如此顺利给我留下了深刻的印象。

接下来，让我们看看 Jarvis 框架支持的不同服务和任务。

# 贾维斯服务公司

Jarvis 目前支持的服务分为三类:

1.  语音识别— Jasper，Quartznet
2.  语音合成— TacoTron2，Waveglow
3.  自然语言理解—威震天，伯特

NLU 服务包括几个高级和低级 API。

## 高层

*   命名实体识别
*   意图分类—域分类器和意图/槽标记器(对查询的*意图*进行分类，并检测意图的相关*实体*和*槽*)
*   问题回答
*   标点符号和大写

## 低级的

*   文本分类
*   令牌分类

所有这些服务都可以通过执行[快速入门指南](https://docs.nvidia.com/deeplearning/jarvis/user-guide/docs/quick-start-guide.html)中给出的几个命令来轻松部署。最棒的是，服务是通过 Docker 部署的，所以你真正需要安装的只是 Docker(支持 NVIDIA GPUs)。

*您不一定需要部署所有可用的服务。如果您只需要特定的服务并保持较小的资源占用，您可以选择想要部署的服务。*

一旦部署完成，您就可以使用提供的 API([gRPC](https://grpc.io/)、Python 或命令行)与这些服务进行交互。这使得根据需要构建集成各种 Jarvis 服务的应用程序变得非常容易。

# 接下来呢？

默认情况下，Jarvis 使用预先训练好的模型，这意味着这些服务将开箱即用地适用于许多不同的用例。例如，您可以通过使用**语音识别服务**轻松构建一个基于语音的问题回答系统，以获取用户的查询(可能还有在其中寻找答案的文档的名称)，使用**问题回答服务**提取答案，并使用**语音合成服务**大声读出答案。

虽然预先训练的模型很可能适用于一般情况，但您可以根据感兴趣领域的数据对模型进行微调，以获得最佳性能。例如，如果问答模型预期用于法律案例文件、医疗保健中的患者记录或学术界的研究论文，则可以通过使用相关领域的数据对模型进行微调来获得更好的性能。使用迁移学习工具包框架可以很容易地对模型进行微调，它可以生成一个与 Jarvis 兼容的模型，以便于部署。

总的来说，Jarvis 为您提供了很大的灵活性来更新/微调预训练的模型，以便在定制域上执行得更好，并且仍然能够使用相同的一致管道轻松地部署微调的模型。用于与不同服务交互的 API 也是一致且易于使用的，这使得将 Jarvis 集成到您自己的应用程序中的过程非常简单。

# 包扎

Jarvis 框架使得为对话式人工智能的各个方面部署最先进的模型成为可能，而不必担心设置不同框架和服务*以及*让它们相互配合的(通常令人沮丧的)细节。您还可以根据需要自由地微调这些模型，并轻松地将更新的模型部署为 Jarvis 服务。

不同的 Jarvis 服务可以通过 API 单独访问，这使得构建具有高质量 ASR、NLU 和 TTS 功能的定制应用程序变得简单。

总而言之，Jarvis 框架支持对话式 AI 系统的整个生命周期，从训练/微调模型到将它们部署为优化的、生产就绪的服务。这对于那些不太熟悉人工智能和深度学习，但对将对话式人工智能元素融入他们的应用程序感兴趣的应用程序开发人员来说尤其有用。另一方面，熟悉 AI 的研究人员不一定想处理*部署*他们的模型的后勤工作，他们肯定会欣赏 Jarvis 模型和服务的简单部署过程。