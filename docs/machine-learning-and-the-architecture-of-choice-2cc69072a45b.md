# 机器学习和选择架构

> 原文：<https://towardsdatascience.com/machine-learning-and-the-architecture-of-choice-2cc69072a45b?source=collection_archive---------30----------------------->

## 行为经济学对评估机器学习如何让我们做出决策的贡献

![](img/b7c1b3f831cdedd1e731d1cec160044f.png)

照片由[布伦丹·丘奇](https://unsplash.com/@bdchu614?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)在 [Unsplash](https://unsplash.com/s/photos/one-way?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄

人工智能(AI)已经说服我们甚至不用质疑就能做出决定。当我们选择一部推荐的电影或去你家的最佳路线时，就会发生这种情况。这些是她能做什么的好例子。尽管如此，人工智能可以说服我们选择高利率贷款的金融交易。此外，即使你有很好的资历和经验，你也可能因为失业期间没有支付账单而失去工作机会。

也许你认为这是最好的选择，因为你相信机器是公正的，不会出错。这些决定是通过应用我们的数据做出的，这些数据被聚合到许多其他人的数据中，对我们进行分类。但问题是，人工智能是否真的向我们展示了可以用道德方式做出的最佳选择。这个关于人工智能滥用的问题是由[凯茜·奥尼尔](https://en.wikipedia.org/wiki/Cathy_O'Neil)在她的书中提出的，她用真实经历的例子进行了论证。

有了大数据，人工智能正在成为一个大规模的选择建筑师，让人们相信什么对他们是坏的或好的。选择架构是行为经济学的一个概念，由卡斯·桑斯坦和理查德·塞勒在他们的书中提出。他们提出的理论认为，决策过程受到选项显示方式的影响。当您交替使用这些选项来影响某些行为时，会发生轻推。这种交替基于自由家长主义，这意味着以更好的方式影响行为是可能的和合法的，同时也尊重选择的自由。但是，我们往往不知道用的是什么数据或者算法。

机器影响我们行为的能力取决于它说服我们的能力。根据[b . j . Fogg](https://en.wikipedia.org/wiki/B._J._Fogg)【3】的说法，说服性技术应用社会心理学原理来影响人们，即:

> 吸引力:对目标用户有视觉吸引力的计算技术也可能更有说服力。
> 
> 相似性:人们更容易被在某些方面与自己相似的计算技术产品所说服。
> 
> 赞美:通过文字、图像、符号或声音来提供赞美，计算机技术可以让用户更容易接受劝说。
> 
> 互惠:当计算技术帮了他们一个忙时，人们会觉得有必要回报。
> 
> 权威:承担权威角色的计算技术将增强说服力。

基于我们的数据，AI 有能力根据这些原则中的每一条来调整呈现给我们的内容。因此，对所有类型的人的行为进行个性化呈现，创造人工智能认为对我们最好的泡泡。因此，人工智能是一个强大的说服机器，能够影响尽可能多的人。

人工智能可能会在无意中以某种方式推动我们的社会现状。你可能认为 AI 是公平的，没有偏见的，然而，它从人类制造的数据中学习。有几次，[机器学习算法重复了人类制造的偏见和不公正](https://www.newscientist.com/article/2166207-discriminating-algorithms-5-times-ai-showed-prejudice/)。

根据 [Vincent C. Müller](https://en.wikipedia.org/wiki/Vincent_C._M%C3%BCller) 的说法，我们需要机器伦理，这意味着“对人类的行为应该是伦理上可接受的”[4]。什么会导致“人造道德代理人”的存在[5]，拥有权利和责任。基于这一原则，可以说人工智能的架构选择必须遵循伦理标准。

这篇文章的功能是开启一场关于人工智能选择建筑的伦理意义的讨论，这被证明是相当丰富的。

## 参考

[1]奥尼尔。数学毁灭武器:大数据如何增加不平等和威胁(2016)。[https://www . Amazon . com/Weapons-Math-Destruction-Increases-Inequality/DP/0553418815](https://www.amazon.com/Weapons-Math-Destruction-Increases-Inequality/dp/0553418815)

[2] C. Sunstein，R . Thaler,《推动:改善关于财富、财富和幸福的决定》( 2008 年)。[https://www . Amazon . com/Nudge-Improving-Decisions-Health-Happiness/DP/014311526 x/ref = Sr _ 1 _ 1？dchild=1 &关键字=推动% 3A+改善+决策+关于+财富% 2C+财富+和+幸福&qid = 1621540327&s =书籍& sr=1-1](https://www.amazon.com/Nudge-Improving-Decisions-Health-Happiness/dp/014311526X/ref=sr_1_1?dchild=1&keywords=Nudge%3A+Improving+Decisions+about+Wealth%2C+Wealth+and+Happiness&qid=1621540327&s=books&sr=1-1)

[3] B. J. Fogg,《说服技术:利用计算机改变我们的想法和行为》( 2002 年)。[https://www . Amazon . com/劝诱-技术-计算机-互动-技术/dp/1558606432/ref=sr_1_1？dchild=1 &关键词=说服+技术% 3A+使用+电脑+改变+什么+我们+想+做&qid = 1621540428&s =书籍& sr=1-1](https://www.amazon.com/Persuasive-Technology-Computers-Interactive-Technologies/dp/1558606432/ref=sr_1_1?dchild=1&keywords=Persuasive+Technology%3A+Using+Computers+to+Change+What+We+Think+and+Do&qid=1621540428&s=books&sr=1-1)

[4] M. Anderson，S. L. Anderson，《机器伦理:创造一个有道德的智能主体》(2007)。[https://ojs . aaai . org//index . PHP/aimagazine/article/view/2065/0](https://ojs.aaai.org//index.php/aimagazine/article/view/2065/0)

[5] V. C. Müller，《人工智能和机器人学的伦理学》，斯坦福哲学百科全书(2020)。[https://plato.stanford.edu/entries/ethics-ai/](https://plato.stanford.edu/entries/ethics-ai/)