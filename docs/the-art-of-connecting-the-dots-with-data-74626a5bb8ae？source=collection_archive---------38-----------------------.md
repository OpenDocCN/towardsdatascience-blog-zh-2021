# 用数据连接点的艺术

> 原文：<https://towardsdatascience.com/the-art-of-connecting-the-dots-with-data-74626a5bb8ae?source=collection_archive---------38----------------------->

## 我们每周精选的必读编辑精选和原创特写

“意外之喜”是一个描述小快乐的大词:当美好的事情就这样发生时的感觉，好像是偶然的。一些我们最喜欢的博客帖子给我们留下了类似的快乐感，意想不到的发现，尽管作家需要很高的技巧(和大量的工作)来建立联系，并以一种感觉毫不费力的方式让事情点击。

举个例子，Ofir Magdaci 漫不经心的观察到[如果足球是一种语言，它将是世界上使用最广泛的语言](/embedding-the-language-of-football-using-nlp-e52dc153afa6)。这让他开始了一个令人着迷的项目:试图将他的 NLP 专业知识和“美丽游戏”的语言结合起来，为体育分析领域未来的机器学习解决方案奠定基础。[迈克尔·布朗斯坦](https://medium.com/u/7b1129ddd572?source=post_page-----74626a5bb8ae--------------------------------)(和合著者)意识到在[将图形神经网络(GNNs)作为偏微分方程(PDEs)](/graph-neural-networks-as-neural-diffusion-pdes-8571b8c0c774) 来处理有很大的潜力，为“研究许多流行的图形深度学习架构以及开发新架构的蓝图”开辟了空间

![](img/f07e0931b51ed0ab89cab7ceae1e5a29.png)

约翰·巴克利普在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

更多的意外收获？我们中的大多数人，当我们试图插入 USB 连接器时，只是不停地翻转它，直到它卡入到位。另一方面，艾伦·唐尼对很少有人第一次就做对的事实感到震惊。这让他思考并写下了这个令人惊讶的联系(没有双关语的意思！也许吧？)在[这种日常挫折与……贝叶斯决策分析](/flipping-usb-connectors-5ac65ea9f355)之间。

我们一些最平凡的日常工作流程会突然变成顿悟和灵感的跳板。数据清理有时可能会感觉重复和单调，但对艾米丽·伯恩斯来说，这是一个系统思考所谓“坏数据”的起点，而 T2 创建了一个四步法来识别和纠正管道源头的错误。A/B 测试是许多数据科学家的饭碗；通过他在 Wix 的工作，“大规模”运行它们之后，[伊塔马尔·法兰](https://medium.com/u/153789513a7b?source=post_page-----74626a5bb8ae--------------------------------)成为贝叶斯 A/B 测试价值的信徒，并且[他慷慨地分享了支持它们的统计模型的概述](/how-to-do-bayesian-a-b-testing-fast-41ee00d55be8)。

寻找更多的点来连接？本周剩下的选择范围很广，但每一个都提供了一个可供探索的想法小宇宙:

*   [在 Parul Pandey](/reviewing-the-recently-released-huggingface-course-a6b4ace16167) 对图书馆创建者最近发布的课程的评论中，为那些在 NLP 工作的人发现拥抱脸生态系统及其许多用途。
*   我们已经深入到了骄傲月，但是用一组关于数据科学、偏见和 LGBTQIA+社区的交集的帖子来纪念这个时刻永远不会太晚(作者有 [Rhea Moutafis](https://medium.com/u/593908e0206?source=post_page-----74626a5bb8ae--------------------------------) 和 [Heather Krause](https://medium.com/u/7e89d86194d2?source=post_page-----74626a5bb8ae--------------------------------) ),由[本·胡伯尔曼](https://medium.com/u/e6ad8abedec9?source=post_page-----74626a5bb8ae--------------------------------)选出。
*   [了解企业机器学习的来龙去脉](/enterprise-ml-why-building-and-training-a-real-world-model-is-hard-59d09a430fae)在 [Ketan Doshi](https://medium.com/u/54f9ca55ed47?source=post_page-----74626a5bb8ae--------------------------------) 的温柔指导下，他的新系列从建立和训练模型的关键步骤开始。
*   如果你是函数数据领域的新手，一个非常好的起点是 [Johannes Wohlenberg](https://medium.com/u/8644189ad630?source=post_page-----74626a5bb8ae--------------------------------) 的实践教程[，该教程侧重于函数主成分分析](/functional-principal-component-analysis-and-functional-data-91d21261ab7f) (FPCA)。
*   最后，最近出现了一系列关于人工智能的不祥预测——该领域的进步可能最终加速人类的灭亡。在 TDS 播客上， [Jeremie Harris](https://medium.com/u/59564831d1eb?source=post_page-----74626a5bb8ae--------------------------------) 与艾伦人工智能研究所首席执行官[柳文欢·埃齐奥尼](https://medium.com/u/af9252b7f0b8?source=post_page-----74626a5bb8ae--------------------------------)聊天，他[更看好我们智胜未来霸主的机会](/the-case-against-worrying-about-existential-risk-from-ai-d4aaa77e812b)。

为又一周的学习、发现和社区机会干杯——感谢你的陪伴和对我们工作的支持。

直到下一个变量，
TDS 编辑器

## 我们策划主题的最新内容:

## 入门指南

*   [发现并可视化非线性关系](/finding-and-visualising-non-linear-relationships-4ecd63a43e7e)作者[康纳·奥沙利文](https://medium.com/u/4ae48256fb37?source=post_page-----74626a5bb8ae--------------------------------)
*   [为什么 Jupyter 笔记本没有那么糟糕](/why-jupyter-notebooks-arent-all-that-bad-d75e90d02c3a)作者[马腾·格罗腾·奥斯特](https://medium.com/u/22405c3b2875?source=post_page-----74626a5bb8ae--------------------------------)
*   [从预测到行动——如何从数据中学习最优政策(第一部分)](/from-prediction-to-action-how-to-learn-optimal-policies-from-data-part-1-1edbfdcb725d)作者[拉玛·拉玛克里希南](https://medium.com/u/28748480e8bd?source=post_page-----74626a5bb8ae--------------------------------)

## 实践教程

*   [匹配和倾向评分匹配终极指南](/an-ultimate-guide-to-matching-and-propensity-score-matching-644395c46616)作者[叶雷华博士研究员](https://medium.com/u/4e1d06dd743?source=post_page-----74626a5bb8ae--------------------------------)
*   [数据先于模型，但问题先公式化](/data-before-models-but-problem-formulation-first-b4c2a9a3e978)由[布莱恩·肯特](https://medium.com/u/fea25fff8539?source=post_page-----74626a5bb8ae--------------------------------)
*   [pytorch-widedeep，针对表格数据的深度学习 IV:深度学习 vs. LightGBM](/pytorch-widedeep-deep-learning-for-tabular-data-iv-deep-learning-vs-lightgbm-cadcbf571eaf) 作者 [Javier Rodriguez Zaurin](https://medium.com/u/4b8da97b9a0?source=post_page-----74626a5bb8ae--------------------------------)

## 深潜

*   [强化学习](/reinforcement-learning-fda8ff535bb6)由[克里斯·马奥尼](https://medium.com/u/56d03114dd5a?source=post_page-----74626a5bb8ae--------------------------------)
*   [互信息:预测为模仿](/mutual-information-prediction-as-imitation-da2cfb1e9bdd)作者[道格拉斯·汉密尔顿](https://medium.com/u/2ffa03b79ca7?source=post_page-----74626a5bb8ae--------------------------------)
*   [完美洗牌](/the-perfect-shuffle-aa388ad1ffd1)由[沈懿洪](https://medium.com/u/66204695b9a0?source=post_page-----74626a5bb8ae--------------------------------)

## 思想和理论

*   过多的伯特会对你有害吗？作者[费德里科·比安奇](https://medium.com/u/2aff872fe60e?source=post_page-----74626a5bb8ae--------------------------------)
*   [拓扑变化点检测](/topological-change-point-detection-162c6e11d3ca)由[蒂姆·约瑟兰](https://medium.com/u/713bf26ad5f2?source=post_page-----74626a5bb8ae--------------------------------)
*   [露西打招呼——2031 年，AGI，人工智能的未来](/lucy-says-hi-2031-agi-and-the-future-of-a-i-28b1e7b373f6)作者[哈维尔·伊达米](https://medium.com/u/7f7b5d730c84?source=post_page-----74626a5bb8ae--------------------------------)