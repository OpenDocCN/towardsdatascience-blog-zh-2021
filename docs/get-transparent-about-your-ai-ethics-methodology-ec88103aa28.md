# 让你的人工智能道德方法论透明化

> 原文：<https://towardsdatascience.com/get-transparent-about-your-ai-ethics-methodology-ec88103aa28?source=collection_archive---------42----------------------->

## 从道德实践的“为什么”到“如何”

![](img/f33411ce283ed7985178e9cd8097cf0f.png)

照片由 Anh Vy 在 Unsplash 上拍摄

所以你已经听说了人工智能伦理及其在构建符合社会价值观的人工智能系统中的重要性。你选择踏上将负责任的人工智能原则融入你的设计、开发和部署阶段的旅程，可能有许多原因。但是，我们之前在这里讨论过这些，你会在其他地方找到大量的文献来阐述为什么你应该这样做。

我想花点时间谈谈你应该怎么做。我想专注于其中的一个方面:你的人工智能伦理方法论的透明度。

> 我认为有一个非常强有力的理由来说明为什么我们需要对我们的人工智能道德方法论保持透明，特别是因为它将帮助你更好地定位自己，以在高度竞争的环境中吸引稀缺的人工智能人才，展示成熟度，提高客户信任，并降低反馈障碍。

因此，让我们深入到这些领域中的每一个，并了解你的人工智能道德过程透明的好处:你会做得更好，你将能够做得更多！

# 1.在有限人工智能人才的竞争中胜出

正如 ElementAI(现在是 ServiceNow 的一部分)的[全球人工智能人才报告](https://www.elementai.com/press-room/element-ai-founder-releases-2020-global-ai-talent-report)中多次提到的那样，人工智能人才继续向世界上的某些地区倾斜。即使在这些地区，人口也高度集中在少数几个地区，人口构成非常有限，导致了多样性问题。进一步加剧所有这些问题的是，那些不是最大的人工智能公司的有限能力，无法吸引和留住能够创造和提供功能良好、高性能人工智能系统的顶级人才。另一个需要考虑的方面是，我们目前对西方伦理方法论的关注要比对伦理框架的考虑更加全球化和多样化。

但是，这不应该成为绝望的理由！

越来越多的证据表明，技术专家正在认识到他们的工作对社会的影响，因此，它可以成为一个区分因素，让你展示你拥有人工智能道德方法论，即使它是新生的，因为它有助于求职者筛选出并专注于与他们的价值观一致的机会。

有时，组织选择保持他们的人工智能道德过程的私密性，通常是因为他们不确定它会被如何看待，以及他们是否会因为它的当前状态而受到惩罚。然而，它可以为求职者提供一个关于你正在做的工作的强烈的市场信号。你计划做的工作可能会帮助你的组织与更大的组织竞争类似的工作，但不同的是，你会思考如何以一种审慎的方式管理你的工作的社会影响。

因此，它可以帮助您用同样多的资源做更多的事情，并通过吸引关心这些问题的顶级人才来帮助您走得更远！

# 2.展示成熟

阻碍组织的事情之一(除了对法律后果的担忧之外)是他们对他们的过程缺乏信心，并且害怕他们可能被认为是不成熟的，尤其是在过程开发和利用的早期阶段。

使流程公开透明展示了组织的成熟度，也有助于您学习并与您所在行业的同行组织分享最佳实践。这是一项团队运动，我们不会有一个单独的组织能够独自找出所有的答案。对你的过程保持透明，并分享它在哪里工作，在哪里失败，将有助于整个生态系统更快地成熟，帮助你在负责任的人工智能工作中走得更远，更有效。

# 3.提高客户信任度

当客户四处寻找他们可以雇佣的不同公司为他们工作时，比如说引入外部专业知识来帮助将人工智能能力注入他们现有的产品中，有许多选项可供选择。[事实上，这些选择与日俱增](https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/global-survey-the-state-of-ai-in-2020)！

那么，当顾客在四处观望时，我们如何用我们的产品吸引他们呢？

这些客户中的一些人关心他们的工作对[社会的影响](https://www.mckinsey.com/~/media/McKinsey/Business%20Functions/Strategy%20and%20Corporate%20Finance/Our%20Insights/Five%20ways%20that%20ESG%20creates%20value/Five-ways-that-ESG-creates-value.pdf)，随着他们的用户和客户表现出更强的意识并使用他们的钱来支持他们的信念，越来越多的组织开始关注这一点。

通过对你的人工智能道德方法论保持透明，你向正在寻找合作伙伴的客户发出了一个明确的信号，即你不仅在名义上关心这些想法，而且已经给予足够的思考来将这些想法付诸实践。在过去的几年里，我们已经看到了很多很多的文档出现[谈论原则](http://lcfi.ac.uk/media/uploads/files/AIES-19_paper_188_Whittlestone_Nyrup_Alexandrova_Cave.pdf)，但是很少关注实施策略，这是生态系统中的参与者注意到并呼吁的事情。

***事实上，我即将出版的新书《*** [***可操作的人工智能伦理***](https://actionableaiethics.substack.com/) ***》正在帮助人工智能从业者弥合这一鸿沟！***

你可以具体地提升客户的信任，这将对你的组织的底线产生直接影响，并利用这一点作为在你的组织中吸收和组织人工智能道德努力的号角。这是一种很好的方式来提高你的工作的影响(从社会的角度来看)，并帮助你建立长期的可持续性，因为你的客户信任你做正确的事情，他们可以通过你实施的人工智能道德流程来验证这一点。

# 4.降低反馈障碍

当你的过程透明时，征求和接受反馈就变得更加容易。

征求反馈变得更加容易，因为人们可以在你的流程中提出他们的反馈，他们可以评估这是否有效。这也清楚地表明，你有反馈渠道，表明你对你的过程有信心，并致力于随着时间的推移改善它。对于那些希望提供反馈的人，他们知道在哪里可以这样做，这是建立用户和客户信任的另一个途径。

正如我们从上面的讨论中看到的，让你的人工智能道德方法论透明化有很多好处:

*   在有限人工智能人才的竞争中胜出
*   展示成熟
*   提高客户信任度
*   降低反馈障碍

我强烈建议你走这条路，把你的人工智能道德反馈透明化！我总是乐于与你进行简短的交谈，就你的过程向你提供建议，并从什么有效和什么无效中学习。不要犹豫，通过蒙特利尔人工智能伦理研究所联系我。

我很乐意听到更多关于你正在做什么来将你的组织的人工智能道德方法论公开化，以及如果这些点是你已经付诸实践的事情。

# 在这里注册以获得关于[可操作的人工智能伦理书](https://actionableaiethics.substack.com/)的更新！你可以在这里了解更多关于我的作品[！](https://atg-abhishek.github.io/)

# 你可以通过订阅[人工智能伦理简报](https://brief.montrealethics.ai/)从[蒙特利尔人工智能伦理研究所](https://montrealethics.ai/)了解更多这样的见解！