# AI 有政治吗？

> 原文：<https://towardsdatascience.com/does-ai-have-politics-21145e5b5445?source=collection_archive---------8----------------------->

## [人工智能校准和安全](https://towardsdatascience.com/tagged/ai-alignment-and-safety)

## 兰登·温纳 1980 年对*的分析《人工智能有政治*》反思当前的人工智能创新

![](img/4d16fa5454b5be86d44d920f55786367.png)

[刘宇英](https://unsplash.com/@yuyeunglau?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

兰登·温纳 1980 年论文*文物有政治吗？* (Winner n.d. 1980)是一篇开创性的技术伦理文章，作者在其中提出，技术人工制品可能对某些政治结构有偏见，即威权主义和民主。作者触及了两个主要话题，“作为秩序形式的技术安排”和“固有的政治技术”。本文将探讨这些话题以及它们与当前人工智能创新的关系。

# “作为订单形式的技术安排”

Winner 以对服务于一个目的的技术对象的讨论开始，但也可能有政治倾向。作者举了几个存在这些政治偏见的例子，包括开发商罗伯特·摩斯在长岛建造的立交桥，其设计方式使公共汽车无法从下面通过，使经常使用这种交通工具的贫困阶层无法进入他的公园。另一个例子是 McCormick 气动成型机，用于几个制造过程的自动化。这些设备取代了 McCormick reaper 制造厂的许多工作，用一些非熟练工人代替了熟练的模具工人来操作机器。引进这种机器的理由是为了提高生产率。然而，真正的原因是为了解散默尔德斯钢铁全国联盟，该组织与麦考密克有纠纷。

作者在这里提出了一个有趣的问题，即某些技术是否“可以被用来增强一些人对另一些人的权力、权威和特权”。他描述了罗伯特·摩斯的桥和麦考密克的机器是如何被创造出来帮助完成某项任务的(分别是公路运输和成型)，然而两者“包含的目的远远超出了它们最初的用途”(1980 年第 125 页)

## 许多人工智能系统有可能落入类似的类别。

![](img/05f4ddc71cdcab5d8ed20cf5930376af.png)

克里斯·利维拉尼在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

尽管大多数人工智能技术是为了进步和改善我们的生活而开发的，但当我们考虑如何使用这些技术时，风险就出现了。以从可穿戴设备收集用户健康数据的**为例。如果这些数据被用于让佩戴者获得他们健康的准确模型，这将对一个人的健康产生深远的积极影响。然而，如果数据超出了其预期的原始用途，并被出售给第三方以制作个人性质的定向广告，则可能会出现严重的隐私问题，甚至是用户心理健康问题。因此，人工智能和数据收集的良性用例必须保持这种方式——围绕数据用例引入法律，特别是针对基于敏感用户数据的广告，可以有助于加强这一点。**

# “固有政治技术”

温纳描述人工制品如何具有政治属性的第二种方式是“固有的政治技术，似乎需要或强烈兼容特定类型的政治关系的人造系统。”(Winner n.d. 1980，p123)在这里，作者给出了核能的例子，指的是这样一种危险的技术需要一个严格的军国主义政府来管理和执行严格的监管。另一个例子是原子弹，如果没有一个科学先进、有军方支持的政府的存在和支持，这项技术甚至不会存在。

## 我们在哪些方面可以与现代人工智能系统的发展相提并论？

![](img/fc6056ce999344ba0ffa66180619d591.png)

由 [Enrique Alarcon](https://unsplash.com/@qikealarcon?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

存在天生专制的人工智能系统吗？一个明显的例子是中国在全国范围内大规模采用和部署面部识别系统。这种大规模监控系统显然是为了维护威权国家的秩序，但这有可能永远是这种特定技术的最终用例吗？面部识别系统于 1993 年由 DARPA 首次用于生产环境，作为 FERET 计划的一部分(Rauss 等人，1997 年)。由于人脸识别领域的许多技术进步都是由美国军事工业开创的，因此这种系统的使用可能永远是为了执行命令。这种系统可能本来就是为专制国家设计的，对其中一些国家来说，使用面部识别进行种族定性并非偶然，而是受到积极鼓励的。(‘记者论中国对待维吾尔族穆斯林:“这是绝对的奥威尔式的监视’”2021。)

## 结论

令人惊讶的是，获奖者的论文在今天仍然如此切合实际，这说明它在 1980 年是多么精心制作。在最后一段中，在将人工智能和数据收集融入当今社会的背景下，我们发现了一个非常准确的观察结果:

> “在我们这个时代，人们常常愿意对他们的生活方式做出剧烈的改变，以适应技术创新，同时他们会抵制基于政治理由的类似的改变”(Winner n.d. 1980，p135)。

毫无疑问，随着更新的人工智能创新在未来不可避免地出现，保持道德警惕将是重要的。

## *参考文献*

Rauss，P.J .，Phillips，j .，Hamilton，M.K .，DePersia，a . t .(1997)“FERET(人脸识别技术)程序”，第 25 届 AIPR 研讨会:计算机视觉的新兴应用，2962，253–263。

中国对待维吾尔穆斯林的记者:“这是绝对的奥威尔式监控”(在线)(2021 年)可用:[https://www . CBS news . com/news/China-puts-维吾尔人-uyghyrsmuslim-儿童-监狱-再教育-拘留-营地-vice-news/](https://www.cbsnews.com/news/china-puts-uighurs-uyghyrsmuslim-children-in-prison-re-education-internment-camps-vice-news/)[2021 年 6 月 14 日访问]。

“艺术品有政治吗？”(1980), 17.

*这篇文章是我在爱尔兰利默里克大学(University of Limerick)攻读人工智能非全日制硕士学位期间，撰写的人工智能风险、伦理和治理课程的一部分。*

如果你喜欢这个故事，请考虑在[媒体](https://mark-garvey.medium.com/)上关注我。你可以在 https://mark-garvey.com/找到更多信息