# Apache Spark Monitoring:如何使用 Spark API 和开源库来获得应用程序更好的数据可观察性

> 原文：<https://towardsdatascience.com/apache-spark-monitoring-how-to-use-spark-api-open-source-libraries-to-get-better-data-9f48074a4fc9?source=collection_archive---------27----------------------->

![](img/88ff9d9e69ebbdd0fffac53274e1216f.png)

Arie Wubben 在 [Unsplash](https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄的照片

## 了解如何使用监听器 API 和数据质量库为 Apache Spark 获得不同级别的数据可观察性。

Spark 对于[现代数据堆栈](https://databand.ai/blog/modern-data-stack/)至关重要。因此，对于您的 Spark 环境来说，拥有正确的可观察性水平是极其重要的。监控 Spark 有很多选项，包括为 Spark 和 Spark SQL 指标提供预配置仪表板的 SaaS 程序。如果这还不够呢？

典型的 Spark 应用程序设置，无论是自托管还是托管解决方案，都包括一些用于集群健康监控的操作仪表板。尽管这些控制面板非常有用，但它们只为我们带来了基础架构概述，而不是与数据相关的实际指标。是的，当 CPU 使用率增加或集群内存不足时，我们可以假设应用程序可能有问题，但当[源改变了模式](https://databand.ai/blog/end-to-end-data-observability-goes-beyond-your-warehouse/)或来自另一个部门的数据被破坏时，这没有帮助。工程师面临的大多数问题都是由数据引起的，而不是由底层基础设施引起的，因此他们不得不花费大量时间重现问题或者像侦探一样摆弄文件和桶。这正是实际应用程序监控可以提供帮助的地方。

每种情况都需要不同级别的可见性，数据工程师需要具备比执行指标更深入的能力。否则，您可能会花费大量时间在 Spark 中调试数据质量问题。

在本指南中，您将了解如何为 Spark 获得高级和低级的[数据可观察性](https://databand.ai/blog/a-data-observability-model-for-data-engineers/)。对于高层，您将使用 Spark 的内部系统，如监听器 API 和查询执行监听器。对于底层，您将学习如何使用库来跟踪[数据质量度量](https://databand.ai/blog/what-is-good-data-quality-for-data-engineers/)。

学会这两种方法后，你可以选择哪一种最适合你要解决的问题。

# 监视 Apache Spark 的低级方法

## 火花监听器

这是一种非常古老且可靠的获取指标的方法。实际上， [Spark UI](https://spark.apache.org/docs/latest/web-ui.html) 利用完全相同的机制来可视化指标。Spark 监听器 API 允许开发人员跟踪 Spark 在应用程序执行期间发出的事件。这些事件通常是应用程序开始/结束、作业开始/结束、阶段开始/结束等。你可以在 [Spark JavaDoc](https://spark.apache.org/docs/2.4.8/api/java/org/apache/spark/scheduler/SparkListener.html) 中找到完整的列表。它很容易配置，也很容易使用 Spark 监听器来获取指标。在执行每个操作之后，Spark 将调用 Spark Listener 并将一些元数据信息传递给它的方法。这将包括像执行时间，记录读/写，字节读/写和其他。

这种非常基本和低级的数据质量监控将检查记录的数量和大小。假设您有一些每天都在运行的作业，并对传入的数据集执行一些转换/分析。您可以编写一个侦听器来检查从输入中读取了多少记录，并将其与前一天的结果进行比较。当[差异显著](https://databand.ai/blog/anomaly-detection-to-meet-data-delivery-deadlines/)时，我们可以假设数据源可能有问题。

然而，这种方法需要编写内部监控解决方案。度量值应该存储在某个地方，应该配置警报机制。当应用程序代码将改变时，所有的度量键也将改变，人们应该正确地处理它。

然而，即使是一个简单的 Spark 监听器也可以对您的数据提供一些见解。

这里有一个这样的火花监听器的例子:

您可以通过几种方式将 Spark 监听器添加到您的应用程序中:

以编程方式添加它:

或者通过 spark-submit/spark cluster 驱动程序选项传递它:

# Spark 查询执行监听器

这是另一种开箱即用的火花监测机制。查询执行监听器允许开发人员订阅查询完成事件，而不是关注非常低级的指标。它提供了关于执行的查询的更高层次的元数据，如逻辑和物理计划，以及执行度量。

您可以获得像查询读/写的记录这样的指标，但是这次是针对整个查询而不是特定的任务/作业/阶段进行聚合的。

还可以从计划中提取非常有用的信息，如数据位置和模式。您可以提取和存储模式以及数据帧维度，并将其与之前的运行进行比较，在出现问题时触发警报。

然而，从计划中提取数据可能很复杂，因为您被迫使用低级别的 Spark API。

此外，实施指标存储和警报机制的所有运营负担仍然存在。你从 Spark 中得到的只是元数据。开发人员有责任利用它。

下面是一个简单的查询执行监听器示例，它打印计划和度量:

查询执行侦听器可以通过编程方式或配置方式添加:

通过 spark-提交:

实现低级别的监控可能是非常繁重的工作，然而，“系统”监控方式有一个巨大的好处:它不会引入[计算开销](https://databand.ai/blog/building-data-pipelines/)。因为元数据是由 Spark 内部发出和记录的，所以它不会对查询执行时间造成任何损失。

使用监听器进行监控可以让您完全避免接触应用程序代码！当您想要跟踪现有和遗留应用程序上的数据，但没有预算进行更改时，这将带来巨大的好处。只需编写一个侦听器，通过 spark 配置传递它，并获得您的数据的图片。

# 监视 Apache Spark 的高级方法

# 人工数据质量检查

通过手动验证，您可以大大增强对传入数据的信心。假设我们期望输入数据源中有一定数量的记录，并且该数量通常不应该低于 x。我们可以写一些非常简单的东西，比如:

这里的可能性是无限的。我们可以比较计数、非空值计数、推断模式等。

# 使用数据质量库

由于许多质量检查或多或少都是琐碎的，比如确保数据帧具有正确的形状和内容，社区为此类检查开发了方便的库。其中一个图书馆是 [Deequ](https://github.com/awslabs/deequ) 。它为大多数情况提供了丰富的领域特定语言(DSL)。看看这个。此外，它还具有一些高级功能，如分析列的能力——计算最小值/最大值/平均值/百分位数、计算直方图、检测异常等等。

考虑 Deequ 文档中的以下示例:

你可以看到我们有一大堆的支票包装在一个漂亮的随时可用的 DSL 中。

更重要的是，Deequ 提供了存储检查结果和自动运行与以前运行的比较的能力。这可以通过利用[度量库](https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/examples/metrics_repository_example.md)来完成。用户可以编写自己的实现，并将 Deequ 无缝集成到现有的监控基础设施中。

虽然高级别的应用程序质量检查比低级别的方法灵活得多，但是它们也有一个很大的缺点:性能损失。由于每个计算都会产生火花操作，因此在某些情况下，开销会非常大，尤其是在大型数据集上。每个“计数”和“位置”都可以导致全面扫描。Spark 内部将尽力优化执行计划，但您应该考虑这些影响，并确保数据分析不会损害您的性能。

# 结论

我们已经回顾了几种监测 Spark 应用程序数据质量的方法。低级方法利用 Spark 事件监听器 API，并提供对低级指标(如记录读/写、逻辑/物理计划)的访问，可用于构建趋势，确保数据管道产生正确的结果，并在不修改任何代码的情况下获得现有应用的概览。像手工检查数据或使用数据质量库这样的高级方法要方便得多，但是也有一些缺点，比如性能损失。

正如在任何实际情况中一样，根据您的应用程序类型，这两种方法总会有折衷和更好的方案。明智地使用它。

在 [Databand](https://databand.ai) ，我们利用这两种方式提供一套全面的选项来跟踪 Spark 应用。虽然在我们的核心中，我们使用 Spark 监听器来构建指标趋势和数据谱系，但我们也为 Deequ 提供了方便的指标存储，以及跟踪单个手动计算的指标的能力。