# 人工智能不会很快掌握人类语言

> 原文：<https://towardsdatascience.com/ai-wont-master-human-language-anytime-soon-3e7e3561f943?source=collection_archive---------17----------------------->

## 人工智能|哲学

## 有一个障碍，除非它彻底改变，否则人工智能无法通过。

![](img/cb1ac50a966a75749ece64f0f73084ea.png)

阿玛多·洛雷罗在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

近年来，我们目睹了人工智能语言模型的爆炸式增长。这些系统的最终目标是能够在人类水平上生成、交流和理解语言。

去年，OpenAI 的 GPT-3 以其无与伦比的能力震惊了世界。有人甚至说它是“[智能](https://twitter.com/rauchg/status/1282449154107600897?s=20)”，能够“[理解](https://www.lesswrong.com/posts/L5JSMZQvkBAx9MD5A/to-what-extent-is-gpt-3-capable-of-reasoning#eq6FTwG2yWuBdPofs)”，甚至“[有情](https://twitter.com/sonyasupposedly/status/1284188369631629312?s=20)”今年，谷歌在年度 I/O 大会上展示了两种超级强大的语言模型。LaMDA 和 MUM，正如它们的名字一样，可以进行类似人类的对话，并分别处理复杂的搜索查询。

然而，尽管围绕这些人工智能系统产生了所有的大惊小怪，但在他们掌握语言的道路上，有一个明确定义的障碍无法通过。GPT-3、LaMDA、MUM 或他们的继承人都不会成功。

在这篇文章中，我将回顾这些系统能做什么和不能做什么，它们不能突破的障碍是什么，以及为什么唯一的选择是转移占主导地位的人工智能范式。

# 最先进的语言模型:GPT-3，LaMDA 和 MUM

## GPT-3:open ai 研究的巅峰

GPT 模型是实现这一假设的阶梯:有可能创建一个无监督训练的元学习语言模型。凭借其元学习能力，它可以通过向它展示几个上下文相关的例子，来学习从未接受过训练的不同任务。

2020 年 5 月展示的 GPT 3 号就是这种可能性的活生生的证明。自从 OpenAI 发布了测试版 API 供人们玩这个系统以来，我们已经看到了如此疯狂的例子，以至于我想知道 GPT-3 是否真的有知觉。它可以创作诗歌和歌曲，在对话中扮演历史人物，根据描述编写代码或思考未来。

为了深入了解 GPT-3，我建议你阅读这篇长篇文章:GPT-3 是什么，它是如何工作的，疯狂的结果，疯狂的炒作，潜在的危险，以及它受到的批评:

</gpt-3-a-complete-overview-190232eb25fd> [## GPT-3 —全面概述

towardsdatascience.com](/gpt-3-a-complete-overview-190232eb25fd) 

## LaMDA:聊天机器人的革命

谷歌展示了一个经过对话训练的人工智能系统如何导航人类对话的细微差别。LaMDA 是新一代聊天机器人的第一个例子，它可以跟上典型的谈话突然转向和变化，这是其他人工智能无法做到的。

在一次能力展示中，它扮演了冥王星和一架纸飞机，并回答了谷歌开发人员的问题。它表现出了理智(它的回答非常有道理)、特异性(它没有给出笼统、平淡的回答)，保持了趣味性，而且它的回答是真实的(这是 GPT 三号做不到的)。

如果你想更多地了解 LaMDA，我推荐你阅读这篇关于它做什么和如何工作的文章。现在还没有太多可用的信息，但我确信当谷歌开放这个系统让我们测试它的极限时，人们会疯狂的。

</googles-lamda-the-next-generation-of-chatbots-62294be58426> [## 谷歌的 LaMDA:下一代聊天机器人

towardsdatascience.com](/googles-lamda-the-next-generation-of-chatbots-62294be58426) 

## 妈妈:搜索引擎的大脑

谷歌从一开始就试图让它的搜索引擎更像人类。妈妈是他们努力的结果。该系统可以接受诸如“我爬上了亚当斯山。现在我想去爬富士山。我应该做些什么不同的准备？”找到关键信息，编辑它，给出一个合理而简洁的答案。

它是多语言的(接受了 75 种语言的训练)，它是多任务的(它可以搜索和编译关键信息，回答问题，翻译语言，生成它……)，它是多模态的(它可以结合图像和文本，这是一种超越类似人工智能系统的能力)。

我在下面写了一篇关于 MUM 的能力以及它如何对 SEO 构成威胁的文章。同样，谷歌还没有透露太多关于这个系统的信息，但是当它在他们的搜索引擎中实现时，我们会看到它的威力。

</will-googles-mum-kill-seo-d283927f0fde> [## 谷歌妈妈会扼杀 SEO 吗？

towardsdatascience.com](/will-googles-mum-kill-seo-d283927f0fde) 

# 语言模型缺乏理解

这些超级强大的人工智能已经达到了一定程度的人类语言能力。他们精通语法和语义。他们已经掌握了语言的形式和结构。如果你和他们说话，很多时候你都分不清他们是人工智能还是人类。不可否认，他们擅长自己的工作。然而，与一些人声称的相反，他们缺乏对他们在人类意义上所说的话的理解。

理解来自于把形式和意义联系起来。如果我说:“我今天早上吃了一个苹果”，你很清楚那是什么意思。你知道，吃是我们饥饿时的一个动作，也是我们生存的必要条件。你知道苹果是一种水果，尝起来很甜，如果我向你扔苹果，会很疼。你知道，我可能在吃早餐，也可能喝了点咖啡。

一个 AI 系统从来没有吃过任何东西，从来没有摸过或闻过苹果，不理解早上喝一杯好喝的咖啡的感觉。它可能会说“我今天早上吃了一个苹果”，但它缺乏对这些话的真实体验和主观理解。

然而，即使人工智能不能理解吃苹果的感觉，他们仍然可以精确而敏感地使用这个句子。那不是语言掌握吗？不完全是。我将通过稍微调整一下这个例子来说明为什么，看看这个概念是如何被打破的。

现在让我们想象一下，我说:“今天早上我吃了一个苹果。我去店里，拿了，吃了，就走了。”这是一个非常相似的例子，所以我们可以假设人工智能仍然可以使用这个句子。然而，其中隐藏着只有人类才能理解的东西，因为我们有一个真正的理解:我偷了苹果！这些信息不在单词本身，而是在我们生活的更广阔的背景中；这是实用信息。

# 不可逾越的障碍:语用学

[语用学](https://en.wikipedia.org/wiki/Pragmatics)是语言学的一个分支，研究语境如何影响意义。19 世纪重要的实用主义者乔治·赫伯特·米德认为，交流不仅仅是我们使用的语言；“它涉及到人们交流时做出的非常重要的社会标志。”

这里有一个来自[美国演讲-语言-听力协会](https://www.asha.org/public/speech/development/Social-Communication/)的例子，我们可以完全理解，但人工智能系统不能:

> “你邀请你的朋友过来吃饭。你的孩子看到你的朋友伸手去拿饼干，说:“最好不要拿，否则你会变得更大。”你不能相信你的孩子会如此粗鲁。"

从语义上来说，这个孩子是在说吃饼干会使人发胖。然而，如果我们考虑到语用层面(在这种情况下的社会背景)，孩子实际上是在叫朋友胖，这是一件应该受到谴责的事情。人工智能系统会错过这种交互背后的意义的关键部分。它不能推断这句话的社会意义，因为它不能理解称某人为胖子的含义。

让我们看看美国语言学会的另一个例子:

> 考虑两个人，帕特和克里斯，他们在第一次约会时就互相认识了。如果克里斯在晚会结束时对帕特说，“我非常喜欢你。”帕特可能会对这种情况感觉良好。但是想象一下，帕特和克里斯已经约会几个星期了，帕特问:“你爱我吗？”现在，如果克里斯说，“我非常喜欢你，”反应可能会非常不同，因为克里斯的声明被视为一个否定的答案！

这两个句子是一样的。然而，更广泛的上下文从根本上改变了这个短语的实际含义。它改变了很多，一个是积极的，另一个是消极的。人工智能看不出这两种情况的区别。

现在，一个生活在计算机内部的人工智能系统如何访问上下文信息呢？关键问题是人工智能被输入单词，而单词不包含语用信息。我们从他们那里推断出来。语用学存在于人们共享的关于世界如何运转的常识中。人们能够表达的比语言所能表达的更多，因为我们生活在一个共享的现实中。但是人工智能不会和我们分享这个事实。这才是我们应该改变的。

# 人工智能系统如何掌握语言

在过去的十年里，基于神经网络的人工智能占据了主导地位。人们认为更多的数据、更大的网络和更多的训练最终会产生人工智能。深度学习是遵循这一思想的前沿框架，它占据着强大的统治地位，似乎没有失去动力。GPT-3、LaMDA 和 MUM 是最近的例子，但是在这个范例中有无数成功的系统。

然而，这种方法受到了一些重要的批评。哲学家休伯特·德雷福斯是 20 世纪的主要批评家之一，[反对当前的人工智能方法，他说大多数人类专业知识都是以隐性知识的形式出现的——经验和直觉知识，不能直接传播或编纂，因此虚拟人工智能无法获得。语言专业知识也不例外，而且正是语用层面经常与隐性知识交织在一起。](https://www.goodreads.com/book/show/1039575.What_Computers_Can_t_Do)

Dreyfus 声称脱离实体的机器将永远无法获得智能和理解，因为要获得它们，它们必须走进世界并与之互动。通过体验世界，我们可以发展我们的隐性知识，我们可以掌握隐藏在语言中的语用信息。人工智能的意志需要具体化，并生活在与我们相同的现实中，像我们一样与它互动，以实现语言掌握。

用卑尔根大学教授 [Ragnar Fjelland](https://www.nature.com/articles/s41599-020-0494-4) 的话说:“只要计算机不成长，不属于一种文化，不在世界上行动，它们就永远不会获得类似人类的智能。”获得类似人类的语言能力也是如此。但这似乎不会很快发生。

# 总结

近年来，我们已经看到了人工智能在自然语言处理系统方面的巨大成功，比如 GPT-3。这些语言系统似乎在人类水平上执行语言任务。他们的潜力是无可否认的。他们很强大，而且会变得更加强大。

然而，他们无法真正理解自己所说的话。他们将无法独立于他们拥有的参数数量和他们接受训练的数据量而达到语言精通。

原因是他们无法获取语境信息——语言的语用维度——人类对话发生的语境信息。他们忽略了语言之外的意义。人工智能并不生活在这个世界上。他们不认同我们的现实。这也是为什么它们在可预见的未来不会发展出类似人类的语言能力。