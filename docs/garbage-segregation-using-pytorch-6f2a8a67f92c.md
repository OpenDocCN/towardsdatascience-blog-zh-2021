# 使用 PyTorch 进行垃圾分类

> 原文：<https://towardsdatascience.com/garbage-segregation-using-pytorch-6f2a8a67f92c?source=collection_archive---------35----------------------->

## PyTorch 中卷积神经网络的 RESNET 方法

人类每天产生数百万吨垃圾。众所周知，这些垃圾在被带出家门之前需要被分类。这个过程对于社区的运作和地球母亲的维系是必不可少的，但却是乏味的！

![](img/c9f3c88925ca0a903bc9d382bf669add.png)

分离你的想法|照片由[paweczerwi ski](https://unsplash.com/@pawel_czerwinski)在 [Unsplash](http://unsplash.com/) 拍摄

我们都曾在某个时候想象过有一个机器人私人助理来为我们做所有的家务，包括垃圾分类。我是说，我们在骗谁呢？我们不喜欢手里拿着一个汽水罐，盯着 6 个垃圾桶，想知道它去了哪里。这个梦想不是遥不可及的想法，而是由于深度学习的进步而成为现实。

今天我们将使用 PyTorch 构建一个这样的图像分类模型。PyTorch 是一个 Python 库，具有各种各样的函数和操作，主要用于深度学习。我们将通过使用属于 6 个不同垃圾箱的 2527 个图像的 Kaggle 数据集来训练这个模型。那些是-

1.  不真实的
2.  玻璃
3.  金属
4.  纸
5.  塑料的
6.  废物

数据集从 [Kaggle](https://www.kaggle.com/asdasdasasdas/garbage-classification) 获得。

我们将使用`opendatasets`库来下载数据集。

在下载数据集时，您将被要求提供您的 Kaggle 用户名和凭证，您可以使用 Kaggle 上您的帐户页面上的“创建新的 API 令牌”按钮来获得这些信息。使用“文件”选项卡上传`kaggle.json`笔记本，或在出现提示时手动输入用户名和密钥。

现在我们将导入必要的库。

# 探索数据

我们已经下载了数据。现在我们来看一下图像，看看数据是如何存储的。

正如我们所看到的，我们将图像分为以上 6 个不同的类别，或者在我们的例子中，是垃圾箱。

# 应用转换

在我们将这些图像用于我们的模型之前，我们必须应用一些变换。其中之一是将图像转换成张量。张量是数字、向量、矩阵或任何 n 维数组。当我们将图像转换成张量时，PyTorch 能够对其应用不同的函数和变换。在我们将图像转换为张量之前，我们将调整它们的大小或缩小为 64 * 64 像素的图像。这是为了减少训练时间，不让我们的 GPU 超负荷运转。可以使用`transforms.Compose` 链接变换，如下所示

## 检查图像

在定义我们的模型之前，让我们看一下我们正在处理的数据。我们将定义一个助手函数，它将显示图像和与之对应的标签。我们将使用 matplotlib，这是一个用于数据可视化的 python 库。

如我们所见，我们正在处理存储在单个数据集中的 64 * 64 像素图像。让我们检查数据集包含多少样本

## 分割数据集

我们分离垃圾的下一步是将数据集分成:

1.  训练数据集-模型将在其上进行训练。
2.  测试数据集—出于预测目的随机选择的数据集部分。

理想情况下，还会创建一个验证数据集来检查模型的准确性，但由于我们的图像数量有限，我们将使用测试数据集作为验证数据集来提高模型的准确性。

我们使用了 random_split 函数，它将数据集随机分成几部分。

## 创建数据加载器

现在我们将创建数据加载器。这些数据加载器将数据批量加载到我们的模型中。

通过这样做，数据将以 18 幅图像为一批输入到模型中。为了可视化一批数据，我们可以如下创建一个助手函数。

正如我们看到的，一批包含随机选择的图像。

## 使用 GPU

GPU 使用 CUDA 核心来加速我们的训练过程。因此，最好将我们的数据和模型转移到 GPU。我们将为此创建助手函数。

这里我们定义了几个函数来检查 GPU 是否可用。如果 GPU 可用，数据将传输到 GPU 以进行更快的处理。数据加载器和模型也被移到 GPU 中。

我们现在可以使用 DeviceDataLoader 来包装我们的训练和验证数据加载器，以便自动将数据批量传输到 GPU(如果可用的话)。

## 定义模型

现在是时候定义我们的模型了。我们将扩展包含训练函数的 **nn.module** 类。我们将在 **ImageClassificationBase** 类中定义可用于任何图像分类类的函数。

*   **精度**功能将帮助我们计算每个历元后模型的精度。
*   **training_step** 将在训练数据集上批量训练我们的模型，并计算损失。
*   **validation_step** 将通过在验证数据集上应用我们的模型来计算验证损失。
*   **validation_epoch_end** 和 **epoch_end** 用于显示每个历元后的损失和精度。

## 创建一个 RESNET CNN

我们现在已经定义了基类，它包含了训练模型所必需的函数。我们仍然没有定义我们的模型架构。

我们将使用的模型被称为卷积神经网络。它不是对张量的每个元素都应用权重，而是从一个核开始，它只是一个权重的小矩阵。这个内核在 2D 输入数据上“滑动”,对它当前所在的输入部分执行元素级乘法，然后将结果相加到单个输出像素中。[ [来源](/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)

![](img/746ad250ddc3ad38944d6908b1f2242d.png)

来源:[https://towards data science . com/直观理解-卷积用于深度学习-1f6f42faee1](/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)

使用卷积神经网络的优势是—

*   **更少的参数**:使用一小组参数(内核)来计算整个图像的输出，因此与完全连接的层相比，该模型的参数要少得多。
*   **连接的稀疏性**:在每一层中，每个输出元素只依赖于少量的输入元素，这使得向前和向后的传递更加高效。
*   **参数共享和空间不变性**:由图像的一部分中的内核学习的特征可以用于检测另一图像的不同部分中的类似模式。

对于我们的卷积模型，我们还将添加一个**残差块**。该块将原始输入添加回通过将输入传递通过一个或多个卷积层而获得的输出特征图。我们不能改变残差块中的输出通道，因为那样的话输入和输出形状会改变，从而不可能将两者相加。

上面是一个简单的剩余块的例子。这里，卷积层之后是 **ReLU** ，它是一个非线性激活函数，保留正值并将负值设置为零。ReLU 之后是另一个卷积层。我们可以将输入添加回该层的输出，然后应用 ReLU，反之亦然。

现在我们准备定义我们的模型。

这里我们定义了一个有 3 层的卷积块。将输入通道数转换为输出通道数的卷积层、[批量归一化](https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/#:~:text=Batch%20normalization%20is%20a%20technique,required%20to%20train%20deep%20networks.)层和 ReLU 层。如果 pool 设置为 *True，* [Max Pooling](https://computersciencewiki.org/index.php/Max-pooling_/_Pooling#:~:text=Max%20pooling%20is%20a%20sample,in%20the%20sub%2Dregions%20binned.) 将在前 3 层之后应用。

我们已经扩展了 ImageClassificationBase 类来定义我们的架构。如您所见，我们有 2 个卷积块，后跟一个残差块。这是重复 2 次以上。由于每个卷积块将使我们的图像的维度减半，通道的数量加倍，所以在我们的最终残差层之后，我们的 3 * 64 * 64 图像将被转换为 1024 * 4 * 4。然后，我们应用了一个分类器块，该分类器块将信道的数量转换成 6 个值，这 6 个值表示属于每个垃圾箱的概率。我们现在可以将我们的模型移动到 GPU。

## 训练模型

现在我们可以定义函数来训练我们的模型。

*   **evaluate** 函数将调用 validation_step()并返回验证损失。
*   我们使用了一些技术来改进我们的模型，包括**学习速率调度**、**权重衰减**和**梯度裁剪**。关于这些的更多信息可以在[这里](https://www.notion.so/Data-Augmentation-Regularization-and-Res-Nets-b30e613133b345a3846f724c897ca2dc#6aa005432297462190d9c0436f2ffc41)找到。

让我们检查一下我们的初始精度和损失。

由于模型尚未训练，损失相当高，而准确性非常低。我们现在准备训练我们的模型。

我们已经用 0.001 的最大学习率训练了我们的模型 10 个时期。我们已经达到了 80%的准确率。让我们以较低的学习率再训练 5 个时期的模型。

精确度在 80%左右反弹，这表明除非我们改变我们的模型结构，引入新技术，增加图像尺寸或微调超参数，否则我们不会达到更高的精确度。

## 评估模型性能

我们现在知道我们的模型大约有 80%的准确性。这还不是结束，重要的是要多了解为什么会这样。我们现在将绘制一些图表来更好地理解我们的模型。

1.  **精确度与纪元:**

可以观察到，在第一个历元中精度增加了最大余量，随后，曲线变得平滑。

2.**训练和验证损失与时期:**

从趋势来看很明显，我们的模型并没有过度拟合训练数据，因为两条曲线都下降了。尝试逐个移除数据扩充层和剩余层，以研究它们对过度拟合的影响。

3.**学习率与时期:**

请记住，我们对模型进行了两次训练。在这两种情况下，学习率在大约 30%的时期增加，然后开始下降。这就是学习率调度器的作用。

让我们尝试预测一些样本图像的标签。

## 生成测试预测

我们现在可以对测试数据集进行预测。

在上面的例子中，我们的模型已经猜对了。但是我们的模型并不是 100%准确。下面是我们的模型出错的图像的例子。

正如我们所见，该模型有时会给出错误的结果。

## 保存工作

Jovian 让我们保存笔记本并记录超参数以备将来参考。

## 结论

计算正在发展，深度学习是计算可以给我们的最新和最伟大的东西。垃圾分离，尽管这个过程很乏味，但我们在现实中不仅是垃圾分离，而且几乎任何乏味，复杂和不人道的过程都可以通过人工智能实现自动化。我们肯定离有意识的机器人帮助人类世界还有很长的路要走，但毫无疑问，这是朝着正确方向迈出的一步。

## **学分:**

1.  这个博客是[深度学习项目的一部分:PyTorch : Zero to GANs](http://zerotogans.com) ，这是一个由 [Jovian](http://jovian.ai) 提供的广泛、丰富且非常有趣的免费认证课程。特别感谢 Aakash N.S .和整个木星团队。
2.  数据集提供:[https://www.kaggle.com/asdasdasasdas/garbage-classification](https://www.kaggle.com/asdasdasasdas/garbage-classification)
3.  PyTorch 文档:[https://pytorch.org/](https://pytorch.org/)
4.  一个可执行的 Jupyter 笔记本可以在[这里](https://jovian.ai/aditya-pat10/garbage-segregation)找到。