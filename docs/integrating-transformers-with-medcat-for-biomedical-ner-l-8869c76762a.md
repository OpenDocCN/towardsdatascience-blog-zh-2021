# (ä½¿)èå…¥ğŸ¤—å¸¦ MedCAT çš„å˜å‹å™¨ï¼Œç”¨äºç”Ÿç‰©åŒ»å­¦ NER+L

> åŸæ–‡ï¼š<https://towardsdatascience.com/integrating-transformers-with-medcat-for-biomedical-ner-l-8869c76762a?source=collection_archive---------26----------------------->

![](img/7a2582a634b4492303dc26acac99c6fd.png)

ç”± [Irwan iwe](https://unsplash.com/@aboutiwe?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) åœ¨ [Unsplash](https://unsplash.com/s/photos/medical-record?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) æ‹æ‘„çš„ç…§ç‰‡

ç”Ÿç‰©åŒ»å­¦ NER+L è‡´åŠ›äºä»ç”µå­å¥åº·è®°å½•(EHRs)ä¸­çš„è‡ªç”±æ–‡æœ¬ä¸­æå–æ¦‚å¿µï¼Œå¹¶å°†å®ƒä»¬é“¾æ¥åˆ°å¤§å‹ç”Ÿç‰©åŒ»å­¦æ•°æ®åº“ï¼Œå¦‚ SNOMED-CT å’Œ UMLSã€‚

åŒ»å­¦æ¦‚å¿µæ³¨é‡Šå·¥å…·åŒ…(MedCAT)ä½¿ç”¨åŸºäº Word2Vec çš„æµ…å±‚ç¥ç»ç½‘ç»œæ¥æ£€æµ‹å’Œæ¶ˆé™¤ç”Ÿç‰©åŒ»å­¦æ¦‚å¿µçš„æ­§ä¹‰ã€‚è¿™ç§æ–¹æ³•ç»™äº†æˆ‘ä»¬:1)æ— ç›‘ç£è®­ç»ƒï¼›2)æ£€æµ‹æ•°ç™¾ä¸‡ä¸ªç‹¬ç‰¹æ¦‚å¿µçš„å¯èƒ½æ€§ï¼›3)è®­ç»ƒé€Ÿåº¦å¿«ï¼Œèµ„æºè¦æ±‚ä½ï¼›4)ä»…ä»æ­£é¢ä¾‹å­ä¸­å­¦ä¹ çš„èƒ½åŠ›ï¼›

å¯¹äºä¸€äº›æˆ‘ä»¬æœ‰è¶³å¤Ÿè®­ç»ƒæ ·æœ¬çš„ç”¨ä¾‹ï¼ŒåŸºäºå˜å‹å™¨(å¦‚ BERT)çš„ç›‘ç£å­¦ä¹ æ–¹æ³•å¯èƒ½æ›´åˆé€‚ã€‚

åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•æ•´åˆğŸ¤—ä½¿ç”¨ MedCAT çš„æ•°æ®é›†/è½¬æ¢å™¨ï¼Œæˆ–è€…æ›´å‡†ç¡®åœ°è¯´ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•å°† MedCATtrainer å¯¼å‡º(æ‰‹åŠ¨æ³¨é‡Šçš„é¡¹ç›®)è½¬æ¢ä¸ºğŸ¤—æ•°æ®é›†å’Œè®­ç»ƒ ağŸ¤—å˜å‹å™¨å‹å·ã€‚

å…ˆå†³æ¡ä»¶:

*   ç†Ÿæ‚‰ [MedCAT](https://github.com/CogStack/MedCAT) ( [TDS æ•™ç¨‹](/medcat-introduction-analyzing-electronic-health-records-e1c420afa13a))ã€ [MedCATtrainer](https://github.com/CogStack/MedCATtrainer) ã€[æ‹¥æŠ±è„¸å˜å½¢é‡‘åˆšå’Œæ•°æ®é›†](https://huggingface.co/transformers/)

éšé™„çš„ Jupyter ç¬”è®°æœ¬å¯ä»¥åœ¨ MedCAT [èµ„æºåº“](https://github.com/CogStack/MedCAT/blob/master/notebooks/BERT%20for%20NER.ipynb)ä¸­æ‰¾åˆ°ã€‚

# æ•°æ®å‡†å¤‡

[MedCATtrainer](https://github.com/CogStack/MedCATtrainer/) ç”¨äºæ‰‹åŠ¨æ³¨é‡Šä»»ä½•ç”Ÿç‰©åŒ»å­¦æ¦‚å¿µçš„è‡ªç”±æ–‡æœ¬æ–‡æ¡£(ä¾‹å¦‚ [SNOMED](https://www.snomed.org/) æˆ– [UMLS](https://www.nlm.nih.gov/research/umls/index.html) )ã€‚æ³¨é‡Šè¿‡ç¨‹å®Œæˆåï¼Œé¡¹ç›®å¯ä»¥ä»¥å¦‚ä¸‹æ‰€ç¤ºçš„`.json`æ ¼å¼å¯¼å‡º(æœ‰é™è§†å›¾):

```
{'projects': [{'name': '<something>', 
               'documents': [{'text': '<some text>', 
                              'annotations': [{'start': 23,
                                               'end': 32,
                                               'cui': <label>},
                                              ...]}]}]}
```

ç®€åŒ–å¯¹ä¸€ä¸ªğŸ¤—Transformer æ¨¡å‹ï¼Œæˆ‘ä»¬å°† JSON è¾“å‡ºè½¬æ¢æˆğŸ¤—æ•°æ®é›†ã€‚æˆ‘ä»¬åªä¿ç•™ JSON ä¸­çš„é‡è¦ç‰¹æ€§ï¼Œè€Œä¸¢å¼ƒå…¶ä»–ç‰¹æ€§:

```
features=datasets.Features(
{
"id": datasets.Value("int32"),
"text": datasets.Value("string"),
"ent_starts": datasets.Sequence(datasets.Value("int32")),
"ent_ends": datasets.Sequence(datasets.Value("int32")),
"ent_cuis": datasets.Sequence(datasets.Value("string")),
}),
```

è¿™é‡Œï¼Œ`id`æ˜¯æ–‡æ¡£çš„ IDï¼Œ`text`æ˜¯æ–‡æ¡£çš„æ–‡æœ¬ï¼Œ`ent_starts`æ˜¯æ–‡æ¡£ä¸­æ‰€æœ‰è¢«æ‰‹å·¥æ³¨é‡Šçš„å®ä½“çš„èµ·å§‹å­—ç¬¦çš„ä½ç½®åˆ—è¡¨ï¼Œ`ent_ends`æ˜¯ç»“æŸå­—ç¬¦çš„ä½ç½®ï¼Œ`ent_cuis`æ˜¯æ ‡ç­¾ã€‚è¯·æ³¨æ„ï¼ŒMedCATtrainer ä½¿ç”¨åœ¨çº¿å­¦ä¹ ï¼Œè™½ç„¶ç”¨æˆ·èƒ½å¤Ÿåˆ›å»ºæ–°å®ä½“ï¼Œä½†å¤§å¤šæ•°å®ä½“éƒ½ç”± MedCAT é¢„å…ˆæ³¨é‡Šï¼Œå¹¶ç”±ç”¨æˆ·ç®€å•éªŒè¯(æ­£ç¡®/ä¸æ­£ç¡®)ã€‚å› æ­¤ï¼Œå½“åœ¨ dataset ç±»ä¸­ç”Ÿæˆç¤ºä¾‹æ—¶ï¼Œæˆ‘ä»¬åªä¿ç•™`correct`ç¤ºä¾‹å’Œé‚£äº›ç”±ç”¨æˆ·æ·»åŠ çš„`manually_created`ç¤ºä¾‹ï¼Œæ¢å¥è¯è¯´:

```
for entity in document['annotations']:
    if entity.get('correct', True) or entity.get('manually_created', False):
        # Use the annotation
        ...
```

åŠ è½½`.json`æ–‡ä»¶ç°åœ¨å¾ˆç®€å•:

```
import os
import datasets
from medcat.datasets import medcat_nerDATA_PATH = '<path to my .json export from medcattrainer>'
dataset=datasets.load_dataset(os.path.abspath(medcat_ner.__file__), 
                              data_files=DATA_PATH, 
                              split=datasets.Split.TRAIN)
```

ä¸€æ—¦æ•°æ®é›†è¢«åŠ è½½ï¼Œæˆ‘ä»¬éœ€è¦æŠŠå®ƒè½¬æ¢æˆæ­£ç¡®çš„æ ¼å¼ğŸ¤—å˜å½¢é‡‘åˆšæ¨¡å‹ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹æ–‡æœ¬è¿›è¡Œæ ‡è®°å¹¶åˆ†é…æ ‡ç­¾ã€‚æˆ‘ä»¬å†™äº†ä¸€ä¸ªåŒ…è£…å™¨ğŸ¤—tokenizersï¼Œè¿™å°†ç…§é¡¾ä¸€åˆ‡:

```
from medcat.datasets.tokenizer_ner import TokenizerNER
from transformers import AutoTokenizerhf_tokenizer = AutoTokenizer.from_pretrained('<name>')
id2type = {}
for i in range(hf_tokenizer.vocab_size):
    id2type[i] = 'sub' if hf_tokenizer.convert_ids_to_tokens(i).startswith("##") else 'start'
tokenizer = TokenizerNER(hf_tokenizer, id2type=id2type)
```

ä½¿ç”¨æ–°çš„æ ‡è®°å™¨ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ•°æ®é›†è½¬æ¢æˆæ‰€éœ€çš„æ ¼å¼:

```
encoded_dataset = dataset.map(
 lambda examples: tokenizer.encode(examples, ignore_subwords=True),
 batched=True,
 remove_columns=['ent_cuis', 'ent_ends', 'ent_starts', 'text'])
```

æ•°æ®é›†ç°åœ¨çœ‹èµ·æ¥åƒè¿™æ ·:

```
Dataset({
    features: ['id', 'input_ids', 'labels'],
    num_rows: 4935
})
```

# åŸ¹è®­ ağŸ¤—å˜å½¢é‡‘åˆšæ¨¡å‹

å¦‚æœæˆ‘ä»¬çš„ç”¨ä¾‹å…·æœ‰ç›¸å¯¹è¾ƒå°‘æ•°é‡çš„ç‹¬ç‰¹æ¦‚å¿µ(ä¸æ˜¯å‡ åä¸ªï¼Œå‡ åƒä¸ª)ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ¥è‡ªğŸ¤—ä½¿ç”¨ TokenClassification å¤´:

```
# It is important to set the num_labels, which is the number of unique conceptsmodel = AutoModelForTokenClassification.from_pretrained("emilyalsentzer/Bio_ClinicalBERT", num_labels=len(tokenizer.label_map))
```

ä¸ºäº†å¯¹æ•°æ®è¿›è¡Œæ‰¹å¤„ç†å¹¶å¡«å……åˆ°éœ€è¦çš„åœ°æ–¹ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æ¥è‡ª`MedCAT.datasets`çš„`CollateAndPadNER`ï¼Œå¯¹äº`metrics`ï¼Œæˆ‘ä»¬ç¼–å†™äº†ä¸€ä¸ªç®€å•çš„å‡½æ•°æ¥æ‰“å°ä»¤ç‰Œåˆ†ç±»æŠ¥å‘Šã€‚ç°åœ¨ä¸€åˆ‡éƒ½å‡†å¤‡å¥½äº†ï¼Œæˆ‘ä»¬ä»ğŸ¤—å¹¶è¿è¡ŒåŸ¹è®­:

```
trainer = Trainer(
    model=model,                         
    args=training_args,                 
    train_dataset=encoded_dataset['train'],       
    eval_dataset=encoded_dataset['test'],     
    compute_metrics=metrics,
    data_collator=collate_fn,
    tokenizer=None # We've tokenized earlier
)
trainer.train()
```

# ç»“æœ

æˆ‘ä»¬åœ¨ MedMentions (MM)ä¸Šæµ‹è¯•æ€§èƒ½ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªç›¸å½“å®Œæ•´çš„æ•°æ®é›†ï¼Œæœ‰å¤§é‡çš„æ³¨é‡Š(å®ƒå¹¶ä¸å®Œç¾ï¼Œå› ä¸ºæ³¨é‡Šè€…æœ‰ä¸€äº›åˆ†æ­§ï¼Œä½†å®ƒå·²ç»è¶³å¤Ÿå¥½äº†)ã€‚

è¯¥æ¨¡å‹åœ¨ä¸‰ä¸ªä¸åŒç‰ˆæœ¬çš„ MM ä¸Šè¿›è¡Œæµ‹è¯•:1)æ•´ä¸ªæ•°æ®é›†ï¼›2)åªæœ‰é¢‘ç‡åœ¨ 300 ä»¥ä¸Šçš„æ¦‚å¿µï¼›3)åªæœ‰ 1000 ä»¥ä¸Šçš„é¢‘ç‡ã€‚

## å®Œæ•´çš„ MM æ•°æ®é›†(æµ‹è¯•é›†ä¸­çš„ 13069 ä¸ªæ¦‚å¿µ)

BERT æœ€ç³Ÿç³•çš„ç”¨ä¾‹ï¼Œå¤§é‡çš„æ¦‚å¿µï¼Œå…¶ä¸­å¤§å¤šæ•°æœ‰<10 occurrences. As it can be seen BERT cannot handle this use-case at all â€” at least not in this form. All scores are macro averaged.

*   MedCAT (unsupervised): F1=0.67, P=0.80, R=0.69
*   BERT: F1=0.0, R=0.01, P=0.0

## Only concepts with frequency > 300 ä¸ª(æµ‹è¯•é›†ä¸­æœ‰ 107 ä¸ªæ¦‚å¿µ)

ç¬¬ä¸€ä¸ªç”¨ä¾‹åœ¨åŒ»ç–—ä¿å¥é¢†åŸŸæ˜¯ç›¸å½“æ ‡å‡†çš„ï¼Œå¤§é‡çš„æ¦‚å¿µå¸¦æœ‰ä¸åŒæ•°é‡çš„æ³¨é‡Šã€‚ç¨å¾®ä¸å¤ªæ ‡å‡†çš„æ˜¯ï¼Œæˆ‘ä»¬å·²ç»ä¸ºæ¯ä¸ªæ¦‚å¿µæ·»åŠ äº†ä¸å°‘æ³¨é‡Šã€‚æœ‰è¶£çš„æ˜¯è¡¨æ¼”å‡ ä¹æ˜¯ä¸€æ ·çš„ã€‚

*   MedCAT(ç›‘ç£):P=0.50ï¼ŒR=0.44ï¼ŒF1=0.43
*   ä¼¯ç‰¹:P=0.47ï¼ŒR=0.46ï¼ŒF1=0.43

## ä»…é¢‘ç‡> 1000 çš„æ¦‚å¿µ(æµ‹è¯•é›†ä¸­æœ‰ 12 ä¸ªæ¦‚å¿µ)

è¿™ä¸ªç”¨ä¾‹åº”è¯¥æœ€é€‚åˆ BERTï¼Œå› ä¸ºæˆ‘ä»¬åªå…³æ³¨å…·æœ‰å¤§é‡è®­ç»ƒæ•°æ®çš„æ¦‚å¿µã€‚åƒè¿™æ ·çš„ç”¨ä¾‹éå¸¸ç½•è§ï¼Œè¿™ä¸€ä¸ªæœ‰ç‚¹ç‰¹æ®Šï¼Œå› ä¸ºå‡ºç°è¿™ä¹ˆå¤šæ¬¡çš„æ¦‚å¿µä¸»è¦æ˜¯å®šæ€§æ¦‚å¿µâ€”â€”å®ƒä»¬éå¸¸å¤šæ ·(è®¸å¤šä¸åŒçš„æœ¯è¯­å±äºåŒä¸€ä¸ªæ¦‚å¿µ),æ›´é€‚åˆç±»ä¼¼ BERT çš„æ¨¡å‹ã€‚

*   MedCAT(å—ç›‘ç£):F1=0.34ï¼ŒP=0.24ï¼ŒR=0.70
*   ä¼¯ç‰¹:F1=0.59ï¼ŒP=0.60ï¼ŒR=0.59

# ç»“è®º

ç”Ÿç‰©åŒ»å­¦ NER+1 æ˜¯ä¸€é¡¹è‰°å·¨çš„ä»»åŠ¡ï¼Œå°±åƒå…¶ä»–ä»»ä½•äº‹æƒ…ä¸€æ ·ï¼Œä¸€ä¸ªæ¨¡å‹å¹¶ä¸é€‚åˆæ‰€æœ‰æƒ…å†µã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œå¯¹äºå…·æœ‰æœ‰é™æ•°é‡çš„è®­ç»ƒæ ·æœ¬æˆ–ç›¸å¯¹è¾ƒä½çš„æœ¯è¯­æ–¹å·®çš„ç”¨ä¾‹ï¼ŒåŸºäº Word2Vec çš„æµ…å±‚ç¥ç»ç½‘ç»œæ˜¯æ›´å¥½çš„é€‰æ‹©ã€‚ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬æœ‰å¤§é‡çš„è®­ç»ƒæ ·æœ¬å’Œè¾ƒé«˜çš„é•¿æœŸæ–¹å·®ï¼ŒåŸºäº BERT çš„æ¨¡å‹è¡¨ç°æ›´å¥½ã€‚

æœ€åï¼Œè¿™ä¸¤ç§æ–¹æ³•ç°åœ¨éƒ½æ˜¯ MedCAT çš„ä¸€éƒ¨åˆ†ã€‚