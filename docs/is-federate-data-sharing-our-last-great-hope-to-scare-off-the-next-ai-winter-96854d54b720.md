# 人工智能和数据干旱的令人担忧的未来

> 原文：<https://towardsdatascience.com/is-federate-data-sharing-our-last-great-hope-to-scare-off-the-next-ai-winter-96854d54b720?source=collection_archive---------26----------------------->

## [意见](https://towardsdatascience.com/tagged/opinion)

## 缺乏可用数据阻碍了机器学习解决方案的采用。联合数据共享可能是答案。

![](img/65edc85d326d3455041f1550fc806743.png)

谈到高质量的数据，许多组织都受到了冷落(照片由[哈里森·海恩斯](https://www.pexels.com/@harrisonhaines?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)从 [Pexels](https://www.pexels.com/photo/man-wearing-zip-up-jacket-3536513/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels) 拍摄)

从希腊神话中最早的人工智能主题开始，人们就一直在思考人工智能及其可能带来的可能性。随着计算和数学的进步，[艾伦·图灵 1950 年关于思维机器的论文](https://watermark.silverchair.com/lix-236-433.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAqswggKnBgkqhkiG9w0BBwagggKYMIIClAIBADCCAo0GCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM3shRzb4GsrjM36GOAgEQgIICXvsMJLnRsl4nwcxusewo-3BG-lvgP1Chx3wOmsrTfo_feBVlfBBs9Plmu5LHjmWMftt5Etxe4uGQqO6S_iRAl5Xvjs4MeNTMaVoZHAQn4C50QbOvlM9ovdFUNXQ73xTOwpve2EZfWrA25goXW0E5XmoXW6829QRgRvFg2sqxKgPRtoHg57lJRleC3uO2ExbwrPzspx80QbbtDUEjXQsb9_iNOFilEuD34EOegzw5JHjPHlXFn7Zu0-Vv4SI02pNdNpRam5ctfWNpvYq7Lv_-a-Tu25ZMr8LWtnM7ux4t7IbqFKUAcqjoxB2H8A0cPSLw7XE4nVs2NKt1a_ez1ePsanYxNs5J4U5Uqqsyq9QwqUaWhV_izb8Rne4mvPe6GoqBXnG00AWI88INGqzx8BXBaTQvKBAsLqDhO52YoLyVif7S6FPVpCdO8VAPj1t5CAQRb_29vpVzNG4hQ6gQvaPjRZInWA90eO3q-JPusj-dVliZUaQqocp9r7HKFMavm_7HGMdZQf7moGB0ZCAvxxPuPALHLyQq77vLZM6qChzfP7cQ7cIawWzvbMJAluUefVx4C6JF0Alcemn9D5SNDPHkWKf5_dTUG0D3sPAxHThnzJP0BE-u-MMyS5lyg6rEgurB4sarf-wSyUFeIP44UkdOics7MDkRM3GNuLTExoP2C2C0ARhr1MhZ2tU4JzL8lWPGvag5Pq8ZC8imygC2AeqGVxyYNPD_5u33pQAETGbB0HQXL0aKjX2kPL0mq06_rP-YshgtyEamABPMJ5lyP8AqYCX5xLA8rf4nB0eDQueWyg)引发了这方面的首次实际发展。第一个概念证明是通过艾伦·纽厄尔、克里夫·肖和希尔伯特·西蒙的、[**逻辑理论家**](https://history-computer.com/ModernComputer/Software/LogicTheorist.html) ***、*** 一个旨在模仿人类解决问题能力的程序进行初始化的——被许多人认为是 1956 年提出的第一个人工智能程序。

> 艾还年轻 60 岁，我们才刚刚开始。

尽管它已有 60 年的历史，而且在过去几年里大肆宣传，但还有很长的路要走。我们已经看到了无数令人不安的道德挑战和大企业的一些失败(世界经济论坛的这篇文章是一个很好的起点)。

然而，还有另一个迫在眉睫的威胁，它已经夺走了试图开发人工智能解决商业问题的受害者的公平份额。我已经从组织和个人那里看到和听到了足够多的信息，知道这种威胁是普遍的，并导致整个行业的幻灭。

> 这种威胁首先是缺乏可用的数据。

# 艾·温特斯

![](img/f738d63756086c259775b3f7f040a6bd.png)

决策冻结——我们正在走向另一个可怕的“人工智能冬天”吗？(照片由 [Ricardo Gomez Angel](https://unsplash.com/@ripato?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 拍摄)

自现代诞生以来，人工智能领域已经经历了几次突破性的时刻，随之而来的是热情和辉煌的进步。正是在这些时期，人工智能吸引了一批新的人，他们被似乎充斥媒体的承诺和机会所吸引。

然而，在许多情况下，这种热情是短暂的。一些组织在没有真正了解如何成功部署这些解决方案并从中获取价值的情况下行动过快。或者他们只是期望太多，却遇到了令人沮丧的现实。

然后钟摆摆向另一边，媒体几乎打开了纪律。越来越多关于失败项目和“人工智能冬天”的报道进入了对话。我听说过这样的团队，在一个被认为是成功的项目之后，又回到了旧的工具和方法，因为基础没有建立起来，无法让这些胜利持续下去。

这很大程度上是由于实验室报告的结果与实践中可达到的结果相比而造成的。有一些令人难以置信的重大胜利，也有一些业界应该引以为豪的巨大成果。你应该保持警惕，尽管有人卖给你这些巨大的成果，作为你的公司没有重大投资的速赢。

如果你不熟悉 [Gartner 炒作周期](https://www.gartner.com/smarterwithgartner/5-trends-drive-the-gartner-hype-cycle-for-emerging-technologies-2020/)，我建议你在这里[阅读一下。我相信，对于大多数围绕人工智能的讨论来说，我们已经超越了巅峰。人们开始敏锐地意识到几年前被故意忽视的局限性。](https://www.gartner.com/en/research/methodologies/gartner-hype-cycle)

我想我们也要崩溃了。在很大程度上。许多组织现在已经尝试了人工智能，却发现即使是开始也很难。

> 大多数组织根本没有必要的数据来使人工智能取得成功。

# 数据荒

![](img/073e0d68b5928a1f0dd3963be0c2565d.png)

没有数据，我们什么都没有！(布拉德·赫尔墨克在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片)

互联网的兴起、云计算、大数据处理技术的进步和获取都是人工智能最近崛起的因素。再加上图像处理令人兴奋(有时也令人害怕)的视觉效果，图像处理已经永远改变了物体检测和面部识别等领域，你就有了吸引公众注意力的完美秘诀。

在很多领域，深度学习仍然举步维艰。Deepmind 的最新重大胜利 [AlphaFold](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology) 可能是医学新一轮进步的开端，但除此之外，深度学习在许多更复杂的领域都很艰难。研究中的可能性和对一个组织有用且有价值的东西之间的差距是很难跨越的。

> 组织无法在不泄露秘密的情况下安全地访问和共享可用数据。

即使在组织内部，数据也可能存储在筒仓中，这往往导致沮丧的数据团队重复工作或错过潜在的金矿。已经转向更集中和/或分离的架构，如 data lake、lakehouse 或 data mesh，它们为内部数据共享提供了一些解决方案。然而，伴随着这些解决方案而来的是新的挑战——实现这些工作所需的技能需求量很大，而新技术和程序的采用可能既缓慢又昂贵。

在许多领域，单个组织没有足够的高质量数据来构建强大的模型。最近的许多突破都依赖于大量的数据。获取更多信息是一笔大生意——看看像 [Scale](https://scale.com/) 这样的公司取得的巨大成功就知道了——这是一家成立于 2016 年的数据标签公司[，目前估值为 35 亿美元](https://techcrunch.com/2020/12/01/scale-ai-hits-3-5b-valuation-as-its-turns-the-ai-boom-into-a-venture-bonanza/)。

考虑到像 GDPR 这样的立法，犯这种错误的代价从错失机会到严重的罚款。随着人工智能的伦理和公平使用的发展，我希望我们会看到类似的规定在世界各地出现，这对保护公民的隐私至关重要。这将给组织带来沉重的负担，限制了确保合规性的解决方案。

> 找到一种在保护数据安全和隐私的同时跨越组织边界共享数据的方法，将为中小型组织扫除这些障碍。

# 数据共享(但不要太多)

![](img/2f74c5ec11785054f7816bec6d794203.png)

找到一种在数据集上合作的方法将是成功的关键

如果趋势是更加隐私和安全，那么建立或消除信任的需要可能会成为一个中心主题。为了确保这不会减缓创新并导致某种形式的数据饥荒，技术需要跟上。

> 在“联合数据共享”的保护伞下，一些解决方案即将出现。

有几种技术属于这一类别，包括:

*   **差分隐私** —当从数据集中删除敏感信息还不够时，引入噪声可以让各方成功共享信息。
*   **同态加密** —对数据进行加密，以便可以对其进行分析，而信息本身除了目标方之外不能被任何人读取。
*   **零知识证明** —允许一方证明特定信息，而无需分享除预期之外的任何内容。
*   **安全多方计算** —允许各方对多家机构持有的私有数据进行分析，而不会泄露输入内容。
*   **联合学习** —分别对每个不同的数据集进行分析，然后跨数据集分享见解。

尽管处于不同的成熟阶段，许多工具仍在研究中，但这些工具将使组织能够在不暴露自己或其敏感数据的情况下进行数据协作。

对于 AI 模型开发，联邦学习可能是最相关的(也是更发达的方法之一)。它允许用户使用跨设备和位置分布的多个数据集来训练机器学习模型，同时防止数据泄露和隐私问题。

有三种主要的联邦学习方法。

## 水平的

这种方法根据特性来划分数据资产，通常用于特性比用户有更多重叠的地方。例如，考虑在不同地理位置运营的同一行业的本地企业-它们将拥有许多相同类型的数据，但如果它们位于国家的两端，则可能不会共享一个客户。

## 垂直的

当功能几乎不重叠但用户重叠时，可以使用垂直联合学习。我们已经在医疗保险和可穿戴设备、物流和本地商业等服务领域看到了这一点。获得描述您的用户的新功能可能是解锁新服务和产品的关键，这将大大增加您向他们提供的价值。垂直联合学习允许双方将所有这些特征聚集到一个更具描述性的数据集，双方可以协作使用。

## 转移

就像我们习惯于使用预先训练的模型进行图像处理并将它们应用于其他领域一样，同样的想法也可以应用于组织数据。这可能很困难，因为它需要对不同的领域和高层次的抽象有深刻的理解才能使它有效。

> 随着时间的推移，我们将看到这些技术的巨大进步，因为整个行业的问题变得更加尖锐。

# 结论

近年来，我们经历了人工智能和机器学习的强劲增长期。不幸的是，许多组织在其旅程的早期就遇到了障碍。许多人面临的最大障碍之一是无法获得相关的高质量数据。

新方法有望让组织安全可靠地与其他人合作，构建更强大的数据集。我相信这将成为开启人工智能为中小型企业提供的许多承诺的关键。

只有时间能证明一切。

# 进一步阅读

深入了解金融服务领域的联合共享:

[](https://www.weforum.org/whitepapers/the-next-generation-of-data-sharing-in-financial-services-using-privacy-enhancing-techniques-to-unlock-new-value) [## 金融服务中的下一代数据共享:使用隐私增强技术…

### 这份报告探讨了一组被称为“隐私增强技术”(PETs)的新兴技术，以及它们的能力…

www.weforum.org](https://www.weforum.org/whitepapers/the-next-generation-of-data-sharing-in-financial-services-using-privacy-enhancing-techniques-to-unlock-new-value) 

和医疗保健:

[](https://www.weforum.org/reports/sharing-sensitive-health-data-in-a-federated-data-consortium-model-an-eight-step-guide) [## 在联合数据联盟模型中共享敏感的健康数据:八步指南

### 能够拯救或改善生命的诊断和治疗方法的发现需要访问大型数据集，但这样…

www.weforum.org](https://www.weforum.org/reports/sharing-sensitive-health-data-in-a-federated-data-consortium-model-an-eight-step-guide) 

在这里可以找到对最近一些道德准则的评论:

[](https://link.springer.com/article/10.1007/s11023-020-09517-8) [## 人工智能伦理学的伦理学:对指南的评价

### 人工智能(AI)系统的研究、开发和应用的当前进展已经产生了一种新的趋势

link.springer.com](https://link.springer.com/article/10.1007/s11023-020-09517-8) 

深入了解对数据科学家和数据工程师的要求:

[](https://www.kdnuggets.com/2021/02/dont-need-data-scientists-need-data-engineers.html) [## 我们不需要数据科学家，我们需要数据工程师

### 随着越来越多的人进入数据科学领域，越来越多的公司招聘以数据为中心的角色，什么类型的…

www.kdnuggets.com](https://www.kdnuggets.com/2021/02/dont-need-data-scientists-need-data-engineers.html)