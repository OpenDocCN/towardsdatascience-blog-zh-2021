# 你的人工智能工作是可复制的吗？

> 原文：<https://towardsdatascience.com/are-your-ai-jobs-reproducible-2a86bdffbf44?source=collection_archive---------64----------------------->

## 记录更多关于整个系统的信息可以提高重现性，尤其是性能指标评测结果

![](img/cf4b3aee4c5a36e70aa68b22867152be.png)

马特·布里内在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

除了框架+数据集，我鼓励人们在记录培训工作时考虑他们更广泛的系统。

这在 AI 性能基准测试期间尤其重要。最近有人问我，“在 [MLPerf](https://mlcommons.org/en/training-normal-07/) 测试中，我每秒得到 100，000 张图像。那快吗？”我不知道。你用的是什么精度？多大批量？硬件？数据集存储在哪里？

从基础设施、软件到运行时可调参数，许多因素都会影响训练性能。如果别人不能记下你的笔记并重现你的测试结果，你就没有解决可重复性的问题。

## 关注再现性的几个原因:

**1。严格的文档实践有助于产品开发(在法律上可能是必要的)。**

通常，数据科学家必须在提高准确性和增加训练时间之间做出权衡。检查之前训练跑步设置的矩阵有助于找到更快“达到准确性的时间”的途径

**2。它有助于您确保获得预期的绩效。**

数据科学家应该能够将他们的吞吐量结果与社区提供的结果进行比较。它帮助您检查
-您的脚本是否充分利用了您系统的性能
-您的基础设施没有被错误地配置

**3。它让硬件/软件开发团队评估他们的下一代产品。**

这种最新的加速器模型是否足以作为一种改进来运输呢？这个最新的框架代码版本有性能回归吗？

**4。它帮助开发者和购买者在平台之间进行决策。**

只有通过相互比较，团队才能对更改单个组件将会产生的性能影响有一个合理的想法。

## 我已经在记录 TensorFlow 版本了。

这还不够。

框架版本很重要，但它不是全部。大图有两部分:
-运行级参数
-系统

如果您知道运行级参数，您应该能够走向系统并重现性能结果。这意味着“系统”包括所有端到端硬件(及其操作系统、固件和软件)以及所有设置和库版本(包括容器堆栈)。

我见过的几个随机事件的例子*显著地*影响训练性能:
-Docker 允许使用的内存量
-加速器上的 MTU 设置-以及架顶式交换机上的 MTU 设置！
——我从未听说过的低级 PCIe 设定

## 所以 100 件事会影响表现。我需要记录的最低限度是什么？

以下是 **6 个最重要的项目**。记录这些以使您的结果更具重现性:

1.  加速器模型
2.  加速器驱动程序版本
3.  批量
4.  精确
5.  **完整的**库版本列表，或者容器映像 ID，如果您使用的是来自 NGC 或云供应商的预构建映像。
6.  数据集，包括数据集格式(例如 JPEG v. TFRecord)

这些是影响性能的主要设置，其中大多数可能会随着时间的推移而改变。

## 摘要

如果你测试你的 DL 训练表现，你应该把它想成一个及时的快照。系统是如何配置的，您为运行选择了什么设置？

如果我们开发了更好的实践来使结果具有可重复性，我们将更好地了解随着堆栈的每一部分的发展性能的提高，并且我们将通过突出瓶颈来推动创新。

让我们让“图像/秒”更有意义！