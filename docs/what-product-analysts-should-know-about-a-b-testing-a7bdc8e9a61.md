# 关于 A/B 测试，产品分析师应该知道什么

> 原文：<https://towardsdatascience.com/what-product-analysts-should-know-about-a-b-testing-a7bdc8e9a61?source=collection_archive---------14----------------------->

## [实践教程](https://towardsdatascience.com/tagged/hands-on-tutorials)

## 从计划到评估的产品分析师入门

![](img/2678ec8207e2de494c2e10073d61ee36.png)

来自[佩克斯](https://www.pexels.com/photo/assorted-colorful-lollipops-on-pink-background-4202998/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)的[卡罗琳娜·格拉博斯卡](https://www.pexels.com/@karolina-grabowska?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)的照片

在成为产品数据分析师之前，我的大部分数据角色都是支持市场营销的。我有营销 A/B 测试的经验，但很快意识到不是所有的 A/B 测试都是平等的，尤其是产品测试。通过反复试验，我发现了我希望从一开始就知道的最佳实践。今天，我将讨论我学到了什么，如果你被要求进行产品 A/B 测试，我会给你一个好的开始。

> 产品 A/B 测试的生命周期可分为 3 个阶段。

## 1.规划

*   **实验设计和衡量成功的 KPI**—在计划阶段，产品经理和我审核了实验设计，并就衡量成功的 KPI 达成一致。可以有多个 KPI 来衡量成功，但要与产品经理达成一致，决定哪一个应该是主要的还是次要的 KPI，以决定获胜的变体。我支持的[移动应用订阅](https://uplandsoftware.com/localytics/resources/blog/subscription-based-apps-pros-cons-and-how-to-make-the-big-bucks/)几乎在每个测试中都使用了相同的 KPI，但它会根据你支持的群体和测试的目标而有所不同。
*   **检查用户何时被随机分组** —用户根据应用程序登录被随机分组，但有测试表明这没有意义。例如，一个旨在增加成功注册数量的 A/B 测试将需要从人们点击注册流程的第一个屏幕而不是登录时开始随机选择，因为我们正在测试这一变化是否会方便用户完成注册过程。与产品经理讨论用户将被随机分配到哪里，以确保他们被适当地划分到每个变体中。
*   **确认测试的目标人群** —新功能或变更可能不会同时在所有用户和平台上进行测试。在我的公司，我们在一个国家或平台测试了变化，并在将它们发布给我们剩余的用户之前应用了从测试中学到的知识。与产品经理一起检查预期的测试人群，因为这可能会影响用于计算样本大小的基线 KPI。例如，如果一个新功能只对 iOS 上的英语用户进行测试，转化率可能与 iOS 上所有用户的转化率不同。这也影响了预期参加测试的用户数量，因为更多的用户登录了 iOS，而不仅仅是英语用户。
*   **计算样本量和预期测试持续时间**—这一步很重要，因为你可能会发现需要几个月的时间才能达到确定统计显著性所需的样本量。这通常是因为预期到达被随机化的点的用户数量太低。对于那些情况，你需要回到产品经理那里决定另一个 KPI 来衡量成功或者改变实验设计。

## 2.发动

测试启动后，我们检查了几个项目，以确保实现没有任何问题。这是由我们的产品经理完成的，但作为贵公司的产品分析师，您可能必须这样做。

*   **确认变量比例与分配的百分比相匹配** —例如，如果我们预计测试中有 4 个相等的组，包括控制组，那么每个变量应该包含进入测试的用户总数的 25%。这是比例不平衡的测试中最常见的问题。有时这在早期被发现，工程人员修复了问题，我们重新开始测试。在其他情况下，我们在测试结束时发现了这一点，结果是可疑的。
*   **检查 KPI 是否受损** —并非所有测试都成功，有时变体的表现比对照差。有时，相对于控制的相对差异足够大，以至于在早期达到显著性，产品经理关闭测试以避免造成更大的伤害。其他时候，我们关掉表现比对照差的变体，因为其他变体表现得更好。产品应该运行测试并从中学习，但我们需要确保业务 KPI 不会受到重大影响。

## 3.估价

在一些公司，你可能不参与计划或启动阶段，你只是被要求在最后评估 A/B 测试。如果是这种情况，要求尽早参与，因为这可以确保产品经理获得有用的结果。否则，他们可能会因为糟糕的测试结果而做出错误的决定，或者因为测试设置不当而没有结果。

当测试准备好进行评估时，我在开始计算结果之前浏览了一下这个清单。

*   是否有足够的时间来评估测试？ —即使测试达到了确定显著性所需的样本量，也可能需要运行更长时间，这取决于衡量成功的 KPI。例如，当我们推出一项新功能时，我们想测试它是否增加了注册 30 天后返回应用程序的新用户的百分比。这意味着测试需要额外运行 30 天，以确保控制中的新用户不会在我们想要测量的 30 天参与窗口内接触到新功能。有时候，当我被要求评估 A/B 测试时，测试已经结束了。这减少了我可以用来计算结果的用户数量，并且样本大小不足以确定显著性。
*   **变异比例是否正确**？—如果一个测试有 4 个变量，包括控制变量，并且预期是均匀分布的，那么每个变量包含 25%的用户总数吗？在一些测试中，我没有看到相等的比例，但工程人员告诉我，用户在每个变体中都是随机的。根据具体情况做出最佳判断。现实情况是，A/B 测试可能会出错，而分析师的工作是评估结果是否仍然可用。
*   **用户是否接触到多种变体，有多少**？—每个用户应该只处于一个变体中，但有时一个用户可以处于多个变体中，这意味着他们处于控制中，并且还可以看到我们正在测试的更改。大多数时候，一小部分用户处于多个变体中，这是意料之中的。A/B 测试中有很大比例的用户属于多个变体，这可能会对测试实现和测试结果的有效性提出质疑。如果这发生在你的 A/B 测试中，与你的经理或同事讨论一下，因为他们可能在过去处理过类似的情况。

尽管 A/B 测试结果可能没有明确的赢家，但在审查结果和提出建议时，您应该考虑一些业务因素。

*   用户体验(User experience)—测试很重要，但有时管理层可能会在样本量达到显著水平之前就决定推出新功能，因为他们认为这将提高用户参与度。我们使用测试结果作为方向指导，无法计算相对于控制的真实改进。
*   **平台对等** —有时，在 iOS 上的相同测试与控制相比有正面结果，但在 Android 上有负面结果。偶尔，我们会在两个平台上推出这些变化以保持平等，因为我们觉得随着时间的推移，这将有利于我们的用户，即使测试结果现在没有显示出来。
*   **季节性** —我们不能总是等待一年中的最佳时间来运行 A/B 测试以避免季节性，因为那样我们可以运行的测试数量就会受到限制。如果我们在今年的其他月份运行，结果可能会有所不同，但我们推出了一些变化，我们相信结果的积极方向会保持不变。

无论您是产品新手还是正在考虑成为产品分析师，我希望这能让您在 A/B 测试体验上有一个良好的开端。感谢阅读！

## 你可能也会喜欢…

</my-experience-as-a-product-data-analyst-3d01748bc6ea>  <https://medium.datadriveninvestor.com/netflix-q1-21-subscriber-growth-miss-can-we-avoid-another-one-189a87f9dcb8> 