# 我如何用 Python 创建假新闻检测器

> 原文：<https://towardsdatascience.com/how-i-created-a-fake-news-detector-with-python-65b1234123c4?source=collection_archive---------9----------------------->

## 用 spaCy 和 Streamlit 开发假新闻检测应用程序

![](img/4b545f3ad3681b2b41f8f728d76d36dd.png)

马库斯·温克勒在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

假新闻的泛滥是对现代民主社会的一个重大挑战。不准确的信息会影响人们的健康和福祉，尤其是在新冠肺炎疫情充满挑战的时期。此外，虚假信息通过阻止公民根据可证实的事实做出理性决定，侵蚀了公众对民主制度的信任。一项令人不安的研究表明，假新闻比真实新闻接触到更多人，传播速度更快，尤其是在社交媒体上。麻省理工学院的研究人员发现，假新闻在 Twitter 和脸书等平台上被分享的可能性增加了 70%。

假新闻运动是现代信息战的一种形式，被国家和其他实体用来削弱对手的权力和合法性。根据欧盟当局的说法，欧洲国家已经成为中国和俄罗斯虚假信息运动的目标，在许多话题上散布谎言，包括新冠肺炎疫情。东方战略任务小组已经成立，通过监控和揭露有关欧盟成员国的假新闻来处理这个问题。

事实审查员是核实已发布新闻事实正确性的个人。这些专业人士通过识别他们的虚假声明来揭穿假新闻。研究表明，传统的事实核查可以通过机器学习和自然语言处理(NLP)算法来增强。在这篇文章中，我将解释如何使用 Python 编程语言开发一个 web 应用程序来检测用我的母语(希腊语)编写的假新闻。

# 希腊假新闻数据集

每一个机器学习项目的成功都取决于拥有一个适当而可靠的数据集。有许多公开的假新闻数据集，如《骗子》和《FakeNewsNet⁴》，但不幸的是，其中大多数都是由英文文章组成的。由于我找不到任何包含希腊语文章的数据集，我决定创建自己的数据集。[希腊假新闻(GFN)数据集](https://github.com/derevirn/gfn-detector/tree/main/data)由用希腊语编写的真实和虚假新闻组成，可用于训练文本分类模型，以及其他 NLP 任务。

该数据集是基于以下方法创建的。首先，真实的新闻是从一些著名的希腊报纸和网站上收集的。我添加了各种话题的新闻，主要集中在政治、经济、新冠肺炎疫情和世界新闻上。为了识别假新闻，我咨询了 [Ellinika Hoaxes](https://www.ellinikahoaxes.gr/) ，这是一个希腊事实核查网站，已经获得了[国际事实核查网络](https://www.poynter.org/ifcn/) (IFCN)的认证。被验证为虚假的新闻条目样本也被添加到数据集中。该过程完成后，生成的数据集用于训练希腊假新闻检测器应用程序的文本分类模型。

# spaCy Python 库

有许多高级 Python 库可用于自然语言处理任务。其中最受欢迎的是 [spaCy](https://spacy.io/) ，这是一个 NLP 库，带有预训练的模型，以及对 60 多种语言的标记化和训练的支持。spaCy 包括命名实体识别(NER)、词性标注、句子分割、文本分类、词汇化、形态分析等组件。此外，spaCy 是一款健壮且可用于生产的软件，可用于现实产品中。这个库用于创建希腊假新闻检测器应用程序的文本分类模型。

# 简化框架

[Streamlit](https://www.streamlit.io/) 是一个 Python 框架，可以让你非常快速地为数据科学项目构建 web 应用。您可以用几行代码轻松创建一个包含各种小部件的用户界面。此外，Streamlit 是一个很好的工具，可以将机器学习模型部署到 web 上，并增加数据的可视化效果。Streamlit 还有一个强大的缓存机制，可以优化应用程序的性能。此外， [Streamlit Sharing](https://streamlit.io/sharing) 是一项由库创建者免费提供的服务，让您可以轻松地部署您的应用程序并与其他人共享。有关 Streamlit 的详细介绍，请参见[这里的](/streamlit-101-an-in-depth-introduction-fc8aad9492f2)。

# 开发 Web 应用程序

出于多种原因，我决定开发[希腊假新闻检测器](https://share.streamlit.io/derevirn/gfn-detector/main/app.py)。首先，我想从总体上熟悉 spaCy 库和 NLP，从而提高我的技能集并成为一名专业人员。其次，我想展示使用机器学习来处理假新闻问题的潜力，以一种非专家也能理解的方式。实现这一点的最佳方式是开发一个 web 应用程序形式的简单原型。Streamlit 是实现这一目的的理想工具，所以我决定利用它。我现在将解释源代码功能，从文本分类模型训练开始。我最初使用的是 Jupyter 笔记本，但是出于本文的目的，代码被转换为下面的 Python 文件，名为`gfn_train.py`。

首先，我们导入必要的 Python 库，并定义两个助手函数。`load_data()`函数重组数据，为每篇新闻文章分配一个类别，并将数据集分成训练和测试子集。`evaluate()`函数计算各种指标，如精确度、召回率和 F 分数，这可以帮助我们评估文本分类器的性能。在定义辅助函数之后，我们加载 spaCy 预训练模型。我选择了`el_core_news_md`模式，因为我们正在处理用希腊语写的文章。

之后，我们将 GFN 数据集加载到熊猫数据帧，并通过删除一些不需要的字符来清理它。之后，我们将`textcat`组件添加到我们的预训练模型中。该组件将用 GFN 数据集进行训练，以创建文本分类模型。然后我们禁用其他组件，因为我们只需要训练`textcat`。然后，我们使用`load_data()`和`update()`函数分别加载数据集和训练模型。我们之前定义的`evaluate()`函数用于打印培训指标和绩效。训练完成后，使用`to_disk()`功能保存模型。我们现在将检查 Streamlit web 应用程序的主文件`app.py`。

我们从导入 Streamlit、spaCy 和其他必要的库开始。在此之后，我们定义了`get_nlp_model()`函数，该函数加载我们之前训练的 spaCy 文本分类模型。这个函数用`@st.cache` decorator 标记，它让 Streamlit 将模型存储在本地缓存中，从而提高性能。然后，我们使用`markdown()`函数和一些常见的 HTML 标签定义了打印分类结果的`generate_output()`函数。之后，文章文本被打印出来，同时还有一个用于可视化的单词云。

然后，我们使用各种 Streamlit 小部件创建应用程序布局。首先，我们设置页面标题和描述。其次，我们创建一个用于输入类型选择的单选按钮小部件。通过这样做，用户可以选择输入文章的 URL 或文本。如果用户选择文章 URL 作为输入类型，则使用`get_page_text()`功能抓取文本。否则，用户可以在多行文本输入中粘贴文章。在这两种情况下，都使用一个按钮小部件来调用`generate_output()`函数，从而对文章进行分类并打印结果。最后，我们可以执行`streamlit run app.py`命令在本地运行应用程序，或者使用免费的 Streamlit 共享服务来部署它。

# 结论

我希望读完这篇文章后，你会更加了解使用 NLP 和机器学习来处理假新闻这一严重问题的潜力。此外，我鼓励您尝试并创建自己的假新闻检测应用程序，因为修改代码以在不同的数据集上训练模型很简单。如果你想克隆这个项目的 Github 库，可以在这里找到[。欢迎在评论中分享你的想法，或者在](https://github.com/derevirn/gfn-detector) [LinkedIn](https://www.linkedin.com/in/giannis-tolios-0020b067/) 上关注我，我经常在那里发布关于数据科学和其他主题的内容。你也可以访问我的[个人网站](https://giannis.io/)或者查看我的新书，名为[用 PyCaret](https://leanpub.com/pycaretbook/) 简化机器学习。

# 参考

[1]沃索伊、索罗什、德布罗伊和希南阿拉尔。"真假新闻在网上的传播."*理科*359.6380(2018):1146–1151。

[2]大川、雷、钱景和威廉·王洋。"用于假新闻检测的自然语言处理综述." *arXiv:1811.00770* (2018)。

[3]王，杨威廉."“骗子，骗子裤子着火了”:假新闻检测的新基准数据集." *arXiv:1705.00648* (2017)。

[4]舒，凯等，“假新闻网:一个包含新闻内容、社会背景和时空信息的数据仓库，用于研究社交媒体上的假新闻。”*大数据*8.3(2020):171–188。