# Scribd 的信息提取

> 原文：<https://towardsdatascience.com/information-extraction-at-scribd-f62f3025b5c9?source=collection_archive---------27----------------------->

## 使用自然语言处理通过关键短语和实体在我们的大量文本文档上执行信息抽取

这是一系列博客文章的第 2 部分，描述了我们构建的多组件机器学习系统，用于从我们的文档中提取元数据，以丰富下游发现模型。

在本帖中，我们展示了在为大量文本文档构建信息抽取 NLP 模型时所面临的挑战和局限性，以及我们提出的解决方案。

正如在第一部分中提到的，我们现在有了一种识别大量文本文档的方法。完成这些之后，我们想要构建专用的模型来加深我们对它们的语义理解。我们通过提取关键短语和实体来做到这一点。

![](img/7018430c46cac9debc63293d6d76e33b.png)

**图 1** :我们多组件机器学习系统的示意图(*图片作者*)。

关键短语是代表主要主题/话题的短语，而实体是专有名词，如人、地点和组织。例如，当一个用户上传一个关于曼哈顿项目的文档时，我们首先会发现它是一个很重的文本，然后提取关键短语和实体。潜在的关键词是“原子弹”和“核武器”，潜在的实体是“罗伯特·奥本海默”和“洛斯·阿拉莫斯”。

因为关键短语提取引出了文档中讨论的一般主题，所以它有助于限制每个文档保留的信息量，从而不管文档的原始大小如何，都能得到某种程度上统一的文档表示。另一方面，实体提取识别文本中不一定仅由关键短语反映的元素。我们发现关键短语和实体提取的结合为每个文档提供了丰富的语义描述。

本文的其余部分将解释我们如何处理关键短语和实体提取，以及我们如何识别这些关键短语和实体的子集是否存在于知识库中(也称为链接)，并介绍我们如何使用它们来对文档进行分类。

# 关键短语提取

通常，关键短语提取系统分两步操作，如本调查[中所示](https://www.aclweb.org/anthology/P14-1119.pdf):

*   使用试探法提取作为候选关键短语的单词/短语列表，如词性语言模式、停用词过滤和维基百科文章标题的 n 元语法
*   使用以下两种方法之一来确定这些候选关键短语中的哪些最有可能是关键短语:
*   监督方法，例如候选的二进制分类(有用/无用)、基于位置编码的结构特征等。
*   无监督的方法，例如选择具有最高 tf-idf 的术语和聚类。

训练一个像样的监督模型以能够提取各种主题的关键短语将需要大量的训练数据，并且可能概括得很差。出于这个原因，我们决定采取无人监管的方法。

我们对关键短语提取的实现进行了速度优化，而没有牺牲太多的关键短语质量。我们使用统计方法和语言特定的规则来有效地识别它们。

我们简单地从过滤掉停用词开始，提取基数为 n 的 n 元文法(在我们的例子中是二元文法，n=2)。这一步骤快速且直接，并产生候选 n 元文法的初始集合。

然而，将结果限制到单个 n 元语法类会导致分裂的关键短语，这使得将它们链接到知识库成为一项具有挑战性的任务。为此，我们尝试将较低阶的 n-grams 聚集成潜在较长的关键短语，只要它们与较短的 n_gram 相比以预定的最小频率出现，基于以下 a 模式:

`A sequence of nouns (NN) possibly interleaved with either Coordinating Conjunctions (CC) or Prepositions and Subordinating Conjunctions (IN).`

这里有几个例子:

*   假设聚集的最小频率是 0.5，这意味着只要`world health organization`发生的次数至少是`world health`发生次数的 50%，我们就只用`world (NN) health (NN) organization (NN)`代替二元组`world (NN) health (NN)`。
*   仅当与前者相比，后者至少出现预定百分比的时间时，用`Center(NNP) for (IN) Global (NNP) Development (NNP)`替换`Human (NNP) Development (NNP)`。

这种方法产生更连贯和完整的关键短语，可以更准确地链接到知识库条目。

最后，我们使用候选关键短语的出现次数作为其重要性的代理。这种方法对于较长的文档是可靠的，因为关键短语的重复倾向于可靠地表明它是文档主题的中心。

# 命名实体

关键短语只是发现文档中重要内容的一个方面。为了进一步捕捉文档的内容，我们还必须考虑存在的命名实体。

命名实体提取系统识别文本中命名实体的实例，我们可以对其进行计数，以表示它们在文档中的重要性，类似于我们对关键短语所做的。

天真地通过精确的字符串匹配来计算命名的实体暴露了一个有趣的问题:一个实体可能有许多名称或别名，这意味着字符串频率是一个不可靠的重要性度量。在**图 2** 给出的例子中，我们知道“米尔”、“约翰·斯图尔特·米尔”和“斯图尔特·米尔”都是指同一个人。这意味着米尔比表格显示的更重要，因为他总共被提到了 8 次而不是 5 次。

![](img/3a98b28668887117c1548355de7358bc.png)

**图 2** :节选自约翰·斯图亚特·穆勒的维基百科页面(左)和前几段的 5 大命名实体计数(右)(*图片作者*)。

为了解决这个计数问题，让我们引入一些抽象概念:

*   **命名实体**指独特的人、地点或组织。由于它们的唯一性，我们可以用唯一的标识符( **ID** )来表示它们。
*   **命名实体别名**(或简称为**别名**)，是与特定实体相关的可能的多个名称之一。
*   **规范别名**是实体的首选名称。
*   **命名实体提及**(或简称为**提及**)，指的是一个命名实体在文本中被提及的每一次出现，不管使用了哪个别名。
*   知识库是一个实体集合，允许我们查询 ID、规范名称、别名和其他可能与手头任务相关的信息。一个例子是[维基数据](https://www.wikidata.org/wiki/Wikidata:Main_Page)。

解决计数问题的第一步是规范化文档用来引用一个**命名实体的名称。使用我们的抽象，这意味着我们想要找到文档中所有提到的**和**，并使用它的**别名**来找到它所属的**命名实体**。然后，用**规范名称**或**命名实体 ID** 来替换它——这个区别将在后面变得更加清楚。**

# 实体规范化

给定出现在文档中的一组别名，我们开发了启发法(例如，公共标记、缩写)来识别哪个别名子集引用相同的命名实体。这允许我们在比较别名时限制我们的搜索空间。

使用我们之前的示例来说明这种方法，我们首先假设规范别名是给定实体的文本中最长的别名，并通过评估哪些别名与我们开发的试探法匹配来尝试将别名合并在一起。

![](img/ccd24d1f9cdcb34824c25ae56f7bb2c8.png)

**表 1** :约翰·斯图亚特·穆勒维基百科页面前几段出现的前 5 个别名，有些是指同一个人(*图片作者*)。

使用精确的记号匹配作为启发来相互比较实体将解决这个问题:

![](img/1aa37912dc34344d3beebfd26267a109.png)

**表 2** :成对别名比较和结果合并。匹配项以粗体突出显示(*图片作者*)。

通过用相应的规范别名替换所有提及，我们能够找到正确的命名实体计数。

一种极端情况是当一个别名可能指一个以上的实体时:例如，别名“波特”可能指哈利波特宇宙中的命名实体“哈利波特”或“詹姆斯·波特”。为了解决这个问题，我们构建了一个实体链接器，它决定在给定的上下文中哪个命名实体最有可能匹配别名。在**链接到知识库**一节中进一步解释了这一过程。

当知识库中没有实体时，我们不能使用命名实体链接来消除歧义。在这种情况下，我们的解决方案使用了一种回退方法，该方法将不明确的提及(Potter)分配给与启发法匹配的最接近的明确提及(例如 Harry)。

# 链接到知识库

假设文档中提到的许多关键短语和实体是值得注意的，它们很可能存在于知识库中。这使我们能够利用知识库中存在的额外信息来改进标准化步骤以及下游任务。

实体链接通过提供别名匹配命名实体的信息来帮助规范化，否则该命名实体不会匹配启发式规则(例如，“诚实的 Abe”对“Abraham Lincoln”)。此外，知识库中的[信息可用于在与文本](https://arxiv.org/abs/1601.01343)相同的空间中嵌入链接的实体和关键短语。

能够在与文本相同的空间中嵌入实体是有用的，因为这释放了将可能匹配的命名实体 id 与它们被提及的上下文进行比较的能力，并决定我们考虑的别名是否可能是知识库中的实体之一(在这种情况下，我们将使用 id)，或者该别名是否与知识库中的任何实体不匹配，在这种情况下，我们退回到使用假定的规范别名。

在 [Scribd](https://www.scribd.com) 中，我们利用实体链接不仅改进了实体规范化步骤，还利用了实体和关键短语嵌入作为补充特性。

# 讨论

将所有这些放在一起，我们可以:

1.  将文档链接到关键短语和实体
2.  找出文件中每一项的相对重要性。
3.  利用知识库中的相关信息

这促成了一些有趣的项目:

在其中一个项目中，我们构建了一个文档图以及相关的关键短语和实体。在同一个空间中嵌入文档、关键短语和实体使我们能够通过类比来发现文档。例如，以亚历山大·仲马的《基督山伯爵》为例，这是一本 19 世纪的法国复仇小说。如果我们再加上`science_fiction`的嵌入，它会把我们带到儒勒·凡尔纳(另一位 19 世纪的法国作家)的科幻小说集，比如**《海底两万里》**和**《地心游记》**。

关键短语提取在增加文档聚类的可解释性方面也很有用。通过提取一个集群中最常见的关键短语，我们可以为该集群的内容导出一个共同的主题:

![](img/4ccc3ad858e5f8858897512b060d908e.png)

**图 3** :文档聚类中的顶级关键词。关键词暗示其中的文档与牙科&医疗保健相关，这通过人工检查文档得到确认(*图片由作者*)。

在另一个项目中，我们利用预先计算的知识库嵌入，通过包含的实体和关键短语的组合来表示空间中的文档。这些功能使我们能够了解用户上传的文档，并改进平台上的内容发现。

要了解我们如何使用提取的信息将文档分类到一个分类法中，请务必查看第 3 部分(即将推出):对用户上传的文档进行分类！

如果您有兴趣了解 Scribd 应用研究正在解决的问题或围绕这些解决方案构建的系统，请查看我们的[空缺职位](https://tech.scribd.com/careers/#open-positions)！