# 构建实时 ML 系统的方法

> 原文：<https://towardsdatascience.com/approaches-for-building-real-time-ml-systems-79ea0e340269?source=collection_archive---------4----------------------->

![](img/8de9402f7658318130286b2c9e283864.png)

来源:https://unsplash.com/photos/p3Pj7jOYvnM

## [理解大数据](https://towardsdatascience.com/tagged/making-sense-of-big-data)

## 以毫秒为单位响应预测请求

作为 Zynga 的应用数据科学家，我已经开始着手构建和部署数据产品。随着我探索越来越多的机器学习用例，对实时机器学习(ML)系统的需求越来越多，其中系统执行特征工程和模型推理，以在几毫秒内响应预测请求。虽然我以前使用过 AWS SageMaker 等工具进行近实时的模型推理，但我只是最近才探索了为 ML 系统进行动态特征工程的选项。

广告技术是需要实时 ML 来构建在广告市场中表现良好的系统的领域之一。在广告的需求方面，实现 OpenRTB 规范的实时竞价者需要预测哪些广告印象最有可能驱动转换事件。在供应方，广告中介平台需要实时确定广告库存的投标底价，以便优化广告收入。

在实时 ML 部署中，系统会在请求发出后的几毫秒内回复请求。使用实时系统进行预测请求有两种常规工作流程:

1.  Web 请求
2.  流式工作流

在第一种情况下，需要预测的系统或客户端向一个端点发出 HTTP 请求，该端点使用预测直接响应请求。其他协议，如 gRPC，可以用于这种类型的工作流。

第二个工作流程可以通过多种方式实现。例如，可以向 Kafka 主题发出一个请求，在那里用 Spark 流处理该请求，并将结果发布到一个单独的主题。其他流框架，如 Flink 或 GCP 数据流，可用于近实时响应预测请求。

在过去的一年里，我和 Golang 一起开发了实时 ML 系统。虽然 Python 可以用来实现这些类型的系统，但 Golang 通常能够在固定数量的机器上每秒响应更多的请求。此外，Golang 还有一些优雅的特性，可以在构建实时 ML 系统时使用 NoSQL 数据存储。对于请求量非常大的用例，为了提高效率，我选择了纯 Go 实现。

在这篇文章中，我将讨论构建实时执行特征工程和模型推理的 ML 系统的一些可用选项。我将讨论纯 Go 方法和 Python 混合方法的选择。

# 特征工程

在应用模型之前，通常需要将预测请求转换成可以传递给 ML 模型的特征向量。例如，对于 OpenRTB bid 请求，在预测转换事件之前，需要将 web 请求中传递的 JSON 转换为特征向量。另一个用例是检索移动游戏的用户简档，并将简档转换为特征向量，以进行终身价值(LTV)预测。在这些用例中，基于请求中的信息实时执行特征工程，或者在移动应用中使用先前存储的关于用户的信息。

特征工程需要进行重大转变，从矢量预先计算的批处理过程转变为针对每个传入请求即时进行特征工程的实时系统。在广告技术中，系统可以接收投标请求，然后在执行特征工程之前用额外的数据点(例如来自数据管理平台(DPM)的信息)来扩充该请求。所有这些都需要以最小的延迟来完成，这限制了可以使用的方法的类型。以下是我探索过的一些方法:

1.  经常预先计算特征并存储在 NoSQL
2.  使用 NoSQL 存储和更新特征向量
3.  使用 NoSQL 存储配置文件，并使用自定义应用程序代码进行翻译
4.  使用 NoSQL 存储配置文件，并使用 DSL 进行翻译
5.  为特征工程调用远程端点

这些解决方案大多依赖于使用 NoSQL 数据存储，因为它需要快速响应请求。对于使用哪种工具，需要考虑几个权衡因素，例如要存储的数据点数量、读/写请求以及最大延迟。Redis 是入门时的一个很好的选择，大多数云平台都有托管服务。

## 预计算功能

这种方法最接近于传统的批处理预测工作流，在这种工作流中，同时为大量用户进行预测，并将结果缓存到应用程序数据库中，如 Redis。这实际上不是实时地执行特征工程，而是可以以这样一种方式来实现，即对于在应用中活跃的用户，特征向量被频繁地更新。例如，您可以使用 Spark 作业每 15 分钟查询一次关系数据库，使用 SQL 将用户活动转换为特征向量，并将结果存储到 NoSQL 商店。对于许多用例来说，从用户在应用程序中执行操作到该活动出现在用于模型推断的特征向量中有 15 分钟的延迟可能不是问题。然而，这对于关系数据库来说是一项繁重的工作，只有在需要创建向量的用户数量相对较少的情况下才推荐使用。这种方法不适用于系统需要在特征生成过程中使用来自预测请求的上下文的问题，并且通常应该仅用作后备。

## 在 NoSQL 直接存储媒介

使用 NoSQL 实时执行特征工程的另一种方法是提前确定应用所需的特征向量的形状，并在系统接收到新的跟踪事件时实时更新这些值。例如，特征向量可以具有跟踪用户已经进行的会话总数的属性，并且每当用户开始新的会话时更新该值。对于移动应用程序，具有实时回调事件的 MMP 可用于设置这种跟踪事件功能。

对于这种方法，像用户 ID 这样的键被用作 NoSQL 商店的键，值是特征向量，它可以用多种方式实现。在 Redis 中，散列可以用来实时更新计数器值。向量也可以存储为 JSON，这很简单，但通常会占用更多空间。您可以使用特定于编程语言的库进行序列化，比如 Java 的 [kryo](https://github.com/EsotericSoftware/kryo) 。我通常使用的方法是 Google 协议缓冲区，以可移植的方式序列化数据。

这种方法是基本的，这使得它更容易实现，但是它有一些主要的限制。首先，您需要一个固定的特征向量定义，因为向量是在收到新数据时直接更新的，而不是即时聚合数据，我们将在后面的方法中讨论。第二个大的限制是特性必须能够增量更新，而不是在过去的事件上聚集。这意味着可以使用诸如计数器和标志之类的功能，但不可能使用诸如中位数之类的聚合或其他需要历史数据的计算。

## 配置文件和自定义应用程序代码

为了在可为特征工程执行的操作类型中获得更大的灵活性，一种选择是在 NoSQL 中存储用户简档，并使用存储在简档中的数据来动态执行特征工程以创建矢量。该方法使用与之前相同的过程，其中当接收到新数据时，实时更新 NoSQL 存储中的值，但是该方法不是更新特征向量，而是更新概括用户活动的用户简档。例如，简档可以存储用户在游戏中玩的过去 3 种游戏模式，或者跟踪用户最近使用了哪些加电项目。

当使用这种方法接收到预测请求时，该请求在请求中传递用户 ID，预测端点从 NoSQL 获取配置文件，然后自定义应用程序代码将该配置文件转换为特征向量。在 Golang 中，这可以实现为一个函数，该函数将 protobuf 对象作为输入，并返回一个特征向量([]float64)作为结果。这种方法通常是计算效率最高的方法，但是每次特征向量的定义改变时都需要系统的新部署。这对于只需要为少量模型提供服务并且定义很少改变的系统来说很有效，但是对于为各种模型提供预测的系统来说可能是有问题的。

## 配置文件和领域特定语言(DSL)

为了消除每次特征向量定义改变时部署系统的需要，我们需要系统更新特征变换的更灵活的方法。一种方法是使用数据驱动或配置驱动的方法，在这种方法中，转换被定义为数据结构或配置文件，可以在每次进行更新时由系统加载。例如，可以将系统设置为接收一个 JSON 文件，该文件定义了 OpenRTB bid 请求的哪些属性和值要进行 1-hot 编码。这使得数据科学家能够在单独的运行时(如 PySpark)中定义模型管道，而模型在 Go 中提供服务。

随着时间的推移，团队可能希望定义更复杂类型的操作来对请求数据和用户配置文件执行操作，以将这些数据点转换为特征向量。针对这个问题，我探索了小型的特定领域语言(DSL ),比如在比较值时允许≥和≤操作符，以及添加操作符来检查列表中的某项。这很快变得复杂起来，并成为系统部署的新驱动力，因为新的操作符是为您的定制 DSL 定义的。我已经开始使用谷歌的[通用表达式语言](https://opensource.google/projects/cel) (CEL)将用户资料翻译成特征向量，而不是为每个新系统从头开始构建。该语言支持各种可以在 protobuf 对象上执行的操作，在输入对象上运行的 CEL 程序的输出是一个特征向量。当使用这种方法时，特征工程翻译被定义为 CEL 程序，它可以作为字符串传递。

## 特征工程终点

如果延迟不是问题，并且您希望在如何将用户配置文件转换为特征向量方面有很大的灵活性，那么您可以设置一个端点来执行该转换。这可以通过 AWS Lambda 等无服务器功能或部署到 Kubernetes 实例的 docker 映像来实现。这种方法在构建原型时很有用，但是会导致额外的云基础设施，并且具有定制应用程序代码方法的所有缺点。它仍然使用这种方法，但提供了一个选项，当更新特征工程定义时，只需要重新部署无服务器功能，而不是整个系统。

# 模型推理

一旦有了预测请求的特征向量，就需要在响应实时请求时应用 ML 模型。实现这一功能有多种选择，但是使用 Golang 确实会使事情变得更加复杂。以下是我探索过的方法。

1.  推理终点
2.  自定义应用程序代码
3.  跨运行时算法
4.  便携式模型格式

我曾经开发过数据产品，其中训练环境是 PySpark，运行时环境是 Golang，这使得使用标准数据科学堆栈(如 sklearn、XGBoost、SparkML 和 TensorFlow)训练的模型变得很棘手。我将介绍一些处理这些限制的方法，但是纯粹的 Go 实现仍然有一定的局限性。

## 推理终点

支持各种模型推理算法的最简单方法之一是使用该问题的现有解决方案，如 AWS SageMaker、BentoML 或 fast.ai。这些解决方案使用 Python 运行时为模型提供服务，并支持预测模型的标准 ML 工作台。当使用这种方法时，系统首先在当前过程中执行特征生成，调用端点来执行模型推断，然后用推断端点产生的值来响应预测请求。

这种方法适用于大多数用例，但是有一些注意事项。如果系统正在响应大量的请求，那么像 SageMaker 这样的托管解决方案会变得非常昂贵。另一个问题是延迟，调用远程进程会增加延迟，并会影响系统的 SLA，这对广告技术等领域来说是个问题。

## 自定义应用程序代码

如果系统需要运行的算法相对简单，例如线性模型，那么编写自定义应用程序代码来实现该模型可能是有利的。在 Golang 中，线性回归和逻辑回归相对容易实现，但是您需要定义一种格式来序列化 Python/PySpark to Go 的模型，这取决于您的培训环境。对于更复杂的算法，这种方法可能会很快导致技术债务，并最终导致错误。

这种方法非常有用的地方是当构建具有非常宽的特征向量的系统时，例如成千上万的特征。如果向量非常稀疏，那么在处理这种规模的数据时，可以使用查找表(如哈希映射)来高效地执行模型推断。

## 跨运行时算法

我经常为 Golang ML 系统使用的一种方法是使用在 Python 和 Golang 中都有实现的算法。LightGBM 是一个很好的 ML 算法的例子，它在 Python 中运行良好，并与[叶库](https://github.com/dmitryikh/leaves)相匹配。在 Python 和 Go 中，库与积极支持的实现的交集很小，但有望随着时间的推移而增长。TensorFlow 确实有 Golang API，但目前还不稳定。

## 便携式模型格式

为了帮助解决只有少数 ML 库在 Golang 中得到适当支持的事实，我探索的另一种方法是可移植的模型格式，如 PMML 和 ONNX。PMML 是使 ML 模型可以跨不同运行时移植的最初提议，但是只有有限的几个关键 ML 框架采用了它。前提是你可以用 Python 训练一个模型，用 PMML 格式保存结果，然后在不同的运行时加载模型，进行模型推断。Golang 实现了用于推理的 PMML，例如 [goscore](https://github.com/asafschers/goscore) ，但是目前还不支持流行的算法，例如 XGBoost。

ONNX 是使 ML 模型跨运行时可移植的下一代建议。它最初是为深度学习而设计的，但已经扩展到支持经典算法。理论上，您可以使用 SparkML、XGBoost、sklearn、Tensorflow 和其他工具来训练模型，并使用 ONNX 实现在任何运行时运行模型推理。目前的情况是，许多这些框架对导出到 ONNX 的支持有限，Golang 实现的领先者对经典 ML 算法的支持也有限。对 ONNX 导出和运行时的支持有望随着时间的推移而改进，使 ML 系统的纯 Go 实现成为一个可靠的选择。

# 结论

对于数据产品，从批量转换到实时 ML 预测需要新的方法来执行特征工程和潜在的模型推断。我发现对实时特征工程最有用的方法是在 NoSQL 数据存储中存储一个用户级概要对象，并使用自定义应用程序代码或通用表达式语言对每个请求动态执行特征工程。对于模型推理，我使用了可用于模型训练和模型服务环境的算法和实现。

让我们的团队能够构建能够在数毫秒内响应预测请求的 ML 管道，这开启了各种新的用例。

[本·韦伯](https://www.linkedin.com/in/ben-weber-3b87482/)是 Zynga 应用科学总监。我们正在[招聘](https://www.zynga.com/job-listing-category/data-analytics-user-research/)！