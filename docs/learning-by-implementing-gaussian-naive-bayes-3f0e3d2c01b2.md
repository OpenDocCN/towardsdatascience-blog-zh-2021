# é€šè¿‡å®ç°æ¥ç†è§£:é«˜æ–¯æœ´ç´ è´å¶æ–¯

> åŸæ–‡ï¼š<https://towardsdatascience.com/learning-by-implementing-gaussian-naive-bayes-3f0e3d2c01b2?source=collection_archive---------8----------------------->

## å»ºç«‹ä½ è‡ªå·±çš„æ¨¡å‹

## äº†è§£é«˜æ–¯æœ´ç´ è´å¶æ–¯çš„å·¥ä½œåŸç†ï¼Œå¹¶åœ¨ Python ä¸­å®ç°å®ƒ

![](img/c4e2a8d8f2124edf1ac6f7cfea719ae8.png)

é«˜æ–¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨çš„å†³ç­–åŒºåŸŸã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

æˆ‘è®¤ä¸ºè¿™æ˜¯æ¯ä¸ªæ•°æ®ç§‘å­¦èŒä¸šç”Ÿæ¶¯å¼€å§‹æ—¶çš„ç»å…¸ä¹‹ä½œ:*æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨*ã€‚æˆ–è€…æˆ‘åº”è¯¥è¯´æ˜¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨çš„*å®¶æ—*ï¼Œå› ä¸ºå®ƒä»¬æœ‰å¾ˆå¤šç§é£æ ¼ã€‚ä¾‹å¦‚ï¼Œæœ‰ä¸€ä¸ªå¤šé¡¹å¼æœ´ç´ è´å¶æ–¯ï¼Œä¸€ä¸ªä¼¯åŠªåˆ©æœ´ç´ è´å¶æ–¯ï¼Œè¿˜æœ‰ä¸€ä¸ªé«˜æ–¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œæ¯ä¸ªåˆ†ç±»å™¨åªæœ‰ä¸€ä¸ªå°ç»†èŠ‚ä¸åŒï¼Œæˆ‘ä»¬ä¼šå‘ç°ã€‚æœ´ç´ è´å¶æ–¯ç®—æ³•åœ¨è®¾è®¡ä¸Šéå¸¸ç®€å•ï¼Œä½†åœ¨è®¸å¤šå¤æ‚çš„ç°å®æƒ…å†µä¸­è¯æ˜æ˜¯æœ‰ç”¨çš„ã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæ‚¨å¯ä»¥äº†è§£åˆ°

*   æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨å¦‚ä½•å·¥ä½œï¼Œ
*   ä¸ºä»€ä¹ˆä»¥ä»–ä»¬çš„æ–¹å¼å®šä¹‰ä»–ä»¬æ˜¯æœ‰æ„ä¹‰çš„
*   å¦‚ä½•ä½¿ç”¨ NumPy åœ¨ Python ä¸­å®ç°å®ƒä»¬ã€‚

> ä½ å¯ä»¥åœ¨ [my Github](https://github.com/Garve/TDS/blob/main/TDS%20-%20Gaussian%20Naive%20Bayes.ipynb) ä¸Šæ‰¾åˆ°ä»£ç ã€‚

æ£€æŸ¥ä¸€ä¸‹æˆ‘çš„è´å¶æ–¯ç»Ÿè®¡åˆçº§è¯»æœ¬[å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ï¼Œè¿™æ˜¯å¯¹è´å¶æ–¯æ¨ç†çš„æ¸©å’Œä»‹ç»](/a-gentle-introduction-to-bayesian-inference-6a7552e313cb)ä»¥ä¹ æƒ¯è´å¶æ–¯å…¬å¼ã€‚å› ä¸ºæˆ‘ä»¬å°†ä»¥ scikit learn-conform çš„æ–¹å¼å®ç°åˆ†ç±»å™¨ï¼Œæ‰€ä»¥ä¹Ÿå€¼å¾—çœ‹çœ‹æˆ‘çš„æ–‡ç« [æ„å»ºæ‚¨è‡ªå·±çš„å®šåˆ¶ scikit-learn å›å½’](/build-your-own-custom-scikit-learn-regression-5d0d718f289)ã€‚ç„¶è€Œï¼Œscikit-learn çš„å¼€é”€å¾ˆå°ï¼Œæ— è®ºå¦‚ä½•æ‚¨éƒ½åº”è¯¥èƒ½å¤Ÿè·Ÿä¸Šã€‚

æˆ‘ä»¬å°†å¼€å§‹æ¢ç´¢æœ´ç´ è´å¶æ–¯åˆ†ç±»çš„æƒŠäººç®€å•çš„ç†è®ºï¼Œç„¶åè½¬å‘å®ç°ã€‚

# è¯¥ç†è®º

åˆ†ç±»æ—¶æˆ‘ä»¬çœŸæ­£æ„Ÿå…´è¶£çš„æ˜¯ä»€ä¹ˆï¼Ÿæˆ‘ä»¬å®é™…ä¸Šåœ¨åšä»€ä¹ˆï¼Œè¾“å…¥å’Œè¾“å‡ºæ˜¯ä»€ä¹ˆï¼Ÿç­”æ¡ˆå¾ˆç®€å•:

> ç»™å®šä¸€ä¸ªæ•°æ®ç‚¹ xï¼Œx å±äºæŸç±» c çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ

è¿™å°±æ˜¯æˆ‘ä»¬æƒ³è¦ç”¨**ä»»ä½•**åˆ†ç±»æ¥å›ç­”çš„æ‰€æœ‰é—®é¢˜ã€‚ä½ å¯ä»¥ç›´æ¥æŠŠè¿™ä¸ªè¯­å¥å»ºæ¨¡æˆæ¡ä»¶æ¦‚ç‡:*p*(*c*|*x*)ã€‚

ä¾‹å¦‚ï¼Œå¦‚æœæœ‰

*   3 ç­ *c* â‚ã€ *c* â‚‚ã€ *c* â‚ƒï¼Œä»¥åŠ
*   *x* ç”±ä¸¤ä¸ªç‰¹å¾ç»„æˆ *x* â‚ï¼Œ *x* â‚‚ï¼Œ

åˆ†ç±»å™¨çš„ç»“æœå¯èƒ½ç±»ä¼¼äº *p* ( *c* â‚| *x* â‚ï¼Œ *x* â‚‚)=0.3ï¼Œ
p(*c*â‚‚|*x*â‚ï¼Œ *x* â‚‚)=0.5 å’Œ*p*(*c*â‚ƒ|*x*â‚ï¼Œ*x*å¦‚æœæˆ‘ä»¬å…³å¿ƒå•ä¸ªæ ‡ç­¾ä½œä¸ºè¾“å‡ºï¼Œæˆ‘ä»¬å°†é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„ä¸€ä¸ªï¼Œå³ *c* â‚‚ï¼Œè¿™é‡Œæ¦‚ç‡ä¸º 50%ã€‚**

> æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨è¯•å›¾ç›´æ¥è®¡ç®—è¿™äº›æ¦‚ç‡ã€‚

## æœ´ç´ è´å¶æ–¯

å¥½ï¼Œé‚£ä¹ˆç»™å®šä¸€ä¸ªæ•°æ®ç‚¹ *x* ï¼Œæˆ‘ä»¬è¦è®¡ç®—æ‰€æœ‰ç±» *c* çš„*p*(*c*|*x*)ï¼Œç„¶åè¾“å‡ºæ¦‚ç‡æœ€é«˜çš„ *c* ã€‚åœ¨å…¬å¼ä¸­ï¼Œæ‚¨é€šå¸¸ä¼šçœ‹åˆ°è¿™ç§æƒ…å†µ

![](img/a6876b2d43dc6519e81e86b4d85be8e8.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

**æ³¨:**max*p*(*c*|*x*)è¿”å›æœ€å¤§æ¦‚ç‡ï¼Œarg max*p*(*c*|*x*)è¿”å›æ¦‚ç‡æœ€å¤§çš„ *c* ã€‚

ä½†æ˜¯åœ¨æˆ‘ä»¬èƒ½å¤Ÿä¼˜åŒ–*p*(*c*|*x*)ä¹‹å‰ï¼Œæˆ‘ä»¬å¿…é¡»èƒ½å¤Ÿè®¡ç®—å®ƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨[è´å¶æ–¯å®šç†](https://en.wikipedia.org/wiki/Bayes%27_theorem):

![](img/cdc94dbdc1047244b1cb85f294c98238.png)

è´å¶æ–¯å®šç†ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

è¿™æ˜¯æœ´ç´ è´å¶æ–¯çš„è´å¶æ–¯éƒ¨åˆ†ã€‚ä½†æ˜¯ç°åœ¨ï¼Œæˆ‘ä»¬æœ‰äº†ä»¥ä¸‹é—®é¢˜:ä»€ä¹ˆæ˜¯*p*(*x*|*c*)å’Œ *p* ( *c* )ï¼Ÿ

> è¿™å°±æ˜¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨çš„è®­ç»ƒã€‚

## åŸ¹è®­

ä¸ºäº†è¯´æ˜ä¸€åˆ‡ï¼Œä¸‹é¢è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªæœ‰**ä¸¤ä¸ªçœŸå®ç‰¹å¾** *x* â‚ã€ *x* â‚‚ã€**ä¸‰ä¸ªç±»** *c* â‚ã€ *c* â‚‚ã€ *c* â‚ƒçš„ç©å…·æ•°æ®é›†ã€‚

![](img/73a99a9f39a6cda834c8dd57a533f676.png)

å¯è§†åŒ–çš„æ•°æ®ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼åˆ›å»ºç²¾ç¡®çš„æ•°æ®é›†

```
from sklearn.datasets import make_blobs

X, y = make_blobs(n_samples=20, centers=[(0,0), (5,5), (-5, 5)], random_state=0)
```

è®©æˆ‘ä»¬ä»**ç±»æ¦‚ç‡** *p* ( *c* )å¼€å§‹ï¼Œåœ¨æ ‡è®°çš„æ•°æ®é›†ä¸­è§‚å¯Ÿåˆ°æŸä¸ªç±» *c* çš„æ¦‚ç‡ã€‚ä¼°è®¡è¿™ä¸€ç‚¹çš„æœ€ç®€å•çš„æ–¹æ³•æ˜¯åªè®¡ç®—ç±»çš„ç›¸å¯¹é¢‘ç‡ï¼Œå¹¶ä½¿ç”¨å®ƒä»¬ä½œä¸ºæ¦‚ç‡ã€‚æˆ‘ä»¬å¯ä»¥ç”¨æˆ‘ä»¬çš„æ•°æ®é›†æ¥çœ‹çœ‹è¿™åˆ°åº•æ„å‘³ç€ä»€ä¹ˆã€‚

åœ¨æ•°æ®é›†ä¸­ï¼Œ20 ä¸ªç‚¹ä¸­æœ‰ 7 ä¸ªè¢«æ ‡è®°ä¸ºç±»åˆ« *c* â‚(è“è‰²)ï¼Œå› æ­¤æˆ‘ä»¬ç§°ä¹‹ä¸º*p*(*c*â‚)=7/20.æˆ‘ä»¬ä¹Ÿæœ‰ 7 ç‚¹ç»™èŒä¸š *c* â‚‚(çº¢è‰²)ï¼Œå› æ­¤æˆ‘ä»¬è®¾å®š*p*(*c*â‚‚)=7/20.æœ€åä¸€ç­ *c* â‚ƒ(é»„)åªæœ‰ 6 åˆ†ï¼Œäºæ˜¯*p*(*c*â‚ƒ)=6/20.

è¿™ç§ç®€å•çš„ç±»åˆ«æ¦‚ç‡è®¡ç®—ç±»ä¼¼äºæœ€å¤§ä¼¼ç„¶æ³•ã€‚ä½†æ˜¯ï¼Œå¦‚æœæ‚¨æ„¿æ„ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨å¦ä¸€ä¸ª*previous*åˆ†å¸ƒã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨çŸ¥é“è¿™ä¸ªæ•°æ®é›†ä¸ä»£è¡¨çœŸå®çš„æ€»ä½“ï¼Œå› ä¸ºç±» *c* â‚ƒåº”è¯¥å‡ºç°åœ¨ 50%çš„æƒ…å†µä¸‹ï¼Œé‚£ä¹ˆæ‚¨è®¾ç½® *p* ( *c* â‚)=0.25ï¼Œ *p* ( *c* â‚‚)=0.25 å’Œ *p* ( *c* â‚ƒ)=0.5.ä»»ä½•æœ‰åŠ©äºæé«˜æµ‹è¯•é›†æ€§èƒ½çš„ä¸œè¥¿ã€‚

æˆ‘ä»¬ç°åœ¨è½¬å‘**å¯èƒ½æ€§***p*(*x*|*c*)=*p*(*x*â‚ï¼Œ *x* â‚‚| *c* )ã€‚è®¡ç®—è¿™ç§å¯èƒ½æ€§çš„ä¸€ç§æ–¹æ³•æ˜¯è¿‡æ»¤æ ‡ç­¾ä¸º *c* çš„æ ·æœ¬çš„æ•°æ®é›†ï¼Œç„¶åå°è¯•æ‰¾åˆ°æ•è·ç‰¹å¾ *x* â‚ã€ *x* â‚‚.çš„åˆ†å¸ƒ(ä¾‹å¦‚ï¼ŒäºŒç»´é«˜æ–¯åˆ†å¸ƒ)

> ä¸å¹¸çš„æ˜¯ï¼Œé€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ²¡æœ‰è¶³å¤Ÿçš„æ ·æœ¬å¯¹æ¯ä¸€ç±»è¿›è¡Œé€‚å½“çš„å¯èƒ½æ€§ä¼°è®¡ã€‚

ä¸ºäº†èƒ½å¤Ÿå»ºç«‹ä¸€ä¸ªæ›´å¥å£®çš„æ¨¡å‹ï¼Œæˆ‘ä»¬åšäº†ä¸€ä¸ª**å¤©çœŸçš„å‡è®¾**å‡è®¾ç‰¹å¾ *x* â‚ï¼Œ *x* â‚‚æ˜¯*éšæœºç‹¬ç«‹çš„*ï¼Œç»™å®š *c* ã€‚è¿™åªæ˜¯é€šè¿‡ä¸€ç§å¥‡ç‰¹çš„æ–¹å¼ä½¿æ•°å­¦å˜å¾—ç®€å•

![](img/771f4ff13d99dac453b0418f12789255.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

**ä¸ºæ¯ä¸€ç±»*c*ã€‚è¿™å°±æ˜¯æœ´ç´ è´å¶æ–¯çš„**æœ´ç´ **éƒ¨åˆ†çš„æ¥æºï¼Œå› ä¸ºè¿™ä¸ªç­‰å¼ä¸€èˆ¬ä¸æˆç«‹ã€‚å°½ç®¡å¦‚æ­¤ï¼Œå³ä¾¿å¦‚æ­¤ï¼Œæœ´ç´ è´å¶æ–¯ç†è®ºåœ¨å®è·µä¸­ä¹Ÿèƒ½äº§ç”Ÿè‰¯å¥½çš„ã€æœ‰æ—¶æ˜¯æ°å‡ºçš„ç»“æœã€‚ç‰¹åˆ«æ˜¯å¯¹äºå…·æœ‰è¯è¢‹ç‰¹å¾çš„ NLP é—®é¢˜ï¼Œå¤šé¡¹å¼æœ´ç´ è´å¶æ–¯å¤§æ”¾å¼‚å½©ã€‚**

ä¸Šé¢ç»™å‡ºçš„å‚æ•°å¯¹äºä½ èƒ½æ‰¾åˆ°çš„ä»»ä½•æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨éƒ½æ˜¯ä¸€æ ·çš„ã€‚ç°åœ¨å°±çœ‹ä½ æ€ä¹ˆé€ å‹äº†*p*(*x*â‚|*c*â‚ã€‘ï¼Œ*p*(*x*â‚‚|*c*â‚ã€‘ï¼Œ*p*(*x*â‚|*c*â‚‚ã€‘ï¼Œ*p*()

å¦‚æœä½ çš„ç‰¹å¾åªæœ‰ 0 å’Œ 1ï¼Œä½ å¯ä»¥ä½¿ç”¨ä¸€ä¸ª[ä¼¯åŠªåˆ©åˆ†å¸ƒ](https://en.wikipedia.org/wiki/Bernoulli_distribution)ã€‚å¦‚æœå®ƒä»¬æ˜¯æ•´æ•°ï¼Œä¸€ä¸ª[å¤šé¡¹å¼åˆ†å¸ƒ](https://en.wikipedia.org/wiki/Multinomial_distribution)ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬æœ‰çœŸå®çš„ç‰¹å¾å€¼ï¼Œå¹¶å†³å®šä¸ºä¸€ä¸ª**é«˜æ–¯**åˆ†å¸ƒï¼Œå› æ­¤å¾—åé«˜æ–¯æœ´ç´ è´å¶æ–¯ã€‚æˆ‘ä»¬å‡è®¾ä»¥ä¸‹å½¢å¼

![](img/93c61ce74dcbece82ad84f76832784bc.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

å…¶ä¸­ï¼Œ *Î¼áµ¢,â±¼* æ˜¯å¹³å‡å€¼ï¼Œ *Ïƒáµ¢,â±¼* æ˜¯æˆ‘ä»¬å¿…é¡»ä»æ•°æ®ä¸­ä¼°è®¡çš„æ ‡å‡†åå·®ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬ä¸ºæ¯ä¸ªç‰¹å¾å¾—åˆ°ä¸€ä¸ªå¹³å‡å€¼ *i* å’Œä¸€ä¸ªç±» *c* â±¼ *ï¼Œ*åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯ 2*3=6 ä¸ªå¹³å‡å€¼ã€‚æ ‡å‡†å·®ä¹Ÿæ˜¯å¦‚æ­¤ã€‚**è¿™éœ€è¦ä¸€ä¸ªä¾‹å­ã€‚**

è®©æˆ‘ä»¬è¯•ç€ä¼°è®¡ä¸€ä¸‹*â‚‚,â‚å’Œ* â‚‚,â‚.å› ä¸º *j* =1ï¼Œæˆ‘ä»¬åªå¯¹ç±»åˆ« *c* â‚æ„Ÿå…´è¶£ï¼Œè®©æˆ‘ä»¬åªä¿ç•™å¸¦æœ‰è¿™ä¸ªæ ‡ç­¾çš„æ ·å“ã€‚ä»¥ä¸‹æ ·æœ¬ä»ç„¶å­˜åœ¨:

```
# samples with label = c_1
array([[ 0.14404357,  1.45427351],
       [ 0.97873798,  2.2408932 ],
       [ 1.86755799, -0.97727788],
       [ 1.76405235,  0.40015721],
       [ 0.76103773,  0.12167502],
       [-0.10321885,  0.4105985 ],
       [ 0.95008842, -0.15135721]])
```

ç°åœ¨ï¼Œå› ä¸º *i* =2ï¼Œæˆ‘ä»¬åªéœ€è¦è€ƒè™‘ç¬¬äºŒåˆ—ã€‚ *Î¼* â‚‚,â‚æ˜¯è¯¥åˆ—çš„å¹³å‡å€¼ï¼Œ *Ïƒ* â‚‚,â‚æ˜¯è¯¥åˆ—çš„æ ‡å‡†å·®ï¼Œå³ *Î¼* â‚‚,â‚ = 0.49985176ï¼Œ *Ïƒ* â‚‚,â‚ = 0.9789976ã€‚

å¦‚æœä½ å†æ¬¡ä»ä¸Šé¢çœ‹æ•£ç‚¹å›¾ï¼Œè¿™äº›æ•°å­—æ˜¯æœ‰æ„ä¹‰çš„ã€‚ä»å›¾ç‰‡ä¸­å¯ä»¥çœ‹åˆ°ï¼Œâ‚*c*çº§æ ·å“çš„ç‰¹å¾ *x* â‚‚åœ¨ 0.5 å·¦å³ã€‚

æˆ‘ä»¬ç°åœ¨ä¸ºå…¶ä»–äº”ä¸ªç»„åˆè®¡ç®—è¿™ä¸ªï¼Œæˆ‘ä»¬å®Œæˆäº†ï¼ğŸ˜ƒ

åœ¨ Python ä¸­ï¼Œå¯ä»¥è¿™æ ·åš:

```
from sklearn.datasets import make_blobs
import numpy as np

# Create the data. The classes are c_1=0, c_2=1 and c_3=2.
X, y = make_blobs(n_samples=20, centers=[(0,0), (5,5), (-5, 5)], random_state=0)

# The class probabilities.
# np.bincounts counts the occurence of each label.
prior = np.bincount(y) / len(y)

# np.where(y==i) returns all indices where the y==i.
# This is the filtering step.
means = np.array([X[np.where(y==i)].mean(axis=0) for i in range(3)])
stds = np.array([X[np.where(y==i)].std(axis=0) for i in range(3)])
```

æˆ‘ä»¬æ”¶åˆ°

```
# priors
array([0.35, 0.35, 0.3 ])# means 
array([[ 0.90889988,  0.49985176],
       [ 5.4111385 ,  4.6491892 ],
       [-4.7841679 ,  5.15385848]])# stds
array([[0.6853714 , 0.9789976 ],
       [1.40218915, 0.67078568],
       [0.88192625, 1.12879666]])
```

è¿™æ˜¯é«˜æ–¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨çš„è®­ç»ƒç»“æœã€‚

## åšé¢„æµ‹

å®Œæ•´çš„é¢„æµ‹å…¬å¼æ˜¯

![](img/55ecf803b71e92535de1a6f6b2d565ba.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

è®©æˆ‘ä»¬å‡è®¾ä¸€ä¸ªæ–°çš„æ•°æ®ç‚¹ *x*=* (-2ï¼Œ5)è¿›æ¥ã€‚

![](img/b3d79b2b53078df11eb10c2a46493262.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

ä¸ºäº†æŸ¥çœ‹å®ƒå±äºå“ªä¸ªç±»ï¼Œè®©æˆ‘ä»¬è®¡ç®—æ‰€æœ‰ç±»çš„*p*(*c*|*x **)ã€‚ä»å›¾ç‰‡ä¸Šçœ‹ï¼Œå®ƒåº”è¯¥å±äºç±» *c* â‚ƒ = 2ï¼Œä½†è®©æˆ‘ä»¬çœ‹çœ‹ã€‚è®©æˆ‘ä»¬æš‚ä¸”å¿½ç•¥åˆ†æ¯ *p* ( *x* )ã€‚ä½¿ç”¨ä»¥ä¸‹å¾ªç¯è®¡ç®—å‡º *j* = 1ï¼Œ2ï¼Œ3 çš„å‘½åæ•°ã€‚

```
x_new = np.array([-2, 5])

for j in range(3):
    print(f'Probability for class {j}: {(1/np.sqrt(2*np.pi*stds[j]**2)*np.exp(-0.5*((x_new-means[j])/stds[j])**2)).prod()*p[j]:.12f}')
```

æˆ‘ä»¬æ”¶åˆ°

```
Probability for class 0: 0.000000000263
Probability for class 1: 0.000000044359
Probability for class 2: 0.000325643718
```

å½“ç„¶ï¼Œè¿™äº›*æ¦‚ç‡*(æˆ‘ä»¬ä¸åº”è¯¥è¿™æ ·ç§°å‘¼å®ƒä»¬)å¹¶ä¸ç­‰äº 1ï¼Œå› ä¸ºæˆ‘ä»¬å¿½ç•¥äº†åˆ†æ¯ã€‚ç„¶è€Œï¼Œè¿™æ²¡ä»€ä¹ˆé—®é¢˜ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥æŠŠè¿™äº›æœªæ ‡å‡†åŒ–çš„æ¦‚ç‡é™¤ä»¥å®ƒä»¬çš„å’Œï¼Œç„¶åå®ƒä»¬ä¼šåŠ èµ·æ¥ç­‰äº 1ã€‚å› æ­¤ï¼Œå°†è¿™ä¸‰ä¸ªå€¼é™¤ä»¥å®ƒä»¬çš„æ€»å’Œçº¦ä¸º 0.00032569ï¼Œæˆ‘ä»¬å¾—åˆ°

![](img/e0ff6250c6b2b94940bc8bef3bfb5c79.png)

å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

æ­£å¦‚æˆ‘ä»¬æ‰€é¢„æ–™çš„ï¼Œä¸€ä¸ªæ˜æ˜¾çš„èµ¢å®¶ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬å®æ–½å®ƒå§ï¼

# å®Œæ•´çš„å®ç°

è¿™ç§å®ç°æ–¹å¼æ•ˆç‡å¾ˆä½ï¼Œåœ¨æ•°å€¼ä¸Šä¹Ÿä¸ç¨³å®šï¼Œå®ƒåªç”¨äºæ•™è‚²ç›®çš„ã€‚æˆ‘ä»¬å·²ç»è®¨è®ºäº†å¤§éƒ¨åˆ†äº‹æƒ…ï¼Œæ‰€ä»¥ç°åœ¨åº”è¯¥å¾ˆå®¹æ˜“ç†è§£äº†ã€‚ä½ å¯ä»¥å¿½ç•¥æ‰€æœ‰çš„`check`å‡½æ•°ï¼Œæˆ–è€…é˜…è¯»æˆ‘çš„æ–‡ç« [æ„å»ºä½ è‡ªå·±çš„å®šåˆ¶ scikit-learn](/build-your-own-custom-scikit-learn-regression-5d0d718f289) ï¼Œå¦‚æœä½ å¯¹å®ƒä»¬åˆ°åº•åšä»€ä¹ˆæ„Ÿå…´è¶£çš„è¯ã€‚

è¯·æ³¨æ„ï¼Œæˆ‘é¦–å…ˆå®ç°äº†ä¸€ä¸ª`predict_proba`æ–¹æ³•æ¥è®¡ç®—æ¦‚ç‡ã€‚æ–¹æ³•`predict`åªæ˜¯è°ƒç”¨è¿™ä¸ªæ–¹æ³•ï¼Œå¹¶ä½¿ç”¨ argmax å‡½æ•°è¿”å›æ¦‚ç‡æœ€é«˜çš„ç´¢å¼•(=ç±»)(åˆæ¥äº†ï¼).è¯¥ç±»ç­‰å¾…ä» 0 åˆ° *k* -1 çš„ç±»ï¼Œå…¶ä¸­ *k* æ˜¯ç±»çš„æ•°é‡ã€‚

```
import numpy as np
from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.utils.validation import check_X_y, check_array, check_is_fitted

class GaussianNaiveBayesClassifier(BaseEstimator, ClassifierMixin):
    def fit(self, X, y):
        X, y = check_X_y(X, y)
        self.priors_ = np.bincount(y) / len(y)
        self.n_classes_ = np.max(y) + 1

        self.means_ = np.array([X[np.where(y==i)].mean(axis=0) for i in range(self.n_classes_)])
        self.stds_ = np.array([X[np.where(y==i)].std(axis=0) for i in range(self.n_classes_)])

        return self

    def predict_proba(self, X):
        check_is_fitted(self)
        X = check_array(X)

        res = []
        for i in range(len(X)):
            probas = []
            for j in range(self.n_classes_):
                probas.append((1/np.sqrt(2*np.pi*self.stds_[j]**2)*np.exp(-0.5*((X[i]-self.means_[j])/self.stds_[j])**2)).prod()*self.priors_[j])
            probas = np.array(probas)
            res.append(probas / probas.sum())

        return np.array(res)

    def predict(self, X):
        check_is_fitted(self)
        X = check_array(X)

        res = self.predict_proba(X)

        return res.argmax(axis=1)
```

## æµ‹è¯•å®ç°

è™½ç„¶ä»£ç å¾ˆçŸ­ï¼Œä½†ä»ç„¶å¤ªé•¿ï¼Œæ— æ³•å®Œå…¨ç¡®å®šæˆ‘ä»¬æ²¡æœ‰çŠ¯ä»»ä½•é”™è¯¯ã€‚å› æ­¤ï¼Œè®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹å®ƒä¸ [scikit-learn GaussianNB åˆ†ç±»å™¨](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)çš„å¯¹æ¯”æƒ…å†µã€‚

```
my_gauss = GaussianNaiveBayesClassifier()
my_gauss.fit(X, y)
my_gauss.predict_proba([[-2, 5], [0,0], [6, -0.3]])
```

è¾“å‡º

```
array([[8.06313823e-07, 1.36201957e-04, 9.99862992e-01],
       [1.00000000e+00, 4.23258691e-14, 1.92051255e-11],
       [4.30879705e-01, 5.69120295e-01, 9.66618838e-27]])
```

ä½¿ç”¨`predict`æ–¹æ³•çš„é¢„æµ‹æ˜¯

```
# my_gauss.predict([[-2, 5], [0,0], [6, -0.3]])
array([2, 0, 1])
```

ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ scikit-learnã€‚æ‰”è¿›ä¸€äº›ä»£ç 

```
from sklearn.naive_bayes import GaussianNB

gnb = GaussianNB()
gnb.fit(X, y)
gnb.predict_proba([[-2, 5], [0,0], [6, -0.3]])
```

ç”Ÿäº§

```
array([[8.06314158e-07, 1.36201959e-04, 9.99862992e-01],
       [1.00000000e+00, 4.23259111e-14, 1.92051343e-11],
       [4.30879698e-01, 5.69120302e-01, 9.66619630e-27]])
```

è¿™äº›æ•°å­—çœ‹èµ·æ¥æœ‰ç‚¹ç±»ä¼¼äºæˆ‘ä»¬çš„åˆ†ç±»å™¨ï¼Œä½†å®ƒä»¬åœ¨æœ€åå‡ ä¸ªæ˜¾ç¤ºçš„æ•°å­—ä¸­æœ‰ç‚¹åç¦»ã€‚æˆ‘ä»¬åšé”™ä»€ä¹ˆäº†å—ï¼Ÿ**å¦**sci kit-learn ç‰ˆæœ¬åªæ˜¯ä½¿ç”¨äº†å¦ä¸€ä¸ªè¶…å‚æ•°`var_smoothing=1e-09`ã€‚å¦‚æœæˆ‘ä»¬æŠŠè¿™ä¸ªè®¾ä¸º 0ï¼Œæˆ‘ä»¬å°±èƒ½å¾—åˆ°å‡†ç¡®çš„æ•°å­—ã€‚å®Œç¾ï¼

çœ‹çœ‹æˆ‘ä»¬çš„åˆ†ç±»å™¨çš„å†³ç­–åŒºåŸŸã€‚æˆ‘è¿˜æ ‡è®°äº†æˆ‘ä»¬ç”¨äºæµ‹è¯•çš„ä¸‰ä¸ªç‚¹ã€‚é è¿‘è¾¹ç•Œçš„é‚£ä¸ªç‚¹åªæœ‰ 56.9%çš„æœºä¼šå±äºçº¢è‰²ç±»ï¼Œæ­£å¦‚æ‚¨ä»`predict_proba`è¾“å‡ºä¸­çœ‹åˆ°çš„ã€‚å¦å¤–ä¸¤ç‚¹è¢«å½’ç±»ä¸ºå…·æœ‰é«˜å¾—å¤šçš„ç½®ä¿¡åº¦ã€‚

![](img/376de54604dc54295248e71f90cd0642.png)

å…·æœ‰ 3 ä¸ªæ–°ç‚¹çš„å†³ç­–åŒºåŸŸã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

# ç»“è®º

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å·²ç»äº†è§£äº†é«˜æ–¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨çš„å·¥ä½œåŸç†ï¼Œå¹¶ç›´è§‚åœ°è§£é‡Šäº†ä¸ºä»€ä¹ˆè¦è¿™æ ·è®¾è®¡â€”â€”è¿™æ˜¯ä¸€ç§å¯¹æ„Ÿå…´è¶£çš„æ¦‚ç‡è¿›è¡Œå»ºæ¨¡çš„ç›´æ¥æ–¹æ³•ã€‚ä¸é€»è¾‘å›å½’æ¯”è¾ƒ:åœ¨é€»è¾‘å›å½’ä¸­ï¼Œæ¦‚ç‡æ˜¯ç”¨ä¸€ä¸ªçº¿æ€§å‡½æ•°æ¥æ¨¡æ‹Ÿçš„ï¼Œåœ¨è¿™ä¸ªçº¿æ€§å‡½æ•°ä¸Šåº”ç”¨äº†ä¸€ä¸ª sigmoid å‡½æ•°ã€‚è¿™ä»ç„¶æ˜¯ä¸€ä¸ªç®€å•çš„æ¨¡å‹ï¼Œä½†æ„Ÿè§‰ä¸å¦‚æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨è‡ªç„¶ã€‚

æˆ‘ä»¬ç»§ç»­è®¡ç®—äº†ä¸€äº›ä¾‹å­ï¼Œå¹¶æ”¶é›†äº†ä¸€äº›æœ‰ç”¨çš„ä»£ç ã€‚æœ€åï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ä¸ªå®Œæ•´çš„é«˜æ–¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼Œå®ƒä¸ scikit-learn é…åˆå¾—å¾ˆå¥½ã€‚ä¾‹å¦‚ï¼Œè¿™æ„å‘³ç€æ‚¨å¯ä»¥åœ¨ç®¡é“æˆ–ç½‘æ ¼æœç´¢ä¸­ä½¿ç”¨å®ƒã€‚

æœ€åï¼Œæˆ‘ä»¬é€šè¿‡å¯¼å…¥ scikit-learn è‡ªå·±çš„é«˜æ–¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨è¿›è¡Œäº†ä¸€ä¸ªå°çš„å¥å…¨æ€§æ£€æŸ¥ï¼Œå¹¶æµ‹è¯•æˆ‘ä»¬å’Œ scikit-learn çš„åˆ†ç±»å™¨æ˜¯å¦äº§ç”Ÿç›¸åŒçš„ç»“æœã€‚è¿™æ¬¡æµ‹è¯•æ˜¯æˆåŠŸçš„ã€‚ğŸ˜

æˆ‘å¸Œæœ›ä½ ä»Šå¤©å­¦åˆ°äº†æ–°çš„ã€æœ‰è¶£çš„ã€æœ‰ç”¨çš„ä¸œè¥¿ã€‚æ„Ÿè°¢é˜…è¯»ï¼

**ä½œä¸ºæœ€åä¸€ç‚¹ï¼Œå¦‚æœä½ **

1.  **æƒ³æ”¯æŒæˆ‘å¤šå†™ç‚¹æœºå™¨å­¦ä¹ å’Œ**
2.  **æ— è®ºå¦‚ä½•ï¼Œè®¡åˆ’è·å¾—ä¸€ä¸ªä¸­ç­‰è®¢é˜…ï¼Œ**

**ä¸ºä»€ä¹ˆä¸åš** [**é€šè¿‡è¿™ä¸ªç¯èŠ‚**](https://dr-robert-kuebler.medium.com/membership) **ï¼Ÿè¿™å°†å¯¹æˆ‘å¸®åŠ©å¾ˆå¤§ï¼ğŸ˜Š**

*è¯´ç™½äº†ï¼Œç»™ä½ çš„ä»·æ ¼ä¸å˜ï¼Œä½†å¤§çº¦ä¸€åŠçš„è®¢é˜…è´¹ç›´æ¥å½’æˆ‘ã€‚*

éå¸¸æ„Ÿè°¢ï¼Œå¦‚æœä½ è€ƒè™‘æ”¯æŒæˆ‘çš„è¯ï¼

> *æœ‰é—®é¢˜å°±åœ¨*[*LinkedIn*](https://www.linkedin.com/in/dr-robert-k%C3%BCbler-983859150/)*ä¸Šå†™æˆ‘ï¼*