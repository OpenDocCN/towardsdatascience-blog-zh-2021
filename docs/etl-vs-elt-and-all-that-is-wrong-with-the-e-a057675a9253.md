# ETL 与 ELT 以及“E”的所有错误之处

> 原文：<https://towardsdatascience.com/etl-vs-elt-and-all-that-is-wrong-with-the-e-a057675a9253?source=collection_archive---------26----------------------->

## 了解在数据摄取期间执行转换以及提取尚未准备好或准备用于外部消费的数据的含义

![](img/7a3c624cece5156ba8f454c8dd3bb0a4.png)

*图像经由* [*像素许可*](https://pixabay.com/nl/illustrations/data-record-chain-blok-keten-5716733/) *下的* [像素许可](https://pixabay.com/service/license/)

ETL(Extract Transform Load)已经成为数据集成过程的代名词，尤其是在数据仓库中。ETL 非常成功，许多工具都专注于此。但是产品/工具公司销售他们的产品，这不一定总是一个更好的架构选择。本文讨论了 ETL 中概念的一些问题——中间的转换 T 和提取 e。

## 万能的 T

该行业已经意识到，在旅途中执行转换可能会导致问题。此处见、[此处见](https://www.datanami.com/2019/09/03/can-we-stop-doing-etl-yet/)，还有很多其他的参考文献。起初，这听起来可能是件好事。我们准备并加载数据，以便更容易进行进一步的分析和报告。当然，它传达了这一点。一切都很好，除了事情变坏或者需要进行新的分析工作。

1.  当事情变得糟糕时，例如 BI 报告或分析输出严重不匹配，以至于偏差是明显的错误，那么有 3 个地方可能会出错。首先，在分析期间，其次，在转换 T 期间，第三，在源系统本身。更糟糕的是，那些从事业务系统工作的人和从事数据分析工作的人之间开始相互指责。如果没有 T，那么就更容易找到问题——无论是在分析期间还是在源中。
2.  当为一个分析用例准备的数据在另一个分析用例中作为源被重用时，它可能只是一个错误的起点。更糟糕的是，如果这个测试是基于某个组织范围的[规范数据模型](https://www.infoq.com/news/2015/04/canonical-data-models/#)进行的。如果没有 T，分析团队将执行特定于上下文的转换。
3.  在摄取期间执行的 T 可能会修改不再与源数据匹配的数据。这可能会导致对数据的误解，因为源系统中的人无法解释它，如果没有正确的 T 血统和文档，数据接收人员也可能无法解释它。这可能是错误的另一个原因。
4.  此外，业务总是在变化，客户需求在变化，因此 IT 系统和底层数据也在变化。纳入这一变化要求数据摄取团队调整他们在摄取过程中放置的 T。这种适应将在所有下游分析中产生连锁反应。避免这种情况将需要所有的分析工作来适应新的 T，因为新的数据进来了——这反过来意味着灵活性大大降低。
5.  执行测试的人需要源系统和目标系统的领域知识(例如数据仓库)。由于这些原因，一个数据摄取团队对不属于他们的数据执行 T 类似于一个[可疑的集成团队](https://medium.com/nick-tune-tech-strategy-blog/architecture-ownership-patterns-for-team-topologies-part-2-single-team-patterns-943d31854285) ( *是一个独立的主题*)。

我们能做得更好吗？也许吧。

## 保持数据管道简单

另一方面，ELT，Extract Load Transform，确保装载到 staging 的数据总是与源系统中的数据相同。然后，由每个分析工作量来获取数据并应用特定于上下文测试。注意，这里的关键字是“*特定于上下文的*”。每个工作负载的起点是原始数据，因此是每个分析团队，并与源系统团队进行交互，以进行解释或任何其他合作。摄取团队的中间人在这样的会议中消失了。

这使得摄取团队的工作也变得更容易，因为他们不再是中间人，而这很可能是没有人想成为的。他们只创建数据管道，并对其进行监控，确保他们做到这一点。

> 把这比作邮递员送信。这里的邮递员是数据摄取的一个类比。邮递员只是“按原样”投递信件。如果他/她开始拆信，修改错别字和文本，然后做翻译，我想没有人会喜欢这样。收件人的工作是按照要求做这些事情。

所以 ELT 更好。但是还有一个问题，这个问题是关于 e 的概念。

## 为什么不去 E？

使用 E 或 Extract，数据管道从源系统中“提取”数据，这在大多数情况下直接发生在底层数据库或数据存储中。你现在明白问题了吗？

我看到几个。

1.  公开和共享应用程序的底层数据会产生严重的*依赖性*。这意味着应用程序团队需要意识到一些数据湖/数据仓库正在获取这些数据，如果他们改变数据模型，可能会在那里引起麻烦。它带走了独立。它降低了应用程序团队的敏捷性，使他们无法快速响应新的客户需求。
2.  这种依赖导致应用平台和数据平台的*所有权*的*不明确。数据模型和数据应该因为业务流程中有新的需求而更新，还是应该因为有新的分析需求而更新？在这两种情况下，另一方都会受到不必要的影响。*
3.  *e 表示外部上的*数据很可能与内部*上的*数据相同。这意味着消费者接受应用程序(和域)的*内部*表示。这意味着某些数据可能没有标准化，即使用某种特定的日期格式，而不是 UNIX 秒(或毫秒)或 ISO 日期格式。这也意味着身份可能是内部的，例如应用程序的内部客户 id，而不是来自客户主数据系统的客户 id。**
4.  *此外，内部的*数据是“可变的”,因为有一个应用程序在其上运行。这意味着数据可能会更新，模型也可能会改变(尤其是在无模式数据库上，例如 Mongo DB、Cosmos DB 或 Dynamo DB 等。).这会造成不匹配，数据管道会出错而失败。*不是每一个变化都应该或者需要反映到外面。*但是，通过在内部*公开*数据，应用程序中的每一项更改都需要更新数据管道和存储区域，并且可能进一步更新分析工作负载。**

## *更好的方法*

*它们应该只读取可用的内容，而不是通过数据管道来提取数据。应用程序应该公开它们为“外部消费”准备的数据，并以确保[隐含期望](https://martinfowler.com/articles/data-monolith-to-mesh.html#DomainDataAsAProduct)(例如，质量、可信度、可互操作性等)的方式公开。)的任何此类暴露数据。*

*应用程序有义务实现[产品思维](/effective-data-management-with-domain-driven-and-product-thinking-approach-fc4ace13bddd)，并确保公开的数据质量良好，基于任何适用的数据标准进行标准化，并遵循相关的模式定义。实际上，这种方法可以是 API 或事件，甚至可以是包含供外部使用的数据副本的中间辅助数据库。*

***无论采用哪种方法，最重要的是应用程序公开它“准备好”供“外部”使用的数据，而不是数据管道直接从源数据库中提取它想要的任何数据。***

*数据管道不再执行任何操作。它们仅通过调用 API 或订阅事件等方式将数据加载到 staging 中。*

> *回到邮递员的比喻，他/她递送已经提供给他/她的东西。那也在一个有适当邮票的包裹里。邮递员不会走进人们的房子，在你写信的时候拖着信去投递。作为一个作家，你可以写尽可能多的信，重写，但只投递那封必须装在贴有邮票的信封里的信。邮差挑的就是那个。*
> 
> *换句话说，一个邮递员既不执行 E，也不执行 t。*

*所以，接下来就是 LT 了，以后需要的人可以使用它。*