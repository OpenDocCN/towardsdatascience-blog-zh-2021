# Python 中的要素工程

> 原文：<https://towardsdatascience.com/feature-engineering-in-python-2fdb9bb8ee7a?source=collection_archive---------1----------------------->

## 超越基础

![](img/15bbe7b1675743f3261ee67e6e15c727.png)

安托万·道特里在 [Unsplash](https://unsplash.com/) 上拍摄的照片

在我十多年作为数据科学家的经历中，我的经验很大程度上同意吴恩达的说法，“应用机器学习基本上是特征工程。”从我职业生涯的一开始，在 SAS 建立信用卡欺诈模型，我作为数据科学家的大部分价值来自于我设计新功能和捕捉数据中观察到的业务见解和行为以帮助模型识别目标的能力。Pedro Domingos 博士的声明也与这种观点一致，“在一天结束时，一些机器学习项目成功，一些失败。有什么区别？最重要的因素无疑是所使用的功能。”

## 通用特征工程内容

尽管有这些经验和该领域领导者的声明，特征工程内容仍然缺乏。虽然在谷歌上搜索“功能工程”会返回许多页面，但基本内容非常相似，并且只关注几个主题:

*   处理缺失值
*   处理异常值
*   宁滨数值变量
*   编码分类特征
*   数字变换
*   缩放数字特征
*   提取部分日期

## 这个内容的问题是

这些都是重要的主题，并且在许多情况下，对于底层的机器学习算法甚至能够处理数据都是必要的。然而，它们在三个主要方面有所欠缺。首先，在某些情况下，他们盲目地应用这些技术，却不知道为什么。许多博客讨论了如何在建模前缩放数字要素。这不是真的。基于树的方法，例如 XGBoost、LightGBM 等。对缩放不变。 [Praveen Thenraj](https://medium.com/@praveenmec67) 在他关于数据科学的[帖子中给出了一个很好的例子。](/do-decision-trees-need-feature-scaling-97809eaa60c6)

第二，虽然需要这种技术，但在很多问题中，这种技术并不实用，因此需要其他技术。这方面的一个例子是对分类特征进行编码。大多数关于特征工程的讨论都解释了一次性或虚拟编码，并且经常解释标签编码。他们很少讨论高基数分类变量的挑战。我经常在处理邮政编码时看到这种情况，但在处理医疗数据和 ICD-9 或 ICD-10 诊断代码时也会出现这种情况。一键式编码邮政编码可能会产生 40，000 多种新功能。这不是一个实用的解决方案。理解这些代码的结构可以使它们达到更高的聚合级别。即使在聚合之后，对于一键编码或标签编码来说，可能有太多的类别是有用的。此外，一些分类变量没有可减少所需类别数量的易于识别的集合。目标编码或留一编码可以处理这些高基数分类特征。虽然一些特性工程博客讨论了这些技术，但是他们经常没有强调它们在这种情况下的有用性或者一次性编码的不可行性。

## 特征工程不止于此。

最后，也是最关键的，特性工程远不止这些。当人们谈论特性工程的力量或特性工程的艺术时，他们并不是指这些标准技术。相反，这项工作认识到邮政编码可以聚合到城市、州、DMA 等。并执行这些聚合。通过将这些汇总与该地点的所有采购相结合，可以进一步执行这一工程，以更好地了解当地市场。最后，个人购买和当地整体市场的比较。这只是冰山一角，是数据科学过程中我最喜欢的部分。

公平地说，如果不讨论实际的建模问题，很难展示这种特征工程的例子。但是在讨论特征工程时完全忽略它可能会对它的范围留下一个错误的印象。此外，还有许多强大的技术可以应用于一系列广泛的问题。

## 时间序列数据的特征工程

例如，许多数据科学问题具有时间序列特征。这并不是说这些问题是时间序列问题，而是有重复的观察结果需要汇总在一起，以表示感兴趣的潜在行为。在构建客户分析模型时(如客户流失、终身价值)，单个交易及其随时间变化的方式非常重要。一个特征工程博客可以分享代码，展示如何为此计算公共特征，如下所示。

当处理单个客户在一段时间内的多项观察数据时，聚合这些数据的最常用技术之一是通过滚动窗口，然后在 pandas 中进行聚合。在这种情况下，将创建一个每周聚合，并创建最小、平均、最大和标准偏差。

```
weekly_resample = df.rolling('7D')
aggregated_df = weekly_resample.agg(['min', 'mean', 'max', 'std'])
aggregated_df.columns = ['_'.join(col).strip() + '_week' **for** col **in** 
                         aggregated_df.columns.values]
```

注意，要实现这一点，dataframe `df`需要日期集作为它的索引。

```
df.set_index('date', inplace=**True**)
```

使用滚动窗口，`aggregated_df`包含每笔交易的记录，其中汇总了前七天的所有交易。相反，如果每周之后都需要进行预测，则需要额外的工作来过滤出该周之前的最后一条记录。熊猫用`resample`支持这个用例。如果改为运行以下代码，则每周返回一条记录。

```
weekly_resample = df.resample('7D', 
                              origin=pd.to_datetime('2021-01-03'))
aggregated_df = weekly_resample.agg(['min', 'mean', 'max', 'std'])
aggregated_df.columns = ['_'.join(col).strip() + '_week' **for** col **in** aggregated_df.columns.values]
```

由于 2021 年 1 月 3 日是星期天，所以聚合从每个星期天开始，并包括一周中其余时间的所有交易。如果星期日之前的七天是所期望的，那么可以进行下面的改变。

```
weekly_resample = df.resample('7D', 
                              origin=pd.to_datetime('2021-01-03'),
                              lavel='right')
```

一旦创建了这些每周聚合(任一类型)，这些聚合的变化率可能会非常强大。从物理学的角度来看，这是基础特征的速度，我们可以查看多个时间段的变化率。

```
aggregated_df['velocity_1wk'] = (aggregated_df['mean_week'] - 
                              aggregated_df['mean_week'].shift(1))/7 aggregated_df['velocity_4wk'] = (aggregated_df['mean_week'] - 
                             aggregated_df['mean_week'].shift(4))/28
```

这给出了一周和四周的周均值变化率。接下来，可以计算这个变化率(加速度)的变化率。

```
aggregated_df['acceleration_1wk'] = (aggregated_df['velocity_1wk'] - 
                           aggregated_df['velocity_1wk'].shift(1))/7
```

## 50 多个免费功能工程教程

像这样的技术可以用来构建能够表示感兴趣的潜在行为的特征。在 [Rasgo](https://www.rasgoml.com/) ，我们希望通过分享这些技术来帮助数据科学界。为了做到这一点，我们创建了一个[免费库，专门用于功能工程教程](https://hubs.la/Q0100qK30)，其中包含功能工程代码，包括上面的例子，作为 Jupyter 笔记本。除了功能工程，还有以下示例:

*   特征分析和 EDA
*   数据清理
*   列车测试分离
*   特征重要性
*   特征选择