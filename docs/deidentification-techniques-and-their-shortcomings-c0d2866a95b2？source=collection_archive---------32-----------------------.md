# 去识别技术及其缺点

> 原文：<https://towardsdatascience.com/deidentification-techniques-and-their-shortcomings-c0d2866a95b2?source=collection_archive---------32----------------------->

## 一场失败的捉迷藏游戏？

![](img/8aa28635babdc281c79a905fd3156336.png)

由 [Dmitry Ratushny](https://unsplash.com/@ratushny?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 在 [Unsplash](https://unsplash.com/s/photos/hide-and-seek?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄的照片

如果一条关于你的信息最终出现在公共数据集中，并被利用来羞辱、冒充或勒索你，该怎么办？这看起来不太可能，但是要小心:利用埋藏在数百万份其他记录中的“匿名”数据，[识别法官的色情偏好](https://www.theguardian.com/technology/2017/aug/01/data-browsing-habits-brokers)和[推断未出柜母亲的性取向](https://www.wired.com/2009/12/netflix-privacy-lawsuit/)已经成为可能。本文介绍并批判性地评价了各种去识别方法。

## 归纳

数据匿名大致有两种方式。首先是一般化。通过降低信息的粒度，这种方法旨在切断数据主体和可能将她从数据中分离出来的特殊值之间的关联。

## k-匿名

从统计学上讲，一般化在多大程度上打破了数据主体和数据之间的联系是由 k-匿名性来表示的。萨马拉蒂和斯威尼在 1998 年的论文中介绍了这个概念，它标志着“关于通过链接进行推断的数据的保护程度。”

这里的`k`是指一个集合中数据主体的数量。如果对于任何随机选择的个体，至少有`k-1`个人具有相同的属性，我们可以说我们已经达到了 k-匿名。简而言之，如果数据集中的每个人在地址、性别和生日(也称为“准标识符”)等属性方面共享相同的值，这些属性不是唯一的，但在适当组合时容易被重新标识，我们将无法区分谁是谁。

为了说明这个想法，让我们说有关的属性是邮政编码。如实披露样本——例如`SW1A 2AA`——可以相对容易地追溯到居民，即当时的英国首相。然而，如果它被推广到`SW`，首相的数据将会在伦敦西南 [94 万居民](https://www.plumplot.co.uk/South-West-London-population.html)的人群中变得无法辨认，这些人拥有相同的、经过消毒的邮政编码值。

## l-多样性

但是如果`k`人共有的特征本身是敏感的呢？例如，如果一个 20 人的数据集中的 20 个人都检测出 HIV 阳性，那么没有一个病人会仅仅因为这个原因而从其他人中脱颖而出。然而，在这里，k-匿名实际上是公开承认，这张桌子上的任何人都感染了病毒。潜在的对手只需要确定目标数据主体是否在表中就可以破坏隐私。

这是由于敏感财产缺乏多样性；也就是说，表中只披露了艾滋病病毒感染状况，没有披露其他医疗状况。为了对手的方便，k-匿名以不可区分性为交换条件使记录均匀化。这就是 l 多样性来拯救的地方。

由 Machanavajjhala 等人在 2006 年提出的 l-diversity 是另一种隐私度量，它表明敏感信息的变化程度。参数`l`表示“良好表示的”敏感值的数量，这种去识别方法增加了熵，有助于挫败再识别攻击。例如，如果数据集包含其他病毒状态的账户，如流感、天花或埃博拉，对手将无法如此容易地得出结论，即她的目标必须携带艾滋病毒，因为它属于该表。

取而代之的是，对手需要`l-1`的相关背景信息来成功辨别什么样的特征适用于她的目标。换句话说，她必须知道她的目标的流感、天花和埃博拉状态，才能推断出她的目标的 HIV 状态，因为 l-diversity 表现在将包含每个数据主体的病毒状态的不同组合。这种方法的重要之处在于，数据管理员有权决定对手需要多少先验知识才能重新识别目标。

## 噪声添加

第二种匿名数据的方法是添加噪声。这种技术将随机的数学杂质添加到查询的输出中，以隐藏由于数据集中元组的添加或省略而产生的差异。这使得能够对一般人群进行统计分析，同时阻止任何确定个人数据是否包括在表中的尝试。虽然通过不同的方式，噪声添加和一般化一样，最终以受控的方式破坏数据分辨率。

## 差异隐私

如果数据库的返回值由于元组的存在或不存在而变化很小，则数据库是隐私保护的，这一点被差分隐私的概念所捕获。这是一种正式的、全方位的保证，任何人——即使是最古怪、最不受欢迎的人——都几乎不会影响产量。换句话说，无论数据主体选择加入还是选择不加入数据集，对手造成伤害的机会或多或少是相同的。例如，一个人获得保险覆盖的可能性[不会受到保险提供商对不同私人数据库的咨询的显著影响](https://www.microsoft.com/en-us/research/publication/a-firm-foundation-for-private-data-analysis/)。

差别隐私引发了双重分析。首先，这个隐私的定义构成了对[达勒纽斯 1977 年](https://archives.vrdc.cornell.edu/info7470/2011/Readings/dalenius-1977.pdf)的欲望的重大修改。这种迫切需要可以概括为:“不访问数据库就无法从数据库中了解到的任何个人信息都不应该从数据库中了解到，”这决定了当代的隐私概念。但是，当任何统计数据库的存在理由都是为了让浏览者了解她不知道的事情时，它却过度地专注于最小化对手的信息增益。关于 Dalenius 的主张，隐瞒的必要性和披露的必要性之间的冲突证明是无法补救的，理由有三。

1.  统计数据库缺少解密密钥来防止对手伪装成合法用户。与密码系统不同，窃听者和消息的预期接收者之间没有逻辑界限。
2.  即使访问数据库确实带来了观众信念的实质性转变，也不总是侵犯隐私。例如，如果有人以前认为 50%的青少年每周至少吸烟一次，但得知实际数字接近 1%，她会彻底改变她的想法，但不一定会侵犯任何人的隐私。
3.  有了辅助信息，即使不查询相关数据库，隐私泄露仍然可能发生。例如，如果攻击者已经知道她居住在英国的目标比瑞典的平均年薪低 10，000，她可以通过查找瑞典的统计数据来推断她的目标的工资，即使她的目标甚至不包括在该数据集中。

相比之下，差别隐私设置了一个新的隐私目标:一个人加入数据库是否会增加其信息被用来对付自己的风险？这侧重于被包括在数据库中可能产生的实际危害，而不是试图控制对手的知识，这更具挑战性，如果现实的话。

其次，差别隐私意识到隐私不是一个二元概念，在这个概念中，数据要么被泄露，要么不被泄露。相反，它采用了一个带有参数`ϵ`的累积表达式来量化处理一个人的数据如何更经常地将她的信息置于更大的风险中。该参数代表“隐私损失”，其可接受的阈值应该进行社会辩论。

## 差异隐私的限制

尽管有这些优势，差异隐私并不能提供绝对的隐私保证。至少有四个问题[要求建立某些假设](https://dl.acm.org/doi/abs/10.1145/1989323.1989345)和前提条件，以使差分隐私以最佳方式运行。

首先，差分隐私的性能可能取决于数据库的大小。这是该机制关注消除数据库中单个元组的影响的自然结果。表格中的样本越多，个人就变得越微不足道，当然，差异隐私的目的是防止个人脱颖而出或造成整体差异。作为结果，可能添加的假设是，数据库虽然不是致命的，但应该保持一定的规模。

其次，差别隐私并不能保护“参与证据”免受推断。没错，它可以用噪音掩盖一个元组，但如果隐藏的记录周围散布着参与的痕迹呢？社交网络就是一个很好的例子。简单地删除一个元组已经被证明是不够的，因为在一个网络结构中，一个人会产生有机的联系，暗示她的元组的存在，即使它已经被隐藏——例如，共同朋友的列表和在线互动的星座。因此，差分隐私需要另一个假设，即所有元组必须相互独立才能按预期工作。

第三，差别隐私，虽然不是临时的，但并不能有效对抗任何对手。它必须专注于一个狭窄的攻击者类别，以提供有意义的抵抗，也许与直觉相反，它对那些知识较少的人相对较弱。也就是说，一个有差别的私有数据库最终会无意中把更多的敏感信息泄露给一个先验知识较少的人，而不是一个除了一个元组之外什么都知道的人。这是因为隐藏更细粒度的记录所需的噪声级别更低，或者更具体地说，噪声应该如何集中在单个元组上，而不是表的更大部分。对于不知道大部分数据的对手来说，差异私有表可能是一座数据金矿。

第四，差分隐私，尽管其本身具有鲁棒性，但与隐私的其他定义和实现并不协调。如果对手的背景知识不是由记录的任意子集组成，而是由另一种合理的类型组成，例如，人口普查数据(其中没有注入噪声，完整性、透明性和准确性是最重要的)，差分隐私可能会在灾难性的规模上受到损害，从而允许完整地重建最新的表。