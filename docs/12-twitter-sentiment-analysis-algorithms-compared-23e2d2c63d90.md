# 比较了 12 种 Twitter 情感分析算法

> 原文：<https://towardsdatascience.com/12-twitter-sentiment-analysis-algorithms-compared-23e2d2c63d90?source=collection_archive---------31----------------------->

## 12 种情感分析算法在推文分类的准确性上进行了比较。fasText 深度学习系统胜出。

![](img/0268d78363479419c230a36f62877368.png)

图片:Farknot Architect / iStockPhoto

情感分析用于确定一段文本中的情感是积极的、消极的还是中性的。情感分析是自然语言处理的一种形式，也是自然语言处理技术的一部分，被称为信息提取的 T2。

数据科学家的一项工作是为给定的任务选择最佳算法。通常，最好的方法是尝试许多不同的算法，看看什么效果最好。

在本文中，我将比较十几种使用 Python 编程语言的情感分析技术，包括 Google 和 Amazon 的现成情感分析服务。这些技术的 Python 代码可以在[Github 库](https://github.com/sshwartz/Twitter-sentiment-analysis-code)中找到。

# Twitter 情感分析数据源

本文中用于分析的数据集是一组关于消费者对航空公司表现印象的[推文](https://www.kaggle.com/crowdflower/twitter-airline-sentiment)。每条推文都被分为正面、负面或中性情绪。12 种情绪分析算法中的每一种都为每条推文计算一种情绪。然后，基于数据集中的情感得分，将计算出的情感评分为正确或不正确。使用的总体衡量标准是准确性或算法正确计算的推文百分比。

# 情感分析算法

12 种情感分析算法可以分为四类:

*   情感词汇的使用
*   现成的情感分析系统，包括亚马逊理解、谷歌云服务和斯坦福 CoreNLP 系统
*   经典机器学习算法
*   深度学习算法

# 情感词汇

第一种算法将推文中的每个单词与被标记为积极或消极情绪的单词数据库进行比较。有许多这样的数据库。为了这个分析，我从 [Kaggle](https://www.kaggle.com/nltkdata/opinion-lexicon) 下载了一个正面和负面情绪词汇的列表。

在将推文中的单词与正面和负面单词列表进行比较之前，首先需要将推文或评论拆分成一个令牌列表(主要是单词)。这是使用 NLTK 分词器完成的。NLTK 是 Python 语言中比较流行的自然语言处理工具包之一。

然后，每个令牌通过修改或移除令牌的管道(即，一系列代码转换)来运行。流水线中使用的步骤是:

*   转换为小写
*   删除推文中的@提及
*   删除超链接
*   删除缩写(例如，将“不会”转换为“会”和“不”
*   删除标点符号
*   将每个标记转换成它的基本形式，这个过程称为变元化。比如“动”转换为“动”，“脚”转换为“足”。NLTK 中可用的 WordNet Lemmatizer 就是为了这个目的而使用的。这个 lemmatizer 接受一个标记作为输入，不管它是动词、名词还是形容词，这个符号也是由上面提到的单词标记化器产生的。
*   最后，所有像“a”和“the”这样对情感没有贡献的常用词都被删除。这个“停用词”列表是从 NLTK 语料库停用词函数中获得的。

正面和负面列表中的每个单词也通过这条管道，以实现“苹果对苹果”的比较。正面词多于负面词的推文被评为正面。负面词较多的一个被评为负面，如果没有正面/负面词或相同的数字，则被评为中性。

对于推文情感分析，这种方法对推文产生了 46%的准确率。几率准确率 33%。

使用了 15000 多条推文。

# 使用现成系统的 Twitter 情感分析

第二类算法是现成的系统，不需要对数据进行任何预处理。你提供文本，系统计算情感。我测试了来自[谷歌云](https://cloud.google.com/natural-language/docs/analyzing-sentiment)和[亚马逊理解](https://aws.amazon.com/getting-started/hands-on/analyze-sentiment-comprehend/)的情感分析服务。

相对于下面讨论的机器学习算法，这些服务有点劣势，因为它们必须适用于所有类型的文本。相比之下，机器学习算法有机会了解是什么使推文不同于评论和其他文本。

在这一部分，我还测试了斯坦福大学的 CoreNLP 情感分析器。这个工具甚至更不利，因为它试图首先分析句子的句法结构。然而，tweets 经常不合语法，所以这个工具表现不好也就不足为奇了。

这些工具都经过了 15000 多条推文的测试。谷歌情绪分析工具表现最好，为 59%，亚马逊情绪分析工具紧随其后，为 58%，斯坦福工具为 47%。谷歌和亚马逊工具的性能比情感词典算法好得多。

# 使用机器学习算法的推特情感分析

用于情感分析的机器学习算法应该是表现最好的，因为它们有机会根据特定类型的数据(如推文或评论)来定制决策。

然而，机器学习算法需要比情感词典算法或现成算法大得多的数据集。除了 tweets 的测试集，还必须有一组训练数据。

为了创建训练和测试集，我从 3 万条推文开始。然后，使用上面在情感词典算法部分中讨论的流水线，对其中的每一个进行预处理。

一种标准的方法是将这些数据集分成一个训练数据集和一个测试数据集。我将这些数据集分成 70%用于训练，30%用于测试。

然而，积极、消极和中性推文在训练集中的分布远非均匀。积极的推文远远多于消极或中性的推文。这种不平衡的数据可能会导致机器学习系统发现大多数推文都是正面的，并学会依赖对每条推文的正面猜测。

为了解决这个问题，我使用 [SMOTE 过采样](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)向训练集添加负面和中性的例子，这样训练集就有大约 12，000 条正面、12，000 条负面和 12，000 条中性的推文。需要注意的是，在进行训练测试分割后进行过采样是非常重要的。如果它是在训练-测试分割之前完成的，那么在训练和测试集中都会有一些例子，这会导致误导性的高精度数字。

机器学习需要的另一个修改是将每条推文中的标记转换为一组可以由机器学习算法分析的特征。有很多方法可以做到这一点，但我选择了使用单词袋(BOW)方法。BOW 方法的特点是 tweets 中最常见的 2000 个单词。所以每条微博有 2000 个特征。每个特征值仅仅是这个词在 tweet 中出现的次数。当然，每条推文的特征向量非常稀疏，即大多数特征的值为零。

然后，我使用 scikit-learn 将这些 BOW 特征输入到几个机器学习算法中，包括:

*   朴素贝叶斯:众所周知，这种算法适用于许多文本分类问题，并且需要相对较少的训练样本。
*   支持向量机:像朴素贝叶斯分类器一样，支持向量分类器也适用于文本分类，并且需要相对较少的训练样本。
*   决策树:决策树通常在学习分类方面做得很好，并且以决策树的形式产生易于解释的结果。
*   XGBoost:该算法使用一组不同的决策树，称为随机森林。众所周知，这种方法既快速又能达到很高的精度。然而，它不像简单的决策树那样具有可解释性。
*   k-最近邻:该算法通过寻找最接近测试示例的训练示例来工作。

这些 ML 分类器的最高准确度是 XGBoost 和 Naive Bayes，它们都达到了 73%的准确度。线性 SVC 算法以 71%紧随其后。决策树以 63%的比例出现，k 近邻以 38%的比例远远落后。

# 使用深度学习的推特情感分析

深度学习算法通常优于上一节讨论的更经典的机器学习算法。然而，它们通常需要更多的数据。尽管如此，为了进行比较，我对深度学习算法使用了与上一节中对机器学习算法相同的训练和测试数据。

测试了三个[深度学习](https://www.aiperspectives.com/deep-learning)算法:

*   Keras: Keras 是一个简单易用的层，位于 TensorFlow 和其他深度学习框架之上。我使用了一个 3 层顺序网络。我尝试了 10 个、20 个和 50 个历元，尽管在准确性上差别不大。
*   fasText: fasText 是一个由脸书 AI 开发的 NLP 库。这是一个开源、免费、轻量级的库，允许用户学习文本表示和文本分类器。它在标准的通用硬件上工作。模型可以缩小尺寸，甚至适合移动设备。在这里，我也使用了 10、20 和 50 个历元，发现在准确性上没有什么不同。
*   distill BERT:distill BERT 是著名的 BERT 语言模型的一个更小、更快的版本。预训练的 DistilBERT 系统的最后一层用作逻辑回归分类器的一组特征输入，并遵循本 [Google Colab 演示笔记本](https://colab.research.google.com/github/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb)中使用的基本方案。这也是唯一一个我没有在电脑上运行的算法，因为它太耗费资源了。相反，我在我的 Google Colab Pro 帐户上运行了它。即便如此，我也不得不将数据集中的 tweets 数量限制在 10，000 条以内，以避免耗尽内存。

最快的算法表现最好，准确率为 71%。Keras 和 DistilBERT 网络都获得了 68%的分数。

# 获胜者

XGBoost 和 Naive Bayes 算法在测试的 12 种 Twitter 情绪分析方法中准确率最高。深度学习系统可能没有足够的数据来实现最佳性能。也就是说，我已经看到 XGBoost 在至少另一场烘焙比赛中胜过深度学习系统。

可能有许多方法可以提高整体性能。如果我有足够的内存来运行完整的数据集，那么 DistilBERT 方法的性能可能会更好。此外，除了使用预训练的特征，人们还可以做进一步的训练，以在 tweet 数据集上微调系统。最后，代替使用 BOW 方法，使用单词嵌入作为特征可能会产生更好的整体准确性。也许这将是未来文章的主题。