# 机器学习不是模型，而是特征

> 原文：<https://towardsdatascience.com/machine-learning-isnt-models-it-s-features-be87b386db39?source=collection_archive---------27----------------------->

## 为什么特征工程和特征管理对你的 ML 项目和你选择的算法一样重要

![](img/35d58d8ecca414fc8bf96383f2c2f2ee.png)

图片经由 [emojoez](https://stock.adobe.com/contributor/203936817/emojoez?load_type=author&prev_url=detail) /Adobe Stock 在 Zer0 到 5ive 的许可下

从 Scikit-learn 到 Keras 再到 PyTorch，关于数据科学和 ML 主题的文章和教程数不胜数。只需几个小时，你就可以创建一个 GAN 来生成你看起来像卡通人物的图像，或者创建一个 LSTM 来创建文本消息，就好像它们来自你一样。这些都是具有惊人用例的强大技术。但是有一个关键点，许多教程都忽略了:ML 的力量并不来自于模型，它来自于*数据*，更具体地说，来自于*特性。*

> *“想出新功能是困难的，耗时的，需要专业知识。‘应用机器学习’基本上是特征工程”。~吴恩达*

# 为什么功能不是更…有特色？

你会发现在整个 ML 领域的可用资源中存在同样的疏忽。例如，Coursera 的*机器学习入门*课程有十个部分，但其中只有两个部分是关于数据工程的，涵盖的主题是围绕数据结构化的数学概念(离群点去除和特征缩放)，而不是特征创建。麻省理工学院非常受欢迎。S191 课程(这是我个人推荐的)是对深度学习领域的深入研究，但在其 10 门课程中，数据管理或工程方面的课程完全为零。吴恩达著名的斯坦福机器学习课程是现有的最好的机器学习课程之一，在 112 场讲座中，仅有少数几场专门讲述了数据的重要性。在一个关于异常检测的视频中，Andrew 说，“事实证明[……]对[一个模型]的表现有巨大影响的事情之一是你使用什么样的功能。”

作为一个 ML 社区，我们同样关注我们的技术努力，构建难以置信的建模工具，而忽略了提供给它们的数据。我们已经几乎自动化了构建经典 ML 模型的过程:遍历数千个 Sklearn 算法只需要几行代码，而以一种干净的方式跟踪这些信息只需要几行代码。Keras 极大地简化和民主化了深度学习框架，即使是初学者也能快速进步。但是，所有这些模型、框架和演示都假定了一条至关重要的信息:您的数据已经过预处理，可以放入 CSV 文件中。

# **没有数据就没有数据科学**

对于学习来说，这是一笔巨大的财富，可以消除很多入门的摩擦。但实际上，这是一个几乎永远不会成立的假设。我经常和新毕业的大学生一起做真实世界的数据科学项目，我听到的最常见的反馈是，“我不敢相信我们花了这么多时间来预处理数据。我在学校里从来没学过这些。”这让我想到了大学和在线课程在未来的课程中需要考虑的两点:

1.  数据管理是数据科学工作的主要部分。
2.  数据科学家需要学习如何管理数据并为他们的模型构建有价值的特征。

Splice Machine 的首席数据科学家 Nirek Sharma 告诉我，“数据管理至关重要，但却常常被低估。如果在工程和预处理阶段不密切关注细节，建模阶段将会受到阻碍。”

当被问及他的个人经历时，Nirek 说他把大约 70%的时间花在数据工程上，30%的时间花在为客户的项目建模上。即使在“完美”数据的基础上构建演示模型，他也要花费高达 60%的时间进行特征工程。

特征工程不是简单的需要完成的平凡任务。它对你的模型质量有着巨大的影响。我一次又一次地看到，对精心设计的功能进行线性回归的项目比使用简单预处理的 Keras 模型更好。

我想明确一点:机器学习，特别是深度学习方面的进步非常棒，并且有令人难以置信的好用例。这并不是将这些进步投入生产的全部解决方案。

# **是时候再造特征工程了**

所以特性很重要。难道我们不能自动化吗？有一些令人敬畏的开源自动化功能工程项目，甚至有些项目使用大数据框架，如 Spark 和 Dask。嗯，也许吧。关于你是否能完全自动化特征工程，有相当多的争论。领域专业知识是真实的，难以复制，但除此之外，有针对性的基于时间的功能可以为您的模型添加许多信号，并且可能很难在原始数据的海洋中找到。

然而，就本文的目的而言，假设是的，您可以完全自动化特征提取和工程的过程。那个*仍然*不是故事的全部，因为现在你有了一个*静态*特征集，它基于现在*的数据*。数据不是一成不变的，在构建模型时你也不能假设它是一成不变的。如果你在一组数据上用一组特定的超参数建立一个模型，然后第二天在一组**略有不同的**数据上用**相同的**超参数重建那个模型，你现在有一个*不同的*模型。

数据多了会怎么样？当数据改变时会发生什么？如果您找到另一个数据集，可以将其与当前数据集合并，以驱动更多信号，该怎么办？

当与数据相关时，你如何在你的模型中保持血统、治理和可再现性？

这里需要的是一套类似 DevOps 的工具来管理和自动跟踪 ML 模型的数据，就像软件工程师使用 GitHub 自动跟踪应用程序的代码一样。如果没有这些，你就建立了一个一次性的分析，而不是一个生产机器学习模型。

# **进入特色商店**

![](img/d8b6d13d52bbcb5b781a84c2935685b3.png)

图片经由 [emojoez](https://stock.adobe.com/contributor/203936817/emojoez?load_type=author&prev_url=detail) /Adobe Stock 在 Zer0 到 5ive 的许可下

如果我不提出解决方案就离开这篇文章，那将是不负责任的。要素存储是一种向数据工程工作流添加治理、沿袭和结构的机制。它为数据工程师提供了创建和记录要素的清晰(理想情况下非常灵活)的工作流，并使数据科学家能够重复使用这些要素来创建训练数据集，这些数据集与管道一起保持最新，以修改系统中的新数据。功能存储区在数据周围添加了一个 API 层(可能通过 DataFrame 或 SQL 构造),这使得获取模型的训练数据集变得非常简单…

功能商店有很多好处，比如功能共享、访问控制、实时功能服务等等，其中一些我会在本文[这里](https://medium.com/data-for-ai/5-minimum-requirements-of-an-operational-feature-store-ab1436ca1a2c?sk=11eb65fa5d460cd663040d69c451fe52)中介绍。功能商店领域的另一个重要资源是 featurestore.org，它展示了当前可用的功能商店以及它们之间的一些重要差异。

归根结底，任何给定的机器学习模型的能力都取决于模型的强度*和*用于构建模型的数据质量。作为一个领域，我们需要花更多的时间来强调数据的重要性和最初通知 ML 模型的特性。

资源:

要了解更多关于功能商店的信息，请查看[featurestore.org](http://featurestore.org/)，要查看更深入的分析，请查看功能商店的[技术要求](https://medium.com/data-for-ai/5-minimum-requirements-of-an-operational-feature-store-ab1436ca1a2c?sk=11eb65fa5d460cd663040d69c451fe52)。