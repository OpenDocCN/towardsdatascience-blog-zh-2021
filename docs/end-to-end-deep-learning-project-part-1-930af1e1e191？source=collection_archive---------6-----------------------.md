# ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ é¡¹ç›®:ç¬¬ 1 éƒ¨åˆ†

> åŸæ–‡ï¼š<https://towardsdatascience.com/end-to-end-deep-learning-project-part-1-930af1e1e191?source=collection_archive---------6----------------------->

## åˆå­¦è€…çš„æ•°æ®ç§‘å­¦

## ç”¨ Keras å®ç°è¿ç§»å­¦ä¹ çš„é«˜æ•ˆç½‘ç»œå›¾åƒåˆ†ç±»æ¨¡å‹

*æ³¨æ„:è¿™æ˜¯ä»é›¶å¼€å§‹å®ç°æ·±åº¦å­¦ä¹ é¡¹ç›®çš„ä¸¤éƒ¨åˆ†ç³»åˆ—çš„ç¬¬ä¸€éƒ¨åˆ†ã€‚ç¬¬ 1 éƒ¨åˆ†åŒ…æ‹¬é—®é¢˜é™ˆè¿°çš„è®¾ç½®ã€æ•°æ®é¢„å¤„ç†ã€è¿ç§»å­¦ä¹ èƒŒåçš„ç›´è§‰ã€ç‰¹å¾æå–ã€å¾®è°ƒå’Œæ¨¡å‹è¯„ä¼°ã€‚* [*ç¬¬äºŒéƒ¨åˆ†*](https://varshitasher.medium.com/deploying-an-end-to-end-deep-learning-project-with-few-clicks-part-2-89009cff6f16) *æ¶µç›–äº† Flask app çš„å®ç°åŠå…¶åœ¨ Heroku ä¸Šçš„åç»­éƒ¨ç½²ã€‚ä¸ºäº†ä¿æŒè¿ç»­æ€§ï¼Œè¯·éµå¾ªæ•™ç¨‹ã€‚ä»£ç åœ¨*[*Github*](https://github.com/V-Sher/house-interior-prediction)*ä¸Šã€‚*

![](img/5923fa3c2057259a423d6f9f9e1d7872.png)

ä½ å¯ä»¥åœ¨è¿™é‡Œç©çƒ§ç“¶åº”ç”¨ç¨‹åºã€‚

# ä»‹ç»

æˆ‘éå¸¸å¹¸è¿åœ°åœ¨è¿™æ ·çš„ç¯å¢ƒä¸­å·¥ä½œ:( a)æ•°æ®ç”Ÿæˆçš„åŸºç¡€è®¾æ–½å’Œæ¶æ„éšæ—¶å¯ç”¨,( b)æ•°æ®äº‰è®ºç”±åˆ†æå¸ˆå¤„ç†,( c) MLOps ç”±æ•°æ®å·¥ç¨‹å¸ˆçš„ç‹¬ç«‹éƒ¨é—¨å¤„ç†ã€‚è¿™äº›é¢å¤–æ´¥è´´ç»™äº†æˆ‘è‡ªç”±ï¼Œè®©æˆ‘å¯ä»¥ä¸“æ³¨äºæˆ‘æœ€å–œæ¬¢çš„äº‹æƒ…â€”â€”æ•°æ®å»ºæ¨¡ã€‚è¯è™½å¦‚æ­¤ï¼Œå¦‚æœæˆ‘ä¸å¾—ä¸ç‹¬è‡ªå®Œæˆä¸€ä¸ªå®Œæ•´çš„é¡¹ç›®ï¼Œæˆ‘æ€»æ˜¯æƒ³è‡³å°‘å­¦ä¹ ä¸€äº›åŸºç¡€çŸ¥è¯†ã€‚è¿™æ­£æ˜¯è¿™ç¯‡æ–‡ç« èƒŒåçš„åŠ¨æœºã€‚

æˆ‘å†³å®šå®æ–½ä¸€ä¸ªç«¯åˆ°ç«¯ **DL** é¡¹ç›®ï¼Œå› ä¸ºå­˜åœ¨ä¸€äº›ä¸»è¦ä¸ä»–ä»¬çš„éƒ¨ç½²ç›¸å…³çš„æŒ‘æˆ˜â€”â€”ç”±äºæˆ‘ä»¬å¿…é¡»å¤„ç†çš„æ¨¡å‹çš„å¤§å°â€”â€”ä»¥åŠå¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒä»¥é€‚åº”æˆ‘ä»¬ç‰¹å®šçš„ç”¨ä¾‹ã€‚

è¯¥é¡¹ç›®å°†åŒ…æ‹¬ä¸‰ä¸ªéƒ¨åˆ†:

*   ç¬¬ 1 éƒ¨åˆ†:è®¾ç½®(è™šæ‹Ÿç¯å¢ƒã€è®­ç»ƒæ•°æ®é›†ç­‰ã€‚)ã€æ¨¡å‹è®­ç»ƒ(ç”¨ Keras å¾®è°ƒã€å­¦ä¹ æ›²çº¿ç›‘æ§ç­‰ã€‚)ï¼Œæµ‹è¯•ã€‚
*   ç¬¬ 2 éƒ¨åˆ†:æ„å»º Flask åº”ç”¨ç¨‹åºå¹¶åœ¨ Heroku ä¸Šéƒ¨ç½²ã€‚

è¿™ä¸ªç”±ä¸¤éƒ¨åˆ†ç»„æˆçš„ç³»åˆ—çš„ç›®çš„æ˜¯ä¸ºæ‚¨æä¾›æºä»£ç ã€æç¤ºã€æŠ€å·§ï¼Œå¹¶ç†Ÿæ‚‰ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹æ—¶å¸¸è§çš„è¿è¡Œæ—¶é”™è¯¯ã€‚æˆ‘ç¡®ä¿¡è¿™äº›åœ¨[åœ¨æ•°æ®ç§‘å­¦é¢è¯•](/step-by-step-guide-to-explaining-your-ml-project-during-a-data-science-interview-81dfaaa408bf)ä¸­è§£é‡Šé¡¹ç›®æ—¶ä¼šæ´¾ä¸Šç”¨åœºã€‚

*æé†’:è¿™ç¯‡æ–‡ç« (ä»¥åŠåç»­æ–‡ç« )ä¸­çš„ä¸€äº›å†…å®¹å°†ä¼šè¢«è¯¦ç»†è®¨è®ºï¼Œå› ä¸ºå®ƒçš„ç›®çš„æ˜¯è®©äººä»¬(å°¤å…¶æ˜¯æ—©æœŸç ”ç©¶äººå‘˜)ç†è§£ä¸€äº›è®¾è®¡å†³ç­–èƒŒåçš„åŸå› /åˆ©å¼Šï¼Œå¹¶åœ¨é¢è¯•ä¸­å®Œç¾åœ°å›ç­”è¿™äº›é—®é¢˜ã€‚*

[](https://github.com/V-Sher/house-interior-prediction) [## GitHub-V-Sher/æˆ¿å±‹å†…éƒ¨é¢„æµ‹

### æ­¤æ—¶æ‚¨ä¸èƒ½æ‰§è¡Œè¯¥æ“ä½œã€‚æ‚¨å·²ä½¿ç”¨å¦ä¸€ä¸ªæ ‡ç­¾é¡µæˆ–çª—å£ç™»å½•ã€‚æ‚¨å·²åœ¨å¦ä¸€ä¸ªé€‰é¡¹å¡ä¸­æ³¨é”€ï¼Œæˆ–è€…â€¦

github.com](https://github.com/V-Sher/house-interior-prediction) 

# ç¬¬ 1 éƒ¨åˆ†:è®¾ç½®

## è™šæ‹Ÿç¯å¢ƒ

ä½¿ç”¨ç»ˆç«¯ï¼Œåœ¨é¡¹ç›®ç›®å½•ä¸­åˆ›å»ºä¸€ä¸ªåä¸º`e2eproject`çš„è™šæ‹Ÿç¯å¢ƒï¼Œå¹¶æ¿€æ´»å®ƒã€‚

```
python3 -m venv e2eproject
source e2eproject/bin/activate
```

## èµ„æ–™ç»„

æˆ‘ä»¬å°†ä½¿ç”¨ Kaggle å…¬å¼€å‘å¸ƒçš„[æˆ¿å­æˆ¿é—´æ•°æ®é›†](https://www.kaggle.com/robinreni/house-rooms-image-dataset)ã€‚

æ‚¨å¯ä»¥æ‰‹åŠ¨ä¸‹è½½å®ƒï¼Œç„¶åå°†å®ƒç§»åŠ¨åˆ°æ‚¨çš„é¡¹ç›®ç›®å½•*æˆ–*ä¸­ã€‚åœ¨ç»ˆç«¯ä¸­ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å°†å®ƒç›´æ¥ä¸‹è½½åˆ°æ‚¨çš„é¡¹ç›®ç›®å½•ä¸­ã€‚
*é™„æ³¨:åœ¨è¿è¡Œä»¥ä¸‹å‘½ä»¤ä¹‹å‰ï¼Œç¡®ä¿æ‚¨åœ¨é¡¹ç›®ç›®å½•ä¸­ã€‚*

```
kaggle datasets download -d robinreni/house-rooms-image-dataset â€” unzip
```

## å·¥ä½œ

æˆ‘ä»¬å°†è‡´åŠ›äº**å›¾åƒåˆ†ç±»ä»»åŠ¡**ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†å¼€å‘ä¸€ä¸ªæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥æ£€æµ‹ç»™å®šå§å®¤å›¾åƒçš„æˆ¿å±‹å†…éƒ¨æ˜¯*ç°ä»£(M ç±»)*è¿˜æ˜¯*å¤è€(O ç±»)*ã€‚è¿™ç§æ¨¡å‹å¯ä»¥åœ¨å†æŠµæŠ¼æœŸé—´æˆ–åœ¨å‡ºå”®è´¢äº§æ—¶ç”¨äºè´¢äº§ä¼°ä»·ã€‚

ä½ å¯èƒ½å·²ç»æ³¨æ„åˆ°äº†ï¼Œè¿™ä¸ªæ•°æ®é›†æ˜¯æ²¡æœ‰æ ‡ç­¾çš„ï¼Œç„¶è€Œï¼Œæˆ‘çš„ä¸€ä¸ªæœ‹å‹æ…·æ…¨åœ°æä¾›äº†å¤§çº¦ 450 å¼ å›¾ç‰‡çš„æ‰‹å·¥æ ‡ç­¾ã€‚(æ ‡ç­¾å·²åœ¨ Github repo ä¸­æä¾›ã€‚)å°½ç®¡è¿™ä¸æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„æ•°æ®é›†è§„æ¨¡ï¼Œä½†æˆ‘ä»¬ä»ç„¶èƒ½å¤Ÿåœ¨ä¿ç•™çš„æµ‹è¯•é›†ä¸Šè¾¾åˆ°å‡ ä¹ 80%çš„å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼Œç”¨äºå¾®è°ƒã€æ”¹è¿›æ¨¡å‹åº¦é‡ç­‰çš„é€‚å½“æŠ€æœ¯ã€‚ä»¥ç¡®å®šæ˜¯å¦å€¼å¾—èŠ±è´¹æ›´å¤šçš„æ—¶é—´æ¥æ ‡è®°é¢å¤–çš„æ•°æ®ç‚¹ã€‚

# ç¬¬äºŒéƒ¨åˆ†:æ¨¡ç‰¹åŸ¹è®­

è®©æˆ‘ä»¬åˆ›å»º`model.ipynb`ç¬”è®°æœ¬ã€‚

## è£…ç½®

```
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Modelfrom sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from imutils import paths
from tqdm import tqdmimport matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
import seaborn as sns
import numpy as np
import shutil
import os
```

*æ³¨æ„:ä½ å¯èƒ½éœ€è¦åšä¸€äº›* `*pip install XXX*` *æ¥è®©ä¸Šé¢çš„å•å…ƒæ ¼å·¥ä½œã€‚*

## è¾…åŠ©å˜é‡å’Œå‡½æ•°

```
ORIG_INPUT_DATASET = "House_Room_Dataset/Bedroom"TRAIN = "training"
VAL = evaluation"
TEST = "testing"BASE_PATH = "dataset"
BATCH_SIZE = 32
CLASSES = ["Modern", "Old"]
```

æˆ‘ä»¬å°†åªå¤„ç†å§å®¤å›¾ç‰‡ï¼Œå› æ­¤`ORIG_INPUT_DATASET`æŒ‡å‘å§å®¤å­ç›®å½•ã€‚`BASE_PATH`æ˜¯æˆ‘ä»¬å°†å­˜å‚¨å›¾åƒçš„è®­ç»ƒã€æµ‹è¯•å’ŒéªŒè¯åˆ†å‰²çš„ç›®å½•çš„è·¯å¾„ã€‚è¿™å°†æ˜¯ç©ºçš„ã€‚

```
*def* plot_hist(*hist*, *metric*):
     if *metric* == 'auc':
            plt.plot(*hist*.history["auc"])
            plt.plot(*hist*.history["val_auc"]) else:
            plt.plot(*hist*.history["loss"])
            plt.plot(*hist*.history["val_loss"]) plt.style.use("ggplot")
     plt.title("model {}".format(*metric*))
     plt.ylabel("{}".format(*metric*))
     plt.xlabel("epoch")
     plt.legend(["train", "validation"], *loc*="upper left")
     plt.show()
```

è¿™æ˜¯ä¸€äº›æ ·æ¿ä»£ç ï¼Œç”¨äºç»˜åˆ¶ä¸¤ç§ç±»å‹çš„å­¦ä¹ æ›²çº¿â€”â€”AUC å¯¹ epoch å’Œ loss å¯¹ epochã€‚

*æ³¨æ„:å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯é™¤* `*auc*` *ä¹‹å¤–çš„æŒ‡æ ‡ï¼Œæ¯”å¦‚è¯´* `*accuracy*` *ï¼Œè¯·ç¡®ä¿å°†ä¸Šé¢ä»£ç ç‰‡æ®µä¸­çš„* `*auc*` *æ›´æ–°ä¸º* `*accuracy*` *ï¼Œå°†* `*val_auc*` *æ›´æ–°ä¸º* `*val_accuracy*` *ã€‚*

## åŠ è½½æ ‡ç­¾

(`[labels.txt](https://github.com/V-Sher/house-interior-prediction/blob/main/labels.txt)`å·²ä½œä¸ºå›è´­çš„ä¸€éƒ¨åˆ†ã€‚)

```
*# Reading labels from the txt file*
with open("labels.txt", 'r') as f:
      manual_labels = f.read()*# Extracting individual labels into a list*
labels = [i for i in manual_labels]
len(labels)********* OUTPUT **********
451
```

è¦æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å¹³è¡¡:

```
from collections import Counterprint(Counter(labels).keys()) 
print(Counter(labels).values())********* OUTPUT **********
*dict_keys(['O', 'M'])
dict_values([271, 180])*
```

çœ‹èµ·æ¥åœ¨æˆ‘ä»¬çš„æ•°æ®é›†ä¸­ï¼Œè€æˆ¿å­æ¯”ç°ä»£æˆ¿å­å¤š(å°½ç®¡å·®è·ä¸æ˜¯å¾ˆå¤§)ã€‚å› æ­¤ï¼ŒæŠ›å¼ƒå‡†ç¡®æ€§å¹¶é€‰æ‹©æ›´é€‚åˆå¤„ç†ç±»åˆ«ä¸å¹³è¡¡çš„æŒ‡æ ‡ï¼Œå³ AUC(ROC æ›²çº¿ä¸‹é¢ç§¯)æ˜¯æœ‰æ„ä¹‰çš„ã€‚

## åˆ—è½¦æµ‹è¯•éªŒè¯æ‹†åˆ†

åœ¨æˆ‘ä»¬è¿›è¡Œåˆ†å‰²ä¹‹å‰ï¼Œå¯¹æ–‡ä»¶åè¿›è¡Œæ’åºæ˜¯å¾ˆé‡è¦çš„ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰ç¬¬*ä¸ª* 451 å›¾åƒçš„æ ‡ç­¾(åœ¨`House_Room_Dataset/Bedroom` å­ç›®å½•ä¸­),è€Œä¸ä»…ä»…æ˜¯éšæœºçš„ 451 å›¾åƒã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œ`os.listdir()`ä»¥éšæœºçš„é¡ºåºè¿”å›æ–‡ä»¶ï¼Œæˆ‘ä»¬ä¸åº”è¯¥ä¾èµ–å®ƒã€‚

```
*# sorting files in the order they appear*
files = os.listdir(ORIG_INPUT_DATASET)
files.sort(*key*=*lambda* *f*: *int*(f.split('_')[1].split('.')[0]))# checking to see the correct file order
files[:5]********* OUTPUT **********
['bed_1.jpg', 'bed_2.jpg', 'bed_3.jpg', 'bed_4.jpg', 'bed_8.jpg']
```

ç°åœ¨æˆ‘ä»¬çŸ¥é“æˆ‘ä»¬æœ‰æ­£ç¡®çš„ 451 å¼ å›¾ç‰‡ï¼Œè®©æˆ‘ä»¬ç»§ç»­è¿›è¡Œè®­ç»ƒ-æµ‹è¯•-éªŒè¯åˆ†å‰²ã€‚æˆ‘ä»¬å°†åˆ†åˆ«åˆ†é…å¤§çº¦ 75%ã€15%å’Œ 10%çš„æ•°æ®ç”¨äºè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•ã€‚

```
*# splitting files into train and test sets*
trainX, testX, trainY, testY =  train_test_split(files[:len(labels)], 
                 labels, 
                 *stratify*=labels, 
                 *train_size*=0.90)*# further splitting of train set into train and val sets*
trainX, valX, trainY, valY = train_test_split(trainX, trainY, *stratify*=trainY, *train_size*=0.85)*# Checking the size of train, test, eval*
len(trainX), len(trainY), len(valX), len(valY),  len(testX), len(testY)********* OUTPUT **********
(344, 344, 61, 61, 46, 46)
```

ä½¿ç”¨ Sklearn çš„`train_test_split()`æ–¹æ³•ï¼Œæˆ‘ä»¬é¦–å…ˆå°†æ•´ä¸ªæ•°æ®é›†åˆ†å‰²æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œç„¶åå°†è®­ç»ƒæ•°æ®å†æ¬¡åˆ†å‰²æˆè®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‚ç”±`labels`åˆ°`stratify`æ˜¯å¾ˆé‡è¦çš„ï¼Œå› ä¸ºæˆ‘ä»¬æƒ³è¦åœ¨æ‰€æœ‰ä¸‰ä¸ªé›†åˆ(è®­ç»ƒã€æµ‹è¯•å’ŒéªŒè¯)ä¸­æŒ‰æ¯”ä¾‹åˆ†é…ç°ä»£å’Œæ—§å›¾åƒã€‚

## æ„å»ºè®­ç»ƒæ•°æ®é›†ç›®å½•

åœ¨ä»£ç çš„åé¢ï¼Œæ‚¨ä¼šæ³¨æ„åˆ°ï¼Œåœ¨è®­ç»ƒæœŸé—´ï¼Œæˆ‘ä»¬ä¸ä¼šå°†æ•´ä¸ªæ•°æ®é›†åŠ è½½åˆ°å†…å­˜ä¸­ã€‚ç›¸åï¼Œæˆ‘ä»¬å°†åˆ©ç”¨ Keras çš„`[.flow_from_directory()](https://keras.io/api/preprocessing/image/)`åŠŸèƒ½æ¥å®ç°æ‰¹å¤„ç†ã€‚ä½†æ˜¯ï¼Œè¯¥å‡½æ•°å¸Œæœ›æ•°æ®è¢«ç»„ç»‡åˆ°å¦‚ä¸‹ç›®å½•ä¸­:

![](img/435a64a579810c024684c05037833156.png)

*å›¾ Keras ä¸­æ‰¹é‡è¯»å–å›¾åƒçš„ç›®å½•ç»“æ„ã€‚M çº§*å’Œ O çº§*åˆ†åˆ«æŒ‡*ç°ä»£*å’Œ*æ—§*ã€‚*

ä¸ºäº†è®©æˆ‘ä»¬çš„å›¾åƒæ–‡ä»¶ä»¥ä¸Šè¿°æ ¼å¼ç»„ç»‡èµ·æ¥ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸‹é¢è¿™ä¸ªç®€çŸ­çš„ç‰‡æ®µ:

![](img/cd619b57a6eb9cc82e2a61da33e33ce3.png)

å½“ä»£ç ç‰‡æ®µè¿è¡Œæ—¶ï¼Œæ‚¨åº”è¯¥èƒ½å¤Ÿä½¿ç”¨ `[tqdm](/data-scientists-guide-to-efficient-coding-in-python-670c78a7bf79)` [æ¨¡å—](/data-scientists-guide-to-efficient-coding-in-python-670c78a7bf79)çœ‹åˆ°è¿›åº¦ï¼Œä¸€æ—¦å®ƒå®Œæˆï¼Œæ‚¨å°†å‘ç°åˆ›å»ºäº†ä¸‰ä¸ªæ–°çš„å­ç›®å½•â€” `dataset/training`ã€`dataset/evaluation`å’Œ`dataset/validation`ï¼Œåœ¨æ¯ä¸ªå­ç›®å½•ä¸­ï¼Œå°†æœ‰ä¸¤ä¸ªå­å­ç›®å½•ï¼Œåˆ†åˆ«ç”¨äºç°ä»£å’Œå¤è€çš„æˆ¿å±‹ã€‚

![](img/8beb36ec1ab55ccf04075afd00c4c285.png)

ä½œä¸ºå¥å…¨æ€§æ£€æŸ¥ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹åœ¨æ¯ä¸ªå­ç›®å½•ä¸­æœ‰é¢„æœŸæ•°é‡çš„å›¾åƒã€‚

```
trainPath = os.path.join(BASE_PATH, TRAIN)
valPath = os.path.join(BASE_PATH, VAL)
testPath = os.path.join(BASE_PATH, TEST)totalTrain = len(*list*(paths.list_images(trainPath)))
totalVal = len(*list*(paths.list_images(valPath)))
totalTest = len(*list*(paths.list_images(testPath)))print(totalTrain, totalTest, totalVal)********** OUTPUT *******
344 46 61
```

*æ³¨æ„:å¦‚æœæ‚¨çš„è‡ªå®šä¹‰æ•°æ®æ˜¯ä¸‹é¢æè¿°çš„ç»“æ„ï¼Œæœ‰ä¸€ä¸ªæœ‰ç”¨çš„ python åŒ…å«åš*[*split _ folders*](https://github.com/jfilter/split-folders)*å¯ä»¥ç”¨æ¥è·å–å›¾ 1 ä¸­å®šä¹‰çš„ç›®å½•ç»“æ„ä¸­çš„æ•°æ®ã€‚*

```
dataset/
    class1/
        img1.jpg
        img2.jpg
        ...
    class2/
        img3.jpg
        ...
    ...
```

## å›¾åƒé¢„å¤„ç†

å› ä¸ºæˆ‘ä»¬å¤„ç†çš„æ ·æœ¬é‡ç›¸å½“æœ‰é™ï¼Œæ‰€ä»¥é€šå¸¸å»ºè®®ä½¿ç”¨æ—‹è½¬ã€ç¼©æ”¾ã€å¹³ç§»ç­‰æ–¹æ³•éšæœºæ”¾å¤§å›¾åƒã€‚

> è™½ç„¶è®¤ä¸ºæ•°æ®æ‰©å……å¢åŠ äº†å¯ç”¨çš„è®­ç»ƒæ•°æ®é‡å¯èƒ½å¾ˆè¯±äººï¼Œä½†å®ƒå®é™…ä¸Šåšçš„æ˜¯è·å–è®­ç»ƒæ ·æœ¬å¹¶å¯¹å…¶åº”ç”¨éšæœºå˜æ¢[ [æ¥æº](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/) ]ã€‚æ€»ä½“è€Œè¨€ï¼Œæ ·æœ¬é‡ä¿æŒä¸å˜ã€‚

Keras å…è®¸äº®åº¦ï¼Œæ—‹è½¬ï¼Œç¼©æ”¾ï¼Œå‰ªåˆ‡ç­‰éšæœºå¢å¼ºã€‚ä½¿ç”¨[å›¾åƒæ•°æ®ç”Ÿæˆå™¨](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)ï¼Œæœ€å¥½çš„éƒ¨åˆ†æ˜¯æ‰€æœ‰è¿™äº›éƒ½æ˜¯åœ¨æ¨¡å‹æ‹Ÿåˆè¿‡ç¨‹ä¸­åŠ¨æ€å®Œæˆ*ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ‚¨ä¸éœ€è¦é¢„å…ˆè®¡ç®—å®ƒä»¬ã€‚*

***è®­ç»ƒæ•°æ®æ‰©å……**:*

```
*trainAug = ImageDataGenerator(
*rotation_range*=90,
*zoom_range*=[0.5, 1.0],
*width_shift_range*=0.3,
*height_shift_range*=0.25,
*shear_range*=0.15,
*horizontal_flip*=True,
*fill_mode*="nearest",
*brightness_range*=[0.2, 1.0]
)*
```

*`width_shift`ã€`height_shift`ã€`zoom_range`ã€`rotation_range`ç­‰å¤§éƒ¨åˆ†å‚æ•°åº”è¯¥æ˜¯ç›´è§‚çš„(å¦‚æœæ²¡æœ‰ï¼Œçœ‹ä¸€ä¸‹*å®˜æ–¹ Keras* [*æ–‡æ¡£*](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#args) *)* ã€‚*

*éœ€è¦æ³¨æ„çš„é‡è¦ä¸€ç‚¹æ˜¯ï¼Œå½“æ‚¨æ‰§è¡Œç¼©æ”¾æˆ–æ—‹è½¬æ“ä½œæ—¶ï¼Œå›¾åƒä¸­å¯èƒ½ä¼šäº§ç”Ÿä¸€äº›ç©ºç™½åŒºåŸŸ/åƒç´ ï¼Œå¿…é¡»ä½¿ç”¨`fill_mode`ä¸­æåˆ°çš„é€‚å½“æŠ€æœ¯è¿›è¡Œå¡«å……ã€‚*

***éªŒè¯æ•°æ®æ‰©å……**:*

```
*valAug = ImageDataGenerator()*
```

*æ‚¨å°†ä¼šçœ‹åˆ°ï¼Œåœ¨ä¸ºéªŒè¯æ•°æ®åˆå§‹åŒ–æ•°æ®æ‰©å……å¯¹è±¡æ—¶ï¼Œæˆ‘ä»¬æ²¡æœ‰æä¾›ä»»ä½•å‚æ•°ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å°†å¯¹å®ƒä»¬éƒ½ä½¿ç”¨é»˜è®¤å€¼ï¼Œå³ 0ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬æ²¡æœ‰åº”ç”¨ä»»ä½•æ‰©å±•(æ²¡æœ‰ç¼©æ”¾ï¼Œå®½åº¦ç§»åŠ¨ï¼Œæ°´å¹³ç¿»è½¬ï¼Œç­‰ç­‰ã€‚)æ·»åŠ åˆ°éªŒè¯é›†ï¼Œå› ä¸ºåœ¨è®­ç»ƒæœŸé—´è¯„ä¼°æ¨¡å‹æ—¶ï¼Œè¯¥é›†åº”è¢«è§†ä¸ºæµ‹è¯•é›†ã€‚*

***æµ‹è¯•æ•°æ®æ‰©å……:***

```
*testAug = ImageDataGenerator()*
```

*éµå¾ªä¸ä¸Šé¢ç›¸åŒçš„é€»è¾‘ï¼Œæˆ‘ä»¬æ²¡æœ‰å¯¹æµ‹è¯•é›†åº”ç”¨ä»»ä½•æ‰©å……ã€‚*

***åˆ›å»ºæ•°æ®ç”Ÿæˆå™¨***

*å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€äº›æ•°æ®ç”Ÿæˆå™¨ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒæœŸé—´å°†è¿™äº›å¢å¼ºå›¾åƒæˆæ‰¹åœ°æä¾›ç»™æ¨¡å‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`[flow_from_directory()](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory)` [å‘ç”Ÿå™¨å‡½æ•°](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory)ã€‚*

```
**# Create training batches whilst creating augmented images on the fly*trainGen = trainAug.flow_from_directory(
*directory*=trainPath,
*target_size*=(224,224),
*save_to_dir*='dataset/augmented/train',
*save_prefix*='train',
*shuffle*=True
)*# Create val batches* valGen = valAug.flow_from_directory(
*directory*=valPath,
*target_size*=(224,224),
*shuffle*=True
)*
```

*éœ€è¦è€ƒè™‘çš„å‡ ä»¶é‡è¦äº‹æƒ…:*

*   *åœ¨æ¯ç§æƒ…å†µä¸‹ï¼Œ`directory`è¢«è®¾ç½®ä¸ºè®­ç»ƒ(æˆ–éªŒè¯)å›¾åƒæ‰€åœ¨çš„è·¯å¾„ã€‚*
*   *å°†`target_size`æŒ‡å®šä¸º`(224,224)`å¯ä»¥ç¡®ä¿æ‰€æœ‰å›¾åƒéƒ½å°†è¢«è°ƒæ•´åˆ°è¿™ä¸ªå°ºå¯¸ã€‚*
*   *æˆ‘ä»¬è¿˜å°†æŠŠ`save_to_dir`è®¾ç½®ä¸ºä¿å­˜å¢å¼ºå›¾åƒ(å‰ç¼€åœ¨`save_prefix`ä¸­æŒ‡å®š)çš„ç›®å½•è·¯å¾„ï¼Œè¿™äº›å›¾åƒå°†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€åˆ›å»ºã€‚è¿™æä¾›äº†ä¸€ä¸ªå¾ˆå¥½çš„å¥å…¨æ€§æ£€æŸ¥ï¼Œä»¥æŸ¥çœ‹å›¾åƒæ˜¯å¦å¾—åˆ°äº†åº”æœ‰çš„éšæœºå˜æ¢ã€‚*æ³¨æ„:å¦‚æœä½ æƒ³äº‹å…ˆæ£€æŸ¥ä¸€ä¸‹ï¼Œä¹Ÿå°±æ˜¯åœ¨è®­ç»ƒå¼€å§‹ä¹‹å‰ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªæˆ‘åœ¨*[*stack overflow*](https://stackoverflow.com/questions/63818153/does-keras-imagedatagenerator-randomly-apply-transformations-to-every-image)*ä¸Šæ‰¾åˆ°çš„å¿«é€Ÿç‰‡æ®µã€‚**
*   *æœ€åï¼Œ`shuffle`è¢«è®¾ç½®ä¸º`True`,å› ä¸ºæˆ‘ä»¬å¸Œæœ›æ ·æœ¬åœ¨æ‰¹å¤„ç†ç”Ÿæˆå™¨ä¸­è¢«æ··æ´—ï¼Œè¿™æ ·å½“`model.fit()`è¯·æ±‚ä¸€ä¸ªæ‰¹å¤„ç†æ—¶ï¼Œå°±ä¼šç»™å‡ºéšæœºæ ·æœ¬ã€‚è¿™æ ·åšå°†ç¡®ä¿ä¸åŒæ—¶æœŸä¹‹é—´çš„æ‰¹æ¬¡çœ‹èµ·æ¥ä¸ä¸€æ ·ï¼Œå¹¶æœ€ç»ˆä½¿æ¨¡å‹æ›´åŠ å¥å£®ã€‚*

```
**# Create test batches*testGen = testAug.flow_from_directory(
*directory*=testPath,
*target_size*=(224,224),
*shuffle*=False
)*
```

*é™¤äº†ä¸º`testGen`è®¾ç½®æ­£ç¡®çš„`directory`è·¯å¾„ï¼Œè¿˜æœ‰ä¸€ä»¶ä¸»è¦çš„äº‹æƒ…éœ€è¦è€ƒè™‘:*

*   *`shuffle`å¿…é¡»è®¾ç½®ä¸º`False`ã€‚*

*ä½ é—®ï¼Œä¸ºä»€ä¹ˆï¼Ÿ
å› ä¸ºï¼Œç°åœ¨**æˆ‘ä»¬ä¸å¸Œæœ›æ ·æœ¬åœ¨æµ‹è¯•æ‰¹æ¬¡ç”Ÿæˆå™¨**ä¸­è¢«æ··æ´—ã€‚åªæœ‰å½“ shuffle è®¾å®šä¸º False æ—¶ï¼Œæ‰ä¼šæŒ‰ç…§æä¾›çš„æ–‡ä»¶åç§°çš„é¡ºåºåˆ›å»ºæ‰¹å¤„ç†ã€‚åœ¨æ¨¡å‹è¯„ä¼°æœŸé—´ï¼Œéœ€è¦å°†æ–‡ä»¶å(å³çœŸå®æ ‡ç­¾ï¼Œå¯ä½¿ç”¨`*testGen.classes*`è®¿é—®)ä¸é¢„æµ‹æ ‡ç­¾è¿›è¡ŒåŒ¹é…ã€‚*

**æœ‰è¶£çš„äº‹å®:å¦‚æœä½ ç°åœ¨æ£€æŸ¥* `*trainGen.classes*` *çš„è¾“å‡ºï¼Œå¸Œæœ›å®ƒä»¬è¢«æ‰“ä¹±ï¼Œä½ ä¼šå¤±æœ›çš„ã€‚ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºå½“åœ¨æ¨¡å‹æ‹ŸåˆæœŸé—´è¯·æ±‚ä¸€ä¸ªæ‰¹æ¬¡æ—¶ï¼Œæ´—ç‰Œæ˜¯åŠ¨æ€å‘ç”Ÿçš„ã€‚ã€*[*stack overflow*](https://stackoverflow.com/questions/60927259/keras-flow-from-directory-shuffle-not-working-properly)*ã€‘ã€‚**

## *è®­ç»ƒè¿‡ç¨‹èƒŒåçš„ç›´è§‰*

*æˆ‘ä»¬å¯ä»¥ä»å¤´å¼€å§‹è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œä½†è¿™è‚¯å®šä¼šè¡¨ç°ä¸ä½³â€”â€”ä¸»è¦æ˜¯å› ä¸ºæˆ‘ä»¬çš„æ•°æ®é›†å¦‚æ­¤ä¹‹å°ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåˆ©ç”¨**è¿ç§»å­¦ä¹ **çš„åŠ›é‡æ˜¯æœ‰æ„ä¹‰çš„ã€‚*

> *è¿ç§»å­¦ä¹ æ˜¯æŒ‡åœ¨æ–°æ•°æ®é›†ä¸Šå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹çš„è¿‡ç¨‹ã€‚è¿™ä½¿å®ƒèƒ½å¤Ÿè¯†åˆ«ä»æœªè®­ç»ƒè¿‡çš„ç±»ï¼*

*ç®€è€Œè¨€ä¹‹ï¼Œè¿ç§»å­¦ä¹ å…è®¸æˆ‘ä»¬åˆ©ç”¨æ¨¡å‹åœ¨è®­ç»ƒä¸­è·å¾—çš„çŸ¥è¯†æ¥è¯†åˆ«ç‹—å’ŒçŒ«ï¼Œè¿™æ ·å®ƒç°åœ¨å¯ä»¥ç”¨æ¥é¢„æµ‹æˆ¿å­å†…éƒ¨æ˜¯å¦ç°ä»£ã€‚*

*ä½†æ˜¯å®ƒä¸ºä»€ä¹ˆä¼šèµ·ä½œç”¨å‘¢ï¼Ÿ
å› ä¸ºæˆ‘ä»¬æŒ‘é€‰çš„ä»»ä½•åŸºç¡€æ¨¡å‹(å³é¢„è®­ç»ƒæ¨¡å‹)é€šå¸¸éƒ½æ˜¯åœ¨å¦‚æ­¤å¤§çš„å›¾åƒè¯­æ–™åº“ä¸Šè®­ç»ƒçš„ï¼Œæ‰€ä»¥ä¸€èˆ¬æ¥è¯´ï¼Œå®ƒèƒ½å¤Ÿå­¦ä¹ å›¾åƒçš„è‰¯å¥½çŸ¢é‡è¡¨ç¤ºã€‚å‰©ä¸‹è¦åšçš„å°±æ˜¯åœ¨åŒºåˆ†å®šåˆ¶ç±»æ—¶ä½¿ç”¨è¿™äº›è¡¨ç¤º(åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæ˜¯è€æˆ¿å­è¿˜æ˜¯ç°ä»£æˆ¿å­)ã€‚*

**é¸£è°¢:æˆ‘æƒ³èŠ±ç‚¹æ—¶é—´å¯¹æˆ‘åœ¨è¿™ç¯‡æ–‡ç« çš„ç ”ç©¶é˜¶æ®µå‘ç°çš„å‡ ä¸ªåšå®¢(* [*è¿™ä¸ª*](https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/) *ï¼Œ* [*è¿™ä¸ª*](https://www.pyimagesearch.com/2019/06/03/fine-tuning-with-keras-and-deep-learning/) ï¼Œ*[*è¿™ä¸ª*](/a-bunch-of-tips-and-tricks-for-training-deep-neural-networks-3ca24c31ddc8) *)å¤§å£°ç–¾å‘¼ã€‚è¿™äº›è¢«è¯æ˜æ˜¯çœŸæ­£çš„ç‘°å®ï¼Œå¸®åŠ©æˆ‘è¯¦ç»†ç†è§£äº†è¿ç§»å­¦ä¹ çš„æ¦‚å¿µã€‚æˆ‘çœŸçš„å¾ˆæ„Ÿæ¿€ä½ æ‰€æœ‰çš„è§è§£ï¼Œè¿™äº›è§è§£è®©æˆ‘ä¸ºæˆ‘çš„è¯»è€…ç®€åŒ–äº†ä»£ç /è§£é‡Šã€‚***

****ä½¿ç”¨ Keras è¿›è¡Œè¿ç§»å­¦ä¹ ****

**è¿ç§»å­¦ä¹ åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ­¥éª¤:**

*   ****ç‰¹å¾æå–**:å°†ä¸€ä¸ªé¢„å…ˆè®­ç»ƒå¥½çš„æ¨¡å‹(å¹¶å†»ç»“å…¶æƒé‡)ä½œä¸ºåŸºç¡€æ¨¡å‹ï¼Œç„¶ååœ¨åŸºç¡€æ¨¡å‹ä¸Šè®­ç»ƒä¸€ä¸ªæ–°çš„åˆ†ç±»å™¨*ï¼Œä½¿å…¶å‡†ç¡®è¾“å‡º N ä¸ªå€¼(å…¶ä¸­ N ä¸ºç±»åˆ«æ•°)ã€‚**
*   ****ã€å¯é€‰ã€‘å¾®è°ƒ**:ä¸€æ—¦è®­ç»ƒå¥½åˆ†ç±»å™¨ï¼Œä»åŸºç¡€æ¨¡å‹ä¸­è§£å†»å‡ ä¸ª**å±‚ï¼Œä½¿å…¶å¾ˆå¥½åœ°é€‚åº”æ–°çš„æ•°æ®é›†ã€‚**

***æ–°çš„åˆ†ç±»å™¨å¯ä»¥æ˜¯:**

*   **å¯†é›†å±‚çš„å †å (å³å®Œå…¨è¿æ¥çš„å±‚)ã€‚**

**è¿ç­¹å­¦**

*   **å•ä¸ªå…¨å±€æ± å±‚(å°†æ•´ä¸ªè¦ç´ åœ°å›¾ç¼©å°ä¸ºå•ä¸ªå€¼â€” `maxpool`ã€`avgpool`)ã€‚è¿™æ˜¯ä¼˜é€‰çš„ï¼Œå› ä¸ºæœ‰ 0 ä¸ªå‚æ•°éœ€è¦ä¼˜åŒ–(å› æ­¤æ˜¯æœ¬æ–‡çš„é€‰æ‹©)ï¼Œæ‰€ä»¥è¿‡åº¦æ‹Ÿåˆè¾ƒå°‘ã€‚**

****æ ¹æ®æ‚¨çš„æ•°æ®é›†ä¸é¢„è®­ç»ƒæ¨¡å‹æœ€åˆè®­ç»ƒæ—¶çš„æ•°æ®é›†çš„ä¸åŒç¨‹åº¦ï¼Œå°‘æ•°ä¼šæœ‰æ‰€ä¸åŒã€‚è¯·è®°ä½ï¼Œå¦‚æœä¸¤ä¸ªæ•°æ®é›†éå¸¸ç›¸ä¼¼ï¼Œé‚£ä¹ˆåªè§£å†»æ‰€æœ‰å›¾å±‚çš„ä¸€éƒ¨åˆ†å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ã€‚**

**å¾®è°ƒæ­¥éª¤è™½ç„¶æ˜¯å¯é€‰çš„ï¼Œä½†å¯¹äºè‡ªå®šä¹‰æ•°æ®é›†ä¸è®­ç»ƒåŸºæœ¬æ¨¡å‹çš„æ•°æ®é›†å®Œå…¨ä¸åŒçš„ç”¨ä¾‹æ¥è¯´ï¼Œè¿™ä¸€æ­¥éå¸¸é‡è¦ã€‚æ­¤å¤–ï¼Œä¸ç‰¹å¾æå–æ­¥éª¤ç›¸æ¯”ï¼Œè¿™å¯èƒ½éœ€è¦æ›´å¤šçš„å†å…ƒã€‚å› ä¸ºæ›´å¤šçš„æ—¶æœŸç²—ç•¥åœ°è½¬åŒ–ä¸ºæ›´é«˜çš„è¿‡æ‹Ÿåˆæœºä¼šï¼Œæ‰€ä»¥å»ºè®®åœ¨ä»”ç»†ç›‘æ§æŸå¤±/ç²¾åº¦æ›²çº¿ä¹‹åä½¿ç”¨(æ¨¡å‹è®­ç»ƒçš„)æ—©æœŸåœæ­¢ã€‚**

****å‹å·é€‰æ‹©èƒŒåçš„ç›´è§‰****

**å›åˆ°è¿™ä¸ªç™¾ä¸‡ç¾å…ƒçš„é—®é¢˜â€”â€”æˆ‘ä»¬åº”è¯¥é€‰æ‹©å“ªä¸ªæ¨¡å‹ä½œä¸ºå¾®è°ƒçš„åŸºç¡€æ¨¡å‹ï¼Ÿæ˜¾ç„¶ï¼Œæœ‰ç›¸å½“å¤šçš„é€‰é¡¹å¯ç”¨ï¼Œå¯ä»¥åœ¨ Keras æ–‡æ¡£ä¸­æ‰¾åˆ°[è¿™é‡Œ](https://keras.io/api/applications/#available-models)ã€‚è™½ç„¶æˆ‘æœ€åˆçš„é€‰æ‹©æ˜¯ ResNet-50ï¼Œå› ä¸ºå®ƒå¾ˆå—æ¬¢è¿ï¼Œä½†æˆ‘æœ€ç»ˆå†³å®šç»§ç»­ä½¿ç”¨ [**EfficientNet**](https://keras.io/api/applications/efficientnet/) ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥[å®ç°ä¸ SOTA å‹å·ç±»ä¼¼çš„ç»“æœï¼ŒåŒæ—¶éœ€è¦æ›´å°‘çš„ FLOPS](https://arxiv.org/pdf/1905.11946v5.pdf) ã€‚æ­¤å¤–ï¼Œ[è®ºæ–‡](https://arxiv.org/pdf/1905.11946v5.pdf)æåˆ°å®ƒä»¬çš„**æ€§èƒ½åœ¨** **è¿ç§»å­¦ä¹ ä»»åŠ¡**ä¸Šä¸ SOTA æ¨¡å‹ä¸ç›¸ä¸Šä¸‹ï¼ŒåŒæ—¶å¹³å‡éœ€è¦çš„å‚æ•°å°‘ 9.6 å€ã€‚å“‡å“¦â­ï¸**

**EfficientNet æ¨¡å‹æœ‰å¾ˆå¤šç§(EfficientNetB0ã€EfficientNetB1ã€â€¦â€¦ EfficientB7)ï¼Œå®ƒä»¬åœ¨æ¶æ„(å³ç½‘ç»œæ·±åº¦ã€å®½åº¦)å’Œèµ„æºé™åˆ¶æ–¹é¢ç•¥æœ‰ä¸åŒã€‚è¿™äº›æ¨¡å‹ä¸­çš„æ¯ä¸€ä¸ªéƒ½éœ€è¦ç‰¹å®šå›¾åƒå½¢çŠ¶çš„å›¾åƒï¼Œå¦‚æœ¬[è¡¨](https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/#keras-implementation-of-efficientnet)ä¸­æ‰€è¿°ã€‚é‰´äºæˆ‘ä»¬æ­£åœ¨ä½¿ç”¨`224x224`åˆ†è¾¨ç‡çš„å›¾åƒï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ **EfficientNetB0ã€‚****

## ****ç‰¹å¾æå–æ­¥éª¤çš„æ¨¡å‹è®­ç»ƒ****

***æ³¨æ„:åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Tensorflow çš„ Keras APIã€‚å¦‚æœæ‚¨æ˜¯ Keras æ–°æ‰‹ï¼Œæˆ‘å·²ç»å†™äº†ä¸¤ä¸ªåˆçº§ Keras æ•™ç¨‹(*[*part 1*](/beginners-guide-to-building-artificial-neural-networks-using-keras-in-python-bdc4989dab00)*ï¼Œ*[*part 2*](/beginners-guide-to-building-convolutional-neural-networks-using-tensorflow-s-keras-api-in-python-6e8035e28238)*)ï¼Œå†…å®¹æ¶µç›–äº†ç½‘ç»œæ¶æ„ã€ç¥ç»å…ƒã€æ¿€æ´»å‡½æ•°ã€éšè—å±‚(å¯†é›†ã€ä¸‹é™ã€æœ€å¤§æ± ã€å±•å¹³)ç­‰ï¼Œæ¯”è¿™é‡Œè®¨è®ºçš„è¦è¯¦ç»†å¾—å¤šã€‚è¯·éšæ—¶å‚è€ƒä»–ä»¬çš„å¿«é€Ÿå¤ä¹ ï¼***

**æˆ‘ä»¬ä»ä½¿ç”¨`imagenet`æƒé‡åˆ›å»ºä¸€ä¸ª`EfficientNetB0`åŸºç¡€æ¨¡å‹å¼€å§‹ã€‚**

```
**baseModel = EfficientNetB0(
            *weights*="imagenet",
            *include_top*=False, # make sure top layer is not included
            *input_tensor*=Input(*shape*=(224, 224, 3)),
            *pooling*="avg"
           )**
```

**éœ€è¦è€ƒè™‘çš„äº‹æƒ…å¾ˆå°‘:**

*   **`include_top`å¿…é¡»è®¾ç½®ä¸º`False`ï¼Œå› ä¸º EfficientNet ç½‘ç»œæ¶æ„ä¸­çš„é¡¶å±‚(å³æœ€ç»ˆå±‚)æ˜¯ä¸€ä¸ª`Dense`å±‚ï¼Œå®ƒè¾“å‡º 1000 ä¸ªå¯¹åº”äº ImageNet æ•°æ®é›†çš„ç±»ã€‚æˆ‘ä»¬æ˜¾ç„¶ä¸éœ€è¦è¿™ä¸ªï¼**
*   **å¦‚æœæ‚¨æ²¡è®°é”™çš„è¯ï¼Œæˆ‘ä»¬é€‰æ‹©æ–°çš„åˆ†ç±»å™¨ä½œä¸ºå…¨å±€æ± å±‚(è€Œä¸æ˜¯å¯†é›†å±‚çš„å †æ ˆ)ã€‚å¥½æ¶ˆæ¯æ˜¯ï¼ŒKeras API å·²ç»å…è®¸æˆ‘ä»¬åœ¨å®ä¾‹åŒ–`EfficientNetB0`å¯¹è±¡çš„åŒæ—¶å®Œæˆè¿™ä¸ª*ã€‚æˆ‘ä»¬å¯ä»¥ç®€å•åœ°å°†`pooling`å‚æ•°è®¾ç½®ä¸º`avg`ã€‚é»˜è®¤ä¸º`None`ã€‚***

**ä¸‹ä¸€æ­¥æ˜¯é€šè¿‡å°†æ¯å±‚çš„`trainable`è®¾ç½®ä¸º`False`æ¥å†»ç»“æƒé‡:**

```
***# freeze the weights*for layer in baseModel.layers:
      layer.trainable = False**
```

**ç°åœ¨æ˜¯æ—¶å€™åœ¨ä¸Šé¢åˆ›å»ºä¸€ä¸ªæ–°çš„åˆ†ç±»å™¨äº†ï¼Œå®ƒå°†å‡†ç¡®åœ°äº§ç”Ÿä¸¤ä¸ªç±»(`M`æˆ–`O`)ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿è¿™ä¸ªåˆ†ç±»å™¨æ¨¡å‹çš„æœ€åä¸€å±‚æ˜¯å…·æœ‰ä¸¤ä¸ªè¾“å‡ºç¥ç»å…ƒçš„`Dense`å±‚ã€‚åœ¨è¿™ä¸¤è€…ä¹‹é—´ï¼Œæˆ‘ä»¬è¿˜åŒ…æ‹¬äº†`BatchNormalization`å’Œ`Dropout`å±‚ï¼Œç”¨äºæ­£åˆ™åŒ–ã€‚**

```
***# training a new classifier on top (Functional Keras Model)*x = baseModel.output
Layer_1 = BatchNormalization()(x)
Layer_2 = Dropout(0.5)(Layer_1)
output_layer = Dense(len(CLASSES), *activation*="softmax")(Layer_2)model = Model(*inputs* = baseModel.input, *outputs* = output_layer)**
```

***æ³¨æ„:æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥å»ºç«‹è¿™ä¸ª Keras åˆ†ç±»å™¨æ¨¡å‹:é¡ºåºçš„(æœ€åŸºæœ¬çš„)å’ŒåŠŸèƒ½çš„(å¯¹äºå…·æœ‰å¤šä¸ªè¾“å…¥/è¾“å‡ºçš„å¤æ‚ç½‘ç»œ)ã€‚ä¸Šé¢çš„ä»£ç ç‰‡æ®µæ˜¯ä½œä¸ºä¸€ä¸ªåŠŸèƒ½ç½‘ç»œç¼–å†™çš„ï¼Œå› ä¸ºå¦‚æœæ‚¨ä½¿ç”¨* `*model.summary()*` *æ¥æ£€æŸ¥å®ƒï¼Œå®ƒä¼šä½¿ç½‘ç»œæ¶æ„æ›´åŠ æ¸…æ™°ã€‚åŒæ ·ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªç±»ä¼¼ä¸‹é¢çš„åºåˆ—æ¨¡å‹ï¼Œç»“æœå°†æ˜¯ç›¸åŒçš„ã€‚***

```
***# Another way to create the classifier on top of basemodel*model = tf.keras.Sequential()
model.add(baseModel)
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Dense(len(CLASSES), activation="softmax"))**
```

**æœ€åï¼Œè®©æˆ‘ä»¬ç”¨`Adam`ä¼˜åŒ–å™¨å’Œä¸€ä¸ªç›¸å¯¹è¾ƒå¤§çš„`learning_rate = 1e-3`æ¥ç¼–è¯‘æ¨¡å‹ã€‚ç”±äºæˆ‘ä»¬æœ‰ä¸¤ä¸ªå¯èƒ½çš„è¾“å‡ºç±»ï¼Œæˆ‘ä»¬å°†ç›‘æ§`binary_crossentropy`æŸå¤±(å¦‚æœæ‚¨å¤„ç†ä¸¤ä¸ªä»¥ä¸Šçš„ç±»ï¼Œè¯·ä½¿ç”¨`categorical_crossentropy`)å¹¶æ ¹æ®`tf.keras.metrics.AUC`ä¸­å®ç°çš„ AUC åº¦é‡è¯„ä¼°æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚**

```
***# compile*opt = Adam(*learning_rate*=1e-3)
model.compile(*optimizer*=opt, 
              *loss*='binary_crossentropy', 
              *metrics*=[tf.keras.metrics.AUC()]
              )**
```

**åœ¨ä½¿ç”¨`fit()`è®­ç»ƒæ¨¡å‹ä¹‹å‰è¦åšçš„æœ€åä¸€ä»¶äº‹æ˜¯å®ç°`EarlyStopping`å’Œ`ModelCheckpoint`ã€‚**

**å‰è€…å°†ç¡®ä¿æ¨¡å‹ä¸ä¼šåœ¨ä¸å¿…è¦çš„æƒ…å†µä¸‹è®­ç»ƒæ›´å¤šçš„æ—¶æœŸã€‚è¿™æ˜¯é€šè¿‡ç›‘æ§`val_loss`æ¥å®Œæˆçš„ï¼Œä¸€æ—¦æ²¡æœ‰è¿›ä¸€æ­¥çš„æ”¹è¿›ï¼Œå³ä¸èƒ½è¿›ä¸€æ­¥æœ€å°åŒ–ï¼Œè®­ç»ƒå°±åœæ­¢ã€‚**

**åè€…å°†åœ¨ç»™å®šçš„æ–‡ä»¶è·¯å¾„ä¸­ä¿å­˜æœ€ä½³æ¨¡å‹â€”â€”åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯`feature_extraction.h5`ã€‚æˆ‘ä»¬å°†å†æ¬¡ç›‘æ§éªŒè¯æŸå¤±ï¼Œå¹¶ä¿å­˜æ‰€æœ‰æ—¶æœŸçš„æœ€ä½³æ¨¡å‹ã€‚**

***æ³¨æ„:è¿™é‡Œæœ‰ä¸€ç¯‡ä¼˜ç§€çš„* [*æ–‡ç« *](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/) *æ›´è¯¦ç»†åœ°è§£é‡Šäº†æ—©æœŸåœæ­¢å’Œæ¨¡å‹æ£€æŸ¥ç‚¹å®ç°ï¼***

```
***# implementing early stopping* es = EarlyStopping(
     *monitor*='val_loss',  #metric to monitor
     *mode*='min',  # whether to min or max the metric monitored
     *patience*=10, # epochs to wait before declaring stopped training
     *verbose*=1  # output epoch when training was stopped
     )*# implementing model checkpoint* mc = ModelCheckpoint(
      'feature_extraction.h5',
       *monitor*='val_loss',
       *mode*='min',
       *verbose*=1, # display epoch+accuracy everytime model is saved
       *save_best_only*=True
      )**
```

**æœ€åï¼Œæ˜¯æ¨¡å‹è®­ç»ƒçš„æ—¶å€™äº†:**

```
***# Training the model*hist = model.fit(
       *x*=trainGen,
       *epochs*=25,
       *verbose*=2,
       *validation_data*=valGen,
       *steps_per_epoch*=totalTrain // BATCH_SIZE,
       *callbacks*=[es, mc]
      )**
```

**![](img/8be64a1b56cff0d5ba85befea04db80e.png)**

**æœ€ç»ˆæ—¶æœŸçš„æŸå¤±å’Œ AUC åˆ†æ•°**

**å¿«é€Ÿçœ‹ä¸€ä¸‹ AUC å’ŒæŸå¤±æ›²çº¿ï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾åˆ°æ¨¡å‹æ”¶æ•›çš„è¯æ®(æ„å‘³ç€æ¨¡å‹å·²ç»å‡†å¤‡å¥½è¿›è¡Œå¾®è°ƒ)ã€‚**

**![](img/5c449830a0e73f9fc7c37ae5b8ce5bad.png)****![](img/6832e8c30b0fd1bb27bc643249bd0bb5.png)

AUC å’ŒæŸå¤±çš„å­¦ä¹ æ›²çº¿** 

**å³å›¾ä¸­ä¸€ä¸ªæœ‰è¶£çš„è§‚å¯Ÿç»“æœæ˜¯ï¼Œæˆ‘ä»¬çš„éªŒè¯æŸå¤±ä½äºè®­ç»ƒæŸå¤±ã€‚èµ·åˆï¼Œæˆ‘è®¤ä¸ºæœ‰ä¸€äº›æ•°æ®æ³„æ¼çš„é—®é¢˜ï¼Œä½†åæ¥æˆ‘å‘ç°äº†è¿™ç¯‡ä¼˜ç§€çš„[æ–‡ç« ](https://www.pyimagesearch.com/2019/10/14/why-is-my-validation-loss-lower-than-my-training-loss/)è§£é‡Šäº†ä¸ºä»€ä¹ˆè¿™æ˜¯å®Œå…¨æ­£å¸¸çš„ï¼Œæœ‰æ—¶ä¼šåœ¨è®­ç»ƒä¸­å‘ç”Ÿã€‚**

**æ€»ç»“ä¸¤ä¸ªå¯èƒ½çš„åŸå› (ä»æ–‡ç« æœ¬èº«):**

*   **åŸå› #1:æ­£è§„åŒ–(å¦‚è¾å­¦)åªé€‚ç”¨äºåŸ¹è®­æœŸé—´ï¼Œè€Œä¸æ˜¯åœ¨éªŒè¯æœŸé—´ã€‚å› ä¸ºæ­£åˆ™åŒ–ç‰ºç‰²è®­ç»ƒç²¾åº¦æ¥æé«˜éªŒè¯/æµ‹è¯•ç²¾åº¦ï¼Œæ‰€ä»¥éªŒè¯æŸå¤±å¯ä»¥ä½äºè®­ç»ƒæŸå¤±ã€‚**
*   **åŸå› #2:æˆ‘ä»¬çš„éªŒè¯é›†å¤ªå°(åªæœ‰ 61 å¹…å›¾åƒ)ï¼Œä¹Ÿè®¸å®ƒæ¯”è®­ç»ƒé›†æ›´å®¹æ˜“ï¼Œå³[ä¸å…·æœ‰ä»£è¡¨æ€§çš„éªŒè¯æ•°æ®é›†](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/#unrepresentative-validation-dataset)ã€‚**

## **ç‰¹å¾æå–æ­¥éª¤åçš„æ¨¡å‹æµ‹è¯•**

**æˆ‘ä»¬å°†ä½¿ç”¨ä¸€äº›æ ·æ¿ä»£ç æ¥è¯„ä¼°ä½¿ç”¨`.predict()`è·å¾—çš„æ¨¡å‹é¢„æµ‹ã€‚è®°ä½`predIdxs`å°†ç±»ä¼¼äº`[0.8, 0.2]`ï¼Œå³`M`å’Œ`O`ä¸¤ä¸ªç±»çš„ softmax å€¼ï¼Œæ‰€ä»¥ç¡®ä¿ä½¿ç”¨`np.argmax`é€‰æ‹©ä¸¤ä¸ªä¸­çš„æœ€å¤§å€¼ã€‚æˆ‘ä»¬ä½¿ç”¨`testGen.class_indices`æ¥æ£€æŸ¥ä»ç±»ååˆ°ç±»ç´¢å¼•çš„æ˜ å°„ã€‚**

```
**testGen.reset()predIdxs = model.predict(
             *x*=testGen,
             *steps*=(totalTest // BATCH_SIZE) + 1
            )predIdxs = np.argmax(predIdxs, *axis* = 1)
print("No. of test images", len(predIdxs))
print(testGen.class_indices)cm = confusion_matrix(testGen.classes, predIdxs)
heatmap = sns.heatmap(cm, *annot*=True)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()********* OUTPUT********
No. of test images 46 
{'M': 0, 'O': 1}**
```

**![](img/dba1e0f6352300b87a4e8b44aa25bdd8.png)**

## **å¾®è°ƒæ­¥éª¤çš„æ¨¡å‹è®­ç»ƒ**

**æˆ‘ä»¬å°†ä»è§£å†»å½“å‰æ¨¡å‹çš„æœ€åå‡ å±‚å¼€å§‹ï¼Œä½†æ˜¯ï¼Œæˆ‘ä»¬ä¸åº”è¯¥éšæ„æ‰“å¼€æˆ–å…³é—­å±‚ã€‚æœ‰è®¸å¤šæŠ€æœ¯å’ŒæŠ€å·§å¯ç”¨äºå¾®è°ƒæ¨¡å‹(ä¾‹å¦‚ï¼Œå‚è§[è¿™ä¸ª](https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/#tips-for-fine-tuning-efficientnet)å’Œ[è¿™ä¸ª](https://keras.io/guides/transfer_learning/#finetuning)),ä½†æœ‰ä¸€äº›æ˜¯æˆ‘å‘ç°æœ€æœ‰ç”¨çš„:**

*   **å½“åœ¨è¯¥æ­¥éª¤ç¼–è¯‘æ¨¡å‹æ—¶ï¼Œä¸ç‰¹å¾æå–æ­¥éª¤ç›¸æ¯”ï¼Œä½¿ç”¨ç”šè‡³æ›´å°çš„å­¦ä¹ é€Ÿç‡ã€‚è¾ƒå°çš„å­¦ä¹ é€Ÿç‡æ„å‘³ç€éœ€è¦æ›´å¤šçš„å†å…ƒï¼Œå› ä¸ºæ¯æ¬¡æ›´æ–°æ—¶ç½‘ç»œæƒé‡çš„å˜åŒ–è¾ƒå°ã€‚**
*   **è¿™äº›å±‚éœ€è¦ä¿æŒå†·å†»ã€‚**
*   **åœ¨ç½‘ç»œæ¶æ„ä¸­ï¼Œå·ç§¯å—éœ€è¦åœ¨æ•´ä½“ **ä¸­æ‰“å¼€æˆ–å…³é—­**ã€‚
    ä¾‹å¦‚:è€ƒè™‘`model.summary()`è¾“å‡ºçš„æœ€åå‡ è¡Œã€‚æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œè¿™äº›å±‚è¢«æ•´é½åœ°ç»„ç»‡æˆå—ï¼Œæœ€åä¸€å—æ˜¯`block7d`ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†è§£å†»`block7d`ä¸­çš„æ‰€æœ‰å›¾å±‚(ç„¶è€Œï¼Œä»»ä½•`BathcNormalization`å›¾å±‚éƒ½å°†ä¿æŒåŸæ ·)ä»¥åŠéšåçš„ 7 ä¸ªå›¾å±‚(å…¶ä¸­å¤§éƒ¨åˆ†æ˜¯æˆ‘ä»¬åœ¨æ„å»ºæ–°çš„åˆ†ç±»å™¨å¤´æ—¶å®šä¹‰çš„)ã€‚æ€»çš„æ¥è¯´ï¼Œç½‘ç»œçš„æœ€å 20 å±‚å°†æ˜¯è§£å†»çš„å€™é€‰å±‚ã€‚******

```
****____________________________________________________________________
Layer (type)                    Output Shape         Param #     ====================================================================
                              .
                              .
                              .block6d_project_conv (Conv2D)   (None, 7, 7, 192)    221184      ____________________________________________________________________block6d_project_bn (BatchNormal (None, 7, 7, 192)    768     ____________________________________________________________________block6d_drop (Dropout)          (None, 7, 7, 192)    0           ____________________________________________________________________block6d_add (Add)               (None, 7, 7, 192)    0           ____________________________________________________________________block7a_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184 ____________________________________________________________________block7a_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        ________________________________________________________________block7a_expand_activation (Acti (None, 7, 7, 1152)   0           ____________________________________________________________________block7a_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   10368 ____________________________________________________________________ .
                              .
                              .****
```

****æˆ‘å·²ç»å°†ç”¨äºå¾®è°ƒçš„ä»£ç æ†ç»‘åˆ°ä¸€ä¸ªåä¸º`fine_tune_model()`çš„å‡½æ•°ä¸­ã€‚å¤§éƒ¨åˆ†ä»£ç æ˜¯ä»ç‰¹å¾æå–æ­¥éª¤å¼€å§‹é‡å¤çš„ã€‚****

```
*****def* fine_tune_model(*model*): *# unfreeze last conv block i.e. block7a* for layer in *model*.layers[-20:]:
          if not isinstance(layer, BatchNormalization):
               layer.trainable = True *# check which of these are trainable and which aren't*     for layer in *model*.layers:
          print("{}: {}".format(layer, layer.trainable)) *# compile (with an even smaller learning rate)*     opt = Adam(*learning_rate*=1e-5)
 *model*.compile(
             *optimizer*=opt,
             *loss*='binary_crossentropy',
             *metrics*=[tf.keras.metrics.AUC()]
             ) return *model*model_fine_tuned = fine_tune_model(model)****
```

****å› ä¸ºå¾®è°ƒä¹Ÿå°†ä½¿ç”¨ç›¸åŒçš„æ•°æ®å‘ç”Ÿå™¨ï¼Œå³`trainGen`ã€`valGen`å’Œ`testGen`ï¼Œæ‰€ä»¥é‡ç½®å®ƒä»¬ä»¥ä¾¿å®ƒä»¬ä»æ•°æ®é›†ä¸­çš„ç¬¬ä¸€ä¸ªæ ·æœ¬å¼€å§‹éå¸¸é‡è¦ã€‚****

```
****trainGen.reset()
valGen.reset()
testGen.reset()****
```

****æœ€åï¼Œè®©æˆ‘ä»¬è®¾ç½®æå‰åœæ­¢å’Œæ¨¡å‹æ£€æŸ¥ç‚¹(æ³¨æ„ï¼Œæˆ‘ä»¬å·²ç»å°†`patience`å¢åŠ åˆ° 20ï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨å°†è®­ç»ƒæ›´é•¿æ—¶é—´ï¼Œå³ 50 `epochs`)ï¼Œç„¶åå¼€å§‹è®­ç»ƒã€‚****

```
*****# implementing early stopping* es_tune = EarlyStopping(
     *monitor*='val_loss', 
     *mode*='min',  
     *patience*=20, 
     *verbose*=1  
     )*# implementing model checkpoint* mc_tune = ModelCheckpoint(
      'fine_tuned_house.h5',
       *monitor*='val_loss',
       *mode*='min',
       *verbose*=1, 
       *save_best_only*=True
      )hist = model_fine_tuned.fit(
      *x*=trainGen,
      *steps_per_epoch*=totalTrain // BATCH_SIZE,
      *validation_data*=valGen,
      *epochs*=50,
      *verbose*=2,
      *callbacks*=[es_tune, mc_tune]
     )****
```

****![](img/a1c4636fca8efc60c166daedd428d32e.png)****

## ****ç‰¹å¾æå–æ­¥éª¤åçš„æ¨¡å‹æµ‹è¯•****

****![](img/5aff6fba1c3fcd15623afb4b1144603a.png)****

****é€šè¿‡ä¸ä¹‹å‰çš„æ··æ·†çŸ©é˜µè¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬åªæˆåŠŸåœ°å°†æ­£ç¡®é¢„æµ‹çš„å›¾åƒæ•°é‡å¢åŠ äº† 2 ä¸ª(å‚è§ä¸¤å¼ çƒ­å›¾ä¸­çš„å¯¹è§’çº¿å€¼)ã€‚****

****ä½œä¸ºæœ€åçš„å¥å…¨æ€§æ£€æŸ¥ï¼ŒæŸ¥çœ‹è¿™ä¸ªå¾®è°ƒæ­¥éª¤æ˜¯å¦æ˜¾ç¤ºå‡ºä»»ä½•è¿‡åº¦æ‹Ÿåˆçš„è¿¹è±¡ä¹Ÿæ˜¯å¾ˆå¥½çš„ã€‚****

****![](img/9aad78244a3b92f9199b4d56575a362b.png)********![](img/55cf0a04a1eb6d7c33964e3844117cfc.png)****

******éªŒè¯æŸå¤±**ä¸ç¨³å®šï¼Œç¨³å®šåœ¨ 0.55 å·¦å³ï¼Œè¡¨æ˜æ¨¡å‹æ²¡æœ‰è¿‡åº¦æ‹Ÿåˆã€‚æ€»çš„æ¥è¯´ï¼ŒéªŒè¯é›†é¢„æµ‹çš„ **AUC** ç¡®å®éšç€æ›´å¤šçš„æ—¶æœŸå˜å¾—æ›´å¥½ï¼Œä½†å›æŠ¥å´åœ¨å‡å°‘ã€‚(ç®€å•åœ°è¯´ï¼Œæ›´é•¿æ—¶é—´çš„åŸ¹è®­ä¼¼ä¹ä¸ä¼šå¯¹æˆ‘ä»¬çš„æ¡ˆä¾‹æœ‰å®è´¨æ€§çš„å¸®åŠ©)ã€‚****

****èµ·åˆï¼Œæˆ‘è®¤ä¸ºè®­ç»ƒæ›²çº¿çš„æ³¢åŠ¨æ˜¯ç”±äºæ‰¹é‡å¤§å°ï¼Œå› ä¸ºå®ƒä»¬åœ¨ç½‘ç»œå¦‚ä½•å­¦ä¹ ä¸­å‘æŒ¥äº†ä½œç”¨ã€‚ç±»ä¼¼åœ°ï¼Œè¿‡å¤§çš„å­¦ä¹ é€Ÿç‡ä¼šé˜»ç¢æ”¶æ•›ï¼Œå¹¶å¯¼è‡´æŸå¤±å‡½æ•°æ³¢åŠ¨ï¼Œé™·å…¥å±€éƒ¨æœ€å°å€¼ã€‚ç„¶è€Œï¼Œæ— è®ºæ˜¯å¢åŠ æ‰¹é‡è¿˜æ˜¯é™ä½å­¦ä¹ ç‡éƒ½æ— åŠ©äºå¹³æ»‘æ¢¯åº¦ã€‚****

****æƒ³åˆ°çš„å¦ä¸€ç§å¯èƒ½çš„è§£é‡Šæ˜¯ï¼Œç½‘ç»œå·²ç»è¾¾åˆ°äº†å…¶å…³äºç»™å®šæ•°æ®é›†çš„å®¹é‡ï¼Œå³ï¼Œå®ƒä¸èƒ½å†ä»ä¸­å­¦ä¹ æ›´å¤šã€‚è¿™æ˜¯å¯èƒ½çš„ï¼Œå› ä¸ºæˆ‘ä»¬æ­£åœ¨å°è¯•è®­ç»ƒä¸€ä¸ªç›¸å¯¹è¾ƒå¤§çš„ç½‘ç»œ(è®°ä½ï¼Œæˆ‘ä»¬å·²ç»è§£å†»äº†ä¸€äº›é¢å¤–çš„å±‚ï¼Œè¿™æ„å‘³ç€å­˜åœ¨æ›´å¤šçš„å¯è®­ç»ƒå‚æ•°)ï¼Œä»…ä½¿ç”¨ 344 ä¸ªæ ·æœ¬ï¼Œè¿™äº›æ ·æœ¬æ— æ³•æä¾›è¶³å¤Ÿçš„ä¿¡æ¯æ¥å­¦ä¹ é—®é¢˜(è¿›ä¸€æ­¥)ã€‚****

*****æ³¨æ„:åœ¨å°†æ›´å¤šå›¾åƒæ¨è¿›è®­ç»ƒè¿‡ç¨‹ä»¥å¸Œæœ›æ”¹è¿›æ¨¡å‹ä¹‹å‰ï¼Œå¯èƒ½å€¼å¾—å¯¹æ¨¡å‹è¶…å‚æ•°ã€train:val åˆ†å‰²ã€é¢„è®­ç»ƒæƒé‡çš„é€‰æ‹©(æ¥è‡ª* [*å˜ˆæ‚å­¦ç”Ÿ*](https://github.com/google-research/noisystudent) *è®­ç»ƒçš„æƒé‡å·²çŸ¥æ¯”æ¥è‡ª ImageNet è®­ç»ƒçš„æƒé‡æ›´å¥½*[](https://arxiv.org/pdf/1911.04252.pdf)**)ä»¥åŠç½‘ç»œæ¶æ„æœ¬èº«è¿›è¡Œä¿®æ”¹ã€‚******

# ****æœªæ¥çš„å·¥ä½œ****

****åœ¨æœ€è¿‘çš„[è®ºæ–‡](https://arxiv.org/pdf/1911.04252.pdf)å’Œ[è§†é¢‘](https://youtu.be/q7PjrmGNx5A?t=2240)ä¸­å·²ç»è¯å®ï¼Œä½¿ç”¨æœªæ ‡è®°å’Œæ ‡è®°æ•°æ®é›†çš„è”åˆè®­ç»ƒä¼˜äºç®¡é“ï¼Œåœ¨ç®¡é“ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨æœªæ ‡è®°æ•°æ®è¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶ååœ¨æ ‡è®°æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒã€‚è¿™è¢«ç§°ä¸ºåŠç›‘ç£å­¦ä¹ ï¼Œå°†æ˜¯æˆ‘ä»¬ä¸‹ä¸€ä¸ªæ•™ç¨‹çš„é‡ç‚¹ã€‚è¿™å°†å…è®¸æˆ‘ä»¬å……åˆ†åˆ©ç”¨æ•°æ®é›†ä¸­éš¾ä»¥è·å¾—æ ‡ç­¾çš„å‰©ä½™å›¾åƒã€‚****

****åšæŒäº†è¿™ä¹ˆä¹…ï¼Œå¾ˆå€¼å¾—ç§°èµã€‚ğŸ¥‚****

****å‰å¾€[ç¬¬ 2 éƒ¨åˆ†](https://varshitasher.medium.com/deploying-an-end-to-end-deep-learning-project-with-few-clicks-part-2-89009cff6f16)äº†è§£å¦‚ä½•å°†è¿™ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹åŒ…è£…åœ¨ flask åº”ç”¨ç¨‹åºä¸­ã€‚æˆ‘ä»¬è¿˜å‡†å¤‡å†™ä¸€ä¸ªåˆå¿«åˆè„çš„å‰ç«¯ï¼Œæœ€ååœ¨ Heroku ä¸Šéƒ¨ç½² appã€‚****

****åœ¨é‚£ä¹‹å‰:)****

****æˆ‘å–œæ¬¢å†™å¾ªåºæ¸è¿›çš„åˆå­¦è€…æŒ‡å—ã€æ“ä½œæŒ‡å—ã€é¢è¯•é—®é¢˜ã€ML/AI ä¸­ä½¿ç”¨çš„è§£ç æœ¯è¯­ç­‰ã€‚å¦‚æœä½ æƒ³å®Œå…¨è®¿é—®æˆ‘çš„æ‰€æœ‰æ–‡ç« (ä»¥åŠå…¶ä»–åª’ä½“ä¸Šçš„æ–‡ç« )ï¼Œé‚£ä¹ˆä½ å¯ä»¥ä½¿ç”¨ [***æˆ‘çš„é“¾æ¥***](https://varshitasher.medium.com/membership)**è¿™é‡Œ* ***æ³¨å†Œã€‚********

****[](/deploying-an-end-to-end-deep-learning-project-with-few-clicks-part-2-89009cff6f16) [## é€šè¿‡å‡ æ¬¡ç‚¹å‡»éƒ¨ç½²ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ é¡¹ç›®:ç¬¬ 2 éƒ¨åˆ†

### ä» Jupyter ç¬”è®°æœ¬åˆ° Flask åº”ç”¨ç¨‹åºé‡‡ç”¨æ¨¡å‹ï¼Œä½¿ç”¨ Postman å’Œ Heroku éƒ¨ç½²æµ‹è¯• API ç«¯ç‚¹

towardsdatascience.com](/deploying-an-end-to-end-deep-learning-project-with-few-clicks-part-2-89009cff6f16) [](/fine-tuning-hubert-for-emotion-recognition-in-custom-audio-data-using-huggingface-c2d516b41cd8) [## æ£€æµ‹è¯­éŸ³æ•°æ®ä¸­çš„æƒ…æ„Ÿ:ä½¿ç”¨ Huggingface å¾®è°ƒ HuBERT

### æ„å»ºè‡ªå®šä¹‰æ•°æ®åŠ è½½å™¨ã€å®éªŒæ—¥å¿—ã€æ”¹è¿›æŒ‡æ ‡çš„æŠ€å·§å’Œ GitHub repoï¼Œå¦‚æœæ‚¨æƒ³äº†è§£â€¦

towardsdatascience.com](/fine-tuning-hubert-for-emotion-recognition-in-custom-audio-data-using-huggingface-c2d516b41cd8) [](https://varshitasher.medium.com/six-reasons-to-switch-to-this-podcast-app-today-3a396ada0a2b) [## ä»Šå¤©åˆ‡æ¢åˆ°è¿™ä¸ªæ’­å®¢åº”ç”¨ç¨‹åºçš„å…­ä¸ªç†ç”±ï¼

### å¸¦ä¸Šä½ çš„æœ‹å‹ã€‚

varshitasher.medium.com](https://varshitasher.medium.com/six-reasons-to-switch-to-this-podcast-app-today-3a396ada0a2b) [](/understanding-python-imports-init-py-and-pythonpath-once-and-for-all-4c5249ab6355) [## äº†è§£ Python å¯¼å…¥ï¼Œ__init__ã€‚py å’Œ pythonpath â€”ä¸€åŠ³æ°¸é€¸

### äº†è§£å¦‚ä½•å¯¼å…¥åŒ…å’Œæ¨¡å—(ä»¥åŠä¸¤è€…ä¹‹é—´çš„åŒºåˆ«)

towardsdatascience.com](/understanding-python-imports-init-py-and-pythonpath-once-and-for-all-4c5249ab6355)****