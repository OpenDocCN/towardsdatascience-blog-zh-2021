# 使用 XGBoost 和 PyTorch 进行迁移学习:破解 Alexnet for MNIST 数据集

> 原文：<https://towardsdatascience.com/transfer-learning-with-xgboost-and-pytorch-hack-alexnet-for-mnist-dataset-51c823ed11cd?source=collection_archive---------12----------------------->

![](img/208c39694ea5e973ae372079ae08f617.png)

马修·施瓦茨在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

> **更新**:发现我关于渐变提升的新书[实用渐变提升](https://www.amazon.fr/dp/B0BJ82S916)。这是用 python 中的许多例子对渐变增强的深入探究。

<https://www.amazon.com/dp/B0BJ82S916>  

在处理深度学习时，训练一个模型总是很复杂:不仅是一项耗时且成本高昂的任务，还需要非常大的数据集。微调模型架构也相当繁琐，使用超参数调整/ AutoML 仍然是一个开放的计算耗时的主题。

希望有另一种选择:迁移学习。这种技术允许在新用例中重用预先训练好的模型，避免昂贵的培训。

在本文中，我们将展示如何将 [*XGBoost*](https://xgboost.readthedocs.io/en/latest/) 和 [PyTorch](http://www.pytorch.org) 结合起来，将 *Alexnet* 获得的知识转移到一个新的应用程序中。

最初，Alexnet 在 1000 个类别的子集上接受了 ImageNet 大规模视觉识别挑战(ILSVRC)的培训。给定一幅图像，这个网络能够将其分类到 1000 个类别中的一个。这些课程的完整列表可以在[这里](https://gist.github.com/kayhman/8bb7bcc4563cf33664d9b03bb942acda)找到。

原文值得一读，可以在这里找到[。](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

# 使用 Alexnet

在转移 Alexenet 深度神经网络训练获得的知识之前，我们要提醒自己如何使用它。

让我们回忆一下，Alexenet 是一个深度卷积网络，有 5 个卷积层和 3 个用于功能部分的池层。该分类使用 3 个密集层。Alex Krizhevsky 带来的创新是为了证明网络的深度对表演至关重要。这是通过设计一种新的算法在 GPU 上运行训练来实现的。

我们将把这种预先训练好的架构应用到以下照片中，这些照片是在 Unsplash 上随机挑选的:

<https://unsplash.com/photos/Sg3XwuEpybU>  

多亏了 [pytorch](https://pytorch.org/) ，这可以用几行 python 代码完成:

这几行代码加载图像并使用 Alexnet 对其进行分类。作者代码。

多亏了 Pytorch，我们只需一行代码就可以访问预先训练好的模型。多方便啊！

Alexnet 的输出是一个 1000 维的概率数组，即类的数量。该列表将前 5 名列为最佳标签。

正如你在这段代码的最后一行看到的，深度神经网络识别图像，并使用狗的名字正确地标记它。注意*变换*函数，用于缩放输入图像并将其转换为 PyTorch 张量。

# 转移 Alexnet 学习

迁移学习的思想是将在深度神经网络(或任何其他类型的模型)的训练期间获得的知识应用于试图解决给定问题的另一个问题。

在 Alexnet 的情况下，该网络已经学会对 ImageNet 大规模视觉识别挑战(ILSVRC)的图像进行分类。如上所述，网络输出是 1000 个类别中每一个的概率数组。

为了执行这种分类，Alexnet 使用与 3 个池层交织的 5 个卷积层来计算特征。该层堆栈的输出被送入 3 个密集层，以执行分类并生成最终的 1000 个概率。

我们在这里想要做的是访问特征部分的输出，并从它的知识中获益。

我们在本文中想要验证的假设是，为分类器训练的深度卷积神经网络足够通用，可以应用于另一个问题。

此外，出于兴趣和利益，我们将使用 XGBoost 替换密集神经网络分类器。

# 入侵 Alexnet 来识别数字

为了验证我们的假设， [MNIST 数据集](http://yann.lecun.com/exdb/mnist/)是一个非常好的候选者。这是 Yann Lecunn 广泛用于建立分类器以识别手写数字的数据库之一。再一次， [PyTorch](https://pytorch.org/) 简化了我们的工作，因为它提供了对 MNIST 数据集的便捷访问。

该数据集包含 60 000 个数字，它们的标签在训练集中，另外 10 000 个标记的数字用于测试集。每个数字存储为灰度 28x28 图像。因此，我们不能将它们直接输入 Alexnet。这将是必要的重新调整他们，并将其转换为 RGB。

在这一步，现在可以使用非常方便的 *extract_features* 方法将图像输入 Alexnet 并获取特征。

最后，由于我们计划使用 XGBoost 作为分类器，我们需要将输出存储为 CSV 文件，该文件可以作为 Pandas Dataframe 轻松加载。

所有这些转换都由下面的 python 清单处理:

这个脚本对图像进行预处理，并将它们传送到 Alexnet，这样我们就可以得到图像的特征。作者代码。

运行这个脚本会生成一个 csv 文件，其中每一行都包含给定数字的所有特征及其标签。我们所要做的就是用这些数据装配一个 xgb 分类器。预处理测试数据需要一个类似的脚本。

因为有大量的样本和特征，所以可以根据这些数据的子集进行训练，比如说 10 000 个样本。下面是如何做到这一点:

从预处理数据中编写脚本训练 XGBClassifier。作者代码。

最后几行远远没有给出该模型的完整评估，而是倾向于表明将来自深度神经网络和 XGB 分类器的预先学习的知识相结合是可行的。

注意，由于训练可能需要一些时间，我们使用 *joblib* 将模型存储为 pkl。因此，在进行评估时，我们可以轻松地重新加载它。

下面几行更准确地评估了这个模型:

评估模型性能。作者代码

如混淆矩阵和分类报告所示，分类确实不错。

我们也许可以做得更好，在 XGB 分类器上使用超参数调整，但它已经相当不错了。

# 结论

重用预先训练好的模型是构建新模型的一种非常有效的方式，而没有执行完整训练的负担:收集数据、调整模型、训练模型、评估模型等等。所有这些步骤都可以通过迁移学习来避免。

我们还展示了结合不同类型的模型，利用它们各自的优势是可能的。这里，例如 XGBoost 是一种非常好的基于深度神经网络输出执行分类的方法。PyTorch 非常适合操纵神经网络部分。

为了进一步说明这个例子，最好从卷积网络的第一层提取特征，看看学习如何从这些中间层转移。