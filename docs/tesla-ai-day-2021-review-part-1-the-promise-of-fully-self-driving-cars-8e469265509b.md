# 特斯拉 2021 年人工智能日回顾——第 1 部分:完全自动驾驶汽车的承诺

> 原文：<https://towardsdatascience.com/tesla-ai-day-2021-review-part-1-the-promise-of-fully-self-driving-cars-8e469265509b?source=collection_archive---------8----------------------->

## 人工智能|新闻

## 特斯拉 Autopilot 是如何工作的？

![](img/42bb3a52129782ebe7b4aa4c0b70cfe5.png)

照片由 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的 [Jp Valery](https://unsplash.com/@jpvalery?utm_source=medium&utm_medium=referral)

本文是 4 部分系列的第一部分:

> **1。完全自动驾驶汽车的承诺**
> 
> 2.[训练数据。汽车是如何学习的？](/tesla-ai-day-2021-review-part-2-training-data-how-does-a-car-learn-e8863ba3f5b0)
> 
> 3.[项目道场。特斯拉的新型超级计算机](/tesla-ai-day-2021-review-part-3-project-dojo-teslas-new-supercomputer-715d102dbb29)
> 
> 4.[为什么特斯拉 2022 年不会有自主人形机器人](/tesla-ai-day-2021-review-part-4-why-tesla-wont-have-an-autonomous-humanoid-robot-in-2022-76dff743f885)

几周前，特斯拉举办了 2021 年最重要的人工智能活动之一；特斯拉人工智能日(你可以在这里观看整个过程)。

该公司的领先研究人员和工程师展示了硬件、软件、人工智能、机器人、计算和自动驾驶汽车的最新发展。该活动的重点是吸引潜在候选人在当前和未来项目中工作的注意力。

演讲分为四大部分。我将使用相同的大纲来分隔本系列的文章:

*   **特斯拉自动驾驶。**如何让汽车完全自主解决视觉、规划和控制。
*   **培训数据生成。**如何创建训练网络所需的大数据集:手动标注、自动标注和模拟。
*   **道场和 D1 芯片项目。**下一代 AI 训练计算机。
*   **特斯拉机器人。**马斯克说，自主人形机器人将执行“危险、重复、无聊的任务”。"将来体力劳动将是一种选择."

先说第一部分:**完全自动驾驶汽车的承诺。**

> **免责声明:**由于无法联系到特斯拉，我将在相应的时间段直接链接到 YouTube 演示文稿上的相关视觉效果。我建议你在阅读时点击这些链接，以便更好地理解这些解释。

几十年来，自动驾驶汽车一直是许多大型科技公司的关注焦点。所有的承诺都没有兑现，因为解决现实世界的人工智能是另一个层面的挑战。大多数最先进的人工智能系统都生活在虚拟世界中。穆泽罗和 GPT-3 不像我们一样与现实世界互动。但是自动驾驶汽车需要。

自 2015 年以来，特斯拉的人工智能团队一直试图在最高级别部署完全自动驾驶(FSD)。当时，马斯克说:“进行比人类安全得多的自动驾驶，比人们想象的要容易得多。[……]我几乎把它视为一个已经解决的问题。”从某种意义上来说，他陷入了同一个陷阱，当美国开国元勋们认为 AGI 可以在一代人之内解决的时候

消防处车辆的最后期限已经被推迟了几次。2019 年，他[说](https://ark-invest.com/podcast/on-the-road-to-full-autonomy-with-elon-musk/):“我认为今年我们将实现完全的自动驾驶。”虽然没有发生，但是他们一直在进步。

就在两个月前，他在推特上认识到了挑战的严重性:

马斯克认识到了现实世界人工智能的挑战。[推特](https://twitter.com/elonmusk/status/1411280212470366213)

在看了特斯拉人工智能日的活动后，我可以说他们已经走了这么远来达到 FSD 是令人惊讶的。它没有得到完美的解决——我认为它永远不会得到解决，因为深度学习系统的本质更适合处理不需要完美精确度的问题。不过，如果我们的目标是让自动驾驶系统足够好，让人们乐于信任它，那么我们肯定很接近了。

# 自动驾驶——从视觉感知到行动

自动驾驶仪的目的是模拟动物的视觉和动作系统。FSD 汽车需要快速准确地感知环境，然后做出相应的计划和行动。因为现实世界对可能发生的事情几乎没有限制，所以系统需要能够检测和识别任何事物，并在最多样的情况下正确地行动。

以下是对自动驾驶系统的高级描述:

*   这辆车有八个摄像头，可以捕捉所有角度，并将原始视觉信息以图像的形式输入系统。这些图像然后由一个复杂的神经网络处理(我很快会解释)，这反过来又会生成周围事物的预测。
*   这个预测被投射到他们所谓的“向量空间”我们可以将向量空间想象成汽车及其周围环境的 3D 第三人称图像。
*   该信息然后被传送到规划算法，该算法定义了要遵循的轨迹。
*   最后，控制系统执行实际的转向和加速/制动模式。

[这里是](https://youtu.be/j0z4FweCy4M?t=2989)在从图像空间转换到向量空间后，八个摄像头所看到的和汽车“看到的”之间的比较。

用特斯拉人工智能总监安德烈·卡帕西(Andrej Karpathy)的话说:

> “我们正在有效地从头开始制造一种人造动物。*[……]*汽车可以被认为是一种动物；它四处移动，感知环境，自主智能地行动。”

像任何其他动物一样，一辆完全自主的汽车需要两组系统:**感觉系统和运动系统**。特别是，考虑到手头问题的具体情况，传感器系统只是视觉系统，运动系统由规划和控制模块组成——动物的运动部分由方向盘、加速踏板和刹车踏板代替。

我将把文章的其余部分分成自动驾驶的两个主要功能模块，并在最后给出一些见解:

1.  处理视觉信息并进行向量空间预测的神经网络。
2.  规划和控制的算法:汽车如何到达目的地。
3.  一些见解。

# 1.视觉问题——汽车如何看待这个世界？

在某种意义上，Autopilot 中的视觉神经网络(我将称为 NN)是人类视觉系统的松散类比。摄像头是汽车的“眼睛”，它感知光线并将信息发送到处理模块——汽车的“视觉皮层”。这些模块既模拟了处理线条、方向、深度、形状等的视觉皮层低级区域(V1、V2、V4)，也模拟了识别整个物体的高级区域(IT)。

神经网络经历了多年的变化和发展。卡帕西回顾了这三个不可避免的问题:

*   单一主干架构→汽车需要处理不同的任务。
*   在图像空间中预测→不足以在 3D 世界中导航。
*   处理单个帧→内存不足。

## 用消防栓处理多项任务

HydraNets 是一个神经网络，它有一个共同的主干，但不同的头部——针对每个任务进行了特殊化。通过这种架构，网络可以检测汽车或行人，重建道路表面和线条，或者识别信号和交通灯。所有这些都是通过一个神经网络实现的。多任务模式的精髓，现在非常流行。

## 从图像空间预测到向量空间预测

他们还意识到，在向量空间中预测比在图像空间中预测是更好的解决方案。

在图像中进行预测是计算机视觉的标准。如果你正在检测、识别、辨认、分割物体、人，甚至动作和手势，那么在图像空间中进行预测是有意义的。原因是很容易收集和标记图像，对于大多数任务来说，图像标记可以完成工作。

但是，以在现实世界中采取相应行动为目的获取视觉感知信息是一项非常不同的任务。

自动驾驶的本质要求在现实世界空间，即向量空间中进行预测。通过这种转变，特斯拉采取了一种独特的姿态来解决 FSD 问题。

值得注意的是，图像空间和向量空间之间的转换从系统的第一个版本就存在了。关键的区别在于，他们现在在做出预测之前*进行转换。*

现在，他们如何完成从图像到向量空间的新转换呢？为了解决这个问题，他们发现变压器是最好的选择。然后，来自图像的逐像素信息将与 3D 向量空间中的特定位置相关联。

[这里有一张](https://youtu.be/j0z4FweCy4M?t=3754)图像，展示了图像/向量空间预测的结果。左/右下图分别显示了当在图像/向量空间中进行预测时，汽车如何“看到”道路。区别是激进的。正如卡帕西所说，“你实际上可以在(新版本)上驾驶。”

在向量空间中进行预测的一个副产品是，所有相机都提供信息来进行预测。对于物体太大而不适合单个相机(大型卡车)的情况，或者当一辆汽车遮挡另一辆汽车时，这增加了预测的鲁棒性。

## 将内存注入汽车

Autopilot 现在可以处理不同的任务，并非常好地感知周围的环境。但是世界有 4 个维度。物体会移动和变化。汽车本身相对于它们移动。他们如何包含这些信息，以便汽车记住刚刚发生的事情？

例如，环形交叉路口或强制性方向的信号往往在需要实际行动之前几米发出。他们如何给汽车记忆，让它记住这些信息并做出正确的决定？自动驾驶仪如何测量速度，甚至识别汽车是否在移动？如果是逐帧处理信息，汽车就不会考虑时空背景。

为了解决这个问题，他们包括了一个“特征队列”来给神经网络注入一种记忆存储。如果一段时间过去了，或者汽车行驶了一段距离，神经网络可以查找存储记录并使用这些信息——检测被遮挡的汽车，或者在转弯车道上转弯。

要素队列获取单个帧并生成视频，然后在空间 RNN 中立即进行处理。[下面是](https://youtu.be/j0z4FweCy4M?t=4133)实时空间 RNN 的预测。

处理视频而不是帧，以及向量空间预测，为系统提供了预测鲁棒性。**多摄像机和多帧处理都为整个系统提供了大量的鲁棒性和精确性。**

概括来说，这是他们对自动驾驶仪视觉系统的三个主要改进:

*   **消防栓**——多头——允许网络处理不同的任务，而不仅仅是检测汽车。
*   **从图像到向量空间**生成道路和汽车周围物体的精确预测。它提供了鲁棒性的困难情况下，如遮挡和大对象。
*   **记忆存储**提供过去的信息——无论是空间方面的还是时间方面的——这样汽车就可以在事后做出明智的决定。

[这是](https://youtu.be/j0z4FweCy4M?t=4279)视觉神经网络的最终架构，在一个单一结构中包含所有这些模块，该结构获取原始信息，并在向量空间中预测、检测和识别车外的一切。

# 2.规划和控制——在现实世界中行动

感知世界只是等式的一部分。采取行动甚至更具挑战性。被动感知仅仅是凝视世界，但行动需要我们考虑世界如何与我们互动，反之亦然。这就是为什么特斯拉把 Autopilot 最基本的原则定为“永不崩溃”。不管这辆车做什么，它都不能碰其他任何东西。

如今，Autopilot 使用显式方法来解决规划和控制，这意味着他们直接用手硬编码这些方法，而不使用机器学习技术。然而，有些情况不能用这种方法充分处理，所以他们计划将来使用基于学习的方法。

他们设想了一个规划和控制的双系统结构，结合了:

*   明确的计划
*   基于学习的规划

## 明确的计划——努力实现目标

我在上一节中描述的视觉系统和当前包含计划和控制的行动系统有三个关键的区别。

这两种系统服务于不同的目的。我做这个比较的原因是大多数人都熟悉像视觉神经网络这样的人工智能系统，但不熟悉规划/控制系统。在这里，我的目的是让人们了解它的复杂性。

第一个区别是，视觉系统是完全虚拟的，从这个意义上说，除了汽车，没有人会直接受到它的影响。相比之下，动作系统对现实世界有影响。它直接影响着我们的生活——无论是作为乘客还是行人。

这就是工程团队优先考虑安全、舒适和效率的原因。只有当这些优先事项得到充分满足时，到达目的地才是最重要的。

第二个区别是，正如埃隆·马斯克暗示的那样，任何面向现实世界的系统都会遇到尽可能多的自由度。

与在现实世界中导航相比，解决国际象棋、围棋甚至星际争霸都很容易。用更专业的术语来说，这意味着空间是**非凸的**——系统可能会陷入一个很好的局部最小值，这个最小值解决了一个特定的情况，但作为一般的解决方案是无效的——以及**高维度**——系统需要处理许多参数，如加速度、轨迹等，以计划下一步要做的事情。

![](img/1d2ad64407a03211b58f6f620889c126.png)

非凸空间可以有几个极小值。[谭宝琳](https://www.slideshare.net/WiMLDS_Paris/firstorder-methods-for-nonsmooth-nonconvex-optimization-applications-in-imaging-by-pauline-tan-postdoc-researcher-cmla-ens-parissaclay)

当他们试图同时解决这两个问题时，面临着进退两难的局面。

一方面，非凸性是用**离散搜索算法**解决的，因为它们不会陷入局部极小值，但由于维数高，它们可能变得难以计算。另一方面，**连续函数优化**算法容易处理高维空间，但会陷入局部极小值。

他们找到了一种 [**混合方法解决**](https://youtu.be/j0z4FweCy4M?t=4509) **:**

简而言之，从视觉系统提供的向量空间预测开始，他们用**粗搜索**解决非凸性，以获得**凸走廊**，然后将**连续优化方法**应用于输出，以获得**平滑轨迹**。

这个想法是通过使用具有少量特征的物理模型和应用非精细网格来避免搜索方法中的高维瓶颈——他们发现在薄度和计算时间之间进行权衡是一个很好的解决方案，在 2.5 毫秒内达到 2500 次搜索。

[这里是](https://youtu.be/j0z4FweCy4M?t=4567)系统如何搜索最佳路线的可视化。该系统快速地将空间从非凸转换为凸，找到一组构成他们所谓的凸走廊的候选方案。然后，考虑到安全性、舒适性和效率的最大化，选择最佳轨迹，这就是凸走廊解。

凸走廊是在其中找到最佳轨迹的空间。然而，由于粗搜索方法缺乏精度，只有在信息通过连续优化函数后才能获得最终解。

现在，汽车必须采取必要的行动来执行计划。[这里是](https://youtu.be/j0z4FweCy4M?t=4755)，它使用连续优化算法快速处理可能轨迹的凸走廊集内的高维参数空间，以找到一条平滑的路径。

第三个区别，正如我在本节开始时所说的，是我们必须考虑其他代理人如何行动——或将要如何行动——以找到最佳的联合计划。视觉系统感知到这些信息，但却不做任何处理。但是计划系统必须相应地适应和改变，因为其他代理人的行为可能会以激烈的方式修改我们的行为。

概括地说，以下是关于计划和控制系统的要点:

*   安全性、舒适性和效率被最大化。
*   结合粗搜索和连续优化函数的混合方法解决了非凸性和高维性。
*   该系统首先使用物理模型搜索最佳轨迹集，即凸走廊。
*   然后，它使用连续优化方法找到最终的解决方案。
*   控制系统执行计划的解决方案，使汽车到达目的地。

## 基于学习的规划—处理复杂情况

在有些情况下，粗略搜索+连续优化的组合不足以有效解决规划问题(例如，高峰时间人口高度密集的城市中心)。对于这些情况，他们将实现基于**学习的方法**——目前版本的 Autopilot 中尚未使用。

打个比方，来自视觉神经网络的向量空间预测提供了一个类似于多人雅达利游戏的框架。因为 Atari games 已经被 DeepMind 的 MuZero 解决了，所以特斯拉决定复制这个解决方案，这似乎完全符合规划问题。

**神经网络和蒙特卡罗树搜索(MCTS)** **的结合提供了一个全局解决方案**。神经网络给出状态和动作分布，然后 MCTS 算法使用这些分布来达到目标，同时考虑到成本函数，如与对象干预的接近度、不适或旅行时间。神经网络为搜索算法提供了全局上下文，因此它不会陷入局部最小值。[下面是](https://youtu.be/j0z4FweCy4M?t=4969)两种方法的对比，展示了神经网络+ MCTS 方法如何超越其他选项。

# 自动驾驶架构

[这是视觉、规划和控制系统的完整架构:](https://youtu.be/j0z4FweCy4M?t=5021)

1.  视觉神经网络将图像数据转换成向量空间预测。
2.  这些预测和中级特征一起进入仍在开发中的神经网络规划器，该规划器主要用于在复杂情况下生成轨迹分布，如在市中心驾驶。
3.  视觉神经网络可以与神经网络规划器一起使用明确的成本函数(如安全、舒适或效率度量)进行端到端的训练。
4.  向量空间预测和轨迹分布随后被输入到显式规划器中，以便它能够生成实际的转向和加速命令。

# 一些见解

## 为什么只有摄像头？

一个有趣的观察是，特斯拉 Autopilot 仅使用原始视觉信息进行预测，并最终引导汽车到达目的地。Teslas 有 8 个摄像头分布在汽车两侧，但没有像激光雷达这样的传感器。

在 2019 年的 Autonomy day 中，埃隆·马斯克[说](https://techcrunch.com/2019/04/22/anyone-relying-on-lidar-is-doomed-elon-musk-says/):“激光雷达是傻瓜的差事。任何依赖激光雷达的人都难逃一死。(它们)是不必要的昂贵传感器。”他认为[激光雷达是“一根拐杖”,将引导试图建立自动驾驶系统的公司走向“局部最大化”](https://www.theverge.com/2021/5/24/22451404/tesla-luminar-lidar-elon-musk-autonomous-vehicles)

这里的理由是，尽管激光雷达技术对于进一步增强基于摄像机的视觉系统是有用的，但它是昂贵的并且是不必要的。人类在没有类似雷达的技术的情况下自主导航世界，所以汽车也应该能够。

但是我们不知道。有时候，从自然中转移技术路线已经产生了惊人的结果——轮子、飞机、潜艇……我们能否开发一个仅基于视觉信息的自主系统，或者我们是否需要将它与其他感官输入结合起来？时间会证明一切。

## 无人驾驶汽车的道德困境

有一个非常有趣的网站叫做[道德机器](https://www.moralmachine.net/)，展示玩具道德困境场景。它在人——或动物——面前展示了一辆自动驾驶汽车，你必须决定“自动驾驶汽车应该做什么。”

![](img/301261e198af10136c03937c1ef8400b.png)

自动驾驶汽车的道德困境。[道德机器](https://www.moralmachine.net/)

大多数困境描述了极不可能的场景，但这个想法是将焦点放在一个可能最终成为一个非常现实的问题的哲学问题上:当人类生命处于不可避免的风险时，汽车如何决定该做什么？

进一步思考，我们可以问另一个没有答案的问题:谁该受到谴责？

那辆车。虽然马斯克称他们为“半有知觉”，但没有人会接受。设计失败系统的工程师？首席执行官？公司？在这样的事情发生之前，我们需要填补一个法律空白。

特斯拉汽车已经卷入了正在调查中的[事故](https://theconversation.com/why-the-feds-are-investigating-teslas-autopilot-and-what-that-means-for-the-future-of-self-driving-cars-166307)。但这些困境暗示了一个更深层次的问题，因为我们假设汽车 100%精确和安全。如果我们做到了——别指望了——公司会被追究法律责任吗？人类能解决得更好吗？

最后一个附带问题是，尽管自动驾驶汽车比我们更安全，但我们可能更反感机器人杀死了那些人。

## 垂直整合和特斯拉机器人

由于特斯拉人工智能日是一个如此重要的活动，许多人对该演示进行了回顾和评论。最突出的一个方面是特斯拉“从零开始”设计和创造产品的事实，正如 Karpathy 所说。

他们制造汽车，视觉神经网络，规划和控制模块，训练这一切的数据集……这种方法使他们能够更紧密地掌握技术，更重要的是，能够将这些系统转化为其他形式。这就是他们想用特斯拉机器人做的事情(我将在本系列的最后一部分详细讨论)。

Elon Musk 表示，他们希望“使用我们在汽车中使用的所有相同工具”来制造机器人。他可能没有意识到的是，制造一个四肢活动的人形机器人比制造一辆自动驾驶汽车要复杂得多。汽车作为刚性固体移动，因此它不需要考虑姿态或质心的变化，以及通过触摸或抓取与环境的直接交互。

然而，即使不是所有东西都可以立即转移，垂直整合可能会让特斯拉相对于波士顿动力公司等其他机器人公司具有明显的优势，波士顿动力公司需要用复杂的硬件来补偿愚蠢的软件。

如果你喜欢这篇文章，可以考虑订阅我的免费周报<https://mindsoftomorrow.ck.page>**！每周都有关于人工智能的新闻、研究和见解！**

**您也可以直接支持我的工作，使用我的推荐链接* [*这里*](https://albertoromgar.medium.com/membership) *成为中级会员，获得无限权限！:)**