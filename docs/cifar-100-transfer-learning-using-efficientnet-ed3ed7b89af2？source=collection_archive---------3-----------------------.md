# CIFAR 100:ä½¿ç”¨ EfficientNet è¿›è¡Œè¿ç§»å­¦ä¹ 

> åŸæ–‡ï¼š<https://towardsdatascience.com/cifar-100-transfer-learning-using-efficientnet-ed3ed7b89af2?source=collection_archive---------3----------------------->

## ä½¿ç”¨æœ€å…ˆè¿›çš„ EfficientNet-B0 è¿›è¡Œè¿ç§»å­¦ä¹ 

![](img/97b2167db4dcedd5971ae55dc87eca55.png)

ç›ä¸½å¨œÂ·ç»´å¡”è±åœ¨ [Unsplash](https://unsplash.com/photos/t809JJ6r9KA) ä¸Šæ‹æ‘„çš„ç…§ç‰‡

**å·ç§¯ç¥ç»ç½‘ç»œ** (CNN)æ˜¯ä¸€ç±»å¸¸ç”¨äºåˆ†æå›¾åƒçš„æ·±åº¦ç¥ç»ç½‘ç»œã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä¸€èµ·æ„å»ºä¸€ä¸ª CNN æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥æ­£ç¡®è¯†åˆ«ç‰©ä½“çš„å½©è‰²å›¾åƒå¹¶å°†å…¶åˆ†ç±»åˆ° CIFAR-100 æ•°æ®é›†çš„ 100 ä¸ªå¯ç”¨ç±»ä¸­çš„ä¸€ä¸ªã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬å°†é‡ç”¨ä¸€ä¸ªæœ€å…ˆè¿›çš„æŠ€æœ¯ä½œä¸ºæˆ‘ä»¬æ¨¡å‹çš„èµ·ç‚¹ã€‚è¿™ç§æŠ€æœ¯è¢«ç§°ä¸ºè¿ç§»å­¦ä¹ ã€‚â¡ï¸

æˆ‘ä»¬å…ˆæ¥äº†è§£ä¸€ä¸‹ä»€ä¹ˆæ˜¯è¿ç§»å­¦ä¹ ã€‚æˆ‘ä¸ä¼šè®²å¤ªå¤šç»†èŠ‚ï¼Œä½†ä¼šå°è¯•åˆ†äº«ä¸€äº›çŸ¥è¯†ã€‚ğŸ“

# **è¿ç§»å­¦ä¹ **

*å¦‚ã€Šæœºå™¨å­¦ä¹ åº”ç”¨ç ”ç©¶æ‰‹å†Œã€‹æ‰€è¿°ï¼Œ* ***è¿ç§»å­¦ä¹ *** *æ˜¯é€šè¿‡ä»ä¸€ä¸ªå·²ç»å­¦ä¹ è¿‡çš„ç›¸å…³ä»»åŠ¡ä¸­è¿ç§»çŸ¥è¯†ï¼Œåœ¨ä¸€ä¸ªæ–°ä»»åŠ¡ä¸­å¯¹å­¦ä¹ çš„æé«˜ã€‚*

ç®€å•æ¥è¯´ï¼Œè¿ç§»å­¦ä¹ æ˜¯ä¸€ç§æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œåœ¨ä¸€ä¸ªä»»åŠ¡ä¸Šè®­ç»ƒçš„æ¨¡å‹è¢«é‡æ–°ç”¨äºç¬¬äºŒä¸ªç›¸å…³çš„ä»»åŠ¡ã€‚æ·±åº¦å­¦ä¹ ç½‘ç»œæ˜¯èµ„æºé¥¥æ¸´çš„ï¼Œå¹¶ä¸”å…·æœ‰æ•°ç™¾ä¸‡ä¸ªå‚æ•°ï¼Œè®¡ç®—æˆæœ¬å¾ˆé«˜ã€‚è¿™äº›ç½‘ç»œç”¨å¤§é‡æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä»¥é¿å…è¿‡åº¦æ‹Ÿåˆã€‚å› æ­¤ï¼Œå½“ä¸€ä¸ªæœ€å…ˆè¿›çš„æ¨¡å‹è¢«åˆ›é€ å‡ºæ¥æ—¶ï¼Œé€šå¸¸éœ€è¦ç ”ç©¶äººå‘˜èŠ±è´¹å¤§é‡çš„æ—¶é—´è¿›è¡ŒåŸ¹è®­ã€‚ç”±äºä¸€ä¸ªæœ€å…ˆè¿›çš„æ¨¡å‹æ˜¯åœ¨èŠ±è´¹å¦‚æ­¤å·¨å¤§çš„èµ„æºåè®­ç»ƒå‡ºæ¥çš„ï¼Œç ”ç©¶è€…è®¤ä¸ºè¿™ç§æŠ•èµ„çš„æ”¶ç›Šåº”è¯¥æ˜¯å¤šæ¬¡æ”¶è·çš„ï¼Œå› æ­¤äº§ç”Ÿäº†è¿ç§»å­¦ä¹ çš„æ¦‚å¿µã€‚

è¿ç§»å­¦ä¹ çš„æœ€å¤§å¥½å¤„æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥é‡ç”¨æ•´ä¸ªæ¨¡å‹æˆ–æ¨¡å‹çš„æŸä¸€éƒ¨åˆ†ã€‚å—¯ï¼Œèªæ˜ï¼ğŸ˜è¿™æ ·æˆ‘ä»¬å°±ä¸ç”¨è®­ç»ƒæ•´ä¸ªæ¨¡å‹äº†ã€‚ç‰¹åˆ«æ˜¯ï¼Œè¿ç§»å­¦ä¹ å¯ä»¥èŠ‚çœæ—¶é—´å¹¶æä¾›æ›´å¥½çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨å¯ä»¥è¯†åˆ«æ±½è½¦çš„é¢„è®­ç»ƒæ¨¡å‹åˆ°ç°åœ¨è¯†åˆ«å¡è½¦ã€‚

ç°åœ¨è®©æˆ‘ä»¬äº†è§£ä¸€ä¸‹æˆ‘ä»¬å°†åœ¨è¿™é‡Œä½¿ç”¨çš„æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚

# EfficientNet-B0:æœ€å…ˆè¿›çš„æ¨¡å‹

[**EfficientNet**](https://arxiv.org/pdf/1905.11946.pdf) æ˜¯è°·æ­Œæ‰“é€ çš„ CNN çš„ä¸€ä¸ªå®¶æ—ã€‚ä¸å…¶ä»–æœ€å…ˆè¿›çš„æ¨¡å‹ç›¸æ¯”ï¼ŒâœŒï¸these CNN ä¸ä»…æä¾›äº†æ›´å¥½çš„å‡†ç¡®æ€§ï¼Œè€Œä¸”é€šè¿‡å‡å°‘å‚æ•°æ•°é‡æé«˜äº†æ¨¡å‹çš„æ•ˆç‡ã€‚EfficientNet-B0 æ¨¡å‹æ˜¯ä¸€ä¸ªç®€å•çš„ç§»åŠ¨å¤§å°çš„åŸºçº¿æ¶æ„ï¼Œå¹¶åœ¨ ImageNet æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚

åœ¨æ„å»ºç¥ç»ç½‘ç»œæ—¶ï¼Œæˆ‘ä»¬æé«˜æ¨¡å‹æ€§èƒ½çš„åŸºæœ¬æ–¹æ³•æ˜¯å¢åŠ å•å…ƒæ•°æˆ–å±‚æ•°ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•æˆ–ç­–ç•¥å¹¶ä¸æ€»æ˜¯å¥æ•ˆï¼Œæˆ–è€…æˆ‘å¿…é¡»è¯´ï¼Œåœ¨æŸä¸€ç‚¹ä¸Šæ²¡æœ‰å¸®åŠ©ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä¸º CIFAR-100 æ•°æ®é›†æ„å»ºäº†ä¸€ä¸ª 9 å±‚å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œå¹¶è®¾æ³•å®ç°äº†ä»… 59%çš„å‡†ç¡®ç‡ã€‚ä¸ä»…ä»…æ˜¯éšæœºçš„æœºä¼šã€‚ğŸ˜æˆ‘å¢åŠ å±‚æ•°æˆ–å•å…ƒæ•°çš„å°è¯•å¹¶æ²¡æœ‰è¿›ä¸€æ­¥æé«˜ç²¾åº¦ã€‚â˜¹ï¸ ( [é“¾æ¥åˆ°ä»£ç ](https://github.com/chetnakhanna16/CIFAR100_ImageRecognition/blob/master/CIFAR100_ImageClassification_FinalCode_001081074.py))

**EfficientNet çš„å·¥ä½œç†å¿µæ˜¯ï¼Œæä¾›ä¸€ç§æœ‰æ•ˆçš„å¤åˆç¼©æ”¾æ–¹æ³•(ç¼©æ”¾æ·±åº¦/å®½åº¦/åˆ†è¾¨ç‡çš„æ‰€æœ‰ç»´åº¦)æ¥å¢åŠ æ¨¡å‹å¤§å°ï¼Œå¯ä»¥å¸®åŠ©æ¨¡å‹å®ç°æœ€å¤§çš„ç²¾åº¦å¢ç›Šã€‚**ä¸‹å›¾æ¥è‡ªåŸå§‹è®ºæ–‡ï¼Œç»™å‡ºäº†ä¸€ä¸ªå¾ˆå¥½çš„æ¯”ä¾‹å¯è§†åŒ–ã€‚

![](img/39bd7803926eb84734ddc8d3ab34ff75.png)

ã€https://arxiv.org/pdf/1905.11946.pdfã€‘æ¥æº:

***æ³¨:*** *EfficientNet æœ‰å¾ˆå¤šå˜ç§ã€‚æˆ‘ç”¨çš„æ˜¯ EfficientNet-B0ï¼Œå› ä¸ºå®ƒæ˜¯ä¸ªå°å‹å·ã€‚å¦‚æœä½ æ„¿æ„ï¼Œä½ å¯ä»¥è¯•è¯• EfficientNet çš„å…¶ä»–å˜ç§ã€‚*

æ‰€ä»¥ï¼Œè®©æˆ‘ä»¬ç”¨ EfficientNet-B0 å»ºç«‹ä¸€ä¸ªå›¾åƒè¯†åˆ«æ¨¡å‹ã€‚è¯·æ³¨æ„ï¼Œæˆ‘åªæ˜¯åœ¨åšæ–‡ä¸­è®­ç»ƒæ¨¡å‹ã€‚å¦‚æœä½ æƒ³äº†è§£é¢„å¤„ç†éƒ¨åˆ†ï¼Œè¯·å‚è€ƒ[è¿™ç¯‡åšæ–‡](/cifar-100-pre-processing-for-image-recognition-task-68015b43d658)ã€‚

***æ³¨:*** *æˆ‘ä¼šå°½é‡æŠŠå¤§éƒ¨åˆ†æ¦‚å¿µè¯´æ¸…æ¥šä½†è¿˜æ˜¯ï¼Œæœ¬æ–‡å‡è®¾å¯¹å·ç§¯ç¥ç»ç½‘ç»œ(CNN)æœ‰åŸºæœ¬çš„äº†è§£ã€‚*ğŸ“–

è¿™é¡¹ä»»åŠ¡çš„ä»£ç å¯ä»¥åœ¨æˆ‘çš„ [Github](https://github.com/chetnakhanna16/CIFAR100_ImageRecognition/blob/master/EffiicientNetB0_CIFAR100.ipynb) ä¸Šæ‰¾åˆ°ã€‚è¯·æ”¾å¿ƒä½¿ç”¨å®ƒæ¥æ„å»ºæ›´æ™ºèƒ½çš„å›¾åƒè¯†åˆ«ç³»ç»Ÿã€‚

# ä½¿ç”¨è¿ç§»å­¦ä¹ çš„æ¨¡å‹è®­ç»ƒ

ä¸ºäº†è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªè®­ç»ƒé›†ã€‚ä¸€ä¸ªå¥½çš„åšæ³•æ˜¯ä¿ç•™ä¸€ä¸ªéªŒè¯é›†æ¥é€‰æ‹©è¶…å‚æ•°ï¼Œå¹¶ä¿ç•™ä¸€ä¸ªæµ‹è¯•é›†æ¥æ ¹æ®çœ‹ä¸è§çš„æ•°æ®æµ‹è¯•æ¨¡å‹ã€‚

è®©æˆ‘ä»¬é¦–å…ˆå¯¼å…¥åº“ã€‚

```
**from** sklearn.model_selection **import** StratifiedShuffleSplit
**import** cv2
**import** albumentations **as** albu
**from** skimage.transform **import** resize
**import** numpy **as** np
**import** pandas **as** pd **import** matplotlib.pyplot **as** plt
%matplotlib inline
**from** pylab **import** rcParams
**from** sklearn.metrics **import** accuracy_score, confusion_matrix, classification_report
**from** keras.callbacks **import** Callback, EarlyStopping, ReduceLROnPlateau
**import** tensorflow **as** tf
**import** keras
**from** keras.models **import** Sequential, load_model
**from** keras.layers **import** Dropout, Dense, GlobalAveragePooling2D
**from** keras.optimizers **import** Adam
**import** efficientnet.keras **as** efn
```

æˆ‘ä½¿ç”¨åˆ†å±‚æ··æ´—åˆ†å‰²å°†æˆ‘çš„è®­ç»ƒé›†åˆ†å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œå› ä¸ºå®ƒå°†ä¿ç•™ 100 ä¸ªç±»ä¸­æ¯ä¸ªç±»çš„æ ·æœ¬ç™¾åˆ†æ¯”ã€‚ä¸‹é¢æ˜¯æ‰§è¡Œåˆ†å‰²çš„ä»£ç ã€‚

```
sss = StratifiedShuffleSplit(n_splits=2, test_size=0.2, random_state=123)

**for** train_index, val_index **in** sss.split(X_train, y_train):
    X_train_data, X_val_data = X_train[train_index], X_train[val_index]
    y_train_data, y_val_data = y_train[train_index], y_train[val_index]

**print**("Number of training samples: ", X_train_data.shape[0])
**print**("Number of validation samples: ", X_val_data.shape[0])
```

è¾“å‡ºç»™å‡ºäº†æ¯ç»„ä¸­çš„æ ·æœ¬æ•°ã€‚

```
Number of training samples:  40000 
Number of validation samples:  10000
```

æ ¹æ® EfficientNetï¼Œæˆ‘ä»¬ä¸ä»…éœ€è¦ç¼©æ”¾æ¨¡å‹çš„å®½åº¦å’Œæ·±åº¦(è¿™å°†ç”±é¢„è®­ç»ƒçš„æ¨¡å‹è´Ÿè´£)ï¼Œè¿˜éœ€è¦ç¼©æ”¾å›¾åƒçš„åˆ†è¾¨ç‡ã€‚EfficientNet-B0 æ¨¡å‹æ¶æ„è¦æ±‚æ˜ åƒçš„å¤§å°ä¸º(224ï¼Œ224)ã€‚å› æ­¤ï¼Œè®©æˆ‘ä»¬å°†å¤§å°ä¸º(32ï¼Œ32)çš„å›¾åƒè°ƒæ•´åˆ°æ–°çš„å¤§å°ã€‚

```
height = 224
width = 224
channels = 3input_shape = (height, width, channels)
```

ä¸‹é¢çš„å‡½æ•° **resize_img** å°†å›¾åƒå’Œå½¢çŠ¶ä½œä¸ºè¾“å…¥ï¼Œå¹¶è°ƒæ•´æ¯ä¸ªå›¾åƒçš„å¤§å°ã€‚æˆ‘ä½¿ç”¨äº†åŒä¸‰æ¬¡æ’å€¼æ³•æ¥æ”¾å¤§å›¾åƒã€‚å®ƒè€ƒè™‘æ€»å…± 16 ä¸ªåƒç´ çš„å·²çŸ¥åƒç´ çš„æœ€è¿‘çš„ 4x 4 é‚»åŸŸã€‚è¿™ç§æ–¹æ³•äº§ç”Ÿæ˜æ˜¾æ›´æ¸…æ™°çš„å›¾åƒï¼Œè¢«è®¤ä¸ºæ˜¯å¤„ç†æ—¶é—´å’Œè¾“å‡ºè´¨é‡çš„ç†æƒ³ç»„åˆã€‚

```
**def** resize_img(img, shape):
    **return** cv2.resize(img, (shape[1], shape[0]), interpolation=cv2.INTER_CUBIC)
```

æˆ‘ä»¬éƒ½çŸ¥é“ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½é€šå¸¸ä¼šéšç€æ›´å¤šæ•°æ®çš„æ·»åŠ è€Œæé«˜ï¼Œæ‰€ä»¥æˆ‘è®¡åˆ’è¿›è¡Œå›¾åƒå¢å¼ºï¼Œä½†å†…å­˜å§‹ç»ˆæ˜¯æ·±åº¦å­¦ä¹ æ¨¡å‹çš„ä¸€ä¸ªå¤§é™åˆ¶ï¼Œå› ä¸ºå®ƒä»¬æœ‰å¾ˆå¤šå¯è®­ç»ƒçš„å‚æ•°ã€‚æ‰€ä»¥ï¼Œæˆ‘é€‰æ‹©äº† python çš„ [**ç›¸å†Œ**](https://albumentations.ai/) åº“ï¼Œå®ƒæœ‰åŠ©äºå®æ—¶æ•°æ®æ‰©å……ã€‚(å¦‚æœä½ ä¸äº†è§£è¿™ä¸ªåº“ï¼Œæˆ‘å¼ºçƒˆæ¨èä½ å»çœ‹çœ‹å®ƒçš„ç½‘ç«™å’Œ [GitHub](https://github.com/albumentations-team/albumentations) é¡µé¢ã€‚)

æˆ‘ä½¿ç”¨ Keras æ•°æ®ç”Ÿæˆå™¨ç±»åˆ›å»ºäº†è‡ªå·±çš„è‡ªå®šä¹‰æ•°æ®ç”Ÿæˆå™¨ç±»ã€‚å‚æ•°â€œæ°´å¹³ç¿»è½¬â€ã€â€œå‚ç›´ç¿»è½¬â€ã€â€œç½‘æ ¼æ‰­æ›²â€å’Œâ€œå¼¹æ€§å˜æ¢â€è¢«è°ƒæ•´ä¸ºæ‰©å±•æ•°æ®é›†(æ‚¨ä¹Ÿå¯ä»¥å°è¯•å…¶ä»–å‚æ•°)ã€‚

ç”±äºå›¾åƒä¸­ç‰¹å¾å€¼çš„åˆ†å¸ƒå¯èƒ½å½¼æ­¤éå¸¸ä¸åŒï¼Œå› æ­¤é€šè¿‡å°†æ¯ä¸ªå›¾åƒé™¤ä»¥ 255 æ¥å½’ä¸€åŒ–å›¾åƒï¼Œå› ä¸ºæ¯ä¸ªå•ç‹¬é¢œè‰²çš„èŒƒå›´æ˜¯[0ï¼Œ255]ã€‚å› æ­¤ï¼Œé‡æ–°ç¼©æ”¾çš„å›¾åƒå…·æœ‰æ–°èŒƒå›´[0ï¼Œ1]ä¸­çš„æ‰€æœ‰ç‰¹å¾ã€‚

æˆ‘åˆ†æ‰¹å®Œæˆäº†æ‰€æœ‰è¿™äº›è½¬æ¢ã€‚æ­¤å¤–ï¼Œæˆ‘åªå¯¹è®­ç»ƒæ•°æ®é›†åº”ç”¨äº†å¢å¼ºï¼Œå¹¶ä¿ç•™äº†éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†ã€‚

åœ¨ç¼–å†™è‡ªå®šä¹‰æ•°æ®ç”Ÿæˆå™¨ç±»ä¹‹å‰ï¼Œè®©æˆ‘ä»¬é¦–å…ˆè®¾ç½®æˆ‘ä»¬çš„å¸¸æ•°ã€‚

```
n_classes = 100
epochs = 15
batch_size = 8
```

ä¸‹é¢æ˜¯è‡ªå®šä¹‰æ•°æ®ç”Ÿæˆå™¨ç±»çš„ä»£ç ã€‚

```
**class** DataGenerator(keras.utils.Sequence):
    **def** __init__(*self*, images, labels=**None**, mode='fit', batch_size=batch_size, dim=(height, width), channels=channels, n_classes=n_classes, shuffle=**True**, augment=**False**):

        *#initializing the configuration of the generator*
        *self*.images = images
        *self*.labels = labels
        *self*.mode = mode
        *self*.batch_size = batch_size
        *self*.dim = dim
        *self*.channels = channels
        *self*.n_classes = n_classes
        *self*.shuffle = shuffle
        *self*.augment = augment
        *self*.on_epoch_end()

    *#method to be called after every epoch*
    **def** on_epoch_end(*self*):
        self.indexes = np.arange(*self*.images.shape[0])
        **if** *self*.shuffle == **True**:
            np.random.shuffle(*self*.indexes)

    *#return numbers of steps in an epoch using samples & batch size*
    **def** __len__(*self*):
        **return** int(np.floor(**len**(*self*.images) / *self*.batch_size))

    *#this method is called with the batch number as an argument to #obtain a given batch of data*
    **def** __getitem__(*self*, index):
        *#generate one batch of data*
        *#generate indexes of batch*
        batch_indexes = *self*.indexes[index * *self*.batch_size:(index+1) * *self*.batch_size]

        *#generate mini-batch of X*
        X = np.empty((*self*.batch_size, **self*.dim, *self*.channels)) **for** i, ID **in** enumerate(batch_indexes):
            *#generate pre-processed image*
            img = *self*.images[ID]
            *#image rescaling*
            img = img.astype(np.float32)/255.
            *#resizing as per new dimensions*
            img = resize_img(img, *self*.dim)
            X[i] = img

        *#generate mini-batch of y*
        **if** *self*.mode == 'fit':
            y = *self*.labels[batch_indexes]

            *#augmentation on the training dataset*
            **if** *self*.augment == **True**:
                X = *self*.__augment_batch(X)
            **return** X, y

        **elif** *self*.mode == 'predict':
            **return** X

        **else**:
            **raise** **AttributeError**("The mode should be set to either 'fit' or 'predict'.")

    *#augmentation for one image*
    **def** __random_transform(*self*, img):
        composition = albu.Compose([albu.HorizontalFlip(p=0.5),
                                   albu.VerticalFlip(p=0.5),
                                   albu.GridDistortion(p=0.2),
                                   albu.ElasticTransform(p=0.2)])
        **return** composition(image=img)['image']

    *#augmentation for batch of images*
    **def** __augment_batch(*self*, img_batch):
        **for** i **in** range(img_batch.shape[0]):
            img_batch[i] = *self*.__random_transform(img_batch[i])
        **return** img_batch
```

è®©æˆ‘ä»¬å°†æ•°æ®ç”Ÿæˆå™¨ç±»åº”ç”¨äºæˆ‘ä»¬çš„è®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‚

```
train_data_generator = DataGenerator(X_train_data, y_train_data, augment=**True**) 
valid_data_generator = DataGenerator(X_val_data, y_val_data, augment=**False**)
```

Keras ä¸­æä¾›äº† EfficientNet ç±»æ¥å¸®åŠ©è½»æ¾è½¬ç§»å­¦ä¹ ã€‚æˆ‘ä½¿ç”¨äº†å¸¦æœ‰ ImageNet æƒé‡çš„ EfficientNet-B0 ç±»ã€‚å› ä¸ºæˆ‘ä½¿ç”¨è¿™ä¸ªæ¨¡å‹åªæ˜¯ä¸ºäº†æå–ç‰¹å¾ï¼Œæ‰€ä»¥æˆ‘æ²¡æœ‰åœ¨ç½‘ç»œçš„é¡¶éƒ¨åŒ…æ‹¬å®Œå…¨è¿æ¥çš„å±‚ï¼Œè€Œæ˜¯æŒ‡å®šäº†è¾“å…¥å½¢çŠ¶å’Œæ± ã€‚æˆ‘è¿˜æ·»åŠ äº†è‡ªå·±çš„æ± å’Œå¯†é›†å±‚ã€‚

ä¸‹é¢æ˜¯ä½¿ç”¨é¢„å…ˆè®­ç»ƒå¥½çš„ EfficientNet-B0 æ¨¡å‹çš„ä»£ç ã€‚

```
efnb0 = efn.EfficientNetB0(weights='imagenet', include_top=**False**, input_shape=input_shape, classes=n_classes)

model = Sequential()
model.add(efnb0)
model.add(GlobalAveragePooling2D())
model.add(Dropout(0.5))
model.add(Dense(n_classes, activation='softmax'))

model.summary()
```

è¿™æ˜¯è¾“å‡ºã€‚

![](img/7d50f76f2f5596e7de31ffa0c66a9fa0.png)

ä½œè€…å›¾ç‰‡

è¯¥æ¨¡å‹æœ‰ 4ï¼Œ135ï¼Œ648 ä¸ªå¯è®­ç»ƒå‚æ•°ã€‚ğŸ˜³

```
optimizer = Adam(lr=0.0001)

*#early stopping to monitor the validation loss and avoid overfitting*
early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=**True**)

*#reducing learning rate on plateau*
rlrop = ReduceLROnPlateau(monitor='val_loss', mode='min', patience= 5, factor= 0.5, min_lr= 1e-6, verbose=1)*#model compiling*
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
```

åœ¨ç¼–è¯‘æˆ‘ä»¬çš„æ¨¡å‹ä¹‹åï¼Œè®©æˆ‘ä»¬å°†å®ƒæ”¾åœ¨æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®é›†ä¸Šï¼Œå¹¶åœ¨éªŒè¯æ•°æ®é›†ä¸ŠéªŒè¯å®ƒã€‚

```
model_history = model.fit_generator(train_data_generator, validation_data = valid_data_generator, callbacks = [early_stop, rlrop],verbose = 1, epochs = epochs)

*#saving the trained model weights as data file in .h5 format*
model.save_weights("cifar_efficientnetb0_weights.h5")
```

ä»¥ä¸‹æ˜¯è®­ç»ƒçš„ç‰‡æ®µã€‚

![](img/7d62e1416ad5070255e7d7308ed193ee.png)![](img/814bd93c9cc8cf9f06916249cf500775.png)

ä½œè€…æä¾›çš„å›¾ç‰‡

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œè¯¥æ¨¡å‹åœ¨ç¬¬ 14 ä¸ªæ—¶æœŸè°ƒæ•´äº†å­¦ä¹ ç‡ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒé›†ä¸Šè·å¾—äº† 84.82%çš„æœ€ç»ˆå‡†ç¡®ç‡ï¼Œè¿™æ˜¯éå¸¸å¥½çš„ã€‚ä½†æ˜¯ç­‰ç­‰ï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦çœ‹çœ‹æµ‹è¯•çš„å‡†ç¡®æ€§ã€‚

è§†è§‰åŒ–æœ‰åŠ©äºæ›´å¥½åœ°çœ‹å¾…äº‹ç‰©ã€‚è®©æˆ‘ä»¬ç”»å‡ºç²¾åº¦å’ŒæŸè€—å›¾ã€‚

```
*#plot to visualize the loss and accuracy against number of epochs*
plt.figure(figsize=(18,8))

plt.suptitle('Loss and Accuracy Plots', fontsize=18)

plt.subplot(1,2,1)
plt.plot(model_history.history['loss'], label='Training Loss')
plt.plot(model_history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.xlabel('Number of epochs', fontsize=15)
plt.ylabel('Loss', fontsize=15)

plt.subplot(1,2,2)
plt.plot(model_history.history['accuracy'], label='Train Accuracy')
plt.plot(model_history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.xlabel('Number of epochs', fontsize=14)
plt.ylabel('Accuracy', fontsize=14)
plt.show()
```

![](img/b10c9b2d25e39f80f2b39076fe365f40.png)

ä½œè€…å›¾ç‰‡

ç°åœ¨è®©æˆ‘ä»¬è¯„ä¼°ä¸€ä¸‹æˆ‘ä»¬çš„æ¨¡å‹ã€‚

```
valid_loss, valid_accuracy = model.evaluate_generator(generator = valid_data_generator, verbose = 1)

**print**('Validation Accuracy: ', **round**((valid_accuracy * 100), 2), "%")
```

è¾“å‡º:

```
1250/1250 [==============================] - 85s 68ms/step Validation Accuracy:  82.3 %
```

ç°åœ¨ï¼Œæ˜¯æ—¶å€™çœ‹çœ‹æµ‹è¯•æ•°æ®é›†çš„å‡†ç¡®æ€§äº†ã€‚

```
y_pred = model.predict_generator(DataGenerator(X_test, mode='predict', augment=**False**, shuffle=**False**), verbose=1)
y_pred = np.argmax(y_pred, axis=1)
test_accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred)

**print**('Test Accuracy: ', **round**((test_accuracy * 100), 2), "%")
```

è¾“å‡º:

```
1250/1250 [==============================] - 78s 63ms/step
Test Accuracy:  81.79 %
```

åŸ¹è®­çš„ç»“æœç›¸å½“ä¸é”™ã€‚æˆ‘ä»¬åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šè·å¾—äº† 81.79%çš„å‡†ç¡®ç‡ã€‚ğŸ’ƒ

å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç ä¸ºæ¨¡å‹ç”Ÿæˆæ··æ·†çŸ©é˜µå’Œåˆ†ç±»æŠ¥å‘Šã€‚

```
cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred)
**print**(cm)target = ["Category **{}**".format(i) **for** i **in** range(n_classes)]
**print**(classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target))
```

ä¸‹é¢æ˜¯å‰ 11 ä¸ªç±»çš„ä»£ç ç‰‡æ®µã€‚

![](img/b9c4964e70937330ffb68902bff34a30.png)

ä»åˆ†ç±»æŠ¥å‘Šä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€äº›ç±»åˆ«è¢«å¾ˆå¥½åœ°é¢„æµ‹ï¼Œè€Œä¸€äº›è¢«é”™è¯¯åœ°é¢„æµ‹ã€‚

å¦‚æœæ‚¨æƒ³å¯è§†åŒ–é¢„æµ‹ï¼Œè¿™é‡Œæ˜¯ä»£ç ã€‚

```
prediction = pd.DataFrame(y_pred)rcParams['figure.figsize'] = 12,15

num_row = 4
num_col = 4

imageId = np.random.randint(0, len(X_test), num_row * num_col)

fig, axes = plt.subplots(num_row, num_col)

**for** i **in** range(0, num_row):
    **for** j **in** range(0, num_col):
        k = (i*num_col)+j
        axes[i,j].imshow(X_test[imageId[k]])
        axes[i,j].set_title("True: " + **str**(subCategory.iloc[testData['fine_labels'][imageId[k]]][0]).capitalize() + "**\n**Predicted: " + **str**(subCategory.iloc[prediction.iloc[imageId[k]]]).split()[2].capitalize(), fontsize=14)
        axes[i,j].axis('off')
        fig.suptitle("Images with True and Predicted Labels", fontsize=18) 

plt.show()
```

ä¸‹é¢æ˜¯è¾“å‡ºçš„ç‰‡æ®µã€‚

![](img/20c8157b4f0df50733561ccc76769979.png)

ä½œè€…å›¾ç‰‡

ä½ å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„æ¨¡å‹æ··æ·†äº†æ‘©æ‰˜è½¦å’Œè‡ªè¡Œè½¦ã€‚ğŸ™„ä½†æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¤§å¤šæ•°é¢„æµ‹æ˜¯æ­£ç¡®çš„ã€‚âœ…

æ·±åº¦å­¦ä¹ å°±æ˜¯å®éªŒã€‚ä½¿ç”¨ EfficientNet çš„å…¶ä»–æœ€æ–°ç‰ˆæœ¬ï¼Œå¾ˆæœ‰å¯èƒ½å¯ä»¥è¿›ä¸€æ­¥æé«˜è¯¥æ¨¡å‹çš„æ€§èƒ½ã€‚è¶…å‚æ•°è°ƒæ•´ä¹Ÿæ˜¯æ·±åº¦å­¦ä¹ çš„ä¸€ä¸ªé‡è¦æ–¹é¢ï¼Œå¯ä»¥å¸®åŠ©æé«˜å‡†ç¡®æ€§ã€‚

æˆ‘å¸Œæœ›è¿™ä¸ªåšå®¢èƒ½å¸®åŠ©ä½ ç†è§£å¦‚ä½•è¿›è¡Œè¿ç§»å­¦ä¹ ã€‚è¯·éšæ„å°è¯•æ›´å¤šä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚æŸ¥çœ‹æˆ‘çš„ [GitHub](https://github.com/chetnakhanna16/CIFAR100_ImageRecognition/blob/master/EffiicientNetB0_CIFAR100.ipynb) çš„å®Œæ•´ä»£ç å’Œæˆ‘çš„[ä»¥å‰çš„æ–‡ç« ](/cifar-100-pre-processing-for-image-recognition-task-68015b43d658)çš„åˆå§‹æ­¥éª¤ã€‚å¦å¤–ï¼Œæˆ‘å¼ºçƒˆæ¨èä½ é˜…è¯»[çš„åŸåˆ›è®ºæ–‡](https://arxiv.org/pdf/1905.11946.pdf)ã€‚è¿™æ˜¯ä¸€æœ¬æœ‰è¶£çš„è¯»ç‰©ï¼

**ç›¸å…³æ–‡ç« :**

[](/cifar-100-pre-processing-for-image-recognition-task-68015b43d658) [## CIFAR-100:å›¾åƒè¯†åˆ«ä»»åŠ¡é¢„å¤„ç†

### å¸¸ç”¨å›¾åƒæ•°æ®é›†(CIFAR-100)çš„é¢„å¤„ç†æˆ–æ•°æ®å‡†å¤‡

towardsdatascience.com](/cifar-100-pre-processing-for-image-recognition-task-68015b43d658) 

**å‚è€ƒ:**

1.  åŸæ–‡ï¼š<https://arxiv.org/pdf/1905.11946.pdf>
2.  è¿™ä¸ªç¬”è®°æœ¬ç»™äº†æˆ‘å¦‚ä½•è¿›è¡Œè¿ç§»å­¦ä¹ çš„æŒ‡å¯¼ã€‚

è°¢è°¢å¤§å®¶é˜…è¯»è¿™ç¯‡æ–‡ç« ã€‚è¯·åˆ†äº«æ‚¨å®è´µçš„åé¦ˆæˆ–å»ºè®®ã€‚å¿«ä¹é˜…è¯»ï¼ğŸ“—ğŸ–Œ:æˆ‘ä¹Ÿå¾ˆæƒ³çŸ¥é“ä½ ä½¿ç”¨è¿ç§»å­¦ä¹ åœ¨ CIFAR-100 ä¸Šæœ‰æ²¡æœ‰æ›´å¥½çš„è¡¨ç°ã€‚

[é¢†è‹±](https://www.linkedin.com/in/chetna-khanna/)