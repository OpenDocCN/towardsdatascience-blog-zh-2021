# Hadoop 基础入门指南

> 原文：<https://towardsdatascience.com/a-beginners-guide-to-hadoop-s-fundamentals-8e9b19744e30?source=collection_archive---------32----------------------->

## Hadoop 大数据分析平台及其主要模块的非技术性介绍

![](img/e83eee2b3a044f4d75cfa72395ac73f6.png)

图片由[曼纽尔·盖辛格](https://www.pexels.com/@artunchained)在[佩克斯](https://www.pexels.com/photo/interior-of-office-building-325229/)拍摄

从字面上看，Hadoop 是一只玩具大象的名字——确切地说，是 Doug Cutting(Hadoop 的联合创始人)的儿子的玩具大象。但是，您在这里不是为了了解 Hadoop 是如何或从哪里得名的！从广义上讲，Hadoop 是一个通用的、类似操作系统的并行计算平台。

我相信，在处理我们周围的所有大数据时，我不需要提到单个系统的严重局限性——这完全超出了单台机器的处理能力。Hadoop 提供了一个框架，通过并行处理来处理这些大数据，类似于超级计算机的用途。

但是，为什么我们不能利用超级计算机来并行处理大数据:

*   超级计算机没有标准化的操作系统(或类似操作系统的框架)——这使得中小型组织更难使用它们
*   初始购买和定期维护的成本都很高
*   硬件支持依赖于特定的供应商，也就是说，公司不能从不同的供应商那里采购各种单独的组件，然后将它们放在一起
*   在大多数情况下，需要开发定制软件来基于特定用例操作超级计算机
*   不容易横向扩展

Hadoop 解决了上述所有限制:它是一个开源(具有强大的社区支持和定期更新)、类似操作系统的并行处理平台，不依赖特定硬件供应商的持续硬件支持(与商用硬件配合使用)，也不需要任何专有软件。

自 2006 年以来，Hadoop 已经发布了三个稳定版本:Hadoop 1、Hadoop 2 和 Hadoop 3。

现在让我们更详细地看看 Hadoop 的架构，我将从 Hadoop 1 开始，这将使我们稍后更容易理解 Hadoop 2 的架构。我还将假设对以下术语有一些基本的熟悉:[商用硬件](https://www.techopedia.com/definition/29127/commodity-hardware)、[集群&集群节点](https://en.wikipedia.org/wiki/Computer_cluster)、[分布式系统](https://en.wikipedia.org/wiki/Distributed_computing)和[热备用](https://en.wikipedia.org/wiki/Hot_spare)。

# Hadoop 1 架构

以下是 Hadoop 1 体系结构的主要物理组件:

**主节点:**

*   名称节点:Hadoop 的集中式文件系统管理器，它跟踪数据文件被分成的块数、块大小以及哪些数据节点将保存和处理每个文件块，而不保存任何数据
*   辅助名称节点:名称节点的备份，但不处于热备用状态
*   作业跟踪器:Hadoop 的集中式作业调度器，负责调度数据节点上作业的执行

上述每个节点代表生产环境中的一台机器，以主模式工作，通常放置在生产设置的不同机架中(以避免一个机架故障导致多个主节点停机)。

**从节点:**

*   数据节点:存储和处理数据块形式的工作文件的独立机器/系统
*   任务跟踪器:一种软件服务，用于监控作业跟踪器的状态，跟踪数据节点正在执行的活动，并向作业跟踪器报告状态。每个数据节点一个任务跟踪器

从节点在没有主节点的情况下不能工作，并且完全依赖于它们在进行任何种类的处理活动之前从主节点接收的指令。为了确保连续的正常运行时间，从节点每三秒钟向名称节点发送一次心跳信号，以确认它们已经启动并处于活动状态。

所有上述主节点和从节点通过网络基础设施相互连接，形成一个集群。

就处理能力而言，Job Tracker 比 Name 和 Secondary Name 节点更强大，而且都不需要大量的存储容量。然而，数据节点是集群中最强大的机器，具有大量 RAM 和处理能力。

## 部署模式

以下是 Hadoop 支持的三种主要部署或配置模式:

1.  独立模式:所有 Hadoop 服务(即每个名称节点、辅助名称节点、作业跟踪器和数据节点)都在单个 Java 虚拟机(JVM)内的单个机器上本地运行。然而，现在很少使用独立模式
2.  伪分布式模式:所有 Hadoop 服务都在一台机器上本地运行，但是在不同的 JVM 中运行。伪分布式模式通常在开发和测试活动中使用，并且用于教育目的
3.  完全分布式模式:在生产设置中使用，其中所有 Hadoop 服务都在单独的专用机器/服务器上运行

## Hadoop 中的作业是什么？

Hadoop 生态系统中的作业类似于 Python 脚本/程序，用户可以执行该脚本/程序来执行特定的任务。就像 Python 脚本一样，Hadoop 的工作是一个程序(通常是一个 JAR 文件),它被提交到 Hadoop 集群，以便对驻留在数据节点上的输入(原始)数据进行处理和执行，处理后的输出保存在指定的位置。

## Hadoop 的软件组件

现在让我们从 Hadoop 的物理基础设施转移到它的软件组件。Hadoop 的核心软件组件包括:

1.  用于数据存储和检索的 Hadoop 分布式文件系统(HDFS)
2.  MapReduce 是一个基于 Java 的并行处理框架，是 Hadoop 的编程部门，用于处理 HDFS 提供的数据

MapReduce 还包括:

*   用户定义的映射阶段，执行输入数据的并行处理
*   用户定义的缩减阶段，汇总映射阶段的输出

需要明确的是，Hadoop 是一个并行处理**平台**，它提供硬件和软件工具来实现并行处理，然后提供 MapReduce **框架**(即一个可以根据用户需求定制的基本框架)来进行并行处理。但是 MapReduce 不是 Hadoop 支持的唯一框架——Spark 是另一个。

# Hadoop 分布式文件系统(HDFS)

HDFS 是 Hadoop 生态系统的文件管理组件，负责存储和跟踪跨各种数据节点的大型数据集(结构化和非结构化数据)。

为了理解 HDFS 的工作原理，让我们考虑一个大小为 200MB 的输入文件。如前所述，为了促进数据节点上的并行处理，这个单个文件将被分解成多个块并保存在数据节点上。

HDFS 的默认分割大小(这是一个全局设置，可以由 Hadoop 管理员配置)是 64MB。因此，我们的 200MB 样本输入文件将被分成 4 个块，其中 3 个块为 64MB，第 4 个块为 8MB。HDFS 负责将输入文件分割成单独的块，并保存在特定的数据节点上。

这里需要注意的一个关键方面是，HDFS 对输入文件的拆分发生在 Hadoop 集群之外的客户端机器上，名称节点根据特定算法决定每个数据块在特定数据节点中的放置。因此，一旦名称节点向客户机提供了数据块放置策略，客户机就直接将数据块写入数据节点。

名称节点充当一本书的目录，它记住各个名称节点中每个数据块的位置，以及其它信息，例如块大小、主机名等。，在一个称为文件系统映像(FS 映像)的文件表中。

## 数据节点的故障管理

那么，如果数据节点出现故障，会发生什么情况呢？甚至一个数据节点的故障都会导致整个输入文件被破坏——因为我们的拼图中有一块已经丢失了！在典型的生产设置中，我们通常处理数百 GB 的数据块，将原始数据文件推回 Hadoop 集群效率非常低，而且非常耗时。

为了避免任何潜在的数据丢失，每个数据节点上的数据块的备份副本被保存在相邻的数据节点上。每个数据块的备份副本数量由复制因子控制。默认情况下，复制系数设置为 3，即每个数据节点上的每个数据块都保存在 2 个额外的备份数据节点上，因此 Hadoop 集群将拥有每个数据块的 3 个副本。在将源数据文件推送到 HDFS 时，可以基于每个文件配置此复制因子。

一旦任何数据节点未能向名称节点发送心跳信号，备份数据节点就会开始工作。备份数据节点启动并运行后，名称节点将启动数据块的另一个备份，以便复制因子 3 在整个群集中保持不变。

## 次要名称节点

在 Hadoop 1.0 中，辅助名称节点充当名称节点的文件系统映像的备份。然而，这是 Hadoop 1.0 的主要限制之一，辅助名称节点不能在热备用模式下运行。因此，在名称节点出现故障的情况下，整个 Hadoop 集群将停止运行(数据将存在于数据节点中，但是，由于集群丢失了文件系统映像，数据将不可访问)，并且需要将辅助名称节点的内容手动复制到名称 Nome。

我们稍后将讨论这个问题，但是随着 Hadoop 2.0 的发布，这个问题得到了解决，在 Hadoop 2.0 中，辅助名称节点充当热备用。

# Hadoop 2.0

Hadoop 2.0 有时也被称为 MapReduce 2 (MR2)或另一种资源协商器(YARN)。

让我们试着理解 Hadoop 1.0 和 Hadoop 2.0 之间显著的架构差异。请记住，在 Hadoop 1.0 中，作业跟踪器充当集中式作业调度程序，它将特定作业拆分为多个作业，然后将它们传递给各个数据节点，其中数据节点上的各个任务由任务跟踪器监控，然后任务跟踪器将状态报告给作业跟踪器。除了其作业调度职责之外，作业跟踪器还以静态模式(即，系统资源不是动态的)将系统资源分配给每个数据节点。

Hadoop 2.0 用 YARN 替换了作业跟踪器，而底层文件系统仍然是 HDFS。除了 MapReduce，YARN 还支持其他并行处理框架，例如 Spark。YARN 还可以支持多达 10，000 个数据注释，而 Hadoop 1.0 的作业跟踪器仅支持 4，000 个数据节点。

YARN 有两个组件:调度程序和应用程序管理器。这两项任务都由 Hadoop 1.0 中的作业跟踪器单独管理。将这些不同的职责分离到 YARN 的各个组件中，可以更好地利用系统资源。

此外，在 Hadoop 2.0 中，每个数据节点上的任务跟踪器被单个节点管理器(以从属模式工作)所取代。节点管理器直接与 YARN 的应用程序管理器通信，进行资源管理。

正如前面提到的，除了一个辅助名称节点，Hadoop 2.0 还有一个热备用名称节点，在名称节点出现故障的情况下，它可以无缝地投入使用。在名称和热备用名称节点都出现故障的情况下，备用名称节点就派上了用场。

# 什么是 MapReduce？

顾名思义，MapReduce 由以下两个阶段组成，每个阶段又有 3 个子阶段:

## 地图阶段

映射阶段的所有 3 个子阶段都在驻留在各个数据节点中的每个数据块中执行或操作，这是 Hadoop 中并行化的切入点。

**记录阅读器**

记录阅读器被预编程为一次处理输入文件中的一行，并产生 2 个输出:

*   钥匙:一个数字
*   值:整行

**制图师**

Mapper 是可编程的，可以根据任何所需的逻辑或问题陈述，一次一个地处理记录读取器输出的每个键值对。它根据用户定义的功能输出额外的键值对。

**分拣机**

Mapper 的输出被输入到按字典顺序排序的排序器中(很明显！😊)映射器输出的关键字。如果关键字是数字，那么分类器将执行数字分类。分类器是预编程的，唯一可能的配置是对值进行分类。

## 减少阶段

在映射阶段的最后，我们将有多个映射器输出，每个数据节点一个。所有这些输出都将被传输到一个单独的数据节点，在那里将对它们执行 Reduce 操作。

归约操作的 3 个子阶段是:

**合并**

来自每个映射操作的中间输出被附加到另一个上，以产生单个合并文件。

**洗牌机**

Shuffler 是另一个预编程的内置模块，它将输入中出现的重复键聚集在一起，产生每个唯一键的值列表。

**减速器**

Shuffler 的输出被馈送到 Reducer，它是 Reduce 阶段的可编程模块，类似于 Mapper。Reducer 根据问题陈述中编程执行的内容，以键值对的形式产生输出。

## 实际例子

我将使用一个非常简单的非 ML 问题陈述来尝试和解释 MapReduce 的机制和工作流程。考虑一个只有如下两条语句的输入文件:

```
Processing big data through Hadoop is easy
Hadoop is not the only big data processing platform
```

我们的任务是找到输入文件中单词的频率，预期的输出是:

```
Processing    2
big           2
data          2
through       1
Hadoop        2
is            2
easy          1
not           1
the           1
only          1
platform      1
```

经历上面解释的 MapReduce 阶段:

*   Record Reader 读取第一行后的输出将是:
    Key: 0(文件/行偏移量—起始位置)
    Value:通过 Hadoop 处理大数据很容易
*   我们可以对映射器进行如下编程:
    步骤 1:忽略输入键
    步骤 2:从行中提取每个单词(标记化)
    步骤 3:以键-值对的形式生成输出，其中键是行中的每个单词，值是该单词在输入行中的频率
    相应地，在处理两行之后，映射器的输出将如下所示:

```
Processing     1
big            1
data           1
through        1
Hadoop         1
is             1
easy           1
Hadoop         1
is             1
not            1
the            1
only           1
big            1
data           1
processing     1
platform       1
```

*   排序器的输出将是这样的:

```
big            1
big            1
data           1
data           1
easy           1
Hadoop         1
Hadoop         1
is             1
is             1
not            1
only           1
platform       1
processing     1
Processing     1
the            1
through        1
```

*   Shuffler 的输出将是这样的:

```
big            1, 1
data           1, 1
easy           1
Hadoop         1, 1
is             1, 1
not            1
only           1
platform       1
processing     1, 1
the            1
through        1
```

*   Reducer 可以被编程来执行以下操作:
    步骤 1:从 Shuffler 的输出
    中获取键值对步骤 2:将每个键的列表值相加
    步骤 3:输出键值对，其中键保持不变，并且值是 Shuffler 的输出
    列表中的数字之和步骤 4:对从 Shuffler 接收的每个键值对重复上述步骤
    相应地，Reducer 的输出将是:

```
big            2
data           2
easy           1
Hadoop         2
is             2
not            1
only           1
platform       1
processing     2
the            1
through        1
```

## MapReduce 的使用案例

MapReduce 的某些行业用例包括:

*   在大数据集中搜索关键词
*   谷歌将其用于字数统计、广告词、页面排名、谷歌搜索的索引数据、谷歌新闻的文章聚类(最近谷歌已经从 MapReduce 上转移)
*   文本算法，如 grep、文本索引、倒排索引
*   数据挖掘技术
*   脸书将其用于数据挖掘、广告优化、垃圾邮件检测
*   金融服务提供商的分析
*   批量、非交互式分析

# 结论

是的，这是对 Hadoop 和 MapReduce 世界的一个非常高级的非技术性介绍。显然，还有几个其他的 Hadoop 组件我在这里没有涉及到，例如，Hive、Zookeeper、Pig、HBase、Spark 等等。

如果您想讨论上述内容，或者我以前的任何帖子中的内容，或者任何与数据分析、机器学习和金融风险相关的内容，请随时联系我。

下次见，摇滚起来！