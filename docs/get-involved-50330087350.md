# 介入

> 原文：<https://towardsdatascience.com/get-involved-50330087350?source=collection_archive---------33----------------------->

## 你能做些什么来帮助这个领域朝着正确的方向发展？

![](img/5095c7777af4c34f90edbca289eb6702.png)

[乔丹马德里](https://unsplash.com/@jordanmadrid?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍照

无论你是刚刚开始还是已经在建立你的职业生涯，你都可以帮助数据科学和机器学习以一种有益于人类和社区的方式发展。如果你有兴趣，**这里有一些想法可以指导你接下来的步骤。**

## **1。了解更多信息**

参与并帮助该领域朝着正确方向发展的一个关键因素是跟上数据科学和机器学习的最新发展。[我们创建了这个资源页面](/how-to-get-the-most-out-of-towards-data-science-3bf37f75a345)来支持您的学习之旅。

“做好事”是一个崇高的目标，但有时很难知道如何开始——例如，一些行动可能会带来我们最初没有意识到的负面影响。作为第一步，我们建议您进行一些初步研究，以了解您应该考虑的因素。比如，你可以读 [*做好事更好*](https://www.effectivealtruism.org/doing-good-better/) 一本介绍有效利他主义概念的书，或者[看这个短视频](https://www.ted.com/talks/will_macaskill_what_are_the_most_important_moral_problems_of_our_time)。

接下来，你可能希望具体放大随着机器学习和人工智能变得更加强大而出现的问题和潜在风险。这是一个复杂的话题，为了帮助您驾驭它[，我们基于 TDS 播客第二季](/build-your-own-modular-audio-course-on-ai-ethics-and-safety-5035a66eef55)创建了一个音频课程，在该课程中，我们重点关注数据科学和相邻领域中出现的问题。我们关于这些主题的[精选专栏](#3536)是另一个有用的资源，您可以按照自己的节奏浏览——它们涵盖了广泛的真实世界用例(和解决方案)。

除了 TDS，还有许多其他在线空间，在那里你可以找到关于类似主题的有见地的文章、播客和视频。我们最喜欢的包括[开放慈善项目](https://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence)、[未来生命研究所](https://futureoflife.org/background/benefits-risks-of-artificial-intelligence/)、[人类兼容人工智能中心](https://humancompatible.ai/)、关于新技术和新伦理的 TED [播放列表](https://www.ted.com/playlists/329/new_tech_new_morals)，以及[80000 小时](https://80000hours.org/podcast/episodes/paul-christiano-ai-alignment-solutions/)的对话。

## **2。讨论、贡献和联系**

阅读和教育自己是很好的开始，但是加入对话更好。你可以直接联系从事这些主题的人，并提供你的支持。Twitter 和 LinkedIn 是找到和你有共同兴趣的社区成员的好地方，TDS 也是其中之一。

浏览我们策划的关于这些主题的[专栏](#3536)，如果有任何文章或项目引起你的共鸣，在评论区联系作者是建立初步联系的好方法。许多作者也欢迎通过他们的 Twitter 和 LinkedIn 账户联系。

如果你有兴趣就这些话题发表自己的见解，你可以[向我们的团队](/questions-96667b06af5)提交一篇文章。如果我们选择出版它，我们将帮助突出它，以便它在 TDS 上更长时间可见，在我们的社交媒体帐户上推广它，并通过我们的新闻稿与读者分享它。

## **3。通过你的职业生涯提供帮助**

如果你正在寻找一个能产生直接积极影响的职业，我们鼓励你去看看 80000hours.org 大学。借用他们的话:

你的职业生涯中大约有 8 万个工作小时。这意味着你对职业的选择是你一生中做出的最大决定之一，所以弄清楚如何善用这段时间是非常值得的。

《80，000 小时》出版了一个[指南](https://80000hours.org/career-reviews/)来帮助你思考你可以做出积极贡献的方法。他们还列出了你可能会考虑处理的问题的[问题简介](https://80000hours.org/problem-profiles/)，任务驱动型角色的[工作板](https://80000hours.org/job-board/)，以及关于重要想法的有趣对话的[播客](https://80000hours.org/podcast/)。

## **4。志愿参与一些项目，这些项目的使命与你息息相关**

有许多有价值的项目和社区，你的贡献可以发挥很大的作用。志愿服务也是一种很好的方式来练习你的技能，并结识志同道合的人，他们热衷于利用技术和数据做好事。以下是一些需要考虑的链接:

*   [DataKind](https://www.datakind.org/) —一个将数据科学家与社会变革组织联系起来的计划，在这个计划中，他们的技能可以发挥作用。
*   [DrivenData](https://www.drivendata.org/) —提供持续的挑战，数据科学家竞相创建“对困难的预测问题有所影响的最佳统计模型”
*   [Solve for Good](https://www.solveforgood.org) —一个平台，让致力于社会问题的组织请求志愿者帮助完成数据密集型任务。
*   [在线志愿者](https://www.onlinevolunteering.org/en)——一项由联合国支持的倡议，允许具有研究、技术和其他背景的专家支持解决新冠肺炎相关问题的组织。
*   [Catchafire](https://www.catchafire.org/) —专业人士寻找机会为激励他们的事业贡献时间和技能的社区。

你也可以创建自己的项目:从新冠肺炎和 T21 的污染到当地社区的帮助，有很多方法可以利用你的知识和数据专长做好事。如果你需要一些现实世界的灵感，请查看我们在[改变数据](https://towardsdatascience.com/tagged/data-for-change)专栏中的工作。

## **5。向推动该领域向正确方向发展的非营利组织捐款**

如果你想支持那些致力于让人工智能更安全、更有益于所有人的组织，我们建议去看看[开放慈善项目](https://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence)、[应该](https://ought.org/mission)、 [MIRI](https://intelligence.org/) 、 [GovAI](https://www.fhi.ox.ac.uk/govai/) 、[未来生命研究所](https://futureoflife.org/team/)和[人类兼容人工智能中心](https://humancompatible.ai/)。

如果你不确定该选哪一个，你可以向一个基金捐款，该基金支持围绕类似使命的多个组织。例如，[长期未来基金](https://funds.effectivealtruism.org/funds/far-future)支持众多项目和研究计划；你也可以[阅读这篇评论](https://forum.effectivealtruism.org/posts/K7Z87me338BQT3Mcv/2020-ai-alignment-literature-review-and-charity-comparison)来更详细地探索以人工智能为重点的非营利领域。

# 我们的专栏

## [变更数据](https://towardsdatascience.com/tagged/data-for-change)

人工智能和算法偏见的风险是众所周知的，但数据科学也可以——而且经常是——成为一股好的力量。从环境研究和警察改革到公共卫生举措，数据为人们提供了信息并增强了他们的权能，使他们能够要求更好的政策并努力为边缘化社区实现更大的公平。请访问我们的数据促进变革专栏，了解讨论数据改善人们生活的潜力的各种文章。

## [模型可解释性](https://towardsdatascience.com/tagged/model-interpretability)

机器学习算法每天都在影响着我们。我们用这些算法来做决策，解决问题，让我们的生活更轻松。但是驱动应用程序的算法没有固定的规则和规定。依赖这些算法的企业、政府机构和学校不一定了解模型如何工作的细节或结果的真正含义。我们有权理解一个模型是如何做出决定的，以及为什么人们应该(或不应该)信任它。如果我们要使用这些算法来为我们做出法律、医疗和金融决策，我们需要确保我们理解一个模型是如何创建的，以及它为什么会得到它的结果。

## [公平和偏见](https://towardsdatascience.com/tagged/fairness-and-bias)

人工智能和机器学习模型只与它们接受训练的数据一样公平。算法不会自己思考，它们做出的预测是基于它们的创造者做出的选择。如果没有意识到这些问题，偏见通常会在每个层次的模型中形成。我们需要学习如何避免偏见，并在每一步都将公平融入我们的模型。

## [数据隐私](https://towardsdatascience.com/tagged/data-privacy)

几乎每时每刻都在收集我们所有人的数据。保持任何表面上的隐私越来越难了。我们不断向公司提供信息，帮助他们改善业务运营。无论我们是为了更好的推荐而提供音乐品味，还是为了路线建议而提供我们的位置，或者关于我们健康和身份的信息，我们都需要意识到我们正在做出的选择和我们的数据将去往何处。我们需要问如何保护我们的数据，以及如何在各个层面维护我们的隐私。

## [人工智能校准和安全](https://towardsdatascience.com/tagged/ai-alignment-and-safety)

随着我们提高人工智能的能力，我们如何对人类决策的微妙和复杂之处进行编程？AI 的目标会和我们自己的一样吗？人工智能不太可能默认与人类价值观保持一致。尽管制定一套不伤害人类的法律很好，但有令人信服的理由相信这是不可能的，而且对齐问题实际上很难解决。人工智能正在迅速进步:时间正在流逝，我们应该引导人工智能在每种情况下做出正确的选择，并随着它变得更加聪明而继续这样做。现在讨论这些问题对人工智能的未来至关重要。

我们创建了这份媒体出版物，因为我们相信数据相关知识对于让世界变得更美好至关重要。它不仅能让我们了解自己和周围的世界，还能帮助我们做出更好的决定。几乎在每个领域，数据科学都可以帮助我们更准确地理解手头的事情，从而更好地告知决策者他们的行动的潜在后果。

随着时间的推移，我们认识到，随着我们领域的进展，一些重要的问题正在出现。例如，与隐私、可解释性和一致性相关的问题。这就是为什么我们决定接触我们的社区，研究我们的领域面临的潜在问题以及我们如何帮助解决这些问题。

通过继续这项工作，我们希望更接近这些关键问题和挑战。这有助于我们确保我们的社区走上让世界变得更美好的道路。