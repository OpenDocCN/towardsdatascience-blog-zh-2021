# 为了实现负责任的人工智能，消除“可信度差距”

> 原文：<https://towardsdatascience.com/to-achieve-responsible-ai-close-the-believability-gap-cf809dc81c1e?source=collection_archive---------26----------------------->

在 2019 年和 2020 年，我们对人工智能伦理领域的兴趣不断涌现，这导致许多人分享了见解、最佳实践、技巧和诀窍等。可以帮助我们实现负责任的人工智能。

但是，当我们走向 2021 年时，似乎在人工智能伦理如何操作化方面仍然存在巨大差距。其中一部分源于我所说的可信度差距，在我们实现广泛采用这些实践的目标之前，需要弥合这一差距，从而真正创造积极的变化。

该领域的碎片化以及人工智能的广泛影响意味着我们经常在我们对其来龙去脉知之甚少的领域和领域中挣扎。

通常由于业务和其他考虑因素，时间限制迫使我们使用有时有缺陷的试探法(如快速浏览证书)来寻找专业知识，以选择谁加入对话来弥合我们的知识差距，这进一步加剧了这种情况。

但是，这带来了几个问题，特别是当我们没有考虑到人的可信度，因此遇到了导致负责任的人工智能领域发生表面变化的问题，或者更糟糕的是，由于不明智的想法而造成的伤害。

> 可信度的概念对于在 2021 年成功实现负责任的人工智能系统至关重要。

让我们深入了解这些想法的细节吧！

# 你说可信是什么意思？

雷伊·达里奥在他的书 [*原则*](https://g.co/kgs/qGDshW) 中阐述了对于一个人来说，可信意味着什么的关键概念。这是对可信度这一基本概念的一种强化。它基本上要求我们也考虑来自个人经历的经验证据，这样我们就可以对来自某个特定领域的人的想法和建议赋予正确的权重。

这并不是对一个人的能力进行全面的评价:我们只是通过查看他们在某个领域的记录来考虑他们在该领域的想法，这样我们就可以更好地了解我们应该如何评估他们的想法并将其纳入我们的决策中。

这让人想起内特·西尔弗在他的书《信号与噪音》<https://g.co/kgs/EZddZF>**中提出的一些观点，他在书中指出，我们并没有真正关注那些做出预测的人的记录；我们依赖他们的凭证，相信他们的话，但从不回头检查他们所说的事情是否真的实现了(当然，除非他们在某些事情上是对的，但大多忽略了他们不正确的地方)。这导致了一个生态系统，在这个系统中，我们继续高度重视人们的评论，而忽略了那些对自己的工作不太大声和公开，但却非常正确的人。**

**因此，当谈到人工智能伦理时，我认为在评估可信度时考虑以下因素是非常重要的，作为一种“验证”人们的跟踪记录的方式，以给他们的想法和见解分配适当的权重:**

1.  **活生生的经历，**
2.  **多学科背景，以及**
3.  **关注工作的主体，而不仅仅是证书**

**在深入研究每一点之前，这个达到可信度的“验证过程”必须通过承认和认识自己的偏见来完成，并且对你正在评估的所有信息保持批判性的关注，这样你才能获得良好的可信度分数。**

# **1.亲身经历**

**我们感同身受和想象他人经历的能力是一种强大的能力。然而，它有其局限性。当谈到解决人工智能中一些伦理挑战的分娩解决方案时，依靠有生活经验的人的洞察力将是必不可少的。**

**![](img/27f9dafb630921f62aada91c554a0b0a.png)**

***照片由* [*马克西姆涅利*](https://unsplash.com/@maxa?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) *上* [*下*](https://unsplash.com/s/photos/working?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)**

**即使我们有良好的意图，并正在开发社会技术解决方案来应对挑战，但如果没有来自生活经验的正确的文化和背景洞察力，我们可能会产生弊大于利的风险。**

**我们经常在那些渴望帮助“解决”人工智能伦理领域问题的人们身上看到这种情况。不适当考虑问题的根源及其根深蒂固的社会技术背景是有风险的。社区如何受到影响以及他们可能拥有的见解也应纳入解决方案框架流程。**

# **2.多学科背景**

**是的，这有时会很难，但优先考虑有机会在多个领域工作的人会给你更好的见解，因为(希望)那个人有能力将不同领域的方法和工作方式结合在一起。最好是那些跨越人文科学和技术科学背景的人会给你一个足够好的组合，让你对他们的想法给予足够的重视。**

> **根据我的经验，如果我们足够努力地寻找，我们一定会找到有这种经历的人——令人担忧的是，在实际着手进入世界并寻找这些人的艰难任务时存在惯性。**

**有许多由组织维护的列表和目录有助于暴露这些个人，但它们往往很快就会过时，并且还会加剧问题，有时会在这些列表如何编制方面具有排他性。批判性地思考和审视谁是列表编辑的幕后推手，也能帮助你做出更明智的决定，帮助你实现目标。**

**![](img/6d7489c6f33b7789f74db84b6d405316.png)**

***照片由* [*乔恩·弗洛布兰特*](https://unsplash.com/@jonflobrant?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) *上* [*Unsplash*](https://unsplash.com/s/photos/balance?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)**

**这很重要的原因之一是，我们今天在人工智能伦理领域面临的一些挑战与其他领域类似，学者、活动家和从业者已经建立了一个解决这些挑战的工作机构。如果我们对这些土地不熟悉的话，很难找到这些地方，有人给我们带路是非常有用的。**

# **3.关注工作的主体，而不仅仅是证书**

**当谈到人工智能伦理时，我所进行的一些最有见地的对话来自于社区中其他人不会“判断”他们有“正确”或“值得”的资格。(即使写下这句话，我也觉得很糟糕，但不幸的是，在某些时候，我们可能会遇到这种情绪。)**

> **目前在这一领域过分强调拥有能够参与讨论和分享见解的傲慢的资格，这损害了整体讨论。**

**事实上，[蒙特利尔人工智能伦理研究所](https://montrealethics.ai/)的起源来自类似的认识:我们发现有很多人没有一个聚集的地方，他们可以以尊重和欢迎他们的专业知识和经验的方式谈论这些话题。**

**许多有价值的见解将来自“意想不到”的地方，我的经验法则是浏览这个人所做的工作，而不是太关注他们的证书来评估我可以分配给他们的可信度。**

**我确实遇到过这样的情况，那些拥有傲慢证书的人似乎无法兑现他们的证书所承诺的东西，而其他没有这些证书的人则让我走上了一条从研究和实践角度都产生了有趣发展的道路。**

# **让我们帮助生态系统变得更加可信！**

**希望其中的一些观点能引起你的共鸣，你会明白我为什么强调这种可信度的想法以及与之相关的元素:**

1.  **活生生的经历，**
2.  **多学科背景，以及**
3.  **关注工作的主体，而不仅仅是证书。**

**可信度是一个持续的过程，我们必须不断更新我们的信念，这样我们才能在充分知情的情况下做出决策。**

> **我们的目标不仅是倾听有好想法的人的意见，而且要让他们有能力进入权力和决策的位置，这样这些想法才能公之于众。**

**在[蒙特娄人工智能伦理研究所](https://montrealethics.ai/)，通过我们的[公共咨询研讨会](https://montrealethics.ai/meetup)和[学习社区](https://montrealethics.ai/learning-community)，我们正在帮助迈出第一步，将有伟大想法的人聚集在一起，并提供一个平台，通过这个平台，我们可以在人工智能的伦理、安全和包容性发展的技术和政策措施决策中强调他们的声音。**

**我希望你们能和我一起进一步讨论这些想法，并与在这一领域为带来积极变化而不懈努力的其他人分享这一信息。**

> ****你可以在这里了解更多我的作品:**[**https://ATG-abhishek . github . io**](https://atg-abhishek.github.io/)**