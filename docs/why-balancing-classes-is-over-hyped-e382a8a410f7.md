# 为什么平衡班级被过度炒作

> 原文：<https://towardsdatascience.com/why-balancing-classes-is-over-hyped-e382a8a410f7?source=collection_archive---------13----------------------->

## [*小窍门*](https://towardsdatascience.com/tagged/tips-and-tricks)

## 不需要平衡数据集的三个原因

![](img/c132f353ba4b9b84f5b1a57e9c4e120f.png)

图片由 Loic Leray 在 Unsplash 上拍摄

我上个月上班时掉进了兔子洞。我试图建立一个模型来预测一个罕见的结果，但我的回忆和精度分数仍然很低。鉴于这两个阶层的高度不相称性，我认为这应该归咎于阶层失衡。

平衡类通常被框定为“修复”预测模型的一种方式，在某些方面的确如此。这项技术之所以流行是有原因的——它可以用于提高全局准确性、提供描述性摘要、应用某些统计数据、防止模型惩罚少数样本等。然而，我意识到很容易陷入平衡类的习惯行为中，而没有考虑到这会带来的新问题。在这里，我将回顾你可能*而不是*想要重新平衡的三个原因:

1.  偏差引入
2.  训练数据需要反映真实世界
3.  少数阶级的数量可能已经足够了

首先，让我们快速回顾一下什么是阶级失衡。

## **什么是不平衡班？**

不平衡的阶层，简单来说就是两个人口比例不对等。各行各业都有例子；例如，在医疗保健行业，良性肿瘤(多数类别)的数量远远超过癌性肿瘤(少数类别)，或者在金融行业，正常交易的数量(多数类别)相对于欺诈交易(少数类别)而言相当高。这些比例可从 4:1 到 100:1 不等，极端的不平衡可高达 1000:1 到 10000:1 [1]，有时甚至更高。

一般来说，少数民族阶层有一些邪恶或不受欢迎的东西，这有利于我们提前预测。在我的领域，医院向保险公司索赔的相对较小比例(5-15%)被拒绝。理想情况下，我们可以提前预测这些情况，为已经在微薄利润中生存的医院节省数百万美元的收入损失。

但让我们回顾一下重新平衡班级的一些潜在陷阱，并讨论一些更好地预测少数民族结果的替代方法。

## 原因 1:偏差引入

重新平衡数据集可能会引入偏差。当您重新取样时，除了人为地增加或减少数据点的数量之外，您什么也不做。如果您选择对多数类进行欠采样，如果关键的观察值被移除，则可能会引入偏差。新样本也可能无法准确反映您的真实测试数据。相反，对少数类进行过采样可能会无意中扩大隐藏的数据异常并造成过拟合。SMOTE 是另一种可以改善决策边界的重采样技术[2]，但是如果新数据包含与少数类中的标记样本相似的属性，则预测性增强是次要的[3]。SMOTE 在高维数据集中也会受到影响，因为它没有考虑所有相邻的类，并且会导致重要的类区别重叠。

那么，我们为什么如此热衷于重新平衡数据集呢？事实上，这种动力是为了纠正另一个与估计全球精确度有关的问题。以上面我们被拒绝的索赔为例；基本模型可以达到惊人的 95%的准确性，因为多数类代表了整个数据集中的确切比例。简而言之，仅仅是每次预测多数类“非否认”，你就会有平均 95%的准确率。通过重新平衡，准确度分数变得更加真实。

然而，我们陷入了各种各样可以重新平衡的方法中，我们留下了一些更重要的考虑:我们有足够的代表性数据吗？我们的变量真的具有预测性和重要性吗？我们是否为自己的预测设定了合适的阈值？实际上，阈值的设置对于预测任务非常重要，您可以通过精确度和召回率来优化它们。天气预报是一个很好的例子，说明了为什么阈值比二元分类精度更好。例如，天气预报员从不报告“会下雨”或“不会下雨”。它们提供了阈值，比如“有 52%的可能性会下雨”，这为我们提供了更好的洞察力和自主权，让我们在生活中的其他相关因素下做出决定，例如，如果阳光明媚，我整天拿着夹克会有多烦恼？如果我真的讨厌整天带着一件夹克到处跑，而下雨的可能性只有 52%，我会掷骰子，不穿夹克就出门。然而，在我们的医疗保健示例中，这些阈值可能是生死攸关的，而不仅仅是不便之处。

大多数预测模型将自动阈值设置为 50%，尽管选择一个更上下文相关的阈值是重要的，也是可以做到的[4]。尽管如此，如果你过于关注类的再平衡而不是优化这些类型的权衡，你可能会掉进兔子洞试图“解决”错误的问题。

重新平衡阶级在统计学上也有一些历史根源，旧习难改。许多实验设计假设数据平衡，如多因素方差分析[5]。在这种情况下，平衡设计提高了统计功效，降低了同方差[6]。在计算机出现之前，用非常不平衡的数据来估计模型对于人工处理来说尤其具有挑战性。今天，计算机的进步已经使这些问题变得过时了。高级预测模型可以在高维度和稀疏矩阵中进行优化，而且它们肯定可以解决阶级不平衡问题。

## 原因 2:训练数据需要反映真实世界

不重新平衡数据集的另一个原因是，模型应该在数据集上训练，数据集的分布将反映它们最终应用的未来真实世界的测试案例。如果确定重新平衡是绝对必要的，那么在进行任何重新平衡实践之前，应该拆分训练集和测试集。

在 Harrell 的一篇论文中，根据平衡数据训练的分类器需要根据适当的测试数据重新训练，因为预测和模式可能会发生巨大变化[7]。例如，假设您有两个不平衡的类别:100 万名非癌症患者和 1000 名癌症患者。如果您通过对多数类进行 90%的下采样来训练平衡类的模型，您将训练 1/10 流行率的分类器，而不是自然发生的 1/1000 流行率。正如 Provost 指出的，分类器的假设是它“将对来自与训练数据相同分布的数据进行操作”[4]。对平衡数据的训练可能无法推广到自然不平衡的真实世界数据。

已经设计了几种方法来提高不平衡数据集上的算法性能。我们可以简单地在应用重采样技术之前将类分成测试和训练集*。这防止了在两个集合中出现相似数据的可能性，这种可能性会导致过度拟合和较差的泛化能力。一种更强化的提升方法涉及通过在总数据集的不同样本上使用两个学习者(L1、L2)和一个最终学习者来检测它们之间的差异(L3) [8]，使训练模型适应测试分布。其他常见的方法包括分配与训练数据中的类频率成反比的类权重，这也防止了过拟合[9]。基于核的学习方法也被用来改善 SVM 模型中的决策界限[10]。但是，这些解决方案解决了阶级不平衡，就好像它们是一个非常严重的问题，当更紧迫的问题存在时——你的少数阶级代表吗？少数人有噪音吗？你的课程真的重叠了吗？你的特征变量真的重要吗？你所在的多数班和少数班有太多的“脱节”吗？[11–17].*

因此，成本敏感学习的应用不是平衡班级，而是在直接应用于生活中自然发生的不平衡班级时显示出一些有希望的结果[12，18-19]。特别是，对于大型数据集，对自然、不平衡分布的成本敏感学习比过采样或欠采样不平衡类产生更好的结果。作者认为，大量的训练数据允许模型更准确地估计类成员概率[20]。其他实证研究表明，在不平衡分布中，成本学习优于抽样方法[20–22]。

## 原因 3:少数民族阶级的数量可能已经足够了

如果你的少数类包含足够的相关性和强大的依赖关系来通知你的分类器[23]，那么再平衡可能也是不必要的。这最终优先于少数阶级和多数阶级之间可能存在的极端不平衡的比例。在几项带有不平衡数据集的研究中，少数民族的概念被准确地学习，很少受到不平衡的干扰[24–26]。

这么想吧。包含 101 个样本(100 个多数案例和 1 个少数案例)的不平衡数据集将构成一个糟糕的预测模型。但是如果你有 1000 万个多数案件和 10 万个少数案件呢？同样程度的阶级不平衡。但是在第二个例子中，少数类可能足够大以建立质量预测模型。

如果两个类别都来自具有非常明确定义(即不同)的特征变量的非重叠分布，则尤其如此[1]。在我自己预测医疗保健中被拒绝的索赔的工作中，不平衡的类别不是预测不佳的罪魁祸首；我的初始特征对我的结果变量来说只是无信息的(否认与不否认)。如果您也遇到高维度和稀疏的特征空间，这些问题优先于类不平衡问题。

另一方面，如果少数类中的样本数量太少，分类器无法充分学习，那么你真的有一个不完整训练数据的问题，而不是不平衡数据集的问题。当然，你可以称之为阶级失衡，但这实际上只是权力的问题。如果这种情况发生，我真的想知道少数民族阶层是随机缺失还是不成比例的缺失？只要您可以访问更多的数据，前者是可以的，后者可能会出现采样偏差。

少数样本量低，而不是类别不平衡，可能是预测模型的一个特殊障碍。随机森林分类器(RFC)尤其“数据饥渴”，需要大量数据才能得出有意义的结果。例如，[范·德·普洛格和他的同事](https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-14-137#citeas)证明了为了让 RFC 像处理训练数据一样处理新数据，总体样本量应该是候选特征数量的 200 倍[27]。因此，具有足够样本的少数类可用于分类模型。什么叫“够了”？没有真正的硬性规定。不断优化精度和召回率，同时确保您的数据不会过度拟合或出现泄漏。

## 结论

如果你的不平衡类是可分的，有很好的少数类代表性，并对你的结果变量有独特而强大的影响，那么尽管不平衡，数据对构建可靠的预测模型应该不会造成什么问题。诸如精度和召回率之类的条件概率应该在类的自然分布范围内进行评估和优化。

虽然阶级失衡引起了很多关注，但更重要的问题是:

*   您是否优化了正确的分类指标，如精度和召回率，而不是准确性？
*   你的小众阶层代表吗？有足够多的少数民族案例吗？
*   你的少数群体中存在噪音吗？
*   您的模型是否尊重并很好地应用了现实场景中出现的类的自然分布？
*   你的课程有重叠的地方吗？到什么程度？
*   你的特征变量真的重要吗？

乐意在 [LinkedIn](https://www.linkedin.com/in/gabe-verzino-71401137/) 上与任何人联系！如果你对数据科学和医疗保健的交叉领域感兴趣，或者你有有趣的挑战要分享，请留下评论或 DM。

查看我的一些其他文章:

[**预测患者住院时间**](/machine-learning-an-initial-approach-to-predict-patient-length-of-stay-350e358ea8cb)

[**特征工程 CPT 代码**](https://medium.com/mlearning-ai/working-with-cpt-codes-5a2b04a4d183)

[**设计一个基本神经网络的 7 个步骤**](/7-steps-to-design-a-basic-neural-network-part-1-of-2-ff0d391bf32b)

## 引文

[1]巴托什·科劳兹克。"从不平衡数据中学习:公开挑战和未来方向."智力进展(2016 年)5:221–232

[2] Marco Altini，“处理不平衡数据:欠采样、过采样和适当的交叉验证。”博客。2015 年 8 月。[https://www . marcoaltini . com/blog/处理不平衡数据-欠采样-过采样-适当交叉验证](https://www.marcoaltini.com/blog/dealing-with-imbalanced-data-undersampling-oversampling-and-proper-cross-validation)

[3]杨延平，马广智。"基于集成的主动学习解决类不平衡问题."生物医学科学与工程杂志，第 3 卷第 10 期，2010 年 10 月。

[4]教务长，F.."不平衡数据集的机器学习 101 . "(2000).

[5] R.H. Riffenburgh，第 13 章——多因素 ANOVA 和 ANCOVA，编辑:R.H. Riffenburgh,《医学统计学》(第三版),学术出版社，2012 年，第 275-297 页

[6]斯蒂芬妮·格伦。来自 StatisticsHowTo.com<https://www.statisticshowto.com/>**的“平衡与不平衡的设计:定义，例子”:对我们其余人的基本统计！[https://www . statistics show to . com/balanced-and-unbalanced-designs/](https://www.statisticshowto.com/balanced-and-unbalanced-designs/)**

**[7]弗兰克·哈勒尔，“分类与预测。”博客，2020 年 9 月。[https://www.fharrell.com/post/classification/](https://www.fharrell.com/post/classification/)**

**[8] Robert E. Schapire 在“ ***弱可学习性的强度****”*机器学习，5(2):197–227，1990 年发表。[http://rob.schapire.net/papers/strengthofweak.pdf](http://rob.schapire.net/papers/strengthofweak.pdf)**

**[9] Joshi，m .，Kumar，v .和 Agarwal，R. (2001)评估用于分类稀有类的增强算法:比较和改进。第一届 IEEE 数据挖掘国际会议论文集。华盛顿 DC: IEEE 计算机学会，257–264。**

**[10] Akbani，r .，Kwek，s .和 Japkowicz，N. (2004)将支持向量机应用于不平衡数据集。第 15 届欧洲机器学习会议记录，意大利比萨，39-50。**

**[11]何海波，爱德华多·加西亚，“从不平衡数据中学习”，《IEEE 知识与数据工程汇刊》，第 21 卷。，№9，2009 年 9 月。**

**[12] G.M. Weiss，“稀有矿产:统一框架”，ACM SIGKDD 勘探通讯，第 6 卷，第 1 期，第 7-19 页，2004 年。**

**[13] N. Japkowicz 和 S. Stephen，“阶层失衡问题:系统研究”，《智能数据分析》，第 6 卷，第 5 期，第 429- 449 页，2002 年。**

**[14] T. Jo 和 N. Japkowicz，“等级不平衡与小间断”，ACM SIGKDD 探索通讯，第 6 卷，第 1 期，第 40-49 页，2004 年。**

**[15] N. Japkowicz，“阶级失衡:我们关注的问题是否正确？”继续。国际会议。机器学习，从不平衡数据集中的车间学习 II，2003。**

**[16] R.C .普拉蒂、G.E.A.P.A .巴蒂斯塔和 M.C .莫纳德，“阶级不平衡与阶级重叠:对学习系统行为的分析”，Proc .墨西哥国际会议。人工智能，第 312–321 页，2004 年。**

**[17] S.J. Raudys 和 A.K. Jain，“统计模式识别中的小样本效应:对从业者的建议”，IEEE Trans .模式分析和机器智能，第 13 卷，第 3 期，第 252-264 页，1991 年 3 月。**

**[18] N.V. Chawla、N. Japkowicz 和 A. Kolcz，“社论:关于从不平衡数据集学习的特刊”，ACM SIGKDD 探索通讯，第 6 卷，第 1 期，第 1-6 页，2004 年**

**[19] M.A. Maloof，“学习何时数据集不平衡，何时成本不相等和未知”，Proc .国际会议。机器学习，从不平衡数据集中的车间学习 II，2003。**

**[20] K. McCarthy，B. Zabar，和 G.M. Weiss，“在对稀有类进行分类时，对成本敏感的学习胜过抽样吗？”继续。基于效用的数据挖掘，第 69–77 页，2005。**

**[21]刘晓燕，周志宏，“用处理类不平衡问题的方法训练代价敏感神经网络”，IEEE Trans .知识与数据工程。，第 18 卷，第 1 期，第 63-77 页，2006 年 1 月。**

**[22]刘小燕、周志宏，“班级失衡对成本敏感学习的影响:一项实证研究”，中国教育出版社，2002 年。国际会议。数据挖掘，第 970–974 页，2006 年。**

**[23] Stephen Senn，“临床试验中随机化的七个误区。”医学统计，2012 年 12 月。**

**[24] G.E.A.P.A. Batista、R.C .普拉蒂和 M.C. Monard，“平衡机器学习训练数据的几种方法的行为研究”，ACM SIGKDD 探索通讯，第 6 卷，第 1 期，第 20-29 页，2004 年。**

**[25] N. Japkowicz 和 S. Stephen，“阶层失衡问题:系统研究”，《智能数据分析》，第 6 卷，第 5 期，第 429- 449 页，2002 年。**

**[26] G.M. Weiss 和 F. Provost，“当训练数据很昂贵时的学习:类别分布对树归纳的影响”，《人工智能研究杂志》，第 19 卷，第 315-354 页，2003 年。**

**[27]t .范·德·普洛格，奥斯丁，P.C .和 Steyerberg，E.W,《现代模拟技术对数据的渴求:预测二分终点的模拟研究》。BMC 医学研究方法，第 14 卷，第137 号。(2014).https://doi.org/10.1186/1471-2288-14-137**