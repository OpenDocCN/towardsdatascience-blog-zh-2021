# 一、♡不可复制的研究

> 原文：<https://towardsdatascience.com/i-irreproducible-research-dbc48eb140ac?source=collection_archive---------17----------------------->

## [思想和理论](https://towardsdatascience.com/tagged/thoughts-and-theory)

## 现实世界研究的更好的实验协议

![](img/3bb67e28545db53712f69570c7dbaf56.png)

图片来源:[蔡斯·贝克](https://unsplash.com/@sandbarproductions?utm_source=medium&utm_medium=referral)

机器学习研究的黄金标准是实验的“顺序”模型:你有一个基线、你的实验和一个固定的、预先确定的测试集。你在测试集上评估你的基线，得到一个基线数字。然后你在测试集上运行你的实验，得到另一个数据。然后你比较两者。假设您发布了所有这些工件，任何人都可以复制结果。这是很好的科学。

再现性一直是科学进步的基石，也是无数[研讨会](https://sites.google.com/view/icml-reproducibility-workshop/home)和[的主题，特别是在机器学习领域。虽然提高研究结果再现性的尝试通常是完全正当的，并且明显有益于社区，但它们也带来了将这种非常狭隘的精确再现性模型作为唯一可接受的标准的风险。](https://www.nature.com/articles/d41586-019-03895-5)

学术机器学习界很少意识到，出于非常基本的原因，并非所有的研究都具有完美的再现性，尽管如此，如果你正确设计实验协议，还是有科学合理的方法来实现统计再现性。我相信，作为一个群体，我们需要更好地教育自己，特别是在研究主题是现实世界表现的领域，例如我的实验室正在进行的橡胶碰到马路机器人研究。

谷歌进行的许多实验并不完全可重复，因为它们基本上是关于评估模型对现实世界的影响。现实世界总是在变化的:用户与系统的交互在很大程度上随着昼夜循环、季节变化、世界大事，甚至更难以捉摸的长期社会趋势而变化。更重要的是，用户模式的变化是模型本身变化的结果。

> 如果你关心你的模型对现实世界的影响，那就没有测试集。

你不能按顺序进行你的实验:今天是你的基线，明天是你的实验，因为在这两天之间世界已经发生了变化，你的数据将没有可比性。你也不能保留昨天的测试集，因为你的数据会随着你的模型发展:如果你的模型向用户提供一组搜索结果，而价值指数是人们是否会点击它们，那么你就不能回到昨天的用户那里，问他们如果得到一组不同的结果，他们会怎么做。

解决方法是*平行*实验设计，也称为 A/B 测试。对于每个测试实例，您随机选择您将运行实验的哪一部分，基线还是实验。这种简单的处理方法消除了由于分布的潜在变化而产生的任何差异，即使您的评估设置处于不断变化的状态，您也能获得统计上有效的结果。

这让我们对 A/B 测试及其作为科学工具的实用性产生了最大的误解:例如，它经常被用于 UX 设计，以观察网站布局的微小变化是否会影响用户点击，或者阴影的细微变化是否会使广告更具吸引力。因此，它被认为是改善微小效应置信区间的工具。由于 ML 研究人员与置信区间的关系充其量是一种勉强的容忍，A/B 测试与 ML 研究的实际相关性通常被忽视。

> 并行 A/B 测试完全与大效果测试相关，*尤其是*当你的评估设置不能被严格控制的时候。

我的同事(*)最近在机器人研究领域提供了一个生动的例子。在机器人领域建立一个可重复的评估设置是众所周知的困难:机器人移动位置，设备和物体磨损，照明变化，机器人操作员以微妙的方式影响每次实验后设置重置的方式。臭名昭著的“重置问题”是一个非常棘手的问题，因为执行一个好的重置协议，将你的机器人设置恢复到一个已知的固定状态，可能与一开始进行实验一样困难。

他们采用了我们最简单的设置之一，即在一个箱子内筛选相同的泡沫塑料方块，并测量这种完全受控环境的可重复性。

![](img/27ec0b54d1b87701643ed04f57b9f1fd.png)

简单的机器人分割设置。来源:谷歌的机器人技术。

我的同事在几天内连续进行了 11 次筛选实验，并测量了每次实验的成功率和置信区间。根据基线运行的性能标准化的结果如下所示:

![](img/c7e2aca8e85bacf46bf78ad83c8ec664.png)

相同实验的可变性。来源:谷歌的机器人技术。

如果每个实验都是不同的模型，我们会说实验#7 好了 2%,实验#5 差了 5%。我们甚至会有足够紧的置信区间来说服你。但是这里的实验没有区别，它们都是一样的。请注意，这不是缺乏数据的情况:更多的数据只会缩小置信区间，而不会相对于基线移动它们的位置。无法解释的变化完全落入环境的“未知的未知数”中。这种设置对于真实的机器人实验来说非常简单:许多机器人论文报告了顺序治疗实验，这些实验比这种实验有更多潜在的无法解释的可变性。更重要的是，如果我们没有测量这种日复一日的可变性，我们甚至不会猜到它的存在。很少有研究人员首先想到测量他们的实验设置中的内在可变性，因为让我们面对它:这是工作，只有坏消息可以从那条探究路线中出来。

这里的教训是，对于这个特定的实验协议，我们绝对不能相信任何低于 10%的性能差异——如果没有大量的重复验证，我甚至不知道我是否会相信 10%的差异。是不是没希望了？当然不是。进入平行测试。

一旦你摆脱了完美再现性的幻想，你就可以享受*统计再现性*带来的令人愉快的自由，并且仍然可以做可靠的科学研究，同时获得更高的数据效率作为奖励。

这是三天的完全相同的实验，但这次基线与实验平行进行，在每集随机选取。

![](img/401a4426482cc081bb089e9a3078024b.png)

平行相同实验的可变性。来源:谷歌的机器人技术

注意现在这些数字是多么的一致，告诉你在基线和实验之间确实没有区别。像这样的中性 A/A 实验是最难的统计测试，任何实际影响性能的实验都能够显示出清晰的信号。

这是在实验设置没有任何变化的情况下进行的，只是实验方案略有不同。

那么为什么大家都不这么做呢？让我们来看一些挑战。

一个常见的误解是，因为每个实验都要反复运行基线，所以需要两倍的评估数据。只要您的设置中存在一些可变性，这就不是真的:您从始终运行基线中获得的统计效率的收益可以抵得上一个数量级的数据，或者在最坏的情况下抵得上无限量的数据，正如我们在上面看到的。使用[重叠实验](https://research.google.com/pubs/pub36500.html)有更聪明的方法来获得更高的数据效率——这可能是谷歌最被低估的研究论文，但正确地利用这一点需要比大多数研究人员可能愿意在这个问题上投入的工作更多的工作。

一个缺点是你的基线必须总是可运行的，最好和你的实验在同一个二进制文件中，并且是动态可切换的。不可否认，这需要对你的软件进行工作和仔细的设计。这样做的好处是，您还可以保护自己免受意外的 bitrot，在这种情况下，一些合作者意外地在您的下面更改了一些影响基线性能的东西，而您没有注意到，这在任何共享代码库中都有可预测的规律性。系统中的许多变化是微小的，以微妙的方式影响原始性能，最终与手头的科学问题无关。不必控制所有这些绝对是一种解放。

这种设置的一个明显的优点是，你可以动态地监控你的置信区间，当你确信自己的实验甚至有点负面时，就决定停止实验，这通常需要更少的数据来确定。如果实验是积极的，很好，只要你需要得到适当的误差线，就运行它，如果你不是测量效果的大小，而仅仅是显著性，你也可以早点停止它。

但是让研究可以被其他人复制呢？您仍然可以发布基线和实验模型，以及实验协议，任何人都可以在他们的复制系统上生成自己的数据，以说服自己这些发现的有效性。回想一下，这里的前提是，您使用的数据是*而不是*可重用的，要么是因为它本质上是短暂的，要么是不可移植到同一研究机构的任何未来实例中。

并行测试的另一个主要好处是保护你免受许多偏见的影响。主要的一个是实验者的偏见:因为你不知道哪个数据样本被传送到实验的哪个部分，你不能欺骗自己相信一个结果而不是另一个。它还可以防止您意外地调优测试集，因为在评估中设计了一定程度的随机性。

强化学习和机器人技术的另一个更具体的偏见是不完美的重置:如果实验的一个部分导致重置机制的行为与另一个部分略有不同，那么你可能会有细微的差异，而这些差异不会被注意到。我们已经看到 RL 系统操纵它们的环境来产生特定的重置状态，从而提高它们在后续情节中的成功机会，或者甚至以这种方式跨情节传递信息。

事实上，并行实验协议通常可以首先显著减少或消除重置的需要:如果您的系统在状态空间的有效部分终止了每一集，因为没有办法知道实验的哪一部分导致了环境的特定配置，所以您可以经常运行终身实验，没有重置，也没有跨实验部分的偏差。

![](img/057e1b7163c27468c2f4bbf259384b14.png)

相同基线的绝对可变性。来源:谷歌的机器人技术。

你要放弃的一件重要事情是拥有一对整洁的“基线准确性”和“测试准确性”结果的舒适，你可以把它们写在一篇论文上，这是每个学术评论者都期望的。每个实验都有自己的基线，而基线又有自己的置信区间。您的绝对测试精度数字取决于测量的日期，但它仍然是完美的，因为您每次测量的两臂之间的差异都会进行统计显著性评估。

尽管如此，评论家接受这一现实的障碍仍然很大。从绝对的、可复制的真理到相对的、统计的真理的飞跃是令人不舒服的。这是许多科学领域，如药物开发，出于必要而做的事情，但这对机器学习来说仍然是陌生的，在机器学习中，退回到离线评估通常是一种选择。这种对真实系统实验的机构过敏反应的问题是，在机器人学等领域，真实世界的表现实际上是房间里的科学大象，而违背那些原本坚实的科学协议的学术实践正在积极地阻碍我们。做真实世界的实验是困难的，有风险的，反对这种研究的学术动机应该随时反对。

我们在该领域的太多集体精力都花在了试图提出新的、密封的、完美的基准上，这是非常难以建立的，有点不切实际地追求让机器人看起来更像 ML 研究。最终结果是，除了极少数例外，大多数这方面的努力都止步于模拟基准和用现实主义换取可重复性。这些努力仍然有很多优点，但它们只占等式的一半左右，而且通常建造它们的纯粹费用会分散研究人员对实际科学追求的注意力。其他人试图定义[元基准](https://arxiv.org/abs/2011.01975)，通过不首先精确定义任务或实验协议来规避可重复性问题。作为一个固执于协议和过分详细说明问题的无用性的人，我认为这是一个积极的大方向，即使它将实际执行的许多困难方面留在桌面上。

现在是我们在机器学习和机器人研究中拥抱那些简单工具的时候了，这些工具使“不可重复”的研究可重复并具有科学合理性。我在这里描述的协议没有一个是特别难实现的，它们有希望让现实世界的科学变得更好、更容易、更快。

*(*)本文背后的许多灵感和实际数据都要归功于 Arnab Bose、邝宇恒、Anthony Brohan 和 zvan Surdulescu 的惊人努力。观点是我的。*