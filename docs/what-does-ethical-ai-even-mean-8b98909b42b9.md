# 伦理人工智能到底是什么意思？

> 原文：<https://towardsdatascience.com/what-does-ethical-ai-even-mean-8b98909b42b9?source=collection_archive---------40----------------------->

## [播客](https://towardsdatascience.com/tagged/tds-podcast)

## 莎拉·威廉姆斯在 [TDS 播客](https://towardsdatascience.com/podcast/home)

要选择章节，请访问 Youtube 视频[这里](https://youtu.be/6U-m5zfag3A)。

*编者按:这一集是我们关于数据科学和机器学习新兴问题的播客系列的一部分*，*由 Jeremie Harris 主持。除了主持播客，Jeremie 还帮助运营一家名为*[*sharpes minds*](http://sharpestminds.com)*的数据科学导师初创公司。可以听下面的播客:*

[苹果](https://podcasts.apple.com/ca/podcast/towards-data-science/id1470952338?mt=2) | [谷歌](https://www.google.com/podcasts?feed=aHR0cHM6Ly9hbmNob3IuZm0vcy8zNmI0ODQ0L3BvZGNhc3QvcnNz) | [SPOTIFY](https://open.spotify.com/show/63diy2DtpHzQfeNVxAPZgU) | [其他](https://anchor.fm/towardsdatascience)

毫无疑问，人工智能伦理最近受到了很多应有的关注。但是问普通人什么是道德人工智能，你很可能得不到一个茫然的眼神。我认为这在很大程度上是因为每一个数据科学或机器学习问题都有独特的伦理背景，所以很难确定概括一大类人工智能问题的伦理原则。

幸运的是，有研究人员专门关注这个问题——我今天的嘉宾莎拉·威廉姆斯就是其中之一。莎拉是麻省理工学院建筑与规划学院城市规划副教授和城市数据设计实验室主任。她的工作是研究数据科学在城市规划中的应用，并与决策者合作，以道德的方式应用人工智能。通过这个过程，她提炼出了几个具有实际意义和可操作性的通用人工智能伦理原则。

这一集引发了广泛的讨论，从我们的意识形态如何影响我们的数据分析，到政府在试图监管人工智能时面临的挑战。以下是我在对话中最喜欢的一些观点:

*   有许多方法可以分析数据集、训练模型和解释任何数据项目的结果。因此，一个给定的数据集可以很容易地用于论证相互不相容的结论——这就为分析师、数据科学家或模型构建者的激励和先验信念留下了很大的空间，以确定对该数据的哪些解释是有利的，并最终采取行动。
*   这些激励和信念可以采取不同的形式，并由数据科学家自身的意识形态观点和经验形成。在这种背景下，我们讨论了两个不同但相关的问题:第一，科技领域的多样性问题(从种族和性别多样性的角度来看)，第二，意识形态多样性问题(科技公司中进步派和保守派的不平衡)。
*   政府目前通过对当天的重大问题做出反应来监管人工智能，但随着人工智能的进步步伐不断加快，这种策略似乎不太可能奏效。相反，预期监管可能是必要的，但这将要求政府变得更懂数据，更了解机器学习和人工智能的前沿发展。

你可以[在 Twitter 上关注莎拉](https://twitter.com/datasew)，或者[在 Twitter 上关注我](https://twitter.com/jeremiecharris)

## 播客中引用的链接:

*   莎拉的书名叫[数据行动:利用数据造福公众](https://mitpress.mit.edu/books/data-action)。你可以在这里找到它。
*   麻省理工学院城市设计实验室的网站。

![](img/4d7fabd31d26681bf1058c22f2bddde3.png)

## 章节:

*   0:00 介绍
*   1:16 思域数据设计实验室工作
*   3:27 与决策者的互动
*   7:22 拦截搜身项目
*   17:06 对城市数据分析感兴趣
*   18:25 算法偏差
*   21:41 现场多样性
*   23:00 政治思想
*   28:00 变化的速度
*   34:29 隐私问题
*   42:03 互联网上的私人垄断
*   44:32 总结

## 请查看下面的文字记录:

Jeremie (00:00):
欢迎大家回来。我叫 Jeremie，这是“走向数据科学”播客。现在，毫无疑问，人工智能伦理最近受到了很多应有的关注。但是如果你问普通人人工智能伦理到底意味着什么，你很可能不会得到一个茫然的眼神。现在，我实际上认为这在很大程度上是因为每个数据科学或机器学习问题都有独特的伦理背景。因此，很难确定能够概括更广泛的人工智能问题的伦理原则。

Jeremie (00:26):
幸运的是，现在有研究人员专门研究这个问题，我今天的嘉宾莎拉·威廉姆斯就是其中之一。莎拉是麻省理工学院建筑与规划学院城市规划副教授和城市数据设计实验室主任。她的工作是研究数据科学在城市规划中的应用，并与政策制定者合作，以道德的方式应用人工智能。

Jeremie (00:48):
现在，通过这一过程，她提炼出了几个可概括的伦理原则，这些原则在人工智能的背景下具有实际和可操作的意义。所以，这一集我们将会谈到这一点。我们还将对一切进行广泛的讨论，从我们的意识形态如何影响我们的数据分析，到政府在试图监管人工智能时面临的挑战。我真的很喜欢这次谈话，希望你也一样。好的，莎拉，非常感谢你参加我的播客。

莎拉(01:13):
是的。非常感谢邀请我。来到这里我真的很兴奋。

Jeremie (01:16):
我认为你正在一个服务水平低下的领域工作，这是一个数据科学领域的人们不太关心的领域，但它也是我们生活方式的基础。这是一个政府政策制定面临困难的领域，它迫使我们比其他人更直接地面对人工智能伦理问题。这就是城市规划的理念。你现在在麻省理工学院的城市数据设计实验室。首先，我想了解一下您在那里的日常工作，以及它与数据和数据科学的关系。

莎拉(01:51):
城市数据设计实验室的本质是思考我们如何利用数据来改变政策。我们做这项工作的主要方式之一是通过数据可视化和交流数据的洞察力。但为了做到这一点，显然我们必须进行数据分析。我们还建立了团队，与政府、政策制定者、社区利益相关者合作，以真正确定我们正在寻求答案的问题。做定量分析，然后把它公之于众。

Sarah (02:35):
我认为这可能是与数据科学领域其他学者略有不同的一点，即并非所有类型的分析都适用于所有人。为了真正对数据采取行动，我们需要让数据更容易获取并传达给广大公众，如新闻和媒体，以及社区成员和不同的政策团体，这些人正在做出政策决定，以便他们可以采取行动。

耶雷米(03:05):
是啊。我发现这本身就是一个迷人的想法，而且我认为这是在翻译中迷失的东西，因为这种专注于机器学习，工程，缩放，强大的人工智能系统，所有类型的技术细节。人们有时会忘记，数据科学最终必须被应用才有价值。这涉及到一个沟通的部分，就像没有它，你最终真正在做什么？

Jeremie (03:27):
在某种意义上，这让我想到了你在书中讨论的一个主题，顺便提一下，如果有人感兴趣，这本书叫做《数据行动:利用数据造福公众》。实际上，这是一项非常有趣的工作，涉及我们今天将要深入探讨的一大堆主题。但其中一个主题是，你用来看待数据的视角，做分析的人的动机通常会影响到结果，结果的建议，以及结果的洞察力。你能就此谈一点吗，然后谈谈这如何影响你与政策制定者的互动？比方说，你如何确保给那些决策者一个合理的、平衡的观点？

莎拉(04:10):
超级棒的问题。我很高兴你问了，对吧？我的意思是，我们经常把数据等同于真理或知识。这是事实，我们怎么可能有任何偏见呢？但是，当然，数据是一种工具，就像笔在纸上或颜料在画布上一样，它确实代表了有意或无意使用它的人的目标。

莎拉(04:33):
我的意思是，它对我们有很大的说服力，人们可能会将数据集推到某个特定的区域，以获得他们想要的结果。所以，当我的学生在看数据分析时，我总是告诉他们的一件事是，询问谁制作了这些数据，出于什么目的，对吗？那么，他们创建这种特定分析的目标是什么呢？他们有可能以某种方式从中受益吗？

莎拉(05:11):
数据很复杂。我们用事实创造它，当我们看到图表时，我们几乎立刻就相信了它。所以，就像，也许更多地审问它。然后我告诉数据科学家的一部分是询问你自己的目标，对吗？你可能没有意识到你正在试图做什么来说服人们，因为当你把你的算法放在一起时，你会带着它，这对许多人工智能模型来说是真的，它们充满了我们所有的偏见。因此，要真正地询问这些偏见，以确定它们可能会产生什么样的危害。

耶雷米(05:52):
是啊。很有意思。像数据科学这样的任何类型的高维问题中的一个隐含问题是过度拟合是一个问题。你有这么多的数据，我想，我不知道这是不是马克·吐温说的，但像你这样的人可以用统计数据证明一切，除了事实。差不多就是这样。

莎拉(06:11):
我喜欢这句话是马克·吐温说的。

Jeremie (06:16):
我肯定我在某种程度上破坏了这一点，但你有所有这些虚假的相关性，这是一个层面。这就像一个事实，如果你仔细观察，你会发现鞋带的价格与过去 10 年或类似的时间里天空中的云量相关。但是还有一个单独的问题，如果你打算做一个特定的案例，你实际上有效地 P-hack。我的意思是，这是你所描述的，还是在更广泛的学术界类似于 P-hacking 的东西？

莎拉(06:47):
是的。我的意思是，当然你可以添加尽可能多的变量，可以得到你想要的回归分析，所以真的要质疑。但我也认为你提问的方式也可能会无意中造成伤害，或者你应用数据的方式。我只是在想，同一个数据集可以有两种不同的用途，甚至是两种不同的目的。

莎拉(07:22):
我在想我们在书中谈到的一个项目，即查看 stop 和 frisk 数据。最终，纽约市警察局公布了拦截搜身数据，这是一份公开记录，美国公民自由联盟对其进行了分析，发现警方确实过度压制了非裔美国人和西班牙裔美国人。因此，我们能够对此进行数据可视化，以证明该政策在种族貌相方面存在严重问题。

莎拉(08:07):
但是在警察局的另一边，同样的数据集被用于种族貌相，对吗？因此，他们使用这些数据和分析来确定要去的区域，进行更多的拦截和搜查，在美国公民自由联盟进行这些数据可视化后，这在美国被视为非法搜查和扣押。所以，我认为这也是你使用数据集或进行分析的角度？对吗？

莎拉(08:36):
所以，一方面，警方利用它来思考针对特定社区的策略。另一方面，美国公民自由联盟将其颠倒过来，并将其作为揭露种族主义行为的一种方式。所以，这只是考虑做分析的人的目标。

耶雷米(08:59):
在你自己看来，你是如何分析出其中的相关因果关系的？例如，我想，这是这个领域的一个常规辩论。有些人会说，“嗯，这些社区因为他们的种族，或者他们的肤色，或者他们的人口特征而成为目标。”有人说，“那里的犯罪率更高。这就是为什么你需要更多的警力。这就是为什么会发生这种情况。”所以你基本上有一个反馈回路。我并不是说反馈循环是可取的，但这至少是这方面的论点。你如何将这两者分开，并在上下文中寻找原因和结果，而不是没有关联？

萨拉(09:34):
是的，我的意思是，我认为这项政策明确针对少数族裔社区，是的，也许这些社区的犯罪率更高。但事实是，他们有特定的目标…也许我要退一步说，我认为警方数据的一个特别之处是，他们经常去有更多犯罪的地方，但他们没有考虑它背后的系统性问题，例如可能缺乏职业培训计划，或更好的教育系统，或更好的社会服务。

萨拉(10:20):
所以，我也认为，当我们查看这些数据集时，思考为什么这些社区可能有更多的犯罪也是一件重要的事情。所以，我发现使用警方数据来说，“哦，我们有一个热点。现在，让我们去那里，并把更多的警察，“有问题，因为它实际上并没有解决问题。更确切地说，问题是许多社区持续的贫困导致了这些犯罪的增加。

耶雷米(10:52):
这很有趣。这就好像有一个单独的步骤，好的，我们有这个可视化，它似乎邀请我们跳到一个特定的结论。但是还有一个额外的步骤，几乎是决策说，好吧，相关性不一定是因果关系。这里可能会有一个更有趣的故事。

撒拉(11:08):
正是。

耶雷米(11:09):
让我们看看。是啊。有意思。

撒拉(11:12):
对。我们不经常讨论因果关系，对吧？就像我们说的高犯罪率，所以去那个社区。但实际上是什么导致了那些街区的高犯罪率却很少被提及。

耶雷米(11:26):
所以，我对人类的失败模式很感兴趣，这种模式让我们看到我们的外部群体以非理性的方式思考。举个例子，在这种特殊情况下，对吗？很明显，有一群人会说，“哦，那里的犯罪率很高。我要进去把它踩出来。”

耶雷米(11:49):
然后另一组人可能会看着它说:“哦，好吧。这是你不怀好意的表现。”所以，很有趣的是，在我看来，就像你在书中描述的那样，镜片非常重要。你可以看着同样的过程，同样的数据，然后说，“哦，这是一个完全不同的故事。”

撒拉(12:11):
对。绝对的。是啊。我的意思是，这就是数据分析的棘手之处，也是为什么我认为随着时间的推移，它被用于好的和坏的目的，更简单地说。所以，这是我在这本书的最后，谈论的七个行动数据的原则之一。第一件事是真正质问你做分析的原因，以及它是否可能对任何人造成伤害。

莎拉(12:42):
所以，我认为对于警察部门来说，我真的希望他们能考虑一下以这种方式使用数据会有哪些意想不到的后果。我认为，不幸的是，数据驱动的警务现在在我们的社会中是如此根深蒂固，以至于很难真正改变这种想法。但我认为，最近夏天的对话确实有助于努力突出这一点。

萨拉(13:15):
所以，这些关于解除警察经费的对话是在谈论将警察经费转移到社会服务中，对吗？这是同一个论点。看看系统的问题，而不是我的…如果我们能够思考如何帮助人们摆脱贫困，我们可能真的能够做一些事情。我真的被一些事情所鼓舞。我的意思是，我不认为我们有必要解除对警察的资助，但我认为应该把钱分配到这些系统性的原因上，而不是仅仅派警察去这些相同的社区。

萨拉(13:53):
我们一遍又一遍地做同样的事情，这不就是疯狂的定义吗？所以让我们想一个新的系统。我也喜欢这些数据如何把你带到那里，因为它可以告诉你那些社区需要帮助，就像它告诉你它们有高犯罪率一样。

耶雷米(14:10):
是啊。令人着迷的是，当我们看到一个可视化或一个情节时，它几乎就像是我们进行更深层次分析的责任的一部分被抽象掉了，我们看着它，我们就像，“哦，有…”回到同一个例子，“有一个热点”。因此，让我尽我所能画出最直接的因果模式或故事的直线。”

耶雷米(14:35):
我想象这种情况正在各地发生。我是说，我在我的公司里亲眼见过，对吧？我们会看到一些使用模式，就像，“哦，不。人们不注册或一些可怕的事情正在发生。”你妄下结论，结果发现你完全错了。你如何建议人们开始审问这个思维过程？我的意思是，有没有具体的步骤可以让人们后退一步，并努力确保他们正在这样做？

撒拉(14:58):
是啊。我很高兴你问了这个问题。这也是我在这本小册子中谈到的原因之一，将团队聚集在一起，实事求是地对待你的结果，而不是实事求是地对待你的结果，做实事求是地对待你的结果。我的意思是，实际上看到你所说的是真的。但我认为社区成员、政策专家或该领域的利益相关者会关注你的分析是否真实。我几乎总是发现，当我第一次做分析时，当我把它带给一群人时，他们会说，不，不，不，不，你没有看到它的这个方面。这是这样的。

莎拉(15:40):
所以，我认为这种编辑过程非常重要，特别是在政策领域，因为总有一个盲点，我们可能会忽略，而这个盲点非常有帮助。我认为在过去，在 50 年代和 60 年代，当我们在城市规划中大量使用数据时，我们确实只是做直线，某种程度上，穿过城市的最有效的方法是建造穿过这个社区的高速公路。这是直线，这是数据告诉我们的。我们没有考虑到所有其他种类的，比如说，副作用。如果我们把这些分析带到社区，询问他们对它的看法，我想我们可能会得到，比方说，一个更微妙的高速公路系统。

耶雷米(16:32):
是的，不，我相信在很多领域都是如此。当我们定义问题时，在优化方面留下的东西太多了，这很可怕，我想这是关于狭义地定义问题，或者至少有，这就像用一个太有限的功能集来表示世界。我们说这就是问题所在。这些是重要的特征，不管我的模型怎么说，这是告诉你自己，“好吧，我有一个损失函数，”或者，“我有一个优化函数”的能力。只要这个数字上升，我就很高兴。如果不行，我就不行，这就是故事的结尾。”有点冒险的生意。

莎拉(17:06):
是的。我的意思是，这让我感到害怕，因为有这么多伟大的人对城市数据分析或政策数据分析感兴趣，但可能不精通城市问题或其他类型的政策问题。所以，他们可能会想出这个优化问题的答案，却没有意识到有人已经在过去做过了，结果出了岔子。

莎拉(17:33):
所以，这也是为什么我认为数据科学家总是与该领域真正的专家配对，帮助他们编辑和验证他们的结果是如此重要。但是，是的，我们不希望历史重演。

耶雷米(17:54):
现在，在分类账的另一面，我想我看到了这个有趣的讨论。事实上，我在 Twitter 上看到过 OpenAI 和 OpenAI 政策团队之间的对话。我想阿曼达·阿斯克尔最近在推特上提到了这件事。我认为这是一个有趣的观点。她强调了这样一个事实，即也有一种趋势，即找到一个反对特定系统的道德部署的论点，并利用该论点的存在来含蓄地完全驳回该部署。

耶雷米(18:25):
所以先验地说，“好吧，这个算法有某种形式的偏见，”或者“不可避免地，所有算法在伦理上都有某种缺陷，因此我们不应该部署它。”你认为平衡日志的方法有哪些？你如何决定，道德上的负面影响是否大于正面影响？显然这是一个复杂的问题，但是你会如何开始考虑它呢？

萨拉(18:51):
是的，我的意思是，我认为这是一个很好的问题。自从蒂姆尼特·格布鲁被谷歌解雇后，我一直在思考这个问题。我认为谷歌内部有一个道德团队真正酷的地方是真正找出你的偏见所在，并纠正它们，或试图纠正它们，或解决它们，对吗？而不是把它们扫在地毯下，让某人进去内部调查你的工作道德，这只会让你成为一个更好的公司，因为你在未来会做出更好的算法。

萨拉(19:35):
所以，你要朝着那个目标努力。我认为数据分析是一个迭代的过程。我们从来没有第一次做对。对吗？这是我们的基础。所以，我相信，我们可以在这些经验的基础上创造出更有道德的人工智能。所以，我真的很惊讶，很明显，那里有很多政治，我肯定还有其他事情。但是我认为脸书和谷歌会做出更好的产品，如果他们有人质疑他们的道德的话，因为这样他们就可以回头让它变得更道德。

莎拉(20:18):
所以，我想这是一种冗长的方式来说，我认为我们可以朝着它努力，但我们应该不断地询问我们的工作。

耶雷米(20:31):
你是如何看待那种，我想你在书中提到了它，你使用了意识形态的语言，这很有趣。所以，我们数据分析的意识形态，我认为这是一个迷人且完全正确的看待它的方式。因为那真的是…我们都被我们的意识形态所控制。我们都有一个自己的版本，我们进入时是无意识的，不是分析性的。这就是群体思维等等。

耶雷米(20:54):
你认为像谷歌这样的公司是否存在持续的问题。你有一定数量的人以某种方式思考这个问题，我的意思是，特别是人工智能伦理。我的意思是，我认为公平地说，这是一个领域，例如，有不成比例的人会从亲技术的角度思考。就像，你会叫它什么？就像技术加速主义者，可能更，比如说，更面向社会之类的。

耶雷米(21:27):
你认为在这个领域本身的层面上有没有问题，在处理这些问题的方式上，它需要考虑更多的意识形态多样性？如果是的话，我的意思是，据你所知，有没有积极的措施朝着这个方向发展？

撒拉(21:41):
我的意思是，完全正确。我想你说对了。没错。这不仅仅是质疑算法的道德，而是确保在这个领域有不同的人在工作。特别是，确保少数群体 BIPOC 小组在这个领域开展工作，以带来…因为我确实认为技术领域一直被一种意识形态观点所主导，这种观点可能对数据中存在的所有不同的人并不总是那么敏感，对吗？因为所有的数据都代表人。当它分析一类群体时。

莎拉(22:32):
所以，这就是为什么像黑人生活数据这样的组织开始出现，他们正在想办法确保我们在这个领域的多样性。超级重要。我认为这也有助于我们质疑算法，但创造和产生从一个非常不同的角度看待数据集的新方法，也许也是从那些边缘人的角度。

耶雷米(23:00):
你也从政治意识形态的角度来考虑这个问题吗？我的意思是，以硅谷为例，从历史上来看，这是一种常见的抱怨，你会在很多场合听到，你怎么称呼它？国会的科技听证会。对吗？所以，典型的共和党参议员或众议员会说，“嘿，脸书缺少保守派。”在脸书工作的人中，左翼人士和思想更加自由的人占了压倒性的多数。

耶雷米(23:30):
这是一个不同的轴，对不对？我们有这样的想法，是的，一个单一种族或一种种族的大多数，一种在这些公司工作的自然人。然后我们有意识形态的差异，硅谷的一个很大的差异是，如果你看看民意调查，压倒性地倾向于一个方向而不是另一个方向。你认为这也是值得解决的问题吗？还是你认为这是另一个问题的一部分？

萨拉(24:02):
嗯，我是说，我认为这是个好问题。我认为，至少在政治领域，我们已经看到保守派和共和党在选举中以同样的方式平等使用数据。我的意思是，剑桥分析丑闻就是一个很好的例子，就像保守派真的在部署数据。有些人可能会说剑桥分析与脸书有太多联系，他们真的在为那个特工工作。当然，马克·扎克伯格会说，“嗯，这些是脸书以外的人，他们基本上是在发展，保守的广告，保守的目标。

萨拉(24:56):
所以，我想说我不确定我是否完全同意这是一个完全自由的领域。或者更好的说法是，我绝对认为他们为我们两党的目标而工作。有些人可能会说，他们更倾向于保守派，而不是更倾向于自由派。

耶雷米(25:26):
是的。我的意思是，这是一个有趣而复杂的领域。我对这两个职位之间的映射很感兴趣，人们会说，“嗯，这归结于组成组织的人。”如果这些人有特定的观点，不管是因为肤色、性别还是政治意识形态。我对这些不同的轴之间的区别很感兴趣，我们应该注意和谨慎，显然这是一个复杂的问题。

撒拉(25:55):
是啊。我的意思是，这很复杂，因为我认为在一天结束时，脸书，谷歌，他们的上帝是钱，对不对？赚钱。

耶雷米(26:07):
优化函数。

莎拉(26:09):
他们有钱，对吧？所以，我认为他们会把自己卖给出价最高的人，不管他们现在是自由派。但我同意，这些公司里可能有更多的自由主义者。但同样，我认为他们经常朝着其他目标努力，而这些目标可能不在此列。我想说，共和党人系统地使用数据已经有很长时间了。甚至我会说，自从第一次人口普查在 70 年代出来，他们看到了这个数字普查。

萨拉(26:44):
实际上有一个叫托马斯·霍弗勒的人，他基本上重新划分了美国的大部分地区，并且从早年开始一直是共和党重新划分选区的负责人，他系统地使用数据来推动国会选区向共和党多数派靠拢。他经常被称为不公正选区划分的米开朗基罗，因为他非常擅长移动这些数据集。但是，人们经常谈论奥巴马的当选归因于他非常热衷于使用数据分析来瞄准可能没有投票的新人口。所以，我的意思是，你的问题更多的是，我在思考我们使用的数据的意识形态观点。但是

耶雷米(27:40):
我认为你说的也很有道理。这是一种神奇的力量，它可以进入任何…就像我们必须小心使用它一样。是啊，实际上与此有关。现在，我确实想问一下你的互动，事实上，和政策制定者的互动，因为我猜你已经和他们中的一些人谈过这些问题，具体的道德问题。

耶雷米(28:02):
所以，我有一个问题。我们谈论政策。我们谈论政府。我不会把政策和政府联系在一起的词是速度。我不倾向于考虑快速，快速的反应。在这样一个世界里，我们看到 GPT 3 号即将发射，GPT 4 号也即将发射，谁知道其他地区接下来会发生什么？随着时间的推移，我们越来越多地拥有这些能力。变化的步伐正在加快。我想，在政策领域，你对响应时间有什么看法？你的体验是不是速度确实比较慢？我错了吗？我很可能是。

萨拉(28:37):
是的，不，政策绝对是缓慢的，因为它会削弱不同的派别，让人们加入你的团队。仅仅是向人们推销你的特殊观点或想法就有很多工作要做。所以，我认为政策工作总是需要很长时间，我认为这是因为需要建立这种关系。

萨拉(29:17):
我认为人们也在谈论政府内部进行这些数据分析的速度。我认为，特别是彭博，我知道他在纽约市真的花了很多…他是一家数据公司，所以当他成为市长时，他真的想创建这个数据分析团队。他非常成功地帮助部署和使用数据来帮助政府的许多领域，但仍然经历了这种基于政策和政治的障碍，这种障碍将永远存在。

莎拉(30:00):
我认为数据分析只是其中的一种工具，对吗？我们可以利用它。它真的有助于让我们相信某些策略和想法。它可以说是政策分析师的工具。我希望我正在做的是，我是麻省理工学院城市科学项目的负责人，这是计算机科学和城市规划的结合，是教规划者和政策专家做他们自己的数据分析，并且能够…如果我们有更多的政策制定者可以自己做这些，也许我们可以加快一些进程。但是我认为不管这些，比如说，建立关系的东西会存在。

耶雷米(30:46):
这很有趣。这说明了问题的架构，让政府决策者真正开始为自己利用这些工具，而不是，我猜，让外部顾问进来告诉他们，“嘿，我看了数据，这是图表。”希望这有助于他们在内部证明这一点。这就是他们有这种灵活性的想法吗？

莎拉(31:05):
是的。他们能做到，甚至能读懂顾问在做什么，对吗？因为顾问有时并不关心选民，或者顾问并不…所以，学会做数据分析，也许他们不做，但他们知道如何更快地评论这项工作，并询问它的准确性。

萨拉(31:29):
但我看到，即使在过去的 10 年里，许多城市规划者也知道如何使用绘图软件和计算机绘图软件，这些软件过去需要交给技术人员，现在他们可以非常快速地绘制这种社会人口统计地图。即使在 COVID 的领导下，我们也看到了很多工作在进行，看看哪些社区被边缘化了，哪些没有。许多工作正在公共卫生部门内部进行，这些部门现在也有统计专家。

耶雷米(32:01):
是的。这似乎是一件非常重要的事情，让政府在这方面更加灵活和宽松。我想这也是一个挑战，首先要接近他们，让他们相信，“嘿，这是有价值的。”因为你面临冷启动问题，不是吗？我的意思是，你去找政府，你说，“嘿，你有一堆数据。它可以发挥杠杆作用，用于一系列伟大的事情。”但是政府，我想，可以理解，会说，“哇，哇，别碰我们的数据。之前你需要向我展示价值。”但是你之前不能向他们展示价值，因为你没有数据。当你开始从事这些事情时，这是一个循环吗？

撒拉(32:35):
是啊。你所说的有趣之处在于，我们经常假设政府拥有大量数据，而实际上，通常他们并没有。他们试图从谷歌、脸书和推特等私人公司获取信息。他们需要购买的其他数据集就像房地产投资公司。所以，我认为政府很乐意在数据分析方面做这件事，然后想办法与一些私人组织合作，以便能够进行他们想要的分析。

莎拉(33:10):
想想房地产的价值。这些数据集是由私人公司创建的，但对于理解这座城市的动态和经济动态性质非常有用。所以，我认为城市很难支付这样的数据集。为什么我不说，并不是所有的部门都是数据贫乏的，像警察局有大量的钱来购买这种数据，因为我们为此分配了大量的资源。

莎拉(33:46):
但有趣的是，他们并没有与规划部门分享这些信息。不管怎样，我们又回到了政治上。对吗？但我还想说，我认为另一个原因是，比方说，城市无法启动这些分析是因为他们没有内部人员来推动这些工作。我确实看到，我们开始看到城市更多地尝试这种方式。彭博是其中之一，费城和波斯顿有一些小团队，他们试图在内部进行真正的实验，并建立这种过程。但这是我们需要建立的东西。

耶雷米(34:29):
我想考虑到城市和政府也有访问非常隐私的数据的潜在特权，隐私在这里成为一个真正的问题。在一个城市、州和国家最终会越来越多地部署这种东西的世界里，你如何看待隐私的演变？

撒拉(34:46):
是啊。再说一次，关于隐私问题，我认为政府确实有很多我们的私人数据。我认为他们实际上有很多，比如说，法律来帮助维护隐私。我认为我们没有相关法律的地方在于这些私营公司拥有的数据。我们签字放弃我们所有的隐私，然后他们可以利用这些数据做很多事情。

萨拉(35:12):
我想大概一年前在《纽约时报》上，他们有一篇关于你可以买到的所有手机数据的文章。你甚至可以知道人们在白宫或五角大楼的什么地方。这是一个很棒的故事，因为你可以从第三方经销商那里买到这些数据。他们没有给我们你的观点本身，或者这是约翰或杰里米。但是你可以很好地跟踪人们。

萨拉(35:42):
这些数据根本没有受到监管。目前还没有隐私法。我认为这是我们没有注意到的巨大差距。对吗？我们总是谈论什么是政府…政府有很多法律，所以他们经常从私营公司购买这些数据集。而且它有严重的隐私问题。

萨拉(36:09):
所以，我认为另一种解释是，我们要求私营公司进行自我监管，但这样做并不符合他们的最佳利益。对吗？当他们的业务建立在我们所有的数据之上时，他们为什么要这样做。另一方面，政府应该进行监管，但他们没有这样做，因为他们可以购买数据，不受监管对他们有利。

萨拉(36:36):
他们还说这推动了商业发展。因此，在这种僵局中，我们对我们的隐私有一些严重的担忧，因为这些团体中没有一个致力于思考这个问题。所以，这就是我真正认为数据中介的角色发挥作用的地方。我认为我们需要有一个团体，组织来帮助制定更多的目标和隐私标准，为隐私法游说。

莎拉(37:08):
以及如何将私人数据用于公共利益。如果政府确实想使用这种非常详细的点，这个数据集，他们能把它聚集到一个你不能识别某人的点，然后它可以更有用吗？因此，我认为这是我们未来将会看到的东西，这种私人组织和政府之间的中介的想法有助于维护数据集的隐私。

耶雷米(37:39):
这是一个非常有意思的想法，尤其是在 2000 年，我不知道我是什么时候加入脸书的，我认为隐私问题会越来越多。2008 年或 2009 年，我泄露了一大堆我的私人信息。当然，2008 年，2009 年大概是 AlexNet 出来的三年前。突然间，我们有了可靠的可以识别人脸的计算机视觉。

耶雷米(38:04):
在我知道机器学习可以从我的数据中提取如此多的见解之前，我就把我的数据给了脸书。所以，这甚至不仅仅是我同意放弃我的数据，这是我含蓄地同意脸书或其他任何人，做任何技术和时间允许的数据。这似乎是普通消费者不喜欢的事情，政府必须更有远见，成为某种中介。在这种情况下，它也开始变得有意义了。

莎拉(38:34):
是的，绝对是。我的意思是，我认为还有一个问题是，技术的发展速度往往超过政府的速度。毫无疑问，关于脸书的听证会是国会议员不了解其运作的基本方式的一个例子。所以，我认为这也是这些中介变得重要的地方。他们正在教育我们的政策制定者他们需要解决的问题。试着以你所说的方式更有前瞻性。

萨拉(39:08):
但这也是为什么我认为当我们处理数据时，我们必须提出自己的道德实践标准，因为在这段时间里，政府不会保护我们，而公司正在尝试新事物。因此，我们需要思考超出我们自身用途的道德规范。因为这是前所未有的新事物。对吗？

耶雷米(39:36):
对于像这样的应用，我提到了面部识别的事情。我的意思是，感觉我们的机器学习能力一直呈指数增长，我觉得我们应该期待他们这样做。我们可能会到达这样一个点，即技术在公司内部开发和最终由政府监管之间的时间差是可能会发生非常糟糕的事情的时间。

耶雷米(40:03):
你认为我们会走向这样一个世界吗？在这个世界里，政府不得不，比如说，制定前瞻性的法规，甚至强制对计算机基础设施进行瓶颈控制，比如让 KYC 了解你的客户之类的法规，强制 AWS 说，“好吧，你想用我们的服务器做什么？那是什么来着？你想用它们做什么？”在他们允许之前？你认为这是我们的长期目标吗？

萨拉(40:31):
是的，我的意思是，我看不到这一点，因为我看到有人说这会阻碍创新。我确实认为我们需要制定更多的，比如说，规章制度，就像我们对，比如说，电力所做的那样。因此，它的使用方式、分发方式或数据分发方式。我肯定地认为，有一套特定的规则需要沿着这些路线制定到位。

莎拉(41:13):
也因为我认为政府绝对必须这样做，因为现在私营公司比他们拥有更多的数据。众所周知，数据就是力量。所以，在某种程度上，这些机构正在成为许多领域的管理机构，对吗？因为他们树立了实践的标准。制定实践标准的不是政府。所以，我确实认为这种，这可能是你想说的，就像，制定一些实践标准，政府说要在这个国家运作，你至少需要遵守这些道德标准。我认为这对于确保公众安全至关重要。

莎拉(42:03):
真的是因为当私营公司真的在运营一切的时候，我不知道你是否…当谷歌宕机发生的时候，我这周在网上。我不知道你是否在线。

耶雷米(42:17):
是的，我想知道是不是……所以，我用超人作为我的电子邮件，很抱歉让大家听到。我讨厌成为另一个超人。但是我的超人倒下了。我想弄清楚到底发生了什么。然后我去了 Gmail，我说，“哦，Gmail 坏了。哦，我的上帝。”后来就严重了。

撒拉(42:33):
对吗？我的意思是，他们运行我们的基础设施，这就像这些垄断，这真的很可怕。我在非洲做了很多工作，最疯狂的是，那天早上我们在内罗毕接到一个电话。我们实际上正在内罗毕建设基于社区的无线基础设施。但是我们整个团队都被封锁了，因为谷歌在非洲操作许多交换机。

撒拉(42:57):
因此，欧洲大陆的许多地方陷入黑暗。我的意思是，我们也陷入黑暗，但它让你意识到它们是我们日常基础设施的一部分，是政府过去运营的东西。我的意思是，政府从来没有运行互联网，但同样的方式，我们有其他类似的道路等等。这就是为什么我觉得它在那方面很像电。这是公益事业。我们每天都依赖电力。我们依赖互联网。这是一项公益事业。我们需要它来维持我们目前的生活。

莎拉(43:37):
所以，我认为采取更多的措施来保护我们是绝对重要的。

耶雷米(43:49):
好吧，希望我们能解决这些问题。我相信，当它到来的时候，你也会成为这一努力的重要组成部分。

撒拉(43:53):
是啊。我的意思是，我认为这就是我们现在看到这些垄断案件出现的原因。对吗？

耶雷米(44:00):
耶。这也很有趣，因为现在有很多关于什么是垄断的问题？当你看着亚马逊，他们会说，“哦，我们在所有这些不同的领域只有 40%的市场份额。”但是你看起来像，是的，它是所有这些不同的区域。我的意思是，你可以在一个地区降价到另一个地区。因此，无论如何，你必须重新定义垄断的潜在含义。

撒拉(44:23):
是的。是啊，基本上。

耶雷米(44:23):
好的，谢谢你全面的谈话。我想没有什么话题是我们没有触及的。如果有人对你们感兴趣，我想再次推荐这本书，顺便说一下，各位，这是《数据行动:利用数据造福公众》。这是这本书的名字。但是你能分享你的推特账号或者其他网站吗？

莎拉(44:43):
是的，当然。你可以在 data see 找到我，所以 data see，我的首字母。但也是缝纫吧，我猜。看看 civicdatadesignlab@mit.edu 的市民数据设计实验室网站。

耶雷米(44:59):
真棒。莎拉，非常感谢。真的很感激。

萨拉(45:03):
是啊。非常感谢邀请我。很高兴和你聊天。