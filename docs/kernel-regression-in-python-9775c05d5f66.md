# Python ä¸­çš„å†…æ ¸å›å½’

> åŸæ–‡ï¼š<https://towardsdatascience.com/kernel-regression-in-python-9775c05d5f66?source=collection_archive---------10----------------------->

## å¦‚ä½•åœ¨ Python ä¸­æ‰‹å·¥è¿›è¡Œå†…æ ¸å›å½’

# ç›®å½•

[1 åŸºäºç»Ÿè®¡æ¨¡å‹çš„æ ¸å›å½’](http://localhost:8888/notebooks/personal_data_science_projects/Kernel_regression_example/kernel_regression_by_hand.ipynb#Kernal-Regression-by-Statsmodels)

*   [1.1 ç”Ÿæˆå‡æ•°æ®](http://localhost:8888/notebooks/personal_data_science_projects/Kernel_regression_example/kernel_regression_by_hand.ipynb#Generating-Fake-Data)
*   [1.2 å†…æ ¸å›å½’è¾“å‡º](http://localhost:8888/notebooks/personal_data_science_projects/Kernel_regression_example/kernel_regression_by_hand.ipynb#Output-of-Kernal-Regression)

[2 ç”¨ Python æ‰‹å·¥å›å½’å†…æ ¸](http://localhost:8888/notebooks/personal_data_science_projects/Kernel_regression_example/kernel_regression_by_hand.ipynb#Kernel-regression-by-Hand-in-Python)

*   [2.0.1 æ­¥éª¤ 1:è®¡ç®—å•ä¸ªè¾“å…¥ x ç‚¹çš„æ ¸](http://localhost:8888/notebooks/personal_data_science_projects/Kernel_regression_example/kernel_regression_by_hand.ipynb#Step-1:-Calculate-the-Kernel-for-a-single-input-x-point)
*   [2.0.2 å¯è§†åŒ–æ‰€æœ‰è¾“å…¥ x ç‚¹çš„å†…æ ¸](http://localhost:8888/notebooks/personal_data_science_projects/Kernel_regression_example/kernel_regression_by_hand.ipynb#Visualizing-the-Kernels-for-all-the-input-x-points)
*   [2.0.3 æ­¥éª¤ 2:è®¡ç®—æ¯ä¸ªè¾“å…¥ x å€¼çš„æƒé‡](http://localhost:8888/notebooks/personal_data_science_projects/Kernel_regression_example/kernel_regression_by_hand.ipynb#Step-2:-Calculate-the-weights-for-each-input-x-value)
*   [2.0.4 æ­¥éª¤ 3:è®¡ç®—å•ä¸ªè¾“å…¥ç‚¹çš„ y é¢„æµ‹å€¼](http://localhost:8888/notebooks/personal_data_science_projects/Kernel_regression_example/kernel_regression_by_hand.ipynb#Step-3:-Calcuate-the-y-pred-value-for-a-single-input-point)
*   [2.0.5 æ­¥éª¤ 4:è®¡ç®—æ‰€æœ‰è¾“å…¥ç‚¹çš„ y é¢„æµ‹å€¼](http://localhost:8888/notebooks/personal_data_science_projects/Kernel_regression_example/kernel_regression_by_hand.ipynb#Step-4:-Calcuate-the-y-pred-values-for-all-the-input-points)
*   [2.0.6 ç¬¬äº”æ­¥:æƒ³è±¡ä¸¤ç§æ–¹æ³•çš„åŒºåˆ«](http://localhost:8888/notebooks/personal_data_science_projects/Kernel_regression_example/kernel_regression_by_hand.ipynb#Step-5:--Visualize-the-difference-between-the-two-methods)

[3 ç»“è®º](http://localhost:8888/notebooks/personal_data_science_projects/Kernel_regression_example/kernel_regression_by_hand.ipynb#Conclusion)

[4 å‚è€ƒæ–‡çŒ®](http://localhost:8888/notebooks/personal_data_science_projects/Kernel_regression_example/kernel_regression_by_hand.ipynb#References)

æœ¬ç¬”è®°æ¼”ç¤ºäº†å¦‚ä½•åœ¨ python ä¸­æ‰‹åŠ¨æ‰§è¡Œå†…æ ¸å›å½’ã€‚è™½ç„¶ Statsmodels ä¸ºå†…æ ¸å›å½’æä¾›äº†ä¸€ä¸ªåº“ï¼Œä½†æ˜¯æ‰‹å·¥è¿›è¡Œå†…æ ¸å›å½’å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£æˆ‘ä»¬æ˜¯å¦‚ä½•å¾—åˆ° find ç»“æœçš„ã€‚

é¦–å…ˆï¼Œæˆ‘å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ Statsmodels å®Œæˆå†…æ ¸å›å½’ã€‚æ¥ä¸‹æ¥æˆ‘å°†å±•ç¤ºå¦‚ä½•æ‰‹å·¥å®Œæˆï¼Œç„¶åæœ€åå åŠ ä¸¤ä¸ªå›¾ä»¥æ˜¾ç¤ºç»“æœæ˜¯ç›¸åŒçš„ã€‚

é¦–å…ˆï¼Œè®©æˆ‘ä»¬é€šè¿‡ç»Ÿè®¡æ¨¡å‹æ¥çœ‹çœ‹å†…æ ¸å›å½’

# 1 ç»Ÿè®¡æ¨¡å‹çš„æ ¸å¿ƒå›å½’

æˆ‘ä»¬é€šè¿‡ä½¿ç”¨ lambda å‡½æ•°æ¥ç”Ÿæˆ y å€¼ã€‚ä½ å¯ä»¥æ”¹å˜ lambda å‡½æ•°ï¼Œçœ‹çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆã€‚x å€¼ï¼Œå³ç‹¬ç«‹å˜é‡ï¼Œç”±`new_x`æ§åˆ¶ï¼Œæˆ‘ä»¬å·²ç»æ›¿æ¢äº† x å€¼ï¼Œä»¥æ˜¾ç¤ºæ‚¨å¯ä»¥

# 1.1 ç”Ÿæˆè™šå‡æ•°æ®

```
 import numpy as np
import plotly.express as px
from statsmodels.nonparametric.kernel_regression
import KernelReg as kr 
import plotly.graph_objs as go
import pandas as pd 
```

# 1.1 ç”Ÿæˆè™šå‡æ•°æ®

```
np.random.seed(1)# xwidth controls the range of x values.
xwidth = 20
x = np.arange(0,xwidth,1)# we want to add some noise to the x values so that dont sit at regular intervals
x_residuals = np.random.normal(scale=0.2, size=[x.shape[0]])# new_x is the range of x values we will be using all the way through
new_x = x + x_residuals# We generate residuals for y values since we want to show some variation in the data
num_points = x.shape[0]
residuals = np.random.normal(scale=2.0, size=[num_points])# We will be using fun_y to generate y values all the way through
fun_y = lambda x: -(x*x) + residuals
```

è®©æˆ‘ä»¬ç»˜åˆ¶æ•°æ®ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Plotly express è¿›è¡Œæ‰€æœ‰çš„ç»˜å›¾ã€‚

```
# Plot the x and y values 
px.scatter(x=new_x,y=fun_y(new_x), title='Figure 1:  Visualizing the generated data')
```

![](img/18035560c15a95eec4fcaa45cec30d33.png)

æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä½¿ç”¨å›å½’æ‹Ÿåˆä¸Šè¿°æ•°æ®ç‚¹çš„æ›²çº¿ã€‚æˆ‘ä»¬è¯¥å¦‚ä½•ç€æ‰‹å‘¢ï¼Ÿä½¿ç”¨ statsmodels ç›¸å½“ç®€å•ã€‚

# 1.2 å†…æ ¸å›å½’çš„è¾“å‡º

Statsmodels éå‚æ•°å›å½’æ¨¡å—å†…æ ¸å›å½’çš„è¾“å‡ºæ˜¯ä¸¤ä¸ªæ•°ç»„ã€‚

1)é¢„æµ‹çš„ y å€¼
2)è¾¹é™…æ•ˆåº”

å¯¹äºå•å˜é‡å›å½’é—®é¢˜ï¼Œè¾¹é™…æ•ˆåº”æœ¬è´¨ä¸Šæ˜¯é¢„æµ‹å€¼å¯¹ç‹¬ç«‹å˜é‡çš„ä¸€é˜¶å¯¼æ•°ã€‚æ›´å¤šå…³äºè¾¹é™…æ•ˆåº”çš„ä¿¡æ¯å¯ä»¥åœ¨[è¿™é‡Œ](https://www.aptech.com/blog/marginal-effects-of-linear-models-with-data-transformations/)æ‰¾åˆ°ã€‚

```
fig = px.scatter(x=new_x,y=fun_y(new_x),  title='Figure 2: Statsmodels fit to generated data')
fig.add_trace(go.Scatter(x=new_x, y=pred_y, name='Statsmodels fit',  mode='lines'))
```

![](img/13f86e4e8c49dc1554eb70e5b11cb036.png)

# 2 Python ä¸­çš„æ‰‹å·¥å†…æ ¸å›å½’

è¦æ‰‹å·¥è¿›è¡Œå†…æ ¸å›å½’ï¼Œæˆ‘ä»¬éœ€è¦äº†è§£ä¸€äº›äº‹æƒ…ã€‚é¦–å…ˆï¼Œè¿™é‡Œæ˜¯å†…æ ¸çš„ä¸€äº›å±æ€§ã€‚

1)å†…æ ¸æ˜¯å¯¹ç§°çš„ï¼Œå³

K(x) = K(-x)

2)æ ¸å‡½æ•°ä¸‹çš„é¢ç§¯ç­‰äº 1 çš„æ„ä¹‰

![](img/9568d97e9e9c21de2cc5b6dfc74d1fa2.png)

æˆ‘ä»¬å°†ä½¿ç”¨é«˜æ–¯æ ¸æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚é«˜æ–¯æ ¸å…·æœ‰ä»¥ä¸‹å½¢å¼:

![](img/b0e97141e1edf389057cdfef95fb6507.png)

å…¶ä¸­ b æ˜¯å¸¦å®½ï¼Œxi æ˜¯å› å˜é‡çš„ç‚¹ï¼Œğ‘¥x æ˜¯æˆ‘ä»¬å®šä¹‰æ ¸å‡½æ•°çš„å€¼çš„èŒƒå›´ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œğ‘¥ğ‘–æ¥è‡ª`new_x`

## 2.0.1 æ­¥éª¤ 1:è®¡ç®—å•ä¸ªè¾“å…¥ x ç‚¹çš„å†…æ ¸

```
kernel_x = np.arange(-xwidth,xwidth, 0.1)
bw_manual = 1def gauss_const(h):
    """
    Returns the normalization constant for a gaussian
    """
    return 1/(h*np.sqrt(np.pi*2))def gauss_exp(ker_x, xi, h): 
    """
    Returns the gaussian function exponent term
    """
    num =  - 0.5*np.square((xi- ker_x))
    den = h*h
    return num/dendef kernel_function(h, ker_x, xi): 
    """
    Returns the gaussian function value. Combines the gauss_const and
    gauss_exp to get this result
    """
    const = gauss_const(h)
    gauss_val = const*np.exp(gauss_exp(ker_x,xi,h))
    return gauss_val# We are selecting a single point and calculating the Kernel value
input_x = new_x[0]
col1 = gauss_const(bw_manual)
col2= gauss_exp(kernel_x, input_x, bw_manual)
col3 = kernel_function(bw_manual, kernel_x, input_x)
```

æˆ‘ä»¬å¸Œæœ›æ˜¾ç¤ºå•ç‚¹ xi çš„æ•°æ®å¸§ã€‚

```
# Dataframe for a single observation point x_i. In the code x_i comes from new_x
data = {'Input_x': [input_x for x in range(col2.shape[0])],
        'kernel_x': kernel_x,
        'gaussian_const': [col1 for x in range(col2.shape[0])],
        'gaussian_exp': col2,
        'full_gaussian_value': col3,
        'bw':[bw_manual for x in range(col2.shape[0])],
        }
single_pt_KE = pd.DataFrame(data=data)
single_pt_KE
```

![](img/167f666fa4f45cc308e01f4c84c450d9.png)

æˆ‘ä»¬è¿˜æƒ³å¯è§†åŒ–ä¸€ä¸ªå•ä¸€çš„å†…æ ¸å‡½æ•°ã€‚

```
# Plotting a scatter plot of Kernel 
px.line(x=kernel_x, y=col3, title='Figure 3: Kernel function for a single input value')
```

![](img/e598f05d9db0b89500aaf9f99a7a5004.png)

## 2.0.2 å¯è§†åŒ–æ‰€æœ‰è¾“å…¥ x ç‚¹çš„å†…æ ¸

æˆ‘ä»¬å¸Œæœ›å¯è§†åŒ–æ¯ä¸ªğ‘¥ğ‘–xi.çš„å†…æ ¸ğ¾(ğ‘¥)K(x)ä¸‹é¢æˆ‘ä»¬è®¡ç®—å†…æ ¸å‡½æ•°å€¼ï¼Œå¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨ä¸€ä¸ªåä¸º`kernel_fns`çš„å­—å…¸ä¸­ï¼Œè¯¥å­—å…¸è¢«è½¬æ¢æˆä¸€ä¸ªæ•°æ®å¸§`kernels_df`ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ Plotly express æ¥ç»˜åˆ¶æ¯ä¸ªæ ¸å‡½æ•°ã€‚

```
## Plotting gaussian for all input x points 
kernel_fns = {'kernel_x': kernel_x}
for input_x in new_x: 
    input_string= 'x_value_{}'.format(np.round(input_x,2)) 
    kernel_fns[input_string] = kernel_function(bw_manual, kernel_x, input_x)kernels_df = pd.DataFrame(data=kernel_fns)y_all = kernels_df.drop(columns='kernel_x')
px.line(kernels_df, x='kernel_x', y=y_all.columns, title='Gaussian for all input points', range_x=[-5,20])
```

![](img/23ff36eb699bfaf913f8e5956196e5d5.png)

## 2.0.3 æ­¥éª¤ 2:è®¡ç®—æ¯ä¸ªè¾“å…¥ x å€¼çš„æƒé‡

æˆ‘ä»¬éœ€è¦è®¡ç®—å•ä¸ªè¾“å…¥çš„æƒé‡ã€‚ä½¿ç”¨ä»¥ä¸‹è¡¨è¾¾å¼è®¡ç®—é‡é‡:

![](img/4cae211a93acd392963f7f0c85395450.png)

ä¸Šé¢çš„ç­‰å¼ä»£è¡¨äº†`new_x`çš„ğ‘–ğ‘¡â„ith å…ƒç´ çš„æƒé‡ï¼Œå…¶ä¸­ğ‘¥x æ˜¯`new_x`çš„æ‰€æœ‰å…ƒç´ ã€‚åˆ†æ¯æ˜¯`new_x`ä¸­æ‰€æœ‰ç‚¹çš„æ€»å’Œã€‚è¿™é‡Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ‚¨å°†ä½¿ç”¨æ‰€æœ‰è¾“å…¥ç‚¹çš„æ ¸æ¥è®¡ç®—æƒé‡ã€‚ä¸Šé¢çš„ç­‰å¼åŸºæœ¬ä¸Šåœ¨ 0 å’Œ 1 ä¹‹é—´è°ƒæ•´æƒé‡ã€‚

ä¸Šé¢çš„ç­‰å¼å·²ç»åœ¨å‡½æ•°`weights`ä¸­å®ç°ï¼Œè¯¥å‡½æ•°ç»™å‡ºäº†å•ä¸ªè¾“å…¥ç‚¹çš„æƒé‡ã€‚ã€‚è¯¥å‡½æ•°é‡‡ç”¨å•ä¸ªè¾“å…¥ç‚¹ï¼Œå¹¶ç»™å‡ºä¸€è¡Œæƒé‡ã€‚å®ƒé€šè¿‡åœ¨å®ç°ä¸Šè¿°ç­‰å¼çš„åŒæ—¶å¾ªç¯éå†æ‰€æœ‰è¾“å…¥ç‚¹æ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚

## 2.0.4 æ­¥éª¤ 3:è®¡ç®—å•ä¸ªè¾“å…¥ç‚¹çš„ y é¢„æµ‹å€¼

æˆ‘ä»¬ä»ä¸‹å¼å¾—åˆ°ğ‘–ğ‘¡â„ith ç‚¹çš„é¢„æµ‹å€¼:

![](img/88dddff6294c03b971c84a8f352cf23b.png)

è¯¥ç­‰å¼åœ¨å‡½æ•°`single_y_pred`ä¸­å®ç°ã€‚æˆ‘ä»¬å¯¹ä»`weights`å‡½æ•°ä¸­å¾—åˆ°çš„æƒé‡è¡Œå’Œæ¥è‡ªå‡æ•°æ®çš„ y å€¼è¿›è¡Œç‚¹ç§¯ã€‚ä¸Šé¢çš„ç­‰å¼è¡¨ç¤ºç‚¹ç§¯ã€‚

```
def weights(bw_manual, input_x, all_input_values ): 
    w_row = []
    for x_i in all_input_values: 
        ki = kernel_function(bw_manual, x_i, input_x)
        ki_sum = np.sum(kernel_function(bw_manual, all_input_values, input_x))
        w_row.append(ki/ki_sum)
    return w_rowdef single_y_pred(bw_manual, input_x, new_x): 
    w = weights(bw_manual, input_x, new_x)
    y_single = np.sum(np.dot(fun_y(new_x),w))
    return y_singleypred_single = single_y_pred(bw_manual, new_x[0], new_x)
```

## 2.0.5 æ­¥éª¤ 4:è®¡ç®—æ‰€æœ‰è¾“å…¥ç‚¹çš„ y é¢„æµ‹å€¼

ä»¥ä¸‹ä»£ç åœ¨æ‰€æœ‰è¾“å…¥ç‚¹ä¸Šå¾ªç¯ï¼Œè®¡ç®—é¢„æµ‹å€¼å¹¶å°†å…¶é™„åŠ åˆ°`Y_pred`ã€‚ä¸€æ—¦æˆ‘ä»¬æœ‰äº†é¢„æµ‹å€¼ï¼Œæˆ‘ä»¬ç°åœ¨éœ€è¦åšçš„å°±æ˜¯å°†å®ƒä»¬å¯è§†åŒ–ã€‚

```
Y_pred = []
for input_x in new_x: 
    w = []
    Y_single = single_y_pred(bw_manual, input_x, new_x)
    Y_pred.append(Y_single)
```

## 2.0.6 æ­¥éª¤ 5:æƒ³è±¡ä¸¤ç§æ–¹æ³•ä¹‹é—´çš„åŒºåˆ«

ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»é€šè¿‡æ‰‹åŠ¨è®¡ç®—é¢„æµ‹å€¼è·å¾—äº†é¢„æµ‹å€¼ï¼Œæˆ‘ä»¬å¯ä»¥å°†æˆ‘ä»¬çš„å›å½’æ›²çº¿ä¸ä» statsmodels è·å¾—çš„æ›²çº¿è¿›è¡Œæ¯”è¾ƒã€‚æˆ‘ä»¬å°†åˆèº«çš„è¡£æœé‡å åœ¨å½¼æ­¤çš„ä¸Šé¢ï¼Œå¹¶ä¸”åˆèº«åˆ°å®ƒä»¬å®Œå…¨åŒ¹é…ã€‚

```
data= {'x': new_x, 'y': fun_y(new_x), 'y_manual': np.array(y_all)}
fig = px.scatter(x=new_x,y=fun_y(x))
fig.add_trace(go.Scatter(x=new_x, y=pred_y, name='Statsmodel KR',  mode='lines'))
fig.add_trace(go.Scatter(x=new_x, y=np.array(Y_pred), name='Manual KR',  mode='lines'))
```

![](img/94bb1c6055e4f4e6450db61fd7e49630.png)

# 3 ç»“è®º

æœ¬æ–‡é€šè¿‡ä¸€ä¸ªä½¿ç”¨ç”Ÿæˆæ•°æ®çš„ç®€å•ç¤ºä¾‹ï¼Œå±•ç¤ºäº†æˆ‘ä»¬å¦‚ä½•ç†è§£å†…æ ¸å›å½’ç®—æ³•çš„å†…éƒ¨å·¥ä½œæ–¹å¼ã€‚å¦‚æœä½ ä»è¿™ç¯‡æ–‡ç« ä¸­å­¦åˆ°äº†ä»€ä¹ˆï¼Œè¯·å–œæ¬¢å¹¶åˆ†äº«è¿™ç¯‡æ–‡ç« ã€‚

æ„Ÿè°¢æ‚¨çš„é˜…è¯»ï¼

# 4 å‚è€ƒæ–‡çŒ®

*   [https://www . stat . CMU . edu/~ ryantibs/adv methods/notes/kernel . pdf](https://www.stat.cmu.edu/~ryantibs/advmethods/notes/kernel.pdf)
*   [https://mccormickml.com/2014/02/26/kernel-regression/](https://mccormickml.com/2014/02/26/kernel-regression/)
*   [http://faculty . Washington . edu/yen chic/18W _ 425/le C9 _ reg 01 . pdf](http://faculty.washington.edu/yenchic/18W_425/Lec9_Reg01.pdf)