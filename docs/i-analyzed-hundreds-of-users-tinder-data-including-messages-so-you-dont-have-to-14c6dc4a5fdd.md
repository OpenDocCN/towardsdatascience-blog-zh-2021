# æˆ‘åˆ†æäº†æ•°ç™¾åç”¨æˆ·çš„ Tinder æ•°æ®â€”â€”åŒ…æ‹¬æ¶ˆæ¯â€”â€”æ‰€ä»¥ä½ ä¸å¿…è¿™ä¹ˆåšã€‚

> åŸæ–‡ï¼š<https://towardsdatascience.com/i-analyzed-hundreds-of-users-tinder-data-including-messages-so-you-dont-have-to-14c6dc4a5fdd?source=collection_archive---------3----------------------->

## è¿™äº›æ•°æ®æ˜¯ä»¤äººå°´å°¬çš„éšç§ï¼Œä½†æ­ç¤ºäº†æˆ‘ä»¬å·²ç»çŸ¥é“çš„è‡ªå·±æœ€æ— èŠçš„éƒ¨åˆ†ã€‚

![](img/461c4b09f15a553836ef78e3651a7e93.png)

ç±³å¡Â·é²æ¢…æ–¯ç‰¹åœ¨ [Unsplash](https://unsplash.com/s/photos/tinder?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) ä¸Šçš„ç…§ç‰‡

æˆ‘åœ¨ 2016 å¹´è¯»äº†é˜¿é½å…¹Â·å®‰è¨é‡Œçš„ã€ŠT4 ç°ä»£æµªæ¼«å²ã€‹ï¼Œæ¯«æ— ç–‘é—®ï¼Œè¿™æ˜¯æˆ‘è¯»è¿‡çš„æœ€æœ‰å½±å“åŠ›çš„ä¹¦ä¹‹ä¸€ã€‚é‚£æ—¶ï¼Œæˆ‘è¿˜æ˜¯ä¸€ä¸ªé¼»æ¶•æ¨ªæµçš„å¤§å­¦ç”Ÿï¼Œè¿˜åœ¨å’Œé«˜ä¸­åŒå­¦çº¦ä¼šã€‚

è¿™æœ¬ä¹¦ç»™å‡ºçš„å…³äºç½‘ä¸Šçº¦ä¼šæˆåŠŸçš„æ•°å­—å’Œæ•°æ®è®©æˆ‘è§‰å¾—å†·é…·æ— æƒ…ã€‚åƒç¦§ä¸€ä»£å’Œä»–ä»¬çš„å‰è¾ˆéšç€äº’è”ç½‘çš„å‡ºç°è€Œå—åˆ°ç¥ç¦å’Œè¯…å’’ã€‚åœ¨å¯»æ‰¾æˆ‘ä»¬çš„â€œçµé­‚ä¼´ä¾£â€æ—¶ï¼Œä¼´ä¾£é€‰æ‹©çš„æ¿€å¢ä½¿æˆ‘ä»¬å˜å¾—éº»æœ¨ï¼Œå¹¶ç»™äº†æˆ‘ä»¬ä¸åˆ‡å®é™…çš„æœŸæœ›ã€‚

æˆ‘ä¸ä½†æ²¡æœ‰è¢«åŠé˜»ï¼Œåè€Œå—åˆ°äº†é¼“èˆã€‚å‡ ä¸ªæœˆä¹‹å†…æˆ‘å°±å’Œé«˜ä¸­ç”·å‹åˆ†æ‰‹äº†ï¼Œè‡ªå·±ä¹Ÿè¿›å…¥äº†ç½‘æ‹ä¸–ç•Œã€‚æˆ‘å¾ˆå¿«æ„è¯†åˆ°çº¦ä¼šæœ¬èº«å°±å¾ˆç³Ÿç³•ï¼Œå½“å®ƒæ•°å­—åŒ–æ—¶ï¼Œæƒ…å†µå˜å¾—æ›´ç³Ÿã€‚

ç«ç»’ã€‚é‚¦å¸ƒå°”ã€‚é“°é“¾ã€‚CoffeeMeetsBagelã€‚å¦‚æœå®ƒåœ¨ App Store ä¸Šï¼Œé‚£ä¹ˆæˆ‘å¯èƒ½ä¼šä½¿ç”¨å®ƒã€‚å°½ç®¡æˆ‘çš„çº¦ä¼šç»å†å¤§å¤šå¾ˆå¹³æ·¡ï¼Œä½†æˆ‘æ— æ³•æ‘†è„±å¯¹è¿™äº›è¢«ä¸Šå¸é—å¼ƒçš„åº”ç”¨ç¨‹åºçš„è¿·æ‹ã€‚æˆ‘å†³å®šå°†è¿™ç§é­…åŠ›ä½œä¸ºæˆ‘åœ¨å“¥ä¼¦æ¯”äºšå¤§å­¦æ•°æ®æ–°é—»å­¦ Lede é¡¹ç›®çš„æœ€ç»ˆé¡¹ç›®çš„ä¸€éƒ¨åˆ†ã€‚

ä»…ä»…ä½¿ç”¨ Pythonã€Jupyter ç¬”è®°æœ¬å’Œç–¯ç‹‚çš„ç”µå­é‚®ä»¶ï¼Œæˆ‘å°±ç›´æ¥ä½¿ç”¨çº¦ä¼šåº”ç”¨ç¨‹åºæ•°æ®åˆ›å»ºäº†ä¸€ä¸ªé¡¹ç›®ã€‚

# 1.å¯»æ‰¾æ•°æ®

ç°åœ¨æˆ‘å·²ç»æœ‰äº†ä¸€ä¸ªé¡¹ç›®ï¼Œæˆ‘éœ€è¦æ‰¾åˆ°å®é™…çš„æ•°æ®ã€‚è¿™æ˜¯ä¸€ä¸ªå·¨å¤§çš„éšœç¢ã€‚

é¦–å…ˆï¼Œæˆ‘éœ€è¦é€‰æ‹©ä¸€ä¸ªåº”ç”¨ç¨‹åºæ¥å…³æ³¨ã€‚åœ¨ r/dataisbeautiful ä¸Šæµè§ˆäº†å‡ ä¸ªå°æ—¶åï¼Œæˆ‘å†³å®šä½¿ç”¨ Tinderï¼Œå› ä¸ºå®ƒå¾ˆå—æ¬¢è¿ã€‚

æˆ‘ä» Reddit ä¸Šäº†è§£åˆ°ï¼Œé€šè¿‡é˜…è¯»[å…¶ä»–](https://medium.com/r?url=https%3A%2F%2Ftowardsdatascience.com%2Fmy-friends-gave-me-their-tinder-data-7fcd2621c140) [æ–‡ç« ](https://medium.com/swlh/analyzing-my-tinder-data-3b4f05a4a34f)ï¼Œæˆ‘å¯ä»¥è¯·æ±‚æˆ‘è‡ªå·±çš„æ•°æ®ã€‚å‡ å¹´å‰ï¼Œ*å«æŠ¥*å†™äº†ä¸€ç¯‡å…³äº Tinder å¦‚ä½•ä½¿ç”¨ä¸ªäººæ•°æ®çš„æŠ¥é“ã€‚è¯¥å…¬å¸çš„éƒ¨åˆ†å›åº”æ˜¯æ ¹æ®è¦æ±‚æä¾›ç”¨æˆ·æ•°æ®

<https://www.theguardian.com/technology/2017/sep/26/tinder-personal-data-dating-app-messages-hacked-sold>  

ä¼¼ä¹å¾ˆå®¹æ˜“åšåˆ°ï¼Œå¯¹ä¸å¯¹ï¼Ÿé™¤äº†ï¼Œæˆ‘æ²¡æœ‰ä»»ä½•æ•°æ®ä¸‹è½½ã€‚æˆ‘æœ‰ä¸‹è½½ Tinder ä½¿ç”¨å‡ ä¸ªæœˆçš„ä¹ æƒ¯ï¼Œç„¶åå‡ºäºæ²®ä¸§åˆ é™¤æˆ‘çš„è´¦æˆ·ï¼Œç»“æœåªæ˜¯é‡å¤è¿™ä¸ªè¿‡ç¨‹ã€‚

æˆ‘çŸ¥é“æ•°æ®å°±åœ¨é‚£é‡Œï¼Œå°½ç®¡éšœç¢é‡é‡ï¼Œæˆ‘å†³å¿ƒæ‰¾åˆ°å®ƒã€‚åœ¨è°·æ­Œæœç´¢äº†å‡ è½®â€œTinder æ•°æ®â€å´ä¸€æ— æ‰€è·ä¹‹åï¼Œæˆ‘å›åˆ°äº† Redditã€‚æˆ‘åœ¨ r/dataisbeautiful ä¸Šæ³¨æ„åˆ°ï¼Œä¸€äº›äººæ­£åœ¨ä½¿ç”¨ä¸€ä¸ªåä¸º [Swipestats.io](https://swipestats.io/) çš„ç½‘ç«™å¯è§†åŒ–ä»–ä»¬çš„ Tinder æ•°æ®ã€‚

![](img/0f1413f910cbddede171ad83d2b4f942.png)

éšæœºç”·æ€§ç”¨æˆ·çš„ Swipestats.io å¯è§†åŒ–

æˆ‘å†³å®šå°è¯•ä¸€ä¸‹ï¼Œç»™ç½‘ç«™çš„æ‰€æœ‰è€…å‘ä¸€å°ç”µå­é‚®ä»¶ï¼Œè¯¢é—®ä»–æ˜¯å¦å¯ä»¥ä¸ºæˆ‘çš„é¡¹ç›®ä¸æˆ‘åˆ†äº«åŒ¿åçš„ Tinder æ•°æ®ã€‚ä»–åŒæ„äº†(è°¢è°¢ä½ ï¼Œå…‹é‡Œæ–¯)ã€‚

æ¥ä¸‹æ¥ä½ çŸ¥é“ï¼Œæˆ‘ååœ¨ä¸€ä¸ªæœ‰ 556 ä¸ª Tinder ä¸ªäººèµ„æ–™çš„ JSON ä¸Šã€‚

# 2.æ¸…ç†æ•°æ®

è¿™å®Œå…¨æ˜¯ä¸€åœºå™©æ¢¦ã€‚

æˆ‘å·²ç»æµªè´¹äº†ç”Ÿå‘½ä¸­çš„å‡ åä¸ªå°æ—¶ï¼Œä¸ä»…è¯•å›¾ç†è§£è¿™äº›æ•°æ®ï¼Œè¿˜è¯•å›¾æ¸…ç†å®ƒä»¬ã€‚æœ€åï¼Œæˆ‘å’Œä¸€ä¸ªè‡ƒè‚¿çš„ JSON å»ºç«‹äº†ä¸€æ®µéå¸¸å¿ è¯šçš„å…³ç³»ã€‚

æˆ‘é¢ä¸´çš„ç¬¬ä¸€ä¸ªéšœç¢æ˜¯å¦‚ä½•æ‰“å¼€æ–‡ä»¶ã€‚å®ƒå¾ˆå¤§ï¼Œæ¯å½“æˆ‘è¯•å›¾æŠŠå®ƒä¸Šä¼ åˆ°ç¬”è®°æœ¬ç”µè„‘ï¼Œæˆ‘ä¼šå¾—åˆ°ä¸€ä¸ªé”™è¯¯ã€‚æˆ‘å’Œ Lede é¡¹ç›®çš„å¯¼å¸ˆè°ˆè¿‡(è°¢è°¢ä½ ï¼ŒJeff)ï¼Œä»–å»ºè®®é€šè¿‡ JSON lint æ¥è¿è¡Œå®ƒã€‚æˆ‘ä¸çŸ¥é“é‚£æ˜¯ä»€ä¹ˆã€‚

æˆ‘è§‰å¾—æ‰“å¼€ä¸€ä¸ªå¤§ JSON æ˜¯æ²¡æœ‰ç”¨çš„ã€‚äº‹æƒ…çœ‹èµ·æ¥å¾ˆé»¯æ·¡ï¼Œä½†æˆ‘ä¸‹å®šå†³å¿ƒè¦ç”¨ Tinder æ•°æ®åˆ›å»ºä¸€ä¸ªé¡¹ç›®ã€‚

é•¿è¯çŸ­è¯´ï¼Œæˆ‘æŠŠ JSON è½¬æ¢æˆ. txt æ–‡ä»¶ï¼Œç„¶åæŠŠå¤§çš„ã€‚ä½¿ç”¨[è¿™ä¸ªç«™ç‚¹](https://textfilesplitter.com/)æŠŠ txt æ–‡ä»¶å˜æˆæ›´å°çš„æ–‡ä»¶ã€‚ç”±äºæŸç§ç¥çš„å¥‡è¿¹ï¼Œç½‘ç«™åˆ†è£‚äº†ã€‚txt æ–‡ä»¶å®Œç¾åœ°ç”±æ¯ä¸ªäººçš„æ–‡ä»¶ç»„æˆã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘è½¬æ¢äº†æ–°çš„åæ§½ã€‚txt æ–‡ä»¶è½¬æ¢æˆ JSON æ ¼å¼ã€‚ç°åœ¨æˆ‘æœ‰ä¸€ä¸ªåŒ…å« 556 ä¸ª JSONs çš„æ–‡ä»¶å¤¹ã€‚

```
# Loading the data
import jsonf = open(â€œuser_x.jsonâ€, encoding=â€utf-8")
data = json.load(f)
```

æœ€åï¼Œæˆ‘èƒ½å¤Ÿæ‰“å¼€æˆ‘çš„æ•°æ®ã€‚ä»¤æˆ‘æƒŠè®¶çš„æ˜¯ï¼Œæˆ‘æ³¨æ„åˆ°é‚®ä»¶è¢«åŒ…æ‹¬åœ¨å†…ã€‚

![](img/65bf7a2d8a95335e079554d208bf2c99.png)

21 ä¸–çºªçš„æµªæ¼«

æˆ‘çŸ¥é“æˆ‘å¿…é¡»ä¼˜å…ˆè€ƒè™‘ï¼Œå¹¶å†³å®šåªå…³æ³¨ä¸‰ä¸ªä¸åŒçš„å¯¹è±¡ï¼Œ**å¯¹è¯**ã€**å¯¹è¯å…ƒ**å’Œ**ç”¨æˆ·**ã€‚åœ¨æµç¨‹å›¾ä¸­ï¼Œæˆ‘æ¦‚è¿°äº†æ¯ä¸ªå¯¹è±¡ä¸­çš„ä¿¡æ¯ã€‚

![](img/6748cbc035cf0b72abe5526ceba459dd.png)

æˆ‘èƒ½åšçš„äº‹æƒ…æœ‰æ— æ•°ç§å¯èƒ½æ€§ï¼Œä½†æˆ‘ä»ç„¶æ²¡æœ‰æ¸…ç†å®Œæ•°æ®ã€‚ä¸‹ä¸€ä¸ªéšœç¢æ˜¯ç»„ç»‡å®ƒã€‚

æˆ‘çš„ä¸‹ä¸€æ­¥æ˜¯æŒ‰ç…§æ€§åˆ«å’Œè¯­è¨€æ¥ç»„ç»‡æ–‡ä»¶ã€‚æˆ‘è¯»è¿‡çš„å¾ˆå¤šæ–‡ç« éƒ½å–œæ¬¢æ¯”è¾ƒç”·äººå’Œå¥³äººçš„çº¦ä¼šç»å†ï¼Œæ‰€ä»¥æˆ‘æƒ³æ‹¥æœ‰é‚£äº›ç‹¬ç«‹çš„æ•°æ®é›†ã€‚æ­¤å¤–ï¼Œæˆ‘è¿˜æ”¶åˆ°äº†ä¸€å¥—ç›¸å½“å›½é™…åŒ–çš„å¥—è£…ï¼Œä¸Šé¢æ•£å¸ƒç€æ—¥è¯­ã€è¥¿ç­ç‰™è¯­æˆ–å¾·è¯­ç­‰è¯­è¨€ã€‚å°½ç®¡æˆ‘å¾ˆæ¬£èµè¿™ç§å¤šæ ·æ€§ï¼Œä½†æˆ‘åªæƒ³ç”¨è‹±æ–‡èµ„æ–™å·¥ä½œã€‚

æˆ‘ä¸çŸ¥é“ä»å“ªé‡Œå¼€å§‹ç»„ç»‡ï¼Œæ‰€ä»¥æˆ‘å»äº†åŠå…¬æ—¶é—´(è°¢è°¢ä½ ï¼ŒThanasis)ã€‚åœ¨ Gather ä¸Šç»å°½è„‘æ±ä¹‹åï¼Œæˆ‘ä»¬â€”â€”ä¸»è¦æ˜¯ than asisâ€”â€”æ‰¾åˆ°äº†ä¸€ä¸ªè§£å†³æ–¹æ¡ˆã€‚

```
import shutil
import os
import glob
from os import pathall_files = '/directory'
male = "/directory/MALE"
female = "/directory/FEMALE"
files = glob.glob(all_files+"/*.json")
for file in files:
    with open(file, encoding="utf-8") as f:
        data = json.load(f)
        stat = data["user"]
        for stats in stat:
            if stat["gender"] == "M":
                try:
                    shutil.move(os.path.join(all_files, file), male)
                except:
                    pass 
            else:
                try:
                    shutil.move(os.path.join(all_files, file),   female)
                except:
                    pass
```

è¿™æ®µä»£ç åªæ˜¯å°†ä¸€ä¸ª JSON ç§»åŠ¨åˆ°å®ƒå„è‡ªçš„æ–‡ä»¶å¤¹ä¸­ï¼Œä¸ç®¡å®ƒæ˜¯ç”·çš„è¿˜æ˜¯å¥³çš„ã€‚

æˆ‘è¯•å›¾ç”¨ **TextBlob** å’Œ **langdetect å†™ä¸€ä¸ªç±»ä¼¼çš„ä»£ç æ¥åŒºåˆ†è¯­è¨€ã€‚**æ²¡ç”¨ã€‚å‡ºäºçº¯ç²¹çš„æ¶æ„ï¼Œæˆ‘æ ¹æ®è¯­è¨€æ‰‹å·¥åˆ†ç¦»äº†æ–‡ä»¶ã€‚

åˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘æ„Ÿè§‰ç¥å¿—ä¸æ¸…ï¼Œä½†æˆ‘å‡ ä¹ç»“æŸäº†ã€‚æˆ‘çš„æœ€åä¸€æ­¥æ˜¯å°†æ•°æ®ä¿å­˜åˆ°å‹å¥½çš„ CSV ä¸­ï¼Œç»™æˆ‘ç•™ä¸‹å¤§çº¦ 300 ä¸ªè‹±è¯­æ•°æ®ã€‚

## å°†å¯¹è¯ä¿å­˜åˆ° CSV ä¸­:

*æ³¨æ„:*Tinder æ¶ˆæ¯å¸¦æœ‰ HTML æ ‡ç­¾ã€‚æˆ‘åœ¨ä¸‹é¢åŒ…å«äº†åˆ é™¤å®ƒä»¬çš„ä»£ç ã€‚

```
all_files = '/GENDER/ENGLISH'
files = glob.glob(all_files+"/*.json")# HTML parser code
from io import StringIO
from html.parser import HTMLParserclass MLStripper(HTMLParser):
    def __init__(self):
        super().__init__()
        self.reset()
        self.strict = False
        self.convert_charrefs= True
        self.text = StringIO()
    def handle_data(self, d):
        self.text.write(d)
    def get_data(self):
        return self.text.getvalue()def strip_tags(html):
    s = MLStripper()
    s.feed(html)
    return s.get_data()for file in files:
    with open(file, encoding="utf-8") as q:
        data = json.load(q)
        all_convo = data["conversations"]
        text = []
        for message in all_convo: 
            for messages in message["messages"]:
                messages["final_messages"] = ""
                updated = messages["message"]
                messages["final_messages"] = strip_tags(updated)
                text.append(messages)

        with open('GENDER_convos.csv', 'a') as csvfile:
            field_names = ['to', 'from', 'message', 'sent_date', 'final_messages']
            writer = csv.DictWriter(csvfile, fieldnames=field_names, extrasaction='ignore')
            writer.writeheader()
            writer.writerows(text)
```

## å°†å¯¹è¯å…ƒä¿å­˜åˆ° CSV ä¸­:

```
for file in files:
    with open(file, encoding="utf-8") as q:
        data = json.load(q)
        user_data = []
        user_data.append(data["conversationsMeta"])
        field_names = ['nrOfConversations', 'longestConversation', 'longestConversationInDays', 
                       'averageConversationLength', 'averageConversationLengthInDays', 
                       'medianConversationLength', 'medianConversationLengthInDays', 
                       'nrOfOneMessageConversations', 'percentOfOneMessageConversations', 
                       'nrOfGhostingsAfterInitialMessage']
        with open('GENDER_convometa.csv', 'a') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=field_names)
            writer.writeheader()
            writer.writerows(user_data)
```

## å°†ç”¨æˆ·å…ƒæ•°æ®ä¿å­˜åˆ° CSV ä¸­:

```
for file in files:
    with open(file, encoding="utf-8") as q:
        data = json.load(q)
        user_data = []
        md = data["user"]
        for job in md['jobs']:
            if job['title'] == None:
                pass
            else: 
                md['jobs'] = job['title']
        try:         
            for school in md['schools']:
                if school['name'] == None:
                    pass        
                else: 
                    md['schools'] = school['name']  
        except:
            pass
        user_data.append(md)
        field_names = ['birthDate', 'ageFilterMin', 'ageFilterMax', 'cityName', 'country', 'createDate', 
                    'education', 'gender', 'interestedIn', 'genderFilter', 'instagram', 'spotify', 'jobs', 
                    'educationLevel', 'schools']
        with open('GENDER_md.csv', 'a') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=field_names)
            writer.writeheader()
            writer.writerows(user_data)
```

æ•°æ®æ›¾ç»è¢«å®Œå…¨æ¸…ç†è¿‡å—ï¼Ÿä¸ã€‚è¿™æ˜¯ä¸€ä¸ªæ— æ­¢å¢ƒçš„ä»»åŠ¡ã€‚

# 3.åˆ†ææ•°æ®

åœ¨ä½ å˜å¾—å¤ªå…´å¥‹ä¹‹å‰ï¼Œæˆ‘éœ€è¦æ‰¿è®¤æˆ‘å‘ç°çš„æ‰€æœ‰ä¸œè¥¿éƒ½æœ‰ç‚¹æ— èŠã€‚æˆ‘èŠ±äº†å¤§éƒ¨åˆ†æ—¶é—´æ¸…ç†æ•°æ®ï¼Œæ‰€ä»¥è¿™ä¸€éƒ¨åˆ†æœ‰ç‚¹æ¯ç‡¥ï¼Œç‰¹åˆ«æ˜¯è€ƒè™‘åˆ°æˆ‘æ˜¯åœ¨æ™šä¸Š 10:54 å†™çš„è¿™ç¯‡æ–‡ç« ï¼Œæˆ‘åº”è¯¥åœ¨æ˜å¤©æ—©ä¸Š 9:00 æäº¤ã€‚

ä½ ç”Ÿæ´»å’Œå­¦ä¹ ã€‚

æˆ‘æ ¹æ®ä¹‹å‰åšçš„ä¸‰ä¸ª CSV åšäº†ä¸€ä¸ªåˆ†æã€‚æé†’ä¸€ä¸‹ï¼Œå®ƒä»¬æ¯ä¸ªéƒ½åŒ…å«**å¯¹è¯**ã€**å¯¹è¯å…ƒ**å’Œ**ç”¨æˆ·**å…ƒæ•°æ®ã€‚ä»£ç å¯åœ¨[è¿™é‡Œ](https://github.com/alyssafrndz/lede_final_project)è·å¾—ã€‚

> S *ide æ³¨:æˆ‘æ˜¯ä»* [*æ•°æ®é©±åŠ¨*](https://data-dive.com/tinder-statistics-insights-from-unique-dataset) *åˆ†æåƒµå°¸å·¥å…·åˆ¶ä½œçš„ Tinder æ•°æ®å¼€å§‹ï¼Œå—è¿™ç¯‡æ–‡ç« *å½±å“å¾ˆå¤§ã€‚é‚£ç¯‡æ–‡ç« æ›´æ·±å…¥ï¼Œå¹¶ä¸”ä½¿ç”¨äº†æ›´ç®€æ´çš„ä»£ç ã€‚

## a)åˆ†æå¯¹è¯

è¿™å¯ä»¥è¯´æ˜¯æ‰€æœ‰æ•°æ®é›†ä¸­æœ€ä¹å‘³çš„ï¼Œå› ä¸ºå®ƒåŒ…å«äº† 50 ä¸‡æ¡ Tinder æ¶ˆæ¯ã€‚ä¸è¶³ä¹‹å¤„æ˜¯ï¼ŒTinder åªå­˜å‚¨å‘é€çš„å’Œæœªæ¥æ”¶çš„æ¶ˆæ¯ã€‚

æˆ‘å¯¹å¯¹è¯åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯åˆ›å»ºä¸€ä¸ªè¯­è¨€æ¨¡å‹æ¥æ£€æµ‹è°ƒæƒ…ã€‚æœ€ç»ˆäº§å“å……å…¶é‡æ˜¯åˆæ­¥çš„ï¼Œå¯ä»¥åœ¨è¿™é‡Œé˜…è¯»ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘åšçš„ç¬¬ä¸€ä¸ªåˆ†ææ˜¯å‘ç°ç”¨æˆ·ä¸­æœ€å¸¸ç”¨çš„å•è¯å’Œè¡¨æƒ…ç¬¦å·æ˜¯ä»€ä¹ˆã€‚ä¸ºäº†é¿å…æˆ‘çš„ç”µè„‘å´©æºƒï¼Œæˆ‘åªç”¨äº† 20 ä¸‡æ¡ä¿¡æ¯ï¼Œè€Œä¸”ç”·å¥³æ··åˆã€‚

é‚£ä¹ˆåå¤§å•è¯æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ

![](img/dba407df5a0d1f13772fcc566f15f700.png)

ã€Šç”·å¥³ä¹‹é—´çš„ç«ç»’ã€‹ä¸­ä½¿ç”¨çš„åå¤§è¯æ±‡

å¼•äººå…¥èƒœã€‚

ä¸ºäº†è®©å®ƒæ›´ä»¤äººå…´å¥‹ï¼Œæˆ‘å€Ÿé‰´äº† Data Dive çš„åšæ³•ï¼Œåœ¨è¿‡æ»¤æ‰åœç”¨è¯åï¼Œåˆ¶ä½œäº†ä¸€ä¸ªæ ‡å¿—æ€§çš„ Tinder flame å½¢çŠ¶çš„è¯äº‘ã€‚

![](img/f064322191c3f60fb82f3eabb995a970.png)

ã€Šç”·å¥³ç«ç»’ã€‹500 å¤§çƒ­é—¨è¯æ±‡äº‘

æ˜¯å•Šæ˜¯å•Šã€‚æ–‡å­—æ˜¯ä¼Ÿå¤§çš„â€”â€”ä½†æ˜¯è¡¨æƒ…ç¬¦å·å‘¢ï¼Ÿ

![](img/583dbaf50d429e3ac8a1da79f51ed91b.png)

ç”·å¥³ç«ç»’ä¸­ä½¿ç”¨çš„åå¤§è¡¨æƒ…ç¬¦å·

æœ‰è¶£çš„äº‹å®:æˆ‘æœ€è®¨åŒçš„æ˜¯å“­ç¬‘è¡¨æƒ…ç¬¦å·ï¼Œç®€ç§°:joyã€‚æˆ‘éå¸¸ä¸å–œæ¬¢å®ƒï¼Œç”šè‡³ä¸ä¼šåœ¨æœ¬æ–‡ä¸­å°†å®ƒå±•ç¤ºåœ¨å›¾è¡¨ä¹‹å¤–ã€‚æˆ‘æŠ•ç¥¨å†³å®šç«‹å³å¹¶æ— é™æœŸåœ°æ’¤é”€å®ƒã€‚

è¿™äº›ç»“æœåœ¨å¤šå¤§ç¨‹åº¦ä¸Šå› æ€§åˆ«è€Œå¼‚ï¼Ÿ

![](img/e035bac2a05e848e7d9f79b34a43370c.png)

çœ‹æ¥â€œå–œæ¬¢â€ä¾ç„¶æ˜¯ä¸¤æ€§ä¸­çš„å‹’å®å† å†›ã€‚è™½ç„¶ï¼Œæˆ‘è§‰å¾—å¾ˆæœ‰æ„æ€çš„æ˜¯â€œå˜¿â€æ€ä¹ˆä¼šå‡ºç°åœ¨ç”·æ€§çš„å‰ååé‡Œï¼Œè€Œä¸æ˜¯å¥³æ€§ã€‚ä¼šä¸ä¼šæ˜¯å› ä¸ºç”·äººåº”è¯¥ä¸»åŠ¨å‘èµ·å¯¹è¯ï¼Ÿå¯èƒ½å§ã€‚

è¡¨æƒ…ç¬¦å·å¯¹æ¯”å‘¢ï¼Ÿ

![](img/697d865ddbc4da2458c2dc0c8d380810.png)

ä¼¼ä¹å¥³æ€§ç”¨æˆ·ä½¿ç”¨æ›´è°ƒæƒ…çš„è¡¨æƒ…ç¬¦å·(ğŸ˜,ğŸ˜˜)æ¯”ç”·æ€§ç”¨æˆ·å¤šã€‚å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä»ç„¶æ„Ÿåˆ°ä¸å®‰ï¼Œä½†å¹¶ä¸æ„Ÿåˆ°æƒŠè®¶:ã€Šæ¬¢ä¹:è¶…è¶Šæ€§åˆ«ã€‹åœ¨è¡¨æƒ…ç¬¦å·æ’è¡Œæ¦œä¸Šå æ®ä¸»å¯¼åœ°ä½ã€‚

## b)åˆ†æå¯¹è¯å…ƒ

è¿™éƒ¨åˆ†æ˜¯æœ€ç›´æ¥çš„ï¼Œä½†ä¹Ÿå¯èƒ½æ˜¯æœ€è´¹åŠ›çš„ã€‚ç°åœ¨ï¼Œæˆ‘ç”¨å®ƒæ¥å¯»æ‰¾å¹³å‡å€¼ã€‚

ä»¥ä¸‹æ˜¯è¯¥æ•°æ®å¸§ä¸­å¯ç”¨çš„é”®:

> ['nrOfConversations 'ï¼Œ' longestConversation 'ï¼Œ' longestConversationInDays 'ï¼Œ
> ï¼Œ' averageConversationLength 'ï¼Œ
> ï¼Œ' medianConversationLength 'ï¼Œ' medianConversationLengthInDays 'ï¼Œ
> ï¼Œ' nrOfOneMessageConversations 'ï¼Œ' percentOfOneMessageConversations 'ï¼Œ
> ï¼Œ' nrofghostingafterinitialmessage 'ï¼Œ' Sex']

ç»™æˆ‘ç•™ä¸‹æ·±åˆ»å°è±¡çš„æ˜¯ **nrOfConversations** ã€**nrOfOneMessageConversations**å’Œ**nrofghostingsaftinitialmessageã€‚**

```
import pandas as pd
import numpy as npcmd = pd.read_csv('all_eng_convometa.csv')# Average number of conversations between both sexes
print("The average number of total Tinder conversations for both sexes is", cmd.nrOfConversations.mean().round())# Average number of conversations separated by sex
print("The average number of total Tinder conversations for men is", cmd.nrOfConversations[cmd.Sex.str.contains("M")].mean().round())
print("The average number of total Tinder conversations for women is", cmd.nrOfConversations[cmd.Sex.str.contains("F")].mean().round())
```

*ç”·æ€§å’Œå¥³æ€§çš„å¹³å‡èŠå¤©æ¬¡æ•°æ˜¯ 278.0 æ¬¡ã€‚*

*ç”·æ€§çš„æ€» Tinder å¯¹è¯å¹³å‡æ¬¡æ•°ä¸º 218.0 æ¬¡ã€‚*

*å¥³æ€§æ€» Tinder å¯¹è¯çš„å¹³å‡æ¬¡æ•°æ˜¯ 464.0ã€‚*

å“‡å“¦ã€‚è¿™é‡Œå¯ä»¥æ„Ÿå—åˆ°ç”·äººå’Œå¥³äººçš„ä¸åŒç»å†ã€‚

```
# Average number of one message conversations between both sexes
print("The average number of one message Tinder conversations for both sexes is", cmd.nrOfOneMessageConversations.mean().round())# Average number of one message conversations separated by sex
print("The average number of one message Tinder conversations for men is", cmd.nrOfOneMessageConversations[cmd.Sex.str.contains("M")].mean().round())
print("The average number of one message Tinder conversations for women is", cmd.nrOfOneMessageConversations[cmd.Sex.str.contains("F")].mean().round())
```

ç”·æ€§å’Œå¥³æ€§åœ¨äº¤è°ˆä¸­å¹³å‡æ”¶åˆ° 80.0 æ¡ä¿¡æ¯ã€‚

ç”·æ€§åœ¨äº¤è°ˆä¸­å¹³å‡æ¯æ¡çŸ­ä¿¡çš„æ•°é‡æ˜¯ 74.0 æ¡ã€‚

å¥³æ€§åœ¨äº¤è°ˆä¸­å¹³å‡æ¯æ¡ä¿¡æ¯çš„æ•°é‡æ˜¯ 99.0 æ¡ã€‚

æœ‰æ„æ€ã€‚å°¤å…¶æ˜¯å½“æˆ‘çœ‹åˆ°å¥³æ€§åœ¨ Tinder ä¸Šæ”¶åˆ°çš„å¹³å‡ä¿¡æ¯æ˜¯ç”·æ€§çš„ä¸¤å€å¤šæ—¶ï¼Œæˆ‘å¾ˆæƒŠè®¶å¥¹ä»¬çš„ä¸€æ¡ä¿¡æ¯å¯¹è¯æ˜¯æœ€å¤šçš„ã€‚ç„¶è€Œï¼Œè¿˜ä¸æ¸…æ¥šæ˜¯è°å‘é€äº†ç¬¬ä¸€æ¡ä¿¡æ¯ã€‚æˆ‘çš„å®¢äººæ˜¯ï¼Œå®ƒåªåœ¨ç”¨æˆ·å‘é€ç¬¬ä¸€æ¡æ¶ˆæ¯æ—¶è¯»å–ï¼Œå› ä¸º Tinder ä¸ä¿å­˜æ”¶åˆ°çš„æ¶ˆæ¯ã€‚åªæœ‰ Tinder å¯ä»¥æ¾„æ¸…ã€‚

```
# Average number of ghostings between each sex
print("The average number of ghostings after one message between both sexes is", cmd.nrOfGhostingsAfterInitialMessage.mean().round())# Average number of ghostings separated by sex
print("The average number of ghostings after one message for men is", cmd.nrOfGhostingsAfterInitialMessage[cmd.Sex.str.contains("M")].mean().round())
print("The average number of ghostings after one message for women is", cmd.nrOfGhostingsAfterInitialMessage[cmd.Sex.str.contains("F")].mean().round())
```

*ä¸¤æ€§ä¹‹é—´ä¸€æ¡ä¿¡æ¯åçš„ä»£ç¬”æ¬¡æ•°å¹³å‡ä¸º 50.0 æ¬¡ã€‚*

ç”·æ€§å‘ä¸€æ¡ä¿¡æ¯åçš„å¹³å‡ä»£ç¬”æ¬¡æ•°ä¸º 18.0 æ¬¡ã€‚

*å¥³æ€§å‘ä¸€æ¡ä¿¡æ¯åçš„å¹³å‡ä»£ç¬”æ¬¡æ•°æ˜¯ 151.0 æ¬¡*

ç±»ä¼¼äºæˆ‘ä¹‹å‰åœ¨**nrOfOneMessageConversations**ä¸­æåˆ°çš„ï¼Œå¹¶ä¸å®Œå…¨æ¸…æ¥šæ˜¯è°å‘èµ·äº†é‡å½±ã€‚å¦‚æœå¥³æ€§åœ¨ Tinder ä¸Šè¢«æ›´å¤šäººè·Ÿè¸ªï¼Œæˆ‘ä¸ªäººä¼šæ„Ÿåˆ°éœ‡æƒŠã€‚

## c)åˆ†æç”¨æˆ·å…ƒæ•°æ®

ä»¥ä¸‹æ˜¯ç”¨æˆ·å…ƒæ•°æ®ä¸­å¯ç”¨çš„å¯¹è±¡ã€‚

> ['ç”Ÿæ—¥'ï¼Œ'å¹´é¾„è¿‡æ»¤'ï¼Œ'å¹´é¾„è¿‡æ»¤'ï¼Œ'æœ€å¤§å€¼'ï¼Œ'åŸå¸‚å'ï¼Œ'å›½å®¶'ï¼Œã€T2 'ï¼Œ'åˆ›å»ºæ—¥æœŸ'ï¼Œ'æ•™è‚²'ï¼Œ'æ€§åˆ«'ï¼Œ'å…´è¶£'ï¼Œ'æ€§åˆ«è¿‡æ»¤'ï¼Œã€T3 'ï¼Œ' instagram 'ï¼Œ' spotify 'ï¼Œ'å·¥ä½œ'ï¼Œ'æ•™è‚²æ°´å¹³'ï¼Œ'å­¦æ ¡']

æˆ‘æƒ³åˆ›å»ºä¸€ä¸ªå¹´é¾„åˆ—ï¼Œå¹¶å†³å®šå¯ä»¥å°†ç”¨æˆ·å¹´é¾„ç¡®å®šä¸º(**åˆ›å»ºæ—¥æœŸ** - **å‡ºç”Ÿæ—¥æœŸ** ) **ã€‚**

```
# CSV of updated_md has duplicates
md = md.drop_duplicates(keep=False)from datetime import datetime, datemd['birthDate'] = pd.to_datetime(md.birthDate, format='%Y.%m.%d').dt.date
md['createDate'] = pd.to_datetime(md.createDate, format='%Y.%m.%d').dt.datemd['Age'] = (md['createDate'] - md['birthDate'])/365
md['age'] = md['Age'].astype(str)
md['age'] = md['age'].str[:3]
md['age'] = md['age'].astype(int)# Dropping unnecessary columns
md = md.drop(columns = 'Age')
md = md.drop(columns= 'education')
md = md.drop(columns= 'educationLevel')# Rearranging columns
md = md[['gender', 'age', 'birthDate','createDate', 'jobs', 'schools', 'cityName', 'country',
        'interestedIn', 'genderFilter', 'ageFilterMin', 'ageFilterMax','instagram',
       'spotify']]
# Replaces empty list with NaN
md = md.mask(md.applymap(str).eq('[]'))# Converting age filter to integer
md['ageFilterMax'] = md['ageFilterMax'].astype(int)
md['ageFilterMin'] = md['ageFilterMin'].astype(int)
```

æ¥ä¸‹æ¥ï¼Œæˆ‘æƒ³æ‰¾å‡º**å¹´é¾„**ã€**å¹´é¾„è¿‡æ»¤æœ€å¤§å€¼**å’Œ**å¹´é¾„è¿‡æ»¤æœ€å°å€¼**çš„å¹³å‡å€¼ã€‚æˆ‘æ³¨æ„åˆ°è¿™äº›æ•°å­—å¼‚å¸¸åé«˜ï¼Œæ‰€ä»¥æˆ‘æ£€æŸ¥äº†æˆ‘çš„æ•°æ®é›†ï¼Œå¹¶æ³¨æ„åˆ°ä¸€äº›é’“é±¼ã€‚æˆ‘ä»æ•°æ®é›†ä¸­åˆ é™¤äº†ä»¥ä¸‹å†…å®¹ã€‚

ä¸€ä¸ªäºº 106 å²ï¼Œå¦ä¸€ä¸ª 137 å²ã€‚ä¸¤äºº 16 å²ï¼Œä¸€äººåˆ—ä¸º 15 å²ã€‚æˆ‘è¿˜å»æ‰äº† 17 ä¸ªæŠŠ 1000 ä½œä¸ºè‡ªå·± **ageFilterMax** çš„äººå’Œä¸€ä¸ªåˆ—å‡º 95 çš„äººã€‚

æˆ‘å‘ç°äº†ä»¥ä¸‹æƒ…å†µ:

```
*# Combined age data* 
print("The average user age for both genders is", all_age.age.mean().round()) print("The average user age filter maximum for both genders is", all_age.ageFilterMin.mean().round()) print("The average user age filter minimum for both genders is", all_age.ageFilterMax.mean().round()) print("--------------------") *# By gender* 
print("The average male user age is", all_age.age[all_age.gender.str.contains("M")].mean().round()) print("The average female user age", all_age.age[all_age.gender.str.contains("F")].mean().round())  print("--------------------") print("The average male user age filter maximum is", all_age.ageFilterMax[all_age.gender.str.contains("M")].mean().round()) print("The average female user age filter maximum is", all_age.ageFilterMax[all_age.gender.str.contains("F")].mean().round()) print("--------------------") print("The average male user age filter minumum is", all_age.ageFilterMin[all_age.gender.str.contains("M")].mean().round()) print("The average female user age filter minumum is", all_age.ageFilterMin[all_age.gender.str.contains("F")].mean().round())
```

*ç”·å¥³ç”¨æˆ·å¹³å‡å¹´é¾„ä¸º 24.0
ç”·å¥³ç”¨æˆ·å¹³å‡å¹´é¾„è¿‡æ»¤æœ€å¤§å€¼ä¸º 21.0
ç”·å¥³ç”¨æˆ·å¹³å‡å¹´é¾„è¿‡æ»¤æœ€å°å€¼ä¸º 31.0
-
ç”·æ€§ç”¨æˆ·å¹³å‡å¹´é¾„ä¸º 24.0
å¥³æ€§ç”¨æˆ·å¹³å‡å¹´é¾„ä¸º 23.0
-
ç”·æ€§ç”¨æˆ·å¹³å‡å¹´é¾„è¿‡æ»¤æœ€å¤§å€¼ä¸º 31.0
å¥³æ€§ç”¨æˆ·å¹³å‡å¹´é¾„è¿‡æ»¤æœ€å¤§å€¼ä¸º 32.0 ã€T27*

ä¸ºäº†å¢åŠ æ•ˆæœï¼Œæˆ‘ç”¨åŒæ ·çš„æ•°æ®åˆ¶ä½œç›´æ–¹å›¾ã€‚

![](img/2e371fcf1ae31829638dd530ae2c1f0b.png)![](img/dd915b191b34d7bc7fe4ba69176d20f9.png)![](img/45d589bbcfd5316e2662ecb50f8a5f32.png)

æœ€åï¼Œä½†è‚¯å®šä¸æ˜¯æœ€ä¸é‡è¦çš„ï¼Œæˆ‘çœ‹äº†**å·¥ä½œã€å­¦æ ¡**ã€åŸå¸‚**å’Œå›½å®¶**ã€‚****

```
# Creating df of jobs listed
jobs_df = pd.DataFrame(md['jobs'].value_counts(dropna=True))
jobs_df.reset_index(level=0, inplace=True)
jobs_df = jobs_df.rename(columns={"index": "Jobs", "jobs": "Count"})# Dropped index that said False
jobs_df = jobs_df.drop(0)
jobs_df = jobs_df.drop(1)jobs_df.head(10)
```

![](img/c93be27b138b947a45a235e96acf13c5.png)

æˆ‘çŸ¥é“ä½ åœ¨æƒ³ä»€ä¹ˆâ€”â€”æ— èŠï¼Œå¯¹å§ï¼Ÿæˆ‘è‡ªå·±æµè§ˆäº†ä¸€ä¸‹åˆ—è¡¨ï¼Œé€‰å‡ºäº†æˆ‘æœ€å–œæ¬¢çš„ã€‚

![](img/bc79c8465c2dccaccfda1b92c820f56c.png)

Tinder æ•°æ®ä¸­æ˜¾ç¤ºçš„ Alyssa æœ€å–œæ¬¢çš„å·¥ä½œ

è¿™äº›æ˜¯ Tinder æ•°æ®ä¸­æ’åå‰åçš„å­¦æ ¡ã€‚

```
# Creating df of schools listed
school_df = pd.DataFrame(md['schools'].value_counts(dropna=True))
school_df.reset_index(level=0, inplace=True)
school_df = school_df.rename(columns={"index": "Schools", "schools": "Count"})# Dropped index that was empty list
school_df = school_df.drop(0)school_df.head(10)
```

![](img/855d52580fa077ae2304029298938f39.png)

åŸºäº Tinder æ•°æ®çš„åå¤§åŸå¸‚ã€‚

```
# Creating df of cities listed
city_df = pd.DataFrame(md['cityName'].value_counts(dropna=True))
city_df.reset_index(level=0, inplace=True)
city_df = city_df.rename(columns={"index": "City", "cityName": "Count"})city_df.head(10)
```

![](img/315fa7fdb74041804310621b43e1ab74.png)

å¾ˆå¤šåŠ æ‹¿å¤§äººå’Œå†·é…·çš„ç¾å›½äººã€‚

æœ€åï¼Œåå¤§å›½å®¶ã€‚ç„¶è€Œï¼ŒTinder å°†å·å’Œå›½å®¶åˆ†ç»„åœ¨ä¸€èµ·ï¼Œæ‰€ä»¥è‡³å°‘å¯ä»¥è¯´å®ƒå¾ˆæ··ä¹±ã€‚

```
# Creating df of countries/states listed
country_df = pd.DataFrame(md['country'].value_counts(dropna=True))
country_df.reset_index(level=0, inplace=True)
country_df = country_df.rename(columns={"index": "Country/State", "country": "Count"})country_df.head(10)
```

![](img/1be3f4dc58b7bf451ab5d53cb74c535c.png)

# æœ€åçš„æƒ³æ³•

æ€»è€Œè¨€ä¹‹ï¼Œè¿™äº›æ•°æ®æ˜¯ä»¤äººå°´å°¬çš„éšç§ï¼Œä½†æ­ç¤ºäº†æˆ‘ä»¬å·²çŸ¥çš„æœ€æ— èŠçš„éƒ¨åˆ†ã€‚

æ¯«ä¸å¥‡æ€ªï¼Œæˆ‘ä»¬å‘ç°å¥³æ€§åœ¨ Tinder ä¸Šçš„å¹³å‡å¯¹è¯æ¬¡æ•°æ¯”ç”·æ€§å¤šï¼Œæˆ–è€…â€œå¿«ä¹:æ˜¯æœ€å—æ¬¢è¿çš„è¡¨æƒ…ç¬¦å·â€ã€‚å¦ç™½åœ°è¯´ï¼Œæˆ‘çš„å‘ç°ä»¤äººå°è±¡æ·±åˆ»ï¼Œä½†è¿™æ˜¯ä¸€ä¸ªå¼€å§‹ã€‚

æˆ‘çœ‹åˆ°äº†æœªæ¥é¡¹ç›®ä½¿ç”¨è¿™äº›æ•°æ®çš„å·¨å¤§æ½œåŠ›ï¼Œæˆ‘å‡ ä¹æ²¡æœ‰è§¦åŠè¡¨é¢ã€‚æœªæ¥çš„æƒ³æ³•åŒ…æ‹¬å»ºç«‹ä¸€ä¸ªæ›´å¯é çš„è°ƒæƒ…åˆ†æå·¥å…·æˆ–åˆ›å»ºä¸€ä¸ª Tinder æ¶ˆæ¯æœºå™¨äººã€‚

ä¸ç®¡æ˜¯å“ªç§æƒ…å†µï¼Œæˆ‘éƒ½å¯¹å³å°†åˆ°æ¥çš„äº‹æƒ…æ„Ÿåˆ°å…´å¥‹ã€‚

## æ‰¿è®¤

æ„Ÿè°¢ Soma ä¸ä»…æ˜¯ä¸€åä¼˜ç§€çš„æ•™å¸ˆï¼Œä¹Ÿæ˜¯ Lede é¡¹ç›®çš„å…ˆé”‹ï¼é¢å¤–æ„Ÿè°¢å¡æ£®ã€å¡”çº³è¥¿æ–¯ã€æ°å¤«å’Œçš®ç‰¹å¯¹æˆ‘çš„å¸®åŠ©ã€‚

ç‰¹åˆ«æ„Ÿè°¢ [Swipestats.io](https://swipestats.io/) ä¸ºæˆ‘æä¾›æ•°æ®ï¼Œè”ç³»æ–¹å¼å¦‚ä¸‹ã€‚

å…‹é‡Œæ–¯è’‚å®‰Â·åŸƒå°”å¡ç‰¹Â·åš

ç”µå­é‚®ä»¶:[å…‹é‡Œæ–¯è’‚å®‰@äº¬ä¸œæ–¹.é£æŠ•](mailto:kristian@boe.ventures)

é¢†è‹±:ã€https://www.linkedin.com/in/kristianeboe/ 