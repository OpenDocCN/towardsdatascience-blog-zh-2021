# 在 PyTorch 建立您的第一个网络

> 原文：<https://towardsdatascience.com/all-you-need-to-know-about-pytorch-a0ba3af897fa?source=collection_archive---------16----------------------->

## 启动你深度学习生涯的总结。

![](img/03f7403d7aed867aaf84f4b9193eb09f.png)

在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上由 [Max Duzij](https://unsplash.com/@max_duz?utm_source=medium&utm_medium=referral) 拍照

开始一个深度学习项目，听起来很吓人，很难？我已经通读了关于神经网络的文章，上过课，看过视频，但是我如何开始编程呢？我们都经历过那个阶段，这就是为什么我写这篇文章来告诉你开始 PyTorch 模型训练项目的一切(或者至少是我知道的大部分事情)。

指南以自下而上的方式呈现。我将首先描述对训练深度网络很重要的各个组件，然后提供如何将所有组件组合在一起进行训练和测试的示例。

*边注:*

文章是将 ML 中的理论知识直接转化为代码的桥梁。假设有先验的 ML 知识。

*我的项目主要在计算机视觉领域，所以我发现 PyTorch 中最有用的功能也偏向于图像方面的应用。*

# 目录

[**目录**](#d093)
[**导入**](#b6a4)
**[**网络组件**](#4e1f)
∘ [全连通层](#c4c8)
∘ [卷积族](#98fb)
∘ [递归网络](#ab9a)
∘ [激活功能](#af15)
**[**结合一切**](#4607)
∘ [导入 PyTorch](#66a8)
∘ [创建网络](#1aa7)
∘ [创建数据集和数据加载器](#f3ee)
∘ [初始化网络、优化器和调度器](#93fb)
∘ [培训、评估和保存](#3ddc)**** 

# ****导入****

****PyTorch 有很多相关的库，这里我列出了执行下面所有操作的基本库:****

```
**import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data
from torch.utils.data import Dataset, DataLoader
import torchvision**
```

****所有的代码将基于上述的进口，所以请注意所有的名称别名由' as '创建。****

# ****网络组件****

****让我们从 PyTorch 中训练网络的最重要的方面开始，设计网络本身。深度网络可以由各种类型的层组成，这里我列出了一些最常用的层类型。****

## ****完全连接的层****

****这是最传统的神经网络的主要组成部分，也在今天的大多数模型中使用。它可以通过以下方式创建:****

```
**nn.Linear(input_size, output_size, ...)**
```

*****输入 _ 大小*和*输出 _ 大小*本质上是进出该层的通道数量。****

## ******卷积家族******

******回旋******

****围绕计算机视觉/图像的任务通常由卷积神经网络(CNN)处理。与正常的全连接层不同，CNN 由卷积构建，卷积可以通过以下方式创建:****

```
**nn.Conv2D(input_size, output_size, kernel, stride, padding, ...)
nn.ConvTranspose2D(input_size, output_size, kernel, stride, ...)**
```

*****nn。Conv2D()* 本质上是一个 2D 卷积，带有创建它所需的参数(例如，输入和输出通道大小、内核、步幅、填充)。PyTorch 还提供 1D 和 3D 卷积，具体取决于您查看的是一维数据还是 3D 表示。****

****要执行反卷积(主要用于网络的解码阶段)，请使用 *nn。ConvTranspose2D()* 。通过简单地将 2D 改变为 1D 或 3D，再次支持一至三维。****

******联营******

****卷积通常与池化图层成对出现，以改变输出要素地图的大小。最常用的汇集方法包括:****

```
**nn.MaxPool2d(kernel_size, stride, padding, ...)
nn.AvgPool2d(kernel_size, stride, padding, ...)**
```

****指的是最大和平均池。如果你很懒于计算，只想得到一个目标尺寸，你也可以选择:****

```
**nn.AdaptiveAvgPool2d(output_size)**
```

****这将自动确定应如何进行池化，以便以您想要的大小输出要素。****

******批量标准化******

****想要执行批量标准化吗？PyTorch 也为你解决了:****

```
**nn.BatchNorm2d(num_features, ......)**
```

****你可以在卷积层之后直接应用它****

## ****循环网络****

****如果你更喜欢自然语言处理或时间序列数据分析，你可能会遇到比 CNN 更多的递归网络。以下是 PyTorch 支持的更著名的循环网络类型列表:****

```
**nn.RNN(...)
nn.GRU(...)
nn.LSTM(...)**
```

****你可以关注一些详细的博客。有大量的变化(单向或双向)，有大量的在线资源供你研究。****

## ****激活功能****

****对于要学习的网络，你需要在每一层之后应用激活函数。一些常用的激活，如 sigmoid、ReLU 或 LeakyReLU，可通过以下方式创建:****

```
**nn.Sigmoid()
nn.ReLU()
nn.LeakyReLU()**
```

****请注意，sigmoid 函数存在梯度消失的问题，因此它通常用于最终输出图层，以在 0 和 1 之间进行预测，而在其他地方则不进行预测。LeakyReLU 通常性能更好，但也比计算 ReLU 慢。****

****同样重要的是不要将两个激活函数堆叠在一起。这将使你的网络几乎无法学习，你将花费大量时间调试它！****

# ****损失函数****

****一些最常用的损失(例如，MSE 损失、二元交叉熵、kl 散度)可通过以下方法计算:****

```
**nn.MSELoss()
nn.BCELoss()
nn.KLDivLoss()**
```

# ****乐观主义者****

****为了配合损失函数，下面是 PyTorch 提供的几种最广泛使用的优化器:****

```
**optim.Adam(model.parameters, lr, ...)
optim.SGD(model.parameters, lr, momentum, ...)**
```

****你可能还需要一个学习率计划程序，当你的训练似乎达到平稳状态时，学习率会降低。这可以通过以下方式实现:****

```
**optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode, patience, ...)**
```

# ****设置 GPU****

****深度模型计算量很大。非常贵。如果你有 GPU，建议对他们进行培训。有几种方法可以使用 PyTorch 将你的网络、张量和其他东西放到 GPU 上:****

```
**# 1
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
tensor = tensor.to(device)# 2
tensor = tensor.cuda()**
```

****更明智的方法是第一种方法，因为第二种方法假设 GPU 可用，并且在没有 GPU 的设备上中断。****

****当您有多个 GPU 时，您也可以使用:****

```
**network = nn.DataParallel(network).cuda()**
```

****将网络分布到多个 GPU 上进行并行计算。****

# ****结合一切****

****每个模型都是不同的，但在如何创建和训练它们方面，它们或多或少都有相似的结构。以下是整个过程的大致轮廓:****

## ****进口 PyTorch****

## ****创建网络****

****这是您收集所有网络组件来编写模型的部分。将输入输入网络时，您需要初始化所需的一切:****

## ****创建数据集和数据加载器****

****我们必须处理数据，这样我们就可以迭代地从数据集中获取批量数据，并将其输入神经网络:****

## ****初始化网络、优化器和调度器****

## ****培训、评估和储蓄****

****就在那里！模型可以变化，训练方法可以不同，可视化可以应用，损失可以是许多奇怪组件的组合，但最终它将基于这样一个简单的主干。关于实际网络的例子，请随意在这里</building-a-gan-with-pytorch-237b4b07ca9a>**或者在这里 找到 [**。**](/building-a-convolutional-vae-in-pytorch-a0f54c947f71)******

# ****预训练模型****

****如果您想使用一些成熟的架构，而不是设计自己的架构，PyTorch 也能满足您的要求:****

```
**torchvision.models.resnet50(pretrained=True)**
```

****预训练权重将加载到您的模型中，您可以继续在自己的数据集上对其进行微调。****

# ****其他有趣的 PyTorch 函数****

****以下是我在深入学习的过程中发现的一些有用的功能:****

```
**torch.ge(input, constant)**
```

****如果值>常数，则将整个输入张量转换为 1，否则转换为 0。适用于计算交集和并集之类的东西。****

```
**torch.topk(input, k)**
```

****从输入张量中查找前 k 个值。输出将是前 k 个值及其相应索引的元组。****

```
**torch.stack(list)**
```

****将长度为 n 的张量列表转换为大小为 n 的张量。****

# ****结束注释****

****所以你有它。关于如何开始你的第一个深度学习项目的简单、全面的指南。希望这有所帮助，你的网络工作！****

*****感谢您坚持到现在*🙏*！* *我会在计算机视觉/深度学习的不同领域发布更多内容，所以* [*加入并订阅*](https://taying-cheng.medium.com/membership) *如果你有兴趣了解更多！*****