# 机器学习不是在真空中发生的，那为什么要在一个真空中发展呢？

> 原文：<https://towardsdatascience.com/machine-learning-doesnt-occur-in-a-vacuum-so-why-develop-it-in-one-639ee8b8e0bb?source=collection_archive---------33----------------------->

## 从软件工程师的角度回顾 ML/DS 开发生态系统

![](img/56f6c7588493b9187fbeb61bfa3cc174.png)

由 [Charles Deluvio](https://unsplash.com/@charlesdeluvio?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

参考消息:我所说的关于机器学习的一切也适用于任何数据科学工作；虽然数据科学家的工作可能专注于内部，但如果是用来为业务制定决策，那么它应该是可靠的。

在过去的 30 年里，软件开发取得了长足的进步，开发了成千上万的工具来帮助完成编写代码的复杂任务。虽然这些工具中有许多已经淡出了人们的视线，但是还有一些，比如 git，已经成为全球软件开发的主要工具。这些工具中有许多专注于抽象掉复杂性，让开发人员专注于编写特定于应用程序的代码。让我们回想一下 21 世纪初，部署和适当扩展数据库通常需要几天时间，相比之下，今天只需三次点击就可以创建一个无限可扩展的 DynamoDB 表。为什么？嗯，云服务提供商的崛起让大多数公司完全摆脱了基础设施管理，开发人员在这些服务的基础上构建业务逻辑，不用担心他们是否有足够的服务器机架。这些服务提供商已经从硬件和基础设施元素中抽象出来，以加速云应用程序的开发。在许多情况下，这种加速从几年到几个月不等，推动了成千上万的初创公司，导致了我们目前正在经历的新应用和服务的真正繁荣。云不再只是大玩家的专利，任何开发者都可以使用。

这与机器学习/数据科学有什么关系？他们目前正处于云开发成为前云提供商的同一阶段。由于没有全面降低复杂性的服务，工程师不仅需要了解他们学科的基础知识，还需要了解如何开发、托管和维护他们构建的代码。这大大降低了开发速度，并将机器学习的规模限制在只有预算负担得起基础设施团队的大型科技公司。

这并不是说没有库来帮助解决这个问题，一些神奇的工具正在涌现，如 MLFlow，Google Colab 和 Feast。但它们不是包罗万象的，它们满足特定的标准，仅此而已。

为了说明这一点，假设您有一个用 Python 开发并在 Jupyter 笔记本上运行的模型。它是标准的开发工具，但是你想把它提供给最终用户。你是怎么做到的？将模型导出为 zip 文件？以后想重新培训模特怎么办？谁编写代码来利用模型？这是如何部署的？结果存储在哪里？我认为最好用 Metaflow 团队制作的图表来概括。

![](img/c86a3a73b18f7784094e7b12eb1144e8.png)

数据科学家的典型工作流程[1]

作为一名专业的云工程师，我看到这样的工作流就感到害怕。任何 CD 管道都应该以尽可能少的步骤尽快完成，以确保开发时间最大化。如果您的部署工作流程需要 5 分钟，那么您可以比那些工作流程需要 1 分钟的人少做 5 倍的测试，天才！机器学习很难，让我们给工程师尽可能多的时间来解决问题。

到目前为止，我已经侮辱了一个共同的工作流程，并没有提供答案，所以让我们定义一些标准，并看看我们如何才能改善！

# **成功工作流程的标准**

*   尽可能匹配生产*的开发环境
*   用于开发环境测试的快速且可重复的部署周期
*   轻松访问生成的日志和结果
*   易于版本控制

如何用一个示例任务来说明上面定义的需求。假设我们的 ML 工程师杰洛特在一家在线销售汉堡的公司工作，他的任务是建立一个推荐系统，根据我们每天收到的数据更新向人们推荐不同的汉堡组合。这项工作需要开发，然后推向生产，它将每天为每个客户运行，并将当天的建议转储到数据库中。

# 模拟生产的开发环境

现在，这对于任何进入开发机器学习/数据科学工作的人来说可能有点奇怪，但当与不同的环境和平台一起工作时，这是至关重要的。每当您第一次将代码集成到生产系统中时，总会有问题、缺失的依赖项、不同的操作系统版本和意外的瓶颈会导致错误。如果您可以在尽可能接近生产的环境中开发，这将允许您在开发阶段消除这些问题。对于杰洛特来说，如果他在本地开发，然后推到一个远程实例来按计划运行他的代码，他可能会遇到破坏产品推荐系统的问题。如果杰洛特在远程实例的克隆上开发了他的代码(不要直接在生产系统上开发！)那么他可能已经能够避免这些问题，减少他的工作量和将系统投入生产所需的变更。

坚持这一要求也意味着不必重写开发代码来将其部署到生产中。想象一下，杰洛特开发了一个 Jupyter 笔记本，创建了测试，并确保一切工作正常——只是为了撕掉它，重写它，以便它可以很容易地装入集装箱。这根本说不通。如果杰洛特在一个模拟的生产环境中工作，他可以重用他经过反复测试的开发代码(如果你对为什么这很糟糕感兴趣的话[2])。

虽然这个需求很重要，但是它也不应该妨碍开发人员在两次测试之间进行快速迭代——这是我们的下一个需求。

**建议**:尝试在本地重建生产环境。容器是一个很好的工具，因为它们不需要外部依赖。如果您不能使用容器，那么在轻松地推到远程位置之前允许有限的本地测试是至关重要的。Jupyter 笔记本在这里并不是一个好的工具，因为您可能需要重写部分代码才能在生产中运行它！

# 快速且可重复的测试部署流程

虽然我早些时候谈到了这一点，但让我们重新看看这对机器学习意味着什么。这个过程应该是代码被“部署”到其开发环境(本地或其他地方)并运行以测试代码的方式。在杰洛特的例子中，这将是把他的代码推送到克隆的远程实例(模拟生产)并运行它以在一个示例数据集上产生一些测试建议。如果这个过程需要很多手动步骤，那么这可能会使杰洛特脱离专注状态[3]或者导致错误，从而减慢进度。这是我们想要避免的。

作为其中的一部分，软件管道通常包括单元测试，以确保代码按预期运行。虽然您可能无法直接测试正在开发的模型，但是测试所有内部逻辑和输出以确保它们满足概述的标准仍然有很大的价值。在 Geralds 的案例中，他可以拥有世界上最好的推荐系统，但是如果他的代码不能正确地将值写入数据库，那么它对他的公司就没有用了。

考虑到所有这些，当设计一个工作流时，分三个阶段考虑可能是好的。

**第一阶段**:局部探索- >局部

探索样本数据集，感受可能需要的工作。这最好在本地完成，因为它需要大量的快速迭代，例如，格式化和编组数据。杰洛特不想花 5 分钟等待代码部署，只是为了打印出数据框的内容。

**第二阶段**:批量开发- >开发环境

任何模型的大部分实质性开发都需要大量较慢的迭代，因为此时代码可能很重要，并且做出更改会更加复杂。对杰洛特来说，这是他开发和训练模型的时候。作为其中的一部分，将需要一些健壮的部署，这样他可以持续地测试他的工作，可能包含单元测试，以确保输入/输出保持在规范之内。理想情况下，这也可以在前面讨论过的类似生产的环境中进行，以尽量减少以后的问题。

**第三阶段**:生产调度- >生产环境

为了部署到生产中，代码必须通过一系列严格的测试——结合可伸缩性测试的思想，以确保模型在输入增加时保持准确性。这个过程也应该随着代码在生产调度中的实际部署而自动完成。

**建议**:遵循上面的分阶段过程概述，利用诸如 Metaflow 或 Kubeflow 之类的工具，在部署代码时尽量减少对开发人员的干扰。

# 轻松访问代码库生成的日志和结果

我觉得这个没有太大争议，但是肯定需要强调一下。在开发时，你需要确保可以快速访问代码库创建的任何输出，以便在必要时可以轻松调试。如果您的工作流涉及将代码推送到远程机器，您需要确保能够轻松地访问生成的日志——我们在这里着眼于改进流程，而不是降低它们的效率！

这也适用于任何输出——不仅仅是调试信息——杰洛特不能确定他的代码已经将正确的值写入数据库，除非能够检查它们。

**推荐**:同样，像 Metaflow 这样的工具非常有用，因为它们为调试提供即时反馈，并存储所有变量的结果以供进一步分析。避免使用 SSH 之类的机制来获取日志反馈，因为它们需要手动步骤，容易出错，而且会让开发人员更加难以集中精力。

# 易于版本控制

我向任何人挑战，看他们能否找到一个不对他们的代码库使用某种版本控制的传统软件团队。它有很好的理由，它是存储、恢复、组合和分析任何代码的无价工具。

它不仅作为代码的备份很方便，而且跟踪代码的版本也非常有用——这在跟踪 bug 时非常重要。如果您正在部署您的代码按计划远程运行，通常很难知道您的代码运行的是什么版本。你是否曾经运行某个程序并得到一个输出，然后想——这是不对的？我想知道它是否部署正确—让我再试一次，看看它是否能修复它。在持续部署管道中利用版本控制可以帮助实现这一点[4]，因为它可以在您提交时将您的代码部署到远程位置，因此您可以回顾并查看上次提交的内容，并确定您的代码正在运行的版本。据我所知，部署管道中的不确定性是导致灾难的原因，并且容易导致错误诊断。

这里我想说的最后一点是团队整合。如果杰洛特有一个队友也在开发他的代码库，如果他们使用 git 这样的版本控制系统，他们会更容易合作，而不会妨碍彼此。这将允许他们提交拉请求，并检查彼此的代码，彼此独立地部署代码。

**推荐**:用 git！如果您还有时间，请使用 Github actions 来运行基本的分析、测试和代码部署——不要再手动将拉链放到 S3 了！

那么作为一个 TL:DR，这里有什么外卖？ML 不是在真空中发生的。它总是需要从其他服务中消费数据，并在其他地方写入数据。这意味着它需要像围绕它的服务一样稳定和可靠，而实现这一点的可靠方法是使用良好的软件开发原则来构建可靠的代码库。

对于直接的建议，我会说寻找像 **Metaflow** 、 **Kubernetes/Kubeflow** 这样的工具，它们实现了几个标准点，比如使用容器来减少切换到生产时被改变的内存占用。如果这些超出了您的能力范围，那么使用 bash 来自动部署您的代码——即使这只是本地的——以便其他人可以获得您的代码，运行一个命令，然后开始。虽然安装这些过程可能会占用一些初始开发时间，但它们将在项目的后期产生回报，并证明对将来使用您的工作的其他开发人员是无价的。

我只是简单地介绍了一些我认为可以使用的工具，在以后的博客文章中，我将比较这里提到的一些工具，看看哪一个对所有开发人员都是最有效的。

*在这种情况下，生产被定义为任何 ML/DS 工作运行以产生业务价值的地方——通常这被安排为定期提供业务洞察力或向客户提供服务。

**参考文献**

[1]—https://docs.metaflow.org/introduction/why-metaflow 网飞(2019 年)

[2] —乔尔·斯波尔斯基，《你不该做的事，第一部分》(2000 年)，[https://www . joelonsoftware . com/2000/04/06/Things-You-Should-Never-Do-Part-I/](https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/)

[3] —肯德拉·切瑞，《心流的心理学》(2021)，https://www.verywellmind.com/what-is-flow-2794768

[4] — GitLab，CI/CD 的 4 个好处(2019)，[https://medium.com/@gitlab/4-benefits-of-ci-cd-efc3d6b9d09d](https://medium.com/@gitlab/4-benefits-of-ci-cd-efc3d6b9d09d)