# è¿œè§†æ•™ç¨‹:ä¼˜åŒ–æ‚¨çš„è¶…å‚æ•°è°ƒè°

> åŸæ–‡ï¼š<https://towardsdatascience.com/optimise-your-hyperparameter-tuning-with-hyperopt-861573239eb5?source=collection_archive---------8----------------------->

## ä½¿ç”¨ Hyperopt çš„è´å¶æ–¯è¶…å‚æ•°è°ƒæ•´çš„ç®€å•è§£é‡Šå’Œå®ç°

![](img/164b0d53f6ffe5f26482c2f4d3b84a80.png)

çº¦ä¹¦äºšÂ·é˜¿æ‹‰è´¡åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šæ‹æ‘„çš„ç…§ç‰‡

# ä»‹ç»

[**è¶…å‚æ•°è°ƒæ•´**](https://en.wikipedia.org/wiki/Hyperparameter_optimization) æ˜¯æ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ å·¥ä½œæµçš„ä¸€ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†ï¼Œå› ä¸ºå®ƒå¯ä»¥æŒ¤å‹æ¨¡å‹æ‰€èƒ½æä¾›çš„æœ€ä½³æ€§èƒ½ã€‚å› æ­¤ï¼Œæ‚¨é€‰æ‹©æ‰§è¡Œè¶…å‚æ•°è°ƒæ•´çš„æ–¹æ³•éå¸¸é‡è¦ã€‚**ç½‘æ ¼æœç´¢**æ˜¯ç©·å°½å¼çš„ï¼Œè€Œ**éšæœºæœç´¢**æ˜¯å®Œå…¨éšæœºçš„ï¼Œå› æ­¤å¯èƒ½ä¼šé”™è¿‡æœ€é‡è¦çš„å€¼ã€‚ä½†æ˜¯ï¼Œé€šè¿‡**hyperpt**åŒ…æœ‰ä¸€ä¸ªæ›´å¥½çš„æ–¹æ³•ï¼

**Hyperopt** æ˜¯ä¸€ä¸ªå¼€æºçš„è¶…å‚æ•°è°ƒæ•´åº“ï¼Œå®ƒä½¿ç”¨**è´å¶æ–¯**æ–¹æ³•æ¥å¯»æ‰¾è¶…å‚æ•°çš„æœ€ä½³å€¼ã€‚æˆ‘ä¸æ‰“ç®—æ·±å…¥è¿™ä¸ªè´å¶æ–¯æ–¹æ³•å¦‚ä½•å·¥ä½œçš„ç†è®ºç»†èŠ‚ï¼Œä¸»è¦æ˜¯å› ä¸ºå®ƒéœ€è¦å¦ä¸€æ•´ç¯‡æ–‡ç« æ¥å……åˆ†è§£é‡Šï¼ç„¶è€Œï¼Œæ„Ÿå…´è¶£çš„è¯»è€…å¯ä»¥åœ¨è¿™é‡ŒæŸ¥çœ‹æ–‡æ¡£[](http://hyperopt.github.io/hyperopt/)****ï¼Œå¦‚æœä½ æ„Ÿå…´è¶£çš„è¯ï¼Œè¿˜æœ‰å‡ ç¯‡å…³äºè¿™ä¸ªä¸»é¢˜çš„ç ”ç©¶è®ºæ–‡ã€‚****

****åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†æŠŠä¸€ä¸ª **RandomForestClassifier** æ¨¡å‹æ‹Ÿåˆåˆ° Kaggle æä¾›çš„ [**æ°´è´¨**](https://www.kaggle.com/adityakadiwal/water-potability) (CC0 åŸŸ)æ•°æ®é›†ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨**hyperpt è°ƒæ•´æ¨¡å‹çš„è¶…å‚æ•°ã€‚******

## ****ç¬¦åˆç®€å•æ¨¡å‹****

****é¦–å…ˆï¼Œæˆ‘ä»¬è¯»å…¥æ•°æ®ï¼Œå¹¶ä¸ºæˆ‘ä»¬çš„è®­ç»ƒé›†æ‹Ÿåˆä¸€ä¸ªç®€å•çš„ **RandomForestClassifier** æ¨¡å‹:****

```
**# read in packages
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score# read in the data and info
data = pd.read_csv('../input/water-potability/water_potability.csv')# remove missing values
data = data.dropna()# split to train and test
X = data.drop(['Potability'], axis = 1)
y = data['Potability']
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=200)# build the model
model = RandomForestClassifier(n_estimators=300, max_features='sqrt', random_state=42)
model.fit(x_train, y_train)
y_pred = model.predict(x_test)# print out the score accuracy
print("Accuracy:", accuracy_score(y_test, y_pred))**
```

****è¿è¡Œä¸Šé¢çš„ä»£ç ä¼šäº§ç”Ÿ 67.24% çš„ç²¾ç¡®åº¦ã€‚è¿™æ˜¯å¯ä»¥çš„ï¼Œä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡è¶…å‚æ•°è°ƒæ•´æ¥æ”¹å–„è¿™ä¸€ç‚¹ï¼****

## ****è®¾ç½® Hyperopt****

****è¦ä½¿ç”¨ Hyperoptï¼Œæˆ‘ä»¬éœ€è¦ä¸ºæˆ‘ä»¬çš„æ¨¡å‹æŒ‡å®šå››ä¸ªå…³é”®è¦ç´ :****

1.  ******ç›®æ ‡å‡½æ•°|** è¿™å°†è¿”å›æˆ‘ä»¬å¸Œæœ›åœ¨è®¡ç®—è¿‡ç¨‹ä¸­æœ€å°åŒ–çš„å€¼ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œå®ƒæ˜¯â€œaccuracy_scoreâ€å‡½æ•°ã€‚****
2.  ******æœç´¢ç©ºé—´|** è¿™å®šä¹‰äº†ç»™å®šè¶…å‚æ•°çš„å–å€¼èŒƒå›´ã€‚è¿™å¯ä»¥æ˜¯æ•´æ•°ã€æµ®ç‚¹æ•°æˆ–å­—ç¬¦ä¸²ï¼Œæˆ‘ä»¬å°†åœ¨æœ¬æ–‡åé¢çœ‹åˆ°ã€‚****
3.  ******è°ƒä¼˜ç®—æ³•|** åœ¨ Hyperopt ä¸­ï¼Œæœ‰ä¸¤ç§ä¸»è¦çš„è¶…å‚æ•°æœç´¢ç®—æ³•:éšæœºæœç´¢å’Œ Parzen ä¼°è®¡å™¨æ ‘(è´å¶æ–¯)ã€‚åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨åè€…ï¼Œå› ä¸ºå®ƒå·²çŸ¥ä¼šäº§ç”Ÿæœ€ä½³ç»“æœã€‚****
4.  ******è¯„ä¼°|** è¿™æ˜¯æŒ‡è®­ç»ƒæ¨¡å‹çš„ä¸åŒè¶…å‚æ•°å®ä¾‹çš„æ•°é‡ã€‚å»ºè®®è¿™æ˜¯æœç´¢ç©ºé—´ä¸­å®šä¹‰çš„è¶…å‚æ•°æ•°é‡çš„ 10-30 å€ï¼Œä»¥ä¼˜åŒ–æ€§èƒ½å’Œè®¡ç®—æ—¶é—´ã€‚****

****åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºä¸€ä¸ªç¤ºä¾‹ï¼Œè¯´æ˜å¦‚ä½•ä¸ºæˆ‘ä»¬ä¸Šé¢åˆ›å»ºçš„ç®€å•éšæœºæ£®æ—æ¨¡å‹å®ç°ä¸Šè¿°æ­¥éª¤ã€‚****

## ****å…·æœ‰ä¸€ä¸ªè¶…å‚æ•°çš„è¿œè§†****

****åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†åªè°ƒæ•´ä¸€ä¸ªè¶…å‚æ•°ï¼Œå³**â€˜n _ estimatorsâ€™******

****åœ¨ Hyperopt ä¸­é¦–æ¬¡é˜…è¯»:****

```
**# read in hyperopt values
from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK**
```

****ç°åœ¨æˆ‘ä»¬å®šä¹‰æˆ‘ä»¬çš„ç›®æ ‡å‡½æ•°ã€‚è¿™å°†åªæ˜¯â€œn_estimatorsâ€çš„ä¸€ä¸ªå‡½æ•°ï¼Œå®ƒå°†è¿”å›ä»**â€œaccuracy _ scoreâ€**å‡½æ•°æ¨æ–­å‡ºçš„**å‡å»ç²¾åº¦**ã€‚æˆ‘ä»¬å–è´Ÿå€¼ç²¾åº¦çš„åŸå› æ˜¯å› ä¸º **Hyperopt çš„ç›®æ ‡æ˜¯æœ€å°åŒ–ç›®æ ‡**ï¼Œå› æ­¤æˆ‘ä»¬çš„ç²¾åº¦éœ€è¦ä¸ºè´Ÿï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æœ€åä½¿å…¶ä¸ºæ­£ã€‚****

```
**# define the function we want to minimise
def objective(n_estimators):
    model = RandomForestClassifier(n_estimators=n_estimators,
                                   max_features='sqrt',
                                   random_state=42) model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    accuracy = accuracy_score(y_test, y_pred)
    return {'loss': -accuracy, 'status': STATUS_OK}**
```

****å®šä¹‰â€˜n _ estimatorsâ€™çš„æœç´¢ç©ºé—´:****

```
**# define the values to search over for n_estimators
search_space = hp.randint('n_estimators', 200, 1000)**
```

****è¿™é‡Œï¼Œ **'hp.randint'** åœ¨ç»™å®šçš„èŒƒå›´å†…ç»™' n_estimators 'åˆ†é…ä¸€ä¸ªéšæœºæ•´æ•°ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æ˜¯ 200 åˆ° 1000ã€‚****

****æŒ‡å®šç®—æ³•:****

```
**# set the hyperparam tuning algorithm
algorithm=tpe.suggest**
```

****è¿™æ„å‘³ç€ Hyperopt å°†ä½¿ç”¨â€œ**Parzen ä¼°è®¡å™¨æ ‘â€(tpe)** ï¼Œè¿™æ˜¯ä¸€ç§è´å¶æ–¯æ–¹æ³•ã€‚****

****æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨**â€˜fminâ€™**å‡½æ•°å°†å®ƒç»“åˆèµ·æ¥ã€‚â€˜**fnâ€™**åŠŸèƒ½ç›®æ ‡æ˜¯æœ€å°åŒ–åˆ†é…ç»™å®ƒçš„åŠŸèƒ½ï¼Œè¿™æ˜¯ä¸Šé¢å®šä¹‰çš„ç›®æ ‡ã€‚å¦å¤–ï¼Œ**â€˜max _ evalsâ€™**æŒ‡çš„æ˜¯æˆ‘ä»¬è¦æµ‹è¯•çš„ä¸åŒè¶…å‚æ•°çš„æ•°é‡ï¼Œè¿™é‡Œæˆ‘ä»»æ„è®¾ç½®ä¸º 200ã€‚****

```
**best_params = fmin(
  fn=objective,
  space=search_space,
  algo=algorithm,
  max_evals=200)**
```

****ç”Ÿæˆçš„ä»£ç å—çš„è¾“å‡ºå¦‚ä¸‹æ‰€ç¤º:****

****![](img/16a484d8033bd4b94816ce112c7e9c84.png)****

****å›¾ç‰‡ä½œè€…ã€‚****

****æˆ‘ä»¬çœ‹åˆ°æˆ‘ä»¬çš„å‡†ç¡®ç‡æé«˜åˆ°äº† 68.5% ï¼ç„¶åæˆ‘ä»¬å¯ä»¥è°ƒç”¨**â€˜best _ paramsâ€™**æ¥æ‰¾åˆ°äº§ç”Ÿè¯¥æ¨¡å‹çš„â€˜n _ estimatorsâ€™çš„ç›¸åº”å€¼:****

```
**print(best_params)**
```

****è¾“å‡ºæ˜¯:****

****![](img/7a2324d1d053eb2bed6803ea008d9b1f.png)****

****å›¾ç‰‡ä½œè€…ã€‚****

## ****è°ƒæ•´å¤šä¸ªè¶…å‚æ•°****

****ä½¿ç”¨ä¸ä¸Šé¢ç›¸åŒçš„æƒ³æ³•ï¼Œæˆ‘ä»¬å¯ä»¥å°†**å¤šä¸ªå‚æ•°**ä½œä¸ºå­—å…¸ä¼ é€’åˆ°ç›®æ ‡å‡½æ•°ä¸­ã€‚ä¸‹é¢çš„ä»£ç å—æ˜¾ç¤ºäº†è¿™ä¸€ç‚¹çš„å®ç°:****

```
**# redefine the function usng a wider range of hyperparameters
def objective(search_space):
    model = RandomForestClassifier(**search_space, random_state=42)
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    accuracy = accuracy_score(y_test, y_pred)
    return {'loss': -accuracy, 'status': STATUS_OK}# new search space
search_space={'n_estimators':hp.randint('n_estimators',200,1000),

              'max_depth': hp.randint('max_depth',10,200),           

            'min_samples_split':hp.uniform('min_samples_split',0,1),                'min_samples_leaf':hp.randint('min_samples_leaf',1,10),

               'criterion':hp.choice('criterion'['gini','entropy']),

           'max_features':hp.choice('max_features',['sqrt', 'log2']) }# implement Hyperopt
best_params = fmin(
  fn=objective,
  space=search_space,
  algo=algorithm,
  max_evals=200)**
```

*******æ³¨æ„|***** * search _ space æ„å‘³ç€æˆ‘ä»¬åœ¨è¿™ä¸ªå­—å…¸ä¸­è¯»å…¥é”®å€¼å¯¹ä½œä¸º RandomForestClassifier ç±»å†…éƒ¨çš„å‚æ•°ã€‚*****

****åœ¨è¿™ä¸ªæœç´¢ç©ºé—´ä¸­ï¼Œé™¤äº†**â€˜HP . randintâ€™**ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨äº†**â€˜HP . uniformâ€™**å’Œâ€™**HP . choice .â€™**å‰è€…é€‰æ‹©æŒ‡å®šèŒƒå›´å†…çš„ä»»æ„æµ®ç‚¹æ•°ï¼Œåè€…ä»æŒ‡å®šå­—ç¬¦ä¸²ä¸­é€‰æ‹©ä¸€ä¸ªå€¼ã€‚****

****è¯¥è®¡ç®—çš„è¾“å‡ºæ˜¯:****

****![](img/c98bf00801832ef6ba455d251e279235.png)****

****å›¾ç‰‡ä½œè€…ã€‚****

****ç²¾ç¡®åº¦æé«˜åˆ°äº† 69.5%ï¼****

****ç„¶åæˆ‘ä»¬å¯ä»¥è°ƒç”¨**â€˜space _ evalsâ€™**å‡½æ•°æ¥è¾“å‡ºæˆ‘ä»¬æ¨¡å‹çš„æœ€ä½³è¶…å‚æ•°ã€‚****

```
**space_eval(search_space, best_params)**
```

****è¾“å‡ºæ˜¯:****

****![](img/16cd894f84758411d89070701db105c2.png)****

****å›¾ç‰‡ä½œè€…ã€‚****

*******æ³¨æ„*** *|å¦‚æœä½ ä¸ä½¿ç”¨â€˜space _ evalâ€™è€Œåªæ˜¯æ‰“å°å­—å…¸ï¼Œå®ƒåªä¼šç»™ä½ åˆ†ç±»ç‰¹å¾çš„ç´¢å¼•ï¼Œè€Œä¸æ˜¯å®ƒä»¬çš„å®é™…åç§°ã€‚*****

****æˆ‘ä»¬èµ°å§ï¼æˆ‘ä»¬åˆšåˆšä½¿ç”¨ Hyperopt è°ƒæ•´äº†æˆ‘ä»¬çš„æ¨¡å‹ï¼Œä¸€ç‚¹ä¹Ÿä¸å›°éš¾ï¼****

****å¸Œæœ›ä½ å–œæ¬¢è¿™ç¯‡å…³äºå¦‚ä½•ç®€å•å®ç° Hyperopt çš„æ–‡ç« ï¼****

> ****å¦ä¸€ä¸ªç®€æ´çš„ç‰¹æ€§æ˜¯ï¼ŒHyperopt å…è®¸æ‚¨ä½¿ç”¨**åˆ†å¸ƒå¼è®¡ç®—**ï¼Œæˆ‘å°†åœ¨å¦ä¸€ç¯‡æ–‡ç« ä¸­ä»‹ç»è¿™ä¸ªç‰¹æ€§ã€‚è¿™æ„å‘³ç€ï¼Œå¦‚æœæ‚¨æœ‰**ä¸ªå¤šæ ¸**æˆ–è€…åœ¨**å¤–éƒ¨è®¡ç®—é›†ç¾¤**ä¸Šè¿è¡Œæ¨¡å‹ï¼Œæ‚¨å¯ä»¥**è¿è¡Œå¤šä¸ªå…·æœ‰ä¸åŒè¶…å‚æ•°**çš„æ¨¡å‹**ã€‚è¿™ç§æ–¹æ³•æå¤§åœ°ä¼˜åŒ–äº†ä½ çš„è®¡ç®—æ—¶é—´ï¼Œè¿™åœ¨å¯¹éå¸¸å¤§çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒæ—¶éå¸¸æœ‰ç”¨ã€‚******

**å¦‚æœæ‚¨æƒ³æŸ¥çœ‹æ’°å†™æœ¬æ–‡æ—¶ä½¿ç”¨çš„å®Œæ•´ä»£ç ï¼Œå¯ä»¥åœ¨ä¸‹é¢æ‰¾åˆ°:**

**[](https://github.com/egorhowell/Medium-Articles/blob/main/Data%20Science%20Basics/Hyperparameter_Tuning_With_Hyperopt.ipynb) [## Medium-Articles/Hyperparameter _ Tuning _ With _ hyper opt . ipynb at main egorhowell/Medium-Articles

### æˆ‘åœ¨æˆ‘çš„åª’ä½“åšå®¢/æ–‡ç« ä¸­ä½¿ç”¨çš„ä»£ç ã€‚é€šè¿‡åˆ›å»ºä¸€ä¸ªå…³äºâ€¦çš„å¸æˆ·ï¼Œä¸º egorhowell/Medium-Articles çš„å¼€å‘åšå‡ºè´¡çŒ®

github.com](https://github.com/egorhowell/Medium-Articles/blob/main/Data%20Science%20Basics/Hyperparameter_Tuning_With_Hyperopt.ipynb) 

æˆ‘è¿˜åˆ›å»ºäº†ä¸€ä¸ªæ›´æ–°ç‰ˆæœ¬(2022 å¹´ 9 æœˆ)ï¼Œæ‚¨å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°:

[](https://github.com/egorhowell/Medium-Articles/blob/main/Data%20Science%20Basics/Hyperparameter_Tuning_With_Hyperopt_V2.ipynb) [## Medium-Articles/Hyperparameter _ Tuning _ With _ Hyperopt _ v2 . ipynb at main egorhowell/Medium-Articles

### æˆ‘åœ¨æˆ‘çš„åª’ä½“åšå®¢/æ–‡ç« ä¸­ä½¿ç”¨çš„ä»£ç ã€‚é€šè¿‡åˆ›å»ºä¸€ä¸ªå…³äºâ€¦çš„å¸æˆ·ï¼Œä¸º egorhowell/Medium-Articles çš„å¼€å‘åšå‡ºè´¡çŒ®

github.com](https://github.com/egorhowell/Medium-Articles/blob/main/Data%20Science%20Basics/Hyperparameter_Tuning_With_Hyperopt_V2.ipynb) 

# å’Œæˆ‘è”ç³»ï¼

*   è¦åœ¨åª’ä½“ä¸Šé˜…è¯»æ— é™çš„æ•…äº‹ï¼Œè¯·åŠ¡å¿…åœ¨è¿™é‡Œæ³¨å†Œï¼T37*ğŸ’œ*
*   [*åœ¨æˆ‘å‘å¸ƒæ³¨å†Œé‚®ä»¶é€šçŸ¥æ—¶è·å–æ›´æ–°ï¼*](/subscribe/@egorhowell) ğŸ˜€
*   [*LinkedIn*](https://www.linkedin.com/in/egor-howell-092a721b3/)*ğŸ‘”*
*   *[*ç¢ç¢å¿µ*](https://twitter.com/EgorHowell) ğŸ–Š*
*   *[*github*](https://github.com/egorhowell)*ğŸ–¥**
*   **[](https://www.kaggle.com/egorphysics)**ğŸ…****

> ***(æ‰€æœ‰è¡¨æƒ…ç¬¦å·éƒ½æ˜¯ç”± [OpenMoji](https://openmoji.org/) è®¾è®¡çš„â€”â€”å¼€æºçš„è¡¨æƒ…ç¬¦å·å’Œå›¾æ ‡é¡¹ç›®ã€‚æ‰§ç…§: [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/#)*****