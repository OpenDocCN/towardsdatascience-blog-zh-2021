# 人工智能设计决策

> 原文：<https://towardsdatascience.com/ai-designs-decisions-1d2524589ad?source=collection_archive---------30----------------------->

![](img/c3837fab831820e41b8f79ba9942f0c8.png)

约书亚·苏考夫在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

## 人工智能决策的调查证据剖析

[哈夫洛克·埃利斯](https://www.britannica.com/biography/Havelock-Ellis)说，重要的不是目标的达成，而是途中遇到的事情。他在谈论哲学。在商业中，人工智能是关于目标实现的。一路上遇到的事情，都是决定。

这些决定是 Signal AI 最近对 1，000 名首席执行官进行的调查的焦点，旨在评估人工智能对美国经济的影响。根据这项调查，96%的商业领袖认为人工智能将改变决策，92%的人同意公司应该利用人工智能来增强决策过程。

艾不太确定。

## 大多数决策不是二元的

无论是调查还是业务主管都不能提供有关决策类型的信息。大多数受访者表示，他们每周在这个过程中花费超过 40 个小时。不足为奇:这大概是他们领薪水的原因，但 80%的领导者声称有太多的数据需要评估，高级管理层正在寻求缓解。AI 在图中的什么位置？

AI 渴望通过在决策阶段激励和指导组织来设定和实现目标。[四种决策](https://faculty.babson.edu/krollag/org_site/encyclop/parsons.html)是相关的。

*政策决策*包括选择追求什么目标以及如何实现这些目标。技术对公司的适当调整应该定义这些目标。AI 在这一步冒着失败的风险，因为他爱上了创意之火，没有认识到实用的指导方针。

目标应该很少，但不需要非常具体。剩余的可能性被抛弃了。目的分散是一种商业风险。人工智能擅长不适定问题，但众所周知，它会一直徘徊，直到它认为问题得到解决。

任何目标都必须用一个问题来定义。好的设计要求目标的确定应该导致对问题的理解。人工智能可能不擅长理解，但目标的实现被解释为一组解决方案。像任何好的公司故事一样，故事不能像增加额外收入那样泛泛而谈。必须包含一个转变的因素。

人工智能体现了变革，但还没有为政策决策做好准备。人工智能必须首先准备好自己定义问题。然而，这是一个可以实现的目标。例如，人工智能知道如何识别不良组件或不良行为，从而识别症状，进而提出问题。

接着是分配决策。实现目标需要在人员之间分配资源和责任。在帮助组织实现其目标的过程中，有些职位扮演着重要的角色。每个岗位都有特定的职能，企图为企业赚取利润。

一个职位必须解决一个问题。当有疑问时，回到目标设定作为政策决定。

人工智能可以为内部资源赋值，并智能地为项目分配类型和数量。AI 正在考虑接管项目管理的职责，这也符合目标实现功能。企业生活只应该这么简单。其自身角色的定义和人类角色分配的问题超出了当前的技术。然而，一些人力资源官员，如 IBM 的 Diane Gherson，正在基于生成性对抗网络的模型，松散地训练人工智能。

角色冲突是盲目的组织结构图的常见结果，这是非常人性化的发明。人工智能暴露在相互冲突的角色期望中，确保了出现与公司目标无关的问题。《2001:太空漫游》中哈尔的比喻占据了主流意识，尽管参考了科幻小说，但仍是问题的代表。妥协是一个谈判的问题，而不是组织结构图模板。否则，大赦国际将面临负面制裁和内部冲突。哈尔杀了(几乎)所有人。

人工智能承担多种角色，并可以对他们以及公司内其他人的分配进行排序。与他人的关系是由兴趣和取向控制的，这些兴趣和取向与人工智能的兴趣和取向以不同的方式交织在一起。这些差异通过对人工智能索赔的分配进行调整。排序是按照优先级、上下文和收益分配进行的。有些活动有合适的合作伙伴。其他人可能不太适合现有的伴侣、时间和空间。

人工智能角色系统的分配顺序得到了微妙的平衡。一个部分的任何重大改变都可能影响到其他部分，需要进行一系列的调整。人类的反叛随之而来。脆弱是决策过程的一个不良属性。

*协调决策*包括如何激励员工以及如何管理贡献。薪酬在内部商业计划的讨论中占主导地位。人工智能无法在一个更大的组织中用加薪和相对职位来吸引员工。人们必须接受这个概念，并以这样一种方式接受它，即心甘情愿地接受他们作为机器中杠杆的角色。

人工智能应该提供一种目标感。动机随之而来。

人工智能需要考虑目标实现的这一部分。社会关注人类失业，经济学家预计人工智能保护伞下的职业再培训。再培训在 T2 第一次工业革命中发挥了作用，但是历史记录显示了短期内的巨大痛苦。

## 当价值观到位时，决策更容易

人工智能在这里有自己的问题要问:是人类为人工智能重组决策，还是人工智能为公司组织流程？答案并不明显，但价值观的引入提供了指导。

*支撑价值观* 是那些为决策权合法化服务的价值观。这些价值观的定义和传播方式构成了第四套决策。将价值观纳入目标设定是一个不容错过的机会。

决策权提供了一种在不干扰整体公司文化的情况下，催生人工智能文化的手段。

稳定要求雇员的利益与共同的价值体系相一致。公司内部对人工智能行为的反应被构造成对系统忠诚的函数。从众作为实现目标的一种手段，与引起他人的有利反应和避免不利反应的条件相一致。

符合价值标准符合这些标准。从人工智能的角度来看，它是满足其需求的一种模式，也是优化企业内部决策者反应的一种条件。价值模式在人员互动的背景下被制度化。

将人工智能在决策中的作用制度化是公司的期望。

角色期望为人工智能的行为设定了标准。相对于其他人的反应，也有一系列的期望。后者是*制裁*，反过来可能是正面的，也可能是负面的。人工智能的区别在于它们是促进满足感还是剥夺行动。角色期望和制裁之间的关系是相互的。对 AI 的制裁是对公司的角色期望，反之亦然。

人工智能的决策角色是围绕整合了一套价值观的期望来组织的。同样的价值观支配着与人工智能互补角色的互动。角色期望和相应制裁的制度化是一个程度问题。制度化的对立面是规范秩序的彻底崩溃。这不可能发生。

## 调查作者有一个收获

人工智能在引导组织通过决策制定阶段时取得成功。这不应该与通过决策取得成功相混淆，也不应该与人工智能辅助增加过程中的细节相混淆。

这份声明一部分是希望，另一部分是恐惧。希望是调查传达的信息，但 Signal AI 首席执行官大卫·贝尼格森指出，商业领袖往往有不切实际的期望。“就像其他技术一样，他们在短期内高估了人工智能的影响，在长期内低估了它。”

决策的四个标准说明了所涉及的困难，而公司内部的期望在这幅画中表现突出。从这个意义上说，贝尼格森是正确的。然而，人工智能不像其他技术；这是第一次向员工提出生存挑战。随着人工智能转向决策，高级管理层也面临着这一挑战。

由于担心技术冲击和监管风险，员工集体低估了人工智能在短期内的影响，纷纷取消或推迟项目。它把一般人工智能的概念作为存在主义争论的核心特征，从而高估了长期影响。

人工智能只是一个婴儿，我们不相信婴儿的决定。他们打碎一路上遇到的东西。