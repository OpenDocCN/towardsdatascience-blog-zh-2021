# 作为用户体验挑战的人工智能伦理

> 原文：<https://towardsdatascience.com/ai-ethics-as-a-user-experience-challenge-ceb7abb3cd38?source=collection_archive---------24----------------------->

## [播客](https://towardsdatascience.com/tagged/tds-podcast)

## 温迪·福斯特在 Shopify 谈道德人工智能设计

[苹果](https://podcasts.apple.com/ca/podcast/towards-data-science/id1470952338?mt=2) | [谷歌](https://www.google.com/podcasts?feed=aHR0cHM6Ly9hbmNob3IuZm0vcy8zNmI0ODQ0L3BvZGNhc3QvcnNz) | [SPOTIFY](https://open.spotify.com/show/63diy2DtpHzQfeNVxAPZgU) | [其他](https://anchor.fm/towardsdatascience)

*编者按:TDS 播客由 Jeremie Harris 主持，他是数据科学导师初创公司 SharpestMinds 的联合创始人。每周，Jeremie 都会与该领域前沿的研究人员和商业领袖聊天，以解开围绕数据科学、机器学习和人工智能的最紧迫问题。*

人工智能伦理学通常被视为枯燥、抽象的学术课题。它没有那种一致的、统一的原则，你可能会从计算机科学或物理学这样的定量学科中期待这些原则。

但不知何故，道德橡胶必须符合人工智能的道路，而在这种情况下，真正的开发者必须与真正的用户打交道，并应用具体的道德原则，这就是你在这个主题上找到一些最有趣、最实用的想法的地方。

这就是为什么我想和 Shopify 的工程和数据科学总监温迪·福斯特(Wendy Foster)谈谈。温迪对人工智能伦理的方法是令人耳目一新的具体和可操作的。与更抽象的方法不同，它基于像用户授权这样的明确原则:即你应该避免强迫用户做出特定的决定，而是设计用户界面，将人工智能推荐的操作框定为可以忽略或采取行动的建议。

在这一集的 TDS 播客中，Wendy 和我一起讨论了她对人工智能伦理的实际观点，人工智能产品用户体验设计的重要性，以及负责任的人工智能如何在 Shopify 的产品中得到体现。

以下是我在对话中最喜欢的一些观点:

*   Wendy 的理念是打造尽可能将决策外包给用户的 AI 产品，给用户最大限度的代理。她并没有将推荐系统的输出框定为最优，而是更愿意将它们作为可以采纳或忽略的建议传达给用户。一种方法是依靠设计:例如，按钮颜色、阴影、文本字体和其他风格选择可以传达各种形式的不确定性。虽然实现各不相同，但这里的基本原则是用户授权和增强用户控制。
*   可解释性经常被吹捧为负责任的人工智能的一个重要因素，但温迪认为解释并不总是最好的方法。首先，解释必须适应最终用户:对 19 岁的技术人员有效的解释可能对 70 岁的人没有意义。解释往往是静态的:它们为用户从人工智能获得的输出提供了一个基本原理，但可解释的人工智能方案往往不会以一种让用户容易提出后续问题的方式运行。由于这个原因，温迪对观察越来越感兴趣，认为观察可以替代解释。在这种情况下，观察意味着让用户有机会以一种动手的方式与他们正在使用的输出算法进行交互。这给了他们调整某些参数的机会，让他们对人工智能有更好的感觉，并知道它会犯什么样的错误。
*   Shopify 能够采用这些策略的原因之一是，他们的用户群具有独特的企业家精神。Shopify 上的商家是那种喜欢建造东西并弄清楚系统工作方式的人，所以当他们看到一个可观察的人工智能机制时，或者当他们看到模糊的“建议”而不是清晰的“建议”时，他们不太可能被吓倒。但并非所有的用户群都是一样的，温迪很快指出，人工智能的伦理原则必须以用户为中心——也就是说，它们必须反映最终用户的特征作为出发点。

![](img/566c246ecb05afb1acd78baae0eff7e5.png)

## 章节:

*   0:00 介绍
*   1:40 温迪的背景
*   4:40 练习是什么意思？
*   14:00 不同层次的解释
*   19:05 信任系统
*   24:00 培训新人
*   30:02 公司文化
*   34:10 人工智能伦理的核心
*   40:10 与用户交流
*   44:15 总结