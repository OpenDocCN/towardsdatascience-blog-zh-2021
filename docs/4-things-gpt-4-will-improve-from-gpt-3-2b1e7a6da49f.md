# GPT 4 号将从 GPT 3 号改进的 4 件事

> 原文：<https://towardsdatascience.com/4-things-gpt-4-will-improve-from-gpt-3-2b1e7a6da49f?source=collection_archive---------2----------------------->

## 人工智能

## GPT 3 彻底改变了人工智能。GPT-4 也会这样做吗？

![](img/1b542476dadc380c0468074a23d2e540.png)

Robynne Hu 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

2020 年 5 月，OpenAI 在一篇名为 [*的论文中展示了 GPT-3，语言模型是很少尝试的学习者*](https://arxiv.org/abs/2005.14165) 。GPT-3，有史以来最大的神经网络，彻底改变了人工智能世界。OpenAI 发布了一个测试版 API 供人们使用，很快宣传就开始了。人们发现了疯狂的结果。GPT-3 可以将网页的描述转换成相应的代码。它可以[模仿人](https://twitter.com/jordanmoore/status/1285918878212792321)并写出定制的[诗歌](https://www.gwern.net/GPT-3#poetry)或[歌曲](https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/)。它可能会对未来或者生命的意义产生疑问。

它没有受过这方面的训练。GPT-3 在互联网上可用的大部分文本数据中接受过暴力训练。但是它并没有被明确地教导去做这些任务。这个系统如此强大，以至于它变成了一个元学习者。它学会了如何学习。用户可以用简单的自然语言与它交流；GPT 3 号将收到描述并认识到它必须完成的任务。

这是一年前。在过去的 3 年里，OpenAI 每年都会发布 GPT 模型。2018 年他们推出了 [GPT-1](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf) ，然后是 2019 年的 [GPT-2](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) ，最后是 2020 年的 GPT-3。按照这种模式，我们大概可以接近创造一个假设的 GPT 4。鉴于 GPT-3 能做的一切，以及它改变人工智能中一些范式的程度，问题是:我们能从 GPT-4 期待什么？让我们开始吧！

***免责声明:****【GPT-4】(还)不存在。接下来是根据我对 GPT 模型的了解，特别是对 GPT-3 模型的了解，对推测和预测的汇编，我在这篇长文《走向数据科学》中对其进行了汇编:*

</gpt-3-a-complete-overview-190232eb25fd> [## GPT-3 —全面概述

towardsdatascience.com](/gpt-3-a-complete-overview-190232eb25fd) 

# GPT 3 号很大。GPT 4 号会更大。原因如下

GPT 3 号不仅仅是大。有史以来最大的神经网络的名称非常模糊。它可能只是比其他模型大一点点。客观地看，GPT 3 号比它的前任 GPT 2 号大 100 倍，后者在 2019 年出现时已经非常大了。GPT-3 有 175 亿个参数，是最接近的竞争对手的 10 倍。

从 GPT-2 到 GPT-3 将参数数量增加 100 倍不仅带来了数量上的差异。GPT 3 号不仅仅比 GPT 2 号更强大，它更强大的方式也不同。这两种模式之间有一个质的飞跃。GPT 3 号可以做 GPT 2 号做不到的事情。从这个事实来看，有理由期待 OpenAI 继续这一趋势，使 GPT-4 明显大于 GPT-3，旨在找到新的质量差异。如果 GPT 3 号能学会学习，谁知道 GPT 4 号会带来什么。我们可能会看到第一个能够真正推理和理解的神经网络。

这些结果将进一步强化“越大越好”的观念。用 DeepMind 的研究员理查德·萨顿的话来说，“从 70 年的人工智能研究中，我们可以学到的最大教训是，利用计算的一般方法最终是最有效的，而且是最有效的。”他称这是人工智能的惨痛教训。我们将看到它是否能在未来继续存在。

# GPT-4 将执行更好的少数镜头多任务处理

GPT-3 在解决 NLP 任务方面给人留下了深刻的印象，如机器翻译，问题回答，或在少数镜头设置中的完形填空任务。然而，在零镜头设置中，它的性能并不好。期望 GPT 3 号在事先甚至没有看到一个例子的情况下解决一个它没有被训练过的任务，对它来说可能是过分的要求。即使是我们人类，也不能靠纯粹的直觉解决很多任务。我们有生活在这个世界上的优势，这个世界充满了丰富的背景，帮助我们驾驭现实。

GPT-3 的优势是少镜头多任务处理。OpenAI 的研究人员承认，少量注射的结果明显好于零注射的结果。正如 Rohin Shah 所言，“少击性能随着参数数量的增加而增加，并且增加的速度比零击性能的相应速度更快。”这意味着 GPT-3 是一个元学习者，模型越大，它的元学习能力越好。

如果我们假设 GPT-4 将有更多的参数，那么我们可以期待它是一个更好的元学习者。对深度学习系统的一个常见批评是，它们需要大量的例子来学习单个任务。GPT-4 可以证明，语言模型可以像我们一样从几个例子中学习多任务处理。GPT-3 可以“理解”它必须在没有被明确告知的情况下继续对话。我们只能想象 GPT 4 号能做什么。

# GPT-4 不会太依赖好的提示

OpenAI 于 2020 年 7 月发布了测试版 API playground，供外部开发者与 GPT-3 一起玩。该系统最强大的功能之一是我们可以用自然语言与它交流。我可以告诉 GPT-3:“下面是一个关于宇宙的故事，一个智者正在告诉一个小男孩。这个聪明人很好，乐于助人，对宇宙学和天文学也很了解，”这个系统会继续这个故事，而不用我明确地这么说。

但不仅仅如此。GPT-3 还会让聪明人很好地讲述故事，让他看起来像对宇宙很了解的 T2。它还会用*简单语言*写这个故事，因为这个男人在和一个小孩说话。GPT-3 将通过这句简单的话获得所有这些信息。任何人都可以推断出这一切，但人工智能呢？太不可思议了。科技博客作者 Gwern Branwen 在他的博客中有很多类似的例子。

Gwern 将这种与 GPT-3 *的交互方式称为提示编程*。我们可以给 GPT 3 号一个书面输入，它就会知道它必须执行哪个任务。提示可以包括一些明确的例子——一些镜头设置——来帮助系统。令人惊讶的是，只要用简单的英语告诉系统去做，这个系统就可以完成不同的任务，而这些任务从来没有被训练过。

然而，Gwern 警告说，这些测试的结果可能在质量上有所不同。原因是提示编程涉及到采样。而抽样可以“证明知识的存在但不能证明知识的不存在”。一个错误的提示会产生一个不好的结果，但是谁该负责任呢？GPT-3 还是那个写了错误提示的人？

这是一个问题，因为正如 Gary Marcus 所批评的，不知道提示何时会产生不好的结果凸显了系统的一个严重缺陷。格温认为，我们总是可以找到更好的提示，但是如果我们不能确定结果是否正确，那还有什么意义呢？为了找到系统的极限，如果提示不起作用，我们不应该放弃，只有在没有提示起作用的情况下。然而，这种方法的不可行性是显而易见的；我们不能测试每一个可能的提示。

这就是为什么我们需要让 GPT-4 对不良提示更加稳健。除非我们将即时编程标准化(这很可能在未来几年内完成)，否则人为错误将会存在，即使如此，这些系统的局限性也将与我们无法提取其真正潜力的能力密切相关。

一个真正的人工智能首先不应该如此依赖一个好的提示。我们人类也依靠“提示”，但是我们可以自我评估来发现问题。如果我在考试，练习的措辞很糟糕，这可能会让我困惑，但我可以意识到措辞不好，并问老师。GPT 3 号做不到这一点，它会试图在没有意识到任何事情的情况下执行任务。

GPT-4 可以实现一种评估给定提示质量的方法。到目前为止，这更像是科幻小说，而不是现实，但我们需要在未来记住这一点。一个不能自我评估的系统不能被称为智能的。如果 GPT-4 能像“我不知道”、“我不太相信我的答案”或“你的提示不是很清楚”这样表达怀疑和缺乏理解，那将是朝着这个方向迈出的一大步。

# GPT-4 将有一个更大的背景窗口

GPT-3 非常强大，但它的内存相当有限。一个人不会忘记昨天发生的事情。测试版 API 允许用户输入一个 500-1000 字长的文本——上下文窗口——供 GPT-3 使用。这意味着系统不能继续写一部写了一半的小说或者完成一个大程序的代码。

GPT 3 号完全不知道它的上下文窗口之外是什么。这种限制严重影响了少镜头设置，因为用户必须编写不同的示例。在问答中，这可能不是一个问题，因为它非常重复，但在其他任务中，如翻译文章，这是不可行的。GPT-4 也有这种局限性，但其有用性被缩小的程度肯定会减少。

可以说，一个更重要的问题是，即使我们可以用几百字的提示来表达我们的意图，GPT-3 也是一台健忘的机器。它发现很难在长文本中保持连贯。如果我们开始写一篇文章，并要求 GPT-3 无限期地继续下去，它最终会重复想法，甚至转向不相关的话题。

GPT-3 和以前基于变压器的模型都受到这种限制。变形金刚是 2017 年出现的仅基于注意力的“旧”架构——无卷积、无递归。已经有更好的方法来执行这些类型的任务。Gwern [认为](https://www.gwern.net/notes/Attention)有办法改善变形金刚的注意力缺陷。简单的变形金刚是创建超级强大的语言模型的一种方式，但可能不是唯一的方式，甚至不是最好的方式。(变压器架构的改进汇编可以在[这里](https://www.gwern.net/docs/www/arxiv.org/4b545d261b12d222fe71f312cc32d13bfa3e25cc.pdf#org=google&page=6)找到)。

这些想法可以在 GPT-4 中实现。它将享受更大的上下文窗口，并允许用户向系统提供书籍、长篇文章、图像、视频或音频。

# 结论

以下是我对 GPT 4 号将如何改进 GPT 3 号的预测:

*   GPT-4 将有更多的参数，它将被更多的数据训练，使它在质量上更强大。
*   GPT-4 在少拍场景下更擅长多任务处理。它在这些环境中的表现将更接近人类。
*   GPT-4 将更少依赖好的提示。它将对人为错误更加稳健。
*   GPT-4 将避免早期变压器架构的局限性。上下文窗口将会更大，允许系统执行更复杂的任务。