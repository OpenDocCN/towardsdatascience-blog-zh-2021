# 理解偏差:神经科学&伦理人工智能的关键理论

> 原文：<https://towardsdatascience.com/understanding-bias-neuroscience-critical-theory-for-ethical-ai-de7a31db6c05?source=collection_archive---------32----------------------->

## [公平和偏见](https://towardsdatascience.com/tagged/fairness-and-bias)

## 将批判理论框架应用于 AI 伦理学，同时使用神经科学来理解具有突触可塑性的**无意识偏见**。

![](img/e094e720f1b4ba7f21ae5989ae792c5d.png)

照片由[乔希·里默尔](https://unsplash.com/@joshriemer?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 拍摄

一年前，当讨论面部识别中存在的种族偏见时，人工智能先驱严乐存在推特上引起了争议，“当数据有偏见时，ML 系统就会有偏见”([来源:推特](https://twitter.com/ylecun/status/1274782757907030016))。这激起了人工智能伦理研究员 Timnit Gebru 的回应，她对这个问题过于简单的框架表示失望，这是基于她在人工智能伦理方面的专业知识的观点([来源:Twitter](https://twitter.com/timnitgebru/status/1274809417653866496?lang=en) )。Gebru 的回答和随后的对话被主流媒体放大，虽然这确实在人工智能社区引发了更广泛的偏见讨论，但媒体的焦点是 Lecun 选择如何(错误)沟通。

抛开诚意不谈，乐存的道歉([来源](https://syncedreview.com/2020/06/30/yann-lecun-quits-twitter-amid-acrimonious-exchanges-on-ai-bias/))让我想起了奥德·洛德关于内疚的想法，

> “太多时候，它变成了一种保护无知和事物延续现状的手段，是对永恒性的终极保护。”([洛德，1981](https://www.blackpast.org/african-american-history/speeches-african-american-history/1981-audre-lorde-uses-anger-women-responding-racism/) )。

关于被边缘化的人应该负责教育他人偏见的合理期望，Lorde 说，

> “我们的精力不断流失，而这些精力本可以更好地用来重新定义我们自己，并设计出改变现在、建设未来的现实情景。”([洛德，1980](https://www.colorado.edu/odece/content/women-redefining-difference) )。

我和格布鲁一样沮丧。社会偏见渗透到人工智能的每一个方面，从数据集，研究环境，甚至从业者本身。一个公平的未来取决于我们创造道德人工智能的能力；因此，我认为批判性地反思*的偏见是很重要的——尽管这在情感上是多么困难，尽管没有简单的答案。此外，讨论偏见而不解决社会和结构问题是一种空洞的、最终毫无意义的努力。因此，我寻求将[批判理论](https://en.wikipedia.org/wiki/Critical_theory)与神经科学相结合，以理解无意识偏见，并绘制出一条通往伦理人工智能的道路。*

在一个由两部分组成的系列中，我从神经科学、遗传学、心理学、批判理论、语言学、数学和教育学等不同领域中汲取经验，阐述我的观点，即人工智能伦理学可以受益于结合各种学科的非常规方法。这第一篇文章使用神经科学来理解无意识偏见，同时与人工智能建立直接联系，所有这些都在一个关键的理论框架内。第二篇文章探索了关于神经科学的学习，并提出了一个基于关键理论的因果关系观点，允许讨论神经符号人工智能，作为一种潜在实现机器正念的方式。

在这里，我从批判理论开始，并将该领域与 STEM 学科进行对比，以表明人工智能从业者可以从交叉性的思考中受益。接下来，我将简要介绍神经科学，并强调特定子学科之间的重要差异以及它们与人工智能的关系。这直接导致了对突触可塑性的讨论，这为讨论本文的中心话题无意识偏见奠定了基础。接下来，我用批判理论解决了数据集中的偏见问题。最后，我回到我以前的语言学系列([第 1 部分](https://medium.com/swlh/what-is-natural-about-nlp-af31eb9cf354) & [第 2 部分](/from-natural-to-artificial-language-b59f5e00ba74))，并使用人工智能语言模型中的偏见作为一个实际例子来展示神经科学和批判理论与人工智能伦理的联系。

## **批判理论与人工智能伦理**

很久以前，我被介绍给那些帮助我形成对世界的看法的作家:奥德·洛德、玛娅·安杰洛、贝尔·胡克、奥克塔维亚·巴特勒和安吉拉·戴维斯。我相信我姐姐的影响；与此同时，她也分享了批判理论家的作品，如弗朗兹法农，爱德华·萨义德，保罗·弗莱雷和米歇尔福柯。虽然批判理论有时被狭隘地定义为法兰克福学派，但我支持批判理论的更广泛的观点，其中学科的目的是旨在减少压迫和增加自由的社会调查。引用福柯的话来说，这需要挑战传统的权力结构，

> “批判并不在于说事情不像现在这样好。它在于看清公认的做法是基于什么样的假设、熟悉的概念、既定的和未经检验的思维方式……进行批评就是使那些现在太容易的行为变得更难。”([福柯，1982](https://philpapers.org/rec/FOUIIR) )。

STEM 学科中流行的态度要么是对批判理论的无知，要么是对批判理论的蔑视；这个领域被普遍认为在智力上不如纯科学。流行的观点包括宣称“事实胜于感觉”的优越性。考虑非经验主义主张的价值已经变得激进，数据的缺乏足以成为否定整个学科的理由。我不同意这种观点，而是选择接受批判理论有价值的激进观点，特别是在涉及到人工智能新兴领域的发展时。具体来说，创造道德人工智能的尝试将受益于对交叉性的理解([克伦肖，2017](https://scholarship.law.columbia.edu/books/255/) )。偏见不仅仅是种族主义、性别不平等或宗教不容忍，它是所有形式的偏见相互作用的结果。

1989 年，金伯利·克伦肖创造了“交叉性”这个术语，试图描述社会身份相互作用的复杂方式。如今，这一含义被那些受到当前社会等级丧失威胁的人扭曲了，被嘲笑和斥为“身份政治”。然而，根据克伦肖自己的说法，

> “一个透镜，一个棱镜，让我们看到各种形式的不平等是如何相互作用、相互加剧的。我们倾向于将种族不平等与基于性别、阶级、性取向或移民身份的不平等区分开来。人们经常忽略的是一些人是如何受到所有这些的影响，而这种体验不仅仅是其各个部分的总和。”([来源](https://time.com/5786710/kimberle-crenshaw-intersectionality/))。

人工智能已经在许多人生活的许多方面交织在一起；这是一个不断增长的趋势，因为人工智能的使用在各个行业都在增加。在 2018 年的一本书中，*人工智能超级大国:中国，硅谷和新的世界秩序，*人工智能先驱和风险投资家李开复将人工智能的现状描述为处于“实施时代”。在谈到人工智能的潜在危害时，李开复说，

> “[b]将它们推向市场不需要人工智能研究的重大新突破，只需要日常实施的具体工作:收集数据、调整公式、在实验和不同组合中迭代算法、制作产品原型，以及对商业模式进行实验。”([李，2018](https://en.wikipedia.org/wiki/AI_Superpowers) )。

李对人类与人工智能共存的愿景是基于促进彼此的爱；他建议将爱作为设计社会项目的蓝图，以对抗人工智能未来的生存威胁。虽然我同意爱情的重要性，但我认为他的观点所缺乏的是对当前对我们共同人性的生存威胁的理解，这种根深蒂固的系统性和结构性不平等正是人工智能产生的根源。

伦理人工智能需要不仅仅是确保像 GPT-3 这样的语言模型不会反刍种族主义文本，或者面部识别可以识别不同的面孔。一个鼓舞人心的例子是强有力的纪录片 [*《编码偏见*](https://www.codedbias.com/) ，它始于 Joy Buolamwini 和 Timnit Gebru 撰写的一篇论文，题为“ [*性别阴影:商业性别分类的交叉准确性差异*](http://proceedings.mlr.press/v81/buolamwini18a.html) ”。交叉性和批判理论的影响贯穿整部电影。这一点在让所有利益相关方参与进来的努力中尤为明显，尤其是那些目前受到面部识别技术负面影响的利益相关方。重要的是，研究人员咨询了受影响的人，并将他们纳入了围绕伦理人工智能的讨论。更重要的是，这项工作正在持续进行，并朝着[让研究变得可及](http://gendershades.org/)的方向不断努力，我希望所有参与人工智能伦理的研究人员和组织都能采用这种方法。

整个人工智能行业、政府，尤其是人工智能从业者，应该提出交叉性的问题。问题如:*谁研究、构建和教授 AI？谁能接触到，谁从中获利，谁的工作被 AI 服务取代？谁生产，谁拥有用于构建人工智能的数据？谁控制着 AI 所需的基础设施？*。更广泛地说，*谁对艾的意见被听到了？谁来决定围绕 AI 的法律，谁来执行这些法律？哪些国家有能力研究或建设人工智能，它将被部署在哪里？哪些国家的经济会因 AI 而受益或受损？*。这些问题仅仅触及了表面，但目前那些有能力实施变革的人并没有讨论这些问题。

理解交叉只是朝着正确方向迈出的一步；然而，这是一个包括所有人在内的容易实现的目标。[女权主义者。AI](https://www.feminist.ai/) 是一个通过交叉女权主义参与进来的组织，致力于让每个人都能接触到 AI——他们的[资源页面](https://www.feminist.ai/resources)是一个开始学习的好地方。他们推荐的一些书籍包括:萨菲亚·乌莫哈·诺布尔的 [*压迫算法*](https://en.wikipedia.org/wiki/Algorithms_of_Oppression) 、凯茜·奥尼尔的 [*数学毁灭武器*](https://en.wikipedia.org/wiki/Weapons_of_Math_Destruction) 以及鲁哈·本杰明的 [*科技之后的种族*](https://www.ruhabenjamin.com/race-after-technology) 。当前的数据科学、机器学习和人工智能教育计划将受益于将这些材料纳入他们的课程，为学生提供人工智能伦理的交叉框架。我不自称在批判理论或交叉性方面有专长，但这些想法是帮助我批判性思考人工智能的基础。作为起点，交叉性提供了希望，随着人工智能的发展，我们不会把那些拥有最少而可能受益最多的人抛在后面。如上所述，接下来的两个部分介绍了神经科学和无意识偏见，然后在最后两个部分回到批判理论，进一步讨论人工智能的发展和伦理。

## **神经科学:精选分支学科概述**

神经元是构成人脑结构的细胞单位，这是 Santiago Ramón y Cajal 在 19 世纪 80 年代发现的事实( [Rapport，2006](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1472722/) )。目前认为，人类大脑包含大约 860 亿个神经元，每个神经元大约有 10，000 个突触——这些可以被认为是神经元之间的连接。这篇来自《约翰·霍普斯金医学》的[有用文章](https://www.hopkinsmedicine.org/health/conditions-and-diseases/anatomy-of-the-brain)提供了一个大脑解剖和功能的简单概述。为了便于理解，本文中介绍的所有神经科学概念都将有足够详细的解释，以保证没有技术复杂性的理解。

在最简单的层面上，[神经科学](https://en.wikipedia.org/wiki/Neuroscience)是对神经网络如何工作的研究，与研究大脑疾病的神经学形成对比。神经科学有几种类型或子学科，这里我重点介绍与人工智能最相关的三种:[系统神经科学](https://en.wikipedia.org/wiki/Systems_neuroscience)、[认知神经科学](https://en.wikipedia.org/wiki/Cognitive_neuroscience)和[计算神经科学](https://en.wikipedia.org/wiki/Computational_neuroscience)。系统神经科学与[系统生物学](https://en.wikipedia.org/wiki/Systems_biology)相关，后者涉及复杂生物系统的计算和数学建模。因此，系统神经科学包括在分子和细胞水平上研究大脑，然后将这种理解与认知功能(如记忆存储和语言)联系起来。这一分支学科对人工智能很有用，因为它采用了研究物理大脑的方法来理解思维，例如，大脑的物理结构如何与意识相关联。

认知神经科学采取了相反的方法，它受心理学的影响很大，并依靠理解心灵(认知)来帮助理解大脑。例如，它采用记忆的心理学分类，通过使用[情景](https://en.wikipedia.org/wiki/Episodic_memory)、[语义](https://en.wikipedia.org/wiki/Semantic_memory)和[程序](https://en.wikipedia.org/wiki/Procedural_memory)记忆的定义。关于人工智能，一个关键的概念是[意识的神经关联](https://en.wikipedia.org/wiki/Neural_correlates_of_consciousness)，它可以被定义为与特定意识体验相关的大脑活动的特定模式。例如，考虑[强化学习](https://en.wikipedia.org/wiki/Reinforcement_learning)，决策的神经关联表明，大脑的[额叶皮层](https://en.wikipedia.org/wiki/Frontal_lobe)通过添加情景记忆的上下文进行干预，这样决策就受到了过去事件的影响。认知神经科学也与符号人工智能领域直接相关，其中智能被设计为根据因果规则通过逻辑运算操纵符号。

除了认知神经科学，符号 AI 植根于数学的哲学；它遵循基于逻辑主义的观点，即人类的认知是通过形成内部符号表示和创建处理这些概念的规则来实现的。所以，有了符号化的 AI，机器认知就是以一种机器拥有世界知识的方式，将这些因果规则形式化的结果。作为一名哲学家和数学家，伯特兰·罗素是逻辑主义的坚定捍卫者，他认为数学可以还原为逻辑。符号逻辑的建立可以归功于罗素；1910 年，他出版了《数学原理》，提出了一个公理系统，所有的数学都可以建立在这个系统上。

二十年后，库尔特·哥德尔提出了他的[不完全性定理](https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorem)，证明了任何原始递归算法系统都有极限。本质上，哥德尔证明了不可能使用符号逻辑来创造一套完整一致的公理来对世界进行建模。这一缺陷延伸到符号人工智能，它在 20 世纪 50 年代和 80 年代流行，但在很大程度上被放弃，转而支持神经元的连接主义观点。神经网络。从符号人工智能向神经网络的转变反映在神经科学中，认知神经科学在 1985 年被计算神经科学的新分支超越。

虽然哥德尔的不完全性定理可以作为符号 AI 对于认知不足的数学基础，但我们仍然没有正式的数学理论来解释神经网络在实践中为什么有效。因此，计算神经科学的重要性；这个领域寻求用数学模型来理解不仅仅是认知，还有大脑的结构和发展。在这个分支学科中，有兴趣开发突触可塑性现象的数学模型，这是理解无意识偏见所需的关键神经科学概念。接下来的部分涵盖了这一点，本系列的[第二篇文章](https://medium.com/@haaya-naushan/mindful-machines-neuroscience-critical-theory-for-ethical-ai-4162ebdcc334)更详细地涵盖了计算神经科学。

## **突触可塑性和无意识偏向**

突触可塑性，有时也被称为神经可塑性，由唐纳德·赫布于 1949 年首次提出([来源](https://qbi.uq.edu.au/brain-basics/brain/brain-physiology/what-synaptic-plasticity))。这个想法是神经元之间的突触连接能够改变；这种灵活性很重要，因为活动的变化决定了突触连接的强度。突触之间的现有连接可能会消失或变得沉默。此外，新的连接可以在一对神经元突触之间的新位置形成。这意味着生物神经网络的网络结构是动态的，突触之间的连接表现出时间可塑性。

有趣的是，学习是通过调整突触连接的强度来实现的，这个想法将在本系列的第二篇文章中深入探讨。这里，突出的一点是，突触可塑性可以被视为神经元在学习过程中的适应。与此相关的是，Hebb 试图通过理论化的方法来解释突触可塑性，即突触效能的增加源于突触前细胞对突触后细胞的重复和持续刺激( [Choe，2014](https://link.springer.com/referenceworkentry/10.1007%2F978-1-4614-7320-6_672-1) )。更正式地说，Hebbian 学习理论是这样一种原理，即一个突触前神经元 A，如果在它本身(神经元 A)活跃时成功地重复激活一个突触后神经元 B，将逐渐变得更有效地激活神经元 B ( [Hebb，1949](https://www.taylorfrancis.com/books/mono/10.4324/9781410612403/organization-behavior-hebb) )。

短期突触可塑性是指在亚秒时间尺度上发生的突触强度变化，例如强度快速增加或减少，随后连接恢复正常。另一方面，长期突触可塑性可以持续几分钟到几年，并代表了大脑将信息存储为记忆的方式([来源](https://qbi.uq.edu.au/brain-basics/brain/brain-physiology/what-synaptic-plasticity))。在去年发布的一本神经科学书籍: [*Sway:解开无意识偏见*](https://www.goodreads.com/book/show/49678279-sway) 中，Pragya Agarwal 用长期突触可塑性来解释无意识偏见。在《科学美国人》 [*、*](https://blogs.scientificamerican.com/observations/what-neuroimaging-can-tell-us-about-our-unconscious-biases/) 发表的一篇评论文章中，Agarwal 写道:

> “刻板印象等社会态度和期望会改变大脑处理信息的方式，因此基于大脑的行为特征和认知技能的差异会随着时间、地点和文化的变化而变化。这意味着我们的无意识偏见并不是天生的。它们是通过我们的经验习得的，因此也可以不学。”([阿加瓦尔，2020](https://blogs.scientificamerican.com/observations/what-neuroimaging-can-tell-us-about-our-unconscious-biases/) )。

Agrawal 使用神经成像研究来支持她关于无意识偏见的说法，具体来说，最近的[fMRI](https://en.wikipedia.org/wiki/Functional_magnetic_resonance_imaging)研究表明，人们在对熟悉和陌生的情况进行推理时使用了大脑的不同区域。该研究指出了大脑的两个特定部分，即[杏仁核](https://en.wikipedia.org/wiki/Amygdala)和[前额叶皮层](https://en.wikipedia.org/wiki/Prefrontal_cortex)，这两个部分都对刻板印象做出反应。Agrawal 解释说，当遇到一个新的人时，我们会迅速“将行为转化为带有可识别信息的神经信号，以形成对他们的印象”。当这种情况发生时，在潜意识层面，前额叶皮层同时监控来自我们所有感官的神经信息，与社会规范或个人偏好联系起来。这意味着有意识的大脑会形成不完整的解释，并且经常会包含某种偏见，也就是说，我们的社交、记忆和经历会产生无意识的偏见。

杏仁核对于理解偏见非常重要，因为它会无意识地标记传入的刺激，因此人们会迅速将他人归类为"*像我*和*不像我"*。Agrawal 声称这是偏见和歧视的根源，这意味着固型激活了大脑中与威胁和恐惧相关的部分(杏仁核)。更具体地说，fMRI 数据显示，当人们看到“与自己不同种族背景的人的面部图像时，往往比看到相同种族的人更容易激活杏仁核。”。此外，研究表明，“群体外的负面偏见甚至比群体内的同理心更加突出。”([来源](https://blogs.scientificamerican.com/observations/what-neuroimaging-can-tell-us-about-our-unconscious-biases/))。

虽然神经成像清楚地表明无意识偏见与杏仁核和前额叶皮层都有关，但突触可塑性提供了一种解决这两个区域偏见的方法。阿格拉瓦尔强调的要点是:就像无意识偏见是后天习得的一样，它也可以是后天习得的。在本系列的第二篇文章中，我回到了这个想法，在那里我将突触可塑性与正念冥想联系起来，提出了一种可以在机器中消除无意识偏见的方法。接下来的两节提供了偏见和人工智能发展的关键理论框架。

## **数据集偏差和人工智能开发**

Borealis AI 的产品总监凯瑟琳·休姆(Kathryn Hume)提供了一个很好的理由来批判性地思考关于人工智能发展的无意识偏见。她说

> “算法就像折射人类偏见的凸面镜，但以一种相当生硬的方式进行。他们不允许像那些我们经常用来维持我们的社会的礼貌小说”([来源](https://venturebeat.com/2019/11/15/probeat-algorithms-are-like-convex-mirrors-that-refract-human-biases/))。

她进一步警告说，

> “我们需要小心，因为如果我们没有很好地设计这些系统，它们将会对数据进行编码，并可能放大当今社会存在的偏见。”([来源](https://venturebeat.com/2019/11/15/probeat-algorithms-are-like-convex-mirrors-that-refract-human-biases/))。

当严乐存提出人工智能中的偏见源于数据中的偏见时，他暗示数据本身是客观的，一个平衡的和种族代表性的数据集将解决这个问题。如前所述，这是一个有问题的方法，因为它天真地忽视了系统和结构的偏见。尽管如此，它提供了一个机会来更深入地挖掘数据应该被视为客观的观点。在 [*被压迫者教育学*](https://en.wikipedia.org/wiki/Pedagogy_of_the_Oppressed) 中，保罗·弗莱雷暗示，主体性在改变权力结构的斗争中发挥着作用。弗莱雷指出，“没有主观性，就无法想象客观性。两者都不能脱离对方而存在，也不能一分为二。”；他提出了一种“主观和客观处于不断的辩证关系中”的方法(“T10”Freire，1970 )。

数据主观性的一个令人信服的例子是由 Northpointe 创建的用于评估被告再犯风险的 [COMPAS(替代制裁的矫正罪犯管理概况)](https://en.wikipedia.org/wiki/COMPAS_(software))软件。2016 年 [ProPublica 的一项研究](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm)揭露了算法中编码的种族偏见；该软件更有可能对黑人产生 1 型错误(假阳性)，对白人产生 2 型错误(假阴性)。这意味着黑人被告被错误地分配了比白人被告更高的分数，因此在预测暴力犯罪的风险时，该算法的准确率只有 20%([来源](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing))。COMPAS 是一种专有软件，算法的工作原理被视为商业秘密，这意味着该软件相当于一个黑匣子。假设这些算法是在一个平衡的、具有种族代表性的数据集上训练的，这将强调一点，即简单地将有色人种包括在数据集中并不能解决偏见的问题。

然而，清楚的是，当累犯风险评估工具基于诸如“你的父母之一曾经被送进过监狱吗？”([来源](https://www.documentcloud.org/documents/2840784-Practitioner-s-Guide-to-COMPAS-Core.html#document/p30/a296482))，偏差问题延伸到数据之外。Northpointe 的创始人、前统计学教授蒂姆·布伦南(Tim Brennan)声称，很难构建一个不包括与种族相关的项目的分数，他说，“如果这些项目从你的风险评估中被忽略，准确性就会下降”([来源](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing))。根据 Northpointe 的披露，他们的 COMPAS 数据涵盖了贫困、失业和社会边缘化([来源](https://www.documentcloud.org/documents/2840784-Practitioner-s-Guide-to-COMPAS-Core.html#document/p30/a296482))。

这些社会问题与结构性和系统性种族主义密不可分；事实上，监狱作为一种制度和犯罪本身的定义，有着种族主义的历史。革命的书里，“ [*监狱过时了吗？*](https://www.penguinrandomhouse.com/books/213837/are-prisons-obsolete-by-angela-y-davis/) ”，安吉拉·戴维斯考察了美国奴隶制和早期监狱系统之间的历史联系。她指出，从历史上看，在美国，种族一直在构建犯罪推定中发挥着核心作用，

> 奴隶制废除后，前蓄奴州通过了新的立法来修改奴隶法典，以类似奴隶制时期的方式来规范自由黑人的行为。([戴维斯，2003 年](https://www.penguinrandomhouse.com/books/213837/are-prisons-obsolete-by-angela-y-davis/))。

Brennan 和 Northpointe 忽略了历史和当前的现实，主观地选择了数据，从而产生了编码和传播社会不公的算法。因此，将数据视为客观忽略了根深蒂固的有问题的偏见。

因此，在实践中，在收集手段、框架、包容性措施、问题的适当性、质量标准以及最重要的结构性和系统性压迫的存在方面，数据应被视为主观的。为了支持这样的调查，麻省理工学院和 MILA 大学的研究人员创建了一个数据集，用来测量人工智能语言模型中的刻板印象偏见。 [StereoSet](https://stereoset.mit.edu/) 提供了一种测量语言模型对与种族、性别、宗教和职业相关的刻板印象的偏好的方法，同时确保所使用的去偏置技术不会对潜在的模型性能产生负面影响。本文的最后一节继续讨论人工智能语言模型中的偏差；然而，请注意，这种偏见存在于所有类型的人工智能中，这些模型只是一个例子。

## **人工智能语言模型和语言偏见**

我对自然语言处理(NLP)有着浓厚的兴趣，并且我一直在与人工智能语言模型中的偏见问题进行直接斗争。这场斗争促使我在今年早些时候写了两篇文章，使用语言学理论来探索人工智能语言模型。[第一篇](https://medium.com/swlh/what-is-natural-about-nlp-af31eb9cf354)对比了[语言相对论](https://en.wikipedia.org/wiki/Linguistic_relativity)和[语言普遍性](https://en.wikipedia.org/wiki/Linguistic_universal)，以更好地理解指导语言模型发展的哲学。在第一篇文章的前面，我提到了谷歌如何解雇 Timnit Gebru，因为他研究人工智能语言模型的社会和环境影响。我的第二篇关注语言学的文章直接讨论了偏见的问题；作为一个实际的例子，我主要关注令人印象深刻的大型 [GPT-3 模型](https://en.wikipedia.org/wiki/GPT-3)。引用最初的 GPT-3 论文，“[ *GPT-3* ]保留了它被训练的数据的偏差。…这可能导致模型产生刻板印象或偏见的内容”。

我目前的观点是，人工智能语言模型中的偏见不仅仅是数据，结构也很重要；具体来说，语言的结构很重要。通过研究经济不确定性，我偶然发现了沃尔夫社会经济学，康奈尔大学的托马斯·佩平斯基教授将其描述为，

> “一个新兴的跨学科研究领域，认为语言结构解释了跨社区的信仰、价值观和观点的差异”( [Pepinsky，2019](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3321347) )。

当文本被用于经济分析时，经济语境中的相关性是理解语言所带来的不确定性。M. Keith Chen ( [2013](https://www.aeaweb.org/articles?id=10.1257/aer.103.2.690) )在*美国经济评论*上的先前研究也表明语言对经济行为有影响。陈认为，一种语言的未来和现在的语法联系会影响一个人的储蓄习惯([陈，2013](https://www.aeaweb.org/articles?id=10.1257/aer.103.2.690) )。经济研究的当前趋势包括采用机器学习技术；我本人写过经济学的因果 ML，这里[这里](/causal-machine-learning-for-econometrics-causal-forests-5ab3aec825a7)和[这里](/causal-ml-for-data-science-deep-learning-with-instrumental-variables-96e5b7cc0482)。更重要的是，NLP 对经济学非常有用；因此，语言结构的重要性直接关系到人工智能对经济学的有用性。

撇开经济学不谈，既然语言的结构具有相关性，那么将语言学应用于人工智能的发展是很自然的。伦斯勒理工学院认知科学系的研究人员最近出版了一本名为“*人工智能时代的语言学”*的书，该书专注于自然语言理解的语言学方法(NLU)。令人惊讶的是，作者 Marjorie McShane 和 Sergei Nirenburg 已经开源了整本书，这本书可以在麻省理工学院出版社网站上获得。作者声称，歧义是 NLU 的一个障碍，人类的方法是利用上下文来解读单词背后的意思。然而，当前的 NLP 范式是使用非常大的数据集和单词序列之间的统计关系来确定上下文，这种方法不能捕获含义。此前，在 AI 语言模型出现之前，包含词汇结构和本体的基于知识的系统用于向机器解释语言。不幸的是，这种类型的知识工程有很高的资源成本；因此，缺乏对意义的理解的替代统计方法流行起来。"修行者的行为就好像文字足以代表他们的意思，但事实并非如此."，批判麦克沙恩([来源](https://venturebeat.com/2021/07/18/natural-language-understanding-tough-for-neural-networks/))。

她还声称，“在其发展的这个阶段，神经科学无法为我们承担的认知模型类型和目标提供任何令人满意的(句法或结构)支持。”。也许这是 NLU 的真实情况；然而，语言结构、突触可塑性和无意识偏见之间的联系提供了关于语言在人工智能模型中偏见编码中所起作用的见解。假设语言结构包含偏见的表达，假设这种结构直接影响大脑活动(例如，储蓄习惯)，那么操纵突触可塑性可以提供一种解决人工智能语言模型中编码的偏见的方法就不难了。在本系列的第二篇文章中，我从多个角度探讨了这个观点。

## **最后的想法**

批判理论可以帮助人工智能实践者认真思考人工智能伦理，神经科学可以提供对偏见问题的神经洞察力。简单来说，系统神经科学依赖于生物学，认知神经科学依赖于心理学和符号逻辑，计算神经科学以对生物神经网络的定量理解为中心。相关地，可以说人工神经网络(AI)的目标是在设计和功能上模仿生物神经网络。为此，突触可塑性提供了一种理解生物神经网络的方法，其机制可以扩展到改进人工神经网络。

因此，在这个系列的[第二部分](https://medium.com/@haaya-naushan/mindful-machines-neuroscience-critical-theory-for-ethical-ai-4162ebdcc334)中，我将人类学习与机器学习进行了对比，并讨论了[层次结构](https://en.wikipedia.org/wiki/Heterarchy)的概念，以将批判理论与认知联系起来。然后，我将重点放在将突触可塑性与正念冥想联系起来，这让我能够探索从错误中学习是可能的这一想法。最后，我回到符号人工智能，并介绍神经符号人工智能的新领域，它是融合不同学习范式的混合方法的代表。这为从批判理论的角度讨论因果关系创造了空间，连接到用有意识的机器创造有道德的人工智能的主要目标。

如果读者对将交叉性融入人工智能伦理学的进一步材料感兴趣，我再次推荐以下书籍:萨菲亚·乌莫哈·诺布尔的 [*【压迫算法】*](https://en.wikipedia.org/wiki/Algorithms_of_Oppression)；凯茜·奥尼尔的 [*【数学毁灭武器】*](https://en.wikipedia.org/wiki/Weapons_of_Math_Destruction) 和鲁哈·本杰明的*【科技之后的种族】* 。

对本系列提到的话题感兴趣的读者可以在 [Linkedin](https://www.linkedin.com/in/haaya-naushan-a4b5b61a5/) 上与我联系。我欢迎提问和反馈。