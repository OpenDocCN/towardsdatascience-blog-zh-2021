# 人工智能不是“可怕的聪明”，而是盲目的危险

> 原文：<https://towardsdatascience.com/ai-isnt-scary-smart-but-mindlessly-dangerous-e2642fa2aec6?source=collection_archive---------9----------------------->

## 人工智能|新闻|观点

## 前谷歌高管说我们在“创造上帝”——但他错了。

![](img/efd19081d19d88c15fbf20f3a5c4e0a5.png)

何塞·安德烈斯在 [Pixabay](https://pixabay.com/es/) 上拍摄的照片

人工智能中有很多分裂的事情。有可能用当前的范式创造智能机器吗，或者我们应该根据认知科学的发现更新指导人工智能研究的原则吗？我们应该继续利用深度学习的前景，还是应该使用混合方法向机器灌输知识和数据？我们应该期待更大的模型产生越来越好的结果，还是需要算法突破来引领人工智能的下一阶段？

这些问题描绘了人工智能的现在和未来，但只有少数人关心寻找答案。然而，人工智能的另一个方面应该会困扰我们所有人。包括你。它将以这样或那样的方式影响尚未被书写的历史。我说的是 AI 的风险和危险。奇怪的是，尽管这个问题很紧迫，甚至在这方面专家们也没有就什么是最紧迫的问题达成一致。

人工智能在我们的日常生活中根深蒂固，以至于任何不熟悉这个话题的人肯定会低估它的程度。[智能手机中的个人助理](https://techresearchonline.com/blog/best-ai-assistant-of-2021/#What_is_an_AI_assistant?)；[机场和街道上的监视和控制装置](https://carnegieendowment.org/2019/09/17/global-expansion-of-ai-surveillance-pub-79847)；[客服中的友好聊天机器人](https://www.intercom.com/blog/customer-service-chatbots/)；[影响你职业前途的招聘算法](https://www.vox.com/recode/2019/12/12/20993665/artificial-intelligence-ai-job-screen)；推荐系统，决定你看的电影和购买的产品；[知道你是谁，你长什么样的检测识别软件](https://www.nytimes.com/wirecutter/blog/how-facial-recognition-works/)；在不久的将来，准智能汽车将使驾驶变得过时。

人工智能的无处不在加深了任何潜在的错位，这可能会对我们生活的许多方面产生影响。已经发生了。人工智能专家正在努力提高这些系统的安全性、可靠性和可解释性。他们押注于不伤害少数群体、不传播错误信息的道德人工智能。他们试图为蓝领和白领行业的劳动力面临的迫在眉睫的损失寻找解决方案。但即使在这个极其关键的问题上，也不是每个人都在同一条船上。有些人认为我们应该更关心控制超级智能的潜在出现。谷歌 X 的前 CBO 莫·格达特就是其中之一。这就是为什么我们应该对他的恐惧和警告半信半疑。

# 我们在建造上帝吗？

莫·格达害怕艾。他最近出版了一本名为《可怕的聪明》的书，在书中，他警告我们，即将到来的世界末日只有我们能够阻止。在《泰晤士报》的采访中，他回忆起他意识到人工智能将会是我们的败笔的那一刻。在 Google X 的一个项目中，开发人员试图教会机械臂捡球。经过数周的缓慢进展，其中一只手臂伸到了球上，举起手向镜头展示，好像在“炫耀”——在任何了解 AI 工作原理的人看来，这只是拟人化的又一个例子。那一刻让他意识到“真的很可怕”

Gawdat 想知道为什么几乎没有人谈论这个。在[与作家兼技术从业者肯·雅莫什的对话](https://youtu.be/cc6KgUifWRw)中，Gawdat 总结了他对人工智能生命周期所处阶段的看法:“人工智能不再是一台机器，”他说。“我们正在建造一个……数字生物，它……拥有构成有意识生物的所有特征。所以它是自主的，进化的，它有智能，它发展智能…它自我复制…而且它有代理。”

“我们在建造上帝。”

这样一个大胆的主张需要同样强有力的证据，但 Gawdat 只提供了轶事般的例子，这些例子可以很好地解释，而不必求助于深奥的概念，如“有知觉的数字生物”、“T4”、“奇点”或“上帝”。他认为，我们没有意识到我们在人工智能发展方面已经走了多远，并提到了一些在我们通往他描绘的未来的道路上“不可避免”会发生的事情。(他的辩论围绕着未来是乌托邦还是反乌托邦展开。他相信这一天终将到来。)

第一个不可避免的是，人工智能将会发生，事实上“[它]已经发生了，”他说。他认为深度学习已经是人工智能了，因为它比我们更好地完成了分配给它的每一项任务——这不是真的，我将在下一节中展示。第二个必然是，AI 会比人类更聪明。他提到了未来学家雷·库兹韦尔(Ray Kurzweil)，这位“预测我们未来的先知”，以及奇点(Singularity)，这是他最受欢迎的概念:“到 2029 年，机器将比人更聪明。”这个精确的日期来自于指数增长的论点，这仍然是一个无力的辩护，因为“[自然界中没有任何事物遵循纯粹的指数增长](https://web.archive.org/web/20121030072409/http://www.growth-dynamics.com/articles/Kurzweil.htm#:~:text=Nothing%20in%20nature%20follows%20a%20pure%20exponential)

总的来说，他的论点有两大缺陷。首先，他从未给人工智能下过定义。当讨论的术语没有明确定义时，不可能同意或不同意任何人。在那次谈话中，他承认了定义人工智能的重要性——但他没有遵循自己的前提。第二，他将今天有效的论点延伸到我们知之甚少的未来。他谈到的人工智能失调的场景已经在今天的狭义人工智能系统中发生了。然而，他用它们来证明超级智能机器才是真正的威胁。为什么不关注眼前的事情，而不是展望不可预见的未来呢？

# 为什么人工智能不“聪明得吓人”

我们应该小心人工智能，但不是出于 Gawdat 描述的原因。人工智能可能很可怕，但不是因为它太聪明。几乎没有人工智能专家会同意 Gawdat 的观点，即当今的主要威胁是这些系统已经或“即将”变得超级智能。这可能最终会发生，但最有可能的是不会在八年后，在我们面对今天出现的其他危险情景之后。

## 艾已经来了吗？

AI(最广义的定义，包含所有机器学习/深度学习系统)已经在许多狭义的任务中超过了我们，但在许多其他方面却无法达到我们的水平——更不用说在一般意义上显示智能了。

算法擅长对象识别，这是研究得最多的任务之一，但只在非常特定的条件下。最佳视觉人工智能模型在 ImageNet 挑战赛上取得了惊人的 [+90%的前 1 名准确率](https://paperswithcode.com/sota/image-classification-on-imagenet)(这远比人类好[)。然而，当面对真实世界的对象数据集 ObjectNet 时，这个模型经历了](https://arxiv.org/abs/1502.01852)[40–45%的性能下降](https://objectnet.dev/objectnet-a-large-scale-bias-controlled-dataset-for-pushing-the-limits-of-object-recognition-models.pdf)。ImageNet 描绘了一个理想化的世界，因此挑战的结果扭曲了人工智能在物体识别方面的真实能力。

Gawdat 回忆说，早在 1989 年，机器就已经是最好的国际象棋选手(人类不再有任何可能击败最好的人工智能选手)。两年前横扫 Stockfish 8 的 DeepMind 的 AlphaZero ，是最好的棋手之一。在普通的游戏中，你无法战胜它，但只要把棋盘的大小从 8×8 改为 9×9，你就成了主人。这项任务极其相似，但是当面临与它所学知识的最小偏差时，AlphaZero 将无法概括它的知识。

Gawdat 还提到，自动驾驶汽车是世界上最好的司机。但是相对而言，它们不仅比人类更容易撞车，我们也更善于处理意外情况。自动驾驶汽车的关键弱点是现实有尽可能多的自由度。任何事情都可能发生，人工智能系统不太擅长从训练集推断出新的情况。因为他们缺乏对世界如何运作的更深层次的模型，所以他们经验之外的任何东西都成为不可逾越的障碍。

[OpenAI 的 GPT-3](https://arxiv.org/abs/2005.14165) ，虽然被认为是最强大的公共大语言模型，但是不能[生成类比](https://medium.com/@melaniemitchell.me/follow-up-to-can-gpt-3-make-analogies-b202204bd292)，[解决数学问题](https://venturebeat.com/2021/03/09/researchers-find-that-large-language-models-struggle-with-math/)，理解上下文信息，[推理](https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/#:~:text=many%20major%20issues%20with%20GPT-3%20were%20immediately%20evident%2C%20in%20every%20domain%20of%20reasoning%20and%20comprehension%20that%20we%20tested.)关于世界的底层原理，甚至链接因果。它可以生成各种形式的文本，但它还没有掌握人类意义上的语言。

人工智能缺乏思维理论、常识和因果推理、推断能力以及身体，因此它在几乎任何稍微复杂或一般的事情上都远远没有“比我们好”。

## AI 会比人类聪明吗？

如果我们继续以目前的速度前进，没有任何事情会让我们慢下来(从社会政治体系的剧烈变化到全球现象——比如气候灾难——都可能阻碍技术进步)，那么“没有办法阻止它”的想法是合乎逻辑的。然而，对于 AI 来说，八年时间对于达到这样一个里程碑来说似乎是很短的时间。

雷·库兹韦尔，加速回报定律的创造者，在他的书《精神机器的时代》中提出，技术趋向于指数增长。然而，正如物理学家西奥多·莫迪斯(Theodore Modis)在反驳库兹韦尔的预测时解释的那样，“他的错误行为依赖于数学函数，而不是自然法则……所有的自然增长都遵循逻辑函数。”

事实上，我们喜欢谈论指数变化率，比如摩尔定律，但是这些“定律”只有在不成立时才成立。指数增长有自然的极限，因此合乎逻辑的假设是现实中“没有什么遵循纯粹的指数增长”，正如莫迪斯所辩护的那样。

2029 年是库兹韦尔认为地球上最聪明的生物将是人工智能的日子。但他用数学如何与自然世界相关的简单观点来计算它——更不用说所有其他不断干扰技术进步速度甚至可能完全改变其方向的因素，如社会运动、道德辩论或政府监管。

然而，即使我们假设人工智能最终会变得比我们更聪明，也没有理由认为它会决定“与我们作对”，Gawdat 显然就是这样做的。他把智力和动机混淆了。正如史蒂芬·平克所解释的(引用自加里·马库斯的书*重新启动人工智能*)，“智能是运用新方法来达到目标的能力。但目标与智力无关:聪明并不等同于想要某样东西。”

我们不知道如何给人工智能注入动机——这是一种进化特征，只因为我们进化的方式而存在。但是即使我们知道怎么做，我们为什么要这么做？仅仅因为人类既有知道如何实现目标的智慧，又有采取行动的动机，并不意味着他们一起进化，或者他们本质上是交织在一起的。

# 真正的问题——无脑人工智能

加里·马库斯(Gary Marcus)在推特上回应了 Gawdat 对《纽约时报》的采访，强调了我们今天在人工智能领域面临的“真正挑战”:

AI 没那么聪明，但确实很恐怖。Gawdat 对生存威胁的关注掩盖了我们对当前社会结构各个层面每天都在发生的问题的看法。对尚未理解的假设风险给予更多的重视——这些风险距离未来如此之远，甚至没有一种有用的方法来讨论它们——阻碍了我们面对人工智能的真正危险的努力。

正如马库斯所说，没有大脑的人工智能是真正的问题。我们用它来制定决策，并在许多行业的决策过程中采取行动。当这些系统不了解世界如何运作或其行为的后果时，我们如何做到这一点呢？这正是近年来人工智能研究的新分支开始出现的原因，这些分支专注于包含这些问题，其中人工智能安全和人工智能伦理脱颖而出。

我们如何确保一项技术像一个“黑匣子”一样有效地运行，其决策通常是不可预测的，而这些决策背后的原因是不可理解的，我们希望它做什么？Gawdat 承认，对齐的问题现在非常现实。如果人工智能最终做了我们没有预料到的事情，我们不需要等待超级智能遭受人工智能可能带来的麻烦。偏见是人工智能系统的一个非常有害的普遍特征，它最终变成了种族主义者、性别歧视者和主要针对代表性不足的少数民族。

没有大脑的人工智能也非常有能力取代工人，同时产生大量的污染，增加其碳足迹。它也是假新闻的首要引擎，它对几乎每个决定我们在休闲和信息方面消费的系统都有不可避免的影响。人工智能的真正危险是那些看不见的，并通过我们的生活方式缓慢而无声地传播其分支，同时牢固地巩固其在我们世界基础上的根基。

*如果你喜欢这篇文章，可以考虑订阅我的免费周报*<https://mindsoftomorrow.ck.page>**！每周都有关于人工智能的新闻、研究和见解！**

**您也可以直接支持我的工作，使用我的推荐链接* [*这里*](https://albertoromgar.medium.com/membership) *成为媒介会员，获得无限权限！:)**