# PyMC3 åº”ç”¨è´å¶æ–¯æ¨ç†ç¬¬ 2 éƒ¨åˆ†

> åŸæ–‡ï¼š<https://towardsdatascience.com/applied-bayesian-inference-with-python-pt-2-80bcd63b507e?source=collection_archive---------13----------------------->

## åœ¨ StockX ä¸Šå±•ç¤ºé˜¿è¿ªè¾¾æ–¯ Yeezy å’Œè€å…‹ç±³è‰²è½¬å”®

![](img/d8eef2d3087d285ce851d08e4a17a5ae.png)

çº½çº¦æ—¶æŠ¥ã€‚ä½œè€…å›¾ç‰‡

# ä»‹ç»

å¦‚æœä½ æ˜¯ä»ç¬¬ 1 éƒ¨åˆ†æ¥åˆ°è¿™é‡Œçš„ï¼Œé‚£ä¹ˆæˆ‘å·²ç»å‡è®¾ä½ è‡³å°‘çŸ¥é“ Python &ç»Ÿè®¡å­¦çš„åŸºç¡€ã€‚å¦‚æœä¸æ˜¯ï¼Œä»ç¬¬ 1 éƒ¨åˆ†å¼€å§‹å¯èƒ½å¯¹ä½ è‡ªå·±çš„å­¦ä¹ ä½“éªŒæ›´èˆ’æœã€‚

åœ¨ç¬¬ 1 éƒ¨åˆ†ä¸­ï¼Œæˆ‘å±•ç¤ºäº†å¦‚ä½•é€šè¿‡ Python ä½¿ç”¨ PyMC3ï¼Œé€šè¿‡æ·ç¡¬å¸çš„ä¾‹å­è¿›è¡Œè´å¶æ–¯å»ºæ¨¡ã€‚è¿™ä¸ªä¾‹å­æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªå¤§å¤šæ•°äººéƒ½ç†Ÿæ‚‰çš„æ¦‚å¿µï¼Œè€Œä¸”æ•°æ®å¹¶ä¸â€œæ··ä¹±â€ã€‚è¿™ä¸ªä¾‹å­çš„é—®é¢˜æ˜¯å®ƒçš„äººä¸ºæ€§è´¨ä½¿ä½ ï¼Œå­¦ä¹ è€…ï¼Œå¾ˆéš¾çœŸæ­£ä½¿ç”¨è¿™ä¸ªæŠ€èƒ½ã€‚æˆ‘çŸ¥é“ï¼Œå› ä¸ºè¿™æ­£æ˜¯æˆ‘çš„æ„Ÿå—ã€‚å› æ­¤ï¼Œåœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘å°†æŠŠ PyMC3 æ¨¡å‹å’Œæ–¹æ³•åº”ç”¨äºâ€œçœŸå®â€æ•°æ®é›†ã€‚ç”±äºæˆ‘æ˜¯ä¸€ä¸ªç‹‚çƒ­çš„è€å…‹ç²‰ä¸ï¼Œæˆ‘å°†æµè§ˆè¿™ä¸ª [StockX 2019 æ•°æ®ç«èµ›æ•°æ®é›†](https://www.kaggle.com/hudsonstuck/stockx-data-contest)ã€‚è¿™ä¸ªæ•°æ®é›†æ¯”è¿™ä¸ªé¢†åŸŸçš„å¤§å¤šæ•°ä¸“å®¶ä½¿ç”¨çš„æ•°æ®é›†éƒ½è¦å¹²å‡€å¾—å¤šã€‚Kaggle æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ¸¸ä¹åœºï¼Œå¯ä»¥åšæ•°æ®ç§‘å­¦çš„æœ‰è¶£äº‹æƒ…ï¼Œä½†æ˜¯ç°å®ä¸–ç•Œä¸­çš„å¤§å¤šæ•°æ•°æ®é›†éƒ½éå¸¸æ··ä¹±ã€‚

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå‡è®¾æˆ‘ä»¬æƒ³ä¸º Yeezys å’Œ Off-white çš„åˆ©æ¶¦ç‡å»ºæ¨¡ï¼Œä»¥å¸®åŠ©æˆ‘ä»¬åœ¨è½¬å”®ä¸–ç•Œä¸­æ‰¾åˆ°ä¸€ä¸ªæ›´å¥½çš„æƒè¡¡ã€‚

ä¸ä»»ä½•å¥½çš„æ•°æ®ç§‘å­¦é¡¹ç›®ä¸€æ ·ï¼Œè®©æˆ‘ä»¬å…ˆåšå°½èŒè°ƒæŸ¥ï¼Œè¿›è¡Œæ¢ç´¢æ€§çš„æ•°æ®åˆ†æï¼Œå¹¶åœ¨æ­¤è¿‡ç¨‹ä¸­åšä¸€äº›æ¸…ç†å·¥ä½œã€‚

# æ¢ç´¢æ€§æ•°æ®åˆ†æå’Œæ•°æ®æ¸…ç†

```
import pandas as pd
import numpy as np
import pymc3 as pm
import arviz as az
from arviz.plots.plot_utils import xarray_var_iter
import matplotlib.pyplot as plt
import seaborn as sns
import xarray as xr%matplotlib inlineRANDOM_SEED = 42stockx_data = pd.read_csv('StockX-Data-Contest-2019-3.csv')#Seeing how many rows/columns we're working with
print(stockx_data.shape)(99956, 8)#Getting first glimpse at dataset
stockx_data.head(10)
```

![](img/b575e71a453376a464b0565d860777de.png)

ä½œè€…å›¾ç‰‡

é¦–å…ˆæ£€æŸ¥ nan å’Œ dtypes:

```
stockx_data.isna().sum()
```

![](img/9c91c1b609527d9e890c9243621648dc.png)

ä½œè€…å›¾ç‰‡

```
stockx_data.dtypes
```

![](img/a433dda87bb654e7bcd357d439382749.png)

ä½œè€…å›¾ç‰‡

ä¸€å¼€å§‹çœ‹èµ·æ¥ç›¸å¯¹å¹²å‡€ã€‚è®©æˆ‘ä»¬ç¨å¾®æ¸…ç†ä¸€ä¸‹æ•°æ®/æ•°æ®ç±»å‹ï¼Œç„¶ååˆ›å»ºä¸€äº›æœ‰è¶£çš„ç‰¹æ€§ã€‚

```
def cleanCurrency(series):
    """
    Input: a dataframe series for currency (USD)
    Output: cleaned series as a float
    """
    #Replaces dollar sign and comma with empty string
    series = series.str.replace('$', '', regex=True)
    series = series.str.replace(',', '', regex=True)
    series = series.astype(float)
    return series#Fix the Price fields to only be numeric
stockx_data['Sale Price'] = cleanCurrency(stockx_data['Sale Price'])
stockx_data['Retail Price'] = cleanCurrency(stockx_data['Retail Price'])#Calculate Profit by subtracting Sale from Retail
stockx_data['Profit'] = stockx_data['Sale Price'] - stockx_data['Retail Price']#Cleaning Sneaker Name column by removing hyphens
stockx_data['Sneaker Name'] = stockx_data['Sneaker Name'].str.replace('-', '')#Making brand name a little more descriptive
stockx_data['Brand'] = stockx_data['Brand'].str.replace('Yeezy', 'Yeezy (Adidas)')
stockx_data['Brand'] = stockx_data['Brand'].str.replace('Off-White', 'Off-White (Nike)')#Getting only 'object' dtype columns and then stripping trailing white spaces
stockx_data_obj = stockx_data.select_dtypes(['object'])
stockx_data[stockx_data_obj.columns] = stockx_data_obj.apply(lambda x: x.str.strip())#Ensure date fields are the right dtype
stockx_data['Order Date'] = pd.to_datetime(stockx_data['Order Date'])
stockx_data['Release Date'] = pd.to_datetime(stockx_data['Release Date'])#Calculate Duration of Days from Release Date to Order Date
stockx_data['Duration (days)'] = stockx_data['Order Date'] - stockx_data['Release Date']#Univariate stats on the numeric measures
stockx_data.describe()
```

![](img/d50ee1f6f9d360d558dbe5f212f86378.png)

ä½œè€…å›¾ç‰‡

é¦–å…ˆå¼•èµ·æˆ‘æ³¨æ„çš„æ˜¯è¿™åŒé‹çš„ä»·æ ¼ã€‚è€ƒè™‘åˆ°å“ç‰Œå’Œ StockX çš„ç›®æ ‡(è½¬å”®é«˜ç«¯è¡—å¤´æœé¥°)ï¼Œè¿™ä¸€ç‚¹å¾—åˆ°äº†è¯å®ã€‚è¿™é‡Œçš„å¹³å‡è®¢å•ä¹Ÿä»è½¬å”®ä¸­è·å¾—äº†ç›¸å½“ä¸é”™çš„åˆ©æ¶¦ï¼Œå¤§çº¦ 60 ç¾å…ƒã€‚ä¸è¿‡ï¼Œæ ‡å‡†å·®æ˜¾ç¤ºåˆ©æ¶¦æœ‰å¾ˆå¤§çš„å˜åŒ–ã€‚è¿™é‡Œéœ€è¦æ³¨æ„çš„å¦ä¸€ä»¶æœ‰è¶£çš„äº‹æƒ…æ˜¯ï¼Œåœ¨ 2017-2019 å¹´æœŸé—´ï¼ŒOff-Whites & Yeezys å¹³å‡éœ€è¦ 2 ä¸ªæœˆæ‰èƒ½åœ¨ StockX ä¸Šè½¬å”®ã€‚è¿™å¯èƒ½æ˜¯ç”±äºåœ¨é‹å­å‘å¸ƒçš„æœ€åˆå‡ ä¸ªæœˆä¾›è´§ç‡ä½ã€‚

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å¿«é€Ÿäº†è§£ä¸€ä¸‹æ—¥æœŸå­—æ®µçš„èŒƒå›´ã€‚

```
#Getting the min and max dates to understand order date range
print(stockx_data['Order Date'].min(), stockx_data['Order Date'].max())2017-09-01 00:00:00 2019-02-13 00:00:00
```

ä¼¼ä¹æˆ‘ä»¬æœ‰ç›¸å½“å¤šçš„æ•°æ®ï¼å°†è¿‘ä¸¤å¹´çš„ç›¸å¯¹å¹²å‡€çš„æ•°æ®ã€‚ç›®å‰çœ‹èµ·æ¥ä¸é”™ï¼Œç°åœ¨è®©æˆ‘ä»¬å¼€å§‹å¯è§†åŒ–æ•°æ®ï¼Œä»¥ä¾¿æ›´å¥½åœ°ç†è§£æˆ‘ä»¬æ­£åœ¨å¤„ç†çš„å†…å®¹:

```
#Grouping by Brand to see how the general distribution of sales are
brand_group = pd.DataFrame(stockx_data.groupby('Brand').size(), columns=['values']).reset_index().sort_values('values', ascending=False)
brand_group['values'] = brand_group['values'].astype(int)
plt.figure(figsize=(16, 8))
plt.rcParams.update({'font.size': 10})
ax = sns.barplot(x=brand_group['Brand'], y=brand_group['values'], data=brand_group, hue='Brand', palette="icefire")
ax.set(ylabel='Number of Shoes')
plt.show()
```

![](img/4106917b1ab952c3dc782c6d4bf64894.png)

æŒ‰å“ç‰Œé”€å”®çš„é‹å­æ€»æ•°ã€‚ä½œè€…å›¾ç‰‡

è¿™æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„é˜¶çº§ä¸å¹³è¡¡ï¼ŒYeezys åœ¨è¿™ä¸¤å¹´çš„é”€é‡ä¼¼ä¹è¿œè¿œè¶…è¿‡äº†ç™½äººã€‚è®©æˆ‘ä»¬æ½œå¾—æ›´æ·±ã€‚

```
#Grouping by Sneaker Name to see how the general distribution of ratings are
sneaker_group = pd.DataFrame(stockx_data.groupby(['Brand', 'Sneaker Name']).size(), columns=['values']).reset_index().sort_values('values', ascending=False)
sneaker_group['values'] = sneaker_group['values'].astype(int)
plt.figure(figsize=(20, 8))
plt.rcParams.update({'font.size': 10})
ax = sns.barplot(x=sneaker_group['Sneaker Name'], y=sneaker_group['values'], data=sneaker_group, hue='Brand', palette="icefire")
ax.set(ylabel='Number of Shoes')
plt.xticks(rotation=90)
plt.show()
```

![](img/d531af5d6ba6d7074c4072c054d554d7.png)

æŒ‰è¿åŠ¨é‹åç§°é”€å”®çš„é‹å­æ€»æ•°ã€‚ä½œè€…å›¾ç‰‡

æŒ‰é”€é‡æ’åå‰ 10 çš„è¿åŠ¨é‹å“ç‰Œä¼¼ä¹ä¸»è¦ç”± Yeezys å æ®ã€‚å³:

```
sneaker_group[:10]
```

![](img/bd1491311a0d07fe332378195856d6e5.png)

ä½œè€…å›¾ç‰‡

å°½ç®¡ä¹°æ–¹åœ°åŒº(å·)å¯èƒ½æœ‰ç‚¹æ˜¾è€Œæ˜“è§ï¼Œä½†è®©æˆ‘ä»¬ç¡®è®¤ä¸€ä¸‹å‡è®¾ã€‚

```
#Grouping by Region to see how the general distribution of ratings are
region_group = pd.DataFrame(stockx_data.groupby([â€˜Buyer Regionâ€™, â€˜Brandâ€™]).size(), columns=[â€˜valuesâ€™]).reset_index().sort_values(by=â€™valuesâ€™, ascending=False)
region_group[â€˜valuesâ€™] = region_group[â€˜valuesâ€™].astype(int)
plt.figure(figsize=(20, 8))
plt.rcParams.update({â€˜font.sizeâ€™: 10})
ax = sns.barplot(x=region_group[â€˜Buyer Regionâ€™], y=region_group[â€˜valuesâ€™], data=region_group, hue=â€™Brandâ€™, palette=â€icefireâ€)
ax.set(ylabel=â€™Number of Shoesâ€™)
plt.xticks(rotation=90)
plt.show()
```

![](img/a7aaf10b769f8c826a6a43d43cd5a0ea.png)

æŒ‰ä¹°å®¶åŒºåŸŸåˆ—å‡ºçš„å”®å‡ºé‹å­æ€»æ•°ã€‚ä½œè€…å›¾ç‰‡

åƒåŠ åˆ©ç¦å°¼äºšå’Œçº½çº¦è¿™æ ·çš„å·åœ¨è¿™é‡Œæœ‰å¾ˆå¤šä»£è¡¨ã€‚è¿™æ— ç–‘è¯æ˜äº†è¿™äº›å·(å’Œä¿„å‹’å†ˆå·)çš„è¿åŠ¨é‹æ–‡åŒ–æ˜¯éå¸¸å¼ºå¤§çš„ã€‚

```
region_group[:10]
```

![](img/a40270f62d2fadf12e41be481208f67b.png)

ä½œè€…å›¾ç‰‡

æœ€åï¼Œè®©æˆ‘ä»¬æ›´å¥½åœ°äº†è§£ä¸€ä¸‹åˆ©æ¶¦ä¸æˆ‘ä»¬ç›®å‰æ‰€çœ‹åˆ°çš„å†…å®¹ä¹‹é—´çš„å…³ç³»ã€‚

```
order_group = pd.DataFrame(stockx_data.groupby([â€˜Order Dateâ€™, â€˜Brandâ€™]).size(), columns=[â€˜valuesâ€™]).reset_index().sort_values(by=â€™valuesâ€™, ascending=False)
order_group[â€˜valuesâ€™] = order_group[â€˜valuesâ€™].astype(int)
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 12))
plt.rcParams.update({â€˜font.sizeâ€™: 10})
ax1 = sns.lineplot(x=order_group[â€˜Order Dateâ€™], y=order_group[â€˜valuesâ€™], data=order_group, hue=â€™Brandâ€™, palette=â€icefireâ€, ax=ax1)
ax2 = sns.lineplot(x=stockx_data[â€˜Order Dateâ€™], y=stockx_data[â€˜Profitâ€™], data=stockx_data, hue=â€™Brandâ€™, palette=â€icefireâ€, ax=ax2)
ax1.set(ylabel=â€™Number of Shoesâ€™)
plt.show()
```

![](img/d6e878e88b01d74d79aba9b19f7290b0.png)

ä¸€æ®µæ—¶é—´å†…å”®å‡ºçš„é‹å­æ•°é‡(ä¸Šå›¾)ã€‚ä¸€æ®µæ—¶é—´å†…æ¯æ¬¡é”€å”®çš„åˆ©æ¶¦(ä¸‹å›¾)ã€‚ä½œè€…å›¾ç‰‡

è¿™è®²è¿°äº†ä¸€ä¸ªéå¸¸æœ‰è¶£çš„æ•…äº‹â€”â€”è™½ç„¶ Yeezys åœ¨ StockX ä¸Šé”€å”®çš„é‹å­æ•°é‡ä¸Šå ä¸»å¯¼åœ°ä½(æ ¹æ®è¯¥æ•°æ®é›†)ï¼Œä½†ç™½äººçš„åˆ©æ¶¦æ•°å­—ä¸€ç›´è¾ƒé«˜ã€‚å°†æ•£ç‚¹å›¾çŸ©é˜µå¯è§†åŒ–å°†æœ‰åŠ©äºæŸ¥çœ‹æ˜¯å¦æœ‰ä»»ä½•å›ºæœ‰çš„æ¨¡å¼å‡ºç°åœ¨æ•°å€¼æµ‹é‡ä¸­:

```
sns.pairplot(stockx_data, diag_kind=â€™kdeâ€™, hue=â€™Brandâ€™, palette=â€™icefireâ€™);
```

![](img/2cff9cbefd519a597e631c6b7f3d92a4.png)

ä½œè€…å›¾ç‰‡

å¾ˆæ˜æ˜¾ï¼Œé”€å”®ä»·æ ¼å’Œåˆ©æ¶¦ä¼šæœ‰ä¸€ä¸ªå®Œç¾çš„çº¿æ€§å…³ç³»ï¼Œä½†é™¤æ­¤ä¹‹å¤–ï¼Œå˜é‡ä¹‹é—´ä¸ä¼šå‡ºç°æ˜æ˜¾çš„æ¨¡å¼ã€‚ä¸ Yeezys ç›¸æ¯”ï¼Œæˆ‘ä»¬åœ¨å„ç§æ•£ç‚¹å›¾ä¸­çœ‹åˆ°äº†æ›´å¤šçš„ç°ç™½è‰²åˆ†æ•£å’Œå˜åŒ–ã€‚æœ€åï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå”®å‡ºçš„å¹³å‡é‹ç ä¼¼ä¹åœ¨ 10 ç å·¦å³ã€‚åœ¨ç¾å›½ï¼Œè¿™ä¸ªæ•°å­—ç›¸å½“å¤§ï¼Œå¯èƒ½æ„å‘³ç€é”€å”®çš„ä¸»è¦æ˜¯ç”·é‹ã€‚

å› ä¸ºæˆ‘ä»¬æœ€ç»ˆæƒ³è¦å¯¹åˆ©æ¶¦å»ºæ¨¡ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬ä»”ç»†çœ‹çœ‹å®ƒä»¬çš„åˆ†å¸ƒã€‚

```
fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 8))ax1 = sns.histplot(stockx_data.loc[stockx_data[â€˜Brandâ€™]==â€™Yeezy (Adidas)â€™,â€™Profitâ€™], kde=True, color=â€™midnightblueâ€™, ax=ax1)
ax2 = sns.histplot(stockx_data.loc[stockx_data[â€˜Brandâ€™]==â€™Off-White (Nike)â€™,â€™Profitâ€™], kde=True, color=â€™maroonâ€™, ax=ax2)ax1.set_title(â€˜Rating Distribution for Yeezy (Adidas) Productsâ€™)
ax2.set_title(â€˜Rating Distribution for Off-White (Nike) Productsâ€™)plt.show()
```

![](img/e574e2c6c8a56afd7b475a3a4848c8b9.png)

ä½œè€…å›¾ç‰‡

ä¸€å®šè¦è®°ä½å¤©å¹³ï¼›è¯¥æ•°æ®é›†ä¸­çš„ç°ç™½è‰²è®¡æ•°è¦å°‘å¾—å¤šï¼Œä½†å®ƒä»¬éƒ½éµå¾ªç±»ä¼¼çš„åŒå³°åˆ†å¸ƒï¼Œå¤§é¢‘ç‡æ¥è¿‘ 0â€“500ï¼Œé•¿å°¾å°†å¹³å‡å€¼å‘å³å€¾æ–œã€‚ä»çº¿å›¾ä¸­å¯ä»¥çœ‹å‡ºï¼Œæˆ‘ä»¬ç¡®å®è¯å®äº†ç±³ç™½è‰²çš„å¹³å‡åˆ©æ¶¦æ›´é«˜ã€‚

```
#Filtering dataframe to get the respective brands only
yeezy = stockx_data[stockx_data[â€˜Brandâ€™]==â€™Yeezy (Adidas)â€™]
offwhite = stockx_data[stockx_data[â€˜Brandâ€™]==â€™Off-White (Nike)â€™]
```

æˆ‘ä»¬å·²ç»å¯¹æˆ‘ä»¬çš„æ•°æ®æœ‰äº†ä¸€ä¸ªç›¸å½“ä¸é”™çš„æƒ³æ³•ï¼Œç°åœ¨æ˜¯æ—¶å€™å¼€å§‹æ„å»ºæ¨¡å‹äº†ã€‚

# å»ºæ¨¡å’Œåˆ†æ

åœ¨æˆ‘ä»¬å¼€å§‹ç¼–ç ä¹‹å‰ï¼Œé‡è¦çš„æ˜¯è¦ç»å†ç¬¬ 1 éƒ¨åˆ†ä¸­è¯´æ˜çš„æ­¥éª¤:
**1ã€‚**æè¿°è¿™ä¸ªåˆ©æ¶¦æ•°æ®çš„æœ€ä½³éšæœºå˜é‡æ˜¯ä»€ä¹ˆï¼Ÿè¿™ç§åˆ†å¸ƒä¼¼ä¹è¡¨æ˜ï¼Œæœ‰ä¸¤ç§ç±»å‹çš„äººä» yee zys/Off-white(åŒå³°)ä¸­è·åˆ©ã€‚æ­¤å¤–ï¼Œé•¿å°¾å¯èƒ½ä»£è¡¨æ›´å…·æ’ä»–æ€§çš„äº§å“ï¼Œä½†æˆ‘ä»¬çš„æ¨¡å‹ä¼šå°†å®ƒä»¬è§£è¯»ä¸ºå™ªéŸ³ã€‚ä¸ºäº†è¯´æ˜è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å­¦ç”Ÿçš„ t åˆ†å¸ƒã€‚è¿™ç§åˆ†å¸ƒä¸æ­£æ€åˆ†å¸ƒéå¸¸ç›¸ä¼¼ï¼Œé™¤äº†å¯¹å¼‚å¸¸å€¼æ›´ç¨³å¥ï¼Œè¿™å¯¹æˆ‘ä»¬éå¸¸æœ‰ç”¨ã€‚è¿™ç§å‡è®¾åæ˜ äº†æˆ‘ä»¬æ‰€è®¤ä¸ºçš„åˆ©æ¶¦äººç¾¤ä¼šå¾—åˆ°æˆ‘ä»¬æ‰€æ‹¥æœ‰çš„ä¿¡æ¯ã€‚è€ƒè™‘åˆ°ä¸–ç•Œä¸Šæµè¡Œçš„é«˜æ–¯äººæ˜¯å¤šä¹ˆæœ‰æ•ˆï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ã€‚

**2ã€‚**æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æƒ³ï¼Œâ€œå¥½å§ï¼Œå‡è®¾åˆ©æ¶¦æ˜¯å­¦ç”Ÿçš„ t åˆ†å¸ƒï¼Œæˆ‘éœ€è¦æ­£æ€åˆ†å¸ƒå—ï¼Ÿâ€å—¯ï¼Œt åˆ†å¸ƒæœ‰ä¸‰ä¸ªå‚æ•° mu ( *Î¼* ) *ã€* sigma ( *Ïƒ* )ï¼Œnu ( *v* )ã€‚è¿™äº›è¡¨ç¤ºå¹³å‡å€¼ã€æ ‡åº¦(ä¸æ•°æ®çš„åˆ†å¸ƒç›¸å…³)å’Œ t åˆ†å¸ƒçš„è‡ªç”±åº¦ï¼Œå®ƒä»¬å†³å®šäº† t åˆ†å¸ƒçš„å½¢çŠ¶ã€‚

**3ã€‚**æˆ‘ä»¬çŸ¥é“ *Î¼ï¼ŒÏƒï¼Œ*å’Œ *v* å—ï¼Ÿä¸ï¼Œæˆ‘ä»¬å¯¹å®ƒçš„æœ€å¥½ä¼°è®¡æ˜¯æˆ‘ä»¬åˆ†å¸ƒçš„å‡å€¼å’Œæ ‡å‡†å·®ã€‚ä¼¼ä¹æ¯ä¸ªå“ç‰Œéƒ½æœ‰ä¸åŒï¼Œæ‰€ä»¥æˆ‘ä»¬èƒ½åšçš„æ˜¯è®¾å®šä¸€ä¸ªå…ˆéªŒæ¥è¯„ä¼°å®ƒä»¬ã€‚

**4ã€‚**å¯¹äº *Î¼ï¼ŒÏƒï¼Œ*å’Œ *v* æœ‰å“ªäº›å¥½çš„åˆ†å¸ƒï¼Ÿå¯¹äº *Î¼* ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ªå¾ˆå®½çš„å‡åŒ€åˆ†å¸ƒæ¥ä½“ç°æˆ‘ä»¬çš„æ— çŸ¥ã€‚ä»æœ¬è´¨ä¸Šè®²ï¼Œæˆ‘ä»¬è®¤ä¸ºåœ¨ç»™å®šçš„èŒƒå›´å†…ï¼Œå¹³å‡å€¼å¯èƒ½æ˜¯ç›¸åŒçš„ã€‚ä»…ä»…é€šè¿‡è§‚å¯Ÿåˆ†å¸ƒï¼Œæˆ‘ä»¬å°±å¯ä»¥å¾—åˆ° Yeezys çš„èŒƒå›´æ˜¯[0ï¼Œ500]ï¼Œç°ç™½è‰²çš„èŒƒå›´æ˜¯[0ï¼Œ1000]ã€‚å¯¹äº *Ïƒ* ï¼Œæˆ‘ä»¬çŸ¥é“æ ‡å‡†å·®éœ€è¦æœ‰æ­£å€¼ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä½¿ç”¨åŠæ­£æ€åˆ†å¸ƒï¼Œå¹¶é€šè¿‡ä½¿ç”¨å®½èŒƒå›´[0ï¼Œ10]æ¥åæ˜ æˆ‘ä»¬çš„æ— çŸ¥ã€‚æœ€åï¼Œæˆ‘ä»¬ä¹Ÿä¸çŸ¥é“ *v* çš„åˆ†å¸ƒï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥éµå¾ªæ¨èçš„æ–‡çŒ®ï¼Œä½¿ç”¨å¦ä¸€ä¸ªå¼±ä¿¡æ¯å…ˆéªŒã€‚è¿™æ„å‘³ç€ä¸€ä¸ªå¹³å‡å€¼ä¸º 30 çš„æŒ‡æ•°åˆ†å¸ƒã€‚è¿™åŸºæœ¬ä¸Šåæ˜ äº†æˆ‘ä»¬æˆ–å¤šæˆ–å°‘åœ°è®¤ä¸º *v* åº”è¯¥åœ¨ 30 å·¦å³ï¼Œä½†æ˜¯å¯ä»¥è½»æ¾åœ°ç§»åŠ¨åˆ°æ›´å°å’Œæ›´å¤§çš„å€¼ã€‚

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è®¨è®ºçš„æ‰€æœ‰è§‚ç‚¹éƒ½åæ˜ äº†æˆ‘ä»¬å¯¹ä¸¤ä¸ªå“ç‰Œåˆ©æ¶¦çš„äººå£åˆ†å¸ƒçš„å„ç§å‡è®¾å’Œå¿½è§†ã€‚è¯·è®°ä½ï¼Œè¿™ä¸ªè¿‡ç¨‹çš„ç›®æ ‡æ˜¯ä»æŸä¸ªç›¸å½“å¥½çš„åœ°æ–¹å¼€å§‹ï¼Œè·å¾—æ–°çš„è¯æ®ï¼Œç„¶åæ›´æ–°æˆ‘ä»¬çš„å…ˆéªŒå’Œå¯èƒ½æ€§ï¼Œä»¥è·å¾—æ›´å‡†ç¡®/ç²¾ç¡®çš„åéªŒã€‚

```
#Creating a model with respective mu, sigma, and y distributions
with pm.Model() as model:
    mu_offwhite = pm.Uniform('mu_offwhite', 0, 1000)
    sigma_offwhite = pm.HalfNormal('sigma_offwhite', sd=10)
    nu_offwhite = pm.Exponential('nu_offwhite', 1/30)
    y_offwhite = pm.StudentT('y_offwhite', mu=mu_offwhite, sd=sigma_offwhite, nu=nu_offwhite, observed=offwhite['Profit_transformed'])mu_yeezy = pm.Uniform('mu_yeezy', 0, 500)
    sigma_yeezy = pm.HalfNormal('sigma_yeezy', sd=10)
    nu_yeezy = pm.Exponential('nu_yeezy', 1/30)
    y_yeezy = pm.StudentT('y_yeezy', mu=mu_yeezy, sd=sigma_yeezy, nu=nu_yeezy, observed=yeezy['Profit_transformed'])

pm.model_to_graphviz(model)
```

![](img/bb78ee7d45f5076f145c359ea9548ef6.png)

ä½œè€…å›¾ç‰‡

ä½ å¯èƒ½æƒ³çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘åœ¨åŒä¸€ä¸ªæ¨¡å‹ä¸­æœ‰ä¸¤ç§åˆ©æ¶¦åˆ†å¸ƒã€‚è¿™åº”è¯¥ä¸ä¼šå¯¹æˆ‘ä»¬çš„æ¨¡å‹äº§ç”Ÿå¾ˆå¤§çš„å½±å“ï¼Œå¦‚æœæœ‰çš„è¯ï¼Œå¯¹æˆ‘ä»¬åé¢è¦è®¨è®ºçš„éƒ¨åˆ†ä¼šæœ‰å¸®åŠ©ã€‚

```
with model:
    trace = pm.sample(10000, tune=2000, target_accept=.9, return_inferencedata=True, random_seed=RANDOM_SEED)
```

å…³äºæ’é™¤å‘æ•£é“¾æ•…éšœçš„å¿«é€Ÿè¯´æ˜:å½“æ‚¨åˆ›å»ºè‡ªå·±çš„ MCMC æ¨¡å‹æ—¶ï¼Œæ‚¨å¯èƒ½ä¼šé‡åˆ°åéªŒåˆ†å¸ƒæ”¶æ•›çš„é—®é¢˜ã€‚é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡ç½—(MCMC)ä½¿ç”¨é©¬å°”å¯å¤«é“¾ğ‘0,â€¦,ğ‘ğ‘.çš„çŠ¶æ€æ¥é€¼è¿‘å…³äºç»™å®šç›®æ ‡(åéªŒ)åˆ†å¸ƒçš„æœŸæœ›é—®é¢˜æ˜¯ï¼Œåªæœ‰å½“é“¾å˜å¾—æ— é™é•¿æ—¶ï¼Œå®ƒä»¬æ‰èƒ½ä¿è¯ç²¾ç¡®ã€‚è¿™é€šå¸¸åœ¨è®¡ç®—ä¸Šæ˜¯ä¸å¯è¡Œçš„ï¼Œå› æ­¤æˆ‘ä»¬è¯•å›¾åœ¨ä¸è€—å°½èµ„æºçš„æƒ…å†µä¸‹å¿«é€Ÿæ”¶æ•›åˆ°ç›®æ ‡åˆ†å¸ƒã€‚ä¸å¹¸çš„æ˜¯ï¼Œè¿™éœ€è¦ä¸€ä¸ªå«åšå‡ ä½•éå†çš„æ¡ä»¶æ‰èƒ½æˆç«‹ã€‚è¿™ä¸ªæ¡ä»¶æœ¬è´¨ä¸Šä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨ä»…åˆ©ç”¨æœ‰é™æ¬¡è¿­ä»£æ—¶éµå¾ª MCMC æ¨¡å‹çš„ä¸­å¿ƒæé™å®šç†ã€‚ä»æŠ€æœ¯ä¸Šè®²ï¼Œæˆ‘ä»¬æ— æ³•ä»¥ç®€å•çš„æ–¹å¼è¯æ˜å‡ ä½•éå†æ€§ï¼Œä½†æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°é“¾ä¸­çš„å‘æ•£ï¼Œè¿™è¡¨æ˜æ¡ä»¶å·²è¢«è¿åã€‚é‡‡æ ·ä¸­å‘ç°çš„ Rhat ç»Ÿè®¡å’Œå‘æ•£é“¾æ˜¯è¿åè¯¥æ¡ä»¶çš„å…³é”®æŒ‡æ ‡ï¼Œå¦‚æœæ‚¨å‘ç°äº†è¿™ä¸€ç‚¹ï¼Œæˆ‘å»ºè®®å°è¯•ä»¥ä¸‹ç­–ç•¥:

1.  å¢åŠ â€œè°ƒæ•´â€å‚æ•°:å¦‚æœä½ æƒ³ä»ä½ çš„æ¨¡å‹ä¸­æŠ½å–â€œçœŸå®çš„â€(æ— åçš„)æ ·æœ¬ï¼Œä½ éœ€è¦â€œè°ƒæ•´â€(è®©å®ƒæ”¶æ•›)è¿™ä¸ªé“¾ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œtune å¯¹ 1000 ä¸ªæ ·æœ¬æ‰§è¡Œæ­¤æ“ä½œï¼Œä½†å¢åŠ æ­¤æ“ä½œä¼šè®©æ¨¡å‹æœ‰æ›´å¤šæ—¶é—´è¾¾åˆ°æ”¶æ•›ã€‚
2.  å¢åŠ æŠ½å–çš„æ ·æœ¬æ•°é‡:é©¬å°”å¯å¤«é“¾ä»éšæœºåˆ†å¸ƒå¼€å§‹ï¼Œæ…¢æ…¢æ”¶æ•›åˆ°ä½ çš„æ¨¡å‹çš„åˆ†å¸ƒã€‚åœ¨è°ƒæ•´æ­¥éª¤æ”¶æ•›åï¼Œå¢åŠ ç»˜åˆ¶æ¬¡æ•°å¯ä»¥ä¸ºæ¨¡å‹æä¾›æ›´å¤šæ ·æœ¬ä¾›é€‰æ‹©ã€‚
3.  å¢åŠ â€œtarget_acceptâ€å‚æ•°:è¿™ç­‰åŒäºé™ä½æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­çš„å­¦ä¹ é€Ÿç‡ã€‚é™ä½è¯¥å€¼å¯ä½¿é‡‡æ ·å™¨ç¡®ä¿æ›´å°‘çš„å‘æ•£ã€‚

å¦‚ä½•å¯¹æ¨ç†å¼•æ“è¿›è¡Œæœ€ä½³æ•…éšœè¯Šæ–­çš„ç†è®ºå’Œè§£é‡Šåœ¨è¿™é‡Œå¾—åˆ°äº†æœ€å¥½çš„è¯´æ˜[ã€‚](https://docs.pymc.io/notebooks/Diagnosing_biased_Inference_with_Divergences.html)

```
var_names = ['mu_offwhite', 'sigma_offwhite', 'nu_offwhite', 'mu_yeezy', 'sigma_yeezy', 'nu_yeezy']
lines = list(xarray_var_iter(trace.posterior[var_names].mean(dim=("chain", "draw"))))
az.plot_trace(trace, lines=lines);
```

![](img/ada292120c5f4216604f8b7456b6fda2.png)

ä½œè€…å›¾ç‰‡

![](img/5a494cb8bb3e97cfab809800af80384c.png)

ä½œè€…å›¾ç‰‡

å¯¹æˆ‘ä»¬å‰ç§‘çš„åˆæ­¥åˆ†æçœ‹èµ·æ¥ä¸é”™ã€‚å·¦è¾¹çš„ KDE å›¾å¹³æ»‘ä¸”ç›¸å¯¹å¯¹é½(å°½ç®¡åœ¨è¿™é‡Œå’Œé‚£é‡Œå¯ä»¥çœ‹åˆ°è½»å¾®çš„åå·®),å³è¾¹çš„å›¾çœ‹èµ·æ¥æ›´åƒç™½å™ªå£°ï¼Œæ²¡æœ‰æ˜æ˜¾çš„æ¨¡å¼ã€‚

åœ¨ç»§ç»­å‰è¿›ä¹‹å‰ï¼Œå¯¹ä½ çš„è¿‡å»è¿›è¡Œæ›´å¤šçš„åˆ†ææ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¹ æƒ¯ã€‚è¯·è®°ä½ï¼Œä»æ•°æ®ä¸­è·å¾—æ´å¯ŸåŠ›çš„æ¡¥æ¢æ˜¯é€šè¿‡å‡è®¾ï¼Œå› æ­¤ç†è§£å’Œæç‚¼æˆ‘ä»¬çš„å…ˆéªŒçŸ¥è¯†éå¸¸é‡è¦ï¼å¹¸è¿çš„æ˜¯ï¼ŒArviZ è®©æˆ‘ä»¬çš„å·¥ä½œå˜å¾—ç®€å•å¤šäº†ã€‚

```
with model:
 prior_checks = pm.sample_prior_predictive(random_seed=RANDOM_SEED)
 idata_prior = az.from_pymc3(prior=prior_checks)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,8))
ax1 = az.plot_dist(idata_prior.prior[â€˜mu_yeezyâ€™], kind=â€™kdeâ€™, rug=True, 
 quantiles=[.25, .5, .75], color=â€™midnightblueâ€™, ax=ax1)
ax2 = az.plot_dist(idata_prior.prior[â€˜mu_offwhiteâ€™], kind=â€™kdeâ€™, rug=True,
 quantiles=[.25, .5, .75], color=â€™maroonâ€™, ax=ax2)ax1.set_title(â€˜Prior Distribution for mu_yeezyâ€™)
ax2.set_title(â€˜Prior Distribution for mu_offwhiteâ€™)plt.show()
```

![](img/ec492ae7e90c5d43371f1853cb7fa88d.png)

ä½œè€…å›¾ç‰‡

```
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,8))ax1 = az.plot_dist(idata_prior.prior[â€˜sigma_yeezyâ€™], kind=â€™kdeâ€™, rug=True, 
 quantiles=[.25, .5, .75], color=â€™midnightblueâ€™, ax=ax1)
ax2 = az.plot_dist(idata_prior.prior[â€˜sigma_offwhiteâ€™], kind=â€™kdeâ€™, rug=True,
 quantiles=[.25, .5, .75], color=â€™maroonâ€™, ax=ax2)ax1.set_title(â€˜Prior Distribution for sigma_yeezyâ€™)
ax2.set_title(â€˜Prior Distribution for sigma_offwhiteâ€™)plt.show()
```

![](img/ea6cea7bb55c85f767fdcffbd21f6cce.png)

ä½œè€…å›¾ç‰‡

```
az.summary(trace)
```

![](img/3d69b66a61c61912ec7a7cda56cfa90f.png)

ä½œè€…å›¾ç‰‡

è¿™äº›å…ˆéªŒåˆ†å¸ƒå›¾å¹¶ä¸æ„å‘³ç€ä¸æˆ‘ä»¬çš„åˆ©æ¶¦åˆ†å¸ƒç›¸åŒ¹é…ï¼›åœ¨ç»™å®šæ•°æ®çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ­£åœ¨ç ”ç©¶æ¨¡å‹å‘ç°çš„æ¯ä¸ªå“ç‰Œåˆ©æ¶¦çš„å‡å€¼å’Œæ ‡å‡†å·®çš„å¯èƒ½åˆ†å¸ƒã€‚æ‰€ä»¥å¯¹äºå¹³å‡çš„å…ˆéªŒåˆ†å¸ƒï¼Œæˆ‘ä»¬ç¡®å®çœ‹åˆ°å¹³å‡å€¼ä¸æˆ‘ä»¬åœ¨æ¯ä¸ªåˆ©æ¶¦åˆ†å¸ƒä¸­å‘ç°çš„ç›¸å¯¹æ¥è¿‘ã€‚äº‹å®ä¸Šï¼Œå¯¹äº yeezyï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæ‹¾å–ç”±è¾ƒå¤§æ•°æ®åˆ†å¸ƒç»„æˆçš„è¾ƒå¤§çš„ç¬¬ä¸€ä¸ªå°–å³°ã€‚æˆ‘ä»¬ä¼°è®¡å€¼çš„ä½æ ‡å‡†åå·®æ˜¯ä¸€å¤§ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼ŒæŸ¥çœ‹æ‘˜è¦ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ° rhat çš„è‰¯å¥½æ•°å­—å’Œç›¸å½“ä½çš„ MCSE è¯¯å·®ï¼Œè¿™æ˜¯ä¸€ä¸ªå¥½ç°è±¡ã€‚æœ€åï¼Œæˆ‘ä»¬çœ‹åˆ°è‡ªç”±åº¦çš„ä¼°è®¡å€¼çº¦ä¸º 2.4ï¼Œè¿™è¡¨æ˜æˆ‘ä»¬çš„åˆ†å¸ƒç¡®å®æœ‰è¾ƒé‡çš„å°¾éƒ¨(ç”±äºå¼‚å¸¸å€¼)ï¼Œé€‰æ‹© Student çš„ t åˆ†å¸ƒæ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é€‰æ‹©ï¼Œå› ä¸ºå®ƒå¯ä»¥ä¸ºæˆ‘ä»¬æä¾›æ›´ç¨³å¥çš„ä¼°è®¡ã€‚

æˆ‘ä»¬è‚¯å®šè¦è¿›è¡ŒåéªŒé¢„æµ‹æ£€éªŒï¼Œçœ‹çœ‹åéªŒåˆ†å¸ƒæ˜¯å¦æˆç«‹ã€‚

```
with model:
 ppc = pm.sample_posterior_predictive(trace, var_names=var_names+[â€˜y_offwhiteâ€™, â€˜y_yeezyâ€™], random_seed=RANDOM_SEED)fig, (ax1,ax2) = plt.subplots(1,2, figsize=(10, 5))
ax1.hist([y.mean() for y in ppc['y_yeezy']], bins=19, alpha=0.5, color='midnightblue')
ax2.hist([y.mean() for y in ppc['y_offwhite']], bins=19, alpha=0.5, color='maroon')
ax1.axvline(yeezy['Profit'].mean(), color='r')
ax2.axvline(offwhite['Profit'].mean(), color='r')
for ax in [ax1, ax2]:
    ax.set(xlabel='x', ylabel='')
ax1.set_title('Posterior Predictive Check for y_yeezy')
ax2.set_title('Posterior Predictive Check for y_offwhite');
```

![](img/5fcee0d5a3b9234bdda9317977ac1d90.png)

ä½œè€…å›¾ç‰‡

çº¢çº¿ä»£è¡¨æˆ‘ä»¬è§‚å¯Ÿåˆ°çš„å„ä¸ªåˆ©æ¶¦åˆ†å¸ƒçš„å¹³å‡å€¼ã€‚è¿™é‡Œå¾ˆå®¹æ˜“è¯´æˆ‘ä»¬çš„æ¨¡å‹æ²¡æœ‰åƒæˆ‘ä»¬æœ€åˆæƒ³çš„é‚£æ ·å­¦ä¹ æ•°æ®ï¼Œä½†æ˜¯è®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸‹æˆ‘ä»¬çš„å‡è®¾ã€‚æˆ‘ä»¬ç¬¬ä¸€çœ¼çœ‹åˆ°çš„åˆ©æ¶¦åˆ†å¸ƒæ˜¾ç¤ºï¼Œç”±äºç¦»ç¾¤å€¼çš„é•¿å°¾æ•ˆåº”ï¼Œåˆ©æ¶¦åˆ†å¸ƒæ˜æ˜¾å‘å³å€¾æ–œã€‚æˆ‘ä»¬çš„å‡è®¾æ˜¯ï¼Œè¿™äº›å¼‚å¸¸å€¼å¹¶ä¸ä»£è¡¨æ¯ä¸ªå“ç‰Œçš„åˆ©æ¶¦ï¼Œå¦‚æœæˆ‘ä»¬æƒ³æ›´å‡†ç¡®åœ°äº†è§£å“ªä¸ªå“ç‰Œçš„åˆ©æ¶¦ç‡æ›´é«˜ï¼Œæˆ‘ä»¬åº”è¯¥æ„å»ºä¸€ä¸ªå¯¹è¿™äº›å¼‚å¸¸å€¼ç¨³å¥çš„æ¨¡å‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é€‰æ‹©å­¦ç”Ÿçš„ t åˆ†å¸ƒä½œä¸ºæˆ‘ä»¬çš„å¯èƒ½æ€§ã€‚è¿™æ˜¯ä¸€ä¸ªç›´æ¥çš„ç»“æœã€‚æˆ‘ä»¬è§‚å¯Ÿæ•°æ®çš„å¹³å‡å€¼*åº”è¯¥*é«˜äºæˆ‘ä»¬åéªŒåˆ†å¸ƒçš„å¹³å‡å€¼ï¼Œå› ä¸ºæˆ‘ä»¬æ˜ç¡®æƒ³è¦ä¸€ä¸ªå¯¹å¼‚å¸¸å€¼æ›´ç¨³å¥çš„ç›®æ ‡åˆ†å¸ƒã€‚

æ—¢ç„¶æˆ‘ä»¬å¯¹æ¯ä¸ªåˆ©æ¶¦åˆ†é…éƒ½æœ‰äº†ä¸€ä¸ªçœ‹ä¼¼å¼ºå¤§çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å°±å¯ä»¥æ˜æ˜¾åœ°çœ‹åˆ°ç±³è‰²çš„å¹³å‡åˆ©æ¶¦ç‡æ›´é«˜ï¼Œæˆ–è€…è¿›è¡Œå…¸å‹çš„ t æ£€éªŒæ¥è¯„ä¼°å·®å¼‚ã€‚å¯¹æˆ‘ä»¬æ¥è¯´å¹¸è¿çš„æ˜¯ï¼Œè´å¶æ–¯ä¼°è®¡ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªå¾ˆå¥½çš„æ¯”è¾ƒç¾¤ä½“çš„æ–¹æ³•ï¼ŒåŒæ—¶ä¹Ÿäº§ç”Ÿäº†å¯¹ä¸ç¡®å®šæ€§çš„è¯„ä¼°ã€‚

# åˆ†ç»„æ¯”è¾ƒ

```
with model:
    diff_means = pm.Deterministic('means difference', mu_yeezy-mu_offwhite)
    diff_std = pm.Deterministic('stds difference', sigma_yeezy-sigma_offwhite)
    effect_size = pm.Deterministic('effect size (cohens d)', diff_means/np.sqrt((yeezy['Profit'].std() ** 2 + offwhite['Profit'].std() ** 2) / 2))
```

æˆ‘ä»¬å¯ä»¥è®¡ç®—å‡å€¼ã€æ ‡å‡†å·®å’Œæ•ˆåº”å¤§å°çš„å·®å¼‚ï¼Œç„¶åç”¨ç¡®å®šæ€§å¯¹è±¡æ¥è¡¨ç¤ºæˆ‘ä»¬å¸Œæœ›å°†é‡‡æ ·å€¼è®°å½•ä¸ºè¾“å‡ºçš„ä¸€éƒ¨åˆ†ã€‚

å¯¹äºæ•ˆåº”å¤§å°ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Cohen çš„ d æµ‹é‡å€¼æ¥è®¡ç®—ï¼Œd æµ‹é‡å€¼æ˜¯ä¸¤ç»„å¹³å‡æ ‡å‡†å·®çš„å¹³å‡å€¼ä¹‹å·®ã€‚

```
with model:
 trace = pm.sample(5000, return_inferencedata=True, random_seed=RANDOM_SEED)pm.plot_posterior(trace, var_names=['mu_yeezy', 'mu_offwhite', 'sigma_yeezy', 'sigma_offwhite'], color='#87ceeb');
```

![](img/005f3bea0c0154f18f7f802ad4442577.png)

ä½œè€…å›¾ç‰‡

```
pm.plot_posterior(trace, var_names=['means difference', 'stds difference', 'effect size (cohens d)'], ref_val=0, color='#87ceeb');
```

![](img/003d38ec79e303a601c5889807e2b164.png)

ä½œè€…å›¾ç‰‡

![](img/b435c170c89044ef43c6daddbe43d76a.png)

ä½œè€…å›¾ç‰‡

```
az.summary(trace, var_names=['means difference', 'stds difference', 'effect size (cohens d)'])
```

![](img/1811330d808c35ee9a2125e0e37f255a.png)

ä½œè€…å›¾ç‰‡

å¦‚æœ Yeezy å’Œ Off-White ä¹‹é—´çš„åˆ©æ¶¦ç‡å‡ºç°å·¨å¤§å·®å¼‚ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°ä»€ä¹ˆï¼›Yeezys åœ¨è¯¥æ•°æ®é›†ä¸­çš„é”€å”®é¢å¯èƒ½æ›´é«˜ï¼Œä½†åˆ©æ¶¦ç‡æ¯”éç™½ç§äººä½ 330 ç¾å…ƒå·¦å³ã€‚æ•ˆæœå¤§å°ä¹Ÿéå¸¸é‡è¦ï¼Œå¯ä»¥è§£é‡Šä¸º Z åˆ†æ•°ã€‚æ‰€ä»¥ Yeezy çš„åˆ©æ¶¦ç‡æ¯”ç™½äººä½ 1.3 ä¸ªæ ‡å‡†å·®ã€‚

# ç»“è®º

è´å¶æ–¯ä¼°è®¡å’Œå»ºæ¨¡çš„æƒŠäººä¹‹å¤„åœ¨äºï¼Œå®ƒä¸ºæ‚¨æä¾›äº†åˆ†å¸ƒçš„ç¨³å¥ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œå¹¶ä¸”æ‚¨å¯ä»¥è½»æ¾åœ°æ·»åŠ æ–°çš„æ•°æ®/è¯æ®æ¥å®Œå–„æ‚¨çš„å…ˆéªŒçŸ¥è¯†ã€‚ä½¿ç”¨ PyMC3ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™ä¸€ç‚¹è¿›ä¸€æ­¥æ‰©å±•åˆ°åˆ†å±‚å»ºæ¨¡ï¼Œæˆ‘ä»¬ä¸ä»…å¯ä»¥æ¯”è¾ƒå“ç‰Œï¼Œè¿˜å¯ä»¥å¯¹æ¯æ¬¾é‹çš„ç›®æ ‡åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ï¼Œå³ä½¿æˆ‘ä»¬åªæœ‰æ¯æ¬¾é‹ç›¸å¯¹å°‘é‡çš„æ•°æ®ã€‚

æˆ‘ä»¬æœ€åˆçš„ç›®æ ‡æ˜¯ä¸º Yeezys å’Œ Off-white çš„åˆ©æ¶¦ç‡å»ºæ¨¡ï¼Œä»¥å¸®åŠ©æˆ‘ä»¬åœ¨è½¬å”®ä¸–ç•Œä¸­æ‰¾åˆ°æ›´å¥½çš„æƒè¡¡ã€‚çœ‹çœ‹æˆ‘ä»¬çš„æ•°æ®é›†ï¼ŒYeezys çš„è½¬å”®æ•°é‡å å‹å€’æ€§å¤šæ•°ï¼Œè¿™ç»™äººçš„å°è±¡æ˜¯ï¼Œè¿™äº›å°†æ˜¯æ›´å¥½çš„ç›®æ ‡é€‰æ‹©ã€‚åœ¨ä½¿ç”¨è´å¶æ–¯ä¼°è®¡å¯¹æˆ‘ä»¬çš„ç›®æ ‡åˆ©æ¶¦åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡åï¼Œæˆ‘ä»¬å‘ç°ç™½è‰²äººç§çš„åˆ©æ¶¦ç‡å¯ä»¥é«˜å‡ºè¿‘ 1.3 ä¸ªæ ‡å‡†å·®ã€‚ä½œä¸ºè€å…‹çš„ç‹‚çƒ­çˆ±å¥½è€…ï¼Œè¿™æ˜¯ä¸€ä¸ªå¥½æ¶ˆæ¯ï¼

**å‚è€ƒæ–‡çŒ®**

[1]å¥¥æ–¯ç“¦å°”å¤šÂ·é©¬ä¸ï¼Œ[ç”¨ Python è¿›è¡Œè´å¶æ–¯åˆ†æ](https://learning.oreilly.com/library/view/bayesian-analysis-with/9781785883804/)

[2]å¡æ¢…éš†Â·æˆ´ç»´æ£®-çš®éš†ï¼Œ[é»‘å®¢çš„æ¦‚ç‡ç¼–ç¨‹å’Œè´å¶æ–¯æ–¹æ³•](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers)

[3] PyMC3ï¼Œ[äº‹å‰å’Œäº‹åé¢„æµ‹æ£€æŸ¥](https://docs.pymc.io/notebooks/posterior_predictive.html)

[4] PyMC3ï¼Œ[è´å¶æ–¯ä¼°è®¡å–ä»£äº† T æ£€éªŒ](https://docs.pymc.io/pymc-examples/examples/case_studies/BEST.html)

[5] PyMC3ï¼Œ[è¯Šæ–­æœ‰åå·®çš„æ¨ç†ä¸åˆ†æ­§](https://docs.pymc.io/pymc-examples/examples/diagnostics_and_criticism/Diagnosing_biased_Inference_with_Divergences.html)