# 理解模型和算法

> 原文：<https://towardsdatascience.com/making-sense-of-models-and-algorithms-9f753a924092?source=collection_archive---------28----------------------->

数据科学家越来越意识到，当我们简单地将数据放入模型(无论多么强大)并在没有真正理解是什么产生的情况下使用结果时，我们面临的风险。为了限制代价高昂(甚至有害)的错误和偏见，我们需要避免众所周知的黑箱。幸运的是，TDS 作者非常擅长理解复杂的概念。这里是一些我们最近最喜欢的解释模型和算法的具体细节的帖子。

*   [**了解梯度推进决策树如何工作**](/gradient-boosted-decision-trees-explained-with-a-real-life-example-and-some-python-code-77cee4ccf5e) 。在过去的几周里， [Carolina Bento](https://medium.com/u/e960c0367546?source=post_page-----9f753a924092--------------------------------) 耐心地带领我们走过了基于树的算法的复杂道路。在她的系列文章的最后一部分中，Carolina 探索了梯度增强决策树，将它们与其他一些流行的算法进行了比较，并展示了它们控制模型偏差的能力。
*   [**更好地理解图形嵌入算法背后的数学原理**](/behind-the-scenes-on-the-fast-random-projection-algorithm-for-generating-graph-embeddings-efb1db0895) 。快速随机投影(FastRP)算法——名副其实——非常快速，知道如何部署它会非常方便。CJ Sullivan 的帖子是关于其基本功能和核心数学概念的精彩入门。

![](img/46037b18ec62fc4fd8631a2d971f4123.png)

照片由 [Aaron Burden](https://unsplash.com/@aaronburden?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄

*   [**发现多智能体强化学习(MARL)算法背后的历史**](/from-a-to-marl-part-1-mapf-d4c0796ce1af) 。当我们读到机器学习的最新前沿发展时，有时很容易忘记让我们走到今天的漫长而曲折的道路。Omri Kaduri 的五部分系列从最开始就公正地讲述了 RL 的历史——第一部分集中在 A*算法(可以追溯到 1968 年)及其后续的改进迭代。
*   [**采取正确的步骤给你的模型一个更好的记忆**](/bayesian-hierarchical-modeling-in-pymc3-d113c97f5149) 。[Robert kübler 博士](https://medium.com/u/6d6b5fb431bf?source=post_page-----9f753a924092--------------------------------)求助于贝叶斯分层建模和 PyMC3 来解决处理未规划模型时常见的过拟合问题。结果是一个更有效的过程，防止罗伯特所谓的“模型的健忘症。”
*   [**探索一个有趣而迷人的人工智能游戏项目**](/training-an-ai-to-play-warhammer-40k-part-one-planning-78aa5dfa888a) 。如果你曾经想更好地掌握强化学习*和*如何训练人工智能(最终)击败它们的人类创造者，请加入 [Ben Williams](https://medium.com/u/348277337eba?source=post_page-----9f753a924092--------------------------------) 的行列，他将着手构建一个战锤 40k-playing 代理。在这篇文章中，Ben 搭建了舞台，奠定了基础；在以后的文章中，您将会看到这个项目的雏形。
*   [**认识一位利用计量经济学技能促进社会公正的数据科学家**](/why-data-scientists-should-stay-open-minded-curious-and-non-judgemental-49784a883a78) 。如果我们不考虑它们对人类和社区的影响，最强大的算法也只能带我们走这么远，甚至会造成伤害。这是 Haaya Naushan 在最近与 TDS 的本胡伯尔曼 T21 的谈话中强有力地提出的一个观点，她还谈到了保持好奇心和开放思想的重要性，以及将一个人的数据科学之旅转变为自我发现的过程的好处。

我们喜欢从我们发布的帖子中学习新的东西，我们更喜欢与你分享它们。感谢你找到的所有支持我们工作的方式，分享我们的工作，并与我们互动。

直到下一个变量，
TDS 编辑

# 我们策划主题的最新内容:

## [入门](https://towardsdatascience.com/tagged/getting-started)

*   [10 分钟后的飞行表演](/airtable-in-10-minutes-d06f7d73c6d1)作者[杰夫·黑尔](https://medium.com/u/451599b1142a?source=post_page-----9f753a924092--------------------------------)
*   [XGBost 回归:解释给我听就像我 10 岁](/xgboost-regression-explain-it-to-me-like-im-10-2cf324b0bbdb)作者 [Shreya Rao](https://medium.com/u/99b63de2f2c3?source=post_page-----9f753a924092--------------------------------)
*   [快速移动而不破坏 ML 中的东西](/move-fast-without-breaking-things-in-ml-c070bfca2705)由 [Aparna Dhinakaran](https://medium.com/u/f32f85889f3a?source=post_page-----9f753a924092--------------------------------)

## [实践教程](https://towardsdatascience.com/tagged/hands-on-tutorials)

*   [有了 MAPIE，不确定性又回到了机器学习中](/with-mapie-uncertainties-are-back-in-machine-learning-882d5c17fdc3)
*   [实验设计响应优化和 Python](/response-optimization-with-design-of-experiments-and-python-63f9afb3f26f) 作者 [Andrea Castiglioni](https://medium.com/u/17db10ba741b?source=post_page-----9f753a924092--------------------------------)
*   [Sejal Dua](/extracting-metadata-from-medium-daily-digest-newsletters-via-gmail-api-97eee890a439)[通过 Gmail API](https://medium.com/u/e353ddb0c125?source=post_page-----9f753a924092--------------------------------) 从媒体每日文摘简讯中提取元数据

## [深潜](https://towardsdatascience.com/tagged/deep-dives)

*   [智力的丧失功能](/the-loss-function-of-intelligence-44bf9913733e)由[弗里克·范·桑贝克](https://medium.com/u/268961c0b194?source=post_page-----9f753a924092--------------------------------)
*   [A/B 测试设计、实施和缺陷的完整指南](/simple-and-complet-guide-to-a-b-testing-c34154d0ce5a)作者 [Tatev Karen](https://medium.com/u/d12e4d4d0100?source=post_page-----9f753a924092--------------------------------)
*   [带到推特:国会议员的社交媒体分析](/take-it-to-twitter-sentiment-analysis-of-congressional-twitter-in-r-ee206a5b05bc)作者[布莱克·罗伯特·米尔斯](https://medium.com/u/f6081040f6ab?source=post_page-----9f753a924092--------------------------------)

## [思想和理论](https://towardsdatascience.com/tagged/thoughts-and-theory)

*   [学会复制论文:初学者指南](/learn-to-reproduce-papers-beginners-guide-2b4bff8fcca0)奥尔加·切尔内茨卡[著](https://medium.com/u/cc932e019245?source=post_page-----9f753a924092--------------------------------)
*   [GLMs 第三部分:深度神经网络作为递归广义线性模型](/glms-part-iii-deep-neural-networks-as-recursive-generalized-linear-models-ccb02817c9b5)作者 [Andrew Rothman](https://medium.com/u/4688574fc42a?source=post_page-----9f753a924092--------------------------------)
*   [NeRF 和当图形变得可微时会发生什么](/nerf-and-what-happens-when-graphics-becomes-differentiable-88a617561b5d)作者 [Jonathan Laserson 博士](https://medium.com/u/56d1c8006910?source=post_page-----9f753a924092--------------------------------)