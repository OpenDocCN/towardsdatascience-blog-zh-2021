# ä»ç†ŠçŒ«åˆ° PySpark

> åŸæ–‡ï¼š<https://towardsdatascience.com/from-pandas-to-pyspark-fd3a908e55a0?source=collection_archive---------7----------------------->

![](img/ad02c21c88a2631129533aeaf46cf905.png)

ç…§ç‰‡ç”±[hÂ·æµ·å°”æ—](https://unsplash.com/@heyerlein?utm_source=medium&utm_medium=referral)åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) æ‹æ‘„

## åˆ©ç”¨æ‚¨çš„ç†ŠçŒ«æ•°æ®æ“ä½œæŠ€èƒ½æ¥å­¦ä¹  PySpark

å¯¹äºæ•°æ®åˆ†æå¸ˆã€æ•°æ®ç§‘å­¦å®¶å’Œä»»ä½•ä¸æ•°æ®æ‰“äº¤é“çš„äººæ¥è¯´ï¼Œèƒ½å¤Ÿç†Ÿç»ƒã€é«˜æ•ˆåœ°æ“ä½œå¤§æ•°æ®æ˜¯ä¸€é¡¹æœ‰ç”¨çš„æŠ€èƒ½ã€‚å¦‚æœæ‚¨å·²ç»ç†Ÿæ‚‰ Python å’Œ pandasï¼Œå¹¶ä¸”æƒ³è¦å­¦ä¹ è®¨è®ºå¤§æ•°æ®ï¼Œä¸€ä¸ªå¥½çš„å¼€å§‹æ–¹å¼æ˜¯ç†Ÿæ‚‰ PySparkï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äº Apache Spark çš„ Python APIï¼Œ[ä¸€ä¸ªæµè¡Œçš„å¤§æ•°æ®å¼€æºæ•°æ®å¤„ç†å¼•æ“](https://www.ibm.com/cloud/blog/hadoop-vs-spark)ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†å¹¶æ’æ¯”è¾ƒç”¨äºåŸºæœ¬æ•°æ®æ“ä½œä»»åŠ¡çš„ pandas ä»£ç ç‰‡æ®µå’Œå®ƒä»¬åœ¨ PySpark ä¸­çš„å¯¹åº”éƒ¨åˆ†ã€‚

*è¿™ç¯‡æ–‡ç« å‡è®¾è¯»è€…èƒ½å¤Ÿç†Ÿç»ƒåœ°ä½¿ç”¨ Python ä¸­çš„ pandas æ“ä½œæ•°æ®ã€‚*

# 0.èµ„æ–™ç»„ğŸ“¦

è®©æˆ‘ä»¬ä»å¯¼å…¥å¿…è¦çš„åº“å¼€å§‹ã€‚åœ¨ PySpark ä¸­ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ª Spark ä¼šè¯ã€‚ä¸€æ—¦åˆ›å»ºäº† Spark ä¼šè¯ï¼Œå°±å¯ä»¥ä»: [http://localhost:4040/](http://localhost:4040/) è®¿é—® Spark web ç”¨æˆ·ç•Œé¢(Web UI)ã€‚ä¸‹é¢å®šä¹‰çš„åº”ç”¨ç¨‹åºåç§°â€œæ•™ç¨‹â€å°†ä½œä¸ºåº”ç”¨ç¨‹åºåç§°æ˜¾ç¤ºåœ¨ Web UI çš„å³ä¸Šè§’ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ä¸ä¼šä½¿ç”¨ Web UIï¼Œä½†æ˜¯ï¼Œå¦‚æœä½ æœ‰å…´è¶£äº†è§£æ›´å¤šï¼Œè¯·æŸ¥çœ‹å®˜æ–¹æ–‡æ¡£ã€‚

```
import pandas as pd
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('tutorial').getOrCreate()
```

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[ä¼é¹…æ•°æ®é›†](https://github.com/mwaskom/seaborn-data/blob/master/penguins.csv)ã€‚ä½¿ç”¨ä¸‹é¢çš„è„šæœ¬ï¼Œæˆ‘ä»¬å°†åœ¨å·¥ä½œç›®å½•ä¸­ä¿å­˜æ•°æ®çš„ä¿®æ”¹ç‰ˆæœ¬`penguins.csv`ã€‚

```
from seaborn import load_dataset
(load_dataset('penguins')
    .drop(columns=['culmen_length_mm', 'culmen_depth_mm'])
    .rename(columns={'flipper_length_mm': 'flipper',
                     'body_mass_g': 'mass'})
    .to_csv('penguins.csv', index=False))
```

# 1.æ¯”è¾ƒğŸ”

ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ä¸¤ä¸ªåº“ä¹‹é—´çš„è¯­æ³•æ¯”è¾ƒã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œåªæ˜¾ç¤º PySpark è¾“å‡ºï¼Œä»¥å‡å°‘å¸–å­çš„æ··ä¹±ã€‚

## ğŸ“ 1.1.åŸºç¡€

ä¸¤ä¸ªåº“çš„æ•°æ®å¯¹è±¡éƒ½è¢«ç§°ä¸º data frame:pandas data frame vs PySpark data frameã€‚è®©æˆ‘ä»¬å¯¼å…¥æ•°æ®å¹¶æ£€æŸ¥å…¶å½¢çŠ¶:

```
# ğŸ¼ pandas 
df = pd.read_csv('penguins.csv')
df.shape# ğŸ‡ PySpark
df = spark.read.csv('penguins.csv', header=True, inferSchema=True)
df.count(), len(df.columns)
```

![](img/d33fcdac3987628e1aa46e0d5358dfb3.png)

å½“ä½¿ç”¨ PySpark å¯¼å…¥æ•°æ®æ—¶ï¼Œç¬¬ä¸€è¡Œè¢«ç”¨ä½œæ ‡é¢˜ï¼Œå› ä¸ºæˆ‘ä»¬æŒ‡å®šäº†`header=True`ï¼Œå¹¶ä¸”æ•°æ®ç±»å‹è¢«æ¨æ–­ä¸ºæ›´åˆé€‚çš„ç±»å‹ï¼Œå› ä¸ºæˆ‘ä»¬è®¾ç½®äº†`inferSchema=True`ã€‚å¦‚æœæ‚¨æ„Ÿåˆ°å¥½å¥‡ï¼Œå¯ä»¥å°è¯•ä¸ä½¿ç”¨è¿™äº›é€‰é¡¹è¿›è¡Œå¯¼å…¥ï¼Œå¹¶æ£€æŸ¥æ•°æ®å¸§åŠå…¶æ•°æ®ç±»å‹(ä¸ pandas ç±»ä¼¼ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ PySpark æ•°æ®å¸§çš„`df.dtypes`æ¥æ£€æŸ¥æ•°æ®ç±»å‹)ã€‚

ä¸ç†ŠçŒ« DataFrame ä¸åŒï¼ŒPySpark DataFrame æ²¡æœ‰`.shape`è¿™æ ·çš„å±æ€§ã€‚æ‰€ä»¥ä¸ºäº†å¾—åˆ°æ•°æ®å½¢çŠ¶ï¼Œæˆ‘ä»¬åˆ†åˆ«æ‰¾åˆ°è¡Œæ•°å’Œåˆ—æ•°ã€‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ£€æŸ¥æœ‰å…³æ•°æ®çš„é«˜çº§ä¿¡æ¯:

```
# ğŸ¼ pandas 
df.info()# ğŸ‡ PySpark
df.printSchema()
```

![](img/b9d6a14a135572575e970d631eef40bc.png)

è™½ç„¶è¿™ä¸ªæ–¹æ³•ä¸ä¼šç»™`df.info()`ç›¸åŒçš„è¾“å‡ºï¼Œä½†å®ƒæ˜¯æœ€æ¥è¿‘çš„å†…ç½®æ–¹æ³•ä¹‹ä¸€ã€‚æ˜¯æ—¶å€™çœ‹çœ‹æ•°æ®çš„å¼€å¤´äº†:

```
# ğŸ¼ pandas 
df.head()# ğŸ‡ PySpark
df.show(5)
```

![](img/2cc7481f3c8bdf7dfa1716e953822fa4.png)

é»˜è®¤æƒ…å†µä¸‹ï¼Œå¦‚æœè¶…è¿‡ 20 è¡Œï¼Œ`df.show()`å°†æ˜¾ç¤º 20 è¡Œã€‚PySpark DataFrame å…¶å®æœ‰ä¸€ä¸ªå«`.head()`çš„æ–¹æ³•ã€‚è¿è¡Œ`df.head(5)`æä¾›å¦‚ä¸‹è¾“å‡º:

![](img/4dd285b411edce7b203710ac882db451.png)

æ¥è‡ª`.show()`æ–¹æ³•çš„è¾“å‡ºæ›´åŠ ç®€æ´ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†åœ¨è¿™ç¯‡æ–‡ç« çš„å‰©ä½™éƒ¨åˆ†ä½¿ç”¨`.show()`æ¥æŸ¥çœ‹æ•°æ®é›†çš„é¡¶éƒ¨è¡Œã€‚ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•é€‰æ‹©åˆ—:

```
# ğŸ¼ pandas 
df[['island', 'mass']].head(3)# ğŸ‡ PySpark
df[['island', 'mass']].show(3)
```

![](img/c9022576cde276240b4b10a0b9e81361.png)

è™½ç„¶æˆ‘ä»¬åœ¨è¿™é‡Œå¯ä»¥ä½¿ç”¨å‡ ä¹ç±»ä¼¼ç†ŠçŒ«çš„è¯­æ³•ï¼Œä½†ä»¥ä¸‹ç‰ˆæœ¬çš„ä»£ç ç‰‡æ®µå¯èƒ½æ›´å¸¸ç”¨äºåœ¨ PySpark ä¸­é€‰æ‹©åˆ—:

```
df.select('island', 'mass').show(3)
df.select(['island', 'mass']).show(3)
```

## ğŸ“ 1.2.è¿‡æ»¤

è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•æ ¹æ®æ¡ä»¶è¿‡æ»¤æ•°æ®:

```
# ğŸ¼ pandas 
df[df['species']=='Gentoo'].head()# ğŸ‡ PySpark
df[df['species']=='Gentoo'].show(5)
```

![](img/1ec6d7e67cd18f1c9c1497a08b8b190b.png)

è¿™ä¸¤ä¸ªåº“çš„è¯­æ³•å‡ ä¹ç›¸åŒã€‚ä¸ºäº†è·å¾—ç›¸åŒçš„è¾“å‡ºï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨:

```
df.filter(df['species']=='Gentoo').show(5) df.filter("species=='Gentoo'").show(5) 
```

ä¸‹é¢æ˜¾ç¤ºäº†ä¸€äº›å¸¸è§çš„è¿‡æ»¤å™¨æ¯”è¾ƒ:

```
# ğŸ¼ pandas 
2a df[df['species'].isin(['Chinstrap', 'Gentoo'])].head()
3a df[df['species'].str.match('G.')].head()
4a df[df['flipper'].between(225,229)].head()
5a df[df['mass'].isnull()].head()1b df.loc[df['species']!='Gentoo'].head()
2b df[~df['species'].isin(['Chinstrap', 'Gentoo'])].head()
3b df[-df['species'].str.match('G.')].head()
4b df[~df['flipper'].between(225,229)].head()
5b df[df['mass'].notnull()].head()6 df[(df['mass']<3400) & (df['sex']=='Male')].head()
7 df[(df['mass']<3400) | (df['sex']=='Male')].head()# ğŸ‡ PySpark
2a df[df['species'].isin(['Chinstrap', 'Gentoo'])].show(5)
3a df[df['species'].rlike('G.')].show(5)
4a df[df['flipper'].between(225,229)].show(5)
5a df[df['mass'].isNull()].show(5)1b df[df['species']!='Gentoo'].show(5)
2b df[~df['species'].isin(['Chinstrap', 'Gentoo'])].show(5)
3b df[~df['species'].rlike('G.')].show(5)
4b df[~df['flipper'].between(225,229)].show(5)
5b df[df['mass'].isNotNull()].show(5)6 df[(df['mass']<3400) & (df['sex']=='Male')].show(5)
7 df[(df['mass']<3400) |(df['sex']=='Male')].show(5)
```

è™½ç„¶åœ¨ pandas ä¸­`~`å’Œ`-`éƒ½ç”¨ä½œå¦å®šï¼Œä½†æ˜¯åœ¨ PySpark ä¸­åªæœ‰`~`ç”¨ä½œæœ‰æ•ˆå¦å®šã€‚

## ğŸ“ 1.3.æ•´ç†

è®©æˆ‘ä»¬å¯¹æ•°æ®è¿›è¡Œåˆ†ç±»ï¼Œæ£€æŸ¥è´¨é‡*æœ€å°çš„ 5 è¡Œ*:

```
# ğŸ¼ pandas 
df.nsmallest(5, 'mass')# ğŸ‡ PySpark
df[df['mass'].isNotNull()].orderBy('mass').show(5)
```

![](img/96b1a3eaa658c13e4ce30b349b177548.png)

Pandas çš„`.nsmallest()`å’Œ`.nlargest()`æ–¹æ³•æ˜æ™ºåœ°æ’é™¤äº†ç¼ºå¤±å€¼ã€‚ç„¶è€Œï¼ŒPySpark æ²¡æœ‰ç­‰æ•ˆçš„æ–¹æ³•ã€‚ä¸ºäº†è·å¾—ç›¸åŒçš„è¾“å‡ºï¼Œæˆ‘ä»¬é¦–å…ˆè¿‡æ»¤æ‰ç¼ºå°‘*è´¨é‡*çš„è¡Œï¼Œç„¶åæˆ‘ä»¬å¯¹æ•°æ®è¿›è¡Œæ’åºå¹¶æ£€æŸ¥å‰ 5 è¡Œã€‚å¦‚æœæ²¡æœ‰ä¸¢å¤±æ•°æ®ï¼Œè¯­æ³•å¯ä»¥ç¼©çŸ­ä¸º:`df.orderBy(â€˜massâ€™).show(5)`ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹ä½¿ç”¨`.sort()`ä»£æ›¿`.orderBy()`çš„å¦ä¸€ç§æ’åºæ–¹å¼:

```
# ğŸ¼ pandas 
df.nlargest(5, 'mass')# ğŸ‡ PySpark
df.sort('mass', ascending=False).show(5)
```

![](img/6c62cdec7e95ebee316f1bef6018c7e4.png)

è¯­æ³•çš„è¿™äº›å˜åŒ–ä¹Ÿæ˜¯æœ‰æ•ˆçš„:

```
df.sort(df['mass'].desc()).show(5)
df.orderBy('mass', ascending=False).show(5)
df.orderBy(df['mass'].desc()).show(5)
```

æˆ‘ä»¬å¯ä»¥æŒ‰å¤šåˆ—æ’åºï¼Œå¦‚ä¸‹æ‰€ç¤º:

```
# ğŸ¼ pandas 
df.sort_values(['mass', 'flipper'], ascending=False).head()# ğŸ‡ PySpark
df.orderBy(['mass', 'flipper'], ascending=False).show(5)
```

![](img/705c5810d51707b15edeef7fa767be7c.png)

åœ¨ PySpark é‡Œï¼Œä½ å¯ä»¥è¿™æ ·ä¸ç”¨å•å­å°±è„±èº«:`df.orderBy(â€˜massâ€™, â€˜flipperâ€™, ascending=False).show(5)`ã€‚è¦æŒ‰ä¸åŒæ–¹å‘çš„å¤šåˆ—æ’åº:

```
# ğŸ¼ pandas 
df.sort_values(['mass', 'flipper'], ascending=[True, False]).head()# ğŸ‡ PySpark
df[df['mass'].isNotNull()]\
  .sort('mass', 'flipper', ascending=[True, False]).show(5)
```

![](img/67f4aa3e59947a86ecb10ddec049a51d.png)

è¿™é‡Œæœ‰ä¸€ä¸ªæ›¿ä»£æ–¹æ¡ˆ:

```
df[df['mass'].isNotNull()]\
  .orderBy(df['mass'].asc(), df['flipper'].desc()).show(5)
```

## ğŸ“ 1.4.èšåˆ

ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹å‡ ä¸ªæ±‡æ€»æ•°æ®çš„ä¾‹å­ã€‚ç®€å•çš„èšåˆéå¸¸ç±»ä¼¼ï¼Œå¦‚ä¸‹æ‰€ç¤º:

```
# ğŸ¼ pandas 
df.agg({â€˜flipperâ€™: â€˜meanâ€™})# ğŸ‡ PySpark
df.agg({'flipper': 'mean'}).show()
```

![](img/353564ab1fde29969920ff1e0d2824ea.png)

æŸ¥çœ‹å¤šä¸ªèšåˆæ—¶ï¼Œæˆ‘ä»¬éœ€è¦é‡‡ç”¨ä¸åŒçš„æ–¹æ³•:

```
# ğŸ¼ pandas 
df.agg({'flipper': ['min', 'max']})# ğŸ‡ PySpark
from pyspark.sql import functions as F
df.agg(F.min('flipper'), F.max('flipper')).show()
```

![](img/d3b631dd00b0acb9e53f6a18ac2ac3c0.png)

è¦è·å–åˆ—ä¸­çš„ä¸åŒå€¼:

```
# ğŸ¼ pandas 
df['species'].unique()# ğŸ‡ PySpark
df.select('species').distinct().show()
```

![](img/4942239148d09f87a2395df2f476d794.png)

è¦åœ¨ä¸€åˆ—ä¸­è·å–å¤šä¸ªä¸åŒçš„å€¼ï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:

```
# ğŸ¼ pandas 
df['species'].nunique()# ğŸ‡ PySpark
df.select('species').distinct().count()
```

![](img/462418ec775db2b831fd450303803906.png)

## ğŸ“ 1.5.æŒ‰ç»„æ±‡æ€»

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæ‚¨å¯èƒ½å·²ç»æ³¨æ„åˆ° PySpark åœ¨æ–¹æ³•å’Œå‡½æ•°ä¸­ä½¿ç”¨äº†*é©¼å³°*ã€‚å¯¹äº`.groupBy()`ä¹Ÿæ˜¯å¦‚æ­¤ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„æŒ‰èšåˆåˆ†ç»„çš„ç¤ºä¾‹:

```
# ğŸ¼ pandas 
df.groupby('species')['mass'].mean()# ğŸ‡ PySpark
df.groupBy('species').agg({'mass': 'mean'}).show()
```

![](img/5b2a580fbe64c1a02b880c0da7bb2d26.png)

ä»¥ä¸‹æ˜¯èšåˆå¤šä¸ªé€‰å®šåˆ—çš„ç¤ºä¾‹:

```
# ğŸ¼ pandas 
df.groupby(â€˜speciesâ€™).agg({â€˜flipperâ€™: â€˜sumâ€™, â€˜massâ€™: â€˜meanâ€™})# ğŸ‡ PySpark
df.groupBy('species').agg({'flipper': 'sum', 'mass': 'mean'}).show()
```

![](img/7976ae3dd82bec2517d5581e00e9cc6c.png)

å¦‚æœæˆ‘ä»¬ä¸æŒ‡å®šåˆ—ï¼Œå®ƒå°†æ˜¾ç¤ºæ‰€æœ‰æ•°å­—åˆ—çš„ç»Ÿè®¡ä¿¡æ¯:

```
# ğŸ¼ pandas 
df.groupby('species').mean()# ğŸ‡ PySpark
df.groupBy('species').mean().show()
```

![](img/500deda6e86e56987849d72ba20e910b.png)

æˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨`.avg()`ä»£æ›¿`.mean()`ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`df.groupBy(â€˜speciesâ€™).avg().show()`ã€‚

è¿™å°±æ˜¯è¿™ç¯‡æ–‡ç« çš„å…¨éƒ¨å†…å®¹ï¼å¸Œæœ›è¿™äº›æ¯”è¾ƒå¯¹æ‚¨æœ‰ç”¨ï¼Œå¹¶å¯¹ PySpark è¯­æ³•æœ‰æ‰€äº†è§£ã€‚æ‚¨å¯èƒ½å·²ç»æ³¨æ„åˆ°ï¼Œåœ¨åŸºæœ¬ä»»åŠ¡æ–¹é¢ï¼Œè¿™ä¸¤ä¸ªåº“æœ‰å¾ˆå¤šç›¸ä¼¼ä¹‹å¤„ã€‚è¿™ä½¿å¾—å¯¹ç†ŠçŒ«æœ‰å·¥ä½œçŸ¥è¯†çš„äººæ›´å®¹æ˜“å¼€å§‹ä½¿ç”¨ PySparkã€‚

![](img/b2b8c93b70af741d58ac7583d76ae966.png)

ç…§ç‰‡ç”±[æ²™å“ˆè¾¾ç‰¹Â·æ‹‰èµ«æ›¼](https://unsplash.com/@hishahadat?utm_source=medium&utm_medium=referral)åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šæ‹æ‘„

*æ‚¨æƒ³è®¿é—®æ›´å¤šè¿™æ ·çš„å†…å®¹å—ï¼Ÿåª’ä½“ä¼šå‘˜å¯ä»¥æ— é™åˆ¶åœ°è®¿é—®åª’ä½“ä¸Šçš„ä»»ä½•æ–‡ç« ã€‚å¦‚æœæ‚¨ä½¿ç”¨* [*æˆ‘çš„æ¨èé“¾æ¥*](https://zluvsand.medium.com/membership) ï¼Œ*æˆä¸ºä¼šå‘˜ï¼Œæ‚¨çš„ä¸€éƒ¨åˆ†ä¼šè´¹å°†ç›´æ¥ç”¨äºæ”¯æŒæˆ‘ã€‚*

æ„Ÿè°¢æ‚¨é˜…è¯»æˆ‘çš„æ–‡ç« ã€‚å¦‚æœä½ æ„Ÿå…´è¶£ï¼Œè¿™é‡Œæœ‰æˆ‘çš„ä¸€äº›å…¶ä»–å¸–å­çš„é“¾æ¥:
â—¼ï¸ï¸ [ç»™ pandas ç”¨æˆ·çš„ 5 ä¸ªæç¤º](/5-tips-for-pandas-users-e73681d16d17)
â—¼ï¸ï¸ [åœ¨ pandas ä¸­èšåˆæ•°æ®çš„ 5 ä¸ªæç¤º](/writing-5-common-sql-queries-in-pandas-90b52f17ad76)
â—¼ï¸ï¸ [åœ¨ pandas ä¸­ç¼–å†™ 5 ä¸ªå¸¸è§çš„ SQL æŸ¥è¯¢](/writing-5-common-sql-queries-in-pandas-90b52f17ad76)
â—¼ï¸ï¸ [åœ¨ pandas ä¸­ç¼–å†™é«˜çº§ SQL æŸ¥è¯¢](/writing-advanced-sql-queries-in-pandas-1dc494a17afe)
â—¼ï¸ï¸ [å¦‚ä½•åœ¨ pandas DataFrame ä¸­è½¬æ¢å˜é‡](/transforming-variables-in-a-pandas-dataframe-bce2c6ef91a1)

å†è§ğŸƒ ğŸ’¨