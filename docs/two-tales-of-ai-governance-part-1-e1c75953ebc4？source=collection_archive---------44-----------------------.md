# 人工智能治理的两个故事

> 原文：<https://towardsdatascience.com/two-tales-of-ai-governance-part-1-e1c75953ebc4?source=collection_archive---------44----------------------->

## **良好的数据驱动决策**

这是一篇关于**数据驱动的**和**良好数据驱动的决策制定**的两部分文章。它使用两个故事来说明任何人工智能(AI)应用程序的支柱概念，以增强人类决策者或自主决策。

这篇文章是*而不是*关于什么的——深入的技术或规范分析。它的目的只是在人工智能治理的背景下提出问题并鼓励关于数据和模型的对话。

# 第 1 部分:切尔姆的白痴——我们的数据有多好？

![](img/0a7332368cdfe13b674fa33d43799a1b.png)

Joanna Nix-Walkup 在 [Unsplash](https://unsplash.com) 上拍摄的照片

有一个意第绪语的民间故事，讲述了格泽尔如何成为切尔姆镇的哲学家。有一天，Getzel 出发去另一个城镇，但是一路上他觉得很累，决定小睡一会儿。他害怕忘记自己是从哪个方向来的，所以他脱下鞋子，让它们指向他要去的城镇的方向。当盖泽尔睡觉的时候，一个路过的农民拿走了他的鞋子并试了试。因为他们不是他的尺寸，他把他们放回去，但指向不同的方向。Getzel 醒来后顺着他鞋子朝向的方向走去，于是他不知不觉地走回了家。盖泽尔断定还有一个和他一模一样的切尔姆。不仅如此，由于一切都与他自己的城镇相同，他甚至得出结论，整个世界是一个巨大的 Chelm。

尽管这个故事有各种版本和解释，但它说明了一个误导数据驱动决策的案例。在这个故事中，决策者使用数据(和模型)来评估他的风险。格泽尔做出了明智的决定，但却是错误的决定。他的决定导致了意想不到的后果和不准确的结论，最终增加了不确定性，而这正是数据驱动的决策制定所要最小化的。

在绝大多数情况下，我们更喜欢依靠数据而不是我们的信念或直觉来做决定，尤其是那些涉及风险的决定。因为冒险对回报至关重要，所以我们经常以这样或那样的方式在做决定前评估风险。我们有兴趣了解个人或组织层面的任何逆境的机会(如果可能的话，还有严重程度)，从健康到财富，从财产到气候。

我们用来做这些决定的数据由一个模型处理和解释。模型是现实生活情况或自然现象的表现。例如，算法是遵循一套规则或计算的模型，允许我们解决问题，从而做出决策——但或许更重要的是，使这一过程自动化。

算法由数据提供，数据的准确性以及定义模型规则的准确性决定了结果的准确性(即预测准确性)。在静态条件下，当使用通用算法来自动化简单的决策(如 Getzel 的算法)时，大多数模型都会产生相当准确的结果。当提供给模型的数据没有被正确验证时，问题就出现了。结果，预测的事件或结果不再准确，导致错误的决策。

让我们抛开现实生活中需要考虑的关键因素，比如数据的大小、安全性和隐私。Getzel 的天真模型提供了一个很好的线索来记住去哪里，然而收集的数据却指向了错误的方向。在这种情况下，问题超出了通常用来描述数据质量重要性的众所周知的“垃圾输入，垃圾输出”。这里关注的是我们需要在现实生活中实施的政策和措施，以确保收集的数据为我们指明正确的方向。

因此，我们获取、准备和分析数据的方式至关重要。低估它的重要性会产生一系列不准确的结论、错误的行动和意想不到的问题——甚至是想象中的问题，如 Getzel 的问题。这个故事经常被命名为“切尔姆的白痴”，这可能不是巧合

Getzel 的故事为当今的大数据世界提供了一个有意义的教训，在这个世界中，我们将各种个人和集体决策委托给机器。这个故事与组织内数据分析的民主化以及人工智能的民主化特别相关。它清楚地说明了建立治理框架以从技术和道德上增强人工智能等数据驱动技术的重要性。

没有数据和解释这些数据的模型，我们的决定只是意见。有了有缺陷的数据或模型，我们的决定可能会像由观点产生的决定一样误导人，但没有犯错的借口。

# 第二部分:罗摩衍那的悲剧英雄——我们的模式有多好？

![](img/b2fcb80c8252185b3af66dfc91aa9a6e.png)

由 [Ruslan Poluektov](https://www.shutterstock.com/g/RuslanPoluektov) 在 [Shutterstock](https://www.shutterstock.com/home) 拍摄的照片

《美猴王的故事》是一部《罗摩衍那》的印度教史诗。在这个故事中，孙悟空或《罗摩衍那》的悲剧英雄瓦阿里和他的兄弟苏格里瓦追捕进入一个深洞的恶魔玛雅维。瓦利进入洞穴追捕恶魔，告诉苏格里瓦在外面等着。苏格里娃等了一年，然后血随着痛苦的哭喊从洞穴中涌出。苏格里瓦断定他的兄弟已经被杀，因此，为了防止恶魔攻击他们的领域，苏格里瓦用一块石头封住了洞穴，成为了猴子之王。然而，瓦阿里并没有被杀死，事实上，他战胜了恶魔。当他回家后，看到苏格里瓦扮演国王，他断定他的兄弟背叛了他。故事的结果是两兄弟变成了死敌，最终导致了瓦阿里的死亡。

和前面的故事一样，做出的决定是由数据驱动的，但却是不正确的。与 Getzel 一样，Sugriva 没有验证为模型提供的数据，兄弟俩也没有验证所用模型的正确性，导致了不准确的结论和意想不到的后果。

让我们把现实生活中需要考虑的关键但更复杂的方面放在一边，比如偏见、模型拟合、概念漂移、可解释性和其他一些问题。乍一看，瓦阿里的模型是有道理的，但它实际上并没有提供密封洞穴的原因。在现实生活的问题中，系统不是被设计来做一次性的决定，而是通过使用算法来自动化任务。这进一步增加了问题的难度，因为它需要找到一个具有最佳性能的算法，因此“给定带有标签 Y 的数据 X，找到一个误差最小的模型。”

在人工智能(AI)环境中，如果一个模型表现良好，我们通常不会关注为什么要做出决策，只要知道验证或测试数据的预测性能良好就足够了。然而，尤其是当这些预测对人类有很大影响时(例如，在医疗保健、金融、交通等方面的应用)。)，理解为什么是必须的。

罗摩衍那的故事提供了一个简单的例子来说明为什么我们不仅仅相信模型。在这个故事中，模型没有显示输入和输出之间的正确关系，因此它没有对潜在问题提供令人满意的解释或预测。

总之，这两个故事都说明了数据和模型缺陷的风险。他们表明，检测输入数据中的异常是良好的数据驱动决策的基础。它们还表明，模型处理或解释数据的方式最终限制了它的预测能力。

但是这里有一个警告，所有的模型都有内在的局限性，因为它们是心智的构造。它们是对某个现实的抽象练习的结果。因此，不确定性是模型本身固有的，因此，通常使用概率来管理模型误差。然而，当 **(1)** 模型的结果导致意想不到的后果时，如格采尔回国或苏格里瓦成为国王，或者当 **(2)** 这些结果描述了一个扭曲的系统，如格采尔或瓦阿里对世界的解释，关于模型和数据的合法性的严重问题就出现了。

这样，像 Getzel 或 Sugriva 这样的简单模型需要被质疑，更复杂的模型需要被审视。当大规模部署人工智能技术时，许多人的鞋子可能会指向错误的方向，或者在错误的时间自动封闭洞穴，甚至有人会注意到这一点。

由于这种决策的影响，组织应该采用治理框架，该框架包含标准、风险和责任，尤其是与算法决策相关的。因此，需要进行根本性的转变和组织变革，以便在保护这些数据的生产者和消费者的同时，使数据能够用于良好的决策。

数据需要由专题专家彻底检查，数据质量标准需要由公共和私营部门合作制定和修订。模型需要经过讨论，也需要与其他模型进行比较和补充。这一点尤其重要，因为模型是不可避免的:我们需要它们。尽管它们有内在的不确定性，但它们引导我们做出决定，它们是我们理解和解决问题的唯一工具。