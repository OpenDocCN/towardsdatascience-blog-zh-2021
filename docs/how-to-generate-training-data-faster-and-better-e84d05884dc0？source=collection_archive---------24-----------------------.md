# 如何更快更好地生成训练数据

> 原文：<https://towardsdatascience.com/how-to-generate-training-data-faster-and-better-e84d05884dc0?source=collection_archive---------24----------------------->

## 作为机器学习工程师，提高工作效率的最佳实践

![](img/a56e85b51b75b0ee9bce502cbd26a0eb.png)

照片由[像素](https://www.pexels.com/photo/athletes-running-on-track-and-field-oval-in-grayscale-photography-34514/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)的[皮克斯拜](https://www.pexels.com/@pixabay?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)拍摄

当你在现实世界中创建机器学习模型时，与在线课程或 Kaggle 风格的比赛相反，你需要自己生成训练数据。

这是任何 ML 项目的第一步。尽管这很重要，但却是我们最容易忽视的一点。

作为一名自由 ML 工程师，我经常接受新的项目，并且一次又一次地面临同样的问题:我如何更快更好地生成训练数据？

在本文中，我想分享我在这个过程中发现的一些最佳实践，并帮助您提高工作效率。

你可以在这个 [**资源库**](https://github.com/Paulescu/how-to-generate-training-data-faster-and-better) 中找到所有的代码。

# 问题

开发机器学习模型的第一步是获取训练数据。

在现实世界的 ML 项目中，通常情况下，您不会 ***获得*** 数据。你 ***生成*** 它。除非你在非常精通 ML 的公司工作，这些公司拥有先进的数据工程基础设施(例如谷歌、脸书、亚马逊等等)，否则这一步绝不是无足轻重的。作为初创公司的人工智能/人工智能顾问，我需要生成自己的培训数据。每次都是。

在大多数情况下，这些数据是表格形式的，即有行(样本/观测值)和列(特征和目标)的数据。这些数据存储在数据库中，如 Redshift 或 BigQuery 集群，甚至是 SQL server 或 Postgress。您可以使用 SQL 查询这些数据。

理想情况下，您应该编写一个 SQL 查询，如下所示:

然后运行一次，导出一个包含训练数据的 CSV 文件，进入数据探索和模型构建阶段。

然而，在现实中，事情要复杂一点，因为:

# 1.那个奇妙的桌子不存在

相反，您最终会编写一个更复杂的 SQL 查询，从不同的表中获取、聚合和连接数据。

大概是这样的:

当你写长 SQL 时，你一定会犯错误。要么是语法错误(很容易修复)，要么是根本错误(很难修复)，这些错误来自于对数据库中每个表和字段所代表的含义的误解。

您可能需要花几天时间，与负责数据库的人员(数据库管理员或理想情况下的数据工程师)来回通话，以了解在哪里可以找到您需要输入到模型中的每一位数据，编写查询，运行它，并祈祷能够获得您开始 ML 工作所需的黄金数据集。

因为第二个问题，这不是大多数情况下会发生的。

# 2.我的 SQL 查询不执行

您完成了长 SQL 查询的编写，并将其发送执行。

等待…等待…0%进度…仍在等待中…

是的，在你意识到它不会执行之后。

我去过那里无数次。试图得到该死的数据。

![](img/8d0f4ec65699fd785bf16027992d508a.png)

凯拉·伯顿从[派克斯](https://www.pexels.com/photo/desperate-screaming-young-boy-6624327/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)拍摄的照片

问题是你试图一次获取*太多的*数据。

一种快速解决方法是只查询一小部分数据。你可以在项目的最开始这样做，来排除障碍，并获得问题的基线表现。但是，当您想要改进模型时，您可能会意识到有一些有用的特性没有包含在查询中。这就把你带到了第三个问题。

# 3.我的 SQL 查询需要调整(通常需要很多次)

你可以用自己的方式获得一个初始数据集。然而，这种方法从长远来看是行不通的，这就是为什么:

*   在构建机器学习模型的原型时，您需要在数据库中的训练数据中添加额外的功能。因此，您需要编辑并重新运行该查询。又来了。
*   当您将您的模型转移到生产(顺便说一下，这是您工作的最终目标)时，您将需要实现一个再培训管道，以避免模型漂移。您需要每天、每周或每月重新生成一次培训数据。

生成训练数据是您需要迭代的关键步骤。像我描述的手动方法(遗憾的是，这是 ML 工程师和数据科学家在实践中最常用的方法)并不是最佳的。

有没有更好的方法解决问题 1，2，3，更好更快的生成训练数据？

没错。

# 解决方案

我想到的解决方案是基于*划分* ( *自动化*的原理🤖)和*征服*。

# 步骤 1:将 SQL 查询拆分成更小的查询

试图通过一次查询执行获取所有训练数据的问题有两个方面:

*   这个查询很可能不起作用，因为您想要一次获得的数据量太大，DB 无法处理。
*   即使查询今天运行，也不能保证它明天(当您重新训练模型时)也能运行，因为数据大小会更大。或者后天。或者另一个。最终，这将打破。

我们的朋友，数据工程师，经常使用的一个技巧是聪明地查询数据。我们运行 *N* 个查询来提取 *N* 个块中的数据，而不是一个查询提取所有数据。

例如，一个电子商务站点的数据库至少有一个包含所有历史订单的表，以及一些参数，如购买的商品 id、支付的金额等。以及购买的**时间**。不是一次获取所有数据:

您可以通过一系列查询在 *N* 个步骤中获取相同的数据:

运行 N 个较小的查询是可伸缩的，并且消除了数据库中的容量瓶颈。但是，如何自动执行 N 个查询呢？我猜您不希望将 N 个查询复制并粘贴到您的 DB IDE 或 CLI 来获取数据，对吗？

这将我们带到解决方案的第 2 步。

# 步骤 2:用 python 自动执行查询

Python 是你可能在你的机器学习项目中使用的语言。它也是一种很好的语言，可以快速地自动完成一些枯燥的事情，比如将数据从数据库中提取到 CSV 文件中。

Python 还有一个丰富的 DB 客户端库生态系统，允许您从 Python 脚本对 DB 运行查询。我过去广泛使用的一些是用于 MySQL 服务器的[***py odbc***](https://pypi.org/project/pyodbc/)或用于 postr press/Redshift 的[***psycopg 2***](https://pypi.org/project/psycopg2/)。

话虽如此，自动执行 N 个查询的一个简单方法是将一个查询字符串模板和一个简单的 *for 循环*放在一个`data.py`脚本中:

这个解决方案是可行的。但是，它也重复了很多不必要的工作人员。以前下载并存储在 CSV 文件中的数据不应重新下载，除非 SQL 查询中有错误或更改。

让我们在最后一步处理这些细节。

# 第三步:包起来

为了避免重新处理日期，我们可以添加一个`overwrite`参数。

有时您想要强制覆盖。例如，您在 SQL 查询中发现了一个错误，想要重新生成所有文件。在这种情况下，你设置`overwrite=True`。

有时，您只想下载缺失日期的文件，以扩展您的培训数据。例如，当您在生产中重新训练模型时，您不需要重新下载所有日期的数据，而只需要重新下载您训练模型时的前一个日期的数据。在这种情况下`overwrite=False`。

代码如下:

最后，我是`tqdm`图书馆的忠实粉丝。它可以让您打印出令人惊叹的进度条，为您提供关于迭代速度和预计完成时间的反馈。

再加一个吧😊

你可以在这个 [**库中找到所有的代码**](https://github.com/Paulescu/how-to-generate-training-data-faster-and-better) 🎁

# 结论

所以，这是我作为 ML 工程师提高生产力的策略之一。

使用这个漂亮的`data.py`脚本，您将能够:

*   更快地将新功能添加到您的训练集中。
*   更快地调试和重新生成数据集。
*   并最终更快更好的训练 ML 模型，创造产品。

我希望这有所帮助，乡亲们。如果有任何问题，请随时联系。

如果你想了解更多真实世界的 ML 技巧和提示，并成为一名更好的机器学习开发者，请订阅我的简讯。

我很乐意帮助你成为一名更好的机器学习开发者。

祝你愉快