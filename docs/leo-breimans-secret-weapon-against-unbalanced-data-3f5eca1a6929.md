# 利奥·布雷曼对付不平衡数据的秘密武器

> 原文：<https://towardsdatascience.com/leo-breimans-secret-weapon-against-unbalanced-data-3f5eca1a6929?source=collection_archive---------63----------------------->

## 在数据严重失衡的情况下，机器学习之父会帮助我们。

![](img/6bd1f16a6b6207e06a907c1ed418a76a.png)

[ev](https://unsplash.com/@ev?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 在 [Unsplash](https://unsplash.com/s/photos/imbalance-data?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上的照片

在一个大学项目中，我和我的同学发现自己站在一个数据集前，这个数据集代表了我们进入机器学习世界的入门仪式。

该数据集是一个 cookies 的集合，这些 cookies 来自观看了电信公司的广告横幅的用户，其中的目标变量指的是广告商是否点击了它。

外观上很简单的二元变量，直到我们计算出点击和不点击的比例。我们面对的数据集有 0.3%的不平衡，因此非常显著。

起初我们并不害怕，因为引用伏地魔的话，[你知道哈利的咒语](https://getyarn.io/yarn-clip/e01d4dec-56bd-49b0-8f19-e4d2a076c56c)。事实上，我们非常熟悉过采样和欠采样，它们是重采样技术:

*   第一种允许将少数类的随机副本整合到训练数据集中，从而倍增初始集中的比例。这种方法被认为是最稳健的方法之一。
*   第二种随机删除多数类的行，从而增加少数类的比例。主要问题是它会增加分类器的方差，并且会丢弃有用或重要的样本。
*   第三种方法，也是我更喜欢的一种，是前两种方法的混合。

正如我前面所说的，了解这些技术后，我们认为可以毫不费力地解决这个问题，但我们的数据集是如此不平衡，以至于仅仅应用随机重采样不足以建立一个可以以可接受的方式执行的模型。

在第一次绝望之后，我们开始努力寻找一个解决方案，让我们能够改善我们的模型指标，除了机器学习之父，谁能伸出援手。

# 布雷曼平衡随机森林

伟大的 Leo Breiman 又一次拯救了我们，事实上，经过仔细的搜索，我们发现了一篇非常有趣的论文，标题为“[使用随机森林学习不平衡数据](https://statistics.berkeley.edu/tech-reports/666)”[1]。

众所周知，在随机森林中，每棵树都是在初始数据集的 bootstrap 样本上拖动的，很明显，在高度不平衡的数据集上应用 bootstrap 甚至会产生更大的反作用，因为它会增加减少少数类比例的风险。

假设通过在平衡数据集上训练树，性能提高了很多，这导致了平衡随机森林算法，该算法包括以下步骤:

*   对于随机森林中的每次迭代，从少数类中抽取一个引导样本。从多数班级中随机抽取相同数量的案例，并进行替换。
*   从数据中归纳出一个分类树到最大尺寸，无需修剪。该树是用 CART 算法导出的，具有以下修改:在每个节点，不是搜索所有变量以获得最佳分割，而是仅搜索一组 m 个随机选择的变量。
*   重复上述两个步骤，重复所需的次数。汇总集合的预测并做出最终预测。

简单地说，这种方法包括在平衡数据的引导样本上训练树，考虑到每棵树的 m 个随机选择的变量。

在尝试了不同的平衡随机森林之后，不时地改变每棵树中所选变量的数量 m 以及 bootstap 样本中类的比例，我们得到了非常令人满意的评估指标。

# 最后

在我个人看来，深化这种类型的技术是有用的，因为在现实世界中，经常会遇到非常难以处理的数据集，所以我们拥有的武器越多，我们就越有可能以最有效的方式解决数据分析的问题。

非常感谢您阅读这篇文章，我希望它可能会激励您进行持续和绝望的研究，这是数据科学家工作的一部分。

[1] C. Chen，A. Liaw，L. Breiman，[利用随机森林学习不平衡数据](https://statistics.berkeley.edu/tech-reports/666) (2004)