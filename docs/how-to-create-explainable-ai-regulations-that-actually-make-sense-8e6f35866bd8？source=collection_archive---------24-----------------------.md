# 如何创建可解释的、实际上有意义的人工智能规则

> 原文：<https://towardsdatascience.com/how-to-create-explainable-ai-regulations-that-actually-make-sense-8e6f35866bd8?source=collection_archive---------24----------------------->

## [播客](https://towardsdatascience.com/tagged/tds-podcast)

## 吉莉安·哈德菲尔德谈正当人工智能和人工智能监管的未来

[苹果](https://podcasts.apple.com/ca/podcast/towards-data-science/id1470952338?mt=2) | [谷歌](https://www.google.com/podcasts?feed=aHR0cHM6Ly9hbmNob3IuZm0vcy8zNmI0ODQ0L3BvZGNhc3QvcnNz) | [SPOTIFY](https://open.spotify.com/show/63diy2DtpHzQfeNVxAPZgU) | [其他](https://anchor.fm/towardsdatascience)

*编者按:TDS 播客由 Jeremie Harris 主持，他是数据科学导师初创公司 SharpestMinds 的联合创始人。每周，Jeremie 都会与该领域前沿的研究人员和商业领袖聊天，以解开围绕数据科学、机器学习和人工智能的最紧迫问题。*

众所周知，世界各国政府都在努力制定有效的政策来应对人工智能带来的风险和机遇。发生这种情况的原因有很多:许多人——包括技术人员——认为他们了解前沿人工智能的样子，但很少人真正了解，更少人有兴趣将他们的理解应用到政府环境中，那里的工资很低，甚至不存在股票补偿。

因此，有一个关键的政策-技术差距需要弥合，无法解决这一差距实际上不是一个选项:这将意味着盲目地通过世界上有史以来面临的最重要的技术治理测试。不幸的是，政策制定者不得不在这一危险的知识缺口存在的情况下推进监管和立法，结果并不理想:广受批评的隐私和可解释性定义，以及创造可利用漏洞的人工智能定义是一些更令人担忧的结果。

吉莉安·哈德菲尔德是一位法学教授、战略管理教授，也是施瓦茨赖斯曼技术与社会研究所所长。Gillian 的背景是法律和经济学，这使她关注人工智能政策，以及最近和正在出现的人工智能和隐私法规的定义问题。但是——正如我在播客中发现的——她碰巧也是戴尔兰·哈德菲尔德-梅内尔的亲戚，她是一名人工智能比对研究员，我们在之前已经在节目中见过她。部分通过 Dyllan，Gillian 也一直在探索人工智能校准研究的原则如何应用于人工智能政策和合同法。在本期播客中，吉莉安和我一起谈论所有这些以及更多。

以下是我在对话中最喜欢的一些观点:

*   Gillian 认为，监管者认为的“解释”和技术人工智能社区成员构想的“解释”之间存在语言脱节。当被要求“请解释为什么这个人工智能拒绝了我的银行贷款”时，技术专家可能会提供一个简化的答案，这与人工智能算法中的活动有关，该算法产生了正在被询问的输出。这听起来可能有点像，“你被拒绝银行贷款，因为神经元#381 被解雇，而神经元#17 没有。”虽然有些更直观的“解释”是可能的，但它们通常都具有这种定量分析的性质。但这不是监管者所说的“解释”，也不是我们期望从法律机构和法官那里得到的那种解释。相反，监管者想要但往往不知道如何要求的解释听起来像是“你被拒绝银行贷款，因为你以前的行为模式表明，到时候你不能依靠你偿还债务。”吉莉安认为，这种答案不应该被视为一种解释，而是一种正当理由，她主张将重点转向“合理的人工智能”而不是“可解释的人工智能”，以反映监管者真正追求的是什么。
*   我们在播客中讨论了古德哈特定律:任何指标一旦成为优化的目标(并被“指标黑掉”)，就不再是有效的指标。Gillian 应用这一原则指出，你永远无法使任何合同、协议或政策如此完整，以至于涵盖所有可能的意外情况:不管怎样，古德哈特定律保证合同会有可被利用的漏洞。鉴于这种限制，Gillian 有兴趣寻找设计最优*不完全契约*的方法:不假装漏洞百出，但最大限度地减少其频率和影响的契约。
*   吉莉安指出，我们不应该指望能够以传统方式立法解决人工智能问题。鉴于人工智能发展的速度，法律在通过时往往已经过时。私营部门的行动要快得多，需要被用来协助政府监管人工智能，政府需要鼓励它这样做。这就是吉利恩所谓的“人工智能监管市场”背后的理念——一个由政府设定安全指标(例如，“无人驾驶汽车每行驶 Y 英里造成的碰撞少于 X 次”)并推动整个经济部门在这些目标上竞争的系统。吉利恩认为，随着私营公司建立旨在检查其他人工智能的偏见和其他不良特征的人工智能，我们已经看到了这种动态的种子。
*   Gillian 认识到在政府中招聘技术人工智能专家的挑战，但她也指出，大多数人工智能监管问题可以通过教育政策制定者掌握人工智能的基础知识来解决，而不是雇佣昂贵的开发人员在政府中工作(他们的技能可能得不到充分利用)。因此，政府教育需要成为人工智能全面监管工作的关键组成部分。

你可以[点击这里](https://twitter.com/ghadfield?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor)在 Twitter 上关注阿娇。

**链接**

*   [施瓦茨赖斯曼技术与社会研究所](https://srinstitute.utoronto.ca/)网站
*   阿娇的网站，上面有她的论文和项目(包括她在未完成合同上的工作)

![](img/b8542a1aae8acd0b8a8bf8da4ff9fa6d.png)

## 章节:

*   0:00 介绍
*   1:35 阿娇的背景
*   8:44 层和政府立法
*   13:45 解释和理由
*   17:30 可解释的人类
*   24:40 古德哈特定律
*   29:10 引入人工智能校准
*   GDPR 时间 38 点
*   42:00 涉及技术人员
*   49:20 总结