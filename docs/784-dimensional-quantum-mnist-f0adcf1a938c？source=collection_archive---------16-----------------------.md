# 784 维量子 MNIST

> 原文：<https://towardsdatascience.com/784-dimensional-quantum-mnist-f0adcf1a938c?source=collection_archive---------16----------------------->

![](img/e7620493a3de60425cfd89c7d99be1f0.png)

[https://commons.wikimedia.org/wiki/File:MnistExamples.png](https://commons.wikimedia.org/wiki/File:MnistExamples.png)

## 没有降维

我有史以来点击率最高的媒体文章是《T2》和《量子 MNIST》。如果你冒险进入机器学习，人工智能的一个子集，你几乎肯定会遇到 MNIST，这是一个流行的手写数字数据集，数字 0 到 9。数据集因其高质量而广受欢迎，这使您可以专注于训练和测试模型，而不必担心清理数据。当然，在现实世界中，您总是会遇到数据问题，但是一个干净的数据集肯定会使学习卷积神经网络(CNN)等应用程序变得更加容易。

对于量子 MNIST，我将 784 维的数据集减少到 16 个灰度维度，然后使用密集角度编码将这些维度映射到 8 个量子位。我用了所有的 10 个数字。相比之下，谷歌的 Tensorflow Quantum 将数据集缩减为 16 个黑白维度，只处理数字 3 和 6。在我的免费电子书《T4 地下城&量子比特:超越量子计算教程的冒险家的故事》中，详细描述了量子 MNIST 的发展过程

虽然我在分辨率和数字使用方面“击败”了谷歌，但我一直记得我们将数据集减少到了相同的维数。我不想在这个指标上与谷歌相提并论，但量子计算模拟器是有限的，我没有足够的量子位在量子处理器上运行它。然而，我已经决定使用[振幅编码](https://levelup.gitconnected.com/amplitude-encoding-dd89dc84170d)再次尝试这个实验，试图看看是否可以在完全不使用维度缩减的情况下完成。

不幸的是，784 维量子 MNIST 使用 Python，额外的量子位和纠缠，所以它运行得非常非常慢。但是，如果你想知道它是如何做到的，一步一步的算法如下。

## 算法

1.  从 Kaggle 下载 CSV 格式的[MNIST](https://www.kaggle.com/oddrationale/mnist-in-csv)。或者，从“[MNIST 数据库](http://yann.lecun.com/exdb/mnist/)”下载图像，并做硬的方式；你不会伤害我的感情。mnist_train 和 mnist_test CSV 文件分别包含 60，000 和 10，000 个 28x28 像素图像的值。因此，每幅图像都有从 0 到 255 的 784 个值，每个值代表一个特定灰度像素的强度。
2.  计算每个训练数字的每个维度的平均值。每个训练数字大约有 6000 个表示，因此对于每个维度，所有值的总和除以所有值的计数:*值的总和/值的计数*。我以前考虑过平均值的替代方法，如标准差和宁滨，但是我担心十位数会重叠，降低分类的准确性。
3.  对于每个数字的每个维度，计算除以该数字所有值之和的值的平方根:*sqrt(value/sum _ of _ values)*。振幅编码，顾名思义，对振幅进行编码，振幅的平方和必须为 1。
4.  填充零。对于 784 维，我们有两种选择:添加 240 个零，这样我们就有 1024 维来编码 10 个量子位，或者去掉 272 维，这样我们就有 512 维来编码 9 个量子位。老实说，你应该真的想删除维度，因为 784 个维度中的一些维度在所有数字中都有零的含义。但是，这个特殊练习的重点是避免仅仅为了说我使用了所有 784 个维度而减少维度，所以我填充了零。
5.  纠正错误。例如，对于火车零，1024 个振幅实际上总计为 0.999999998266969，而不是 1。因为所有训练数字的前几个值都是零，所以我将每个训练数字的第一维更新为该数字差异的平方根: *sqrt(error)* 。但是，总和超过 1 是个问题，因为调整必须是负的。负的幅度平方是正的，这实际上使误差更大。因此，解决方法是遍历这些值，直到找到一个大于或等于误差的值，然后将该值更新为原始值的平方减去误差的平方的平方根: *sqrt(value**2 - error**2)* 。
6.  使用[交换测试](https://levelup.gitconnected.com/comparing-quantum-states-c6445e1e46fd)，即距离度量、内核方法、内积，将测试数字与每个训练数字进行比较。对于 1024 个振幅，每个训练数位需要 10 个量子位，对于 1024 个振幅，每个测试数位需要 10 个量子位，并且我们需要 1 个 ancilla 量子位来执行比较，总共 21 个量子位。安西拉量子位以哈达玛门开始和结束。在 Hadamards 之间，ancilla 是 10 个 Fredkin 门的控制量子位，也称为受控交换，类似于训练数字和测试数字的量子位。我们只测量安西拉量子位。
7.  等等。
8.  再等一会儿。
9.  这需要相当长的时间。
10.  比较零测量值。当两个量子态相同时，它们以 100%的概率测量为 0。当两个状态最大程度相反时，它们以 50%的概率测量为 0。它们越接近，测量 0 的频率就越高。例如，两个非常相似的状态可能以 90–95%的概率测量为 0，而两个非常不相似的状态可能以 55–60%的概率测量为 0。因此，具有最多 0 测量值的训练数位是测试数位最接近的数位。那个火车数字是最有可能的[分类](https://medium.com/swlh/quantum-classification-cecbc7831be)。

## 结果如何？

上一次我做量子 MNIST 时，我运行了一次，因为经典的预处理是如此乏味，我挑战自己不要使用 Python。我最初的量子 MNIST 实验使用 MS Excel 进行经典的前处理和后处理，电路是使用 IBM Quantum OpenQASM 编辑器构建的。幸运的是，测试零点的测量值最接近于训练零点，所以实验成功了。我有足够的资料来发表这篇文章，但有一个警告。

这次我把它当作 IBM Quantum Jupyter 笔记本来运行。我还是在 MS Excel 里做了一些经典的预处理，但绝对没有上次那么繁琐。这是好消息。它极其缓慢，令人痛苦，这是个坏消息。但是，我被迫使用古典模拟器，古典 MNIST 很慢。我猜这在量子处理器上只需要几分钟，然而在 NISQ 设备上 10 个 Fredkin 门只会产生噪音。

在我写这篇文章的时候，我只能完成每个火车数字 10 个镜头的运行。我让它在我打字的时候每列数字运行 100 次，但是我想我会在它完成之前自然死亡。到目前为止，在 10 次运行和可见的 100 次运行结果之间，我基本上是在看随机数。相比之下，我最初的量子 MNIST 在合理的时间框架内对每个训练数字进行了 8192 次拍摄，结果的分布是有意义的。但是，量子 MNIST 将八个量子比特与八个量子比特的个体旋转进行了比较，而不是将十个纠缠量子比特与十个纠缠量子比特进行比较。因此，虽然量子分类与交换测试是绝对有效的，量子分类是否与振幅编码一起工作的问题是不确定的。

## 量子计算优势？

我考虑过运行一次纠错，然后对调整进行硬编码以加快执行速度。然而，当我在整个代码中添加打印语句时，这些计算几乎是瞬间完成的。一旦作业开始执行，速度就会变慢。因此，这可能是对量子计算优势的一个很好的测试。

尽管在 NISQ 设备上的结果会是纯粹的噪音，如前所述，在 21 个量子位上运行它真的需要多长时间？我认为在队列中等待真正的硬件仍然会比这执行得更快，特别是因为 10 个电路可以作为一批运行并且只排队一次。此外，我们需要考虑到模拟器上的 1024 个镜头，更不用说更高的镜头数了，可能会因为任何可能中断内核的事情而永远无法完成。

再说一次，古典 MNIST 很慢。如果 NISQ MNIST 只需要几分钟，那么即使未来通过容错来减慢它的速度，仍然预示着计算优势。

## 你能做得更好吗？

我用 Jupyter 笔记本创建了一个 [GitHub 知识库](https://cb.run/NO6X)，我曾在 IBM 量子实验室中用它运行 784 维量子 MNIST。不幸的是，我用来做一些经典预处理的 MS Excel 文件大大超过了 GitHub 的 25 MB 限制，即使有压缩，所以我上传了两个压缩的 [162 MB。zip 文件](https://cb.run/6AxU)和 [189 MB 未压缩。xlsx 文件](https://cb.run/t3rp)到 Google Drive，希望能缓解你的互联网安全偏好。

## 我的下一步是什么？

我在考虑找一个更小的真实世界数据集来测试这个。我直接去了 MNIST，因为我可以直接比较。但要确认量子分类是否与振幅编码一起工作，我认为 8 或 16 维的数据集会更好，分别需要 3 或 4 个量子位。虽然我可以在真实的硬件上运行一个 2 量子位的 4 维数据集，但这太小了，不会给任何人留下深刻印象，结果仍然是噪音。不幸的是，在 NISQ 时代，模拟是唯一可行的选择，所以我认为 3 或 4 个量子位将是一个很好的测试。

我也有一个相关的想法，我一直抱着希望得到一个微补助金，但这看起来不会发生，所以我只是在这里发表它。我可能应该吸取教训，不要从 784 维开始，但如果那样的话会更令人印象深刻，所以我会采取“不成功便成仁”的方法。