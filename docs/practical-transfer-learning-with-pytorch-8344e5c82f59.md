# PyTorch 实用迁移学习

> 原文：<https://towardsdatascience.com/practical-transfer-learning-with-pytorch-8344e5c82f59?source=collection_archive---------19----------------------->

## 当解决一个 ML 问题时，利用一个已经起作用的深度神经网络是一个巨大的加速

![](img/a18a334f091bc42fd2768d537bb76d4f.png)

奥马尔·弗洛雷斯在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

在之前的一篇文章中，我解释了 PyTorch 和 XGBoost 如何结合起来执行迁移学习。

</transfer-learning-with-xgboost-and-pytorch-hack-alexnet-for-mnist-dataset-51c823ed11cd>  

这是一种非常非常规的转移学习的方式，混合了深度神经网络和梯度引导树。为了说明这种方法，我解释了如何将 AlexNet 从 ILSVRC 数据集中获取的图像分类知识转移到 XGBoost 的另一个用例:识别手写数字。

在写完这篇文章的几天后，我意识到 PyTorch 并没有真正在网上涵盖更常见的用例，即只涉及神经网络的迁移学习。然而， [Dipanjan (DJ) Sarkar](https://medium.com/u/6278d12b0682?source=post_page-----8344e5c82f59--------------------------------) 的一篇优秀文章详细介绍了深度学习，有一些代码但使用了 Keras。

</a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a>  

我强烈推荐阅读这篇文章。

在这篇文章中，我们将填补迁移学习和 pytorch 之间的空白。

我们将做与前一篇文章相同的转换，仅使用神经网络方法，并比较混合 XGBoost 或仅使用神经网络时的性能。

# 动机

在深入研究代码之前，有必要提醒一下迁移学习为什么有趣。主要原因是时间:需要大量的时间和精力来收集和标记足够大的深度学习数据库，并且大量的时间和精力对于配置、拟合和调整深度神经网络也是必要的。

当解决一个 ML 问题时，利用一个已经起作用的深度神经网络是一个巨大的加速。

在为计算机视觉设计的深度神经网络的情况下，大多数复杂性包含在构建特征的层中。负责分类的层通常只有 3 层深。

能够利用这些预先训练好的特性计算层是非常有吸引力的。

下一节将展示如何使用传统的深度学习方法来实现这一点。

# MNIST 用例

为了简单起见，我们希望使用 Python 中容易获得的数据库。MNIST 看起来是个不错的候选人。它是开源的，使用 TorchVision 可以在几秒钟内加载。训练集和测试集都非常大:60k 的图像用于训练集，10k 的图像用于测试集。此外，它们与用于训练 AlexNet 的图像没有相同的维度。看看我们如何处理这件事是很有趣的。

AlexNet 最初被训练成用 1 000 个标签对 ILSVRC 的图像进行分类。在这次训练中，它学会了用深度卷积神经网络建立视觉特征。我们在这一部分中所做的假设是，这些特征可以被重新使用来执行完全不同的分类，即识别仅具有 10 个标签的手写数字。

# 重新定位 Alex Net

在这一点上，我们需要一种方法来保持特征层的结构和权重，并重新训练分类层。

这是通过下面的代码实现的:

作者代码。

它创建一个新的神经网络模型，获得一个原始模型作为输入，并生成一个新的模型，其中分类器网络已被一个新的分类器取代。要素图层保持不变。

重要的部分在于冻结要素图层权重的线。这将强制计算要素的图层在训练过程中保持不变。

这些是负责迁移学习的行，因为在初始训练期间在 ILSVRC 数据集上获得的所有知识将在新的用例中不加修改地重用。

# 学习识别手写数字

我们现在要做的就是建立一个新的模型，基于原始的，预训练的 AlexNet，并改装一个新的分类器来识别手写数字。

感谢 pytorchvision 和 pytorch，这是一个非常简单的任务。下面的代码解释了如何:

转移学习。作者代码

这种方法很简单，除了变换部分，它需要调整 MNIST 图像的大小，以适应用于训练 AlexNet 的数据集的大小。这是通过转换方法完成的。

标签的数量从 1k 减少到 10 个。

在我的笔记本电脑上花了相当长时间的培训结束时，模型被序列化并存储。我们将使用此转储来评估此传输的性能，并检查此方法是否相关。

# 估价

scikit learns 提供了两种评估分类模型性能的简便方法: ***混淆 _ 矩阵*** 和 ***分类 _ 报告*** 。

第一个基于实际值计算每个类使用的标签数。第二个计算标准特征，如 f1 分数、召回率、精确度等

我们将把这两种方法应用到 torchvision 提供的测试数据集上。这个数据集包含 10k 个手写数字，这对于验证来说是一个合适的大小。

下面的代码行类似于培训中使用的代码行。*变换*被重新用于调整测试图像的大小。

评估模型性能。作者代码。

正如您在上面的注释行中看到的程序输出，性能非常好。

有趣的是，我发现这个性能比我在[上一篇文章](/transfer-learning-with-xgboost-and-pytorch-hack-alexnet-for-mnist-dataset-51c823ed11cd)中使用 XGBoost 获得的性能稍好。这是以更长时间的训练为代价的。然而，使用适当的超参数调优可以进一步提高 XGBoost 性能:在上一篇文章中，使用了分类的默认值。

# 结论

使用预训练模型转移学习是获得准确模型的非常有效和快速的方式，对于分类来说也是如此，而对于回归来说则不是。

使用 pytorch 和 pytochvision，这可以在非常有限的几行中完成。

在这篇文章中，我们一直在使用在图像上获得的知识来应用到其他图像上。我敢肯定，我们也可以在任何其他类型的信号上获得不错的结果，比如 1D 信号。