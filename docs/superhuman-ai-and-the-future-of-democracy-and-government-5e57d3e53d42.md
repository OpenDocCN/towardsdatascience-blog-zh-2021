# 超人人工智能与民主和政府的未来

> 原文：<https://towardsdatascience.com/superhuman-ai-and-the-future-of-democracy-and-government-5e57d3e53d42?source=collection_archive---------22----------------------->

## [播客](https://towardsdatascience.com/tagged/tds-podcast)

## 本·加芬克尔探索了我们能够和不能够预测人类未来的事情

要选择章节，请访问 Youtube 视频[这里](https://youtu.be/QHEEQqh7wd4)。

*编者按:这一集是我们关于数据科学和机器学习新兴问题的播客系列的一部分，由 Jeremie Harris 主持。除了主持播客，Jeremie 还帮助运营一家名为*[*sharpes minds*](http://sharpestminds.com)*的数据科学导师初创公司。可以听下面的播客:*

[苹果](https://podcasts.apple.com/ca/podcast/towards-data-science/id1470952338?mt=2) | [谷歌](https://www.google.com/podcasts?feed=aHR0cHM6Ly9hbmNob3IuZm0vcy8zNmI0ODQ0L3BvZGNhc3QvcnNz) | [SPOTIFY](https://open.spotify.com/show/63diy2DtpHzQfeNVxAPZgU) | [其他](https://anchor.fm/towardsdatascience)

随着我们继续开发越来越复杂的人工智能系统，越来越多的经济学家、技术专家和未来学家一直在试图预测所有这些进展的可能终点。人类会无关紧要吗？我们会把所有的决定——从我们空闲时间想做什么，到我们如何治理社会——都交给机器吗？高能力和高度通用的人工智能系统的出现对民主和治理的未来意味着什么？

这些问题是不可能完全直接回答的，但把眼光放长远一点人类技术发展史，或许可以得到一些提示。这是我的客人本·加芬克尔在他关于人工智能未来的研究中采用的策略。本是一名物理学家和数学家，目前在牛津人类未来研究所从事新兴技术风险预测的研究。

除了研究预测人工智能等技术的未来影响，本还花时间探索人工智能风险的一些经典论点，其中许多他不同意。因为我们播客上有很多认真对待这些风险的嘉宾，我认为也有必要和本谈谈他的观点，我很高兴我这样做了。

以下是我们谈话中我最喜欢的一些带回家的东西:

*   不出所料，预测未来很难。但是，当谈到人工智能及其对经济可能产生的影响时，让它变得特别困难的一件事是，人工智能似乎可能挑战我们标准经济模型中的许多假设。例如，市场是由赚了钱并打算把钱花在产品上的人组成的这一观点，可能无法推广到大多数买卖决策都由机器做出的世界。同样，我们目前假设劳动力(人们为建造物品和提供服务而投入的工作)和资本(他们建造或用于建造其他物品的工具、设备和物品)之间有非常明显的区别。目前还不清楚哪种经济直觉会推广到这样一个世界:人工智能系统被视为资本，但也在做我们的大部分工作。
*   经济学家、历史学家和未来学家之间的一个活跃辩论是，全球人类经济的增长和发展是平稳渐进的，还是一步一个脚印的？例如，一些人指出工业革命、新石器时代革命和其他类似事件是经济发展离散而突然增长的时刻，而另一些人则认为这些只是环境持续发展水平最终变得引人注目的时刻。有趣的是，人们对人类经济史相对平滑或尖锐的看法，在他们想象向人工智能经济过渡的方式中起着重要作用。如果你通常认为经济增长一直是持续和渐进的，那么你就不太可能认为人工智能会在短时间内给我们的日常生活带来不连续的变革性飞跃。
*   本对人工智能风险的某些“经典”论点持怀疑态度。虽然没有完全否定它们，但他指出，其中许多是不必要的抽象。他还提出，越来越多像 OpenAI 的 GPT-3 这样的系统的出现给了我们机会，让我们看到具体的和有点通用的人工智能系统在实践中的行为，他认为，结果表明，对来自[递归自我改进系统](https://futureoflife.org/2019/03/19/the-unavoidable-problem-of-self-improvement-in-ai-an-interview-with-ramana-kumar-part-1/)的人工智能风险的担忧可能没有特别坚实的基础。在这里很难用要点的形式来解释这些论点，所以如果你对这方面感兴趣，我真的推荐你听这一集！

你可以[在推特上关注本](https://twitter.com/bmgarfinkel)(尽管他还没有发推特:P)或者[在推特上关注我](https://twitter.com/jeremiecharris)。

## 播客中引用的链接:

*   本在人类未来研究所网站上的页面。

![](img/79f0d98b5f173414fbb4d5f03292a2af.png)

## 章节:

*   0:00 介绍
*   1:21 本的背景
*   3:14 人工智能的风险
*   钱的价值
*   13:38 大赦国际作为一种参与现象
*   16:01 人工智能与 GDP
*   生命的进化
*   30:36 人工智能风险论证
*   45:23 构建这些系统
*   51:29 人类自我完善的反馈
*   观念的转变
*   1:07:38 总结

## 请查看以下文字记录:

杰瑞米(00:00:00):
嘿，大家好，我是杰瑞米。欢迎回到迈向数据科学播客。我对今天的这一集感到非常兴奋，因为我们将讨论许多与人工智能有关的长期的、改革的和半未来的话题。人工智能技术将塑造未来的治理方式。人类会变得与经济无关吗？我们有多少日常决策将被转移到机器上？也许最重要的是，高能力和高度通用的人工智能系统的出现对民主和治理本身的未来意味着什么？这些问题不可能有任何确定的答案，但是从人类技术发展的历史中寻找一些线索是可能的。

Jeremie (00:00:41):
这正是我的嘉宾 Ben Garfinkel 在研究人工智能的未来时所采用的策略。现在，本是一名多学科的研究人员，致力于预测先进技术带来的风险，包括牛津大学人类未来研究所的人工智能。本也花了很多时间探索人工智能风险的一些经典论点，其中许多你会在播客中遇到。我们邀请了很多嘉宾来详细讨论和探讨这些问题，其中很多他都不同意。我们将探究他的不同意见，为什么他会有这些不同意见，以及他认为人工智能风险的论点在哪里有点站不住脚。我真的很喜欢这次谈话。我希望你也是。本，非常感谢你参加我的播客。

本(00:01:19):
是的。非常感谢邀请我。

Jeremie (00:01:21):
你能来我真的很开心。你关注的是一大堆长期问题，其中很多都是围绕人工智能的。不过，在我们深入讨论这个话题之前，我想更好地了解一下是什么让你来到这个领域。那么你的背景是什么，你是如何发现人工智能中的长期主义的？

本(00:01:38):
是的，所以我想实际上是相当迂回的。所以在大学里，我学习物理和哲学，对物理哲学非常感兴趣，甚至考虑去读研究生，幸运的是我没有去。是的，我想通过哲学，我开始了解更多关于伦理的知识，并接触到一些关于人口伦理的观点。这种观点认为，围绕着我们应该如何在决策中重视后代，以及我们对后代的义务，存在着不同的问题。或者做对其他人至少有些用处的事情的义务有多强。后来，我对长期主义越来越感兴趣，也试图找出一些似乎有用的东西。我开始想，也许哲学和物理学并不是这样。

Ben (00:02:28):
事实上，我非常幸运，不仅仅是在这个时候，当我试图更多地研究长期或未来的主题时，我碰巧遇到了当时在耶鲁大学的教授 Allan Dafoe。他只是自己转向人工智能治理问题。我想当我还在那里读大四的时候，他就已经开始招聘研究助理了。我对这个话题很感兴趣，我读过一些关于人工智能风险的文章。例如，我开始阅读《超级智能》这本书，我并没有真正涉足这一领域，但似乎那里可能有一些重要的问题。一个机会出现了，我开始和艾伦一起工作。几年后的现在，我实际上仍在和 Allan 一起工作，我刚刚相当确信，从长远的角度来看，研究新兴技术的风险至少是一件相当好的事情。

Jeremie (00:03:14):
这实际上是一个很好的继续，我认为这是我真正想谈论的主要话题之一。这就是你花了很多时间思考人工智能的存在风险及其论据的想法。我知道你并不完全相信其中的很多。也许我们可以从这里开始，当涉及到人工智能时，人们特别是 Allan 和你所担心的存在风险的本质是什么？然后，我们也许也可以对这些论点进行反驳，但首先，风险是什么？

Ben (00:03:44):
是的，所以我认为，在考虑人工智能的长期影响的人群中，至少没有一种风险真正占主导地位。所以我会说有几个主要的，非常广泛的，有点模糊的类别。所以一类风险很快就会出现，那就是不稳定带来的风险。因此，很多人，特别是在国际安全领域的人，担心致命的自主武器系统，可能会增加国家间冲突的风险。也许是偶然的，闪光冲突或潜在的某些 AI 应用，比如说移动第二次打击能力和增加核战争的风险。或者他们担心大国竞争。他们担心的主要问题是，也许人工智能的某些东西会破坏国内或国际政治的稳定，然后可能会有战争，这将带来持久的破坏或其他一些负面的长期冲突。

Ben (00:04:43):
还有另一类关注点，比如一些特定的冲突、崩溃或战争。并且更专注于这样一种观点，即在人工智能重塑社会的过程中可能存在某种程度的偶然性。因此，你可能会认为，人们做出的关于政府和人工智能的某些决定将会产生持久的影响，进而影响后代。事实上，例如，民主有多普遍，权力分配如何，或者人们关心的其他各种事情，例如，坏的价值观在某种意义上根深蒂固。

耶雷米(00:05:23):
因为在那方面，我想那显然是一个非常复杂的地区。但是，人们想象人工智能在多大程度上改变了我们所说的民主在未来是一种有吸引力的治理模式，有哪些方式呢？

Ben (00:05:36):
就民主而言，显然存在一些投机因素，但担心民主的一个理由是民主并不真正正常。如果你纵观历史，追溯到最初的文明，这并不罕见，比如说每周都有民主元素。所以这不是完全的专制，有某种形式的机构，比如罗马元老院之类的，但在罗马，这是一个众所周知的机构。但这与我们现在的情况相去甚远，我们现在的情况就像是在许多国家几乎实行普选制，这些国家的政府反应非常迅速，而且不断地向更多的国家转移。从历史的角度来看，这是极其罕见的。即使事情不是完全的独裁或之前的事情，这是过去 100 年非常不同的事情。关于为什么这种现代形式的民主变得越来越普遍，有不同的理论。关于这一点有很多争论，因为很难进行随机对照试验。但是很多人确实指出，至少工业革命前后发生的某些经济变化是相关的。

Ben (00:06:43):
因此，人们有时会提出的一类变化是机器人，这在工业革命之前是一个非常严重的问题。有人担心，如果你给很多普通人政府的权力，或者利用[听不清 00:06:56]重新分配土地，这是更广泛的富人财富的主要形式，应该会非常具有破坏性。随着国家的工业化，土地作为一种财富变得不那么重要，也许这些土地改革问题不再是阻碍因素。你不再有土地贵族，不再有对政策的恐惧。

本(00:07:18):
还有其他一些问题，就是随着生产力的提高，劳动力的价值也提高了。这在某种模糊的意义上给了人们更多的讨价还价的权力，因为你有典型的工人，他们做什么，更多的价值。他们可能会通过威胁基本上只是拿走他们的劳动力来制造更大的威胁。或者一些组织也被认为是相关的，比如人们聚集在城市里，更容易组织起来，实际上也有成功的革命。有很多不同的因素，人们基本上认为是经济变革，这可能有助于民主的发展，或者至少有助于部分解释为什么它在今天更加普遍。

Ben (00:07:52):
所以你可能会非常广泛地关注民主的普及是否在某种程度上取决于某些物质或经济因素。这种情况只持续了 100 年。也许这是不正常的，也许如果你只是改变许多经济和技术变量，这是不成立的。这里还有一些更具体的论点。所以一个非常具体的论点是，如果人类劳动力的价值变得非常低，甚至在大多数情况下变为零，因为你可以用资本代替劳动力。因为人工智能系统可以做人们可以做的任何事情，也许当我们减少工人的权力时，如果你可以自动化执法或镇压起义，因为军事技术也可以自动化。

本(00:08:33):
这可能会让威权政府更加稳定。这意味着他们甚至不会因为害怕起义而做出让步。也许如果劳动力的价值变为零，那么在这一点上可能会变得非常严重，主要取决于谁拥有资本或谁拥有机器。也许它创造了一个系统，一个与土地改革的小问题非常相似的情况。财富并不是真正基于这些模糊的东西来划分人们的劳动，并没有真正发挥作用，很大程度上，你拥有的东西，你基本上是在收取租金。如果你回到那个系统，那可能对民主的稳定也没有好处。

本(00:09:09):
所以有一个外部视角，这是很罕见的事情。也许我们不应该指望它会持续下去，我们改变了很多。此外，还有一些内部观点的争论，可能会使专制政府更加稳定，并使人们更加担心将权力交给[听不清 00:09:24]。

Jeremie (00:09:24):
非常有趣的是，所有这些问题都是如此错综复杂，要清晰地描绘出所有这些变革发生后的未来是多么困难。当我们开始谈论民主将会发生什么，经济将会发生什么时，我脑海中不断浮现的一件事是。劳动力谈判的力量等等，是一个潜在的假设，即我们有任何一种市场结构，在某种程度上，所有的劳动都是由机器完成的。

Jeremie (00:09:57):
我想我可能会问的一个问题是，在这种情况下，金钱的价值是什么？价格发现的价值是什么？在这种情况下，价格发现是如何发生的？如果…这并不是说我们一定处于后稀缺状态，你会期望稀缺的梯度。但无论如何，我甚至不确定我在这里想表达什么思想，但看起来你有东西要扔进去。

本(00:10:23):
所以我认为这是一个非常严肃的问题。我认为我们不应该期望自己真的能够在任何细节层面上想象一个拥有非常先进的人工智能的未来，并且真的是正确的。因此，我有时使用的一个类比是，我认为在这个世界的某些方面，人工智能系统至少可以做人类可以做的所有事情。我们可以在某种程度上抽象地推理。我们确实有这些经济模型，我们有劳动力，你有资本，你可以问如果用资本代替劳动力会发生什么。甚至项目是非常抽象的观点。也许有一些理由希望这些理论足够抽象，即使我们不知道细节。仍然有一些理由认为，有足够的一般抽象，我们仍然可以用它们来推理未来。但是肯定有一个担忧，就像任何关于政府如何运作的细节。我们可能会认为政府的功能是完全错误的。

Ben (00:11:19):
我有时使用的一个类比是，让我们假设你在 1500 年，有人用非常抽象的术语向你描述互联网，就好像通信将会快得多。检索信息和学习东西会快得多。它给了你一些抽象的属性。有些东西你或许可以推理一下。

本(00:11:40):
所以你可能会想，“哦，你可能会有更少的自主权，因为人们可以更快地与他们沟通，而不是他们在海外和失去联系。或者企业可能会更大，因为这些协调成本可能会下降。”有些事情你可能会说这是真的，或者你可以说，“哦，也许人们远程工作，”你可能甚至不知道很多细节。但是如果你试着去弄清楚到底发生了什么，你可能会认为这是完全错误的。因为你根本不了解电脑到底是什么样子，也不知道人们是如何与电脑互动的。

Ben (00:12:15):
你不会得到像 Reddit 和 GameStop stock 这样的细节。所有这些问题，你不可能在任何细节层次上预见到。还有很多你可能想象不到的问题，因为你使用了不太合适的抽象概念。所以这是一种有点啰嗦的说法，我确实认为我们有一些理论和推理方法，足够抽象，我希望它们至少能支持一点。但是我认为有很多事情是我们无法预见的。很多我们不能谈论的问题。我们今天说的很多东西，从未来的角度来看，可能会变得愚蠢。

耶雷米(00:12:51):
是的，我想是的，“这一次会有所不同，”在任何时候说都是一件危险的事情。但当谈到人工智能革命的下一个阶段时，如果你想这么说的话。我知道这也是你经常使用的语言，在这种情况下似乎很合适。我确实想知道的一件事是一种几乎类似于抽象的泄漏，我们依赖抽象来定义像市场这样的东西。当我们谈论预测未来时，这是我们推理的一个非常基本的要素。市场隐含地围绕着人，因为最终价格只是个人愿意为一件东西支付的价格。我们拓宽了市场参与者的定义。

Jeremie (00:13:38):
在这里，我们进入了这样的问题，我们如何考虑一个人工智能代理？在哪一点上是社会的参与成员？在什么程度上，价格发现真的围绕着非人类系统的需求和欲望之类的东西？我想这就是我开始怀疑的地方，这是一个默认的非建设性的观点。所以对我来说，说“市场是一个糟糕的抽象概念”是没有帮助的，但是你认为这是一个严重的问题吗？

本(00:14:06):
是的，是的，我确实认为这是一个问题，我认为你指出了一个很好的、具体的问题，我们有一个非常明确的区别……目前，人与机器和软件非常不同。这很像[相声 00:14:19]经济演员与经济相关的东西[听不清 00:14:23]。公司在某种程度上是模糊的，出于某种目的[听不清 00:14:29]在某些方面类似于人。但是区别非常非常明显。即使只是在资本和劳动力之间，目前也没有任何含糊之处。

Ben (00:14:41):
但是，如果你认为未来会有非常强大、温和的人工智能系统。我们认为，也许人们与人工智能系统有着有趣的关系，他们在那里创建评估，这意味着追求他们的价值。我认为我们做出的许多区别实际上可能会变得比现在更加模糊。它们在未来变得模棱两可的方式可能会使我们依赖于清晰区分的任何理由，可能会以目前难以预见的方式失败。

耶雷米(00:15:12):
是的。预测这是一个有趣的风险，因为它确实是不可预测的，而且从根本上来说具有挑战性。这似乎也是其中的一个问题，你在你的一些关于技术历史的作品中探索了这个问题，那就是你将会看哪一个指标来讲述这个技术的进化故事。你能就此谈一点吗，你的历史观点，你觉得哪些指标有趣，为什么它们在未来可能相关或不相关？

本(00:15:36):
是的。所以我认为人们经常使用的一个指标是全球生产总值。GDP 作为一个指标很有意思，因为它要衡量的基本上是某种程度上的生产能力，比如你能生产多少东西或者你能生产多少人们看重的东西。和

耶雷米(00:16:01):
我有一个愚蠢的问题。那么什么是 GDP 呢？GDP 的实际定义是什么？

Ben (00:16:08):
因此，至少名义 GDP 是指在一个经济体中销售的所有最终产品的总价格。所以最终产品基本上是某种类似于最终结果的东西。如果你卖给某人螺丝钉，然后他们把螺丝钉卖给某人，某人用螺丝钉做吊扇之类的东西。螺丝不应该被计算在内，因为你在重复计算。如果有人买了一个吊扇，当他们买吊扇的时候也买了螺丝，他们也买了螺丝。所以它基本上意味着把一个经济体中除了中间产品之外的所有东西的销售价格加起来。

本(00:16:48):
但人们也经常想谈论实际 GDP，这与名义 GDP 不同。所以名义 GDP 就是，你把基本上所有的价格加起来。名义 GDP 的一个问题是，如果你有通货膨胀，那么你可能会因为与实际基础股票无关的原因而增加名义 GDP。所以政府决定印更多的钱，突然所有东西的价格都上涨了 1000 倍，但是你仍然有同样的东西。从名义上看，GDP 的增长并不真的非常快，但这并不是说你实际上生产了更多的东西。

耶雷米(00:17:25):
是啊。委内瑞拉做得很好。

本(00:17:27):
是的，没错。所以实际的 GDP，应该是为此而调整的。至少粗略地说，它的工作方式是，你试图定义一切相对于过去某个时间点的价格。假设你有一个经济体，唯一出售的产品是黄油，由于通货膨胀，黄油的价格上涨了 1000 倍。但是你在经济中只卖出了双倍的黄油。真实的 GDP 只会说，“哦，因为你卖的黄油量增加了两倍。你们的经济规模只增长了两倍。”经济规模的定义是，用过去的黄油价格，乘以现在存在的数量，这就是真实的 GDP。这变得非常复杂，因为随着时间的推移，人们不断推出新产品。那么，鉴于人们在 2020 年购买的大部分东西在 1700 年并不存在，你如何将 2020 年的经济与 18 世纪的经济进行比较呢？你实际上是如何进行比较的呢？人们使用各种不可靠的方法，但他们并不真正理解。

Ben (00:18:36):
但在问这个问题时，你也提到了 GDP 的一个主要问题。它意味着跟踪社会的生产能力，比如我们基本上制造了多少东西。如果你使用短期内的实际 GDP，这似乎不成问题，因为你通常不会推出那么多新产品。但随着时间的推移，这些比较实际上是如何进行的变得越来越模糊。所以非常直接的比较还是很好的。所以你仍然可以说公元前 10000 年的人均 GDP 和今天的相比。即使我不知道如何准确定义 100 个其他社会的人均 GDP，我仍然很有信心它会更低。

本(00:19:21):
从某种意义上来说，它就像一个钝器，我认为它的有用性取决于你希望你的讨论或预测有多精确。假设有人做了一个非常大胆的预测，由于自动化，人均 GDP 增长率将增加 10 倍。如果有人做出这样大胆的预测，那么在某些疯狂的未来经济中，实际 GDP 意味着什么就有点模糊了。但是，即使你看起来有点模糊，GDP 和增长率之间的差异并没有改变，增长率增加了 10 倍，这仍然足够直接了。这是一种表达主张的有用方式。

Ben (00:19:57):
这是一种啰嗦的说法，我认为 GDP 或人均 GDP 通常很好地代表了生产能力增长的速度。它对工业革命很有用，在人均 GDP 中表现得很明显。或者当一个国家似乎真的停滞不前时，比如不发达国家没有发展，人均 GDP 通常是相当平稳的。然后，当中国，例如，开始在一个真正明显的质量意义上起飞，人均国内生产总值跟踪得很好。因此，这是有用的，但它也有各种问题。除此之外，还有一些问题，人们经常想用它来代表人们的生活有多好，比如人均 GDP。

Ben (00:20:38):
但是有很多事情通常不会被考虑进去，比如医疗质量，不会直接被考虑进去，空气污染也不会被考虑进去。如果每个人都只是非常沮丧或麻醉，正在开发的麻醉的价值就真的不会显现出来。威廉·诺德豪斯的一篇经典论文表明，100 多年前，灯的质量提高，灯泡比蜡烛好得多的事实，并没有真正显现出来。因此，这是一种冗长的方式来说同样的财政问题，至少作为一个粗略的衡量标准，相当不错。但实际上并不一定与你可能对幸福和其他感兴趣的事情有所帮助。

耶雷米(00:21:15):
有趣的是，当你在最后一块上加标签时，它与幸福没有很好的关联。我想不出更好的封装一种对齐问题。基本上，问题是要拿出一个指标，说明这就是我们想要的。人类真的很坏，或者说不是我们坏。指定有意义的指标可能真的是一个困难的问题。你看股票市场，我们决定关注这个指标。有一段时间，股票市场是一个很好的衡量标准，一般来说，经济怎么样，普通人怎么样？但接下来会出现脱钩，我们最终会看到股市与普通人的生活大相径庭。无论如何，对不起。我不是有意打断你，但你刚才提到了-

本(00:22:00):
是啊。所以我应该说，作为一个小小的警告，我认为目前，GDP 实际上是一个很好的指标。如果你经常定义你关心的事情，比如预期寿命或者生活满意度。事实上，目前，这两者之间有很强的相关性。我认为你就像，什么都不知道，你落后于[听不清 00:22:17]或什么，你需要选择一个国家生活。你唯一得到的是人均 GDP。这通常会是对你有用的信息。我想我的想法更符合对齐问题，如果它在未来变得更加解耦，我不会感到惊讶。

Ben (00:22:30):
特别是，假设我们最终用资本和机器完全取代了劳动力，人们不再为工资而工作。经济增长主要是机器制造其他机器，工人并没有真正参与其中。如果经济增长 10 倍，我不会感到震惊，但一个人的生活不会增长 10 倍。

耶雷米(00:22:47):
是啊。这也很有趣，并提出了什么的问题，这又回到了价格发现，这是 GDP 的一个重要方面。有很多领域的事情变得复杂。但有趣的是，看看你在这个技术的历史探索中所做的一些工作。这些指标中有很多确实是相互关联的。在某种程度上，你测量什么并不重要，在过去的 2000 年或 20000 年里发生了一些戏剧性的事情。但是，你要衡量一下，要么是文化革命，要么是新石器革命，要么是工业革命。就好像人类这个超级有机体，地球上的所有人类都是一个优化算法，只是捆绑在某种最优或局部最优或其他什么上。我们现在正在非常陡峭地爬坡。

耶雷米(00:23:44):
你认为人工智能是它的连续体极限吗？这是自然的下一步吗？或者我们应该把它看作是一个量子飞跃，就像一个阶跃函数，事情只是质的不同？

本(00:23:56):
是的。我认为这是一个非常好的问题。我确实认为，这是一场关于如何确切解释经济增长或社会能力增长的历史的争论。或者不管你想用什么模糊的术语来描述人们在这个世界上制造东西或改变东西或完成事情的能力。实际上存在一场争论，例如，在对工业革命的不同解释之间。因此，对大约发生在 1750 年至 1850 年间的工业革命的一种解释是，在工业革命之前，英国和一些周边国家的经济增长非常停滞。然后发生了一些变化，一些有趣的转折，可能发生在工业革命的另一端，也可能是另一个世纪。因为某种原因，技术进步的速度加快了。

本(00:24:55):
人们从农业经济转向工业经济。人们开始使用非有机能源。所以不再是木材和动物肥料。现在是化石燃料和通过电力传输的能源，诸如此类。T4 研发现在在经济增长中发挥作用，而以前它并没有真正发挥作用。在过去的 100 年里，发生了一些有趣的相变。我们刚刚从一个经济体过渡到一个几乎完全不同的经济体，这个经济体的增长和变化可能会更快。

Ben (00:25:29):
现在有另一种解释，基本上是说至少在人类文明史上有一种长期趋势，增长率越来越快。这种解释认为，随着经济整体规模的增长，增长率本身，也就是增长，会不断上升。这是一个有趣的反馈循环，经济规模越来越大，增长率越来越大，这在工业革命中非常明显。只是因为这里的速度终于变得足够快，让人们注意到这一点，但实际上有一个相当一致的趋势。这并不是真正的相变。

本(00:26:12):
例如，大卫·罗德曼最近做了一些工作，他是一名经济学家，为开放慈善项目工作。他最近写了一篇报告，我想是《人类轨迹建模》,讨论或探索了这种连续视角。经济史上也有争论。所以有一个经济学家，迈克尔·克莱默，为这种平稳加速的观点辩护，很多经济史学家也这么认为。实际上，当你从一个经济体转换到另一个经济体时，会有一些奇怪的事情发生。

Ben (00:26:42):
我只想说有不同的解释。所以人们只是偶尔会说，这有点奇怪，有点特殊。发生了一些事情，一些不连续的变化。我们转向了增长更快的新经济。另一种解释说，不，实际上这是一个相当一致的森林。只是事情变得越来越快，这不是相变，也不是不连续，只是有一个平稳的，真正的长期趋势，只是世界继续加速越来越多

Jeremie (00:27:11):
有趣的是，这几乎像两个不同的子问题一样纠缠在一起。其中一个问题是，人类是否几乎不间断地学习？换句话说，是不是穴居人一代又一代地逐渐掌握了越来越多的技能，这只有在一万年后才变得明显。或者是这样的情况，不，他们基本上是停滞的，一切都是真正平坦的，然后你得到一些起飞。这似乎可以被视为一个更深层次问题的一部分，如果你不断缩小，不断缩小。这不再是一个人工智能接管的人类向未来经济迭代的故事。而是从完全的生物物质和宇宙大爆炸，纯粹没有任何价值创造到…

Jeremie (00:28:01):
我想这是一个阶梯函数，生命进化的第一个时刻。这就是我好奇的地方，这个观点似乎更倾向于量子跳跃角或者阶跃函数方法，除非我错了。

本(00:28:15):
是的。所以我觉得没错。毫无疑问，至少从直觉上来说，历史上有某些转变，看起来确实像是一些不同的事情发生了。所以第一个可以被称为生命形式的自我复制的东西，在某种意义上看起来像是一个相当离散的边界。或者像这样的事情，我真的不知道进化史，但我认为首先你进行一些像线粒体成为细胞的一部分。这是一个相当独立的事件，我相信其中一个生物体比另一个小，[听不清 00:28:48]整个真核生物分支都是从这个事件中进化而来的。还有各种有趣的事情，比如人们从那里掉下来，这似乎也是一种直觉上的不连续变化，我也不太清楚。

Ben (00:29:06):
从直觉上看，确实有些事情。另一个例子是在工业革命时期，人们开始大规模地从事农业。我认为普遍的想法是，从历史的角度来看，这实际上是相当快的，因为人类已经存在了 10 到 1000 年。然后可能在几千年的时间里，像西亚和后来的其他大陆的人们，过渡到定居的农业文明。

本(00:29:35):
我认为这是一个大约持续了 10 万年的大规模冰河时期，然后冰河时期结束了。气候发生了变化，在某种程度上变得更有利于人们真正过渡到定居农业，然后这一切发生得非常非常快。所以，是的，我确实认为你是对的，确实有一些历史案例，至少在我个人对它们了解不多的情况下，感觉像是不连续的变化。我也认为在某种程度上对人工智能来说也是如此。我不认为这是一个，你明天醒来的事情。但我确实认为，如果我们最终实现完全自动化，或者如果增长率因人工智能而再次提高。人们可能不会把它仅仅视为自 1950 年以来就存在的经济趋势的稳定延续。现在我们有非常稳定的经济增长率，我们有非常稳定的自动化填充率。如果增长率变得疯狂，我认为人们会觉得那里有一些拐点或支点或临界点。

Jeremie (00:30:36):
这实际上是一个很好的过渡点，可以想象到我真正想讨论的你一直在看的第二个领域，即你对人工智能安全的看法…不一定是人工智能安全，让我们说人工智能风险和这种平稳过渡到人工智能驱动的世界的想法，或者让我们说一种非常突然的过渡到一种反主题或存在致命的场景。那么你对此有什么看法吗？也许我会以此开始。所以，你能不能把你的想法放在你认为人工智能风险的论点在哪里是强有力的，也许在哪里是失败的？

本(00:31:14):
是的。所以我想我可以先说一点连续性问题，或者至少与连续性问题的相关性。正如你提到的，这也是人们关于人工智能的辩论，即人工智能会有多突然…让我们假设我们最终会进入一个人工智能系统可以基本上使人类劳动过时并做各种其他疯狂事情的世界。这种转变会有多突然？它会是那种类似于工业革命的东西吗？它会持续几十年的时间，这种渐进的东西会以渐进的方式传播到世界各地吗？

Ben (00:31:48):
我认为即使是像蒸汽动力这样的东西，人们从不使用化石燃料过渡到使用化石燃料，这也是一个极其漫长的过渡。它会更像那些案例吗？还是会让人感觉更突然？会不会有一个时间点，比如说两年的时间，我们从基本正常的东西到现在一切都是人工智能，甚至不到两年。这是一场长期或未来的辩论[听不清 00:32:15]。在某些方面，它似乎是相关的，某些方面应该是增加风险或最终降低风险。

Ben (00:32:24):
就增加风险而言，突然或非常快速的变化意味着它可能会突然出现。所以这是非常连续的，你会看到很多事情提前发生了。然而，如果它真的很突然，如果这是一个需要两年时间的过程，这意味着原则上两年后，如果它碰巧发生，我们可能会生活在一个非常不同的世界。准备的时间更少，适应不同中间水平差异的时间更少，尝试和错误学习的时间更少，对风险的感觉也更少。没有什么风险。如果我们把这个问题说出来，并意识到有机会看到如何发现和习惯问题，并提出中间解决方案，并从你的错误中学习。我认为这方面最大的风险可能是与错位人工智能相关的风险，我想这是最后一个主要风险类别。这些也有一点不同，我相信你已经有一些播客上的人谈论过它们。

Ben (00:33:21):
但很多担忧基本上都归结为我们未来开发的许多人工智能系统可能会在某种程度上表现得好像它们在追求某些目标。或者试图最大化世界的某些事物。从某种意义上说，就像[听不清 00:33:35]系统从刑事司法的角度对犯罪率进行预测，在某种意义上，试图提高预测的准确性或诸如此类的事情。令人担忧的是，目标是人工智能系统在某种意义上有分歧，而[听不清 00:33:58]人往往会有分歧，这将导致灾难性的后果。我们有人工智能系统，它们非常聪明，非常善于实现它们的任何目标，只是做与人们想要的不同的事情。

本(00:34:12):
所以速度确实与此相关，因为如果你认为这将是一个普遍的问题，有人会创建一个人工智能系统并部署它。然后在它的目标和人们的目标之间有一些分歧，这导致了伤害。看起来，如果人工智能系统在世界上扮演越来越大的角色，那么可能有相当多的时间来了解这种担忧的不那么灾难性的版本，或者了解什么可行或不可行。不是每个人都完全相信渐进和试错就足以完全解决问题。但是，实际上能够看到问题的更多次要版本，并提出在次要情况下有效的解决方案，似乎肯定是有帮助的。这种事情总是很突然，假设我们明天醒来，我们有了人工智能系统，原则上可以完全取代人类劳动，可以管理政府，可以做任何事情。

本(00:34:59):
无论出于什么原因，如果我们决定使用它们。他们的目标在某些重要方面与我们不同，那么这可能更令人担忧，我们可能看不到问题的出现。是啊。所以我猜你的问题是，为什么这可能不是一个主要的关注点，或者说这是一个关注点的论据是什么？

Jeremie (00:35:21):
实际上，我认为还有一个更具体的问题，那就是你花了很多时间来整理行李。尼克·博斯特罗姆在他的书《超级智能》中提出的论点就是这种担忧。简单总结一下，放在这里，我的想法是，我要把它切掉，请随意强调我切掉它的各种方式。但这个想法是这样的，如果我们假设人工智能团队，比如 OpenAI 和 DeepMind 以及其他任何东西都在逐步迭代，迭代，迭代。有一天，他们中的一个人有了一个想法或者购买了一整套计算，或者访问了一整套数据。这就是把一个系统从可怜的小 GPT 3 号提升到现在人类水平或更高水平所需要的东西。

耶雷米(00:36:06):
那个系统因为是人类水平或更高，它可能知道如何改进自己，因为人类知道如何改进人工智能系统。所以也许它知道如何改进自己，你得到一些递归循环，因为循环很紧，人工智能可以改进自己。最终，它变得如此聪明，以至于它可以用它的智慧压倒俘虏它的人，接管世界，导致一个完全灾难性的结果。这至少是大致正确的吗？

本(00:36:30):
是啊。所以我认为这基本上是正确的。是啊。因此，一种思考方式是，我认为存在一系列的对齐问题。其中一些是在更模糊的未来视角，随着时间的推移，我们逐渐创造出许多人工智能系统，它们的目标与我们不同，对未来的控制逐渐丧失，诸如此类。还有更极端的情况，就像有一个单一的人工智能系统，并且来得非常突然。从某种意义上来说，这是一种广义的超智能，并没有真正的先例。这个系统会很快地在世界上造成大破坏，就像有一些重大的跳跃到这个单一的非常破坏性的系统，这肯定是令人担忧的版本。它在尼克的书《超智能》和《叙事》中得到了强调，我猜你刚刚描述过了。

本(00:37:18):
所以我自己对人工智能风险的很多思考都是关于这个更极端的领域，所以出于几个原因，对超级智能的担忧出现了。我认为这是我第一次遇到的版本，这让我特别感兴趣，我想这是我感兴趣的部分个人原因。

Ben (00:37:39):
和其他人一样，我认为这只是，即使许多人工智能比对研究人员，也不会首先考虑这个版本的问题。我觉得还是挺有影响力的，挺有知名度的。通常，如果有人了解人工智能风险，这就是我们想到的担忧。所以听起来我认为这可能是一个特别值得关注的问题。所以我的一些想法只是关于看似合理的问题，你实际上有一个非常突然的跳跃，从你没有真正感兴趣的主要人工智能系统，有点像今天。然后某个地方的某个研究人员突然有了重大突破，你就有了这个单一的系统。我想我可能出于无聊的原因对此相当怀疑。

Ben (00:38:15):
最初令人厌烦的一个原因是，这不是技术的工作方式。如果从喜欢的角度出发，我们来看看技术通常是如何改造世界的。通常情况下，这是一个漫长的过程，需要几十年的时间，有人开发了一些东西，然后这是一个漫长的改进过程。然后它在某些领域比其他领域更重要，在某些领域比其他领域更有用。然后人们需要开发互补的发明来利用它。人们需要弄清楚如何恰当地使用它。还有很多你无法预见的调整和问题，这使得它成为一个缓慢的过程。所以就像电一样，我认为电动机是在 19 世纪早期的某个时候发明的。但是直到 20 世纪 30 年代，电动马达才在美国工厂占据主导地位。

本(00:39:02):
或者是 20 世纪中期的第一台数字计算机，但是从 90 年代开始，它们真正以一种大的方式出现在生产力统计中。即使这样，也不是所有的国家，不像在不同的重要场合普遍使用的那样。甚至不像经济中的大部分那样。因此，它成为一个起点，就像你不会太具体地看人工智能的细节，并说:“如果它像我们曾经拥有的任何其他技术一样，我会期待什么？”很可能是经济转型，这将是一个渐进的过程，会发生很多恼人的事情。

Jeremie (00:39:35):
只是稍微探索一下。所以我认为在过去的 100 年里，无论我们选择哪个时期，有一件事加速了技术的进步和传播，那就是交流。我们谈了很多次，互联网扮演的角色等等。尤其是沟通，在设计产品的团队，部署产品的团队，销售产品的团队等等之间的紧密反馈循环方面。就整合而言，一致性是由沟通驱动的。从某种意义上来说，这是否会破坏这一论点，“好吧，如果你有一个内部连贯的单一人工智能系统，它能够本质上收紧反馈回路，不是无限地，而是机器时间。”我想，我想问的是，你觉得那个职位有趣吗？

本(00:40:28):
所以我想我觉得这很有趣，但没有说服力。所以我会说，如果我们突然想象一下，突然出现一个功能极其广泛的人工智能系统，它可以为你提供所有与经济相关的生产任务。它可以挖掘芯片，它可以运行投票中心，它可以进行人工智能研究，它可以建立更多的计算资源，它可以管理没有军事战略。如果我们想象有一个单一的系统突然出现，它只是自己做所有的事情，而不与外界因素相互作用或依靠外部资源。看起来确实有一些直觉，事情可以发生得更快，因为沟通效率成本已经下降了很多。但是有这样的问题，我们应该想象这是发展的方式吗？将会有一个单一的系统突然获得所有这些能力。我想这可能是我对人工智能持怀疑态度的原因，也是因为一些无聊的原因。

本(00:41:32):
所以我们知道你可以同时在不同的领域取得进展。所以，就像……我想可能你的很多听众都很熟悉这个，语言模型或者这个最近由 OpenAI 开发的系统 GPT-3。这是一个系统的例子，通过一个简单的训练过程，在几乎相同的时间里，在许多不同的任务上变得相当好。所以我是在一个基本上是网页的大型语料库上接受训练的。我接受的训练是，根据我在一份文件中已经遇到的单词，试着预测下一个最不令人惊讶的单词。

Ben (00:42:08):
这样你就可以用它来为一篇新闻文章写标题，然后我会试着想想在给定标题的情况下，文章中最不令人惊讶的文字是什么。人们发现的一件事是，你可以用它来做很多不同的事情。所以你可以用它来做翻译，例如，我们可以用西班牙语写一个句子，然后说英语翻译，这个句子是空白的。而且这个系统会出去，至少会发现一个令人惊讶的东西，接下来基本上会像英文翻译它，并用它来写诗。艾米莉·狄金森这首诗最不令人惊讶的结尾是什么？

Ben (00:42:42):
但即使在这些情况下，从某种意义上来说，许多不同的功能同时上线。你仍然可以看到人工智能在不同方面的变化。所以它在很大程度上是很糟糕的，就像可用的计算机代码一样。你可以做到这一点，但目前基本上无法用有用的方式做到。它很擅长写贾巴沃克风格的诗，一首接一首。有理由认为，这甚至可能是一种不断扩展的情况，其中一些功能优先于其他功能。也有一些能力，你真的不能仅仅通过这种 GPT-3 风格来产生，在这个庞大的在线事物语料库上训练它。

本(00:43:23):
如果你想翻译国防部的内部备忘录，你需要接受其他方面的培训。如果你想让它写得像医疗保健立法，可能[听不清 00:43:30]不会为你做到这一点。如果你想让它设定超市价格，或者你个性化电子邮件，它知道什么时候为你安排会议。你需要一种不同的训练方法。或者，如果你想比人类表现得更好，你也需要一种不同的训练方法，因为你需要给它像…它基本上做的是试图说出一个人在互联网上写的最不令人惊讶的事情。但是如果你想比人做得更好，你就需要使用其他东西，某种反馈机制。

Ben (00:43:55):
我认为不同的功能会在不同的时间上线。也可能会有许多讨厌的东西出现在不同的特定领域，并没有真正显示给研究人员。但当你想把类似[听不清 00:44:07]这样的定律应用到工厂里实际使用电动机的人身上时，就好像，你需要重新设计你的工厂车间。因为它不再以中央蒸汽机为基础。你需要重新设计使用硬件的东西，你需要重新设计你的工人使用的流程，实际上是利用这个东西。你有需要发生的规则，等等，等等。或许这些事情在某种程度上需要被处理，至少在最初由不同的团队处理。其中一些会比其他的更难或者需要不同的资源。如果，这就像是说我期待东西上线的一种很长的方式，那我基本上会感到惊讶，那实际上在世界上不同的点上对不同的任务真的很有用。

Jeremie (00:44:40):
有意思。是啊，很有道理。对我来说有趣的是，这正是一个理论家会犯的错误，想象一个系统…这不是一个错误，这种情况很容易发生。但这些有趣的反对意见似乎映射到了那些关注理论优化而非实践中系统和经济优化的人的心理上。有意思。因此，这一切似乎并不意味着，在未来的某个时刻，开发一个具有自我迭代改进能力的人工智能系统是不可能的。

耶雷米(00:45:23):
这个问题有两个部分。首先，A，你认为是这样吗，或者你认为有可能建立这样一个系统吗？第二，你认为这样的系统会被建立或可能被建立吗？有没有一系列的激励因素累积起来，让我们得到一个递归的自我改进的人工智能，它最终会[foom 00:45:47]，做任何事情？这个故事可信吗？

本(00:45:51):
是的。所以我这里有一些。所以第一点是，我不清楚递归自我改进是否真的会成为一件事。很明显，现在有反馈回路，将来也会有反馈回路。所以我们以一种更有限的方式看待许多技术。所以现有的软件对于开发软件是有用的。软件开发者使用软件，计算机对于设计计算机是有用的。如果像 Nvidia 或任何种类的硬件制造商这样的人没有电脑可用，他们可能会发现他们的工作会更加困难。因此，在很多情况下，辅助设计开发技术或一种技术辅助另一种技术的开发。它通常不是递归的，或者它通常不是完全相同的自我改进的工件。

Ben (00:46:44):
在 AI 的例子中，我并不认为它是递归的。我当然希望人工智能越来越多地应用在人工智能开发寻找正确架构的背景下。或者学习，找出基本上开发另一个系统或使其良好运行的最佳方式。但我不认为这是一个独立的系统对自己做的事情，而不是一个用来帮助训练其他系统的系统。就像软件不会自我完善一样。我真的看不出递归有什么好处。如果这样做了，情况可能是这样，但我不明白为什么它会是递归的，为什么它天生更有吸引力。从某些方面来看，它似乎没那么有吸引力。这看起来有点混乱，或者如果这是一个有点模块化的东西，这似乎很好。

耶雷米(00:47:33):
是的，我想，从某种程度上来说，只是为了从工程的角度支持这个论点，我可以想象……所以这是不同系统的抽象，这个术语我们用来说有系统 A，有系统 B。系统 A 要么在改进自己，要么系统 B 在改进它，然后可能是系统 A……所有这些东西。我想在这种情况下，我想到的是一个抽象概念，它涵盖了类似于一个封闭系统的东西，这个系统在机器时间上起着关键的作用。所以在我看来，定义这种形式起飞的关键区别在于，这种自我优化或者系统 A 改进系统 B 的过程发生在微秒级。或者你有什么，以至于人类没有在过程中调解，最终对结果感到惊讶，而结果会大大偏离我们的期望。

本(00:48:33):
是的。所以我认为其中一个关键的区别是劳动力基本上参与了改进过程。因此，这种人工智能反馈循环的一个普遍反作用，对于真正提高变化率非常重要。我想我们确实已经有了这些反馈回路，在这些回路中，研究人员或工程师在 20 世纪初会做的大量任务，他们只是不再做了。它们已经完全自动化了。所以实际上手动计算就像一个巨大的时间水槽。这就像是工程学的研究成果。因此，从人们花费的时间来看，已经有了大规模的自动化，其中很大一部分已经实现了自动化。所以从这个意义上来说，这是一个非常强大的反馈循环，技术进步帮助了技术进步。

Ben (00:49:25):
但至少自 20 世纪中叶以来，我们还没有看到生产率像技术进步那样增长，至少在领先国家是这样。如果有什么不同的话，那就是它实际上走得更慢了。现在的比率相当于美国 20 世纪初的水平..所以很明显，这个反馈回路本身是不够的，还有一个抵消的东西，可能意味着同样的事情，就像这个想法越来越难找到现象。科技帮助你制造新的东西，但是你想制造的每一件新东西都比以前的东西更难制造。因为如果很简单，你早就做了。这是一个普遍的反驳论点。

本(00:50:01):
然后是反驳，反驳的论点就像，我们一直在将研究中涉及的许多任务自动化，然后创造机器来完成它们，然后改进机器。人类劳动一直是其中的一部分。如果你有这样一个故事，由资本填充的人力基本上是互补的。我认为我们有劳动力瓶颈的故事，我们不断制造更冷的机器，我们不断制造更多的机器。但是对于固定数量的研究工作来说，你的机器的酷和数量的回报是递减的。所以研究工作真的是瓶颈。它造成了这种收益递减现象，这实际上限制了由研究人员参与、完成或拥有的额外酷技术的边际价值。然后，研究人员的数量以相当恒定的指数速度增长，这实际上不可能轻易改变，因为它与人口等因素相关。

Ben (00:50:57):
所以我刚才说，如果你真的把人类劳动完全从画面中去掉，人们就不再参与研发或制造了。那么也许在这种情况下，你不再有这种收益递减效应，你不再有这种瓶颈，你在固定数量的劳动力上获得的资本收益递减。也许它只是直接反馈给自己，收益递减在某种重要意义上消失了。一旦你完全将人类从反馈回路中移除，反馈回路就真正启动了，这将是你可以讲述的故事，来说明为什么反馈回路在未来会不同于我们在过去一个世纪中所拥有的不明确的反馈回路。

Jeremie (00:51:29):
我想这是人类自我提高的一种反馈。我认为时钟时间是这里的显著特征，但我确实努力提高自己的生产率，我也确实努力做到这一点。我试着用提高自己的方式来提高自己。原则上，我认为我对无穷多的导数，或者接近于物质，都是这样做的。所以这是一个指数性质，但显然我还不是埃隆·马斯克。我还没有实现艰难的起飞，所以在某些地方有所不同。

本(00:52:05):
是的。所以我想我要说的是，我认为你绝对是对的，这是一个真实的现象。我认为，尽管涉及的数量级，你需要自我提高的程度比技术要小。让我们想象一个研究单位是你笔记本电脑里的一个人。这就是产生研究的原因。这个人实际上可以让自己更好地编码，他们可以让自己更好地学习如何快速做事情，他们可以学习如何学习。但是也许生产力的实际差异，也许你可以帮助增加 10 倍的人力资本，相对于 2020 年研究人员的平均水平。而你的笔记本电脑，看起来可能有更多的[听不清 00:52:44]可以比现在更好。

Jeremie (00:52:49):
不幸的是，似乎确实是这样，但我需要继续努力。我认为这是它所需要的。

本(00:52:56):
是的。我祝你在与笔记本电脑进步率的竞赛中好运。

耶雷米(00:52:59):
是的。谢了。如果我按了起飞键，我会告诉你的。所以这真的很有趣，你在这个问题上做了这么多的思考，我可以从自己身上看到你思考这个问题的方式的一些转变，当然还有一些我以前没有考虑到的方面。从经济学的角度来看，从系统的角度来看。这是你认为在技术型 AI 安全人中特别不常见的一种思维方式吗？或者你开始看到它被采用了…我仍然试图拼凑出这个景观是什么样子的，以及随着时间的推移，人们对这个主题的看法是如何转变的。因为举例来说，我记得 2009 年是[听不清 00:53:45]。基本上每个人都在谈论大脑在盒子里的想法，或者一些快速起飞的东西，在那里机器自我改进等等。

Jeremie (00:53:54):
虽然现在 OpenAI、Paul Christiano 和未来人类研究所的许多工作看起来确实很像，但事情正在发生变化。我很乐意听取您对这一转变、时间表以及机构群体目前对所有这些主题的看法。

本(00:54:11):
是的。所以我确实认为这种方式已经发生了转变，比如说这些社区中的普通人正在思考这个问题。对我来说有一点模糊，这在多大程度上是人们从一种思维方式转向另一种思维方式的转变。相对于更多的人带着已经存在的不同思维方式进入社区。我确实认为，有一些人以更具体的方式思考问题。你认为很多旧的分析非常抽象。它非常依赖于…它不完全像数学，它就像人们做一个抽象的代数或什么的。但这肯定更像是一种数学思维。

本(00:54:58):
它会随着时间的推移而改变。我认为其中的一个原因，也是非常合理的，就是当人们在 2000 年代中期谈论这个问题的时候。机器学习并不是一件大事。人们认为，也许面向逻辑的系统会更像 AGI 的样子。任何真正看起来像 AGI 的东西都可以作为思考的模型。我认为，随着机器学习的兴起，人们开始拥有这些系统，像 GPT-3，这里显然不是 AGI，可能 AGI 会有很大不同。这就像是通往 AGI 道路上的一块踏脚石。这有点像 AGI 什么的。

Ben (00:55:41):
我认为有了这些具体的例子，你就会开始以一种稍微不同的方式思考。你会开始意识到，在你之前拥有的这些抽象框架的背景下，它们实际上有点难以描述。那么 GPT-3 有目标吗，或者如果你想预测这种行为，有多有用。我猜它的目标是产生下一个不令人惊讶的词，但这样想有点不太对。尚不清楚它对预测这种行为有多大用处。它似乎并不真的有做一些疯狂的事情的风险，比如杀人来阻止他们阻止它输出。不知怎么的就是感觉不太合身。也只是看到更具体的应用和思考…所以我认为就像保罗·克里斯蒂诺说的那样，例如，在某种程度上是乐观的，“哦，我认为你实际上可能会用机器学习做那件事，在没有重大突破的情况下，在不远的将来。”让人们以更连续的方式思考，而不是全无或全无。就好像你可以看到中间转化的垫脚石。

Ben (00:56:41):
所以我认为这是一种中间应用，更具体一些。感觉有点怀疑抽象的构成，只是因为很难把它们放在你看到的事物上，或者一些有影响的力量。一般来说，我确实认为有很多人认为更数学化、更经典的处理事物的方式仍然很有用，或者这可能是他们处理事物的主要方式。

耶雷米(00:57:09):
是的。我实际上听到了争论…不一定是像 GPT-3 这样的系统会像你描述的那样变得病态。但至少可以讲述的故事听起来内在一致，描述了这样一个系统可能会严重出错的世界。在这种情况下，就像，想象一下 GPT 10 号，无论那一年发生了什么。你有一个系统，它必须像美化的自动完成任务一样做这件事。但是为了完成这项任务，有一点似乎很清楚，那就是它正在开发一个相当复杂的世界模型。关于这在多大程度上是记忆还是真正的概括学习，还存在一些争论。但是让我们假定 GPT-3 是可推广的学习。在这种情况下，系统继续开发一个越来越复杂的世界模型，一个越来越大的上下文窗口。

Jeremie (00:58:06):
最终，这个世界的模型包括了 GPT-3 本身的存在，它是世界的一部分。最终，当它试图优化它的渐变时，这种认识使它意识到，“哦，我可以通过某种走线来直接控制我的渐变，”这通常是它在[crosstalk 00:58:25]社区等中的框架。我认为你描述的问题适用于这种思维方式。但有趣的是，GPT-3 真的导致了对其中一些摘要的具体思考。

本(00:58:39):
是啊。我认为拥有这些具体的系统也是非常有用的，因为我也认为它们迫使直觉产生差异。或者把复出和假设中的分歧强行浮出水面。举个例子，肯定有一些人对这些 GPT 系统表示担忧，或者如果你有 GPT-10，这可能会非常危险。我真的没想到会这样。或者我估计我不会猜到别人有这种直觉只是因为我没有。因为我的基本直觉只是对系统工作方式的粗略估计。它是一个由一些参数组成的模型，然后暴露在一个文本语料库中。它只是基本上输出一个 X 单词，然后下一个单词实际上是对的或者不是。或者基本上有一个梯度，使得输出相对于数据集中的实际单词越来越不令人惊讶。

本(00:59:35):
它基本上是为输出单词而优化的，在一段文本中发现一个 X 单词并不奇怪，这段文本在网上的某个地方。当我想到 GPT-10 时，我想，“哇，我想它只是输出单词，这在网上的网页上发现并不奇怪。”就像它做的事情一样。假设，假设它确实输出单词，导致人们毁灭世界之类的东西。似乎只有当这些词在网上最不令人惊讶时，它才会这样做。如果导致它毁灭世界的词不是，在网上找到会令人惊讶吗，因为人们通常不会在网上写这种东西。那么梯度下降过程似乎发生了一些奇怪的事情。

Jeremie (01:00:15):
所以我认为这是一种非常好的设计方式。我相信，对此的反驳可能听起来像是，我们可能会把 20 万年前的人类视为性优化者之类的东西。然后我们发现，随着进化的展开，我们并不是那样。我认为这里的情况是，首先，有一个深刻的问题，神经网络实际上是在优化什么。实际上并不清楚它是在优化它的损失函数，还是每次梯度更新时它都会感到一阵兴奋。就像，“哦，你错了。以此更新您的所有费率。”

杰里米(01:00:58):
那一脚疼吗？如果是这样的话，这些系统优化的是真的吗？如果是这样的话，那么这整个区域显然是内部对齐的，我们在这里绕着，但我想这是一个很深的兔子洞。

Ben (01:01:15):
所以我有点同意在训练系统时使用的损失函数和这个系统试图做的事情之间有区别。有一种非常简单的说法，那就是如果你从下棋强化学习系统开始。你有一个回报函数，一个与之相关的损失函数，只是你还没有训练它。它不会表现得像是在试图赢国际象棋，因为这就像是一个最简单的例子，它就是没有意义。

本(01:01:40):
然后很明显，你有这些移植的案例，你在比如说一个视频游戏中训练一个系统，每次它打开左边的一个绿盒子，右边就有一个红盒子，它就会得分。你把它放在一个新的环境中，左边有一个红盒子，右边有一个绿盒子。到目前为止，你给它的训练数据实际上还不足以区分，听起来像是实际上被奖励的东西。是打开红色的盒子还是打开左边的盒子？如果系统，比如说，打开左边的盒子，你不应该感到惊讶，即使实际上不是损失函数的东西是红盒子，反之亦然。如果用错误的方式概括，也不奇怪。

Ben (01:02:21):
所以我当然同意存在泛化错误。我很难理解为什么你会以像 GPT-3 这样的情况结束，我只是不明白机械地会发生什么，它会在哪里…所以让我们说，关注是因为它的文本生成系统输出一些文本，如果有人阅读，它是一个杀死所有人的工程蓝图。我不知道是否有一个非科幻的版本，它会导致存在的风险，但假设它确实是这样的。我有时觉得我几乎是…要回答什么的或者我错过了什么。但我只是不明白为什么这个分级设计过程会导致它有一个这样的政策。为什么会朝那个方向优化呢？

Jeremie (01:03:06):
我要给出的答案，我肯定没有充分考虑过，我应该先说。但原则上，如果我们想象一下，比如无限的计算量，无限的数据规模，等等。这个模型会，比方说它开始思考，它思考得越来越多，越来越多，就像一个越来越大，越来越完整的世界图景。同样，根据它试图优化的内容，假设它试图优化以最小化其梯度。这是很自然的，我假设我在某种程度上是错的，但在某种程度上，想象神经网络每次被踢来踢去都感觉不好是对的。我不知道。

Ben (01:03:47):
我认为这实际上没有任何意义，尽管感觉很糟糕。我认为它只是，它有某些参数，然后它输出一些东西，并与训练集进行比较。然后根据差异，它[听不清 01:04:02]踢向不同的方向。但是我不认为实际上有任何内在的…我不认为实际上有一种有意义的感觉它感觉不好。它的参数可以像棍子一样来回移动。这是一个拿着棍子的家伙，在差异或缺乏差异的基础上，将参数推向不同的方向，然后它们最终在某个地方结束。

耶雷米(01:04:23):
是的。所以这本身就是，我认为最酷的方面之一。我快要被内心的兴奋分散注意力了。但对我来说，这是对齐辩论中最酷的一个方面，因为它真的让你对主观体验和意识产生了怀疑。因为如果不说“这是一种学习过程”这样的话，就无法进行对话学习过程往往会产生一个人造物，就像人类一样，它是一个大脑，似乎有一些主观经验，基本上是所有的生命。你可以观察变形虫，在显微镜下移动它。它真的好像在不同的时刻以不同的方式经历了痛苦和快乐。

Jeremie (01:05:02):
无论如何，看到这些系统以类似的方式运行，至少在我心中激发了一些问题，即实际的 Mesa-objective(优化器真正试图改进的功能)和主观体验之间的联系是什么。我将要进入一个我还不够了解的领域。但是也许我可以把这个想法留在，我认为这也是这个问题的一个令人兴奋和有趣的方面。你认为意识和主观经验，在这些机器的环境中的研究，有作用吗？还是你-

本(01:05:44):
我不这么认为。这里有一个困难，很明显人们对意识有不同的理解。所以我想我主要是在我想大卫[听不清 01:05:55]的意识体验中认为这至少是假设的现象学的东西，它不是本质上的一部分……它不像一个物理过程，所以它不是对事物如何处理信息的描述。这是一种叠加在大脑中发生的机械物质之上的体验。然而，如果你是魔术师，你会认为没有这样的东西，这就像一个呜呜呜的东西。但是我想对于意识的概念，它似乎在某种意义上没有直接的关联，因为它实际上没有它的怪异方面。这是一个定义或假设，而不是实际上物理影响任何已经发生的行为。你可以看到僵尸的行为方式也是一样的，但是它们的顶部没有额外的意识层。

Ben (01:06:44):
因此，我认为意识的这个版本与理解机器学习训练如何工作或 MACE 优化问题如何工作没有太大关系。也许有机械论的东西，人们有时指的是使用意识，我认为这有时与信息系统有关。不知何故，当人们使用“意识”这个术语时，他们可能会挑选出自己的表征。似乎有些东西是相关的，或者是关于你自己的目标是什么的信念，诸如此类。也许这与最优化和人类自我意识之类的东西有一些有趣的关系。所以我可以看到其中的联系，但我想这一切都是说，这取决于一个人头脑中意识的概念。

耶雷米(01:07:38):
不，完全有道理。有趣的是，这些东西确实与许多不同的领域重叠，从经济学到意识理论，心智理论。非常感谢你分享你的见解，本，我真的很感激。你有没有一个 Twitter 或个人网站可以分享，这样人们就可以查看你的工作，因为我认为你正在做一些令人着迷的事情。

本(01:07:57):
是的。所以我确实有一个个人网站，上面的内容很少，但是我参考了一些论文。那是 benmgarfinkel.com。我有一个推特账号，但是我从来没有在上面发过微博。我忘记了我的用户名是什么，但如果你想找到它并跟随我，有一天我可能会用它发微博。

耶雷米(01:08:15):
这是一个令人信服的推介。所以各位，看看本发微博的可能性。

Ben (01:08:22):
如果你现在就开始工作，你可能是第一批看到我发推文的人。

耶雷米(01:08:27):
他们正在播种。这是投资种子期的时候了。太棒了。非常感谢，本。我会链接到这两个东西，包括 Twitter。

Ben (01:08:36):
我期待着更多的 Twitter 关注者。

耶雷米(01:08:40):
这就对了。是啊。各位，跟着本，去看看他的网站。我还会在这篇播客的博文中发布一些链接，只是为了…我们在这次对话中提到的本整理的一些具体论文和作品，因为我认为还有很多值得挖掘的内容。本，非常感谢。真的很感激。

本(01:08:56):
非常感谢。这是一次超级有趣的谈话。