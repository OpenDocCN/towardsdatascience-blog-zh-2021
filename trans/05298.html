<html>
<head>
<title>Multilayer Perceptron for Image Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于图像分类的多层感知器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multilayer-perceptron-for-image-classification-5c1f25738935?source=collection_archive---------17-----------------------#2021-05-10">https://towardsdatascience.com/multilayer-perceptron-for-image-classification-5c1f25738935?source=collection_archive---------17-----------------------#2021-05-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8c9d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">没有回旋也没有关注。只是全连接层。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/126f4a3bc8669fa475a8231dda112fce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jbXlZk9cNhq1OGHu_Y3Plw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@urielsc26?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">乌列尔SC </a>在<a class="ae ky" href="https://unsplash.com/s/photos/neural-network?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="f868" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">介绍</h1><p id="a25d" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">卷积神经网络(CNN)已经帮助我们解决了图像分类等计算机视觉任务。它可以捕捉邻居信息，这要归功于它的卷积过程，其中它通过一个过滤器使用相乘矩阵的和。此外，使用CNN是因为它在其模型上具有权重共享机制，因此参数的数量将少于使用深度神经网络。</p><p id="31b6" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">随着时间的进步，CNN并不是做计算机视觉任务的唯一方式。主要用于自然语言处理任务的transformer体系结构可以在ImageNet数据集上以很高的性能完成图像分类任务。并且与CNN模型具有可比性[1]。</p><p id="fe84" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">现在，Touvron等人(2021)提出了一种仅使用全连接层的图像分类架构。它被称为剩余多层感知器(ResMLP)。它的伟大之处在于，该模型可以在ImageNet-1k训练数据上取得很好的结果[2]。</p><p id="dd6f" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">本文将向您解释ResMLP架构。此外，我将向您展示使用PyTorch实现这个模型。没有进一步，让我们开始吧！</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="5935" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">建筑</h1><p id="9dd8" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">那么这个模型是如何工作的呢？该模型的灵感来自于基于变形金刚模型[1]的ViT架构。</p><p id="3fc1" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">首先，ResMLP模型将图像分成N×N个小块，其中N是16。然后，每个面片将被展平为一个矢量，然后这些面片被独立地馈送到ResMLP层。</p><p id="742e" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">ResMLP将采用大小为d x (N x N)的矩阵X，其中d是向量维数，N x N是面片数。然后，那个矩阵会得到几次变换，直到得到一个与矩阵x大小相同的矩阵Y，下面是得到矩阵Y的等式。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/f599b044901429196b4c5129c8e26f82.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*2U-ZPdh9FnsU1NJOvqZ6BQ.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/2a4bab3debf9bb90b1cd74514f86991f.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*1-jox-hCJHDGkUDpKnh3pA.png"/></div></figure><p id="efaf" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">GELU是激活层，aff是通过重新缩放和移动图像来变换输入列的算子，B C矩阵是模型可学习的权重。</p><p id="9b85" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">在我们获得矩阵Y之后，该矩阵将被平均为d维向量，其中该向量将被用作线性分类器的特征并捕捉预测结果。该架构的概述可以在下图中看到。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/b1b8179eedc48b34cab55f68236687c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bxJrvGfCLCTeHUW-"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">架构(Touvron等人(2021年) )</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="ba3a" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">实施</h1><p id="12ed" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">值得庆幸的是，作者还包括了GitHub上的实现，你可以看看这个<a class="ae ky" href="https://github.com/lucidrains/res-mlp-pytorch" rel="noopener ugc nofollow" target="_blank">链接</a>。代码是使用PyTorch库实现的，并且已经打包成了一个包。你可以用pip下载，看起来是这样的。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="ade3" class="nh lh it nd b gy ni nj l nk nl"><strong class="nd iu">! pip install res-mlp-pytorch</strong></span></pre><h2 id="bd54" class="nh lh it bd li nm nn dn lm no np dp lq mh nq nr ls ml ns nt lu mp nu nv lw nw bi translated">数据</h2><p id="07ec" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">我们将使用的数据来自EPFL，名为Food 5K。该数据集由5000幅图像组成，这些图像根据是否包含食物进行了分类。要下载数据集，可以从<a class="ae ky" href="https://www.epfl.ch/labs/mmspg/downloads/food-image-datasets/" rel="noopener ugc nofollow" target="_blank">官网</a>或者<a class="ae ky" href="https://www.kaggle.com/binhminhs10/food5k" rel="noopener ugc nofollow" target="_blank">这个kaggle资源库</a>下载。</p><h2 id="dd48" class="nh lh it bd li nm nn dn lm no np dp lq mh nq nr ls ml ns nt lu mp nu nv lw nw bi translated">导入库</h2><p id="ef3c" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">在运行代码之前，我们需要导入库。这是完成这项工作的代码，</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><h2 id="b86c" class="nh lh it bd li nm nn dn lm no np dp lq mh nq nr ls ml ns nt lu mp nu nv lw nw bi translated">加载数据</h2><p id="7e1d" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">PyTorch的主要优点是模块化，因为您可以更容易地定制您的数据加载器，因此您可以更容易地将数据加载到模型中。下面是加载数据的代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><h2 id="00b3" class="nh lh it bd li nm nn dn lm no np dp lq mh nq nr ls ml ns nt lu mp nu nv lw nw bi translated">训练模型</h2><p id="1952" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">准备好数据后，现在可以使用ResMLP模型对数据进行建模。在这种情况下，我们将通过20个时期迭代建模过程。下面是训练模型的代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><h2 id="ab3f" class="nh lh it bd li nm nn dn lm no np dp lq mh nq nr ls ml ns nt lu mp nu nv lw nw bi translated">与CNN的比较</h2><p id="1d2b" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">这是使用ResMLP模型的训练结果，</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="fef4" class="nh lh it nd b gy ni nj l nk nl"><strong class="nd iu"># ResMLP <br/>Best val loss: 0.2860 <br/>Best acc: 0.891</strong></span></pre><p id="8131" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">基于训练结果，我们得到验证损失为0.2789，准确率为0.895。对于一个只使用前馈神经网络的模型来说，确实是一个不错的结果。但我们需要将其与现有模型进行比较。</p><p id="12dc" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">为了确定该模型与其他模型的性能如何，我还使用ResNet-18和ResNet-50架构训练了CNN模型。这是结果，</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="4f5a" class="nh lh it nd b gy ni nj l nk nl"><strong class="nd iu"># ResNet-18 <br/>Best val loss: 0.0365 <br/>Best acc: 0.986   </strong></span><span id="20ad" class="nh lh it nd b gy nz nj l nk nl"><strong class="nd iu"># ResNet-50 <br/>Best val loss: 0.0245 <br/>Best acc: 0.993</strong></span></pre><p id="fb71" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">正如你所看到的，ResNet-18实现了良好的性能。验证损失为0.0365，准确率为0.986。ResNet-50取得了较好的效果。验证损失为0.0245，准确率为0.993。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="1392" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">结束语</h1><p id="563e" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">从这些结果来看，我们可以说ResMLP仍然支持ResNet或类似的体系结构。但有了这个结果，我相信这个模型可以改进得更好，所以它可以像CNN一样有相当的表现，甚至更好。</p><p id="cf87" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">以上是对ResMLP模型的解释和实现。我希望你现在能从深度学习的进展中得到启发。如果你以后喜欢我的文章，对我的文章感兴趣，请关注我的媒体。如有疑问，可联系我<a class="ae ky" href="https://www.linkedin.com/in/alghaniirfan/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>。</p><p id="2bb7" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">谢谢你看我的文章！</p><h2 id="0fe0" class="nh lh it bd li nm nn dn lm no np dp lq mh nq nr ls ml ns nt lu mp nu nv lw nw bi translated">参考</h2><p id="c6c7" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">[1] Dosovitskiy，a .，Beyer，l .，科列斯尼科夫，a .，Weissenborn，d .，Zhai，x .，Unterthiner，t .，Dehghani，m .，Minderer，m .，Heigold，g .，Gelly，s .，Uszkoreit，j .，&amp; Houlsby，N. (2020)。一幅图像相当于16x16个字:大规模图像识别的变形金刚。ArXiv:2010.11929 [Cs]。<a class="ae ky" href="http://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/2010.11929</a></p><p id="bc5d" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">[2]图夫龙，h .、博雅诺斯基，p .、卡隆，m .、科德，m .、埃尔-努比，a .、格雷夫，e .、朱林，a .、辛那夫，g .、维尔比克，j .、杰古，H. (2021年)。具有数据有效训练的图像分类前馈网络。ArXiv:2105.03404 [Cs]。http://arxiv.org/abs/2105.03404<a class="ae ky" href="http://arxiv.org/abs/2105.03404" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>