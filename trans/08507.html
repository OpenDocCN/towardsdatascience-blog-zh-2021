<html>
<head>
<title>Use Case: Classifying Wood Veneers Into Dry and Wet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用例:将木材单板分为干和湿</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/use-case-classifying-wood-veneers-into-dry-and-wet-19e10c387973?source=collection_archive---------27-----------------------#2021-08-05">https://towardsdatascience.com/use-case-classifying-wood-veneers-into-dry-and-wet-19e10c387973?source=collection_archive---------27-----------------------#2021-08-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0e31" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">我们如何构建一个图像识别模型来自动化密钥验证过程</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/15009a9faf229a7bfd8c718c1c23fef2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z39GIPEhwEfWIY8pv_5VmA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/photos/JH_R66BihvA" rel="noopener ugc nofollow" target="_blank">图片来源</a>。</p></figure><p id="e85d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">工业物联网在<a class="ae kv" href="https://en.wikipedia.org/wiki/Fourth_Industrial_Revolution" rel="noopener ugc nofollow" target="_blank">工业4.0 </a>中发挥着重要作用，尤其是在自动化<a class="ae kv" href="https://en.wikipedia.org/wiki/Internet_of_things#Industrial_applications" rel="noopener ugc nofollow" target="_blank">制造</a>流程方面。随着传感器、摄像头和人工智能在边缘的集成，组织现在可以自动化许多流程，如视觉质量控制检查。</p><p id="62bb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以制造<a class="ae kv" href="https://en.wikipedia.org/wiki/Wood_veneer" rel="noopener ugc nofollow" target="_blank">木皮</a>为例。制造过程的一个重要部分包括在高达320°F的温度下干燥木材片，以获得大约8%至12%的含水量。在此干燥过程之后，必须对板材进行多次验证，以确保它们已正确干燥并符合质量控制标准。</p><p id="a8dc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了帮助自动化这一验证过程，我们开始在<a class="ae kv" href="https://www.perceptilabs.com/" rel="noopener ugc nofollow" target="_blank"> PerceptiLabs </a>中构建一个图像识别模型，该模型可以识别单板是<em class="ls">干</em>还是<em class="ls">湿</em>。像这样的模型可能有助于制造商自动识别水分含量过高的单板。</p><p id="12de" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">数据集</strong></p><p id="a5f4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了训练我们的模型，我们使用了来自<a class="ae kv" href="https://ieee-dataport.org/open-access/veneer21" rel="noopener ugc nofollow" target="_blank">单板21数据集</a>的图像。原始数据集包括高分辨率。png图像(通常超过4000x4000像素)分为两类，分别代表<em class="ls">湿</em>和<em class="ls">干</em>木皮。使用PerceptiLabs的<a class="ae kv" href="https://docs.perceptilabs.com/perceptilabs/references/ui-overview/data-wizard" rel="noopener ugc nofollow" target="_blank">数据向导</a>，我们将图像预处理为224x224像素。图1显示了来自该数据集的<em class="ls">干</em>单板的一些示例图像:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lt"><img src="../Images/ee5c91a71419f1c437eac2ae03fea6dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Xel_eVumXiVkOyp2"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="lu">图1:显示干燥单板的数据集的图像示例— </em> <a class="ae kv" href="https://ieee-dataport.org/open-access/veneer21" rel="noopener ugc nofollow" target="_blank"> <em class="lu">图像来源</em> </a> <em class="lu">。</em></p></figure><p id="eccc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了将分类映射到图像，我们创建了一个. csv文件，将每个图像文件与适当的分类号(0 =干，1 =湿)相关联，以便使用PerceptiLabs的数据向导加载数据。下面是一个部分的例子。csv文件看起来:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lv"><img src="../Images/4d6f5e55f7159604264a20b219c9f709.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zU98q7RPkK3NbdsgMpT2MQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="lu">的例子。csv文件，用于将数据加载到将图像文件映射到其分类号的PerceptiLabs中。</em></p></figure><p id="a720" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">车型总结</strong></p><p id="2e0c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的模型只用了三个<a class="ae kv" href="https://docs.perceptilabs.com/perceptilabs/references/components" rel="noopener ugc nofollow" target="_blank">组件</a>:</p><p id="0dd8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">组件1:卷积神经网络(CNN)，Activation= <a class="ae kv" href="https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank"> ReLU </a>，特征映射=16，Patch_size=3，Stride=2</p><p id="d640" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">组件2:密集，激活= <a class="ae kv" href="https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank"> ReLU </a>，神经元=256</p><p id="62f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">组件3:密集，激活= <a class="ae kv" href="https://en.wikipedia.org/wiki/Softmax_function" rel="noopener ugc nofollow" target="_blank"> Softmax </a>，神经元=2</p><p id="042d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图2显示了感知实验室中模型的拓扑结构:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lt"><img src="../Images/c9187ebf3046e1cf7b673d8c6ddec29a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IlBFwMc-4nmXq3HM"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="lu">图2:感知实验室中模型的拓扑结构— </em> <a class="ae kv" href="http://www.perceptilabs.com" rel="noopener ugc nofollow" target="_blank"> <em class="lu">图片来源</em> </a> <em class="lu">。</em></p></figure><p id="96a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">训练和结果</strong></p><p id="be51" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">我们用32个</strong>批量5个历元训练模型，使用<a class="ae kv" href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/#:~:text=Adam%20is%20a%20replacement%20optimization,sparse%20gradients%20on%20noisy%20problems." rel="noopener ugc nofollow" target="_blank"> ADAM </a>优化器，学习率0.001，交叉熵<a class="ae kv" href="https://blog.perceptilabs.com/choosing-and-customizing-loss-functions-for-image-processing/" rel="noopener ugc nofollow" target="_blank">损失</a>函数。在大约22分10秒的训练时间内，<strong class="ky ir">我们实现了100%的训练准确率和99.7%的验证准确率</strong>。图3显示了训练期间PerceptiLabs的统计视图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lt"><img src="../Images/5c93e483a6ea05a518fa652c6ae24fd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AZ3wDh4wCkocsQk4"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="lu">图3: PerceptiLabs在训练时的统计视图— </em> <a class="ae kv" href="http://www.perceptilabs.com" rel="noopener ugc nofollow" target="_blank"> <em class="lu">图片来源</em> </a> <em class="lu">。</em></p></figure><p id="ebb6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面的图4和图5显示了训练期间五个时期的准确度和损失:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lt"><img src="../Images/19830730613d0dd8110c585ac525ddd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sdV7Kb0uFzzjdndN"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="lu">图4:训练时的准确度— </em> <a class="ae kv" href="http://www.perceptilabs.com" rel="noopener ugc nofollow" target="_blank"> <em class="lu">图片来源</em> </a> <em class="lu">。</em></p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lt"><img src="../Images/33f6b2c99e697485b78db4e5c4e31e40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8HNtwdIVdjdjseYj"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="lu">图5:训练中的损耗— </em> <a class="ae kv" href="http://www.perceptilabs.com" rel="noopener ugc nofollow" target="_blank"> <em class="lu">图片来源</em> </a> <em class="lu">。</em></p></figure><p id="f20a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里我们可以看到，在训练和验证的第一个时期，精确度增加最多，损失减少最多。在第一个时期之后，精确度和损失在其余时期保持稳定。</p><p id="994c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">垂直应用</strong></p><p id="1767" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">像这样的模型可以用来检测生产线上的制造缺陷。例如，该模型可用于分析照片或视频帧，这些照片或视频帧是通过工厂地板上的摄像机采集的，这些摄像机在制造过程中捕捉通过装配线的单板。任何含有T2湿木材的板材都会被标记出来，供工厂工人进一步检查。该模型本身也可以用作<a class="ae kv" href="https://blog.perceptilabs.com/when-to-use-transfer-learning-in-image-processing/" rel="noopener ugc nofollow" target="_blank">迁移学习</a>的基础，以创建用于检测其他类型的材料或产品中的缺陷的附加模型。</p><p id="201b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">总结</strong></p><p id="b653" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个使用案例是一个例子，说明图像识别如何用于帮助制造业。如果你想建立一个类似这样的深度学习模型，<a class="ae kv" href="https://docs.perceptilabs.com/perceptilabs/getting-started/quickstart-guide" rel="noopener ugc nofollow" target="_blank">运行PerceptiLabs </a>并在<a class="ae kv" href="https://github.com/PerceptiLabs/Classifying-Wood-Veneers-as-Dry-or-Wet" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上查看我们为这个用例创建的repo。</p><p id="5268" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://gharpedia.com/blog/manufacturing-process-of-wood-veneer/" rel="noopener ugc nofollow" target="_blank">https://ghar pedia . com/blog/manufacturing-process-of-wood-单板/ </a></p><p id="4abf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">T.Jalonen，F. Laakom，M. Gabbouj和T. Puoskari，“使用暹罗神经网络的视觉产品跟踪系统”，IEEE Access，第9卷，第76796–76805页，2021年，doi:10.1109/Access . 2021 . 3082934(<a class="ae kv" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank">cc 4.0</a>)。</p></div></div>    
</body>
</html>