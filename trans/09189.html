<html>
<head>
<title>Building a Vanilla Artificial Neural Network from Scratch (in R)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始构建一个普通的人工神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-vanilla-artificial-neural-network-from-scratch-in-r-5f03dfec628b?source=collection_archive---------8-----------------------#2021-08-25">https://towardsdatascience.com/building-a-vanilla-artificial-neural-network-from-scratch-in-r-5f03dfec628b?source=collection_archive---------8-----------------------#2021-08-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e051" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">从基础到实际实施</h2></div><h1 id="6570" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated"><strong class="ak">什么是神经网络？</strong></h1><p id="b4ad" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">人工神经网络(ANN)是一种现代机器学习方法，它试图模仿人脑学习和处理信息的方式。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/2c36025cebc9448c8a0823273b29d6ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/0*SZBGG0tkd3t4wh40.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">来源:<a class="ae mf" href="https://pixabay.com/illustrations/artificial-neural-network-ann-3501528/" rel="noopener ugc nofollow" target="_blank">https://pix abay . com/插图/人工神经网络-ann-3501528/ </a></p></figure><p id="502e" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">如今，人工神经网络广泛用于开发人工智能驱动的产品，对于计算机视觉(CV)和自然语言处理(NLP)中的不同应用，存在许多不同的神经网络架构:</p><ul class=""><li id="e6a6" class="ml mm iq kz b la mg ld mh lg mn lk mo lo mp ls mq mr ms mt bi translated">面部识别</li><li id="a0b5" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated">语言翻译</li><li id="5a94" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated">目标检测</li><li id="2b07" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated">语音识别</li><li id="1f55" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated">自动更正文本</li><li id="59cd" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated">创造艺术</li></ul><p id="2ebb" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">可能性是无穷无尽的，清单还在继续…</p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="88c5" class="kf kg iq bd kh ki ng kk kl km nh ko kp jw ni jx kr jz nj ka kt kc nk kd kv kw bi translated"><strong class="ak">它们是如何工作的？</strong></h1><p id="cd3a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">通过将人工神经网络分解为基本组件，可以更好地理解人工神经网络:</p><ul class=""><li id="f148" class="ml mm iq kz b la mg ld mh lg mn lk mo lo mp ls mq mr ms mt bi translated">前馈机制</li><li id="f1ec" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated">重量优化</li></ul><h2 id="242a" class="nl kg iq bd kh nm nn dn kl no np dp kp lg nq nr kr lk ns nt kt lo nu nv kv nw bi translated">前馈机制</h2><p id="dbf9" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">该组件负责使我们的模型能够进行预测。在其最简单的形式中，前馈机制首先将线性函数应用于给定的输入，然后使用称为“激活”的非线性函数将结果转换为期望的输出。</p><p id="3cf6" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">让我们通过考虑由一组输入、一个隐藏神经元和一个输出神经元组成的简单模型来可视化这些操作:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi nx"><img src="../Images/9fb16ad31deb6172af8997d9ea5d58d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x15siLNe8Kh6gSlZLiDfpQ.png"/></div></div></figure><ul class=""><li id="7e1a" class="ml mm iq kz b la mg ld mh lg mn lk mo lo mp ls mq mr ms mt bi translated">x:输入的矩阵集合(<strong class="kz ir">预测器</strong>)。</li><li id="1251" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated">w:一些可以被视为输入和输出之间关系的斜率/变化率的矩阵，称为<strong class="kz ir">权重</strong>。</li><li id="6439" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated">b:类似于“y轴截距”的常数，称为<strong class="kz ir">偏差</strong>。</li><li id="2436" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated"><em class="oc"> g(a): </em>应用于线性输出‘a’的非线性<strong class="kz ir">‘激活’</strong>函数(一些最流行的激活函数的例子):<br/> -整流线性单位(ReLU): max{0，x }<br/>-Sigmoid:1/(1+exp {-x })<br/>-双曲正切(tanh): sinh(x) / cosh(x)</li></ul><p id="2778" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">当处理由几个预测值组成的数据时，我们通常需要更多的隐藏层和神经元，但我们仍然应用与上述相同的操作顺序。唯一的区别是，我们的模型变得明显更加复杂，使得最终训练我们的模型变得更加困难。</p><h2 id="fa55" class="nl kg iq bd kh nm nn dn kl no np dp kp lg nq nr kr lk ns nt kt lo nu nv kv nw bi translated">重量优化</h2><p id="97fe" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><em class="oc">我们如何知道前馈机制做出的预测实际上是正确的？</em></p><p id="14ae" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">人工神经网络通过优化与预测器相关的权重矩阵来学习更好地逼近目标变量。与前馈组件相比，优化模型权重是一个不太直观的过程，因此无需深入研究所需的严格数学，我将给出继续本教程所需的概念性理解。</p><p id="c71e" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated"><strong class="kz ir">反向传播</strong>是一种先进的数学算法，结合了链式法则和相应变量的偏导数，计算权重矩阵的梯度。</p><p id="397c" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated"><em class="oc">那么，既然有了梯度，我们如何优化权重呢？</em></p><p id="abab" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated"><strong class="kz ir">随机梯度下降</strong> ( <strong class="kz ir"> SGD </strong>)，通过在选定数量的训练迭代(<strong class="kz ir">时期</strong>)上以指定的收敛速率(<strong class="kz ir">学习速率</strong>)最小化成本函数，利用反向传播算法来调整模型权重。由于梯度是一个常数，在每个时期，我们调整权重，直到收敛到全局最优值。</p><p id="00e8" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">希望这个图表可以帮助我们了解SGD在每个时期的目标。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi od"><img src="../Images/0942d59c3f692f865bc8c20dcad28ce3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*i9d04LgojJd05kkB1c3C-w.png"/></div></figure></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="9db2" class="kf kg iq bd kh ki ng kk kl km nh ko kp jw ni jx kr jz nj ka kt kc nk kd kv kw bi translated">在R中构建模型</h1><p id="14b4" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">现在我们有了所需的基础知识，我们终于可以开始构建模型了！！！</p><p id="28a5" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">我将通过一个简单的指南从头开始构建一个“香草”人工神经网络(不使用任何内置模块)。我们将建立的模型类型将是一个<strong class="kz ir">回归变量</strong>，因为预测变量和响应变量都是数字。</p><h2 id="f677" class="nl kg iq bd kh nm nn dn kl no np dp kp lg nq nr kr lk ns nt kt lo nu nv kv nw bi translated">为什么从零开始？</h2><p id="0ce9" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我也曾经问过自己同样的问题，但是一旦我被迫从头开始编写自己的代码，我注意到我开始在更深的层次上理解底层的概念(及其乐趣)。</p><h2 id="0d91" class="nl kg iq bd kh nm nn dn kl no np dp kp lg nq nr kr lk ns nt kt lo nu nv kv nw bi translated">模型架构</h2><p id="c2f3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们将要构建的人工神经网络将由一组输入、一个包含5个神经元的隐藏层和一个最终输出层组成。让我们来看看组装模型所必需的构件:</p><ul class=""><li id="2160" class="ml mm iq kz b la mg ld mh lg mn lk mo lo mp ls mq mr ms mt bi translated">输入数据(<strong class="kz ir"> X </strong>):来自区间[-2，2 ]上连续均匀分布的60个模拟随机变量。</li><li id="1362" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated">响应(<strong class="kz ir">Y</strong>):X的某三角函数，(<em class="oc"> f(X) </em> ) = cos(2x +1)</li><li id="f374" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated">激活功能:<strong class="kz ir">乙状结肠</strong></li><li id="fd5b" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated">权重矩阵(<strong class="kz ir"> w1，w2 </strong>):大小为{N * (p + 1)，Q * (N +1)}，其中N是每层中隐藏神经元的数量，p是不同预测器的数量，Q是输出(1)的维数。最初，随机模拟模型权重，然后通过我们的随机梯度下降算法进行优化。</li><li id="f10a" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated">成本函数:使用误差平方和(<strong class="kz ir"> SSE </strong>)来评估我们模型的预测质量，因此我们将使用<strong class="kz ir">二次成本</strong>。</li></ul><p id="9476" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">让我们看看我们如何在R中定义这些变量:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/acf6235fd30af8d1e3c19ad42ec13e55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*TjNz0uG1PtVKBh1nZXbRqw.png"/></div></figure><h2 id="bfaf" class="nl kg iq bd kh nm nn dn kl no np dp kp lg nq nr kr lk ns nt kt lo nu nv kv nw bi translated">前馈机制</h2><p id="c736" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">现在我们已经有了变量，我们定义我们自己的函数，我们将用它来预测我们的输入向量。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi of"><img src="../Images/486f84e566a5c583e205a3f6de659bb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*Nun1y2jqmJuzZ8mlcWdRJw.png"/></div></figure><h2 id="dfa7" class="nl kg iq bd kh nm nn dn kl no np dp kp lg nq nr kr lk ns nt kt lo nu nv kv nw bi translated">反向传播</h2><p id="fb58" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">首先，我们必须定义激活函数的导数，因为它是通过网络反向传播时的关键特征:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi og"><img src="../Images/63a24d9eb0a1f892189688f7eb57a1df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*diyjyaEu98csYIBRG-W3yA.png"/></div></figure><p id="3410" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">让我们仔细看看为了执行反向传播我们需要概述的必要操作。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/94a993d27d1dd72043cdc36508c85a7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*qfoIyZv4obhwf17vVu9j5g.png"/></div></figure><p id="4a0f" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">分解代码:</p><ul class=""><li id="74d7" class="ml mm iq kz b la mg ld mh lg mn lk mo lo mp ls mq mr ms mt bi translated"><strong class="kz ir"> preds </strong>:最小化成本函数所需的模型预测</li><li id="eba9" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated"><strong class="kz ir"> derivCost </strong>:由于我们使用上证综指作为模型误差的衡量标准(二次成本)，对预测值求导会产生上述结果</li><li id="1c73" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated"><strong class="kz ir"> (dW1，dW2) </strong>:最初，我们用来存储权重矩阵梯度的空矩阵。</li></ul><p id="092e" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">理解代码块的其余部分需要对反向传播算法有更深入的理解。这个视频应该可以达到目的:</p><figure class="lu lv lw lx gt ly"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="1c0f" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">执行反向传播很不直观，而且这些只是对通过隐藏层的一组输入的计算。随着更多的层被添加到网络中，计算梯度在计算上变得昂贵。</p><h2 id="ca86" class="nl kg iq bd kh nm nn dn kl no np dp kp lg nq nr kr lk ns nt kt lo nu nv kv nw bi translated">模特培训</h2><p id="85b3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如果你已经注意到了，我们还没有真正使用我们在代码块中定义的任何函数。在这里，我们通过调用所有前面的函数来执行模型训练，从而将所有东西联系在一起。</p><p id="9e91" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">我们定义了随机梯度下降函数来优化我们的权重和跟踪训练误差。</p><p id="e82b" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">本质上，我们将在每次迭代时通过选择的学习率(通常是从0到1的浮点数)来调整权重矩阵，同时我们将在每个时期将SSE值存储在一个空矩阵中。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi ok"><img src="../Images/ddb245e7f65b80e712848676a3ff2f4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qsU1xVrBvbj9jmWkEv4qoA.png"/></div></div></figure><p id="cc32" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">最后，我们的模型参数通过调用我们的SGD函数获得…(我选择200个历元，因为通过反复试验，它给出了最好的结果)。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi ol"><img src="../Images/89c256ac6f0c73e0ad81240ccbc44b60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RJC3FvhOUJ6gsjzFaxEV6g.png"/></div></div></figure><h1 id="bbc1" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">模型评估图</h1><h2 id="a320" class="nl kg iq bd kh nm nn dn kl no np dp kp lg nq nr kr lk ns nt kt lo nu nv kv nw bi translated">训练误差</h2><p id="5255" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这是我们的训练误差在历元数(200)上的图，我们看到性能在开始时有很大提高，随后在每次连续迭代后模型误差稳步下降。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi om"><img src="../Images/7fd4cc6d34470f834ad94b035a534443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C0yJbRQo4e7IcPQc3dyoYw.png"/></div></div></figure><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi on"><img src="../Images/725487325e823679047fc5ded5c738f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tlr3ZsGHoTCPbifmEARwfQ.png"/></div></div></figure><p id="b75e" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated"><strong class="kz ir"> ***注意:</strong>我们省略测试误差图的原因是我们实际上没有测试集，因为我们的预测值是从随机均匀分布模拟的，而不是从实际数据集模拟的。</p><h2 id="fd7b" class="nl kg iq bd kh nm nn dn kl no np dp kp lg nq nr kr lk ns nt kt lo nu nv kv nw bi translated">实际值与预测值</h2><p id="3766" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">让我们看看我们的模型如何通过绘制原始响应值与预测值来预测目标变量:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi oo"><img src="../Images/59a1d9a85334ec505aa0f807466149b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*766lQ0JgHx1TQ-k6BPqIhw.png"/></div></div></figure><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi on"><img src="../Images/dc6c739bbda29064267c5080090642ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c74jFaV36n5d998tgjgp6g.png"/></div></div></figure><p id="d70a" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">还不错！我们的模型在解释响应变量方面做得很好，性能似乎偏向右尾，但没有过度拟合的迹象。</p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="9746" class="kf kg iq bd kh ki ng kk kl km nh ko kp jw ni jx kr jz nj ka kt kc nk kd kv kw bi translated">最后的想法</h1><p id="f887" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">神经网络负责为我们今天看到的最先进的人工智能技术提供动力。我们从头开始浏览了构建简单的香草人工神经网络架构的指南。</p><p id="19cc" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">现在，您已经对神经网络如何工作有了基本的了解，我鼓励您探索更高级的模型架构，这些架构支持我们今天拥有的一些最好的人工智能产品/服务。</p><p id="528d" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">这里是一个开始的好地方:</p><div class="op oq gp gr or os"><a rel="noopener follow" target="_blank" href="/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd ir gy z fp ox fr fs oy fu fw ip bi translated">解释了最完整的神经网络图</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">神经网络类型的动物园呈指数增长。人们需要一张地图在众多新兴架构之间导航…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">towardsdatascience.com</p></div></div><div class="pb l"><div class="pc l pd pe pf pb pg lz os"/></div></div></a></div></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><p id="9fd4" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated">我真的希望你喜欢这个小教程！如果你觉得有用或有趣，请随意评论，并<a class="ae mf" href="https://medium.com/@andrew.tchircoff" rel="noopener">订阅</a>关于机器学习和其他技术主题的未来文章:)</p><p id="3b47" class="pw-post-body-paragraph kx ky iq kz b la mg jr lc ld mh ju lf lg mi li lj lk mj lm ln lo mk lq lr ls ij bi translated"><strong class="kz ir"> ***获取完整R脚本:</strong></p><div class="op oq gp gr or os"><a href="https://github.com/tristanoprofetto/neural-networks/tree/main/ANN/Regressor" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd ir gy z fp ox fr fs oy fu fw ip bi translated">神经网络/ANN/tristanofetto主回归器/神经网络</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">使用深度学习库来实现针对不同类型数据优化的各种网络架构…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">github.com</p></div></div><div class="pb l"><div class="ph l pd pe pf pb pg lz os"/></div></div></a></div></div></div>    
</body>
</html>