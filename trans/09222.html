<html>
<head>
<title>The struggles and the tips: What I learn from doing my own classification project</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">挣扎和提示:我从自己的分类项目中学到了什么</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-struggles-and-the-tips-what-i-learn-from-doing-my-own-classification-project-dc1e70937b09?source=collection_archive---------17-----------------------#2021-08-26">https://towardsdatascience.com/the-struggles-and-the-tips-what-i-learn-from-doing-my-own-classification-project-dc1e70937b09?source=collection_archive---------17-----------------------#2021-08-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="0e9c" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="c31b" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">与Iris数据集不同，一旦你开始在一些非常规的数据集上做你的第一个项目，1001个问题就出现了</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/9c12448b322edf5ceee55c2b5a665d34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3ge-rwXsB_YcP34E"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@octadan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">屋大维丹</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="7ded" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，已经到了建议你“找到你自己的数据集，并产生一些有趣的分析”的地步。如果数据集不那么受欢迎，或者任务更模糊，定义更不明确，并且Kaggle上没有数百个可用的笔记本，那就更好了。从我(可能是很多人)的经验来看，这样的数据集乱七八糟，有遗漏的条目，有太多/太少的观察，所有的特征都是最原始的形式。我的数据集没有什么不同，在经历了第一个项目后，我很乐意分享我的过程，并强调一些我在这个过程中遇到的数据问题以及我是如何处理它们的。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mb"><img src="../Images/df7ca52d132852fcd9731f67fd43a27d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2m5blY080ftDF6shYKqMbg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">我正在使用的数据帧的快照</p></figure><p id="6a63" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">首先，我正在处理的数据集是关于来自<a class="ae le" href="https://www.kaggle.com/nehaprabhavalkar/indian-food-101/code" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>的印度美食，它已经被许多人用于EDA任务。它只包含大约250个观察值(盘)和9个特征。尽管得到的样本量如此之小，我还是决定尝试一下，看看能否从这个数据集建立一个好的机器学习模型。故事是这样的，按时间顺序:</p><h1 id="424f" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">“定义问题”阶段:仅有2个数值变量！！</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mu"><img src="../Images/8faf597e32f384ae9a4bf2be0a9b304d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6NcsnUbOc8fFG3p4"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">沃洛德梅尔·赫里先科在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplas </a> h拍摄的照片</p></figure><p id="89d9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我感兴趣的第一个问题是从其他变量中预测烹饪时间，因为我认为味道太容易预测了——比方说，辛辣的菜肴肯定有一些特定的成分；另一方面，饮食相当简单，因为它只是二元的(素食者对非素食者)；每个州和地区都有各种各样的菜肴，所以用配料和口味作为这些菜肴地理位置的指标是没有意义的；最后，知道一道菜属于哪道菜不是很有趣，也没有帮助。然而，能够预测烹饪或准备时间可以帮助我们研究那些不太明显的特性组合(配料、口味等)，这些特性组合使得一道菜烹饪起来慢/快。</p><p id="7ee6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">数据集中只有两个数值变量(准备时间和烹饪时间)，如果烹饪时间被设置为目标变量，准备时间将是唯一的连续自变量，这对于回归任务来说并不理想(事实上，我已经尝试过了，并且得到了一个很大的难以减少的RMSE)。</p><p id="12c9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了解决这个问题，我通过将我的目标变量离散化为3个范围，将其转换为一个分类任务:1-quick ( &lt;30 mins), 2-medium (30-60 mins), and 3-slow (&gt; 1hr)。</p><pre class="kp kq kr ks gt mv mw mx my aw mz bi"><span id="cebd" class="na md iq mw b gy nb nc l nd ne">&gt;&gt; bins = [0, 30, 60, 720]</span><span id="3dae" class="na md iq mw b gy nf nc l nd ne">&gt;&gt; group_names = ['quick', 'medium', 'slow']</span><span id="6cc6" class="na md iq mw b gy nf nc l nd ne">&gt;&gt; df_train['cook_time'] = pd.cut(df_train['cook_time'], bins, labels=group_names)</span></pre><h1 id="236d" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">“预处理数据”阶段1:缺失值</h1><pre class="kp kq kr ks gt mv mw mx my aw mz bi"><span id="e7d8" class="na md iq mw b gy nb nc l nd ne">&gt;&gt; df.isnull().mean().round(4)*100</span><span id="9950" class="na md iq mw b gy nf nc l nd ne">name               0.00 <br/>ingredients        0.00 <br/>diet               0.00 <br/>prep_time         11.76 <br/>cook_time         10.98 <br/>flavor_profile    11.37 <br/>course             0.00 </span></pre><p id="3a1f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">超过10%的观测值包含至少一个NA值。对于这样一个小数据集，删除所有这些行将留下非常少的数据点来训练模型，因此它不是这里的一个选项。相反，我将使用sklearn的<em class="ng">估算</em>模块估算<em class="ng"> prep_time </em>和<em class="ng"> flavor_profile </em>的缺失值。<em class="ng"> cook_time </em>不应被估算，因为它是我们的目标变量，因此事先使用其他数据填充它没有意义，所以我们必须删除该特性的所有缺失值。我们从估算准备时间开始。看一看烹饪和准备时间的分布，我们可以看到它们都高度向右倾斜:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nh"><img src="../Images/a29624aca88bf1108fad0e4d3b4b7999.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RdTdBBbJiaicXyiSyFnX3Q.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">准备和烹饪时间直方图</p></figure><p id="a71c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，最合适的方法是使用mode来替换缺失值，而不是使用median或mean。代码如下:</p><pre class="kp kq kr ks gt mv mw mx my aw mz bi"><span id="5636" class="na md iq mw b gy nb nc l nd ne">from sklearn.impute import SimpleImputer</span><span id="eae0" class="na md iq mw b gy nf nc l nd ne">imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')</span><span id="f221" class="na md iq mw b gy nf nc l nd ne">df.dropna(subset=['cook_time'], inplace=True)</span><span id="c417" class="na md iq mw b gy nf nc l nd ne"><em class="ng"># fit transform the prep_time column </em><br/>df['prep_time'] = imp.fit_transform(df['prep_time'].values.reshape(-1, 1))</span></pre><p id="c95f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于flavor_profile，我将使用k-最近邻来估算其缺失值。因此，这必须在预处理所有其他列之后进行，在本例中，大多数列目前都是多种格式的字符串，下面将详细介绍其中一些。预处理其他特征后，该部分的代码为:</p><pre class="kp kq kr ks gt mv mw mx my aw mz bi"><span id="717a" class="na md iq mw b gy nb nc l nd ne">from sklearn.impute import KNNImputer<br/>imputer = KNNImputer(n_neighbors=3)</span><span id="c4c6" class="na md iq mw b gy nf nc l nd ne">df= imputer.fit_transform(df)</span></pre><h1 id="325e" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">“预处理数据”阶段2:配料栏</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ni"><img src="../Images/06e5716e4f7cf548002cc04fdd6baea8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ts1d61Z3j_QEGZJc"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@calumlewis?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Calum Lewis </a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="c682" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我有两种方法可以设计这个功能:对最受欢迎的成分进行热编码，或者对每种成分使用原始的TF-IDF分数。从实验来看，后者比前者有更好的准确率。对于这两种方法，我使用了<strong class="lh ja"> TF-IDF分数</strong>来衡量一种成分代表了整道菜的多少特征。(你可以在这里阅读更多关于TF-IDF <a class="ae le" href="https://monkeylearn.com/blog/what-is-tf-idf/" rel="noopener ugc nofollow" target="_blank">。这个想法是，普通的配料，如盐、胡椒等，可能并不代表一道菜的烹饪时间，也不代表它的味道，因为很多菜都含有这些配料。另一方面，可能存在一些成分的组合，表明这道菜将需要很长时间来烹饪，我们正在尝试挖掘这种模式。</a></p><p id="a528" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我将在下面总结我是如何使用这两种方法的:</p><h2 id="b0b8" class="na md iq bd me nj nk dn mi nl nm dp mm lo nn no mo ls np nq mq lw nr ns ms iw bi translated">一个热门编码:</h2><p id="2ba7" class="pw-post-body-paragraph lf lg iq lh b li nt ka lk ll nu kd ln lo nv lq lr ls nw lu lv lw nx ly lz ma ij bi translated">这种方法被广泛用作构建电影推荐算法的示例，其中我们将每部电影的类型编码为以下格式:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/ab6d7c0650364ce38998ef4295e49da1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*hzuRzN5fAf8uYbaC0dUqtw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">电影类型—一个热编码</p></figure><p id="8018" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我会做同样的事情，但不是一个热编码所有的成分，我只选择最“tf-idf重要”的成分烹饪时间。首先，我将配料栏分为3类烹饪时间:</p><pre class="kp kq kr ks gt mv mw mx my aw mz bi"><span id="e3bf" class="na md iq mw b gy nb nc l nd ne">quick_dish = df[df['cook_time'] == "quick"]['ingredients']<br/>medium_dish = df[df['cook_time'] == "medium"]['ingredients']<br/>slow_dish = df[df['cook_time'] == "slow"]['ingredients']</span></pre><p id="b17c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后我把它们变成一个长文档:</p><pre class="kp kq kr ks gt mv mw mx my aw mz bi"><span id="8f1a" class="na md iq mw b gy nb nc l nd ne"><strong class="mw ja">def</strong> one_doc(dishList):<br/>    string = ''<br/>    <strong class="mw ja">for</strong> dish <strong class="mw ja">in</strong> dishList:<br/>        string = string + " " + dish<br/>    <strong class="mw ja">return</strong> string<br/><br/>quick = one_doc(quick_dish)<br/>medium = one_doc(medium_dish)<br/>slow  = one_doc(slow_dish)</span></pre><p id="c9d9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">其输出如下所示:</p><pre class="kp kq kr ks gt mv mw mx my aw mz bi"><span id="4bcd" class="na md iq mw b gy nb nc l nd ne">' Maida flour, yogurt, oil, sugar Gram flour, ghee, sugar Flour, ghee, kewra, milk, clarified butter, sugar, almonds, pistachio, saffron, green cardamom Cashews, ghee, cardamom, sugar Milk, cottage cheese, sugar Yogurt, milk, nuts, sugar Refined flour, besan, ghee, powdered sugar, yoghurt, green cardamom Firm white pumpkin, sugar...</span></pre><p id="98ea" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后我用sklearn的TfidfVectorizer计算他们的TF-IDF分数:</p><pre class="kp kq kr ks gt mv mw mx my aw mz bi"><span id="9180" class="na md iq mw b gy nb nc l nd ne">vectorizer = TfidfVectorizer()<br/>vectors = vectorizer.fit_transform([quick, medium, slow])<br/>feature_names = vectorizer.get_feature_names()<br/>dense = vectors.todense()<br/>denselist = dense.tolist()<br/>pd.DataFrame(denselist, columns=feature_names)</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nz"><img src="../Images/58714a078db260f23b4e1c0e84de30f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UqK47IMjv47q368COK7QIQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">由此产生的tfidf数据帧“虚拟”</p></figure><p id="eada" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后，我提取了每个烹饪时间类型的“重要”成分，我在这里任意定义为每个文档中得分最高的60种成分，总共最多为180种成分(考虑到重复)，这是理想的，因为最初我不想有比观察更多的特征，但是您可以改变这个数字，并查看哪个阈值给出最高的准确性。</p><pre class="kp kq kr ks gt mv mw mx my aw mz bi"><span id="8ce9" class="na md iq mw b gy nb nc l nd ne">all_important_ingre = []<br/><strong class="mw ja">for</strong> index, item <strong class="mw ja">in</strong> enumerate(denselist):<br/>    scores = {feature: tfidf <strong class="mw ja">for</strong> feature, tfidf <strong class="mw ja">in</strong> <br/>              zip(feature_names, item)}<br/>    sorted_words = sorted(scores.items(), key=<strong class="mw ja">lambda</strong> x: x[1], <br/>                          reverse=<strong class="mw ja">True</strong>)<br/>    <strong class="mw ja">for</strong> word, score <strong class="mw ja">in</strong> sorted_words[:60]:<br/>        all_important_ingre.append(word)<br/><br/>top_ingre = list(set(all_important_ingre))</span></pre><p id="3b87" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我的all_important_ingre变量现在将存储所有不同的重要成分，我们准备创建一个虚拟编码数据帧:</p><pre class="kp kq kr ks gt mv mw mx my aw mz bi"><span id="d98e" class="na md iq mw b gy nb nc l nd ne">zeros = np.zeros((len(df_train), len(top_ingre)))<br/>dummies = pd.DataFrame(zeros, columns = top_ingre)</span><span id="941c" class="na md iq mw b gy nf nc l nd ne">ingredients = df_train['ingredients']<br/>sep_ingre = ingredients.apply(str.split, sep= ", ")<br/><strong class="mw ja">for</strong> i, dish <strong class="mw ja">in</strong> enumerate(sep_ingre):<br/>    dish = list(map(str.lower, dish))<br/>    indices = dummies.columns.get_indexer(dish)<br/>    dummies.iloc[i, indices] = 1<br/>dummies</span><span id="32dc" class="na md iq mw b gy nf nc l nd ne"><em class="ng"># joining the original dataframe</em><br/>df = df.join(dummies.add_prefix('ingre_'))</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oa"><img src="../Images/5b71d3a38d9b94eae8377c53dba7b238.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*63ZCa_fTUSMZqBUyGgBcTA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">最终表格的一部分如下所示</p></figure><p id="20c8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">我认为这种方法没有产生最佳结果的原因</strong>:除了有数百种成分和更少的观察值之外，当用PCA和t-SNE可视化时，我们的数据无法聚类成不同的组。似乎表明一种成分是否在一道菜里并不足以让算法学习和做出决定，因为我们的数据框架已经由除了<em class="ng"> prep_time </em>之外的所有分类变量组成(这也是为什么保留原始tf-idf分数——第二种策略——有助于模型更好地执行)。</p><h2 id="5fec" class="na md iq bd me nj nk dn mi nl nm dp mm lo nn no mo ls np nq mq lw nr ns ms iw bi translated">原始TFIDF分数</h2><p id="eaab" class="pw-post-body-paragraph lf lg iq lh b li nt ka lk ll nu kd ln lo nv lq lr ls nw lu lv lw nx ly lz ma ij bi translated">对于这种方法，我决定保留所有的配料，因为不像仅仅用二进制来表示一种配料是否包含在一道菜里，原始的tfidf分数已经表明该配料是否不重要。换句话说，在前面的方法中，配料X在菜肴A上的得分为1，如果它在两个菜肴中都有，则在菜肴B上的得分为1，这使得A中的X与B中的X相同；但是在这种方法中，X可能比B更能指示菜肴A的烹饪时间，因此X在A处的得分是0.6，而X在B处的得分可能只有0.1。此任务的过程类似于前面的方法，但更简单:</p><pre class="kp kq kr ks gt mv mw mx my aw mz bi"><span id="e877" class="na md iq mw b gy nb nc l nd ne">vectorizer = TfidfVectorizer()<br/>vectors = vectorizer.fit_transform(df_train['ingredients'])<br/>feature_names = vectorizer.get_feature_names()<br/>dense = vectors.todense()<br/>denselist = dense.tolist()<br/>dummies = pd.DataFrame(denselist, columns=feature_names)<br/>one_hot_encode_data = one_hot_encode_data.join(dummies.add_prefix('ingre_'))</span></pre><p id="3833" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">就是这样！</p><p id="0a3f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我建议两种方法都尝试一下，除非你的数据框架强烈表明，基于上述理由，一种方法会比另一种更好。简单地连接到前面的部分，这是我们继续使用KNNImputer为<em class="ng"> flavor_profile </em>估算缺失值的地方。</p><h1 id="e5f1" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">“模型构建”阶段:一些好的实践</h1><p id="25b6" class="pw-post-body-paragraph lf lg iq lh b li nt ka lk ll nu kd ln lo nv lq lr ls nw lu lv lw nx ly lz ma ij bi translated">这些是我在做这个项目之前不知道的事情，但是在了解它们之后，我为自己节省了很多工作！</p><ul class=""><li id="6b20" class="ob oc iq lh b li lj ll lm lo od ls oe lw of ma og oh oi oj bi translated">使用<a class="ae le" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html?highlight=cross%20val%20score#sklearn.model_selection.cross_val_score" rel="noopener ugc nofollow" target="_blank"><em class="ng">sk learn . model _ selection . cross _ val _ score</em></a><em class="ng"/>轻松对数据集进行<strong class="lh ja">交叉验证</strong>。它返回每一次折叠所达到的准确度分数(或者您选择的另一个度量)的列表。在我对模型的所有评估中，我使用交叉验证的分数(这个列表的平均值和标准偏差)。我的所有模型(逻辑回归、随机森林、多重贝叶斯、SVM)在应用于重采样数据集时都提高了10-20%。</li></ul><pre class="kp kq kr ks gt mv mw mx my aw mz bi"><span id="23ce" class="na md iq mw b gy nb nc l nd ne"><em class="ng"># example</em><br/>rf = RandomForestClassifier(random_state=0)<br/>scores = cross_val_score(rf, X, y, scoring='accuracy', cv=4, n_jobs=-1)<br/>print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))</span></pre><ul class=""><li id="c745" class="ob oc iq lh b li lj ll lm lo od ls oe lw of ma og oh oi oj bi translated">对于你的<strong class="lh ja">基线模型</strong>，使用<a class="ae le" href="https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html?highlight=dummy%20classifier#sklearn.dummy.DummyClassifier" rel="noopener ugc nofollow" target="_blank"><em class="ng">sk learn . dummy . dummy classifier</em></a><em class="ng">。</em>它使用简单的规则对数据进行分类，如使用最频繁的类别标签，或随机统一生成预测。</li></ul><pre class="kp kq kr ks gt mv mw mx my aw mz bi"><span id="24c1" class="na md iq mw b gy nb nc l nd ne">model = DummyClassifier(strategy='most_frequent')<br/>scores = cross_val_score(model, X, y, scoring='accuracy', cv=4, n_jobs=-1)<br/>print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))</span></pre><ul class=""><li id="d5f8" class="ob oc iq lh b li lj ll lm lo od ls oe lw of ma og oh oi oj bi translated"><strong class="lh ja">做错误分析</strong>:除了准确性，我们还应该考察f1的得分和召回率。最初，我只对类3进行了重新采样(因此在此之后，类1有131个示例，类3有131个示例，但类2只有84个)。在这个数据集上拟合模型，我观察到所有3个类的准确度和精确度都非常高。但是二班的召回率很差。进一步的检查表明，许多类别2的例子被预测为属于类别1。正是这种过度预测的行为让我意识到，相比其他班级，2班的代表性不足。通过修正重采样方法来修正这个问题，提高了类2的召回率，从而产生了一个总体上更好、更一致的模型。这是一个例子，说明研究你的模型所犯的错误是多么富有成效。</li></ul><p id="e593" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">除了参数调整，特征工程和特征选择是构建机器学习模型不可或缺的两个过程。特性工程应该总是在特性选择之前，特性选择在参数调整之前。在<strong class="lh ja">特征工程</strong>中，我经常会想到一些常见的任务，比如缩放/标准化特征、创建新列(我们预处理‘成分’列的方式也是特征工程)，以及更多特定于上下文的任务，比如处理不平衡的数据集，如下所述。对于<strong class="lh ja">特征选择</strong>，我使用了sklearn的<em class="ng">特征选择</em>模块，而<a class="ae le" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html" rel="noopener ugc nofollow" target="_blank">选择KBes </a> t是我最喜欢的技术之一。我在我构建的4 ML模型上尝试了“chi2”和“mutual_info”方法，每个模型都有我迄今为止拥有的3个数据集(一个是“前特征工程”，一个是“后特征工程，预重采样”，以及重采样数据集)。对于每一次拟合，我根据精度改变保留的特征数量(参数k ),并选择产生最佳结果的阈值。</p><h1 id="20ef" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">“特征工程”阶段:不平衡数据集</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/8baad5fdc8566fd6df6691f8e019ba77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ytl7kbWy9qHUhj3V"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@saltsup?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Piret Ilver </a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="f5ba" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">大大提高我的模型性能的一件事是在烹饪时间的3个类别中有一个平衡的数据集。目前，我有131道快菜，84道中菜，只有12道慢菜。<a class="ae le" href="https://imbalanced-learn.org/stable/references/index.html" rel="noopener ugc nofollow" target="_blank">不平衡学习</a>是一个建立在scikit-learn基础上的包，它提供了处理不平衡数据集的工具，如重采样、计算平衡精度分数等。这里，我使用一种称为SMOTENC的过采样策略对类2和类3进行过采样，以便它们具有与类1相同的观察结果。SMOTE是过采样的常用技术；SMOTENC构建于SMOTE之上，但可用于具有数值和分类特征的数据帧。</p><pre class="kp kq kr ks gt mv mw mx my aw mz bi"><span id="4d4f" class="na md iq mw b gy nb nc l nd ne">X_resampled, y_resampled = SMOTENC(categorical_features=range(1, <br/>11),random_state=0,sampling_strategy='minority').fit_resample(x_full2, y_full2)</span></pre><p id="d909" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">值得注意的是，虽然过采样有助于产生更好的结果，但它也有一些缺陷，因为它精确地复制了少数类的例子。因此，如果少数类中只有一个示例，那么在重新采样的数据帧中就会有数百个它的副本。这将导致严重的过度拟合。对多数类进行欠采样通常会更好。然而，由于我们的数据集非常小，这不是一个好策略。事实上，我的各种模型在3类中表现得非常好，但它与1类和2类的一些示例更加混淆。</p><h1 id="f6f7" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">“模型调整”阶段:堆叠模型</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ol"><img src="../Images/b4a699310f9680e0d9a1a1e9447875c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OIvF4pg3cGPvzOvw"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马库斯·斯皮斯克</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="d8c8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我通常会在对一些选定的模型进行参数调整后停下来，结束一天的工作。但是当我看到<a class="ae le" href="https://www.dummies.com/programming/big-data/data-science/10-ways-improve-machine-learning-models/" rel="noopener ugc nofollow" target="_blank">这篇关于改进ML模型的文章</a>时，我看到了堆叠模型，这是一种我以前没有尝试过的技术。堆叠是一种有效的集成方法，其中通过使用各种机器学习算法生成的预测被用作第二层学习算法<a class="ae le" href="https://blogs.sas.com/content/subconsciousmusings/2017/05/18/stacked-ensemble-models-win-data-science-competitions/" rel="noopener ugc nofollow" target="_blank">【1】</a>中的输入。我们构建堆叠分类器的方式类似于我们制作管道的方式，具有我们在之前的调优阶段已经实现的所有最佳参数:</p><pre class="kp kq kr ks gt mv mw mx my aw mz bi"><span id="ae03" class="na md iq mw b gy nb nc l nd ne">models = [<br/>('lr', LogisticRegression(C=2.976351441631316, max_iter=500) ),<br/>('svm', SVC(random_state=0, C=6.158482110660261) ),<br/>('rfc', RandomForestClassifier(n_estimators=130, random_state=0, max_depth=46))]</span><span id="2527" class="na md iq mw b gy nf nc l nd ne">level1 = LogisticRegression()</span><span id="420e" class="na md iq mw b gy nf nc l nd ne">stacking = StackingClassifier(estimators=models, final_estimator=level1, cv=5)<br/></span></pre><p id="3e84" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">之后，我们将在经过特征工程和特征选择的数据集上拟合模型。据观察，在单个模型上产生最佳结果的k值(即使所有模型具有相同的最佳k值)并不是组合模型的最佳k值。因此，我们也应该改变这个阈值，看看哪个k值表现最好。</p><h1 id="41ff" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">一些结束语…</h1><p id="3b58" class="pw-post-body-paragraph lf lg iq lh b li nt ka lk ll nu kd ln lo nv lq lr ls nw lu lv lw nx ly lz ma ij bi translated">最后，我的性能最好的模型是随机森林和SVM的堆叠模型，使用了mutual_info特征选择技术，达到了81%的交叉验证准确率。我认为用你的数据集和模型做大量的试验(和错误)是必要的。你测试的越多，你就越有把握获得最好的结果。众所周知，建立一个好的ML模型是一个探索和修正的循环，所以要有耐心，把任务分解，一次一个阶段地攻克它。我希望这篇文章能帮助你建立自己的项目，尤其是初学者。如果你做到了这一步，非常感谢你的阅读，祝你的项目好运！</p><p id="1ef4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这个笔记本的完整版本可以在这个Github repo中找到:</p><div class="om on gp gr oo op"><a href="https://github.com/irenechang1510/indian-cuisine-EDA" rel="noopener  ugc nofollow" target="_blank"><div class="oq ab fo"><div class="or ab os cl cj ot"><h2 class="bd ja gy z fp ou fr fs ov fu fw iz bi translated">GitHub-Irene Chang 1510/Indian-cuisine-EDA:进行EDA，建立模型预测是否…</h2><div class="ow l"><h3 class="bd b gy z fp ou fr fs ov fu fw dk translated">一个来自Kaggle的项目，探索印度菜肴中不同因素之间的关系，我对此的第一次分析…</h3></div><div class="ox l"><p class="bd b dl z fp ou fr fs ov fu fw dk translated">github.com</p></div></div><div class="oy l"><div class="oz l pa pb pc oy pd ky op"/></div></div></a></div><p id="8bf1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">请随时通过我的LinkedIn联系我，如果您有任何问题，我很乐意与您联系！</p><p id="6706" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[1] Güne，Funda。<em class="ng">为什么堆叠集合模型赢得了数据科学竞赛？</em>SAS数据科学博客，2017年。<a class="ae le" href="https://blogs.sas.com/content/subconsciousmusings/2017/05/18/stacked-ensemble-models-win-data-science-competitions/" rel="noopener ugc nofollow" target="_blank">https://blogs . SAS . com/content/潜意识音乐/2017/05/18/stacked-ensemble-models-win-data-science-competitions/</a></p></div></div>    
</body>
</html>