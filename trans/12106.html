<html>
<head>
<title>How to Leverage Neural Style Transfer to Create Stunning Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何利用神经风格转移来创建令人惊叹的图像</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-leverage-neural-style-transfer-to-create-stunning-images-c30eb4a9007a?source=collection_archive---------43-----------------------#2021-12-06">https://towardsdatascience.com/how-to-leverage-neural-style-transfer-to-create-stunning-images-c30eb4a9007a?source=collection_archive---------43-----------------------#2021-12-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="12f6" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">人工智能艺术</h2><div class=""/><div class=""><h2 id="0d24" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">会画图像的人工智能</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/ccc3345ba4613e1f3d7bb5f7d4a6f6b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fE--Nub-x4oZJ86F8zR0nQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">神经风格转移应用于阿尔及利亚足球运动员马赫雷斯的图像——由作者制作</p></figure><h1 id="a8bb" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">图像风格转移</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi lz"><img src="../Images/e4de803ee9a65e3d713da1386ee58529.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vw6IRNL-QqfQZIrzqdpb2A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片来自纸张[3]</p></figure><p id="0e3c" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">图像样式转移是一种可以应用于图像绘画的方法，其目标是从一个图像中提取样式，并将其应用于第二个图像，同时保留第二个图像的内容，就像上面的图像所示。</p><p id="1d5f" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">为了实现这一点，需要定义图像的风格。</p><p id="f54b" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">事实上，图像的风格与其纹理有很大关系。因此，通过使用纹理提取方法，我们本质上是在提取图像的风格。</p><p id="7ab8" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">这些方法被称为视觉纹理建模方法。这些方法有两种类型:</p><ul class=""><li id="07c5" class="mw mx it mc b md me mg mh mj my mn mz mr na mv nb nc nd ne bi translated">具有汇总统计的参数纹理建模</li><li id="7da1" class="mw mx it mc b md nf mg ng mj nh mn ni mr nj mv nb nc nd ne bi translated">基于马尔可夫随机场的非参数纹理建模</li></ul><p id="af5a" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">为了在图像上应用这种风格，我们可以使用图像重建技术。这些技术也有两种类型:</p><ul class=""><li id="b9aa" class="mw mx it mc b md me mg mh mj my mn mz mr na mv nb nc nd ne bi translated">基于图像优化的在线图像重建。</li><li id="a26c" class="mw mx it mc b md nf mg ng mj nh mn ni mr nj mv nb nc nd ne bi translated">基于模型优化的离线图像重建。</li></ul><p id="f732" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">卷积神经网络可用于视觉纹理建模和图像重建。</p><h1 id="cf0c" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">神经类型转移</h1><p id="de75" class="pw-post-body-paragraph ma mb it mc b md nk kd mf mg nl kg mi mj nm ml mm mn nn mp mq mr no mt mu mv im bi translated">在图像中进行风格转换的一种相当简单的方法是使用论文“<a class="ae np" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank"> <strong class="mc jd">艺术风格的神经算法</strong> </a>中描述的方法。</p><p id="1238" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated"><strong class="mc jd">你需要什么:</strong></p><ul class=""><li id="e375" class="mw mx it mc b md me mg mh mj my mn mz mr na mv nb nc nd ne bi translated">一个 CNN (VGG，盗梦空间等等)，它是在一个大的数据集(ImageNet)上预先训练的。</li><li id="72fe" class="mw mx it mc b md nf mg ng mj nh mn ni mr nj mv nb nc nd ne bi translated">一个你想样式化但保留其内容的图片，姑且称之为“<em class="nq">内容图片</em>”。</li><li id="ebc2" class="mw mx it mc b md nf mg ng mj nh mn ni mr nj mv nb nc nd ne bi translated">一个你想提取其风格的图像，姑且称之为“<em class="nq">风格图像</em>”。</li></ul><p id="0a3f" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated"><strong class="mc jd">怎么办:</strong></p><ul class=""><li id="04d6" class="mw mx it mc b md me mg mh mj my mn mz mr na mv nb nc nd ne bi translated">把这两张照片都传给 CNN。</li><li id="aa8e" class="mw mx it mc b md nf mg ng mj nh mn ni mr nj mv nb nc nd ne bi translated">从内容图像和样式图像中提取特征映射。</li><li id="72a3" class="mw mx it mc b md nf mg ng mj nh mn ni mr nj mv nb nc nd ne bi translated">要从样式图像中获取样式，您需要使用所谓的“Gram matrix”。这是一种奇特的说法:计算不同特征地图的平均值和相关性。</li><li id="a026" class="mw mx it mc b md nf mg ng mj nh mn ni mr nj mv nb nc nd ne bi translated">因此，特征图将代表图像的内容，而 Gram 矩阵将代表图像的风格。</li><li id="3b7f" class="mw mx it mc b md nf mg ng mj nh mn ni mr nj mv nb nc nd ne bi translated">接下来，你需要优化一个损失函数。这个损失函数的目标是使内容图像的样式尽可能接近样式图像的样式。</li><li id="45d1" class="mw mx it mc b md nf mg ng mj nh mn ni mr nj mv nb nc nd ne bi translated">最后，你基本上将一幅图像的风格转移到了另一幅图像上，同时保留了后一幅图像的内容。​</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/848fe3fa219041441333a4a6304f0096.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/0*U0k5LxUzhLnPMEwK"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者使用 NST 方法创作的狮子图像</p></figure><p id="dfda" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">上图是我用 Tensorflow 提供的教程中的<a class="ae np" href="https://www.tensorflow.org/tutorials/generative/style_transfer" rel="noopener ugc nofollow" target="_blank"> <strong class="mc jd">开源代码</strong> </a>创建的。</p><p id="d273" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">顺便说一句，如果你想学习如何使用 Tensorflow，那么请查看我的<a class="ae np" href="https://aifee.teachable.com/p/introduction-to-tensorflow-2-for-computer-vision" rel="noopener ugc nofollow" target="_blank"> <strong class="mc jd"> <em class="nq">免费 Tensorflow 课程</em> </strong> </a>，它专注于计算机视觉的深度学习。</p><h1 id="7618" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">实时神经类型转移</h1><p id="72ab" class="pw-post-body-paragraph ma mb it mc b md nk kd mf mg nl kg mi mj nm ml mm mn nn mp mq mr no mt mu mv im bi translated">从艺术的角度来看，前面的方法给出了一些很好的结果，但是缺点是它太长了。</p><p id="a6f6" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">每幅图像都必须经过一系列的迭代，提取两幅图像的内容和风格，然后进行优化，使一幅图像的风格接近另一幅图像的风格。</p><p id="4f84" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">由于这个障碍，文献中提出了另一种方法[2]。通过这种方法，有两个神经网络一起工作。</p><p id="4031" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">一个网络从风格图像中提取风格。另一个网络有两个输入:内容图像和前一个网络的输出。</p><p id="1af6" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">使用这种方法，整个系统在训练阶段从大数据集学习绘画风格的表示。</p><p id="f7b9" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">在测试时，网络直接从样式图像中提取样式，并将其应用于内容图像。不需要优化！</p><h1 id="ffaf" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">结论</h1><p id="addc" class="pw-post-body-paragraph ma mb it mc b md nk kd mf mg nl kg mi mj nm ml mm mn nn mp mq mr no mt mu mv im bi translated">AI 可以用于艺术造型。有一些深度学习方法可以将一幅图像的风格转移到另一幅图像，同时保留后者的内容。</p><p id="63ed" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">有不同的方法来实现这一点，其中一些需要在线优化。这意味着无论何时你想要设计一个图像，都必须有一个优化例程，这需要一些时间。</p><p id="1e16" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">其他方法使用离线优化，这使得神经风格转移系统能够学习如何提取图像的风格，并在训练过程中将其应用于新图像。在测试时，样式的转换很快。</p><h1 id="1bae" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">参考</h1><p id="4fc4" class="pw-post-body-paragraph ma mb it mc b md nk kd mf mg nl kg mi mj nm ml mm mn nn mp mq mr no mt mu mv im bi translated">[1] Leon A. Gatys，Alexander S. Ecker，Matthias Bethge，“<em class="nq">一种艺术风格的神经算法</em>”。</p><p id="df7c" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">[2] Golnaz Ghiasi，Honglak Lee，Manjunath Kudlur，Vincent Dumoulin，黄邦贤 Shlens，“<em class="nq">探索实时、任意神经艺术风格化网络的结构</em>”。</p><p id="bbf9" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">[3]永成静等，<em class="nq">神经风格迁移:综述</em>。</p><h1 id="9097" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">关于作者</h1><p id="f9a0" class="pw-post-body-paragraph ma mb it mc b md nk kd mf mg nl kg mi mj nm ml mm mn nn mp mq mr no mt mu mv im bi translated">我是一名机器学习工程师，致力于解决具有挑战性的计算机视觉问题。在<a class="ae np" href="https://www.linkedin.com/in/nour-islam-mokhtari-07b521a5/" rel="noopener ugc nofollow" target="_blank"> <strong class="mc jd"> LinkedIn </strong> </a>和<a class="ae np" href="https://twitter.com/NourIslamMo" rel="noopener ugc nofollow" target="_blank"> <strong class="mc jd"> Twitter </strong> </a> <strong class="mc jd"> </strong>上关注我的每日内容。此外，通过加入我的<a class="ae np" href="https://nourislam.ck.page/dc3e8b7e12" rel="noopener ugc nofollow" target="_blank"> <strong class="mc jd">时事通讯</strong> </a> <strong class="mc jd">，让这样的文章直接进入你的收件箱。</strong></p></div></div>    
</body>
</html>