<html>
<head>
<title>Limitations of Integrated Gradients for Feature Attribution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">特征属性综合梯度的局限性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/limitations-of-integrated-gradients-for-feature-attribution-ca2a50e7d269?source=collection_archive---------17-----------------------#2021-10-12">https://towardsdatascience.com/limitations-of-integrated-gradients-for-feature-attribution-ca2a50e7d269?source=collection_archive---------17-----------------------#2021-10-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="bee2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">可解释人工智能中流行的方法有严重的缺陷</h2></div><p id="561d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="http://proceedings.mlr.press/v70/sundararajan17a/sundararajan17a.pdf" rel="noopener ugc nofollow" target="_blank">集成梯度</a>是一种特征属性方法，具有几个吸引人的特性，非常适合神经网络。然而，它可能具有不广为人知的非直觉行为。使用具体的例子，我在这里证明，综合梯度并不具有我们希望一个理想的特征属性方法拥有的所有特征。理解这个工具的优点和缺点将有助于用户解释他们的结果，并且可能在将来构思更高性能的工具。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/0b76d6289bd76a45d72da3ab2e930fb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iClJMBTJEP1Sjv9m1ZULxQ.jpeg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">由<a class="ae lb" href="https://unsplash.com/@sldoug?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">史蒂夫·道格拉斯</a>在<a class="ae lb" href="https://unsplash.com/s/photos/rice-paddy?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="ac36" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">背景</h2><p id="b0b7" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">特征归因起源于博弈论。假设我们有一群玩家合作来获得一些奖励。假设每个玩家对团队的贡献不同，那么奖励应该如何在玩家之间分配呢？在机器学习的背景下，“奖励”类似于模型输出的分数，“玩家”类似于输入特征。也就是说，我们想知道每个特性占最终得分的多少。</p><p id="3f8c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Shapley提供了任何这样的系统都应该满足的一组公理，并表明只有一个可能的解决方案，现在被称为Shapley值，满足他的每个公理。他的解决方案依赖于这样的观察，即每个玩家的贡献取决于在场的其他玩家，因此当游戏由可能的玩家的不同子集进行时，他会考虑游戏的结果。回到机器学习中的特征属性问题，我们将不得不定义模型对特征子集而不是全部输入进行预测意味着什么。对于像神经网络这样的模型，如何做到这一点并不明显。由于这种概念上的限制，以及Shapley值的高计算成本，在实践中需要其他方法，而积分梯度是一种令人信服的替代解决方案。</p><p id="5e5d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下一节中，我将解释集成渐变，并讨论它所引入的“基线”输入的概念是如何与合作游戏联系在一起的。这样做，我们将能够评估积分梯度如何符合Shapley公理，并揭示一些奇怪的行为。</p><h2 id="51bd" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">集成渐变</h2><p id="b179" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">比方说，要将Shapley值应用于图像分类问题，我们必须定义神经网络对缺失像素的图像进行预测意味着什么(如果我们回想合作游戏，这类似于缺失玩家)。作者认为，我们可以将这些“缺失”的特征视为其值已被某种无信息基线所取代。在图像的上下文中，这可能意味着例如用灰色基线替换真实像素值。</p><p id="e378" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这一点上，积分梯度与Shapley方法大相径庭。它提供的解决方案有着完全不同的优点和缺点，了解全貌超出了本文的范围。出于我们的目的，我只想在这里简单描述一下什么是积分梯度，以及它是否以我们想要和期望的方式运行。</p><p id="d1f2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">设<em class="mq">f(</em><strong class="kh ir"><em class="mq">x</em></strong><em class="mq">)</em>代表我们的机器学习模型为输入向量<strong class="kh ir"> <em class="mq"> x </em> </strong>。然后对于基线，无信息输入<strong class="kh ir"><em class="mq">x’</em></strong>(想想全灰图像)，集成梯度提出以下特征属性:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mr"><img src="../Images/627a13faca568fa5ca6a400946e4885d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tbmcfYvtkmPm8saHqTyZiw.png"/></div></div></figure><p id="1ba1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中左手边代表赋予向量<strong class="kh ir"> <em class="mq"> x </em> </strong>的第<em class="mq"> i </em>个特征的特征属性。注意，在上面的等式中，可以理解的是，在沿着路径对其进行评估之前，先获取<em class="mq"> f </em>的梯度。利用微积分的基本定理，所有特征的属性之和等于<em class="mq">f(</em><strong class="kh ir"><em class="mq">x</em></strong><em class="mq">)</em>和<em class="mq">f(</em><strong class="kh ir"><em class="mq">x’</em></strong><em class="mq">)</em>之差。这是该方法背后的关键直觉，但它还有其他几个卖点。我鼓励读者查看原文以了解更多细节。</p><h2 id="1292" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">Shapley公理和积分梯度</h2><p id="1276" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">为了评估集成梯度满足Shapley的哪个公理，我们将从输入中删除要素解释为等同于用它们的基线值替换它们。为了简洁起见，我在这里只描述积分梯度满足的相关公理<em class="mq">而不是</em>；它还满足其他一些公理。</p><p id="0668" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">一致性</strong></p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ms"><img src="../Images/74136942cf5656d9cbf5cab558ec9481.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*47xIt6-cznC5GTRKFnrYyw.png"/></div></div></figure><p id="4561" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在上面的等式中，<em class="mq"> S </em>表示特征的子集，<em class="mq"> S </em>联合<em class="mq"> i </em>表示相同的子集，但是现在包括了特征<em class="mq"> i </em>，并且phi表示任何特征属性。这个公理说的是，如果对于每一个子集<em class="mq"> S，</em>特征<em class="mq"> i </em>对模型<em class="mq"> f </em>的影响<em class="mq">大于模型<em class="mq"> g，</em>那么<em class="mq"> i </em>在<em class="mq"> f </em>下应该比在<em class="mq"> g. </em>下得到更高的<em class="mq"> </em>本质上，更大的奖励应该意味着更大的属性。我个人并不认为这个公理的重要性非常直观<em class="mq">，</em>，但是它暗示了下面给出的另外两个公理，它们对于合理的特征归属是必不可少的。</em></p><p id="c471" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">对称性</strong></p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mt"><img src="../Images/2659dab49e99bdb378feb00adfd4af84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HObxNmZOX2vkmetOAXLtEA.png"/></div></div></figure><p id="546a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个公理强加了一个非常合理的条件，如果两个特征或玩家对每个可能的特征/玩家子集做出相同的贡献，他们必须得到相同的属性。如果一个玩家的贡献与另一个玩家相同，那么给他们更多的奖励是不公平的。正如我们将在后面看到的，事实上积分梯度不满足这个公理！</p><p id="8eef" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">无效效果</strong></p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mu"><img src="../Images/5382805fea4ae903ab1d2ea71ef039fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8kcP04NC5eVyqRPORxWl9Q.png"/></div></div></figure><p id="2572" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该公理表示，如果特征/玩家<em class="mq"> i </em>的存在对特征/玩家<em class="mq">、</em>的所有子集S的<em class="mq"> f </em>没有影响<em class="mq">、</em>，则该玩家的属性应该为零<em class="mq">。没有任何贡献的玩家不应该得到奖励<em class="mq">。</em></em></p><p id="71a0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下一节中，我提供了反例，表明积分梯度不符合这些公理。</p><h2 id="6e5a" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">反例</h2><p id="1c10" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated"><strong class="kh ir">一致性</strong></p><p id="1cae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">设<em class="mq"> f(x1，x2) = (x1)(x2)，g(x1，x2) = (x1)(x2)，</em>设基线<em class="mq"/><strong class="kh ir"><em class="mq">x '</em></strong><em class="mq">=(1，0)，</em>设输入为<em class="mq"/><strong class="kh ir"><em class="mq">x</em></strong><em class="mq">=(2，6/5)。</em>那么与模型<em class="mq"> f </em>的<em class="mq"> x1=2 </em>相关联的特征属性是:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mv"><img src="../Images/fba661887c881adfaa8dd222eef796b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*njqf6nBeY2EHHOCtvIZpAg.png"/></div></div></figure><p id="4532" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与模型<em class="mq"> g </em>的<em class="mq"> x1=2 </em>相关的特征属性为</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mw"><img src="../Images/928ab2a77ab92db6242918c37c7d4fb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6IgYccZXVIi1QLHdPBsVCA.png"/></div></div></figure><p id="5a4a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们采用输入特征和基线特征的所有组合，我们需要考虑的值是</p><p id="2a6a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mq"> f(1，0) = 0 </em></p><p id="5b6c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mq"> g(1，0) = 0 </em></p><p id="e9c0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mq"> f(2，0) = 0 </em></p><p id="cc70" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">g(2，0) = 0</p><p id="3acd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">f(1，6/5) = 36/25</p><p id="f807" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">g(1，6/5) = 6/5</p><p id="011d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">f(2，6/5) = 72/25</p><p id="27ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">g(2，6/5) = 12/5</p><p id="6ed2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于<em class="mq"> (x1，x2) </em>的每个组合，我们有f <em class="mq"> (x1，x2) ≥ g(x1，x2)。</em>然而根据积分梯度，f下输入<em class="mq"> (2，6/5) </em>的<em class="mq"> x1=2 </em>的特征属性为<em class="mq"> 36/75，</em>而g下为<em class="mq"> 6/10。</em>因此<em class="mq"> x1=2 </em>在<em class="mq"> f </em>下得到比<em class="mq">g</em>更小的特征属性，违反了一致性公理<em class="mq">。</em></p><p id="e772" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">对称</strong></p><p id="54df" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">设<em class="mq"> f(x1，x2) = sin(pi*x1)sin(2*pi*x2) </em>，基线为<strong class="kh ir"> <em class="mq"> x' </em> </strong> <em class="mq"> = (0，0) </em>，输入为<strong class="kh ir"> <em class="mq"> x </em> </strong> <em class="mq"> = (1，1) </em>。那么<em class="mq"> x1=1 </em>的特征属性为</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mx"><img src="../Images/88c1aacc72fa2004805fdf8e32cc6801.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WSKSwGSgFOJHqybePxNvpg.png"/></div></div></figure><p id="4881" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">并且<em class="mq"> x2=1 </em>的特征属性为</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi my"><img src="../Images/b7b8f390cbc4420233b19fd756624c5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Uk_OgQxamk37FqJWicmNA.png"/></div></div></figure><p id="98d2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要评估的输入有</p><p id="5eda" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">f(0，0) = 0</p><p id="8a24" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">f(1，0) = 0</p><p id="b137" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">f(0，1) = 0</p><p id="9ccf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">f(1，1) = 0</p><p id="490a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为f的值总是相同的，不管我们提供什么输入组合，根据对称公理<em class="mq"> x1=1 </em>和<em class="mq"> x2=1 </em>对于基线<strong class="kh ir"><em class="mq"/></strong><em class="mq">=(0，0) </em>必须得到相同的属性。然而<em class="mq"> IG(x1) = 4/3 </em>和<em class="mq"> IG(x2) = -4/3 </em>，违反了公理。</p><p id="ce60" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">无效效果</strong></p><p id="584e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">设<em class="mq"> f(x1，x2) = cos(2*pi*x1)( </em> x2)，再次设基线为<strong class="kh ir"><em class="mq">【x’</em></strong><em class="mq">=(0，0) </em>输入为<strong class="kh ir"> <em class="mq"> x </em> </strong> <em class="mq"> = (1，1) </em>。<em class="mq"> x1=1 </em>的特征属性为</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mz"><img src="../Images/f8a3842cba4cab6cf30c77e4e8b87e81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*teXwgWfn4RnBq_BxYZ6fhw.png"/></div></div></figure><p id="cd70" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意，这实际上等于在输入端评估的<em class="mq"> f </em>。这意味着(并且可以通过计算来确认)，所有的属性都给了<em class="mq"> x1 </em>，没有一个属性给了<em class="mq"> x2。</em>然而将<em class="mq"> x1 </em>从基线<em class="mq"> x1' = 0 </em>切换到输入<em class="mq"> x1 = 1 </em>对功能<em class="mq">没有影响！</em>这揭示了积分梯度不满足无效效应公理，这尤其令人不安。</p><p id="38e2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">讨论</strong></p><p id="4d16" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们研究了整合梯度在Shapley公理下的表现，将丢失的特征解释为基线值的替换。通过这样做，我们发现积分梯度违反了Shapley的一些公理，正因为如此，它有时给出与合理的特征归属方法不相称的答案。特别地，集成梯度可以将不同的属性分配给总是对模型具有完全相同影响的两个特征(违反对称性)，并且可以将正属性分配给对模型没有影响的特征(违反无效影响)。在试图解释他们的模型做出的决定之前，用户理解这些警告是很重要的。</p></div></div>    
</body>
</html>