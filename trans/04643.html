<html>
<head>
<title>OpenAI GPT leaking your data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">开放GPT泄露你的数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/openai-gpt-leaking-your-data-2dfb9e22c1b2?source=collection_archive---------25-----------------------#2021-04-21">https://towardsdatascience.com/openai-gpt-leaking-your-data-2dfb9e22c1b2?source=collection_archive---------25-----------------------#2021-04-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/7dc90941486560163cfa10ff5d0d9ae5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*FLcBRm6AcpAELWWG"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">汤姆·索多吉在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="69fe" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">我们如何从GPT-2中提取数据？</h2></div><p id="d718" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">第一部分:了解泄露GPT-2训练数据的方法</strong></p><p id="d913" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi lr translated"><span class="l ls lt lu bm lv lw lx ly lz di">在</span>这一系列围绕GPT的语言模型中，我们将重点阐述<a class="ae jd" href="https://arxiv.org/abs/2012.07805" rel="noopener ugc nofollow" target="_blank">从大型语言模型中提取训练数据</a></p><h2 id="88fa" class="ma mb jg bd mc md me dn mf mg mh dp mi le mj mk ml li mm mn mo lm mp mq mr ms bi translated"><strong class="ak">论文目标</strong></h2><p id="e07f" class="pw-post-body-paragraph kv kw jg kx b ky mt kh la lb mu kk ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">作者想证明他们可以从诸如GPT-2这样的语言模型中提取逐字数据。更有趣的是，他们解释说，他们可以从模型本身中逐字提取在训练数据中只出现过几次的内容。当然，如果你拥有一家公司，并且你正在使用客户的数据来训练一个语言模型，这可能是非常危险的。</p><blockquote class="my mz na"><p id="7fed" class="kv kw nb kx b ky kz kh la lb lc kk ld nc lf lg lh nd lj lk ll ne ln lo lp lq ij bi translated">用他们自己的话说，“该论文证明(…)，对手可以通过查询语言模型来执行训练<em class="jg">数据提取攻击</em>以恢复单个训练样本。”</p></blockquote><p id="4b14" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">谁愿意冒泄露私人信息的风险？</p><p id="a2b6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这听起来确实非常可怕。让我们来理解作者是如何攻击GPT-2并表面“记忆”数据的。为此，我们将遵循原始文件的流程，并注释掉任何感兴趣的元素。</p><p id="de60" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，让我们定义什么是语言模型。</p><h2 id="0919" class="ma mb jg bd mc md me dn mf mg mh dp mi le mj mk ml li mm mn mo lm mp mq mr ms bi translated"><strong class="ak">什么是语言模型？</strong></h2><p id="eb4d" class="pw-post-body-paragraph kv kw jg kx b ky mt kh la lb mu kk ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi lr translated"><span class="l ls lt lu bm lv lw lx ly lz di"/>浅层定义在于将语言模型视为能够推断给定一系列标记的下一个单词的条件概率分布的模型。例如，如果输入的一系列记号是“<strong class="kx jh"> <em class="nb">这只猫正在吃一只</em> </strong>”，那么<em class="nb"> LM </em>的目标是正确推断词汇表中所有可能单词的概率分布。我们想让<em class="nb"> LM </em>做的是给像“<strong class="kx jh"> <em class="nb">骨</em> </strong>”、“<strong class="kx jh"> <em class="nb">猫</em> </strong>”等词分配一个大的可能性。任何狗能吃的东西。同样，它应该给像“<strong class="kx jh"> <em class="nb">汽车</em> </strong>”、“<strong class="kx jh"> <em class="nb">月亮</em> </strong>”这样与狗能吃什么没有关系的词分配一个低可能性。</p><p id="6d0b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">既然我们理解了什么是语言模型，我们可以继续阅读这篇介绍了许多有趣概念的文章。在此之前，我们需要强调作者的目标。作者声称他们可以提取数据，并对他们可以提取的数据类型做了一些具体说明。为了理解这一点，我们需要说服自己，提取一些非常普通的东西，如“<em class="nb">巴拉克·奥巴马是美国总统</em>”，并不是很有趣。相反，我们的目标是在训练数据中不常见的实体，秘密实体。这就是有趣的事情开始的地方！</p><blockquote class="my mz na"><p id="a37f" class="kv kw nb kx b ky kz kh la lb lc kk ld nc lf lg lh nd lj lk ll ne ln lo lp lq ij bi translated">用他们自己的话说，“我们的攻击是可能的，即使上面的每个序列都包含在训练数据的<strong class="kx jh">一个文件</strong>中”。</p></blockquote><h2 id="41c4" class="ma mb jg bd mc md me dn mf mg mh dp mi le mj mk ml li mm mn mo lm mp mq mr ms bi translated"><strong class="ak">什么是语言模型记忆？</strong></h2><p id="892e" class="pw-post-body-paragraph kv kw jg kx b ky mt kh la lb mu kk ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">在阅读这篇论文之前，我不知道如何定义一个模型如何“记忆”一些东西，以及记忆具体指的是什么。从某种程度上来说，从人类的角度来看，记忆只是一种对过去已经看到的元素进行推断的能力，并且在推断的时候，就在现在。换句话说，如果你把你的脑力仅仅当作一本字典，那么你纯粹是在调用你的记忆，因为你不是在看每一句话的模式。</p><p id="6870" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">传统上，在ML中，我们的目标模型能够在与训练数据“相似”的数据上进行推断，但不能“完全”作为训练数据。因此，对一个模型的记忆可以被看作是负面的。</p><p id="f513" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，根据作者的说法，在语言建模中有许多方法来定义记忆。作为一个例子，他们展示了从GPT-2的邮政编码推断，这显然是记忆是一些抽象的形式。他们进一步形式化了对'<strong class="kx jh">记忆</strong>的定义，以便将其限制在被认为是“非预期”的情况下，例如客户数据。如果像我一样，下图似乎不能描述“记忆”的情况，让我为你澄清一下。从本质上来说，我们可以把“记忆”看作是缺乏基于训练期间所学的现有模式的推理。该模型在旧金山有很多地址的可能性很小，因此它不是基于学习的模式进行推理，而是基于某种形式的“记忆”。</p><figure class="ng nh ni nj gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nf"><img src="../Images/0896e81ce6e4943fce8a3030915373d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_K06cjlm33OU1PU22nuOlA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">GPT-2推断一个有效的邮政编码给定一个地址在三藩市。<a class="ae jd" href="https://github.com/NaxAlpha/gpt-2xy" rel="noopener ugc nofollow" target="_blank">自己试试吧！</a></p></figure><p id="4c59" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">意识到难以定义记忆对一个ML模型意味着什么，作者介绍了一些关键概念。第一个是关于k-Eidetic记忆法。</p><blockquote class="my mz na"><p id="d2cc" class="kv kw nb kx b ky kz kh la lb lc kk ld nc lf lg lh nd lj lk ll ne ln lo lp lq ij bi translated"><strong class="kx jh">定义2(k-本质记忆):</strong>一个字符串s被一个LM fθ记忆(对于k ≥ 1)如果s可从fθ提取且s出现在训练数据x中至多k个例子中:|{x ∈ X : s ⊆ x}| ≤ k</p></blockquote><p id="01db" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这一点非常重要，因为我们之前解释过，我们对普通的句子不感兴趣。换句话说，当<em class="nb"> k </em>很大时，比k很小时危害小。实际上，直觉上，人们不应该期望在训练数据的许多示例中出现客户地址。另外，值得一提的是，对于任何一个<em class="nb"> k，</em>记忆较长的字符串<em class="nb"> s </em>应该比较短的更有害。</p><blockquote class="my mz na"><p id="f685" class="kv kw nb kx b ky kz kh la lb lc kk ld nc lf lg lh nd lj lk ll ne ln lo lp lq ij bi translated"><strong class="kx jh">注</strong>:您可以将k值较低的k-Eidetic视为异常，对于这种异常，模型将很难找到与其他数据观察结果相结合的模式。换句话说，那些k低的k本质的例子，很可能是输入空间中的孤立点。</p></blockquote><h2 id="50e1" class="ma mb jg bd mc md me dn mf mg mh dp mi le mj mk ml li mm mn mo lm mp mq mr ms bi translated">👀正式的攻击目标是什么？</h2><p id="b8c6" class="pw-post-body-paragraph kv kw jg kx b ky mt kh la lb mu kk ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">既然我们已经介绍了记忆的关键概念，我们可以正式介绍作者攻击的目标。对手的目标是从模型中提取记忆的训练数据。人们可以通过特定提取的字符串的私密性来衡量攻击的强度。这与上面定义中的<em class="nb"> k </em>的值相关联。根据我们之前的评论，“更强的攻击总共提取更多的示例和具有更低的<em class="nb"> k值的示例”。</em></p><p id="104e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里，理解作者想要不加区别地提取训练数据而不特别关注数据的任何子集是很重要的。</p><p id="7a34" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">作者本质上对找出任何能被LM记住的东西感兴趣。为此，他们把重点放在了GPT-2上。</p><h1 id="0d64" class="nk mb jg bd mc nl nm nn mf no np nq mi km nr kn ml kp ns kq mo ks nt kt mr nu bi translated">🦊作者选择了什么方法来泄露GPT 2号的数据？</h1><p id="7a1f" class="pw-post-body-paragraph kv kw jg kx b ky mt kh la lb mu kk ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">作者采用了两步走的方法:</p><ol class=""><li id="6e39" class="nv nw jg kx b ky kz lb lc le nx li ny lm nz lq oa ob oc od bi translated">他们通过top-n采样由GPT-2生成文本。</li><li id="b93f" class="nv nw jg kx b ky oe lb of le og li oh lm oi lq oa ob oc od bi translated">他们预测哪些输出包含记忆的文本。</li></ol><p id="da0c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，让我们关注步骤1，该步骤包括应用top-n采样。</p><p id="db86" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，当GPT-2生成新的标记时，我们记得它在给定输入字符串的情况下，对词汇表中可能的下一个标记使用概率分布。这个概念可能会令人困惑，这里我们可以利用来自huggingface 的Patrick von Platen的精彩解释，他为我们提供了自动回归语言生成的清晰示例。</p><p id="29a6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">实际上，取样只是众多方法中的一种。下面显示了一个例子，其中在得到作为输入的令牌“<strong class="kx jh"><em class="nb"/></strong>”之后，通过迭代采样，自回归生成的输出是“<strong class="kx jh"><em class="nb">【The nice house</em></strong>”。</p><figure class="ng nh ni nj gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oj"><img src="../Images/4ebb74e546a780bfe98d4a5c42ab83d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*62JZH7mzT_ESUdT87oYaVA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">GPT-2可以根据相关概率生成{“尼斯”、“狗”、“汽车”}中给定“该”的任何单词。一旦我们基于它们的概率从先前的集合中取样，我们就得到“好的”。现在，我们有了“好的”作为输入。GPT-2然后确定在这个简化的集合中可能的记号的可能性(“女人”、“男人”、“房子”)。然后我们可以随机抽取一个令牌，得到“房子”。来自帕特里克的<a class="ae jd" href="https://huggingface.co/blog/how-to-generate" rel="noopener ugc nofollow" target="_blank">篇</a>。</p></figure><p id="409d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">自然，当基于标记的概率分布对词汇表进行随机采样时，会出现问题。例如，可能最终生成不期望的标记，尤其是在概率分布具有“接近”概率的相当“接近”的候选的设置中。解决这个问题的一个想法是过滤掉低可能性预测的标记。这就是<a class="ae jd" href="https://arxiv.org/pdf/1805.04833.pdf" rel="noopener ugc nofollow" target="_blank">范等人提出的top-n抽样(通常称为Top-K抽样)所采取的方向。铝(2018) </a>。</p><figure class="ng nh ni nj gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ok"><img src="../Images/2178d549f2203a4e95cdcf1524d3e6d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*08oWpk-SeGJpMoT6YIYmLg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">上述策略在采样阶段只保留蓝色令牌，过滤掉黑色令牌。我们看到，它成功地在第二个采样步骤中排除了相当奇怪的候选对象(“not”、“the”、“small”、“told”)。摘自帕特里克的<a class="ae jd" href="https://huggingface.co/blog/how-to-generate" rel="noopener ugc nofollow" target="_blank">篇</a>。</p></figure><p id="41f3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在我们更好地理解了Top-n采样指的是什么，让我们回到作者的策略。对于每次试验，他们通过top-n采样生成256个令牌。论文中给出的图表反映了设置为200，000的一些试验。换句话说，他们<strong class="kx jh">通过top-n采样从GPT-2生成200，000个字符串</strong>。</p><blockquote class="my mz na"><p id="4f44" class="kv kw nb kx b ky kz kh la lb lc kk ld nc lf lg lh nd lj lk ll ne ln lo lp lq ij bi translated">“我们希望通过根据模型分配的可能性进行采样，我们将对模型认为“非常可能”的序列进行采样，并且可能的序列对应于记忆的文本。具体来说，我们使用top-n策略对每次试验的256个令牌进行精确采样。”</p></blockquote><p id="8669" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从那些<strong class="kx jh"> 20万个</strong>样本中，他们只关注那些困惑度较高的。人们可以把一个序列的迷惑性看作是“LM<em class="nb">预测该序列中的记号有多好”的度量。换句话说，就像作者解释的那样，对于那些复杂度较低的序列，该模型对该序列并不感到非常“惊讶”,并且平均而言已经为序列中的每个后续标记分配了高概率。</em></p><figure class="ng nh ni nj gt is gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/9b294c39caebce901ac3e7069fe4a3b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*3pUP35JLWMqGgGG7xbh9SA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">序列x1，…，xn的迷惑性</p></figure><p id="3545" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，为什么他们认为“极有可能”的序列对应于记忆的文本？</p><p id="9eb4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">嗯，正如我们在上面看到的，困惑与每个标记被预测的可能性有关，给定过去的标记。对于那些低复杂度的过滤序列，该模型已经找到了具有高可能性的下一个记号。因此，在这种情况下，模型对预测非常有信心，这当然意味着它在训练期间已经看到了非常相似的一系列标记(过去的标记+新的标记)。</p><p id="cd4c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">作者随后解释说，如果你只是对最有可能的序列进行采样和过滤，这实际上并不起作用，因为你最终会获得k值很大的k-eidetic内容。例如，他们最终会获得数百份Vaughn Live的记忆用户指南副本。类似地，他们最终获得了麻省理工学院公共许可证的完整文本，这是github 上的一个流行文本文件。</p><blockquote class="my mz na"><p id="a596" class="kv kw nb kx b ky kz kh la lb lc kk ld nc lf lg lh nd lj lk ll ne ln lo lp lq ij bi translated">“(…)在我们生成的200，000个样本中，有数百个是记忆的沃恩Live用户指南的副本。”</p></blockquote><figure class="ng nh ni nj gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi om"><img src="../Images/7ce0d7bd9bf886f2c4569ae107eb0681.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6chpUOEhQ9oDB2J3CDhTOw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">沃恩直播，一个流媒体网站。GPT-2的攻击用上述方法拉它的用户指南。</p></figure><p id="f654" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">第二个问题是，这种攻击得到的内容“被分配了高可能性(低困惑度)，但那是<strong class="kx jh">没有记住的</strong>”。<strong class="kx jh"> </strong>那些都是误报。正如作者解释的那样，大多数误报包含“重复的”字符串。</p><p id="75fc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">值得知道的是，即使重复串出现在同一系列的记号中的这种例子是极不可能的，并且因此在训练数据中未被充分表示，“大的LMs经常错误地将高可能性分配给这种重复序列”。<em class="nb">(假设LM从两个第一重复序列中识别出模式，则第三重复序列可能尤其如此)</em></p><blockquote class="my mz na"><p id="a5d5" class="kv kw nb kx b ky kz kh la lb lc kk ld nc lf lg lh nd lj lk ll ne ln lo lp lq ij bi translated">注意:作者可以访问训练数据。因此，给定一个预测为正面的或记忆的示例，作者可以检查它是否确实在训练数据中。</p></blockquote></div><div class="ab cl on oo hu op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="ij ik il im in"><h2 id="b6cb" class="ma mb jg bd mc md me dn mf mg mh dp mi le mj mk ml li mm mn mo lm mp mq mr ms bi translated">✶Conclusion</h2><p id="d90b" class="pw-post-body-paragraph kv kw jg kx b ky mt kh la lb mu kk ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">总之，作者可以找到一种提取记忆数据的方法。然而，这第一种方法得到了<strong class="kx jh">大众记忆的例子</strong>。到目前为止，这些例子不会伤害任何公司。</p><p id="4ff4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，作者提出了一种提取<strong class="kx jh">相关记忆数据</strong>的改进过程，该过程稍微复杂一些。我们将在下一篇关于“GPT 2号泄露数据”的文章中讨论这个问题。</p></div><div class="ab cl on oo hu op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="ij ik il im in"><p id="7b1b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae jd" href="https://www.linkedin.com/in/mastafa-foufa-666a1a109/" rel="noopener ugc nofollow" target="_blank"><em class="nb">masta fa Foufa</em></a><em class="nb">在LinkedIn上。</em></p></div></div>    
</body>
</html>