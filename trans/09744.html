<html>
<head>
<title>Image Segmentation with Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">聚类图像分割</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-segmentation-with-clustering-b4bbc98f2ee6?source=collection_archive---------10-----------------------#2021-09-12">https://towardsdatascience.com/image-segmentation-with-clustering-b4bbc98f2ee6?source=collection_archive---------10-----------------------#2021-09-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="737a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">K均值和模糊C均值聚类的基本原理及其在图像分割中的应用</h2></div><p id="9cdb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我之前的文章中，我们概述了经典的图像分割方法。现在是时候检查基于人工智能的图像分割方法了，我们将从聚类开始。</p><p id="fdaf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在开始使用聚类进行图像分割之前，让我们先回顾一下“什么是聚类？”"如何用Python实现一个基本的聚类方法？"</p><p id="f88a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">什么是集群</strong></p><p id="c44d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">无非是把给定的数据按照相似性进行分组，最后得到不同的聚类。根据我们使用的聚类方法，我们对数据分组的方式会发生变化。让我们考察2种不同的最常用的图像分割类型:分割聚类和模糊聚类</p><p id="0387" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="lf">划分聚类</em> </strong></p><p id="830e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">分区聚类方法将数据细分为k个组，其中k是用户预定义的数字。对于<strong class="kk iu"> K-means聚类</strong>，哪一种是最流行的划分聚类方法</p><ol class=""><li id="501f" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld ll lm ln lo bi translated">我们选择数据中的<strong class="kk iu"> k个随机点</strong>作为聚类的<strong class="kk iu">中心，并通过查看该点与中心</strong>之间的L2距离将每个点分配给<strong class="kk iu">最近的聚类。</strong></li><li id="f6a9" class="lg lh it kk b kl lp ko lq kr lr kv ls kz lt ld ll lm ln lo bi translated">计算每个聚类的平均值，将该平均值指定为该聚类的新中心。</li><li id="aa0b" class="lg lh it kk b kl lp ko lq kr lr kv ls kz lt ld ll lm ln lo bi translated">将每个数据点重新分配到其最近的聚类中心。重复步骤2。</li></ol><p id="0a1d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该过程继续进行<strong class="kk iu">直到没有新的分配被执行</strong>(因此模型被收敛，没有什么可进一步进行的)<strong class="kk iu">或者对于给定的迭代次数</strong>。因此，K-means聚类是一种<strong class="kk iu">迭代</strong>方法，其中我们也可以确定迭代次数。</p><p id="a0c8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们可视化一些随机数据，对每个数据应用10次迭代的K均值聚类。</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="ae5b" class="md me it lz b gy mf mg l mh mi">from sklearn.cluster import KMeans<br/>from sklearn.datasets import make_blobs<br/>import numpy as np<br/>from matplotlib import pyplot as plt<br/>import cv2</span><span id="c9a5" class="md me it lz b gy mj mg l mh mi">""" Plot the data """</span><span id="d661" class="md me it lz b gy mj mg l mh mi">data = np.array([[1, 2], [1, 4], [1, 0],[10, 2], [10, 4], [10, 0]])<br/>data = np.array([[1, 5], [3, 1], [10, 3], [10, 2], [10, 1], [1, 0], [2, 15], [0.5, 4.9], [5, 3], [7, 13], [18, 18], [1.9, 0.5]]) <br/>data = np.random.randint(100, size=(2,2))</span><span id="a1df" class="md me it lz b gy mj mg l mh mi">centers = [[1, 1], [-1, -1], [1, -1]]<br/>data, _ = make_blobs(n_samples=10000, centers=centers, cluster_std=0.6)</span><span id="7f8e" class="md me it lz b gy mj mg l mh mi"># Plot the data<br/>plt.scatter(data[:,0],data[:,1])<br/>plt.xlabel('x'),plt.ylabel('y')<br/>plt.show()</span><span id="a122" class="md me it lz b gy mj mg l mh mi">""" Visualize K means for each iteration """</span><span id="7b50" class="md me it lz b gy mj mg l mh mi">""" create an empty list for each cluster, k is the cluster number """</span><span id="ef23" class="md me it lz b gy mj mg l mh mi">k = 2<br/>clusters = [[[0 for _ in range(2)] for _ in range(1)] for _ in range(k)]</span><span id="67bc" class="md me it lz b gy mj mg l mh mi">for i in range(k):<br/>    clusters[i].pop() #if we dont do that, additional [0,0] points will be stayed added in our data<br/>    <br/>""" Visualize each iteration. """</span><span id="0965" class="md me it lz b gy mj mg l mh mi">for i in range(1,10):<br/>    kmeans = KMeans(n_clusters=k, random_state = 0, max_iter=i).fit(data)<br/>    for index,data_point in enumerate(data):<br/>        clusters[kmeans.labels_[index]].append(list(data_point))<br/>        <br/>    for i in range(k):<br/>        clusters[i] = np.array(clusters[i])<br/>        plt.scatter(clusters[i][:,0],clusters[i][:,1])<br/>        clusters[i] = clusters[i].tolist() <br/>    plt.show()</span></pre><figure class="lu lv lw lx gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mk"><img src="../Images/28381c353dea7d03dd2677f483e10003.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CcgYg9F5Bukwef_laP4xzQ.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">前两个示例被分为2个组，第三个示例分为3个组“作者图片”</p></figure><p id="13a3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们看到，甚至在第一次迭代中，我们就获得了最终结果。因为数据非常小，初始聚类效果很好。让我们对下面随机生成的数据运行相同的代码，并将它们分成5个组。</p><p id="c45d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">centers = [[1，1]，[-1，-1]，[1，-1]] <br/> data，_ = make_blobs(n_samples=10000，centers=centers，cluster_std=0.6)</p><figure class="lu lv lw lx gt ml gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/e6bb8977f55526801635725578dfa706.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/1*pe726pBkod0F4I4c-rCNUg.gif"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">“作者提供的图像”</p></figure><p id="c3d7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们可以更好地看到在每次迭代中集群是如何更新的！</p><p id="95bf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">是时候对真实图像应用K-means聚类并获得分段输出了！</p><pre class="lu lv lw lx gt ly lz ma mb aw mc bi"><span id="1417" class="md me it lz b gy mf mg l mh mi">""" Image Segmentation """</span><span id="637b" class="md me it lz b gy mj mg l mh mi">img = cv2.imread("bird1.jpg", cv2.IMREAD_UNCHANGED) <br/>img = cv2.imread("birds2.jpg", cv2.IMREAD_UNCHANGED)  <br/>img = cv2.imread("peppers3.jpg", cv2.IMREAD_UNCHANGED)  <br/>vectorized = img.reshape((-1,3))</span><span id="7171" class="md me it lz b gy mj mg l mh mi">kmeans = KMeans(n_clusters=5, random_state = 0, n_init=5).fit(vectorized)</span><span id="4402" class="md me it lz b gy mj mg l mh mi">centers = np.uint8(kmeans.cluster_centers_)<br/>segmented_data = centers[kmeans.labels_.flatten()]<br/> <br/>segmented_image = segmented_data.reshape((img.shape))<br/>plt.imshow(segmented_image)<br/>plt.pause(1)</span></pre><figure class="lu lv lw lx gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mx"><img src="../Images/d68d657d2a5811946dbbe6b071f9b5e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8GEXSMN6FyVNBWNBXVAA7A.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">“作者提供的图像”</p></figure><figure class="lu lv lw lx gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ca"><img src="../Images/d27dc999d8710033687b10dda6855bfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0-3CJlPQqkSv0CtZ0m6EJA.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">“作者提供的图像”</p></figure><figure class="lu lv lw lx gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi my"><img src="../Images/7ccd20b7d939d81614547dac4ed1c11b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*STQrHldd2f5kKdPziz8pHA.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">“作者提供的图像”</p></figure><p id="5033" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以意识到我没有使用那次确定迭代次数参数的<strong class="kk iu"> max_iter </strong>。我将这一决定留给模型，这样当聚类中没有发生变化时，分割就停止了。另一方面，<strong class="kk iu"> n_init </strong>参数决定了在初始步骤中用不同的随机聚类中心完成多少次不同的试验。该算法选择最佳拟合，这给出了最佳分割。</p><p id="979a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以意识到随着<strong class="kk iu">增加k </strong>，结果<strong class="kk iu">会变得更好</strong>和更详细！</p><p id="ea2a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是该节中使用的代码的<a class="ae le" href="https://github.com/YCAyca/Image-Segmentation/tree/main/Clustering" rel="noopener ugc nofollow" target="_blank"><strong class="kk iu">githu</strong></a><strong class="kk iu">b</strong>链接:</p><p id="cb36" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">模糊聚类</strong></p><p id="d701" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">模糊聚类是一种<strong class="kk iu">硬</strong>聚类类型，而划分聚类被称为<strong class="kk iu">软</strong>。其原因是，在划分聚类中，<strong class="kk iu"> 1个数据点可能仅在1个聚类</strong>中，在模糊聚类中，我们有每个聚类的数据点的<strong class="kk iu">概率，并且它们可能<strong class="kk iu">属于该概率水平的任何聚类。</strong></strong></p><p id="e425" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们来看看最常见的模糊聚类类型<strong class="kk iu">模糊C均值聚类</strong>，看看如何计算点的概率、聚类的中心等。[1]</p><ol class=""><li id="ccd1" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld ll lm ln lo bi translated">随机初始化概率矩阵。因此，为每个数据-聚类对分配权重，这是指数据x位于聚类C中的概率。</li><li id="a319" class="lg lh it kk b kl lp ko lq kr lr kv ls kz lt ld ll lm ln lo bi translated">计算聚类的中心(质心)，</li><li id="d932" class="lg lh it kk b kl lp ko lq kr lr kv ls kz lt ld ll lm ln lo bi translated">根据新的聚类中心计算新的概率。</li><li id="8ab7" class="lg lh it kk b kl lp ko lq kr lr kv ls kz lt ld ll lm ln lo bi translated">重复2。第三。步进，直到中心不变或给定迭代次数</li></ol><p id="a666" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们想象一个例子:</p><p id="dcbd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们有4个数据点p1、p2、p3、p4二维，所以我们有这些点的x和y坐标，我们想把它们分成两个组。</p><ol class=""><li id="5bc0" class="lg lh it kk b kl km ko kp kr li kv lj kz lk ld ll lm ln lo bi translated">我们随机初始化权重矩阵:</li></ol><figure class="lu lv lw lx gt ml gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/05df8182e4134b8d174fc21c04f6778f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*kOCW1aQtGhCjrWXQouFvZw.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">“作者提供的图像”</p></figure><p id="0b4a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.我们根据初始概率用下面的公式计算聚类的质心:</p><figure class="lu lv lw lx gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi na"><img src="../Images/c3af92c03bdfe105dbd70e36a17ee99f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z5xriT3F-ZMbnYArp4b41w.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">“作者提供的图像”</p></figure><p id="dc54" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意<strong class="kk iu">模糊参数</strong>是我们应该选择的，就像聚类数一样，它可以在1 &lt; m &lt; ∞之间选择</p><p id="d16a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们通过选择<strong class="kk iu"> m = 2 </strong>将公式应用于我们的示例案例:</p><figure class="lu lv lw lx gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nb"><img src="../Images/e79a2e36c4d436fe23c1732cc38f25bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_hnJNJsx-gQS1CYEGVO7RQ.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">“作者提供的图像”</p></figure><p id="1fcd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为我们有2D点，所以群集的中心也是2D。所以我们用我们点的x坐标计算C1x(第一个聚类的x坐标)，用我们点的y坐标计算C1y(第一个聚类的y坐标)。</p><p id="2904" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们对C2也应用同样的公式时，我们得到如下结果</p><figure class="lu lv lw lx gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nc"><img src="../Images/59f3ac5890e4500beca63849c2f5e007.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*twvfsA26igi07IopJGMfhw.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">“作者提供的图像”</p></figure><p id="0f8f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们得到了我们的聚类中心，现在是时候根据新的聚类中心来计算点的概率了。</p><p id="106f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3.我们使用以下公式计算新的概率——权重:</p><figure class="lu lv lw lx gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nd"><img src="../Images/696606d106f0b30e3a72b8b32d703fe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SChn--npyIKU7VBFNneDGQ.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">“作者提供的图像”</p></figure><p id="775e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">别忘了在我们的例子中m = 2，所以1/m-1 = 1。</p><figure class="lu lv lw lx gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ne"><img src="../Images/adc06db40a7fe0df5a9feb1c61202cf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9GmCQG0skjxTkSbCHhmuwg.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">“作者提供的图像”</p></figure><figure class="lu lv lw lx gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nf"><img src="../Images/b52b45f20751fcc6e4853a04b9bd3b1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RMXSJQp4k28Elm32pIBBkQ.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">“作者提供的图像”</p></figure><p id="63d7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">诸如此类！我没有计算每个点和聚类的权重，而是想手动显示每个步骤的逻辑。</p><p id="f702" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我希望大家清楚模糊C均值聚类的基本逻辑和应用。现在是时候做一些实验并检查结果了。</p><figure class="lu lv lw lx gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ng"><img src="../Images/561db65854c9b9f8646a295e92353620.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pdzfZTSBR34e3ZjXozkwCQ.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">“作者提供的图像”</p></figure><p id="6f2c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">选择模糊参数m太大会导致结果失真。我们再次看到，随着聚类数的增加，我们获得了更详细和更好的分割结果。</p><p id="857c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您使用Linux，您可以尝试使用PyPI [1]中的fuzzy c means模块，我在windows上安装它时遇到了一些问题，尽管我按照建议使用了pip install fuzzy-c-means[windows]命令。感谢[2]中的fuzzy c意味着从头开始实现，我在准备最后一部分时使用了它。</p><p id="e1b6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在图像分割与神经网络部分再见！👐</p></div><div class="ab cl nh ni hx nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="im in io ip iq"><p id="65d3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[1]<a class="ae le" href="https://pypi.org/project/fuzzy-c-means/" rel="noopener ugc nofollow" target="_blank">https://pypi.org/project/fuzzy-c-means/</a></p><p id="239e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2]<a class="ae le" href="https://github.com/jeongHwarr/various_FCM_segmentation/blob/master/FCM.py" rel="noopener ugc nofollow" target="_blank">https://github . com/jeongHwarr/variable _ FCM _ segmentation/blob/master/FCM . py</a></p><p id="cbb1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，所有用于不同代码部分实验的图片都来自unsplash.com</p></div></div>    
</body>
</html>