<html>
<head>
<title>Protecting your Money: Detecting Credit Card Fraud with ML/DL</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">保护您的资金:使用ML/DL检测信用卡欺诈</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/protecting-your-money-detecting-credit-card-fraud-with-ml-dl-2c4a9b9a0779?source=collection_archive---------9-----------------------#2021-09-30">https://towardsdatascience.com/protecting-your-money-detecting-credit-card-fraud-with-ml-dl-2c4a9b9a0779?source=collection_archive---------9-----------------------#2021-09-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ac52" class="pw-subtitle-paragraph jv ip iq bd b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km dk translated">利用机器学习和深度学习检测信用卡欺诈，同时处理不平衡数据</h2></div><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi kn"><img src="../Images/0d8a42628b282e4ed4a7ade83a32c210.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*L9COBx9nR-rXBsW3"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">瑞安出生于<a class="ae ld" href="https://unsplash.com/photos/x8i6FfaZAbs" rel="noopener ugc nofollow" target="_blank">Unplash</a>的照片</p></figure><p id="e2f1" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">2019年，全球信用卡欺诈损失达<strong class="lg ir">286.5亿美元<em class="ma"/></strong>。正如商户风险委员会(Merchant Risk Council)首席执行官朱莉·弗格森(Julie Ferguson)所说，“如果一家小单店企业或一家餐馆突然亏损1万美元，这可能就是为该公司发工资和不发工资的区别。”许多公司，如VISA，正在寻找基于人工智能的解决方案来解决这个问题。使用ML检测信用卡欺诈有许多好处，例如更多:</p><ul class=""><li id="73e2" class="mb mc iq lg b lh li lk ll ln md lr me lv mf lz mg mh mi mj bi translated"><strong class="lg ir">高效</strong>数据处理</li><li id="5688" class="mb mc iq lg b lh mk lk ml ln mm lr mn lv mo lz mg mh mi mj bi translated"><strong class="lg ir">模式识别</strong></li><li id="84fc" class="mb mc iq lg b lh mk lk ml ln mm lr mn lv mo lz mg mh mi mj bi translated"><strong class="lg ir">准确的</strong>预测</li></ul><p id="e525" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">本文将演示不同的机器学习方法来检测信用卡欺诈。它们包括:</p><ul class=""><li id="9857" class="mb mc iq lg b lh li lk ll ln md lr me lv mf lz mg mh mi mj bi translated">随机森林分类器</li><li id="422d" class="mb mc iq lg b lh mk lk ml ln mm lr mn lv mo lz mg mh mi mj bi translated">逻辑回归</li><li id="3ab1" class="mb mc iq lg b lh mk lk ml ln mm lr mn lv mo lz mg mh mi mj bi translated">神经网络</li></ul><p id="b79f" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">您可以在此<a class="ae ld" href="https://github.com/shayaf84/Credit_Card_Fraud_Detection" rel="noopener ugc nofollow" target="_blank">链接</a>处找到该项目的GitHub存储库。</p><h1 id="2f4c" class="mp mq iq bd mr ms mt mu mv mw mx my mz ke na kf nb kh nc ki nd kk ne kl nf ng bi translated">检索数据</h1><p id="df55" class="pw-post-body-paragraph le lf iq lg b lh nh jz lj lk ni kc lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">该项目使用来自kaggle.com“信用卡欺诈检测”数据集的数据。您可以通过<a class="ae ld" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank"/>链接访问。出于这个项目的目的，我下载了这个文件，并把它放在我的谷歌驱动器中，因为这个文件很大。如果驱动器安装了谷歌合作实验室，就可以很容易地访问它。由于信用卡欺诈依赖于对敏感数据的处理，原始数据无法显示。因此，使用主成分分析(PCA)掩蔽了28个特征(V1 — V28)。只有两个变量没有被转换:</p><ul class=""><li id="ff4e" class="mb mc iq lg b lh li lk ll ln md lr me lv mf lz mg mh mi mj bi translated"><strong class="lg ir">时间</strong>“表示当前事务和数据集中第一个事务之间经过的秒数</li><li id="4ae8" class="mb mc iq lg b lh mk lk ml ln mm lr mn lv mo lz mg mh mi mj bi translated"><strong class="lg ir">金额</strong>，表示交易总额。</li></ul><p id="31b9" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">响应变量<strong class="lg ir"> Class </strong>有两个值:</p><ul class=""><li id="c18f" class="mb mc iq lg b lh li lk ll ln md lr me lv mf lz mg mh mi mj bi translated">1 .办理诈骗案件</li><li id="b93f" class="mb mc iq lg b lh mk lk ml ln mm lr mn lv mo lz mg mh mi mj bi translated">非欺诈案例为0</li></ul><h1 id="a98e" class="mp mq iq bd mr ms mt mu mv mw mx my mz ke na kf nb kh nc ki nd kk ne kl nf ng bi translated">设置环境和上传数据</h1><p id="f5d7" class="pw-post-body-paragraph le lf iq lg b lh nh jz lj lk ni kc lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">我们将从导入我们将使用的关键包开始，并安装我们的谷歌驱动器，这样我们就可以上传我们的数据集！文件路径将根据存储数据集的文件夹而有所不同。</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="c8e2" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们将使用的库有:</p><ul class=""><li id="fbfb" class="mb mc iq lg b lh li lk ll ln md lr me lv mf lz mg mh mi mj bi translated">Numpy</li><li id="8601" class="mb mc iq lg b lh mk lk ml ln mm lr mn lv mo lz mg mh mi mj bi translated">熊猫</li><li id="7568" class="mb mc iq lg b lh mk lk ml ln mm lr mn lv mo lz mg mh mi mj bi translated">Seaborn和Matplotlib</li><li id="17d3" class="mb mc iq lg b lh mk lk ml ln mm lr mn lv mo lz mg mh mi mj bi translated">不平衡-学习，Scikit-学习，Tensorflow</li><li id="290c" class="mb mc iq lg b lh mk lk ml ln mm lr mn lv mo lz mg mh mi mj bi translated">谷歌。Colab(上传文件)</li></ul><h1 id="0dd5" class="mp mq iq bd mr ms mt mu mv mw mx my mz ke na kf nb kh nc ki nd kk ne kl nf ng bi translated">探索性数据分析</h1><p id="b06b" class="pw-post-body-paragraph le lf iq lg b lh nh jz lj lk ni kc lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">让我们分析我们的数据！我们可以从查看数据集的前五行开始，并检索其形状。</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi no"><img src="../Images/b9a46cb3a7faaa3d0a17ad92f5070ccf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m1-jEqvZzFPDOxjSCBzkLQ.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">作者形象</p></figure><p id="1c3a" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">数据集中有<strong class="lg ir"> 31列</strong>，其中28列是PCA (V1 — V28)的输出，以及数量和时间的值。我们的响应变量是class，0表示没有欺诈，1表示有欺诈。数据的形状告诉我们有284807个条目和31列。</p><p id="da75" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">接下来，我们可以创建一个Seaborn countplot来可视化这两个类的分布。</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi np"><img src="../Images/b6a99724cfc484c80b99a034a5a61855.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z9gABYRpAj2P7OeDmZNYHw.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">作者图片</p></figure><p id="9f05" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">呃……这确实是一个两难的选择。如你所见，我们的数据集是<em class="ma">高度</em>不平衡的，因为我们绝大多数的数据都在0类中。这是个问题，因为<strong class="lg ir">我们必须给两个班的模特同等的训练机会</strong>。</p><p id="65c2" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">接下来，我们可以绘制两个类的数量和时间分布图。我们可以通过索引数据帧来提取我们想要绘制的列。此外，我们可以使用matplotlib中的不同函数来调整字体大小、图形大小和轴标题，如下所示。</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nm nn l"/></div></figure><div class="ko kp kq kr gt ab cb"><figure class="nq ks nr ns nt nu nv paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/8828a9cb7e5d0ef66307eeb26bec1d35.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*SNseWDLIJkKcEfIIjYWx2w.png"/></div></figure><figure class="nq ks nw ns nt nu nv paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/fa046c9761f69ff481d753be8ce9d813.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*HE4NWGdl6D5-Dj6HJncWxw.png"/></div><p class="kz la gj gh gi lb lc bd b be z dk nx di ny nz translated">作者图片</p></figure></div><p id="47af" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">从左边的图中，我们可以看到欺诈性分录往往具有较低的金额值，而非欺诈性分录。同样值得注意的是，非欺诈金额的值分布不均匀，因为该变量的较高值之间存在较大的间隔。</p><p id="f08f" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">就时间而言，这两个类别之间似乎没有区别，因为这些值在欺诈性和非欺诈性条目中是一致的。这是有意义的，因为如前所述，时间特性表示从第一个事务开始经过的秒数。因此，时间变量将继续增加。假设欺诈性交易在时间上并非都与非欺诈性交易相隔离，它们都将具有连续的时间值。</p><p id="3455" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">另一个我们可以用来分析所有变量之间关系的技术，包括PCA转换的变量，是建立一个相关矩阵！</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi oa"><img src="../Images/39f16aeabba415eedaae7b4e7e01e0e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-O1EcBaDeERI5xWil6po2Q.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">作者图片</p></figure><p id="208b" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">从这个相关性矩阵中，我们可以看到数据集中的特征之间没有<strong class="lg ir">主要<em class="ma">相关性</em>和</strong>。大多数关系都在-0.2到0.2之间。尽管如此，还是有一些例外，特别是在分析数量特性、V7和V20之间的相关性时。</p><p id="4d73" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">另一个观察是特性和类之间的最小关系。这可以归因于数据的不平衡性质，这可以淡化某些特征的重要性。</p><h1 id="7efd" class="mp mq iq bd mr ms mt mu mv mw mx my mz ke na kf nb kh nc ki nd kk ne kl nf ng bi translated">分割和标准化我们的数据集</h1><p id="75b8" class="pw-post-body-paragraph le lf iq lg b lh nh jz lj lk ni kc lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">现在让我们放弃时间特性。这与分类无关，只是记录时间…然后，我们可以将数据分为训练和测试值，测试规模为30%<strong class="lg ir"/>。</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi no"><img src="../Images/b9a46cb3a7faaa3d0a17ad92f5070ccf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m1-jEqvZzFPDOxjSCBzkLQ.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">作者图片</p></figure><p id="33c8" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">如果查看数据，您会发现金额值明显高于其他功能的条目。例如，在data.head()的第一个条目中，amount值是149.62，这与V1的值(大约为-1.36)有很大的不同。为了解决这个问题，我们将使用<strong class="lg ir">标准定标器。</strong>通过缩放变量，模型的效率会提高。</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nm nn l"/></div></figure><h1 id="099d" class="mp mq iq bd mr ms mt mu mv mw mx my mz ke na kf nb kh nc ki nd kk ne kl nf ng bi translated">用边界SMOTE平衡数据</h1><p id="7ea2" class="pw-post-body-paragraph le lf iq lg b lh nh jz lj lk ni kc lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">现在，我们将需要平衡我们的数据，以确保模型对两个类都有足够的暴露度！这确保了模型不会偏向非欺诈性值，因为目前有超过280，000个条目的类别为0，而只有492个欺诈性值。</p><p id="9229" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">要改变类1中值的数量，有两种可能的方法:随机欠采样(减少多数类的条目数量)和合成过采样(为少数类合成生成新条目)。因为我们希望为我们的模型提供尽可能多的数据，所以我们将使用一种称为<a class="ae ld" href="https://sci2s.ugr.es/keel/pdf/specific/congreso/han_borderline_smote.pdf" rel="noopener ugc nofollow" target="_blank"> Borderline-SMOTE </a>的技术(Borderline Synthetic Minority over sampling Technique)。使用Borderline-SMOTE而不是SMOTE的原因是，它综合生成少数类<strong class="lg ir">中不同元素之间的数据，同时忽略异常值</strong>。离群点可以定义为比少数点邻近更多多数点的特征。</p><p id="7327" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">下面是应用边界平滑的代码。仅平衡训练数据很重要，因为测试系列必须反映真实世界的现场数据。</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nm nn l"/></div></figure><div class="ko kp kq kr gt ab cb"><figure class="nq ks ob ns nt nu nv paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/a1d9a93ce5b88140d449cd203e7c46e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*bGtFe3C007ZG7ShTbsP4fw.png"/></div></figure><figure class="nq ks oc ns nt nu nv paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/301e0a7d7dc193d1eae6a8b61eac3aed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*k-mCyGlCUcoIsfr5fzgV_w.png"/></div><p class="kz la gj gh gi lb lc bd b be z dk od di oe nz translated">(左)过采样前的训练数据分布；(右)过采样后的数据分布</p></figure></div><h1 id="2613" class="mp mq iq bd mr ms mt mu mv mw mx my mz ke na kf nb kh nc ki nd kk ne kl nf ng bi translated">机器学习模型</h1><p id="0bf2" class="pw-post-body-paragraph le lf iq lg b lh nh jz lj lk ni kc lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">我们的数据集现在平衡了！这确保了我们的模型可以从每个类中看到相同数量的元素。我们可以建立机器学习模型进行分类。将使用两种模型:</p><ul class=""><li id="d11e" class="mb mc iq lg b lh li lk ll ln md lr me lv mf lz mg mh mi mj bi translated"><strong class="lg ir">随机森林</strong></li><li id="1417" class="mb mc iq lg b lh mk lk ml ln mm lr mn lv mo lz mg mh mi mj bi translated"><strong class="lg ir">逻辑回归</strong></li></ul><p id="b4a6" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在我们开始构建模型之前，定义我们将使用的性能指标是至关重要的。由于我们的验证数据是不平衡的，<strong class="lg ir"> </strong>如果模型每次都预测多数类，那么我们的模型将获得<strong class="lg ir">显著偏斜的准确度，而不考虑少数类。</strong>因此，我们将使用精确度、召回率和F1分数。</p><p id="5a05" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">首先，我们将建立我们的随机森林模型，有15个估计量。请记住，由于数据集的大小，它将需要几分钟来运行。</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi of"><img src="../Images/ff6da0124d8b23496e0d34de17aaec06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r7G-Acj6tNObbiAENZmyAw.png"/></div></div></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi og"><img src="../Images/25d335d627ea401baaf24159caca3502.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*SshpFP0Dx8pkBbmxiYNXCw.png"/></div><p class="kz la gj gh gi lb lc bd b be z dk translated">四舍五入到两位小数</p></figure><p id="3e01" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">太好了！我们的模型具有很高的精确度和召回率，这意味着它选择的假阳性(精确度)或假阴性(召回率)没有真阳性多！正因为如此，F1的分数也很高。</p><p id="f52e" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">其次，我们还将建立一个逻辑回归模型来解决这个分类问题。</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nm nn l"/></div></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi oh"><img src="../Images/ef58070a48b6af3b01c924bd9b543767.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sI4eExo6OPcg3AS5Z2MkWQ.png"/></div></div></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/5549e9aef22c8581bcc2e38cf2241718.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*6SDWrmma7sD0bzumgk0anw.png"/></div><p class="kz la gj gh gi lb lc bd b be z dk translated">四舍五入到两位小数</p></figure><p id="89e8" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">嗯……在这种情况下，虽然召回率很高(模型选择的真阳性比假阴性多)，但精确度却很低，这意味着模型选择的假阳性比真阳性多。因此，F1分数下降。</p><p id="2157" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在比较这两个模型时，评估我们用来比较它们的指标是很重要的。我们的<strong class="lg ir">逻辑回归</strong>模型有一个<strong class="lg ir">更高的召回</strong>(大约5%)，而<strong class="lg ir">随机森林</strong>分类器有一个<strong class="lg ir">更高的精确度</strong>(大约78%)。因此，就F1分数而言，它是精确度和召回率的调和平均值，<strong class="lg ir">随机森林模型</strong>表现更好。</p><h1 id="a801" class="mp mq iq bd mr ms mt mu mv mw mx my mz ke na kf nb kh nc ki nd kk ne kl nf ng bi translated">神经网络</h1><p id="334f" class="pw-post-body-paragraph le lf iq lg b lh nh jz lj lk ni kc lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">最后，我们还将制作一个具有两个隐层的神经网络来解决这个分类问题。</p><p id="b8aa" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在创建我们的模型之前，定义我们将使用的超参数是很重要的。以下是我使用过的方法，但是你可以随意调整它们，以达到更好的效果。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi oj"><img src="../Images/b85cc0e4d7bf50065fb6ca68a4f30194.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gJoNhcqMPnMJB5SrRbLnHg.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">我们的神经网络——作者图片</p></figure><p id="d64a" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">如图所示，我们有:</p><ul class=""><li id="4db4" class="mb mc iq lg b lh li lk ll ln md lr me lv mf lz mg mh mi mj bi translated">具有<strong class="lg ir"> ReLU </strong>激活的<strong class="lg ir"> 64个神经元</strong>的输入层</li><li id="b2be" class="mb mc iq lg b lh mk lk ml ln mm lr mn lv mo lz mg mh mi mj bi translated">分别为<strong class="lg ir"> 32 </strong>和<strong class="lg ir"> 16神经元</strong>的两个密集隐藏层，每个都有一个<strong class="lg ir"> ReLU </strong>激活</li><li id="2786" class="mb mc iq lg b lh mk lk ml ln mm lr mn lv mo lz mg mh mi mj bi translated"><strong class="lg ir"> 1神经元</strong>的输出层，具有<strong class="lg ir">s形</strong>激活</li></ul><p id="db6b" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">此外，我们还有:</p><ul class=""><li id="a1aa" class="mb mc iq lg b lh li lk ll ln md lr me lv mf lz mg mh mi mj bi translated">一个<strong class="lg ir"> Adam </strong>优化器，其学习率为<strong class="lg ir"> 1e-4 </strong>，衰减率为<strong class="lg ir"> 1e-6 </strong></li><li id="18b0" class="mb mc iq lg b lh mk lk ml ln mm lr mn lv mo lz mg mh mi mj bi translated"><strong class="lg ir">二元交叉熵</strong>和<strong class="lg ir">精度和召回指标</strong>丢失</li></ul><p id="86cc" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">模型将在<strong class="lg ir"> 5个时期</strong>进行训练</p><p id="4190" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">下面是我用来创建模型的代码，用的是Tensorflow的Keras模块。</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="b595" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在我们已经建立了模型，让我们运行它来看看我们的结果！</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi ok"><img src="../Images/f01ac11af427ed57d90d7c6007281b00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*doRpE5IyiFgrNEaOa4ioFQ.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">模型的输出</p></figure><p id="2b54" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们可以看到，我们的验证精度从大约<strong class="lg ir"> 19.52 </strong>到<strong class="lg ir"> 61.26% </strong>，而验证召回率从<strong class="lg ir"> 86.03 </strong>到<strong class="lg ir"> 90.44%。</strong>纪元4的验证召回率最高，纪元1的验证精度最高。该模型没有过度拟合，因为精度和召回率的值仍在增加。您可以随意更改历元数，以查看模型在更长时间内的表现！但是请注意，这将需要更长的时间来训练…</p></div><div class="ab cl ol om hu on" role="separator"><span class="oo bw bk op oq or"/><span class="oo bw bk op oq or"/><span class="oo bw bk op oq"/></div><div class="ij ik il im in"><p id="7c85" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">ML/DL带来的<strong class="lg ir"> <em class="ma">速度</em> </strong>和<strong class="lg ir"> <em class="ma">准确性</em> </strong>在打击信用卡诈骗中如这个简单的例子<strong class="lg ir">所示。</strong>2019年，Visa通过其人工智能系统防止了约250亿美元的信用卡欺诈。Kount的平台AI能够以快至250毫秒的速度返回风险率。通过利用机器学习和深度学习的力量，我们可以努力打击这种盗窃行为。</p></div><div class="ab cl ol om hu on" role="separator"><span class="oo bw bk op oq or"/><span class="oo bw bk op oq or"/><span class="oo bw bk op oq"/></div><div class="ij ik il im in"><p id="5784" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">希望你喜欢阅读这篇文章！欢迎在Linkedin 上加我，关注更多内容！</p><h1 id="4c4c" class="mp mq iq bd mr ms mt mu mv mw mx my mz ke na kf nb kh nc ki nd kk ne kl nf ng bi translated">文献学</h1><p id="57c8" class="pw-post-body-paragraph le lf iq lg b lh nh jz lj lk ni kc lm ln nj lp lq lr nk lt lu lv nl lx ly lz ij bi translated">[1] Anon，<a class="ae ld" href="https://www.businesswire.com/news/home/20190617005366/en/Visa-Prevents-Approximately-25-Billion-in-Fraud-Using-Artificial-Intelligence" rel="noopener ugc nofollow" target="_blank"> Visa利用人工智能防止了约250亿美元的欺诈</a> (2019)，商业资讯</p><p id="c029" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[2] L .哥伦布，<a class="ae ld" href="https://www.forbes.com/sites/louiscolumbus/2019/09/05/how-ai-is-protecting-against-payments-fraud/?sh=518f57044d29" rel="noopener ugc nofollow" target="_blank">人工智能如何防范支付欺诈</a> (2019)，福布斯</p><p id="772c" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[3] N. Lee，<a class="ae ld" href="https://www.cnbc.com/2021/01/27/credit-card-fraud-is-on-the-rise-due-to-covid-pandemic.html" rel="noopener ugc nofollow" target="_blank">信用卡诈骗将因Covid疫情而增加，专家警告</a> (2021)，美国消费者新闻与商业频道</p><p id="aee4" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[4]机器学习小组— ULB，<a class="ae ld" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank">信用卡欺诈检测</a>(2021年更新)，Kaggle</p><p id="a059" class="pw-post-body-paragraph le lf iq lg b lh li jz lj lk ll kc lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[5] S. Goswami，<a class="ae ld" rel="noopener" target="_blank" href="/class-imbalance-smote-borderline-smote-adasyn-6e36c78d804">类不平衡，SMOTE，临界SMOTE，ADASYN </a> (2020)，走向数据科学</p></div></div>    
</body>
</html>