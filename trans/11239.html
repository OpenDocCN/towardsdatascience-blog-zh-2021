<html>
<head>
<title>Spark Streaming with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Python 的 Spark 流</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/spark-streaming-with-python-5144cfc8b883?source=collection_archive---------23-----------------------#2021-11-03">https://towardsdatascience.com/spark-streaming-with-python-5144cfc8b883?source=collection_archive---------23-----------------------#2021-11-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="576a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Pyspark 流管道入门指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/dee02332ef0736b4963a9392dc565f29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tAiyRD1MJppOUuECm2gqRg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@jjying?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> JJ 英</a>在<a class="ae ky" href="https://unsplash.com/@jjying?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="4569" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Apache Spark 流相当受欢迎。由于其集成技术，Spark Streaming 在数据流质量和综合方法方面优于以前的系统。</p><p id="aefe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Python 和 Spark 流在一起使用时会给行业巨头带来奇迹。网飞是一个优秀的 Python/Spark 流媒体代表:这个流行的流媒体平台背后的人们已经发表了多篇文章，讲述他们如何使用该技术来帮助我们更好地享受网飞。让我们从基础开始。</p><h1 id="6d5a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">什么是 spark 流，它是如何工作的？</h1><p id="74fe" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">Spark 平台包含各种模块，包括 Spark 流。Spark 流是一种分析“无界”信息的方法，有时也称为“流”信息。这是通过将其划分为微批处理并允许在多个批处理上执行窗口来实现的。</p><p id="38c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Spark 流接口是一个 Spark API 应用程序模块。Python，Scala，Java 都支持。它允许您以容错和灵活的方式处理真实的数据流。Spark 引擎获取数据批次，并批量生成最终结果流。</p><h1 id="7bd4" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">什么是流式数据管道？</h1><p id="4e94" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这是一种允许数据从一个位置平滑且自动地移动到另一个位置的技术。这项技术消除了该公司的许多典型问题，如信息泄漏、瓶颈、多个数据冲突和重复创建条目。</p><p id="ef70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">流数据管道是可伸缩地实时处理数千个输入的数据管道架构。结果是，您将能够收集、分析和保留大量数据。该功能支持实时应用、监控和报告。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/d67473d02311ad519642fd71f61875b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Y2xGwC0wLopAYZTc"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="mt">图片由</em><a class="ae ky" href="https://unsplash.com/@olloweb?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"><em class="mt">agency followeb</em></a><em class="mt">on</em><a class="ae ky" href="https://unsplash.com/s/photos/concepts?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"><em class="mt">Unsplash</em></a></p></figure><h1 id="a021" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">Spark 的流架构。</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/870ab6790673a26436b6c0214cd35be1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*spAOni9eLExL_Qo_0lRXUQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="mt">作者提供的 Spark 流架构图</em></p></figure><p id="2484" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Spark 流的主要结构是逐批离散时间流。微批处理不断地被分配和分析，而不是一次一个项目地通过流处理管道。因此，数据根据可访问的资源和位置分发给员工。</p><p id="ae21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当数据被接收时，它被接收机分成 RDD 部分。因为 rdd 确实是 Spark 数据集的一个关键抽象，所以转换成 rdd 可以使用 Spark 脚本和工具进行分组分析。</p><h1 id="98e7" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">现实生活中的火花流示例(Twitter Pyspark 流)</h1><p id="a0c5" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在这个解决方案中，我将构建一个流管道，从互联网上获取特定关键字(Ether)的推文，并对这些实时推文执行转换，以获取与其相关的其他热门关键字。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/75987d98ee3f17a8356f13a03c593995.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*K9YzVXif6BxWPp95"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自作者的真实生活火花流示例架构异想天开的图</p></figure><h2 id="0b15" class="mw lw it bd lx mx my dn mb mz na dp mf li nb nc mh lm nd ne mj lq nf ng ml nh bi translated">视频教程</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ni nj l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">从<a class="ae ky" href="https://www.youtube.com/channel/UCO8XsgcjqArk_mAd1VGBMfg?sub_confirmation=1" rel="noopener ugc nofollow" target="_blank"> Anuj Syal </a>开始，不到 12 分钟就有 Python 的火花流</p></figure><h1 id="f0a9" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">第一步:使用 tweepy 传输推文</h1><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="adf3" class="mw lw it nl b gy np nq l nr ns">import tweepy<br/>from tweepy import OAuthHandler<br/>from tweepy import Stream<br/>from tweepy.streaming import StreamListener<br/>import socket<br/>import json<br/><br/># Set up your credentials<br/>consumer_key=''<br/>consumer_secret=''<br/>access_token =''<br/>access_secret=''<br/><br/><br/>class TweetsListener(StreamListener):<br/><br/>  def __init__(self, csocket):<br/>      self.client_socket = csocket<br/><br/>  def on_data(self, data):<br/>      try:<br/>          msg = json.loads( data )<br/>          print( msg['text'].encode('utf-8') )<br/>          self.client_socket.send( msg['text'].encode('utf-8') )<br/>          return True<br/>      except BaseException as e:<br/>          print("Error on_data: %s" % str(e))<br/>      return True<br/><br/>  def on_error(self, status):<br/>      print(status)<br/>      return True<br/><br/>def sendData(c_socket):<br/>  auth = OAuthHandler(consumer_key, consumer_secret)<br/>  auth.set_access_token(access_token, access_secret)<br/><br/>  twitter_stream = Stream(auth, TweetsListener(c_socket))<br/>  twitter_stream.filter(track=['ether'])<br/><br/>if __name__ == "__main__":<br/>  s = socket.socket()         # Create a socket object<br/>  host = "127.0.0.1"     # Get local machine name<br/>  port = 5554                 # Reserve a port for your service.<br/>  s.bind((host, port))        # Bind to the port<br/><br/>  print("Listening on port: %s" % str(port))<br/><br/>  s.listen(5)                 # Now wait for client connection.<br/>  c, addr = s.accept()        # Establish connection with client.<br/><br/>  print( "Received request from: " + str( addr ) )<br/><br/>  sendData( c )</span></pre><h1 id="3439" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">步骤 2:编码 PySpark 流管道</h1><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="9f5d" class="mw lw it nl b gy np nq l nr ns"># May cause deprecation warnings, safe to ignore, they aren't errors<br/>from pyspark import SparkContext<br/>from pyspark.streaming import StreamingContext<br/>from pyspark.sql import SQLContext<br/>from pyspark.sql.functions import desc<br/># Can only run this once. restart your kernel for any errors.<br/>sc = SparkContext()</span><span id="94bd" class="mw lw it nl b gy nt nq l nr ns">ssc = StreamingContext(sc, 10 )<br/>sqlContext = SQLContext(sc)<br/>socket_stream = ssc.socketTextStream("127.0.0.1", 5554)<br/>lines = socket_stream.window( 20 )<br/>from collections import namedtuple<br/>fields = ("tag", "count" )<br/>Tweet = namedtuple( 'Tweet', fields )<br/># Use Parenthesis for multiple lines or use \.<br/>( lines.flatMap( lambda text: text.split( " " ) ) #Splits to a list<br/>  .filter( lambda word: word.lower().startswith("#") ) # Checks for hashtag calls<br/>  .map( lambda word: ( word.lower(), 1 ) ) # Lower cases the word<br/>  .reduceByKey( lambda a, b: a + b ) # Reduces<br/>  .map( lambda rec: Tweet( rec[0], rec[1] ) ) # Stores in a Tweet Object<br/>  .foreachRDD( lambda rdd: rdd.toDF().sort( desc("count") ) # Sorts Them in a DF<br/>  .limit(10).registerTempTable("tweets") ) ) # Registers to a table.</span></pre><h1 id="e298" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">步骤 3:运行 Spark 流管道</h1><ul class=""><li id="1c07" class="nu nv it lb b lc mn lf mo li nw lm nx lq ny lu nz oa ob oc bi translated">打开“终端”并运行 TweetsListener，开始播放推文</li></ul><p id="0861" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe od oe of nl b">python TweetsListener.py</code></p><ul class=""><li id="5470" class="nu nv it lb b lc ld lf lg li og lm oh lq oi lu nz oa ob oc bi translated">在 Jupyter notebook 启动 spark 流上下文中，这将让传入的 tweets 流进入 spark 流管道，并执行步骤 2 中所述的转换</li></ul><p id="1465" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe od oe of nl b">ssc.start()</code></p><h1 id="fb81" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">步骤 4:查看实时输出</h1><p id="76dc" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">从 spark <code class="fe od oe of nl b">tweets</code>中注册的临时表在图表/仪表板上绘制实时信息。该表将每 3 秒更新一次推文分析</p><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="3200" class="mw lw it nl b gy np nq l nr ns">import time<br/>from IPython import display<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/># Only works for Jupyter Notebooks!<br/>%matplotlib inline <br/><br/>count = 0<br/>while count &lt; 10:<br/>    time.sleep( 3 )<br/>    top_10_tweets = sqlContext.sql( 'Select tag, count from tweets' )<br/>    top_10_df = top_10_tweets.toPandas()<br/>    display.clear_output(wait=True)<br/>    plt.figure( figsize = ( 10, 8 ) )<br/>#     sns.barplot(x='count',y='land_cover_specific', data=df, palette='Spectral')<br/>    sns.barplot( x="count", y="tag", data=top_10_df)<br/>    plt.show()<br/>    count = count + 1</span></pre><p id="48da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">出局:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/368d16c7e8c70b6f59c93b904e3594ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/0*phpqiKNGELlnFYyZ"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者输出的屏幕截图</p></figure><h1 id="9a08" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">火花流的一些优点和缺点</h1><p id="8d15" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">既然我们已经完成了构建 spark 流管道的实际解决方案，让我们列出使用这种方法的一些优点和缺点。</p><p id="696d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">优点</strong></p><ul class=""><li id="1200" class="nu nv it lb b lc ld lf lg li og lm oh lq oi lu nz oa ob oc bi translated">对于困难的工作，它提供了非凡的速度。</li><li id="e43f" class="nu nv it lb b lc ok lf ol li om lm on lq oo lu nz oa ob oc bi translated">对故障的敏感性。</li><li id="02e0" class="nu nv it lb b lc ok lf ol li om lm on lq oo lu nz oa ob oc bi translated">在云平台上，执行起来很简单。</li><li id="01b7" class="nu nv it lb b lc ok lf ol li om lm on lq oo lu nz oa ob oc bi translated">支持多种语言。</li><li id="fc2f" class="nu nv it lb b lc ok lf ol li om lm on lq oo lu nz oa ob oc bi translated">与主要框架的集成。</li><li id="f553" class="nu nv it lb b lc ok lf ol li om lm on lq oo lu nz oa ob oc bi translated">连接各种类型数据库的能力。</li></ul><p id="d04b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">缺点</strong></p><ul class=""><li id="7676" class="nu nv it lb b lc ld lf lg li og lm oh lq oi lu nz oa ob oc bi translated">需要大量的存储空间。</li><li id="ba11" class="nu nv it lb b lc ok lf ol li om lm on lq oo lu nz oa ob oc bi translated">很难使用、调试和掌握。</li><li id="90a5" class="nu nv it lb b lc ok lf ol li om lm on lq oo lu nz oa ob oc bi translated">缺少文档和指导资源。</li><li id="8ac4" class="nu nv it lb b lc ok lf ol li om lm on lq oo lu nz oa ob oc bi translated">数据的可视化并不令人满意。</li><li id="5c86" class="nu nv it lb b lc ok lf ol li om lm on lq oo lu nz oa ob oc bi translated">处理少量数据时反应迟钝</li><li id="0b3c" class="nu nv it lb b lc ok lf ol li om lm on lq oo lu nz oa ob oc bi translated">只有少数机器学习技术。</li></ul><h1 id="4554" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="719b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">Spark Streaming 确实是一种收集和分析大量数据的技术。在不久的将来，流数据可能会变得更加流行，所以您应该现在就开始了解它。请记住，数据科学不仅仅是构建模型；它还需要管理一个完整的管道。</p><p id="4004" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文讨论了 Spark 流的基础知识，以及如何在真实数据集上使用它。我们建议您使用另一个样本或实时数据，将我们学到的一切付诸实践。</p></div><div class="ab cl op oq hx or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="im in io ip iq"><p id="881c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ow">最初发表于</em><a class="ae ky" href="https://anujsyal.com/spark-streaming-with-python" rel="noopener ugc nofollow" target="_blank"><em class="ow">【https://anujsyal.com】</em></a><em class="ow">。</em></p></div></div>    
</body>
</html>