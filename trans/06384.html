<html>
<head>
<title>Elegant CICD with Databricks notebooks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">优雅的CICD，配有Databricks笔记本</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/elegant-cicd-with-databricks-notebooks-760623bb3e9b?source=collection_archive---------14-----------------------#2021-06-08">https://towardsdatascience.com/elegant-cicd-with-databricks-notebooks-760623bb3e9b?source=collection_archive---------14-----------------------#2021-06-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="26eb" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何用Azure DevOps发布Databricks笔记本神器</h2></div><p id="2f7a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">卢克·范·德·维尔登</p><p id="4dad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从数据科学探索到生产中的ETL和ML，笔记本是数据块的主要运行时。这种对笔记本的强调要求我们改变对生产质量标准的理解。我们必须消除对凌乱的笔记本的犹豫，并问自己:我们如何将笔记本转移到我们的生产流水线中？我们如何在笔记本上执行单元测试和集成测试？我们可以将笔记本视为DevOps管道中的工件吗？</p><h1 id="f452" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">作为一等公民的数据砖笔记本</h1><p id="d700" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">选择Databricks作为计算平台时，您的最佳选择是在您的生产环境中运行笔记本电脑。这个决定是由对笔记本运行时和经典python脚本的压倒性支持决定的。我们认为，人们应该完全接受笔记本电脑方法，并选择最佳方法在生产环境中测试和部署笔记本电脑。在这篇博客中，我们使用Azure DevOps管道通过瞬态数据块集群和笔记本工件注册进行笔记本(单元、集成)测试。</p><h1 id="0864" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">笔记本:python包的入口点</h1><p id="595f" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">笔记本可以独立存在，但是我们更喜欢将它们作为Git存储库的一部分，它具有以下结构。它包含一个笔记本目录，用于将数据块笔记本作为源文件签入；一个Python包(“my_model”)，包含要在笔记本中导入的功能；一个测试目录，包含Python包的单元测试；一个Azure DevOps管道和一个cluster-config.json，用于配置我们的瞬态数据块集群。此外，我们使用诗歌进行基于pyproject.toml规范的Python依赖管理和打包。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="f968" class="mj le iq mf b gy mk ml l mm mn">notebooks/<br/>-        run_model.py  # Databricks notebook checked in as .py file<br/>my_model/<br/>-        preprocessing.py  # Python module imported in notebook<br/>tests/<br/>azure-pipelines.yml<br/>cluster-config.yml<br/>pyproject.toml<br/>...</span></pre><p id="d455" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过将Git存储库链接到Databricks工作区中的笔记本，或者通过手动将笔记本导出为<em class="mo">源文件</em>，可以将笔记本提交到Git存储库中。在这两种情况下，存储库中的笔记本都是带有数据块标记命令的Python文件。我们存储库的笔记本入口点如下所示。请注意，它从包含的存储库中安装并导入Python包‘my _ model’build。包版本将在后面详细说明。任何笔记本逻辑都在main函数中被捕获。执行主函数dbutils.notebook.exit()后，调用该函数，表示成功完成，并允许将结果值返回给调用者。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="aadb" class="mj le iq mf b gy mk ml l mm mn"># Databricks notebook source<br/>dbutils.widgets.text("package_version", defaultValue='')<br/>package_version = dbutils.widgets.get("package_version")<br/> <br/># COMMAND ----------<br/> <br/>devops_pat = dbutils.secrets.get("devops_scope", "devops-artifact-read")<br/>%pip install my_model==$package_version --index=<a class="ae mp" href="https://build:$devops_pat@pkgs.dev.azure.com/organization/project/_packaging/feed/pypi/simple/" rel="noopener ugc nofollow" target="_blank">https://build:$devops_pat@pkgs.dev.azure.com/organization/project/_packaging/feed/pypi/simple/</a><br/> <br/># COMMAND ----------<br/> <br/>from my_model.preprocessing import do_nothing<br/> <br/># COMMAND ----------<br/> <br/># define the main model function<br/>def main(spark):<br/>  do_nothing(spark)<br/> <br/># COMMAND ----------<br/> <br/># run the model<br/>from loguru import logger<br/> <br/>with logger.catch(reraise=True):<br/>  main(spark)<br/> <br/># COMMAND ----------<br/> <br/>dbutils.notebook.exit("OK")</span></pre><h1 id="3a86" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">笔记本拉取请求管道</h1><p id="2fd0" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">在开发笔记本及其支持的Python包时，开发人员提交开发分支，并创建一个Pull请求供同事审阅。图1显示了支持我们的拉请求的管道步骤。Pull请求自动触发Azure DevOps管道，该管道必须在最近一次提交时成功。首先，我们运行Python包的单元测试，成功后构建它并将开发构建包发布到Azure工件。这个开发构建包的版本字符串被传递给笔记本输入小部件“package_version ”,以便在我们的登台环境中进行笔记本集成测试。管道验证笔记本是否成功运行(是否调用了dbutils.notebook.exit ),并提供关于Pull请求的反馈。</p><figure class="ma mb mc md gt mr gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi mq"><img src="../Images/99039ebbdf631e051260d614310260ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mPHr4gShLsZ7bbBQdPON_g.png"/></div></div><p class="my mz gj gh gi na nb bd b be z dk translated">图1:用于持续集成的PR笔记本管道，图片由作者提供</p></figure><h1 id="172e" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">瞬态集群上的集成测试</h1><p id="c63a" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">目标是在来自Azure DevOps管道的数据块上执行这个笔记本。为了灵活性，我们选择数据块池。这些池的优势在于，当许多不同的作业需要在即时集群上运行时，它们可以减少集群的启动和自动扩展时间。对于笔记本的执行(以及对可选数据源的访问)，我们使用Azure应用程序注册。此Azure应用程序注册将拥有管理数据块群集和执行笔记本的权限。流水线的基本步骤包括数据块集群配置和创建、笔记本的执行以及集群的最终删除。我们将详细讨论每个步骤(图2)。</p><figure class="ma mb mc md gt mr gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi nc"><img src="../Images/aa1557c9acee39d5479a16de349aa0e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NAnN2u0S0T8uPIRtmBombA.png"/></div></div><p class="my mz gj gh gi na nb bd b be z dk translated"><em class="nd">图Databricks笔记本的集成测试管道步骤，作者图片</em></p></figure><p id="5eee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了使用Azure DevOps管道来测试和部署Databricks笔记本，我们使用由Data heedy Ltd开发的<a class="ae mp" href="https://marketplace.visualstudio.com/publishers/DataThirstLtd" rel="noopener ugc nofollow" target="_blank"> Azure DevOps任务</a>来创建集群，并使用来自<a class="ae mp" href="https://marketplace.visualstudio.com/publishers/Microsoft%20DevLabs" rel="noopener ugc nofollow" target="_blank">微软DevLabs </a>的任务来执行笔记本。由于他们的任务集还不支持所有需要的操作，我们也使用他们为数据块开发的PowerShell工具。任务和PowerShell工具都是围绕Databricks API的包装器。</p><h2 id="7297" class="mj le iq bd lf ne nf dn lj ng nh dp ln ko ni nj lp ks nk nl lr kw nm nn lt no bi translated">应用程序注册的数据块权限</h2><p id="61fa" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">作为准备，我们创建了一个可用于集成测试的数据块池。我们使用Azure应用程序注册作为主体在实例池上执行笔记本。应用程序注册被注册为Databricks服务主体，在Databricks池上具有“可以附加到”权限以创建群集。</p><figure class="ma mb mc md gt mr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/c8631e8533b3636cb70d89ed6d18c985.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*5aKF4Hcf8E2vCoiEfoGTPg.png"/></div><p class="my mz gj gh gi na nb bd b be z dk translated"><em class="nd">数据块实例池配置，作者图片</em></p></figure><h2 id="0e3f" class="mj le iq bd lf ne nf dn lj ng nh dp ln ko ni nj lp ks nk nl lr kw nm nn lt no bi translated">准备管道机密</h2><p id="f697" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">CI/CD管道的第一步是获取所有需要的机密。为简单起见，我们将应用注册客户端id、secret、tenant-id和Databricks池id存储在一个密钥库中。秘密是使用AzureKeyVault任务收集的。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="5609" class="mj le iq mf b gy mk ml l mm mn"># azure-pipelines.yml excerpt<br/>jobs:<br/>- job: integration_test<br/>  displayName: Test on databricks<br/>  pool:<br/>    vmImage: "windows-latest"<br/>  steps:<br/>  - task: AzureKeyVault@1<br/>    inputs:<br/>      azureSubscription: "Azure DevOps Service Connection"<br/>      keyVaultName: "keyvault-test-environment"<br/>      secretsFilter: "appreg-client-id,appreg-client-secret,tenant-id,databricks-pool-id"</span></pre><h2 id="235d" class="mj le iq bd lf ne nf dn lj ng nh dp ln ko ni nj lp ks nk nl lr kw nm nn lt no bi translated">数据块工作空间连接</h2><p id="c307" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">为了与数据块交互，我们需要从Azure DevOps连接到工作区。我们使用Data heart中的两个Azure Devops任务来生成Databricks的访问令牌并连接到工作区。令牌存储在BearerToken变量中，并为我们在Databricks中授予权限的应用程序注册生成。可以在Databricks资源上的Azure门户中找到工作区URL。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="5d27" class="mj le iq mf b gy mk ml l mm mn"># azure-pipelines.yml excerpt<br/>- task: databricksDeployCreateBearer@0<br/>  inputs:<br/>    applicationId: $(appreg-client-id)<br/>    spSecret: $(appreg-client-secret)<br/>    resourceGroup: "DatabricksResourceGroup"<br/>    workspace: "DatabricksWorkspace"<br/>    subscriptionId: "AzureSubscriptionId"<br/>    tenantId: $(tenant-id)<br/>    region: "westeurope"<br/>- task: configuredatabricks@0<br/>  inputs:<br/>    url: "<a class="ae mp" href="https://adb-000000000000.0.azuredatabricks.net" rel="noopener ugc nofollow" target="_blank">https://adb-000000000000.0.azuredatabricks.net</a>"<br/>    token: $(BearerToken)</span></pre><p id="8816" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，使用databricksDeployCreateBearer任务存在潜在的安全问题，我们已经在实时管道中解决了这个问题。该任务的当前版本创建了没有截止日期的不记名令牌，不幸的是，无法使用该任务设置截止日期。或者，也可以使用Data hedge的Powershell Databricks工具。通过连续调用Connect-Databricks和New-databrickbearertoken，可以创建具有有限生存期的令牌。</p><h2 id="53c9" class="mj le iq bd lf ne nf dn lj ng nh dp ln ko ni nj lp ks nk nl lr kw nm nn lt no bi translated">创建瞬态测试集群</h2><p id="fc98" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">在建立到数据块的连接之后，我们在数据块中创建一个专用集群，用于由这个管道执行的集成测试。集群配置只包含一个工作人员，这对于集成测试来说已经足够了。当我们在ADLS第二代存储帐户上存储笔记本电脑所需的测试数据时，我们设置了ADLS传递，以允许应用程序注册通过存储帐户进行验证。为了达到最佳效果，我们<strong class="kh ir">而不是</strong>直接在集群配置中插入应用注册客户端密码，因为这将在数据块中可见。相反，我们在集群配置中使用Databricks Secret作用域及其模板标记，这在运行时填充。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="e13b" class="mj le iq mf b gy mk ml l mm mn">// cluster-config.json<br/>{<br/>    "num_workers": 1,<br/>    "cluster_name": "",<br/>    "spark_version": "",<br/>    "spark_conf": {<br/>        "fs.azure.account.auth.type": "OAuth",<br/>        "fs.azure.account.oauth.provider.type": "org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider",<br/>        "fs.azure.account.oauth2.client.id": "",<br/>        "fs.azure.account.oauth2.client.secret": "{{secrets/zpz_scope/appreg-client-secret}}",<br/>        "fs.azure.account.oauth2.client.endpoint": "",<br/>        "spark.hadoop.fs.permissions.umask-mode": "002"<br/>    },<br/>    "ssh_public_keys": [],<br/>    "custom_tags": {},<br/>    "spark_env_vars": {<br/>        "PYSPARK_PYTHON": "/databricks/python3/bin/python3",<br/>        "NSK_ENV": ""<br/>    },<br/>    "autotermination_minutes": 10,<br/>    "cluster_source": "API",<br/>    "init_scripts": [],<br/>    "instance_pool_id": ""<br/>}</span></pre><p id="167a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们提交集群配置文件的上述模板，并在运行时使用Linux‘jq’命令从Azure Key Vault中填写详细信息，如池id和应用注册客户端id。集群名称基于当前的devops构建ID和其他参数，cluster-config.json被呈现并写入磁盘。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="e38a" class="mj le iq mf b gy mk ml l mm mn"># azure-pipelines.yml excerpt<br/>- bash: |<br/>    jq -c ".cluster_name = \"${CLUSTER_NAME}\""`<br/>         `"| .spark_conf.\"fs.azure.account.oauth2.client.id\" = \"$(ar20zpz001-client-id)\""`<br/>         `"| .spark_conf.\"fs.azure.account.oauth2.client.endpoint\" = \"<a class="ae mp" href="https://login.microsoftonline.com/$(tenant-id)/oauth2/token\" rel="noopener ugc nofollow" target="_blank">https://login.microsoftonline.com/$(tenant-id)/oauth2/token\</a>""`<br/>         `"| .spark_version = \"${RUNTIME}\""`<br/>         `"| .instance_pool_id = \"${INSTANCE_POOL_ID}\""`<br/>         `"| .spark_env_vars.NSK_ENV = \"${NSK_ENV}\"" cluster-config.json &gt; tmp.$$.json<br/>    mv tmp.$$.json cluster-config.json<br/>    echo "Generated cluster-config.json:"<br/>    cat cluster-config.json<br/>  displayName: "Generate cluster-config.json"<br/>    env:<br/>      CLUSTER_NAME: "integration-build-$(Build.BuildId)"<br/>      RUNTIME: "7.5.x-scala2.12"<br/>      INSTANCE_POOL_ID: $(main-pool-id)<br/>      NSK_ENV: "test"</span></pre><p id="1354" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Data heedy中的databricksClusterTask使用呈现的cluster-config.json在我们的暂存环境中创建和部署一个集群，其中包含从Databricks池中获取的资源。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="3230" class="mj le iq mf b gy mk ml l mm mn">- task: databricksClusterTask@0<br/>  name: createCluster<br/>  inputs:<br/>    authMethod: "bearer"<br/>    bearerToken: $(appreg-access-token)<br/>    region: "westeurope"<br/>    sourcePath: "cluster-config.json"</span></pre><h2 id="05dd" class="mj le iq bd lf ne nf dn lj ng nh dp ln ko ni nj lp ks nk nl lr kw nm nn lt no bi translated">执行笔记本</h2><p id="279e" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">最后，我们可以上传笔记本来测试和执行它。databricksDeployScripts任务将笔记本上载到Databricks，该任务使用Microsoft DevLabs的executenotebook任务执行。笔记本存储在包含devops构建ID的路径中，以便在以后需要时识别(并删除)它。如果笔记本使用小部件，executionParams输入用于传递带有输入参数的JSON字符串。在我们的例子中，Python包开发版本字符串作为“package_version”传递，用于受控集成测试。最后，我们等待笔记本的执行完成。如果在笔记本运行期间调用了Databricks builtin dbutils . notebook . exit(" return value ")，则executenotebook任务将成功完成。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="393c" class="mj le iq mf b gy mk ml l mm mn"># azure-pipelines.yml excerpt<br/>- task: databricksDeployScripts@0<br/>  inputs:<br/>    authMethod: "bearer"<br/>    bearerToken: $(appreg-access-token)<br/>    region: "westeurope"<br/>    localPath: "notebooks/"<br/>    databricksPath: "/test/package_name/$(Build.BuildId)"<br/>    clean: false       <br/>- task: executenotebook@0<br/>  inputs:<br/>    notebookPath: "/test/package_name/$(Build.BuildId)/$(notebook_name)"<br/>    executionParams: '{"package_version":"0.0.0-dev"}'<br/>    existingClusterId: $(createCluster.DatabricksClusterId)<br/>- task: waitexecution@0<br/>  name: waitForNotebook</span></pre><h1 id="4973" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">删除集群</h1><p id="6674" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">最后，我们删除集群。不幸的是，不存在来自数据渴求的Azure DevOps任务来删除集群，所以我们安装了他们的Powershell Databricks工具，并使用Remove-DatabricksCluster命令来删除集群。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="f260" class="mj le iq mf b gy mk ml l mm mn"># azure-pipelines.yml excerpt<br/>- task: PowerShell@2<br/>  condition: always()<br/>  inputs:<br/>    targetType: "inline"<br/>    script: |<br/>      Install-Module -Name azure.databricks.cicd.tools -force -Scope CurrentUser<br/>- task: PowerShell@2<br/>  condition: always()<br/>  inputs:<br/>    targetType: "inline"<br/>    script: |<br/>      Remove-DatabricksCluster -BearerToken $(BearerToken) -Region 'westeurope' -ClusterId $(createCluster.DatabricksClusterId)<br/>  displayName: "Delete Databricks integration cluster"</span></pre><h1 id="46b3" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">笔记本神器发布</h1><p id="1218" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">测试成功的笔记本准备与主分支合并。合并后，我们希望将笔记本电脑投入生产。我们使用Azure devops工件将项目笔记本目录注册为Azure devops工件提要中的通用包。我们用发布版本标记主分支，这触发了包括工件注册的管道运行。在注册notebook工件之前，发布版本在notebook input小部件中用<em class="mo"> sed </em>设置为默认的“package_version ”,见下文(下面的示例为1.0.0版)。注意，附带的Python包也注册为具有相同名称和版本的工件，但是在不同的工件devops工件提要中。这确保了在默认情况下，笔记本将使用测试时使用的Python包版本运行。因此，我们的笔记本产品是可复制的，并允许一个受控的发布过程。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="edf3" class="mj le iq mf b gy mk ml l mm mn"># Databricks notebook source<br/>dbutils.widgets.text("package_version", defaultValue='1.0.0')<br/>package_version = dbutils.widgets.get("package_version")</span></pre><p id="db30" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如何生成发布版本由您决定。最初，您可以向主分支添加一个git标签来触发一个包含工件注册的构建，如下所示。对于完整CICD，您可以在合并拉取请求时即时生成一个版本。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="dbb8" class="mj le iq mf b gy mk ml l mm mn"># azure-pipelines.yml excerpt<br/> variables:<br/>  packageName: 'my_model'<br/>  ${{ if startsWith(variables['Build.SourceBranch'], 'refs/tags/') }}:<br/>    packageVersion: $(Build.SourceBranchName)<br/>  ${{ if not(startsWith(variables['Build.SourceBranch'], 'refs/tags/')) }}:<br/>    packageVersion: 0.0.0-dev.$(Build.BuildId)</span><span id="a0e5" class="mj le iq mf b gy nq ml l mm mn">- job: publish_notebook_artifact<br/>  pool:<br/>    vmImage: "ubuntu-latest"<br/>  dependsOn: [integration_test]<br/>  condition: and(succeeded(), or(eq(variables['Build.Reason'], 'Manual'),  startsWith(variables['Build.SourceBranch'], 'refs/tags/')))<br/>  steps:<br/>  - bash: |<br/>      set -e<br/>      if [ -z "$PACKAGEVERSION" ]<br/>      then<br/>        echo "Require PACKAGEVERSION parameter"<br/>        exit 1<br/>      fi<br/>      sed -i "s/defaultValue=.*/defaultValue='$PACKAGEVERSION')/" \<br/>        notebooks/run_model.py<br/>    displayName: Update default value for version<br/>  - task: UniversalPackages@0<br/>    displayName: Publish notebook artifact $(packageVersion)<br/>    inputs:<br/>      command: publish<br/>      publishDirectory: "notebooks/"<br/>      vstsFeedPublish: "DNAKAA/databricks-notebooks"<br/>      vstsFeedPackagePublish: "my_model"<br/>      packagePublishDescription: "notebooks of my_model"<br/>      versionOption: custom<br/>      versionPublish: "$(packageVersion)"</span></pre><h1 id="c859" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">结论</h1><p id="67c1" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">我们已经展示了如何通过Python包单元测试在瞬态数据块集群上运行笔记本集成测试。这导致可再现的笔记本工件，允许笔记本的受控发布过程。Databricks笔记本电脑是一等公民，要求工程师将笔记本电脑解放到他们的测试和发布流程中。我们期待着了解更多关于将数据科学家的现实与数据工程师的现实相结合，以提高生产力，定期发布。我们的目标是简化从探索、概念验证到生产的过程。在我们的下一篇博客中，我们将深入探讨如何在生产管道中使用笔记本工件，重点是Azure DataFactory管道。</p></div><div class="ab cl nr ns hu nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="ij ik il im in"><p id="c498" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mo">最初发布于</em><a class="ae mp" href="https://codebeez.nl/blogs/elegant-cicd-databricks-notebooks/" rel="noopener ugc nofollow" target="_blank"><em class="mo">https://codebeez . nl</em></a><em class="mo">。</em></p></div></div>    
</body>
</html>