<html>
<head>
<title>Implementing Real-time Object Detection System using PyTorch and OpenCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用PyTorch和OpenCV实现实时目标检测系统</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-real-time-object-detection-system-using-pytorch-and-opencv-70bac41148f7?source=collection_archive---------1-----------------------#2021-06-18">https://towardsdatascience.com/implementing-real-time-object-detection-system-using-pytorch-and-opencv-70bac41148f7?source=collection_archive---------1-----------------------#2021-06-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="55d5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用python实现实时对象检测系统的实践指南</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0c6bf1d0883604fb4d167a5db62369bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ADo7r1hofD1RWB7Wo_k79A.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">文森特·梵高(1853–1890)，巴黎，1887年5月至7月(<a class="ae kv" href="https://www.vangoghmuseum.nl/en/collection/s0086V1962#details" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="f78f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">无人驾驶汽车可能仍然很难理解人类和垃圾桶之间的区别，但这并不影响最先进的物体检测模型在过去十年中取得的惊人进展。</p><p id="112a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结合OpenCV等库的图像处理能力，现在在几个小时内构建一个实时对象检测系统原型要容易得多。在本指南中，我将尝试向您展示如何开发一个简单的对象检测应用程序的子系统，以及如何将所有这些放在一起。</p><h1 id="7d84" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">Python vs C++</h1><p id="113e" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我知道你们中的一些人可能会想为什么我使用Python，对于实时应用程序来说，它是不是太慢了，你是对的；在某种程度上。</p><p id="f427" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">大多数计算繁重的操作，如预测或图像处理，都是由PyTorch和OpenCV执行的，它们都在幕后使用c++来实现这些操作，因此，如果我们在这里使用c++或python，不会有太大的区别。</p><p id="1948" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但同样，它只是一个原型，只有很少的基础设施代码和附加开销。如果你想学习生产级的实时实现，我建议你不要选择python，至少现在不要。</p><h1 id="31fc" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">读取视频流</h1><p id="97bf" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">您的输入视频流源可以是任何东西，您可能想从您的网络摄像头读取，或解析已存在的视频，或从连接到网络的外部摄像机。无论是什么问题，OpenCV都是解决方案。在这个例子中，我将展示如何从youtube或网络摄像头读取视频流。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/00c2f0ccfdbb5f00d7657749857eb102.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RYOxzW7nU4sxmNplxjgxGA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">您可以使用OpenCV创建一个视频流来支持您的应用程序。(<a class="ae kv" href="https://www.youtube.com/watch?v=wqctLW0Hb_0" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h2 id="bc24" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">从你的试管中读取</h2><p id="6655" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">对于您的原型，您可能不想出去创建一个新的视频，而是使用许多在线可用的视频之一。在这种情况下，你可以从youtube上阅读视频流。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="f6fa" class="mq lt iq nd b gy nh ni l nj nk">import cv2 # opencv2 package for python.<br/>import pafy # pafy allows us to read videos from youtube.</span><span id="5407" class="mq lt iq nd b gy nl ni l nj nk">URL = "https://www.youtube.com/watch?v=dQw4w9WgXcQ" #URL to parse<br/>play = pafy.new(self._URL).streams[-1] #'-1' means read the lowest quality of video.<br/>assert play is not None # we want to make sure their is a input to read.<br/>stream = cv2.VideoCapture(play.url) #create a opencv video stream.</span></pre><h2 id="9d43" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">从网络摄像头读取</h2><p id="1111" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">有时候你只想看看自己的脸。在这种情况下，请随意使用内置网络摄像头。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="3bc3" class="mq lt iq nd b gy nh ni l nj nk">import cv2</span><span id="dc2c" class="mq lt iq nd b gy nl ni l nj nk">stream = cv2.VideoCapture(0) # 0 means read from local camera.</span></pre><h2 id="0a0e" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">读取IP摄像头</h2><p id="1c0e" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">如果您正在构建一个将部署在服务器上的应用程序，您的摄像机将拥有一个IP地址，您可以从该地址访问视频流。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="9d2a" class="mq lt iq nd b gy nh ni l nj nk">import cv2</span><span id="0a60" class="mq lt iq nd b gy nl ni l nj nk">camera_ip = "rtsp://username:password@IP/port"<br/>stream = cv2.VideoCapture(camera_ip)</span></pre><h1 id="ab7b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">加载模型</h1><p id="60a7" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">今天的机器学习工程师被选择宠坏了，或者我应该说被选择弄糊涂了。有许多伟大的对象检测模型，每一个都有其优点和缺点。为了简单起见，我们将使用<strong class="ky ir"> YoloV5 </strong>，因为它为我们提供了快速推理，这对我们的实时应用程序至关重要。你也可以看看其他的模型，比如FasterRCNN。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/9bdc9098cff99d65604725c2d04c7ccd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hwwso_UOhbAqBru7.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">根据Yolov5文件，它是目前市场上最快的型号。(<a class="ae kv" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="57b7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以直接从PyTorch hub加载模型，第一次运行代码可能需要几分钟，因为它会从互联网上下载模型，但下一次它将直接从磁盘加载。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="6d14" class="mq lt iq nd b gy nh ni l nj nk">from torch import hub # Hub contains other models like FasterRCNN</span><span id="b260" class="mq lt iq nd b gy nl ni l nj nk">model = torch.hub.load( \<br/>                      'ultralytics/yolov5', \<br/>                      'yolov5s', \<br/>                      pretrained=True)</span></pre><h1 id="38e7" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">对单帧进行评分</h1><p id="724b" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">俗话说“千里之行，始于足下”，所以我们可以说“解析一个视频流，始于一帧”。让我们看看如何对单个帧进行评分和解析。</p><p id="2b96" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们用来执行推理的设备对我们的推理速度产生了巨大的影响，现代深度学习模型在与GPU一起工作时效果最佳，所以如果你有一个带有CUDA内核的GPU，它将大幅提高你的性能。在我的经验中，即使只有一个GPU的系统也可以达到每秒45-60帧，而CPU最多只能给你25-30帧。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="f07b" class="mq lt iq nd b gy nh ni l nj nk">"""<br/>The function below identifies the device which is availabe to make the prediction and uses it to load and infer the frame. Once it has results it will extract the labels and cordinates(Along with scores) for each object detected in the frame.<br/>"""</span><span id="9c85" class="mq lt iq nd b gy nl ni l nj nk">def score_frame(frame, model):<br/>    device = 'cuda' if torch.cuda.is_available() else 'cpu'<br/>    model.to(device)<br/>    frame = [torch.tensor(frame)]<br/>    results = self.model(frame)<br/>    labels = results.xyxyn[0][:, -1].numpy()<br/>    cord = results.xyxyn[0][:, :-1].numpy()<br/>    return labels, cord</span></pre><h1 id="dc65" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">在框架上绘制方框</h1><p id="8072" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">一旦我们对该帧进行了评分，我们就需要在将该帧写入输出流之前，在该帧上绘制出已标识的对象及其盒子。为此，我们可以使用OpenCV的图像处理工具包。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="e606" class="mq lt iq nd b gy nh ni l nj nk">"""<br/>The function below takes the results and the frame as input and plots boxes over all the objects which have a score higer than our threshold.<br/>"""<br/>def plot_boxes(self, results, frame):<br/>    labels, cord = results<br/>    n = len(labels)<br/>    x_shape, y_shape = frame.shape[1], frame.shape[0]<br/>    for i in range(n):<br/>        row = cord[i]<br/>        # If score is less than 0.2 we avoid making a prediction.<br/>        if row[4] &lt; 0.2: <br/>            continue<br/>        x1 = int(row[0]*x_shape)<br/>        y1 = int(row[1]*y_shape)<br/>        x2 = int(row[2]*x_shape)<br/>        y2 = int(row[3]*y_shape)<br/>        bgr = (0, 255, 0) # color of the box<br/>        classes = self.model.names # Get the name of label index<br/>        label_font = cv2.FONT_HERSHEY_SIMPLEX #Font for the label.<br/>        cv2.rectangle(frame, \<br/>                      (x1, y1), (x2, y2), \<br/>                       bgr, 2) #Plot the boxes<br/>        cv2.putText(frame,\<br/>                    classes[labels[i]], \<br/>                    (x1, y1), \<br/>                    label_font, 0.9, bgr, 2) #Put a label over box.<br/>        return frame</span></pre><p id="5470" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦完成，这个函数将产生类似这样的输出。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/5998ace85748bac16dc39634a6e6ba42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1towgGw7VpoYrfypxgd0ng.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">你可以尝试不同的物体有不同的颜色。(图片由作者提供)</p></figure><h1 id="dbc6" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">一个将他们团结起来的功能</h1><p id="163a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">很抱歉引用了《指环王》,但是是的，现在我们把它们都放在一个单独的调用函数中，在一个循环中执行整个操作。</p><p id="e3da" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，让我们回顾一下我们的主函数要成功运行应用程序必须执行的步骤。</p><ol class=""><li id="303a" class="no np iq ky b kz la lc ld lf nq lj nr ln ns lr nt nu nv nw bi translated">创建视频流输入。</li><li id="8786" class="no np iq ky b kz nx lc ny lf nz lj oa ln ob lr nt nu nv nw bi translated">加载模型。</li><li id="4f2a" class="no np iq ky b kz nx lc ny lf nz lj oa ln ob lr nt nu nv nw bi translated">当输入可用时，读取下一帧。</li><li id="92be" class="no np iq ky b kz nx lc ny lf nz lj oa ln ob lr nt nu nv nw bi translated">对框架进行评分，以获得标签和坐标。</li><li id="29e0" class="no np iq ky b kz nx lc ny lf nz lj oa ln ob lr nt nu nv nw bi translated">在探测到的物体上画出方框。</li><li id="e37a" class="no np iq ky b kz nx lc ny lf nz lj oa ln ob lr nt nu nv nw bi translated">将处理后的帧写入输出视频流。</li></ol><p id="86ea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">六个简单的操作步骤，虽然我们会添加一些基础设施代码来帮助我们使应用程序更加健壮，但基本原理是一样的。所以让我们开始吧。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="880c" class="mq lt iq nd b gy nh ni l nj nk">"""<br/>The Function below oracestrates the entire operation and performs the real-time parsing for video stream.<br/>"""<br/>def __call__(self):<br/>    player = self.get_video_stream() #Get your video stream.<br/>    assert player.isOpened() # Make sure that their is a stream. <br/>    #Below code creates a new video writer object to write our<br/>    #output stream.<br/>    x_shape = int(player.get(cv2.CAP_PROP_FRAME_WIDTH))<br/>    y_shape = int(player.get(cv2.CAP_PROP_FRAME_HEIGHT))<br/>    four_cc = cv2.VideoWriter_fourcc(*"MJPG") #Using MJPEG codex<br/>    out = cv2.VideoWriter(out_file, four_cc, 20, \<br/>                          (x_shape, y_shape)) <br/>    ret, frame = player.read() # Read the first frame.<br/>    while rect: # Run until stream is out of frames<br/>        start_time = time() # We would like to measure the FPS.<br/>        results = self.score_frame(frame) # Score the Frame<br/>        frame = self.plot_boxes(results, frame) # Plot the boxes.<br/>        end_time = time()<br/>        fps = 1/np.round(end_time - start_time, 3) #Measure the FPS.<br/>        print(f"Frames Per Second : {fps}")<br/>        out.write(frame) # Write the frame onto the output.<br/>        ret, frame = player.read() # Read next frame.</span></pre><p id="31f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您应该将所有这些组件打包到一个好的类中，该类可以与URL和您希望将输出流写入的输出文件一起被调用。您的最终产品将看起来像这样。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/777b6a2059361e516ac4e92a1cfd1dc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*e9eu2a2tZyI2qCfN.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">60 FPS的实时处理视频输出流。(图片由作者提供)</p></figure><h1 id="9eda" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="0ebe" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">当然，生产级别的实时应用程序要比这复杂得多，但是本指南并不打算教这个。它将向您展示Python的惊人威力，它允许我们在几个小时内构建如此复杂的应用程序原型。这里的可能性只受到你的想象力的限制。</p><p id="3f95" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以在我的<a class="ae kv" href="https://github.com/akash-agni" rel="noopener ugc nofollow" target="_blank"> Github </a>个人资料上查看完整的代码和更多这类令人敬畏的应用。</p><h2 id="2736" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">如果你喜欢这本指南。</h2><blockquote class="od oe of"><p id="4a46" class="kw kx og ky b kz la jr lb lc ld ju le oh lg lh li oi lk ll lm oj lo lp lq lr ij bi translated">留下评论让我知道你的想法。</p><p id="b45b" class="kw kx og ky b kz la jr lb lc ld ju le oh lg lh li oi lk ll lm oj lo lp lq lr ij bi translated">通过<a class="ae kv" href="https://twitter.com/agni_akash" rel="noopener ugc nofollow" target="_blank"> Twitter </a>、<a class="ae kv" href="https://www.linkedin.com/in/agni25/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>或<a class="ae kv" href="https://www.linkedin.com/in/agni25/" rel="noopener ugc nofollow" target="_blank"> Medium </a>与我联系。</p><p id="4e5b" class="kw kx og ky b kz la jr lb lc ld ju le oh lg lh li oi lk ll lm oj lo lp lq lr ij bi translated">与你的网络分享这篇文章。</p></blockquote><p id="d286" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">编码快乐！！</p></div></div>    
</body>
</html>