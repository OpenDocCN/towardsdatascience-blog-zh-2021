<html>
<head>
<title>How to use Transformer Networks to build a Forecasting model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用变压器网络建立预测模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-use-transformer-networks-to-build-a-forecasting-model-297f9270e630?source=collection_archive---------3-----------------------#2021-05-15">https://towardsdatascience.com/how-to-use-transformer-networks-to-build-a-forecasting-model-297f9270e630?source=collection_archive---------3-----------------------#2021-05-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="4b49" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="6fac" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">使用变压器和PyTorch训练预测模型</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/05f7f9a6393b6f3e80421e95cd8ed3f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u19R5vJjiJEuZvDM8VUQSQ.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@antoskli?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">安东尼·斯克里瓦科斯</a>在<a class="ae le" href="https://unsplash.com/s/photos/mountain-range?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="8331" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我最近读了一篇非常有趣的论文，叫做<a class="ae le" href="https://arxiv.org/pdf/2001.08317.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">时间序列预测的深度转换模型:流感流行案例</strong> </a> <strong class="lh ja">。</strong>我认为这可能是一个有趣的项目，从头实现类似的东西，以了解更多关于时间序列预测的信息。</p><h1 id="95f5" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">预测任务:</h1><p id="8f84" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">在时间序列预测中，目标是在给定历史值的情况下预测时间序列的未来值。时间序列预测任务的一些示例如下:</p><ul class=""><li id="c7fa" class="my mz iq lh b li lj ll lm lo na ls nb lw nc ma nd ne nf ng bi translated">预测流感流行案例:<a class="ae le" href="https://arxiv.org/pdf/2001.08317.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">时间序列预测的深度变换模型:流感流行案例</strong> </a> <strong class="lh ja"> e </strong></li><li id="fc4a" class="my mz iq lh b li nh ll ni lo nj ls nk lw nl ma nd ne nf ng bi translated">能源生产预测:<a class="ae le" href="https://arxiv.org/abs/2011.05519" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">能源消费预测采用堆叠式非参数贝叶斯方法</strong> </a></li><li id="30a7" class="my mz iq lh b li nh ll ni lo nj ls nk lw nl ma nd ne nf ng bi translated">天气预报:<a class="ae le" href="https://arxiv.org/abs/2003.12140" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja"> MetNet:降水预报的神经天气模型</strong> </a></li></ul><p id="d6ab" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">例如，我们可以存储一个城市几个月的能源消耗指标，然后训练一个模型，该模型将能够预测该城市未来的能源消耗。这可以用于估计能源需求，因此能源公司可以使用该模型来估计在任何给定时间需要生产的能源的最佳值。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/f97b7679aab83903960b3bee78a39534.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*BBXlFL2q_KibpFRJz78FIA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">时间序列预测示例</p></figure><h1 id="87b2" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">型号:</h1><p id="bead" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">我们将使用的模型是编码器-解码器转换器，其中编码器部分将时间序列的历史作为输入，而解码器部分以自回归方式预测未来值。</p><p id="6c5a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">解码器使用注意机制与编码器链接。通过这种方式，解码器可以在进行预测之前学会“关注”时间序列历史值中最有用的部分。</p><p id="2382" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">解码器使用掩蔽的自我关注，使得网络不能通过向前看并使用未来值来预测过去值而在训练期间作弊。</p><p id="8b41" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">编码器子网:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nn"><img src="../Images/be39337902923a274a1140056f9c445d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-TBbM8pqLIDzTV1D3kbJ4Q.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者提供的编码器/图像</p></figure><p id="972a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">解码器子网络:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi no"><img src="../Images/58172b45245e45eff7a21f08bb05ddcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0exIY1YFSFuANggL_ED9Ug.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者的解码器/图像</p></figure><p id="ac90" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">完整模型:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi np"><img src="../Images/840a3870c025bd522ee23aa220025818.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*uDEFRcm3BijnbMAPJQET_w.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">自回归编码器-解码器转换器/作者提供的图像</p></figure><p id="d406" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">可以使用PyTorch通过以下方式构建该架构:</p><pre class="kp kq kr ks gt nq nr ns nt aw nu bi"><span id="41d9" class="nv mc iq nr b gy nw nx l ny nz">encoder_layer = nn.TransformerEncoderLayer(<br/>    d_model=channels,<br/>    nhead=8,<br/>    dropout=self.dropout,<br/>    dim_feedforward=4 * channels,<br/>)<br/>decoder_layer = nn.TransformerDecoderLayer(<br/>    d_model=channels,<br/>    nhead=8,<br/>    dropout=self.dropout,<br/>    dim_feedforward=4 * channels,<br/>)<br/><br/>self.encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers=8)<br/>self.decoder = torch.nn.TransformerDecoder(decoder_layer, num_layers=8)</span></pre><h1 id="9daf" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">数据:</h1><p id="80cb" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">每次我实现一种新方法，我都喜欢先在合成数据上尝试，这样更容易理解和调试。这降低了数据的复杂性，并且更加关注实现/算法。</p><p id="d2cb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我编写了一个小脚本，可以生成具有不同周期、偏移量和模式的非平凡时间序列。</p><pre class="kp kq kr ks gt nq nr ns nt aw nu bi"><span id="4f01" class="nv mc iq nr b gy nw nx l ny nz">def generate_time_series(dataframe):<br/><br/>    clip_val = random.uniform(0.3, 1)<br/><br/>    period = random.choice(periods)<br/><br/>    phase = random.randint(-1000, 1000)<br/><br/>    dataframe["views"] = dataframe.apply(<br/>        lambda x: np.clip(<br/>            np.cos(x["index"] * 2 * np.pi / period + phase), -clip_val, clip_val<br/>        )<br/>        * x["amplitude"]<br/>        + x["offset"],<br/>        axis=1,<br/>    ) + np.random.normal(<br/>        0, dataframe["amplitude"].abs().max() / 10, size=(dataframe.shape[0],)<br/>    )<br/><br/>    return dataframe</span></pre><div class="kp kq kr ks gt ab cb"><figure class="oa kt ob oc od oe of paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/c749dc930179b843403ad984c6e92ceb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*VoKmpnYon5AKt4MFXfEFVA.png"/></div></figure><figure class="oa kt ob oc od oe of paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/0c26dd5f110b3a607920bf0ef61c788f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*y2_dfQCMs9fDwp8vA7-W9w.png"/></div></figure></div><div class="ab cb"><figure class="oa kt ob oc od oe of paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/04862e720c1e570eec5e8f2bd072bdf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*ZKZio5DaqV-tVmmlwwPkQA.png"/></div></figure><figure class="oa kt ob oc od oe of paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/69da8921b8b07d209f8fb7d253acd90d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*nLlMj_e8wrRidQ7b3ZqDNg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk og di oh oi translated">作者生成的时间序列/图像示例</p></figure></div><p id="9cfa" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后在<strong class="lh ja">对模型进行训练，所有这些时间序列同时进行</strong>:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oj"><img src="../Images/0c0db411e6f117e82b2ae1fcf815770c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rt4fFBV4wMptlw9hTI0osg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者培训损失/图像</p></figure><h1 id="5727" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">结果:</h1><p id="36b4" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">我们现在使用该模型对这些时间序列的未来值进行预测。结果有些复杂:</p><p id="2a07" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">坏消息:</p><div class="kp kq kr ks gt ab cb"><figure class="oa kt ob oc od oe of paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/6773983664758e86fe4c8457fb5d5797.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*UbI3cK3-TSp31TJO7KAaRQ.png"/></div></figure><figure class="oa kt ob oc od oe of paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/9d73ddb9f6890e489ddabfe12dbdb208.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*XwQ9pCzQiwSLkuSKYBBLcA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk og di oh oi translated">作者的错误预测/图片示例</p></figure></div><p id="493d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">优点:</p><div class="kp kq kr ks gt ab cb"><figure class="oa kt ob oc od oe of paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/09c67493192f2b0e743434864d115070.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*EXykLkAcIDEJDr5SC7loog.png"/></div></figure><figure class="oa kt ob oc od oe of paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/8cd1c9f73c9e53aa431cb8ca21fcb1f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*dyAHocm9GaaUNmvxZ50Fmw.png"/></div></figure></div><div class="ab cb"><figure class="oa kt ob oc od oe of paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/1586869f392286ed05564aee1fe29522.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*xxZY-YvkP1h9-_5O-d1Uow.png"/></div></figure><figure class="oa kt ob oc od oe of paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/4f9d775e2c9144e49c333fd8c767c4f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*oTFFsq1-Ba7mcAXsCwLUXg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk og di oh oi translated">作者的优秀预测/图像示例</p></figure></div><p id="81d4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">结果没有我预期的那么好，特别是考虑到对合成数据做出好的预测通常很容易，但它们仍然令人鼓舞。</p><p id="1233" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">该模型的预测有些异相，在一些糟糕的例子中略微高估了振幅。在好的例子中，预测与地面真实情况非常吻合，排除了噪声。</p><p id="16e9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我可能需要对我的代码进行更多的调试，并对超参数进行优化，然后才能期望获得更好的结果。</p><h1 id="0580" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">结论:</h1><p id="fe60" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">变压器目前是众多机器学习应用中非常受欢迎的模型，因此它们将用于时间序列预测是很自然的。</p><p id="fff3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在处理时间序列时，Transformers可能不是您的首选方法，因为它们可能很笨重且需要大量数据，但考虑到它们的多功能性和广泛的应用范围，它们很适合放在您的机器学习工具包中，从它们在NLP中的首次引入到音频处理、计算机视觉和时间序列。</p><p id="3795" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果您有任何问题或建议，请随时发表评论。</p><p id="d8de" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">https://github.com/CVxTz/time_series_forecasting<a class="ae le" href="https://github.com/CVxTz/time_series_forecasting" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>