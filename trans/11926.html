<html>
<head>
<title>5 Open Source Tools You Can Use to Train and Deploy an OCR Project</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">您可以使用5种开源工具来训练和部署OCR项目</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-open-source-tools-you-can-use-to-train-and-deploy-an-ocr-project-8f204dec862b?source=collection_archive---------2-----------------------#2021-11-30">https://towardsdatascience.com/5-open-source-tools-you-can-use-to-train-and-deploy-an-ocr-project-8f204dec862b?source=collection_archive---------2-----------------------#2021-11-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c3a2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">第一部分:如果你正在做文本检测，你应该知道这些工具</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7e0a6911e4b0bd73514c9421ca622d38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JcDPTmkDR8atVL2gq0GR7g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://www.pexels.com/photo/black-text-on-gray-background-261763/" rel="noopener ugc nofollow" target="_blank">pexels.com</a></p></figure><pre class="kj kk kl km gt kz la lb lc aw ld bi"><span id="22cb" class="le lf it la b gy lg lh l li lj"><span class="l lk ll lm bm ln lo lp lq lr di">P</span>art I  - 5 open-source tools you can use to train your own data and  deploy it for your next OCR project!<br/>Part II - From labelling to serving your OCR model! (Coming soon)</span></pre><p id="156b" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">在很多情况下，我们需要检测图像中的文本。</p><ol class=""><li id="8d3a" class="mo mp it lu b lv lw ly lz mb mq mf mr mj ms mn mt mu mv mw bi translated">为了实现运营数字化，银行需要将所有文书工作存储到云数据库中。为此，文档必须被扫描并转换成机器可读的格式。</li><li id="e4c3" class="mo mp it lu b lv mx ly my mb mz mf na mj nb mn mt mu mv mw bi translated">在房地产行业，购房者和代理商通常以纸质形式填写他们的协议表格。要在云中保存表格，你需要OCR软件，该软件将文本转换成机器可读的文件。</li><li id="a7c6" class="mo mp it lu b lv mx ly my mb mz mf na mj nb mn mt mu mv mw bi translated">在Edtech初创公司中，有一些严重依赖OCR。举个例子，<a class="ae ky" href="https://photomath.com/en/" rel="noopener ugc nofollow" target="_blank"> Photomath </a>，一家将问题分解成简单步骤来帮助人们理解数学的初创公司。该应用程序为用户提供了扫描他们在纸上的问题并通过扫描将其翻译成机器可读格式的便利。</li></ol><p id="9fa5" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">OCR可以使用传统的计算机视觉技术或更先进的深度学习技术来完成。本文的重点将只放在使用深度学习模型的工具上。作为奖励，我还将包括脚本，让您一次体验所有的模型。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="5046" class="nj lf it bd nk nl nm nn no np nq nr ns jz nt ka nu kc nv kd nw kf nx kg ny nz bi translated">EasyOCR</h1><div class="oa ob gp gr oc od"><a href="https://github.com/JaidedAI/EasyOCR" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">GitHub - JaidedAI/EasyOCR:支持80多种语言和所有流行文字的现成OCR</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">支持80多种语言和所有流行的书写文字，包括拉丁语、汉语、阿拉伯语…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">github.com</p></div></div><div class="om l"><div class="on l oo op oq om or ks od"/></div></div></a></div><p id="a619" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">EasyOCR是一款开源的、随时可用的OCR，支持近<a class="ae ky" href="https://www.jaided.ai/easyocr/" rel="noopener ugc nofollow" target="_blank"> 80种语言</a>。您可以选择用您自己的数据训练模型(您可以遵循他们的<a class="ae ky" href="https://www.jaided.ai/easyocr/modelhub/" rel="noopener ugc nofollow" target="_blank">示例数据集</a>来格式化您自己的数据集)或使用<a class="ae ky" href="https://www.jaided.ai/easyocr/modelhub/" rel="noopener ugc nofollow" target="_blank">现有模型</a>来为您自己的应用服务。</p><p id="fc92" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">以下脚本可用于运行代码:</p><pre class="kj kk kl km gt kz la lb lc aw ld bi"><span id="34f7" class="le lf it la b gy lg lh l li lj"># installation<br/>pip install easyocr</span><span id="42ef" class="le lf it la b gy os lh l li lj"># import<br/>import easyocr</span><span id="3191" class="le lf it la b gy os lh l li lj"># inference<br/>reader = easyocr.Reader(['en'])<br/>result = reader.readtext(img_path)</span></pre><p id="1890" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">这里有一个快速测试，看看这个OCR软件有多准确。下图来自pexels.com，OCR工具会检测图片中的文字。在一个完美的模型中，它应该能够输出“让这一天变得伟大！”。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/3f5b816af472fb62386d274d616c42d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kTYb9MGKKGW8c1_yc8uPYw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://www.pexels.com/@alexasfotos?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Alexas Fotos </a>从<a class="ae ky" href="https://www.pexels.com/photo/illuminated-qoute-board-2255441/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>拍摄</p></figure><p id="4145" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">结果如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ou ov l"/></div></figure><p id="fe69" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">你可以看到结果并不完美。它误解了字母G，把H误认为是小写字母H。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="f3b7" class="nj lf it bd nk nl nm nn no np nq nr ns jz nt ka nu kc nv kd nw kf nx kg ny nz bi translated">PaddleOCR</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/16b7cc658322ef587fc19cae19a6555a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8DMUM0GGqoaEubcX_eAtJQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.3/doc/imgs_results/ch_ppocr_mobile_v2.0/test_add_91.jpg" rel="noopener ugc nofollow" target="_blank">来源</a>。下<a class="ae ky" href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.3/LICENSE" rel="noopener ugc nofollow" target="_blank">阿帕奇牌照2.0 </a>。</p></figure><div class="oa ob gp gr oc od"><a href="https://github.com/PaddlePaddle/PaddleOCR" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">GitHub - PaddlePaddle/PaddleOCR:基于PaddlePaddle的超棒多语言OCR工具包(实用…</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">基于PaddlePaddle的超棒多语言OCR工具包(实用超轻量OCR系统，支持80多种语言…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">github.com</p></div></div><div class="om l"><div class="ox l oo op oq om or ks od"/></div></div></a></div><p id="eb20" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">PaddleOCR是中国百度团队开发的开源产品。我使用这个软件工具已经有一段时间了，我真的很惊讶这个团队做了多少工作来使这个免费的产品像市场上任何商业OCR软件一样强大。框架中使用的模型使用最先进的(SOTA)技术(如CML知识提炼和复制粘贴数据扩展策略)和大量打印和手写图像进行训练。这使得它成为最强大的开源OCR软件之一。下面是一些你可以用开源代码做的事情:</p><ol class=""><li id="3428" class="mo mp it lu b lv lw ly lz mb mq mf mr mj ms mn mt mu mv mw bi translated">您可以在您的应用程序中使用他们现有的模型。它们还提供了一个极其轻量级但功能强大的模型，称为PP-OCRv2，这样您就不需要担心大内存问题。</li><li id="ffce" class="mo mp it lu b lv mx ly my mb mz mf na mj nb mn mt mu mv mw bi translated">他们支持多种语言，如中文，英语，韩语，日语，德语等。</li><li id="a5d8" class="mo mp it lu b lv mx ly my mb mz mf na mj nb mn mt mu mv mw bi translated">他们有多种工具来支持您进行数据标注。例如，它们为您提供PPOCRLabel来快速标记图像中的文本。由于数据对于训练OCR模型非常重要，他们还有一个名为Style-text的工具，可以让您快速合成图像，以便您有更多的图像来训练您的模型，使其在生产环境中使用起来更加强大。</li><li id="1c7f" class="mo mp it lu b lv mx ly my mb mz mf na mj nb mn mt mu mv mw bi translated">您可以使用提供的脚本对数据集上的模型进行微调。</li></ol><p id="0f92" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">你可以这样使用它:</p><pre class="kj kk kl km gt kz la lb lc aw ld bi"><span id="8ed2" class="le lf it la b gy lg lh l li lj"># installation<br/>pip install paddleocr paddlepaddle</span><span id="87ea" class="le lf it la b gy os lh l li lj"># import<br/>from paddleocr import PaddleOCR</span><span id="f8e2" class="le lf it la b gy os lh l li lj"># inference<br/>ocr = PaddleOCR(use_angle_cls=True, lang='en')<br/>result = ocr.ocr(img_path, cls=True)</span></pre><p id="64ba" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">让我们使用上面的同一个图像来检查模型性能:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ou ov l"/></div></figure><p id="9cef" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">令人惊讶的是，从一个之前已经在类似图像上训练过的模型中看到如此精确的输出。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="f497" class="nj lf it bd nk nl nm nn no np nq nr ns jz nt ka nu kc nv kd nw kf nx kg ny nz bi translated">TrOCR</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/589e0af03afa54018be7d535f586e46b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gEBAWtOpVv47Wrs-"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://camo.githubusercontent.com/dd6287135427538254c94fe33edadcc1e810f30723c6edb93e733b8ae1c2cc7e/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f46414464545845566741417354574c3f666f726d61743d6a7067266e616d653d343039367834303936" rel="noopener ugc nofollow" target="_blank">来源</a>。根据麻省理工学院的许可。</p></figure><div class="oa ob gp gr oc od"><a href="https://huggingface.co/transformers/model_doc/trocr.html" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">TrOCR</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">PyTorch和TensorFlow 2.0的最先进的自然语言处理。变形金刚提供了成千上万的…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">huggingface.co</p></div></div><div class="om l"><div class="oz l oo op oq om or ks od"/></div></div></a></div><div class="oa ob gp gr oc od"><a href="https://github.com/microsoft/unilm/tree/6f60612e7cc86a2a1ae85c47231507a587ab4e01/trocr" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">unilm/trocr at 6f 60612 e 7c 86 a2 a1 AE 85c 47231507 a 587 ab 4 e 01 Microsoft/unilm</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">TrOCR是一种端到端的文本识别方法，具有预先训练的图像转换器和文本转换器模型，这些模型…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">github.com</p></div></div><div class="om l"><div class="pa l oo op oq om or ks od"/></div></div></a></div><p id="0fa6" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">TrOCR最初是由、吕腾超、等人在<a class="ae ky" href="https://arxiv.org/abs/2109.10282" rel="noopener ugc nofollow" target="_blank"> TrOCR:基于变压器的光学字符识别中提出的。它是基于图像转换器编码器和自回归文本解码器(类似于GPT-2)开发的。代码已经包含在著名的Huggingface库中，因此我们可以直接从库中使用训练好的模型。</a></p><pre class="kj kk kl km gt kz la lb lc aw ld bi"><span id="4814" class="le lf it la b gy lg lh l li lj"># installation<br/>pip install transformers</span><span id="a116" class="le lf it la b gy os lh l li lj"># import<br/>from transformers import TrOCRProcessor, VisionEncoderDecoderModel<br/>from PIL import Image</span><span id="6a03" class="le lf it la b gy os lh l li lj"># inference<br/>model_version = "microsoft/trocr-base-printed"<br/>processor = TrOCRProcessor.from_pretrained(model_version)<br/>model = VisionEncoderDecoderModel.from_pretrained(model_version)<br/><br/>image = Image.open(img_path).convert("RGB")<br/><br/>pixel_values = processor(image, return_tensors="pt").pixel_values<br/>generated_ids = model.generate(pixel_values)<br/>generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]</span></pre><p id="847b" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">与其他两个模型不同，这些模型只输出最终的文本输出，而不输出文本位置。该模型是用于文本识别的，所以你不应该期望它检测图像中的文本。运行上述脚本后，您将收到的输出是“MASKAY”。正如所料，结果很差，因为管道中没有文本检测模型。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="340c" class="nj lf it bd nk nl nm nn no np nq nr ns jz nt ka nu kc nv kd nw kf nx kg ny nz bi translated">MMOCR</h1><div class="oa ob gp gr oc od"><a href="https://github.com/open-mmlab/mmocr" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">GitHub-open-mmlab/mmocr:OpenMMLab文本检测、识别和理解工具箱</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk">English | 简体中文 MMOCR is an open-source toolbox based on PyTorch and mmdetection for text detection, text recognition…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">github.com</p></div></div><div class="om l"><div class="pb l oo op oq om or ks od"/></div></div></a></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/161c8d2d36c69ed15f35123cd24f74c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wvXQKczVXzKoNJ8I.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://github.com/open-mmlab/mmocr/blob/main/resources/illustration.jpg" rel="noopener ugc nofollow" target="_blank">来源</a>。下<a class="ae ky" href="https://github.com/open-mmlab/mmocr/blob/main/LICENSE" rel="noopener ugc nofollow" target="_blank">阿帕奇牌照2.0 </a>。</p></figure><p id="0dcb" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">MMOCR是另一个开源OCR工具，它是在著名的<a class="ae ky" href="https://openmmlab.com" rel="noopener ugc nofollow" target="_blank"> OpenMMLab </a>项目下开发的。该项目由香港中文大学的团队开发，已成为计算机视觉领域的领先项目之一。</p><p id="10a8" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">它支持多种SOTA模式，还允许您进行培训和部署。这个开源工具的亮点之一是它能够在同一管道中提供除其他模块(文本检测和识别)之外的关键信息提取模型。<a class="ae ky" href="https://arxiv.org/pdf/2103.14470.pdf" rel="noopener ugc nofollow" target="_blank">关键信息提取</a>解决了用户必须匹配某个模板才能从文档中提取数据的问题。传统的方法很难使用带有未知模板的文档。</p><p id="23bd" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">一旦我们安装了工具(是的，它没有前两个工具方便)，我们就可以用它来检测我们的样本图像并测试它的性能。我们得到与PaddleOCR类似的结果，只是感叹号没有出现在“GREAT”的末尾。总的来说，这个工具将几乎所有的东西都放在一个管道中，所以使用起来非常强大。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ou ov l"/></div></figure></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="a8cb" class="nj lf it bd nk nl nm nn no np nq nr ns jz nt ka nu kc nv kd nw kf nx kg ny nz bi translated">宇宙魔方光学字符识别</h1><div class="oa ob gp gr oc od"><a href="https://github.com/tesseract-ocr/tesseract" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">GitHub-tessera CT-ocr/tessera CT:tessera CT开源OCR引擎(主存储库)</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">这个包包含一个OCR引擎- libtesseract和一个命令行程序- tesseract。宇宙魔方4增加了一个新的…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">github.com</p></div></div><div class="om l"><div class="pc l oo op oq om or ks od"/></div></div></a></div><div class="oa ob gp gr oc od"><a href="https://pypi.org/project/pytesseract/" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">宇宙魔方</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">Python-tesseract是Python的光学字符识别(OCR)工具。也就是说，它会识别并“读取”…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">pypi.org</p></div></div><div class="om l"><div class="pd l oo op oq om or ks od"/></div></div></a></div><p id="9545" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">对于之前做过OCR项目的人来说，你应该对这个库非常熟悉。这里有一点关于宇宙魔方光学符的历史:</p><blockquote class="pe pf pg"><p id="6ad0" class="ls lt ph lu b lv lw ju lx ly lz jx ma pi mc md me pj mg mh mi pk mk ml mm mn im bi translated">Tesseract最初是由布里斯托尔的惠普实验室和科罗拉多州格里利的惠普公司在1985年到1994年间开发的，1996年做了一些修改以移植到Windows，1998年做了一些c++化。2005年，宇宙魔方被惠普开源。从2006年到2018年11月，它由谷歌开发。—来自<a class="ae ky" href="https://github.com/tesseract-ocr/tesseract" rel="noopener ugc nofollow" target="_blank">https://github.com/tesseract-ocr/tesseract</a></p></blockquote><p id="8e00" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">python-pytesserac是tesserac-OCR引擎的包装器。使用它非常简单。由于该模型自2019年12月26日以来一直没有更新，并且使用了一个非常简单的LSTM模型，因此结果可能不如该方法的其他部分理想。尽管如此，该模型可以使用新的数据进行<a class="ae ky" href="https://tesseract-ocr.github.io/tessdoc/" rel="noopener ugc nofollow" target="_blank">训练</a>，这样你就可以根据自己的需要对其进行定制。</p><p id="9fb5" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">为了测试这个工具，我使用了上面同样的图片。尽管用<a class="ae ky" href="https://opencv.org/" rel="noopener ugc nofollow" target="_blank"> OpenCV </a>对图像进行了预处理，我还是得到了一个空的结果。该工具似乎不能很好地处理场景中的文本。对于背景相对干净的普通文档，性能应该更好。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="797a" class="nj lf it bd nk nl nm nn no np nq nr ns jz nt ka nu kc nv kd nw kf nx kg ny nz bi translated">摘要</h1><p id="2f92" class="pw-post-body-paragraph ls lt it lu b lv pl ju lx ly pm jx ma mb pn md me mf po mh mi mj pp ml mm mn im bi translated">以下是不同开源OCR工具的比较:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/cf203a2b0cc7aeca31930c48a85a3717.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*BCqH6v03IeLzamuNuCcEqw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分类的表格</p></figure><p id="fd75" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">这个评级完全基于我自己对开源工具的体验。他们每个人都有自己的优势。我们的项目要求我们根据一组特定的需求选择正确的工具。</p><p id="db5a" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">如果你想试一试，这是Colab笔记本！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ou ov l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><h1 id="9a5c" class="nj lf it bd nk nl pr nn no np ps nr ns jz pt ka nu kc pu kd nw kf pv kg ny nz bi translated">下一步是什么？</h1><p id="6ffd" class="pw-post-body-paragraph ls lt it lu b lv pl ju lx ly pm jx ma mb pn md me mf po mh mi mj pp ml mm mn im bi translated">在为现实世界服务部署时，不能完全依赖开源工具。特别是对于一些应用，需要99%以上的准确率。为了实现这一点，我们可以从我们的业务中收集数据，并在训练开源工具之前对它们进行标记。我的下一步将向您展示Label Studio如何简化整个过程。从贴标签到服务模特，我全包了！</p><p id="a81c" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">如果您没有读过我的Label Studio文章，请在这里阅读:</p><div class="oa ob gp gr oc od"><a rel="noopener follow" target="_blank" href="/a-free-and-powerful-labelling-tool-every-data-scientist-should-know-ce66473c7557"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">每个数据科学家都应该知道的免费且强大的标签工具</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">我用过的最好的标签工具之一。</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">towardsdatascience.com</p></div></div><div class="om l"><div class="pw l oo op oq om or ks od"/></div></div></a></div><p id="d0ee" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">请关注我并喜欢我的帖子，以获得该系列的最新更新。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="ae35" class="nj lf it bd nk nl nm nn no np nq nr ns jz nt ka nu kc nv kd nw kf nx kg ny nz bi translated">关于作者</h1><p id="753d" class="pw-post-body-paragraph ls lt it lu b lv pl ju lx ly pm jx ma mb pn md me mf po mh mi mj pp ml mm mn im bi translated">Woen Yon是新加坡的一名数据科学家。他的经验包括为几家跨国企业开发先进的人工智能产品。</p><p id="85da" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">Woen Yon与一些聪明人合作，为当地和国际初创企业主提供网络解决方案，包括网络爬行服务和网站开发。他们非常清楚构建高质量软件的挑战。如果你需要帮助，请不要犹豫，给他发一封电子邮件到wushulai@live.com。</p><p id="697c" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">他喜欢交朋友！在<a class="ae ky" href="https://www.linkedin.com/in/woenyon/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae ky" href="https://laiwoenyon.medium.com/" rel="noopener"> Medium </a>上随时与他联系</p><div class="oa ob gp gr oc od"><a href="https://laiwoenyon.medium.com/" rel="noopener follow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">赖文渊-媒体</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">阅读赖文渊在媒体上的文章。数据科学家，TDS特约撰稿人。我喜欢结交来自世界各地的朋友…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">laiwoenyon.medium.com</p></div></div><div class="om l"><div class="px l oo op oq om or ks od"/></div></div></a></div></div></div>    
</body>
</html>