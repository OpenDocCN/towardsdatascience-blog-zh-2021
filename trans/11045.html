<html>
<head>
<title>An original method to combine regression estimators in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 中组合回归估计量的一种新颖方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-original-method-to-combine-regression-estimators-in-python-b9247141263?source=collection_archive---------33-----------------------#2021-10-27">https://towardsdatascience.com/an-original-method-to-combine-regression-estimators-in-python-b9247141263?source=collection_archive---------33-----------------------#2021-10-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9856" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">COBRA:一种非线性组合回归策略</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c8401a334cc164e4c881795f931d9778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cWFbdU5bwHo6apj3cxxGTg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自<a class="ae kv" href="https://pixabay.com/fr/vectors/diriger-serpent-orange-cobra-44803/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae kv" href="https://pixabay.com/fr/users/clker-free-vector-images-3736/" rel="noopener ugc nofollow" target="_blank"> Clker-Free-Vector-Images </a>的图像。</p></figure><p id="618f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在数据科学家有很多精确的机器学习算法。但是，选择最佳模型是一项复杂的任务，集成学习已经在实践中证明了它的有效性。在以前的帖子里:“<a class="ae kv" rel="noopener" target="_blank" href="/how-to-choose-the-best-model-cf74bf8015d8">如何选择最好的模特？</a>"和<a class="ae kv" rel="noopener" target="_blank" href="/how-to-deal-with-overlapping-rules-16bc0446af66">如何处理重叠规则？</a>“我已经提出了专家的聚合理论。一种应该更多地用于集成学习而不是简单平均的理论。在这里，我想把重点放在 COBRA 方法上，在[1]中提出。这种方法对于估计量的组合有一种非常不同的和新颖的方法。<em class="ls">为了简单起见，我不加区分地使用术语估计者、预测模型和专家。事实上，在回归设置中，回归函数的估计量可以用作预测模型，或者它可以用作对每个新观察值进行预测的专家。</em></p><p id="4fec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我回顾了专家聚集理论的主要框架。我们有一组专家，他们在每一次<em class="ls"> t </em>给我们一个目标<em class="ls"> yₜ.值的预测这个想法是聚集 k 位专家的预测来产生一个聚集预测ŷₜ.</em></p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="0216" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">COBRA <em class="ms">(组合回归备选)。</em></h1><h2 id="4416" class="mt mb iq bd mc mu mv dn mg mw mx dp mk lf my mz mm lj na nb mo ln nc nd mq ne bi translated">用手解释。</h2><p id="4e5c" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">通常，在专家聚集理论中，我们使用专家预测的凸组合来做出<em class="ls"> ŷ.</em>但是<em class="ls"> </em>眼镜蛇却有着截然不同的做法。它基于与<em class="ls">k-最近邻</em>算法相似的思想。每次<em class="ls"> t </em>我们都有一个新的观测值<em class="ls"> xₜ </em>，我们计算<em class="ls"> K </em>专家预测<em class="ls">{p₁(xₜ】</em><em class="ls">p₂(xₜ】</em>，…<em class="ls">pₖ(xₜ)}</em>。然后，想法是平均实现<em class="ls"> y </em>，<strong class="ky ir">未使用<em class="ls"> </em>来生成专家</strong>，这些专家在<em class="ls"> {p₁(xₜ) </em>，<em class="ls"> p₂(xₜ) </em>，…，<em class="ls"> pₖ(xₜ)} </em>的相同邻域(在欧几里德意义上)具有预测。在这些邻域中搜索实现的步骤被称为<em class="ls">共识步骤</em>。下面的例子将用来说明这个概念。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/f875375998778b3cdc1ef861275efdae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bbLszF5rlYydCQIyfIkjlQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">两个预测因子的 COBRA 聚合。图片来自作者。</p></figure><p id="1ac0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个例子中，我们有一个横坐标表示的特征<em class="ls"> x ∈ R </em>。<em class="ls"> y </em>的实现标记为黑色圆圈。我们有两个专家:第一个专家给出红色预测，第二个给出绿色预测。对于新的观测值<em class="ls"> x = 11 </em>，我们有预测值<em class="ls"> p ₜ </em>和<em class="ls"> p ₜ </em>。对于每个预测，形成一个邻域，用彩色虚线表示。然后，对邻域中所有预测的所有实现(标记为蓝色圆圈)进行平均，以计算<em class="ls"> ŷₜ </em>(蓝色菱形)。</p><h2 id="b513" class="mt mb iq bd mc mu mv dn mg mw mx dp mk lf my mz mm lj na nb mo ln nc nd mq ne bi translated">数学解释。</h2><p id="4ed1" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">形式上，COBRA 估计量如下。设<em class="ls"> Dₙ </em>为随机变量对<em class="ls">(</em><strong class="ky ir"><em class="ls">x</em></strong><em class="ls">，y)的<em class="ls"> n </em>个独立同分布观测值的一个样本。</em>样本分为两个独立的样本，<em class="ls"> Dₗ </em>和<em class="ls"> D </em> ₘ.然后，<em class="ls"> Dₗ </em>用于生成一组专家<em class="ls"> {p </em> ₁，<em class="ls"> p </em> ₂、…<em class="ls">pₖ}</em>和<em class="ls"> D </em> ₘ用于计算<em class="ls"> ŷₜ </em>、<em class="ls">t41】的组合预测值，用于一次新的观测<em class="ls"> xₜ </em>。我们有以下公式</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/147c10d912162e0850fbc26c1da15381.png" data-original-src="https://miro.medium.com/v2/resize:fit:346/format:webp/1*EC0_9COGCSzPKA3qd3dDkw.png"/></div></figure><p id="5cbf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中随机重量<em class="ls"> Wᵢ </em>采取的形式</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/72e19bac1e36d71269dc507c82c99ad5.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*90lEfe3-2z0wxykNZLZtdA.png"/></div></figure><p id="0947" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls"> ϵₘ </em>是平滑参数。ϵₘ<em class="ls">越大</em>，这个过程就越宽容。反之，如果<em class="ls"> ϵₘ </em>太小，许多专家就被抛弃。因此，其校准是至关重要的一步。为了克服这一步，作者在[1]的第三部分提出了一种数据相关校准。</p><p id="a2f4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些文字表达式表明，COBRA 与其他常用汇总方法的主要区别之一是，COBRA 相对于专家<em class="ls"> {p </em> ₁、<em class="ls"> p </em> ₂、…、<em class="ls"> pₖ}.来说是一种非线性方法</em>否则，从理论的角度来看，COBRA 也满足一个 oracle 界，该界表明，集合预测器的累积损失以专家组的最小累积损失为上界，直到一个向零衰减的残差项。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="25cb" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">Pycobra 图书馆</h1><p id="e027" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">Pycobra 是在[2]中引入的 Python 开源库。这个库不仅仅是 COBRA 聚合的一个实现。即便如此，用一种叫做 Python 的语言开发一种叫做 COBRA 的算法这一简单事实已经足够了。该库还包括[3]中详述的 EWA 算法(指数加权聚合)，以及受[4]启发的用于分类设置的 COBRA 版本<em class="ls"> ClassifierCobra </em>。这个包还包括一些可视化工具来衡量专家的表现。此外，一类<em class="ls">诊断</em>允许比较组成专家的不同组合和数据分割，以及其他基本参数。它允许更好的参数分析。最后，这个库可以在 GitHub <a class="ae kv" href="https://github.com/bhargavvader/pycobra" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="4a6c" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">结论</h1><p id="d42d" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">COBRA 是一种新颖的非线性集成学习方法，具有理论保证。第一篇论文的主要作者仍在致力于开发一个更好的版本，正如最近介绍内核版本的论文所示[5]。此外，该算法在开源 Python 库中可用，因此没有理由不在您的下一个数据科学项目或 Kaggle 挑战赛中尝试一下。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="d9a8" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">关于我们</h1><p id="a0ba" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated"><a class="ae kv" href="https://www.advestis.com/" rel="noopener ugc nofollow" target="_blank"> Advestis </a>是一家欧洲合同研究组织(CRO ),对统计学和可解释的机器学习技术有着深刻的理解和实践。Advestis 的专长包括复杂系统的建模和时间现象的预测分析。</p><p id="8050" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">领英</em>:<a class="ae kv" href="https://www.linkedin.com/company/advestis/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/company/advestis/</a></p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="56fc" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">参考</h1><p id="2ed4" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">[1] G.Biau，A.Fischer，B.Guedj &amp; J.D.Malley <a class="ae kv" href="https://www.sciencedirect.com/science/article/pii/S0047259X15000950" rel="noopener ugc nofollow" target="_blank"> COBRA:一种组合回归策略</a>。<em class="ls">多元分析杂志</em>146(2016):18–28。</p><p id="e213" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2] B.Guedj 和 B.Srinivasa Desikan <a class="ae kv" href="https://www.jmlr.org/papers/volume18/17-228/17-228.pdf" rel="noopener ugc nofollow" target="_blank"> Pycobra:用于集成学习和可视化的 python 工具箱</a>。<em class="ls">机器学习研究杂志</em>18.190(2018):1–5。</p><p id="4fb1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3] A. S.Dalalyan 和 A.B.Tsybakov <a class="ae kv" href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.106.9082&amp;rep=rep1&amp;type=pdf" rel="noopener ugc nofollow" target="_blank">通过指数加权和夏普甲骨文不等式进行聚合</a>。<em class="ls">计算学习理论国际会议</em>(2007):97–111。</p><p id="bb80" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[4] M.Mojirsheibani <a class="ae kv" href="https://www.tandfonline.com/doi/abs/10.1080/01621459.1999.10474154" rel="noopener ugc nofollow" target="_blank">通过离散化组合分类器</a>。<em class="ls">美国统计协会杂志</em> <em class="ls"> 94。446 (1999 年):600–609。</em></p><p id="8cb1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[5] B.Guedj 和 B . s . desikan .<a class="ae kv" href="https://www.mdpi.com/2078-2489/11/2/63" rel="noopener ugc nofollow" target="_blank">Python 中基于内核的集成学习</a>。<em class="ls">信息</em> 11，2 号(2020): 63。</p></div></div>    
</body>
</html>