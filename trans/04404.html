<html>
<head>
<title>Similarity Metrics in NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理中的相似性度量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/similarity-metrics-in-nlp-acc0777e234c?source=collection_archive---------13-----------------------#2021-04-14">https://towardsdatascience.com/similarity-metrics-in-nlp-acc0777e234c?source=collection_archive---------13-----------------------#2021-04-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8edf" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">欧几里德距离、点积和余弦相似度</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/fa2d148843550f2a43988f6e8133b733.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vjxvrsTNhJ92IF-N95uIOQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="f6d2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当我们将语言转换成机器可读的格式时，<em class="lu">标准的</em>方法是使用密集向量。</p><p id="b310" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">神经网络通常生成密集向量。它们允许我们将单词和句子转换成高维向量——组织起来使得每个向量的几何位置都可以赋予意义。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/c8e3b8ded96e18e4842a5ec20e5c7b3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CBxUXv7niY5hS9TH.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">众所周知的语言算术例子表明<strong class="bd lw">女王=国王——男人+女人</strong></p></figure><p id="501b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有一个特别有名的例子，我们取<em class="lu">国王</em>的向量，减去向量<em class="lu">男人</em>，加上向量<em class="lu">女人</em>。与合成向量最接近的匹配向量是<em class="lu">皇后</em>。</p><p id="d3c0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们也可以将同样的逻辑应用于更长的序列，比如句子或段落——我们会发现，相似的意思对应于这些向量之间的接近度/方向。</p><p id="f03d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以，相似性是很重要的——我们将在这里介绍计算相似性的三个最常用的指标。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="d5d2" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">欧几里得距离</h1><p id="e218" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated">欧几里德距离(通常称为L2范数)是最直观的度量。让我们定义三个向量:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl nb"><img src="../Images/659ba9178f8e4150740e6562544b0d46.png" data-original-src="https://miro.medium.com/v2/format:webp/1*zkJlmLrKyzSgae6PUypwxQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">三个向量示例</p></figure><p id="0138" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">仅仅通过观察这些向量，我们就可以自信地说<strong class="la iu"> a </strong>和<strong class="la iu"> b </strong>彼此更近——当我们在图表上可视化每个向量时，我们会看到这一点更加清晰:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl nb"><img src="../Images/ea0c7900c8f3e2b5c84b1e5956d14cf4.png" data-original-src="https://miro.medium.com/v2/format:webp/1*0PuxQcmsuL2pRVFJBt2cHA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">矢量<strong class="bd lw"> a </strong>和<strong class="bd lw"> b </strong>离原点很近，矢量<strong class="bd lw"> c </strong>远得多</p></figure><p id="ae24" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">显然，<strong class="la iu"> a </strong>和<strong class="la iu"> b </strong>靠得更近，我们使用欧几里得距离计算:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl nb"><img src="../Images/5d300f134569a9eefeb99029fd895106.png" data-original-src="https://miro.medium.com/v2/format:webp/1*X5MMsxJauDXDh3RKnJKWLQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">欧几里德距离公式</p></figure><p id="dc32" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了将这个公式应用于我们的两个向量，<strong class="la iu"> a </strong>和<strong class="la iu"> b，</strong>我们做:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl nb"><img src="../Images/2514276b073bf698994346827b4a08a7.png" data-original-src="https://miro.medium.com/v2/format:webp/1*nvG_GpVyjMUcMz5R7M7xHA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">计算矢量<strong class="bd lw"> a </strong>和<strong class="bd lw"> b </strong>之间的欧几里德距离</p></figure><p id="cc5a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">并且我们得到距离<strong class="la iu"> 0.014 </strong>，对<strong class="la iu"> d(a，c) </strong>返回<strong class="la iu"> 1.145 </strong>，<strong class="la iu"> d(b，c) </strong>返回<strong class="la iu"> 1.136 </strong>进行同样的计算。显然，<strong class="la iu"> a </strong>和<strong class="la iu"> b </strong>在欧氏空间中更近。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="5320" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">点积</h1><p id="e1dc" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated">欧几里得距离的一个缺点是在计算中没有考虑方向，它仅仅基于大小。这是我们可以使用其他两个指标的地方。第一个是点积。</p><p id="0768" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">点积考虑方向(方位),也与矢量幅度成比例。</p><p id="96b4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们关心方向，因为相似的意思(我们经常会发现)可以用向量的方向来表示——不一定是向量的大小。</p><p id="0337" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，我们可能会发现向量的大小与它在数据集中代表的单词的频率相关。现在，单词<strong class="la iu"> hi </strong>的意思与<strong class="la iu"> hello </strong>相同，如果我们的训练数据包含单词<strong class="la iu"> hi </strong> 1000次，而<strong class="la iu"> hello </strong>只有两次，这可能不会被表示出来。</p><p id="93e4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，向量的方向通常被认为和距离一样重要(如果不是更重要的话)。</p><p id="962c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">点积的计算公式如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/4b449da227a9d2d4cc676b09ab027d1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*928VGLCFwRwaFnIu-Ptxfg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">点积公式</p></figure><p id="e773" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">点积考虑向量之间的角度，其中角度为~0，公式的<strong class="la iu"> cosθ </strong>分量等于~1。如果角度接近90度(正交/垂直)，则<strong class="la iu"> cosθ </strong>分量等于~0度，而在180度时<strong class="la iu"> cosθ </strong>分量等于~-1度。</p><p id="e5f5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，<strong class="la iu"> cosθ </strong>分量增加了两个向量之间角度较小的结果。因此，更高的点积与更高的方向相关。</p><p id="4da2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">同样，让我们将这个公式应用于我们的两个向量，<strong class="la iu"> a </strong>和<strong class="la iu"> b </strong>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/ed390a3538b8a9ae13ad4fab761b322e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GEXd3-OOXouzqjiWCCaXZA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">计算矢量<strong class="bd lw"> a </strong>和<strong class="bd lw"> b </strong>的点积</p></figure><p id="7513" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">显然，点积计算很简单(三者中最简单的)，这在计算时间方面给我们带来了好处。</p><p id="8d98" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，有一个缺点。它不是归一化的，这意味着较大的矢量倾向于获得较高的点积，尽管不太相似。</p><p id="e6fa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，如果我们计算<strong class="la iu">a a</strong>——我们会期望比<strong class="la iu"> a c </strong>更高的分数(<strong class="la iu"> a </strong>与<strong class="la iu"> a </strong>完全匹配)。但不幸的是，事情并非如此。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/dad90c381f3dd6a28f8aa30a1356ab38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J3wa5uDstM57pFHSpMUl9w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">当向量大小不同时，点积就没那么大了。</p></figure><p id="df78" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，实际上，点积用于确定两个向量的大致方向，因为:</p><ul class=""><li id="e834" class="nf ng it la b lb lc le lf lh nh ll ni lp nj lt nk nl nm nn bi translated">指向相似方向的两个向量返回一个正的<strong class="la iu">点积。</strong></li><li id="f430" class="nf ng it la b lb no le np lh nq ll nr lp ns lt nk nl nm nn bi translated">两个垂直向量返回<strong class="la iu">零</strong>的点积。</li><li id="f2b3" class="nf ng it la b lb no le np lh nq ll nr lp ns lt nk nl nm nn bi translated">指向相反方向的向量返回一个负的点积。</li></ul></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="4eeb" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">余弦相似性</h1><p id="0286" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated">余弦相似性考虑矢量方向，与矢量大小无关。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/cb1b7975e8908c6945492f4e6d6cb646.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BJq5ZVsO4rpYTsmV9pIGUQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">余弦相似公式</p></figure><p id="cc65" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个公式中，我们应该注意的第一件事是，分子实际上是点积——它同时考虑了<em class="lu">大小</em>和<em class="lu">方向</em>。</p><p id="1659" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在分母中，我们有奇怪的双竖线——这意味着<em class="lu">‘长度’</em>。因此，我们将<strong class="la iu"> u </strong>的长度乘以<strong class="la iu"> v </strong>的长度。长度当然要考虑<em class="lu">量级</em>。</p><p id="ae66" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当我们采用一个考虑<em class="lu">大小</em>和<em class="lu">方向</em>的函数，并将其除以一个只考虑<em class="lu">大小</em>的函数时，这两个<em class="lu">大小</em>相互抵消，留给我们一个考虑<em class="lu">方向</em> <strong class="la iu">与大小</strong>无关的函数。</p><p id="7119" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以把余弦相似度看成是<em class="lu">归一化</em>点积！这显然是有效的。<strong class="la iu"> a </strong>和<strong class="la iu"> b </strong>的余弦相似度接近<strong class="la iu"> 1 </strong>(完美):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/501b43a720ced970bd4ce7d2107dcfde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SWK3921MItHvJEoefHhJsw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">计算向量<strong class="bd lw"> a </strong>和<strong class="bd lw"> b </strong>的余弦相似度</p></figure><p id="eed5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">并且使用余弦相似性的<code class="fe nv nw nx ny b">sklearn</code>实现来比较<strong class="la iu"> a </strong>和<strong class="la iu"> c </strong>再次给我们更好的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/442a0c745ebb894b9c08f918f76f3996.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5vhMrw6lgUGQj9HtYb5W1w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">余弦相似度通常可以提供比点积更好的结果。</p></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><p id="9dfc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就是本文涵盖三个距离/相似性度量的全部内容——欧几里德距离、点积和余弦相似性。</p><p id="2402" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">了解每种方法的工作原理及其优缺点是值得的，因为它们都被大量用于机器学习，尤其是NLP。</p><p id="d6b5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以在本笔记本中找到每个指标的Python实现。</p><p id="462d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我希望你喜欢这篇文章。如果您有任何问题或建议，请通过<a class="ae oa" href="https://twitter.com/jamescalam" rel="noopener ugc nofollow" target="_blank"> Twitter </a>或在下面的评论中告诉我。如果你对更多类似的内容感兴趣，我也会在YouTube上发布。</p><p id="3d8e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢阅读！</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="04e4" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">来源</h1><p id="f9d0" class="pw-post-body-paragraph ky kz it la b lb mw ju ld le mx jx lg lh my lj lk ll mz ln lo lp na lr ls lt im bi translated"><a class="ae oa" href="https://bit.ly/nlp-transformers" rel="noopener ugc nofollow" target="_blank">🤖带变压器的NLP课程</a></p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><p id="165d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">*所有图片均由作者提供，除非另有说明</em></p></div></div>    
</body>
</html>