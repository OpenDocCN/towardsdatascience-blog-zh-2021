<html>
<head>
<title>Testing PySpark DataFrame transformations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">测试PySpark数据帧转换</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/testing-pyspark-dataframe-transformations-d3d16c798a84?source=collection_archive---------12-----------------------#2021-06-09">https://towardsdatascience.com/testing-pyspark-dataframe-transformations-d3d16c798a84?source=collection_archive---------12-----------------------#2021-06-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6458" class="pw-subtitle-paragraph jo ip iq bd b jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf dk translated">提高开发到生产的速度，并确保您的代码在部署之前符合质量标准。</h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/daf443ec9fbf96d754ce0e02dfaf2555.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BJePvx2y_S6464UK"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">杰里米·帕金斯在<a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="b640" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如果你喜欢测试——不是写很多测试和测试的有用性，那么你来对地方了。我大多用<em class="lt"> Scala </em>写<em class="lt"> Spark </em>代码，但是我看到<strong class="kz ir"> <em class="lt"> PySpark </em> </strong>越来越占优势。不幸的是，在用<em class="lt"> Python </em>开发<em class="lt"> Spark </em>代码时，我经常看到较少的测试。我认为单元测试<em class="lt"> PySpark </em>代码甚至比<em class="lt"> Spark-Scala </em>代码(<a class="ae kw" href="https://medium.com/codex/how-to-easily-test-spark-dataframe-transformations-3b8cc160a705" rel="noopener"> <em class="lt">单元测试</em> <em class="lt"> Spark-Scala </em> </a>)更容易。让我们看一个例子，看看对数据帧转换进行单元测试有多容易。</p><h2 id="2eaf" class="lu lv iq bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated">数据集</h2><p id="80cd" class="pw-post-body-paragraph kx ky iq kz b la mn js lc ld mo jv lf lg mp li lj lk mq lm ln lo mr lq lr ls ij bi translated">我们将设想一个简单的数据集，但是它非常大，以至于在集成开发环境(IDE)中用小得多的数据来测试我们的转换更加方便。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ms"><img src="../Images/a29f7b1dc3bcb396fbcb6d30740698a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hwj8xyUv3GqMVb7HFLqi_g.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">包含员工数据的样本数据集</p></figure><h2 id="59e5" class="lu lv iq bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated">任务</h2><p id="1b25" class="pw-post-body-paragraph kx ky iq kz b la mn js lc ld mo jv lf lg mp li lj lk mq lm ln lo mr lq lr ls ij bi translated">不要太复杂，让我们假设雇员数据集<em class="lt"> id </em>列包含雇员年龄，我们需要将其提取到一个名为<em class="lt"> age </em>的单独列中。员工的年龄由破折号(“-”)前的数字表示。</p><h2 id="111b" class="lu lv iq bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated">解决方案</h2><p id="0b38" class="pw-post-body-paragraph kx ky iq kz b la mn js lc ld mo jv lf lg mp li lj lk mq lm ln lo mr lq lr ls ij bi translated">为此，我们需要提取破折号前的数字。有两种方法可以做到这一点——要么使用正则表达式(regex ),要么用破折号分割列值。让我们在这个例子中使用正则表达式来提取年龄:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="f807" class="lu lv iq mu b gy my mz l na nb">\d+(?=-)</span></pre><ul class=""><li id="b1cd" class="nc nd iq kz b la lb ld le lg ne lk nf lo ng ls nh ni nj nk bi translated"><strong class="kz ir"> \d </strong>匹配任何数字字符(0–9)。</li><li id="7a5d" class="nc nd iq kz b la nl ld nm lg nn lk no lo np ls nh ni nj nk bi translated"><strong class="kz ir"> + </strong>是一个量词，用于匹配1个或多个此类字符(数字)。</li><li id="4bca" class="nc nd iq kz b la nl ld nm lg nn lk no lo np ls nh ni nj nk bi translated"><strong class="kz ir">(？=-) </strong>匹配主表达式后的一个组，但不包括在结果中的破折号符号后。</li></ul><p id="2e18" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">为了在我们的转换中使用这个正则表达式，我们将编写一个简单的函数，该函数接受一个数据帧和雇员id列的名称，但返回一个全新的数据帧和<em class="lt">年龄</em>列:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="eb6a" class="lu lv iq mu b gy my mz l na nb">def extract_age_func(input_df: DataFrame, id_col: str):<br/>    pattern = '\d+(?=-)'<br/>    return input_df.withColumn('age', regexp_extract(col(id_col), pattern, 0))</span></pre><h2 id="4d9d" class="lu lv iq bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated">测试设置</h2><p id="8f1f" class="pw-post-body-paragraph kx ky iq kz b la mn js lc ld mo jv lf lg mp li lj lk mq lm ln lo mr lq lr ls ij bi translated">现在继续测试——我们将使用一个更流行的<em class="lt"> Python </em>标准库包<em class="lt"> unittest </em>。关于<em class="lt"> unittest </em>的伟大之处在于它很容易创建一个可重用的<em class="lt"> SparkSession </em>。让我们首先编写一些<em class="lt"> SparkSession </em>初始化代码，我们可以在所有的测试中重用这些代码:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="776a" class="lu lv iq mu b gy my mz l na nb">class PySparkTestCase(unittest.TestCase):<br/>    <em class="lt">"""Set-up of global test SparkSession"""<br/><br/>    </em>@classmethod<br/>    def setUpClass(cls):<br/>        cls.spark = (SparkSession<br/>                     .builder<br/>                     .master("local[1]")<br/>                     .appName("PySpark unit test")<br/>                     .getOrCreate())<br/><br/>    @classmethod<br/>    def tearDownClass(cls):<br/>        cls.spark.stop()</span></pre><p id="1add" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这里我们创建了类<em class="lt"> PySparkTestCase() </em>，它扩展了<em class="lt"> unittest。TestCase </em>类并有两个类方法:</p><ul class=""><li id="5a03" class="nc nd iq kz b la lb ld le lg ne lk nf lo ng ls nh ni nj nk bi translated"><strong class="kz ir"> setUpClass() </strong> — <em class="lt">“在类中运行测试之前设置类夹具的挂钩方法。”</em>确保不要使用<code class="fe nq nr ns mu b">setUp</code>而不是<code class="fe nq nr ns mu b">setUpClass</code>来初始化每个测试的新<em class="lt">火花会话</em>。这里我们设置<em class="lt"> SparkSession </em>在一个线程上本地运行。</li><li id="67a1" class="nc nd iq kz b la nl ld nm lg nn lk no lo np ls nh ni nj nk bi translated"><strong class="kz ir"> tearDownClass() </strong> — <em class="lt">“测试后解构测试夹具的挂钩方法。”</em>测试运行后，我们指定停止我们的<em class="lt"> SparkSession </em>。</li></ul><p id="7e9a" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在开始编写我们的测试之前，我们必须了解在进行<em class="lt">数据帧</em>转换时需要测试什么。从<em class="lt">数据框架</em>的角度来看，有两件事——<em class="lt">数据框架</em>T26】模式测试和<em class="lt">数据框架</em>T30】数据测试。让我们创建帮助器函数来完成这个任务:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="4a30" class="lu lv iq mu b gy my mz l na nb">def<strong class="mu ir"> </strong>test_schema(df1: DataFrame, df2: DataFrame, check_nullable=True):<em class="lt"><br/>    </em>field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)<br/>    fields1 = [*map(field_list, df1.schema.fields)]<br/>    fields2 = [*map(field_list, df2.schema.fields)]<br/>    if check_nullable:<br/>        res = set(fields1) == set(fields2)<br/>    else:<br/>        res = set([field[:-1] for field in fields1]) == set([field[:-1] for field in fields2])<br/>    return res</span></pre><p id="1554" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">和</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="c684" class="lu lv iq mu b gy my mz l na nb">def test_data(df1: DataFrame, df2: DataFrame):<em class="lt"><br/>    </em>data1 = df1.collect()<br/>    data2 = df2.collect()<br/>    return set(data1) == set(data2)</span></pre><ul class=""><li id="78fb" class="nc nd iq kz b la lb ld le lg ne lk nf lo ng ls nh ni nj nk bi translated"><strong class="kz ir"><em class="lt">test _ schema()</em></strong>—获取两个<em class="lt">数据帧</em>，比较它们之间是否存在模式差异。如果模式与函数匹配，则返回<em class="lt">真</em>否则<em class="lt">假</em>。此外，还有一个是否检查列可空性的标志，因为这并不总是需要的，有时管理起来会很繁琐。</li><li id="23fd" class="nc nd iq kz b la nl ld nm lg nn lk no lo np ls nh ni nj nk bi translated"><strong class="kz ir"><em class="lt">test _ data()</em></strong>—也获取两个<em class="lt">数据帧</em>并检查那些<em class="lt">数据帧</em>中的数据是否匹配—如果匹配则返回<em class="lt">真</em>，如果不匹配则返回<em class="lt">假</em>。</li></ul><h2 id="ff0f" class="lu lv iq bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated">测试案例</h2><p id="66d8" class="pw-post-body-paragraph kx ky iq kz b la mn js lc ld mo jv lf lg mp li lj lk mq lm ln lo mr lq lr ls ij bi translated">太好了，我们现在有助手函数来检查<em class="lt">数据帧</em>是否相等。让我们为我们的<em class="lt">数据帧</em>转换函数<em class="lt"> extract_age_func() </em>编写测试:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="964e" class="lu lv iq mu b gy my mz l na nb">class SimpleTestCase(PySparkTestCase):<br/><br/>    def test_dataparser_schema(self):<br/>        input_df = self.spark.createDataFrame(<br/>            data=[['Jan', 'Janson', 'jj@email.com', '20-504123'],<br/>                  ['Jen', 'Jenny', 'jen@email.com', '55-357378'],<br/>                  ['Bill', 'Bill', 'bill@email.com', '79-357378']],<br/>            schema=['first_name', 'last_name', 'email', 'id'])<br/><br/>        transformed_df = extract_age_func(input_df, "id")<br/><br/>        expected_df = self.spark.createDataFrame(<br/>            data=[['Jan', 'Janson', 'jj@email.com', '20-504123', '20'],<br/>                  ['Jen', 'Jenny', 'jen@email.com', '55-357378', '55'],<br/>                  ['Bill', 'Bill', 'bill@email.com', '79-357378', '79']],<br/>            schema=['first_name', 'last_name', 'email', 'id', 'age'])<br/><br/>        self.assertTrue(test_schema(transformed_df, expected_df))</span></pre><p id="8621" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">方法非常简单——我们在我们的测试用例中创建一个输入数据帧,并通过我们的转换函数运行它，将它与我们预期的<em class="lt">数据帧</em>进行比较。类似地，对于数据比较测试:</p><pre class="kh ki kj kk gt mt mu mv mw aw mx bi"><span id="8edd" class="lu lv iq mu b gy my mz l na nb">def test_dataparser_data(self):<br/>    input_df = self.spark.createDataFrame(<br/>        data=[['Jan', 'Janson', 'jj@email.com', '20-504123'],<br/>              ['Jen', 'Jenny', 'jen@email.com', '55-357378'],<br/>              ['Bill', 'Bill', 'bill@email.com', '79-357378']],<br/>        schema=['first_name', 'last_name', 'email', 'id'])<br/><br/>    transformed_df = extract_age_func(input_df, "id")<br/><br/>    expected_df = self.spark.createDataFrame(<br/>        data=[['Jan', 'Janson', 'jj@email.com', '20-504123', '20'],<br/>              ['Jen', 'Jenny', 'jen@email.com', '55-357378', '55'],<br/>              ['Bill', 'Bill', 'bill@email.com', '79-357378', '79']],<br/>        schema=['first_name', 'last_name', 'email', 'id', 'age'])<br/><br/>    self.assertTrue(test_data(transformed_df, expected_df))</span></pre><p id="25b8" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在这里，你也可以从一个单独的数据文件如<em class="lt">创建输入<em class="lt">数据帧</em>。csv </em>或<em class="lt">。如果方便的话。或者像我通常做的那样——在测试用例中创建，但是注意不要将敏感信息放入代码库中。</em></p><p id="5ed0" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">现在让我们运行这些测试，检查我们的年龄提取转换是否如预期的那样工作。我将使用<em class="lt"> PyCharm </em>来运行这些测试:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nt"><img src="../Images/c057e82c8c84308e183724858acb8249.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PmNToYjLTXc9Jx_XDCbIOQ.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">为<em class="jn"> PySpark </em>转换运行我们的单元测试。</p></figure><p id="aefc" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">很好，看起来我们的年龄提取转换像预期的那样工作。在我们的IDE中运行这些测试的好处是，我们还可以在代码中设置断点，并看到我们的转换或测试逐步执行:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nt"><img src="../Images/9cef12e9acc0f52f960d650cd13536ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vdI0-rwx3XqjW-KDn2LQfw.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">使用断点在调试中运行测试</p></figure><h2 id="f93b" class="lu lv iq bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated">结论</h2><p id="7125" class="pw-post-body-paragraph kx ky iq kz b la mn js lc ld mo jv lf lg mp li lj lk mq lm ln lo mr lq lr ls ij bi translated">这就是开始测试您的<em class="lt"> PySpark </em>转换所需要的全部内容。如您所见，在您的IDE中进行本地测试所需的时间比打包、将其发送到您的测试环境并等待您的集群启动所需的时间要少得多。IDE的调试功能非常方便，如果您愿意，可以一步一步地剖析您的转换。</p><p id="4817" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我希望这为开始编写自己的测试打下了良好的基础。祝你好运！</p><p id="c994" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">代码可在<a class="ae kw" href="https://github.com/Bigdataengr/unittest_pyspark" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上获得。</p></div></div>    
</body>
</html>