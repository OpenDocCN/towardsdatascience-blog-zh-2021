<html>
<head>
<title>Engineering Intuitive Computer Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">工程直观计算机视觉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/programming-an-intuitive-image-classifier-part-1-266bd657aa4?source=collection_archive---------13-----------------------#2021-09-15">https://towardsdatascience.com/programming-an-intuitive-image-classifier-part-1-266bd657aa4?source=collection_archive---------13-----------------------#2021-09-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="e814" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">动手教程</a>，<em class="iy">比人工更智能</em></h2><div class=""/><div class=""><h2 id="9af5" class="pw-subtitle-paragraph jx ja iq bd b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko dk translated"><em class="iy">我们如何才能创建一个像人类一样做出决策和预测的图像分类系统？</em></h2></div><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/d660c3b3a180e34252fbaf99eb684013.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BdvWjeDTJsMnaqaj"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">照片由<a class="ae lf" href="https://unsplash.com/@maximalfocus?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">最大聚焦</a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">未飞溅</a>上拍摄</p></figure></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="647b" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">图像分类是机器学习、数据科学和人工智能的最热门领域之一，通常用于测试某些类型的人工智能算法——从逻辑回归到深度神经网络。</p><p id="506e" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">但是现在，我想把你的注意力从这些热门技术上移开，问我们自己一个问题:如果我们人类看到一个手写字符的图像，或者一只狗或猫，我们的大脑如何直观地分类不同类型的图像？以下是图像中数字的示例；“2”、“0”、“1”和“9”。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mk"><img src="../Images/725ce23b1d3fc18acc4785a415baeadc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8A_EfkvyxafZjdv7"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">照片由<a class="ae lf" href="https://unsplash.com/@nordwood?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">诺德伍德主题</a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="0c16" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在上面的数字例子中，我们的大脑如何区分底部的1和9呢？嗯，直觉上，我们的大脑对1的样子有一种“心智模型”，对9的样子也有一种心智模型。对于一个数字的新图像，我们的大脑可以根据每个心理模型来比较这个数字，并决定它是1、9还是完全不同的手写字符。事实上，我们的心智模型不仅仅可以分类:它可以<em class="mj">生成</em>相似数据的新实例。第一次给小孩子看数字，这样他们的大脑可以形成一个心理模型，我很肯定他们可以学会画出新的数字，比如1或9，或者上面照片中的其他数字。</p><p id="4d3c" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">现在<em class="mj">这种</em>类型的决策、分类，与你在摄像机、医院等世界各地部署的流行人工智能视觉系统中看到的截然不同。——那些依赖于卷积深度学习的东西——<a class="ae lf" href="https://poloclub.github.io/cnn-explainer/" rel="noopener ugc nofollow" target="_blank">看看这个视觉演示。</a>虽然卷积神经网络(CNN)的卷积层可能类似于我们眼中视觉系统的特定部分<a class="ae lf" href="https://www.nature.com/articles/srep32672" rel="noopener ugc nofollow" target="_blank">根据作者</a>的说法，深度CNN网络的实际决策主要来自网络前馈“最终完全连接层”中成千上万的调谐权重。</p><p id="a84d" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">顺便说一句，如果你没有听说过神经网络或者不熟悉神经网络是如何用于图像分类的，我绝对<a class="ae lf" href="https://www.youtube.com/watch?v=aircAruvnKk&amp;t=985s" rel="noopener ugc nofollow" target="_blank">推荐3Blue1Brown (3b1b) Youtube频道上格兰特·桑德森</a>的这个视频；他的阐述和解释非常精彩。</p><p id="c5ab" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">但是我们将要设计的决定和分类数字的ML系统将不会像人工神经网络那样包含成千上万的权重和参数。</p><p id="1173" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在我们继续之前，我们需要弄清楚数字在计算机中的“心智模型”是什么样的。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="738d" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><strong class="lp jb">什么是大脑相对于计算机的“心智模型”？</strong></p><p id="e83e" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">简而言之，大脑中的实际心理模型——嗯，我们仍在研究中。关于大脑，我们还有很多不了解的地方，神经科学家、认知科学家和其他人有很多共同之处。</p><p id="95b8" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">然而，越来越多的理论认为大脑中的心智模型在计算上与T10相似。计算神经科学家Karl Friston的这篇文章更多地讨论了大脑如何“调用一个内部的、精神的世界生成模型”来推断和预测从身体其他部分(包括视觉系统)接收到的感觉信号背后的原因的计算理论。在这个理论中，大脑基本上必须根据它拥有的心理模型来推断感觉的原因，关于哪些可能的原因导致可能的身体感知。弗里斯顿还提到，像这样的计算模型已经预测了广泛的真实生物生理和行为现象。我省略了一堆细节，如果你感兴趣，可以看看这篇文章:)</p><p id="130c" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在我们的机器学习案例中，谢天谢地，我们不必处理所有的身体感觉——只是屏幕上的28x28黑白图像。但这仍然是一个具有挑战性的问题！——否则计算机视觉早就“解决”了。所以现在的问题仍然是:在某种意义上，我们如何创建一个“心理生成模型”，让计算机能够将其作为一个对象保存在内存中？</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="f49a" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><strong class="lp jb">作为“分布”的生成模型</strong></p><p id="1235" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">之前我说过一个“心智模型”，或者说一个生成模型，如何让你基本上创建类似数据的<em class="mj">新</em>实例。如果我在比如数字2上训练一个生成模型，那么计算机将能够画出2的新实例。拥有一个创建这些实例的模型就像一个粗略的蓝图:它允许你填充细节并创建房屋、建筑等的不同实例。这个“粗略的蓝图”被称为<em class="mj">分布</em>，因为，直觉上，你基本上是在生成新数据的集合——而分布只是集合的另一个词。专业术语称之为“<em class="mj">概率分布</em>”(别担心，我不会重温统计职业的恐怖！)因为在您生成的集合中，有些样本比其他样本更有可能。例如，如果计算机正在生成“2”的新实例，那么顶部缺少“弯钩”的2的样本将被计算为“不太可能像”2，而不是如果它有2。不太可能只是意味着模型产生的2比通常的a 2看起来要少<em class="mj"/>。</p><p id="1059" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">用机器学习的语言来看待生成模型的另一种方式是，它们创建“聚类”的模型——它们帮助将数据聚类到特定的区域。这将被称为“无监督学习”——在没有任何训练标签来教导机器的情况下推断数据<em class="mj">中的结构。</em></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ml"><img src="../Images/099b40d78c6ed58a5c98b7cf8151d51d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4X1X4fv3PUdF1iX_"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">美国宇航局在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片。看到上图中城市灯光的某些“簇”是如何聚集在一起的了吗？生成模型将能够为用户提供一个“蓝图模型”,显示城市和农村地区的光照分布情况。</p></figure><p id="7c5b" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">既然我们知道生成模型是分布，我们首先需要做的是看看如何在数字类型(0，1，2，..9).在Python的<em class="mj"> sci-kit learn </em>库中，有一个名为<em class="mj">密度估计模型</em>的函数可以帮助我们。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="0c22" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">分类的最后一步:推理</p><p id="c0e4" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">现在，我们的计算机为每种类型的数字调用它自己的内部生成“心智模型”,并生成新类型的图像——这肯定很酷！—但我们仍然需要完成我们的第一个目标:分类和预测它以前没有见过的数字的新图像。</p><p id="458e" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在我们的直觉分类器中进行分类和预测的关键叫做<em class="mj">推理</em>。实际上，我们的大脑一直在这么做！想象一下下面这个问题:</p><p id="7260" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">"你今天晚餐只能吃绿色蔬菜了！"绿色指的是什么？</p><p id="fe61" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">嗯，绿色是一种颜色，而且绿色以复数形式使用，可以推断它指的是绿色物体——但是<em class="mj">什么</em>物体？我们的大脑<em class="mj">推断</em>这些“物体”是指绿色蔬菜，如花椰菜、菠菜、甘蓝等。因为还有什么绿色的东西可以煮着吃？我们的大脑很容易一直进行这样的推理，但如果没有数十亿个数据点、参数和高能量使用，让自然语言处理(NLP)计算机系统进行这样的推理是非常困难的——这是人类大脑并不真正需要的。幸运的是，我们现在没有处理NLP推理，但不要误解我——视觉类人推理也是人工智能中需要克服的一个长期挑战。</p><p id="e9fd" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">总之，回到视觉。我们希望我们的计算机<em class="mj">根据它对数字外观的“心智模型”(分布)来推断</em>新的数字将会是什么。这样的推论会是怎样的呢？假设我们只处理两种类型的数字。一个2和一个7。假设计算机已经创建了它认为2和7的28x28图像的分布。当一个新的未见过的图像出现时，它是如何推断的？计算机问自己:在哪个心智模型下，图像<em class="mj">更有可能</em>:我的a 2模型，还是a 7模型？如果它更有可能在a 2下，那么我将决定该图像是a2；否则我决定7。这样，实际的分类就变成了if-else条件语句，这种语句在从Python到Java再到c的计算机科学语言中非常普遍。有趣的是，这个决定是非常程序化的！</p><p id="7154" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">如果你想了解更多关于概率分布的知识或者熟悉它，我推荐<a class="ae lf" href="https://www.youtube.com/watch?v=ZA4JkHKZM50" rel="noopener ugc nofollow" target="_blank">来自Youtube频道“3Blue1Brown”的Grant Sanderson </a>的这个视频，以及关于概率和统计的KhanAcademy视频！</p><p id="246e" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">所以…让我们开始实施吧！在我们开始之前，请稍作休息！</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="255b" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><strong class="lp jb">数据导入</strong></p><p id="0d2f" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">首要任务是从某处导入手写数字数据。为此，TensorFlow和Keras(运行在Tensorflow之上的高级语言)有一个组织良好的数据集集合，而Keras恰好有手写数字。MNIST数据集<a class="ae lf" href="https://keras.io/api/datasets/mnist/" rel="noopener ugc nofollow" target="_blank">可以在这里</a>找到(它的许可证是:CC BY-SA 3.0)。要导入数字数据集，我们只需使用代码:</p><pre class="kq kr ks kt gt mm mn mo mp aw mq bi"><span id="6657" class="mr ms iq mn b gy mt mu l mv mw">from keras.datasets import mnist<br/>(x_train, y_train), (x_test, y_test) = mnist.load_data()</span></pre><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/2aabb07813cedbb8ea800c134ad26505.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*RY5MWliPM198ixDCQaj0RQ.jpeg"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">这里有一个Keras MNIST训练图像数据的样本</p></figure><p id="338b" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">来自Keras的MNIST数据集每个数字类有6，000个训练样本，我们有10个类(因此总共有60，000个训练数字)，但我们不会使用那么多数据。为什么？首先，为了表明原则上我们可以不用那么多数据来创建这些生成模型。但是，在现实世界中，60，000个训练数据点可能并不存在，每个类可能只有几十或几百个训练数据。所以我们要做的只是从训练组中随机选择一组，比如说6000个数字。这给了我们每个数字类大约600个训练数字样本。那已经是<em class="mj">减少90% </em>的原始数据了！因此，如果我们可以基于这个更小的训练集来训练每个数字类的生成性“心智”模型，我们将更有数据效率。</p><p id="96d8" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我们可以随机抽样，用下面的代码创建一个新的更小的训练集:</p><pre class="kq kr ks kt gt mm mn mo mp aw mq bi"><span id="6a30" class="mr ms iq mn b gy mt mu l mv mw">np.random.seed(10)<br/>random_indices = np.random.choice(60000, size=6000, replace=False)<br/>random_x_train = x_train[random_indices, :]<br/>random_y_train = y_train[random_indices]</span></pre></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="d9c1" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><strong class="lp jb">特征提取</strong></p><p id="c649" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">为了创建模型，我们首先必须做所谓的“特征工程”(或者“特征选择”，如果您处理的数据中的特征是表中的列)。我们为什么要这么做？嗯，我们必须意识到一些事情:这些图像存在于一个非常非常高维度的空间中。每幅图像有784个像素，所以作为一个<em class="mj">向量，</em>每幅图像都存在于同一个784维空间中。就此而言，我们甚至不能在4D空间中绘制图形，所以放弃在784D空间中绘图吧！</p><p id="8557" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">处理高维数据可能非常困难，高维空间会发生一些奇怪的事情——例如，在4D和更高的地方，球体开始变得“尖锐”:<a class="ae lf" href="https://www.youtube.com/watch?v=mceaM2_zQd8&amp;t=224s" rel="noopener ugc nofollow" target="_blank">如果你想体验一下，请查看Youtube频道Numberphile </a>的视频。你可能也听说过这种现象，称之为机器学习中的“维数灾难”。</p><p id="acdf" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">如果您有以要素为列的表格数据，有一些统计方法可以根据统计资料(如相关性和分布)预先选择一组较小的要素。如果你<em class="mj">没有</em>有表格数据，一般来说有几种方法可以做特征<em class="mj">提取。</em>对我们来说幸运的是，有一种提取特征的神奇方法——在ML行话中也称为“降维”——我们可以保存几乎所有关于数据的信息，然后一路走到2D！它被称为UMAP-y<a class="ae lf" href="https://umap-learn.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">你可以在这里阅读Python用户手册</a>-它是由数学家利兰·麦金尼斯在2018年创建的。UMAP代表“一致流形逼近和投影”——如果这是一个口，不要担心。(如果你想要一个解释，<a class="ae lf" href="https://www.youtube.com/watch?v=6BPl81wGGP8" rel="noopener ugc nofollow" target="_blank">看看Letitia博士的这个视频</a>)我可以用最简单的方式解释:UMAP算法试图根据数据的聚集程度用点和线连接784D图像数据(有点像社交网络！);然后使用<em class="mj">拓扑将整个图<em class="mj">投影</em>，</em>到一个低维空间。如果你想将数据点可视化，你必须一直向下投射到2D或3D空间，就像我下面所做的:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi my"><img src="../Images/0d47677c15d3da52582afd60082679c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PRcq0EHo9Uu0-lYkqqVZ7w.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来源:Raveena Jayadev。“组件1”和2代表UMAP组件。如果你听说过的话，这基本上与“PCA”中用于降维的“主成分”是一回事。</p></figure><pre class="kq kr ks kt gt mm mn mo mp aw mq bi"><span id="3a1d" class="mr ms iq mn b gy mt mu l mv mw">mapper = umap.UMAP(n_components=2, random_state=40).fit(random_x_train)<br/>umap_components = mapper.transform(random_x_train)</span></pre><p id="e07b" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">你在这里看到的星团之间的距离反映了这样一个事实，以某种具体的方式，像0和7这样的数字与7和9“很远”或“相当分开”。当然你可能会说“Raveena！每个数字都是分开的”这是事实，但是当手写数字时，有时笔画会令人困惑。这就是UMAP试图压缩到2D的基本结构，这样我们就可以亲眼看到了！</p><p id="7310" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><em class="mj">(免责声明:</em>虽然UMAP分量在散点图中显示出清晰的聚类，但是分量轴本身并不是人类能够真正解释的。但是，决策预测过程仍然是。)</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="bc64" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><strong class="lp jb">学习“心理”生成模型</strong></p><p id="5699" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">现在是时候学习“心智模型”了——计算机将从数据中学习的每一类手写数字的生成概率模型，以便在分类时做出有根据的推断。为了创建实际的模型，我们将在<em class="mj"> sci-kit learn </em>模块中使用一种称为<em class="mj">内核密度估计(KDE) </em>的技术。想象一组数据点，其中一些点彼此靠近，一些点更加孤独和孤立。估算过程如下图所示:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mz"><img src="../Images/9702ede523e5a5a834dd93de95d84bd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gx8pV4xGGxe52riKPjcoJw.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来源:维基百科。底部的黑色刻度线是集合中的数据点，红色虚线是放置在每个点上的小钟形曲线。KDE将钟形曲线平均成蓝色实线，从而得到大致的形状。(链接:<a class="ae lf" href="https://en.wikipedia.org/wiki/Kernel_density_estimation" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Kernel_density_estimation</a>)</p></figure><p id="73df" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">一旦我们了解了每个数字的生成性“心理”模型，我们就可以将这些模型绘制在一起，并使用10种不同的颜色来表示数字0-9及其模型形状。下面的每个“形状优美的斑点”代表计算机从每个数字的数据中学习的内部模型，类似于人类大脑对数字应该看起来像什么的内部模型。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi na"><img src="../Images/c8230290a33fe793f04480fc306bac52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WOxL7TXUXywwGJCh9yqasQ.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来源:Raveena Jayadev</p></figure><p id="fcd7" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">现在我们的计算机已经有了每个数字的生成模型，是时候做…推理了！在这个项目中，我想强调两件事:1)我们可以编写图像分类器，像人脑一样用内部“心理”模型进行推理和决策，2)这使得人工智能系统易于<em class="mj">排除故障</em>。在一个黑盒深度人工智能系统正在世界各地部署<a class="ae lf" rel="noopener" target="_blank" href="/towards-trans-inclusive-ai-a4abe9ad4e62">并经常歧视边缘化人群</a>(Zachary Hay的文章<em class="mj">走向数据科学</em>)的时代，很难排除这些系统可能做出的歧视性预测——如果你不能排除故障，这个系统在我看来还不如危险。</p><p id="0518" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">不过，让我向您展示我们如何检查我们在本文中创建的系统。下面是我们的系统将如何推断和预测一个看不见的测试图像的内容的总结代码:</p><pre class="kq kr ks kt gt mm mn mo mp aw mq bi"><span id="0934" class="mr ms iq mn b gy mt mu l mv mw">def decision(sample, mental_models):<br/>... (summary) <br/>   <strong class="mn jb">if likelihood_ratio &lt;= 3.0:</strong><br/>        print("There's very little evidence that my first choice, is better than my second choice."<br/>       <strong class="mn jb">return "I refuse to decide!"</strong><br/>   <strong class="mn jb">elif (likelihood_ratio &gt; 4.0) and (likelihood_ratio &lt;= 10.0):</strong><br/>        print("There is a bit of evidence that my first choice is better than my second choice")<br/>       <strong class="mn jb">return "maybe digit {} over {}"<br/>   else:</strong> print('There is strong evidence that my first choice, is better than my second choice.'<br/>       <strong class="mn jb">return [confident machine choice]</strong></span></pre><p id="5e44" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">(机器预测代码看起来就像一个<em class="mj"> if-else语句</em>(如上所述)，机器可以用<em class="mj">不同的</em>置信度进行预测，这非常直观！)</p><p id="4cc8" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">现在假设我们给这个人工智能系统一个3的图像，相反它预测的是5。我们如何对模型进行故障诊断，以了解它是如何出错的？好吧，跟我来:</p><ul class=""><li id="6caf" class="nb nc iq lp b lq lr lt lu lw nd ma ne me nf mi ng nh ni nj bi translated">机器从if-else语句中决定，在其生成性“心理”模型下，5比3更有可能来自图像数据。</li><li id="2b9e" class="nb nc iq lp b lq nk lt nl lw nm ma nn me no mi ng nh ni nj bi translated">If-else决策是纯逻辑，因此这意味着问题不在于决策，而在于<em class="mj">统计心智模型</em>或<em class="mj">特征提取</em>。我们可以要求机器显示心智模型和特征提取，就像我上面做的那样。从那里我们可以分析模型的缺点，并看看如何调整它们。</li></ul><p id="f46b" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在这两个步骤中，我们已经确定了如果这个人工智能系统出错，它可能会在哪里出现问题，相比之下，世界上许多连接到监控技术的深度学习系统甚至不能以这种方式进行故障排除，这导致了潜在的危险人工智能。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="fbac" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我希望你，读者，从这篇文章中带着这样的希望离开:1)我们可以创建人工智能系统，它可能像人类一样直观地做出决策，2)如果人工智能模型出错，我们可能可以<em class="mj">对其进行故障排除</em>，并回溯错误直到系统的内部部分，并了解应该修复什么，应该废弃什么。</p><p id="4a00" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">不可否认，你可能会告诉我:“Raveena，UMAP”特征提取看起来不太直观！”是的，我知道。不幸的是，这些特征不是人类可以解释的。然而，有一种方法可以修改这个系统，使它<em class="mj">可以</em>被解释，尽管是以不同的方式。如果你有兴趣知道，<a class="ae lf" href="https://www.cs.cmu.edu/~rsalakhu/papers/LakeEtAl2015Science.pdf" rel="noopener ugc nofollow" target="_blank">麻省理工学院教授Joshua Tenenbaum </a> <em class="mj"> </em>在2015年发表的这篇文章谈到了使用与我们的概率生成模型<em class="mj"> </em>非常相似的内部“心智模型”来制作人工智能手写字符分类器系统。事实上，它是如此直观和数据高效，它只从<em class="mj"> 30个数据点</em>中学习，并模仿人类手写符号出奇地好。在我看来，这是人工智能未来最具革命性的创造之一。</p><p id="8d37" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">顺便说一下，<a class="ae lf" href="https://github.com/galaxyenby1997/Image-Classifier-generative" rel="noopener ugc nofollow" target="_blank">如果你想看完整的实现细节，这里有我的代码</a>的链接:我的Github是公开的，可以免费访问:)</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="c3cd" class="pw-post-body-paragraph ln lo iq lp b lq lr kb ls lt lu ke lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><strong class="lp jb">参考文献</strong></p><ol class=""><li id="0c95" class="nb nc iq lp b lq lr lt lu lw nd ma ne me nf mi np nh ni nj bi translated">托马斯·帕尔(Thomas Parr)，卡尔·弗里斯顿(Karl Friston)，《推理的解剖:生成模型和大脑结构》(2018)，《计算神经科学前沿<em class="mj">，<em class="mj"> </em> 2018。</em></li><li id="c2d4" class="nb nc iq lp b lq nk lt nl lw nm ma nn me no mi np nh ni nj bi translated">S.R. Kheradpisheh等人，深度网络可以在不变物体识别中类似人类的前馈视觉(2016)，<em class="mj"> Nature </em>。</li><li id="bb4a" class="nb nc iq lp b lq nk lt nl lw nm ma nn me no mi np nh ni nj bi translated">约书亚·特南鲍姆(Joshua Tenenbaum)，布伦丹·莱克(Brendan Lake)，通过概率程序归纳进行人类水平的概念学习(2015)，<em class="mj">科学</em>。</li></ol></div></div>    
</body>
</html>