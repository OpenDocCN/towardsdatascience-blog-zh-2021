<html>
<head>
<title>LambdaNetworks: Efficient &amp; accurate, but also accessible? A reproducibility project with CIFAR-10</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">LambdaNetworks:高效、准确，但也是可访问的？CIFAR-10的再现性项目</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lambdanetworks-efficient-accurate-but-also-accessible-a-reproducibility-project-with-cifar-10-3429d8ece677?source=collection_archive---------36-----------------------#2021-04-25">https://towardsdatascience.com/lambdanetworks-efficient-accurate-but-also-accessible-a-reproducibility-project-with-cifar-10-3429d8ece677?source=collection_archive---------36-----------------------#2021-04-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0ac9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">LambdaNetworks胜过attention和CNN。这是否适用于小型和低维数据集？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f2035ee21c2c7abe4141d9ab37cccb60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*djc8tigVIklpvU9L"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">洛伦佐·埃雷拉在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="fb92" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们介绍了我们使用更小和更低维度的CIFAR-10数据集复制LambdaNetworks的实现和结果，LambdaNetworks是由Irwan Bello在Google Brain开发的一种新的机器学习架构。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="cd19" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个再现性项目的作者是<a class="ae kv" href="https://www.linkedin.com/in/jose-ignacio-de-alvear-cardenas/" rel="noopener ugc nofollow" target="_blank">joséIgnacio de alv ear cárdenas</a>和<a class="ae kv" href="https://www.linkedin.com/in/wesleyajgdevries/" rel="noopener ugc nofollow" target="_blank"> Wesley A.J.G. de Vries </a>，代尔夫特理工大学航空航天工程硕士研究生。我们实现LambdaNetworks的源代码可以在<a class="ae kv" href="https://github.com/joigalcar3/LambdaNetworks" rel="noopener ugc nofollow" target="_blank"> GitHub </a>中找到。我们还有一张总结这篇文章的海报<a class="ae kv" href="https://github.com/joigalcar3/LambdaNetworks/blob/main/Poster.pdf" rel="noopener ugc nofollow" target="_blank">在这里</a>。如果你对代尔夫特大学学生的其他复制品感兴趣，可以在这个<a class="ae kv" href="https://reproducedpapers.org/" rel="noopener ugc nofollow" target="_blank">链接</a>找到。</p><p id="b8d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章的结构如下:</p><ol class=""><li id="aa57" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated"><a class="ae kv" href="#d4ff" rel="noopener ugc nofollow">简介</a></li><li id="9416" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated"><a class="ae kv" href="#31bc" rel="noopener ugc nofollow">现有的LambdaNetworks论文评审和再现性项目</a></li><li id="e1e6" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated"><a class="ae kv" href="#443c" rel="noopener ugc nofollow">本再现性项目的目标</a></li><li id="9f0b" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated"><a class="ae kv" href="#b6fc" rel="noopener ugc nofollow">为什么要λ层？</a></li><li id="d070" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">【LambdaNetworks解释 <br/> 5.1 <a class="ae kv" href="#f060" rel="noopener ugc nofollow">内容λ</a><br/>5.2<a class="ae kv" href="#5951" rel="noopener ugc nofollow">位置λ</a><br/>5.3<a class="ae kv" href="#e96f" rel="noopener ugc nofollow">λ应用于查询</a> <br/> 5.4 <a class="ae kv" href="#ed77" rel="noopener ugc nofollow">多查询λ层</a></li><li id="f0f4" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated"><a class="ae kv" href="#6520" rel="noopener ugc nofollow">约束、数据集和参数</a> <br/> 6.1 <a class="ae kv" href="#ef05" rel="noopener ugc nofollow">约束</a> <br/> 6.2 <a class="ae kv" href="#b7a2" rel="noopener ugc nofollow">数据集</a> <br/> 6.3 <a class="ae kv" href="#b975" rel="noopener ugc nofollow">参数</a></li><li id="5196" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated"><a class="ae kv" href="#2566" rel="noopener ugc nofollow">实施细节:ResNet-50 </a> <br/> 7.1 <a class="ae kv" href="#3e7e" rel="noopener ugc nofollow">数据预处理</a> <br/> 7.2 <a class="ae kv" href="#aa7c" rel="noopener ugc nofollow">模型准备</a> <br/> 7.3 <a class="ae kv" href="#800f" rel="noopener ugc nofollow">训练和测试</a></li><li id="d14c" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated"><a class="ae kv" href="#78cf" rel="noopener ugc nofollow">实现细节:lambda networks</a><br/>8.1<a class="ae kv" href="#3a1d" rel="noopener ugc nofollow">单Lambda层实现</a> <br/> 8.2 <a class="ae kv" href="#4831" rel="noopener ugc nofollow"> Lambda层集成在ResNet-50内</a></li><li id="02ee" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated"><a class="ae kv" href="#d613" rel="noopener ugc nofollow">结果</a> <br/> 9.1 <a class="ae kv" href="#29ed" rel="noopener ugc nofollow">准确度和模型复杂度</a> <br/> 9.2 <a class="ae kv" href="#88c4" rel="noopener ugc nofollow">训练时间和吞吐量</a> <br/> 9.3 <a class="ae kv" href="#7f71" rel="noopener ugc nofollow">学习率敏感度分析</a></li><li id="b0b6" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated"><a class="ae kv" href="#ec9d" rel="noopener ugc nofollow">结论</a></li><li id="a58e" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated"><a class="ae kv" href="#4a8a" rel="noopener ugc nofollow">建议</a></li><li id="e57f" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated"><a class="ae kv" href="#bc3e" rel="noopener ugc nofollow">作者对Lambda Networks论文的看法</a></li></ol><p id="1310" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="#fba1" rel="noopener ugc nofollow">参考文献</a></p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="d4ff" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">1.介绍</h1><p id="7098" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">Irwan Bello在<a class="ae kv" href="https://arxiv.org/abs/2102.08602" rel="noopener ugc nofollow" target="_blank"><em class="nk">“LambdaNetworks:Modeling long-range interactions without attention”</em></a><em class="nk"/>【1】中提出了一种方法，其中通过将上下文转换为称为lambdas的线性函数的层来对远程交互进行建模，以避免使用注意力图。根据Bello的原始论文，lambda层的巨大优势在于，它们比自我关注机制需要更少的计算。这太棒了，因为它不仅能更快地提供结果，还能省钱，并有更好的碳足迹！然而，Bello仍然使用32<a class="ae kv" href="https://cloud.google.com/tpu" rel="noopener ugc nofollow" target="_blank">TPU v3</a>和200 GB大小的ImageNet分类数据集。因此，我们开始了这个再现性项目，想知道:lambda层是否可以在保持其吸引人的特性的同时，适用于主流计算机？</p><p id="69d5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2021年，世界不仅要应对新冠肺炎疫情，还要应对T2芯片短缺，这也是由于家用电子产品的增加、中国工厂的关闭和加密货币价格的上涨。这使得供应下降到创纪录的低点，价格下降到创纪录的高点。导致研究人员、学者和学生(他们通常都在预算范围内)不再能够利用COTS(商用现成)GPU快速构建集群，从而不得不处理更旧、更少、效率更低的硬件。</p><p id="4278" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在2021年3月启动该项目时，没有发布任何官方代码。因此，为了回答上述问题，我们需要尽可能准确地复制Bello的论文，同时尝试将其缩小，以便可以在普通的消费者计算机上运行。产生的代码是公开的</p><h1 id="31bc" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated">2.现有的LambdaNetworks论文审查和再现性项目</h1><p id="b744" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">Bello的论文已于2021年2月2日发表，在撰写本文时已被引用7次。这意味着这篇文章是全新的，因此还没有被学术界梳理过。</p><p id="5df0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，一些研究人员和机器学习社区的成员已经阅读了这篇文章，并提供了这篇论文的评论。</p><ul class=""><li id="e2b0" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr nq mf mg mh bi translated"><a class="ae kv" href="https://www.youtube.com/watch?v=3qxJ2WD8p4w" rel="noopener ugc nofollow" target="_blank"> Yannic Kilcher </a>在Bello发表这篇文章的4个月前，已经在YouTube上发表了<em class="nk">“LambdaNetworks:建模没有注意力的远程相互作用(论文解释)”</em>。基尔彻检查了论文的初稿，向听众解释了它们，并向作者提供了建议。</li><li id="4bb6" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr nq mf mg mh bi translated"><a class="ae kv" href="https://www.youtube.com/watch?v=awclKwG0_sM" rel="noopener ugc nofollow" target="_blank"> Carlos Ledezma </a>发表了一个类似Kilcher的视频，但是花了更多的时间来阐明注意力层和lambda层结构之间的区别。</li><li id="c421" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr nq mf mg mh bi translated"><a class="ae kv" href="https://github.com/leaderj1001/LambdaNetworks" rel="noopener ugc nofollow" target="_blank"> Myeongjun Kim </a>不仅复制了lambda层代码，该社区成员还将其应用于不同的ResNet版本和不同的数据集，并进行消融研究。来自上述数据科学家的代码不用于生成我们的代码。然而，我们将简单地将我们的代码与他们的代码进行比较，以了解他们为什么为自己的实现做出特定的选择，并证明我们的代码是正确的。</li><li id="b108" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr nq mf mg mh bi translated">王飞用Pytorch发布了关于lambda层的非官方代码。</li></ul><p id="8fed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">幸运的是，Bello已经澄清，他将很快发布与LambdaNetworks论文相对应的代码。这很可能会增强每个人对LambdaNetworks的理解。</p><h1 id="443c" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated">3.这个再现性项目的目标</h1><p id="edb9" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">最初，本文的科学目标是复制Bello论文表3中的两个特定结果，如下所示。这些结果分别是<em class="nk">(何等，2016) </em>、<em class="nk">λ层</em>。这是为了确定我们是否能够在没有先前代码实现的情况下重现这一点。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/bf9e8784ba14cebb576df3acecd595f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-0fAd_q7L81UFNMiBGRl1A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在具有ResNet-50架构的ImageNet上，lambda层与卷积和注意力机制的比较。benchmark from "<a class="ae kv" href="https://arxiv.org/abs/2102.08602" rel="noopener ugc nofollow" target="_blank">lambda networks:无需关注的远程交互建模</a></p></figure><p id="ea2e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，由于Bello在他的研究中使用了大量数据集，即ImageNet，以及他为在合理的时间内获得这些结果而开发的计算资源，即8–128 TPU v3，这些结果的一对一再现对于普通学生和研究人员来说是不可能的；超出我们作为学生所掌握的资源。因此，范围略有变动。我们的目标不再是在没有公开代码的情况下准确地再现上述结果，而是找出这些结果是否也可以用更小的数据集来实现。</p><p id="f0f1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个再现性项目的个人目标是双重的。首先，随着大量正在进行的研究，注意力似乎是目前最先进的。然而，注意力有一些缺点，lambda层旨在解决这些缺点，同时略微提高准确性。因此，复制lambda层有助于社区在未来尽早采用这种潜在的高级算法。此外，它在更小和更低维数据集上的实现证明了该算法的鲁棒性，以及它在资源受限设备(TinyML)上的潜在实现。</p><p id="66c5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第二个原因是增强和拓宽了此处展示的可再现性项目作者的深度学习知识和技能，这是代尔夫特理工大学由<a class="ae kv" href="https://scholar.google.com/citations?user=JUdMRGcAAAAJ" rel="noopener ugc nofollow" target="_blank">Jan van Gemert</a>博士教授的深度学习课程的一部分。为了感受深度学习，不仅要阅读大量的在线资源，还要对一些开创性的论文有亲身体验。在阅读了名为<a class="ae kv" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">“注意力是你所需要的全部”</a> [2]的广受欢迎的论文后，我们对可能跟进的所有论文感到兴奋。从抽象上来说，lambda层有望成为变形金刚的一大进步，它针对多个弱点，带来更高的性能和更低的计算负载。渴望了解更多关于注意力的知识，并对lambda层的潜力感到兴奋，选择这个再现性项目对我们来说是一个显而易见的选择。</p><h1 id="b6fc" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated">4.为什么是lambda层？</h1><p id="1bb6" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">Lambda层与自我关注机制密切相关，因为它们允许模拟长程互动。然而，自我注意机制有一个很大的缺点，这与它们需要注意图来模拟层激活的相对重要性的事实有关，这需要额外的计算并且渴望RAM(随机存取存储器)。这使得它们不太适用于严重依赖图像(由像素网格组成)的机器视觉应用，因为对这些像素中的每一个之间的远程交互进行建模需要计算和RAM。因此，很明显，为了减少任何基于注意力的视觉任务的训练和推理时间，应该解决这个问题。</p><p id="953d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如Bello在他的文章[1]: <em class="nk">中所说的，“我们提出了lambda层，它以更低的内存成本对查询和一组结构化的上下文元素之间的长期交互进行建模。Lambda层将每个可用的上下文转换成称为lambda的线性函数，然后直接应用于相应的查询”。</em></p><p id="bf64" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://arxiv.org/abs/2007.14902" rel="noopener ugc nofollow" target="_blank">线性注意力机制</a>【3】提出了一个解决高内存使用率问题的方案。然而，这些方法不捕捉查询和上下文元素之间的位置信息(例如，像素在图像上的位置)。相比之下，Lambda图层的内存使用率较低，并且可以捕获位置信息。后者甚至导致性能的提高，使得它在ImageNet数据集上优于具有线性注意和局部相对自我注意的卷积。</p><h1 id="31ec" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated">5.LambdaNetworks解释道</h1><p id="407c" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">LambdaNetworks优于Transformers的主要优点是，计算上下文的所有组件之间基于内容和位置的交互，可以选择是全局的还是局部的，而不产生昂贵的和存储器密集型的注意力图。为了实现这一点，lambda层有3个主要步骤:</p><ol class=""><li id="4d31" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated">计算内容lambda封装了上下文内容。</li><li id="85d1" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">位置λ的计算，其封装了查询和上下文元素之间的相对位置信息。</li><li id="d2d9" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">将内容和位置应用于输出计算的查询。</li></ol><p id="3413" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图提供了完整流程的概览。在下面的小节中，我们将详细解释每一个步骤，不断地引用所呈现的lambda层计算图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/bac05a20cd7ba3b912bc1e752312c228.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*LTwkkaJlhrapyxRKdpZbgA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">λ层的计算图。图片由作者提供，灵感来源<a class="ae kv" href="https://arxiv.org/abs/2102.08602" rel="noopener ugc nofollow" target="_blank"><em class="nt">《lambda networks:无需注意的远程交互建模》</em> </a></p></figure><h2 id="f060" class="nu mo iq bd mp nv nw dn mt nx ny dp mx lf nz oa mz lj ob oc nb ln od oe nd of bi translated">5.1含量λ</h2><p id="8892" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">对于内容λ的计算，使用全局上下文。在单个正方形图像的情况下，全局上下文由所有像素组成。因此，如果图像形状是d×n×n，n是沿着图像的宽度和长度的像素数，d是图像尺寸(在彩色图像的情况下是3)，则上下文是形状|n|×d，其中|n|=n。当理解上下文的尺寸时，计算图可能会产生误导，因为它显示它是形状|m|×d。与内容λ相比，位置λ使用局部上下文，作者决定根据后者的计算需要来表示尺寸。实际上，首先用全局上下文计算内容λ，然后用局部上下文计算位置λ。不幸的是，这种对λ和不同矩阵维数的顺序计算没有清楚地反映在计算图中。</p><p id="a335" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在全局上下文中，值和键的计算如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/927aebb8fb2b0435245f6a2e1eaea56d.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*RHt9-67rWNDUcauk6_HUgw.png"/></div></figure><p id="4291" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后使用softmax沿着|m|维度对键进行规范化，而对值进行批量规范化。最后，从标准化值和密钥的矩阵乘法中获得内容λ。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/cbb50525df882b829cc01a33f9175fe6.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*4vUT256aj7OmJmRQAcFl5w.png"/></div></figure><p id="33e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种方法的好处是，内容lambda编码了如何独立于每个查询，仅基于上下文内容来转换查询。结果，内容λ在图像的所有查询/像素之间共享。</p><h2 id="5951" class="nu mo iq bd mp nv nw dn mt nx ny dp mx lf nz oa mz lj ob oc nb ln od oe nd of bi translated">5.2位置λ</h2><p id="9c89" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">对于内容λ的计算，用户可以通过使|m|等于|n|来选择是使用大小为|m|×d的局部上下文还是使用全局上下文。出于该再现性项目的目的，由于馈送到λ层的输入的低|n|值，即|n|⊂ [8，4，2，1]，全局上下文用于位置λ的计算。这个小的输入维度是由所使用的数据集(即CIFAR-10)造成的，其图像比ImageNet小6倍。与从输入中提取局部上下文所需的额外计算相比，利用这个减少的数据集，从较小的上下文中计算位置λs所获得的潜在加速是微不足道的。</p><p id="9c49" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来可以观察到，位置λ是值矩阵和位置嵌入之间的乘积的结果。后者是封装了n个查询中的每一个与上下文之间的位置关系的n个学习|m|×k矩阵。结果，嵌入是产生n个位置λ的|n|×|m|× k块。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/01d583d35ec98a9862b968f337e1225a.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*HXIwznharCuUqLTWuW97eQ.png"/></div></figure><p id="daa4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于内容和位置信息的分离，可以在接收相同输入大小的lambda层之间共享位置嵌入，从而降低内存占用。位置λ编码查询需要如何仅基于它们相对于其上下文的每个组件的相对位置进行转换。</p><h2 id="e96f" class="nu mo iq bd mp nv nw dn mt nx ny dp mx lf nz oa mz lj ob oc nb ln od oe nd of bi translated">5.3应用于查询的Lambdas</h2><p id="28d4" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">一旦计算了内容和位置λ，就有可能通过对两个分量求和来计算将应用于查询的最终λ矩阵。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/3ad352aabc141fca2ad088655b2245f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*-xxJLn084f4li9mHRjqWsg.png"/></div></figure><p id="e1e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，查询的计算方式与键和值类似，即通过将线性投影矩阵应用于输入。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/663796fb294abf88323882f1cff3700a.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*fghR7SSddjDVNQ4LlCMGaA.png"/></div></figure><p id="2609" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦计算了查询和它们各自的λ，λ通过计算的λ和从每个像素生成的查询之间的简单矩阵乘法将查询转换成输出；<strong class="ky ir"><em class="nk"/></strong>矩阵中的每一行。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/158e972cf6b9329eb6b61154366527c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:416/format:webp/1*LgohI9EFSR8zBe-TigSexA.png"/></div></figure><h2 id="ed77" class="nu mo iq bd mp nv nw dn mt nx ny dp mx lf nz oa mz lj ob oc nb ln od oe nd of bi translated">5.4多重查询λ层</h2><p id="7745" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">在LambdaNetworks论文[1]中，观察到值维|v|的减少可以极大地减少计算成本以及空间和时间复杂性。因此，作者决定通过随意操纵它的值来将这些复杂性与这个维度解耦。</p><p id="0a7a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为此，他建议对应用相同lambda的每个(像素)输入使用|h|查询。那么单个(像素)输入的输出是h个输出中的每一个的级联结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/3ae1a7c3b1684a8f5ea401283ee7607b.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*SDZxs77euq3pwTi6yxoZig.png"/></div></figure><p id="076a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，|v|现在等于d/|h|，这将复杂度降低了|h|倍。作者将这种值维度的减少称为多查询lambda层。值得注意的是，在lambdas的大小之间有一个权衡:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/9f6bc893700cd9b3fb66fb9b744f11b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*2pMVPmCoNcESHuj7UoQiYQ.png"/></div></figure><p id="9797" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">，以及查询的大小:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/99ebebefa8b3bf73ca4c7ba9eb3a9375.png" data-original-src="https://miro.medium.com/v2/resize:fit:226/format:webp/1*oHRAOL4l9LDcsa8NOs8njQ.png"/></div></div></figure><h1 id="6520" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated">6.约束、数据集和参数</h1><p id="f2d1" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">在本节中，我们将解释compute中的约束如何导致使用不同的数据集，以及Bello如何以及为什么从原始论文中调整一些参数。然而，我们想强调的是，为了公平比较，大多数参数都与Bello使用的参数完全相同。</p><h2 id="ef05" class="nu mo iq bd mp nv nw dn mt nx ny dp mx lf nz oa mz lj ob oc nb ln od oe nd of bi translated">6.1制约因素</h2><p id="31a4" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">与Bello的设置相比，存在一些计算限制。Bello作为一名谷歌研究员，在他的研究项目中使用了32个TPUv3单位的ImageNet分类数据集。不幸是，我们没有这台计算机。代尔夫特大学非常慷慨地向我们提供了50欧元的谷歌云信用。然而，50欧元很可能不足以用200 GB大小的ImageNet来训练该架构几次。根据Bello使用的数据集，ImageNet由1.3亿张过滤和平衡的JFT图像组成，这些图像带有由EfficientNet-L2生成的伪标签，准确率为88.4%。因此，选择了不同的数据集，即CIFAR-10。</p><p id="fb2c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些数据是在<a class="ae kv" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank">谷歌Colab </a>和一台高端笔记本电脑上进行训练和测试的，该笔记本电脑配有2020年的普通显卡。由于组件的可用性是固定的，本地笔记本电脑提供了可比较的结果作为健全性检查，而Colab根据运行时的可用性为客户机分配不同的资源。</p><p id="21cc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">主要环境是Google Colab。它可以免费获得，因此被认为是这个项目最合适的候选。在这种环境中，由于资源是在平台的用户之间共享的，所以无法保证资源，因此很难说获得的结果在运行时间方面是否一致。这是因为在<a class="ae kv" href="https://research.google.com/colaboratory\/faq.html\#usage-limits" rel="noopener ugc nofollow" target="_blank"> Nvidia K80、T4、P4和P100 </a>之间，不仅RAM的数量会发生变化，而且可用的GPU类型也会发生变化。该算法根据具体情况确定最有可能使用的内存量，并为重度用户分配更多内存，最高可达12 GB。一次会话的最大允许时间为12小时。就本项目而言，关键是分配的资源在整个会议期间不发生变化，这使得闭会期间的结果可以可靠地进行比较。</p><p id="e8ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第二个培训环境包括一台笔记本电脑，配备Intel i7–10750h，具有足够的冷却能力，Nvidia Quadro T1000 Max-Q 4 GB DDR5(库存速度)和16 GB DDR 4 ram，采用单槽配置，库存速度为2400 MHz。由于完全独立运行，所有结果都是可重复的。</p><h2 id="b7a2" class="nu mo iq bd mp nv nw dn mt nx ny dp mx lf nz oa mz lj ob oc nb ln od oe nd of bi translated">6.2数据集</h2><p id="2555" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">我们决定使用一个更小的数据集，即<a class="ae kv" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR-10 </a>。<br/>这是一个包含10类60，000幅32x32彩色图像的数据集，每类6，000幅图像，分割成5:1的训练测试比率。下面是这些图像的一个例子。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/4e8ea0934fe44d6470ab34d086bf6a70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RJHrWSxV9UtHTAeWovDj4Q.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">CIFAR-10数据集样本。</p></figure><h2 id="b975" class="nu mo iq bd mp nv nw dn mt nx ny dp mx lf nz oa mz lj ob oc nb ln od oe nd of bi translated">6.3参数</h2><p id="0247" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">为了找出论文作者是如何准确地汇编结果的，查看用于获得结果的初始条件和超参数是很重要的。接下来，我们编译一个列表，列出所有最重要的参数及其相应的定义和值。它们被分成三个表:</p><p id="bd2a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一个表包含用户可以轻易改变的参数。它们都可以在我们的代码中的<strong class="ky ir"> <em class="nk"> user_input.py </em> </strong>中找到。这些参数包括批量大小、输入大小和初始学习速率等。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oq"><img src="../Images/78cad45515bd43c0af04e5a46b211c11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vhkab4n-iyyqGJ9yuOiNqQ.png"/></div></div></figure><p id="94b8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第二个表包含在ResNet-50和lambda层的实现中使用的其他参数。分别在<strong class="ky ir"> <em class="nk"> lambda_layer.py </em> </strong>、<strong class="ky ir"> <em class="nk"> resnet.py </em> </strong>和<strong class="ky ir"><em class="nk">resnet \ _ lambda . py</em></strong>中定义。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi or"><img src="../Images/6313d625035993e448664a3b40a1ae91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4aVPqYQDelwtUcG2f0K9ag.png"/></div></div></figure><p id="4faf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第三表包含关于算法实现的更多信息。要了解更多信息，我们希望读者参考代码中的文档。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi os"><img src="../Images/5122a39b688bcc0f47a6b7faf963452a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ERZ9sfCowljVCDXXefsWw.png"/></div></div></figure><h1 id="2566" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated">7.实现细节:ResNet-50</h1><p id="0cb5" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">对于基线实现，我们使用的是由<a class="ae kv" href="https://pytorch.org/hub/pytorch_vision_resnet/" rel="noopener ugc nofollow" target="_blank"> Pytorch团队</a>提供的。接下来，我们解释数据预处理步骤、模型准备，并简要讨论训练和测试步骤。</p><h2 id="3e7e" class="nu mo iq bd mp nv nw dn mt nx ny dp mx lf nz oa mz lj ob oc nb ln od oe nd of bi translated">7.1数据预处理</h2><p id="13a4" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">在将数据输入算法之前，需要对其进行预处理。在这里，数据首先被下载、扩充和标准化。为此，原始图像被随机裁剪，通过用四个黑色像素填充所有图像边来保持原始大小。此外，以50%的概率随机翻转图像，并用均值[0.4914，0.4822，0.4465]和方差[0.2023，0.1994，0.2010]进行归一化；对应于CIFAR-10数据沿3个图像维度的平均值和方差的值。训练数据集的转换可以在下一个代码片段中观察到。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="1255" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此后，训练和测试数据被馈送到迭代器(数据加载器),并且训练图像的样本被绘制用于视觉验证。</p><h2 id="aa7c" class="nu mo iq bd mp nv nw dn mt nx ny dp mx lf nz oa mz lj ob oc nb ln od oe nd of bi translated">7.2模型准备</h2><p id="6732" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">在使用预处理的数据执行训练和测试之前，需要创建模型。为此，需要定义损失函数和优化器，以及学习率调度器。</p><p id="9d92" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于损失函数或标准的定义，LambdaNetworks论文的作者提到使用了平滑值为0.1的标签平滑。但是，在所选的ResNet-50架构实现中，默认情况下这是找不到的。因此，Christian Szegedy在论文“<a class="ae kv" href="https://arxiv.org/abs/1512.00567" rel="noopener ugc nofollow" target="_blank">反思计算机视觉的初始架构</a>”[5]中提出的标签平滑必须实现。为此，我们调整了由<a class="ae kv" href="https://gist.github.com/suvojit-0x55aa/0afb3eefbb26d33f54e1fb9f94d6b609" rel="noopener ugc nofollow" target="_blank"> Suvojit Manna </a>提出的标签平滑，这导致了如下面的代码片段所示的最终紧凑形式。可以看出，在标签平滑之前应用的损失是与log softmax激活的交叉熵。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="0da2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，Adam优化器与超参数(重量衰减、初始学习率等)一起使用。)显示在<a class="ae kv" href="#b975" rel="noopener ugc nofollow">参数部分</a>。学习率调度器基于线性和余弦学习率调度器的组合。</p><p id="b48f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在模型准备中，进一步检查模型是否可以在具有CUDA的主机GPU中运行，并且在由用户指定的情况下，它用存储在先前运行的用户指定的检查点中的参数来填充模型参数。作为设计选择，该模型每隔5个时期自动存储检查点。</p><h2 id="800f" class="nu mo iq bd mp nv nw dn mt nx ny dp mx lf nz oa mz lj ob oc nb ln od oe nd of bi translated">7.3培训和测试</h2><p id="6b2e" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">一旦定义了模型并预处理了数据，就在Nvidia Quadro T1000 max-Q 4GB DDR5上同时执行90个时期的训练和测试。在这一过程中，实施了两项措施，以保证顺利分析和比较结果。首先，训练和测试精度、损失和计算时间，以及每个时期的学习率，被存储在日志文本文件中，用于以后的分析。此外，存储精度和损耗信息，以便可以在Tensorboard中绘制。</p><h1 id="78cf" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated">8.实现细节:LambdaNetworks</h1><h2 id="3a1d" class="nu mo iq bd mp nv nw dn mt nx ny dp mx lf nz oa mz lj ob oc nb ln od oe nd of bi translated">8.1单λ层实现</h2><p id="8d45" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">尽管本文中提供了一些代码片段，但它假设已经计算了键、值和查询，没有提供层参数初始化，并且不清楚如何定义位置嵌入。为了实现lambda层及其在ResNet-50架构中的平滑集成，使用3个主要方法创建了一个类:</p><p id="7664" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="nk"> __init__ </em> </strong>:接收输入大小(|n|)、上下文大小(|m|)、值大小(|v|)、输出大小(d)、头数(h)和位置嵌入(<strong class="ky ir"> <em class="nk"> E </em> </strong>)作为输入的初始化方法。位置嵌入不是在类中创建的，因此它们可以在多个层中轻松共享。在类之外，嵌入被创建并作为输入提供给不同的lambda层。位置嵌入的实例化及其在lambda层之外的初始化定义如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="b09a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于键、值和查询的计算，应用单一线性变换而没有偏差。在查询的情况下，线性转换的输出大小为|n|×(kh ),如<a class="ae kv" href="#ed77" rel="noopener ugc nofollow">多查询部分</a>所述。可以在下面的代码中观察到这些转换:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="9657" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，为值和查询实例化了1D批处理规范化层，并为键实例化了softmax函数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="9217" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该函数通过调用“<strong class="ky ir"> <em class="nk"> reset_params </em> </strong>”方法结束，这将在下面解释。</p><p id="279d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="nk"> reset_params </em> </strong>:初始化lambda层的学习矩阵，即文中提到的具有相同正态分布的键、值和查询投影矩阵。如前所述，位置嵌入在λ层之外被初始化。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="18bf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="nk">正向</em> </strong>:神经网络正向传播过程中运行的函数。首先，由于λ层需要将输入图像的高度和宽度压缩成一维，即|n|，输入x被整形如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="7ded" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，由于全局上下文用于当前的再现性项目，因此上下文也通过相应地调整输入的大小来获得:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="0732" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一步是使用<strong class="ky ir"> <em class="nk"> __init__ </em> </strong>中定义的线性变换和归一化来计算关键字、查询和值:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="77af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，通过使用torch.einsum函数并遵循<a class="ae kv" href="#31ec" rel="noopener ugc nofollow">λ网络解释章节</a>中概述的等式，计算λs和输出。输出在最后被整形，使得它具有与馈送到λ层的输入相同的维数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="fed9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可以看出，复制lambda层所需的所有计算都可以压缩到不到20行代码。</p><h2 id="4831" class="nu mo iq bd mp nv nw dn mt nx ny dp mx lf nz oa mz lj ob oc nb ln od oe nd of bi translated">8.2 ResNet-50中的Lambda层集成</h2><p id="abdb" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">当阅读来自脸书人工智能研究所的<a class="ae kv" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">原始ResNet论文</a> [6]时，提出了不同的架构，其主要区别在于层数。从第一列可以看出，ResNet架构包含5个模块(<em class="nk"> conv1 </em>、<em class="nk"> conv2_x </em>、<em class="nk"> conv3_x </em>、<em class="nk"> conv4_x </em>和<em class="nk"> conv5_x </em>)，在LambdaNetworks白皮书中称为<em class="nk"> cx </em>级。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ov"><img src="../Images/db075cb9984c32296ea2eaeac15f85c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X-wqIkaIPahX8g_GXdiS7A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自“<a class="ae kv" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">图像识别深度残差学习</a>的ResNet-50架构</p></figure><p id="6b63" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<a class="ae kv" href="https://arxiv.org/abs/2102.08602" rel="noopener ugc nofollow" target="_blank"> LambdaNetworks论文</a> [1]中指出,(非混合)lambda网络是通过用lambda层替换ResNet架构的瓶颈块中的3×3卷积而获得的，即<em class="nk"> conv2_x </em>、<em class="nk"> conv3_x </em>、<em class="nk"> conv4_x </em>和<em class="nk"> conv5_x </em>。因此，原始ResNet-50体系结构中的主要变化可以在瓶颈层的定义中找到，也可以在初始化位置嵌入的ResNet的初始化中找到。</p><p id="67a6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下两个代码片段显示了部分原始ResNet-50瓶颈层初始化及其在具有集成lambda层的ResNet-50中的相应代码行。它清楚地显示了3×3 CNN层如何被替换为lambda层，而其余代码保持不变。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="58b8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，从<a class="ae kv" href="#31ec" rel="noopener ugc nofollow"> lambda层架构</a>可以看出，lambda层的输出与其输入具有相同的维度。然而，在最初的ResNet-50架构中，一些3×3 CNN层通过使用大于1的步幅来减小输入图像的大小。为了在基线和λ层实现之间建立公平的比较，在ResNet-50架构的那些阶段，也需要在λ层实现中缩小图像，其中原始3×3 CNN层使用大于1的步幅。为此，在网络的这些阶段，引入了一个平均2D池层，其内核大小为3×3，(1，1)填充和相应的步长。与1×1卷积相比，汇集层的好处是网络不需要学习额外的参数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="7bb3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每当对图像进行下采样时，都会生成新的位置嵌入，这些位置嵌入将与下一个lambda层共享，直到对图像进行新的下采样。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="11ab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，下图显示了没有和有lambda层的ResNet-50的瓶颈层中的一个层的当前架构。在给出的场景中，该层使用的步幅是2。在最初的ResNet-50中，已经存在由1×1卷积构成的下采样块，该下采样块应用于剩余连接，并且增加瓶颈层输入的维度以匹配其输出。现在，前面提到的平均汇集下采样块被添加到瓶颈层的末端。这种下采样的实施导致所需的GPU RAM从5GB减少到2GB。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/6f7fc19392c90c4acec5a10fe9372b37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hKCnfOioxR_7h0_ST4xCXw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">该框图显示了在基于2D平均池的具有lambda层的ResNet-50中附加下采样模块的实现。</p></figure><h1 id="d613" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated">9.结果</h1><p id="b004" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">原始论文对lambda层的主要主张是，与卷积层和注意力层相比，它们具有更好的性能和更高的计算效率。因此，下面两个部分分别比较了原始ResNet-50与其带有lambda层的修改版本的准确性，以及它们所需的训练计算时间和吞吐量。然后，第三部分提供了对初始学习率执行的简单灵敏度分析，以便将该超参数调整到新的架构-数据集组合。</p><p id="7190" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除了使用的初始学习率是0.0005之外，所有的结果都是用先前定义的参数和值获得的；因为它被发现是最佳选择。</p><h2 id="29ed" class="nu mo iq bd mp nv nw dn mt nx ny dp mx lf nz oa mz lj ob oc nb ln od oe nd of bi translated">9.1准确性和模型复杂性</h2><p id="3e80" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">下面两个图表示ResNet-50及其lambda层修改版本相对于历元数的训练和测试数据分裂的准确度和损失。它显示了前1名的准确性，即其顶级类(softmax之后概率最高的类)与其相应目标相同的数据点的百分比。正如可以观察到的，ResNet-50的训练和测试精度性能度量高于具有lambda层的版本。在测试数据集的情况下，它高出3.2%。结果，当在较低维度的数据集(如CIFAR-10)上训练时，lambda层并不优于卷积层；然而，他们仍然达到了竞争的结果。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/81f37a93c189ca226d908d31091f0100.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Je8brgfuqXhUDtzQy_50BQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">前1个vs时期的精度图</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/353078efcd9e76058f9a2f8113278d5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i3VXazyLJkXRy7MecHX3Hw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">损失与时期的损失图</p></figure><p id="1ce4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在原始的ImageNet数据集上，Bello报告卷积基线的准确率为76.9%，而lambda layers版本的准确率为78.4%。与在CIFAR-10数据集中获得的结果相比，两种体系结构之间的关系已经颠倒。除此之外，据观察，在CIFAR-10上，两种架构的精度都有所提高。这个观察暗示了在10类而不是1000类中对图像进行分类的较低难度。</p><p id="c6b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，Bello报道了基线和lambda层模型分别具有25.6米和15米的可训练参数。在我们的例子中，他们分别有23.5米和12.8米。由于两个模型丢失了大约相同数量的参数，即2M，我们假设丢失的参数来自借用的<a class="ae kv" href="https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py" rel="noopener ugc nofollow" target="_blank"> ResNet-50实现</a>，而不是来自我们的lambda层实现。</p><h2 id="88c4" class="nu mo iq bd mp nv nw dn mt nx ny dp mx lf nz oa mz lj ob oc nb ln od oe nd of bi translated">9.2培训时间和吞吐量</h2><p id="292a" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">准确度和损失图还显示了每个模型的训练时间。对于ResNet-50，这是1小时17分29秒，结果每个时期的平均时间为51.6秒。对于具有实现的lambda层的ResNet-50，总运行时间为1小时3分6秒，导致每个时期42.1秒。因此，看起来ResNet-50的训练和测试时间大约长了18.5%，而准确性仅增加了3.2%，并且lambda层的实现是有回报的。然而，人们不仅可以访问在时期90获得的最终结果，还可以访问中间结果。可以看出，对于基线ResNet-50，在时期90具有λ层的ResNet-50的最高测试精度已经达到时期41左右。在这种情况下，基线ResNet-50的时期41转换为大约35分20秒，因此比其具有lambda层的等效物几乎快两倍。</p><p id="d68b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当比较不同架构的吞吐量结果时，它们必须运行在相同的平台上。鉴于Bello在多个TPUv3s上运行他的算法，不可能将这个再现性项目的通量结果与Bello的结果进行比较。但是，可以比较CIFAR-10上基线和lambda层版本之间的吞吐量。在基线的情况下，训练时期平均花费50.92秒。假设有50，000个训练样本，基线的吞吐量是981.93 ex/s。在λ层的情况下，训练时期大约花费38.96秒。结果，λ层模型具有1283.26 ex/s的吞吐量。从这些值可以看出，λ层具有比卷积层更高的吞吐量，即高31%。</p><h2 id="7f71" class="nu mo iq bd mp nv nw dn mt nx ny dp mx lf nz oa mz lj ob oc nb ln od oe nd of bi translated">9.3学习率敏感性分析</h2><p id="244e" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">最后，为了确定在该再现性项目中提出的架构-数据集组合的良好学习速率，初始学习速率(<strong class="ky ir"> <em class="nk"> initial_lr </em> </strong>)被修改；然而，学习速率调度器保持不变。结果，前5个时期的学习速率被定义为[<strong class="ky ir">]initial _ lr]T7]，2个⋅<strong class="ky ir">]T9]initial _ lr]t11]，3个⋅<strong class="ky ir">]t13]initial _ lr]t15]，4个⋅<strong class="ky ir">]t17]initial _ lr]t19]，5个⋅<strong class="ky ir">【t21]initial _ lr]并且增加，而后面时期的学习速率遵循a</strong></strong></strong></strong></strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/e579c8d19e9e04a5c0ac09a7dcac88f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-vfXv8Etpuui3r74Dn7Z9Q.png"/></div></div></figure><p id="39d2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于以下初始学习率，基线和lambda模型获得了最高的测试精度:0.01、0.005、0.001、0.0005和0.0001。使用Bello提出的公式得到了最高的学习率(0.01)，即<strong class="ky ir"><em class="nk">initial _ lr</em></strong>= 0.1⋅b/(256⋅5)，以b作为我们128个样本的批量。其余的学习率是通过将预先计算的最高学习率连续减半而获得的。对于基线和λ层变体，可以在<strong class="ky ir"> 0.0005 </strong>处观察到最大精度。结果可以在下图中看到。</p><h1 id="ec9d" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated">10.结论</h1><p id="a794" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">LambdaNetworks承诺提供优于卷积和注意力替代方案的性能，以及更低的内存占用和在训练和推理期间的显著加速。更高的准确性主要归因于提取的基于位置和基于上下文的交互的组合，而更低的存储器使用和更高的速度是通过绕过存储器密集型注意力图、在批元素之间共享上下文信息以及在lambda层之间共享位置嵌入来实现的。在最初的论文中，Bello通过在ImageNet a ResNet-50上用lambda层交换其标准的3×3卷积来验证所有这些说法。这种数据集的选择阻碍了论文的可重复性，因为作者使用32 TPUv3进行训练，这是一种大多数学生和研究人员远远无法获得的资源。因此，本文介绍的工作通过在低维数据集(即CIFAR-10)上进行训练来评估lambda层的准确性和速度。为此，我们不仅总结了LambdaNetworks上的原始论文并介绍了我们的实现，而且还讨论了我们认为对理解或复制它有歧义的那些方面。</p><p id="d35f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从再现性项目中，我们可以突出4个主要结论:</p><ol class=""><li id="d3c3" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated">当在CIFAR-10这样的低维数据集上训练时，lambda层并不优于卷积层；然而，他们仍然达到了竞争的结果。</li><li id="69e2" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">在ImageNet数据集上，Bello报告基线准确率为76.9%，λ层准确率为78.4%。在CIFAR-10上，两种架构的精度都有所提高。这个观察暗示了在10个类别中对一幅图像进行分类的难度低于1000个类别。</li><li id="e227" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">λ层具有比卷积层更高的吞吐量，即高31%。这导致更少的训练时间。</li><li id="fdb7" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">两种架构的最佳初始学习率都是0.0005。</li></ol><p id="12bf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这项工作的结果表明，LambdaNetworks可以应用于较小的低维数据集，其性能与原始论文中提出的性能相当，并且在可承受的计算时间预算内，即几个小时而不是几天。</p><p id="0d30" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这项工作的下一步是用本地上下文实现位置lambda，其中| m |≦| n |。先前的再现性尝试为此目的使用了3D卷积。然而，得到的相对位置嵌入的维数是|m| × |k|,而不是|n| × |m| × |k|。因此，他们不是为每个像素计算相对位置嵌入，而是为整个输入计算单个位置嵌入。</p><p id="e7f9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们希望这项工作将有助于研究界对这种新型架构的讨论和潜在采用，并且我们的实施将加速业界对它的整合。</p><h1 id="4a8a" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated">11.推荐</h1><p id="2927" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">为了对获得训练和测试准确度结果所需的时间得出更合理的结论，这些运行必须执行多次，并通过取其平均值或中值进行后处理。当在(免费的)Google Colab中执行时，多次运行的重要性增加了，因为计算可用性会随着时间的推移而变化，并且人们无法正确地确定在每个时间点使用了哪个硬件配置。然而，一个会话内的结果是可比较的，但是建议在更稳定的平台上运行该算法，以便获得更准确的运行时间结果。</p><p id="58b3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Bello在ImageNet上使用的最大学习速率与我们在CIFAR-10上使用的有很大不同。当他使用一个特定的公式来获得最大学习速率时，我们使用一个粗糙的1D网格来调整学习速率。比较他的结果和我们的结果的准确性可能不公平。也许他训练过的ResNet-50和带有lambda层网络的ResNet-50的行为与我们的有很大不同，因为我们优化了学习速率。因此，他的人际网络中可能有比显示的更多的潜力。建议进行进一步的研究以找到最佳的学习速率。在这种情况下，观察热重启的调整或取消以及调度程序的类型是否会对准确性产生重大影响也是很有趣的。</p><h1 id="bc3e" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated">12.LambdaNetworks论文作者的观点</h1><p id="bdc0" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">这篇关于LambdaNetworks的论文承诺，与现有的基于注意力的替代方法相比，在加速训练和推理以及减少内存占用方面取得巨大进步，同时保持或略微提高性能。在此，我们希望向您介绍我们对该论文的看法，其中包括一些使其从现有文献中脱颖而出的方面，以及一些可以改进的地方。</p><p id="9a18" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总是先有好消息。尽管论文很长，也就是31页，但我们很高兴作者在讨论算法时非常完整和详细。Bello不仅在lambda层的部分实现中包含了紧凑的代码片段，还包含了精确再现结果所需的所有信息(本文中已经讨论了模糊性)，甚至包括用于可学习参数的初始化。此外，他还包括一项消融研究，以支持他对建筑的选择。</p><p id="b1c5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们也对论文的附录A感到非常惊讶。它以“常见问题”的形式提出了读者可以问自己的理论和实践问题。本附录中的一些条目有助于我们更好地理解论文并加以实施。因此，我们认为这是对文件的巨大补充，也是机构群体可以考虑在未来出版物中采用的成功格式。在提交给会议时，作者总是要回答审稿人提出的问题，以使他/她的提交被接受。如果这些问题不会导致最终文档的变化，它们可以作为“问答”附录包含在作者的回复中。</p><p id="945b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然这是事实，为复制文件，它包含了所有需要的信息，我们认为，作者提出了太多的变化，他的模型，使其阅读困难，有时令人困惑。因此，我们认为，该文件可能已被分成多份文件。例如，在论文的多个部分，Bello提到了ResNet-RS在挤压和激励下的使用，这是一种与lambda layers论文同时发布的架构。这种分散在整篇论文中的信息的结合只会使读者迷失方向，即使对于注意力领域的专家来说也是如此，因为该信息最近才变得可用。此外，LambdaResnets和带有lambda层的ResNet体系结构之间的区别不是很清楚。我们认为后者是前者的一个特例，但这在论文中没有明确指明。</p><p id="5fb7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除此之外，与“<a class="ae kv" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">注意力是你所需要的全部</a>”论文[2]相比，我们对LambdaNetworks论文的难度和复杂性感到惊讶。尽管架构和一般概念有许多共同点，但我们发现LambdaNetworks的论文更难阅读和可视化。鉴于这种架构的巨大潜力，我们认为可以从2017年推动机器学习领域关注的原始论文中吸取一些教训。</p><p id="6299" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，我们认为原始论文中的图2可能非常误导人，因为它没有清楚地反映出全局上下文可用于内容λ，而局部上下文用于位置λ。此外，它没有显示如何从层输入中获得上下文。由于它是唯一显示概念的图形，该图中的模糊性会对研究团体对λ层的接受和传播产生不利影响。</p><p id="df6c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总之，尽管该文件有许多含糊之处，但我们已经亲身体验了这一框架的巨大潜力。因此，我们希望作者将他未来的工作建立在lambda层的基础上，并通过提供Google Colab教程和概念的逐步解释来简化这种新方法的可访问性。通过这里提出的再现性项目和开源实现，我们希望为研究社区和行业提供访问这个新框架的便利。</p><h1 id="fba1" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated"><em class="nt">参考文献</em></h1><p id="7fdf" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">[1] I. Bello，<a class="ae kv" href="https://arxiv.org/abs/2102.08602" rel="noopener ugc nofollow" target="_blank"> LambdaNetworks:建模无注意的远程交互</a> (2021)，学习表征国际会议</p><p id="092b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2] A. Vaswani，N. Shazeer，N. Parmar，J. Uszkoreit，L. Jones，A. N. Gomez，L. Kaiser和I. Polosukhin，<a class="ae kv" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">注意力是你所需要的全部</a> (2017)，神经信息处理系统的进展</p><p id="3910" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3]李，苏，段，郑，<a class="ae kv" href="https://arxiv.org/abs/2007.14902" rel="noopener ugc nofollow" target="_blank">线性注意机制:一种有效的语义切分注意机制</a> (2020)，arXiv:2007.14902 [cs .简历]</p><p id="9e22" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[4] S. Ioffe和C. Szegedy，<a class="ae kv" href="https://arxiv.org/abs/1502.03167" rel="noopener ugc nofollow" target="_blank">批量标准化:通过减少内部协变量偏移加速深度网络训练</a> (2015)，第32届国际机器学习会议论文集</p><p id="417b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[5] C. Szegedy，V. Vanhoucke，S. Ioffe，J. Shlens和Z. Wojna，<a class="ae kv" href="https://arxiv.org/abs/1512.00567" rel="noopener ugc nofollow" target="_blank">重新思考计算机视觉的初始架构</a> (2016)，2016年IEEE计算机视觉和模式识别会议(CVPR)</p><p id="0e29" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[6]何国光，张，任，孙，【深度残差学习用于图像识别】 (2016)，2016年IEEE计算机视觉与模式识别会议(CVPR)</p></div></div>    
</body>
</html>