<html>
<head>
<title>Word Vectors Intuition and Co-Occurrence Matrixes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">词向量直觉和共现矩阵</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/word-vectors-intuition-and-co-occurence-matrixes-a7f67cae16cd?source=collection_archive---------8-----------------------#2021-08-16">https://towardsdatascience.com/word-vectors-intuition-and-co-occurence-matrixes-a7f67cae16cd?source=collection_archive---------8-----------------------#2021-08-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/a309c09cf220377d7441dbaf1e50467d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bPd3Lur4gPypGJ81"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">照片由<a class="ae kf" href="https://unsplash.com/@raphaelphotoch" rel="noopener ugc nofollow" target="_blank">@拉斐尔摄影</a>—Unsplash.com拍摄</p></figure><p id="7d56" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated"><span class="l lf lg lh bm li lj lk ll lm di">如果你对自然语言处理做过一些研究，你可能会偶然发现单词向量的概念。虽然这个概念似乎很直观，但如果你没有数据科学或机器学习方面的知识，可能会有点难以理解。</span></p><p id="4312" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，我们将检查构建单词向量背后的一些直觉，并了解当我们谈到几个NLP应用程序时，为什么它们是相关的。我们将使用一个简单的共现概念来解释为什么一键向量不是将单词表示为数字的最佳方法。</p></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><p id="4440" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们先用两个词来举例——<em class="lu">车</em>和<em class="lu">吉普。</em>对于人类来说，这两个词可能有某种程度的相似性，因为我们知道<em class="lu">吉普车</em>和<em class="lu">汽车</em>有相似的特征——它们都是有发动机的四轮车辆，用于运输或休闲目的。我们可以用这样的短语:</p><ul class=""><li id="64fc" class="lv lw it ki b kj kk kn ko kr lx kv ly kz lz ld ma mb mc md bi translated">吉普车是汽车的一种。</li><li id="b9ad" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">我的<em class="lu">车</em>是一辆<em class="lu">吉普。</em></li><li id="7539" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated"><em class="lu">吉普车</em>类似于其他<em class="lu">汽车</em></li><li id="1987" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated"><em class="lu">吉普</em>类似于<em class="lu">车，</em>但不是<em class="lu">车。</em></li></ul><figure class="mj mk ml mm gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/b378959d11b0b316bd91eb7d64e7d59a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4fN6CJOKANdNzl-N"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">一辆吉普车与其他汽车有一些共同的特征(照片由<a class="ae kf" href="https://unsplash.com/@neonbrand" rel="noopener ugc nofollow" target="_blank">@ neon brand</a>—Unsplash.com拍摄)</p></figure><p id="a893" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">一个有意思的事情是<em class="lu">车</em>和<em class="lu">吉普</em>都可能在一句话里做替身:</strong></p><ul class=""><li id="f381" class="lv lw it ki b kj kk kn ko kr lx kv ly kz lz ld ma mb mc md bi translated">我正骑着我的<em class="lu">车</em>去海滩；</li><li id="f487" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">我正骑着我的吉普车去海滩；</li></ul><p id="a1a0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这两个词都被描绘成主体用来走向海滩的物体。这两个词也可以属于<em class="lu">车辆的范畴:</em> <strong class="ki iu">通常有轮子和发动机的机器，用于运送人或货物，尤指在陆地上。</strong></p><p id="a4a7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们人类有能力以一种非常简单的方式理解这两个词之间的相似性，因为当我们阅读这两个词时，我们可以在脑海中创建一辆汽车或一辆吉普车的图像。但是计算机怎么能像你我一样理解这两个词之间的这些概念呢？</p></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><p id="b6a0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们先做一些基本的实验——在排序单词时，我们能想到的第一个方法是按字母顺序排序。我们现在把字母表看成是某种固有的顺序，所以，让我们天真地假设这可能会把相似的单词组合在一起。</p><ul class=""><li id="88f0" class="lv lw it ki b kj kk kn ko kr lx kv ly kz lz ld ma mb mc md bi translated"><em class="lu">汽车</em>以<em class="lu"> c </em>启动</li><li id="0364" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated"><em class="lu">吉普</em>始于<em class="lu"> j </em></li></ul><p id="deba" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以想出一大堆介于字母表中的<em class="lu">车</em>和<em class="lu">吉普</em>之间的单词——比如<em class="lu">爸爸</em>、<em class="lu">欧洲</em>、<em class="lu">决赛</em>、<em class="lu">痒</em>。所有这些单词都有完全不同的意思，所以我们可以排除这个想法。</p><p id="8e31" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们比较单词的字母呢？有些词表达了相似的意思，有相似的字母，例如:</p><ul class=""><li id="a6cb" class="lv lw it ki b kj kk kn ko kr lx kv ly kz lz ld ma mb mc md bi translated"><em class="lu">创建</em>和<em class="lu">创建</em></li><li id="ef34" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated"><em class="lu">书</em>和<em class="lu">书架</em></li></ul><p id="ebe2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不幸的是，英语并没有那么简单。<em class="lu">吉普</em>和<em class="lu">轿车，</em>为例，不共用任何字母。而<em class="lu">鹿</em>和<em class="lu">深</em>呢？他们共享四个字母中的三个，他们的意思不可能不同。</p><p id="1071" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">似乎使用单词中包含的字母是一个微不足道的练习。我们还可以根据上下文，在单词和相似单词之间建立一个巨大的查找表。但是想象一下，为了跟踪特定语言的自然进化而更新那个表会有多混乱。</p><p id="30a0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们尝试另一种方法——用更“数学”的方式来看待我们的单词。</p></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="e093" class="mn mo it bd mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk bi translated">一个热点向量方法</h1><p id="50c4" class="pw-post-body-paragraph kg kh it ki b kj nl kl km kn nm kp kq kr nn kt ku kv no kx ky kz np lb lc ld im bi translated">直接看我们的信看起来像是一个不会给我们带来任何结果的练习。很自然，随之而来的是某种想法，将我们的文字表示为数字。</p><p id="a1b4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将一个单词表示为单个数字会导致我们得到与按字母顺序比较单词相同的结果——我们必须附加一个单词的单个数字。这个数字旁边的单词在某种程度上会被认为是相似的单词，我们仍然会有正确排序的问题。</p><p id="da64" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以，一个可行的方法是，我们可以用多维数字的方式来表示我们的单词。我们可以使用的一种数据结构是<strong class="ki iu">数组(或向量)——例如</strong>:</p><pre class="mj mk ml mm gt nq nr ns nt aw nu bi"><span id="c0c4" class="nv mo it nr b gy nw nx l ny nz">[1, 0, 0, 0, 0]</span></pre><p id="8ab8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面的数组是一个<strong class="ki iu">独热向量</strong>的例子——一个向量在单个值中包含1，在其他值中包含0。这些热点向量可以用来表示我们称之为词汇表的一组单词中的特定单词。</p><p id="3c0b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">回到我们的例子，让我们想象我们的词汇将由以下单词组成:</p><ul class=""><li id="694d" class="lv lw it ki b kj kk kn ko kr lx kv ly kz lz ld ma mb mc md bi translated">自行车</li><li id="8943" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">步行</li><li id="b4ef" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">吉普车</li><li id="4ab2" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">汽车</li><li id="0205" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">卡车</li><li id="0dfa" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">自行车</li></ul><p id="57f3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">看着这些单词，我们可以建立几个心理“集群”:</p><ul class=""><li id="2a84" class="lv lw it ki b kj kk kn ko kr lx kv ly kz lz ld ma mb mc md bi translated">所有这些单词都与一个人从一个地方移动到另一个地方的方法有关。</li><li id="f636" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">看起来最“关”的词是<em class="lu">走</em>这个词</li><li id="8367" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">人们可以把两轮车(自行车和三轮车)与四轮或四轮以上的车(卡车、轿车和吉普车)区分开来。</li></ul><p id="8c99" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们能否重建数组，以某种方式传达这些单词的细节？</p><p id="c86c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们先来整理一下我们的词汇:</p><pre class="mj mk ml mm gt nq nr ns nt aw nu bi"><span id="a194" class="nv mo it nr b gy nw nx l ny nz">bike, bicycle, car, jeep, truck, walk</span></pre><p id="9f2d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，用我们的单词代替0，将上面的元素转换成数组格式:</p><pre class="mj mk ml mm gt nq nr ns nt aw nu bi"><span id="2cda" class="nv mo it nr b gy nw nx l ny nz">[0, 0, 0, 0, 0, 0]</span></pre><p id="7c59" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在可以用一个热点向量来表示我们的单词，例如:</p><ul class=""><li id="ffc5" class="lv lw it ki b kj kk kn ko kr lx kv ly kz lz ld ma mb mc md bi translated">自行车用[1，0，0，0，0，0]来表示</li><li id="575b" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">行走由[0，0，0，0，0，1]表示</li></ul><p id="42db" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些词向量的主要问题是它们是<strong class="ki iu">正交的。</strong>我在这里就不跟你讲数学了，但是，这意味着这些向量的点积大约为0——如果我们以二维方式可视化<em class="lu">汽车</em>和<em class="lu">吉普车</em>的向量:</p><figure class="mj mk ml mm gt ju gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/e4cf2e2f9f6e18ea41560e5fda5222e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*hkCDAgHQ_5qg6jsBITyO1A.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">一个热点向量的二维表示——由平面图标表示的图标</p></figure><p id="bc4c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些向量之间的角度约为90度。这将引起一些麻烦，因为代表<em class="lu">汽车</em>和<em class="lu">吉普车</em>的向量之间的相似性将与<em class="lu">汽车</em>和<em class="lu">步行</em>或<em class="lu">汽车</em>和<em class="lu">自行车之间的相似性完全相同。</em></p><p id="9f2a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">我们如何以向量反映相似性的方式来表示这些向量？</strong></p></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="01d4" class="mn mo it bd mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk bi translated">共现表示</h1><p id="9797" class="pw-post-body-paragraph kg kh it ki b kj nl kl km kn nm kp kq kr nn kt ku kv no kx ky kz np lb lc ld im bi translated">同现表示帮助你建立单词的上下文。没有什么比语言学家约翰·弗斯的话更能阐明这个概念了:</p><blockquote class="ob oc od"><p id="0db4" class="kg kh lu ki b kj kk kl km kn ko kp kq oe ks kt ku of kw kx ky og la lb lc ld im bi translated"><em class="it">“从一个人交的朋友就可以知道他说的一句话”</em></p></blockquote><p id="161b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">事实上，一个词是由其上下文反映出来的。让我们想象一些简单的句子来反映这一点:</p><ul class=""><li id="fb0b" class="lv lw it ki b kj kk kn ko kr lx kv ly kz lz ld ma mb mc md bi translated">我正开车去海滩。</li><li id="d65d" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">我开着我的吉普车去海滩。</li><li id="451a" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">我的汽车是一辆吉普车。</li><li id="c74b" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">我的吉普车是一辆小汽车。</li><li id="0577" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">我昨天吃了一根香蕉。</li><li id="7382" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">我昨天吃了一个桃子。</li></ul><p id="90fa" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如你可能意识到的，意思完全不同的单词在同一上下文中同时出现的可能性极小。<strong class="ki iu">让我们称之为单词的上下文，即围绕在特定单词两边的两个单词</strong>——例如在句子<em class="lu">中，我昨天吃了一个桃子，</em>桃子这个单词被以下单词所包围:</p><ul class=""><li id="e91a" class="lv lw it ki b kj kk kn ko kr lx kv ly kz lz ld ma mb mc md bi translated">昨天吃了一个</li></ul><p id="5027" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这些单词中，你找到不同于食物的东西的可能性很小。你不会发现下面这句话的可能性:</p><blockquote class="ob oc od"><p id="2923" class="kg kh lu ki b kj kk kl km kn ko kp kq oe ks kt ku of kw kx ky og la lb lc ld im bi translated">我昨天吃了一辆吉普车</p></blockquote><p id="aa66" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">或者</p><blockquote class="ob oc od"><p id="3bbf" class="kg kh lu ki b kj kk kl km kn ko kp kq oe ks kt ku of kw kx ky og la lb lc ld im bi translated">我昨天吃了一辆自行车</p></blockquote><p id="d7c8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是共现表征背后的主要原理——彼此相似的单词往往会一起共现。最常见的共现表示是单个单词的单词表示。让我们检查一下！</p><h1 id="b0f1" class="mn mo it bd mp mq oh ms mt mu oi mw mx my oj na nb nc ok ne nf ng ol ni nj nk bi translated">共生矩阵</h1><p id="6a6e" class="pw-post-body-paragraph kg kh it ki b kj nl kl km kn nm kp kq kr nn kt ku kv no kx ky kz np lb lc ld im bi translated">为了构建共现矩阵，我们必须从特定语料库中的完整词汇开始，就像我们在one-hot vector部分中所做的那样——让我们看看上面示例中这组句子的词汇，考虑单个gram:</p><pre class="mj mk ml mm gt nq nr ns nt aw nu bi"><span id="9ca3" class="nv mo it nr b gy nw nx l ny nz">a, ate, banana, beach, car, in, is, I’m, jeep, my, riding, to, the, yesterday</span></pre><p id="74c1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在上面所有的句子中，我们的词汇由一组不同的单词组成。与one-hot vectors类似，我们的向量将由大小为<em class="lu"> k、</em>的向量组成，其中<em class="lu"> k </em>是不同单词的数量——让我为单词<em class="lu"> car </em>初始化一个示例向量:</p><pre class="mj mk ml mm gt nq nr ns nt aw nu bi"><span id="9034" class="nv mo it nr b gy nw nx l ny nz">[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</span></pre><p id="5fe5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我们的句子中，单词<em class="lu"> car </em>出现在三个句子中:</p><blockquote class="ob oc od"><p id="98d9" class="kg kh lu ki b kj kk kl km kn ko kp kq oe ks kt ku of kw kx ky og la lb lc ld im bi translated">我正骑着我的车<strong class="ki iu">去</strong>海滩<strong class="ki iu">。</strong></p><p id="c86a" class="kg kh lu ki b kj kk kl km kn ko kp kq oe ks kt ku of kw kx ky og la lb lc ld im bi translated">我的车<strong class="ki iu">是一辆</strong>吉普。</p><p id="500f" class="kg kh lu ki b kj kk kl km kn ko kp kq oe ks kt ku of kw kx ky og la lb lc ld im bi translated"><strong class="ki iu">我的</strong>吉普<strong class="ki iu">是一辆</strong>车。</p></blockquote><p id="2842" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">我已经标出了句子中所有与单词<em class="lu"> car </em>同时出现的单词。</strong>如果我们将<strong class="ki iu"> 1 </strong>加到每个共现的元素上，返回的单词向量会是多少？—更新单词<em class="lu"> car </em>的向量:</p><pre class="mj mk ml mm gt nq nr ns nt aw nu bi"><span id="0650" class="nv mo it nr b gy nw nx l ny nz">a, ate, banana, beach, car, in, is, I’m, jeep, my, riding, to, the, [2,   0,     0,     0,   0,  1,  2,   0,    0,  2,      0,  1,   1, yesterday<br/>0]</span></pre><p id="4aee" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个共现向量现在将表示单词car。</p><p id="86bc" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们为单词<em class="lu"> jeep </em>建立相同的向量会怎么样？查看我们的示例:</p><blockquote class="ob oc od"><p id="39ec" class="kg kh lu ki b kj kk kl km kn ko kp kq oe ks kt ku of kw kx ky og la lb lc ld im bi translated">我的车是一辆吉普车。</p><p id="67a7" class="kg kh lu ki b kj kk kl km kn ko kp kq oe ks kt ku of kw kx ky og la lb lc ld im bi translated">我正骑着我的吉普车去海滩。</p><p id="5a93" class="kg kh lu ki b kj kk kl km kn ko kp kq oe ks kt ku of kw kx ky og la lb lc ld im bi translated">我的车<strong class="ki iu">是一辆</strong>吉普。</p></blockquote><p id="166d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">产生的共现向量将是:</p><pre class="mj mk ml mm gt nq nr ns nt aw nu bi"><span id="8901" class="nv mo it nr b gy nw nx l ny nz">a, ate, banana, beach, car, in, is, I’m, jeep, my, riding, to, the, [2,   0,     0,     0,   0,  1,  2,   0,    0,  2,      0,  1,   1, yesterday<br/>0]</span></pre><p id="88d8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你注意到了，这个向量和我们对单词<em class="lu"> car的向量完全一样。发生这种情况是因为，在我们的句子中，这些单词往往与相同的单词同时出现。这似乎是一个有前途的方法！</em></p><p id="94cf" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们检查单词banana的向量，共现向量完全不同:</p><blockquote class="ob oc od"><p id="bbbe" class="kg kh lu ki b kj kk kl km kn ko kp kq oe ks kt ku of kw kx ky og la lb lc ld im bi translated">我<strong class="ki iu">昨天吃了一根</strong>香蕉<strong class="ki iu"/>。</p></blockquote><pre class="mj mk ml mm gt nq nr ns nt aw nu bi"><span id="146b" class="nv mo it nr b gy nw nx l ny nz">a, ate, banana, beach, car, in, is, I’m, jeep, my, riding, to, the, [1,   1,     0,     0,   0,  0,  0,   0,    0,  0,      0,  0,   0, yesterday<br/>1]</span></pre><p id="9e4a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">我们为单词banana生成的向量与为Jeep和Car生成的向量完全不同。</strong></p><p id="c204" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我几乎能听到你在想——“<em class="lu">等一下……</em><em class="lu">这些例子似乎都是为了符合解释</em>”而吹毛求疵。</p><p id="087d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这倒是真的！为了检查这在更大的文本中是否有意义，让我们在维基百科的一篇文章上做一个快速实现。</p><p id="271a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">之后我们将学习如何量化向量之间的关系(提示:<strong class="ki iu">相似性度量！</strong>)</p></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="2a0d" class="mn mo it bd mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk bi translated">大文章单词共现</h1><p id="477b" class="pw-post-body-paragraph kg kh it ki b kj nl kl km kn nm kp kq kr nn kt ku kv no kx ky kz np lb lc ld im bi translated">让我们直接进入Python实现，在这里我们将提取维基百科<em class="lu">美利坚合众国</em>文章中所有单词的共现向量— <strong class="ki iu">首先，让我们检索数据并将其标记化</strong>(不要担心代码，我们最后会有一个要点！):</p><pre class="mj mk ml mm gt nq nr ns nt aw nu bi"><span id="6fb1" class="nv mo it nr b gy nw nx l ny nz">def retrieve_page(page_name: str) -&gt; list:<br/>    '''<br/>    Retrieves page data from wikipedia<br/>    and stores words in lower case format in<br/>    a list - tokenized format.<br/>    '''<br/>    usa_article = wikipedia.page(page_name)<br/>    # Strip puncuation from page<br/>    usa_article = (<br/>        usa_article.content.translate(str.maketrans('', '', string.punctuation))<br/>    )<br/>    # Lower text case<br/>    usa_article = usa_article.lower()<br/>    # Tokenize using NLTK word tokenizer<br/>    usa_article_token = word_tokenize(usa_article)<br/>    return usa_article_token</span><span id="690b" class="nv mo it nr b gy om nx l ny nz">usa_article_token = retrieve_page('United States of America')</span></pre><p id="7b3b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">我们的<em class="lu"> usa_article_token </em>以标记化的格式包含了整个维基百科文章</strong>——让我们看看文章的第一段:</p><figure class="mj mk ml mm gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi on"><img src="../Images/8adb6225f382fc494b4ef9fcc3861204.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Y2bONzLPLHF3Wn9y86ArQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">美国维基百科文章的第一段</p></figure><p id="3400" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从文章中提取所有句子后，我们能够理解每个单词的上下文——在上面的文本中，单词<em class="lu">平方</em>(第四行)<em class="lu"> </em>具有以下上下文，去掉标点符号:<strong class="ki iu"> 3.8，百万，英里，9.8 </strong></p><p id="06c1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">鉴于此，我们现在可以为文本中的每个单词构建共现向量，让我们编码吧！</p><p id="5fc1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从构建我们的词汇开始，词汇将由我们的共现向量的大小组成:</p><pre class="mj mk ml mm gt nq nr ns nt aw nu bi"><span id="93b3" class="nv mo it nr b gy nw nx l ny nz">def build_vocabulary(page:list) -&gt; list:<br/>    '''<br/>    Builds vocabulary with all the words<br/>    present in the list page.<br/>    '''<br/>    vocab = list(set(page))<br/>    vocab.sort()<br/>    <br/>    vocab_dict = {}<br/>    for index, word in enumerate(vocab):<br/>        vocab_dict[word] = index<br/>    return vocab_dict</span><span id="1cd7" class="nv mo it nr b gy om nx l ny nz">vocab_dict = build_vocabulary(usa_article_token)</span></pre><p id="dccb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">警告:由于维基百科文章的更新，当您运行这段代码时，词汇表的大小可能会有所不同。</p><p id="6672" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的词汇表中有大约3.640个单词——我们的<em class="lu"> vocab_dict </em>对象包含单词和索引之间的映射——这个索引将使我们能够更快地填充共现向量。</p><p id="eda3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将我们的同现矩阵初始化为0-我将使用熊猫数据框来简化可视化:</p><pre class="mj mk ml mm gt nq nr ns nt aw nu bi"><span id="67d2" class="nv mo it nr b gy nw nx l ny nz">co_ocurrence_vectors = pd.DataFrame(<br/>    np.zeros([len(vocab_dict), len(vocab_dict)]),<br/>    index = vocab_dict.keys(),<br/>    columns = vocab_dict.keys()<br/>)</span></pre><p id="1819" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是我们初始化的共现矩阵的大致外观——行由单词<em class="lu"> i </em>的索引组成，列由单词<em class="lu"> j </em>与单词<em class="lu"> i. </em>共现<em class="lu"> n次组成</em></p><figure class="mj mk ml mm gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oo"><img src="../Images/2a5a9c0c1aa7759001a0f3f455e5c904.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lJulF8CuupWa3rs5VjI3Pg.png"/></div></div></figure><p id="5b2d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，根据上下文，每当我们在我们在行中看到的单词的上下文中看到特定的单词时，我将添加<strong class="ki iu"> 1 </strong>。<strong class="ki iu">例如，在本文中，单词<em class="lu">表示</em>应该与单词<em class="lu"> United </em>以及可能的<em class="lu"> America </em>同时出现。</strong></p><p id="a1ed" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用Python更新矩阵:</p><pre class="mj mk ml mm gt nq nr ns nt aw nu bi"><span id="0ea6" class="nv mo it nr b gy nw nx l ny nz">def build_context(<br/>    page:str, <br/>    co_ocurrence_vectors: pd.DataFrame<br/>) -&gt; pd.DataFrame:<br/>    '''<br/>    Updates co-ocurrence vectors based on<br/>    text read from the page.<br/>    '''<br/>    for index, element in enumerate(page):<br/>        # Build start and finish of context<br/>        start = 0 if index-2 &lt; 0 else index-2<br/>        finish = len(page) if index+2 &gt; len(page) else index+3</span><span id="5d39" class="nv mo it nr b gy om nx l ny nz">        # Retrieve Context for word<br/>        context = page[start:index]+page[index+1:finish]<br/>        for word in context:<br/>            # Update Co-Occurrence Matrix <br/>            co_ocurrence_vectors.loc[element, word] = (<br/>                co_ocurrence_vectors.loc[element, word]+1<br/>            )<br/>            <br/>    return co_ocurrence_vectors</span><span id="91a1" class="nv mo it nr b gy om nx l ny nz">co_ocurrence_vectors = build_context(usa_article_token, co_ocurrence_vectors)</span></pre><p id="8b9a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们可以从我们的共现矩阵中提取与<em class="lu">状态</em>共现更多的词，例如前10个词:</p><pre class="mj mk ml mm gt nq nr ns nt aw nu bi"><span id="5169" class="nv mo it nr b gy nw nx l ny nz">co_ocurrence_vectors.loc['states'].sort_values(ascending=False).head(10)</span></pre><figure class="mj mk ml mm gt ju gh gi paragraph-image"><div class="gh gi op"><img src="../Images/4fd32f63efc37e95a391a18bac530260.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*EwvTrgwl8-IPQ2GITRqjoQ.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">与州共现的前10个单词</p></figure><p id="663d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lu"/>是与文本共现次数最多的第一个词——在我们的文本中出现了189次(在两个邻居的窗口中)，其次是<em class="lu"> united </em>和<em class="lu"> is。</em>另一方面，<em class="lu">美国</em>是第九个——如果你注意到这篇文章，<em class="lu">美国</em>在整篇文章中被用作<em class="lu">美利坚合众国</em>的别名，所以，这是有道理的。</p><p id="e7f6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">爽！所以我们现在有了3.640个单词的多维向量。</strong></p><p id="55f4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们如何衡量它们的相似性？</p></div><div class="ab cl ln lo hx lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="im in io ip iq"><h1 id="9137" class="mn mo it bd mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk bi translated">余弦相似性</h1><p id="7009" class="pw-post-body-paragraph kg kh it ki b kj nl kl km kn nm kp kq kr nn kt ku kv no kx ky kz np lb lc ld im bi translated">测量两个向量之间相似性的最常见方法之一是使用余弦相似性——测量任意向量<strong class="ki iu"><em class="lu"/></strong>A和向量<strong class="ki iu"> <em class="lu"> B </em> </strong>之间的相似性:</p><figure class="mj mk ml mm gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oq"><img src="../Images/d4c8ccdff1da8f7dc037ac207299205d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*koI1MIvINGYn2vU1.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">余弦相似性公式(来自维基百科)</p></figure><p id="3125" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我们的例子中，我们将有3.640个元素</p><p id="4c9d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">余弦相似性为我们提供了一种相似性度量，其范围在以下值之间:</strong></p><ul class=""><li id="e718" class="lv lw it ki b kj kk kn ko kr lx kv ly kz lz ld ma mb mc md bi translated">1如果向量真的相似；</li><li id="db41" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">如果向量没有任何关系(正交向量！);</li><li id="ce97" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">如果向量相反，则为-1；</li></ul><p id="2ed5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">按逻辑，相似的词会有更高的余弦相似度。如果向量完全相同，则余弦相似度将为1。让我们看看维基百科文章中的一些例子——搜索与单词<em class="lu"> States — </em> <strong class="ki iu">具有高余弦相似度的单词。首先，我们需要使用<em class="lu"> scikit-learn </em>实现<em class="lu"> : </em> </strong>在文章中的每个单词之间创建余弦相似度</p><pre class="mj mk ml mm gt nq nr ns nt aw nu bi"><span id="8021" class="nv mo it nr b gy nw nx l ny nz">similarity_words = pd.DataFrame(<br/>    cosine_similarity(co_ocurrence_vectors),<br/>    columns = vocab_dict.keys(),<br/>    index = vocab_dict.keys()<br/>)</span></pre><p id="d10d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">就相似性而言，检查顶部单词与单词<em class="lu">的状态:</em></p><figure class="mj mk ml mm gt ju gh gi paragraph-image"><div class="gh gi or"><img src="../Images/95b867ae8e57bcf51fd37bc8c1ebd08c.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/1*7P_LkjUTwrVyD8vypyv4Kw.png"/></div></figure><p id="be8c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有些词看起来确实有道理——比如<em class="lu">国家、王国</em>和<em class="lu">宪法。</em>其他词有点偏— <em class="lu">离开，的，在— </em>但是，即便如此，这些结果还是很有意思。</p><p id="2f16" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们检查另一个词，如<em class="lu">中国:</em></p><figure class="mj mk ml mm gt ju gh gi paragraph-image"><div class="gh gi os"><img src="../Images/21ec40aa60238f9178689c4949e68098.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*y5amd_M9VskkA4_JmfvP1Q.png"/></div></figure><p id="959a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">同样，有些词似乎很有意义，比如菲律宾、加拿大和墨西哥等其他国家——但也有一些词看起来很“奇怪”,因为它们与“中国”这个词很接近。</p><p id="b714" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当然，我们只使用了维基百科中的一篇文章，所以，我们并不期待完美。如今，共现矩阵是很好的第一手资料，可以很好地掌握单词向量背后的必要性和直觉。</p><p id="37bb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">使用共现向量有一些缺点，即:</strong></p><ul class=""><li id="e0ba" class="lv lw it ki b kj kk kn ko kr lx kv ly kz lz ld ma mb mc md bi translated">同现向量变得很大，很快。你的词汇量越大，你的向量就越大。</li><li id="efb3" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">大多数共生矩阵包含零和无信息。您可以通过使用稀疏格式来解决空间问题，但即使如此，一些罕见的单词可能具有非常糟糕的向量表示。</li><li id="9f29" class="lv lw it ki b kj me kn mf kr mg kv mh kz mi ld ma mb mc md bi translated">共现向量无法把握对立词的概念。</li></ul><p id="3d25" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其他技术已经被用于表示单词向量，例如包含压缩版本的<a class="ae kf" href="https://en.wikipedia.org/wiki/Word2vec" rel="noopener ugc nofollow" target="_blank"> Word2Vec </a>和可能的<em class="lu">隐藏的</em>共现表示，后者概括得更好一些。我们将把它留给下一篇文章！</p><p id="7f6c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是这篇文章代码的要点:</p><figure class="mj mk ml mm gt ju"><div class="bz fp l di"><div class="ot ou l"/></div></figure><blockquote class="ob oc od"><p id="e668" class="kg kh lu ki b kj kk kl km kn ko kp kq oe ks kt ku of kw kx ky og la lb lc ld im bi translated">感谢你花时间阅读这篇文章！我希望你喜欢它，并随时添加我到LinkedIn或者给我发消息！</p></blockquote><p id="df25" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> <em class="lu">这个例子摘自我的</em> </strong> <a class="ae kf" href="https://www.udemy.com/course/nlp_natural_language_processing_python_beginners/?referralCode=ABA4DB815299652F2A37" rel="noopener ugc nofollow" target="_blank"> <strong class="ki iu"> <em class="lu"> NLP课程，该课程面向Udemy平台上的绝对初学者</em></strong></a><strong class="ki iu"><em class="lu">——该课程非常适合初学者和希望学习自然语言处理基础知识的数据科学家。该课程还包含50多个编码练习，使您能够在学习新概念的同时进行练习。</em>T13】</strong></p><div class="ov ow gp gr ox oy"><a href="https://ivopbernardo.medium.com/membership" rel="noopener follow" target="_blank"><div class="oz ab fo"><div class="pa ab pb cl cj pc"><h2 class="bd iu gy z fp pd fr fs pe fu fw is bi translated">通过我的推荐链接加入Medium-Ivo Bernardo</h2><div class="pf l"><h3 class="bd b gy z fp pd fr fs pe fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pg l"><p class="bd b dl z fp pd fr fs pe fu fw dk translated">ivopbernardo.medium.com</p></div></div><div class="ph l"><div class="pi l pj pk pl ph pm jz oy"/></div></div></a></div></div></div>    
</body>
</html>