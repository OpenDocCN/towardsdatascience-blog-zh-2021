<html>
<head>
<title>Analyzing commonly used slang words on TikTok using Twitter</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Twitter分析抖音常用俚语</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/analyzing-commonly-used-slang-words-on-tiktok-using-twitter-3b9043e32f93?source=collection_archive---------6-----------------------#2021-10-17">https://towardsdatascience.com/analyzing-commonly-used-slang-words-on-tiktok-using-twitter-3b9043e32f93?source=collection_archive---------6-----------------------#2021-10-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="41a7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我们如何在Python &amp; Tableau上使用情感分析和主题建模来发现俚语的含义和用法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/45461efea469ea283a0516a75e749c56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r7nejeqqPB1lUzLrLjp85w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供— Tableau仪表板</p></figure></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><p id="a57b" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">近年来，抖音在全球范围内一直呈上升趋势，特别是在1997年至2015年出生的Z世代人口中。像<strong class="lh iu"> <em class="mb"> LOL </em> </strong>(笑出声来)<strong class="lh iu"> <em class="mb"> ROFL </em> </strong>(笑得在地上打滚)<strong class="lh iu"> <em class="mb"> FOMO </em> </strong>(害怕错过)这些俚语是我们大多数人都知道的，但是抖音的崛起带来了另一套俚语吗？事实上，根据<a class="ae mc" href="https://thesmartlocal.com/read/tiktok-slangs/" rel="noopener ugc nofollow" target="_blank"> TheSmartLocal </a>(新加坡领先的旅游和生活方式门户网站)，有9个抖音俚语被认为是Z世代孩子常用的。平台上正在使用的<strong class="lh iu"> <em class="mb"> bussin </em> </strong>，<strong class="lh iu"><em class="mb">no cap</em></strong>&amp;<strong class="lh iu"><em class="mb">sheesh</em></strong>等词汇是指什么？像<strong class="lh iu"> <em class="mb"> bestie </em> </strong>，<strong class="lh iu"> <em class="mb"> fax </em> </strong> <em class="mb">，</em>或者<strong class="lh iu"> <em class="mb"> slaps </em> </strong>这样的常见英文单词，意思还一样吗？</p><p id="372c" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">这篇文章解释了9个俚语的意思，以及如何在对话中使用它们。在本文中，我们将从数据科学的角度来分析这些俚语，我们将使用Python来进行一些自然语言处理(NLP)技术，如情感分析和主题建模。这将使我们更好地了解通常与俚语一起使用的一些关联单词，信息的情感，以及与这些单词一起讨论的话题。</p><h2 id="8ba8" class="md me it bd mf mg mh dn mi mj mk dp ml lo mm mn mo ls mp mq mr lw ms mt mu mv bi translated">资料组</h2><p id="1cf3" class="pw-post-body-paragraph lf lg it lh b li mw ju lk ll mx jx ln lo my lq lr ls mz lu lv lw na ly lz ma im bi translated">我们将利用另一个社交媒体平台Twitter，在一个月内，包含9个俚语中任何一个的推文将被捕获，这将形成我们的整个数据集。Python <code class="fe nb nc nd ne b">twitter</code>上的Twitter公共API库允许我们在获得消费者密钥和访问令牌的身份验证后收集过去7天的tweets。一旦我们初始化了与Twitter的连接，我们就设置了纬度、经度的最大区域范围，并将搜索查询设置为俚语词。由于我对提取新加坡用户的推文感兴趣，所以我将地理位置设置为新加坡。最喜爱的计数和转发计数也是从Twitter上收集的。</p><pre class="kj kk kl km gt nf ne ng nh aw ni bi"><span id="c98c" class="md me it ne b gy nj nk l nl nm"># import libraries<br/>from twitter import *<br/>import pandas as pd<br/>from datetime import datetime</span><span id="802d" class="md me it ne b gy nn nk l nl nm"># store the slang words in a list<br/>slangs = ['fax', 'no cap', 'ceo of', 'stan', 'bussin', 'slaps', 'hits different', 'sheesh', 'bestie']</span><span id="52df" class="md me it ne b gy nn nk l nl nm"># twitter authentication<br/>consumer_key = '...'<br/>consumer_secret = '...'<br/>access_token = '...'<br/>access_token_secret = '...'<br/>twitter = Twitter(auth = OAuth(access_token, access_token_secret, consumer_key, consumer_secret))</span><span id="2ec5" class="md me it ne b gy nn nk l nl nm"># set latitude &amp; longitude to Singapore, maximum radius 20km<br/>latitude = 1.3521    <br/>longitude = 103.8198    <br/>max_range = 20</span><span id="4a2b" class="md me it ne b gy nn nk l nl nm"># loop through each of the slang<br/>for each in slangs:<br/>    # extract tweets with query containing the planning area; note max count for standard API is 100<br/>    query = twitter.search.tweets(q = each, geocode = "%f,%f,%dkm" % (latitude, longitude, max_range),\<br/>                                  lang = 'en', count = 100)<br/>    # once done, loop through each tweet<br/>    for i in range (0, len(query['statuses'])):<br/>        # store the planning area, tweet, created time, retweet count &amp; favorite count as a list variable<br/>        temp_list = [each, query['statuses'][i]['text'],\<br/>                     datetime.strptime(query['statuses'][i]['created_at'], '%a %b %d %H:%M:%S %z %Y').strftime('%Y-%m-%d'),\<br/>                    query['statuses'][i]['retweet_count'], query['statuses'][i]['favorite_count']]<br/>        # append list to tweets dataframe<br/>        tweets.loc[len(tweets)] = temp_list</span></pre><h2 id="24ab" class="md me it bd mf mg mh dn mi mj mk dp ml lo mm mn mo ls mp mq mr lw ms mt mu mv bi translated">数据清理/令牌化</h2><p id="3c65" class="pw-post-body-paragraph lf lg it lh b li mw ju lk ll mx jx ln lo my lq lr ls mz lu lv lw na ly lz ma im bi translated">由于收集的推文是原始形式，包含用户名、表情符号和标点符号等单词，因此有必要进行数据清理以删除它们。我们将首先把所有的大小写转换成小写，过滤掉单个单词的回答，删除标点符号/网址/链接。</p><pre class="kj kk kl km gt nf ne ng nh aw ni bi"><span id="6416" class="md me it ne b gy nj nk l nl nm"># function to clean column, tokenize &amp; consolidate into corpus list<br/>def column_cleaner(column, slang_word):<br/>    # convert all to lower case and store in a list variable<br/>    corpus = column.str.lower().tolist()<br/>    # filter off single word responses, 'nil', 'nan'<br/>    corpus = [x for x in corpus if len(x.split(' ')) &gt; 1]<br/>    corpus = [x for x in corpus if x != 'nan']<br/>    corpus = [x for x in corpus if x != 'nil']<br/>    # remove punctuations, links, urls<br/>    for i in range (len(corpus)):<br/>        x = corpus[i].replace('\n',' ') #cleaning newline “\n” from the tweets<br/>        corpus[i] = html.unescape(x)<br/>        corpus[i] = re.sub(r'(@[A-Za-z0–9_]+)|[^\w\s]|#|http\S+', '', corpus[i])</span></pre><p id="5075" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">然后我们扩展上面的函数<code class="fe nb nc nd ne b">column_cleaner</code>,将tweets(来自<code class="fe nb nc nd ne b">RegexpTokenizer</code>函数)标记为单个单词，移除停用词(来自<code class="fe nb nc nd ne b">nltk</code>包)/数字，并使用词性(来自<code class="fe nb nc nd ne b">WordNetLemmatizer</code>函数)执行词条化。</p><pre class="kj kk kl km gt nf ne ng nh aw ni bi"><span id="b9a1" class="md me it ne b gy nj nk l nl nm"># empty list to store cleaned corpus<br/>    cleaned_corpus = []<br/>    # extend this slang into stopwords<br/>    stopwords = nltk.corpus.stopwords.words("english")<br/>    stopwords.extend([slang_word])<br/>    # tokenise each tweet, remove stopwords &amp; digits &amp; punctuations and filter to len &gt; 2, lemmatize using Part-of-speech<br/>    for i in range (0, len(corpus)):<br/>        words = [w for w in tokenizer.tokenize(corpus[i]) if w.lower() not in stopwords]<br/>        cleaned_words = [x for x in words if len(x) &gt; 2]<br/>        lemmatized_words = [wordnet_lemmatizer.lemmatize(x, pos = 'v') for x in cleaned_words]<br/>        cleaned_corpus.extend(lemmatized_words)<br/>    return cleaned_corpus</span></pre><p id="c079" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">整个功能将在我们收集的tweets数据集上运行，每条tweets将被标记化，然后我们将能够在我们的可视化软件(即Tableau)上绘制出与俚语相关的前n个单词。</p><pre class="kj kk kl km gt nf ne ng nh aw ni bi"><span id="7083" class="md me it ne b gy nj nk l nl nm"># loop through each slang word<br/>for each in slangs:<br/>    # filter dataframe to responses with regards to this slang word<br/>    temp_pd = tweets.loc[tweets.slang == each, :]<br/>    # save result in temp pandas dataframe for easy output<br/>    temp_result = pd.DataFrame(columns = ['slang', 'word'])<br/>    # run column_cleaner function on the tweets<br/>    temp_result['word'] = column_cleaner(temp_pd['tweets'], each)<br/>    # add slang to slang column<br/>    temp_result['slang'] = each<br/>    # append temp_result to result<br/>    result = result.append(temp_result, ignore_index = True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/850f89044defd55d9cd5ca717281eaae.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*tF1GTVHTAQkV2wXXIWd6Cg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供—运行column_cleaner函数后的excel输出</p></figure><h2 id="d297" class="md me it bd mf mg mh dn mi mj mk dp ml lo mm mn mo ls mp mq mr lw ms mt mu mv bi translated">情感分析/极性得分</h2><p id="bc2a" class="pw-post-body-paragraph lf lg it lh b li mw ju lk ll mx jx ln lo my lq lr ls mz lu lv lw na ly lz ma im bi translated">我们可以利用Python包<code class="fe nb nc nd ne b">textblob</code>进行简单的情感分析，其中如果<em class="mb">极性得分&gt; 0 </em>，我们会将每条推文标记为<em class="mb">正</em>，如果<em class="mb">极性得分&lt; 0 </em>，则标记为<em class="mb">负</em>，否则标记为<em class="mb">中性</em>。请注意，在我们进行情感分析之前，不需要运行上述函数<code class="fe nb nc nd ne b">column_cleaner</code>，因为<code class="fe nb nc nd ne b">textblob</code>包可以直接从原始推文中提取极性得分。</p><pre class="kj kk kl km gt nf ne ng nh aw ni bi"><span id="3bb1" class="md me it ne b gy nj nk l nl nm">from textblob import TextBlob</span><span id="f4fc" class="md me it ne b gy nn nk l nl nm"># empty list to store polarity score<br/>polarity_score = []<br/># loop through all tweets<br/>for i in range (0, len(tweets)):<br/>    # run TextBlob on this tweet<br/>    temp_blob = TextBlob(tweets.tweets[i])<br/>    # obtain polarity score of this tweet and store in polarity_score list<br/>    # if polarity score &gt; 0, positive. else if &lt; 0, negative. else if 0, neutral.<br/>    if temp_blob.sentiment.polarity &gt; 0:<br/>        polarity_score.append('Positive')<br/>    elif temp_blob.sentiment.polarity &lt; 0:<br/>        polarity_score.append('Negative')<br/>    else:<br/>        polarity_score.append('Neutral')<br/>    <br/># create polarity_score column in tweets dataframe<br/>tweets['polarity_score'] = polarity_score</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/2376ea8654562a3e94d05b141248ba48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4s4etzzCPaW_dwPJ8qoooQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者提供的图片—进行情感分析后的excel输出</p></figure><h2 id="28d1" class="md me it bd mf mg mh dn mi mj mk dp ml lo mm mn mo ls mp mq mr lw ms mt mu mv bi translated">主题建模</h2><p id="1b93" class="pw-post-body-paragraph lf lg it lh b li mw ju lk ll mx jx ln lo my lq lr ls mz lu lv lw na ly lz ma im bi translated">接下来，我们编写一个函数，可以对我们的推文进行主题建模。主题建模是一种统计建模，用于发现文档集合中出现的抽象“主题”。我们将使用常见的潜在狄利克雷分配(LDA)算法，该算法用于将文档中的文本分类到特定主题，我们可以在<code class="fe nb nc nd ne b">sklearn</code>库包中找到它。在我们的函数中，我们还将使用单个标记生成二元模型和三元模型，以及每个俚语词的前3个主题。</p><pre class="kj kk kl km gt nf ne ng nh aw ni bi"><span id="7af8" class="md me it ne b gy nj nk l nl nm">from sklearn.decomposition import LatentDirichletAllocation<br/>from sklearn.feature_extraction.text import TfidfVectorizer<br/>from sklearn.pipeline import make_pipeline</span><span id="6769" class="md me it ne b gy nn nk l nl nm"># function to conduct topic modelling<br/>def topic_modeller(column, no_topic, slang_word):<br/>    # extend this slang into stopwords<br/>    stopwords = nltk.corpus.stopwords.words("english")<br/>    stopwords.extend([slang_word])<br/>    # set up vectorizer that remove stopwords, generate bigrams/trigrams<br/>    tfidf_vectorizer = TfidfVectorizer(stop_words = stopwords, ngram_range = (2, 3))<br/>    # set the number of topics in lda model<br/>    lda = LatentDirichletAllocation(n_components = no_topic)<br/>    # create a pipeline that vectorise and then perform LDA<br/>    pipe = make_pipeline(tfidf_vectorizer, lda)<br/>    # run the pipe on the cleaned column<br/>    pipe.fit(topic_column_cleaner(column, slang_word))<br/>    # inner function to return the topics and associated words<br/>    def print_top_words(model, feature_names, n_top_words):<br/>        result = []<br/>        for topic_idx, topic in enumerate(model.components_):<br/>            message = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]<br/>            result.append(message)<br/>        return result<br/>    return print_top_words(lda, tfidf_vectorizer.get_feature_names(), n_top_words = 3)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/fddea009fa0309764d086ced421fd987.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p7Nobkv_qtrmVPCm4kKcVA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供—进行主题建模后的excel输出</p></figure><h2 id="4873" class="md me it bd mf mg mh dn mi mj mk dp ml lo mm mn mo ls mp mq mr lw ms mt mu mv bi translated">数据可视化/分析</h2><p id="0b2d" class="pw-post-body-paragraph lf lg it lh b li mw ju lk ll mx jx ln lo my lq lr ls mz lu lv lw na ly lz ma im bi translated">一旦我们准备好数据集，我们就可以将我们的发现绘制到数据可视化软件上，即Tableau。由于本文更多地关注收集数据和生成我们的见解所需的步骤，我将不讨论我是如何设法将我的发现绘制到Tableau上的。可以参考我的Tableau公众号上的<a class="ae mc" href="https://public.tableau.com/app/profile/kieran.tan/viz/TiktokSlangAnalysis/Dashboard1" rel="noopener ugc nofollow" target="_blank"> Tableau仪表盘</a>。</p><p id="c0e8" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">让我们以俚语单词<strong class="lh iu"> <em class="mb"> sheesh </em> </strong>为例，我们可以将Tableau仪表板过滤到该俚语，整个仪表板将被刷新。使用iPhone线框作为用户过滤器的想法是不是很酷？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/de8983865a4f701f6d3584d9c8cdee3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*GHbPVknaDsUnOhLxMgUitg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供—文字过滤器的表格截图</p></figure><p id="2ca9" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">2021年8月期间，在新加坡共收集了173条推文，我们的极性得分显示，31.8%的推文是正面的，47.4%是中性的，20.8%是负面的。这似乎表明俚语<strong class="lh iu"> <em class="mb"> sheesh </em> </strong>更多地带有中性到积极的意思。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/9036b5bbea25fd073e1c1e25a5860769.png" data-original-src="https://miro.medium.com/v2/resize:fit:276/format:webp/1*kQVswZd_LI2tL5jucSMKSA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供—情绪分析的Tableau截图</p></figure><p id="1e3a" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">在我们的Python代码中，我们对tweet进行了标记，这样我们就可以根据单词在所有包含俚语单词的tweet中的出现频率对它们进行排序。我们的视觉化显示，像<em class="mb"> like、schmuck、</em>和<em class="mb"> sembab </em>(在印尼语中是肿胀的意思)这样的词似乎暗示<strong class="lh iu"> <em class="mb"> sheesh </em> </strong>被用来进一步加剧某事的影响。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/34920423d5813a3762836d2edfa5029e.png" data-original-src="https://miro.medium.com/v2/resize:fit:308/format:webp/1*9j8A6GQLOZfu9lLHReOi8g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者提供的图片—前5个关联单词的表格截图</p></figure><p id="e1c4" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">查看3个建模的主题，我们的假设是<strong class="lh iu"><em class="mb"/></strong>被用来加剧某事的影响，这在<em class="mb">渴望murtabak、</em>和<em class="mb">可爱女孩等主题中得到了进一步的暗示。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/7c29614510200ef7fe445844ce251ec1.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*AygbU262nAXduxO7t0C9_A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供—主题建模的Tableau截图</p></figure><p id="8ff8" class="pw-post-body-paragraph lf lg it lh b li lj ju lk ll lm jx ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">事实上，根据TheSmartLocal的文章，单词<strong class="lh iu"> <em class="mb"> sheesh </em> </strong>与<strong class="lh iu"> <em class="mb"> damn </em> </strong>的用法相似，都是表示不相信或恼怒。如果我们看我们的一些推文，<em class="mb"/><strong class="lh iu"><em class="mb">Sheesh</em></strong><em class="mb">渴求murtabak</em><strong class="lh iu"><em class="mb">Sheesh</em></strong><em class="mb">【他是一个幸运的人】</em>做暗示的意思。</p><h2 id="f2b6" class="md me it bd mf mg mh dn mi mj mk dp ml lo mm mn mo ls mp mq mr lw ms mt mu mv bi translated">结尾注释</h2><p id="9c23" class="pw-post-body-paragraph lf lg it lh b li mw ju lk ll mx jx ln lo my lq lr ls mz lu lv lw na ly lz ma im bi translated">我希望这篇文章是有趣的，并给你们一些关于自然语言处理技术如情感分析和主题建模如何帮助我们更好地理解我们的一系列文档(即我们的推文)的想法。玩Tableau仪表板玩得开心，整理仪表板真的很有趣，<strong class="lh iu"> <em class="mb">没有大写sheesh </em> </strong>！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://www.buymeacoffee.com/tankahwang"><div class="gh gi nv"><img src="../Images/4bc5de35955c00939383a18fb66b41d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:340/format:webp/1*9vg3-OY14aZN1UpKwIxxZg.png"/></div></a></figure></div></div>    
</body>
</html>