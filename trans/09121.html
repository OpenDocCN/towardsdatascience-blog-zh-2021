<html>
<head>
<title>Practical Transfer Learning with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch实用迁移学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/practical-transfer-learning-with-pytorch-8344e5c82f59?source=collection_archive---------19-----------------------#2021-08-23">https://towardsdatascience.com/practical-transfer-learning-with-pytorch-8344e5c82f59?source=collection_archive---------19-----------------------#2021-08-23</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><div class=""/><div class=""><h2 id="925b" class="pw-subtitle-paragraph js iu iv bd b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj dk translated">当解决一个ML问题时，利用一个已经起作用的深度神经网络是一个巨大的加速</h2></div><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi kk"><img src="../Images/a18a334f091bc42fd2768d537bb76d4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4kOUfVAbtbI28Eb3"/></div></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">奥马尔·弗洛雷斯在<a class="ae la" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="a2dd" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">在之前的一篇文章中，我解释了PyTorch和XGBoost如何结合起来执行迁移学习。</p><div class="lx ly gp gr lz ma"><a rel="noopener follow" target="_blank" href="/transfer-learning-with-xgboost-and-pytorch-hack-alexnet-for-mnist-dataset-51c823ed11cd"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd iw gy z fp mf fr fs mg fu fw iu bi translated">使用XGBoost和PyTorch进行迁移学习:破解Alexnet for MNIST数据集</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">PyTorch和XGBoost可以结合起来进行迁移学习。在本文中，我们展示了Alexnet知识可以如何…</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">towardsdatascience.com</p></div></div><div class="mj l"><div class="mk l ml mm mn mj mo ku ma"/></div></div></a></div><p id="e3a9" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">这是一种非常非常规的转移学习的方式，混合了深度神经网络和梯度引导树。为了说明这种方法，我解释了如何将AlexNet从ILSVRC数据集中获取的图像分类知识转移到XGBoost的另一个用例:识别手写数字。</p><p id="3165" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">在写完这篇文章的几天后，我意识到PyTorch并没有真正在网上涵盖更常见的用例，即只涉及神经网络的迁移学习。然而，<a class="mp mq ep" href="https://medium.com/u/6278d12b0682?source=post_page-----8344e5c82f59--------------------------------" rel="noopener" target="_blank"> Dipanjan (DJ) Sarkar </a>的一篇优秀文章详细介绍了深度学习，有一些代码但使用了Keras。</p><div class="lx ly gp gr lz ma"><a rel="noopener follow" target="_blank" href="/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd iw gy z fp mf fr fs mg fu fw iu bi translated">在深度学习中通过真实世界的应用转移学习的综合实践指南</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">用知识转移的力量进行深度学习！</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">towardsdatascience.com</p></div></div><div class="mj l"><div class="mr l ml mm mn mj mo ku ma"/></div></div></a></div><p id="5825" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">我强烈推荐阅读这篇文章。</p><p id="5322" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">在这篇文章中，我们将填补迁移学习和pytorch之间的空白。</p><p id="1edb" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">我们将做与前一篇文章相同的转换，仅使用神经网络方法，并比较混合XGBoost或仅使用神经网络时的性能。</p><h1 id="08bc" class="ms mt iv bd mu mv mw mx my mz na nb nc kb nd kc ne ke nf kf ng kh nh ki ni nj bi translated">动机</h1><p id="7a18" class="pw-post-body-paragraph lb lc iv ld b le nk jw lg lh nl jz lj lk nm lm ln lo nn lq lr ls no lu lv lw io bi translated">在深入研究代码之前，有必要提醒一下迁移学习为什么有趣。主要原因是时间:需要大量的时间和精力来收集和标记足够大的深度学习数据库，并且大量的时间和精力对于配置、拟合和调整深度神经网络也是必要的。</p><p id="9feb" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">当解决一个ML问题时，利用一个已经起作用的深度神经网络是一个巨大的加速。</p><p id="e3de" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">在为计算机视觉设计的深度神经网络的情况下，大多数复杂性包含在构建特征的层中。负责分类的层通常只有3层深。</p><p id="cb05" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">能够利用这些预先训练好的特性计算层是非常有吸引力的。</p><p id="2c43" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">下一节将展示如何使用传统的深度学习方法来实现这一点。</p><h1 id="0a3c" class="ms mt iv bd mu mv mw mx my mz na nb nc kb nd kc ne ke nf kf ng kh nh ki ni nj bi translated">MNIST用例</h1><p id="22c8" class="pw-post-body-paragraph lb lc iv ld b le nk jw lg lh nl jz lj lk nm lm ln lo nn lq lr ls no lu lv lw io bi translated">为了简单起见，我们希望使用Python中容易获得的数据库。MNIST看起来是个不错的候选人。它是开源的，使用TorchVision可以在几秒钟内加载。训练集和测试集都非常大:60k的图像用于训练集，10k的图像用于测试集。此外，它们与用于训练AlexNet的图像没有相同的维度。看看我们如何处理这件事是很有趣的。</p><p id="9181" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">AlexNet最初被训练成用1 000个标签对ILSVRC的图像进行分类。在这次训练中，它学会了用深度卷积神经网络建立视觉特征。我们在这一部分中所做的假设是，这些特征可以被重新使用来执行完全不同的分类，即识别仅具有10个标签的手写数字。</p><h1 id="6fc0" class="ms mt iv bd mu mv mw mx my mz na nb nc kb nd kc ne ke nf kf ng kh nh ki ni nj bi translated">重新定位Alex Net</h1><p id="984c" class="pw-post-body-paragraph lb lc iv ld b le nk jw lg lh nl jz lj lk nm lm ln lo nn lq lr ls no lu lv lw io bi translated">在这一点上，我们需要一种方法来保持特征层的结构和权重，并重新训练分类层。</p><p id="3051" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">这是通过下面的代码实现的:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="np nq l"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">作者代码。</p></figure><p id="b318" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">它创建一个新的神经网络模型，获得一个原始模型作为输入，并生成一个新的模型，其中分类器网络已被一个新的分类器取代。要素图层保持不变。</p><p id="3c25" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">重要的部分在于冻结要素图层权重的线。这将强制计算要素的图层在训练过程中保持不变。</p><p id="108a" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">这些是负责迁移学习的行，因为在初始训练期间在ILSVRC数据集上获得的所有知识将在新的用例中不加修改地重用。</p><h1 id="11ed" class="ms mt iv bd mu mv mw mx my mz na nb nc kb nd kc ne ke nf kf ng kh nh ki ni nj bi translated">学习识别手写数字</h1><p id="2c37" class="pw-post-body-paragraph lb lc iv ld b le nk jw lg lh nl jz lj lk nm lm ln lo nn lq lr ls no lu lv lw io bi translated">我们现在要做的就是建立一个新的模型，基于原始的，预训练的AlexNet，并改装一个新的分类器来识别手写数字。</p><p id="4c81" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">感谢pytorchvision和pytorch，这是一个非常简单的任务。下面的代码解释了如何:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="np nq l"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">转移学习。作者代码</p></figure><p id="49ca" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">这种方法很简单，除了变换部分，它需要调整MNIST图像的大小，以适应用于训练AlexNet的数据集的大小。这是通过转换方法完成的。</p><p id="13bb" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">标签的数量从1k减少到10个。</p><p id="38c6" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">在我的笔记本电脑上花了相当长时间的培训结束时，模型被序列化并存储。我们将使用此转储来评估此传输的性能，并检查此方法是否相关。</p><h1 id="dd72" class="ms mt iv bd mu mv mw mx my mz na nb nc kb nd kc ne ke nf kf ng kh nh ki ni nj bi translated">估价</h1><p id="b5f4" class="pw-post-body-paragraph lb lc iv ld b le nk jw lg lh nl jz lj lk nm lm ln lo nn lq lr ls no lu lv lw io bi translated">scikit learns提供了两种评估分类模型性能的简便方法:<strong class="ld iw"> <em class="nr">混淆_矩阵</em> </strong>和<strong class="ld iw"> <em class="nr">分类_报告</em> </strong>。</p><p id="7cba" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">第一个基于实际值计算每个类使用的标签数。第二个计算标准特征，如f1分数、召回率、精确度等</p><p id="e393" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">我们将把这两种方法应用到torchvision提供的测试数据集上。这个数据集包含10k个手写数字，这对于验证来说是一个合适的大小。</p><p id="81de" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">下面的代码行类似于培训中使用的代码行。<em class="nr">变换</em>被重新用于调整测试图像的大小。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="np nq l"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">评估模型性能。作者代码。</p></figure><p id="2c95" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">正如您在上面的注释行中看到的程序输出，性能非常好。</p><p id="fc41" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">有趣的是，我发现这个性能比我在<a class="ae la" rel="noopener" target="_blank" href="/transfer-learning-with-xgboost-and-pytorch-hack-alexnet-for-mnist-dataset-51c823ed11cd">上一篇文章</a>中使用XGBoost获得的性能稍好。这是以更长时间的训练为代价的。然而，使用适当的超参数调优可以进一步提高XGBoost性能:在上一篇文章中，使用了分类的默认值。</p><h1 id="3255" class="ms mt iv bd mu mv mw mx my mz na nb nc kb nd kc ne ke nf kf ng kh nh ki ni nj bi translated">结论</h1><p id="2166" class="pw-post-body-paragraph lb lc iv ld b le nk jw lg lh nl jz lj lk nm lm ln lo nn lq lr ls no lu lv lw io bi translated">使用预训练模型转移学习是获得准确模型的非常有效和快速的方式，对于分类来说也是如此，而对于回归来说则不是。</p><p id="b954" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">使用pytorch和pytochvision，这可以在非常有限的几行中完成。</p><p id="ea98" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">在这篇文章中，我们一直在使用在图像上获得的知识来应用到其他图像上。我敢肯定，我们也可以在任何其他类型的信号上获得不错的结果，比如1D信号。</p></div></div>    
</body>
</html>