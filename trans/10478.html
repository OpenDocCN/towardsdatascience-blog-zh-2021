<html>
<head>
<title>GANshare: Creating and Curating Art with AI for Fun and Profit</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">甘沙尔:用人工智能创造和管理艺术，以获取乐趣和利润</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ganshare-creating-and-curating-art-with-ai-for-fun-and-profit-1b3b4dcd7376?source=collection_archive---------1-----------------------#2021-10-06">https://towardsdatascience.com/ganshare-creating-and-curating-art-with-ai-for-fun-and-profit-1b3b4dcd7376?source=collection_archive---------1-----------------------#2021-10-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3e3a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用CLIP和VQGAN模型生成ChromaScapes，即在OpenSea上作为NFT出售的高质量数字绘画</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/42d82a01feea5ab425115d94a9c7e15f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S95Yre97uaqE6Vbu1wJzZQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">由GANshare One创建的色彩场景样本，</strong>作者提供的图片</p></figure><p id="9637" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2020年8月，我第一次写了关于使用生成性对抗网络(GANs)来创造视觉艺术的文章。为了那个项目，<a class="ae lv" rel="noopener" target="_blank" href="/machineray-using-ai-to-create-abstract-art-39829438076a?source=user_profile---------13----------------------------"> MachineRay </a>，我用公共领域的抽象画来训练NVidia的style gan 2【1】创作新的作品。从那以后，我又写了几篇关于使用GANs制作艺术作品的文章<a class="ae lv" href="https://robgon.medium.com/list/creating-fine-art-with-gans-73476c209de3" rel="noopener">。从我收到的反馈中，我可以看出一些读者想学习如何制作数字艺术作品，作为不可替代的代币(NFT)在一个新兴的市场中出售。</a></p><p id="0585" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你不熟悉加密货币和NFTs，这里有一个简单的类比。</p><blockquote class="lw"><p id="05df" class="lx ly it bd lz ma mb mc md me mf lu dk translated">加密货币之于贵金属，就像NFT之于宝石一样。</p></blockquote><p id="a105" class="pw-post-body-paragraph kz la it lb b lc mg ju le lf mh jx lh li mi lk ll lm mj lo lp lq mk ls lt lu im bi translated">每盎司纯金的价值都是一样的，但每颗钻石都是独一无二的，因此价值也不同。</p><p id="0d5e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了这个项目，我一头扎进了NFTs的世界。我不仅创作并出售新创作的数字艺术作品，还出售受过训练的甘的“股份”,让其他艺术家制作他们自己的数字艺术作品，作为非数字艺术作品出售。我把这个概念叫做“GANshare”，我的第一个人工智能模型叫做GANshare One。</p><h1 id="2775" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">GANshare One组件</h1><p id="a03a" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">这是系统的高级示意图，其中简要描述了组件。再往下，你可以找到每个部分的细节。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/18e23003dda79b12d0a5ee7494f8655e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GKZzvCOcvpYhPkTERAO4GA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky"> GANshare组件图，</strong>作者图片</p></figure><p id="77cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我开始在公共领域收集来自WikiArt.org的50，000多幅画。然后我训练了一个新的人工智能模型，名为VQGAN [2]，是在德国海德堡大学开发的。VQGAN有一个图像编码器、转换器和解码器，用于创建新图像，还有一个鉴别器，用于检测生成的图像部分是真实的还是生成的。</p><p id="c42b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我使用VQGAN根据文本提示创建新的绘画。我从文本文件中自动生成提示，这些文本文件包含绘画风格、几何形状、地理位置的列表，以及大量颜色名称的列表。我使用OpenAI的CLIP model [3]来控制VQGAN解码器，使用Pytorch库中的Adam optimizer [4]生成一幅数字绘画来匹配提示。</p><p id="6994" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我使用ISR超分辨率Resizer [5]将图像放大到1024x1024，并发布到OpenSea上作为NFT出售。你可以在这里查看艺术品的样品:<a class="ae lv" href="https://opensea.io/collection/chromascapes" rel="noopener ugc nofollow" target="_blank">https://opensea.io/collection/chromascapes</a></p><h1 id="c8cd" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">GANshare One系统详情</h1><p id="7a06" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">本节将更详细地讨论我用来构建GANshare One系统的组件。</p><h2 id="54af" class="nj mm it bd mn nk nl dn mr nm nn dp mv li no np mx lm nq nr mz lq ns nt nb nu bi translated">收集图像</h2><p id="6ba1" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">类似于我为我的<a class="ae lv" rel="noopener" target="_blank" href="/magnet-modern-art-generator-using-deep-neural-networks-57537457bb7">磁铁</a>项目所做的，我使用一个定制的python脚本从WikiArt.org收集绘画作为训练数据。剧本按字母顺序浏览了网站上的每个艺术家。它检查了这些艺术家是否生于1800年之后，死于1950年之前。然后，它检查每个艺术家的画，以确保它们是在公共领域，然后将它们复制到我的谷歌驱动器的文件夹中。它找到了52，288张符合我标准的图片。</p><p id="1680" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有一些我用来训练GANshare One的原画，来自康定斯基、梵高和毕加索等艺术家。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/a8114d91f740e116395c8cad98de6175.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w6nGS8UZvBPpvjgwlQzDig.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">训练图片</strong>，来源WikiArt.org</p></figure><h2 id="e357" class="nj mm it bd mn nk nl dn mr nm nn dp mv li no np mx lm nq nr mz lq ns nt nb nu bi translated">VQGAN</h2><p id="cc0d" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">Esser等人的矢量量化生成对抗网络(VQGAN)模型是一种用于生成高质量图像的混合GAN/Transformer模型[2]。</p><p id="7ea6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在他们题为“驯服高分辨率图像合成的变形金刚”的论文中，作者声明他们的方法学习…</p><blockquote class="nw nx ny"><p id="c4f8" class="kz la nz lb b lc ld ju le lf lg jx lh oa lj lk ll ob ln lo lp oc lr ls lt lu im bi translated">…由上下文丰富的可视部分组成的码本，其组成随后用自回归转换器架构建模。离散码本提供了这些架构之间的接口，基于补丁的鉴别器支持强压缩，同时保持高感知质量。该方法将卷积方法的效率引入到基于变换的高分辨率图像合成中。帕特里克·埃塞尔、罗宾·龙巴赫和比约恩·奥默</p></blockquote><p id="59e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是他们的VQGAN架构图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/f821de490d42c0a2c04cc82e9c0a8a10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q73DHnLEvWd1qMtwrBT16A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky"> VQGAN架构</strong>，来自Esser等人的<a class="ae lv" href="https://compvis.github.io/taming-transformers/paper/paper.pdf" rel="noopener ugc nofollow" target="_blank">驯服变压器用于高分辨率图像合成</a>。</p></figure><p id="7b36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我收集了我的训练图像之后，我使用我的Google Colab Pro [7]帐户使用这个命令来训练VQGAN:</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="d5cc" class="nj mm it of b gy oj ok l ol om">!python main.py -b configs/custom_vqgan.yaml --train True --gpus 0,</span></pre><p id="afd3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为VQGAN是一个混合变压器模型，它在训练期间向您显示原始和编码的样本。下面是一组示例图像。</p><div class="kj kk kl km gt ab cb"><figure class="on kn oo op oq or os paragraph-image"><img src="../Images/6895631599d5e8b9cb70ced3a2f713ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*nkDBzivW8Ojo048wH1P7Mg.jpeg"/></figure><figure class="on kn oo op oq or os paragraph-image"><img src="../Images/a628ebe6932557d73c491e7b3df418b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*lzh_5cCIVJF2G0jGBBDrhA.jpeg"/><p class="ku kv gj gh gi kw kx bd b be z dk ot di ou ov translated"><strong class="bd ky">使用VQGAN的原始和重新编码图像</strong>，(左)WikiArt.org，(右)作者</p></figure></div><p id="074d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以看到模型在重建原始图像方面做得很好，但它似乎对一些面部特征做了自己的事情，如眼睛和嘴巴。</p><p id="90cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总的来说，我发现VQGAN工作得很好。下表比较了经典GAN和VQGAN的一些特性。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="7df6" class="nj mm it of b gy oj ok l ol om"><strong class="of iu">Feature             Classic GAN             VQGAN<br/></strong>Discriminator:      All-or-nothing          Sub-image<br/>Output Image Size:  Fixed Size              Variable Size<br/>Reverse Encoding:   Iterative Process       Trained Encoder<br/>Image Generation:   New Images Look Good    Images Need Steering</span></pre><p id="5aa1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于VQGAN，训练很快，因为图像的每个部分都由鉴别器检查，而传统的GAN使用全有或全无的方法进行训练。换句话说，VQGAN中的鉴别器查看4x4网格中的16个子图像，并对每个部分给发生器一个向上或向下的大拇指作为改进的反馈。经典GAN中的鉴别器为整个图像向发生器提供单个拇指向上或向下。</p><p id="5e4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于经典的GANs，输出图像总是固定大小。因为它与“代码本”一起工作，VQGAN可以输出不同大小的图像。例如，我用256x256输入图像训练VQGAN，并用它产生512x512输出图像。</p><p id="3bd9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，以下是以256x256和512x512渲染的提示“起伏的农田”的生成图像。</p><div class="kj kk kl km gt ab cb"><figure class="on kn oo op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/b419fff1b3ffb3f0cb9891e6e8176b96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*wqA39HHGXkkBEmw84LhOLQ.png"/></div></figure><figure class="on kn oo op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/2edc541985fba7542cda128ed123e11f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*_tgZ_iS7sJmolRghIHcPDg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk ot di ou ov translated">起伏的农田，渲染尺寸为(左)256x256和(右)512x512，图片由作者提供</p></figure></div><p id="b97b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意512x512图像中的更多功能。这是因为VQGANs码本中的特征是以256x256的比例学习的，并被渲染为对更大画面的较小贡献。512x512图像的输出类似于将多个晕影合并在一起。</p><p id="f5a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">经典的GANs没有用于反向编码的内置模型，反向编码是一种在给定任意真实图像的情况下寻找最接近的生成图像的过程。对于经典GAN来说，这必须通过迭代方法来完成，并且它并不总是工作得很好。然而，反向编码对于VQGAN模型来说很容易，因为它实际上是一种编解码器。它有一个将图像编码成嵌入的模型和一个将嵌入解码成图像的相应模型。</p><p id="a3fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">前三点都是VQGAN的优势。然而，第四点是很容易从经典的GANs产生输出图像。只要给它一些随机数，它就会生成一个好看的图片。但是VQGAN没有制作新图像的简单方法。如果给解码器一些随机数，输出的图像就不连贯了。VQGAN需要由一些其他过程来控制，比如使用剪辑模型生成可识别图像的文本提示。</p><h2 id="ce7b" class="nj mm it bd mn nk nl dn mr nm nn dp mv li no np mx lm nq nr mz lq ns nt nb nu bi translated">OpenAI的剪辑模型</h2><p id="64eb" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">OpenAI设计并训练了一个名为CLIP的人工智能系统，代表对比语言-图像预训练[3]。CLIP系统有一个图像和文本编码器，它可以用来执行跨模态语义搜索，例如，你可以使用单词来搜索图像，正如我在我的<a class="ae lv" rel="noopener" target="_blank" href="/magnet-modern-art-generator-using-deep-neural-networks-57537457bb7"> MAGnet </a>项目中所做的那样。</p><p id="bfa8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">OpenAI在带有相应短语的图像数据集上训练编码器。训练的目标是使编码图像与编码单词相匹配。一旦经过训练，图像编码器系统将图像转换为嵌入，即捕获图像一般特征的512个浮点数的列表。文本编码器将文本短语转换为相似的嵌入，该嵌入可以与图像嵌入进行比较以进行语义搜索。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/2a4e37de00d03e9b2dabd277bb65058e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n8nS8HglNNMzzW1noGyGpA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">对比语言-图像预训练(剪辑)</strong>，OpenAI图像</p></figure><p id="dc6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，如果您有一个图像数据库，您可以通过图像编码器运行每个图像，以获得图像嵌入的列表。如果您随后通过文本编码器运行短语“绿色草坪上的小狗”，您可以找到与该短语最匹配的图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/b088af21d4d839f16352a906ce0f76ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3_hKaSxVYEvVwwaT2k23fA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">待办事项清单</strong>，作者图片说明，基于莱克西·詹尼在<a class="ae lv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的一张照片</p></figure><h2 id="46a4" class="nj mm it bd mn nk nl dn mr nm nn dp mv li no np mx lm nq nr mz lq ns nt nb nu bi translated">生成提示</h2><p id="d612" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">如上所述，GANshare系统使用文本提示创建由CLIP控制的图像。比如说，如果你告诉VQGAN+CLIP创建一幅“橙色圆圈的抽象画”，它就会创建一幅。</p><p id="df33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了画出大量的画，我生成了包含三个不同部分的提示:风格、主题和颜色。</p><p id="29bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">经过试验，我发现这九种风格相当不错:抽象、立体主义、表现主义、野兽派、未来主义、几何、印象派、后现代和超现实主义。</p><p id="9334" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于主题，我从三个类别中选择:几何形状、地理特征和物体。我从伊万·马洛平斯基的<a class="ae lv" href="https://github.com/imsky/wordlists/tree/master/nouns" rel="noopener ugc nofollow" target="_blank">单词表</a>开始，为我的形状和地理特征列表做了一些调整。对于我的物品列表，我组合了由<a class="ae lv" href="https://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> COCO </a>和<a class="ae lv" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR 100 </a>检测系统识别的物品列表，得到181个物品的列表。</p><p id="1e80" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我从维基百科<a class="ae lv" href="https://en.wikipedia.org/wiki/List_of_colors:_A%E2%80%93F" rel="noopener ugc nofollow" target="_blank">中抓取了一份颜色名称的详细列表，并稍微编辑了一下，得到了805种独特的颜色。</a></p><p id="9188" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是四个列表中的前七个条目。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="49be" class="nj mm it of b gy oj ok l ol om"><strong class="of iu">shapes.txt   places.txt       things.txt          colors.csv<br/></strong>angles       an archipelago   an airplane         absolute zero<br/>blobs        an atoll         an apple            acid green<br/>circles      a beach          apples              aero<br/>cones        a bay            an aquarium fish    aero blue<br/>cubes        a butte          a baby              african violet<br/>curves       a canal          a backpack          alabaster<br/>cylinders    a canyon         a banana            alice blue<br/>...          ...              ...                 ...</span></pre><p id="e3c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有一个<a class="ae lv" href="https://gist.github.com/robgon-art/8bdaf6593ae4c1d7ed4037064969e818" rel="noopener ugc nofollow" target="_blank">链接</a>到Python代码，它通过随机选择样式、主题和颜色来生成提示。</p><p id="0970" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是代码生成的一些提示。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="bf91" class="nj mm it of b gy oj ok l ol om">Futurist Painting of a City in Vivid Burgundy Brown<br/>Abstract Painting with Diagonals in Beige Pink<br/>Impressionist Painting with Prisms in Carolina Blue</span></pre><p id="fb2b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们有了一些有趣的提示，接下来我们将看看如何引导VQGAN生成相应的图像。</p><h2 id="6e28" class="nj mm it bd mn nk nl dn mr nm nn dp mv li no np mx lm nq nr mz lq ns nt nb nu bi translated">带夹子的转向VQGAN</h2><p id="fc4b" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">在我的<a class="ae lv" rel="noopener" target="_blank" href="/magnet-modern-art-generator-using-deep-neural-networks-57537457bb7"> MAGnet项目</a>中，我使用了一个定制的生成算法，让CLIP操纵StlyeGAN2的一个变体，根据文本提示创建图像。在这个项目中，我使用了凯瑟琳·克劳森设计的算法，她是一位人工智能/生殖艺术家，在Twitter上以<a class="ae lv" href="https://twitter.com/RiversHaveWings" rel="noopener ugc nofollow" target="_blank"> RiversHaveWings </a>的身份发布帖子。为了使用CLIP控制VQGAN，她使用Pytorch库中的优化器Adam，Adam代表自适应矩估计[4]。下面是算法的示意图。</p><p id="8c53" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，这里有两个嵌入空间。CLIP系统使用512个数的平面嵌入(表示为<em class="nz"> I </em>和<em class="nz"> T </em>)，其中VQGAN使用256x16x16个数的三维嵌入，表示为<em class="nz"> Z </em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/ff7367277099e0a360764bbf96f73934.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cXB0BN476mh-U2QUtt0cbA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">优化算法</strong>，图片作者</p></figure><p id="0fa6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">优化算法的目标是产生与文本查询紧密匹配的输出图像。系统首先通过剪辑文本编码器运行文本查询，以获得目标<em class="nz"> T </em>。Adam优化器从初始VQGAN向量<em class="nz"> Zi </em>开始。它修改向量<em class="nz"> Zn </em>以产生一个嵌入了剪辑<em class="nz"> I </em>的图像，该图像试图匹配原始目标<em class="nz"> T </em>。随着<em class="nz"> I </em>接近<em class="nz"> T </em>，输出图像将更好地匹配文本查询。</p><p id="bca7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看该算法与上一节中的提示配合得如何。对于每个提示，我运行系统200次迭代。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/a768dd017a98992db9e2464c82e776c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xJynMwEIQRIP16iw2NBS8A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">未来主义者用鲜艳的勃艮第棕色画了一座城市</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/1403ba891cc47b2ca75ee683896d173d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3GfKi_bPun6L_DxcwjTVfA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">米色粉色斜线抽象画</strong>，图片由GANshare One提供</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/eb90f594365392f1949fa406a6f1ede4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3vMywNX4-zOwnxYJprAn3w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">印象派画家用卡罗莱纳蓝棱镜作画</strong>，图片由GANshare One提供</p></figure><p id="4054" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">果然，系统创建的图像似乎与提示相符。请注意优化算法是如何即兴发挥的。例如，不清楚第三张图片本身是否包含任何棱镜。但它确实在调色板中显示了一些彩虹色，暗示了光线通过棱镜的效果。</p><h1 id="4ea2" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">结果</h1><p id="ffc6" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">在生成了数百幅数字绘画后，我注意到它们并不都是赢家。从形状类别中的提示生成的图像似乎具有最好的产量，即，大约33%可以被认为是合理的。但地点和事物类别中的图片效果不佳，只有大约20%的人保留。</p><p id="7dfe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是我判断的一些样品。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/934f66df23c7e53633d75b30d149df0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/1*WZcz7ES7NRFeFQpcq2FSLQ.png"/></div></figure><div class="kj kk kl km gt ab cb"><figure class="on kn pb op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/ab5af4e80d528c23d543b9599cdb6909.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*aCRfsDiDITH16wK2pNblFQ.png"/></div></figure><figure class="on kn pb op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/7984c1b8cfefae1ca95c8b84c1e61da9.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*qdUOx9w6ugJJu4s1I0TazQ.png"/></div></figure><figure class="on kn pb op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/663f3246ebc1c095257d6997b820be84.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*xrLoBn2GHXcNpDxqtfsK-Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk pc di pd ov translated"><strong class="bd ky">音速银棕色的对角线几何画</strong>(左)<strong class="bd ky">樱花粉色的城市几何画</strong>(中)<strong class="bd ky">台盼蓝的女孩几何画</strong>(右)，图片由甘沙尔一</p></figure></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/5f4598633f3c11fb22176d9b00208238.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*ugZr5YeVJiVpQRaVgjUFvA.png"/></div></figure><div class="kj kk kl km gt ab cb"><figure class="on kn pb op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/cdd6caf75dc4d6d5c0df2e76a96f8a94.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*msYfSVLj_RgDabccZCYZgA.png"/></div></figure><figure class="on kn pb op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/3cde8df4cf38d130bc86023908a881ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*gbuJsFUYDdZ4iMuVNMOLww.png"/></div></figure><figure class="on kn pb op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/cb0472ac4a042f466fb980522395e871.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*0yQEvnfaflQPhNbUv-O68g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk pc di pd ov translated"><strong class="bd ky">野兽派的宝石红色池塘画</strong>(左)<strong class="bd ky">薰衣草粉色吹风机抽象画</strong>(中)<strong class="bd ky">松绿色臭鼬抽象画</strong>(右)，图片由甘沙尔一</p></figure></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/3d33aac981bbd177a80d87f83bfdbbe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*Pnupa6_TlPpk27exnaF1Dg.png"/></div></figure><div class="kj kk kl km gt ab cb"><figure class="on kn pb op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/802acce4dedad9f6a4ac8d2d32c0e565.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*4M4u4bVV2it-sZRxlBRp6A.png"/></div></figure><figure class="on kn pb op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/d8690cf3421e14696a18b55f57a6dfc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*AHKTfBCrJDYrxnRIXjheQA.png"/></div></figure><figure class="on kn pb op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/b9fe36fd48975b8f58bbe1d43728c33e.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*-A2_KNo3MqMwJoJtG7WJVQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk pc di pd ov translated"><strong class="bd ky">芦笋棕色松鼠的后现代绘画</strong>(左)<strong class="bd ky">最大紫色岛屿的抽象画</strong>(中)<strong class="bd ky">白粉色野兽派自行车的绘画</strong>(右)，图片由GANshare One提供</p></figure></div><p id="141d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在这里看到更多结果<a class="ae lv" href="https://opensea.io/collection/chromascapes" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="5ede" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">在OpenSea上销售NFT</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/80f11ddaa0025a4a79d0ffcdd97a3831.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8CAD_LhQaWh6Qg3V.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky"> <em class="ph">每一天</em> </strong> <em class="ph"> </em> <strong class="bd ky"> <em class="ph"> —前5000天</em>作者:毕普</strong>，来源:<a class="ae lv" href="https://www.beeple-crap.com/" rel="noopener ugc nofollow" target="_blank">beeple-crap.com</a></p></figure><p id="870e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">自从2021年3月被称为Beeple的数字艺术家以6900万美元的价格出售了一份JPG文件以来，人们对使用区块链出售数字艺术产生了浓厚的兴趣</p><blockquote class="nw nx ny"><p id="9363" class="kz la nz lb b lc ld ju le lf lg jx lh oa lj lk ll ob ln lo lp oc lr ls lt lu im bi translated">皮普尔的拼贴JPG是在二月份作为一种“不可伪造的象征”或NFT制作或“铸造”的。一个由计算机系统组成的安全网络将销售记录在一个被称为“区块链”的数字账本上，为买家提供真实性和所有权的证明。大多数人用以太坊加密货币支付。“Everydays”是佳士得售出的第一件纯数字NFT，它提出接受以太坊付款，这对这家有255年历史的拍卖行来说是第一次。——<strong class="lb iu">斯科特·雷伯恩，</strong> <a class="ae lv" href="https://www.nytimes.com/2021/03/11/arts/design/nft-auction-christies-beeple.html" rel="noopener ugc nofollow" target="_blank">《纽约时报》</a></p></blockquote><p id="30dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我考虑以NFTs的形式出售我的数字艺术，在进行了一点研究后，我发现使用多边形区块链[10]的OpenSea市场是一个很好的选择。这是出于成本和环境影响的原因。</p><p id="678b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">OpenSea允许创作者在以太坊区块链或多边形区块链(也称为MATIC)上发布待售商品。下表显示了以太坊和多边形区块链之间的一些差异。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="fa56" class="nj mm it of b gy oj ok l ol om"><strong class="of iu">Feature                      Ethereum         Polygon<br/></strong>Account initializing:        ~US$50           Free<br/>Selling cost:                2.5%             2.5%<br/>Selling items in bundles:    Yes              No<br/>Blockchain validation:       Proof of work    Proof of stake<br/>Environmental impact:        Huge*            Minimal</span><span id="589a" class="nj mm it of b gy pi ok l ol om">*expected to change in Q1/Q2 2022</span></pre><p id="2e27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从表中可以看出，在OpenSea上建立一个帐户来销售多边形区块链是免费的，在这里使用以太坊区块链大约需要50美元。OpenSea将从区块链的销售额中抽取2.5%的销售价格。此外，在多边形区块链上不支持捆绑销售项目。</p><h2 id="671a" class="nj mm it bd mn nk nl dn mr nm nn dp mv li no np mx lm nq nr mz lq ns nt nb nu bi translated">NFTs的环境影响</h2><p id="5770" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">两个区块链之间的另一个巨大差异是工作证明(PoW)与利益证明(PoS)验证的环境影响。</p><blockquote class="nw nx ny"><p id="fffe" class="kz la nz lb b lc ld ju le lf lg jx lh oa lj lk ll ob ln lo lp oc lr ls lt lu im bi translated">能量消耗是两种共识机制之间的一个主要区别。因为利害关系证明区块链不要求矿工在重复的过程中花费电力(竞争解决相同的难题)，利害关系证明允许网络以低得多的资源消耗运行。—<a class="ae lv" href="https://www.coinbase.com/learn/crypto-basics/what-is-proof-of-work-or-proof-of-stake" rel="noopener ugc nofollow" target="_blank">coinbase.com</a></p></blockquote><p id="1483" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据多边形…</p><blockquote class="nw nx ny"><p id="2b87" class="kz la nz lb b lc ld ju le lf lg jx lh oa lj lk ll ob ln lo lp oc lr ls lt lu im bi translated">…最大的电力公司区块链每年可消耗35-140太瓦时的电力，持续消耗3-15吉瓦的电力。如果区块链是一个国家，它的年能源消耗将排在第27位，高于瑞典、越南和阿根廷。…相比之下，Polygon的验证器每年大约消耗0.00079TWh的电力，大约持续汲取0.00009GW的电力，比主要的PoW区块链网络的能耗低几个数量级。— <a class="ae lv" href="https://blog.polygon.technology/polygon-the-eco-friendly-blockchain-scaling-ethereum-bbdd52201ad/" rel="noopener ugc nofollow" target="_blank">多边形技术</a></p></blockquote><p id="e462" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">经营区块链以太坊的人们清楚地意识到他们对环境的严重影响。他们计划在2022年中期转向利益证明验证。</p><blockquote class="nw nx ny"><p id="ec51" class="kz la nz lb b lc ld ju le lf lg jx lh oa lj lk ll ob ln lo lp oc lr ls lt lu im bi translated">…[ 2022年]的升级代表着正式转向利益相关共识。这消除了对能源密集型采矿的需求，取而代之的是使用支撑以太网来保护网络。实现Eth2愿景的真正激动人心的一步——更高的可扩展性、安全性和可持续性。——【ethereum.org T4】</p></blockquote><h2 id="a1a5" class="nj mm it bd mn nk nl dn mr nm nn dp mv li no np mx lm nq nr mz lq ns nt nb nu bi translated">建立一个OpenSea账户</h2><p id="928e" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">建立以NFTs形式销售数字艺术的平台很容易(而且使用多边形区块链是免费的)。我跟随OpenSea的简单指示<a class="ae lv" href="https://support.opensea.io/hc/en-us/articles/4404029357587-How-do-I-create-and-sell-NFTs-on-Polygon-" rel="noopener ugc nofollow" target="_blank">来到这里</a>。一旦我建立了我的账户，我就把我的数码作品上传到这里，在这里出售，<a class="ae lv" href="https://opensea.io/collection/chromascapes" rel="noopener ugc nofollow" target="_blank">https://opensea.io/collection/chromascapes</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/df5c60c2ec0c86054a68bc0cabf2c735.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_8w0QsWyqMAPUQgQHaEzsQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">色彩景观</strong>，作者图片</p></figure><p id="5d44" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">OpenSea的一个很酷的特性是能够为待售商品添加属性。购物者可以使用这些属性来定义他们希望看到的商品。对于我的例子，我为生成的绘画添加了以下属性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/864a39d98b9a65b73803f96b06cfa103.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*IUwyf1Uu40hibiA1vm8sqg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky"> NFT房产</strong>，图片作者</p></figure><p id="3b9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你有半打左右的项目，用户界面是可以的。但是如果你想卖100样东西，直接从OpenSea上传并列出要卖的东西是不容易的。</p><h2 id="97a5" class="nj mm it bd mn nk nl dn mr nm nn dp mv li no np mx lm nq nr mz lq ns nt nb nu bi translated">使用脚本批量上传项目</h2><p id="48f1" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">尽管OpenSea确实有一个<a class="ae lv" href="https://docs.opensea.io/reference/api-overview" rel="noopener ugc nofollow" target="_blank"> API </a>来自动完成特定的任务，但是他们的API没有自动上传和在他们的市场上销售商品的功能。这是不幸的，因为上传数百个文件将是一个真正的痛苦。</p><p id="4ff6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在阅读了Jim Dees关于<a class="ae lv" href="https://medium.com/web-design-web-developer-magazine/how-to-post-giant-10-000-sets-of-nfts-on-opensea-2a8efd4c836e" rel="noopener">使用宏程序</a>发布NFT的文章后，我开始用我喜欢的语言Python来做这件事。正确设置后，我发现<a class="ae lv" href="https://www.selenium.dev/documentation/webdriver/" rel="noopener ugc nofollow" target="_blank">的Selenium WebDriver </a>与我本地笔记本电脑上运行的Chrome浏览器配合得很好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/fb1bfda81b7226ffccab6a8c19e39781.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xB3xOxGlO1s4nleP6yWFeg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">使用Selenium和Chrome上传和销售NFTs </strong>，作者配图</p></figure><p id="df6f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我在一个文本文件中捕获了NFTs的所有元数据。它包括每幅画的文件名、标题和属性。然后，我的脚本使用MetaMask wallet登录到我在OpenSea上的帐户，并运行列表中的每个项目，执行以下任务:</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="05f3" class="nj mm it of b gy oj ok l ol om">1. Create a new item in my OpenSea collection<br/>2. Upload the image file<br/>3. Enter the name of the item<br/>4. Enter the description<br/>5. Enter the properties (i.e. color, style, etc.)<br/>6. Save the item<br/>7. Go to sell the item<br/>8. Enter the price<br/>9. Post the item for sale</span></pre><p id="37de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这需要一点调整，但我让脚本运行得足够好，可以上传1，000个NFT。</p><h1 id="ce09" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">甘沙尔</h1><p id="6f83" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">除了以的身份出售好的形象，我还把训练有素的甘的“股份”卖给其他希望创造新形象的艺术家。我为自己保留一股，并在这里卖出另外三股<a class="ae lv" href="https://opensea.io/collection/ganshare-one" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="a9e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">OpenSea在销售NFT时允许“锁定内容”。购买GANshare后，这些内容将使新的所有者能够创建新的图像，并上传到OpenSea或任何其他NFT市场进行销售。</p><h1 id="e7d9" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">后续步骤</h1><p id="8f10" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">我在上面提到过,“好的”生成图像的产量只有大约20%到33%。运行优化算法超过200次迭代可能会改善结果，特别是对于地点和事物类别。此外，可以将剪辑编码器用作自动艺术评论家。查看图像嵌入与“美丽的绘画”这样的短语有多接近，可以提供一种更容易的方法来区分小麦和谷壳。这可以很好地工作，除非你喜欢绿色臭鼬的邋遢画😀。</p><p id="de4f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我还从我的一位评论者奥利弗·斯特瑞普那里得到了一个很好的建议。他问我是否可以训练一个基于语言的人工智能系统来生成高质量的提示，这可能会使它成为一个全自动的艺术生成系统。好主意！</p><h1 id="6205" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">源代码</h1><p id="d678" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">一个用于试验VQGAN和Clip的Google Colab是<a class="ae lv" href="https://colab.research.google.com/github/robgon-art/GANshare/blob/main/GANshare_One.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h1 id="1014" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">感谢</h1><p id="e16a" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">我要感谢詹尼弗·林和奥利弗·斯特瑞普对这个项目的帮助。</p><h1 id="a6c5" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">参考</h1><p id="21ab" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">[1]由T. Karras、S. Laine、M. Aittala、J. Hellsten、J. Lehtinen和T. Aila编写的StyleGAN2，<a class="ae lv" href="https://arxiv.org/pdf/1912.04958.pdf" rel="noopener ugc nofollow" target="_blank"/>(2020)</p><p id="ec6c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2]p . Esser、R. Rombach和B. Ommer的VQGAN，<a class="ae lv" href="https://arxiv.org/pdf/2012.09841.pdf" rel="noopener ugc nofollow" target="_blank">驯服高分辨率图像合成的变形金刚</a> (2020年)</p><p id="987b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[3]a .拉德福德等人的剪辑，<a class="ae lv" href="https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf" rel="noopener ugc nofollow" target="_blank">从自然语言监督中学习可转移的视觉模型</a> (2021)</p><p id="baa2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[4]d . Kingma和J. Ba的Adam Optimizer，A <a class="ae lv" href="https://arxiv.org/pdf/1412.6980.pdf" rel="noopener ugc nofollow" target="_blank"> dam:一种随机优化方法</a> (2017)</p><p id="e8d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[5]卡迪纳尔等人的ISR，<a class="ae lv" href="https://idealo.github.io/image-super-resolution/" rel="noopener ugc nofollow" target="_blank"> ISR超分辨率Resizer </a> (2018)</p></div><div class="ab cl pl pm hx pn" role="separator"><span class="po bw bk pp pq pr"/><span class="po bw bk pp pq pr"/><span class="po bw bk pp pq"/></div><div class="im in io ip iq"><p id="6fe7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了无限制地访问Medium上的所有文章，<a class="ae lv" href="https://robgon.medium.com/membership" rel="noopener">成为会员</a>，每月支付5美元。非会员每月只能看三个锁定的故事。</p></div></div>    
</body>
</html>