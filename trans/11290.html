<html>
<head>
<title>Convolutional Neural Network: Good Understanding of the Layers and an Image Classification Example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络:对层的良好理解和图像分类示例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convolutional-neural-network-good-understanding-of-the-layers-and-an-image-classification-example-a280bc02c13e?source=collection_archive---------12-----------------------#2021-11-05">https://towardsdatascience.com/convolutional-neural-network-good-understanding-of-the-layers-and-an-image-classification-example-a280bc02c13e?source=collection_archive---------12-----------------------#2021-11-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/0688aaebc61cf3ad6829138fbe0bb2df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fphUiE2laSmtzjXp"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">艾莉娜·格鲁布尼亚克在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="29b8" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">包含了大量的信息</h2></div><p id="b28a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">卷积神经网络(CNN)是一种多层神经网络，已知能够检测模式和复杂特征。它在人脸检测、自动驾驶汽车和许多非常复杂的任务中非常有用。在本文中，我将向您介绍卷积神经网络是如何工作的。</p><p id="d38e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本文将涵盖:</p><ol class=""><li id="03c8" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">卷积层如何在正向过程中工作。</li><li id="65da" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">池层如何工作。</li><li id="34c3" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">用于图像分类项目的卷积神经网络的完整模型结构。</li><li id="62ca" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">模型总结分析。</li><li id="7171" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">训练模型并显示结果。</li></ol><h1 id="2076" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">CNN 是如何运作的？</h1><p id="b58f" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">CNN 可以用于很多不同的领域，但是在这篇文章中，我们将讨论图像分类的例子。图像数据可以表示为数字像素值。然后这些数值被传入 CNN 进行处理。普通的神经网络也能够检测图像，但 CNN 在准确性和速度方面更有效。</p><h2 id="a87b" class="nf mj jj bd mk ng nh dn mo ni nj dp ms lh nk nl mu ll nm nn mw lp no np my nq bi translated">卷积层</h2><p id="bb4f" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">卷积层是 CNN 中非常重要的层，因为这是它成为卷积神经网络的原因。在这一层中，使用过滤器或内核来检测重要的特征。目的是使数据集更小，并且只将重要的要素发送到下一个图层。这样节省了密集层的大量计算，也保证了较高的精度。让我们来看一张图。</p><figure class="ns nt nu nv gt iv gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/451ecb06574c3e8962e6ab5050ae3795.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*MiXn9U76eDILy85G8-VsqA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="aaa7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上图是深度 3 的输入数据，一个深度和偏置项相同的核。</p><h2 id="e068" class="nf mj jj bd mk ng nh dn mo ni nj dp ms lh nk nl mu ll nm nn mw lp no np my nq bi translated">这个内核如何过滤输入数据？</h2><p id="33fa" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">接下来的几张图片将一步步展示这一点。</p><figure class="ns nt nu nv gt iv gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/72e0a00434f20c5a74e9ac8f16755d01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*RN9ZghUwLoG9eVGEJJVg7g.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="e699" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">计算是这样进行的:</p><figure class="ns nt nu nv gt iv gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/510c4c4b379c2e0061f59f99404f575b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*i37fQ-Hg6Qzb9FZrwKlDuw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="5faf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们把剩下的三个输出填满。下面是如何移动过滤器或内核来计算 y12。</p><figure class="ns nt nu nv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/d63ece385d4b63d4c17d5ca196af5f56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*8V71tf4WRp4pY_ZW_JxtwQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="8156" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我没有展示计算部分。这是相同的项目-明智的乘法，然后求和，如前所示。下图显示了 y21 的内核位置和偏差:</p><figure class="ns nt nu nv gt iv gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/9fb0b8207f3c35a963075f5fada08e0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*DbLzi2c1AHDK9O-JeKxtlA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="0de1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，y22 计算的内核和偏差:</p><figure class="ns nt nu nv gt iv gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/09335467791d4c317e956ea99df698cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*i8JkABluIaOy6cGC9JxN2w.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="cd36" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在上图中，只使用了一个内核。但是在真实模型中，可以使用几个内核。在这种情况下，相同大小的输出会更多。我在这里使用的填充类型称为“有效”。这意味着我实际上没有使用任何填充。还有另外两种主要类型，称为“全”和“相同”。我不打算在本文中讨论这些。但是在练习部分，我会用‘有效’。在 high label 思想中，填充“相同”意味着在输入数据的所有边上添加一个零层，然后在其上使用内核。</p><h2 id="de38" class="nf mj jj bd mk ng nh dn mo ni nj dp ms lh nk nl mu ll nm nn mw lp no np my nq bi translated">汇集层</h2><p id="6544" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">汇集层减少了数据的维数，并且还检测特征，而不管特征在图像中的位置如何。下面是一个 MaxPooling2D 如何工作的例子。</p><figure class="ns nt nu nv gt iv gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/1e3f874998dbe7bcc7ccb43c2196366a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*00mx9Q6h574uKyOJtVgupA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="c8e6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上图展示了 MaxPooling 的工作原理。紫色方框的最大值是 15，所以只需要 15。绿框最多 19 个，所以只剩 19 个了。另外两个盒子也是如此。还有其他类型的池，如平均池或最小池。这个名字表明了它们是如何工作的。在平均池中，我们取每个盒子的平均值，在最小池中，我们取每个盒子的最小值。</p><p id="3b1e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些是理解本文练习的重要思想。</p><h1 id="2c09" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">卷积神经网络练习</h1><p id="8c5c" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">在这个练习中，我将使用 TensorFlow 库自带的免费“cifar”数据集。该数据集包括对象图像的像素值，标签包括数字。每个对象由一个数字表示。我们将首先训练网络，并使用测试数据集检查准确性。数据集已经由训练集和测试集分隔。我正在加载数据:</p><pre class="ns nt nu nv gt oc od oe of aw og bi"><span id="3197" class="nf mj jj od b gy oh oi l oj ok">import tensorflow as tf<br/>(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()</span></pre><p id="886e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">数据集包含以下类:</p><pre class="ns nt nu nv gt oc od oe of aw og bi"><span id="6b56" class="nf mj jj od b gy oh oi l oj ok">'airplane', 'automobile', 'bird', 'cat', 'deer',   'dog', 'frog', 'horse', 'ship', 'truck'</span></pre><p id="96b3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">每一类都用一个数字来表示。</p><p id="208e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果打印 y_train 数据，它看起来像这样:</p><figure class="ns nt nu nv gt iv gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/d708e0bf747c9c2b7411f438ab5dcd7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*sZLDv9l4XMPcPJyKzJ_t7A.png"/></div></figure><p id="a53e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从训练集中检查一个图像:</p><pre class="ns nt nu nv gt oc od oe of aw og bi"><span id="9b41" class="nf mj jj od b gy oh oi l oj ok">import matplotlib.pyplot as plt<br/>image=X_train[3]<br/>plt.imshow(image)<br/>plt.show()</span></pre><p id="6de0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><figure class="ns nt nu nv gt iv gh gi paragraph-image"><div class="gh gi om"><img src="../Images/258cbd97e5faeebb1d7b2bba0a75dd71.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*c-YYQS-QKbt5hmKauBqteA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="6f11" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">缩放输入数据总是好的。因为我们有像素值，我会把它们除以 255。</p><pre class="ns nt nu nv gt oc od oe of aw og bi"><span id="dd6e" class="nf mj jj od b gy oh oi l oj ok">X_train = X_train/255<br/>X_test = X_test/255</span></pre><p id="d698" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们检查一下训练输入的形状:</p><pre class="ns nt nu nv gt oc od oe of aw og bi"><span id="6c5c" class="nf mj jj od b gy oh oi l oj ok">X_train.shape</span></pre><p id="d2bc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="ns nt nu nv gt oc od oe of aw og bi"><span id="b585" class="nf mj jj od b gy oh oi l oj ok">(50000, 32, 32, 3)</span></pre><p id="5cc0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">从这个形状我们知道什么？</strong></p><p id="08de" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们有 50000 个训练数据。输入大小为 32x32，深度为 3。这意味着图像是彩色图像。我们有 RGB 值。</p><h2 id="796f" class="nf mj jj bd mk ng nh dn mo ni nj dp ms lh nk nl mu ll nm nn mw lp no np my nq bi translated">CNN 结构</h2><p id="8f81" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">对于这个项目，我将使用 3x3 的内核大小，我将在第一个卷积层使用 32 个输出窗口。下面是它的样子:</p><figure class="ns nt nu nv gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi on"><img src="../Images/28bfdd2261ebba6a88d6b62e2d008450.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lDyokcNKKdq5QCAryxGLRQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="0d9e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在之前的演示中，为了简单起见，我只解释了一个内核。但是您可以根据需要使用任意数量的内核。在这个练习中，我将使用 32 个内核。</p><p id="cd8b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">为了澄清，上图显示的是 3x3 和深度 3 的输入数据。我们的数据也有三个深度，正如您从 X-train 形状中看到的。但是尺寸是 32x32 而不是这张图所示的 3x3。</strong></p><blockquote class="oo"><p id="d241" class="op oq jj bd or os ot ou ov ow ox lt dk translated">图中所有的内核都是 2x2。但是我会用 3x3 内核。你可以试试其他尺寸的。事实上，核不一定是正方形的。它们可以是 4x2 或任何其他矩形形状。</p></blockquote><p id="606b" class="pw-post-body-paragraph ky kz jj la b lb oy kk ld le oz kn lg lh pa lj lk ll pb ln lo lp pc lr ls lt im bi translated">但是内核肯定不能比输入形状大。在此示例中，输入形状为 32x32。所以，内核不能比这个大。</p><p id="9700" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此外，当我们使用一个内核时，我们有一个输出窗口。因为我在这里使用了 32 个内核，所以我将有 32 个输出窗口。</p><p id="b32b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">卷积层之后，会有一个 MaxPooling 层。我用了一个 2x2 的过滤器。此外，步幅为 2 意味着将有 2 个步骤。可以尝试不同的步幅。</p><p id="43b6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我将有另外两个卷积和最大池层。然后会有一个'扁平化'层。它确实如其名。它会将三维数据展平为一维列。因为之后我们会把这个一维数据传到致密层。我假设你知道常规神经网络。密集层采用一维数据。对于这个项目，将有三个密集层。最终，输出层。</p><p id="7223" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出层将使用“softmax”激活。所有其他层将使用“relu”激活功能。</p><p id="657a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">模型如下:</p><pre class="ns nt nu nv gt oc od oe of aw og bi"><span id="773f" class="nf mj jj od b gy oh oi l oj ok">model = tf.keras.Sequential([<br/>    tf.keras.layers.Conv2D(32, (3, 3), padding="valid",<br/>                          activation="relu", input_shape=(32, 32, 3)),<br/>    tf.keras.layers.MaxPooling2D((2, 2), strides=2),<br/>    <br/>    tf.keras.layers.Conv2D(48, (3, 3), padding="valid", activation="relu"),<br/>    tf.keras.layers.MaxPooling2D((2, 2), strides=2),<br/>    <br/>    tf.keras.layers.Conv2D(48, (3, 3), padding="valid", activation="relu"),<br/>    tf.keras.layers.MaxPooling2D((2, 2), strides=2),<br/>    <br/>    tf.keras.layers.Flatten(),<br/>    tf.keras.layers.Dense(100, activation="relu"),<br/>    tf.keras.layers.Dense(100, activation="relu"),<br/>    tf.keras.layers.Dense(100, activation="relu"),<br/>    tf.keras.layers.Dense(10, activation="softmax")]<br/>)</span></pre><p id="436e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下是该模型的总结:</p><pre class="ns nt nu nv gt oc od oe of aw og bi"><span id="1655" class="nf mj jj od b gy oh oi l oj ok">model.summary()</span></pre><p id="c689" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="ns nt nu nv gt oc od oe of aw og bi"><span id="5575" class="nf mj jj od b gy oh oi l oj ok">Model: "sequential_25"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d_81 (Conv2D)           (None, 30, 30, 32)        896       <br/>_________________________________________________________________<br/>max_pooling2d_79 (MaxPooling (None, 15, 15, 32)        0         <br/>_________________________________________________________________<br/>conv2d_82 (Conv2D)           (None, 13, 13, 48)        13872     <br/>_________________________________________________________________<br/>max_pooling2d_80 (MaxPooling (None, 6, 6, 48)          0         <br/>_________________________________________________________________<br/>conv2d_83 (Conv2D)           (None, 4, 4, 48)          20784     <br/>_________________________________________________________________<br/>max_pooling2d_81 (MaxPooling (None, 2, 2, 48)          0         <br/>_________________________________________________________________<br/>flatten_27 (Flatten)         (None, 192)               0         <br/>_________________________________________________________________<br/>dense_98 (Dense)             (None, 100)               19300     <br/>_________________________________________________________________<br/>dense_99 (Dense)             (None, 100)               10100     <br/>_________________________________________________________________<br/>dense_100 (Dense)            (None, 100)               10100     <br/>_________________________________________________________________<br/>dense_101 (Dense)            (None, 10)                1010      <br/>=================================================================<br/>Total params: 76,062<br/>Trainable params: 76,062<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><p id="6de6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们试着理解这个总结。为了便于理解，我将讨论一个卷积层和一个 MaxPooling 层。第一个卷积层输出后的形状是(无，30，30，32)。</p><p id="b6d8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们来理解一下 30，30 和 32。这里最后一个元素是 32。这很容易理解。因为我们使用了 32 个内核，所以预期有 32 个输出窗口。</p><p id="aa38" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">这是什么 30，30？</strong>因为我们使用了“有效”的填充，所以输出形状应该是:</p><p id="0697" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输入大小—内核大小+ 1</p><p id="0c4e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里输入大小为 32，内核大小为 3，因此，</p><p id="0235" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">32–3+1 = 30</p><blockquote class="oo"><p id="4b6b" class="op oq jj bd or os ot ou ov ow ox lt dk translated">此公式仅用于“有效”的填充。如果你使用“相同”或“完整”的填充，公式是不同的。</p></blockquote><p id="3a31" class="pw-post-body-paragraph ky kz jj la b lb oy kk ld le oz kn lg lh pa lj lk ll pb ln lo lp pc lr ls lt im bi translated">下一个元素是 MaxPooling 层。第一个 MaxPooling 层的输出形状是(无，15，15，32)。如前所述，32 来自 32 个内核。因为我们在 MaxPooling 层中使用了 2x2 过滤器，所以数据在两边都变成了一半。所以，卷积层的 30，30 变成了 15，15。</p><p id="e186" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我开始训练模特之前。我想用一个提前停止的条件。</p><h2 id="e42e" class="nf mj jj bd mk ng nh dn mo ni nj dp ms lh nk nl mu ll nm nn mw lp no np my nq bi translated">什么是提前停止？</h2><p id="8931" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">假设，我将我的模型训练设置为 100 个时期，但是我的模型不需要 100 个时期。可能它在 50 个纪元后收敛。在这种情况下，如果我让它运行 100 个纪元，就会导致过度拟合。我们可以用我们选择的耐心值来设置提前停止条件。我将在这里使用耐心值 5。这意味着，如果模型损失在 5 个时期内没有足够的变化，则模型将停止训练，即使它仅运行 30 个时期或 50 个时期。</p><pre class="ns nt nu nv gt oc od oe of aw og bi"><span id="d44f" class="nf mj jj od b gy oh oi l oj ok">from tensorflow.keras.callbacks import EarlyStopping<br/>callbacks=[EarlyStopping(patience=5)]</span></pre><h2 id="153f" class="nf mj jj bd mk ng nh dn mo ni nj dp ms lh nk nl mu ll nm nn mw lp no np my nq bi translated">训练模型</h2><p id="4718" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">首先，我们需要编译，然后开始训练:</p><pre class="ns nt nu nv gt oc od oe of aw og bi"><span id="ca0f" class="nf mj jj od b gy oh oi l oj ok">model.compile(optimizer="adam", <br/>             loss=tf.keras.losses.SparseCategoricalCrossentropy(),<br/>             metrics=['accuracy'])<br/>history = model.fit(X_train, y_train, epochs = 50, <br/>                    validation_data=(X_test, y_test), callbacks=callbacks)</span></pre><p id="0261" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我设定了 50 个纪元的模型。但是它在 17 个周期后停止，因为提前停止条件节省了大量时间。</p><p id="6d31" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下是结果摘要:</p><pre class="ns nt nu nv gt oc od oe of aw og bi"><span id="fb3c" class="nf mj jj od b gy oh oi l oj ok">met_df1 = pd.DataFrame(history.history)<br/>met_df1</span></pre><p id="9225" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><figure class="ns nt nu nv gt iv gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/c3d150c8181a15e5e22044be2fb80bd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*O6QCcuu301tr-SU-sL2Mfw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="969d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是每个历元的训练准确度和验证准确度的曲线图:</p><pre class="ns nt nu nv gt oc od oe of aw og bi"><span id="203f" class="nf mj jj od b gy oh oi l oj ok">met_df1[["accuracy", "val_accuracy"]].plot()<br/>plt.xlabel("Epochs")<br/>plt.ylabel("Accuracy")<br/>plt.title("Accuracies per Epoch")<br/>plt.show()</span></pre><figure class="ns nt nu nv gt iv gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/d8681e07260687d6fcf2b49465e0cba0.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*CshW17dd-d8oCA-4eqCn-w.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="2c61" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从上面的图中可以看出，训练精度一直在上升，但验证精度在几个时期后几乎稳定下来。</p><h2 id="6268" class="nf mj jj bd mk ng nh dn mo ni nj dp ms lh nk nl mu ll nm nn mw lp no np my nq bi translated">模型改进</h2><p id="58e6" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">在这篇文章解释的思想范围内，你可以尝试很多事情。如果你想尝试一下，这里有一些想法给你:</p><ol class=""><li id="2006" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">改变内核形状。您可以尝试 2x2、4x4、2x4、3x2 或您选择的任何其他形状。</li><li id="2ecc" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">请随意尝试使用“相同”或“完整”作为填充值，而不是“有效”。</li><li id="8487" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">更改内核数量，并使用不同的数字，如 48、64、56 或任何其他数字，而不是 32、48 和 48。</li><li id="2034" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">添加或移除卷积层。</li><li id="157b" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">尝试用平均池代替最大池。</li><li id="0f85" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">添加或删除密集层，并改变神经元的数量。</li><li id="06d9" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">尝试其他激活功能，如 tanh、elu 或 leakyRelu。</li></ol><p id="6ca0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我敢肯定，如果你足够努力，你可能会得到比我在这里显示的结果更好的验证准确性。</p><h1 id="95f6" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">结论</h1><p id="8559" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">我试图让卷积神经网络的想法，它如何在幕后工作。尽管如果你不得不从头开始实现它，会涉及到更多的数学问题。尤其是参数更新。但幸运的是我们有张量流。这为我们更新了参数，我们不需要对所有的元素做偏导数。请随意尝试我上面建议的一些不同的模型架构，如果你觉得有趣，请分享你的发现！</p><p id="454a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">欢迎随时关注我的推特(Twitter)和我的新 T2 YouTube 频道(T3)。</p><h2 id="9c0b" class="nf mj jj bd mk ng nh dn mo ni nj dp ms lh nk nl mu ll nm nn mw lp no np my nq bi translated">更多阅读</h2><div class="is it gp gr iu pf"><a rel="noopener follow" target="_blank" href="/an-ultimate-guide-to-time-series-analysis-in-pandas-d511b8e80e81"><div class="pg ab fo"><div class="ph ab pi cl cj pj"><h2 class="bd jk gy z fp pk fr fs pl fu fw ji bi translated">熊猫时间序列分析终极指南</h2><div class="pm l"><h3 class="bd b gy z fp pk fr fs pl fu fw dk translated">在 Pandas 中执行时间序列分析所需的所有 Pandas 功能。您也可以将此用作备忘单。</h3></div><div class="pn l"><p class="bd b dl z fp pk fr fs pl fu fw dk translated">towardsdatascience.com</p></div></div><div class="po l"><div class="pp l pq pr ps po pt ja pf"/></div></div></a></div><div class="is it gp gr iu pf"><a rel="noopener follow" target="_blank" href="/a-complete-anomaly-detection-algorithm-from-scratch-in-python-step-by-step-guide-4c115e65d54e"><div class="pg ab fo"><div class="ph ab pi cl cj pj"><h2 class="bd jk gy z fp pk fr fs pl fu fw ji bi translated">Python 中从头开始的完整异常检测算法:分步指南</h2><div class="pm l"><h3 class="bd b gy z fp pk fr fs pl fu fw dk translated">基于概率的异常检测算法</h3></div><div class="pn l"><p class="bd b dl z fp pk fr fs pl fu fw dk translated">towardsdatascience.com</p></div></div><div class="po l"><div class="pu l pq pr ps po pt ja pf"/></div></div></a></div><div class="is it gp gr iu pf"><a href="https://pub.towardsai.net/text-data-visualization-with-wordcloud-of-any-shape-in-python-8cec334e5c4f" rel="noopener  ugc nofollow" target="_blank"><div class="pg ab fo"><div class="ph ab pi cl cj pj"><h2 class="bd jk gy z fp pk fr fs pl fu fw ji bi translated">用 Python 中任意形状的 WordCloud 实现文本数据可视化</h2><div class="pm l"><h3 class="bd b gy z fp pk fr fs pl fu fw dk translated">学习生成任何形状的单词云</h3></div><div class="pn l"><p class="bd b dl z fp pk fr fs pl fu fw dk translated">pub.towardsai.net</p></div></div><div class="po l"><div class="pv l pq pr ps po pt ja pf"/></div></div></a></div><div class="is it gp gr iu pf"><a rel="noopener follow" target="_blank" href="/detailed-guide-to-multiple-linear-regression-model-assessment-and-inference-in-r-e9b183b1441"><div class="pg ab fo"><div class="ph ab pi cl cj pj"><h2 class="bd jk gy z fp pk fr fs pl fu fw ji bi translated">多元线性回归模型、评估和推理的详细指南</h2><div class="pm l"><h3 class="bd b gy z fp pk fr fs pl fu fw dk translated">模型开发、解释、方差计算、f 检验和 t 检验</h3></div><div class="pn l"><p class="bd b dl z fp pk fr fs pl fu fw dk translated">towardsdatascience.com</p></div></div><div class="po l"><div class="pw l pq pr ps po pt ja pf"/></div></div></a></div></div></div>    
</body>
</html>