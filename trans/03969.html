<html>
<head>
<title>Control DJI Tello drone with Hand gestures</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用手势控制DJI·泰洛无人机</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/control-dji-tello-drone-with-hand-gestures-b76bd1d4644f?source=collection_archive---------2-----------------------#2021-04-03">https://towardsdatascience.com/control-dji-tello-drone-with-hand-gestures-b76bd1d4644f?source=collection_archive---------2-----------------------#2021-04-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f5d7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用MediaPipe手关键点检测器和简单的神经网络来识别手势和控制无人机</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/bd358cbe2ab2873d6d902be49bab4631.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xoNbldnILV2GcWJk"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae kv" href="https://unsplash.com/@dose?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">剂量媒体</a>拍照</p></figure><p id="dfc1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用手势控制无人机是一个非常常见的主题。但是大多数解决方案都集中在旧的OpenCV上。因此，这是快速的解决方案(如果你想直接在无人机上运行它)，但很难添加自定义手势，甚至是动作。在这篇文章中，我想介绍一种基于手部关键点检测模型的解决方案，它由<a class="ae kv" href="https://mediapipe.dev" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> MediaPipe </strong> </a>和简单的<strong class="ky ir">多层感知器</strong>(神经网络)组成。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="87c9" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">介绍</h1><p id="5018" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">该项目依托<strong class="ky ir">两个主要部分</strong>——DJI泰洛无人机和MediaPipe快手关键点检测。</p><p id="cc68" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">DJI·泰洛</strong>是任何一种编程实验的完美无人机。它有一个丰富的Python API(也有Swift和JS APIs可用)，这有助于几乎完全控制无人机，创建无人机群，并利用其相机进行计算机视觉。</p><p id="2cac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> MediaPipe </strong>是一个令人惊叹的ML平台，拥有许多强大的解决方案，如面部网格、手关键点检测和Objectron。此外，他们的模型可以在具有设备上加速的移动平台上使用。</p><p id="aaa2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是你需要的<strong class="ky ir">启动包</strong>:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/556d9deee33484e9d67dec971f35d85f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zH92AbrPoGIxw3GYHagelA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者| DJI·泰洛，笔记本电脑和人手(狗爪子正在开发中)</p></figure><h1 id="1e87" class="lz ma iq bd mb mc mx me mf mg my mi mj jw mz jx ml jz na ka mn kc nb kd mp mq bi translated">进场说明</h1><p id="6c47" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">该应用分为两个主要部分:<strong class="ky ir">手势识别</strong>和<strong class="ky ir">无人机控制器</strong>。这些都是独立的实例，很容易修改。例如，添加新的手势或改变无人机的移动速度。</p><p id="814d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们仔细看看每个部分！</p><h2 id="673d" class="nc ma iq bd mb nd ne dn mf nf ng dp mj lf nh ni ml lj nj nk mn ln nl nm mp nn bi translated">手势识别</h2><p id="a757" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">当然，这个项目的主要部分是致力于手势检测器。这个项目中识别方法的想法受到了这个<a class="ae kv" href="https://github.com/Kazuhito00/hand-gesture-recognition-using-mediapipe" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>的启发。这里是它如何工作的一个快速概述。</p><p id="71b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">MediaPipe为他们的手关键点检测器提供了python实现。正在返回<strong class="ky ir"> 20手界标</strong>的三维坐标。像这样:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/13b742f7dcd75f758769c6a2bc47ad38.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/1*jjjT8CJMZhldv_SdrZaLPw.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自开放媒体管道库的GIF(<a class="ae kv" href="https://github.com/google/mediapipe/blob/master/docs/images/mobile/hand_tracking_3d_android_gpu.gif" rel="noopener ugc nofollow" target="_blank">链接</a>)</p></figure><p id="743d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个项目中，将只使用<strong class="ky ir"> 2D </strong>坐标。在这里，您可以看到所有20个要点。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/a24721e5153a9dfa4203d27dff69c298.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fMBLvkdLbg0MEfv7KbJZjQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来自开放媒体管道库(<a class="ae kv" href="https://github.com/google/mediapipe/blob/master/docs/images/mobile/hand_landmarks.png" rel="noopener ugc nofollow" target="_blank">链接</a></p></figure><p id="61db" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，将这些坐标展平并归一化。手势的<strong class="ky ir"> ID </strong>被添加到每个点列表中。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/9a56353b8dfa18726380e3690502fa0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7XQio4wmboJpS5UAbWnowA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片|此类积分列表示例</p></figure><p id="a1bc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我们为每个手势收集了大约<strong class="ky ir">20–100个例子</strong>时，我们就可以开始训练我们的神经网络了。</p><p id="ac76" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">MLP只是一个简单的<strong class="ky ir"> 5层</strong> NN，有<strong class="ky ir"> 4个全连接</strong>层和<strong class="ky ir"> 1个Softmax </strong>层用于分类。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/681423f1920d9abfd1de954eed5a24f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TZw8_IMH2biAHgDEiSlL8Q.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者|神经网络结构</p></figure><p id="f7dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为这样简单的结构，我们可以用少量的例子得到极好的精度。我们不需要在不同的光照下为每个手势重新训练模型，因为MediaPipe接管了所有的检测工作。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/cb7cbdc4e14125376399220d13294f7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iha4qLw1bVgsrhzoO3iC1w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="7bc2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我的实验中，我可以对8种不同的手势中的每一种获得超过97%的准确率。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="ad59" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为网络的结构非常简单，您可以很容易地使用<strong class="ky ir">网格搜索</strong>来找到最适合神经网络的超参数。</p><p id="ad69" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是我在这个项目中使用的Tensorboard的一个例子:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/d062bde20745a90c21631e91b095567f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2eWubDnhjW5xb4LMGcRXwg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片|网格搜索可视化示例</p></figure><h2 id="04a5" class="nc ma iq bd mb nd ne dn mf nf ng dp mj lf nh ni ml lj nj nk mn ln nl nm mp nn bi translated">无人机控制器</h2><p id="6bbe" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">好了，我们有了无人机的图像和基于检测到的关键点返回手势ID的模型。但是如何控制我们的无人机呢？</p><p id="f57e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">泰洛最棒的地方在于他有现成的Python API来帮助我们完成这项工作。我们只需要将每个手势ID设置为一个命令。</p><p id="eeb4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">尽管如此，为了消除错误识别的情况，我们将创建一个手势缓冲区。当这个缓冲区主要包含一个特定的手势ID时，我们可以发送一个命令来移动无人机。</p><p id="11c0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nu">以下是项目代码的功能实现示例:</em></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="7530" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里可以看到，我们只是根据每个ID设置不同方向的期望速度。这使得无人机能够朝着一个方向飞行而不会颠簸。</p><h1 id="199b" class="lz ma iq bd mb mc mx me mf mg my mi mj jw mz jx ml jz na ka mn kc nb kd mp mq bi translated">演示</h1><p id="dacf" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">这是最甜蜜的部分🔥</p><p id="7797" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是首先，运行项目需要一些准备工作:</p><h2 id="9d0d" class="nc ma iq bd mb nd ne dn mf nf ng dp mj lf nh ni ml lj nj nk mn ln nl nm mp nn bi translated">设置</h2><p id="c4ab" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">首先，克隆存储库</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="7c37" class="nc ma iq ny b gy oc od l oe of"># Using HTTPS<br/>git clone <a class="ae kv" href="https://github.com/kinivi/tello-gesture-control.git" rel="noopener ugc nofollow" target="_blank">https://github.com/kinivi/tello-gesture-control.git</a><br/># Using SSH<br/>git clone <a class="ae kv" href="mailto:git@github.com" rel="noopener ugc nofollow" target="_blank">git@github.com</a>:kinivi/tello-gesture-control.git</span></pre><p id="7790" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 1。媒体管道设置</strong></p><p id="f185" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，安装以下依赖项:</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="0600" class="nc ma iq ny b gy oc od l oe of">ConfigArgParse == 1.2.3<br/>djitellopy == 1.5<br/>numpy == 1.19.3<br/>opencv_python == 4.5.1.48<br/>tensorflow == 2.4.1<br/>mediapipe == 0.8.2</span></pre><p id="3ebc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图像处理需要OpenCV，djitellop是DJI官方Python API的一个非常有用的包装器</p><p id="2925" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 2。泰洛设置</strong></p><p id="76d8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">打开无人机并将电脑连接到其WiFi</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/cc129381bee9a7c72e3c76682ea83561.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*OUJOX5piPcReTWBftIjZoA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="9561" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，运行以下代码来验证连通性</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="8039" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">成功连接后，您将看到以下内容</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="ba76" class="nc ma iq ny b gy oc od l oe of">1. Connection test:<br/>Send command: command<br/>Response: b'ok'</span><span id="7bdb" class="nc ma iq ny b gy oh od l oe of">2. Video stream test:<br/>Send command: streamon<br/>Response: b'ok'</span></pre><h2 id="cd5a" class="nc ma iq bd mb nd ne dn mf nf ng dp mj lf nh ni ml lj nj nk mn ln nl nm mp nn bi translated">运行应用程序</h2><p id="61fb" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">有两种控制方式:<strong class="ky ir">键盘</strong>和<strong class="ky ir">手势</strong>。在飞行过程中，你可以在不同的控制类型之间转换。下面是对这两种类型的完整描述。</p><p id="8ad5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">运行以下命令启动tello控件:</p><pre class="kg kh ki kj gt nx ny nz oa aw ob bi"><span id="9082" class="nc ma iq ny b gy oc od l oe of">python3 main.py</span></pre><p id="637d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该脚本将启动python窗口，显示如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oi"><img src="../Images/6793a5c4e67f18396d28e118bd4d21ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PCf2a-dSwBKOHbkv54YuAA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h2 id="cce8" class="nc ma iq bd mb nd ne dn mf nf ng dp mj lf nh ni ml lj nj nk mn ln nl nm mp nn bi translated">键盘控制</h2><p id="cfd0" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">为了将你的无人机定位到一个完美的地方或者在紧急情况下，你可以使用键盘控制。默认情况下，起飞后，<em class="nu">键盘的控制方式</em>是<strong class="ky ir">在</strong>上</p><p id="ed33" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">检查以下按键和动作描述列表:</p><ul class=""><li id="29a2" class="oj ok iq ky b kz la lc ld lf ol lj om ln on lr oo op oq or bi translated"><code class="fe os ot ou ny b">k</code> - &gt;切换键盘控制</li><li id="6280" class="oj ok iq ky b kz ov lc ow lf ox lj oy ln oz lr oo op oq or bi translated"><code class="fe os ot ou ny b">g</code> - &gt;切换手势控制</li><li id="8e60" class="oj ok iq ky b kz ov lc ow lf ox lj oy ln oz lr oo op oq or bi translated"><code class="fe os ot ou ny b">Space</code> - &gt;起飞无人机(如果降落)或降落无人机(如果飞行中)</li><li id="bbf6" class="oj ok iq ky b kz ov lc ow lf ox lj oy ln oz lr oo op oq or bi translated"><code class="fe os ot ou ny b">w</code> - &gt;向前移动</li><li id="6819" class="oj ok iq ky b kz ov lc ow lf ox lj oy ln oz lr oo op oq or bi translated"><code class="fe os ot ou ny b">s</code> - &gt;向后移动</li><li id="9964" class="oj ok iq ky b kz ov lc ow lf ox lj oy ln oz lr oo op oq or bi translated"><code class="fe os ot ou ny b">a</code> - &gt;向左移动</li><li id="3ae5" class="oj ok iq ky b kz ov lc ow lf ox lj oy ln oz lr oo op oq or bi translated"><code class="fe os ot ou ny b">d</code> - &gt;向右移动</li><li id="dc2b" class="oj ok iq ky b kz ov lc ow lf ox lj oy ln oz lr oo op oq or bi translated"><code class="fe os ot ou ny b">e</code> - &gt;顺时针旋转</li><li id="e219" class="oj ok iq ky b kz ov lc ow lf ox lj oy ln oz lr oo op oq or bi translated"><code class="fe os ot ou ny b">q</code> - &gt;逆时针旋转</li><li id="3ec1" class="oj ok iq ky b kz ov lc ow lf ox lj oy ln oz lr oo op oq or bi translated"><code class="fe os ot ou ny b">r</code> - &gt;上移</li><li id="b0dd" class="oj ok iq ky b kz ov lc ow lf ox lj oy ln oz lr oo op oq or bi translated"><code class="fe os ot ou ny b">f</code> - &gt;向下移动</li><li id="d5d6" class="oj ok iq ky b kz ov lc ow lf ox lj oy ln oz lr oo op oq or bi translated"><code class="fe os ot ou ny b">Esc</code> - &gt;结束程序，降落无人机</li></ul><h2 id="6fa8" class="nc ma iq bd mb nd ne dn mf nf ng dp mj lf nh ni ml lj nj nk mn ln nl nm mp nn bi translated">手势控制</h2><p id="6798" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">按下<code class="fe os ot ou ny b">g</code>激活<em class="nu">手势控制模式</em>。以下是我的回购中可用手势的完整列表:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pa"><img src="../Images/07dcdaa9e71e19d0f0aabe4e943a2e58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*elvnt0z3mplWZn0EZGvq9w.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者|手势列表</p></figure><h2 id="4d29" class="nc ma iq bd mb nd ne dn mf nf ng dp mj lf nh ni ml lj nj nk mn ln nl nm mp nn bi translated">飞行🚀</h2><p id="5f4b" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">现在你已经准备好飞翔了。按下<code class="fe os ot ou ny b">Space</code>起飞，享受🛸</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/220d944c2b8a4278e89c8a5d86ddf35c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/1*2yuA-Jnmx3ANo9pWpbywPQ.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者GIF |演示</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h2 id="6429" class="nc ma iq bd mb nd ne dn mf nf ng dp mj lf nh ni ml lj nj nk mn ln nl nm mp nn bi translated">项目回购</h2><div class="pc pd gp gr pe pf"><a href="https://github.com/kinivi/tello-gesture-control.git" rel="noopener  ugc nofollow" target="_blank"><div class="pg ab fo"><div class="ph ab pi cl cj pj"><h2 class="bd ir gy z fp pk fr fs pl fu fw ip bi translated">kinivi/tello手势控制</h2><div class="pm l"><h3 class="bd b gy z fp pk fr fs pl fu fw dk translated">这个项目的主要目标是在没有任何手套或附加设备的情况下使用手势控制无人机…</h3></div><div class="pn l"><p class="bd b dl z fp pk fr fs pl fu fw dk translated">github.com</p></div></div><div class="po l"><div class="pp l pq pr ps po pt kp pf"/></div></div></a></div><h2 id="2d37" class="nc ma iq bd mb nd ne dn mf nf ng dp mj lf nh ni ml lj nj nk mn ln nl nm mp nn bi translated">参考</h2><ul class=""><li id="29d9" class="oj ok iq ky b kz mr lc ms lf pu lj pv ln pw lr oo op oq or bi translated"><a class="ae kv" href="https://google.github.io/mediapipe/solutions/hands" rel="noopener ugc nofollow" target="_blank"> MediaPipe手关键点检测器</a></li><li id="f3e5" class="oj ok iq ky b kz ov lc ow lf ox lj oy ln oz lr oo op oq or bi translated"><a class="ae kv" href="https://github.com/damiafuentes/DJITelloPy" rel="noopener ugc nofollow" target="_blank"> DJI泰洛API包装库</a></li><li id="1a0c" class="oj ok iq ky b kz ov lc ow lf ox lj oy ln oz lr oo op oq or bi translated"><a class="ae kv" href="https://github.com/Kazuhito00/hand-gesture-recognition-using-mediapipe" rel="noopener ugc nofollow" target="_blank">使用手关键点的手势识别(Kazuhito00) </a></li></ul><p id="956c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">附言</strong>。这个项目也可以很容易地添加你自己的手势。只需查看<a class="ae kv" href="https://github.com/kinivi/tello-gesture-control#Adding-new-gestures" rel="noopener ugc nofollow" target="_blank">自述</a>的这一部分。</p><p id="bdf7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> P.S.S. </strong>在不久的将来，我将使用一个<a class="ae kv" href="https://google.github.io/mediapipe/solutions/holistic" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">整体模型</strong> </a>来检测大距离的手势，并使用TensorFlow JS来利用智能手机上的<strong class="ky ir"> WebGPU加速</strong>(用智能手机上的摄像头控制无人机)。所以，如果你对它感兴趣，请在<a class="ae kv" href="https://github.com/kinivi" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上关注我。</p></div></div>    
</body>
</html>