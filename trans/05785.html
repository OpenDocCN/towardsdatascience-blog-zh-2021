<html>
<head>
<title>Basics of CountVectorizer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计数矢量器的基础</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/basics-of-countvectorizer-e26677900f9c?source=collection_archive---------1-----------------------#2021-05-24">https://towardsdatascience.com/basics-of-countvectorizer-e26677900f9c?source=collection_archive---------1-----------------------#2021-05-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7fba" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解关于CountVectorizer的一切信息。</h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/5ecaea201e43975d2b65012cf0d5d45d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vkEcmXufTIj-hEsB"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">照片由<a class="ae kw" href="https://unsplash.com/@lakhani?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">阿里·沙阿·拉哈尼</a>在<a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="244a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">机器不能理解字符和单词。所以在处理文本数据时，我们需要用机器能够理解的数字来表示它。Countvectorizer是一种将文本转换为数字数据的方法。为了向您展示它是如何工作的，让我们举一个例子:</p><pre class="kh ki kj kk gt lt lu lv lw aw lx bi"><span id="da2e" class="ly lz iq lu b gy ma mb l mc md">text = [‘Hello my name is james, this is my python notebook’]</span></pre><p id="5c92" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">文本被转换成如下所示的稀疏矩阵。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi me"><img src="../Images/4e5249e098f713c2cb8939e3bbc7ef6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*v_jgSbul8mjfQeBfBIpGLQ.png"/></div></figure><p id="f79e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们在文本中有8个唯一的单词，因此在矩阵中有8个不同的列，每个列代表一个唯一的单词。该行代表字数。因为单词“is”和“my”重复出现了两次，所以我们对这些特定单词的计数为2，对其余单词的计数为1。</p><p id="1871" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Countvectorizer使文本数据可以很容易地直接用于机器学习和深度学习模型，如文本分类。</p><p id="fbe3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">让我们再举一个例子，但这一次有不止一个输入:</p><pre class="kh ki kj kk gt lt lu lv lw aw lx bi"><span id="de6f" class="ly lz iq lu b gy ma mb l mc md">text = [‘Hello my name is james' , ’this is my python notebook’]</span></pre><p id="7539" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我有两个文本输入，所发生的是每个输入被预处理，标记化，并表示为一个稀疏矩阵。默认情况下，Countvectorizer将文本转换为小写，并使用单词级标记化。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/7fdc48ff174b79ec812f0aa922b7410e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*64-SAdEtdZW2Et8HZzqJYA.png"/></div></figure><p id="32d5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">现在我们已经看了一些例子，让我们实际编码！</p><p id="98d7" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们将首先从导入必要的库开始。我们将使用pandas库来可视化矩阵，并使用sk learn . feature _ extraction . text库来执行矢量化。</p><pre class="kh ki kj kk gt lt lu lv lw aw lx bi"><span id="f8d2" class="ly lz iq lu b gy ma mb l mc md">import pandas as pd</span><span id="964a" class="ly lz iq lu b gy mg mb l mc md">from sklearn.feature_extraction.text import CountVectorizer<br/></span><span id="8c5f" class="ly lz iq lu b gy mg mb l mc md">text = [‘Hello my name is james’,</span><span id="92cc" class="ly lz iq lu b gy mg mb l mc md">‘james this is my python notebook’,</span><span id="270c" class="ly lz iq lu b gy mg mb l mc md">‘james trying to create a big dataset’,</span><span id="5d85" class="ly lz iq lu b gy mg mb l mc md">‘james of words to try differnt’,</span><span id="1d6e" class="ly lz iq lu b gy mg mb l mc md">‘features of count vectorizer’]<br/></span><span id="e22f" class="ly lz iq lu b gy mg mb l mc md">coun_vect = CountVectorizer()</span><span id="45d7" class="ly lz iq lu b gy mg mb l mc md">count_matrix = coun_vect.fit_transform(text)<br/></span><span id="e349" class="ly lz iq lu b gy mg mb l mc md">count_array = count_matrix.toarray()<br/></span><span id="6e61" class="ly lz iq lu b gy mg mb l mc md">df = pd.DataFrame(data=count_array,columns = coun_vect.get_feature_names())</span><span id="76c4" class="ly lz iq lu b gy mg mb l mc md">print(df)</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi mh"><img src="../Images/61fad6ca2b2dc6575a5e276be7b2820b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZJZgYom-FcI1sXkp3XgR1w.png"/></div></div></figure><h1 id="ac61" class="mi lz iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated"><strong class="ak">参数</strong></h1><ul class=""><li id="20b6" class="mz na iq kz b la nb ld nc lg nd lk ne lo nf ls ng nh ni nj bi translated"><strong class="kz ir">小写</strong></li></ul><p id="2310" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在标记前将所有字符转换成小写。默认值设置为true，并采用布尔值。</p><pre class="kh ki kj kk gt lt lu lv lw aw lx bi"><span id="b12c" class="ly lz iq lu b gy ma mb l mc md">text = [‘hello my name is james’,</span><span id="8b99" class="ly lz iq lu b gy mg mb l mc md">‘Hello my name is James’]<br/></span><span id="7971" class="ly lz iq lu b gy mg mb l mc md">coun_vect = CountVectorizer(<strong class="lu ir">lowercase=False</strong>)</span><span id="c789" class="ly lz iq lu b gy mg mb l mc md">count_matrix = coun_vect.fit_transform(text)<br/></span><span id="f7ac" class="ly lz iq lu b gy mg mb l mc md">count_array = count_matrix.toarray()<br/></span><span id="dbc7" class="ly lz iq lu b gy mg mb l mc md">df = pd.DataFrame(data=count_array,columns = coun_vect.get_feature_names())</span><span id="b20d" class="ly lz iq lu b gy mg mb l mc md">print(df)</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/7ca597e7ee05a8797fb726828f391f55.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*5GvkDEFE4X9SZElpdXKuJQ.png"/></div></figure><p id="c33c" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">现在让我们尝试不使用“小写=假”</p><pre class="kh ki kj kk gt lt lu lv lw aw lx bi"><span id="c813" class="ly lz iq lu b gy ma mb l mc md">text = [‘hello my name is james’,</span><span id="0aae" class="ly lz iq lu b gy mg mb l mc md">‘Hello my name is James’]<br/></span><span id="f181" class="ly lz iq lu b gy mg mb l mc md">coun_vect = CountVectorizer()</span><span id="db87" class="ly lz iq lu b gy mg mb l mc md">count_matrix = coun_vect.fit_transform(text)<br/></span><span id="8cdd" class="ly lz iq lu b gy mg mb l mc md">count_array = count_matrix.toarray()<br/></span><span id="f7d5" class="ly lz iq lu b gy mg mb l mc md">df = pd.DataFrame(data=count_array,columns = coun_vect.get_feature_names())</span><span id="7d3e" class="ly lz iq lu b gy mg mb l mc md">print(df)</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/a3eafb063b286ad5e5bb20e3709f275b.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*TWl7gvbS2XCYtDVLyVP2IA.png"/></div></figure><ul class=""><li id="7e53" class="mz na iq kz b la lb ld le lg nm lk nn lo no ls ng nh ni nj bi translated"><strong class="kz ir">停_字</strong></li></ul><p id="f56d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">停用词是任何语言中对句子没有多大意义的词。它们可以被安全地忽略，而不会牺牲句子的意义。有三种处理停用词的方法:</p><ol class=""><li id="ab66" class="mz na iq kz b la lb ld le lg nm lk nn lo no ls np nh ni nj bi translated">自定义停用字词列表</li></ol><pre class="kh ki kj kk gt lt lu lv lw aw lx bi"><span id="055b" class="ly lz iq lu b gy ma mb l mc md">text = [‘Hello my name is james’,</span><span id="9603" class="ly lz iq lu b gy mg mb l mc md">‘james this is my python notebook’,</span><span id="d602" class="ly lz iq lu b gy mg mb l mc md">‘james trying to create a big dataset’,</span><span id="a84b" class="ly lz iq lu b gy mg mb l mc md">‘james of words to try differnt’,</span><span id="d600" class="ly lz iq lu b gy mg mb l mc md">‘features of count vectorizer’]<br/></span><span id="cbe3" class="ly lz iq lu b gy mg mb l mc md">coun_vect = CountVectorizer(<strong class="lu ir">stop_words= [‘is’,’to’,’my’]</strong>)</span><span id="96b1" class="ly lz iq lu b gy mg mb l mc md">count_matrix = coun_vect.fit_transform(text)<br/></span><span id="d2ba" class="ly lz iq lu b gy mg mb l mc md">count_array = count_matrix.toarray()<br/></span><span id="3fc2" class="ly lz iq lu b gy mg mb l mc md">df = pd.DataFrame(data=count_array,columns = coun_vect.get_feature_names())</span><span id="d545" class="ly lz iq lu b gy mg mb l mc md">print(df)</span></pre><p id="3591" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">稀疏矩阵去掉这几个字后是，到和我的:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nq"><img src="../Images/ca8a4520c458e617e4be22416bac8106.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7PmjJ0AdyhPCLFsx5qBFrw.png"/></div></div></figure><p id="2c34" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">2.sklearn内置停用词表</p><pre class="kh ki kj kk gt lt lu lv lw aw lx bi"><span id="a250" class="ly lz iq lu b gy ma mb l mc md">text = [‘Hello my name is james’,</span><span id="975a" class="ly lz iq lu b gy mg mb l mc md">‘james this is my python notebook’,</span><span id="bdf5" class="ly lz iq lu b gy mg mb l mc md">‘james trying to create a big dataset’,</span><span id="f548" class="ly lz iq lu b gy mg mb l mc md">‘james of words to try differnt’,</span><span id="aa53" class="ly lz iq lu b gy mg mb l mc md">‘features of count vectorizer’]<br/></span><span id="79c5" class="ly lz iq lu b gy mg mb l mc md">coun_vect = CountVectorizer(<strong class="lu ir">stop_words=’english’</strong>)</span><span id="80bb" class="ly lz iq lu b gy mg mb l mc md">count_matrix = coun_vect.fit_transform(text)<br/></span><span id="6907" class="ly lz iq lu b gy mg mb l mc md">count_array = count_matrix.toarray()<br/></span><span id="8dc2" class="ly lz iq lu b gy mg mb l mc md">df = pd.DataFrame(data=count_array,columns = coun_vect.get_feature_names())</span><span id="dcb1" class="ly lz iq lu b gy mg mb l mc md">print(df)</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nr"><img src="../Images/3eac8af3b53e57530c3a7753e04185bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SB8pr1p4yIMq33lFHY1qwQ.png"/></div></div></figure><p id="672a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">3.使用max_df和min_df(稍后介绍)</p><p id="cefc" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><em class="ns"> Max_df: </em></p><p id="a532" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Max_df代表最大文档频率。类似于min_df，我们可以忽略频繁出现的单词。这些单词可能就像在每个文档中出现的单词“the ”,不会为我们的文本分类或任何其他机器学习模型提供有价值的信息，因此可以安全地忽略。Max_df查看有多少文档包含该单词，如果它超过max_df阈值，则从稀疏矩阵中消除它。这个参数又可以是2种类型的值，百分比和绝对值。</p><p id="9580" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">使用绝对值:</p><pre class="kh ki kj kk gt lt lu lv lw aw lx bi"><span id="264e" class="ly lz iq lu b gy ma mb l mc md">text = [‘Hello my name is james’,</span><span id="adea" class="ly lz iq lu b gy mg mb l mc md">‘james this is my python notebook’,</span><span id="5d4a" class="ly lz iq lu b gy mg mb l mc md">‘james trying to create a big dataset’,</span><span id="87a9" class="ly lz iq lu b gy mg mb l mc md">‘james of words to try differnt’,</span><span id="28e1" class="ly lz iq lu b gy mg mb l mc md">‘features of count vectorizer’]<br/></span><span id="b6b6" class="ly lz iq lu b gy mg mb l mc md">coun_vect = CountVectorizer(<strong class="lu ir">max_df=1</strong>)</span><span id="6fb8" class="ly lz iq lu b gy mg mb l mc md">count_matrix = coun_vect.fit_transform(text)<br/></span><span id="b806" class="ly lz iq lu b gy mg mb l mc md">count_array = count_matrix.toarray()<br/></span><span id="66d1" class="ly lz iq lu b gy mg mb l mc md">df = pd.DataFrame(data=count_array,columns = coun_vect.get_feature_names())</span><span id="6fb1" class="ly lz iq lu b gy mg mb l mc md">print(df)</span></pre><p id="3aea" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">单词“is”、“to”、“james”、“my”和“of”已从稀疏矩阵中删除，因为它们出现在多个文档中。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nt"><img src="../Images/9183d2a946bbfddae51f4ff28cbe686a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RQJYNgtCmnlD5o2E3d7jjA.png"/></div></div></figure><p id="62b8" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">使用百分比:</p><pre class="kh ki kj kk gt lt lu lv lw aw lx bi"><span id="cb67" class="ly lz iq lu b gy ma mb l mc md">text = [‘Hello my name is james’,</span><span id="3e98" class="ly lz iq lu b gy mg mb l mc md">‘james this is my python notebook’,</span><span id="e7a4" class="ly lz iq lu b gy mg mb l mc md">‘james trying to create a big dataset’,</span><span id="de65" class="ly lz iq lu b gy mg mb l mc md">‘james of words to try differnt’,</span><span id="a464" class="ly lz iq lu b gy mg mb l mc md">‘features of count vectorizer’]<br/></span><span id="d994" class="ly lz iq lu b gy mg mb l mc md">coun_vect = CountVectorizer(<strong class="lu ir">max_df=0.75</strong>)</span><span id="3ce2" class="ly lz iq lu b gy mg mb l mc md">count_matrix = coun_vect.fit_transform(text)<br/></span><span id="e9c0" class="ly lz iq lu b gy mg mb l mc md">count_array = count_matrix.toarray()<br/></span><span id="2b49" class="ly lz iq lu b gy mg mb l mc md">df = pd.DataFrame(data=count_array,columns = coun_vect.get_feature_names())</span><span id="4851" class="ly lz iq lu b gy mg mb l mc md">print(df)</span></pre><p id="2362" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如您所见，单词“james”在5个文档中出现了4个(85%)，因此越过了75%的阈值并从稀疏矩阵中移除</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nu"><img src="../Images/bba8034c4dd8c37a49d0ac0c3ec220bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rlTlO6rSnJR4NXRzA4gQGw.png"/></div></div></figure><p id="41d0" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><em class="ns"> Min_df: </em></p><p id="a399" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Min_df代表最小文档频率，与计算单词在整个数据集中出现的次数的术语频率相反，文档频率计算数据集中(也称为行或条目)具有特定单词的文档的数量。当构建词汇表时，Min_df忽略文档频率严格低于给定阈值的术语。例如，在您的数据集中，您可能有只出现在1或2个文档中的名称，现在这些名称可以被忽略，因为它们不能提供整个数据集的足够信息，而只能提供几个特定文档的信息。min_df可以取绝对值(1，2，3..)或表示文档百分比的值(0.50，忽略出现在50%文档中的单词)</p><p id="5879" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">使用绝对值:</p><pre class="kh ki kj kk gt lt lu lv lw aw lx bi"><span id="6002" class="ly lz iq lu b gy ma mb l mc md">text = [‘Hello my name is james’,</span><span id="4a58" class="ly lz iq lu b gy mg mb l mc md">‘james this is my python notebook’,</span><span id="3871" class="ly lz iq lu b gy mg mb l mc md">‘james trying to create a big dataset’,</span><span id="b4fa" class="ly lz iq lu b gy mg mb l mc md">‘james of words to try differnt’,</span><span id="0f0a" class="ly lz iq lu b gy mg mb l mc md">‘features of count vectorizer’]<br/></span><span id="3dd1" class="ly lz iq lu b gy mg mb l mc md">coun_vect = CountVectorizer(<strong class="lu ir">min_df=2</strong>)</span><span id="73af" class="ly lz iq lu b gy mg mb l mc md">count_matrix = coun_vect.fit_transform(text)<br/></span><span id="abd9" class="ly lz iq lu b gy mg mb l mc md">count_array = count_matrix.toarray()<br/></span><span id="d0a3" class="ly lz iq lu b gy mg mb l mc md">df = pd.DataFrame(data=count_array,columns = coun_vect.get_feature_names())</span><span id="5bab" class="ly lz iq lu b gy mg mb l mc md">print(df)</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nv"><img src="../Images/b86c2f44cbfb8c9ed7cd69a303ccb1dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*rbz0ouA43LO4pY22BXKnIA.png"/></div></div></figure><ul class=""><li id="e0bf" class="mz na iq kz b la lb ld le lg nm lk nn lo no ls ng nh ni nj bi translated"><strong class="kz ir"> max_features </strong></li></ul><p id="ec38" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">计数矢量器将选择出现频率最高的单词/特征/术语。它采用绝对值，因此如果您设置“max_features = 3”，它将选择数据中最常见的3个单词。</p><pre class="kh ki kj kk gt lt lu lv lw aw lx bi"><span id="ab40" class="ly lz iq lu b gy ma mb l mc md">text = [‘This is the first document.’,’This document is the second document.’,’And this is the third one.’, ‘Is this the first document?’,]</span><span id="eede" class="ly lz iq lu b gy mg mb l mc md">coun_vect = CountVectorizer(max_features=3)</span><span id="e365" class="ly lz iq lu b gy mg mb l mc md">count_matrix = coun_vect.fit_transform(text)</span><span id="7fe3" class="ly lz iq lu b gy mg mb l mc md">count_array = count_matrix.toarray()</span><span id="0bb9" class="ly lz iq lu b gy mg mb l mc md">df = pd.DataFrame(data=count_array,columns = coun_vect.get_feature_names())</span><span id="5fc2" class="ly lz iq lu b gy mg mb l mc md">print(df)</span><span id="cd94" class="ly lz iq lu b gy mg mb l mc md">df</span></pre><ul class=""><li id="4beb" class="mz na iq kz b la lb ld le lg nm lk nn lo no ls ng nh ni nj bi translated"><strong class="kz ir">双星</strong></li></ul><p id="354e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">通过设置“binary = True”，CountVectorizer不再考虑术语/单词的频率。如果发生，则设置为1，否则为0。默认情况下，binary设置为False。这通常在术语/单词的计数不能为机器学习模型提供有用信息时使用。</p><pre class="kh ki kj kk gt lt lu lv lw aw lx bi"><span id="3ecd" class="ly lz iq lu b gy ma mb l mc md">text = [‘This is the first document. Is this the first document?’ ]</span><span id="9d28" class="ly lz iq lu b gy mg mb l mc md">coun_vect = CountVectorizer(binary=True)</span><span id="dcb9" class="ly lz iq lu b gy mg mb l mc md">count_matrix = coun_vect.fit_transform(text)</span><span id="5757" class="ly lz iq lu b gy mg mb l mc md">count_array = count_matrix.toarray()</span><span id="c1c6" class="ly lz iq lu b gy mg mb l mc md">df = pd.DataFrame(data=count_array,columns = coun_vect.get_feature_names())</span><span id="24b7" class="ly lz iq lu b gy mg mb l mc md">print(df)</span></pre><p id="9444" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">尽管所有的单词在上面的输入中出现了两次，我们的稀疏矩阵只是用1来表示它</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/a5422f336aea6fa113cb0e17dad6e84b.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*tMKDp2MgT7hks6AQH2t_1A.png"/></div></figure><p id="3a79" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">现在让我们看看我们是否使用了默认值:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/38de8fdcd3a7c8c33b298b7a487db13e.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*Ya_j_zZG9u6aDTe3HPCwPw.png"/></div></figure><ul class=""><li id="92e3" class="mz na iq kz b la lb ld le lg nm lk nn lo no ls ng nh ni nj bi translated"><strong class="kz ir">词汇</strong></li></ul><p id="34aa" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">它们是稀疏矩阵中单词的集合。</p><pre class="kh ki kj kk gt lt lu lv lw aw lx bi"><span id="6ada" class="ly lz iq lu b gy ma mb l mc md">text = [‘hello my name is james’,</span><span id="8b2e" class="ly lz iq lu b gy mg mb l mc md">‘Hello my name is James’]</span><span id="870d" class="ly lz iq lu b gy mg mb l mc md">coun_vect = CountVectorizer()</span><span id="ffc2" class="ly lz iq lu b gy mg mb l mc md">count_matrix = coun_vect.fit_transform(text)</span><span id="0044" class="ly lz iq lu b gy mg mb l mc md">print(coun_vect.vocabulary_)</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/cb7fa7ec2f1546f1074f0807bf35112b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*MMIFG9TIjA9NNQCAdQe1VQ.png"/></div></figure><p id="6ed0" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这些数字不代表单词的数量，而是代表单词在矩阵中的位置</p><p id="94b8" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如果你只是想要没有单词在稀疏矩阵中的位置的词汇表，你可以使用' get_feature_names()'方法。如果您注意到这是我们在创建数据库和设置列时使用的相同方法。</p><pre class="kh ki kj kk gt lt lu lv lw aw lx bi"><span id="0ae4" class="ly lz iq lu b gy ma mb l mc md">text = [‘Hello my name is james’,</span><span id="9425" class="ly lz iq lu b gy mg mb l mc md">‘james this is my python notebook’,</span><span id="d22e" class="ly lz iq lu b gy mg mb l mc md">‘james trying to create a big dataset’]<br/></span><span id="e5f5" class="ly lz iq lu b gy mg mb l mc md">coun_vect = CountVectorizer()</span><span id="8fcc" class="ly lz iq lu b gy mg mb l mc md">count_matrix = coun_vect.fit_transform(text)<br/></span><span id="cd99" class="ly lz iq lu b gy mg mb l mc md">print( coun_vect.get_feature_names())</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nz"><img src="../Images/fa40c8cbe6b6ce263b145ba2579ac50c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fiWzNPv0PQoferCf_eXHug.png"/></div></div></figure><p id="9ce4" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">CountVectorizer只是处理文本数据的方法之一。Td-idf是一种更好的数据矢量化方法。我建议你查看一下sklearn的官方文档以了解更多信息。</p><p id="dc9e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">希望这有所帮助:)</p></div></div>    
</body>
</html>