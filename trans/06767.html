<html>
<head>
<title>Using Conditional Deep Convolutional GANs to Generate Custom Faces from Text Descriptions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用条件深度卷积GANs从文本描述生成自定义人脸</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-conditional-deep-convolutional-gans-to-generate-custom-faces-from-text-descriptions-e18cc7b8821?source=collection_archive---------23-----------------------#2021-06-18">https://towardsdatascience.com/using-conditional-deep-convolutional-gans-to-generate-custom-faces-from-text-descriptions-e18cc7b8821?source=collection_archive---------23-----------------------#2021-06-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="e8be" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本项目代码见:<a class="ae kp" href="https://github.com/evanhu1/pytorch-CelebA-faCeGAN" rel="noopener ugc nofollow" target="_blank"><em class="ko">【https://github.com/evanhu1/pytorch-CelebA-faCeGAN】</em></a></p><p id="518a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">GANs(生成对抗网络)是无监督学习模型的一个子集，它利用两个网络以及对抗训练来输出与输入数据相似的“新”数据。更具体地说，GANs通常涉及“捕获数据分布的生成模型G，以及估计样本来自训练数据而不是G [1]的概率的判别模型D。”</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div class="gh gi kq"><img src="../Images/4d881f26bac80ce9f7f2df6b3cbcc7bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*fWJjR-nURSTNrg1etd-e_A.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">生成性对抗网络。<a class="ae kp" href="https://developers.google.com/machine-learning/gan/gan_structure" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="cf27" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">条件甘是原始甘模型的修改，后来由Mehdi Mirza和Simon Osindero在论文“<a class="ae kp" href="https://arxiv.org/abs/1411.1784" rel="noopener ugc nofollow" target="_blank">条件生成对抗网络</a>”(2014)中提出。在cGAN(条件GAN)中，鉴别器被给予数据/标签对，而不仅仅是数据，并且除了噪声向量之外，生成器还被给予标签，指示图像应该属于哪个类。标签的添加迫使生成器学习不同训练数据类的多种表示，允许显式控制生成器的输出的能力。在训练模型时，标签通常与生成器和鉴别器的数据样本相结合。实现这一点的代码将在下面给出。</p><p id="31f2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在本文中，我将描述PyTorch中条件深度卷积GAN的实现，它使用英文文本而不是单个数字作为标签。我们的模型是深度卷积GAN (DCGAN)，也就是说，它在其架构中使用深度卷积层，而不是原始论文中的全连接层。我们将在名人面孔的数据集上进行训练，图像被裁剪为64x64。我们的模型架构包含五个卷积/转置卷积层，具有批量归一化和泄漏ReLU激活，以及用于鉴别器输出层的sigmoid激活和用于发生器输出层的tanh激活。使用Adam优化器和二元交叉熵损失。</p><p id="66d0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">参数和数据清理步骤由关于GAN训练的“传统智慧”指导，从诸如<a class="ae kp" href="https://github.com/soumith/ganhacks" rel="noopener ugc nofollow" target="_blank"> GANHacks </a>和原始论文等来源收集。这些包括Adam优化器的学习率为0.0002 (beta 0.5)，步进卷积而不是向下/向上采样，使用高斯分布的自定义权重初始化(平均值为0.0，标准差为0.02)，以及将真实图像从[0，1]缩放到[-1，1]以匹配伪图像中的tanh输出。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi lc"><img src="../Images/7179f4106b68553099d85c40b530b29c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9Y1ZnEUt2xb9mbfP"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">发生器模型的架构——鉴别器模型几乎完全相同，只是输入/输出维度和简单卷积层有所不同，而不是转置层。作者图片</p></figure><p id="13a4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在确定了设计之后，我们用PyTorch编写了我们的模型。</p><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="lh li l"/></div></figure><p id="ff2c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">至于数据集，CelebA为每张图像提供了40个二进制属性注释，如下例所示。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi lj"><img src="../Images/957be3e917599b66116c945172dc949f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*s9nhMoHZoT56StKa.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><a class="ae kp" href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="5ba1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用这些二元属性作为我们的标签或条件，我们可以训练我们的cGAN生成具有我们控制的特定特征的人脸。此外，我们可以选择多个属性进行训练和学习，只需将它们连接起来形成多维标签。给定足够的属性，我们可以生成具有不同人类特征的各种各样的人脸。例如，我们的初步训练结果显示，该模型可以学习二元属性，[男性，年轻]，允许我们生成4种不同的面部类型组合(年轻男性，“不年轻”男性，年轻女性，“不年轻”女性)</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi lk"><img src="../Images/63c696c88d4a7cc563a7a8a123c49159.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kp3NMzddiuZxyM6lwBkEtA.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者图片</p></figure><p id="fef4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在我们的代码中，我们构建了一个定制的PyTorch数据集，它带有一个参数来指定在总共40个二进制属性中包含哪些属性，因为对所有40个属性进行训练太困难了。</p><p id="83ee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于我们模型的实际输入，我们创建了沿标签轴具有二维的多热点编码张量。具体来说，假设我们在训练中仅使用64x64图像的两个二进制属性，则生成器将接收32x2x1x1(批量大小、标签数量和反卷积层要作用的2个“伪”图像尺寸)的multi-hot编码张量作为每个训练样本的标签。相反，鉴别器将接收32×2×64×64的多热编码张量，根据训练样本的二进制属性填充0和1。</p><p id="9ba5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在训练期间，在每个标签通过卷积/去卷积层之后，使用torch.cat()层将这些标签与数据样本连接在一起。创建标签并将其处理成正确尺寸的代码在训练循环中，该循环基本上与普通的GAN训练循环相同，只是增加了将标签与数据样本一起输入的步骤。</p><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="lh li l"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">鉴别器模型的训练代码</p></figure><p id="a1d4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在Google Collaboratory GPUs上，每个时期的训练时间约为30分钟，平均到第5个时期时产生了有趣的结果。我们尝试稳步增加训练数据中用于描述面部的属性数量，希望了解cGAN能够学习多少。</p><p id="0648" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">每个图像有5个二进制属性:</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi ll"><img src="../Images/de5253b884303d8704a04033903e251b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jbi6WG0YYJwjB_nDo_AXlQ.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者图片</p></figure><p id="baab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">10个属性:</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi lm"><img src="../Images/fc01bf3643dd37c909677f57cc8cd388.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YdZUHHRdPDMEKBQ06LFmeA.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">['秃头'，'黑发'，'金发'，'棕发'，'灰发'，'男性'，'无胡须'，'后退_发际线'，'直发'，'波浪发']。作者图片</p></figure><p id="bde2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">正如您可能看到的，随着属性数量的增加，结果会受到影响。考虑到我们有限的计算资源和时间，我们没有超过10个属性，但看看它能走多远，以及一个足够大的模型是否能学习celebA的所有40个二进制属性将会很有趣。</p><p id="a0a6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">作为额外的工作，我们还在celebA数据样本上使用旋转变换进行实验，看看cGAN是否不仅可以学习二进制属性，还可以学习旋转等增强。从论文<a class="ae kp" href="https://arxiv.org/abs/1803.07728" rel="noopener ugc nofollow" target="_blank">通过预测图像旋转的无监督表示学习</a>中获得灵感，我们生成了旋转90、180和270度的样本用于训练。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi ln"><img src="../Images/9dc052cbeae46341298241a3adbc2bd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IsRC9X5NQNJi47llU_Bpag.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者图片</p></figure><p id="ef33" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">结果表明，令人惊讶的是，cGAN模型确实能够学习面部属性以及图像增强。</p><p id="3cd5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">总之，这是对GANs从数据中学习的明确能力以及cGANs令人印象深刻的灵活性的引人入胜的观察。我们希望你会觉得有趣，就像我们一样。</p></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><p id="2357" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">承认</p><p id="9b07" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这个项目是与来自伯克利<a class="ae kp" href="https://ml.berkeley.edu/" rel="noopener ugc nofollow" target="_blank">机器学习</a>的<a class="ae kp" href="https://www.linkedin.com/in/jake-austin-371770199/" rel="noopener ugc nofollow" target="_blank">杰克·奥斯丁</a>、<a class="ae kp" href="https://www.linkedin.com/in/aryan-jain-9101/" rel="noopener ugc nofollow" target="_blank">雅利安·贾恩</a>和<a class="ae kp" href="https://www.linkedin.com/in/brian-liu-9b302816b/" rel="noopener ugc nofollow" target="_blank">布莱恩·刘</a>共同合作的成果。</p></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><p id="0913" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">参考</p><p id="fd19" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">[1]生成性对抗网络:<a class="ae kp" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1406.2661</a></p></div></div>    
</body>
</html>