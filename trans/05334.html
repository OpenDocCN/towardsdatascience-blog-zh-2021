<html>
<head>
<title>Basic Text to Speech, Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基本文本到语音转换，已解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/text-to-speech-explained-from-basic-498119aa38b5?source=collection_archive---------13-----------------------#2021-05-11">https://towardsdatascience.com/text-to-speech-explained-from-basic-498119aa38b5?source=collection_archive---------13-----------------------#2021-05-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="48dc" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解Alexa、Siri和其他聊天机器人中使用的文本到语音转换技术。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/cfdd07681e162ea78feaebcd1c8a9390.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*S3Anyc-8_unK_O-B"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ky" href="https://unsplash.com/@findawayvoices?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Findaway Voices </a>拍摄</p></figure><p id="b189" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">顾名思义，在这个博客中，我们将学习文本到语音(TTS)合成。当你听文本到语音转换时，你脑海中响起的第一个铃声是什么？对我来说，它是Alexa、Google Home、Siri和许多其他目前呈指数增长的对话机器人。深度学习研究的进展帮助我们生成了类似人类的声音，所以让我们看看如何利用这一点。我将从几个定义开始，但是如果你想了解更多，那么先阅读<a class="ae ky" href="https://medium.com/@AnveeNaik/all-you-need-to-know-to-start-speech-processing-with-deep-learning-102c916edf62" rel="noopener">这篇</a>博客。</p><p id="4761" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">音位</strong>:音位是使一个单词的发音和意义不同于另一个单词的最小声音单位。</p><p id="c734" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">韵律:诗歌中使用的节奏和声音模式。</p><p id="1f19" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> Mel-spectrogram: </strong>通过对音频的短时傅立叶变换(STFT)的频率轴进行非线性变换，降低维数而得到的<strong class="lb iu"> </strong>。它强调对区分语音非常重要的低频细节，而不强调通常是噪声的高频细节。</p><p id="57c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我强烈建议您在继续之前阅读这篇<a class="ae ky" href="https://medium.com/@AnveeNaik/all-you-need-to-know-to-start-speech-processing-with-deep-learning-102c916edf62" rel="noopener">文章</a>，因为在这里我已经详细解释了上述术语和音频的其他基础知识。现在，让我们了解深度学习算法用于设计TTS系统的基本结构。</p><h1 id="debc" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">文本到语音(TTS)结构</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mn"><img src="../Images/b33797f72fc73d16093125ae8b0b0972.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MaatR_a4XTOee7bifTX6rg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">整体设计(图片由作者提供)</p></figure><p id="1385" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是TTS系统中使用的不同组件的高级示意图。我们模型的输入是文本，它经过几个模块，最终被转换成音频。让我们了解一下这些模块对流程的贡献。</p><p id="93a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">预处理器</strong></p><ul class=""><li id="be46" class="mo mp it lb b lc ld lf lg li mq lm mr lq ms lu mt mu mv mw bi translated"><strong class="lb iu">分词</strong>:将句子分词</li><li id="9c74" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu mt mu mv mw bi translated"><strong class="lb iu">音素/发音</strong>:它根据音素的发音将输入文本分解成音素。例如，“你好，祝你愉快”转换为HH AH0 L OW1，HH AE1 V AH0 G UH1 D D EY1。</li><li id="1f41" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu mt mu mv mw bi translated"><strong class="lb iu">音素时长:</strong>表示音频中每个音素所用的总时间。</li><li id="1c67" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu mt mu mv mw bi translated"><strong class="lb iu">音高:</strong>传达情感的关键特征，它极大地影响着语音的韵律。</li><li id="e9a8" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu mt mu mv mw bi translated"><strong class="lb iu">能量:</strong>表示mel频谱图的帧级幅度，直接影响语音的音量和韵律。</li></ul><p id="01d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">语言特征只包含音素。能量、音调和持续时间实际上分别用于训练能量预测器、音调预测器和持续时间预测器，模型使用它们来获得更自然的输出。</p><p id="cc8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">编码器</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/60096d03def38c19471c48fe6b420b2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*4BstJxNACcaIXFMnV73d5A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">编码器(图片由作者提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/6d50da5f5f5dd01609fa06245ed9d2d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a3vQcPHfbhRR0GfwaWz7Yg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">其他处理(图片由作者提供)</p></figure><p id="a98e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">编码器输入语言特征(音素)并输出n维嵌入。编码器和解码器之间的这种嵌入被称为潜在特征。潜在特征是至关重要的，因为像说话人嵌入(将在未来的博客中解释)等其他特征与这些特征连接在一起，并传递给解码器。此外，潜在特征还用于预测能量、音调和持续时间，这反过来在控制音频的自然度方面起着至关重要的作用。</p><p id="f6a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">解码器</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/bca404e79b99121c2d3bc493bd2608aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*FiJZ-GbN8QUXZZY-et4MuQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">解码器(作者图片)</p></figure><p id="3429" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">解码器用于将嵌入在潜在处理特征中的信息转换成声学特征，即Mel频谱图。</p><p id="3f50" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是为什么输出mel频谱图而不是直接从解码器产生语音/音频呢？</p><p id="33bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是因为音频包含比Mel频谱图更多的变化信息(例如，相位)。与文本到语谱图生成相比，这导致文本到音频的输入和输出之间的信息差距更大。因此，Mel光谱图是优选的。</p><p id="bc81" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">声码器</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/c48fd8c4b55b932bd847ce2ce9bd9d43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*xbEQCEogbBOVTKBPYwqy_g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">声码器(作者图片)</p></figure><p id="9388" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它将声学特征(Mel声谱图)转换为波形输出(音频)。这可以使用Griffin Lim这样的数学模型来完成，或者我们也可以训练一个神经网络来学习从mel频谱图到波形的映射。事实上，基于学习的方法通常优于Griffin Lim方法。</p><p id="c00a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我们没有使用解码器直接预测波形，而是将这一复杂而复杂的任务分为两个阶段，首先从潜在的处理特征预测mel-spectrogram，然后使用mel-spectrogram生成音频。</p><p id="3daf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，您已经熟悉了TTS系统中使用的所有基本组件。我们可以得出结论，你已经准备好阅读和学习像Fastspeech、Tacotron、WaveNet等复杂的研究论文。为了感受一下TTS的实际表现，请点击这里查看一些音频样本<a class="ae ky" href="https://speechresearch.github.io/fastspeech2/" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="1886" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让你看看下一篇博客包含了什么，我们知道如何从文本中生成特定说话者的音频，但是我们如何为一段文本生成不同说话者的音频呢？我们不能只转储与模型架构的当前设置中的所有说话者相关的数据，因为模型会与这种一对多映射(一个文本到多个说话者的映射)混淆。这将导致模型产生在扬声器之间平均的音频，这将不是清晰可闻或可理解的。</p><p id="88aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ng">成为</em> <a class="ae ky" href="https://medium.com/@AnveeNaik/membership" rel="noopener"> <em class="ng">介质会员</em> </a> <em class="ng">解锁并阅读介质上的许多其他故事。关注我们的</em><a class="ae ky" href="https://medium.com/@AnveeNaik" rel="noopener"><em class="ng">Medium</em></a><em class="ng">，阅读更多此类博文</em>。</p></div></div>    
</body>
</html>