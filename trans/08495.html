<html>
<head>
<title>An Introduction to Polynomial Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多项式回归导论</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-introduction-to-polynomial-regression-9aa6a8c0ce95?source=collection_archive---------15-----------------------#2021-08-05">https://towardsdatascience.com/an-introduction-to-polynomial-regression-9aa6a8c0ce95?source=collection_archive---------15-----------------------#2021-08-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="775f" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="0c7b" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">R语言中的数值例子及实现</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/26035d8f4ba69cf027f9ae428feef405.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cesm2PE95RsXkLB_hmmDlw.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片来自<a class="ae lh" href="https://www.pexels.com/cs-cz/foto/umeni-vzor-abstraktni-barevny-310452/" rel="noopener ugc nofollow" target="_blank">像素</a></p></figure><p id="6f8d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在介绍多项式回归之前，我们需要有一个概念，线性回归是做什么的。线性回归的主要思想是<strong class="lk jd">利用基函数的线性组合建立模型</strong>。为了引入这个概念，有一个问题需要回答。</p><p id="db13" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">「线性组合」是什么意思？它是几个项的组合，通过标量进行加法和乘法，形式如下</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/afad3dabf972aabdd52fc8e987b30ab8.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*NDRImlCs-mFOp73aN-eGOw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">线性组合的定义。作者图片</p></figure><p id="e477" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其中a₁、a₂,…是标量，x₁、x₂,…是项，或者用线性代数的语言来说，是向量。无论这些项是什么，模型都与<strong class="lk jd">参数</strong>成线性。</p><p id="6132" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一个<strong class="lk jd">多项式回归</strong>模型可以被认为是<em class="me">几个单项式的线性组合</em>并采取以下形式</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/654109cfeb23b97657eb3f71e466f4de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*3IxbJh1HlV41eVh6rbeo6g.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">多项式回归模型。作者图片</p></figure><h1 id="9962" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">线性回归模型的变异</h1><p id="a896" class="pw-post-body-paragraph li lj it lk b ll mz kd ln lo na kg lq lr nb lt lu lv nc lx ly lz nd mb mc md im bi translated">在线性回归领域，可能会遇到一些变化，有时很容易被看起来相似的术语搞混。</p><p id="e35f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">多元线性回归</strong>:试图用一个线性模型来描述一个因变量与两个或两个以上自变量之间的关系。在本文中，我们将关注多项式回归，它被认为是多元线性回归的一个特例。</p><p id="12e5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">简单线性回归</strong> : <strong class="lk jd"> </strong>也是多元线性回归的特例，只涉及一个自变量。它使用一条直线来模拟数据，这条直线是一次多项式。</p><p id="43c7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">一般多元回归模型</strong>:它是几个多元线性回归同时写在一起的形式</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/76b676c72e5bebee432548db867fa470.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*tVvbNRirB2Sdxn-B-aeT0A.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">一般多元回归模型。作者图片</p></figure><p id="12c2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其中Y是一个n乘p的矩阵，每列有p个因变量，每行有n个个体，X是一个有观测数据的n乘q的已知矩阵，B和U分别表示未知参数和噪声。</p><p id="f17c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">广义线性模型</strong>:应用<strong class="lk jd"> <em class="me"> </em>链接函数<em class="me"> </em> </strong>将因变量分布的参数链接到线性预测器(因变量的线性组合)。与其他线性模型不同，它允许因变量的误差项具有不同于正态分布的分布。</p><p id="faa0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当连接函数为恒等式时，该模型退化为具有正态误差的普通线性模型。</p><h1 id="b2e2" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">拟合数据</h1><p id="2c57" class="pw-post-body-paragraph li lj it lk b ll mz kd ln lo na kg lq lr nb lt lu lv nc lx ly lz nd mb mc md im bi translated">要使用多项式找到合适的模型来拟合数据，需要完成两件事情:</p><ol class=""><li id="c9c6" class="nf ng it lk b ll lm lo lp lr nh lv ni lz nj md nk nl nm nn bi translated">我们需要知道它的<strong class="lk jd">度</strong>是多少。</li><li id="2bda" class="nf ng it lk b ll no lo np lr nq lv nr lz ns md nk nl nm nn bi translated">我们需要找到每个单项的<strong class="lk jd">系数</strong>。</li></ol><h2 id="2237" class="nt mi it bd mj nu nv dn mn nw nx dp mr lr ny nz mt lv oa ob mv lz oc od mx iz bi translated">确定系数</h2><p id="fcab" class="pw-post-body-paragraph li lj it lk b ll mz kd ln lo na kg lq lr nb lt lu lv nc lx ly lz nd mb mc md im bi translated">上面描述的第一个任务实际上更困难，所以我们可以先看看第二个。为了说明线性回归的原理，让我们生成一些带有白噪声的数据</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="007e" class="nt mi it of b gy oj ok l ol om">X &lt;- seq(from=-10, to=10, by=1)<br/>Y &lt;- vector(mode = "double", length = length(X))<br/>lenY &lt;- length(Y)</span><span id="a4c0" class="nt mi it of b gy on ok l ol om"><strong class="of jd">for</strong> (i <strong class="of jd">in</strong> seq(from = 1, to = lenY)){<br/>  noise &lt;- runif(1, min=-1, max=1)[1]<br/>  rangeNoise &lt;- 25<br/>  Y[i] &lt;- X[i]^2 + 2*X[i] + 2 + noise*rangeNoise<br/>}</span><span id="43bf" class="nt mi it of b gy on ok l ol om">df &lt;- data.frame(X, Y)</span></pre><p id="8c20" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当然，拟合该数据的最佳模型是二次多项式。让我们试着拟合数据，看看它是什么样子的。这很简单，这就是我们需要做的</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="0c91" class="nt mi it of b gy oj ok l ol om">model &lt;- lm(Y ~ I(X^2)+ I(X), df)</span></pre><p id="e20d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">事实上，使用<code class="fe oo op oq of b">poly(X, 2)</code>更好，因为它使用正交多项式，可以避免X和X之间的相关性引起的问题。然而，为了比较来自<code class="fe oo op oq of b">lm</code>的结果和来自手动计算的结果，我们仍然使用<code class="fe oo op oq of b">Y ~ I(X^2) + I(X)</code>。</p><p id="62be" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">拟合数据的最佳多项式看起来是这样的(显然，线性模型不一定是一条线，因为它只是一些项的线性组合，项可以是任意的，线性模型看起来可以是任意的。但是它<strong class="lk jd">关于参数是</strong>线性的。)</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi or"><img src="../Images/29a0529eb2e79f8c73e017cc8bdd0fb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*w1-605x5oPhq_CDifc_NgQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">拟合的结果。作者图片</p></figure><p id="2f4a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其中灰色区域描述了<a class="ae lh" href="https://en.wikipedia.org/wiki/Confidence_interval" rel="noopener ugc nofollow" target="_blank">置信区间</a>。</p><p id="1bdf" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe oo op oq of b">lm</code>函数使用了什么方法，我们获得了什么结果，如何解读？让我们用<code class="fe oo op oq of b">summary</code>来看看吧</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/e1e5fc1d2662144641a8be9fca6d4b15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*MY0p5JJboafOR8HCdFyXqg.jpeg"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">线性模型概述</p></figure><p id="0246" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先让我们看一下<code class="fe oo op oq of b">Estimate Std.</code>，那里的数字是我们模型的系数，也就是说得到的多项式是f(x) = 1.0341x + 1.7416x-0.7320。计算系数的方法是最小化成本函数，在这种情况下，成本函数被选择为均方误差函数</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/48628c476f8b2ddf64cc865011973992.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/1*zjlLCmUdT8U0z9SqkDT3TA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">MSE(均方差)函数。作者图片</p></figure><p id="9755" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其中，yᵢ是观测值，yᵢ哈特是预测值。由于yᵢ是单项式x，x，x，…和系数(我也将互换使用“<strong class="lk jd">权重</strong>”)w₁，w₂，…的函数，确定成本函数何时达到最小值给了我们关于x的w的表达式，x-es是已知的，因此我们可以求解系数。这就是<strong class="lk jd">最小二乘法</strong>。</p><p id="a2a6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">系数也可以通过<strong class="lk jd">伪逆</strong>来计算。将输入数据、权重和观察值写入矩阵</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/cc4b107d0492cb832d7181c20487b58b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*V8VoR4cL2LrXw_FaSeHUIQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">输入数据、权重和观察值。作者图片</p></figure><p id="6854" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">预测值将是XW，我们希望XW尽可能接近Y。权重可以通过以下方式获得</p><p id="3038" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，损失函数为</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/6880f75dc334da4fd82559e1312d0769.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*AwmOXzOfVmxpYzTNb6LDFw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">损失函数。作者图片</p></figure><p id="118c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是我们计算重量的方法</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/ccf56232d3f0c9ce92b342e75323f02e.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*SetjWyzTy0LVav8Dsv7Ysw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">使用伪逆计算权重。作者图片</p></figure><p id="987c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在我们要证明这是作为最小二乘法的东西，也就是说我们可以从(2.2)推导出(2.3)。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ox"><img src="../Images/a407546b55a9bbea81e5be3fd055fec7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VAV0s-CLTh86zSUK4WAHKg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">从(2.2) (a)推导出(2.3)。作者图片</p></figure><p id="e389" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后我们对<em class="me"> f </em>对w求导</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oy"><img src="../Images/fc9bc23aa6ab6234462080e066ed7fad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Aa-wiI2b-nrAXvZwb700Jw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">从(2.2) (b)推导出(2.3)。作者图片</p></figure><p id="9c0e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在转置两边乘以(X^T X)的逆后，我们立即得到(2.3)。</p><p id="9c91" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了验证这一点</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="e663" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">存储在<code class="fe oo op oq of b">Wm</code>中的结果对应于使用<code class="fe oo op oq of b">lm</code>找到的系数。(此处<a class="ae lh" href="https://www.theanalysisfactor.com/interpreting-the-intercept-in-a-regression-model/" rel="noopener ugc nofollow" target="_blank">截距</a>为常数)。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="577a" class="nt mi it of b gy oj ok l ol om">[,1]<br/>X^2  1.0340966<br/>X    1.7415511<br/>1   -0.7320286</span></pre><h2 id="c939" class="nt mi it bd mj nu nv dn mn nw nx dp mr lr ny nz mt lv oa ob mv lz oc od mx iz bi translated">拟合误差及评价</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/2d616ea88dc91d98ee963fca29a677eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*tyhR47ABZhjshDO7YToiWg.jpeg"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">线性模型概述。作者图片</p></figure><p id="b631" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe oo op oq of b">Std. Error</code>是<strong class="lk jd">标准</strong> <strong class="lk jd">误差的估计参数</strong>。由于我们拥有的数据是来自总体的样本，因此整个总体的最优回归模型可能在一个范围内——我们获得的最优解是<strong class="lk jd">而不是</strong>(对于样本来说，它是最好的，但是对于整个总体来说，基本关系可能有点不同)。在统计学中，重要的是要知道，我们谈论的是什么数据，整个人口，还是只有样本数据。这些误差用于计算距离。那我们如何计算这些误差呢？</p><p id="0e1d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在表格中填写我们的模型</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/8703af7249b3b6dfb903fc6c4e4732a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*pi4YNBUOmZ04ICsbzO7Z1Q.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">我们例子中的线性模型。作者图片</p></figure><p id="013d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这意味着</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/383ffb81e76320c523b5efee303e73b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*c95nJKdp4wd7GlDRk8P_fA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">。作者图片</p></figure><p id="2b54" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其中εᵢ是误差项，它是观测值和预测值之间的差值。</p><p id="3d72" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">根据<a class="ae lh" href="https://people.duke.edu/~rnau/mathreg.htm#slopeintercept" rel="noopener ugc nofollow" target="_blank">这个</a>，我们可以通过以下方式计算系数</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/aefe9db6a984173d06134002f8572d4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*zBdv2EmmQkF1LhN9KiRKyw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">估计系数误差的计算公式。作者图片</p></figure><p id="cd8c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其中，变量上的帽子表示它们是估计值，σ(X)是X的标准差，X_hat是X的平均值。<a class="ae lh" href="https://www.investopedia.com/terms/d/degrees-of-freedom.asp\" rel="noopener ugc nofollow" target="_blank">自由度</a>是<em class="me"> n-3 </em>(在本例中，n-3 = 21–3 = 18，我们在样本中有21个点)。s就是<code class="fe oo op oq of b">Residual standard error</code>，这里s = 15.11。</p><p id="3caa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在<a class="ae lh" href="https://people.duke.edu/~rnau/mathreg.htm#slopeintercept" rel="noopener ugc nofollow" target="_blank">这个源</a>中，符号似乎不是很常见和清晰，所以也参考了<a class="ae lh" href="https://en.wikipedia.org/wiki/Simple_linear_regression#:~:text=is%20the%20standard%20error%20of%20the%20estimator" rel="noopener ugc nofollow" target="_blank">维基百科</a>。在这两个来源中，仅给出了最简单模型(a线Y = aX + b)的公式，但是可以推导出我们的二次示例的公式。但是当然，鼓励读者尝试实现它们，并用一些数据验证它们。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/a7d21da30d3a1f5f09f30f8babab7740.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*CG51Mn04L-JTPsCmsJrwDw.jpeg"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">线性模型概述。作者图片</p></figure><p id="fb0f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe oo op oq of b">Coefficients</code>中的最后两列告诉我们模型中的一个组件是否重要。方法是计算一个t统计量，即<code class="fe oo op oq of b">t value</code>。然后我们计算p值，即<code class="fe oo op oq of b">Pr(&gt;|t|)</code>，这是反对零假设的证据(H₀: <em class="me">模型中的成分在统计上不显著</em>，我们在模型中不需要它)。如果p值足够小，我们可以拒绝零假设(值得注意的是，我们不能<strong class="lk jd">永远</strong>接受零假设，因为我们只有证据<strong class="lk jd">反对</strong>它)。</p><p id="5774" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">以x项为例，x的系数为w₁，t值为w₁</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/a0ff74636a78550c1297c3b0e92cae72.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*T41fCrLq8EYweQZgN0LxvA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">t值。作者图片</p></figure><p id="dcd1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">t遵循学生的t分布，自由度为n-3。在这个例子的情况下，t值简单地通过系数/标准误差来计算。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/0670d8fb4fe3e7404a68c342c05833b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*tZNaB4cAP9qhbyH_JQr-GA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">函数lm中t值是如何计算的？作者图片</p></figure><p id="0bae" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">而结果是<code class="fe oo op oq of b">3.197</code>。为了找到p值，我们需要参考<a class="ae lh" href="https://www.sjsu.edu/faculty/gerstman/StatPrimer/t-table.pdf" rel="noopener ugc nofollow" target="_blank">学生t分布临界值表</a>。我们可以看到我们的t值在2.878到3.610之间。所以累积概率在0.002和0.01之间——结果是<code class="fe oo op oq of b">0.00499</code>。总体中基本关系式(2.4)中参数的区间可由下式确定</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/31fe46d47475f21cd76296e4187cb240.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/1*vdBdVpbQ1llhvzHaL0eF-A.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">总体参数的区间。作者图片</p></figure><p id="c233" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其中t*ₙ₋₃是tₙ₋₃分布的第(1-α/2)分位数，这个值也可以在<a class="ae lh" href="https://www.sjsu.edu/faculty/gerstman/StatPrimer/t-table.pdf" rel="noopener ugc nofollow" target="_blank">这个表</a>中找到。默认情况下，α = 0.05，置信区间为1-α=0.95。如果p值小于α，我们可以拒绝零假设。因此，X项在我们的例子中很重要。</p><p id="d5b3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这个预测将在最后一节讨论。在R中非常方便，我们只需要应用函数<code class="fe oo op oq of b">predict</code>。</p><h1 id="f922" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">比较和选择模型</h1><p id="7f92" class="pw-post-body-paragraph li lj it lk b ll mz kd ln lo na kg lq lr nb lt lu lv nc lx ly lz nd mb mc md im bi translated">这里我们回到第一个任务，我们要用什么样的线性模型？线性组合的项应该是什么？</p><p id="60ac" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当使用多元线性回归时，我们经常需要减少因变量的数量，因为<strong class="lk jd">如果一个更复杂的模型并不比一个更简单的模型好多少，我们应该使用更简单的模型</strong>。对于一个非常复杂的模型，我们可能会获得高性能，但它也更加难以解释。有时过度拟合也会发生。有几种简化的方法，例如，<a class="ae lh" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank">主成分分析</a>就是一个有用的工具。</p><p id="c5b6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于这里我们只处理多项式，PCA不是很合适，<strong class="lk jd">逐步回归</strong>将是一个更好的方法，我们可以应用它来降低模型的阶数。但是减少多项式模型的次数的任务类似于减少任何多变量线性回归模型中的独立变量的数量。对于多项式回归模型，次数越高，多项式就能更好地拟合数据，但同时会包含更多的噪声，这将导致非常差的预测(过度拟合)。</p><p id="d012" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以对我们的数据使用一个5次多项式，当然这不是必须的，它也不利于预测。如果我们检查这个模型的摘要，我们会发现组件具有较大的p值—它们在统计上不显著。以下代码可用于进行逐步回归(需要库<code class="fe oo op oq of b">MASS</code>)</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="5aa5" class="nt mi it of b gy oj ok l ol om">fullModel &lt;- lm(Y ~ I(X^5) + I(X^4) + I(X^3) + I(X^2) + I(X) + 1, df)<br/>stepModel &lt;- stepAIC(fullModel, direction = "backward", trace = FALSE)<br/>summary(stepModel)</span></pre><p id="307b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正如我们已经知道的，结果<code class="fe oo op oq of b">stepModel</code>是一个二次多项式。</p><h1 id="7126" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">什么时候应该使用多项式回归，什么时候不应该？</h1><p id="7339" class="pw-post-body-paragraph li lj it lk b ll mz kd ln lo na kg lq lr nb lt lu lv nc lx ly lz nd mb mc md im bi translated">1.速度和距离</p><p id="2270" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用的例子将是R中的内置数据集<code class="fe oo op oq of b">car</code>，它记录了汽车的速度和停车时所经过的距离。多项式回归在这里是合适的。事实上，根据我们的物理知识，这是正确的答案。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/d057dcd3ca8237129fdf4c1b00b034a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*vGVUz7BsGgagAJwOoIdBqQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图3.1速度和距离。使用此处的<a class="ae lh" href="http://sia.webpopix.org/polynomialRegression1.html" rel="noopener ugc nofollow" target="_blank">代码制作的图像。</a></p></figure><p id="449f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将数据分为训练集和测试集，并用测试数据绘制线性模型。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pi"><img src="../Images/1035df6b97fd40019d29f0cc9253da03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fk57yswmZqiR_FmwGz0zNw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图3.2拟合(75%随机选择的训练数据)和预测。作者图片</p></figure><p id="40f5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果我们运行一个<a class="ae lh" href="https://en.wikipedia.org/wiki/Coefficient_of_determination#:~:text=%22r%20squared%22%2C%20is%20the%20proportion%20of%20the%20variation%20in%20the%20dependent%20variable" rel="noopener ugc nofollow" target="_blank"> R测试</a>，它会告诉我们这个模型解释了测试集中80.089%的数据可变性。</p><p id="3e2f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">2.油价</p><p id="9e13" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里是我们不应该使用线性回归的时候。假设我们想根据历史数据预测油价(数据来源:【https://finance.yahoo.com/quote/OIL/history?p=OIL】<a class="ae lh" href="https://finance.yahoo.com/quote/OIL/history?p=OIL" rel="noopener ugc nofollow" target="_blank">)。</a></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/ff693aefc9107d57766c61be02f7b610.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*BZ_LVwaBMsTUXrFPB_qwng.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图3.3一年的每日油价。作者图片</p></figure><p id="a39f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们用了一个三次多项式，这个图看起来不错。(<code class="fe oo op oq of b">index</code>为天数指数，<code class="fe oo op oq of b">CloseP</code>为每天收盘价)。但在测试数据上，这似乎并不可信</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pk"><img src="../Images/2a57d7439b6ee483acc4c803a5039750.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nUwwtpM50Jntmeiu4PDIbQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图3.4拟合(从数据集开始的75%的数据)，和预测。作者图片</p></figure><p id="90f9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">事实上，在这个例子中，它永远不会工作，因为如果我们使用一个偶数阶的多项式，当指数变大时，曲线将上升，奇数阶的曲线将下降。但是很明显，这不是商品价格的变化方式。</p><p id="9b28" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为什么比第一个例子差那么多？图3.1看起来没有图3.3那么混乱和嘈杂。然而，在图3.1中有一个时间序列，距离与速度之间的关系和油价与时间之间的关系是完全不同的故事。更多的因素使价格变化变得复杂，例如，时滞、周期性等。</p><h1 id="ac64" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">摘要</h1><p id="1a5b" class="pw-post-body-paragraph li lj it lk b ll mz kd ln lo na kg lq lr nb lt lu lv nc lx ly lz nd mb mc md im bi translated">本文试图介绍多项式回归，并把它与一元线性回归和多元线性回归联系起来。它还简要描述了什么是线性回归和有什么变化。</p><p id="8b83" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在关注多项式回归的部分，首先，我们知道如何拟合数据和如何确定系数(使用R中的内置函数实现，但也可以手动实现)。然后介绍了模型和评估中的误差，主要是t值和p值的计算。此外，对统计推断也作了简要介绍。</p><p id="4701" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最后，我们看了两个例子，多项式回归模型分别适用和不适用。</p></div><div class="ab cl pl pm hx pn" role="separator"><span class="po bw bk pp pq pr"/><span class="po bw bk pp pq pr"/><span class="po bw bk pp pq"/></div><div class="im in io ip iq"><h2 id="98cf" class="nt mi it bd mj nu nv dn mn nw nx dp mr lr ny nz mt lv oa ob mv lz oc od mx iz bi translated">资源</h2><p id="b6cd" class="pw-post-body-paragraph li lj it lk b ll mz kd ln lo na kg lq lr nb lt lu lv nc lx ly lz nd mb mc md im bi translated">[1] <a class="ae lh" href="https://ncatlab.org/nlab/show/linear+combination" rel="noopener ugc nofollow" target="_blank">线性组合</a> (2015)，<em class="me"> nLab </em>。</p><p id="6d18" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[2]米歇尔·莱西<em class="me">，</em>，<a class="ae lh" href="http://www.stat.yale.edu/Courses/1997-98/101/linmult.htm" rel="noopener ugc nofollow" target="_blank">多元线性回归</a></p><p id="f9e4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[3]肯特，J. T .，毕比，j .，&amp;马迪亚，K. V. <a class="ae lh" href="https://statisticalsupportandresearch.files.wordpress.com/2017/06/k-v-mardia-j-t-kent-j-m-bibby-multivariate-analysis-probability-and-mathematical-statistics-academic-press-inc-1979.pdf" rel="noopener ugc nofollow" target="_blank">多变量分析</a> (1979)。<em class="me">阿姆斯特丹:学术出版社</em>。</p><p id="545c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[4]内尔德，J. A .，，威德伯恩，R. W . <a class="ae lh" href="https://docs.ufpr.br/~taconeli/CE225/Artigo.pdf" rel="noopener ugc nofollow" target="_blank">广义线性模型</a> (1972)。<em class="me">英国皇家统计学会杂志:A辑(总论)</em>，<em class="me"> 135 </em> (3)，370–384。</p><p id="42f0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[5] Jonathan Bartlett，<a class="ae lh" href="https://thestatsgeek.com/author/jwb133googlemail-com/" rel="noopener ugc nofollow" target="_blank">线性回归的假设</a> (2013)</p><p id="7ea0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[6] Alboukadel Kassambara，<a class="ae lh" href="http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/154-stepwise-regression-essentials-in-r/#comments-list" rel="noopener ugc nofollow" target="_blank">R</a>中的逐步回归要点(2018)</p></div></div>    
</body>
</html>