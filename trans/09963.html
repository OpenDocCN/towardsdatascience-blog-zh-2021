<html>
<head>
<title>How to Create a Real-Time Face Detector</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何创建实时人脸检测器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-create-real-time-face-detector-ff0e1f81925f?source=collection_archive---------1-----------------------#2021-09-20">https://towardsdatascience.com/how-to-create-real-time-face-detector-ff0e1f81925f?source=collection_archive---------1-----------------------#2021-09-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5c42" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Python、TensorFlow/Keras和OpenCV</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/673c86156149682ea4c206cab0b9c082.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*vFOtMEpY3NWFA9PFSlAPiw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">实时人脸检测器。不是我——照片由<a class="ae ky" href="https://www.pexels.com/@simon-robben-55958?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">西蒙·罗本</a>从<a class="ae ky" href="https://www.pexels.com/photo/man-in-brown-polo-shirt-614810/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">派克斯</a>拍摄</p></figure><p id="7682" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我将向您展示如何使用Python、TensorFlow/Keras和OpenCV编写实时人脸检测器。</p><p id="7b27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我马上会注意到，所有代码文件都可以在<a class="ae ky" href="https://gitlab.com/Winston-90/me_not_me_detector/" rel="noopener ugc nofollow" target="_blank">这个repo </a>中获得。</p><div class="lv lw gp gr lx ly"><a href="https://gitlab.com/Winston-90/me_not_me_detector/" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">dmy tro Nikolai ev/me _ not _ me _ detector</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">用Python，TensorFlow/Keras和OpenCV实现实时人脸检测</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">gitlab.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div><p id="7637" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，在<strong class="lb iu">理论部分</strong>我会告诉你一些对我们有用的概念(<em class="mn">迁移学习</em>和<em class="mn">数据扩充</em>)，然后我会在<strong class="lb iu">实践部分</strong>部分进行代码分析。</p><p id="b5b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意，您必须安装<em class="mn"> TensorFlow </em>和<em class="mn"> OpenCV </em>库来运行这段代码。你可以手动完成，或者在你下载了repo之后简单地运行<code class="fe mo mp mq mr b">pip install -r requirements.txt </code>命令。你也可以用conda命令<code class="fe mo mp mq mr b">conda install -c conda-forge numpy, opencv, tensorflow</code> <strong class="lb iu"> <em class="mn">来完成。</em> </strong></p><h1 id="6a96" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">问题陈述</h1><p id="0396" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">在这里，我想建立一个面部检测器，也可以区分我和其他人。你可以在本文末尾看到我的工作成果。</p><p id="1a3f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">初始任务可以分为两个子任务:</p><ol class=""><li id="8ac5" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu nu nv nw nx bi translated">为人脸分类训练一个模型。</li><li id="7b56" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">调整模型，使其与作为检测器的网络摄像头一起工作。</li></ol><p id="78bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更详细地说，该任务可以分为以下几个阶段:</p><ol class=""><li id="1a5f" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu nu nv nw nx bi translated">数据集集合。</li><li id="123e" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">寻找迁移学习的基础模型。</li><li id="585a" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">训练一个模特。</li><li id="2a3a" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">将分类器转换为检测器。</li></ol><p id="a443" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我开始分析这些阶段之前，我想非常简要地概述一下对我们有用的概念。</p><h1 id="6315" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">理论部分</h1><p id="e21c" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">在这一点上，我必须说，这个教程是不详细的，因为它可以。例如，我不会解释什么是<em class="mn">卷积</em>或者为什么在CNN架构中需要<em class="mn">池层</em>。当然，你需要知道这些才能理解CNN是如何工作的，但我认为如果我解释所有的概念，这个教程会太繁琐。另一方面，其他人已经解释了很多东西，而且做得比我好。例如，<a class="ae ky" rel="noopener" target="_blank" href="/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">在这里你可以读到CNN的概况</a>，而<a class="ae ky" href="https://www.jeremyjordan.me/convnet-architectures/" rel="noopener ugc nofollow" target="_blank">在这里——关于流行的CNN架构</a>。</p><h2 id="c6ed" class="od mt it bd mu oe of dn my og oh dp nc li oi oj ne lm ok ol ng lq om on ni oo bi translated">卷积神经网络</h2><p id="e74b" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">由于我们正在讨论图像识别，我们将使用<em class="mn"> CNN —卷积神经网络</em>，这种架构在这项任务中取得了最大的成功。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/fff293357945e7f1d58d1fca7db08cbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3BRLw4lsANPEfGgimG3YVQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="oq">典型的卷积神经网络架构。</em> <a class="ae ky" href="https://en.wikipedia.org/wiki/File:Typical_cnn.png" rel="noopener ugc nofollow" target="_blank">公共领域</a></p></figure><p id="7fdc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与经典神经网络(这里我指的是<em class="mn">FDN——前馈神经网络</em>)不同，在CNN中，神经元是:</p><ul class=""><li id="2fae" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu or nv nw nx bi translated">首先:以矩阵(张量)的形式排列，而不是数组，</li><li id="3939" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu or nv nw nx bi translated">其次:它们只与前一层的一小部分神经元相连，因此层之间并不完全相连。</li></ul><p id="268e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法允许您显著减少网络参数的数量，并使图像的模板搜索更有效。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/ef8a7eed276d3bddb0c10c8375222d70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DMlNByTBpqywI7rE8DwzOw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="oq">前馈神经网络vs卷积神经网络</em>。作者图片</p></figure><p id="ebcf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这张图的底部，我想说明一下，CNN中的层是一个<em class="mn">张量</em>(经常被画成平行六面体)。我将把张量作为矩阵序列来讲。所以这些张量中的每一个都是一系列的矩阵，像披萨盒一样一个接一个的叠在一起。反过来，矩阵只是以矩阵形式排列的神经元序列，而不是像在经典网络中那样的阵列。</p><h2 id="864e" class="od mt it bd mu oe of dn my og oh dp nc li oi oj ne lm ok ol ng lq om on ni oo bi translated">迁移学习</h2><p id="fb98" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">迁移学习是这项任务中最重要的概念，因为从头开始构建人脸分类器非常困难(几乎不可能)。迁移学习是在自己的任务中使用预先训练好的模型的过程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/a11929f941b7f39cd3f73cf4863c8ab1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ENXpDcgEvTGl_1A_tqQ34A.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="oq">转移学习</em>。作者图片</p></figure><p id="5c69" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种情况发生如下。你找到一个为类似任务训练过的模型(例如，识别1000类图像，就像在<em class="mn"> ImageNet </em>中一样，而你只需要识别少数几类)。然后使用它的权重(冻结它们，这意味着它们不会改变)，并在您的小数据集上完成模型的训练。之后还可以解冻所有权重，继续用极小的学习率训练模型。</p><p id="c735" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于CNN架构和图像识别任务的特征，该过程变得可能(但是也可以用于不同的架构)。网络学会从一层到另一层(从输入到输出)看到模式，它们变得越来越复杂。事实证明，所有问题的一般模式大致相同，这允许我们使用预先训练的权重。</p><h2 id="f2c7" class="od mt it bd mu oe of dn my og oh dp nc li oi oj ne lm ok ol ng lq om on ni oo bi translated">数据扩充</h2><p id="6d68" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">图像分类问题中的另一个重要概念是数据扩充。数据扩充是通过对原始图像应用一些变换来人为增加数据集大小的过程。例如，我们可以使用水平和垂直反射、小旋转或放大、颜色反转等等。这将显著增加数据集的大小，从而提高网络的概化能力。</p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/image-augmentation-for-deep-learning-histogram-equalization-a71387f609b2"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">用于深度学习的图像增强</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">深度网络需要大量的训练数据来实现良好的性能。要建立一个强大的图像分类器…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="ou l mj mk ml mh mm ks ly"/></div></div></a></div><p id="ead8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的例子中(文章中的第一个图像)，当偏移值很高时，有时会出现只有部分图像可见的情况。一方面，这是好的(在头部不可见的图像情况下，网络可以通过爪子和尾巴而不是通过口鼻来学习识别猫)，但如果你过度进行这样的转换，也会使网络混淆。</p><p id="d434" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TensorFlow中有多种数据扩充方法。我们可以生成图像并保存到磁盘，或者我们可以将生成器直接传送到网络。我选择了第一个选项，这样做更明确。但是这里也有两种方法:生成随机数量的图像或者生成特定图像的几个版本。您可以在<code class="fe mo mp mq mr b">data_augmentation.ipynb</code>笔记本中看到这两个选项的实现。我使用了第二个选项，并专门为每张图像生成了五个转换。</p><h1 id="5675" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">实用部分</h1><h2 id="52c4" class="od mt it bd mu oe of dn my og oh dp nc li oi oj ne lm ok ol ng lq om on ni oo bi translated">项目结构</h2><p id="ea4b" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">该项目的结构如下:</p><pre class="kj kk kl km gt ov mr ow ox aw oy bi"><span id="0d16" class="od mt it mr b gy oz pa l pb pc">me_not_me_detector<br/>├───article<br/>├───datasets<br/>│   ├───face_dataset_test_images<br/>│   │   ├───me      # contains TEST images for ME class<br/>│   │   └───not_me  # contains TEST images for NOT_ME class<br/>│   ├───face_dataset_train_aug_images (optional)<br/>│   │   ├───me      # contains aug TRAIN images for ME class<br/>│   │   └───not_me  # contains aug TRAIN images for NOT_ME class<br/>│   └───face_dataset_train_images<br/>│       ├───me      # contains TRAIN images for ME class<br/>│       └───not_me  # contains TRAIN images for NOT_ME class<br/>├───models<br/>│   .gitignore<br/>│   data_augmentation.ipynb<br/>│   me_not_me_classifier.ipynb<br/>│   me_not_me_classifier_model_comparison.ipynb<br/>│   me_not_me_detector.ipynb<br/>│   README.md<br/>└── requirements.txt</span></pre><p id="3ed5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">先说文件夹。</p><ul class=""><li id="f834" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu or nv nw nx bi translated"><code class="fe mo mp mq mr b">article</code>文件夹包含本教程的数据。</li><li id="5cbb" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu or nv nw nx bi translated"><code class="fe mo mp mq mr b">models</code>文件夹包含了用于测试和进一步使用的训练模型。</li><li id="7d8d" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu or nv nw nx bi translated"><code class="fe mo mp mq mr b">datasets</code>文件夹包含三个文件夹——用于训练集、测试集和扩充训练集(可选)。其中每一个都包含两个子文件夹，用于两个类- <em class="mn"> me </em>和<em class="mn"> not_me </em>。在一般情况下，它包含N类分类问题的N个子文件夹。</li></ul><p id="fc2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们来谈谈代码文件——jupyter笔记本。</p><ul class=""><li id="751b" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu or nv nw nx bi translated"><code class="fe mo mp mq mr b">data_augmentation.ipynb</code>文件从初始数据集创建一个扩充数据集，并提供关于数据集的一些信息。</li><li id="5b3a" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu or nv nw nx bi translated">文件包含训练和测试五个不同模型的代码。</li><li id="e97f" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu or nv nw nx bi translated"><code class="fe mo mp mq mr b">me_not_me_classifier.ipynb</code> file做同样的事情，但是针对一个特定的模型。您可以将它作为构建自己的分类器的示例。</li><li id="1065" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu or nv nw nx bi translated"><code class="fe mo mp mq mr b">me_not_me_detector.ipynb</code>文件使用OpenCV库，将分类器变成实时检测器。</li></ul><p id="951a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其他文件用作附加文件:</p><ul class=""><li id="a2fe" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu or nv nw nx bi translated"><code class="fe mo mp mq mr b">.gitignore</code>包含git中不会推送的文件，</li><li id="a39d" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu or nv nw nx bi translated"><code class="fe mo mp mq mr b">requirements.txt</code>包含了运行这些代码需要安装的库列表，等等。</li></ul><h2 id="7689" class="od mt it bd mu oe of dn my og oh dp nc li oi oj ne lm ok ol ng lq om on ni oo bi translated">1.数据集集合</h2><p id="a553" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">首先，我们需要收集一个数据集。我用我的照片和我家人的照片来训练模型，但是你也可以在<a class="ae ky" href="https://analyticsindiamag.com/10-face-datasets-to-start-facial-recognition-projects/" rel="noopener ugc nofollow" target="_blank">其他一些人脸数据集</a>上训练模型。我只使用了个人照片来检查这样一个小数据集是否足以让模型显示出可接受的质量。</p><p id="7e9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我从每张照片中裁剪出面部，并将它们的大小调整为250x250(您不必这样做，因为TensorFlow可以为您完成)。以下是初始数据集中的一些照片示例:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/12ae925293400d2ffd7a013a381e7122.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*aHkN1M3vHE9er01HF37LIQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="oq">初始数据集照片</em>。作者图片</p></figure><p id="3271" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我一共收集了215张照片，其中82张是<em class="mn">我</em>，133张是<em class="mn">非_我</em>。</p><p id="4ea8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于测试集，我立即搁置了20张照片。这可以自动完成，但我是手动完成的，因为数据集太小。对于列车组，我应用了来自<code class="fe mo mp mq mr b">data_augmentation.ipynb</code>笔记本的数据增强代码。因此，数据集增加了五倍！(每张照片生成五张照片)。以下是生成的照片示例:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/7f6100ab1f30f5777d48846f2e441a74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VhAQ8Y4ce9_ztKEmm3gXeg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="oq">增强照片</em>。作者图片</p></figure><p id="9910" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当数据集准备好时，我们可以开始训练模型。</p><h2 id="d645" class="od mt it bd mu oe of dn my og oh dp nc li oi oj ne lm ok ol ng lq om on ni oo bi translated">2.寻找迁移学习的基本模式</h2><p id="abed" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">这里没有什么复杂的——我只是使用了在<em class="mn"> ImageNet </em>数据集上训练的不同模型。如果他们没有很好的准确性，那么我想我会使用类似VGGFace模型的东西比如这里的<a class="ae ky" href="https://machinelearningmastery.com/how-to-perform-face-recognition-with-vggface2-convolutional-neural-network-in-keras/" rel="noopener ugc nofollow" target="_blank"/>。但是我得到的质量足够好。我们可以用以下代码加载预训练模型:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf pg l"/></div></figure><h2 id="df43" class="od mt it bd mu oe of dn my og oh dp nc li oi oj ne lm ok ol ng lq om on ni oo bi translated">3.训练模特</h2><p id="e00b" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">现在，我们必须冻结这些权重，在模型上添加一些层，并在我们的小数据集上训练模型。</p><p id="8236" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我前面说过的，<code class="fe mo mp mq mr b">me_not_me_classifier_model_comparison.ipynb</code>文件包含了不同型号的代码。你可以用它来做你自己的实验。下面的代码示例摘自<code class="fe mo mp mq mr b">me_not_me_classifier.ipynb</code>。这里我们将使用<em class="mn"> ResNet50 </em>作为初始模型。</p><p id="f940" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在导入库和数据集加载之后，我们完全按照上面的代码加载预训练模型。之后，我们需要恢复模型的顶部——密集的部分。请注意，这部分因型号不同而不同。要知道你需要哪些层，你可以加载带顶层和不带顶层的模型，调用<em class="mn"> model.summary() </em>方法，看看它们有什么不同:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf pg l"/></div></figure><p id="c32b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了添加层，我使用了<em class="mn"> TensorFlow函数API </em>。当然，你需要一些关于TensorFlow和CNN的知识，但你也可以尝试添加不同的层，获得非原创的架构。在我的例子中，我们需要一个全局平均池层和密集层。不要忘记预先冻结其他重量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf pg l"/></div></figure><p id="e4df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，我们继续配置模型。我添加了一个<em class="mn"> ModelCheckpoint </em>对象，以便在出错时将模型保存在磁盘上，同时作为一种正则化技术，我还添加了<em class="mn">提前停止</em>。作为一种优化方法，我使用了具有标准学习率值的Adam。我也尝试使用各种<em class="mn">调度技术</em>，但是它们没有带来多少结果。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf pg l"/></div></figure><p id="0bbb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以现在我们可以开始训练了。结束后，你将有一个现成的模型。您可以通过<code class="fe mo mp mq mr b">me_not_me_classifier.ipynb</code>文件中的<em class="mn">测试</em>部分代码来检查其功能。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf pg l"/></div></figure><h2 id="7525" class="od mt it bd mu oe of dn my og oh dp nc li oi oj ne lm ok ol ng lq om on ni oo bi translated">4.将分类器转换为检测器</h2><p id="d80a" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">现在我们必须使用<em class="mn"> OpenCV </em>库进行网络摄像头访问和人脸检测。</p><p id="feff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">坦率地说，由于分类器和检测器的定义，短语“将分类器转换为检测器”是不正确的。分类器(理解为图像分类器)是一种模型，它接收图像作为输入，并在输出端给出一个可能类别的标签(在我们的例子中，是<em class="mn"> me </em>或<em class="mn"> not_me </em>)。检测器(理解为面部检测器)是一种模型，其接收图像作为输入，并且如果该图片中存在面部，则输出面部周围的边界框的坐标。</p><p id="3f63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我用这个短语来说明最终的程序(它仍然是一个分类器)现在也给出了人脸在图片中的确切位置。此外，现在它可以在照片中同时有几个人脸的情况下正确工作。</p><p id="6603" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练一个人脸检测器是一件非常困难的事情(主要是因为数据很难标注)，所以我会使用OpenCV提供的人脸检测器。使用起来非常简单。在下面的代码中，faces变量是图像中所有面孔的数组。对于每个面，边界框有四个值:</p><ul class=""><li id="a610" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu or nv nw nx bi translated">左上角的x-x坐标，</li><li id="f9d1" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu or nv nw nx bi translated">左上角的y-y坐标，</li><li id="ed38" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu or nv nw nx bi translated">w —边界框的宽度，</li><li id="0ed4" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu or nv nw nx bi translated">h-边界框的高度。</li></ul><p id="ea73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下代码在网络摄像机图像中实时突出显示您的面部，如下图所示。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pf pg l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/c45f36d4b0abc9ea2f2855873bda9d9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*ASWR0MYZEP1jGhFibLbCcg.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="oq">用OpenCV进行人脸检测</em>。照片由<a class="ae ky" href="https://www.pexels.com/@simon-robben-55958?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">西蒙·罗本</a>从<a class="ae ky" href="https://www.pexels.com/photo/man-in-brown-polo-shirt-614810/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">派克斯</a>拍摄</p></figure><p id="1f6c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在剩下的就是加载预先训练好的模型，将人脸所在的图像片段传递给它，并在屏幕上显示文本！事实上，在这个阶段我面临一个小困难——模型只是有时认出我。发生这种情况是因为我训练她在图像上“留有空白”，不仅仅是脸部的位置。</p><p id="12e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我可以向数据集添加不同比例的图像，但我决定诚实地这样做。为此，我编写了函数<em class="mn"> get_extended_image() </em>，用某个系数k来增大裁剪后的图像的大小，k越大，人脸周围的面积越大。为了解释这个函数的操作(或者更让你迷惑)，我给出下图(为简单起见，这里k = 0.3。没有观察到刻度。注意，左上坐标是(0，0))。你也可以看到不同k参数的我的脸的剪报(根据OpenCV，它使用BGR而不是RGB，但不是调整颜色，让我们想象我是一个头像)。对于结果模型，我使用k = 0.5。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/423d5f5d79dbe113ae090738d93b7dd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*iqIF59-PS_wqg37xf7HZNw.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="oq"> get_extended_image()函数说明</em>。作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/fbf214ef46b443c1fbe48723f66f3e5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*WcqiWLkjGXZegecIx7yK2w.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="oq">具有不同k参数</em>的get_extended_image()的图像。作者图片</p></figure><p id="d509" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我想指出的是，我使用了<em class="mn"> MobileNet </em>作为基础模型。最初，我使用的是<em class="mn"> ResNet50 </em>，因为它显示的质量最好，但图像滞后了一点，而更轻的<em class="mn"> MobileNet </em>则没有这些问题。我在一台配有i7–10750h和32G内存的电脑上测试了所有这些。</p><p id="f961" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就是这样！您可以在<code class="fe mo mp mq mr b">me_not_me_detector.ipynb</code>笔记本中找到完成的代码，但是注意，要使用它，您需要在<code class="fe mo mp mq mr b">models</code> <strong class="lb iu"> <em class="mn"> </em> </strong>文件夹中有一个模型，否则您将在<em class="mn">加载模型</em>单元格中得到一个错误。这是结果。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pk pg l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">实时人脸检测器的视频演示</p></figure><p id="118e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我必须说，虽然模型相当简单，但它已经很好地识别了我，例如，如果脸部的一部分被覆盖。另外，我的数据集中没有威利姆·达福的照片，所以模特以前没有见过他。</p><p id="38b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">面具识别中的人脸呢——你可以看到，如果我的鼻子被完全遮住，程序就会停止识别我的脸(或者当它旋转太多的时候)。但是这在检测器侧是一个问题，因为它停止将图像传输到模型。这是因为OpenCV人脸检测器通常看不到戴面具的人。但我认为，如果你能收集一个大型数据集，你也可以教你的模型区分戴面具的人。</p><p id="baa8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我感到惊讶的是——当脸的下半部分被遮住时，模特比上半部分更容易认出我。你可以看到，当我戴上帽子或者用手遮住额头时，模特开始怀疑。我想这是因为在我所有的照片中，我的头都是敞开的，而且我只有一种发型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/1608bd5ed6ead91ac0e8dc637820e343.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*st0Z59nAphlzexhgAIL2hw.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">好模式！作者图片</p></figure><h1 id="af4a" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">结论</h1><p id="5fc3" class="pw-post-body-paragraph kz la it lb b lc nk ju le lf nl jx lh li nm lk ll lm nn lo lp lq no ls lt lu im bi translated">下面，我展示了使用或不使用数据扩充(本例中为x5数据扩充)的不同模型的训练结果。最佳质量(99%的验证准确性)由<em class="mn"> ResNet50 </em>显示。但正如我上面所说，我使用了基于<em class="mn"> MobileNet </em>的模型，因为它在实时操作中表现得很好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/4ba5d56a2ebc4f48cfcf2a8aab0e008f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qZPjaQyk55R9U-QXQ80uCw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="oq">不同车型的训练结果</em>。作者图片</p></figure><p id="00e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些结果表明，数据扩充可以显著提高模型的质量。在这种情况下，验证损失下降了10倍，但这是关于非常少的数据集。我试图生成更多的图像，并获得更多的准确性。该参数(数据集的系数增加，因此为每幅图像生成的增强图像的数量)可以通过<em class="mn">交叉验证</em>来选择。我在MobileNet中得到的最好的模型是验证损失= 0.09886，验证准确度= 0.9589，数据集增加系数= 15。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/366141e1ea367ba0a0185556ab993b7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*yJm3ZWXCN94OaDrgfHm0xQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="oq">数据集大小对MobileNet示例中模型质量的依赖性</em>。作者图片</p></figure><p id="e71d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与此同时，学习过程变得非常缓慢。有道理，数据集规模增加，学习时间也增加。您可以在下面看到训练时间对数据集大小的依赖关系图，它几乎是线性的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/4053bb5c3884f9acc71b98e959ae32d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*gtUfAMZWHLSBHJijTeu5lg.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="oq">MobileNet示例中数据集大小对学习时间的依赖性</em>。作者图片</p></figure><p id="7b3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下表是上一个表的扩展版。在这里，您可以看到参数的数量、模型的深度和测试精度。请注意，图层被计为<em class="mn"> model.layers </em>对象的数量，这并不完全正确，但给出了模型深度的概念。测试准确性没有太多的统计能力，因为我只有20张测试图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi po"><img src="../Images/9e05581f432e0baf968d01c1e1ba0179.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cr0mvtbed1syAp3WK8bfCQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="oq">扩展结果</em>。作者图片</p></figure><p id="0796" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于VGG的一件事。我用两个1024密集层替换了两个4096密集层，模型显示了大致相同的结果，尽管参数数量分三次下降(从1.34亿下降到4100万，可训练值从1.19亿下降到2700万)。该型号的磁盘大小为368 MB。</p><p id="6358" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从所做的工作中，我可以得出以下结论。有些比较明显，有些不太明显:</p><ul class=""><li id="480b" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu or nv nw nx bi translated">你需要收集的数据集应该<strong class="lb iu">尽可能的多样化</strong>，同时<strong class="lb iu">尽可能的接近真实数据</strong>。</li><li id="0101" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu or nv nw nx bi translated">更简单的模型训练速度更快，预测速度更快，占用硬盘空间更少。更简单的模型有更少的参数，但是，同时，可以更深入。</li><li id="1951" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu or nv nw nx bi translated"><strong class="lb iu">迁移学习</strong>是一种非常强大的技术，即使只有很小的数据集，它也能让你解决你的任务。</li><li id="27b4" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu or nv nw nx bi translated"><strong class="lb iu">数据扩充</strong>技术允许你显著地提高模型的质量，但是它也增加了训练时间。您可以通过交叉验证选择数据扩充系数。</li><li id="e149" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu or nv nw nx bi translated">结果很大程度上取决于随机初始化。因此，<strong class="lb iu">即使是相同参数的训练过程也要运行几次</strong>。例如，在22分钟和150个历元中，我在没有数据增强的情况下使用ResNet50得到的验证损失结果为0.1334，比常规ResNet50好39%。</li></ul><p id="1844" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我要再说一句让你更加困惑的话。</p><blockquote class="pp pq pr"><p id="64c3" class="kz la mn lb b lc ld ju le lf lg jx lh ps lj lk ll pt ln lo lp pu lr ls lt lu im bi translated"><em class="it">网络的卷积部分(上至稠密层)将原始图像转化为某个高维空间中的点(这类似于</em>嵌入<em class="it">的概念)，稠密层再在这个空间中构建分离超平面。</em></p></blockquote><p id="bb94" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，最好建立一个模型来更好地定位这些点，然后您可以使用更简单的分类器。当然，构建这些表示的规则非常复杂，这就是为什么我们需要具有大量参数的深度模型。</p><p id="b369" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个能够很好地创建嵌入的网络能够解决最初没有被训练过的任务。所以，一个好的模型会把我所有的照片彼此靠近(在某个高维空间)定位，把威利姆·达福所有的照片彼此靠近定位。但同时，这两个点云的位置应该相距很远。现在，当你向网络展示另一个人的照片时，它将能够说这是<em class="mn">而不是_me </em>，但是除此之外，它将能够给出他最像的人或者注意到这个人不在数据集中。这是<em class="mn">度量学习</em>的变体，这里使用<em class="mn">三重损失</em>。</p></div><div class="ab cl pv pw hx px" role="separator"><span class="py bw bk pz qa qb"/><span class="py bw bk pz qa qb"/><span class="py bw bk pz qa"/></div><div class="im in io ip iq"><h1 id="4b8a" class="ms mt it bd mu mv qc mx my mz qd nb nc jz qe ka ne kc qf kd ng kf qg kg ni nj bi translated">感谢您的阅读！</h1><ul class=""><li id="448d" class="np nq it lb b lc nk lf nl li qh lm qi lq qj lu or nv nw nx bi translated">我希望这些材料对你有用。在媒体上关注我以获得更多类似的文章。</li><li id="8cdd" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu or nv nw nx bi translated">如果您有任何问题或意见，我将很高兴得到任何反馈。在评论中问我，或者通过<a class="ae ky" href="https://www.linkedin.com/in/andimid/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae ky" href="https://twitter.com/dimid_ml" rel="noopener ugc nofollow" target="_blank"> Twitter </a>联系我。</li><li id="bb82" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu or nv nw nx bi translated">为了支持我作为一名作家，并获得数以千计的其他媒体文章，使用<a class="ae ky" href="https://medium.com/@andimid/membership" rel="noopener">我的推荐链接</a>获得媒体会员资格(不收取额外费用)。</li></ul></div></div>    
</body>
</html>