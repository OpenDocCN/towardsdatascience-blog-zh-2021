<html>
<head>
<title>Training NLP Models on Counterfactual Text</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在反事实文本上训练自然语言处理模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-nlp-models-on-counterfactual-text-ff1b2a4fffbc?source=collection_archive---------32-----------------------#2021-05-27">https://towardsdatascience.com/training-nlp-models-on-counterfactual-text-ff1b2a4fffbc?source=collection_archive---------32-----------------------#2021-05-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="23c3" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">西班牙语和阿拉伯语的再反射实验</h2></div><p id="7d7f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://medium.com/codex/counterfactual-text-with-seq2seq-5ca11bef342" rel="noopener">今年年初</a>，我上传了一个seq2seq模型来生成西班牙语的性别反事实(<em class="lc">El professor viejo</em>&lt;-&gt;<em class="lc">la profesora vieja</em>)。从那以后，我调试了一些问题，做了一个通用库，并为阿拉伯语创建了一个初始的seq2seq模型。</p><p id="8991" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">目标是看看通过流程传递数据是否会创建更一般化的训练数据(数据扩充),从而提高准确性和公平性。</p><p id="5a8c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">这篇文章和笔记本在2021年7月更新了一个新的、固定的</strong> <code class="fe ld le lf lg b"><strong class="kh ir">random_state</strong></code> <strong class="kh ir">和一个更精确的SimpleTransformers版本。</strong></p><h1 id="856d" class="lh li iq bd lj lk ll lm ln lo lp lq lr jw ls jx lt jz lu ka lv kc lw kd lx ly bi translated">训练阿拉伯语seq2seq模型</h1><p id="7248" class="pw-post-body-paragraph kf kg iq kh b ki lz jr kk kl ma ju kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">当我提出这个项目的阿拉伯语版本时，<a class="ae lb" href="https://twitter.com/wissam_antoun" rel="noopener ugc nofollow" target="_blank"> Wissam Antoun </a>推荐了一篇论文“<a class="ae lb" href="https://www.aclweb.org/anthology/W19-3822/" rel="noopener ugc nofollow" target="_blank">自动性别识别和阿拉伯语再输入</a>”。阿布扎比NYU大学的作者发布了他们改编自OpenSubtitles的平行性别语料库。这是少数几篇NLP和语言学论文中的一篇，这些论文称这种反事实构建实践为“再反射”。</p><p id="9e71" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对数据集的两大警告是:</p><ul class=""><li id="15d9" class="me mf iq kh b ki kj kl km ko mg ks mh kw mi la mj mk ml mm bi translated">它只有第一人称陈述，这意味着没有翻转一些名词和代词的训练数据(“你见过我的朋友吗？”)和有限的兴趣去翻动其他的词，比如‘母亲’或者‘经理’。</li><li id="409c" class="me mf iq kh b ki mn kl mo ko mp ks mq kw mr la mj mk ml mm bi translated">阿拉伯语电视和电影通常是埃及阿拉伯语，但其中一些字幕是志愿者翻译的。我没有用方言分类器测试数据集。</li></ul><p id="2177" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我<a class="ae lb" href="https://colab.research.google.com/drive/1TuDfnV2gQ-WsDtHkF52jbn699bk6vJZV" rel="noopener ugc nofollow" target="_blank">基于最近的阿拉伯模型训练了几个seq2seq模型</a>:来自UBC NLP(温哥华)的MARBERT和来自AUB MindLab(贝鲁特)的AraBERT。我测试了一个方向的准确性(男性-女性或女性-男性句子翻转)，然后是双向任务。我包括了一组有限的第三人称训练示例，但是没有进一步扩展它和编辑其他训练数据，没有一个模型能很好地处理这些。</p><p id="cc44" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最终，我在HuggingFace上发布了一个基于MARBERT模型的解码器和编码器。</p><h1 id="f135" class="lh li iq bd lj lk ll lm ln lo lp lq lr jw ls jx lt jz lu ka lv kc lw kd lx ly bi translated">数据扩充和基准</h1><h2 id="4ade" class="ms li iq bd lj mt mu dn ln mv mw dp lr ko mx my lt ks mz na lv kw nb nc lx nd bi translated">西班牙语</h2><p id="8a21" class="pw-post-body-paragraph kf kg iq kh b ki lz jr kk kl ma ju kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">在西班牙语笔记本中，我过滤了一个现有的亚马逊评论数据集。我发现BETO(一个单语西班牙模型)在预测评论的星级数方面优于mBERT。</p><p id="b6d6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我有两个策略来使用这些性别再反应模型来增加和消除我的训练数据(数据扩充)。对我来说，哪种策略更好并不明显:</p><ul class=""><li id="1bee" class="me mf iq kh b ki kj kl km ko mg ks mh kw mi la mj mk ml mm bi translated"><em class="lc">将</em>翻转的示例添加到训练数据中——顺序稍后将被随机化，因此它们将与原始数据混合在一起</li><li id="063e" class="me mf iq kh b ki mn kl mo ko mp ks mq kw mr la mj mk ml mm bi translated"><em class="lc">用反事实替换训练数据中的</em>例子</li></ul><p id="b642" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于mBERT来说，当作为一个分类器时，附加数据对问题的改善微不足道；替换数据取得了微小但更可衡量的改进(54.8%比56.2%)。</p><h2 id="ec9e" class="ms li iq bd lj mt mu dn ln mv mw dp lr ko mx my lt ks mz na lv kw nb nc lx nd bi translated">重新思考我的方法</h2><p id="d9d7" class="pw-post-body-paragraph kf kg iq kh b ki lz jr kk kl ma ju kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">我对这个实验最大的担心是<em class="lc">花费数小时通过seq2seq </em>运行数千个例子。该库没有使用GPU来转换这些示例，因此您可以提前在本地运行它，但它对实验进行了甚至很小的调整和更改，这令人沮丧。</p><p id="1116" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我对阿拉伯语seq2seq模型和笔记本感到困惑时，我离开了这个问题，回来时没有理解我自己的代码。我决定写一个脚本(<a class="ae lb" href="https://github.com/MonsoonNLP/seq2seq-for-data-augmentation" rel="noopener ugc nofollow" target="_blank"> GitHub link </a>)让这两种方法的实验变得更容易，并阅读我的<a class="ae lb" href="https://colab.research.google.com/drive/194ITDA1AjxAx_4ZLjoRFQI1aWzsl7xU8?usp=sharing" rel="noopener ugc nofollow" target="_blank">阿拉伯语笔记本</a>。</p><pre class="ne nf ng nh gt ni lg nj nk aw nl bi"><span id="cf3c" class="ms li iq lg b gy nm nn l no np">append_sequenced(<br/>    "monsoon-nlp/es-seq2seq-gender-encoder",<br/>    "monsoon-nlp/es-seq2seq-gender-decoder",<br/>    [[txt1, label1], ...],<br/>    seq_length=512,     # cap length of input for model<br/>    random_state=404,   # random state for scikit-learn<br/>    frequency=0.5,      # fraction of examples to edit<br/>    always_append=False # append example even if unchanged by flip<br/>)<br/>replace_sequenced(<br/>    "monsoon-nlp/es-seq2seq-gender-encoder",<br/>    "monsoon-nlp/es-seq2seq-gender-decoder",<br/>    [[txt1, label1], ...],<br/>    seq_length=512,<br/>    random_state=404,<br/>    frequency=0.5<br/>)</span></pre><h2 id="3fc0" class="ms li iq bd lj mt mu dn ln mv mw dp lr ko mx my lt ks mz na lv kw nb nc lx nd bi translated">阿拉伯实验</h2><p id="a930" class="pw-post-body-paragraph kf kg iq kh b ki lz jr kk kl ma ju kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">我尝试的第一个数据集(<a class="ae lb" href="https://huggingface.co/datasets/ajgt_twitter_ar" rel="noopener ugc nofollow" target="_blank"> ajgt_twitter_ar </a>，Jordanian Tweets)相当小，但所有分类器都得分很高，不可能显示数据增强的效果。</p><p id="d7dd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我最终使用的数据集(<a class="ae lb" href="https://huggingface.co/datasets/hard" rel="noopener ugc nofollow" target="_blank"> HARD </a>，Hotel Arabic-Reviews数据集)包含评论和评级(0–3)。</p><p id="5960" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将此视为一个回归问题，当附加示例时，新模型具有<em class="lc">明显更小的误差</em>(RMSE = 0.2442至0.1977)。</p><p id="cbda" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在替换时，误差介于前两次运行之间(0.2285)。</p><p id="194a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我在Koc大学(伊斯坦布尔)的bert-base-arabic模型上重新运行了这些测试。用一个模型及其嵌入生成示例，并将它们覆盖到另一个模型的嵌入上，可能会有好处[除非seq2seq模型基于每个模型会有相同的输出？].</p><p id="e75c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">未编辑时，追加时误差为0.2694 <br/>，替换时误差略微降低至0.2643 <br/>，误差也降低至0.2523</p><h1 id="b009" class="lh li iq bd lj lk ll lm ln lo lp lq lr jw ls jx lt jz lu ka lv kc lw kd lx ly bi translated">此seq2seq步骤的用途</h1><p id="c2e1" class="pw-post-body-paragraph kf kg iq kh b ki lz jr kk kl ma ju kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">替换方法对西班牙分类模型的整体准确性有一个小的积极影响，而附加方法对阿拉伯回归模型总是有一个小的积极影响。当我们考虑整体准确性时，选择特定的模型或随机种子可能是一个更重要的选择。不幸的是，我在2020年测试中看到的积极结果很可能是错误的。<br/>阿拉伯模型仍有很大的空间，可以通过更多的例子进行训练，并在翻转方面更加全面。</p><h2 id="9708" class="ms li iq bd lj mt mu dn ln mv mw dp lr ko mx my lt ks mz na lv kw nb nc lx nd bi translated">数据集的适用性</h2><p id="567f" class="pw-post-body-paragraph kf kg iq kh b ki lz jr kk kl ma ju kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">评论以第一人称编写，这有助于阿拉伯语seq2seq模型在第一人称对话文本上训练。因为评论是关于产品和地点的，所以评论文本可能较少提及性别和其他人。</p><p id="2ba7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当涉及到数据来源(员工评论、个人经历、艺术描述)时，更好的是有更多的多样性，或者更好的是，一个专门围绕这些语言的公平性或健壮性的数据集。</p><p id="52d6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于较小的少数群体来说，一个微小的准确度变化，甚至是对多数群体的负变化，都可能隐藏了显著的准确度变化，我们希望更好地打包和标记数据，以便我们可以衡量和了解如何为每个人提供最佳选择。</p><h2 id="58b8" class="ms li iq bd lj mt mu dn ln mv mw dp lr ko mx my lt ks mz na lv kw nb nc lx nd bi translated">未来是菲利克斯</h2><p id="c051" class="pw-post-body-paragraph kf kg iq kh b ki lz jr kk kl ma ju kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">展望未来，我会对<a class="ae lb" href="https://ai.googleblog.com/2021/05/introducing-felix-flexible-text-editing.html" rel="noopener ugc nofollow" target="_blank">谷歌的新FELIX架构</a>感兴趣:</p><blockquote class="nq nr ns"><p id="3b49" class="kf kg lc kh b ki kj jr kk kl km ju kn nt kp kq kr nu kt ku kv nv kx ky kz la ij bi translated">与seq2seq方法相比，速度提高了90倍，同时在四个单语生成任务上取得了令人印象深刻的结果</p></blockquote><h1 id="1cf5" class="lh li iq bd lj lk ll lm ln lo lp lq lr jw ls jx lt jz lu ka lv kc lw kd lx ly bi translated">更新？</h1><p id="8b73" class="pw-post-body-paragraph kf kg iq kh b ki lz jr kk kl ma ju kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">这篇文章发表于2021年5月。有关任何更新，请参见<a class="ae lb" href="https://github.com/mapmeld/use-this-now/blob/main/README.md#gender-re-inflection" rel="noopener ugc nofollow" target="_blank">GitHub自述文件。</a></p></div></div>    
</body>
</html>