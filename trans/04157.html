<html>
<head>
<title>Tackling Imbalanced Data with Predicted Probabilities</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用预测概率处理不平衡数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tackling-imbalanced-data-with-predicted-probabilities-3293602f0f2?source=collection_archive---------9-----------------------#2021-04-08">https://towardsdatascience.com/tackling-imbalanced-data-with-predicted-probabilities-3293602f0f2?source=collection_archive---------9-----------------------#2021-04-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="e8bb" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">在数据世界里争吵</h2><div class=""/><div class=""><h2 id="3692" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">葡萄牙银行营销数据集中优化分类概率的案例研究</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/ef2f622e1a6dbe9ac34fef39ab86736b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cF24Tkl4shc7DqYigECZrA.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><em class="lh">图片由</em> Budarinphoto <em class="lh">通过创意市集</em></p></figure><p id="698b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi me translated">分类算法通常能够输出预测的概率。有时，这些预测的概率本身也很有意义，例如在评估博彩赔率时。<strong class="lk jd">预测概率</strong>也可以通过给我们<strong class="lk jd">调整分类阈值</strong>的选项来改善模型预测，从而帮助处理不平衡数据。</p><p id="4776" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">本文讨论了各种机器学习算法在预测概率上的<strong class="lk jd">差异</strong>，以及如何通过案例研究使用它们来<strong class="lk jd">提高这些算法的预测能力</strong>。案例研究是一个<strong class="lk jd">葡萄牙银行营销</strong>数据集，其中<strong class="lk jd">目标变量</strong>是<strong class="lk jd"> </strong>定期存款的“是”或“否”预订。</p><p id="ef8b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我将首先讨论目标变量和选择的评分标准。然后网格搜索最佳模型超参数，接着分析预测概率。然后将这些概率校准到数据中的真实观察概率。随后定位使评分度量最大化的召回精度阈值。最后，最优概率阈值用于重新分类模型预测，并计算最终的训练测试分数。</p><p id="cfc2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">几年前，我在一次数据科学访谈评估中收到了有问题的数据集，它被故意调整为需要一些数据争论，以将数据放入正确的Pandas数据框架中进行进一步分析。我提到这一点，是为了让你在我的Github页面上查看代码时，不会被最初的数据争论所迷惑，并且对那些可能面临类似调整的采访数据集的人也有帮助。<strong class="lk jd"> UCI数据集</strong>可在<a class="ae mn" href="https://archive.ics.uci.edu/ml/datasets/bank+marketing" rel="noopener ugc nofollow" target="_blank">这里</a>获得，但是我用于案例研究的版本发布在我的Github页面上，链接在本文底部。</p><h1 id="bd66" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">不平衡数据</h1><p id="3aed" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">调整后的数据集有<strong class="lk jd">41176个观察值</strong>。<strong class="lk jd">目标分类变量</strong>不平衡，<strong class="lk jd">的“是”率为11.27%</strong>,<strong class="lk jd">的“否”率为88.73% </strong>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nl"><img src="../Images/fb8e822d6179adca8fe78340e4f5e5a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*upYc-SgEpWInAzYM8FZp9A.png"/></div></div></figure><p id="4828" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">换句话说，如果这是一个装有九个黑白球组合的袋子，那么(大约)只有一个黑球<strong class="lk jd">和八个白球</strong>。因此，如果我的目标是选一个黑球，也就是预测营销活动的“是”订阅，我将有很大的胜算。</p><p id="af1b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我将目标变量中的<strong class="lk jd">“yes”类编码为“1”</strong><strong class="lk jd">，将“no”编码为“0”。将感兴趣的类别编码为<strong class="lk jd"> class 1 </strong>非常有用，因为许多重要的<em class="nm"> scikit-learn </em>评分指标，包括F1指标，都使用<em class="nm"> pos_label=1 </em>作为默认的感兴趣类别。</strong></p><p id="0e56" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">考虑到不平衡的数据，通常的<strong class="lk jd">准确度分数</strong>对这个问题帮助不大。即使模型一直简单地说“不”，它的准确率也有88.73%。说破钟一天对两次！这种模式将被打破，但仍然看起来强大的印象深刻的所有时间。</p><p id="4d87" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了解决这个问题，让我们转向<strong class="lk jd">混淆矩阵</strong>。假设我们有一个被分类为“正”(1)或“负”(0)的二元变量，这是纯粹用来区分这两个类别的术语。根据下面描述的<strong class="lk jd">风格化混淆矩阵</strong>，我们有沿着水平轴的二元变量的<strong class="lk jd">预测</strong>类(左0 &amp;右1)和沿着垂直轴的<strong class="lk jd">实际</strong>类(顶部1 &amp;底部0)。这个程式化矩阵的设计遵循了与<em class="nm"> scikit-learn </em>的<a class="ae mn" href="https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix" rel="noopener ugc nofollow" target="_blank">混淆矩阵</a>相同的顺序。</p><p id="4da7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">自然，预测很可能不是100%准确的，所以我们可以将那些“积极的”预测分为正确的(<em class="nm">真阳性</em>)或错误的(<em class="nm">假阳性</em>)。我们可以对“否定”预测做同样的事情，即<em class="nm">真否定</em>和<em class="nm">假否定</em>。矩阵的右上象限保存<em class="nm">真正</em>预测，例如，假定它包含<strong class="lk jd">预测1和真1。</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nn"><img src="../Images/3a78571c30aac2943cdd3a75d033842d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sVd4-nPkUXjfuuwC.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">程式化的混淆矩阵</strong></p></figure><p id="cfa3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">“阳性”类别的<strong class="lk jd">精确率</strong>将是<em class="nm">真阳性</em>的总和除以总阳性类别预测(或<em class="nm">真阳性</em> + <em class="nm">假阳性</em>)。<em class="nm">假阳性</em>是那些被模型错误地标记为“阳性”但实际上是“阴性”的观察结果。在上图的上下文中，它是黑盒除以红盒和黑盒的总和。<strong class="lk jd">所以</strong> <strong class="lk jd">精度是模型从其<em class="nm">预测的</em>正观测值</strong>中挑选出<em class="nm">真正</em>的概率。</p><p id="77ab" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">另一方面，<strong class="lk jd">召回率</strong>将是<em class="nm">真阳性</em>的数量除以<em class="nm">真阳性</em>和<em class="nm">假阴性</em>之和的比率。请注意，假阴性是那些被模型错误地标记为“阴性”但实际上是“阳性”的观察结果。在上图的上下文中，它是黑盒除以绿盒和黑盒的总和。<strong class="lk jd">回忆描述了模型从<em class="nm">实际</em>阳性观察值</strong>中挑选出<em class="nm">真阳性</em>的概率。</p><h1 id="8174" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">评分标准</h1><p id="b8be" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">当正类在不平衡数据集中占少数时，精确度和召回率是模型预测能力的更有用的度量，并且主要目标(但不是唯一目标)是正确识别那些正观察值。<strong class="lk jd">F1分数是精确度和召回率的调和平均值</strong>。</p><p id="9b5d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">F1分数实际上是<strong class="lk jd"> F-Beta分数</strong>的一个特例，其中Beta &gt; 1意味着更加重视<strong class="lk jd">召回率</strong>，而Beta &lt; 1则更加重视<strong class="lk jd">精确率</strong>。在模型预测中追求更高的召回率必然会降低准确率，反之亦然，我将在下面演示。所以F1分数在召回率和精确率之间取得平衡。这可能不适合每一种情况，但在我看来，它符合这种情况下的目的。</p><p id="b5e2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">科恩的kappa 是评估不平衡数据的另一个有用的统计。它告诉我们这个模型在预测<strong class="lk jd"/>【正面】和【负面】类别时，比单独的随机机会要好得多。kappa统计值大于0意味着模型比chance更好，它越接近最大上限1意味着模型对数据的分类越好。然而，Cohen的kappa统计不能用于比较不同数据集之间的模型性能。</p><p id="0089" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所以我的模型<strong class="lk jd">评测指标</strong>会是<strong class="lk jd"> F1评分</strong> <em class="nm">和</em> <strong class="lk jd">科恩的kappa </strong>。在数据不平衡的情况下，另一个有用的指标是精确召回曲线 (AUC-PR)下的<strong class="lk jd">面积，如果人们关心这两个比率之间的平衡的话。</strong></p><h1 id="03b4" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">变量和初始分数</h1><p id="9c15" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">我将省略EDA和数据工程的解释，因为这不是本文的重点。感兴趣的读者可以参考我的Github页面，跟进具体采取的措施。我选定的<strong class="lk jd">变量</strong>如下，包括目标变量(名为“target”)，其中大部分是虚拟变量:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi np"><img src="../Images/ce5f5ca730ef6962bd5eeaf770a72811.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HuOUKqrGlVOa91b4KtK7Hw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">变量列表</strong></p></figure><p id="8bb2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我将比较五种流行的分类算法的结果:</p><ul class=""><li id="2c96" class="nq nr it lk b ll lm lo lp lr ns lv nt lz nu md nv nw nx ny bi translated"><strong class="lk jd">逻辑回归</strong> (Logit)，</li><li id="73c7" class="nq nr it lk b ll nz lo oa lr ob lv oc lz od md nv nw nx ny bi translated"><strong class="lk jd">随机森林</strong>(射频)，</li><li id="2d1f" class="nq nr it lk b ll nz lo oa lr ob lv oc lz od md nv nw nx ny bi translated">天真的贝叶斯 (NB)，</li><li id="928f" class="nq nr it lk b ll nz lo oa lr ob lv oc lz od md nv nw nx ny bi translated"><strong class="lk jd">支持向量分类器</strong> (SVC)，以及</li><li id="323e" class="nq nr it lk b ll nz lo oa lr ob lv oc lz od md nv nw nx ny bi translated"><strong class="lk jd"> XGBoost </strong> (XGB)</li></ul><p id="1e74" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Python中的<em class="nm"> scikit-learn </em>库允许您更改Logit、RF和SVC的<strong class="lk jd"><em class="nm"/></strong>class-weight参数，在处理不平衡数据时，通常建议指明<em class="nm">class _ weight = " balanced "</em><strong class="lk jd"/>。你也可以为NB模型设置<strong class="lk jd">先验概率</strong>来反映目标变量各自的比例，我是这样做的<em class="nm">【0.11，0.89】</em>。至于XGBoost，可以设置<strong class="lk jd"><em class="nm">scale _ pos _ weight</em></strong>参数来反映负类与正类的比值，我表示为7.85。通常这些超参数设置只会有边缘帮助，尤其是当数据高度不平衡时，但每一点都有帮助！</p><p id="3743" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用<strong class="lk jd">最小-最大缩放</strong>对数据进行缩放，由于存在大量虚拟变量，因此选择了这种特定的缩放程序。数据通过70:30的<strong class="lk jd">训练测试分割</strong>，对数据的第一次分析得出以下训练测试分数:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oe"><img src="../Images/ab13ce222945634f0eacd1328ba4812a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V4tC_3WhzvrmgvD-A0fyPw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">训练集和测试集的初始分数</strong></p></figure><p id="ae25" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> SVC </strong>是<strong class="lk jd">在<strong class="lk jd">测试F1、科恩的kappa和精确回忆AUC分数</strong>中表现最好的</strong>，尽管它没有最高的测试准确度分数。<strong class="lk jd"> XG Boost在F1测试、Cohen的kappa和AU-PR评分中排名第二</strong>，而<strong class="lk jd">逻辑回归</strong>在这些指标中排名第三。<strong class="lk jd">随机森林</strong>在训练和测试集上获得了最高的<strong class="lk jd">准确性分数</strong>，但在其他指标上表现不佳，这表明它专注于预测多数类0。</p><h1 id="2c2e" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">网格搜索超参数</h1><p id="eff5" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">接下来是使用<strong class="lk jd"> F1 <em class="nm">和</em> Cohen的kappa作为评分标准</strong>对这五个模型进行<strong class="lk jd"> gridsearch和分层KFold </strong>交叉验证(k =3)。gridsearch程序显示了五种分类算法的以下优化超参数:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi of"><img src="../Images/309187fe8f5efad8371e83bc9867829f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*duEZjypRFItTrugxL8039A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">网格搜索优化模型</strong></p></figure><p id="6525" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后，这些数据被用于再次对训练集和测试集上的每个算法进行拟合和评分:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi og"><img src="../Images/316b9d1ce50a18031d73410a7585265e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rSxU3ML22ikVQlI8nvX_MQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">训练集和测试集的网格搜索后得分</strong></p></figure><p id="1c89" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">grid search-tuned<strong class="lk jd">XG Boost model</strong>摘得了<strong class="lk jd">顶级表演者桂冠</strong>。我们看到<strong class="lk jd">训练F1 </strong>和<strong class="lk jd"> Cohen的kappa </strong>分数在五个模型中表现出混合变化，但是在测试集分数中有一个<strong class="lk jd">总体改善。<strong class="lk jd">随机森林</strong>和<strong class="lk jd"> XG Boost </strong>的测试成绩进步最大，其次是<strong class="lk jd"> SVC </strong>。相比之下，Logit </strong>和<strong class="lk jd">nave Bayes</strong>只有轻微的改善。</p><h1 id="d249" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">预测概率</h1><p id="b312" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">现在让我们检查由各种<strong class="lk jd"> gridsearch-tuned模型</strong>提供的<strong class="lk jd">类1 </strong>的预测概率，并将它们与真实的类概率进行比较。这可以通过<strong class="lk jd">校准曲线</strong>图(或可靠性图表)来完成。预测的概率与目标变量的真实观察值一起被分类并分布到十个箱中。</p><p id="f40a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后计算每个箱中预测概率的平均值，并与该箱中类别1观察值的真实分数进行比较。这是通过绘制每个箱的平均预测概率来实现的。<strong class="lk jd">如果模型校准良好，那么平均概率点将落在对角线</strong>附近，这意味着每个箱中的平均预测概率与该箱中的实际1类观测值的比例相当。</p><p id="7bea" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">校准曲线的计算仅使用上述gridsearch程序之前分割的数据集的<strong class="lk jd">训练</strong>部分进行。模型预测概率的校准曲线如下，不幸的是，它们都没有校准好。几乎每个模型在对角线下都有一致的图，这意味着它们倾向于<strong class="lk jd">过度预测每个分类箱中目标变量</strong>(第1类)的分数，表明算法的精确度较低。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/c9470e32f5e00007a95d55152a3d84f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zOQg08Msyhrep4PXjlVlUg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">概率缩放前的可靠性图</strong></p></figure><p id="c26a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">朴素贝叶斯</strong>因提供偏向极端的预测概率而臭名昭著，而<strong class="lk jd">支持向量机</strong>倾向于生成偏向中间的预测概率，正如<strong class="lk jd">随机森林</strong>在较小程度上一样。然而，即使是<strong class="lk jd">逻辑回归</strong>，通常被认为提供了良好的未校准预测概率，在这种情况下也表现不佳。</p><p id="c033" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面的预测概率点提供了他们糟糕表现的另一个视角。NB的预测概率(红色)确实集中在两个极端，而SVC的预测概率(绿色)更多地集中在中间。Logit(蓝色)似乎不太愿意做出接近0%概率的预测，而RF(黄色)似乎相反。另一方面，XG Boost (grey)对于做出接近0%或100%的预测显得非常害羞。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oi"><img src="../Images/1ff02addb939bd18371c66b744b03f2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qH9i2TxtbysabLNUBcgfBA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">缩放前的预测概率剥离图</strong></p></figure><p id="f4a5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在任何情况下，预测概率的<strong class="lk jd">分布</strong>在不同的模型中是不同的。在我们可以使用预测的概率来改进分类预测之前，需要通过校准来<strong class="lk jd">校正这些偏斜的分布。</strong></p><h1 id="03eb" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">缩放预测概率</h1><p id="d5aa" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">通过使用初始概率来预测目标变量(即真实概率)的附加回归器，对预测概率进行校准或缩放，以反映观察到的<strong class="lk jd">1级</strong>事件的发生。更简单的程序是使用逻辑回归进行缩放，也称为<strong class="lk jd">普拉特缩放</strong>或<strong class="lk jd"> sigmoid回归变量</strong>。替代程序是利用<strong class="lk jd">等渗回归仪</strong>。</p><p id="1b4b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">令人高兴的是，<em class="nm"> scikit-learn </em>具有<strong class="lk jd"><em class="nm">calibrated classifiercv</em></strong>函数来进行缩放。我将校准函数嵌套在<em class="nm"> GridSearchCV </em>中，使用<strong class="lk jd"> brier score </strong>作为计分器，为每个算法找到最佳缩放程序，sigmoid或等张。仅使用训练数据再次完全执行该第二网格搜索。<strong class="lk jd">除了<strong class="lk jd"> SVC显示sigmoid校准</strong>为更好的选项外，所有模型均显示偏好等张校准</strong>。这实际上是非常典型的SVC算法。</p><p id="ddad" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面显示了<strong class="lk jd">比例预测概率</strong>，人们可以立即看到改进。现在大部分概率曲线大部分时间都在拥抱对角线。然而，<strong class="lk jd">朴素贝叶斯</strong>是一个主要的例外，因为它似乎无法在校准后以更高的概率生成任何预测。因此，我决定放弃对它的进一步分析。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oj"><img src="../Images/5b94d69fd5533d3adb988c39d1b4280c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sqNASmNaGfM784WuSn-p_g.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">概率缩放后的可靠性图</strong></p></figure><p id="4143" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了提供另一个视角，让我们看看由各种算法提供的预测概率(类别1)的分布的<strong class="lk jd">直方图</strong>。下面的第一张图表是<strong class="lk jd">预缩放分布图</strong>，我们可以看到它们之间的明显差异，尤其是各种分布图的模式和分布图。第二张图描绘了<strong class="lk jd">缩放后的分布</strong>，现在我们观察到预测概率的分布更加相似。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/45ac8fe261a416248d0ed5f3f904a6a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uSySrpAakZ5yQ59Y362Amg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">概率缩放前的分布</strong></p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ol"><img src="../Images/0b13e9f336891d8eaf641ef7cd685320.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TMxY8LTNJSM97OforuOMsA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">概率缩放后的分布</strong></p></figure><p id="23bd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">概括地说，我采取的步骤(为了简化，省略了上面讨论的训练测试评分)是:</p><ul class=""><li id="821b" class="nq nr it lk b ll lm lo lp lr ns lv nt lz nu md nv nw nx ny bi translated">训练-测试分割数据；</li><li id="2043" class="nq nr it lk b ll nz lo oa lr ob lv oc lz od md nv nw nx ny bi translated">grid在<strong class="lk jd">训练数据</strong>(训练验证集)上使用分层三重交叉验证搜索5个模型；</li><li id="de85" class="nq nr it lk b ll nz lo oa lr ob lv oc lz od md nv nw nx ny bi translated">启动根据上述网格搜索参数化的5个模型；</li><li id="0d9d" class="nq nr it lk b ll nz lo oa lr ob lv oc lz od md nv nw nx ny bi translated">将这5个模型放入另一个gridsearch中，使用对<strong class="lk jd">训练数据</strong>(训练验证集)的分层三重交叉验证来找到最佳概率比例回归变量。</li></ul><p id="f07f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">换句话说，两种网格搜索都是纯粹使用训练数据完成的。唯一一次使用测试数据是在对网格搜索前后的模型进行评分时。无论如何，感兴趣的读者可以参考我的GitHub页面来检查我采取的具体步骤。</p><p id="2f11" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于是否应该为网格搜索后的概率校准分离出完全独立的一批训练数据，存在一些争论。换句话说，将初始数据<strong class="lk jd">分成三份</strong> s - gridsearch训练集、概率标度训练集和测试集-同时注意对所有三个批次中少数类1的出现进行分层。如果一个人有很多数据，我想这可能是一个选择，但是你将需要更多的数据，其中的不平衡越大。然而，我不认为这是绝对必要的，因为概率校准不是为了导出新的模型超参数，而是简单地缩放已经参数化的模型的预测概率。</p><h1 id="cb2b" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">概率阈值调整</h1><p id="19fa" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">在放弃NB之后，我接着在完整的<strong class="lk jd">训练数据</strong>上拟合剩余的四个模型(Logit、RF、SVC &amp; XGB)。这些<strong class="lk jd">网格搜索调整和概率比例模型</strong>然后在<em class="nm"> y_train </em>上生成预测概率。这些预测概率用于根据将观察分类为属于<strong class="lk jd">类别1 </strong>的概率阈值来计算<strong class="lk jd">召回率和精确率</strong>。</p><p id="3c29" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">换句话说，这些是给定各种概率分类阈值的混淆矩阵的召回率和精确率。请注意，这些是<strong class="lk jd"> <em class="nm">而不是</em> </strong>通常y轴(纵轴)上的精确率和x轴(横轴)上的召回率。召回率和精确率都映射在y轴上，将预测分类为1类的概率阈值沿着x轴。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi om"><img src="../Images/90aa0fdab1b4fe5f86591bb173c42d67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SimhQgsAa0vmA8AsCcpnnw.png"/></div></div></figure><p id="6879" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如前所述，在召回率和精确率之间有一个权衡<strong class="lk jd">，我们在下面的每个图中都看到了这一点，召回率随着概率阈值的上升而下降，反之亦然，精确率随着阈值的上升而上升。所以如果我们想要100%的召回率，就把门槛定在0%就好了！不幸的是，在这种情况下，你将被海啸般的<em class="nm">假阳性</em>预测淹没，导致极低的准确率。</strong></p><p id="029f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你还记得的话，F1分数仅仅是更广泛的F-Beta 统计的一个子集。例如，如果偏好相对于精度更高的召回，那么你应该调整Beta &gt; 1。总会有一个权衡，深思熟虑的分析师会决定什么是服务于他们目标的最佳权衡。<strong class="lk jd">召回精度阈值组合</strong>是使用预测概率阈值<strong class="lk jd">优化召回精度权衡</strong>的关键。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi on"><img src="../Images/7532e35ecb60505d6300d1c411ed3bfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2IjXiGDWPu12MnpkEPeDGg.png"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oo"><img src="../Images/123eaa0b5f49ae0b0d9db7609bf60346.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m4fjSG1j-K5E4XMDdPJAkg.png"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi op"><img src="../Images/c8e5b56bdd531c4eae84439796f7b41f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r8i2WjkDTG8-A5oWynMxuw.png"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oq"><img src="../Images/991e9dab7aefc25ce17f5fe23b79dfca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*py9KRwuYdXFjl6vknFRNZg.png"/></div></div></figure><p id="dd66" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下一步是找到最大化<em class="nm"> y_train </em>上F1分数的概率阈值。然后使用<strong class="lk jd">拟合</strong> <strong class="lk jd">网格搜索调整和概率比例模型</strong>来预测<em class="nm"> y_test </em>的概率。对测试集的预测概率应用最佳阈值，以<strong class="lk jd">重新分类类别预测</strong>(分类为新的类别1或0标签)。然后对阈值调整后的类预测进行评分。同样，如果你有不同的偏好，调整F-Beta会给你不同的概率阈值和结果。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi or"><img src="../Images/73bc49a0086ed860b6c9a3199e6ea7fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cr98nj3pJyfiDjOeS6XNsw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">寻找使F1分数最大化的概率阈值的代码</strong></p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi os"><img src="../Images/0953c1c871c5c947269f4e9d5ce23e39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p44I0OhpDWusRSNaGQ8RRA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">对预测类进行重分类的代码(针对Logit模型)</strong></p></figure><h1 id="6d74" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">最终分数</h1><p id="8cb9" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">阈值调整后的重新分类预测的<strong class="lk jd">最终得分如下所示。为了便于比较，我再次加入了上面的初始和后网格搜索评分表。记住<strong class="lk jd">朴素贝叶斯</strong>模型已经从这部分分析中去掉了。</strong></p><p id="2f70" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最终的<strong class="lk jd">培训</strong> F1和Cohen的kappa分数显示所有四个模型都比gridsearch后的分数有所提高。<strong class="lk jd">测试分数</strong>当然更重要，它们揭示了阈值调整后的一个<strong class="lk jd">一般改进</strong>，除了<strong class="lk jd">随机森林</strong>算法。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oe"><img src="../Images/ab13ce222945634f0eacd1328ba4812a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V4tC_3WhzvrmgvD-A0fyPw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">训练集和测试集的初始分数</strong></p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi og"><img src="../Images/316b9d1ce50a18031d73410a7585265e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rSxU3ML22ikVQlI8nvX_MQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">训练集和测试集上的网格搜索后得分</strong></p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ot"><img src="../Images/baebc469ba01ca0ff88d2a3c1457d790.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LWbHGDi2KiH68RE_l_WPXQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">训练集和测试集上的阈值后调整分数</strong></p></figure><p id="0339" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">阈值调整显著提高了<strong class="lk jd"> Logit模型在F1、Cohen的kappa和precision-recall AUC指标上的测试分数</strong>。在这三项指标中，SVC和XG Boost模型得分的增长更加适度。然而，<strong class="lk jd"> XG Boost算法凭借在所有三项指标上的最佳测试分数，保住了其顶级性能</strong>的桂冠。<strong class="lk jd">根据培训和测试分数，SVC是第二名</strong>，但<strong class="lk jd"> Logit在测试分数中非常接近第三名</strong>，F1分数略高，但Cohen的kappa和AUC-PR较低。</p><p id="36d9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">有趣的是，所有四个模型的<strong class="lk jd">训练和测试准确性分数都上升了</strong>，尽管准确性分数从来不是网格搜索和校准措施的重点。事实上，所有车型(除NB外)<strong class="lk jd">的<strong class="lk jd">最终测试准确度得分</strong>是整个练习</strong>中最高的。因此，概率阈值调整不仅改善了除RF之外的少数类1的预测，还改善了两个类中模型的总体准确性。这表明，即使在处理平衡数据时，阈值调整也可能是有用的。</p><p id="4d4c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">达到这一点所采取的步骤是:</p><ul class=""><li id="888b" class="nq nr it lk b ll lm lo lp lr ns lv nt lz nu md nv nw nx ny bi translated">启动5个网格搜索调整的<em class="nm">和</em>概率比例模型；</li><li id="7df0" class="nq nr it lk b ll nz lo oa lr ob lv oc lz od md nv nw nx ny bi translated">对完整的<strong class="lk jd">训练数据</strong>进行模型拟合，预测<em class="nm">y _ train</em>；</li><li id="05b9" class="nq nr it lk b ll nz lo oa lr ob lv oc lz od md nv nw nx ny bi translated">导出召回-精度-阈值曲线，并计算每个模型在预测的<em class="nm"> y_train </em>上最大化F1分数的<strong class="lk jd">概率阈值</strong>；</li><li id="ed7f" class="nq nr it lk b ll nz lo oa lr ob lv oc lz od md nv nw nx ny bi translated">最后，预测<em class="nm"> y_test </em>，输出预测概率，应用上面的概率阈值对预测类进行重新分类；</li><li id="a3d7" class="nq nr it lk b ll nz lo oa lr ob lv oc lz od md nv nw nx ny bi translated">对重新分类的类别预测进行评分。</li></ul><p id="f4a7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当然，永远不要将<strong class="lk jd">测试数据</strong>用于任何网格研究、概率缩放或计算最佳概率阈值。通过这种方式，您可以保持测试数据的完整性，作为前面的步骤在提高分类算法性能方面有多成功的最终仲裁者。最后一步，我们转向得到的<strong class="lk jd">混淆矩阵</strong>。</p><h1 id="87ec" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">混淆矩阵</h1><p id="0971" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">让我们看看精度矩阵，以便更好地评估这些模型的细节。为了保持简洁，我将只关注<strong class="lk jd">表现最好的模型——XG Boost和改进最多的模型——逻辑回归</strong>的矩阵。</p><p id="637c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面的图表是<strong class="lk jd"> XGB的混淆矩阵</strong>，左边是后网格搜索矩阵，右边是后阈值调整矩阵。矩阵的右上象限包含预测的<em class="nm">真阳性</em>。两个右侧象限共同组成<em class="nm">预测的</em>正类，两个顶部象限共同保存<em class="nm">实际的</em>正类。</p><p id="6c99" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，后网格搜索矩阵(左)的<strong class="lk jd">精确率为830/(830+1065)= <strong class="lk jd"> 43.80% </strong>，<strong class="lk jd">召回率</strong>为830/(562+830) = <strong class="lk jd"> 59.63% </strong>。对于<strong class="lk jd">后阈值调整矩阵</strong>(右图)<strong class="lk jd">精确率</strong>为799/(799+969) = <strong class="lk jd"> 45.19% </strong>，<strong class="lk jd">召回率</strong>为799/(593+799) = <strong class="lk jd"> 57.40% </strong>。阈值调整提高了召回率，降低了准确率，导致<strong class="lk jd"> F1得分从50.50%小幅攀升至50.57% </strong>。</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ou"><img src="../Images/440153f158ba290b9c20fdaa00596efa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PFMNZ8PEwhDYN_zCtPyVbQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">左侧为网格搜索后矩阵，右侧为阈值调整后矩阵</strong></p></figure><p id="522e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面的图表是<strong class="lk jd"> Logit的混淆矩阵。</strong>后网格搜索矩阵(左)的<strong class="lk jd">准确率为898/(898+1813) = <strong class="lk jd"> 33.12% </strong>，<strong class="lk jd">召回率</strong>为898/(494+898) = <strong class="lk jd"> 64.51% </strong>。对于<strong class="lk jd">后阈值调整矩阵</strong>(右图)<strong class="lk jd">精确率</strong>为795/(795+1055) = <strong class="lk jd"> 42.97% </strong>，<strong class="lk jd">召回率</strong>为795/(597+795) = <strong class="lk jd"> 57.11% </strong>。在这种情况下，阈值调整非常显著地提高了准确率，导致<strong class="lk jd"> F1得分从43.77%跃升至49.04% </strong>。</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ov"><img src="../Images/9f7e2e9a34687f23821a45cb5c5d296c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XtpgkY4AmrI5Pxi3UG2tFw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd no">左侧为网格搜索后矩阵，右侧为阈值调整后矩阵</strong></p></figure><p id="d101" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">基于混淆矩阵，很明显，XGB模型始终比Logit有更好的准确率。换句话说，XGB模型的1类预测更有可能是真正的1类预测。阈值调整有助于大力提高Logit模型的准确率，但仍不足以在这一指标上超过XGB。</p><p id="f21e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果我们考察准确度得分，<strong class="lk jd"> XGB的后gridsearch准确度得分</strong>为(830+9896)/sum(所有象限)= <strong class="lk jd"> 86.83% </strong>，<strong class="lk jd">后阈值调整准确度得分</strong>为(799+9992)/sum(所有象限)= <strong class="lk jd"> 87.36% </strong>。对于<strong class="lk jd"> Logit型号</strong>同样的数字是(898+9148)/sum(所有象限)= <strong class="lk jd"> 81.32% </strong>和(795+9906)/sum(所有象限)= <strong class="lk jd"> 86.63% </strong>。</p><p id="8239" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">细节显示，即使在XGB和Logit模型(右上象限图)中预测的<em class="nm">真阳性</em> <strong class="lk jd">的数量下降</strong>，在阈值调整后，准确度得分仍有所提高。这是因为模型在<strong class="lk jd">变得更好，而不是</strong>误分类<em class="nm">误报</em>(右下象限数字)，对Logit来说尤其如此。</p><h1 id="9f2a" class="mo mp it bd mq mr ms mt mu mv mw mx my ki mz kj na kl nb km nc ko nd kp ne nf bi translated">结论</h1><p id="bcbf" class="pw-post-body-paragraph li lj it lk b ll ng kd ln lo nh kg lq lr ni lt lu lv nj lx ly lz nk mb mc md im bi translated">这是一个<strong class="lk jd">不平衡数据</strong>的例子，大约八个0类目标观测值与一个1类观测值之比。因此，我选择了<strong class="lk jd"> F1分数<em class="nm">和</em>科恩的kappa </strong>作为评分标准。<strong class="lk jd">选择了五个流行的分类模型</strong>(Logit、NB、RF、SVC &amp; XGB)，在将数据分成训练测试集之后，我继续进行通常的<strong class="lk jd">超参数网格搜索</strong>。</p><p id="c22a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">gridsearch-tuned模型的<strong class="lk jd">预测概率</strong>被发现<strong class="lk jd">校准不良</strong>，因此它们必须被缩放以反映真实的观测概率。然后将<strong class="lk jd"> gridsearch-tuned <em class="nm">和</em>概率标度</strong>算法拟合到训练数据中，以预测<em class="nm"> y_train </em>，而不是<strong class="lk jd">朴素贝叶斯</strong>模型，该模型由于其极差的校准结果而被放弃。</p><p id="b16f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下一步是在每个概率阈值下生成精确度和召回率。找到了在<em class="nm"> y_train </em>预测中最大化F1分数的<strong class="lk jd">阈值。然后对模型进行paces预测<em class="nm"> y_test </em>，并提取预测概率。然后根据最大化概率阈值对<strong class="lk jd">类预测进行重新分类</strong>，并进行评分。</strong></p><p id="2b9b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">结果显示，算法的后网格搜索训练<em class="nm">和</em>测试分数<strong class="lk jd">在概率阈值调整后普遍提高</strong>，除了<strong class="lk jd">随机森林</strong>(以及被丢弃的<strong class="lk jd">朴素贝叶斯</strong>)。<strong class="lk jd">逻辑回归</strong>显示测试分数有显著提高，但仍不足以在性能排名中挤掉<strong class="lk jd"> XG Boost </strong>(榜首)和<strong class="lk jd">支持向量分类</strong>(亚军)。</p><p id="cc06" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所有模型的总体<strong class="lk jd">准确度分数</strong>也从阈值调整中受益，尽管准确度从来不是练习的重点。这表明，即使在平衡数据中，调整预测的概率阈值也可能是有用的。总而言之，这些发现展示了使用<strong class="lk jd">预测概率和调整它们的阈值</strong>如何能够提高分类算法的性能。</p><p id="c8aa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">(这个练习的完整Python代码和数据可以在我的<em class="nm"> GitHub </em> <a class="ae mn" href="https://github.com/at-tan/Predicted_Probabilities_Bank_Marketing" rel="noopener ugc nofollow" target="_blank">资源库</a>中找到。如果直接渲染GitHub笔记本文件有问题，使用<a class="ae mn" href="https://nbviewer.org/" rel="noopener ugc nofollow" target="_blank"> nbviewer </a>。)</p></div><div class="ab cl ow ox hx oy" role="separator"><span class="oz bw bk pa pb pc"/><span class="oz bw bk pa pb pc"/><span class="oz bw bk pa pb"/></div><div class="im in io ip iq"><p id="3766" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你在阅读这样的文章中看到了价值，你可以在这里订阅Medium<a class="ae mn" href="https://at-tan.medium.com/membership" rel="noopener"><em class="nm"/></a><em class="nm">来阅读我和无数其他作家的其他文章。谢谢你。</em></p></div><div class="ab cl ow ox hx oy" role="separator"><span class="oz bw bk pa pb pc"/><span class="oz bw bk pa pb pc"/><span class="oz bw bk pa pb"/></div><div class="im in io ip iq"><div class="ks kt ku kv gt pd"><a rel="noopener follow" target="_blank" href="/time-seasonality-features-in-time-series-7e8236f7b04a"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd jd gy z fp pi fr fs pj fu fw jc bi translated">时间序列中的时间和季节性特征</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">以数据为中心，并在模型校准过程中包括季节性选项</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">towardsdatascience.com</p></div></div><div class="pm l"><div class="pn l po pp pq pm pr lb pd"/></div></div></a></div><div class="ps pt gp gr pu pd"><a href="https://medium.datadriveninvestor.com/bitcoins-shifting-relationship-to-macro-factors-5465d542078f" rel="noopener  ugc nofollow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd jd gy z fp pi fr fs pj fu fw jc bi translated">比特币与宏观因素关系的转变</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">使用回归和统计推断来估计自疫情以来的关系变化</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">medium.datadriveninvestor.com</p></div></div><div class="pm l"><div class="pv l po pp pq pm pr lb pd"/></div></div></a></div><div class="ps pt gp gr pu pd"><a rel="noopener follow" target="_blank" href="/stacking-machine-learning-models-for-multivariate-time-series-28a082f881"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd jd gy z fp pi fr fs pj fu fw jc bi translated">多元时间序列的堆积机器学习模型</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">PM 2.5空气污染数据集的个例研究</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">towardsdatascience.com</p></div></div><div class="pm l"><div class="pw l po pp pq pm pr lb pd"/></div></div></a></div><div class="ps pt gp gr pu pd"><a rel="noopener follow" target="_blank" href="/wrangling-through-dataland-modeling-house-prices-in-ames-iowa-75b9b4086c96"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd jd gy z fp pi fr fs pj fu fw jc bi translated">用线性回归破解Ames住房数据集</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">预测和统计推断相结合的模型</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">towardsdatascience.com</p></div></div><div class="pm l"><div class="px l po pp pq pm pr lb pd"/></div></div></a></div></div></div>    
</body>
</html>