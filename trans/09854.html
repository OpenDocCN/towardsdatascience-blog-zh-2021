<html>
<head>
<title>Best Text Aggregation Methods: VLDB 2021 Crowd Science Challenge Revisited</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最佳文本聚合方法:重访VLDB 2021人群科学挑战赛</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/best-text-aggregation-methods-vldb-2021-crowd-science-challenge-revisited-1be2062bdab5?source=collection_archive---------26-----------------------#2021-09-15">https://towardsdatascience.com/best-text-aggregation-methods-vldb-2021-crowd-science-challenge-revisited-1be2062bdab5?source=collection_archive---------26-----------------------#2021-09-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="aa4a" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/9bd372a8cd6f6a8c4a191cf7d6574dab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ajfdThv8WdtNAPLs"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">由<a class="ae kl" href="https://unsplash.com/@joshgmit?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">乔舒亚·戈德</a>在<a class="ae kl" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="3e12" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">今年，<a class="ae kl" href="https://toloka.ai/" rel="noopener ugc nofollow" target="_blank"> Toloka </a>在丹麦哥本哈根举行的世界上最大的数据科学会议之一——<a class="ae kl" href="https://vldb.org/2021/" rel="noopener ugc nofollow" target="_blank">超大规模数据库</a> (VLDB 2021)上领导了一个<a class="ae kl" href="https://crowdscience.ai/conference_events/vldb21" rel="noopener ugc nofollow" target="_blank">群体科学研讨会</a>。作为研讨会的一部分，Toloka研究团队组织了一场竞赛，以确定众包文本文件的最佳聚合方法。所谓的<a class="ae kl" href="https://crowdscience.ai/challenges/vldb21" rel="noopener ugc nofollow" target="_blank">群众科学挑战</a>提供6000美元的现金奖励，其中3000美元给获胜者，2000美元给亚军，剩下的1000美元给第三名。至关重要的是，作为这场激动人心的比赛的结果，我们能够找到聚合众包文本的最佳方法。</p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi lk"><img src="../Images/5ba192770c9fb8a83116f1aaa5e35d3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RbqrhYammMvacgzm7tZSaQ.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated"><em class="lp">文本聚合</em></p></figure><p id="963c" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为什么大惊小怪？</p><p id="7000" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">大多数众包任务都是关于分类的:众包执行者必须从一组预定义的选项中选择正确的答案。然而，一些任务需要内容生成、音频注释或对象选择。由于这些任务需要的答案超出了多项选择的范围，因此通常需要手工检查作业。出于这个原因，两个标签项目并行运行——一个收集来自群众演员(我们也称之为Tolokers)的提交，另一个在项目中涉及的其他演员验证后接受或拒绝这些提交。验收后，绿灯Tolokers得到相应的报酬。</p><p id="3f50" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们感兴趣的问题是，这两个阶段的过程是否可以被绕过，整个机制是否可以自动化。</p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi lq"><img src="../Images/6c4594ee85e6d70b8e2b9e563d37c593.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WiYSoyVo_xGGRkYwntaukg.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated"><em class="lp">转录音频→验证转录</em></p></figure><p id="de60" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">开拓者和超越者</p><p id="735a" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们绝不是第一个想到或试图这样做的人。90年代，<a class="ae kl" href="https://ieeexplore.ieee.org/document/659110" rel="noopener ugc nofollow" target="_blank">识别器输出表决误差减少</a> (ROVER)被开发出来。它使用动态编程从几种可能的预测中提供一种新的高质量的语音识别预测。由于这种方法在众包中被广泛认可(<a class="ae kl" href="https://ieeexplore.ieee.org/document/5494979" rel="noopener ugc nofollow" target="_blank"> Marge et。，2010 </a>，我们选择它作为我们的基线。因此，一种新的聚合方法不仅有望展示最好的结果，而且有望在相同的数据集上超过ROVER。</p><p id="4282" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">当然，在过去的30年里，同样的问题还有其他的解决方案。其中有一类RASA和HRRASA方法(<a class="ae kl" href="https://dl.acm.org/doi/10.1145/3397271.3401239" rel="noopener ugc nofollow" target="_blank">李，2020 </a>)，它们使用类似BERT的语言转换器来聚合文本。这些方法使用检索方法解决聚集问题；然而，从我们的经验来看，它们通常不如ROVER工作得好。尽管如此，它们也包括在基准中以供参考。</p><p id="ce5f" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因此，最好的聚合方法应该能够处理大量嘈杂的转录，并提供与相应音频文件精确匹配的最佳文本版本。作为评估标准，我们使用平均单词准确度(AWAcc)。</p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi lr"><img src="../Images/813a62732d2ba2cbc54fbb0db9518c3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LjTO5g7oHvAsQF3ByvYaaQ.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated"><em class="lp">转录音频→谢谢！</em></p></figure><p id="68e0" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">数据准备</strong></p><p id="fe91" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于我们的竞争，我们决定使用一个全新的、<a class="ae kl" href="https://www.openslr.org/12" rel="noopener ugc nofollow" target="_blank">类似LibriSpeech </a>的数据集，它不会类似于任何其他东西。以下是我们为此所做的准备:</p><p id="c2a0" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">1.选自维基百科和图书语料库的随机句子。</p><p id="f386" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">2.丢弃很短或很长的句子，以及包含数字的句子。</p><p id="492c" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">3.使用<a class="ae kl" href="https://cloud.yandex.ru/services/speechkit" rel="noopener ugc nofollow" target="_blank"> Yandex SpeechKit </a>生成所选句子的音频版本。</p><p id="7bb8" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">4.在Toloka上发起了一个标签项目，要求表演者转录音频文件。</p><p id="4db4" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">5.为每段录音收集了一些注释。</p><p id="60d2" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">(正确答案提前知道)。</p><p id="1616" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">正如大多数ML竞赛一样，我们将过程分为一个训练(“训练”)和两个测试阶段(“公开测试”和“私人测试”)。“训练”用于训练和调整竞争的ML模型，“公开测试”用于评估比赛过程中的质量，“私人测试”用于确定获胜者并结束比赛。我们从3，039名群众工作者那里收集了总共99，414条音频注释，转录了9，700条音频记录。</p><p id="35e3" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">数据</strong></p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ls"><img src="../Images/26e5c03a27394a02e50d4ee3db5fb478.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4JCh7zxvl1Hm9mz5HuVy7A.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">挑战中使用的所有数据都可以在<a class="ae kl" href="https://github.com/Toloka/VLDB2021_Crowd_Science_Challenge" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上获得。</p></figure><p id="114b" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">描述本次比赛整个数据准备过程的研究论文已在<strong class="ko ja"> NeurIPS 2021数据集和基准赛道</strong>上发表，并在<a class="ae kl" href="https://openreview.net/forum?id=3_hgF1NAXU7" rel="noopener ugc nofollow" target="_blank">此处</a>提供。</p><p id="01f2" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja"> VLDB大赛</strong></p><p id="0993" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">ML比赛通常在<a class="ae kl" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank">赛道</a>、<a class="ae kl" href="https://www.aicrowd.com/" rel="noopener ugc nofollow" target="_blank">赛道</a>或<a class="ae kl" href="https://competitions.codalab.org/" rel="noopener ugc nofollow" target="_blank">赛道</a>举行。权衡各种选择后，我们最终选择了Yandex。谁能够为我们提供优先支持。</p><p id="633d" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">除了想出最好的转录文本聚合方法，参赛者还被邀请提交他们方法的书面描述，我们后来在我们的研讨会记录中发表了这些描述。托洛卡还向有意愿和能力的参与者提供竞赛资助。</p><p id="e9d0" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">VLDB 2021人群科学挑战赛时间表如下:</p><ul class=""><li id="322b" class="lt lu iq ko b kp kq kt ku kx lv lb lw lf lx lj ly lz ma mb bi translated">2021年4月15日——比赛启动，训练阶段开始(“训练”)</li><li id="d704" class="lt lu iq ko b kp mc kt md kx me lb mf lf mg lj ly lz ma mb bi translated">2021年5月5日——主要比赛阶段开始(“公开测试”+“私人测试”)</li><li id="9bb0" class="lt lu iq ko b kp mc kt md kx me lb mf lf mg lj ly lz ma mb bi translated">2021年6月18日—比赛结束</li><li id="3606" class="lt lu iq ko b kp mc kt md kx me lb mf lf mg lj ly lz ma mb bi translated">2021年7月5日—概述汇总方法的论文提交截止日期</li><li id="e62e" class="lt lu iq ko b kp mc kt md kx me lb mf lf mg lj ly lz ma mb bi translated">2021年8月20日— <a class="ae kl" href="https://crowdscience.ai/conference_events/vldb21" rel="noopener ugc nofollow" target="_blank"> VLDB 2021人群科学研讨会</a></li></ul><p id="84d6" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">获奖者和荣誉奖</strong></p><p id="6b8a" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">由于ROVER和HR/RASA显示的AWAcc值分别等于92.25%和91.04%，我们一直在寻找具有更好结果的模型。共有18名参赛者参加，其中只有8人在活动的“私人测试”阶段展示了超过ROVER基线的平均单词准确度值。需要注意的是，包含大规模语言模型的HR/RASA方法最终未能给人留下深刻印象。以下是挑战赛的三名获胜者以及那些想出了巧妙解决方案但没有获胜的参赛者:</p><ul class=""><li id="e864" class="lt lu iq ko b kp kq kt ku kx lv lb lw lf lx lj ly lz ma mb bi translated"><strong class="ko ja">第一名</strong> (AWAcc = 95.73%)。最好的方法是用于文本摘要的微调BART模型。为了在训练中调整模型，参赛者打乱了所有提交的转录，随后用美国英语单词替换英国英语。<strong class="ko ja">令人惊讶的是，一个成功的文本聚合方法依赖于一个执行良好的文本摘要策略</strong>。</li><li id="43e8" class="lt lu iq ko b kp mc kt md kx me lb mf lf mg lj ly lz ma mb bi translated"><strong class="ko ja">第二名</strong> (AWAcc = 95.66%)。在使用微调的T5模型进行自动文本摘要之前，这位参赛者还尝试了许多seq2seq方法。他们的方法证实了获胜方法的有效性；然而，亚军可能由于缺乏模型正规化而缺乏一致性。</li><li id="9e91" class="lt lu iq ko b kp mc kt md kx me lb mf lf mg lj ly lz ma mb bi translated"><strong class="ko ja">第三名</strong> (AWAcc = 95.48%)。该值是不同信号的线性组合的结果，包括BERT、假设分类器和执行者特征，如答案的数量及其一致性。值得注意的是，这是我们在比赛的三个获胜者中看到的唯一一个真正考虑表演者技能的方法。此外，这位参赛者使用了我们提供的一笔资助来完善他们的方法。</li><li id="6d4e" class="lt lu iq ko b kp mc kt md kx me lb mf lf mg lj ly lz ma mb bi translated"><strong class="ko ja">第四名</strong> (AWAcc = 95.00%)。这个参与者使用了一个经过微调的T5模型，并使用<a class="ae kl" href="https://github.com/microsoft/LightGBM" rel="noopener ugc nofollow" target="_blank"> LightGBM </a>对注释进行了排序。这种方法虽然值得称赞，但产生的输出不如前三种精确。</li><li id="f56f" class="lt lu iq ko b kp mc kt md kx me lb mf lf mg lj ly lz ma mb bi translated"><strong class="ko ja">第六名</strong> (AWAcc = 93.37%)。事实证明，人们可以使用Levenshtein距离的中值来提出可行的解决方案。但是这种方法意味着一个非常仔细的执行者选择试探法，它极大地影响了结果。</li></ul><p id="7867" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">结果和结论</strong></p><p id="6253" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">感谢VLDB 2021人群科学挑战赛，我们能够获得一种可靠的文本聚合方法，成功地将ROVER在我们的新数据集上的错误率减半，从7.75%降至4.27%。</p><p id="31cb" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们收到了来自不同背景和观点的人的解决方案，有趣的是，事实证明，总的来说，整合音频转录和文本的任务是一个自动文本摘要问题。此外，我们了解到一些基于语言的模型显示了不错的结果，在这种情况下，大多数检索方法都不是特别好，并且ROVER不再是无可争议的音频转录聚合之王。第一名获胜者提供的方法将被添加到我们的<a class="ae kl" href="https://github.com/Toloka/crowd-kit" rel="noopener ugc nofollow" target="_blank">众包</a>中，这是一个用于众包的开源Python库。<strong class="ko ja">这并不意味着问题已经完全解决，但它确实意味着已经取得了相当大的进展。</strong></p><p id="41da" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们的研讨会记录包括题为VLDB 2021 <a class="ae kl" href="http://ceur-ws.org/Vol-2932/invited1.pdf" rel="noopener ugc nofollow" target="_blank">关于聚合众包音频转录的众包科学挑战</a>的论文，其中包含对竞赛及其结果的更详细描述。还有两篇论文概述了竞赛冠军<a class="ae kl" href="http://ceur-ws.org/Vol-2932/short1.pdf" rel="noopener ugc nofollow" target="_blank">和亚军</a>和亚军<a class="ae kl" href="http://ceur-ws.org/Vol-2932/short2.pdf" rel="noopener ugc nofollow" target="_blank">使用的汇总方法。</a></p></div></div>    
</body>
</html>