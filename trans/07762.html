<html>
<head>
<title>Introduction to Normalizing Flows</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">标准化流程简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-normalizing-flows-d002af262a4b?source=collection_archive---------0-----------------------#2021-07-16">https://towardsdatascience.com/introduction-to-normalizing-flows-d002af262a4b?source=collection_archive---------0-----------------------#2021-07-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e70a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">为什么以及如何实现gan和vae上的标准化流</h2></div><p id="df85" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">学习复杂数据表示的表示是机器学习中的一个基本问题。这项任务的重要性在于可以获得大量非结构化和无标签的数据，这些数据只能通过无监督学习来理解。它可以应用于密度估计、离群点检测、文本摘要、数据聚类、生物信息学、DNA建模等。多年来，已经引入了许多方法来学习大数据集的概率分布。这些技术包括生成式对抗网络(GANs)、变分自动编码器(VAEs)和规范化流程。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lb"><img src="../Images/cabfdc028f23b9da507303d8197644a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*4Ow5vrz9u3KJp7NJh8FHPA.png"/></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">来自发光模型的样本(<a class="ae ln" href="https://papers.nips.cc/paper/2018/file/d139db6a236200b21cc7f752979132d0-Paper.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="ff83" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">GANs和VAEs在学习复杂的数据分布和简单的推理方法方面显示了令人惊叹的结果。然而，GAN和VAE都缺乏对概率分布的精确评估和推断，这通常导致VAEs中的低质量模糊结果，并且在GAN中具有挑战性的GAN训练具有诸如模式崩溃和消失梯度后验崩溃等挑战。通过使用可逆函数，标准化流被提出来解决gan和vae的许多当前问题。</p><h1 id="2d64" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">标准化流程</h1><p id="5d4f" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">简而言之，标准化流是一系列可逆的简单函数，或者可以计算出函数的解析逆。例如，f(x) = x + 2是可逆函数，因为对于每个输入，存在唯一的输出，反之亦然，而f(x) = x不是可逆函数。这种函数也称为双射函数。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ml"><img src="../Images/fd3b0a5c6b7a908751fdbbd872e0dda8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wR6mfpyRY5Xbm5EPrLPNUw.png"/></div></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">(来源:作者)</p></figure><p id="fc29" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从上图可以看出，归一化流程将复杂的数据点(如MNIST图像)转换为简单的高斯分布，反之亦然。从训练生成器的GANs中可以看出明显的差异，该生成器采用随机向量并产生图像，其中基于流量的模型在训练期间从数据点转换为简单分布。在测试期间，从高斯分布中抽取随机样本，以从模型反向获得MNIST图像。</p><p id="541a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用负对数似然损失函数训练基于流量的模型，其中p(z)是概率函数。下面的损失函数是利用基本统计学中的变量变化公式得到的。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mq"><img src="../Images/6729d62a1ab98515a1d90954265ab40c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DgSWBiBf-GOP4ybs88IWHQ.png"/></div></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">(<a class="ae ln" href="https://papers.nips.cc/paper/2018/file/d139db6a236200b21cc7f752979132d0-Paper.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h1 id="b6e6" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">标准化流程的优势:-</h1><p id="7928" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">规范化流提供了各种优于GANs和VAEs的优势。其中一些列举如下</p><ul class=""><li id="c84f" class="mr ms iq kh b ki kj kl km ko mt ks mu kw mv la mw mx my mz bi translated">标准化流模型不需要在输出中加入噪声，因此可以具有更强大的局部方差模型。</li><li id="e5e9" class="mr ms iq kh b ki na kl nb ko nc ks nd kw ne la mw mx my mz bi translated">与GAN的GAN训练相比，基于流的模型的训练过程非常稳定，GAN训练需要仔细调整生成器和鉴别器的超参数。</li><li id="455a" class="mr ms iq kh b ki na kl nb ko nc ks nd kw ne la mw mx my mz bi translated">与GANs和VAEs相比，标准化流更容易收敛。</li></ul><h1 id="fb24" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">标准化流程的缺点:-</h1><p id="fbee" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">虽然基于流的模型有其优点，但它们也有如下一些缺点</p><ul class=""><li id="ee14" class="mr ms iq kh b ki kj kl km ko mt ks mu kw mv la mw mx my mz bi translated">由于流模型在密度估计等任务上表现平平，人们认为它们不如其他方法有表现力。</li><li id="3ab4" class="mr ms iq kh b ki na kl nb ko nc ks nd kw ne la mw mx my mz bi translated">流动模型双射的两个要求之一是变换时的体积保持，这通常导致非常高维的潜在空间，这通常更难解释。</li><li id="de31" class="mr ms iq kh b ki na kl nb ko nc ks nd kw ne la mw mx my mz bi translated">与GANs和VAEs相比，通过基于流量的模型生成的样本没有那么好。</li></ul><p id="d070" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了更好的理解，我们以Glow架构为例，这是OpenAI在2018年提出的基于流程的模型。下图显示了Glow架构。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/ffee0e2b2b0e12f9e6013e2e7aed80ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*IEgeGoFGD7lKfYJSOVidzw.png"/></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">发光建筑(<a class="ae ln" href="https://papers.nips.cc/paper/2018/file/d139db6a236200b21cc7f752979132d0-Paper.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="9d96" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">glow架构是由本文后面讨论的一些表面层组合而成的。首先，我们将通过辉光模型的多尺度架构。光晕模型由一系列重复层(称为“比例”)组成。每个秤都包含一个挤压功能，后跟一个流动步骤。每个流程步骤都包含ActNorm、1x1卷积和耦合层，后跟一个分裂函数。分裂函数在通道维度上将输入分成两个相等的部分，其中一半进入进一步的层。相比之下，后半部分去损失函数。进行分割是为了减少梯度消失的影响，当以端到端的方式训练模型时，会发生梯度消失。</p><p id="f1f8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">挤压函数</strong>通过对张量进行横向整形，将大小为[c，h，w]的输入张量转换为大小为[4*c，h/2，w/2]的张量，如下所示。此外，在整形期间，可以在测试阶段使用函数来将输入[4*c，h/2，w/2]整形为大小为[c，h，w]的张量。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/ffeec51f64efe64dc527f573bd1470e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*FCWNCv3jVjCwLEGHoVQoUw.png"/></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">(<a class="ae ln" href="https://arxiv.org/pdf/1605.08803.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="3156" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其他层如ActNorm、1x1卷积和仿射耦合层可以从下表中理解，该表以正向和反向方式显示了每层的功能。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nh"><img src="../Images/d7b7832d1790f51f570c0ea202fa8d2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jbIZZetlYupHcMO7BgCbBQ.png"/></div></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">(<a class="ae ln" href="https://arxiv.org/pdf/1605.08803.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><h1 id="143f" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">实施:</h1><p id="f3bc" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">在讨论了标准化流程和发光模型的基础知识后，我们将使用PyTorch实现该模型，并在MNIST数据集上进行训练。</p><h2 id="b953" class="ni lp iq bd lq nj nk dn lu nl nm dp ly ko nn no ma ks np nq mc kw nr ns me nt bi translated">发光模型:</h2><p id="7496" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">首先，我们将使用PyTorch和nflows实现Glow架构，它包含所有层的实现，以节省实验时间。</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="bc24" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该模型可以在各种数据集上进行训练，例如MNIST、CIFAR-10、ImageNet等。在本文中，我们将仅限于MNIST数据集。像<a class="ae ln" href="https://www.google.com/url?q=https://gas.graviti.com/dataset/hellodataset/MNIST?utm_medium%3D0715Aryansh_1&amp;sa=D&amp;source=editors&amp;ust=1626367404346000&amp;usg=AOvVaw1rp0JNNJALdWZzSHQookR_" rel="noopener ugc nofollow" target="_blank"> MNIST </a>这样的数据集可以很容易地从<a class="ae ln" href="https://www.google.com/url?q=https://gas.graviti.com/open-datasets?utm_medium%3D0715Aryansh_1&amp;sa=D&amp;source=editors&amp;ust=1626367404343000&amp;usg=AOvVaw0tJPuwlGEGCSvWApwkLipF" rel="noopener ugc nofollow" target="_blank"> Graviti的开放数据集平台</a>中访问，该平台包含机器学习中常用的所有开放数据集，用于各种任务，如分类、密度估计、对象检测和基于文本的分类数据集等。</p><p id="b283" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要访问一个数据集，用户需要<a class="ae ln" href="https://www.google.com/url?q=https://account.graviti.com/sign-in/?callback%3Dhttps%253A%252F%252Fgas.graviti.com%252Fopen-datasets?utm_medium%3D0715Aryansh_1&amp;sa=D&amp;source=editors&amp;ust=1626367404344000&amp;usg=AOvVaw1vZLkDjshAEOYWBjYMiZn1" rel="noopener ugc nofollow" target="_blank">在Graviti平台上创建一个账户</a>，派生相关数据集以下载并导入他们管道中的数据集。基本代码片段和相关文档可在<a class="ae ln" href="https://www.google.com/url?q=https://graviti.com/tensorBay?utm_medium%3D0715Aryansh_1&amp;sa=D&amp;source=editors&amp;ust=1626367404346000&amp;usg=AOvVaw0nkt_CgI2ieUAczctfCQGk" rel="noopener ugc nofollow" target="_blank"> TensorBay </a>平台上获得。</p><p id="d24a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为MNIST数据集创建PyTorch数据集的代码示例如下所示。</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h2 id="cd15" class="ni lp iq bd lq nj nk dn lu nl nm dp ly ko nn no ma ks np nq mc kw nr ns me nt bi translated">训练模型:</h2><p id="960b" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">要训练模型，可以编写一个简单的脚本，如下所示。该代码使用Graviti tensorbay管道创建数据加载器。ACCESS_KEY可以从accounts部分的设置中获得。</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="9d8c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以上脚本用于为MNIST数据集训练规范化流量模型。通过替换相应数据集的数据加载器，可以类似地训练其他数据集的模型。</p><h2 id="38cb" class="ni lp iq bd lq nj nk dn lu nl nm dp ly ko nn no ma ks np nq mc kw nr ns me nt bi translated">生成样本:</h2><p id="b792" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">在为两个数据集训练模型之后，我们可以生成如下样本</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="e87d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">nflows库提供了一种仅使用一行代码生成样本的完美方式。显示功能在正方形网格中显示生成的样本。为两个数据集生成的样本如下</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/8f47a3804db7084c98de3add145cdca8.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*xJpIJYFO4w-xzZ6tB_wpog.png"/></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">在MNIST数据集上生成的样本</p></figure><h1 id="6098" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">结论:</h1><p id="c780" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">本文介绍了标准化流的基本知识，并将其与其他gan和vae进行了比较，然后讨论了Glow模型。我们还实现了发光模型，并使用MNIST数据集对其进行了训练，并从两个数据集采样了25幅图像。在Graviti的开放数据集平台的帮助下，数据集可以更容易地访问。除了采样之外，还可以使用潜在空间向量来做更多的事情，比如让一张脸微笑或者改变性别或头发颜色，以及许多其他事情。</p></div></div>    
</body>
</html>