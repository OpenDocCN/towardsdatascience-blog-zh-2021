<html>
<head>
<title>Image Segmentation with Classical Computer Vision-Based Approaches</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于经典计算机视觉方法的图像分割</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-segmentation-with-classical-computer-vision-based-approaches-80c75d6d995f?source=collection_archive---------7-----------------------#2021-09-12">https://towardsdatascience.com/image-segmentation-with-classical-computer-vision-based-approaches-80c75d6d995f?source=collection_archive---------7-----------------------#2021-09-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2248" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">经典的基于计算机视觉的图像分割方法，如阈值分割，基于区域，基于边缘检测和形态学分割，将在1篇文章中解释，以便快速了解这个领域</h2></div><p id="df8b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">图像分割是将数字图像细分成多个片段(对象)的过程。分割的目标是将图像的表示变成更有意义和更容易分析的东西。我们可以组合不同的分割方法，如下所示。</p><ul class=""><li id="f930" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">经典的基于计算机视觉的方法</li></ul><ol class=""><li id="d8bf" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld ln lk ll lm bi translated">阈值处理</li><li id="7051" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld ln lk ll lm bi translated">基于区域的方法</li><li id="aded" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld ln lk ll lm bi translated">基于边缘/边界的方法</li></ol><ul class=""><li id="8236" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">基于人工智能的方法</li></ul><ol class=""><li id="fdb2" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld ln lk ll lm bi translated"><a class="ae lt" rel="noopener" target="_blank" href="/image-segmentation-with-clustering-b4bbc98f2ee6">基于聚类的方法</a></li><li id="f65a" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld ln lk ll lm bi translated">神经网络</li></ol><p id="05c3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，我将回顾经典的基于计算机视觉的方法，你可以阅读我的基于聚类的方法的文章，并关注神经网络的文章！</p><h1 id="a1b7" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">阈值处理</h1><p id="dfb5" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">阈值处理是分割图像的最简单的方法，它根据图像像素的亮度值将其分成不同的组。通常，它用于获取二值图像，将图像分割成两部分。主要思想是选择一个阈值T，将低于该阈值的像素值改为0 <strong class="kk iu">(背景像素)</strong>，将较高的像素值改为1 <strong class="kk iu">(前景像素)</strong>。如果要保留图像数据类型，可以选择0作为背景像素，选择该数据类型的最大值作为前景像素值。例如，如果您使用uint8数据类型图像，您的图像像素可以采用的最大值是255，因此将255分配给前景像素，将0分配给背景像素也是一种适用的方法。</p><p id="283d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">全局阈值<br/> </strong>阈值是在开始时选定的，在处理过程中不能改变。您可以<strong class="kk iu">手动</strong>选择阈值，或者使用Otsu阈值法根据图像直方图自动<strong class="kk iu">获得阈值</strong>。</p><p id="ed60" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mr">基本阈值</em></p><p id="a668" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">手动选择阈值T。</p><p id="508e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以使用OpenCV的阈值函数和cv2非常容易地应用基本阈值。THRESH_BINARY选项。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="5bb7" class="nb lv it mx b gy nc nd l ne nf">import cv2<br/>import numpy as np</span><span id="625c" class="nb lv it mx b gy ng nd l ne nf">img = cv2.imread("dog.jpg", cv2.IMREAD_GRAYSCALE)<br/>_, segmented1 = cv2.threshold(img, 127,255,cv2.THRESH_BINARY)<br/>print(segmented1)</span><span id="617d" class="nb lv it mx b gy ng nd l ne nf">cv2.imshow("Segmented Output Image", segmented1)<br/>cv2.waitKey(0)</span></pre><p id="9516" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里，127是阈值，255是分配给前景像素的值。</p><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi nh"><img src="../Images/7cf2b80cb76ac13edc6bc31395cc7ad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d-mNNgGRQbDtXqXIGHMEPg.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">背景像素= 0，前景像素= 255的基本阈值“作者图像”</p></figure><p id="031d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">OpenCV的threshold函数返回与输入图像具有相同数据类型的分割图像。因此，如果您希望前景像素为1，背景像素为0，您将看到如下所示的错误结果:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="9255" class="nb lv it mx b gy nc nd l ne nf">_, segmented1 = cv2.threshold(img, 127,1,cv2.THRESH_BINARY)<br/>print(segmented1)</span><span id="a252" class="nb lv it mx b gy ng nd l ne nf">cv2.imshow("Segmented Output Image", segmented1)<br/>cv2.waitKey(0)</span></pre><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/31173f77d0055f3d37ffc4f59d40dfce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*NsmyrptTbh_I_qZCX3bZ8Q.png"/></div><p class="np nq gj gh gi nr ns bd b be z dk translated">“作者提供的图像”</p></figure><p id="a4b0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">即使分割是正确的，以至于我们在图像像素中看到了1和0，但是在输出图像中，我们的前景像素(1)在哪里呢？</p><p id="ff12" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们想与OpenCV的功能更紧密地合作，这是非常重要的一点。正如我所说的，cv2.threshold函数为我们提供了一个与输入图像具有相同数据类型的分割图像。由于我们的“dog.jpg”图像来自uint8数据类型，因此像素范围在0和255之间，当我们的输出图像在0和255范围内只有0和1时，0和1都对应于黑色像素！为了做到这一点，我们需要将输出图像数据类型改为float32:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="9fbd" class="nb lv it mx b gy nc nd l ne nf">_, segmented2 = cv2.threshold(img, 127,1,cv2.THRESH_BINARY)<br/>segmented2 = segmented2.astype(dtype='f')<br/>print(segmented2)</span><span id="54bb" class="nb lv it mx b gy ng nd l ne nf">cv2.imshow("Segmented Output Image", segmented1)<br/>cv2.waitKey(0)</span></pre><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi nu"><img src="../Images/bdb1264c4dea38eb5fbf4cc3f3181325.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZDuHbtGfRoNB_FB76Ie7xQ.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">背景像素= 0，前景像素= 1的基本阈值“作者图像”</p></figure><p id="1177" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里又是正确的输出！</p><p id="5e10" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意，具有0或1值和0或255值的两个图像都是<strong class="kk iu">二进制</strong>，因为它们只有两种类型的像素值。</p><p id="75ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mr">大津阈值法</em></p><p id="d0bb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是一种自动阈值决定方法，试图<strong class="kk iu">最小化</strong>下面的等式以获得最佳的t</p><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi nv"><img src="../Images/b2c30537f777b4c4eaeecfaaa4d24d37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FBfBhQWoliDfOVHjMNaqDw.png"/></div></div></figure><p id="b6c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Po:前景像素根据阈值T的概率<br/> Pb:背景像素根据阈值T的概率</p><p id="679f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">σ o:前景像素的方差<br/> σ b:背景像素的方差</p><p id="6f2d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以使用OpenCV的阈值函数和cv2非常容易地应用Otsu阈值。OTSU选项。这一次，我们可以使用函数的第一个返回值来查看选择的阈值是什么。THRESH_BINARY中不存在这个选项，因为是我们已经给出了阈值。😉</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="177b" class="nb lv it mx b gy nc nd l ne nf">thresh, segmented2 = cv2.threshold(img, 127,1,cv2.THRESH_OTSU)<br/>segmented2 = segmented2.astype(dtype='f')<br/>print(thresh)<br/>print(segmented2)</span><span id="4f7f" class="nb lv it mx b gy ng nd l ne nf">cv2.imshow("Segmented Output Image", segmented2)<br/>cv2.waitKey(0) <br/>cv2.destroyAllWindows()</span></pre><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi nw"><img src="../Images/e48e3e7324f9cf0c53fda97f11115415.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aZ4_vN5XtSfDCG7WnNC1YQ.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">Otsu阈值，我们看到Otsu给我们119作为阈值“作者的图像”</p></figure><p id="687f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">局部阈值处理</strong></p><p id="ef92" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在局部阈值处理中，对于给定大小的区域，不是全局地而是局部地选择阈值。为此，我们取停留在该区域的像素的平均值，从该平均值中减去一个常数值C，就得到我们的阈值！</p><p id="3e1b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">局部阈值化背后的思想是图像可以在不同的区域暴露于不同的光。用于整个图像的通用阈值可能不适用于这种例外区域。因此，全局阈值化对于这种图像来说不是最好的方法，对于不同的光线条件选择不同的阈值会给我们带来更好的结果。</p><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi nx"><img src="../Images/eae9383bdd1e6e5074985da9673f07ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DpQXXneB-z0Ck_OlO-Hs1g.png"/></div></div></figure><p id="4115" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个问题中，我们需要决定<strong class="kk iu"> n、</strong> <strong class="kk iu"> C、</strong>和<strong class="kk iu">平均值的计算方法。</strong>对于局部阈值处理，有两种不同的常用方法来计算平均值。您可以选择<strong class="kk iu">标准平均值计算</strong>，将所有像素强度相加，然后除以该区域中的像素数量，或者您可以使用<strong class="kk iu">高斯平均值</strong>(或加权平均值)，其中距离区域中心最近的像素的强度贡献更大——为计算加权。</p><p id="c7f5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">选择n 是另一个问题:太大的n可能导致与全局阈值处理类似的输出，因为它没有将图像分割成足够小的区域，而太小的n可能导致该区域不包含像素多样性。</p><p id="2855" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以使用OpenCV cv2应用自适应阈值。自适应阈值函数很容易:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="d568" class="nb lv it mx b gy nc nd l ne nf">segmented4 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,15,2)<br/>print(segmented4)</span><span id="9684" class="nb lv it mx b gy ng nd l ne nf">cv2.imshow("Segmented Output Image", segmented4)<br/>cv2.waitKey(0)</span><span id="1402" class="nb lv it mx b gy ng nd l ne nf">segmented5 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,15,2)<br/>print(segmented5)</span><span id="2b33" class="nb lv it mx b gy ng nd l ne nf">cv2.imshow("Segmented Output Image", segmented5)<br/>cv2.waitKey(0)</span></pre><p id="8336" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 255 </strong>是前景像素的值，<strong class="kk iu"> ADAPTIVE_THRESH_MEAN_C </strong>是选择局部阈值计算的标准均值方法，<strong class="kk iu">ADAPTIVE _ THRESH _ GAUSSIAN _ C</strong>是高斯均值。<strong class="kk iu">看到我们还在用cv2。THRESH_BINARY </strong>！这意味着，在局部选择我们的阈值之后，我们应用简单的阈值方法来决定一个像素是前景像素还是背景像素。<strong class="kk iu"> 15 </strong>是区域n的大小，所以我们对于每个局部区域有一个15×15的窗口，2 <strong class="kk iu"> </strong>是常量值c。</p><p id="2456" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种情况下，不同参数的一些输出结果如下所示:</p><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi ny"><img src="../Images/9e976e0f410e472dbba434833d5e2479.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hKARzUqaiL-3nFdrTWJyMA.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">“作者提供的图像”</p></figure><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/82f485670d27b0b1534b9b6d6f9d752c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*DSdMWpDMHrvnZLgY482s-g.jpeg"/></div><p class="np nq gj gh gi nr ns bd b be z dk translated">“作者提供的图像”</p></figure><p id="a74c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于随着<strong class="kk iu">增加C </strong>，<strong class="kk iu">阈值减少</strong>，我们在输出中看到<strong class="kk iu">更多的前景像素</strong>。</p><p id="cdf4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">可能不太清楚自适应阈值在这里做什么，因为来自全局阈值的结果也被很好地分割。现在，让我们来看一些在不同区域有光线差异或标记了不同颜色的图像:</p><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oa"><img src="../Images/fee85ada1c2c8550dd602419901ab609.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c0xkNHd-SmSf9-Y2E3akgQ.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">“作者提供的图像”</p></figure><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi ob"><img src="../Images/1feea913c8c196e1d87de9bbf365834a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aUwlcQGHY7VilIDa17_jlA.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">“作者提供的图像”</p></figure><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oc"><img src="../Images/18caf4d82dfe0feff05adf62293d1ae2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*90YL5EMRFuid9GMTpjuNPg.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">“作者提供的图像”</p></figure><p id="129e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们可以看到，对于这些图像，局部阈值处理要比全局阈值处理好得多。以书籍为例，自适应阈值处理的输出初看起来可能更嘈杂、更复杂，但如果你仔细观察，你会发现，在全局阈值处理中有一些部分丢失了，这是我们在课堂上再也看不到的，而自适应阈值处理则不是这样。</p><p id="a482" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最终，选择哪种阈值方法取决于您和您的图像类型！</p><p id="0778" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以上就是图像分割与阈值分割，相关代码可以在我的<a class="ae lt" href="https://github.com/YCAyca/Image-Segmentation/tree/main/Thresholding" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu"> GitHub </strong> </a>链接中找到，现在让我们继续下一个话题✋</p></div><div class="ab cl od oe hx of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="im in io ip iq"><h1 id="39d3" class="lu lv it bd lw lx ok lz ma mb ol md me jz om ka mg kc on kd mi kf oo kg mk ml bi translated">基于区域的图像分割</h1><p id="a86d" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">在本帖中，我们将回顾基于“区域”方法的图像分割方法，其中使用了像素之间的邻域和连接关系。如果你对<strong class="kk iu">邻域</strong>、<strong class="kk iu">连接</strong>、<strong class="kk iu">连通分量</strong>术语没有任何概念，可以<a class="ae lt" href="https://yagmurcigdemaktas.medium.com/neighborhood-connections-and-connected-components-cedf922dd383" rel="noopener"> <strong class="kk iu">点击</strong> </a>看我的简短帖子。</p><p id="ee85" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">区域生长</strong></p><p id="99e8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一种基于区域的方法是区域生长，我们选择<strong class="kk iu">种子</strong>点，让种子按照符合一组规则的像素生长。有一套不同的规则来决定增长的过程和停止的条件，这里我们将研究两种不同的方法。</p><p id="6e91" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一种方法:</p><ol class=""><li id="778e" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld ln lk ll lm bi translated">从那个种子像素开始，我们查看种子的<strong class="kk iu">4-连接</strong>或<strong class="kk iu">8-连接</strong>像素。4还是8，看你的选择。</li><li id="e9e5" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld ln lk ll lm bi translated">在那些有可能被添加到该区域中的像素中，选择与该区域的平均强度具有最小距离 <strong class="kk iu">的像素<strong class="kk iu">。如果该距离低于确定的“<strong class="kk iu">相似性阈值</strong>，则我们最终将该像素添加到该区域中。</strong></strong></li><li id="f814" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld ln lk ll lm bi translated">当一个新的像素被添加到该区域时，现在它就是我们的<strong class="kk iu">新种子，</strong> so 1。第二。将对该种子点<strong class="kk iu">重复这些步骤，直到</strong>在种子的邻域中不存在任何符合这些规则的可能像素(因此它不能再增长)或者图像中的所有像素已经被分类。</li></ol><p id="5459" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我不认为OpenCV有一个内置的区域增长算法函数，但是我准备了一个实现来按照我上面解释的规则做一些实验。首先，在尝试真实图像之前，让我们来看看2D阵列的一些结果，以便更好地了解发生了什么:</p><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div class="gh gi op"><img src="../Images/cd0fe9e053037ba4fffff74c376900f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*OjtvvLLEdtQX4frokhem7w.png"/></div><p class="np nq gj gh gi nr ns bd b be z dk translated">表示要分割的图像的初始8x8数组。我们将用两个种子来分割它，第一个在[1，1]位置，第二个在[7，7]。阈值是25，我们使用4-连接“作者的图像”</p></figure><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oq"><img src="../Images/3fb39162c67501770f2ae67db8d7949e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ewsRfQRKAZ3ODE1wWW-loA.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">“作者提供的图像”</p></figure><p id="784d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，对于分割的图像，我们从与我们的输入大小相同的空图像开始，我们看到该区域如何增长，同时为每个种子区域分配一个唯一标签，其中10是[1，1]种子的标签，30是[7，7]种子的标签。</p><p id="1c43" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您也可以跟踪种子像素，但在此之前，我建议您注释掉分段输出以获得更好的效果。</p><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div class="gh gi or"><img src="../Images/6e20d5d15a5349a03463d750850b5e58.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*JIqeHSeIG3OCAFEcUAqhbA.png"/></div><p class="np nq gj gh gi nr ns bd b be z dk translated">“作者提供的图像”</p></figure><p id="6207" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们用这种方法来看一个真实的图像示例:</p><p id="1125" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在左侧，我们看到输入图像，我想分割中心的圆，所以我在该区域选择一些种子点，如[[245，245]，[240，195]，[300，245]，[230，300]]。这是以8-连通性和10作为阈值的结果。请注意，分割的图像是一个到处都是255的空白图像(对于2D实验来说，这是0，以使它的噪声更少)，因此黑线是我们分割的唯一部分。</p><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi os"><img src="../Images/6a03ec4ed834098988dbeb560c619712.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ojoTGwII3xMAbs5AeUQSMA.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">"自动生成的图像"</p></figure><p id="a182" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这不是一个好的输出，对不对？</p><p id="d517" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为即使图像非常容易分割，当种子到达对象(这里是圆)的边界时只有0和255个值，但是种子很可能不能走得更远，因为它的相邻像素都是0，且其他相邻像素已经被分类。让我们思考一下如何改进这种方法:</p><ul class=""><li id="d7e9" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">我们可以添加与该区域兼容的种子的所有邻居，而不是最小距离的邻居。</li><li id="d485" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld lj lk ll lm bi translated">当种子停止生长时，我们可以在该区域中搜索另一个具有兼容性条件的像素，而不是直接搜索该种子的邻居。</li></ul><p id="1f96" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们用实现的第二个版本来检查结果:</p><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/46875ae2d97fa7458f94f0871f99d020.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*3Gl1tBMdu3YnjwiV7kgM-A.png"/></div><p class="np nq gj gh gi nr ns bd b be z dk translated">"自动生成的图像"</p></figure><p id="663d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个远比第一个输出好，对吗？</p><p id="8da3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以尝试这两种实现，并通过点击我的<a class="ae lt" href="https://github.com/YCAyca/Image-Segmentation/tree/main/Region_Growing" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu"> Github </strong> </a> <strong class="kk iu"> </strong>链接，用<strong class="kk iu">多种子</strong>选项做自己的实验。</p><p id="0539" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，种子点的选择非常重要，因为它们是起点。例如，它可以是您想要分割的对象的中心。种子点选择甚至可以自动完成，此时您需要计算图像的直方图并返回n个<strong class="kk iu">峰值</strong>点。然后选择1个具有该峰值点值的像素作为每个峰值点的种子。</p><p id="98b2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">峰值点</strong>:如果您有一个0–255范围内的灰度图像，并且您看到直方图峰值(占大多数)在200、100和10处，您可以选择3个具有200、100和10强度值的种子点。最后，你将有3个分割区域。</p><p id="11d8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，这是一个非常好的区域增长算法的可视化，其中该方法应用于RGB图像。<a class="ae lt" href="https://www.youtube.com/watch?v=VaR21S8ewCQ" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=VaR21S8ewCQ</a></p><p id="869f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">！！！</strong>注意，在RGB图像中，由于我们有3个通道，而不是像在灰色图像中那样有1个通道，所以要添加到区域中的条件从最接近区域平均值变为距离区域平均值最小。并且两个RGB像素之间的距离为:<br/> <code class="fe ou ov ow mx b">distance = sqrt((R2-R1)^2 +(G2-G1)^2 +(B2-B1)^2)</code></p><p id="9589" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">拆分/合并</strong></p><p id="adbf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">分割和合并方法与区域增长相反。我们从整个图像开始，把它作为一个区域</p><ol class=""><li id="5b63" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld ln lk ll lm bi translated">将该区域分成4个子区域</li><li id="246d" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld ln lk ll lm bi translated">如果4个子区域中任何区域不是<strong class="kk iu">同质的</strong>，则将其再次分割成4个子区域。如果任何相邻子区域是同质的，则合并它们。</li><li id="783c" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld ln lk ll lm bi translated">重复2。直到所有的区域都是同质的。</li></ol><p id="a649" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="mr">如何检查一个区域是否同质？</em>T25】</strong></p><p id="d30c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有不同的方法来检查一个区域是否是同质的。您可以选择其中一个并将其作为<strong class="kk iu">分割条件</strong>来分割满足条件的区域，并将其作为<strong class="kk iu">合并条件</strong>来合并满足条件的<strong class="kk iu">邻居</strong>区域。</p><ul class=""><li id="8823" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">如果像素的灰度等级在给定的<strong class="kk iu">范围内</strong>(或者全部相同)，则该区域是同质的</li><li id="8ef4" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld lj lk ll lm bi translated">如果该区域的平均值高于整个图像的平均值，则该区域是同质的</li><li id="4d1c" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld lj lk ll lm bi translated">如果该区域的<strong class="kk iu">方差</strong>低于确定的阈值，则该区域是同质的。其中区域的方差是</li></ul><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/ba58ad7029808b0b6c695545ad072a8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*uSkIvVRq4byBbs6kUFyerg.png"/></div><p class="np nq gj gh gi nr ns bd b be z dk translated">区域R [1]的方差</p></figure><p id="4e16" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着</p><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/46bf3582ac00b8d7c07ebf31641747da.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*cxKAJsnCXkxMO7jrDnGVvQ.png"/></div><p class="np nq gj gh gi nr ns bd b be z dk translated">区域的强度和除以1/N，其中N:区域中的像素数[2]</p></figure><p id="ea62" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">分割和合并方法通常由树形结构表示。我们看到下面的输出示例:</p><div class="ms mt mu mv gt ab cb"><figure class="oz ni pa pb pc pd pe paragraph-image"><img src="../Images/bbbfeef2e2bae563b2f19a05ea3c8266.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*Y_0eGr2_jXWRXUKL1Xt7cQ.png"/></figure><figure class="oz ni pf pb pc pd pe paragraph-image"><img src="../Images/c4fc347c880e5b2802045f35aa2b36d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*Stx4KWyD3BfGaV33ZkOSgw.png"/><p class="np nq gj gh gi nr ns bd b be z dk pg di ph pi">[3]</p></figure></div><p id="75c8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意，基于区域的分割方法经常用于医学图像分割，并且它们仍然是图像分割的重要基本方法之一。</p></div><div class="ab cl od oe hx of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="im in io ip iq"><h1 id="3dbb" class="lu lv it bd lw lx ok lz ma mb ol md me jz om ka mg kc on kd mi kf oo kg mk ml bi translated">基于边缘的图像分割</h1><p id="e73e" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">正如我们在<a class="ae lt" href="https://yagmurcigdemaktas.medium.com/image-processing-part-2-2-4ab76a18e276" rel="noopener">空间线性滤波</a>中已经看到的，有不同类型的内核为我们提供图像的边缘。基于边缘的图像分割就是这样！<strong class="kk iu">我们需要跟踪图像的边缘，当我们获得边缘图时，我们通常使用形态学填充那些边缘中的空洞，</strong>然后就完成了！如果你对我们用来检测边缘的“一阶导数和二阶导数核”没有任何概念，你可以看看我之前提到的那篇文章。</p><p id="7b29" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除了这些内核类型之外，还有一些“边缘检测器”,我们不仅仅使用边缘检测内核，而是使用一些额外的步骤来获得更好的结果。一个非常常见的边缘检测器是Canny边缘检测器，它在下面的帖子中有很好的解释和详细说明:</p><div class="pj pk gp gr pl pm"><a rel="noopener follow" target="_blank" href="/canny-edge-detection-step-by-step-in-python-computer-vision-b49c3a2d8123"><div class="pn ab fo"><div class="po ab pp cl cj pq"><h2 class="bd iu gy z fp pr fr fs ps fu fw is bi translated">Python中的谨慎边缘检测——计算机视觉</h2><div class="pt l"><h3 class="bd b gy z fp pr fr fs ps fu fw dk translated">这是一个简单易懂的教程，一步一步讲解如何构建Canny边缘检测算法。</h3></div><div class="pu l"><p class="bd b dl z fp pr fr fs ps fu fw dk translated">towardsdatascience.com</p></div></div><div class="pv l"><div class="pw l px py pz pv qa nn pm"/></div></div></a></div><p id="ba87" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们试着看看边缘检测器和孔洞填充一起使用的一些结果，同时使用Scipy的内置函数:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="5131" class="nb lv it mx b gy nc nd l ne nf">"""Edge Based Segmentation """</span><span id="8ad0" class="nb lv it mx b gy ng nd l ne nf">""" edge detection with canny """</span><span id="bde6" class="nb lv it mx b gy ng nd l ne nf">edges = canny(img)</span><span id="e474" class="nb lv it mx b gy ng nd l ne nf">fig, ax = plt.subplots(figsize=(4, 4))<br/>ax.imshow(edges, cmap=plt.cm.gray)<br/>ax.axis('off')<br/>ax.set_title('Canny detector')</span><span id="03a9" class="nb lv it mx b gy ng nd l ne nf">""" region - hole filling """</span><span id="a83d" class="nb lv it mx b gy ng nd l ne nf">fill_holes = ndi.binary_fill_holes(edges)</span><span id="cb01" class="nb lv it mx b gy ng nd l ne nf">fig, ax = plt.subplots(figsize=(4, 3))<br/>ax.imshow(fill_holes, cmap=plt.cm.gray, interpolation='nearest')<br/>ax.axis('off')<br/>ax.set_title('Filling the holes')</span></pre><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi qb"><img src="../Images/625057032e2dc20a8644eb58dc83900e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*RIfigniDBSfurZiNDQAzug.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">“作者提供的图像”</p></figure><p id="546a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，处理太大的图像或大的对象可能会破坏您的结果图像，因为边缘大多没有闭合。如果边缘不闭合，填充洞算法也不能正常工作。让我们在不调整大小的情况下检查相同的图像:</p><figure class="ms mt mu mv gt ni gh gi paragraph-image"><div class="gh gi qc"><img src="../Images/0d26e7984912f9bf5528b3d8b62f665a.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*Mzla2U73i3RvYe6ZInX-EA.png"/></div><p class="np nq gj gh gi nr ns bd b be z dk translated">没有调整输入图像“作者的图像”的大小</p></figure><p id="8858" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">记住这些小技巧，祝你自己的试验好运！你可以从那个<a class="ae lt" href="https://github.com/YCAyca/Image-Segmentation/tree/main/Edge_Based" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu"> Github </strong> </a>链接到达代码。</p><p id="250e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我试图在一篇文章中收集经典的方法，让你对每一种方法有一个简单的了解。我希望代码和解释对那些开始研究这个领域的人有所帮助！如果你想用经典方法更进一步，我建议你继续用<strong class="kk iu">分水岭算法</strong>和<strong class="kk iu">提取连通分量</strong>。两者都在某些部分使用了形态学运算，值得一看！</p><p id="1c70" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要进一步了解更多先进的方法，请点击我的<a class="ae lt" rel="noopener" target="_blank" href="/image-segmentation-with-clustering-b4bbc98f2ee6">基于聚类的方法</a>帖子，在那里我解释了聚类分割，这是基于人工智能的图像分割的一个子组。</p><p id="acc7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">谢谢✋</p></div><div class="ab cl od oe hx of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="im in io ip iq"><p id="ea0d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[1] [2] [3]:图片来自<a class="ae lt" href="https://en.wikipedia.org/wiki/Split_and_merge_segmentation" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Split_and_merge_segmentation</a></p><p id="70cb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，所有用于不同代码部分实验的图片都来自unsplash.com</p></div></div>    
</body>
</html>