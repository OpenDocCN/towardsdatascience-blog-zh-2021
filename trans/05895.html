<html>
<head>
<title>Graph Representation Learning — The Encoder-Decoder Model (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图形表示学习——编码器-解码器模型(下)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/graph-representation-learning-the-encoder-decoder-model-part-2-ed8b505af447?source=collection_archive---------13-----------------------#2021-05-26">https://towardsdatascience.com/graph-representation-learning-the-encoder-decoder-model-part-2-ed8b505af447?source=collection_archive---------13-----------------------#2021-05-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="789c" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/graphedm-series" rel="noopener" target="_blank"> GraphEDM系列</a></h2><div class=""/><div class=""><h2 id="27aa" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">深入探究GraphEDM架构</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/023921674932518a9ef5400f46c2aaec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_pQYeluX7koZHWhsbP8_yg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">GraphEDM框架的表示——作者修改的原始纸质图像(经允许后发布)</p></figure><p id="154c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="md">这个系列总结了一个关于图的机器学习的综合分类法，并报告了关于GraphEDM的细节(</em>横山雅美等人。al <em class="md">，一个统一不同学习方法的新框架。</em></p><p id="6ba3" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">图是无处不在的结构，能够编码不同领域中不同元素之间的关系，从社交网络到金融交易。图嵌入是来自网络结构化数据的低维连续表示，可以通过应用图表示学习(GRL)技术来学习。</p><p id="c893" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在本系列的前一篇文章中，我从不同的角度提出了对网络嵌入的讨论，进行了不同的比较，包括欧几里德几何与非欧几里德几何，位置嵌入与结构嵌入，以及直推式学习与归纳式学习。</p><div class="me mf gp gr mg mh"><a rel="noopener follow" target="_blank" href="/graph-representation-learning-network-embeddings-d1162625c52b"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jd gy z fp mm fr fs mn fu fw jc bi translated">图形表示学习——网络嵌入(上)</h2><div class="mo l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">towardsdatascience.com</p></div></div><div class="mp l"><div class="mq l mr ms mt mp mu lb mh"/></div></div></a></div><p id="d820" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在第二篇文章中，我们将详细介绍GraphEDM架构，从编码器-解码器的角度来看，它在一个独特的框架中连贯地包含了不同的GRL技术。横山雅美等人在文章中报道了所有的框架细节。艾尔:</p><blockquote class="mv mw mx"><p id="4630" class="lh li md lj b lk ll kd lm ln lo kg lp my lr ls lt mz lv lw lx na lz ma mb mc im bi translated">I .横山雅美、s .阿布埃尔海贾、b .佩罗齐、réc .、k .墨菲(2020年)。图的机器学习:一个模型和综合分类法。arXiv预印本:2005.03675。</p></blockquote><p id="3a04" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">编码器的目标是将数据点的特征转换成低维表示。解码器将该表示作为输入，并试图重建原始数据。如果在训练过程中计算的嵌入能够捕获核心信息，该核心信息能够编码数据中的最高方差，则该架构的性能增加。因此，编码器-解码器架构的学习目标是在重建过程中最小化信息损失。</p><p id="9274" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在网络的情况下，该重建过程旨在恢复原始图形结构(无监督设置)或实现解决特定任务的表示，例如节点或边分类(有监督设置)。与现有的研究工作相比，GraphEDM定义了一个端到端的模型，能够封装监督和非监督学习方法。以下各节描述了该框架的主要组成部分，该框架能够在GRL的背景下归纳出30多种方法。</p><h2 id="73dc" class="nc nd it bd ne nf ng dn nh ni nj dp nk lq nl nm nn lu no np nq ly nr ns nt iz bi translated">投入</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nu"><img src="../Images/1fa6844b57b0fdb75f6560573c0859a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1vZp2aQDHmMb0o4UowTxAA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">GraphEDM框架的输入</p></figure><p id="12b1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">GraphEDM框架认为输入是一个无向加权图，<em class="md"> G=(N，E) </em>，其中<em class="md"> N </em>是节点集，而<em class="md"> E </em>表示边集。这个无向图是使用两种不同类型的矩阵定义的:邻接矩阵<em class="md"> W </em>和描述节点特征的可选矩阵<em class="md"> X </em>。</p><p id="6d19" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">邻接矩阵<em class="md"> W </em>是一个维数为|<em class="md">N</em>|<em class="md">x</em>|<em class="md">N</em>的方阵，它对图中节点之间的关系进行编码。在未加权图形的情况下，<em class="md"> W </em>包括0和1之间的值。否则，对于加权图，这些值对应于边权重。<em class="md"> X </em>矩阵的行数对应于图中的节点数| <em class="md"> N </em> |，列数对应于特征尺寸<em class="md"> d </em> ₀.以下文章提供了此类维度的示例:</p><div class="me mf gp gr mg mh"><a rel="noopener follow" target="_blank" href="/understanding-the-building-blocks-of-graph-neural-networks-intro-56627f0719d5"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd jd gy z fp mm fr fs mn fu fw jc bi translated">了解图形神经网络的构建模块(简介)</h2><div class="nv l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">框架上的直觉(带有运行代码),用神经架构分析和学习图形数据</h3></div><div class="mo l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">towardsdatascience.com</p></div></div><div class="mp l"><div class="nw l mr ms mt mp mu lb mh"/></div></div></a></div><p id="2b36" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对于(半)监督设置，我们需要包括目标标签，用于在特定的下游任务上训练模型。为节点<em class="md"> N </em>边<em class="md"> E </em>和/或整个图形<em class="md"> G </em>提供训练目标标签。监控信号的集合在GraphEDM论文中表示为<em class="md"> S∈{N，E，G} </em>。</p><h2 id="2b75" class="nc nd it bd ne nf ng dn nh ni nj dp nk lq nl nm nn lu no np nq ly nr ns nt iz bi translated">图形编码器网络</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nx"><img src="../Images/20468774e36ca8d167433ee0df21eeac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fv7VPHJz1oKfHlNN7etLAw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">GraphEDM编码器</p></figure><p id="df71" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">属于GraphEDM架构的第一个组件是图形编码器网络，表示为<em class="md"> ENC(W，X；θ^e).</em>编码器将以下内容作为输入:</p><ol class=""><li id="be62" class="ny nz it lj b lk ll ln lo lq oa lu ob ly oc mc od oe of og bi translated">图的结构形式为邻接矩阵<em class="md">W→</em>|<em class="md">N</em>|<em class="md">x</em>|<em class="md">N</em>|；</li><li id="d08d" class="ny nz it lj b lk oh ln oi lq oj lu ok ly ol mc od oe of og bi translated">该节点特征以特征矩阵X →| <em class="md"> N </em> | <em class="md"> x </em> d₀.的形式出现</li></ol><p id="cbb5" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">该输入由<em class="md">θ^e</em>参数化，以便产生节点嵌入矩阵<em class="md"> Z = ENC(W，x；θ^e)</em>。<em class="md"> Z </em>的维数为| <em class="md"> N </em> | <em class="md"> x d </em>，其中<em class="md"> d </em>对应节点嵌入维数。根据编码器的类型，在训练过程中生成并在矩阵<em class="md"> Z </em>中编码的节点嵌入可能捕获不同的图形属性。例如，在本系列的前一篇文章中报道的，矩阵分解和随机漫步等技术旨在学习低维表示，以保持输入图的全局结构。包括图形神经网络(GNNs)在内的其他技术旨在捕捉局部图形结构:具有相似局部表示的节点应该具有相似的嵌入，而不管原始网络中节点的距离如何。</p><h2 id="7aef" class="nc nd it bd ne nf ng dn nh ni nj dp nk lq nl nm nn lu no np nq ly nr ns nt iz bi translated">图形解码器和分类网络</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi om"><img src="../Images/dde5b55889095df68d51989dbd728acf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3LTYT70Xnd5GkaO7H16EAg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图形解码器网络</p></figure><p id="c703" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">解码器组件<em class="md">DEC(Z；θ)</em>将捕捉到的图形特征作为输入，并将其转换成由<em class="md">θ</em>参数化的低维表示。对于无监督的任务，图解码器网络的目标<em class="md">ŵ=dec(z；θ^d)</em>是从节点嵌入<em class="md"> Z </em>中重建邻接矩阵<em class="md">ŵ</em>，以计算所有节点对的相似性(或不相似性)得分。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nu"><img src="../Images/98107443d8071d57a92a94ff1de3d773.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MY6jpFxi6QISbGlxKJpQww.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">分类网络</p></figure><p id="5af0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在监督设置中，分类网络产生标签值<em class="md">ŷ^s=dec(z；θ^s)</em>对应于与下游任务相关的输出。如输入部分所介绍的，<em class="md"> S </em>包括被监控信号的采集<em class="md"> {N，E，G} </em>。</p><h2 id="a1a0" class="nc nd it bd ne nf ng dn nh ni nj dp nk lq nl nm nn lu no np nq ly nr ns nt iz bi translated">输出</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nu"><img src="../Images/78acc0f7f74e82066496825766f2dca0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RjH46xsCp3FGvB586D_8cw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">GraphEDM框架的输出</p></figure><p id="012b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">GraphEDM框架能够根据具体的问题设置产生双重输出。事实上，模型的输出对应于训练无监督嵌入算法的邻接矩阵，以及有监督任务的输出标签。直观来看，<em class="md">ŵ</em>的维数与<em class="md">w</em>(|<em class="md">n</em>|<em class="md">x</em>|<em class="md">n</em>|)的维数相同。另一方面，<em class="md"> ŷ^S的维数为</em>|<em class="md">n</em>|<em class="md">x</em>|<em class="md">υ</em>|，其中<em class="md"> Y </em>为标签空间。取决于受监督的应用，标签输出空间可以不同，以表示节点标签空间、边标签空间和图标签空间。</p><h2 id="d90c" class="nc nd it bd ne nf ng dn nh ni nj dp nk lq nl nm nn lu no np nq ly nr ns nt iz bi translated">损失函数</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nu"><img src="../Images/33caecf76c0922b12262e263cdf77727.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ikdhcg1bJFjL5f0YEBKK9A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">GraphEDM框架中的损失函数</p></figure><p id="382c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">不同类型的损失项用于优化GRL环境中的模型，包括<em class="md">监督损失</em>、<em class="md">图正则化损失</em>和<em class="md">权重正则化</em>。GraphEDM模型能够通过学习前面章节中提到的参数组合这些术语<em class="md">θ</em>∈{<em class="md">θ^e、θ^d、θ^s}</em>。</p><p id="aea2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">监督损失项<em class="md"> Lₛᵤₚ^S </em>将预测标签<em class="md"> ŷ^S </em>与目标标签y <em class="md"> ^S </em>进行比较，这取决于下游任务(例如节点分类)。</p><p id="8dce" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">图正则化损失项<em class="md"> L </em> 𝓰 ᵣₑ利用图结构对模型的权重施加正则化约束。与监督损失不同，图正则化比较解码的邻接矩阵<em class="md">ŵ</em>和地面真实邻接<em class="md"> W </em>。这种类型的正则化施加了例如相邻节点共享相似嵌入的约束。</p><p id="7d92" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">权重正则化<em class="md"> L </em> ᵣₑ传统上包括一套技术，可以防止神经架构中的过拟合，提高它们的泛化能力。这使得能够学习正则化系数，其在最小损失函数的方向上定义约束边界。因此，在训练阶段，优化被阻止达到损失函数的最小值，这可能导致过拟合。</p><h1 id="050a" class="on nd it bd ne oo op oq nh or os ot nk ki ou kj nn kl ov km nq ko ow kp nt ox bi translated">下一步是什么</h1><p id="9d07" class="pw-post-body-paragraph lh li it lj b lk oy kd lm ln oz kg lp lq pa ls lt lu pb lw lx ly pc ma mb mc im bi translated">在本系列的下一篇文章中，我将详细介绍GraphEDM架构的不同组件，包括不同类型的编码器和损失函数。</p><p id="d9f4" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对于GraphEDM框架上的所有文章，您可以使用以下链接:<a class="ae nb" href="https://towardsdatascience.com/tagged/graphedm-series" rel="noopener" target="_blank">https://towardsdatascience.com/tagged/graphedm-series</a>。</p><p id="5562" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="md">关于图形表征学习的进一步阅读，可以关注</em>:<a class="ae nb" href="https://towardsdatascience.com/tagged/grl-series" rel="noopener" target="_blank">https://towardsdatascience.com/tagged/grl-series</a>的相关系列。</p></div></div>    
</body>
</html>