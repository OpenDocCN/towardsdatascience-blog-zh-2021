<html>
<head>
<title>U-Net for Semantic Segmentation on Unbalanced Aerial Imagery</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不平衡航空影像语义分割的U-Net方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/u-net-for-semantic-segmentation-on-unbalanced-aerial-imagery-3474fa1d3e56?source=collection_archive---------3-----------------------#2021-10-03">https://towardsdatascience.com/u-net-for-semantic-segmentation-on-unbalanced-aerial-imagery-3474fa1d3e56?source=collection_archive---------3-----------------------#2021-10-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5101" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用于航空影像语义分割的U-Net py torch实现。</h2></div><p id="ee3b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我们回顾了不平衡二进制掩码的语义分割问题。引入焦点损耗和mIoU作为损耗函数来调整网络参数。最后，我们训练PyTorch中实现的U-Net对航拍图像进行语义分割。训练代码和PyTorch实现可以通过<a class="ae lb" href="https://github.com/amirhosseinh77/UNet-AerialSegmentation" rel="noopener ugc nofollow" target="_blank"> Github </a>获得。</p><h1 id="8397" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated"><strong class="ak">数据集</strong></h1><p id="457a" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">这里使用的数据集是“<a class="ae lb" href="https://www.kaggle.com/humansintheloop/semantic-segmentation-of-aerial-imagery" rel="noopener ugc nofollow" target="_blank">航空影像语义分割</a>”，包含阿联酋迪拜的72幅卫星影像，被分割成6类。这些类别包括水、土地、道路、建筑、植被和未标注。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi lz"><img src="../Images/6f7f53c67eadb5cba8a113eb5264f41e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7f97NC1f_KZr0ss_qMceRg.png"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">图一。<a class="ae lb" href="https://www.kaggle.com/humansintheloop/semantic-segmentation-of-aerial-imagery" rel="noopener ugc nofollow" target="_blank">数据集</a>的样本</p></figure><h1 id="1152" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">U-Net神经网络</h1><p id="b3bd" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated"><a class="ae lb" href="https://arxiv.org/pdf/1505.04597v1.pdf" rel="noopener ugc nofollow" target="_blank"> U-Net </a>是一种卷积神经网络，最初由弗赖堡大学计算机科学系用于生物医学图像分割。它基于完全卷积神经网络，并具有修改和扩展的架构，以使用更少的训练图像并产生更精确的分割。</p><p id="9916" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">主要概念是使用一个收缩的网络，然后是一个扩展的网络，在扩展的网络中用上采样操作代替池操作。这些图层提高了输出的分辨率。此外，一个扩展的卷积网络可以学习根据编码信息组合一个精确的输出。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi mp"><img src="../Images/e8c33fd7e90ca6fa402fc3059b29e481.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eQLQo43suhzuHslqy-LL3g.png"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">图二。Unet结构(图片由<a class="ae lb" href="https://arxiv.org/pdf/1505.04597v1.pdf" rel="noopener ugc nofollow" target="_blank"> U-Net </a>提供)</p></figure><p id="a2e6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该网络由一条收缩路径(左侧)和一条扩张路径(右侧)组成，这使其具有u形架构。收缩路径是一个典型的卷积网络，由重复的卷积组成，每个卷积后面都有一个校正线性单元(ReLU)和一个最大汇集操作。在收缩期间，空间信息减少，而特征信息增加。扩展路径通过一系列上卷积和连接将特征和空间信息与来自收缩路径的高分辨率特征相结合。</p><h1 id="bbfd" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">损失函数</h1><p id="3606" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">本文的目的是回顾损失函数对分割输出结果的影响。在训练过程中使用了三种不同的损失函数。但首先，让我们快速回顾一下。</p><p id="7fe2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们假设p是图像中每个像素的输出值。在这种情况下，我们可以将研究的损失函数定义如下:</p><h2 id="d975" class="mq ld iq bd le mr ms dn li mt mu dp lm ko mv mw lo ks mx my lq kw mz na ls nb bi translated">交叉熵损失</h2><p id="d56d" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">交叉熵(或对数损失)计算输出的对数值，因为我们讨论的是图像，所以它是输出张量中每个像素的对数值。</p><p id="deb7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">阿尔法项是不同类别的权重超参数，是平衡不平衡类别损失的一种方式。加权交叉熵损失的最终等式如等式1所示。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/7cf656ccf8e5d57b41f2a7792cc31884.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*xC1WZB__z-iOYuICf4WZ6w.png"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">Eq 1。加权交叉熵损失</p></figure><h2 id="327f" class="mq ld iq bd le mr ms dn li mt mu dp lm ko mv mw lo ks mx my lq kw mz na ls nb bi translated">焦点损失</h2><p id="57cd" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated"><a class="ae lb" href="https://arxiv.org/pdf/1708.02002.pdf" rel="noopener ugc nofollow" target="_blank">焦损</a>为不平衡数据集问题提供了更好的解决方案。它增加了一个额外的项，以减少正确预测的影响，并专注于不正确的示例。伽马是一个超参数，它规定了这种减少的力度有多大。</p><p id="8fc0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这种损失影响网络在不平衡数据集上的训练，并且可以改善分割结果。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/8546af9cdeb7ee2e77e9b5d0efaa5429.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*9iOvQPuSRrbirdtzbAG4Ng.png"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">Eq 2。焦点损失</p></figure><h2 id="9751" class="mq ld iq bd le mr ms dn li mt mu dp lm ko mv mw lo ks mx my lq kw mz na ls nb bi translated">借据损失(Jaccard指数)</h2><p id="52bf" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">最后，我们得到IoU损失，这是不平衡分段的另一个选项，它比其他选项具有更少的超参数。但首先，让我们熟悉一下等式3中的这个度量。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/36afe0e89babca006efc3a24ab632058.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*YKfagJ_tk0xZPPnlU8I0dg.png"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">Eq 3。并集上的交集</p></figure><p id="20ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在等式中，命名者是预测的和基本事实掩码之间的重叠，分母是它们的联合。IoU的计算方法是将这两个数字相除，数值越接近1表示预测越准确。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/c76022dacf20caa3d81f9fa3f1823a63.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*ST5HZdhiEG3_xEbZf_4SRw.png"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">图三。IoU(图片由作者提供)</p></figure><p id="87a1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">优化的目的是最大化IoU，其值介于0和1之间，因此损失函数定义为:</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/4da4a30e49ac081fa7705271dfe8924a.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*pWWdntVHklrF5Vj17XDxtQ.png"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">Eq 3。欠条损失</p></figure><h1 id="e311" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">培训和结果</h1><p id="0363" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">我在提到的数据集上用所有三个损失函数训练了U-Net。需要注意的是，只有65张图片用于训练，7张图片用于验证，所以我们不能期望有很好的结果。但是这个数据数量对于我们的目的来说已经足够了。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nh"><img src="../Images/035bad16cac45b48aeeb4f78f48524c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9uMRl9M7zbay_vpw8773Gw.png"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">图4。使用<strong class="bd ni">交叉熵损失</strong>的分割结果(图片由作者提供)</p></figure><p id="102d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如你所见，交叉熵在分割小区域方面有问题，并且在这些损失函数中性能最差。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nh"><img src="../Images/8d2990608c79995b24e2450258cb1c1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*irCDe7-9eBuJnZmPqf66ZQ.png"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">图五。使用<strong class="bd ni">聚焦损失</strong>的分割结果(图片由作者提供)</p></figure><p id="ee47" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">焦损可以达到更好的效果，尤其是在小区域，但是仍然需要通过试错进行一些超参数调谐。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nh"><img src="../Images/e3581b642d8ac2fe9945ed5e0a215397.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oAiVHWHHkhQoBh_wr1YDxw.png"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">图六。使用<strong class="bd ni"> IoU loss </strong>的分割结果(图片由作者提供)</p></figure><p id="89ad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我们可以看到，无论是小区域还是大区域，IoU loss在分割方面也非常出色。</p><p id="217a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里您可以看到一些其他输出:</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/198cf988adccda85c752a44a3da97f4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*9pVgN5f521wRxjiDxJxkgA.png"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">图六。左边是交叉熵，中间是焦损，右边是IoU损(图片由作者提供)</p></figure><h1 id="54b9" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">结论</h1><p id="b54f" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">本文综述了损失函数对不平衡图像分割的影响。我们训练U-Net神经网络使用3种不同的损失函数，交叉熵损失、焦点损失和IoU损失来执行语义分割航空图像。</p><p id="cf7d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">结果表明交叉熵损失不能处理不平衡的数据集。即使是针对不同的阶层增加权重也不是很有效。另一方面，焦点损失和IoU损失都代表不平衡图像分割的更好结果。</p><p id="9f4e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">也可以参考<a class="ae lb" href="https://github.com/amirhosseinh77/UNet-AerialSegmentation" rel="noopener ugc nofollow" target="_blank"> GitHub </a>页面访问项目和PyTorch实现。</p></div></div>    
</body>
</html>