<html>
<head>
<title>Conv1D and Conv2D: Did you realize that Conv1D Is a Subclass of Conv2D?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Conv1D和Conv2D:你知道Conv1D是Conv2D的子类吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/conv1d-and-conv2d-did-you-realize-that-conv1d-is-a-subclass-of-conv2d-8819675bec78?source=collection_archive---------13-----------------------#2021-04-20">https://towardsdatascience.com/conv1d-and-conv2d-did-you-realize-that-conv1d-is-a-subclass-of-conv2d-8819675bec78?source=collection_archive---------13-----------------------#2021-04-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="520f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">比较和评估Conv1d和Conv2D</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/791475f33242aed5741e7c44349f2f20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SyPQVEy8yiMXXOdz"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://www.pexels.com/photo/grayscale-photo-of-computer-laptop-near-white-notebook-and-ceramic-mug-on-table-169573/" rel="noopener ugc nofollow" target="_blank">像素</a>上的<a class="ae ky" href="https://www.pexels.com/@negativespace" rel="noopener ugc nofollow" target="_blank">负空间</a>拍摄</p></figure><p id="475d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">很可能，阅读本文的大多数人已经实现了一些基于CNN的神经网络，并想知道在进行时间序列分析时是使用Conv1D还是Conv2D。在这篇文章中，我将解释和比较这两种卷积类型，并回答以下问题:<em class="lv">为什么我说Conv1D是Conv2D的子类？</em></p><p id="8ba5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你不能轻易地回答这个问题，我想这篇文章会让你感兴趣的。一如既往，欢迎任何问题/评论。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="d704" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">几个月前，我被要求为一个基于时间序列的挑战创建一个神经网络。数据大概是这样的:</p><ul class=""><li id="7c38" class="md me it lb b lc ld lf lg li mf lm mg lq mh lu mi mj mk ml bi translated">数据数量:500</li><li id="7216" class="md me it lb b lc mm lf mn li mo lm mp lq mq lu mi mj mk ml bi translated">长度:3200</li><li id="0c9f" class="md me it lb b lc mm lf mn li mo lm mp lq mq lu mi mj mk ml bi translated">频率:40</li><li id="797c" class="md me it lb b lc mm lf mn li mo lm mp lq mq lu mi mj mk ml bi translated">频道:1</li></ul><p id="1cf8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基于时间序列的长度，我决定实现<a class="ae ky" href="https://en.wikipedia.org/wiki/Short-time_Fourier_transform#:~:text=The%20Short%2Dtime%20Fourier%20transform,as%20it%20changes%20over%20time." rel="noopener ugc nofollow" target="_blank">短时傅立叶变换</a>进行分析。一个数据看起来类似于图1所示的曲线图。此外，输出具有如下所示的形状。</p><ul class=""><li id="b055" class="md me it lb b lc ld lf lg li mf lm mg lq mh lu mi mj mk ml bi translated">输入形状:(500，1，3200)</li><li id="8080" class="md me it lb b lc mm lf mn li mo lm mp lq mq lu mi mj mk ml bi translated">输出STFT形状:(500，20，160)</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mr"><img src="../Images/c92308d13473b5c50d80da33b0a80c97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r2mcDNwmaHEbxbkvtFPZiA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一个数据的STFT</p></figure><p id="6429" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在与几个人交谈后，我意识到在日常生活中与图像打交道的人建议使用Conv2D，在Conv2D中，数据被视为图像。另一方面，处理时间序列的人表示Conv1D是最佳解决方案，类似于多通道时间序列任务，其中每个通道对应一个频率。在<a class="ae ky" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>的符号中，神经网络的输入是:</p><ul class=""><li id="8c28" class="md me it lb b lc ld lf lg li mf lm mg lq mh lu mi mj mk ml bi translated">CNN: ( <em class="lv"> N </em> =256，<em class="lv"> Cin </em> =20，<em class="lv">林</em> =160)</li><li id="1ab1" class="md me it lb b lc mm lf mn li mo lm mp lq mq lu mi mj mk ml bi translated">2D CNN: ( <em class="lv"> N </em> =256，<em class="lv"> Cin </em> =1，<em class="lv">欣</em> =20，<em class="lv">胜</em> =160)</li></ul><p id="17a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我们可以实现两种可能的2层神经网络来解决这个任务:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/c7f716c015dd12acf6e6dd8e39ad4bd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3eRQePu2fuyJ8USeWrtx5g.png"/></div></div></figure><p id="af3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如所观察到的，1D CNN的参数数量是8160，而2D CNN是18816，这两种方法都是时间序列分析的有效方法。</p><p id="7d73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，在写报告的时候，我想到了以下问题:<strong class="lb iu">有没有可能创建一个类似于1D CNN的2D CNN？如果有，执行情况如何？</strong></p><p id="968e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然这一开始听起来很奇怪，但这是可能的，而且为了理解这种说法，有必要了解卷积层是如何工作的。</p><p id="811a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用参数<em class="lv">内核大小</em>、<em class="lv">填充、步幅和膨胀</em>来定义卷积层:</p><ul class=""><li id="5d1d" class="md me it lb b lc ld lf lg li mf lm mg lq mh lu mi mj mk ml bi translated"><em class="lv">内核大小</em>:指滤镜蒙版的形状。</li><li id="546f" class="md me it lb b lc mm lf mn li mo lm mp lq mq lu mi mj mk ml bi translated"><em class="lv">填充</em>:添加到图像中的像素数量。</li><li id="f5a6" class="md me it lb b lc mm lf mn li mo lm mp lq mq lu mi mj mk ml bi translated"><em class="lv">步距</em>:输入矩阵上移动的像素数。</li><li id="9f60" class="md me it lb b lc mm lf mn li mo lm mp lq mq lu mi mj mk ml bi translated"><em class="lv">膨胀</em>:内核中值之间的间距。</li></ul><p id="793f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个卷积层的输出取决于这些参数，并使用以下PyTorch公式进行计算。</p><h2 id="e145" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">Conv1D</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/2f0d334329f109b19a88df44b8d12613.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-_6xM75L_aI5EEASpZU41g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">塑造1D·conv。<a class="ae ky" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html" rel="noopener ugc nofollow" target="_blank">参考</a></p></figure><h2 id="0296" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">Conv2D</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/93403751c6836ee4a374e2cfb0b4e222.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l2UPynGCXQvefi0KXPCT5g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">塑造2D·conv。<a class="ae ky" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html" rel="noopener ugc nofollow" target="_blank">参考</a></p></figure><p id="ebb1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，即使首先要获得两种类型卷积的相同结果似乎很困难，但问题的答案最终还是要为参数设置正确的值。</p><p id="76ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们用上面提到的例子来研究这个问题。如果我定义一个具有32和64个过滤器的两层1D CNN，参数和形状如下所示。</p><ul class=""><li id="76a3" class="md me it lb b lc ld lf lg li mf lm mg lq mh lu mi mj mk ml bi translated">输入:(<em class="lv"> N </em> =256，<em class="lv"/>= 20，<em class="lv">林</em> =160)</li><li id="74e4" class="md me it lb b lc mm lf mn li mo lm mp lq mq lu mi mj mk ml bi translated">Conv1d-1: kernel_size=3，padding=1，stride=1，dilation=0</li><li id="3666" class="md me it lb b lc mm lf mn li mo lm mp lq mq lu mi mj mk ml bi translated">Conv1d-2: kernel_size=3，padding=1，stride=1，dilation=0</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/6cc251538ca1d6353766221a6d098c93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fc6RtAgjxrDEinnfl1j0Bg.png"/></div></div></figure><p id="58a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我们的目标是找到2D CNN的参数，其输出结果类似于1D CNN:</p><ul class=""><li id="d959" class="md me it lb b lc ld lf lg li mf lm mg lq mh lu mi mj mk ml bi translated">输出层1: ( <em class="lv"> N </em> =256，<em class="lv"/>= 32，<em class="lv">林</em> =160)</li><li id="9939" class="md me it lb b lc mm lf mn li mo lm mp lq mq lu mi mj mk ml bi translated">输出第二层:(<em class="lv"> N </em> =256，<em class="lv"/>= 62，<em class="lv">林</em> =160)</li></ul><p id="8634" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在2D有线电视新闻网，翻译为获得:</p><ul class=""><li id="7f1e" class="md me it lb b lc ld lf lg li mf lm mg lq mh lu mi mj mk ml bi translated">输入2D: ( <em class="lv"> N </em> =256，<em class="lv"> Cin </em> =1，<em class="lv">欣</em> =20，<em class="lv">赢</em> =160)</li><li id="4396" class="md me it lb b lc mm lf mn li mo lm mp lq mq lu mi mj mk ml bi translated">输出层1: ( <em class="lv"> N </em> =256，<em class="lv"> Cin </em> =32，<em class="lv">欣</em> =1，<em class="lv">赢</em> =160)</li><li id="1ee1" class="md me it lb b lc mm lf mn li mo lm mp lq mq lu mi mj mk ml bi translated">输出层2: ( <em class="lv"> N </em> =256，<em class="lv"> Cin </em> =62，<em class="lv">欣</em> =1，<em class="lv">赢</em> =160)</li></ul><p id="e5f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总之，本文提出的问题的答案非常简单:</p><blockquote class="nr ns nt"><p id="21db" class="kz la lv lb b lc ld ju le lf lg jx lh nu lj lk ll nv ln lo lp nw lr ls lt lu im bi translated">设置正确的参数，我们可以创建一个具有与Conv1D相同功能的Conv2D。</p></blockquote><p id="ea48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特别是，要设置的主要参数是内核大小。对于这种特殊情况，Hin 的内核必须设置为20，类似于1D CNN的频率或频道总数。此外，需要将该维度的填充固定为0，因此我们得到维度1作为该层的输出。</p><p id="8d2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实现如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><h2 id="13d0" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">Conv2D</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/64c674ca94741fae35163e844f8c1433.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rJv8bSTJ6bMqieYq6uH85g.png"/></div></div></figure><p id="2837" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总之，我们能肯定1D CNN是2D CNN的一个子类吗？正如我在这篇文章中试图解释的那样，我们总是可以创建一个2D CNN，其功能与1D CNN相同，并设置正确的内核大小、填充和步幅。作为一个说明性的例子，我们有这个最后的2D CNN，它的参数数量类似于上面实现的1D CNN。</p><p id="d9ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，这一结论并不意味着我们应该总是使用2D CNN而不是1D CNN，因为后者在处理例如多通道时间序列时更容易实现。我只是试图表达Conv1D和Conv2D最终是相同的。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="bac4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">如果你喜欢这个帖子，请考虑</em> </strong> <a class="ae ky" href="https://javiferfer.medium.com/membership" rel="noopener"> <strong class="lb iu"> <em class="lv">订阅</em> </strong> </a> <strong class="lb iu"> <em class="lv">。你将获得我所有的内容+所有其他来自牛逼创作者的文章！</em>T15】</strong></p></div></div>    
</body>
</html>