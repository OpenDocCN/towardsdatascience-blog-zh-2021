<html>
<head>
<title>How to convert a PyTorch DataParallel project to use DistributedDataParallel</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何将PyTorch DataParallel项目转换为使用DistributedDataParallel</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-convert-a-pytorch-dataparallel-project-to-use-distributeddataparallel-b84632eed0f6?source=collection_archive---------18-----------------------#2021-05-25">https://towardsdatascience.com/how-to-convert-a-pytorch-dataparallel-project-to-use-distributeddataparallel-b84632eed0f6?source=collection_archive---------18-----------------------#2021-05-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/f53a214dbcbfaafbb6c9e7e4f0ffb669.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9jnvL9o6VV9QiXMe"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">泰勒·维克在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="0b34" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">许多帖子讨论PyTorch <a class="ae kc" href="https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#dataparallel" rel="noopener ugc nofollow" target="_blank"> DataParallel </a>和<a class="ae kc" href="https://arxiv.org/pdf/2006.15704.pdf" rel="noopener ugc nofollow" target="_blank"> DistributedDataParallel </a>之间的区别，以及为什么使用DistributedDataParallel是<a class="ae kc" href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html#comparison-between-dataparallel-and-distributeddataparallel" rel="noopener ugc nofollow" target="_blank">最佳实践</a>。</p><p id="0d88" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">PyTorch文档对此进行了总结:</p><blockquote class="lb"><p id="d9c7" class="lc ld iq bd le lf lg lh li lj lk la dk translated">由于线程间的GIL争用、每次迭代的复制模型以及分散输入和收集输出带来的额外开销，即使在单台机器上，DataParallel通常也比DistributedDataParallel慢</p></blockquote><p id="63ec" class="pw-post-body-paragraph kd ke iq kf b kg ll ki kj kk lm km kn ko ln kq kr ks lo ku kv kw lp ky kz la ij bi translated">但事实是，对于开发和原型设计，当处理一个新项目时，或者当在现有的GitHub存储库(已经使用了DataParallel)之上构建时，使用现成的DataParallel版本更简单，特别是当使用一个服务器(有一个或几个GPU)时。最突出的优点是用DataParallel更容易调试。</p><p id="ef66" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管如此，总有一天，您会希望将现有的DataParallel项目转换为大联盟，并使用分布式DataParallel这显然不是小事，因为它应该是。</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/eeaaa955ea313824d385f06bd0a77dba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*e8vFOb-aABa9Hnhqxh59hw.jpeg"/></div></figure><p id="2270" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以在这篇文章中，我不会进一步讨论每种方法的优缺点，而是集中在将一个用DataParallel实现的现有项目转换成一个分布式DataParallel项目的实际方面。</p><p id="dd9e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我将尽可能概括地描述不同的部分，但是当然，您的用例是独特的😃并且可能需要根据您的实现和代码进行仔细和具体的调整。</p><p id="92f5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们走吧…</p><p id="a5bf" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一步是包装。DataParallel使用带有多线程的单进程，但是DistributedDataParallel在设计上是多进程的，所以我们要做的第一件事就是使用多进程包装器包装整个代码——我们的主要功能。</p><p id="9b51" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为此，我们将使用由FAIR在<a class="ae kc" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank"> Detectron2 </a>存储库中提供的<a class="ae kc" href="https://github.com/facebookresearch/detectron2/blob/9246ebc3af1c023cfbdae77e5d976edbcf9a2933/detectron2/engine/launch.py" rel="noopener ugc nofollow" target="_blank">包装器</a>。我们还需要<a class="ae kc" href="https://github.com/facebookresearch/detectron2/blob/master/detectron2/utils/comm.py" rel="noopener ugc nofollow" target="_blank"> comm </a>文件，它为处理分发资源提供了一些不错的功能。</p><figure class="lr ls lt lu gt jr"><div class="bz fp l di"><div class="lv lw l"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">从Detectron2 GitHub库复制的包装代码</p></figure><p id="1c1e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们需要运行的函数叫做<code class="fe lx ly lz ma b">launch()</code>。让我们回顾一下输入参数:</p><figure class="lr ls lt lu gt jr"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="9f3b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们需要向它提供我们正在使用的机器的数量，对于这个帖子，我们将使用一台带有四个GPU的机器，所以<code class="fe lx ly lz ma b">num_machines=1</code>和<code class="fe lx ly lz ma b">num_gpus_per_machine=4</code>。使用多台机器时，<code class="fe lx ly lz ma b">machine_rank</code>用于指定机器的编号[或索引],例如，在分布式培训中使用多台机器时，<code class="fe lx ly lz ma b">machine_rank=0.</code>T5用于提供主机IP地址，但由于我们只使用一台机器，因此我们可以使用<code class="fe lx ly lz ma b">dist_url=“auto”</code>,它将使用本地主机作为IP和自由端口。<code class="fe lx ly lz ma b">main_func</code>变量提供了我们代码的主要功能，这应该是到目前为止在DataParallel情况下运行您的流所使用的主要函数。最后，我们可以提供<code class="fe lx ly lz ma b">args</code>变量，这些都是我们的<code class="fe lx ly lz ma b">main_func</code>函数的输入参数。</p><p id="cd30" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在引擎盖下，launch函数将使用torch多处理模块[torch.multiprocessing]和spawn函数旋转多个进程，这将启动作为新的子进程的进程-每个GPU一个。</p><p id="0120" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">值得注意的是，在运行启动函数后，完全相同的代码将同时在每个子进程中运行。因此，所有只需要在开始时运行一次的预设置代码，都应该在运行启动函数之前调用。例如，连接到您的实验管理器应用程序，从应该预先传递给所有进程的配置文件中获取参数，将数据同步到本地服务器，等等。</p><p id="20c1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们有了一个工作的包装器，我们可以调整我们的模型了。我们需要将在CPU上初始化的模型“转换”为分布式数据并行GPU模型。</p><p id="b5f2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果在数据并行的情况下，我们需要用以下内容包装我们的模型:</p><p id="088f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe lx ly lz ma b">model = torch.nn.DataParallel(model)</code></p><p id="1c5b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在分布式的情况下，我们将使用DistributedDataParallel类包装模型，这个调用将由每个进程独立完成。所以，我们首先需要弄清楚我们当前进程的“等级”是什么[等级基本上是我们的GPU索引]，将模型从CPU复制到那个特定的GPU，并将其设置为DistributedDataParallel模型:</p><figure class="lr ls lt lu gt jr"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="bcee" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe lx ly lz ma b">broadcast_buffers</code>是一个重要的参数，它意味着在训练过程中是否要同步GPU之间基于统计的变量，例如BatchNorm层的均值和方差。</p><p id="f358" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们有了主包装器和模型，接下来我们需要调整数据加载部分。</p><p id="416a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在数据并行的情况下，我们有一个大小为N的单批，在向前传递期间，它会自动均匀地分布在我们的4个GPU上，为每个GPU提供大小为N/4的小批。现在，在分布式情况下，我们需要每个GPU进程从完整的样本批次中只读取与其小批次相关的样本。这是通过PyTorch <a class="ae kc" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.distributed.DistributedSampler" rel="noopener ugc nofollow" target="_blank">分布式取样器</a>完成的:</p><figure class="lr ls lt lu gt jr"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="c71e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">采样器根据我们拥有的流程数量分割样本，并为每个流程提供其迷你批次的相关样本索引。初始化采样器后，我们需要为DataLoader类提供这个采样器实例，并将其shuffle参数设置为False。我们还需要调用采样器的<code class="fe lx ly lz ma b">set_epoch(epoch)</code> <a class="ae kc" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.distributed.DistributedSampler" rel="noopener ugc nofollow" target="_blank">函数</a>作为我们的历元for-loop的一部分，以在每个历元中获得不同顺序的训练样本。</p><p id="ad6d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">至此，我们基本上拥有了三个主要组件:多进程包装器、定义为分布式类型的模型和处理数据加载部分的方法。接下来，我们将回顾我们可以在代码中进行的与日志记录、报告和度量计算相关的其他重要调整。</p><p id="3be9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于所有进程都运行相同的代码，使用打印和记录器向控制台(或文件)报告将会重复导致写入相同的打印。虽然有些消息可能很重要，并且与每个进程的报告相关，但是许多消息并不重要，我们可以使用下面的命令在主进程中只报告一次消息[这是我们的0级进程]:</p><pre class="lr ls lt lu gt mb ma mc md aw me bi"><span id="abb6" class="mf mg iq ma b gy mh mi l mj mk">if comm.is_main_process():<br/>    print(“something that is printed only once”)</span></pre><p id="f0ea" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当向外部工具报告指标或者保存模型权重时，这个技巧也很有价值。您可以使用它来确保一个动作在主流程的流程中只发生一次。</p><p id="2118" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那么，指标呢？</p><p id="8759" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用PyTorch DistributedDataParallel模块，您不需要管理和“收集”[收集]所有进程的损失值来运行后退步骤，<code class="fe lx ly lz ma b">loss.backward()</code>将在幕后为您完成，并且由于它为每个进程运行，它将为所有GPU上的所有模型复制提供相同的梯度校正。</p><p id="f4fa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是，这仅与反向过程中使用的损失值相关。为了报告实际损失值或它们的平均值，您需要收集每个进程的损失，并让主进程报告它们的平均值:</p><pre class="lr ls lt lu gt mb ma mc md aw me bi"><span id="3f3f" class="mf mg iq ma b gy mh mi l mj mk">loss = criterion(outputs, labels)<br/>...<br/>all_loss = comm.gather(loss)<br/>if comm.is_main_process():<br/>    report_avg(all_loss)</span></pre><p id="8a46" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，<code class="fe lx ly lz ma b">all_loss</code>有了所有进程的损耗值，主进程可以对它们进行平均，累加，并报告需要什么。</p><p id="6059" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，<code class="fe lx ly lz ma b">gather</code>命令要求所有进程向主进程提供它们的值，从而降低了整个流程的速度。处理这个问题的一个更好的方法是让每个进程收集并存储它的损失值，并在每次迭代或在一个时期结束时运行收集。</p><p id="d456" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其他重要评论:</p><ul class=""><li id="aaab" class="ml mm iq kf b kg kh kk kl ko mn ks mo kw mp la mq mr ms mt bi translated">一个有价值的技巧是能够在代码中的特定点同步所有进程，并强制它们相互等待。这可以解决以下情况:流运行，但由于某种原因挂起。查看<code class="fe lx ly lz ma b">nvidia-smi</code>,您会发现所有GPU的利用率都为100%,而一个GPU的利用率为0%。这是一个令人沮丧的例子，发生在使用分布式模式时，可能是因为主GPU正在处理一些需要更多时间的事情，如保存和上传您的模型。在流程中的某些特定点强制过程同步可能会有所帮助，例如，当从评估步骤回到下一个训练时期时。这可以通过使用下面的命令用一个<code class="fe lx ly lz ma b">barrier</code>函数来完成:<code class="fe lx ly lz ma b">comm.synchronize()</code> <br/>这个函数在代码中放置一个屏障，强制所有进程等待其余进程到达并一起通过那个点😃。</li><li id="4936" class="ml mm iq kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated">DistributedDataParallel模块在进程之间传输信息，为此，PyTorch会序列化属于数据加载器类的变量。这要求此类变量对序列化有效。这个错误提供了相当多的信息，所以当你面临这样的问题时你会知道。我在序列化部分日志实例时遇到了问题，因为它有一个过滤器使用了一个不适合序列化的不同类。</li></ul><p id="0808" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就是这样。我希望本指南将帮助您从PyTorch数据并行实现过渡到分布式数据并行机制，并享受它提供的好处和速度。</p><p id="88aa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">延伸阅读:</p><ul class=""><li id="8222" class="ml mm iq kf b kg kh kk kl ko mn ks mo kw mp la mq mr ms mt bi translated"><a class="ae kc" href="https://pytorch.org/tutorials/beginner/dist_overview.html" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/tutorials/beginner/dist_overview.html</a></li><li id="2918" class="ml mm iq kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated"><a class="ae kc" href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html#comparison-between-dataparallel-and-distributeddataparallel" rel="noopener ugc nofollow" target="_blank">https://py torch . org/tutorials/intermediate/DDP _ tutorial . html # comparison-between-data parallel-and-distributed data parallel</a></li><li id="5957" class="ml mm iq kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated">PyTorch分发:加速数据并行训练的经验[【https://arxiv.org/pdf/2006.15704.pdf】T4</li></ul></div></div>    
</body>
</html>