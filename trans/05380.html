<html>
<head>
<title>Optimized Docker Images for Apache Spark — Now Public on DockerHub</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">针对Apache Spark优化的Docker映像—现已在DockerHub上公开</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/optimized-docker-images-for-apache-spark-now-public-on-dockerhub-1f9f8fed1665?source=collection_archive---------20-----------------------#2021-05-12">https://towardsdatascience.com/optimized-docker-images-for-apache-spark-now-public-on-dockerhub-1f9f8fed1665?source=collection_archive---------20-----------------------#2021-05-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="73ae" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">开始使用Spark支持的所有通用数据源。</h2></div><p id="aa63" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们为<a class="ae lb" href="https://www.datamechanics.co/apache-spark" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>优化的Docker映像现在可以在我们的<a class="ae lb" href="https://hub.docker.com/r/datamechanics/spark" rel="noopener ugc nofollow" target="_blank"> DockerHub库</a>上免费获得，无论你是否是<a class="ae lb" href="https://www.datamechanics.co" rel="noopener ugc nofollow" target="_blank">数据机制</a>的客户。</p><p id="32fe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是我们工程团队大量工作的结果:</p><ul class=""><li id="620e" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">我们构建了一个Docker映像舰队，结合了各种版本的Spark、Python、Scala、Java、Hadoop和所有流行的数据连接器。</li><li id="41dc" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">在各种工作负载中自动测试它们，以确保包含的依赖关系能够协同工作——换句话说，将您从<em class="lq">依赖地狱</em>中解救出来😄</li></ul><p id="5416" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的理念是提供“附带电池”的高质量Docker图像，这意味着您将能够使用Spark支持的所有常见数据源开始工作。随着时间的推移，我们将维护这些图像，更新Spark的最新版本和错误修复以及各种内置依赖项。</p><h1 id="c6d3" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">Spark的Docker形象是什么？</h1><p id="5fe5" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">当你在Kubernetes 上运行<a class="ae lb" href="https://datamechanics.co/spark-on-kubernetes" rel="noopener ugc nofollow" target="_blank"> Spark时，Spark驱动程序和执行器都是Docker容器。这些容器使用专门为Spark构建的图像，其中包含Spark分布本身(Spark 2.4、3.0、3.1)。这意味着Spark版本不是全局簇属性，因为它适用于纱线簇。</a></p><p id="d502" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您还可以使用Docker映像在本地运行Spark。例如，您可以在纯驱动模式下(在单个容器中)运行Spark，或者在本地minikube集群上的Kubernetes上运行Spark。我们的许多用户在开发和测试过程中选择这样做。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi mo"><img src="../Images/cee9017ed146114ba98667db299640eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uGSCc5sFY8Nl8DRG.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">使用Docker将加速您的开发工作流程，并为您提供快速、可靠且可重复的生产部署。图片作者。</p></figure><p id="f4ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">‍To了解更多关于使用Docker for Spark的好处，并查看在您的开发工作流程中使用Docker的具体步骤，查看我们的文章:<a class="ae lb" href="https://www.datamechanics.co/blog-post/spark-and-docker-your-spark-development-cycle-just-got-ten-times-faster" rel="noopener ugc nofollow" target="_blank"> Spark和Docker:您的开发周期快了10倍！</a>。</p><h1 id="7ebe" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">这些Docker图像中有什么？</h1><p id="eeca" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">它们包含Spark分发版本身——来自开源代码，没有任何专有修改。</p><p id="7a4d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它们内置了到公共数据源的连接器:</p><ul class=""><li id="dd78" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">AWS S3 (s3a:// scheme)</li><li id="c2ef" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">谷歌云存储(gs:// scheme)</li><li id="98d7" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">Azure Blob存储(wasbs:// scheme)</li><li id="c375" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">Azure Datalake第1代(adls:// scheme)</li><li id="a4e4" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">蔚蓝数据湖第二代(abfss:// scheme) <a class="ae lb" href="https://docs.snowflake.com/en/user-guide/spark-connector.html" rel="noopener ugc nofollow" target="_blank"> ‍ </a></li></ul><p id="a71b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它们还内置了对<strong class="kh ir">Python</strong>&amp;<strong class="kh ir">PySpark</strong>的支持，以及<strong class="kh ir"> pip </strong>和<strong class="kh ir"> conda </strong>以便于安装额外的Python包。(如果不需要PySpark，可以使用标签前缀为‘JVM-only’的更简单的映像)</p><p id="189d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，每个映像使用以下组件版本的组合:</p><ul class=""><li id="49f9" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">Apache Spark: 2.4.5到3.1.1</li><li id="1ab5" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">Apache Hadoop: 3.1还是3.2</li><li id="a9fb" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">Java: 8或11</li><li id="f7de" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">Scala: 2.11或2.12</li><li id="b454" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">Python: 3.7还是3.8</li></ul><p id="496c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，并非所有可能的组合都存在，请查看我们的<a class="ae lb" href="https://hub.docker.com/r/datamechanics/spark" rel="noopener ugc nofollow" target="_blank"> DockerHub </a>页面以找到支持列表。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ne"><img src="../Images/094b456b22517b4f671c1770a064edf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-hL3Q7_e5YygJeGIo4VqQQ.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">我们的图像包括GCS、S3、Azure数据湖、Delta和雪花的连接器，以及对Python、Java、Scala、Hadoop和Spark的支持！图片作者。</p></figure><h1 id="4a61" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">如何使用我们的Spark Docker图片</h1><p id="770e" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">您应该使用我们的Spark Docker映像作为基础，然后通过在其上添加您的代码依赖项来构建您自己的映像。这里有一个Dockerfile示例可以帮助您开始:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nf"><img src="../Images/d32a3e1a2da7fcfea946065061774b31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MPVsXJgJIeGC1WsS.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">示例Dockerfile文件。图片作者。</p></figure><p id="c88a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦你建立了你的Docker镜像，你可以通过运行以下命令在本地运行它:<strong class="kh ir"><em class="lq">Docker run { { image _ name } } driver local:///opt/application/pi . py { args }</em></strong></p><p id="1a5a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">或者您可以将新构建的映像推送到您自己的Docker注册中心，然后在您的生产k8s集群上使用它！</p><blockquote class="ng nh ni"><p id="0b34" class="kf kg lq kh b ki kj jr kk kl km ju kn nj kp kq kr nk kt ku kv nl kx ky kz la ij bi translated"><em class="iq">不要以未经验证的方式直接从您的生产集群中提取我们的DockerHub映像，因为您有达到速率限制的风险。最好将你的图片推送到你自己的注册中心(或者从Dockerhub购买付费计划)。</em></p><p id="dee2" class="kf kg lq kh b ki kj jr kk kl km ju kn nj kp kq kr nk kt ku kv nl kx ky kz la ij bi translated"><em class="iq">数据力学用户可以直接使用来自我们</em> <a class="ae lb" href="https://docs.datamechanics.co/docs/docker-images" rel="noopener ugc nofollow" target="_blank"> <em class="iq">文档</em> </a> <em class="iq">的图片。它们有更高的可用性和一些数据机制独有的附加功能，比如Jupyter支持。</em></p></blockquote><h1 id="9355" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">结论——我们希望这些图片对您有用</h1><p id="f42f" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">这些图片对你有用吗？需要添加新的连接器或版本吗？请告诉我们，我们希望得到你的反馈。</p></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><p id="da36" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lq">原载于</em><a class="ae lb" href="https://www.datamechanics.co/blog-post/optimized-spark-docker-images-now-available" rel="noopener ugc nofollow" target="_blank"><em class="lq">https://www.datamechanics.co</em></a><em class="lq">。</em></p></div></div>    
</body>
</html>