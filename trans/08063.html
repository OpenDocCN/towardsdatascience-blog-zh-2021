<html>
<head>
<title>The Way to Deep Learning on AWS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AWS上的深度学习之路</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-way-to-deep-learning-on-aws-851fad7e5725?source=collection_archive---------4-----------------------#2021-07-24">https://towardsdatascience.com/the-way-to-deep-learning-on-aws-851fad7e5725?source=collection_archive---------4-----------------------#2021-07-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e453" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><strong class="ak">在云中使用GPUs】</strong></h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/2f661a68a5ba1cdfc18846e59f4df477.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wKuF1OF-GfOEDLHj"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@moritz_photography?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">莫里茨·金德勒</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="849d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">深度学习仍然是机器学习从业者的热门话题。与早期相比，那时你花更多的时间配置你的堆栈和你的深度学习库，而不是实际训练你的模型，我们已经取得了很大的进步。观点可能会有所不同，但Keras和Tensorflow的结合已经成为一种准标准，对于刚刚开始进入该主题的每个人来说，这绝对是最佳选择。设计深度神经网络至少仍然是一门科学，也是一门艺术。使用Keras和Tensorflow的另一个优势是，几乎每种类型的神经网络都有大量免费的深度学习Python笔记本。</p><p id="5454" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以在本地系统上安装所有的库。您将需要一个Python安装，目前最好是Python 3.x。然后您将需要Jupyter笔记本或JupyterLab。以及机器学习的标准库，如scikit.learn或Pandas。而你显然需要Keras和Tensorflow。安装这一切都是很容易做到的pip或conda，它会在您的CPU没有问题。</p><p id="69b1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以一切都很好，你只需要开始？深度学习的问题是，按照今天的标准，即使是中等规模的网络也需要通过反向传播来适应数百万个权重。这需要大量的计算能力，通常在单精度浮点或FP32中。不幸的是，即使是游戏电脑中常见的高端CPU也只能提供几百GFLOPs(每秒浮点运算)。另一方面，AWS EC2实例中最慢的GPU可以提供大约4,8 TFLOPs。因此，我们谈论的是在GPU上训练你的网络会更快的20倍。将笔记本电脑的CPU与当前的GPU相比，它将更像是两个数量级。</p><p id="1e40" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为什么这很重要？当你尝试训练和优化你的网络时，你需要合理的周转时间。如果你晚上在GPU上训练8个小时，你将在CPU上训练一周。所以除了玩具示例，你肯定需要使用GPU来在相当长的时间内得到结果。</p><h1 id="040d" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">为什么要上云？</h1><p id="986e" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">一种解决方案是在本地系统上使用GPU。这有几个缺点。一个是，由于全球芯片危机，到2021年年中，几乎不可能以合理的价格购买当前的GPU。除非你真的想投入大量资金，否则唯一有效的替代方案是购买旧的GPU，如特斯拉K10。特别是没有HDMI连接器的旧服务器GPU，有时可以以合理的价格买到二手。</p><p id="8914" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">甚至不要考虑AMD GPU，除非你想深入了解如何安装不同版本的Linux，调试和修补有缺陷的AMD库以及重新编译Tensorflow。我尝试了这一点，最后一步是AMD正式从他们的库中放弃了对我的GPU的支持。他们只是完全错过了深度学习的列车。AWS不提供AMD GPUs上的深度学习。</p><p id="a80d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你有一个合适的NVIDIA图形处理器，你需要Linux。理论上它应该可以在WIndows上运行，但是除非你投入大量时间，否则通常不会。安装所有需要的库并不简单，需要反复试验才能让GPU支持正常工作。你也不应该忘记你的GPU满负荷运行时200瓦的功耗。以德国每千瓦时约0.3€的电价为例，我们谈论的大约是每小时培训用电0.07美元。在支付AWS实例价格时，这显然不是必需的。</p><p id="78d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一个问题是你的卡上的内存，这可能是关键，取决于网络结构和大小。通常，面向游戏的GPU卡比服务器卡具有更少的板载内存。也不时有媒体文章猜测NVIDIA可能会取消对游戏GPU通用计算的支持。所以上云的说法也不少。</p><h1 id="4d33" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">我能从AWS得到什么？</h1><p id="2bfa" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">作为最大的云计算供应商，AWS很早就意识到向客户提供GPU计算能力可能是一笔好生意。所有更高级服务背后的服务总是亚马逊弹性计算云，更好地称为AWS EC2。在EC2上可以找到大量不同的实例类型。</p><p id="f9ba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当寻找用于深度学习的GPU时，当前相关的实例类型是g3、g4、p2、p3和p4。命名方案是第一个字母描述一般实例类型，数字是实例类型的代。对于GPU来说，这意味着更新的芯片设计。额外的字母给出了额外的功能，例如本地实例内存，即与EBS(弹性块存储)相对的SSD内存。然后，在一个点之后，您就可以根据vCPUs的数量、GPU的数量和主内存的数量来确定实例的大小。</p><p id="3408" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为参考，我从AWS网站收集了截至2021年7月的信息。由于我们对FP32 TFLOPs感兴趣，我查找了用于该实例的NVIDIA芯片，并参考了NVIDIA发布的FP32 TFLOPs信息。总TFLOPs乐观地假设在多个GPU配置中线性扩展。这给了我们18种可能的实例类型，用于在GPU上进行深度学习！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/983ad1472225169087c06f0bb60032d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*mXX38xeSyEV9ifpKB3alww.png"/></div></figure><p id="d62c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我没有给出实例价格，因为它们会随着你所在的地区而变化。目前，最便宜的实例(g4dn.xlarge)每小时的成本约为0.60美元，而最大的实例(p4d.24xlarge)每小时的成本约为35美元。此外，如果您计算每个TFLOP的价格，会发现定价存在巨大差异，因为其他因素也被考虑在内。但即使是FP32中最便宜的8，1 TFLOPs的GPU实例，也能给你比任何CPU都大得多的计算能力。因此，AWS可以为深度学习助手提供很多东西。</p><h1 id="6614" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">如何使用所有的TFLOPs？</h1><p id="b08c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">大多数人都会同意亚马逊是一家非常以客户为导向的公司。这也适用于销售深度学习的GPU。利用power on的一种方法是用标准的Linux AMI(或Amazon机器映像)启动EC2实例。然后，您可以ssh到新租用的计算资源，开始安装您需要的所有库，就像在本地系统上一样。但幸运的是，亚马逊的聪明人想为他们的客户节省所有的时间和麻烦。请注意，互联网上的一些教程仍然描述这种做事情的方式，到目前为止，这是完全不必要的，而且容易出错。</p><p id="ffe9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">更好的方法是只使用亚马逊提供的深度学习ami之一。亚马逊提供基于Ubuntu和亚马逊Linux的深度学习AMIs。你可以使用你喜欢的任何东西，但是注意，用来登录的用户是不同的；ec2-亚马逊Linux的用户和ubuntu的Ubuntu。我更喜欢亚马逊Linux，所以相应地适应。</p><p id="cc02" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用深度学习AMIs的优势在于，亚马逊已经为AWS基础设施安装并优化了相关的库。ami预装了MXNet、PyTorch、Keras、Tensorflow和Tensorflow 2。对于GPU的使用，所有这些库都使用NVIDIA CUDA，这也是包含和预配置的，截至目前，最常用的组合是基于Tensorflow的Keras(而不是基于CUDA的Tensorflow 2)。没有必要自己安装这个堆栈，除非你真的想详细了解它的内部工作原理，或者想使用绝对最新的版本。</p><p id="306b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">基于深度学习AMI，这里解释了如何连接到EC2实例并执行下面的示例笔记本。创建AWS帐户后，您可以转到AWS web控制台并搜索ec2。一旦你在那里，你会发现右上角的“启动实例”按钮。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/1736e716908d278cf2330a402f94e546.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HKw5pOTT-qDLDX2A"/></div></div></figure><p id="cd31" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">启动EC2实例的第一步是选择AMI或Amazon机器映像。这有点像本地磁盘上的引导分区，或者更准确地说，是它的第一个版本。如果您稍后修改该实例，它将不会反映在AMI中，而只会反映在该实例的附加存储上。您可以创建自己的ami或ami版本，但这超出了本文的范围。</p><p id="7a50" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有各种各样的深度学习人工智能可用。我会选择基于亚马逊Linux 2的，因为它似乎是最新的，我更喜欢亚马逊Linux。您还可以看到预安装的库及其版本。真正好的是，它们针对大多数EC2实例类型进行了预配置，包括GPU和优化的CPU使用。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/2d1eb5e040e89307f4977f0c1a444eaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7a0-3Y7ZMV5CIcCb"/></div></div></figure><p id="0cda" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一步是选择实例类型。您将只能选择与AMI兼容的实例类型。您可以按实例族(如g4dn)进行过滤，以查找支持GPU的实例类型。您还会看到一些关于实例类型的相关信息。您不会看到GPU的数量和类型，因此您必须记住这一点，或者使用本文中上面的便利表格。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/85001e3ec7d8a4de414e2fefdac53bb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*f7KJ1RS4C3aYCXoe"/></div></div></figure><p id="ac06" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">启动实例时，可能会出现一些警告。一个问题是，GPU实例不是免费层的一部分，所以即使在使用AWS的前12个月，你也必须付费。第二件事是安全组默认对世界开放。它仍然受到SSH和密钥对的保护，但是对于Python笔记本场景，最好只限制对您的IP的访问。第三件事是，大多数AWS帐户都有配额，其中不包括GPU实例，以防止欺诈和计费冲击。你可以通过开一张票来改变这个报价，它通常会通过。然而这需要几个小时。请注意，配额在vCPUs上！例如，在g4dn实例类型中，您需要至少4 (v)个CPU的配额才能启动最小的实例类型。由于AWS以客户为导向，您将在AWS web控制台的警告或错误消息中找到解决所有这些问题的便捷链接。</p><p id="25e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你需要的最后一件事是一个密钥对，以便能够从互联网访问你的机器。请注意，您必须将它存储在本地，因为您将无法再次从AWS中检索它！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/df6e3236faff3d3bcfd6b9f4da7491f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/0*f8UaNplcbEh5mDtc"/></div></figure><p id="bf00" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在您按下“启动实例”之后，如果使用AWS，您将会遇到一个不利的情况:您必须等待几分钟实例才能启动。考虑到他们必须分配虚拟资源、配置网络和路由器、连接存储和启动Linux，几分钟似乎是合理的。然而，这比从SSD启动本地系统花费的时间要长得多。</p><p id="92dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">恭喜你，几分钟后，你将有一个虚拟系统在云端运行，等待你使用。现在，你能用它做什么？其实不多。基本上，您现在唯一能做的就是使用您已经安全存储的密钥对对它进行ssh。</p><p id="9ae6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为此，您需要新启动的实例的公共IP地址。您可以通过单击实例详细信息来查找它。如果你选择了Amazon Linux，你可以在Ubuntu上以ec2-user的身份登录。从Linux或MacOS在系统上使用ssh非常简单:</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="d029" class="mz lt iq mv b gy na nb l nc nd">ssh -i my-key-pair.pem ec2-user@ip.region.compute.amazonaws.com</span></pre><p id="705e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在Windows AWS上，建议使用您必须预先安装的PuTTY。在PuTTY中，您需要相同的信息。您在SSH → Auth → private key file中输入用户和公共IP als主机名以及密钥文件。注意，密钥文件有两种不同的格式，您可以使用PuTTYgen来回转换文件。PuTTYgen与PuTTY一起安装，对于Linux和MacOS，您将需要一个pem文件，而对于PuTTY，您将需要一个ppk文件。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/a8abeba31280751233733fa5d6c3b1a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/0*xwUJKWSjZNlWG5PZ"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/86e53475baa00af8d4b5443a0298bc6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/0*tmHt6HrOVijhns_R"/></div></figure><p id="3021" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">完成所有这些步骤后，您将最终在云中看到您新租用的系统的控制台。AWS将向您展示，您已经安装了相当多的Python和深度学习框架的不同组合的环境。要开始使用Keras，我推荐TensorFlow(+Keras2)和Python3 (CUDA +和英特尔MKL-DNN)。正如您所看到的，这些配置包含了相当多的库，希望能在所有AWS实例类型上为您提供最佳性能。要开始，请键入:</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="448b" class="mz lt iq mv b gy na nb l nc nd">source activate tensorflow_p37</span></pre><p id="b25c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦你运行了这个Python环境，你就可以通过输入jupyter notebook来创建一个笔记本。但是，您将无法从浏览器访问它，因为您的AWS实例将只接受ssh连接，而不接受任何其他端口上的连接。对于Jupyter笔记本电脑，您可以调整安全组，使其也接受从您的IP到端口8888的连接。推荐且更安全的方法是建立ssh隧道。</p><p id="d3fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在MacOS或Linux上设置隧道是通过以下命令行完成的:</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="f955" class="mz lt iq mv b gy na nb l nc nd">ssh -i my-key-pair.pem -L 8888:localhost:8888 <br/>  ec2-user@ip.region.compute.amazonaws.com</span></pre><p id="cc1e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用PuTTY是另一个菜单中的另一个选项:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/9da98dfb1b5aa75ee4714ea046324759.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/0*AlNqRtmjgzfSxui7"/></div></figure><p id="7ff7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将要发生的是，ssh或PuTTY将在您的本地主机上建立隧道，并启动与您的AWS实例的控制台会话。您必须保持ssh或PuTTY运行，以使隧道工作。一旦在实例上启动了Jupyter笔记本，就可以使用localhost:8888在浏览器上访问它。不要忘记在启动笔记本之前设置环境，因为在不同的Python环境中可能会有不同版本的Jupyter。最终我们得到了我们需要的开始。在笔记本中，您将再次有各种Python内核和库可供选择。你应该用conda_tensorflow_p37内核。</p><h1 id="63fc" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">有更简单的方法吗？</h1><p id="b963" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">与在本地系统上运行整个堆栈相比，在EC2实例上使用深度学习AMIs已经相当容易了。你可以考虑的一个选择是使用docker容器，它也是AWS为深度学习提供的。唯一合适的情况是，您已经在AWS上运行了一个容器基础设施。在这样的设置中，部署训练好的模型变得更容易，但是对于开始深度学习的人来说，这是未来相当多的步骤，你直接使用AMI学到的一切仍然适用。</p><p id="9bb0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一个值得考虑的替代产品是AWS Sagemaker。定义Sagemaker是相当棘手的，因为它基本上只是AWS的一个相当大的机器学习产品集的营销名称。除了已经在Sagemaker旗下提供了大量服务之外，AWS还在不断扩展这一服务。深度学习只是其中的一小部分。</p><p id="5bc0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里要考虑的服务是Sagemaker笔记本。或者有Sagemaker工作室，但这是截至2021年7月的最近产品。目前我看不出使用Sagemaker Studio有什么好处，但这可能会随着时间的推移而改变。</p><p id="c08a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从深度学习开始使用Sagemaker笔记本变得更加容易，并且您还可以在单独的实例上进行培训。这意味着您的笔记本电脑实际上不需要GPU实例，而只是为了训练您的网络。以下是对这种情况的逐步解释。</p><p id="9bf9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与使用普通EC2不同，您可以在AWS控制台上搜索Sagemaker:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/85006026e00ecd5dff89b9485ea8f76b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*siKLtPXUxFkY3oDS"/></div></div></figure><p id="7f97" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，我们要创建一个笔记本，所以只需查找笔记本→笔记本实例，然后选择创建。现在，您可以选择所需的实例类型。用于Sagemaker的所有实例类型都有一个“ml”在他们的名字前面加上前缀。您还需要一个IAM角色，但是您可以让Sagemaker为您创建一个默认角色并使用它。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/570c31ab8a5325e624cdc588159ec9d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oXVhk9-qZLfGJnQy"/></div></div></figure><p id="e866" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">按下“创建笔记本实例”并再次等待几分钟。一旦AWS为您设置好一切，您就可以看到您的笔记本实例。使用Jupyter notebook或JupyterLab就像点击提供给您的链接一样简单。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/606a7e2a0862f3a2b20d72d2de6db7d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Vx86mSihIPe_KwcT"/></div></div></figure><p id="1ca6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这很容易。缺点是什么？正如您在分步示例中看到的，您将使用ml。EC2实例类型的变体。由于生活中没有免费的东西，AWS目前将对使用Sagemaker的每一小时收取30%的费用！公平地说，Sagemaker还有额外的好处。然而，如果你刚刚开始探索深度学习，这些额外的服务并不真正相关。</p><p id="a31d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果易用性值得，额外费用由您决定。不利的一面是，Sagemaker使用的图像似乎比深度学习AMIs的最新版本要老一些。随着机器学习和深度学习的流行包的新版本以相当高的频率发布，这对你来说可能是个问题。</p><h1 id="d728" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">摘要</h1><p id="e464" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">虽然长期以来，先进的深度学习实验一直是拥有必要硬件的IT专家的专属，但现在每个人都可以在云中进行，Sagemaker等AWS服务使几乎每个人都有可能拥有Python的基本技能和机器学习的一般知识。您将能够使用高端硬件进行培训，使您能够从最近的研究成果中获得深度网络方面的经验。这将花费你，但是为你的本地系统购买一个700美元以上的现代GPU将会为你购买相当多的云培训时间。</p><p id="145c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有了AWS服务，如果你愿意支付账单，你基本上没有任何限制。其他云供应商也有替代方案，有些甚至是免费的，免费的解决方案通常有一些限制，这取决于您想要处理的网络和数据可能是至关重要的。总之，当前的AWS产品非常有吸引力，为以合理的成本进行深度学习实验提供了一个良好的起点。</p></div></div>    
</body>
</html>