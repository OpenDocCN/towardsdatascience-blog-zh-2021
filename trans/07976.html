<html>
<head>
<title>Discussing Trust, Ethics, and Responsibility in ML at ICML, VLDB, and ICLR</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在ICML、VLDB和ICLR讨论ML中的信任、道德和责任</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/discussing-trust-ethics-and-responsibility-in-ml-at-icml-vldb-and-iclr-46b85b368375?source=collection_archive---------48-----------------------#2021-07-21">https://towardsdatascience.com/discussing-trust-ethics-and-responsibility-in-ml-at-icml-vldb-and-iclr-46b85b368375?source=collection_archive---------48-----------------------#2021-07-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5fae" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">随着人工智能研究中的道德和责任问题开始在全球人工智能社区中引起共鸣，我们来看看今年致力于这项事业的一些研讨会。</h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/b3d004744c71ed60a17233ef7be9239d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OG2M2IXplQECVgjP"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">由<a class="ae kw" href="https://unsplash.com/@askkell?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">安迪·凯利</a>在<a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="93d2" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">人工智能研究和相关讨论正在如火如荼地进行——这对任何人来说都不奇怪。另一方面,“负责任的人工智能”的说辞还有待改进。根据去年的一项调查，目前只有25%的公司认为无偏见的人工智能是一个有价值的目标。大型科技公司已经采取措施来改变这种状况，但总的来说，私营部门还没有把负责任的人工智能作为优先事项。</p><p id="cb1b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">与此同时，当你申请银行贷款时，通常是<a class="ae kw" href="https://www.nature.com/articles/s41599-020-0501-9.pdf" rel="noopener ugc nofollow" target="_blank">机器根据交叉引用年龄、性别、邮政编码和语言等因素的算法来决定你是被批准还是被拒绝</a>。许多工作申请现在也是这样评估的。当你进入一辆现代汽车，语音识别被使用，你被理解的程度(或者根本不被理解)取决于你的口音。自然，这些因素引起了对ML模型如何构建和实现的合理关注。</p><p id="94aa" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">一些世界领导人非常清楚受控和良好维护的人工智能实践的重要性。例如，去年，欧洲议会发表了一份100页的综合报告，内容是关于与不受控制的人工智能发展相关的潜在问题。WEF和经合组织也公开反对黑箱算法和不道德的数据使用。</p><p id="828e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">显然，ML科学家今天从事和监督的研究有着深远的影响。这种发展必须为透明管道留出空间，以适应公平和道德的决策，避免歧视和不公正。或者至少没有损坏的数据——这将是第一个危险信号，接下来会有更多的麻烦。</p><p id="bdab" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">世界各地的许多ML研讨会和会议已经开始定期关注这些关键问题，希望有所作为。让我们来看看今年最有趣的三个例子。</p><p id="e8cf" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir"> →负责任的人工智能:对公平性、可解释性、安全性、健壮性和超越性之间的实际限制和权衡的跨学科视角</strong></p><p id="ef6d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">作为今年ICLR会议的一部分，5月7日举行了一次跨学科研讨会。该研讨会聚集了各个人工智能子领域的专家，从学术界和商业到政府-包括研究人员和从业人员。目的是从公平性、安全性和可解释性的角度评估ML管道。通过一系列谈话，该活动提出了反映在道德和法律准则和实践中的透明度和偏见(黑盒算法)问题，其中包括刑事司法、医学和教育。</p><p id="136b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">演讲者</strong></p><p id="037d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">所有的谈话都被记录下来，可以在<a class="ae kw" href="https://iclr.cc/virtual/2021/workshop/2132" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="0aed" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">📣这篇题为“负责任的解释:仅有良好的意愿是不够的”的演讲是由谷歌大脑的科学家贝金博士发表的。金从社会责任的角度提出了她对曼梯·里未来的看法。她展示了一系列作品，并重新审视了可解释ML中的目标和方法。</p><p id="a1d9" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">📣下一个演讲的题目是“作为一名社会科学家与计算机科学家一起工作的挑战和机遇”，由南加州大学的副教授埃里克·赖斯博士主讲。Eric讨论了人工智能的当代研究，分享了他对人工智能驱动的干预计划的见解，并介绍了他对无家可归的青少年进行艾滋病毒预防干预的3项主要研究结果。</p><p id="e133" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">📣另一个题为“创造人们可以使用的模型:来自健康应用的经验”的演讲是由哈佛大学副教授约翰·l·勒布和T2的压轴博士多希-维勒兹做的。Finale讨论了人类受试者实验，这些实验测试了旨在促进人工智能和临床医生在抗抑郁治疗背景下的交互的界面。她揭示了临床医生提出的最常见的改进要求，以及他们对正确和不正确的人工智能建议的反应。</p><p id="f817" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">关于ICLR </strong></p><p id="ebcf" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">学习表征国际会议(ICLR)是每年春天举行的国际ML会议。第一届ICLR会议于2013年举行，自那以来已经成为计算机科学家的主要聚会。今年有近3000篇论文提交，30%的接受率，今天大会被认为是人工智能和人工智能领域的前三大全球活动。</p><p id="80e5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir"> →规模化众包数据管理中的信任、道德和卓越</strong></p><p id="8c10" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">作为VLDB今年第47期的一部分，一个群体科学研讨会将在会议的最后一天，即8月20日举行。该研讨会名为“大规模众包数据管理中的信任、道德和卓越”，将涵盖数据标签众包方法的三个主要问题:大规模数据卓越、人群-人工智能相互作用以及信任和道德。</p><p id="34e5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在研讨会期间，三位主旨发言人将考察众包在大规模研究中的作用，重点是众包工作者的福利和注释数据的可信度。</p><p id="53e4" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">扬声器</strong></p><p id="c5bd" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">📣题为“计算与组织”的第一个研讨会演讲由获奖作者、斯坦福大学副教授迈克尔·伯恩斯坦博士主讲。迈克尔将研究工作和在线平台的未来。他将讨论未来如何组织工作，以及当前的基础设施如何导致权利被剥夺和异化。然后，他将从工程和设计的角度以及政策的角度描述应对这些负面结果的可能对策。</p><p id="058d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">📣第二个演讲的题目是“健康字节:培育群体工作的可持续未来”，由荷兰代尔夫特理工大学助理教授Ujwal Gadiraju博士主讲。虽然大多数与众包市场相关的问题和解决方案主要集中在数据质量上，但加迪拉朱博士将研究该领域鲜为人知的问题——大众工作者的福祉。通过使用MTurk和perspective作为例子，研究人员将从那些完成任务的人的角度剖析微任务众包，包括他们的薪酬和身心健康。将讨论管理众包的合同法的必要性。</p><p id="16aa" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">📣题为“数字社区驱动的众包”系列的最后一个演讲由<a class="ae kw" href="https://www.datasciencenigeria.org/wuraola-oyewusi/" rel="noopener ugc nofollow" target="_blank">Wuraola oye wus</a>主讲，他是尼日利亚<em class="lt">数据科学</em>的研究和创新负责人。演讲者将提供她对众包“人性化”方面的见解，即众包工作者不仅可以与众包平台互动，还可以在全球和区域社区内互动。将讨论众包背景下人与人之间的学习和反馈，并提供新的员工培训模式。</p><p id="8863" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">关于VLDB </strong></p><p id="363e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">成立于1975年的<em class="lt">超大型数据库国际会议</em> (VLDB)是致力于数据库管理的研究人员和开发人员最重要的年度聚会之一。由美国VLDB基金会组织，每年在不同的国家举行，备受期待的2021年VLDB奥运会将于8月16日至20日在丹麦哥本哈根举行。</p><p id="161b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir"> →社会责任ML </strong></p><p id="11f8" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">作为ICML今年第38期的一部分，一个虚拟研讨会将于7月24日举行。该研讨会将汇集理论和应用研究人员，目的是讨论如何建立对社会负责的ML管道。在其他主题中，将提出易受安全和隐私攻击、数据泄露以及种族和性别偏见等问题。该研讨会将讨论缺乏透明度的问题，以及它如何导致现实生活中故意或意外的数据扰动。</p><p id="52fc" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">关于ICML </strong></p><p id="ff1a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">机器学习国际会议(ICML)是人工智能和人工智能领域的领先全球会议。首次于1980年在匹兹堡举行，这一年度活动致力于统计和数据科学，重点是机器视觉，计算生物学，语音识别和机器人技术。这是目前世界上发展最快的人工智能聚会之一。今年的会议日期是7月18日至24日。</p><p id="7a03" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">主要外卖</strong></p><p id="3856" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">随着人工智能研究的进展，道德和公平的问题变得日益重要。对透明和建造良好的ML管道的需求是这种日益增长的关注的中心。目标是确保新兴技术的明显优势不会被不负责任的人工智能开发带来的问题所掩盖。本文中提到的研讨会详细研究了这些伦理问题，并提供了一些解决方案。</p></div></div>    
</body>
</html>