<html>
<head>
<title>The Explainable Boosting Machine</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可解释的助推器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-explainable-boosting-machine-f24152509ebb?source=collection_archive---------1-----------------------#2021-04-02">https://towardsdatascience.com/the-explainable-boosting-machine-f24152509ebb?source=collection_archive---------1-----------------------#2021-04-02</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><h2 id="4386" class="is it iu bd b dl iv iw ix iy iz ja dk jb translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/tag/explainable-ai" rel="noopener">可解释的人工智能</a></h2><div class=""/><div class=""><h2 id="b2a3" class="pw-subtitle-paragraph ka jd iu bd b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr dk translated">像梯度推进一样精确，像线性回归一样可解释。</h2></div><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ks"><img src="../Images/3a67a1716a7ba2f59946a5cb86309f78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4TvF3j3hYiwvLbGW"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">由<a class="ae li" href="https://unsplash.com/@fabulu75?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Fabrice Villard </a>在<a class="ae li" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="6eb9" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">可解释性和准确性的权衡</h1><p id="8596" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">在机器学习社区，我经常听到和读到关于<em class="mx">可解释性</em>和<em class="mx">准确性</em>的概念，以及它们之间如何进行权衡。通常，它是这样描述的:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj my"><img src="../Images/d330fa0dc295260b506068f798014580.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*SI3wAOvfTQrLl5NXQHwuxA.png"/></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="74cf" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">你可以这样理解:线性回归和决策树是非常简单的模型，一般来说并不精确。神经网络是<em class="mx">黑盒模型</em>，也就是说，它们很难解释，但通常表现得相当不错。像随机森林和梯度推进这样的集合模型也不错，但很难解释。</p><h2 id="f4d8" class="ne lk iu bd ll nf ng dn lp nh ni dp lt mk nj nk lv mo nl nm lx ms nn no lz ja bi translated">可解释性</h2><p id="8e6b" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">但是什么是可解释性呢？对此没有明确的数学定义。一些作者，如[1]和[2]将可解释性定义为人类可以理解和/或预测模型输出的属性<strong class="md je">。这有点不切实际，但我们仍然可以根据这一点对机器学习模型进行分类。</strong></p><p id="4f86" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">为什么线性回归<em class="mx"> y=ax+b+ɛ </em>可以解释？因为你可以说类似“增加一个<em class="mx"> x </em>增加一个<em class="mx"> a </em>的结果”。该模型不会给你一个意外的输出。越大的<em class="mx"> x </em>，越大的<em class="mx"> y </em>。较小的<em class="mx"> x </em>较小的<em class="mx"> y </em>。没有输入<em class="mx"> x </em>会让<em class="mx"> y </em>以奇怪的方式摆动。</p><p id="290c" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">为什么神经网络不可解释？好吧，试着猜测一个128层深度神经网络的输出，不用实际实现，不用纸笔。当然，输出是根据某个大公式得出的，但是即使我告诉你对于<em class="mx"> x </em> =1，输出是<em class="mx"> y </em> =10，对于<em class="mx"> x </em> =3，输出是<em class="mx"> y </em> =12，你也猜不出<em class="mx"> x </em> =2的输出。可能是11，可能是-420。</p><h2 id="847e" class="ne lk iu bd ll nf ng dn lp nh ni dp lt mk nj nk lv mo nl nm lx ms nn no lz ja bi translated">准确(性)</h2><p id="ba4e" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">这是你能接受的——原始数据。对于回归，均方差、平均绝对误差、平均绝对百分比误差，应有尽有。对于分类，F1，精度，召回，当然，还有老国王本人的准确性。</p></div><div class="ab cl np nq hy nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="in io ip iq ir"><p id="12e8" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">让我们回到图片上来。虽然我同意这一点，但我想强调以下几点:</p><blockquote class="nw"><p id="4e11" class="nx ny iu bd nz oa ob oc od oe of mw dk translated"><strong class="ak">可解释性和准确性之间没有内在的平衡</strong>。有些模型既可解释又准确。</p></blockquote><p id="7a34" class="pw-post-body-paragraph mb mc iu md b me og ke mg mh oh kh mj mk oi mm mn mo oj mq mr ms ok mu mv mw in bi translated">所以，不要让这张图骗了你。<strong class="md je">可解释的助推机器</strong>将帮助我们突破中间向下倾斜的线，到达我们图表右上角的圣杯。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj my"><img src="../Images/7292fcaa21f8907f5676f47b5c5b8e5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*VEZDShIrgmDyxBUZyocihw.png"/></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="cc00" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated"><em class="mx">(当然，您也可以创建不准确且难以解释的模型。这是一个你可以自己做的练习。)</em></p></div><div class="ab cl np nq hy nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="in io ip iq ir"><p id="6b23" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">阅读本文后，您将能够</p><ul class=""><li id="a334" class="ol om iu md b me mz mh na mk on mo oo ms op mw oq or os ot bi translated">理解为什么可解释性很重要，</li><li id="ca24" class="ol om iu md b me ou mh ov mk ow mo ox ms oy mw oq or os ot bi translated">解释黑箱解释的缺点，如石灰和沙普利值，以及</li><li id="126d" class="ol om iu md b me ou mh ov mk ow mo ox ms oy mw oq or os ot bi translated">理解并使用可解释的助推机器学习器</li></ul><h1 id="9cd7" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">解释的重要性</h1><p id="fa54" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">能够解释模型有几个好处。它可以帮助您改进模型，有时它甚至是业务所必需的，简单明了。</p><h2 id="1e11" class="ne lk iu bd ll nf ng dn lp nh ni dp lt mk nj nk lv mo nl nm lx ms nn no lz ja bi translated">模型改进</h2><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ks"><img src="../Images/870798f348f6c3c52cfe50597b1f7947.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*I8eoQfmuc0nl5zoc"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">照片由<a class="ae li" href="https://unsplash.com/@alevisionco?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">alevision.co</a>在<a class="ae li" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="a09b" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">假设你想建立一个模型来预测房子的价格。<em class="mx">有创意吧？</em>其中一个输入特征是<strong class="md je">房间数量</strong>。其他特征包括大小、建造年份和一些衡量社区质量的指标。标准化特征后，您决定使用线性回归。测试集上的<em class="mx"> r </em>很好，您可以部署模型。在稍后的时间点，新的房屋数据进来，你注意到你的模型相当偏离。<strong class="md je">哪里出了问题？</strong></p><p id="2117" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">由于线性回归具有高度的可解释性，您可以直接看到答案:特征“房间数量”的系数是负的，尽管作为一个人，您会期望它是正的。房间越多越好，对吧？但是<strong class="md je">型号因为某种原因学了相反的</strong>。</p><p id="42cc" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">这可能有很多原因。也许你的训练和测试集是有偏见的，如果一个房子有更多的房间，它往往是旧的。如果房子越旧，价格就越便宜。</p></div><div class="ab cl np nq hy nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="in io ip iq ir"><p id="0eac" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">这是你唯一能够发现的东西，因为你可以看看模型内部是如何工作的。您不仅可以发现它，还可以修复它:您可以将“房间数”的系数设置为零，或者您也可以重新训练该模型并将“房间数”的系数强制为正。这是你可以通过设置关键字<code class="fe oz pa pb pc b">positive=True</code>用scikit-learn的<code class="fe oz pa pb pc b">LinearRegression</code>做的事情。</p><blockquote class="pd pe pf"><p id="0ec2" class="mb mc mx md b me mz ke mg mh na kh mj pg nb mm mn ph nc mq mr pi nd mu mv mw in bi translated">注意，这将所有的T2系数设为正。如果你想完全控制系数，你必须写你自己的线性回归。你可以查看<a class="ae li" rel="noopener" target="_blank" href="/build-your-own-custom-scikit-learn-regression-5d0d718f289">这篇文章</a>来开始。</p></blockquote><h2 id="9fe3" class="ne lk iu bd ll nf ng dn lp nh ni dp lt mk nj nk lv mo nl nm lx ms nn no lz ja bi translated">业务或法规要求</h2><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pj"><img src="../Images/f6abeb12edc5f375ed62c46e9ddcd68b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6SiIUWC_2JP3-kvJ"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated"><a class="ae li" href="https://unsplash.com/@tingeyinjurylawfirm?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">廷杰律师事务所</a>在<a class="ae li" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="66ba" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">通常，利益相关者希望至少有一些关于事情为什么会发生的直觉，你必须能够向他们解释。虽然即使是最非技术人员也可以同意“我将一堆数字加在一起”(线性回归)或“我沿着一条路径走，并根据一些简单的条件向左或向右走”(决策树)，但对于神经网络或集成方法来说，这要困难得多。农民不知道的东西他不吃。这是可以理解的，因为这些利益相关者经常要向其他人报告，而其他人也需要对事情大致如何运作的解释。祝你好运，向你的老板解释梯度推进，这样他或她可以把知识传递给更高的实例，而不会犯任何重大错误。</p><p id="d3e5" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">除此之外，可解释性甚至可能是法律所要求的。如果你为一家银行工作，并且创建了一个决定一个人是否能获得贷款的模型，那么你很有可能被法律要求创建一个可解释的模型，这可能是逻辑回归。</p></div><div class="ab cl np nq hy nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="in io ip iq ir"><p id="ffc4" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">在我们讨论可解释的助推机器之前，让我们先看看一些解释黑盒模型的方法。</p><h1 id="e294" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">黑盒模型的解释</h1><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pk"><img src="../Images/5fc893080e9978a3c08ac8f21229a859.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1LTNBE2EPRkdE4yd"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">劳拉·乔伊特在<a class="ae li" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="006c" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">有几种方法试图解释黑盒模型的工作原理。所有这些方法的优点是你可以利用你已经训练好的模型，并在此基础上训练一些解释者。这些解释器使模型更容易理解。</p><p id="4b0f" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">这种解释器的著名例子是局部可解释的模型不可知解释(<em class="mx">LIME</em>)【3】和Shapley值【4】。让我们快速了解一下这两种方法的缺点。</p><h2 id="054c" class="ne lk iu bd ll nf ng dn lp nh ni dp lt mk nj nk lv mo nl nm lx ms nn no lz ja bi translated">石灰的缺点</h2><p id="e1b5" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">在LIME中，你试图一次解释你的模型的一个预测。给定一个样本<em class="mx"> x </em>，为什么标签是<em class="mx"> y </em>？假设您可以在围绕<em class="mx"> x. </em>的封闭区域中用一个可解释的模型来近似您的复杂黑盒模型。这个模型被称为<strong class="md je">代理模型</strong>，通常为此选择线性/逻辑回归或决策树。然而，如果近似不好，你可能没有注意到，解释就会产生误导。</p><p id="a0f3" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">还是一个你要注意的<a class="ae li" href="https://github.com/marcotcr/lime" rel="noopener ugc nofollow" target="_blank">甜库</a>。</p><h2 id="431f" class="ne lk iu bd ll nf ng dn lp nh ni dp lt mk nj nk lv mo nl nm lx ms nn no lz ja bi translated">沙普利值</h2><p id="ef4e" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">使用Shapley值，可以将每个预测分解为每个特征的单独贡献。例如，如果您的模型输出50，使用Shapley值，您可以说要素1贡献了10，要素2贡献了60，要素3贡献了-20。这三个Shapley值之和是10+60–20 = 50，即模型的输出。这很好，但遗憾的是，这些值极难计算。</p><p id="275a" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">对于一般的黑盒模型，计算它们的运行时间是特征数量的指数级。如果你有几个特性，比如10个，这可能还是可以的。但是，根据你的硬件，20美元可能已经不可能了。公平地说，如果你的黑盒模型由树组成，有更快的近似值来计算Shapley值，但它仍然会很慢。</p><p id="09e9" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">不过，Python有一个很棒的<a class="ae li" href="https://shap.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> shap库</a>，它可以计算Shapley值，你绝对应该去看看！</p></div><div class="ab cl np nq hy nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="in io ip iq ir"><p id="c542" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">不要误解我。<strong class="md je">黑盒解释比完全没有解释要好得多</strong>，所以如果你出于某种原因不得不使用黑盒模型，就使用它们。但是当然，如果你的模型表现良好<em class="mx">并且同时</em>是可解释的，那就更好了。现在终于到了继续寻找这种方法的代表的时候了。</p><h1 id="c828" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">可解释的助推器</h1><p id="a35d" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">可解释的助推的基本思想一点也不新鲜。它始于加法模型，早在1981年就由杰罗姆·h·弗里德曼和沃纳·斯图兹尔首创。这种类型的模型具有以下形式:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pl"><img src="../Images/849d76473d16426d402b1ab1d2028c96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UF_nKxXPXNrckg6rbxDRNQ.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="64dd" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">其中<em class="mx"> y </em>是预测值，而<em class="mx"> x </em> ₁、…、<em class="mx"> xₖ </em>是输入特征。</p><h2 id="7622" class="ne lk iu bd ll nf ng dn lp nh ni dp lt mk nj nk lv mo nl nm lx ms nn no lz ja bi translated">一位老友</h2><p id="8b9b" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">我声称你们所有人都已经偶然发现了这样一个模型。让我们大声说出来:</p><blockquote class="nw"><p id="d670" class="nx ny iu bd nz oa ob oc od oe of mw dk translated">线性回归！</p></blockquote></div><div class="ab cl np nq hy nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="in io ip iq ir"><p id="330a" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">线性回归只不过是一种特殊的可加模型。在这里，所有的功能<em class="mx"> fᵢ </em>就是身份，即<em class="mx">。f </em> ᵢ( <em class="mx"> xᵢ </em> ) = <em class="mx"> xᵢ </em>。很简单，对吧？但是你也知道，如果违背了<a class="ae li" href="https://en.wikipedia.org/wiki/Linear_regression#Assumptions" rel="noopener ugc nofollow" target="_blank">的假设</a>，特别是<strong class="md je">的线性假设</strong>，线性回归可能不是精度方面的最佳选择。</p><p id="8296" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">我们需要的是更通用的函数，能够捕捉输入和输出变量之间更复杂的相关性。微软的一些人给出了一个如何设计这种功能的有趣例子[5]。更好的是:他们为Python甚至围绕这个想法开发了一个舒适的包。</p><p id="93f4" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">注意，在下文中，我将只描述可解释的增压<strong class="md je">回归变量</strong>。分类也很有效，并不复杂。</p><h2 id="ba13" class="ne lk iu bd ll nf ng dn lp nh ni dp lt mk nj nk lv mo nl nm lx ms nn no lz ja bi translated">解释</h2><p id="ea27" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">你可能会说:</p><blockquote class="nw"><p id="610f" class="nx ny iu bd nz oa ob oc od oe of mw dk translated">有了这些函数f，这看起来比线性回归更复杂。这个怎么更容易解读？</p></blockquote><p id="8add" class="pw-post-body-paragraph mb mc iu md b me og ke mg mh oh kh mj mk oi mm mn mo oj mq mr ms ok mu mv mw in bi translated">为了说明这一点，假设我们已经训练了一个如下所示的附加模型:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pm"><img src="../Images/fc1920647127a128120f38da7e826565.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LpMH56IPOVA8ITEGwGuwbQ.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="5572" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">您可以将(16，2)插入到模型中，并接收5+12–16 = 1作为输出。这是已经分解的1的输出——有一个5的<em class="mx">基线</em>,然后功能1提供了一个额外的12，功能3提供了一个额外的-16。</p><p id="ddbc" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">事实上，所有的功能，即使它们很复杂，也只是由简单的加法组成，这使得这个模型很容易解释。</p><p id="ecba" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">现在让我们看看这个模型是如何工作的。</p><h2 id="cd31" class="ne lk iu bd ll nf ng dn lp nh ni dp lt mk nj nk lv mo nl nm lx ms nn no lz ja bi translated">这个想法</h2><p id="2c0e" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">作者以类似梯度推进的方式使用小树。如果你不知道梯度增强是如何工作的，请参考这个很棒的视频。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pn po l"/></div></figure><p id="d330" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">现在，代替在所有特征上训练每棵小树，可解释的增强回归器的作者提议用<strong class="md je">一次一个特征</strong>训练每棵小树。这将创建一个如下所示的模型:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pl"><img src="../Images/a9c8bc8732fbca686c87059e169695d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6gmus_xHnElVJWP0ZBlE1A.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="fceb" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated"><strong class="md je">你可以在这里看到以下内容:</strong></p><ul class=""><li id="6b13" class="ol om iu md b me mz mh na mk on mo oo ms op mw oq or os ot bi translated">每个<em class="mx"> T </em>都是深度小的树。</li><li id="abd6" class="ol om iu md b me ou mh ov mk ow mo ox ms oy mw oq or os ot bi translated">对于每一个<em class="mx"> k </em>特征，<em class="mx"> r </em>树被训练。所以，你可以在方程中看到<em class="mx"> k*r </em>不同的<em class="mx"> </em>树。</li><li id="40c9" class="ol om iu md b me ou mh ov mk ow mo ox ms oy mw oq or os ot bi translated">对于每个特征，其所有树的总和就是前面提到的<em class="mx"> f </em>。</li></ul><p id="960e" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">这意味着函数<em class="mx"> f </em>由小树的和组成。由于树的用途非常广泛，许多复杂的函数都可以非常精确地建模。</p><p id="b0bd" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">请务必观看此视频，了解另一种解释:</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pn po l"/></div></figure><p id="154c" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">好吧，我们已经看到了它是如何工作的，你可以很容易地解释可解释的增压机的输出。但是这些模型有什么好的吗？他们的论文[5]这样写道:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pp"><img src="../Images/f4bf1ddbe593a5b7a6bf68164afbf3a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K7naOnYi5EQx2xrMf4PAWA.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片摘自[5]。可解释增压机。</p></figure><p id="2f28" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">我看不错！当然，我也测试了这个算法，它在我的数据集上也很有效。说到测试，让我们看看如何在Python中实际使用可解释的boosting。</p><h2 id="d02e" class="ne lk iu bd ll nf ng dn lp nh ni dp lt mk nj nk lv mo nl nm lx ms nn no lz ja bi translated">在Python中使用可解释的增强</h2><p id="cc1e" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">微软的<a class="ae li" href="https://github.com/interpretml/interpret" rel="noopener ugc nofollow" target="_blank">解释包</a>使得使用explainable boosting变得轻而易举，因为它使用了scikit-learn API。这里有一个小例子:</p><pre class="kt ku kv kw gu pq pc pr bn ps pt bi"><span id="fca2" class="pu lk iu pc b be pv pw l px py">from interpret.glassbox import ExplainableBoostingRegressor<br/>from sklearn.datasets import load_boston<br/><br/>X, y = load_boston(return_X_y=True)<br/><br/>ebm = ExplainableBoostingRegressor()<br/>ebm.fit(X, y)</span></pre><p id="3203" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">这没什么奇怪的。但是解释包提供了更多的东西。我特别喜欢可视化工具。</p><pre class="kt ku kv kw gu pq pc pr bn ps pt bi"><span id="9d10" class="pu lk iu pc b be pv pw l px py">from interpret import show<br/><br/>show(ebm.explain_global())</span></pre><p id="eba1" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">除此之外，<code class="fe oz pa pb pc b">show</code>方法甚至可以让您检查函数<em class="mx"> f </em>。这里是针对特性4(<em class="mx">NOX；波士顿住房数据集的氮氧化物浓度</em>。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pz"><img src="../Images/3cfa550f8863fa923c03bcc0ab21d065.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wsqN7VnV0eIAO7atevjZYw.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="0929" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">这里可以看到，最高到0.58左右，NOX对房价没有影响。从0.58开始，影响变得略微积极，0.62左右的NOX值对房价的积极影响最高。然后，它再次下降，直到对于大于0.66的NOX值，影响变为负的<strong class="md je">。</strong></p><h1 id="e4f2" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">结论</h1><p id="7941" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">在本文中，我们已经看到了可解释性是一个理想的属性。如果我们的模型在默认情况下是不可解释的，我们仍然可以用诸如LIME和Shapley值这样的方法来帮助自己。这比什么都不做要好，但是这些方法也有它们的缺点。</p><p id="a17a" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">然后，我们介绍了可解释的boosting machine，它的精度可与梯度boosting算法(如XGBoost和LightGBM)相媲美，但也是可解释的。这表明准确性和可解释性并不相互排斥。</p><p id="9008" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">多亏了解释包，在生产中使用可解释的增强并不困难。</p><h2 id="4c60" class="ne lk iu bd ll nf ng dn lp nh ni dp lt mk nj nk lv mo nl nm lx ms nn no lz ja bi translated">微小的改进空间</h2><p id="f280" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">这是一个很棒的库，目前只有一个主要缺点:<strong class="md je">它只支持树作为基础学习者</strong>。大多数时候这可能就足够了，但是如果你需要<em class="mx">单调</em>函数，比如说，你现在是一个人。然而，我认为这应该很容易实现:开发人员只需添加两个功能:</p><ol class=""><li id="dacd" class="ol om iu md b me mz mh na mk on mo oo ms op mw qa or os ot bi translated"><strong class="md je">支持一般基础学习者。</strong>然后我们可以使用<a class="ae li" href="https://en.wikipedia.org/wiki/Isotonic_regression" rel="noopener ugc nofollow" target="_blank">保序回归</a>来创建单调函数。</li><li id="a74f" class="ol om iu md b me ou mh ov mk ow mo ox ms oy mw qa or os ot bi translated"><strong class="md je">支持不同基础学习者的不同功能。因为对于某些特征，你希望你的函数单调增加，对于其他特征，你不在乎。</strong></li></ol><p id="1ddd" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">你可以在这里查看讨论<a class="ae li" href="https://github.com/interpretml/interpret/issues/184" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="b3ef" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">参考</h1><p id="7cb1" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">[1]t .米勒(2019年)。<a class="ae li" href="https://arxiv.org/abs/1706.07269" rel="noopener ugc nofollow" target="_blank">人工智能的解释:来自社会科学的见解</a>。<em class="mx">人工智能</em>，<em class="mx"> 267 </em>，1–38。</p><p id="5af8" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">[2] Kim，b .，Koyejo，o .，&amp; Khanna，R. (2016年12月)。<a class="ae li" href="https://papers.nips.cc/paper/2016/hash/5680522b8e2bb01943234bce7bf84534-Abstract.html" rel="noopener ugc nofollow" target="_blank">例子还不够，学会批判！对可解释性的批评</a>。在<em class="mx">辊隙中</em>(第2280–2288页)。</p><p id="508a" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">[3]里贝罗，M. T .，辛格，s .，&amp; Guestrin，C. (2016年8月)。<a class="ae li" href="https://arxiv.org/abs/1602.04938" rel="noopener ugc nofollow" target="_blank">“我为什么要相信你？”解释任何分类器的预测</a>。第22届ACM SIGKDD知识发现和数据挖掘国际会议论文集<em class="mx">(第1135-1144页)。</em></p><p id="5abf" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">[4] Lundberg，s .，，Lee，S. I. (2017)。<a class="ae li" href="https://arxiv.org/abs/1705.07874" rel="noopener ugc nofollow" target="_blank">解释模型预测的统一方法</a>。<em class="mx"> arXiv预印本arXiv:1705.07874 </em>。</p><p id="db9e" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">[5]诺里，h .，詹金斯，s .，科赫，p .，&amp;卡鲁阿纳，R. (2019)。Interpretml:机器学习可解释性的统一框架。<em class="mx"> arXiv预印本arXiv:1909.09223 </em>。</p></div><div class="ab cl np nq hy nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="in io ip iq ir"><blockquote class="pd pe pf"><p id="5aea" class="mb mc mx md b me mz ke mg mh na kh mj pg nb mm mn ph nc mq mr pi nd mu mv mw in bi translated">感谢Patrick Bormann的有用评论！</p></blockquote></div><div class="ab cl np nq hy nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="in io ip iq ir"><p id="f6ef" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">我希望你今天学到了新的、有趣的、有用的东西。感谢阅读！</p><p id="ede0" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated"><strong class="md je">作为最后一点，如果你</strong></p><ol class=""><li id="41c8" class="ol om iu md b me mz mh na mk on mo oo ms op mw qa or os ot bi translated"><strong class="md je">想支持我多写点机器学习和</strong></li><li id="33db" class="ol om iu md b me ou mh ov mk ow mo ox ms oy mw qa or os ot bi translated"><strong class="md je">无论如何，计划获得一个中等订阅，</strong></li></ol><p id="d949" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated"><strong class="md je">为什么不做</strong> <a class="ae li" href="https://dr-robert-kuebler.medium.com/membership" rel="noopener"> <strong class="md je">通过这个环节</strong> </a> <strong class="md je">？这将对我帮助很大！😊</strong></p><p id="ab3e" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated"><em class="mx">说白了，给你的价格不变，但是大约一半的订阅费直接归我。</em></p><p id="8068" class="pw-post-body-paragraph mb mc iu md b me mz ke mg mh na kh mj mk nb mm mn mo nc mq mr ms nd mu mv mw in bi translated">非常感谢，如果你考虑支持我的话！</p><blockquote class="nw"><p id="1892" class="nx ny iu bd nz oa ob oc od oe of mw dk translated"><em class="qb">有问题就在</em><a class="ae li" href="https://www.linkedin.com/in/dr-robert-k%C3%BCbler-983859150/" rel="noopener ugc nofollow" target="_blank"><em class="qb">LinkedIn</em></a><em class="qb">上写我！</em></p></blockquote></div></div>    
</body>
</html>