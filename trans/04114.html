<html>
<head>
<title>Linear Tree: the perfect mix of Linear Model and Decision Tree</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性树:线性模型和决策树的完美结合</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-tree-the-perfect-mix-of-linear-model-and-decision-tree-2eaed21936b7?source=collection_archive---------10-----------------------#2021-04-07">https://towardsdatascience.com/linear-tree-the-perfect-mix-of-linear-model-and-decision-tree-2eaed21936b7?source=collection_archive---------10-----------------------#2021-04-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="814f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">发现和开发线性模型树——决策树的一种有价值的替代方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d64e849d686ad85bc30d3569d929e90b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5g6X3fRM5gJ3OCbU"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">理查德·巴纳德在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="cf5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">决策树是统计学和机器学习领域中众所周知的算法。当然，每个数据科学家都尝试过拟合决策树。它们是我们学习如何处理监督和非监督任务的每个数据挖掘课程的首要主题之一。拟合决策树时，目标是通过学习基于几个输入变量的简单决策规则来创建预测目标值的模型。</p><p id="82d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">决策树的预测是在最佳数据分割过程结束时获得的简单常数近似值。这个基本特性使得决策树被广泛采用。它们易于理解和解释。不需要关于输入数据的特定假设(无数据准备，对要素类型无约束)。相反，如果生长不受监控，它们很容易过度生长。如果在训练阶段，一些看不见的样本落在勘探程度较低的部分，不稳定性可能是一个严重的问题。</p><p id="04f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不是每个人都知道决策树算法的简单而有效的变体。这些被称为<strong class="lb iu">模型树</strong>。他们学习训练数据的最佳分割，就像在标准决策树中一样，主要区别在于分割的良好性是通过拟合模型来评估的。<strong class="lb iu">模型树</strong>的一个特例被称为<strong class="lb iu">线性树</strong>。这意味着在树叶中有线性模型，而不是简单的常数近似。这可以看作是对标准决策树的简单改进/替代，同时保留了解释能力。</p><p id="845a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我们将介绍如何使用<strong class="lb iu">线性树</strong>包轻松创建线性树。<a class="ae ky" href="https://github.com/cerlymarco/linear-tree" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">Linear-tree</strong></a><strong class="lb iu"/>是<em class="lv">一个python库，在叶子处用线性模型构建模型树</em>。</p><blockquote class="lw lx ly"><p id="06f6" class="kz la lv lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">线性树被开发为与scikit-learn完全集成。<code class="fe mc md me mf b">LinearTreeRegressor</code>和<code class="fe mc md me mf b">LinearTreeClassifier</code>作为scikit-learn BaseEstimator提供。它们是在数据上构建决策树的包装器，以适应来自<code class="fe mc md me mf b">sklearn.linear_model</code>的线性估计器。在<a class="ae ky" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model" rel="noopener ugc nofollow" target="_blank"> sklearn.linear_model </a>中可用的所有模型都可以用作线性估值器。</p></blockquote><p id="d3f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">换句话说，我们只需要选择一个线性模型来构建我们的线性树。线性树包装器只是在数据上开发一个决策树结构。在每个节点上，它搜索一个最佳分割，简单地评估子节点的加权损失是否低于父节点的损失。所涉及的损失来自于数据部分的线性模型拟合。</p><p id="ee34" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个特征中的分割阈值通过分位数宁滨导出，以加快处理速度。唯一涉及的参数是损失<code class="fe mc md me mf b">criterion</code>、<code class="fe mc md me mf b">max_depth</code>、<code class="fe mc md me mf b">min_samples_split</code>、<code class="fe mc md me mf b">min_samples_leaf</code>和<code class="fe mc md me mf b">max_bins</code>(它们是自解释的，与经典决策树中的相同)。让我们看看它的实际效果。</p><h1 id="2b74" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">回归线性树</h1><p id="a96d" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">在本节中，我们使用线性树来建模回归任务。为了便于理解和直观解释，我们拟合了1D时间序列数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/496cf1c592e45bcc038cc5e01f01d1d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*poJLJXWnAHdCyytKkDnKzQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">1D正弦数据(图片由作者提供)</p></figure><p id="06b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们在不同深度进行拟合，以观察线性树如何分割输入空间并进行预测。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/43d4a7b1127ab4974221299738926357.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Aa_-C39suxRR2CoP"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">不同深度的线性树回归(图片由作者提供)</p></figure><p id="2252" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显而易见，线性树在分割中进行线性近似。这与经典的决策树形成对比，后者对相同的数据进行常数近似运算。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/d2b1999b6b90a55fc40ab3b080b1c327.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LHyINLT8F4_x15B5n93nhQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">深度6的线性树和决策树回归器(图片由作者提供)</p></figure><p id="825f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练完成后，我们可以绘制树形图，查看训练过程中遵循的学习路径。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/71082728a2ae9ca178adfec7f4bb9ae8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_dE3du62hxNsXwyRA5x4hQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">绘制线性树回归方程(图片由作者提供)</p></figure><h1 id="665a" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">用于分类的线性树</h1><p id="b551" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">在本节中，我们使用线性树来模拟分类任务。为了便于理解和直观解释，我们拟合了一个2D数据集。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/416dbe2d64957b7c7965db7e669a9704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*84Lca95IFqYPqV_c5r-EtA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">2D分类数据(图片由作者提供)</p></figure><p id="c792" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们在不同深度进行拟合，以观察线性树如何分割输入空间并进行预测。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/e60d594c272a8c7a62063871743f1e2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*giDRxZQ1kr7nzcMi"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">不同深度的线性树分类器(图片由作者提供)</p></figure><p id="9271" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显而易见，线性树在分割中进行线性近似。这与对相同数据进行分段常数近似的经典决策树形成对比。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/bdd1e743bc6d2016347b185288a217e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zhbe3zQYsRQUpx23vsg4UQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">深度6的线性树和决策树分类器(图片由作者提供)</p></figure><p id="47d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练完成后，我们可以绘制树形图，查看训练过程中遵循的学习路径。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/e05c53f33a30a9848b83fdffc4962d7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HEwB3LEx2AI3Oh-qU8g9hA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">绘制线性树分类器(图片由作者提供)</p></figure><h1 id="0d7b" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">摘要</h1><p id="8b75" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">在这篇文章中，我们介绍了经典决策树的一种变体，称为模型树，它评估适合更复杂模型的分裂，而不是进行简单的常数近似。然后我们提出了<a class="ae ky" href="https://github.com/cerlymarco/linear-tree" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"/></a><strong class="lb iu"/>一个python框架，用线性模型构建模型树。我们用简单的例子展示了线性树是如何工作的，以及与决策树的区别。线性树并不被认为是标准的决策树，但是它们显示出是一个很好的选择。一如既往，这并不适用于所有情况，采用这种模型系列的好处可能会因研究的情况而异，必须进行适当的验证。</p></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><p id="aec3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/cerlymarco/MEDIUM_NoteBook" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">查看我的GITHUB回购</strong> </a></p><p id="4332" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保持联系:<a class="ae ky" href="https://www.linkedin.com/in/marco-cerliani-b0bba714b/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a></p></div></div>    
</body>
</html>