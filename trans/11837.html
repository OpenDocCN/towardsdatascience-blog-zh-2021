<html>
<head>
<title>Don’t Get Caught in the Trap of Imbalanced Data When Building Your ML Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在构建你的ML模型时，不要陷入不平衡数据的陷阱</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/working-with-imbalanced-data-efbd96b3e655?source=collection_archive---------22-----------------------#2021-11-25">https://towardsdatascience.com/working-with-imbalanced-data-efbd96b3e655?source=collection_archive---------22-----------------------#2021-11-25</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="5d8a" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">利用这些技术带来平衡并提高性能</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/3382ef8093118b084c9242006da94988.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xI-6VhBgYajt7uj-"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated"><a class="ae kz" href="https://unsplash.com/@agebarros?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">阿格巴洛斯</a>在<a class="ae kz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="348e" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">什么是不平衡数据</h1><p id="7d37" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated"><strong class="lu iv">不平衡数据</strong>是机器学习应用中极其常见的一种情况。当您的数据中有许多观察值代表一种类型的类和其他小得多的类时，就会出现不平衡数据。这方面的例子可能是与合法购买相关的欺诈性<em class="mo">信用卡交易</em>或与合法电子邮件相关的潜在<em class="mo">垃圾电子邮件</em>(现在合法电子邮件也可能是少数)。</p><h1 id="314f" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">挑战是什么？</h1><p id="a35c" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">你会遇到的不平衡数据的挑战是算法如何从你的数据中学习。当您构建训练/测试数据集时，表示少数类的观察值数量将比多数类少得多。该算法没有足够的数据来真实地模拟少数阶级的样子，并最终过度偏向多数阶级。使用简单的<em class="mo">精度</em>指标来评估你的模型或者寻找高精度或者向少数类召回可能是特别危险的。稍后将详细介绍<a class="ae kz" href="https://medium.com/data-knows-all/evaluating-ml-models-with-a-confusion-matrix-3fd9c3ab07dd" rel="noopener">评估指标</a>。</p><h1 id="2653" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">处理不平衡数据的方法</h1><p id="a17a" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">幸运的是，在您的培训和测试阶段，只要有一点额外的思考和设置，您就可以处理不平衡的数据；有许多方法可以处理不平衡的数据。以下是您可以管理它的一些(不是全部)方法:</p><ol class=""><li id="d27e" class="mp mq iu lu b lv mr ly ms mb mt mf mu mj mv mn mw mx my mz bi translated">算法选择</li><li id="0d59" class="mp mq iu lu b lv na ly nb mb nc mf nd mj ne mn mw mx my mz bi translated">不平衡数据的交叉验证</li><li id="923c" class="mp mq iu lu b lv na ly nb mb nc mf nd mj ne mn mw mx my mz bi translated">生成合成数据</li><li id="92bf" class="mp mq iu lu b lv na ly nb mb nc mf nd mj ne mn mw mx my mz bi translated">选择正确的绩效指标</li></ol><h1 id="d991" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">我如何知道我是否有不平衡的数据</h1><p id="1b56" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">检查不平衡数据只需要一行简单的代码。取你的目标变量，使用下面的代码</p><pre class="kk kl km kn gu nf ng nh bn ni nj bi"><span id="20fa" class="nk lb iu ng b be nl nm l nn no">df['Target'].value_counts()</span></pre><pre class="np nf ng nh bn ni nj bi"><span id="d047" class="nk lb iu ng b be nl nm l nn no">1    17433 <br/>0     5193</span></pre><p id="952c" class="pw-post-body-paragraph ls lt iu lu b lv mr jv lx ly ms jy ma mb nq md me mf nr mh mi mj ns ml mm mn in bi translated">通过检查项目的数量，我们可以快速而容易地看到,<code class="fe nt nu nv ng b">1</code>类比<code class="fe nt nu nv ng b">0</code>类多得多。</p><h1 id="9254" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">算法选择</h1><p id="ead6" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">先说最简单的方法。在这个例子中，我将参考<strong class="lu iv"> Scikit-Lern的</strong>算法选择以及它们如何处理不平衡数据。他们的很多算法都支持一个可以设置为<code class="fe nt nu nv ng b">balanced</code>的<code class="fe nt nu nv ng b">class_weight</code>参数。例如<code class="fe nt nu nv ng b">RandomForest</code>、<code class="fe nt nu nv ng b">LogisticRegression</code>、<code class="fe nt nu nv ng b">Perceptron</code>、<code class="fe nt nu nv ng b">SVM</code>都支持此参数。根据<a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=class_weight" rel="noopener ugc nofollow" target="_blank">文档</a>:</p><blockquote class="nw nx ny"><p id="25d4" class="ls lt mo lu b lv mr jv lx ly ms jy ma nz nq md me oa nr mh mi ob ns ml mm mn in bi translated"><strong class="lu iv"> class_weight{"balanced "，" balanced_subsample"}，字典或字典列表，default=None </strong>与表单<code class="fe nt nu nv ng b">{class_label: weight}</code>中的类相关联的权重。如果没有给定，所有类的权重都应该是1。对于多输出问题，可以按照与“y”列相同的顺序提供字典列表。</p><p id="866c" class="ls lt mo lu b lv mr jv lx ly ms jy ma nz nq md me oa nr mh mi ob ns ml mm mn in bi translated">“平衡”模式使用<code class="fe nt nu nv ng b">y</code>的值自动调整与输入数据中类别频率成反比的权重，如<code class="fe nt nu nv ng b">n_samples / (n_classes * np.bincount(y))</code></p></blockquote><p id="c860" class="pw-post-body-paragraph ls lt iu lu b lv mr jv lx ly ms jy ma mb nq md me mf nr mh mi mj ns ml mm mn in bi translated">如果您发现其中一个分类器在您的模型选择阶段表现良好，您可以简单地继续使用该算法。</p><h1 id="17bd" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">训练-测试分离和交叉验证</h1><p id="0d2e" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">当数据不平衡时，您需要以保持类比例的方式分割数据，也称为<em class="mo">分层分割</em>。<code class="fe nt nu nv ng b">train_test_split</code>自动默认通过<code class="fe nt nu nv ng b">stratify=None</code>参数分割数据。为了对你的分割进行分层，然后使用你的目标变量<code class="fe nt nu nv ng b">stratify=y</code>。</p><pre class="kk kl km kn gu nf ng nh bn ni nj bi"><span id="f8b5" class="nk lb iu ng b be nl nm l nn no">X_train, X_test, y_train, y_test = train_test_split(X,<br/>                                                    y,<br/>                                                    test_size=0.33,<br/>                                                    random_state=53,<br/>                                                    stratify=y)</span></pre><p id="bd5a" class="pw-post-body-paragraph ls lt iu lu b lv mr jv lx ly ms jy ma mb nq md me mf nr mh mi mj ns ml mm mn in bi translated">那么分层是什么意思呢？据<a class="ae kz" href="https://en.wikipedia.org/wiki/Stratified_sampling" rel="noopener ugc nofollow" target="_blank">维基百科</a>:</p><blockquote class="nw nx ny"><p id="80d8" class="ls lt mo lu b lv mr jv lx ly ms jy ma nz nq md me oa nr mh mi ob ns ml mm mn in bi translated">在统计学中，分层抽样是一种从可以划分为子人群的人群中抽样的方法。</p></blockquote><p id="d4cc" class="pw-post-body-paragraph ls lt iu lu b lv mr jv lx ly ms jy ma mb nq md me mf nr mh mi mj ns ml mm mn in bi translated">换句话说，它考虑了<em class="mo">子种群</em>或<em class="mo">类</em>的大小，并在分割时考虑了这一点。</p><p id="8310" class="pw-post-body-paragraph ls lt iu lu b lv mr jv lx ly ms jy ma mb nq md me mf nr mh mi mj ns ml mm mn in bi translated">当执行<strong class="lu iv">交叉验证</strong>进行模型评估时，您应该使用<code class="fe nt nu nv ng b">StratifiedKFold</code>交叉验证器。这将确保通过保留每个类别的样本百分比来进行折叠。</p><p id="accc" class="pw-post-body-paragraph ls lt iu lu b lv mr jv lx ly ms jy ma mb nq md me mf nr mh mi mj ns ml mm mn in bi translated"><strong class="lu iv"> <em class="mo">重要提示:</em> </strong> <em class="mo">这一步很关键。如果没有这一点，您可能会在测试中以零个少数类样本结束。</em></p><h1 id="921c" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">重击</h1><p id="9445" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">合成少数过采样技术(SMOTE)使用最近邻方法来生成新的少数类样本。该方法仅应用于<em class="mo">训练数据</em>，然后在原始的<em class="mo">未受影响的</em>测试分区上进行测试。这里选择的方法是首先对少数类进行过采样以使其平衡，然后对其进行欠采样以减小大小和膨胀。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj oc"><img src="../Images/f62aacbe3797a45de31110524c63725f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jid_-tc1kat_uN4S.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="533e" class="pw-post-body-paragraph ls lt iu lu b lv mr jv lx ly ms jy ma mb nq md me mf nr mh mi mj ns ml mm mn in bi translated">通过综合生成类似于但不等同于其他少数类观察值的少数类观察值<em class="mo">，我们可以提高模型在少数类上的性能。</em></p><p id="cf8b" class="pw-post-body-paragraph ls lt iu lu b lv mr jv lx ly ms jy ma mb nq md me mf nr mh mi mj ns ml mm mn in bi translated">包<a class="ae kz" href="https://imbalanced-learn.org/stable/index.html" rel="noopener ugc nofollow" target="_blank"> imblearn </a>包含SMOTE算法，可以很容易地集成到SKLearn管道中。</p><p id="f3cf" class="pw-post-body-paragraph ls lt iu lu b lv mr jv lx ly ms jy ma mb nq md me mf nr mh mi mj ns ml mm mn in bi translated"><strong class="lu iv"> <em class="mo">重要说明:</em> </strong> <em class="mo">永远不要对你的</em> <strong class="lu iv"> <em class="mo">测试</em> </strong> <em class="mo">数据集执行SMOTE，只对</em> <strong class="lu iv"> <em class="mo">训练</em> </strong> <em class="mo">分区！</em></p><p id="bb15" class="pw-post-body-paragraph ls lt iu lu b lv mr jv lx ly ms jy ma mb nq md me mf nr mh mi mj ns ml mm mn in bi translated"><strong class="lu iv"> <em class="mo">实现注意:</em> </strong> <em class="mo">必须导入</em> <code class="fe nt nu nv ng b"><em class="mo">imblearn</em></code> <em class="mo">管道而不是sklearn管道，否则无法工作。</em></p><pre class="kk kl km kn gu nf ng nh bn ni nj bi"><span id="ffb1" class="nk lb iu ng b be nl nm l nn no">from imblearn.pipeline import Pipeline<br/>from imblearn.over_sampling import SMOTE<br/>from imblearn.under_sampling import RandomUnderSampler<br/><br/>pipeline = Pipeline([('prep',column_trans),<br/>                     ('over', SMOTE(random_state=42)),<br/>                     ('under', RandomUnderSampler(random_state=42)),<br/>                     ('clf', clf)])</span></pre><p id="75c7" class="pw-post-body-paragraph ls lt iu lu b lv mr jv lx ly ms jy ma mb nq md me mf nr mh mi mj ns ml mm mn in bi translated"><strong class="lu iv">更多:</strong>关于使用管道的更多信息，请查看我的帖子:<a class="ae kz" href="https://medium.com/@broepke/using-pipelines-in-sci-kit-learn-516aa431dcc5" rel="noopener">在Sci-kit中使用管道学习</a>。</p><h1 id="a718" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">选择正确的评估指标</h1><p id="ae65" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">最后，对于不平衡的数据，选择正确的评估指标至关重要。如果你依赖于准确性，你很可能不会达到你认为的结果。根据您想要的结果，您可以查看几个不同的指标，如<em class="mo">精度</em>、<em class="mo">召回</em>和<em class="mo">F1-分数</em>。请看我的另一篇帖子:<a class="ae kz" rel="noopener" target="_blank" href="/evaluating-ml-models-with-a-confusion-matrix-3fd9c3ab07dd">停止用精度来评价你的分类模型</a>。</p><h1 id="c940" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">结论</h1><p id="7919" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">在机器学习的实际应用中，不平衡数据无处不在。我们很容易陷入忽略不平衡数据的陷阱，却发现数据并没有按照我们想象的方式运行。幸运的是，有几种方法可以处理这一点，例如<em class="mo">选择一种处理不平衡数据的</em> <em class="mo">算法</em>，<em class="mo">分割</em>您的数据，并以<em class="mo">分层</em>的方式<em class="mo">交叉验证</em>您的模型，利用<em class="mo"> SMOTE </em>综合生成数据，最后但并非最不重要的是，为您想要的结果选择<em class="mo">最佳评估指标</em>。快乐模型建筑！</p><p id="7ebd" class="pw-post-body-paragraph ls lt iu lu b lv mr jv lx ly ms jy ma mb nq md me mf nr mh mi mj ns ml mm mn in bi translated">如果你喜欢阅读这样的故事，并想支持我成为一名作家，可以考虑报名成为一名媒体成员。一个月5美元，让你可以无限制地访问成千上万篇文章。如果你使用<a class="ae kz" href="https://medium.com/@broepke/membership" rel="noopener">我的链接</a>注册，我会赚一小笔佣金，不需要你额外付费。</p><h2 id="a781" class="od lb iu bd lc oe of dn lg og oh dp lk mb oi oj lm mf ok ol lo mj om on lq oo bi translated"><strong class="ak">参考文献</strong></h2><ol class=""><li id="673f" class="mp mq iu lu b lv lw ly lz mb op mf oq mj or mn mw mx my mz bi translated"><a class="ae kz" href="https://doi.org/10.1613/jair.953" rel="noopener ugc nofollow" target="_blank"> SMOTE:合成少数过采样技术</a></li><li id="3ab1" class="mp mq iu lu b lv na ly nb mb nc mf nd mj ne mn mw mx my mz bi translated"><a class="ae kz" href="https://scikit-learn.org/stable/modules/cross_validation.html" rel="noopener ugc nofollow" target="_blank">交叉验证:评估评估者的表现</a></li><li id="9df6" class="mp mq iu lu b lv na ly nb mb nc mf nd mj ne mn mw mx my mz bi translated"><a class="ae kz" href="https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/" rel="noopener ugc nofollow" target="_blank">用Python对不平衡分类进行SMOTE】</a></li></ol></div></div>    
</body>
</html>