<html>
<head>
<title>Hyper-Parameter Optimization with Optuna</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Optuna进行超参数优化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hyper-parameter-optimization-with-optuna-4920d5732edf?source=collection_archive---------7-----------------------#2021-10-28">https://towardsdatascience.com/hyper-parameter-optimization-with-optuna-4920d5732edf?source=collection_archive---------7-----------------------#2021-10-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1ed7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何生成模型的最佳版本。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e3879f50b33d3da4d9e70a5b9e6568be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*vs12Y5ilOZlvkOmGLEAaCg.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Optuna超参数优化(GIF由作者提供)</p></figure><p id="c761" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated">超参数优化是一项艰巨的任务。然而，使用像Optuna这样的工具可以使它变得更容易。</p><p id="dca9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这篇文章中，我展示了如何使用Optuna调优CatBoost模型的超参数。</p><blockquote class="md me mf"><p id="ac89" class="ky kz mg la b lb lc ju ld le lf jx lg mh li lj lk mi lm ln lo mj lq lr ls lt im bi translated">这里针对Optuna的代码可以快速适应您正在训练的任何模型。请随意收藏这篇文章以备将来使用。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mk"><img src="../Images/1e6b48f42b6739275c6c93dae1a3f76e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xk3xwKeIev5_b_sNAARGLw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自Optuna的单个超参数性能(由作者绘制)</p></figure></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="4d4f" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">超参数</h1><p id="6ed4" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">构建数据科学模型的一个经常被低估的任务是超参数优化。这项任务通常放在构建模型的最后。</p><p id="7abb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，它可以<strong class="la iu">区分一个可怕的模型和一个神奇的模型</strong>。这些超参数自成一类，因为它们简化了您正在使用的模型的结构。</p><p id="6df0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">相比之下，常规参数是由机器学习算法在训练期间学习的参数。在最基本的示例中，线性回归使用参数来确定每个要素的权重。</p><p id="91e3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些参数控制模型的基本输出。但是，对于线性回归，您也可以将正则化添加到模型中，并附带一个超参数来控制正则化项的权重。</p><p id="d1f3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个带有超参数的附加项改变了模型的整体预测方式。改变这个参数可以让一个像样的模型预测无意义的东西，或者将模型转换成非常健壮的东西。</p><h2 id="bff1" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">改变模型行为</h2><p id="dc78" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">这种行为在更复杂的模型中更为突出，如决策树，其中许多不同的超参数控制着树的深度、叶子的数量、分割的方式以及许多其他选项。</p><p id="54de" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些选项中的每一个都控制着模型的结构及其决策方式。虽然在每个配置中仍然有决策树，但是树的类型可以有很大的不同。<strong class="la iu">这就是松树和盆景的区别。</strong></p><p id="a3f0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">更复杂的是，进一步的集合模型带来了额外的挑战。这些复杂的模型建立在许多不同的模型之上，每个模型都有其超参数。</p><p id="9858" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">大多数情况下，您选择每个模型用来训练集合中的模型的超参数。例如，在诸如CatBoost的基于树的集合模型中，这些初始参数控制树的集合。无论是树的形状还是数量。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="6969" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated"><strong class="ak">超参数优化</strong></h1><p id="c324" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">谈到超参数优化，有几个选项可用。最常用的方法是网格搜索的变体。</p><h2 id="c6e2" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">网格搜索</h2><p id="3473" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">网格搜索是一种简单的强力方法，可以为您输入到搜索空间的每个超参数组合生成模型。因此，为每个品种创建一个模型，然后进行比较。虽然一开始很吸引人，但还是要意识到一些关键的方面。</p><p id="ba52" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，确定<strong class="la iu">最优超参数是一个NP-Hard问题</strong>，因为你要处理超参数的组合。因此，就复杂性而言，强力搜索的代价是惊人的。</p><p id="d347" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要注意的第二个方面是，你可能正在训练的模型在搜索的大部分时间里一直表现很差。但是网格搜索是为了建立和训练这些模型而设计的。</p><p id="3e2d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">假设您正在构建一个决策树，您有一个网格搜索，其中包括从“基尼”到标准熵的变化。此外，假设您发现“Gini”在您运行的前几个测试中的性能要优越得多。然而，即使熵在每个后续模型中表现更差，网格搜索仍将搜索这些组合中的每一个。</p><h2 id="8189" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">随机搜索</h2><p id="dfe7" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">网格搜索的替代方法是随机搜索。乍一看，这似乎是比网格搜索更糟糕的选择。然而，已经证明随机搜索比网格搜索执行得更好。</p><p id="60d5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">基本原理很简单，随机搜索避免了网格搜索执行的许多冗余搜索。例如，通过以不均匀的间隔搜索超参数空间，更有可能找到超参数的更实质的局部最优。</p><h2 id="70eb" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">可供选择的事物</h2><p id="4423" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">现在有了到目前为止讨论的两个超参数搜索的替代方案。这些选择正是这篇文章的目标。</p><p id="6cf7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于<strong class="la iu">之前的两种方法都没有结合任何结构化的方法来搜索</strong>最优超参数集，因此它们处于劣势。相反，像scikit-optimization和Optuna这样的库已经引导了超参数搜索。</p><p id="850f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">关于网格搜索和随机搜索比较的更多细节，你可以阅读我关于超参数优化的文章。此外，我展示了另一种方法，贝叶斯优化如何比这两种方法表现得更好。</p><div class="ob oc gp gr od oe"><a rel="noopener follow" target="_blank" href="/hyperparameter-tuning-always-tune-your-models-7db7aeaf47e9"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">超参数调整—始终调整您的模型</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">不要放弃免费的性能提升。</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">towardsdatascience.com</p></div></div><div class="on l"><div class="oo l op oq or on os ks oe"/></div></div></a></div></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="3ac3" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated"><strong class="ak"> Optuna </strong></h1><p id="9a0e" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">Optuna是一个优化工具，允许用户在超参数空间上运行实验。重要的是，它也总是用户暂停搜索，尝试其他超参数组合，然后继续优化过程。</p><p id="ecd2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此外，Optuna支持基于树的超参数搜索，称为TPESampler“树结构Parzen Estimator”。这种方法依靠贝叶斯概率来确定哪些超参数选择是最有希望的，并迭代地调整搜索。</p><h2 id="99c8" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">Optuna设置</h2><p id="ea6c" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">无论您使用的是哪种模型，使用Optuna优化超参数都遵循类似的过程。第一步是建立一个学习函数。该函数规定了每个超参数的样本分布。</p><p id="2df7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最常见的可用选项是分类、整数、浮点或统一对数。当您想要检查0.001、0.01和0.1范围内的值时，对数统一是理想的，其中每个值都有相同的被选中概率。</p><p id="184d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Optuna的另一个巨大优势是能够设置条件超参数。不幸的是，许多超参数只有在与其他参数结合使用时才有意义。因此，简单地使用它们的变体会导致错误。为每个选择添加案例可以确保这些情况不会发生。</p><h2 id="658f" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">模型优化</h2><p id="3af8" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">为了说明Optuna的一个用例，我选择优化一个CatBoost模型。这些模型有大量的超参数。虽然这篇文章只展示了其中的一小部分，但还是展示了许多Optuna特性，比如条件超参数。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="6f03" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">Catboost</h1><p id="ba23" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">Catboost是一种基于树的集成方法。这是一个非常稳健的模型。</p><p id="f779" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">与其他预测模型相比，CatBoost的一个直接好处是<strong class="la iu"> CatBoost可以直接处理分类变量</strong>。因此“猫”这个名字是分类的缩写。</p><p id="5ce7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">CatBoost的这一特性使其成为懒惰的数据科学家的理想选择。将分类变量转换为数值变量可能需要一些时间，并且需要支持其他模型的假设。此外，您需要确定特征的正确表示。</p><p id="3565" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是，使用CatBoost，您只需要定义分类参数，然后调整超参数来处理这些分类特征。</p><p id="867e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">超参数“cat_features”规定了哪些特性是分类的。<strong class="la iu">如果没有指定所有这些分类特征，CatBoost将抛出一个浮点型预期错误</strong>，因为模型通常假设剩余的特征是数字。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="8466" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">CatBoost超参数</h1><ul class=""><li id="7965" class="ot ou it la b lb nk le nl lh ov ll ow lp ox lt oy oz pa pb bi translated"><strong class="la iu"> loss_function </strong> —训练损失函数，对于回归可以使用RMSE或MAE。</li><li id="2d24" class="ot ou it la b lb pc le pd lh pe ll pf lp pg lt oy oz pa pb bi translated"><strong class="la iu">迭代</strong> —限制树的数量。但是，其他超参数可能会限制树的数量，从而导致总数小于迭代次数。</li><li id="2153" class="ot ou it la b lb pc le pd lh pe ll pf lp pg lt oy oz pa pb bi translated"><strong class="la iu"> learning_rate </strong> —学习率在优化期间使用，即在梯度下降期间。</li><li id="7da4" class="ot ou it la b lb pc le pd lh pe ll pf lp pg lt oy oz pa pb bi translated"><strong class="la iu">L2 _ leaf _ reg</strong>-指定正则化项的系数。该术语是L2，并被添加到成本函数中。</li><li id="03dc" class="ot ou it la b lb pc le pd lh pe ll pf lp pg lt oy oz pa pb bi translated"><strong class="la iu">深度</strong> —树的深度。</li><li id="a27c" class="ot ou it la b lb pc le pd lh pe ll pf lp pg lt oy oz pa pb bi translated"><strong class="la iu"> min_data_in_leaf </strong> —指定何时停止分割。当实例数量低于此最小值时，该节点将成为一个叶节点。</li><li id="e26a" class="ot ou it la b lb pc le pd lh pe ll pf lp pg lt oy oz pa pb bi translated"><strong class="la iu"> one_hot_max_size </strong> —唯一值小于或等于该值的参数的One-Hot编码。</li><li id="8b01" class="ot ou it la b lb pc le pd lh pe ll pf lp pg lt oy oz pa pb bi translated"><strong class="la iu">boosting _ type</strong>——“有序”或“普通”有序在较小的数据集上更好，但比普通方案慢。因此，对于较大的数据集，建议使用“普通”增强类型。</li><li id="dc33" class="ot ou it la b lb pc le pd lh pe ll pf lp pg lt oy oz pa pb bi translated"><strong class="la iu">RSM</strong>—‘Alias:col sample _ by level’定义了用于在分割时选择特征以及再次随机选择特征的百分比。</li><li id="44ab" class="ot ou it la b lb pc le pd lh pe ll pf lp pg lt oy oz pa pb bi translated"><strong class="la iu"> bootstrap_type </strong> —对权重进行采样的方法，可以是“贝叶斯”、“伯努利”、“MVS”、“泊松”或“否”</li><li id="864c" class="ot ou it la b lb pc le pd lh pe ll pf lp pg lt oy oz pa pb bi translated"><strong class="la iu"> bagging_temperature </strong> —定义贝叶斯引导的设置。当参数设置为1时，根据指数分布添加权重。</li><li id="98b0" class="ot ou it la b lb pc le pd lh pe ll pf lp pg lt oy oz pa pb bi translated"><strong class="la iu">子样本</strong> —当‘泊松’、‘伯努利’或‘MVS’用于引导法时，使用装袋的采样率。</li></ul></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="658d" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">实验</h1><p id="e614" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">对于这个例子，我在公共领域许可下使用diamonds数据集。这个数据集由分类变量和数字变量的组合组成。</p><p id="207e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该数据集旨在根据其他属性预测钻石的价格。一些变量是分类的，这通常需要一些预处理。</p><div class="ob oc gp gr od oe"><a href="https://www.kaggle.com/shivam2503/diamonds" rel="noopener  ugc nofollow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">钻石</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">通过切割、颜色、净度、价格和其他属性来分析钻石</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">www.kaggle.com</p></div></div><div class="on l"><div class="ph l op oq or on os ks oe"/></div></div></a></div><p id="caf2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是，使用CatBoost，无需任何预处理就可以生成模型。此外，即使是缺失值也可以使用CatBoost进行处理，这使得它成为一个非常健壮且易于使用的模型。</p><p id="4b91" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">只需加载数据集并运行。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pi pj l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">为CatBoost设置Optuna研究(由作者编写代码)</p></figure><p id="52ef" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在Optuna中设置研究后，仍需要调整一些参数。首先是采样器。在这里，我手动更改采样器以使用前面讨论的TPESampler。这种选择确保了搜索将比标准的网格搜索更加结构化和有针对性。</p><p id="8bed" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">需要注意的其他几个选项是方向、n_trials和超时。方向规定了如何执行优化。<strong class="la iu">确保这与您正在使用的损失函数的预期优化相匹配。</strong></p><p id="d6f5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">接下来，n_trials控制将执行多少超参数空间的样本。加上超时，这两个因素会影响研究运行的时间。如果你发现自己时间紧迫，这些可以成为救命稻草。</p><p id="4758" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于搜索的最终状态将被保存(并可在以后重新启动)，您可以使用同一研究连续搜索越来越好的超参数选择。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pi pj l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">运行Optuna研究(作者代码)</p></figure></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="ddaf" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">超参数搜索的可视化</h1><p id="a697" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">一旦研究终止，无论是在达到最后一次迭代还是达到超时限制之后，下一步就是评审研究结果。</p><p id="1fc2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上面的脚本将输出最佳模型性能和使用的超参数。您还可以使用Optuna的内置可视化功能查看研究进度。</p><h2 id="80db" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">超参数重要性</h2><p id="6acd" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">确定哪些参数对模型的整体性能影响最大。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pi pj l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">绘图超参数重要性(作者代码)</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pk pj l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自Optuna的CatBoost超参数重要性图(由作者绘制)</p></figure><h2 id="7347" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">多次迭代的性能</h2><p id="f80f" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">该图显示了模型在多次迭代中的性能。预期的行为是搜索顺序地提高模型性能。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pi pj l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">情节优化进度(作者代码)</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pk pj l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">超过100次迭代的Optuna优化进度(由作者绘制)</p></figure><h2 id="fdb2" class="np mt it bd mu nq nr dn my ns nt dp nc lh nu nv ne ll nw nx ng lp ny nz ni oa bi translated">单个超参数的性能</h2><p id="9980" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">该图显示了多次试验中不同超参数的变化。颜色表示试用号。</p><p id="cc9a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，预期的行为是，随着研究的进展，超参数将收敛到单一值。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pi pj l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">单个超参数性能(作者代码)</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pk pj l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自Optuna的单个超参数性能(由作者绘制)</p></figure></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="4775" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">包裹</h1><p id="cdee" class="pw-post-body-paragraph ky kz it la b lb nk ju ld le nl jx lg lh nm lj lk ll nn ln lo lp no lr ls lt im bi translated">如果没有对超参数进行适当的调整，模型的性能会受到很大影响。有几个选项可用于优化；然而，像Optuna这样的工具使这个过程变得简单而有效。</p><p id="80b8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Optuna为超参数优化和有效的搜索结构提供了一种基于贝叶斯的方法。用户可以搜索、停止、搜索更多内容并保存结果。</p><p id="9e93" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于具有许多选项的复杂模型(如CatBoost ),搜索可用模型配置的能力变得至关重要。</p><p id="da9c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Optuna为模型的实际超参数调整提供了一个理想的解决方案。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><p id="6b21" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你有兴趣阅读关于新颖的数据科学工具和理解机器学习算法的文章，可以考虑在medium上关注我。我总是在我的文章中包含代码，您可以将其应用到您的工作中！</p><p id="52b9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="mg">如果你对我的写作感兴趣，想直接支持我，请通过以下链接订阅。这个链接确保我会收到你的会员费的一部分。</em></p><div class="ob oc gp gr od oe"><a href="https://zjwarnes.medium.com/membership" rel="noopener follow" target="_blank"><div class="of ab fo"><div class="og ab oh cl cj oi"><h2 class="bd iu gy z fp oj fr fs ok fu fw is bi translated">通过我的推荐链接加入Medium-Zachary Warnes</h2><div class="ol l"><h3 class="bd b gy z fp oj fr fs ok fu fw dk translated">阅读扎卡里·沃恩斯(以及媒体上成千上万的其他作家)的每一个故事。您的会员费直接支持…</h3></div><div class="om l"><p class="bd b dl z fp oj fr fs ok fu fw dk translated">zjwarnes.medium.com</p></div></div><div class="on l"><div class="pl l op oq or on os ks oe"/></div></div></a></div></div></div>    
</body>
</html>