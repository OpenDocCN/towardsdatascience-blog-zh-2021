<html>
<head>
<title>Quantitative evaluation of a pre-trained BERT model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预训练BERT模型的定量评估</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/quantitative-evaluation-of-a-pre-trained-bert-model-73d56719539e?source=collection_archive---------15-----------------------#2021-04-10">https://towardsdatascience.com/quantitative-evaluation-of-a-pre-trained-bert-model-73d56719539e?source=collection_archive---------15-----------------------#2021-04-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="54fc" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><div class=""><h2 id="8130" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">一个<strong class="ak">先决条件</strong>使用一个<strong class="ak">预训练模型</strong>作为<strong class="ak">，没有微调</strong></h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/141afb12a237ce994012252b9342f3c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZzM5uRBxQEMUCNGPAgenyw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lh">图一。</strong>对预训练的BERT模型进行定量评估。该测试定量地评估预训练模型的(a)通过模型预测屏蔽位置的能力的上下文敏感向量，以及(b)通过检查屏蔽短语的向量质量的[CLS]向量质量。底层词汇向量的聚类质量，尤其是实体类型到聚类的分离在其中起着隐含的作用。该测试通过使用三元组的测试数据集来完成(具有屏蔽短语的句子、句子中的屏蔽短语、句子上下文中的屏蔽短语的实体类型)。模型在句子上的性能由屏蔽位置的预测的实体类型和屏蔽短语的[CLS]向量来确定。屏蔽位置或[CLS]向量的预测的实体类型由上下文无关向量的聚类确定-其质量由聚类的性质定性地确定(实体类型的分离程度)。定量测试产生混淆矩阵和每种实体类型的F1分数。<strong class="bd lh">作者创作的图像。</strong></p></figure><h1 id="a23a" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">TL；速度三角形定位法(dead reckoning)</h1><p id="4779" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">自我监督的学习正在使用变形金刚大规模使用，不仅用于文本，最近还用于图像<em class="mw"> ( </em> <a class="ae mx" href="https://openai.com/blog/clip/" rel="noopener ugc nofollow" target="_blank"> <em class="mw">剪辑</em> </a> <em class="mw">，</em> <a class="ae mx" href="https://arxiv.org/pdf/2102.05918.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="mw">对齐</em> </a> <em class="mw"> ) </em>，以解决传统的监督任务<em class="mw">(例如分类)</em>，要么原样，要么进行后续微调。虽然大多数(如果不是全部的话)下游NLP任务被执行，但是迄今为止，随后对预训练的变压器模型进行微调，有可能照原样使用预训练的模型<em class="mw">，而没有随后的微调</em>。</p><p id="1004" class="pw-post-body-paragraph ma mb it mc b md my kd mf mg mz kg mi mj na ml mm mn nb mp mq mr nc mt mu mv im bi translated">例如，<strong class="mc jd">一个预先训练好的BERT模型对于多种NLP任务<strong class="mc jd">的效用</strong>，<strong class="mc jd">没有任何微调</strong>就被大大忽略了。</strong>直接使用预训练的BERT模型而无需微调的例子有</p><ul class=""><li id="dca3" class="nd ne it mc b md my mg mz mj nf mn ng mr nh mv ni nj nk nl bi translated"><a class="ae mx" rel="noopener" target="_blank" href="/unsupervised-ner-using-bert-2d7af5f90b8a"> <strong class="mc jd">无人监管的NER </strong>。</a> NER，传统的监督任务可以完成，而不必标记句子中的单个术语。相反，对于感兴趣的实体类型，一次性标记BERT词汇向量集群就足够了，其中词汇向量直接从预先训练的模型中获得。</li><li id="cdd6" class="nd ne it mc b md nm mg nn mj no mn np mr nq mv ni nj nk nl bi translated"><strong class="mc jd">无监督的句子表述。</strong>训练有素的关于下一句预测的BERT模型可用于创建短语、句子片段或完整句子表示，其表现与在监督下创建的句子表示一样好，甚至在某些任务中取代它们。</li><li id="0fd6" class="nd ne it mc b md nm mg nn mj no mn np mr nq mv ni nj nk nl bi translated"><strong class="mc jd">U</strong><a class="ae mx" rel="noopener" target="_blank" href="/unsupervised-synonym-harvesting-d592eaaf3c15"><strong class="mc jd">n监督同义词采集</strong> </a> <em class="mw">(或一般关系抽取)。</em>预训练的BERT模型与依存解析器/位置标记器组合可用于关系提取基线，并为同一任务的下游监督模型创建弱监督标记数据。</li><li id="8224" class="nd ne it mc b md nm mg nn mj no mn np mr nq mv ni nj nk nl bi translated"><strong class="mc jd">条件句分类。</strong>在给定输入句子中指定的术语的情况下，与依存解析器/词性标注器组合协同工作的预训练BERT模型可用作选择句子分类任务的基线模型，并为同一任务的下游监督模型创建弱监督标记数据。</li><li id="a025" class="nd ne it mc b md nm mg nn mj no mn np mr nq mv ni nj nk nl bi translated"><strong class="mc jd">弱监督带置信度评分。</strong>为任何下游微调任务创建带有关联置信度得分的标记数据。下游微调模型可以学习使用置信度得分作为附加的输入特征。这对于选择性地手动处理那些低置信度的输入来提高模型性能也很有用。</li><li id="b83f" class="nd ne it mc b md nm mg nn mj no mn np mr nq mv ni nj nk nl bi translated"><strong class="mc jd">下游微调任务的训练集覆盖量化。</strong>在训练鉴别器模型p(y/x)时，量化训练集对底层分布p(x)的覆盖。在为监督任务创建标记数据集时，这在实践中非常有用，在监督任务中，预先训练的模型被微调。</li><li id="d8d2" class="nd ne it mc b md nm mg nn mj no mn np mr nq mv ni nj nk nl bi translated"><strong class="mc jd">相对于预训练模型量化微调模型的学习。</strong>不仅根据测试集分数，而且根据底层输入分布样本<em class="mw">(由训练集捕获)</em><em class="mw">如何映射的相对方式，对微调模型的学习进行量化<em class="mw">(与预训练模型创建的聚类相比，微调可以改变从训练集创建的聚类的性质)。</em></em></li><li id="f5cc" class="nd ne it mc b md nm mg nn mj no mn np mr nq mv ni nj nk nl bi translated"><strong class="mc jd">在部署期间检测OOD或罕见输入。</strong>为部署模型的输出<em class="mw">(可以是预训练模型或微调模型)</em>赋予置信度得分，特别是对于它很少或从未见过的输入。这在模型的生产部署中变得至关重要——以识别OOD <em class="mw">(不在分布范围内)</em>或<a class="ae mx" href="https://jmtomczak.github.io/blog/1/1_introduction.html" rel="noopener ugc nofollow" target="_blank">在培训期间很少出现的情况</a>并检测错误分类/误报。</li></ul><p id="e28b" class="pw-post-body-paragraph ma mb it mc b md my kd mf mg mz kg mi mj na ml mm mn nb mp mq mr nc mt mu mv im bi translated">然而，预训练模型的这种直接用例突出了对定量<em class="mw"> ( </em> <a class="ae mx" rel="noopener" target="_blank" href="/maximizing-bert-model-performance-539c762132ab"> <em class="mw">)的需要，这与任务上的预训练模型的定性测量</em> </a> <em class="mw"> ) </em>评估方法相反，而不仅仅是模型训练损失<em class="mw">(或固定步数的训练)</em>。</p><p id="330c" class="pw-post-body-paragraph ma mb it mc b md my kd mf mg mz kg mi mj na ml mm mn nb mp mq mr nc mt mu mv im bi translated">本文的前半部分描述了这种定量测试的实现。文章的第二部分描述了预训练步骤——自定义词汇生成、数据准备、多GPU预训练、预训练的超参数选择等。下面描述的所有模型的预训练都是在托管<a class="ae mx" href="https://www.nvidia.com/en-us/data-center/dgx-a100/" rel="noopener ugc nofollow" target="_blank">英伟达DGX A100 </a>机器的<a class="ae mx" href="https://www.corescientific.com/" rel="noopener ugc nofollow" target="_blank">核心科学云</a>上进行的。</p><h1 id="b15d" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">需要评估的BERT组件</h1><p id="ecb8" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">BERT模型的自我监督训练产生</p><ul class=""><li id="b0e5" class="nd ne it mc b md my mg mz mj nf mn ng mr nh mv ni nj nk nl bi translated">词汇向量。这些是上下文不敏感的向量，其中一个单词的所有含义都被压缩到一个向量中(<em class="mw">例如，细胞——其所有含义、手机、监狱细胞、生物细胞都被压缩到一个向量中)</em></li><li id="8d6a" class="nd ne it mc b md nm mg nn mj no mn np mr nq mv ni nj nk nl bi translated">将由所学习的词汇向量表示的输入句子转换成每个符号化输入单词的上下文敏感向量的模型权重。模型权重也有助于为输入句子创建丰富的句子表示<em class="mw">(假设模型在下一个句子预测任务中被训练)</em>。</li></ul><p id="15ee" class="pw-post-body-paragraph ma mb it mc b md my kd mf mg mz kg mi mj na ml mm mn nb mp mq mr nc mt mu mv im bi translated">虽然在之前已经对预训练模型<a class="ae mx" rel="noopener" target="_blank" href="/maximizing-bert-model-performance-539c762132ab">进行了定性检查，但本文描述了一种同时测试所有三个输出的评估方法</a></p><ul class=""><li id="8976" class="nd ne it mc b md my mg mz mj nf mn ng mr nh mv ni nj nk nl bi translated">句子中屏蔽短语的模型上下文敏感输出向量的定量度量</li><li id="a3bc" class="nd ne it mc b md nm mg nn mj no mn np mr nq mv ni nj nk nl bi translated">句子中屏蔽短语的[CLS]向量的定量度量</li><li id="63c9" class="nd ne it mc b md nm mg nn mj no mn np mr nq mv ni nj nk nl bi translated">上下文无关词汇向量聚类的定性和定量测量，其计数是定量测量<em class="mw">(大量的单个聚类意味着不适当的/较差的预训练模型)</em>，并且聚类的实体分离水平是定性测量<em class="mw">(考虑到词汇向量的上下文无关性质，必然会有混合实体聚类)</em>。这些群集的质量对上面提到的两个定量测试有直接影响。</li></ul><p id="2ee6" class="pw-post-body-paragraph ma mb it mc b md my kd mf mg mz kg mi mj na ml mm mn nb mp mq mr nc mt mu mv im bi translated">定量测试<em class="mw">(针对上述测试一和测试二)</em>产生一个混淆矩阵，其中包含每个实体类型的F1分数。</p><h1 id="ed51" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">模型评估方法</h1><p id="0202" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">从事实正确性的角度来看，BERT对句子<em class="mw">(即使被删除的术语存在于底层词汇表中)</em>中被删除的确切术语的预测是不可靠的，就像对任何语言模型一样，不管它是自回归模型还是自动编码器模型。然而，如果模型是在语料库上用真正代表输入句子的自定义词汇预先训练的，则BERT对屏蔽位置的实体类型的预测始终是准确的。也就是说，如果我们输入句子<em class="mw">“_ _ _用于治疗癌症</em>”，一个训练有素的模型的最高预测将主要是药物和治疗。下面利用BERT的这种健壮的实体类型预测能力来评估模型<em class="mw">(这基本上是用于执行无监督的</em><a class="ae mx" rel="noopener" target="_blank" href="/unsupervised-ner-using-bert-2d7af5f90b8a"><em class="mw">NER</em></a><em class="mw">的相同方法，在</em> <a class="ae mx" rel="noopener" target="_blank" href="/unsupervised-ner-using-bert-2d7af5f90b8a"> <em class="mw">以前的文章</em> </a> <em class="mw">中有描述)。</em></p><h1 id="1dd8" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">试验结果</h1><p id="ce5c" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">三种实体类型<em class="mw">(药物、疾病和细胞类型)</em>的屏蔽位置预测的累积F1分数如下所示。对三种模型进行了预训练和评估——大套管、大无套管和基本无套管。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nr"><img src="../Images/f951be932a7f91d2ffa02a363a1fb548.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EZzkfVfX96siahXgsSUEQg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lh">图二。</strong>通过下述方法预训练的模型的评估结果，以及可公开获得的预训练模型。作者创造的形象。</p></figure></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><p id="263a" class="pw-post-body-paragraph ma mb it mc b md my kd mf mg mz kg mi mj na ml mm mn nb mp mq mr nc mt mu mv im bi translated">这篇文章的其余部分描述了完成上面列出的分数所遵循的训练前步骤。评估步骤也很详细。</p><h1 id="df69" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">培训前的步骤</h1><p id="ef19" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">从语料库预处理开始的预训练过程在实现良好的模型性能方面起着关键作用。</p><ul class=""><li id="ee63" class="nd ne it mc b md my mg mz mj nf mn ng mr nh mv ni nj nk nl bi translated"><strong class="mc jd">语料预处理。</strong>句子边界检测，在句子边界上分割句子，起到取得良好性能的作用。不在句子边界上折叠句子的缺点是在训练的最大510 <em class="mw">(考虑到CLS和SEP) </em>边界限制时剪裁长序列的风险。对于超过句子长度限制的病态长句，一种方法是将它们以一定长度折叠成一个新行，其中换行的限制因素是句子的平均标记化长度。句子的标记化长度通常高于原始句子长度。理想情况下，可以使用用于训练的相同标记器对句子进行标记，然后基于它进行折叠，但对于大规模语料库来说，这可能是一个过于昂贵的操作——句子长度增加的平均度量(<em class="mw">~ 1.5–2x)</em>可能是一个实用的选择。使用额外的换行符<em class="mw">分隔段落和文档(即，两个换行符分隔文档，一个换行符分隔文档内的句子)</em>也是确保下一句预测的高准确度的关键，这反过来会影响[CLS]向量的质量</li><li id="1bfc" class="nd ne it mc b md nm mg nn mj no mn np mr nq mv ni nj nk nl bi translated"><strong class="mc jd">词汇生成。</strong>在感兴趣的语料库上创建自定义词汇也在模型性能中发挥作用。如果预训练的目标不是为了学习数字术语<em class="mw">(例如，年)</em>和外语句子的良好表示，则确保所学习的词汇真正代表基础语料库的一种方法是消除纯粹是数字术语<em class="mw">(不是任何其中含有数字的术语，如CD20-a基因)</em>和外语字符<em class="mw">(相对于感兴趣的语言)</em>的单词<em class="mw">(仅用于词汇生成)</em>。一种简单的方法是删除这些术语，然后只添加数字0-9<em class="mw">(确保它们被重复足够的次数，以满足最小阈值，从而有资格被词汇生成挑选出来)</em>以确保它们出现在最终的词汇中。然而，请注意，生成训练记录的输入没有删除任何术语，它是应用了句子边界的原始原始语料库。这个原始语料库中的数字项将被转换成由数字项组成的子词。外语字符将被转换成[UNK]标记，保留它们穿插其中的句子结构。</li><li id="30ed" class="nd ne it mc b md nm mg nn mj no mn np mr nq mv ni nj nk nl bi translated"><strong class="mc jd">培训记录生成。</strong> Google的Github存储库有训练记录生成功能，支持全词屏蔽。PyTorch HuggingFace也支持它——但是，它仍然不适合训练大型语料库，因为它将整个语料库读入内存。使用Google code生成训练记录可能需要很长时间，因为它是按顺序执行的<em class="mw">(甚至比实际训练时间还要长)</em> —所以最好通过拆分语料库<em class="mw">(使用parallel等)来并行生成训练记录。)</em></li><li id="6f9c" class="nd ne it mc b md nm mg nn mj no mn np mr nq mv ni nj nk nl bi translated"><strong class="mc jd">实际训练流程</strong>。谷歌用于培训的TensorFlow版本不支持多GPU<em class="mw">(NVIDIA-SMI输出可能会产生误导，除非使用dmon选项来查看实际的多GPU使用情况)</em>。然而，Nvidia有一个多GPU容器版本，它确实使用所有GPU进行训练<em class="mw"> ( </em> <a class="ae mx" href="https://horovod.ai/" rel="noopener ugc nofollow" target="_blank"> <em class="mw">在内部使用Horovod</em></a><em class="mw">)</em>——所以这可能是一个理想的选择。然而，Nvidia release迄今为止还不支持整个单词屏蔽来生成训练记录——所以我们可能必须使用谷歌的记录生成过程，然后用Nvidia的代码进行训练。此外，如果选择了正确的学习率，Nvidia的优化器变化可能有助于更快的收敛。在A100上使用4个GPU在两天多一点的时间内完成了针对BERT-Large的24 GB大小的语料库的大约500k步的训练过程。批量是影响模型性能的一个关键超参数。A100机器大GPU内存40GB有助于训练大批量<em class="mw"> (128序列长度—批量64，然后是512序列长度，批量16) </em>。使用4个GPU的A100上的吞吐量约为1200个序列/秒。学习率为7.5 e-4时，训练损失约为1.5，NSP损失约为0.005。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nz"><img src="../Images/3c881585299397d8dee222a3f24a8570.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UWB4z1-H__gL9qi08bGPPg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lh">图三。</strong>预训练的带全词屏蔽的BERT base未区分大小写词汇表中约1000个词的随机样本的余弦分布直方图。如图2所示，模型F1值在90%左右。用于训练的较大批量对直方图分布图中间接捕获的模型性能有影响(较小批量的预训练产生较低的模型性能以及均值向右移动的直方图分布图-较小的尾部)。<strong class="bd lh">以上图片作者</strong></p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nz"><img src="../Images/5597ec9a2abdfecb9578a52ca2934a12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lJPVzqbGOhxm8zJmqm9g3w.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lh">图4。</strong>预训练的带全词屏蔽的BERT大型未区分大小写词汇表中约1000个词的随机样本的余弦分布直方图。如图2所示，模型F1得分在90分左右。用于训练的较大批量对直方图中间接捕捉的模型性能有影响(较小批量的预训练产生较低的模型性能，以及均值向右移动的直方图——较小的尾部)。<strong class="bd lh">以上图片作者</strong></p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/c1f2db0c635b3fa13fb2f66566701138.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4S_DyceJSxBKKidWOOtuIA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lh">图五。</strong>预训练BERT大容量词汇中约1000个词的随机样本的余弦分布直方图，具有全词掩蔽。如图2所示，模型F1值在90%左右。用于训练的较大批量对直方图分布图中间接捕获的模型性能有影响(较小批量的预训练产生较低的模型性能以及均值向右移动的直方图分布图-较小的尾部)。<strong class="bd lh">以上图片作者</strong></p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/8c30e383362462820322f3e4952265f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9RnkzCdcO4RvhJFPvV66QQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lh">图六。</strong>本次评测使用的其他公共模型(MSPubmed，SciBERT)的词汇表中约1000个词的随机样本的余弦分布直方图。MSPubmed的直方图类似于高性能的预训练模型，但在掩蔽测试中表现不佳，这表明底层词汇向量训练得足够好，但模型层没有将它们转换为上下文敏感向量。<strong class="bd lh">以上图片由作者摘自文章</strong> <a class="ae mx" rel="noopener" target="_blank" href="/maximizing-bert-model-performance-539c762132ab"> <strong class="bd lh">最大化BERT模型性能。</strong>T15】</a></p></figure><h1 id="88a2" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">评估步骤</h1><p id="8d4f" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">通过将Tensorflow检查点转换为PyTorch模型进行评估。预训练模型的评估如下进行。</p><ul class=""><li id="7eee" class="nd ne it mc b md my mg mz mj nf mn ng mr nh mv ni nj nk nl bi translated">BERT学习的词汇向量提取和聚类——这可以使用下面列出的库中的实用程序来完成。一旦聚类完成，需要为感兴趣的特定实体手动标记这些聚类。如果聚类通常产生大约3000个聚类，那么对于大约30000个词汇，这最多需要一个小时的人工标记。</li><li id="6938" class="nd ne it mc b md nm mg nn mj no mn np mr nq mv ni nj nk nl bi translated">运行评估脚本。这需要一个三元组(1)包含一个屏蔽短语的句子(2)屏蔽短语的句子(3)屏蔽短语的实体类型。测试数据的格式如下所示。评估产生带有感兴趣实体的混淆矩阵的输出。F1得分报告的默认行为是所有被评估实体的最大F1得分值。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oc"><img src="../Images/82053beca6bdf8f0fb9633bb4321bd70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*15L_Cf3LDjNkTKz1X3QsGA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lh">图3。</strong>评估测试样本。<strong class="bd lh">作者创建的图像</strong></p></figure><h1 id="71db" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">最后的想法</h1><p id="e0fd" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated">当前标准方法的一个<a class="ae mx" href="https://huggingface.co/blog/how_many_data_points/" rel="noopener ugc nofollow" target="_blank">最新替代方案</a>是用特定任务的头部对预训练模型进行微调——<a class="ae mx" href="https://huggingface.co/blog/how_many_data_points/" rel="noopener ugc nofollow" target="_blank">提示预训练模型进行少量镜头学习</a>，这显示了前景。这种方法的灵感来自于由GPT-3 推广的<a class="ae mx" href="https://arxiv.org/abs/2005.14165" rel="noopener ugc nofollow" target="_blank">提示，其中模型执行新任务而无需微调<em class="mw">(无梯度更新)</em>，只需与预训练的自回归模型进行文本交互。虽然基于提示的监督不同于传统的监督，但它仍然需要人工来为模型准备<em class="mw">(或者微调)</em>特定于任务的提示。本文中描述的BERT模型的使用为同一问题提供了一种不同的方法，其中人类的努力花费在标记几个聚类上，其大小受聚类过程的限制，与标记句子的传统监督或更近的基于句子提示的方法形成对比。</a></p><h2 id="8f1f" class="od lj it bd lk oe of dn lo og oh dp ls mj oi oj lu mn ok ol lw mr om on ly iz bi translated">承认</h2><p id="e536" class="pw-post-body-paragraph ma mb it mc b md me kd mf mg mh kg mi mj mk ml mm mn mo mp mq mr ms mt mu mv im bi translated"><em class="mw">用于评估的Pubmed和SEC测试数据集是由我的同事</em><a class="ae mx" href="https://www.linkedin.com/in/harishashokkumar/?originalSubdomain=in" rel="noopener ugc nofollow" target="_blank"><em class="mw">Harish</em></a><em class="mw">通过从已知实体类型的选择术语中收集句子并在句子中屏蔽它们而用算法创建的。</em></p><p id="aec9" class="pw-post-body-paragraph ma mb it mc b md my kd mf mg mz kg mi mj na ml mm mn nb mp mq mr nc mt mu mv im bi translated"><em class="mw">代码用于</em> <a class="ae mx" href="https://github.com/ajitrajasekharan/pretrained_model_evaluation.git" rel="noopener ugc nofollow" target="_blank"> <em class="mw">进行评估，此处可用</em> </a> <em class="mw">。准备用于评估</em> <a class="ae mx" href="https://github.com/ajitrajasekharan/bert_vector_clustering" rel="noopener ugc nofollow" target="_blank"> <em class="mw">(集群创建)的模型的代码可在此处</em> </a> <em class="mw">获得。使用[CLS]向量创建句子表示的代码可在此处获得</em>  <em class="mw">。</em></p></div></div>    
</body>
</html>