<html>
<head>
<title>The Million-Dollar Question: When to Stop Training your Deep Learning Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">价值百万的问题:何时停止训练你的深度学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-million-dollar-question-when-to-stop-training-deep-learning-models-fa9b488ac04d?source=collection_archive---------7-----------------------#2021-06-22">https://towardsdatascience.com/the-million-dollar-question-when-to-stop-training-deep-learning-models-fa9b488ac04d?source=collection_archive---------7-----------------------#2021-06-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9d16" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">关于早期停止，或者如何通过知道训练你的神经网络多长时间来避免过拟合或欠拟合</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/fa6eccd7f9dc179c468772eee2c870b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ElmbZRvosT0DqeTk"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@icons8?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Icons8团队</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="0b01" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当训练深度神经网络时，首先要做出的决定之一是选择停止的时期。这并不容易。</p><p id="3832" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果训练在最佳时间之前停止，模型将没有时间从训练集中学习最重要的特征，因此为训练集和测试集提供不太适合的解决方案。</p><p id="b96f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一方面，如果在最佳时期之后停止训练，则在训练集中将实现高性能，但是当查看测试结果时，该模型将不会正确地概括，因为它已经过度调整到训练集。</p><p id="ee4b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">幸运的是，有一种简单且广泛使用的方法可以避免这两个问题。它被称为<strong class="ky ir">早期停止</strong>，大多数深度学习框架都提供了一个开箱即用的接口来使用它。</p><blockquote class="ls"><p id="1ee9" class="lt lu iq bd lv lw lx ly lz ma mb lr dk translated">几乎普遍应该使用早期停止。</p><p id="7b96" class="lt lu iq bd lv lw lx ly lz ma mb lr dk translated">— Ian Goodfellow等人，深度学习。</p></blockquote><h1 id="4ed0" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">提前停止</h1><p id="3edf" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">这种方法背后的思想在于训练集和测试集之间的比较，或者为了得到更可靠的结果<a class="ae kv" rel="noopener" target="_blank" href="/how-to-split-a-tensorflow-dataset-into-train-validation-and-test-sets-526c8dd29438">，训练集和验证集之间的比较。</a></p><p id="3f49" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过分析随着时代的过去，训练和验证分裂中的错误或损失图，我们将看到最初两者都减少了。然而，验证误差将在某个时间开始变平或增加，而训练误差将继续减小。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/e4ebe5a274dff2bdcc6afd3fcc5ae36f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*W368qtCQlCYmt6YlwIYnJg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">说明欠拟合和过拟合区域以及最佳停止时期的训练示例。</p></figure><p id="1976" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">验证集的目的是让我们了解我们的模型如何处理未经训练的数据。因此，当验证误差开始增加时，正好是模型过度适应训练集并且没有正确地概括新数据的时候。这是我们需要停止训练的时候。</p><h2 id="4b74" class="na md iq bd me nb nc dn mi nd ne dp mm lf nf ng mo lj nh ni mq ln nj nk ms nl bi translated">观察哪个指标？</h2><p id="8b8b" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">虽然验证损失是对模型应用提前停止时广泛使用的指标，但它并不总是最相关的。</p><p id="567c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有时候，根据用例选择一个代表模型性能的指标可能会更好。例如，它可以是准确度、精确度、召回率或度量的组合。</p><h2 id="3f39" class="na md iq bd me nb nc dn mi nd ne dp mm lf nf ng mo lj nh ni mq ln nj nk ms nl bi translated">具体什么时候停止？</h2><p id="f5d7" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">现在，我们知道了应该观察哪些指标，以及当验证指标不再随着培训指标一起提高或者开始表现得更差时，我们应该停止。</p><p id="47b0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，观察到的指标可能会有多次起伏(由于神经网络的随机性)，这意味着在验证指标第一次变坏时就停止可能不是最佳解决方案(尽管这是最简单的方案)。</p><p id="ebf2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一些更复杂的停止训练的触发器如下(注意，它们也可以组合应用):</p><ul class=""><li id="5d1d" class="nm nn iq ky b kz la lc ld lf no lj np ln nq lr nr ns nt nu bi translated">观察到的度量在给定数量的时期内没有改善(称为<em class="nv">提前停止</em> <em class="nv">耐心)。</em></li><li id="eadc" class="nm nn iq ky b kz nw lc nx lf ny lj nz ln oa lr nr ns nt nu bi translated">观察到的度量没有改善超过给定的被认为是改善的最小变化(称为<em class="nv"> min_delta </em>)。</li></ul><blockquote class="ob oc od"><p id="e3f0" class="kw kx nv ky b kz la jr lb lc ld ju le oe lg lh li of lk ll lm og lo lp lq lr ij bi translated">请注意，当使用提前停止耐心时，当监控的精度没有超过在过去X个时期获得的<strong class="ky ir">最佳结果</strong>时，将执行触发。如果它提高了，但没有超过最好的结果，那就不算数。</p></blockquote><h2 id="edd5" class="na md iq bd me nb nc dn mi nd ne dp mm lf nf ng mo lj nh ni mq ln nj nk ms nl bi translated">如何在TensorFlow上使用？</h2><p id="959f" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated"><a class="ae kv" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a> API在<em class="nv"> model.fit() </em>上提供了一个回调函数，用于在受监控的指标停止改善时停止训练。</p><p id="946a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nv">指标</em>参数接收您想要观察的指标的名称。在引用验证度量的情况下(更真实的结果，因为它近似于您的模型在生产中的行为)，名称必须以前缀“val_”开头。请注意，验证集必须传递给<em class="nv"> model.fit() </em>，以便包含验证指标。</p><p id="ebb5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，您可以指定<em class="nv">耐心</em>和<em class="nv"> min_delta </em>，如前一节所述。最后，<em class="nv">模式</em>参数指定所需结果是从高到低(最小模式)还是从低到高(最大模式)。例如，监控精度时，模式应为最大。</p><pre class="kg kh ki kj gt oh oi oj ok aw ol bi"><span id="3135" class="na md iq oi b gy om on l oo op">callback = <a class="ae kv" href="https://keras.io/api/callbacks/early_stopping/" rel="noopener ugc nofollow" target="_blank">tf.keras.callbacks.EarlyStopping</a>(<br/>    monitor="val_loss",<br/>    min_delta=0,<br/>    patience=0,<br/>    verbose=0,<br/>    mode="auto",<br/>    baseline=None,<br/>    restore_best_weights=False,<br/>)</span></pre><blockquote class="ob oc od"><p id="ea63" class="kw kx nv ky b kz la jr lb lc ld ju le oe lg lh li of lk ll lm og lo lp lq lr ij bi translated">这个回调还提供了一个参数<code class="fe oq or os oi b">restore_best_weights</code>,用在性能最好的时期获得的模型权重来恢复结果模型。</p></blockquote><p id="fc68" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要使用提前停止回调，我们只需将对象传递给model.fit()中的callbacks参数，如下所示:</p><pre class="kg kh ki kj gt oh oi oj ok aw ol bi"><span id="fec8" class="na md iq oi b gy om on l oo op">model.fit(train_images, train_labels, epochs=10, batch_size=1, callbacks=[callback], verbose=0)</span></pre><h2 id="9def" class="na md iq bd me nb nc dn mi nd ne dp mm lf nf ng mo lj nh ni mq ln nj nk ms nl bi translated">如何观察多个指标？</h2><p id="49eb" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">根据您的使用情况，提前停止回调可能是不够的。例如，如果有一个带有多个输出的<strong class="ky ir">模型</strong>，并且想要监控一组指标而不是一个指标。或者诸如给定精度和召回率的F-beta分数的组合度量。</p><p id="cee9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了解决这个问题，你可以找到一个我基于Keras文档中的<a class="ae kv" href="https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/python/keras/callbacks.py#L1683-L1823" rel="noopener ugc nofollow" target="_blank">可用实现</a>和一个<a class="ae kv" href="https://stackoverflow.com/questions/64556120/early-stopping-with-multiple-conditions" rel="noopener ugc nofollow" target="_blank"> StackOverflow问题</a>开发的自定义回调。它接收一个<em class="nv">指标名称</em>参数，在这里，您可以指定一组指标，而不是单个指标。为了组合这些指标，<a class="ae kv" href="https://en.wikipedia.org/wiki/Harmonic_mean" rel="noopener ugc nofollow" target="_blank">调和平均值</a>的计算通常用于比率。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">自定义提前停止回调，通过使用调和平均值计算将多个指标组合起来来监控它们。</p></figure><p id="d7ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在代码的最后，您可以找到一个示例，说明如何使用验证f1分数作为监控指标(即验证精度和召回率之间的调和平均值)来创建提前停止的回调。</p><h2 id="d244" class="na md iq bd me nb nc dn mi nd ne dp mm lf nf ng mo lj nh ni mq ln nj nk ms nl bi translated">有什么值得推荐的<em class="ov">耐心</em>？</h2><p id="8b8c" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">大多数情况下，这个问题的答案在很大程度上取决于您使用的模型和数据集。</p><p id="86ef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从我的经验来看，我建议首先运行一个具有大量历元的训练阶段，并从结果中直观地观察所监控的指标何时开始下降以及下降的速率。在那之后，我会用一些额外的时期运行下面的实验，直到它开始饱和，随着时期数量的减少，耐心会显著减少，同时记住，如果结果非常随机，耐心应该更大。</p><h1 id="4e4c" class="mc md iq bd me mf mg mh mi mj mk ml mm jw ow jx mo jz ox ka mq kc oy kd ms mt bi translated">结论</h1><p id="8495" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">在本文中，开发机器学习模型时最常见的挑战之一已经得到解决:何时停止训练。本文详细介绍了广泛使用的解决方案<em class="nv">提前停止</em>，解释了更高级的技术，如复杂的提前停止触发器以获得最佳结果，以及如何通过实现自定义回调来监控多个指标。</p><p id="3fcb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你想发现更多像这样的帖子，你可以在下面找到我:</p><ul class=""><li id="a37a" class="nm nn iq ky b kz la lc ld lf no lj np ln nq lr nr ns nt nu bi translated"><a class="ae kv" href="https://github.com/angeligareta" rel="noopener ugc nofollow" target="_blank"> GitHub </a></li><li id="ba04" class="nm nn iq ky b kz nw lc nx lf ny lj nz ln oa lr nr ns nt nu bi translated"><a class="ae kv" href="https://www.linkedin.com/in/angeligareta/" rel="noopener ugc nofollow" target="_blank">领英</a></li><li id="94c8" class="nm nn iq ky b kz nw lc nx lf ny lj nz ln oa lr nr ns nt nu bi translated"><a class="ae kv" href="https://angeligareta.com/" rel="noopener ugc nofollow" target="_blank">个人网站</a></li></ul></div></div>    
</body>
</html>