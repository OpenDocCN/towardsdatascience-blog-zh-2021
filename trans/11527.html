<html>
<head>
<title>Asset2Vec: Turning 3D Objects into Vectors and Back</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Asset2Vec:将3D对象转化为矢量，然后再转化回来</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/asset2vec-turning-3d-objects-into-vectors-and-back-8335496b756d?source=collection_archive---------5-----------------------#2021-11-14">https://towardsdatascience.com/asset2vec-turning-3d-objects-into-vectors-and-back-8335496b756d?source=collection_archive---------5-----------------------#2021-11-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="993e" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/notes-from-industry" rel="noopener" target="_blank">行业笔记</a></h2><div class=""/><div class=""><h2 id="9ffb" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">我们如何使用NeRF将我们的整个3D对象目录嵌入到一个共享的潜在空间中，这对图形的未来意味着什么</h2></div><p id="96b8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在我目前担任人工智能研究主管的<a class="ae lk" href="https://www.datagen.tech/" rel="noopener ugc nofollow" target="_blank"> Datagen </a>，我们创建常见3D环境的合成照片级真实感图像，用于训练计算机视觉算法。例如，如果你想教一个房屋机器人在一个脏乱的卧室中导航，就像下面这样，这将花费你相当多的时间来收集足够大的训练集的真实图像[人们通常不喜欢外人进入他们的卧室，他们肯定不会喜欢给他们的混乱拍照]。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/7edf32dc674f76ea79c64e051fc590e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZwDfxAGr_yIz5oCT"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">凌乱卧室的合成图像(图片由作者提供)。</p></figure><p id="b3b4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们使用图形软件生成了上面的图像。一旦我们(在软件中)建立了环境和其中所有东西的3D模型，我们就可以使用它的光线跟踪渲染器在我们想要的任何光照条件下，从我们喜欢的任何相机视点生成场景的图像。我们已经完全控制了。</p><p id="a56c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，如果你认为<em class="mb">收集</em>真实图像很难，那么等到你尝试<em class="mb">标记</em>这些图像。你需要启动一个漫长而昂贵的标记操作，教人类如何根据你的标准标记这些像素。当然，使用合成图像，我们可以轻松地为图像的任何方面生成像素完美的标签，包括人类无法评估的东西，如深度和表面法线贴图。</p><div class="lm ln lo lp gt ab cb"><figure class="mc lq md me mf mg mh paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><img src="../Images/b55cde1d001f180fe79bf0cdd8c6e940.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*MdsVvoOSQoYcpKEi4ZROUQ.png"/></div></figure><figure class="mc lq md me mf mg mh paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><img src="../Images/4c3f811bcaeda5108cf51c397310caa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*fnTr2AOBU5c-dslyF77L8A.png"/></div></figure></div><div class="ab cb"><figure class="mc lq md me mf mg mh paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><img src="../Images/65eb6689d5de4cffd9b52c06f53f7bad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*fjk8Ko9epLKN949j75DqgA.png"/></div></figure><figure class="mc lq md me mf mg mh paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><img src="../Images/4e689dbecc170e13a29233f16b67c6a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*jZU93uVkF8NuPCNOMPKHdA.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk mi di mj mk translated">从左上顺时针方向:不同光照条件下渲染的场景，表面法线贴图，深度贴图，对象类标签(图片由作者提供)。</p></figure></div><h2 id="b37e" class="ml mm iq bd mn mo mp dn mq mr ms dp mt kx mu mv mw lb mx my mz lf na nb nc iw bi translated">收集资产</h2><p id="e1b9" class="pw-post-body-paragraph ko kp iq kq b kr nd ka kt ku ne kd kw kx nf kz la lb ng ld le lf nh lh li lj ij bi translated">为了帮助我们的用户训练她的机器人，我们需要生成成千上万个像上面这样的卧室，我们需要用东西填满它们:家具、布、书、用过的杯子、遥控器等等。因此，我们维护了一个艺术家制作的3D对象的大型目录(我们称之为<em class="mb">资产</em> ) <em class="mb">。</em>我们的产品目录涵盖100多万件商品，我们对此深感自豪。</p><p id="339f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">每个资产对象由一个详细的3D网格(由三角形组成的多边形结构，它定义了对象的<strong class="kq ja">形状</strong>)和一个纹理贴图(一个图像，它定义了对象的<strong class="kq ja">外观</strong>，就好像它是一个用来覆盖网格表面的毯子)。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ni"><img src="../Images/184ffe2f7ab64497506f873d53daffac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i9efJ0hLIYtHMWieL9DfhA.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">资源(左)由网格结构(中)和纹理贴图(右)表示。图片作者。</p></figure><p id="3982" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">除了在视觉上定义对象的网格和纹理贴图之外，为每个资产存储的其余信息是3D艺术家决定放入文本元数据文件中的任何内容，如对象的类型(“餐椅”)，以及当时似乎相关的任何标签。</p><p id="5828" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因此，在目录中搜索(例如，“给我所有有三条腿的表”)只能使用它们的元数据属性来完成。如果艺术家没有写下每张桌子的腿数，那么要知道哪些桌子是三条腿的，唯一的方法就是一个一个地打开它们的3D模型文件去看。</p><h2 id="366c" class="ml mm iq bd mn mo mp dn mq mr ms dp mt kx mu mv mw lb mx my mz lf na nb nc iw bi translated">资产-2-Vec</h2><p id="28b2" class="pw-post-body-paragraph ko kp iq kq b kr nd ka kt ku ne kd kw kx nf kz la lb ng ld le lf nh lh li lj ij bi translated">相反，我们建议<em class="mb">在嵌入空间中编码</em>每个资产，这将封装整个资产的形状和外观。与Word2Vec非常相似，它为字典中的每个单词提供一个“代码”向量，该向量对应于一个<em class="mb"> n </em>维空间中的一个位置，这样语义相似的单词就彼此靠近，我们希望为我们的每个资产分配一个向量，这样我们就可以通过查看向量来判断资产的所有视觉属性。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nj"><img src="../Images/49ac3f1cb42c8f1bd40cccd349b6389a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EKdPweq5B-8w7dnkYKXQ2g.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">将我们所有的3D资产编码成向量。图片作者。</p></figure><p id="6d23" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">理想情况下，我们还希望将形状属性(例如，腿的数量)与外观属性(如颜色或材料)分离开来。我们怎么知道向量确实抓住了物体的全部本质？最终的方法是能够从向量回到资产的3D模型。</p><p id="d17d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">您可以想象一个神经网络，它将学习读取向量作为输入，并输出资源的原始网格和纹理贴图。然而，这将是困难的。每个资源的网格都有完全不同的拓扑:不同数量的三角形，每个节点的不同含义，纹理贴图和网格之间不同的映射格式。我们还需要其他东西，一种适合<em class="mb">所有</em>资产的替代3D表示。</p><h2 id="c693" class="ml mm iq bd mn mo mp dn mq mr ms dp mt kx mu mv mw lb mx my mz lf na nb nc iw bi translated">NeRF来救援了</h2><p id="1bdd" class="pw-post-body-paragraph ko kp iq kq b kr nd ka kt ku ne kd kw kx nf kz la lb ng ld le lf nh lh li lj ij bi translated">这就是NeRF的用武之地。正如你所记得的，在<a class="ae lk" rel="noopener" target="_blank" href="/nerf-and-what-happens-when-graphics-becomes-differentiable-88a617561b5d">我之前的文章</a>中，我展示了如何使用大约40张从不同角度拍摄的物体图像，我们可以训练一个神经网络来学习物体周围的整个空间。经过训练的神经网络将空间中的点<em class="mb"> (x，y，z) </em>作为输入，并返回该点中材质的颜色<em class="mb"> (r，g，b) </em>和不透明度(α)。网络对空间了解得如此之好，以至于渲染器可以拍摄对象的“照片”，只需通过沿着来自模拟“相机”的光线的点查询该网络。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nk"><img src="../Images/14e07f35497e562d970990080aeeb9d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AfHoqXHQ0eG2McZD.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">NeRF中心的神经网络(图片由作者提供)。</p></figure><p id="4e0d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们可以轻松获得40张图片，涵盖我们目录中的每项资产。我们简单地使用图形软件从它们的原始网格模型渲染它们(所以我们也可以渲染80)。然后，我们可以使用这些图像来训练NeRF网络，以对物体周围的空间进行编码。网络训练完成后，我们可以生成一个短片，从各种新的角度展示物体，其中每一帧都是通过查询训练好的NeRF网络来渲染的。</p><div class="lm ln lo lp gt ab cb"><figure class="mc lq nl me mf mg mh paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><img src="../Images/c00f85f4b97c251b31288b1e576f7021.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*KRFny8HM8mbtsOb3hkH1bg.png"/></div></figure><figure class="mc lq nm me mf mg mh paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><img src="../Images/fa2b951668412b067c838c6266f2b9d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/1*Wrva7VPRl5K3tULXKovEvQ.gif"/></div><p class="lx ly gj gh gi lz ma bd b be z dk nn di no mk translated">左图:来自图形软件Blender的截图，其中我们从各个方向渲染了该资产的80幅合成图像(每个金字塔是一个模拟相机)，用于训练NeRF网络。右图:通过查询训练好的NeRF网络，从80个<strong class="bd np">新</strong>视点渲染的对象，跨越360度。作者图片。</p></figure></div><p id="02c3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们接下来要做的是，使用单个NeRF网络，不仅对单个资产进行编码(就像上面的椅子)，而且对我们目录中的所有椅子进行编码<strong class="kq ja"/>。这个单一网络将拥有与NeRF网络完全相同的架构。唯一的区别是它将有一个额外的输入:分配给每把椅子的(潜在)向量，它将在训练期间<em class="mb">学习</em>。我们将像训练NeRF网络一样训练这个网络，除了我们将使用从我们目录中的所有<strong class="kq ja">椅子上拍摄的照片。</strong></p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nq"><img src="../Images/6c1379b910bd9e600a3e44b2952cb7fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M2zjufeZJXF-Y9j2yGeLVw.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">NeRF网络，以潜在向量作为附加输入。在训练期间，资产的潜在向量也与全连接层的权重一起被学习(图片由作者提供)。</p></figure><p id="ea06" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这种训练不同于普通训练，在某种意义上，除了其自身的权重之外，网络还学习与每把椅子相关联的一组特殊变量——其潜在向量(类似于嵌入层的学习方式)。当我们反向传播从渲染椅子图像获得的误差时，不仅更新了NeRF网络的权重，而且更新了分配给特定椅子的<strong class="kq ja">的潜在向量中的值(例如<em class="mb"> vec </em>输入)。</strong></p><p id="3496" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">一旦我们训练了这个网络，我们就可以用它来制作产品目录中所有椅子的电影！要渲染任何特定的椅子，我们只需要在查询时将椅子的潜在代码作为输入提供给NeRF网络。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/0d870c760121c369bb47c6f0f6814a11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*OrkU9cGlvGbCK0YRiKkxcQ.gif"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">通过查询一个<strong class="bd np">单个</strong> NeRF网络呈现的椅子资产示例。图片作者。</p></figure><h2 id="f949" class="ml mm iq bd mn mo mp dn mq mr ms dp mt kx mu mv mw lb mx my mz lf na nb nc iw bi translated">潜在探索</h2><p id="dbde" class="pw-post-body-paragraph ko kp iq kq b kr nd ka kt ku ne kd kw kx nf kz la lb ng ld le lf nh lh li lj ij bi translated">我们不需要将自己局限于为当前目录中的资产学习的向量。我们还可以探索当我们任意改变潜在向量，或者混合和匹配来自两个不同资产的潜在向量时会发生什么。或许在不久的将来，我们能够通过以下方式用新资产丰富我们的产品目录:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/be1b8c7823d1ddf02166a7a16c3c14f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*dPUqOvyj2sKUvr6Fi-r8zQ.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated"><strong class="bd np">混合潜在向量</strong>:当NeRF网络的输入将椅子<strong class="bd np"> <em class="ns"> i </em> </strong>的潜在向量的<strong class="bd np"> <em class="ns">形状</em>部分</strong>与椅子<strong class="bd np"> j </strong>的<strong class="bd np">外观部分</strong>组合时，产生位置(I，j)的椅子。图片由作者提供。</p></figure><p id="cea3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了直观地了解资产潜在空间的样子，我们可以使用TSNE算法将我们的资产放置在2D平面上(根据它们的潜在向量):</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nt"><img src="../Images/414f1f90a063818bf93b86f3b82395e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SZ5BbYNyJqOGuojSsx1KCQ.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">我们522个资产的向量的T-SNE图。对象类和子类之间的清晰分离。图片由作者提供。</p></figure><p id="9931" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们可以看到，椅子的不同子类之间的区别是明显的，即使在一个子类中(即<em class="mb">扶手椅</em>)，我们也可以很容易地找到椅子共享视觉属性的区域(即带木质扶手的扶手椅与带软垫扶手的扶手椅)。</p><p id="8b4f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这就是重点，不是吗？因为这意味着我们可以很容易地训练一个线性分类器(像SVM一样)来识别我们关心的任何视觉属性，只需给它提供少数正面和负面资产的向量，然后用它来标记其余的100万资产目录，而无需加载这些资产。这种特别的分类可以节省我们大量的时间！</p><h2 id="c8b0" class="ml mm iq bd mn mo mp dn mq mr ms dp mt kx mu mv mw lb mx my mz lf na nb nc iw bi translated">潜伏是未来</h2><p id="44f6" class="pw-post-body-paragraph ko kp iq kq b kr nd ka kt ku ne kd kw kx nf kz la lb ng ld le lf nh lh li lj ij bi translated">最后，这种分析不仅适用于椅子，也适用于我们产品目录中的所有其他资产系列。我们可以想象一个未来，我们渲染的每个场景都将被这些潜影完全描述:每个资产的潜影，背景的潜影，姿势的潜影，相机角度，灯光。如果我们敢，我们可以想象一个未来，传统的网格和纹理贴图将不再被用来渲染合成但逼真的图像，就像上图中凌乱的卧室场景。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/89645e046caa32b6f3e9c7258e8993e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*Plc1fTYTGglcJE3p8gRI4w.gif"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">通过查询一个<strong class="bd np">单个</strong> NeRF网络，我们的<em class="ns">表</em>资产的一个示例。图片作者。</p></figure><h1 id="5f2c" class="nu mm iq bd mn nv nw nx mq ny nz oa mt kf ob kg mw ki oc kj mz kl od km nc oe bi translated">附录:解耦形状和外观</h1><p id="7ac5" class="pw-post-body-paragraph ko kp iq kq b kr nd ka kt ku ne kd kw kx nf kz la lb ng ld le lf nh lh li lj ij bi translated">NeRF网络有两个分支，一个用于不透明度(α),另一个用于颜色。为了分离潜在向量中的形状和外观部分，我们将输入的潜在代码分成两部分，并且仅向颜色分支显示外观部分，如下所示。这个技巧来自最近的GIRRAFE论文(尼迈耶和盖格，CVPR 2021)。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi of"><img src="../Images/6c916ef077c1d1e910f35e60b3c1b062.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GZZ3uQf-woSwTMFBKd7VZA.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">我们修改后的NeRF网络架构(图片由作者提供)。</p></figure><p id="d368" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了更好地理解形状和外观子空间，我们对潜在向量的相关部分进行了PCA分析:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/3dcc39c26dc4b9bd9cc7650210993b23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*7K5VkXpTNZo2ECPC_s-kww.gif"/></div></figure><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/afab20878827545a266354ee8af6e4bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*uKxP0st9e3t-kBpt2mofvA.gif"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">形状空间(上)和外观空间(下)的前10个PCA组件的图示。作者图片。</p></figure><p id="dd5c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们可以看到这些是如何控制椅子的各个方面的，如座位的大小，宽度，靠背的高度等。在外观空间中，我们可以看到PCA方向如何控制颜色，以及它们的饱和度、亮度和光照条件。</p></div></div>    
</body>
</html>