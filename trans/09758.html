<html>
<head>
<title>Design a neuromorphic predictive network architecture with pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用pytorch设计神经形态预测网络结构</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/design-a-neuromorphic-predictive-network-architecture-with-pytorch-72d523e16930?source=collection_archive---------24-----------------------#2021-09-12">https://towardsdatascience.com/design-a-neuromorphic-predictive-network-architecture-with-pytorch-72d523e16930?source=collection_archive---------24-----------------------#2021-09-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2e43" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用脉冲神经元网络进行深度学习——脉冲神经网络是未来吗？</h2></div><p id="8fac" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">朋友们好，今天我们将看到一个非常有趣的话题，用<em class="lb">第三代神经网络</em>构建一个<strong class="kh ir">脉冲神经元</strong>网络，即脉冲神经网络(SNN)。我们将看到低代码解决方案“<a class="ae lc" href="https://github.com/ajayarunachalam/pynmsnn" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> pynmsnn </strong> </a>”是一个python库，可以轻松用于设计&amp;部署这样一个具有snn的神经形态预测模型。</p><p id="497d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">为什么要建立神经形态SNN预测模型？</strong></p><p id="25e5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">神经形态结构非常类似于我们用来进行计算的生物大脑结构。简单地说:神经形态脉冲神经网络密切模仿我们的生物神经元的工作方式。人们可以使用这些类型的网络来绕过具有少量样本或数据点的数据中传统的学习规则的缺乏，并且还特别针对没有潜在模式和趋势的数据，该数据基于原理“<strong class="kh ir">一起激发的神经元，连接在一起”</strong>，这是来自hebbian learning的著名习语。在SNNs中，有一个<strong class="kh ir">时间轴</strong>和<strong class="kh ir">神经网络通过时间</strong>看到数据，并且<strong class="kh ir">激活函数是超过某个预激活阈值</strong>的尖峰。如果神经元不够兴奋，预激活值会不断减弱。把它想象成一个<em class="lb">时间分布的ReLU，在特定的时间步长上有尖峰或者没有尖峰</em>。</p><p id="602b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更多细节请看这里</p><p id="8ecc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">为什么是pynmsnn？</strong></p><p id="2dbd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lc" href="https://pypi.org/project/pynmsnn/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> pynmsnn </strong> </a>是一个开源的低代码<strong class="kh ir"> python库</strong>到<strong class="kh ir">使用【尖峰神经网络(SNNs)】</strong>构建神经形态预测模型(分类&amp;回归问题) <strong class="kh ir">。</strong></p><p id="7aac" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">谁可以使用pynmsnn？</p><p id="622e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">PYNMSNN是一个开源库，非常适合:-</p><ul class=""><li id="2706" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated">偏爱低代码解决方案的数据科学家。</li><li id="3688" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">希望提高模型准确性和生产力的经验丰富的数据科学家。</li><li id="4872" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">参与构建概念验证(POC)项目的数据科学专业人员和顾问。</li><li id="4a3c" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">快速概念验证的研究人员。</li><li id="fcc2" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">ML/AI爱好者。</li></ul><p id="8f8c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有关安装步骤和先决条件，请查看此处的<a class="ae lc" href="https://github.com/ajayarunachalam/pynmsnn#requirements" rel="noopener ugc nofollow" target="_blank">和</a></p><p id="8a85" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">开始—让我们为回归问题创建一个尖峰神经网络架构。</strong></p><p id="1032" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">演示回归:房价数据集。这个博客的完整代码可以在<a class="ae lc" href="https://github.com/ajayarunachalam/pynmsnn/blob/main/pyNM/spiking-regressor-model.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到</p><p id="0418" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们将导入所有必要的库&amp; T4 pynmsnn T5库。对于这个回归问题，我们从模块中导入了“<strong class="kh ir"> spiking_regressor </strong>”。</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="lw lx l"/></div></figure><p id="de50" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们创建一个名为“<strong class="kh ir"> run_regressor </strong>的函数，该函数将分别分配计算资源、加载数据集、预处理数据、分配预测器&amp;响应变量以及将数据集分割成train-val-test集合。</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="lw lx l"/></div></figure><p id="065c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还定义了模型参数，并使用数据加载器创建了pytorch数据集，使您的数据易于管理，并有助于简化您的机器学习管道。</p><p id="9ae7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们创建我们的尖峰神经网络架构。我们为网络模型使用3个隐藏层。</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="lw lx l"/></div></figure><p id="cdd8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们来看看创建的网络模型</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ly"><img src="../Images/996110e45bbc8931465e5aa52f068caf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IHXfiYlHlwFFDrT_wahSGA.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">作者提供的图片:显示正在使用的计算设备、数据集信息、train-val-test大小和SNN网络架构</p></figure><p id="6ba7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，我们初始化创建的模型，选择适当的优化器，以及相应的损失函数(在本例中为MSE)。我们创建了一个字典来存储每个时期的训练丢失和验证丢失。然后，从模型训练开始。显示列车和阀门组在每个时期的相应损失。此外，我们使用所有常见的回归指标来评估模型的性能。这里，我使用了库“<a class="ae lc" href="https://github.com/ajayarunachalam/regressormetricgraphplot" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir">regressormetricgraphplot</strong></a>”对设计的SNN回归器模型进行评估。这个包有助于简化回归模型的通用评估指标的绘制。该库的度量部分包括皮尔逊相关系数(r)、决定系数(r平方)、均方误差(mse)、均方根误差(rmse)、均方根相对误差(rmsre)、平均绝对误差(mae)、平均绝对百分比误差(mape)等。</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="lw lx l"/></div></figure><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi mj"><img src="../Images/557e17e49e56f7fe509d3c668de014d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ien7eNwwizxJG-7QdB-PcQ.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">作者图片:显示培训和验证损失</p></figure><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi mk"><img src="../Images/04099d00f5a848458362265a8e530359.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3kQL1EGI3u8FWJiITtbCrg.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">作者图片:评估指标</p></figure><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="lw lx l"/></div></figure><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ml"><img src="../Images/fb79e0964688f9f42acc745f5a1345c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p0hvC6WtpC2AVCzPHlelgg.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">作者图片:显示测试集上的训练和验证损失/时期和模型性能的图</p></figure><p id="3347" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">查看更多分类和回归问题的示例，代码如下</strong></p><ul class=""><li id="c2a7" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated"><em class="lb">在这里找到Spiking神经网络多类分类器预测模型演示的笔记本</em>:-<a class="ae lc" href="https://github.com/ajayarunachalam/pynmsnn/blob/main/pyNM/spiking-multiclass-classifier-model.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/ajayarunachalam/pynmsnn/blob/main/pyNM/Spiking-multi class-classifier-model . ipynb</a></li><li id="c1bb" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><em class="lb">在这里找到非尖峰神经网络多类分类器预测模型演示的笔记本:-</em><a class="ae lc" href="https://github.com/ajayarunachalam/pynmsnn/blob/main/pyNM/nonspiking-multiclass-classifier-model.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/ajayarunachalam/pynmsnn/blob/main/pyNM/Non Spiking-multi class-classifier-model . ipynb</a></li><li id="c489" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><em class="lb">在此处找到Spiking神经网络二元分类器预测模型演示的笔记本:-</em><a class="ae lc" href="https://github.com/ajayarunachalam/pynmsnn/blob/main/pyNM/spiking-binary-classifier-model.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/ajayarunachalam/pynmsnn/blob/main/pyNM/Spiking-Binary-classifier-model . ipynb</a></li><li id="aec4" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><em class="lb">在此找到非尖峰神经网络二元分类器预测模型演示的笔记本:-</em><a class="ae lc" href="https://github.com/ajayarunachalam/pynmsnn/blob/main/pyNM/nonspiking-binary-classifier-model.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/ajayarunachalam/pynmsnn/blob/main/pyNM/nonspiking-Binary-classifier-model . ipynb</a></li><li id="39ac" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><em class="lb">在这里找到Spiking神经网络回归器预测模型演示的笔记本:-</em><a class="ae lc" href="https://github.com/ajayarunachalam/pynmsnn/blob/main/pyNM/spiking-regressor-model.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/ajayarunachalam/pynmsnn/blob/main/pyNM/Spiking-Regressor-model . ipynb</a></li><li id="3f6c" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><em class="lb">在这里找到非尖峰神经网络回归器预测模型演示的笔记本:-</em><a class="ae lc" href="https://github.com/ajayarunachalam/pynmsnn/blob/main/pyNM/nonspiking-regressor-model.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/ajayarunachalam/pynmsnn/blob/main/pyNM/nonspiking-Regressor-model . ipynb</a></li></ul><h1 id="1f23" class="mm mn iq bd mo mp mq mr ms mt mu mv mw jw mx jx my jz mz ka na kc nb kd nc nd bi translated">连接</h1><p id="8839" class="pw-post-body-paragraph kf kg iq kh b ki ne jr kk kl nf ju kn ko ng kq kr ks nh ku kv kw ni ky kz la ij bi translated">你可以在ajay.arunachalam08@gmail.com找到我</p><p id="bb5c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们上<a class="ae lc" href="https://www.linkedin.com/in/ajay-arunachalam-4744581a/" rel="noopener ugc nofollow" target="_blank"> linkedin </a>连线吧，干杯:)</p><h1 id="f13c" class="mm mn iq bd mo mp mq mr ms mt mu mv mw jw mx jx my jz mz ka na kc nb kd nc nd bi translated">参考</h1><p id="aa62" class="pw-post-body-paragraph kf kg iq kh b ki ne jr kk kl nf ju kn ko ng kq kr ks nh ku kv kw ni ky kz la ij bi translated"><a class="ae lc" href="https://en.wikipedia.org/wiki/Spiking_neural_network" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Spiking_neural_network</a></p><p id="5258" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lc" href="https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html" rel="noopener ugc nofollow" target="_blank">https://www . Intel . com/content/www/us/en/research/neuromorphic-computing . html</a></p><p id="9826" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lc" rel="noopener" target="_blank" href="/neuromorphic-and-spiking-or-not-894a836dc3b3">https://towards data science . com/neuromorphic-and-spiking-or-not-894 a 836 DC 3 b 3</a></p><p id="5ab2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lc" href="https://www.embedded.com/neuromorphic-ai-chips-for-spiking-neural-networks-debut/" rel="noopener ugc nofollow" target="_blank">https://www . embedded . com/neuromorphic-ai-chips-for-spiking-neural-networks-处女作/ </a></p><p id="7fb1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lc" href="https://www.frontiersin.org/articles/10.3389/fnins.2018.00774/full" rel="noopener ugc nofollow" target="_blank">https://www . frontier sin . org/articles/10.3389/fnins . 2018.00774/full</a></p><p id="5eb3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lc" href="https://arxiv.org/ftp/arxiv/papers/1809/1809.09707.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/ftp/arxiv/papers/1809/1809.09707.pdf</a></p><div class="nj nk gp gr nl nm"><a href="https://www.frontiersin.org/articles/10.3389/fnins.2020.00662/full" rel="noopener  ugc nofollow" target="_blank"><div class="nn ab fo"><div class="no ab np cl cj nq"><h2 class="bd ir gy z fp nr fr fs ns fu fw ip bi translated">优化用于神经形态应用的脉冲神经网络的能量消耗</h2><div class="nt l"><h3 class="bd b gy z fp nr fr fs ns fu fw dk translated">在过去的几年里，脉冲神经网络(SNNs)已被证明具有与常规神经网络相当的性能</h3></div><div class="nu l"><p class="bd b dl z fp nr fr fs ns fu fw dk translated">www.frontiersin.org</p></div></div><div class="nv l"><div class="nw l nx ny nz nv oa md nm"/></div></div></a></div><div class="nj nk gp gr nl nm"><a href="https://pytorch.org/" rel="noopener  ugc nofollow" target="_blank"><div class="nn ab fo"><div class="no ab np cl cj nq"><h2 class="bd ir gy z fp nr fr fs ns fu fw ip bi translated">PyTorch</h2><div class="nt l"><h3 class="bd b gy z fp nr fr fs ns fu fw dk translated">推动自然语言处理和多任务学习的发展。利用PyTorch的灵活性有效地研究新的…</h3></div><div class="nu l"><p class="bd b dl z fp nr fr fs ns fu fw dk translated">pytorch.org</p></div></div><div class="nv l"><div class="ob l nx ny nz nv oa md nm"/></div></div></a></div><div class="nj nk gp gr nl nm"><a href="https://en.wikipedia.org/wiki/Hebbian_theory" rel="noopener  ugc nofollow" target="_blank"><div class="nn ab fo"><div class="no ab np cl cj nq"><h2 class="bd ir gy z fp nr fr fs ns fu fw ip bi translated">赫比理论-维基百科</h2><div class="nt l"><h3 class="bd b gy z fp nr fr fs ns fu fw dk translated">赫布边理论是一个神经科学理论，声称突触效能的增加来自于突触前…</h3></div><div class="nu l"><p class="bd b dl z fp nr fr fs ns fu fw dk translated">en.wikipedia.org</p></div></div></div></a></div><div class="nj nk gp gr nl nm"><a rel="noopener follow" target="_blank" href="/spiking-neural-networks-the-next-generation-of-machine-learning-84e167f4eb2b"><div class="nn ab fo"><div class="no ab np cl cj nq"><h2 class="bd ir gy z fp nr fr fs ns fu fw ip bi translated">脉冲神经网络，下一代机器学习</h2><div class="nt l"><h3 class="bd b gy z fp nr fr fs ns fu fw dk translated">每个远程关注机器学习最新进展的人都听说过当前的第二代机器…</h3></div><div class="nu l"><p class="bd b dl z fp nr fr fs ns fu fw dk translated">towardsdatascience.com</p></div></div><div class="nv l"><div class="oc l nx ny nz nv oa md nm"/></div></div></a></div></div></div>    
</body>
</html>