<html>
<head>
<title>Fundamentals Of Statistics For Data Scientists and Analysts</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学家和分析师的统计学基础</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fundamentals-of-statistics-for-data-scientists-and-data-analysts-69d93a05aae7?source=collection_archive---------0-----------------------#2021-04-17">https://towardsdatascience.com/fundamentals-of-statistics-for-data-scientists-and-data-analysts-69d93a05aae7?source=collection_archive---------0-----------------------#2021-04-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3c3d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">数据科学或数据分析之旅的关键统计概念</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3d837e28f741cef15e30cf335d054a33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5gU4KwudRqY-vP0G2UpRZA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://www.pexels.com/photo/marketing-businessman-person-hands-6801647/" rel="noopener ugc nofollow" target="_blank">佩克斯/安娜·涅克拉舍维奇</a></p></figure><p id="bcc4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如英国数学家卡尔·皮尔逊曾经说过的那样，<strong class="lb iu">统计学</strong>是科学的语法，尤其适用于计算机和信息科学、物理科学和生物科学。当你开始你的<strong class="lb iu">数据科学</strong>或<strong class="lb iu">数据分析</strong>之旅时，拥有统计知识将帮助你更好地利用数据洞察力。</p><blockquote class="lv lw lx"><p id="1760" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">"统计学是科学的语法。"<strong class="lb iu">卡尔·皮尔逊</strong></p></blockquote><p id="8f82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">统计学在数据科学和数据分析中的重要性不可低估。统计学提供了工具和方法来发现结构并给出更深层次的数据见解。统计学和数学都热爱事实，讨厌猜测。了解这两个重要主题的基础知识将允许您进行批判性思考，并在使用数据解决业务问题和做出数据驱动的决策时具有创造性。在本文中，我将介绍数据科学和数据分析的以下统计主题:</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="a360" class="mh mi it md b gy mj mk l ml mm"><strong class="md iu">- Random variables<br/>- Probability distribution functions (PDFs)<br/>- Mean, Variance, Standard Deviation<br/>- Covariance and Correlation <br/>- Bayes Theorem<br/>- Linear Regression and Ordinary Least Squares (OLS)<br/>- Gauss-Markov Theorem<br/>- Parameter properties (Bias, Consistency, Efficiency)<br/>- Confidence intervals<br/>- Hypothesis testing<br/>- Statistical significance <br/>- Type I &amp; Type II Errors<br/>- Statistical tests (Student's t-test, F-test)<br/>- p-value and its limitations<br/>- Inferential Statistics <br/>- Central Limit Theorem &amp; Law of Large Numbers<br/>- Dimensionality reduction techniques (PCA, FA)</strong></span></pre><p id="b5a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你以前没有统计学知识，你想从头开始识别和学习基本的统计学概念，为你的工作面试做准备，那么这篇文章就是为你准备的。这篇文章也是任何想更新他/她的统计知识的人的好读物。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="b2de" class="mu mi it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">随机变量</h1><p id="f663" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">随机变量的概念构成了许多统计概念的基石。可能很难理解其正式的数学定义，但简单地说，<strong class="lb iu">随机变量</strong>是一种将随机过程的结果映射到数字的方法，例如抛硬币或掷骰子。例如，我们可以用随机变量X来定义抛硬币的随机过程，如果结果是<em class="ly">正面</em>则取值1，如果结果是<em class="ly">反面则取值0。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/60fb33982e6ce0725cdfda9a41c42722.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*VLrlt3YrYCjgFvQWfTAoDw.png"/></div></figure><p id="04cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个例子中，我们有一个抛硬币的随机过程，这个实验可以产生<strong class="lb iu"> <em class="ly">两个</em> </strong> <strong class="lb iu"> <em class="ly">可能的结果</em> </strong> : {0，1}。这组所有可能的结果称为实验的<strong class="lb iu"> <em class="ly">样本空间</em> </strong>。每次重复随机过程时，称为一个<strong class="lb iu"> <em class="ly">事件。</em> </strong>在这个例子中，抛硬币得到一条尾巴作为结果是一个事件。这一事件以特定结果发生的几率或可能性称为该事件的<strong class="lb iu"> <em class="ly">概率</em> </strong>。事件的概率是随机变量取x的特定值的可能性，可以用P(x)来描述。在抛硬币的例子中，获得正面或反面的可能性是相同的，即0.5%或50%。因此，我们有以下设置:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/f787fa37199930c834dd91a96bc68474.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yKkymQ4HqNzx1WJbFM-9cg.png"/></div></div></figure><p id="6fb1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本例中，事件的概率只能取[0，1]范围内的值。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><blockquote class="ns"><p id="44ac" class="nt nu it bd nv nw nx ny nz oa ob lu dk translated">统计学在数据科学和数据分析中的重要性不可低估。统计学提供了工具和方法来发现结构并给出更深层次的数据见解。</p></blockquote><h1 id="723e" class="mu mi it bd mv mw oc my mz na od nc nd jz oe ka nf kc of kd nh kf og kg nj nk bi translated">均值、方差、标准差</h1><p id="0c85" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">为了理解均值、方差和许多其他统计主题的概念，学习<strong class="lb iu"> <em class="ly">人口</em> </strong>和<strong class="lb iu"> <em class="ly">样本</em>的概念是很重要的。</strong><strong class="lb iu"><em class="ly">总体</em> </strong>是所有观察值(个体、对象、事件或程序)的集合，通常非常大且多样，而<strong class="lb iu"> <em class="ly">样本</em> </strong> <em class="ly"> </em>是总体中观察值的子集，理想情况下是总体的真实代表。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/797118cbf3ae8a240f806077144db6fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VnNrkwNuW2hBKA8DC84Gdg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</p></figure><p id="f43c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">鉴于对整个人群进行实验要么是不可能的，要么就是太昂贵，研究人员或分析师在他们的实验或试验中使用样本而不是整个人群。为了确保实验结果可靠并适用于整个群体，样本需要真实地代表总体。也就是说，样本需要是无偏的。为此，可以使用统计抽样技术，如<a class="ae ky" href="https://github.com/TatevKaren/mathematics-statistics-for-data-science/tree/main/Sampling%20Techniques" rel="noopener ugc nofollow" target="_blank">随机抽样、系统抽样、整群抽样、加权抽样和分层抽样。</a></p><h2 id="2d7c" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">平均</h2><p id="7ad0" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">均值，也称为平均值，是一组有限数字的中心值。让我们假设数据中的随机变量X具有以下值:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/a5e8cec1a593947980f7c8f066f3decf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zrm1qmeLIK8kQksS039OHw.png"/></div></div></figure><p id="e1e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中N是样本集中观察值或数据点的数量，或简称为数据频率。那么<strong class="lb iu"> <em class="ly">样本均值</em> </strong> <em class="ly"> </em>由<strong class="lb iu"> μ </strong>定义，这非常常用于近似<strong class="lb iu"> <em class="ly">总体均值</em> </strong> <em class="ly">，</em>可表示如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/1ad2e99479fc81f6152d7b92cbd4af4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*97xrJnzgY0nabQF1yCG-tQ.png"/></div></div></figure><p id="cf61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">平均值也称为<strong class="lb iu"> <em class="ly">期望</em> </strong>，通常由<strong class="lb iu"> E </strong>()或顶部带横杠的随机变量定义。例如，随机变量X和Y的期望，即分别为<strong class="lb iu"> E </strong> (X)和<strong class="lb iu"> E </strong> (Y)，可以表示如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/4db687755f2022f31d622a20151f1242.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fIlJnEyfoTbXX-no9CWOjw.png"/></div></div></figure><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="d2d4" class="mh mi it md b gy mj mk l ml mm">import numpy as np<br/>import math</span><span id="c016" class="mh mi it md b gy ow mk l ml mm">x = np.array([1,3,5,6])<br/>mean_x = np.mean(x)</span><span id="41b0" class="mh mi it md b gy ow mk l ml mm"># in case the data contains Nan values<br/>x_nan = np.array([1,3,5,6, math.nan])<br/>mean_x_nan = np.nanmean(x_nan)</span></pre><h2 id="3674" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">差异</h2><p id="909b" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">方差测量数据点与平均值<em class="ly">、</em>相差多远，等于数据值与平均值(平均值)之差的平方和。再者，<strong class="lb iu"> <em class="ly">人口方差</em></strong><em class="ly"/>可以表示如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ca"><img src="../Images/8cc4e3d99c2bf70ebcf49b55486deaaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MtRN-SST_josB7RY9AqWMA.png"/></div></div></figure><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="d1ca" class="mh mi it md b gy mj mk l ml mm">x = np.array([1,3,5,6])<br/>variance_x = np.var(x)</span><span id="b58c" class="mh mi it md b gy ow mk l ml mm"><br/># here you need to specify the degrees of freedom (df) max number of logically independent data points that have freedom to vary</span><span id="2944" class="mh mi it md b gy ow mk l ml mm">x_nan = np.array([1,3,5,6, math.nan])<br/>mean_x_nan = np.nanvar(x_nan, ddof = 1)</span></pre><p id="dd45" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要获得不同流行概率分布函数的期望和方差，<a class="ae ky" href="https://github.com/TatevKaren/mathematics-statistics-for-data-science/tree/main/Deriving%20Expectation%20and%20Variances%20of%20Densities" rel="noopener ugc nofollow" target="_blank">查看Github repo </a>。</p><h2 id="245c" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">标准偏差</h2><p id="8d16" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">标准差就是方差的平方根，衡量数据偏离均值的程度。<strong class="lb iu"><em class="ly">∑</em></strong><em class="ly"/>定义的标准偏差可以表示如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/6e3bbe33757f9a5364f60c93e009ea2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m4UE4oDLL7ysLUAbfSmbag.png"/></div></div></figure><p id="32f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">标准差通常优于方差，因为它与数据点具有相同的单位，这意味着您可以更容易地解释它。</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="6e94" class="mh mi it md b gy mj mk l ml mm">x = np.array([1,3,5,6])<br/>variance_x = np.std(x)<br/><br/>x_nan = np.array([1,3,5,6, math.nan])<br/>mean_x_nan = np.nanstd(x_nan, ddof = 1)</span></pre><h2 id="8d68" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">协方差</h2><p id="e6e6" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">协方差是两个随机变量的联合可变性的度量，描述了这两个变量之间的关系。它被定义为两个随机变量与其均值的偏差乘积的期望值。两个随机变量X和Z之间的协方差可以用下面的表达式来描述，其中<strong class="lb iu"> E </strong> (X)和<strong class="lb iu"> E </strong> (Z)分别代表X和Z的均值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/56312fb811e722d4380a24750859402d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jaov1ABZH4HAHE3cmz_eyQ.png"/></div></div></figure><p id="1d3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">协方差可以取负值或正值，也可以取值0。协方差的正值表示两个随机变量趋向于同向变化，而负值表示这些变量反向变化。最后，值0意味着它们不一起变化。</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="37a6" class="mh mi it md b gy mj mk l ml mm">x = np.array([1,3,5,6])<br/>y = np.array([-2,-4,-5,-6])</span><span id="d73e" class="mh mi it md b gy ow mk l ml mm">#this will return the covariance matrix of x,y containing x_variance, y_variance on diagonal elements and covariance of x,y<br/>cov_xy = np.cov(x,y)</span></pre><h2 id="17d0" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">相互关系</h2><p id="813d" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">相关性也是对关系的度量，它度量两个变量之间线性关系的强度和方向。如果检测到相关性，则意味着在两个目标变量的值之间存在关系或模式。两个随机变量X和Z之间的相关性等于这两个变量之间的协方差除以这些变量的标准偏差的乘积，这可以由下面的表达式来描述。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/0b3f005b5d2c6eae337c05af6492a7e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k96hYXHRfiH7XGBWgffQjQ.png"/></div></div></figure><p id="4925" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相关系数的值介于-1和1之间。请记住，变量与其自身的相关性始终为1，即<strong class="lb iu"> Cor(X，X) = 1 </strong>。在解释相关性时要记住的另一件事是不要将其与<strong class="lb iu"> <em class="ly">因果关系</em> </strong>混淆，因为相关性不是因果关系。即使两个变量之间存在相关性，你也不能断定一个变量会引起另一个变量的变化。这种关系可能是巧合，或者第三个因素可能导致这两个变量发生变化。</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="7f08" class="mh mi it md b gy mj mk l ml mm">x = np.array([1,3,5,6])<br/>y = np.array([-2,-4,-5,-6])</span><span id="01ab" class="mh mi it md b gy ow mk l ml mm">corr = np.corrcoef(x,y)</span></pre></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="fa3e" class="mu mi it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated"><strong class="ak">概率分布函数</strong></h1><p id="ac32" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">描述所有可能值、样本空间和随机变量在给定范围内可能取的相应概率的函数，介于最小和最大可能值之间，称为<strong class="lb iu"> <em class="ly">概率分布函数(pdf) </em> </strong>或概率密度。每个pdf都需要满足以下两个标准:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/ea31b532ed33858bca4969673ef749e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jwC75xVvcFg7iXUxfaTNFw.png"/></div></div></figure><p id="f3e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中第一个标准规定所有的概率应该是在[0，1]范围内的数字，第二个标准规定所有可能的概率之和应该等于1。</p><p id="0cbe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">概率函数通常分为两类:<strong class="lb iu"> <em class="ly">离散</em> </strong>和<strong class="lb iu"> <em class="ly">连续</em> </strong>。离散<em class="ly"> </em>分布<em class="ly"> </em>函数用<strong class="lb iu"> <em class="ly">可数</em> </strong>样本空间描述随机过程，就像在抛硬币的例子中，只有两种可能的结果。连续<em class="ly"> </em>分布函数描述了随机过程与<strong class="lb iu"><em class="ly"/></strong>连续的样本空间。离散分布函数的例子有<a class="ae ky" href="https://en.wikipedia.org/wiki/Bernoulli_distribution" rel="noopener ugc nofollow" target="_blank">伯努利</a>、<a class="ae ky" href="https://en.wikipedia.org/wiki/Binomial_distribution" rel="noopener ugc nofollow" target="_blank">二项式</a>、<a class="ae ky" href="https://en.wikipedia.org/wiki/Poisson_distribution" rel="noopener ugc nofollow" target="_blank">泊松</a>、<a class="ae ky" href="https://en.wikipedia.org/wiki/Discrete_uniform_distribution" rel="noopener ugc nofollow" target="_blank">离散均匀</a>。连续分布函数的例子有<a class="ae ky" href="https://en.wikipedia.org/wiki/Normal_distribution" rel="noopener ugc nofollow" target="_blank">正态</a>、<a class="ae ky" href="https://en.wikipedia.org/wiki/Continuous_uniform_distribution" rel="noopener ugc nofollow" target="_blank">连续均匀</a>、<a class="ae ky" href="https://en.wikipedia.org/wiki/Cauchy_distribution" rel="noopener ugc nofollow" target="_blank">柯西</a>。</p><h2 id="22ff" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">二项分布</h2><p id="9537" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated"><a class="ae ky" href="https://brilliant.org/wiki/binomial-distribution/" rel="noopener ugc nofollow" target="_blank">二项分布</a>是一系列<strong class="lb iu"> n个</strong>独立实验中成功次数的离散概率分布，每个实验的结果为布尔值:<strong class="lb iu"><em class="ly"/></strong>(概率为<strong class="lb iu"> p </strong>)或<strong class="lb iu"> <em class="ly">失败</em> </strong>(概率为<strong class="lb iu">q</strong>= 1p)。假设随机变量X遵循二项分布，那么在n次独立试验中观察到<em class="ly"> </em> <strong class="lb iu"> <em class="ly"> k </em> </strong>成功的概率可以由下面的概率密度函数表示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/e193daa6333c73c1eaebb8fe4dda42d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*llaosjWmH_0huR5Z80XTSw.png"/></div></div></figure><p id="0f61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当分析重复独立实验的结果时，二项式分布是有用的，特别是如果人们对在给定特定错误率的情况下满足特定阈值的概率感兴趣。</p><p id="44ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">二项分布均值&amp;方差</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/ab458651b75e2bb483a6d5e51bd75760.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*la5m94kDTYUhEB2CExi8_w.png"/></div></div></figure><p id="9d3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图显示了一个二项式分布的例子，其中独立试验的数量等于8，每次试验的成功概率等于16%。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/ac4bfcede854d1ba125c9855a2a2fa24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*68nMYVFT0e5VsMBf8c226g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</p></figure><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="0a83" class="mh mi it md b gy mj mk l ml mm"># Random Generation of 1000 independent Binomial samples<br/>import numpy as np<br/>n = 8<br/>p = 0.16<br/>N = 1000<br/>X = np.random.binomial(n,p,N)</span><span id="08ca" class="mh mi it md b gy ow mk l ml mm"># Histogram of Binomial distribution<br/>import matplotlib.pyplot as plt<br/>counts, bins, ignored = plt.hist(X, 20, density = True, rwidth = 0.7, color = 'purple')<br/>plt.title("Binomial distribution with p = 0.16 n = 8")<br/>plt.xlabel("Number of successes")<br/>plt.ylabel("Probability")<br/>plt.show()</span></pre><h2 id="34ea" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">泊松分布</h2><p id="bcab" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated"><a class="ae ky" href="https://brilliant.org/wiki/poisson-distribution/" rel="noopener ugc nofollow" target="_blank">泊松分布</a>是特定时间段内发生的事件数量的离散概率分布，给定该时间段内事件发生的平均次数。假设随机变量X服从泊松分布，那么在一段时间内观察到<em class="ly"> </em> <strong class="lb iu"> <em class="ly"> k </em> </strong>事件的概率可以用下面的概率函数表示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/2119ef3873e68c2082ff4268106a1d7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nDKMS-M07qbNPmRK6Z8OeA.png"/></div></div></figure><p id="7236" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中<strong class="lb iu"> <em class="ly"> e </em> </strong>为<a class="ae ky" href="https://brilliant.org/wiki/eulers-number/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="ly">欧拉数</em> </strong> </a>和<strong class="lb iu"><em class="ly">λ</em></strong>λ，<strong class="lb iu"> <em class="ly">到达率参数</em> </strong>为<strong class="lb iu"><em class="ly"/></strong>x的期望值。泊松分布函数因其在对给定时间间隔内发生的可数事件建模中的用途而非常流行。</p><p id="193b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">泊松分布均值&amp;方差</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/552e43a1afc23e649337bce0ddd8728b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2HtMzd1HbGzcSWXZEpU1xw.png"/></div></div></figure><p id="f3b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，泊松分布可用于模拟晚上7点到10点之间到达商店的顾客数量，或者晚上11点到12点之间到达急诊室的患者数量。下图显示了泊松分布的一个示例，其中我们计算了到达网站的Web访问者的数量，到达率λ假定等于7分钟。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/0172b3a36df54a0c82300cf02a20669a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pMhbq88yZEp4gGFYhId82Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</p></figure><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="38dc" class="mh mi it md b gy mj mk l ml mm"># Random Generation of 1000 independent Poisson samples<br/>import numpy as np<br/>lambda_ = 7<br/>N = 1000<br/>X = np.random.poisson(lambda_,N)<br/><br/># Histogram of Poisson distribution<br/>import matplotlib.pyplot as plt<br/>counts, bins, ignored = plt.hist(X, 50, density = True, color = 'purple')<br/>plt.title("Randomly generating from Poisson Distribution with lambda = 7")<br/>plt.xlabel("Number of visitors")<br/>plt.ylabel("Probability")<br/>plt.show()</span></pre><h2 id="0a80" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">正态分布</h2><p id="3b05" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated"><a class="ae ky" href="https://brilliant.org/wiki/normal-distribution/" rel="noopener ugc nofollow" target="_blank">正态概率分布</a>是实值随机变量的连续概率分布。正态分布，也称为<strong class="lb iu"> <em class="ly">高斯分布</em> </strong>可以说是社会科学和自然科学中最常用的分布函数之一，用于建模，例如，它用于对人的身高或考试成绩进行建模。假设随机变量X服从正态分布，那么它的概率密度函数可以表示如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/cb39019b83d98ec302eaffeae47f0858.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gLmxkk3zPtwT6oriJ3B6LA.png"/></div></div></figure><p id="6c7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中参数<strong class="lb iu">μ</strong>(μ)<strong class="lb iu"/>是分布的平均值，也称为<strong class="lb iu"> <em class="ly">位置参数</em> </strong>，参数<strong class="lb iu"> σ </strong> (sigma) <strong class="lb iu"> </strong>是分布的标准偏差，也称为<em class="ly">比例参数</em>。数字<a class="ae ky" href="https://www.mathsisfun.com/numbers/pi.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> π </strong> </a> (pi)是一个数学常数，大约等于3.14。</p><p id="9b1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">正态分布均值&amp;方差</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/a46f0def0098d23f90879136c09aca1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N21FGnh4krG1Sd7E8y49zQ.png"/></div></div></figure><p id="ac1f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图显示了一个均值为0 ( <strong class="lb iu"> μ = 0 </strong>)标准差为1 ( <strong class="lb iu"> σ = 1 </strong>)的正态分布示例，这被称为<strong class="lb iu"> <em class="ly">标准正态</em> </strong>分布，它是<em class="ly">对称的。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/13e2dec2bcd12ae3059bd94225e54afa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T_jAWtNjpf5lx29TbqwigQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</p></figure><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="1e93" class="mh mi it md b gy mj mk l ml mm"># Random Generation of 1000 independent Normal samples<br/>import numpy as np<br/>mu = 0<br/>sigma = 1<br/>N = 1000<br/>X = np.random.normal(mu,sigma,N)<br/><br/># Population distribution<br/>from scipy.stats import norm<br/>x_values = np.arange(-5,5,0.01)<br/>y_values = norm.pdf(x_values)</span><span id="a078" class="mh mi it md b gy ow mk l ml mm">#Sample histogram with Population distribution<br/>import matplotlib.pyplot as plt<br/>counts, bins, ignored = plt.hist(X, 30, density = True,color = 'purple',label = 'Sampling Distribution')<br/>plt.plot(x_values,y_values, color = 'y',linewidth = 2.5,label = 'Population Distribution')<br/>plt.title("Randomly generating 1000 obs from Normal distribution mu = 0 sigma = 1")<br/>plt.ylabel("Probability")<br/>plt.legend()<br/>plt.show()</span></pre><h1 id="6536" class="mu mi it bd mv mw oc my mz na od nc nd jz pk ka nf kc pl kd nh kf pm kg nj nk bi translated"><strong class="ak">贝叶斯定理</strong></h1><p id="cf5a" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">贝叶斯定理或通常称为<strong class="lb iu"> <em class="ly">贝叶斯定律</em> </strong>可以说是概率统计中最强大的规则，以著名的英国统计学家和哲学家托马斯·贝叶斯的名字命名。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/ecf099fa99478160ae60f470fbabb5d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/0*ypJ6xW1FA_Lh7Faw.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://en.wikipedia.org/wiki/Thomas_Bayes" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="534b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">贝叶斯定理是一个强大的概率定律，它将<strong class="lb iu"> <em class="ly">主观性</em> </strong>的概念带入了一切都与事实有关的统计和数学世界。它描述了一个事件发生的概率，基于可能与该事件相关的<strong class="lb iu"> <em class="ly">条件</em> </strong>的先验信息。例如，如果已知患冠状病毒或新冠肺炎的风险会随着年龄的增长而增加，那么贝叶斯定理允许通过将年龄作为条件来更准确地确定已知年龄的个体的风险，而不是简单地假设该个体是整个人口中的常见个体。</p><p id="c503" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="ly">条件概率</em>，</strong>的概念在贝叶斯理论中起着核心作用，它是一个事件发生的概率的度量，假设另一个事件已经发生。贝叶斯定理可以由下面的表达式描述，其中X和Y分别代表事件X和Y:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi po"><img src="../Images/9d5cea618a072361ae7c165a5034e1c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4js6ZegGoR7otx55kLZ-Lg.png"/></div></div></figure><ul class=""><li id="e4d2" class="pp pq it lb b lc ld lf lg li pr lm ps lq pt lu pu pv pw px bi translated">Pr  (X|Y):给定事件或条件Y已经发生或为真，事件X发生的概率</li><li id="eebf" class="pp pq it lb b lc py lf pz li qa lm qb lq qc lu pu pv pw px bi translated">Pr  (Y|X):给定事件或条件X已经发生或为真，事件Y发生的概率</li><li id="323c" class="pp pq it lb b lc py lf pz li qa lm qb lq qc lu pu pv pw px bi translated"><em class="ly">Pr</em>(X)&amp;<em class="ly">Pr</em>(Y):分别为观察事件X和Y的概率</li></ul><p id="75d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在前面的例子中，以在某个年龄为条件的获得冠状病毒(事件X)的概率是<em class="ly"> Pr </em> (X|Y)，它等于给定一个人在某个年龄获得冠状病毒的概率，<em class="ly"> Pr </em> (Y|X)，乘以获得冠状病毒的概率，<em class="ly"> Pr </em> (X)，除以在某个年龄的概率。，<em class="ly"> Pr </em> (Y)。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="95d1" class="mu mi it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">线性回归</h1><p id="7298" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">早些时候，变量之间的因果关系的概念被引入，这发生在一个变量对另一个变量有直接影响的时候。当两个变量之间的关系是线性时，那么线性回归是一种统计方法，可以帮助建模一个变量中单位变化的影响，<strong class="lb iu"><em class="ly"/></strong><strong class="lb iu"><em class="ly">自变量</em> </strong>，<strong class="lb iu"> <em class="ly">因变量</em> </strong>。</p><p id="b4df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因变量常被称为<strong class="lb iu"> <em class="ly">反应变量</em> </strong>或<strong class="lb iu"> <em class="ly">解释变量</em><em class="ly"/></strong>而自变量常被称为<strong class="lb iu"> <em class="ly">回归变量</em> </strong>或<strong class="lb iu"> <em class="ly">解释变量</em> </strong>。当线性回归模型基于单个自变量时，则该模型称为<strong class="lb iu"> <em class="ly">简单线性回归</em> </strong>，当模型基于多个自变量时，则称为<strong class="lb iu"> <em class="ly">多元线性回归</em>。</strong>简单的线性回归可以用下面的表达式来描述:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qd"><img src="../Images/afe697f64175be3da20e56b1120ee977.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EdKLk0rUW2Q3dqcbc_tquQ.png"/></div></div></figure><p id="3bca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中<strong class="lb iu"> Y </strong>为因变量，<strong class="lb iu"> X </strong>为自变量，为数据的一部分，<strong class="lb iu"> β0 </strong>为未知常数的截距，<strong class="lb iu"> β1 </strong>为斜率或未知常数的变量X对应的参数。最后，<strong class="lb iu"> u </strong>是模型在估计Y值时产生的误差项。线性回归背后的主要思想是通过一组成对的(X，Y)数据找到最拟合的直线，<strong class="lb iu"> <em class="ly">回归线，</em> </strong>。线性回归应用的一个例子是模拟<em class="ly">鳍状肢长度</em>对企鹅<em class="ly">体重</em>的影响，如下图所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/2cb648d6af35f0b4dbd3c6eba39d83e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*cS-5_yS2xa--V97U1RoAIQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</p></figure><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="0ea2" class="mh mi it md b gy mj mk l ml mm"># R code for the graph<br/>install.packages("ggplot2")<br/>install.packages("palmerpenguins")<br/>library(palmerpenguins)<br/>library(ggplot2)</span><span id="573d" class="mh mi it md b gy ow mk l ml mm">View(data(penguins))</span><span id="8685" class="mh mi it md b gy ow mk l ml mm">ggplot(data = penguins, aes(x = flipper_length_mm,y = body_mass_g))+<br/>  geom_smooth(method = "lm", se = FALSE, color = 'purple')+<br/>  geom_point()+<br/>  labs(x="Flipper Length (mm)",y="Body Mass (g)")</span></pre><p id="41f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">具有三个独立变量的多元线性回归可由以下表达式描述:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qf"><img src="../Images/980bd41a342eddfb4000979d94db7d48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OKlROokMK1rabqlg4_lZoQ.png"/></div></div></figure><h2 id="77b8" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">普通最小二乘法</h2><p id="9916" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">普通最小二乘法(OLS)是一种估计线性回归模型中β0和β1 <strong class="lb iu"> </strong>等未知参数的方法。该模型基于<strong class="lb iu"> <em class="ly">最小二乘</em> </strong>的原理，即<strong class="lb iu"> </strong>使观察到的因变量与其由自变量的线性函数预测的值之差的平方和最小化，通常称为<strong class="lb iu"> <em class="ly">【拟合值】</em> </strong>。因变量Y的实际值和预测值之间的差异被称为<strong class="lb iu"> <em class="ly">残差</em> </strong>，OLS所做的是最小化残差平方和。这个优化问题导致未知参数β0和β1的以下OLS估计，也称为<strong class="lb iu"> <em class="ly">系数估计</em> </strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qg"><img src="../Images/999c493c5db71d57bf481243e7171c42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HK5bkukVqwBT0hzqrh_68w.png"/></div></div></figure><p id="76d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦简单线性回归模型的这些参数被估计，响应变量的<strong class="lb iu"> <em class="ly">拟合值</em> </strong> <em class="ly"> </em>可以计算如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qh"><img src="../Images/6fd1bc42b02d5ba485b8cff3d4c523ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eu95xXeRNFv0FV6XWPbOwQ.png"/></div></div></figure><h2 id="5946" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">标准误差</h2><p id="6fb7" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated"><strong class="lb iu"> <em class="ly">残差</em> </strong>或估计误差项可确定如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qi"><img src="../Images/6df001944c63c263ca6b9a0efc02a891.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wexzs-h-512g18ezmTAY-w.png"/></div></div></figure><p id="bf01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">记住误差项和残差之间的区别很重要。误差项永远不会被观察到，而残差是从数据中计算出来的。OLS估计每个观测值的误差项，但不是实际的误差项。因此，真正的误差方差仍然未知。此外，这些估计受抽样不确定性的影响。这意味着我们将永远无法从经验应用的样本数据中确定这些参数的准确估计值和真实值。但是我们可以通过计算<strong class="lb iu"> <em class="ly">样本</em> </strong> <em class="ly"> </em> <strong class="lb iu"> <em class="ly">残差方差</em> </strong>来估计，使用的残差如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qj"><img src="../Images/4ce93be44d95d6f8506fa080bbfb2162.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VhtarIwqjIaucrsKZjh5xw.png"/></div></div></figure><p id="e87b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">样本残差方差的这种估计有助于估计估计参数的方差，估计参数的方差通常表示如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qk"><img src="../Images/7289dd3f6d1bac1148fc8c6817077c60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rv7usmqF5bF3afav_TuT0Q.png"/></div></div></figure><p id="85cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个方差项的平方根被称为<strong class="lb iu">估计值的标准误差</strong>，这是评估参数估计值准确性的关键部分。它用于计算测试统计和置信区间。标准误差可以表示如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ql"><img src="../Images/5232b62aa312d75c7c673ceba1e8bac4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LsY-hPm7Fodfvy2DXY_6Gw.png"/></div></div></figure><blockquote class="ns"><p id="8902" class="nt nu it bd nv nw qm qn qo qp qq lu dk translated">记住误差项和残差之间的区别很重要。误差项永远不会被观察到，而残差是从数据中计算出来的。</p></blockquote><h2 id="842e" class="mh mi it bd mv oi qr dn mz ok qs dp nd li qt on nf lm qu op nh lq qv or nj os bi translated">OLS假设</h2><p id="bf98" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">OLS估计法作出如下假设，需要满足这些假设才能得到可靠的预测结果:</p><p id="8850" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> A1:线性</strong>假设模型的参数是线性的。</p><p id="8d0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> A2: </strong> <strong class="lb iu">随机</strong> <strong class="lb iu">样本</strong>假设样本中的所有观测值都是随机选取的。</p><p id="bb4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> A3:外生性</strong>假设独立变量与误差项不相关。</p><p id="d34a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> A4:同方差</strong>假设所有误差项的方差为常数。</p><p id="0680" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> A5:没有完美的多重共线性</strong>假设没有一个自变量是恒定的，自变量之间没有精确的线性关系。</p><pre class="kj kk kl km gt mc md me mf aw mg bi"><span id="9060" class="mh mi it md b gy mj mk l ml mm">def runOLS(Y,X):<br/><br/>   # OLS esyimation Y = Xb + e --&gt; beta_hat = (X'X)^-1(X'Y)<br/>   beta_hat = np.dot(np.linalg.inv(np.dot(np.transpose(X), X)), np.dot(np.transpose(X), Y))<br/><br/>   # OLS prediction<br/>   Y_hat = np.dot(X,beta_hat)<br/>   residuals = Y-Y_hat<br/>   RSS = np.sum(np.square(residuals))<br/>   sigma_squared_hat = RSS/(N-2)<br/>   TSS = np.sum(np.square(Y-np.repeat(Y.mean(),len(Y))))<br/>   MSE = sigma_squared_hat<br/>   RMSE = np.sqrt(MSE)<br/>   R_squared = (TSS-RSS)/TSS<br/><br/>   # Standard error of estimates:square root of estimate's variance<br/>   var_beta_hat = np.linalg.inv(np.dot(np.transpose(X),X))*sigma_squared_hat<br/>   <br/>   SE = []<br/>   t_stats = []<br/>   p_values = []<br/>   CI_s = []<br/>   <br/>   for i in range(len(beta)):<br/>       #standard errors<br/>       SE_i = np.sqrt(var_beta_hat[i,i])<br/>       SE.append(np.round(SE_i,3))<br/><br/>        #t-statistics<br/>        t_stat = np.round(beta_hat[i,0]/SE_i,3)<br/>        t_stats.append(t_stat)<br/><br/>        #p-value of t-stat p[|t_stat| &gt;= t-treshhold two sided] <br/>        p_value = t.sf(np.abs(t_stat),N-2) * 2<br/>        p_values.append(np.round(p_value,3))<br/><br/>        #Confidence intervals = beta_hat -+ margin_of_error<br/>        t_critical = t.ppf(q =1-0.05/2, df = N-2)<br/>        margin_of_error = t_critical*SE_i<br/>        CI = [np.round(beta_hat[i,0]-margin_of_error,3), np.round(beta_hat[i,0]+margin_of_error,3)]<br/>        CI_s.append(CI)</span><span id="4d33" class="mh mi it md b gy ow mk l ml mm">        return(beta_hat, SE, t_stats, p_values,CI_s, <br/>               MSE, RMSE, R_squared)</span></pre></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="c825" class="mu mi it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">参数属性</h1><blockquote class="lv lw lx"><p id="767f" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">在满足OLS准则A1 — A5的假设下，系数β0和β1的OLS估计量为<strong class="lb iu">蓝色</strong>和<strong class="lb iu">一致</strong>。</p><p id="e003" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated"><strong class="lb iu">高斯-马尔可夫定理</strong></p></blockquote><p id="9c85" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个定理突出了OLS估计的性质，其中术语<strong class="lb iu"><em class="ly"/></strong>代表<strong class="lb iu"> <em class="ly">最佳线性无偏估计量</em> </strong>。</p><h2 id="4dac" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated"><strong class="ak">偏差</strong></h2><p id="d61c" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">估计量的<strong class="lb iu">偏差</strong>是其期望值和被估计参数的真实值之间的差值，可以表示如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qw"><img src="../Images/8409a7b205ff9698fc1b499bb51cd383.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dkNeD-TsZUm9L0Q0a5MzTw.png"/></div></div></figure><p id="19d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们声明估计量是<strong class="lb iu"> <em class="ly">无偏的</em> </strong>时，我们的意思是偏倚等于零，这就暗示了估计量的期望值等于真实参数值，即:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/3dd86e83777d49238dd680cc860a1124.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T9wYHyB9GwoFyw9azp5IUQ.png"/></div></div></figure><p id="9f5e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">无偏性不能保证任何特定样本的估计值等于或接近β。这意味着，如果一个<strong class="lb iu"> <em class="ly">重复</em> </strong>从总体中抽取随机样本，然后每次都计算估计值，那么这些估计值的平均值将等于或非常接近β。</p><h2 id="78b6" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">效率</h2><p id="93fb" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">高斯-马尔可夫定理中的术语<strong class="lb iu"><em class="ly"/></strong>与估计量的方差有关，称为<strong class="lb iu"> <em class="ly">效率</em> </strong> <em class="ly">。</em>一个参数可以有多个估计值，但是方差最小的那个被称为有效的<strong class="lb iu">。</strong></p><h2 id="5994" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">一致性</h2><p id="e0c1" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">术语一致性与术语<strong class="lb iu"> <em class="ly">样本量</em> </strong>和<strong class="lb iu"> <em class="ly">收敛</em> </strong>密切相关。如果当样本量变得很大时，估计量收敛于真实参数，则称该估计量是一致的，即:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qx"><img src="../Images/c49e28207d2893ddbd4c663d2941120f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Iu0mDhst-eLg5KNNMmzSyw.png"/></div></div></figure><blockquote class="ns"><p id="c758" class="nt nu it bd nv nw qm qn qo qp qq lu dk translated">在满足OLS准则A1 — A5的假设下，系数β0和β1的OLS估计量是<strong class="ak">蓝色</strong>和<strong class="ak">一致</strong>。</p><p id="8fb8" class="nt nu it bd nv nw nx ny nz oa ob lu dk translated"><strong class="ak">高斯-马尔科夫定理</strong></p></blockquote><p id="5f50" class="pw-post-body-paragraph kz la it lb b lc qy ju le lf qz jx lh li ra lk ll lm rb lo lp lq rc ls lt lu im bi translated">所有这些性质都适用于OLS估计，正如高斯-马尔可夫定理所总结的那样。换句话说，OLS估计具有最小的方差，它们是无偏的，参数是线性的，并且是一致的。这些性质可以通过使用先前的OLS假设在数学上得到证明。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="5aba" class="mu mi it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">置信区间</h1><p id="ad04" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">置信区间是包含具有某个预先指定的概率的真实总体参数的范围，称为实验的<strong class="lb iu"><em class="ly"/></strong><em class="ly"/>，它是利用样本结果和<strong class="lb iu"> <em class="ly">误差</em> </strong>得到的。</p><h2 id="5c25" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated"><strong class="ak">误差幅度</strong></h2><p id="f98c" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">误差幅度是样本结果之间的差异，基于如果使用整个人口的结果。</p><h2 id="b6bb" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">可信度</h2><p id="532a" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">置信水平描述了实验结果的确定性水平。例如，95%的置信水平意味着，如果一个人重复进行100次相同的实验，那么这100次实验中的95次会产生相似的结果。请注意，置信水平是在实验开始之前定义的，因为它会影响实验结束时的误差幅度。</p><h2 id="9b53" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">OLS估计的置信区间</h2><p id="05ae" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">如前所述，简单线性回归的OLS估计值、截距β0和斜率β1的估计值会受到采样不确定性的影响。但是，我们可以为这些参数构建CI的<em class="ly"> </em>，它将包含所有样本中95%的这些参数的真实值。也就是说，β的95%置信区间可以解释如下:</p><ul class=""><li id="bcda" class="pp pq it lb b lc ld lf lg li pr lm ps lq pt lu pu pv pw px bi translated">置信区间是假设检验不能被拒绝到5%水平的一组值。</li><li id="0760" class="pp pq it lb b lc py lf pz li qa lm qb lq qc lu pu pv pw px bi translated">置信区间有95%的机会包含β的真值。</li></ul><p id="4038" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">OLS估计值的95%置信区间可构建如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rd"><img src="../Images/37c7c5c1afde362538eb597d1d775711.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w-IL5VP-tXNLPuoG1BZVUQ.png"/></div></div></figure><p id="b5d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其基于参数估计、该估计的标准误差以及表示对应于5%拒绝规则的误差容限的值1.96。该值使用<a class="ae ky" href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Ffreakonometrics.hypotheses.org%2F9404&amp;psig=AOvVaw2IcJrhGrWbt9504WTCWBwW&amp;ust=1618940099743000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCOjR4v7rivACFQAAAAAdAAAAABAI" rel="noopener ugc nofollow" target="_blank">正态分布表</a>确定，这将在本文后面讨论。同时，下图说明了95% CI的概念:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi re"><img src="../Images/88c14e2699226ebd2e020153e5368627.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XtBhY43apW_xIyf23eOWow.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://en.wikipedia.org/wiki/Standard_deviation#/media/File:Standard_deviation_diagram.svg" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="edcf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，置信区间也取决于样本大小，因为它是使用基于样本大小的标准误差计算的。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><blockquote class="ns"><p id="a531" class="nt nu it bd nv nw nx ny nz oa ob lu dk translated">置信水平是在实验开始之前定义的，因为它会影响实验结束时的误差幅度有多大。</p></blockquote><h1 id="9fc2" class="mu mi it bd mv mw oc my mz na od nc nd jz oe ka nf kc of kd nh kf og kg nj nk bi translated">统计假设检验</h1><p id="65b6" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">检验统计学中的假设是检验实验或调查结果的一种方法，以确定这些结果有多大意义。基本上，一个是通过计算结果偶然发生的几率来测试获得的结果是否有效。如果是信，那么结果不可靠，实验也不可靠。假设检验是<strong class="lb iu"> <em class="ly">统计推断</em> </strong>的一部分。</p><h2 id="aba7" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">无效假设和替代假设</h2><p id="f7be" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">首先，你需要确定你想要测试的论题，然后你需要制定<strong class="lb iu"> <em class="ly">零假设</em> </strong>和<strong class="lb iu"> <em class="ly">替代假设</em>。</strong>测试可能有两种结果，根据统计结果，您可以拒绝或接受所述假设。根据经验，统计学家倾向于将假设的版本或表述放在需要拒绝的无效假设<em class="ly"/><em class="ly"/>下，而可接受的和期望的版本则放在替代假设<em class="ly">下。</em></p><h2 id="c1a3" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">统计显著性</h2><p id="0d79" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">让我们看看前面提到的例子，线性回归模型被用来调查企鹅的<em class="ly">鳍长</em>(自变量)是否对<em class="ly">(因变量</em>的体重有影响。我们可以用下面的统计表达式来建立这个模型:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rf"><img src="../Images/3387a9e5c1bd6cf765cc8ea03f8a479b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ukXC87ASnjoDPZMyvqStA.png"/></div></div></figure><p id="f884" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，一旦估计了系数的OLS估计，我们可以制定以下无效和替代假设来测试鳍状肢长度是否对身体质量具有<strong class="lb iu"> <em class="ly">统计显著性</em> </strong>影响:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rg"><img src="../Images/d080b0c627ab84d771dd7b4e16984394.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DVPqyel26EtGY__fwp_-rA.png"/></div></div></figure><p id="f921" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中H0和H1分别代表零假设和备择假设。拒绝零假设意味着<em class="ly">鳍状肢长度</em>增加一个单位会对<em class="ly">体重</em>产生直接影响。假设β1的参数估计值描述了自变量<em class="ly">脚蹼长度</em>对因变量<em class="ly">身体质量的影响。</em>这个假设可以重新表述如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rh"><img src="../Images/faa865b19653066ebaea3d5498776d04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6a0PPmy22ZnaefyUmdQ61w.png"/></div></div></figure><p id="8353" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中H0陈述β1的参数估计等于0，即<em class="ly">鳍长</em>对<em class="ly">体质量</em>的影响<strong class="lb iu"> <em class="ly">统计上不显著</em> </strong>而<em class="ly"> </em> H0陈述β1的参数估计不等于0，暗示<em class="ly">鳍长</em>对<em class="ly">体质量</em>的影响<strong class="lb iu"> <em class="ly">统计上显著</em> </strong> <em class="ly">。</em></p><h2 id="f95b" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">第一类和第二类错误</h2><p id="a68d" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">在进行统计假设检验时，需要考虑两种概念上的错误:第一类错误和第二类错误。当零假设被错误地拒绝时，出现类型I错误，而当零假设没有被错误地拒绝时，出现类型II错误。混淆矩阵有助于清楚地显示这两种错误的严重程度。</p><blockquote class="ns"><p id="731f" class="nt nu it bd nv nw nx ny nz oa ob lu dk translated">根据经验，统计学家倾向于将假设版本放在需要拒绝的<em class="ri"/><em class="ri"/><em class="ri"/>无效假设下，而可接受的和期望的版本放在<em class="ri">备选假设下。</em></p></blockquote><h1 id="205d" class="mu mi it bd mv mw oc my mz na od nc nd jz oe ka nf kc of kd nh kf og kg nj nk bi translated">统计测试</h1><p id="e6a6" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">一旦陈述了无效假设和替代假设，并定义了测试假设，下一步就是确定哪个统计测试是合适的，并计算<em class="ly"> </em> <strong class="lb iu"> <em class="ly">测试统计量</em> </strong>。通过将测试统计量与<strong class="lb iu"> <em class="ly">临界值</em>进行比较，可以确定是否拒绝空值。</strong>该比较显示观察到的测试统计值是否比定义的临界值更极端，它可能有两种结果:</p><ul class=""><li id="7264" class="pp pq it lb b lc ld lf lg li pr lm ps lq pt lu pu pv pw px bi translated">检验统计量比临界值更极端→可以拒绝零假设</li><li id="5b8d" class="pp pq it lb b lc py lf pz li qa lm qb lq qc lu pu pv pw px bi translated">检验统计量不像临界值那样极端→不能拒绝零假设</li></ul><p id="20c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">临界值基于预先指定的<strong class="lb iu"> <em class="ly">显著性水平</em> α </strong>(通常选择等于5%)和检验统计遵循的概率分布类型。临界值将该概率分布曲线下的面积分为<strong class="lb iu"> <em class="ly">拒绝区域</em> </strong>和<strong class="lb iu"> <em class="ly">非拒绝区域</em> </strong>。有许多统计测试用来测试各种假设。统计检验的例子有<a class="ae ky" href="https://en.wikipedia.org/wiki/Student%27s_t-test" rel="noopener ugc nofollow" target="_blank">学生t检验</a>、<a class="ae ky" href="https://en.wikipedia.org/wiki/F-test" rel="noopener ugc nofollow" target="_blank"> F检验</a>、<a class="ae ky" href="https://en.wikipedia.org/wiki/Chi-squared_test" rel="noopener ugc nofollow" target="_blank">卡方检验</a>、<a class="ae ky" href="https://www.stata.com/support/faqs/statistics/durbin-wu-hausman-test/" rel="noopener ugc nofollow" target="_blank">德宾-豪斯曼-吴内生性检验</a>、W <a class="ae ky" href="https://en.wikipedia.org/wiki/White_test#:~:text=In%20statistics%2C%20the%20White%20test,by%20Halbert%20White%20in%201980." rel="noopener ugc nofollow" target="_blank">海特异方差检验</a>。在本文中，我们将研究其中的两个统计测试。</p><blockquote class="ns"><p id="529a" class="nt nu it bd nv nw nx ny nz oa ob lu dk translated">当零假设被错误地拒绝时，出现类型I错误，而当零假设没有被错误地拒绝时，出现类型II错误。</p></blockquote><h2 id="cd9d" class="mh mi it bd mv oi qr dn mz ok qs dp nd li qt on nf lm qu op nh lq qv or nj os bi translated">“学生”t检验</h2><p id="df9d" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">最简单也是最受欢迎的统计测试之一是学生的t检验。其可用于测试各种假设，尤其是在处理主要关注领域是寻找单变量<strong class="lb iu"><em class="ly"/></strong><em class="ly">的统计显著效果的证据的假设时。</em>t检验的<strong class="lb iu"> </strong>检验统计量遵循<a class="ae ky" href="https://en.wikipedia.org/wiki/Student%27s_t-distribution" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="ly">学生的t分布</em> </strong> </a>，可以确定如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi rj"><img src="../Images/dea30078bcd99a1b341a1be943860de1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*3_nkUuVyzmrxwMd2lbOjTg.png"/></div></figure><p id="c6de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中，指定器中的h0是参数估计值的测试值。因此，t检验统计量等于参数估计值减去假设值除以系数估计值的标准误差。在早先陈述的假设中，我们想测试鳍状肢的长度是否对体重有统计学上的显著影响。该测试可以使用t-test来执行，并且在这种情况下，h0等于0，因为斜率估计是针对值0来测试的。</p><p id="aa84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">t检验有两个版本:一个<strong class="lb iu"> <em class="ly">双边t检验</em> </strong>和一个<strong class="lb iu"> <em class="ly">单边t检验</em> </strong>。你是需要前一个版本的测试还是后一个版本的测试，完全取决于你想要测试的假设。</p><p id="daab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">双边<strong class="lb iu"> </strong>或<em class="ly">双尾t检验</em> 可用于假设检验无效和替代假设下<em class="ly">等于</em>与<em class="ly">不等于</em>的关系，类似于下例:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rk"><img src="../Images/b7dc5995f73648d77cdba8e6564a6681.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zXzxU9raiJa-sjxCqIkSOw.png"/></div></div></figure><p id="bb34" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">双边t检验有两个拒绝区域<strong class="lb iu"><em class="ly"/></strong>，如下图所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rl"><img src="../Images/ca46e98ed0aabadcea7280edbbefea1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*otgnlBKy306KgrFUZxk0Og.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://www.geo.fu-berlin.de/en/v/soga/Basics-of-statistics/Hypothesis-Tests/Introduction-to-Hypothesis-Testing/Critical-Value-and-the-p-Value-Approach/index.html" rel="noopener ugc nofollow" target="_blank"> <em class="ri"> Hartmann，k .，Krois，j .，Waske，b .(2018):SOGA电子学习项目:统计和地理空间数据分析。柏林自由大学地球科学系</em> </a></p></figure><p id="d3cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个版本的t-检验中，如果计算的t-统计量太小或太大，则拒绝空值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rm"><img src="../Images/7d63cfe3bf7c5181e8d87de237fcca7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UgBXsYRPFEZymNPMKwdllQ.png"/></div></div></figure><p id="9049" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，根据样本大小和选定的显著性水平，将测试统计数据与临界值进行比较。为了确定分界点的精确值，可以使用双边t分布表。</p><p id="78b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当假设在检验零假设和备选假设下的<em class="ly">正/负</em>对<em class="ly">负/正</em>关系时，可以使用单侧或<strong class="lb iu"> <em class="ly">单尾t检验</em> </strong>，类似于下面的例子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/2962c24e85789d35c3d5f97b42fe9a57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uKChnDWApLtrCf8bq13o4w.png"/></div></div></figure><p id="1417" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">单侧t检验有一个<strong class="lb iu"> <em class="ly">单个</em> </strong> <em class="ly"> </em> <strong class="lb iu"> <em class="ly">拒绝区域</em> </strong>和依赖<strong class="lb iu"> </strong>在假设侧，拒绝区域要么在左侧，要么在右侧，如下图所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rn"><img src="../Images/0561ae3cb3e0a4d25bbddddc0a2ed0d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SVKBOOFtXIvYwL2gC9XEoQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://www.geo.fu-berlin.de/en/v/soga/Basics-of-statistics/Hypothesis-Tests/Introduction-to-Hypothesis-Testing/Critical-Value-and-the-p-Value-Approach/index.html" rel="noopener ugc nofollow" target="_blank"> <em class="ri"> Hartmann，k .，Krois，j .，Waske，b .(2018):SOGA电子学习项目:统计和地理空间数据分析。柏林自由大学地球科学系</em></a></p></figure><p id="153f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个版本的t检验中，如果计算出的t统计值小于/大于临界值，则拒绝空值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ro"><img src="../Images/2bbd24116f8ef68e2c9e24ff8c5c8e2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UvLof79AQigLFgxbKAvYgA.png"/></div></div></figure><h2 id="e375" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">f检验</h2><p id="85c2" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">f检验是另一种非常流行的统计检验，常用于检验假设检验<em class="ly"/><strong class="lb iu"><em class="ly">多个变量的联合统计显著性</em> </strong> <em class="ly">。</em>当您想要测试多个自变量是否对因变量有显著的统计影响时，就是这种情况。下面是一个可以使用f检验进行检验的统计假设示例:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rp"><img src="../Images/b21fafa03ae13e6c95eb1befd8e8a999.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MfuzKfYpbr2WaHBag3j49A.png"/></div></div></figure><p id="6683" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中零表示对应于这些系数的三个变量在统计上联合不显著，而备选项表示这三个变量在统计上联合显著。f检验的检验统计量遵循<a class="ae ky" href="https://en.wikipedia.org/wiki/F-distribution" rel="noopener ugc nofollow" target="_blank"> F分布</a>，可确定如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rq"><img src="../Images/8dd52ce0a63393ed1ef3d2aa2e3442b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wYdICJYeaH4-9h7yALqlBw.png"/></div></div></figure><p id="bbeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中，SSRunrestricted为<em class="ly"/><strong class="lb iu"><em class="ly"><strong class="lb iu"><em class="ly">受限</em> <em class="ly">模型</em> </strong>的残差平方和，该模型与从数据中排除了在空值<em class="ly"/>下声明为无关紧要的目标变量的模型相同，SSRunrestricted为<strong class="lb iu"><em class="ly"/><em class="ly">模型</em> </strong> <em class="ly"> </em>的残差平方和 q代表在空值下联合检验显著性的变量数量，N是样本大小，k是无限制模型中的变量总数。 运行OLS回归后，在参数估计值旁边提供SSR值，这同样适用于F统计。以下是MLR模型输出的示例，其中标记了SSR和F统计值。</em></strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rr"><img src="../Images/75ba2cadb5d53da36a50f4c884df6923.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5kTyYIc3LztrgM-oLKltwg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://www.uio.no/studier/emner/sv/oekonomi/ECON4150/v18/lecture7_ols_multiple_regressors_hypothesis_tests.pdf" rel="noopener ugc nofollow" target="_blank">股票和Whatson </a></p></figure><p id="e9d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">f检验有<strong class="lb iu">一个单一剔除区域</strong>，如下图所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi rs"><img src="../Images/eb4f13bb1e5ae619b8ff7cc142a76581.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*U3c2dRBPYCqtDqNGvk1BKA.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://www.statisticshowto.com/probability-and-statistics/f-statistic-value-test/" rel="noopener ugc nofollow" target="_blank"> <em class="ri">密歇根大学</em>T43】</a></p></figure><p id="7230" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果计算出的F-统计量大于临界值，则可以剔除空值，这表明独立变量共同具有统计显著性。拒绝规则可以表示如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rt"><img src="../Images/28f758c0a65e4ee5ef04b93799e68c5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2H4kGFurmQ8dsPhLByTloA.png"/></div></div></figure></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="c46b" class="mu mi it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">p值</h1><p id="026f" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">另一种快速确定是拒绝还是支持零假设的方法是使用<strong class="lb iu"> <em class="ly"> p值</em> </strong>。p值是零发生条件下的概率。换句话说，假设零假设为真，p值是观察到至少与检验统计量一样极端的结果的概率。p值越小，反对零假设的证据越强，表明它可以被拒绝。</p><p id="0792" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对<em class="ly"> p </em>值的解释取决于所选的显著性水平。通常，1%、5%或10%的显著性水平用于解释p值。因此，这些检验统计的p值可以用来检验相同的假设，而不是使用t-检验和F-检验。</p><p id="22b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图显示了具有两个独立变量的OLS回归的输出示例。在此表中，t检验的p值(测试<em class="ly"> class_size </em>变量参数估计的统计显著性)和F检验的p值(测试<em class="ly"> class_size、</em>和<em class="ly"> el_pct </em>变量参数估计的联合统计显著性)带有下划线。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ru"><img src="../Images/0d01ee97736e887433bd996022ee5007.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aJh-8BEvYnwid5jS7fDLHA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://www.uio.no/studier/emner/sv/oekonomi/ECON4150/v18/lecture7_ols_multiple_regressors_hypothesis_tests.pdf" rel="noopener ugc nofollow" target="_blank">股票和Whatson </a></p></figure><p id="9353" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对应于<em class="ly"> class_size </em>变量的p值为0.011，当将该值与1%或0.01、5%或0.05、10%或0.1的显著性水平进行比较时，可以得出以下结论:</p><ul class=""><li id="cf08" class="pp pq it lb b lc ld lf lg li pr lm ps lq pt lu pu pv pw px bi translated">0.011 &gt; 0.01 →在1%的显著性水平上不能拒绝t检验的空值</li><li id="cf58" class="pp pq it lb b lc py lf pz li qa lm qb lq qc lu pu pv pw px bi translated">0.011 &lt; 0.05 → Null of the t-test can be rejected at 5% significance level</li><li id="1022" class="pp pq it lb b lc py lf pz li qa lm qb lq qc lu pu pv pw px bi translated">0.011 &lt; 0.10 →Null of the t-test can be rejected at 10% significance level</li></ul><p id="d764" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">So, this p-value suggests that the coefficient of the <em class="ly"> class_size </em>变量在5%和10%的显著性水平上具有统计显著性。对应于f检验<em class="ly"> </em>的p值为0.0000，因为0小于所有三个截止值；0.01，0.05，0.10，我们可以得出结论，在所有三种情况下都可以拒绝f检验的零。这表明<em class="ly"> class_size </em>和<em class="ly"> el_pct </em>变量的系数在1%、5%和10%的显著性水平上共同具有统计显著性。</p><h2 id="a71f" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">p值的限制</h2><p id="11ef" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">虽然使用p值有很多好处，但它也有局限性<strong class="lb iu">。</strong>也就是说，p值取决于关联的大小和样本量。如果影响的幅度很小并且在统计上不显著，p值可能仍然显示出<strong class="lb iu"> <em class="ly">显著影响</em> </strong> <em class="ly"> </em>，因为大样本量很大。也可能出现相反的情况，影响可能很大，但如果样本量很小，则无法满足p &lt; 0.01、0.05或0.10的标准。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="2823" class="mu mi it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">推断统计学</h1><p id="a622" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">推断统计学使用样本数据对样本数据来源的总体做出合理的判断。它用于调查样本中变量之间的关系，并预测这些变量将如何与更大的总体相关。</p><p id="a950" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="ly">大数定律(LLN) </em> </strong>和<strong class="lb iu"> <em class="ly">中心极限定理(CLM) </em> </strong>在推断统计学中都有重要作用，因为它们表明，当数据足够大时，无论原始人口分布是什么形状，实验结果都成立。收集的数据越多，统计推断就变得越准确，因此，产生的参数估计就越准确。</p><h2 id="c1de" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated"><strong class="ak">大数定律(LLN) </strong></h2><p id="d15e" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">假设<strong class="lb iu"> X1，X2，。。。，Xn </strong>都是具有相同基础分布的独立随机变量，也称为独立同分布或i.i.d .，其中所有X都具有相同的均值<strong class="lb iu"> μ </strong>和标准差<strong class="lb iu"> σ </strong>。随着样本量的增加，所有X的平均值等于均值μ的概率等于1。大数定律可以总结如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rv"><img src="../Images/36f7e0fe1d8a288efd7d3c226c68bbcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*guDCKe5lIntrCicvX1WeBQ.png"/></div></div></figure><h2 id="4981" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">中心极限定理(CLM)</h2><p id="56a8" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">假设<strong class="lb iu"> X1，X2，。。。，Xn </strong>都是具有相同基础分布的独立随机变量，也称为独立同分布或i.i.d .，其中所有X都具有相同的均值<strong class="lb iu"> μ </strong>和标准差<strong class="lb iu"> σ </strong>。随着样本量的增长，X <strong class="lb iu"> <em class="ly">的概率分布收敛于均值<strong class="lb iu"> μ </strong>和方差<strong class="lb iu"> σ- </strong>平方的正态分布</em> </strong>。中心极限定理可以概括如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rw"><img src="../Images/e7fe092d5b6a2e5f033d6255f78e1990.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FCDUcznU-VRRdctstA1WJA.png"/></div></div></figure><p id="de15" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">换句话说，当您有一个具有均值μ和标准差σ的总体，并且您从该总体中选取足够大的随机样本进行替换时，样本均值的分布将近似为正态分布。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="4fcb" class="mu mi it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated"><strong class="ak">降维技术</strong></h1><p id="3896" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">降维是将数据从一个<strong class="lb iu"> <em class="ly">高维空间</em> </strong>转换到一个<strong class="lb iu"> <em class="ly">低维空间</em> </strong>，使得数据的这种低维表示仍然尽可能地包含原始数据的有意义的属性。</p><p id="b46a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着大数据越来越受欢迎，对这些降维技术(减少不必要的数据和特征的数量)的需求也在增加。流行的降维技术的例子有<a class="ae ky" href="https://builtin.com/data-science/step-step-explanation-principal-component-analysis" rel="noopener ugc nofollow" target="_blank">主成分分析</a>、<a class="ae ky" href="https://en.wikipedia.org/wiki/Factor_analysis" rel="noopener ugc nofollow" target="_blank">因子分析</a>、<a class="ae ky" href="https://en.wikipedia.org/wiki/Canonical_correlation" rel="noopener ugc nofollow" target="_blank">典型相关</a>、<a class="ae ky" rel="noopener" target="_blank" href="/understanding-random-forest-58381e0602d2">随机森林</a>。</p><h2 id="d403" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated"><strong class="ak">主成分分析</strong></h2><p id="1c02" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">主成分分析(PCA)是一种降维技术，通常用于降低大型数据集的维数，方法是将一组大型变量转换为一个较小的集合，该集合仍然包含原始大型数据集中的大部分信息或变化。</p><p id="0d96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设我们有一个有p个变量的数据X；X1，X2，…、Xp带<strong class="lb iu"> <em class="ly">特征向量</em> </strong> e1、…、ep、<strong class="lb iu"> <em class="ly">特征值</em> </strong> λ1、…、λp特征值表示总方差中某一特定数据字段所解释的方差PCA背后的思想是创建新的(独立的)变量，称为主成分，是现有变量的线性组合。第i <em class="ly">个</em>主分量可以表示如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rx"><img src="../Images/7c38d61662af7df63410a8ac10c4cf9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jkvmpsADsuGEP3AdhnvZ5Q.png"/></div></div></figure><p id="14b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后使用<strong class="lb iu">肘规则</strong>或<a class="ae ky" href="https://docs.displayr.com/wiki/Kaiser_Rule" rel="noopener ugc nofollow" target="_blank">或<strong class="lb iu">凯泽规则</strong>或</a>就可以确定最优概括数据的主成分个数而不会丢失太多信息。还要看<strong class="lb iu"><em class="ly">【PRTV】</em></strong>每一个主成分所解释的总变异的比例来决定是包含还是排除它是有益的。第i <em class="ly">个</em>主分量的PRTV可以使用特征值计算如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ry"><img src="../Images/b2ae7144e60f8ebf2eba7287a75e5339.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TWsWjfWkcGuc120gRWov0g.png"/></div></div></figure><h2 id="178f" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated">肘尺</h2><p id="4c21" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">肘规则或肘方法是一种启发式方法，用于从PCA结果中确定最佳主成分的数量。这种方法背后的思想是将所解释的变化绘制为组件数量的函数<em class="ly">，并选择曲线的拐点作为最佳主组件的数量。以下是此类散点图的示例，其中PRTV (Y轴)绘制在主成分数(X轴)上。肘对应于X轴值2，这表明最佳主成分的数量是2。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi rz"><img src="../Images/1d87a7bb5174bbceb05514a8493e6df7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*cLCESS2u2ZIsQbPBd7Ljlg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://raw.githubusercontent.com/TatevKaren/Multivariate-Statistics/main/Elbow_rule_%25varc_explained.png" rel="noopener ugc nofollow" target="_blank">多元统计Github </a></p></figure><h2 id="65f8" class="mh mi it bd mv oi oj dn mz ok ol dp nd li om on nf lm oo op nh lq oq or nj os bi translated"><strong class="ak">因子分析</strong></h2><p id="d191" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">因子分析是另一种降维的统计方法。这是最常用的相互依赖技术之一，当相关变量集显示系统的相互依赖时使用，目标是找出产生共性的潜在因素。假设我们有一个有p个变量的数据X；X1，X2，…，Xp。FA模型可以表示如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi sa"><img src="../Images/1ecbabe06fe6ca61dd23776001651515.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2TgqED9J7xAoi8AwuaIUOA.png"/></div></div></figure><p id="a859" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中X是p个变量和N个观察值的[p x N]矩阵，是[p x N]总体均值矩阵，A是[p x k]公共<strong class="lb iu"> <em class="ly">因子加载矩阵</em> </strong>，F [k x N]是公共因子矩阵，u [pxN]是特定因子矩阵。因此，换句话说，因子模型是一系列的多元回归，从不可观察的公共因子fi的值预测每个变量Xi:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi sb"><img src="../Images/2bcb27214fcb107313ee08f36c8c9070.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qwKQpdc-cs-4CovpvzJNcg.png"/></div></div></figure><p id="d12a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个变量都有k个自己的公因子，这些公因子通过因子加载矩阵与单个观察值相关联，如下:在因子分析中，计算<strong class="lb iu"> <em class="ly">因子</em> </strong>以使<strong class="lb iu"> <em class="ly">最大化</em> <em class="ly">组间方差</em> </strong>而<strong class="lb iu"> <em class="ly">最小化组内方差</em> </strong> <em class="ly"> e </em>。它们之所以是因素，是因为它们将潜在的变量组合在一起。与PCA不同，FA中的数据需要归一化，因为FA假设数据集遵循正态分布。</p><h1 id="336e" class="mu mi it bd mv mw oc my mz na od nc nd jz pk ka nf kc pl kd nh kf pm kg nj nk bi translated">额外资源</h1><div class="sc sd gp gr se sf"><a href="https://github.com/TatevKaren" rel="noopener  ugc nofollow" target="_blank"><div class="sg ab fo"><div class="sh ab si cl cj sj"><h2 class="bd iu gy z fp sk fr fs sl fu fw is bi translated">TatevKaren —概述</h2><div class="sm l"><h3 class="bd b gy z fp sk fr fs sl fu fw dk translated">我是Tatev Karen Aslanyan，数据科学家和定量分析师，在数学、统计…</h3></div><div class="sn l"><p class="bd b dl z fp sk fr fs sl fu fw dk translated">github.com</p></div></div><div class="so l"><div class="sp l sq sr ss so st ks sf"/></div></div></a></div><p id="c885" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> Github仓库进行A/B测试:</strong> <a class="ae ky" href="https://github.com/TatevKaren/data-science-popular-algorithms/tree/main/AB_Testing" rel="noopener ugc nofollow" target="_blank">此处</a></p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="59cd" class="mu mi it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">如果你喜欢这篇文章，这里有一些你可能喜欢的其他文章:</h1><div class="sc sd gp gr se sf"><a href="https://tatev-aslanyan.medium.com/bias-variance-trade-off-in-machine-learning-7f885355e847" rel="noopener follow" target="_blank"><div class="sg ab fo"><div class="sh ab si cl cj sj"><h2 class="bd iu gy z fp sk fr fs sl fu fw is bi translated">机器学习中的偏差-方差权衡</h2><div class="sm l"><h3 class="bd b gy z fp sk fr fs sl fu fw dk translated">机器学习和统计模型中偏差-方差权衡的介绍</h3></div><div class="sn l"><p class="bd b dl z fp sk fr fs sl fu fw dk translated">tatev-aslanyan.medium.com</p></div></div><div class="so l"><div class="su l sq sr ss so st ks sf"/></div></div></a></div><div class="sc sd gp gr se sf"><a href="https://tatev-aslanyan.medium.com/data-sampling-methods-in-python-a4400628ea1b" rel="noopener follow" target="_blank"><div class="sg ab fo"><div class="sh ab si cl cj sj"><h2 class="bd iu gy z fp sk fr fs sl fu fw is bi translated">Python中的数据采样方法</h2><div class="sm l"><h3 class="bd b gy z fp sk fr fs sl fu fw dk translated">使用不同的数据采样技术创建Python中的随机样本的现成代码</h3></div><div class="sn l"><p class="bd b dl z fp sk fr fs sl fu fw dk translated">tatev-aslanyan.medium.com</p></div></div><div class="so l"><div class="sv l sq sr ss so st ks sf"/></div></div></a></div><div class="sc sd gp gr se sf"><a rel="noopener follow" target="_blank" href="/simple-and-complet-guide-to-a-b-testing-c34154d0ce5a"><div class="sg ab fo"><div class="sh ab si cl cj sj"><h2 class="bd iu gy z fp sk fr fs sl fu fw is bi translated">简单完整的A/B测试指南</h2><div class="sm l"><h3 class="bd b gy z fp sk fr fs sl fu fw dk translated">为您的数据科学实验进行端到端A/B测试，面向非技术和技术专家，提供示例和…</h3></div><div class="sn l"><p class="bd b dl z fp sk fr fs sl fu fw dk translated">towardsdatascience.com</p></div></div><div class="so l"><div class="sw l sq sr ss so st ks sf"/></div></div></a></div><div class="sc sd gp gr se sf"><a rel="noopener follow" target="_blank" href="/monte-carlo-simulation-and-variants-with-python-43e3e7c59e1f"><div class="sg ab fo"><div class="sh ab si cl cj sj"><h2 class="bd iu gy z fp sk fr fs sl fu fw is bi translated">蒙特卡罗模拟和Python变种</h2><div class="sm l"><h3 class="bd b gy z fp sk fr fs sl fu fw dk translated">蒙特卡洛模拟指南，必须了解Python实现的统计抽样技术</h3></div><div class="sn l"><p class="bd b dl z fp sk fr fs sl fu fw dk translated">towardsdatascience.com</p></div></div><div class="so l"><div class="sx l sq sr ss so st ks sf"/></div></div></a></div><div class="sc sd gp gr se sf"><a href="https://medium.com/analytics-vidhya/pyspark-cheat-sheet-big-data-analytics-161a8e1f6185" rel="noopener follow" target="_blank"><div class="sg ab fo"><div class="sh ab si cl cj sj"><h2 class="bd iu gy z fp sk fr fs sl fu fw is bi translated">PySpark备忘单:大数据分析</h2><div class="sm l"><h3 class="bd b gy z fp sk fr fs sl fu fw dk translated">这里是基本PySpark命令和函数的备忘单。在PySpark中开始您的大数据分析。</h3></div><div class="sn l"><p class="bd b dl z fp sk fr fs sl fu fw dk translated">medium.com</p></div></div><div class="so l"><div class="sy l sq sr ss so st ks sf"/></div></div></a></div><div class="sc sd gp gr se sf"><a href="https://medium.com/mlearning-ai/using-customer-and-product-features-in-recommender-systems-2734258873cf" rel="noopener follow" target="_blank"><div class="sg ab fo"><div class="sh ab si cl cj sj"><h2 class="bd iu gy z fp sk fr fs sl fu fw is bi translated">在推荐系统中使用客户和产品特征</h2><div class="sm l"><h3 class="bd b gy z fp sk fr fs sl fu fw dk translated">提出了一种基于矩阵分解的向推荐系统添加额外用户和项目特征的方法</h3></div><div class="sn l"><p class="bd b dl z fp sk fr fs sl fu fw dk translated">medium.com</p></div></div><div class="so l"><div class="sz l sq sr ss so st ks sf"/></div></div></a></div></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="9449" class="mu mi it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">调查:完美的数据科学课程对你来说是什么样的？</h1><p id="5649" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated"><em class="ly">你是否也注意到，作为数据科学家，我们很难浏览多个博客和课程，即使在这种情况下，也没有一个地方涵盖所有主题。所以，我愿意为您打造这个</em> <strong class="lb iu"> <em class="ly">【一站式数据科学店】</em> </strong> <em class="ly">课程。</em></p><p id="5809" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ly">为了为您定制本课程，我很想了解您的意见，以了解“完美的数据科学课程对您来说是什么样的？”。</em></p><p id="0d2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ly">因此，我想请您回答几个问题来完成这个</em> <a class="ae ky" href="https://docs.google.com/forms/d/e/1FAIpQLSeRxugd3ACiD1wsC8H3y8Y29L4sk2fdysw1lxzGNedL5sPqUw/viewform" rel="noopener ugc nofollow" target="_blank"> <em class="ly"> </em> <strong class="lb iu"> <em class="ly">简短调查</em></strong></a><strong class="lb iu"><em class="ly"/></strong><em class="ly">，一旦课程开始，您将是第一个收到通知的人。也请</em> <a class="ae ky" href="https://docs.google.com/forms/d/e/1FAIpQLSeRxugd3ACiD1wsC8H3y8Y29L4sk2fdysw1lxzGNedL5sPqUw/viewform" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="ly">与你认为会对此课程感兴趣的人分享</em> </strong> </a> <em class="ly">？</em></p><p id="9c0b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">预先感谢您，非常感谢您的参与！</p><p id="2632" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="ly">为调查链接:</em> </strong> <a class="ae ky" href="https://docs.google.com/forms/d/e/1FAIpQLSeRxugd3ACiD1wsC8H3y8Y29L4sk2fdysw1lxzGNedL5sPqUw/viewform" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="ly">点击此处</em> </strong> </a></p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="93f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="ly">感谢阅读</em> </strong></p><p id="2549" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ly">我鼓励你</em> <a class="ae ky" href="https://tatev-aslanyan.medium.com/membership" rel="noopener"> <strong class="lb iu"> <em class="ly">加入Medium today </em> </strong> </a> <em class="ly">以拥有</em> <strong class="lb iu"> <em class="ly"> </em> </strong> <em class="ly">完整访问所有跨媒体发布的伟大锁定内容，并在我的feed上发布关于各种数据科学、机器学习和深度学习主题的内容。</em></p><p id="7c21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ly">关注我</em> <a class="ae ky" href="https://medium.com/@tatev-aslanyan" rel="noopener"> <strong class="lb iu"> <em class="ly">中</em></strong></a><strong class="lb iu"><em class="ly"/></strong><em class="ly">阅读更多关于各种数据科学和数据分析主题的文章。更多机器学习的动手应用，数学和统计概念查看我的</em><a class="ae ky" href="https://github.com/TatevKaren" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="ly">Github</em></strong></a><strong class="lb iu"><em class="ly"/></strong><em class="ly">账号。<br/>我欢迎反馈，可以联系</em><a class="ae ky" href="https://www.linkedin.com/in/tatev-karen-aslanyan/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="ly">LinkedIn</em></strong></a><em class="ly">。</em></p><p id="7bb9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="ly">快乐学习！</em> </strong></p></div></div>    
</body>
</html>