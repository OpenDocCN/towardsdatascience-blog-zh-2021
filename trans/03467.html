<html>
<head>
<title>Exploring Thai Food with Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用数据探索泰国菜</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/exploring-thai-food-with-data-fae0193851be?source=collection_archive---------27-----------------------#2021-03-19">https://towardsdatascience.com/exploring-thai-food-with-data-fae0193851be?source=collection_archive---------27-----------------------#2021-03-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d3c3" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用R和Python的端到端探索性数据项目</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1c5a601fea4c06c6d0a482be179afe88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CbhGXdj4-NfuLkMgGq0weg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="72ed" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">概观</h1><p id="c8eb" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">“我们点泰国菜吧。”</p><p id="af9b" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">“太好了，你的拿手好菜是什么？”</p><p id="178b" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">"泰式炒面"</p><p id="2e08" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">这困扰了我多年，也是这个项目的起源。</p><p id="b285" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">人们需要知道除了泰式炒面，他们还有其他选择。泰式炒面是53道独立菜肴之一，在那里停下来可能会错过至少201道共享泰式菜肴(来源:<a class="ae mo" href="https://en.wikipedia.org/wiki/List_of_Thai_dishes" rel="noopener ugc nofollow" target="_blank">维基百科</a>)。</p><p id="4791" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">这个项目是一个通过从维基百科中抓取表格来建立泰国菜数据集的机会。我们将使用Python进行web抓取，使用R进行可视化。网页抓取用<code class="fe mp mq mr ms b">Beautiful Soup</code> (Python)完成，用<code class="fe mp mq mr ms b">dplyr</code>进一步预处理，用<code class="fe mp mq mr ms b">ggplot2</code>可视化。</p><p id="ffdc" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">此外，我们将使用R中的<code class="fe mp mq mr ms b">tidytext</code>包来探索泰国菜的名称(英文),看看我们是否可以从文本数据中了解一些有趣的东西。</p><p id="8c3b" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">最后有机会做一个开源<a class="ae mo" href="https://github.com/holtzy/R-graph-gallery/pull/34" rel="noopener ugc nofollow" target="_blank">贡献</a>。</p><p id="121b" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">项目回购这里是<a class="ae mo" href="https://github.com/PaulApivat/thai_dishes" rel="noopener ugc nofollow" target="_blank">这里是</a>。</p><h1 id="d866" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">探索性问题</h1><p id="b39d" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">这种分析的目的是提出问题。</p><p id="8827" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">因为<strong class="lp ir">探索性分析</strong>是迭代的，所以这些问题是在操纵和可视化数据的过程中产生的。我们可以用这些问题来组织文章的其余部分:</p><ol class=""><li id="c748" class="mt mu iq lp b lq mj lt mk lw mv ma mw me mx mi my mz na nb bi translated">我们如何组织泰国菜？</li><li id="8883" class="mt mu iq lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">组织不同菜肴的最好方法是什么？</li><li id="1434" class="mt mu iq lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">哪种原材料最受欢迎？</li><li id="d618" class="mt mu iq lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">哪些原材料最重要？</li><li id="85cf" class="mt mu iq lp b lq nc lt nd lw ne ma nf me ng mi my mz na nb bi translated">你能仅仅从菜名中了解泰国菜吗？</li></ol><h1 id="e8fe" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">网页抓取</h1><p id="acf2" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><strong class="lp ir">注意</strong>:维基百科向感兴趣的用户提供所有可用内容的免费副本。他们的<a class="ae mo" href="https://en.wikipedia.org/wiki/Wikipedia:Database_download" rel="noopener ugc nofollow" target="_blank">数据库下载</a>可以用于个人使用，离线使用或者数据库查询。我们在这里搜集的所有文本内容都是在知识共享署名-共享3.0 (CC-BY-SA)下获得多项许可的。虽然我们可以在技术上查询数据，但我们在这里是出于教育目的。为了确保<strong class="lp ir">不会</strong>产生繁重的服务器工作负载，我们将会话超时设置为<strong class="lp ir"> 10秒</strong>(参见下面的代码)。另见他们关于通过<a class="ae mo" href="https://en.wikipedia.org/robots.txt" rel="noopener ugc nofollow" target="_blank">机器人</a>抓取网页的通知。</p><p id="17ee" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">我们刮了300道泰国菜。每道菜，我们都有:</p><ul class=""><li id="069d" class="mt mu iq lp b lq mj lt mk lw mv ma mw me mx mi nh mz na nb bi translated">泰语名称</li><li id="52f6" class="mt mu iq lp b lq nc lt nd lw ne ma nf me ng mi nh mz na nb bi translated">泰国文字</li><li id="c842" class="mt mu iq lp b lq nc lt nd lw ne ma nf me ng mi nh mz na nb bi translated">英文名</li><li id="cea7" class="mt mu iq lp b lq nc lt nd lw ne ma nf me ng mi nh mz na nb bi translated">地区</li><li id="6d17" class="mt mu iq lp b lq nc lt nd lw ne ma nf me ng mi nh mz na nb bi translated">描述</li></ul><p id="7f11" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">首先，我们将使用以下Python库/模块:</p><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="dfd1" class="nm kw iq ms b gy nn no l np nq">import requests<br/>from bs4 import BeautifulSoup<br/>import urllib.request<br/>import urllib.parse<br/>import urllib.error<br/>import ssl<br/>import pandas as pd</span><span id="a990" class="nm kw iq ms b gy nr no l np nq"># To avoid overloading Wikipedia servers, we set the timeout to 10 seconds</span><span id="a9b3" class="nm kw iq ms b gy nr no l np nq">url = "https://en.wikipedia.org/wiki/List_of_Thai_dishes"<br/>s = requests.Session()<br/>response = s.get(url, timeout=10)<br/></span><span id="f098" class="nm kw iq ms b gy nr no l np nq">ctx = ssl.create_default_context()<br/>ctx.check_hostname = False<br/>ctx.verify_mode = ssl.CERT_NONE</span><span id="8570" class="nm kw iq ms b gy nr no l np nq">html = urllib.request.urlopen(url, context=ctx).read()<br/>soup = BeautifulSoup(html, 'html.parser')<br/>soup.title.string</span></pre><p id="f392" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">我们将使用<code class="fe mp mq mr ms b">requests</code>向我们需要的维基百科url发送一个HTTP请求。我们将使用“安全套接字层”(SSL)访问网络套接字。然后我们将读入html数据，用<strong class="lp ir">美汤</strong>解析它。</p><p id="8ef8" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">在使用<strong class="lp ir">美汤</strong>之前，我们想了解我们要在浏览器上<strong class="lp ir"> inspect元素</strong>下刮取的页面(和表格)的结构(注:我用的是Chrome)。我们可以看到，我们需要标签<code class="fe mp mq mr ms b">table</code>，以及维基可排序的标签<code class="fe mp mq mr ms b">class</code>。</p><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="991c" class="nm kw iq ms b gy nn no l np nq">all_tables = soup.findAll('table', {"class": "wikitable sortable"})</span></pre></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/9d5419ace520520af10345d0f5281a55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*C_Oji0kW7LDVsLwF.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="ee03" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">我们将从<strong class="lp ir">美汤</strong>中使用的主函数是<code class="fe mp mq mr ms b">findAll()</code>，三个参数是<code class="fe mp mq mr ms b">th</code>(HTML表格中的表头单元格)、<code class="fe mp mq mr ms b">tr</code>(HTML表格中的行)和<code class="fe mp mq mr ms b">td</code>(标准数据单元格)。</p><p id="094a" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">首先，我们将表格标题保存在一个列表中，我们将在创建一个空的<code class="fe mp mq mr ms b">dictionary</code>来存储我们需要的数据时使用它。</p><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="4ade" class="nm kw iq ms b gy nn no l np nq">header = [item.text.rstrip() for item in all_tables[0].findAll('th')]</span><span id="c176" class="nm kw iq ms b gy nr no l np nq">table = dict([(x, 0) for x in header])</span></pre><p id="d0de" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">最初，我们想要抓取一个表，知道我们需要对所有16个表重复这个过程。因此我们将使用一个<em class="oa">嵌套循环</em>。因为所有的表都有6列，所以我们想要创建6个空列表。</p><p id="d712" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">我们将遍历所有表格行<code class="fe mp mq mr ms b">tr</code>并检查6个单元格(我们应该有6列)，然后我们将<em class="oa">将数据追加到我们创建的每个空列表中。</em></p><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="a4d7" class="nm kw iq ms b gy nn no l np nq"># loop through all 16 tables<br/>a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]</span><span id="7ece" class="nm kw iq ms b gy nr no l np nq"># 6 empty list (for 6 columns) to store data<br/>a1 = []<br/>a2 = []<br/>a3 = []<br/>a4 = []<br/>a5 = []<br/>a6 = []</span><span id="89b9" class="nm kw iq ms b gy nr no l np nq"># nested loop for looping through all 16 tables, then all tables individually<br/>for i in a:<br/>    for row in all_tables[i].findAll('tr'):<br/>        cells = row.findAll('td')<br/>        if len(cells) == 6:<br/>            a1.append([string for string in cells[0].strings])<br/>            a2.append(cells[1].find(text=True))<br/>            a3.append(cells[2].find(text=True))<br/>            a4.append(cells[3].find(text=True))<br/>            a5.append(cells[4].find(text=True))<br/>            a6.append([string for string in cells[5].strings])</span></pre><p id="7ad0" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">你会注意到<code class="fe mp mq mr ms b">a1</code>和<code class="fe mp mq mr ms b">a6</code>的代码略有不同。回想起来，我发现<code class="fe mp mq mr ms b">cells[0].find(text=True)</code>没有<strong class="lp ir">而</strong>产生某些文本，特别是如果它们是链接的话，因此做了一点小小的调整。</p><p id="1ec1" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">字符串标签返回一个<code class="fe mp mq mr ms b">NavigableString</code>类型对象，而文本返回一个<code class="fe mp mq mr ms b">unicode</code>对象(参见<a class="ae mo" href="https://stackoverflow.com/questions/25327693/difference-between-string-and-text-beautifulsoup" rel="noopener ugc nofollow" target="_blank">堆栈溢出</a>解释)。</p><p id="cd97" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">在我们丢弃数据之后，我们需要在转换到<code class="fe mp mq mr ms b">data frame</code>之前将数据存储在<code class="fe mp mq mr ms b">dictionary</code>中:</p><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="db67" class="nm kw iq ms b gy nn no l np nq"># create dictionary<br/>table = dict([(x, 0) for x in header])</span><span id="d0d9" class="nm kw iq ms b gy nr no l np nq"># append dictionary with corresponding data list<br/>table['Thai name'] = a1<br/>table['Thai script'] = a2<br/>table['English name'] = a3<br/>table['Image'] = a4<br/>table['Region'] = a5<br/>table['Description'] = a6</span><span id="c74c" class="nm kw iq ms b gy nr no l np nq"># turn dict into dataframe<br/>df_table = pd.DataFrame(table)</span></pre><p id="161f" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">对于<code class="fe mp mq mr ms b">a1</code>和<code class="fe mp mq mr ms b">a6</code>，我们需要做一个额外的步骤将字符串连接在一起，所以我额外创建了两个对应的列，<code class="fe mp mq mr ms b">Thai name 2</code>和<code class="fe mp mq mr ms b">Description2</code>:</p><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="5512" class="nm kw iq ms b gy nn no l np nq"># Need to Flatten Two Columns: 'Thai name' and 'Description'<br/># Create two new columns<br/>df_table['Thai name 2'] = ""<br/>df_table['Description2'] = ""</span><span id="8565" class="nm kw iq ms b gy nr no l np nq"># join all words in the list for each of 328 rows and set to thai_dishes['Description2'] column<br/># automatically flatten the list<br/>df_table['Description2'] = [<br/>    ' '.join(cell) for cell in df_table['Description']]</span><span id="f582" class="nm kw iq ms b gy nr no l np nq">df_table['Thai name 2'] = [<br/>    ' '.join(cell) for cell in df_table['Thai name']]</span></pre><p id="f952" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">在我们废弃了所有的数据并从<code class="fe mp mq mr ms b">dictionary</code>转换到<code class="fe mp mq mr ms b">data frame</code>之后，我们将向csv写入，准备在R中进行数据清理(<strong class="lp ir">注</strong>:我将CSV保存为thai _ dishes.csv，但你可以选择不同的名称)。</p><h1 id="6e54" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">数据清理</h1><p id="c757" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">数据清理通常是非线性的。</p><p id="907f" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">我们将操纵数据进行探索，了解<em class="oa">关于</em>数据的信息，并发现某些东西需要清理，或者在某些情况下，需要返回Python重新清理。由于在探测和清理过程中发现<strong class="lp ir">缺失数据</strong>，列<code class="fe mp mq mr ms b">a1</code>和<code class="fe mp mq mr ms b">a6</code>与其他列的刮除方式不同。</p><p id="a024" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">对于某些链接，使用<code class="fe mp mq mr ms b">.find(text=True)</code>没有达到预期的效果，所以做了一点小小的调整。</p><p id="f5ed" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">对于本文来说，<code class="fe mp mq mr ms b">R</code>是清理数据的首选工具。</p><p id="6a33" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">以下是其他数据清理任务:</p><ul class=""><li id="4aff" class="mt mu iq lp b lq mj lt mk lw mv ma mw me mx mi nh mz na nb bi translated">更改列名(蛇形)</li></ul><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="53da" class="nm kw iq ms b gy nn no l np nq"># read data<br/>df &lt;- read_csv("thai_dishes.csv")</span><span id="cea8" class="nm kw iq ms b gy nr no l np nq"># change column name<br/>df &lt;- df %&gt;%<br/>    rename(<br/>        Thai_name = `Thai name`,<br/>        Thai_name_2 = `Thai name 2`,<br/>        Thai_script = `Thai script`,<br/>        English_name = `English name`<br/>    )</span></pre><ul class=""><li id="b5be" class="mt mu iq lp b lq mj lt mk lw mv ma mw me mx mi nh mz na nb bi translated">删除换行符转义序列(\n)</li></ul><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="6bde" class="nm kw iq ms b gy nn no l np nq"># remove  \n from all columns ----<br/>df$Thai_name &lt;- gsub("[\n]", "", df$Thai_name)<br/>df$Thai_name_2 &lt;- gsub("[\n]", "", df$Thai_name_2)<br/>df$Thai_script &lt;- gsub("[\n]", "", df$Thai_script)<br/>df$English_name &lt;- gsub("[\n]", "", df$English_name)<br/>df$Image &lt;- gsub("[\n]", "", df$Image)<br/>df$Region &lt;- gsub("[\n]", "", df$Region)<br/>df$Description &lt;- gsub("[\n]", "", df$Description)<br/>df$Description2 &lt;- gsub("[\n]", "", df$Description2)</span></pre><ul class=""><li id="5cca" class="mt mu iq lp b lq mj lt mk lw mv ma mw me mx mi nh mz na nb bi translated">添加/变更新列(主要分组，次要分组):</li></ul><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="eba1" class="nm kw iq ms b gy nn no l np nq"># Add Major AND Minor Groupings ----<br/>df &lt;- df %&gt;%<br/>    mutate(<br/>        major_grouping = as.character(NA),<br/>        minor_grouping = as.character(NA)<br/>        )</span></pre><ul class=""><li id="b211" class="mt mu iq lp b lq mj lt mk lw mv ma mw me mx mi nh mz na nb bi translated">编辑Thai_name列中缺少数据的行:26，110，157，234–238，240，241，246</li></ul><p id="f155" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir">注意</strong>:这只在第一轮时需要，在我刮的方式<code class="fe mp mq mr ms b">a1</code>和<code class="fe mp mq mr ms b">a6</code>改变后，这一步<strong class="lp ir">不再需要</strong>:</p><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="88ef" class="nm kw iq ms b gy nn no l np nq"># If necessary; may not need to do this after scraping a1 and a6 - see above<br/># Edit Rows for missing Thai_name<br/>df[26,]$Thai_name &lt;- "Khanom chin nam ngiao"<br/>df[110,]$Thai_name &lt;- "Lap Lanna"<br/>df[157,]$Thai_name &lt;- "Kai phat khing"<br/>df[234,]$Thai_name &lt;- "Nam chim chaeo"<br/>df[235,]$Thai_name &lt;- "Nam chim kai"<br/>df[236,]$Thai_name &lt;- "Nam chim paesa"<br/>df[237,]$Thai_name &lt;- "Nam chim sate"<br/>df[238,]$Thai_name &lt;- "Nam phrik i-ke"<br/>df[240,]$Thai_name &lt;- "Nam phrik kha"<br/>df[241,]$Thai_name &lt;- "Nam phrik khaep mu"<br/>df[246,]$Thai_name &lt;- "Nam phrik pla chi"</span></pre><ul class=""><li id="ab7e" class="mt mu iq lp b lq mj lt mk lw mv ma mw me mx mi nh mz na nb bi translated">保存到“edit _ thai _ dishes.csv”</li></ul><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="1a86" class="nm kw iq ms b gy nn no l np nq"># Write new csv to save edits made to data frame<br/>write_csv(df, "edit_thai_dishes.csv")</span></pre><h1 id="e948" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">数据可视化</h1><p id="896b" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">有几种方法可以将数据可视化。因为我们想要传达泰国菜的多样性，除了泰国菜之外，我们想要一个包含许多选项的可视化。</p><p id="f93a" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">我选择了<strong class="lp ir">树状图</strong>。该图假设数据中存在层次结构，这适合我们的项目，因为我们可以按分组和子分组来组织菜肴。</p><h2 id="314f" class="nm kw iq bd kx ob oc dn lb od oe dp lf lw of og lh ma oh oi lj me oj ok ll ol bi translated">我们如何组织泰国菜？</h2><p id="16b0" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我们首先区分<strong class="lp ir">个人</strong>和<strong class="lp ir">共享</strong>菜肴，以表明泰式炒面根本不是最好的<em class="oa">个人</em>菜肴。事实上，更多的菜肴归入<strong class="lp ir">共享</strong>组。</p><p id="f322" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">为了避免在一个视图中塞进太多的数据，我们将为单独和共享的菜肴创建两个单独的视图。</p><p id="334c" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">这是第一张<strong class="lp ir">树状图</strong>，代表泰式炒面的52种不同菜式。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/e3e9e9d36166a22e9714ed92dd08d267.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LBLyjtOP34lg1T3g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="820d" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">创建一个树状图需要使用<code class="fe mp mq mr ms b">ggraph</code>和<code class="fe mp mq mr ms b">igraph</code>库。首先，我们将加载库，并通过过滤单个菜肴来子集化数据框:</p><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="1c13" class="nm kw iq ms b gy nn no l np nq">df &lt;- read_csv("edit_thai_dishes.csv")</span><span id="a20b" class="nm kw iq ms b gy nr no l np nq">library(ggraph)<br/>library(igraph)</span><span id="23c6" class="nm kw iq ms b gy nr no l np nq">df %&gt;%<br/>    select(major_grouping, minor_grouping, Thai_name, Thai_script) %&gt;%<br/>    filter(major_grouping == 'Individual dishes') %&gt;%<br/>    group_by(minor_grouping) %&gt;%<br/>    count()</span></pre><p id="7d85" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">我们创建边和节点(即from和to)来创建单个菜肴(即米饭、面条和其他)中的子分组:</p><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="222f" class="nm kw iq ms b gy nn no l np nq"># Individual Dishes ----</span><span id="4ddf" class="nm kw iq ms b gy nr no l np nq"># data: edge list<br/>d1 &lt;- data.frame(from="Individual dishes", to=c("Misc Indiv", "Noodle dishes", "Rice dishes"))</span><span id="8e4d" class="nm kw iq ms b gy nr no l np nq">d2 &lt;- df %&gt;%<br/>    select(minor_grouping, Thai_name) %&gt;%<br/>    slice(1:53) %&gt;%<br/>    rename(<br/>        from = minor_grouping,<br/>        to = Thai_name<br/>    ) </span><span id="196f" class="nm kw iq ms b gy nr no l np nq">edges &lt;- rbind(d1, d2)</span><span id="a7e9" class="nm kw iq ms b gy nr no l np nq"># plot dendrogram (idividual dishes)<br/>indiv_dishes_graph &lt;- graph_from_data_frame(edges)</span><span id="096f" class="nm kw iq ms b gy nr no l np nq">ggraph(indiv_dishes_graph, layout = "dendrogram", circular = FALSE) +<br/>    geom_edge_diagonal(aes(edge_colour = edges$from), label_dodge = NULL) +<br/>    geom_node_text(aes(label = name, filter = leaf, color = 'red'), hjust = 1.1, size = 3) +<br/>    geom_node_point(color = "whitesmoke") +<br/>    theme(<br/>        plot.background = element_rect(fill = '#343d46'),<br/>        panel.background = element_rect(fill = '#343d46'),<br/>        legend.position = 'none',<br/>        plot.title = element_text(colour = 'whitesmoke', face = 'bold', size = 25),<br/>        plot.subtitle = element_text(colour = 'whitesmoke', face = 'bold'),<br/>        plot.caption = element_text(color = 'whitesmoke', face = 'italic')<br/>    ) +<br/>    labs(<br/>        title = '52 Alternatives to Pad Thai',<br/>        subtitle = 'Individual Thai Dishes',<br/>        caption = 'Data: Wikipedia | Graphic: @paulapivat'<br/>    ) +<br/>    expand_limits(x = c(-1.5, 1.5), y = c(-0.8, 0.8)) +<br/>    coord_flip() +<br/>    annotate("text", x = 47, y = 1, label = "Miscellaneous (7)", color = "#7CAE00")+<br/>    annotate("text", x = 31, y = 1, label = "Noodle Dishes (24)", color = "#00C08B") +<br/>    annotate("text", x = 8, y = 1, label = "Rice Dishes (22)", color = "#C77CFF") +<br/>    annotate("text", x = 26, y = 2, label = "Individual\nDishes", color = "#F8766D")</span></pre><h2 id="418e" class="nm kw iq bd kx ob oc dn lb od oe dp lf lw of og lh ma oh oi lj me oj ok ll ol bi translated">组织不同菜肴的最好方法是什么？</h2><p id="262d" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">大约有<strong class="lp ir"> 4X </strong>个<em class="oa">共享</em>个菜肴作为单个菜肴，所以树状图应该是<strong class="lp ir">圆形</strong>以适合一个图形中所有菜肴的名称。</p><p id="974d" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">对于这些类型的视觉效果，我经常使用的一个很棒的资源是R图库。在如何计算<strong class="lp ir">文本角度</strong>方面有一个小问题，所以我提交了一个<a class="ae mo" href="https://github.com/holtzy/R-graph-gallery/pull/34" rel="noopener ugc nofollow" target="_blank"> PR来修复</a>。</p><p id="c8d8" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">也许区分个人菜肴和共享菜肴过于粗略，在201种共享泰国菜的树状图中，我们可以看到进一步的细分，包括咖喱、酱/酱、蒸、烤、油炸、油炸和炒菜、沙拉、汤和其他杂项:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/d8cec3dea961ef1b0d310c0ecbd21ad0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xdEK88XSV3aIVshc.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="b2d1" class="nm kw iq ms b gy nn no l np nq"># Shared Dishes ----<br/>df %&gt;%<br/>    select(major_grouping, minor_grouping, Thai_name, Thai_script) %&gt;%<br/>    filter(major_grouping == 'Shared dishes') %&gt;%<br/>    group_by(minor_grouping) %&gt;%<br/>    count() %&gt;%<br/>    arrange(desc(n))</span><span id="6978" class="nm kw iq ms b gy nr no l np nq">d3 &lt;- data.frame(from="Shared dishes", to=c("Curries", "Soups", "Salads",<br/>                                            "Fried and stir-fried dishes", "Deep-fried dishes", "Grilled dishes",<br/>                                            "Steamed or blanched dishes", "Stewed dishes", "Dipping sauces and pastes", "Misc Shared"))<br/></span><span id="8b1a" class="nm kw iq ms b gy nr no l np nq">d4 &lt;- df %&gt;%<br/>    select(minor_grouping, Thai_name) %&gt;%<br/>    slice(54:254) %&gt;%<br/>    rename(<br/>        from = minor_grouping,<br/>        to = Thai_name<br/>    )</span><span id="e81a" class="nm kw iq ms b gy nr no l np nq">edges2 &lt;- rbind(d3, d4)</span><span id="2fed" class="nm kw iq ms b gy nr no l np nq"># create a vertices data.frame. One line per object of hierarchy<br/>vertices = data.frame(<br/>    name = unique(c(as.character(edges2$from), as.character(edges2$to)))<br/>)</span><span id="a0ff" class="nm kw iq ms b gy nr no l np nq"># add column with group of each name. Useful to later color points<br/>vertices$group = edges2$from[ match(vertices$name, edges2$to)]</span><span id="ca5c" class="nm kw iq ms b gy nr no l np nq"># Add information concerning the label we are going to add: angle, horizontal adjustment and potential flip<br/># calculate the ANGLE of the labels<br/>vertices$id=NA<br/>myleaves=which(is.na(match(vertices$name, edges2$from)))<br/>nleaves=length(myleaves)<br/>vertices$id[myleaves] = seq(1:nleaves)<br/>vertices$angle = 360 / nleaves * vertices$id + 90    <br/></span><span id="0014" class="nm kw iq ms b gy nr no l np nq"># calculate the alignment of labels: right or left<br/>vertices$hjust&lt;-ifelse( vertices$angle &lt; 275, 1, 0)</span><span id="74ff" class="nm kw iq ms b gy nr no l np nq"># flip angle BY to make them readable<br/>vertices$angle&lt;-ifelse(vertices$angle &lt; 275, vertices$angle+180, vertices$angle)</span><span id="c619" class="nm kw iq ms b gy nr no l np nq"># plot dendrogram (shared dishes)<br/>shared_dishes_graph &lt;- graph_from_data_frame(edges2)</span><span id="93b3" class="nm kw iq ms b gy nr no l np nq">ggraph(shared_dishes_graph, layout = "dendrogram", circular = TRUE) +<br/>    geom_edge_diagonal(aes(edge_colour = edges2$from), label_dodge = NULL) +<br/>    geom_node_text(aes(x = x*1.15, y=y*1.15, filter = leaf, label=name, angle = vertices$angle, hjust= vertices$hjust, colour= vertices$group), size=2.7, alpha=1) +<br/>    geom_node_point(color = "whitesmoke") +<br/>    theme(<br/>        plot.background = element_rect(fill = '#343d46'),<br/>        panel.background = element_rect(fill = '#343d46'),<br/>        legend.position = 'none',<br/>        plot.title = element_text(colour = 'whitesmoke', face = 'bold', size = 25),<br/>        plot.subtitle = element_text(colour = 'whitesmoke', margin = margin(0,0,30,0), size = 20),<br/>        plot.caption = element_text(color = 'whitesmoke', face = 'italic')<br/>    ) +<br/>    labs(<br/>        title = 'Thai Food is Best Shared',<br/>        subtitle = '201 Ways to Make Friends',<br/>        caption = 'Data: Wikipedia | Graphic: @paulapivat'<br/>    ) +<br/>    #expand_limits(x = c(-1.5, 1.5), y = c(-0.8, 0.8)) +<br/>    expand_limits(x = c(-1.5, 1.5), y = c(-1.5, 1.5)) +<br/>    coord_flip() +<br/>    annotate("text", x = 0.4, y = 0.45, label = "Steamed", color = "#F564E3") +<br/>    annotate("text", x = 0.2, y = 0.5, label = "Grilled", color = "#00BA38") +<br/>    annotate("text", x = -0.2, y = 0.5, label = "Deep-Fried", color = "#DE8C00") +<br/>    annotate("text", x = -0.4, y = 0.1, label = "Fried &amp;\n Stir-Fried", color = "#7CAE00") +<br/>    annotate("text", x = -0.3, y = -0.4, label = "Salads", color = "#00B4F0") +<br/>    annotate("text", x = -0.05, y = -0.5, label = "Soups", color = "#C77CFF") +<br/>    annotate("text", x = 0.3, y = -0.5, label = "Curries", color = "#F8766D") +<br/>    annotate("text", x = 0.5, y = -0.1, label = "Misc", color = "#00BFC4") +<br/>    annotate("text", x = 0.5, y = 0.1, label = "Sauces\nPastes", color = "#B79F00")</span></pre><h1 id="47b0" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">文本挖掘</h1><h2 id="02c6" class="nm kw iq bd kx ob oc dn lb od oe dp lf lw of og lh ma oh oi lj me oj ok ll ol bi translated">哪种原材料最受欢迎？</h2><p id="f99b" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">回答这个问题的一个方法是使用文本挖掘，通过任一单词对<strong class="lp ir">进行标记化，并通过频率对单词进行计数，作为流行度的一种度量。</strong></p><p id="c79a" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">在下面的柱状图中，我们可以看到所有泰国菜的词频。<strong class="lp ir"> Mu </strong> (หมู)在泰语中的意思是猪肉，在所有菜式和子类别中出现频率最高。接下来我们吃แกง咖喱饭，意思是咖喱。(ผัด)名列第三，暗示“炒”是一种受欢迎的烹饪方式。</p><p id="ecc9" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">正如我们看到的<strong class="lp ir">不是</strong>所有的词都是指原材料，所以我们可能无法直接回答这个问题。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/80fe1b85f285b21056db8672b0acc802.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZlZ8Qe9VLh8GL74f.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="7d49" class="nm kw iq ms b gy nn no l np nq">library(tidytext)<br/>library(scales)</span><span id="0c42" class="nm kw iq ms b gy nr no l np nq"># new csv file after data cleaning (see above)<br/>df &lt;- read_csv("../web_scraping/edit_thai_dishes.csv")</span><span id="3782" class="nm kw iq ms b gy nr no l np nq">df %&gt;%<br/>    select(Thai_name, Thai_script) %&gt;%<br/>    # can substitute 'word' for ngrams, sentences, lines<br/>    unnest_tokens(ngrams, Thai_name) %&gt;%  <br/>    # to reference thai spelling: group_by(Thai_script)<br/>    group_by(ngrams) %&gt;%  <br/>    tally(sort = TRUE) %&gt;%  # alt: count(sort = TRUE)<br/>    filter(n &gt; 9) %&gt;%<br/># visualize<br/># pipe directly into ggplot2, because using tidytools<br/>    ggplot(aes(x = n, y = reorder(ngrams, n))) + <br/>    geom_col(aes(fill = ngrams)) +<br/>    scale_fill_manual(values = c(<br/>        "#c3d66b",<br/>        "#70290a",<br/>        "#2f1c0b",<br/>        "#ba9d8f",<br/>        "#dda37b",<br/>        "#8f5e23",<br/>        "#96b224",<br/>        "#dbcac9",<br/>        "#626817",<br/>        "#a67e5f",<br/>        "#be7825",<br/>        "#446206",<br/>        "#c8910b",<br/>        "#88821b",<br/>        "#313d5f",<br/>        "#73869a",<br/>        "#6f370f",<br/>        "#c0580d",<br/>        "#e0d639",<br/>        "#c9d0ce",<br/>        "#ebf1f0",<br/>        "#50607b"<br/>    )) +<br/>    theme_minimal() +<br/>    theme(legend.position = "none") +<br/>    labs(<br/>        x = "Frequency",<br/>        y = "Words",<br/>        title = "Frequency of Words in Thai Cuisine",<br/>        subtitle = "Words appearing at least 10 times in Individual or Shared Dishes",<br/>        caption = "Data: Wikipedia | Graphic: @paulapivat"<br/>    )</span></pre><p id="8c32" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">我们还可以看到个人菜肴和共享菜肴共有的词汇。我们还看到了其他一些词，如nuea(牛肉)、phrik(辣椒)和kaphrao(罗勒叶)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/84fc7206469a965bcb8896c358ffa6a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Q38qnm9zErF2DcP-.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="4d19" class="nm kw iq ms b gy nn no l np nq"># frequency for Thai_dishes (Major Grouping) ----</span><span id="b590" class="nm kw iq ms b gy nr no l np nq"># comparing Individual and Shared Dishes (Major Grouping)<br/>thai_name_freq &lt;- df %&gt;%<br/>    select(Thai_name, Thai_script, major_grouping) %&gt;%<br/>    unnest_tokens(ngrams, Thai_name) %&gt;% <br/>    count(ngrams, major_grouping) %&gt;%<br/>    group_by(major_grouping) %&gt;%<br/>    mutate(proportion = n / sum(n)) %&gt;%<br/>    select(major_grouping, ngrams, proportion) %&gt;%<br/>    spread(major_grouping, proportion) %&gt;%<br/>    gather(major_grouping, proportion, c(`Shared dishes`)) %&gt;%<br/>    select(ngrams, `Individual dishes`, major_grouping, proportion)<br/></span><span id="8c00" class="nm kw iq ms b gy nr no l np nq"># Expect warming message about missing values<br/>ggplot(thai_name_freq, aes(x = proportion, y = `Individual dishes`,<br/>       color = abs(`Individual dishes` - proportion))) +<br/>    geom_abline(color = 'gray40', lty = 2) +<br/>    geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +<br/>    geom_text(aes(label = ngrams), check_overlap = TRUE, vjust = 1.5) +<br/>    scale_x_log10(labels = percent_format()) +<br/>    scale_y_log10(labels = percent_format()) +<br/>    scale_color_gradient(limits = c(0, 0.01), <br/>                         low = "red", high = "blue") +    # low = "darkslategray4", high = "gray75"<br/>    theme_minimal() +<br/>    theme(legend.position = "none",<br/>          legend.text = element_text(angle = 45, hjust = 1)) +<br/>    labs(y = "Individual Dishes",<br/>         x = "Shared Dishes",<br/>         color = NULL,<br/>         title = "Comparing Word Frequencies in the names Thai Dishes",<br/>         subtitle = "Individual and Shared Dishes",<br/>         caption = "Data: Wikipedia | Graphics: @paulapivat")</span></pre><h2 id="de39" class="nm kw iq bd kx ob oc dn lb od oe dp lf lw of og lh ma oh oi lj me oj ok ll ol bi translated">哪些原材料最重要？</h2><p id="0565" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我们只能从频率中了解到这么多，因此文本挖掘从业者创造了<strong class="lp ir">术语频率—逆文档频率</strong>来更好地反映一个词在文档或语料库中的重要性(进一步的细节<a class="ae mo" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank">在此</a>)。</p><p id="ca08" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">还是那句话，不一定指的是原材料，所以这个问题在这里不能直接完全回答。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/260c7372690d9cb00480b8e381491623.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EW9crPfcWglYDPW4.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h2 id="c9ff" class="nm kw iq bd kx ob oc dn lb od oe dp lf lw of og lh ma oh oi lj me oj ok ll ol bi translated">你能仅仅从菜名中了解泰国菜吗？</h2><p id="f7ef" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">简短的回答是“是的”。</p><p id="5cb4" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">我们仅从频率和“术语频率—逆文档频率”中了解到，不仅是最常见的单词，还有我们用<code class="fe mp mq mr ms b">tidytext</code>标记的当前单词集中的相对重要性。这不仅告诉我们流行的原材料(猪肉)，还告诉我们菜肴类型(咖喱)和其他流行的准备方式(炒菜)。</p><p id="73e8" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">我们甚至可以检查单词之间的关系网的<strong class="lp ir">。深色箭头表示单词对之间的关系更强，例如“nam phrik”是一个强配对。这在泰语中是“辣椒酱”的意思，暗示了辣椒酱在许多菜肴中的重要作用。</strong></p><p id="83e0" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">我们在上面了解到“目”(猪肉)经常出现。现在我们看到“mu”和“krop”比其他配对关系更密切(注:“mu krop”的意思是“脆皮猪肉”)。我们在上面也看到了“khao”频繁出现在米饭菜肴中。这并不奇怪，因为“khao”在泰语中是米饭的意思，但我们在这里看到“khao phat”与炒饭(“khao phat”)密切相关，表明炒饭非常受欢迎。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/f79a631b1ffc789f3e9afda9e6b801e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*c9gm3O_3ScaOVWCJ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="0b26" class="nm kw iq ms b gy nn no l np nq"># Visualizing a network of Bi-grams with {ggraph} ----<br/>library(igraph)<br/>library(ggraph)<br/>set.seed(2021)</span><span id="3a0a" class="nm kw iq ms b gy nr no l np nq">thai_dish_bigram_counts &lt;- df %&gt;%<br/>    select(Thai_name, minor_grouping) %&gt;%<br/>    unnest_tokens(bigram, Thai_name, token = "ngrams", n = 2) %&gt;%<br/>    separate(bigram, c("word1", "word2"), sep = " ") %&gt;%<br/>    count(word1, word2, sort = TRUE)<br/></span><span id="3a3a" class="nm kw iq ms b gy nr no l np nq"># filter for relatively common combinations (n &gt; 2)<br/>thai_dish_bigram_graph &lt;- thai_dish_bigram_counts %&gt;%<br/>    filter(n &gt; 2) %&gt;%<br/>    graph_from_data_frame()<br/></span><span id="2c19" class="nm kw iq ms b gy nr no l np nq"># polishing operations to make a better looking graph<br/>a &lt;- grid::arrow(type = "closed", length = unit(.15, "inches"))</span><span id="e31c" class="nm kw iq ms b gy nr no l np nq">set.seed(2021)<br/>ggraph(thai_dish_bigram_graph, layout = "fr") +<br/>    geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,<br/>                   arrow = a, end_cap = circle(.07, 'inches')) +<br/>    geom_node_point(color = "dodgerblue", size = 5, alpha = 0.7) +<br/>    geom_node_text(aes(label = name), vjust = 1, hjust = 1) +<br/>    labs(<br/>        title = "Network of Relations between Word Pairs",<br/>        subtitle = "{ggraph}: common nodes in Thai food",<br/>        caption = "Data: Wikipedia | Graphics: @paulapivat"<br/>    ) +<br/>    theme_void()</span></pre><p id="f1e1" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">最后，我们可能会对道菜肴中<em class="oa">的词汇关系感兴趣。</em></p><p id="96c7" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">下图显示了一个中度到高度相关的词对网络。我们可以看到某些单词以相对较暗的线条聚集在一起:kaeng(咖喱)、pet(辣)、wan(甜)、khiao(绿咖喱)、phrik(辣椒)和mu(猪肉)。这些词代表了通常组合在一起的配料、烹饪方式和描述的集合。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/7c1e327cbeec249f925103933468045c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*po3u5pa8vz3n-co6.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><pre class="kg kh ki kj gt ni ms nj nk aw nl bi"><span id="c197" class="nm kw iq ms b gy nn no l np nq">set.seed(2021)</span><span id="3d0d" class="nm kw iq ms b gy nr no l np nq"># Individual Dishes<br/>individual_dish_words &lt;- df %&gt;%<br/>    select(major_grouping, Thai_name) %&gt;%<br/>    filter(major_grouping == 'Individual dishes') %&gt;%<br/>    mutate(section = row_number() %/% 10) %&gt;%<br/>    filter(section &gt; 0) %&gt;%<br/>    unnest_tokens(word, Thai_name)  # assume no stop words</span><span id="4d1a" class="nm kw iq ms b gy nr no l np nq">individual_dish_cors &lt;- individual_dish_words %&gt;%<br/>    group_by(word) %&gt;% <br/>    filter(n() &gt;= 2) %&gt;%     # looking for co-occuring words, so must be 2 or greater<br/>    pairwise_cor(word, section, sort = TRUE) <br/></span><span id="5dd5" class="nm kw iq ms b gy nr no l np nq">individual_dish_cors %&gt;%<br/>    filter(correlation &lt; -0.40) %&gt;%<br/>    graph_from_data_frame() %&gt;%<br/>    ggraph(layout = "fr") +<br/>    geom_edge_link(aes(edge_alpha = correlation, size = correlation), show.legend = TRUE) +<br/>    geom_node_point(color = "green", size = 5, alpha = 0.5) +<br/>    geom_node_text(aes(label = name), repel = TRUE) +<br/>    labs(<br/>        title = "Word Pairs in Individual Dishes",<br/>        subtitle = "{ggraph}: Negatively correlated (r = -0.4)",<br/>        caption = "Data: Wikipedia | Graphics: @paulapivat"<br/>    ) +<br/>    theme_void()</span></pre><h2 id="30d6" class="nm kw iq bd kx ob oc dn lb od oe dp lf lw of og lh ma oh oi lj me oj ok ll ol bi translated">摘要</h2><p id="9997" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我们已经完成了一个探索性的数据项目，在这个项目中，我们使用Python和r的组合来搜集、清理、操作和可视化数据。我们还使用<code class="fe mp mq mr ms b">tidytext</code>包来完成基本的文本挖掘任务，看看我们是否可以使用从维基百科上搜集的菜名中的单词来深入了解泰国美食。</p><p id="ce1d" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">欲了解更多关于数据科学、R、Python、SQL等内容，<a class="ae mo" href="https://twitter.com/paulapivat" rel="noopener ugc nofollow" target="_blank">在Twitter上找到我</a>。</p></div></div>    
</body>
</html>