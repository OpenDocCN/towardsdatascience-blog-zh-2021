<html>
<head>
<title>A Fuzzy String Matching Story</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一个模糊字符串匹配的故事</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-fuzzy-string-matching-story-314bbecaa098?source=collection_archive---------11-----------------------#2021-09-30">https://towardsdatascience.com/a-fuzzy-string-matching-story-314bbecaa098?source=collection_archive---------11-----------------------#2021-09-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="64ec" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解如何构建模糊字符串匹配基线模型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d3d6991cdcf0650f4e18bca9eb1aded4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ksC1QZlcpJHcTUGygqkksg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">布鲁诺·马丁斯在Unsplash 上的照片</p></figure><p id="fbc2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在构建基于机器学习应用的新产品时，我们需要从不同的来源提取、收集和存储数据。无论采用何种提取方法(API、<a class="ae kv" href="https://medium.com/@eortizrecalde/a-practical-web-scraping-guide-62073b69b003" rel="noopener">网络抓取</a>或其他)，收集的数据仍然需要经过可能是最重要、最耗时的任务，即把来自这些来源的数据整合、匹配和规范化到数据库中。</p><p id="20cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇文章中，我们将讨论关于<strong class="ky ir">模糊字符串匹配</strong>。这个问题包括尝试匹配相似但不同的字符串(可能是由于拼写差异或错误)，例如“Lionel Messi”和“L. Messi”或“Argentina”和“Argentina”。</p><p id="7869" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是这有什么关系呢？我给你讲个故事吧(免责声明:<em class="ls">本文所有人物和事件均属虚构，与现实有任何雷同，纯属巧合</em>)。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h2 id="e8ce" class="ma mb iq bd mc md me dn mf mg mh dp mi lf mj mk ml lj mm mn mo ln mp mq mr ms bi translated">开始</h2><p id="3782" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">John拥有一家大型连锁售货亭，他希望使用竞争对手(其他售货亭、附近的商店和超市)的价格建立更精确的定价模型。不久前，他曾经付钱给神秘顾客，让他们每隔一个月访问并收集一些竞争对手的价格数据，直到他意识到这根本不划算，因为价格似乎每个月都要调整多次。</p><p id="1618" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">意识到这一点后，他迅速采取行动，决定建立一个网络抓取服务，以更高的频率提取竞争对手的产品价格。实施该解决方案后，一切似乎都很顺利，成功地收集了数据，John觉得他已经击败了系统，并认为他的数据团队将能够直接构建新的定价模型。然而，有一个他没有考虑到的大问题:废弃产品的拼写不一定与他的售货亭目录匹配，这意味着他无法直接将他的内部数据与外部来源进行关联和比较。例如:</p><p id="7923" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">【健怡可乐1.5L】≠“可乐dieet 1500ml”</p><p id="dc22" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那么，他在意识到不能使用数据后做了什么呢？首先，在一次突然的暴怒中，他弄坏了他的键盘。后来，冷静下来后，他继续询问他的数据团队是否知道如何解决这个问题(使用他的另一个键盘)。“独角兽”员工卡尔看到了赢得约翰好感的机会，他告诉约翰，他以前处理过类似的问题，可以在一周内获得MVP(但说实话，他不知道自己在做什么)。约翰愉快地同意了，但是他没有给卡尔一周时间去做，而是给他两周时间。</p><h2 id="64b8" class="ma mb iq bd mc md me dn mf mg mh dp mi lf mj mk ml lj mm mn mo ln mp mq mr ms bi translated">寻找解决方案</h2><p id="647a" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">利用过去被证明有效的方法，卡尔用他最可靠的工具“谷歌”搜索“python中的字符串匹配”。他很快就看到了几篇关于正则表达式匹配字符串的帖子，一种他从未听说过的新距离，称为“Levenshtein距离”，以及模糊字符串匹配的概念。但是没有一个人给他提供实用的解决方案，直到他偶然发现了一篇名为“模糊字符串匹配的故事”的文章，作者是一个叫Ezequiel Ortiz Recalde的人。这篇文章为他提供了一些有用的建议，告诉他如何通过一个实际的例子来完成匹配过程和构建基线模型。我们现在来看看卡尔看到了什么。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><p id="ac1e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 1。Imports <br/> </strong>首先，我们安装并导入主库，用于匹配售货亭或超市中的饮料字符串(数据是手动生成的)。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="7c2d" class="ma mb iq mz b gy nd ne l nf ng">#!pip install fuzzywuzzy<br/>#!pip install python-Levenshtein<br/>#!pip install polyfuzz<br/>#!pip install nltk</span><span id="9589" class="ma mb iq mz b gy nh ne l nf ng">import pandas as pd<br/>import numpy as np<br/>import string<br/>import re</span><span id="1bea" class="ma mb iq mz b gy nh ne l nf ng">from nltk.metrics.distance import edit_distance<br/>from fuzzywuzzy import fuzz<br/>from polyfuzz import PolyFuzz<br/>from polyfuzz.models import TFIDF</span></pre><p id="6b30" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 2。数据</strong></p><p id="168d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们已经生成了两个饮料数据集(外部数据和内部数据)。第一个是指可能通过抓取网站获得的外部数据，而第二个是复制一个售货亭的虚拟官方饮料目录的一部分。在这里，我们可以看到两者的示例:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/6b38d5ae5ca0b762fd42525c2495f38f.png" data-original-src="https://miro.medium.com/v2/resize:fit:426/format:webp/1*MzjLLT-7mKESAvxQ5MdFCA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">外部数据</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/96f9ea055dff9bcd3afb7ee9bd10087f.png" data-original-src="https://miro.medium.com/v2/resize:fit:414/format:webp/1*clT12TBxqLOZRkeXnomzmQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">内部数据</p></figure><p id="4369" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 3。字符串预处理</strong></p><p id="a61b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在尝试匹配不同来源的字符串之前，有一些有用的转换可以简化这个问题:</p><ul class=""><li id="fc58" class="nk nl iq ky b kz la lc ld lf nm lj nn ln no lr np nq nr ns bi translated">将字符串转换为小写；</li><li id="a09b" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated">小心地去掉符号和标点符号；</li><li id="7e67" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated">删除连续的空格(或全部，取决于问题)；</li><li id="3b2b" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated">小心地删除停用词(注意删除关键词，因为它们在将来可能会有用；避免删除太多特定的单词，因为你仍然希望你的模型能够概括)；</li><li id="c48a" class="nk nl iq ky b kz nt lc nu lf nv lj nw ln nx lr np nq nr ns bi translated">标准化不同表达式的拼写(例如，在grams的情况下，我们可以找到g，gr，gs，g，gr，gs。等)；</li></ul><p id="f825" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据这些建议，我们使用下面的函数来清理两个数据帧的列:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="edb6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在应用该函数之前，我们创建要修改的列的副本，以便保留原始版本:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="f3e6" class="ma mb iq mz b gy nd ne l nf ng">external_data["product_cleaned_from"]=\<br/>external_data["product"].copy()</span><span id="0106" class="ma mb iq mz b gy nh ne l nf ng">internal_data["product_cleaned_to"]=\<br/>internal_data["product_name"].copy()</span></pre><p id="e5ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将函数应用于两个数据帧:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="c5f3" class="ma mb iq mz b gy nd ne l nf ng">string_processing(df=external_data,columns_to_clean=["product"])</span><span id="b4ee" class="ma mb iq mz b gy nh ne l nf ng">string_processing(df=internal_data,columns_to_clean=["product_name"])</span></pre><p id="68b1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这样做之后，我们终于有了干净的数据进行匹配。接下来，我们将讨论要使用的主要方法。</p><p id="20d2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 4。使用Tf-Idf矢量化进行字符串匹配</strong></p><p id="122c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">词频逆文档词频矢量化是许多NLP应用中使用的一种技术，其目的是考虑单词在文档中以及在所有语料库中出现的次数，来近似估计该单词在文档中的相关性。通过这种方法，我们获得了每个文档中每个单词的“权重”向量，我们可以将它用作分类模型的特征。</p><p id="36a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，这与字符串匹配有什么关系呢？我们可以将令牌划分成n元文法，然后获得它们的TF-IDF向量化。一旦我们有了n-gram的权重向量，我们就可以计算它们之间的相似性。注意，相对于使用基于Levenshtein距离的比率来检查在所有可能的短语对的每一个之间应该进行多少编辑的缓慢过程，这允许我们利用矩阵运算的快速计算。</p><p id="5de4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">匹配过程如下进行:</p><p id="8146" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> a) </strong>定义两个字符串列表，一个列表“From”(指我们想要匹配的内容)和一个列表“to”(在本例中为目录)。</p><p id="23df" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> b) </strong>定义n元文法的数量，其中的字符串将被分割。</p><p id="85ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> c) </strong>用两个列表拟合TF-IDF矢量器，以便得到所有可能的唯一n元文法的表示。</p><p id="2f3b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> d) </strong>使用TF-IDF表示，将每个列表转换为相同的表示(如果一个字符串不包含矢量器的唯一n元语法分区之一，则该分区的值将为0)。在这一步中，我们将获得两个矩阵，其列数与唯一n-grams划分的列数一样多(两个矩阵的列数相同，因为矢量器适合使用两个列表)，行数指的是每个源列表中的元素数。</p><p id="8028" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">幸运的是，整个过程已经集成到了PolyFuzz库中，但是我们仍然想知道我们是否理解了眼见为实的工作原理:</p><p id="616a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我们将导入一些解释所需的函数:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="42e6" class="ma mb iq mz b gy nd ne l nf ng">from sklearn.feature_extraction.text import TfidfVectorizer<br/>from sklearn.metrics.pairwise import cosine_similarity</span></pre><p id="874e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们生成要匹配的字符串列表:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="cfa9" class="ma mb iq mz b gy nd ne l nf ng">from_list = ["coke 1.5L","sprite zero 1.5L"]<br/>to_list = ["diet coke 1.5L"]</span></pre><p id="9e78" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们稍微修改了这个函数，为在<a class="ae kv" href="https://maartengr.github.io/PolyFuzz/" rel="noopener ugc nofollow" target="_blank"> PolyFuzz </a>库中使用的标记创建n元语法分区，使其直接使用3元语法。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="ccb4" class="ma mb iq mz b gy nd ne l nf ng">def _create_ngrams(string: str):</span><span id="7a13" class="ma mb iq mz b gy nh ne l nf ng">   result = []<br/>   for n in range(3, 4):<br/>      ngrams = zip(*[string[i:] for i in range(n)])<br/>      ngrams = [''.join(ngram) for ngram in ngrams if ' ' not in ngram]<br/>   <br/>   result.extend(ngrams)<br/>   return(result)</span></pre><p id="dbf6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个函数接收一个字符串，并为每个由空格分隔的标记创建一个n大小的分区。例如,“健怡可乐”会被分成“die，iet，cok，oke”。接下来，我们能够使用<em class="ls"> _create_ngrams </em>函数来拆分标记并创建列表元素的矢量化表示，从而适应scikit learn的<a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" rel="noopener ugc nofollow" target="_blank"> TfidfVectorizer </a>:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="bf2f" class="ma mb iq mz b gy nd ne l nf ng"># Define the vectorizer<br/>vectorizer = TfidfVectorizer(min_df=1, analyzer=_create_ngrams).fit(to_list + from_list)</span></pre><p id="f435" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意这里有两个显式参数<em class="ls"> min_df </em>和<em class="ls"> analyzer </em>。第一个是指一个划分必须在语料库中出现以被包括在词汇表中的最小次数，而第二个是用于指定如何创建矢量器的词汇表，即从单词或n元语法中创建。</p><p id="c53e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">给定输入列表，我们可以检查结果词汇。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="4834" class="ma mb iq mz b gy nd ne l nf ng">vectorizer.vocabulary_</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/1ffe468445abaefa1193c1b553ae92ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:244/format:webp/1*s4aB_WybULd8MCuY6FeLbQ.png"/></div></figure><p id="1c6c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些数字表示矩阵的列索引(“. 5L”将在列1中)。</p><p id="e060" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">创建矩阵表示后，我们继续转换每个列表以匹配其结构，接收稀疏矩阵:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="1881" class="ma mb iq mz b gy nd ne l nf ng">tf_idf_to = vectorizer.transform(to_list)<br/>tf_idf_from = vectorizer.transform(from_list)</span></pre><p id="d327" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了检查每行中这三个字母的权重，我们将tf_idf_to和tf_idf_from转换为密集格式，然后转换为dataframe，使用词汇索引来设置列名:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="2716" class="ma mb iq mz b gy nd ne l nf ng">matrix_from=pd.DataFrame(tf_idf_from.todense(),\<br/>columns=sorted(vectorizer.vocabulary_))</span><span id="e5e1" class="ma mb iq mz b gy nh ne l nf ng">matrix_to=pd.DataFrame(tf_idf_to.todense(),\<br/>columns=sorted(vectorizer.vocabulary_))</span></pre><p id="8aa6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">两个矩阵都有n个元素x n个词汇，如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/c6e4aa112c5eddf6d86df8a921ae7f0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZjNeyq9qWbBytYoHIvfMFg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">矩阵_从</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/071b59f5f838412114fc436fa4ce4e33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*RfetaWJDLpuzEv5bsZRJkg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">matrix_to</p></figure><p id="d17a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">既然我们有了矩阵，我们就能够计算n-grams划分的向量之间的相似性。在这种情况下，我们使用余弦相似度:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="6e5f" class="ma mb iq mz b gy nd ne l nf ng">cosine_similarity(matrix_from, matrix_to)</span></pre><p id="3c79" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">带输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/229e0dd5b996a1624e4da9350030a23d.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*KQHXijWNm8f3PMas1Mh00Q.png"/></div></figure><p id="24c0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这给出了记号向量对之间的相似性得分。在这种情况下，我们可以看到“可乐1.5L”比“雪碧零度1.5L”更类似于“健怡可乐1.5”。我们刚刚做的是矩阵之间的点积:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="de73" class="ma mb iq mz b gy nd ne l nf ng">np.dot(np.array(matrix_from.iloc[0]),np.array(matrix_to.iloc[0]))</span></pre><p id="605a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">返回0.6936279421797706，而</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="11d0" class="ma mb iq mz b gy nd ne l nf ng">np.dot(np.array(matrix_from.iloc[1]),np.array(matrix_to.iloc[0]))</span></pre><p id="32b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">返回0.1373086119752811。</p><p id="7aeb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 5。其他有用的度量:令牌集比率和Levenshtein距离</strong></p><p id="5bd0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们只检查了字符串之间相似性的一个度量，但是根据您正在比较的字符串类型，还有其他可能有帮助的度量。对于这个特殊的例子，我喜欢在分析中包括记号集比率和levenshtein距离。</p><p id="6198" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">标记集比率是字符串的相似性度量，它考虑了值的重复和单词顺序的差异(例如，“diet coke”与“coke diet”相同，对于这些类型的情况，我们会对捕捉这样的直接答案感兴趣)。我们用一个简单的例子“健怡可乐1.5ml”和“健怡库克减肥药1.5ml”来看看如何计算:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="0c1a" class="ma mb iq mz b gy nd ne l nf ng"># We create the 2 strings<br/>s1="diet coke 600ml"<br/>s2="diet cooke diet 600ml"</span></pre><p id="a63a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">I)我们从预处理开始，将字符串分离成标记:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="4b21" class="ma mb iq mz b gy nd ne l nf ng">tokens1 = set(fuzz.utils.full_process(s1).split())<br/>tokens2 = set(fuzz.utils.full_process(s2).split())</span></pre><p id="b31f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里tokens1 = { ' 600ml '，'可乐'，'减肥' }</p><p id="d229" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">ii)然后，我们取记号集，并获得它们的交集和差异:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="7ed8" class="ma mb iq mz b gy nd ne l nf ng"># Intersection<br/>tokens1.intersection(tokens2)</span><span id="013a" class="ma mb iq mz b gy nh ne l nf ng"># Difference (which tokens are we missing so that both sets are equal)<br/>diff1to2 = tokens1.difference(tokens2)<br/>diff2to1 = tokens2.difference(tokens1)</span></pre><p id="d57b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">iii)我们连接了有序交集和差集，解决了字符串的顺序问题:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="4dd2" class="ma mb iq mz b gy nd ne l nf ng">#We concatenate the ordered intersections and differences</span><span id="2249" class="ma mb iq mz b gy nh ne l nf ng">sorted_sect = " ".join(sorted(intersection))<br/>sorted_1to2 = " ".join(sorted(diff1to2))<br/>sorted_2to1 = " ".join(sorted(diff2to1))</span></pre><p id="0761" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">iv)我们组合每个选项中的标记来重构整个字符串:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="bf33" class="ma mb iq mz b gy nd ne l nf ng">combined_1to2 = sorted_sect + " "+ sorted_1to2<br/>combined_2to1 = sorted_sect + " "+ sorted_2to1</span></pre><p id="44b2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">v)我们消除了重复的空白:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="a9d8" class="ma mb iq mz b gy nd ne l nf ng">sorted_sect = sorted_sect.strip()<br/>combined_1to2 = combined_1to2.strip()<br/>combined_2to1 = combined_2to1.strip()</span></pre><p id="ed14" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">vi)我们计算不同组合对的模糊率(即归一化的Levenshtein距离):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/4ceec267b5b4e1f5a93101d94dbf61a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*oco2RUyE3dQfoD9vstqn8A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">模糊率</p></figure><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="6f2d" class="ma mb iq mz b gy nd ne l nf ng">pairwise = [fuzz.ratio(sorted_sect, combined_1to2)/100,<br/> fuzz.ratio(sorted_sect, combined_2to1)/100,<br/> fuzz.ratio(combined_1to2, combined_2to1)/100]<br/></span></pre><p id="fb30" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">带输出[0.8，0.77，0.97]。</p><p id="11b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">vii)我们保留具有最大模糊率的配对及其相似性。</p><p id="1606" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于Levenshtein距离，我们简单地使用nltk的<em class="ls"> edit_distance </em>函数。这告诉我们将一个字符串转换成另一个字符串所需的编辑次数。</p><p id="0284" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 6。构建基线模型</strong></p><p id="9b19" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们已经对这个过程有了更好的理解，剩下的就是构建一个管道，它接受两个列表，用它们内容的分区来拟合一个矢量器，计算矢量之间的点积，并匹配具有最高相似性得分的对。这就是Polyfuzz库发挥作用的地方，它为我们提供了一个完全遵循我们刚才解释的模型。此外，我们可以向最终结果添加一些额外的信息(标记集比率和Levenshtein距离),以避免在后验结果过滤中只有一种方法来检查匹配质量。</p><p id="2fb1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下代码块详细描述了整个过程:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="bc9b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">7 .<strong class="ky ir">。结果</strong></p><p id="42d5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里有一个获得结果的例子，你可以通过检查<a class="ae kv" href="https://github.com/eortizrecalde/string-matching/blob/main/string_matching.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>来探索其余的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/b5851f8878f0cce1e2ab6c03f3cd9654.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qPqC-loHgBvIxsR9S4WyNA.png"/></div></div></figure><p id="e7f6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 8。结束语</strong></p><p id="1194" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇简短的文章中，我们展示了一个简单的框架，它可能能够为任何模糊字符串匹配问题产生不错的结果(至少对我来说是这样)。不管kiosk产品的例子是什么，只要您需要将非规范化或自由文本与某种已经过企业理想验证的目录或参考进行匹配，这应该会对您有所帮助。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h2 id="4534" class="ma mb iq bd mc md me dn mf mg mh dp mi lf mj mk ml lj mm mn mo ln mp mq mr ms bi translated">结束了</h2><p id="81a0" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">读完之后，在着手解决他的匹配问题之前，Carl做了每个人都会做的事情，即他喜欢并分享了这篇文章😉。</p><h1 id="e82e" class="og mb iq bd mc oh oi oj mf ok ol om mi jw on jx ml jz oo ka mo kc op kd mr oq bi translated">参考</h1><div class="or os gp gr ot ou"><a href="https://en.wikipedia.org/wiki/Approximate_string_matching" rel="noopener  ugc nofollow" target="_blank"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd ir gy z fp oz fr fs pa fu fw ip bi translated">近似字符串匹配-维基百科</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">在计算机科学中，近似字符串匹配(通常通俗地称为模糊字符串搜索)是…</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">en.wikipedia.org</p></div></div><div class="pd l"><div class="pe l pf pg ph pd pi kp ou"/></div></div></a></div><div class="or os gp gr ot ou"><a href="https://openclassrooms.com/en/courses/6532301-introduction-to-natural-language-processing/7067116-apply-the-tf-idf-vectorization-approach" rel="noopener  ugc nofollow" target="_blank"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd ir gy z fp oz fr fs pa fu fw ip bi translated">应用TF-IDF矢量化方法</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">自然语言处理(NLP)允许我们对大量文本数据进行分类、校正、预测，甚至翻译…</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">openclassrooms.com</p></div></div><div class="pd l"><div class="pj l pf pg ph pd pi kp ou"/></div></div></a></div><div class="or os gp gr ot ou"><a href="https://github.com/MaartenGr/PolyFuzz" rel="noopener  ugc nofollow" target="_blank"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd ir gy z fp oz fr fs pa fu fw ip bi translated">GitHub - MaartenGr/PolyFuzz:模糊字符串匹配、分组和评估。</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">PolyFuzz执行模糊字符串匹配、字符串分组，并包含广泛的评估函数。PolyFuzz是…</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">github.com</p></div></div><div class="pd l"><div class="pk l pf pg ph pd pi kp ou"/></div></div></a></div></div></div>    
</body>
</html>