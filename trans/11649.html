<html>
<head>
<title>End to End Deep Learning Project: Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">端到端深度学习项目:第1部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/end-to-end-deep-learning-project-part-1-930af1e1e191?source=collection_archive---------6-----------------------#2021-11-18">https://towardsdatascience.com/end-to-end-deep-learning-project-part-1-930af1e1e191?source=collection_archive---------6-----------------------#2021-11-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="d0af" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">初学者的数据科学</h2><div class=""/><div class=""><h2 id="7f5c" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">用Keras实现迁移学习的高效网络图像分类模型</h2></div><p id="675d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">注意:这是从零开始实现深度学习项目的两部分系列的第一部分。第1部分包括问题陈述的设置、数据预处理、迁移学习背后的直觉、特征提取、微调和模型评估。</em> <a class="ae lo" href="https://varshitasher.medium.com/deploying-an-end-to-end-deep-learning-project-with-few-clicks-part-2-89009cff6f16" rel="noopener"> <em class="ln">第二部分</em> </a> <em class="ln">涵盖了Flask app的实现及其在Heroku上的后续部署。为了保持连续性，请遵循教程。代码在</em><a class="ae lo" href="https://github.com/V-Sher/house-interior-prediction" rel="noopener ugc nofollow" target="_blank"><em class="ln">Github</em></a><em class="ln">上。</em></p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/5923fa3c2057259a423d6f9f9e1d7872.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZjH36Uiu1VMjkVcKfHN7Rw.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">你可以在这里玩烧瓶应用程序<a class="ae lo" href="https://house-interior-prediction.herokuapp.com/" rel="noopener ugc nofollow" target="_blank"/>。</p></figure><h1 id="83d6" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">介绍</h1><p id="20fc" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">我非常幸运地在这样的环境中工作:( a)数据生成的基础设施和架构随时可用,( b)数据争论由分析师处理,( c) MLOps由数据工程师的独立部门处理。这些额外津贴给了我自由，让我可以专注于我最喜欢的事情——数据建模。话虽如此，如果我不得不独自完成一个完整的项目，我总是想至少学习一些基础知识。这正是这篇文章背后的动机。</p><p id="f23e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我决定实施一个端到端<strong class="kt jd"> DL </strong>项目，因为存在一些主要与他们的部署相关的挑战——由于我们必须处理的模型的大小——以及对模型进行微调以适应我们特定的用例。</p><p id="29de" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">该项目将包括三个部分:</p><ul class=""><li id="f5d1" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm nh ni nj nk bi translated">第1部分:设置(虚拟环境、训练数据集等。)、模型训练(用Keras微调、学习曲线监控等。)，测试。</li><li id="265d" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">第2部分:构建Flask应用程序并在Heroku上部署。</li></ul><p id="c3d3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这个由两部分组成的系列的目的是为您提供源代码、提示、技巧，并熟悉使用深度学习模型时常见的运行时错误。我确信这些在<a class="ae lo" rel="noopener" target="_blank" href="/step-by-step-guide-to-explaining-your-ml-project-during-a-data-science-interview-81dfaaa408bf">在数据科学面试</a>中解释项目时会派上用场。</p><p id="90a5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">提醒:这篇文章(以及后续文章)中的一些内容将会被详细讨论，因为它的目的是让人们(尤其是早期研究人员)理解一些设计决策背后的原因/利弊，并在面试中完美地回答这些问题。</em></p><div class="nq nr gp gr ns nt"><a href="https://github.com/V-Sher/house-interior-prediction" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jd gy z fp ny fr fs nz fu fw jc bi translated">GitHub-V-Sher/房屋内部预测</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">github.com</p></div></div><div class="oc l"><div class="od l oe of og oc oh lz nt"/></div></div></a></div><h1 id="1d58" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">第1部分:设置</h1><h2 id="0ae0" class="oi mg it bd mh oj ok dn ml ol om dp mp la on oo mr le op oq mt li or os mv iz bi translated">虚拟环境</h2><p id="d01d" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">使用终端，在项目目录中创建一个名为<code class="fe ot ou ov ow b">e2eproject</code>的虚拟环境，并激活它。</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="c9ed" class="oi mg it ow b gy pb pc l pd pe">python3 -m venv e2eproject<br/>source e2eproject/bin/activate</span></pre><h2 id="2e97" class="oi mg it bd mh oj ok dn ml ol om dp mp la on oo mr le op oq mt li or os mv iz bi translated">资料组</h2><p id="b176" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">我们将使用Kaggle公开发布的<a class="ae lo" href="https://www.kaggle.com/robinreni/house-rooms-image-dataset" rel="noopener ugc nofollow" target="_blank">房子房间数据集</a>。</p><p id="0d96" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">您可以手动下载它，然后将它移动到您的项目目录<em class="ln">或</em>中。在终端中使用以下命令将它直接下载到您的项目目录中。<br/> <em class="ln">附注:在运行以下命令之前，确保您在项目目录中。</em></p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="e1f0" class="oi mg it ow b gy pb pc l pd pe">kaggle datasets download -d robinreni/house-rooms-image-dataset — unzip</span></pre><h2 id="d9a1" class="oi mg it bd mh oj ok dn ml ol om dp mp la on oo mr le op oq mt li or os mv iz bi translated">工作</h2><p id="c6ae" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">我们将致力于<strong class="kt jd">图像分类任务</strong>。具体来说，我们将开发一个模型，该模型可以检测给定卧室图像的房屋内部是<em class="ln">现代(M类)</em>还是<em class="ln">古老(O类)</em>。这种模型可以在再抵押期间或在出售财产时用于财产估价。</p><p id="b8c2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">你可能已经注意到了，这个数据集是没有标签的，然而，我的一个朋友慷慨地提供了大约450张图片的手工标签。(标签已在Github repo中提供。)尽管这不是一个很大的数据集规模，但我们仍然能够在保留的测试集上达到几乎80%的准确率。此外，用于微调、改进模型度量等的适当技术。以确定是否值得花费更多的时间来标记额外的数据点。</p><h1 id="9240" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">第二部分:模特培训</h1><p id="3514" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">让我们创建<code class="fe ot ou ov ow b">model.ipynb</code>笔记本。</p><h2 id="b442" class="oi mg it bd mh oj ok dn ml ol om dp mp la on oo mr le op oq mt li or os mv iz bi translated">装置</h2><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="4e78" class="oi mg it ow b gy pb pc l pd pe">from tensorflow.keras.preprocessing.image import ImageDataGenerator<br/>from tensorflow.keras.applications import EfficientNetB0<br/>from tensorflow.keras.callbacks import EarlyStopping<br/>from tensorflow.keras.callbacks import ModelCheckpoint<br/>from tensorflow.keras.layers import BatchNormalization<br/>from tensorflow.keras.layers import Dropout<br/>from tensorflow.keras.layers import Dense<br/>from tensorflow.keras.layers import Input<br/>from tensorflow.keras.optimizers import Adam<br/>from tensorflow.keras.models import Model</span><span id="f4d4" class="oi mg it ow b gy pf pc l pd pe">from sklearn.metrics import classification_report, confusion_matrix<br/>from sklearn.model_selection import train_test_split<br/>from imutils import paths<br/>from tqdm import tqdm</span><span id="d9fd" class="oi mg it ow b gy pf pc l pd pe">import matplotlib.pyplot as plt<br/>import numpy as np<br/>import tensorflow as tf<br/>import seaborn as sns<br/>import numpy as np<br/>import shutil<br/>import os</span></pre><p id="5a8c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">注意:你可能需要做一些</em> <code class="fe ot ou ov ow b"><em class="ln">pip install XXX</em></code> <em class="ln">来让上面的单元格工作。</em></p><h2 id="a27d" class="oi mg it bd mh oj ok dn ml ol om dp mp la on oo mr le op oq mt li or os mv iz bi translated">辅助变量和函数</h2><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="bf71" class="oi mg it ow b gy pb pc l pd pe">ORIG_INPUT_DATASET = "House_Room_Dataset/Bedroom"</span><span id="3de1" class="oi mg it ow b gy pf pc l pd pe">TRAIN = "training"<br/>VAL = evaluation"<br/>TEST = "testing"</span><span id="4618" class="oi mg it ow b gy pf pc l pd pe">BASE_PATH = "dataset"<br/>BATCH_SIZE = 32<br/>CLASSES = ["Modern", "Old"]</span></pre><p id="a1df" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们将只处理卧室图片，因此<code class="fe ot ou ov ow b">ORIG_INPUT_DATASET</code>指向卧室子目录。<code class="fe ot ou ov ow b">BASE_PATH</code>是我们将存储图像的训练、测试和验证分割的目录的路径。这将是空的。</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="4e23" class="oi mg it ow b gy pb pc l pd pe"><em class="ln">def</em> plot_hist(<em class="ln">hist</em>, <em class="ln">metric</em>):<br/>     if <em class="ln">metric</em> == 'auc':<br/>            plt.plot(<em class="ln">hist</em>.history["auc"])<br/>            plt.plot(<em class="ln">hist</em>.history["val_auc"])</span><span id="416b" class="oi mg it ow b gy pf pc l pd pe">     else:<br/>            plt.plot(<em class="ln">hist</em>.history["loss"])<br/>            plt.plot(<em class="ln">hist</em>.history["val_loss"])</span><span id="1791" class="oi mg it ow b gy pf pc l pd pe">     plt.style.use("ggplot")<br/>     plt.title("model {}".format(<em class="ln">metric</em>))<br/>     plt.ylabel("{}".format(<em class="ln">metric</em>))<br/>     plt.xlabel("epoch")<br/>     plt.legend(["train", "validation"], <em class="ln">loc</em>="upper left")<br/>     plt.show()</span></pre><p id="e892" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这是一些样板代码，用于绘制两种类型的学习曲线——AUC对epoch和loss对epoch。</p><p id="3fd1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">注意:如果您使用的是除</em> <code class="fe ot ou ov ow b"><em class="ln">auc</em></code> <em class="ln">之外的指标，比如说</em> <code class="fe ot ou ov ow b"><em class="ln">accuracy</em></code> <em class="ln">，请确保将上面代码片段中的</em> <code class="fe ot ou ov ow b"><em class="ln">auc</em></code> <em class="ln">更新为</em> <code class="fe ot ou ov ow b"><em class="ln">accuracy</em></code> <em class="ln">，将</em> <code class="fe ot ou ov ow b"><em class="ln">val_auc</em></code> <em class="ln">更新为</em> <code class="fe ot ou ov ow b"><em class="ln">val_accuracy</em></code> <em class="ln">。</em></p><h2 id="c71a" class="oi mg it bd mh oj ok dn ml ol om dp mp la on oo mr le op oq mt li or os mv iz bi translated">加载标签</h2><p id="c4a1" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">(<code class="fe ot ou ov ow b"><a class="ae lo" href="https://github.com/V-Sher/house-interior-prediction/blob/main/labels.txt" rel="noopener ugc nofollow" target="_blank">labels.txt</a></code>已作为回购的一部分。)</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="6624" class="oi mg it ow b gy pb pc l pd pe"><em class="ln"># Reading labels from the txt file</em><br/>with open("labels.txt", 'r') as f:<br/>      manual_labels = f.read()</span><span id="52b5" class="oi mg it ow b gy pf pc l pd pe"><em class="ln"># Extracting individual labels into a list</em><br/>labels = [i for i in manual_labels]<br/>len(labels)</span><span id="8033" class="oi mg it ow b gy pf pc l pd pe">********* OUTPUT **********<br/>451</span></pre><p id="1069" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">要检查数据集是否平衡:</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="d78d" class="oi mg it ow b gy pb pc l pd pe">from collections import Counter</span><span id="588d" class="oi mg it ow b gy pf pc l pd pe">print(Counter(labels).keys()) <br/>print(Counter(labels).values())</span><span id="1e81" class="oi mg it ow b gy pf pc l pd pe">********* OUTPUT **********<br/><em class="ln">dict_keys(['O', 'M'])<br/>dict_values([271, 180])</em></span></pre><p id="b577" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">看起来在我们的数据集中，老房子比现代房子多(尽管差距不是很大)。因此，抛弃准确性并选择更适合处理类别不平衡的指标，即AUC(ROC曲线下面积)是有意义的。</p><h2 id="06d0" class="oi mg it bd mh oj ok dn ml ol om dp mp la on oo mr le op oq mt li or os mv iz bi translated">列车测试验证拆分</h2><p id="1db2" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">在我们进行分割之前，对文件名进行排序是很重要的，因为我们有第<em class="ln">个</em> 451图像的标签(在<code class="fe ot ou ov ow b">House_Room_Dataset/Bedroom </code>子目录中),而不仅仅是随机的451图像。默认情况下，<code class="fe ot ou ov ow b">os.listdir()</code>以随机的顺序返回文件，我们不应该依赖它。</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="2c30" class="oi mg it ow b gy pb pc l pd pe"><em class="ln"># sorting files in the order they appear</em><br/>files = os.listdir(ORIG_INPUT_DATASET)<br/>files.sort(<em class="ln">key</em>=<em class="ln">lambda</em> <em class="ln">f</em>: <em class="ln">int</em>(f.split('_')[1].split('.')[0]))</span><span id="d2bd" class="oi mg it ow b gy pf pc l pd pe"># checking to see the correct file order<br/>files[:5]</span><span id="c92a" class="oi mg it ow b gy pf pc l pd pe">********* OUTPUT **********<br/>['bed_1.jpg', 'bed_2.jpg', 'bed_3.jpg', 'bed_4.jpg', 'bed_8.jpg']</span></pre><p id="46bf" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在我们知道我们有正确的451张图片，让我们继续进行训练-测试-验证分割。我们将分别分配大约75%、15%和10%的数据用于训练、验证和测试。</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="2440" class="oi mg it ow b gy pb pc l pd pe"><em class="ln"># splitting files into train and test sets</em><br/>trainX, testX, trainY, testY =  train_test_split(files[:len(labels)], <br/>                 labels, <br/>                 <em class="ln">stratify</em>=labels, <br/>                 <em class="ln">train_size</em>=0.90)</span><span id="2d24" class="oi mg it ow b gy pf pc l pd pe"><em class="ln"># further splitting of train set into train and val sets</em><br/>trainX, valX, trainY, valY = train_test_split(trainX, trainY, <em class="ln">stratify</em>=trainY, <em class="ln">train_size</em>=0.85)</span><span id="e75f" class="oi mg it ow b gy pf pc l pd pe"><em class="ln"># Checking the size of train, test, eval</em><br/>len(trainX), len(trainY), len(valX), len(valY),  len(testX), len(testY)</span><span id="337e" class="oi mg it ow b gy pf pc l pd pe">********* OUTPUT **********<br/>(344, 344, 61, 61, 46, 46)</span></pre><p id="79b8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">使用Sklearn的<code class="fe ot ou ov ow b">train_test_split()</code>方法，我们首先将整个数据集分割成训练集和测试集，然后将训练数据再次分割成训练集和验证集。由<code class="fe ot ou ov ow b">labels</code>到<code class="fe ot ou ov ow b">stratify</code>是很重要的，因为我们想要在所有三个集合(训练、测试和验证)中按比例分配现代和旧图像。</p><h2 id="5f4d" class="oi mg it bd mh oj ok dn ml ol om dp mp la on oo mr le op oq mt li or os mv iz bi translated">构建训练数据集目录</h2><p id="4262" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">在代码的后面，您会注意到，在训练期间，我们不会将整个数据集加载到内存中。相反，我们将利用Keras的<code class="fe ot ou ov ow b"><a class="ae lo" href="https://keras.io/api/preprocessing/image/" rel="noopener ugc nofollow" target="_blank">.flow_from_directory()</a></code>功能来实现批处理。但是，该函数希望数据被组织到如下目录中:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi pg"><img src="../Images/435a64a579810c024684c05037833156.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fYK6t2VBCwjopiUolZMTGw.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated"><em class="ph">图Keras中批量读取图像的目录结构。M级</em>和O级<em class="ph">分别指<em class="ph">现代</em>和<em class="ph">旧</em>。</em></p></figure><p id="ea72" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了让我们的图像文件以上述格式组织起来，我们将使用下面这个简短的片段:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="pi pj l"/></div></figure><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi pk"><img src="../Images/cd619b57a6eb9cc82e2a61da33e33ce3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZyI8p63b1eSSZTGWnVojpA.png"/></div></div></figure><p id="fce6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">当代码片段运行时，您应该能够使用 <code class="fe ot ou ov ow b"><a class="ae lo" rel="noopener" target="_blank" href="/data-scientists-guide-to-efficient-coding-in-python-670c78a7bf79">tqdm</a></code> <a class="ae lo" rel="noopener" target="_blank" href="/data-scientists-guide-to-efficient-coding-in-python-670c78a7bf79">模块</a>看到进度，一旦它完成，您将发现创建了三个新的子目录— <code class="fe ot ou ov ow b">dataset/training</code>、<code class="fe ot ou ov ow b">dataset/evaluation</code>和<code class="fe ot ou ov ow b">dataset/validation</code>，在每个子目录中，将有两个子子目录，分别用于现代和古老的房屋。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/8beb36ec1ab55ccf04075afd00c4c285.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*JYKKFvX1NONG2Jyw5qYhGg.png"/></div></figure><p id="9877" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">作为健全性检查，让我们看看在每个子目录中有预期数量的图像。</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="5917" class="oi mg it ow b gy pb pc l pd pe">trainPath = os.path.join(BASE_PATH, TRAIN)<br/>valPath = os.path.join(BASE_PATH, VAL)<br/>testPath = os.path.join(BASE_PATH, TEST)</span><span id="dd02" class="oi mg it ow b gy pf pc l pd pe">totalTrain = len(<em class="ln">list</em>(paths.list_images(trainPath)))<br/>totalVal = len(<em class="ln">list</em>(paths.list_images(valPath)))<br/>totalTest = len(<em class="ln">list</em>(paths.list_images(testPath)))</span><span id="733f" class="oi mg it ow b gy pf pc l pd pe">print(totalTrain, totalTest, totalVal)</span><span id="f546" class="oi mg it ow b gy pf pc l pd pe">********** OUTPUT *******<br/>344 46 61</span></pre><p id="f5e8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">注意:如果您的自定义数据是下面描述的结构，有一个有用的python包叫做</em><a class="ae lo" href="https://github.com/jfilter/split-folders" rel="noopener ugc nofollow" target="_blank"><em class="ln">split _ folders</em></a><em class="ln">可以用来获取图1中定义的目录结构中的数据。</em></p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="5f3a" class="oi mg it ow b gy pb pc l pd pe">dataset/<br/>    class1/<br/>        img1.jpg<br/>        img2.jpg<br/>        ...<br/>    class2/<br/>        img3.jpg<br/>        ...<br/>    ...</span></pre><h2 id="41fb" class="oi mg it bd mh oj ok dn ml ol om dp mp la on oo mr le op oq mt li or os mv iz bi translated">图像预处理</h2><p id="05f9" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">因为我们处理的样本量相当有限，所以通常建议使用旋转、缩放、平移等方法随机放大图像。</p><blockquote class="pm pn po"><p id="cb13" class="kr ks ln kt b ku kv kd kw kx ky kg kz pp lb lc ld pq lf lg lh pr lj lk ll lm im bi translated">虽然认为数据扩充增加了可用的训练数据量可能很诱人，但它实际上做的是获取训练样本并对其应用随机变换[ <a class="ae lo" href="https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/" rel="noopener ugc nofollow" target="_blank">来源</a> ]。总体而言，样本量保持不变。</p></blockquote><p id="3bd7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">Keras允许亮度，旋转，缩放，剪切等随机增强。使用<a class="ae lo" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" rel="noopener ugc nofollow" target="_blank">图像数据生成器</a>，最好的部分是所有这些都是在模型拟合过程中动态完成<em class="ln"/>，也就是说，您不需要预先计算它们。</p><p id="1d6a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">训练数据扩充</strong>:</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="7299" class="oi mg it ow b gy pb pc l pd pe">trainAug = ImageDataGenerator(<br/><em class="ln">rotation_range</em>=90,<br/><em class="ln">zoom_range</em>=[0.5, 1.0],<br/><em class="ln">width_shift_range</em>=0.3,<br/><em class="ln">height_shift_range</em>=0.25,<br/><em class="ln">shear_range</em>=0.15,<br/><em class="ln">horizontal_flip</em>=True,<br/><em class="ln">fill_mode</em>="nearest",<br/><em class="ln">brightness_range</em>=[0.2, 1.0]<br/>)</span></pre><p id="a1ea" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><code class="fe ot ou ov ow b">width_shift</code>、<code class="fe ot ou ov ow b">height_shift</code>、<code class="fe ot ou ov ow b">zoom_range</code>、<code class="fe ot ou ov ow b">rotation_range</code>等大部分参数应该是直观的(如果没有，看一下<em class="ln">官方Keras </em> <a class="ae lo" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#args" rel="noopener ugc nofollow" target="_blank"> <em class="ln">文档</em> </a> <em class="ln"> ) </em>。</p><p id="ef1d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">需要注意的重要一点是，当您执行缩放或旋转操作时，图像中可能会产生一些空白区域/像素，必须使用<code class="fe ot ou ov ow b">fill_mode</code>中提到的适当技术进行填充。</p><p id="6311" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">验证数据扩充</strong>:</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="4b45" class="oi mg it ow b gy pb pc l pd pe">valAug = ImageDataGenerator()</span></pre><p id="ed12" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">您将会看到，在为验证数据初始化数据扩充对象时，我们没有提供任何参数。这意味着我们将对它们都使用默认值，即0。换句话说，我们没有应用任何扩展(没有缩放，宽度移动，水平翻转，等等。)添加到验证集，因为在训练期间评估模型时，该集应被视为测试集。</p><p id="f7a8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">测试数据扩充:</strong></p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="af69" class="oi mg it ow b gy pb pc l pd pe">testAug = ImageDataGenerator()</span></pre><p id="9761" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">遵循与上面相同的逻辑，我们没有对测试集应用任何扩充。</p><p id="b045" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">创建数据生成器</strong></p><p id="36b3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如前所述，我们需要创建一些数据生成器，以便在训练期间将这些增强图像成批地提供给模型。为此，我们可以使用<code class="fe ot ou ov ow b"><a class="ae lo" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory" rel="noopener ugc nofollow" target="_blank">flow_from_directory()</a></code> <a class="ae lo" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory" rel="noopener ugc nofollow" target="_blank">发生器函数</a>。</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="9749" class="oi mg it ow b gy pb pc l pd pe"><em class="ln"># Create training batches whilst creating augmented images on the fly</em></span><span id="3dd7" class="oi mg it ow b gy pf pc l pd pe">trainGen = trainAug.flow_from_directory(<br/><em class="ln">directory</em>=trainPath,<br/><em class="ln">target_size</em>=(224,224),<br/><em class="ln">save_to_dir</em>='dataset/augmented/train',<br/><em class="ln">save_prefix</em>='train',<br/><em class="ln">shuffle</em>=True<br/>)</span><span id="f110" class="oi mg it ow b gy pf pc l pd pe"><em class="ln"># Create val batches </em></span><span id="73e3" class="oi mg it ow b gy pf pc l pd pe">valGen = valAug.flow_from_directory(<br/><em class="ln">directory</em>=valPath,<br/><em class="ln">target_size</em>=(224,224),<br/><em class="ln">shuffle</em>=True<br/>)</span></pre><p id="900c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">需要考虑的几件重要事情:</p><ul class=""><li id="61fe" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm nh ni nj nk bi translated">在每种情况下，<code class="fe ot ou ov ow b">directory</code>被设置为训练(或验证)图像所在的路径。</li><li id="305a" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">将<code class="fe ot ou ov ow b">target_size</code>指定为<code class="fe ot ou ov ow b">(224,224)</code>可以确保所有图像都将被调整到这个尺寸。</li><li id="f42a" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">我们还将把<code class="fe ot ou ov ow b">save_to_dir</code>设置为保存增强图像(前缀在<code class="fe ot ou ov ow b">save_prefix</code>中指定)的目录路径，这些图像将在训练过程中动态创建。这提供了一个很好的健全性检查，以查看图像是否得到了应有的随机变换。<em class="ln">注意:如果你想事先检查一下，也就是在训练开始之前，这里有一个我在</em><a class="ae lo" href="https://stackoverflow.com/questions/63818153/does-keras-imagedatagenerator-randomly-apply-transformations-to-every-image" rel="noopener ugc nofollow" target="_blank"><em class="ln">stack overflow</em></a><em class="ln">上找到的快速片段。</em></li><li id="df0f" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">最后，<code class="fe ot ou ov ow b">shuffle</code>被设置为<code class="fe ot ou ov ow b">True</code>,因为我们希望样本在批处理生成器中被混洗，这样当<code class="fe ot ou ov ow b">model.fit()</code>请求一个批处理时，就会给出随机样本。这样做将确保不同时期之间的批次看起来不一样，并最终使模型更加健壮。</li></ul><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="c49d" class="oi mg it ow b gy pb pc l pd pe"><em class="ln"># Create test batches</em></span><span id="d4e6" class="oi mg it ow b gy pf pc l pd pe">testGen = testAug.flow_from_directory(<br/><em class="ln">directory</em>=testPath,<br/><em class="ln">target_size</em>=(224,224),<br/><em class="ln">shuffle</em>=False<br/>)</span></pre><p id="208e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">除了为<code class="fe ot ou ov ow b">testGen</code>设置正确的<code class="fe ot ou ov ow b">directory</code>路径，还有一件主要的事情需要考虑:</p><ul class=""><li id="85ef" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm nh ni nj nk bi translated"><code class="fe ot ou ov ow b">shuffle</code>必须设置为<code class="fe ot ou ov ow b">False</code>。</li></ul><p id="e9cb" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">你问，为什么？<br/> 因为，现在<strong class="kt jd">我们不希望样本在测试批次生成器</strong>中被混洗。只有当shuffle设定为False时，才会按照提供的文件名称的顺序创建批处理。在模型评估期间，需要将文件名(即真实标签，可使用<code class="fe ot ou ov ow b"><em class="ln">testGen.classes</em></code>访问)与预测标签进行匹配。</p><p id="c39b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">有趣的事实:如果你现在检查</em> <code class="fe ot ou ov ow b"><em class="ln">trainGen.classes</em></code> <em class="ln">的输出，希望它们被打乱，你会失望的。为什么？因为当在模型拟合期间请求一个批次时，洗牌是动态发生的。【</em><a class="ae lo" href="https://stackoverflow.com/questions/60927259/keras-flow-from-directory-shuffle-not-working-properly" rel="noopener ugc nofollow" target="_blank"><em class="ln">stack overflow</em></a><em class="ln">】。</em></p><h2 id="094b" class="oi mg it bd mh oj ok dn ml ol om dp mp la on oo mr le op oq mt li or os mv iz bi translated">训练过程背后的直觉</h2><p id="420f" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">我们可以从头开始训练一个模型，但这肯定会表现不佳——主要是因为我们的数据集如此之小。在这种情况下，利用<strong class="kt jd">迁移学习</strong>的力量是有意义的。</p><blockquote class="pm pn po"><p id="0efe" class="kr ks ln kt b ku kv kd kw kx ky kg kz pp lb lc ld pq lf lg lh pr lj lk ll lm im bi translated">迁移学习是指在新数据集上微调预训练模型的过程。这使它能够识别从未训练过的类！</p></blockquote><p id="c9e9" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">简而言之，迁移学习允许我们利用模型在训练中获得的知识来识别狗和猫，这样它现在可以用来预测房子内部是否现代。</p><p id="e802" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">但是它为什么会起作用呢？ <br/>因为我们挑选的任何基础模型(即预训练模型)通常都是在如此大的图像语料库上训练的，所以一般来说，它能够学习图像的良好矢量表示。剩下要做的就是在区分定制类时使用这些表示(在我们的例子中，是老房子还是现代房子)。</p><p id="9f61" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">鸣谢:我想花点时间对我在这篇文章的研究阶段发现的几个博客(</em> <a class="ae lo" href="https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/" rel="noopener ugc nofollow" target="_blank"> <em class="ln">这个</em> </a> <em class="ln">，</em> <a class="ae lo" href="https://www.pyimagesearch.com/2019/06/03/fine-tuning-with-keras-and-deep-learning/" rel="noopener ugc nofollow" target="_blank"> <em class="ln">这个</em> </a>，<em class="ln"/><a class="ae lo" rel="noopener" target="_blank" href="/a-bunch-of-tips-and-tricks-for-training-deep-neural-networks-3ca24c31ddc8"><em class="ln">这个</em> </a> <em class="ln">)大声疾呼。这些被证明是真正的瑰宝，帮助我详细理解了迁移学习的概念。我真的很感激你所有的见解，这些见解让我为我的读者简化了代码/解释。</em></p><p id="188d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">使用Keras进行迁移学习</strong></p><p id="de24" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">迁移学习包括两个主要步骤:</p><ul class=""><li id="454f" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm nh ni nj nk bi translated"><strong class="kt jd">特征提取</strong>:将一个预先训练好的模型(并冻结其权重)作为基础模型，然后在基础模型上训练一个新的分类器*，使其准确输出N个值(其中N为类别数)。</li><li id="1add" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated"><strong class="kt jd">【可选】微调</strong>:一旦训练好分类器，从基础模型中解冻几个**层，使其很好地适应新的数据集。</li></ul><p id="2166" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">*新的分类器可以是:</p><ul class=""><li id="9221" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm nh ni nj nk bi translated">密集层的堆叠(即完全连接的层)。</li></ul><p id="d9e1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">运筹学</p><ul class=""><li id="0b31" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm nh ni nj nk bi translated">单个全局池层(将整个要素地图缩小为单个值— <code class="fe ot ou ov ow b">maxpool</code>、<code class="fe ot ou ov ow b">avgpool</code>)。这是优选的，因为有0个参数需要优化(因此是本文的选择)，所以过度拟合较少。</li></ul><p id="571d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">**根据您的数据集与预训练模型最初训练时的数据集的不同程度，少数会有所不同。请记住，如果两个数据集非常相似，那么只解冻所有图层的一部分可能会有所帮助。</p><p id="118d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">微调步骤虽然是可选的，但对于自定义数据集与训练基本模型的数据集完全不同的用例来说，这一步非常重要。此外，与特征提取步骤相比，这可能需要更多的历元。因为更多的时期粗略地转化为更高的过拟合机会，所以建议在仔细监控损失/精度曲线之后使用(模型训练的)早期停止。</p><p id="fb43" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">型号选择背后的直觉</strong></p><p id="4f25" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">回到这个百万美元的问题——我们应该选择哪个模型作为微调的基础模型？显然，有相当多的选项可用，可以在Keras文档中找到<a class="ae lo" href="https://keras.io/api/applications/#available-models" rel="noopener ugc nofollow" target="_blank">这里</a>。虽然我最初的选择是ResNet-50，因为它很受欢迎，但我最终决定继续使用<a class="ae lo" href="https://keras.io/api/applications/efficientnet/" rel="noopener ugc nofollow" target="_blank"> <strong class="kt jd"> EfficientNet </strong> </a>，因为它们可以<a class="ae lo" href="https://arxiv.org/pdf/1905.11946v5.pdf" rel="noopener ugc nofollow" target="_blank">实现与SOTA型号类似的结果，同时需要更少的FLOPS </a>。此外，<a class="ae lo" href="https://arxiv.org/pdf/1905.11946v5.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>提到它们的<strong class="kt jd">性能在</strong> <strong class="kt jd">迁移学习任务</strong>上与SOTA模型不相上下，同时平均需要的参数少9.6倍。哇哦⭐️</p><p id="ebbb" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">EfficientNet模型有很多种(EfficientNetB0、EfficientNetB1、…… EfficientB7)，它们在架构(即网络深度、宽度)和资源限制方面略有不同。这些模型中的每一个都需要特定图像形状的图像，如本<a class="ae lo" href="https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/#keras-implementation-of-efficientnet" rel="noopener ugc nofollow" target="_blank">表</a>中所述。鉴于我们正在使用<code class="fe ot ou ov ow b">224x224</code>分辨率的图像，我们将使用<strong class="kt jd"> EfficientNetB0。</strong></p><h2 id="1009" class="oi mg it bd mh oj ok dn ml ol om dp mp la on oo mr le op oq mt li or os mv iz bi translated"><strong class="ak">特征提取步骤的模型训练</strong></h2><p id="d0df" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated"><em class="ln">注意:在本教程中，我们将使用Tensorflow的Keras API。如果您是Keras新手，我已经写了两个初级Keras教程(</em><a class="ae lo" rel="noopener" target="_blank" href="/beginners-guide-to-building-artificial-neural-networks-using-keras-in-python-bdc4989dab00"><em class="ln">part 1</em></a><em class="ln">，</em><a class="ae lo" rel="noopener" target="_blank" href="/beginners-guide-to-building-convolutional-neural-networks-using-tensorflow-s-keras-api-in-python-6e8035e28238"><em class="ln">part 2</em></a><em class="ln">)，内容涵盖了网络架构、神经元、激活函数、隐藏层(密集、下降、最大池、展平)等，比这里讨论的要详细得多。请随时参考他们的快速复习！</em></p><p id="d898" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们从使用<code class="fe ot ou ov ow b">imagenet</code>权重创建一个<code class="fe ot ou ov ow b">EfficientNetB0</code>基础模型开始。</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="a8a6" class="oi mg it ow b gy pb pc l pd pe">baseModel = EfficientNetB0(<br/>            <em class="ln">weights</em>="imagenet",<br/>            <em class="ln">include_top</em>=False, # make sure top layer is not included<br/>            <em class="ln">input_tensor</em>=Input(<em class="ln">shape</em>=(224, 224, 3)),<br/>            <em class="ln">pooling</em>="avg"<br/>           )</span></pre><p id="8100" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">需要考虑的事情很少:</p><ul class=""><li id="9462" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm nh ni nj nk bi translated"><code class="fe ot ou ov ow b">include_top</code>必须设置为<code class="fe ot ou ov ow b">False</code>，因为EfficientNet网络架构中的顶层(即最终层)是一个<code class="fe ot ou ov ow b">Dense</code>层，它输出1000个对应于ImageNet数据集的类。我们显然不需要这个！</li><li id="3220" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">如果您没记错的话，我们选择新的分类器作为全局池层(而不是密集层的堆栈)。好消息是，Keras API已经允许我们在实例化<code class="fe ot ou ov ow b">EfficientNetB0</code>对象的同时完成这个<em class="ln">。我们可以简单地将<code class="fe ot ou ov ow b">pooling</code>参数设置为<code class="fe ot ou ov ow b">avg</code>。默认为<code class="fe ot ou ov ow b">None</code>。</em></li></ul><p id="a41c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">下一步是通过将每层的<code class="fe ot ou ov ow b">trainable</code>设置为<code class="fe ot ou ov ow b">False</code>来冻结权重:</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="ca40" class="oi mg it ow b gy pb pc l pd pe"><em class="ln"># freeze the weights</em></span><span id="0f1a" class="oi mg it ow b gy pf pc l pd pe">for layer in baseModel.layers:<br/>      layer.trainable = False</span></pre><p id="c076" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在是时候在上面创建一个新的分类器了，它将准确地产生两个类(<code class="fe ot ou ov ow b">M</code>或<code class="fe ot ou ov ow b">O</code>)。为此，我们需要确保这个分类器模型的最后一层是具有两个输出神经元的<code class="fe ot ou ov ow b">Dense</code>层。在这两者之间，我们还包括了<code class="fe ot ou ov ow b">BatchNormalization</code>和<code class="fe ot ou ov ow b">Dropout</code>层，用于正则化。</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="a2b4" class="oi mg it ow b gy pb pc l pd pe"><em class="ln"># training a new classifier on top (Functional Keras Model)</em></span><span id="0133" class="oi mg it ow b gy pf pc l pd pe">x = baseModel.output<br/>Layer_1 = BatchNormalization()(x)<br/>Layer_2 = Dropout(0.5)(Layer_1)<br/>output_layer = Dense(len(CLASSES), <em class="ln">activation</em>="softmax")(Layer_2)</span><span id="7e69" class="oi mg it ow b gy pf pc l pd pe">model = Model(<em class="ln">inputs</em> = baseModel.input, <em class="ln">outputs</em> = output_layer)</span></pre><p id="cd3b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">注意:有两种方法可以建立这个Keras分类器模型:顺序的(最基本的)和功能的(对于具有多个输入/输出的复杂网络)。上面的代码片段是作为一个功能网络编写的，因为如果您使用</em> <code class="fe ot ou ov ow b"><em class="ln">model.summary()</em></code> <em class="ln">来检查它，它会使网络架构更加清晰。同样，我们可以创建一个类似下面的序列模型，结果将是相同的。</em></p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="f84c" class="oi mg it ow b gy pb pc l pd pe"><em class="ln"># Another way to create the classifier on top of basemodel</em></span><span id="a2ed" class="oi mg it ow b gy pf pc l pd pe">model = tf.keras.Sequential()<br/>model.add(baseModel)<br/>model.add(BatchNormalization())<br/>model.add(Dropout(0.5))<br/>model.add(Dense(len(CLASSES), activation="softmax"))</span></pre><p id="c133" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">最后，让我们用<code class="fe ot ou ov ow b">Adam</code>优化器和一个相对较大的<code class="fe ot ou ov ow b">learning_rate = 1e-3</code>来编译模型。由于我们有两个可能的输出类，我们将监控<code class="fe ot ou ov ow b">binary_crossentropy</code>损失(如果您处理两个以上的类，请使用<code class="fe ot ou ov ow b">categorical_crossentropy</code>)并根据<code class="fe ot ou ov ow b">tf.keras.metrics.AUC</code>中实现的AUC度量评估模型的有效性。</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="38f7" class="oi mg it ow b gy pb pc l pd pe"><em class="ln"># compile</em></span><span id="2b90" class="oi mg it ow b gy pf pc l pd pe">opt = Adam(<em class="ln">learning_rate</em>=1e-3)<br/>model.compile(<em class="ln">optimizer</em>=opt, <br/>              <em class="ln">loss</em>='binary_crossentropy', <br/>              <em class="ln">metrics</em>=[tf.keras.metrics.AUC()]<br/>              )</span></pre><p id="0e5b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在使用<code class="fe ot ou ov ow b">fit()</code>训练模型之前要做的最后一件事是实现<code class="fe ot ou ov ow b">EarlyStopping</code>和<code class="fe ot ou ov ow b">ModelCheckpoint</code>。</p><p id="29e4" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">前者将确保模型不会在不必要的情况下训练更多的时期。这是通过监控<code class="fe ot ou ov ow b">val_loss</code>来完成的，一旦没有进一步的改进，即不能进一步最小化，训练就停止。</p><p id="31fd" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">后者将在给定的文件路径中保存最佳模型——在我们的例子中是<code class="fe ot ou ov ow b">feature_extraction.h5</code>。我们将再次监控验证损失，并保存所有时期的最佳模型。</p><p id="5a4b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">注意:这里有一篇优秀的</em> <a class="ae lo" href="https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/" rel="noopener ugc nofollow" target="_blank"> <em class="ln">文章</em> </a> <em class="ln">更详细地解释了早期停止和模型检查点实现！</em></p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="6c68" class="oi mg it ow b gy pb pc l pd pe"><em class="ln"># implementing early stopping<br/></em>es = EarlyStopping(<br/>     <em class="ln">monitor</em>='val_loss',  #metric to monitor<br/>     <em class="ln">mode</em>='min',  # whether to min or max the metric monitored<br/>     <em class="ln">patience</em>=10, # epochs to wait before declaring stopped training<br/>     <em class="ln">verbose</em>=1  # output epoch when training was stopped<br/>     )</span><span id="6a3d" class="oi mg it ow b gy pf pc l pd pe"><em class="ln"># implementing model checkpoint<br/></em>mc = ModelCheckpoint(<br/>      'feature_extraction.h5',<br/>       <em class="ln">monitor</em>='val_loss',<br/>       <em class="ln">mode</em>='min',<br/>       <em class="ln">verbose</em>=1, # display epoch+accuracy everytime model is saved<br/>       <em class="ln">save_best_only</em>=True<br/>      )</span></pre><p id="db93" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">最后，是模型训练的时候了:</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="e497" class="oi mg it ow b gy pb pc l pd pe"><em class="ln"># Training the model</em></span><span id="9186" class="oi mg it ow b gy pf pc l pd pe">hist = model.fit(<br/>       <em class="ln">x</em>=trainGen,<br/>       <em class="ln">epochs</em>=25,<br/>       <em class="ln">verbose</em>=2,<br/>       <em class="ln">validation_data</em>=valGen,<br/>       <em class="ln">steps_per_epoch</em>=totalTrain // BATCH_SIZE,<br/>       <em class="ln">callbacks</em>=[es, mc]<br/>      )</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ps"><img src="../Images/8be64a1b56cff0d5ba85befea04db80e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D8Klv_ZGlBa1ehSFvQdVjw.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">最终时期的损失和AUC分数</p></figure><p id="c172" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">快速看一下AUC和损失曲线，我们可以找到模型收敛的证据(意味着模型已经准备好进行微调)。</p><div class="lq lr ls lt gt ab cb"><figure class="pt lu pu pv pw px py paragraph-image"><img src="../Images/5c449830a0e73f9fc7c37ae5b8ce5bad.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*krCZhiXrhZKRNxvO8smTxA.png"/></figure><figure class="pt lu pz pv pw px py paragraph-image"><img src="../Images/6832e8c30b0fd1bb27bc643249bd0bb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*Aej6vkEH0bcYfDYcDkcWrQ.png"/><p class="mb mc gj gh gi md me bd b be z dk qa di qb qc translated">AUC和损失的学习曲线</p></figure></div><p id="0e49" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">右图中一个有趣的观察结果是，我们的验证损失低于训练损失。起初，我认为有一些数据泄漏的问题，但后来我发现了这篇优秀的<a class="ae lo" href="https://www.pyimagesearch.com/2019/10/14/why-is-my-validation-loss-lower-than-my-training-loss/" rel="noopener ugc nofollow" target="_blank">文章</a>解释了为什么这是完全正常的，有时会在训练中发生。</p><p id="2a2d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">总结两个可能的原因(从文章本身):</p><ul class=""><li id="8829" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm nh ni nj nk bi translated">原因#1:正规化(如辍学)只适用于培训期间，而不是在验证期间。因为正则化牺牲训练精度来提高验证/测试精度，所以验证损失可以低于训练损失。</li><li id="1dc8" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">原因#2:我们的验证集太小(只有61幅图像)，也许它比训练集更容易，即<a class="ae lo" href="https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/#unrepresentative-validation-dataset" rel="noopener ugc nofollow" target="_blank">不具有代表性的验证数据集</a>。</li></ul><h2 id="1a27" class="oi mg it bd mh oj ok dn ml ol om dp mp la on oo mr le op oq mt li or os mv iz bi translated">特征提取步骤后的模型测试</h2><p id="4ab4" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">我们将使用一些样板代码来评估使用<code class="fe ot ou ov ow b">.predict()</code>获得的模型预测。记住<code class="fe ot ou ov ow b">predIdxs</code>将类似于<code class="fe ot ou ov ow b">[0.8, 0.2]</code>，即<code class="fe ot ou ov ow b">M</code>和<code class="fe ot ou ov ow b">O</code>两个类的softmax值，所以确保使用<code class="fe ot ou ov ow b">np.argmax</code>选择两个中的最大值。我们使用<code class="fe ot ou ov ow b">testGen.class_indices</code>来检查从类名到类索引的映射。</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="d364" class="oi mg it ow b gy pb pc l pd pe">testGen.reset()</span><span id="af8d" class="oi mg it ow b gy pf pc l pd pe">predIdxs = model.predict(<br/>             <em class="ln">x</em>=testGen,<br/>             <em class="ln">steps</em>=(totalTest // BATCH_SIZE) + 1<br/>            )</span><span id="1ac4" class="oi mg it ow b gy pf pc l pd pe">predIdxs = np.argmax(predIdxs, <em class="ln">axis</em> = 1)<br/>print("No. of test images", len(predIdxs))<br/>print(testGen.class_indices)</span><span id="384b" class="oi mg it ow b gy pf pc l pd pe">cm = confusion_matrix(testGen.classes, predIdxs)<br/>heatmap = sns.heatmap(cm, <em class="ln">annot</em>=True)<br/>plt.xlabel("Predicted")<br/>plt.ylabel("Actual")<br/>plt.show()</span><span id="133d" class="oi mg it ow b gy pf pc l pd pe">********* OUTPUT********<br/>No. of test images 46 <br/>{'M': 0, 'O': 1}</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi qd"><img src="../Images/dba1e0f6352300b87a4e8b44aa25bdd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*Iah-UvKRJUODCC9JsccGtg.png"/></div></figure><h2 id="eff1" class="oi mg it bd mh oj ok dn ml ol om dp mp la on oo mr le op oq mt li or os mv iz bi translated">微调步骤的模型训练</h2><p id="8bf5" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">我们将从解冻当前模型的最后几层开始，但是，我们不应该随意打开或关闭层。有许多技术和技巧可用于微调模型(例如，参见<a class="ae lo" href="https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/#tips-for-fine-tuning-efficientnet" rel="noopener ugc nofollow" target="_blank">这个</a>和<a class="ae lo" href="https://keras.io/guides/transfer_learning/#finetuning" rel="noopener ugc nofollow" target="_blank">这个</a>),但有一些是我发现最有用的:</p><ul class=""><li id="c575" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm nh ni nj nk bi translated">当在该步骤编译模型时，与特征提取步骤相比，使用甚至更小的学习速率。较小的学习速率意味着需要更多的历元，因为每次更新时网络权重的变化较小。</li><li id="7f54" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">这些层需要保持冷冻。</li><li id="98b8" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">在网络架构中，卷积块需要在整体 <strong class="kt jd">中打开或关闭<strong class="kt jd"/>。<br/>例如:考虑<code class="fe ot ou ov ow b">model.summary()</code>输出的最后几行。正如你所看到的，这些层被整齐地组织成块，最后一块是<code class="fe ot ou ov ow b">block7d</code>。首先，我们将解冻<code class="fe ot ou ov ow b">block7d</code>中的所有图层(然而，任何<code class="fe ot ou ov ow b">BathcNormalization</code>图层都将保持原样)以及随后的7个图层(其中大部分是我们在构建新的分类器头时定义的)。总的来说，网络的最后20层将是解冻的候选层。</strong></li></ul><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="e685" class="oi mg it ow b gy pb pc l pd pe">____________________________________________________________________<br/>Layer (type)                    Output Shape         Param #     ====================================================================<br/>                              .<br/>                              .<br/>                              .</span><span id="2294" class="oi mg it ow b gy pf pc l pd pe">block6d_project_conv (Conv2D)   (None, 7, 7, 192)    221184      ____________________________________________________________________</span><span id="471c" class="oi mg it ow b gy pf pc l pd pe">block6d_project_bn (BatchNormal (None, 7, 7, 192)    768     ____________________________________________________________________</span><span id="42ba" class="oi mg it ow b gy pf pc l pd pe">block6d_drop (Dropout)          (None, 7, 7, 192)    0           ____________________________________________________________________</span><span id="6764" class="oi mg it ow b gy pf pc l pd pe">block6d_add (Add)               (None, 7, 7, 192)    0           ____________________________________________________________________</span><span id="59a8" class="oi mg it ow b gy pf pc l pd pe">block7a_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184    </span><span id="2f58" class="oi mg it ow b gy pf pc l pd pe">____________________________________________________________________</span><span id="1cb6" class="oi mg it ow b gy pf pc l pd pe">block7a_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        ________________________________________________________________</span><span id="592f" class="oi mg it ow b gy pf pc l pd pe">block7a_expand_activation (Acti (None, 7, 7, 1152)   0           ____________________________________________________________________</span><span id="05ce" class="oi mg it ow b gy pf pc l pd pe">block7a_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   10368       </span><span id="5e5c" class="oi mg it ow b gy pf pc l pd pe">____________________________________________________________________</span><span id="d795" class="oi mg it ow b gy pf pc l pd pe">                              .<br/>                              .<br/>                              .</span></pre><p id="c170" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我已经将用于微调的代码捆绑到一个名为<code class="fe ot ou ov ow b">fine_tune_model()</code>的函数中。大部分代码是从特征提取步骤开始重复的。</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="ec53" class="oi mg it ow b gy pb pc l pd pe"><em class="ln">def</em> fine_tune_model(<em class="ln">model</em>):</span><span id="18f7" class="oi mg it ow b gy pf pc l pd pe"><em class="ln">     # unfreeze last conv block i.e. block7a <br/>     </em>for layer in <em class="ln">model</em>.layers[-20:]:<br/>          if not isinstance(layer, BatchNormalization):<br/>               layer.trainable = True</span><span id="2091" class="oi mg it ow b gy pf pc l pd pe"><em class="ln">     # check which of these are trainable and which aren't<br/></em>     for layer in <em class="ln">model</em>.layers:<br/>          print("{}: {}".format(layer, layer.trainable))</span><span id="7616" class="oi mg it ow b gy pf pc l pd pe"><em class="ln">     # compile (with an even smaller learning rate)<br/></em>     opt = Adam(<em class="ln">learning_rate</em>=1e-5)<br/><em class="ln">     model</em>.compile(<br/>             <em class="ln">optimizer</em>=opt,<br/>             <em class="ln">loss</em>='binary_crossentropy',<br/>             <em class="ln">metrics</em>=[tf.keras.metrics.AUC()]<br/>             )</span><span id="8887" class="oi mg it ow b gy pf pc l pd pe">      return <em class="ln">model</em></span><span id="4596" class="oi mg it ow b gy pf pc l pd pe">model_fine_tuned = fine_tune_model(model)</span></pre><p id="dec7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">因为微调也将使用相同的数据发生器，即<code class="fe ot ou ov ow b">trainGen</code>、<code class="fe ot ou ov ow b">valGen</code>和<code class="fe ot ou ov ow b">testGen</code>，所以重置它们以便它们从数据集中的第一个样本开始非常重要。</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="3a34" class="oi mg it ow b gy pb pc l pd pe">trainGen.reset()<br/>valGen.reset()<br/>testGen.reset()</span></pre><p id="e726" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">最后，让我们设置提前停止和模型检查点(注意，我们已经将<code class="fe ot ou ov ow b">patience</code>增加到20，因为我们现在将训练更长时间，即50 <code class="fe ot ou ov ow b">epochs</code>)，然后开始训练。</p><pre class="lq lr ls lt gt ox ow oy oz aw pa bi"><span id="0847" class="oi mg it ow b gy pb pc l pd pe"><em class="ln"># implementing early stopping<br/></em>es_tune = EarlyStopping(<br/>     <em class="ln">monitor</em>='val_loss', <br/>     <em class="ln">mode</em>='min',  <br/>     <em class="ln">patience</em>=20, <br/>     <em class="ln">verbose</em>=1  <br/>     )</span><span id="1216" class="oi mg it ow b gy pf pc l pd pe"><em class="ln"># implementing model checkpoint<br/></em>mc_tune = ModelCheckpoint(<br/>      'fine_tuned_house.h5',<br/>       <em class="ln">monitor</em>='val_loss',<br/>       <em class="ln">mode</em>='min',<br/>       <em class="ln">verbose</em>=1, <br/>       <em class="ln">save_best_only</em>=True<br/>      )</span><span id="defd" class="oi mg it ow b gy pf pc l pd pe">hist = model_fine_tuned.fit(<br/>      <em class="ln">x</em>=trainGen,<br/>      <em class="ln">steps_per_epoch</em>=totalTrain // BATCH_SIZE,<br/>      <em class="ln">validation_data</em>=valGen,<br/>      <em class="ln">epochs</em>=50,<br/>      <em class="ln">verbose</em>=2,<br/>      <em class="ln">callbacks</em>=[es_tune, mc_tune]<br/>     )</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi qe"><img src="../Images/a1c4636fca8efc60c166daedd428d32e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iFb_Mw8rQZBcJ-xro5Tgfw.png"/></div></div></figure><h2 id="ada2" class="oi mg it bd mh oj ok dn ml ol om dp mp la on oo mr le op oq mt li or os mv iz bi translated">特征提取步骤后的模型测试</h2><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi qd"><img src="../Images/5aff6fba1c3fcd15623afb4b1144603a.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*F8TesOg815E98EYwkzaGLg.png"/></div></figure><p id="c3a0" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">通过与之前的混淆矩阵进行比较，我们只成功地将正确预测的图像数量增加了2个(参见两张热图中的对角线值)。</p><p id="9719" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">作为最后的健全性检查，查看这个微调步骤是否显示出任何过度拟合的迹象也是很好的。</p><div class="lq lr ls lt gt ab cb"><figure class="pt lu qf pv pw px py paragraph-image"><img src="../Images/9aad78244a3b92f9199b4d56575a362b.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*S9kR3dMuq25DOiCaTtjFkA.png"/></figure><figure class="pt lu qf pv pw px py paragraph-image"><img src="../Images/55cf0a04a1eb6d7c33964e3844117cfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*STVhme7-wNnJJnQXTX4C7A.png"/></figure></div><p id="5861" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">验证损失</strong>不稳定，稳定在0.55左右，表明模型没有过度拟合。总的来说，验证集预测的<strong class="kt jd"> AUC </strong>确实随着更多的时期变得更好，但回报却在减少。(简单地说，更长时间的培训似乎不会对我们的案例有实质性的帮助)。</p><p id="93ef" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">起初，我认为训练曲线的波动是由于批量大小，因为它们在网络如何学习中发挥了作用。类似地，过大的学习速率会阻碍收敛，并导致损失函数波动，陷入局部最小值。然而，无论是增加批量还是降低学习率都无助于平滑梯度。</p><p id="de3f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">想到的另一种可能的解释是，网络已经达到了其关于给定数据集的容量，即，它不能再从中学习更多。这是可能的，因为我们正在尝试训练一个相对较大的网络(记住，我们已经解冻了一些额外的层，这意味着存在更多的可训练参数)，仅使用344个样本，这些样本无法提供足够的信息来学习问题(进一步)。</p><p id="af3b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">注意:在将更多图像推进训练过程以希望改进模型之前，可能值得对模型超参数、train:val分割、预训练权重的选择(来自</em> <a class="ae lo" href="https://github.com/google-research/noisystudent" rel="noopener ugc nofollow" target="_blank"> <em class="ln">嘈杂学生</em> </a> <em class="ln">训练的权重已知比来自ImageNet训练的权重更好</em><a class="ae lo" href="https://arxiv.org/pdf/1911.04252.pdf" rel="noopener ugc nofollow" target="_blank"><em class="ln"/></a><em class="ln">)以及网络架构本身进行修改。</em></p><h1 id="4a77" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">未来的工作</h1><p id="2818" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">在最近的<a class="ae lo" href="https://arxiv.org/pdf/1911.04252.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>和<a class="ae lo" href="https://youtu.be/q7PjrmGNx5A?t=2240" rel="noopener ugc nofollow" target="_blank">视频</a>中已经证实，使用未标记和标记数据集的联合训练优于管道，在管道中，我们首先使用未标记数据进行预训练，然后在标记数据上进行微调。这被称为半监督学习，将是我们下一个教程的重点。这将允许我们充分利用数据集中难以获得标签的剩余图像。</p></div><div class="ab cl qg qh hx qi" role="separator"><span class="qj bw bk qk ql qm"/><span class="qj bw bk qk ql qm"/><span class="qj bw bk qk ql"/></div><div class="im in io ip iq"><p id="d81b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">坚持了这么久，很值得称赞。🥂</p><p id="b200" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">前往<a class="ae lo" href="https://varshitasher.medium.com/deploying-an-end-to-end-deep-learning-project-with-few-clicks-part-2-89009cff6f16" rel="noopener">第2部分</a>了解如何将这个训练好的模型包装在flask应用程序中。我们还准备写一个又快又脏的前端，最后在Heroku上部署app。</p><p id="c815" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在那之前:)</p></div><div class="ab cl qg qh hx qi" role="separator"><span class="qj bw bk qk ql qm"/><span class="qj bw bk qk ql qm"/><span class="qj bw bk qk ql"/></div><div class="im in io ip iq"><p id="93a6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我喜欢写循序渐进的初学者指南、操作指南、面试问题、ML/AI中使用的解码术语等。如果你想完全访问我的所有文章(以及其他媒体上的文章)，那么你可以使用 <a class="ae lo" href="https://varshitasher.medium.com/membership" rel="noopener"> <strong class="kt jd"> <em class="ln">我的链接</em></strong></a><strong class="kt jd"><em class="ln"/></strong><em class="ln">这里</em> <strong class="kt jd"> <em class="ln">注册。</em> </strong></p><div class="nq nr gp gr ns nt"><a rel="noopener follow" target="_blank" href="/deploying-an-end-to-end-deep-learning-project-with-few-clicks-part-2-89009cff6f16"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jd gy z fp ny fr fs nz fu fw jc bi translated">通过几次点击部署端到端深度学习项目:第2部分</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">从Jupyter笔记本到Flask应用程序采用模型，使用Postman和Heroku部署测试API端点</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">towardsdatascience.com</p></div></div><div class="oc l"><div class="qn l oe of og oc oh lz nt"/></div></div></a></div><div class="nq nr gp gr ns nt"><a rel="noopener follow" target="_blank" href="/fine-tuning-hubert-for-emotion-recognition-in-custom-audio-data-using-huggingface-c2d516b41cd8"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jd gy z fp ny fr fs nz fu fw jc bi translated">检测语音数据中的情感:使用Huggingface微调HuBERT</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">构建自定义数据加载器、实验日志、改进指标的技巧和GitHub repo，如果您想了解…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">towardsdatascience.com</p></div></div><div class="oc l"><div class="qo l oe of og oc oh lz nt"/></div></div></a></div><div class="nq nr gp gr ns nt"><a href="https://varshitasher.medium.com/six-reasons-to-switch-to-this-podcast-app-today-3a396ada0a2b" rel="noopener follow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jd gy z fp ny fr fs nz fu fw jc bi translated">今天切换到这个播客应用程序的六个理由！</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">带上你的朋友。</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">varshitasher.medium.com</p></div></div><div class="oc l"><div class="qp l oe of og oc oh lz nt"/></div></div></a></div><div class="nq nr gp gr ns nt"><a rel="noopener follow" target="_blank" href="/understanding-python-imports-init-py-and-pythonpath-once-and-for-all-4c5249ab6355"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd jd gy z fp ny fr fs nz fu fw jc bi translated">了解Python导入，__init__。py和pythonpath —一劳永逸</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">了解如何导入包和模块(以及两者之间的区别)</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">towardsdatascience.com</p></div></div><div class="oc l"><div class="qq l oe of og oc oh lz nt"/></div></div></a></div></div></div>    
</body>
</html>