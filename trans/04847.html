<html>
<head>
<title>The Story of a Migration from EMR to Spark on Kubernetes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从EMR迁移到Kubernetes上Spark的故事</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-story-of-a-migration-from-emr-to-spark-on-kubernetes-a2decd6de0a4?source=collection_archive---------17-----------------------#2021-04-27">https://towardsdatascience.com/the-story-of-a-migration-from-emr-to-spark-on-kubernetes-a2decd6de0a4?source=collection_archive---------17-----------------------#2021-04-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="33dd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这篇文章中，Lingk的联合创始人讲述了他们从EMR迁移到由数据力学管理的Spark-on-Kubernetes平台的故事:他们的目标、解决方案的架构&amp;他们必须解决的挑战，以及他们获得的结果。</p><h1 id="b381" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">此次迁移的目标</h1><p id="411b" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated"><a class="ae lo" href="https://www.lingk.io" rel="noopener ugc nofollow" target="_blank"> Lingk.io </a>是一个数据加载、数据管道和集成平台，构建在<a class="ae lo" href="https://www.datamechanics.co/apache-spark" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>之上，服务于商业客户，拥有教育领域的专业知识。在他们的可视化界面上，只需点击几下鼠标，他们的客户就可以从几十个来源加载数据、消除重复数据和丰富数据。</p><p id="6d4c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在引擎盖下，Lingk使用AWS EMR ( <a class="ae lo" href="https://aws.amazon.com/emr" rel="noopener ugc nofollow" target="_blank"> ElasticMapReduce </a>)来驱动他们的产品。但是他们面临着一些问题:</p><ul class=""><li id="1d12" class="lp lq iq jp b jq jr ju jv jy lr kc ls kg lt kk lu lv lw lx bi translated">EMR要求他们的Devops团队进行过多的基础架构管理，而Spark经验有限。选择正确的集群实例类型、内存设置、spark配置等。</li><li id="c4ed" class="lp lq iq jp b jq ly ju lz jy ma kc mb kg mc kk lu lv lw lx bi translated">他们的AWS总成本很高，他们直觉认为EMR的自动缩放策略不是很有效，而且浪费了大量计算资源。</li><li id="1faf" class="lp lq iq jp b jq ly ju lz jy ma kc mb kg mc kk lu lv lw lx bi translated">Spark应用程序平均需要40秒才能启动。Lingk的最终用户需要等待很长时间，特别是如果他们正在建立一个新的数据管道或集成。</li><li id="87e2" class="lp lq iq jp b jq ly ju lz jy ma kc mb kg mc kk lu lv lw lx bi translated">核心Spark应用程序停留在早期版本，因为将Spark升级到3.0+导致了无法解释的性能退化。</li></ul><p id="41a1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">他们决定在数据机制的帮助下，迁移到Kubernetes上的Spark。他们此次迁移有三个目标:</p><ol class=""><li id="cf65" class="lp lq iq jp b jq jr ju jv jy lr kc ls kg lt kk md lv lw lx bi translated">降低他们的总基础设施成本</li><li id="65fb" class="lp lq iq jp b jq ly ju lz jy ma kc mb kg mc kk md lv lw lx bi translated">简化他们的数据团队运营工作</li><li id="3023" class="lp lq iq jp b jq ly ju lz jy ma kc mb kg mc kk md lv lw lx bi translated">改善Lingk平台的最终用户体验</li></ol><p id="1ff9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="me"> * </em> <a class="ae lo" href="https://www.datamechanics.co" rel="noopener ugc nofollow" target="_blank"> <em class="me">数据机制</em> </a> <em class="me">是一个云原生的Spark平台，可在AWS、GCP和Azure上使用。</em> <a class="ae lo" href="https://medium.com/r?url=https%3A%2F%2Ftowardsdatascience.com%2Fspark-on-kubernetes-the-easy-way-585e558abf59" rel="noopener"> <em class="me">阅读更多</em> </a> <em class="me">关于他们的服务以及它是如何建立在Spark-on-Kubernetes开源之上的。</em></p><h1 id="9427" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">迁移后的目标体系结构</h1><p id="8c7e" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">Lingk的新数据平台建立在长期运行的托管Kubernetes集群(EKS)之上，部署在他们的AWS帐户中。Data Mechanics负责管理该集群，从初始配置到长期维护(使用最新的Spark和Kubernetes更新来保持其最新状态)，并根据负载按需自动扩展。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mf"><img src="../Images/49b19d8cc2ef3120cafcfbf5e3cedf78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_diPSdzisuCOv-KM.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">lingk+数据力学架构。图片作者。</p></figure><p id="0bb1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">像Jupyter笔记本支持和气流集成这样的额外集成也是可能的，尽管在这种情况下，Lingk会使用Data Mechanics gateway公开的REST API简单地触发Spark作业。因此，Lingk的团队不再需要管理EMR集群，他们只需通过API提交Dockerized Spark应用程序，并享受无服务器的体验。</p><p id="68f8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该团队可以控制Spark使用的docker图像，这带来了3个额外的好处:</p><ol class=""><li id="687a" class="lp lq iq jp b jq jr ju jv jy lr kc ls kg lt kk md lv lw lx bi translated">应用程序启动速度更快，因为所有依赖项都在Docker映像中完成。</li><li id="2ab5" class="lp lq iq jp b jq ly ju lz jy ma kc mb kg mc kk md lv lw lx bi translated">CI/CD流程更简单—合并PR时会自动构建Docker映像。</li><li id="c9ae" class="lp lq iq jp b jq ly ju lz jy ma kc mb kg mc kk md lv lw lx bi translated">Docker映像包括Spark分发版本身(没有全局Spark版本)，这意味着所有应用程序都可以在同一个集群上高效运行，并且很容易逐步升级到Spark 3.0。</li></ol><p id="f488" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用Data Mechanics提供的一个<a class="ae lo" href="https://www.datamechanics.co/blog-post/optimized-spark-docker-images-now-available" rel="noopener ugc nofollow" target="_blank">公共Spark-on-Kubernetes docker映像</a>作为基础，很容易开始使用基于<a class="ae lo" href="https://www.datamechanics.co/blog-post/spark-and-docker-your-spark-development-cycle-just-got-ten-times-faster" rel="noopener ugc nofollow" target="_blank"> docker的开发工作流</a>，并打包所需的依赖项。</p><h1 id="5668" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">迁移过程中应对的挑战</h1><p id="6c88" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">迁移的主要技术挑战是停止使用HDFS作为中间存储，而是使用S3——因为HDFS很难在Kubernetes上设置和维护。这需要更改一些应用程序代码，但最终的体系结构更加健壮，因为计算资源现在与存储资源完全分离(允许群集在不使用时几乎完全缩减)。</p><p id="93ca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一些性能优化也很关键:</p><ol class=""><li id="1b88" class="lp lq iq jp b jq jr ju jv jy lr kc ls kg lt kk md lv lw lx bi translated">调整容器大小以最大化实例上容器的装箱。小型容器用于大多数应用程序(它们很短，处理的数据量很小)，大型容器用于较长应用程序的尾部。这些设置由数据力学平台自动调整。</li><li id="fc35" class="lp lq iq jp b jq ly ju lz jy ma kc mb kg mc kk md lv lw lx bi translated">调整默认的分区数量，以保证Spark中的最佳并行性——因为许多Spark作业受到太多小分区的影响(从Spark UI中可以看到，因为平均任务持续时间&lt; 50毫秒)。</li><li id="989e" class="lp lq iq jp b jq ly ju lz jy ma kc mb kg mc kk md lv lw lx bi translated">启用动态分配(从Spark 3.0开始，它适用于Kubernetes上的Spark)，以加速长时间运行的管道(对于第99百分位最长的应用程序，速度提高了5倍！)通过让他们请求更多的遗嘱执行人。</li><li id="317d" class="lp lq iq jp b jq ly ju lz jy ma kc mb kg mc kk md lv lw lx bi translated">启用少量过度配置，以确保群集始终有备用容量供应用程序启动。</li></ol><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mv"><img src="../Images/e3bb743b14d338b534dab0316d46ebfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZmJdItO-vIvBs-FXNsFPKg.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">示例节点池配置说明了我们实施的一些优化。图片作者。</p></figure><p id="25f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="me">这些优化详见技术指南:</em> <a class="ae lo" rel="noopener" target="_blank" href="/how-to-guide-set-up-manage-monitor-spark-on-kubernetes-with-code-examples-c5364ad3aba2"> <em class="me">如何在Kubernetes上设置、管理&amp; Monitor Spark(附代码示例)</em> </a> <em class="me">。</em></p><h1 id="4ba9" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">迁移取得的成果</h1><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mw"><img src="../Images/e453c791fc800c5c8e460052a17f3a75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pk8tE8jksKLp1qaXWyWXUA.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">EMR =&gt; Spark-on-K8S迁移中获得的结果。图片作者。</p></figure><p id="ac5f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从EMR到Spark-on-Kubernetes的迁移是一大胜利:</p><ul class=""><li id="bb17" class="lp lq iq jp b jq jr ju jv jy lr kc ls kg lt kk lu lv lw lx bi translated">在最终用户体验方面，Spark应用程序启动时间减半，平均应用程序持续时间减少了40%。</li><li id="0e1a" class="lp lq iq jp b jq ly ju lz jy ma kc mb kg mc kk lu lv lw lx bi translated">在成本方面，AWS成本降低了65%以上。Lingk的总拥有成本(包括数据机制管理费)降低了33%。这些节省来自对所有Spark应用程序使用单个Kubernetes集群的成本效益，以及上一节中描述的性能优化。</li></ul><p id="0c5b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Lingk还能够将Spark升级到3.0(逐渐地，由于他们的Spark分发的docker化)，这在其平台中实现了新的面向用户的功能。</p><blockquote class="mx my mz"><p id="5fb7" class="jn jo me jp b jq jr js jt ju jv jw jx na jz ka kb nb kd ke kf nc kh ki kj kk ij bi translated"><em class="iq">“利用数据机制激发专业知识和平台降低成本，同时让我们晚上睡个好觉，实现我们梦想的计划。”<br/> </em> <strong class="jp ir"> <em class="iq">戴尔·麦克罗里，Lingk的联合创始人&amp;首席产品官。</em> </strong></p></blockquote></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><p id="d808" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="me">原载于</em> <a class="ae lo" href="https://www.datamechanics.co/blog-post/migrating-from-emr-to-spark-on-kubernetes-with-data-mechanics" rel="noopener ugc nofollow" target="_blank"> <em class="me">数据力学博客</em> </a> <em class="me">。</em></p></div></div>    
</body>
</html>