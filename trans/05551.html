<html>
<head>
<title>Classifying the PROTEINS Benchmark Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">蛋白质基准数据集分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/classifying-the-proteins-benchmark-dataset-ec18e728a17a?source=collection_archive---------20-----------------------#2021-05-17">https://towardsdatascience.com/classifying-the-proteins-benchmark-dataset-ec18e728a17a?source=collection_archive---------20-----------------------#2021-05-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a351" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">实现图形卷积网络的两种方法</h2></div><p id="d80b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是图论和图卷积网络系列的第四部分。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/bb73019b2cf7083564a5069633c59f9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_UKdazyQe2cIdY5VcTX46g.jpeg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated"><a class="ae ls" href="https://unsplash.com/@photoholgic?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">摄影</a>在<a class="ae ls" href="https://unsplash.com/s/photos/science?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="13ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你一直在阅读这整个系列，那么你已经伴随我走过了这整个旅程——通过<a class="ae ls" href="https://medium.com/mlearning-ai/why-graph-theory-is-cooler-than-you-thought-4df73e2a4950" rel="noopener">讨论什么是图论以及为什么它很重要</a>，什么是<a class="ae ls" href="https://medium.datadriveninvestor.com/graph-convolutional-networks-explained-d88566682b8f?source=your_stories_page-------------------------------------" rel="noopener ugc nofollow" target="_blank">图卷积网络甚至是</a>和<a class="ae ls" rel="noopener" target="_blank" href="/what-makes-graph-convolutional-networks-work-53badade0ce9?source=your_stories_page-------------------------------------">它们如何工作</a>，现在我们在这里，到了有趣的部分——构建我们自己的GCN。</p><p id="e85b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你是这个系列的新手，那也完全没问题！不管是哪种情况，让我们开始编码吧！</p><p id="0841" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本教程中，我们将通过GCNs的两个实现来对蛋白质基准数据集进行分类。<em class="lb">如果你想找到这些数据的归属或论文，或者自己下载看看，可以在“生物信息学”标题下</em> <a class="ae ls" href="https://chrsmrrs.github.io/datasets/docs/datasets/" rel="noopener ugc nofollow" target="_blank"> <em class="lb">这里</em> </a> <em class="lb">找到。</em>你也可以在这里看一看整个笔记本<a class="ae ls" href="https://colab.research.google.com/drive/1W0syoaSSP-MpFhYC14cBV0O32Esyr_zF?usp=sharing" rel="noopener ugc nofollow" target="_blank">。代码的属性可以在这个项目的</a><a class="ae ls" href="https://github.com/sidneyarcidiacono/graph-convolutional-networks#readme" rel="noopener ugc nofollow" target="_blank">库</a>中找到。</p><h2 id="8179" class="lt lu iq bd lv lw lx dn ly lz ma dp mb ko mc md me ks mf mg mh kw mi mj mk ml bi translated">第一部分:带频谱的GCNs</h2><p id="7d32" class="pw-post-body-paragraph kf kg iq kh b ki mm jr kk kl mn ju kn ko mo kq kr ks mp ku kv kw mq ky kz la ij bi translated">什么是<a class="ae ls" href="https://graphneural.network/" rel="noopener ugc nofollow" target="_blank">光谱</a>？根据他们的主页:</p><blockquote class="mr ms mt"><p id="5b78" class="kf kg lb kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">Spektral是一个用于图形深度学习的Python库，基于Keras API和TensorFlow 2。这个项目的主要目标是为创建图形神经网络(GNNs)提供一个简单而灵活的框架。</p></blockquote><p id="6d03" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">开始使用Spektral非常容易，因为对项目进行了预先考虑——如果你已经使用Keras或Tensorflow进行过建模，我想你会发现Spektral非常直观。</p><p id="bcfb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，Spektral有许多内置的基准图数据集，这意味着您不必担心需要确保您的数据是使用GNNs建模的正确格式，并且可以很容易地开始实验。</p><p id="e307" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">无论您是在Colab中学习本教程，还是仅仅学习一本普通的笔记本，我们的第一步都是一样的。Spektral不是Colab的内置库之一，所以我们需要安装它:</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="0c84" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">PROTEINS是来自TU Dortmund的图形内核的基准数据集之一。您可以从<code class="fe mz na nb nc b">TUDataset</code>类中访问这个数据集类，我们通过首先导入然后实例化它的一个对象来访问它，我们要访问的数据集的名称被传入:</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="a339" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我们加载数据集时，我们可以看到它在<code class="fe mz na nb nc b">n_graphs</code>属性中包含了多少个图。在这里，我们可以看到这个数据集有1113个图形。在这个数据集中，这些被分成两个不同的类。</p><p id="dc79" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Spektral的<code class="fe mz na nb nc b">GCNConv</code>层基于Thomas N. Kipf和Max Welling的论文:“<a class="ae ls" href="https://arxiv.org/abs/1609.02907" rel="noopener ugc nofollow" target="_blank">使用图卷积网络的半监督分类</a>”。这是完美的，因为这是我们一直在参考的论文，如果你一直在关注这个系列的话。如果您还没有，我建议您看看这篇论文以及我写的关于这些网络如何工作的文章，以便更好地了解Spektral在幕后为我们做了什么！</p><p id="0cb7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为这是我们想要使用的层，我们将不得不执行一些预处理。Spektral用他们的<code class="fe mz na nb nc b">GCNFilter</code>类让这变得非常简单，该类只用两行代码就为我们执行了预处理步骤(在论文中有概述)。</p><p id="e337" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，从<code class="fe mz na nb nc b">spektral.transforms</code>导入<code class="fe mz na nb nc b">GCNFilter</code>，然后在我们的数据集上调用<code class="fe mz na nb nc b">.apply()</code>，传入<code class="fe mz na nb nc b">GCNFilter</code>的实例:</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="4f43" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个阶段，我们希望确保执行我们的训练/测试分割。在这个简单的例子中，我通过混排数据，然后取切片(分别约80/20%)来实现，但是一旦您熟悉了这个实现，欢迎您进一步优化这个步骤！</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="022c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，让我们导入我们的模型需要的层:</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="dcd1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">等一下——这些导入语句不是来自Keras吗？别担心——这不是偶然的。因为Spektral是建立在Keras之上的，所以我们可以很容易地使用Keras functional API来构建我们的模型，在我们处理图形结构数据时添加Spektral特定的层。</p><p id="bf9b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们导入<code class="fe mz na nb nc b">Dense</code>和<code class="fe mz na nb nc b">Dropout</code>层— <code class="fe mz na nb nc b">Dense</code>是典型的执行前向传播的密集神经网络层，而<code class="fe mz na nb nc b">Dropout</code>以我们设定的速率将输入单元随机设置为0。这里的直觉是，这一步可以帮助避免过度拟合*。</p><p id="e572" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们导入我们之前介绍的<code class="fe mz na nb nc b">GCNConv</code>层和<code class="fe mz na nb nc b">GlobalSumPool</code>层。Spektral为我们简明地定义了这一层:</p><blockquote class="mr ms mt"><p id="ea27" class="kf kg lb kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">全局汇总层。通过计算图的节点特征的总和来汇集图。</p></blockquote><p id="4a9c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是全部了！让我们建立我们的模型:</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="4021" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，我们使用模型子类来定义我们的模型。当我们实例化模型进行训练时，我们将向模型传递<code class="fe mz na nb nc b">n_hidden</code>:隐藏层数和<code class="fe mz na nb nc b">n_labels</code>:标签(目标类)数。</p><p id="1ac4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，在<code class="fe mz na nb nc b">__init__</code>中，我们将所有的层定义为属性。在<code class="fe mz na nb nc b">call</code>中，我们定义了这个方法，通过按顺序调用我们的输入层来创建和返回我们想要的输出。</p><p id="daf5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们为训练实例化我们的模型！</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="5b13" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我们将初始化32个隐藏层和数据标签的数量。当我们读入时，Spektral方便地在我们的<code class="fe mz na nb nc b">TUDataset</code>上给了我们一个<code class="fe mz na nb nc b">n_labels</code>属性。<em class="lb">这样做的好处是，如果您想探索其他数据，您可以对任何其他光谱数据集使用相同的代码，无需修改！</em></p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="38a0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面，我们在我们的模型上调用<code class="fe mz na nb nc b">.compile()</code>。如果你熟悉Keras，你就会熟悉这个方法。我们将传递我们的优化器，<code class="fe mz na nb nc b">adam</code>，并定义我们的损失函数，<code class="fe mz na nb nc b">categorical crossentropy</code>。</p><p id="ca5f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们遇到了一个障碍。你们中熟悉Tensorflow和Keras的人可能会尝试给<code class="fe mz na nb nc b">model.fit()</code>打电话，然后就到此为止。然而，即使Spektral在Keras上无缝地构建GNNs，我们也不能完全以同样的方式处理我们的数据。</p><p id="d68c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为我们使用的是图形结构的数据，所以需要创建批处理来填充我们的Keras模型。对于这项任务，Spektral仍然通过提供<a class="ae ls" href="https://graphneural.network/loaders/" rel="noopener ugc nofollow" target="_blank">装载机</a>让我们的生活变得更加轻松。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="5d8b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们已经处理了批处理，我们可以调用<code class="fe mz na nb nc b">model.fit()</code>。我们不需要指定批处理，只需传入我们的加载器，因为它作为一个生成器工作。我们需要提供我们的<code class="fe mz na nb nc b">steps_per_epoch</code>参数用于培训。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="1e31" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于这个简单的例子，我们只选择了10个时期。为了验证，让我们为测试数据创建一个加载器:</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="a5d4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将通过调用<code class="fe mz na nb nc b">.load()</code>把它提供给我们的模型。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="8494" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">用Spektral构建gcn到此结束！我强烈建议您试着优化这个例子，或者深入到可以用Spektral构建的其他gnn中去。</p><h2 id="8e09" class="lt lu iq bd lv lw lx dn ly lz ma dp mb ko mc md me ks mf mg mh kw mi mj mk ml bi translated">第二部分:Pytorch几何的GCNs</h2><p id="2e8d" class="pw-post-body-paragraph kf kg iq kh b ki mm jr kk kl mn ju kn ko mo kq kr ks mp ku kv kw mq ky kz la ij bi translated">尽管Spektral为我们提供了一个优秀的图形神经网络层、加载器、数据集等库，但有时我们可能需要更精细的控制，或者我们可能需要另一个工具来完成这项工作。</p><p id="edd7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae ls" href="https://pytorch-geometric.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> Pytorch-Geometric </a>还提供了基于Kipf &amp; Welling paper以及基准数据集的GCN图层。PyTorch的实现看起来略有不同，但仍然易于使用和理解。</p><p id="e6be" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们开始吧！我们将从同一个<a class="ae ls" href="https://colab.research.google.com/drive/1W0syoaSSP-MpFhYC14cBV0O32Esyr_zF?usp=sharing" rel="noopener ugc nofollow" target="_blank">笔记本</a>开始，从标题“Pytorch几何GCN”的正下方开始。提供了此代码的归属。</p><p id="ebe4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">像往常一样，我们的第一步是安装我们需要的包:</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="b3a9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，让我们拿起数据集:</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="03a0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">看看我们的数据:</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="c5bc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，我们演示了Pytorch-Geometric在我们的TUDataset对象上提供的各种属性。这为我们提供了大量信息，我们可以使用这些信息在以后微调我们的方法，并深入了解我们的数据。</p><p id="39ea" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们知道了数据的样子，我们将执行我们的训练/测试分割。对于这个例子，我也使用了一个简单的洗牌和切片方法，但是和往常一样，我鼓励你研究一下这个步骤的优化！</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="6621" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Pytorch还为我们提供用于配料的<code class="fe mz na nb nc b">DataLoaders</code>:</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="4da5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们已经完成了这一步，我们可以构建我们的模型了。我们将使用类似的方法，但是记住现在我们使用Pytorch而不是Keras。</p><p id="a912" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将导入我们的功能层(类似于Keras的<code class="fe mz na nb nc b">Dense</code>层)、我们的<code class="fe mz na nb nc b">GCNConv</code>层和一个<code class="fe mz na nb nc b">global_mean_pool</code>层。这执行了与Spektral的<code class="fe mz na nb nc b">GlobalSumPool</code>类似的汇集操作，但是取平均值而不是相邻节点的和。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="e13b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在构建我们的模型时，我们继承了Pytorch的<code class="fe mz na nb nc b">GCN</code>模型，然后初始化三个卷积层。我们将在实例化模型时传递隐藏通道的数量。</p><p id="aa6e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们构建一个<code class="fe mz na nb nc b">forward()</code>方法，它类似于我们之前在特定GCN中构建的<code class="fe mz na nb nc b">call()</code>方法。这告诉我们的模型如何通过卷积层传播我们的输入。使用Pytorch，我们显式地定义了我们的激活函数。在这个例子中，我们使用<code class="fe mz na nb nc b">relu</code>。</p><p id="3872" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们的最终分类之前，我们执行我们的池，然后设置我们的dropout并通过最终的线性层传递我们的输入。</p><p id="c6ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然有很多机会来定制和微调我们的Spektral模型，但我喜欢我们用Pytorch明确定义我们的架构的方式。当谈到“哪种方法更好”时，像大多数事情一样，这取决于你的团队需要优先考虑什么(例如，解释能力比快速证明概念的效率更重要)。</p><p id="53cb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们来看看由此产生的架构:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nd"><img src="../Images/0ff8d771b32299615348fe9219063ee9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iiu6WUayTffObujHSY6UaQ.png"/></div></div></figure><p id="dc4b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们需要:</p><ol class=""><li id="9ba9" class="ne nf iq kh b ki kj kl km ko ng ks nh kw ni la nj nk nl nm bi translated">设置我们的优化器——我们也将在这个实现中使用<code class="fe mz na nb nc b">adam</code></li><li id="2c42" class="ne nf iq kh b ki nn kl no ko np ks nq kw nr la nj nk nl nm bi translated">定义我们的损失函数——同样，我们将保持<code class="fe mz na nb nc b">categorical crossentropy</code></li><li id="1d60" class="ne nf iq kh b ki nn kl no ko np ks nq kw nr la nj nk nl nm bi translated">定义训练和测试函数，然后在设定的时间段内调用它们。</li></ol><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="1347" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们在这个例子中使用了更多的纪元，因此，我们获得了更好的指标。除了我用来帮助构建模型和学习各个库的代码示例之外，没有什么内在的原因。此外，鉴于Pytorch-Geometric实现是我的最终实现，我比早期的实验更关注结果。一如既往地，我鼓励您尝试和优化代码，使它变得更好！</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ns"><img src="../Images/c370b8b45e69b95e9ac1136e30aa50ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lt1rS4uURSOXVgabkGqzjA.png"/></div></div></figure><p id="69e3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">查看最近20个训练时期，我们看到我们实现了大约71.34%的训练准确度和大约62.67%的测试准确度。评估186年前后的测试数据的准确性，一个潜在的优化将是早期停止回调，这确保我们一旦达到收敛就停止训练，以避免过度拟合模型。</p><p id="aecb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还可以进行更多的优化，但这是一篇很长的文章，所以我们就此打住，我将让您自己进行试验和优化！</p><p id="31f7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">注意事项</strong>:</p><p id="cb8c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">* —要了解更多关于辍学或为什么辍学的信息，请查看<a class="ae ls" href="https://ai-pool.com/a/s/dropout-in-deep-learning" rel="noopener ugc nofollow" target="_blank">这个</a>来源。</p></div></div>    
</body>
</html>