<html>
<head>
<title>Implementing Single Shot Detector (SSD) in Keras: Part VI — Model Evaluation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Keras中实现单触发探测器(SSD ):第六部分——模型评估</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-single-shot-detector-ssd-in-keras-part-vi-model-evaluation-c519852588d1?source=collection_archive---------14-----------------------#2021-06-26">https://towardsdatascience.com/implementing-single-shot-detector-ssd-in-keras-part-vi-model-evaluation-c519852588d1?source=collection_archive---------14-----------------------#2021-06-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="33b9" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/object-detection-in-keras" rel="noopener" target="_blank">Keras中的物体检测</a></h2><div class=""/><div class=""><h2 id="d96d" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">评估经过训练的SSD模型</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/c510af597ea5dc3738d3fb34b60e517e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0tfzXusay2nb-TMwkoY7fQ.png"/></div><p class="kz la gj gh gi lb lc bd b be z dk translated">在PASCAL VOC 2007 trainval上训练的SSD300-VGG16的图在测试集上评估。图片作者。</p></figure><h1 id="18dc" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">一.导言</h1><p id="552d" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">在本系列的前几部分中，我们深入探讨了SSD背后的概念以及这些概念是如何在代码中实现的。通过这个，我们能够构建SSD网络，训练它产生一个Keras模型，我们可以用它来进行预测。然而，我们仍然需要弄清楚模型的表现有多好。要回答这个问题，我们需要执行一个评估过程。目标检测的不同竞争/挑战有其自己的一套评估指标。由于在之前的文章中，我们在PASCAL VOC数据集上训练了我们的SSD网络，因此本文重点关注理解PASCAL VOC挑战评估过程所需的概念。特别地，我们将详细了解如何计算目标检测模型的<em class="mr">平均精度(mAP) </em>。</p><blockquote class="ms mt mu"><p id="bad7" class="lv lw mr lx b ly mv kd ma mb mw kg md mx my mg mh mz na mk ml nb nc mo mp mq im bi translated"><strong class="lx jd">注意:</strong>除了PASCAL VOC challenge为本次评估提供的Matlab代码，您还可以在评估过程中使用其他开源工具(例如<a class="ae nd" href="https://github.com/rafaelpadilla/review_object_detection_metrics" rel="noopener ugc nofollow" target="_blank">review _ object _ detection _ metrics</a>)。<strong class="lx jd">此处</strong>的目标是让您了解地图指标的使用和计算方式，以便您能够解读评估结果。</p><p id="974d" class="lv lw mr lx b ly mv kd ma mb mw kg md mx my mg mh mz na mk ml nb nc mo mp mq im bi translated"><em class="it">本文是一个更大的系列的一部分，称为在Keras中实现单次检测器(SSD)。以下是系列</em>的概要</p><p id="e866" class="lv lw mr lx b ly mv kd ma mb mw kg md mx my mg mh mz na mk ml nb nc mo mp mq im bi translated"><a class="ae nd" rel="noopener" target="_blank" href="/implementing-ssd-in-keras-part-i-network-structure-da3323f11cff?sk=2d12a3f967fd6f1c32518b30c56d0ca5"> <em class="it">第一部分:网络结构</em> </a> <em class="it"> <br/> </em> <a class="ae nd" rel="noopener" target="_blank" href="/implementing-single-shot-detector-ssd-in-keras-part-ii-loss-functions-4f43c292ad2a?sk=5e1265989a1e250844b0674dc670f234"> <em class="it">第二部分:损失函数</em></a><em class="it"><br/></em><a class="ae nd" rel="noopener" target="_blank" href="/implementing-single-shot-detector-ssd-in-keras-part-iii-data-preparation-624ba37f5924?sk=39164c76031c0f60785dd3aa559cc2a6"><em class="it">第三部分:数据准备</em></a><em class="it"><br/></em><a class="ae nd" rel="noopener" target="_blank" href="/implementing-single-shot-detector-ssd-in-keras-part-iv-data-augmentation-59c9f230a910?sk=cf25ff5e9e78ea56415f1f4c8be1fa32"><em class="it">第四部分:数据扩充</em></a><em class="it"><br/></em><a class="ae nd" rel="noopener" target="_blank" href="/implementing-single-shot-detector-ssd-in-keras-part-v-predictions-decoding-2305a6e4c7a1?sk=4c80a5b66d49fee2055b98437d4ca474"><em class="it">第五部分:预测解码</em> </a> <em class="it"> <br/>第六部分</em></p></blockquote><h1 id="b0c5" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">二。计算地图:一个简单的例子</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ne"><img src="../Images/abce97a635c1866e0714c99d2049ec86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xn6B2b99n-l1DkyIn2cNcw.jpeg"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">图1:类别“dog”的检测结果。图片作者。来源:<a class="ae nd" href="https://unsplash.com/photos/F0a5b3DAoOU?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=view-photo-on-unsplash&amp;utm_campaign=unsplash-ios" rel="noopener ugc nofollow" target="_blank">丹尼尔·林肯</a>，<a class="ae nd" href="https://unsplash.com/photos/yQutKDW3H6U?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=view-photo-on-unsplash&amp;utm_campaign=unsplash-ios" rel="noopener ugc nofollow" target="_blank">埃莉诺拉·卡塔拉诺</a>，<a class="ae nd" href="https://unsplash.com/photos/k9JXiwocnLg?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=view-photo-on-unsplash&amp;utm_campaign=unsplash-ios" rel="noopener ugc nofollow" target="_blank">张轩睿</a>，<a class="ae nd" href="https://unsplash.com/photos/CKsDMYPDgCs?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=view-photo-on-unsplash&amp;utm_campaign=unsplash-ios" rel="noopener ugc nofollow" target="_blank">贾卡琳·比厄斯</a></p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ne"><img src="../Images/83b437f8592997af58e76e7ba3aeaafe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Znj9xQAYCZQe3zBslTjIQA.jpeg"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">图2:类别“cat”的检测结果。图片作者。来源:<a class="ae nd" href="https://unsplash.com/photos/F0a5b3DAoOU?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=view-photo-on-unsplash&amp;utm_campaign=unsplash-ios" rel="noopener ugc nofollow" target="_blank">丹尼尔·林肯</a>，<a class="ae nd" href="https://unsplash.com/photos/yQutKDW3H6U?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=view-photo-on-unsplash&amp;utm_campaign=unsplash-ios" rel="noopener ugc nofollow" target="_blank">埃莉诺拉·卡塔拉诺</a>，<a class="ae nd" href="https://unsplash.com/photos/k9JXiwocnLg?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=view-photo-on-unsplash&amp;utm_campaign=unsplash-ios" rel="noopener ugc nofollow" target="_blank">张轩睿</a>，<a class="ae nd" href="https://unsplash.com/photos/CKsDMYPDgCs?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=view-photo-on-unsplash&amp;utm_campaign=unsplash-ios" rel="noopener ugc nofollow" target="_blank">贾卡琳·比厄斯</a></p></figure><p id="e146" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">为了更好地理解评估过程，让我们看一个简单的例子。假设我们为猫和狗这两个类训练了一个SSD300-VGG16模型。我们对模型在包含狗和猫的4幅图像的测试集上的表现感兴趣，因此我们在测试集中的所有图像中运行了我们训练的模型。基本事实边界框以绿色绘制，而检测(预测边界框)以红色绘制。图1显示了一组图像，这些图像显示了“狗”类的所有检测及其基本事实。类似地，图2显示了一组图像，这些图像显示了“cat”类的所有检测及其基本事实。我们可以看到总共有12个检测(5猫7狗)和7个地面真相盒(4猫3狗)。此外，如前几篇文章所述，每个检测都有一个置信度得分。请记住这些数字，因为它将在下面的步骤中对我们有用。</p><h2 id="c6e9" class="nj le it bd lf nk nl dn lj nm nn dp ln me no np lp mi nq nr lr mm ns nt lt iz bi translated">步骤1-确定“狗”类的AP</h2><h2 id="5e85" class="nj le it bd lf nk nl dn lj nm nn dp ln me no np lp mi nq nr lr mm ns nt lt iz bi translated">1.1-将每个“狗”检测状态确定为TP或FP</h2><p id="92e9" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">在评估过程中，我们需要完成的第一件事是确定哪些检测是“正确的”，哪些是“不正确的”。这就是混淆矩阵的由来。一个类别(例如狗)的混淆矩阵将该类别的所有检测分为四类:真阳性(TP)、真阴性(TN)、假阳性(FP)和假阴性(FN)。在对象检测设置中，</p><ul class=""><li id="9446" class="nu nv it lx b ly mv mb mw me nw mi nx mm ny mq nz oa ob oc bi translated"><strong class="lx jd">真阳性(TP) </strong> —真实边界框的正确检测。</li><li id="0f73" class="nu nv it lx b ly od mb oe me of mi og mm oh mq nz oa ob oc bi translated"><strong class="lx jd">误报(FP) </strong> —对不存在的对象的错误检测或对现有对象的错误检测。</li><li id="5745" class="nu nv it lx b ly od mb oe me of mi og mm oh mq nz oa ob oc bi translated"><strong class="lx jd">假阴性(FN) </strong> —一个未被检测到的真实边界框。</li><li id="4527" class="nu nv it lx b ly od mb oe me of mi og mm oh mq nz oa ob oc bi translated"><strong class="lx jd">真底片(TN) </strong> —不适用，因为在一幅图像中有无限数量的边界框需要检测。</li></ul><p id="0ef8" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">为了将检测分类为阳性或阴性，使用预测边界框和基本事实框之间的IOU。PASCAL VOC挑战将IOU阈值设置为50% (Everingham等人，2009年)。如果有两个或更多的检测具有50%或更高的IOU，并且具有相同的基本事实，那么具有最高IOU的检测被标记为TP，而所有其他的被标记为FP。在我们的例子中，IOU阈值设置为30%，而不是50%。浏览所有的检测和地面真理，我们有以上的类“狗”，我们可以构建下表:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi oi"><img src="../Images/26d07ce972f0b7f4b1676065009c1b1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5w2buyIfaFdtztfO5AHFjg.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">表1:“狗”类的检测及其TP和FP状态</p></figure><p id="ea53" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">请注意，检测列表也是按置信度得分降序排列的(从大到小)。这样做是为下一步做准备，在下一步中，我们需要计算所有置信度下的精确-召回对。</p><h2 id="6ba2" class="nj le it bd lf nk nl dn lj nm nn dp ln me no np lp mi nq nr lr mm ns nt lt iz bi translated">1.2 —计算每个置信度级别的精确度/召回率</h2><blockquote class="ms mt mu"><p id="949b" class="lv lw mr lx b ly mv kd ma mb mw kg md mx my mg mh mz na mk ml nb nc mo mp mq im bi translated">你可以试试这个互动演示来更直观地了解精确/召回是如何工作的。</p></blockquote><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi oj"><img src="../Images/41810639de98899230eab1c3382c2133.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5p2lcG7JYFgibU2kEBVkZA.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">图3:计算精度和召回率的公式。图片作者。</p></figure><p id="cc3d" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">知道每个检测的TP和FP状态并不能为我们提供关于模型性能的任何有价值的信息。我们需要能够将这些检测的状态合并到一个指标中。为了解决这个问题，可以使用信息检索领域中的精确度和召回率之间的关系。在对象检测的情况下:</p><ul class=""><li id="b7d9" class="nu nv it lx b ly mv mb mw me nw mi nx mm ny mq nz oa ob oc bi translated"><strong class="lx jd">精度</strong> —测量模型仅识别相关对象的能力。(帕迪拉等人，2020年)</li><li id="7d57" class="nu nv it lx b ly od mb oe me of mi og mm oh mq nz oa ob oc bi translated"><strong class="lx jd">回忆</strong>——测量一个模型找到所有相关案例(所有真实边界框)的能力(Padilla等人，2020)</li></ul><p id="510e" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">根据上述概念，我们需要确定哪些检测是“相关”的，哪些是“不相关”的。为此，我们使用每个检测附带的置信度阈值(𝜏)。置信度得分≥ 𝜏的检测将被认为是相关的，而置信度得分</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ok"><img src="../Images/3d41c3c079a99c9eae828651c0a6b16c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YxUI36M4IZI4zlAeefWjRA.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">表2:“狗”类的检测，它们的TP和FP状态，以及在每个置信度阈值的精度/召回值。作者图片</p></figure><p id="ea58" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">由于1.1中的列表是按照置信度得分以降序排序的，因此计算每个置信度得分级别的精确召回对只是遍历列表(自上而下)，同时在每次迭代中将要考虑的项目数(从1开始)增加1。因此，在第一次迭代中，要考虑的检测数量将仅为1(检测B)。因此，在这个置信度级别的精度是1.00，而召回率是0.33。在第二次迭代中，要考虑的检测的数量增加到2(检测B和检测E ),给我们1.00的精确度和0.66的召回率。重复这个过程，直到所考虑的项目数等于列表的大小。</p><h2 id="69d9" class="nj le it bd lf nk nl dn lj nm nn dp ln me no np lp mi nq nr lr mm ns nt lt iz bi translated">1.3-绘制精度-召回(PR)曲线</h2><p id="3c0f" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">计算特定置信度级别的精度和召回率，可以告诉我们特定类别的模型在特定置信度阈值下的性能。然而，要了解模型在特定类别上跨所有置信度得分阈值的整体性能，我们可以转向精确召回(PR)曲线。它显示了精确度和召回率之间的权衡。为了构建曲线，我们可以在不同的置信度下绘制精度/召回率对。PR曲线向右上角倾斜得越多越好，因为它表明模型很可能识别相关对象(高精度)，同时还能够找到所有相关对象中的大多数(高召回率)。对于我们的示例，类别“dog”的PR曲线如下所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ok"><img src="../Images/7b12ec20e32e298e2b49bd520a01a0de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rF-T3ZsBqv44nSTyFOpPcw.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">图4:“狗”类的精确召回曲线。作者图片</p></figure><h2 id="81aa" class="nj le it bd lf nk nl dn lj nm nn dp ln me no np lp mi nq nr lr mm ns nt lt iz bi translated">1.4-确定的11点插值精度/召回对和AP</h2><p id="7745" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">我们可以通过估计曲线的曲线下面积(AUC)将PR曲线的特征总结为一个值。AUC值越大，该模型在所有阈值范围内对该类别的表现越好。尽管在PR曲线中精度和召回率之间存在权衡关系，但精度值可能会随着召回率值的增加而降低，也可能不会。这导致曲线有时具有之字形图案，这对于估计AUC来说不是直线的。为了解决这个问题，PASCAL VOC挑战赛使用了11点插值平均精度(AP)方法。这种方法通过对一组11个等距召回水平的最大精度值进行平均来总结PR曲线(Padilla等人，2020)。特定召回级别的最大精度值是该召回级别右侧的最大精度值。此外，由于回忆范围从0到1，11个等间隔的回忆水平是[0，0.1，0.2，… 0.8，0.9，1]。较高的AP值(接近1)意味着该模型对于该特定类别具有较高的召回率和精确度。在我们的示例中，11点插值精度是下图中的红点:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ok"><img src="../Images/5a05c3c304fdccccfb7cd0751fd43284.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M445n633pVPP_C567Ov9ww.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">图5:具有11点插值精度的“dog”类的精度-召回曲线。作者图片</p></figure><p id="2e5c" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">因此，在我们的例子中，类“dog”的AP是:(1+1+1+1+1+1+0+0+0+0)/11 = 0.63 = 63%。</p><h2 id="7324" class="nj le it bd lf nk nl dn lj nm nn dp ln me no np lp mi nq nr lr mm ns nt lt iz bi translated">步骤2—确定“cat”类别的AP</h2><p id="9597" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">为了确定类别“cat”的AP，我们简单地再次重复步骤1，其中我们的检测和基础事实列表是类别“cat”。通过这种方式，我们确定“cat”类的AP为45%。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ol"><img src="../Images/ab8f63f1544b4a6d2383f38bf4280baa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qVVQj9kcJ4W8xHXNwWPbYg.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">表3:类别“cat”的检测，它们的TP和FP状态，以及在每个置信度阈值的精度/召回值。作者图片</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ok"><img src="../Images/da8652449c73233416141f61a4a3a7b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xvGLUijFcuaM9t6mq2E8iA.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">图6:具有11点插值精度的“cat”类的精度-召回曲线。作者图片</p></figure><h2 id="02f5" class="nj le it bd lf nk nl dn lj nm nn dp ln me no np lp mi nq nr lr mm ns nt lt iz bi translated">步骤3-计算地图</h2><p id="ce11" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">在估计了每个类的AP之后，我们可以通过计算mAP来总结模型跨所有类的性能，mAP的值也在0到1的范围内。它只是所有班级AP的平均值。高mAP值(接近1)意味着模型在所有类别中表现良好。因此，在我们的例子中，模型的映射是(63 + 45) / 2 = 54%。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ok"><img src="../Images/30eff6e2f6d38a7bb4f836d35fd36a22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dht0AT1xgBMMY-BF1pcyJw.png"/></div></div><p class="kz la gj gh gi lb lc bd b be z dk translated">图7:类别“猫”和“狗”的精确回忆曲线。作者图片</p></figure><h1 id="62f8" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">三。SSD300-VGG16经过PASCAL VOC 2007培训</h1><blockquote class="ms mt mu"><p id="b1c2" class="lv lw mr lx b ly mv kd ma mb mw kg md mx my mg mh mz na mk ml nb nc mo mp mq im bi translated">我用来执行评估过程的代码可以在<a class="ae nd" href="https://github.com/Socret360/object-detection-in-keras/blob/master/evaluate.py" rel="noopener ugc nofollow" target="_blank"> evaluate.py </a>中找到。</p></blockquote><p id="8a09" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">在从上述示例中了解了mAP计算之后，我将使用这一部分展示我在PASCAL VOC 2007 trainval数据集上训练的SSD300-VGG16模型的评估结果(批处理大小= 32，epochs = 275 ≈ 42k迭代),并提供我对如何改进它的一些意见。评估是在同一数据集的测试集上完成的。SSD模型产生的检测数量设置为200(与SSD纸张相同),而IOU阈值设置为50%,如PASCAL VOC挑战中一样。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/c510af597ea5dc3738d3fb34b60e517e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0tfzXusay2nb-TMwkoY7fQ.png"/></div><p class="kz la gj gh gi lb lc bd b be z dk translated">图8:在PASCAL VOC 2007 trainval上训练的SSD300-VGG16的图。图片作者。</p></figure><div class="ks kt ku kv gt ab cb"><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/7f0d892245a8763e22f7fcb0d861ab37.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Geml_u-OLX7ra_avhseU6g.png"/></div></figure><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/2f51bdf6d7ca84d55cbe6de8687dce38.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*nqRaWe1H1iT3vZIbrut3MA.png"/></div></figure><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/7f354a13fb6cc3a3c6bbbde0d2afa82a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*nNgF-n-RlozESuZh7WRv5Q.png"/></div></figure></div><div class="ab cb"><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/9d222d6464b8e95718a151ef6ca0a0c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Y-aeUj6CvKq5ERH9_g0a7Q.png"/></div></figure><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/b4878bc1da9aee22ac015bcfab1784f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*o1v4VxiXgD98l_T4n2pyqw.png"/></div></figure><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/f3a3cc1ed7a0825797ee4dd3056f4fde.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*mdKPA2ECAVJd9poGKZoZHA.png"/></div></figure></div><div class="ab cb"><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/2ef60845e439f1ce5e1a7e8e9de99ba8.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Abg01woy1FyHxtFi_7p3Jg.png"/></div></figure><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/5d9d6a210c1f4bc7fee91cc634f84bad.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*H3XHWbMSyqmuI_sRv6w91Q.png"/></div></figure><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/519cfe48e534827d574287ff9da1e2b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Z6NKRXmscxJT9itTwhysgw.png"/></div></figure></div><div class="ab cb"><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/29cca54756ce283217a89390cafe70d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*XeIGMLqh-4xIN5AGmrNcdw.png"/></div></figure><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/21287d06f247620850a98d835cd23819.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*NmymCz0bt4T5QUM_fpSdiw.png"/></div></figure><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/e8a0231da8f29187856ce40314ed4ac3.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*H_XCKSXvuUXOA9giVNp0jQ.png"/></div></figure></div><div class="ab cb"><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/57d33cd21d239a9538de54371045112d.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*g2AIx1nSdKfG1BZ7bBy7MQ.png"/></div></figure><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/abed6e9ec38c8f6d5c35f34e5716b0ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*aWmdUs8DuqHkbtQTJNolRQ.png"/></div></figure><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/4f007f3c2d089e02f8d4835484328f66.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*zqwIMyhBPV8DFuIaVgIS1Q.png"/></div></figure></div><div class="ab cb"><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/64645c087466c4a0ac00f3ec78f63114.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*a5lckuwNqdt4VRguFTW3iA.png"/></div></figure><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/d91c40a8bc42d4aa14801192568d9aff.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Ugdu1jPJVMHaobumRUYT6g.png"/></div></figure><figure class="om kw on oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/d8973d567b313de955aaba6872cb3014.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*SNHPZ70FQFCAYy9ygbpDqg.png"/></div></figure></div><div class="ab cb"><figure class="om kw os oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/c48634f914c24599165f681e9f2343e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*bFfew-DwLsg4ZsThJZ1Qgg.png"/></div></figure><figure class="om kw os oo op oq or paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><img src="../Images/8fd6ed703c670603d177c92de7bae4d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*i-pL4gqYY1aVIxkYGcgixQ.png"/></div><p class="kz la gj gh gi lb lc bd b be z dk ot di ou ov translated">图PASCAL VOC 2007数据集中20个类的精确召回曲线。图片作者。</p></figure></div><p id="c1b7" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">很明显，一张38.58%的地图与SSD的作者在他们的论文中所展示的(68%的地图)并不相符。以下是我对如何改进结果的看法:</p><ol class=""><li id="a181" class="nu nv it lx b ly mv mb mw me nw mi nx mm ny mq ow oa ob oc bi translated"><strong class="lx jd">进一步的训练:</strong>由于时间/资源的限制，我在42k迭代时停止了我的训练。我相信进一步的训练可以改进模型的映射，因为1)当我停止训练时，训练损失和验证损失仍然在很好地减少SSD的作者在没有随机扩展增强的情况下训练相同的模型配置多达60k次迭代，在有随机扩展增强的情况下训练多达120k次迭代。</li><li id="1f9e" class="nu nv it lx b ly od mb oe me of mi og mm oh mq ow oa ob oc bi translated"><strong class="lx jd">改进数据扩充和生成器:</strong>数据生成器的当前实现没有考虑过小的边界框或退化框(具有xmax &lt; xmin和ymax &lt; ymin的框)。移除这样的边界框将有助于模型产生更好的边界框预测。此外，可以改进增强管道，以更好地匹配SSD的原始Caffe实现中所示的管道。此外，在训练过程中使用的增强方法的更有效的实现也可以帮助加速训练过程。</li></ol><h1 id="c12d" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">三。结论</h1><p id="2a75" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">这标志着“在Keras中实现单次检测器(SSD)”系列的结束。就我个人而言，在这个系列的工作中，我学到了很多关于SSD的知识。因此，我希望这一系列文章对您有所帮助，就像它对我一样，帮助您实现了解SSD并自己实现它的目标。</p></div><div class="ab cl ox oy hx oz" role="separator"><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc"/></div><div class="im in io ip iq"><p id="464a" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated"><em class="mr">喜欢这篇文章，想表示你的支持？关注我或者给我买咖啡</em></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://www.buymeacoffee.com/socretlee"><div class="gh gi pe"><img src="../Images/69716627feab2505c60838bbd29241a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gS6Sh6i8g535gOafY4Wl1w.png"/></div></a></figure><h1 id="6a9a" class="ld le it bd lf lg lh li lj lk ll lm ln ki lo kj lp kl lq km lr ko ls kp lt lu bi translated">参考</h1><p id="da53" class="pw-post-body-paragraph lv lw it lx b ly lz kd ma mb mc kg md me mf mg mh mi mj mk ml mm mn mo mp mq im bi translated">j .戴维斯和m .戈德里奇(2006年)。精确回忆与ROC曲线的关系。<em class="mr">2006年ICML第23届国际机器学习会议论文集。<a class="ae nd" href="https://doi.org/10.1145/1143844.1143874" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1145/1143844.1143874</a></em></p><p id="75df" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">Everingham，m .，Van Gool，l .，Williams，C. K .，Winn，j .，&amp; Zisserman，A. (2009年)。Pascal视觉对象类(VOC)挑战。<em class="mr">国际计算机视觉杂志</em>，<em class="mr"> 88 </em> (2)，303–338。<a class="ae nd" href="https://doi.org/10.1007/s11263-009-0275-4" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1007/s11263-009-0275-4</a></p><p id="4ae6" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">Géron，A. (2020)。第1章——机器学习的前景。在<em class="mr">使用Scikit-Learn、Keras和TensorFlow进行机器实践学习:构建智能系统的概念、工具和技术</em>(第3–34页)中。论文，奥赖利。</p><p id="6a29" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">谷歌。(未注明)。<em class="mr">分类:真与假、正与负</em>。谷歌。<a class="ae nd" href="https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative." rel="noopener ugc nofollow" target="_blank">https://developers . Google . com/machine-learning/速成课程/分类/真-假-正-负。</a></p><p id="da72" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">谷歌。(未注明)。<em class="mr">评估模型|自动视觉物体检测|谷歌云</em>。谷歌。<a class="ae nd" href="https://cloud.google.com/vision/automl/object-detection/docs/evaluate." rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/vision/automl/object-detection/docs/evaluate。</a></p><p id="5bfb" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">马纳尔·埃尔·艾杜尼。(未注明)。<a class="ae nd" href="https://manalelaidouni.github.io/." rel="noopener ugc nofollow" target="_blank">https://manalelaidouni.github.io/.</a></p><p id="9e38" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">r .帕迪拉，Netto，S. L .，&amp; da Silva，E. A. (2020年)。目标检测算法的性能度量综述。<em class="mr"> 2020年系统、信号和图像处理国际会议(IWSSIP) </em>。【https://doi.org/10.1109/iwssip48289.2020.9145130 T2】号</p><p id="67fc" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">Phy，V. (2019年12月11日)。<em class="mr">分类任务</em>精度不够。中等。<a class="ae nd" rel="noopener" target="_blank" href="/accuracy-is-not-enough-for-classification-task-47fca7d6a8ec.">https://towardsdatascience . com/accuracy-is-not-sufficient-for-class ification-task-47 FCA 7d 6 a 8 EC。</a></p><p id="7229" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated"><em class="mr">精确召回</em>。sci kit-学习。(未注明)。<a class="ae nd" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html." rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/auto _ examples/model _ selection/plot _ precision _ recall . html</a></p><p id="6cf5" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">拉斐尔·帕迪拉。(未注明)。<em class="mr">rafaelpadilla/对象检测指标</em>。GitHub。<a class="ae nd" href="https://github.com/rafaelpadilla/Object-Detection-Metrics." rel="noopener ugc nofollow" target="_blank">https://github.com/rafaelpadilla/Object-Detection-Metrics.</a></p><p id="fe16" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">t .沙阿(2020年7月10日)。<em class="mr">关于机器学习中的训练、验证和测试集</em>。中等。<a class="ae nd" rel="noopener" target="_blank" href="/train-validation-and-test-sets-72cb40cba9e7.">https://towards data science . com/train-validation-and-test-sets-72 CB 40 CBA 9 e 7。</a></p><p id="35d8" class="pw-post-body-paragraph lv lw it lx b ly mv kd ma mb mw kg md me my mg mh mi na mk ml mm nc mo mp mq im bi translated">Solawetz，J. (2020年10月5日)。<em class="mr">什么是物体检测中的平均精度(mAP)？</em> Roboflow博客。<a class="ae nd" href="https://blog.roboflow.com/mean-average-precision/." rel="noopener ugc nofollow" target="_blank">https://blog.roboflow.com/mean-average-precision/.</a></p></div></div>    
</body>
</html>