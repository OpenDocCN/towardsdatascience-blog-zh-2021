<html>
<head>
<title>Profanity Detection with FastText</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用FastText进行亵渎检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/profanity-detection-with-fasttext-ab2b3d63264f?source=collection_archive---------33-----------------------#2021-07-26">https://towardsdatascience.com/profanity-detection-with-fasttext-ab2b3d63264f?source=collection_archive---------33-----------------------#2021-07-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5b58" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">通过Python在文本分类模式下使用fastText</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/98e835adac456ab74c518b877dbb07b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YECeOxlko9KoOJNw8RNm3A.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">艾莉娜·格鲁布尼亚克在<a class="ae kv" href="https://unsplash.com/s/photos/neural-network?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="cdd6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如今，无数网站以文本的形式接受来自用户的内容。社交媒体平台上的帖子评论、电子商务网站上的产品评论以及Medium等平台上的文章等内容每天都在以比以前更快的速度增长。随着如此大量的内容产生，有越来越多的负担，主持人来调节这些内容。自动化这个审核过程的几个方面不仅有助于审核过程中的仲裁者，还会使整个过程更加有效。检测内容中的亵渎就是这样一个用例。</p><p id="bf82" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://fasttext.cc/" rel="noopener ugc nofollow" target="_blank"> FastText </a>是脸书开发的一个<a class="ae kv" href="https://en.wikipedia.org/wiki/Word_embedding" rel="noopener ugc nofollow" target="_blank">单词嵌入</a>和<a class="ae kv" href="https://en.wikipedia.org/wiki/Document_classification" rel="noopener ugc nofollow" target="_blank">文本分类</a>模型。它建立在<a class="ae kv" href="https://www.tensorflow.org/tutorials/text/word2vec" rel="noopener ugc nofollow" target="_blank"> Word2vec </a>之上，依靠浅层<a class="ae kv" href="https://en.wikipedia.org/wiki/Artificial_neural_network" rel="noopener ugc nofollow" target="_blank">神经网络</a>来训练一个单词嵌入模型。fastText从Word2vec继承了一些要点，我们将在继续我们的用例之前考虑这些要点，</p><ol class=""><li id="e2ff" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir"> FastText根据单词使用的上下文创建单词嵌入</strong>。这是在训练期间通过滑动单词窗口来完成的。它采用两种方法— <a class="ae kv" rel="noopener" target="_blank" href="/nlp-101-word2vec-skip-gram-and-cbow-93512ee24314">连续包字和跳过克数</a>。</li><li id="2ec3" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">Word2vec模型依赖于训练数据集的词汇。具有异构单词的较大数据集导致更好的嵌入模型。为单词生成嵌入时，如果该单词不是在训练模型期间构建的词汇表的一部分，则该单词将被忽略。因此，当训练样本量很小时，Word2vec变得不太有效。<strong class="ky ir"> FastText通过将每个单词分解成n个字母的记号，并用这些n个字母的记号创建一个词汇表</strong>来代替原来的单词，从而解决了这个问题。这增加了词汇表的大小，并适应了存在单词拼写错误或训练数据集很小的情况。</li><li id="9714" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">像Word2vec这样的FastText已经被证明比更确定的特征提取/矢量化技术(如<a class="ae kv" href="https://en.wikipedia.org/wiki/Bag-of-words_model" rel="noopener ugc nofollow" target="_blank">单词包</a>)更好。用fastText或Word2vec创建的向量分布更加均匀，每个向量维度都包含一些关于单词的信息。</li></ol><p id="c4c1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">FastText库被开发用于两种模式——<a class="ae kv" href="https://fasttext.cc/docs/en/unsupervised-tutorial.html" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">单词嵌入</strong> </a> <strong class="ky ir"> </strong>和<strong class="ky ir"> </strong> <a class="ae kv" href="https://fasttext.cc/docs/en/supervised-tutorial.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">文本分类</strong> </a>。在嵌入模式中，我们训练一个具有一个隐层的浅层神经网络来构建一个词向量矩阵<a class="ae kv" href="https://en.wikipedia.org/wiki/Matrix_(mathematics)" rel="noopener ugc nofollow" target="_blank">。该矩阵可用于识别具有相似含义的单词。由于单词向量是在考虑单词上下文的情况下构建的，因此有了足够的数据，可以实现诸如V(国王)-V(男人)+V(女人)=V(王后)的计算。在文本分类模式中，fastText训练单词嵌入模型，建立单词向量矩阵，并使用这些单词向量训练多项式</a><a class="ae kv" href="https://en.wikipedia.org/wiki/Logistic_regression" rel="noopener ugc nofollow" target="_blank">逻辑回归</a>模型。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="85e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇博客中，我将只关注文本分类模式下的fastText。以下是我们在训练分类模型时将遵循的几个重要步骤:</p><ol class=""><li id="7285" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">训练和测试数据集取自Kaggle ( <a class="ae kv" href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data?select=train.csv.zip" rel="noopener ugc nofollow" target="_blank">下载</a>)。数据集可以免费分发，并归入<a class="ae kv" href="https://creativecommons.org/share-your-work/public-domain/cc0/" rel="noopener ugc nofollow" target="_blank"> CC0 </a>之下，底层评论文本由<a class="ae kv" href="https://creativecommons.org/licenses/by-sa/3.0/" rel="noopener ugc nofollow" target="_blank">维基百科的CC-SA-3.0 </a>管理。该数据集包含带有6个标签的注释。</li><li id="70f5" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">根据注释是否亵渎，预处理数据集，使其只有一种标签类型。</li><li id="359f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">清理注释——删除停用词，删除标点符号和词条。</li><li id="e82f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">在训练集上训练FastText单词嵌入模型。</li><li id="19cd" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">在训练的单词向量上训练逻辑回归模型。</li><li id="923d" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">使用10重交叉验证进行训练和测试，以更好地量化模型的准确性。</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mn"><img src="../Images/2381c7a883cdc8b4ee529c72fee3fc9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8CjVpgrSHkmhJMJPzwkd4w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="155c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们开始吧。</p><p id="3269" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">默认情况下，数据集为CSV格式，结构如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mo"><img src="../Images/ae7aed6673b48c0fec470fa09ff48aeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IiewEKoJAfsDtZz5NS-ZQw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="763a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们首先重新构建这个数据集，使其只包含一种标签类型，这种标签类型将表明这个句子是否是亵渎的。如果任何有毒，严重有毒，淫秽，威胁，侮辱，身份仇恨被标记为1 ，我们将认为该评论是<strong class="ky ir">亵渎。最终重构的数据集应该如下所示。请注意，<strong class="ky ir">数据集也应该转换为FastText兼容格式，标签设置为<em class="mp"> __label__ </em>前缀</strong>。在我们的例子中，<em class="mp"> __label__1 </em>和<em class="mp"> __label__2 </em>分别对应被亵渎和不被亵渎的评论。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/6673773b368ab7cd3df764bbf784a8f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oTNKI185PT7ySwi9ybM22g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="7978" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如你已经注意到的，数据集中仍然存在许多不必要的数据，比如<a class="ae kv" href="https://en.wikipedia.org/wiki/Stop_word" rel="noopener ugc nofollow" target="_blank">停用词</a>和标点符号。这些并不真正包含任何有用的数据，只是在训练过程中造成了<em class="mp">噪声</em>。因此，下一步，我们必须通过执行操作来清除数据集的这些不必要的数据，例如:<strong class="ky ir">删除标点符号，删除停用词和</strong> <a class="ae kv" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html#:~:text=Lemmatization%20usually%20refers%20to%20doing,is%20known%20as%20the%20lemma%20." rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">词条匹配</strong> </a> <strong class="ky ir">词</strong>。我最终使用了来自<a class="ae kv" href="https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing" rel="noopener ugc nofollow" target="_blank"> Sklearn </a>的停用词，因为它们为这个用例提供了更好的结果。为了进行词汇匹配，我使用了<a class="ae kv" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank">NLTK</a>T16】wordnet lemmatizer。这里值得一提的重要一点是，在去除单词方面，lemmatising比<a class="ae kv" href="https://www.baeldung.com/cs/stemming-vs-lemmatization" rel="noopener ugc nofollow" target="_blank">词干</a>做得更好。总之，在这些操作之后，数据集看起来应该是这样的，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/b342faabab6c402276333121766370c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nKaqE03vc9UcgiMx4gfRBg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="8bab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个清理过的数据集现在准备好用于训练FastText单词嵌入模型和分类器。为此，我使用了Python的<em class="mp"> fasttext </em>库。<strong class="ky ir">在文本分类模式下，可以使用<em class="mp">fast text . train _ supervised】</em>定义。该定义在内部负责为</strong> <a class="ae kv" href="https://machinelearningmastery.com/multinomial-logistic-regression-with-python/" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">多类分类</strong> </a>训练词向量模型和多项式逻辑回归分类器。对于我们的用例，我们只有2个类—世俗的(__label__1)和非世俗的(__label__2)。为了更好地量化测试准确性，<strong class="ky ir">使用K倍交叉验证</strong>是一个很好的实践。在这种情况下，我使用sk learn<a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html" rel="noopener ugc nofollow" target="_blank">StratifiedKFold</a>进行了10重交叉验证。下面的代码片段显示了如何使用FastText库来训练模型和测试数据。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="0e38" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们来谈谈我配置的超参数。<strong class="ky ir"><em class="mp">ws</em></strong><em class="mp"/>是窗口大小。大小为1意味着模型将考虑上下文单词两边的一个单词。"<strong class="ky ir"><em class="mp">wordNgrams</em></strong><em class="mp">"</em>定义了我们一次要为上下文考虑多少个单词。在这里将其设置为2意味着两个相邻的单词将被同时采用。<em class="mp"/><strong class="ky ir"><em class="mp">Minn</em></strong><em class="mp"/>和<em class="mp"/><strong class="ky ir"><em class="mp">maxn</em></strong><em class="mp"/>定义单词进一步分解成的最小和最大字符大小。请注意，正如本文开头所讨论的，这是FastText相对于Word2vec的改进之处。<em class="mp"/><strong class="ky ir"><em class="mp">lr</em></strong><em class="mp"/>是学习率，而<strong class="ky ir"><em class="mp">epoch</em></strong><em class="mp"/>定义了模型应该迭代每个数据样本的次数。这里使用的<a class="ae kv" href="https://en.wikipedia.org/wiki/Loss_function" rel="noopener ugc nofollow" target="_blank">损失函数</a>是<a class="ae kv" href="https://paperswithcode.com/method/hierarchical-softmax#:~:text=Hierarchical%20Softmax%20is%20a%20is,the%20path%20to%20that%20node." rel="noopener ugc nofollow" target="_blank">分级Softmax </a>。通过反复试验，我最终在我的模型中收敛了这些值。"<em class="mp"> model.test_label" </em>定义返回每个标签的准确度分数字典— <a class="ae kv" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank"> precision </a>，<a class="ae kv" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank"> recall </a>和<a class="ae kv" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank"> f1score </a>。它应该看起来像，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mu"><img src="../Images/852585de096dc2be18cd229e78a2496a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*66kxpvLoMqwdYYtEY6OrYQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="41f6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我不会深入研究如何对训练数据进行K-fold交叉验证来计算准确性分数。将来我可能会就此单独写一篇文章。</p><p id="8fe7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">10倍的每次迭代花费3分钟来训练模型，对于大约170k的数据集，总训练时间达到大约30分钟。培训是在我的Macbook Pro Intel i7、16GB内存、4GB GPU内存上完成的。用这些超参数在10倍上平均得到的模型的最终精度是，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mv"><img src="../Images/c64041e1e0e6a775b013fd1ca8178059.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mGfg023-p9MIn9IhEkou4w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="ea1e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你不知道<a class="ae kv" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">精度和</strong> </a>召回，这些本质上是<strong class="ky ir">精度测量，以确定我们的模型预测的假阳性和假阴性</strong>的数量。虽然这些分数的一个好值取决于用例，但是一般来说，<strong class="ky ir">越接近100%，越好</strong>。</p><p id="f3eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，确定模型的精度和召回率是非常好的，因为它有助于量化我们模型的准确性。但是，如果我们自己测试几个语句，看看模型预测的是什么，那会更令人满意。下面是我测试模型的几个样本，<em class="mp"> __label__1 </em>为亵渎，<em class="mp"> __label__2 </em>为非亵渎，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/dcf6d6e68faf6b62881295ee395b62bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*j18LqxFnJ1uFf-DQ3TG-_A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/7877b19554f9b95c084271f66ea5d70a.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*nCwUHnaFbSB53-J6_604gw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="8a8f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如你所看到的,<strong class="ky ir">模型能够预测句子中的脏话，可信度得分非常高</strong>。不仅是简单的情况，而且该模型还能够根据使用单词的上下文来预测脏话，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi my"><img src="../Images/3c71e2a4a9968476a0f42d01e4857f00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*movc17oO79fb_MtCvF9THA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/2c30ab86a8ca71a1924a9b93138c9b36.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*7t84HtzjloJxDqVLhJ27BQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="cf9d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如你所观察到的，<strong class="ky ir">模型预测<em class="mp"> pig </em>在一个基于上下文的评论中会被亵渎</strong>。FastText证明有用的另一种情况是对于打字错误，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/b860cdd4b2c200f337e7e58561278896.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*vFgX8CB3YxmNtp1d6CYg3w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/aaf0f1fa3b4e9b759a22c6e9645bf4ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*4JCm9PwbT1ZqbwW-ObE-tg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="4360" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为<strong class="ky ir"> FastText将一个单词进一步分解成n-gram标记来构建其单词向量矩阵，所以用户可能输入拼写错误的单词的用例也被考虑在内</strong>。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="668b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">利用我们上面训练和测试的模型，可以得出结论，文本分类模式中的<strong class="ky ir"> fastText对于检测句子中的亵渎性</strong>产生了非常好的结果。凭借超过95%的<strong class="ky ir">精确度和召回分数</strong>，FastText是其他已建立的检测亵渎的方法中的一个极好的选择。FastText的单词嵌入功能非常强大，像逻辑回归这样的相对基本的分类器能够以如此高的精度在类之间进行分类。此外，我们在上面看到，我们训练过的<strong class="ky ir"> fastText模型会处理拼写错误，甚至会考虑单词使用的上下文</strong>来判断它是亵渎还是非亵渎。FastText的这些预测能力使其成为识别句子中脏话的强大工具，它在几乎每个接受和调节用户内容的领域都有自动调节的应用。</p></div></div>    
</body>
</html>