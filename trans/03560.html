<html>
<head>
<title>Topic Modeling of Scientific Literature on Online Sexual Abuse Materials(CSAM)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在线性虐待材料科学文献的主题建模(CSAM)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/topic-modeling-of-scientific-literature-on-online-sexual-abuse-materials-csam-749a3e42250b?source=collection_archive---------40-----------------------#2021-03-22">https://towardsdatascience.com/topic-modeling-of-scientific-literature-on-online-sexual-abuse-materials-csam-749a3e42250b?source=collection_archive---------40-----------------------#2021-03-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c6f0" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用TF-IDF、Louvain聚类和D3.js的网络图可视化</h2></div><p id="f464" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我最近与<a class="ae lb" href="https://www.savethechildren.net/" rel="noopener ugc nofollow" target="_blank">救助儿童会</a>合作参加了<a class="ae lb" href="https://omdena.com/projects/children-violence/" rel="noopener ugc nofollow" target="_blank"> Omdena AI挑战赛</a>，这是一个领先的儿童人道主义组织，使用自然语言处理(NLP)技术探索针对儿童的在线性暴力问题。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/c9aedc621490062130283f0f48416f7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uEgKP84lMXQ9ZWzBVNFpIQ.jpeg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">照片由<a class="ae lb" href="https://unsplash.com/@jtzanno?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">若昂·赞诺</a>在<a class="ae lb" href="/s/photos/scientific-literature?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="21d0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">主题建模</h1><p id="ce95" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">主题建模是一种无监督的机器学习文本分析技术，能够检测文档集合中的单词和短语模式。然后，检测到的模式用于将文档聚类到特定主题中。它是一种常用的文本挖掘工具，用于发现文本数据中的语义结构。</p><p id="534a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">简单地说，关于特定主题的文档或多或少会包含特定于该主题的某些单词。</p><p id="eb9c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该任务的目标是收集科学文章的文本数据，应用主题建模将文档聚类成单独的主题，然后使用图形网络创建该聚类的可视化。</p><h1 id="971d" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">数据收集</h1><p id="9660" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">在进行任何分析之前，首先执行的任务之一是收集关于CSAM的数据。文章收集自多个资源库，包括<a class="ae lb" href="https://core.ac.uk/" rel="noopener ugc nofollow" target="_blank">核心</a>、<a class="ae lb" href="https://www.worldcat.org/" rel="noopener ugc nofollow" target="_blank">理念</a>、<a class="ae lb" href="https://www.researchgate.net/directory/publications" rel="noopener ugc nofollow" target="_blank">研究门户</a>、<a class="ae lb" href="https://doaj.org/" rel="noopener ugc nofollow" target="_blank">开放获取期刊目录</a>和<a class="ae lb" href="https://www.worldcat.org/" rel="noopener ugc nofollow" target="_blank">世界猫</a>。在本文中，我们将重点关注从CORE收集的文章。</p><p id="2de8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据是通过API收集的。为了发出请求，我们向CORE注册了一个帐户，并收到了一个API密钥。我们需要API键和搜索词来提出请求。使用的搜索词—</p><pre class="ld le lf lg gt mp mq mr ms aw mt bi"><span id="3e2b" class="mu lt iq mq b gy mv mw l mx my">#query = "((internet OR online OR technology OR chatroom OR chat) AND (minor OR child OR underage OR children OR teenager) AND (abuse OR exploitation OR grooming OR predation) AND (sex OR sexual OR carnal)) OR (internet OR online OR technology OR chatroom OR chat) AND (predators OR offenders) AND (sex OR sexual OR carnal) OR (child sexual abuse material OR CSAM)"</span><span id="baab" class="mu lt iq mq b gy mz mw l mx my">#query = "(internet OR online OR technology OR chatroom OR chat) AND (predators OR offenders) AND (sex OR sexual OR carnal)"</span><span id="ee37" class="mu lt iq mq b gy mz mw l mx my">#query = "(child sexual abuse material OR CSAM)"</span></pre><p id="c980" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">收集数据的Python代码—</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="na nb l"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">核心提取代码</p></figure><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="nc nb l"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">核心数据帧</p></figure><h1 id="415d" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">数据清理和预处理</h1><p id="fdb7" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">与任何类型的数据分析一样，我们必须首先清理数据。对数据的直观检查显示存在重复的行。基于包括标题、摘要和DOI在内的许多列，删除了重复的内容。对这些问题进行了单独和组合研究。</p><pre class="ld le lf lg gt mp mq mr ms aw mt bi"><span id="ca41" class="mu lt iq mq b gy mv mw l mx my">core_df = core_df.drop_duplicates(subset=['Title'])</span></pre><p id="f0fc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们使用了clean text library，这是一个python包，它结合了许多清理步骤，包括删除标点、数字和多余的空格，以及将文本改为小写。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="c9a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过检查某些关键词是否出现在摘要和/或文本栏中来过滤数据。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="na nb l"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">关键词过滤</p></figure><p id="6375" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，这种手动过滤方法导致了许多相关文章的丢失。最终采取了不同的方法。稍后将详细介绍。</p><p id="679a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在预处理步骤之后，我们在数据帧中有35K行—</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nd"><img src="../Images/4a153417ba5d8974b32c16f7519875ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-t8DcLNGglD97rVCxVrlnA.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">已清理的文本—按作者排序的图像</p></figure><h1 id="7e92" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">TF-IDF矢量化</h1><p id="ae92" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">在自然语言处理中，文本必须首先被转换成机器能够理解的东西。转换成数字使我们能够对它们进行数学运算。有许多文本矢量化的方法，在本文中，我们将探讨TF-IDF矢量化。</p><p id="6859" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">TF-IDF代表词频逆文档频率。这是一种技术，我们给语料库或数据集中的词分配一个重要性分数。重要性的分配基于两个标准——</p><p id="9716" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">词频</strong> —这被定义为单词在文档中出现的频率除以单词的数量。</p><p id="0608" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">逆文档频率</strong>—一个词在语料库中的稀有或常见程度。这可以通过取文档总数与包含该单词的文档数之比的对数来计算。我们通过取这两项的乘积来计算TF-IDF分数。术语越高，单词越重要。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="na nb l"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">TF-IDF矢量器</p></figure><p id="77c0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">参数值<em class="ne"> max_features </em>为10000是指要考虑的顶级特性的最大数量。ngram_range指定我们正在考虑一元模型和二元模型。矢量器的输出是一个35000x10000的稀疏矩阵，其中35K表示文章的数量，10000表示max_features。</p><h1 id="ad9b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">降维</h1><p id="c19a" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">这是通过将数据集中的特征的维数从高维空间减少到低维空间来进行的数据转换，使得低维表示仍然保留数据的一些相对有意义的属性。</p><p id="1a28" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们遇到了一些问题，在内存上拟合K-Means聚类的数据。我们选择使用潜在语义分析(LSA)或截断奇异值分解(在SKlearn上)进行降维。</p><p id="09eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与任何降维技术一样，为了决定要选择的组件数量，我们检查了不同数量的组件，并选择了具有最高解释比率的组件。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="na nb l"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">降维</p></figure><p id="833f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们选择了一些2800的成分，其解释方差比为0.89。</p><h1 id="ade2" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">k均值聚类</h1><p id="01f3" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">K-Means是一种流行的无监督学习聚类技术，用于将数据点分组到非重叠的子组中。集群被定义为与集群内的其他对象比与集群外的对象更相似的对象组。</p><p id="7c4a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">类似地，我们对2-80范围内的多个聚类数运行K-Means，并计算每个聚类数的轮廓得分。选择得分最高的聚类。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="na nb l"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">k均值聚类</p></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/2a0993cc4010b290f09f97481611dea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*l7U-momx4WOSmqIvkHfs9w.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">剪影分数图-作者提供的图像</p></figure><p id="0751" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们选择72作为最佳聚类的初始数量。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="na nb l"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">去掉无关的话题</p></figure><p id="be95" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在对集群进行人工检查时，我们注意到一些集群被认为需要移除。我们注意到与领域无关的文档集群，以及不同语言的集群。聚类是过滤掉不相关文章的好方法。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="na nb l"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">词云</p></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ng"><img src="../Images/4243f109ce5588f51294317d6d9d7078.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Z1jHGhRDtNZsvMFb"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">文字云可视化——作者图片</p></figure><p id="46ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面的单词云显示了第一次实现聚类时每个片段中最重要的单词。例如，我们注意到，Cluster-ID 4、10、14、18和44不是英语。</p><h1 id="7e34" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">网络图</h1><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nh"><img src="../Images/98e835adac456ab74c518b877dbb07b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YECeOxlko9KoOJNw8RNm3A.jpeg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">艾莉娜·格鲁布尼亚克在<a class="ae lb" href="/s/photos/network?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="ff31" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">网络图是显示实体间相互联系的一种方式。这个子任务的目标是可视化地表示不同文章之间的关系。为了实现这一点，我们选择突出两种类型的关系，文章所属的不同主题，以及文章之间相似性的数字度量。我们决定采用两种不同的技术来实现这一点—</p><h2 id="0391" class="mu lt iq bd lu ni nj dn ly nk nl dp mc ko nm nn me ks no np mg kw nq nr mi ns bi translated">余弦相似性</h2><p id="d0c0" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">这是对文档之间相似程度的一种度量。它用于测量在多维空间中投影的两个向量之间的角度的余弦。这就告诉我们这些矢量是指向相同的方向。</p><p id="7c8b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">衡量文档间相似性的另一种常用方法是计算它们共有的字数。这种方法有一个问题，然而，文档越大，不管主题是什么，它们之间的共同点就越多。余弦相似性在这里起作用，因为它捕捉的是向量的方向，而不是大小。</p><h2 id="b507" class="mu lt iq bd lu ni nj dn ly nk nl dp mc ko nm nn me ks no np mg kw nq nr mi ns bi translated">鲁文聚类</h2><p id="01db" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">用于社区检测的Louvain聚类是一种无监督的机器学习技术，用于理解和检测大型复杂网络中的社区。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="na nb l"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">Louvain集群实现</p></figure><h2 id="544e" class="mu lt iq bd lu ni nj dn ly nk nl dp mc ko nm nn me ks no np mg kw nq nr mi ns bi translated">主题</h2><p id="74fa" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">从卢万，我们得到5个不同的社区。对社区的人工检查表明—</p><ul class=""><li id="bab1" class="nt nu iq kh b ki kj kl km ko nv ks nw kw nx la ny nz oa ob bi translated">制度、政治(立法)和社会话语</li><li id="4c6f" class="nt nu iq kh b ki oc kl od ko oe ks of kw og la ny nz oa ob bi translated">在线儿童保护—漏洞</li><li id="539b" class="nt nu iq kh b ki oc kl od ko oe ks of kw og la ny nz oa ob bi translated">技术视角</li><li id="5fd5" class="nt nu iq kh b ki oc kl od ko oe ks of kw og la ny nz oa ob bi translated">罪犯分析</li><li id="f58f" class="nt nu iq kh b ki oc kl od ko oe ks of kw og la ny nz oa ob bi translated">商业视角与贩运</li></ul><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi oh"><img src="../Images/512f5f0d8684f236a535b40adaa64f37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ToSgaMIQQUyIP0-F"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">主题分布-按作者分类的图片</p></figure><h2 id="16a0" class="mu lt iq bd lu ni nj dn ly nk nl dp mc ko nm nn me ks no np mg kw nq nr mi ns bi translated">形象化</h2><p id="762f" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">随着余弦相似性的计算和Louvain聚类的实现，我们现在有了创建网络图所需要的东西。如上所述，网络图显示了实体之间的连接，实体可以由节点(或顶点)表示，节点之间的连接由链接(边)表示。</p><p id="0107" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">余弦相似性输出是介于0和1之间的数字，分别代表无关系到完美关系的范围。文档越相似，链接就越强。节点可以基于文章最认同的主题来着色。</p><p id="7f18" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可视化是使用D3.js创建的，托管在Netlify的免费Github托管服务上(如果第一次没有正确加载，请刷新页面)，可以在这里找到<a class="ae lb" href="https://blissful-blackwell-f90fcb.netlify.app/tasks/task-7_data_visualization/graphnetwork/plot/graphtemp" rel="noopener ugc nofollow" target="_blank"/>。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="na nb l"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">网络图实现</p></figure><p id="a89e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将鼠标悬停在节点上可查看文章和其他链接文章的标题。可以拖动节点以获得更好的可视性。为了获得更好的可视性，我们为链接强度设置了一个阈值，这意味着低于0.3的链接应该从可视化中排除。</p><p id="8c6d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，为了防止节点偏离可视屏幕区域太远，我们设置了一个边框，这就是可视化周围的方形边框形状。</p><p id="31d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">报纸文章也做了类似的分析，可以在<a class="ae lb" href="https://blissful-blackwell-f90fcb.netlify.app/tasks/task-7_data_visualization/graphnetwork/plot/news_graph" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h1 id="366c" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">未来的工作</h1><p id="c759" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">许多不同的领域可能需要改进。TF-IDF有许多限制——对于大型词汇表来说计算量很大，并且不能捕获单词的语义。例如，困惑和迷惑在意思上是相似的，但是TF-IDF可能没有抓住这一点。</p><p id="35e7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更高级的方法包括单词嵌入、word2vec和doc2vec(针对文档而非单词)。</p><p id="bbb4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，一种更先进的测量文档相似性的方法是使用来自变压器的<strong class="kh ir">双向编码器表示(BERT) </strong>使用变压器，一种基于注意力的模型来学习单词嵌入。</p><p id="f1fe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个可能的应用是创建一个搜索功能，在与特定文章相似的某个范围内查询特定主题内的文章。这可以借助于能够以图形结构存储数据的图形数据库来实现。图形网络的直观结构允许人们进行复杂的查询，而这在关系数据库中是不可能的。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi oi"><img src="../Images/0ab2b794ed77c12fcfb93debc8abf833.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Tp6a1X4l8NRKwSKX"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">Neo4j数据库—图片由作者提供</p></figure><p id="c2a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此时加载的特定数据非常简单，只有一些节点、属性，并且只定义了一个关系(余弦相似性)。然而，由于图形数据库的灵活性，将来或在需要时，可以添加更多的节点和标签，以及定义更多的关系。这些关系可以使用机器学习以及其他非ML方法来导出。</p><p id="6d1a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://neo4j.com/" rel="noopener ugc nofollow" target="_blank"> Neo4j </a>还允许安装第三方插件，包括data science/ML插件，允许在数据库中实现和应用机器学习算法，包括Louvain聚类和社区检测。</p><h1 id="c047" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><p id="597f" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">Nasar Z，Jaffry S W，Malik M K (2018)从科学文章中提取信息:一项调查<a class="ae lb" href="http://faculty.pucit.edu.pk/swjaffry/rpr/Scientometrics18InformationMining.pdf" rel="noopener ugc nofollow" target="_blank">http://faculty . pucit . edu . PK/swjaffrey/RPR/scientimetrics 18 Information mining . pdf</a></p><p id="80dc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Stecanella R (2017)文本矢量化初学者指南<a class="ae lb" href="https://monkeylearn.com/blog/beginners-guide-text-vectorization/" rel="noopener ugc nofollow" target="_blank">https://monkey learn . com/blog/初学者指南-文本-矢量化/ </a></p><p id="c491" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">范德马腾，劳伦斯；邮政局长，埃里克；范·登·赫里克，贾普(2009)维数约减:一个比较评论<a class="ae lb" href="https://members.loria.fr/moberger/Enseignement/AVR/Exposes/TR_Dimensiereductie.pdf" rel="noopener ugc nofollow" target="_blank">https://members . loria . fr/moberger/enseignment/AVR/Exposes/TR _ dimensionereductie . pdf</a></p><p id="f732" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Pantola P (2018)自然语言处理:文本数据矢量化<a class="ae lb" href="https://medium.com/@paritosh_30025/natural-language-processing-text-data-vectorization-af2520529cf7" rel="noopener">https://medium . com/@ paritosh _ 30025/Natural-Language-Processing-Text-Data-矢量化-af2520529cf7 </a></p><p id="62a0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">普拉巴卡兰(2019)余弦相似性——理解数学及其工作原理<a class="ae lb" href="https://www.machinelearningplus.com/nlp/cosine-similarity/" rel="noopener ugc nofollow" target="_blank">https://www.machinelearningplus.com/nlp/cosine-similarity/</a></p><p id="54aa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">博斯托克M (2017)力定向图<a class="ae lb" href="https://observablehq.com/@d3/force-directed-graph" rel="noopener ugc nofollow" target="_blank">https://observablehq.com/@d3/force-directed-graph</a></p><p id="bb2b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Raghunathan D (2020) NLP in Python-矢量化<a class="ae lb" rel="noopener" target="_blank" href="/nlp-in-python-vectorizing-a2b4fc1a339e">https://towardsdatascience . com/NLP-in-Python-矢量化-a2b4fc1a339e </a></p><p id="3f5c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Jayaswal V (2020)文本矢量化:词频—逆文档频率(tfi df)<a class="ae lb" rel="noopener" target="_blank" href="/text-vectorization-term-frequency-inverse-document-frequency-tfidf-5a3f9604da6d">https://towardsdatascience . com/Text-Vectorization-Term-Frequency-Inverse-Document-Frequency-tfi df-5a 3f 9604 da6d</a></p><p id="66bb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">巴赫T (2020)用变形金刚寻找相似文档<a class="ae lb" href="https://www.codegram.com/blog/finding-similar-documents-with-transformers/" rel="noopener ugc nofollow" target="_blank">https://www . codegram . com/blog/Finding-similar-documents-with-transformers/</a></p><p id="55ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Borad A (2020) NLP文本预处理:文本矢量化【https://www.einfochips.com/blog/nlp-text-vectorization/ T4】</p></div></div>    
</body>
</html>