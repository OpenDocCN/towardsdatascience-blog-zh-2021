<html>
<head>
<title>Using PyTorchVideo for efficient video understanding</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用PyTorchVideo实现高效的视频理解</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-pytorchvideo-for-efficient-video-understanding-24d3cd99bc3c?source=collection_archive---------8-----------------------#2021-05-19">https://towardsdatascience.com/using-pytorchvideo-for-efficient-video-understanding-24d3cd99bc3c?source=collection_archive---------8-----------------------#2021-05-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a893" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解如何轻松可视化和评估PyTorchVideo库中的活动分类模型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b4e3338f8974f09e05f46d91d0e18236.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e3hsEHljdJ1Y18E9gKFJqw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://pytorchvideo.org/" rel="noopener ugc nofollow" target="_blank"> PyTorchVideo </a>预言在<a class="ae kv" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank">第五十一</a>可视化(图片由作者提供)</p></figure><p id="4c17" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你试图找到最好的模型，或者仅仅是与你的任务相关的基线，那么海量的计算机视觉模型可能很难导航。像<a class="ae kv" href="https://www.tensorflow.org/hub" rel="noopener ugc nofollow" target="_blank"> TensorFlow Hub </a>和<a class="ae kv" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank">脸书的Detectron2 </a>这样的模型动物园让人们很容易接触到受欢迎的模型。此外，像PyTorch lightning 这样的库使得修改这些模型来满足你的需求变得容易。这对于图像来说很好，但对于视频来说，这是另一回事。视频数据正变得越来越受欢迎，但随之而来的额外复杂性往往使与视频相关的任务处于次要地位。</p><blockquote class="ls"><p id="505a" class="lt lu iq bd lv lw lx ly lz ma mb lr dk translated"><a class="ae kv" href="https://pytorchvideo.org/" rel="noopener ugc nofollow" target="_blank"><strong class="ak">PyTorchVideo</strong></a><strong class="ak">是一个新的库，旨在使视频模型像图像模型一样易于加载、构建和训练</strong>。</p></blockquote><p id="8f0b" class="pw-post-body-paragraph kw kx iq ky b kz mc jr lb lc md ju le lf me lh li lj mf ll lm ln mg lp lq lr ij bi translated">PyTorchVideo提供对视频模型动物园、视频数据处理功能和以视频为中心的加速器的访问，以部署所有受<a class="ae kv" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>支持的模型，允许无缝集成到现有工作流程中。</p><p id="5be4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"/><a class="ae kv" href="https://pytorchvideo.org/" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">PyTorchVideo</strong></a><strong class="ky ir">要完成您的视频工作流程，唯一缺少的是可视化数据集和解释模型结果的方法</strong>。这就是第51个<a class="ae kv" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank">出现的地方。</a><a class="ae kv" href="https://github.com/voxel51/fiftyone" rel="noopener ugc nofollow" target="_blank"> FiftyOne是我在</a><a class="ae kv" href="https://voxel51.com/" rel="noopener ugc nofollow" target="_blank"> Voxel51 </a>一直在做的开源工具。它旨在使可视化任何图像或视频数据集变得容易，并探索存储在本地<a class="ae kv" href="https://voxel51.com/docs/fiftyone/environments/index.html" rel="noopener ugc nofollow" target="_blank">或云中</a>的地面真相和预测标签。<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/basics.html" rel="noopener ugc nofollow" target="_blank">51个数据集</a>和<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/app.html" rel="noopener ugc nofollow" target="_blank">51个应用程序</a>的灵活表示让您可以快速操作您的数据集并解释您的<a class="ae kv" href="https://voxel51.com/docs/fiftyone/tutorials/evaluate_detections.html" rel="noopener ugc nofollow" target="_blank">模型，以找到故障模式</a>、<a class="ae kv" href="https://voxel51.com/docs/fiftyone/tutorials/detection_mistakes.html" rel="noopener ugc nofollow" target="_blank">注释错误</a>、<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/index.html" rel="noopener ugc nofollow" target="_blank">可视化复杂标签</a>等等。</p><p id="d278" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇博文是最近的PyTorchVideo教程的延伸，旨在教你如何将<a class="ae kv" href="https://pytorchvideo.org/" rel="noopener ugc nofollow" target="_blank"> PyTorchVideo </a>与<a class="ae kv" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank">fiftone</a>集成起来，从而结束基于视频的ML工作流程。具体来说，这篇文章包括:</p><ul class=""><li id="fa1e" class="mh mi iq ky b kz la lc ld lf mj lj mk ln ml lr mm mn mo mp bi translated">下载<a class="ae kv" href="https://deepmind.com/research/open-source/kinetics" rel="noopener ugc nofollow" target="_blank">动力学数据集</a>的子集</li><li id="8417" class="mh mi iq ky b kz mq lc mr lf ms lj mt ln mu lr mm mn mo mp bi translated">加载带有51个的<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#videoclassificationdirectorytree-import" rel="noopener ugc nofollow" target="_blank">视频数据集</a></li><li id="81ad" class="mh mi iq ky b kz mq lc mr lf ms lj mt ln mu lr mm mn mo mp bi translated">使用<a class="ae kv" href="https://pytorchvideo.org/docs/tutorial_torchhub_inference" rel="noopener ugc nofollow" target="_blank"> PyTorchVideo进行推理</a></li><li id="433e" class="mh mi iq ky b kz mq lc mr lf ms lj mt ln mu lr mm mn mo mp bi translated"><a class="ae kv" href="https://voxel51.com/docs/fiftyone/tutorials/evaluate_classifications.html" rel="noopener ugc nofollow" target="_blank">可视化和评估</a>PyTorchVideo模型</li></ul><h1 id="7937" class="mv mw iq bd mx my mz na nb nc nd ne nf jw ng jx nh jz ni ka nj kc nk kd nl nm bi translated">跟随Colab！</h1><p id="6731" class="pw-post-body-paragraph kw kx iq ky b kz nn jr lb lc no ju le lf np lh li lj nq ll lm ln nr lp lq lr ij bi translated">你可以在你的浏览器中直接运行这篇博文中的例子。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/8e6aaa161cabb491ded4d7c739a6f8d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rt8tA_yaVdpDwMhhaFG3Nw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Google Colab 中<a class="ae kv" href="https://colab.research.google.com/github/voxel51/fiftyone-examples/blob/master/examples/pytorchvideo_tutorial.ipynb" rel="noopener ugc nofollow" target="_blank">这个演练的截图(图片由作者提供)</a></p></figure><h1 id="aa5c" class="mv mw iq bd mx my mz na nb nc nd ne nf jw ng jx nh jz ni ka nj kc nk kd nl nm bi translated">设置</h1><p id="c9f0" class="pw-post-body-paragraph kw kx iq ky b kz nn jr lb lc no ju le lf np lh li lj nq ll lm ln nr lp lq lr ij bi translated">为了完成这个演练，您需要安装<a class="ae kv" href="https://voxel51.com/docs/fiftyone/getting_started/install.html" rel="noopener ugc nofollow" target="_blank"> FiftyOne </a>、<a class="ae kv" href="https://github.com/facebookresearch/pytorchvideo/#installation" rel="noopener ugc nofollow" target="_blank"> PyTorchVideo </a>、<a class="ae kv" href="https://pytorch.org/get-started/locally/" rel="noopener ugc nofollow" target="_blank"> PyTorch和TorchVision </a>:</p><pre class="kg kh ki kj gt nt nu nv nw aw nx bi"><span id="f1b6" class="ny mw iq nu b gy nz oa l ob oc">pip install fiftyone pytorch torchvision</span></pre><p id="4b3a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然<a class="ae kv" href="https://github.com/facebookresearch/pytorchvideo/blob/master/pytorchvideo/models/slowfast.py" rel="noopener ugc nofollow" target="_blank"> PyTorchVideo </a>也可以通过<code class="fe od oe of nu b">pip</code>安装，但本文中的功能要求它通过<a class="ae kv" href="https://github.com/facebookresearch/pytorchvideo" rel="noopener ugc nofollow" target="_blank"> GitHub </a>安装:</p><pre class="kg kh ki kj gt nt nu nv nw aw nx bi"><span id="1a40" class="ny mw iq nu b gy nz oa l ob oc">git clone https://github.com/facebookresearch/pytorchvideo.git<br/>cd pytorchvideo<br/>pip install -e .</span></pre><p id="04ef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本演练使用了<a class="ae kv" href="https://deepmind.com/research/open-source/kinetics" rel="noopener ugc nofollow" target="_blank"> Kinetics-400数据集</a>的子集，可通过以下代码片段下载:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="1048" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">视频数据集比图像数据集更难处理的原因之一是，许多流行的视频数据集只能通过YouTube获得。因此，你不需要下载一个包含你需要的所有内容的zip文件，而是需要运行如下脚本，从YouTube下载自数据集管理以来可能不可用的单个视频。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><h1 id="4af2" class="mv mw iq bd mx my mz na nb nc nd ne nf jw ng jx nh jz ni ka nj kc nk kd nl nm bi translated">加载和浏览视频数据集</h1><p id="7ed9" class="pw-post-body-paragraph kw kx iq ky b kz nn jr lb lc no ju le lf np lh li lj nq ll lm ln nr lp lq lr ij bi translated">对于图像数据集，有一些基本的选项可用于可视化批量数据，如<a class="ae kv" href="https://pillow.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> pillow </a>和<a class="ae kv" href="https://opencv.org/" rel="noopener ugc nofollow" target="_blank"> OpenCV </a>。用于可视化视频数据集的选项非常少。<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/index.html" rel="noopener ugc nofollow" target="_blank"> FiftyOne </a>是一个新的开源库，为图像和视频数据集提供简单而强大的可视化。</p><p id="3522" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您的数据集遵循一种通用格式，比如用于检测的<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#cocodetectiondataset-import" rel="noopener ugc nofollow" target="_blank"> COCO格式</a>，那么您可以在一行代码中加载它:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="c128" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">即使你的数据集是一个<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/samples.html" rel="noopener ugc nofollow" target="_blank">自定义格式</a>，用FiftyOne加载你的数据集仍然很简单。例如，如果您使用的是对象检测视频模型，您可以按如下方式加载数据:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="8609" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本例中，我们将按照<a class="ae kv" href="https://pytorchvideo.org/docs/tutorial_torchhub_inference" rel="noopener ugc nofollow" target="_blank"> PyTorchVision教程</a>运行视频分类模型。通常，视频分类数据集将存储在磁盘上的<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/datasets.html#videoclassificationdirectorytree-import" rel="noopener ugc nofollow" target="_blank">目录树</a>中，该目录树的子文件夹定义了数据集类别。这种格式可以在一行代码中加载:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="5b20" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="oi">如果您自己也在关注，请将鼠标悬停在样本上或点击样本来播放视频:</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/f77e2ca19fb2b2267b7ef0d74c9e2527.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*YDzvrZDlgwJ12RsBIyCafA.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/app.html" rel="noopener ugc nofollow" target="_blank">五十一应用</a>中观看的动力学视频(图片由作者提供)</p></figure><p id="7069" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还需要下载并<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/using_datasets.html#storing-class-lists" rel="noopener ugc nofollow" target="_blank">存储一个默认类名列表</a>，在评估预测时会用到:</p><pre class="kg kh ki kj gt nt nu nv nw aw nx bi"><span id="e1a3" class="ny mw iq nu b gy nz oa l ob oc">wget <a class="ae kv" href="https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json" rel="noopener ugc nofollow" target="_blank">https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json</a></span></pre><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><h1 id="989e" class="mv mw iq bd mx my mz na nb nc nd ne nf jw ng jx nh jz ni ka nj kc nk kd nl nm bi translated">运行PyTorchVideo模型</h1><p id="432e" class="pw-post-body-paragraph kw kx iq ky b kz nn jr lb lc no ju le lf np lh li lj nq ll lm ln nr lp lq lr ij bi translated">在本节中，我们使用PyTorchVideo下载并运行视频分类模型，该模型基于我们在上一节中加载的数据，并将结果存储在我们的数据集中。本节代码改编自<a class="ae kv" href="https://pytorchvideo.org/docs/tutorial_torchhub_inference" rel="noopener ugc nofollow" target="_blank">本PyTorchVideo教程</a>。</p><p id="4bf8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://pytorch.org/hub/" rel="noopener ugc nofollow" target="_blank"> Torch Hub </a>是一个预训练PyTorch模型的存储库，允许您下载模型并在数据集上运行推理。PyTorchVideo通过其火炬中心支持的<a class="ae kv" href="https://pytorchvideo.readthedocs.io/en/latest/model_zoo.html" rel="noopener ugc nofollow" target="_blank">模型动物园</a>提供了<a class="ae kv" href="https://pytorchvideo.readthedocs.io/en/latest/model_zoo.html" rel="noopener ugc nofollow" target="_blank">数量的视频分类模型</a>，包括SlowFast、I3D、C2D、R(2+1)D和X3D。以下代码片段下载带有ResNet50主干的SlowFast的慢速分支，并将其加载到Python中:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="6c62" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每个模型都有它期望的特定输入结构。标准的工作流程是编写定制脚本，执行必要的加载和转换功能，为每个模型格式化数据。<a class="ae kv" href="https://pytorchvideo.org/" rel="noopener ugc nofollow" target="_blank"> PyTorchVideo </a>通过<a class="ae kv" href="https://pytorchvideo.readthedocs.io/en/latest/transforms.html" rel="noopener ugc nofollow" target="_blank">以灵活的方式为您提供这些功能</a>来加速这一过程，这些功能将满足大多数视频处理需求。例如，以下代码构造了<a class="ae kv" href="https://pytorchvideo.readthedocs.io/en/latest/transforms.html" rel="noopener ugc nofollow" target="_blank">转换</a>来对视频帧进行采样、归一化、缩放和裁剪，而无需自己编写任何函数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="d372" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于数据集存储在fiftone中，我们可以轻松地遍历这些样本，使用PyTorchVideo加载并运行我们的模型，并将预测存储回fiftone中，以便进一步可视化和分析:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><h1 id="a681" class="mv mw iq bd mx my mz na nb nc nd ne nf jw ng jx nh jz ni ka nj kc nk kd nl nm bi translated">评估PyTorchVideo模型</h1><p id="44d9" class="pw-post-body-paragraph kw kx iq ky b kz nn jr lb lc no ju le lf np lh li lj nq ll lm ln nr lp lq lr ij bi translated">除了作为数据集监管的开源生态系统，FiftyOne还旨在通过允许您快速<a class="ae kv" href="https://voxel51.com/docs/fiftyone/tutorials/evaluate_classifications.html" rel="noopener ugc nofollow" target="_blank">找到并解决模型故障模式</a>来可视化、评估和解释模型。</p><p id="c255" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为此，我们可以从可视化上一节中生成的预测开始:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/25a55213001c977de8dc3ed24e348d24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t5U0MB1Y39N9COXrzl2_ww.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">PyTorchVideo模型预测在<a class="ae kv" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank">第五十一</a>中可视化(图片由作者提供)</p></figure><p id="6093" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们可以使用<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/evaluation.html" rel="noopener ugc nofollow" target="_blank"> FiftyOne来评估</a>具有基本事实的预测，以查看聚合指标和图表，显示诸如<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#confusion-matrices" rel="noopener ugc nofollow" target="_blank">混淆矩阵</a>和<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#binary-evaluation" rel="noopener ugc nofollow" target="_blank">精确召回曲线</a>之类的东西。这种评估将每个样本的正确性标签(“eval”)添加到数据集，这使得通过正确/不正确的预测进行过滤变得容易，或者更一般地，通过TP/FP/FN进行对象检测。评估只需一行代码即可完成:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><pre class="kg kh ki kj gt nt nu nv nw aw nx bi"><span id="cc73" class="ny mw iq nu b gy nz oa l ob oc">                           precision    recall  f1-score   support</span><span id="fba0" class="ny mw iq nu b gy ol oa l ob oc">       springboard diving       0.80      0.80      0.80         5<br/>            surfing water       1.00      0.60      0.75         5<br/>      swimming backstroke       1.00      0.80      0.89         5<br/>   swimming breast stroke       0.57      0.80      0.67         5<br/>swimming butterfly stroke       1.00      0.60      0.75         5</span><span id="a844" class="ny mw iq nu b gy ol oa l ob oc">                micro avg       0.82      0.72      0.77        25<br/>                macro avg       0.87      0.72      0.77        25<br/>             weighted avg       0.87      0.72      0.77        25</span></pre><p id="88a4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们为我们感兴趣的类绘制混淆矩阵:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/028cd5fcc19de61de30c0ec9dd79bbf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8bKrQE-bGsE_y1IljAtvsw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#confusion-matrices" rel="noopener ugc nofollow" target="_blank">结果在第五十一个</a>的混淆矩阵中可视化(图片由作者提供)</p></figure><p id="8e95" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以将这个图附加到一个会话对象上，使其<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/plots.html" rel="noopener ugc nofollow" target="_blank">交互</a>。因此，如果您单击其中一个单元格，<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/app.html" rel="noopener ugc nofollow" target="_blank"> FiftyOne App </a>会话会更新以显示该单元格中的样本。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/7bcd7931241a7447191483241387c078.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*A7KJ9HyRAFXPMode7tbDZw.gif"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/plots.html#confusion-matrices" rel="noopener ugc nofollow" target="_blank">Jupyter实验室与FiftyOne的互动混淆矩阵</a>(图片由作者提供)</p></figure><p id="8eab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="oi">注意:目前只有Jupyter笔记本中的绘图是交互式的，但其他环境将很快得到支持！</em></p><p id="b9b0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">FiftyOne还提供了一种新颖的查询语言，通过搜索和过滤任何给定的标签和元数据来创建数据集的视图。这使得浏览数据集和查找与您想到的任何问题相关的样本变得非常容易。例如，我们可以基于跨多个类别的相似置信度快速找到模型对其预测最不确定的样本，并使用来自先前评估的每样本正确性标签(“eval”)来仅查看错误预测的样本:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/5c77b6220d94e91686f7adc63146c540.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-pkM2HmsYm1fdOmz0KzjLQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">不确定的PyTorchVideo模型预测在<a class="ae kv" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank">51</a>中被可视化(图片由作者提供)</p></figure><p id="0039" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可视化这些样本让我们了解应该添加到训练数据集中的数据类型。为了标记这些以备将来参考，我们可以使用51应用程序中的<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/app.html#tags-and-tagging" rel="noopener ugc nofollow" target="_blank">标记功能:</a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/14cc390043ec61cdb059f7fbcd5706b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s88fXlu35otnUYCwh_Qfmg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/app.html#tags-and-tagging" rel="noopener ugc nofollow" target="_blank">在第五十一个应用</a>中标记样本(图片由作者提供)</p></figure><p id="1d3b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种动手分析的便利性通常会显著提高数据集质量，从而提高模型性能，比仅使用聚合数据集统计数据的任何分析都要快。</p><h2 id="6c0f" class="ny mw iq bd mx oq or dn nb os ot dp nf lf ou ov nh lj ow ox nj ln oy oz nl pa bi translated">视频中的目标检测</h2><p id="b497" class="pw-post-body-paragraph kw kx iq ky b kz nn jr lb lc no ju le lf np lh li lj nq ll lm ln nr lp lq lr ij bi translated">虽然大多数大型视频数据集和研究工作都围绕着分类问题，如人类活动识别，但基于视频的ML的应用通常涉及对象检测。目前，PyTorchVideo主要支持视频分类问题，但是，在FiftyOne中有视频对象检测功能。</p><p id="eead" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">FiftyOne允许您从<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/model_zoo/index.html#basic-recipe" rel="noopener ugc nofollow" target="_blank"> FiftyOne模型动物园</a>中基于图像的对象检测模型生成预测，或者<a class="ae kv" href="https://voxel51.com/docs/fiftyone/recipes/adding_detections.html" rel="noopener ugc nofollow" target="_blank">将来自您自己模型的预测</a>添加到视频数据集中。动物园里有许多模型可供选择。例如，让我们使用<a class="ae kv" href="https://voxel51.com/docs/fiftyone/user_guide/model_zoo/models.html#efficientdet-d0-coco-tf1" rel="noopener ugc nofollow" target="_blank"> EfficientDet-D0 </a>。我们首先需要安装<a class="ae kv" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>和<a class="ae kv" href="https://github.com/google/automl" rel="noopener ugc nofollow" target="_blank"> AutoML </a>。我们可以使用FiftyOne附带的<a class="ae kv" href="https://github.com/voxel51/eta" rel="noopener ugc nofollow" target="_blank"> eta </a>包轻松安装AutoML:</p><pre class="kg kh ki kj gt nt nu nv nw aw nx bi"><span id="2cc0" class="ny mw iq nu b gy nz oa l ob oc">pip install tensorflow==1.14<br/>eta install automl</span></pre><p id="d661" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们将该模型应用于视频并可视化结果:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pb"><img src="../Images/f6aa3d9f98318d4057850408cc741f7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*9np2za1zRt5xPL52TtLj3A.gif"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">可视化视频对象检测在<a class="ae kv" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank">第五十一</a>(图片由作者提供)</p></figure><p id="a2fa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种可视化需要编写定制脚本来加载原始视频、注释和预测，然后使用像<a class="ae kv" href="https://opencv.org/" rel="noopener ugc nofollow" target="_blank"> OpenCV </a>这样的软件来绘制方框并将可视化导出到磁盘上的新视频中。然后，如果你想改变你正在看的标签，你需要重写你的脚本，并每次重新生成视频。相反，所有这些只花了我们几行代码，并产生了更易于使用和更灵活的数据表示。</p><h1 id="7123" class="mv mw iq bd mx my mz na nb nc nd ne nf jw ng jx nh jz ni ka nj kc nk kd nl nm bi translated">摘要</h1><p id="b370" class="pw-post-body-paragraph kw kx iq ky b kz nn jr lb lc no ju le lf np lh li lj nq ll lm ln nr lp lq lr ij bi translated">基于视频的机器学习模型越来越受欢迎，但缺乏相同水平的易用代码库，以允许快速开发和评估图像模型。<a class="ae kv" href="https://pytorchvideo.org/" rel="noopener ugc nofollow" target="_blank"> PyTorchVideo </a>旨在通过他们的模型动物园、以视频为中心的组件和加速功能，使视频模型更容易实现、训练和评估。另一方面，<a class="ae kv" href="https://pytorchvideo.org/" rel="noopener ugc nofollow" target="_blank"> PyTorchVideo </a>正在使视频模型的工作变得更容易，<a class="ae kv" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank"> FiftyOne </a>是一个开源库，旨在使管理、评估和改进视频(和图像)数据集变得简单高效。<a class="ae kv" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank"> FiftyOne </a>和<a class="ae kv" href="https://pytorchvideo.org/" rel="noopener ugc nofollow" target="_blank"> PyTorchVideo </a>共同为创建高质量视频数据集和模型节省了大量时间和精力。</p></div><div class="ab cl pc pd hu pe" role="separator"><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph"/></div><div class="ij ik il im in"><h1 id="c3c3" class="mv mw iq bd mx my pj na nb nc pk ne nf jw pl jx nh jz pm ka nj kc pn kd nl nm bi translated"><strong class="ak">关于体素51 </strong></h1><p id="9bd7" class="pw-post-body-paragraph kw kx iq ky b kz nn jr lb lc no ju le lf np lh li lj nq ll lm ln nr lp lq lr ij bi translated"><em class="oi">披露:我在Voxel51工作，是</em> <a class="ae kv" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank"> <em class="oi">五十一</em> </a>的开发者</p><p id="073d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://voxel51.com" rel="noopener ugc nofollow" target="_blank"> Voxel51 </a>总部位于密歇根州安阿伯，由密歇根大学教授杰森·科尔索博士和布莱恩·摩尔博士于2016年创立，是一家人工智能软件公司，通过提供开放核心软件构建模块，使计算机视觉和机器学习工程师能够快速设计数据驱动的工作流，从而实现软件2.0的民主化。</p><p id="9aa8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<a class="ae kv" href="http://fiftyone.ai" rel="noopener ugc nofollow" target="_blank"> fiftyone.ai </a>了解更多！</p></div></div>    
</body>
</html>