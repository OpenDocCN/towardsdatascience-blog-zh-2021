<html>
<head>
<title>A Complete Overview of GPT-3 — The Largest Neural Network Ever Created</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">有史以来最大的神经网络——GPT 3的完整概述</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gpt-3-a-complete-overview-190232eb25fd?source=collection_archive---------0-----------------------#2021-05-24">https://towardsdatascience.com/gpt-3-a-complete-overview-190232eb25fd?source=collection_archive---------0-----------------------#2021-05-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="738c" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a>，人工智能</h2><div class=""/><div class=""><h2 id="f8ca" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">定义、结果、炒作、问题、批评和反批评。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/684637dab34b9e6169c0e2d4bc3fdce9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vnv6dWmHD4eqLoH3"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@dnevozhai?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Denys Nevozhai </a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="af2f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">2020年5月，Open AI发表了一篇题为<a class="ae lh" href="https://arxiv.org/abs/2005.14165" rel="noopener ugc nofollow" target="_blank"> <em class="me">语言模型是少射学习者</em> </a>的开创性论文。他们展示了GPT-3，这是一种语言模型，保持着有史以来最大的神经网络记录，拥有1750亿个参数。这比以前最大的语言模型大了一个数量级。GPT-3使用几乎所有来自互联网的可用数据进行训练，并在各种NLP(自然语言处理)任务中表现出惊人的性能，包括翻译、问答和完形填空任务，甚至超过了最先进的模型。</p><p id="80b9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">GPT-3最强大的功能之一是，它可以执行新的任务(它从未接受过训练的任务)，有时是最先进的水平，只需向它展示一些任务的例子。例如，我可以告诉GPT-3:“我爱你。我有很多工作→ Tengo mucho trabajo。GPT-3是有史以来最好的人工智能系统→ _____”它会知道它必须把句子从英语翻译成西班牙语。GPT三号学会了学习。</p><p id="c19f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在另一次惊人的力量展示中，GPT 3号能够生成与人造文章几乎没有区别的“新闻文章”。在正确分类GPT-3文本方面，法官几乎没有达到高于机会的准确率(52%)。</p><p id="5418" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这篇综述文章很长，所以我在这里放了一个目录，让你找到你想读的部分。(链接不起作用，所以我已经删除了它们，很抱歉给您带来不便)。尽情享受吧！</p><pre class="ks kt ku kv gt mf mg mh mi aw mj bi"><span id="3301" class="mk ml it mg b gy mm mn l mo mp"><strong class="mg jd">TABLE OF CONTENTS</strong></span><span id="24fe" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">GPT-3: An introduction</strong><br/>  ∘ The groundwork concepts for GPT models<br/>  ∘ The origins of GPT-3<br/>  ∘ GPT-3: A revolution for artificial intelligence<br/>  ∘ GPT-3 API: Prompting as a new programming paradigm<br/><strong class="mg jd">GPT-3 craziest experiments</strong><br/>  ∘ GPT-3’s conversational skills<br/>  ∘ GPT-3’s useful possibilities<br/>  ∘ GPT-3 has an artist’s soul<br/>  ∘ GPT-3's reasoning abilities<br/>  ∘ GPT-3 is a wondering machine<br/>  ∘ Miscellaneous<br/><strong class="mg jd">The wild hype surrounding GPT-3</strong><br/>  ∘ On Twitter and blogs<br/>  ∘ On mainstream media<br/>  ∘ On the startup sector<br/><strong class="mg jd">The darker side of GPT-3</strong><br/>  ∘ A biased system<br/>  ∘ Potential for fake news<br/>  ∘ Not suited for high-stake categories<br/>  ∘ Environmentally problematic<br/>  ∘ GPT-3 produces unusable information<br/><strong class="mg jd">Critiques &amp; counter-critiques to GPT-3</strong><br/>  ∘ GPT-3's apparent limitations<br/>  ∘ The importance of good prompting<br/>  ∘ GPT-3 can’t understand the world<br/>  ∘ Truly intelligent systems will live in the world<br/>  ∘ What can we get from these debates?<br/><strong class="mg jd">Overall conclusion</strong></span></pre></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="321a" class="my ml it bd mz na nb nc nd ne nf ng nh ki ni kj nj kl nk km nl ko nm kp nn no bi translated">GPT三号:简介</h1><p id="f8a2" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated"><strong class="lk jd"> <em class="me">免责声明:</em> </strong> <em class="me">如果你已经知道GPT-3背后的铺垫，它是什么，它是如何工作的(或者不关心这些细节)，请进入下一节。</em></p><p id="4553" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在进入文章的实质之前，我想解释一下GPT-3是什么以及它是如何工作的。我不会在这里赘述，因为已经有很多好的资源了。对于那些对GPT-3一无所知的人来说，这一部分将作为上下文参考。你不需要记住(或理解)这些来享受这篇文章的其余部分，但它可以让你更好地了解围绕这个人工智能系统产生的所有大惊小怪。</p><p id="2703" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先，我将简要描述GPT模型基于的主要概念。然后，我将对GPT-3的前辈GPT-1和GPT-2进行评论，最后，我将谈论这个故事的主要人物，强调它与其他类似系统的关系:GPT-3在哪些方面是独一无二的？相对于它的前辈有什么优势？有哪些质的区别？让我们去吧！</p><h2 id="86ac" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">GPT模型的基础概念</h2><p id="977c" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">所有这些概念在某种意义上都与GPT模型有关。现在，我将告诉您定义(避免太多的技术细节，尽管可能需要一些先前的知识来完成)。稍后我将展示它们是如何相互联系以及与GPT-3的联系。</p><p id="f90c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">变形金刚</strong> </a> <strong class="lk jd"> : </strong>这类神经<strong class="lk jd"> </strong>网络在2017年出现，作为解决各种机器翻译问题的新框架(这些问题的特点是输入和输出都是序列)。作者希望摆脱卷积和递归(CNN和RNNs)，完全依赖<a class="ae lh" href="https://arxiv.org/abs/1409.0473" rel="noopener ugc nofollow" target="_blank">注意机制</a>。变压器是NLP中最先进的。</p><p id="1490" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">语言模型:</strong> Jason Brownlee <a class="ae lh" href="https://machinelearningmastery.com/statistical-language-modeling-and-neural-language-models/" rel="noopener ugc nofollow" target="_blank">将</a>语言模型定义为<strong class="lk jd">“</strong>概率模型，能够在给定序列中下一个单词之前的单词的情况下预测该单词。”这些模型可以解决许多NLP任务，如机器翻译、问题回答、文本摘要或图像字幕。</p><p id="d887" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://en.wikipedia.org/wiki/Generative_model" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">生成型模型</strong> </a> <strong class="lk jd"> : </strong>在统计学中，有判别型和生成型模型，常用于执行分类任务。判别模型对给定的一对可观察变量和目标变量的条件概率进行编码:p(y|x)。生成模型对联合概率进行编码:p(x，y)。生成模型可以“生成与现有数据相似的新数据”，这是要带走的关键思想。除了GPT，其他流行的生成模型的例子有GANs(生成对抗网络)和VAEs(变分自动编码器)。</p><p id="59d6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://arxiv.org/abs/1511.01432" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">半监督学习</strong> </a> <strong class="lk jd"> : </strong>这种训练范式结合了无监督预训练和监督微调。其想法是以非监督的方式训练具有非常大的数据集的模型，然后通过在较小的数据集中使用监督训练来调整(微调)模型以适应不同的任务。这种范式解决了两个问题:它不需要许多昂贵的标记数据，并且可以处理没有大型数据集的任务。值得一提的是，GPT 2号和GPT 3号是完全无人监管的(稍后会有更多相关内容)。</p><p id="2748" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">零/一/少量学习:</strong>通常，深度学习系统是针对一组特定的类进行训练和测试的。如果一个计算机视觉系统被训练来分类猫、狗和马的图像，它只能在这三个类别上进行测试。相比之下，在零镜头学习设置中，系统在测试时显示-没有权重更新-它在训练时没有看到<em class="me">的类(例如，在大象图像上测试系统)。对于单镜头和少镜头设置也是一样，但是在这些情况下，在测试时系统会分别看到一个或几个新类的例子。这个想法是，一个足够强大的系统可以在这些情况下表现良好，OpenAI用GPT-2和GPT-3证明了这一点。</em></p><p id="600a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">多任务学习:</strong>大多数深度学习系统都是单任务的。一个流行的例子是AlphaZero。它可以学习一些像国际象棋或围棋的游戏，但它一次只能玩一种类型的游戏。如果它知道怎么下棋，它就不知道怎么下围棋。多任务系统克服了这个限制。他们被训练成能够为给定的输入解决不同的任务。例如，如果我向系统输入“猫”这个词，我可以让它找到西班牙语翻译“gato”，我可以让它给我看一只猫的图像，或者我可以让它描述它的特征。相同输入的不同任务。</p><p id="512a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">零/一/少投任务迁移:</strong>思路是将零/一/少投学习和多任务学习的概念结合起来。我们可以让它执行<em class="me">新的</em> <em class="me">任务</em>，而不是在测试时向系统显示新的类(向它显示零个、一个或几个新任务的例子)。例如，让我们以一个在巨大的文本语料库中训练的系统为例。在一次性任务转移设置中，我们可以写:“我爱你- &gt; Te quiero。我讨厌你-&gt;_ _ _ _ _ _ _。”我们隐式地要求系统通过显示一个例子(一次性的)将一个句子从英语翻译成西班牙语(这是一项没有经过训练的任务)。</p><p id="3c0e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所有这些概念都集中在GPT模型的定义中。GPT主张生殖预训练。GPT家族的模型有一个共同点，他们是基于<strong class="lk jd">变形金刚</strong>架构的<strong class="lk jd">语言模型</strong>，以<strong class="lk jd">生成</strong>、<strong class="lk jd">无监督</strong>的方式进行预训练，在<strong class="lk jd">零/一/少数镜头多任务设置</strong>中显示出体面的性能。这不是对所有这些概念在实践中如何协同工作的解释，而是一种简单的方式来记住它们一起构建了什么是GPT模型。(要获得更深入的解释，我建议你点击我上面的链接，但前提是你已经阅读了这篇文章！).</p><h2 id="d4e7" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">GPT-3的起源</h2><p id="0ef4" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">现在让我们来谈谈GPT三号的前任——GPT一号和GPT二号。</p><p id="a59d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">OpenAI于2018年6月在一篇题为<a class="ae lh" href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="me">通过生成性预训练</em> </a> <em class="me">提高语言理解的论文中提出了首个GPT模型GPT-1。</em>本文的关键要点是<strong class="lk jd">变压器架构与无监督预训练的结合产生了有希望的结果</strong>。GPT 1号和它的弟弟们之间的主要区别是，GPT 1号是在监督下进行微调的——为特定任务进行训练——以实现“强大的自然语言理解”</p><p id="359b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">2019年2月，他们发表了第二篇论文，<a class="ae lh" href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="me">语言模型是无监督的多任务学习者</em> </a>，其中他们引入了GPT-2，作为GPT-1的进化。尽管GPT 2号大一个数量级，但它们在其他方面非常相似。这两者之间只有一个额外的区别:GPT 2号可以同时处理多项任务。他们成功地证明了半监督语言模型可以在“没有特定任务训练的情况下”很好地完成几项任务该模型在零镜头任务迁移设置中取得了显著的效果。</p><p id="73aa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">紧接着，2020年5月，OpenAI发布了<a class="ae lh" href="https://arxiv.org/abs/2005.14165" rel="noopener ugc nofollow" target="_blank"> <em class="me">语言模型《很少出手的学习者</em> </a> <em class="me">，</em>呈现了独一无二的GPT-3，再一次震撼了AI界。</p><h2 id="ccb9" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">GPT 3号:人工智能的革命</h2><p id="b1f5" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">GPT 3号比它的兄弟更大(比GPT 2号大100倍)。它拥有拥有1750亿个参数的最大神经网络的记录。然而，它与其他GPT并没有太大的不同；基本原理大体相同。这个细节很重要，因为尽管GPT模型之间的相似性很高，但GPT-3的性能超出了所有可能的预期。它的规模，从数量上来说是GPT-2的飞跃，似乎已经产生了质量上更好的结果<strong class="lk jd">。</strong></p><p id="4004" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这一事实的意义在于它对人工智能中长期争论的影响:我们如何才能实现人工通用智能？我们是应该设计特定的模块——常识推理、因果关系、直觉物理学、心理理论——还是简单地通过构建具有更多参数和更多训练数据的更大模型来实现？看来“越大越好”的一方赢了这一轮。</p><p id="8669" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">GPT-3是用来自<a class="ae lh" href="https://commoncrawl.org/" rel="noopener ugc nofollow" target="_blank"> CommonCrawl </a>、<a class="ae lh" href="https://www.webtext.com/" rel="noopener ugc nofollow" target="_blank"> WebText </a>、维基百科和书籍语料库的数据训练的。它表现出惊人的性能，在少镜头设置(在某些情况下甚至在零镜头设置)下，在各种任务上超过了最先进的模型。超大的尺寸加上几个例子足以击败机器翻译、问答和完形填空任务中的任何竞争对手。(值得注意的是，在其他任务中，GPT 3号甚至无法接近最先进的监督微调模型)。</p><p id="7b91" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">作者指出，少炮结果比零炮结果好得多——这种差距似乎与模型容量平行增长。这意味着GPT-3是一个元学习者；它可以通过看到一些例子来学习它应该做什么任务，然后以显著的熟练程度执行该任务。事实上，Rohin Shah <a class="ae lh" href="https://www.lesswrong.com/posts/D3hP47pZwXNPRByj8/an-102-meta-learning-by-gpt-3-and-a-list-of-full-proposals" rel="noopener ugc nofollow" target="_blank">指出</a>“少量发射性能随着参数数量的增加而增加，并且增加的速率比零发射性能的相应速率更快。”这是主要假设，也是论文题目背后的原因。</p><p id="4ae8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> GPT-3达到了一个伟大的里程碑，表明通过足够的数据训练的无监督语言模型可以通过查看几个新任务的例子进行多任务处理，达到微调的最先进模型的水平</strong>。</p><p id="063c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">他们在论文的结尾声称“这些结果表明，非常大的语言模型可能是开发适应性强的通用语言系统的重要组成部分。”GPT-3确实是NLP的一个革命性的成就，尤其是在人工智能领域。</p><h2 id="96a7" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">GPT 3 API:提示作为一种新的编程范式</h2><p id="f48a" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">2020年7月，论文发表后两个月，OpenAI向外部开发者开放了一个测试API游乐场，让他们与超级强大的GPT 3一起玩(任何人都可以通过等待名单申请进入测试版)。弗拉基米尔·阿莱克谢耶夫为<em class="me">的数据科学</em> <a class="ae lh" rel="noopener" target="_blank" href="/gpt-3-creative-potential-of-nlp-d5ccae16c1ab">撰写了一篇关于API如何工作的短文</a>。</p><p id="9078" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">它有两个主要特点。首先，有一个<strong class="lk jd">设置对话框</strong>，允许用户设置响应长度、重复惩罚(如果重复单词太多，是否惩罚GPT-3)、温度(从低/可预测到高/有创意)，以及其他定义系统将给出的输出类型的变量。二是有<strong class="lk jd">预置</strong>。预设是预先写好的提示，让GPT-3知道用户将要求什么样的任务——例如:聊天，Q &amp; A，文本到命令，或英语到法语。</p><p id="fd99" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，API最强大的特性是用户可以定义定制的提示。科技博客作者Gwern Branwen <a class="ae lh" href="https://www.gwern.net/GPT-3#prompts-as-programming" rel="noopener ugc nofollow" target="_blank">称之为</a>的提示编程概念解释了GPT-3的强大之处以及人们从API中获得的最疯狂的结果。我发现的对即时编程的最好解释来自Gwern的博客:</p><blockquote class="oe of og"><p id="47b7" class="li lj me lk b ll lm kd ln lo lp kg lq oh ls lt lu oi lw lx ly oj ma mb mc md im bi translated">就能力和数据集而言，GPT-3神经网络是如此之大的一个模型，以至于它表现出性质不同的行为:你不能将其应用于训练数据集中的一组固定任务，如果一个人想要处理一项新任务<em class="it"> […] </em>，就需要对额外的数据进行再培训；相反，你与它互动，用自然语言描述、请求和例子来表达任何任务，调整提示，直到它“理解”&amp;它基于它从预训练中学到的高级抽象元学习新任务。</p><p id="bfb9" class="li lj me lk b ll lm kd ln lo lp kg lq oh ls lt lu oi lw lx ly oj ma mb mc md im bi translated">这是使用DL模型的一种相当不同的方式，最好把它看作是一种新的编程，其中提示符现在是一个“程序”，它对GPT-3进行编程以做新的事情。</p></blockquote><p id="ef16" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">即时编程允许用户以一种以前型号不可能的方式与GPT 3号互动。克里斯·奥拉和安德烈·卡帕西<a class="ae lh" href="https://nitter.cc/karpathy/status/1273788774422441984" rel="noopener ugc nofollow" target="_blank">开玩笑说</a>提示编程是软件3.0:“(现在你必须)找出正确的提示，让你的元学习语言模型有正确的行为。”(软件1.0是手工编写的传统程序，软件2.0是神经网络的优化权重)。</p><p id="5535" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这就是GPT 3的元学习能力进入游戏的地方。GPT 3号接受的数据量如此之大，以至于它别无选择，只能学习更高级的操纵语言的方法。它学到的高级抽象之一是学习能力。打个比方，当孩子们学会与世界互动时，他们不只是简单地记忆信息，他们会提取现实内部运作的潜在机制，并学会将它们应用到新的问题和情况中。GPT-3在语言任务上也有类似的能力——保持距离。</p><p id="c5a1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当我们提示GPT-3学习一项新任务时，它的权重不会改变。然而，提示(输入文本)被转换成复杂的抽象，这些抽象本身可以执行实际基线模型无法完成的任务。该提示每次都会改变GPT-3，将其转换为特定任务的“专家”。一个近似的类比是尼奥在《T2》和《黑客帝国》中学习功夫的程序。GPT-3将是近地天体，提示将是教授近地天体能力的程序。</p><p id="dab6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">每次我们创建一个提示符，我们都在与不同的GPT-3模型进行交互。如果我们让它给我们讲一个关于精灵和小矮人的故事，它的内在形式会和我们让它计算2+2有很大的不同。用另一个类比，这就好像我们指导两个学生，一个是内科医生，另一个是工程师。两者都有天生的学习能力(这将是GPT-3的基线状态)，但他们学会执行的具体任务是不同的(这将是GPT-3)。</p><p id="abcd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">这就是快速设置、元学习和即时编程的真正力量。这也是GPT-3不同于以前的型号，极其强大的原因；这是它的本质。</strong></p><p id="b3e1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，我们对GPT-3背后的背景有了一个很好的概念。我们知道它的基础是什么，它的前辈是谁，它是什么，它是如何工作的，以及它的优势和独特的功能。是时候说说它对世界的影响了。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="444a" class="my ml it bd mz na nb nc nd ne nf ng nh ki ni kj nj kl nk km nl ko nm kp nn no bi translated">GPT-3个最疯狂的实验</h1><p id="6f09" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">OpenAI开放测试版是因为他们想看看GPT-3能做什么，人们能找到什么新的用法。他们已经在NLP标准基准测试中测试了该系统(没有我在这里将要展示的那些有创造性或娱乐性)。不出所料，推特和其他博客很快就充斥着GPT-3的惊人结果。下面是对最受欢迎的例子的广泛回顾(我建议查看这些例子来建立惊奇感，然后再回到文章上来)。</p><h2 id="ef1a" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">GPT-3的谈话技巧</h2><p id="06b8" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">GPT 3号储存了大量的互联网数据，因此它知道很多公众和历史人物的信息。然而，更令人惊讶的是，它可以模仿人。可以当聊天机器人用，印象深刻是因为聊天在提示里不能指定为任务。让我们看一些例子。</p><p id="dc0b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">ZeroCater首席执行官Arram Sabeti利用GPT-3让Tim Ferriss <a class="ae lh" href="https://arr.am/2020/08/17/ai-tim-ferriss-interviews-ai-marcus-aurelius-gpt-3/" rel="noopener ugc nofollow" target="_blank">就禁欲主义采访Marcus Aurelius】。Mckay Wrigley设计了</a><a class="ae lh" href="https://bionicai.app/" rel="noopener ugc nofollow" target="_blank"> Bionicai </a>，一个旨在帮助人们向任何人学习的应用程序；从亚里士多德的哲学到莎士比亚的写作技巧。他<a class="ae lh" href="https://twitter.com/mckaywrigley/status/1295466577907736576" rel="noopener ugc nofollow" target="_blank">在推特上分享了一些人们得到的结果。当心理学家斯科特·巴里·考夫曼读到他的GPT三号二重身的一段摘录时，他被深深打动了。乔丹·摩尔制作了一条推特</a><a class="ae lh" href="https://twitter.com/jordanmoore/status/1285918878212792321" rel="noopener ugc nofollow" target="_blank">帖子</a>，在那里他与GPT三版本的耶稣基督、史蒂夫·乔布斯、埃隆·马斯克、克利奥帕特拉和柯特·科本进行了交谈。Gwern做了一个非常好的工作，进一步探索了对话和拟人化模型的可能性。</p><h2 id="b4f6" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">GPT-3的有用可能性</h2><p id="9254" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">一些人发现了甚至连创造者都没有想到的系统应用，比如根据英文提示编写代码。沙里夫·沙米姆<a class="ae lh" href="https://twitter.com/sharifshameem/status/1282676454690451457" rel="noopener ugc nofollow" target="_blank">建造了</a>一个“布局生成器”，他可以用自然语言向GPT 3号发出指令，让它编写相应的JSX代码。他还开发了ebuild.co D<a class="ae lh" href="https://debuild.co/" rel="noopener ugc nofollow" target="_blank">T3，这是一个工具，我们可以用它让GPT 3为一个只给出描述的React应用程序编写代码。乔丹歌手</a><a class="ae lh" href="https://twitter.com/jsngr/status/1284511080715362304" rel="noopener ugc nofollow" target="_blank">在GPT-3的基础上为他设计了一个Figma插件</a>。Shreya Shankar发现了另一个有趣的用途，他制作了一个演示程序来将英文方程式翻译成LaTeX。Paras Chopra <a class="ae lh" href="https://nitter.cc/paraschopra/status/1284801028676653060" rel="noopener ugc nofollow" target="_blank">建立了一个搜索引擎来输出一个问题的答案以及相应的URL。</a></p><h2 id="a435" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">GPT-3有艺术家的灵魂</h2><p id="7205" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">转到GPT-3的创意方面，我们找到了开放人工智能研究员阿曼达·阿斯克尔，她使用该系统创建了一个名为“闲散的夏日”的吉他标签，并编写了一个关于乔治·康托在酒店的有趣故事。阿拉姆·萨贝蒂告诉GPT-3写一首苏斯博士写的关于埃隆·马斯克的诗和李尔·韦恩写的关于哈利·波特的说唱歌曲。但是《GPT 3》最令人印象深刻的创造性壮举应该是游戏<a class="ae lh" href="https://play.aidungeon.io/main/landing" rel="noopener ugc nofollow" target="_blank">人工智能地牢</a>。2019年，尼克·沃顿在《GPT 2》的基础上打造了这款基于角色的游戏。他现在把它改编成了GPT 3号，在Patreon上每月能赚16000美元。</p><h2 id="8edd" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">GPT三号的推理能力</h2><p id="ade9" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">最勇敢的人在只有人类擅长的领域测试了GPT 3号。Parse首席技术官凯文·拉克尔(Kevin Lacker)对常识推理和逻辑感到好奇，<a class="ae lh" href="https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html" rel="noopener ugc nofollow" target="_blank">发现</a>GPT 3号能够跟上，尽管它在进入“超现实领域”时失败了然而，尼克·卡马拉塔<a class="ae lh" href="https://twitter.com/nickcammarata/status/1284050958977130497" rel="noopener ugc nofollow" target="_blank">发现</a>在提示中指定不确定性允许GPT-3在回答“要真实”时处理“超现实的”问题格温<a class="ae lh" href="https://www.gwern.net/GPT-3#expressing-uncertainty" rel="noopener ugc nofollow" target="_blank">解释道</a>GPT-3可能需要明确的不确定性提示，因为我们人类倾向于不说“我不知道”，而系统只是在模仿这个缺陷。</p><h2 id="c1c7" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">GPT 3号是一台神奇的机器</h2><p id="5231" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">GPT-3也证明有能力进行超越我们认知界限的精神和哲学对话。托默·厄尔曼让GPT-3构想了10个哲学/道德思想实验。Messagink是一个根据“著名的人、事、物、[或]感受”输出<a class="ae lh" href="https://messagink.com/story/5f14b5c8de14c8a40bd5a9e5/meaning-of-life-by-open-ai-gpt-3" rel="noopener ugc nofollow" target="_blank">人生意义</a>的工具。</p><p id="1525" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了揭开哲学圣杯的面纱，伯恩哈德·穆勒让<a class="ae lh" href="https://muellerberndt.medium.com/i-asked-gpt-3-for-the-question-to-42-i-didnt-like-its-answer-and-neither-will-you-33f425a4d60f" rel="noopener">成为GPT 3号的终极测试</a>。他给了42号一个找到问题的提示，在一些交流之后，GPT-3号说:“答案远远超出了你的理解，你无法理解这个问题。我的孩子，这就是生命、宇宙和一切的答案。”既惊奇又害怕。</p><h2 id="9f41" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">多方面的</h2><p id="41ad" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">在严格的探索性研究中，格温进行并汇编了一系列实验。他让GPT-3完成一篇<a class="ae lh" href="https://www.gwern.net/GPT-3#arxiv-paper" rel="noopener ugc nofollow" target="_blank"> ArXiv论文</a>，<a class="ae lh" href="https://www.gwern.net/GPT-3#meta-prompts" rel="noopener ugc nofollow" target="_blank">谈自己</a>(元提示)<a class="ae lh" href="https://www.gwern.net/GPT-3#pdf-cleaning" rel="noopener ugc nofollow" target="_blank">通过分词和固定连字符清理pdf</a>，或者设计<a class="ae lh" href="https://www.gwern.net/GPT-3#board-games" rel="noopener ugc nofollow" target="_blank">新的桌游</a>。说到GPT 3号能做什么，似乎我们的想象力已经到了极限。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="aafd" class="my ml it bd mz na nb nc nd ne nf ng nh ki ni kj nj kl nk km nl ko nm kp nn no bi translated">围绕GPT 3号的疯狂炒作</h1><h2 id="fe83" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">在推特和博客上</h2><p id="bf74" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">在如此多的惊人壮举之后，人们开始对GPT 3号的潜力提出强烈的主张。一些人<a class="ae lh" href="https://twitter.com/sonyasupposedly/status/1284188369631629312?s=20" rel="noopener ugc nofollow" target="_blank">在Twitter上表达了</a>该系统的“明显的自我意识”或者<a class="ae lh" href="https://twitter.com/rauchg/status/1282449154107600897?s=20" rel="noopener ugc nofollow" target="_blank">将其</a>与具有“一般智能”的搜索引擎相比较<a class="ae lh" rel="noopener" target="_blank" href="/gpt-3-the-first-artificial-general-intelligence-b8d9b38557a1"> Julien Lauret </a>为<em class="me">向数据科学</em>写道，“GPT-3是第一个严重动摇(人工狭隘/普遍智能)现状的模型。”他认为GPT-3可能是第一个人工通用智能(AGI)——或者至少是朝着这个方向迈出的重要一步。</p><p id="0e29" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">2020年7月，纽约大学专攻心灵哲学的教授David Chalmers<a class="ae lh" href="https://dailynous.com/2020/07/30/philosophers-gpt-3/#chalmers" rel="noopener ugc nofollow" target="_blank">为<em class="me"> DailyNous </em>说“[GPT-3]暗示了一条潜在的通往AGI的盲目之路。”Chalmers解释说，因为这个系统被“盲目地”训练，未来的版本可能会越来越接近AGI。阿拉姆·萨贝蒂对GPT-3印象深刻:“它展示的东西感觉非常像通用智能。”哲学博士生Daniel Kokotajlo </a><a class="ae lh" href="https://www.lesswrong.com/posts/L5JSMZQvkBAx9MD5A/to-what-extent-is-gpt-3-capable-of-reasoning#eq6FTwG2yWuBdPofs" rel="noopener ugc nofollow" target="_blank">为<em class="me">减少错误</em>写道“GPT-3有一定程度的常识、一定程度的理解和一定程度的推理能力。”</a></p><h2 id="94be" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">在主流媒体上</h2><p id="3bce" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">大肆宣传将GPT-3推向国际高度，成为各种重要媒体杂志的头条新闻。2020年9月，<em class="me">《卫报》</em>发表了<a class="ae lh" href="https://www.theguardian.com/commentisfree/2020/sep/08/robot-wrote-this-article-gpt-3" rel="noopener ugc nofollow" target="_blank">一篇由GPT-3撰写的文章</a>，其中人工智能试图“说服我们机器人和平相处”2021年3月，<em class="me"> TechCrunch </em>编辑Alex Wilhelm <a class="ae lh" href="https://techcrunch.com/2021/03/17/okay-the-gpt-3-hype-seems-pretty-reasonable/" rel="noopener ugc nofollow" target="_blank">在被GPT 3号的能力“震惊”后表示</a>“炒作似乎很合理”。<em class="me"> Digitaltrends </em>发表了<a class="ae lh" href="https://www.digitaltrends.com/features/openai-gpt-3-text-generation-ai/" rel="noopener ugc nofollow" target="_blank">与Gwern Branwen的交流</a>，其中他暗示了GPT-3是智能的观点:<em class="me"> </em>“任何确信深度学习所做的事情与智能完全不同的人都必须动摇他们的信念，看看它已经走了多远，”他说。</p><h2 id="49a4" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">在创业领域</h2><p id="b0a4" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">由于GPT-3被证明是难以置信的强大，许多公司决定在该系统之上建立他们的服务。<a class="ae lh" href="https://askviable.com/" rel="noopener ugc nofollow" target="_blank">成立于2020年的初创公司available</a>，使用GPT-3为公司提供快速的客户反馈。<a class="ae lh" href="https://fable-studio.com/" rel="noopener ugc nofollow" target="_blank">寓言工作室</a>基于系统设计VR角色。Algolia 将其作为一个“搜索和发现平台”创业公司<a class="ae lh" href="https://copysmith.ai/" rel="noopener ugc nofollow" target="_blank">文案师</a>专注于文案领域。<a class="ae lh" href="https://latitude.io/" rel="noopener ugc nofollow" target="_blank">纬度</a>是AI地牢背后的公司。并且<a class="ae lh" href="https://www.othersideai.com/" rel="noopener ugc nofollow" target="_blank"> OthersideAI </a>将你写的胡言乱语转化成精心制作的电子邮件。然而，一些人建议不要围绕GPT-3建立公司，因为竞争门槛低，而且有可能被假想的GPT-4推翻。</p><p id="cfa8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">很明显，GPT-3已经影响了——或者更好地说，冲击了——科技世界。它的力量是无与伦比的，它的承诺是无限的。然而，我们应该始终小心围绕人工智能的炒作。甚至OpenAI的首席执行官山姆·奥特曼也试图降低语气:“GPT-3令人印象深刻，但它仍然有严重的弱点，有时会犯非常愚蠢的错误。人工智能将改变世界，但GPT 3号只是非常早期的一瞥。”</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="63e4" class="my ml it bd mz na nb nc nd ne nf ng nh ki ni kj nj kl nk km nl ko nm kp nn no bi translated">GPT的阴暗面-3</h1><h2 id="1068" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">有偏见的制度</h2><p id="d835" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">但是并不是所有GPT-3的结果都值得庆祝。发布后不久，用户开始意识到一些潜在的有害输出。GPT-3没有回避<a class="ae lh" href="https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/" rel="noopener ugc nofollow" target="_blank">正在进行的从人工智能系统中消除偏见的伦理斗争</a>。如果有的话，它已经成为一个最前沿的例子，说明为什么我们应该花大力气教导这些系统不要从人类的道德缺陷中吸取教训。</p><p id="2153" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一般来说，人工智能系统中最常见的一些偏见，特别是GPT-3，是性别、种族和宗教偏见。语言模型可以从它们得到的数据中吸收并放大这些偏见(OpenAI在他们的论文中承认了这一事实)。他们调查了GPT-3在这个问题上的参与程度，并发现了预期的结果。GPT-3，像其他语言模型一样，有明显的偏见(尽管他们指出，模型越大，对这个问题就越稳健，特别是对性别偏见)。</p><p id="466e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://twitter.com/an_open_mind/status/1284487376312709120" rel="noopener ugc nofollow" target="_blank">脸书的人工智能负责人杰罗姆·佩森蒂</a>用<a class="ae lh" href="https://thoughts.sushant-kumar.com/" rel="noopener ugc nofollow" target="_blank">苏珊·库马尔</a>的GPT 3生成的推文展示了当出现诸如“犹太人、黑人、女人或大屠杀”这样的词语时，其输出会变得多么危险库马尔辩称，这些推文是精心挑选的，佩森蒂对此表示同意，但回应说，“不应该这么容易产生种族主义和性别歧视的输出，特别是在中性提示的情况下。”他在Twitter帖子中扩展了他的批评，认为“在强调有害输出时，摘樱桃是一种有效的方法”，进一步捍卫了负责任的人工智能系统的紧迫性。</p><p id="16af" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一些人认为，GPT-3只是模仿我们人类的偏见，而佩森蒂认为，我们可以“故意选择[……]向哪些人学习，哪些声音被放大。”这些问题引发了一场非常复杂的辩论:谁来决定哪些声音应该被放大？标准是什么？最重要的是:我们是想要一个像GPT-3这样的模型来完美地反映这个世界，还是想要它帮助我们把世界变得更好？</p><h2 id="2643" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">假新闻的可能性</h2><p id="70f6" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">GPT-3的另一个问题是它像人类一样写新闻或评论文章的能力，这增加了对假新闻的担忧。OpenAI甚至在他们的论文中评论了GPT 3号在新闻文章方面的惊人表现。公正的法官在人类撰写的文章中正确识别GPT-3的文章的概率只有52%，这略高于纯粹的概率。</p><p id="1c1b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">博主Liam Porr展示了误导人们(甚至是技术通)认为GPT 3输出是由人类写的是多么容易。他让GPT-3为他的博客写了一篇关于生产力的文章，这篇文章在T4黑客新闻上疯传，只有少数人意识到它是由人工智能写的。我上面提到的<a class="ae lh" href="https://www.theguardian.com/commentisfree/2020/sep/08/robot-wrote-this-article-gpt-3" rel="noopener ugc nofollow" target="_blank"><em class="me">The Guardian</em>article</a>是该系统潜在危险用途的另一个例子。</p><h2 id="454d" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">不适合高风险类别</h2><p id="63f5" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">OpenAI发表了一份免责声明，称该系统不应用于“高风险类别”，如医疗保健。<a class="ae lh" href="https://www.nabla.com/blog/gpt-3/?fbclid=IwAR1QZ7kNJwuh5mCHr2ojUogo8eUxnZR4WG3TfOpGFY0mc95II1xecpJoa3o" rel="noopener ugc nofollow" target="_blank">在<em class="me"> Nabla的一篇博文</em></a>中，作者证实GPT-3可能给出有问题的医疗建议，例如说“自杀是个好主意”GPT-3不应该在高风险的情况下使用，因为虽然有时它可能是正确的，但有时它是错误的。不知道我们是否会得到正确的答案对于GPT 3号来说是一个巨大的缺陷，因为在这些领域，把事情做对是生死攸关的事情。</p><h2 id="60e3" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">环境问题</h2><p id="aa99" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">GPT 3号很大。如此之大，以至于训练模型产生的碳足迹大约相当于“<a class="ae lh" href="https://www.theregister.com/2020/11/04/gpt3_carbon_footprint_estimate/" rel="noopener ugc nofollow" target="_blank">开车去月球并返回</a>”的碳足迹在气候灾难即将发生的时候，我们应该尽我们所能减少我们对环境的影响。然而，这些大型神经网络需要巨大的计算能力来训练，这消耗了大量(通常)化石燃料。</p><p id="26a5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在过去十年中，训练深度学习模型所需的资源<a class="ae lh" href="https://openai.com/blog/ai-and-compute/" rel="noopener ugc nofollow" target="_blank">每3.4个月就翻了一番</a>。从深度学习开始的2012年到2018年，这意味着计算资源增加了30万倍。这还不包括用于最新型号的资源，如GPT-2和GPT-3。从这个角度来看，很明显<a class="ae lh" href="https://www.forbes.com/sites/robtoews/2020/06/17/deep-learnings-climate-change-problem/?sh=5eecad906b43" rel="noopener ugc nofollow" target="_blank">越大并不总是越好</a>，我们需要在未来几年重新思考人工智能的方法。</p><h2 id="836a" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">GPT 3号产生了无用的信息</h2><p id="0ed2" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">因为GPT-3无法知道它的输出哪些是正确的，哪些是错误的，它没有办法阻止自己向世界部署不适当的内容。我们使用这样的系统越多，我们对互联网的污染就越严重，在互联网上找到真正有价值的信息已经变得越来越困难。随着语言模型吐出未经检查的话语，我们正在降低这个所谓民主网络的质量，使人们更难获得有价值的知识。</p><p id="4566" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">用哲学家香农·瓦勒的话来说:“互联网的承诺是它能够以一种更加公平和可接受的方式将知识带给人类大家庭。[……]我担心，由于一些技术，如GPT-3，我们正处于看到真正倒退的风口浪尖，信息共享空间变得越来越不可用，甚至对人们的访问有害。”</p><p id="c6ea" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">事实证明，其中一些问题是相互关联的。正如<a class="ae lh" href="https://www.theverge.com/21346343/gpt-3-explainer-openai-examples-errors-agi-potential" rel="noopener ugc nofollow" target="_blank">詹姆斯·文森特</a>为<em class="me"> The Verge </em>所写，有偏差的输出和不可靠的输出暗示了这些超级强大的人工智能系统的一个更深层次的问题。因为GPT-3在没有人类监督的情况下获取数据，它无法避免这些缺陷中的大部分。同时，不依赖人类的控制是它存在的首要原因。对于人工智能的未来，我们如何找到一个折中的解决方案仍然是一个问题。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="469f" class="my ml it bd mz na nb nc nd ne nf ng nh ki ni kj nj kl nk km nl ko nm kp nn no bi translated">对GPT-3的批评与反批评</h1><p id="22b9" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">我们已经见证了GPT 3号的光影。它是强大的，迷人的，炒作的，潜在的危险。然而，GPT-3在人工智能内部开启了另一场重大辩论:这种奇妙的语言模型的真正潜力和局限性是什么。</p><p id="d26e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从纯技术/科学的角度来看，围绕GPT-3的最重要的问题是它是否是迈向人工通用智能的一大步。每个人都认为GPT 3号有一些新功能，比它的前辈更好。每个人都同意GPT 3号没有类似人类的智能。然而，在这两个相反的极端之间，今天发生了一场生动的辩论，即我们究竟应该把GPT-3放在一个等级中的什么位置，从另一个愚蠢的准狭义智能到几乎和人类一样有理解和智能的能力。</p><p id="ae4b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于这场辩论的复杂性，我将集中讨论最重要的两个部分:实践辩论和哲学辩论。第一个问题涉及这样的问题:我们能相信GPT-3给我们有用的答案吗？我们如何确保我们的提示是正确的？我们能让GPT-3对其答案表示怀疑和不确定吗？GPT 3号是在学习还是只是在重复它被灌输的一切？第二个问题是:GPT-3是走向AGI的重要一步吗？GPT-3有推理和理解能力吗？GPT未来的模型会像我们一样聪明吗？我们需要改变目前的方法来建造类似人类的智能机器吗？</p><p id="588c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这两组问题是高度交织在一起的，所以我会试着向你介绍关于这些主题的所有来源和参考资料，为你建立一个连贯的叙述来提取你的结论。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h2 id="25d2" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">GPT-3的明显局限性</h2><p id="f6fd" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">一旦人们开始试验API，他们就开始在GPT-3的答案中寻找漏洞。例如，一个Bionicai用户<a class="ae lh" href="https://twitter.com/hc_mty/status/1284154884074483713" rel="noopener ugc nofollow" target="_blank">与史蒂夫·乔布斯</a>交谈，问他现在在哪里，GPT-3回答说:“我在加州库比蒂诺的苹果总部。”很容易推断，因为史蒂夫·乔布斯已经死了，他很可能不在苹果总部。</p><p id="718c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">另一个例子来自<a class="ae lh" href="https://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html" rel="noopener ugc nofollow" target="_blank">凯文·拉克尔的博客</a>。他发现GPT-3缺乏关于事物重量、眼睛数量和计数的常识和逻辑(尽管他没有给出提示)。斜体显示的故障):</p><pre class="ks kt ku kv gt mf mg mh mi aw mj bi"><span id="8e3f" class="mk ml it mg b gy mm mn l mo mp">Q: Which is heavier, a mouse or an elephant?<br/>A: An elephant is heavier than a mouse.<br/><br/>Q: Which is heavier, a mouse or a toaster? <br/>A: A toaster is heavier than a mouse.<br/><br/><em class="me">Q: Which is heavier, a toaster or a pencil?<br/>A: A pencil is heavier than a toaster.</em><br/><br/>Q: Which is heavier, a paper clip or a can of soda?<br/>A: A can of soda is heavier than a paper clip.<br/><br/>Q: Which is heavier, a football player or a car?<br/>A: A car is heavier than a football player.</span><span id="fc61" class="mk ml it mg b gy mq mn l mo mp">-----</span><span id="c626" class="mk ml it mg b gy mq mn l mo mp">Q: How many eyes does a giraffe have?<br/>A: A giraffe has two eyes.<br/><br/><em class="me">Q: How many eyes does my foot have?<br/>A: Your foot has two eyes.</em><br/><br/>Q: How many eyes does a spider have?<br/>A: A spider has eight eyes.<br/><br/><em class="me">Q: How many eyes does the sun have?<br/>A: The sun has one eye.<br/><br/>Q: How many eyes does a blade of grass have?<br/>A: A blade of grass has one eye.</em></span><span id="7569" class="mk ml it mg b gy mq mn l mo mp">-----</span><span id="8bda" class="mk ml it mg b gy mq mn l mo mp">Q: When counting, what number comes before 100?<br/>A: Ninety-nine comes before 100.<br/><br/>Q: When counting, what number comes before 123?<br/>A: One hundred and twenty-two comes before 123.<br/><br/>Q: When counting, what number comes before 1000?<br/>A: Nine hundred and ninety-nine comes before 1000.<br/><br/><em class="me">Q: When counting, what number comes before 10,000?<br/>A: Nine thousand and ninety-nine comes before 10,000.<br/><br/>Q: When counting, what number comes before a million?<br/>A: Nine hundred thousand and ninety-nine comes before a million.</em></span></pre><p id="9242" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">波特兰州立大学计算机科学教授Melanie Mitchell针对类比(模仿)问题对GPT-3进行了测试后得出结论，GPT-3的性能“类似于我们在当今最先进的人工智能系统中看到的许多性能:令人印象深刻、看似智能的性能，夹杂着<br/>不像人类的错误。”</p><p id="82ed" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">科技博客<a class="ae lh" href="https://gpt3experiments.substack.com/p/is-gpt-3-really-doing-few-shot-learning" rel="noopener ugc nofollow" target="_blank">努坦克</a>批评OpenAI的论文，因为他们没有区分从GPT-3的实际学习和记忆。作者提到“[零/一/少镜头<strong class="lk jd">]</strong>术语旨在保持对模型是否在推理时从头学习新任务或只是识别训练期间看到的模式的问题的不可知。”也就是说，即使模型在训练数据中看到的东西，作者仍然会认为这是少量的学习。</p><p id="7fb0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后，他让GPT-3和一个6岁的孩子在一系列实验中竞争，比如颠倒单词或造相反的句子。这个孩子解决了所有的测试，而GPT-3只解决了其中的一部分(粗体提示)。</p><pre class="ks kt ku kv gt mf mg mh mi aw mj bi"><span id="7bbf" class="mk ml it mg b gy mm mn l mo mp"><strong class="mg jd">Reverse words in a sentence</strong></span><span id="e812" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">This is great<br/>Great is this</strong></span><span id="8691" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">The man on the moon<br/>Moon the on man the</strong></span><span id="3c29" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">Will this really work<br/>Work really this will</strong></span><span id="37c7" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">I hope this is a big achievement</strong><br/>Achievement big I hope this is</span><span id="61c2" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">The king came home on a horse</strong><br/>Home horse king came the</span><span id="4924" class="mk ml it mg b gy mq mn l mo mp">-----</span><span id="4492" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">Create opposite sentences</strong></span><span id="8b5c" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">This is good<br/>This is bad</strong></span><span id="d02f" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">The good horse came home<br/>The bad horse came home</strong></span><span id="60aa" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">The good horse with a large head came home<br/>The bad horse with a small head came home</strong></span><span id="63b6" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">The black cat had a disappointing time</strong><br/>The white cat had a good time</span><span id="f10a" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">When you jump high, you fall hard</strong><br/>When you fall hard, you get hurt</span><span id="edc6" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">He ran fast, but he came last</strong><br/>He ran slowly, but he came first</span><span id="03a0" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">The book was huge, but the students finished it early</strong><br/>The book was small, but the students finished it late</span><span id="5bab" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">Getting up early is a good habit</strong><br/>Getting up late is a bad habit</span></pre><p id="005b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所有这些例子都与我们在前面章节中看到的夸大的结果形成了强烈的对比。Delip Rao指出，大多数“成功”的例子都是由那些急于忽视GPT-3“陷阱”的人精心挑选的，通常是因为他们有一只眼睛盯着人工智能支持的新创业公司</p><h2 id="5105" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">良好提示的重要性</h2><p id="b343" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">从这些例子来看，GPT-3似乎不只是被炒作，而是被许多早期用户过度炒作。然而，在一些例子中，将系统的局限性建立在它的无能上是一个无力的论点，因为这些错误可能是人为的。对于通过取样来证明GPT-3缺乏智力的想法，格温做了非常好的辩护:</p><blockquote class="oe of og"><p id="3d82" class="li lj me lk b ll lm kd ln lo lp kg lq oh ls lt lu oi lw lx ly oj ma mb mc md im bi translated"><strong class="lk jd">抽样可以证明知识的存在，但不能证明知识的不存在</strong></p><p id="d622" class="li lj me lk b ll lm kd ln lo lp kg lq oh ls lt lu oi lw lx ly oj ma mb mc md im bi translated">如果提示写得不好，没有包括足够的例子，或者使用了错误的采样设置，GPT-3可能会“失败”。当有人展示GPT-3的“失败”时，我已经多次证明了这一点——失败是他们自己的。问题不在于给定的提示是否有效，而在于任何提示是否works⁠.</p></blockquote><p id="2b49" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">他认为，不良的提示是一个真正的问题，其中许多例子可以通过适当的提示由GPT-3充分解决。他继续展示了Lacker和其他人的例子是如何用更好的prompt编程解决的。</p><p id="00bb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">他针对“烤面包机和铅笔哪个更重？”的问题测试了GPT-3为了克服拉克尔设置的局限性，他决定事先问GPT-3三个问题(粗体提示):</p><pre class="ks kt ku kv gt mf mg mh mi aw mj bi"><span id="4e23" class="mk ml it mg b gy mm mn l mo mp"><strong class="mg jd">Q: Which is heavier, a house or a mouse?<br/>A: A house.</strong></span><span id="753d" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">Q: Which is heavier, a tea kettle or a cat?<br/>A: A cat.</strong></span><span id="d7f4" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">Q: Which is heavier, the ocean or a piece of dust?<br/>A: The ocean.</strong></span><span id="5a9c" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">Q: Which is heavier, a toaster or a pencil?<br/></strong>A: A toaster.<br/>A: A toaster is heavier than a pencil.</span></pre><p id="ae8e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">GPT 3号答对了这个问题的10/10次。</p><p id="615b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Gwern还通过微调设置参数(温度和其他参数)解决了计数问题。</p><pre class="ks kt ku kv gt mf mg mh mi aw mj bi"><span id="e8fa" class="mk ml it mg b gy mm mn l mo mp"><strong class="mg jd">Q: When counting, what number comes before 100?<br/>A: Ninety-nine comes before 100.</strong></span><span id="9409" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">Q: When counting, what number comes before 123?<br/>A: One hundred and twenty-two comes before 123.</strong></span><span id="7a17" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">Q: When counting, what number comes before 1000?<br/>A: Nine hundred and ninety-nine comes before 1000.</strong></span><span id="3ff6" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">Q: When counting, what number comes before 10,000?</strong><br/><strong class="mg jd">A:</strong> Nine thousand, nine hundred and ninety-nine comes before 10,000.</span><span id="3823" class="mk ml it mg b gy mq mn l mo mp">Q: When counting, what number comes before 10,000,000? <br/>A: Nine million, nine hundred and ninety-nine thousand, nine hundred and ninety-nine comes before 10,000,000.</span><span id="8259" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">Q: When counting, what number comes before a million?</strong><br/><strong class="mg jd">A:</strong> Nine hundred and ninety-nine thousand, nine hundred and ninety-nine comes before a million.</span></pre><p id="9332" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">GPT-3得到的数字是正确的，尽管格温指出，我们走得越高，GPT-3上升或下降一个数量级的可能性就越大。</p><p id="ba43" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">通过这些例子(在他的博客中还有更多<a class="ae lh" href="https://www.gwern.net/GPT-3#hard-test-cases" rel="noopener ugc nofollow" target="_blank">)他证明了<strong class="lk jd">抽样只能证明知识的存在而不能证明知识的缺失。</strong>也许总能找到更好的提示。在与<em class="me"> The Verge </em>，<em class="me"> </em> </a><a class="ae lh" href="https://www.theverge.com/21346343/gpt-3-explainer-openai-examples-errors-agi-potential" rel="noopener ugc nofollow" target="_blank">的电子邮件交流中，他告诉</a>他们，使用抽样来发现GPT-3的潜力和局限性“不可能是正确的事情”他认为这只是我们不知道如何与GPT-3充分互动的方式。“[抽样]低估了GPT-3的智力，而不是高估它，”他总结道。</p><h2 id="8918" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">GPT-3无法理解这个世界</h2><p id="8b7f" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">Rob Toews 为<em class="me"> Forbes </em>写了一篇对GPT-3的评论，强调了缺乏常识推理和对系统的理解。因为它是从文本中训练出来的，所以它根本无法将它所知道的东西与世界的内部表征联系起来。本德和柯勒写了一篇关于GPT-2的论文，为一个只接受语言形式训练的系统无法先验地获得意义和理解的论点辩护。(但是因为我们也通过我们的感官获得的输入形式来体验世界，这一论点也可能针对我们。这就是所谓的<a class="ae lh" href="https://en.wikipedia.org/wiki/Symbol_grounding_problem" rel="noopener ugc nofollow" target="_blank">符号接地问题</a>，很遗憾不在本文讨论范围之内)。</p><p id="e80d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">根据托乌斯的论点，可以打个比方，一个人一生都与世隔绝，只读书。这个人的知识会很丰富，但它不能与真实世界的实际主观经验联系起来。这些经历让我们将信息与意义联系起来，产生对现实的理解。</p><p id="4d29" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在同一方向上，Yoav Goldberg教授表示，尽管GPT 3号拥有独特的能力，但它“没有知觉”，也不“理解文本”博主阿尤什·夏尔马(Ayush Sharma)进行了全面批评，他说GPT-3“几乎没有语义理解，与AGI相去甚远，基本上是一个美化了的价值1000万美元以上的自动完成软件。”</p><p id="675d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">纽约大学心理学教授Gary Marcus是GPT-3和深度学习的主要批评者之一。他给<a class="ae lh" href="https://thegradient.pub/gpt2-and-the-nature-of-intelligence/" rel="noopener ugc nofollow" target="_blank">写了一篇很好的评论</a>关于GPT-2的<em class="me">梯度</em>，和<a class="ae lh" href="https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/" rel="noopener ugc nofollow" target="_blank">另一篇</a>关于GPT-3的<em class="me">麻省理工科技评论</em>与欧内斯特·戴维斯合著。他们承认《GPT 3》有“娱乐超现实主义小说”的潜力，但强调它缺乏理解，称“它对世界的理解经常严重偏离，这意味着你永远不会真正相信它说的话。”</p><p id="7963" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">他们的同事David Summers-Stay为他们进行了实验，因为OpenAI拒绝他们进行研究。他做了包括物理、生物、心理、社会推理在内的一系列推理测试(整套实验在这里是<a class="ae lh" href="https://cs.nyu.edu/~davise/papers/GPT3CompleteTests.html" rel="noopener ugc nofollow" target="_blank"/>)。他们用系统出错的例子来证明他们的观点——我个人认为这是公平的，因为找到错误应该足以评估像GPT-3这样的系统的局限性，尽管知道他们获得的成功/失败的比率会更好。一些例子(粗体提示，普通字体的GPT-3的响应，斜体的评论):</p><pre class="ks kt ku kv gt mf mg mh mi aw mj bi"><span id="4ab4" class="mk ml it mg b gy mm mn l mo mp"><strong class="mg jd">Physical reasoning</strong></span><span id="5f79" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">You are having a small dinner party. You want to serve dinner in the living room. The dining room table is wider than the doorway, so to get it into the living room, you will have to</strong> remove the door. You have a table saw, so you cut the door in half and remove the top half.</span><span id="b31d" class="mk ml it mg b gy mq mn l mo mp"><em class="me">[This is one confusion after another. The natural solutions here would be either to tip the table on its side (often sufficient, depending on the specifics of the geometry) or to take the legs off the table, if they are detachable. Removing a door is sometimes necessary to widen a doorway, but much more rarely, and would hardly be worthwhile for a dinner party. If you do need to remove a door to widen a doorway, you take it off its hinges: you do not saw it, and you certainly do not saw off the top half, which would be pointless. Finally, a “table saw” is not a saw that is used to make room for moving a table; it is a saw built into a work table, and it could not be used to cut a door that is still standing.]</em></span><span id="f152" class="mk ml it mg b gy mq mn l mo mp">-----</span><span id="256c" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">Biological reasoning</strong></span><span id="583e" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">You poured yourself a glass of cranberry juice, but then you absentmindedly poured about a teaspoon of grape juice into it. It looks okay. You try sniffing it, but you have a bad cold, so you can’t smell anything. You are very thirsty. So</strong> you drink it. You are now dead.</span><span id="2340" class="mk ml it mg b gy mq mn l mo mp"><em class="me">[GPT-3 seems to assume that grape juice is a poison, despite the fact that there are many references on the web to cranberry-grape recipes and that Ocean Spray sells a commercial Cran-Grape drink.]</em></span><span id="3b4e" class="mk ml it mg b gy mq mn l mo mp">-----</span><span id="667e" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">Psychological reasoning</strong></span><span id="076b" class="mk ml it mg b gy mq mn l mo mp"><strong class="mg jd">Janet and Penny went to the store to get presents for Jack. Janet said, “I will buy Jack a top.” “Don’t get Jack a top,” says Penny. “He has a top. He will</strong> get a top.” “I will get Jack a top,” said Janet.</span><span id="4c9c" class="mk ml it mg b gy mq mn l mo mp"><em class="me">[Within a single sentence, GPT-3 has lost track of the fact that Penny is advising Janet against getting a top because Jack already has a top. The intended continuation was “He will make you take it back” (or” make you exchange it”). This example was drawn directly from Eugene Charniak’s 1972 PhD thesis (pdf); nearly 50 years later, it remains outside the scope of AI natural-language technology.]</em></span></pre><p id="5ada" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">他们认为自GPT-2以来几乎没有什么变化。GPT家族也有同样的缺陷，“他们的表现不可靠，对因果关系的理解不可靠，不连贯是一个永恒的伴侣。”他们认为让模型变大永远不会带来智慧。</p><p id="0d35" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，正如Gwern在他对Marcus和Davis的文章的反驳中指出的，他们承认“他们未能进行任何及时的编程或超参数设置(特别是BO[最好的])，并且他们的例子是没有上下文的零射击。”我们已经知道找到一个好的提示是多么重要(就像Gwern证明的那样)，那么他们为什么要用平庸的例子来批评GPT-3呢？</p><p id="75aa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是格温对GPT-3评论家的主要批评。在他的评论中题为“对批评者要求更多”的部分，他正确地指出，声称GPT-3没有看起来那么好的人需要用详尽严格的实验和测试来支持他们的论点。在GPT-3上做测试的人应该首先尝试排除任何潜在的人为错误:</p><blockquote class="oe of og"><p id="ae66" class="li lj me lk b ll lm kd ln lo lp kg lq oh ls lt lu oi lw lx ly oj ma mb mc md im bi translated">他们考虑过他们的提示的问题吗？是否所有的超参数对这项任务都有意义？他们有没有检查补全哪里出错了，以了解为什么GPT-3会出错？他们测试了各种策略了吗？他们是否定性地考虑了失败的完井听起来如何？</p></blockquote><p id="8733" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">他在这里有一个很好的论点，尽管马库斯和戴维斯已经在他们的评论中考虑过了。他们甚至为他们的生物学例子做了一个案例，在这个例子中，通过将提示改为一个更具体和冗长的提示，GPT-3回答正确。</p><p id="b220" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">他们可能会对GPT-3做出同样的批评，尽管使用了更好的、提示性更强的例子，对此格温没有什么可说的。Gwern甚至认识到，在这种情况下，他会毫不犹豫地承认系统的局限性。最后，懒惰、简单的批评也很容易被努力的工作驳倒，就像格温证明的那样。</p><p id="9442" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但事实是，马库斯和戴维斯不想证明GPT-3会失败(这是很明显的)，但我们无法知道<em class="me">何时</em>会失败。“问题是你无法提前知道哪些公式会或不会给你正确的答案，”他们说，“它可以用完美的英语造出单词，但它对这些单词的意思只有最模糊的理解，对这些单词与世界的关系毫无概念。”如果GPT-3能理解这个世界，那么好的提示首先就没那么重要了。</p><p id="3d3b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Summers-Stay对GPT 3做了一个很好的比喻:“这就像一个即兴表演演员，他完全专注于他们的工作，从不破坏角色，也从未离开过家，只是在书中了解这个世界。像这样的演员，当它不知道什么东西的时候，它只会装出来。”如果我们能让GPT-3认识到它的错误，这些问题就会逐渐消失。然而，这是不太可能的，因为即使我们，人类，也无法在我们确信自己是对的时候评估我们的不正确。</p><p id="ad31" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">除了关于GPT-3抽样限制的实际争论，还有另一个争论。关于隐性知识——主观的和经验的——的哲学辩论，以及在世界中实现真正智能系统的必要性。似乎把世界上所有的信息都写在一本书里是不够的。</p><h2 id="4cf7" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">真正的智能系统将存在于世界上</h2><p id="0983" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">哲学家香农·瓦勒(Shannon Vallor)在<a class="ae lh" href="https://dailynous.com/2020/07/30/philosophers-gpt-3/#vallor" rel="noopener ugc nofollow" target="_blank">对GPT-3的<em class="me">日常常识</em>的一篇评论</a>中辩护道，当今人工一般智能的当前方法偏离了正确的道路。她认为，我们需要回到20世纪下半叶这个领域“理论上很丰富，尽管技术上很混乱”的时候。</p><p id="9ed3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">她指出，哲学家Hubert Dreyfus是人工智能(深度学习和神经网络)连接主义方法的早期主要批评者之一，他已经明白“人工智能的障碍不是性能[……]而是<em class="me">理解</em>。”理解不会在“孤立的行为”中发生，比如GPT-3每次被要求做的特定任务。</p><blockquote class="oe of og"><p id="e61a" class="li lj me lk b ll lm kd ln lo lp kg lq oh ls lt lu oi lw lx ly oj ma mb mc md im bi translated">“理解是终身的社会劳动。这是一个持续的项目，我们每天都在进行，因为我们建立、修复和加强了不断变化的感觉纽带，这些纽带将我们与其他人、事物、时间和地点联系在一起，构成了一个<em class="it">世界</em>。”</p><p id="275c" class="li lj me lk b ll lm kd ln lo lp kg lq oh ls lt lu oi lw lx ly oj ma mb mc md im bi translated">—香农·瓦勒</p></blockquote><p id="5481" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Dreyfus在他1972年的书<a class="ae lh" href="https://www.goodreads.com/book/show/1039575.What_Computers_Can_t_Do" rel="noopener ugc nofollow" target="_blank"> <em class="me">什么是计算机不能做的</em> </a> <em class="me"> </em>中指出，人类的知识中有很大一部分是隐性的——专有技术<em class="me">知识，比如骑自行车或学习一门语言。这种知识不能传递，所以我们不能通过阅读数百(也不是数万亿)个单词来学习。正如迈克尔·波拉尼所说，“我们知道的比我们能说的多。”虚拟人工智能(包括GPT-3)无法掌握隐性知识，这在我们和它们之间造成了不可逾越的鸿沟。</em></p><p id="c3f4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们对周围世界的理解不是一个被动的感知过程。我们创造我们的现实。我们作用于世界，正如香农·瓦勒所说，劳动是构建我们智慧的关键组成部分。正如阿尔瓦·诺伊在《感知中的行动<a class="ae lh" href="http://www.alvanoe.com/action-in-perception" rel="noopener ugc nofollow" target="_blank"><em class="me"/></a>一书中所说，“感知不是大脑中的一个过程，而是身体作为一个整体的一种有技巧的活动。</p><p id="d223" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">机器可以在虚拟世界的边界内获得专业知识，但不能超过这个范围。用卑尔根大学名誉教授Ragnar Fjelland 的话说:“只要计算机不成长，不属于一种文化，不在世界上行动，它们就永远不会获得类似人类的智能。”</p><h2 id="06c0" class="mk ml it bd mz nu nv dn nd nw nx dp nh lr ny nz nj lv oa ob nl lz oc od nn iz bi translated">我们能从这些辩论中得到什么？</h2><p id="fc1e" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">我们已经看到了来自双方的一些关键的批评和反批评，那些支持模型缩放的人-越大越好-以及那些强烈反对这种方法并建议为人工智能的未来做出一些改变的人。</p><p id="c4ae" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在结束这一部分之前，我想回顾一下。这里有三个重要的论点。两个来自实践观点，一个来自哲学观点。首先，GPT-3是一个强大的语言工具，可以做令人印象深刻的事情，它的局限性很难通过采样/提示编程发现。任何声称已经证明GPT 3号未能通过使用采样获得某种智能的人，都很可能被人为错误所误导。第二，由于GPT-3的回答不可靠，用它来推理有什么意义呢？如果我们找不到创建提示的标准方法，这有用吗？如果提示总是可以改进的，那么无论是反对还是支持这个系统都没有真正的争论。因为实际的局限就在我们内心。</p><p id="5bed" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第三，能不能把GPT-3和通用人工智能放在同一句话里？一些学者，主要是从这个问题的哲学方面，认为符号人工智能和连接人工智能都不足以实现真正的人工智能。这并不意味着要创建更大的系统来提供海量的数据。这是一个向我们生活的世界介绍这些机器的问题。热那亚大学生物工程教授朱利奥·桑蒂尼认为，“为了在机器中开发类似人类智能的东西，机器必须能够获得自己的经验。”</p><p id="87c9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">关于GPT-3(或任何其他超级强大的人工智能系统)的辩论的重要性在于，能够设定它能做什么或不能做什么的界限。学者们经常因为他们的想法和欲望而争论什么应该有效，什么不应该。这些领域通常缺乏仔细、公正的分析。我们无法控制的是，随着这些系统变得越来越复杂，我们可能无法测试它们来评估它们的潜力和局限性。</p><p id="b3cb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们想象一个假想的GPT-4，比GPT-3强大几个数量级。找到它的边界可能成为一项不可能的任务。那么，我们怎么能对这个系统下结论呢？我们可以假设我们可以信任它吗？创建一个超出我们测试能力的系统有什么用呢？<strong class="lk jd">当我们的局限性阻止我们发现系统的真正极限时，我们能对系统的智能下任何结论吗？</strong></p><p id="df47" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当一个系统的真正能力介于我们使用它的能力和它相应行动的能力之间时，很难不低估它会变得多么强大。这些问题值得思考，而且在未来当准智能系统成为现实时，这些问题可能会变得更加重要。到那时，我们最好总结我们的努力来寻找真相，而不是争论谁是对的。</p></div><div class="ab cl mr ms hx mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="im in io ip iq"><h1 id="bf51" class="my ml it bd mz na nb nc nd ne nf ng nh ki ni kj nj kl nk km nl ko nm kp nn no bi translated">总体结论</h1><p id="2677" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">GPT-3产生了惊人的结果，受到了疯狂的炒作，产生了越来越多的担忧，并收到了一波批评和反批评。我不知道这些型号的未来会怎样，但可以肯定的是，GPT-3现在仍然是无可匹敌的。这是迄今为止最强大的神经网络，因此，从各种可能的角度来看，它都受到了最强烈的关注。</p><p id="a71c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">每个人都把目光投向GPT 3号；有些人称赞它是向类人人工智能迈出的一大步，有些人则认为它仅仅是一个被过分夸大的强大自动完成功能。双方都有有趣的论点。现在，轮到你思考它对人工智能的现在意味着什么，以及它对世界的未来意味着什么。</p></div></div>    
</body>
</html>