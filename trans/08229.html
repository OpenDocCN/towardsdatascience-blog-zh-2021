<html>
<head>
<title>Practical Python Pandas Tricks - Part 3: Data Wrangling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实用的Python熊猫把戏-第3部分:数据争论</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-pandas-part-3-data-wrangling-b490f8e47ca2?source=collection_archive---------26-----------------------#2021-07-28">https://towardsdatascience.com/introduction-to-pandas-part-3-data-wrangling-b490f8e47ca2?source=collection_archive---------26-----------------------#2021-07-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d946" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">任何统计分析和机器学习模型都可以和你输入的数据质量一样好</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/05eb1098f87d8bfe6878c32b12be0d55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1441GPj_U2Iz8cla"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@kazuend?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">和</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="ce38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章是熊猫系列<a class="ae ky" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank">的第三部分。请继续关注更多关于这个主题的文章。</a></p><p id="a235" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/introduction-to-pandas-part-1-import-and-create-dataframe-e53326b6e2b1"> <strong class="lb iu">第1部分:导入并创建数据帧</strong> </a></p><p id="8c4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/introduction-to-pandas-part-2-quick-data-exploration-582fc9b0de28"> <strong class="lb iu">第二部分:数据预览和子集化</strong> </a></p><p id="de8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/introduction-to-pandas-part-3-data-wrangling-b490f8e47ca2"> <strong class="lb iu">第三部分:数据角力</strong> </a></p><h1 id="4740" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">介绍</h1><p id="e9e6" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在这篇文章中，我将介绍Pandas清理和转换数据帧的函数。我认为这是任何数据科学项目中最重要的步骤之一。<a class="ae ky" rel="noopener" target="_blank" href="/etl-skills-you-will-need-for-data-science-project-ebc67f7c9277"> <strong class="lb iu">任何统计分析和机器学习模型都可以和你输入其中的数据质量一样好。</strong> </a></p><h1 id="2e35" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">先决条件</h1><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="792a" class="mx lw it mt b gy my mz l na nb"><strong class="mt iu"># Install pandas library</strong><br/>!pip install pandas</span><span id="d77a" class="mx lw it mt b gy nc mz l na nb"><strong class="mt iu"># Import libraries</strong><br/>import pandas as pd<br/>import numpy as np</span></pre><h1 id="5942" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">缺少值</h1><p id="1f4b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">先说和熊猫处理缺失值。我将使用下面的dataframe作为数据源。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="e217" class="mx lw it mt b gy my mz l na nb">data = {'emp_id': [1, 1, 2, 2],<br/>        'emp_name': ['Jane Dow', 'Jane Dow', 'Thomas Daley', 'Thomas Daley'],<br/>        'gender': [np.nan, 'M', 'F', 'F'],<br/>        'year': [2019, 2020, 2019, 2020],<br/>        'compensation': [53000, np.nan, 53000, '$56,000']}</span><span id="515e" class="mx lw it mt b gy nc mz l na nb">df2  = pd.DataFrame(data)<br/>df2</span><span id="5393" class="mx lw it mt b gy nc mz l na nb">Out[107]: <br/>   emp_id      emp_name gender  year compensation<br/>0       1      Jane Dow    NaN  2019        53000<br/>1       1      Jane Dow      M  2020          NaN<br/>2       2  Thomas Daley      F  2019        53000<br/>3       2  Thomas Daley      F  2020      $56,000</span></pre><p id="07d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">is null()&amp;not null():</strong><code class="fe nd ne nf mt b">isnull()</code>允许我们根据指定的列显示缺少值的行，而<code class="fe nd ne nf mt b">notnull()</code>将返回没有缺少值的行。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="38ab" class="mx lw it mt b gy my mz l na nb"><strong class="mt iu">df2[df2['compensation'].isnull()]</strong><br/>Out[108]: <br/>   emp_id  emp_name gender  year compensation<br/>1       1  Jane Dow      M  2020          NaN</span><span id="0a35" class="mx lw it mt b gy nc mz l na nb"><strong class="mt iu">df2[df2['compensation'].notnull()]</strong><br/>Out[109]: <br/>   emp_id      emp_name gender  year compensation<br/>0       1      Jane Dow    NaN  2019        53000<br/>2       2  Thomas Daley      F  2019        53000<br/>3       2  Thomas Daley      F  2020      $56,000</span></pre><p id="e428" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们检查了丢失的数据之后，我们可以删除它们或者用适当的值填充丢失的单元格。(关于缺失数据可以查看我的另一篇文章<a class="ae ky" rel="noopener" target="_blank" href="/etl-skills-you-will-need-for-data-science-project-ebc67f7c9277">】。)</a></p><p id="6f64" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在此数据框架中，我们看到“性别”和“薪酬”列中缺少值。我们可以用每个员工的非缺失性别值来填充缺失的性别，因为性别不会随时间而改变。此外，人力资源部门告诉我们，薪酬缺失意味着该员工已在当年离开公司。我们应该用0代替缺失的补偿。</p><p id="bd7a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nd ne nf mt b">fillna()</code>允许我们用任何值替换丢失的值。在这种情况下，我们用值0替换丢失的补偿。我们可以将<code class="fe nd ne nf mt b">method = 'backfill'</code>和<code class="fe nd ne nf mt b">'ffill'</code>与<code class="fe nd ne nf mt b">groupby()</code>一起使用，用给定员工的上一次或下一次有效观察来填充缺失的性别。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="e694" class="mx lw it mt b gy my mz l na nb"><strong class="mt iu">df2['compensation'].fillna(0, inplace = True)</strong></span><span id="7775" class="mx lw it mt b gy nc mz l na nb">df2['gender'] = df2.groupby('emp_id')['gender'].<strong class="mt iu">fillna(method = 'backfill')</strong></span><span id="b3c6" class="mx lw it mt b gy nc mz l na nb">df2['gender'] = df2.groupby('emp_id')['gender'].<strong class="mt iu">fillna(method = 'ffill')</strong></span><span id="5239" class="mx lw it mt b gy nc mz l na nb">print(df2)<br/>   emp_id      emp_name gender  year compensation<br/>0       1      Jane Dow      <strong class="mt iu">M</strong>  2019        53000<br/>1       1      Jane Dow      M  2020           <strong class="mt iu"> 0</strong><br/>2       2  Thomas Daley      F  2019        53000<br/>3       2  Thomas Daley      F  2020      $56,000</span></pre><h1 id="63ba" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">字符串操作</h1><p id="ffd3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><strong class="lb iu"> str.split(): </strong> <code class="fe nd ne nf mt b">str.split()</code>允许我们将给定列中的文本拆分成多列。在下面的代码中，使用选项<code class="fe nd ne nf mt b">expand = True</code>将“emp_name”列拆分为“first_name”和“last_name”列。默认情况下，列中的文本由空白分割，但是您可以使用选项<code class="fe nd ne nf mt b">pat = '&lt;str&gt;'</code>指定分隔符。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="eff6" class="mx lw it mt b gy my mz l na nb">df2[['first_name', 'last_name']] = df2['emp_name'].str.split(expand = True)<br/>print(df2)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/de2261bc8aa40100f9012cbc09c996ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oftpoTRx3zb08Uf12KuyBQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者创作)</p></figure><p id="8f7e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> str.replace &amp; re():字符串值包含字符，如“$”和“，”。</strong></p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="90f6" class="mx lw it mt b gy my mz l na nb"><strong class="mt iu">df2.apply(lambda x: type(x['compensation']), axis = 1).value_counts()</strong></span><span id="0167" class="mx lw it mt b gy nc mz l na nb">Out[118]: <br/>&lt;class 'int'&gt;    3<br/>&lt;class 'str'&gt;    1<br/>dtype: int64<br/></span><span id="fc8e" class="mx lw it mt b gy nc mz l na nb"><strong class="mt iu">df2[df2.apply(lambda x: type(x['compensation']), axis = 1)== str]</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/1e9222e6fdf3b7be50aabd086f3eb586.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cvn8zN1oF2tgVs3dh85Lnw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者创作)</p></figure><p id="dd59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">很容易使用<code class="fe nd ne nf mt b">str.replace()</code>来删除“$”和“，”。但是当我们这样做时，我们注意到整数值将被替换为<code class="fe nd ne nf mt b">np.nan</code>，因为<code class="fe nd ne nf mt b">str.replace()</code>不能处理整数值。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="4e0b" class="mx lw it mt b gy my mz l na nb"># Incorrect Method <br/><strong class="mt iu">df2['compensation'].str.replace('\$|,', '')</strong></span><span id="3089" class="mx lw it mt b gy nc mz l na nb">Out[124]: <br/>0      NaN<br/>1      NaN<br/>2      NaN<br/>3    56000<br/>Name: compensation, dtype: object</span></pre><p id="7062" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">技巧1: </strong>为了正确地清理混合了字符串和数值的列，我们需要首先使用<code class="fe nd ne nf mt b">astype()</code>将列中的值转换为字符串值，然后根据需要使用<code class="fe nd ne nf mt b">str.replace()</code>或<code class="fe nd ne nf mt b">re.sub()</code>替换相关的字符串值。最后，我们将列转换回数值。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="37ea" class="mx lw it mt b gy my mz l na nb"># Method 1: Using str.replace() with astype()<br/>df2['compensation'].astype(str).str.replace('\$|,', '').astype(int)</span><span id="c6ff" class="mx lw it mt b gy nc mz l na nb"># Method 2: Using apply with re.sub()<br/>df2['compensation'] = df2.apply(lambda x: re.sub('\$|,', '', str(x['compensation'])), axis = 1).astype(int)</span></pre><h1 id="de8f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">窗口功能</h1><p id="90c3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">窗口功能在称为<strong class="lb iu">窗口框架</strong>的一组行上实现。窗口框架是基于一列或多列的同一组中的所有行。当一个窗口函数被实现时，一个新的列将被产生，并且输出将具有与原始数据集相同数量的行<strong class="lb iu">。</strong></p><p id="ec04" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">创建行号为</strong>的新列</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="d072" class="mx lw it mt b gy my mz l na nb">df['new_column_name'] = df.groupby('{column name}').cumcount()+1</span></pre><p id="ca6a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">在组内创建计数/最大值/最小值/平均值/总和</strong></p><p id="244d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在熊猫中，我们经常使用带窗口函数的<strong class="lb iu">变换</strong>，比如，count，max，min，avg，sum。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="479b" class="mx lw it mt b gy my mz l na nb">df.groupby('gender')['salary'].transform('count')<br/>df.groupby('gender')['salary'].transform('max')<br/>df.groupby('gender')['salary'].transform('min')<br/>df.groupby('gender')['salary'].transform('mean')<br/>df.groupby('gender')['salary'].transform('sum')</span></pre><p id="dd30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">在组内创建运行总和</strong></p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="fd28" class="mx lw it mt b gy my mz l na nb">df.groupby('gender')['salary'].transform('cumsum')</span></pre><p id="7493" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">在组内创建百分位数</strong></p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="0b1e" class="mx lw it mt b gy my mz l na nb"># create median <br/>df.groupby('gender')['salary'].transform(lambda x: x.quantile(0.5))</span></pre><p id="3f6e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">在组内创建滞后/领先</strong></p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="d36a" class="mx lw it mt b gy my mz l na nb"># create lag variable<br/>df.groupby('gender')['salary'].transform(lambda x: x.shift(1)) <br/># create lead variable<br/>df.groupby('gender')['salary'].transform(lambda x: x.shift(-1))</span></pre><p id="de52" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">创建组内排名</strong></p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="5e9e" class="mx lw it mt b gy my mz l na nb">df.groupby('gender')['salary'].rank('dense', ascending = False)</span></pre><h1 id="7b14" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">聚合函数</h1><p id="edaf" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">集合函数的实现方式与窗口函数相同。但是结果会更紧凑。最终输出中的观察值数量将等于不同组的数量(即分组变量中的唯一值)。</p><p id="bb5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">折叠一个组中具有计数/最大值/最小值/平均值/总和的行</strong></p><p id="d384" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在Pandas中，有许多方法可以实现聚合函数。我在下面的代码片段中包含了3种不同的方法。</p><ul class=""><li id="6082" class="ni nj it lb b lc ld lf lg li nk lm nl lq nm lu nn no np nq bi translated">使用<strong class="lb iu"> groupby </strong>将聚合函数作为默认函数运行</li><li id="db51" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">使用<strong class="lb iu">应用</strong>运行内置聚合函数或带有<strong class="lb iu"> groupby </strong>的用户自定义函数</li><li id="b7a5" class="ni nj it lb b lc nr lf ns li nt lm nu lq nv lu nn no np nq bi translated">使用<strong class="lb iu"> agg </strong>更灵活地运行内置聚合函数或用户定义函数，例如命名新列和创建多个新列</li></ul><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="aed1" class="mx lw it mt b gy my mz l na nb">df.groupby('gender')['salary'].mean().reset_index()<br/>df.groupby('gender')['salary'].min().reset_index()<br/>df.groupby('gender')['salary'].max().reset_index()<br/>df.groupby('gender')['salary'].sum().reset_index()</span><span id="979d" class="mx lw it mt b gy nc mz l na nb">df.groupby('gender').apply(lambda x: x['salary'].mean()).reset_index()</span><span id="d665" class="mx lw it mt b gy nc mz l na nb">df.groupby('gender').agg(count = pd.NamedAgg('salary', 'mean')).reset_index()</span></pre><p id="512c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">在组内创建百分位数</strong></p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="e5e2" class="mx lw it mt b gy my mz l na nb">df.groupby(‘gender’)[‘salary’].quantile(0.9).reset_index()</span></pre><p id="8acf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在本文中查看更多关于<a class="ae ky" rel="noopener" target="_blank" href="/data-manipulation-sql-vs-pandas-116bb33a9abf"> <strong class="lb iu">窗口函数&amp;聚合函数</strong> </a>的内容。</p><p id="13e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">招数二:应用自定义函数</strong> — <code class="fe nd ne nf mt b">apply</code>函数让我们有更大的灵活性和可控性来创建自定义函数。在下面的例子中，我将使用“supermarket _ sales—sheet 1 . CSV”(<a class="ae ky" href="https://www.kaggle.com/aungpyaeap/supermarket-sales" rel="noopener ugc nofollow" target="_blank">下载链接</a>)作为数据源。我们将根据“评级”列中的值创建一个新的评级类别列。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="6016" class="mx lw it mt b gy my mz l na nb"># Import data source<br/>df = pd.read_csv('supermarket_sales - Sheet1.csv')</span><span id="0cee" class="mx lw it mt b gy nc mz l na nb">def <strong class="mt iu">rating_category</strong>(rating):<br/>    if rating &gt;= 4 and rating &lt;6:<br/>        return 'Low'<br/>    elif rating &gt;= 6 and rating &lt;8:<br/>        return 'Mid'<br/>    else:<br/>        return 'High'</span><span id="f67d" class="mx lw it mt b gy nc mz l na nb">df['rating_cat'] = df.apply(lambda x: <strong class="mt iu">rating_category</strong>(x['Rating']), axis = 1)</span></pre><p id="202b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">招数三:使用tqdm </strong>显示进度条——处理大数据集时，运行<code class="fe nd ne nf mt b">apply</code>函数需要一段时间。如果我们知道工作状态以及我们预计任务完成的时间，那就太好了。Python库<code class="fe nd ne nf mt b">tqdm</code>与熊猫无缝协作。你只需要把<code class="fe nd ne nf mt b">apply</code>换成<code class="fe nd ne nf mt b">progress_apply</code>，其他都不变。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="0e5a" class="mx lw it mt b gy my mz l na nb">from tqdm import tqdm<br/>tqdm.pandas()<br/>df.progress_apply(lambda x: rating_category(x['Rating']), axis = 1)</span><span id="694e" class="mx lw it mt b gy nc mz l na nb"><strong class="mt iu">100%|██████████| 1000/1000 [00:00&lt;00:00, 104413.84it/s]</strong></span></pre><p id="e643" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">技巧4:使用Swifter加速</strong> —能够充分利用硬件能力来加速运行时间对于数据科学任务来说非常重要。如果决策者希望在短时间内看到结果，您的分析可能对他们没有帮助，但是您的程序需要几周或几个月才能运行。</p><p id="9784" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Python库<code class="fe nd ne nf mt b"><a class="ae ky" href="https://medium.com/@jmcarpenter2/swiftapply-automatically-efficient-pandas-apply-operations-50e1058909f9" rel="noopener">swifter</a></code>可以有效地利用硬件能力，以最快的方式将任何函数应用于Pandas数据帧或系列对象。语法很简单，你只需要在<code class="fe nd ne nf mt b">apply</code>函数前加上<code class="fe nd ne nf mt b">swifter</code>。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="1b9a" class="mx lw it mt b gy my mz l na nb">import swifter<br/>df.swifter.apply(lambda x: rating_category(x['Rating']), axis = 1)</span></pre><h1 id="605d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">连接多个数据框架</h1><h2 id="a7c5" class="mx lw it bd lx nw nx dn mb ny nz dp mf li oa ob mh lm oc od mj lq oe of ml og bi translated">组合行</h2><p id="e308" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><strong class="lb iu"> append() &amp; concat(): </strong>我们可以使用<code class="fe nd ne nf mt b">append()</code>或<code class="fe nd ne nf mt b">concat()</code>按行方式组合两个数据帧，并产生相同的输出。我们可以使用<code class="fe nd ne nf mt b">reset_index(drop=True)</code>来重置组合数据帧中的索引。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="4b76" class="mx lw it mt b gy my mz l na nb">df3 = pd.DataFrame({'emp_id': 3, 'emp_name': 'Jason Zandi', 'gender': 'M', 'year': 2020, 'compensation': 60000}, index = [0])</span><span id="8c9a" class="mx lw it mt b gy nc mz l na nb"><strong class="mt iu">df2.append(df3).reset_index(drop=True)<br/>pd.concat([df2, df3]).reset_index(drop=True)</strong></span><span id="28a5" class="mx lw it mt b gy nc mz l na nb">Out[182]: <br/>   emp_id      emp_name gender  year compensation<br/>0       1      Jane Dow    NaN  2019        53000<br/>1       1      Jane Dow      M  2020          NaN<br/>2       2  Thomas Daley      F  2019        53000<br/>3       2  Thomas Daley      F  2020      $56,000<br/>4       3   Jason Zandi      M  2020        60000</span></pre><h2 id="a6be" class="mx lw it bd lx nw nx dn mb ny nz dp mf li oa ob mh lm oc od mj lq oe of ml og bi translated">合并列</h2><p id="d0e5" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><strong class="lb iu">join()&amp;merge():</strong><code class="fe nd ne nf mt b">join()</code>或<code class="fe nd ne nf mt b">merge()</code>都可以按列的方式组合两个数据帧。<strong class="lb iu">区别在于</strong> <code class="fe nd ne nf mt b"><strong class="lb iu">join()</strong></code> <strong class="lb iu">是基于索引，而</strong> <code class="fe nd ne nf mt b"><strong class="lb iu">merge()</strong></code> <strong class="lb iu">是基于两个数据帧的公共列。</strong>在下面的示例中，当使用基于索引的join()组合df2和df4时，我们有一个匹配索引为[0]的行。当基于列“emp_id”使用merge()组合df2和d5时，我们实现了一个典型的左连接操作。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="18d4" class="mx lw it mt b gy my mz l na nb">df4 = pd.DataFrame({'test': 300}, index = [0]) <br/>df4<br/>Out[190]: <br/>   test<br/>0   300</span><span id="5843" class="mx lw it mt b gy nc mz l na nb">df5 = pd.DataFrame({'emp_id': [1, 2], 'title': ['Engineer', 'Analyst']})<br/>df5<br/>Out[192]: <br/>   emp_id     title<br/>0       1  Engineer<br/>1       2   Analyst<br/></span><span id="00ae" class="mx lw it mt b gy nc mz l na nb"><strong class="mt iu">df2.join(df4)</strong><br/>Out[188]: <br/>   emp_id      emp_name gender  year compensation   test<br/>0       1      Jane Dow    NaN  2019        53000  300.0<br/>1       1      Jane Dow      M  2020          NaN    NaN<br/>2       2  Thomas Daley      F  2019        53000    NaN<br/>3       2  Thomas Daley      F  2020      $56,000    NaN</span><span id="d906" class="mx lw it mt b gy nc mz l na nb"><strong class="mt iu">df2.merge(df5, on = 'emp_id', how = 'right')</strong><br/>Out[189]: <br/>   emp_id      emp_name gender  year compensation     title<br/>0       1      Jane Dow    NaN  2019        53000  Engineer<br/>1       1      Jane Dow      M  2020          NaN  Engineer<br/>2       2  Thomas Daley      F  2019        53000   Analyst<br/>3       2  Thomas Daley      F  2020      $56,000   Analyst</span></pre><h1 id="8c79" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">重新格式化数据帧</h1><h2 id="1017" class="mx lw it bd lx nw nx dn mb ny nz dp mf li oa ob mh lm oc od mj lq oe of ml og bi translated">将数据帧从长转换为宽</h2><p id="823b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><code class="fe nd ne nf mt b">pivot()</code>和<code class="fe nd ne nf mt b">pivot_table()</code>都会生成一个(宽)表，汇总来自一个更大(长)表的数据。不同的是<code class="fe nd ne nf mt b">pivot_table()</code>还可以合并聚合函数，比如sum、average、max、min和first。在下面的示例中，我们尝试基于“year”列创建单独的薪酬列“2019”和“2020”。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="a79f" class="mx lw it mt b gy my mz l na nb">df2<br/>Out[200]: <br/>   emp_id      emp_name gender  year compensation<br/>0       1      Jane Dow      M  2019        53000<br/>1       1      Jane Dow      M  2020            0<br/>2       2  Thomas Daley      F  2019        53000<br/>3       2  Thomas Daley      F  2020      $56,000</span><span id="bfe6" class="mx lw it mt b gy nc mz l na nb"><strong class="mt iu">df_wide = df2.pivot(index = ['emp_id', 'emp_name', 'gender'], columns = ['year'], values = 'compensation').reset_index()</strong><br/>print(df_wide)<br/>year  emp_id      emp_name gender   2019     2020<br/>0          1      Jane Dow      M  53000        0<br/>1          2  Thomas Daley      F  53000  $56,000</span><span id="3ba6" class="mx lw it mt b gy nc mz l na nb"><strong class="mt iu">df_wide2 = df2.pivot_table(index = ['emp_id', 'emp_name', 'gender'], columns = ['year'], values = 'compensation', aggfunc = 'first').reset_index()</strong><br/>print(df_wide2)<br/>year  emp_id      emp_name gender   2019     2020<br/>0          1      Jane Dow      M  53000        0<br/>1          2  Thomas Daley      F  53000  $56,000</span></pre><h2 id="2ea7" class="mx lw it bd lx nw nx dn mb ny nz dp mf li oa ob mh lm oc od mj lq oe of ml og bi translated">将数据帧从宽转换为长</h2><p id="4127" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><code class="fe nd ne nf mt b">melt()</code>允许我们将数据帧格式从宽改为长。这与创建数据透视表相反。在下面的示例中，我们希望将薪酬列“2019”和“2020”合并为一列，并创建一个新的“年份”列。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="b190" class="mx lw it mt b gy my mz l na nb"><strong class="mt iu">df_long = df_wide.melt(id_vars= ['emp_id', 'emp_name', 'gender'], var_name= 'year', value_vars= [2019, 2020], value_name="Compensation")</strong><br/>print(df_long)<br/>   emp_id      emp_name gender  year Compensation<br/>0       1      Jane Dow      M  2019        53000<br/>1       2  Thomas Daley      F  2019        53000<br/>2       1      Jane Dow      M  2020            0<br/>3       2  Thomas Daley      F  2020      $56,000</span></pre><h1 id="8b62" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">感谢您的阅读！！！</h1><p id="bde0" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">如果你喜欢这篇文章，并且想<strong class="lb iu">请我喝杯咖啡，请<a class="ae ky" href="https://ko-fi.com/aaronzhu" rel="noopener ugc nofollow" target="_blank">点击这里</a>。</strong></p><p id="77e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以注册一个<a class="ae ky" href="https://aaron-zhu.medium.com/membership" rel="noopener"> <strong class="lb iu">会员</strong> </a>来解锁我的文章的全部访问权限，并且可以无限制地访问介质上的所有内容。如果你想在我发表新文章时收到电子邮件通知，请<a class="ae ky" href="https://aaron-zhu.medium.com/subscribe" rel="noopener"> <strong class="lb iu">订阅</strong> </a>。</p></div></div>    
</body>
</html>