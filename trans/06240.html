<html>
<head>
<title>What Bias-Variance Bulls-Eye Diagram Really Represents</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">偏差-方差靶心图真正代表了什么</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-bias-variance-bulls-eye-diagram-really-represent-ff6fb9670993?source=collection_archive---------18-----------------------#2021-06-04">https://towardsdatascience.com/what-bias-variance-bulls-eye-diagram-really-represent-ff6fb9670993?source=collection_archive---------18-----------------------#2021-06-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="9476" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="84d3" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">它与欠拟合和过拟合有什么关系</h2></div><p id="796b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在寻找偏差-方差权衡时，我们可以看到下面的<strong class="kt jd">靶心图</strong>:</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ln"><img src="../Images/8409ede89c558e27e72e5abdc82d039b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WjgaFV1WGPbw3-fR-2CB0A.png"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">偏差-方差的靶心图—图片由作者提供</p></figure><p id="3732" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">它们看起来直观醒目，用一些蓝点来表示偏差和方差。但是它们到底是什么意思呢？中心点代表目标，但蓝点真正代表什么？这些牛眼是如何与欠适和过适联系在一起的？</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi md"><img src="../Images/b6a1d0a62b829bd267dfb470fc3f622d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qorp3RRTtLAPmWiU"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">照片由<a class="ae me" href="https://unsplash.com/@little_klein?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">维托达·克莱恩</a>在<a class="ae me" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="b49b" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">与过度拟合和欠拟合的关系</h1><p id="5bb3" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">偏差-方差权衡与<strong class="kt jd">过拟合</strong>和<strong class="kt jd">欠拟合</strong>的概念有关。为了说明这一点，我们可以举多项式回归的例子。在下面的例子中，x和y之间的真实关系是二次的</p><ul class=""><li id="9bcb" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm nh ni nj nk bi translated">所以如果我们使用简单的线性回归，模型是<strong class="kt jd">欠拟合</strong>；</li><li id="5d10" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">如果多项式的次数太高(例如8)，那么模型<strong class="kt jd">过拟合</strong>。</li><li id="0416" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated"><strong class="kt jd">最优</strong>模型为二次模型。</li></ul><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi nq"><img src="../Images/c980433730bf840b061ab3851d4949f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oyZFcmlLNygV7KldHcWLBg.png"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">多项式回归、欠拟合和过拟合—作者图片</p></figure><p id="f91b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在，如果我们回到靶心图，关系如下所示:</p><ul class=""><li id="dad6" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm nh ni nj nk bi translated"><strong class="kt jd">最优</strong>模型对应低方差和低偏差。(好吧，可以理解)</li><li id="ad24" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated"><strong class="kt jd">过拟合</strong>对应高方差低偏差。(但是为什么呢？如前图所示，它与8次多项式回归有什么关系？)</li><li id="6668" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated"><strong class="kt jd">欠拟合</strong>对应高偏差和低方差。(但是为什么呢？它与上图中的简单回归有什么关系？)</li><li id="7d18" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">那么高方差和高偏差呢？什么模式会导致这种情况？</li></ul><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi nr"><img src="../Images/beba5a9ab8cc4391bb04df14a04eaa9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2HV_rbv0XEgmOveyMw3X8g.png"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">偏差-方差与过度拟合和欠拟合-作者图片</p></figure><p id="a6fb" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果我们将它们放在一起，我们如何将靶心中的点与回归图中的数据点联系起来？</p><div class="lo lp lq lr gt ab cb"><figure class="ns ls nt nu nv nw nx paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><img src="../Images/adb23adbed6f9baee9a6e1dd2a85cca0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Ml3hpJxboH_yMdqs5_qqYw.png"/></div></figure><figure class="ns ls nt nu nv nw nx paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><img src="../Images/7daba0665ee1849fd55ab01a2ff32654.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Uzm4s26COsRevqFJrLKZTQ.png"/></div></figure></div><h1 id="b2d0" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">更准确的表述</h1><p id="2b9b" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">乍一看，靶心图还是挺直观和醒目的。但如果我们真的试着问自己这个问题:每个预测点都有两个坐标？<strong class="kt jd">两个维度是什么？</strong></p><p id="cc6b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">然后我们意识到眼睛只是目标变量值的艺术表现。因为我们通常<strong class="kt jd">只有一个目标变量</strong>。所以要想更准确，应该只展示一个维度。</p><p id="0e22" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">中间的红点是我们试图预测的真实值(一个特定的观察值)。蓝点是我们建立的不同模型的预测。</p><p id="a2e3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">因此，如果我们想更准确地描述目标值和预测值之间的比较，靶心将变成只有一个轴，它代表目标变量。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ny"><img src="../Images/e14316a90fbf57238489ac48972c0b52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4E1J7a71ttQ6feTO921OMg.png"/></div></div></figure><p id="5a95" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">那么，它们到底代表了什么，我们怎样才能创造出一个具体的模型例子呢？我们编码吧。</p><h1 id="254e" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">多项式回归模型</h1><p id="5ee5" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">我们将在以下过程中创建多个模型来说明(欠拟合和过拟合)与(偏差-方差权衡)之间的关系:</p><ul class=""><li id="2223" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm nh ni nj nk bi translated">首先，我们选择从一个已知的函数生成一些简单的数据。</li><li id="b0ba" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">然后我们可以试着创造模型</li><li id="012f" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">对于一个或多个新的观察值，我们可以进行预测，并查看方差和偏差。</li></ul><h2 id="b39c" class="nz mg it bd mh oa ob dn ml oc od dp mp la oe of mr le og oh mt li oi oj mv iz bi translated">生成数据</h2><p id="5338" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">我们可以生成一些真正的二次关系的数据。</p><pre class="lo lp lq lr gt ok ol om on aw oo bi"><span id="f2bc" class="nz mg it ol b gy op oq l or os">import numpy as np<br/>import pandas as pd</span><span id="8c04" class="nz mg it ol b gy ot oq l or os">n = 20<br/>x = np.linspace(0,7,n) + np.random.randn(n)*0.1</span><span id="2df7" class="nz mg it ol b gy ot oq l or os">def f(x):<br/>    return (x-3)**2</span><span id="8043" class="nz mg it ol b gy ot oq l or os">y = f(x)+np.random.randn(n)</span></pre><p id="1791" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们可以用红色的实函数来绘制数据。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ou"><img src="../Images/fa221f142217d43644c0e48c3fc9f88b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0qY8M7_Hy625MQPENK2EDA.png"/></div></div></figure><h2 id="5a12" class="nz mg it bd mh oa ob dn ml oc od dp mp la oe of mr le og oh mt li oi oj mv iz bi translated">不适合的模型</h2><p id="5bf0" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">为了用以前的数据创建欠拟合模型，我们可以创建简单的线性回归。利用从原始数据集中选择的一些训练数据，我们可以创建一些模型。</p><pre class="lo lp lq lr gt ok ol om on aw oo bi"><span id="f608" class="nz mg it ol b gy op oq l or os">for i in range(20):<br/>    model = make_pipeline(PolynomialFeatures(1), LinearRegression())<br/>    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)<br/>    model.fit(X_train, y_train)<br/>    y_plot = model.predict(X_seq)<br/>    plt.plot(X_seq, y_plot,c=”c”)<br/>    plt.scatter(4, model.predict([[4]]),s=300,c=”c”)</span></pre><p id="c5bc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果我们对4的值进行预测，我们可以得到下面的图:</p><ul class=""><li id="09c8" class="nc nd it kt b ku kv kx ky la ne le nf li ng lm nh ni nj nk bi translated">红点是真正的目标值</li><li id="6293" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">蓝点是由训练数据样本创建的模型(简单线性回归)的预测。</li></ul><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ov"><img src="../Images/f286758fe019f3724595d9d507231b88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2W4NAyAxZu3U7auG_g0l0w.png"/></div></div></figure><p id="4fb7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在，我们可以清楚地看到偏见。我们可以预测几个值</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ov"><img src="../Images/0bfe630cbae94ed8b3c285f8322631ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ahkmXRsxZgeHYx3DTSpKag.png"/></div></div></figure><p id="4bc0" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在，让我们回顾一下不同的插图:</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ow"><img src="../Images/5f339f5112ee2847e20bfbabff15d184.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v7TL7GSV4DZROOYYVYDVlA.png"/></div></div></figure><h2 id="449e" class="nz mg it bd mh oa ob dn ml oc od dp mp la oe of mr le og oh mt li oi oj mv iz bi translated">过度拟合的模型</h2><p id="f8dc" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">对于过拟合，我们可以通过改变多项式的次数来创建相同的比较。</p><pre class="lo lp lq lr gt ok ol om on aw oo bi"><span id="ef5e" class="nz mg it ol b gy op oq l or os">for i in range(20):<br/>    model = make_pipeline(PolynomialFeatures(8), LinearRegression())<br/>    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)<br/>    model.fit(X_train, y_train)<br/>    y_plot = model.predict(X_seq)<br/>    plt.plot(X_seq, y_plot,c=”c”)<br/>    plt.scatter(4, model.predict([[4]]),s=300,c=”c”)</span></pre><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ox"><img src="../Images/89ba1df2d70387a1a9ec56f2e231181c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G0VbnC6ZyhuxjhmJPS-QUw.png"/></div></div></figure><h2 id="fdfd" class="nz mg it bd mh oa ob dn ml oc od dp mp la oe of mr le og oh mt li oi oj mv iz bi translated">最优模型</h2><p id="776d" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">当多项式的次数为2时，我们可以清楚地看到模型的预测具有低偏差和低方差。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi oy"><img src="../Images/f22f06ae2917509bb3b611f6b47cc859.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*05AIHizMRpw8qoBzThnLIw.png"/></div></div></figure><h1 id="9f19" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">回归树模型</h1><p id="9ebf" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">我们也可以用回归树来说明</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi oz"><img src="../Images/4ab067a4fd21cf26ce1b3c281264c268.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wb0_EOeBxgATVxz3aLi_nw.png"/></div></div></figure><h1 id="2d84" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">结论</h1><p id="02b0" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">我希望现在你能更准确地看到偏差-方差靶心。</p><p id="fab7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果是这样，最后一件事:什么样的模型可能具有高方差和高偏差？</p></div></div>    
</body>
</html>