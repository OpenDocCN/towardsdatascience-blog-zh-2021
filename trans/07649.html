<html>
<head>
<title>The Top Five Machine Learning Methods to Forecast Demand for New Products</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测新产品需求的五大机器学习方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-top-five-machine-learning-methods-to-forecast-demand-for-new-products-b881ac7e3f32?source=collection_archive---------13-----------------------#2021-07-13">https://towardsdatascience.com/the-top-five-machine-learning-methods-to-forecast-demand-for-new-products-b881ac7e3f32?source=collection_archive---------13-----------------------#2021-07-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f91b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为什么XGBoost在最近的研究中表现如此出色</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8f2a780145376fe8e4a1fd1849d5b152.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*S7dGAuAtH8afQUEm"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@priscilladupreez?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">普里西拉·杜·普里兹</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="fc7a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated">预测未来的时尚需求既有价值又复杂。它是有价值的，因为对于零售商来说，准备或不准备销售下一个高需求商品的机会成本。此外，如果他们错误地预测了需求，他们必须为商品付款，并可能以某种形式支付未售出的商品。</p><p id="8b27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于多维性(例如，颜色、切割、材料、图案、印花、年龄范围、尺码范围、风格以及文化、地理和社会经济差异)，它很复杂(Paton，2018)。传统上，对物品的需求最常试图使用同一物品的历史销售的时间序列统计来预测；然而，这种方法未能预测需求的高阶变化，以预测未来的趋势或流行商品(Singh，2019)。</p><p id="5aeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，能够最大限度地减少识别新产品需求(例如，时尚趋势)和将其用于销售之间的等待时间(时间延迟)具有巨大的价值。例如，2019年年中，对印度电子商务零售商Myntra的26，762件时尚商品的数据集进行了七种流行的机器学习预测算法的比较研究，发现XGBoost在预测新时尚趋势的需求方面一直表现最佳或接近最佳。它比较了随机森林(RF)、梯度增强回归树(GBRT)、光梯度机(LGBM)、CatBoost (CB)、XGBoost (XGB)、属性嵌入+多层感知器<br/> (MLP)、属性嵌入+长短期记忆(LSTM)。</p><p id="029d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下表列出了每种方法相对于功能丧失的衡量标准(Singh，2019)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi me"><img src="../Images/05a12ee3337f97fb1ea0f588ab0e1884.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C282_l3Ot34_hskkCJMxaw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1:使用标准/损失函数预测需求的比较算法表(Singh，2019年)</p></figure><p id="2bbd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">研究中使用的衡量销售因素有:折扣、知名度和促销。研究中使用的衍生销售因素是款式的年代、季节性和趋势以及同类产品。在这里，折扣被衡量为一个品牌的平均折扣与零售平台整体平均折扣的偏差。可见性是通过相对于品牌的平均浏览量和整个平台的浏览量来衡量的。促销是按计划促销之前或之后的天数来衡量的。由此计算衍生特征。对于一种款式的年龄，它是通过计算该款式可供销售的天数得出的。对于季节性和趋势性，它是通过开始日期和当前日期之间的周数来计算的。对于季节性，一年中一周的傅立叶变换的前三项被用作特征。对于同类产品，计算了某个品牌与其他品牌相比，在给定的一周内可获得的相似风格产品的数量，以及相同价格范围内的相似风格(Singh，2019)。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="5bc2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">获胜者总结:极限梯度提升(XGBoost) </strong></p><p id="5470" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">极端梯度提升(XGBoost)被亚马逊自己的基于云的机器学习平台SageMaker的开发者描述为“梯度提升树算法的一种流行而有效的开源实现……一种监督学习算法，试图通过组合一组更简单、更弱的模型的估计来准确预测目标变量”(亚马逊SageMaker，2019)(陈，XGBoost:可扩展的树提升系统，2016)。XGBoost是分布式机器学习社区(DMLC)工具集中的一个工具，它也传播MXNet深度学习库。DMLC将XGBoost描述为“一个开源软件库，它为C++、Java、Python、R、…Julia提供了一个梯度增强框架”，而JVM“提供了一个并行树增强”2014年3月首次发布；最新版本是2019年5月的. 90(XGBoost，2019)。与任何其他机器学习算法相比，XGBoost赢得或几乎赢得了更多专注于结构化或表格化数据集的分类和回归预测数据科学竞赛(Brownlee，2016)。</p><p id="1379" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Boosting是一种机器学习集成技术，其中新的机器学习模型被顺序地添加，以尝试并校正先前模型中的错误，直到不可能进一步改进为止(例如，通过对难以预测的数据点进行加权)。梯度推进得名于梯度下降算法，该算法用于在添加这些<br/>替代模型时最小化损失(布朗利，2016)。</p><p id="13aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">XGBoost经常与梯度增强(GB)、随机梯度下降和梯度增强树(GBT)混淆(Tseng，2018)。此外，因为GB和GBT可以说是XGBoost的先决条件，而随机梯度下降可以说是一种替代方案，所以区分它们也是解释XGBoost应用的一种很好的方式。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="429a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">批量梯度下降(BGD) </strong></p><p id="dfbd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">梯度下降是一种数学优化技术，可以用于许多机器学习算法。在最高层，它被用来确定一个函数的参数值或系数，该函数将最小化一个成本，通常是预测的误差。在传统数学中，这些系数的值是用线性代数解析计算的。当这些系数的值未知时，梯度下降算法最大化搜索它们的效率，以使机器学习算法最优化。或者，让它在预测事物时更准确，因为它找到了使误差最小化的系数(权重、参数)组合(Brownlee，Gradient descent for machine learning，2016)。</p><p id="f7b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">批量或基本梯度增强的目标是找到函数(例如，直线、曲线等。)最符合数据。例如，如果有人试图使用线性回归根据房子的平方英尺或平方米来预测房子的价格，则流程图算法将如下所示。应用于预测未来时尚，回归方法将是最合适的，因为要预测的变量是连续的(Ng，2018)。如果回归问题使用逻辑回归而不是线性回归，函数中参数的术语将变为权重。</p><p id="af2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">梯度下降或批量梯度下降的一般数学程序从随机选取一个系数开始。数字与实际数字的差异称为“成本”或“误差”通过将系数插入梯度下降公式或函数来计算该系数的成本:成本=(系数)，这变成:<br/>成本=评估((系数))。</p><p id="0aff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来计算成本的导数，这是一个微积分概念，表示一条线在任意给定点的斜率，这将表示我们需要为下一个系数猜测去优化结果的方向；成本的导数通常用希腊字母Delta(δ)的大写表示:Delta =导数(成本)。一阶导数可以用两种方式表示:y '(牛顿符号)或(y)(莱布尼茨符号)。所以，这也可以用符号写成δ= y '(成本)。一旦斜率已知，它就指示了下一个系数估计-猜测应该进行的方向。</p><p id="714c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">系数在每次迭代更新中可以改变的量被定义为alpha (α)，并与成本或误差成比例。89因此，算法“学习”的最终计算结果是:新系数=旧系数—(δx Alpha)或(δ*α)(brown lee，Gradient descent for machine learning，2016)。这种“更新”规则也被称为最小均方(LMS)更新规则或Widrow-Hoff学习规则(ng，2018)。</p><p id="e804" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些迭代继续进行，直到成本或误差为零，或接近零，这意味着预测的最佳系数和实际的最佳系数之间的差异最小化，并且猜测和正确答案收敛(ng，2018)。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="95dc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">随机梯度下降(SGD) </strong></p><p id="b7f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">进化梯度下降和发明新东西的必要性主要与速度有关。因为梯度下降需要对整个训练数据集运行和重复这一迭代过程，所以对于大数据来说，它的计算量非常大，并且计算速度很慢。因此，一种叫做随机梯度下降的进化开始被使用<br/>(布朗利，机器学习的梯度下降，2016)。</p><p id="6561" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随机梯度下降(SGD)是批量梯度下降的变体和替代方案。在随机排序之后，SGD将这些迭代校正估计分解到每个数据点，而不是每次在采取任何调整步骤之前都必须遍历整个训练数据集。用机器学习偶像吴恩达的话来说，SGD“重复地运行训练集，每次[它]遇到训练样本时，[它]都根据仅与单个训练样本相关的误差[成本]的梯度来更新参数”(ng，2018)。结果的确定要快得多，并且很少需要超过1-10次通过整个数据集来优化成本函数(Brownlee，<br/>Gradient descent for machine learning，2016)。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="cb03" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">梯度升压(GB) </strong></p><p id="69bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">采用随机梯度下降(SGD)的一个关键假设是模型结构是固定的。因此，目标是优化系数(分类或线性或多元回归问题中的参数或逻辑回归中的权重)。那么，如果架构模型不固定呢？因此，梯度推进的发明(Tseng，2018)。</p><p id="5c88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">梯度引导是一种基于加法建模的集成机器学习方法。这种想法是通过将一堆模型加在一起并平均它们来形成一个更准确的模型(Mahto，2019)。梯度增强的目标是找到最佳参数和函数(函数不是像batch和SGD中那样预先确定的)。确定最佳参数和函数的目标以指数方式增加了分析和搜索可能组合的复杂性和数量，并试图了解哪些是最佳的。为了提高效率，梯度增强通过采用许多简单的试验函数并组合它们来实现这一点(Tseng，2018)。然而，与boosting不同的是，将被组合的简单基础模型是顺序训练的，一个接一个，而不是并行或同时训练的(Mahto，2019)。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="fec9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">极端梯度推进(XGBoost) </strong></p><p id="e48c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">XGBoost在机器学习领域已经有点传奇色彩了。其成就包括:(1)2015年在机器学习竞赛网站Kaggle上的29场挑战中，有17场以XGBoost获胜，8场专门使用XGBoost，9场使用XGBoost与神经网络进行集成；(2)在2016年杯，一个领先的基于会议的机器学习比赛中，所有前10名的位置都使用了XGBoost(陈，XGBoost:一个可扩展的树提升系统，2016)。</p><p id="cf06" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简单来说，XGBoost是一种超级优化的梯度下降和提升算法，它异常快速和准确。这种“超级优化”是通过组合批量梯度下降函数(如上所述)和模型复杂性的惩罚(也称为回归树函数)来实现的；然而，它通常只适用于一种类型的机器学习模型——<br/>决策树(更正式的名称是分类和回归树或购物车)(亚马逊SageMaker，2019)。</p><p id="3e13" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">XGBoost的竞争优势很大程度上是因为它能够快速调查许多超参数并识别最佳参数，然后可以手动设置这些参数，以便模型自动识别正确的参数。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="a351" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我的下一篇文章中，我将讨论XGBoost的超参数调优和优化方法。与此同时，如果你在应用机器学习方面的目标是预测新产品的需求，从XGBoost算法开始是一种被证明可以快速获得好结果的方法，而无需大量的算法选择试验和错误。</p></div></div>    
</body>
</html>