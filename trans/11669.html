<html>
<head>
<title>Understanding Apache Hive LLAP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解阿帕奇蜂房LLAP</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-apache-hive-llap-fa6d93f73032?source=collection_archive---------26-----------------------#2021-11-18">https://towardsdatascience.com/understanding-apache-hive-llap-fa6d93f73032?source=collection_archive---------26-----------------------#2021-11-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/2407f6c7173662205c7b1ae8a014a776.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vU_Or7A3jt0bbWhT.jpg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">来源:<a class="ae kc" href="https://unsplash.com/photos/PR_0IPlMXgk" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="54e8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当你看的时候，Apache Hive是一个复杂的系统，但是一旦你去寻找更多的信息，它比复杂更有趣。Hive有多种查询引擎，在查询引擎之上还有LLAP，使实时、交互式查询更加可行。当你了解更多的时候，长寿和过程，或者LLAP，是一个令人敬畏的概念和执行。</p><p id="24e2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这正是我所做的，我读了一些关于LLAP的文件和其他帖子，对它有了更好的了解。我也理解Tez查询引擎，并期待很快看到关于它的帖子。在这篇文章中，我将展示我对LLAP的了解，以及如果你使用它会有多棒。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="77d9" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">配置单元查询引擎</h1><p id="3600" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">Hive有三个查询引擎:</p><ul class=""><li id="6a94" class="ml mm iq kf b kg kh kk kl ko mn ks mo kw mp la mq mr ms mt bi translated">MapReduce (MR)</li><li id="0d15" class="ml mm iq kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated">阿帕奇技术中心</li><li id="3392" class="ml mm iq kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated">阿帕奇火花</li></ul><h2 id="b7e6" class="mz lj iq bd lk na nb dn lo nc nd dp ls ko ne nf lw ks ng nh ma kw ni nj me nk bi translated">MapReduce (MR)</h2><p id="569f" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">MapReduce是Hive附带的第一个查询引擎，也是最慢的一个。当您使用MR作为查询引擎提交一个Hive查询时，每个查询都会被转换成MapReduce作业并提交给YARN容器。YARN或另一种资源协商器在MR和Tez查询引擎之间是常见的。但是MR查询引擎的问题是所有的查询都需要转换成MR jobs。转换本身需要时间。因此，您可以想象这个查询引擎是如何因为大量的延迟而变得缓慢的。</p><h2 id="3529" class="mz lj iq bd lk na nb dn lo nc nd dp ls ko ne nf lw ks ng nh ma kw ni nj me nk bi translated">阿帕奇技术中心</h2><p id="4829" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">为了克服这个延迟问题，Tez作为一个查询引擎被引入到Hive的更高版本中。Tez使用有向无环图(Dag)来处理查询，而不是MapReduce作业。这大大减少了延迟并缩短了查询响应时间。在最新版本的Hive中，尽管不推荐使用MR查询引擎，但它是默认引擎。但是，每当您输入Hive shell时，都会收到反对警告，并建议您切换到Tez或Spark作为查询引擎。而且普遍建议改用Tez。我们将在我的下一篇文章中看到原因。</p><h2 id="81a7" class="mz lj iq bd lk na nb dn lo nc nd dp ls ko ne nf lw ks ng nh ma kw ni nj me nk bi translated">阿帕奇火花</h2><p id="45c1" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">最后，我们有<a class="ae kc" href="https://blog.contactsunny.com/?s=spark" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>作为第三个查询引擎选项。到目前为止，Spark是其中最快的。有人声称Spark可以将Hive的性能提高100倍，这是一个非常大胆的说法。Tez没有提供如此高的性能提升，公认的提升是10倍。所以你可能会说，好吧，火花是明显的赢家，对不对？嗯，那得看情况！Tez和Spark都使用Dag来优化MR的查询性能，因此两者都可以并行或并发执行大量任务。</p><p id="319b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在Tez和Spark之间选择一个查询引擎完全取决于您的应用程序和需求。但是无论你选择什么，LLAP和坐在那个查询引擎的上面并且更好的性能甚至更多。例如，我们知道，如果我们再次需要数据，Spark可以在内存或磁盘上缓存(持久化)数据。但是这种缓存在同一个Spark作业中是可用的，另一个Spark作业不能访问该数据。如果我告诉你LLAP也有这种可能呢？我知道，这太疯狂了。所以，让我们看看LLAP还能做什么。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="ca24" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">长寿和进步(LLAP)</h1><p id="0e70" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">我们终于要谈谈LLAP了。首先你需要知道，就像我已经说得很清楚的，LLAP不是一个查询引擎。它位于查询引擎之上，使查询和数据处理更快。如果你把不同的蜂巢组件想象成一个堆栈，HDFS在底部，纱线在顶部，蜂巢在顶部。现在想象一下在HDFS之上有一层缓存和内存处理。这意味着很多请求根本不会发送到HDFS。这就是LLAP在很高层次上所做的。</p><p id="39c0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我说LLAP是一个缓存和内存处理层时，我肯定是把事情过于简化了。肯定有更好的说法。我来详细说明一下。</p><p id="7691" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以把LLAP想象成另一个运行在Hadoop集群中所有数据节点上的YARN应用。唯一的区别是LLAP是一个长期的过程(因此得名)。但这并不意味着它会耗尽你所有的资源。它可以被配置成一个非常小的进程来处理简单的查询，或者它可以被配置成在需要的时候动态地伸缩。与Spark相比，这带来了非常大的不同。因为LLAP仍然致力于纱线，它带来了纱线的所有优点，如分布式和容错。</p><p id="3bc0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">LLAP在数据节点上运行守护进程，这些守护进程不依赖于发出配置单元查询的用户。这是一个非常重要的区别，因为这允许LLAP跨用户重用缓存的数据。所以你和我都在同一个表上执行类似的查询，LLAP将能够使用已经可用于我们两个查询的缓存，这将提高我们两个的性能。如果没有LLAP，这两个查询将不得不分别执行相同的操作。你可以想象这是多么的不理想。</p><h2 id="46ba" class="mz lj iq bd lk na nb dn lo nc nd dp ls ko ne nf lw ks ng nh ma kw ni nj me nk bi translated">LLAP不是一个查询引擎，它是可选的</h2><p id="1448" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">你现在应该意识到了，LLAP是完全可以选择的。使用LLAP进行配置单元查询并不是强制性的。只有当您希望在交互和批处理模式下提高配置单元查询的响应能力时，才使用LLAP。即使使用LLAP，也不像查询的所有部分都在LLAP执行。LLAP不是用来做这个的，这才是查询引擎的用途。LLAP接受部分查询，这些查询可以通过使用缓存或长寿命进程而受益。</p><p id="f5c1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">LLAP没有承诺它会自己执行整个查询。事实上，是查询引擎决定了什么可以进入LLAP，什么不可以。目前，查询引擎Tez和Pig等其他框架可以在其堆栈中使用LLAP。不幸的是，对MapReduce的支持还没有计划，不要对此抱太大希望。</p><p id="5ab8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">而且因为LLAP仍然是为了和YARN一起工作而建立的，资源分配完全在YARN的控制之中。这也是LLAP守护进程节点能够相互通信并跨节点共享数据的原因。这里的另一个优点是守护进程本身不需要很多资源来运行。YARN分配进程本身所需的最少资源，并会根据工作量在需要时增加资源分配。为了避免堆问题或JVM内存问题，缓存的数据总是保存在堆外的大缓冲区中。因此，与查询引擎相比，LLAP对group by和joins等聚合的处理要快得多。</p><h2 id="c96c" class="mz lj iq bd lk na nb dn lo nc nd dp ls ko ne nf lw ks ng nh ma kw ni nj me nk bi translated">查询片段</h2><p id="392e" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">我已经提到过，LLAP通常执行部分查询，而不是整个查询。查询的这些部分被称为查询片段。这些片段包括过滤器、数据转换、部分聚合、投影、排序、分桶、连接、半连接、散列连接等。需要注意的是，LLAP只接受某些“受祝福的”UDF和Hive代码。</p><p id="d2b8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了流程的稳定性和数据的安全性，LLAP不本地化任何代码，并且动态执行。因为守护进程不依赖于任何特定的用户(如前所述)，所以LLAP节点可以允许跨查询和会话并行执行各种查询片段。这是性能提高的主要原因之一。另一个好消息是，特别是对开发人员来说，LLAP API可以通过客户端SDK直接获得。您可以使用这些API直接指定关系转换。</p><h2 id="e37e" class="mz lj iq bd lk na nb dn lo nc nd dp ls ko ne nf lw ks ng nh ma kw ni nj me nk bi translated">输入和输出</h2><p id="e271" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">正如我已经提到的，守护进程本身占用的内存非常小，这是因为其他的事情大部分都是通过将工作卸载给多线程来完成的。例如，输入和输出被卸载到线程。和转换是在单独的线程中完成的。因此，一旦I/O线程准备好数据，数据就被传递给单独的线程进行处理。这使得I/O线程可用于新的I/O操作。</p><p id="4ffb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据在进程中以游程编码(RLE)列格式进一步传递给其他线程。这在很大程度上减少了跨线程和进程复制数据。通过扩展，缓存也是同样的RLE格式。你可以从这里开始看到好处。</p><p id="c5dd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">I/O和缓存在很大程度上依赖于存储数据的文件格式。如果I/O和缓存必须是高性能的，这是必要的。所以LLAP借助插件将这些知识具体化了。ORC是LLAP支持的第一种文件格式。这就是为什么越来越多地采用ORC作为外部Hive表的首选文件格式的原因之一。</p><p id="604e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">说到缓存，元数据和数据本身都会被缓存。正如我在前面几节中提到的，数据被缓存在堆外以避免其他潜在的问题。但是另一方面，元数据作为Java对象存储在进程中。这确保了即使数据本身被逐出缓存，元数据仍然在内存中，以避免一些开销。</p><p id="9215" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我提到了缓存中的数据驱逐。如您所料，有各种各样的数据驱逐策略。默认情况下，使用LRFU策略。但是您可以随时插入任何其他策略。</p><h2 id="44e7" class="mz lj iq bd lk na nb dn lo nc nd dp ls ko ne nf lw ks ng nh ma kw ni nj me nk bi translated">处理</h2><p id="c5d8" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">这是Hive中争论的一大领域，交易还是不交易。但这是另一篇博文的主题。就LLAP而言，它理解交易。它足够智能，可以在数据被缓存之前执行转换(比如合并或增量文件)。如果在同一个表上执行各种事务(这种情况很常见)，LLAP可以为每种变化存储多个版本的数据。并且将根据查询动态地从缓存中获取正确的版本。这将确保不会对相同的数据一次又一次地执行相同的转换集，从而减少大量的处理时间。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="0027" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">了解LLAP不止于此。还有更多，你越想理解它，它就变得越有趣。随着我探索的深入，我打算写更多关于它的东西。但现在，这是我的全部。理解LLAP的工作方式将使编写查询变得容易得多，而且编写查询的方式可以利用这些优化来减少延迟。我希望这对你的<a class="ae kc" href="https://blog.contactsunny.com/tag/hadoop" rel="noopener ugc nofollow" target="_blank"> Hadoop </a>或<a class="ae kc" href="https://blog.contactsunny.com/?s=hive" rel="noopener ugc nofollow" target="_blank"> Hive </a>之旅有一点帮助。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="505e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你喜欢这里看到的，或者在我的<a class="ae kc" href="https://blog.contactsunny.com/" rel="noopener ugc nofollow" target="_blank">个人博客</a>和<a class="ae kc" href="https://dev.to/contactsunny" rel="noopener ugc nofollow" target="_blank"> Dev上看到的。要写博客</a>，并希望在未来看到更多这样有用的技术帖子，请考虑在<a class="ae kc" href="https://github.com/sponsors/contactsunny" rel="noopener ugc nofollow" target="_blank"> Github </a>上关注我。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="0348" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="nl">原载于2021年11月18日</em><a class="ae kc" href="https://blog.contactsunny.com/data-science/understanding-apache-hive-llap" rel="noopener ugc nofollow" target="_blank"><em class="nl">【https://blog.contactsunny.com】</em></a><em class="nl">。</em></p></div></div>    
</body>
</html>