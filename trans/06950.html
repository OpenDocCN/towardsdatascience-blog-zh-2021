<html>
<head>
<title>Determining the trust in the DNN-based classifier outputs using the hardness of samples</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用样本硬度确定基于DNN的分类器输出的可信度</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/determining-the-trust-in-the-dnn-based-classifier-outputs-using-the-hardness-of-samples-f8fa767fc10e?source=collection_archive---------38-----------------------#2021-06-23">https://towardsdatascience.com/determining-the-trust-in-the-dnn-based-classifier-outputs-using-the-hardness-of-samples-f8fa767fc10e?source=collection_archive---------38-----------------------#2021-06-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="df1e" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想与理论</a>，值得信赖的深度学习</h2><div class=""/><div class=""><h2 id="61f4" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">您只需要样品的硬度</h2></div><p id="e681" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">可信机器学习中最重要的挑战之一是测量分类器输出的可信度。在关键和安全敏感的任务中，确定分类器输出的信任度是至关重要的。我们使用样本的硬度作为估计分类器输出可信度的新度量。首先，我们需要定义样品的硬度。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lk"><img src="../Images/15a990d3b0fe754457e241cde120ddea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XLP8Uiy5Yku5RlO8mWRF3w.png"/></div></div><p class="lw lx gj gh gi ly lz bd b be z dk translated">照片由<a class="ae ma" href="https://unsplash.com/@brett_jordan" rel="noopener ugc nofollow" target="_blank"> <strong class="bd mb">布雷特乔丹</strong> </a>在<a class="ae ma" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="dbb7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">由于基于DNN的分类器的训练过程是在几个时期中完成的，因此我们可以将分类器训练过程视为一系列分类器，其中最后一个分类器被视为实际使用的最终分类器。假设分类器<em class="mc"> f_t </em>被训练了<em class="mc"> m </em>个时期。分类器<em class="mc"> f_t </em>的训练过程可以表示为如下序列:</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div class="gh gi md"><img src="../Images/b17145318a97d95213f01e84029c4657.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*tkw8FnFTtfwAoiyO6a3OIg.png"/></div></figure><p id="8c96" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">其中<em class="mc"> f_t^i </em>是第<em class="mc">个</em>时段结束时的分类器<em class="mc"> f_t </em>。在每个时段结束时创建的分类器被称为子分类器，第<em class="mc"> i个</em>子分类器<em class="mc"> f_t^i </em>是在时段<em class="mc"> i </em>结束时创建的分类器。当<em class="mc"> f_t^e </em>是由<em class="mc"> f_t^e </em>分配的标签等于所有后续子类预测标签的第一个子类时，我们说样本<em class="mc"> x_i </em>在时期<em class="mc"> e </em>中被学习。一般来说，随着历元数量的增加，分类器<em class="mc"> f_t </em>的性能会提高。因此，当一个样本在早期学习时，我们认为它是一个简单的样本，当它在更高的时期学习时，我们认为它是一个更难的样本。</p><p id="766c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因此，<em class="mc">【ϕ_{f_t}(x_i】</em>显示的分级机<em class="mc"> f_t </em>样品<em class="mc"> x_i </em>的硬度直接关系到f_t学习<em class="mc"> x_i </em>的历元数，因此，<em class="mc">【ϕ_{f_t}(x_i】</em>定义如下:</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi me"><img src="../Images/8e45a571c14d36fd60b8e3b631e8f7c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CMe2ukrtcOFhGxiQl81CQw.png"/></div></div></figure><p id="be08" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">硬度范围取决于子类的数量。当我们有<em class="mc"> m </em>个子分类器时，样品的硬度在范围[0，m-1]内。我们在CIFAR10和CIFAR100训练集上训练了三种不同类型的分类器，包括DenseNet121、ResNet18和MobileNet，共100个时期。使用动量为0.9且批量为128的随机梯度下降来训练所有分类器。学习率是0.1，并且计划在每个时期以常数因子0.955减少。我们在每个分类器的训练过程中保存所有100个子分类器，用它们来计算一个样本的硬度程度。</p><p id="a631" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">图1显示了在CIFAR10和CIFAR100测试集的10个硬度范围内，样品被正确和错误分类的百分比。该图表明，随着样品硬度的增加，被正确分类的样品比例减少。超过99%和95%的样本在前30个时期(硬度&lt; 30) are correctly classified in CIFAR10 and CIFAR100 test sets, respectively. On the other side, less than 55% and 36% of samples being learned in the last 10 epochs (hardness degree ≥ 90) are correctly classified in Cifar10 and Cifar100 datasets, respectively. Therefore, as the hardness degree of a sample is increased, the magnitude of trust in the classifier output for that sample is reduced.</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mf"><img src="../Images/b4a3b2c12467622e2bedf643f86d642b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wuIfmZciXJ2onOOzVjQtAA.png"/></div></div><p class="lw lx gj gh gi ly lz bd b be z dk translated">Figure 1: Blue and red bars show that the percentage of test samples in each range of hardness degrees being correctly or wrongly classified, respectively. For each range of hardness degrees, Data Fraction indicates the percentage of CIFAR10 and CIFAR100 test samples whose hardness degrees are in that range.</p></figure><p id="6128" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi">…</p><h1 id="8e78" class="mg mh iq bd mi mj mk ml mm mn mo mp mq kf mr kg ms ki mt kj mu kl mv km mw mx bi translated">Reference:</h1><p id="5a88" class="pw-post-body-paragraph ko kp iq kq b kr my ka kt ku mz kd kw kx na kz la lb nb ld le lf nc lh li lj ij bi translated"><a class="ae ma" href="https://arxiv.org/abs/2106.11424" rel="noopener ugc nofollow" target="_blank"> Amir Mahdi Sadeghzadeh、Amir Mohammad Sobhanian、Faezeh Dehghan和Rasool Jalili)被学习。"</a> HODA:面向硬度的模型提取攻击检测<a class="ae ma" href="https://arxiv.org/abs/2106.11424" rel="noopener ugc nofollow" target="_blank">"(2021).</a></p></div></div>    
</body>
</html>