<html>
<head>
<title>The missing ingredient in deep multi-temporal satellite image super-resolution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度多时相卫星图像超分辨率中缺失的成分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-missing-ingredient-in-deep-multi-temporal-satellite-image-super-resolution-78cac0f063d9?source=collection_archive---------19-----------------------#2021-12-08">https://towardsdatascience.com/the-missing-ingredient-in-deep-multi-temporal-satellite-image-super-resolution-78cac0f063d9?source=collection_archive---------19-----------------------#2021-12-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="6268" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><div class=""><h2 id="d63d" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">置换不变性在单个模型中利用了集成的力量</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/99b437069c9d35c11014e5e22c99831b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wSchv3XJUrXHzpU7tbHTVA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">多时相卫星图像实现超分辨率。修改欧空局哥白尼哨兵2数据，根据CC BY-SA 3.0 IGO许可。</p></figure><p id="bf3a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">由卫星获取的图像的<strong class="lg ja">空间分辨率</strong>永远不够，对于能够显示越来越精细的细节的图像，全球各地的精准农业、灾害监测和可持续发展等应用都有着持续的需求。</p><p id="e436" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">多时相图像是一个场景的快照，它是通过多次重访卫星获得的，可能需要几天或几个月的时间。正如我们在<a class="ae ma" rel="noopener" target="_blank" href="/enhancing-satellite-imagery-with-deep-multi-temporal-super-resolution-24f08586ada0">上一篇文章</a>中解释的那样，多时相图像是提高图像分辨率的关键，但它们必须由复杂的深度学习模型仔细处理，以充分利用它们的信息，同时管理精确配准、场景内容变化等挑战。</p><p id="bb8b" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">受欧洲航天局Proba-V超分辨率挑战的刺激，卫星图像的多图像超分辨率(MISR)主题经历了一系列的研究活动，导致了几种有趣的深度学习方法，如<a class="ae ma" href="https://arxiv.org/abs/1907.06490" rel="noopener ugc nofollow" target="_blank"> DeepSUM </a>、<a class="ae ma" href="http://www.classic.grss-ieee.org/earthvision2020/july_stuff/webpage/papers/Arefin_Multi-Image_Super-Resolution_for_Remote_Sensing_Using_Deep_Recurrent_Networks_CVPRW_2020_paper.pdf" rel="noopener ugc nofollow" target="_blank"> HighRes-net </a>和<a class="ae ma" href="https://www.mdpi.com/2072-4292/12/14/2207/htm" rel="noopener ugc nofollow" target="_blank"> RAMS </a>。</p><h1 id="8202" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">丢失的一块</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mt"><img src="../Images/0e4a9febe23fb329799d76c382bbb6b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JKTdy1Y_J5qbcYEzkWDIgw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">时间顺序在卫星MISR中并不重要。我们需要对时间排列不变的模型。</p></figure><p id="9582" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">然而，现有技术缺少有效深度模型的一个关键要素:<strong class="lg ja">对时间置换的不变性</strong>。动机是输入低分辨率多时相图像的特定顺序对于模型产生超分辨率产品并不重要。<strong class="lg ja">时间排序不携带相关信息</strong>，因为不存在作为时间函数的相关模式，该相关模式可以在一些训练数据上学习，然后在测试中发现和利用。事实上，时间变化更不可预测，因为它有许多来源(云、光照、季节变化、人类活动等)。)和多时态集合的收集中涉及的时间尺度，通常以天为单位。这与视频序列形成了鲜明的对比，在视频序列中，由于从一帧到下一帧的运动的因果演变，排序确实很重要，这是由于所涉及的时间尺度短得多(毫秒分隔连续的帧)。</p><p id="c606" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">当RAMS的作者通过随机改变输入图像的时间顺序，然后对超分辨率输出进行平均来测试他们的方法时，这种现象的暗示已经出现在文献中。据观察，这个<strong class="lg ja">时间集合</strong>提高了性能！然而，运行模型几次并希望一些随机抽取的排列能帮助你，这显然是非常昂贵的。</p><h1 id="3b7d" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">PIUnet:完全不变的模型</h1><p id="2497" class="pw-post-body-paragraph le lf iq lg b lh mu ka lj lk mv kd lm ln mw lp lq lr mx lt lu lv my lx ly lz ij bi translated">问题的解决方案已经在最近一部名为<a class="ae ma" href="https://arxiv.org/abs/2105.12409" rel="noopener ugc nofollow" target="_blank"> PIUnet </a>(排列不变性和不确定性网络)的作品中介绍。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mz"><img src="../Images/3bc70c5c0503abb4b5b24eba300efe37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TrqlU9kshCTurJEXY6HwQw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">皮乌内建筑。图来自<a class="ae ma" href="https://arxiv.org/abs/2105.12409" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2105.12409</a>。</p></figure><p id="c80a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">PIUnet为MISR重新定义了神经网络体系结构的构建块，从而通过设计使其对时间置换完全不变。这允许PIUnet保证对于输入的任何时间排列都返回相同的精确输出。PIUnet的主要设计原理是通过使用<strong class="lg ja">等变层</strong>实现置换不变性，即当输入被暂时置换时，其输出仍然相同但被置换的层。如图所示，然后通过用平均操作折叠时间维度，将等方差转化为不变性。</p><p id="c8d5" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">更详细地，该架构在精神上类似于单图像超分辨率中使用的注意力网络，以及用于卫星MISR的DeepSUM和RAMS作品，但是在主要构建块中具有等变操作，这些是<strong class="lg ja"> TEFA </strong>(时变特征注意力)，以及<strong class="lg ja"> TERN </strong>(时变配准网络)。这些模块的核心是如何以等变方式提取时空特征。这是通过分离空间和时间维度来实现的。空间特征通过卷积来提取，卷积的核在时间上是共享的。然后，多个时刻的空间特征与自我注意操作相混合。<strong class="lg ja">因《变形金刚》而流行的自我关注</strong>，在设计上是置换等变的，因为它依赖于计算所有瞬间的成对互相关。顺便提一下，自我关注的等方差也是变形金刚需要某种位置编码的原因，如果他们想利用排序的话。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi na"><img src="../Images/e6bd344d6d252726845581c54f61e97c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*CgyQYBIDn0BQ0NHdKuQSXg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">TEFA街区。图来自<a class="ae ma" href="https://arxiv.org/abs/2105.12409" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2105.12409</a>。</p></figure><p id="81e0" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja"> TEFA </strong>然后修改经典的特征注意范式，以利用这种等变时空特征提取。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/1280d164cd07a3bf88c33741bb299994.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*G4vwTdz0po3ntbAit_ZurQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">燕鸥街区。图来自<a class="ae ma" href="https://arxiv.org/abs/2105.12409" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2105.12409</a>。</p></figure><p id="2822" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja"> TERN </strong>另一方面是RegNet的等变版本，在DeepSUM中提出，这是一种计算自适应滤波器的方法，即其内核作为输入函数计算的滤波器，可以执行图像之间的插值和微调配准。请注意，TERN不依赖于选择参考图像来注册其他图像，而是允许所有图像同时彼此注册。</p><h1 id="42a6" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">不错！有什么好的吗？</h1><p id="93a7" class="pw-post-body-paragraph le lf iq lg b lh mu ka lj lk mv kd lm ln mw lp lq lr mx lt lu lv my lx ly lz ij bi translated">PIUnet已经在现在经典的Proba-V数据集上进行了测试，并显示了一些令人印象深刻的结果，改善了最先进的技术。特别有趣的是，它如何在质量方面优于使用时态集成的其他方法的版本。这很有趣，因为这意味着PIUnet已经设法<strong class="lg ja">捕捉到了其模型中集合</strong>的丰富性。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nc"><img src="../Images/8820e1ccd968b4a30f4209e6b5a5ff41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ryCCHbogRR2qPAAuKJKdyA.png"/></div></div></figure><p id="40e4" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这也意味着它可以比以前的模型<strong class="lg ja">在计算上更加高效</strong>，并且在利用可用的训练数据方面更加有效，因为它不会浪费数据来学习如何处理排序，而事实上，排序并不重要。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/81162531862a08b7187b21260a364ac9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*PI0rb06zDOcuOSQ5qaktcw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">PIUnet比运行临时集合模型要快得多。</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/498a3c89cf7fc1b376bdbe7bb114fc1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*eHCmc5p5Pt8YV3rCsFiMFw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">PIUnet处理训练数据的效率更高，仅用25%的数据就达到了挑战赛冠军DeepSUM的质量。</p></figure><p id="d563" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">除了在Proba-V挑战数据集上达到最先进水平，PIUnet还在最近的<strong class="lg ja"> AI4EO挑战</strong>中展示了其在增强Sentinel 2农业方面的实力。在这一挑战中，来自Sentinel 2的多时相图像可用于制作耕作区域的超分辨率分割图。虽然Sentinel 2的最大分辨率为每像素10米，但它被要求以每像素2.5米的分辨率制作分割地图。对PIUnet做了一个小小的修改，增加了一个分段头，使得<strong class="lg ja">赢得了挑战</strong>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nf"><img src="../Images/63857baf46ec1be0eaa71e27837529c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eyBbPosm_O1shho6U1za2w.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">在AI4EO增强型农业挑战赛中，PIUnet用于预测来自多个1000万Sentinel2图像的2.5米分割图。</p></figure><h1 id="bb7c" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">结论和进一步阅读</h1><p id="689b" class="pw-post-body-paragraph le lf iq lg b lh mu ka lj lk mv kd lm ln mw lp lq lr mx lt lu lv my lx ly lz ij bi translated">置换不变性似乎是多时相图像超分辨率中的一个基本概念，利用它可以为该任务建立新一代深度学习模型。PIUnet论文包含更多值得阅读的细节，例如量化任意不确定性(PIUnet中的“U ”)对于可解释的人工智能模型的重要性，以及它与图像中时间变化的关系，但这可能是另一个时代的故事。</p><p id="9ef4" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">皮乌内纸:【https://arxiv.org/abs/2105.12409 T4】</p><p id="38cf" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">皮内代码:<a class="ae ma" href="https://github.com/diegovalsesia/piunet" rel="noopener ugc nofollow" target="_blank">https://github.com/diegovalsesia/piunet</a></p></div></div>    
</body>
</html>