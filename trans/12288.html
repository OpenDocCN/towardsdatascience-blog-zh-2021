<html>
<head>
<title>Precision@k: The Overlooked Metric for Fraud and Lead Scoring Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Precision@k:欺诈和销售线索评分模型中被忽视的指标</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/precision-k-the-overlooked-metric-for-fraud-and-lead-scoring-models-fabad2893c01?source=collection_archive---------11-----------------------#2021-12-14">https://towardsdatascience.com/precision-k-the-overlooked-metric-for-fraud-and-lead-scoring-models-fabad2893c01?source=collection_archive---------11-----------------------#2021-12-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0f3e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如果您的模型产生的数据超出了人们的处理能力，Precision@k可能是一个简单的解决方案</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/c482374a2d78db2296d36013d8a44393.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*rIn0bECIVcO7HyoM_epP6Q.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">precision @ k .[图片由作者提供]</p></figure><p id="f86e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当我作为数据科学家在Shopify的零售上市团队工作，现在在Wealthsimple的欺诈团队工作时，我看到了一个共同的问题:我们建立的模型经常产生太多的输出，让我们的同事无法处理。</p><p id="b859" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">例如，在销售中，任何一天都可能有500个潜在的销售线索交给销售团队。但是，如果你只有5名销售代表，他们在工作日可能只能接触到其中的一小部分。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi lq"><img src="../Images/9d5f45811f60d24b5a8a9fa49263916a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SmI5sPo17xoooXF80PWYkQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">当您的输出超过您的容量时，P@K非常有用。【图片由作者提供。]</p></figure><p id="095f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">像<a class="ae lv" href="https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Average_precision" rel="noopener ugc nofollow" target="_blank">平均精度</a>这样的指标——需要计算精度-召回曲线下的面积——是在整个数据集上测量的，并且需要处理所有这些线索，以便随着时间的推移监控指标的性能。</p><p id="7ffc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我想强调一下另一个已经存在了几十年并有助于解决这个问题的指标，但人们谈论得还不够多:<strong class="kw iu"> Precision@k </strong>。</p><h1 id="f53c" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated"><strong class="ak">什么是Precision@k？</strong></h1><p id="85ad" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">Precision@k有几个不同的名字:<em class="mt"> P@k、Prec@k、Precision-at-k、在固定等级测量的精度</em>和<em class="mt"> P(n) </em>(不是一个错别字)<em class="mt">、</em>以及在过去30年左右的文献中你会发现的其他细微变化。这是一个简单的指标，最好用例子来解释，所以让我们从这里开始。</p><p id="0426" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你正在研究了不起的卡尔·萨根，你在搜索引擎中只输入他的姓“萨根”，你可能会发现，在返回的前10篇文章中，只有4篇与他有关。因为在返回的10篇文章中，只有4篇是相关的，所以可以用以下公式计算Precision@10:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi mu"><img src="../Images/b9f182a12ae978722121c369f0049f88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y0S1GIyH426j8eu4R1Jb0g.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi lq"><img src="../Images/ffb8ba6962a3f13e7d147dba876e93fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HY7ypDCJPHDmgVVRXtXtTA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">萨根匹配卡尔·萨根的P@10是0.4。【图片由作者提供。萨根的头像由美国国家航空航天局提供。]</p></figure><p id="27be" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">换句话说,<em class="mt"> k </em>就是你查看的文章数量，Precision@k是那些与你相关的文章的百分比。如果你看第二页的结果，<em class="mt"> k </em>会变成20。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi lq"><img src="../Images/9709034393e6958803d9302cd23f1dd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R66PO4n62X2RtzHrYIOG4g.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">萨根匹配卡尔·萨根的P@20是0.35。【图片由作者提供。萨根的头像由美国国家航空航天局提供。]</p></figure><p id="f996" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你已经熟悉<a class="ae lv" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank">精度</a>，这是完全相同的计算，只是你在以某种合理的方式排序后，将你包括的项目限制为第一个<em class="mt"> k </em>。</p><p id="080f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你觉得Precision@k这个看起来很花哨的术语和你所习惯的精度是一样的，你并不孤单。它在90年代的文本检索会议(TREC)上的早期使用并没有将其作为一个值得大写的特殊术语——它仅仅是人们在确定他们的算法有多好时使用的许多测量精确度的方法之一[1]。直到2000年代中期，Precision@k这个简写形式才从一种方便的表格标题方式，变成了一个完全的专有名词。</p><h1 id="937b" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">Precision@k什么时候有用？</h1><p id="8635" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">Precision@k作为一个不同于平均精度的度量变得有用的地方是在实践中如何使用它。虽然您可以在标记的训练和测试数据集上使用平均精度，但实际上每天测量它要困难得多。如上所述，如果你有500条线索，但你的团队只能完成100条，你永远也不会知道你在另外400条线索上做得如何。但是，你绝对可以在他们完成的工作上计算Precision@100，并且你可以每天都这样做，不管他们能够处理的量有多大。</p><p id="e081" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">回到上面的搜索引擎类比，当你真正考虑它时，搜索引擎和线索评分或欺诈模型之间没有太大的区别。它们都提供了一个项目列表供人们查看，只是我们编写了一个模型而不是一个查询。在所有情况下，我们希望人们看到的结果是相关的，我们不太关心他们永远达不到的结果。</p><p id="752b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，与搜索引擎相比，销售和欺诈应用程序的主要区别在于，顺序通常并不重要。如果您有一个复杂的销售流程，并且您的4人销售团队的每个成员每天可以处理10个销售线索，那么您需要确保最佳销售线索位于列表的前40位。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi lq"><img src="../Images/8c6976f1dc19d9bea601e8ab7b784f7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k1MS4jfGcmG6F7Sa5_fmAw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">如果k=40，您需要确保尽可能多的销售线索(显示为蓝色)低于该限制。【图片由作者提供。]</p></figure><p id="398a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">11号位的领先优势是否比45号位的领先优势更重要。但是，如果好的销售线索发现自己排在前75名之外，你应该关心这个问题，所以你的模型应该围绕这个事实进行优化。这将P@k与排名指标区分开来，如<a class="ae lv" href="https://en.wikipedia.org/wiki/Discounted_cumulative_gain#Normalized_DCG" rel="noopener ugc nofollow" target="_blank">标准化贴现累积收益</a>，其中排序很重要。</p><h1 id="14f4" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">Precision@k不是一个独立的指标。但其他人也不是。</h1><p id="dac2" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">虽然precision的根源始于20世纪50年代早期，在命名确定precision之前，它被称为“相关性因子”和“相关性比率”,但Precision@k在1992年随着上面提到的TREC的创建而开始真正获得关注[2]。这使得研究人员聚集在一起，竞相从大量样本中检索信息。</p><p id="fbab" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在浏览这些早期作品时，我最感兴趣的不是他们对单一指标的选择，而是每个研究人员在并排放置多个指标以获得完整图像时的一致性。例如，下面是TREC-2中的一篇论文的表格，作者使用平均精度、P@5、P@30、P@100、<a class="ae lv" href="https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#R-precision" rel="noopener ugc nofollow" target="_blank"> R-Precision </a>和Recall [3]比较了多个查询性能:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi mv"><img src="../Images/a3b9630730734d85cf1c97763c72dba2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X22uWwv4M0hkW1ds37ytMg.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">来源:[3]</p></figure><p id="905b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我认为这是一个很好的教训:Precision@k不应该<em class="mt">取代</em>其他指标，如平均精度和召回率，而是应该<em class="mt">补充</em>它们，让你对你的模型的性能有一个全面的了解。尤其是在输出由人审核而不是完全自动化的情况下。</p><h1 id="593a" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">你是怎么实现P@k的？</h1><p id="7cf3" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">因为P@K只比precision多一点，对记录的数量有硬性限制，所以它的实现并不复杂。虽然您可以只取数据的前<em class="mt"> k </em>行并将结果传递给Scikit-learn的<code class="fe mw mx my mz b">precision_score</code>函数，但这里有一个更明确的示例，它使用Numpy和一些Scikit-learn的助手来帮助那些想要详细了解它的人。关于使用一些虚假数据的完整示例，请参见笔记本<a class="ae lv" href="https://github.com/Brideau/whackdata-notebooks/blob/main/precision-at-k/Precision%20at%20K.ipynb" rel="noopener ugc nofollow" target="_blank">这里的</a>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="na nb l"/></div></figure><h1 id="a169" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">最后的想法</h1><p id="4f74" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">如果您的模型被能力有限的人使用，Precision@k是添加到您的工具箱中的一个很好的工具。话虽如此，也没什么特别之处。如果有的话，它应该提醒你不要以表面价值来衡量精度和召回率:它们在某些用例中各有用途，但应该扩展、压缩和修改以适应你的特定情况。像所有的数据科学一样，它归结为让工具为你工作，而不是让工具为你工作。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><p id="558a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[1] Harman，D. K. (1993年)。<em class="mt">第一次文本检索会议(TREC-1) </em>(第500卷，第207期)。美国商务部，国家标准与技术研究所。</p><p id="5da4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[2]m .桑德森(2010年)。<em class="mt">基于测试集的信息检索系统评估</em>。现在出版公司。</p><p id="ac65" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">[3]罗伯逊、沃克、琼斯、汉考克-比留和盖特福德(1994年)。TREC的Okapi。<em class="mt"> NIST特刊SP </em>，21–21。</p></div></div>    
</body>
</html>