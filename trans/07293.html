<html>
<head>
<title>Natural Language Processing &amp; Social Sciences</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理和社会科学</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/natural-language-processing-social-sciences-94a35a8a7c78?source=collection_archive---------21-----------------------#2021-07-02">https://towardsdatascience.com/natural-language-processing-social-sciences-94a35a8a7c78?source=collection_archive---------21-----------------------#2021-07-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="09dd" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">这篇文章解释了自然语言处理(NLP)模型在社会科学中的应用。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8f737c5c4df880c3c7672eaec823b777.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RsV4-DkpEu1YkNAM"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@madhur?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Madhur Chadha </a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><blockquote class="kw kx ky"><p id="7edd" class="kz la lb lc b ld le jr lf lg lh ju li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><em class="iq">这是一篇解释自然语言处理(NLP)模型如何应用于社会科学的文章。此外，将使用由OpenAI开发的GPT-3 NLP模型给出几个例子。</em></p></blockquote></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h2 id="a43d" class="md me iq bd mf mg mh dn mi mj mk dp ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated"><strong class="ak">目录</strong></h2><p id="b8d1" class="pw-post-body-paragraph kz la iq lc b ld mz jr lf lg na ju li mm nb ll lm mq nc lp lq mu nd lt lu lv ij bi translated">- <a class="ae kv" href="#3ce2" rel="noopener ugc nofollow">描述</a> <br/> - <a class="ae kv" href="#99c8" rel="noopener ugc nofollow">可能性</a> <br/> - <a class="ae kv" href="#d80c" rel="noopener ugc nofollow">关联性</a>-<br/>-<a class="ae kv" href="#5440" rel="noopener ugc nofollow">举例</a> <br/> - <a class="ae kv" href="#6858" rel="noopener ugc nofollow">结论</a></p></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h2 id="3ce2" class="md me iq bd mf mg mh dn mi mj mk dp ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">描述</h2><p id="7dfb" class="pw-post-body-paragraph kz la iq lc b ld mz jr lf lg na ju li mm nb ll lm mq nc lp lq mu nd lt lu lv ij bi translated">其核心是，自然语言处理工具将预测在处理输入文本后应该输出什么文本。通常，会使用复杂类型的<a class="ae kv" href="https://en.wikipedia.org/wiki/Neural_network" rel="noopener ugc nofollow" target="_blank">神经网络</a>，这是一种机器学习构造。</p><h2 id="99c8" class="md me iq bd mf mg mh dn mi mj mk dp ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">可能性</h2><p id="0762" class="pw-post-body-paragraph kz la iq lc b ld mz jr lf lg na ju li mm nb ll lm mq nc lp lq mu nd lt lu lv ij bi translated">使用NLP模型处理文本的常用方法包括:</p><p id="9353" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated"><em class="lb">文本延续:</em>这是自然语言处理模型可以给出的最基本的任务类型。基于概率，它将继续输入文本，只是长度受限于模型允许运行的周期数。您可以输入句子:“吸烟是”，其中模型可能首先吐出单词“不好”，但如果再运行几个周期，这可能“对您的健康有害”。</p><p id="edb5" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated"><em class="lb">回答问题:</em>同样，基于给定的约束，模型将返回给定问题的答案，开放式或是或否。你甚至可以要求NLP模型就给定的主题写文章，尽管当被问及精确的科学时，它们的表现相当差；真正的理解还不存在。根据所使用的定义，你可能会认为语言模型目前也不理解其他主题。只是对于社会科学相关的问题，更容易预测一个接一个的正确单词。这可能是部分原因，因为社会科学在本质上相对更基于论证，而有形的社会科学相关的论证通常遵循类似的模式。当你进入数学直觉的领域，事情往往会变得更加抽象、多变和复杂。注意，所有接下来的例子都可以被认为是这个例子的子集，但是额外的细节是出于信息的原因给出的。</p><p id="b0f8" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated"><em class="lb">摘要:</em>给出一段文本作为输入，并返回一个符合先前指定约束的摘要作为输出。一些复杂的NLP模型甚至能够输出摘要，就好像是给二年级学生<a class="ae kv" href="https://beta.openai.com/examples/default-summarize" rel="noopener ugc nofollow" target="_blank">看的一样。通常，这些模型相当善于挑选应该包括在摘要中的内容，这可能是因为上一个例子中给出的相同推理路线:写摘要通常需要查看类似的短语，这些短语表明文本中的重要性，并且一些语法“理解”似乎存在于这些模型中。这种理解的概念是值得思考的。这些模型估计了某段文本在最后一段之后出现的可能性，但是我们在哪些方面与之不同呢？这样的问题怎么回答就不那么清楚了。这并不意味着我们在某种程度上与这些模型相似的可能性很高，这种可能性确实存在。</a></p><p id="4f2a" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated"><em class="lb">在正文中寻找答案:</em>这是一个与上一个例子有些关联的例子。这里，所提供的文本连同与所提供的文本相关的问题一起被给予模型。与摘要一样，对于这些模型来说，这通常是一项简单的任务，但是一旦模型被要求从文本中给出的信息中进行抽象，它就很难有效地内插或外推这些想法。</p><p id="ae35" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated"><em class="lb">文本分类:</em>这也与前面的例子相关。一个例子是要求模型将给定文本分类为包含积极、中立或消极情绪。这对于分析与某个主题相关的大量社交媒体帖子的情绪非常方便。</p><p id="688c" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated"><em class="lb">编写代码:</em>为了恢复，模型本质上是对下一个文本的预测(准确地说，通常模型一次预测一个'<a class="ae kv" href="https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html" rel="noopener ugc nofollow" target="_blank">标记</a>)。这些模型是在有标签或无标签的数据上训练的，前者是在某些指定的NLP任务的流线被指定时选择的，而后者是在使用模型时需要更多的自由度时选择的。标记数据的一个例子是一段带有相应摘要的文本，并相应地进行标记。当涉及到代码时，这些数据通常包含基本的示例，由于其学习性质，该模型通常不擅长预测边缘情况下返回什么，或者如何根据其“知识”进行推断以解决不同的编码问题。因此，模型能够很好预测的代码通常与标准的、已知的编码问题相关联。</p><blockquote class="kw kx ky"><p id="15c4" class="kz la lb lc b ld le jr lf lg lh ju li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><em class="iq">取自OpenAI网站的一个例子的输入:<br/> </em> <code class="fe ne nf ng nh b">Use list comprehension to convert this into one line of JavaScript:<br/>dogs.forEach((dog) =&gt; {<br/>car.push(dog);<br/>});<br/>JavaScript one line version:</code></p><p id="7d6a" class="kz la lb lc b ld le jr lf lg lh ju li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><em class="iq">带有GPT-3返回的输出:<br/> </em> <code class="fe ne nf ng nh b">dogs.forEach(dog =&gt; car.push(dog))</code></p></blockquote><p id="629d" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated">除非您的特定问题与某些数据条目有许多相似之处，例如，只是执行顺序不同，否则您的特定问题输入将不会得到满意的回答。</p><h2 id="d80c" class="md me iq bd mf mg mh dn mi mj mk dp ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">关联</h2><p id="6372" class="pw-post-body-paragraph kz la iq lc b ld mz jr lf lg na ju li mm nb ll lm mq nc lp lq mu nd lt lu lv ij bi translated">基于上面给出的例子，我们可以提炼出自然语言处理在社会科学中的三个应用领域:</p><p id="b6c9" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated"><em class="lb"> 1。教育工具:</em>对于给出的所有示例，它认为模型能够根据提供给模型的数据返回输出。鉴于输入的是我们已经知道的东西，而模型在这些知识上的构建能力还没有以不同方式回忆信息的能力那么复杂，NLP模型可以被视为工具，既可以以更小的片段再现我们已经知道的东西，也可以执行我们自己也可以完成的基本任务，如总结或情感分析。尽管模型可能只“知道”人类也知道的事情，但这并不意味着模型可能“知道”的所有事情也为任何给定的个人所知。因此，在某种程度上，该模型类似于我们钟爱的搜索引擎Google，根据手头的用例，可能更具延展性，并配备了额外的功能，如摘要技能。</p><blockquote class="kw kx ky"><p id="2735" class="kz la lb lc b ld le jr lf lg lh ju li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><em class="iq">有一个例子很好地说明了这些工具如何应用于教育:</em></p></blockquote><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="200c" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated"><em class="lb"> 2。研究中的辅助任务工具:</em>与前面的观点重叠，人们可以将他们的知识扩充到NLP模型在某种程度上已经训练过的数据中嵌入的知识。此外，用例的一些想法包括根据一些标签集对其他研究人员的论文进行分类，从而建立一个易于访问的知识库。然后，可以提出问题在这些论文的正文中查找。还可以向模特提出快速的一次性问题，以查找必要的一般信息。然而，谷歌也许能够更可靠地做同样的事情。此外，将草稿转换成写得很好的语言是可能的，但是成功执行这样的命令需要相当多的逻辑，所以这可能会给模型带来困难。同样的道理也适用于将书面文本转换成领域外的人能够理解的更清晰的语言。对你写的东西进行快速总结并发给研究合作者也是可能的。就目前而言，自己写摘要或研究论文似乎更可靠(如果你的研究超出了模型训练数据中嵌入的“知识”的界限)。不过，看看NLP模型如何总结你的工作也无妨。最后，编写代码可以帮助简化作为最终项目组成部分的标准算法的实现过程。</p><p id="7896" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated">3.<em class="lb">用于研究的数据收集:</em>特别是对于政治研究项目，使用社交媒体的数据收集<a class="ae kv" href="https://beta.openai.com/examples/default-adv-tweet-classifier" rel="noopener ugc nofollow" target="_blank">针对某些相关话题的情感分析</a>可以在瞬间产生大量可信的数据。以类似的方式，它可以用来观察思想如何在社交媒体上传播，金融新闻如何在网上处理和在公众中谈论，并最终影响我们的经济。可能有更多的可能性可以探索，但命名的似乎是最简单的。</p><h2 id="5440" class="md me iq bd mf mg mh dn mi mj mk dp ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">示例性实现</h2><p id="394b" class="pw-post-body-paragraph kz la iq lc b ld mz jr lf lg na ju li mm nb ll lm mq nc lp lq mu nd lt lu lv ij bi translated">在写这篇文章之前，我也尝试过使用社会科学的NLP模型，准确地说，是OpenAI的GPT-3，我被授予了beta访问权限。我的基本计划是创建一个辅助的和鼓舞人心的工具，在那里简短的问题将得到简短的回答。其核心是，我开发了两种不同的提示，用户可以通过这两种提示询问一些决定某种现象的因素，或者用有限的句子解释是什么导致了一个事件的发生。在对每个不同问题的参数做了一些调整后，通常，这个模型会发挥作用。对于因素列表提示，出现的不准确性比解释提示更多，这可能是因为描述事件更像是一种回忆行为，而不是命名某种现象的因素，后者更经常需要从训练的数据中建立。换句话说，如果你能说出一些特殊的历史事件，你也能说出是什么导致了它。由于OpenAI的GPT-3基本上是在互联网上训练的，所以它是在互联网上注册的事件上训练的，因此它也知道导致最详细记录的事件的原因，因为这些原因通常包含在命名它们的文章中。某些特定现象的因素通常不太好记录，有时需要对数据进行更多的外推或插值，有人认为这些NLP模型并不擅长。</p><p id="eb46" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated"><em class="lb">使用该工具的一个例子:</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/7f4ae41f66377b8bedf5c4912b86c536.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nwvX-RRvASERUAA7U1zrmA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">提交<a class="ae kv" href="https://omnisci-ai.glitch.me" rel="noopener ugc nofollow" target="_blank">工具</a>的因子提示</p></figure></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h2 id="6858" class="md me iq bd mf mg mh dn mi mj mk dp ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">结论</h2><p id="3669" class="pw-post-body-paragraph kz la iq lc b ld mz jr lf lg na ju li mm nb ll lm mq nc lp lq mu nd lt lu lv ij bi translated">自然语言处理已经走过了漫长的道路，并产生了令人惊讶的结果。通常，在某些模型发布后的媒体平台上，这些模型能够做什么的最惊人的例子会被挑选出来，例如一个<a class="ae kv" href="https://www.youtube.com/watch?v=PqbB07n_uQ4&amp;t=790s" rel="noopener ugc nofollow" target="_blank">采访</a>，在采访中向模型提出精心设计的问题，以确保它能给出有趣的答案(本文包含为什么这些问题对模型来说很容易回答的解释)。在现实中，当这些模型暴露于甚至需要最基本的问题解决的中等复杂的问题时，它们就崩溃了。然而，NLP模型有许多用途，并且随着其能力的不断发展，自然语言处理模型在不久的将来将会发挥相当大的作用是很有可能的。</p></div></div>    
</body>
</html>