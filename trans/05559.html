<html>
<head>
<title>Interpreting CNN Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解读CNN模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/interpreting-cnn-models-a11b1f720097?source=collection_archive---------28-----------------------#2021-05-17">https://towardsdatascience.com/interpreting-cnn-models-a11b1f720097?source=collection_archive---------28-----------------------#2021-05-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2f76" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何对我们的预测进行直观的解释</h2></div><h1 id="dfdd" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">TL；DR —跳转到代码</h1><p id="121e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Grad-CAM为您的CNN模型的预测提供了一个区分类别的可视化解释。制导Grad-CAM也使可视化具有高分辨率。您可以在这里找到生成可视化效果<a class="ae lt" href="https://colab.research.google.com/drive/1L4Oy-_dkP4Qb1SpuqbyrIPDu7DYQCMAN?usp=sharing" rel="noopener ugc nofollow" target="_blank">的代码。</a></p><h1 id="6672" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">问题是</h1><p id="44c5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如今，机器学习模型被广泛用于自动化和决策制定。模型的可解释性对于调试这些模型以及在系统中建立信任都是至关重要的。当我们使用传统的机器学习解决方案，如基于树的模型时，有大量的工具可用于模型的可解释性。我们可以可视化单个的树，绘制<a class="ae lt" href="https://scikit-learn.org/stable/modules/partial_dependence.html" rel="noopener ugc nofollow" target="_blank">部分相关</a>图来理解不同特征对目标变量的影响，使用像<a class="ae lt" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank">形状值</a>这样的技术来计算特征重要性或解释单个预测背后的因素，等等。</p><p id="a342" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">然而，深度学习模型通常被视为黑盒。我们投入大量数据，训练一个模型，希望它能起作用。在本文中，我们将一窥计算机视觉模型的黑箱内部——特别是，模型在进行预测时关注的是什么？是学习人类相似的直觉，看着正确的事物做出正确的预测吗？</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/1e0d0bb8b2ca13500b488e7b5e42c5e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*0e1tqqRUqJLdSSvQoNIWdQ.png"/></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">通过<a class="ae lt" href="https://xkcd.com/1838/" rel="noopener ugc nofollow" target="_blank"> xkcd </a>进行机器学习</p></figure><h1 id="6f3c" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">什么是好的直观解释？</h1><p id="f7f6" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">对于图像分类，用于证明任何目标类别的来自模型的“好的”视觉解释应该满足两个特性:</p><ol class=""><li id="afc8" class="ml mm iq kz b la lu ld lv lg mn lk mo lo mp ls mq mr ms mt bi translated"><strong class="kz ir">类别区分</strong> -它应该能够定位输入图像中的不同区域，这些区域对不同的输出类别有贡献。</li><li id="e043" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated"><strong class="kz ir">高分辨率</strong>:应该能够捕捉到精细的细节。</li></ol><h1 id="fa79" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">Grad-CAM</h1><p id="f9f7" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">梯度加权类激活映射(Grad-CAM)使用流入最终卷积层的任何目标概念(比如分类网络中的“狗”)的梯度来生成粗略定位图，突出显示图像中的<br/>重要区域，用于预测概念。让我们来分解一下:</p><h2 id="575c" class="mz kg iq bd kh na nb dn kl nc nd dp kp lg ne nf kr lk ng nh kt lo ni nj kv nk bi translated">为什么要用最后的卷积层？</h2><p id="ba8d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">CNN中更深的层捕捉更高层次的视觉结构。此外，卷积层自然保留了全连接层中丢失的空间信息(通常出现在CNN架构中的最后一个卷积层之后)，因此我们可以预期最后一个卷积层在高级语义和详细空间信息之间具有最佳折衷。这些层中的神经元在图像中寻找特定于语义类别的信息(比如对象部分)。</p><h2 id="374a" class="mz kg iq bd kh na nb dn kl nc nd dp kp lg ne nf kr lk ng nh kt lo ni nj kv nk bi translated">生成类激活图</h2><p id="d325" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">要生成类激活图，我们需要获取在最后一个卷积层中检测到的特征，并查看在预测输出概率时哪些特征最活跃。换句话说，我们可以将最后一个卷积层的特征图阵列中的每个通道乘以关于输出类的“该通道有多重要”,然后对所有通道求和，以获得图像中相关区域的热图。</p><h2 id="fc23" class="mz kg iq bd kh na nb dn kl nc nd dp kp lg ne nf kr lk ng nh kt lo ni nj kv nk bi translated">CAM vs Grad-CAM</h2><p id="7a48" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">传统的CAM使用全局平均池权重来衡量最后一个卷积层的激活。CAM的一个缺点是，它需要特征映射直接位于softmax层之前，因此它仅适用于在<br/>预测之前对卷积映射执行全局平均池化的特定种类的CNN架构(即，conv特征映射→全局平均池化<br/> → softmax预测层)。</p><p id="9f54" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">Grad-CAM使用流入CNN最后一个卷积层的梯度信息来分配重要性值。Grad-CAM适用于<br/>种类繁多的CNN型号系列</p><h2 id="803e" class="mz kg iq bd kh na nb dn kl nc nd dp kp lg ne nf kr lk ng nh kt lo ni nj kv nk bi translated">观看Grad-CAM的运行</h2><p id="f51e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">让我们拍摄一张包含一只猫和一只狗的输入图像，看看Grad-CAM的表现如何。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi nl"><img src="../Images/0edd85abd6ef8fa425fd15db3c35b5b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jl-v7tMjDPwG-FCv2bH7ZA.jpeg"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">包含一只猫和一只狗的图像。(图片来自Keras <a class="ae lt" href="https://keras.io/examples/vision/grad_cam/" rel="noopener ugc nofollow" target="_blank">示例</a>在Apache许可下)</p></figure><p id="d667" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">应用Grad-CAM会生成与卷积特征图大小相同的粗略热图</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/bd2e7fbe7c1698dc52895ce8ebe9fae1.png" data-original-src="https://miro.medium.com/v2/resize:fit:474/format:webp/1*Zpg8Ba1OPeOq4AQL87fvVQ.png"/></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">Grad-CAM热图显示了最终卷积层神经元在预测中的重要性。(图片由作者提供)</p></figure><p id="610e" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">然后可以调整该热图的大小，并将其叠加在原始图像上。我们可以看到，它能够非常准确地识别狗的区域和猫的区域。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi nl"><img src="../Images/634c0a0ef622adf392a6be56d5569294.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TUvRRsdt0Qjrntd1har1cA.jpeg"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">对应于狗类的Grad-CAM热图。(图片来自Keras <a class="ae lt" href="https://keras.io/examples/vision/grad_cam/" rel="noopener ugc nofollow" target="_blank">示例</a>由作者编辑)</p></figure><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi nl"><img src="../Images/0fe2ca6169facdbceef57172d147e0d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fmzTe88Ik7aIOR0KaLpAIg.jpeg"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">对应于cat类别的Grad-CAM热图。(图片来自Keras <a class="ae lt" href="https://keras.io/examples/vision/grad_cam/" rel="noopener ugc nofollow" target="_blank">示例</a>由作者编辑)</p></figure><h1 id="1953" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">应用:使用Grad-CAM减少偏差</h1><p id="87c2" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">让我们离开猫和狗，看看一个更实际的用例。在有偏见的数据集上训练的模型可能无法推广到真实世界的场景，或者更糟的是，可能会延续偏见和刻板印象(性别、种族、年龄等。).以一个在图像搜索结果上训练以识别护士和医生的模型为例。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi nr"><img src="../Images/60bc683bfe93b15ff9710c2135f87111.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FG2Tc2yQMz7y4qf-c-9xNQ.png"/></div></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">一个医生的形象。有偏模型预测这个是护士，无偏模型预测医生。我们使用Grad-CAM来可视化两个模型的预测。(图片来自<a class="ae lt" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank"> Grad-CAM论文</a>)</p></figure><p id="12b5" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">事实证明，搜索结果存在性别偏见——78%的医生图片是男性，93%的护士图片是女性。有偏见的模型通过看脸和发型做出了错误的预测(将医生误归类为护士)。我们使用Grad-CAM来可视化模型关注的区域。</p><p id="3ca8" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">使用从Grad-CAM可视化中获得的直觉，我们通过添加男护士和女医生的图像来减少训练集中的偏差，同时保持每个班级的图像数量与以前相同。看着白大褂和听诊器，无偏模型做出了正确的预测。这不仅对更好的推广很重要，而且对公平和道德的结果也很重要，因为在<br/>社会中有更多的算法决策</p><h1 id="e72b" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">更进一步:高分辨率</h1><p id="808a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Grad-CAM能够产生区分类别的可视化效果。但是，它会生成最终卷积层大小的热图，然后将最终卷积层的大小调整为输入图像的大小。因此，该热图是一个粗糙的低分辨率热图。</p><h2 id="9aae" class="mz kg iq bd kh na nb dn kl nc nd dp kp lg ne nf kr lk ng nh kt lo ni nj kv nk bi translated">导向反向传播</h2><p id="70aa" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如果我们对输入图像进行进一步的梯度处理，而不是停留在最终的卷积层，会怎么样？它可以生成细粒度的输入像素级热图。</p><p id="5e4d" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">这种反向传播可视化，通常称为显著图，可以通过获得损失相对于图像像素的梯度来生成。强烈影响损失的某些像素的变化将被明亮地显示。然而，这通常会产生噪声图像，并且已经表明在反向传播期间将梯度削波小于零(直观上只允许正面影响)会产生更清晰的图像。这类似于向前传播中的重新激活。这项技术被称为引导反向传播。</p><p id="6005" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">导向反向传播生成与输入图像大小相同的梯度热图。由于我们不需要将小特征地图的尺寸调整到输入图像的尺寸，这是构造高分辨率。然而，这里的缺点是可视化没有阶级区分。你可以看到图像中狗和猫的部分都亮了，这与狗的丢失相对应。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/62f7bc4297aed921a59c55ed61d7a481.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*PwvPIxdJ6yDnNuCdgFA6fA.png"/></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">狗的引导反传可视化。(图片由作者提供)</p></figure><p id="a2c2" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">但是请注意，这种可视化仍然非常有用。这只是图像大小的梯度，但它清楚地识别了猫区域、狗区域和背景区域。这可能表明，如果狗或猫的区域发生变化(比如猫显示得更突出或狗显示得不那么突出)，它可以改变预测。</p><h2 id="dc7f" class="mz kg iq bd kh na nb dn kl nc nd dp kp lg ne nf kr lk ng nh kt lo ni nj kv nk bi translated">制导摄像机</h2><p id="4efe" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们可以通过合并Grad-CAM热图作为特征重要性来解决引导式反向传播可视化不具有类别区分性的事实。这给出了一个类区分和高分辨率的图像。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/c6bb396e860e40ccf89d3e43b0393f55.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*vBH-RZJO02XkWtd5GBPtIA.png"/></div><p class="mh mi gj gh gi mj mk bd b be z dk translated">狗的引导Grad-CAM可视化。(图片由作者提供)</p></figure><h1 id="588c" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">摘要</h1><p id="71e5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们不要再把深度学习模型当成黑盒了。我们需要开发更多的工具和技术来窥视模型内部并理解它们。这对于验证模型不仅做出正确的预测，而且使用正确的信号做出预测是至关重要的。Grad-CAM和引导Grad-CAM为理解CNN模型的预测提供了一种极好的方式。</p><p id="8dba" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">这是一个包含代码的<a class="ae lt" href="https://colab.research.google.com/drive/1L4Oy-_dkP4Qb1SpuqbyrIPDu7DYQCMAN?usp=sharing" rel="noopener ugc nofollow" target="_blank"> colab </a>笔记本，用于生成Grad-CAM、引导后向传播和引导Grad-CAM可视化。</p><h1 id="04d4" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">参考</h1><ol class=""><li id="b405" class="ml mm iq kz b la lb ld le lg nt lk nu lo nv ls mq mr ms mt bi translated">Grad-CAM:通过基于梯度的定位来自深度网络的视觉解释，<a class="ae lt" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank"> arXiv:1610.02391 </a></li><li id="5f94" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated">【https://keras.io/examples/vision/grad_cam/ T4】</li><li id="59b4" class="ml mm iq kz b la mu ld mv lg mw lk mx lo my ls mq mr ms mt bi translated"><a class="ae lt" href="https://github.com/ismailuddin/gradcam-tensorflow-2/blob/master/notebooks/GradCam.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/ismailuddin/grad cam-tensor flow-2/blob/master/notebooks/grad cam . ipynb</a></li></ol></div></div>    
</body>
</html>