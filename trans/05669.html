<html>
<head>
<title>Galaxy Multi-Image Classification with LeNet-5</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于LeNet-5的星系多影像分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/galaxy-multi-image-classification-with-lenet-5-1bc2f66d3cfc?source=collection_archive---------19-----------------------#2021-05-20">https://towardsdatascience.com/galaxy-multi-image-classification-with-lenet-5-1bc2f66d3cfc?source=collection_archive---------19-----------------------#2021-05-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/1e8309e0ebca24fd30b66011f78bb04e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0XJWFzhNfULkEMFo"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">Guillermo Ferla 在Unsplash上拍摄的照片。</p></figure><div class=""/><div class=""><h2 id="fe83" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">用梯度下降魔法探索空间</h2></div><p id="f10e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">星系的美丽从未停止征服我。思考星系是令人难以置信的基础，它们是重塑视角的有力工具。</p><p id="66be" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">不久前，当我在互联网上搜索我的下一次机器学习冒险时，我偶然发现了<a class="ae jd" href="https://astronn.readthedocs.io/en/latest/galaxy10.html" rel="noopener ugc nofollow" target="_blank">这个</a>机器，我知道我必须试一试。不过，在训练机器对图像进行分类之前，我很好奇，<em class="lr"> I </em>能把它们分类得多好？</p><p id="8e42" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">简短的回答是不太好。其中一些非常明显，我可以很容易地把它们挑选出来，归类为一个特定的标签。其他人我会很有信心，但当我发现我错了的时候，我的信心就破灭了。</p><p id="6f5d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">考虑到这一点，我现在很好奇。一台机器能做得多好？因此，我对这个问题进行了测试，并构建了一个卷积神经网络——到底是哪一个呢？心爱的LeNet-5！</p><p id="8ff5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本文中，我将从头到尾介绍如何建立一个对星系进行分类的机器学习模型！</p><p id="3531" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">只对代码感兴趣？没关系，我不太生气。我将为您省去通读整篇文章的麻烦，因为说实话，当我只需要某个特定部分时，我不太喜欢费力地阅读大量信息。这里是<a class="ae jd" href="https://www.kaggle.com/tenzinmigmar/classifying-iris-flower-types-with-k-means" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>笔记本的链接。</p><h2 id="103f" class="ls lt jg bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">导入依赖关系</h2><p id="e5e9" class="pw-post-body-paragraph kv kw jg kx b ky ml kh la lb mm kk ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">在构建任何机器学习模型时，要做的第一件事是下载我们需要的依赖关系。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="c1e3" class="ls lt jg mv b gy mz na l nb nc">! pip install astroNN<br/>import tensorflow as tf<br/>import matplotlib.pyplot as plt<br/>import pandas as pd<br/>import seaborn as sns<br/>import numpy as np<br/>from tensorflow import keras<br/><br/>from keras.models import Sequential<br/>from keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Dropout<br/>from keras.callbacks import ReduceLROnPlateau<br/>from keras.optimizers import Adam<br/><br/>import sklearn<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import classification_report,confusion_matrix<br/>from tensorflow.keras import utils<br/><br/>from astroNN.datasets import galaxy10<br/>from astroNN.datasets.galaxy10 import galaxy10cls_lookup</span></pre><p id="c181" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">完成后，我们现在有了开始构建模型所需的工具。</p><h2 id="a9c7" class="ls lt jg bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">关于数据集</h2><p id="a366" class="pw-post-body-paragraph kv kw jg kx b ky ml kh la lb mm kk ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">如果你读过我的其他机器学习文章，你就会知道我对数据的评价有多高。数据点是我们日常决策的北极星。你知道你的同事总是在上午10点霸占着咖啡机吗？你可以把喝咖啡的时间改到9:30。因为你的老师喜欢用突击测验给你惊喜而不断受挫？你将开始每天学习，为第二天他们可能扔给你的任何东西做好准备。</p><p id="871d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">数据是机器学习的核心。如果人工智能有一个口号，我会说是“只添加数据”。话虽如此，我还是给大家简单介绍一下今天节目的明星:galaxy10！</p><p id="6a81" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">galaxy10数据集包含21785个69x69像素的彩色星系图像，分为10个不同的类别。该数据集的图像来自斯隆数字巡天，标签来自银河动物园。</p><p id="58de" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">数据集内的每个图像被分类为10个类别中的一个，然而，在分配给来自人类志愿者的某些图像的类别中存在差异，所述人类志愿者的任务是标记图像，其作为经验证据，表明在类别之间的图像中存在高水平的相似性。为了缓解这个问题，Galaxy10数据集不包括没有最终决定的图像。(55%的人类志愿者投票支持一个类别)</p><p id="a841" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">您现在已经熟悉了数据集！我们继续吧。</p><h2 id="62fe" class="ls lt jg bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">数据探索</h2><p id="6da4" class="pw-post-body-paragraph kv kw jg kx b ky ml kh la lb mm kk ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">现在，我们不能探索尚未加载的数据。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="d6a8" class="ls lt jg mv b gy mz na l nb nc">images, labels = galaxy10.load_data()<br/><br/>x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)<br/><br/>features = ['Disk, Face-on, No Spiral', 'Smooth, Completely round', 'Smooth, in-between round', 'Smooth, Cigar shaped', 'Disk, Edge-on, Rounded Bulge', 'Disk, Edge-on, Boxy Bulge', <br/>            'Disk, Edge-on, No Bulge','Disk, Face-on, Tight Spiral', 'Disk, Face-on, Medium Spiral', 'Disk, Face-on, Loose Spiral']<br/><br/>x_train = x_train / 255.0<br/>x_test = x_test / 255.0</span></pre><p id="064b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">那更好。现在，让我们试着更好地理解这些数据。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="3d1d" class="ls lt jg mv b gy mz na l nb nc">x_train.shape, x_test.shape</span><span id="71a3" class="ls lt jg mv b gy nd na l nb nc"># This prints ((17428, 69, 69, 3), (4357, 69, 69, 3))</span></pre><p id="ad14" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，我们对数据集有了更多的了解。这里，我们有17248个尺寸为69×69的彩色训练图像和4357个尺寸为69×69的彩色测试图像的数据集。让我们来看看数据集中随机选择的图像。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="72fa" class="ls lt jg mv b gy mz na l nb nc">fig = plt.figure(figsize=(20,20)) <br/><br/>for i <strong class="mv jh">in</strong> range(25):<br/>    plt.subplot(5,5,i+1)    <br/>    plt.imshow(x_train[i])<br/>    plt.title(features[y_train[i]])<br/>    fig.tight_layout(pad=3.0)<br/>    <br/>plt.show()</span></pre><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/65bf3749ff545f3098e01d1b26af91fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MQNB-MYMLcrnokXBDsEScg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">从数据集中选择星系图像。来自galaxy10数据集的图像。</p></figure><p id="d309" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">令人敬畏不是吗？让我们看看这个数据集还能揭示什么。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="bdc6" class="ls lt jg mv b gy mz na l nb nc"><em class="lr"># Check class distribution</em><br/><br/>df = pd.DataFrame(data=labels)<br/><br/>counts = df.value_counts().sort_index()<br/>print(counts)</span></pre><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nf"><img src="../Images/b2f938bf4c7f544da3f9750195a2643b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gOK2EPmIjfEewuOSx0-zLw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">上面代码的输出。图片由作者提供。</p></figure><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="4771" class="ls lt jg mv b gy mz na l nb nc">def class_distribution(x, y, labels):<br/>    fig, ax = plt.subplots()<br/>    ax.bar(x, y)<br/>    ax.set_xticklabels(labels, rotation=90)<br/>    plt.show()<br/>    <br/>class_distribution(features, counts, features)</span></pre><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ng"><img src="../Images/61d47e56433884ee533dd73b682b164e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dPFD29i5BvNb-5pAY7KfBA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">上面代码的输出。图片由作者提供。</p></figure><h2 id="b176" class="ls lt jg bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">不平衡数据:准确性悖论</h2><p id="cbb8" class="pw-post-body-paragraph kv kw jg kx b ky ml kh la lb mm kk ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">这里，我们有一个相当不平衡的数据集。每个类别中的图像数量范围从类别5中的17(最小)到类别1中的6997(最大)。具有偏斜类别分布的数据的问题在于，准确度不再是正确反映机器学习模型对图像进行分类的能力的评估度量。这也被称为<strong class="kx jh">准确性悖论</strong>，即具有较高准确性的模型可能比具有较低准确性的模型具有更少的预测能力。</p><p id="2ddf" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">总结一下:准确性可能并不总是评估你的模型的最佳指标。因此，如果我们使用其他评估指标，如精确度或召回率，这将是一个更公平的分析。</p><p id="e5fc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">精度</strong>:精度=真阳性(TP) /真阳性(TP) +假阳性(FP)</p><p id="9880" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">召回</strong>:召回=真阳性(TP) /真阳性(TP) +假阴性(FN)</p><p id="0bf1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">补充说明:</strong>精度和召回指标已被移除，因此我们将使用精度作为指标来训练卷积网络，但稍后将使用Scikit Learn的分类报告来更好地了解我们模型的精度、召回和f1分数。</p><h2 id="4edd" class="ls lt jg bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">训练基线模型</h2><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="a06d" class="ls lt jg mv b gy mz na l nb nc">model = Sequential()<br/><br/><em class="lr"># Baseline model to compare to LeNet-5</em><br/>model.add(Flatten(input_shape=(69, 69, 3)))<br/>model.add(Dense(128, activation='relu'))<br/>model.add(Dense(10, activation='softmax'))<br/><br/>model_optimizer = Adam(lr=0.001)<br/><br/>model.compile(optimizer=model_optimizer, loss='sparse_categorical_crossentropy', metrics=["accuracy"])<br/>reduceLR = ReduceLROnPlateau(monitor='accuracy', factor=.001, patience=1, min_delta=0.01, mode="auto")<br/>lol = model.fit(x_train, y_train, epochs=10, callbacks=[reduceLR])</span></pre><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nh"><img src="../Images/e8bb05bdf343f2048e916b2785b52a42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SAdDfxyYLYIXpHVQGtJsLw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">上面代码的输出。图片由作者提供。</p></figure><p id="abb3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">还不错。最终准确率为70%。让我们看看LeNet-5在比较中表现如何，但在此之前，我先向您介绍一下LeNet-5的背景。</p><h2 id="fb7d" class="ls lt jg bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">LeNet-5架构</h2><p id="5d38" class="pw-post-body-paragraph kv kw jg kx b ky ml kh la lb mm kk ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">LeNet-5是一种古老而经典的卷积神经网络架构，由Yann Andre LeCun、Leon Bottou、Yoshua Bengio和Patrick Haffner于1998年开发。最初开发时，它是为手写MNIST数字识别而设计的，后来成为了AlexNet和VGG等未来架构的基础。</p><p id="d569" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">第一个卷积块由两个卷积和平均池层组成，其后是一个平坦层，然后是3个密集层。</p><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ni"><img src="../Images/172e13f86781ac763010a24d776bd772.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*utJ5tWibo6-k17ZR.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">LeNet-5架构。图可以在<a class="ae jd" href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" rel="noopener ugc nofollow" target="_blank">原文中找到。</a></p></figure><p id="09eb" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们开始构建LeNet-5模型吧！</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="9e18" class="ls lt jg mv b gy mz na l nb nc">model2 = Sequential()<br/><br/><em class="lr"># LeNet-5 conv-net architecture</em><br/>model2.add(Conv2D(filters=6, kernel_size=(5,5), strides=(1,1), activation='tanh', input_shape=(69,69,3)))<br/>model2.add(AveragePooling2D(pool_size=(2,2), strides=(2,2)))<br/>model2.add(Conv2D(filters=16, kernel_size=(5,5), strides=(1,1), activation='tanh'))<br/>model2.add(AveragePooling2D(pool_size=(2,2), strides=(2,2)))<br/><br/>model2.add(Flatten())<br/>model2.add(Dense(units=120, activation='tanh'))<br/>model2.add(Dense(units=84, activation='tanh'))<br/>model2.add(Dense(units=10, activation='softmax'))<br/><br/>model_optimizer = Adam(lr=0.001)<br/><br/>reduceLR = ReduceLROnPlateau(monitor='accuracy', factor=.001, patience=1, min_delta=0.01, mode="auto")<br/><br/>model2.compile(optimizer=model_optimizer, loss='sparse_categorical_crossentropy', metrics=["accuracy"])<br/>model2.fit(x_train, y_train, epochs=10, callbacks=[reduceLR])</span></pre><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nj"><img src="../Images/51d197a2af6852c093430d904b1dc028.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MuLcTOpWrtjHzHfKS-2c3A.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">上面代码的输出。图片由作者提供。</p></figure><p id="d808" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">90%的准确率！这不完全是机器学习的圣杯，但也是一个相当不错的分数。现在，让我们看看LeNet-5模型的预测。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="7bd8" class="ls lt jg mv b gy mz na l nb nc">predict = model2.predict(x_test).argmax(axis=1)<br/><br/>for i <strong class="mv jh">in</strong> range(10):<br/>    print("Actual:", features[y_test[i]])<br/>    print("Prediction:", features[np.argmax(predict[i])])<br/>    print("-----")<br/>    print()</span></pre><figure class="mq mr ms mt gt is gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/f72da0954329ac2845043dc4584dd1d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*hKbETLMxTklSkSoAgdEF4A.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">上面代码的输出。图片由作者提供。</p></figure><p id="43be" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">看起来一些星系等级被其他的混淆了。即使是人类也很难正确地对每一类图像进行分类。为了更好地理解所犯的错误，使用混淆矩阵是有帮助的。我们还会在这里看一下分类报告。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="ae2f" class="ls lt jg mv b gy mz na l nb nc">classification_report(y_test, predict)</span></pre><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nl"><img src="../Images/5f6a81094597816d0abe4f27bedbda3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*sqGvMVX0cH7Rz8WtL84M6A.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">上面代码的输出。图片由作者提供。</p></figure><p id="ac93" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从这个报告中，我们可以看出，我们的模型对于分类0、1、2、4(特别是1和2)具有很高的精度和召回率。请注意，类1和类2也有最多的训练和测试样本。另一方面，对于只有6个测试样本的类别5，该模型具有非常低的精度和召回率(0)。绘制混淆矩阵将进一步明确这6个测试样本的预测结果。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="c549" class="ls lt jg mv b gy mz na l nb nc">matrix = confusion_matrix(y_test, predict)<br/>sns.heatmap(matrix, annot=True)<br/>plt.title('Galaxy Confusion Matrix')<br/>plt.xlabel('Predicted class')<br/>plt.ylabel('True class')</span></pre><figure class="mq mr ms mt gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/00ea889a3ced621da777ac2361203e8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZRkcErAyU3gbwlSJROrZlA.png"/></div></div></figure><p id="a1a9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该模型很好地预测了1类和2类图像！这并不奇怪，因为它们是样本最多的类。0和4也做得不算太差。我们的模型一贯混淆类别0和类别7 (76个样本)，类别1和类别2也经常被预测为类别0。此外，该模型在分类第8类时存在问题，经常将其误认为第0类和第7类。让我们调查一下。8类是盘面，正面，中螺旋，0类是盘面，正面，无螺旋，7类是盘面，正面，紧螺旋。看看上面的图像，很容易看出为什么这些图像看起来非常相似。</p><h2 id="e0d9" class="ls lt jg bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">结论</h2><p id="284d" class="pw-post-body-paragraph kv kw jg kx b ky ml kh la lb mm kk ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">这是一个有趣的数据集！当我找到它并检查图像时，作为一个人，我很难辨别不同星系类别之间的差异，因为它们具有高度相似的特征，所以我很想看看机器学习模型与人类相比表现如何。我做的一些最初的假设是正确的:我相信这个模型在螺旋上有最大的困难，其他的有点偏离。我曾认为该模型会更频繁地混淆类别1和类别2(平滑、完全圆形和平滑、圆形之间),因为这些类别在一些图像中看起来也非常相似。经过训练后，我认为模型能够很好地区分两个类别，是因为每个类别都有大量的图像可供训练。</p><p id="d3b1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其他要注意的事情:准确性并不总是评估你的模型的最佳指标，也是LeNet-5的一个旁注；LeNet-5虽然它的体系结构可能相对较老，但它在这个数据集上的表现并不太差。</p></div></div>    
</body>
</html>