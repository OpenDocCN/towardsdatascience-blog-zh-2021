<html>
<head>
<title>Convert a Tensorflow2 model to OpenVINO®</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将Tensorflow2模型转换为OpenVINO</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convert-a-tensorflow2-model-to-openvino-c498f526c60b?source=collection_archive---------19-----------------------#2021-05-05">https://towardsdatascience.com/convert-a-tensorflow2-model-to-openvino-c498f526c60b?source=collection_archive---------19-----------------------#2021-05-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/3a00a00fccbdab6721625093b0583eea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gQyQ-xoZWCZicgqCwtLZ2g.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">装有无数芯片神经计算棒2。图片作者。</p></figure><div class=""/><div class=""><h2 id="61b4" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">在任何地方运行您的模型的简要指南</h2></div><p id="7707" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">如今，机器学习的应用层出不穷。那里有已经训练好的模型和只需要拟合的数据。</p><p id="ca77" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">当一个人处理机器学习应用程序时，通常很难决定哪个硬件训练模型并卸载推理。</p><p id="5162" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">英特尔推出了openVINO，帮助将模型(主要与计算机视觉相关)部署到任何英特尔设备，无论它们是CPU、GPU、FPGAs还是带有无数芯片的神经计算棒。</p><div class="ip iq gp gr ir lq"><a href="https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jg gy z fp lv fr fs lw fu fw je bi translated">英特尔发布OpenVINO工具包</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">在跨英特尔硬件的应用中模拟人类视觉，并扩展工作负载和最大化性能。</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">software.intel.com</p></div></div><div class="lz l"><div class="ma l mb mc md lz me ix lq"/></div></div></a></div><p id="9ecf" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这项技术的一个常见用途是使用openVINO进行<strong class="kw jg">快速</strong>推理(即从网络摄像头预测视频中的实时对象)。一些模型需要一个强大的硬件来训练，但是一个更小更便宜的硬件来执行推理就足够了。例如，你可以使用一个<strong class="kw jg">复杂的</strong>预训练模型，然后在<a class="ae mf" rel="noopener" target="_blank" href="/a-live-ai-web-server-with-intel-ncs-and-a-raspberrypi-9831dce859e6"> <strong class="kw jg">轻型</strong>硬件上运行它，就像一个RaspberryPi </a>。</p><p id="3eed" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">OpenVINO是一个强大的工具，但它需要一些段落才能正常工作。我们将经历转换模型的过程，将它加载到推理引擎插件中并执行推理。</p><h1 id="0030" class="mg mh jf bd mi mj mk ml mm mn mo mp mq kl mr km ms ko mt kp mu kr mv ks mw mx bi translated">定制模型</h1><p id="a962" class="pw-post-body-paragraph ku kv jf kw b kx my kg kz la mz kj lc ld na lf lg lh nb lj lk ll nc ln lo lp ij bi translated">英特尔框架有一个<a class="ae mf" href="https://github.com/openvinotoolkit/open_model_zoo" rel="noopener ugc nofollow" target="_blank">集合</a>可以使用的预训练和优化模型。但是如果你想训练一个定制模型呢？</p><p id="15bf" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们将考虑使用<strong class="kw jg"> Tensorflow </strong>进行模型训练，即使openVINO支持许多其他框架。步骤大多相似。</p><p id="3be2" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我会用Google Colab来描述这一切，它应该很容易被复制。</p><h2 id="6941" class="nd mh jf bd mi ne nf dn mm ng nh dp mq ld ni nj ms lh nk nl mu ll nm nn mw no bi translated">在Colab上下载OpenVINO</h2><p id="d47d" class="pw-post-body-paragraph ku kv jf kw b kx my kg kz la mz kj lc ld na lf lg lh nb lj lk ll nc ln lo lp ij bi translated">首先，我们需要下载openVINO repository，安装Tensorflow的先决条件。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="894a" class="nd mh jf nu b gy ny nz l oa ob">!git clone https://github.com/openvinotoolkit/openvino</span><span id="4c1f" class="nd mh jf nu b gy oc nz l oa ob">!cd openvino/model-optimizer/install_prerequisites/ &amp;&amp; ./install_prerequisites.sh tf2</span></pre><h2 id="303e" class="nd mh jf bd mi ne nf dn mm ng nh dp mq ld ni nj ms lh nk nl mu ll nm nn mw no bi translated">你习惯使用keras吗</h2><p id="1c34" class="pw-post-body-paragraph ku kv jf kw b kx my kg kz la mz kj lc ld na lf lg lh nb lj lk ll nc ln lo lp ij bi translated">在这一步你可以做任何你想做的事情。创建一个定制<strong class="kw jg"> keras </strong>模型，带有定制<strong class="kw jg">层</strong>。<strong class="kw jg">编译</strong>它。<strong class="kw jg">在<em class="od">任何</em>数据集上训练</strong>它等等。</p><p id="b825" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">当你对你的训练感到满意时，你可以准备将模型加载到<em class="od">推理机</em>插件中。那么该模型可以用于任何类型设备上的推理。</p><h2 id="254a" class="nd mh jf bd mi ne nf dn mm ng nh dp mq ld ni nj ms lh nk nl mu ll nm nn mw no bi translated">从h5中保存模型</h2><p id="108a" class="pw-post-body-paragraph ku kv jf kw b kx my kg kz la mz kj lc ld na lf lg lh nb lj lk ll nc ln lo lp ij bi translated">第一步是将模型保存到一个<em class="od"> .h5 </em>文件中。使用keras API很容易做到这一点。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="6ec6" class="nd mh jf nu b gy ny nz l oa ob">model = tf.keras.models.load_model(“/content/model.h5”)</span><span id="7416" class="nd mh jf nu b gy oc nz l oa ob">tf.saved_model.save(model,’model’)</span></pre><h2 id="0130" class="nd mh jf bd mi ne nf dn mm ng nh dp mq ld ni nj ms lh nk nl mu ll nm nn mw no bi translated">转换模型</h2><p id="9995" class="pw-post-body-paragraph ku kv jf kw b kx my kg kz la mz kj lc ld na lf lg lh nb lj lk ll nc ln lo lp ij bi translated">模型需要被转换成推理机可以加载到设备中进行推理的表示。这个步骤可以使用所谓的<em class="od">模型优化器</em>来完成，如下所示。</p><p id="0764" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">模型优化器需要输入一些参数，比如<em class="od"> input_shape。</em></p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="c51f" class="nd mh jf nu b gy ny nz l oa ob">python3 openvino/model-optimizer/mo_tf.py --saved_model_dir model/ --input_shape=\[1,28,28\]</span></pre><p id="6cc7" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">此时，您应该有两个文件<em class="od"> model.xml </em>和<em class="od"> model.bin </em>，它们包含对您的定制模型执行推理所需的所有信息。</p><h2 id="f60d" class="nd mh jf bd mi ne nf dn mm ng nh dp mq ld ni nj ms lh nk nl mu ll nm nn mw no bi translated">例子</h2><p id="f9a3" class="pw-post-body-paragraph ku kv jf kw b kx my kg kz la mz kj lc ld na lf lg lh nb lj lk ll nc ln lo lp ij bi translated">以下笔记本中提供了此转换步骤的示例:</p><div class="ip iq gp gr ir lq"><a href="https://colab.research.google.com/drive/1wiFilpyXv947kLOqFJh_oqEp2224y8IL?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jg gy z fp lv fr fs lw fu fw je bi translated">谷歌联合实验室</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">编辑描述</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">colab.research.google.com</p></div></div><div class="lz l"><div class="oe l mb mc md lz me ix lq"/></div></div></a></div><h1 id="bff6" class="mg mh jf bd mi mj mk ml mm mn mo mp mq kl mr km ms ko mt kp mu kr mv ks mw mx bi translated">执行模型</h1><p id="52e1" class="pw-post-body-paragraph ku kv jf kw b kx my kg kz la mz kj lc ld na lf lg lh nb lj lk ll nc ln lo lp ij bi translated">当转换后的模型准备好了，下一步就是使用它进行推理。这可以在任何支持的设备上完成。没有必要使用与您执行培训时相同的设备。</p><h2 id="f4db" class="nd mh jf bd mi ne nf dn mm ng nh dp mq ld ni nj ms lh nk nl mu ll nm nn mw no bi translated">安装openVINO进行推理</h2><p id="cba0" class="pw-post-body-paragraph ku kv jf kw b kx my kg kz la mz kj lc ld na lf lg lh nb lj lk ll nc ln lo lp ij bi translated">为了运行推理，有必要安装openVINO框架。这可以通过pip轻松完成。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="54fa" class="nd mh jf nu b gy ny nz l oa ob">!pip install --upgrade pip<br/>!pip install openvino</span></pre><h2 id="81f8" class="nd mh jf bd mi ne nf dn mm ng nh dp mq ld ni nj ms lh nk nl mu ll nm nn mw no bi translated">将模型加载到插件中</h2><p id="56be" class="pw-post-body-paragraph ku kv jf kw b kx my kg kz la mz kj lc ld na lf lg lh nb lj lk ll nc ln lo lp ij bi translated">我们需要将模型加载到设备上进行推理。</p><p id="2d59" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><em class="od">推理引擎核心</em>对象具有读取<em class="od">的能力。xml </em>和<em class="od">。将</em>绑定到<strong class="kw jg">网络</strong>对象中。</p><p id="7845" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这个网络可以加载到任何<strong class="kw jg">设备</strong>中，无论是CPU、GPU还是MYRIAD。这是这个API的强大之处之一，它可以毫不费力地在任何设备上透明运行。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="d619" class="nd mh jf nu b gy ny nz l oa ob">from openvino.inference_engine import IECore, IENetwork</span><span id="db47" class="nd mh jf nu b gy oc nz l oa ob">ie = IECore()</span><span id="1aef" class="nd mh jf nu b gy oc nz l oa ob">net =  ie.read_network(model=model_xml, weights=model_bin)</span><span id="d43c" class="nd mh jf nu b gy oc nz l oa ob">exec_net =  ie.load_network(network=net, device_name="MYRIAD")</span></pre><h2 id="f70e" class="nd mh jf bd mi ne nf dn mm ng nh dp mq ld ni nj ms lh nk nl mu ll nm nn mw no bi translated">获取关于拓扑的信息</h2><p id="3c73" class="pw-post-body-paragraph ku kv jf kw b kx my kg kz la mz kj lc ld na lf lg lh nb lj lk ll nc ln lo lp ij bi translated">我们可以检查网络拓扑。这个API只支持单个输入，无论如何，如果你在一个视频上运行这个，你需要一次对一个帧进行推理，所以这不是一个大问题。</p><p id="d176" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">此外，我们可以检查输入或输出形状，这对于由其他人训练的模型特别有用。我们需要确保数据处于正确的状态。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="0f86" class="nd mh jf nu b gy ny nz l oa ob">assert len(net.input_info.keys()) == 1, "Sample supports only single input topologies"</span><span id="934e" class="nd mh jf nu b gy oc nz l oa ob">assert len(net.outputs) == 1, "Sample supports only single output topologies"</span><span id="bc06" class="nd mh jf nu b gy oc nz l oa ob">input_blob = next(iter(net.input_info.keys()))<br/></span><span id="916b" class="nd mh jf nu b gy oc nz l oa ob">out_blob = next(iter(net.outputs))</span><span id="1c3d" class="nd mh jf nu b gy oc nz l oa ob">net.batch_size = len([0])</span><span id="9e80" class="nd mh jf nu b gy oc nz l oa ob">net.input_info[input_blob].input_data.shape</span></pre><h1 id="d9ce" class="mg mh jf bd mi mj mk ml mm mn mo mp mq kl mr km ms ko mt kp mu kr mv ks mw mx bi translated">推理</h1><p id="eddd" class="pw-post-body-paragraph ku kv jf kw b kx my kg kz la mz kj lc ld na lf lg lh nb lj lk ll nc ln lo lp ij bi translated">最后，是进行推理的时候了。给定一个对象<em class="od"> X_test[0] </em>我们准备在网络上使用infer方法来推断它。</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="c535" class="nd mh jf nu b gy ny nz l oa ob">res = exec_net.infer(inputs={input_blob: X_test[0]})</span><span id="1cc3" class="nd mh jf nu b gy oc nz l oa ob">res[out_blob].reshape(1,10)</span></pre><h1 id="b67b" class="mg mh jf bd mi mj mk ml mm mn mo mp mq kl mr km ms ko mt kp mu kr mv ks mw mx bi translated">结论</h1><p id="5460" class="pw-post-body-paragraph ku kv jf kw b kx my kg kz la mz kj lc ld na lf lg lh nb lj lk ll nc ln lo lp ij bi translated">我们训练了一个定制模型。</p><p id="45b3" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">使用openVINO <em class="od">模型优化器</em>，我们<strong class="kw jg">将</strong>转换成将模型加载到推理引擎模块所需的新表示。</p><p id="794a" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">当训练好的模型准备好使用推理机来<strong class="kw jg">推断</strong>输入数据时，它几乎是微不足道的。另外，这可以在任何设备上进行。</p></div></div>    
</body>
</html>