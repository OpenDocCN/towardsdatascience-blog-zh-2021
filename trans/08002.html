<html>
<head>
<title>Machine Learning Use Case: Classifying Ways to Wear a Face Mask</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习用例:对佩戴口罩的方式进行分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-use-case-classifying-ways-to-wear-a-face-mask-f90af8562530?source=collection_archive---------25-----------------------#2021-07-22">https://towardsdatascience.com/machine-learning-use-case-classifying-ways-to-wear-a-face-mask-f90af8562530?source=collection_archive---------25-----------------------#2021-07-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/2e1087f7a38a1d6a81694fc0e654536c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iVBGGxrEZ83aNg6FeaOwDA.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">新冠肺炎期间，街上的人们戴着口罩——图片来源。</p></figure><p id="4d77" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">无论您是在医疗行业、工业环境中佩戴面罩或呼吸器，还是作为公众中的一员，面罩的使用和正确放置对于最大程度的保护至关重要。</p><p id="9cdb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，随着新冠肺炎的传播，许多地方(如机场、工作场所等。)要求戴上面罩，并将其正确放置在鼻子和嘴上。为了帮助检测和执行这些要求，我们开始在PerceptiLabs中建立一个图像识别模型，该模型可以对人们佩戴面具的不同方式进行分类。然后，像这样的模型可以用于检查站、入口和其他位置，以帮助工作人员或当局识别不遵守其组织的口罩佩戴规则的个人。</p><p id="2d60" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">数据集</strong></p><p id="cf0d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了训练我们的模型，我们获取了<a class="ae kc" href="https://ieee-dataport.org/open-access/ways-wear-mask-or-respirator-wwmr-db" rel="noopener ugc nofollow" target="_blank">佩戴口罩或呼吸器的方式数据库(WWMR-DB) </a>，其中包含了佩戴口罩的人的图像，如图1所示。</p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lb"><img src="../Images/cc1d76ad67fc0a97220b631c8518f93e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cGi8q5Q6DkYVi9LQ3aKsCg.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><em class="lg">图1:来自数据集的图像示例—图像</em> <a class="ae kc" href="https://ieee-dataport.org/open-access/ways-wear-mask-or-respirator-wwmr-db" rel="noopener ugc nofollow" target="_blank"> <em class="lg">来源</em> </a> <em class="lg">。</em></p></figure><p id="5d55" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据集包括。jpg图片分为八类，描绘了最常见的佩戴口罩或呼吸器的方式。</p><p id="12c2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据戴面具的人，原始数据集被分成一系列子目录。为了使事情变得更顺利并与PerceptiLabs兼容，我们通过创建对应于八个分类的八个子目录来简化这一点，然后将适当的图像移动到相应的子目录中。然后，使用PerceptiLabs的<a class="ae kc" href="https://docs.perceptilabs.com/perceptilabs/references/ui-overview/data-wizard" rel="noopener ugc nofollow" target="_blank">数据向导</a>中的调整大小功能，将每个图像调整为224x224像素。</p><p id="07fe" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了将分类映射到图像，我们创建了一个. csv文件(<em class="lh"> mask_log.csv </em>)，该文件将每个图像文件与一个数字标签相关联，以便使用PerceptiLabs的数据向导加载数据:</p><blockquote class="li lj lk"><p id="c4b8" class="kd ke lh kf b kg kh ki kj kk kl km kn ll kp kq kr lm kt ku kv ln kx ky kz la ij bi translated">0:下巴上方的遮罩</p><p id="987b" class="kd ke lh kf b kg kh ki kj kk kl km kn ll kp kq kr lm kt ku kv ln kx ky kz la ij bi translated">1:正确佩戴面罩</p><p id="5991" class="kd ke lh kf b kg kh ki kj kk kl km kn ll kp kq kr lm kt ku kv ln kx ky kz la ij bi translated">2:面具挂在佩戴者的耳朵上</p><p id="1e33" class="kd ke lh kf b kg kh ki kj kk kl km kn ll kp kq kr lm kt ku kv ln kx ky kz la ij bi translated">3:没有戴口罩</p><p id="53f4" class="kd ke lh kf b kg kh ki kj kk kl km kn ll kp kq kr lm kt ku kv ln kx ky kz la ij bi translated">4:额头上的面具</p><p id="af51" class="kd ke lh kf b kg kh ki kj kk kl km kn ll kp kq kr lm kt ku kv ln kx ky kz la ij bi translated">5:鼻尖上的面具</p><p id="a668" class="kd ke lh kf b kg kh ki kj kk kl km kn ll kp kq kr lm kt ku kv ln kx ky kz la ij bi translated">6:下巴下的面膜</p><p id="128e" class="kd ke lh kf b kg kh ki kj kk kl km kn ll kp kq kr lm kt ku kv ln kx ky kz la ij bi translated">7:鼻下面具</p></blockquote><p id="415e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是一个部分的例子。csv文件看起来:</p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lo"><img src="../Images/1d484250ee8c70c1b69b467ca22d46ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xm1fMGajxfq0EJQli8AxBQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><em class="lg">的例子。csv文件，用于将数据加载到将图像文件映射到其关联标签的PerceptiLabs中。</em></p></figure><p id="5102" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">车型总结</strong></p><p id="60a1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的模型仅由三个组件组成:</p><p id="6e62" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">组件1: <a class="ae kc" href="https://keras.io/api/applications/inceptionv3/" rel="noopener ugc nofollow" target="_blank"> InceptionV3 </a>，include_top=no</p><p id="c3e4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">成分2:密集，激活= <a class="ae kc" href="https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank"> ReLU </a>，神经元=128</p><p id="4830" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">组件3:密集，激活= <a class="ae kc" href="https://en.wikipedia.org/wiki/Softmax_function" rel="noopener ugc nofollow" target="_blank"> Softmax </a>，神经元=8</p><p id="b136" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意，尽管InceptionV3要求图像为229x229像素，但是将<strong class="kf ir"> include_top </strong>设置为<strong class="kf ir"> no，</strong>允许使用其他尺寸的图像(例如，224x224像素)。</p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lp"><img src="../Images/a88c44c38fc97b174832f68889084054.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yH8f-TNX7jXKTT5OgpMVMA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><em class="lg">图2:感知实验室中模型的拓扑结构-图像</em> <a class="ae kc" href="http://www.perceptilabs.com" rel="noopener ugc nofollow" target="_blank"> <em class="lg">来源</em> </a> <em class="lg">。</em></p></figure><p id="cbfc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">训练和结果</strong></p><p id="35f6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">我们用32个</strong>批量20个历元训练模型，使用<a class="ae kc" href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/#:~:text=Adam%20is%20a%20replacement%20optimization,sparse%20gradients%20on%20noisy%20problems." rel="noopener ugc nofollow" target="_blank"> ADAM </a>优化器，学习率0.001，交叉熵<a class="ae kc" href="https://blog.perceptilabs.com/choosing-and-customizing-loss-functions-for-image-processing/" rel="noopener ugc nofollow" target="_blank">损失</a>函数。图3显示了训练期间PerceptiLabs的统计视图。</p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/4ca821010dd042403c6c2df989793c96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hVdICTQn_3l2w1CVM0ZecA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><em class="lg">图3: PerceptiLabs在训练时的统计视图—图片</em> <a class="ae kc" href="http://www.perceptilabs.com" rel="noopener ugc nofollow" target="_blank"> <em class="lg">来源</em> </a> <em class="lg">。</em></p></figure><p id="db6d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在大约34分28秒的训练时间内，<strong class="kf ir">我们能够实现99.4%的训练准确率和77.1%的验证准确率。</strong>较低的验证精度反映了在面部检测相关数据上训练模型的难度</p><p id="87f2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下面来自PerceptiLabs的屏幕截图(图4)中，您可以看到在前六个左右的时期中，训练验证准确性如何上升，之后它保持相当稳定。在最初的几个时期，训练大部分是上升的，并且在稳定下来之前波动，直到第14个时期左右:</p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lr"><img src="../Images/a97e4835aac26a86f0c8cf4987e4698c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*l_WFs1qFWnm5fhjd"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><em class="lg">图4:精度图。</em></p></figure><p id="7904" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图5中的截屏显示了前14个时期在训练和验证过程中的相应损失:</p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lr"><img src="../Images/c1605eeff226369521b76da68f99c51f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Lw3gnb40MoVd-56f"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><em class="lg">图5:损失图。</em></p></figure><p id="7ae0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里我们可以看到，在稳定之前的第一个时期，训练损失显著下降，而验证损失开始较低，并始终保持相对稳定。</p><p id="a02b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">垂直应用</strong></p><p id="8044" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">像这样的模型可以用于安全或健康和安全目的，以确保工人或游客有一个面具，并在进入前正确佩戴。例如，该模型可用于分析通过现场安全摄像头获取的照片或视频帧。该模型本身也可用作<a class="ae kc" href="https://blog.perceptilabs.com/when-to-use-transfer-learning-in-image-processing/" rel="noopener ugc nofollow" target="_blank">转移学习</a>的基础，以创建用于检测其他类型健康或安全设备的存在和正确使用的附加模型。</p><p id="4930" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">总结</strong></p><p id="e0d9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此使用案例是如何使用图像识别来帮助确保健康和安全的示例。如果你想建立一个类似这样的深度学习模型，<a class="ae kc" href="https://docs.perceptilabs.com/perceptilabs/getting-started/quickstart-guide" rel="noopener ugc nofollow" target="_blank">运行PerceptiLabs </a>并获取我们的。来自<a class="ae kc" href="https://github.com/PerceptiLabs/Ways-to-Wear-a-Face-Mask" rel="noopener ugc nofollow" target="_blank"> GitHub </a>的csv文件。</p></div></div>    
</body>
</html>