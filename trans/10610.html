<html>
<head>
<title>Tesla AI Day 2021 Review — Part 3: Project Dojo. Tesla’s New Supercomputer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">特斯拉人工智能日2021回顾-第3部分:项目道场。特斯拉的新超级计算机</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tesla-ai-day-2021-review-part-3-project-dojo-teslas-new-supercomputer-715d102dbb29?source=collection_archive---------17-----------------------#2021-10-11">https://towardsdatascience.com/tesla-ai-day-2021-review-part-3-project-dojo-teslas-new-supercomputer-715d102dbb29?source=collection_archive---------17-----------------------#2021-10-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="7566" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">人工智能|新闻</h2><div class=""/><div class=""><h2 id="294c" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">AI专用硬件的出现。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/3d6ea0e59629541304da0d12a7b26659.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HZ3CzfIcmg0HVb0n"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@kelvin1987?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Kelvin Ang </a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="66ff" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">本文是4部分系列的第三部分:</p><blockquote class="me mf mg"><p id="9904" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated">1.<a class="ae lh" rel="noopener" target="_blank" href="/tesla-ai-day-2021-review-part-1-the-promise-of-fully-self-driving-cars-8e469265509b">完全自动驾驶汽车的承诺</a></p><p id="8831" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated">2.<a class="ae lh" rel="noopener" target="_blank" href="/tesla-ai-day-2021-review-part-2-training-data-how-does-a-car-learn-e8863ba3f5b0">训练数据。汽车是如何学习的？</a></p><p id="feb4" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated"><strong class="lk jd"> 3。道场项目。特斯拉的新型超级计算机</strong></p><p id="a793" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated">4.<a class="ae lh" rel="noopener" target="_blank" href="/tesla-ai-day-2021-review-part-4-why-tesla-wont-have-an-autonomous-humanoid-robot-in-2022-76dff743f885">为什么特斯拉2022年不会有自主人形机器人</a></p></blockquote></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="0d85" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">GPU的发展</h1><p id="f631" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">早在20世纪70年代和80年代，图形处理器——通常被称为GPU——开始与游戏产业一起出现。在90年代，随着对街机和主机游戏的需求，任天堂、索尼和富士通等公司开始竞相构建改进的3D图形硬件。但直到Nvidia在21世纪初普及了GPU，并在几年后发布了<a class="ae lh" href="https://en.wikipedia.org/wiki/GeForce_8_series" rel="noopener ugc nofollow" target="_blank"> Nvidia GeForce 8系列</a>，它才成为一种通用计算设备，超越了游戏。</p><p id="f25a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如今，GPU在很多领域都有应用。从游戏到线性代数运算和图像处理，再到机器学习等更新颖的应用。2009年，来自斯坦福大学的吴恩达和他的同事发表了一篇开创性的论文，其中他们提出了图形处理器作为克服机器学习模型训练中计算限制的手段:“现代图形处理器远远超过多核CPU的计算能力，并有可能彻底改变深度无监督学习方法的适用性。”</p><p id="a08e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">GPU不再是从属于CPU的特定硬件元素。因此，随着深度学习行业的兴起，公司开始研究特定的计算单元，这些计算单元将利用GPU奠定的基础。2016年，谷歌开创了这一趋势，推出了一款名为<a class="ae lh" href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit" rel="noopener ugc nofollow" target="_blank">张量处理单元(TPU) </a>的新计算单元，专门用于神经网络训练。</p><p id="595a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">随着对高性能硬件的需求不断增加，芯片制造商的数量也在不断增加，以满足越来越大的神经网络的要求。SambaNova成立于2017年，是人工智能专用芯片市场的<a class="ae lh" href="https://www.statista.com/statistics/1104843/top-ai-chip-startups/" rel="noopener ugc nofollow" target="_blank">领导者——甚至与英伟达等公司竞争。他们押注于VentureBeat的Poornima Apte </a><a class="ae lh" href="https://venturebeat.com/2021/08/11/how-sambanova-systems-is-tackling-dataflow-as-a-service/#:~:text=Genesis%20in%20software-driven%20hardware" rel="noopener ugc nofollow" target="_blank">所说的</a>“软件驱动的硬件”他们专注于人工智能系统需要什么，并从那里开始。同一条路上的另一家创业公司Cerebras最近与知名AI公司OpenAI进行了对话。他们想用似乎是“有史以来最大的计算机芯片”来驱动下一代GPT</p><h1 id="988d" class="ms mt it bd mu mv np mx my mz nq nb nc ki nr kj ne kl ns km ng ko nt kp ni nj bi translated">特斯拉转向内部芯片开发</h1><p id="f6c6" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">2021年6月，安德烈·卡帕西(Andrej Karpathy)发表了一篇关于特斯拉走向完全自动驾驶汽车的战略的演讲。他详细介绍了他们最新和最大的用于神经网络训练和测试的集群的规格(他们总共有三个集群)。该集群由720个节点组成，每个节点由8个Nvidia A100 GPUs组成，在FP16上总共可实现1.8 EFLOPs就FLOPs而言，它将在世界超级计算机中排名第五。</p><p id="a6ca" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">到目前为止，特斯拉一直都是这样。一方面，他们不想再依赖其他公司的芯片，另一方面，英伟达GPU不是专门为处理机器学习训练而设计的，这使得它们对于这项任务来说相对低效——GPU是最佳选择，直到人工智能行业发展到构建特定硬件变得有利可图。</p><p id="75bb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">特斯拉决定跟随潮流，开始制造他们的芯片，并最终制造出一台超级计算机。遵循垂直整合的原则，他们希望自己设计和制造硬件，于是Dojo项目诞生了。</p><h1 id="d44a" class="ms mt it bd mu mv np mx my mz nq nb nc ki nr kj ne kl ns km ng ko nt kp ni nj bi translated">project Dojo——特斯拉的新超级计算机</h1><p id="320b" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">特斯拉与Dojo的目标是“实现最佳的人工智能训练性能。支持更大更复杂的神经网络模型。高能效和经济高效的计算。”这意味着Dojo不一定要比他们已经拥有的GPU集群更强大或更快。他们也不想让它与最强大的通用超级计算机竞争。主要标准是制造一台比其他任何计算机都更擅长人工智能的计算机——这样他们在未来就再也不需要使用GPU了。</p><p id="1332" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">构建超级计算机时的一个常见因素是如何在扩展计算能力(容易)同时保持高带宽(困难)和低延迟(非常困难)之间找到一个折中的解决方案。他们在分布式2D架构(一个平面)中找到了答案，该架构由强大的芯片和独特的网络结构组成，允许快速通信、高带宽和低延迟。</p><p id="97a9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">忠于他们的垂直整合原则，他们想自下而上地构建几乎每一层的元素。从包含最小计算元素的训练节点，到D1芯片，到训练瓦片(它们的规模单位)，再到最终将取代其GPU堆栈的ExaPOD集群。在接下来的几节中，我将一个接一个地解释这些组件，并一如既往地提出一些见解:</p><ol class=""><li id="6fba" class="nu nv it lk b ll lm lo lp lr nw lv nx lz ny md nz oa ob oc bi translated">训练节点——规模的最小实体</li><li id="b185" class="nu nv it lk b ll od lo oe lr of lv og lz oh md nz oa ob oc bi translated">D1芯片——可与市面上最好的GPU相媲美</li><li id="8932" class="nu nv it lk b ll od lo oe lr of lv og lz oh md nz oa ob oc bi translated">训练砖——一项伟大的工程</li><li id="11a5" class="nu nv it lk b ll od lo oe lr of lv og lz oh md nz oa ob oc bi translated">exa pod——特斯拉的新超级星团</li><li id="1386" class="nu nv it lk b ll od lo oe lr of lv og lz oh md nz oa ob oc bi translated">洞察力</li></ol></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="e33a" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">训练节点——规模的最小实体</h1><p id="87b3" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">GPU由在整个芯片上复制的更小的元素集组成。这些较小的集合是训练节点。它们包含进行大规模计算所需的不同部分——算术和逻辑单元，以及控制单元、SRAM存储器和其他组件。</p><p id="df6f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Dojo项目主管Ganesh Venkataramanan称训练节点为“规模最小的实体”。它是最小的组件，通过在每个方向放置精确的副本可以进一步扩展。特别是，354个连接的训练节点构成一个芯片，25个连接的芯片构成一个训练片，12个训练片构成一个机柜，10个机柜构成ExaPOD。通过从训练节点一路扩展这些元素，有可能达到EFLOP的计算性能，但要实现这一壮举，需要解决一些限制。</p><p id="0f00" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">特别是，有一个问题是<a class="ae lh" href="https://youtu.be/j0z4FweCy4M?t=6552" rel="noopener ugc nofollow" target="_blank">训练节点</a>的大小是多少。太小会使速度变快，但同步成本太高。太大会使实现变得困难，并且会产生“内存瓶颈”因为他们希望保持低延迟，所以他们设计了测量高时钟周期信号(+2GHz)在1个周期(最低延迟)内可以穿越的最远距离的训练节点，并在其周围画了一个框来定义节点的大小。因为他们想保持高带宽，他们在盒子里放满了“到边缘”的电线</p><p id="aae8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后完成了具有计算元件、内存池和可编程控制核心的<a class="ae lh" href="https://youtu.be/j0z4FweCy4M?t=6589" rel="noopener ugc nofollow" target="_blank">高性能节点</a>。这些特性的组合在BF16时提供1024 GFLOPs的计算能力，在FP32时则降至64 GFLOPs(单精度格式更多用于性能测试)。最后，使这些训练节点能够在不降低性能的情况下进行扩展的是它们被设计成高度模块化。也就是说，它们以这样一种方式连接，即计算能力是恒定的，并且它们形成了一个高吞吐量的通信平面。</p><h1 id="e2dd" class="ms mt it bd mu mv np mx my mz nq nb nc ki nr kj ne kl ns km ng ko nt kp ni nj bi translated">D1芯片——可与市面上最好的GPU相媲美</h1><p id="2de3" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">将354个训练节点放在一起，FP32的计算结果为22.6 TFLOPs为了进行比较，<a class="ae lh" href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet.pdf" rel="noopener ugc nofollow" target="_blank"> Nvidia A100 </a>提供19.5 TFLOPs——每个方向的片上带宽为10 TBps。在这组节点周围，他们放置了一系列高速、低功耗通道，以获得每边4 TBps的片外I/O带宽，这是最先进的网络交换芯片I/O带宽的两倍。所有这些构成了特斯拉的D1芯片。</p><p id="b3b7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">与英伟达A100等其他芯片相比，D1芯片完全是为了训练机器学习模型。其独特的设计提供了“GPU级的计算、CPU级的灵活性以及两倍于网络芯片级的I/O带宽。”<a class="ae lh" href="https://youtu.be/j0z4FweCy4M?t=6828" rel="noopener ugc nofollow" target="_blank">下面是</a>(片外带宽与计算的TFLOPs)与最先进的机器学习芯片的比较，包括谷歌的TPU、现代GPU和启动芯片。</p><p id="d79d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">芯片可以无缝连接，无需胶水，扩展计算能力和各个方向的通信，同时保持芯片之间的最小延迟。设想中的<a class="ae lh" href="https://youtu.be/j0z4FweCy4M?t=6878" rel="noopener ugc nofollow" target="_blank">计算平面</a>包括大约50万个训练节点和1500个d 1芯片。但是他们如何集成芯片来创建这样一个计算平台，并将其与<a class="ae lh" href="https://youtu.be/j0z4FweCy4M?t=6878" rel="noopener ugc nofollow" target="_blank">其余的高级组件</a>——主机系统和接口处理器连接起来呢？</p><h1 id="e704" class="ms mt it bd mu mv np mx my mz nq nb nc ki nr kj ne kl ns km ng ko nt kp ni nj bi translated">训练砖——一项伟大的工程</h1><p id="fe67" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">答案是训练瓷砖。25个D1芯片被集成到一个扇出晶圆工艺中，以保持高带宽。此外，他们在边缘放置连接器，以保留片外I/O带宽。由此产生的组件被称为<a class="ae lh" href="https://youtu.be/j0z4FweCy4M?t=6959" rel="noopener ugc nofollow" target="_blank">训练瓦片</a>，它在BF16提供9 PFLOPs和36 TB/s片外I/O带宽。这也许使训练瓦片成为“芯片工业中最大的有机mcm(多芯片模块)”</p><p id="772e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">他们设计了训练瓦片以满足计算平面上的高带宽和低延迟的标准，但是他们很快意识到他们需要找到新的解决方案来实现其制造。为了给训练瓦片供电，他们创建了一个定制的电压调节器模块，可以直接连接到扇出晶片上。他们还整合了电力、热能和机械部件，创造出一个完全整合的训练瓷砖<a class="ae lh" href="https://youtu.be/j0z4FweCy4M?t=7055" rel="noopener ugc nofollow" target="_blank">。电源和冷却与计算平面正交，允许高性能、高带宽和低延迟。</a></p><p id="c928" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">CleanTechnica的Chanan Bos说,<a class="ae lh" href="https://cleantechnica.com/2021/08/22/teslas-dojo-supercomputer-breaks-all-established-industry-standards-cleantechnica-deep-dive-part-2/#:~:text=What%20Tesla%20is,is%20completely%20unprecedented." rel="noopener ugc nofollow" target="_blank">训练瓷砖违背了“将晶片切割成碎片”的行业趋势。“这完全是前所未有的。”</a></p><h1 id="cdf5" class="ms mt it bd mu mv np mx my mz nq nb nc ki nr kj ne kl ns km ng ko nt kp ni nj bi translated">exa pod——特斯拉的新超级星团</h1><p id="5403" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">为了构建集群，他们只需将瓷砖拼在一起。一个2×3的瓷砖矩阵形成一个托盘，两个托盘一起形成一个橱柜。ExaPOD由10个机柜组成。但是，考虑到高带宽的必要性，他们“打破了机柜的墙壁”，一个接一个地连接托盘，创建了一个“<a class="ae lh" href="https://youtu.be/j0z4FweCy4M?t=7188" rel="noopener ugc nofollow" target="_blank">无缝训练垫</a>。"</p><p id="0006" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">ExaPOD在BF16时提供1.1 EFLOPs(120个训练瓦片、3000个D1芯片和+1M训练节点)，这使得Dojo几乎与Tesla现在用于训练其网络的GPU集群一样强大。由于高度分布式的模块化设计，可以使用Dojo的任何子集——称为DPUs，Dojo处理单元——用于训练目的。</p><p id="7546" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">高带宽低延迟结构使Dojo在相同成本下的性能比任何其他人工智能超级计算机高4倍，同时碳足迹减少5倍，节省更多能源(每W 1.3倍)。</p><p id="2140" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Elon Musk在演示结束时表示，Dojo可能会在明年投入使用。如果这还不够，特斯拉已经想到了下一代计划，据称将比第一代Dojo计算机提供10倍的改进。</p><p id="f5e4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从最高层次来看，Dojo上的演示有两个关键点。首先，在内部构建所有硬件允许特斯拉在训练人工智能模型方面实现无与伦比的性能，并允许完全垂直集成。其次，将所有组件设计为高度模块化有助于保持非常高的带宽和非常低的延迟，这是实现这种性能改进的两个要求。特斯拉再次承诺大，让我们看看他们能提供什么。</p><h1 id="9992" class="ms mt it bd mu mv np mx my mz nq nb nc ki nr kj ne kl ns km ng ko nt kp ni nj bi translated">洞察力</h1><h2 id="c614" class="oi mt it bd mu oj ok dn my ol om dp nc lr on oo ne lv op oq ng lz or os ni iz bi translated"><strong class="ak">公平的比较</strong></h2><p id="4aec" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">【TOP500强项目每年两次展示世界上最强大的非分布式超级计算机。今年6月刊将第一名让给了日本的<a class="ae lh" href="https://en.wikipedia.org/wiki/Fugaku_(supercomputer)" rel="noopener ugc nofollow" target="_blank"> Fugaku </a>，它达到了每秒442.01 PFLOPs。如果我们将ExaPOD的1.1 EFLOPs性能与此进行比较，我们肯定会得出结论，特斯拉不仅要建造世界上最快的超级计算机，而且它的功能将是目前排名第一的两倍。</p><p id="589a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Dojo不会加冕最快超级计算机的原因有两个。首先，入选500强的高性能计算机(HPC)必须能够执行许多不同的任务。Dojo的特殊性<a class="ae lh" href="https://www.techrepublic.com/article/teslas-dojo-is-impressive-but-it-wont-transform-supercomputing/#:~:text=Dojo%27s%20reported%20capabilities%20don%27t%20grant%20it%20true%20high-performance%20computer%20(HPC)%20status%2C%20said%20Gartner%20research%20vice%20president%20Chirag%20Dekate%2C%20largely%20because%20it%20hasn%27t%20been%20tested%20using%20the%20same%20standards%20as%20Fugaku%20and%20other%20supercomputers.%C2%A0" rel="noopener ugc nofollow" target="_blank">阻止了它</a>获得HPC的资格。</p><p id="aa15" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第二，HPC的性能测试是在单精度或双精度格式上进行的。也就是FP64或者FP32。Dojo在BF16实现1.1 EFLOPs(脑浮点格式16。“Brain”是Google Brain)，它计算的<a class="ae lh" href="https://moocaholic.medium.com/fp64-fp32-fp16-bfloat16-tf32-and-other-members-of-the-zoo-a1ca7897d407#:~:text=The%20bfloat16%20format%2C%20being%20a%20truncated%20IEEE%20754%20FP32" rel="noopener">是FP32 </a>的一半位数。而且它不支持FP64，而FP64是最苛刻的科学计算所需要的。</p><p id="dbe9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，为了便于说明，我们可以计算Dojo每秒可以进行多少次计算。因为Tesla公开了D1芯片在BF16和FP32上的性能，所以可以进行转换来计算Dojo在FP32上的计算能力。(这一过程并不完全正确，因为我们不能简单地从芯片到集群线性扩展性能，但它有助于我们进行粗略的比较。)</p><p id="d934" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">D1芯片在FP32时提供22.6 TFLOPs，在BF16时提供362 TFLOPs。在BF16时，ExaPOD的运算速度为1.1 EFLOPs。计算一下:Dojo在FP32时的性能= 1.1 EFLOPs(BF16)/362 TFLOPs(BF16)22.6 TFLOPs(FP32)= 68.67 PFLOPs。如果我们假设计算足够准确，那么Dojo的功能略低于Tesla当前使用的集群，后者提供了<a class="ae lh" href="https://cleantechnica.com/2021/08/22/teslas-dojo-supercomputer-breaks-all-established-industry-standards-cleantechnica-deep-dive-part-1/#:~:text=Considering%20the%20components,around%2090%20PetaFLOP" rel="noopener ugc nofollow" target="_blank"> ~90 PFLOPs </a>。</p><p id="4354" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">无论如何，Dojo在成本和污染方面效率更高，而且在人工智能训练方面，很长一段时间内没有计算机能打败Dojo。</p><h2 id="39dc" class="oi mt it bd mu oj ok dn my ol om dp nc lr on oo ne lv op oq ng lz or os ni iz bi translated">独特的设计</h2><p id="9845" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">为了创造一个完全符合人工智能系统需求的系统，特斯拉工程师需要打破一些规则，在行业标准方面进行一些创新。Bos在这里对这个话题<a class="ae lh" href="https://cleantechnica.com/2021/08/22/teslas-dojo-supercomputer-breaks-all-established-industry-standards-cleantechnica-deep-dive-part-1/" rel="noopener ugc nofollow" target="_blank">有一个非常透彻的回顾。</a></p><p id="3cd9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">特斯拉的D1芯片是一种“片上系统”，简称SoC。作为SoC的芯片包括高速缓冲存储器、处理器、图形卡和集成在其中的其他组件。现在大部分芯片都是这样设计的。然而，在D1芯片和其他类似的芯片之间，以及在训练瓦片和其他MCM之间有一些重要的区别。</p><p id="20e1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">任何计算硬件专家都会意识到的第一件事是，特斯拉承诺在训练瓷砖中达到的性能水平通常无法完全确定地事先定义。原因是芯片通常集成到训练瓦片中的方式。</p><p id="2433" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">芯片不是由一个个的组件组装而成的。取而代之的是，芯片的元件被集成到一个细长的圆形高质量硅晶片上，称为晶片。然后，该晶片被分解成组成处理器(GPU、SOC等)的多个部分。</p><p id="e448" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在破碎晶片的过程中，一些芯片可能会变得部分无用。这就是为什么特斯拉能够承诺从训练瓷砖获得完美的性能是不寻常的(按照行业标准，这将是一块破碎的晶片)。当芯片有时不能按预期工作时，他们如何确保25个D1芯片在训练瓷砖中完全正常工作？</p><p id="8901" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">有两种可能。特斯拉的工程师可能已经找到了一种方法，当从更大的晶片中提取芯片时，可以确保D1芯片的5×5网格完美工作。另一种选择是，训练瓦片本身是整个晶片。无论如何，这都是突破性的创新，因为通过这样做，他们可以从D1芯片的设计中保证ExaPOD的性能。</p><p id="483b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第二个很大的区别是，计算机总是在芯片之外有一个RAM(随机存取存储器)组件，但Dojo没有。RAM有两种类型:SRAM(静态RAM，例如，高速缓冲存储器是SRAM)和DRAM(动态RAM)。SRAM的主要优点是存取速度更快，能耗更低。另一方面，DRAM的密度更大，因此在同样的空间里可以容纳更多的数据。两者通常都是必要的，但特斯拉设计了Dojo，所以它不需要DRAM。</p><p id="edaa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">每个训练节点有1.25 MB的SRAM。Bos认为，它可能是速度更快的SRAM类型之一，L2缓存，其响应时间为3-4 ns(相比之下，DRAM的响应时间为60 ns)。通过在每个D1芯片中放置354个训练节点，它相当于每个芯片442.5 MB的缓存，这比其他任何芯片都多。</p><p id="3472" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，我们在这里得到的是一个D1芯片，它有足够的SRAM，既不需要外部DRAM也不需要共享缓存。Bos说:“虽然设计听起来很奇怪，但你通常期望在SoC中找到的缺失组件可能是不必要的。”“这是一个非常特殊的系统，针对非常特殊的任务进行了微调，而大多数处理器都有更广泛的组件，可以更加灵活地适应各种任务。”</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><p id="6410" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">作为结束部分，我想强调Dojo的重要性，不仅因为它在创新和性能方面的突破性规格，还因为Musk说他们将允许其他公司在未来访问Dojo来训练他们的神经网络。</p><p id="cd35" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当一名用户问他是否曾将Dojo视为一种机器学习培训服务时，马斯克的回答很简单:“是的。”</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="8c03" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这不仅仅是训练与车辆自动驾驶相关的网络，而是"<a class="ae lh" href="https://twitter.com/flcnhvy/status/1307829022332719104" rel="noopener ugc nofollow" target="_blank">几乎任何机器学习</a>"</p><p id="7a33" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">尽管特斯拉没有取得任何重大的理论突破，比如OpenAI或deep mind——目前没有人可以将他们发明或设计的东西用于研究目的——但很明显他们正在努力押注人工智能的适用性。最终结果如何还不得而知，但值得关注。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><p id="c53a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="mh">如果你喜欢这篇文章，可以考虑订阅我的免费每周简讯</em><a class="ae lh" href="https://mindsoftomorrow.ck.page" rel="noopener ugc nofollow" target="_blank"><em class="mh"/></a><em class="mh">！每周都有关于人工智能的新闻、研究和见解！</em></p><p id="334c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="mh">您也可以直接支持我的工作，使用我的推荐链接</em> <a class="ae lh" href="https://albertoromgar.medium.com/membership" rel="noopener"> <em class="mh">这里</em> </a> <em class="mh">成为中级会员，获得无限权限！:)</em></p></div></div>    
</body>
</html>