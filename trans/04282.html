<html>
<head>
<title>Detecting Pulmonary Abnormalities in Chest X-Rays</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在胸部x光检查中检测肺部异常</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/detecting-pulmonary-abnormalities-in-chest-x-rays-47f3bf2a8499?source=collection_archive---------22-----------------------#2021-04-11">https://towardsdatascience.com/detecting-pulmonary-abnormalities-in-chest-x-rays-47f3bf2a8499?source=collection_archive---------22-----------------------#2021-04-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8b35" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用于图像识别的卷积神经网络</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8edf9f5d2bcef8b5ef9f223f7e4336a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4YCKWPlzbfxiapCV"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@cdc?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">疾控中心</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="1e9b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">应用数据科学和人工智能已经并将继续为许多不同的领域和行业做出贡献，其中一个例子是医疗保健和医学研究。</p><p id="4bcf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如今，能够进行X射线扫描的技术很容易以相对较低的成本获得。然而，从所述扫描中做出诊断所需的合格的放射学专家并不多，尤其是在发展中国家。</p><p id="aecb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这一领域实施人工智能解决方案可能会推动发展向前迈出关键的一步。</p><p id="4436" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个项目背后的动机是探索建立卷积神经网络(CNN)模型的可能性，以检测胸部X射线扫描图像中的肺部异常，希望使诊断过程更快，更便宜，减少对人类专家干预的依赖。</p><p id="1f6b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">完成项目的阶段如下:</p><ol class=""><li id="f900" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">探索和预处理训练数据</li><li id="ac0d" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">构建、评估和调整CNN模型</li><li id="2b58" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">讨论该方法的成功之处、局限性和潜在的未来改进</li></ol></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="1c78" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">第一部分:训练数据的预处理和探索性分析</h1><p id="63af" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">本项目的训练数据集将包括800幅胸部x光图像:其中662幅由中国深圳市第三人民医院提供，其余138幅来自美国蒙哥马利县卫生与公众服务部。</p><p id="964c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据集中的每幅图像都已经过放射科医师的检查，并且提供了一个标签来指示患者是否表现出由结核病表现引起的肺部异常。</p><p id="da04" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该数据集最初由美国国家医学图书馆发布，旨在为计算机辅助肺部疾病诊断领域的研究提供足够的公共训练数据。本项目中使用的数据由用户<a class="ae kv" href="https://www.kaggle.com/kmader" rel="noopener ugc nofollow" target="_blank"> K Scott Mader </a>通过<a class="ae kv" href="https://www.kaggle.com/kmader/pulmonary-chest-xray-abnormalities" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>获得。所有相关的引用都可以在本文末尾的<em class="nk">参考文献</em>部分找到。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/09c04a0a37623638426ea939f1ba230d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*He75vH8OQKvWZ7ZhtNK2hQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图1:训练图像的两个例子，一个显示异常(左)，一个不显示异常(右)</p></figure><h2 id="f197" class="nm mo iq bd mp nn no dn mt np nq dp mx lf nr ns mz lj nt nu nb ln nv nw nd nx bi translated">编码图像</h2><p id="9f81" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">在图像数据可以被分析或传递到机器学习模型之前，它必须首先被转换成某种数字格式。为此，我们可以使用<a class="ae kv" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html" rel="noopener ugc nofollow" target="_blank"> OpenCV </a> Python包对图像进行编码。</p><p id="445c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个包的<code class="fe ny nz oa ob b">imread</code>方法将为每幅图像创建一个numPy数组，数组中的每一项代表一个像素的编码灰度，有三个单独的层用于蓝色、绿色和红色。</p><p id="6ef6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每个阵列的尺寸将等于图像的高度(像素)、宽度(像素)和颜色层的数量(三个)。</p><p id="c536" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然X射线图像不包含从白色到黑色范围以外的颜色，但我们稍后将用于构建CNN模型的包(<a class="ae kv" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>)要求每个输入变量都是3D数组，因此我们无法读取2D灰度的图像。</p><h2 id="e453" class="nm mo iq bd mp nn no dn mt np nq dp mx lf nr ns mz lj nt nu nb ln nv nw nd nx bi translated">正在检索目标标签</h2><p id="9a0c" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">训练数据来源中的描述解释了每个图像的基本事实标签(由医学专家确定)作为后缀存储在其文件名中:用<em class="nk"> 1 </em>表示扫描显示异常，用<em class="nk"> 0 </em>表示不显示异常。</p><p id="613c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了检索目标标签，我们可以简单地在filetype前面添加最后一个字符(<em class="nk">)。png </em>)到一个列表中，这个列表将作为目标变量。</p><p id="4d95" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以使用如下定义的嵌套for循环为两个目录中的每个目录中的每个图像创建编码特征变量的数组和目标标签的列表:</p><pre class="kg kh ki kj gt oc ob od oe aw of bi"><span id="eff5" class="nm mo iq ob b gy og oh l oi oj">def encode_images():<br/>    <br/>    X = []<br/>    y = []</span><span id="6385" class="nm mo iq ob b gy ok oh l oi oj">    directories = ['xray_images/ChinaSet_AllFiles/ChinaSet_AllFiles/CXR_png/', <br/>                  'xray_images/Montgomery/MontgomerySet/CXR_png/']</span><span id="6f63" class="nm mo iq ob b gy ok oh l oi oj">for directory in directories:<br/>        for filename in os.listdir(directory):<br/>            if filename.endswith('.png'):<br/>                X.append(cv2.imread(directory + filename))<br/>                y.append(int(filename[-5]))<br/>    <br/>    return np.array(X), np.array(y)</span></pre><h2 id="2874" class="nm mo iq bd mp nn no dn mt np nq dp mx lf nr ns mz lj nt nu nb ln nv nw nd nx bi translated">评估和调整图像大小</h2><p id="25ce" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">CNN模型要求每个输入条目的形状相同。在我们的数据的上下文中，这将对应于每个图像具有相同的大小，因此每个特征阵列具有相同的维度。</p><p id="fab6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们通过在训练数据中绘制图像的高度和宽度分布来检查是否是这种情况:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/6d1e9b07fe8546ef8674d4cf4af31709.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NQFwXmqIaln3uKziwFmRbA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图2:图像尺寸的分布</p></figure><p id="4cd0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到图像大小存在差异。为了解决这个问题，我们可以重写我们的编码函数来实现For循环开始处的<a class="ae kv" href="https://pillow.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> Pillow </a>包中的<code class="fe ny nz oa ob b">resize</code>方法。</p><p id="87e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是我们应该为输入图像选择多大的尺寸呢？</p><p id="22e3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">理论上，保持尽可能高的分辨率可以得到更精确的模型。我们可以从上面的分布中看到，这些图像的分辨率相当高，几乎所有图像的高度和宽度都至少有1000像素。</p><p id="de77" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，我们也需要考虑计算速度。保持超过1000平方像素可能需要很长时间才能使模型适应训练数据，特别是因为我们将在本地运行代码。像往常一样，我们在准确性和速度之间有所取舍。</p><p id="c49a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为一个折衷点，并且记住选择2的指数的图像尺寸通常是一个好的实践，让我们将图像的大小调整为256像素的正方形:</p><pre class="kg kh ki kj gt oc ob od oe aw of bi"><span id="dd03" class="nm mo iq ob b gy og oh l oi oj">img = Image.open(directory + filename)<br/>img = img.resize((256, 256))<br/>img.save(directory + filename)</span></pre><h2 id="50ba" class="nm mo iq bd mp nn no dn mt np nq dp mx lf nr ns mz lj nt nu nb ln nv nw nd nx bi translated">标准化图像的比例</h2><p id="85fc" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">像素的灰度代码可以从0(黑色)到255(白色)。目前，我们的编码特征数组包含高达255的值。机器学习模型，特别是那些涉及梯度下降的模型，如神经网络，通常在标准化数据上表现更好。</p><p id="86d3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在进入建模阶段之前，为了说明这一点，让我们将特征数组除以最大值(255)来归一化每个条目，使其范围从0到1:</p><pre class="kg kh ki kj gt oc ob od oe aw of bi"><span id="0586" class="nm mo iq ob b gy og oh l oi oj">print((np.min(X), np.max(X)))<br/>X = X.astype('float32') / 255<br/>print((np.min(X), np.max(X)))<br/>&gt;&gt;&gt; (0, 255)<br/>&gt;&gt;&gt; (0.0, 1.0)</span></pre><h2 id="abb2" class="nm mo iq bd mp nn no dn mt np nq dp mx lf nr ns mz lj nt nu nb ln nv nw nd nx bi translated">分析目标变量</h2><p id="3099" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">在继续构建模型之前，获得目标变量的一些可见性也是一个好主意。</p><p id="aa6a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们来看看训练数据中正面分类和负面分类之间的差异:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/2d6787dedfeae1f011ca1548c30772a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*S4_uc9v2JqowMrbdohIJuA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图3:目标变量分割</p></figure><p id="6d5c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从上面我们可以看到，我们的训练数据在各个类之间是平衡的，超过49%的图像显示异常。这应该作为以后评估模型准确性的基准。</p><p id="d1b3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们已经将训练数据预处理成适合CNN模型的格式，并通过一些探索性分析获得了对它的更好理解，我们可以进入CNN建模阶段。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="4d41" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">第二部分:构建CNN模型</h1><h2 id="f9ee" class="nm mo iq bd mp nn no dn mt np nq dp mx lf nr ns mz lj nt nu nb ln nv nw nd nx bi translated">分割训练数据</h2><p id="d09c" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">为了便于在模型构建和训练后对其进行评估和调整，我们需要将数据分成训练集和测试集。</p><p id="cdaf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当使用任何形式的神经网络时，建议将数据分成<strong class="ky ir">三个</strong>独立的集合(训练、验证和测试)，而不是传统的两个集合。</p><p id="02f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是因为神经网络模型使用训练集作为输入来馈通模型，计算损失，并在每个时期调整权重和偏差，然后使用单独的验证集来确定新参数是否是对来自前一时期的参数的改进。</p><p id="96eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于模型在训练期间已经“看到”了验证数据，使用相同的数据来评估最终模型在技术上可能会导致数据泄漏，因此需要在初始分割时创建第三个测试集。</p><p id="023a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以通过使用<a class="ae kv" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>的<code class="fe ny nz oa ob b">train_test_split</code>方法来执行这种分割，首先将数据分割成训练集和测试集，然后再将测试集分割成单独的验证集和测试集:</p><pre class="kg kh ki kj gt oc ob od oe aw of bi"><span id="abfa" class="nm mo iq ob b gy og oh l oi oj">train_size = 0.6<br/>val_size = 0.2<br/>test_size = 0.2</span><span id="a18a" class="nm mo iq ob b gy ok oh l oi oj">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(val_size + test_size), random_state=42)</span><span id="cc01" class="nm mo iq ob b gy ok oh l oi oj">X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=(test_size / (val_size + test_size)), random_state=42)</span><span id="c420" class="nm mo iq ob b gy ok oh l oi oj">print('Training: {}; Validation: {}; Testing: {}'.format((len(X_train), len(y_train)), (len(X_val), len(y_val)), (len(X_test), len(y_test))))<br/>&gt;&gt;&gt; Training: (480, 480); Validation: (160, 160); Testing: (160, 160)</span></pre><h2 id="f626" class="nm mo iq bd mp nn no dn mt np nq dp mx lf nr ns mz lj nt nu nb ln nv nw nd nx bi translated">编码目标变量</h2><p id="e9fd" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">不管可能的类的数量是多少，Keras中的任何神经网络模型都要求目标变量被分类(一次性)编码。在开始构建模型之前，我们需要对三个目标集进行分类转换:</p><pre class="kg kh ki kj gt oc ob od oe aw of bi"><span id="2705" class="nm mo iq ob b gy og oh l oi oj">y_train = keras.utils.to_categorical(y_train, len(set(y)))<br/>y_val = keras.utils.to_categorical(y_val, len(set(y)))<br/>y_test = keras.utils.to_categorical(y_test, len(set(y)))</span><span id="9e20" class="nm mo iq ob b gy ok oh l oi oj">print(y_train.shape, y_val.shape, y_test.shape)<br/>&gt;&gt;&gt; (480, 2) (160, 2) (160, 2)</span></pre><h2 id="c14d" class="nm mo iq bd mp nn no dn mt np nq dp mx lf nr ns mz lj nt nu nb ln nv nw nd nx bi translated">构建基线模型</h2><p id="fdd8" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">在Keras中构建CNN模型的第一步是定义模型架构。与其他神经网络一样，该架构必须包括:</p><ol class=""><li id="42e6" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">初始输入图层，我们在其中指定输入要素的形状</li><li id="1ce1" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">零个或多个“隐藏”层，试图揭示数据中的模式</li><li id="aa17" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">最终输出层，它将根据输入对每个实例进行分类</li></ol><p id="94d3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">基线模型架构的代码可以写成如下形式:</p><pre class="kg kh ki kj gt oc ob od oe aw of bi"><span id="0571" class="nm mo iq ob b gy og oh l oi oj">base_model = Sequential()<br/>base_model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=X[0].shape))<br/>base_model.add(MaxPooling2D(pool_size=2))<br/>base_model.add(Flatten())<br/>base_model.add(Dense(len(set(y)), activation='softmax'))</span></pre><p id="d17c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于基线模型有几点需要注意:</p><ol class=""><li id="2db3" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">我们需要指定想要使用的过滤器的数量以及输入层中方形内核的大小</li><li id="ca6f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">我们还需要指定填充，以防滤镜溢出图像边缘，为此我们将使用<code class="fe ny nz oa ob b">‘same’</code></li><li id="61f3" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">我们将从ReLu激活函数开始，它保持正值不变，并将负值设置为0。当我们调整模型时，我们可以测试不同的功能</li><li id="1103" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">由于我们调整了所有要素输入的大小，因此它们不会发生变化，我们可以使用第一个实例来指定输入形状</li><li id="87e4" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">添加了最大池图层，通过从每个2x2方块中获取最大值来减少数据的维数</li><li id="c270" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">在到达输出层之前，我们需要将数据展平到一个2D数组中，以便它可以被馈送到一个完全连接的层中</li><li id="a1cb" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">在输出层中，我们需要指定模型应该预测多少个类(等于目标数组中唯一值的数量，在本例中为2 ),并使用Softmax激活函数将输出归一化为概率分布</li></ol><p id="6508" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还需要编译模型，这包括定义我们将用来衡量其性能的度量标准。因为我们发现在研究数据时，目标变量在各个类之间是均衡的，所以纯粹的准确性应该是一个合适的度量标准:</p><pre class="kg kh ki kj gt oc ob od oe aw of bi"><span id="5369" class="nm mo iq ob b gy og oh l oi oj">base_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])</span></pre><p id="7056" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以看到,<code class="fe ny nz oa ob b">compile</code>方法也用于为模型选择合适的损失函数和优化指标，以便在训练时使用。</p><p id="7c37" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦我们定义并编译了模型的架构，我们就可以使它适合训练数据:</p><pre class="kg kh ki kj gt oc ob od oe aw of bi"><span id="7566" class="nm mo iq ob b gy og oh l oi oj">base_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), verbose=1, shuffle=True)</span></pre><p id="7cea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ny nz oa ob b">fit</code>方法中的参数本质上是告诉模型适应训练集，并使用验证集作为评估性能的看不见的数据。</p><p id="a9b7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">批量大小用于将数据分成子集，以便一次一个地通过网络。这具有极大地减少完成每个训练步骤所需的计算能力的优点。</p><p id="89e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">历元数告诉模型应该通过网络推送数据多少次，然后反向传播权重和偏差。我们将很快讨论要使用的最佳历元数，但首先我们将使用10。</p><h2 id="4a41" class="nm mo iq bd mp nn no dn mt np nq dp mx lf nr ns mz lj nt nu nb ln nv nw nd nx bi translated">评估基线模型</h2><p id="7c6d" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">一旦我们在指定数量的时期内拟合了模型，我们就可以在以前看不到的测试集上评估它的真实性能:</p><pre class="kg kh ki kj gt oc ob od oe aw of bi"><span id="2886" class="nm mo iq ob b gy og oh l oi oj">round(base_model.evaluate(X_test, y_test, verbose=0)[1], 4)<br/>&gt;&gt;&gt; 0.7812</span></pre><p id="47f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到基线模型可以准确地对78%的测试样本进行分类。考虑到大约一半的数据集包含积极标记的实例，我们可以推断简单基线模型已经比我们随机猜测每个图像的类别表现得更好。</p><p id="b8d2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这提供了一个很好的起点，但是让我们深入研究一下，看看我们是否可以采取措施来提高模型的性能。</p><h2 id="13d0" class="nm mo iq bd mp nn no dn mt np nq dp mx lf nr ns mz lj nt nu nb ln nv nw nd nx bi translated">选择历元的数量</h2><p id="2f10" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">为了确定拟合模型时使用的最佳时段数，我们可以在<code class="fe ny nz oa ob b">fit</code>方法中使用不同的时段数从基础模型的多次测试运行中收集准确度分数:</p><pre class="kg kh ki kj gt oc ob od oe aw of bi"><span id="a3a7" class="nm mo iq ob b gy og oh l oi oj">epochs = [5, 10, 20, 50, 100, 200]<br/>scores = []</span><span id="a1ad" class="nm mo iq ob b gy ok oh l oi oj">for e in epochs:<br/>    test_model = Sequential()<br/>    test_model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=X[0].shape))<br/>    test_model.add(MaxPooling2D(pool_size=2))<br/>    test_model.add(Flatten())<br/>    test_model.add(Dense(len(set(y)), activation='softmax'))<br/>    test_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])<br/>    test_model.fit(X_train, y_train, epochs=e, batch_size=32, validation_data=(X_val, y_val), verbose=False, <br/>                   shuffle=True)<br/>    scores.append(test_model.evaluate(X_test, y_test, verbose=False)[1])</span></pre><p id="7478" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">并随后绘制结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/5776983d1b6e2fa5f4cc45ce237a31e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i6sJSW7MVpCHkSRyCaZw5Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图4:每个时期的准确度分数</p></figure><p id="9900" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从上面我们可以看到，使用20个历元而不是5个或10个显著提高了模型的性能。然而，随后时代数量的增加，即使有改进，也不会产生太大的改进。</p><p id="234b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然对神经网络模型运行更大数量的时期可以使其变得更加精细，但增加到某个级别以上最终会导致模型对训练数据过度拟合，从而损害测试集的性能。</p><p id="7f1f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">考虑到性能和计算效率，我们在调整基线模型时使用20个时期。</p><h2 id="013c" class="nm mo iq bd mp nn no dn mt np nq dp mx lf nr ns mz lj nt nu nb ln nv nw nd nx bi translated">实现图像增强</h2><p id="aa71" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">一种常用的使CNN模型更健壮并进而提高性能的方法是图像增强。这实质上是指在训练数据内生成新图像，这些新图像是现有图像的翻译，作为一种为杂乱的真实世界数据准备模型的手段，在真实世界数据中，要识别的对象可以以多个角度和大小出现在图像空间内的任何地方。</p><p id="a8e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在Keras中执行图像增强相对简单。我们首先需要为每个训练集和验证集创建和调整图像生成器对象:</p><pre class="kg kh ki kj gt oc ob od oe aw of bi"><span id="c8aa" class="nm mo iq ob b gy og oh l oi oj">datagen_train = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)<br/>datagen_val = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)</span><span id="cb2a" class="nm mo iq ob b gy ok oh l oi oj">datagen_train.fit(X_train)<br/>datagen_val.fit(X_val)</span></pre><p id="52a6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后可以将其传递给CNN的<code class="fe ny nz oa ob b">fit</code>方法。为了测试这种技术是否提高了模型的性能，让我们在相同的条件下重新创建基线模型，但是这一次，当我们将数据生成器对象与定型数据相匹配时，要传递数据生成器对象:</p><pre class="kg kh ki kj gt oc ob od oe aw of bi"><span id="6a8a" class="nm mo iq ob b gy og oh l oi oj">batch_size = 32</span><span id="f8cb" class="nm mo iq ob b gy ok oh l oi oj">aug_base_model.fit(datagen_train.flow(X_train, y_train, batch_size=batch_size), <br/>                   steps_per_epoch=X_train.shape[0] / batch_size, epochs=20, verbose=1, callbacks=[checkpointer], <br/>                   validation_data=datagen_val.flow(X_val, y_val, batch_size=batch_size), <br/>                   validation_steps=X_val.shape[0] / batch_size)</span></pre><p id="8547" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，我们需要在函数中指定每个时期要执行的步骤数。这可以被定义为在给定的批量中输入实例的数量。</p><p id="c6aa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以使用与之前相同的方法来评估增强基线模型的性能:</p><pre class="kg kh ki kj gt oc ob od oe aw of bi"><span id="5d25" class="nm mo iq ob b gy og oh l oi oj">round(aug_base_model.evaluate(X_test, y_test, verbose=0)[1]<br/>&gt;&gt;&gt; 0.6875</span></pre><p id="6359" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以上表明，使用图像增强实际上阻碍了我们的模型的性能，而不是提高它。</p><p id="d078" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了理解为什么会这样，让我们试着应用一些领域知识。虽然图像增强可以在典型的非结构化图像的环境中提高模型的鲁棒性，例如识别道路图片中的汽车，但同样的规则可能不适用于我们的数据环境。</p><p id="8f82" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">x射线扫描是在受控条件下进行的，因此我们可以预期在训练集和测试集中的图像之间存在结构一致性。因此，在训练中包括真实图像的翻译可能只会通过创建不现实的环境来混淆模型。</p><p id="6b42" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">考虑到这一点，让我们决定在不使用图像增强的情况下进行调整。</p><h2 id="7774" class="nm mo iq bd mp nn no dn mt np nq dp mx lf nr ns mz lj nt nu nb ln nv nw nd nx bi translated">调整模型</h2><p id="e89b" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">CNN模型提供了无数的调谐和调整机会，以提高性能。因为这是一个据说应用领先于理论的领域，所以发现模型的最佳条件的最有效的方法就是简单地钻研和试验。</p><p id="ca78" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">调谐CNN是一个反复尝试的过程。由于这个项目的代码可以在最后链接的资源库中找到，我不会在本文中包括所有的调优步骤，但下面是调优过程中调整和测试的各种条件的概述:</p><ol class=""><li id="2a7c" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">实现附加卷积层</li><li id="0baa" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">在最终输出图层之前添加密集图层</li><li id="3db2" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">实现丢弃以随机“关闭”每层中的一些节点</li><li id="f991" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">尝试不同的激活函数，如Sigmoid函数</li><li id="aa25" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">在卷积层中使用更大的步幅</li></ol><h2 id="1d0e" class="nm mo iq bd mp nn no dn mt np nq dp mx lf nr ns mz lj nt nu nb ln nv nw nd nx bi translated">最终产品</h2><p id="cc1e" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">经过多轮调整后，产生最高准确度分数(84%)的模型包括:</p><ul class=""><li id="0fab" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr oo ly lz ma bi translated">增加滤波器数量的三个卷积层</li><li id="4387" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr oo ly lz ma bi translated">每层中的ReLu激活函数</li><li id="edd2" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr oo ly lz ma bi translated">每层之后的最大池层大小为2</li><li id="ee16" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr oo ly lz ma bi translated">第三卷积层之后的概率为0.3的丢弃层</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/0f42d4f6b858ea1a6604432a2a0935f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ax1SuvSWz3yABdHZ9Jxqbw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图5:最终模型的架构</p></figure></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="e61a" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">第三部分:探讨方法</h1><h2 id="3d39" class="nm mo iq bd mp nn no dn mt np nq dp mx lf nr ns mz lj nt nu nb ln nv nw nd nx bi translated">成功</h2><p id="8e4b" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">使用由专家放射科医生预先标记的X射线图像数据集，我们能够构建一个简单的CNN模型，以正确识别肺部异常<strong class="ky ir"> 78% </strong>的时间。</p><p id="11f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们能够通过实施额外的卷积层和dropout等功能来调整模型，以提高性能，实现最终的准确度分数<strong class="ky ir"> 84% </strong>。</p><h2 id="d7ef" class="nm mo iq bd mp nn no dn mt np nq dp mx lf nr ns mz lj nt nu nb ln nv nw nd nx bi translated">限制</h2><p id="7914" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">虽然最终的模型可能为进一步的研究提供有用的基础，但84%的准确率可能被认为不足以应用于现实世界的医疗环境。在这种型号真正投入使用之前，需要达到更高的性能水平。</p><p id="0d75" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种方法最明显的缺点是训练数据集的大小。在机器学习的背景下，800的样本量被认为是非常小的，我们可以通过使用更大的训练集来提高模型的性能。</p><p id="f2b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，这也会带来自身的问题。CNN是计算复杂的算法，因此将训练数据的大小增加到超过某一点，最终在本地机器上训练将变得不切实际。</p><p id="ab00" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种方法的另一个局限性是数据集只包含一种疾病的基本事实诊断:结核病。如果这种类型的模型被用于现实世界病例的诊断，它将需要能够检测由其他肺部疾病引起的异常。</p><p id="652e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">解决这一问题将再次需要使用扩展的训练数据集，其中包括多种可能疾病的标签，从而将该方法转化为多标签分类问题，而不是二进制问题。</p><h2 id="f1a5" class="nm mo iq bd mp nn no dn mt np nq dp mx lf nr ns mz lj nt nu nb ln nv nw nd nx bi translated">在未来版本中开发模型</h2><p id="93ea" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">如上所述，在未来版本中建立改进模型的第一步是收集更大和更多样的训练数据集。</p><p id="5676" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了克服在本地CPU上训练复杂CNN的不切实际性，使用基于云的、支持GPU的服务器(比如AWS)的服务也是明智的。</p><p id="1f90" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一个尝试改进模型的途径是使用迁移学习。这将涉及采用预训练的神经网络，并用针对该问题定制的完全连接的层来替换最终输出层。</p><p id="25d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这在小的训练数据集的环境中特别有用，因为它可以获得在大得多的数据集上训练的模型的好处，并且将相同的模式应用于所讨论的数据。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="e683" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">结束语</h1><p id="ad0f" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">该项目的目的是探索构建CNN模型的可能性，以检测胸部X射线扫描图像中的肺部异常，作为通过应用人工智能辅助诊断的一种手段。</p><p id="0138" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是因为尽管有x光机，但缺乏专业的放射科医生，特别是在发展中国家。</p><p id="b576" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从原始图像数据集到最终工作模型的过程包括:</p><ol class=""><li id="44b7" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">调整图像数据的大小、编码和标准化</li><li id="7f53" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">构建和评估基线CNN模型的架构，以此作为起点</li><li id="ffc0" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">试验和调整模型的许多条件，如历元数、卷积层数和dropout的使用，以提高性能</li></ol><p id="1307" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有兴趣更详细地研究代码(包括各种调优阶段)的读者可以在我的<a class="ae kv" href="https://github.com/harryroper96/xray_abnormality_detector" rel="noopener ugc nofollow" target="_blank"> Github </a>的资源库中找到它。随时欢迎关于改进模型的反馈、问题和建议。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="90ee" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">参考</h1><p id="f5f8" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">K Scott Mader <em class="nk">肺部胸部x光异常</em><a class="ae kv" href="https://www.kaggle.com/kmader/pulmonary-chest-xray-abnormalities" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/k Mader/Pulmonary-胸部x光异常</a></p><p id="0b99" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Jaeger S，Candemir S，Antani S，Wáng YX，Lu PX，Thoma G. <em class="nk">用于计算机辅助肺部疾病筛查的两个公共胸部X射线数据集</em>。量子成像医学外科，2014年；4(6):475–477.2014年11月20日</p><p id="1d07" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">耶格S、卡拉吉里斯A、坎迪米尔S、福利欧L、西格尔曼J、卡拉汉F、薛Z、帕拉尼亚潘K、辛格RK、安塔尼S、托马斯G、王YX、卢PX、麦克唐纳CJ。<em class="nk">利用胸片进行自动结核病筛查</em>。IEEE跨医学成像。2014年2月；33(2):233–45.多伊岛:10.1109/TMI 2013 . PMID:24101 . 13838383621</p><p id="dda4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">坎迪米尔S，耶格S，帕拉尼亚潘K，穆斯科JP，辛格RK，薛Z，卡拉吉里斯A，安塔尼S，托马斯G，麦克唐纳CJ。<em class="nk">使用非刚性配准的解剖图谱在胸片中进行肺部分割</em>。IEEE跨医学成像。2014年2月；33(2):577–90.多伊岛:10.1109/TMI 2013 . 2291 . PMID:24233243223</p></div></div>    
</body>
</html>