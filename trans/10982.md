# 完整的深度学习组合项目第 1 部分

> 原文：[https://towardsdatascience.com/full-deep-learning-portfolio-project-part-1-78df161214aa?source=collection_archive---------14-----------------------#2021-10-26](https://towardsdatascience.com/full-deep-learning-portfolio-project-part-1-78df161214aa?source=collection_archive---------14-----------------------#2021-10-26)

## 系统地寻找鸟类图像分类任务的最佳训练策略

![](../Images/8ccbcee15f72e92b6a8f79de63d6679b.png)

托马斯·列斐伏尔在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

# 介绍

想从事机器学习工程师的工作，但从未实际从事过机器学习项目？然后找工作真的不容易。大多数公司都在寻找有经验的机器学习工程师。我所说的经验并不是指你参加过机器学习在线课程。不要误解我的意思:参加机器学习在线课程以获得更多关于该主题的知识总是很棒的！然而，对于一个雇主来说，正确地评估一门在线课程是非常困难的。有些很容易，有些很有挑战性。然而，雇主能评估好的是自己的项目。在那里，他可以直接看到你如何处理某些话题，以及你已经从项目中获得了什么经验。

然而，在这些项目中，你不应该只关注机器学习部分，这主要是在 Jupyter 笔记本上完成的，但你也应该考虑部署。因为现在训练深度学习模型不再具有挑战性。像 Keras 这样的库允许你在几行代码内创建和训练一个深度学习模型。然而，如果你能够开发一个成熟的应用程序，那么你肯定会更有趣。此外，如果你已经开发了一个网页，并可以在那里展示你训练有素的模型，而不是让他浏览你的 Jupyter 笔记本，在那里只能看到代码和打印输出，那么你可以更好地说服一个没有技术背景的招聘人员。

为此，我创作了两篇文章，其中系统地发现并应用了深度学习训练策略，并通过网站部署了训练好的模型。

在这个系列的第一部分，我想向你展示一个如何为图像分类任务找到一个好模型的系统方法。作为数据集，我决定使用来自 Kaggle 的开源鸟类物种数据集，你可以在这里找到。代码和所有文档都可以在我的 Github 页面[这里](https://github.com/patrickbrus/Birds_Classifier_API)找到。代码是用 Python 写的。

在本系列的第二部分，我将向您展示如何使用 html 和 Flask 开发一个完整的 web 应用程序，包括前端和后端。你可以在这里找到文章。

如果你对我如何使用 Docker 和 Github Actions 将完整的 web 应用程序部署到 AWS Elastic Beanstalk 感兴趣，那么我可以推荐你阅读我的这篇文章。

# 内容

在第一部分中，我介绍了数据集，并已经对输入数据进行了一些预处理。在第二部分，我将向您展示我如何使用 Tensorflow 创建输入管道，以及它的代码是什么样子。方法部分描述了我为找到最佳训练策略而进行的各种评估。每当要训练 CNN 时，可以使用这些评估。结果部分显示了最终培训策略的培训结果。结论部分总结了这个项目的结果，而展望部分提供了本系列第二篇文章的参考。

# 探索性数据分析和预处理

作为第一步，我将提供的“Bird_Species.csv”文件加载到 pandas 数据框中(图 1)。

![](../Images/b28c3a909d703725bce1f7dd8d3b62d9.png)

图 1:初始加载的数据帧头。

数据集的创建者还提供了第二个 csv 文件，包含图像的类和一些元数据。我还将这个 csv 文件加载到 pandas 数据框中(图 2)。

![](../Images/9124295f457c3ea7eb48e109e75d2e07.png)

图 2:包含类和图像形状的数据帧的头部。

然后，我使用第二个数据框快速检查了该数据集中不同类的数量，并将其与“Bird_Species.csv”文件(代码 1)中唯一标签的数量进行了比较。

代码 1:读入数据文件并检查所有的类是否都存在于完整的数据集中。

有趣的是，根据“class_dict.csv”文件，鸟类有 300 个不同的类别，但在整个数据集中，只有 285 个不同的类别。因此，我检查了哪些类没有出现在数据集中，并查看了文件夹，以确定它们是真的没有出现，还是只是在“Bird_Species.csv”文件中丢失了。确实有缺失班级的图片。这意味着现有的 csv 文件不正确。所以我首先创建了一个干净的 csv 文件，保存它并在这个项目的其余部分使用它。这一步的代码可以在“Make_Clean_Dataset.ipynb”笔记本[这里](https://github.com/patrickbrus/Birds_Classifier_API/blob/master/Make_Clean_Dataset.ipynb)找到。

既然数据集是干净的，我开始进一步研究它。我从绘制数据集的一些随机示例图像开始，以便对图像的外观有所了解。图 3 显示了两个示例鸟图像。

![](../Images/09c55316dbe3abd24dd4574fb118cbab.png)![](../Images/b4b86f6387097e63ac159ccbe727b9e1.png)

图 3:鸟类数据集的两个示例图像。左图是一只非洲冠鹤，右图是一只冈比亚鹌鹑。

作为下一步，我绘制了已经由作者创建的训练和测试集的分布图(图 4 和图 5)。这对于检查数据集是否不平衡以及确保测试分布和训练分布大致相同非常重要。

![](../Images/b66e78b1aeb01aaca80c8627f7c1d094.png)

图 4:从数据集作者创建的训练集的分布。

![](../Images/91cda2391e6ba25c1e261fb1166620f6.png)

图 5:从数据集作者创建的测试集的分布。

可以看出，训练集是不平衡的，而测试集是完全平衡的。这清楚地表明测试集来自不同于训练集的分布。这可能会导致模型在测试集上表现良好，但在真实世界数据上表现不佳，因为测试分布没有反映“真实”分布。因此，我决定使用 Scikit-Learn 的分层混洗技术创建自己的训练、验证和测试集。但是在分割数据之前，我还对标签进行了一次性编码，以匹配 CNN 所需的输入格式。代码 2 显示了这些步骤的代码，包括清理后的数据集 csv 文件的初始加载。

代码 2:用于通过执行分层混洗分割来创建训练、验证和测试集的代码。

图 6 和图 7 显示了分层洗牌拆分后训练集和测试集的分布。这两个发行版现在来自同一个发行版。

![](../Images/bd0952dfe3ee209fc1e52608879e4d8c.png)

图 6:使用分层洗牌拆分后的训练集分布。

![](../Images/bb6d4b9f24cc42d3e3cd49a95573869e.png)

图 7:使用分层洗牌拆分后测试集的分布。

训练数据集有点不平衡，这应该不是问题。但是让我们稍后检查过采样是否可以提高这个数据集的性能。

这里没有添加验证集的数字，但是它与测试集和训练集具有相同的分布。

# 创建输入管道

对于训练深度学习模型来说，拥有一个好的输入管道总是很重要的。Tensorflow 通过其 ImageDataGenerator 类为您提供了很好的支持。这个类允许您指定一些预处理，让您从一些数据扩充中选择，并允许您在训练期间批量加载图像。这一点尤其重要，因为对于大型数据集，如果在训练之前必须先加载一次所有图像，将会占用大量 RAM。

对于鸟类分类，我创建了以下输入管道步骤:

1.  应用一些随机选择的数据扩充，这样大约 10%的数据没有被扩充。
2.  归一化图像像素值，使它们在(0，1)的范围内。

我使用了一些来自 [imgaug](https://imgaug.readthedocs.io/en/latest/index.html) Python 库的基本数据扩充，以增加数据集中的变化。这个库非常有用，因为它实现了几乎所有你能想到的扩充。本项目使用的数据扩充是通过对示例图像应用扩充并评估图像是否仍然有意义来手动选择的。在上面提到的 Github 存储库中，可以在 Jupyter 笔记本中看到不同应用增强的评估结果，称为“Check Augmentations.ipynb”。一般来说，可以使用这些增强，并且可以一次用一个额外的增强来训练模型，并且将其性能与没有任何增强的基线模型进行比较。但是为了这个项目，我决定不做这个评估，因为我假设每一个增强都会导致与基线模型相比的改进。

我使用了以下扩展(图 8):

1.  左右翻转图像。
2.  将像素值乘以偏移量。
3.  盐和胡椒。
4.  伽玛对比度变化。
5.  向像素值添加偏移量。
6.  添加附加高斯噪声。
7.  应用运动模糊。
8.  应用仿射变换。
9.  旋转图像。
10.  应用弹性变换。

增强“添加”和“伽玛对比度”从不同时使用，因为这可能导致不真实的图像。

![](../Images/4401b337e0fc29e2008944bf63085652.png)

图 8:应用增强的概述(图片由作者提供)。

代码 3 展示了创建输入管道的完整 Python 代码，同时使用了 Tensorflow 的“flow_from_dataframe”选项。这允许在训练期间分批加载图像。您只需要一个 csv 文件，其中第一列包含图像的名称，其他列包含该图像的标签。为了首先找到最佳的 CNN 架构，我决定使用 8 的批量大小，并将图像的大小固定为(224，224)。

代码 3:使用 Tensorflow 和 ImageDataGenerator 类创建输入管道的代码。

# 方法学

输入管道已创建。现在是时候找到最适合的训练策略了。首先，比较了一些最先进的 CNN 架构，并选择性能最佳的架构作为本项目剩余部分的架构。其次，比较不同的图像尺寸，以便找到最佳的图像尺寸。第三步，尝试过采样来处理稍微不平衡的数据集。最后一步，使用贝叶斯超参数搜索来搜索最优超参数。

方法部分的代码没有包含在本文中，因为它太长了。请随意检查我的 [Github Jupyter 笔记本](https://github.com/patrickbrus/Birds_Classifier_API/blob/master/DeepLearning_Project.ipynb)，查看并复制我创建的代码。我只包含了对数据帧进行过采样的代码，因为这可能是更有趣的代码部分。

## CNN 架构比较

有许多不同的 CNN 架构可用于鸟类分类器。在本项目中，选择了六种不同的 CNN 架构(表 2)并进行相互比较。每种架构都用于训练具有表 1 中给出的超参数的鸟分类器。最后，最佳验证 f1 分数被存储并用于找到最佳 CNN 架构。这里，仅使用最佳验证 f1 分数，并且忽略了这一点，即每个体系结构具有不同的训练复杂性，并且可能一个体系结构仅导致稍差的验证 f1 分数，但是具有比达到更高验证 f1 分数的模型少得多的参数。但是对于未来的优化，也可以考虑训练复杂度，并且可以将其包括在决定中，将哪个编码器架构用于最终的鸟分类器。表 2 还显示了最终结果。可以看出，DenseNet121 实现了最佳的 f1 验证分数，因此被用作鸟类分类器的最终编码器架构，也用于该项目的其他评估。图 5 显示了不同编码器在训练过程中的 f1 分数，图 4 显示了训练过程中的损失值。

![](../Images/94595a9e47e971e0fc1ed563da5e40dc.png)

表 1:用于 CNN 架构比较的超参数。

![](../Images/4210c16cac2de809e529bfea5e3e642b.png)

图 4:不同编码器架构的训练过程中的损耗值。使用分类交叉熵作为损失函数。

![](../Images/ee7a3217fbfbb4ad30ef65a72d198a56.png)

图 5:F1-不同编码器架构训练过程中的得分。

![](../Images/95766ca28cbb41e10983547d9b05b071.png)

表 2:在训练过程中使用的 CNN 架构和它们的最好成绩。

## 图像大小比较

在通往最佳训练策略的道路上，接下来应该找到最佳图像尺寸。将评估和比较四个不同的选项。使用表 1 中的超参数为四种图像尺寸中的每一种训练 DenseNet。结果可以在表 3 中找到，其中再次将最佳验证 f1 分数作为决策的衡量标准。图 6 和 7 显示了在不同图像尺寸的训练过程中 f1 分数和损失值的结果。

正如人们所猜测的:图像越大，模型的性能越好。然而，从图像大小 192x192 到 224x224，最佳验证 f1 分数仅增加 0.4%。因此，我决定使用 192x192 作为图像大小，以便减少可训练参数的数量，并稍微加快训练过程。

![](../Images/eeb5939dee8054628efe6e1d4571aa85.png)

图 6:F1-在用不同图像尺寸训练 DenseNet 的训练过程中的分数。

![](../Images/c7438a7697477e37508b1063c849f929.png)

图 7:用不同图像尺寸训练 DenseNet 的训练过程中的损失值。使用分类交叉熵作为损失函数。

![](../Images/9e94024946d4540e96baec7ebe3a2159.png)

表 3:最佳验证 f1-用不同图像尺寸训练 DenseNet 的得分和准确度。

## 过采样

如前所述，数据集略有不平衡。因此，可以使用过采样来更好地平衡数据集，并避免模型更偏向多数类而预测少数类不太准确的风险(图 8，代码 4)。

代码 4:获取数据帧并对其进行过采样以获得完全平衡的数据帧的代码。过采样是通过对少数类更频繁地重用图像来实现的。

然后使用过采样数据集和来自表 1 的超参数来训练 DenseNet121，除了时期的数量减少到 20 个时期。这是由于过采样，因此是模型应该学习得更快的原因，因为相同的图像在一个训练时期内不止一次可用。过采样模型的最佳验证 f1 分数为 95.4%，这与没有应用过采样的情况几乎相同。因此，过采样不用于训练最终的鸟类分类器，因为它也需要更多的训练时间，并且通常更容易过拟合。

![](../Images/e8e7c02648517c366dc37e205b0c8bdb.png)

图 8:应用过采样后的训练数据集。训练集现在完全平衡，这是通过复制少数类的相同图像来实现的，只要每个类具有相同数量的样本。

## 贝叶斯超参数搜索

作为找到最佳训练策略的最后一步，使用贝叶斯超参数搜索来优化超参数。贝叶斯搜索的优点在于，它在寻找最优超参数方面比随机搜索更有效，并且比网格搜索需要更少的迭代。κ为 3 的高斯过程被用作优化策略。手动提供四个初始点，这将有助于将优化过程引向最佳方向。贝叶斯优化被执行 12 次迭代。使用称为“置信下限”的获取函数，并且它获得最佳验证 f1 分数作为要优化的度量。置信下限试图最小化其优化度量。因此，使用负的最佳验证 f1 分数。表 4 显示了超参数使用的搜索空间，而表 5 显示了最佳参数。衰减率指定学习率在每个衰减步骤时期应该减少多少。

图 9 显示了贝叶斯超参数搜索的收敛图。可以看出，最佳参数是在最后一次迭代中找到的。这是由于贝叶斯优化的性质。在开始阶段，存在大量的不确定性，Bayes 模型在非最优区域采样较多。但是最后，模型在最佳区域中采样更多，因此找到越来越好的参数。

![](../Images/6a64b301d8e48ce1e6734d62370544fe.png)

表 4:贝叶斯超参数优化的优化超参数及其搜索空间。

![](../Images/966bbe6affc2978e2a6bad3c2b6b909a.png)

表 5:通过贝叶斯超参数搜索找到的最佳超参数。

![](../Images/d2e917917cdd0d4ad2e3e4d43c9a7123.png)

图 9:贝叶斯优化的收敛图。该图显示了迭代次数和获得的最佳 f1 分数。

# 结果

使用在方法部分中找到的所有发现来训练鸟类分类器。鸟类分类器现在已经训练了 30 个时期，根据验证 f1 分数的最佳模型被存储为 Tensorflow 模型(图 10)。之后，加载验证 f1 分数为 96.2%的最佳模型，并在保留测试集上进行评估，以检查最终 birds 分类器在真实世界数据上的性能。最佳模型在保留测试集上获得了几乎 96%的 f1 分数，这与在训练过程中获得的最佳验证 f1 分数几乎相同。这表明，该模型在真实世界数据上表现得非常好，并且该模型在训练和验证数据上没有过度拟合。

![](../Images/3133ce2698f7e9fc07a6fab2000059bc.png)

图 10:用于训练最终鸟类分类器的训练指标。

# 结论

最终的鸟类分类器在保留测试集上实现了几乎 96%的 f1 分数。由于其良好的性能，DenseNet121 被用作 CNN 的底层架构。作为目标图像尺寸，使用 192x192 像素的尺寸。训练集不是过采样的，因为在过采样的训练集上训练的模型与在非过采样的训练集上训练的模型获得了近似相同的验证 f1 分数。利用贝叶斯超参数搜索优化了一些超参数。

# 观点

在本系列的第二部分中，我开发了一个 API，前端用 HTML 编写，后端应用程序使用 Python 库 Flask。如果你对它的工作原理感兴趣，请阅读第二篇文章。你可以在这里找到第二篇[。总的来说，我总是建议您将最终的机器学习应用程序嵌入到可部署的应用程序中，因为这是机器学习工程师在一天结束时需要考虑的问题。](/full-deep-learning-portfolio-project-part-2-e37d09a451fa)

谢谢你把我的文章看完！我希望你喜欢这篇文章和我参与的项目。如果你想在未来阅读更多类似的文章，请关注我，保持更新。