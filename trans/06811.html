<html>
<head>
<title>Borderless Tables Detection with Deep Learning and OpenCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度学习和OpenCV的无边界表格检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/borderless-tables-detection-with-deep-learning-and-opencv-ebf568580fe2?source=collection_archive---------2-----------------------#2021-06-20">https://towardsdatascience.com/borderless-tables-detection-with-deep-learning-and-opencv-ebf568580fe2?source=collection_archive---------2-----------------------#2021-06-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8c72" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">构建您自己的对象检测器并将图像中的半结构化数据块转换为机器可读文本的方法</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/72bcb80c1d7f72d54ea7fc2a2fc8fdcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*0IX1PpWDeeA-G4WbZTyCfQ.gif"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="e4b7" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">文档解析</h1><p id="8304" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">文档解析是将信息转换成有价值的业务数据的第一步。这些信息通常以表格形式存储在商业文档中，或者存储在没有明显图形边界的数据块中。一个无边界的表格可能有助于简化我们人类对半结构化数据的视觉感知。从机器阅读的角度来看，这种在页面上呈现信息的方式有很多缺点，使得很难将属于假定的表格结构的数据与周围的文本上下文分开。</p><p id="d5e6" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">表格数据提取作为一项业务挑战，可能有几个特别的或启发式的基于规则的解决方案，对于布局或风格稍有不同的表，这些解决方案肯定会失败。在大规模上，应该使用更通用的方法来识别图像中的表格状结构，更具体地说，应该使用基于深度学习的对象检测方法。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="b7a2" class="kv kw iq bd kx ky mw la lb lc mx le lf jw my jx lh jz mz ka lj kc na kd ll lm bi translated">本教程的范围:</h1><ul class=""><li id="b38f" class="nb nc iq lp b lq lr lt lu lw nd ma ne me nf mi ng nh ni nj bi translated">基于深度学习的物体检测</li><li id="c795" class="nb nc iq lp b lq nk lt nl lw nm ma nn me no mi ng nh ni nj bi translated">安装和设置<strong class="lp ir"> TF2对象检测API </strong></li><li id="deb2" class="nb nc iq lp b lq nk lt nl lw nm ma nn me no mi ng nh ni nj bi translated">数据准备</li><li id="d257" class="nb nc iq lp b lq nk lt nl lw nm ma nn me no mi ng nh ni nj bi translated">模型配置</li><li id="1abb" class="nb nc iq lp b lq nk lt nl lw nm ma nn me no mi ng nh ni nj bi translated">模型训练和保存</li><li id="ed77" class="nb nc iq lp b lq nk lt nl lw nm ma nn me no mi ng nh ni nj bi translated">现实生活图像中的表格检测和细胞识别</li></ul></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="7e1a" class="kv kw iq bd kx ky mw la lb lc mx le lf jw my jx lh jz mz ka lj kc na kd ll lm bi translated">基于深度学习的物体检测</h1><p id="1ffd" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">著名的CV研究员Adrian Rosebrock在他的“<a class="ae mj" href="http://gentle guide to deep learning object detection" rel="noopener ugc nofollow" target="_blank">深度学习对象检测温和指南</a>”中指出:“对象检测，无论是通过深度学习还是其他计算机视觉技术来执行，都建立在图像分类的基础上，并寻求精确定位对象出现的区域”。正如他所建议的，建立自定义对象检测器的一种方法是选择任何分类器，并在此之前使用一种算法来选择和提供图像中可能包含对象的区域。在这种方法中，您可以自由决定是否使用传统的ML算法进行图像分类(<a class="ae mj" href="https://www.pyimagesearch.com/2019/05/27/keras-feature-extraction-on-large-datasets-with-deep-learning/" rel="noopener ugc nofollow" target="_blank">是否使用<strong class="lp ir"> CNN </strong>作为特征提取器</a>)或者<a class="ae mj" href="https://www.pyimagesearch.com/2019/05/27/keras-feature-extraction-on-large-datasets-with-deep-learning/" rel="noopener ugc nofollow" target="_blank">训练一个简单的神经网络</a>来处理任意的大型数据集。尽管其效率已被证明，但这种被称为<strong class="lp ir"> R-CNN </strong>的两阶段对象检测范式仍然依赖于繁重的计算，不适合实时应用。</p><p id="aae5" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">上述帖子中还进一步说，“另一种方法是将预先训练好的分类网络作为多组件深度学习对象检测框架中的基础(骨干)网络(如<strong class="lp ir">更快的R-CNN </strong>、<strong class="lp ir"> SSD </strong>，或<strong class="lp ir"> YOLO </strong>)。因此，您将受益于其完整的端到端可培训架构。</p><p id="4638" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">无论选择是什么，它都会让你进一步了解重叠边界框的问题。在下文中，我们将触及为此目的执行的非最大抑制。</p><p id="0db2" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">同时，请参考任意新类别的对象检测器的迁移学习流程图(参见<a class="ae mj" href="https://viewer.diagrams.net/?target=blank&amp;highlight=0000ff&amp;edit=_blank&amp;layers=1&amp;nav=1&amp;title=Copy%20of%20obj_detection.html#Uhttps%3A%2F%2Fdrive.google.com%2Fuc%3Fid%3D1ej4QfW4xK1z4S1xWv0qu8NeUfktFsFiO%26export%3Ddownload" rel="noopener ugc nofollow" target="_blank">交互视图</a>):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/42b2a5f1837787ad628595de8f42fb5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jq83BOA6zhqBWX5SDoezlA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="94b9" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">由于第二种方法速度更快、更简单且更准确，它已经被广泛用于商业和科学论文中的表格结构识别。例如，您可以很容易地找到使用<a class="ae mj" rel="noopener" target="_blank" href="/pdfs-parsing-using-yolov3-987c85c639dc"><strong class="lp ir">【YOLO】</strong></a>、<a class="ae mj" href="https://djajafer.medium.com/pdf-table-extraction-with-keras-retinanet-173a13371e89" rel="noopener"> <strong class="lp ir"> RetinaNet </strong> </a>、<a class="ae mj" href="https://github.com/DevashishPrasad/CascadeTabNet" rel="noopener ugc nofollow" target="_blank"> <strong class="lp ir"> Cascade R-CNN </strong> </a>和其他框架从PDF文档中提取表格数据的实现。</p><p id="e25d" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">继续学习本教程，您将了解如何使用像<strong class="lp ir"> TensorFlow (TF2)对象检测API </strong>这样的工具，使用预先训练的最先进的模型轻松构建您的自定义对象检测器。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="4fd7" class="kv kw iq bd kx ky mw la lb lc mx le lf jw my jx lh jz mz ka lj kc na kd ll lm bi translated">开始之前</h1><p id="c4c0" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">请注意，这不会是对深度学习对象检测的详尽介绍，而是对如何在特定开发环境(<strong class="lp ir"> Anaconda/Win10 </strong>)中与<strong class="lp ir"> TF2对象检测API </strong>(和其他工具)交互以解决明显的业务问题(如无边界表格检测)的分阶段描述。在这篇文章的其余部分，我们将会比其他人更详细地介绍建模过程的一些方面和结果。尽管如此，在我们的实验之后，您将会找到基本的代码示例。要继续，你应该安装好<strong class="lp ir"> Anaconda </strong>和<strong class="lp ir">宇宙魔方</strong>，下载<strong class="lp ir"> protobuf </strong>并添加到PATH。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="8f5d" class="kv kw iq bd kx ky mw la lb lc mx le lf jw my jx lh jz mz ka lj kc na kd ll lm bi translated">TF2对象检测API的安装和设置</h1><p id="97d2" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在您选择的路径下创建一个新文件夹，我们在下文中称之为<em class="nq">‘项目的根文件夹’</em>。从您的终端窗口逐一运行以下命令:</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="4d54" class="nw kw iq ns b gy nx ny l nz oa"><em class="nq"># from &lt;project’s root folder&gt;<br/>conda create -n &lt;new environment name&gt; \<br/>python=3.7 \<br/>tensorflow=2.3 \<br/>numpy=1.17.4 \<br/>tf_slim \<br/>cython \<br/>git</em></span><span id="fe3d" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">conda activate &lt;new environment name&gt;</em></span><span id="7381" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">git clone </em><a class="ae mj" href="https://github.com/tensorflow/models.git" rel="noopener ugc nofollow" target="_blank"><em class="nq">https://github.com/tensorflow/models.git</em></a></span><span id="ba8f" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI</em></span><span id="5ac6" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">cd models\research<br/></em></span><span id="35d8" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq"># from &lt;project’s root folder&gt;\models\researchprotoc object_detection\protos\*.proto — python_out=.</em></span><span id="87c1" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">copy object_detection\packages\tf2\setup.py .</em></span><span id="4c86" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">python setup.py install</em></span><span id="734a" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">python object_detection\builders\model_builder_tf2_test.py</em></span><span id="f06b" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">conda install imutils pdf2image beautifulsoup4 typeguard</em></span><span id="ff6e" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">pip install tf-image</em></span><span id="735c" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">copy object_detection\model_main_tf2.py ..\..\workspace\.</em></span><span id="76a4" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">copy object_detection\exporter_main_v2.py ..\..\workspace\.</em></span><span id="819f" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">cd ..\..</em></span></pre><p id="9c1f" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">它将在您的本地环境中安装使用<strong class="lp ir"> TF2对象检测API </strong>所需的核心和一些助手库，并负责您的训练数据集。从这一步开始，你应该能够从<strong class="lp ir"> TF2模型园</strong>下载一个预训练模型，并且<a class="ae mj" href="https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/auto_examples/index.html" rel="noopener ugc nofollow" target="_blank">从它</a>得到相应预训练类的推论。</p><h1 id="48e6" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">数据准备</h1><p id="c103" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我希望到目前为止你已经成功了！请记住，我们的最终目标是使用预训练模型来执行迁移学习，以检测单个“无边界”类，而该模型在初始训练时对此一无所知。如果你研究过我们的迁移学习流程图，你应该已经注意到我们整个过程的起点是一个数据集，不管有没有注释。如果你需要注释，有<a class="ae mj" href="https://lionbridge.ai/articles/image-annotation-tools-for-computer-vision/" rel="noopener ugc nofollow" target="_blank">吨的解决方案</a>可用。选择一个能给你XML注释的，与我们的例子兼容的。</p><p id="6cd8" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">我们拥有的注释数据越多越好(<em class="nq">重要:这篇文章的所有表格图片都选自开放的数据源，如</em><a class="ae mj" href="https://github.com/DevashishPrasad/CascadeTabNet#7-datasets" rel="noopener ugc nofollow" target="_blank"><em class="nq">this</em></a><em class="nq">，并由作者</em>注释/重新注释)。但是一旦你尝试手工标注数据，你就会明白这项工作有多乏味。不幸的是，没有一个流行的用于图像增强的python库能够处理选定的边界框。在没有收集和注释新数据的高成本的情况下，增加初始数据集符合我们的利益。这就是一个<a class="ae mj" rel="noopener" target="_blank" href="/tensorflow-and-image-augmentation-3610c6c243a2"> <strong class="lp ir"> tf-image </strong> </a>包将变得方便的情况。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="13cb" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">上述脚本将随机转换原始图像和对象的边界框，并将新图像和相应的XML文件保存到磁盘。这就是我们的数据集经过三倍扩展后的样子:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/e1e5b77d0574fee36a38d34e00b26f71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8oOOVIRboLMC3sCS"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="ceb2" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">接下来的步骤将包括将数据分成训练集和测试集。基于<strong class="lp ir"> TF2对象检测API </strong>的模型需要一种特殊的格式用于所有输入数据，称为<em class="nq"> TFRecord </em>。你会在<a class="ae mj" href="https://github.com/woldemarg/borderless_tbls_detection" rel="noopener ugc nofollow" target="_blank"> Github库</a>中找到相应的脚本来拆分和转换你的数据。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="de21" class="kv kw iq bd kx ky mw la lb lc mx le lf jw my jx lh jz mz ka lj kc na kd ll lm bi translated">模型配置</h1><p id="7145" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在这一步，我们将创建一个标签映射文件(<em class="nq">)。pbtxt </em>)将我们的类标签(‘无边界’)链接到某个整数值。<strong class="lp ir"> TF2对象检测API </strong>需要此文件用于训练和检测目的:</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="ea86" class="nw kw iq ns b gy nx ny l nz oa"><em class="nq">item {<br/>id: 1<br/>name: ‘borderless’<br/>}</em></span></pre><p id="2035" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">实际的模型配置发生在相应的<em class="nq"> pipeline.config </em>文件中。你可以阅读<a class="ae mj" href="https://neptune.ai/blog/how-to-train-your-own-object-detector-using-tensorflow-object-detection-api" rel="noopener ugc nofollow" target="_blank">对模型配置</a>的介绍，并决定是手动配置文件还是通过运行<a class="ae mj" href="https://github.com/woldemarg/borderless_tbls_detection" rel="noopener ugc nofollow" target="_blank"> Github库</a>中的脚本来配置文件。</p><p id="1e45" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">到目前为止，您的项目的根文件夹可能如下所示:</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="36e3" class="nw kw iq ns b gy nx ny l nz oa">📦borderless_tbls_detection<br/>┣ 📂images<br/>┃ ┣ 📂processed<br/>┃ ┃ ┣ 📂all_annots<br/>┃ ┃ ┃ ┗ 📜…XML<br/>┃ ┃ ┗ 📂all_images<br/>┃ ┃ ┃ ┗ 📜…jpg<br/>┃ ┣ 📂splitted<br/>┃ ┃ ┣ 📂test_set<br/>┃ ┃ ┃ ┣ 📜…jpg<br/>┃ ┃ ┃ ┗ 📜…XML<br/>┃ ┃ ┣ 📂train_set<br/>┃ ┃ ┃ ┣ 📜…jpg<br/>┃ ┃ ┃ ┗ 📜…XML<br/>┃ ┃ ┗ 📂val_set<br/>┃ ┗ 📜xml_style.XML<br/>┣ 📂models<br/>┃ ┗ 📂…<br/>┣ 📂scripts<br/>┃ ┣ 📜…py<br/>┣ 📂train_logs<br/>┣ 📂workspace<br/>┃ ┣ 📂data<br/>┃ ┃ ┣ 📜label_map.pbtxt<br/>┃ ┃ ┣ 📜test.csv<br/>┃ ┃ ┣ 📜test.record<br/>┃ ┃ ┣ 📜train.csv<br/>┃ ┃ ┣ 📜train.record<br/>┃ ┃ ┣ 📜val.csv<br/>┃ ┃ ┗ 📜val.record<br/>┃ ┣ 📂models<br/>┃ ┃ ┗ 📂efficientdet_d1_coco17_tpu-32<br/>┃ ┃ ┃ ┗ 📂v1<br/>┃ ┃ ┃ ┃ ┗ 📜pipeline.config<br/>┃ ┣ 📂pretrained_models<br/>┃ ┃ ┗ 📂datasets<br/>┃ ┃ ┃ ┣ 📂efficientdet_d1_coco17_tpu-32<br/>┃ ┃ ┃ ┃ ┣ 📂checkpoint<br/>┃ ┃ ┃ ┃ ┃ ┣ 📜checkpoint<br/>┃ ┃ ┃ ┃ ┃ ┣ 📜ckpt-0.data-00000-of-00001<br/>┃ ┃ ┃ ┃ ┃ ┗ 📜ckpt-0.index<br/>┃ ┃ ┃ ┃ ┣ 📂saved_model<br/>┃ ┃ ┃ ┃ ┃ ┣ 📂assets<br/>┃ ┃ ┃ ┃ ┃ ┣ 📂variables<br/>┃ ┃ ┃ ┃ ┃ ┃ ┣ 📜variables.data-00000-of-00001<br/>┃ ┃ ┃ ┃ ┃ ┃ ┗ 📜variables.index<br/>┃ ┃ ┃ ┃ ┃ ┗ 📜saved_model.pb<br/>┃ ┃ ┃ ┃ ┗ 📜pipeline.config<br/>┃ ┃ ┃ ┗ 📜efficientdet_d1_coco17_tpu-32.tar.gz<br/>┃ ┣ 📜exporter_main_v2.py<br/>┃ ┗ 📜model_main_tf2.py<br/>┣ 📜config.py<br/>┗ 📜setup.py</span></pre></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="40f6" class="kv kw iq bd kx ky mw la lb lc mx le lf jw my jx lh jz mz ka lj kc na kd ll lm bi translated">模型训练和保存</h1><p id="dcbd" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我们做了很多工作才来到这里，并为开始训练做好了一切准备。下面是如何做到这一点:</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="6f91" class="nw kw iq ns b gy nx ny l nz oa"><em class="nq"># from &lt;project’s root folder&gt;<br/>tensorboard — logdir=&lt;logs folder&gt;</em></span><span id="5b54" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">set NUM_TRAIN_STEPS=1000</em></span><span id="c46d" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">set CHECKPOINT_EVERY_N=1000</em></span><span id="79de" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">set PIPELINE_CONFIG_PATH=&lt;path to model’s pipeline.config&gt;</em></span><span id="6377" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">set MODEL_DIR=&lt;logs folder&gt;</em></span><span id="510e" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">set SAMPLE_1_OF_N_EVAL_EXAMPLES=1</em></span><span id="d57c" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">set NUM_WORKERS=1</em></span><span id="57bc" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq">python workspace\model_main_tf2.py \<br/> — pipeline_config_path=%PIPELINE_CONFIG_PATH% \<br/> — model_dir=%MODEL_DIR% \<br/> — checkpoint_every_n=%CHECKPOINT_EVERY_N% \<br/> — num_workers=%NUM_WORKERS% \<br/> — num_train_steps=%NUM_TRAIN_STEPS% \<br/> — sample_1_of_n_eval_examples=%SAMPLE_1_OF_N_EVAL_EXAMPLES% \<br/> — alsologtostderr</em></span><span id="6cef" class="nw kw iq ns b gy ob ny l nz oa"><em class="nq"># (optionally in parallel terminal window)<br/>python workspace\model_main_tf2.py \<br/> — pipeline_config_path=%PIPELINE_CONFIG_PATH% \<br/> — model_dir=%MODEL_DIR% \<br/> — checkpoint_dir=%MODEL_DIR%</em></span></pre><p id="19f0" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">现在，您可以在浏览器中监控培训过程，网址为<a class="ae mj" href="http://localhost:6006" rel="noopener ugc nofollow" target="_blank"> http://localhost:6006 </a>:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/403257c6fb0b037c49e41f6bd31f9983.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ai4NJ0S4ogReYiDf"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="fb1c" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">要在训练完成后导出您的模型，只需运行以下命令:</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="f938" class="nw kw iq ns b gy nx ny l nz oa"><em class="nq"># from &lt;project’s root folder&gt;<br/>python workspace\exporter_main_v2.py \<br/> — input_type=image_tensor \<br/> — pipeline_config_path=%PIPELINE_CONFIG_PATH% \<br/> — trained_checkpoint_dir=%MODEL_DIR% \<br/> — output_directory=saved_models\efficientdet_d1_coco17_tpu-32</em></span></pre></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="4614" class="kv kw iq bd kx ky mw la lb lc mx le lf jw my jx lh jz mz ka lj kc na kd ll lm bi translated">图像中的表格检测和细胞识别</h1><h2 id="c1ea" class="nw kw iq bd kx og oh dn lb oi oj dp lf lw ok ol lh ma om on lj me oo op ll oq bi translated">NMS和欠条</h2><p id="80f4" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">由于我们已经保存了新的微调模型，我们可以开始检测文档中的表格。前面我们提到了一个物体检测系统不可避免的问题——重叠包围盒。考虑到我们正在处理的无边界表格的过度分段性质，我们的模型偶尔会为单个对象输出比您预期的更多的边界框。毕竟，这是我们的目标探测器正在正确发射的标志。为了处理重叠边界框(指同一对象)的移除，我们可以使用<a class="ae mj" href="https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/" rel="noopener ugc nofollow" target="_blank">非最大抑制</a>。</p><p id="44df" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">неre是我们的检测器在执行非最大值抑制前后的推断结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/82dba89b06d5b8d730275789024e905d.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/0*omYQoYUbW8DM0-we"/></div></figure><p id="bfa6" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">看起来我们已经成功地解决了预测重叠矩形包围物体的问题，但是我们的检测仍然达不到真实边界框。这是必然的，因为没有完美的模型。我们可以用交并比(IoU)来测量检波器的精度。作为分子，我们计算预测边界框和实际边界框之间的重叠面积。作为分母，我们计算由预测边界框和实际边界框包围的区域。IoU得分&gt; 0.5通常被认为是“好”的预测[ <a class="ae mj" href="https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/" rel="noopener ugc nofollow" target="_blank"> Rosenbrock，2016 </a> ]。</p><p id="253c" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">对于我们测试集中的一些图像，我们有以下指标:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/b547d617cd023e170f5dd5f73242fa2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*00yH19i1667ePyXE"/></div></div></figure></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h2 id="f640" class="nw kw iq bd kx og oh dn lb oi oj dp lf lw ok ol lh ma om on lj me oo op ll oq bi translated">细胞识别和OCR</h2><p id="993d" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">这将是我们的三部分算法的最后步骤:在(1)表格被检测到之后，我们将(2)用<strong class="lp ir"> OpenCV </strong>识别它的单元格(因为表格是无边界的)并将它们彻底分配到适当的行和列，以进一步进行(3)用<strong class="lp ir">pytesserac</strong>通过光学字符识别(OCR)从每个分配的单元格中提取文本。</p><p id="58e9" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">大多数细胞识别算法都是基于表格的行结构。清晰和可检测的线条对于正确识别细胞是必要的。由于我们的表格没有空白，我们将手动重建表格网格，在经过阈值处理和调整大小的图像上搜索白色垂直和水平间隙。这种方法有点类似于这里使用的<a class="ae mj" rel="noopener" target="_blank" href="/data-extraction-from-a-pdf-table-with-semi-structured-layout-ef694f3f8ff1"/>。</p><p id="643c" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">完成这一步后，我们可以用<strong class="lp ir"> OpenCV </strong>找到轮廓(即我们的单元格边界)，将它们分类并分配到一个类似表格的结构中:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="804a" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">图表上显示了整个工作流程:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi os"><img src="../Images/6d5fc4bf48feff0815baca92f9d27c1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tleCV_3GfTS7bqRc"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="0445" class="pw-post-body-paragraph ln lo iq lp b lq mk jr ls lt ml ju lv lw mm ly lz ma mn mc md me mo mg mh mi ij bi translated">至此，我们已经将所有的盒子和它们的值按正确的顺序排序了。剩下的工作就是获取每个基于图像的盒子，通过膨胀和腐蚀为OCR做准备，并让<strong class="lp ir">pytesserac</strong>识别包含的字符串:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/acc05e4a6c8df0ae80c0e5ebd96e7d8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*V_brvVvaaAsLEh9l"/></div></div></figure></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="9a4a" class="kv kw iq bd kx ky mw la lb lc mx le lf jw my jx lh jz mz ka lj kc na kd ll lm bi translated">最后的想法</h1><p id="69c8" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">啊，走了很长一段路！我们的自定义对象检测器可以识别文档中的半结构化信息块(也称为无边界表格),进一步将它们转换为机器可读的文本。尽管这个模型没有我们预期的那么精确。因此，我们有很大的改进空间:</p><ul class=""><li id="ddd3" class="nb nc iq lp b lq mk lt ml lw ot ma ou me ov mi ng nh ni nj bi translated">在我们模型的配置文件中进行更改</li><li id="0e1d" class="nb nc iq lp b lq nk lt nl lw nm ma nn me no mi ng nh ni nj bi translated">与来自<a class="ae mj" href="https://github.com/tensorflow/models" rel="noopener ugc nofollow" target="_blank">模型园</a>的其他模型玩耍</li><li id="3f40" class="nb nc iq lp b lq nk lt nl lw nm ma nn me no mi ng nh ni nj bi translated">执行更保守的数据扩充</li><li id="4a11" class="nb nc iq lp b lq nk lt nl lw nm ma nn me no mi ng nh ni nj bi translated">尝试重新使用<a class="ae mj" href="https://github.com/doc-analysis/TableBank/blob/master/MODEL_ZOO.md" rel="noopener ugc nofollow" target="_blank">模型，之前在表格数据</a>上训练过(虽然不可用于TF2对象检测API)</li></ul></div></div>    
</body>
</html>