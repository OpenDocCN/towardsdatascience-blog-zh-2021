<html>
<head>
<title>Building a Linear Regression by Hand</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">手动构建线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-linear-regression-by-hand-b930e63bf0ae?source=collection_archive---------13-----------------------#2021-10-07">https://towardsdatascience.com/building-a-linear-regression-by-hand-b930e63bf0ae?source=collection_archive---------13-----------------------#2021-10-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/22939c5fcdf930793d96a33bae8c3f96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*b6jMAo3meAa0gPFe"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">由<a class="ae jd" href="https://unsplash.com/@michalmatlon" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的图像</p></figure><h2 id="3ebf" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/getting-started" rel="noopener" target="_blank">入门</a></h2><div class=""/><div class=""><h2 id="2190" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">让我们使用Python来创建估计我们自己的线和验证我们的结果所需的所有方程，而不依赖于库来训练我们的模型！</h2></div><p id="437d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi ma translated"><span class="l mb mc md bm me mf mg mh mi di"> W </span>我们基于x的值采用线性回归来预测Y的值。因为我们需要知道Y，所以这是一种监督学习方法。线性回归分为两种类型:基本的和多重的。让我们从简单的开始。所有代码的笔记本这里是<a class="ae jd" href="https://colab.research.google.com/drive/1vuSLuMxZcFaXu0Z4KVFkJCuWP4mHheyJ?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里是</a>。所有的方程式都是用乳胶做的<a class="ae jd" href="https://snip.mathpix.com/dairenkonmajime/notes/note-1" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="mj mk ml mm gt is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="0c6f" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在我们开始之前，理解线性回归是一种参数方法是至关重要的。</p><p id="96c7" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq">参数化方法</strong>:</p><p id="c184" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">1.它预先假定了函数的形状。</p><p id="28da" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">2.它将估计f (X)的问题简化为估计一组参数。这种假设简化了任务，因为估计参数集合比使用完全任意的函数更容易。</p><p id="02c4" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">3.这些方法中最困难的方面是做出正确的估计。我们只能猜测曲线的正确形式，从而导致错误的预测。</p><p id="7aed" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">因此，我们必须估计参数，使我们能够创建一条最接近Y值的线，不管是已知的还是未知的。</p><h1 id="8944" class="mp mq jg bd mr ms mt mu mv mw mx my mz kv na kw nb ky nc kz nd lb ne lc nf ng bi translated">简单线性回归</h1><figure class="mj mk ml mm gt is gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/7e0a35e55fe201bd1cc79ce76004d9ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:468/format:webp/1*CtAntI12L3Y54wzH6Crszg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="fad3" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这是简单线性回归的函数。这个方程的变体可以在统计文献中找到，但是它们都有相同的实质。可能是W0和W1，α和β，等等。</p><p id="9682" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">不过，我想让你注意一件事。注意符号≈。当我们估计值时，我们的主要目标是使我们的预测接近Y到x的真实值。也就是说，我们的目标是尽可能地最小化真实值和估计值之间的差异。</p><p id="705b" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">因此，当处理f (X) = Y的估计，或者更具体地，f(X)的参数，其中f (X) = Y或者Y = f (X)时，我们的目标不是完美地定义f(X)，而是估计最好地代表f(X)的参数。但是，因为y = ^f (X)+<strong class="lg jq">+<em class="ni">e</em></strong>，我们对f(x)的估计将等于y加上<strong class="lg jq"> <em class="ni"> e </em> </strong>后的余数。</p><p id="190d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">其中Y = ^f (X) + <strong class="lg jq"> <em class="ni"> e </em> </strong>，则^f (X) = ^B0 + ^B1X = ^Y.也就是说，为了估计^Y，首先要估计^f (X)、^B0、B1的参数。Y = ^Y + <strong class="lg jq"> <em class="ni"> e </em> </strong>既然Y = ^f (X) + <strong class="lg jq"> <em class="ni"> e </em> </strong>和<strong class="lg jq"> <em class="ni"> </em> </strong> ^f (X) = ^Y.</p><p id="c548" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">考虑到这一点，我们将使用的公式是:</p><figure class="mj mk ml mm gt is gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/0b80aebb4c1d4bdf1a19f4ae44655ffa.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*YFtVdXApjWTUXPl9nDkm2g.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="c193" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">不再分心。</p><h2 id="a75c" class="nk mq jg bd mr nl nm dn mv nn no dp mz ln np nq nb lr nr ns nd lv nt nu nf jm bi translated"><strong class="ak">什么是B0和B1 </strong>？</h2><p id="b842" class="pw-post-body-paragraph le lf jg lg b lh nv kq lj lk nw kt lm ln nx lp lq lr ny lt lu lv nz lx ly lz ij bi translated">BO表示截距，即X = 0时的Y值，或线性回归线开始处的Y值。这里有一个例子。我们希望根据活动中的投资金额来估计销售转化的数量。不投钱能卖多少？</p><p id="74db" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">B1呢？斜率由B1的值表示。基本决定了趋势线。这在实践中是如何运作的？考虑根据体重计算身高的例子。身高以厘米为单位，体重以公斤为单位。我们发现斜率为2.5。表示体重每增加一公斤，人的身高就增加2.5毫米。</p><p id="e19e" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">假设我们知道B0和B1是什么，我们如何估计它们呢？这些参数可以用多种方法来估计。首先，让我们看看普通的最小二乘法(OLS)，这是最常见和最简单的方法之一。要估算B0，首先要估算B1。</p><blockquote class="oa ob oc"><p id="e579" class="le lf ni lg b lh li kq lj lk ll kt lm od lo lp lq oe ls lt lu of lw lx ly lz ij bi translated">在统计学中，<strong class="lg jq">普通最小二乘法</strong> ( <strong class="lg jq"> OLS </strong>)是一种估计线性回归模型中未知参数的线性最小二乘法。OLS通过最小二乘法原理选择一组解释变量的线性函数的参数:最小化给定数据集中观察到的因变量(被观察变量的值)和自变量的线性函数预测的变量之间的差的平方和。—来源:<a class="ae jd" href="https://en.wikipedia.org/wiki/Ordinary_least_squares" rel="noopener ugc nofollow" target="_blank">维基百科</a>。</p></blockquote><p id="871b" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们看看这意味着什么。我们想用这种方法达到什么目的？减少一些东西。应该尽量减少什么？观察数据和估计数据之差的平方和。让我们把这个等式放在一起。</p><p id="39de" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">反过来，我们有观察值和估计值之间的差异。作为回归结果的估计值称为估计值。观察值是真实值。因此，</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="ef55" class="nk mq jg oh b gy ol om l on oo">observedValue - estimatedValue</span></pre><p id="62cf" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在，<em class="ni">平方</em>估计值和观测值之差。因此:</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="7e54" class="nk mq jg oh b gy ol om l on oo">square (observedValue - estimatedValue)</span></pre><p id="9c44" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">最后，观察数据和估计数据之间差异的平方和。：</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="2388" class="nk mq jg oh b gy ol om l on oo">sum (square (observedValue - estimatedValue))</span></pre><p id="cb3b" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">好的，但是这个和的意义是什么？observedValue和estimatedValue是值。考虑一下:我们有两列，Y和Y。第一列是真实值，观察值，第二列是估计值。正如我之前提到的，我们构建了一个模型，并利用X来估计Y，从而得到Y。假设每一列都有三个值，Y = [5，9，2]和Y = [6，7，2]。使用我们的公式，我们得到以下结果:</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="2242" class="nk mq jg oh b gy ol om l on oo">(5–6)²<br/>(9–7)²<br/>(2–2)²</span></pre><p id="8696" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">总数是这三个操作的总和。结果是，(5–6)+(9–7)+(2–2)。作为这些程序的结果，我们得到了残差平方和(RSS)。这种情况下使用RSS = 5。我们的目标是使用OLS来减少RSS。</p><p id="70ea" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">RSS的一般公式是:</p><figure class="mj mk ml mm gt is gh gi paragraph-image"><div class="gh gi op"><img src="../Images/869713518d44751a51387f6f383770b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*pNSzREKesxSIgfOLHX4nJQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="4f23" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们如何用Python来编码呢？</p><figure class="mj mk ml mm gt is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="ef23" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">OLS是减少这种RSS的众多方法之一。另一种做法是，我不知道，猜测B0和B1的各种参数，计算所有的误差，选择最小的一个，但是发现的最小的误差可能没有那么微小。我们将以这样的方式结束。当我们有少量的功能和列时，OLS是最快捷和最容易使用的方法。</p><p id="a004" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们将在文章中使用虚构的数据。</p><figure class="mj mk ml mm gt is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="d6b7" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在本例中，我制作了两个数组来表示X和y。我创建了1000个值，以便提供一个更有趣的视角。我把X和Y分成四份。训练数据将包含80%的X和Y值(X训练和Y训练)，而20%的数据将用于测试(X测试和Y测试)。</p><p id="296b" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在估计B0和B1之前，我们先讨论一下假设。线性回归的基本假设是什么？我们利用线性回归来预测新值或做出推论。有许多方法可以估计回归中的参数。许多方法，如OLS，需要特定的假设，以使他们的结论尽可能准确和公正。这些前提不必在每个线性回归中都严格遵循！</p></div><div class="ab cl oq or hu os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="ij ik il im in"><h2 id="ce27" class="nk mq jg bd mr nl nm dn mv nn no dp mz ln np nq nb lr nr ns nd lv nt nu nf jm bi translated">因变量和自变量必须有线性关系。</h2><p id="67e9" class="pw-post-body-paragraph le lf jg lg b lh nv kq lj lk nw kt lm ln nx lp lq lr ny lt lu lv nz lx ly lz ij bi translated">当使用线性回归进行预测时，满足这一要求是合乎逻辑的。本质上，线性回归将通过数据画一条直线。如果数据没有线性关系，模型就无法处理数据的复杂性。我们如何检验这个概念？</p><p id="1079" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在大多数假设下，有两种形式的确认。有图形确认，也有数学确认。只要可行，我将同时介绍这两种方法。当事情变得太复杂时，我就只覆盖视觉效果。</p><p id="ea76" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">所以我们可以把X数据和Y数据对应起来，寻找趋势。让我们执行这个命令，看看会发生什么。</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="45c5" class="nk mq jg oh b gy ol om l on oo">plt.figure(figsize=(10,10))<br/>plt.scatter(X_train, y_train)<br/>plt.show()</span></pre><figure class="mj mk ml mm gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ox"><img src="../Images/2873d097a6cf00fdbe5cb301ab42055d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C-CL8aiXOhEux6bUIvmvcA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="9def" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对我来说，它似乎是线性的！我甚至能看到一条直线！但是这有什么意义呢？我不确定你，但视觉确认并不能完全满足我。当然，你的视角是由你的时间、金钱和教育决定的。然而，我们在这里拥有世界上所有的时间，它是免费的，我们有足够的知识来使用替代方法。</p><p id="bc47" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">除了图表，我们如何评估线性关系？计算X和Y之间的相关系数。但是这种相关性到底是什么呢？</p><blockquote class="oa ob oc"><p id="9b79" class="le lf ni lg b lh li kq lj lk ll kt lm od lo lp lq oe ls lt lu of lw lx ly lz ij bi translated">在<a class="ae jd" href="https://en.wikipedia.org/wiki/Statistics" rel="noopener ugc nofollow" target="_blank">统计中</a>、<strong class="lg jq">相关</strong>或<strong class="lg jq">相关</strong>是两个<a class="ae jd" href="https://en.wikipedia.org/wiki/Random_variable" rel="noopener ugc nofollow" target="_blank">随机变量</a>或<a class="ae jd" href="https://en.wikipedia.org/wiki/Bivariate_data" rel="noopener ugc nofollow" target="_blank">二元数据</a>之间的任何统计关系，无论<a class="ae jd" href="https://en.wikipedia.org/wiki/Causality" rel="noopener ugc nofollow" target="_blank">是否为因果</a>。从最广泛的意义上来说，<strong class="lg jq">相关性</strong>是任何统计关联，尽管它通常指一对变量线性<a class="ae jd" href="https://en.wikipedia.org/wiki/Line_(geometry)" rel="noopener ugc nofollow" target="_blank">相关的程度。依赖性现象的常见例子包括父母及其子女的身高之间的相关性，以及商品价格和消费者愿意购买的数量之间的相关性，正如所谓的需求曲线中所描述的那样..—来源:维基百科。</a></p></blockquote><p id="82f5" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在这个简短的解释之后，我将重申一个统计学家的口头禅:相关性并不意味着因果关系！在我们对因果关系做出明确的判断之前，我们需要进行一些统计测试。但这是另一天的话题！</p><p id="0734" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在我们的数据中，我们希望计算X和y之间的相关程度。有各种方法来解决这个问题。皮尔逊系数是最常用的。其通式如下:</p><figure class="mj mk ml mm gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oy"><img src="../Images/afb94db3883e28a68f0d216ff659712d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J7wKZPfmiTwtKsJfcpRSRw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="ee5d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">也就是说，两个变量的标准差除以它们的协方差。让我们把事情分解一下，这样你能更好地理解它。我们将看两个部分。X相对于Y的协方差，以及X和Y的方差。我将把这些信息留给方差的概念，其中包括一些图形解释。绝对值得一看。总之，协方差表示两个变量协同波动的程度。</p><p id="4552" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在Python中我们如何计算两个变量的协方差？让我们用这个公式:</p><figure class="mj mk ml mm gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oz"><img src="../Images/ee334d3656cd11ec5d90cb097f2dd961.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CBReY1vWWfk0feotMcBnsg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><figure class="mj mk ml mm gt is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="283c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">仅此而已！样本的标准差是多少？随机变量的标准偏差是对其围绕总体均值的离差的度量。低标准偏差意味着数据点经常接近平均值或预期值。较大的标准差意味着数据点分布在较大的数值范围内(维基百科)。方差的平方根也是标准差。让我们使用Python通过利用方差公式并计算其根来创建我们的标准差公式:</p><figure class="mj mk ml mm gt is gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/c07f384e96a7890917e4e9a26eaaf0b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*Pge-gS03l4b9xymtyyc9rQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="7e76" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们先来看看标准差。</p><figure class="mj mk ml mm gt is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="5169" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">如你所见，我们利用方差公式来寻找问题的根源。我们现在可以使用皮尔逊系数。让我们从原始公式开始，并从那里创建我们的函数:</p><figure class="mj mk ml mm gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oy"><img src="../Images/afb94db3883e28a68f0d216ff659712d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J7wKZPfmiTwtKsJfcpRSRw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="a987" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">鉴于我们已经完成了一半以上，让我们进一步简化这个公式:</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="db86" class="nk mq jg oh b gy ol om l on oo">covarianceOfXY / StdX * StdY</span></pre><figure class="mj mk ml mm gt is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="f849" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们看看我们的数据结果如何。</p><figure class="mj mk ml mm gt is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="c166" class="nk mq jg oh b gy ol om l on oo">The Pearson Correlation Coefficient between X and Y is [0.98478235].</span></pre><p id="8935" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">而皮尔逊系数的意义是什么？皮尔逊系数是一个介于-1和1之间的数字，1和-1表示完全线性相关，0表示不存在相关。完全正相关是1，而完全负相关是-1。</p><p id="3bc0" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">理想的价值观应该是什么样的？这是有条件的。有时0.7的相关性是最佳的，而其他时候0.9是不够的。这将取决于你的问题的性质。在多元线性回归中，您可以使用皮尔逊系数来查找模型中最重要的因素或排除相关变量。</p><p id="2e42" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在我们已经确定了一个假设，让我们开始估计参数。</p></div><div class="ab cl oq or hu os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="ij ik il im in"><p id="37cc" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">B0和B1将使用OLS公式进行估算。以下是方程式:</p><figure class="mj mk ml mm gt is gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/d8ea15e63fd844ac69e9cd54510680a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*lfXkSJgB0tkBdGqHW6NHPg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="4ec0" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这么看，有点难，lol。但是，实际上，这很容易。让我们从B1开始:</p><figure class="mj mk ml mm gt is gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/b31a0405a5e312beb2f3f929b96083c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*7ZAeRqAQo7XkrCgxipLH7w.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="a706" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">如前所述，B1是X和Y之间的协方差除以X的方差。B0只是X = 0时Y的值，考虑了Y的中值与角度系数和X的中值的乘积之差。</p><p id="ba59" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们用Python估算一下B0和B1？</p><figure class="mj mk ml mm gt is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="8b1c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">因为我们在训练和测试中划分数据，所以我们的X和Y将是我们的训练X和Y，是时候估算了！</p><figure class="mj mk ml mm gt is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="3edd" class="nk mq jg oh b gy ol om l on oo">Intercept: -4.959319577525191,        <br/>Slope: [2.00341869].</span></pre><p id="7bc0" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">换句话说，我们的线从-4.9593开始，x每增加一次，线就前进2.003。现在我们将这些参数应用到新数据中，看看我们的预测结果如何！现在是时候建立我们的线性回归了！</p><figure class="mj mk ml mm gt is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="04e1" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">因为我们之前分离了我们的数据，所以我们现在可以测试和评估我们的模型了！</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="be34" class="nk mq jg oh b gy ol om l on oo">y_pred = predict_function(b0_coeficient, b1_coeficient, X_test)</span></pre><p id="c504" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">之后呢？现在是时候设计我们的返程路线了！</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="5613" class="nk mq jg oh b gy ol om l on oo">plt.figure(figsize=(8,6))</span><span id="f409" class="nk mq jg oh b gy pd om l on oo">plt.scatter(X_test, y_test,  color='blue')</span><span id="63d9" class="nk mq jg oh b gy pd om l on oo">plt.plot(X_test, y_pred, color='red', linewidth=2)</span><span id="ed07" class="nk mq jg oh b gy pd om l on oo">plt.title("Linear Regression Demonstration", fontweight="bold", size=15)</span><span id="6e3e" class="nk mq jg oh b gy pd om l on oo">plt.show()</span></pre><figure class="mj mk ml mm gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pe"><img src="../Images/a3eaa71df7de1f0c56f98af6ff1f9260.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p77n_qMWpaXdp1fOBSdtEQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="1e47" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">看来我们的回归很顺利！</p><p id="05ac" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">自然，线性回归线永远不会到达所有点。或者，至少，如果他们是正确的，如果模型的意图是将其推广到新数据，这将不是一件好事。这是因为每个线性方程都有误差。</p><p id="1587" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">此刻，我们将加入我们等式的最后一个部分，关于它我们已经说过了。错误。</p><figure class="mj mk ml mm gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pf"><img src="../Images/3308f1a53997941fde1c64f63c2cc0da.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*Y2qAo3YjzwT6ZCSaAeMaFQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="cbd0" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">误差是y的预测值和实际值之间的差值。误差的成本可能是多种因素的结果。有时是你没有考虑的单一变量，而其他时候你假设了现实中不存在的线性关系。</p><p id="0e49" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">另一个原因可能是数据短缺。由于数据如此有限，你的估计可能无法揭示问题的真正本质。首先，有几种方法可以减少错误。你可能会寻找更多的数据，选择一个非参数或线性模型，并添加更多的变量。策略不同，将由您的评估决定。寻找更多的数据要花多少钱？值得寻找进一步的信息吗？测试另一个模型需要多长时间？专业工作时，你应该问所有这些问题。</p><p id="79ff" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">有限制吗？是的。称之为不可逆转的错误。不可逆误差是随机的，根据定义，不能测量或观察。我们会给你带来我们的新方程，我会给你解释的。</p><blockquote class="pg"><p id="f799" class="ph pi jg bd pj pk pl pm pn po pp lz dk translated">Y = ^f(X) + e</p></blockquote><p id="ba7c" class="pw-post-body-paragraph le lf jg lg b lh pq kq lj lk pr kt lm ln ps lp lq lr pt lt lu lv pu lx ly lz ij bi translated">当然，我们已经完成了第一阶段，并估计了f(X)的参数。为了有助于理解，我们采用线性回归来确定或预测给定一定量的辉瑞疫苗应用于小鼠的一小时内的平均心跳水平。</p><p id="ff3a" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">但是，该错误尚未提交，也不会提交。为什么会这样呢？我们猜测你昨晚回家很晚，很累，睡了一夜。同一天晚上，你的一只老鼠皮图被马金奥斯拴住了。Pitu和gaiola里的其他老鼠一样，变得极度紧张。幸运的是，没有人受伤。皮图第二天想跟你说委屈，但是因为你不和动物说话，所以你不知道发生了什么。</p><p id="27c4" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">Pitu的压力水平被发生的事情和你不明白发生了什么的事实所改变。压力水平是你的结果中的一个重要变量，但你忽略了N个原因，其中之一是你不会说“mouseguese”。</p><p id="9285" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">另一只小老鼠玛格达莱娜很孤独，没有人和她说话或一起玩。当你出去的时候，其他人有一个聚会，但是玛格达莱娜留在她的角落里，沉思她的悲伤。你很可能无法识别抹大拉的悲伤，因为你没有主修老鼠心理学。这个你无法测量甚至看不到的变量，在评估抹大拉的结果时将是至关重要的！</p><p id="004e" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">你明白我的意思吗？有些因素对于你的分析来说是不可观察或不可收集的。</p><p id="5d77" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">你应该感到奇怪，但这是什么错误，为什么我相信我在哪里听到过？你在上面看到了它，但是它有一个不同的名字:RSS。我们会计算模型的RSS吗？</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="bb27" class="nk mq jg oh b gy ol om l on oo">print(f'The RSS is {get_rss(y_pred, y_test)}.')</span><span id="5c04" class="nk mq jg oh b gy pd om l on oo"># The RSS is 191.16066429.</span></pre><p id="c133" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">有了这个数字，我们可以想办法减少它。但这不是今天的议题！我提到这个错误是有原因的。线性回归的第二个前提。</p></div><div class="ab cl oq or hu os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="ij ik il im in"><h2 id="ad66" class="nk mq jg bd mr nl nm dn mv nn no dp mz ln np nq nb lr nr ns nd lv nt nu nf jm bi translated">残留物必须以规则的方式分布。</h2><p id="c551" class="pw-post-body-paragraph le lf jg lg b lh nv kq lj lk nw kt lm ln nx lp lq lr ny lt lu lv nz lx ly lz ij bi translated">为什么会这样呢？关于为什么这个假设应该被证实，以及当它不满足时会发生什么，即使它是必要的，有几个争议。由于这些都是非常技术性的问题，所以我不会在本文中讨论它们。</p><p id="e3f3" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们如何知道一个数据分布是否正常？有两种类型的图形:图形和数学。我将在这部分使用图形。如果我们想检查所有剩菜的行为，我们不能使用RSS，因为RSS查看剩菜的总和，但我对剩菜的总和不感兴趣，而是对单个剩菜感兴趣。</p><p id="1589" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">还记得一开始的注册吗？我们来看公式Y = ^Y + e，要计算残差，只需将y从左向右切换，结果为:y ^y =<strong class="lg jq"><em class="ni">e</em></strong>。</p><blockquote class="pg"><p id="a6d5" class="ph pi jg bd pj pk pl pm pn po pp lz dk translated">e =观察值—估计值</p></blockquote><p id="7ae7" class="pw-post-body-paragraph le lf jg lg b lh pq kq lj lk pr kt lm ln ps lp lq lr pt lt lu lv pu lx ly lz ij bi translated">很简单，用Python来说:</p><figure class="mj mk ml mm gt is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="0ff3" class="nk mq jg oh b gy ol om l on oo">residual_lr = get_residual(y_test, y_pred)</span></pre><p id="e2e0" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">因此，我们将有一个剩菜阵列。我们会使用直方图来检查它们的分布吗？</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="1dc3" class="nk mq jg oh b gy ol om l on oo">plt.subplots(figsize=(12, 6))</span><span id="d38b" class="nk mq jg oh b gy pd om l on oo">plt.title('Distribution of Residuals')</span><span id="9072" class="nk mq jg oh b gy pd om l on oo">sns.distplot(residual_lr)</span><span id="4a1b" class="nk mq jg oh b gy pd om l on oo">plt.show()</span></pre><figure class="mj mk ml mm gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pv"><img src="../Images/d173ca656c29c4c9325f13b9137a5222.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DjUucsrnYMxxgzmQPGMV-A.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="a292" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这看起来是正态分布，尽管有点不对称！有没有另一种方法可以从图形上确认这是一个正态分布？有，有！它被称为QQPlot图！</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="dadb" class="nk mq jg oh b gy ol om l on oo">lst = []<br/>for i in residual_lr:<br/>    for n in i:<br/>        lst.append(n)</span><span id="bd19" class="nk mq jg oh b gy pd om l on oo">sm.qqplot(np.array(lst), line='45', fit=True)<br/>plt.show()</span></pre><p id="7f92" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在这段代码中，我从一组数组中提取了值，并将它们放在一个列表中，供我们的QQPlot验证！你有它！</p><figure class="mj mk ml mm gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pw"><img src="../Images/00ef322cf38c95d16b9e3a699de62f58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8KBOEtNRnInJfBG5LL2K2Q.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="26b3" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这到底是什么我从来没见过的东西？你可能会好奇。我不会花太多时间去概念化QQPlot，而是去解释它。<a class="ae jd" href="https://pt.wikipedia.org/wiki/Gr%C3%A1fico_Q-Q" rel="noopener ugc nofollow" target="_blank">如果你有兴趣了解更多</a>。</p><p id="889a" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">从一个QQ情节中我们可以得出什么结论？我们有一条红色的直线和一个蓝色的残差离差。我们可以使用QQ图来可视化我们的数据分布。如果它们完全沿着红线，我们就有一个完美的正态分布。我们的数据离这条直线越远，正态分布特征就越少。为了更好的理解，你可以在这里找到可视化的解释<a class="ae jd" href="https://qastack.com.br/stats/101274/how-to-interpret-a-qq-plot#:~:text=Se%20os%20valores,menores%20e%20maiores." rel="noopener ugc nofollow" target="_blank">。</a></p><p id="c60a" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">基于这一可视化，我们得出结论，我们的废物有一个典型的分布，尽管一些点远离中心。</p><p id="1000" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">有几种统计检验可以确定分布是否正态，如夏皮罗-维尔克检验。但是现在，我们只要坚持视觉化！我们正前往下一站。</p></div><div class="ab cl oq or hu os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="ij ik il im in"><h2 id="c44b" class="nk mq jg bd mr nl nm dn mv nn no dp mz ln np nq nb lr nr ns nd lv nt nu nf jm bi translated">残差的方差应该是常数</h2><p id="5ded" class="pw-post-body-paragraph le lf jg lg b lh nv kq lj lk nw kt lm ln nx lp lq lr ny lt lu lv nz lx ly lz ij bi translated">线性回归模型在很大程度上依赖于同方差的前提(即“恒定方差”)。同方差定义了一种情况，其中误差项(自变量和因变量之间关系中的“噪声”或随机扰动)对于所有自变量值都是相同的。</p><p id="98af" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">当误差项的大小在独立变量值之间变化时，就会出现异方差(违反同方差)。违反异方差假设的影响与异方差的程度成正比。</p><p id="582c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这对我们有什么意义？当我们使用MMQ时，我们给所有的X值相同的权重。如果某些X值比其他值有更大的影响，我们就有问题了。</p><p id="09b9" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">考虑基于家庭收入的奢侈品购买估计。我们有贫困的家庭，他们不买或者只买一些奢侈品。如果奢侈品的购买随着家庭收入的增加而增加，我们就会有一个恒定的方差。但假设只有一部分富裕家庭购买奢侈品，而其他人购买相对较少:我们有异方差的问题。</p><p id="5cef" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">你还记得B1公式吗？X值的方差在除数部分计算。因为OLS为X的所有变量提供了相同的权重，所以很大的变化会造成阻碍！</p><p id="fcc5" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们如何才能看到这一点？让我们使用Python吧！让我们从视觉表现开始。我们将根据预期值绘制残差图，以观察误差的变化。</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="7311" class="nk mq jg oh b gy ol om l on oo">plt.scatter(residual_lr, y_pred)<br/>plt.show()</span></pre><figure class="mj mk ml mm gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi px"><img src="../Images/21e94a587668f89e3260b423c35289fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K40HfSiDlXmUous5B4TYww.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="bfe9" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">老实说，我无法从这张图片中得出任何结论！这些点上似乎没有任何图案。那么，我们要测试一下吗？</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="01e2" class="nk mq jg oh b gy ol om l on oo">H0 = homocedasticity<br/>H1 != homocedasticity</span><span id="8dbf" class="nk mq jg oh b gy pd om l on oo">alpha = 0.05</span></pre><p id="bf7f" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们为此使用<em class="ni"> statsmodels.stats </em>库！</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="b7ea" class="nk mq jg oh b gy ol om l on oo">print(sm.diagnostics.het_goldfeldquandt(residual_lr, y_pred))</span><span id="2418" class="nk mq jg oh b gy pd om l on oo">Test: 1.0206718127917291<br/>p-value: 0.45956295321355667</span></pre><p id="a760" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们不能因为α&lt; p值而拒绝零假设，因此我们不能否认同方差的存在！</p><p id="6147" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">咻！我们的模型确认并通过了所有的假设！你很可能在想“我们现在可以走了吗？模式太神奇了！”。如果你想利用模型来分析变量，你可以放松一下。你可以明天开始检查，看看是否能从中得到什么。如果你想利用这个模型来做预测，我们只是成功了一半！</p></div><div class="ab cl oq or hu os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="ij ik il im in"><p id="1cbd" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在是时候评估我们模型的可推广性了！如您所见，我们的模型在盯着测试数据方面做得很好。但是有多好呢？我们如何评估我们的模型？使用度量标准！</p><p id="344f" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对此有多种测量方法。其中之一是R平方，通常称为决定系数。R2是一种度量，它表示模型可以解释多少数据变化。换句话说，这个度量计算回归模型可能预测的方差的比例，因此向我们显示实际度量与我们的模型有多“接近”。它表示响应变量中可由预测变量或解释变量解释的可变性的比例。</p><p id="8986" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">它的R平方值从0到1不等，0表示最差的估计值，1表示最好的估计值。它通常用百分比表示。例如，R2 = 73 %表明模型可以解释我们数据中73 %的波动性，而剩余的27%理论上是剩余方差。</p><p id="f469" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">有可能出现负的R平方吗？是的，当你的模型有能力比所有Y值的均值更差的时候。</p><p id="54c7" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">R2公式到底是什么？让我们再看一遍我们的RSS公式。我们会根据它来改变它。我们有RSS中残差的平方和。然而，我们希望计算残差的总平方和。</p><p id="36bb" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在RSS中，我们取Y的每个观察值和估计值之间的差，或者Y，对其求平方，并添加结果。在TSS中，我们计算Y值和Y平方平均值之间的差值。也就是说:</p><blockquote class="pg"><p id="5b54" class="ph pi jg bd pj pk pl pm pn po pp lz dk translated">TSS = sum ( ( valuesX — meanY))</p></blockquote><figure class="py pz qa qb qc is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="59ce" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">R2基本上是:</p><blockquote class="pg"><p id="53b3" class="ph pi jg bd pj pk pl pm pn po pp lz dk translated">1 — (RSS / TSS)</p></blockquote><figure class="py pz qa qb qc is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="41af" class="nk mq jg oh b gy ol om l on oo">rss = get_rss(y_pred, y_test)<br/>rst = rst_metric(y_test)</span><span id="d124" class="nk mq jg oh b gy pd om l on oo">print(f'The R2 of the model is {get_r2(rss, rst)[0]*100}%.')</span></pre><blockquote class="pg"><p id="e87e" class="ph pi jg bd pj pk qd qe qf qg qh lz dk translated">该模型的R2达到了97.177738738677</p></blockquote><p id="f379" class="pw-post-body-paragraph le lf jg lg b lh pq kq lj lk pr kt lm ln ps lp lq lr pt lt lu lv pu lx ly lz ij bi translated">这意味着，我们的模型能够解释近97.18 %的数据！该模型似乎可以推广到新的数据！</p><p id="92d6" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">r平方也可以通过平方皮尔逊系数来计算:</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="aae6" class="nk mq jg oh b gy ol om l on oo">print(0.98478235 ** 2)</span><span id="4ee3" class="nk mq jg oh b gy pd om l on oo"># 0.969796276871522</span></pre><p id="55aa" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">你想知道如果你取平均值，R的平方是多少吗？我们一起来看看吧！让我们做一个和Y一样大的列表，但是用Y的平均值代替。</p><figure class="mj mk ml mm gt is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="c5db" class="nk mq jg oh b gy ol om l on oo">plt.figure(figsize=(8,6))<br/>plt.scatter(X_test, y_test,  color='blue')<br/>plt.plot(X_test, lst, color='red', linewidth=2)<br/>plt.title("Linear Regression Demonstration", size=15)</span><span id="539d" class="nk mq jg oh b gy pd om l on oo">plt.show()</span></pre><figure class="mj mk ml mm gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qi"><img src="../Images/94de3c1b9c12c07082ebc470eb8cc810.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ad0KClTB6Vj1D5P7PyMh9Q.png"/></div></div></figure><p id="3a87" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在，让我们来计算R的平方:</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="4a6a" class="nk mq jg oh b gy ol om l on oo">rst = tss_metric(y_test)</span><span id="0e9a" class="nk mq jg oh b gy pd om l on oo">rss = get_rss(lst, y_test)</span><span id="ad87" class="nk mq jg oh b gy pd om l on oo">print(f'The R2 of the model is {get_r2(rss, rst)[0]*100}%.')</span></pre><blockquote class="pg"><p id="6e39" class="ph pi jg bd pj pk qd qe qf qg qh lz dk translated">模型的R2为0.0%。</p></blockquote><p id="92e3" class="pw-post-body-paragraph le lf jg lg b lh pq kq lj lk pr kt lm ln ps lp lq lr pt lt lu lv pu lx ly lz ij bi translated">还记得我说过R的平方可以小于0吗？RST以上的RSS越大，R的平方就越低。</p></div><div class="ab cl oq or hu os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="ij ik il im in"><p id="b64a" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">然而，问题依然存在。估计线性回归的另一种方法是什么？好吧，我会迅速找到一个合理的策略。</p><p id="b1e2" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这背后的解释如下。我们先挑100个截距和100个斜率值，然后测试10000个线性回归，比较一下，挑RSS最小的组合。我们开始吧！</p><figure class="mj mk ml mm gt is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><figure class="mj mk ml mm gt is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><figure class="mj mk ml mm gt is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="ad4c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这里我们运行10，000次回归。我们要不要计算得到最小的RSS？</p><figure class="mj mk ml mm gt is"><div class="bz fp l di"><div class="mn mo l"/></div></figure><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="cbf8" class="nk mq jg oh b gy ol om l on oo">min_index = rss_list.index(np.min(rss_list))</span><span id="dc2c" class="nk mq jg oh b gy pd om l on oo">print(f'The lowest RSS is: {np.min(rss_list)} with index {min_index}.')</span><span id="942c" class="nk mq jg oh b gy pd om l on oo"># The lowest RSS is: 190.52186974065032 with index 4552.</span></pre><p id="8657" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">与使用OLS相比，我们使用这种变通方法得到的RSS要小一些！用这个指数在测试数据上画出我们的回归线。</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="f75c" class="nk mq jg oh b gy ol om l on oo">plt.figure(figsize=(8,6))</span><span id="cd58" class="nk mq jg oh b gy pd om l on oo">plt.scatter(X_test, y_test,  color='blue')</span><span id="2e68" class="nk mq jg oh b gy pd om l on oo">plt.plot(X_test, linear_reg[min_index], color='red', linewidth=2)</span><span id="3f80" class="nk mq jg oh b gy pd om l on oo">plt.title("Linear Regression Demonstration", size=15)</span><span id="eba5" class="nk mq jg oh b gy pd om l on oo">plt.show()</span></pre><figure class="mj mk ml mm gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi qj"><img src="../Images/3bc07e04eb4c81eaca13c2c385d6a850.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-S_nROXjw0TahUNnlXxjvg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="1694" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">R的平方呢？</p><pre class="mj mk ml mm gt og oh oi oj aw ok bi"><span id="c48c" class="nk mq jg oh b gy ol om l on oo">rst = tss_metric(y_test)</span><span id="705c" class="nk mq jg oh b gy pd om l on oo">rss = get_rss(linear_reg[min_index], y_test)</span><span id="4ac0" class="nk mq jg oh b gy pd om l on oo">print(f'The R2 of the model is {get_r2(rss, rst)[0]*100}%.')<br/># The R2 of the model is 97.18512940329813%.</span></pre><p id="a0bc" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">正如你所看到的，这种差异可以忽略不计，几乎不存在。而使用MMQ方法我们得到97.175%，这里我们得到97.185%。</p></div><div class="ab cl oq or hu os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="ij ik il im in"><p id="d004" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">到此，我们将结束我们的文章！我试图通过理解五六行代码背后的东西来解决创建线性回归的最重要的方面，这些代码足以完成我们在这里讨论的所有事情。</p><p id="9f49" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">剩下的问题是:是否需要检查所有这些？有没有另一种方法可以在不经历所有这些的情况下获得一致的结果？我现在想做的就是完成Kaggle的巨大线性回归。我真的有必要这样做吗？这是一场激烈的辩论！<a class="ae jd" href="https://qastack.com.br/stats/130775/why-do-we-care-so-much-about-normally-distributed-error-terms-and-homoskedastic" rel="noopener ugc nofollow" target="_blank">这里可以找到一些水花</a>。但请记住，作为一名数据科学家，你必须解决问题，并向你的同行展示你的发现。</p><p id="e614" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">当你处理真实数据的时候，不会像这里的那些可爱，而是需要解决问题！</p></div><div class="ab cl oq or hu os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="ij ik il im in"><p id="9006" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">参考资料:</p><p id="fe28" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq">homscedastidade——应用统计中心</strong>。https://estatistica.pt/homoscedasticidade/&gt;<a class="ae jd" href="https://estatistica.pt/homoscedasticidade/" rel="noopener ugc nofollow" target="_blank">。Acesso em: 24套。2021.</a></p><p id="c13c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">‌ <strong class="lg jq">测试正态分布和方差分布</strong>。disponível em:&lt;<a class="ae jd" href="https://biostatistics-uem.github.io/Bio/aula8/teste_normalidade_homocedasticidade.html" rel="noopener ugc nofollow" target="_blank">https://Bio statistics-uem . github . io/Bio/aula 8/test _ normalidade _ homocedastidade . html</a>&gt;。Acesso em: 24套。2021.</p><p id="d8a7" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">‌HOW，你能给一个只懂均值的人解释一下协方差吗？你将如何向只懂均值的人解释协方差？disponível em:&lt;<a class="ae jd" href="https://stats.stackexchange.com/questions/18058/how-would-you-explain-covariance-to-someone-who-understands-only-the-mean" rel="noopener ugc nofollow" target="_blank">https://stats . stack exchange . com/questions/18058/how-would-you-explain-co variance-to someone-someone-who-understand-only-the-mean</a>&gt;。Acesso em: 24套。2021.</p><p id="5ad6" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">‌DAMACENO，l .<strong class="lg jq">entendendo regresso linear:as suposis por tras de tudo！</strong>disponível em:&lt;<a class="ae jd" href="https://medium.com/@lauradamaceno/entendendo-regress%C3%A3o-linear-as-suposi%C3%A7%C3%B5es-por-tr%C3%A1s-de-tudo-d0e29004c7f8" rel="noopener">https://medium . com/@ lauradamaceno/entendendo-regression % C3 % A3o-linear-as-suposi % C3 % A7 % C3 % B5es-por-tr % C3 % A1s-de-tudo-d0e 29004 C7 f 8</a>&gt;。Acesso em: 24套。2021.</p><p id="9e10" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">‌SHRUTIMECHLEARN.<strong class="lg jq">逐步假设—线性回归</strong>。可在以下网址查阅:&lt;<a class="ae jd" href="https://www.kaggle.com/shrutimechlearn/step-by-step-assumptions-linear-regression" rel="noopener ugc nofollow" target="_blank">【https://www . kag gle . com/shruteimechlar/分步假设线性回归】</a> &gt;。访问时间:9月24日。2021.</p><p id="575c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">蒂托。<strong class="lg jq">scikit-学习还是状态模式？评估我的回归模型</strong>。可在以下网址查阅:&lt;<a class="ae jd" href="https://nathaliatito.medium.com/scikit-learn-ou-statsmodels-avaliando-meu-modelo-de-regress%C3%A3o-f4c04b361fa7" rel="noopener">【https://nathaliatito . medium . com/scikit-learn-or-state models-asserting-my-return model % C3 % a3 % a3-3o-F4 c04 b361 fa 7】&gt;。访问时间:9月24日。2021.</a></p><p id="8765" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg jq">使用Python的多行回归</strong>。可于:&lt;<a class="ae jd" href="https://ichi.pro/pt/regressao-multilinear-usando-python-75578758662189" rel="noopener ugc nofollow" target="_blank">https://ichi . pro/pt/return au-multiline-using-python-75787662189</a>&gt;查阅。访问时间:9月24日。2021.</p><p id="87de" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">米兰达修女。<strong class="lg jq"> 19线性回归|基本生物统计</strong>。可查阅:&lt;<a class="ae jd" href="http://www.lampada.uerj.br/arquivosdb/_book/regress%C3%A3o-linear.html#eqReta" rel="noopener ugc nofollow" target="_blank">【http://www . lamp . uerj . br/db/_ book/regret % C3 % a3 % a3-o-linear . html # straight</a>&gt;。访问时间:9月24日。2021.</p></div></div>    
</body>
</html>