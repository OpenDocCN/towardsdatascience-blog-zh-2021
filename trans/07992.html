<html>
<head>
<title>Apply Propensity Score Method in Causal Inference — Part 2: K-Nearest Neighbor Matching</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">倾向得分方法在因果推理中的应用——第二部分:K近邻匹配</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/apply-propensity-score-method-in-causal-inference-part-2-k-nearest-neighbor-matching-c0cd2cdb0f74?source=collection_archive---------15-----------------------#2021-07-22">https://towardsdatascience.com/apply-propensity-score-method-in-causal-inference-part-2-k-nearest-neighbor-matching-c0cd2cdb0f74?source=collection_archive---------15-----------------------#2021-07-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8364" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用Python写了一个真实的例子</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3e67708712f41c09d3d1bff4697c4c23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kTNWBSyBq8irzkkRUq2wyA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@willianjusten?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">威利安·贾斯登·德·瓦斯康塞洛斯</a>在<a class="ae ky" href="https://unsplash.com/collections/2wH1Mm-Y10A/reflection?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="abea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我的上一篇文章中，我介绍了如何使用logistic回归模型估计倾向得分，并逐步进行分层匹配。综上所述，<strong class="lb iu">在实践中，倾向评分法通常分两步完成。首先，我们估计倾向得分。第二，我们通过使用一种匹配方法来估计治疗的效果。</strong></p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/apply-propensity-score-methods-in-causal-inference-part-1-stratification-afce2e85730c"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">倾向得分方法在因果推理中的应用——第一部分:分层</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">用Python一步步实现了一个例子</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="5de3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我假设我们已经使用相同的数据并按照我上一篇文章中列出的程序(链接如上)获得了治疗组和对照组的估计倾向得分。</p><p id="8909" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我深入最近邻匹配之前，下面是倾向评分估计的Python代码。最后，我保存了带有估计分数的数据集，以便稍后进行匹配:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mu mv l"/></div></figure></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="2cfe" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">k近邻匹配</h2><p id="d981" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">最近邻匹配是分层的替代方法，用于匹配处理单元和比较单元。它获取每个处理过的单元，并搜索具有最接近p值的比较单元。匹配后，我们计算每个治疗组和对照组之间的结果差异，并对多个治疗组的这些差异进行平均。</p><p id="c6d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有不同类型的最近邻匹配。在本文中，我考虑k从1到5的范围内的k最近邻匹配。我使用了实现k-最近邻算法的<code class="fe nu nv nw nx b"><a class="ae ky" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.neighbors" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">sklearn.neighbors</strong></a></code>模块。在k个对照单位与每个治疗单位匹配后，我计算所有变量平均值的加权差异，以1)估计治疗效果(结果变量<strong class="lb iu"> <em class="ny"> re78 </em> </strong>)，以及2)比较治疗组和对照组之间的协变量平衡。k=1，3，5的结果总结在下表1中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/05be733f701098bc9c8d92ab2fb5d2a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*K-lcUO4JcsiojsVbckGxYw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">表1:不同Ks的KNN倾向评分匹配结果</p></figure><p id="0717" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设我们已经获得了实验基准效应= $1，676，分层匹配的治疗效应= $1，632(在上面链接的前一篇文章中)，当我们将它们与实验效应进行比较时，KNN匹配似乎产生了比分层更小且更差的效应。可能的解释包括:1)即使knn匹配保证所有处理过的单元都找到匹配。然而，这些匹配中的一些可能相当差，因为对于一些处理过的单元，匹配的比较单元(最近邻)可能具有非常不同的p分数，同样2)即使分数匹配得很好，匹配的处理单元和比较单元在我的模型中似乎并不总是很好的匹配。例如，下面是来自k=1 NM匹配的一个例子，其显示了处理和比较单元具有几乎相等的p-分数，但是在其他特征上非常不同。我的观点是，倾向得分模型还不够好，如果可能的话，我应该包含更多的特征。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/aaacbad9611641a613a79f7436b1660f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*FEVBQUs-3Eu9WaYEDiPP4g.png"/></div></figure><p id="270f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是我用于k近邻匹配的Python代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mu mv l"/></div></figure></div></div>    
</body>
</html>