<html>
<head>
<title>Evaluating Multi-label Classifiers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">评估多标签分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/evaluating-multi-label-classifiers-a31be83da6ea?source=collection_archive---------0-----------------------#2021-11-01">https://towardsdatascience.com/evaluating-multi-label-classifiers-a31be83da6ea?source=collection_archive---------0-----------------------#2021-11-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0e33" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">以及这些指标在不同场景下如何变化</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/876f64d36a00064813e19f1aae45a679.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PTWgBdqvIRdGEw5j1xK1mA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="c0d7" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">介绍</h1><p id="3188" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">分类是机器学习的一个重要应用。这是一项预测性建模任务，需要为数据点分配一个类别标签，这意味着该特定数据点属于所分配的类别。</p><h1 id="77a2" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">目录</h1><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="4c5d" class="mo kw iq mk b gy mp mq l mr ms">- Accuracy<br/>- The Confusion Matrix<br/>- A multi-label classification example<br/>- Multilabel classification confusion matrix<br/>- Aggregate metrics<br/>- Some Common Scenarios</span></pre><h1 id="cab1" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">准确(性)</h1><p id="4746" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">开发和应用模型是一回事，但是如果没有评估它们的方法，实验很快就会变得毫无意义。</p><p id="2695" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">大多数人都知道准确性是什么，即使只是在直观的意义上——某件事情有多准确，指的是它实现某个目标的频率。这个目标可能是一个足球运动员的射门击中目标的频率，或者对明天天气的预测有多准确。</p><p id="3d0e" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">说到分类，它是通过一个模型正确分类数据的频率来衡量的。</p><p id="f621" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">简而言之，对于分类问题，精确度可以用以下公式来衡量:</p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="a310" class="mo kw iq mk b gy mp mq l mr ms">accuracy = number of correct predictions / total predictions</span></pre><h1 id="bfd0" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">准确性并不能说明全部</h1><p id="b889" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">这似乎是评估一个模型的好方法——你会期望一个“更好”的模型比一些“不太好”的模型更准确。虽然这通常是正确的，但准确性有时无法给你完整的图像，例如不平衡的数据集。</p><p id="f259" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">假设您有属于两个类的数据:<code class="fe my mz na mk b">red</code>和<code class="fe my mz na mk b">blue</code>。红色类别拥有大多数数据点。假设他们的比例是<code class="fe my mz na mk b">9:1</code>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/61d10f0bfca5bee114fe9039cf9e3c47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JJ-E1kDDSDwH1OFIFsprlg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">红色类与蓝色类的比率—作者使用<a class="ae nc" href="https://app.diagrams.net/" rel="noopener ugc nofollow" target="_blank"> draw.io </a></p></figure><p id="edeb" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">这意味着给定 100 个数据点，90 个将属于类别<code class="fe my mz na mk b">red</code>，而只有 10 个将属于类别<code class="fe my mz na mk b">blue</code>。</p><blockquote class="nd"><p id="a39a" class="ne nf iq bd ng nh ni nj nk nl nm mi dk translated">现在，如果我的模型训练得太差，以至于它总是预测<strong class="ak">红色</strong>，不管它给出什么数据点，该怎么办？</p></blockquote><p id="3ff7" class="pw-post-body-paragraph ln lo iq lp b lq nn jr ls lt no ju lv lw np ly lz ma nq mc md me nr mg mh mi ij bi translated">你可能已经明白我的意思了。</p><p id="8ab1" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">在上面的例子中，我的模型的准确率最终是 90%。它会让所有的<code class="fe my mz na mk b">reds</code>正确，所有的<code class="fe my mz na mk b">blues</code>错误。因此，精确度将为<code class="fe my mz na mk b">90 / (90 + 10)</code>或<strong class="lp ir"> 90% </strong>。</p><p id="0619" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">客观地说，这将是一个相当不错的分类精度目标。但是准确性，在这种情况下，隐藏了这样一个事实，即我们的模型实际上什么也没有学到，并且总是预测红色类别。</p><h1 id="5ffd" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">混乱矩阵</h1><p id="f01d" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">混淆矩阵是一个正确和错误地分为以下几类的矩阵:</p><ul class=""><li id="513f" class="ns nt iq lp b lq mt lt mu lw nu ma nv me nw mi nx ny nz oa bi translated"><strong class="lp ir">真阳性(TP): </strong>正确预测阳性类别</li><li id="d8e6" class="ns nt iq lp b lq ob lt oc lw od ma oe me of mi nx ny nz oa bi translated"><strong class="lp ir">真阴性(TN): </strong>正确预测阴性类别</li><li id="4761" class="ns nt iq lp b lq ob lt oc lw od ma oe me of mi nx ny nz oa bi translated"><strong class="lp ir">假阳性(FP): </strong>错误预测阳性类别</li><li id="b7ec" class="ns nt iq lp b lq ob lt oc lw od ma oe me of mi nx ny nz oa bi translated"><strong class="lp ir">假阴性(FN): </strong>错误预测阴性类别</li></ul><p id="0db4" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">使用这些，定义了类似于<strong class="lp ir">精度</strong>、<strong class="lp ir">召回、</strong>和<strong class="lp ir"> f1 分数</strong>的指标，与<strong class="lp ir">精度</strong>相比，这些指标为我们提供了一个更准确的衡量标准。</p><p id="3e23" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">回到我们的例子，我们的负类是类<code class="fe my mz na mk b">red</code>，正类是<code class="fe my mz na mk b">blue</code>。假设我们在 100 个数据点上测试我们的模型。保持相同的分布，90 个数据点将是<code class="fe my mz na mk b">red</code>，而 10 个数据点将是<code class="fe my mz na mk b">blue</code>，并且我们的模型将在所有情况下预测<code class="fe my mz na mk b">red</code>(负类)。</p><p id="f828" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">它的混淆矩阵是:</p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="dabd" class="mo kw iq mk b gy mp mq l mr ms">True positive   = 0 (we never predict the positive class)<br/>True negative   = 90 (we always predict the negative class)<br/>False positive  = 0 (we never predict the positive class)<br/>False Negative  = 10 (we labeled the positive class as neg)</span></pre><p id="dad2" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated"><strong class="lp ir">计算精度、召回率和 F1 值</strong></p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="fb8e" class="mo kw iq mk b gy mp mq l mr ms"><strong class="mk ir">Precision</strong> = TP / (TP + FP)<br/>          = 0 / (0 + 0)<br/>          = undefined</span><span id="7e2d" class="mo kw iq mk b gy og mq l mr ms"><strong class="mk ir">Recall</strong>    = TP / (TP + FN)<br/>          = 0 / (0 + 10)<br/>          = 0</span></pre><p id="dffd" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">因此，尽管我的模型的<code class="fe my mz na mk b">accuracy</code>是<code class="fe my mz na mk b">90%</code>，一个普遍好的分数，但它的<code class="fe my mz na mk b">precision</code>是<code class="fe my mz na mk b">undefined</code>而<code class="fe my mz na mk b">recall</code>是<code class="fe my mz na mk b">0</code>，这表明该模型甚至一次都没有预测到正类。</p><p id="a34a" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">这是一个很好的例子，说明准确性并不能给我们提供全貌。分别对精度和召回率也是如此。</p><h1 id="4225" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">多标签分类</h1><p id="554e" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">多标签分类是指一个数据点可以被分配到多个类别，并且有许多类别可用的情况。</p><p id="f94f" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">这与<strong class="lp ir">多类分类不同，</strong>多类分类是每个数据点只能被分配到一个类，而不考虑可能的类的实际数量。</p><blockquote class="nd"><p id="d11f" class="ne nf iq bd ng nh ni nj nk nl nm mi dk translated">与多类别分类不同，在多标签分类中，类别并不相互排斥</p></blockquote><p id="e4fe" class="pw-post-body-paragraph ln lo iq lp b lq nn jr ls lt no ju lv lw np ly lz ma nq mc md me nr mg mh mi ij bi translated">使用精度、召回率和 f1 分数等指标来评估二进制分类器是非常简单的，所以我不会讨论这个问题。对多标签分类做同样的事情也不太难——只是稍微复杂一点。</p><p id="105f" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">为了使它更简单，让我们来看一个简单的例子，我们将在过程中对其进行调整。</p><h1 id="4d32" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">一个例子</h1><p id="4acd" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">假设我们有分布在三个类别中的数据——A 类、B 类和 c 类。我们的模型试图将数据点分类到这些类别中。这是一个多标签分类问题，所以这些类不是排他的。</p><h2 id="70dc" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated">估价</h2><p id="ddcf" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">让我们以 3 个数据点作为简单事物的测试集。</p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="032f" class="mo kw iq mk b gy mp mq l mr ms">expected   predicted<br/>A, C        A, B<br/>C           C<br/>A, B, C     B, C</span></pre><p id="c413" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">我们先来看看<strong class="lp ir">多标签问题</strong>的混淆矩阵是什么样子，然后为其中一个类创建一个单独的混淆矩阵作为例子。</p><p id="80b2" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">我们将使用 sklearn 的<code class="fe my mz na mk b">MultiLabelBinarizer</code>对类 A、B 和 C 进行编码。因此，每个预测都可以表示为一个三位的字符串，其中第一位代表 A，然后是 B，最后一位是 c。</p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="1a94" class="mo kw iq mk b gy mp mq l mr ms">expected    predicted<br/>1 0 1       1 1 0<br/>0 0 1       0 0 1<br/>1 1 1       0 1 1</span></pre><h2 id="e43a" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated"><strong class="ak">注</strong></h2><blockquote class="os ot ou"><p id="c61f" class="ln lo ov lp b lq mt jr ls lt mu ju lv ow mv ly lz ox mw mc md oy mx mg mh mi ij bi translated">基于一个读者的问题，我想澄清像二进制化器和缩放器这样的变换应该是只适合你的训练集的<strong class="lp ir">。</strong>当然，您希望在推理过程中应用这些相同的转换，但是它们并不适合新数据。</p><p id="6443" class="ln lo ov lp b lq mt jr ls lt mu ju lv ow mv ly lz ox mw mc md oy mx mg mh mi ij bi translated">上面列出的预期和预测标签只是为了直观地了解它们有什么不同。</p></blockquote><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="684b" class="mo kw iq mk b gy mp mq l mr ms">train, test &lt;- data<br/>transformed_train &lt;- fit + transform</span><span id="b350" class="mo kw iq mk b gy og mq l mr ms">transformed_test &lt;- transform (using the same scaler/binarizer)</span></pre><p id="1ef6" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">基于我们的测试，让我们找出 A 类的混淆矩阵。</p><h2 id="b101" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated">A 级</h2><p id="202a" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">为了计算真阳性，我们正在考虑我们的模型预测标签 A 并且预期标签也包含 A 的情况。</p><p id="32e5" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">所以 TP 等于 1。</p><p id="020c" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">到了 FP，我们寻找那些我们的模型预测了标签 A 但是 A 不在真正的标签中的情况。</p><p id="284a" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">所以 FP 是 0。</p><p id="778e" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">来到 TN，这是期望标签和预测标签都不包含 a 类的地方。</p><p id="f9a7" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">所以 TN 是 1。</p><p id="fa8d" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">最后，FN 表示 A 是一个预期的标签，但是我们的模型没有预测到它。</p><p id="aaec" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">所以 FN 是 1。</p><p id="04cd" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">让我们使用这些值来制作 A 类的混淆矩阵:</p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="be79" class="mo kw iq mk b gy mp mq l mr ms">TN   FP</span><span id="0fd8" class="mo kw iq mk b gy og mq l mr ms">FN   TP</span></pre><p id="5963" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">我们得到:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/e352b7581948645baed4b3259a00232e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m4Gq8ThK4at1brcmvx9ifg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">A 类的困惑矩阵——作者在 IPad 上写的</p></figure><p id="d16a" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">可以对其他两个类进行类似的计算。</p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="4485" class="mo kw iq mk b gy mp mq l mr ms"><strong class="mk ir">Class B:</strong> 1   1<br/>         0   1</span><span id="5ca0" class="mo kw iq mk b gy og mq l mr ms"><strong class="mk ir">Class C:</strong> 0   0 <br/>         1   2</span></pre><h2 id="d17d" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated">混淆矩阵</h2><p id="5703" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">像我们刚刚计算的混淆矩阵可以使用 sklearn 的<code class="fe my mz na mk b">multilabel_confusion_matrix</code>生成。我们简单地传入预期和预测标签(在二进制化它们之后),并从混淆矩阵列表中获取第一个元素——每个类一个。</p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="ee58" class="mo kw iq mk b gy mp mq l mr ms">confusion_matrix_A<br/>    = multilabel_confusion_matrix(y_expected, y_pred)[0]</span></pre><p id="4ff7" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">输出与我们的计算一致。</p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="3891" class="mo kw iq mk b gy mp mq l mr ms">print(confusion_matrix_A)</span><span id="2228" class="mo kw iq mk b gy og mq l mr ms"># prints:<br/>1  0<br/>1  1</span></pre><h2 id="dd53" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated">精确度、召回率和 F1 分数</h2><p id="0616" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">使用我们刚刚计算的混淆矩阵，让我们作为一个例子来计算 A 类的每个度量。</p><p id="1349" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated"><strong class="lp ir">A 级精度</strong></p><p id="1e63" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">精确度简单来说就是:</p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="f913" class="mo kw iq mk b gy mp mq l mr ms">Precision = TP / (TP + FP)</span></pre><p id="83db" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">在 A 类的情况下，结果是:</p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="4449" class="mo kw iq mk b gy mp mq l mr ms">1 / (1 + 0) = 1</span></pre><p id="ca1a" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated"><strong class="lp ir">召回 A 类</strong></p><p id="1b64" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">使用如下给出的召回公式:</p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="c84a" class="mo kw iq mk b gy mp mq l mr ms">Recall = TP / (TP + FN)</span></pre><p id="17ce" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">我们得到:</p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="16b6" class="mo kw iq mk b gy mp mq l mr ms">1 / (1 + 1) = 0.5</span></pre><p id="3db4" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated"><strong class="lp ir">F1-A 类分数</strong></p><p id="5946" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">这只是我们计算的精度和召回率的调和平均值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pa"><img src="../Images/11bbc979a9a018a70119c1a8bcba4292.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RUq3h3ab-fJhPEp_P1GJWA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">F1 分数的公式—作者使用<a class="ae nc" href="https://app.diagrams.net/" rel="noopener ugc nofollow" target="_blank"> draw.io </a></p></figure><p id="0932" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">这给了我们:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/c1dced4de53d3e0931bd32788c844d7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eW21z3y6PfwaYukbtl17Ug.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">计算 F1-A 类分数——作者使用<a class="ae nc" href="https://app.diagrams.net/" rel="noopener ugc nofollow" target="_blank"> draw.io </a></p></figure><p id="e9c8" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">可以用同样的方式为 B 类和 C 类计算这些度量。</p><p id="ead6" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">在完成所有其他类的测试后，我们得到了以下结果:</p><p id="c4b0" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated"><strong class="lp ir">B 类</strong></p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="8d96" class="mo kw iq mk b gy mp mq l mr ms">Precision = 0.5<br/>Recall = 1.0<br/>F1-score = 0.667</span></pre><p id="c129" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated"><strong class="lp ir">丙类</strong></p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="3bbf" class="mo kw iq mk b gy mp mq l mr ms">Precision = 1.0<br/>Recall = 0.667<br/>F1-score = 0.8</span></pre><h2 id="b90e" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated">聚合指标</h2><p id="4e87" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">宏观、微观、加权和抽样平均值等聚合指标为我们提供了模型执行情况的高级视图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/c5835ebaba39f9c69b1b7535c98c2504.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E_ooGm14nsBLQC-yzyIH-Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">我们将要讨论的综合指标——作者在 IPad 上</p></figure><p id="7986" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated"><strong class="lp ir">宏观平均</strong></p><p id="d17b" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">这只是所有类别中某个指标(精确度、召回率或 f1 分数)的平均值。</p><p id="53d1" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">在我们的例子中，精度的宏观平均值是</p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="86fb" class="mo kw iq mk b gy mp mq l mr ms">Precision (macro avg)<br/>= (Precision of A + Precision of B + Precision of C) / 3<br/>= 0.833</span></pre><p id="fc48" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated"><strong class="lp ir">微平均</strong></p><p id="d360" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">通过考虑每个类别的所有 TP、TN、FP 和 FN，将它们相加，然后使用这些来计算指标的微平均值，来计算指标的微平均值</p><p id="fa91" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">例如，微精度可以是:</p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="855e" class="mo kw iq mk b gy mp mq l mr ms">micro avg (precision) = sum(Tp) / (sum(TP) + sum(FP))</span></pre><p id="50f0" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">对于我们的例子，我们最终得到:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/74655153e599c35dace218ea0c861a66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JfHCZSO55O9cM0gCqUXmIw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Precision 的微观平均值——作者在 IPad 上写的</p></figure><p id="ba6c" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated"><strong class="lp ir">加权平均</strong></p><p id="0f6a" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">这只是单个类的度量值的平均值，由该类的支持进行加权。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/d2da00e2d22b6195b23718c528188378.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iFkmaSlxoWRcKloZ9E-Z6w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Precision 的加权平均值——作者在 Ipad 上给出的</p></figure><p id="2ddc" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated"><strong class="lp ir">样本平均值</strong></p><p id="3869" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">这里，我们计算每个样本的指标，然后对它们进行平均。在我们的例子中，我们有三个样本。</p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="3ab9" class="mo kw iq mk b gy mp mq l mr ms">expected   predicted<br/>A, C        A, B<br/>C           C<br/>A, B, C     B, C</span></pre><p id="c5c5" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">对于<code class="fe my mz na mk b">sample #1</code>，预测了 A 和 B，但是期望的类是 A 和 C</p><p id="f38d" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">所以这个样本的精度是<code class="fe my mz na mk b">1 / 2</code>，因为在两个预测标签中，只有一个是正确的。</p><p id="5b6b" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">对于<code class="fe my mz na mk b">sample #2</code>，预测到了<code class="fe my mz na mk b">C</code>，预计到了<code class="fe my mz na mk b">C</code>。</p><p id="7f74" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">所以这个样本的精度是<code class="fe my mz na mk b">1</code>——所有预测的标签都是预期的。</p><p id="7ba4" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">对于<code class="fe my mz na mk b">sample #3</code>，预测了<code class="fe my mz na mk b">B</code>和<code class="fe my mz na mk b">C</code>，但所有三个标签都是预期的。</p><p id="9b81" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">因为所有预测的标签都是预期的，所以精度是<code class="fe my mz na mk b">1</code>。注意，虽然<code class="fe my mz na mk b">A</code>没有被预测到，但是丢失的标签不会影响精确度，只会影响召回率。</p><p id="a5c4" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">平均这个，我们得到我们的<strong class="lp ir">样本的平均精度。</strong></p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="007b" class="mo kw iq mk b gy mp mq l mr ms">(1/2 + 1 + 1) / 3 = 5/6 = 0.833</span></pre><p id="a866" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">也可以为<code class="fe my mz na mk b">recall</code>和<code class="fe my mz na mk b"> f1-score</code>计算这些总量。</p><h2 id="a8e2" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated"><strong class="ak">分类报告</strong></h2><p id="7679" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">将所有这些放在一起，我们最终得到了我们的分类报告。我们的计算值与 sklearn 生成的值相匹配。我们就用 sklearn 的<code class="fe my mz na mk b">metrics.classifiction_report</code>函数。</p><pre class="kg kh ki kj gt mj mk ml mm aw mn bi"><span id="af6f" class="mo kw iq mk b gy mp mq l mr ms">classification_report(<br/>    y_expected,<br/>    y_pred,<br/>    output_dict=False,<br/>    target_names=['class A', 'class B', 'class C']<br/>)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pb"><img src="../Images/7ce32ed98c9d11f58a275fd62b5c9867.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*knFxyEusNj8Og_ujPEKGJw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Sklearn 生成的分类报告</p></figure></div><div class="ab cl pc pd hu pe" role="separator"><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph"/></div><div class="ij ik il im in"><h1 id="a6a4" class="kv kw iq bd kx ky pj la lb lc pk le lf jw pl jx lh jz pm ka lj kc pn kd ll lm bi translated">一些常见场景</h1><p id="8400" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">这些是评估多标签分类器时可能出现的一些情况。</p><h2 id="ffdc" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated">在你的测试数据中有重复</h2><p id="a313" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">真实世界的测试数据可以有副本。如果您不删除它们，它们会如何影响您的模型的性能？评估分类模型时通常使用的聚合指标是平均值的形式。因此，重复的影响归结于这些重复的数据点是否被正确分类。</p><h2 id="fb01" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated">您的模型只预测了一些预期的标签</h2><p id="4352" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">当您的模型没有预测每个预期的标签，也没有预测额外的标签时，您会看到较高的精度值和较低的召回值。</p><p id="2325" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">无论你的模型预测什么，它都是正确的(高精度)，但它并不总是预测预期的(低回忆)。</p><h2 id="4436" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated">您的模型预测的标签比预期的多</h2><p id="d426" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">这与前一种情况相反。由于您的模型预测了额外的标注，这些额外的类将以较低的精度结束(因为这些预测不是预期的)。同时，你的模型也预测了所有预期的标签，所以你最终会得到高的回忆分数。</p><h2 id="69e1" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated">高精度—高召回率</h2><p id="cbec" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">这是一个理想的场景，精确度和召回率都很高。直观地说，这意味着当我们的模型预测一个特定的标签时，这通常是一个预期的标签，当一个特定的标签是预期的时，我们的模型通常是正确的。</p><h2 id="d60c" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated">高精度—低召回率</h2><p id="0b8a" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">这意味着我们的模型在预测时确实是有选择性的。当数据点特别难以标记时，我们的模型选择不冒预测不正确标签的风险。这意味着当我们的模型预测一个特定的标签时，它往往是正确的(高精度)，但反过来就不是这样了(低召回)。</p><h2 id="cc34" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated">低精度—高召回率</h2><p id="30e8" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在这种情况下，我们的模型的预测相当宽松。即使不完全确定，也更有可能给数据点分配一个标签。正因为如此，我们的模型很可能会给某些数据点分配不正确的标签，从而导致精度下降。</p><h2 id="a381" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated">阈值处理以改善结果</h2><p id="0e1b" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">大多数算法使用 0.5 的阈值。这意味着置信度大于 0.5 的预测被认为属于正类，而不考虑置信度较低的预测。</p><p id="f01a" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">这与整个精确回忆的讨论有什么关系？好吧，想想如果你修改这个阈值会发生什么。</p><p id="8ec9" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">如果你提高你的门槛，你会对你的模型预测更加严格。既然只分配了具有高可信度的预测，那么您的模型在预测类时更有可能是正确的，从而导致高精度。与此同时，您的模型可能会错过置信度较低的预期标签，从而导致较低的召回率。</p><p id="89cf" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">另一方面，降低模型的分类阈值意味着模型对其预测较为宽松。这将意味着你的模型更有可能预测预期的标签，尽管它们可能是低信心的决定，这意味着你将有很高的回忆。但是现在你的模型不那么严格了，它分配的标签很可能不是预期标签的一部分，导致精度降低。</p><h2 id="8dbb" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated">平衡召回率和精确度</h2><p id="b474" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">正如我们刚刚看到的，在精确度和召回率之间有一个折衷。如果你使你的模型具有高度选择性，你最终会得到更好的精度，但是面临召回率下降的风险，反之亦然。</p><p id="54ff" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">在这两个指标之间，什么更重要取决于您试图解决的问题。</p><p id="36f2" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">医学诊断工具，如皮肤癌检测系统，不能将一个癌症病例标记为非癌症病例。在这里，你会想尽量减少假阴性。这意味着你试图最大化回忆。</p><p id="502a" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">同样，如果你考虑一个推荐系统，你更关心的是推荐客户可能不感兴趣的东西，而不是不推荐他们感兴趣的东西。在这里，负面消息不是问题，目标是让内容尽可能相关。因为我们在这里减少了误报，我们关注的是精确度，而不是召回。</p><h2 id="a686" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated">注意#1:不断忘记精确和召回的区别？</h2><p id="6461" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">Jennifer 在 data science StackExchange 网站上的回答中解释了记住精度和召回代表的区别的一个好方法:</p><div class="po pp gp gr pq pr"><a href="https://datascience.stackexchange.com/a/54172" rel="noopener  ugc nofollow" target="_blank"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd ir gy z fp pw fr fs px fu fw ip bi translated">什么时候精准比回忆更重要？</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">哪个更重要仅仅取决于每个错误的成本。精确往往涉及…</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">datascience.stackexchange.com</p></div></div><div class="qa l"><div class="qb l qc qd qe qa qf kp pr"/></div></div></a></div><h2 id="222e" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated"><strong class="ak">注意#2:除了本文讨论的指标，还有其他指标吗？</strong></h2><p id="56aa" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">绝对的。不同类型的问题有不同的衡量标准，最适合特定的情况。即使对于我们刚刚讨论的情况，即多标签分类，也有另一个称为汉明分数的度量，它评估模型的预测与预期的接近程度。你可以把它看作是多标签分类器的一种更宽容的准确性。</p><p id="b431" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">Rahul Agarwal 的这篇优秀的《走向数据科学》文章是一个很好的起点。</p><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd ir gy z fp pw fr fs px fu fw ip bi translated">每个数据科学家都必须知道的 5 个分类评估指标</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">以及具体什么时候使用它们？</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qg l qc qd qe qa qf kp pr"/></div></div></a></div></div><div class="ab cl pc pd hu pe" role="separator"><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph"/></div><div class="ij ik il im in"><h1 id="fb3b" class="kv kw iq bd kx ky pj la lb lc pk le lf jw pl jx lh jz pm ka lj kc pn kd ll lm bi translated">示例代码</h1><p id="8e79" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">本文中使用的所有代码都可以在以下位置获得:</p><div class="po pp gp gr pq pr"><a href="https://github.com/Polaris000/BlogCode/tree/main/MetricsMultilabel" rel="noopener  ugc nofollow" target="_blank"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd ir gy z fp pw fr fs px fu fw ip bi translated">blog code/metrics polar 000 处的多标签/BlogCode</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">示例代码来自我在 Medium 和我的个人网站上的博客文章。-blog code/metrics multilabel at main…</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">github.com</p></div></div><div class="qa l"><div class="qh l qc qd qe qa qf kp pr"/></div></div></a></div></div><div class="ab cl pc pd hu pe" role="separator"><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph"/></div><div class="ij ik il im in"><h1 id="6b94" class="kv kw iq bd kx ky pj la lb lc pk le lf jw pl jx lh jz pm ka lj kc pn kd ll lm bi translated">结论</h1><p id="875a" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">使用正确的度量标准评估您的模型是必要的。实验进行到一半时，意识到自己测量的东西是错误的，这可不是一件有趣的事情。</p><p id="227a" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">您可以通过找出哪些指标与您的用例最相关来避免这种情况，然后实际理解这些指标是如何计算的以及它们的含义。</p><p id="3ebb" class="pw-post-body-paragraph ln lo iq lp b lq mt jr ls lt mu ju lv lw mv ly lz ma mw mc md me mx mg mh mi ij bi translated">希望本文能让您了解如何评估多标签分类器。感谢阅读！</p></div><div class="ab cl pc pd hu pe" role="separator"><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph"/></div><div class="ij ik il im in"><h2 id="ce5e" class="mo kw iq bd kx oh oi dn lb oj ok dp lf lw ol om lh ma on oo lj me op oq ll or bi translated">更新</h2><blockquote class="os ot ou"><p id="9049" class="ln lo ov lp b lq mt jr ls lt mu ju lv ow mv ly lz ox mw mc md oy mx mg mh mi ij bi translated"><code class="fe my mz na mk b">22/21/12</code></p></blockquote><ul class=""><li id="a0f5" class="ns nt iq lp b lq mt lt mu lw nu ma nv me nw mi nx ny nz oa bi translated">修复召回公式中的问题</li></ul><blockquote class="os ot ou"><p id="895f" class="ln lo ov lp b lq mt jr ls lt mu ju lv ow mv ly lz ox mw mc md oy mx mg mh mi ij bi translated"><code class="fe my mz na mk b">2/11/21</code></p></blockquote><ul class=""><li id="717d" class="ns nt iq lp b lq mt lt mu lw nu ma nv me nw mi nx ny nz oa bi translated">改进措辞</li><li id="74d0" class="ns nt iq lp b lq ob lt oc lw od ma oe me of mi nx ny nz oa bi translated">添加示例代码</li></ul><blockquote class="os ot ou"><p id="065c" class="ln lo ov lp b lq mt jr ls lt mu ju lv ow mv ly lz ox mw mc md oy mx mg mh mi ij bi translated"><code class="fe my mz na mk b"><em class="iq">15/4/22</em></code></p></blockquote><ul class=""><li id="5d70" class="ns nt iq lp b lq mt lt mu lw nu ma nv me nw mi nx ny nz oa bi translated">添加关于转换数据的注释</li></ul><blockquote class="os ot ou"><p id="c9a4" class="ln lo ov lp b lq mt jr ls lt mu ju lv ow mv ly lz ox mw mc md oy mx mg mh mi ij bi translated"><code class="fe my mz na mk b"><em class="iq">18/1/23</em></code></p></blockquote><ul class=""><li id="0ab2" class="ns nt iq lp b lq mt lt mu lw nu ma nv me nw mi nx ny nz oa bi translated">修正计算步骤中的一个打字错误</li><li id="5fa5" class="ns nt iq lp b lq ob lt oc lw od ma oe me of mi nx ny nz oa bi translated">突出显示类名以提高可读性</li></ul></div></div>    
</body>
</html>