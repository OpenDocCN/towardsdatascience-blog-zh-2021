<html>
<head>
<title>When to use LASSO regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">何时使用套索回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/when-to-use-lasso-regression-8a4c4b334fa8?source=collection_archive---------21-----------------------#2021-12-28">https://towardsdatascience.com/when-to-use-lasso-regression-8a4c4b334fa8?source=collection_archive---------21-----------------------#2021-12-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="8ed1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您正在处理大数据，LASSO 回归是您数据科学武库中的一个很好的工具。计算效率很高<em class="kl">和</em>同时执行变量选择和回归。那有多厉害？！在本文中，我们将讨论何时需要使用这个强大的工具对多元线性回归建模。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/39957498cefec5550a487a9fc32eeec8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pv0g0Klm2-qEG7DBTaHKMA.jpeg"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">照片由迈克考克斯在 Unsplash。</p></figure><h1 id="52f0" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">1.你想要一个稀疏模型。</h1><p id="a6b9" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">在多元线性回归中使用 LASSO 的第一种情况是当您想要一个稀疏模型时。实际上，稀疏模型可以采取多种形式。最“经典”的情况是，你有一大组变量，但其中只有一小部分是真正重要的。但情况并非总是如此。例如，所有的变量可能都很重要，但是在一个局部区域内，只有少数变量是必需的。例如，假设您有高光谱成像数据，这些数据的波长彼此高度相关。因为它们高度相关，所以你只需要在高度相关的集合中选择一个变量。基本上，这一个变量充当所有与其高度相关的变量的代表。最后，也有可能你的所有变量都很重要，但只有少数变量解释了大部分变异。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi mf"><img src="../Images/279d26d3b3e2eda8544a53e0acd2bbf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ur0IHbp_ZLh3oz3a.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">该图显示了 15 种不同的组织类型，基因从上到下排列。套索正则多项式分类器显示相对少量的基因是重要的(4，718 个基因中的 254 个)，右边的条表示正系数，左边的条表示负系数。图片来自具有稀疏性的统计学习(2015)。</p></figure><p id="62d5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">套索回归适用于稀疏模型，因为它是围绕“赌稀疏”原则建立的。本质上，这一原则表明，如果我们想有效地估计我们的参数，“真相”必须是稀疏的。</p><blockquote class="mg mh mi"><p id="d25c" class="jn jo kl jp b jq jr js jt ju jv jw jx mj jz ka kb mk kd ke kf ml kh ki kj kk ij bi translated"><em class="iq">“使用在稀疏问题中表现良好的过程，因为没有过程在密集问题中表现良好。”</em></p><p id="b984" class="jn jo kl jp b jq jr js jt ju jv jw jx mj jz ka kb mk kd ke kf ml kh ki kj kk ij bi translated"><em class="iq">哈斯蒂，提布拉尼，&amp;弗里德曼(2015) </em></p></blockquote><p id="31ff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，一些人认为“真相”本质上是密集的，我们的模型应该考虑到这一点。绝对是哲学辩论的话题！</p><h1 id="1618" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">2.n &lt;&lt; p</h1><p id="5226" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">当预测变量的数量远大于观测值的数量时，您会希望选择套索回归而不是多元线性回归。当<em class="kl"> n </em> &lt; &lt; <em class="kl"> p </em>时，这就是所谓的大<em class="kl"> p </em>，小<em class="kl"> n </em>的问题。这是非常典型的基因组数据。有了基因组数据，每个人都有成千上万个基因。这意味着，仅仅为了使<em class="kl"> n </em>等于<em class="kl"> p </em>，你就必须收集数千个样本。这种情况通常不会发生，因为这相当昂贵，而且需要做很多工作。这通常意味着你会留下一个大问题，小问题。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi mm"><img src="../Images/86a9ebf8250733fa9c38a266ae9ae5ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pce9vfkAR5iB6g5RQ6znHg.jpeg"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">包含 1，000 个基因序列的微阵列数据。照片由国家癌症研究所在 Unsplash 上拍摄。</p></figure><p id="0bd4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl"> n </em> &lt; <em class="kl"> p </em>怎么了？本质上，如果真实的模型不是稀疏的，我们就没有足够的观测值来精确估计我们的参数。如果<em class="kl"> n &lt; p </em>，最小二乘法将失效，我们将无法获得唯一的估计值(Hastie，Tibshirani，&amp; Wainwright，2015)。现在，如果我们假设稀疏性，或者，如果我们假设只有一小部分变量是重要的，我们可以使用 LASSO 将许多系数缩小到零，只留下大<em class="kl"> p </em>，小<em class="kl"> n </em>场景中的重要系数。</p><h1 id="4d41" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">3.你有一些多重共线性。</h1><p id="5be3" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">最后，当您的模型中存在多重共线性时，套索回归非常有用。多重共线性意味着预测变量(也称为独立变量)并不那么独立。对于多元线性回归，这可能会导致系数发生显著变化，并影响模型的可解释性。幸运的是，由于 LASSO 内置的变量选择，它可以在不牺牲可解释性的情况下处理一些多重共线性。但是，如果共线性太高，LASSO 的变量选择性能将开始受到影响。如果有高度相关或共线的预测值，它将只选择其中一个。如果每次运行 LASSO 时得到不同的预测值，您将知道您的共线性是否过高。如果您确实发现您的数据有许多多重共线性，请尝试使用弹性网。这是岭回归和套索回归的混合，在多重共线性较高时效果很好。或者，你可以通过多次运行 LASSO 来破解它，每次运行都跟踪所有重要的预测因素。</p><p id="14f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">多元线性回归是对大量数据进行建模的一个很好的工具，但是它也有其局限性。幸运的是，LASSO 回归是处理稀疏模型和大数据的一个很好的选择。我希望你有机会自己尝试套索！快乐造型！</p><h2 id="7c5c" class="mn ld iq bd le mo mp dn li mq mr dp lm jy ms mt lq kc mu mv lu kg mw mx ly my bi translated">参考</h2><p id="eaa0" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">Hastie，T.J .，Tibshirani，R.J .，和 Friedman，J.H. (2001 年)。统计学习的要素:数据挖掘、推理和预测。纽约斯普林格。</p><p id="4152" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">t . j . hastie、r . j . TiB shirani 和 m . wain right(2015 年)。稀疏统计学习。佛罗里达州博卡拉顿 CRC 出版社。</p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><p id="81a3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">原载于 2021 年 12 月 28 日</em><a class="ae ng" href="https://thatdarndata.com/when-to-use-lasso-regression/" rel="noopener ugc nofollow" target="_blank"><em class="kl">【https://thatdarndata.com】</em></a><em class="kl">。</em></p></div></div>    
</body>
</html>