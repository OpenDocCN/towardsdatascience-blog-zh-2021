<html>
<head>
<title>Transfer Learning for Robust Image Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">鲁棒图像分类的迁移学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/transfer-learning-data-augmentation-for-robust-image-classification-643ca88b3175?source=collection_archive---------12-----------------------#2021-11-19">https://towardsdatascience.com/transfer-learning-data-augmentation-for-robust-image-classification-643ca88b3175?source=collection_archive---------12-----------------------#2021-11-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/95cf4566ce965a731b24184256cec582.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3Wbc1sE-GBdd47Xd"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">亨特·哈里特在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="1063" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">了解如何将Google Colab与VScode结合使用，并将您的解决方案提交给Kaggle</h2></div><p id="e3dd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">众所周知，Google Colab是一个非常有用的工具，可以使用Google提供的硬件来开发机器学习项目。的确，在Colab上使用单个页面构建项目有时很复杂，而使用像VScode这样的IDE来管理一切会容易得多。嗯，有解决的办法！</p><p id="e644" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">打开一个新的Colab笔记本，输入以下命令</p><figure class="lr ls lt lu gt is"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="e3cd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在在已经启动的网页编辑器中选择并打开<em class="lx">内容</em>文件夹。</p><figure class="lr ls lt lu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ly"><img src="../Images/33728789d99e4b20b95ec132d3d57f97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1rzmon_kTEhKPuA6Cun4JQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="b56a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你已经正式在Google Colab上使用VScode了！</p><h2 id="4c86" class="lz ma jg bd mb mc md dn me mf mg dp mh le mi mj mk li ml mm mn lm mo mp mq mr bi translated">资料组</h2><p id="8da8" class="pw-post-body-paragraph kv kw jg kx b ky ms kh la lb mt kk ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated">我们将使用<em class="lx"> dogs vs cats </em>数据集(它有一个免费的许可证)，您可以在下面的链接中找到:<a class="ae jd" href="https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/overview" rel="noopener ugc nofollow" target="_blank"><em class="lx">https://www . ka ggle . com/c/dogs-vs-cats-redux-kernels-edition/overview</em></a>。我将向您展示如何创建一个模型来解决这个二元分类任务，并提交您的解决方案。</p><p id="35c0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了下载该数据集，首先要做的是使用您的凭证访问Kaggle，然后下载<em class="lx"> kaggle.json </em>文件，您可以通过单击<em class="lx">创建新的API令牌</em>按钮来获得该文件。</p><figure class="lr ls lt lu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mx"><img src="../Images/9d8c02119f3998e5fe501f5b559ccd59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mhtu7C5E1RQ1oPthR2iZTg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="9055" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">您现在必须将我们下载的<em class="lx"> kaggle.json </em>文件加载到您的<em class="lx">内容</em>工作目录中。那我们来创建下面的<em class="lx">。这个项目需要的py </em>文件</p><figure class="lr ls lt lu gt is gh gi paragraph-image"><div class="gh gi my"><img src="../Images/c2cb1044f1aab3ccac8429ef639d3c59.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*5v26Rt8MmYMtxf1_tl-F8g.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><h2 id="6c13" class="lz ma jg bd mb mc md dn me mf mg dp mh le mi mj mk li ml mm mn lm mo mp mq mr bi translated">实用工具</h2><p id="b5f9" class="pw-post-body-paragraph kv kw jg kx b ky ms kh la lb mt kk ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated">让我们从<em class="lx"> utils.py </em>文件开始。我们首先定义一个函数来下载包含图像的压缩文件夹，并适当地提取它们。</p><figure class="lr ls lt lu gt is"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="550c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">您现在应该会看到这样的目录结构</p><figure class="lr ls lt lu gt is gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/c9814054210e581df2f814cd5b386d3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*XIpYFxFjczd6XuFr1y4Z4A.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="8406" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">您将在培训文件夹中找到的所有图像必须被分割并放入子文件夹<em class="lx"> train </em>和<em class="lx"> val </em>中，它们分别包含我们的培训和验证集的图像。基于sklearn库，我们编写了一个执行这种分割的函数。</p><figure class="lr ls lt lu gt is"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="bcf1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在同一个文件中，我们还需要两个函数。第一个是<em class="lx"> get_avg_size </em>，它将迭代训练集的所有图像，以计算所有图像的平均<em class="lx">高度</em>和<em class="lx">宽度</em>。这是需要的，因为我们应该指定卷积网络的输入大小，因为每个图像的输入是不同的，取平均值似乎是一个很好的妥协。</p><figure class="lr ls lt lu gt is"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="6b99" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，我们已经清理了文件系统e，知道了图片的平均大小，我们可以使用我们的数据来实际创建训练、验证和测试集，以提供给我们的网络。TensorFlow为我们提供了<em class="lx"> ImageDataGenerator </em>类<em class="lx"> </em>以非常简单的方式编写基本的数据处理。</p><p id="1cbd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下代码中的训练和验证预处理程序将对输入图像像素执行缩放，将它们除以255。</p><p id="6c3b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lx"> ImageDataGenerator </em>的后续输入参数允许我们通过添加现有数据的稍微修改的副本来修改和增加数据量(<strong class="kx jh">数据增加</strong>)。例如，<em class="lx"> rotation_range </em>将图像旋转0到360度之间的任意角度。</p><p id="5e59" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">您可以通过阅读Tensorflow文档了解用于数据扩充的所有参数:<a class="ae jd" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/keras/preprocessing/image/image Data generator</a></p><p id="5082" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">请注意，验证数据的预处理器没有数据扩充特性，因为我们希望保持不变，以便更好地验证我们的模型。</p><figure class="lr ls lt lu gt is"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="96e9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于<em class="lx">测试装置发生器</em>自然也应该做同样的事情。</p><figure class="lr ls lt lu gt is"><div class="bz fp l di"><div class="lv lw l"/></div></figure><h2 id="f383" class="lz ma jg bd mb mc md dn me mf mg dp mh le mi mj mk li ml mm mn lm mo mp mq mr bi translated">深度学习模型</h2><p id="0d8a" class="pw-post-body-paragraph kv kw jg kx b ky ms kh la lb mt kk ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated">我们现在继续在d<em class="lx">eeplearning _ models . py</em>文件中创建我们的模型。<br/>在解决大多数Kaggle任务时，你不会从头开始编写一个网络，而是使用一个名为<em class="lx"> base_model </em>的预训练模型，并使其适应手头的任务。把<em class="lx"> base_model </em>想象成一个已经学会识别图像中重要特征的模型。我们想做的是通过添加一个由其他密集层组成的<em class="lx">头</em>来适应它。在我们的例子中，最后的密集层将由单个神经元组成，该神经元将使用<em class="lx"> sigmoid </em>激活函数，以便我们将具有为0或1(猫或狗)的输出概率。</p><figure class="lr ls lt lu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi na"><img src="../Images/cc7a614689286b9d44a570b299f41141.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_59Qgk2QSxOYBO2yctbcBg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="3412" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们必须小心不要训练之前已经训练过的基础模型。<br/>我们要导入的base_model是<strong class="kx jh"> <em class="lx"> MobileNetV2 </em> </strong>非常常用于图像分类任务的任务。(<a class="ae jd" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v2/MobileNetV2" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/keras/applications/mobilenet _ v2/mobilenet v2</a>)</p><figure class="lr ls lt lu gt is"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="9137" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">训练模型</strong></p><p id="5969" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在让我们来处理<em class="lx"> model_training.py </em>文件。</p><p id="5e18" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在训练步骤中，我们将使用回调<em class="lx">模型检查点</em>,它允许我们不时地保存在每个时期找到的最佳模型(根据验证损失进行评估)。如果在<em class="lx">耐心=x </em>次之后没有改善，则<em class="lx">提前停止</em>回调用于中断训练阶段。我们照常编译和拟合模型。记得包括两个回调。</p><p id="8684" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在让我们处理一下<em class="lx"> model_training.py </em>文件。<br/>在训练步骤中，我们将使用回调<em class="lx">模型检查点</em>，它允许我们不时地保存在每个时期找到的最佳模型(根据验证损失进行评估)。如果在<em class="lx">耐心=x </em>次后没有改善，则<em class="lx">提前停止</em>回调用于中断训练阶段。所以让我们像往常一样编译和拟合模型。记得包括两个回调。</p><figure class="lr ls lt lu gt is"><div class="bz fp l di"><div class="lv lw l"/></div></figure><h2 id="bbc5" class="lz ma jg bd mb mc md dn me mf mg dp mh le mi mj mk li ml mm mn lm mo mp mq mr bi translated">预言</h2><p id="9ef2" class="pw-post-body-paragraph kv kw jg kx b ky ms kh la lb mt kk ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated">让我们在<em class="lx"> predictions.py </em>中编写我们的预测过程。</p><figure class="lr ls lt lu gt is"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="c60a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">预测完测试图像后，下载生成的<em class="lx"> submission.csv </em>文件，上传到Kaggle，才能完成挑战！</p><p id="f654" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你在排行榜上排到了什么位置？</p><h2 id="dc37" class="lz ma jg bd mb mc md dn me mf mg dp mh le mi mj mk li ml mm mn lm mo mp mq mr bi translated">结束了</h2><p id="2c7c" class="pw-post-body-paragraph kv kw jg kx b ky ms kh la lb mt kk ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated"><em class="lx">马赛洛·波利蒂</em></p><p id="2c71" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae jd" href="https://www.linkedin.com/in/marcello-politi/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>，<a class="ae jd" href="https://twitter.com/_March08_" rel="noopener ugc nofollow" target="_blank"> Twitter </a>，<a class="ae jd" href="https://march-08.github.io/digital-cv/" rel="noopener ugc nofollow" target="_blank"> CV </a></p></div></div>    
</body>
</html>