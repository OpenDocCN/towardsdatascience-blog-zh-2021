<html>
<head>
<title>How to Deal with Imbalanced Multiclass Datasets in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在Python中处理不平衡的多类数据集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-deal-with-imbalanced-multiclass-datasets-in-python-fe0bb3f2b669?source=collection_archive---------7-----------------------#2021-05-26">https://towardsdatascience.com/how-to-deal-with-imbalanced-multiclass-datasets-in-python-fe0bb3f2b669?source=collection_archive---------7-----------------------#2021-05-26</a></blockquote><div><div class="fc ik il im in io"/><div class="ip iq ir is it"><h2 id="eeed" class="iu iv iw bd b dl ix iy iz ja jb jc dk jd translated" aria-label="kicker paragraph">数据预处理</h2><div class=""/><div class=""><h2 id="7654" class="pw-subtitle-paragraph kc jf iw bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">这是一个现成的教程，介绍了用imblearn和scikit-learn平衡多类数据集的一些技巧</h2></div><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ku"><img src="../Images/216b9c6e57ac0e5907a7bbf7a5153ab0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qLzPzqfMBvcUKxxygrX74g.jpeg"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">图片由<a class="ae lk" href="https://pixabay.com/users/gidonpico-850967/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1757593" rel="noopener ugc nofollow" target="_blank"> Gidon Pico </a>提供，来自<a class="ae lk" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1757593" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="69ec" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在运行机器学习模型时，不平衡的数据集通常会产生较差的性能，尽管在某些情况下，评估指标会产生良好的结果。这可能是因为该模型擅长预测多数阶级，但在预测少数阶级时性能较差。由于评估指标计算的是多数类和少数类之间的平均值，所以最终的性能看起来还可以。</p><p id="e792" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">多数类是指数据集中代表性最强的类，而少数类是指数据集中代表性较弱的类。换句话说，多数阶级比少数阶级有更多的样本。在这种情况下，数据集是不平衡的。</p><blockquote class="mh mi mj"><p id="6a98" class="ll lm mk ln b lo lp kg lq lr ls kj lt ml lv lw lx mm lz ma mb mn md me mf mg ip bi translated">在大多数情况下，平衡可以提高模型的性能，尽管这并不总是正确的。</p></blockquote><p id="356d" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在本教程中，我处理多类数据集。多类数据集是指输出类的数量大于2的数据集。我提出两种策略来平衡多类数据集:</p><ul class=""><li id="ea82" class="mo mp iw ln b lo lp lr ls lu mq ly mr mc ms mg mt mu mv mw bi translated">流水线欠采样和过采样</li><li id="e1d6" class="mo mp iw ln b lo mx lr my lu mz ly na mc nb mg mt mu mv mw bi translated">玩级重。</li></ul><h1 id="1ee4" class="nc nd iw bd ne nf ng nh ni nj nk nl nm kl nn km no ko np kp nq kr nr ks ns nt bi translated">加载数据集</h1><p id="c0ef" class="pw-post-body-paragraph ll lm iw ln b lo nu kg lq lr nv kj lt lu nw lw lx ly nx ma mb mc ny me mf mg ip bi translated">首先，我将数据集作为一个<code class="fe nz oa ob oc b">pandas</code>数据帧加载。我利用了<a class="ae lk" href="https://raw.githubusercontent.com/jbrownlee/Datasets/master/glass.csv" rel="noopener ugc nofollow" target="_blank">玻璃数据集</a>和<a class="ae lk" href="https://raw.githubusercontent.com/jbrownlee/Datasets/master/glass.names" rel="noopener ugc nofollow" target="_blank">它们的名字</a>。这个数据集描述了玻璃的化学性质。更多详情请点击链接<a class="ae lk" href="https://machinelearningmastery.com/multi-class-imbalanced-classification/" rel="noopener ugc nofollow" target="_blank">。</a></p><pre class="kv kw kx ky gu od oc oe of aw og bi"><span id="4c97" class="oh nd iw oc b gz oi oj l ok ol">import pandas as pd</span><span id="40e4" class="oh nd iw oc b gz om oj l ok ol">df = pd.read_csv('glass.csv')<br/>df.head()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj on"><img src="../Images/017b1ba3387f86634d40f820fcb33ab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rR2vKfl6FULQUEXFtT1deg.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="3765" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">该数据集由214个样本和7个类别组成。</p><h1 id="f2a0" class="nc nd iw bd ne nf ng nh ni nj nk nl nm kl nn km no ko np kp nq kr nr ks ns nt bi translated">准备数据</h1><p id="3568" class="pw-post-body-paragraph ll lm iw ln b lo nu kg lq lr nv kj lt lu nw lw lx ly nx ma mb mc ny me mf mg ip bi translated">我构建了两个变量，<code class="fe nz oa ob oc b">X</code>和<code class="fe nz oa ob oc b">y</code>，分别包含输入特征和输出类。为此，我计算输入特征，并将它们存储到一个名为<code class="fe nz oa ob oc b">features</code>的变量中。</p><pre class="kv kw kx ky gu od oc oe of aw og bi"><span id="06cd" class="oh nd iw oc b gz oi oj l ok ol">features = []<br/>for feature in df.columns:<br/>    if feature != 'target':<br/>        features.append(feature)<br/>X = df[features]<br/>y = df['target']</span></pre><p id="0ef7" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">通过利用由<code class="fe nz oa ob oc b">sklearn</code>库提供的<code class="fe nz oa ob oc b">train_test_split()</code>函数，将数据集分成两部分:训练集和测试集。我将测试集大小设置为<code class="fe nz oa ob oc b">0.2</code>(即整个数据集的20%)。</p><pre class="kv kw kx ky gu od oc oe of aw og bi"><span id="a6a6" class="oh nd iw oc b gz oi oj l ok ol">from sklearn.model_selection import train_test_split</span><span id="5487" class="oh nd iw oc b gz om oj l ok ol">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)</span></pre><p id="3006" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在，我计算训练集中每个目标类的样本数。我利用了<code class="fe nz oa ob oc b">value_counts()</code>函数。我注意到数据集是不平衡的。</p><blockquote class="mh mi mj"><p id="6752" class="ll lm mk ln b lo lp kg lq lr ls kj lt ml lv lw lx mm lz ma mb mn md me mf mg ip bi translated">平衡仅适用于训练集。</p></blockquote><pre class="kv kw kx ky gu od oc oe of aw og bi"><span id="8ce7" class="oh nd iw oc b gz oi oj l ok ol">import matplotlib.pyplot as plt</span><span id="e362" class="oh nd iw oc b gz om oj l ok ol">count = y_train.value_counts()<br/>count.plot.bar()<br/>plt.ylabel('Number of records')<br/>plt.xlabel('Target Class')<br/>plt.show()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj oo"><img src="../Images/2ea00096b3ff3a537fc7999a7268470c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WpM4n5YCGJiLQjPhPqzTSA.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><h1 id="7beb" class="nc nd iw bd ne nf ng nh ni nj nk nl nm kl nn km no ko np kp nq kr nr ks ns nt bi translated">建立不平衡模型</h1><p id="bfb4" class="pw-post-body-paragraph ll lm iw ln b lo nu kg lq lr nv kj lt lu nw lw lx ly nx ma mb mc ny me mf mg ip bi translated">在平衡训练集之前，我计算了具有不平衡数据的模型的性能。我利用一个<code class="fe nz oa ob oc b">KNeighborsClassifier</code>进行测试。我还从<code class="fe nz oa ob oc b">scikitplot</code>库中导入了其他有用的函数，来绘制ROC和precision recall曲线。具体来说，首先我建立模型，然后我拟合训练集，最后我通过应用于测试集的<code class="fe nz oa ob oc b">predict_proba()</code>函数计算模型的性能。</p><pre class="kv kw kx ky gu od oc oe of aw og bi"><span id="4d16" class="oh nd iw oc b gz oi oj l ok ol">from sklearn.neighbors import KNeighborsClassifier<br/>from scikitplot.metrics import plot_roc<br/>from scikitplot.metrics import plot_precision_recall</span><span id="cf52" class="oh nd iw oc b gz om oj l ok ol">model = DecisionTreeClassifier()<br/>model.fit(X_train, y_train)<br/>y_score = model.predict_proba(X_test)<br/>y_pred = model.predict(X_test)</span><span id="36b8" class="oh nd iw oc b gz om oj l ok ol"># Plot metrics <br/>plot_roc(y_test, y_score)<br/>plt.show()<br/>    <br/>plot_precision_recall(y_test, y_score)<br/>plt.show()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj op"><img src="../Images/994f07c3e46adad7f048a5d45add5ec0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N9q5Q5zaf3JcovYmImfI8g.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj oo"><img src="../Images/70d9eb0ae2d5df474d4a46a73828b94c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QLdZahyS1RGS4z3QF0vqNg.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><h1 id="e464" class="nc nd iw bd ne nf ng nh ni nj nk nl nm kl nn km no ko np kp nq kr nr ks ns nt bi translated">流水线欠采样和过采样</h1><p id="8264" class="pw-post-body-paragraph ll lm iw ln b lo nu kg lq lr nv kj lt lu nw lw lx ly nx ma mb mc ny me mf mg ip bi translated">第一种策略涉及流水线的创建，该流水线对多数类进行欠采样，对少数类进行过采样。这里的要点是定义一个阈值，该阈值划分多数类和少数类，以及每个类所需的样本数。在这个特定示例中，我们将阈值设置为等于每个类别的期望样本数。</p><p id="0fee" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">一种可能的解决方案是将阈值设置为类中样本数量的中值。因此，我可以将阈值设置为19，并考虑样本数量大于阈值的多数a类。类似地，少数类是样本数量少于阈值的类。</p><p id="cb28" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我计算中间值，并将其转换为整数。</p><pre class="kv kw kx ky gu od oc oe of aw og bi"><span id="03ed" class="oh nd iw oc b gz oi oj l ok ol">import numpy as np<br/>n_samples = count.median().astype(np.int64)</span></pre><p id="5348" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在我可以对最具代表性的类进行欠采样。首先，我禁止警告。</p><pre class="kv kw kx ky gu od oc oe of aw og bi"><span id="24b2" class="oh nd iw oc b gz oi oj l ok ol">import warnings<br/>warnings.filterwarnings('ignore')</span></pre><p id="6983" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">然后，我定义一个效用函数，它接收数据集、阈值(<code class="fe nz oa ob oc b">n_samples</code>)和相关类(<code class="fe nz oa ob oc b">majority</code>或<code class="fe nz oa ob oc b">minority</code>)作为输入。该函数返回一个<code class="fe nz oa ob oc b">dict</code>,其中包含属于相关类的每个类的期望样本数。</p><pre class="kv kw kx ky gu od oc oe of aw og bi"><span id="ce6a" class="oh nd iw oc b gz oi oj l ok ol">def sampling_strategy(X,y,n_samples, t='majority'):<br/>    target_classes = ''<br/>    if t == 'majority':<br/>        target_classes = y.value_counts() &gt; n_samples<br/>    elif t == 'minority':<br/>        target_classes = y.value_counts() &lt; n_samples<br/>    tc = target_classes[target_classes == True].index<br/>    #target_classes_all = y.value_counts().index<br/>    sampling_strategy = {}<br/>    for target in tc:<br/>        sampling_strategy[target] = n_samples<br/>    return sampling_strategy</span></pre><p id="744f" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在我对大多数类进行欠采样。我利用了<code class="fe nz oa ob oc b">imblearn</code>库。</p><pre class="kv kw kx ky gu od oc oe of aw og bi"><span id="8c99" class="oh nd iw oc b gz oi oj l ok ol">from imblearn.under_sampling import ClusterCentroids<br/>under_sampler = ClusterCentroids(sampling_strategy=sampling_strategy(X_train,y_train,n_samples,t='majority'))<br/>X_under, y_under = under_sampler.fit_resample(X_train, y_train)</span></pre><p id="0a85" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我注意到多数类中的记录数量被设置为<code class="fe nz oa ob oc b">n_samples</code>。</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj oq"><img src="../Images/6ea9d9590f5b214a939556be5bd607df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NPDsFXJ1hcvIcE2TGtg_kw.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="fdda" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">然后，我对较少表示的类进行过采样。我利用了<code class="fe nz oa ob oc b">SMOTE</code>过采样策略。</p><pre class="kv kw kx ky gu od oc oe of aw og bi"><span id="7222" class="oh nd iw oc b gz oi oj l ok ol">from imblearn.over_sampling import SMOTE<br/>over_sampler = SMOTE(sampling_strategy=sampling_strategy(X_under, y_under,n_samples, t='minority'),k_neighbors=2)<br/>X_bal, y_bal = over_sampler.fit_resample(X_under, y_under)</span></pre><p id="0333" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">最终我有了一个平衡的数据集。</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj or"><img src="../Images/fb4f630ce8d83bb97d63d0dd354c6446.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ei24UNN_SmwbShx383hGBQ.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="1727" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我在新的平衡数据集上训练模型，我注意到ROC曲线改善了，而精确召回曲线似乎降低了。然而，看看类别3，在原始模型中的精确度和召回率低于平衡模型。这意味着该模型现在能够更好地预测少数民族阶层。</p><pre class="kv kw kx ky gu od oc oe of aw og bi"><span id="7f9b" class="oh nd iw oc b gz oi oj l ok ol">model = KNeighborsClassifier()<br/>model.fit(X_bal, y_bal)<br/>y_score = model.predict_proba(X_test)</span><span id="ef18" class="oh nd iw oc b gz om oj l ok ol">y_pred = model.predict(X_test)</span><span id="e7b4" class="oh nd iw oc b gz om oj l ok ol"># Plot metrics <br/>plot_roc(y_test, y_score)<br/>plt.show()<br/>    <br/>plot_precision_recall(y_test, y_score)<br/>plt.show()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj oq"><img src="../Images/dfa8582c28a149100e6388e1c8050d17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O8RNiy-aaKgmd1MHu2XI-Q.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj os"><img src="../Images/816fb03feca794ccf5eca7a5c7c02510.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xeLFwA7-bHtAUYVUbKu4WA.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><h1 id="c9b3" class="nc nd iw bd ne nf ng nh ni nj nk nl nm kl nn km no ko np kp nq kr nr ks ns nt bi translated">玩重量级游戏</h1><p id="7264" class="pw-post-body-paragraph ll lm iw ln b lo nu kg lq lr nv kj lt lu nw lw lx ly nx ma mb mc ny me mf mg ip bi translated">平衡的替代方法是在构建模型时指定原始数据集中的类权重。这允许算法给予少数类更多的重要性。可以通过<code class="fe nz oa ob oc b">sklearn.utils</code>库的<a class="ae lk" href="https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html" rel="noopener ugc nofollow" target="_blank"> class_weight() </a>函数计算类权重。</p><pre class="kv kw kx ky gu od oc oe of aw og bi"><span id="013b" class="oh nd iw oc b gz oi oj l ok ol">from sklearn.utils import class_weight</span><span id="9cc4" class="oh nd iw oc b gz om oj l ok ol">classes = np.unique(y_train)<br/>cw = class_weight.compute_class_weight('balanced', classes, y_train)<br/>weights = dict(zip(classes,cw))</span></pre><p id="2ecc" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在我可以将类权重作为输入提供给一个分类器，比如一个<code class="fe nz oa ob oc b">DecisionTreeClassifier</code>，并计算模型的性能。我没有像在教程的前一部分那样使用<code class="fe nz oa ob oc b">KNeighborsClassifier</code>，因为它不支持类权重。</p><pre class="kv kw kx ky gu od oc oe of aw og bi"><span id="4c27" class="oh nd iw oc b gz oi oj l ok ol">from sklearn.tree import DecisionTreeClassifier<br/>model = DecisionTreeClassifier(class_weight=weights)<br/>model.fit(X_train, y_train)<br/>y_score = model.predict_proba(X_test)</span><span id="904f" class="oh nd iw oc b gz om oj l ok ol">y_pred = model.predict(X_test)</span><span id="ca9d" class="oh nd iw oc b gz om oj l ok ol"># Plot metrics <br/>plot_roc(y_test, y_score)<br/>plt.show()<br/>    <br/>plot_precision_recall(y_test, y_score)<br/>plt.show()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ot"><img src="../Images/1423a337cd354d5ad0976b66dcefe644.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P4HPkNavLrt9e-4p6Y7T2w.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ou"><img src="../Images/8de6dbcda576d4e5cad3f17466a17ed1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FmEGSecuAbH3_v7qD4e3NA.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><h1 id="6e76" class="nc nd iw bd ne nf ng nh ni nj nk nl nm kl nn km no ko np kp nq kr nr ks ns nt bi translated">摘要</h1><p id="c0e8" class="pw-post-body-paragraph ll lm iw ln b lo nu kg lq lr nv kj lt lu nw lw lx ly nx ma mb mc ny me mf mg ip bi translated">在本教程中，我已经说明了如何执行多类数据集的平衡。可以采用两种可能的策略:欠采样后跟随过采样，或者定义类权重。</p><p id="a8a1" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">如果你对数据预处理感兴趣，可以在<a class="ae lk" href="https://medium.com/@angelica.loduca" rel="noopener">我的主页</a>找到其他文章。</p><p id="6817" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">如果你想了解我的研究和其他活动的最新情况，你可以在<a class="ae lk" href="https://twitter.com/alod83" rel="noopener ugc nofollow" target="_blank"> Twitter </a>、<a class="ae lk" href="https://www.youtube.com/channel/UC4O8-FtQqGIsgDW_ytXIWOg?view_as=subscriber" rel="noopener ugc nofollow" target="_blank"> Youtube </a>和<a class="ae lk" href="https://github.com/alod83" rel="noopener ugc nofollow" target="_blank"> Github </a>上关注我。</p><p id="dd82" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">感谢阅读！你可以从<a class="ae lk" href="https://github.com/alod83/data-science/blob/master/Preprocessing/Balancing/Multiclass%20Balancing.ipynb" rel="noopener ugc nofollow" target="_blank">我的Github库</a>下载完整代码。</p><h1 id="df6a" class="nc nd iw bd ne nf ng nh ni nj nk nl nm kl nn km no ko np kp nq kr nr ks ns nt bi translated">相关文章</h1><div class="ov ow gq gs ox oy"><a rel="noopener follow" target="_blank" href="/how-to-balance-a-dataset-in-python-36dff9d12704"><div class="oz ab fp"><div class="pa ab pb cl cj pc"><h2 class="bd jg gz z fq pd fs ft pe fv fx jf bi translated">如何在Python中平衡数据集</h2><div class="pf l"><h3 class="bd b gz z fq pd fs ft pe fv fx dk translated">本教程属于如何提高机器学习算法的性能系列。在本教程中，我…</h3></div><div class="pg l"><p class="bd b dl z fq pd fs ft pe fv fx dk translated">towardsdatascience.com</p></div></div><div class="ph l"><div class="pi l pj pk pl ph pm le oy"/></div></div></a></div><div class="ov ow gq gs ox oy"><a rel="noopener follow" target="_blank" href="/a-complete-data-analysis-workflow-in-python-and-scikit-learn-9a77f7c283d3"><div class="oz ab fp"><div class="pa ab pb cl cj pc"><h2 class="bd jg gz z fq pd fs ft pe fv fx jf bi translated">Python和scikit中的完整数据分析工作流程-学习</h2><div class="pg l"><p class="bd b dl z fq pd fs ft pe fv fx dk translated">towardsdatascience.com</p></div></div><div class="ph l"><div class="pn l pj pk pl ph pm le oy"/></div></div></a></div><h1 id="f942" class="nc nd iw bd ne nf ng nh ni nj nk nl nm kl nn km no ko np kp nq kr nr ks ns nt bi translated">新到中？您可以每月订阅几美元，并解锁无限的文章— <a class="ae lk" href="https://alod83.medium.com/membership" rel="noopener">单击此处</a>。</h1></div></div>    
</body>
</html>