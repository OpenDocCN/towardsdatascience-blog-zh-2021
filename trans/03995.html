<html>
<head>
<title>How to use Pytorch as a general optimizer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Pytorch作为通用优化器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-use-pytorch-as-a-general-optimizer-a91cbf72a7fb?source=collection_archive---------4-----------------------#2021-04-04">https://towardsdatascience.com/how-to-use-pytorch-as-a-general-optimizer-a91cbf72a7fb?source=collection_archive---------4-----------------------#2021-04-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/749220319a1a682c43cad2e6e7accb45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZWuYkSvtsk_WTrQxhy91Kg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图片作者。</p></figure><div class=""/><p id="c180" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">Pytorch真的很有趣，如果你正在寻找一个框架来开始学习神经网络，我强烈推荐它——在Pytorch <a class="ae ld" rel="noopener" target="_blank" href="/up-and-running-with-pytorch-minibatching-dataloading-and-model-building-7c3fdacaca40">这里</a>可以看到我关于如何使用基本神经网络的简短教程。</p><p id="8b68" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然而，许多人没有意识到Pytorch可以用于一般的梯度优化。换句话说，<strong class="kh jj">您可以使用Pytorch找到任意复杂优化目标的最小值或最大值。但是，你为什么要这样做呢？我能想到的理由至少有三个(还有很多)。</strong></p><ol class=""><li id="67d6" class="le lf ji kh b ki kj km kn kq lg ku lh ky li lc lj lk ll lm bi translated">您已经熟悉Pytorch，不想再学习另一个优化框架</li><li id="ebb9" class="le lf ji kh b ki ln km lo kq lp ku lq ky lr lc lj lk ll lm bi translated">您希望对Pytorch模型的结果进行优化，即，您希望对Pytorch神经网络的预测进行优化(例如，第一阶段神经网络可能会预测客户参与特定高价值活动的倾向，优化器用于确定在给定一些约束条件(如营销预算)的情况下哪个活动是最佳的)。</li><li id="117b" class="le lf ji kh b ki ln km lo kq lp ku lq ky lr lc lj lk ll lm bi translated">您希望使用Pytorch中定义的高级优化器，比如Adam。</li></ol><h2 id="9435" class="ls lt ji bd lu lv lw dn lx ly lz dp ma kq mb mc md ku me mf mg ky mh mi mj mk bi translated">实现通用优化器</h2><p id="b6a1" class="pw-post-body-paragraph kf kg ji kh b ki ml kk kl km mm ko kp kq mn ks kt ku mo kw kx ky mp la lb lc im bi translated">嗯……你实际上不需要实现任何东西，如果你已经熟悉Pytorch，你只需要简单地写一个Pytorch自定义模块，就像你写神经网络一样，Pytorch会处理好所有其他的事情。让我们看一个成功的例子。</p><p id="4c20" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了演示，我们将定义一个简单的函数——指数衰减函数。让我们定义数据——标量浮点值<code class="fe mq mr ms mt b">a, k, b</code>是函数的未知参数，优化的目标是估计这些参数。</p><pre class="mu mv mw mx gt my mt mz na aw nb bi"><span id="1028" class="ls lt ji mt b gy nc nd l ne nf">import numpy as np<br/>import torch<br/>import matplotlib.pyplot as plt<br/>from torch import nn<br/>from torch.functional import F<br/>from copy import copy</span><span id="a200" class="ls lt ji mt b gy ng nd l ne nf">import seaborn as sns</span><span id="5a5c" class="ls lt ji mt b gy ng nd l ne nf">sns.set_style("whitegrid")</span><span id="c068" class="ls lt ji mt b gy ng nd l ne nf">n = 1000<br/>noise = torch.Tensor(np.random.normal(0, 0.02, size=n))<br/>x = torch.arange(n)<br/>a, k, b = 0.7, .01, 0.2<br/>y = a * np.exp(-k * x) + b + noise</span><span id="9296" class="ls lt ji mt b gy ng nd l ne nf">plt.figure(figsize=(14, 7))<br/>plt.scatter(x, y, alpha=0.4)</span></pre><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/9dc554ceb78f6394f8062e3be806bd73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BpO_NRRA9oe8H-oaI_IaEg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">指数衰减函数——作者图片。</p></figure><p id="0c7a" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">接下来，让我们定义模型和训练循环:</p><pre class="mu mv mw mx gt my mt mz na aw nb bi"><span id="653d" class="ls lt ji mt b gy nc nd l ne nf">class Model(nn.Module):<br/>    """Custom Pytorch model for gradient optimization.<br/>    """<br/>    def __init__(self):<br/>        <br/>        super().__init__()<br/>        # initialize weights with random numbers<br/>        weights = torch.distributions.Uniform(0, 0.1).sample((3,))<br/>        # make weights torch parameters<br/>        self.weights = nn.Parameter(weights)        <br/>        <br/>    def forward(self, X):<br/>        """Implement function to be optimised. In this case, an exponential decay<br/>        function (a + exp(-k * X) + b),<br/>        """<br/>        a, k, b = self.weights<br/>        return a * torch.exp(-k * X) + b<br/>    <br/>def training_loop(model, optimizer, n=1000):<br/>    "Training loop for torch model."<br/>    losses = []<br/>    for i in range(n):<br/>        preds = model(x)<br/>        loss = F.mse_loss(preds, y).sqrt()<br/>        loss.backward()<br/>        optimizer.step()<br/>        optimizer.zero_grad()<br/>        losses.append(loss)  <br/>    return losses</span></pre><p id="9962" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">如果你熟悉Pytorch，这里没有什么特别的东西。我们在这里要做的关键事情是定义我们自己的权重，并手动将它们注册为Pytorch参数，这就是这些行要做的事情:</p><pre class="mu mv mw mx gt my mt mz na aw nb bi"><span id="7054" class="ls lt ji mt b gy nc nd l ne nf">weights = torch.distributions.Uniform(0, 0.1).sample((3,))<br/># make weights torch parameters<br/>self.weights = nn.Parameter(weights)</span></pre><p id="1934" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">下面几行确定了要优化的功能。你可以用你想要最小化的函数的定义来代替它们。</p><pre class="mu mv mw mx gt my mt mz na aw nb bi"><span id="c290" class="ls lt ji mt b gy nc nd l ne nf">a, k, b = self.weights<br/>return a * torch.exp(-k * X) + b</span></pre><p id="79e8" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">通过调用<code class="fe mq mr ms mt b">nn.Parameter</code>,我们定义的权重将以与标准Pytorch参数相同的方式运行——即，它们可以计算梯度并根据损失函数进行更新。训练循环简单地在<code class="fe mq mr ms mt b">n</code>历元上迭代，每次估计均方误差并更新梯度。</p><p id="8f67" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">运行模型的时间到了，我们将使用Adam进行优化。</p><pre class="mu mv mw mx gt my mt mz na aw nb bi"><span id="280c" class="ls lt ji mt b gy nc nd l ne nf"># instantiate model<br/>m = Model()<br/># Instantiate optimizer<br/>opt = torch.optim.Adam(m.parameters(), lr=0.001)</span><span id="4705" class="ls lt ji mt b gy ng nd l ne nf">losses = training_loop(m, opt)<br/>plt.figure(figsize=(14, 7))<br/>plt.plot(losses)<br/>print(m.weights)</span></pre><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nh"><img src="../Images/fbb7eb1feda41a4c33fae537f689adbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*14QSukqo4RKG1ytFLJaW0A.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">超过1000个时代的损失—作者图片..</p></figure><p id="dc36" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">上面的图显示了超过1000个时期的损失函数——你可以看到，在大约600年后，它没有显示出进一步改善的迹象。a、k、b的估计权重为0.697、0.0099、0.1996，非常接近定义函数的参数，我们可以使用训练好的模型来估计函数:</p><pre class="mu mv mw mx gt my mt mz na aw nb bi"><span id="633f" class="ls lt ji mt b gy nc nd l ne nf">preds = m(x)<br/>plt.figure(figsize=(14, 7))<br/>plt.scatter(x, preds.detach().numpy())<br/>plt.scatter(x, y, alpha=.3)</span></pre><figure class="mu mv mw mx gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/749220319a1a682c43cad2e6e7accb45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZWuYkSvtsk_WTrQxhy91Kg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">蓝线是估计的指数衰减曲线——图片由作者提供。</p></figure><p id="3b50" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">您可以看到，通过优化参数，我们现在可以拟合数据的指数衰减。虽然你可以用来自<code class="fe mq mr ms mt b">scipy</code>的<code class="fe mq mr ms mt b">curve_fit</code>做同样的事情，但是我认为Pytorch更大的灵活性来适应更复杂的功能是值得花时间去学习的。</p><p id="bee2" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh jj">总结</strong></p><p id="6282" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">虽然大多数人会使用Pytorch来构建神经网络，但该框架的灵活性使它非常通用。在这篇文章中，我们拟合了一条由指数衰减函数定义的简单曲线，但是没有理由为什么相同的构建块不能扩展到任意复杂的优化函数。</p><p id="490b" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">希望这是有帮助的，如果你有任何想法，评论或问题，请告诉我。</p><p id="72cd" class="pw-post-body-paragraph kf kg ji kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">感谢阅读！</p></div></div>    
</body>
</html>