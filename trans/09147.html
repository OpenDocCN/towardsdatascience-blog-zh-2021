<html>
<head>
<title>Neural Network for input of variable length using Tensorflow TimeDistributed wrapper</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">采用张量流时间分布包装器的变长输入神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-network-for-input-of-variable-length-using-tensorflow-timedistributed-wrapper-a45972f4da51?source=collection_archive---------5-----------------------#2021-08-24">https://towardsdatascience.com/neural-network-for-input-of-variable-length-using-tensorflow-timedistributed-wrapper-a45972f4da51?source=collection_archive---------5-----------------------#2021-08-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5f6c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何使用Tensorflow时间分布包装器处理可变长度输入(通常是信号)的指南</h2></div><h1 id="d5f5" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">目录</h1><ol class=""><li id="4110" class="kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo bi translated">为什么输入长度可变？</li><li id="1411" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">Tensorflow时间分布式包装器</li><li id="618e" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">数据生成程序</li><li id="c517" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">参考</li></ol><h1 id="33df" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">为什么输入长度可变？</h1><p id="6a68" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">你是否曾经想要将神经网络应用于你的数据集，但是数据(信号、时间序列、文本等。)有了一个<strong class="kz ir">可变长度</strong>？不幸的是，这种情况对于数据科学家来说很常见。</p><blockquote class="mh mi mj"><p id="f28d" class="lu lv mk kz b la ml jr lw lc mm ju lx mn mo lz ma mp mq mc md mr ms mf mg lk ij bi translated">正如我们所知，在现实世界中，数据永远不会像我们希望的那样漂亮和有条理。</p></blockquote><p id="4a2b" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">有各种各样的方法来解决这个问题，但是没有一个让我满意。</p><p id="83f6" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">最普遍采用的解决方案是<strong class="kz ir">将所有输入截断</strong>到相同长度，这通常与较短长度的输入相一致。然而，这造成了巨大的数据损失，正如我们所知，数据对我们来说是金子。</p><p id="970a" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">一个可能的替代方案是它的反面，即<a class="ae mt" href="https://www.tensorflow.org/guide/keras/masking_and_padding" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir">填充</strong> </a>(添加数据直到所有信号长度相同)。填充的问题是，它添加了没有实际意义的数据，而且输入非常长，网络的规模变得不可持续。当然，填充可以通过<a class="ae mt" href="https://www.tensorflow.org/tutorials/images/data_augmentation" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir">增强</strong> </a>来完成。然而，特别是对于数据顺序非常重要的信号，应用增强会“污染”这些信息。</p><blockquote class="mh mi mj"><p id="98ba" class="lu lv mk kz b la ml jr lw lc mm ju lx mn mo lz ma mp mq mc md mr ms mf mg lk ij bi translated">我感到很失落，但当我看到这个包装纸时，我知道它就是我要的。</p></blockquote><h1 id="4acf" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">Tensorflow时间分布式包装器</h1><p id="3bae" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi mu translated"><span class="l mv mw mx bm my mz na nb nc di">T</span>he<a class="ae mt" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed" rel="noopener ugc nofollow" target="_blank"><strong class="kz ir">time distributed</strong></a>wrapper允许对输入的每个时间片应用一个层。</p><p id="c561" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">假设作为输入，我们有一个由以100 Hz(每秒100点)采样的<strong class="kz ir">信号</strong>组成的数据集。我们的目标是对每个30秒的片段进行分类(称为<strong class="kz ir">纪元</strong>)。</p><p id="f87c" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">因此，我们希望建立一个深度神经网络，递归地应用于这些片段中的每一个。为了阐明网络的工作原理，下面是一个简化的示意图:</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi nd"><img src="../Images/9c3cfb2ee0261a493e74bd5d72945413.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qo9Ipvl2e1rkbfU-rZd_YQ.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">网络如何运作的模式[图片由作者提供]</p></figure><p id="77ff" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">让我们从导入所有必需的元素开始:</p><pre class="ne nf ng nh gt nt nu nv nw aw nx bi"><span id="2b65" class="ny kg iq nu b gy nz oa l ob oc">from tensorflow.keras.layers import Conv2D, TimeDistributed,Dropout,Input, Dense,\<br/>    BatchNormalization, GRU, Layer, Flatten<br/>from tensorflow.keras.regularizers import l2<br/>from tensorflow.keras.models import Model<br/>from tensorflow.keras.utils import plot_model<br/>from tensorflow.keras.optimizers import Adam</span></pre><p id="8d30" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">现在我们可以建立我们的网络。我们将使用<a class="ae mt" href="https://www.tensorflow.org/tutorials/images/cnn" rel="noopener ugc nofollow" target="_blank"><strong class="kz ir">【CNN】</strong></a>卷积块从原始信号中提取特征，随后使用<strong class="kz ir"/><a class="ae mt" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU" rel="noopener ugc nofollow" target="_blank"><strong class="kz ir">【GRU】</strong></a>组合提取的特征。所以让我们写我们的函数:</p><pre class="ne nf ng nh gt nt nu nv nw aw nx bi"><span id="9038" class="ny kg iq nu b gy nz oa l ob oc">def nn(shape_1,shape_2):<br/>    input = Input(shape=[None, shape_1,shape_2,1])<br/><br/>    conv1 = TimeDistributed(Conv2D(filters=32, kernel_size=[32,1], activation='relu',strides =(3,1)))(input)<br/>    batch1 = TimeDistributed(BatchNormalization())(conv1)<br/><br/><br/>    conv2 = TimeDistributed(Conv2D(filters=32, kernel_size=[32,1], activation='relu',strides =(2,1)))(batch1)<br/>    batch2 = TimeDistributed(BatchNormalization())(conv2)<br/><br/>    conv3 = TimeDistributed(Conv2D(filters=32, kernel_size=[32,1], activation='relu',strides =(2,1)))(batch2)<br/>    batch3 = TimeDistributed(BatchNormalization())(conv3)<br/><br/>    conv4 = TimeDistributed(Conv2D(filters=32, kernel_size=[32,1], activation='relu',strides =(2,1)))(batch3)<br/>    batch4 = TimeDistributed(BatchNormalization())(conv4)<br/><br/>    flat = TimeDistributed(Flatten())(batch4)<br/><br/><br/>    gru1 = GRU(256, activation='relu',return_sequences=True, kernel_regularizer=l2(0.01))(flat)<br/>    drop1 = Dropout(rate=0.4)(gru1)<br/>    batch1 = BatchNormalization()(drop1)<br/><br/>    gru2 = GRU(128, activation='relu',return_sequences=True, kernel_regularizer=l2(0.01))(batch1)<br/>    drop2 = Dropout(rate=0.4)(gru2)<br/>    batch2 = BatchNormalization()(drop2)<br/><br/><br/>    dense = TimeDistributed(Dense(2, activation='softmax'),name = 'output')(batch2)<br/><br/><br/>    return [input], [dense]</span></pre><p id="a8e8" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">正如我们所见，网络由<strong class="kz ir">四个卷积层</strong>和<strong class="kz ir">两个卷积层</strong>组成。网络中还有其他元素，如<a class="ae mt" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir">批量归一化层</strong> </a>，由于时间原因我们不再赘述。最后，一个<strong class="kz ir"> </strong> <a class="ae mt" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir">密集层</strong> </a>允许分类。如果您想要对整个信号而不是每个时期进行分类，我们可以使用以下内容作为最后一层:</p><pre class="ne nf ng nh gt nt nu nv nw aw nx bi"><span id="37d2" class="ny kg iq nu b gy nz oa l ob oc">dense = Dense(2, activation='sigmoid',name = 'status_output')(batch2)</span></pre><p id="9f9f" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">需要注意的重要一点是，包装器<strong class="kz ir">不应该应用于时间层</strong>，比如GRU或LSTM。默认情况下，这种类型的层已经可以处理可变长度。</p><p id="27d1" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">一旦函数准备就绪，让我们构建模型并详细查看它:</p><pre class="ne nf ng nh gt nt nu nv nw aw nx bi"><span id="b404" class="ny kg iq nu b gy nz oa l ob oc">EPOCH_LENGTH = 30<br/>SAMPLE_RATE = 100<br/><br/>input, output = nn(SAMPLE_RATE*EPOCH_LENGTH,1)<br/>model = Model(inputs=input,outputs=output)<br/><br/>optimizer = Adam(learning_rate=2*1e-4)<br/><br/># Compile Model<br/>model.compile(optimizer=optimizer, loss={<br/>                  'output': 'sparse_categorical_crossentropy', },<br/>              metrics={<br/>                  'output': 'sparse_categorical_accuracy', },<br/>              sample_weight_mode='temporal')<br/>model.summary()</span></pre><p id="104b" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated"><strong class="kz ir"> <em class="mk">输出:</em> </strong></p><pre class="ne nf ng nh gt nt nu nv nw aw nx bi"><span id="66ab" class="ny kg iq nu b gy nz oa l ob oc">Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>input_13 (InputLayer)        [(None, None, 3000, 1, 1) 0         <br/>_________________________________________________________________<br/>time_distributed_58 (TimeDis (None, None, 990, 1, 32)  1056      <br/>_________________________________________________________________<br/>time_distributed_59 (TimeDis (None, None, 990, 1, 32)  128       <br/>_________________________________________________________________<br/>time_distributed_60 (TimeDis (None, None, 480, 1, 32)  32800     <br/>_________________________________________________________________<br/>time_distributed_61 (TimeDis (None, None, 480, 1, 32)  128       <br/>_________________________________________________________________<br/>time_distributed_62 (TimeDis (None, None, 225, 1, 32)  32800     <br/>_________________________________________________________________<br/>time_distributed_63 (TimeDis (None, None, 225, 1, 32)  128       <br/>_________________________________________________________________<br/>time_distributed_64 (TimeDis (None, None, 97, 1, 32)   32800     <br/>_________________________________________________________________<br/>time_distributed_65 (TimeDis (None, None, 97, 1, 32)   128       <br/>_________________________________________________________________<br/>time_distributed_66 (TimeDis (None, None, 3104)        0         <br/>_________________________________________________________________<br/>gru_22 (GRU)                 (None, None, 256)         2582016   <br/>_________________________________________________________________<br/>dropout_20 (Dropout)         (None, None, 256)         0         <br/>_________________________________________________________________<br/>batch_normalization_48 (Batc (None, None, 256)         1024      <br/>_________________________________________________________________<br/>gru_23 (GRU)                 (None, None, 128)         148224    <br/>_________________________________________________________________<br/>dropout_21 (Dropout)         (None, None, 128)         0         <br/>_________________________________________________________________<br/>batch_normalization_49 (Batc (None, None, 128)         512       <br/>_________________________________________________________________<br/>output (TimeDistributed)     (None, None, 2)           258       <br/>=================================================================<br/>Total params: 2,832,002<br/>Trainable params: 2,830,978<br/>Non-trainable params: 1,024<br/>_________________________________________________________________</span></pre><p id="db80" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">正如我们所看到的，网络有280万个可训练参数，总的来说这是一个很小的数目。让我们形象地描述一下:</p><pre class="ne nf ng nh gt nt nu nv nw aw nx bi"><span id="75b5" class="ny kg iq nu b gy nz oa l ob oc">model._layers = [<br/>    layer for layer in model._layers if isinstance(layer, Layer)<br/>]<br/><br/>plot_model(model, 'model.png', show_shapes=True)</span></pre><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi od"><img src="../Images/f2fc229c62c387ad6c748f6a48c71adf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8FVvD3lBNtOatRSLghyVgw.png"/></div></div><p class="np nq gj gh gi nr ns bd b be z dk translated">模型形状[图片来自作者]</p></figure><p id="581e" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">从网络的形状中，我们注意到<strong class="kz ir"> TimeDistributed在默认的基础上增加了一个维度</strong>(即第二个问号)，它对应于每个信号的不同时期数。</p><p id="dcdf" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">此外，GRU(或<a class="ae mt" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir"> LSTM </strong> </a>)允许我们利用时间信息，这在信号中是必不可少的。</p><p id="6c7a" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">不幸的是，这个网络不能自我训练，特别是在我们的例子中，我们有各种由IDs标识的文件。然后，我们构建一个生成器来管理输入。</p><h1 id="0ca6" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">数据生成程序</h1><p id="c705" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">在我们的例子中，我们有一个文件列表，每个文件代表一个输入信号。因此，我们需要为Tensorflow构建一个生成器，在运行时接收信号并为网络做好准备。</p><p id="b528" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">现在让我们构建一个类，它将类型为<a class="ae mt" href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir">的对象序列</strong> </a>作为输入，并实现训练网络所需的所有方法(<em class="mk"> __init__，__len__，__getitem__，on_epoch_end </em>):</p><pre class="ne nf ng nh gt nt nu nv nw aw nx bi"><span id="90f2" class="ny kg iq nu b gy nz oa l ob oc">import numpy as np<br/>from keras.utils import Sequence<br/>from keras.preprocessing.sequence import pad_sequences<br/><br/><br/>class DataGenerator(Sequence):<br/>    <em class="mk">"""Generates data for Keras<br/>    Sequence based data generator. Suitable for building data generator for training and prediction.<br/>    """<br/><br/>    </em>def __init__(self, list_IDs, input_path, target_path,<br/>                 to_fit=True, batch_size=32, shuffle=True):<br/>        <em class="mk">"""Initialization<br/>        </em><strong class="nu ir"><em class="mk">:param</em></strong><em class="mk"> list_IDs: list of all 'label' ids to use in the generator<br/>        </em><strong class="nu ir"><em class="mk">:param</em></strong><em class="mk"> to_fit: True to return X and y, False to return X only<br/>        </em><strong class="nu ir"><em class="mk">:param</em></strong><em class="mk"> batch_size: batch size at each iteration<br/>        </em><strong class="nu ir"><em class="mk">:param</em></strong><em class="mk"> shuffle: True to shuffle label indexes after every epoch<br/>        """<br/>        </em>self.input_path = input_path<br/>        self.target_path = target_path<br/>        self.list_IDs = list_IDs<br/>        self.to_fit = to_fit<br/>        self.batch_size = batch_size<br/>        self.shuffle = shuffle<br/>        self.on_epoch_end()<br/><br/>    def __len__(self):<br/>        <em class="mk">"""Denotes the number of batches per epoch<br/>        </em><strong class="nu ir"><em class="mk">:return</em></strong><em class="mk">: number of batches per epoch<br/>        """<br/>        </em>return int(np.floor(len(self.list_IDs) / self.batch_size))<br/><br/>    def __getitem__(self, index):<br/>        <em class="mk">"""Generate one batch of data<br/>        </em><strong class="nu ir"><em class="mk">:param</em></strong><em class="mk"> index: index of the batch<br/>        </em><strong class="nu ir"><em class="mk">:return</em></strong><em class="mk">: X and y when fitting. X only when predicting<br/>        """<br/><br/>        </em># Generate indexes of the batch<br/>        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]<br/><br/>        # Find list of IDs<br/>        list_IDs_temp = [self.list_IDs[k] for k in indexes]<br/><br/>        # Generate data<br/>        X = self._generate_X(list_IDs_temp)<br/><br/>        if self.to_fit:<br/>            y = self._generate_y(list_IDs_temp)<br/>            return [X], y<br/>        else:<br/>            return [X]<br/><br/>    def on_epoch_end(self):<br/>        <em class="mk">"""<br/>        Updates indexes after each epoch<br/>        """<br/>        </em>self.indexes = np.arange(len(self.list_IDs))<br/>        if self.shuffle:<br/>            np.random.shuffle(self.indexes)<br/><br/>    def _generate_X(self, list_IDs_temp):<br/>        <em class="mk">"""Generates data containing batch_size images<br/>        </em><strong class="nu ir"><em class="mk">:param</em></strong><em class="mk"> list_IDs_temp: list of label ids to load<br/>        </em><strong class="nu ir"><em class="mk">:return</em></strong><em class="mk">: batch of images<br/>        """<br/>        </em># Initialization<br/>        X = []<br/><br/>        # Generate data<br/>        for i, ID in enumerate(list_IDs_temp):<br/>            # Store sample<br/>            temp = self._load_input(self.input_path, ID)<br/>            X.append(temp)<br/><br/>        X = pad_sequences(X, value=0, padding='post')<br/><br/>        return X<br/><br/>    def _generate_y(self, list_IDs_temp):<br/>        <em class="mk">"""Generates data containing batch_size masks<br/>        </em><strong class="nu ir"><em class="mk">:param</em></strong><em class="mk"> list_IDs_temp: list of label ids to load<br/>        </em><strong class="nu ir"><em class="mk">:return</em></strong><em class="mk">: batch if masks<br/>        """<br/>        </em>y = []<br/><br/>        # Generate data<br/>        for i, ID in enumerate(list_IDs_temp):<br/>            # Store sample<br/>            y.append(self._load_target(self.target_path, ID))<br/><br/>        y = pad_sequences(y, value=0, padding='post')<br/><br/>        return y</span></pre><p id="4934" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">一旦生成器类被编写，让我们提取文件的id列表，将它们分成<strong class="kz ir">训练</strong>、<strong class="kz ir">验证</strong>和<strong class="kz ir">测试</strong>。注意，我们构建了两个生成器，一个用于训练，一个用于验证:</p><pre class="ne nf ng nh gt nt nu nv nw aw nx bi"><span id="a09f" class="ny kg iq nu b gy nz oa l ob oc">import numpy as np<br/>import re<br/>from os import listdir<br/>from os.path import isfile, join</span><span id="c808" class="ny kg iq nu b gy oe oa l ob oc">TEST_SIZE = 128<br/>onlyfiles = [f for f in listdir(input_path) if isfile(join(input_path, f))]<br/><br/>id = [re.search('(.+?).npz', x).group(1) for x in onlyfiles]<br/>id.sort()<br/><br/>np.random.seed(1234)<br/>id_test = np.random.choice(id, size=TEST_SIZE,replace=False)<br/>id = list(set(id) - set(id_test))<br/>id_validation = np.random.choice(id, size=TEST_SIZE,replace=False)<br/>id = list(set(id) - set(id_validation))<br/><br/>print(len(id))<br/><br/>training_generator = DataGenerator(id,  input_path = input_path,<br/>                                   target_path=target_path)<br/><br/>validation_generator = DataGenerator(id_validation, input_path = input_path,<br/>                                   target_path=target_path)</span></pre><p id="a452" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">我们现在终于可以进行模型训练了，祈祷好运吧😆。</p><pre class="ne nf ng nh gt nt nu nv nw aw nx bi"><span id="e693" class="ny kg iq nu b gy nz oa l ob oc">model.fit(training_generator,<br/>                    validation_data=validation_generator,<br/>                    epochs=8,<br/>                    use_multiprocessing=True)</span></pre><p id="866e" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">对于本文，我们已经完成了，我在参考资料中为您留下了包含代码的repo的链接。</p><p id="8077" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">一会儿见，</p><p id="e2ee" class="pw-post-body-paragraph lu lv iq kz b la ml jr lw lc mm ju lx le mo lz ma lg mq mc md li ms mf mg lk ij bi translated">弗朗西斯科</p></div><div class="ab cl of og hu oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="ij ik il im in"><h1 id="b085" class="kf kg iq bd kh ki om kk kl km on ko kp jw oo jx kr jz op ka kt kc oq kd kv kw bi translated">参考</h1><ol class=""><li id="35a8" class="kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo bi translated"><a class="ae mt" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/TimeDistributed" rel="noopener ugc nofollow" target="_blank">时间分布式张量流包装器</a></li><li id="92e8" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">带有代码的Github <a class="ae mt" href="https://github.com/dallanoce/timedistributed" rel="noopener ugc nofollow" target="_blank">库</a></li></ol></div></div>    
</body>
</html>