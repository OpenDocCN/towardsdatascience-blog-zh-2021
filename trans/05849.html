<html>
<head>
<title>Your Cross Validation Error Confidence Intervals are Wrong — here’s how to Fix Them</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你的交叉验证误差置信区间是错误的——以下是如何修正它们的方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/your-cross-validation-error-confidence-intervals-are-wrong-heres-how-to-fix-them-abbfe28d390?source=collection_archive---------20-----------------------#2021-05-25">https://towardsdatascience.com/your-cross-validation-error-confidence-intervals-are-wrong-heres-how-to-fix-them-abbfe28d390?source=collection_archive---------20-----------------------#2021-05-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="411b" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><div class=""><h2 id="2022" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">一种利用嵌套交叉验证来消除交叉验证过程中偏差的新算法。</h2></div><p id="645d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lk" href="https://arxiv.org/abs/2104.00673" rel="noopener ugc nofollow" target="_blank"> Stanford (2021) </a>的研究人员开发了一种方法，该方法使用嵌套交叉验证(NCV)来说明数据分割之间的相关性，从而允许我们计算误差周围的准确置信区间。尽管NCV有潜力，但它需要比计算量大的常规交叉验证更多的拟合迭代。但是，如果您能够访问多个计算节点/内核，这些迭代可以轻松实现并行化。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/e1d0c6bd1880cac1eefd0d4988f28f36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1XmPC6gPccF1Nu_uVWbbZA.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">NCV概述:内部CV循环是常规交叉验证。维持集是一个测试集，用于估计我们的模型的偏差— <a class="ae lk" href="http://statweb.stanford.edu/~tibs/ftp/NCV.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>(图8)</p></figure><h1 id="0f4b" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">1.技术TLDR</h1><p id="7450" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">论文中概述的方法首先创建了一个可以估计偏倚的有偏倚的嵌套交叉验证算法。然后，我们使用NCV中的偏差和误差项来调整我们的常规CV模型。最终产品是有效的MSE和置信区间，它控制数据折叠的相关性。</p><h2 id="cbc5" class="my mc iq bd md mz na dn mh nb nc dp ml kx nd ne mn lb nf ng mp lf nh ni mr iw bi translated">算法步骤的高级概述</h2><p id="6051" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated"><strong class="kq ja"> 1.1)使用嵌套交叉验证(NCV)创建一个过度偏倚的模型。</strong>我们首先对<em class="nj"> K-1 </em>折叠执行交叉验证，保持第<em class="nj"> K </em>个维持组不变。一旦我们有了每个<em class="nj"> K-1 </em>折叠的损失向量，我们就在维持组上运行训练/测试分割，其中训练和测试集分别是第<em class="nj"> K-1 </em>和第<em class="nj"> K </em>折叠。对每个折叠重复这一过程，创建下面的矩阵，其中每一列代表一次迭代:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nk"><img src="../Images/fbcfc98c39ee8c703ee115117c83b544.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CNt796yKN8hamGuUoD_ZwQ.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">NCV算法的损失矩阵。每个单元格对应一个损失向量，而不是一个数字。</p></figure><p id="9215" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">请注意，我们的“维持损失”是无偏的，因为测试数据(维持集)从未被训练数据(所有<em class="nj"> K-1 </em>其他折叠)看到。还要注意的是，我们的每个“fold_ <em class="nj"> n </em> _loss”向量都是有偏差的，因为我们根据之前看到的数据重新调整了模型。</p><p id="4a98" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">计算矩阵中每一列的MSE。请注意，给定列的MSE定义为我们的“fold_ <em class="nj"> n </em> _loss”向量的平均值减去“holdout_loss”向量的平均值。有关计算步骤，请参见下面的python代码。</p><pre class="lm ln lo lp gt nl nm nn no aw np bi"><span id="1421" class="my mc iq nm b gy nq nr l ns nt">MSE = []<br/>for i in range(K): # iterate through folds<br/>  folds_idxs = [j for j in range(K) if i != j]</span><span id="343f" class="my mc iq nm b gy nu nr l ns nt">  avg_fold_n_loss = mean(K_minus_1_folds_losses[folds_idxs, i])<br/>  avg_holdout_loss = mean(holdout_loss[i, i])</span><span id="643e" class="my mc iq nm b gy nu nr l ns nt">  error_sq = (avg_fold_n_loss - avg_holdout_loss)**2<br/>  MSE.append(error_sq - var(holdout_loss))</span></pre><p id="634a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> 1.3)使用常规K折CV训练另一个模型。由于我们只对误差项感兴趣，我们只存储每个折叠的样本外损失。</strong></p><pre class="lm ln lo lp gt nl nm nn no aw np bi"><span id="3123" class="my mc iq nm b gy nq nr l ns nt">cv_errors = mean(K_fold_CV_loss)</span></pre><p id="ddef" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> 1.4)计算偏差。</strong></p><pre class="lm ln lo lp gt nl nm nn no aw np bi"><span id="d64d" class="my mc iq nm b gy nq nr l ns nt">weight = (1 + ((n_folds — 2) / (n_folds))^(1.5))<br/>bias = (MSE — cv_errors) * weight</span></pre><p id="93f2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> 1.5)计算这个去偏误差周围的置信区间。</strong>最终置信区间的形式为…</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nv"><img src="../Images/b1f96764c5a6c65adbd0a85c3c8b1be7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0nXUpJ8O7Nfrab_rkYnzjw.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">考虑数据折叠之间相关性的调整置信区间公式— <a class="ae lk" href="http://statweb.stanford.edu/~tibs/ftp/NCV.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>(等式17)</p></figure><ul class=""><li id="a4fa" class="nw nx iq kq b kr ks ku kv kx ny lb nz lf oa lj ob oc od oe bi translated"><em class="nj"> Err (NCV) </em>是嵌套交叉验证模型误差，</li><li id="c88a" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ob oc od oe bi translated"><em class="nj"> Bias_hat </em>以上估算，</li><li id="f015" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ob oc od oe bi translated"><em class="nj"> q 1-α/2 </em>是我们置信度的z值，</li><li id="a946" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ob oc od oe bi translated"><em class="nj"> K </em>是折叠的次数，并且</li><li id="17ec" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ob oc od oe bi translated"><em class="nj"> MSE_hat </em>是步骤2中估计的MSE。</li></ul><h1 id="f5bf" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated"><strong class="ak"> 2。但是，到底是怎么回事呢？</strong></h1><p id="04a7" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">让我们回溯并充分理解为什么我们数据中折叠之间的相关性会导致不正确的小置信区间。</p><p id="c9e2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在拟合预测模型时，我们的目标是可推广性，即我们希望我们的模型在新数据上表现良好。通过在我们的训练/测试分割中回收数据，我们实际上从未给我们的模型<em class="nj">新的</em>数据。那么，如何才能知道模型会泛化呢？</p><p id="7eb6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">考虑一次50%的训练/测试分割。这种分割是有效的，因为模型没有根据我们的测试数据进行训练，因此这些数据是全新的。然而，一旦我们采用2重CV，用测试数据重新改装，一大块数据就被回收了。而且，因为模型之前看过数据，所以它认为我们的样本很能代表总体。</p><p id="afd0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">随着我们的模型的“信心”的增加，它减少了我们的置信区间的大小。</p><h2 id="60df" class="my mc iq bd md mz na dn mh nb nc dp ml kx nd ne mn lb nf ng mp lf nh ni mr iw bi translated">2.1数学视角</h2><p id="db7f" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">既然我们希望对为什么我们的误差置信区间可能有偏差有一些直觉，让我们从数学的角度来看一下。</p><p id="66dc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">方差代表数据中的自然变化，是任何置信区间的关键组成部分。当估计总体方差时，即不考虑样本中具体数据的真实方差时，我们经常使用样本方差。然而，由于我们的数据折叠中存在相互依赖性，我们必须在每个数据折叠内部和之间纳入协方差。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/1ba0508592f831569ad93f637919d515.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*U4NcyIuUhMxaPQP6NkeKww.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">我们数据折叠的协方差矩阵。— <a class="ae lk" href="http://statweb.stanford.edu/~tibs/ftp/NCV.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>(图7)</p></figure><p id="e302" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">使用上面的图，我们可以看到交叉验证数据集的方差有3个组成部分。</p><ol class=""><li id="6307" class="nw nx iq kq b kr ks ku kv kx ny lb nz lf oa lj ol oc od oe bi translated">红色方块是褶皱内的<strong class="kq ja">协方差</strong>，</li><li id="cd5e" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ol oc od oe bi translated">蓝色方块是褶皱之间的<strong class="kq ja">协方差</strong>，以及</li><li id="1ba1" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ol oc od oe bi translated">黑色方块是我们误差的方差。</li></ol><p id="3634" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们将这一概念转化为上述3个部分的数学函数:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi om"><img src="../Images/f9a5be64096471be8a4497d45b0cf0d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*_lhVKX6nU5GXIwklEollyQ.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">交叉验证模型的误差方差— <a class="ae lk" href="http://statweb.stanford.edu/~tibs/ftp/NCV.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>(等式13)</p></figure><ul class=""><li id="87f3" class="nw nx iq kq b kr ks ku kv kx ny lb nz lf oa lj ob oc od oe bi translated"><em class="nj"> n </em>是样本量，</li><li id="1a17" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ob oc od oe bi translated"><em class="nj"> K </em>是数据折叠的次数，</li><li id="2348" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ob oc od oe bi translated"><em class="nj"> a1 </em>是我们误差的<strong class="kq ja">方差</strong>，<em class="nj"> var(e) </em>，</li><li id="b562" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ob oc od oe bi translated"><em class="nj"> a2 </em>为同一次、<em class="nj"> cov(ei，ej) </em>误差的<strong class="kq ja">协方差，且</strong></li><li id="3af2" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ob oc od oe bi translated"><em class="nj"> a3 </em>为<strong class="kq ja">不同道次</strong>的误差协方差，(<em class="nj"> cov(ei，ej) </em>)。</li></ul><p id="6c52" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">注意<em class="nj"> i </em>和<em class="nj"> j </em>是上图中一个正方形对应的指数。</p><p id="3c0d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">关键在于，大多数交叉验证方法假设<em class="nj"> a2 </em>和<em class="nj"> a3 </em>为0，即我们的折叠内或折叠间的误差不存在相互依赖性。然而，<em class="nj"> a2 </em>和<em class="nj"> a3 </em>通常是&gt; 0，因为我们重用数据。</p><p id="b979" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">那么，你能看到当我们不假设独立性时，误差的方差是如何变大的吗？</p><h1 id="27fd" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">3.解决方案</h1><p id="f22d" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">嵌套交叉验证(NVC)已经存在很多年了，但是在计算模型误差的置信区间时，独立性经常被错误地假设。那么如何计算我们褶皱的相互依存性并去除它呢？</p><p id="7a98" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">有3个“简单”的步骤…</p><h2 id="b553" class="my mc iq bd md mz na dn mh nb nc dp ml kx nd ne mn lb nf ng mp lf nh ni mr iw bi translated">3.1计算偏差</h2><p id="914b" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">让我们来看看下面这个定义偏差的等式。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi on"><img src="../Images/e343ae2215a803cf64e59c7c04c18220.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*gW30B9_EnY3LAib6hD4yfg.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">估计偏差的公式— <a class="ae lk" href="http://statweb.stanford.edu/~tibs/ftp/NCV.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>(等式16)</p></figure><ul class=""><li id="75de" class="nw nx iq kq b kr ks ku kv kx ny lb nz lf oa lj ob oc od oe bi translated"><em class="nj"> K </em>是折叠的次数，</li><li id="3713" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ob oc od oe bi translated"><em class="nj"> Err(NCV) </em>是我们过度偏向的NCV模型中的估计误差，以及</li><li id="55ea" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ob oc od oe bi translated"><em class="nj"> Err (CV) </em>是我们常规CV模型中的估计误差。</li></ul><p id="ee5f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">换句话说，偏差是我们的额外偏差模型<em class="nj">Err(NCV)</em>和常规偏差模型<em class="nj"> Err (CV) </em>之间的加权差。</p><p id="e27d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在我们已经对我们的偏差有了一个估计，我们打算如何解释它呢？</p><h2 id="5000" class="my mc iq bd md mz na dn mh nb nc dp ml kx nd ne mn lb nf ng mp lf nh ni mr iw bi translated">3.2计算MSE</h2><p id="f220" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">我们调整两个量。第一个是我们的均方误差(MSE ),第二个是误差的置信区间。</p><p id="a2b4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在下面的等式中，我们定义了偏差调整的MSE的估计值…</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi oo"><img src="../Images/81d50f4218bf63872aa07b885754ad6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2XkKVnEPasNlQ_rJsOApug.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">MSE的概念定义—改编自<a class="ae lk" href="http://statweb.stanford.edu/~tibs/ftp/NCV.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>(引理4)</p></figure><p id="66ee" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在不深入统计数据的情况下，让我们定义我们的术语…</p><ul class=""><li id="cc62" class="nw nx iq kq b kr ks ku kv kx ny lb nz lf oa lj ob oc od oe bi translated"><em class="nj"> Err XY，s </em>(可以估计)<em class="nj"> </em>是给定训练集X和Y的观测<strong class="kq ja">样本误差</strong>，</li><li id="652f" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ob oc od oe bi translated"><em class="nj"> Err XY，p </em>(无法估计)是我们模型的<strong class="kq ja">理论误差</strong>其中X和Y不能自由变化，而</li><li id="301e" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ob oc od oe bi translated"><em class="nj"> ebar (out) </em>(可以估计)是通过我们的维持集计算的无偏误差的<strong class="kq ja">平均值。</strong></li></ul><p id="8e55" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这种偏差/方差分解的美妙之处在于，它允许我们绕过让我们的<em class="nj"> Err XY，p </em>项的要求。相反，我们可以简单地计算误差的方差来代替最右边的项。</p><p id="0402" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果你想知道为什么要包含<em class="nj"> Err XY，p </em>项，这是证明有效的必要条件。它不是一个可以计算的“真实”术语——它是一个统计概念，代表了我们当前模型的概括程度。</p><p id="f468" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在我们已经有了MSE，让我们进入最后一步。</p><h2 id="2440" class="my mc iq bd md mz na dn mh nb nc dp ml kx nd ne mn lb nf ng mp lf nh ni mr iw bi translated">3.3计算模型误差的置信区间</h2><p id="0fe2" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">为了进行这种计算，让我们重温一下技术TLDR第1.5节中的公式。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nv"><img src="../Images/b1f96764c5a6c65adbd0a85c3c8b1be7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0nXUpJ8O7Nfrab_rkYnzjw.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">考虑数据折叠之间相关性的调整置信区间公式— <a class="ae lk" href="http://statweb.stanford.edu/~tibs/ftp/NCV.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>(等式17)</p></figure><p id="2030" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们可以通过查找带帽子的所有内容(^)来确定需要估计的项，这里，帽子表示在前面的步骤中估计的值。第一个是<em class="nj"> Err(NCV) </em>，我们的嵌套交叉验证错误。我们还需要计算这个。第二个是我们的<em class="nj">偏差</em>估计，在第3.1节中计算。最后，第三个是我们的<em class="nj"> MSE </em>，在3.2节中计算。</p><p id="20e4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">不幸的是，<em class="nj"> Err(NCV) </em>由于NCV算法的复杂性，很难用数学方法来表示。然而，从概念的角度来看，这是我们的交叉验证错误的无效部分，即由我们的数据折叠中的相关性产生的部分。</p><p id="1ca4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在运行NCV算法得到<em class="nj"> Err(NCV) </em>之后，我们可以插入我们的值并观察我们改进的置信区间。这些CI应展示更好的覆盖面，并具有强大的统计基础，能够说明我们数据的依赖性。</p><h2 id="a796" class="my mc iq bd md mz na dn mh nb nc dp ml kx nd ne mn lb nf ng mp lf nh ni mr iw bi translated">3.4伪代码解决方案</h2><p id="71fe" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">由于我们没有使用数学符号完全涵盖NCV算法，这里有一些从作者写的<a class="ae lk" href="https://github.com/stephenbates19/nestedcv/blob/master/R/core.R" rel="noopener ugc nofollow" target="_blank"> R包</a>改编的pythonic伪代码。注意，在某些情况下，为了计算效率，代码偏离了理论。还要注意，这段代码还没有运行——如果您看到错误，请留下评论，我会进行调整。</p><figure class="lm ln lo lp gt lq"><div class="bz fp l di"><div class="op oq l"/></div></figure><h1 id="ee0b" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">4.实施说明</h1><ul class=""><li id="9fb5" class="nw nx iq kq b kr mt ku mu kx or lb os lf ot lj ob oc od oe bi translated">NCV在计算上非常昂贵，但是迭代很容易并行化。作者推荐50次迭代作为默认值，这将导致10倍CV的交叉验证拟合超过500次。</li><li id="6b5c" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ob oc od oe bi translated">这里我们关注MSE作为我们的损失函数，然而NCV框架理论上可以推广到任何损失函数。也就是说，还不清楚该算法如何处理非平方损失，即负数。</li><li id="9850" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ob oc od oe bi translated">虽然这篇文章的重点是交叉验证部分，但原始论文也讨论了样本之间的相关性概念如何影响Mallow的<em class="nj"> Cp </em>和bootstrap采样<em class="nj">等方法。</em></li><li id="c1b0" class="nw nx iq kq b kr of ku og kx oh lb oi lf oj lj ob oc od oe bi translated">最后，这篇论文于2021年3月发表。可能会有未来的发展，改进的文档，和一个python包。如果你知道资源，请在评论中留下它们或者<a class="ae lk" href="https://michaeldberk.com/contact" rel="noopener ugc nofollow" target="_blank">给我</a>发消息，我会添加它们。</li></ul></div><div class="ab cl ou ov hu ow" role="separator"><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz"/></div><div class="ij ik il im in"><p id="26db" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">查看我的评论，获得论文链接、R包和一些潜在的后续步骤。</p></div></div>    
</body>
</html>