<html>
<head>
<title>How to Handle Uncertainty in Forecasts</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何处理预测中的不确定性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-handle-uncertainty-in-forecasts-86817f21bb54?source=collection_archive---------14-----------------------#2021-09-08">https://towardsdatascience.com/how-to-handle-uncertainty-in-forecasts-86817f21bb54?source=collection_archive---------14-----------------------#2021-09-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="a7ee" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="a17c" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">对保形预测的深入研究。</h2></div><p id="62de" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">每当我们做预测时，我们的估计都有不确定性。例如，让我们考虑一个柠檬水摊位，该摊位希望预测需求。如果预测非常准确，就可以采取行动，他们可以优化他们的柠檬购买策略。另一方面，如果预测有很大范围的可能值，那就没用了。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lk"><img src="../Images/89a6bb1253025348d93797f63a57f683.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PmaHZ-9OfEqLB0svBOENGg.png"/></div></div><p class="lw lx gj gh gi ly lz bd b be z dk translated">图1:不同水平的预测区间覆盖的例子— <a class="ae ma" href="https://arxiv.org/pdf/2107.07511.pdf" rel="noopener ugc nofollow" target="_blank"> src </a>。顶行显示分类，底行显示回归预测任务。“有条件的”覆盖是最稳健的。图片作者。</p></figure><p id="dc7c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在<a class="ae ma" href="https://www.stat.cmu.edu/~ryantibs/papers/conformal.pdf" rel="noopener ugc nofollow" target="_blank">2017年的一篇论文</a>中，卡耐基梅隆大学的研究人员解决了这个问题。他们证明了在最小假设的情况下，保形预测保证了正确的覆盖率。这个证据适用于小规模的数据集。不确定性很重要的主题，如自动驾驶汽车的物体检测，确实可以从这种方法中受益。然而，尽管保形预测已被证明是有效的，但它仍是一种相当不成熟的方法，还没有被DS工业广泛采用。</p><p id="f992" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下面，我们将概述它是如何工作的，并提供一些实现说明...</p><h1 id="c74c" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">技术TLDR</h1><p id="51da" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">保形预测保证了仅使用可交换性假设的预测的α水平覆盖，不需要IID数据。这是通过使用样本外<em class="my">校准集</em>创建共形分数分布来实现的。请注意，这些保形分数本质上是基于条件概率的残差，见图2。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/fe14daad1d63fdd80c230b4f4825c285.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*MkJcl7dlqL3bTu1vWPLvMg.png"/></div><p class="lw lx gj gh gi ly lz bd b be z dk translated">图2:共形分数的公式。图片作者。</p></figure><p id="5e54" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">从有序共形分数的分布中，我们找到什么分位数对应于我们的置信水平(<em class="my"> α </em>)。然后，我们使用该分位数来确定保证<em class="my"> 1-α </em>覆盖的预测区间，而不考虑IID数据或正确的模型。</p><h1 id="9666" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">但是，保形预测实际上是如何工作的呢？</h1><p id="2166" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">好吧，那是很多。让我们慢下来，真正明白发生了什么。</p><h2 id="d615" class="na mc iq bd md nb nc dn mh nd ne dp ml kx nf ng mn lb nh ni mp lf nj nk mr iw bi translated">预测区间的背景</h2><p id="2a52" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">首先，我们来讨论一下预测区间及其问题。</p><p id="7407" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">简而言之，<a class="ae ma" href="https://www.statisticshowto.com/prediction-interval/" rel="noopener ugc nofollow" target="_blank">预测区间</a>是预测值的置信区间，即我们预计未来预测的大部分将落在该范围内。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nl"><img src="../Images/4dc085e41ac24c6b5f1899c5bbd25283.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pG0Eal5sc1yKJ1MXwVnVZA.png"/></div></div><p class="lw lx gj gh gi ly lz bd b be z dk translated">图3:假数据95%预测区间的例子— <a class="ae ma" href="https://statisticsglobe.com/draw-plot-with-confidence-intervals-in-r" rel="noopener ugc nofollow" target="_blank"> src </a>。图片作者。</p></figure><p id="4988" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在图3中，我们可以看到一些假数据的预测区间的例子。每个数据点上方和下方的水平线对应于95%的预测区间范围— <strong class="kq ja">我们未来预测的95%将落在该范围内。</strong></p><p id="9ed1" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">不幸的是，预测间隔通常需要几个假设。一些例子包括独立同分布(IID)数据以及正确指定的模型。如果您真的关心准确的预测区间覆盖率，这些假设可能会有问题。</p><p id="28fc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">那么保形预测带来了什么呢？</p><h2 id="06b3" class="na mc iq bd md nb nc dn mh nd ne dp ml kx nf ng mn lb nh ni mp lf nj nk mr iw bi translated">保形预测缺乏假设</h2><p id="9aa8" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">保形预测只需要一个叫做<a class="ae ma" href="https://stats.stackexchange.com/questions/3520/can-someone-explain-the-concept-of-exchangeability" rel="noopener ugc nofollow" target="_blank">互换性</a>的假设。<strong class="kq ja">可交换性是指数据的任何排序都同样可能发生。</strong></p><p id="33de" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于熟悉IID假设的人来说，这是“ID”部分——可交换数据相对于预测值是同分布的。</p><p id="bca6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">由于只需要一个假设，保形预测可以说是开发预测区间的最具统计稳健性的方法。</strong></p><h1 id="eb51" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">该方法是如何工作的？</h1><p id="ef96" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">让我们从一个二元分类的例子开始。从这里开始，我们将把概念扩展到多类分类以及预测连续变量。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nm"><img src="../Images/57d9914db311ebea64dd43f51307025b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FDYQT7Z3kZgXI55mIYu9yA.png"/></div></div><p class="lw lx gj gh gi ly lz bd b be z dk translated">图4:我们的二元分类目标是确定一幅图像显示的是一头牛还是一头骆驼。图片作者。</p></figure><p id="0f08" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如图4所示，我们希望确定一幅图像显示的是骆驼还是奶牛。如果我们认为图像显示的是一头牛，我们将预测y=1，如果我们认为图像显示的是一头骆驼，我们将预测y=0。</p><h2 id="aa46" class="na mc iq bd md nb nc dn mh nd ne dp ml kx nf ng mn lb nh ni mp lf nj nk mr iw bi translated">步骤1-创建一个共形分数分布</h2><p id="5f99" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">在我们的第一步中，我们开发了训练/测试分割，并使用训练数据拟合分类模型。假设我们使用逻辑回归。拟合模型后，我们使用测试集(称为<em class="my">校准集</em>)开发因变量(奶牛对骆驼)的概率预测。</p><p id="b591" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">在这一阶段，我们有了校准集中每个观察值的预测概率向量。</strong></p><p id="b24f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">从那里，我们使用每个预测的概率计算共形分数。图5中定义了保形分数的公式。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nn"><img src="../Images/0204198b887b4a880174ad34ce022782.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NPebYHUr5pI-p4FXK327WA.png"/></div></div><p class="lw lx gj gh gi ly lz bd b be z dk translated">图5:包含每个变量定义的共形分数公式。图片作者。</p></figure><p id="b4c9" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">共形分数可以认为是非共形分数。</strong>它们取值在-1和1之间，越接近任一极端，就越偏离观察到的标签。请注意，我们经常使用绝对值，因为我们只关心不符合的程度，而不是方向。</p><p id="05f0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">在获得我们校准集中所有标签的共形分数后，我们将共形分数的绝对值从低到高排序。</strong></p><h2 id="e8c3" class="na mc iq bd md nb nc dn mh nd ne dp ml kx nf ng mn lb nh ni mp lf nj nk mr iw bi translated">步骤2-创建预测间隔</h2><p id="7f16" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">有了保形分数的分布，我们可以将这个概念与预测区间联系起来。</p><p id="8ed4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如前所述，预测间隔要求工程师指定一个假阳性率(<em class="my"> α </em>)，通常为0.05或0.01。为了找到我们的预测区间的上限和下限，我们找到对应于<em class="my"> α的分布中的分位数。</em></p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi no"><img src="../Images/726feba558be025b6a5e96feef18b4bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xhMp1BLRRrikQV_Y2lW3Ag.png"/></div></div><p class="lw lx gj gh gi ly lz bd b be z dk translated">图6:通过预测二元类的概率找到的分级共形分数的示例分布。图片作者。</p></figure><p id="26d7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在图6中，<em class="my"> α- </em>水平分位数由标有绿色“临界阈值”的垂直线表示。x轴对应于一组有序的共形分数。假设他们有500人。蓝色和红色的交叉点，即“临界阈值”，是百分位数<em class="my"> 1-α </em>。因此，如果<em class="my"> α </em>为0.1，那么统计显著性的截止值将是第90百分位的一致性分数，例如第450一致性分数。</p><p id="ff53" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">蓝色的适形分数没有统计学意义。它们在我们的预测区间内。非常大的共形分数(红色)表示与真实标签的高度偏离。这些适形评分具有统计学意义，因此超出了我们的预测区间。</strong></p><p id="c4d1" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">还要注意，我们推导出每个标签的分位数截止值。</p><h2 id="a082" class="na mc iq bd md nb nc dn mh nd ne dp ml kx nf ng mn lb nh ni mp lf nj nk mr iw bi translated">步骤3-估计每个标签的概率</h2><p id="27ea" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">从这里开始，对于每一次观察，我们确定成为牛、骆驼、两者或都不是的概率。这是怎么做到的？</p><p id="61b0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">嗯，对于每个观察，我们计算每个标签的共形分数，例如骆驼和母牛。从那里，我们确定每个适形分数是否超过其相应的临界阈值。<strong class="kq ja">如果超过阈值，我们认为它在统计上是显著的，因此是错误的。如果不是，我们认为这是真的。</strong></p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi np"><img src="../Images/2ac256ca33e2268cf5316ba8828a89c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sGyrptF4r4NGjCay77msbw.png"/></div></div><p class="lw lx gj gh gi ly lz bd b be z dk translated">图7:分类矩阵。蓝色和红色的值分别对应于非stat-sig和stat-sig预测。作者图片</p></figure><p id="3679" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们的二元分类问题有四种可能的结果，如图7所示。红色表示预测在统计上有意义，蓝色表示没有意义。这里，<strong class="kq ja">统计显著性意味着预测是假的，缺乏统计显著性意味着预测是真的。</strong></p><p id="67c3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们依次看看每个单元格…</p><ul class=""><li id="1e06" class="nq nr iq kq b kr ks ku kv kx ns lb nt lf nu lj nv nw nx ny bi translated"><strong class="kq ja">左上角</strong>:两个标签都<em class="my">不</em>具有统计显著性的预测。在这里，模型预言<strong class="kq ja">这两个阶级都是真正的阶级。</strong></li><li id="c838" class="nq nr iq kq b kr nz ku oa kx ob lb oc lf od lj nv nw nx ny bi translated"><strong class="kq ja">右下</strong>:两个标签都具有统计显著性的预测。在这里，模型预测<strong class="kq ja">这两个类都不是真正的类。</strong></li><li id="c453" class="nq nr iq kq b kr nz ku oa kx ob lb oc lf od lj nv nw nx ny bi translated"><strong class="kq ja">右上</strong>:所有camel标签(0)都<em class="my">不</em>具有统计显著性的预测。在这里，模型预测<strong class="kq ja"> camel才是真正的类。</strong></li><li id="7a35" class="nq nr iq kq b kr nz ku oa kx ob lb oc lf od lj nv nw nx ny bi translated"><strong class="kq ja">左下</strong>:所有奶牛标签(1)都<em class="my">不</em>具有统计显著性的预测。在这里，模型预测<strong class="kq ja">牛才是真正的类。</strong></li></ul><p id="c13c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这一步可能有点违反直觉。一个模型怎么能预测一个以上的类甚至根本没有类呢？</p><p id="b8a1" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们采取一种直观的方法。简单的二进制分类模型找出哪个类的概率最高，并将其确定为预测。但是有了保形预测，我们可以让模型说两者都不是或者都不是真正的标签。实际上，模型可以说“我不知道”</p><p id="78ea" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因为我们不强迫模型做出预测，所以我们在预测集中得到了更可靠的预测。</p><p id="ecda" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">并且，<strong class="kq ja">我们的<em class="my"> 1-α </em>预测集只有一个预测，即右上角和左下角的单元格。</strong></p><h1 id="c8ed" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">扩展到更复杂的标签</h1><p id="da9b" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">既然我们已经理解了保形预测对于二元分类是如何工作的，那么这个概念就可以很容易地扩展到多级分类。在第3步中，我们发现被标记为<em class="my"> 1，0，两者皆是，</em>或<em class="my">都不是</em>的概率，我们只是对三个级别而不是两个级别进行相同的操作。</p><p id="f6ce" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">从概念上讲，这是一个简单的下一步，但计算上的复杂性呈指数增长，因此对具有许多级别的标签进行保形预测并不总是一个好主意。</p><p id="7737" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于连续变量，有几种方法，但最简单的是预测分位数而不是平均值。如前所述，我们可以将共形分数视为残差:真实的<em class="my"> y </em>减去预测的<em class="my"> y </em>。然而，与分类变量不同，我们没有固定数量的标签可供尝试。</p><p id="0b0f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因此，对于连续标签，我们尝试预测有限数量的不同分位数，并查看它们在哪里变得具有统计显著性。对于处于统计显著性边缘的值，我们认为它们是<em class="my"> α- </em>水平预测区间。请注意，<a class="ae ma" href="https://www.evergreeninnovations.co/blog-quantile-loss-function-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">分位数损失</a>可以添加到几乎任何建模损失函数中，这就是为什么它被称为“最简单的”</p><p id="7202" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果你想了解更多，这里有<a class="ae ma" href="https://arxiv.org/pdf/2107.07511.pdf" rel="noopener ugc nofollow" target="_blank">一个非常好的资源</a>，可以在连续变量上使用保形预测。</p><p id="74a4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在你知道了！全盛时期的共形预测。</p><h1 id="c0ec" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">摘要和实施说明</h1><p id="659c" class="pw-post-body-paragraph ko kp iq kq b kr mt ka kt ku mu kd kw kx mv kz la lb mw ld le lf mx lh li lj ij bi translated">为了深入理解这些概念，让我们总结一下。</p><p id="03a6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">保形预测是开发预测区间的最少假设的方法。因此，这是最普遍的防御方法。它还适用于小样本数据集，可以产生更精确的预测区间/集合。</p><p id="2dcc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">该方法利用共形分数的分布来开发标记的任何组合为真的概率的排列。如果预测的概率足够低，即保形分数足够大，我们认为它在我们的预测区间之外。然后，这些排列用于开发连续变量的预测区间或分类变量的预测集。</p><p id="7f64" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这种方法仍然没有得到太多的关注，但它对预测建模有着巨大的潜力。</p></div><div class="ab cl oe of hu og" role="separator"><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj"/></div><div class="ij ik il im in"><p id="c12a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="my">感谢阅读！我会再写36篇文章，把学术研究带到DS行业。查看我的评论，链接到这篇文章的主要来源和一些有用的资源。</em></p></div></div>    
</body>
</html>