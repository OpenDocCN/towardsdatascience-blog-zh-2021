<html>
<head>
<title>Speech Recognition in Real-Time using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python实现实时语音识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/speech-recognition-in-real-time-using-python-fbbd62e6ff9d?source=collection_archive---------4-----------------------#2021-12-13">https://towardsdatascience.com/speech-recognition-in-real-time-using-python-fbbd62e6ff9d?source=collection_archive---------4-----------------------#2021-12-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bda7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">现场转录分步指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0d4508a1269a166abe879dbab1b2ad82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZQjUF9tKIzfGjRpphdyJGQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@sincerelymedia?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">真诚媒体</a>在<a class="ae ky" href="https://unsplash.com/s/photos/microphone?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="3fed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我将向你展示如何使用Python将你的演讲实时转换成文本。我们将编写一个程序，理解我们所说的话，并将其翻译成书面文字。这种翻译被称为语音识别。对于机器学习和人工智能来说，语音识别是一个非常令人兴奋和有趣的领域。</p><p id="1514" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我之前的帖子中，我已经讨论过类似的主题，比如<a class="ae ky" rel="noopener" target="_blank" href="/building-a-speech-recognizer-in-python-2dad733949b4">使用谷歌的语音识别API </a>将语音转换为文本，以及<a class="ae ky" rel="noopener" target="_blank" href="/building-a-speech-emotion-recognizer-using-python-4c1c7c89d713">使用Python </a>构建语音情感识别器。在这些项目中，识别和训练是通过静态音频文件完成的。今天，我们将在这个项目中做一些更先进、更非凡的事情。我们将学习如何实时地将我们的语音转换成文本。</p><p id="0607" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你准备好了，让我们开始工作吧！</p><h2 id="87b6" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">目录</h2><ul class=""><li id="4c25" class="mo mp it lb b lc mq lf mr li ms lm mt lq mu lu mv mw mx my bi translated"><strong class="lb iu"> <em class="mz">入门</em> </strong></li><li id="fb25" class="mo mp it lb b lc na lf nb li nc lm nd lq ne lu mv mw mx my bi translated"><strong class="lb iu"> <em class="mz">第一步——库</em> </strong></li><li id="580a" class="mo mp it lb b lc na lf nb li nc lm nd lq ne lu mv mw mx my bi translated"><strong class="lb iu"> <em class="mz">第二步——直播</em> </strong></li><li id="4859" class="mo mp it lb b lc na lf nb li nc lm nd lq ne lu mv mw mx my bi translated"><strong class="lb iu"> <em class="mz">第三步—异步功能</em> </strong></li><li id="f20a" class="mo mp it lb b lc na lf nb li nc lm nd lq ne lu mv mw mx my bi translated"><strong class="lb iu"> <em class="mz">最后一步——测试实时识别器</em> </strong></li></ul></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="845d" class="nm lw it bd lx nn no np ma nq nr ns md jz nt ka mg kc nu kd mj kf nv kg mm nw bi translated">入门指南</h1><p id="c856" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">在今天的教程中，我们将使用AssemblyAI的<a class="ae ky" href="https://docs.assemblyai.com/overview/real-time-transcription" rel="noopener ugc nofollow" target="_blank">实时转录API </a>。作为一名软件工程师和技术爱好者，很高兴看到语音识别领域正在飞速发展。我相信这些发展正使我们的生活变得更容易。</p><p id="4d7d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，实时转录可以有所帮助的一个领域是在线讲座。在听导师讲课的同时，我们也可以把导师的讲话当字幕来读。这一功能将使听力障碍者的学习过程更加容易。这只是一个基本的例子；我确信有许多领域可以实现实时转录。</p><p id="f587" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">顺便说一下，<a class="ae ky" href="https://www.assemblyai.com/" rel="noopener ugc nofollow" target="_blank"> AssemblyAI的API </a>是免费访问的。创建帐户后，您将获得一个唯一的API密钥。我们需要这个API密匙来使用服务和特性。</p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="0eeb" class="nm lw it bd lx nn no np ma nq nr ns md jz nt ka mg kc nu kd mj kf nv kg mm nw bi translated">步骤1 —库</h1><p id="1023" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">我们将在这个项目中使用三个Python库。它们可以列举如下:PortAudio、PyAudio和Websockets。以下是它们的简短定义。</p><p id="2142" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> PortAudio </strong>是一个免费、跨平台、开源的音频输入/输出库。这也是让后续库<em class="mz"> PyAudio </em>工作的先决条件库。</p><p id="bdf0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="http://www.portaudio.com/" rel="noopener ugc nofollow" target="_blank">公文</a>。</p><p id="2385" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PyAudio是一个免费的开源库，可以在各种平台上播放和录制音频文件。这个库是PortAudio的扩展。</p><p id="17db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://people.csail.mit.edu/hubert/pyaudio/docs/" rel="noopener ugc nofollow" target="_blank">官方文件</a>。</p><p id="163f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> Websockets </strong>是建立在asyncio之上的依赖项，asyncio是Python的标准异步I/O框架。它提供了一个优雅的基于协程的API。</p><p id="7660" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://websockets.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank">官方文件</a>。</p><p id="a9ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们开始安装它们。</p><p id="7c44" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将在终端窗口中运行以下代码行。要安装PortAudio，我们必须使用名为brew的python库管理器。</p><pre class="kj kk kl km gt oa ob oc od aw oe bi"><span id="a9d5" class="lv lw it ob b gy of og l oh oi">brew install portaudio</span></pre><p id="670b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，是时候安装另外两个库了。这次我们使用另一个python库管理器pip。您知道我们可以在一行代码中安装一个或多个库吗？</p><pre class="kj kk kl km gt oa ob oc od aw oe bi"><span id="4f50" class="lv lw it ob b gy of og l oh oi">pip install pyaudio websockets</span></pre></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="5761" class="nm lw it bd lx nn no np ma nq nr ns md jz nt ka mg kc nu kd mj kf nv kg mm nw bi translated">步骤2 —实时流</h1><p id="a7f0" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">我们的图书馆已经安装好了。是时候准备好流媒体系统了！</p><p id="eed6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">是时候打开我们的编码平台，开始编码了。我们的代码是静态的，所以我将使用Atom文本编辑器。整个代码将在一个python文件中。易于运行。</p><pre class="kj kk kl km gt oa ob oc od aw oe bi"><span id="88d1" class="lv lw it ob b gy of og l oh oi">import pyaudio<br/> <br/>FRAMES_PER_BUFFER = 3200<br/>FORMAT = pyaudio.paInt16<br/>CHANNELS = 1<br/>RATE = 16000<br/>p = pyaudio.PyAudio()<br/> <br/><br/>stream = p.open(<br/>   format=FORMAT,<br/>   channels=CHANNELS,<br/>   rate=RATE,<br/>   input=True,<br/>   frames_per_buffer=FRAMES_PER_BUFFER<br/>)</span></pre><p id="a907" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的代码中，我们定义了流系统的参数。说到细节，音频世界真的很复杂。我建议在网上搜索每一个变量，以便更好地理解它们。</p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="1af3" class="nm lw it bd lx nn no np ma nq nr ns md jz nt ka mg kc nu kd mj kf nv kg mm nw bi translated">步骤3 —异步功能</h1><p id="1478" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">在这一步，我们将编写一个<em class="mz">异步</em>函数，用API发送和接收音频数据。异步函数在主题<a class="ae ky" href="https://docs.python.org/3/library/asyncio-task.html" rel="noopener ugc nofollow" target="_blank">协程和任务</a>下。</p><p id="e60c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用异步语法声明的协同程序是编写asyncio应用程序的首选方式。因为我们希望实时地传输语音，所以这是一个很好的方法，可以在终端窗口中显示识别出的单词，但需要等待一段时间。</p><h2 id="a36a" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">发送和接收音频数据</h2><p id="8a6c" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">首先，让我们导入python库。</p><pre class="kj kk kl km gt oa ob oc od aw oe bi"><span id="59d9" class="lv lw it ob b gy of og l oh oi">import websockets<br/>import asyncio<br/>import base64<br/>import json<br/>from configure import auth_key</span></pre><p id="61a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们将编写一个函数，我将其命名为:<em class="mz"> send_receive_data( </em>)。在这个函数中发生了许多事情:</p><ul class=""><li id="7a56" class="mo mp it lb b lc ld lf lg li oj lm ok lq ol lu mv mw mx my bi translated">将程序连接到AssemblyAI的端点url。</li><li id="8d0d" class="mo mp it lb b lc na lf nb li nc lm nd lq ne lu mv mw mx my bi translated">音频数据被传输到API进行识别。</li><li id="854d" class="mo mp it lb b lc na lf nb li nc lm nd lq ne lu mv mw mx my bi translated">API返回一个json数据和识别的语音。</li></ul><p id="c569" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这基本上是一条双向高速公路，我们通过笔记本电脑的麦克风发送语音数据。然后，从API接收识别的语音。一切都发生得太快了。</p><p id="3785" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">是不是很酷？你猜怎么着，没有高峰时间:)</p><pre class="kj kk kl km gt oa ob oc od aw oe bi"><span id="913e" class="lv lw it ob b gy of og l oh oi"># the AssemblyAI endpoint we're going to hit<br/>URL = "wss://api.assemblyai.com/v2/realtime/ws?sample_rate=16000"<br/> <br/>async def send_receive_data():<br/>   print(f'Connecting websocket to url ${URL}')<br/>   async with websockets.connect(<br/>       URL,<br/>       extra_headers=(("Authorization", "our API key"),),<br/>       ping_interval=5,<br/>       ping_timeout=20<br/>   ) as _ws:<br/>       await asyncio.sleep(0.1)<br/>       print("Receiving SessionBegins ...")<br/>       session_begins = await _ws.recv()<br/>       print(session_begins)<br/>       print("Sending messages ...")<br/>       async def send():<br/>           while True:<br/>               try:<br/>                   data = stream.read(FRAMES_PER_BUFFER)<br/>                   data = base64.b64encode(data).decode("utf-8")<br/>                   json_data = json.dumps({"audio_data":str(data)})<br/>                   await _ws.send(json_data)<br/>               except websockets.exceptions.ConnectionClosedError as e:<br/>                   print(e)<br/>                   assert e.code == 4008<br/>                   break<br/>               except Exception as e:<br/>                   assert False, "Not a websocket 4008 error"<br/>               await asyncio.sleep(0.01)<br/>          <br/>           return True<br/>      <br/>       async def receive():<br/>           while True:<br/>               try:<br/>                   result_str = await _ws.recv()<br/>                   print(json.loads(result_str)['text'])<br/>               except websockets.exceptions.ConnectionClosedError as e:<br/>                   print(e)<br/>                   assert e.code == 4008<br/>                   break<br/>               except Exception as e:<br/>                   assert False, "Not a websocket 4008 error"<br/>      <br/>       send_result, receive_result = await asyncio.gather(send(), receive())</span></pre><h2 id="7953" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">环</h2><p id="fc82" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated"><em class="mz"> send_receive_data() </em>函数全部设置完毕！</p><p id="f7aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们把它放在一个循环中，这样我们的程序就能连续不断地听到我们的声音。由于我们不想让它永远运行，所以有一个超时，也就是1分钟。阿辛西奥会为我们做这件事。</p><pre class="kj kk kl km gt oa ob oc od aw oe bi"><span id="eb47" class="lv lw it ob b gy of og l oh oi">asyncio.run(send_receive_data())</span></pre></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="fd54" class="nm lw it bd lx nn no np ma nq nr ns md jz nt ka mg kc nu kd mj kf nv kg mm nw bi translated">最后一步—测试实时识别器</h1><p id="e752" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nx lk ll lm ny lo lp lq nz ls lt lu im bi translated">在终端中运行main.py后，程序开始监听。并在那一刻显示识别的语音。我看了这篇文章的引言部分，下面是结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/1bbbe985791ce3b13debdf0618b0bc64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NkkwMSWh6uuXxF9z9jSUIQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者截图。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/a54fff0e953980eb4d47294ebbe052a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GY3fBQAPgXEy2p0lsD-IQg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者截图。</p></figure><p id="e31d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">恭喜你。在本实践教程中，我们学习了如何使用Python构建一个程序来检测我们的语音并将其实时转换为文本。我喜欢创建和从事这些项目，因为它们是机器学习和人工智能在我们日常生活中的自然应用。希望你喜欢阅读本指南，并在今天学到一些新东西。</p><blockquote class="oo op oq"><p id="0196" class="kz la mz lb b lc ld ju le lf lg jx lh or lj lk ll os ln lo lp ot lr ls lt lu im bi translated">我是<a class="ou ov ep" href="https://medium.com/u/a073b4360020?source=post_page-----fbbd62e6ff9d--------------------------------" rel="noopener" target="_blank">贝希克·居文</a>，我喜欢分享关于编程、教育和生活的故事。<a class="ae ky" href="https://lifexplorer.medium.com/membership" rel="noopener">订阅</a>我的内容，保持灵感。泰，</p></blockquote><p id="3a4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想知道我写的是什么样的文章，这里有一些:</p><ul class=""><li id="eeae" class="mo mp it lb b lc ld lf lg li oj lm ok lq ol lu mv mw mx my bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/building-a-face-recognizer-in-python-7fd6630c6340">使用Python构建人脸识别器</a></li><li id="4985" class="mo mp it lb b lc na lf nb li nc lm nd lq ne lu mv mw mx my bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/step-by-step-guide-building-a-prediction-model-in-python-ac441e8b9e8b">分步指南—用Python构建预测模型</a></li><li id="af7c" class="mo mp it lb b lc na lf nb li nc lm nd lq ne lu mv mw mx my bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/building-a-speech-emotion-recognizer-using-python-4c1c7c89d713">使用Python构建语音情感识别器</a></li></ul></div></div>    
</body>
</html>