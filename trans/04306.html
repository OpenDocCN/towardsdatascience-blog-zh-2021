<html>
<head>
<title>LightAutoML vs Titanic: 80% accuracy in several lines of code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">LightAutoML vs Titanic:几行代码80%的准确率</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lightautoml-preset-usage-tutorial-2cce7da6f936?source=collection_archive---------15-----------------------#2021-04-12">https://towardsdatascience.com/lightautoml-preset-usage-tutorial-2cce7da6f936?source=collection_archive---------15-----------------------#2021-04-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="852b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本教程中，我们将讨论如何使用开源框架LightAutoML在Kaggle上为泰坦尼克号生存竞赛自动创建几行代码的ML模型。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/b06d5d868c8174f83a65778d70f9d251.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*grZb0sIZyS6qeM6c"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">照片由<a class="ae lb" href="https://unsplash.com/@clarktibbs?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">克拉克·蒂布斯</a>在<a class="ae lb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="70a7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2020年底，开源python库<a class="ae lb" href="https://github.com/sberbank-ai-lab/LightAutoML" rel="noopener ugc nofollow" target="_blank"> LightAutoML </a>由Sber AI实验室的AutoML团队发布，作为自动化机器学习(AutoML)框架。它被设计成轻量级的，高效的，用于表格数据集中的各种任务(二进制/多类分类和回归)，表格数据集中包含不同类型的特征:数字、分类、日期、文本等。</p><p id="3ea6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">LightAutoML安装非常简单— <code class="fe lc ld le lf b">pip install -U lightautoml</code> <br/> <a class="ae lb" href="https://lightautoml.readthedocs.io/" rel="noopener ugc nofollow" target="_blank">官方LightAutoML文档</a></p><p id="4610" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">LightAutoML不仅提供了端到端ML任务解决的预设，还提供了易于使用的ML管道创建构造器，包括数据预处理元素、高级特征生成、CV方案(包括嵌套CV)、超参数调整、不同的模型和组合构建方法。它还为用户提供了一个选项来生成模型训练和分析报告，以检查模型结果，并找到从初始数据集不明显的见解。</p><p id="7856" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面我们将展示如何使用LightAutoML解决<a class="ae lb" href="https://www.kaggle.com/c/titanic" rel="noopener ugc nofollow" target="_blank">Titanic-机器从灾难中学习</a>竞赛-从python库导入到保存最终提交文件。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><h1 id="4dcf" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">0.0步。基于LightAutoML的超短钛解决方案</h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ml"><img src="../Images/c0d79be090ef5200bbf8788b970a49ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DpJvQVTiirzaxR_1fhg7hA.png"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">基于LightAutoML的超短钛解决方案</p></figure><p id="3498" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面的代码作为内核<a class="ae lb" href="https://www.kaggle.com/alexryzhkov/lightautoml-extreme-short-titanic-solution" rel="noopener ugc nofollow" target="_blank">在这里</a>可用，在Kaggle公共排行榜上仅用7分12行就获得了<strong class="jp ir"> 0.77990 </strong>的分数。主要的LightAutoML部分只有3行—从第8行到第10行。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="67a2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面我们将讨论<a class="ae lb" href="https://www.kaggle.com/alexryzhkov/lightautoml-titanic-love" rel="noopener ugc nofollow" target="_blank">另一个得分为<strong class="jp ir"> 0.79665的内核</strong></a>，它的结构更像一个真正的商业ML解决方案，可以用作自己项目的模板。</p><h1 id="c7aa" class="ln lo iq bd lp lq mm ls lt lu mn lw lx ly mo ma mb mc mp me mf mg mq mi mj mk bi translated">步骤0.1。导入必要的库</h1><p id="18cd" class="pw-post-body-paragraph jn jo iq jp b jq mr js jt ju ms jw jx jy mt ka kb kc mu ke kf kg mv ki kj kk ij bi translated">在这一步，我们导入3个标准python库，几个来自常用数据科学家集的库，包括<em class="mw"> numpy </em>、<em class="mw"> pandas、</em>和<em class="mw"> sklearn </em>以及来自LightAutoML的2个预置— <em class="mw"> TabularAutoML </em>和<em class="mw"> TabularUtilizedAutoML </em>。我们将在后面讨论它们能做什么以及它们之间的区别。</p><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="04a2" class="nb lo iq lf b gy nc nd l ne nf"><em class="mw"># Standard python libraries</em><br/>import os<br/>import time<br/>import re<br/><br/><em class="mw"># Installed libraries</em><br/>import numpy as np<br/>import pandas as pd<br/>from sklearn.metrics import accuracy_score, f1_score<br/>from sklearn.model_selection import train_test_split<br/><br/><em class="mw"># Imports from LightAutoML package</em><br/>from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML<br/>from lightautoml.tasks import Task</span></pre><h1 id="cb3c" class="ln lo iq bd lp lq mm ls lt lu mn lw lx ly mo ma mb mc mp me mf mg mq mi mj mk bi translated">第0.2步。数据集加载</h1><p id="a123" class="pw-post-body-paragraph jn jo iq jp b jq mr js jt ju ms jw jx jy mt ka kb kc mu ke kf kg mv ki kj kk ij bi translated">现在我们需要加载训练和测试数据集以及提交文件，我们应该用预测的类来填充它:</p><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="2e67" class="nb lo iq lf b gy nc nd l ne nf">%%time<br/><br/>train_data = pd.read_csv('../input/titanic/train.csv')<br/>train_data.head()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ng"><img src="../Images/2bca22632da769fe8e95efd900e3427c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LRQ5duPcSarpL7HMr457VQ.png"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">训练数据集</p></figure><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="cbde" class="nb lo iq lf b gy nc nd l ne nf">test_data = pd.read_csv('../input/titanic/test.csv')<br/>test_data.head()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ng"><img src="../Images/91c37076bc548ac20f98e8cb1c142ece.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qGZriWxeRiP5TgJZL6KbjQ.png"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">测试数据集</p></figure><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="cba1" class="nb lo iq lf b gy nc nd l ne nf">submission = pd.read_csv('../input/titanic/gender_submission.csv')<br/>submission.head()</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nh"><img src="../Images/a57278226dbeb79a6c0314dd8635e874.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hcBaw9panWgR0NtNmfhJVA.png"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">提交文件模板</p></figure><h1 id="be42" class="ln lo iq bd lp lq mm ls lt lu mn lw lx ly mo ma mb mc mp me mf mg mq mi mj mk bi translated">步骤0.3。附加专家功能创建模块</h1><p id="2cdb" class="pw-post-body-paragraph jn jo iq jp b jq mr js jt ju ms jw jx jy mt ka kb kc mu ke kf kg mv ki kj kk ij bi translated">下面的单元格显示了一些用户特性准备，这有助于LightAutoML区分正负类对象。这些特征背后的逻辑是用于票列的票类型提取、家庭大小计算、名字特征清理等。：</p><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="ded4" class="nb lo iq lf b gy nc nd l ne nf">def get_title(name):<br/>    title_search = re.search(' ([A-Za-z]+)\.', name)<br/>    <em class="mw"># If the title exists, extract and return it.</em><br/>    if title_search:<br/>        return title_search.group(1)<br/>    return ""<br/><br/>def create_extra_features(data):<br/>    data['Ticket_type'] = data['Ticket'].map(lambda x: x[0:3])<br/>    data['Name_Words_Count'] = data['Name'].map(lambda x: len(x.split()))<br/>    data['Has_Cabin'] = data["Cabin"].map(lambda x: 1 - int(type(x) == float))<br/>    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1<br/>    <br/>    data['CategoricalFare'] = pd.qcut(data['Fare'], 5).astype(str)<br/>    data['CategoricalAge'] = pd.cut(data['Age'], 5).astype(str)<br/>    <br/>    data['Title'] = data['Name'].apply(get_title).replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')<br/>    data['Title'] = data['Title'].replace('Mlle', 'Miss')<br/>    data['Title'] = data['Title'].replace('Ms', 'Miss')<br/>    data['Title'] = data['Title'].replace('Mme', 'Mrs')<br/>    data['Title'] = data['Title'].map({"Mr": 1, "Miss": 2, "Mrs": 3, "Master": 4, "Rare": 5}).fillna(0)<br/>    return data<br/><br/>train_data = create_extra_features(train_data)<br/>test_data = create_extra_features(test_data)</span></pre><h1 id="9068" class="ln lo iq bd lp lq mm ls lt lu mn lw lx ly mo ma mb mc mp me mf mg mq mi mj mk bi translated">步骤0.4。用于列车验证的数据分割</h1><p id="2825" class="pw-post-body-paragraph jn jo iq jp b jq mr js jt ju ms jw jx jy mt ka kb kc mu ke kf kg mv ki kj kk ij bi translated">为了验证我们将要构建的模型，我们需要将数据集分成训练和验证部分:</p><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="8f01" class="nb lo iq lf b gy nc nd l ne nf">%%time<br/><br/>tr_data, valid_data = train_test_split(train_data, <br/>                                       test_size=0.2, <br/>                                       stratify=data[‘Survived’], <br/>                                       random_state=42)<br/>logging.info(‘Parts sizes: tr_data = {}, valid_data = {}’<br/>              .format(tr_data.shape, valid_data.shape))</span></pre><h1 id="b89f" class="ln lo iq bd lp lq mm ls lt lu mn lw lx ly mo ma mb mc mp me mf mg mq mi mj mk bi translated">= LightAutoML预设用法=</h1><h1 id="2c1e" class="ln lo iq bd lp lq mm ls lt lu mn lw lx ly mo ma mb mc mp me mf mg mq mi mj mk bi translated">第一步。创建任务对象</h1><p id="56ca" class="pw-post-body-paragraph jn jo iq jp b jq mr js jt ju ms jw jx jy mt ka kb kc mu ke kf kg mv ki kj kk ij bi translated">在这条线以下，我们准备建立幸存目标变量预测的模型。首先，我们使用LightAutoML任务类对象设置我们需要的模型类型，有效值可以是:</p><ul class=""><li id="a4ed" class="ni nj iq jp b jq jr ju jv jy nk kc nl kg nm kk nn no np nq bi translated">“二进制”用于二进制分类</li><li id="0ca2" class="ni nj iq jp b jq nr ju ns jy nt kc nu kg nv kk nn no np nq bi translated">reg '用于回归和</li><li id="2487" class="ni nj iq jp b jq nr ju ns jy nt kc nu kg nv kk nn no np nq bi translated">多类分类的“多类”</li></ul><p id="8907" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于我们有二进制分类竞赛，我们用F1度量设置具有“二进制”值的任务对象，以更加关注模型预测精度-召回平衡:</p><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="5c39" class="nb lo iq lf b gy nc nd l ne nf">def f1_metric(y_true, y_pred):<br/>    return f1_score(y_true, (y_pred &gt; 0.5).astype(int))<br/><br/>task = Task('binary', metric = f1_metric)</span></pre><h1 id="6a45" class="ln lo iq bd lp lq mm ls lt lu mn lw lx ly mo ma mb mc mp me mf mg mq mi mj mk bi translated">第二步。设置列角色</h1><p id="4bbf" class="pw-post-body-paragraph jn jo iq jp b jq mr js jt ju ms jw jx jy mt ka kb kc mu ke kf kg mv ki kj kk ij bi translated">这里的角色设置是将名为<em class="mw">的目标列survivors</em>和drop列<em class="mw"> PassengerId </em>从已经用于专家特征<em class="mw"> Name </em>和<em class="mw"> Ticket </em>列的数据集中删除；</p><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="7ab0" class="nb lo iq lf b gy nc nd l ne nf">%%time<br/><br/>roles = {'target': 'Survived',<br/>         'drop': <!-- -->['PassengerId', 'Name', 'Ticket']<!-- -->}</span></pre><h1 id="0550" class="ln lo iq bd lp lq mm ls lt lu mn lw lx ly mo ma mb mc mp me mf mg mq mi mj mk bi translated">第三步。从预设创建自动模型</h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="ab gu cl nw"><img src="../Images/44cd008f1b3a20aed068276d8308b91d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*VdoX78-sv4wThpGxpCSmnQ.png"/></div><p class="kx ky gj gh gi kz la bd b be z dk translated">我们的第一个模型的结构-线性模型，具有专家参数的LightGBM和具有Optuna优化参数的LightGBM被加权平均以创建最终预测</p></figure><p id="f31c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了开发具有上述结构的第一个LightAutoML模型，我们使用了<code class="fe lc ld le lf b">TabularAutoML</code>预置。在代码中，它看起来像这样:</p><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="728d" class="nb lo iq lf b gy nc nd l ne nf">automl = TabularAutoML(task = task, <br/>                       timeout = 600, # 600 seconds = 10 minutes<br/>                       cpu_limit = 4, # Optimal for Kaggle kernels<br/>                       general_params = {'use_algos': [['linear_l2', <br/>                                         'lgb', 'lgb_tuned']]})</span></pre><p id="108c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基本算法，目前可用于<code class="fe lc ld le lf b">general_params use_algos</code>:</p><ul class=""><li id="16d4" class="ni nj iq jp b jq jr ju jv jy nk kc nl kg nm kk nn no np nq bi translated">线性模型(称为<code class="fe lc ld le lf b">'linear_l2'</code>)</li><li id="3367" class="ni nj iq jp b jq nr ju ns jy nt kc nu kg nv kk nn no np nq bi translated">基于数据集的具有专家参数的LightGBM模型(<code class="fe lc ld le lf b">'lgb'</code></li><li id="6c3f" class="ni nj iq jp b jq nr ju ns jy nt kc nu kg nv kk nn no np nq bi translated">使用Optuna ( <code class="fe lc ld le lf b">'lgb_tuned'</code>)调整参数的LightGBM</li><li id="7785" class="ni nj iq jp b jq nr ju ns jy nt kc nu kg nv kk nn no np nq bi translated">带专家参数(<code class="fe lc ld le lf b">'cb'</code>)的CatBoost模型和</li><li id="ef2c" class="ni nj iq jp b jq nr ju ns jy nt kc nu kg nv kk nn no np nq bi translated">带有Optuna参数的CatBoost(<code class="fe lc ld le lf b">'cb_tuned'</code>)</li></ul><p id="3e52" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如您所见，<code class="fe lc ld le lf b">use_algos</code>是列表中的列表——这是创建ML管道的符号，可以根据您的需要创建任意多级算法。例如，<code class="fe lc ld le lf b">[['linear_l2', 'lgb', 'cb'], ['lgb_tuned', 'cb']]</code>代表第一层3个算法，第二层2个算法。在第二层被完全训练后，来自2个算法的预测被加权平均以构建最终的预测。在<code class="fe lc ld le lf b">TabularAutoML</code>的<a class="ae lb" href="https://github.com/sberbank-ai-lab/LightAutoML/blob/master/lightautoml/automl/presets/tabular_config.yml" rel="noopener ugc nofollow" target="_blank"> YAML配置</a>中可以找到为【】定制提供的全套参数(不仅仅是通用参数)。</p><p id="6fe9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了使我们的<code class="fe lc ld le lf b">TabularAutoML</code>预设模型适合数据集的train部分，我们使用下面的代码:</p><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="30ed" class="nb lo iq lf b gy nc nd l ne nf">oof_pred = automl.fit_predict(tr_data, roles = roles)</span></pre><p id="fe20" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为<code class="fe lc ld le lf b">fit_predict</code>函数的结果，我们得到了折叠外(简称OOF)预测。它们基于LightAutoML的内部CV，可用于计算训练数据的模型性能指标。</p><h1 id="4dcd" class="ln lo iq bd lp lq mm ls lt lu mn lw lx ly mo ma mb mc mp me mf mg mq mi mj mk bi translated">第四步。预测验证数据并检查分数</h1><p id="4f36" class="pw-post-body-paragraph jn jo iq jp b jq mr js jt ju ms jw jx jy mt ka kb kc mu ke kf kg mv ki kj kk ij bi translated">现在我们有了一个经过训练的模型，我们希望接收验证数据的预测:</p><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="d2a7" class="nb lo iq lf b gy nc nd l ne nf">valid_pred = automl.predict(valid_data)</span></pre><p id="b66f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">既然我们有了这个对象的基本事实标签，让我们检查一下我们有多好:</p><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="34fa" class="nb lo iq lf b gy nc nd l ne nf">def acc_score(y_true, y_pred):<br/>    return accuracy_score(y_true, (y_pred &gt; 0.5).astype(int))</span><span id="67d1" class="nb lo iq lf b gy nx nd l ne nf">print('OOF acc: <strong class="lf ir">{}</strong>'.format(acc_score(tr_data['Survived'].values,      oof_pred.data[:, 0])))<br/>print('VAL acc: <strong class="lf ir">{}</strong>'.format(acc_score(valid_data['Survived'].values, valid_pred.data[:, 0])))</span></pre><p id="5805" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">结果非常好且稳定，在2.5分钟内，OOF的准确率为84.4%，验证数据的准确率为83.2%。但是我们想要更多:)</p><h1 id="aa40" class="ln lo iq bd lp lq mm ls lt lu mn lw lx ly mo ma mb mc mp me mf mg mq mi mj mk bi translated">第五步。创建具有时间利用率的LightAutoML模型</h1><p id="c7a0" class="pw-post-body-paragraph jn jo iq jp b jq mr js jt ju ms jw jx jy mt ka kb kc mu ke kf kg mv ki kj kk ij bi translated">下面我们将为超时利用率创建特定的AutoML预设(尽量在超时界限内使用):</p><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="bedc" class="nb lo iq lf b gy nc nd l ne nf">automl = TabularUtilizedAutoML<!-- -->(task = task, <br/>                       timeout = 600, # 600 seconds = 10 minutes<br/>                       cpu_limit = 4, # Optimal for Kaggle kernels<br/>                       general_params = {'use_algos': [['linear_l2', <br/>                                         'lgb', 'lgb_tuned']]})</span></pre><p id="cc18" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">是时候适应并获得更好的结果了:</p><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="60b5" class="nb lo iq lf b gy nc nd l ne nf">oof_pred = automl.fit_predict(tr_data, roles = roles)</span></pre><p id="6af4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如您所看到的，两个预置的API是相同的，所以您可以轻松地检查它们，而无需太多的编码。</p><h1 id="d1d4" class="ln lo iq bd lp lq mm ls lt lu mn lw lx ly mo ma mb mc mp me mf mg mq mi mj mk bi translated">第六步。预测验证数据并检查所用模型的分数</h1><p id="9dff" class="pw-post-body-paragraph jn jo iq jp b jq mr js jt ju ms jw jx jy mt ka kb kc mu ke kf kg mv ki kj kk ij bi translated"><code class="fe lc ld le lf b">TabularUtilizedAutoML</code>的预测API也是一样的:</p><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="5df9" class="nb lo iq lf b gy nc nd l ne nf">valid_pred = automl.predict(valid_data)</span></pre><p id="6352" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们检查分数:</p><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="0b27" class="nb lo iq lf b gy nc nd l ne nf">print('OOF acc: <strong class="lf ir">{}</strong>'.format(acc_score(tr_data['Survived'].values,      oof_pred.data[:, 0])))<br/>print('VAL acc: <strong class="lf ir">{}</strong>'.format(acc_score(valid_data['Survived'].values, valid_pred.data[:, 0])))</span></pre><p id="8116" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">哇！<strong class="jp ir">在不到9分钟的时间内，OOF的准确率为85.5%，验证数据的准确率为82.7%。</strong>这里的验证分数稍低，但我们只有179名乘客。OOF分数增加在这里更有价值，因为在它的计算中我们有712名乘客。</p><h1 id="54f3" class="ln lo iq bd lp lq mm ls lt lu mn lw lx ly mo ma mb mc mp me mf mg mq mi mj mk bi translated">第七步。在完整数据集上重新训练所选模型，并为真实测试进行预测</h1><p id="c600" class="pw-post-body-paragraph jn jo iq jp b jq mr js jt ju ms jw jx jy mt ka kb kc mu ke kf kg mv ki kj kk ij bi translated">现在我们知道使用什么模型在Titanic数据集上获得好的结果，所以是时候在整个数据集上重新训练它了:</p><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="e2bd" class="nb lo iq lf b gy nc nd l ne nf">automl = TabularUtilizedAutoML<!-- -->(task = task, <br/>                       timeout = 600, # 600 seconds = 10 minutes<br/>                       cpu_limit = 4, # Optimal for Kaggle kernels<br/>                       general_params = {'use_algos': [['linear_l2', <br/>                                         'lgb', 'lgb_tuned']]})<br/>oof_pred = automl.fit_predict(train_data, roles = roles)<br/>test_pred = automl.predict(test_data)</span></pre><h1 id="ee1b" class="ln lo iq bd lp lq mm ls lt lu mn lw lx ly mo ma mb mc mp me mf mg mq mi mj mk bi translated">第八步。准备提交给Kaggle</h1><p id="c547" class="pw-post-body-paragraph jn jo iq jp b jq mr js jt ju ms jw jx jy mt ka kb kc mu ke kf kg mv ki kj kk ij bi translated">因为我们已经加载了样本提交文件，所以我们唯一需要做的就是将我们的预测插入其中并保存文件:</p><pre class="km kn ko kp gt mx lf my mz aw na bi"><span id="8ecc" class="nb lo iq lf b gy nc nd l ne nf">submission['Survived'] = (test_pred.data[:, 0] &gt; 0.5).astype(int)<br/>submission.to_csv('automl_utilized_600_f1_score.csv', index = False)</span></pre><h1 id="dd73" class="ln lo iq bd lp lq mm ls lt lu mn lw lx ly mo ma mb mc mp me mf mg mq mi mj mk bi translated">第九步。臣服于Kaggle！！！</h1><p id="8a48" class="pw-post-body-paragraph jn jo iq jp b jq mr js jt ju ms jw jx jy mt ka kb kc mu ke kf kg mv ki kj kk ij bi translated">我们准备的提交分数<strong class="jp ir"> 0.79665 </strong>在Kaggle公共排行榜上。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><h1 id="fa6c" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">结论</h1><p id="80e8" class="pw-post-body-paragraph jn jo iq jp b jq mr js jt ju ms jw jx jy mt ka kb kc mu ke kf kg mv ki kj kk ij bi translated">在本教程中，我们使用<a class="ae lb" href="https://github.com/sberbank-ai-lab/LightAutoML" rel="noopener ugc nofollow" target="_blank"> LightAutoML </a>为泰坦尼克号生存竞赛创建了一个分步解决方案，LightAutoML是一个用于快速、自动创建ML模型的开源框架。</p><p id="f82b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">完整的教程代码可以在Kaggle内核<a class="ae lb" href="https://www.kaggle.com/alexryzhkov/lightautoml-titanic-love" rel="noopener ugc nofollow" target="_blank">这里</a>(和<a class="ae lb" href="https://www.kaggle.com/alexryzhkov/lightautoml-extreme-short-titanic-solution" rel="noopener ugc nofollow" target="_blank">这里</a>超短版本的解决方案)——只要在这个数据集或任何其他数据集上试一试。能让你大吃一惊:)</p><p id="722d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请继续关注更多示例！</p></div></div>    
</body>
</html>