<html>
<head>
<title>A Variational Information Bottleneck (VIB) Based Method to Compress Sequential Networks for Human Action Recognition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于变分信息瓶颈(VIB)的人体动作识别序列网络压缩方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-variational-information-bottleneck-vib-based-method-to-compress-sequential-networks-for-human-b559d3a50e30?source=collection_archive---------35-----------------------#2021-07-14">https://towardsdatascience.com/a-variational-information-bottleneck-vib-based-method-to-compress-sequential-networks-for-human-b559d3a50e30?source=collection_archive---------35-----------------------#2021-07-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="33f5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">压缩LSTMs并推断边上的模型</h2></div><p id="aa66" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文是关于我们<a class="ae lb" href="https://openaccess.thecvf.com/content/WACV2021/papers/Srivastava_A_Variational_Information_Bottleneck_Based_Method_to_Compress_Sequential_Networks_WACV_2021_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">最近在WACV 2021 </strong> </a>上发表的关于神经网络压缩的论文。</p><h1 id="d6c4" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated"><strong class="ak">需要压缩网络以执行具有序列数据的任务，例如用于动作识别的视频:</strong></h1><p id="d866" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">递归神经网络(RNNs)及其高级变体长短期(LSTM)等网络专门用于处理文本、口语和视频等序列数据。但是这些网络具有大量的参数，并且导致大量的推理时间。这些网络中隐藏状态的数量是一个超参数，通常选择的数量(256或512或1028)通常比精确预测所需的数量大得多，并导致过度参数化。在视频动作识别任务中，输入视频帧通常由RGB叠加彩色帧组成，形成高维输入。因此，对于RNNs，输入的维数变高，使得输入-隐藏矩阵非常大。例如，来自UCF11数据集的视频具有尺寸为160x120像素的RGB帧。因此，总输入大小必须为160x120x3= 57，000。即使相对较小的隐藏状态大小为256，单层LSTM模型中所需的总参数为<strong class="kh ir">5890万。</strong>天真的<strong class="kh ir"> <em class="lz"> </em> </strong> <em class="lz">过参数化</em>一层端到端LSTM模型在UCF11数据集上以67.7%的精度过度拟合[4]。</p><h1 id="061e" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated"><strong class="ak">具有可变信息瓶颈的“相关性”思想:</strong></h1><p id="6803" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">几种张量分解方法[3，4，5]已应用于RNNs，以低秩结构取代标准的输入-隐藏矩阵。这些方法修改输入并对输入-隐藏矩阵建模，以保留较低秩的密集权重矩阵。然而，大多数压缩RNNs的方法并不压缩隐藏到隐藏矩阵的大小。作为一个简单的动作识别数据集，UCF11比其他大型数据集(如UCF101)具有更少的类，数据集中的变化很小。这提示只需要几个与正确预测动作相关的隐藏状态来对数据表示进行建模。Tishby等人[1]提出的<em class="lz">变分信息瓶颈(VIB) </em>理论引入了在神经网络中仅保留<em class="lz">相关中间数据表示</em>同时保持预测准确性的思想。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi ma"><img src="../Images/c4816774188f53bc39327fc9ef04d049.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v-INnALzu7tbShsdTxN9Uw.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">图1: Tishby等人。文献[1]提出了基于信息论测度的变分信息瓶颈原理，以获得最简洁而又可预测的相关表示。</p></figure><p id="2fe3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将这一想法应用于RNNs的复杂变体，LSTM网络<em class="lz">移除冗余输入特征和隐藏状态</em>，从而减少模型参数的总数。</p><h1 id="cfb8" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated"><strong class="ak">如何用VIB保留相关的隐藏状态和输入特征到LSTMs？</strong></h1><p id="55e9" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">受VIB去除冗余神经元思想的启发，我们在压缩时序网络方面做出了以下贡献:</p><p id="6bf4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">(a)我们提出了如图2(a)所示的新型VIB-LSTM结构，用于训练高精度稀疏LSTM模型。</p><p id="086f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">(b)我们开发了一个顺序网络压缩流水线，该流水线稀疏化RNNs/lstm/gru的预训练模型矩阵。</p><p id="bcb1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">(c)对于结合CNN和LSTM的架构，我们的VIB框架仅保留预测相关特征，这些特征可以作为VIB-LSTM结构的输入。</p><p id="7fac" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">(d)我们在流行的动作识别数据集UCF11、UCF101和HMDB51上评估我们的方法，以产生具有可与最先进模型相比的验证准确度的紧凑模型。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mq"><img src="../Images/b2b399bdd0bf63894554613b8e26e14e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kCbqJ5Tyth-Z3IVIpRbyaA.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">图2: (a)单个VIB-LSTM电池。它在每个门输出后有一个VIB层<strong class="bd mr"> z </strong>(显示为绿色)，作为一个可训练的面具。每个<strong class="bd mr"> z </strong>遵循具有可训练参数的多元高斯分布。(b)VIB-LSTM结构的方程表明只需要对原始方程稍加修改。</p></figure><p id="632d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的目标是学习一个压缩表示门表示<em class="lz"> i^t、f^t、o^t和g^t </em>，同时保留<em class="lz"> v^t </em>中预测所需的相关空间和时间信息。在变分信息瓶颈(VIB)框架[1]中，这是一个优化问题，目标是学习<em class="lz"> k\tilda^T </em>，使其具有最少的关于LSTM输入<em class="lz"> v^t </em>的信息，同时保留学习目标<em class="lz"> Y </em>所需的所有相关信息。注意，压缩<em class="lz"> k\tilda^T </em>等同于压缩<em class="lz"> h^T、</em>，因为它们之间存在确定性映射。<em class="lz"> </em>从数学上讲，它相当于优化以下目标函数:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi ms"><img src="../Images/d44effcec619c9edd676f62696ed2508.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i7RSofHhEu59mVlFxPhFMQ.png"/></div></div></figure><p id="9c1f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中I()表示两个随机变量之间的互信息，<em class="lz"> θ </em>是将<em class="lz"> v^t </em>转换为<em class="lz"> k\tilda^T的压缩神经网络的参数集，β </em>是控制压缩和预测精度之间的折衷量的超参数。由于模型的复杂性和互信息项的不可行性，上述方程通常是难以处理的，因此调用了变分上限[2]。我们将VIB理论作为一个层应用于LSTM门输出，这产生了图2(b)中的方程。这仅保留了相关的隐藏状态，从而降低了LSTM的隐藏到隐藏矩阵的隐藏状态维数。类似地，对于端到端和CNN-LSTM架构，我们在LSTM的输入上引入VIB层，以仅保留预测相关的特征向量，从而降低LSTM的输入到隐藏矩阵的输入维度。这种基于VIB的模型压缩方法稀疏化了所有的LSTM矩阵，不像以前的动作识别张量分解方法[3，4，5]。</p><h1 id="1059" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated"><strong class="ak">对树莓Pi的推断:</strong></h1><p id="c7b0" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">为了测试使用我们的方法获得的压缩CNN-VIB-LSTM模型相对于相同任务的天真的CNN-LSTM模型的推理速度，我们在Raspberry Pi模型3上部署了这两个模型。我们从UCF11数据集中提取了一个人从跳板上跳水的视频，标记为“跳水”,并分别使用未压缩和压缩模型来推断动作。如图3所示，压缩模型的执行速度比未压缩版本快100倍。</p><div class="mb mc md me gt ab cb"><figure class="mt mf mu mv mw mx my paragraph-image"><img src="../Images/c2e0acfc6e1a5d381f02f811405f5eb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*S7EqssPvzE101U8J5FKCfw.gif"/></figure><figure class="mt mf mu mv mw mx my paragraph-image"><img src="../Images/17152a2328649a8e9929fbe968acee66.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*DFrqhm6K4ebg5hzcL2r-qg.gif"/><p class="mm mn gj gh gi mo mp bd b be z dk mz di na nb translated">图3:来自UCF11数据集的视频的动作识别，标记为在Raspberry Pi模型3上潜水运行。左图:使用经过训练的未压缩CNN-LSTM模型，在1.26秒内使用33.57米的LSTM参数推断动作。右图:使用经过训练和<strong class="bd mr">压缩的</strong> CNN-VIB-LSTM模型在0.013秒内使用2052个LSTM参数进行动作推断。</p></figure></div><h1 id="26f2" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated"><strong class="ak">结论和进一步工作:</strong></h1><p id="1889" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">我们提出了一种基于VIB理论的通用RNN压缩技术。具体来说，我们提出了一种从输入特征中提取预测相关信息的压缩方案。为此，我们制定了一个损失函数，旨在利用端到端的LSTM压缩和CNN-LSTM架构进行人体动作识别。我们最小化公式化的损失函数，以表明我们的方法显著压缩了基线的过参数化LSTM结构矩阵，从而减少了它们中的过拟合问题。因此，我们的方法可以产生适合部署在边缘设备上的模型，我们通过在Raspberry Pi上部署我们的CNN- VIB-LSTM训练模型并对其进行推理来展示这一点。此外，我们表明，我们的方法可以有效地与其他压缩方法一起使用，以获得更显著的压缩，而精度略有下降。进一步的研究可以尝试将张量分解和基于VIB的压缩相结合，用于RNNs的所有变体。</p><p id="5615" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更多细节可以在论文和下面的Youtube视频中找到。</p><figure class="mb mc md me gt mf"><div class="bz fp l di"><div class="nc nd l"/></div></figure><h1 id="d5b5" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated"><strong class="ak">参考文献</strong></h1><p id="055f" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">[1] Tishby，Naftali和Noga Zaslavsky。"深度学习和信息瓶颈原理."<em class="lz"> 2015年IEEE信息论研讨会(ITW) </em>。IEEE，2015。</p><p id="579e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2]Alemi，Alexander A .等，“深度变分信息瓶颈”<em class="lz"> arXiv预印本arXiv:1612.00410 </em> (2016)。</p><p id="6a18" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[3]杨、尹冲、丹尼斯·克龙帕斯和福尔克·特雷普。"用于视频分类的张量训练递归神经网络."<em class="lz">机器学习国际会议</em>。PMLR，2017。</p><p id="fabd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[4]潘，于，等.“用张量环压缩递归神经网络进行动作识别.”<em class="lz">AAAI人工智能会议记录</em>。第33卷。№01.2019.</p><p id="50a0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[5]叶，金冕，等.“用块项张量分解学习紧致递归神经网络”<em class="lz">IEEE计算机视觉和模式识别会议论文集</em>。2018.</p></div></div>    
</body>
</html>