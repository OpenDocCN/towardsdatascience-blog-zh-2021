<html>
<head>
<title>SHAP for Feature Selection and HyperParameter Tuning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于特征选择和超参数调整的SHAP</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/shap-for-feature-selection-and-hyperparameter-tuning-a330ec0ea104?source=collection_archive---------8-----------------------#2021-06-08">https://towardsdatascience.com/shap-for-feature-selection-and-hyperparameter-tuning-a330ec0ea104?source=collection_archive---------8-----------------------#2021-06-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9428" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">调整参数时，使用SHAP进行最佳特征选择</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d932a495c94edf0f554f2a1ecff070f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GWuKmong4NBI0kXV"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">蓝菊·福托雷菲在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="b72c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特征选择和超参数调整是每个机器学习任务中的两个重要步骤。大多数情况下，它们有助于提高性能，但缺点是耗费时间。参数组合越多，或者选择过程越精确，持续时间就越长。这是一个实际上我们无法克服的物理极限。我们能做的是利用我们管道中的最佳资源。我们面临不同的可能性，最方便的两种是:</p><ul class=""><li id="eea1" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">结合调音和选择功能</strong>；</li><li id="55fc" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">采用SHAP</strong>(SHapley Additive explaints)使整个过程更具概括性和准确性。</li></ul><p id="037a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将调整过程与特征的最佳选择相结合可能是每个基于排序的选择算法的需要。排序选择包括迭代地丢弃不太重要的特征，同时重新训练模型，直到达到收敛。<strong class="lb iu">用于特征选择的模型可能(在参数配置或类型上)不同于用于最终拟合和预测的模型</strong>。这可能导致次优性能。这是例如RFE(递归特征消除)或Boruta的情况，其中由算法通过可变重要性选择的特征被另一个算法用于最终拟合。</p><p id="b7a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们使用基于排名的算法进行特征选择时，SHAP会有所帮助。我们不使用梯度增强生成的默认变量重要性，而是选择最佳特征，如具有最高shapley值的特征。<strong class="lb iu">使用SHAP的好处显而易见，因为基于原生树的特征重要性存在偏差</strong>。标准方法倾向于高估连续或高基数分类变量的重要性。这使得在特征转移或类别数量变化的情况下计算的重要性不可信。</p><p id="ea20" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了克服这些不足，我们开发了<a class="ae ky" href="https://github.com/cerlymarco/shap-hypetune" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">shap-hype tune</strong></a>:<em class="mj">一个python包，用于同时进行超参数调整和特性选择。</em>它允许将超参数调整和特征选择结合到一个具有梯度增强模型的管道中。它支持网格搜索、随机搜索或贝叶斯搜索，并提供分级特征选择算法，如递归特征消除(RFE)、递归特征添加(RFA)或Boruta。额外的提升包括提供使用SHAP重要性进行特征选择的可能性。</p><p id="cf77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本帖中，我们展示了在执行监督预测任务时采用<a class="ae ky" href="https://github.com/cerlymarco/shap-hypetune" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> shap-hypetune </strong> </a>的实用程序。我们尝试搜索最佳参数配置，同时选择具有(和不具有)SHAP的最佳特征集。我们的实验分为三次试验。给定分类场景中的数据集，首先我们简单地通过优化参数来拟合LightGBM。然后，我们尝试在优化参数的同时，使用默认的基于树的特征重要性来操作标准RFE。最后，我们做同样的事情，但选择SHAP的功能。为了让事情更有趣，我们使用了一个不平衡的二进制目标和一些高基数的分类特征。</p><h1 id="86d8" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">参数调谐</h1><p id="5c8d" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">在第一部分中，我们计算训练集的拟合，只搜索最佳参数组合。最好的模型达到了高于0.9的精度，但是在我们的测试数据上具有低召回率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/09a1d62d45597a44d81bc613ee046e6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RDDTG82S88Xga0FRaKQC0g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试数据上的性能(图片由作者提供)</p></figure><p id="afba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看是否能做得更好。</p><h1 id="a8ea" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">参数调整+功能选择</h1><p id="ed8b" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">通常，引入特征选择是为了从原始数据集中去除有噪声的预测值。在搜索最佳参数集时，我们使用递归特征消除(RFE)。换句话说，对于每个参数配置，我们在初始训练数据上迭代RFE。可以通过配置适当的拟合参数来加速该过程，例如提前停止，或者在删除较差特征的同时设置较大的步长。存储在验证集上具有最佳分数的管道，并准备在推断时使用。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/535e14d9e36b058c7a1cd356d777432f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fh6So4T4-xqi-i86HzU_AA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试数据上的性能(图片由作者提供)</p></figure><p id="ab25" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，我们总体上有所提高，但召回率和F1得分仍然较低。</p><h1 id="8e7b" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">SHAP参数调整+功能选择</h1><p id="5638" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">最后，我们重新提出和以前一样的程序，但是用SHAP代替RFE。当与基于树的模型结合使用时，SHAP非常有效。它使用一种<em class="mj">树路径</em>方法来跟踪这些树，并提取沿着每片叶子向下的训练样本的数量，以提供背景计算。它也不容易过于自信，因为我们可以在验证集而不是在训练数据上计算重要性(像经典的基于树的重要性)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/e651bc68c33401dff72755ce4d8e113e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0e7pN46TQM-0Gqrfw8tIQw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试数据上的性能(图片由作者提供)</p></figure><p id="1e49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们在召回率和F1分数方面取得了巨大进步。SHAP能够排出低质量的分类特征，只保留最佳预测值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/1d663654bb2413f7a65bf8b91b893e82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P1QAsEVWYg1cfqxu8SOvxg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试数据上的性能对比(图片由作者提供)</p></figure><h1 id="2e4f" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">摘要</h1><p id="6ab1" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">在这篇文章中，我们介绍了<a class="ae ky" href="https://github.com/cerlymarco/shap-hypetune" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> shap-hypetune </strong> </a>，<strong class="lb iu"> </strong>作为一个有用的框架，用于对梯度增强模型进行参数调整和最佳特征搜索。我们展示了一个应用程序，其中我们使用了网格搜索和递归特征消除，但随机搜索和Boruta也是其他可用的选项。我们还看到了在经典特征重要性方法缺乏性能的情况下，如何使用SHAP幂来改进选择过程。</p><p id="48a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">如果你对题目感兴趣，我建议:</strong></p><ul class=""><li id="e9c1" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/boruta-and-shap-for-better-feature-selection-20ea97595f4a"> <strong class="lb iu">博鲁塔和SHAP进行更好的特征选择</strong> </a></li><li id="75f0" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/recursive-feature-selection-addition-or-elimination-755e5d86a791"> <strong class="lb iu">递归特征选择:增加还是消除？</strong> </a></li><li id="28e2" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/boruta-shap-for-temporal-feature-selection-96a7840c7713"> <strong class="lb iu">博鲁塔SHAP进行时态特征选择</strong> </a></li><li id="a0e2" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/shap-for-drift-detection-effective-data-shift-monitoring-c7fb9590adb0"> <strong class="lb iu">漂移检测SHAP:有效数据漂移监控</strong> </a></li></ul></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><p id="96b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/cerlymarco/MEDIUM_NoteBook" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">查看我的GITHUB回购</strong> </a></p><p id="47d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保持联系:<a class="ae ky" href="https://www.linkedin.com/in/marco-cerliani-b0bba714b/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a></p></div></div>    
</body>
</html>