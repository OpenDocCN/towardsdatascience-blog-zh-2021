<html>
<head>
<title>Can Machines Dream?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器会做梦吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/can-machines-dream-2fdf7afa7fdb?source=collection_archive---------30-----------------------#2021-09-15">https://towardsdatascience.com/can-machines-dream-2fdf7afa7fdb?source=collection_archive---------30-----------------------#2021-09-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/849b361d0b43b18fb66b47fd200d378d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*89pUkVdjX8vCsAky"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">Jr Korpa 在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="a755" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">围绕风格转移的理论和概念的描述和实现(以几个例子为特色)。</h2></div><p id="9a76" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">查看我的</em> <a class="ae jd" href="https://github.com/jamie-mcg/deep_dreams" rel="noopener ugc nofollow" target="_blank"> <em class="lr"> GitHub </em> </a> <em class="lr">的工作风格转移代码库。</em></p><p id="a2bd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一个你肯定没想过要问的问题。当然，除非你和一个朋友在凌晨4点刚刚看完iRobot。</p><p id="4220" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，我们现在……在一个机器在做梦的世界里……有点。</p><p id="b4ef" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">好消息是你不需要担心。虽然这些算法的输出可能非常怪异(我鼓励你谷歌搜索“深度梦境”)。它们完全依赖于输入，这是机器学习的准则。</p><p id="f6bd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">所以我们不会做任何邪恶的梦，除非我们一开始就给它灌输一些非常恶心的东西。</p><p id="63d2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们用来描述这种行为的术语是神经风格转移[1]。</p><p id="528a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">它包括给神经网络一个内容图像和一个样式图像。然后要求它以样式图像的样式重建内容图像。</p><h2 id="435d" class="ls lt jg bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">动机</h2><p id="21c9" class="pw-post-body-paragraph kv kw jg kx b ky ml kh la lb mm kk ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">我发现任何深度学习概念的一个迷人之处是它的生物学根源。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mq"><img src="../Images/d7010a50166e39e853be712ebaff5b54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MyT5ljOWCgW2CuPl"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">照片由<a class="ae jd" href="https://unsplash.com/@v2osk?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> v2osk </a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="404a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了理解神经风格转移如何工作，我们需要理解卷积神经网络(CNN)如何工作。为了理解CNN，我们需要了解我们自己的视觉皮层是如何工作的。</p><p id="77db" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这听起来像是一项巨大的工作，但老实说，理解起来超级简单。还有很多听起来很聪明很酷的词，这样你就能给最好的人留下深刻印象！</p><h2 id="0695" class="ls lt jg bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">眼睛和大脑</h2><p id="ffd2" class="pw-post-body-paragraph kv kw jg kx b ky ml kh la lb mm kk ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">我们的眼睛不可思议，更不可思议的是我们的大脑。我们的大脑是我们意识和潜意识的中心。</p><p id="50a3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你可能已经知道，眼睛通过我们的视觉皮层向大脑提供信息，然后大脑皮层形成我们的视觉。</p><p id="1f33" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">但是真正有趣的是大脑如何建立我们的视觉。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/25c5d15b23ee84fbf10252c8ce33cb26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GuJ-SJWQ5IzqZ2FG"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">Robina Weermeijer 在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="7f6c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有无数的神经元连接着眼睛和我们的视觉皮层。一端是单个细胞(视杆细胞和视锥细胞),每个细胞负责我们视觉的一小部分。而在另一端，我们对世界有一个完全成形的、无缝的(在大多数情况下)视觉感知。</p><p id="87a5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Hubel和Wiesel在20世纪60年代和70年代发现了我们的视觉是如何形成的线索。他们用猫做实验，给猫看一条不同角度的光。当分析V1神经元(连接到初级视觉皮层的神经元)的放电率或激活时。他们发现这种神经元的放电频率和光条的旋转之间存在相关性。</p><p id="0b29" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这是一个如此惊人的发现，因为它表明不同的神经元负责从我们从眼睛接收的视觉输入中检测不同的模式。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mw"><img src="../Images/989dd360b5051ea233013a53233a9670.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DnjswWj9TE5kSgE_PtD33A.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图1:大脑的视觉输入图。</p></figure><p id="56d7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">图1显示了我试图解释的内容的一个粗略的手绘示意图。这里我们有4个不同的神经元连接到大脑，每个神经元对一条线的特定方向做出反应。</p><p id="1f09" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我们继续之前，让我们把一些机器学习术语放入其中……神经元发现的这些非常简单的特征就是我们所说的，<em class="lr">低级</em>特征。与更复杂的<em class="lr">高级</em>功能相反。</p><p id="0d91" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">所以我们有一些低级的特征，这些特征是我们所看到的一切的基本组成部分。你可以想象有数百万个这样的特征。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mx"><img src="../Images/6434e4c0883be3d452047cc8ad3c6217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3UAQpmnGb3ifTq9q"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">照片由<a class="ae jd" href="https://unsplash.com/@xavi_cabrera?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">哈维·卡夫雷拉</a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="bca4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这有点像当你打开一个新的乐高玩具时，你有上百万种不同类型的砖块可以玩，并放在一起，以构建高水平的功能。</p><p id="49b9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这正是我们的大脑所做的。这些神经元连接到更多的神经元，这些神经元已经学会识别从其输入建立的特征，如图2所示。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi my"><img src="../Images/827495da6754ca5423394e9bd847e65e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SJYMJ4hFYNUVZ__62woUtQ.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图2:显示构建更高级特征的两层神经元的图。</p></figure><p id="36f0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">图2向我们展示了一个非常简单的例子，展示了我们可以利用低级特征构建的一些结构。</p><p id="316d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">就我们的乐高套装而言，我们正在组装第一对积木，并想象我们可以建造什么！</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mz"><img src="../Images/a8c07253153afe825c5259b3f1b84e76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XOeFeVHIj1XObruWgdAKag.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图3:显示简单的房子或船如何被视觉通路中的高级神经元识别的图。</p></figure><p id="9c32" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">更进一步，我们可以看到每一层新的神经元是如何构建更复杂的(或更高级别的)结构的。</p><p id="c92f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里我们有几张相当不错的房子和船的画。这是我们的三级视觉通道现在能够识别的。</p><p id="a64d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，当大脑通过这两个神经元接收到一个脉冲(或动作电位)时，这意味着在我们的视觉感知中，有一所房子<em class="lr">和一艘船</em>。或者如果这只是一个冲动，那么它要么是一栋房子<em class="lr">或</em>一艘船取决于哪一个，你明白了吗？</p><p id="7c4e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">随着每一个新的层次，我们允许我们的大脑开始构建我们的完整视觉。或者完成我们的千年猎鹰乐高套装，如果我们回到乐高类比。</p><h2 id="dcba" class="ls lt jg bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">从眼睛到…CNN？</h2><p id="b8e9" class="pw-post-body-paragraph kv kw jg kx b ky ml kh la lb mm kk ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">是的，这里还有更多好消息！</p><p id="db57" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你看了最后一部分(希望你看了)，那么你已经知道CNN是如何工作的了！</p><p id="fc77" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">回过头来看一下图3…我们需要做的就是给这个图添加一些数学符号，并将其重新构建为机器学习和viola中的神经网络！</p><p id="b496" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">CNN的来龙去脉是一些广泛研究的主题，我们不会在这里深入探讨。但是有几篇优秀的媒体文章和发表的论文围绕这个主题，所以如果你感兴趣，我鼓励你四处搜索。</p><p id="ccae" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于本文，您只需要知道CNN通常由几个卷积层组成，这些卷积层负责构建我们上面探讨的更高级的功能。然后通常是一些<em class="lr">池</em>层，用来缩小图像的尺寸，迫使CNN寻找更高层次的特征。</p><h2 id="f150" class="ls lt jg bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">图像的风格和内容</h2><p id="e719" class="pw-post-body-paragraph kv kw jg kx b ky ml kh la lb mm kk ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">再看图3，你认为内容和风格存在于这个非常基本的神经网络中的什么地方？</p><p id="1d22" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里要考虑的更明显的是内容，因为像房子和船这样的高级特征最有可能代表图像的内容。而不是一行或一些非常低级的细节。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi na"><img src="../Images/5d9179f56e11ad8f2dcc8d3100b2361b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1zSDf2DiD5tqio5R"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">照片由<a class="ae jd" href="https://unsplash.com/@steve_j?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">斯蒂夫·约翰森</a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="cc25" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">另一方面，让我们想想图像的风格是什么…想象一下我刚刚画了一幅绝对的杰作，就像这里看到的一样…</p><p id="8bb8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这幅图像风格的一大贡献者是笔触。</p><p id="fd1e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">笔画可以是图像的大特征，然而与图像的内容相比，它们是相对低级的特征。</p><p id="f500" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此我们可以想象图像的更多的<em class="lr">样式表示</em>将位于图3的左侧。或者CNN中每个卷积层的较低层。</p><p id="be7f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在让我们来看看一个实际的CNN架构。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/3e6edacce9c4bb1ad9f0d72bb49d2d7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*U6_b8aNUtOgdkRlP3b9Vpg.jpeg"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图4:来自[2]的VGG-19架构。</p></figure><p id="cd49" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">图4显示了在[3]中开发的著名的VGG-19模型的架构。输入从左边输入，输出在右边反馈给我们。在中间，我们所有的神经元结合在一起识别低级到高级的特征。</p><p id="ddc4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在每个卷积层(图4中的绿色阴影)，我们重复前面描述的过程。在卷积层的第一维(低级)中搜索简单特征，直到卷积层的最后一维(高级)中的更复杂特征。然后，我们有一个最大池层，减少了图像的大小，我们再次重复这一过程。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nc"><img src="../Images/aeed5d1ef90bc9b22b4076bd43e22562.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RHSireCHShApH48G"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">照片由<a class="ae jd" href="https://unsplash.com/@siora18?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Siora摄影</a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="17e5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这些最大池层是非常重要的，因为当他们减少了图像的大小，我们失去了图像的细节。因此，在每一步中，我们自然会看到更大的特征。</p><p id="33ee" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这些最大池层是非常重要的，因为当他们减少了图像的大小，我们失去了图像的细节。因此，在每一步中，我们自然会看到更大的特征。</p><p id="2b34" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们还注意到，每个卷积层的深度从左向右增加。这是因为我们在更大的尺度上发现了更复杂的特征，这些特征对图像内容来说比在较低的级别上更重要。例如，一个真正复杂的笔触或铅笔标记没有画出的整体形状重要。</p><p id="41cf" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">很明显，每个图像都是不同的，所以不容易定义一个特定的层，每个层都是不同的，也不容易在CNN中定义一个特定的点来最好地定义图像的内容。然而，作为一个经验法则，我们通常不期望内容在非常小的范围内，或者在非常大的范围内。介于两者之间通常是一个很好的起点。</p><p id="daaa" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">关于风格，这可以在任何尺度上表现出来，因此在每个卷积层进行一些加权是一个好主意。然而，正如我们有希望证明的那样，在卷积层开始变得更加复杂和更加基于内容的表示之前，尽早在卷积层中选择样式层也是一个好主意。</p><h2 id="f53e" class="ls lt jg bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">生成图像</h2><p id="eb27" class="pw-post-body-paragraph kv kw jg kx b ky ml kh la lb mm kk ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">为了生成图像，我们必须首先选择包含我们的内容和风格的图层。我们将选择我们的:</p><pre class="mr ms mt mu gt nd ne nf ng aw nh bi"><span id="a1a2" class="ls lt jg ne b gy ni nj l nk nl">content = "conv4_2"</span><span id="e495" class="ls lt jg ne b gy nm nj l nk nl">style = {<br/>        "conv1_1": 1.0,<br/>        "conv2_1": 0.75,<br/>        "conv3_1": 0.2,<br/>        "conv4_1": 0.2,<br/>        "conv5_1": 0.2<br/>    }</span></pre><p id="60fd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">注意，这些对应于图4中的标记。</em></p><p id="b083" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">与样式层相关的数字是我们希望赋予每一层的权重。所以我们希望风格更多地由最底层的<code class="fe nn no np ne b">conv1_1</code>层决定，而不是其他层。但是同样，这是可以根据您的输入和偏好来玩的东西。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/d1e5d94deb7e115fd6c0251e99980d5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0WBtFvACNUvJCq_Z"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">由<a class="ae jd" href="https://unsplash.com/@clemhlrdt?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">克莱门特·赫拉尔多</a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="aaa2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，我们将把我们的内容和风格图像分别传入我们的CNN。当我们这样做时，我们可以找到内容层<code class="fe nn no np ne b">conv4_2</code>的<em class="lr">基本表示</em>，以及分别用于内容和样式图像的每个样式层。</p><p id="b2b9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在我们有目标了！</p><p id="6d31" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">基本上，我们希望有一个通过CNN的图像，并再现我们在通过样式图像时为我们选择的样式层找到的相同样式表示。然后，当通过内容图像时，我们为我们选择的内容层找到了相同的内容表示。</p><p id="a24e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这就是乐趣的开始…</p><p id="e76c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，我们需要一个形象的起点。由于我们最有可能尝试制作一个看起来更像我们的内容图像但风格不同的最终产品，我们将继续为我们的初始输入制作一个内容图像的副本。</p><p id="9db9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这一点上，我们稍微偏离了你可能习惯的通常的机器学习设置。我们实际上不是在训练模型，我们实际上是在训练图像。</p><p id="5ad7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，我们没有将反向传播图与CNN的权重联系起来，而是实际上将它与输入图像(单个像素)的权重联系起来。</p><p id="5e99" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这样，当我们发现从输入图像中找到的所选特征和我们之前准备的基本特征之间的内容和风格损失时。执行反向传播将导致输入图像略有变化，而不是CNN。</p><p id="93bc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">这不是一件容易解释的事情，所以我鼓励你花几分钟时间浏览一下我的</em><a class="ae jd" href="https://github.com/jamie-mcg/deep_dreams/blob/main/code/algorithms/style_transfer.py" rel="noopener ugc nofollow" target="_blank"><em class="lr">GitHub</em></a><em class="lr">上的代码示例，特别是在algorithms/style_transfer.py文件中。</em></p><h2 id="2459" class="ls lt jg bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">我们会失去什么？—更数学一点…</h2><p id="db4c" class="pw-post-body-paragraph kv kw jg kx b ky ml kh la lb mm kk ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">我们现在只需要一个损失函数。</p><p id="aa6f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将从内容损失开始，因为这稍微更容易解释，因为它只是来自具有基本内容图像(C)和新图像(X)的“conv4_2”的特征映射之间的均方误差。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/c32d1afced8b35f4d819bbb08067a028.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*O_11JJzUCHDzjOk7mK8UGw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图5:内容损失方程</p></figure><p id="8d5f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这仅仅是惩罚与内容图像的基本表示中发现的特征的任何偏离。</p><p id="8bad" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在对于图像的风格，我们需要简单介绍一下<em class="lr"> Gram矩阵</em>。这些听起来比它们实际上要复杂得多，所以为了本文的目的，我将简单地把它们描述为<em class="lr">高维点积</em>。</p><p id="ff95" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">直觉告诉我们，对于风格，我们并不真的想要在我们图像的完全相同的地方重新创建完全相同的笔触。我们只是想在整个图像中有一个类似的风格。因此，最好根据样式表示的相似程度来计算损失，就像余弦相似度或点积一样。</p><p id="c774" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当然，我们必须记住，我们使用的是特征地图，它的维度比通常的点积要高。所以我们实际上需要使用一个<em class="lr"> Gram矩阵</em>来封装输入X的风格和基本风格图像s之间的相关性</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/958417845f32baad2185a7321e077778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*WZi060nZfXfBbU_a0ZjaLQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图6:风格损失方程。</p></figure><p id="a692" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">图6显示了封装到一个公式中的内容。其中每个选择的样式层的gram矩阵的MSE损失乘以它们的权重(在上面的代码块中定义),然后求和。</p><p id="244b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后我们得到一个总损失函数，</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/debf07fb40bfe9054e5bd34594367a98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*ikYrXJOkm_0E9RK4-9VMyw.png"/></div></figure><p id="5042" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其特征在于α和β超参数乘以损耗。这些决定了风格在最终图像中的应用程度，留给我们自己去定义。</p><h2 id="be3a" class="ls lt jg bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">摘要</h2><p id="79eb" class="pw-post-body-paragraph kv kw jg kx b ky ml kh la lb mm kk ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">一旦我们具备了所有这些特征，我们就可以开始训练了，结果令人难以置信！</p><p id="4a6d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里有几个空间主题的例子…</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nt"><img src="../Images/f7af688b3023f5b65e8fe403ed9ab39d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yPTmOUA6ghIDFpw5PwEugg.png"/></div></div></figure><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nu"><img src="../Images/1336163ae39605dcb69d9e591104cb77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j8mxgBoIQ_wPWf4a3JoYuA.png"/></div></div></figure><p id="9b29" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你想尝试一下，<a class="ae jd" href="https://github.com/jamie-mcg/deep_dreams" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上的代码应该很容易使用。只需将您自己的图像添加到content and style文件夹中，然后使用新文件名运行代码。</p><p id="b630" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一如既往，让我知道任何问题或意见！</p><h2 id="4333" class="ls lt jg bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">参考</h2><p id="8528" class="pw-post-body-paragraph kv kw jg kx b ky ml kh la lb mm kk ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">[1] — L. A. Gatys，A. S. Ecker和M. Bethge，<a class="ae jd" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank">一种艺术风格的神经算法</a>，(2015)</p><p id="cc76" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[2] — D. H. Hubel和T. N. Wiesel，<a class="ae jd" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1359523/" rel="noopener ugc nofollow" target="_blank">猫视觉皮层的感受野、双眼互动和功能结构</a>，(1962)</p><p id="b7f3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[3] — K. Simonyan，A. Zisserman，<a class="ae jd" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank">用于大规模图像识别的甚深卷积网络</a>，(2015)</p></div></div>    
</body>
</html>