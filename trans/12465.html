<html>
<head>
<title>Parallel XGBoost with Dask in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Python 中的 Dask 并行 XGBoost</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/parallel-xgboost-with-dask-in-python-11f7ed004dd3?source=collection_archive---------29-----------------------#2021-12-20">https://towardsdatascience.com/parallel-xgboost-with-dask-in-python-11f7ed004dd3?source=collection_archive---------29-----------------------#2021-12-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bb30" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">扩展到非常大的数据集的机器学习</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/44421179e98c8b5076717af766110764.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ae4vbREflb6_Bjvcvci3RQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由 Billy Hunh 通过 Unsplash.com 提供</p></figure><h1 id="329e" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">TL；博士；医生</h1><p id="f830" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">开箱即用，XGBoost 无法在大于你电脑内存的数据集上进行训练；Python 会抛出一个<code class="fe mm mn mo mp b">MemoryError</code>。本教程将向您展示如何通过利用 Dask 的<strong class="ls iu">分布式</strong><a class="ae mq" href="https://xgboost.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"><strong class="ls iu">XGBoost</strong></a><strong class="ls iu">来超越您的本地机器限制，只需对您现有的代码进行微小的更改。</strong></p><p id="6004" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">具体来说，您将学习如何:</p><ol class=""><li id="f32b" class="mw mx it ls b lt mr lw ms lz my md mz mh na ml nb nc nd ne bi translated">使用<a class="ae mq" href="https://dask.org/" rel="noopener ugc nofollow" target="_blank"> Dask </a>在小型数据集上本地训练分布式 XGBoost 模型，</li><li id="32f4" class="mw mx it ls b lt nf lw ng lz nh md ni mh nj ml nb nc nd ne bi translated">使用 Dask 和<a class="ae mq" href="https://coiled.io/" rel="noopener ugc nofollow" target="_blank"> Coiled </a>将您的分布式 XGBoost 模型扩展到云，以在大于内存的数据集上进行训练，</li><li id="cef5" class="mw mx it ls b lt nf lw ng lz nh md ni mh nj ml nb nc nd ne bi translated">借助 Dask 核心团队的专业技巧，加快训练速度。</li></ol><p id="6261" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated"><a class="ae mq" href="https://github.com/coiled/coiled-resources/blob/main/xgboost-with-coiled/coiled-xgboost-synthetic-100GB.ipynb" rel="noopener ugc nofollow" target="_blank">这是我们将使用的代码</a>，如果你想直接进入的话。</p><p id="1ec9" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated"><em class="nk">关于代码的问题？</em> <a class="ae mq" href="https://join.slack.com/t/coiled-users/shared_invite/zt-hx1fnr7k-In~Q8ui3XkQfvQon0yN5WQ" rel="noopener ugc nofollow" target="_blank"> <em class="nk">加入盘绕群落的松弛通道</em> </a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/11dde01d873b5c6a02a45e1645608175.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*S9qxEFFvCe-nCh_8"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者创建的图像</p></figure><h1 id="f5ff" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">用<code class="fe mm mn mo mp b">xgb.dask.train()</code>进行平行模型训练</h1><p id="aaa3" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">默认情况下，XGBoost 按顺序训练模型。这对于基本项目来说没什么问题，但是随着数据集和/或 ML 模型的大小增加，您可能需要考虑使用 Dask 在分布式模式下运行 XGBoost，以加快计算速度并减轻本地机器的负担。</p><p id="487f" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">XGBoost 自带原生 Dask 集成，使得并行训练多个模型成为可能。使用分布式 Dask 后端运行 XGBoost 只需要对常规的 XGBoost 代码进行两处修改:</p><ol class=""><li id="7b29" class="mw mx it ls b lt mr lw ms lz my md mz mh na ml nb nc nd ne bi translated">用<code class="fe mm mn mo mp b">dtrain = xgb.dask.DaskDMatrix(X_train, y_train)</code>代替<code class="fe mm mn mo mp b">dtrain = xgb.DMatrix(X_train, y_train)</code>T26</li><li id="9f1e" class="mw mx it ls b lt nf lw ng lz nh md ni mh nj ml nb nc nd ne bi translated">用<code class="fe mm mn mo mp b">xgb.dask.train(client, params, dtrain, ...)</code>替换<code class="fe mm mn mo mp b">xgb.train(params, dtrain, ...)</code> <br/></li></ol><p id="7b71" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">让我们用一个实际的数据集来看看这一点！</p><p id="b32b" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">我们将使用存储在公共亚马逊 S3 桶中的合成 100GB 数据集。你需要一个免费的 Coiled Cloud 帐户来自己运行这个笔记本中的整个示例<a class="ae mq" href="https://github.com/coiled/coiled-resources/blob/main/xgboost-with-coiled/coiled-xgboost.ipynb" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="391f" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated"><em class="nk">免责声明:我在 Coiled 工作，是一名数据科学传播者。</em> <a class="ae mq" href="http://coiled.io/" rel="noopener ugc nofollow" target="_blank"> <em class="nk"> Coiled </em> </a> <em class="nk">由</em><a class="ae mq" href="https://dask.org/" rel="noopener ugc nofollow" target="_blank"><em class="nk">Dask</em></a><em class="nk">的最初作者 Matthew Rocklin 创立，是一个面向分布式计算的开源 Python 库。</em></p><h1 id="d9b4" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">具有本地 Dask 集群的分布式 XGBoost</h1><p id="fa04" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">好了，让我们开始这个分布式派对吧！</p><p id="5b85" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">首先，实例化一个本地版本的 Dask 分布式调度器，它将并行地编排训练你的模型。</p><pre class="kj kk kl km gt nm mp nn no aw np bi"><span id="9cf3" class="nq kz it mp b gy nr ns l nt nu">from dask.distributed import Client, LocalCluster </span><span id="5b6b" class="nq kz it mp b gy nv ns l nt nu"># local dask cluster <br/>cluster = LocalCluster(n_workers=4) <br/>client = Client(cluster) <br/>client</span></pre><p id="1d99" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">由于这是合成数据，我们不会对数据做任何预处理。关于包含预处理的真实世界数据的例子，请看<a class="ae mq" href="https://github.com/coiled/coiled-resources/blob/main/xgboost-with-coiled/coiled-xgboost-arcos-20GB.ipynb" rel="noopener ugc nofollow" target="_blank">这本笔记本</a>，它在 ARCOS 数据集的 20GB 子集上训练 XGBoost。当您完成预处理后，您可以使用 dask-ml 库创建您的训练和测试分割。</p><p id="c63f" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">在本节中，我们将使用<strong class="ls iu"> data_local </strong>，它是整个数据集的子集，只包含前 50 个分区。</p><pre class="kj kk kl km gt nm mp nn no aw np bi"><span id="99e2" class="nq kz it mp b gy nr ns l nt nu">from dask_ml.model_selection import train_test_split </span><span id="e12f" class="nq kz it mp b gy nv ns l nt nu"># Create the train-test split <br/>X, y = data_local.iloc[:, :-1], data_local["target"] <br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    X, y, test_size=0.3, shuffle=True, random_state=2<br/>)</span></pre><p id="3e0d" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">现在您已经准备好开始训练您的 XGBoost 模型了！</p><p id="2aeb" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">让我们在这个例子中使用默认参数。</p><pre class="kj kk kl km gt nm mp nn no aw np bi"><span id="1efd" class="nq kz it mp b gy nr ns l nt nu">import xgboost as xgb <br/># Create the XGBoost DMatrices <br/>dtrain = xgb.dask.DaskDMatrix(client, X_train, y_train) <br/>dtest = xgb.dask.DaskDMatrix(client, X_test, y_test) </span><span id="1dae" class="nq kz it mp b gy nv ns l nt nu"># train the model <br/>output = xgb.dask.train( <br/>    client,<br/>    params,<br/>    dtrain, <br/>    num_boost_round=4, <br/>    evals=[(dtrain, 'train')] <br/>)</span></pre><p id="b5c4" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">然后，您可以使用训练好的模型以及测试分割来进行预测。</p><pre class="kj kk kl km gt nm mp nn no aw np bi"><span id="aebe" class="nq kz it mp b gy nr ns l nt nu"># make predictions <br/>y_pred = xgb.dask.predict(client, output, dtest)</span></pre><p id="8d62" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">如您所见，与常规的 XGBoost 代码相比，没有什么变化。我们只是用了<code class="fe mm mn mo mp b">xgb.dask.DaskDMatrix</code>代替了<code class="fe mm mn mo mp b">xgb.DMatrix</code>，用<code class="fe mm mn mo mp b">xgb.dask.train()</code>代替了<code class="fe mm mn mo mp b">xgb.train()</code>。</p><h1 id="8824" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">使用 Coiled 将 XGBoost 扩展到云</h1><p id="998d" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">现在让我们扩展这个工作流，通过将 XGBoost 扩展到云来处理整个 100GB 的数据集。</p><p id="82e5" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">你需要对我们上面写的代码进行<strong class="ls iu"> 2 修改</strong>:</p><ol class=""><li id="afb7" class="mw mx it ls b lt mr lw ms lz my md mz mh na ml nb nc nd ne bi translated">将 Dask 连接到云中的盘绕式集群，而不是我们的本地 CPU 核心，</li><li id="6ea8" class="mw mx it ls b lt nf lw ng lz nh md ni mh nj ml nb nc nd ne bi translated">使用整个 100GB 数据集，而不是本地子集。</li></ol><p id="1117" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">我们将首先在云中启动一个 Dask 集群，它可以在整个数据集上运行您的管道。要运行本节中的代码，您需要一个 Coiled Cloud 帐户。用你的 Github 证书登录<a class="ae mq" href="http://cloud.coiled.io" rel="noopener ugc nofollow" target="_blank">盘绕云</a>来创建一个。</p><p id="f873" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated"><em class="nk">注意，如果您使用盘绕空闲层，您必须将 n_workers 参数减少到 25，因为该层最多允许 100 个并发内核。</em></p><pre class="kj kk kl km gt nm mp nn no aw np bi"><span id="bd2f" class="nq kz it mp b gy nr ns l nt nu">import coiled </span><span id="9615" class="nq kz it mp b gy nv ns l nt nu">cluster = coiled.Cluster( <br/>    name="xgboost", <br/>    software="coiled-examples/xgboost", <br/>    n_workers=50, <br/>    worker_memory='16Gib', <br/>    shutdown_on_close=False, <br/>)</span></pre><p id="6471" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">最后，让 Dask 在您的盘绕式集群上运行计算。</p><pre class="kj kk kl km gt nm mp nn no aw np bi"><span id="6a29" class="nq kz it mp b gy nr ns l nt nu"># connect Dask to your Coiled cluster <br/>from dask.distributed import Client <br/>client = Client(cluster) </span></pre><p id="742a" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">对于这一部分，请确保使用包含 2750 个分区的整个 dataframe 数据，而不是我们上面使用的仅包含前 10 个分区的<code class="fe mm mn mo mp b">data_local</code>子集。</p><pre class="kj kk kl km gt nm mp nn no aw np bi"><span id="3a09" class="nq kz it mp b gy nr ns l nt nu"># download data from S3 <br/>data = dd.read_parquet( <br/>    "s3://coiled-datasets/synthetic-data/synth-reg-104GB.parquet/", <br/>    compression="lz4", <br/>    storage_options={"anon": True, 'use_ssl': True},<br/>) </span><span id="9669" class="nq kz it mp b gy nv ns l nt nu">data</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/8f075a80552006c2749cda7f927e66c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YamsgQnth30zx4j_"/></div></div></figure><p id="56d7" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">现在，您可以从上面重新运行所有相同的代码。所有的计算都将在云中的集群上运行，而不是在本地机器上。这意味着您将拥有数量级以上的计算能力！</p><pre class="kj kk kl km gt nm mp nn no aw np bi"><span id="ec50" class="nq kz it mp b gy nr ns l nt nu">%%time <br/># train the model <br/>output = xgb.dask.train( <br/>    client, <br/>    params, <br/>    dtrain, <br/>    num_boost_round=5, <br/>    evals=[(dtrain, 'train')] <br/>)</span></pre><p id="ed1f" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated"><code class="fe mm mn mo mp b">CPU times: user 17.5 s, sys: 3.43 s, total: 20.9 s<br/> Wall time: 3min 24s</code></p><p id="362e" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">正如您在 Coiled Cloud 仪表盘中看到的，在云中培训 100GB 数据的 XGBoost 花费了 0.83 美元。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/be25f90a3698671eeba613230ef4375e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cvdTvCMoEXhGujED"/></div></div></figure><p id="c3cf" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">训练完成后，我们可以保存模型并关闭集群，释放资源。如果我们出于某种原因忘记这样做，Coiled 会在 20 分钟不活动后自动关闭集群，以帮助避免不必要的成本。</p><pre class="kj kk kl km gt nm mp nn no aw np bi"><span id="a42b" class="nq kz it mp b gy nr ns l nt nu"># Shut down the cluster <br/>client.cluster.close()</span></pre><h1 id="548f" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">加速 XGBoost 训练的专业技巧</h1><p id="b352" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">最后，我们从 Dask 核心团队收集了一些专业技巧，帮助您加快 XGBoost 训练:</p><ul class=""><li id="a6c0" class="mw mx it ls b lt mr lw ms lz my md mz mh na ml nw nc nd ne bi translated">提升性能的第一件事是增加集群中 Dask workers 的数量。这将加速你的计算。</li><li id="69f4" class="mw mx it ls b lt nf lw ng lz nh md ni mh nj ml nw nc nd ne bi translated">将列重新转换为占用内存较少的数据类型。例如，尽可能将<code class="fe mm mn mo mp b">float64</code>转换成<code class="fe mm mn mo mp b">int16</code>。这将减少数据帧的内存负载，并加快训练速度。</li><li id="2dd4" class="mw mx it ls b lt nf lw ng lz nh md ni mh nj ml nw nc nd ne bi translated">使用 Dask Dashboard 来发现瓶颈，并找出提高代码性能的机会。观看 Dask 的原作者 Matt Rocklin 解释如何充分利用 Dask Dashboard <a class="ae mq" href="https://www.youtube.com/watch?v=N_GqzcuGLCY" rel="noopener ugc nofollow" target="_blank">这里</a>。</li><li id="1741" class="mw mx it ls b lt nf lw ng lz nh md ni mh nj ml nw nc nd ne bi translated">注意非托管内存。阅读 Dask 核心贡献者 Guido Imperiale 的博客，了解如何解决 Dask workers 中的非托管内存问题。</li></ul><div class="nx ny gp gr nz oa"><a href="https://coiled.io/blog/common-dask-mistakes/" rel="noopener  ugc nofollow" target="_blank"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd iu gy z fp of fr fs og fu fw is bi translated">使用 Dask 时要避免的常见错误</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">第一次使用 Dask 可能是一个陡峭的学习曲线。经过多年的建设 Dask 和引导人们通过…</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">coiled.io</p></div></div><div class="oj l"><div class="ok l ol om on oj oo ks oa"/></div></div></a></div><h1 id="54ca" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">Python 摘要中的并行 XGBoost</h1><p id="cd6e" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">让我们回顾一下我们在这篇文章中讨论的内容:</p><ul class=""><li id="43e1" class="mw mx it ls b lt mr lw ms lz my md mz mh na ml nw nc nd ne bi translated">开箱即用，XGBoost 无法在大于内存的数据集上进行训练。</li><li id="2f07" class="mw mx it ls b lt nf lw ng lz nh md ni mh nj ml nw nc nd ne bi translated">将 XGboost 连接到本地 Dask 集群允许您利用机器中的多个内核。</li><li id="3cc7" class="mw mx it ls b lt nf lw ng lz nh md ni mh nj ml nw nc nd ne bi translated">如果这还不够，您可以将 Dask 连接到 Coiled，并在需要时突发到云。</li><li id="16bb" class="mw mx it ls b lt nf lw ng lz nh md ni mh nj ml nw nc nd ne bi translated">您可以通过检查 Dask 仪表板来调整您的分布式 XGBoost 性能。</li></ul><p id="98ba" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">让我知道你是否最终把你的数据集换到了这个笔记本上，并亲自驾驶 XGBoost + Dask。</p><p id="6d86" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated">在 LinkedIn 上关注我<a class="ae mq" href="https://www.linkedin.com/in/richard-pelgrim/" rel="noopener ugc nofollow" target="_blank">，了解定期的数据科学和机器学习更新和黑客攻击。</a></p></div><div class="ab cl op oq hx or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="im in io ip iq"><p id="6ad4" class="pw-post-body-paragraph lq lr it ls b lt mr ju lv lw ms jx ly lz mt mb mc md mu mf mg mh mv mj mk ml im bi translated"><em class="nk">原载于 2021 年 12 月 20 日</em><a class="ae mq" href="https://coiled.io/blog/dask-xgboost-python-example/" rel="noopener ugc nofollow" target="_blank"><em class="nk">https://coiled . io</em></a><em class="nk">。</em></p></div></div>    
</body>
</html>