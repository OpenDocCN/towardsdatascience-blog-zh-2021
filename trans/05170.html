<html>
<head>
<title>Quality &gt; Quantity: Cleaning Noisy Datasets Using Training Dynamics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">质量&gt;数量:使用训练动力学清理噪声数据集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/quality-quantity-cleaning-noisy-datasets-using-training-dynamics-97769b4aaa3f?source=collection_archive---------26-----------------------#2021-05-06">https://towardsdatascience.com/quality-quantity-cleaning-noisy-datasets-using-training-dynamics-97769b4aaa3f?source=collection_archive---------26-----------------------#2021-05-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d356" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">看看最近的一篇论文，它利用一种新的信息源来清理分类数据集:<strong class="ak">训练动态</strong>。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c08cd81e8d367dff3fc1bbe3aa9fbbac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MJVsyzWMWYrZtYY47Dcp5Q.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/@nkalil?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">纳吉布·卡利尔</a>在<a class="ae kv" href="https://unsplash.com/s/photos/filter?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="a34e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有了深度学习的掌舵，我们已经看到了NLP领域中使用的数据量的巨大增长。然而，控制这些数据集的质量成为一项具有挑战性的任务。例如，数据集设计者蜂拥至众包平台，以获得注释任务的帮助。然而，这种不受控制的环境也会降低注释的质量。</p><p id="1d1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<a class="ae kv" href="https://arxiv.org/abs/2009.10795" rel="noopener ugc nofollow" target="_blank">数据集制图</a>论文中，作者提出了一种诊断分类数据集的方法，承诺将数据集的大小减少多达70%，同时保持分布内(ID，在同一数据集的测试分割上)和分布外(OOD)性能！</p><h1 id="1fa0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">资料图</h1><p id="42c2" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">这个想法很简单，非常直观。让我们直接进入(简单的4步)算法。</p><p id="7aa3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">要求:</strong></p><ol class=""><li id="3d7f" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">数据集应该已经针对二元或多类分类任务进行了标注。</li><li id="3e04" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">在该数据集上训练一些时期的神经网络(作者使用至少5个时期来帮助收集所需的统计数据)</li></ol><p id="04e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">步骤:</strong></p><ol class=""><li id="923a" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">训练:开始训练神经网络(使用BCE损失进行二元分类，使用CCE损失进行多类分类)。</li><li id="ac50" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">统计数据收集:跨所有时期，为每个数据样本计算真实标签的<em class="nd">概率(注意:不是预测标签)</em></li><li id="430a" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">最终统计计算:一旦训练结束，对每个数据样本计算<strong class="ky ir">:</strong></li></ol><p id="3a98" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">a.<strong class="ky ir">置信度</strong>:所有时期真实标签的<em class="nd">概率的平均值</em></p><p id="9816" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">b.<strong class="ky ir">可变性</strong>:所有时期真实标签的<em class="nd">概率的标准偏差</em></p><p id="78d1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">c.<strong class="ky ir">正确性</strong>:占<em class="nd"> ' </em>预测标签==真实标签的总时期的比例</p><p id="0e89" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">4.最后，在<strong class="ky ir">数据图</strong>上绘制所有数据样本:一个x-y图，其中(x轴为<strong class="ky ir">可变性</strong>)<strong class="ky ir"/>(y轴为<strong class="ky ir">置信度</strong>)，也可选择(色调为<strong class="ky ir">正确性</strong>)。</p><p id="5f6c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我以推特上的有毒言论数据集为例。在<a class="ae kv" href="https://huggingface.co/roberta-base" rel="noopener ugc nofollow" target="_blank"> roberta-base </a>模型上训练5个时期产生:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/5af45a1022d6286b35abd7bd6680f6ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uq-TwQEaGUyKfrPKJeUegw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">不同标签的不同图(0 =无毒，1 =有毒)。色调彩条:(黄色/浅色=高正确率，紫色/深色=低正确率)(注:图片由作者提供)</p></figure><p id="47b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为健全性检查，该图类似于作者在他们研究的数据集上看到的图。</p><h2 id="6d71" class="nf lt iq bd lu ng nh dn ly ni nj dp mc lf nk nl me lj nm nn mg ln no np mi nq bi translated">应用1:发现错误标记的数据</h2><p id="a9b0" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">现在最酷的部分来了。让我们看看如何使用这些数据图在数据中找到错误标记的样本。</p><p id="efd0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面生成的数据图中，位于“难以学习”区域的样本是被分配了属于其标签的低概率的样本(<strong class="ky ir">低置信度</strong>)，并且模型也从未对此不确定(<strong class="ky ir">低可变性</strong>)！模型字面意思是告诉我们这些样品贴错标签了！</p><p id="4ba3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在手动检查示例数据集时，这些样本看起来确实被错误地标记了:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/2d74e97f6ef4286f04f666e222db8ea8.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*7QD1GZ55_v8MJr6Q69W_rA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">标签位于“难学”区域的样本。“有毒”的看似无毒，标着“无毒”的本质上明显是性别歧视(/有毒)。(注:图片由作者提供)</p></figure><h2 id="7a95" class="nf lt iq bd lu ng nh dn ly ni nj dp mc lf nk nl me lj nm nn mg ln no np mi nq bi translated">应用2:减少数据集大小</h2><p id="c6a8" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">作者已经表明，仅在来自“模糊”区域的总训练数据的33%上的训练模型产生了相等(甚至更好)的ID和OOD总体性能。考虑到数据量的巨大减少，这一发现意义重大。</p><h2 id="6f6c" class="nf lt iq bd lu ng nh dn ly ni nj dp mc lf nk nl me lj nm nn mg ln no np mi nq bi translated">应用3:发现意外偏差</h2><p id="0cc0" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">对于“易于学习”区域中的样本，模型具有<strong class="ky ir">高置信度</strong>和<strong class="ky ir">低可变性</strong>。由于移除这些样本(仅保留“不明确的”样本)不会影响模型的性能，因此可以肯定的是，这些样本包含某些不需要的属性，这些属性会降低模型的可推广性，例如，非预期的偏差。</p><h2 id="2d4c" class="nf lt iq bd lu ng nh dn ly ni nj dp mc lf nk nl me lj nm nn mg ln no np mi nq bi translated">密码</h2><p id="5241" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">查看我的GitHub项目,该项目将该算法实现为PyTorch Lightning⚡️回调。它超级容易使用，更多关于该项目的信息自述！</p><p id="8ae2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您也可以查看这个项目以找到TensorFlow回调实现。</p><h1 id="85e2" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="3816" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">通过使用统计方法的样本过滤或注释校正，数据集去噪是一个流行的概念。然而,<a class="ae kv" href="https://arxiv.org/abs/2009.10795" rel="noopener ugc nofollow" target="_blank">数据集制图</a>论文从利用训练动态的有趣角度来处理这个问题。它有一点开销:在完整的数据集上训练一个模型<em class="nd">一次</em>，但我认为与它提供的简洁应用程序相比，这并不算过分。此外，引入一种新的媒介(训练动力学)为同一方向的进一步研究打开了大门。</p><h1 id="9104" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><p id="d45f" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">论文讨论:数据集制图:利用训练动力学绘制和诊断数据集，Swayamdipta等人，2020年</p><p id="afad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用的示例数据集:可恶的符号还是可恶的人？Twitter上仇恨言论检测的预测特征，Waseem等人，2016年</p></div></div>    
</body>
</html>