<html>
<head>
<title>How to Perform Ordinal Regression / Classification in PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在PyTorch中执行有序回归/分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-perform-ordinal-regression-classification-in-pytorch-361a2a095a99?source=collection_archive---------4-----------------------#2021-07-10">https://towardsdatascience.com/how-to-perform-ordinal-regression-classification-in-pytorch-361a2a095a99?source=collection_archive---------4-----------------------#2021-07-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1228" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">订购标签时提高模型性能的一个简单技巧。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/43a1b34a899ba6629035b66b7e3df474.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wZRDPXMCiMdiAAqXck6y6w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由vectorjuice创建的抽象向量—<a class="ae ky" href="http://www.freepik.com" rel="noopener ugc nofollow" target="_blank">www.freepik.com</a></p></figure><p id="bdda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当你有一个多类分类问题，并且这些类是有序的，这就是所谓的“有序回归”问题。一个例子可以是将学生的表现分类为A &gt; B &gt; C &gt; D &gt; E。使用普通分类器解决这类问题的问题是，模型会假设将<em class="lv"> A </em>误分类为<em class="lv"> D </em>的错误与将<em class="lv"> A </em>误分类为<em class="lv"> B </em>的错误一样严重——这显然是不正确的，因为<em class="lv"> A </em>和<em class="lv"> D </em>之间的差异要比它们之间的差异大得多有序回归的另一个名字是<em class="lv">有序分类</em>或者甚至<em class="lv">排序学习；</em>你可能已经猜到了，这些方法让模型知道类的顺序关系，让模型<em class="lv">学习排序</em>，而不是<em class="lv">学习分类</em>。</p><p id="20e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章将展示一个使用自定义损失函数在PyTorch中执行有序回归的简单技巧。虽然我将针对一个特定的问题介绍这个技巧，但是你可以将它应用于任何顺序回归问题和任何其他框架。</p><h2 id="2f17" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">一个序数问题的例子</h2><p id="d807" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">让我们首先找到一个数据集进行测试。我最近写了一篇关于<a class="ae ky" rel="noopener" target="_blank" href="/chemical-predictions-with-3-lines-of-code-c4c6a4ce7378">如何预测化学分子的性质</a>的帖子——通常对于这类问题，预测分子性质是否在给定范围内是很有趣的，例如，我们可能在预测不同分子对于给定任务的效率，我们希望将这种效率分为<em class="lv">高&gt;中&gt;低</em>。</p><div class="mu mv gp gr mw mx"><a rel="noopener follow" target="_blank" href="/chemical-predictions-with-3-lines-of-code-c4c6a4ce7378"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">三行代码的化学预测</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">使用Chemprop &amp; graph神经网络的最新结果</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">towardsdatascience.com</p></div></div><div class="ng l"><div class="nh l ni nj nk ng nl ks mx"/></div></div></a></div><p id="eb89" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了测试，我从<a class="ae ky" href="https://github.com/chemprop/chemprop" rel="noopener ugc nofollow" target="_blank"> GitHub </a>获取了一个“亲脂性”回归数据集，其中包含2100个分子及其相关的亲脂性测量值(在油中的溶解度)。我将数据集转换为多类有序分类问题，目标是将分子分为5类:<em class="lv">最低&lt;低&lt;中&lt;高&lt;最高。</em></p><p id="f563" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是序数问题的数据分布概述:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/276a461f8af4ac408281a8273333ea5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bZrzQybreHG384C5wdFz4Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nn">左)</strong>回归数据集中目标的原始分布。<strong class="bd nn">右)</strong>左边的数据集转换成五个大小相等的顺序标签，对应<em class="no">最低&lt;低&lt;中&lt;高&lt;最高。由作者策划。</em></p></figure><h2 id="6b2c" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">基线模型:正常分类</h2><p id="c651" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">正如我在<a class="ae ky" rel="noopener" target="_blank" href="/chemical-predictions-with-3-lines-of-code-c4c6a4ce7378">上一篇文章</a>中所展示的，很容易为我们的数据集快速训练一个标准分类模型，“标准”，这意味着它是用给定5个定义的类的正常交叉熵损失函数来训练的。作为最初的评估，我将数据集分为50%的训练和50%的测试，并在测试数据集上运行我的评估。结果如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/972e281d0aa55c236689be66a6402bf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*ya6S6ACUoPyayveSW2iC_w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用交叉熵损失训练的模型的混淆矩阵。由作者策划。</p></figure><p id="19ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它的表现不太稳定；它在划分低等级和高等级方面相当不错，但是对于中等等级就不那么好了。</p><h2 id="5b41" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">有序回归模型</h2><p id="16a9" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">现在让我们试着训练一个序数模型；我们使用的技巧是由程等人在2008年介绍的。我们的想法是将每个类转换成以下向量:</p><pre class="kj kk kl km gt nq nr ns nt aw nu bi"><span id="2cd1" class="lw lx it nr b gy nv nw l nx ny">Lowest  -&gt; [1,0,0,0,0]<br/>Low     -&gt; [1,1,0,0,0]<br/>Medium  -&gt; [1,1,1,0,0]<br/>High    -&gt; [1,1,1,1,0]<br/>Highest -&gt; [1,1,1,1,1]</span></pre><p id="0b9c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个简单编码(或类似的变体)的酷之处在于，类之间的差异遵循一个顺序尺度；即<em class="lv">最低</em>与<em class="lv">最高</em>之差大于<em class="lv">最低</em>与<em class="lv">中等</em>之差。</p><p id="9121" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的网络的想法是为每个标签输出一个具有二进制分数的5维向量(例如，最终层上的sigmoid激活函数),并训练它来预测这些独一无二的嵌入。一旦我们对其进行了训练，我们就可以通过对我们的预测应用大于0.5的阈值，并从左到右计数预测中(即代码中)出现了多少个连续的<code class="fe nz oa ob nr b">True</code>值，来将预测转换回目标标签:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">显示如何将预测转换为目标标签的示例代码。作者代码。</p></figure><p id="9795" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了训练网络，我们需要一个合适的损失函数。2008年的论文指出，这可以是二元<em class="lv"> </em>交叉熵损失，也可以是平方误差损失。要了解误差如何随着类间距离的增加而增加，请考虑以下平方误差函数的情况:</p><pre class="kj kk kl km gt nq nr ns nt aw nu bi"><span id="4d6a" class="lw lx it nr b gy nv nw l nx ny">Lowest vs. Lowest: (1-1)²+0+0+0+0 = 0<br/>Lowest vs. Low: (1-1)²+(0–1)²+0+0+0 = 1<br/>Lowest vs. Medium: (1–1)²+(0–1)²+(0–1)²+0+0 = 2<br/>Lowest vs. High: (1–1)²+(0–1)²+(0–1)²+(0–1)²+0 = 3<br/>Lowest vs. Highest: (1–1)²+(0–1)²+(0–1)²+(0–1)²+(0–1)² = 4</span></pre><p id="3114" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">损失函数应该以两个参数作为输入，即<code class="fe nz oa ob nr b">predictions</code>和<code class="fe nz oa ob nr b">targets</code>。在我们的设置中，<code class="fe nz oa ob nr b">predictions</code>数组的输入维数是[batch_size × 5]，而<code class="fe nz oa ob nr b">targets</code>数组只是一个标签id列表。为了执行有序回归，我们需要根据我们之前的编码将<code class="fe nz oa ob nr b">targets</code>列表扩展为<code class="fe nz oa ob nr b">[batch_size, num_labels]</code>张量，并返回预测和扩展目标之间的均方误差损失:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">损失函数的代码，它首先对目标标签进行编码，然后计算MSE。作者代码。</p></figure><p id="c86e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们用这个损失函数重新训练我们的模型，结果是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/3455e18489a6a9c2301c44338116fd27.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*04el-2r1I8bri66ZfzPCaQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用有序损失函数训练的模型的混淆矩阵。由作者策划。</p></figure><p id="ad12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显然，结果看起来比之前的分类运行更“斜”，这表明，事实上，我们更多地惩罚了在序数尺度上偏离几个标签的模型。我们能量化这种方法的效果吗？一种选择是查看标签指数的均方根误差(RMSE ),即我们的预测距离目标大约有多少个类别。在这个测试案例中，分类模型的RMSE是1.06，而顺序模型的是0.93，提高了12%！</p><p id="e5bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是！这只是针对一个数据集的一个随机训练测试分割——为了完整起见，我使用10倍交叉验证(CV)对多个数据集和不同数量的标签进行了量化；这应该让我们更现实地了解这两种方法的优劣。折叠外的结果如下，其中我列出了RMSE误差的%改进:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/e81dab0a87a0135735fb425a3c7fc7ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*2WoItJCGfWlSCWKYBCt64A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">顺序训练代替交叉熵训练对RMSE的改进。每一列都是一个独立的数据集，分为3、5、10或20个标签。</p></figure><p id="ee77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在大多数情况下，我们实现了改进，但是偶尔结果是相反的——性能<em class="lv">随着顺序损失而降低</em>。怎么会这样呢？除了数据集和我们正在建模的内容的根本差异之外，还有一些潜在的因素浮现在脑海中:</p><ul class=""><li id="5611" class="og oh it lb b lc ld lf lg li oi lm oj lq ok lu ol om on oo bi translated"><strong class="lb iu">数据集大小；</strong>如果我们有一个大的数据集，我们可能对每个标签有足够数量的样本来执行正常分类，交叉熵损失可能比有序损失函数表现得更好。为了测试这一点，我们可以运行相同的CV，其中我们只从每个数据集挑选500个分子(明显少于完整的数据集)。结果(如下所示)好得多；但是，对于某些数据集组合，有序损失函数的性能仍然比多类模型差。天下没有免费的午餐，所以这种序数伎俩显然不能保证奏效。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/7d2a979ddc85128d64b4e4bac2958fe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*e8eZVrNAvNDZMCYXGadHuA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在只有500个分子的数据集上，通过顺序训练而不是交叉熵训练来改善RMSE。每一列都是一个独立的数据集，分为3、5、10或20个标签。</p></figure><ul class=""><li id="bca2" class="og oh it lb b lc ld lf lg li oi lm oj lq ok lu ol om on oo bi translated"><strong class="lb iu">排名不一致；</strong>如果我们的顺序预测输出<code class="fe nz oa ob nr b">[0.9, 0.9, 0.49, 0.72, 0.1]</code>会怎么样。从左到右的迭代将导致预测标签为2(因为0.49 &lt; 0.5)，即使正确答案也可能是4(因为0.72 &gt; 0.5)。我发现在任何预测中几乎没有等级不一致，所以这不是性能下降的原因。</li></ul><h2 id="3b7a" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">结束语</h2><p id="f854" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">使用有序目标类时，使用有序损失函数可以快速获得显著的性能提升。然而，没有免费的午餐，我们应该用不同的损失函数训练模型，看看什么对给定的数据集最有效</p><p id="5b4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在2020年，Cao <em class="lv">等人</em>在[2]中发表了一种方法，该方法使用神经网络的共享倒数第二层，对每个二进制输出使用单独的偏置单元，以秩一致的方式执行有序回归。他们在这个<a class="ae ky" href="https://github.com/raschka-research-group/coral_pytorch" rel="noopener ugc nofollow" target="_blank"> Github库</a>中发布了他们的<em class="lv"> Coral </em>方法。尽管本帖中提出的问题集中没有等级不一致，但我确实尝试在本帖中执行的CV测试中使用Coral，但这些数据集的性能一直较差。这再次表明，没有免费的午餐，一个人应该总是尝试多种事情。</p></div><div class="ab cl oq or hx os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="im in io ip iq"><p id="3c7d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[1] <a class="ae ky" href="https://ieeexplore.ieee.org/author/37673823700" rel="noopener ugc nofollow" target="_blank">简麟程</a>；<a class="ae ky" href="https://ieeexplore.ieee.org/author/37675519600" rel="noopener ugc nofollow" target="_blank">郑旺</a>；<a class="ae ky" href="https://ieeexplore.ieee.org/author/37694852700" rel="noopener ugc nofollow" target="_blank"> Gianluca Pollastri </a>，有序回归的神经网络方法(2008年)<a class="ae ky" href="https://ieeexplore.ieee.org/xpl/conhome/4625775/proceeding" rel="noopener ugc nofollow" target="_blank"> IEEE国际神经网络联合会议</a></p><p id="2b19" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2]曹，瓦希德米尔贾利利，塞巴斯蒂安拉什卡，秩一致序贯回归神经网络及其在年龄估计中的应用(2020)，<a class="ae ky" href="https://www.sciencedirect.com/science/article/pii/S016786552030413X?via%3Dihub" rel="noopener ugc nofollow" target="_blank">模式识别字母</a>。</p></div></div>    
</body>
</html>