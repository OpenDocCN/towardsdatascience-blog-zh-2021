<html>
<head>
<title>NAACL-HLT 2021: Six Tutorials You Can’t Afford to Miss</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NAACL-HLT 2021:不容错过的六个教程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/naacl-hlt-2021-six-tutorials-you-cant-afford-to-miss-36bfe4908e?source=collection_archive---------43-----------------------#2021-06-01">https://towardsdatascience.com/naacl-hlt-2021-six-tutorials-you-cant-afford-to-miss-36bfe4908e?source=collection_archive---------43-----------------------#2021-06-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="50c6" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">计算语言学协会(NAACL-HLT)北美分会拥有2000名与会者、50多名知名研究员和22%的论文接受率，是一支不可忽视的科学力量。</h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/f7790a80566edd4ed214fe702be9cb5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7XW8YKZSdplDR9z1q1DO5Q.jpeg"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">由<a class="ae kw" href="https://unsplash.com/@manuarr?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Manuel Arroyo </a>在<a class="ae kw" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="20bc" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">自1998年成立以来，NAACL-HLT一直处于当代计算语言学的前沿，促进了全球科学家和专业协会之间的研究和信息交流。今年的NAACL-HLT 定于6月6日至11日在墨西哥城举行。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi lt"><img src="../Images/11eb7c2707f2086004698537d529f12d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gO0Ecbb_C8Lvvx_l99GrBA.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">教程时间表截图。来源:<a class="ae kw" href="https://2021.naacl.org/program/tutorials/#t1" rel="noopener ugc nofollow" target="_blank">https://2021.naacl.org/program/tutorials/#t1</a></p></figure><p id="b947" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">六个备受期待的NLP(自然语言处理)教程已经提上日程，让我们简单看看每一个都提供了什么:</p><h2 id="6602" class="lu lv iq bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated"><strong class="ak">文本排序的预训练变形器:BERT和Beyond </strong></h2><p id="45a6" class="pw-post-body-paragraph kx ky iq kz b la mn jr lc ld mo ju lf lg mp li lj lk mq lm ln lo mr lq lr ls ij bi translated"><strong class="kz ir"> ❓Content.</strong>本教程将概述使用神经网络架构的文本排序，即BERT(来自变压器的双向编码器表示)。排序的目的是从语料库中生成一个有序的文本列表，BERT和自我监督的预训练为NLP提供了许多可能性。具体来说，演讲者将着眼于多阶段和直接文本排名架构，重点是处理长文档的技术，以及解决有效性与效率之间的权衡。</p><p id="1f6b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">💡关键见解。排序问题是信息检索和问题回答的基础。由于基于Transformer的表示在各种NLP任务中表现出令人印象深刻的结果，因此应用<a class="ae kw" href="https://arxiv.org/abs/2010.06467" rel="noopener ugc nofollow" target="_blank">预训练BERT </a>进行排序以及<a class="ae kw" href="https://arxiv.org/abs/2008.09093" rel="noopener ugc nofollow" target="_blank">减少模型参数的数量</a>可能会很有趣。</strong></p><h2 id="aeed" class="lu lv iq bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated"><strong class="ak">深度NLP模型中的细粒度解释和原因分析</strong></h2><p id="92f3" class="pw-post-body-paragraph kx ky iq kz b la mn jr lc ld mo ju lf lg mp li lj lk mq lm ln lo mr lq lr ls ij bi translated"><strong class="kz ir"> ❓Content.</strong>深度神经网络(DNNs)在许多自然语言处理任务中起着至关重要的作用，其中包括机器翻译、问题回答和摘要。在本教程中，演讲者将从两个角度研究如何解释神经网络模型的组件:1 .内在分析(关于期望的语言任务)；第二。因果关系分析(关于模型做出的决策)。我们将讨论模型预测的可解释性以及有助于精细解释的相关工具包。</p><p id="9b81" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">💡关键见解。</strong>dnn学习自然语言现象的隐式表示，这需要付出巨大努力才能在性能分析期间正确解释。该研究领域在<a class="ae kw" href="https://blackboxnlp.github.io" rel="noopener ugc nofollow" target="_blank">black Xbox NLP研讨会</a>系列中进行调查。通过<a class="ae kw" href="https://ojs.aaai.org/index.php/AAAI/article/view/4592" rel="noopener ugc nofollow" target="_blank">分析神经网络中的单个神经元</a>和<a class="ae kw" href="https://www.aclweb.org/anthology/2020.emnlp-main.398.pdf" rel="noopener ugc nofollow" target="_blank">冗余</a>，有可能揭示神经元中各种语言属性的有意义分布。</p><h2 id="6338" class="lu lv iq bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated"><strong class="ak">NLP中的深度学习和图形神经网络</strong></h2><p id="743d" class="pw-post-body-paragraph kx ky iq kz b la mn jr lc ld mo ju lf lg mp li lj lk mq lm ln lo mr lq lr ls ij bi translated"><strong class="kz ir"> ❓Content.</strong>图形神经网络(GNNs)为许多NLP问题提供了受欢迎的解决方案；然而，将原始文本序列数据转换成图结构数据仍然存在一系列障碍。本教程将向您展示如何使用Graph4NLP，一个最近开发的开源库，通过基于GNN的高级模型来克服这些NLP挑战。这种方法有助于在机器翻译、NLG(自然语言生成)和语义分析等领域取得进展。</p><p id="aa44" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">💡关键见解。</strong>最近，图形神经网络受到了机器学习社区的极大关注，而NLP领域则专注于基于转换器的表示。类似于<a class="ae kw" href="http://textgraphs.org" rel="noopener ugc nofollow" target="_blank"> TextGraphs workshop </a>系列，本教程提供了一个不同的观点，通过使用语言图和网络中的结构化信息以及现成的开源库来增强您的模型。</p><h2 id="415c" class="lu lv iq bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated"><strong class="ak">自然语言生成中的自动评估指标</strong></h2><p id="aadc" class="pw-post-body-paragraph kx ky iq kz b la mn jr lc ld mo ju lf lg mp li lj lk mq lm ln lo mr lq lr ls ij bi translated"><strong class="kz ir"> ❓Content.</strong>有了DL(深度学习)，对NLG的研究大大加速；然而，促进DL研究改进的AEMs(自动评估指标)需要调整。在本教程中，演讲者将研究AEMs的演变以及最新的新兴趋势，并试图回答最紧迫的问题，包括:如何将AEMs组织成一个连贯的分类法；现有AEMs的缺点是什么；有什么可能的新的改善途径？</p><p id="ca73" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">💡关键见解。</strong>评估非结构化领域中的对话代理并不简单，因为模型需要与人类的判断相匹配。幸运的是，有像<a class="ae kw" href="https://doi.org/10.1609/aaai.v33i01.33016220" rel="noopener ugc nofollow" target="_blank"> ADEM </a>和<a class="ae kw" href="https://www.aclweb.org/anthology/D18-1429/" rel="noopener ugc nofollow" target="_blank"> AQG </a>这样的方法来处理这个问题。如果你开发了一个对话系统，本教程将为改善对话流程提供可行的见解。</p><h2 id="ed82" class="lu lv iq bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated"><strong class="ak">自然语言处理中的长序列处理</strong></h2><p id="bd0a" class="pw-post-body-paragraph kx ky iq kz b la mn jr lc ld mo ju lf lg mp li lj lk mq lm ln lo mr lq lr ls ij bi translated"><strong class="kz ir"> ❓Content.</strong>处理长序列文档的能力对于许多自然语言处理任务至关重要，其中包括文档分类、摘要、问题回答和共指消解。同时，许多变压器(BERT型)型号对于此目的来说太贵了。在这个带编码练习的实践教程中，演讲者将评估长序列处理和文档级表示学习的分层、基于图和基于检索的方法；概述不同的转换器和内存节省方法；并深入研究该领域正在出现的新研究。</p><p id="f6d5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">💡关键见解。</strong>基于变压器的表示显示了大量NLP基准和下游应用的最新结果。然而，这些模型的训练和推理都很昂贵，考虑其他强有力的信号是有帮助的，如<a class="ae kw" href="https://www.aclweb.org/anthology/D19-1371/" rel="noopener ugc nofollow" target="_blank"> SciBERT </a>、<a class="ae kw" href="https://www.aclweb.org/anthology/2020.acl-main.207/" rel="noopener ugc nofollow" target="_blank"> SPECTER </a>等。</p><h2 id="9445" class="lu lv iq bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated"><strong class="ak">大规模众包自然语言数据</strong></h2><p id="be05" class="pw-post-body-paragraph kx ky iq kz b la mn jr lc ld mo ju lf lg mp li lj lk mq lm ln lo mr lq lr ls ij bi translated"><strong class="kz ir"> ❓Content.</strong>在基于Toloka六年行业经验的本教程中，我们的团队将关注使用公共众包市场的数据标记，重点关注任务设计和分解、质量控制技术和注释者选择。相关的数学背景以及许多有用的行业技巧将被揭示，随后是动手制作任务，在此期间，观众成员将能够在最大的众包平台之一上启动他们的标签收集项目，并相互分享他们的注释想法。</p><p id="a89d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">💡关键见解。</strong>由于机器学习方法需要越来越多的标记数据，我们需要使用大规模产生这种数据的方法。流行的评估数据集，如<a class="ae kw" href="https://rajpurkar.github.io/SQuAD-explorer/" rel="noopener ugc nofollow" target="_blank">小队</a>、<a class="ae kw" href="https://cims.nyu.edu/~sbowman/multinli/" rel="noopener ugc nofollow" target="_blank">多民族</a>和其他已经使用众包建立了——这是一个值得考虑的选择。构建众包管道是一项特殊的技能，需要练习任务分解和质量控制。动手练习给了你提高这一技能的机会。</p></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><p id="064e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">多么棒的一套教程。还有很多东西需要探索。你呢？你对大会最期待的是什么？欢迎在评论中分享一些建议👇</p></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="759e" class="mz lv iq bd lw na nb nc lz nd ne nf mc jw ng jx mf jz nh ka mi kc ni kd ml nj bi translated">参考</h1><p id="a003" class="pw-post-body-paragraph kx ky iq kz b la mn jr lc ld mo ju lf lg mp li lj lk mq lm ln lo mr lq lr ls ij bi translated">[1]文本排名的预训练变形金刚:伯特和超越，林志颖等2020。</p><p id="0dc0" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">[2] PARADE:面向文档重排序的段落表征聚合，李灿佳等，2020 .</p><p id="ccef" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">[3]沙漠中的一粒沙是什么？在深度NLP模型中分析单个神经元，Dalvi等人，2019年。</p><p id="388f" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">[4]分析预训练变压器模型中的冗余，Dalvi等人，2020年。</p><p id="3439" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">[5]图神经网络综述，吴等. 2020 .</p><p id="c6e1" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">[6]重新评估ADEM:更深入地了解对话回应评分，Sai等人，2019年。</p><p id="6a28" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">[7] <a class="ae kw" href="https://www.aclweb.org/anthology/D18-1429.pdf" rel="noopener ugc nofollow" target="_blank">迈向评估问题生成系统的更好指标</a>、<a class="ae kw" href="https://www.aclweb.org/anthology/people/p/preksha-nema/" rel="noopener ugc nofollow" target="_blank"> Nema和</a> <a class="ae kw" href="https://www.aclweb.org/anthology/people/m/mitesh-m-khapra/" rel="noopener ugc nofollow" target="_blank"> Khapra </a> 2018。</p><p id="5f83" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">[8] <a class="ae kw" href="https://www.aclweb.org/anthology/D19-1371.pdf" rel="noopener ugc nofollow" target="_blank"> SciBERT:科学文本的预训练语言模型</a>，Beltagy et al. 2019。</p><p id="6dfe" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">[9] <a class="ae kw" href="https://www.aclweb.org/anthology/2020.acl-main.207.pdf" rel="noopener ugc nofollow" target="_blank"> SPECTER:使用引用通知转换器的文档级表示学习</a>，Cohan等人，2020。</p></div></div>    
</body>
</html>