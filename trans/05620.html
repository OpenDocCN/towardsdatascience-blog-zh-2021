<html>
<head>
<title>Apache Spark: Sharing Fairly between Concurrent Jobs within an Application</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark:在应用程序中的并发作业之间公平共享</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/apache-spark-sharing-fairly-between-concurrent-jobs-d1caba6e77c2?source=collection_archive---------12-----------------------#2021-05-19">https://towardsdatascience.com/apache-spark-sharing-fairly-between-concurrent-jobs-d1caba6e77c2?source=collection_archive---------12-----------------------#2021-05-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="76f6" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">确保在应用程序中的并发作业之间平等分配资源，而不管它们的大小</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/08e00432106a26010e3237321d98df72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_WflkzYYXDp57msUj6qGLw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Krzysztof Maksimiuk 在<a class="ae kv" href="https://unsplash.com/s/photos/jars?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><blockquote class="kw kx ky"><p id="67e9" class="kz la lb lc b ld le jr lf lg lh ju li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">注意:在本帖中，短语“spark job”和“job”用于指代spark操作，如保存、收集、计数等。，短语“并发作业”是指在一个应用程序中同时运行的多个并行spark动作。</p></blockquote><p id="14ff" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">在我的<a class="ae kv" href="https://medium.com/analytics-vidhya/boosting-apache-spark-application-by-running-multiple-parallel-jobs-25d13ee7d2a6" rel="noopener"> <strong class="lc ir"> <em class="lb">上一篇文章</em> </strong> </a>中，我们讨论了通过Scala Futures或Parallel Collections并发运行Spark作业来提升单调的Apache Spark应用程序，这<strong class="lc ir">将应用程序时间减少到了四分之一</strong>。(如果你之前没看过，现在<a class="ae kv" href="https://medium.com/analytics-vidhya/boosting-apache-spark-application-by-running-multiple-parallel-jobs-25d13ee7d2a6" rel="noopener">看</a>就值得了。)</p><p id="153d" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">然而，可能存在这样一种情况，即仅在spark作业级别实现并发性不足以优化应用程序的性能。例如，一个大型作业消耗所有可用的spark资源，并将其他并行作业推入等待状态，直到前者的任务没有利用所有资源。发生这种情况是因为spark在应用程序中的默认调度选项是FIFO(先进先出)，这确保了第一个作业优先获得所有可用的Spark资源，直到其阶段有任务运行。在大多数这样的场景中，我们绝不会希望spark应用程序只被一个长作业卡住，同时，我们希望所有spark作业，无论是短作业还是长作业，都能公平地共享资源。</p><p id="943f" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">为了满足我们的需求，Apache Spark提供了一个完美的解决方案，通过它我们可以将默认的调度选项更改为FAIR，这样任务之间的任务就会以循环方式执行。这意味着所有的工作都获得了同等份额的星火资源。<strong class="lc ir">通过使用公平调度，我将我的应用程序的持续时间减少了27 %,因此，我强烈推荐它用于任何同时运行多个并行spark作业的spark应用程序。</strong></p><blockquote class="kw kx ky"><p id="a81a" class="kz la lb lc b ld le jr lf lg lh ju li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">利用公平调度的先决条件:在Spark应用程序中，多个任务从不同的线程提交。如果你不知道怎么做，请看这里的<a class="ae kv" href="https://medium.com/analytics-vidhya/boosting-apache-spark-application-by-running-multiple-parallel-jobs-25d13ee7d2a6" rel="noopener"/>。</p></blockquote><p id="121c" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">此时，我们准备探索如何在具有并发作业的Spark应用程序中实现公平调度。</p><p id="da6d" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">首先创建“<a class="ae kv" href="https://gist.github.com/hariviapak/06310a6f62fe2b59ea37b8d1cc051726" rel="noopener ugc nofollow" target="_blank"> fairscheduler.xml </a>”，使用您选择的池名和调度模式FAIR。这里，我们需要明确地提到它的调度模式，因为默认情况下，它是每个池的FIFO。你可以在这里了解更多<a class="ae kv" href="https://spark.apache.org/docs/latest/job-scheduling.html#configuring-pool-properties" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lz ma l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://gist.github.com/hariviapak/06310a6f62fe2b59ea37b8d1cc051726" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/hariviapak/06310 a6f 62 fe2b 59 ea 37 b 8 D1 cc 051726</a></p></figure><p id="a89a" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">其次，我们需要配置spark应用程序，以便在创建spark会话或提交Spark应用程序时使用公平调度。</p><p id="9ee3" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">最后，我们需要将"<a class="ae kv" href="https://gist.github.com/hariviapak/06310a6f62fe2b59ea37b8d1cc051726" rel="noopener ugc nofollow" target="_blank"> fairscheduler.xml </a>"中定义的池设置为spark上下文的本地属性。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lz ma l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://gist.github.com/hariviapak/d3ba23ea12082e6f36df124e5f6bea8a" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/hariviapak/d3ba 23 ea 12082 e 6 f 36 df 124 e 5 f 6 bea 8 a</a></p></figure></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="2d50" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lw mr ms mt lx mu mv mw ly mx my mz na bi translated"><strong class="ak">通过Spark UI确认公平调度</strong></h2><p id="1685" class="pw-post-body-paragraph kz la iq lc b ld nb jr lf lg nc ju li lw nd ll lm lx ne lp lq ly nf lt lu lv ij bi translated">确认公平调度是否成功实施是非常重要的，因为在执行上述步骤时稍有差错，就可能使您回到起点。此外，</p><ol class=""><li id="936b" class="ng nh iq lc b ld le lg lh lw ni lx nj ly nk lv nl nm nn no bi translated">仅将"<em class="lb"> spark.scheduler.mode </em>"设置为" FAIR "是不够的，因为任务的阶段仍在调度模式为FIFO的默认池中运行。</li><li id="e073" class="ng nh iq lc b ld np lg nq lw nr lx ns ly nt lv nl nm nn no bi translated">这就是我们用公平调度模式创建自己的池的原因。</li><li id="a1ea" class="ng nh iq lc b ld np lg nq lw nr lx ns ly nt lv nl nm nn no bi translated">并将该池设置为spark context的本地属性。</li></ol><p id="5aec" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">为了确认我们的工作，我们可以使用Spark UI。</p><ol class=""><li id="2d80" class="ng nh iq lc b ld le lg lh lw ni lx nj ly nk lv nl nm nn no bi translated">检查“Jobs”页面，确认调度模式是公平的，但是，如前所述，它不能确保池级别的调度也是公平的。</li><li id="46f0" class="ng nh iq lc b ld np lg nq lw nr lx ns ly nt lv nl nm nn no bi translated">因此，转到“阶段”页面，检查正在运行或已完成阶段的池名称。在我们的例子中，应该是“<em class="lb"> mypool </em>”。</li></ol><p id="8025" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">下面的片段将帮助你更清楚地理解它。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/8e09efb6f637f3b077375343b5c38fc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G7O7X8yosC4mKyIHvO6I7A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Spark UI的工作网页</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/a7a1004b8ee1456aaba3fef982c621f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vcaTUezDz9m-QNsLFSg0DA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Spark UI的Stages网页</p></figure><p id="70fc" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">总之，<em class="lb">公平调度</em>是一个必须具备的特性，如果一个应用程序包含并发运行的大小spark任务。通过这种方式，我们可以在资源利用方面显著提高应用程序的性能，并最终节省成本。</p><p id="0f62" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">我希望，你喜欢这篇文章。我很乐意在评论区听到你的建议或反馈。</p><p id="6480" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated"><strong class="lc ir"> <em class="lb">参考文献</em> </strong></p><ul class=""><li id="75e9" class="ng nh iq lc b ld le lg lh lw ni lx nj ly nk lv nw nm nn no bi translated">Apache Spark官方文档|<a class="ae kv" href="https://spark.apache.org/docs/latest/job-scheduling.html" rel="noopener ugc nofollow" target="_blank">https://spark.apache.org/docs/latest/job-scheduling.html</a></li><li id="e6b5" class="ng nh iq lc b ld np lg nq lw nr lx ns ly nt lv nw nm nn no bi translated"><a class="ae kv" href="https://medium.com/analytics-vidhya/boosting-apache-spark-application-by-running-multiple-parallel-jobs-25d13ee7d2a6" rel="noopener">通过运行多个并行作业提升Apache Spark应用</a>Hari Viapak Garg</li></ul></div></div>    
</body>
</html>