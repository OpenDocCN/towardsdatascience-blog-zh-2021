<html>
<head>
<title>A cautionary tale: multi-stakeholder feedback in AI Ethics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">警示故事:人工智能伦理中的多方利益相关者反馈</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-cautionary-tale-multi-stakeholder-feedback-in-ai-ethics-2ba1a03ef59d?source=collection_archive---------32-----------------------#2021-06-30">https://towardsdatascience.com/a-cautionary-tale-multi-stakeholder-feedback-in-ai-ethics-2ba1a03ef59d?source=collection_archive---------32-----------------------#2021-06-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="a7b2" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/ai-alignment-and-safety" rel="noopener" target="_blank">人工智能校准和安全</a></h2><div class=""/><div class=""><h2 id="1f1c" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">多利益相关者反馈有其固有的缺陷，因此，最好将它们视为建立和维护人工智能道德的“手段之一”，而不是“目的”</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/445fdb57517e99a8a18c170f9c5a01a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7ztsmkIpS5cPVaJEKZYQ4g.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:Freepik |高观多样木质人物包容理念</p></figure><p id="1699" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">设定背景</strong></p><p id="35ce" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">道德是一个公认的信念体系，它指导或控制个人或团体的行为。信念在某些部分代表理性的、真实的、事实的观点，在某些部分代表与当前时间相关的相反观点。公认的信仰可能与从历史中学到的社会哲学、群体认可的道德、社区界定的原则以及有时由负责治理的人制定的规则有关。公认信念的共同主题是支持和赋予人们力量。几个世纪以来，社区、团体、组织和治理结构总是通过多方利益相关者协商和收集不同意见来建立道德规范。全球各地的社会和文化都将道德作为一种生活方式，远远超出了定义“什么是道德的”(建立一个公认的信仰体系)的监管范围。因此，道德(不受任何地域限制)应大于相关监管要求(固有地受地理区域限制)。</p><p id="a63a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">对多利益主体反馈的需求</strong></p><p id="d2db" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">人工智能是一种变革的代理，它赋予人们权力并优化手中资源的效用。任何对人们产生重大影响的变革因素都会带来变革带来的某些副作用。对于人工智能来说，这些副作用包括伤害和歧视等。鉴于这些副作用对人的潜在影响的重要性，有必要建立道德规范。关于谁、如何以及何时应该被授权建立伦理(关于人工智能伦理)的争论正在进行。为了将道德规范扩展到更广的范围，除了法规之外，还需要社会、社区和地区的不同派别的人提供更广泛的投入和包容性参与。因此，多利益相关方的参与、社会对话和多样化的投入被认为是建立“人工智能伦理”的关键因素。</p><p id="29b2" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">信任:这一机制的核心</strong></p><p id="2f17" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">多利益主体和多样化投入(在线和离线)的潜在目的是确保在构建公认的信仰体系时考虑包容性因素。多利益相关方反馈机制旨在固有地信任利益相关方的(1)意图和(2)诚信。这是多利益主体反馈机制最重要的优势和局限性之一。最近的历史表明，由多利益攸关方反馈驱动的社交媒体趋势操纵了政治体系和宗教和谐。</p><p id="2c71" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在确定反馈的利益相关者时，无意的采样偏差可能会产生更多的分裂性反馈，从而放大现有的社会结构。这是因为在现有的社会结构中存在意图冲突(接受的信念的差异)和不均衡的基线(代表性不足或缺乏接触)。社会系统通过提供领土独立(不一定总是地理领土)来处理这些冲突。例如种族)或者为不同的组提供最小或最大的机会限制(例如配额系统)以确保它们的共存，这在人工智能的世界中实际上是困难的。例如，在为AI应用中的选定组建立配额系统时存在实际困难和困境，其中AI应用当前不具有这样的组的标识符。这是一个人工智能应用是否应该在现有的社会歧视基础上扩展的两难问题。</p><p id="a57a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对诚信的信任很难验证。社会系统中的经济机会和不稳定的领土独立有时会诱使利益相关者或利益相关者群体利用对诚信的信任，淡化/转移对公认信仰(伦理)系统的印象。虽然这些剥削迟早会从宿舍里浮出水面，但到那时它已经造成了损害。</p><p id="ac39" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">为什么多利益主体的意见可能有缺陷？</strong></p><p id="0046" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">从商业组织构建人工智能系统的角度来看“道德规范中的多利益相关方投入”将有助于揭示多利益相关方反馈机制中的挑战以及使用该机制时应注意的事项。</p><p id="0059" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><em class="ma"> 1。研究</em>:商业组织的人工智能研究对于构建更好的解决方案，服务于现有和未来的客户群非常重要。这些都是通过与教育机构的研究合作、研究金/实习以及为从事本组织感兴趣的特定主题的社会机构和智囊团提供资金来实现的。这项研究涉及收集多利益相关方的反馈，这些反馈在最近受到质疑，如(1)沉默的反馈——交易忠诚度、激励或更高目的的意识形态,( 2)没有探究研究缺点的反馈——要么是出于选择，要么是由于数据不足或时间不够。</p><p id="62e9" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><em class="ma"> 2。自动反馈:</em>采用自我学习或人类训练学习或两者结合的人工智能应用程序容易出现(1)错误反馈——例如机器人驱动的趋势新闻(2)受影响的反馈——例如分享和评论假新闻(3)非理性反馈——例如关于一个国家应该如何应对恐怖分子的无保留意见或判断或建议。在许多情况下，很难区分授权和/或分裂人们的反馈。这些都是通过各种敌对攻击完成的，包括数据中毒和通过雇佣对手进行的反馈渠道。</p><p id="f3a7" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">3.决策和相关行动:人工智能应用程序可能会根据多方利益相关者的反馈(在线和离线)做出选择或做出权衡。这些选择/权衡可能与对基本事实的理解/印象及其与组织的经济或商业原则的冲突有关。这些反馈可能会受到以下问题的困扰:(1)代表性不独立的反馈——利益冲突;( 2)似乎是一个或多个群体对其他群体的问题的选择性表述——例如，在某些问题上比其他群体更快地寻求反馈;( 3)具有保护商业组织利益的固有观念的反馈;( 4)来自权力和能力不平衡的利益相关方群体的反馈;( 5)当潜在环境发生变化时未达成共识的反馈。</p><p id="3dfa" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">重要的是要理解，并非所有这些都受到构建人工智能系统的商业组织本身的影响，有时它是由(a)利益相关者的经济和社会需求以及(b)谁在迎合这些需求(公司、其竞争对手——如间谍攻击、活动家和/或政治代表等)驱动的。这决定了他们是表达(赞同、反对或虚假)还是保持沉默。</p><p id="cd81" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">结论</strong></p><p id="29d2" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这并不是说多利益相关方反馈机制无效。这是恢复人类对人工智能系统信心的最具包容性的方法之一，然而，重要的是要认识到它们是有缺陷的。揭露这些缺陷的原因是在使用它们时要足够谨慎，并将它们视为建立和维护人工智能道德的“手段之一”，而不是“目的”。</p></div></div>    
</body>
</html>