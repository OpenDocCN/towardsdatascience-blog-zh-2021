<html>
<head>
<title>Seeing Numbers: Bayesian Optimisation of a LightGBM Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">看数字:LightGBM模型的贝叶斯优化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/seeing-numbers-bayesian-optimisation-of-a-lightgbm-model-3642228127b3?source=collection_archive---------9-----------------------#2021-08-05">https://towardsdatascience.com/seeing-numbers-bayesian-optimisation-of-a-lightgbm-model-3642228127b3?source=collection_archive---------9-----------------------#2021-08-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="a0a7" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="0d9d" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">使用贝叶斯优化调整<code class="fe ko kp kq kr b">LightGBM</code>模型的超参数，并与简单特征工程实践的改进进行比较。</h2></div><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ks"><img src="../Images/571c111bf0891b705fa7359f8499f395.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*94ESUUc5ObtNcIY7"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">由<a class="ae li" href="https://unsplash.com/@dtravisphd?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">大卫·特拉维斯</a>在<a class="ae li" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="2c0f" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ls lt lu lv lw lx ly lz ma mb mc md iw bi translated"><strong class="ak">背景</strong></h2><p id="48e5" class="pw-post-body-paragraph me mf iq mg b mh mi ka mj mk ml kd mm ls mn mo mp lw mq mr ms ma mt mu mv mw ij bi translated">在“小心搜索”的经典案例中，阅读了几篇关于模型超参数优化的在线文章后，我的新闻订阅受到了操作指南的狂轰滥炸，这些指南保证通过几个简单的步骤“获得可能的最强大的模型”</p><p id="0839" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">我当然是在夸大其词。</p><p id="5444" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">然而，我确实注意到，很少有文章真正提到超参数调整只是过程的一部分，而不是预测能力的银弹解决方案。更少的文章提到从超参数优化中获得的预测能力是适度的，并且可能比从体面的特征工程中获得的少。</p><h1 id="5024" class="nc lk iq bd ll nd ne nf lo ng nh ni lr kf nj kg lv ki nk kj lz kl nl km md nm bi translated">被砍伐的树木</h1><p id="fdb1" class="pw-post-body-paragraph me mf iq mg b mh mi ka mj mk ml kd mm ls mn mo mp lw mq mr ms ma mt mu mv mw ij bi translated"><code class="fe ko kp kq kr b">LightGBM</code>是一个使用基于树的学习算法的梯度推进框架。这是集合技术的一个例子，它将弱的单个模型结合起来形成一个单一的精确模型。</p><p id="eb1b" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">有各种形式的梯度增强的基于树的模型— <code class="fe ko kp kq kr b">LightGBM</code>和<code class="fe ko kp kq kr b">XGBoost</code>只是流行的例程的两个例子。</p><p id="683d" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated"><code class="fe ko kp kq kr b">LightGBM</code>在速度和内存需求方面具有优势，是我首选的梯度推进模型框架。</p><h1 id="07e3" class="nc lk iq bd ll nd ne nf lo ng nh ni lr kf nj kg lv ki nk kj lz kl nl km md nm bi translated">参数和超参数</h1><p id="4b2c" class="pw-post-body-paragraph me mf iq mg b mh mi ka mj mk ml kd mm ls mn mo mp lw mq mr ms ma mt mu mv mw ij bi translated">当我们谈论调整机器学习模型时，需要做出一个微妙但重要的区别——一个<em class="nn">参数</em>和一个<em class="nn">超参数之间的区别。</em></p><ul class=""><li id="7997" class="no np iq mg b mh mx mk my ls nq lw nr ma ns mw nt nu nv nw bi translated"><strong class="mg ja">参数</strong>是指模型本身计算出的值。</li><li id="0b29" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw nt nu nv nw bi translated"><strong class="mg ja">超参数</strong>是由用户作为输入提供给模型的值。</li></ul><p id="aaad" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">例如，如果我们使用LASSO回归框架，用户将提供正则化惩罚𝜆(超参数),模型将计算回归系数𝛽(参数)等。</p><p id="7933" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated"><code class="fe ko kp kq kr b">LightGBM</code>通过各种超级参数提供大量定制功能。虽然一些超参数有一个建议的“缺省”值，通常可以提供良好的结果，但为手头的任务选择定制的参数可以提高预测精度。</p><p id="4732" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">没有硬性的规则来决定每个任务的最佳模型参数。在大多数情况下，建模者通过使用专家判断和经验或者通过使用某种形式的搜索技术来设置参数。</p><p id="ecc0" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">有许多搜索技术旨在将“最佳”超参数集识别为提供最具预测性模型(由用户或用例定义)的集，理想情况下结合交叉验证以提高严格性。</p><p id="4481" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated"><strong class="mg ja">网格搜索</strong>技术是基本的强力搜索，其中设置每个超参数的可能值，搜索算法全面评估超参数的每个组合。这在时间和计算能力方面都是一种密集的方法，因为搜索空间很快变得很大。</p><p id="bbeb" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">作为基本网格搜索的扩展，<strong class="mg ja">随机网格搜索技术</strong>已经被证明可以提供可靠的结果。该设置类似于基本搜索，因为建模器为每个参数设置搜索空间，然而在每个评估步骤，对于每个参数，算法从搜索空间的边界内(随机地)抽取一个值。</p><p id="b533" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">使用<strong class="mg ja">“智能”搜索技术，</strong>建模者为每个超参数设置一个搜索空间。该算法评估从搜索空间提取的一组参数的性能，并使用结果以迭代的方式通知参数的选择。这样，算法以更有效的方式“锁定”最优解。贝叶斯优化——如下所示——是智能搜索技术的一个例子。</p><h1 id="d528" class="nc lk iq bd ll nd ne nf lo ng nh ni lr kf nj kg lv ki nk kj lz kl nl km md nm bi translated">超参数调谐v特征工程</h1><p id="58fa" class="pw-post-body-paragraph me mf iq mg b mh mi ka mj mk ml kd mm ls mn mo mp lw mq mr ms ma mt mu mv mw ij bi translated">早些时候，我提出了一个未经证实的主张，即超参数调整带来的预测能力的提高可能会被适当的特性工程带来的提高所超越。</p><p id="b0a7" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">不管许多人怎么想(和写)，参数优化在生成高度精确的模型中起着相对较小的作用。参数调整带来的精度增益通常比预期的要小* —我认为2% — 3%的增益是一个不小的成就，因此应该被视为最后的尝试。</p><p id="986f" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">为了获得更大的准确性，建模者应该真正检查他们的模型规格和特征工程过程；更丰富、信息量更大的数据通常会产生更强大的模型。</p><p id="1cb1" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">当我们将超参数调整和特征工程在模型准确性方面的改进与基线准确性度量进行比较时，我们将对这一假设进行测试。</p><p id="2fa1" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated"><em class="nn">*当然，这并不是在所有情况下都是正确的，例如，使用完全不合适的超参数的模型在选择“最佳”超参数后会有显著的改善。</em></p><h1 id="5acf" class="nc lk iq bd ll nd ne nf lo ng nh ni lr kf nj kg lv ki nk kj lz kl nl km md nm bi translated"><strong class="ak">数据</strong></h1><p id="58e5" class="pw-post-body-paragraph me mf iq mg b mh mi ka mj mk ml kd mm ls mn mo mp lw mq mr ms ma mt mu mv mw ij bi translated">我们将使用MNIST数据的子集，这是一个大型手写数字数据库，经常用于计算机视觉基准测试。</p><ul class=""><li id="05a8" class="no np iq mg b mh mx mk my ls nq lw nr ma ns mw nt nu nv nw bi translated">42 000个手写数字中的每一个都被捕捉到一个28×28像素的图像中。</li><li id="1802" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw nt nu nv nw bi translated">每个图像被分解成具有784列的单行，每列代表图像的一个像素。像素值在[0，255]的范围内变化，并指示像素的强度(即像素被“照亮”的程度)。</li><li id="8145" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw nt nu nv nw bi translated">除此之外，我们还有可用于预测的真实标签。</li></ul><p id="bbe0" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated"><em class="nn">完整的MNIST数据库可以在这里找到:</em> <a class="ae li" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST手写数字数据库，Yann LeCun，Corinna Cortes和Chris Burges </a></p><h1 id="1d5d" class="nc lk iq bd ll nd ne nf lo ng nh ni lr kf nj kg lv ki nk kj lz kl nl km md nm bi translated"><strong class="ak">流程</strong></h1><p id="ee11" class="pw-post-body-paragraph me mf iq mg b mh mi ka mj mk ml kd mm ls mn mo mp lw mq mr ms ma mt mu mv mw ij bi translated">让我们开始吧—我们将:</p><ol class=""><li id="aba4" class="no np iq mg b mh mx mk my ls nq lw nr ma ns mw oc nu nv nw bi translated">导入和处理数据。</li><li id="e0a4" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw oc nu nv nw bi translated">为<code class="fe ko kp kq kr b">LightGBM</code>模型构建一个交叉验证过程，并获得交叉验证模型准确性的基线估计。</li><li id="bddb" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw oc nu nv nw bi translated">建立贝叶斯优化过程，设置参数搜索空间并运行优化器。</li><li id="de69" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw oc nu nv nw bi translated">设计一个简单的特征，并评估新特征对模型精度的影响。</li></ol><h1 id="180f" class="nc lk iq bd ll nd ne nf lo ng nh ni lr kf nj kg lv ki nk kj lz kl nl km md nm bi translated">数据导入和处理</h1><h2 id="b739" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ls lt lu lv lw lx ly lz ma mb mc md iw bi translated">数据导入</h2><p id="55b2" class="pw-post-body-paragraph me mf iq mg b mh mi ka mj mk ml kd mm ls mn mo mp lw mq mr ms ma mt mu mv mw ij bi translated">使用<code class="fe ko kp kq kr b">pandas</code>导入数据后，我们可以非常容易地创建交叉验证折叠:</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="f0ae" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">这导致了相当均匀分布的褶皱:</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div class="gh gi of"><img src="../Images/5f23e0eb5983728b1e772bc83b56506e.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*sk_s81AachgysNsxZEwpyg.png"/></div><p class="le lf gj gh gi lg lh bd b be z dk translated">作者图片</p></figure><p id="52c2" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">让我们做一些可视化——首先检查一些我们试图通过从数据中重建图像来预测的例子:</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi og"><img src="../Images/87913e59356b597973593e288fa407c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cv-ufIx109IvYqPW9DFf6Q.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">作者图片</p></figure><p id="8a81" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">…然后检查目标值的总体分布(即数字):</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi og"><img src="../Images/3e7fc7a9651f92019ffa1446913f25df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xYIhaW_IPIMzX_sHy8LoWQ.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">作者图片</p></figure><p id="86d4" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">…最后检查目标在交叉验证折叠中的分布:</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi og"><img src="../Images/5439cfb5dcd88dd3ac4889ace485db9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y9W_or0IYAEqOjGTPlaVjQ.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">作者图片</p></figure><p id="9521" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">上面的分布图和统计数据看起来很有希望:褶皱被均匀地创建，褶皱内目标值的分布看起来与整体目标分布一致。我找不到任何不平衡的问题——咻——所以我会继续努力。</p><h2 id="9d3c" class="lj lk iq bd ll lm ln dn lo lp lq dp lr ls lt lu lv lw lx ly lz ma mb mc md iw bi translated"><strong class="ak">数据处理:缩放和降维</strong></h2><p id="ba70" class="pw-post-body-paragraph me mf iq mg b mh mi ka mj mk ml kd mm ls mn mo mp lw mq mr ms ma mt mu mv mw ij bi translated">我们现在有一个长42 000行、宽784列的数据集。对这么大的数据集执行交叉验证和超参数优化对我可怜的小笔记本电脑来说是相当沉重的负担。</p><p id="d76d" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">因此，我热衷于将数据集压缩成更易于管理的东西。我将首先缩放像素数据，然后执行主成分分析(PCA)来减少列数。</p><p id="4a1a" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated"><code class="fe ko kp kq kr b">sklearn</code>有一个很好的PCA算法实现，我用它将784个特征减少到87个，同时保留了数据中90%的“变化”。</p><h1 id="f92b" class="nc lk iq bd ll nd ne nf lo ng nh ni lr kf nj kg lv ki nk kj lz kl nl km md nm bi translated"><code class="fe ko kp kq kr b">LightGBM</code>的交叉验证功能</h1><p id="4068" class="pw-post-body-paragraph me mf iq mg b mh mi ka mj mk ml kd mm ls mn mo mp lw mq mr ms ma mt mu mv mw ij bi translated">开始交叉验证！</p><p id="2aa7" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">幸运的是，<code class="fe ko kp kq kr b">LightGBM</code>自带交叉验证功能，有助于简化代码:</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="bb9f" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">眼尖的读者会注意到，该函数只接受可用<code class="fe ko kp kq kr b">LightGBM</code>超参数的子集。这是有目的的，因为这些是我们稍后要调优的超参数。</p><p id="e065" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">使用上面的“默认”参数集运行交叉验证，返回95.8%的基线准确性——不算太差！</p><h1 id="59e3" class="nc lk iq bd ll nd ne nf lo ng nh ni lr kf nj kg lv ki nk kj lz kl nl km md nm bi translated">贝叶斯优化</h1><p id="8c90" class="pw-post-body-paragraph me mf iq mg b mh mi ka mj mk ml kd mm ls mn mo mp lw mq mr ms ma mt mu mv mw ij bi translated">我们提到贝叶斯优化是一种超参数调整的“智能”方法。</p><p id="ced3" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">我们将使用Python实现<code class="fe ko kp kq kr b">BayesianOptimization</code>，这是一个基于贝叶斯推理原则的约束全局优化包。</p><p id="d820" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">该软件包试图在尽可能少的迭代中找到“黑箱”函数的最大值，特别适合于需要大量计算和/或时间资源的优化问题。</p><p id="c5e9" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">贝叶斯分析方法非常简单:</p><ol class=""><li id="0997" class="no np iq mg b mh mx mk my ls nq lw nr ma ns mw oc nu nv nw bi translated">收集一个<strong class="mg ja"> <em class="nn">先验</em>假设</strong> —关于过程的初始假设，而不收集或分析任何真实世界的数据。在我们的例子中，我指定的超参数搜索空间是先验的假设。</li><li id="aa70" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw oc nu nv nw bi translated"><strong class="mg ja">通过调查被分析的过程来收集证据</strong>，通常是通过取样或研究现实生活中的事件。“证据”来自使用从搜索空间提取的超参数值的交叉验证的模型准确性。</li><li id="eec7" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw oc nu nv nw bi translated">使用收集的证据，<strong class="mg ja">更新初始假设以形成<em class="nn">后验</em>信念</strong>；从理论上讲，后验应该比前验更见多识广，更准确。我们的后验信念将是一个狭窄的超参数搜索空间。</li></ol><p id="92ff" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">在实践中，步骤2和3将重复多次——有时步骤3通知步骤2——每次迭代创建“最佳”超参数集的更明智的视图。</p><p id="f2cf" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">例如，运行可能类似于1 → 2 → 3 → 2 → 3→ 2 → 3 → <em class="nn">最终参数</em>。</p><p id="24ac" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated"><code class="fe ko kp kq kr b">BayesianOptimization</code>对用户友好，对用户要求相对较少:</p><ul class=""><li id="5b0d" class="no np iq mg b mh mx mk my ls nq lw nr ma ns mw nt nu nv nw bi translated">要最大化的功能的规格。在这种情况下，这是我们交叉验证的精度函数<code class="fe ko kp kq kr b">cross_val</code></li><li id="01b5" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw nt nu nv nw bi translated">超参数搜索空间的规范。</li><li id="dcf8" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw nt nu nv nw bi translated">初始勘探和后续优化数量的说明(即重复上述步骤2和3的次数)。</li></ul><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="od oe l"/></div></figure><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/5aab50f9c16fef1b522331c46291d8d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*CCcrSOB68T5V-9Tq2VrIwA.png"/></div><p class="le lf gj gh gi lg lh bd b be z dk translated">作者图片</p></figure><p id="d1bf" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">上表显示了优化过程的结果。前10次迭代用作初始证据收集，随后是10次更新和优化的迭代步骤。新的精度最大值以紫色突出显示。</p><p id="3e48" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">我们可以看到，在步骤4、16和20中，准确性有所提高。</p><ul class=""><li id="401b" class="no np iq mg b mh mx mk my ls nq lw nr ma ns mw nt nu nv nw bi translated">步骤4中的改进来自纯粹的随机选择——类似于我们从随机网格搜索中获得的成功。</li><li id="97eb" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw nt nu nv nw bi translated">步骤16和20中的改进来自收集证据和更新假设的贝叶斯过程。</li></ul><p id="f13f" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">优化耗时约14.5分钟，并将模型精度从95.8%提高至96.5%。</p><h1 id="ff63" class="nc lk iq bd ll nd ne nf lo ng nh ni lr kf nj kg lv ki nk kj lz kl nl km md nm bi translated">不如换成一个强大的新功能？</h1><p id="9e68" class="pw-post-body-paragraph me mf iq mg b mh mi ka mj mk ml kd mm ls mn mo mp lw mq mr ms ma mt mu mv mw ij bi translated">是时候验证我们的假设了，即特征工程比超参数优化更强大。</p><p id="915c" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">在这里，我们将创建一个相当简单的K-均值聚类。因为这是一个相当著名的技术，我不会花太多时间在理论上，除了说:</p><ul class=""><li id="bb04" class="no np iq mg b mh mx mk my ls nq lw nr ma ns mw nt nu nv nw bi translated">该算法将每一行数据分配给一个集群。</li><li id="4c71" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw nt nu nv nw bi translated">聚类特征应该有助于模型区分数字，因此应该将相似的观察结果组合在一起。可能会有一些事情出错的情况(例如，将一些7分组为1，反之亦然)。因此，我将指定创建10个集群——每个数字0-9(含)对应一个集群。</li><li id="8b25" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw nt nu nv nw bi translated">我们将对折叠内建模和折叠外预测更加严格。</li></ul><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="33d7" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">从这段代码中并不明显，但是执行集群大约需要30秒。</p><p id="c107" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">使用默认参数和通过聚类增强的数据进行交叉验证的准确率现在为96.2%。</p><p id="df33" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated"><strong class="mg ja">所以看起来我错了——超参数调整的性能超过了功能工程！</strong></p><p id="64da" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">嗯，也许不完全是，一旦我们把时间和计算因素考虑进去…</p><ul class=""><li id="e9a7" class="no np iq mg b mh mx mk my ls nq lw nr ma ns mw nt nu nv nw bi translated">超级参数调整使14.5分钟的计算时间增加了0.7个百分点。每分钟的准确率大约提高了0.05个百分点。</li><li id="82c7" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw nt nu nv nw bi translated">功能工程在30秒的计算时间内增加了0.4个百分点。每分钟的准确率大约提高了0.8个百分点。</li></ul><h1 id="40d3" class="nc lk iq bd ll nd ne nf lo ng nh ni lr kf nj kg lv ki nk kj lz kl nl km md nm bi translated">最后的想法</h1><p id="d7e9" class="pw-post-body-paragraph me mf iq mg b mh mi ka mj mk ml kd mm ls mn mo mp lw mq mr ms ma mt mu mv mw ij bi translated">…还有一些漫谈。</p><p id="aedf" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">我们在这张纸条上做了很多！</p><p id="30c3" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">首先，我们介绍了MNIST数据，并了解了<strong class="mg ja">如何以表格形式</strong>表示图像。这有更多的微妙之处，尤其是在处理彩色图像时，但这只是一个开始。</p><p id="18af" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">我们讨论了一些理论，包括<strong class="mg ja">提升树、参数和超参数、超参数优化和特征工程、</strong>和<strong class="mg ja">贝叶斯推理方法以及如何将其应用于超参数优化。</strong></p><p id="ca8e" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">我们<strong class="mg ja">以整洁且可再现的方式手工创建了交叉验证折叠</strong>。我们本可以通过其他方式获得类似的结果，但是这种方法很容易定制<strong class="mg ja"> </strong>，并且可以扩展以确保某些观察总是以相同的方式结束。有用！</p><p id="3cea" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">一些简洁的<strong class="mg ja">可视化</strong>向我们展示了我们试图建模的内容，并允许我们<strong class="mg ja">检查数据不平衡</strong>和<strong class="mg ja">交叉验证折叠创建的适当性</strong>。</p><p id="9d47" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">我们简单地提到了<strong class="mg ja">缩放、</strong>和<strong class="mg ja">主成分分析</strong>让我们大幅减少了建模集的规模。我做PCA的方式有几个问题:</p><ol class=""><li id="dd67" class="no np iq mg b mh mx mk my ls nq lw nr ma ns mw oc nu nv nw bi translated">我将数据缩放到范围[0，1]内；在运行PCA之前，确实应该对其进行归一化(即零均值和单位标准偏差)。</li><li id="71cb" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw oc nu nv nw bi translated">为了提高交叉验证的严格性，PCA组件应该仅在折叠数据上训练。我已经使用了完整的数据集，但是应该将转换构建到一个可以在交叉验证过程中使用的管道中。</li><li id="0651" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw oc nu nv nw bi translated">根据所用的模型和超参数，PCA后可能需要一些额外的缩放。例如，神经网络倾向于对位于特定范围(通常为[0，1])的数据执行更好的操作。如果我们要使用一个带有规范化惩罚的<code class="fe ko kp kq kr b">LightGBM</code>模型，我们将需要再次规范化数据。</li></ol><p id="e37c" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated"><strong class="mg ja">交叉验证</strong>和<strong class="mg ja">贝叶斯优化</strong>功能已经建立——而且非常简单，就像<strong class="mg ja"> K均值聚类</strong>一样。</p><p id="0e60" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">我们看到了在这种情况下，尽管两种方法都提高了模型精度，但<strong class="mg ja">超参数调整在绝对意义上胜过特征工程。</strong>然而，一旦将计算时间考虑在内，我们就会发现<strong class="mg ja">功能工程</strong> <strong class="mg ja">带来了更大的效益。</strong></p><p id="e11e" class="pw-post-body-paragraph me mf iq mg b mh mx ka mj mk my kd mm ls mz mo mp lw na mr ms ma nb mu mv mw ij bi translated">我认为还可以做进一步的改进来提高模型的准确性:</p><ul class=""><li id="0587" class="no np iq mg b mh mx mk my ls nq lw nr ma ns mw nt nu nv nw bi translated"><strong class="mg ja">图像旋转</strong>可以提高模型的概括能力。作为特征工程的一种形式，这将涉及通过稍微旋转像素数据来从现有集合创建“新”观察。该模型将在原始数据和旋转数据的混合上进行训练，并有望对凌乱的作者更加鲁棒。</li><li id="f68d" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw nt nu nv nw bi translated">图像的像素之间可能存在非线性关系——想想“关”和“开”的相邻像素之间的阶跃(或非常快速的)变化。<strong class="mg ja">非线性降维技术——t-SNE或类似技术——在这里可能很有用。</strong></li><li id="6137" class="no np iq mg b mh nx mk ny ls nz lw oa ma ob mw nt nu nv nw bi translated">一个<strong class="mg ja">不同的模型规格可以提高性能:</strong>已经注意到神经网络在计算机视觉任务上工作得很好。</li></ul></div></div>    
</body>
</html>