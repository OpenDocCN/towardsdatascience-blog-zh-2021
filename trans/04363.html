<html>
<head>
<title>Classifying Ships in Satellite Imagery with Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用神经网络对卫星图像中的船舶进行分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/classifying-ships-in-satellite-imagery-with-neural-networks-944024879651?source=collection_archive---------22-----------------------#2021-04-13">https://towardsdatascience.com/classifying-ships-in-satellite-imagery-with-neural-networks-944024879651?source=collection_archive---------22-----------------------#2021-04-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6148" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何从零开始训练CNN的一课</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0443e5a7ba8859583e56c9afb376766d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SGAmMpPQvnwYUOLg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">内特·切尼在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="574c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">没有什么比<a class="ae ky" href="https://www.google.com/maps" rel="noopener ugc nofollow" target="_blank">谷歌地图</a>更能说明卫星图像的无处不在。一项完全免费的服务为任何人提供互联网接入，获取整个地球的卫星图像。虽然谷歌地图是免费的，但也存在其他付费的替代品，它们可以更频繁地为商业用途拍摄地球表面的照片。世界各国政府也将其卫星用于许多国内用途。</p><p id="5cdd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于卫星图像的可用性超过了人类手动浏览它们的能力，因此必须开发一种对它们进行分类的自动化方法。图像分类是计算机视觉中的一个基本问题，神经网络提供了一个有趣的解决方案。</p><h1 id="ffd9" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">对海湾中的船只进行分类</h1><p id="2930" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">卫星图像数据集中的船只包含4000张船只和非船只的注释图像。取自<a class="ae ky" href="https://developers.planet.com/" rel="noopener ugc nofollow" target="_blank">星球API </a>的1000张飞船图像统一为80px x 80px，包含一艘处于不同方位的飞船，但总是在中心附近。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/d90ef1b78a0ad1b3f868f6c15b428cca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*igtD603xYRODzjtRs0HIwg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">取自数据集的示例。CC-BY-SA许可下的所有图像。</p></figure><p id="4e1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在3000幅非船只图像中，大约1000幅描绘了随机特征，如海洋或建筑物，大约1000幅描绘了船只的部分但不完整的图像，最后1000幅描绘了被其他机器学习模型错误标记的图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/cfa11a328a9b4b0bf9936f54d6773584.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CB4uj3uZW30UipZum6jY2g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">取自数据集的示例。CC-BY-SA许可下的所有图像。</p></figure><p id="1208" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">附带的JSON文件包括图像的ID和图像是否包含船只的标记，相应地用1或0表示。此外，它还包含每个图像的实际像素值。</p><p id="4403" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">排列为19，200个整数值，前三分之一包含红色通道中的所有像素值，接下来是绿色通道中的像素值，最后三分之一包含蓝色通道中的像素值。由于像素值是在数据集中明确说明的，实际的图像本身在技术上不需要下载，但它们是一个很好的参考。</p><p id="4a4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了对这些图像进行分类，将训练一个卷积神经网络(CNN)。作为一种人工神经网络，CNN模仿大脑中的神经元，特别是那些用于视觉的神经元。网络中的每个神经元都开发了一个独特的特征图，可以识别图像中的特征。在浅层网络中，要素地图可能会识别垂直线或水平线。但是，随着图层被添加到网络中，要素地图可能会识别更复杂的结构，例如眼睛，或者在本例中是船只。</p><p id="2a63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">存在各种库来编写CNN，但是本教程将使用Keras来介绍TensorFlow。</p><h1 id="0dbc" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">Python中的卷积神经网络</h1><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="6cf1" class="mz lw it mv b gy na nb l nc nd">import tensorflow as tf<br/>import pandas as pd<br/>import numpy as np</span></pre><p id="95c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在训练任何东西之前，使用基本导入。TensorFlow是一个机器学习库，主要关注神经网络。Pandas是一个电子表格类型的库，用于帮助解析数据。最后，NumPy有助于快速有效地处理数字。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="e5d8" class="mz lw it mv b gy na nb l nc nd"># Read the data<br/>df = pd.read_json("shipsnet.json")</span></pre><p id="25e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这一行只是导入JSON文件，并将其作为数据帧读取。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="a3e8" class="mz lw it mv b gy na nb l nc nd"># Normalize and reshape the image data<br/>df["normalized_data"] = df["data"].apply(lambda x: (np.array(x) / 255).reshape(80, 80, 3))</span></pre><p id="fc28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像素值存储在标题为“数据”的数据框的列中事实上，这些像素值还不能被CNN处理。相反，新数据被转换成一个NumPy数组，然后除以255来对值进行规范化。所有19，200个值现在应该是介于0和1之间的某个值。接下来，数据被整形为80 x 80 x 3的矩阵，这样它就被格式化为一张图片。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="175e" class="mz lw it mv b gy na nb l nc nd"># Define X and Y<br/>X = df["normalized_data"]<br/>Y = df["labels"]</span><span id="6aee" class="mz lw it mv b gy ne nb l nc nd"># Split the data into training and testing sets. Use a 75/25 split<br/>from sklearn.model_selection import train_test_split<br/>(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.25, random_state=42)</span></pre><p id="7f3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">定义了X和Y值。y是标题为“标签”的列，包含1和0的数组，以定义图像是否包含船。X是从像素值中提取的归一化图像数据。</p><p id="ff07" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">定义了X和Y后，它们被分成75/25的训练集和测试集。因此，该模型将在3000幅图像上进行训练，并在1000幅其他图像上验证其结果。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="c6f0" class="mz lw it mv b gy na nb l nc nd"># Transform the training and testing data into arrays<br/>X_train = np.array([x for x in X_train])<br/>X_test = np.array([x for x in X_test])<br/>Y_train = np.array([y for y in Y_train])<br/>Y_test = np.array([y for y in Y_test])</span></pre><p id="71b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不幸的是，TensorFlow不接受Pandas系列，因此训练和测试数据被转换为数组。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="3812" class="mz lw it mv b gy na nb l nc nd">from tensorflow.keras import datasets, layers, models<br/>from tensorflow.keras.layers import Activation</span><span id="e165" class="mz lw it mv b gy ne nb l nc nd"># Starts the model with a sequential ANN<br/>model = models.Sequential()</span></pre><p id="d309" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">经过几次导入，真正的CNN已经准备好了。CNN被初始化为一个<a class="ae ky" href="https://keras.io/guides/sequential_model/#:~:text=A%20Sequential%20model%20is%20appropriate,%22layer1%22)%2C%20layers." rel="noopener ugc nofollow" target="_blank">序列模型</a>，它确保每一层接收一个输入和一个输出。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="56c4" class="mz lw it mv b gy na nb l nc nd"># Adds the first convulsion layer and follows up with max pooling<br/>model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(80, 80, 3)))<br/>model.add(layers.MaxPooling2D((2, 2)))</span></pre><p id="13e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">前两层被添加到模型中。第一层是卷积层，其使用“<a class="ae ky" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" rel="noopener ugc nofollow" target="_blank"> ReLu </a>”激活函数，并期望80×80×3的输入张量，即训练图像的精确尺寸。32表示图层输出的维度，而(3，3)表示卷积窗口的大小，在本例中为3px x 3px。</p><p id="9d3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">添加的下一层用于最大池化，其池大小为2 x 2。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="595a" class="mz lw it mv b gy na nb l nc nd"># Add additional hidden layers<br/>model.add(layers.Conv2D(64, (3, 3), activation='relu'))<br/>model.add(layers.MaxPooling2D((2, 2)))<br/>model.add(layers.Conv2D(64, (3, 3), activation='relu'))</span></pre><p id="9ae6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与前面的代码非常相似，这两行代码是网络的附加隐藏层。虽然输出大小发生了变化，但这些层遵循与前两层相同的基本模式。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="3d75" class="mz lw it mv b gy na nb l nc nd"># Flattens the input into a 1D tensor<br/>model.add(layers.Flatten())</span><span id="ac83" class="mz lw it mv b gy ne nb l nc nd"># Makes the input more readable for classification<br/>model.add(layers.Dense(64, activation='relu'))</span><span id="3c58" class="mz lw it mv b gy ne nb l nc nd"># Classifies - ensure the input in the number of classes, indexed<br/># at 0<br/>model.add(layers.Dense(1))</span><span id="06e7" class="mz lw it mv b gy ne nb l nc nd"># Final activation function<br/>model.add(Activation('sigmoid'))</span></pre><p id="1efb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一行简单地将张量展平为一维，这将使处理更容易。下一行，第一个密集层，格式化结果输入。</p><p id="38f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一个密集层与分类有关。因此，传递的唯一参数是类的数量，索引为0。因为在这个例子中有两个类，ship或者not-ship，所以传递1。</p><p id="c144" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，添加一个激活层，告知是否激活神经元。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="1562" class="mz lw it mv b gy na nb l nc nd">model.summary()</span></pre><p id="f14a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在继续下一步之前，花点时间用总结的方法回顾一下模型。输出应该如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/097605511939feb4caf9ba698772afff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wHuXXgZYggjlqvwiI6EWzA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型总结。图由作者制作。</p></figure><p id="ec0e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意每一行是如何描述CNN内置的一个层的，以及它的输出形状和参数数量。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="77e9" class="mz lw it mv b gy na nb l nc nd"># Compile the model<br/># Use binary_crossentropy because there are only 2 classes present<br/>model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])</span></pre><p id="df12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这一行只是编译模型。如果添加图层时存在输入/输出维度问题，程序会在这一步通知您。</p><p id="1cfe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">损失函数采用二元交叉熵，因为该模型仅使用两个类别。使用更多的类将需要一些不同的东西。损失函数的完整列表可在<a class="ae ky" href="https://keras.io/api/losses/" rel="noopener ugc nofollow" target="_blank">这里</a>查看。优化器被当作RMS prop算法，但是其他的也是可用的<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers" rel="noopener ugc nofollow" target="_blank">这里</a>。度量参数只是查看需要优化的内容，在本例中就是准确性。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="a25a" class="mz lw it mv b gy na nb l nc nd"># Train the model<br/>gen_model = model.fit(X_train, Y_train, epochs=10, validation_data=(X_test, Y_test))</span></pre><p id="66a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">终于到了拟合模型的时候了。传递训练和测试数据非常简单。epochs参数本质上是告诉模型要经历多少次迭代。</p><p id="509a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">设定时代的回报边际递减。数字越大，通常精度越高，但是精度的每一次提高都会降低，直到接近数据集能够产生的最大精度。此外，更多的纪元将需要更长的时间来运行。对于这个数据集，10将返回好的结果。</p><p id="dc86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当模型训练时，每个历元的输出如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/cff197272ea80e1f3014658ddb31cd58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8b1CPfhGaiH6AnElme9pkg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">为模型定型的输出。作者制作的图</p></figure><p id="6424" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在返回样本数并给出训练历元的时间后，该行还将返回其自己的训练图像集的模型的损失和准确性，以及其验证集的损失和准确性。</p><p id="a07d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，在第10个时期，该模型在其自己的训练图像上实现了99.27%的准确性，在该模型从未见过的图像上实现了98.5%的准确性。</p><h1 id="c0d1" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">估价</h1><p id="78ba" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在过度庆祝之前，应该对结果进行更深入的分析。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="8dec" class="mz lw it mv b gy na nb l nc nd"># Evaluate the model<br/>from sklearn.metrics import classification_report, confusion_matrix<br/>predictions = model.predict(X_test)<br/>print(classification_report(Y_test, predictions.round()))<br/>print(confusion_matrix(Y_test, predictions.round()))</span></pre><p id="b781" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些行导入一些函数来帮助评估模型的准确性，将模型应用到测试数据，并打印分类报告和混淆矩阵。</p><p id="cfdd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分类报告:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/526c7233a4a9e47ee07de5d63e8aca9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*EpUapgnouBfk9VwDHLQ0BA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型的分类报告。图由作者制作。</p></figure><p id="8706" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">测试数据由1000幅图像组成，其中733幅是非舰船，267幅是舰船。非船舶的精度为99%，略高于船舶的精度97%。本质上，对于所有被模型归类为船只的图像，97%都是真实的船只。该模型能够分别回忆起99%的非船只图像和98%的非船只图像。</p><p id="00f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总的来说，对于一个简单的CNN来说，这些都是很好的结果。</p><p id="d5de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，看看混乱矩阵:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/59d6a78b2fa6f453abb28870e615b710.png" data-original-src="https://miro.medium.com/v2/resize:fit:286/format:webp/1*-3LPeXbwL3LbQM69fPGKsQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型的混淆矩阵。图由作者制作。</p></figure><p id="4736" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在733幅非船只图像中，725幅被正确识别，8幅被误标为船只。这些都是误报。</p><p id="27eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在267张舰船图像中，262张被正确识别，5张被误标为非舰船。这些是假阴性。</p><h1 id="a883" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">保存和加载模型</h1><p id="8998" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">如果每次需要的时候都需要训练，CNN可能不会很有用。在这种情况下，训练时间只需要几分钟，但在更深的具有更多纪元的网络上，训练可能需要几个小时甚至几天。因此，有一个简单的方法可以调用来保存整个模型。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="9979" class="mz lw it mv b gy na nb l nc nd"># Save the model for later use<br/>model.save("ShipCNN.h5")</span></pre><p id="1d02" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">save方法只接受路径名，将其保存为H5文件。</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="d788" class="mz lw it mv b gy na nb l nc nd"># Load a model<br/>new_model = tf.keras.models.load_model("model.h5")</span></pre><p id="6296" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">加载预先保存的文件也相当简单。调用summary方法来检查模型的架构是否符合预期也是一个好主意。</p><h1 id="81a1" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="9793" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">使用卫星图像训练CNN提供了完美的数据集。所有的图像都是同样的大小，在基本相同的角度和距离拍摄，每艘船都保留了俯视图。虽然改变这些参数中的任何一个都会使分类问题变得更加困难，但船只图像展示了神经网络应用于计算机视觉问题的能力。</p><p id="52df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用的CNN相对简单，但仍然只需要几分钟的训练就可以返回很高的准确度。接近人类水平的表现，1000张图像中只有13张被错误标记。虽然应用程序是理想化的，但潜力是显而易见的。</p></div></div>    
</body>
</html>