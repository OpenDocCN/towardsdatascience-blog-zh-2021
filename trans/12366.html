<html>
<head>
<title>Intuition Builder: How to Wrap Your Mind Around Transformer’s Attention Mechanism</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">直觉建造者:如何围绕变形金刚的注意力机制来思考</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-explain-transformer-self-attention-like-i-am-five-9020bf50b764?source=collection_archive---------10-----------------------#2021-12-16">https://towardsdatascience.com/how-to-explain-transformer-self-attention-like-i-am-five-9020bf50b764?source=collection_archive---------10-----------------------#2021-12-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0810" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">变压器注意机制为我们其余的人解释</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ecb3f5e5a35ab758e25dc7ddde08b61e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*uEWzH0tb8QWtsfIB1bc2KA.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">注意力计算—作者创作的动画</p></figure><p id="828b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">目录</strong></p><p id="b576" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae lu" href="#cc44" rel="noopener ugc nofollow">动机</a> <br/> <a class="ae lu" href="#4196" rel="noopener ugc nofollow">基本构建模块:一种叫做‘嵌入’的特殊向量</a> <br/> <a class="ae lu" href="#7a5c" rel="noopener ugc nofollow">核心机制:向量的点积</a> <br/> <a class="ae lu" href="#027b" rel="noopener ugc nofollow">让我们把它应用在更容易的东西上:推荐系统</a> <br/> <a class="ae lu" href="#1606" rel="noopener ugc nofollow">现在我们可以谈谈注意力:YouTube如何找到你搜索的视频(QKV系统)</a> <br/> <a class="ae lu" href="#3d6c" rel="noopener ugc nofollow">翻译中的注意力，这一切都很自然</a> <br/> <a class="ae lu" href="#2706" rel="noopener ugc nofollow">自我关注:发现越复杂</a></p><h1 id="cc44" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">动机</h1><p id="f897" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi ms translated"><span class="l mt mu mv bm mw mx my mz na di">如果</span>你在人工智能行业工作，或者正在学习进入该行业，那么你没有听说过<strong class="la iu"> Transformer </strong>的可能性很小。谷歌用其署名论文<strong class="la iu"> <em class="nb">介绍了它【关注就是你所需要的一切】</em></strong><em class="nb"/><a class="ae lu" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank"><em class="nb">瓦斯瓦尼等人(2017) </em> </a>。它很快在NLP的研究人员中流行起来，人们用<strong class="la iu"> Transformer </strong>重新实现了RNN/LSTM曾经完成的主要NLP论文。基于Transformer的预训练语言模型OpenAI的GPT-3和像<a class="ae lu" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank">拥抱脸</a>这样的工具很快在工业和商业领域获得了牵引力。但并没有就此止步。原来<strong class="la iu"> Transformer </strong>就是这么一个不可思议的架构，除了<em class="nb">自然语言处理之外的问题也能被它解决。</em>视觉、音频、物体检测、强化学习，应有尽有。任何你能做成一个令牌序列的东西，你都可以用<strong class="la iu"> Transformer </strong>解决。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nc nd l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Andrej Karpathy的推文解释了神经网络架构如何融合到变压器中</p></figure><p id="2d4a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，Transformer并不是一个容易理解的架构。这是一个编码器/解码器模型。每个编码器和解码器都有多个子层和组件。其核心是<strong class="la iu">自我关注</strong>机制，不那么容易找到直觉。这是本文试图帮助的。我将使用简单的英语、动画和恰当的类比来解释它是什么，它是如何工作的。希望当你阅读完这篇文章的时候，你会清楚地理解令人生畏的注意力机制。也许在你的下一次聚会上向你的朋友解释🍸。让我们直接跳进来吧！</p></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><h1 id="4196" class="lv lw it bd lx ly nl ma mb mc nm me mf jz nn ka mh kc no kd mj kf np kg ml mm bi translated">基本构件:一个叫做“嵌入”的特殊向量</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/9de4aec82f6ec2fef9b556361f5f7ea8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*T-a_SkSV4hlYuMDY"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae lu" href="https://unsplash.com/@kellysikkema?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Kelly Sikkema </a>在<a class="ae lu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="0264" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi ms translated"><span class="l mt mu mv bm mw mx my mz na di"> C </span>分类数据(输入许多离散类型，如文字、电影、产品等。).我们如何表示它们并将其编号？我们可以使用<a class="ae lu" href="https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">一键编码</a>。当然可以。但是当类别越大越难管理，而且不是很直观。vector [1，0，0，0]和[0，0，0，1]有什么区别？它没有说太多。更好更自然的方式是使用<em class="nb">嵌入</em>。由于每个类别都有一些内在的特征，我们可以用一个低维向量来表示它。例如，我们通常将Marvell的新电影<em class="nb">蜘蛛侠：英雄无归</em>描述为<code class="fe nr ns nt nu b">50%</code>动作、<code class="fe nr ns nt nu b">30%</code>浪漫、<code class="fe nr ns nt nu b">15%</code>剧情、<code class="fe nr ns nt nu b">5%</code>惊险。我们可以很容易地将这种描述转换成一个向量，第一维为'<code class="fe nr ns nt nu b">action</code>、'第二维'<code class="fe nr ns nt nu b">romance</code>、'第三维'<code class="fe nr ns nt nu b">drama</code>'和第四维'<code class="fe nr ns nt nu b">thrilling</code>':</p><pre class="kj kk kl km gt nv nu nw nx aw ny bi"><span id="f140" class="nz lw it nu b gy oa ob l oc od">Spider-Man: No Way Home = [0.5, 0.3, 0.15, 0.05]</span></pre><p id="7cb1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于不会有两部分数相同的电影，所以用向量来表示电影更有意义。这使得通过模型学习变得更容易，更重要的是，更容易解释。嵌入是建模现实世界对象的一种更好的方式。例如，单词嵌入将含义放入向量中，您可以做一些有趣的事情，如:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/975abaa5101b16823ed24276f511afec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/0*Kc5RAgRWWF2o5lEF"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者创作的照片</p></figure><p id="918c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">或者，如果用户共享相似的嵌入，您可以将电影与用户匹配(特征/兴趣匹配)。向高动作评分嵌入用户推荐高动作评分嵌入电影听起来是个好主意。</p></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><h1 id="7a5c" class="lv lw it bd lx ly nl ma mb mc nm me mf jz nn ka mh kc no kd mj kf np kg ml mm bi translated">核心机制:向量的点积</h1><p id="7fe8" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi ms translated">我们已经确定注意力机制是变形金刚<em class="nb">的核心。</em></p><blockquote class="of og oh"><p id="6d42" class="ky kz nb la b lb lc ju ld le lf jx lg oi li lj lk oj lm ln lo ok lq lr ls lt im bi translated">注意力机制的中心是一个简单的数学概念:<em class="it">向量的点积</em>。</p></blockquote><p id="8cf0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于向量的点积相对简单，我不会在这里用解释来烦你，我只想指出它的意思并给出一些直觉，这对于理解<strong class="la iu">注意力</strong>的意思是必不可少的。</p><p id="f8b9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">两个向量之间的点积表示'<strong class="la iu"> <em class="nb">与</em> </strong>的关联程度。一个很好的直觉是它们之间的角度。角度越小，两个矢量指向同一方向越近。参见下面的动画:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1953d9f1f57a6c43426134d0eb51bf4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*uGCRM-OMpEx1uC4vdW2zFQ.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">点积衡量两个向量的“相关”程度</p></figure><p id="3b33" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">直角意味着两个向量不相关。如果角度大于90度，它们是负相关的。</p><p id="fb5e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">将点积直觉应用于嵌入给了我们一种数学上匹配向量的方法。如果我们有产品和客户的嵌入向量，我们如何确定客户是否会喜欢特定的产品？只是在它们的嵌入之间做一个点积！如果我们获得高价值，客户很有可能会喜欢它。不然他不会喜欢的。</p><p id="f870" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们看一个现实生活中的例子，把我们新学到的概念放在一起。</p></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><h1 id="027b" class="lv lw it bd lx ly nl ma mb mc nm me mf jz nn ka mh kc no kd mj kf np kg ml mm bi translated">让我们把它应用到更简单的东西上:推荐系统</h1><p id="dae1" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi ms translated"><span class="l mt mu mv bm mw mx my mz na di"/>推荐系统广泛应用于网飞或YouTube等内容平台，以匹配产品/项目和用户。基本思路是给类似电影的物品一个(<strong class="la iu">特征</strong>)嵌入向量，给用户另一个同维(<strong class="la iu">兴趣</strong>)嵌入向量。如果两个嵌入的点积显著，那么电影的'<strong class="la iu">特征</strong>与用户的'<strong class="la iu">兴趣</strong>一致，用户很可能喜欢这部电影。否则，他可能不会。见下文:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5766bcd35aa7f213ca8524a0434cb938.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4CpOO5LJZ9FSJ-n2opDRUw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用户和电影嵌入的点积</p></figure><p id="01ac" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过计算用户和电影的嵌入矩阵的点积，我们可以获得所有电影/用户对的<em class="nb">匹配分数</em>，并且可以将它们与真实情况(从用户反馈收集的评论分数)进行比较。然后，我们可以使用梯度下降来拟合嵌入并优化我们的损失函数。本质上，这就是'<a class="ae lu" href="https://en.wikipedia.org/wiki/Collaborative_filtering" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">协同过滤</strong> </a>'推荐系统的工作原理。</p></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><h1 id="1606" class="lv lw it bd lx ly nl ma mb mc nm me mf jz nn ka mh kc no kd mj kf np kg ml mm bi translated">现在我们可以谈谈注意力:YouTube如何找到你搜索的视频(QKV系统)</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/b317781617138091c1d63beb15f99887.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*p319FtwiZVcWtsH9"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Nathana rebou as在<a class="ae lu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="8946" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi ms translated">现在我们离理解注意力又近了一步。我们可以看到另一个例子，如何使用点积来查找您输入的关键字的最佳视频。我们将介绍<strong class="la iu">查询</strong>、<strong class="la iu">键</strong>、<strong class="la iu">值</strong>的思路。假设你想找一个关于'<em class="nb">变形金刚</em>的视频，你在搜索框里输入了这个词(<strong class="la iu">查询</strong>)。你点击回车，YouTube就会查看他们的视频库，找到那些在标题或标签中有“transformer”的视频(<strong class="la iu">键</strong>)，然后返回给你他们认为最合适的视频(<strong class="la iu">值</strong>)。如果我们使用嵌入向量来表示我们的查询和视频的关键字，那么查询和每个关键字之间的点积将告诉我们该项目和您输入的关键字之间的“<strong class="la iu">相关性</strong>”。这个简单的QKV系统是注意力机制的核心。</p></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><h1 id="3d6c" class="lv lw it bd lx ly nl ma mb mc nm me mf jz nn ka mh kc no kd mj kf np kg ml mm bi translated">翻译中的注意，这都是很自然的</h1><p id="a411" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi ms"><span class="l mt mu mv bm mw mx my mz na di">F</span>inally, let’s look at how attention works. More precisely, how encoder-decoder attention works. Take translation as an example, say we have a Chinese sentence “潮水退了，才知道谁没穿裤子”, and we want to translate it into English: “<em class="nb">When the tide goes out, we know who is not wearing pants. </em>”. The natural way for us humans to do this is to look at the original sentence, translate one or two words, then look again to get the context, then translate another one or two words, rinse and repeat. So here we are actually doing three things:</p><p id="d804" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">人类友好词汇:</strong></p><ol class=""><li id="651e" class="om on it la b lb lc le lf lh oo ll op lp oq lt or os ot ou bi translated">看看翻译过来的单词，这样我们就可以建立上下文了。</li><li id="43cb" class="om on it la b lb ov le ow lh ox ll oy lp oz lt or os ot ou bi translated">看原句(所有的单词)，这样我们对意思会有更好的理解。</li><li id="6ab1" class="om on it la b lb ov le ow lh ox ll oy lp oz lt or os ot ou bi translated">我们搜索我们的记忆，找到给定1和2的最佳下一个单词。</li></ol><p id="2741" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">变形金刚的注意力机制也在做类似的事情。</p><p id="09c5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">在向量/嵌入词汇中:</strong></p><ol class=""><li id="2a41" class="om on it la b lb lc le lf lh oo ll op lp oq lt or os ot ou bi translated">Transformer模型的编码器计算当前翻译的嵌入/表示向量，将其用作<strong class="la iu"> <em class="nb">查询</em> </strong>。</li><li id="c1ca" class="om on it la b lb ov le ow lh ox ll oy lp oz lt or os ot ou bi translated">变换器模型的编码器计算每个原始单词的单词嵌入向量作为<strong class="la iu"> <em class="nb">键</em> </strong>。</li><li id="dd78" class="om on it la b lb ov le ow lh ox ll oy lp oz lt or os ot ou bi translated">Transformer模型的解码器计算查询/键的点积，我们可以得到一个新的向量，每个值是每个<em class="nb">查询</em> / <em class="nb">键对之间的“<em class="nb">相关性得分</em>”(稍后使用softmax转化为权重)。</em>用这些权重对原句的所有<strong class="la iu"> <em class="nb">值</em> </strong>嵌入向量进行加权求和，得到最终的<em class="nb">预测向量</em>，用这个预测向量预测下一个单词。请参见下面的动画:</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ecb3f5e5a35ab758e25dc7ddde08b61e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*uEWzH0tb8QWtsfIB1bc2KA.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">机器翻译中注意力是如何计算的</p></figure><p id="d0cc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">As the animation shows, <strong class="la iu"><em class="nb">attention</em></strong> is how much we need to ‘care’ about each word in the original sentence ( “潮 水 退 了” ), given the current already translated words (“<em class="nb">When the tide</em>”). We can achieve this by doing the dot product of the query vector and each word embeddings of the original sentence. The calculated attention vector is then used to calculate a new predictive vector, <strong class="la iu">extracting</strong> the embeddings with the respective amount of ‘attention’ needed from the original words. Then the model uses it to make the prediction (through some other dense layers etc.). You can come to <a class="ae lu" href="https://jalammar.github.io/illustrated-transformer/" rel="noopener ugc nofollow" target="_blank">this blog </a>for more details on how encoder-decoder attention works.</p></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><h1 id="2706" class="lv lw it bd lx ly nl ma mb mc nm me mf jz nn ka mh kc no kd mj kf np kg ml mm bi translated">自我关注:发现更成熟的自我</h1><p id="5051" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi ms translated"><span class="l mt mu mv bm mw mx my mz na di">在</span> <strong class="la iu"> Transformer的</strong>编码器部分，原句会先做<em class="nb">自关注</em>来更好的表现句子的上下文含义。让我们来看看自我关注是如何工作的。这与我们刚才解释的编码器-解码器注意力没有太大区别。见下图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/c0cdf204d30997bd7996eed6659de87f.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/0*oA8VLkmeHUu2ea6J.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">比例点积是自我关注的计算方式</p></figure><p id="d8e4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里最显著的区别是如何获得<code class="fe nr ns nt nu b">Query</code>、<code class="fe nr ns nt nu b">Key</code>和<code class="fe nr ns nt nu b">Values</code>。在编码器/解码器的关注下，<code class="fe nr ns nt nu b">Query</code>来自解码器读取当前翻译文本，<code class="fe nr ns nt nu b">Keys</code>和<code class="fe nr ns nt nu b">Values</code>来自编码器读取原句。而对于自我关注来说，<code class="fe nr ns nt nu b">Q</code>、<code class="fe nr ns nt nu b">K</code>、<code class="fe nr ns nt nu b">V</code>都来源于句子本身，故名自我关注。通俗地说，我们可以做到以下几点:</p><p id="e3c4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于句子中的每个单词，查看其余每个单词，并找出应该对它们给予多少关注(点积)，以获得一个“关注度”向量。例如，下图来自谷歌关于变形金刚的博客:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/f99e76fbb111385e1bc8c8affff475fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vKVdSQkKAdnWeGhWnSA3jA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">“它”这个词关注它自己，“动物”和“街道”——图来自谷歌关于变形金刚的博客</p></figure><p id="595a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">单词'<strong class="la iu"> it </strong>'通过对自己和句子中的所有单词进行点积来计算自己的自我关注度(在上图中用不同深浅的蓝色表示)。一旦计算出自我关注度，模型就可以用它来'<strong class="la iu">重新分配</strong>单词嵌入。这样，单词'<strong class="la iu"> it </strong>的新的'<em class="nb">表示</em>就生成了。它结合了自己的词向量和一些注意力权重大的词。“<strong class="la iu"> it </strong>的新表述现在更加“<em class="nb">上下文感知</em>”和“<em class="nb">复杂</em>”，更适合翻译和其他与语言相关的任务。这是对每个单词做的，所以当所有的都说了，做了，我们将有一个每个单词的表示，都知道上下文。实际上，转换者将有多个关注层，我们将有“上下文的上下文”、“上下文的上下文”等等。，从而提高了模型的抽象性。这可能就是transformer在语言相关任务中表现如此出色的原因。它提供了一个很好的语言抽象模型，就像CNN为视觉任务所做的那样。</p><p id="785e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">但是等一下，你说</strong>。那<code class="fe nr ns nt nu b">Q</code>、<code class="fe nr ns nt nu b">K</code>、<code class="fe nr ns nt nu b">V</code>呢？我们知道它们来自编码器/解码器的注意力，但是它们是如何计算自我注意力的呢？就更简单了。自我关注中的<code class="fe nr ns nt nu b">query</code>、<code class="fe nr ns nt nu b">key</code>、<code class="fe nr ns nt nu b">value</code>就是他们自己。我们正在询问我们自己(询问关键点积)以获得<strong class="la iu">自我</strong>-注意力，然后使用我们自己的自我注意力(注意力矩阵以评估点积)来获得新的表示。如果我们看看衡量点积注意力的公式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/0daa847445625e4ab6e3f0568cccf0b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*n7oAnUY5ZaLCI2Jt"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">标度点积注意力公式</p></figure><p id="3351" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">自我关注公式应该是这样的(<code class="fe nr ns nt nu b"><strong class="la iu"><em class="nb">X</em></strong></code>是句子词向量):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/7cbe5d66cb1a34a56adc7fad5daac6da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4WXjIKMaFgiAtWoK"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">自我关注公式</p></figure><p id="a34b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在实际实现中，我们在<code class="fe nr ns nt nu b"><strong class="la iu"><em class="nb">X</em></strong></code>之上堆叠三个独立的线性层，以获得<code class="fe nr ns nt nu b">Q</code>、<code class="fe nr ns nt nu b">K</code>、<code class="fe nr ns nt nu b">V</code>，但这只是为了更灵活的建模。本质上，他们还是<code class="fe nr ns nt nu b"><strong class="la iu"><em class="nb">X</em></strong></code>。</p></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><h1 id="f365" class="lv lw it bd lx ly nl ma mb mc nm me mf jz nn ka mh kc no kd mj kf np kg ml mm bi translated">结论</h1><p id="dc70" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi ms translated"><span class="l mt mu mv bm mw mx my mz na di"> T </span> he <em class="nb"> attention </em>机制有很多应用，并不仅限于<strong class="la iu">T5】NLPT7。例如，图像识别可以利用注意力找出图像的相关部分。</strong></p><blockquote class="pe"><p id="fd4d" class="pf pg it bd ph pi pj pk pl pm pn lt dk translated">任何可以放进记号序列的东西，我们都可以使用注意力机制来帮助我们发现模式、提取特征、连接点、做抽象等等。这确实是一个非常强大的模型。</p></blockquote><p id="8ae9" class="pw-post-body-paragraph ky kz it la b lb po ju ld le pp jx lg lh pq lj lk ll pr ln lo lp ps lr ls lt im bi translated"><em class="nb">注意力</em>和<em class="nb">变压器</em>(或多或少与培训相关)的其他部分不在本文讨论范围内，比如“缩放点积注意力”中的“<em class="nb">缩放</em>是什么意思？口罩是如何工作的？等等。这篇文章并不意味着包罗万象。相反，它试图在<strong class="la iu"> Transformer </strong>架构中确定<em class="nb">自我关注</em>机制如何工作的<strong class="la iu">直觉</strong>部分。如果你在读完这篇文章后觉得注意力的概念更有意义，那么它已经达到了它的目的。</p></div><div class="ab cl ne nf hx ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="im in io ip iq"><p id="3e3f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我希望你觉得这篇文章读起来很有趣，并从中学习到一些东西。如果你想更多地了解我对数据科学的思考、实践和写作，可以考虑报名成为Medium会员。每月5美元，你可以无限制地阅读媒体上的故事。如果你注册使用我的链接，我会赚一小笔佣金。</p><div class="pt pu gp gr pv pw"><a href="https://lymenlee.medium.com/membership" rel="noopener follow" target="_blank"><div class="px ab fo"><div class="py ab pz cl cj qa"><h2 class="bd iu gy z fp qb fr fs qc fu fw is bi translated">通过我的推荐链接——李立伟加入Medium</h2><div class="qd l"><h3 class="bd b gy z fp qb fr fs qc fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="qe l"><p class="bd b dl z fp qb fr fs qc fu fw dk translated">lymenlee.medium.com</p></div></div><div class="qf l"><div class="qg l qh qi qj qf qk ks pw"/></div></div></a></div></div></div>    
</body>
</html>