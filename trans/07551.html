<html>
<head>
<title>Machine Learning: Getting Started with the K-Neighbours Classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习:K近邻分类器入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-getting-started-with-the-k-neighbours-classifier-d7e6b25f2b09?source=collection_archive---------16-----------------------#2021-07-10">https://towardsdatascience.com/machine-learning-getting-started-with-the-k-neighbours-classifier-d7e6b25f2b09?source=collection_archive---------16-----------------------#2021-07-10</a></blockquote><div><div class="fc ik il im in io"/><div class="ip iq ir is it"><h2 id="6a86" class="iu iv iw bd b dl ix iy iz ja jb jc dk jd translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><div class=""><h2 id="86bc" class="pw-subtitle-paragraph kc jf iw bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">一个Python的现成代码，它实现了scikit-learn中的K-neighbors分类器，从数据预处理到生产。</h2></div><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ku"><img src="../Images/7b1a6a8c473bb8fe98153cf9b8a4944a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*msNTiBKD0LyhAyg2mcMV-g.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="1cfb" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">在本教程中，我将演示如何实现一个利用K-neighbors分类器的分类模型。完整的代码实现为一个Jupyter笔记本，可以从我的<a class="ae mg" href="https://github.com/alod83/data-science/tree/master/DataAnalysis/KNN" rel="noopener ugc nofollow" target="_blank"> Github库</a>下载。</p><p id="2bc0" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">作为一个示例数据集，我利用了Kaggle Challenge中提供的Titanic数据集:<a class="ae mg" href="https://www.kaggle.com/c/titanic/overview" rel="noopener ugc nofollow" target="_blank">Titanic-机器从灾难中学习</a>。这项挑战的目标是建立一个模型，根据乘客的一些特征，预测乘客在泰坦尼克号灾难中是否幸存。</p><h1 id="7ac9" class="mh mi iw bd mj mk ml mm mn mo mp mq mr kl ms km mt ko mu kp mv kr mw ks mx my bi translated">加载数据集</h1><p id="0cb2" class="pw-post-body-paragraph lk ll iw lm b ln mz kg lp lq na kj ls lt nb lv lw lx nc lz ma mb nd md me mf ip bi translated">数据集由三个文件组成:</p><ul class=""><li id="1d9e" class="ne nf iw lm b ln lo lq lr lt ng lx nh mb ni mf nj nk nl nm bi translated"><strong class="lm jg"> train.csv </strong> —包含用于训练模型的数据集</li><li id="b2c5" class="ne nf iw lm b ln nn lq no lt np lx nq mb nr mf nj nk nl nm bi translated"><strong class="lm jg">test . CSV</strong>——包含执行新预测的未知样本</li><li id="adc8" class="ne nf iw lm b ln nn lq no lt np lx nq mb nr mf nj nk nl nm bi translated"><strong class="lm jg">gender _ submission . CSV</strong>-输出数据集的示例。</li></ul><p id="eef6" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">在本教程中，我们只考虑train.csv文件。train.csv文件由891行和12列组成:</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ns"><img src="../Images/e6a6ba8b2be14c26ac8c7567c4fbda3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y-WTGCkGhoUro_dTYp_JHA.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="fa45" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">为每位乘客提供不同的功能。test.csv文件与前一个文件类似，只是没有提供幸存列。</p><p id="3b96" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">我们利用<code class="fe nt nu nv nw b">pandas</code>库来加载数据集:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="263c" class="ob mi iw nw b gz oc od l oe of">import pandas as pd</span><span id="3460" class="ob mi iw nw b gz og od l oe of">df = pd.read_csv('data/train.csv')</span></pre><p id="57f9" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">查看这些列，可以将下列列用作输入要素:</p><ul class=""><li id="adc4" class="ne nf iw lm b ln lo lq lr lt ng lx nh mb ni mf nj nk nl nm bi translated">Pclass</li><li id="0c87" class="ne nf iw lm b ln nn lq no lt np lx nq mb nr mf nj nk nl nm bi translated">性</li><li id="e51b" class="ne nf iw lm b ln nn lq no lt np lx nq mb nr mf nj nk nl nm bi translated">年龄</li><li id="bbed" class="ne nf iw lm b ln nn lq no lt np lx nq mb nr mf nj nk nl nm bi translated">SibSp</li><li id="6e62" class="ne nf iw lm b ln nn lq no lt np lx nq mb nr mf nj nk nl nm bi translated">烤</li><li id="18da" class="ne nf iw lm b ln nn lq no lt np lx nq mb nr mf nj nk nl nm bi translated">票价</li><li id="07e5" class="ne nf iw lm b ln nn lq no lt np lx nq mb nr mf nj nk nl nm bi translated">上船了。</li></ul><p id="39b0" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">柱舱也可以作为输入特征插入。但是，在test.csv文件中，Cabin列的几乎所有值都丢失了。为此，我们决定不插入作为输入特征。</p><h1 id="770e" class="mh mi iw bd mj mk ml mm mn mo mp mq mr kl ms km mt ko mu kp mv kr mw ks mx my bi translated">预处理</h1><p id="0fb7" class="pw-post-body-paragraph lk ll iw lm b ln mz kg lp lq na kj ls lt nb lv lw lx nc lz ma mb nd md me mf ip bi translated">首先，我们删除分析中不使用的列:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="2036" class="ob mi iw nw b gz oc od l oe of">df = df.drop(['Cabin', 'Ticket'], axis=1)</span></pre><p id="811b" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">然后，我们需要将所有分类特征转换为数字，并将范围[0，1]中的所有数字特征转换为数字。</p><p id="d6d1" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">对于每个特性，我们利用<code class="fe nt nu nv nw b">unique()</code>函数列出该特性可能采用的所有可能值。例如，对于性特征，我们可以写:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="7c25" class="ob mi iw nw b gz oc od l oe of">df['Sex'].unique()</span></pre><p id="bbfb" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">它给出了以下输出:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="9bc2" class="ob mi iw nw b gz oc od l oe of">array(['male', 'female'], dtype=object)</span></pre><p id="fbc9" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">这意味着:</p><ul class=""><li id="c1e3" class="ne nf iw lm b ln lo lq lr lt ng lx nh mb ni mf nj nk nl nm bi translated">该特征只能采用两个值</li><li id="1807" class="ne nf iw lm b ln nn lq no lt np lx nq mb nr mf nj nk nl nm bi translated">性别列中没有缺失值</li><li id="a507" class="ne nf iw lm b ln nn lq no lt np lx nq mb nr mf nj nk nl nm bi translated">该特征是分类特征。</li></ul><p id="4a0f" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">我们可以使用<code class="fe nt nu nv nw b">scikit-learn</code> <code class="fe nt nu nv nw b">LabelEncoder</code>将分类特征转换为数字，或者我们可以定义自己的函数，如下面的代码片段所示:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="2f37" class="ob mi iw nw b gz oc od l oe of">def get_gender(x):<br/>    if x == 'male':<br/>        return 0<br/>    return 1</span></pre><p id="b646" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">然后我们可以将我们的函数应用到性别列:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="3b01" class="ob mi iw nw b gz oc od l oe of">df['Sex'] = df['Sex'].apply(lambda x : get_gender(x))</span></pre><p id="2d15" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">一旦所有的分类特征都被转换成数字，我们需要映射[0，1]区间中的所有特征。这可以通过<code class="fe nt nu nv nw b">scikit-learn</code> <code class="fe nt nu nv nw b">MinMaxScaler()</code>类来实现。为此，我们定义了一个函数，所有功能都可以利用它:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="de11" class="ob mi iw nw b gz oc od l oe of">from sklearn.preprocessing import MinMaxScaler</span><span id="a5c1" class="ob mi iw nw b gz og od l oe of">def scale_column(column, df):<br/>    values = df[column].values<br/>    <br/>    scaler = MinMaxScaler()<br/>    scaler.fit(values.reshape(-1, 1))<br/>    return scaler.transform(values.reshape(-1, 1))</span></pre><p id="e143" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">前面的函数将列名和数据集作为输入，对该列的值构建一个<code class="fe nt nu nv nw b">MinMaxScaler()</code>，拟合缩放器并返回转换后的值。</p><p id="57cf" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated"><code class="fe nt nu nv nw b">scaler_column()</code>功能可以如下调用:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="0fdf" class="ob mi iw nw b gz oc od l oe of">df['Parch'] = scale_column('Parch', df)</span></pre><p id="07e0" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">但是，我们已经注意到，在test.csv文件的一些列中有一些丢失的值，这些值在train.csv文件中不存在。我们可以用一个虚构值替换缺失值，如下所示:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="73b1" class="ob mi iw nw b gz oc od l oe of">df['Age'] = df['Age'].fillna(value=0)</span></pre><p id="1ab4" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">我们可以修改<code class="fe nt nu nv nw b">scale_column()</code>函数来处理缺失值，如下所示:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="86ee" class="ob mi iw nw b gz oc od l oe of">def scale_column(column, df, nan=False):<br/>    values = df[column].values<br/>    <br/>    scaler = MinMaxScaler()<br/>    if nan:<br/>        # also consider missing values in the test set<br/>        new_values = np.append(values,0)<br/>        scaler.fit(new_values.reshape(-1, 1))<br/>    else:<br/>        scaler.fit(values.reshape(-1, 1))<br/>    return scaler.transform(values.reshape(-1, 1))</span></pre><p id="76bf" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">如果该列包含缺失值，则将<code class="fe nt nu nv nw b">nan</code>变量设置为<code class="fe nt nu nv nw b">True</code>，否则将其设置为<code class="fe nt nu nv nw b">False</code>。</p><p id="6f4b" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">预处理的完整代码如下:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="2ae7" class="ob mi iw nw b gz oc od l oe of">df['Embarked'] = df['Embarked'].fillna(value='N')<br/>df['Age'] = df['Age'].fillna(value=0)<br/>df['Fare'] = df['Fare'].fillna(value=0)</span><span id="231f" class="ob mi iw nw b gz og od l oe of">df['Sex'] = df['Sex'].apply(lambda x : get_gender(x))<br/>df['Embarked'] = df['Embarked'].apply(lambda x : get_embarked(x))</span><span id="dbdc" class="ob mi iw nw b gz og od l oe of">for i in ['Age', 'Parch', 'Fare', 'Pclass', 'SibSp']:<br/>    df[i] = scale_column(i, df)</span></pre><p id="3462" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">最后，我们可以删除所有剩余的NaN值:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="d869" class="ob mi iw nw b gz oc od l oe of">df = df.dropna()</span></pre><h1 id="a0fd" class="mh mi iw bd mj mk ml mm mn mo mp mq mr kl ms km mt ko mu kp mv kr mw ks mx my bi translated">在训练集和测试集中拆分数据集</h1><p id="781e" class="pw-post-body-paragraph lk ll iw lm b ln mz kg lp lq na kj ls lt nb lv lw lx nc lz ma mb nd md me mf ip bi translated">预处理之后，我们可以从数据集中提取输入(X)和输出(y ):</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="fac7" class="ob mi iw nw b gz oc od l oe of">features = ['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']<br/>X = df[features]<br/>y = df['Survived']</span></pre><p id="8fff" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">我们可以将获得的数据集分为训练集和测试集，保留33%的样本进行测试:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="2030" class="ob mi iw nw b gz oc od l oe of">from sklearn.model_selection import train_test_split</span><span id="b224" class="ob mi iw nw b gz og od l oe of">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)</span></pre><h1 id="2cb4" class="mh mi iw bd mj mk ml mm mn mo mp mq mr kl ms km mt ko mu kp mv kr mw ks mx my bi translated">训练模型</h1><p id="5141" class="pw-post-body-paragraph lk ll iw lm b ln mz kg lp lq na kj ls lt nb lv lw lx nc lz ma mb nd md me mf ip bi translated">现在我们准备训练模型。我们利用交叉验证的网格搜索来调整K-neighbors分类器。</p><p id="6e72" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">我们定义要调整的参数网格:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="3f86" class="ob mi iw nw b gz oc od l oe of">from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.model_selection import GridSearchCV<br/>import numpy as np</span><span id="279c" class="ob mi iw nw b gz og od l oe of">parameters = {  'n_neighbors'   : np.arange(3, 8),<br/>                'weights'       : ['uniform', 'distance'],<br/>                'metric'        : ['euclidean', 'manhattan', 'chebyshev', 'minkowski'],<br/>                'algorithm'     : ['auto', 'ball_tree', 'kd_tree'],<br/>            }</span></pre><p id="2ca0" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">然后我们调整分类器:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="89e8" class="ob mi iw nw b gz oc od l oe of">classifier = KNeighborsClassifier()<br/>clf = GridSearchCV(classifier, parameters, cv = 5)<br/>clf.fit(X_train, y_train.values.ravel())</span></pre><p id="24da" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">我们可以检索最佳模型:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="0d14" class="ob mi iw nw b gz oc od l oe of">model = clf.best_estimator_</span></pre><h1 id="1912" class="mh mi iw bd mj mk ml mm mn mo mp mq mr kl ms km mt ko mu kp mv kr mw ks mx my bi translated">测试模型</h1><p id="f5a6" class="pw-post-body-paragraph lk ll iw lm b ln mz kg lp lq na kj ls lt nb lv lw lx nc lz ma mb nd md me mf ip bi translated">现在，我们可以在测试集上测试模型:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="b22c" class="ob mi iw nw b gz oc od l oe of">y_score = model.predict_proba(X_test)</span></pre><p id="c5e8" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">并绘制ROC和预测/回忆曲线:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="e686" class="ob mi iw nw b gz oc od l oe of">import matplotlib.pyplot as plt<br/>from sklearn.metrics import roc_curve<br/>from scikitplot.metrics import plot_roc,auc<br/>from scikitplot.metrics import plot_precision_recall</span><span id="2927" class="ob mi iw nw b gz og od l oe of"># Plot metrics <br/>plot_roc(y_test.values.ravel(), y_score)<br/>plt.savefig('roc.png')<br/>plt.show()<br/>    <br/>plot_precision_recall(y_test.values.ravel(), y_score)<br/>plt.savefig('pr.png')<br/>plt.show()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ku"><img src="../Images/7b1a6a8c473bb8fe98153cf9b8a4944a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*msNTiBKD0LyhAyg2mcMV-g.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj oh"><img src="../Images/dbb0cb6a19211b96f0c0b0555dc9ed2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C9J5PwyjiGOHdqZPSmEU2A.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="7dfd" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">我们还可以计算精确度、召回率和准确度:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="ec83" class="ob mi iw nw b gz oc od l oe of">from sklearn.metrics import precision_score, recall_score, accuracy_score</span><span id="6b8d" class="ob mi iw nw b gz og od l oe of">y_pred = model.predict(X_test)</span><span id="46a8" class="ob mi iw nw b gz og od l oe of">precision = precision_score(y_test.values.ravel(),y_pred)</span><span id="4045" class="ob mi iw nw b gz og od l oe of">recall = recall_score(y_test.values.ravel(),y_pred)</span><span id="b246" class="ob mi iw nw b gz og od l oe of">accuracy = accuracy_score(y_test.values.ravel(),y_pred)</span><span id="b8d9" class="ob mi iw nw b gz og od l oe of">print('Precision: ' , precision)<br/>print('Recall: ' , recall)<br/>print('Accuracy: ' , accuracy)</span></pre><p id="6cdc" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">它给出了以下输出:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="fad1" class="ob mi iw nw b gz oc od l oe of">Precision:  0.7536200639348735<br/>Recall:     0.7542372881355932<br/>Accuracy:   0.7542372881355932</span></pre><h1 id="5614" class="mh mi iw bd mj mk ml mm mn mo mp mq mr kl ms km mt ko mu kp mv kr mw ks mx my bi translated">最终确定模型</h1><p id="1ee7" class="pw-post-body-paragraph lk ll iw lm b ln mz kg lp lq na kj ls lt nb lv lw lx nc lz ma mb nd md me mf ip bi translated">我们可以通过在整个X数据集上再次训练来最终确定模型:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="1ba6" class="ob mi iw nw b gz oc od l oe of">model.fit(X, y.values.ravel())</span></pre><p id="128d" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">我们保存模型以备将来使用:</p><pre class="kv kw kx ky gu nx nw ny nz aw oa bi"><span id="297c" class="ob mi iw nw b gz oc od l oe of">import pickle<br/>pickle.dump(model, open("knn.sav", 'wb'))</span></pre><h1 id="c247" class="mh mi iw bd mj mk ml mm mn mo mp mq mr kl ms km mt ko mu kp mv kr mw ks mx my bi translated">摘要</h1><p id="f837" class="pw-post-body-paragraph lk ll iw lm b ln mz kg lp lq na kj ls lt nb lv lw lx nc lz ma mb nd md me mf ip bi translated">在这篇初学者教程中，我已经演示了如何使用<code class="fe nt nu nv nw b">scikit-learn</code>库建立、训练和完成K-neighbors分类器。应遵循以下步骤:</p><ul class=""><li id="3330" class="ne nf iw lm b ln lo lq lr lt ng lx nh mb ni mf nj nk nl nm bi translated">数据预处理</li><li id="858e" class="ne nf iw lm b ln nn lq no lt np lx nq mb nr mf nj nk nl nm bi translated">模特培训</li><li id="2d2d" class="ne nf iw lm b ln nn lq no lt np lx nq mb nr mf nj nk nl nm bi translated">模型检验</li><li id="fbed" class="ne nf iw lm b ln nn lq no lt np lx nq mb nr mf nj nk nl nm bi translated">模型最终确定</li></ul><p id="59f3" class="pw-post-body-paragraph lk ll iw lm b ln lo kg lp lq lr kj ls lt lu lv lw lx ly lz ma mb mc md me mf ip bi translated">如果你想了解我的研究和其他活动的最新情况，你可以在<a class="ae mg" href="https://twitter.com/alod83" rel="noopener ugc nofollow" target="_blank"> Twitter </a>、<a class="ae mg" href="https://www.youtube.com/channel/UC4O8-FtQqGIsgDW_ytXIWOg?view_as=subscriber" rel="noopener ugc nofollow" target="_blank"> Youtube </a>和<a class="ae mg" href="https://github.com/alod83" rel="noopener ugc nofollow" target="_blank"> Github </a>上关注我。</p><h1 id="4616" class="mh mi iw bd mj mk ml mm mn mo mp mq mr kl ms km mt ko mu kp mv kr mw ks mx my bi translated">相关文章</h1><div class="oi oj gq gs ok ol"><a rel="noopener follow" target="_blank" href="/data-normalization-with-python-scikit-learn-e9c5640fed58"><div class="om ab fp"><div class="on ab oo cl cj op"><h2 class="bd jg gz z fq oq fs ft or fv fx jf bi translated">使用Python scikit进行数据规范化-学习</h2><div class="os l"><h3 class="bd b gz z fq oq fs ft or fv fx dk translated">继关于数据预处理的系列文章之后，在本教程中，我将讨论Python中的数据规范化…</h3></div><div class="ot l"><p class="bd b dl z fq oq fs ft or fv fx dk translated">towardsdatascience.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz le ol"/></div></div></a></div><div class="oi oj gq gs ok ol"><a rel="noopener follow" target="_blank" href="/a-complete-data-analysis-workflow-in-python-pycaret-9a13c0fa51d4"><div class="om ab fp"><div class="on ab oo cl cj op"><h2 class="bd jg gz z fq oq fs ft or fv fx jf bi translated">Python PyCaret中的完整数据分析工作流</h2><div class="os l"><h3 class="bd b gz z fq oq fs ft or fv fx dk translated">这是一个现成的教程，利用了我用过的最好的机器学习库。</h3></div><div class="ot l"><p class="bd b dl z fq oq fs ft or fv fx dk translated">towardsdatascience.com</p></div></div><div class="ou l"><div class="pa l ow ox oy ou oz le ol"/></div></div></a></div><div class="oi oj gq gs ok ol"><a rel="noopener follow" target="_blank" href="/automl-in-python-a-comparison-between-hyperopt-sklearn-and-tpot-8c12aaf7e829"><div class="om ab fp"><div class="on ab oo cl cj op"><h2 class="bd jg gz z fq oq fs ft or fv fx jf bi translated">Python中的AutoML:Hyperopt sk learn和TPOT的比较</h2><div class="os l"><h3 class="bd b gz z fq oq fs ft or fv fx dk translated">两种流行的Python AutoML库的优缺点</h3></div><div class="ot l"><p class="bd b dl z fq oq fs ft or fv fx dk translated">towardsdatascience.com</p></div></div><div class="ou l"><div class="pb l ow ox oy ou oz le ol"/></div></div></a></div><div class="oi oj gq gs ok ol"><a rel="noopener follow" target="_blank" href="/a-complete-data-analysis-workflow-in-python-and-scikit-learn-9a77f7c283d3"><div class="om ab fp"><div class="on ab oo cl cj op"><h2 class="bd jg gz z fq oq fs ft or fv fx jf bi translated">Python和scikit中的完整数据分析工作流程-学习</h2><div class="ot l"><p class="bd b dl z fq oq fs ft or fv fx dk translated">towardsdatascience.com</p></div></div><div class="ou l"><div class="pc l ow ox oy ou oz le ol"/></div></div></a></div><h1 id="845f" class="mh mi iw bd mj mk ml mm mn mo mp mq mr kl ms km mt ko mu kp mv kr mw ks mx my bi translated">新到中？您可以每月订阅几美元，并解锁无限的文章— <a class="ae mg" href="https://alod83.medium.com/membership" rel="noopener">点击此处</a>。</h1></div></div>    
</body>
</html>