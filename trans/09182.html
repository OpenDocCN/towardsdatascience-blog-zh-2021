<html>
<head>
<title>MPIRE for Python: MultiProcessing Is Really Easy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MPIRE for Python:多重处理非常简单</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/mpire-for-python-multiprocessing-is-really-easy-d2ae7999a3e9?source=collection_archive---------1-----------------------#2021-08-25">https://towardsdatascience.com/mpire-for-python-multiprocessing-is-really-easy-d2ae7999a3e9?source=collection_archive---------1-----------------------#2021-08-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="cb4c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">MPIRE简介，这是一个速度极快且最用户友好的Python多处理库</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e546d592e7a433ee4c981d6a9279108d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1701SlfKpJW6Pmwm"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Jarek Jordan 在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="778b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Python是一种流行的编程语言，原因有几个。最重要的是，它易于设置和学习，因此开发速度快。然而，一个主要的缺点是Python的执行速度。与许多其他流行的编程语言相比，Python在速度方面排在最后。幸运的是，通过用C编写许多性能关键的库并添加Python包装器(例如NumPy)，速度问题已经大大缓解了。这些解决方案运行良好，它们可以利用多线程进行并行计算。当您自己的代码降低了您的速度，并且您想要并行化纯Python代码时，事情就变得棘手了。</p><p id="fb03" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过多线程，单个进程的多个线程被同时执行。用C/C++编写的库可以毫无问题地利用多线程。Python不能利用多线程，因为臭名昭著的全局解释器锁(GIL)。我不会去解释它是做什么的，为什么它还在这里，因为有很多关于这个话题的<a class="ae kv" href="https://realpython.com/python-gil/" rel="noopener ugc nofollow" target="_blank">其他优秀的博客帖子</a>。这里要记住的是，由于这个GIL，Python不能像其他语言一样利用多线程处理CPU密集型任务。(注意:对于I/O密集型任务和其他释放GIL的任务，多线程可以很好地工作。)</p><p id="9f8c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，Python程序员经常需要依赖多重处理，新的进程同时产生和执行。通过产生新的进程，我们有效地避开了GIL。然而，为了在这些进程之间进行通信，我们需要使用管道或队列。这些通信原语不仅降低了多重处理的速度，而且如果你不是很有经验的话，它们也很难使用。</p><p id="715d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有许多Python库提供了多处理能力，并且不需要编写所有样板代码来处理进程和进程间通信。例如，有<code class="fe ls lt lu lv b">multiprocessing.Pool</code> <em class="lw"> </em>和<code class="fe ls lt lu lv b">concurrent.futures.ProcessPoolExecutor</code>类，它们都可以在Python标准库中找到。此外，还有Joblib等第三方包，以及Dask <em class="lw"> </em>和Ray等分布式计算包。后一类还提供了跨几台机器的计算。然而，在我7年的Python程序员生涯中，单台机器上的多处理通常就足够了，建立一个工人集群的额外成本得不偿失。</p><p id="7f62" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，即使有这么多图书馆，没有一个能让我满意。大多数都有一个陡峭的学习曲线，因为它们引入了一个全新的关于<code class="fe ls lt lu lv b">multiprocessing.Pool</code>的编程语法，提供了很差的错误处理，或者根本没有提供我正在寻找的所有功能。因此，四年前，我创建了一个新的包，它可以完成所有这些功能，甚至更多。它已经在Slimmer AI的几十个项目中使用，经过几次迭代的反馈和在生产环境中的暴露，它已经成为今天的成熟包。它现在是Slimmer AI的首选多处理库，最近，我们在<a class="ae kv" href="https://github.com/Slimmer-AI/mpire" rel="noopener ugc nofollow" target="_blank"> GitHub </a>和<a class="ae kv" href="https://pypi.org/project/mpire/" rel="noopener ugc nofollow" target="_blank"> PyPI </a>上公开了它。文档可在<a class="ae kv" href="https://slimmer-ai.github.io/mpire/" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p><p id="d089" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇博文中，我将介绍我们的多处理库MPIRE(多处理真的很简单),并将它与现有的库在功能、易用性和速度方面进行比较。除了普通的串行处理，我对MPIRE进行基准测试的库有<code class="fe ls lt lu lv b">multiprocessing.Pool</code>、<code class="fe ls lt lu lv b">concurrent.futures.ProcessPoolExecutor</code>、<em class="lw">、</em>(一个<code class="fe ls lt lu lv b">multiprocessing.Pool</code>的包装器)、Joblib、Dask和Ray。在这篇文章的剩余部分，我将用<code class="fe ls lt lu lv b">ProcessPoolExecutor</code>来指代<code class="fe ls lt lu lv b">concurrent.futures.ProcessPoolExecutor</code>。</p><h1 id="eb3e" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">MPIRE概述</h1><p id="dbce" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">MPIRE构建在流行的<code class="fe ls lt lu lv b">multiprocessing</code> <em class="lw"> </em>标准库之上，大部分遵循相同的语法，这使得它非常容易学习。<code class="fe ls lt lu lv b">mpire.WorkerPool</code>级类似于<code class="fe ls lt lu lv b">multiprocessing.Pool</code>级，但是增加了更多的特性和配置选项。MPIRE的主要特点是:</p><ul class=""><li id="2324" class="mu mv iq ky b kz la lc ld lf mw lj mx ln my lr mz na nb nc bi translated">比其他多处理库执行速度更快</li><li id="9429" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">直观的Pythonic语法</li><li id="a437" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">优雅且用户友好的异常处理</li><li id="5c99" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">通过一组工作人员轻松使用写入时复制共享对象</li><li id="3333" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">每个工作者可以有自己的状态，并且通过方便的工作者初始化和退出功能，可以容易地操纵该状态</li><li id="f5af" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">进度条支持使用<a class="ae kv" href="https://tqdm.github.io/" rel="noopener ugc nofollow" target="_blank"> tqdm </a></li><li id="b494" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">仪表板支架</li><li id="7993" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">Worker insights可让您深入了解多处理效率</li><li id="dc45" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">子进程可以被固定到特定的或一系列的CPU上</li><li id="193f" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">多种进程启动方法可用，包括:fork、forkserver、spawn和threading(是的，threading)</li><li id="b22b" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated">可选地利用<a class="ae kv" href="https://pypi.org/project/dill/" rel="noopener ugc nofollow" target="_blank"> dill </a>作为通过<a class="ae kv" href="https://github.com/uqfoundation/multiprocess" rel="noopener ugc nofollow" target="_blank">多进程</a>的序列化后端，支持在iPython和Jupyter笔记本中并行化更多外来对象、lambdas和函数</li></ul><p id="4ef3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于这篇博文来说，浏览所有特性太多了。因此，我将重点放在几乎每个多处理任务的相关特性上。请参考<a class="ae kv" href="https://slimmer-ai.github.io/mpire/" rel="noopener ugc nofollow" target="_blank">文档</a>了解更多关于MPIRE的其他特性。</p><p id="0cf2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看几个例子，并将MPIRE与其他库进行比较。</p><h2 id="cb24" class="ni ly iq bd lz nj nk dn md nl nm dp mh lf nn no mj lj np nq ml ln nr ns mn nt bi translated">例1。句法</h2><p id="50bf" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">假设我们有一个耗时的函数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="3565" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们想调用100次并并行化:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="0d80" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Joblib <em class="lw"> </em>和Ray <em class="lw"> </em>相对于<code class="fe ls lt lu lv b">multiprocessing.Pool</code>引入了全新的语法。这意味着需要更多的时间来学习如何充分和优化地利用这些库。相比之下，MPIRE的语法非常接近<code class="fe ls lt lu lv b">multiprocessing.Pool</code>。</p><p id="498d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在没有多处理的情况下运行这个函数大约需要100秒，而所有经过测试的多处理库大约需要20秒。这是因为它们都被配置为创建5个流程，从而并行处理5个任务。在启动子进程和进程间通信时会有一些小的开销，但是在这种情况下预期会有5倍的加速。</p><h2 id="be54" class="ni ly iq bd lz nj nk dn md nl nm dp mh lf nn no mj lj np nq ml ln nr ns mn nt bi translated">示例2:进度条</h2><p id="e4e9" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">让我们添加一个进度条，让事情变得更有趣一点。当然，当你运行一个长任务时，你想知道任务的状态和完成的时间。我们将建立在前一个例子的基础上，利用<code class="fe ls lt lu lv b">tqdm</code>作为进度条库。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="d083" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<code class="fe ls lt lu lv b">multiprocessing.Pool</code>的情况下，如果我们想要显示实时进度信息，我们必须使用<code class="fe ls lt lu lv b">imap</code>，一个返回生成器的<code class="fe ls lt lu lv b">map</code>的惰性版本。尽管Ray <em class="lw"> </em>有一个仪表板，但是在那里找不到进度信息。<code class="fe ls lt lu lv b">ProcessPoolExecutor</code>和雷<em class="lw"> </em>都引入了许多样板代码来实现进度条这样的琐碎工作。然而，雷在这里拿了蛋糕。当使用MPIRE时，我们可以简单地设置<code class="fe ls lt lu lv b">progress_bar</code>标志，我们就完成了。</p><h2 id="49b6" class="ni ly iq bd lz nj nk dn md nl nm dp mh lf nn no mj lj np nq ml ln nr ns mn nt bi translated">示例3:异常处理</h2><p id="7eea" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">尽管您可能很有经验，但每个人都会偶尔引入bug。在多处理上下文中调试异常并不总是容易的。然而，多重处理库至少可以使调试变得更容易。让我们看下面这个简单的例子:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="89df" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，这个函数到处都在叫<code class="fe ls lt lu lv b">ZeroDivisionError</code> <em class="lw"> </em>，这里只是为了说明。让我们看看不同的库将如何处理以下数据:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="1424" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们稍微修改了一下上面的代码，以使用新的函数和数据，但大部分都是相似的。完整代码见<a class="ae kv" href="https://gist.github.com/sybrenjansen/989027a3844e002c3ca9bdb944fe4237#file-error_test-py" rel="noopener ugc nofollow" target="_blank">此链接</a>。我们来看看输出。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/09e98bcf4f54c00c1795274bfa02761c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*53GiuLoprx3FC9sUq01utA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="nx">光线(上)、Joblib(中)、MPIRE(下)的错误输出。图片作者。</em></p></figure><p id="6857" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于大多数库，我们可以确切地看到哪一行导致了错误，即<code class="fe ls lt lu lv b">return (x * y) / z</code>。然而Joblib和Ray只表示发生在<code class="fe ls lt lu lv b">some_function</code>的第3行。即使雷<em class="lw"> </em>召唤出一个<code class="fe ls lt lu lv b">RayTaskError(ZeroDivisionError)</code>，它仍然可以作为普通<code class="fe ls lt lu lv b">ZeroDivisionError</code>被抓，所以那里不用担心。然而，这些回溯之间的主要区别在于，MPIRE显示传递给导致错误的函数的参数。这使得调试更加容易。唯一做这件事的其他图书馆是Dask。</p><p id="816f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">MPIRE包含更多的特性，其中一些将在接下来的基准测试部分展示。</p></div><div class="ab cl ny nz hu oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="ij ik il im in"><h1 id="75ed" class="lx ly iq bd lz ma of mc md me og mg mh jw oh jx mj jz oi ka ml kc oj kd mn mo bi translated">基准</h1><p id="7782" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">这篇帖子显示了三个基准的结果，这些结果来自2019年由罗伯特·西原<a class="ae kv" href="https://medium.com/@robertnishihara" rel="noopener">发表的关于雷<em class="lw"> </em>的</a><a class="ae kv" rel="noopener" target="_blank" href="/10x-faster-parallel-python-without-python-multiprocessing-e5017c93cce1">帖子</a>。为了使基准测试更加公平，我将客户端的启动和关闭调用添加到总基准测试时间中，并删除了代码来“预热”Ray <em class="lw"> </em>工作线程。后者本来是作者做的，因为初始内存访问比较慢。预热在实践中并不常见，无论如何，所有多处理库都会受到预热的影响。此外，我增加了每个基准测试的工作负载，并使其在不同数量的内核之间保持一致，以更好地了解增加更多工作人员的好处。最后，通过允许使用<code class="fe ls lt lu lv b"><a class="ae kv" href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing-managers" rel="noopener ugc nofollow" target="_blank">Manager</a></code> <em class="lw"> </em>对象，一些多处理实现得到了进一步优化。同样，这使得比较更加公平。</p><p id="abc2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">基准测试运行在一台具有20个内核的Linux机器上，禁用了超线程，内存为200GB(对于这些基准测试来说已经足够了)。对于每项任务，使用不同数量的流程/工人进行实验，结果在5次运行中取平均值。各个库和基准测试的计时是一致的，所以为了使图形不那么混乱，省略了误差线。所有基准代码都可以在<a class="ae kv" href="https://github.com/sybrenjansen/multiprocessing_benchmarks" rel="noopener ugc nofollow" target="_blank">这里</a>找到。查看<code class="fe ls lt lu lv b"><a class="ae kv" href="https://github.com/sybrenjansen/multiprocessing_benchmarks/blob/main/requirements.txt" rel="noopener ugc nofollow" target="_blank">requirements.txt</a></code> <em class="lw"> </em>文件，了解需要安装哪些依赖项。</p><h2 id="8b49" class="ni ly iq bd lz nj nk dn md nl nm dp mh lf nn no mj lj np nq ml ln nr ns mn nt bi translated">基准1:数字数据</h2><p id="23d5" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">该基准使用不同的图像过滤器处理图像。每个滤镜的图像保持不变。因此，能够以某种方式将图像发送给每个进程的库具有明显的优势。这在<code class="fe ls lt lu lv b">multiprocessing.Pool</code>中是不可能的，因为你需要求助于<code class="fe ls lt lu lv b">multiprocessing.Process</code> <em class="lw"> </em>并且自己处理所有的通信和启动/加入过程。不理想。对于MPIRE，代码如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="6925" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">就这么简单。该映像作为一个写时复制共享对象传递给每个进程，这意味着数据没有被复制，但底层内存被重用。只有当进程改变图像数据时，才会制作副本。在我们的例子中，这种情况不会发生，所以我们是安全的，处理将会很快。</p><p id="eb4a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">计时结果如下图所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/00fbb8203133d8f4b7f034aecd098efe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2IO6H7VY6H8BHyHqSl_F3w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="nx">数值计算基准测试结果平均超过5次运行。图片作者。</em></p></figure><p id="08d9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">multiprocessing.Pool</code>和<code class="fe ls lt lu lv b">ProcessPoolExecutor</code>明显表现不佳，我们认为为他们使用4名以上的工人没有额外的好处。每次发送图像显然会导致大量开销。另一方面，随着工作人员数量的增加，其他库的计算时间确实持续减少。当使用4个或更少的工人时，Joblib和Ray都比Dask和MPIRE慢一点，但之后它们会赶上来。最终，Joblib和MPIRE胜出，尽管差距很小。</p><p id="1f90" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个基准测试中，Joblib利用其<a class="ae kv" href="https://joblib.readthedocs.io/en/latest/parallel.html#automated-array-to-memmap-conversion" rel="noopener ugc nofollow" target="_blank"> NumPy内存映射特性</a>来加速重复共享相同的图像对象。禁用此项会显著增加Joblib的总时间。所以重要的是要记住，当你在一个不是NumPy数组的对象上做简单的计算时，Joblib不会那么快。</p><h2 id="4b09" class="ni ly iq bd lz nj nk dn md nl nm dp mh lf nn no mj lj np nq ml ln nr ns mn nt bi translated">基准2:有状态计算</h2><p id="d3fb" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">在第二个基准中，每个工作者跟踪自己的状态，并且应该在新任务到来时更新它。正如在<a class="ae kv" rel="noopener" target="_blank" href="/10x-faster-parallel-python-without-python-multiprocessing-e5017c93cce1">原始Ray <em class="lw"> </em> post </a>中一样，任务是处理文本文档并跟踪单词前缀计数——最多3个字符。每当某个前缀出现3次以上时，一旦处理完所有文档，就应该返回该前缀。</p><p id="b357" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">执行流前缀计数的简单类如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="1fe6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意:<code class="fe ls lt lu lv b">StreamingPrefixCount</code> <em class="lw"> </em>的这个实现类似于来自原始Ray <em class="lw"> </em> post的<em class="lw"> </em>，并不保证返回所有文档的正确前缀。然而，这在这种情况下并不重要，因为这个基准只是用来说明有状态计算。</p><p id="2246" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可以为每个工作人员存储本地数据，并在所有工作完成后返回数据的库显然最适合这项任务。支持这一点的库有Dask、Ray和MPIRE。<a class="ae kv" href="https://distributed.dask.org/en/latest/actors.html" rel="noopener ugc nofollow" target="_blank"> Dask </a>和<a class="ae kv" href="https://docs.ray.io/en/master/actors.html" rel="noopener ugc nofollow" target="_blank"> Ray </a>都支持<code class="fe ls lt lu lv b">Actors</code>，支持有状态计算。然而，对Dask来说，这种支持似乎是实验性的，我无法让它在不崩溃的情况下工作。为了避免使用<code class="fe ls lt lu lv b">Actors</code> <em class="lw"> </em>，我使用了<code class="fe ls lt lu lv b">get_worker</code>，并在最后发送了一个特殊的哨兵令牌来收集结果。它并不漂亮，但很管用。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="42a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于Ray来说，<code class="fe ls lt lu lv b">Actor</code> <em class="lw"> </em>功能运行良好。人们可以使用<code class="fe ls lt lu lv b">ActorPool</code> <em class="lw"> </em>来很好地分配工作量:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="335a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于MPIRE，我们可以利用<a class="ae kv" href="https://slimmer-ai.github.io/mpire/usage/workerpool/worker_state.html" rel="noopener ugc nofollow" target="_blank"> </a> <code class="fe ls lt lu lv b"><a class="ae kv" href="https://slimmer-ai.github.io/mpire/usage/workerpool/worker_state.html" rel="noopener ugc nofollow" target="_blank">worker_state</a></code>和<code class="fe ls lt lu lv b"><a class="ae kv" href="https://slimmer-ai.github.io/mpire/usage/map/worker_init_exit.html" rel="noopener ugc nofollow" target="_blank">worker_exit</a></code>功能。在这种情况下，我们还可以利用写入时拷贝:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="2730" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与其他库相比，样板代码的数量有限。与Ray一样，还有一个额外的好处，即负载会自动在工作人员之间进行平衡。</p><p id="25a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">multiprocessing.Pool</code>、<code class="fe ls lt lu lv b">ProcessPoolExecutor</code>和Joblib对worker状态没有支持，需要依赖Python <code class="fe ls lt lu lv b">Manager</code>对象。使用<code class="fe ls lt lu lv b">Manager</code>对象的缺点是它们存在于独立的服务器进程中，任何状态变化都必须通过代理传递给它们。因此，这些库的性能受到了很大的影响，与串行处理相比，性能更差。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/4d649d907fb9f0358b1aec45cf214e16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mGq_jI7f8mae_zWCsSm5Cg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="nx">5次运行的平均有状态计算基准测试结果。图片作者。</em></p></figure><p id="e462" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">串行处理的时间在这里有一点波动，尽管它只能利用一个工作线程。对于这个基准测试，每个工作者都有自己的状态，并保持本地前缀计数。为了使比较公平串行处理还利用了多个<code class="fe ls lt lu lv b">StreamingPrefixCount</code> <em class="lw"> </em>对象，等于工人的数量。</p><p id="fb3e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从结果来看，Dask在速度上显然很难赶上Ray和MPIRE。如果Dask要修复他们的<code class="fe ls lt lu lv b">Actor</code> <em class="lw"> </em>实现，可能会不相上下。雷和姆皮尔的表现差不多。虽然，MPIRE一直比它快一点点，但差距很小。</p><h2 id="d483" class="ni ly iq bd lz nj nk dn md nl nm dp mh lf nn no mj lj np nq ml ln nr ns mn nt bi translated">基准3:昂贵的初始化</h2><p id="2b56" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">在该基准中，神经网络模型用于预测图像数据集上的标签。(注:为了简单起见，反复使用同一个数据集进行预测。)加载这个模型只需要几秒钟。但是如果每项任务都需要这样做，那么时间会很快增加。虽然这个基准看起来与前面的例子相似，但是这个基准不需要跟踪工作状态的变化。</p><p id="18fa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于下面的代码片段，假设我们有一个<code class="fe ls lt lu lv b">Model</code> <em class="lw"> </em>类，它在创建时加载到模型和数据集中。对于<code class="fe ls lt lu lv b">multiprocessing.Pool</code>，代码如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="20b8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于MPIRE，我们再次利用<code class="fe ls lt lu lv b"><a class="ae kv" href="https://slimmer-ai.github.io/mpire/usage/workerpool/worker_state.html" rel="noopener ugc nofollow" target="_blank">worker_state</a></code>。这一次，我们还使用了<code class="fe ls lt lu lv b"><a class="ae kv" href="https://slimmer-ai.github.io/mpire/usage/map/worker_init_exit.html" rel="noopener ugc nofollow" target="_blank">worker_init</a></code>功能:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="9f60" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以在这里再次利用写时复制，但是Tensorflow模型在这样做的时候并不好用。然而，使用<code class="fe ls lt lu lv b">worker_init</code>功能也一样快。注意，我们将<code class="fe ls lt lu lv b">keep_alive</code>设置为<code class="fe ls lt lu lv b">True</code>。默认情况下，MPIRE会在一次<code class="fe ls lt lu lv b">map</code>调用后关闭工作线程，以减少内存需求。由于MPIRE启动和停止工作线程的速度非常快，而Python可能非常需要内存(它倾向于将分配的内存保持在备用状态)，这通常是所希望的行为。然而，在这种情况下，我们不希望每次运行都重新加载模型，所以我们保留了工作线程。方便的是，当退出上下文管理器时，它们会自动关闭。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/c1dcffec8a9d6badb039b77fa3298cfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QMSOOzjYcIPVPF8X7U9lMw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="nx">昂贵的初始化基准测试结果平均超过5次运行。图片作者。</em></p></figure><p id="8c95" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Joblib和Dask一开始都表现不错，但很快被Ray和MPIRE超越。<code class="fe ls lt lu lv b">multiprocessing.Pool</code>和<code class="fe ls lt lu lv b">ProcessPoolExecutor</code>似乎在最后赶上了，但是你必须意识到，如果加载模型的时间增加，它们之间的差异——以及像Ray和MPIRE这样的库——也会增加。</p><h2 id="1d33" class="ni ly iq bd lz nj nk dn md nl nm dp mh lf nn no mj lj np nq ml ln nr ns mn nt bi translated">总体基准性能</h2><p id="d2bf" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">当将基准计时标准化到0–1的范围并取平均值时，我们看到以下趋势:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/747601338c3dacb5e0e2e26e486c16c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a5mcK_T2Np9UJBVVQEmEQQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="nx">平均归一化基准结果。图片作者。</em></p></figure><p id="1ca0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所有多处理库都可以超越单核性能，这是关键所在。Joblib明显优于<code class="fe ls lt lu lv b">multiprocessing.Pool</code>和<code class="fe ls lt lu lv b">ProcessPoolExecutor</code>，反过来Dask也击败了Joblib，因为它有存储状态的能力。MPIRE和Ray的性能甚至比Dask还要好，是首选。</p><p id="d54d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然Ray和MPIRE的速度差不多，但是当您只能在一台计算机上使用时，MPIRE的易用性使其成为更有趣的库。</p></div><div class="ab cl ny nz hu oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="ij ik il im in"><h1 id="9794" class="lx ly iq bd lz ma of mc md me og mg mh jw oh jx mj jz oi ka ml kc oj kd mn mo bi translated">摘要</h1><p id="fa87" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">这篇博客文章介绍了MPIRE，这是一个用于Python的多处理库，它易于使用，包含许多特性，并且在速度方面一直胜过所有其他的多处理库。</p><p id="d95a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">MPIRE不仅具有直观的Pythonic语法，还具有本机进度条支持和用户友好的异常回溯。后者将减少您的调试时间，并让您的注意力集中在重要的地方:尽可能快速地执行您的工作。</p><p id="0816" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你发现MPIRE是一个对你自己的工作有价值的多重处理工具，我很乐意听到你的意见。我希望它为你提供效率收益，就像它为我们在Slimmer AI提供的一样。</p></div></div>    
</body>
</html>