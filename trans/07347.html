<html>
<head>
<title>Relighting and Material Editing with Implicit Representations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用隐式表示进行重新照明和材质编辑</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/relighting-and-material-editing-with-implicit-representations-cc967818b3c0?source=collection_archive---------22-----------------------#2021-07-04">https://towardsdatascience.com/relighting-and-material-editing-with-implicit-representations-cc967818b3c0?source=collection_archive---------22-----------------------#2021-07-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="f702" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><div class=""><h2 id="a546" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated"><em class="ko">了解我们如何为使用像NeRF </em>这样的隐式表示的场景添加重新光照和材质编辑功能</h2></div><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/2d1654a70ea1c25faaf8ec3b4f3a1e24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HAvWcluWmVMSo79d"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">照片由<a class="ae lf" href="https://unsplash.com/@samimatias?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">萨米·塔卡劳蒂奥</a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="95c2" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">计算机视觉最大的挑战之一是从图像中学习场景。如果我们能理解这个场景并以某种方式表现出来，我们就能从新的角度来观察这个场景。这被称为基于图像的渲染(IBR)。</p><p id="d075" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">想法是从2D图像生成3D重建并生成独特的视图。此外，如果我们希望在其他属性中检索场景的材质和照明，这被称为反向渲染。</p><p id="4dfd" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">有许多不同的方法来表示3D对象。经典方法包括将其表示为网格、体素或点云。这些年来已经被广泛研究，并且有它们的优点和缺点。典型地，它们是内存密集型的，并且不能表现非常详细的对象/场景，或者需要很多计算。虽然点云可以很好地缩放，但它们通常会因定义表面而变得不稳定。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi mc"><img src="../Images/83449af2e12c7618b2cf64b779b165ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MNKEj15hjHDhXn6bXHBBfw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">表来自<a class="ae lf" href="https://arxiv.org/pdf/2006.12057.pdf" rel="noopener ugc nofollow" target="_blank">可区分渲染:调查</a></p></figure><p id="2bc7" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们讨论一类新的表示法，叫做隐含表示法，它因为所有正确的理由而制造了许多噪音。其中之一被称为非常著名的神经辐射场或NeRF，仅在去年一年就产生了15-20种变体。NeRF非常擅长表现整个场景，并且可以从任何角度观看。然而，我们不能以任何方式编辑场景。因此，我们进一步研究了在使用NeRF作为场景表示时可以执行重新照明和材质编辑的变体。</p><h1 id="024b" class="md me iq bd mf mg mh mi mj mk ml mm mn kf mo kg mp ki mq kj mr kl ms km mt mu bi translated">隐性表征</h1><p id="29a9" class="pw-post-body-paragraph lg lh iq li b lj mv ka ll lm mw kd lo lp mx lr ls lt my lv lw lx mz lz ma mb ij bi translated">最近出现了一种新的表示法，称为隐式表示法。区别主要在于，我们在这里学习一个描述几何的函数。例如，对于一个圆，隐式方程是f(x，y) = x +y -R，其中R是圆的半径。对于任意一点(x，y)，我们知道它是在圆上，在圆内，还是在圆外。因此，给定许多点及其相对于圆的位置信息，我们可以估计圆的半径。</p><p id="08cb" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">类似地，我们也将同样的想法扩展到3D。我们知道点是在一个特定的表面之上、之内还是之外，因此我们可以估计我们的物体表面。还有什么比神经网络更好的函数逼近器呢，神经网络是“通用函数逼近器”</p><p id="b7a5" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">根据我们想要如何渲染场景，有两类隐式表示。表面表示旨在找到对象的表面和相应的颜色。相比之下，体积表示并不明确地寻找表面，而是尝试对该点的深度及其相应的颜色进行建模。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi na"><img src="../Images/737974120b2c01fb8053e94e041e1e9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*qHi8qs2tw09f6AQegJFVpw.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><a class="ae lf" href="https://arxiv.org/pdf/1812.03828.pdf" rel="noopener ugc nofollow" target="_blank">占位网络:学习功能空间中的3D重建</a></p></figure><p id="f984" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">隐式表面表示包括占用网络和带符号的距离场(SDF)。这里的想法是，我们有一个神经网络，它预测给定点相对于对象的位置，即，它是在表面上，在对象内部，还是在对象外部。因此，当我们发射一束光线并在其上采样点时，网络会学习它们相对于物体的位置。利用这一点，我们可以对更接近表面的点进行采样，并找到表面。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nb"><img src="../Images/f911e87964643b61af07b321b80f346d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f-0qxl1_LoMDwzGmVF0w_Q.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><a class="ae lf" href="https://arxiv.org/pdf/1901.05103" rel="noopener ugc nofollow" target="_blank"> DeepSDF:学习用于形状表示的连续符号距离函数</a></p></figure><p id="8405" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">占位网络和带符号距离场的主要区别在于占位网络给出的是二元答案。如果点在外面，那么它是0，如果在里面，它是1，在表面上，值是0.5。另一方面，带符号的距离字段给出了点到表面的距离。因此，我们的工作是找出满足f(x) = 0的所有点。我们在物体内部得到正值，在外部得到负值。我们可以用光线行进法或球体追踪法找到这些表面。类似地，可以通过特定3D点的网络输出来找到表面的颜色。虽然它们非常有名，但它们只在光线可以与表面相互作用的地方工作。</p><p id="cbe9" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">其他作品使用隐式表面表示，如<a class="ae lf" href="https://arxiv.org/abs/1906.01618" rel="noopener ugc nofollow" target="_blank"> SRN </a>、<a class="ae lf" href="https://arxiv.org/abs/1912.07372" rel="noopener ugc nofollow" target="_blank">可微分体绘制</a>、<a class="ae lf" href="https://arxiv.org/abs/1905.05172" rel="noopener ugc nofollow" target="_blank">皮夫</a>等。</p><h1 id="a781" class="md me iq bd mf mg mh mi mj mk ml mm mn kf mo kg mp ki mq kj mr kl ms km mt mu bi translated">（把汽车拆卸减重后举行的短程高速驾驶比赛中）冲撞别的汽车</h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nc"><img src="../Images/c37d9656921c29a45406048e82e6a281.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j50Lluh3ihh_QeXwHFoDRA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><a class="ae lf" href="https://arxiv.org/pdf/2003.08934" rel="noopener ugc nofollow" target="_blank"> NeRF:将场景表示为用于视图合成的神经辐射场</a></p></figure><p id="8edb" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们可以执行体绘制，而不是找到所有对象的表面。这就是NeRF及其变体出现的原因。这个想法是，我们不是学习一个表面，而是学习整个体积，不仅包括物体，还包括介质的影响。Neural Volumes是第一批对场景进行编码的作品之一，但它是以不可缩放的基于体素的表示进行编码的。</p><p id="41f4" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">另一方面，NeRF使用MLPs对场景进行编码。对于从每个像素发出的光线，我们对光线上的点进行采样。现在每个点都有一个3D位置和相应的观察方向。我们传递这个5D向量，并获得相应的颜色和体积深度。我们对光线上的所有样本都这样做，然后将它们合成在一起，得到一个像素颜色。NeRF有两个网络，一个是粗略的，它在光线上均匀地采样点，另一个是精细的网络，它做的一切都一样，除了我们使用重要性采样。这意味着我们对更有深度的点，也就是物体，进行更多的采样。采用观察方向有助于对依赖于观察的效果进行建模，例如镜面效果，例如光亮表面的反射[1]。合成这些信息使用经典的体绘制技术，这给了我们最终的图像。</p><p id="e743" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">到目前为止，我们读到的方法可以很好地表示场景的几何形状，并且以一种合理的内存高效的方式。然而，正如我们注意到的，这些方法直接学习和预测表面或场景的特定点的颜色。因此，它直接烘烤的材料和照明效果，我们不能编辑。因此，虽然这些网络可以很好地执行视图合成，但它们不能改变场景中的照明或对象的材质。</p><h1 id="2fdb" class="md me iq bd mf mg mh mi mj mk ml mm mn kf mo kg mp ki mq kj mr kl ms km mt mu bi translated">渲染方程</h1><p id="1241" class="pw-post-body-paragraph lg lh iq li b lj mv ka ll lm mw kd lo lp mx lr ls lt my lv lw lx mz lz ma mb ij bi translated">在我们继续之前，让我们了解计算机图形如何建模材料和照明。考虑一个有一个光源、一些物体和一个照相机的场景。现在我们想知道物体上的一个点是什么样子的。我们可以用一些古老的物理学来计算这个。通过利用能量平衡，在某一特定点我们可以说[6]:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/8969aa1e967f9eeb7e16e444c8d06baa.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/1*W2O0KQEyA4g0O9W6J_9__A.gif"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">功率守恒方程</p></figure><p id="85e3" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">即离开物体的能量和进入物体的能量之差，等于物体发出的能量和吸收的能量之差。为了加强表面的能量平衡，出射辐射Lo必须等于发射辐射加上散射入射辐射的分数[6]。发射辐射由Le给出，散射辐射由散射方程给出，该方程给出</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ne"><img src="../Images/258c78e358501ba836d67f14647845d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZTdAHoFRopDjkw10wrrMrw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">来自<a class="ae lf" href="https://twitter.com/levork/status/609603797258600448" rel="noopener ugc nofollow" target="_blank">源</a>的渲染方程</p></figure><p id="7223" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">不要担心它看起来太专业。在一个特定的点上，我们总结了整个半球反射光的贡献。因子f被称为双向反射分布函数或BRDF，它告诉我们特定材料会反射和吸收多少功率。BRDF告诉我们一种材料的特性。BRDF有很多模式，像库克-托兰斯，迪士尼等。如果BRDF对于每个点都是不同的，比如在一个纹理中，我们称之为空间变化BRDF或SVBRDF。</p><p id="d603" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">还有另一个版本叫做渲染方程的表面版本，我们将来也会提到它:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nf"><img src="../Images/277de0582208bb82e83c00840167b506.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VrBkegSKDDeiYLeePdHgzA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">渲染方程的曲面形式</p></figure><p id="17fb" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">这里p '是我们的表面，p是观察者表面或相机。“p”是光线照射的表面，A是所有的表面。g是几何耦合项，代表:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/82e5c23efed34c5c804d8c0c6563c81d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*cfAhVWkt_7o4WEafsvga5w.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">几何耦合项</p></figure><p id="5110" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">v是可见度函数，它是能看到彼此的表面之一。</p><p id="7cb3" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">既然我们已经了解了材质和照明是如何建模的，我们就可以理解在隐式表示中赋予我们材质和照明编辑能力的各种工作思路。</p><h1 id="df87" class="md me iq bd mf mg mh mi mj mk ml mm mn kf mo kg mp ki mq kj mr kl ms km mt mu bi translated">神经</h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nh"><img src="../Images/566b602818db4f62f6fe5562178dd1d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GxIGBtL0n_PvAE0Q0UXrTw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><a class="ae lf" href="https://arxiv.org/abs/2012.03927" rel="noopener ugc nofollow" target="_blank">神经:用于重新照明和视图合成的神经反射和可见度场</a></p></figure><p id="e9ea" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">用于重新照明和视图合成的神经反射和可见性场或神经尝试使用多个点光源重新照明场景。在NeRF中，我们假设光线上采样的点都不反射光线。然而，由于我们想执行重新照明，我们需要模拟每个点对直接和间接照明的反应。因此，现在我们需要计算每个点的反射率函数，而不是每个点都是一个发射器。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ni"><img src="../Images/d8f3fc783de470a07d9c9a32db36746a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jp_NtSfb9p_1n3iXh4UxEA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">从<a class="ae lf" href="https://youtu.be/4XyDdvhhjVo?t=61" rel="noopener ugc nofollow" target="_blank">源</a>看，每个点都是一个反射场</p></figure><p id="8290" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">因此，首先，用两个MLP替换NeRF的辐射MLP:输出体积密度σ的“形状”MLP和输出任何输入3D点的BRDF参数的“反射”MLP。该方法使用的BRDF模型用三维反照率矢量和粗糙度常数对其建模。</p><p id="aa4c" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">现在，我们可以沿着光线解析地计算每个点的反射函数。我们需要查询光线在击中一个点后击中的每个对应点的可见性。但是，这种操作非常非常昂贵，而且这只是为了直接照明。对于间接照明，我们需要递归地做同样的事情。因此，相反，我们做的是我们有一个能见度MLP和距离MLP。可见性MLP计算给定点的可见性因子，而距离MLP计算一次反弹后光线的终止点。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nj"><img src="../Images/bead435c4d7913fe336e4209f39ce687.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K2UDW67j6vJ-bM8z6BaWeQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">来自<a class="ae lf" href="https://arxiv.org/pdf/2012.03927" rel="noopener ugc nofollow" target="_blank">源</a>的神经素材编辑结果</p></figure><p id="6f3c" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">总而言之，事情是这样的:</p><ul class=""><li id="572d" class="nk nl iq li b lj lk lm ln lp nm lt nn lx no mb np nq nr ns bi translated">对每条光线进行采样，并查询体积密度、曲面法线和BRDF参数的形状和反射率MLP</li><li id="b583" class="nk nl iq li b lj nt lm nu lp nv lt nw lx nx mb np nq nr ns bi translated">用直射光给光线上的每个点着色。通过使用由每个采样点的相应MLP预测的能见度和BRDF值来计算。</li><li id="6ef3" class="nk nl iq li b lj nt lm nu lp nv lt nw lx nx mb np nq nr ns bi translated">用间接照明给光线上的每个点加阴影。使用预测的终点，然后通过沿该射线采样并结合每个点的贡献来计算其效果。</li><li id="27cb" class="nk nl iq li b lj nt lm nu lp nv lt nw lx nx mb np nq nr ns bi translated">像在NeRF中一样组合所有这些量来得到结果</li></ul><p id="722a" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">NeRV设计用于精确处理多个点光源。培训是计算密集型的。一旦训练完毕，我们就可以修改BRDF参数，并对整个场景进行材质编辑。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/724ecd16d883a09102a7bc1bd664496b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*raXFFsy8YVCGa2smb9djbw.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">来自<a class="ae lf" href="https://arxiv.org/pdf/2012.03927" rel="noopener ugc nofollow" target="_blank">的神经重新点燃结果来源</a></p></figure><blockquote class="nz oa ob"><p id="b62f" class="lg lh oc li b lj lk ka ll lm ln kd lo od lq lr ls oe lu lv lw of ly lz ma mb ij bi translated">TLDR；NeRV使用形状MLP来预测体积，使用BRDF MLP来预测反照率和粗糙度，使用可见度MLP来预测每个点的可见度，使用距离MLP来预测一次反弹后光线的终止。结果通过每个点的渲染方程进行组合，然后像NeRF一样使用经典的体积渲染技术合成在一起。</p></blockquote><h1 id="0917" class="md me iq bd mf mg mh mi mj mk ml mm mn kf mo kg mp ki mq kj mr kl ms km mt mu bi translated">缺乏社交能力者</h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi og"><img src="../Images/2ec7ab8ab2b9f8c7ba67bc046d8ef475.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VOX_6hvJRo5Zx6yoZlYWQQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><a class="ae lf" href="https://arxiv.org/pdf/2012.03918" rel="noopener ugc nofollow" target="_blank"> NeRD:来自图像集合的神经反射分解</a></p></figure><p id="016f" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">神经反射分解(NeRD)将基于物理的渲染或PBR整合到了NeRF框架中。如前所述，一个点的颜色是入射光和SVBRDF乘积在半球上的积分。一个点可能由于材质、遮挡或者表面法线指向远处而变暗[3]。所有这些因素都没有被NeRF考虑在内，因为它在辐射中烘烤。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oh"><img src="../Images/06c38350589a9f92c3255df478e4e788.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8YPBnkTo1OfWhV0sCkpy4w.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">书呆子网来自<a class="ae lf" href="https://arxiv.org/abs/2012.03918" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="8b40" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">NeRD有两个MLP，即采样MLP和分解MLP。采样MLP输出独立于视图但依赖于照明的颜色和场景的体积密度。像NeRF一样，在这个网络中，光线上的点是均匀采样的，体积密度用于第二个网络中对象上的重要采样点。采样网络中的最后一个要素是特定图像的照明。我们不传递环境光，而是传递它的球面高斯表示。球面高斯类似于2D的傅立叶变换。我们这样做的原因是我们不能解析地计算渲染方程。因此，我们把它转换成球面高斯形式，积分转换成乘积运算。现在我们可以快速地计算这个方程。因此，我们从采样网络中学习照明、音量和照明颜色。</p><p id="9f26" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">分解网络扩展了NeRF的第二个网络。除了颜色和体积密度，我们还计算一个向量，并将其传递给另一个小的自动编码器，以输出对象的BRDF参数。这里，BRDF参数不同于NeRV，因为模型输出反照率、金属和粗糙度。自动编码器可以优化训练并提高结果。最后，我们像NeRF一样组合输出，并通过经典的体绘制来输出图像。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oi"><img src="../Images/87f924fd9cc9bb7f845f9a83f8b3cd79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IByPHqDN60UmXyIz3KHUSw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">书呆子结果来自<a class="ae lf" href="https://arxiv.org/pdf/2012.03918" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="28d6" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">NeRD使场景视图的颜色独立，并学习照明和BRDF属性。一旦学会，建模重新照明是简单的，因为我们知道照明是如何组合起来产生颜色的。</p><blockquote class="nz oa ob"><p id="364b" class="lg lh oc li b lj lk ka ll lm ln kd lo od lq lr ls oe lu lv lw of ly lz ma mb ij bi translated">TLDR；NeRD分解场景，分别学习场景的光照和BRDF参数。NeRF的两个网络被增强以学习独立于视图和依赖于照明的颜色，并且一旦被训练，执行重新照明是简单的。</p></blockquote><h1 id="5390" class="md me iq bd mf mg mh mi mj mk ml mm mn kf mo kg mp ki mq kj mr kl ms km mt mu bi translated">神经因素</h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oj"><img src="../Images/61d813e6c4501e19d5f0a07fb81310fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oxJ9RUU7I1EkVRoKkkJdvA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><a class="ae lf" href="https://arxiv.org/pdf/2106.01970" rel="noopener ugc nofollow" target="_blank">神经因子:未知光照下形状和反射率的神经因子分解</a></p></figure><p id="1671" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">NeRFactor与我们迄今为止看到的所有作品都非常不同，因为它提炼了经过训练的NeRF模型，这是迄今为止该领域中没有其他作品做到的，因为NeRF在整个体积上工作，而它在表面点上工作。它可以执行自由视点重新照明以及材质编辑。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/c52576e466d4cd3e2d629f2beec708de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*Gq2kAkeq3w1BIYxFz2B93A.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">神经因素网络来自<a class="ae lf" href="https://arxiv.org/pdf/2106.01970" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="14ff" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">首先，我们在现场训练一个NeRF网络。然后，我们保留粗网络并冻结其权重。然后，我们在MERL数据集上训练一个BRDF MLP。MERL数据集包含100种不同材料的反射率函数。然后，我们使用来自预训练的NeRF的预测体积来初始化法线贴图和可见性贴图。这些图非常嘈杂，因此我们没有冻结它们，而是将它们作为初始化。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ol"><img src="../Images/a64cee0c0aa57066dd82e5d46eecc754.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6lE-ZIXyv1eFVEkm9hl-0A.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">来源于<a class="ae lf" href="https://arxiv.org/pdf" rel="noopener ugc nofollow" target="_blank">的神经因子结果</a></p></figure><p id="6049" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">现在我们首先预测光线将在哪里照射到表面。使用它作为输入，我们训练4个MLP，即光能见度MLP、BRDF识别MLP、反照率MLP和正常MLP。因为我们已经初始化了可见性和法线，所以它们被称为预训练。现在我们输入表面点并得到输出。BRDF MLP输出将用于素材编辑的潜在向量z。反照率网络处理漫反射颜色分量。我们还估计每个表面点的照明。NeRFactor可以通过显式建模灯光可见性来分离阴影和反照率，并在任意光照条件下合成逼真的软阴影或硬阴影。所有的输出然后像在NeRF中一样被组合，并使用经典的体积渲染进行渲染。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi om"><img src="../Images/32cac7bbc127ddfef80dd308fe301231.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZUYFj3R7gESORZ4EELJaUQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">来自<a class="ae lf" href="https://arxiv.org/pdf" rel="noopener ugc nofollow" target="_blank">的神经因子重新点燃结果来源</a></p></figure><p id="e88e" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">NeRFactor不能预测BRDF参数。相反，它学习一个潜在的向量，可以很容易地用于渲染材料编辑。最重要的是，它不是在体积的任何地方取点，而是只在物体的表面取点。</p><blockquote class="nz oa ob"><p id="652d" class="lg lh oc li b lj lk ka ll lm ln kd lo od lq lr ls oe lu lv lw of ly lz ma mb ij bi translated">TLDR；NerFactor使用经过训练的NeRF来初始化法线和可见度图，并使用经过训练的BRDF MLP来学习潜在向量表示。然后，它搜索物体表面上的点，并学习其各种参数。学习后，我们可以进行重新光照和材质编辑。</p></blockquote><h1 id="a3c2" class="md me iq bd mf mg mh mi mj mk ml mm mn kf mo kg mp ki mq kj mr kl ms km mt mu bi translated">外卖食品</h1><p id="004b" class="pw-post-body-paragraph lg lh iq li b lj mv ka ll lm mw kd lo lp mx lr ls lt my lv lw lx mz lz ma mb ij bi translated">我们通过三种方法让NeRF至少有了重新点燃的能力。NeRV通过计算每个点的直接和间接照明的效果来实现这一点，并使用MLP近似可见性和光线终止。另一方面，NeRFactor通过首先找到对象的表面进行分解，然后学习照明和BRDF参数(在这种情况下，是一种潜在的矢量表示)。NeRD处于中间位置，其分解网络使用加权采样计算对象的表面法线，并使用它来渲染场景，但仍然对体积中的所有点运行。</p><p id="2004" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们注意到，越来越多的方法倾向于表面表现，以获得对场景编辑的更多控制，因为我们并不太关心介质会发生什么。很兴奋看到这个领域将会把两篇论文带向哪个方向。</p><h1 id="9992" class="md me iq bd mf mg mh mi mj mk ml mm mn kf mo kg mp ki mq kj mr kl ms km mt mu bi translated">参考</h1><p id="742f" class="pw-post-body-paragraph lg lh iq li b lj mv ka ll lm mw kd lo lp mx lr ls lt my lv lw lx mz lz ma mb ij bi translated">[1] <a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mildenhall%2C+B" rel="noopener ugc nofollow" target="_blank">本·米尔登霍尔</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srinivasan%2C+P+P" rel="noopener ugc nofollow" target="_blank">普拉图尔·p·斯里尼瓦桑</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tancik%2C+M" rel="noopener ugc nofollow" target="_blank">马修·坦西克</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barron%2C+J+T" rel="noopener ugc nofollow" target="_blank">乔纳森·t·巴伦</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ramamoorthi%2C+R" rel="noopener ugc nofollow" target="_blank">拉维·拉马穆尔蒂</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ng%2C+R" rel="noopener ugc nofollow" target="_blank">任·吴</a>，<a class="ae lf" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank">内尔夫:将场景表示为用于视图合成的神经辐射场</a>【2020 ECCV】</p><p id="c763" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">[2] <a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srinivasan%2C+P+P" rel="noopener ugc nofollow" target="_blank">普拉图尔·p·斯里尼瓦桑</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+B" rel="noopener ugc nofollow" target="_blank">柏杨·邓</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X" rel="noopener ugc nofollow" target="_blank">张秀明</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tancik%2C+M" rel="noopener ugc nofollow" target="_blank">马修·坦西克</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mildenhall%2C+B" rel="noopener ugc nofollow" target="_blank">本·米尔登霍尔</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barron%2C+J+T" rel="noopener ugc nofollow" target="_blank">乔纳森·t·巴伦</a>，<a class="ae lf" href="https://arxiv.org/abs/2012.03927" rel="noopener ugc nofollow" target="_blank">神经:用于重新照明和视图合成的神经反射和可见度场</a>【2021】CVPR</p><p id="0f57" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">[3] <a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boss%2C+M" rel="noopener ugc nofollow" target="_blank">马克·博斯</a>、<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Braun%2C+R" rel="noopener ugc nofollow" target="_blank">拉斐尔·布劳恩</a>、<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jampani%2C+V" rel="noopener ugc nofollow" target="_blank">瓦伦·詹帕尼</a>、<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barron%2C+J+T" rel="noopener ugc nofollow" target="_blank">乔纳森·t·巴伦</a>、<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+C" rel="noopener ugc nofollow" target="_blank">刘策</a>、<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lensch%2C+H+P" rel="noopener ugc nofollow" target="_blank">亨德里克P.A伦施</a>、<a class="ae lf" href="https://arxiv.org/abs/2012.03918" rel="noopener ugc nofollow" target="_blank">讷德:来自图像集合的神经反射分解</a>、【2021 arxiv】</p><p id="818b" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">[4] <a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X" rel="noopener ugc nofollow" target="_blank">张秀明</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Srinivasan%2C+P+P" rel="noopener ugc nofollow" target="_blank">普拉图尔·p·斯里尼瓦桑</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Deng%2C+B" rel="noopener ugc nofollow" target="_blank">柏杨·邓</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Debevec%2C+P" rel="noopener ugc nofollow" target="_blank">保罗·德贝维奇</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Freeman%2C+W+T" rel="noopener ugc nofollow" target="_blank">威廉·t·弗里曼</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barron%2C+J+T" rel="noopener ugc nofollow" target="_blank">乔纳森·t·巴伦</a>，<a class="ae lf" href="https://arxiv.org/abs/2106.01970" rel="noopener ugc nofollow" target="_blank">神经因子:未知光照下形状和反射率的神经因子分解</a>【2021 arxiv】</p><p id="2c51" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">[5] <a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kato%2C+H" rel="noopener ugc nofollow" target="_blank">加藤广治</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Beker%2C+D" rel="noopener ugc nofollow" target="_blank">德尼兹·贝克</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Morariu%2C+M" rel="noopener ugc nofollow" target="_blank">米哈伊·莫拉里乌</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ando%2C+T" rel="noopener ugc nofollow" target="_blank">田崎敬浩·安藤</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Matsuoka%2C+T" rel="noopener ugc nofollow" target="_blank">松冈彻</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kehl%2C+W" rel="noopener ugc nofollow" target="_blank">瓦迪姆·凯尔</a>，<a class="ae lf" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gaidon%2C+A" rel="noopener ugc nofollow" target="_blank">阿德里安·盖登</a>，<a class="ae lf" href="https://arxiv.org/abs/2006.12057" rel="noopener ugc nofollow" target="_blank">可微分渲染:综述</a>【2020 arxiv】</p><p id="1b5c" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">[6]马特·法尔，文泽尔·雅各布，格雷格·汉弗莱斯，<a class="ae lf" href="https://pbr-book.org/" rel="noopener ugc nofollow" target="_blank">基于物理的渲染:从理论到实现</a></p><p id="a5ed" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">[7]弗兰克·德拉雷特，<a class="ae lf" href="https://dellaert.github.io/NeRF/" rel="noopener ugc nofollow" target="_blank"> NeRF爆炸2020 </a></p><p id="ed4c" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">[8]李泽宇，<a class="ae lf" href="http://viclw17.github.io/2018/06/30/raytracing-rendering-equation/" rel="noopener ugc nofollow" target="_blank">光线追踪——渲染方程式洞察</a></p></div></div>    
</body>
</html>