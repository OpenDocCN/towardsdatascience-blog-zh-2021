<html>
<head>
<title>Using Sklearn Pipelines to Streamline your Machine Learning Process</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Sklearn 管道简化您的机器学习过程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-sklearn-pipelines-to-streamline-your-machine-learning-process-a27721fdff1b?source=collection_archive---------16-----------------------#2021-12-21">https://towardsdatascience.com/using-sklearn-pipelines-to-streamline-your-machine-learning-process-a27721fdff1b?source=collection_archive---------16-----------------------#2021-12-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c887" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解 Pipeline 类如何简化和自动化您的机器学习工作流</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2ed2b43fc7cbabb06c8d7af03ac8c3fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uiSCm89F2SNKd_Fo"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@xoforoct?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">EJ·斯特拉特</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="9503" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">机器学习通常涉及多个步骤——加载数据、可视化数据、拆分数据、预处理数据，然后最终用训练数据训练模型。所有这些步骤都必须按顺序进行，我们通常在 Jupyter Notebook 中按顺序执行所有这些步骤。在你知道它之前，它是一个混乱的地狱，代码片段分散在不同的单元格中。然而，所有这些都可以使用 sklearn 的<code class="fe lv lw lx ly b">Pipeline</code>类来简化，该类旨在提供一种自动化机器学习工作流的方法。</p><p id="c164" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我将向你解释如何使用 sklearn <code class="fe lv lw lx ly b">Pipeline</code>来定义和自动化你的机器学习工作流。</p><h1 id="3deb" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">执行机器学习</h1><p id="d253" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li mt lk ll lm mu lo lp lq mv ls lt lu im bi translated">在我们讨论如何使用 sklearn 的管道来简化机器学习过程之前，我们先来看看在数据集上执行机器学习的典型步骤。这样，您将更好地理解为什么使用管道进行机器学习是有用的。</p><h2 id="fc69" class="mw ma it bd mb mx my dn mf mz na dp mj li nb nc ml lm nd ne mn lq nf ng mp nh bi translated">加载数据</h2><p id="3c66" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li mt lk ll lm mu lo lp lq mv ls lt lu im bi translated">首先要做的是加载数据。对于本文，我们将使用流行的泰坦尼克号数据集，我们将从 ka ggle(<a class="ae ky" href="https://www.kaggle.com/c/titanic/data?select=train.csv" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/titanic/data?select=train.csv</a>)下载该数据集:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="34ff" class="mw ma it ly b gy nm nn l no np">import pandas as pd<br/>import numpy as np</span><span id="ca57" class="mw ma it ly b gy nq nn l no np">df = pd.read_csv('<a class="ae ky" href="https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/train.csv'" rel="noopener ugc nofollow" target="_blank">train.csv'</a>)</span><span id="4138" class="mw ma it ly b gy nq nn l no np">display(df)</span></pre><blockquote class="nr ns nt"><p id="4bd6" class="kz la nu lb b lc ld ju le lf lg jx lh nv lj lk ll nw ln lo lp nx lr ls lt lu im bi translated"><strong class="lb iu">数据来源</strong>:本文数据来源于<a class="ae ky" href="https://www.kaggle.com/c/titanic/data" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/titanic/data</a><a class="ae ky" href="https://www.kaggle.com/c/titanic/data" rel="noopener ugc nofollow" target="_blank">。</a></p></blockquote><p id="ea23" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如您从输出(如下)中看到的，总共有 12 列，其中一些对于预测乘客是否会在灾难中幸存没有用:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/8f756fce8c2c9054c7567a7657fc9fc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*exmec9bn7oJXgMTVmjXb0g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="e911" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们选择要用于机器学习模型的特定列:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="c815" class="mw ma it ly b gy nm nn l no np"># save only those columns that we want to use as features<br/>df = df[['Survived','Pclass','Sex','Age','Fare','Embarked']]<br/>df</span></pre><blockquote class="nr ns nt"><p id="854e" class="kz la nu lb b lc ld ju le lf lg jx lh nv lj lk ll nw ln lo lp nx lr ls lt lu im bi translated">为了简单起见，我将不深究为什么选择上面的列。如果您想了解关于特性选择的更多信息，请查看我以前的文章:</p><p id="6bbe" class="kz la nu lb b lc ld ju le lf lg jx lh nv lj lk ll nw ln lo lp nx lr ls lt lu im bi translated"><strong class="lb iu">Python 中的统计—使用 ANOVA 进行特征选择</strong>—<a class="ae ky" rel="noopener" target="_blank" href="/statistics-in-python-using-anova-for-feature-selection-b4dc876ef4f0">https://towardsdatascience . com/Statistics-in-Python-Using-ANOVA-for-Feature-Selection-b4dc 876 ef4f 0</a></p><p id="ee67" class="kz la nu lb b lc ld ju le lf lg jx lh nv lj lk ll nw ln lo lp nx lr ls lt lu im bi translated"><strong class="lb iu">Python 中的统计—使用卡方进行特征选择</strong>—<a class="ae ky" rel="noopener" target="_blank" href="/statistics-in-python-using-chi-square-for-feature-selection-d44f467ca745">https://towards data science . com/Statistics-in-Python-Using-Chi-Square-for-Feature-Selection-d44f 467 ca 745</a></p><p id="2775" class="kz la nu lb b lc ld ju le lf lg jx lh nv lj lk ll nw ln lo lp nx lr ls lt lu im bi translated"><strong class="lb iu">Python 中的统计—共线性和多重共线性</strong>—<a class="ae ky" rel="noopener" target="_blank" href="/statistics-in-python-collinearity-and-multicollinearity-4cc4dcd82b3f">https://towardsdatascience . com/Statistics-in-Python-共线性和多重共线性-4c 4 DCD 82 B3 f</a></p><p id="e184" class="kz la nu lb b lc ld ju le lf lg jx lh nv lj lk ll nw ln lo lp nx lr ls lt lu im bi translated"><strong class="lb iu">Python 中的统计—了解方差、协方差和相关性</strong>—<a class="ae ky" rel="noopener" target="_blank" href="/statistics-in-python-understanding-variance-covariance-and-correlation-4729b528db01">https://towardsdatascience . com/Statistics-in-Python-Understanding-Variance-协方差-and-Correlation-4729 b 528 db 01</a></p></blockquote><p id="587b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">剩余的数据帧现在有六列:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/180b4f159617526ee4d7575a7966835b.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*nlSZNNN_yfdkGpdXpNNQVQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="0633" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们检查数据集中是否有 nan:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="f8ce" class="mw ma it ly b gy nm nn l no np"># check for NaNs<br/>df.isna().sum()</span><span id="6f6e" class="mw ma it ly b gy nq nn l no np"># Survived      0<br/># Pclass        0<br/># Sex           0<br/><strong class="ly iu"># Age         177<br/></strong># Fare          0<br/><strong class="ly iu"># Embarked      2</strong><br/># dtype: int64</span></pre><p id="0d7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如上面以粗体突出显示的那样，<strong class="lb iu">年龄</strong>和<strong class="lb iu">着手</strong>列有 nan。</p><h2 id="b76f" class="mw ma it bd mb mx my dn mf mz na dp mj li nb nc ml lm nd ne mn lq nf ng mp nh bi translated">拆分数据</h2><p id="814a" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li mt lk ll lm mu lo lp lq mv ls lt lu im bi translated">在我们进行任何特性预处理之前，让我们将数据分成训练集和测试集:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="867d" class="mw ma it ly b gy nm nn l no np">from sklearn.model_selection import train_test_split</span><span id="a8f6" class="mw ma it ly b gy nq nn l no np"># get all columns except Survived<br/>X = df.iloc[:,1:]</span><span id="5d87" class="mw ma it ly b gy nq nn l no np"># Survived<br/>y = df.iloc[:,0]</span><span id="0cc1" class="mw ma it ly b gy nq nn l no np"># perform the splitting now<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, <br/>                                                  test_size = 0.3, <br/>                                                  stratify = y, <br/>                                                  random_state = 0)</span><span id="1cdf" class="mw ma it ly b gy nq nn l no np"># reset the indices for training and testing sets<br/>X_train = X_train.reset_index(drop=True)<br/>y_train = y_train.reset_index(drop=True)</span><span id="c5a1" class="mw ma it ly b gy nq nn l no np">X_test = X_test.reset_index(drop=True)<br/>y_test = y_test.reset_index(drop=True)</span></pre><blockquote class="nr ns nt"><p id="c5e7" class="kz la nu lb b lc ld ju le lf lg jx lh nv lj lk ll nw ln lo lp nx lr ls lt lu im bi translated">请注意，我们在进行任何数据预处理(如编码、替换 nan 等)之前分割了数据集。这里有两种观点——一种观点认为，在分割数据之前，我们应该首先进行数据预处理。另一个学派认为，我们应该在进行任何数据预处理之前拆分数据。一般来说，要防止“数据泄露”，最好先拆分数据，然后独立于测试数据对训练数据进行预处理。使用定型数据对模型进行定型后，您可以对测试数据进行预处理，并将其提供给模型进行评估。</p></blockquote><p id="4ec9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的代码片段中，数据帧被分成 70%的训练集和 30%的测试集。为了确保训练集和测试集具有相同比例的存活值，我们对<code class="fe lv lw lx ly b"><strong class="lb iu">y</strong></code>进行了分层，并为可重复性固定了一个<code class="fe lv lw lx ly b"><strong class="lb iu">random_state</strong></code>参数值。</p><h2 id="a2ad" class="mw ma it bd mb mx my dn mf mz na dp mj li nb nc ml lm nd ne mn lq nf ng mp nh bi translated">特征预处理</h2><p id="7092" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li mt lk ll lm mu lo lp lq mv ls lt lu im bi translated">下一步是预处理训练数据。这里我们需要预处理两种类型的列——数字列和分类列:</p><p id="b949" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于数字列，我们要做两件事:</p><ul class=""><li id="838c" class="oa ob it lb b lc ld lf lg li oc lm od lq oe lu of og oh oi bi translated">用一些值替换数字列中的所有 nan</li><li id="44bd" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated">标准化数字列值</li></ul><p id="1ed0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们用各列的中值替换<strong class="lb iu">年龄</strong>和<strong class="lb iu">票价</strong>列中缺失的值。为此，您可以使用 sklearn 中的<code class="fe lv lw lx ly b"><strong class="lb iu">SimpleImputer</strong></code>类:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="6564" class="mw ma it ly b gy nm nn l no np">from sklearn.impute import SimpleImputer</span><span id="d3a1" class="mw ma it ly b gy nq nn l no np"># use the SimpleImputer to replace all NaNs in numeric columns <br/># with the median<br/>numeric_imputer = SimpleImputer(strategy='median', <br/>                                missing_values=np.nan)</span><span id="c6c7" class="mw ma it ly b gy nq nn l no np"># apply the SimpleImputer on the Age and Fare columns<br/>X_train[['Age','Fare']] = \<br/>    numeric_imputer.fit_transform(X_train[['Age','Fare']])</span><span id="2051" class="mw ma it ly b gy nq nn l no np">display(X_train)</span></pre><blockquote class="nr ns nt"><p id="e8a4" class="kz la nu lb b lc ld ju le lf lg jx lh nv lj lk ll nw ln lo lp nx lr ls lt lu im bi translated">参考我之前关于使用 SimpleImputer 类的文章:</p></blockquote><div class="oo op gp gr oq or"><a rel="noopener follow" target="_blank" href="/imputing-missing-values-using-the-simpleimputer-class-in-sklearn-99706afaff46"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd iu gy z fp ow fr fs ox fu fw is bi translated">使用 sklearn 中的 SimpleImputer 类输入缺失值</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">了解如何使用 SimpleImputer 类来替换 Pandas 数据帧中的 nan</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">towardsdatascience.com</p></div></div><div class="pa l"><div class="pb l pc pd pe pa pf ks or"/></div></div></a></div><p id="50f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">年龄</strong>和<strong class="lb iu">费用</strong>栏中缺失的值现在用各栏的中间值填充:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/e770abe52a58047fda6ae991fafcf133.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*AplYJ1XNvZvSABT4UPM5ug.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="8f12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一步是使用<code class="fe lv lw lx ly b"><strong class="lb iu">StandardScaler</strong></code>类标准化这些值:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="5b70" class="mw ma it ly b gy nm nn l no np">from sklearn.preprocessing import StandardScaler</span><span id="aafc" class="mw ma it ly b gy nq nn l no np"># Standardize the Age and Fare columns using the StandardScaler<br/>scaler = StandardScaler()<br/>X_train[['Age','Fare']] = \<br/>    scaler.fit_transform(X_train[['Age','Fare']])</span><span id="05d0" class="mw ma it ly b gy nq nn l no np">display(X_train)</span></pre><p id="65fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">年龄</strong>和<strong class="lb iu">票价</strong>列的值现已标准化:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/dfb2952deaae28f6ee86820c7ff7afe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*CSkY8jZUiNJLDvKuyjtB4w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="3ca3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于分类列(<strong class="lb iu"> Pclass </strong>、<strong class="lb iu"> Sex </strong>和<strong class="lb iu">oaked</strong>)，您希望用最频繁出现的值替换缺失值。同样，您可以使用<code class="fe lv lw lx ly b"><strong class="lb iu">SimpleImputer</strong></code>类:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="af68" class="mw ma it ly b gy nm nn l no np"># use the SimpleImputer to replace all NaNs in categorical columns <br/># with the most frequent ones<br/>categorical_imputer = SimpleImputer(strategy='most_frequent', <br/>                                    missing_values=np.nan)</span><span id="1fff" class="mw ma it ly b gy nq nn l no np"># apply the SimpleImputer on the Pclass, Sex, and Embarked columns<br/>X_train[['Pclass','Sex','Embarked']] = \<br/>    categorical_imputer.fit_transform(<br/>        X_train[['Pclass','Sex','Embarked']])<br/>X_train</span></pre><p id="7d03" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您现在可以确认在<code class="fe lv lw lx ly b">X_train</code>数据框中不再有任何 nan:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="5ac4" class="mw ma it ly b gy nm nn l no np">X_train.isna().sum()</span><span id="163f" class="mw ma it ly b gy nq nn l no np"># Pclass      0<br/># Sex         0<br/># Age         0<br/># Fare        0<br/># Embarked    0<br/># dtype: int64</span></pre><p id="99f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">既然 dataframe 中没有 nan，那么对分类列要做的最后一件事就是执行编码。有两个选项可用:</p><ul class=""><li id="b2ac" class="oa ob it lb b lc ld lf lg li oc lm od lq oe lu of og oh oi bi translated"><strong class="lb iu">序号编码</strong> —这适用于存在隐式排序的列。例如经济状况、等级、乘客级别等。</li><li id="844e" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated"><strong class="lb iu"> One-hot encoding </strong> —这对于值的排序不重要的列很有用。例如性别、发色、肤色等。</li></ul><p id="728e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的数据集的情况下，<code class="fe lv lw lx ly b"><strong class="lb iu">Sex</strong></code>和<code class="fe lv lw lx ly b"><strong class="lb iu">Embarked</strong></code>的值没有隐式排序，因此它们可以被一次性编码:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="4cce" class="mw ma it ly b gy nm nn l no np">from sklearn.preprocessing import OneHotEncoder</span><span id="fdb3" class="mw ma it ly b gy nq nn l no np"># one-hot-encode the categorical columns - Sex, and Embarked<br/>enc = OneHotEncoder(handle_unknown='ignore')</span><span id="ab66" class="mw ma it ly b gy nq nn l no np">X_train[['Sex_female','Sex_male',<br/>         'Embarked_C','Embarked_Q','Embarked_S']] = \    <br/>    pd.DataFrame(enc.fit_transform(<br/>        X_train[['Sex','Embarked']]).toarray()) </span><span id="95c6" class="mw ma it ly b gy nq nn l no np">display(X_train)</span></pre><p id="c9b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您现在应该已经将<strong class="lb iu">性别</strong>和<strong class="lb iu">列的值进行了 one-hot 编码:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/3d416d863f07551bb12cc7e2e727de59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fZi_xPPHYGt2mDEPwmlVtA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="9758" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，您可以继续删除<strong class="lb iu">性别</strong>和<strong class="lb iu">装载的</strong>列(接下来，您将使用它们的独热编码列):</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="2e0a" class="mw ma it ly b gy nm nn l no np"># drop the Sex and Embarked and use their one-hot encoded columns<br/>X_train.drop(columns=['Sex','Embarked'], inplace=True)</span><span id="d54c" class="mw ma it ly b gy nq nn l no np">display(X_train)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/4447e0f54dbf2d7a0f08effdbb7868ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*3VEI6KGm_GubouLss6cY-A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="2171" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，您现在可以使用分类器来训练模型。对于这个例子，我将使用<code class="fe lv lw lx ly b"><strong class="lb iu">LogisticRegression</strong></code>类:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="1d3d" class="mw ma it ly b gy nm nn l no np">from sklearn.linear_model import LogisticRegression</span><span id="7822" class="mw ma it ly b gy nq nn l no np"># train using LogisticRegression<br/>logregress = LogisticRegression()<br/>logregress.fit(X_train,y_train)</span></pre><h2 id="1eb3" class="mw ma it bd mb mx my dn mf mz na dp mj li nb nc ml lm nd ne mn lq nf ng mp nh bi translated">准备用于评估模型的测试集</h2><p id="a155" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li mt lk ll lm mu lo lp lq mv ls lt lu im bi translated">训练好模型后，您现在可以使用测试集来评估模型，以查看它的执行情况。还记得你在训练集上做的预处理吗？您现在需要对您的测试集做同样的事情:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="82b7" class="mw ma it ly b gy nm nn l no np"><strong class="ly iu"># replace all NaNs and standardize the numerical columns</strong><br/>X_test[['Age','Fare']] = \<br/>    numeric_imputer.transform(X_test[['Age','Fare']])</span><span id="a7c2" class="mw ma it ly b gy nq nn l no np"><strong class="ly iu"># standardize the Age and Fare columns</strong><br/>X_test[['Age','Fare']] = scaler.transform(X_test[['Age','Fare']])</span><span id="f6a9" class="mw ma it ly b gy nq nn l no np"><strong class="ly iu"># replace all NaNs in the categorical columns</strong><br/>X_test[['Pclass','Sex','Embarked']] = \<br/>    categorical_imputer.transform(<br/>        X_test[['Pclass','Sex','Embarked']])</span><span id="ca67" class="mw ma it ly b gy nq nn l no np"><strong class="ly iu"># one-hot encode the Sex and Embarked columnns</strong><br/>X_test[['Sex_female','Sex_male',<br/>        'Embarked_C','Embarked_Q','Embarked_S']] = \    <br/>    pd.DataFrame(enc.transform(<br/>        X_test[['Sex','Embarked']]).toarray())</span><span id="08cb" class="mw ma it ly b gy nq nn l no np"><strong class="ly iu"># drop the Sex and Embarked columns</strong><br/>X_test.drop(columns=['Sex','Embarked'], inplace=True)</span><span id="222b" class="mw ma it ly b gy nq nn l no np">display(X_test)</span></pre><p id="877b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在对测试集执行预处理之后，它现在看起来像这样:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/7909c5734cf5ecfd80a4e543be9713ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*99uNxSSzKAv-clV7BMc-mA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><blockquote class="nr ns nt"><p id="aef4" class="kz la nu lb b lc ld ju le lf lg jx lh nv lj lk ll nw ln lo lp nx lr ls lt lu im bi translated">预处理测试集以匹配定型集的列是很重要的。否则，您将无法使用它来评估您的模型。</p></blockquote><p id="ca8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您现在可以调用<code class="fe lv lw lx ly b"><strong class="lb iu">score()</strong></code>函数来评估模型:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="525f" class="mw ma it ly b gy nm nn l no np"><strong class="ly iu">logregress.score(X_test,y_test)</strong><br/># 0.8097014925373134                  this is the accuracy score</span></pre><h1 id="1ebf" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">使用流水线简化机器学习</h1><p id="897f" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li mt lk ll lm mu lo lp lq mv ls lt lu im bi translated">因此，您刚刚使用上一节中的 Titanic 数据集构建并训练了一个模型。你注意到了什么？以下是值得注意的几点:</p><ul class=""><li id="7fc1" class="oa ob it lb b lc ld lf lg li oc lm od lq oe lu of og oh oi bi translated">您必须分别预处理您的训练集和测试集，这涉及到相当多的重复性工作</li><li id="1d7b" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated">这涉及到许多步骤，必须按照正确的顺序来执行</li></ul><p id="1ae5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用 sklearn <code class="fe lv lw lx ly b">Pipeline</code>类，您现在可以为您的机器学习过程创建一个工作流，并强制执行各个步骤的执行顺序。</p><p id="8120" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在接下来的章节中，你将看到如何使用 sklearn <code class="fe lv lw lx ly b">Pipeline</code>类来简化之前的机器学习过程。</p><h2 id="26f1" class="mw ma it bd mb mx my dn mf mz na dp mj li nb nc ml lm nd ne mn lq nf ng mp nh bi translated">加载和拆分数据</h2><p id="2a6a" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li mt lk ll lm mu lo lp lq mv ls lt lu im bi translated">第一步是加载数据并执行拆分:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="ed58" class="mw ma it ly b gy nm nn l no np">import pandas as pd<br/>import numpy as np<br/>from sklearn.model_selection import train_test_split</span><span id="686d" class="mw ma it ly b gy nq nn l no np">df = pd.read_csv('<a class="ae ky" href="https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/train.csv'" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/train.csv'</a>) </span><span id="4947" class="mw ma it ly b gy nq nn l no np">df = df[['Survived','Pclass','Sex','Age','Fare','Embarked']]<br/>X = df.iloc[:,1:]<br/>y = df.iloc[:,0]</span><span id="1fdd" class="mw ma it ly b gy nq nn l no np">X_train, X_test, y_train, y_test = train_test_split(X, y, <br/>                                                  test_size = 0.3, <br/>                                                  stratify = y, <br/>                                                  random_state = 0)</span></pre><h2 id="79da" class="mw ma it bd mb mx my dn mf mz na dp mj li nb nc ml lm nd ne mn lq nf ng mp nh bi translated">为预处理创建管道</h2><p id="1259" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li mt lk ll lm mu lo lp lq mv ls lt lu im bi translated">让我们使用<code class="fe lv lw lx ly b"><strong class="lb iu">Pipeline</strong></code>类来指定将转换应用到数据的一系列步骤。下面的代码片段创建了三个<code class="fe lv lw lx ly b">Pipeline</code>对象:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="540b" class="mw ma it ly b gy nm nn l no np">from sklearn.pipeline import Pipeline<br/>from sklearn.impute import SimpleImputer<br/>from sklearn.preprocessing import StandardScaler, OneHotEncoder</span><span id="f765" class="mw ma it ly b gy nq nn l no np"># define the transformer for numeric columns<br/># for 'Age' and 'Fare'<br/><strong class="ly iu">numeric_transformer = Pipeline(steps=[<br/>    ('imputer', SimpleImputer(strategy='median')),<br/>    ('scaler', StandardScaler())<br/>])</strong></span><span id="96c0" class="mw ma it ly b gy nq nn l no np"># define the transformer for categorical columns<br/># for 'Sex' and 'Embarked'<br/><strong class="ly iu">categorical_transformer1 = Pipeline(steps=[<br/>    ('imputer', SimpleImputer(strategy='most_frequent')),<br/>    ('onehot', OneHotEncoder(handle_unknown='ignore'))<br/>])</strong></span><span id="8a3b" class="mw ma it ly b gy nq nn l no np"># define the transformer for categorical columns<br/># for 'Pclass'<br/><strong class="ly iu">categorical_transformer2 = Pipeline(steps=[<br/>    ('imputer', SimpleImputer(strategy='most_frequent'))</strong><br/><strong class="ly iu">])</strong></span></pre><p id="4abe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的代码片段中，我:</p><ul class=""><li id="c30b" class="oa ob it lb b lc ld lf lg li oc lm od lq oe lu of og oh oi bi translated">创建了一个<code class="fe lv lw lx ly b">Pipeline</code>对象(<code class="fe lv lw lx ly b"><strong class="lb iu">numeric_transformer</strong></code>)，首先用他们的中间值替换<strong class="lb iu">年龄</strong>和<strong class="lb iu">费用</strong>列中的 NaNs。然后，这两列的值被标准化:</li></ul><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="aabe" class="mw ma it ly b gy nm nn l no np">numeric_transformer = Pipeline(steps=[<br/>    ('imputer', SimpleImputer(strategy='median')),<br/>    ('scaler', StandardScaler())<br/>])</span></pre><ul class=""><li id="b82a" class="oa ob it lb b lc ld lf lg li oc lm od lq oe lu of og oh oi bi translated">创建了另一个<code class="fe lv lw lx ly b">Pipeline</code>对象(<code class="fe lv lw lx ly b"><strong class="lb iu">categorical_features1</strong></code>)来替换<strong class="lb iu"> Sex </strong>和<strong class="lb iu">abowed</strong>列中的 NaNs，使其具有每列中最频繁出现的值。然后，对这两列的值进行一次性编码:</li></ul><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="7636" class="mw ma it ly b gy nm nn l no np">categorical_transformer1 = Pipeline(steps=[<br/>    ('imputer', SimpleImputer(strategy='most_frequent')),<br/>    ('onehot', OneHotEncoder(handle_unknown='ignore'))<br/>])</span></pre><ul class=""><li id="1ef6" class="oa ob it lb b lc ld lf lg li oc lm od lq oe lu of og oh oi bi translated">创建另一个<code class="fe lv lw lx ly b">Pipeline</code>对象(<code class="fe lv lw lx ly b"><strong class="lb iu">categorical_features2</strong></code>)来替换<strong class="lb iu"> Pclass </strong>列中出现频率最高的值:</li></ul><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="af93" class="mw ma it ly b gy nm nn l no np">categorical_transformer2 = Pipeline(steps=[<br/>    ('imputer', SimpleImputer(strategy='most_frequent'))<br/>])</span></pre><p id="0f91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe lv lw lx ly b"><strong class="lb iu">Pipeline</strong></code>类的<strong class="lb iu">步骤</strong>参数接受一个元组列表。每个元组包含:</p><ul class=""><li id="9cbb" class="oa ob it lb b lc ld lf lg li oc lm od lq oe lu of og oh oi bi translated">转换的名称，以及</li><li id="6d38" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated">实现<code class="fe lv lw lx ly b">fit</code>或<code class="fe lv lw lx ly b">transform</code>方法的转换对象。例如，<code class="fe lv lw lx ly b">SimpleImputer</code>、<code class="fe lv lw lx ly b">StandardScaler</code>、<code class="fe lv lw lx ly b">MinMaxScaler</code>等。最后一个变换对象可以作为估计器(实现<code class="fe lv lw lx ly b">fit</code>方法)，例如<code class="fe lv lw lx ly b">LogisticRegression</code>等。</li></ul><p id="cbe6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe lv lw lx ly b">Pipeline</code>对象中的转换按照元组列表中指定的顺序执行:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/aceaad13560cf9edf2f97914d4263619.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oLxux1vfX9bzvEPihiJS2w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="0043" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，您将使用<code class="fe lv lw lx ly b"><strong class="lb iu">ColumnTransformer</strong></code>类将在<code class="fe lv lw lx ly b">Pipeline</code>对象中指定的转换应用到 dataframe 中的各个列:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="3f29" class="mw ma it ly b gy nm nn l no np">from sklearn.compose import ColumnTransformer</span><span id="701a" class="mw ma it ly b gy nq nn l no np">features_preprocessor = ColumnTransformer(<br/>    transformers=[<br/>     ('numeric',      numeric_transformer,      ['Age','Fare']),<br/>     ('categorical1', categorical_transformer1, ['Sex','Embarked']),<br/>     ('categorical2', categorical_transformer2, ['Pclass'])<br/>    ])</span></pre><p id="ea77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的代码片段中，您应用了:</p><ul class=""><li id="8308" class="oa ob it lb b lc ld lf lg li oc lm od lq oe lu of og oh oi bi translated"><code class="fe lv lw lx ly b"><strong class="lb iu">numeric_transformer</strong></code> <code class="fe lv lw lx ly b">Pipeline</code>对象为<strong class="lb iu">年龄</strong>和<strong class="lb iu">票价</strong>列</li><li id="e198" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated"><code class="fe lv lw lx ly b"><strong class="lb iu">categorical_transformer1</strong></code> <strong class="lb iu"> </strong> <code class="fe lv lw lx ly b">Pipeline</code>对象到<strong class="lb iu">性别</strong>和<strong class="lb iu">列</strong></li><li id="5640" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated"><code class="fe lv lw lx ly b"><strong class="lb iu">categorical_transformer2</strong></code> <strong class="lb iu"> </strong> <code class="fe lv lw lx ly b">Pipeline</code>对象到<strong class="lb iu"> Pclass </strong>列</li></ul><blockquote class="nr ns nt"><p id="5cd2" class="kz la nu lb b lc ld ju le lf lg jx lh nv lj lk ll nw ln lo lp nx lr ls lt lu im bi translated">如果有不需要转换的列，您应该将<code class="fe lv lw lx ly b">ColumnTransformer</code>类的<code class="fe lv lw lx ly b">remainder</code>参数设置为<code class="fe lv lw lx ly b">passthrough</code>以确保这些列被保留。否则，它们将被默认删除)</p></blockquote><p id="bcf9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有这些步骤都被传入<code class="fe lv lw lx ly b">ColumnTransformer</code>类并作为<code class="fe lv lw lx ly b"><strong class="lb iu">features_preprocessor</strong></code>返回。现在你可以使用<code class="fe lv lw lx ly b"><strong class="lb iu">features_preprocessor</strong></code>和你想用来训练你的模型的分类器创建另一个<code class="fe lv lw lx ly b">Pipeline</code>对象:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="05af" class="mw ma it ly b gy nm nn l no np">from sklearn.linear_model import LogisticRegression</span><span id="5968" class="mw ma it ly b gy nq nn l no np">pipe = Pipeline(steps=[<br/>    ('preprocessor', features_preprocessor),  # preprocess features<br/>    ('classifier', LogisticRegression())      # apply classifier<br/>])</span></pre><p id="8020" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的代码片段中，我使用了<code class="fe lv lw lx ly b"><strong class="lb iu">LogisticRegression</strong></code>类来训练模型。</p><blockquote class="nr ns nt"><p id="2d7b" class="kz la nu lb b lc ld ju le lf lg jx lh nv lj lk ll nw ln lo lp nx lr ls lt lu im bi translated">回想一下，<code class="fe lv lw lx ly b"><strong class="lb iu">Pipeline</strong></code>类接受一个包含转换对象列表的元组列表，最后一个类可以实现<code class="fe lv lw lx ly b">fit()</code>方法。</p></blockquote><p id="7cc5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，您可以使用<code class="fe lv lw lx ly b">Pipeline</code>对象训练模型:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="6e7d" class="mw ma it ly b gy nm nn l no np"># start the training<br/>pipe.fit(X_train, y_train)</span></pre><p id="23b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行上述代码，您将看到以下输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/44fe9c7497e96be92005313d9000979b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*79b3iLODGoLaBJ_BBLqWAg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h2 id="329a" class="mw ma it bd mb mx my dn mf mz na dp mj li nb nc ml lm nd ne mn lq nf ng mp nh bi translated">对模型评分</h2><p id="e169" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li mt lk ll lm mu lo lp lq mv ls lt lu im bi translated">要评估模式，请调用<code class="fe lv lw lx ly b">Pipeline</code>对象上的<code class="fe lv lw lx ly b">score()</code>方法:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="363e" class="mw ma it ly b gy nm nn l no np">pipe.score(X_test,y_test)<br/># 0.8097014925373134</span></pre><p id="67e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出与前面手动执行机器学习的部分相同。</p><p id="aca5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">概括一下，下面是使用<code class="fe lv lw lx ly b">Pipeline</code>对象的整个代码块:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="d7c5" class="mw ma it ly b gy nm nn l no np">import pandas as pd<br/>import numpy as np</span><span id="15bc" class="mw ma it ly b gy nq nn l no np">from sklearn.model_selection import train_test_split<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.impute import SimpleImputer<br/>from sklearn.preprocessing import StandardScaler, OneHotEncoder<br/>from sklearn.compose import ColumnTransformer<br/>from sklearn.linear_model import LogisticRegression</span><span id="30e0" class="mw ma it ly b gy nq nn l no np">df = pd.read_csv('<a class="ae ky" href="https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/train.csv'" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/train.csv'</a>)</span><span id="75aa" class="mw ma it ly b gy nq nn l no np">df = df[['Survived','Pclass','Sex','Age','Fare','Embarked']]<br/>X = df.iloc[:,1:]<br/>y = df.iloc[:,0]</span><span id="f138" class="mw ma it ly b gy nq nn l no np">X_train, X_test, y_train, y_test = train_test_split(X, y, <br/>                                                  test_size = 0.3, <br/>                                                  stratify = y, <br/>                                                  random_state = 0)</span><span id="1a04" class="mw ma it ly b gy nq nn l no np"># define the transformer for numeric columns<br/># for 'Age' and 'Fare'<br/>numeric_transformer = Pipeline(steps=[<br/>    ('imputer', SimpleImputer(strategy='median')),<br/>    ('scaler', StandardScaler())<br/>])</span><span id="6f1e" class="mw ma it ly b gy nq nn l no np"># define the transformer for categorical columns<br/># for 'Sex' and 'Embarked'<br/>categorical_transformer1 = Pipeline(steps=[<br/>    ('imputer', SimpleImputer(strategy='most_frequent')),<br/>    ('onehot', OneHotEncoder(handle_unknown='ignore'))<br/>])</span><span id="22e7" class="mw ma it ly b gy nq nn l no np"># define the transformer for categorical columns<br/># for 'Pclass'<br/>categorical_transformer2 = Pipeline(steps=[<br/>    ('imputer', SimpleImputer(strategy='most_frequent'))<br/>])</span><span id="e5f6" class="mw ma it ly b gy nq nn l no np">features_preprocessor = ColumnTransformer(<br/>    transformers=[<br/>     ('numeric',      numeric_transformer,      ['Age','Fare']),<br/>     ('categorical1', categorical_transformer1, ['Sex','Embarked']),<br/>     ('categorical2', categorical_transformer2, ['Pclass'])<br/>    ])</span><span id="6859" class="mw ma it ly b gy nq nn l no np">pipe = Pipeline(steps=[<br/>    ('preprocessor', features_preprocessor),  # preprocess features<br/>    ('classifier', LogisticRegression())      # apply classifier<br/>])</span><span id="0ec9" class="mw ma it ly b gy nq nn l no np"># start the training<br/>pipe.fit(X_train, y_train)</span><span id="46fd" class="mw ma it ly b gy nq nn l no np"># evaluate the model<br/>pipe.score(X_test,y_test)                     # 0.8097014925373134</span></pre><p id="2fd8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您观察，会发现不需要对测试集执行预处理——<code class="fe lv lw lx ly b">Pipeline</code>对象的<code class="fe lv lw lx ly b">score()</code>方法会处理好它！此外，工作流现在定义得更加清晰，也更容易理解。</p><h1 id="09f6" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">通过 GridSearchCV 使用管道</h1><p id="6d86" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li mt lk ll lm mu lo lp lq mv ls lt lu im bi translated">您还可以使用带有<code class="fe lv lw lx ly b">GridSearchCV</code>类的<code class="fe lv lw lx ly b">Pipeline</code>对象进行超参数调优。</p><div class="oo op gp gr oq or"><a rel="noopener follow" target="_blank" href="/tuning-the-hyperparameters-of-your-machine-learning-model-using-gridsearchcv-7fc2bb76ff27"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd iu gy z fp ow fr fs ox fu fw is bi translated">使用 GridSearchCV 调整机器学习模型的超参数</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">了解如何使用 sklearn 中的 GridSearchCV 函数来优化您的机器学习模型</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">towardsdatascience.com</p></div></div><div class="pa l"><div class="pn l pc pd pe pa pf ks or"/></div></div></a></div><p id="355a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面的代码片段显示了如何将<code class="fe lv lw lx ly b">Pipeline</code>对象传递给<code class="fe lv lw lx ly b">GridSearchCV</code>类，以便您可以找到使用<code class="fe lv lw lx ly b">LogisticRegression</code>类训练您的模型的最佳超参数:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="1d11" class="mw ma it ly b gy nm nn l no np">from sklearn.model_selection import GridSearchCV<br/>from sklearn.linear_model import LogisticRegression<br/>import warnings</span><span id="c0c3" class="mw ma it ly b gy nq nn l no np">warnings.filterwarnings('ignore')</span><span id="481a" class="mw ma it ly b gy nq nn l no np">pipe = Pipeline(steps=[<br/>    ('preprocessor', features_preprocessor),  # preprocess features<br/>    ('classifier', LogisticRegression())      # apply classifier<br/>])</span><span id="2b0e" class="mw ma it ly b gy nq nn l no np"><strong class="ly iu"># parameter grid<br/>parameters = {<br/>    'classifier__penalty' : ['l1','l2'],          <br/>    'classifier__C'       : np.logspace(-3,3,7),<br/>    'classifier__solver'  : ['newton-cg', 'lbfgs', 'liblinear'],<br/>}</strong></span><span id="b5d4" class="mw ma it ly b gy nq nn l no np"><strong class="ly iu">clf = GridSearchCV(pipe,                      # model<br/>                   param_grid = parameters,   # hyperparameters<br/>                   scoring='accuracy',        # metric for scoring<br/>                   cv=10)                     # number of folds</strong></span><span id="3ae4" class="mw ma it ly b gy nq nn l no np"><strong class="ly iu">clf.fit(X, y)     # GridSearchCV will automatically split the data<br/>                  # into training and testing data</strong></span></pre><blockquote class="nr ns nt"><p id="3777" class="kz la nu lb b lc ld ju le lf lg jx lh nv lj lk ll nw ln lo lp nx lr ls lt lu im bi translated">当将<code class="fe lv lw lx ly b">GridSearchCV</code>与<code class="fe lv lw lx ly b">Pipeline</code>对象一起使用时，注意超参数的键必须以转换器的名称为前缀—“<code class="fe lv lw lx ly b"><strong class="lb iu">classifier__</strong></code>”(注意双下划线)。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi po"><img src="../Images/4d3b87f92d2997af13ab5a32b773dd7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*AInvJhyts965W8_y1GPM5Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="f7d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型定型后，您现在可以评估模型:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="c1c8" class="mw ma it ly b gy nm nn l no np"><strong class="ly iu">clf.score(X_test, y_test)</strong><br/># 0.8134328358208955</span></pre><p id="4f02" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在模型的精度提高了(与之前的 0.8097014925373134 相比)。</p><p id="6ef5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以打印出最佳超参数和最佳估计值的平均交叉验证分数:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="be03" class="mw ma it ly b gy nm nn l no np">print("Tuned Hyperparameters :", clf.best_params_)<br/>print("Accuracy :",clf.best_score_)   # Mean cross-validated score <br/>                                      # of the best_estimator</span></pre><p id="bb54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您应该会看到以下结果:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="0f81" class="mw ma it ly b gy nm nn l no np">Tuned Hyperparameters : {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}<br/>Accuracy : 0.7934956304619226</span></pre><h1 id="5e05" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">使用管道评估分类器</h1><p id="71be" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li mt lk ll lm mu lo lp lq mv ls lt lu im bi translated"><code class="fe lv lw lx ly b">Pipeline</code>对象的另一个好用途是用它来评估不同的算法来训练你的模型。对于我们的例子，让我们尝试不同的分类器，看看哪一个给出最高的准确性。</p><p id="019d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们导入以下模块:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="4c7a" class="mw ma it ly b gy nm nn l no np">from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.svm import SVC <br/>from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.ensemble import RandomForestClassifier, \<br/>    AdaBoostClassifier <br/>from sklearn.discriminant_analysis import \<br/>    QuadraticDiscriminantAnalysis<br/>from sklearn.gaussian_process import GaussianProcessClassifier<br/>from sklearn.gaussian_process.kernels import RBF<br/>from sklearn.neural_network import MLPClassifier<br/>from sklearn.naive_bayes import GaussianNB</span></pre><p id="f436" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">创建我们希望使用的分类器列表，并指定其特定参数:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="361c" class="mw ma it ly b gy nm nn l no np">classifiers = [    <br/>    LogisticRegression(C=0.1, penalty='l2', solver='liblinear'),<br/>    KNeighborsClassifier(3),<br/>    KNeighborsClassifier(),<br/>    KNeighborsClassifier(7),<br/>    SVC(kernel="linear", C=0.025),<br/>    SVC(gamma=2, C=1),<br/>    GaussianProcessClassifier(1.0 * RBF(1.0)),<br/>    DecisionTreeClassifier(max_depth=5),<br/>    RandomForestClassifier(max_depth=5, n_estimators=10, <br/>                           max_features=1),<br/>    MLPClassifier(alpha=1, max_iter=1000),<br/>    AdaBoostClassifier(),<br/>    GaussianNB(),<br/>    QuadraticDiscriminantAnalysis(),<br/>]</span></pre><p id="b7ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还将使用一个数据帧来存储每个分类器的精度:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="ec74" class="mw ma it ly b gy nm nn l no np"># dataframe to store the accuracy of each classifier<br/>df_results = pd.DataFrame(columns=<br/>    ['Classifier', 'Accuracy'])</span></pre><p id="2f3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要试用各种分类器:</p><ul class=""><li id="f591" class="oa ob it lb b lc ld lf lg li oc lm od lq oe lu of og oh oi bi translated">遍历列表中的每个分类器，并在每次迭代中创建一个<code class="fe lv lw lx ly b">Pipeline</code>对象。</li><li id="9380" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated">对于每个<code class="fe lv lw lx ly b">Pipeline</code>对象，应用预处理器，然后应用分类器。</li><li id="a484" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated">使用<code class="fe lv lw lx ly b">Pipeline</code>对象训练一个模型，然后对其进行评估。</li></ul><p id="322a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下代码片段总结了上述步骤:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="cb3b" class="mw ma it ly b gy nm nn l no np"># train a model using each classifier<br/>for classifier in classifiers:</span><span id="e369" class="mw ma it ly b gy nq nn l no np">    # create the pipeline to preprocess the features <br/>    # and apply the classifier<br/>    pipe = Pipeline(steps=[<br/>        ('preprocessor', features_preprocessor),<br/>        ('classifier', classifier)])</span><span id="1a87" class="mw ma it ly b gy nq nn l no np">    # train the model<br/>    pipe.fit(X_train, y_train)   <br/>    <br/>    # append the result to the dataframe<br/>    df_results = df_results.append(pd.Series({<br/>        'Classifier' : classifier, <br/>        'Accuracy' : pipe.score(X_test, y_test)<br/>    }),ignore_index = True)</span></pre><p id="ca4f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当使用并评估所有分类器时，您可以基于最高准确度对结果数据帧进行排序:</p><pre class="kj kk kl km gt ni ly nj nk aw nl bi"><span id="0cde" class="mw ma it ly b gy nm nn l no np">display(df_results.sort_values(by='Accuracy', ascending=False))</span></pre><p id="fe90" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/37aea8b17bbdc65809b98cb4687fd578.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*VWyxgm1_ooW7kFlPG1HgTQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h1 id="114d" class="lz ma it bd mb mc md me mf mg mh mi mj jz mk ka ml kc mm kd mn kf mo kg mp mq bi translated">摘要</h1><p id="3a70" class="pw-post-body-paragraph kz la it lb b lc mr ju le lf ms jx lh li mt lk ll lm mu lo lp lq mv ls lt lu im bi translated">在本文中，我已经讨论了 sklearn 中<code class="fe lv lw lx ly b">Pipeline</code>类的使用。在 sklearn 中使用管道最大的好处就是让你的机器学习工作流程更清晰，更容易理解。此外，您可以使用它来快速评估数据集的各种机器学习算法。我希望您现在对 sklearn 中的管道是如何工作的有了更清楚的了解！</p><div class="oo op gp gr oq or"><a href="https://weimenglee.medium.com/membership" rel="noopener follow" target="_blank"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd iu gy z fp ow fr fs ox fu fw is bi translated">加入媒介与我的介绍链接-李伟孟</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">weimenglee.medium.com</p></div></div><div class="pa l"><div class="pq l pc pd pe pa pf ks or"/></div></div></a></div></div></div>    
</body>
</html>