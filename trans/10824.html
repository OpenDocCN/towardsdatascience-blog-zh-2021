<html>
<head>
<title>Getting Started with a Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-started-with-a-neural-network-43ca6025c8ba?source=collection_archive---------33-----------------------#2021-10-19">https://towardsdatascience.com/getting-started-with-a-neural-network-43ca6025c8ba?source=collection_archive---------33-----------------------#2021-10-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bdc3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Pytorch的简单CNN示例</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/58c6e344195af062a2bef95a0914e3c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_PNCySq7ZgoTM7GKQnj3VA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自https://pixabay.com/images/id-1201014/的https://pixabay.com/users/remazteredstudio-1714780/</p></figure><h2 id="cca0" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">问题是</h2><p id="0b2e" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">在这篇文章中，我们要解决的玩具问题是识别图像中一条线的起点和终点的坐标。图像将是全黑的，即除了代表线的像素之外，所有像素都是0。</p><p id="c5ae" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">这既不是分类问题(目标是识别线的存在或不存在)，也不是对象检测问题(处理识别不是一个而是许多对象，对对象进行分类并通过边界框识别它们的位置)。这在某种程度上介于两者之间，这种选择的基本原理只是为了处理一些与网上数百个现有分类示例略有不同的东西。</p><h2 id="c774" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">基础知识</h2><p id="13ee" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">我们需要做一些事情来设置神经网络的必要组件。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/2af3dc6d9108a5fa3db1188636b0f00c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*24FPNTVUzdqiwqLGSQDFpQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1:训练步骤的简单列表(图片由作者提供)</p></figure><ol class=""><li id="9e12" class="mu mv it lx b ly mo mb mp li mw lm mx lq my mn mz na nb nc bi translated">数据准备</li><li id="cb47" class="mu mv it lx b ly nd mb ne li nf lm ng lq nh mn mz na nb nc bi translated">模型定义</li><li id="e109" class="mu mv it lx b ly nd mb ne li nf lm ng lq nh mn mz na nb nc bi translated">训练和测试功能:训练功能是图1中调用的步骤将驻留的地方</li><li id="4295" class="mu mv it lx b ly nd mb ne li nf lm ng lq nh mn mz na nb nc bi translated">损失函数和优化器</li></ol><h2 id="69ed" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">1.数据</h2><p id="a6d0" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">在我们的练习中，我们将准备自己的自定义数据集。我用skimage生成了线坐标。给定起点和终点坐标，这将生成两个数组，表示属于该行的像素的索引。一个代表x的列表，另一个代表y的列表，把它们放在一起给出了直线经过的坐标。</p><div class="ni nj gp gr nk nl"><a href="https://scikit-image.org/docs/dev/api/skimage.draw.html#skimage.draw.line" rel="noopener  ugc nofollow" target="_blank"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd iu gy z fp nq fr fs nr fu fw is bi translated">模块:draw-skim age v 0 . 19 . 0 . dev 0文档</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">用于确定输出像素坐标的最大范围的图像形状。这对于…的圆很有用</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">scikit-image.org</p></div></div><div class="nu l"><div class="nv l nw nx ny nu nz ks nl"/></div></div></a></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/aa5d31d1a8f8fac3e161b947252cdb09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tJ7eCbPDAT3DsCCqkeC-rA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图2:生成一行(作者图片)</p></figure><p id="7671" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">图2显示了一个简单的例子，说明我们将如何实现这一点。首先，我们将创建一个表示全0的单通道10 X 10图像的张量。然后，我们将随机选择一个起点和终点，以获取表示该行的像素的索引，并在创建的图像张量中将相应的值设为1。</p><p id="c8d5" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">图3是利用该逻辑来创建图像和结果张量的函数。图像数量(dataCount)和图像大小(imgPixelSize)被定义为输入参数。注意:在这个例子中，我使用128作为imgPixelSize。</p><p id="7176" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">当我们随机选择一个起点和终点时，我们还会执行一些基本的检查。</p><p id="7351" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">首先，我们确保起点总是在终点的左边。这仅仅是基于一种直觉，对于给定的任何一条线，我个人很可能总是将最左边的点指定为“起点”，而将另一个点指定为“终点”。</p><p id="ea20" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">这使我能够消除“顺序无关紧要”的问题。给定一条从(0，0)到(9，9)的线，虽然从技术上来说将任一点称为起点或终点都是正确的，但训练模型以适应这两种可能性可能需要我编写一个自定义损失函数，而不是简单地与一个单一的基本事实进行比较。我还直觉地感觉到，像这样的约束可能有助于模型训练得更快。</p><p id="45de" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">第二个检查相当简单，我们确保随机选择的起点和终点不相同(如果是，那就不是一条线，而只是一个点)。</p><p id="051f" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">最后，我们返回图像和相应的结果张量。结果张量只不过是开始和结束坐标的表示，即具有4个值的张量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3:创建线条</p></figure><p id="5d93" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">虽然这创建了我们需要的张量，但是使用它需要我们创建一个自定义数据集和一个相应的数据加载器。自定义数据集应该是实现__len__()函数(返回数据集的长度)和__getitem__(index)函数(返回给定索引处的样本)的类。我们还将使用Pytorch的数据加载器来创建一个可迭代的加载器，它将允许我们批处理和混洗数据。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4:定制数据集和数据加载器</p></figure><h2 id="e736" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">2.培训和测试功能</h2><p id="0a57" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">训练函数非常简单，实现了图1中的内容。它将数据加载器、模型、损失函数和优化器作为输入，将模型置于训练模式，并为每一批迭代数据加载器。</p><p id="a0d8" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">对于每一批，我们首先将数据移动到可用的设备(gpu vs cpu)，然后使用当前模型预测该批的结果，根据预测和基本事实计算损失，将上一轮的梯度归零，使用反向传播计算这一轮的梯度，并让优化器采取一个步骤来更新模型参数。</p><p id="d3df" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">正如您可能注意到的，这是一个非常通用的函数，不管我们的模型结构如何，也不管我们选择的损失函数或优化器如何，它都能工作。</p><p id="a758" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我们也有通用的测试函数，旨在评估不同于训练数据集的单独测试数据集的损失。测试函数的目的是查看模型对以前没有见过的数据(即没有训练过的数据)的表现。因此，我们将模型置于评估模式，只进行预测并计算损失。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图5:训练和测试功能</p></figure><h2 id="8a9c" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">3.模型</h2><p id="7931" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">通过设计，卷积运算考虑了两个相邻像素之间的空间关系。一段时间以来，卷积神经网络一直是处理图像的事实架构。尽管还很初级，我们的玩具数据集也能处理基本的线条图像。所以让我们从建筑开始。</p><p id="4820" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我从一个接一个的卷积层的随机排列开始。一个简单的谷歌搜索“卷积神经网络”显示，典型的标准似乎减少了高度和宽度，同时增加了这些层上的通道。最后，我们往往会有一个线性层堆栈，将最后一个卷积层展平为输出矢量。</p><p id="97ac" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">在我们的例子中，输出向量将代表我们想要预测的内容。它将是一个4个值的张量，代表线的起点和终点的(x，y)坐标。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图6:模型1</p></figure><p id="76ea" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">上面的图6代表了模型本身。在这个例子中，我使用128作为imgPixelSize。因此你所看到的数字都是由此而来的。第一个卷积层表示输入将有1层，这是我们在图3的createDate函数中生成的。它还指示输出将具有4层，卷积核的大小将为3，步长为2。我们有三个以上的conv层堆叠在这上面。然后，我们将输出变平，并在顶部堆叠几个线性层，最后一层产生4个值的输出张量。</p><p id="d844" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">你可能会注意到，重要的是我们不仅要知道第一层的输入形状，还要知道每一层的输入形状。在Conv2D中，我们需要知道输入中的通道数，而在线性中，我们需要知道输入张量的大小。虽然手动推导对于了解这些操作是如何工作的很重要，但是您可以将样本输入传递到一个临时的顺序网络，该网络由模型中使用的一个或多个相同的层组成，并打印结果的大小。请参见下面的图7，了解如何快速了解添加到模型中的图层末尾的大小。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/ed926cadb8a3bbe7cee25acb10bb9c5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0HrzDU63HvxGKkH4byahMg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图7:快速确定每层末尾尺寸的方法(图片由作者提供)</p></figure><h2 id="b9f7" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">4.损失函数和优化器</h2><p id="5364" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">交叉熵损失和MSE损失可能是许多例子中两个比较流行的损失函数。交叉熵通常用于分类问题，从公式的核心你可能已经注意到了。它是预测值的对数的函数，在分类问题中，我们感兴趣的是将真实类别的预测值推至1，当预测值向1移动时，对数和损失将向0移动(反之亦然)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/7d5759a194fab68a9cc91640352619cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*ZMWUY-xVCrTb2bVpnn9UBw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图8:交叉熵损失(图片由作者提供)</p></figure><p id="9e6c" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">然而，我们不是在处理分类问题。我们处理的是预测一个“连续”值——介于0和(imgPixelSize-1)之间的任何值。以指示起点和终点的坐标。MSE或均方误差适用于这类问题。正如下面的核心公式所示，这里我们处理的是实际值和预测值之间的差异，而不是预测值的对数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/7aba34d2a2fb3a55dce9802844fa9a7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*p4_S4Nzxs1wltQzU-YxuWg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图9: MSE损失(图片由作者提供)</p></figure><p id="829f" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">输出向量预计包含4个数字，代表线的两个点——起点和终点。由于不熟悉哪种优化器工作得最好，我选择了SGD——在Pytorch文档的快速入门示例中，它与MSE损失一起使用。</p><h1 id="12ef" class="og la it bd lb oh oi oj le ok ol om lh jz on ka ll kc oo kd lp kf op kg lt oq bi translated">结果、观察和改进</h1><p id="6a6e" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">请参见下面的图10，了解我们上面讨论的所有内容是如何组合在一起的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图10:将所有这些整合在一起</p></figure><p id="6692" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">只是为了测试所有部分是否都按预期工作，我重新创建了一个只有100张图像的训练数据集，并用该模型运行了1个时期。虽然端到端的过程看似可行，但结果却非常糟糕。对于更大的数据集，我甚至无法完成训练。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/46158dc66e088fc34bb9f0c70b2a8bec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7V41apbEY8zbt7ZxJo6GdQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图11:不良结果— 100个图像训练数据集(作者提供的图像)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/5e675544d2cc6cd3fc6db5be6befed4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DxJcIJYlR4kiTZPS33_9lA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图12:不良结果— 1000个图像训练数据集(作者提供的图像)</p></figure><p id="9e6b" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">但这是我们想要的初稿。第一稿不是迷失在一个“部分”的完美中，而是意味着首先将整个设置到位。我们可以稍后微调这些部分。</p><h2 id="7d8b" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">爆炸梯度</h2><p id="cba0" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">在最后一次跑步中，我注意到了一些事情。一是所有结果都是NaN。当打印来自训练函数的预测时，很明显，在几轮训练后，预测开始呈指数增长，直到它变成NaN。在打印模型参数(即权重)时，它们也变成了NaN。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/edc41a5bfed05b65c3697f37cb95b23b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3lUizDH9Ntz_27AKFgauQA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图13:参数和预测都是NaN(图片作者提供)</p></figure><p id="4a58" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">这表明了爆炸梯度问题。这是当导数很大时的情况，因为当我们反向传播时梯度也很大，并且模型权重变化如此剧烈，以至于它们变得太大而无法存储并变成NaN。在图14中，您可以看到权重是如何以指数方式在各个时期更新变大的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/392e8613442aef89c1ce770fb12c4779.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/format:webp/1*ZPlHHnRUj4YSsZUpj6-_QA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图14:爆炸渐变(作者图片)</p></figure><h2 id="e936" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">标准化数据</h2><p id="304f" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">图像处理中的一个基本建议是归一化输入数据和输出，以避免爆炸梯度问题。在我们的数据中，我们没有这样做。</p><p id="5daf" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我们有两组数据。一个是图像本身，另一个是结果集。碰巧的是，我们生成图像的方式已经将背景像素标记为0，将代表线条的像素标记为1。因此不需要对图像数据进行进一步的归一化。</p><p id="181b" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">或者，如果我们处理的是一幅真实世界的图像，其中像素值可能在0到255之间变化，我们可能必须将它们除以255才能得到介于0和1之间的值。</p><p id="3d3b" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">另一方面，结果集需要一些规范化。目前，我们有绝对坐标，即一对0到127之间的数字，来代表起点和终点。让我们将它们除以128，这是我们使用的图像的大小。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/c945e2ddc6fe9e075411dcff0d4fed29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bFuG1wQedcb3m8a0JRk5Dw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图15:规范化结果集(作者图片)</p></figure><h2 id="e2cb" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">激活功能</h2><p id="c7d8" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">还要注意，我们的任何一层都没有激活功能。一般来说，跨层具有非线性激活函数是很常见的。这在一般意义上有所帮助，因为网络将学习非线性关系，没有这种关系，我们只是将一个线性函数应用于另一个，并创建一个大的线性函数。</p><p id="54a1" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">尽管有卷积层，但在它们之间缺乏非线性激活函数将导致这样一个线性网络。如果我们把不同的层看作是代表一系列抽象概念的观察者的输入图像，以寻找起点和终点为最终目标，我不得不想象这些层之间的关系的性质将不会简单地是线性的。即使是这样，也可以用非线性激活函数在模型中表示这种关系，而用线性函数表示非线性关系则是不可能的。</p><p id="1cf7" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">所以在图层后添加了ReLU。如今，在各种中枢神经系统中，标准做法是在卷积函数之后添加ReLU。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/26684fadac1031a274908164bbf23a39.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*DkvdSB9tZB6yX3-Z_Cp1FQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图16:修改后的模型(作者图片)</p></figure><h2 id="6c5c" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">减少的层</h2><p id="0493" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">考虑到我们的问题相对简单，我们还减少了卷积层的总层数。注意:我们现在没有添加任何脱落层(图像处理模型中的另一个常用功能)，因为我们处理的是非常初级的图像，而不是具有复杂图案的真实图像。因此，在我们的案例中，辍学实际上可能会伤害学习，而不是帮助学习。</p><h2 id="41ba" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">精度度量</h2><p id="c40c" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">为了获得更好的精确度，还添加了一个新的函数，允许在预测开始和结束坐标时有一定的回旋余地。即，如果(20，20)是起点的坐标，则预测(22，22)不一定是错误。因此，为了更好地了解模型是如何运行的，编写了一个新的函数，该函数将基础事实、预测和偏差作为输入参数，任何落在偏差定义的边界内的预测都不被视为错误。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/faa3b55dc1662cf257a642c4f7d241a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*EHc4aNQdEizP7QQF-hAn-w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图17:考虑偏差的准确度指标(作者图片)</p></figure><h2 id="49c2" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">学习率</h2><p id="4573" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">最后，我们必须了解要使用的正确学习率。从0.1的学习率开始，我注意到输出要么是1，要么是0。在打印线性层末端的中间权重和输出时，我注意到最后一个线性层的输出达到非常高的正值或负值。虽然参数本身没有发生如此剧烈的变化，但无论做了什么改变，都足以导致这种情况。</p><p id="06ff" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">所以我将速率降低到0.01，较慢的学习速率意味着参数值的变化较小，然后再次尝试。虽然更新确实更小，并且需要几个额外的时期，但最终结果仍然相同，输出收敛为0或1。但是0.001的情况要好得多，我注意到即使经过5个时期，这些值并没有真正变成1或0。它们在第一批结束时增加，在下一批减少，表明某种对最优解的搜索正在发生。</p><p id="8907" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">因此，在这种学习速度下，我运行了500个时期的训练，如图X中的度量标准所定义的，准确率飙升至94%以上，这使得这成为解决我们着手解决的玩具问题的一次相当令人满意的尝试。合并了上述修改后的笔记本最终版本的要点可以在这里找到。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/46bbae84469fe656900081bed9e76844.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*00CbYgGRKUw48q2UJbxvpQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图18:修改后的结果更好(作者图片)</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure></div></div>    
</body>
</html>