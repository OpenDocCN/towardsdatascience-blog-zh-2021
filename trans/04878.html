<html>
<head>
<title>Four mistakes in Clustering you should avoid</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">集群中你应该避免的四个错误</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/common-mistakes-in-cluster-analysis-and-how-to-avoid-them-eb960116d773?source=collection_archive---------7-----------------------#2021-04-28">https://towardsdatascience.com/common-mistakes-in-cluster-analysis-and-how-to-avoid-them-eb960116d773?source=collection_archive---------7-----------------------#2021-04-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5c96" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">每个人都应该知道的聚类分析的关键步骤</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/40c8c3d9dd65ac8d41c75f089b962d7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o7seR0EZ_i0faxJeAMzSDA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由来自<a class="ae ky" href="https://www.pexels.com/photo/close-up-photography-of-yellow-green-red-and-brown-plastic-cones-on-white-lined-surface-163064/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的<a class="ae ky" href="https://www.pexels.com/@pixabay?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>拍摄</p></figure><p id="7dce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">TL；博士</strong></p><ul class=""><li id="9b21" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">缺乏详尽的探索性数据分析和可消化的数据清理</li><li id="fc5a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">缺少特征缩放</li><li id="c1f6" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">没有建立代表性的集群</li><li id="1270" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">缺少分类结果的描述</li></ul></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><p id="e4ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi mq translated"><span class="l mr ms mt bm mu mv mw mx my di">答</span>在看了大量聚类方法和分析并做了大量工作后，我想与您分享聚类分析中的四个常见错误以及如何避免它们。</p><h1 id="35a4" class="mz na it bd nb nc nd ne nf ng nh ni nj jz nk ka nl kc nm kd nn kf no kg np nq bi translated">错误#1:缺乏详尽的探索性数据分析(EDA)和可消化的数据清理</h1><p id="6b0f" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">使用像<code class="fe nw nx ny nz b">.describe()</code>和<code class="fe nw nx ny nz b">.isnull().sum()</code>这样的常用方法是开始探索性分析的一个非常好的方法，但绝对不应该是你的EDA的结束。变量的<strong class="lb iu">更深层次(视觉)分析</strong>和<strong class="lb iu">它们如何相互关联</strong><strong class="lb iu">至关重要</strong>。否则，异常值等异常值可能无法完全检测出来，某些变量之间的相关性也可能无法发现。这些步骤中的错误将牵连随后的特征选择步骤和聚类结果。</p><p id="12db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您在数据集中发现了缺失值或异常值，您通常可以选择是<strong class="lb iu">用巧妙的方法</strong>替换这些值(如KNNImputer，使用平均值/中值)<strong class="lb iu">还是从数据集中删除它们</strong>。不管你在这种情况下决定做什么，重要的是要清楚地解释为什么你决定选择各自的方法。因此，你应该经常问自己这些问题(并证明答案的正确性):</p><ul class=""><li id="c60e" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">我的清理步骤对分析和建模有什么影响？</li><li id="4cdb" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如果我从数据集中删除x%的行，这意味着什么？</li><li id="008c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">离群值对我的数据集有什么影响，为什么我决定保留/删除它们？</li><li id="e1e2" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">这些异常值的原因是什么？</li></ul><h1 id="a7ad" class="mz na it bd nb nc nd ne nf ng nh ni nj jz nk ka nl kc nm kd nn kf no kg np nq bi translated">错误#2:缺少特征缩放</h1><p id="91d7" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">如果您正在使用基于距离的聚类算法，如k-means，在应用该算法之前，标准化所使用的特征<strong class="lb iu">是非常重要的。这一步骤的原因在于计算聚类的方式。</strong></p><p id="be26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">稍后确定的聚类是由数学空间中数据点之间的距离(例如欧几里德距离)定义的<strong class="lb iu">。数据集中的变量通常有不同的单位，因此也有不同的取值范围。例如，如果有一个变量的取值范围比另一个变量的取值范围大得多，它可能会强烈影响聚类结果。数据集中的每个变量通常也有不同的含义(例如，体重和身高)，因此，变量不能直接比较(例如，1公斤比1米更重要吗？).<strong class="lb iu">通过标准化我们的特征，我们可以通过将其转换为无单位的度量或相对距离来获得每个特征的相对权重。</strong></strong></p><p id="d9c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">展示标准化重要性的最佳方式是使用葡萄酒数据集示例，该示例也在sklearn的文章“特性缩放的重要性”(<a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html" rel="noopener ugc nofollow" target="_blank">链接</a>)中使用。</p><p id="99bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们看一看通常的描述性数字(tbl。1)我们不仅可以看到变量具有不同的取值范围(由于它们的单位不同)，而且其中一些变量与其他变量相比具有较高的标准偏差(std)值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/8c138da671ba5f646708b9f1a52c53b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Z5Sp1-2SPQVjAoEk"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">表1。我们的葡萄酒数据集的描述性分析。</p></figure><p id="4454" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，与其他变量如<em class="ob">镁</em> ( <strong class="lb iu"> 14.28 </strong>)或<em class="ob">苹果酸</em> ( <strong class="lb iu"> 1.12 </strong>)相比，变量<em class="ob">脯氨酸</em>具有较高的标准偏差<strong class="lb iu"> 314.91 </strong>。</p><p id="5c92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当比较单个变量的方差(std)时，巨大的差异变得更加明显(图1)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/07dcaf0cbec1abaadcbe7af264ff0c87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z34RTAkZIoMvtU28TzZBdg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图一。按方差排序的特征方差。</p></figure><p id="b4c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">很明显，与其他变量相比，脯氨酸的方差最大。</p><p id="1dee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了显示像<em class="ob">脯氨酸</em>和<em class="ob">镁</em>这样的具有高方差的变量可能主导聚类，我们应用了主成分分析(PCA ),不使用和使用所用特征的预先标准化(图2)。</p><p id="9e99" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主成分分析侧重于最大化方差的成分。如果像<em class="ob">酒精</em>这样的一个变量由于其各自的单位(例如<em class="ob">体积百分比</em>对<em class="ob">毫克/升</em>)而比另一个变量(例如<em class="ob">脯氨酸</em>)变化更小，如果这些特征没有被缩放，则PCA可以确定最大变化的方向与<em class="ob">脯氨酸</em>轴更紧密地对应。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/445c0866352da31f55f1ecc5cae602d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nSR4ZVp0K4g1HQuRKVGLZQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图二。缩放和不缩放的特征及其对PCA的影响。</p></figure><p id="6a17" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<strong class="lb iu">未缩放的情况</strong>(图2中的第一行)中，具有最高方差<em class="ob">脯氨酸</em>和<em class="ob">镁</em> <strong class="lb iu">的特征主导方向，这导致数据点</strong>的噪声聚类。</p><p id="9745" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然您可以在<strong class="lb iu">缩放案例</strong>(图2中的第二行)中看到，对于所有特征来说，t <strong class="lb iu">的幅度大致相同，并且数据点<strong class="lb iu">的聚类在这里要清晰得多</strong>。</strong></p><p id="2e8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望这个例子向您清楚地展示了为什么特征缩放对于基于距离的聚类算法(如k-means)如此重要，尽管丢失特征缩放并不是常见聚类分析中的唯一错误。</p><h1 id="76cd" class="mz na it bd nb nc nd ne nf ng nh ni nj jz nk ka nl kc nm kd nn kf no kg np nq bi translated">错误3:没有建立有代表性的集群</h1><p id="89ac" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">另一个非常常见的错误是没有建立有代表性的集群。我这么说是什么意思？一些聚类结果可能如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/c51415edd1973d39737bb18facdba17a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z5lVMppWP0v_sQwOEXHmJw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3。无代表性集群的示例。</p></figure><p id="5107" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与簇1和2相比，簇0的大小<strong class="lb iu">明显更小</strong>。当然，在某些情况下，这样的结果可能是有效的<strong class="lb iu">，如果在那个</strong>后面有可理解的推理的话。</p><p id="2432" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，这种情况通常是例外的，并且<strong class="lb iu">每个聚类的相对相等数量的数据点应该总是针对</strong>。通常<strong class="lb iu">错误在于</strong>或者是<strong class="lb iu">缺少特征缩放/选择</strong>或者是<strong class="lb iu">选择的聚类数量</strong>。</p><p id="d3f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在k-means中你通常可以使用<strong class="lb iu">肘方法</strong>或者<strong class="lb iu">剪影评分方法</strong>来确定合适的聚类数(图4)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/64135be4145393f13357688b262fa8e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O63onQcdXmWkMgvDhx_lAw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4。肘部和轮廓评分法。</p></figure><p id="d79d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用<strong class="lb iu">肘方法</strong>，您<strong class="lb iu">计算多个聚类K </strong> <strong class="lb iu">的失真</strong>(即从聚类中心到各个聚类的平方距离的平均值)<strong class="lb iu">或惯性</strong>(即样本到其最近的聚类中心的平方距离的总和)。然后，在一个图表中，将变形/惯性值与聚类数K一起可视化。在失真/惯性开始线性下降后，通过<strong class="lb iu">寻找<strong class="lb iu">图中的扭结或肘状点</strong>，从视觉上确定<strong class="lb iu">最佳集群数</strong>。看看我们的例子，这意味着3是最佳集群的数量。</strong></p><p id="0887" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了肘图法，还可以使用<strong class="lb iu">(平均)剪影评分法</strong>。</p><p id="a7ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">至于肘图法，我们也对几个聚类大小K运行k-means。但我们不是计算失真/惯性，<strong class="lb iu">而是计算每个K的轮廓系数</strong>。</p><blockquote class="of og oh"><p id="723e" class="kz la ob lb b lc ld ju le lf lg jx lh oi lj lk ll oj ln lo lp ok lr ls lt lu im bi translated">轮廓系数定义为:(x-y)/max(x，y)。</p></blockquote><p id="c9e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中<strong class="lb iu"> y代表平均类内距离</strong>(即从一个点到同一类中其他点的平均距离)。而<strong class="lb iu"> x表示平均最近聚类距离</strong>(即，到下一个最近聚类的点的平均距离)。</p><p id="0374" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">计算完成后，我们绘制系数值和聚类数K，以直观地确定合适的聚类数。在这里，我们<strong class="lb iu">为选定数量的K个集群寻找全局最优值</strong>(即图中的最高点)。至于肘图，轮廓系数图的最佳聚类数将是3。</p><p id="2581" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在应用了具有确定的最佳聚类数的聚类之后，您应该查看一下聚类结果。</p><p id="bff8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">关注属性非常有用，例如</strong>:</p><ul class=""><li id="1fde" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">集群基数</li><li id="b190" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">集群星等</li><li id="3f93" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">数量与基数</li></ul><p id="f993" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图5显示了上述属性以及使用PCA的聚类可视化。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/7749d687e7f903f3d3fe314132f598d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iJp2v9hkDrNpdqe2-K9hAg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图5。我们的集群、集群基数、数量和数量与基数的关系的可视化。</p></figure><p id="cd4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">群集基数</strong>或群集大小图显示了每个群集的点数。您可以使用此图表来查看某些分类包含的数据点是否明显少于或多于其他分类。在我们的示例中，每个集群的数据点分布看起来不错。</p><p id="4995" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">群集幅度</strong>图显示了每个群集的总点到质心的距离。此图表可用于查看每个聚类中的点的“分布”有多高，以及是否有任何簇或宽簇。</p><p id="c823" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">基数对数量</strong>图比较了集群基数和集群数量。基数较高的聚类往往也具有较高的聚类数量级。这个想法是正常的星团位于或非常接近45度线上。异常往往离它更远。在我们的例子中，群集1是异常的。</p><p id="2aae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我强烈推荐你看看谷歌开发流程图(<a class="ae ky" href="https://developers.google.com/machine-learning/clustering/interpret" rel="noopener ugc nofollow" target="_blank">链接</a>)来检查你的集群质量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/1e74f0c745c1fba41cd9d0648fbc58c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2SCjHpNKTfg67WZ0"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图6。流程图“如何检查你的聚类质量”(作者<a class="ae ky" href="https://developers.google.com/machine-learning/clustering/interpret" rel="noopener ugc nofollow" target="_blank"> Google Dev </a>)。</p></figure><h1 id="3f40" class="mz na it bd nb nc nd ne nf ng nh ni nj jz nk ka nl kc nm kd nn kf no kg np nq bi translated">错误#4:最后但同样重要的是:缺少对集群特征的描述</h1><p id="8917" class="pw-post-body-paragraph kz la it lb b lc nr ju le lf ns jx lh li nt lk ll lm nu lo lp lq nv ls lt lu im bi translated">这可能是聚类过程中最重要的一步:描述我们的发现。不幸的是，这一步大多被忽略了。</p><p id="5662" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">我们的目标是以一种非技术人员一眼就能理解的方式描述每个集群。</strong></p><p id="61c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你应该回答的问题是:</p><ul class=""><li id="b435" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">哪些特征代表了每个分类？</li><li id="4cfa" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">哪些特征区分了我的集群？</li></ul><p id="143a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个快速简单的解决方案是计算每个聚类的每个特征的平均值(tbl。2).</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/aff8af9c47451630de3316bebc291041.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z1GC8Lg537fKfDrM80GnKg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">表二。每个聚类的每个特征的平均值。</p></figure><p id="2203" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像这样的表格为读者提供了每个聚类中的特征看起来如何的第一概述。例如，我们可以看到，与其他聚类相比，聚类1包含较高的脯氨酸和镁值。</p><p id="3447" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为绝对值的替代方法，您也可以计算相对差异(tbl。3).在这种情况下，计算每个聚类的每个要素与每个要素的总体平均值的相对差异(百分比)。</p><p id="cde1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这意味着，例如，值为619时，聚类0中的特征脯氨酸与特征脯氨酸的总体平均值(743)相差-17%(=(743–619)/743)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/2f33f3ce82e28348d1e3d523f737611e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m7pzxDgeafnL3dRjT4IoBg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">表3。每个聚类的每个特征相对于每个特征的总体平均值的差异百分比。</p></figure><p id="ffd0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了表格可视化之外，绘制结果图通常也很有帮助。根据聚类和特征的数量，不同的可视化选项是合适的。</p><p id="d8fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，其中之一是在单独的图表中显示每个特征的平均值的相对差异(图7)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/7be7e05fdbb643c757a4d7bf584ef564.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UdFcXOgWvh2uVaaf4n50yA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图7。每个特征与平均值的相对差异显示为条形图。</p></figure><p id="4f2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，如果您必须处理许多功能，很容易很快失去对概览的关注。</p><p id="a653" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个可视化选项是用雷达图而不是条形图来显示集群特征(图8)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/58b87ab033648373c0ed90792e76bd0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9rbwLWGOgM16HlLX5LOgeA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图8。以雷达图形式显示的每个特征平均值的相对差异。</p></figure><p id="7576" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">聚类及其特征或与平均值的相对偏差显示为彩色区域。根据集群的数量，单个集群的特征可以一眼快速识别。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><p id="a8aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi mq translated"><span class="l mr ms mt bm mu mv mw mx my di"> C </span>光泽分析是一种(无监督的)方法，它将没有标记或分类的数据进行分组。因此，我们有责任使用正确的应用方法和最佳实践程序在数据中找到可解释和可理解的模式。但是在我们对数据进行聚类之前，不仅适当的EDA和清理是必不可少的，而且特性缩放也是必不可少的。一旦我们建立了我们的集群，我们必须确保这些结果不仅具有代表性，而且对于(商业)用户来说是可以理解的。</p><p id="9b85" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望这篇文章有助于填补一些空白，并为您的下一次聚类分析提供有用的提示。</p></div></div>    
</body>
</html>