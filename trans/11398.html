<html>
<head>
<title>Precision and Recall Made Simple</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">精确度和召回变得简单</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/precision-and-recall-made-simple-afb5e098970f?source=collection_archive---------5-----------------------#2021-11-09">https://towardsdatascience.com/precision-and-recall-made-simple-afb5e098970f?source=collection_archive---------5-----------------------#2021-11-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="08b1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过简单的例子、一步一步的解释和动画 gif，使精确度和召回容易理解</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/541a8cf309a8255a9559da62f60e0d8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zSGgydA2b1xK8J_Y"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">János Venczák 在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="61c8" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">目录</h1><ol class=""><li id="36a7" class="lr ls it lt b lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated"><a class="ae ky" href="#3ccc" rel="noopener ugc nofollow">简介</a></li><li id="6c1f" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me mf mg mh mi bi translated"><a class="ae ky" href="#8130" rel="noopener ugc nofollow">精确和召回背后的动机</a></li><li id="1e27" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me mf mg mh mi bi translated"><a class="ae ky" href="#87ae" rel="noopener ugc nofollow">什么是精准和召回？</a></li><li id="9b3f" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me mf mg mh mi bi translated"><a class="ae ky" href="#7891" rel="noopener ugc nofollow">如何不迷茫？</a></li><li id="4255" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me mf mg mh mi bi translated"><a class="ae ky" href="#4bd9" rel="noopener ugc nofollow">为什么精确度和召回率高于准确度？</a></li><li id="24c8" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me mf mg mh mi bi translated"><a class="ae ky" href="#0036" rel="noopener ugc nofollow">什么时候用精度和召回？</a></li><li id="3b29" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me mf mg mh mi bi translated"><a class="ae ky" href="#a656" rel="noopener ugc nofollow">相关资源</a></li><li id="3945" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me mf mg mh mi bi translated"><a class="ae ky" href="#3193" rel="noopener ugc nofollow">结论</a></li></ol></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="3ccc" class="kz la it bd lb lc mv le lf lg mw li lj jz mx ka ll kc my kd ln kf mz kg lp lq bi translated">1.介绍</h1><p id="4968" class="pw-post-body-paragraph na nb it lt b lu lv ju nc lw lx jx nd ly ne nf ng ma nh ni nj mc nk nl nm me im bi translated">在我之前的<a class="ae ky" href="https://medium.com/mlearning-ai/evaluating-classification-models-why-accuracy-is-not-enough-abf3d9c93a69?source=friends_link&amp;sk=c72c3d9ccb63549d861801ce772b3cc2" rel="noopener">帖子</a>中，我写了关于准确性作为二进制分类模型的评估标准。我使用癌症预测示例来说明准确性不足以评估模型在预测<strong class="lt iu">少数类别</strong>(即<strong class="lt iu">感兴趣类别</strong>或<strong class="lt iu">阳性类别</strong>)时的表现，尤其是在类别不平衡的数据集。原因是精度没有区分少数类和多数类(即<strong class="lt iu">否定类</strong>)。</p><p id="eb43" class="pw-post-body-paragraph na nb it lt b lu nn ju nc lw no jx nd ly np nf ng ma nq ni nj mc nr nl nm me im bi translated">在这篇文章中，我将分享<strong class="lt iu"> precision </strong>和<strong class="lt iu"> recall </strong>如何减轻这种准确性限制，并帮助揭示二进制分类模型的预测性能。我将使用一个简单的例子、一步一步的解释和动画 gif(附:我是一个简化事物的信徒)来浏览这些概念，甚至分享一个关于如何不混淆这两者的提示。你准备好了吗？让我们开始吧！</p><h1 id="8130" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">2.精确和回忆背后的动机</h1><p id="baf7" class="pw-post-body-paragraph na nb it lt b lu lv ju nc lw lx jx nd ly ne nf ng ma nh ni nj mc nk nl nm me im bi translated">让我们从理解为什么精确和召回是重要的开始。我们用混淆矩阵来做这个。通常，二元分类的混淆矩阵将模型预测总结为四种不同的结果，如图 1 所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/40ce03dd9c5f1e9f24904e9f97335b38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*oBPLpbh4rwRU31gYLzIZ4Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 1:二元分类的混淆矩阵(图片由作者提供)</p></figure><p id="3adf" class="pw-post-body-paragraph na nb it lt b lu nn ju nc lw no jx nd ly np nf ng ma nq ni nj mc nr nl nm me im bi translated">在我的<a class="ae ky" href="https://medium.com/mlearning-ai/evaluating-classification-models-why-accuracy-is-not-enough-abf3d9c93a69?source=friends_link&amp;sk=c72c3d9ccb63549d861801ce772b3cc2" rel="noopener">上一篇文章</a>中的癌症预测示例的背景下，这些结果描述了以下四种情况(见图 2):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/d4257388cfed45ddcc86a8c5bac1aa6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ofXM4xP4FssT8b_ghaDePg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 2:癌症预测的混淆矩阵(图片由作者提供)</p></figure><ul class=""><li id="8913" class="lr ls it lt b lu nn lw no ly nu ma nv mc nw me nx mg mh mi bi translated"><strong class="lt iu">场景#1 </strong>:模型预测癌症患者的癌症(真阳性)</li><li id="5609" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me nx mg mh mi bi translated"><strong class="lt iu">场景#2 </strong>:该模型预测一个没有癌症的患者患有癌症(假阳性)</li><li id="8095" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me nx mg mh mi bi translated"><strong class="lt iu">场景#3 </strong>:模型预测患有癌症的患者没有癌症(假阴性)</li><li id="4791" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me nx mg mh mi bi translated"><strong class="lt iu">场景#4 </strong>:模型预测没有癌症的患者没有癌症(真阴性)</li></ul><p id="bb52" class="pw-post-body-paragraph na nb it lt b lu nn ju nc lw no jx nd ly np nf ng ma nq ni nj mc nr nl nm me im bi translated">其中，场景#1 和#4 是理想的，但是场景#2 和#3 是错误的预测，并且具有不期望的结果。原因如下:</p><ul class=""><li id="6524" class="lr ls it lt b lu nn lw no ly nu ma nv mc nw me nx mg mh mi bi translated">场景#2 代表<strong class="lt iu">误报(FPs) </strong>。这意味着，在 900 名真正没有患癌症的患者中，模型显示其中 80 人患有癌症。在现实生活中，这 80 名患者可能会接受昂贵和不必要的治疗，以牺牲他们的福祉为代价。</li><li id="534b" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me nx mg mh mi bi translated">场景#3 代表<strong class="lt iu">假阴性</strong>。这意味着 100 名真正患有癌症的患者中，模型显示其中 20 人没有。这种情况的后果可能会更糟，因为这 20 名患者将无法确诊，也无法接受适当的治疗。</li></ul><p id="6caf" class="pw-post-body-paragraph na nb it lt b lu nn ju nc lw no jx nd ly np nf ng ma nq ni nj mc nr nl nm me im bi translated">可以想象，这两个场景有着非常不同但却非常重要的后果。这不仅用于预测癌症，还可用于许多其他应用。尽管我们希望所有的模型预测都落在场景#1 和#4 中，但是我们知道在现实世界中没有模型是完美的。几乎可以肯定的是，模型预测最终会有 FPs 和 fn。目标是确保<strong class="lt iu"> <em class="ny">尽可能少的 FPs 和 fn</em></strong>，评估的方法是使用<strong class="lt iu">精度</strong>和<strong class="lt iu">召回</strong>。</p><h1 id="87ae" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">2.什么是精度和召回率？</h1><p id="7da1" class="pw-post-body-paragraph na nb it lt b lu lv ju nc lw lx jx nd ly ne nf ng ma nh ni nj mc nk nl nm me im bi translated">解释了为什么精度和召回是重要的，让我们正式介绍他们。精度和召回率本身并不是很难掌握的概念<em class="ny"/>，但是很容易迷失在 TP、FP、TN 和 FN 的术语以及它们的数学公式中。我制作了动画 gif 来帮助你更好地理解精确度和召回率是如何计算的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/2599ea081e2b13e21bf8b04f58722f30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/1*M36qddUammTfYXLnXitLCg.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 3:计算精度(作者提供的 GIF)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/48fd58b66b6b92ca52f85caf1a7c7c26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/1*Ar_b6lj_TjKJh0CVZfcByw.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 4:计算召回(作者 GIF)</p></figure><p id="f0d1" class="pw-post-body-paragraph na nb it lt b lu nn ju nc lw no jx nd ly np nf ng ma nq ni nj mc nr nl nm me im bi translated">如果我们把概念和例子联系起来，总是更容易理解它们。所以，让我们用癌症预测的例子来做。</p><ul class=""><li id="c58a" class="lr ls it lt b lu nn lw no ly nu ma nv mc nw me nx mg mh mi bi translated"><strong class="lt iu">精确</strong>是关于问这样一个问题，“<em class="ny">所有被预测患有癌症的患者中，有多少真的患有癌症？</em>“在我们的例子中，160 名患者被模型预测患有癌症，但其中只有 80 人真的患有癌症。因此精度为 0.5。</li><li id="c6e9" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me nx mg mh mi bi translated"><strong class="lt iu">回忆</strong>是关于问这样一个问题，“<em class="ny">在所有真正患有癌症的患者中，有多少人被预测患有癌症？</em>“在我们的例子中，有 100 名患者真的得了癌症。其中，模型正确预测了 80。因此召回率为 0.8。</li></ul><p id="11d5" class="pw-post-body-paragraph na nb it lt b lu nn ju nc lw no jx nd ly np nf ng ma nq ni nj mc nr nl nm me im bi translated">我在上面提到过，精度和召回允许我们评估由 FPs 和 FNs 造成的错误的程度。让我解释一下。形式上，精度和召回率由下式给出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/3dbd6878387e97654fe9b613e64cc6ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:366/0*0DljcsfL9y5iKBAY"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/eaa4969c1956034b9b1ab17e4e731fe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:314/0*EEImx_EDP6TdcoNx"/></div></figure><p id="905c" class="pw-post-body-paragraph na nb it lt b lu nn ju nc lw no jx nd ly np nf ng ma nq ni nj mc nr nl nm me im bi translated">注意 FP 和 FN 是如何分别出现在精度和召回率的分母中的。这意味着:</p><ul class=""><li id="733c" class="lr ls it lt b lu nn lw no ly nu ma nv mc nw me nx mg mh mi bi translated">FPs 越少，精度越高；和</li><li id="0760" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me nx mg mh mi bi translated">fn 越少，召回率越高。</li></ul><p id="eb30" class="pw-post-body-paragraph na nb it lt b lu nn ju nc lw no jx nd ly np nf ng ma nq ni nj mc nr nl nm me im bi translated">这也意味着，如果根本没有 FNs 和 FPs，即模型做出完美的预测，则精度和召回率都将是 1。现实中，这是很难实现的。在精确度和召回率之间也有一个权衡——增加精确度会导致召回率降低，反之亦然。实际上，精确度和召回率越接近 1，模型的性能就越好。</p><h1 id="7891" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">4.如何不迷茫？</h1><p id="4ceb" class="pw-post-body-paragraph na nb it lt b lu lv ju nc lw lx jx nd ly ne nf ng ma nh ni nj mc nk nl nm me im bi translated">精度和召回很容易混淆，因为它们太相似了。我已经无数次把它们弄混了，每次都得用谷歌搜索才能知道哪个是哪个……直到我想到一个简单的窍门。以下是帮助你更好地记住它们的窍门:</p><p id="bbbb" class="pw-post-body-paragraph na nb it lt b lu nn ju nc lw no jx nd ly np nf ng ma nq ni nj mc nr nl nm me im bi translated">Precision 以字母“P”开头，所以我们把它和<strong class="lt iu"> <em class="ny">预测</em> </strong>这个词联系起来。另一方面，recall 是以字母“R”开头的，所以我们把它与单词<strong class="lt iu"> <em class="ny">联系起来，真的是</em> </strong>。</p><ul class=""><li id="ffda" class="lr ls it lt b lu nn lw no ly nu ma nv mc nw me nx mg mh mi bi translated">当你想到精度的时候，想想“R”之前的“P”(即<strong class="lt iu"> <em class="ny">预测</em> </strong>之前的<strong class="lt iu"> <em class="ny">真的</em> </strong>)，像这样:</li></ul><blockquote class="oc od oe"><p id="71a8" class="na nb ny lt b lu nn ju nc lw no jx nd of np nf ng og nq ni nj oh nr nl nm me im bi translated">“在所有<strong class="lt iu"> <em class="it">预测</em> </strong>为阳性的病例中，<strong class="lt iu"> <em class="it">真的是</em> </strong>阳性的有多少？”</p></blockquote><ul class=""><li id="c6be" class="lr ls it lt b lu nn lw no ly nu ma nv mc nw me nx mg mh mi bi translated">反之，为了回忆，想想“P”前面的“R”(即<strong class="lt iu"> <em class="ny">真的</em> </strong>在<strong class="lt iu"> <em class="ny">预测的</em> </strong>之前):</li></ul><blockquote class="oc od oe"><p id="9430" class="na nb ny lt b lu nn ju nc lw no jx nd of np nf ng og nq ni nj oh nr nl nm me im bi translated">在所有<strong class="lt iu"> <em class="it">真的</em> </strong>阳性的病例中，<strong class="lt iu"> <em class="it">预测</em> </strong>为阳性的有多少</p></blockquote><p id="f738" class="pw-post-body-paragraph na nb it lt b lu nn ju nc lw no jx nd ly np nf ng ma nq ni nj mc nr nl nm me im bi translated">我意识到试图记忆精确和回忆的数学公式是没有帮助的。当然，如果对你有用，就去做吧。否则，你很可能会把 TP，FP，FN 和 TN 弄混，就像我一直做的那样。想想我分享的这个技巧，然后在你的脑海中想象如何获得精确度和召回率(见图 3 和图 4 中的动画 gif)。最好理解它们是如何产生的，然后简单地记忆:)</p><h1 id="4bd9" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">5.为什么精确度和召回率高于准确度？</h1><h2 id="1d54" class="oi la it bd lb oj ok dn lf ol om dp lj ly on oo ll ma op oq ln mc or os lp ot bi translated">(1)评估预测误差的程度</h2><p id="c565" class="pw-post-body-paragraph na nb it lt b lu lv ju nc lw lx jx nd ly ne nf ng ma nh ni nj mc nk nl nm me im bi translated">如上所述，精度和召回允许我们评估由 FPs 和 FNs 造成的错误程度。考虑到这两种类型的错误会产生非常不同的影响，使用单独的指标来评估每种错误的程度是有意义的。在这方面不能使用精确度，因为它隐含地假设两种类型的误差同等重要，而我们知道事实并非如此。</p><h2 id="4954" class="oi la it bd lb oj ok dn lf ol om dp lj ly on oo ll ma op oq ln mc or os lp ot bi translated">(2)评估少数类的预测性能</h2><p id="3395" class="pw-post-body-paragraph na nb it lt b lu lv ju nc lw lx jx nd ly ne nf ng ma nh ni nj mc nk nl nm me im bi translated">我们在我的前一篇文章中确定，精确度不足以评估一个模型在预测少数类中的表现，因为它没有将它与多数类区分开来。然而，精确和回忆却恰恰相反。他们关注于<strong class="lt iu">正确预测的正类</strong>(注意两个公式的分子都是“TP”)。相反，他们真的不关心<strong class="lt iu">正确预测的负类</strong>(“TN”在两个公式中都根本没有出现)。</p><h1 id="0036" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">6.什么时候使用精确和召回？</h1><p id="6fba" class="pw-post-body-paragraph na nb it lt b lu lv ju nc lw lx jx nd ly ne nf ng ma nh ni nj mc nk nl nm me im bi translated">那么，你应该<em class="ny">总是</em>使用精度和召回吗？要考虑的一些简单的事情是:</p><ol class=""><li id="6203" class="lr ls it lt b lu nn lw no ly nu ma nv mc nw me mf mg mh mi bi translated">是二元分类问题吗？</li><li id="1a2a" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me mf mg mh mi bi translated">你的训练数据集在不同的班级中不平衡吗？</li><li id="8392" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me mf mg mh mi bi translated">在您的训练数据集中是否有特定的感兴趣的类别(即少数族裔类别)？</li></ol><p id="9d02" class="pw-post-body-paragraph na nb it lt b lu nn ju nc lw no jx nd ly np nf ng ma nq ni nj mc nr nl nm me im bi translated">如果以上问题的答案是“是”，那么马上知道你应该抛弃准确性，使用精确和/或回忆。当然，现实中可能还有其他因素需要考虑，但就目前而言，这将是一个很好的起点。</p><h1 id="a656" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">7.相关资源</h1><p id="4558" class="pw-post-body-paragraph na nb it lt b lu lv ju nc lw lx jx nd ly ne nf ng ma nh ni nj mc nk nl nm me im bi translated">我要感谢 Boaz shmu Eli<a class="ou ov ep" href="https://medium.com/u/57ee515c83c5?source=post_page-----afb5e098970f--------------------------------" rel="noopener" target="_blank">写的这篇精彩的文章，当我第一次开始学习分类指标时，它给了我很大的帮助。我强烈推荐它:</a></p><div class="ow ox gp gr oy oz"><a rel="noopener follow" target="_blank" href="/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2"><div class="pa ab fo"><div class="pb ab pc cl cj pd"><h2 class="bd iu gy z fp pe fr fs pf fu fw is bi translated">多类度量变得简单，第一部分:精度和召回率</h2><div class="pg l"><h3 class="bd b gy z fp pe fr fs pf fu fw dk translated">多个类的精度和召回的原因和方法(有易于理解的例子！)</h3></div><div class="ph l"><p class="bd b dl z fp pe fr fs pf fu fw dk translated">towardsdatascience.com</p></div></div><div class="pi l"><div class="pj l pk pl pm pi pn ks oz"/></div></div></a></div><p id="ba0b" class="pw-post-body-paragraph na nb it lt b lu nn ju nc lw no jx nd ly np nf ng ma nq ni nj mc nr nl nm me im bi translated">我发现其他有用的资源有:</p><ol class=""><li id="5176" class="lr ls it lt b lu nn lw no ly nu ma nv mc nw me mf mg mh mi bi translated"><a class="ae ky" href="https://medium.com/towards-data-science/model-evaluation-i-precision-and-recall-166ddb257c7b" rel="noopener">模型评测一:精度和召回</a>作者<a class="ou ov ep" href="https://medium.com/u/44e0f445aa49?source=post_page-----afb5e098970f--------------------------------" rel="noopener" target="_blank"> Tejumade Afonja </a></li><li id="26de" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me mf mg mh mi bi translated"><a class="ae ky" href="https://medium.com/analytics-vidhya/precision-vs-recall-an-intuitive-guide-for-every-machine-learning-person-796a6caa3842" rel="noopener">精确与回忆——每个机器学习者的直观指南</a>作者<a class="ou ov ep" href="https://medium.com/u/457f7ae0ea51?source=post_page-----afb5e098970f--------------------------------" rel="noopener" target="_blank"> Purva Huilgol </a></li></ol><h1 id="3193" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">8.结论</h1><p id="df3c" class="pw-post-body-paragraph na nb it lt b lu lv ju nc lw lx jx nd ly ne nf ng ma nh ni nj mc nk nl nm me im bi translated">感谢你远道而来！我希望你已经从这篇文章中受益，并且对精确度和召回率有了更好的理解——这是评估分类模型的两个非常重要的指标。请随意保存下面的备忘单，以供将来参考。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi po"><img src="../Images/e3c5d71bf35619e018c0effc939eaf0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xMl_wkMt42Hy8i84zs2WGg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 5:精确度和召回备忘单</p></figure><p id="a37a" class="pw-post-body-paragraph na nb it lt b lu nn ju nc lw no jx nd ly np nf ng ma nq ni nj mc nr nl nm me im bi translated">还有很多关于精度和召回的内容我还没有在这篇文章中介绍。您应该使用哪个——precision<em class="ny">还是</em> recall？哪个更好？如何使用<em class="ny">精度和召回来选择模型？多类分类问题怎么办？在我随后的文章中，我希望超越基础来回答这些问题。在我的下一篇文章中再见！</em></p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><p id="043f" class="pw-post-body-paragraph na nb it lt b lu nn ju nc lw no jx nd ly np nf ng ma nq ni nj mc nr nl nm me im bi translated">我喜欢将数据科学的概念分解成简单的小块，并给出清晰直观的解释。毕竟，这是我发现自己最有效的学习方式。通过分享我如何简化概念，我希望帮助人们降低学习数据科学的门槛。如果你觉得这篇文章有用，请在评论中告诉我！我也欢迎<em class="ny"> </em>的讨论、问题和建设性的反馈。也可以通过<a class="ae ky" href="https://www.linkedin.com/in/zeyalt/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和我联系。祝您愉快！</p><h1 id="c209" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">参考</h1><ol class=""><li id="14f6" class="lr ls it lt b lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">迈克·瓦西科夫斯基和薛·。使用特征选择解决小样本类别不平衡问题。<em class="ny"> IEEE 知识与数据工程汇刊</em>，22(10):1388–1400，2010 年 10 月。ISSN 1041–4347。</li><li id="b682" class="lr ls it lt b lu mj lw mk ly ml ma mm mc mn me mf mg mh mi bi translated">福斯特教务长和汤姆·福塞特。<em class="ny">商业数据科学</em>。奥莱利媒体公司，第一版，2013 年 12 月。</li></ol></div></div>    
</body>
</html>