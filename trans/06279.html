<html>
<head>
<title>Deep Learning for X-ray Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">X射线视觉的深度学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-for-x-ray-vision-bd11564760fd?source=collection_archive---------20-----------------------#2021-06-05">https://towardsdatascience.com/deep-learning-for-x-ray-vision-bd11564760fd?source=collection_archive---------20-----------------------#2021-06-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f95f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">SCSE·NTU大学最后一年项目(FYP)</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/dcb0ec5a054c3a78932d6017d48f5d81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u1Z-ZYN1fIjJCgb6uCicMw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">X射线CT图像中的气孔检测(图像来自<a class="ae kv" href="https://www.a-star.edu.sg/artc" rel="noopener ugc nofollow" target="_blank"> ARTC </a></p></figure><h1 id="e6be" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">摘要</h1><p id="d8b9" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">最近的讨论表明，添加剂材料中裂纹的位置始于孔隙。孔隙上产生的应力引发裂纹向下一个最近的孔隙扩展，最终导致破坏点。在TinkerCAD中创建了一个由逼真的孔状结构组成的3D模型，并上传到aRTist，在那里进行模拟CT扫描以生成模拟CT图像。然后使用VGStudio MAX和ImageJ软件对图像进行预处理。使用可训练的weka分割插件，每个图像被半自动标记。这些图像然后被手动校正并转换成用于训练的掩模图像。然后研究了不同的分割模型，如U-net和DeepLabV3，以执行分割任务。使用检测得分的概率来比较结果，我们得出结论:孔隙的检测严重依赖于真实数据，而不是模拟数据。</p><h1 id="d988" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">项目目标</h1><p id="c589" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">该研究的目的是评估使用模拟X射线CT图像作为真实图像的可能补充的可行性，用于语义分割中的训练数据。</p><h1 id="b129" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">使用的软件</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mk"><img src="../Images/e3df466950a7c7fb8b6cd013b3fcd4b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vBDALgiHeSawHnlT_knsmQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用的软件</p></figure><h2 id="8e41" class="ml kx iq bd ky mm mn dn lc mo mp dp lg lx mq mr li mb ms mt lk mf mu mv lm mw bi translated">TinkerCAD</h2><p id="a0b4" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><a class="ae kv" href="https://www.tinkercad.com/" rel="noopener ugc nofollow" target="_blank"> TinkerCAD </a>是由欧特克公司开发的免费在线3D建模软件工具。它的特点是使用简单的形状和空心物体的创建，从而使其适合于创建孔状物体的模拟目的。</p><h2 id="71f2" class="ml kx iq bd ky mm mn dn lc mo mp dp lg lx mq mr li mb ms mt lk mf mu mv lm mw bi translated">网格混合器</h2><p id="dae9" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><a class="ae kv" href="https://www.meshmixer.com/" rel="noopener ugc nofollow" target="_blank"> Meshmixer </a>是一款免费的3D计算机辅助设计(CAD)建模软件工具。它用于将复杂的孔隙STL文件组合在一起，作为单个对象导出到aRTist软件进行ct扫描模拟。</p><h2 id="e997" class="ml kx iq bd ky mm mn dn lc mo mp dp lg lx mq mr li mb ms mt lk mf mu mv lm mw bi translated">分析RT检测模拟工具(aRTist)</h2><p id="1235" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><a class="ae kv" href="http://www.artist.bam.de/" rel="noopener ugc nofollow" target="_blank"> aRTist </a>是对射线检测(辐射源、辐射的衰减、x光胶片和数字探测器、与CAD接口的交互式虚拟场景)进行定量描述的计算机模拟程序。</p><h2 id="f53e" class="ml kx iq bd ky mm mn dn lc mo mp dp lg lx mq mr li mb ms mt lk mf mu mv lm mw bi translated">VGStudio MAX</h2><p id="4139" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><a class="ae kv" href="https://www.volumegraphics.com/en/products/vgstudio-max.html" rel="noopener ugc nofollow" target="_blank"> Volume Graphics Studio MAX </a>是一款软件程序，旨在为用户提供处理和可视化体积数据的强大方法。它用于在使用aRTist执行模拟ct扫描后重建3D图像。</p><h2 id="92f3" class="ml kx iq bd ky mm mn dn lc mo mp dp lg lx mq mr li mb ms mt lk mf mu mv lm mw bi translated">ImageJ(斐济)</h2><p id="d018" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><a class="ae kv" href="https://imagej.net/Welcome" rel="noopener ugc nofollow" target="_blank"> ImageJ </a>是用Java编写的图像处理程序。它具有广泛的功能。这包括缩放、裁剪、降噪和以多种格式保存图像数据，例如。png，。jpeg，。Weka可训练分割插件也用于这个项目中，以执行图像的半自动标记。</p><h2 id="c072" class="ml kx iq bd ky mm mn dn lc mo mp dp lg lx mq mr li mb ms mt lk mf mu mv lm mw bi translated">Google Colab Pro</h2><p id="222b" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">为了训练模型，使用了<a class="ae kv" href="https://colab.research.google.com/signup" rel="noopener ugc nofollow" target="_blank">谷歌Colab Pro </a>特斯拉P100-PC1E-16GB。Google Colab Pro Edition还配备了速度更快的英特尔至强处理器(2.30GHz)，而免费版的英特尔至强处理器(2.20GHz)</p><h2 id="cd50" class="ml kx iq bd ky mm mn dn lc mo mp dp lg lx mq mr li mb ms mt lk mf mu mv lm mw bi translated">权重和偏差</h2><p id="2d2c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><a class="ae kv" href="https://wandb.ai/site" rel="noopener ugc nofollow" target="_blank">Weights and bias</a>是一款开发者工具，用于跟踪、比较和可视化机器学习实验。本项目中进行的所有实验都记录了重量和偏差。</p><h1 id="8daa" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">概观</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/3e319962dd6c3a5a3f9e548666d92447.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8c4Zs3wxCp7YcUy-ZY3XTA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">为产生结果而采取的步骤</p></figure><p id="b9b2" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">在这个项目中，第一步是从头开始创建一个模拟数据集，并对数据进行预处理。然后使用来自斐济的可训练weka分割插件ImageJ对数据进行标记。然后，在建模阶段测试了几个模型，这需要在数据标记过程中改进像素误差，并在实施过程中调试度量和误差。然后记录并评估结果，其中执行额外的预处理步骤和超参数调整以改善最终结果。</p><h1 id="7c08" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">数据集创建</h1><p id="26a1" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在这项工作中，重点是创建与金属(特别是铝)3D打印过程中生成的现有孔隙高度相似的孔隙。在TinkerCAD中创建CAD模型后，该模型被导出到aRTist中，在其中模拟3D对象以创建X射线ct图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/155d3821ba8d2a74f6d342c396d2ecd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*V4z_VDmHPihI40Qc8JpeWw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">模拟CT图像的输出(图像来自<a class="ae kv" href="https://www.a-star.edu.sg/artc" rel="noopener ugc nofollow" target="_blank"> ARTC </a></p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/1e74314823f2a3f32bedd27270d18552.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*5vXrC0AaQf8hf5CbDp9X_w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">模拟图像和真实图像的放大对比(图像来自<a class="ae kv" href="https://www.a-star.edu.sg/artc" rel="noopener ugc nofollow" target="_blank"> ARTC </a>)</p></figure><h1 id="2486" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">图像处理</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/8465a4649b5958f52a852eb34532ec35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wrEVKW8TZSIbn4iFuvOo0Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图像处理方法</p></figure><p id="b24b" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">执行了几种图像处理方法，以确保在训练模型之前图像是准备好的。使用VGStudio MAX和Fiji-Image软件对这些图像进行预处理。</p><h1 id="ed30" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">数据标记</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/57bc3af0edb5a5458f367208a4510775.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*sdU1B_dT744xehp-3n6Qzg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来自<a class="ae kv" href="https://imagej.net/plugins/tws/" rel="noopener ugc nofollow" target="_blank"> Weka可训练分割插件</a></p></figure><p id="32c6" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">可训练的Weka Segmentation是一个斐济插件，它将一组机器学习算法与一组选定的图像特征相结合，以产生基于像素的分割。上图显示了使用插件创建一个带标签的样本，该样本与其他几个带标签的样本一起用来注释数据集。这三个类是孔隙、对象和背景。</p><h1 id="14dd" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">系统模型化</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/87286e9f62819a0f4483d20e465d12da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*nmAmTHd6RvApMwYpiplEZg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">U-Net架构[1]</p></figure><p id="299a" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">U-net是为生物医学图像的分割而设计的，它在CT图像的制作中得到了应用。在这个项目中，我们使用Keras定义了一个U-net模型，Keras是一个开源软件库，充当Tensorflow库的高级API。除了U-Net模型之外，还在模型的末尾添加了批量标准化和漏失层。</p><h2 id="c1cc" class="ml kx iq bd ky mm mn dn lc mo mp dp lg lx mq mr li mb ms mt lk mf mu mv lm mw bi translated">使用的指标</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/3a7af659a8a5e74a69ee0329e67a6f47.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*1Dd8yD96GraNsmoQXrH_0g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">TPR =召回率=灵敏度=检测概率</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/720d0af0ec9458be3dfc937b85e57f5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZnV_usEHXfMfXsYUxkaQ8g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://gist.github.com/wassname/f1452b748efcbeb4cb9b1d059dce6f96" rel="noopener ugc nofollow" target="_blank"> Jaccard距离损失指标</a></p></figure><p id="2e17" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">项目中使用了2个指标。第一个指标是<strong class="lq ir">检测概率</strong>，或者通常称为真阳性率、召回率或灵敏度。由于背景像素覆盖了像素总数的大部分，使得难以评估模型的性能，所以没有使用交集/并集和Dice分数。</p><p id="495d" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">第二个指标是<strong class="lq ir"> Jaccard距离损耗</strong>，它改编自<a class="ae kv" href="https://gist.github.com/wassname/f1452b748efcbeb4cb9b1d059dce6f96" rel="noopener ugc nofollow" target="_blank">was name</a>。这是一个用于评估不平衡数据集的有用的度量，并且已经进行了移动，以使其收敛到0并进行平滑，从而避免爆发梯度。</p><h2 id="e4cf" class="ml kx iq bd ky mm mn dn lc mo mp dp lg lx mq mr li mb ms mt lk mf mu mv lm mw bi translated">数据集分割</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/18405bb3c738b690418d62cf32fb851f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*lYE2lmH-F7TRWCsMjSvR4Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">模拟数据和真实数据的比率</p></figure><p id="da1f" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">数据集分为6个不同的比率，混合了模拟数据和真实数据。所有数据集都使用一部分真实数据作为测试数据。</p><h2 id="39cc" class="ml kx iq bd ky mm mn dn lc mo mp dp lg lx mq mr li mb ms mt lk mf mu mv lm mw bi translated">超参数调谐</h2><p id="1070" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">为了提高模型的性能，进行了超参数调整。为了获得最佳参数，总共进行了4次扫描。每次扫描由一系列超参数组成，这些超参数将使用权重和偏差按顺序运行。</p><p id="a8e9" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated"><strong class="lq ir">在扫描之前定义了几个规则:</strong></p><ol class=""><li id="6dec" class="nk nl iq lq b lr my lu mz lx nm mb nn mf no mj np nq nr ns bi translated">使用合理的参数值</li><li id="ca75" class="nk nl iq lq b lr nt lu nu lx nv mb nw mf nx mj np nq nr ns bi translated">采用“由粗到细”的方法消除非最佳超参数</li><li id="4b4d" class="nk nl iq lq b lr nt lu nu lx nv mb nw mf nx mj np nq nr ns bi translated">假设运行中的超参数相互独立</li><li id="bd22" class="nk nl iq lq b lr nt lu nu lx nv mb nw mf nx mj np nq nr ns bi translated">使用数据集1和数据集6选择超参数</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/423ce7758126ce7efc959795d3dc5ae7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*rUBnNJg3uibfSmfkj2GCMw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">优化器扫描</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/338d324b2685fa5e042746607ec4ed58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*ldfbYrAVHoIjSJHKaRE9BA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">学习率扫描1</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/6d2c3415f322489a7075ec50ea043d09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*U2CeRUfSnZ1zd52IVzkhjw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">学习率扫描2</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/8a9909564e218b118edf232c442ad6d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*W2sslF7zdYHXYTiTkEzr5Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">批量扫描</p></figure><h1 id="af11" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结果评估</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/0add6291117cf44c940300fe3e0233c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*let8TkLKBL4CfjepI2sG3w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据集1至6的测试集结果</p></figure><p id="09a2" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">该模型被训练以在总共20个时期内收敛。从上图中，我们可以观察到，当只使用模拟数据时(D1比较)，性能明显更差。当使用更多真实数据时，数据集2至6的检测概率表现得越来越好。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/ee8e29b9aae5c6f1e45f1d40c65fbc09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aSrOze1I_i_5QoBJsJk8HQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">度量结果</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/012d7a7f9d0456bf7f2cb030aecd298f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mHCczarkUaB48UccFElUwg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(<strong class="bd oc">左</strong>原始图像来自<a class="ae kv" href="https://www.a-star.edu.sg/artc" rel="noopener ugc nofollow" target="_blank"/>|(<strong class="bd oc">中</strong>)带注释的遮罩| ( <strong class="bd oc">右</strong>)预测遮罩</p></figure><p id="42c7" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">基于所获得的结果，我们可以推断孔隙的检测严重依赖于现有数据，而不是模拟数据，因为只需要真实数据的20% (304个图像)来将数据集2中的检测概率驱动到0.9583。这也证实了来自训练集的大多数图像与测试集高度相似，这解释了其高检测概率。</p><h1 id="0f84" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><p id="b69a" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在这个项目中，我们探索了使用U-Net神经网络结构来检测ct图像中的孔隙。在TinkerCAD中创建了一个由真实毛孔组成的3D模型，并上传到aRTist，在那里进行模拟CT扫描以生成CT图像。然后，在VGStudio MAX和ImageJ中对图像进行预处理，随后，使用可训练的weka分割插件，对每个图像进行半自动标记。然后手动校正这些图像，并将其转换成用于训练的掩模图像。从真实数据和模拟数据的各种比率获得的结果表明，孔隙的检测严重依赖于真实数据，而不是模拟数据。</p><p id="b290" class="pw-post-body-paragraph lo lp iq lq b lr my jr lt lu mz ju lw lx na lz ma mb nb md me mf nc mh mi mj ij bi translated">[1]O. Ronneberger，P. Fischer和T. Brox，“U-Net:卷积网络用于生物医学图像分割”，2015年。</p><h1 id="ba80" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">链接</h1><p id="3c04" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><a class="ae kv" href="https://dr.ntu.edu.sg/handle/10356/147951" rel="noopener ugc nofollow" target="_blank">NTU博士的完整报告</a></p></div></div>    
</body>
</html>