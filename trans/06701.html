<html>
<head>
<title>Lucy says hi — 2031, AGI, and the future of A.I</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">露西向2031年，AGI和人工智能的未来问好</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lucy-says-hi-2031-agi-and-the-future-of-a-i-28b1e7b373f6?source=collection_archive---------17-----------------------#2021-06-16">https://towardsdatascience.com/lucy-says-hi-2031-agi-and-the-future-of-a-i-28b1e7b373f6?source=collection_archive---------17-----------------------#2021-06-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4f48" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在2031年，一款新的Alexa出现了，人工智能是它的特点之一。露西是什么做的？</h2></div><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="kn ko l"/></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">视频作者Javier Ideami @【https://ideami.com T2】</p></figure><p id="6198" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">露西整天都在预测你的需求和关注，并在那里与你分享美好的时光，安慰你度过艰难的时光。她诞生于深度学习革命之后的下一次革命。<strong class="kw iu">露西是什么做的？</strong></p><p id="fc0e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们想象我们在那一年，<strong class="kw iu"> 2031 </strong>(一个象征性的数字，因为Lucy可能在那个日期之后的许多年才可行)，让我们考虑关于Lucy可能有哪种基质的各种<strong class="kw iu">假设</strong>。我们开始吧！</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi lq"><img src="../Images/06484942c4704f2ba92bef81e36dfb94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*886rbVXidg1rr5WQrhWt8Q.jpeg"/></div></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">图片由作者哈维尔·艾达米@ https://ideami.com<a class="ae kt" href="https://ideami.com" rel="noopener ugc nofollow" target="_blank"/></p></figure><h1 id="689e" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">推断和类比</h1><p id="9dbf" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated"><strong class="kw iu"> AGI </strong>，<strong class="kw iu">人工通用智能</strong>，指的是一个单一系统的概念，它可以实现类似于我们的通用智能行为，而不是目前的人工智能系统，我们可以将其归类为<strong class="kw iu">狭义人工智能</strong>，并专门从事各种特定领域和任务。</p><p id="eb91" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们从考虑我们正在寻找的目标的关键部分<strong class="kw iu">开始。让我们思考一个特定的能力，它将是Lucy的一个关键部分，也是一个高级和通用智能系统的基本要素。</strong></p><p id="d312" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我说的是推断T21的能力，将相距甚远的概念和领域联系起来的能力，创造类比和隐喻的能力。</p><p id="5587" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当前的<strong class="kw iu">深度学习模型非常擅长插值</strong>。当用大量数据训练时，它们能够在结果空间中导航，通过插值产生新的结果。然而，智力缺失的一个关键特征是:</p><ul class=""><li id="ab3a" class="mu mv it kw b kx ky la lb ld mw lh mx ll my lp mz na nb nc bi translated">超越原始数据的概率分布持续外推的能力<strong class="kw iu">。</strong></li><li id="cbb7" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated">这种外推的缺乏使得类比和隐喻的创造变得复杂，也就是理解从一个领域转移到另一个领域。</li><li id="2354" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated">理解本身深深植根于我们创造类比的能力中。作为人类，我们可以很快理解事物，因为我们可以将它们与我们已经知道的其他概念和领域联系起来。缺乏推断使深刻理解的出现变得更加复杂。</li></ul><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ni"><img src="../Images/5e7ed91df11b72b4aee58dbe28b4fed6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E5vTXk70jijjx7SmaE6WPw.jpeg"/></div></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">图片由作者哈维尔·艾达米@ https://ideami.com<a class="ae kt" href="https://ideami.com" rel="noopener ugc nofollow" target="_blank">拍摄</a></p></figure><p id="8a00" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，让我们回顾一些可能的互补和重叠的路线，这些路线可能会把我们带到露西那里。</p><h1 id="6a52" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">GPT联结主义路线</h1><p id="7451" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">在我们的探索中，由<strong class="kw iu"> OpenAI </strong>创建的<strong class="kw iu"> GPT </strong>架构代表了连接主义方法。</p><ul class=""><li id="4463" class="mu mv it kw b kx ky la lb ld mw lh mx ll my lp mz na nb nc bi translated">强大的人工<strong class="kw iu">神经网络</strong>，在这种情况下，使用变压器模型，用大量数据进行<strong class="kw iu">训练。</strong></li><li id="80a0" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated">当前版本能够产生<strong class="kw iu">非常令人印象深刻的结果</strong>,这要归功于它们的<strong class="kw iu">能力，即在所学函数跨越的巨大空间内进行插值</strong>。</li><li id="a16f" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated">此时，GPT模型正被应用于许多不同的领域，从<strong class="kw iu">预测文本的延续，</strong>到填补图像或计算机代码的缺失部分。</li><li id="baca" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated">问题是<strong class="kw iu">产生的模型是脆弱的</strong>。如果你用某些输入来挑战它，你会很快注意到<strong class="kw iu">它没有达到深度“理解”</strong>。从统计学的角度来看，它正在生产任何符合当前提示的东西。</li></ul><p id="979a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，有<strong class="kw iu">人相信</strong><strong class="kw iu">随着你不断增加类似GPT的模型</strong>的规模，将会发生质的改进，我们将会看到<strong class="kw iu">外推能力以及其他高级功能的出现。</strong></p><p id="ad47" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">还有一些人说人工智能社区一直在改变目标，GPT模式今天所能取得的成就在几年前会被认为是理解。</p><p id="8dde" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是露西的一条潜在路线。人工智能社区的一部分所信仰的。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nj"><img src="../Images/5ae641c0234a462c40b82df60c2226e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gswiU3ZPp05HSza-oWuO2A.jpeg"/></div></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">照片由<a class="ae kt" href="https://unsplash.com/@alinnnaaaa?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Alina Grubnyak </a>在<a class="ae kt" href="https://unsplash.com/s/photos/network?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="d86d" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">混合路线</h1><p id="e040" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">许多人工智能专家正在倡导一种混合解决方案，这种方案结合了连续和离散的方法，我们可以把它与所谓的系统1和系统2的二元性联系起来。</p><p id="329d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在他的书《思考，快与慢》中，丹尼尔·卡内曼解释了我们大脑产生思想的两种方式:</p><ul class=""><li id="affc" class="mu mv it kw b kx ky la lb ld mw lh mx ll my lp mz na nb nc bi translated"><strong class="kw iu">系统一</strong>快速、频繁、自动、无意识</li><li id="08bc" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated"><strong class="kw iu">系统二</strong>是缓慢的、逻辑的、有意识的、分析的、不频繁的等等</li></ul><p id="6197" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">系统一</strong>与我们对周围环境和信息的<strong class="kw iu">感觉</strong>和<strong class="kw iu">感知</strong>紧密相连。深度学习模型现在做的大部分事情，都可以连接到这种系统上。</p><p id="6925" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">系统二与我们的计划、推理、分析和抽象工作的能力联系更紧密，通常与我们的高级认知功能联系更紧密。</p><p id="b088" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">缩小:</p><ul class=""><li id="8112" class="mu mv it kw b kx ky la lb ld mw lh mx ll my lp mz na nb nc bi translated"><strong class="kw iu">系统1 </strong>可以连接到<strong class="kw iu">连续可微空间</strong>。</li><li id="da6b" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated"><strong class="kw iu">系统2 </strong>与<strong class="kw iu">离散流程</strong>联系更紧密。规则、规划、逻辑论证等都有这种离散性。</li><li id="a09c" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated">这种二元性，连续与离散可以在其他形式中找到。比如量子力学中的<strong class="kw iu">粒子vs波二象性</strong>。</li></ul><p id="8c3f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，关于人工智能领域:</p><ul class=""><li id="a278" class="mu mv it kw b kx ky la lb ld mw lh mx ll my lp mz na nb nc bi translated"><strong class="kw iu">一种方法是连续方法，使用能够在连续空间轻松学习模式的可微分过程</strong>。这是深度学习擅长的领域。</li><li id="1e9f" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated">另一个是<strong class="kw iu">离散方法，利用类别、规则和<strong class="kw iu">离散元素的</strong>系统，可以在更高的抽象层次上运行。这是符号人工智能、合成编程等等的领域。</strong></li></ul><p id="922e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们来考虑一下<strong class="kw iu"> DeepMind </strong>的<strong class="kw iu"> AlphaGo </strong>项目。这个深度学习架构能够击败<strong class="kw iu">围棋</strong>的世界冠军，这是一个非常复杂并且曾经被认为不可能实现的成就。</p><p id="ad21" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> AlphaGo结合了一个卷积神经网络</strong>和一个蒙特卡洛树搜索，前者学习与游戏板相关的不同视觉模式的价值，后者在上述基础上提供了一个离散过程。</p><p id="addf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">可能活动的空间太大了。<strong class="kw iu">离散蒙特卡罗树搜索有助于缩小可能性的范围</strong>。</p><p id="1b12" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是一个简单的<strong class="kw iu">连续方法和离散方法之间协作的例子</strong>。但是，混合模式的支持者认为这种模式可以走得更远，并设想了一种更强大的离散和连续战略的组合，正如Franç ois Chollet所说，这种组合将两种方法结合起来，并在它们之间有必要的重叠。</p><p id="eb65" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">那些相信纯连接主义方法的人有一些保留意见，他们想知道:</p><ul class=""><li id="9dfc" class="mu mv it kw b kx ky la lb ld mw lh mx ll my lp mz na nb nc bi translated">人脑中的符号或离散模块在哪里？他们说，到目前为止还没有发现。</li><li id="f66b" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated">他们提出，类似符号的实体和更强大的抽象能力可能最终会从纯粹的连接主义方法中出现。</li></ul><p id="916a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，这条路线代表了<strong class="kw iu">超越纯连接主义</strong>方法的需要。就连过去对象征性人工智能颇有微词的Yoshua Bengio，现在也在倡导有必要探索深度学习和其他方法的结合。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi lq"><img src="../Images/15d95f5f63a81df25b2d30aa77bb85de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lkb-cJ9Y2MRbVU7nfP7XlA.jpeg"/></div></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">图片由作者哈维尔·艾达米@ ideami.com提供</p></figure><h1 id="8369" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">该实施例路线</h1><p id="f798" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">可能使用前面两种方法中的任何一种，Lucy可能仍然无法超越某一点。为了获得更高级的智能，露西<strong class="kw iu">可能需要能够以类似于我们的方式与世界互动</strong>。也就是说，拥有某种形式的“<strong class="kw iu">身体</strong>”和某种感知周围环境并对其做出反应的方式。</p><p id="4037" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当一个孩子与环境隔绝时会发生什么？她/他的认知能力受损。我们与环境的互动似乎是我们高级智能的关键。当然，没有人说<strong class="kw iu">环境</strong>应该是<strong class="kw iu">物理</strong>的样子。也可能是<strong class="kw iu">虚拟</strong>。一切都可能是虚拟的。</p><p id="b30d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，环境的详细程度和复杂性非常重要，我们将在下一节中对此进行更多的讨论。这就是为什么“<strong class="kw iu">真实的”世界</strong>，以其巨大的复杂性，在相当长的一段时间内，可能是人工智能实体的理想环境，<strong class="kw iu">直到</strong>我们的<strong class="kw iu">模拟变得足够复杂</strong>。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nj"><img src="../Images/731a4f9717140664922a31cba3764aec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cti0Qlv8JKUIkFWzIgiLPQ.jpeg"/></div></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">照片由<a class="ae kt" href="https://unsplash.com/@sharonmccutcheon?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">莎伦·麦卡琴</a>在<a class="ae kt" href="https://unsplash.com/s/photos/senses?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="30b0" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">强化学习路线</h1><p id="b4ff" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated"><strong class="kw iu">强化学习</strong>是机器学习的一个领域，其中<strong class="kw iu">一个代理在一个环境</strong>中采取行动，同时试图<strong class="kw iu">最大化某个奖励</strong>。当代理人结合探索和开发策略来建立一个好的行动策略以增加期望的回报时，学习就发生了。</p><p id="7832" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在David Silver、Satinder Singh、Doina Precup和Richard S.Sutton (Rich Sutton是强化学习的创始人之一)最近发表的论文“<strong class="kw iu">奖励足够了</strong>”中，研究人员指出，当在足够复杂的环境中训练时，<strong class="kw iu">强化学习可能足以达到人工一般智能</strong>。</p><p id="b926" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">他们的论文是一篇哲学论文，他们没有提供如何实现这样一个系统的细节。但是他们强烈暗示，当与足够复杂的环境互动时，强化学习可以产生一个T2露西。</p><p id="4727" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有些人对这样的假设表示怀疑，并说创造这样一个复杂而详细的环境可能需要非常先进的人工智能系统的存在。无论如何，这是另一条通往露西的路线。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nj"><img src="../Images/70b76bd5bb0e0e90f3c3b0e4eddd012f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ua53vh72Xwp6lAEvivpLQg.jpeg"/></div></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">照片由<a class="ae kt" href="https://unsplash.com/@hikeshaw?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">博夫肖</a>在<a class="ae kt" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="c28a" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">马其顿路线</h1><p id="6437" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">另一个互补的可能性是，露西将从多种方法的结合中诞生。Pedro Domingos 在他的书<strong class="kw iu">“主算法”</strong> <strong class="kw iu">中写了与学习过程相关的不同范例:<strong class="kw iu">象征主义者、联结主义者、进化论者、贝叶斯主义者和类比者</strong>。</strong></p><p id="ffed" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> Lucy </strong>可能诞生于<strong class="kw iu">将连续</strong>和<strong class="kw iu">离散</strong>方法与<strong class="kw iu">进化</strong>算法相结合，以及与其他策略如<strong class="kw iu">贝叶斯</strong>相结合，后者允许我们更多地考虑我们周围世界的不确定性。</p><p id="551d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">佩德罗·多明戈斯和他的同事们一直在用这些混合物做实验，产生了有趣的结果。他们的研究正在进行中。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nj"><img src="../Images/961f65ad311bdc408732802ae663fa0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E54HA3kxQn3gLe8HSX4Cjw.jpeg"/></div></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">照片由<a class="ae kt" href="https://unsplash.com/@jannisbrandt?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Jannis Brandt </a>在<a class="ae kt" href="https://unsplash.com/s/photos/fruit-mix?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><h1 id="0e8b" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">网络路由</h1><p id="2e2c" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">Ben Goertzel博士是奇点网的创始人。这个项目代表了通过多个人工智能代理的交互来寻找<strong class="kw iu">AGI出现的方法。在SingularityNET中，这是通过利用<strong class="kw iu">区块链</strong>技术以分散的方式实现的，因此人工智能代理可以在没有任何中央监管的情况下合作解决挑战。</strong></p><p id="5e56" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">与SingularityNET并行的是，Ben Goertzel博士和他的团队正在开发<strong class="kw iu"> OpenCog </strong>，这是一个新的<strong class="kw iu"> AGI架构</strong>，它使用了<strong class="kw iu">超图知识库</strong>和<strong class="kw iu">结合了多种人工智能策略</strong>和算法，从神经网络到进化系统、逻辑引擎等。这些系统根据需要协作并更新知识图。</p><p id="4527" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">超越或补充反向传播</strong> <strong class="kw iu">算法</strong>的使用是Goertzel博士强调的要点之一。他想知道:“<strong class="kw iu">有多少神经架构仅仅因为不适合与反向传播算法一起工作而被丢弃？</strong>“作为一个例子，Ben告诉我们，当使用进化算法时，可以使用适合度估计的推理和其他策略来指导进化学习过程。当我们使用反向传播时，这些策略更难实施。因此，<strong class="kw iu"> OpenCog </strong>结合了多种策略和算法来增强系统的能力。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nk"><img src="../Images/0d4387d0d5d455097a120f66bb78cb7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*txSwGw0kTtlwBwFGDzmvlA.jpeg"/></div></div><p class="kp kq gj gh gi kr ks bd b be z dk translated"><a class="ae kt" href="https://unsplash.com/@sortino?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Joshua Sortino </a>在<a class="ae kt" href="https://unsplash.com/s/photos/network?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="a1fe" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">彭罗斯-哈梅罗夫路线</h1><p id="c671" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">诺奖得主<strong class="kw iu">罗杰·彭罗斯</strong>和科学家<strong class="kw iu">斯图尔特·哈梅罗夫</strong>是<strong class="kw iu"> Orch-OR(有组织的客观还原)</strong>的创造者，这一理论提出<strong class="kw iu">意识来自我们神经元内的量子过程</strong>(特别是在它们的微管内)，而不是来自那些神经元之间的连接。</p><p id="cce6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">尽管意识不是高级智能形式的强制性要求，但这种途径代表了高级人工智能的类型，这种人工智能可能由超越简单架构和算法的<strong class="kw iu">产生，涉及我们现实的更深层次，如上面例子中的量子过程。</strong></p><p id="71d6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，从这个角度来看，要达到一种高级形式的智能，可能需要在这个过程中涉及其他更深层次的难题。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nj"><img src="../Images/b541e6d94ed3351856372923e7d4f083.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2GfKiVAq9eueF7_P788C8g.jpeg"/></div></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">照片由<a class="ae kt" href="https://unsplash.com/@tetromino?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">分形哈桑</a>在<a class="ae kt" href="https://unsplash.com/s/photos/quantum?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><p id="dc79" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所有前面的部分可能会相互重叠。但是<strong class="kw iu">他们每一个人都强调或突出了潜在方程式</strong>的不同部分来接近露西。</p><p id="6e57" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">很有可能最终的结果会与这些假设完全不同，或者看起来像是它们的部分组合。</p><p id="2595" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是，<strong class="kw iu">如果接近露西的最佳策略是</strong>一些不同的和<strong class="kw iu">更反直觉的方式</strong>呢？为此，我们求助于肯尼斯·斯坦利教授。</p><h1 id="a27b" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated"><strong class="ak">无路可走</strong></h1><p id="ca8a" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld mr lf lg lh ms lj lk ll mt ln lo lp im bi translated">在他的优秀著作<strong class="kw iu">“为什么伟大是不可规划的”</strong><strong class="kw iu">中，肯尼斯·斯坦利教授</strong>提供了关于寻找远大目标的深刻见解(比如露西):</p><ul class=""><li id="dc04" class="mu mv it kw b kx ky la lb ld mw lh mx ll my lp mz na nb nc bi translated">Kenneth Stanley告诉我们,<strong class="kw iu">当瞄准接近</strong>我们当前环境的目标和目的时，执行使我们更接近这些目标的优化过程可能会很有效(遵循朝向特定目标的梯度)。</li><li id="7772" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated">但是，<strong class="kw iu">当瞄准真正雄心勃勃的目标</strong>，那些离我们目前的状态真的很远的目标的时候，<strong class="kw iu">这个策略可能会适得其反</strong>。他提供了许多历史上的例子，在这些例子中，最终的成就看起来一点也不像导致它的垫脚石，也不像过程开始时设定的任何目标。当瞄准真正雄心勃勃的目标时，过程的结尾往往看起来一点也不像最初的意图或中间的步骤。</li><li id="0fea" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated">总之，通向远大目标的<strong class="kw iu">垫脚石</strong>通常是<strong class="kw iu">非常奇怪的</strong>。这块垫脚石并不像最终产品。因此，当最伟大的目标被设定为目标时，它们就变得更加难以实现。</li><li id="f165" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated">肯尼斯谈到了目标的暴政(当涉及到真正雄心勃勃的目标时)。目标限制了我们的视野，并可能阻止我们找到好的垫脚石，不仅可以带我们达到目标，还可以带我们去其他意想不到的地方，甚至可能比我们想象的更好。</li><li id="e077" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated">那么，我们应该如何实现一个真正雄心勃勃的目标呢？</li><li id="5e04" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated">肯尼斯·斯坦利教授说:“<strong class="kw iu">为了实现我们的最高目标，我们必须愿意放弃它们</strong>”并且“<strong class="kw iu">如果你愿意停止要求伟大应该是什么样子的话，伟大是可能的</strong>”。</li><li id="b3f8" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated">因此，最好的策略是完全没有目标(当瞄准真正雄心勃勃的目标时)。</li><li id="44e0" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated">肯尼斯·斯坦利教授提倡<strong class="kw iu">遵循兴趣梯度</strong>，而不是试图朝着一个非常雄心勃勃的目标优化(遵循客观梯度)，也就是说，探索并朝着有趣的、能引起我们共鸣的东西前进。这样的过程让我们发现意想不到的垫脚石。</li><li id="6c4f" class="mu mv it kw b kx nd la ne ld nf lh ng ll nh lp mz na nb nc bi translated"><strong class="kw iu">将这些垫脚石串联起来最终会让我们走得更远。</strong>多远？也许不是我们心目中的精确目标，而是一个更好的目的地。</li></ul><p id="3e5f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">反直觉，对吧？少即是多。但是这种感觉不熟悉吗？我们在生活中不是已经习惯了吗？<strong class="kw iu">发生在我们身上的许多美好的事情，不都是在我们不经意间发生的吗？</strong>，当我们只是让自己<strong class="kw iu">朝着自己觉得有趣的方向</strong>前进，对了，朝着<strong class="kw iu">前进的时候，是什么引起了我们的共鸣</strong>？</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nj"><img src="../Images/1134769b3f8d12c9e7cb219d1d10ab7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XjeXwmM8RafsT3oLQbwP0Q.jpeg"/></div></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">伊恩·杜利在<a class="ae kt" href="https://unsplash.com/s/photos/freedom?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="43b5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">陪审团已经出来了，露西正在等待。</p><p id="a360" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你想<strong class="kw iu">阅读更多关于神经科学</strong>可能帮助我们<strong class="kw iu">到达AGI </strong>，<strong class="kw iu">查看</strong>这篇我写的<strong class="kw iu">文章</strong>:</p><div class="ns nt gp gr nu nv"><a rel="noopener follow" target="_blank" href="/towards-the-end-of-deep-learning-and-the-beginning-of-agi-d214d222c4cb"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">走向深度学习的终点和AGI的起点</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">如何最近的研究指出了战胜对立的例子，并实现更有弹性，一致…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">towardsdatascience.com</p></div></div><div class="oe l"><div class="of l og oh oi oe oj lv nv"/></div></div></a></div></div></div>    
</body>
</html>