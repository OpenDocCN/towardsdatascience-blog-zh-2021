<html>
<head>
<title>On the Gap between Adoption and Understanding</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于采纳和理解之间的差距</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/on-the-gap-between-adoption-and-understanding-971c3d63f524?source=collection_archive---------28-----------------------#2021-06-03">https://towardsdatascience.com/on-the-gap-between-adoption-and-understanding-971c3d63f524?source=collection_archive---------28-----------------------#2021-06-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="88b5" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><div class=""><h2 id="5fc9" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">自然语言处理中当前研究趋势的问题会阻碍科学研究的自由发展</h2></div><p id="8c00" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这篇博文描述了我们最近的论文:</p><p id="57b5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">费德里科·比安奇和德克·霍维(2021)。<a class="ae lk" href="https://aclanthology.org/2021.findings-acl.340.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kq ja">关于NLP </strong> </a>中采用与理解的差距。计算语言学协会的发现。计算语言学协会(即将出现)。</p><p id="3c88" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这项工作的主要重点是描述目前影响NLP研究和阻碍科学发展的问题。NLP是由方法学论文驱动的，方法学论文产生更快，因此满足了研究人员尽可能多地发表论文的动机。然而，模型发布和应用程序使用的速度可能会超过发现其风险和局限性的速度。随着它们规模的增长，复制这些模型来发现这些方面变得更加困难。</p><p id="6cbf" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">Dirk和我探讨了其中最受关注的5个问题:模型的早期采用(T8)、计算论文(T10)在我们社区的流行(T11)、发表偏倚(T12 )( T13)、模型的计算不可获得性(T14 )( T15)和方法的不可解释性(T16 )( T17)。</p><p id="3fbc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下图简要总结了这些问题:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lm"><img src="../Images/ff411b38043406edb2de9c6c487e450c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p_r1zDlvfycR7sFo4M01Bg.jpeg"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">当前自然语言处理研究中的问题。图片作者。</p></figure><p id="ef8e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">简而言之，随着产出(模型、出版物、数据集)的增加，我们创造了一个这些方法在被完全理解之前就被广泛使用的局面，以及一个让这种局面永久化的激励体系。</p><h1 id="f9ef" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">早期采用</h1><blockquote class="mu"><p id="dcdc" class="mv mw iq bd mx my mz na nb nc nd lj dk translated">我们不能完全控制语言模型。在没有充分意识到副作用的情况下采用新技术是一种冒险行为。</p></blockquote><p id="b2d2" class="pw-post-body-paragraph ko kp iq kq b kr ne ka kt ku nf kd kw kx ng kz la lb nh ld le lf ni lh li lj ij bi translated">从研究到工业应用的时间在最近一年大大缩短了。例如，今天任何人都可以在HuggingFace知识库上发布一个模型，一旦完成，它就可供世界上任何研究人员使用。然而，这种现成的可用性可能会带来很高的成本。</p><p id="42ce" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们知道像GPT-3这样的模型包含了对少数民族的系统性偏见。Abid等人(2021)表明，GPT-3的反穆斯林偏见<em class="ll">在该模型的不同使用中一致且创造性地出现。</em></p><p id="e250" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因此，使用这些模型构建的应用程序有多可靠呢？</p><p id="9d73" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在最近的一份报告中，Buchanan和他的同事提出，虽然GPT-3不能自己制造错误信息，但它可以作为一种工具，以一种前所未有的方式产生高质量的错误信息。</p><p id="4dd7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">广泛采用和完全理解(或GAU)之间的差距受到我们将在这篇博文的下一部分看到的不同方面的影响。</p><h1 id="7014" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">计算论文</h1><blockquote class="mu"><p id="12ff" class="mv mw iq bd mx my mz na nb nc nd lj dk translated">如果我们不评估源代码，我们就不能确定论文的质量。</p></blockquote><p id="55df" class="pw-post-body-paragraph ko kp iq kq b kr ne ka kt ku nf kd kw kx ng kz la lb nh ld le lf ni lh li lj ij bi translated">自然语言处理作为一门计算科学，充斥着计算论文。新的模型或方法往往会受到社区的高度赞赏，因为它们为给定的任务提供了更好的解决方案。</p><p id="4507" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然而，对这些论文的后评估考虑有限。一旦论文发表，是否有可能用代码复制结果？做到这一点有多容易？</p><p id="7842" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这个问题在机器学习中已经知道了。例如，Musgrave等人(2020)报告说，由于实验中的方法缺陷，度量学习的准确性增加在几篇论文中被错误地报告。</p><p id="235a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了快速发现方法错误，访问代码是很重要的。代码发布在我们的社区中是一个问题，因为它碰巧看到代码以jupyter-notebook的形式发布，很少有评论。</p><p id="6553" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">事实上，这类论文的评估方式缺乏系统性。举一个例子，代码审查并不是一个强制性的实践，许多发表的论文完全没有代码。</p><p id="dfae" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">关于如何设计和发布代码的更好的指导方针可以帮助减轻这个影响我们——以及一般的ML——社区的复制问题。我们已经知道易于使用的代码实现的巨大优势:HuggingFace就是一个明显的例子。</p><h1 id="4f89" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">出版偏差</h1><blockquote class="mu"><p id="8098" class="mv mw iq bd mx my mz na nb nc nd lj dk translated">出版或灭亡。不幸的是，这句话往往是对的，所有的学者都必须遵守，直到终身任职。</p></blockquote><p id="5c7e" class="pw-post-body-paragraph ko kp iq kq b kr ne ka kt ku nf kd kw kx ng kz la lb nh ld le lf ni lh li lj ij bi translated">发表论文和同行评议是现代科学的基础；如果你不能提供实质性的证据证明一个新的模型是新颖的和/或比其他研究者过去所做的更好，你就不能提出新的模型。事实上，研究人员的质量主要是通过他们研究成果的质量来评估的。</p><p id="b260" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然而，论文评审需要很多的关心和注意，并且由于有大量的论文提交给我们的会议，这个任务经常落在3个评审者和1或2个地区主席的肩上。他们必须评估几十篇论文，决定哪些是好的，哪些不是。</p><p id="3f63" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">但是这条规则对科学有帮助吗，或者只是给初级研究人员带来压力？</p><p id="7ac5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">随着这种对发表的推动，在该领域的主要会议上发表论文变得越来越困难。为了简化这个过程，像ArXiv这样的服务可以用来发布研究。ArXiv没有错，但是作为一个没有进入障碍的可变场所，它有局限性:仅仅建立在ArXiv上的出版记录是建立在流沙上的，可能会倒下。</p><h1 id="be9b" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">计算不可获得性</h1><blockquote class="mu"><p id="7d0d" class="mv mw iq bd mx my mz na nb nc nd lj dk translated">我们大多数人可以使用预先训练的BERT模型，有些人可以微调BERT，很少人可以从头开始训练BERT。更不用说GPT 3号了。</p></blockquote><p id="4c8c" class="pw-post-body-paragraph ko kp iq kq b kr ne ka kt ku nf kd kw kx ng kz la lb nh ld le lf ni lh li lj ij bi translated">你能从零开始多次训练你自己的BERT模型来评估你的新假设吗？可能不会:训练BERT一次就需要很大的计算能力，重复做这件事对除了少数研究机构之外的所有人来说都太费力了。即使是BERT微调，有时候也是一个成本很高的操作。</p><p id="01cd" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">通过要求不可能的实验来评估论文是我们需要注意的一种守门方式。</p><p id="013d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">当我们回顾和分析论文时，我们需要意识到，并不是每个人都可以像伯特一样重新培训模型，而且资源匮乏的大学可能无法提供必要的资源，甚至无法进行微调。</p><h1 id="d5d3" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">无法解释的方法</h1><blockquote class="mu"><p id="b3e1" class="mv mw iq bd mx my mz na nb nc nd lj dk translated">技术的局限性并不比它们所能带来的进步更重要。我们应该描述GPT-3的极限和它的能力。</p></blockquote><p id="2b07" class="pw-post-body-paragraph ko kp iq kq b kr ne ka kt ku nf kd kw kx ng kz la lb nh ld le lf ni lh li lj ij bi translated">GPT-3去年出现在《卫报》上。这篇文章是GPT-3“写”的，引起了公众对人工智能和人类劳动未来的强烈抗议。但是，尽管所有关于可能性的争论都值得讨论，但许多人不知何故忘记了描述这种方法的局限性。</p><p id="3a03" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">极限的描述没有出现在报纸上；相反，他们在专业期刊上找到了自己的位置，而这些期刊并不一定面向大众(本德&amp;柯勒，2020；Floridi和Chiriatti，2020年)。</p><p id="7b50" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">虽然一些科技新闻来源描述了与GPT-3相关的问题，但这些新闻并没有出现在主流报纸上。</p><p id="fc6a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们拥有的方法通常无法解释它们是如何工作的:告诉人们GPT-3可以写文章可能会引起恐慌，因为非专家的第一个假设是机器会反抗人类劳动。当我们向公众传达这些无法解释的方法时，我们还需要描述这些技术的局限性。</p><h1 id="c4e0" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">其他问题</h1><p id="887f" class="pw-post-body-paragraph ko kp iq kq b kr nj ka kt ku nk kd kw kx nl kz la lb nm ld le lf nn lh li lj ij bi translated">显然，这些并不是我们这个领域要处理的唯一问题。为了提到我们在这里没有涉及的两个问题(但是在其他论文中涉及了)，我建议读者参考这些论文:</p><ul class=""><li id="755e" class="no np iq kq b kr ks ku kv kx nq lb nr lf ns lj nt nu nv nw bi translated">双重用途问题(Lau和Baldwin，2020年)。我们是否应该检查我们所使用的技术是否以及如何以一种不好的方式被使用？</li><li id="c7c6" class="no np iq kq b kr nx ku ny kx nz lb oa lf ob lj nt nu nv nw bi translated">环境可持续性(Strubell等人，2020年)。我们将如何处理我们正在开发的模型不可持续的事实？</li></ul><h1 id="c111" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">结论</h1><p id="d040" class="pw-post-body-paragraph ko kp iq kq b kr nj ka kt ku nk kd kw kx nl kz la lb nm ld le lf nn lh li lj ij bi translated">这篇博文探讨了NLP中当前出版趋势已经恶化到不可忽视的程度的一些问题。我们不断将越来越大的模型推向市场，却没有确保我们理解它们的风险，传达它们的局限性，或者让它们可以广泛复制。如果我们希望我们的社区在未来取得积极的成果，采取行动并提供解决这些问题的方案是很重要的。</p><p id="8b9b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">有兴趣的话可以在<a class="ae lk" href="https://twitter.com/fb_vinid" rel="noopener ugc nofollow" target="_blank"> twitter </a>上找我。</p><h1 id="7e2a" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">承认</h1><p id="6d62" class="pw-post-body-paragraph ko kp iq kq b kr nj ka kt ku nk kd kw kx nl kz la lb nm ld le lf nn lh li lj ij bi translated">感谢Dirk对本文的编辑和改进建议。</p><h1 id="24ed" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">参考</h1><p id="c144" class="pw-post-body-paragraph ko kp iq kq b kr nj ka kt ku nk kd kw kx nl kz la lb nm ld le lf nn lh li lj ij bi translated">本德，e . m . &amp;柯勒，A. (2020年7月)。向NLU攀登:论数据时代的意义、形式和理解。在<em class="ll">计算语言学协会第58届年会论文集</em>(第5185–5198页)。</p><p id="ceab" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">弗洛里迪和奇里亚蒂(2020年)。GPT-3:它的性质，范围，限制和后果。<em class="ll">头脑与机器</em>，<em class="ll"> 30 </em> (4)，681–694。</p><p id="9e3e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">刘，J. H .，，鲍德温，T. (2020年7月)。给我便利，给她死亡:应该由谁来决定NLP的哪些用途是合适的，在什么基础上？。《计算语言学协会第58届年会论文集(第2908–2913页)。</p><p id="903b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">斯特鲁贝尔，e .，加内什，a .，&amp;麦卡勒姆，A. (2019年7月)。自然语言处理中深度学习的能源和政策考虑。《计算语言学协会第57届年会论文集》(第3645-3650页)。</p><p id="65cc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">Abid，m . Farooqi和j .邹(2021)。大型语言模型中持续的反穆斯林偏见。<em class="ll"> arXiv预印本arXiv:2101.05783 </em>。</p><p id="b2a3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">k .马斯格雷夫、s .贝隆吉和S. N .林(2020年8月)。度量学习现实检查。在<em class="ll">欧洲计算机视觉会议</em>(第681–699页)。斯普林格，查姆。</p></div></div>    
</body>
</html>