<html>
<head>
<title>AvatarGAN — Generate Cartoon Images using GAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AvatarGAN —使用GAN生成卡通图像</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/avatargan-generate-cartoon-images-using-gan-1ffe7d33cfbb?source=collection_archive---------5-----------------------#2021-05-26">https://towardsdatascience.com/avatargan-generate-cartoon-images-using-gan-1ffe7d33cfbb?source=collection_archive---------5-----------------------#2021-05-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b7f4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">有没有想过如何生成不属于任何人脸的bitmoji？看看GAN是如何创建这些图像的。</h2></div><p id="ead4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们大多数人都创建了自己定制的bitmoji，并在不同的社交媒体应用中使用。这些bitmoji是为特定用户定制的。但你有没有想过如何生成不属于任何人脸的bitmoji？好吧，让我们探索一下甘斯是如何为我们完成这项工作的。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/bb66dcaab72ddf14226c8d122263a589.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eoMBljB6gp8aPr0srslvHw.jpeg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">作者对AvatarGAN图像的预测</p></figure><p id="9749" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">生成对抗网络是当今计算机科学中最有趣的想法之一。GANs可以从垃圾数据集生成图像。甘是由<a class="ae ls" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">伊恩·j·古德菲勒</a>于2014年开发的。它由两个神经网络组成，这两个网络相互竞争，以使预测更加准确。</p><p id="9fea" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">生成模型找出输入数据中的特征，能够分析、捕获和复制数据集中的变化，并以无监督的方式生成看起来与输入集相似的新图像。例如，GANs可以创建类似人脸照片的图像。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/8107a074aa9ef11fca7fd8a814470606.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*91Lg0kWLV0PIA_RjsVLgsA.gif"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">来源:https://www.thispersondoesnotexist.com/<a class="ae ls" href="https://www.thispersondoesnotexist.com/" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="385e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所有这些由甘生成的图像都有一个共同的模式。每张脸的眼睛都在同一个坐标上。背景只是一个模糊的随机纹理。如果有多个面，第二个面的形状会非常扭曲。</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><p id="ab95" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们开始训练之前，让我们先了解一下GANs是如何工作的。</p><p id="e10c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">生成</strong>顾名思义就是试图生成看起来像真图像的假图像。它学习特征的概率<em class="lb"> X </em>。发生器将噪声(随机特征)作为输入噪声。</p><p id="34d0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">鉴别器</strong>是一个二元分类器，试图区分真实图像和生成器生成的图像。它学习类<em class="lb"> Y </em>(真或假)给定特征<em class="lb"> X </em>的概率。概率是生成器的反馈。</p><blockquote class="mb mc md"><p id="6cc6" class="kf kg lb kh b ki kj jr kk kl km ju kn me kp kq kr mf kt ku kv mg kx ky kz la ij bi translated">发电机学会制造看起来像真的假货。鉴别者学会辨别真假。</p></blockquote><p id="f97d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">训练GANs的步骤:</p><ol class=""><li id="2c91" class="mh mi iq kh b ki kj kl km ko mj ks mk kw ml la mm mn mo mp bi translated">定义发生器和鉴别器网络架构</li><li id="478c" class="mh mi iq kh b ki mq kl mr ko ms ks mt kw mu la mm mn mo mp bi translated">训练生成器模型以生成可以欺骗鉴别器的假数据</li><li id="d3cc" class="mh mi iq kh b ki mq kl mr ko ms ks mt kw mu la mm mn mo mp bi translated">训练鉴别器模型以区分真实数据和虚假数据</li><li id="9e77" class="mh mi iq kh b ki mq kl mr ko ms ks mt kw mu la mm mn mo mp bi translated">继续训练几个时期，并保存发电机模型</li></ol><p id="6652" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本质上，我们把随机噪声通过发生器。生成器生成假图像。该输出图像连同来自真实图像数据集的图像流一起被传递到鉴别器。真实和伪造的图像都被提供给鉴别器，鉴别器返回图像真实性的概率。然后，我们从鉴别器输出计算成本函数，并更新两个模型的权重。</p><blockquote class="mb mc md"><p id="a489" class="kf kg lb kh b ki kj jr kk kl km ju kn me kp kq kr mf kt ku kv mg kx ky kz la ij bi translated">噪声→发生器→特性→鉴别器→输出→成本(输出)</p></blockquote><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mv"><img src="../Images/a4ce7ace40fbede75e4be32ac56574ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WqHKy8OhdNCVpJIkpg88cw.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">甘建筑—作者图片</p></figure><h1 id="c7cb" class="mw mx iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">甘的训练</h1><p id="2464" class="pw-post-body-paragraph kf kg iq kh b ki no jr kk kl np ju kn ko nq kq kr ks nr ku kv kw ns ky kz la ij bi translated">现在，我们已经完成了GAN的基础知识，是时候进行繁重的工作并训练模型了。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/60bd9beb5ad0eab1df75ca8ab214b41f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*66QefmU0YsH7gAtWs7Furg.gif"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">GIF via <a class="ae ls" href="https://giphy.com/gifs/olympics-shaun-the-sheep-aardman-xT8qBmSnYDXS21ZvHO" rel="noopener ugc nofollow" target="_blank"> Giphy </a></p></figure><h2 id="3d43" class="nu mx iq bd my nv nw dn nc nx ny dp ng ko nz oa ni ks ob oc nk kw od oe nm of bi translated">1.资料组</h2><p id="bb5a" class="pw-post-body-paragraph kf kg iq kh b ki no jr kk kl np ju kn ko nq kq kr ks nr ku kv kw ns ky kz la ij bi translated">我们将在<a class="ae ls" href="https://google.github.io/cartoonset/" rel="noopener ugc nofollow" target="_blank">卡通场景</a>上训练我们的甘，这是一组随机的二维卡通化身图像。这些漫画有10个艺术类别、4个颜色类别和4个比例类别，所以我们有很多可能的组合。我们将使用包含100，000个随机选择的卡通图像的数据集。</p><p id="8549" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下一步是读取所有图像。由于我们有许多图像要读取和处理，这项任务可能需要一段时间。因此，我们将读取所有的图像，将其转换为JPG格式，调整其大小，将其规范化，并将预处理后的图像存储为二进制文件。只执行一次这一系列步骤会更有效。这样我们可以简单地读取处理过的图像数据并快速使用它。我们将为所有图像创建一个Numpy数组，并将其保存为一个. npy文件。我们使用Numpy二进制而不是Pickle，因为该文件非常大，可能会导致某些版本的Pickle出现问题。</p><p id="07b5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，为了在内存中保存图像，我们将使用tensor flow<a class="ae ls" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank">TF . data . dataset</a>。Dataset对象用于编写描述性的高效输入管道。迭代以流的方式发生，因此完整的数据集不需要适合内存。</p><h2 id="e433" class="nu mx iq bd my nv nw dn nc nx ny dp ng ko nz oa ni ks ob oc nk kw od oe nm of bi translated">2.建立模型</h2><p id="01cc" class="pw-post-body-paragraph kf kg iq kh b ki no jr kk kl np ju kn ko nq kq kr ks nr ku kv kw ns ky kz la ij bi translated">这两个模型都使用Keras顺序类。</p><p id="6fe2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">发电机</strong></p><p id="090b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">生成器需要上采样层来从噪声(即种子)生成图像。我们可以使用<em class="lb"> UpSampling2D() </em>和<em class="lb"> Conv2DTranspose() </em>进行上采样。</p><p id="bfc5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lb"> UpSampling2D </em> </strong>只是利用一些上采样技术对图像矩阵进行简单的放大。我们通常使用最近邻法或双线性上采样法。所以没有机器在这里学习。向上采样2D的好处是它很便宜。而<strong class="kh ir"> <em class="lb"> Conv2DTranspose </em> </strong>层是一个卷积运算，学习几个类似于常规Conv2D层的滤波器。转置层简单地交换向后和向前传递，保持其余的操作相同。Conv2DTranspose也将对其输入进行上采样，但关键的区别在于，该模型应该了解什么是该作业的最佳上采样功能。</p><p id="33c0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一层是密集层，其输入是种子噪声。然后我们对其进行多次上采样，直到尺寸为<em class="lb">28</em>x<em class="lb">28</em>x<em class="lb">1</em>。对于生成器，我们将使用LeakyReLU激活函数，对于最后一层，我们将使用tanh。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi og"><img src="../Images/d1284eef70039a614cae449fe1a3eace.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ha-KDefLwg82rIkvk63frw.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">来源:<a class="ae ls" href="https://arxiv.org/pdf/1511.06434.pdf" rel="noopener ugc nofollow" target="_blank"> DCGAN </a></p></figure><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="36ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们尝试绘制生成器神经网络生成的图像。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="oh oi l"/></div></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/5f91d4326048abd4183055aaac4259b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*vuHzBF3Spin2GxA5csAjSQ.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">训练前由生成器根据随机噪声生成的图像—作者提供的图像</p></figure><p id="f1ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">鉴别器</strong></p><p id="020d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">鉴别器网络是一种简单的卷积神经网络图像分类器。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="2b27" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们检查一下我们的鉴别器模型的输出。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="bf4f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">输出:<em class="lb"> tf。张量([0.50059265]]，shape=(1，1)，dtype=float32) </em></p><p id="d9d3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它返回概率得分。</p><h2 id="03d3" class="nu mx iq bd my nv nw dn nc nx ny dp ng ko nz oa ni ks ob oc nk kw od oe nm of bi translated">3.损失函数</h2><p id="b376" class="pw-post-body-paragraph kf kg iq kh b ki no jr kk kl np ju kn ko nq kq kr ks nr ku kv kw ns ky kz la ij bi translated">我们将使用二元交叉熵损失函数。BCE成本函数有两个部分，一个与每个类相关。当标签和预测相似时，该值接近零，但当标签和预测不同时，该值接近无穷大。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/00e7b0d874c54a5f7827d347b923d47d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/1*_ipVhcrkHIVy282HPOHmNQ.gif"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">二元交叉熵损失函数—作者图片</p></figure><p id="c4a3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们分解方程，分析每一部分。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/b0e334430faeb4723d00b5c6e9eeb81b.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/1*xkHv0mzvzu_d2kxZsn0dew.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">作者图片</p></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi om"><img src="../Images/ad37cfd8c61aede35bc7a303cfc306e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*_DsZoKz0iJ0Rl7Z8KSznIg.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">作者图片</p></figure><p id="c6af" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">鉴别器损失量化了鉴别器模型能够区分真实和伪造图像的程度。它将鉴别器对真实图像的预测与1的数组进行比较，并将鉴别器对虚假图像的预测与0的数组进行比较。</p><p id="2978" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">发电机损耗量化了它欺骗鉴别器的能力。直观地说，如果生成器运行良好，鉴别器会将假图像分类为真实图像(或1)。这里，我们将把鉴别器对生成图像的判定与1的数组进行比较。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="48db" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">生成器和鉴别器模型都使用Adam优化器和相同的学习速率和动量。它们的优化器是不同的，因为我们分别训练两个不同的网络。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="oh oi l"/></div></figure><h2 id="8512" class="nu mx iq bd my nv nw dn nc nx ny dp ng ko nz oa ni ks ob oc nk kw od oe nm of bi translated">4.培训渠道</h2><p id="b416" class="pw-post-body-paragraph kf kg iq kh b ki no jr kk kl np ju kn ko nq kq kr ks nr ku kv kw ns ky kz la ij bi translated">现在，我们已经定义了培训渠道的主要组成部分，让我们转到培训部分。下面的函数就是神奇之处。</p><p id="3f54" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意<em class="lb"> tf.function </em>注释的使用。这可以完善功能并提高性能。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="7fa7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这两个神经网络必须在两个单独的过程中独立训练。因此我们为梯度定义了两个独立的损失函数和独立的更新。在鉴别器模型的反向传播期间，有必要仅应用鉴别器的梯度来减少鉴别器的损耗，并且仅更新该模型的权重。如果创成式模型的权重也同时更新，模型将不会学习。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="oh oi l"/></div></figure><h2 id="681b" class="nu mx iq bd my nv nw dn nc nx ny dp ng ko nz oa ni ks ob oc nk kw od oe nm of bi translated"><strong class="ak"> 5。训练模型</strong></h2><p id="1b1a" class="pw-post-body-paragraph kf kg iq kh b ki no jr kk kl np ju kn ko nq kq kr ks nr ku kv kw ns ky kz la ij bi translated">训练数据集应该被规范化。两个类别的样本数量必须相等。对于鉴别器训练集，输入图像将是x和y，对于真实图像包含值1，对于生成的图像包含值0。而对于生成器训练集，x包含随机噪声(种子), y总是1。这里，生成器的目的是生成如此好的图像，以至于鉴别器被愚弄，并给它们分配一个接近1的概率。</p><p id="dcbb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">既然一切都准备好了，我们开始训练吧。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi on"><img src="../Images/598a92a861448ba2f1d188ba7afae8c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*lUkZYUKtkykpHNIOz3c0gg.gif"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">GIF via <a class="ae ls" href="https://giphy.com/gifs/season-15-the-simpsons-15x9-l0G18BkChcRRctMZ2" rel="noopener ugc nofollow" target="_blank"> Giphy </a></p></figure><pre class="ld le lf lg gt oo op oq or aw os bi"><span id="23fe" class="nu mx iq op b gy ot ou l ov ow">train(train_dataset, EPOCHS)</span></pre><p id="3d6e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">查看正在被训练生成卡通图像的模型。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ox"><img src="../Images/76a6d610874adfdf13e7f58e76b63e1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*onZcWG5q5px8zQ02t5FpzQ.gif"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">作者图片</p></figure><p id="4b5a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">拍拍背！我们的模型终于被训练好了，现在是时候保存它了，以便我们将来可以使用它。</p><pre class="ld le lf lg gt oo op oq or aw os bi"><span id="ddb3" class="nu mx iq op b gy ot ou l ov ow">generator.save(os.path.join(DATA_PATH, "face_generator.h5"))</span></pre><h1 id="091d" class="mw mx iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">氮化镓的应用</h1><p id="732b" class="pw-post-body-paragraph kf kg iq kh b ki no jr kk kl np ju kn ko nq kq kr ks nr ku kv kw ns ky kz la ij bi translated">现在我们知道了GAN的功能，是时候检查它的迷人应用了。在研究中有大量关于GAN的用法。</p><h2 id="bfb0" class="nu mx iq bd my nv nw dn nc nx ny dp ng ko nz oa ni ks ob oc nk kw od oe nm of bi translated">图像到图像的翻译</h2><p id="3303" class="pw-post-body-paragraph kf kg iq kh b ki no jr kk kl np ju kn ko nq kq kr ks nr ku kv kw ns ky kz la ij bi translated">在GANs的帮助下，我们可以进行照片的翻译。<a class="ae ls" href="https://arxiv.org/abs/1611.07004" rel="noopener ugc nofollow" target="_blank"> Phillip Isola </a>在论文中展示了pix2pix方法用于许多图像到图像的翻译任务。例如，使用GANs，我们可以将马的图像转换成斑马，从草图创建彩色照片，彩色黑白图像，等等。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi oy"><img src="../Images/a45c1b9c41509c92e6583652057b9b2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nKe_kwZoefrELGHh06sbuw.jpeg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">来源:<a class="ae ls" href="https://arxiv.org/abs/1703.10593" rel="noopener ugc nofollow" target="_blank"> CycleGAN </a></p></figure><h2 id="a3dc" class="nu mx iq bd my nv nw dn nc nx ny dp ng ko nz oa ni ks ob oc nk kw od oe nm of bi translated">甘斯安保公司</h2><p id="f599" class="pw-post-body-paragraph kf kg iq kh b ki no jr kk kl np ju kn ko nq kq kr ks nr ku kv kw ns ky kz la ij bi translated">随着人工智能的兴起，欺诈和网络威胁的风险也在增加。网络威胁会泄露大量机密信息。GANs可以用来防止<em class="lb">【对抗性攻击】</em>。这些对抗性攻击使用各种技术来欺骗深度学习架构。GAN可以创建更多这样的假样本，我们可以通过在假生成的样本上训练模型来轻松地标记它们。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/a8692823267f1b5193b0bba7a3531513.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*ADF8mxpwnN79s2BE85EczQ.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">来源:<a class="ae ls" href="https://arxiv.org/pdf/1707.01613.pdf" rel="noopener ugc nofollow" target="_blank"> SSGAN </a></p></figure><p id="ddcd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae ls" href="https://arxiv.org/abs/1707.01613" rel="noopener ugc nofollow" target="_blank"> SSGAN </a>用于执行隐写分析，并检测图像中不应该出现的隐藏编码。GANs还可用于生成监督用的合成数据。</p><h2 id="264b" class="nu mx iq bd my nv nw dn nc nx ny dp ng ko nz oa ni ks ob oc nk kw od oe nm of bi translated">照片修复</h2><p id="cdd1" class="pw-post-body-paragraph kf kg iq kh b ki no jr kk kl np ju kn ko nq kq kr ks nr ku kv kw ns ky kz la ij bi translated">GANs可用于执行照片修补或斑点填充，即，填充由于某种原因被移除或被破坏的照片的缺失区域。论文<a class="ae ls" href="https://arxiv.org/abs/1604.07379" rel="noopener ugc nofollow" target="_blank">上下文编码器:通过修补的特征学习</a>已经描述了使用上下文编码器来执行照片修补。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/65bcf1acbf93b959549795a5ad4f1a8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*SY29hPaOR51e3XRwinOIuw.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">来源:<a class="ae ls" href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Generative_Image_Inpainting_CVPR_2018_paper.pdf" rel="noopener ugc nofollow" target="_blank">结合上下文注意的生成式图像修复</a></p></figure><h2 id="95d1" class="nu mx iq bd my nv nw dn nc nx ny dp ng ko nz oa ni ks ob oc nk kw od oe nm of bi translated">用于3D对象生成的GAN</h2><p id="e1a2" class="pw-post-body-paragraph kf kg iq kh b ki no jr kk kl np ju kn ko nq kq kr ks nr ku kv kw ns ky kz la ij bi translated">吴家俊提出了一种GAN，可以用来生成三维物体，如枪、椅子、汽车、沙发和桌子。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi pb"><img src="../Images/863c50e368fe3fce7752ae912552850d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KLwNcvvsPo-qbUCtzQpssA.jpeg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">来源:<a class="ae ls" href="http://3dgan.csail.mit.edu/papers/3dgan_nips.pdf" rel="noopener ugc nofollow" target="_blank">通过3D生成-对抗建模</a>学习物体形状的概率潜在空间<br/></p></figure><h1 id="fd6c" class="mw mx iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">结论</h1><p id="311c" class="pw-post-body-paragraph kf kg iq kh b ki no jr kk kl np ju kn ko nq kq kr ks nr ku kv kw ns ky kz la ij bi translated">生成器的目标是欺骗鉴别器，而鉴别器试图区分真假。两个模型都从彼此的竞争中学习。最后，假的看起来像真的。生成数据的想法开启了新的潜力，但不幸的是也带来了巨大的危险。</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><p id="55ef" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你坚持了这么久…谢谢！我希望这对你来说是一次学习经历。如果你喜欢这篇文章，请与你的朋友和同事分享。如果你觉得有用或有任何后续问题，请给我留言。</p><p id="31c6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于那些没有阅读或者没有亲自完成教程的懒人，这里有一个源代码的链接。</p><div class="pc pd gp gr pe pf"><a href="https://github.com/aakashjhawar/AvatarGAN" rel="noopener  ugc nofollow" target="_blank"><div class="pg ab fo"><div class="ph ab pi cl cj pj"><h2 class="bd ir gy z fp pk fr fs pl fu fw ip bi translated">aakashjhawar/AvatarGAN</h2><div class="pm l"><h3 class="bd b gy z fp pk fr fs pl fu fw dk translated">深度卷积GAN是一种生成式对抗网络架构。它使用了几个准则，特别是…</h3></div><div class="pn l"><p class="bd b dl z fp pk fr fs pl fu fw dk translated">github.com</p></div></div><div class="po l"><div class="pp l pq pr ps po pt lm pf"/></div></div></a></div></div></div>    
</body>
</html>