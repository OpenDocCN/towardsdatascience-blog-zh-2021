<html>
<head>
<title>K-Means — Machine Learning Algorithms with Implementation in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k-Means-机器学习算法及其在Python中的实现</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/k-means-machine-learning-algorithms-with-implementation-in-python-ac1d48e90239?source=collection_archive---------16-----------------------#2021-06-05">https://towardsdatascience.com/k-means-machine-learning-algorithms-with-implementation-in-python-ac1d48e90239?source=collection_archive---------16-----------------------#2021-06-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="06c7" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">机器学习算法— 30天挑战</h2><div class=""/><div class=""><h2 id="c4e7" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">在本文中，我们将研究K-Means以及如何使用Python (Scikit-learn)实现它</h2></div><p id="82cf" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在本文中，我们将研究K-Means，这是您的ML算法库中的另一个基本且重要的无监督机器学习算法。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ln"><img src="../Images/cc0e946639f84dcdd290bd45d8efc4b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xHa7TwoWhgTKb2sdNEWsQw.jpeg"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">图片来自<a class="ae md" href="https://unsplash.com/photos/8hgmG03spF4" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="c14b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们将从了解它的功能和工作原理开始。我们将不研究数学部分，因为它本身是另一篇文章。然后我们将使用<code class="fe me mf mg mh b">scikit-learn</code>来实现它</p><ul class=""><li id="7459" class="mi mj it kt b ku kv kx ky la mk le ml li mm lm mn mo mp mq bi translated">什么是K-Means</li><li id="9e86" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm mn mo mp mq bi translated">它是如何工作的</li><li id="6296" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm mn mo mp mq bi translated">Python实现</li><li id="331e" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm mn mo mp mq bi translated">K均值中的假设</li><li id="3fb3" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm mn mo mp mq bi translated">应用程序</li><li id="a160" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm mn mo mp mq bi translated">结论</li><li id="829e" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm mn mo mp mq bi translated">你能做什么</li><li id="7897" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm mn mo mp mq bi translated">其他ML算法</li></ul><p id="15dd" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这是我30天文章写作挑战的一部分。请随意查看我的新人帖子上的文章:</p><div class="mw mx gp gr my mz"><a href="https://nouman10.medium.com/lets-publish-30-articles-in-30-days-a0b8111855bb" rel="noopener follow" target="_blank"><div class="na ab fo"><div class="nb ab nc cl cj nd"><h2 class="bd jd gy z fp ne fr fs nf fu fw jc bi translated">让我们在30天内发表30篇文章</h2><div class="ng l"><h3 class="bd b gy z fp ne fr fs nf fu fw dk translated">在这篇文章中，我将接受挑战，在未来30天内写30篇与数据科学相关的文章…</h3></div><div class="nh l"><p class="bd b dl z fp ne fr fs nf fu fw dk translated">nouman10.medium.com</p></div></div><div class="ni l"><div class="nj l nk nl nm ni nn lx mz"/></div></div></a></div></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="1aab" class="nv nw it bd nx ny nz oa ob oc od oe of ki og kj oh kl oi km oj ko ok kp ol om bi translated">什么是K-Means</h1><p id="f742" class="pw-post-body-paragraph kr ks it kt b ku on kd kw kx oo kg kz la op lc ld le oq lg lh li or lk ll lm im bi translated">K-Means是使用最广泛和最简单的无监督聚类算法之一，它根据实例(未标记数据)之间的相似性将它们分配到不同的聚类中。</p><p id="7907" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">基于未标记距离之间的距离来计算相似性。K-Means直观、易于实现、速度快。我过去曾用它通过使用聚类分配作为伪标签来微调模型，用预训练的神经网络进行无监督分类。(如果您想讨论更多内容，请随时联系我们)</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="c21f" class="nv nw it bd nx ny nz oa ob oc od oe of ki og kj oh kl oi km oj ko ok kp ol om bi translated">它是如何工作的</h1><p id="9acb" class="pw-post-body-paragraph kr ks it kt b ku on kd kw kx oo kg kz la op lc ld le oq lg lh li or lk ll lm im bi translated">K-Means的一个缺点是我们必须预先选择聚类数(<strong class="kt jd"> k </strong>)。这并不总是已知的，在达到一个合适的值之前，我们必须用不同的值进行实验(也没有标记来检查)。</p><p id="0d17" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">让我们用一个直观的例子来看看算法是如何工作的。我们将把集群的数量设置为2。假设我们有一些二维的未标记数据</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi os"><img src="../Images/9b5c6047a7963b24eeba3a98be24cbde.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*KfoSLQfgCQcnuxUGIMlIeg.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">未标记的二维数据(图片由作者提供)</p></figure><p id="b75e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">第一步:我们需要创建质心(聚类中心)，具有与数据相同的维度。</strong></p><p id="9de2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">通常，为了避免较差的初始聚类，质心被选择为已经存在的数据点之一。但是我们将创建单独的质心来更好地解释这个想法</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi os"><img src="../Images/3cf04410258f64713588db063e08b6d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*EMoZK_DiirafZhdGYaYH-A.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">初始聚类质心(图片由作者提供)</p></figure><p id="5e6e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">步骤2:将聚类分配给数据点</strong></p><p id="c054" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们计算每个数据点和聚类质心之间的距离。数据点被分配给最靠近它的聚类质心。通常使用的距离度量是欧几里德距离，其公式如下:</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/ca8577142a0b3a871fa97baa75132cf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*JbRnV2lc38j5xZE4kfz8yQ.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">欧几里德距离(图片由作者提供)</p></figure><p id="9871" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">集群:</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi os"><img src="../Images/3b1f721ccb99555ee6c337f6abf71132.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*GJ4TpERGoKPi5M70Z9BSVA.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">已分配群集(图片由作者提供)</p></figure><p id="285f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">第三步:我们改变聚类中心。</p><p id="848b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">通过取分配给该聚类的数据点的平均值来更新聚类质心。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi os"><img src="../Images/91aa5cb7c4c12b77c42e76c2d258ae4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*W87-noHs5awQV8TXgwRjLg.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">簇质心轻微移动(图片由作者提供)</p></figure><p id="e2e9" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">步骤4:重复步骤2和3，直到集群停止变化</strong></p><p id="e2d2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这就是KMeans的工作原理。在此过程中，聚类分配可能会发生变化，因为每次在步骤3中都会创建新的聚类质心，而这些新的分配又会改变聚类质心。</p><p id="2524" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如前所述，由于质心的初始选择不理想，KMeans可能会产生一些非常差的结果。因此，我们必须用不同的初始质心重复这个过程，并选择簇间变化最小的结果</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="3fd5" class="nv nw it bd nx ny nz oa ob oc od oe of ki og kj oh kl oi km oj ko ok kp ol om bi translated">Python实现</h1><p id="82b1" class="pw-post-body-paragraph kr ks it kt b ku on kd kw kx oo kg kz la op lc ld le oq lg lh li or lk ll lm im bi translated">让我们从在一些虚拟数据上实现KMeans开始。我们首先使用<code class="fe me mf mg mh b">scikit-learn</code>创建一些虚拟数据，并绘制它。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="ou ov l"/></div></figure><p id="9c03" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><code class="fe me mf mg mh b">make_blobs</code>函数为我们创建数据。要想得到和我一样的数据，一定要保持上面提到的<code class="fe me mf mg mh b">random_state</code>。这将像这样绘制数据:</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/2cc03b3e7be6b76f52da09ba6f446e6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*y7BYEQtskXffluIQIk4YdA.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">虚拟数据(图片由作者提供)</p></figure><p id="eecf" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如您所见，有三个可见的集群，因为我们已经将其传递给了<code class="fe me mf mg mh b">make_blobs</code>函数。但是在真实数据的情况下，可视化可以帮助估计聚类数量的值</p><p id="dbbc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在让我们应用<code class="fe me mf mg mh b">scikit-learn</code>中的<code class="fe me mf mg mh b">KMeans</code>，用不同的颜色绘制集群分配</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="ou ov l"/></div></figure><p id="19d4" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们将从初始化<code class="fe me mf mg mh b">KMeans</code>开始，并使其符合我们的数据。然后我们通过预测数据得到我们的聚类分配。为了绘制数据，我们需要计算分配给各个聚类的聚类点。我们通过提取每个聚类分配的索引并从数据中提取来选择数据点。这导致了下面的图:</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/eee9b883fdebbeccc487e9fd5648c3bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*3BdMohMwwvmlYgCuvVLN8Q.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">聚类分配(图片由作者提供)</p></figure><p id="52ce" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这是我们可以看到不同颜色的集群的结果</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="b248" class="nv nw it bd nx ny nz oa ob oc od oe of ki og kj oh kl oi km oj ko ok kp ol om bi translated">K均值中的假设</h1><p id="2074" class="pw-post-body-paragraph kr ks it kt b ku on kd kw kx oo kg kz la op lc ld le oq lg lh li or lk ll lm im bi translated">导致KMeans聚类不准确的原因有很多。这些原因包括:</p><ol class=""><li id="bbeb" class="mi mj it kt b ku kv kx ky la mk le ml li mm lm ox mo mp mq bi translated">簇的数量不正确</li><li id="766c" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm ox mo mp mq bi translated">各向异性分布数据(在不同方向上具有不同属性的数据)</li><li id="6d48" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm ox mo mp mq bi translated">不同方差</li><li id="02d6" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm ox mo mp mq bi translated">大小不均匀的斑点</li></ol><p id="e31c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们将使用来自sklearn网站的代码来演示这一点</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="ou ov l"/></div></figure><p id="7135" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这将导致以下情节:</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi oy"><img src="../Images/2ec65e5437616d5755ca5217dec7c786.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5BeH_hRL22g2Vy-j6toWXQ.png"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">作者图片</p></figure></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="9a4f" class="nv nw it bd nx ny nz oa ob oc od oe of ki og kj oh kl oi km oj ko ok kp ol om bi translated">应用程序</h1><ul class=""><li id="bfad" class="mi mj it kt b ku on kx oo la oz le pa li pb lm mn mo mp mq bi translated">文档聚类</li><li id="50ec" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm mn mo mp mq bi translated">确定犯罪多发地区</li><li id="461c" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm mn mo mp mq bi translated">客户细分，</li><li id="db4d" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm mn mo mp mq bi translated">保险欺诈检测</li><li id="51aa" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm mn mo mp mq bi translated">公共交通数据分析</li><li id="a229" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm mn mo mp mq bi translated">IT警报的群集</li></ul></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="e903" class="nv nw it bd nx ny nz oa ob oc od oe of ki og kj oh kl oi km oj ko ok kp ol om bi translated">结论</h1><p id="3eb5" class="pw-post-body-paragraph kr ks it kt b ku on kd kw kx oo kg kz la op lc ld le oq lg lh li or lk ll lm im bi translated">让我们总结一下本文所做的工作:</p><ul class=""><li id="a3bd" class="mi mj it kt b ku kv kx ky la mk le ml li mm lm mn mo mp mq bi translated">我们从K-Means如何工作的一般解释开始</li><li id="9002" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm mn mo mp mq bi translated">然后，我们在一些虚拟数据上用Python实现了它，并绘制了结果聚类图</li><li id="76a1" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm mn mo mp mq bi translated">然后，我们研究了KMeans的一些假设及其应用。</li></ul></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="6d0f" class="nv nw it bd nx ny nz oa ob oc od oe of ki og kj oh kl oi km oj ko ok kp ol om bi translated">您可以做什么:</h1><ul class=""><li id="c3cc" class="mi mj it kt b ku on kx oo la oz le pa li pb lm mn mo mp mq bi translated">尝试从零开始实现K-Means。</li><li id="d8ab" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm mn mo mp mq bi translated">将您的实现与<code class="fe me mf mg mh b">scikit-learn</code>中的实现进行比较</li><li id="b9f4" class="mi mj it kt b ku mr kx ms la mt le mu li mv lm mn mo mp mq bi translated">在各种其他数据集上测试上面的代码。</li></ul><p id="400f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果你有任何问题，请随时联系我。请继续关注我，因为我计划在未来讲述更多的机器学习算法</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h1 id="ff44" class="nv nw it bd nx ny nz oa ob oc od oe of ki og kj oh kl oi km oj ko ok kp ol om bi translated">其他ML算法:</h1><ul class=""><li id="b348" class="mi mj it kt b ku on kx oo la oz le pa li pb lm mn mo mp mq bi translated">线性回归——用Python实现的机器学习算法</li></ul><div class="mw mx gp gr my mz"><a href="https://medium.com/mlearning-ai/linear-regression-a-to-z-2ab3d1b7277c" rel="noopener follow" target="_blank"><div class="na ab fo"><div class="nb ab nc cl cj nd"><h2 class="bd jd gy z fp ne fr fs nf fu fw jc bi translated">线性回归—从A到Z</h2><div class="ng l"><h3 class="bd b gy z fp ne fr fs nf fu fw dk translated">在本文中，我们将从数学上研究线性回归，以及如何使用Python (Scikit-learn)实现它</h3></div><div class="nh l"><p class="bd b dl z fp ne fr fs nf fu fw dk translated">medium.com</p></div></div><div class="ni l"><div class="pc l nk nl nm ni nn lx mz"/></div></div></a></div><ul class=""><li id="9dd0" class="mi mj it kt b ku kv kx ky la mk le ml li mm lm mn mo mp mq bi translated">k-最近邻——机器学习算法及其Python实现</li></ul><div class="mw mx gp gr my mz"><a href="https://nouman10.medium.com/k-nearest-neighbors-a-to-z-with-implementation-in-python-74630ffb79a2" rel="noopener follow" target="_blank"><div class="na ab fo"><div class="nb ab nc cl cj nd"><h2 class="bd jd gy z fp ne fr fs nf fu fw jc bi translated">k-最近邻-用Python实现的A到Z</h2><div class="ng l"><h3 class="bd b gy z fp ne fr fs nf fu fw dk translated">在本文中，我们将从数学上研究k-最近邻，以及如何使用Python实现它…</h3></div><div class="nh l"><p class="bd b dl z fp ne fr fs nf fu fw dk translated">nouman10.medium.com</p></div></div><div class="ni l"><div class="pd l nk nl nm ni nn lx mz"/></div></div></a></div><ul class=""><li id="7f25" class="mi mj it kt b ku kv kx ky la mk le ml li mm lm mn mo mp mq bi translated">决策树——机器学习算法及其Python实现</li></ul><div class="mw mx gp gr my mz"><a href="https://nouman10.medium.com/decision-trees-machine-learning-algorithms-with-implementation-in-python-5bc034e67fc8" rel="noopener follow" target="_blank"><div class="na ab fo"><div class="nb ab nc cl cj nd"><h2 class="bd jd gy z fp ne fr fs nf fu fw jc bi translated">决策树——机器学习算法及其Python实现</h2><div class="ng l"><h3 class="bd b gy z fp ne fr fs nf fu fw dk translated">在本文中，我们将研究机器学习算法“决策树”以及如何使用Python实现它…</h3></div><div class="nh l"><p class="bd b dl z fp ne fr fs nf fu fw dk translated">nouman10.medium.com</p></div></div><div class="ni l"><div class="pe l nk nl nm ni nn lx mz"/></div></div></a></div></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><p id="4b9c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果您觉得以上内容对您有用，请分享并随时支持我--&gt;</p><ul class=""><li id="86c7" class="mi mj it kt b ku kv kx ky la mk le ml li mm lm mn mo mp mq bi translated"><a class="ae md" href="https://www.buymeacoffee.com/nouman10" rel="noopener ugc nofollow" target="_blank">https://www.buymeacoffee.com/nouman10</a></li></ul></div></div>    
</body>
</html>