<html>
<head>
<title>How Good Is Your NLP Model Really?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你的NLP模型到底有多好？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-good-is-your-nlp-model-really-b5ef2c0857ed?source=collection_archive---------36-----------------------#2021-08-24">https://towardsdatascience.com/how-good-is-your-nlp-model-really-b5ef2c0857ed?source=collection_archive---------36-----------------------#2021-08-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5ddf" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何评价亚马逊SageMaker为拥抱脸的变形金刚模型处理工作的NLP模型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0d76aadaeb1ef4e6348c1ac9f90c5733.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iV0IeOp9NttJiAWP"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">安托万·道特里在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="6cbd" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">这是怎么回事？</h1><p id="72e8" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">NLP项目(或任何ML项目，就此而言)的管道由几个步骤组成，包括数据处理、模型训练和部署。在模型培训和部署之间应该涉及的另一个步骤是<em class="mk">模型评估</em>。只有在评估了新训练的模型之后，我们才应该考虑下一步，这可能涉及注册和/或部署模型，或者，如果模型性能很差，则使用不同的/更多的数据对其进行重新训练:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ml"><img src="../Images/393391b3c9d617eabae1e434d44ca3d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R8piRq3JTjmWNLGPtsZi0w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">NLP项目管道(图片由作者提供)</p></figure><p id="87be" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">亚马逊SageMaker <a class="ae kv" rel="noopener" target="_blank" href="/huggingface-processing-jobs-on-amazon-sagemaker-b1f5af97b663">最近推出了拥抱脸处理作业</a>，这是专门为拥抱脸的变形金刚模型设计和优化的。<a class="ae kv" href="https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html" rel="noopener ugc nofollow" target="_blank">加工作业可用于各种任务</a>:数据预处理或后处理、特征工程、数据验证和模型评估。</p><p id="daa8" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">在这篇博文中，我们将深入探讨列表中的最后一项任务——模型评估。我们将了解模型评估的挑战，以及我们如何利用SageMaker处理作业来克服这些挑战。</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="2efa" class="kw kx iq bd ky kz my lb lc ld mz lf lg jw na jx li jz nb ka lk kc nc kd lm ln bi translated">为什么这很重要？</h1><p id="2f55" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">NLP模型评估可能是资源密集型的，尤其是对于从GPU加速中受益匪浅的Transformer模型。因此，如果我们在没有GPU的机器上运行，评估可能需要几个小时，尤其是在测试数据集很大的情况下。事实上，我们将确切地看到在我的笔记本电脑(没有GPU)上进行模型评估需要多长时间。相比之下，我们将看到，我们可以加快这一进程高达267(！)次通过使用SageMaker的拥抱脸处理作业。</p><p id="e872" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">这些处理作业不仅通过使用按需计算资源实现了更快的模型评估，而且SageMaker生态系统中的紧密集成也允许将这一步骤无缝集成到端到端的NLP管道中。</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="27cb" class="kw kx iq bd ky kz my lb lc ld mz lf lg jw na jx li jz nb ka lk kc nc kd lm ln bi translated">先决条件</h1><p id="d183" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">本教程的Github repo可以在<a class="ae kv" href="https://github.com/marshmellow77/sm-hf-model-evaluation" rel="noopener ugc nofollow" target="_blank">这里</a>找到。它包含一个用于与SageMaker处理作业交互的笔记本，以及两个评估脚本—一个用于评估本地机器(如个人笔记本电脑)上的模型，另一个用于SageMaker处理作业。</p><p id="322a" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">我们还需要一个经过训练的Transformer模型和一个相应的测试数据集。理想情况下，您可以使用自己的模型和测试数据，但是如果您没有现成的模型和测试数据，您也可以在Github repo中找到模型和测试数据。</p><p id="4784" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated"><em class="mk">(回购中的模型是一个基于DistilBERT的二元分类模型，已经过微调，可以检测电影评论中的正面和负面情绪。数据集格式为</em> <a class="ae kv" href="https://huggingface.co/docs/datasets/" rel="noopener ugc nofollow" target="_blank"> <em class="mk"> HuggingFace的数据集</em> </a> <em class="mk">。)</em></p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="5f36" class="kw kx iq bd ky kz my lb lc ld mz lf lg jw na jx li jz nb ka lk kc nc kd lm ln bi translated">如何使用培训师API评估变压器模型</h1><p id="d529" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">拥抱脸的教练API通常用于训练模型，但它也使评估一个已经训练好的模型变得非常简单和直接。我们只需要用我们想要评估的模型调用训练器API，指定测试数据，以及我们想要计算的度量的定义来评估模型:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="ffef" class="kw kx iq bd ky kz my lb lc ld mz lf lg jw na jx li jz nb ka lk kc nc kd lm ln bi translated">局部评估模型</h1><p id="c79c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">通过使用Github repo中的脚本<a class="ae kv" href="https://github.com/marshmellow77/sm-hf-model-evaluation/blob/main/scripts/evaluate-local-hf.py" rel="noopener ugc nofollow" target="_blank"><em class="mk">evaluate-local-HF . py</em></a>，我们现在可以在任何我们想要的地方评估模型。事实上，我在我的笔记本电脑(没有GPU)上运行了这个脚本，看看需要多长时间。<strong class="lq ir">但是</strong>:测试数据由大约15K条记录组成，在NLP项目中的记录数量很容易达到数百万条的今天，这实际上并不算多。然而，它仍然足以让我的笔记本电脑忙碌几个小时。因此，我没有使用整个测试数据集，而是将其精简到只有100条记录:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/cd6e6b983da00f3f2db412c3e9be1820.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*PgOpOALzrFdCA5Qez8PSmA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">100条记录的运行时间(图片由作者提供)</p></figure><p id="b698" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">结果表明，处理100条记录大约需要68秒，每批8条记录大约需要5.3秒(或每条记录0.66秒)。将此推断到15K记录的整个数据集意味着模型评估将在我的笔记本电脑上花费大约3小时。</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="4b4e" class="kw kx iq bd ky kz my lb lc ld mz lf lg jw na jx li jz nb ka lk kc nc kd lm ln bi translated">Sagemaker为拥抱脸处理作业</h1><p id="e63a" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">SageMaker处理允许我们按需配置GPU机器，并且只在评估模型所需的时间内配置。为此，我们使用稍微修改的评估脚本<a class="ae kv" href="https://github.com/marshmellow77/sm-hf-model-evaluation/blob/main/scripts/evaluate-sm-hf.py" rel="noopener ugc nofollow" target="_blank">,它可以与处理作业交互。这一次，我们将对整个测试数据集进行评估，即大约15K条记录。</a></p><p id="141b" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">为了设置模型评估，我们使用<a class="ae kv" href="https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_processing.html" rel="noopener ugc nofollow" target="_blank"> SageMaker Python SDK </a>来设置处理作业:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="7569" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">我们还需要告诉处理器在哪里可以找到模型和测试数据:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="08a5" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">然后我们可以开始模型评估:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="d3ef" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">一旦运行完成，我们可以在S3的指定输出文件夹中的JSON文件中找到评估结果(在我们的例子中，该文件将被称为<em class="mk"> evaluation.json </em>):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/1fe4fe1fb27e341bf7588ebef86396a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*_oAUwY80K5_gcWoEOogzsA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">对S3的评价结果(图片由作者提供)</p></figure><p id="9d39" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">打开这个文件为我们提供了我们在<em class="mk"> compute_metrics() </em>方法中指定的评估指标，以及来自处理作业的一些其他指标:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/6f839cbe677b10a7317b8c11474eb540.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*ET9ZwKjEzy3a0uUVU1bCEA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">评估指标(图片由作者提供)</p></figure><p id="4ee4" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">事实上，评估结果告诉我们，处理作业每秒运行177个样本。如果您还记得，我的笔记本电脑每秒运行0.66个样本，这意味着处理工作比我的笔记本电脑快267倍！我们还可以通过查看处理作业的日志来确认这一点:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/16de5e805d08aafa56004d4c996850e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*jjHOZ6TpEbJeXKCRJ0ghWg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">SageMaker上的运行时间(图片由作者提供)</p></figure><p id="4132" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">正如我们所看到的，在一个大约有15K记录的数据集上评估该模型只需要85秒的处理工作。</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="e0e9" class="kw kx iq bd ky kz my lb lc ld mz lf lg jw na jx li jz nb ka lk kc nc kd lm ln bi translated">结论</h1><p id="176e" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在这篇博文中，我们学习了如何使用Amazon SageMaker处理作业来评估基于Hugging Face的Transformer模型的NLP模型。我们看到，在SageMaker上按需使用GPU计算基础设施非常简单，并且显著加快了模型评估的速度。</p><p id="24b5" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">下一步可能是捕获整个NLP项目生命周期，包括端到端管道中的模型评估，并将其自动化，从而为NLP任务构建可扩展的CI/CD管道。</p></div></div>    
</body>
</html>