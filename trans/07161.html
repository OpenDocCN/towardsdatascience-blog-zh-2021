<html>
<head>
<title>7 Famous AI Quotes Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">7条著名的人工智能语录</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/7-famous-ai-quotes-explained-782dda72d2c5?source=collection_archive---------6-----------------------#2021-06-29">https://towardsdatascience.com/7-famous-ai-quotes-explained-782dda72d2c5?source=collection_archive---------6-----------------------#2021-06-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="4df8" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">人工智能</h2><div class=""/><div class=""><h2 id="2fb9" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">人工智能的过去、现在和未来。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/6513e7cfa2186bd7ce0cdbefaa6b5488.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7KdtwKxNXcO5Lh-I"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@matias_north?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马蒂亚斯·诺斯</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="1f0b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">人工智能已经与我们生活的方方面面交织在一起。在过去的60年里，无数的科学家和哲学家努力工作，将这个领域发展到今天的样子。几十年来，一些观点、方法和范式指导了人工智能的研究，非常聪明的人表达了他们对人工智能伟大探索的想法和见解:征服智能。</p><p id="b357" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些洞见以神秘但吸引人的短语的形式出现在我们面前，而这些短语的潜在含义却常常不为我们所知。我们被留在那里，点头同意一个复杂思想的美丽简化。但是把一句话写成一本书需要专业知识和多年的思考。西塞罗说得好，“如果我有更多的时间，我会写一封更短的信。”</p><p id="b033" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这篇文章中，我从该领域的世界级专家那里挑选了7条著名的人工智能语录，并为你解开其中的含义。尽情享受吧！</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="9c9b" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">图灵测试</h1><blockquote class="nd"><p id="25d2" class="ne nf it bd ng nh ni nj nk nl nm md dk translated">“如果一台计算机能够欺骗人类，让人类相信它是人类，那么它就应该被称为智能的。”</p><p id="a9ae" class="ne nf it bd ng nh ni nj nk nl nm md dk translated">—艾伦·图灵</p></blockquote><p id="d3c8" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">通常被认为是计算机科学之父的艾伦·图灵在1950年<a class="ae lh" href="https://academic.oup.com/mind/article/LIX/236/433/986238" rel="noopener ugc nofollow" target="_blank">发表了一篇论文</a>，他在论文中解释了回答“机器能思考吗？”这个问题的最佳方式就是改变问题本身。他认为询问机器是否能思考是没有用的，因为我们无法正式定义“思考”。</p><p id="c21d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">相反，他提出了“模仿游戏”——我们今天称之为图灵测试。模仿游戏是由三个代理人玩的问答式游戏。审讯者(特工C)向特工A或B提出如下形式的问题:“请给我写一首关于第四座桥的十四行诗”或“把34957加到70764。”特工A的任务是迷惑审讯者，让他误以为是特工B。例如，如果A是个男人，B是个女人，这个男人必须努力让审讯者相信他就是那个女人。</p><p id="3456" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">有了这个框架，图灵提出，原来的问题可以换成“当一台机器在这个游戏中扮演A的角色时会发生什么？”代理人A可以被换成一台通用的数字计算机来测试它的认知能力，如果这台计算机能够欺骗询问者，使其认为它是人类，那么它就应该被称为智能的。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="432a" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">人工智能的未来</h1><blockquote class="nd"><p id="e47e" class="ne nf it bd ng nh ni nj nk nl nm md dk translated">"未来取决于某个对我所说的一切深感怀疑的研究生。"</p><p id="9940" class="ne nf it bd ng nh ni nj nk nl nm md dk translated">—杰弗里·辛顿</p></blockquote><p id="5acf" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">现在被称为人工智能“教父”的杰弗里·辛顿(Geoffrey Hinton)最初是作为认知心理学家接受培训的。这就是为什么当几乎没有人工作时，他一直试图让人工神经网络(ANN)工作。当时，专家认为连接主义AI是一条死胡同，即使大脑是由生物神经网络组成的。但辛顿一直认为，“为了让人工智能发挥作用，我们必须以类似于人脑的方式进行计算。”</p><p id="989b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，深度学习并不像大脑那样工作。即使人工神经网络的名称来自神经科学，但它们在最基本的意义上不同于生物神经网络。人工神经元是一种超级简化的构造，是在生物神经元的基础上构建的，但假设它们只是基础数学的愚蠢计算器。然而，<a class="ae lh" href="https://science.sciencemag.org/content/367/6473/83" rel="noopener ugc nofollow" target="_blank">已经证明</a>“单个神经元可能能够计算真正复杂的功能。例如，它本身可能能够识别一个物体。”</p><p id="de0c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">纵观全局，辛顿的怀疑是坚定的:计算机视觉和CNN<a class="ae lh" href="https://bdtechtalks.com/2020/03/02/geoffrey-hinton-convnets-cnn-limits/" rel="noopener ugc nofollow" target="_blank">不像我们的视觉系统</a>那样工作。深度学习系统需要大量的数据，而<a class="ae lh" href="https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199573776.001.0001/oxfordhb-9780199573776-e-10" rel="noopener ugc nofollow" target="_blank">由于先天的大脑结构，人类从稀疏的数据中学习</a>。而计算机需要巨大的功率来训练最先进的AI，而大脑只消耗20W。Geoffrey Hinton为深度学习奠定了基础，他知道未来的人工智能将走上一条不同的道路。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="f09e" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">意识人工智能</h1><blockquote class="nd"><p id="5908" class="ne nf it bd ng nh ni nj nk nl nm md dk translated">"根本没有人知道如何建造一台有意识的机器."</p><p id="88ad" class="ne nf it bd ng nh ni nj nk nl nm md dk translated">—斯图尔特·罗素</p></blockquote><p id="4dc9" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">有数百本关于意识的书，原因是没有人理解它。正如劳伦斯·克劳斯在接受《诺姆·乔姆斯基》采访时指出的，“一个领域的已知程度和关于这个领域的书籍数量成反比。”</p><p id="081a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们对意识知之甚少。人们普遍认为，大脑中的活动产生了心理过程和我们对现实的主观体验。但是我们对它是如何出现的一无所知。生物电信号是如何产生丰富的、无限的思想、感觉和知觉的，这是完全未知的。不了解科学，就认为我们可以创造技术是愚蠢的。</p><p id="9c6f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，有些人担心我们会建立有意识的人工智能。如果我们真的做到了，其意义将远远大于构建无意识的一般智能。这就是为什么有技术术语来区分这两者:AGI，经常指的是不一定有意识的人类水平的智能——罗素所争论的是人工智能研究的最终目标。另一个术语是强人工智能，这是由约翰·塞尔创造的概念，指的是人类级别的人工智能，也是有意识的。如果我们要构建强大的人工智能，我们需要彻底反思社会。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="63ab" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">元发明</h1><blockquote class="nd"><p id="9e8c" class="ne nf it bd ng nh ni nj nk nl nm md dk translated">“任何可以产生比人类更聪明的智能的东西——以人工智能、脑机接口或基于神经科学的人类智能增强的形式——都毫无疑问地成为最能改变世界的东西。其他的甚至都不在一个联盟里。”</p><p id="d64e" class="ne nf it bd ng nh ni nj nk nl nm md dk translated">—埃利泽·尤德科夫斯基</p></blockquote><p id="1e46" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">自从我们进化成文化生物，我们就一直在发明东西。早在历史开始之前，技术就已经帮助推动我们的文明向前发展。写作、农业、城市、印刷、电力、互联网、社交媒体……都以这样或那样的方式极大地改变了世界。</p><p id="7745" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但是尤德科夫斯基所说的比人类聪明的智能是一种不同类型的发明；这是一个元发明。农业或印刷是有特定用途的技术，被设计来执行预先定义的任务。通过构建一个通用人工智能，我们已经让<em class="ns">发明了一个</em> <em class="ns">发明家——</em>，而不是任何一个发明家；它几乎在所有方面都比我们强。</p><p id="7a28" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">打个比方，让我们想到电脑。它被设计成一台通用机器，一台可以被编程来执行许多不同设备的任务的机器。在某种意义上，计算机是一种元设备。另一个更近的类比可以用流行的语言模型GPT-3来说明，它具有元学习能力。它学会了学习，而不是学会了执行一项特定的任务。AGI将是我们所能想到的最广泛意义上的元。这提出了一个有趣而又可怕的问题:如果我们设法发明了所有这些东西，那么一个超级强大的发明家能发明什么呢？</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="32a8" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">人工智能的危险</h1><blockquote class="nd"><p id="5f15" class="ne nf it bd ng nh ni nj nk nl nm md dk translated">“全人工智能的发展可能意味着人类的终结。[……]它会自己起飞，以越来越快的速度重新设计自己。受到缓慢生物进化限制的人类无法竞争，并将被取代。”</p><p id="db23" class="ne nf it bd ng nh ni nj nk nl nm md dk translated">——斯蒂芬·霍金</p></blockquote><p id="ce3a" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">著名物理学家斯蒂芬·霍金警告我们真正人工智能的危险。他认为一个足够聪明的人工智能将能够摆脱我们的控制。即使我们成功地设计了符合我们价值观的人工智能，最轻微的偏差也可能导致更下游的灾难性后果。有一种观点认为，如果我们可以设计一个全能的人工智能，让它变得仁慈的唯一要求是让它渴望对我们有益的东西，拒绝那些对我们有害的东西。然而，在实践中，我们会发现实现这一目标有许多困难。</p><p id="5bc0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最乐观的人认为，如果我们完整地构建人工智能，它不可能在我们精心设定的界限之外表现。但霍金谈到了重新设计，我们不必看得太远就能意识到这一论点值得考虑:人类在几千年的进化之风、随机突变和自然选择中精心打造，直到最近才找到改变我们基础的工具。如果我们设法改变我们的DNA，我们就成功地克服了进化的限制，进化是我们的主要“设计师”是什么让我们认为像我们一样聪明的机器最终不能做同样的事情？</p><p id="7627" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">此外，因为机器已经在各个方面超越了我们——记忆、精度和计算能力等——它们也将通过改变自身在其他任何方面迅速超越我们。我们可能会失去在这种情况下可能出现的任何冲突；我们会被“取代”</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="d693" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">我们最后的发明</h1><blockquote class="nd"><p id="9346" class="ne nf it bd ng nh ni nj nk nl nm md dk translated">"机器智能是人类需要创造的最后一项发明."</p><p id="d6f6" class="ne nf it bd ng nh ni nj nk nl nm md dk translated">—尼克·博斯特罗姆</p></blockquote><p id="0181" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">尼克·博斯特罗姆是牛津大学的一名哲学家，著有《超级智能:路径、危险、策略、T3》一书，他在书中认为超级智能——这个术语指的是那些远远超过AGI水平、远在我们之上的人工智能，相比之下，我们再也不能称自己为智能——将会出现，我们应该以各种可能的方式为这一事件做准备。</p><p id="6560" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">博斯特罗姆认为，一旦我们到达AGI，ASI(人工超级智能)终将到来。这种智能将能够做我们所做的一切，甚至更多——多到我们就像试图理清人类文明运作的蚂蚁一样——因此它将能够创造所有其他可以创造的东西(与Yudkowsky的观点一致)。</p><p id="629d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于博斯特罗姆来说，这种未来可能以两种相反的形式出现:要么ASI是仁慈的，对人类有益的，因为我们已经成功地将它与我们完美地结合在一起，要么它不是，也不仅仅是“人类需要做出的最后一项发明”，而是我们将做出的最后一项发明。句号。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="3e7f" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">奇点</h1><blockquote class="nd"><p id="bee6" class="ne nf it bd ng nh ni nj nk nl nm md dk translated">“在几十年内，机器智能将超过人类智能，导致奇点——技术变革如此迅速和深刻，以至于代表着人类历史结构的断裂。”</p><p id="59c2" class="ne nf it bd ng nh ni nj nk nl nm md dk translated">—雷·库兹韦尔</p></blockquote><p id="f759" class="pw-post-body-paragraph li lj it lk b ll nn kd ln lo no kg lq lr np lt lu lv nq lx ly lz nr mb mc md im bi translated">世界领先的未来学家之一雷·库兹韦尔(Ray Kurzweil)提出了他所谓的“<a class="ae lh" href="https://en.wikipedia.org/wiki/Accelerating_change#Kurzweil's_The_Law_of_Accelerating_Returns" rel="noopener ugc nofollow" target="_blank">加速回报定律</a>”，根据该定律，进化系统——包括技术——以指数速度变化。他认为，按照这个想法，我们可以断定<a class="ae lh" href="https://www.amazon.com/Singularity-Near-Humans-Transcend-Biology/dp/0143037889" rel="noopener ugc nofollow" target="_blank">奇点就在</a>附近。他声称，在21世纪末之前，我们将达到这一事件，创造“人类历史结构的断裂。”</p><p id="6f85" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">人类将与机器完全融合，我们将被永恒地投射成基于软件的生物，人工智能将比人类的总和更加强大，向外扩展其征服宇宙的范围。库兹韦尔认为这将在不到25年的时间内开始发生:“我将这个奇点的日期定为2045年，这代表着人类能力的一次深刻而具有破坏性的转变。”</p><p id="061a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，对他的想法有很多批评。物理学家保罗·戴维斯<a class="ae lh" href="http://www.singularity.com/When_computers_take_over.pdf" rel="noopener ugc nofollow" target="_blank">说</a>即使在某些情况下增长是指数级的，但由于缺乏资源，这种增长不会持久。物理学家西奥多·莫迪斯(Theodore Modis)<a class="ae lh" href="https://web.archive.org/web/20121030072409/http://www.growth-dynamics.com/articles/Kurzweil.htm" rel="noopener ugc nofollow" target="_blank">认为</a>“自然界中没有什么遵循纯指数规律”，相反，增长是典型的逻辑。一开始，这两个功能看起来是一样的，但是逻辑变平了，这就是现实中最终发生的情况。无论是哪种情况，我们都将活着看到库兹韦尔的预测是否会落空。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="2b08" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://mindsoftomorrow.ck.page/" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> <em class="ns">跟我一起旅行到未来</em> </strong> </a> <strong class="lk jd"> <em class="ns">了解更多关于人工智能、哲学和认知科学的内容！如有任何疑问，欢迎在评论中提问或联系</em></strong><a class="ae lh" href="https://www.linkedin.com/in/alberromgar/" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd"><em class="ns">LinkedIn</em></strong></a><strong class="lk jd"><em class="ns">或</em></strong><a class="ae lh" href="https://twitter.com/Alber_RomGar" rel="noopener ugc nofollow" target="_blank"><em class="ns">Twitter</em></a><strong class="lk jd"><em class="ns">！:)</em> </strong></p></div></div>    
</body>
</html>