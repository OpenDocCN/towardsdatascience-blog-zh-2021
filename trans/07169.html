<html>
<head>
<title>Training T5 for paraphrase generation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ç”¨äºé‡Šä¹‰ç”Ÿæˆçš„è®­ç»ƒT5</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://towardsdatascience.com/training-t5-for-paraphrase-generation-ab3b5be151a2?source=collection_archive---------14-----------------------#2021-06-29">https://towardsdatascience.com/training-t5-for-paraphrase-generation-ab3b5be151a2?source=collection_archive---------14-----------------------#2021-06-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/b289703c2b012e40633a40c401b1c172.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/0*SwOEuUjkNgp0ZOH5.jpg"/></div><p class="ju jv gj gh gi jw jx bd b be z dk translated">ä½¿ç”¨<a class="ae jy" href="https://imgflip.com/memegenerator" rel="noopener ugc nofollow" target="_blank"> Imgflip </a>ç”Ÿæˆçš„å›¾åƒ</p></figure><p id="7788" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">åœ¨æˆ‘ä¹‹å‰çš„åšå®¢<a class="ae jy" rel="noopener" target="_blank" href="/textgenie-augmenting-your-text-dataset-with-just-2-lines-of-code-23ce883a0715">ä¸­</a>è°ˆåˆ°äº†<a class="ae jy" href="https://github.com/hetpandya/textgenie" rel="noopener ugc nofollow" target="_blank"> TextGenie </a>ï¼Œæˆ‘æåˆ°äº†æˆ‘åœ¨ä»é›¶å¼€å§‹æ”¶é›†æ–‡æœ¬æ•°æ®å’Œä½¿ç”¨T5(æ–‡æœ¬åˆ°æ–‡æœ¬è½¬æ¢è½¬æ¢å™¨)ç”Ÿæˆçš„é‡Šä¹‰ä½œä¸ºæ‰©å……æ–‡æœ¬æ•°æ®çš„æ–¹æ³•ä¹‹ä¸€æ—¶æ‰€é¢ä¸´çš„é—®é¢˜ã€‚çœ‹è¿‡æ¨¡å‹çš„è¿è¡Œåï¼Œè®©æˆ‘ä»¬æ¥ä½“éªŒä¸€ä¸‹åŸ¹è®­è¿‡ç¨‹ğŸ˜‰</p><p id="fccf" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">å¦‚æœæ‚¨å¸Œæœ›å…¨ç¨‹è·Ÿéšæˆ‘ï¼Œæ‚¨å¯ä»¥åœ¨æˆ‘çš„Github repoä¸Šçš„<a class="ae jy" href="https://github.com/hetpandya/paraphrase-datasets-pretrained-models/blob/main/examples/t5_paraphrase_model_training_example.ipynb" rel="noopener ugc nofollow" target="_blank">è¿™é‡Œ</a>æ‰¾åˆ°åŸ¹è®­ç¬”è®°æœ¬ã€‚</p><p id="521b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">æç¤º:</strong>å¦‚æœä½ æ²¡æœ‰GPUï¼Œæˆ‘å»ºè®®ä½¿ç”¨<a class="ae jy" href="https://colab.research.google.com" rel="noopener ugc nofollow" target="_blank"> Google Colaboratory </a>æ¥è®­ç»ƒæ¨¡å‹ã€‚</p><h1 id="3bd6" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">å®‰è£…ä¾èµ–é¡¹</h1><p id="3d17" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">åœ¨ç»§ç»­ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å‡†å¤‡å¥½æ‰€æœ‰éœ€è¦çš„åŒ…ï¼Œä½¿ç”¨:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="5071" class="mj ky iq mf b gy mk ml l mm mn">pip install simpletransformers datasets tqdm pandas</span></pre><h1 id="76d1" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">èµ„æ–™ç»„</h1><p id="2bea" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">æˆ‘ä»¬å°†ä½¿ç”¨<a class="ae jy" href="https://huggingface.co/datasets/tapaco" rel="noopener ugc nofollow" target="_blank"> TaPaCo </a>æ•°æ®é›†æ¥å®Œæˆæˆ‘ä»¬çš„ä»»åŠ¡ã€‚è¯¥æ•°æ®é›†ç”±73ç§è¯­è¨€çš„æ€»å…±190ä¸‡ä¸ªå¥å­ç»„æˆï¼Œæˆ‘ä»¬å°†ä»ä¸­æå–<code class="fe mo mp mq mf b">English</code>è¯­è¨€çš„å¥å­ã€‚</p><h2 id="cc39" class="mj ky iq bd kz mr ms dn ld mt mu dp lh kk mv mw ll ko mx my lp ks mz na lt nb bi translated">é¢„å¤„ç†æ•°æ®é›†(å¯é€‰)</h2><p id="ad4f" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">åœ¨å°†æ•°æ®é›†è¾“å…¥æ¨¡å‹ä¹‹å‰ï¼Œéœ€è¦å°†å…¶è½¬æ¢æˆæˆå¯¹çš„è¾“å…¥å¥å­å’Œç›®æ ‡å¥å­ã€‚é¢„å¤„ç†çš„ä»£ç å¯ä»¥åœ¨<a class="ae jy" href="https://github.com/hetpandya/paraphrase-datasets-pretrained-models/tree/main/datasets/tapaco#storing-original-dataset-as-csv" rel="noopener ugc nofollow" target="_blank">è¿™é‡Œ</a>ä»¥åŠç¬”è®°æœ¬ä¸­æ‰¾åˆ°ã€‚</p><h2 id="67ba" class="mj ky iq bd kz mr ms dn ld mt mu dp lh kk mv mw ll ko mx my lp ks mz na lt nb bi translated">ä¸‹è½½å·²ç»é¢„å¤„ç†çš„æ•°æ®é›†</h2><p id="4756" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">å¦‚æœæ‚¨ä¸æƒ³å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œæˆ‘å·²ç»ä¸ºæ‚¨å®Œæˆäº†ä»»åŠ¡ã€‚ä½ å¯ä»¥ç›´æ¥ä»<a class="ae jy" href="https://github.com/hetpandya/paraphrase-datasets-pretrained-models/raw/main/datasets/tapaco/tapaco_paraphrases_dataset.csv" rel="noopener ugc nofollow" target="_blank">è¿™é‡Œ</a>ä¸‹è½½æ•°æ®é›†çš„é¢„å¤„ç†ç‰ˆæœ¬ã€‚</p><h2 id="aaaa" class="mj ky iq bd kz mr ms dn ld mt mu dp lh kk mv mw ll ko mx my lp ks mz na lt nb bi translated">åŠ è½½æ•°æ®é›†</h2><p id="88a0" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">å®Œæˆåï¼Œæ‚¨å¯ä»¥æŒ‰ä»¥ä¸‹æ–¹å¼åŠ è½½æ•°æ®é›†:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="1c1f" class="mj ky iq mf b gy mk ml l mm mn">import pandas as pd</span><span id="67e1" class="mj ky iq mf b gy nc ml l mm mn">dataset_df = pd.read_csv("tapaco_paraphrases_dataset.csv",sep="\t")</span></pre><p id="44d3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">åŠ è½½åï¼Œéœ€è¦é‡å‘½åæ•°æ®çš„åˆ—ã€‚å¦å¤–ï¼Œæˆ‘ä»¬éœ€è¦ç»™æ¯ä¸ªå¥å­åŠ ä¸€ä¸ªå‰ç¼€ã€‚è¿™é‡Œï¼Œå‰ç¼€å¯ä»¥æ˜¯ä½œä¸ºåˆ—æ·»åŠ çš„ä»»ä½•æ–‡æœ¬ï¼Œæ¯è¡Œå…·æœ‰ç›¸åŒçš„å€¼ã€‚</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="dfb1" class="mj ky iq mf b gy mk ml l mm mn"># Renaming the columns<br/>dataset_df.columns = ["input_text","target_text"]</span><span id="094a" class="mj ky iq mf b gy nc ml l mm mn"># Adding a prefix. Here we shall keep "paraphrase" as a prefix.<br/>dataset_df["prefix"] = "paraphrase"</span></pre><h2 id="52d0" class="mj ky iq bd kz mr ms dn ld mt mu dp lh kk mv mw ll ko mx my lp ks mz na lt nb bi translated">åˆ†å‰²æ•°æ®é›†</h2><p id="daa3" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">æˆ‘ä»¬å°†ä»¥90%-10%çš„æ¯”ä¾‹åˆ†å‰²æ•°æ®é›†</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="1f81" class="mj ky iq mf b gy mk ml l mm mn">from sklearn.model_selection import train_test_split</span><span id="d097" class="mj ky iq mf b gy nc ml l mm mn">train_data,test_data = train_test_split(dataset_df,test_size=0.1)</span></pre><h1 id="a4d1" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">è®­ç»ƒæ¨¡å‹</h1><p id="240e" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">è¯¥æ¨¡å‹éœ€è¦è°ƒæ•´æŸäº›å‚æ•°ï¼Œå¦‚ä¸‹æ‰€ç¤º:</p><figure class="ma mb mc md gt jr"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="2462" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">ä»<code class="fe mo mp mq mf b">simpletransformers</code>åˆå§‹åŒ–<code class="fe mo mp mq mf b">T5Model</code>ç±»å¯¹è±¡:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="a179" class="mj ky iq mf b gy mk ml l mm mn">from simpletransformers.t5 import T5Model<br/>import sklearn</span><span id="c0a4" class="mj ky iq mf b gy nc ml l mm mn">model = T5Model("t5","t5-small", args=args)</span></pre><p id="88f0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">æˆ‘ä»¬ç°åœ¨å°†é‡‡ç”¨<code class="fe mo mp mq mf b">t5-small</code>æ¨¡å¼ã€‚è®©æˆ‘ä»¬ç»§ç»­åŸ¹è®­:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="dea2" class="mj ky iq mf b gy mk ml l mm mn">model.train_model(train_data, eval_data=test_data, use_cuda=True,acc=sklearn.metrics.accuracy_score)</span></pre><h1 id="0836" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡ŒåŠ è½½å’Œé¢„æµ‹</h1><p id="2a3c" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">æ¨¡å‹è®­ç»ƒå¯èƒ½éœ€è¦å‡ ä¸ªå°æ—¶ã€‚ä¸€æ—¦åŸ¹è®­å®Œæˆï¼Œæ‚¨å¯èƒ½ä¼šåœ¨<code class="fe mo mp mq mf b">outputs</code>ç›®å½•ä¸­æ‰¾åˆ°æœ€ç»ˆçš„æ¨¡å‹ã€‚å®ƒå¯ä»¥åŠ è½½ä¸º:</p><h2 id="cd0c" class="mj ky iq bd kz mr ms dn ld mt mu dp lh kk mv mw ll ko mx my lp ks mz na lt nb bi translated">åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹</h2><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="4021" class="mj ky iq mf b gy mk ml l mm mn">from simpletransformers.t5 import T5Model<br/>import os</span><span id="599b" class="mj ky iq mf b gy nc ml l mm mn">root_dir = os.getcwd()<br/>trained_model_path = os.path.join(root_dir,"outputs")</span><span id="38da" class="mj ky iq mf b gy nc ml l mm mn">args = {<br/>"overwrite_output_dir": True,<br/>"max_seq_length": 256,<br/>"max_length": 50,<br/>"top_k": 50,<br/>"top_p": 0.95,<br/>"num_return_sequences": 5<br/>}</span><span id="bb08" class="mj ky iq mf b gy nc ml l mm mn">trained_model = T5Model("t5",trained_model_path,args=args)</span></pre><h2 id="ca59" class="mj ky iq bd kz mr ms dn ld mt mu dp lh kk mv mw ll ko mx my lp ks mz na lt nb bi translated">ä½¿ç”¨æ‰€è®­ç»ƒçš„æ¨¡å‹ç”Ÿæˆé‡Šä¹‰</h2><p id="13d9" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">è®©æˆ‘ä»¬çœ‹çœ‹æ¨¡å‹åœ¨æˆ‘ä»¬çš„è‡ªå®šä¹‰è¾“å…¥ä¸‹è¡¨ç°å¦‚ä½•:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="ef45" class="mj ky iq mf b gy mk ml l mm mn">prefix = "paraphrase"<br/>pred = trained_model.predict([f"{prefix}: The house will be cleaned by me every Saturday."])</span><span id="fa6f" class="mj ky iq mf b gy nc ml l mm mn">print(pred)</span><span id="7077" class="mj ky iq mf b gy nc ml l mm mn">#Output:</span><span id="d4fe" class="mj ky iq mf b gy nc ml l mm mn">[['My home will be cleaned on Saturdays.',   <br/>'I will clean the house every Saturday.',   <br/>'The house is going to be clean every Saturday.',   <br/>"I'll clean the house every Saturday.",   <br/>'I will clean the house every Saturday.']]</span></pre><p id="2257" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">è€Œä¸”å¾ˆç®¡ç”¨ï¼ï¼è€¶ï¼</p><p id="bfd1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">T5è½¦å‹åŸ¹è®­åˆ°æ­¤ä¸ºæ­¢ã€‚æˆ‘å·²ç»å¼€æºäº†é¢„è®­ç»ƒæ¨¡å‹å’Œé¢„å¤„ç†æ•°æ®é›†ï¼Œä»¥ä¾¿åœ¨æˆ‘çš„<a class="ae jy" href="https://github.com/hetpandya/paraphrase-datasets-pretrained-models" rel="noopener ugc nofollow" target="_blank"> Github repo </a>ä¸Šè§£é‡Šï¼Œå¦‚æœä½ æƒ³æ¢ç´¢å®ƒä»¬çš„è¯ã€‚</p><p id="d882" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">æ„Ÿè°¢æ‚¨çš„é˜…è¯»ğŸ˜„</p></div></div>    
</body>
</html>