<html>
<head>
<title>LSTM Neural Network: The Basic Concept</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">LSTM神经网络:基本概念</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lstm-neural-network-the-basic-concept-a9ba225616f7?source=collection_archive---------18-----------------------#2021-04-26">https://towardsdatascience.com/lstm-neural-network-the-basic-concept-a9ba225616f7?source=collection_archive---------18-----------------------#2021-04-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="18dd" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">长短期记忆神经网络的高级介绍</h2></div></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/98e835adac456ab74c518b877dbb07b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YECeOxlko9KoOJNw8RNm3A.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">艾莉娜·格鲁布尼亚克在<a class="ae lf" href="https://unsplash.com/s/photos/neural-network?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="d6ff" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">预测未来曾经是猜测和神秘的事情。由于人类的进步，这已经成为一项仅受数据数量和深度限制的任务。</p><p id="8ce1" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">随着我们生活在一个不断以指数速度产生数据的社会，这种预见任务变得越来越容易实现。</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><p id="e49a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">你对数据驱动的预测研究得越深入，LSTM这个词肯定会让人一头雾水。和许多科技概念一样，它是一个首字母缩写词，代表长期短期记忆。</p><p id="106d" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">简单地说，它是一个神经网络——一个旨在模仿人类学习模式的机器学习系统——能够“记住”以前的数据和结论，并使用它来更准确地得出最终结论。</p><blockquote class="mc md me"><p id="4d3b" class="lg lh mf li b lj lk ju ll lm ln jx lo mg lq lr ls mh lu lv lw mi ly lz ma mb im bi translated"><em class="it">“……LSTM为任何顺序处理任务带来了希望，我们怀疑其中可能存在层次分解，但事先不知道这种分解是什么。”</em><br/>——费利克斯·a·热尔斯等译，《学会遗忘:与LSTM的连续预测》，2000年</p></blockquote><p id="a575" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">LSTM是深度学习中的一种递归神经网络，专门开发用于处理顺序预测问题。例如:</p><ul class=""><li id="19a8" class="mj mk it li b lj lk lm ln lp ml lt mm lx mn mb mo mp mq mr bi translated">天气预报</li><li id="7569" class="mj mk it li b lj ms lm mt lp mu lt mv lx mw mb mo mp mq mr bi translated">股票市场预测</li><li id="ecc2" class="mj mk it li b lj ms lm mt lp mu lt mv lx mw mb mo mp mq mr bi translated">产品推荐</li><li id="fa6e" class="mj mk it li b lj ms lm mt lp mu lt mv lx mw mb mo mp mq mr bi translated">文本/图像/手写生成</li><li id="893e" class="mj mk it li b lj ms lm mt lp mu lt mv lx mw mb mo mp mq mr bi translated">文本翻译</li></ul><p id="8018" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mf">需要对整个神经网络进行复习吗？</em></p><div class="mx my gp gr mz na"><a href="https://hackernoon.com/everything-you-need-to-know-about-neural-networks-8988c3ee4491" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd iu gy z fp nf fr fs ng fu fw is bi translated">关于神经网络你需要知道的一切</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">感谢:Kailash ahir war(Mate Labs联合创始人兼首席技术官)</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">hackernoon.com</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no kz na"/></div></div></a></div><p id="ab7d" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mf">“由于LSTMs可以有效地捕捉长期的时间依赖性，而不会遭受困扰简单递归网络(srn)的优化障碍，因此它们已被用于推进许多困难问题的技术发展水平。这包括手写识别和生成、语言建模和翻译、语音声学建模、语音合成、蛋白质二级结构预测、音频和视频数据分析等。”</em> <br/> — Klaus Greff等，LSTM:太空探索之旅，2015年</p><p id="3363" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">像其他神经网络一样，它们包含执行计算的神经元，然而对于LSTM来说，它们通常被称为记忆细胞或简称为<strong class="li iu">细胞</strong>。这些单元格包含权重和门；门是LSTM模型的显著特征。每个牢房里有3道门。输入门、遗忘门和输出门。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi np"><img src="../Images/f42ab99705c7789f51e5ac0fead9abbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LpcFY50k1SO-tx8yVO6y7Q.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来源:<a class="ae lf" href="http://aleia-knight.medium.com" rel="noopener">阿莱亚·奈特</a></p></figure></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="df45" class="nq nr it bd ns nt nu nv nw nx ny nz oa jz ob ka oc kc od kd oe kf of kg og oh bi translated">—重要的变量—</h1><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oi"><img src="../Images/77e9363af60c607a42dbfbd104a956c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gNp0agLOHfGh4s4vfwW3mw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来源:<a class="ae lf" href="http://aleia-knight.medium.com" rel="noopener">阿莱亚骑士</a></p></figure></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="2db2" class="nq nr it bd ns nt nu nv nw nx ny nz oa jz ob ka oc kc od kd oe kf of kg og oh bi translated">—LSTM·盖茨—</h1><h2 id="9334" class="oj nr it bd ns ok ol dn nw om on dp oa lp oo op oc lt oq or oe lx os ot og ou bi translated">细胞状态</h2><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi np"><img src="../Images/24292282e95b701a953788297fb7d276.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*70h1Y6hWXIXD5ht02nH1vg.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来源:<a class="ae lf" href="http://aleia-knight.medium.com" rel="noopener">阿莱亚骑士</a></p></figure><p id="0a55" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">单元状态有点像传送带，在单元中移动数据。虽然它在技术上不是一个门，但它对于通过每个细胞以及向其他细胞传送数据至关重要。流经它的数据根据来自遗忘门和输入门的结果被改变和更新，并被传递到下一个单元。</p><h2 id="208b" class="oj nr it bd ns ok ol dn nw om on dp oa lp oo op oc lt oq or oe lx os ot og ou bi translated">遗忘之门</h2><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi np"><img src="../Images/513a459af9d56054667a959c284d4141.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E8RqxFJOvhx1vY6XAXdhyQ.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来源:<a class="ae lf" href="http://aleia-knight.medium.com" rel="noopener">阿莱亚骑士</a></p></figure><p id="49ee" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">该门在与单元状态合并之前移除不需要的信息。就像人类选择不考虑某些与决策无关或不必要的事件或信息一样。</p><p id="dc7a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">它接受两个输入，新信息(x_t)和先前单元输出(h_t-1)。它通过sigmoid门运行这些输入，以过滤掉不需要的数据，然后通过乘法将其与细胞状态合并。</p><h2 id="c47f" class="oj nr it bd ns ok ol dn nw om on dp oa lp oo op oc lt oq or oe lx os ot og ou bi translated">输入门</h2><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi np"><img src="../Images/2d4ca4891c3c68a34112b98fce2d0397.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JEPPGfRYfTHwamoLjvhZlg.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来源:<a class="ae lf" href="http://aleia-knight.medium.com" rel="noopener">阿莱亚骑士</a></p></figure><p id="f0d6" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这个门向单元状态添加信息。相当于人类在你已有信息的基础上考虑新呈现的信息。</p><p id="7fd9" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">与遗忘门类似，它使用一个sigmoid门来确定需要保留的信息量。它使用tanh函数来创建要添加的信息的向量。然后，它将sigmoid gate和tanh函数的结果相乘，并使用加法将有用信息添加到单元状态中。</p><p id="a044" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">此时，所有的信息都已经设置好了:开始信息、新信息和删除不需要的信息。这些都已经收集整理好了，决定已经准备好了。</p><h2 id="5c02" class="oj nr it bd ns ok ol dn nw om on dp oa lp oo op oc lt oq or oe lx os ot og ou bi translated">输出门</h2><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi np"><img src="../Images/ed54edf5c30a9ea85abfb63d10f3c6eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-UIoQtiKiqxGPkTSyXlTpA.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">图片来源:<a class="ae lf" href="http://aleia-knight.medium.com" rel="noopener">阿莱亚骑士</a></p></figure><p id="43b6" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最后一个门根据单元状态、先前单元输出和新数据选择有用的信息。在输入门和遗忘门合并后，它通过获取单元状态来实现这一点，并通过一个双曲正切函数来创建一个向量。然后，它获取新数据和以前的单元输出，并通过sigmoid函数运行它们，以找到需要输出的值。然后，这两个操作的结果相乘，并作为该单元的输出返回。</p><p id="6e60" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mf">关于激活功能(tanh和sigmoid)的更多信息:</em></p><div class="mx my gp gr mz na"><a href="https://deepai.org/machine-learning-glossary-and-terms/activation-function" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd iu gy z fp nf fr fs ng fu fw is bi translated">激活功能</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">激活函数是在人工神经网络中使用的函数，它为小输入输出小值…</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">deepai.org</p></div></div><div class="nj l"><div class="ov l nl nm nn nj no kz na"/></div></div></a></div><p id="cdd8" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">数据在细胞间移动的整个过程发生在一个细胞中。但是在实际模型中，在得出最终结论之前，无论添加多少层，每层都可以有任意数量的单元。</p><p id="6187" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">然后，无论需要多少个时期(迭代),整个模型都会再次运行，以接近更准确的答案。准确度越好；预测越好。</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><p id="cdf3" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">作为人类，我们不断地以惊人的速度进行这一过程。甚至可以追溯到学习走路的时候，通过回顾我们做错了什么，看看别人做对了什么，然后从中调整。像其他神经网络一样，LSTM过程旨在模拟人类思维。</p><p id="7645" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">区别在于它的计算能力。</p><p id="e04a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">人类是高度智能的生物，因此我们才能走到这一步，但我们知道我们制造的机器比我们更聪明。尤其是在数学和科学的速度方面。</p><p id="8c69" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">LSTM模型能够回顾以前的数据和决策，并据此做出决策。但是他们也要用同样的过程对可能发生的事情做出有根据的猜测/预测。这就是为什么这个模型在连续数据的情况下是最好的。它将发现趋势，并使用这些趋势来预测未来的趋势和结果。</p><p id="6c50" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们能做到吗？是</p><p id="c13c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">但是可能没有同样的精确度。更不用说接受数百万个数据点作为输入了。</p><p id="2bfa" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">所以你看，我们可以预测未来，我们甚至不需要一个算命师这样做。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ow"><img src="../Images/6df1f5b77b20040a1a0d25be55c23fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_sydRtY-DM559T3L5cpyKg.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">迈克尔·泽兹奇在<a class="ae lf" href="https://unsplash.com/s/photos/crystal-ball?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="46a6" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">只是一台强大的计算机，一些数据，和一点数学！</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><p id="af17" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">喜欢阅读吗？Co <em class="mf">请告诉我你对这个话题的想法，并关注以获得更多关于机器学习、数据科学、STEM和职业/个人发展的文章。</em></p></div></div>    
</body>
</html>