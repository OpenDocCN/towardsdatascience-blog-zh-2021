<html>
<head>
<title>An Automatic Hyperparameter Optimization on a Twitter Sentiment Analysis Problem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Twitter情感分析问题的自动超参数优化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-automatic-hyperparameter-optimization-on-a-twitter-sentiment-analysis-problem-6d5dc732f500?source=collection_archive---------19-----------------------#2021-08-24">https://towardsdatascience.com/an-automatic-hyperparameter-optimization-on-a-twitter-sentiment-analysis-problem-6d5dc732f500?source=collection_archive---------19-----------------------#2021-08-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c60b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">这是一个漂亮的超参数调整技术的解释，使您的生活更容易。请放心在你的下一个ML项目中使用它！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a62bc11a82cd4cabddab926c4756d6d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g4KW_YEdYgZdUwZHP_fOaA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@denisseleon?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">丹尼斯·莱昂</a>在<a class="ae ky" href="https://unsplash.com/s/photos/tune?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="95d4" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi mc translated"><span class="l md me mf bm mg mh mi mj mk di"> H </span>超参数调优是机器学习生命周期中最重要的部分之一。这在计算上是昂贵的，并且也是耗时的过程。</p><p id="974b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在读硕士期间，我偶然发现了一个自动超参数优化框架<a class="ae ky" href="https://optuna.org/" rel="noopener ugc nofollow" target="_blank"> Optuna </a>。一个有趣的方面是，我们可以将Optuna与标准的机器学习算法以及神经网络方法一起使用。</p><p id="9eb5" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在本文中，我将通过展示一些例子来记录我发现的关于Optuna的所有有用的东西。最重要的是，我将解决您在测试这个Optuna库时将会遇到的常见问题。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="62cc" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="ml">继续阅读这篇文章，你会发现:</em></p><ol class=""><li id="a16d" class="mm mn it li b lj lk lm ln lp mo lt mp lx mq mb mr ms mt mu bi translated"><em class="ml">如何使用XGBoost和LSTM对情感分析问题建模。</em></li><li id="072f" class="mm mn it li b lj mv lm mw lp mx lt my lx mz mb mr ms mt mu bi translated"><em class="ml">如何将Optuna集成到XGBoost和LSTM模型中，并执行超参数调整。</em></li><li id="01b0" class="mm mn it li b lj mv lm mw lp mx lt my lx mz mb mr ms mt mu bi translated"><em class="ml">在使用Optuna时，我们如何减少一些常见的陷阱。</em></li></ol></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="527d" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">感兴趣？开始阅读！</strong></p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="97ed" class="na nb it bd nc nd ne nf ng nh ni nj nk jz nl ka nm kc nn kd no kf np kg nq nr bi translated">问题是</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/81a67a8e9c7558470e21ec1b6d7b57c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JuEDXzwRGekZEUdzDsJQ2Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">杰瑞米·泽罗在<a class="ae ky" href="https://unsplash.com/s/photos/twitter?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="521c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们可以为此挑选任何问题，但我希望它更有趣一些，所以我选择了<strong class="li iu"><em class="ml">Twitter数据的情感分析</em> </strong>。</p><p id="f669" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">情感分析属于自然语言处理领域，我们使用多种文本处理方法来理解文本数据并从中获得洞察力。这种方法最常见的用途是识别推文的极性或情绪。</p><p id="c959" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">简而言之，我们的目标是将一条推文/短语或一句话归类为一组情绪，如<em class="ml">积极</em>、<em class="ml">消极</em>或<em class="ml">中性</em>。这是一个更广泛的分类，但我们可以更进一步，对推文情绪进行更详细的分类，如<em class="ml">非常快乐</em>、<em class="ml">适度快乐</em>，以及类似版本的<em class="ml">悲伤</em>、<em class="ml">愤怒</em>、<em class="ml">厌恶</em>等。</p><p id="8747" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我使用的数据集来自一场<a class="ae ky" href="https://www.kaggle.com/c/tweet-sentiment-extraction/data" rel="noopener ugc nofollow" target="_blank">卡格尔比赛</a>。</p><blockquote class="nt nu nv"><p id="d911" class="lg lh ml li b lj lk ju ll lm ln jx lo nw lq lr ls nx lu lv lw ny ly lz ma mb im bi translated"><a class="ae ky" href="https://www.kaggle.com/c/tweet-sentiment-extraction/data" rel="noopener ugc nofollow" target="_blank">数据</a>:知识共享署名下的4.0国际许可</p><p id="21fd" class="lg lh ml li b lj lk ju ll lm ln jx lo nw lq lr ls nx lu lv lw ny ly lz ma mb im bi translated">虽然，比赛谈论的是推文提取，但我将数据重新用于情感分析。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/5d0bf23c8627fbcdcaac18964b5f791a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nd-0q5tkFDBNJhc1IKq6zg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自数据集的样本推文(来源:作者)</p></figure><p id="b607" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">对于实验，我将使用<code class="fe oa ob oc od b">text</code>和<code class="fe oa ob oc od b">sentiment</code>功能，在这里我将建立一个机器学习模型，它将一条推文作为输入，并告诉我们它的情感/情绪。由于我们有3种情绪类型(积极、消极和中性)，这是一个<strong class="li iu"> <em class="ml">多类分类任务</em> </strong>的情况。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="e9f8" class="na nb it bd nc nd ne nf ng nh ni nj nk jz nl ka nm kc nn kd no kf np kg nq nr bi translated">数据预处理</h1><p id="5c5f" class="pw-post-body-paragraph lg lh it li b lj oe ju ll lm of jx lo lp og lr ls lt oh lv lw lx oi lz ma mb im bi translated">并非推文的每一部分对我们进行的文本处理都很重要。推文的某些方面，如数字、符号、停用词，对于情感分析来说并不那么有用。</p><p id="c229" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">所以我们只需在预处理步骤中移除它们。我使用了<code class="fe oa ob oc od b">nltk</code> python库和<code class="fe oa ob oc od b">regular expressions</code>来删除停用词、电子邮件、URL、数字、空格、标点符号、特殊字符和Unicode数据。</p><p id="5092" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">代码如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="68b7" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">正如我之前提到的，我们将使用两种不同的方法进行情感分析，即XGBoost分类器和LSTM神经网络架构。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="cb49" class="na nb it bd nc nd ne nf ng nh ni nj nk jz nl ka nm kc nn kd no kf np kg nq nr bi translated">XGBoost分类器</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/124cb345f0532c8260da6d99b95fcd9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n6aa_ZbeL5c4O5vvKKJMVg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@haithemfrd_off?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Haithem Ferdi </a>在<a class="ae ky" href="https://unsplash.com/s/photos/boost?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="deba" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">“清理”完文本数据后，下一步就是矢量化。在这里，我们只是将文本转换成数字格式，以便机器学习模型可以“理解”它。</p><blockquote class="nt nu nv"><p id="8ba7" class="lg lh ml li b lj lk ju ll lm ln jx lo nw lq lr ls nx lu lv lw ny ly lz ma mb im bi translated">您可以观察到，在构建ML模型之前，需要将文本、图像、图表等数据结构转换成数字表示。</p></blockquote><p id="add7" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">矢量化</strong></p><p id="4fea" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">为了对文本进行矢量化，我们可以简单地使用Sci-Kit Learn的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank">计数矢量化工具</a>方法。基本上，我们将文本转换成唯一单词的稀疏矩阵，其中我们使用数字来表示文本示例中某个单词的存在。</p><p id="5eac" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们将数据分为训练集、验证集和测试集，分割比例为-80:10:10。分割是分层的，因此我们在所有数据分割中具有相同比例的标签/情感。</p><p id="dfed" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">您可以使用以下代码来实现这一点:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oj ok l"/></div></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="5d9b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu"> Optuna集成</strong></p><p id="7799" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">现在，我们准备好训练模型并调整超参数。通过以下方式安装Optuna:</p><pre class="kj kk kl km gt om od on oo aw op bi"><span id="e07d" class="oq nb it od b gy or os l ot ou">pip install optuna</span></pre><p id="a266" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在下面的代码中，您会注意到一个被Optuna优化的目标函数。首先，我们定义我们感兴趣的超参数，并将它们添加到试验对象中。在这里，我选择调<code class="fe oa ob oc od b">learning_rate, max_depth and n_estimators</code>。根据超参数的类型，我们可以使用<code class="fe oa ob oc od b">suggest_float, suggest_int, suggest_categorical</code>等方法。</p><p id="299e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在这个目标函数中，我们创建了一个模型实例，并使其适合训练集。在训练之后，我们预测验证集上的情感，并计算准确性度量。Optuna的目标函数将通过用不同的超参数值进行试验来尝试最大化这个准确度分数。在优化过程中，可以采用不同的<a class="ae ky" href="https://optuna.readthedocs.io/en/stable/reference/samplers.html" rel="noopener ugc nofollow" target="_blank">采样技术</a>。</p><blockquote class="nt nu nv"><p id="028b" class="lg lh ml li b lj lk ju ll lm ln jx lo nw lq lr ls nx lu lv lw ny ly lz ma mb im bi translated">我们可以重写目标函数来处理模型的损失值。在这种情况下，我们将尝试最小化目标函数。</p></blockquote><p id="766e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">一种提前停止的方法以修剪的形式实现。如果看起来没有希望，试验将被跳过/取消。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="3a90" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">你可能已经注意到了<code class="fe oa ob oc od b">set_user_attr</code>方法。这是用来保存任何变量，我们可能会发现重要的。这里我们感兴趣的是保存与最高验证准确性相关的最佳模型。我们在这个用户属性中保存了最佳的XGboost模型。</p><p id="8db2" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在Optuna优化过程中，您会看到:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/70c7fab181a24982991cbebcdca1be4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Dvt_af7SyjHB5lTX-60Og.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">通过运行试验调整超参数(来源:作者)</p></figure><blockquote class="nt nu nv"><p id="fb75" class="lg lh ml li b lj lk ju ll lm ln jx lo nw lq lr ls nx lu lv lw ny ly lz ma mb im bi translated">如果您希望Optuna覆盖更大范围的超参数值，则试验次数可以更多。</p></blockquote><p id="5342" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">试验完成后，我们可以检索超参数重要性图，如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/a6946dc34ee19ab864967d9adf752abd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4WCLn201s81Un1Fy_pSZdA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">XGBoost超参数重要性(来源:作者)</p></figure><p id="60de" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们观察到<code class="fe oa ob oc od b">learning_rate</code>是比其他参数更重要的超参数。有了这个，我们就知道需要关注哪些超参数了。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="a3ad" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">在测试集上预测</strong></p><p id="d83d" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">因此，我们已经完成了模型训练和超参数调整。我们进行了20次试验来寻找最佳超参数。现在，我们可以检索我们的最佳模型，并对测试集进行预测。</p><pre class="kj kk kl km gt om od on oo aw op bi"><span id="1816" class="oq nb it od b gy or os l ot ou"># retrieve the best model from optuna study<br/>best_model = study.user_attrs['best_model']</span><span id="6c63" class="oq nb it od b gy ox os l ot ou">y_pred = best_model.predict(x_test)</span><span id="5b4c" class="oq nb it od b gy ox os l ot ou">print(accuracy_score(y_test, y_pred))</span></pre><blockquote class="oy"><p id="68ee" class="oz pa it bd pb pc pd pe pf pg ph mb dk translated">测试精度(XGBoost): 0.683</p></blockquote><p id="2415" class="pw-post-body-paragraph lg lh it li b lj pi ju ll lm pj jx lo lp pk lr ls lt pl lv lw lx pm lz ma mb im bi translated"><strong class="li iu">不算寒酸的分数！让我们看看我们是否能做得更好。</strong></p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="de80" class="na nb it bd nc nd ne nf ng nh ni nj nk jz nl ka nm kc nn kd no kf np kg nq nr bi translated">LSTM建筑</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pn"><img src="../Images/7136bb0c42fda2231a0ffbb1a99eaed7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*poXRRZdZAElrrP9C3ZQLoQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">泰勒·维克在<a class="ae ky" href="https://unsplash.com/s/photos/network?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="7035" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">长短期记忆神经网络结构在自然语言处理领域中很流行，因为它具有在其“记忆”中保留序列信息的能力。</p><p id="0a37" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">就像XGBoost一样，我们应该对文本数据进行矢量化，以便训练LSTM模型。我们执行标记化，然后将矢量化的序列填充到相同的长度。</p><p id="dab8" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">数据以类似于XGBoost模型的方式分割，这样我们就可以对两者进行比较。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="eff0" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">标记化和填充</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="6b96" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">现在，我们将<strong class="li iu"> LSTM模型</strong>定义如下:</p><p id="00c5" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我选择了<code class="fe oa ob oc od b">optimizer, epochs and batch_size</code>作为可调超参数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="48ba" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这个神经网络模型现在可以开始训练了！！</p><p id="fc92" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在训练LSTM模型时，让我们集成Optuna来执行超参数调整。</p><p id="dfea" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这个Optuna集成的代码如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="ddef" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这个Optuna集成的结构是相同的。我们只是改变了目标函数中的模型和超参数。</p><p id="55c0" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">类似地，我们获得LSTM的超参数重要性图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/59253a77209d937afaf8dde5938b6bc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UNLElWX-sDqzZClNj8P4iA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LSTM超参数重要性(来源:作者)</p></figure><p id="f602" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们看到optimizer是一个重要的超参数，批处理大小对准确性分数的提高没有太大贡献。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="5b7e" class="na nb it bd nc nd ne nf ng nh ni nj nk jz nl ka nm kc nn kd no kf np kg nq nr bi translated">我面临的问题</h1><p id="84b7" class="pw-post-body-paragraph lg lh it li b lj oe ju ll lm of jx lo lp og lr ls lt oh lv lw lx oi lz ma mb im bi translated">对于XGBoost，我们可以直接保存模型，但是当您试图以类似的方式保存Keras模型时，Optuna会给出一些错误。从我的搜索中，我发现这是因为Keras模型是不可挑选的？！</p><p id="6821" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">对此的解决方法是只保存最佳模型的权重，然后使用这些权重来重建模型。</p><p id="542a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">以下代码将对此进行更多解释:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="42f8" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">您只需创建模型的一个新实例，并设置从Optuna检索的权重，而不是再次训练它。</p><p id="387a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">用LSTM获得的测试准确度分数:</p><blockquote class="oy"><p id="fe2c" class="oz pa it bd pb pc po pp pq pr ps mb dk translated">测试精度(LSTM): 0.72</p></blockquote><p id="fadf" class="pw-post-body-paragraph lg lh it li b lj pi ju ll lm pj jx lo lp pk lr ls lt pl lv lw lx pm lz ma mb im bi translated">这个分数比XGBoost好。通常，神经网络方法比标准的机器学习方法表现得更好。通过使用BERT、RoBERTa或XLNet等变压器架构，我们可以进一步提高这一精度分数。</p><p id="9f94" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最后，我喜欢使用Optuna进行超参数调优。我可以很容易地从所有不同的试验中检索出最佳模型，并了解在训练过程中哪个超参数是重要的(使用超参数重要性图)。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="0702" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果你看到了这篇文章的这一部分，感谢你的阅读和关注。我希望你觉得这篇文章内容丰富，如果你有任何问题，请随时通过<a class="ae ky" href="https://www.linkedin.com/in/rohithteja/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>、<a class="ae ky" href="https://twitter.com/RohithTeja15" rel="noopener ugc nofollow" target="_blank"> Twitter </a>或<a class="ae ky" href="https://github.com/rohithteja" rel="noopener ugc nofollow" target="_blank"> GitHub </a>联系我。</p></div></div>    
</body>
</html>