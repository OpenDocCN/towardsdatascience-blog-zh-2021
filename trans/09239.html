<html>
<head>
<title>Getting Started with Deep Learning Using CNNs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用CNN开始深度学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-started-with-deep-learning-using-cnns-eaf220d8333d?source=collection_archive---------34-----------------------#2021-08-26">https://towardsdatascience.com/getting-started-with-deep-learning-using-cnns-eaf220d8333d?source=collection_archive---------34-----------------------#2021-08-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a94e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">实现“Hello World！”卷积神经网络</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/7bb46ce12898b1527ace6b4bec3de82f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NqH9q301WMY77DdK"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">罗马法师在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="27db" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">近年来在深度学习方面取得的很大一部分进展是由于<a class="ae kv" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a>或CNN的概念。除了图像处理中最琐碎的任务之外，这些网络已经成为事实上的标准。CNN的基本概念起源于20世纪80年代，首次应用于图像识别发表于<a class="ae kv" href="http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf" rel="noopener ugc nofollow" target="_blank"> 1989 </a>。像深度学习领域的许多主题一样，巨大的进步伴随着更多的计算能力，一个主要因素是从2000年代中期开始使用GPU而不是CPU进行训练。</p><p id="a55b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将查看该领域最重要的论文之一，即<a class="ae kv" href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf" rel="noopener ugc nofollow" target="_blank"> 1998 </a>论文“基于梯度的学习应用于文档识别”。由于种种原因，这篇论文在发表20多年后仍值得一读。值得注意的是包括Yann LeCun和Joshua Bangio在内的作者，他们与Geoffrey Hinton一起被认为是“深度学习的教父”，并因其在该领域的工作而共同获得了2018年图灵奖。</p><p id="7803" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一个问题是，这篇论文不纯粹是一项研究工作，但那里开发的解决方案已经在商业上应用于NCR公司的手写数字识别。由于该论文全面描述了专注于神经网络架构时的工作，我们只需阅读总共10节中的第1至第3节，整篇论文的长度为46页，这本身也是值得注意的，远远超过了通常的长度。</p><p id="7894" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里最相关的问题是，本文中讨论的LeNet-5网络通常被认为是CNN历史上最相关的网络之一。有时它被称为“你好，世界！”CNN的。有一些论据支持这一点:</p><ul class=""><li id="f87b" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">“LeNet-5实现”在谷歌上给了你超过130，000次点击，其中很多都是相关的。</li><li id="3796" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">使用当前的库实现基本架构只需几行代码，而不是本文中描述的大量研究工作。</li><li id="5024" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">你会很快在MNIST数据集上得到很好的结果。这还不足以获得当今的最佳论文奖，但可能比从头开始要好得多。</li><li id="e2f0" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">根据所使用的超参数，每个时期网络的训练在CPU上将花费大约100秒，而在GPU上将花费仅仅几秒。这给了你合理的时间来试验网络。</li></ul><p id="5b16" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一方面，从论文中紧密地重新实现网络将是非常困难的，因为在实现的时候，作者必须手工做所有的事情。1998年还没有GPU，Python不是人工智能的通用语言，也没有现成的深度学习库。在从头开始做每件事的同时，他们也做了许多优化，这些优化很难用最先进的库来重现。你会发现，使用谷歌的大多数实现只是让网络变得更大，从而在MNIST上快速获得类似的好结果。所以这不是简单的“你好，世界！”以获得可比较的结果，但它仍然是一个很好的入门CNN的基础。</p><h1 id="7978" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">编码入门</h1><p id="6295" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">我们甚至不会试图准确地复制这篇论文，但与互联网上的大多数其他实现相反，我们将从一个至少在一些相关参数上遵循这篇论文的版本开始。代码将在Python和Tensorflow上使用Keras。使用像Keras这样的高级库，网络的代码几乎是微不足道的，这也将使实验变得更容易。</p><p id="2015" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该网络的基本结构在文件第二. b节中有详细解释。它总共有七层。</p><ul class=""><li id="f57a" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">一个卷积层，有6个5×5内核，带填充，因此我们实际上有填充的32×32图像作为输入，而不是原始的28×28 MNIST图像。</li><li id="b691" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">2x2池层。这里复制报纸已经开始变得困难，因为你会意识到阅读报纸。为了简单起见，我们使用平均池。</li><li id="342b" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">具有16个5x5内核且没有填充的卷积层。这也是本文结构的简化。</li><li id="68fe" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">另一个2x2池层使用平均池，再次不是真的。</li><li id="9138" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">一个有120个神经元的全连接层。</li><li id="0806" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">一个有84个神经元的全连接层。</li><li id="bfe8" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">一个softmax层，最终得到10个可能的输出类。虽然这也不同于纸张，但完全连接的层是真实的。</li></ul><p id="84d8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">tanh论文中使用的激活函数和损失函数类似于MSE或均方误差。两者都是为论文而优化的，因为它们必须手工编码，而不是像我们一样从高级库中使用它们。对于优化器，我们选择了简单的SGD或随机梯度下降。该网络经过20个时期的训练，学习率为“前两次为0.0005，接下来三次为0.0002，接下来四次为0.00005，此后为0.00001”，如论文中明确规定的。</p><p id="b86f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在Keras中创建模型只需要几行代码:</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="8941" class="ni mh iq ne b gy nj nk l nl nm">model = keras.Sequential(<br/>  [<br/>    keras.Input(shape=input_shape),<br/>    layers.Conv2D(6, kernel_size=(5, 5), padding=’same’, activation=’tanh’),<br/>    layers.AveragePooling2D(pool_size=(2, 2)),<br/>    layers.Conv2D(16, kernel_size=(5, 5), padding=’valid’, activation=”tanh”),<br/>    layers.AveragePooling2D(pool_size=(2, 2)),<br/>    layers.Flatten(),<br/>    layers.Dense(120, activation=”tanh”),<br/>    layers.Dense(84, activation=”tanh”),<br/>    layers.Dense(num_classes, activation=”softmax”)<br/>  ]<br/>)</span></pre><p id="b310" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您查看模型摘要并将其与网络的详细描述进行比较，您会发现只有C1层、C5层和F6层在可训练参数的数量方面与文章相符。这是因为我们没有尝试复制论文中所做的优化。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="2e6b" class="ni mh iq ne b gy nj nk l nl nm">Model: “sequential”<br/>_________________________________________________________________<br/>Layer (type) Output Shape Param #<br/>=================================================================<br/>conv2d (Conv2D) (None, 28, 28, 6) 156<br/>_________________________________________________________________<br/>average_pooling2d (AveragePo (None, 14, 14, 6) 0<br/>_________________________________________________________________<br/>conv2d_1 (Conv2D) (None, 10, 10, 16) 2416<br/>_________________________________________________________________<br/>average_pooling2d_1 (Average (None, 5, 5, 16) 0<br/>_________________________________________________________________<br/>flatten (Flatten) (None, 400) 0<br/>_________________________________________________________________<br/>dense (Dense) (None, 120) 48120<br/>_________________________________________________________________<br/>dense_1 (Dense) (None, 84) 10164<br/>_________________________________________________________________<br/>dense_2 (Dense) (None, 10) 850<br/>=================================================================<br/>Total params: 61,706<br/>Trainable params: 61,706<br/>Non-trainable params: 0</span></pre><h1 id="0f87" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">培训和评分</h1><p id="7063" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">复制纸张的重大挑战并不仅限于网络架构。下一个要回答的问题是如何构建培训过程。从积极的一面来看，本文中使用的MNIST数据集仍然是今天使用的MNIST数据集。第三部分有一段有趣而简短的MNIST历史。这篇论文很值得一读。</p><p id="950f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除了损失函数、优化器和学习率之外，我们还必须决定批量大小，以及在训练期间是否以及如何使用交叉验证。如果没有使用批次，即批次大小为1，则论文中给出的低学习速率结合仅学习20个时期才有意义。请注意，只有在使用微批处理的情况下，使用GPU才能获得相关的加速，因此训练这些参数需要一些时间。</p><p id="9f44" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文还探讨了训练数据量对网络性能的影响，并明确指出使用了来自MNIST的60，000幅训练图像。这些都是标准MNIST中可用的训练图像。因此，我们不使用交叉验证，即验证分割为0。</p><p id="e28b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这会产生以下用于训练网络的代码:</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="d06a" class="ni mh iq ne b gy nj nk l nl nm">lr_list = [0.0005, 0.0005, 0.0002, 0.0002, 0.0002, 0.00005,<br/>           0.00005, 0.00005, 0.00005, 0.00001, 0.00001, 0.00001,<br/>           0.00001, 0.00001, 0.00001, 0.00001, 0.00001, 0.00001,<br/>           0.00001, 0.00001]</span><span id="04e2" class="ni mh iq ne b gy nn nk l nl nm">def calc_lr():<br/>  elem = lr_list[0]<br/>  del lr_list[0]<br/>  return(elem)</span><span id="aec5" class="ni mh iq ne b gy nn nk l nl nm">optimizer = keras.optimizers.SGD(learning_rate=calc_lr)</span><span id="c1cf" class="ni mh iq ne b gy nn nk l nl nm">model.compile(loss=”mean_squared_error”, optimizer=optimizer,<br/>              metrics=[“accuracy”])</span><span id="ad61" class="ni mh iq ne b gy nn nk l nl nm">model.fit(x_train, y_train, batch_size=1, epochs=20,<br/>          validation_split=0.0)</span></pre><p id="b2a9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">训练网络输出训练集的精度，如果使用交叉验证，则输出验证集的精度。网络的唯一相关度量是测试集上的性能，因为这给出了网络在真实生活数据上如何表现的合理提示。在我的例子中，用这些参数训练网络的结果是训练数据的精度为0.9257，测试数据的精度为0.9292。这是一个很好的迹象，表明测试集的准确性更高，并暗示了网络的良好泛化能力。</p><p id="8e53" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是总体来说93%是一个好的准确率吗？实际上不是。本文在C节中比较了MNIST分类的几种技术和模型，其中提到的最差的一种具有大约95%的准确度。本文的一个重要结果是LeNet-5在MNIST上获得了99%或更高的准确率。因此，即使在1998年，我们要赢得最佳论文奖还有很长的路要走。</p><h1 id="8eb0" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">获得更好的分数</h1><p id="2f7f" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">如前所述，论文中暗示了许多优化，试图复制它们可能至少需要一篇博士论文。所以我们不会走那条路。获得更好结果的更简单的方法是采用LeNet-5的基本结构，并在CNN中使用当前的最佳实践，而不是20多年前。另一个值得考虑的方法是扩大网络，因为使用现有的硬件训练只需要很少的时间。</p><p id="fa04" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了看看什么是可能的，我们采取了一种捷径，使用网络上找到的许多实现方式中的一种，例如，这种方式恰好是我在谷歌搜索中的第一次点击:</p><p id="3411" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://hackmd.io/@bouteille/S1WvJyqmI" rel="noopener ugc nofollow" target="_blank">https://hackmd.io/@bouteille/S1WvJyqmI</a></p><p id="4f12" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">代码比我们的代码稍微复杂一点，可能是因为使用了旧版本的Keras。我们的选择没有太多不同，实际上网络看起来完全一样。潜在的相关差异有:</p><ul class=""><li id="a367" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">使用分类交叉熵作为损失函数，而不是均方误差。</li><li id="afbd" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">使用默认的学习率0.01，而不是纸上的学习率。</li><li id="fb19" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">使用默认批量32，而不是没有批量，即批量为1。</li><li id="7194" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">交叉验证的使用。</li></ul><p id="3617" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我的例子中，这些简单的调整极大地提高了训练数据和测试数据的准确度，分别为0.9890和0.9870。回到批量大小1，没有交叉验证，我得到的训练数据精度为1.0000，这表明过度拟合。但是因为我在测试数据上也得到0.9888，所以我并不在乎。所以仅仅通过改变损失函数和提高学习率，我们就离最佳论文奖更近了一点，如果我们在1998年才交论文的话。</p><h1 id="3cdb" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">摘要</h1><p id="f284" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated"><a class="ae kv" href="https://www.kaggle.com/nop287/lenet-5-cnn" rel="noopener ugc nofollow" target="_blank">重新实现</a>LeNet-5的基本结构很容易，但你不会真的复制论文中的工作。然而，在MNIST数据集上，这个有着20多年历史的网络的性能仍然令人印象深刻。使用好的超参数至关重要！虽然使用交叉熵进行分类可能被认为是<a class="ae kv" href="https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">的最佳实践</a>，而不是使用MSE进行回归，但是还有更多选择需要决定。在MNIST上使用CNNs】已经做得如此频繁，以至于最大的精确度是众所周知的。</p><p id="33e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一种替代方案是时尚MNIST，它可以取代经典MNIST，而不需要对网络进行任何改变，因为图像分辨率是相同的。它也有10个类，但目标是对时尚文章进行分类，而不是手写数字。为了进一步试验“你好，世界！”这是一个更有趣的数据集。</p></div></div>    
</body>
</html>