<html>
<head>
<title>Are You Still Using Grid Search for Hyperparameters Optimization?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">您还在使用网格搜索进行超参数优化吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hyperparameters-tuning-from-grid-search-to-optimization-a09853e4e9b8?source=collection_archive---------11-----------------------#2021-06-24">https://towardsdatascience.com/hyperparameters-tuning-from-grid-search-to-optimization-a09853e4e9b8?source=collection_archive---------11-----------------------#2021-06-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="fefc" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">让我们讨论如何以智能的方式搜索机器学习模型的超参数背后的思想。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e358810075c350c7b5dc8ad6bad3c6f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZYC4nQw8g2dv7GCp"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/@mluotio83" rel="noopener ugc nofollow" target="_blank">米伊卡</a>在<a class="ae kv" href="https://unsplash.com/photos/i3WlrO7oAHA" rel="noopener ugc nofollow" target="_blank">上拍摄的照片</a>。</p></figure><p id="542d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我们训练一个机器学习模型时，我们需要做出一些选择，从哪个模型开始使用，如何准备我们的数据集，如何处理离群值，等等。</p><p id="24d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中一个选择是超参数；这些是控制学习过程的参数，但不能由训练本身得出。一些例子是:</p><ul class=""><li id="d43f" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">神经网络中的学习速率、时期和层数/神经元数。</li><li id="190b" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">随机森林中的树木数量、最大深度和质量标准。</li><li id="8567" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">来自支持向量机的核、gamma和C值。</li></ul><p id="93ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">随之而来的一些问题是:我应该为这个模型设置什么超参数？默认的够好吗？我是否可以通过尝试更多架构来提高性能？我如何决定尝试哪些选项？所有这些问题都与超参数调整有关[1]。</p><p id="9f15" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇文章中，我将讨论:</p><ul class=""><li id="cd72" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">监督模型中超参数调整的标准策略。</li><li id="6de2" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">不明智策略的问题在于。</li><li id="d7c6" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">明智策略的权衡。</li><li id="f8d8" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">如何实现超参数调整的遗传算法(GA)思想？</li><li id="9842" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">我们能给GA带来什么额外的特性。</li><li id="2fec" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">包含几个实现的python包的参考和例子。</li></ul><p id="6941" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你想马上获得一些带有示例的代码，你可以查看我在<a class="ae kv" rel="noopener" target="_blank" href="/tune-your-scikit-learn-model-using-evolutionary-algorithms-30538248ac16">其他媒体</a>上的帖子。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="d612" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated"><strong class="ak"> 1。基本策略:</strong></h1><p id="982e" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">有几个选项可用来找到那些将使您的模型增强的超参数，仅举几个例子:</p><ul class=""><li id="0357" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">网格搜索</li><li id="8122" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">随机网格搜索</li><li id="9836" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">贝叶斯优化</li><li id="cd2f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">遗传算法</li></ul><p id="06ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">网格搜索和随机网格搜索都是我们所谓的“强力方法”，这意味着超参数的选择不是以一种提供信息的方式，而是通过尝试一些选项并希望它有效。</p><p id="7f23" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它们的优点是实现简单，并且可以足够快地得到合适的结果，尝试一些组合并基于一些度量选择最佳的，因此对于两个超参数；该过程可能如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/416f3342448eb4efd22f3079509e087e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CzkVwVu5u883ORZitRkVJg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">网格布局。图片由Yoshua Bengio等人提供。</p></figure><p id="30d9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上图展示了网格和随机网格搜索如何优化一个模型，该模型的得分函数(如AUC)是绿色和黄色区域的总和，对得分的贡献是区域的高度，因此基本上只有绿色区域对得分有意义。</p><h1 id="cc92" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated"><strong class="ak"> 2。将问题可视化</strong></h1><p id="6f23" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">您可以看到，随机布局在某种程度上优于网格布局，因为它可以探索优化函数的更多不同值，并且由于其中一个参数不重要，网格搜索“浪费”了六个额外的模型，得分没有重要变化，但在这两种情况下，我们都有可能获得接近或远离最佳值的值。</p><p id="42aa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我将把这种表示简化为一维函数，只是为了获得一些直觉:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/cb8cf796741cd64c17a93ee03533c79f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*XvbnT35uxA9lN6oQfRYItQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">准确度分数与超参数选择。图片由作者提供。</p></figure><p id="e732" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的图中，红线表示估计量可能达到的交叉验证准确度(或任何其他度量)，圆点是基于准确度分数的超参数的固定选择，因此，例如，如果这是一个神经网络，圆点可以表示以下内容:</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="bff3" class="nw mo iq ns b gy nx ny l nz oa"><strong class="ns ir">dot 1:</strong> {"learning_rate": 0.001, "layers": 5, "optimizer": "Adam"}<br/><strong class="ns ir">dot 2:</strong> {"learning_rate": 0.01, "layers": 3, "optimizer": "Adagrad"}<br/><strong class="ns ir">dot 3:</strong> {"learning_rate": 1, "layers": 6, "optimizer": "SGD"}<br/><strong class="ns ir">dot 4:</strong> {"learning_rate": 0.001, "layers": 8, "optimizer": "RMSprop"}<br/><strong class="ns ir">dot 5:</strong> {"learning_rate": 0.1, "layers": 20, "optimizer": "SGD"}</span></pre><p id="5420" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据这一点，我们可以得到沿着这条线的任何值，你想得到尽可能高的值，但是通过随机或手动选择点，我们可能会得到也可能不会得到好的结果。</p><p id="e1fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">好..我们发现了问题，那么我们如何才能让它变得更好呢？</p><h1 id="9b8e" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated">3.信息的方式</h1><p id="c063" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">我提到的另外两种方法是贝叶斯优化[3]和遗传算法[4]，我们可以说，它们遵循一个信息丰富的标准来做出选择，它们的共同点是，它们遵循一个顺序过程，试图通过它们过去做出的决策来找到一组更好的超参数，所以如果我们认为这是一个迭代过程，它可能看起来像这样:</p><div class="kg kh ki kj gt ab cb"><figure class="ob kk oc od oe of og paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/fc2aa4cac5081ff86617d46b3f3e3e25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*YcQYEkFy9253cSUYlfYO6Q.png"/></div></figure><figure class="ob kk oh od oe of og paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/660f80c390a72a88c37307948dc5f58e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*kaPP_qUNvQeujh3Ud4PPxg.png"/></div></figure></div><div class="ab cb"><figure class="ob kk oi od oe of og paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/7064c8e5d85b28b343fc6a7e46edc73f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*pypbn2g1Jh2ZgqPHEomU3Q.png"/></div></figure><figure class="ob kk oj od oe of og paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/77328010019188726dee4ab8b05fbe4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*FpGVlUsaVcf4As_ZbquXWg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk ok di ol om translated">迭代优化过程。图片由作者提供。</p></figure></div><p id="bf16" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以看到，第一次迭代可能会看到一个随机网格会做什么，没关系，我们必须从某个点开始；其思想是聪明地探索超参数的空间，在每次迭代中取得进展，修改要尝试的集合的数量，创建新的集合，等等。</p><p id="0dcb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当然，正如数据科学中预期的那样，这不是一个银弹解决方案；可能会出现以下几种情况:</p><ul class=""><li id="5073" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir">探索与开发的困境:</strong>我是否应该去探索较少的地区，以防错过什么？或者我应该继续尝试我已经知道的显示有希望的结果的区域附近的点？</li><li id="9cb5" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">局部最大:</strong>这是第一种可能的结果；如果我的优化函数是非凸的、非线性的、有噪声的怎么办？，如果我陷入局部最大值，认为这是最好的(全局最大值)解决方案，怎么办？</li><li id="2c90" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">资源消耗:</strong>正如你所看到的，我们已经把它变成了一个迭代的过程，可能比简单的网格搜索消耗更多的资源。</li><li id="3cde" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">新参数:</strong>我应该运行多少次迭代？我如何控制探索和开发？，我应该在每次迭代中创建更多的集合吗？，这些不就是我要决定的更多的超参数吗？</li></ul><p id="1b7a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">希望有几个实现已经(直到某个时候)解决了这些问题，并且这些选择对我们正在优化的分数的最终影响不如机器学习模型本身中超参数的选择敏感。</p><p id="ab1c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，你可以检查遗传算法方法的<a class="ae kv" href="https://sklearn-genetic-opt.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> sklearn-genetic-opt </a>或者贝叶斯方法的<a class="ae kv" href="https://scikit-optimize.github.io/stable/modules/generated/skopt.BayesSearchCV.html" rel="noopener ugc nofollow" target="_blank"> scikit-optimize </a>。我将解释遗传算法的方法。</p><h1 id="d648" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated">4.遗传算法(GA)方法</h1><p id="ed6f" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">遗传算法是一种受自然选择启发的元启发式算法；它们通常用于优化和搜索问题，通常基于一组函数，如变异、交叉和选择[2]。我们称之为遗传算子。</p><p id="31b2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本节中，我将交替使用以下术语来建立遗传算法和机器学习之间的联系:</p><p id="c630" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">超参数的一个选择→个体</p><p id="19fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">人口→若干个人</p><p id="e1f9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">世代→一个包含固定群体的固定迭代</p><p id="49a0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">适应值→交叉验证分数</p><p id="ac74" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有几种变化，但一般来说，要遵循的步骤如下所示:</p><ol class=""><li id="a0e0" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr on ly lz ma bi translated">生成随机抽样总体(不同的超参数集)；这是第0代。</li><li id="5223" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr on ly lz ma bi translated">从机器学习的角度评估种群中每个个体的适应度值，得到交叉验证分数。</li><li id="4e4a" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr on ly lz ma bi translated">通过使用几个遗传算子产生新一代。</li><li id="d5c8" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr on ly lz ma bi translated">重复步骤2和3，直到满足停止标准。</li></ol><p id="c836" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们一步一步来。</p><p id="8436" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 4.1-4.2创建第0代并对其进行评估:</strong></p><p id="2ed8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如上所述，您可以生成一组随机的超参数，或者您可以包含一些您已经尝试过并认为是合适的候选参数的手动选择的超参数。</p><p id="9bfd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每个集合通常以染色体的形式被编码，染色体是这个群体的二进制表示；例如，如果我们将第一代的规模设置为三个个体，它将如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/a0221fd64774816531cbf43780ce7ff2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y4hkqypTM5e3YvvqCuHJcQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">第0代。图片由作者提供。</p></figure><p id="9156" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以在这一代中，我们使用红色箭头表示的编码函数将三个个体映射到一个染色体(二进制)表示中。染色体中的每个方框是一个性别。染色体的一个固定部分是超参数之一。</p><p id="c5ef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们使用显示为紫色箭头的评分函数来获得每个候选人的交叉验证分数(适合度)。</p><p id="8678" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 4.3创造新一代:</strong></p><p id="69b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们可以创建一组新的候选人；如前所述，有几个遗传算子；我将展示最常见的几种:</p><p id="2f15" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="op">交叉:</em> </strong></p><p id="b9bb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种操作包括取两条亲代染色体并使它们交配以产生新的子代；我们选择亲本的方式可以是通过概率分布函数，该函数将更多的概率给予具有更高适应度的个体，假设个体编号1和3被选择，那么我们可以从每个亲本中随机选取两个点，并进行交叉，如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/5f06380e6dc74ed1f4c6cb75a2ec4144.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*T3FTopm0VMHWqD1VCf8Oww.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">交叉操作。图片由作者提供。</p></figure><p id="9198" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在孩子代表了一组新的超参数；如果我们解码每个孩子，我们可以得到，例如:</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="37fa" class="nw mo iq ns b gy nx ny l nz oa"><strong class="ns ir">Child 1:</strong> {"learning_rate": 0.015, "layers": 4, "optimizer": "Adam"}<br/><strong class="ns ir">Child 2:</strong> {"learning_rate": 0.4, "layers": 6, "optimizer": "SGD"}</span></pre><p id="d9a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是在一些迭代之后，在相同的超参数集合上进行交叉可能会给出相似的结果，所以我们会陷入同一种解决方案；这就是为什么我们引入了像变异这样的其他操作。</p><p id="003c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">突变:</strong></p><p id="cce2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以足够低的概率(&lt; ~0.1), this operator randomly changes one of the gens or a whole hyperparameter to create more diverse sets.</p><p id="f20b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Let's take, for example, the child one from the previous image; let us pick up random gen and change its value:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi or"><img src="../Images/1a4413fb7879aeb2b666c9ffa0e1260d.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*YR_XsDp-z9u9zk9X2T4Hsw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Mutant child. Image by the author.</p></figure><p id="5cad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Or it could even change a whole parameter, for example, the optimizer:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/ae39f4ec683818b8f4a02b4c9b02b69b.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*IY-hE8A1-gc7rEGJ9zZCig.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Random change in one parameter. Image by the author.</p></figure><p id="e884" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">精英主义:</strong></p><p id="8f03" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种选择策略指的是选择每一代中最优秀的个体，以确保其信息能够跨代传播。这种策略非常简单，只需根据个体的适应值选择最优秀的k个个体，并将其复制到下一代。</p><p id="d680" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以在执行了那些操作之后，新一代可能看起来像这样:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/e0a60cbb3376a36920ac250c131220a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*FxjFvoIxiiIU5S3DofZLkA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">第一代。图片由作者提供。</p></figure><p id="4143" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从现在开始，重复这个过程几代，直到你满足一个停止标准，例如:</p><ul class=""><li id="fa38" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">已达到最大代数。</li><li id="8e9e" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">流程运行时间超过了预算时间。</li><li id="e3fb" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">与上<em class="op"> n </em>代相比，性能没有提高(低于阈值)。</li></ul><p id="6307" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图是我们运行GA优化器几代后得到的结果的一个例子；这是一个回归模型，使用带有r平方度量的随机森林:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ou"><img src="../Images/1473e12da92eb0bba604c64dc2ed3f26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5lX2YYRJjT_UJseJ"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">几代人的度量改进。图片由作者提供。</p></figure><p id="9b7b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以绘制算法尝试的超参数，如点图，但在这种情况下，遵循最现实的表示，我们可以绘制每个参数的样本值的直方图和与第一个图类似的散点图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ou"><img src="../Images/fe798e3552806e346bab27ae13b8897c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*umkCv-EGF6_FM0_N"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">超参数的抽样分布。图片由作者提供。</p></figure><p id="5572" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图中的颜色越深，在该区域适合的不同估计值就越多；“分数”是相同的r平方。</p><p id="82b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，在这一点上，问题是，我们如何实现这一点？我必须从头开始做吗？如前所述，已经有几个包可以帮助解决这个问题；我们会看到其中一个的特征。</p><p id="3863" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">注:</strong>我是下面这个包的作者；如果你想进一步了解，投稿或者提出一些建议，可以查看本文末尾的文档和GitHub资源库。</p><h1 id="0ed2" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated">介绍Sklearn-genetic-opt</h1><p id="ff5f" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">Sklearn-genetic-opt是一个基于Python的包，它使用来自<a class="ae kv" href="https://deap.readthedocs.io/en/master/" rel="noopener ugc nofollow" target="_blank"> DEAP </a>包的进化算法来选择一组优化(最大或最小)交叉验证分数的超参数；该软件包可用于回归和分类问题。在这一点上，Sklearn-genetic-opt与任何scikit-learn回归器或分类器(或Sklearn兼容的回归器或分类器)兼容。</p><p id="838d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该软件包具有以下特点:</p><ul class=""><li id="ee42" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir"> GASearchCV: </strong>包的主要类，保存进化交叉验证优化例程，它有一个类似于scikit-learn GridSeachCV的API。</li><li id="ab3f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir"> GAFeatureSelectionCV: </strong>软件包的补充类，它使用与GASearchCV相同的进化算法进行特征选择，但通过尝试最小化所使用的特征数量，同时优化CV分数，所有这一切都使用一组固定的超参数。</li><li id="d389" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">算法:</strong>一组不同的进化算法，用作优化程序。</li><li id="b649" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">回调:</strong>定制评估策略，以生成早期停止规则、日志记录或您的定制逻辑。</li><li id="c001" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">适配器:</strong>改变参数作为代函数的策略。</li><li id="7ef1" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">图:</strong>生成预定义的图，以了解优化过程。比如最后两个情节就来自于包。</li><li id="1e34" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir"> MLflow: </strong>与<a class="ae kv" href="https://mlflow.org/" rel="noopener ugc nofollow" target="_blank"> mlflow </a>的内置集成，用于记录和管理所有超参数、cv值和拟合模型的生命周期。</li></ul><p id="973f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，它的工作方式是遵循类似于上一节中描述的过程，但它添加了一些额外的功能，如回调、MLflow日志记录和不同的算法方法；看起来是这样的:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ov"><img src="../Images/b802cae5c370e74f1aba4f864a5a38c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-NP-sDKAN4IXiS2xy9PSaQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Sklearn-genetic-opt一般步骤。图片由作者提供。</p></figure><p id="290a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这就是MLflow测井的外观:</p><div class="kg kh ki kj gt ab cb"><figure class="ob kk ow od oe of og paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/05c820b2f20029335d1eff3d3dab8d67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*QKN4EVhtp1bVFlwFRXRdwQ.png"/></div></figure><figure class="ob kk ox od oe of og paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/4b23233bec4e60d61c29b2c734f14a21.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*Kvfn_HwThvY2oa1m_8kKsQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk oy di oz om translated">Mlflow日志记录。图片由作者提供。</p></figure></div><p id="7e75" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是一个如何使用它进行超参数调整的简单示例:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pa pb l"/></div></figure><p id="5d28" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以在这篇文章中了解更多关于这个代码的每一部分。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="467b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">原来如此！感谢您阅读此内容；我希望这有助于思考您的调优策略；以下是最后一个包的相关链接，如果你想查看的话:</p><p id="159c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">文献:</strong>【https://sklearn-genetic-opt.readthedocs.io/en/stable/ T2】</p><p id="73b2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">【https://github.com/rodrigo-arenas/Sklearn-genetic-opt】储存库:<a class="ae kv" href="https://github.com/rodrigo-arenas/Sklearn-genetic-opt" rel="noopener ugc nofollow" target="_blank"/></p><h1 id="1f50" class="mn mo iq bd mp mq nl ms mt mu nm mw mx jw nn jx mz jz no ka nb kc np kd nd ne bi translated">参考</h1><p id="b61e" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">[1]<a class="ae kv" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Hyperparameter_optimization</a></p><p id="52dc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2]<a class="ae kv" href="https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf" rel="noopener ugc nofollow" target="_blank">https://www . jmlr . org/papers/volume 13/bergstra 12a/bergstra 12a . pdf</a></p><p id="a97e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3]<a class="ae kv" href="https://www.cs.toronto.edu/~rgrosse/courses/csc411_f18/tutorials/tut8_adams_slides.pdf" rel="noopener ugc nofollow" target="_blank">https://www . cs . Toronto . edu/~ rgrosse/courses/CSC 411 _ f18/tutorials/tut 8 _ ADAMS _ slides . pdf</a></p><p id="4d4f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/Genetic_algorithm" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Genetic_algorithm</a></p></div></div>    
</body>
</html>