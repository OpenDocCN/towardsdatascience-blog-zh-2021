<html>
<head>
<title>784-Dimensional Quantum MNIST</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">784维量子MNIST</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/784-dimensional-quantum-mnist-f0adcf1a938c?source=collection_archive---------16-----------------------#2021-12-09">https://towardsdatascience.com/784-dimensional-quantum-mnist-f0adcf1a938c?source=collection_archive---------16-----------------------#2021-12-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div class="gh gi ir"><img src="../Images/e7620493a3de60425cfd89c7d99be1f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*Ft2rLuO82eItlvJn5HOi9A.png"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated"><a class="ae jc" href="https://commons.wikimedia.org/wiki/File:MnistExamples.png" rel="noopener ugc nofollow" target="_blank">https://commons.wikimedia.org/wiki/File:MnistExamples.png</a></p></figure><div class=""/><div class=""><h2 id="f456" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">没有降维</h2></div><p id="34fd" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我有史以来点击率最高的媒体文章是《T2》和《量子MNIST》。如果你冒险进入机器学习，人工智能的一个子集，你几乎肯定会遇到MNIST，这是一个流行的手写数字数据集，数字0到9。数据集因其高质量而广受欢迎，这使您可以专注于训练和测试模型，而不必担心清理数据。当然，在现实世界中，您总是会遇到数据问题，但是一个干净的数据集肯定会使学习卷积神经网络(CNN)等应用程序变得更加容易。</p><p id="326c" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于量子MNIST，我将784维的数据集减少到16个灰度维度，然后使用密集角度编码将这些维度映射到8个量子位。我用了所有的10个数字。相比之下，谷歌的Tensorflow Quantum将数据集缩减为16个黑白维度，只处理数字3和6。在我的免费电子书《T4地下城&amp;量子比特:超越量子计算教程的冒险家的故事》中，详细描述了量子MNIST的发展过程</p><p id="f5f4" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">虽然我在分辨率和数字使用方面“击败”了谷歌，但我一直记得我们将数据集减少到了相同的维数。我不想在这个指标上与谷歌相提并论，但量子计算模拟器是有限的，我没有足够的量子位在量子处理器上运行它。然而，我已经决定使用<a class="ae jc" href="https://levelup.gitconnected.com/amplitude-encoding-dd89dc84170d" rel="noopener ugc nofollow" target="_blank">振幅编码</a>再次尝试这个实验，试图看看是否可以在完全不使用维度缩减的情况下完成。</p><p id="920a" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">不幸的是，784维量子MNIST使用Python，额外的量子位和纠缠，所以它运行得非常非常慢。但是，如果你想知道它是如何做到的，一步一步的算法如下。</p><h2 id="cdab" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">算法</h2><ol class=""><li id="e949" class="mj mk jf kw b kx ml la mm ld mn lh mo ll mp lp mq mr ms mt bi translated">从Kaggle下载CSV格式的<a class="ae jc" href="https://www.kaggle.com/oddrationale/mnist-in-csv" rel="noopener ugc nofollow" target="_blank">MNIST</a>。或者，从“<a class="ae jc" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank">MNIST数据库</a>”下载图像，并做硬的方式；你不会伤害我的感情。mnist_train和mnist_test CSV文件分别包含60，000和10，000个28x28像素图像的值。因此，每幅图像都有从0到255的784个值，每个值代表一个特定灰度像素的强度。</li><li id="84af" class="mj mk jf kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated">计算每个训练数字的每个维度的平均值。每个训练数字大约有6000个表示，因此对于每个维度，所有值的总和除以所有值的计数:<em class="mz">值的总和/值的计数</em>。我以前考虑过平均值的替代方法，如标准差和宁滨，但是我担心十位数会重叠，降低分类的准确性。</li><li id="9527" class="mj mk jf kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated">对于每个数字的每个维度，计算除以该数字所有值之和的值的平方根:<em class="mz">sqrt(value/sum _ of _ values)</em>。振幅编码，顾名思义，对振幅进行编码，振幅的平方和必须为1。</li><li id="ae2e" class="mj mk jf kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated">填充零。对于784维，我们有两种选择:添加240个零，这样我们就有1024维来编码10个量子位，或者去掉272维，这样我们就有512维来编码9个量子位。老实说，你应该真的想删除维度，因为784个维度中的一些维度在所有数字中都有零的含义。但是，这个特殊练习的重点是避免仅仅为了说我使用了所有784个维度而减少维度，所以我填充了零。</li><li id="d538" class="mj mk jf kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated">纠正错误。例如，对于火车零，1024个振幅实际上总计为0.999999998266969，而不是1。因为所有训练数字的前几个值都是零，所以我将每个训练数字的第一维更新为该数字差异的平方根:<em class="mz"> sqrt(error) </em>。但是，总和超过1是个问题，因为调整必须是负的。负的幅度平方是正的，这实际上使误差更大。因此，解决方法是遍历这些值，直到找到一个大于或等于误差的值，然后将该值更新为原始值的平方减去误差的平方的平方根:<em class="mz"> sqrt(value**2 - error**2) </em>。</li><li id="9bd7" class="mj mk jf kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated">使用<a class="ae jc" href="https://levelup.gitconnected.com/comparing-quantum-states-c6445e1e46fd" rel="noopener ugc nofollow" target="_blank">交换测试</a>，即距离度量、内核方法、内积，将测试数字与每个训练数字进行比较。对于1024个振幅，每个训练数位需要10个量子位，对于1024个振幅，每个测试数位需要10个量子位，并且我们需要1个ancilla量子位来执行比较，总共21个量子位。安西拉量子位以哈达玛门开始和结束。在Hadamards之间，ancilla是10个Fredkin门的控制量子位，也称为受控交换，类似于训练数字和测试数字的量子位。我们只测量安西拉量子位。</li><li id="a0ac" class="mj mk jf kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated">等等。</li><li id="4cf6" class="mj mk jf kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated">再等一会儿。</li><li id="d473" class="mj mk jf kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated">这需要相当长的时间。</li><li id="432b" class="mj mk jf kw b kx mu la mv ld mw lh mx ll my lp mq mr ms mt bi translated">比较零测量值。当两个量子态相同时，它们以100%的概率测量为0。当两个状态最大程度相反时，它们以50%的概率测量为0。它们越接近，测量0的频率就越高。例如，两个非常相似的状态可能以90–95%的概率测量为0，而两个非常不相似的状态可能以55–60%的概率测量为0。因此，具有最多0测量值的训练数位是测试数位最接近的数位。那个火车数字是最有可能的<a class="ae jc" href="https://medium.com/swlh/quantum-classification-cecbc7831be" rel="noopener">分类</a>。</li></ol><h2 id="3b8d" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">结果如何？</h2><p id="69d4" class="pw-post-body-paragraph ku kv jf kw b kx ml kg kz la mm kj lc ld na lf lg lh nb lj lk ll nc ln lo lp im bi translated">上一次我做量子MNIST时，我运行了一次，因为经典的预处理是如此乏味，我挑战自己不要使用Python。我最初的量子MNIST实验使用MS Excel进行经典的前处理和后处理，电路是使用IBM Quantum OpenQASM编辑器构建的。幸运的是，测试零点的测量值最接近于训练零点，所以实验成功了。我有足够的资料来发表这篇文章，但有一个警告。</p><p id="4e4e" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这次我把它当作IBM Quantum Jupyter笔记本来运行。我还是在MS Excel里做了一些经典的预处理，但绝对没有上次那么繁琐。这是好消息。它极其缓慢，令人痛苦，这是个坏消息。但是，我被迫使用古典模拟器，古典MNIST很慢。我猜这在量子处理器上只需要几分钟，然而在NISQ设备上10个Fredkin门只会产生噪音。</p><p id="5678" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在我写这篇文章的时候，我只能完成每个火车数字10个镜头的运行。我让它在我打字的时候每列数字运行100次，但是我想我会在它完成之前自然死亡。到目前为止，在10次运行和可见的100次运行结果之间，我基本上是在看随机数。相比之下，我最初的量子MNIST在合理的时间框架内对每个训练数字进行了8192次拍摄，结果的分布是有意义的。但是，量子MNIST将八个量子比特与八个量子比特的个体旋转进行了比较，而不是将十个纠缠量子比特与十个纠缠量子比特进行比较。因此，虽然量子分类与交换测试是绝对有效的，量子分类是否与振幅编码一起工作的问题是不确定的。</p><h2 id="cdfd" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">量子计算优势？</h2><p id="20d2" class="pw-post-body-paragraph ku kv jf kw b kx ml kg kz la mm kj lc ld na lf lg lh nb lj lk ll nc ln lo lp im bi translated">我考虑过运行一次纠错，然后对调整进行硬编码以加快执行速度。然而，当我在整个代码中添加打印语句时，这些计算几乎是瞬间完成的。一旦作业开始执行，速度就会变慢。因此，这可能是对量子计算优势的一个很好的测试。</p><p id="a522" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">尽管在NISQ设备上的结果会是纯粹的噪音，如前所述，在21个量子位上运行它真的需要多长时间？我认为在队列中等待真正的硬件仍然会比这执行得更快，特别是因为10个电路可以作为一批运行并且只排队一次。此外，我们需要考虑到模拟器上的1024个镜头，更不用说更高的镜头数了，可能会因为任何可能中断内核的事情而永远无法完成。</p><p id="e12f" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">再说一次，古典MNIST很慢。如果NISQ MNIST只需要几分钟，那么即使未来通过容错来减慢它的速度，仍然预示着计算优势。</p><h2 id="de2e" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">你能做得更好吗？</h2><p id="2f46" class="pw-post-body-paragraph ku kv jf kw b kx ml kg kz la mm kj lc ld na lf lg lh nb lj lk ll nc ln lo lp im bi translated">我用Jupyter笔记本创建了一个<a class="ae jc" href="https://cb.run/NO6X" rel="noopener ugc nofollow" target="_blank"> GitHub知识库</a>，我曾在IBM量子实验室中用它运行784维量子MNIST。不幸的是，我用来做一些经典预处理的MS Excel文件大大超过了GitHub的25 MB限制，即使有压缩，所以我上传了两个压缩的<a class="ae jc" href="https://cb.run/6AxU" rel="noopener ugc nofollow" target="_blank"> 162 MB。zip文件</a>和<a class="ae jc" href="https://cb.run/t3rp" rel="noopener ugc nofollow" target="_blank"> 189 MB未压缩。xlsx文件</a>到Google Drive，希望能缓解你的互联网安全偏好。</p><h2 id="e324" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">我的下一步是什么？</h2><p id="9c90" class="pw-post-body-paragraph ku kv jf kw b kx ml kg kz la mm kj lc ld na lf lg lh nb lj lk ll nc ln lo lp im bi translated">我在考虑找一个更小的真实世界数据集来测试这个。我直接去了MNIST，因为我可以直接比较。但要确认量子分类是否与振幅编码一起工作，我认为8或16维的数据集会更好，分别需要3或4个量子位。虽然我可以在真实的硬件上运行一个2量子位的4维数据集，但这太小了，不会给任何人留下深刻印象，结果仍然是噪音。不幸的是，在NISQ时代，模拟是唯一可行的选择，所以我认为3或4个量子位将是一个很好的测试。</p><p id="6871" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我也有一个相关的想法，我一直抱着希望得到一个微补助金，但这看起来不会发生，所以我只是在这里发表它。我可能应该吸取教训，不要从784维开始，但如果那样的话会更令人印象深刻，所以我会采取“不成功便成仁”的方法。</p></div></div>    
</body>
</html>