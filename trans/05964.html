<html>
<head>
<title>Scraping Data from Nested HTML Pages with Python Selenium</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python Selenium从嵌套的HTML页面中抓取数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scraping-data-from-nested-html-pages-with-python-selenium-c5f23065841f?source=collection_archive---------20-----------------------#2021-05-28">https://towardsdatascience.com/scraping-data-from-nested-html-pages-with-python-selenium-c5f23065841f?source=collection_archive---------20-----------------------#2021-05-28</a></blockquote><div><div class="fc ik il im in io"/><div class="ip iq ir is it"><h2 id="eb69" class="iu iv iw bd b dl ix iy iz ja jb jc dk jd translated" aria-label="kicker paragraph">数据收集</h2><div class=""/><div class=""><h2 id="200f" class="pw-subtitle-paragraph kc jf iw bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">一个快速的教程来建立一个从网站上提取的术语列表</h2></div><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ku"><img src="../Images/70da319639e3795dc22e2aa2bc06129f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FigrJtTTzUiT7mZZ-2I_6g.jpeg"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">图片来自<a class="ae lk" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4605834" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae lk" href="https://pixabay.com/users/kevinandthepup-14173621/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4605834" rel="noopener ugc nofollow" target="_blank">凯文·莫里森</a></p></figure><p id="0cb1" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">抓取包括从网络上的HTML页面中提取信息。在Python中，可以通过<a class="ae lk" href="https://selenium-python.readthedocs.io/" rel="noopener ugc nofollow" target="_blank"> Selenium库</a>进行抓取。</p><p id="2285" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在本教程中，我演示了如何通过Python <code class="fe mh mi mj mk b">selenium</code>抓取分布在两层嵌套页面上的术语列表。作为例子，我从<a class="ae lk" href="https://www.brocardi.it/" rel="noopener ugc nofollow" target="_blank"> Bocardi </a>中抓取术语列表。</p><p id="dd66" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">本教程的完整代码可以从<a class="ae lk" href="https://github.com/alod83/data-science/tree/master/DataCollection/Web" rel="noopener ugc nofollow" target="_blank">我的Github库</a>下载。</p><h1 id="aee9" class="ml mm iw bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated">装置</h1><p id="f15d" class="pw-post-body-paragraph ll lm iw ln b lo nd kg lq lr ne kj lt lu nf lw lx ly ng ma mb mc nh me mf mg ip bi translated">通过命令<code class="fe mh mi mj mk b">pip install selenium</code>，可以通过<code class="fe mh mi mj mk b">pip</code>轻松安装<code class="fe mh mi mj mk b">selenium</code>库。除了库，我还需要为我的浏览器安装驱动程序，这取决于我的浏览器的版本。在本教程中，我开发了Chrome浏览器。我可以通过在浏览器地址栏输入<code class="fe mh mi mj mk b">chrome://settings/help</code>来查看它的版本。</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ni"><img src="../Images/f3dcff9cda699ffd4fb89cb1ce510b5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xv3RfZJUG1knV8tZigMP0g.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="6422" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在我的例子中，版本是80，因此我可以从<a class="ae lk" href="https://sites.google.com/a/chromium.org/chromedriver/downloads" rel="noopener ugc nofollow" target="_blank">这个链接</a>下载chrome驱动。下载完成后，我可以将文件放入我的文件系统的一个普通文件夹中，我需要用chrome驱动程序的路径配置<code class="fe mh mi mj mk b">$PATH</code>变量:</p><ul class=""><li id="de61" class="nj nk iw ln b lo lp lr ls lu nl ly nm mc nn mg no np nq nr bi translated">Windows用户——在<a class="ae lk" href="https://www.youtube.com/watch?v=mHtlBq5cP2Y&amp;t=4s" rel="noopener ugc nofollow" target="_blank">这个视频</a>中，我解释了如何在Windows 10上为selenium安装Chrome驱动。</li><li id="cd86" class="nj nk iw ln b lo ns lr nt lu nu ly nv mc nw mg no np nq nr bi translated">Mac OS/ Linux -通过添加下面一行<code class="fe mh mi mj mk b">export PATH = "&lt;path to web driver&gt;: $ PATH"</code>来编辑<code class="fe mh mi mj mk b">.bash_profile</code>或<code class="fe mh mi mj mk b">.profile</code>文件，然后重启计算机。</li></ul><h1 id="e74e" class="ml mm iw bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated">识别网站结构</h1><p id="cf9e" class="pw-post-body-paragraph ll lm iw ln b lo nd kg lq lr ne kj lt lu nf lw lx ly ng ma mb mc nh me mf mg ip bi translated">为了从网站上搜集数据，首先我需要研究URIs结构。在我的例子中，术语列表是按字母顺序组织的，字母表中的每个字母都有一个专门的页面，可以在<code class="fe mh mi mj mk b">&lt;basic_url&gt;/dizionario/&lt;current_letter&gt;/</code>(URI的第一级)找到。例如，对于信件<code class="fe mh mi mj mk b">a</code>，可在<code class="fe mh mi mj mk b">https://www.brocardi.it/dizionario/a/</code>获得专用页面。此外，每个字母的术语列表在不同的页面中分页。对于每个字母，第一页在URI的第一层可用，而从第二页开始，URI改变并在<code class="fe mh mi mj mk b">&lt;basic_url&gt;/dizionario/&lt;current_letter&gt;/?page=&lt;page_number&gt;</code>可用。例如，对于字母<code class="fe mh mi mj mk b">a</code>，第二页中的术语列表可通过链接<code class="fe mh mi mj mk b"><a class="ae lk" href="https://www.brocardi.it/dizionario/a/?page=2." rel="noopener ugc nofollow" target="_blank">https://www.brocardi.it/dizionario/a/?page=2</a></code> <a class="ae lk" href="https://www.brocardi.it/dizionario/a/?page=2." rel="noopener ugc nofollow" target="_blank">获得。</a></p><h1 id="e112" class="ml mm iw bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated">环境设置</h1><p id="41c6" class="pw-post-body-paragraph ll lm iw ln b lo nd kg lq lr ne kj lt lu nf lw lx ly ng ma mb mc nh me mf mg ip bi translated">在我的代码中，我需要实现两个循环:一个用于信件的外部循环和一个用于页面的内部循环。我注意到有些字母不见了(<code class="fe mh mi mj mk b">jkwxy</code>)。对于外部循环，我构建了一个包含所有字母的列表，但不包括丢失的字母。我利用<code class="fe mh mi mj mk b">string.ascii_lowercase</code>来构建字母列表。</p><pre class="kv kw kx ky gu nx mk ny nz aw oa bi"><span id="ec38" class="ob mm iw mk b gz oc od l oe of">import string<br/>letters = string.ascii_lowercase<br/>letters = letters.replace('jk', '')<br/>letters = letters.replace('wxy', '')<br/>letters = list(letters)</span></pre><p id="cc39" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">然后我定义了两个变量，<code class="fe mh mi mj mk b">basic_url</code>，它包含网站的基本url，和<code class="fe mh mi mj mk b">table</code>，它将包含所有提取的术语的列表。最初<code class="fe mh mi mj mk b">table</code>是一个空列表。</p><pre class="kv kw kx ky gu nx mk ny nz aw oa bi"><span id="6e11" class="ob mm iw mk b gz oc od l oe of">table = []<br/>basic_url = "<a class="ae lk" href="https://www.brocardi.it" rel="noopener ugc nofollow" target="_blank">https://www.brocardi.it</a>"</span></pre><p id="12e2" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在，我导入所有的<code class="fe mh mi mj mk b">selenium</code>驱动程序和<code class="fe mh mi mj mk b">NoSuchElementException</code>异常，它们将用于在执行内部循环时捕捉某种异常。我还导入了<code class="fe mh mi mj mk b">pandas</code>库。</p><pre class="kv kw kx ky gu nx mk ny nz aw oa bi"><span id="2a45" class="ob mm iw mk b gz oc od l oe of">from selenium import webdriver<br/>from selenium.webdriver.chrome.options import Options  <br/>from selenium.common.exceptions import NoSuchElementException</span></pre><h1 id="434f" class="ml mm iw bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated">嵌套循环</h1><p id="902f" class="pw-post-body-paragraph ll lm iw ln b lo nd kg lq lr ne kj lt lu nf lw lx ly ng ma mb mc nh me mf mg ip bi translated">我通过从<code class="fe mh mi mj mk b">a</code>到<code class="fe mh mi mj mk b">z</code>的<code class="fe mh mi mj mk b">for</code>来实现外部循环。在外部循环的每一步，我都构建url。然后我通过一个<code class="fe mh mi mj mk b">while</code>实现内部无限循环。在内部循环中，我构建了一个执行抓取的驱动程序。我开发了一个<code class="fe mh mi mj mk b">Chrome()</code> webdriver，它接收<code class="fe mh mi mj mk b">--headless</code>和<code class="fe mh mi mj mk b">--lang=it</code>选项作为输入。第一个选项指定不打开浏览器，而第二个选项指定浏览器的语言。</p><p id="2e14" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">一旦连接上，我搜索两个元素:</p><ul class=""><li id="5e4f" class="nj nk iw ln b lo lp lr ls lu nl ly nm mc nn mg no np nq nr bi translated">包含术语列表的元素</li><li id="fda8" class="nj nk iw ln b lo ns lr nt lu nu ly nv mc nw mg no np nq nr bi translated">包含下一页链接的元素。</li></ul><p id="ad05" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">这两个元素都依赖于HTML页面的结构。我利用函数<code class="fe mh mi mj mk b">find_elements_by_xpath()</code>来搜索特定的XPath。</p><p id="4e50" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">如前所述，内部循环是一个无限循环，中断条件由一个<code class="fe mh mi mj mk b">NoSuchElementException</code>给出，当没有下一页时抛出。术语列表存储在<code class="fe mh mi mj mk b">table</code>变量中。</p><pre class="kv kw kx ky gu nx mk ny nz aw oa bi"><span id="2b89" class="ob mm iw mk b gz oc od l oe of">for letter in letters:<br/>    <br/>    url = basic_url + '/dizionario/' + letter + '/'<br/>    while True:<br/>        try:<br/>            print(url)<br/>            options = Options()  <br/>            options.add_argument("--headless") <br/>            options.add_argument("--lang=it");<br/>            driver = webdriver.Chrome(options=options)</span><span id="a1a3" class="ob mm iw mk b gz og od l oe of">driver.get(url)</span><span id="b959" class="ob mm iw mk b gz og od l oe of"># get the list of terms<br/>            xpath = '//ul[<a class="ae lk" href="http://twitter.com/class" rel="noopener ugc nofollow" target="_blank">@class</a>="terms-list"]'<br/>            words = driver.find_element_by_xpath(xpath).text<br/>            table.extend(words.split('\n'))<br/>            <br/>            # get the next page<br/>            xpath = '//a[<a class="ae lk" href="http://twitter.com/class" rel="noopener ugc nofollow" target="_blank">@class</a>="next"]'<br/>            url = driver.find_element_by_xpath(xpath).get_attribute('href')<br/>            <br/>            driver.close()<br/>        <br/>        except NoSuchElementException:<br/>            break</span></pre><h1 id="7fcb" class="ml mm iw bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated">保存结果</h1><p id="9725" class="pw-post-body-paragraph ll lm iw ln b lo nd kg lq lr ne kj lt lu nf lw lx ly ng ma mb mc nh me mf mg ip bi translated">变量<code class="fe mh mi mj mk b">table</code>包含所有术语的列表。我可以将它存储到CSV文件中。这可以通过构建一个<code class="fe mh mi mj mk b">pandas</code>数据框架来实现。</p><pre class="kv kw kx ky gu nx mk ny nz aw oa bi"><span id="c550" class="ob mm iw mk b gz oc od l oe of">import pandas as pd</span><span id="8a1b" class="ob mm iw mk b gz og od l oe of">df = pd.DataFrame(table, columns=['word'])<br/>df['word'] = df['word'].str.lower()<br/>df.to_csv('outputs/glossary.csv')</span></pre><h1 id="1ff2" class="ml mm iw bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated">摘要</h1><p id="fed8" class="pw-post-body-paragraph ll lm iw ln b lo nd kg lq lr ne kj lt lu nf lw lx ly ng ma mb mc nh me mf mg ip bi translated">在本教程中，我演示了如何安装和使用Python <code class="fe mh mi mj mk b">selenium</code>从嵌套的HTML页面中提取数据。</p><p id="e01d" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在库安装和配置之后，需要三个步骤:</p><ul class=""><li id="3010" class="nj nk iw ln b lo lp lr ls lu nl ly nm mc nn mg no np nq nr bi translated">识别网站的结构</li><li id="56fc" class="nj nk iw ln b lo ns lr nt lu nu ly nv mc nw mg no np nq nr bi translated">实现两级循环，提取数据和到下一页的链接</li><li id="d5a9" class="nj nk iw ln b lo ns lr nt lu nu ly nv mc nw mg no np nq nr bi translated">将数据保存到<code class="fe mh mi mj mk b">pandas</code>数据帧中。</li></ul><p id="230a" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">如果你想了解我的研究和其他活动的最新情况，你可以在<a class="ae lk" href="https://twitter.com/alod83" rel="noopener ugc nofollow" target="_blank"> Twitter </a>、<a class="ae lk" href="https://www.youtube.com/channel/UC4O8-FtQqGIsgDW_ytXIWOg?view_as=subscriber" rel="noopener ugc nofollow" target="_blank"> Youtube </a>和<a class="ae lk" href="https://github.com/alod83" rel="noopener ugc nofollow" target="_blank"> Github </a>上关注我。</p><h1 id="196e" class="ml mm iw bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated">相关文章</h1><div class="oh oi gq gs oj ok"><a rel="noopener follow" target="_blank" href="/how-to-extract-tables-from-pdf-using-python-pandas-and-tabula-py-c65e43bd754"><div class="ol ab fp"><div class="om ab on cl cj oo"><h2 class="bd jg gz z fq op fs ft oq fv fx jf bi translated">如何使用Python熊猫和tabula-py从PDF中提取表格</h2><div class="or l"><h3 class="bd b gz z fq op fs ft oq fv fx dk translated">一个从PDF中提取重复表格的快捷脚本</h3></div><div class="os l"><p class="bd b dl z fq op fs ft oq fv fx dk translated">towardsdatascience.com</p></div></div><div class="ot l"><div class="ou l ov ow ox ot oy le ok"/></div></div></a></div><div class="oh oi gq gs oj ok"><a rel="noopener follow" target="_blank" href="/how-to-build-a-dataset-from-twitter-using-python-tweepy-861bdbc16fa5"><div class="ol ab fp"><div class="om ab on cl cj oo"><h2 class="bd jg gz z fq op fs ft oq fv fx jf bi translated">如何使用Python tweepy从Twitter构建数据集</h2><div class="or l"><h3 class="bd b gz z fq op fs ft oq fv fx dk translated">一个快速教程和一个现成的脚本来提取推文</h3></div><div class="os l"><p class="bd b dl z fq op fs ft oq fv fx dk translated">towardsdatascience.com</p></div></div><div class="ot l"><div class="oz l ov ow ox ot oy le ok"/></div></div></a></div></div></div>    
</body>
</html>