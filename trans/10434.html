<html>
<head>
<title>Inductive learning for product assortment graph completion</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">产品分类图完成的归纳学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/inductive-learning-for-product-assortment-graph-completion-a44306da5c42?source=collection_archive---------47-----------------------#2021-10-04">https://towardsdatascience.com/inductive-learning-for-product-assortment-graph-completion-a44306da5c42?source=collection_archive---------47-----------------------#2021-10-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="d64b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇博客文章是在2021年ESANN大会上提交的一篇论文的简短摘要，这篇论文是由人工智能研究所和比萨大学合作完成的。如果你觉得这很有趣，并想阅读全文，这里的<a class="ae kl" href="https://www.esann.org/sites/default/files/proceedings/2021/ES2021-73.pdf" rel="noopener ugc nofollow" target="_blank"/>是会议记录中文章的链接，这里的<a class="ae kl" href="https://www.sciencedirect.com/science/article/pii/S0925231222007822?dgcid=coauthor" rel="noopener ugc nofollow" target="_blank"/>是原始论文的扩展期刊版本。</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h1 id="eceb" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">介绍</h1><p id="d478" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">全球零售商拥有包含数十万种产品的分类，这些产品可以通过几种类型的关系联系在一起，如风格兼容、“一起购买”、“一起观看”等。图是分类的自然表示，其中产品是节点，关系是边。像样式兼容性这样的关系通常是通过手工过程产生的，因此不会均匀地覆盖整个图形。我们建议使用归纳学习来增强时尚分类的图形编码风格兼容性，利用包含文本描述和视觉数据的丰富节点信息。然后，我们展示了所提出的图增强如何在对图稀疏性影响较小的情况下显著提高直推任务的性能。</p><h1 id="74c6" class="kt ku iq bd kv kw lw ky kz la lx lc ld le ly lg lh li lz lk ll lm ma lo lp lq bi translated">方法学</h1><p id="877d" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">图形神经网络是处理图形数据的最新技术[1]。我们建议使用归纳学习来增强时尚分类的图形编码风格兼容性，利用包含文本描述和视觉数据的丰富节点信息。</p><p id="73a8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与假设所有节点在训练时间都存在的直推式链路预测相反，感应式链路预测旨在预测新的、未观察到的节点的链路。然而，感应链路预测通常在现有节点上获得较低的性能。我们提出的方法是使用归纳链接预测来丰富新链接的图形，然后在新图形上训练直推模型，以最大限度地提高链接预测性能，这样可以两全其美，如图1所示。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mb"><img src="../Images/a399abd29c1a2db494f0254c553fd0e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ag098WFjVszL3nttESO-6Q.png"/></div></div><p class="mn mo gj gh gi mp mq bd b be z dk translated"><strong class="bd mr">图1: </strong>我们的方法由三个阶段组成:原始图上的归纳学习、图的丰富化和丰富图上的直推学习。</p></figure><p id="810b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于归纳学习(步骤1)，我们考虑DEAL [2]，一种利用两个编码器的架构，一个面向属性的编码器编码节点特征，一个面向结构的编码器编码图的链接，以及一个对齐机制来对齐两个嵌入向量之间的最大相似性。在图丰富阶段(步骤2)，如果满足两个条件，我们向图中添加新的链接:根据归纳链接预测的存在概率高于阈值，并且节点度低于预定值，以避免添加太多链接。最后，执行直推式链接预测(步骤3)以学习丰富图的结构，其中风格兼容关系已经传播到整个图。</p><h1 id="ad51" class="kt ku iq bd kv kw lw ky kz la lx lc ld le ly lg lh li lz lk ll lm ma lo lp lq bi translated">实验</h1><p id="f22b" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">我们的算法在两个专有的H&amp;M数据集上进行验证，即包含男装和女装时尚项目的男性和女性，以及一个公共数据集，来自亚马逊的计算机数据集[3]。表1中报告了该图的性质，以及对该图的归纳丰富结果的预期。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi ms"><img src="../Images/6219bc40b78bc256f44ec39d7927ad86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CJEBAo4IMsrXYLrLosHmwA.png"/></div></div><p class="mn mo gj gh gi mp mq bd b be z dk translated"><strong class="bd mr">表1: </strong>本文使用的数据集，其中*表示丰富后的图形。</p></figure><h1 id="30df" class="kt ku iq bd kv kw lw ky kz la lx lc ld le ly lg lh li lz lk ll lm ma lo lp lq bi translated">结果和结论</h1><p id="f2af" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">在表2中，我们可以看到，对于所考虑的所有三种不同类型的GNN，即SAGE[4]、GCN [5]和GAT[6]，丰富的图如何显著提高链路预测性能。这种性能上的改进可以解释为丰富过程有效地完成了原始图，使模式更规则、更通用，因此更容易学习。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mt"><img src="../Images/489980c0d379a94a89d56df917954be9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QAW3dz2dwHCBo44llLo3IA.png"/></div></div><p class="mn mo gj gh gi mp mq bd b be z dk translated"><strong class="bd mr">表2: </strong>数据集链接三种众所周知的算法的预测精度，其中*表示富集后的图。</p></figure><h1 id="945f" class="kt ku iq bd kv kw lw ky kz la lx lc ld le ly lg lh li lz lk ll lm ma lo lp lq bi translated">参考</h1><p id="7ebe" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">[1]d . BAC丘、F. Errica、A. Micheli和M. Podda。图形深度学习的温和介绍。神经网络，2020。</p><p id="51cd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[2]郝耀东、曹晓东、方耀东、谢晓东和王。只有属性信息的节点的归纳链接预测。IJCAI，2020。</p><p id="2ad3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[3] J .麦考利、c .塔吉特、q .史和a .范登亨格尔。基于图像的风格和替代品建议。SIGIR，2015年。</p><p id="27db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[4]汉密尔顿、应和莱斯科维奇。大型图上的归纳表示学习。NeurIPS，2017。</p><p id="baa1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[5]基普夫和韦林。基于图卷积网络的半监督分类。，ICLR 2017。</p><p id="b00a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[6]佩利科维奇、库库鲁勒、卡萨诺瓦、罗梅罗、莉雅和本吉奥。图形注意力网络。，ICLR 2018。</p></div></div>    
</body>
</html>