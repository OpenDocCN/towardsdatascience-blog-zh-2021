<html>
<head>
<title>Time to Choose TensorFlow Data over ImageDataGenerator</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">是时候选择TensorFlow数据而不是ImageDataGenerator了</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/time-to-choose-tensorflow-data-over-imagedatagenerator-215e594f2435?source=collection_archive---------14-----------------------#2021-08-30">https://towardsdatascience.com/time-to-choose-tensorflow-data-over-imagedatagenerator-215e594f2435?source=collection_archive---------14-----------------------#2021-08-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4643" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用tf.data构建更好更快的图像管道</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/90ea4a0d6efea2a9916bc852fbe18e3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wjQbWx3Tvz-I90EJkof-eg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">建一条像这条河一样干净的数据管道(来源:<a class="ae ky" href="https://www.flickr.com/photos/suvob/51391307017/in/dateposted-public/" rel="noopener ugc nofollow" target="_blank">作者</a>)</p></figure><p id="f373" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在训练一个神经网络时，使用<code class="fe lv lw lx ly b">ImageDataGenerator</code>类生成具有实时数据扩充的批量张量图像数据是很常见的。然而，在这篇文章中，我将讨论<code class="fe lv lw lx ly b"><a class="ae ky" href="https://www.tensorflow.org/guide/data" rel="noopener ugc nofollow" target="_blank">tf.data </a></code> <a class="ae ky" href="https://www.tensorflow.org/guide/data" rel="noopener ugc nofollow" target="_blank"> API </a>，使用它我们可以用可重用的片段构建一个更快的输入数据管道。正如TensorFlow文档中提到的—</p><blockquote class="lz ma mb"><p id="e1fb" class="kz la mc lb b lc ld ju le lf lg jx lh md lj lk ll me ln lo lp mf lr ls lt lu im bi translated"><code class="fe lv lw lx ly b"><a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/data" rel="noopener ugc nofollow" target="_blank">tf.data</a></code> API使得处理大量数据、读取不同的数据格式以及执行复杂的转换成为可能。</p></blockquote><p id="4a0e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章将简短明了，包括一个使用<code class="fe lv lw lx ly b">tf.data</code>的工作示例；所以，让我们毫不迟疑地开始吧。这里使用的代码可以在我的笔记本中找到，链接在帖子的末尾。</p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h2 id="fcfc" class="mn mo it bd mp mq mr dn ms mt mu dp mv li mw mx my lm mz na nb lq nc nd ne nf bi translated">tf.data.Datset:</h2><p id="ccca" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">我们将在这里用来构建高效管道的tf.data的主要组件是<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank"> tf.data.Dataset API </a>。它可用于以下工作—</p><ol class=""><li id="01db" class="nl nm it lb b lc ld lf lg li nn lm no lq np lu nq nr ns nt bi translated">从输入数据创建“数据集”对象。</li><li id="0f4e" class="nl nm it lb b lc nu lf nv li nw lm nx lq ny lu nq nr ns nt bi translated">应用数据集转换进行预处理。</li><li id="f346" class="nl nm it lb b lc nu lf nv li nw lm nx lq ny lu nq nr ns nt bi translated">以流的方式迭代数据集并处理元素。</li></ol><p id="7f38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将通过一个例子来理解和实现<code class="fe lv lw lx ly b">tf.data</code>的每一个步骤。首先，我们将使用<code class="fe lv lw lx ly b">from_tensor_slices</code>方法创建“数据集”对象。</p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h2 id="64bc" class="mn mo it bd mp mq mr dn ms mt mu dp mv li mw mx my lm mz na nb lq nc nd ne nf bi translated">什么是<code class="fe lv lw lx ly b"><strong class="ak">from_tensor_slices ?</strong></code></h2><p id="b2ff" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">为了理解<code class="fe lv lw lx ly b"><a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices" rel="noopener ugc nofollow" target="_blank">from_tensor_slices</a></code>方法是如何工作的，让我们从加载<a class="ae ky" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR-10数据</a>开始。</p><pre class="kj kk kl km gt nz ly oa ob aw oc bi"><span id="2357" class="mn mo it ly b gy od oe l of og">import matplotlib.pyplot as plt</span><span id="5e80" class="mn mo it ly b gy oh oe l of og">import numpy as np<br/>import time</span><span id="7193" class="mn mo it ly b gy oh oe l of og">import tensorflow as tf<br/>from tensorflow.keras.datasets import cifar10</span><span id="b1bb" class="mn mo it ly b gy oh oe l of og">(x_train, y_train), (x_test, y_test) = cifar10.load_data()</span><span id="9b4e" class="mn mo it ly b gy oh oe l of og">print ('check shapes: ', x_train.shape, y_train.shape, x_test.shape, y_test.shape)</span><span id="7104" class="mn mo it ly b gy oh oe l of og">&gt;&gt;&gt; check shapes:  (50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)</span></pre><p id="1697" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们通过使用<code class="fe lv lw lx ly b"><a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical" rel="noopener ugc nofollow" target="_blank">to_categorical</a></code>将标签转换为分类表示</p><pre class="kj kk kl km gt nz ly oa ob aw oc bi"><span id="e0fd" class="mn mo it ly b gy od oe l of og">train_lab_categorical = tf.keras.utils.to_categorical(y_train, num_classes=10, dtype=’uint8')</span><span id="0f5d" class="mn mo it ly b gy oh oe l of og">test_lab_categorical = tf.keras.utils.to_categorical(y_test, num_classes=10, dtype=’uint8')</span><span id="b359" class="mn mo it ly b gy oh oe l of og">from sklearn.model_selection import train_test_split</span><span id="bbac" class="mn mo it ly b gy oh oe l of og">train_im, valid_im, train_lab, valid_lab = train_test_split(x_train, train_lab_categorical, test_size=0.20, stratify=train_lab_categorical,random_state=40, shuffle = True)</span><span id="7e89" class="mn mo it ly b gy oh oe l of og">print ("validation labels shape: ", valid_lab.shape)</span><span id="31ca" class="mn mo it ly b gy oh oe l of og">&gt;&gt;&gt; validation labels shape:  (10000, 10)</span></pre><p id="a814" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在将结合图像和标签来创建“数据集”对象，如下所示—</p><pre class="kj kk kl km gt nz ly oa ob aw oc bi"><span id="b75f" class="mn mo it ly b gy od oe l of og">training_data = tf.data.Dataset.from_tensor_slices((train_im, train_lab))</span><span id="c73c" class="mn mo it ly b gy oh oe l of og">validation_data = tf.data.Dataset.from_tensor_slices((valid_im, valid_lab))</span><span id="0c52" class="mn mo it ly b gy oh oe l of og">test_data = tf.data.Dataset.from_tensor_slices((x_test, test_lab_categorical))</span><span id="f072" class="mn mo it ly b gy oh oe l of og">print (‘check types; '\n' ‘, type(training_data)) </span><span id="4e3f" class="mn mo it ly b gy oh oe l of og">&gt;&gt;&gt; check types;  <br/>&lt;class 'tensorflow.python.data.ops.dataset_ops.TensorSliceDataset'&gt;</span></pre><p id="a123" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从<code class="fe lv lw lx ly b">type</code>我们不能得到太多，但让我们试着弄清楚这些“数据集”对象是什么，以及我们如何使用它们。首先，我们使用<code class="fe lv lw lx ly b">element.spec()</code>检查这个数据集的一个元素的类型规范。</p><pre class="kj kk kl km gt nz ly oa ob aw oc bi"><span id="5898" class="mn mo it ly b gy od oe l of og">print (training_data.element_spec)</span><span id="0b1e" class="mn mo it ly b gy oh oe l of og">&gt;&gt;&gt; (TensorSpec(shape=(32, 32, 3), dtype=tf.float64, name=None), TensorSpec(shape=(10,), dtype=tf.uint8, name=None))</span></pre><p id="ec60" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这样更好理解。我们看到<code class="fe lv lw lx ly b">from_tensor_slices</code>保持了输入张量的结构。该数据集的一个元素由图像(形状:32，32，3)和相应的标签(形状:10)组成。我们的下一个问题应该是如何访问“数据集”对象中的元素？我们可以创建一个迭代器对象，并使用下面的<code class="fe lv lw lx ly b">next</code>来访问元素</p><pre class="kj kk kl km gt nz ly oa ob aw oc bi"><span id="3d15" class="mn mo it ly b gy od oe l of og">train_iter_im, train_iter_label = next(iter(training_data))</span><span id="aab0" class="mn mo it ly b gy oh oe l of og">print (train_iter_im.numpy().shape, train_iter_label.numpy().shape)</span><span id="2e9a" class="mn mo it ly b gy oh oe l of og">&gt;&gt;&gt; (32, 32, 3) (10,)</span></pre><p id="4712" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">代替<code class="fe lv lw lx ly b">next</code>、<code class="fe lv lw lx ly b">iter</code>和<code class="fe lv lw lx ly b">.numpy()</code>，我们可以返回一个迭代器，它将数据集的所有元素转换成numpy数组，如下所示</p><pre class="kj kk kl km gt nz ly oa ob aw oc bi"><span id="a341" class="mn mo it ly b gy od oe l of og">train_iter_im1, train_iter_label1 = next(training_data.as_numpy_iterator())</span><span id="8604" class="mn mo it ly b gy oh oe l of og">print (train_iter_im1.shape, train_iter_label1.shape)</span><span id="00e6" class="mn mo it ly b gy oh oe l of og">&gt;&gt;&gt; (32, 32, 3) (10,)</span></pre><p id="f228" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们将一些训练图像和相应的标签可视化如下—</p><pre class="kj kk kl km gt nz ly oa ob aw oc bi"><span id="c483" class="mn mo it ly b gy od oe l of og">class_types = [‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,</span><span id="f127" class="mn mo it ly b gy oh oe l of og">‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’] # from cifar-10 website</span><span id="0fbc" class="mn mo it ly b gy oh oe l of og">check_list = list(training_data.as_numpy_iterator())</span><span id="b023" class="mn mo it ly b gy oh oe l of og"><br/>fig = plt.figure(figsize=(10,10))</span><span id="baa8" class="mn mo it ly b gy oh oe l of og">for i in range(12):</span><span id="8de1" class="mn mo it ly b gy oh oe l of og">  plt.subplot(4,3,i+1)</span><span id="248a" class="mn mo it ly b gy oh oe l of og">  plt.xticks([])</span><span id="bf7d" class="mn mo it ly b gy oh oe l of og">  plt.yticks([])</span><span id="03e2" class="mn mo it ly b gy oh oe l of og">  plt.grid(False)</span><span id="7eb2" class="mn mo it ly b gy oh oe l of og">  plt.imshow(check_list[i][0], cmap='gray')</span><span id="e177" class="mn mo it ly b gy oh oe l of og">  plt.xlabel(class_types [np.argmax(check_list[i][1])], fontsize=13)</span><span id="04d7" class="mn mo it ly b gy oh oe l of og">plt.tight_layout()</span><span id="09d8" class="mn mo it ly b gy oh oe l of og">plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/297b66d83fbed5706a528dc71339b5f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*uoNvJMuXUenI1B9PXK_d5Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用上述代码的CIFAR-10示例图像。(来源:<a class="ae ky" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR-10数据</a>)</p></figure></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h2 id="75f0" class="mn mo it bd mp mq mr dn ms mt mu dp mv li mw mx my lm mz na nb lq nc nd ne nf bi translated">tf.data相比ImageDataGenerator有多快？</h2><p id="18bf" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">使用tf.data生成训练和验证批比ImageDataGenerator快得多。我们来对比一下；首先，我们使用ImageDataGenerator，没有使用任何增强功能—</p><pre class="kj kk kl km gt nz ly oa ob aw oc bi"><span id="4e57" class="mn mo it ly b gy od oe l of og">from tensorflow.keras.preprocessing.image import ImageDataGenerator</span><span id="9ff7" class="mn mo it ly b gy oh oe l of og">st1 = time.time()</span><span id="7750" class="mn mo it ly b gy oh oe l of og">train_datagen = ImageDataGenerator().flow(x=train_im, y=train_lab, batch_size=128, shuffle=True,)</span><span id="e006" class="mn mo it ly b gy oh oe l of og">et1 = time.time()</span><span id="9abc" class="mn mo it ly b gy oh oe l of og">print (‘time taken: ‘, et1-st1)</span><span id="8190" class="mn mo it ly b gy oh oe l of og">&gt;&gt;&gt; time taken:  0.2080059051513672</span></pre><p id="88cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们将使用tf.data —</p><pre class="kj kk kl km gt nz ly oa ob aw oc bi"><span id="3914" class="mn mo it ly b gy od oe l of og">autotune = tf.data.AUTOTUNE</span><span id="4a14" class="mn mo it ly b gy oh oe l of og">st2 = time.time()</span><span id="7962" class="mn mo it ly b gy oh oe l of og">train_datagen_tfdata = training_data.shuffle(buffer_size=40000).batch(128).prefetch(buffer_size=autotune)</span><span id="fd0b" class="mn mo it ly b gy oh oe l of og">et2 = time.time()</span><span id="45b5" class="mn mo it ly b gy oh oe l of og">print (‘time taken: ‘, et2-st2) </span><span id="5e00" class="mn mo it ly b gy oh oe l of og">&gt;&gt;&gt; time taken:  0.006140947341918945</span></pre><p id="a77a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此<strong class="lb iu"> tf.data比ImageDataGenerator快大约34倍，其中一个主要原因是一种称为“预取”的技术</strong>。我们在通过<code class="fe lv lw lx ly b">prefetch(buffer_size=tf.data.AUTOTUNE)</code>使用tf.data生成批处理时应用这个预取。在<a class="ae ky" href="https://www.tensorflow.org/guide/data_performance" rel="noopener ugc nofollow" target="_blank"> TensorFlow文档</a>中，给出了一系列示例，并给出了很好的解释，但在此简要说明发生了什么。数据管道可以被认为是“生产者”(生成批次)和“消费者”(用于训练神经网络的批次)的组合，只要有机会将“生产者”的工作与“消费者”的工作重叠，预取转换就会带来好处。</p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h2 id="32b5" class="mn mo it bd mp mq mr dn ms mt mu dp mv li mw mx my lm mz na nb lq nc nd ne nf bi translated">用tf.data扩充数据</h2><p id="29fb" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">由于我们没有使用ImageDataGenerator，我们将使用<a class="ae ky" href="https://keras.io/guides/preprocessing_layers/" rel="noopener ugc nofollow" target="_blank"> Keras预处理层</a>来增强图像。除了一般的增强，我们还可以重新缩放图像(像素值在0和1之间)，这是解决手头问题的必要步骤。这个想法是——我们将使用<code class="fe lv lw lx ly b">keras.sequential </code>,就好像我们正在建立一个深度conv网络，而不是卷积或池层，我们将使用增强层。最后，我们将可视化一个增强图像的例子，下面是代码块。更多示例在<a class="ae ky" href="https://www.tensorflow.org/tutorials/images/data_augmentation#augment_a_dataset_and_train_a_model_with_it" rel="noopener ugc nofollow" target="_blank"> TensorFlow文档</a>中给出。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oj ok l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/1c17e640af8363206cb90aae0e2dd2b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*X5axk09aPweF6w8nmQsZiA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用Keras序列的数据扩充</p></figure></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h2 id="6d82" class="mn mo it bd mp mq mr dn ms mt mu dp mv li mw mx my lm mz na nb lq nc nd ne nf bi translated">用tf.data构建深度神经网络模型:</h2><p id="c568" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">我们将使用<code class="fe lv lw lx ly b">Sequential</code>中的增强层作为我们模型中的一个层。<strong class="lb iu">这也有助于更快地训练模型，因为数据扩充现在正在GPU中进行，而不是在CPU中进行</strong>。此外，为了保持简单，我们将使用预先训练的ResNet和ImageNet数据，而不是从头开始构建模型。我在另一篇文章<a class="ae ky" rel="noopener" target="_blank" href="/understand-and-implement-resnet-50-with-tensorflow-2-0-1190b9b52691">中描述了从零开始构建ResNet。对于像CIFAR-10这样的多类问题，我们的损失函数将是分类交叉熵。下面的代码块将所有这些结合在一起。让我们看看—</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="ba67" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过60个时期，我获得了如下的训练和验证图—</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/fa15c228ddac6834fd738a3d574862a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*YibLtzsxStTR6zPqidKXVg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">训练和验证曲线:损失(左)和准确性(右)。(来源:作者)</p></figure><p id="1629" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还可以绘制测试数据的混淆矩阵，下面是图表—</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/90c75ea8f5e9d1d229c25a5f56fcffc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*SrGhfmc0-F1yfbsNmCEAcw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试数据的混淆矩阵(来源:作者)</p></figure></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><p id="fc57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们通过一个例子来说明如何使用tf.data来创建一个更快速、清晰和可重用的管道，对于现实世界中的模型部署，这通常是比ImageDataGenerator更好的选择。ImageDataGenerator是一个很好的入门选项，但是，tf.data可以根据硬件/实验设计同时自动调优生成批处理和训练的过程，整个过程要快得多。</p><p id="8183" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保持坚强，干杯！！</p><p id="0207" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里使用的代码来自我的笔记本。</p><p id="8d9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">CIFAR-10数据来源和引用:</p><p id="12bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[1]“从微小图像中学习多层特征”:Alex Krizhevsky2009.<a class="ae ky" href="https://www.cs.toronto.edu/%7Ekriz/cifar.html" rel="noopener ugc nofollow" target="_blank">CIFAR-10的来源</a>。</p></div></div>    
</body>
</html>