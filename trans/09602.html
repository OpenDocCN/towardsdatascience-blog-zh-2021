<html>
<head>
<title>A Step-by-Step Guide in detecting causal relationships using Bayesian Structure Learning in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python中的贝叶斯结构学习检测因果关系的分步指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-step-by-step-guide-in-detecting-causal-relationships-using-bayesian-structure-learning-in-python-c20c6b31cee5?source=collection_archive---------0-----------------------#2021-09-07">https://towardsdatascience.com/a-step-by-step-guide-in-detecting-causal-relationships-using-bayesian-structure-learning-in-python-c20c6b31cee5?source=collection_archive---------0-----------------------#2021-09-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="661b" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="cc99" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">有效确定变量间因果关系的入门指南。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/05c22e55bbd09f8c7692e80e1738e65f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zqTKQZwWteFEbb5FfpVVaQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><em class="lh">照片由</em><a class="ae li" href="https://unsplash.com/@grstocks?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">T5】GR股票 </a> <em class="lh">上</em> <a class="ae li" href="https://unsplash.com/s/photos/strategic?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> <em class="lh">下</em> </a></p></figure><p id="81d2" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">确定变量之间的因果关系可能是一个具有挑战性的步骤，但它对于战略行动非常重要。我将从<strong class="ll jd"> <em class="mf">贝叶斯概率</em> </strong>方面总结<strong class="ll jd"> <em class="mf">因果模型</em> </strong>的概念，后面是一个动手教程，利用<em class="mf">贝叶斯结构学习</em>检测<em class="mf">因果</em>关系。我将使用<em class="mf">喷洒器数据集</em>从概念上解释如何使用Python库<a class="ae li" href="https://erdogant.github.io/bnlearn" rel="noopener ugc nofollow" target="_blank"> <em class="mf"> bnlearn </em> </a> <em class="mf">学习结构。</em></p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><p id="15bb" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated"><em class="mf">如果你觉得这篇文章很有帮助，可以使用我的</em> <a class="ae li" href="https://medium.com/@erdogant/membership" rel="noopener"> <em class="mf">推荐链接</em> </a> <em class="mf">继续无限制学习，并注册成为中级会员。另外，</em> <a class="ae li" href="http://erdogant.medium.com" rel="noopener"> <em class="mf">关注我</em> </a> <em class="mf">关注我的最新内容！</em></p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="b681" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">背景</h1><p id="df0b" class="pw-post-body-paragraph lj lk it ll b lm nf kd lo lp ng kg lr ls nh lu lv lw ni ly lz ma nj mc md me im bi translated">在疾病预测、推荐系统、自然语言处理等许多领域，机器学习技术的使用已经成为获得有用见解和进行预测的标准工具包。虽然可以实现良好的性能，但提取与目标变量的因果关系并不简单。换句话说:<em class="mf">哪些变量对目标变量有直接的因果作用？</em>这些洞察对于确定<em class="mf">得出结论的驱动因素</em>非常重要，因此可以采取战略行动。机器学习的一个分支是贝叶斯概率图形模型，也称为贝叶斯网络(BN)，可用于确定这些因果因素。</p><p id="a95c" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在我们进入因果模型的技术细节之前，让我们重温一些术语。术语“<em class="mf">相关性</em>”和“<em class="mf">关联性</em>”经常互换使用。但我们都知道，相关或关联并不是因果关系。或者换句话说，观察到的两个变量之间的关系并不一定意味着一个导致另一个。从技术上讲，相关性指的是两个变量之间的线性关系，而关联性指的是两个(或更多)变量之间的任何关系。另一方面，因果关系意味着一个变量(通常称为预测变量或自变量)引起另一个变量(通常称为结果变量或因变量)[1]。在接下来的两节中，我将通过示例简要描述<em class="mf">关联</em>和<em class="mf">关联</em>。</p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="7414" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">相互关系</h1><p id="22e2" class="pw-post-body-paragraph lj lk it ll b lm nf kd lo lp ng kg lr ls nh lu lv lw ni ly lz ma nj mc md me im bi translated">皮尔逊相关是最常用的相关系数。这是如此普遍，它经常被用作相关的同义词。强度由<em class="mf"> r </em>表示，并在从-1到1的标准化范围内测量样本中线性关系的强度。使用关联时有三种可能的结果:</p><ul class=""><li id="dca9" class="nk nl it ll b lm ln lp lq ls nm lw nn ma no me np nq nr ns bi translated">正相关:两个变量之间的关系，其中两个变量的运动方向相同</li><li id="57c7" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated">负相关:两个变量之间的关系，其中一个变量的增加与另一个变量的减少相关</li><li id="b6c1" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated">无相关性:两个变量之间没有关系。</li></ul><p id="f81e" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">图1 展示了一个正相关的例子，在图1<em class="mf">中，我们看到了巧克力消费量与每个国家诺贝尔奖获得者人数之间的关系【2】。</em></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ny"><img src="../Images/7f5575469dd1625b2fe72a10bc468129.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*to9vieKKHOpVB-bVJ2bMAA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图1:巧克力消费与诺贝尔奖得主之间的相关性</p></figure><p id="3fd7" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">该图显示，巧克力消费可能意味着诺贝尔奖获得者的增加。或者反过来说，诺贝尔奖获得者的增加同样可能导致巧克力消费量的增加。尽管相关性很强，但更有可能的是，社会经济地位或教育系统质量等未被观察到的变量可能会导致巧克力消费量和诺贝尔奖获得者人数的增加。或者换句话说，这种关系是否是因果关系还是个未知数[2]。这并不意味着相关性本身是无用的，它只是有一个不同的目的[3]。相关性本身并不意味着因果关系，因为统计关系并不唯一地约束因果关系。T15】</p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="3920" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">联想。</h1><p id="b7e0" class="pw-post-body-paragraph lj lk it ll b lm nf kd lo lp ng kg lr ls nh lu lv lw ni ly lz ma nj mc md me im bi translated">当我们谈到<em class="mf">关联</em>时，我们的意思是一个变量的某些值往往与另一个变量的某些值同时出现。从统计学的角度来看，有许多关联的测量方法(如卡方检验、Fisher精确检验、超几何检验等),通常用于一个或两个变量为序数或名义变量的情况。应该注意的是，<em class="mf">相关性</em>是一个技术术语，而术语<em class="mf">关联</em>不是，因此，在统计学上并不总是有一致的含义。这意味着陈述你正在使用的术语的含义总是一个好习惯。关于关联的更多信息可以在这个博客[4]中找到，并且阅读这个关于如何<a class="ae li" rel="noopener" target="_blank" href="/explore-and-understand-your-data-with-a-network-of-significant-associations-9a03cf79d254">通过一个重要关联的网络</a> [5】探索和理解你的数据的博客。</p><p id="77cb" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">为了举例，我将使用<em class="mf">超几何测试</em>来演示两个变量是否与使用Titanic数据集的<em class="mf">相关联。泰坦尼克号数据集在许多机器学习例子中使用，众所周知，<em class="mf">性别</em>状态(女性)是<em class="mf">存活率</em>的良好预测器。我来演示一下如何计算<em class="mf">幸存</em>和<em class="mf">女性</em>之间的<em class="mf">关联</em>。</em></p><p id="736d" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">首先安装<a class="ae li" href="https://erdogant.github.io/bnlearn" rel="noopener ugc nofollow" target="_blank"><em class="mf">bnlearn</em></a><em class="mf"/>库，只加载泰坦尼克数据集。</p><pre class="ks kt ku kv gt nz oa ob oc aw od bi"><span id="5740" class="oe mo it oa b gy of og l oh oi">pip install bnlearn</span></pre><p id="4d88" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">问:雌性存活的概率有多大？</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oj ok l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">存活与雌性之间的超几何检验</p></figure><blockquote class="ol om on"><p id="7e8f" class="lj lk mf ll b lm ln kd lo lp lq kg lr oo lt lu lv op lx ly lz oq mb mc md me im bi translated"><strong class="ll jd">无效假设</strong>:存活者与女性没有关系。</p></blockquote><p id="2a22" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">超几何检验使用超几何分布来衡量离散概率分布的统计显著性。在本例中，<strong class="ll jd"> <em class="mf"> N </em> </strong> <em class="mf">是总体大小(891)，</em> <strong class="ll jd"> <em class="mf"> K </em> </strong> <em class="mf">是总体中成功状态的数量(342)，</em> <strong class="ll jd"> <em class="mf"> n </em> </strong> <em class="mf">是样本大小/抽签数(314)，</em> <strong class="ll jd"> <em class="mf"> x </em> </strong> <em class="mf">是成功的数量</em></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi or"><img src="../Images/91dd06441373883e81a1d91564545bdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MMN9cdGoSk-ZxI-kodAdCg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">等式1:使用超几何检验来检验存活者和雌性之间的关联。</p></figure><p id="aa7e" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">我们可以在α= 0.05的情况下拒绝零假设，因此，我们可以谈论幸存者和女性之间的统计显著关联<em class="mf">。</em> <strong class="ll jd"> <em class="mf">重要的是，联想本身并不意味着因果关系。</em> </strong>我们需要区分<strong class="ll jd"> <em class="mf">边际</em> </strong>关联和<strong class="ll jd"> <em class="mf">条件</em> </strong>关联。后者是因果推理的关键组成部分。</p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="e6c6" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">因果关系。</h1><p id="43d5" class="pw-post-body-paragraph lj lk it ll b lm nf kd lo lp ng kg lr ls nh lu lv lw ni ly lz ma nj mc md me im bi translated">因果关系是指一个(独立)变量引起另一个(因变量)，由<em class="mf">赖兴巴赫(1956) </em>表述如下:</p><blockquote class="ol om on"><p id="2846" class="lj lk mf ll b lm ln kd lo lp lq kg lr oo lt lu lv op lx ly lz oq mb mc md me im bi translated">如果两个随机变量x和y在统计上是相关的(X/Y)，那么要么(a) X导致y，(b) Y导致x，要么(c)存在第三个变量z导致x和y。此外，给定z，即X⊥Y∣Z.，x和y变得独立</p></blockquote><p id="a0b2" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这个定义包含在贝叶斯图形模型中(<em class="mf">又称贝叶斯网络、贝叶斯信念网络、贝叶斯网、因果概率网络和影响图</em>)。同一个技术有很多名字。为了确定因果关系，我们可以使用贝叶斯网络(BN)。让我们从图表开始，可视化由<em class="mf">赖兴巴赫</em> (X，Y，Z)描述的三个变量之间的统计相关性(见图2)。节点对应于变量(X，Y，Z ),有向边(箭头)表示依赖关系或条件分布。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/dc4c15dc44a6703af9f2839b3df72f43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*QsJWsAGbEsVbQQR_GtAI1g.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图2:Dag编码条件独立性。(a，b，c)是等价类。(a，b) <em class="lh">级联，</em>(c)<em class="lh"/>、【d】是具有<em class="lh"> V型结构的特殊类。</em></p></figure><p id="e616" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">可以创建四个图形；<em class="mf">【a，b】Cascade、</em><em class="mf">【c】</em><em class="mf">Common parent和(d)</em><em class="mf">V-结构、</em>这些图构成了贝叶斯网络<em class="mf">的基础。</em></p><blockquote class="ot"><p id="ee12" class="ou ov it bd ow ox oy oz pa pb pc me dk translated">但是我们怎么能知道什么导致什么呢？</p></blockquote><p id="a2de" class="pw-post-body-paragraph lj lk it ll b lm pd kd lo lp pe kg lr ls pf lu lv lw pg ly lz ma ph mc md me im bi translated">确定因果关系的方向，从而确定哪个节点影响哪个节点的概念思想是通过保持一个节点不变，然后观察效果。举个例子，让我们看一下图2中的DAG (a ),它描述了Z是由X引起的，Y是由Z引起的，如果我们现在保持Z不变，如果这个模型是真的，Y应该不会有变化。每一个贝叶斯网络都可以用这四个图来描述，用<strong class="ll jd"><em class="mf"/></strong><em class="mf">(见下一节)</em>我们可以把各个部分粘在一起。</p><blockquote class="ot"><p id="e4a9" class="ou ov it bd ow ox oy oz pa pb pc me dk translated">贝叶斯网络是概率论和图论的完美结合。</p></blockquote><p id="8d0e" class="pw-post-body-paragraph lj lk it ll b lm pd kd lo lp pe kg lr ls pf lu lv lw pg ly lz ma ph mc md me im bi translated">应该注意，贝叶斯网络是一个<em class="mf">有向无环图</em> (DAG)，DAG是因果的。这意味着<em class="mf">图</em>中的边是<em class="mf">指向</em>的，并且没有(反馈)循环(<em class="mf">非循环</em>)。</p><h2 id="9578" class="oe mo it bd mp pi pj dn mt pk pl dp mx ls pm pn mz lw po pp nb ma pq pr nd iz bi translated"><strong class="ak">概率论</strong></h2><p id="f857" class="pw-post-body-paragraph lj lk it ll b lm nf kd lo lp ng kg lr ls nh lu lv lw ni ly lz ma nj mc md me im bi translated">概率论，或更具体的<em class="mf">贝叶斯定理或贝叶斯规则，</em>形成了贝叶斯网络的基础。贝叶斯规则用于更新模型信息，在数学上表述为以下等式:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ps"><img src="../Images/c12e641d969d27dd93d1a54df819e409.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Osv6euCMEGlDCjF-N56Ig.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">等式2:贝叶斯法则。</p></figure><p id="5898" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">该方程由四部分组成；<strong class="ll jd"> <em class="mf">后验概率</em> </strong>是给定x时Z发生的概率<strong class="ll jd"> <em class="mf">条件概率</em> </strong>或可能性是假设为真时证据出现的概率。这可以从数据中推导出来。我们的<strong class="ll jd"> <em class="mf">先验</em> </strong>信念是在观察证据之前假设的概率。这也可以从数据或领域知识中获得。最后，<strong class="ll jd"> <em class="mf">边际</em> </strong>概率描述了新证据在所有可能假设下需要计算的概率。如果你想阅读更多关于(因式分解)概率分布或贝叶斯网络联合分布的细节，试试这个博客[6]。</p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="1d48" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">贝叶斯结构学习估计DAG。</h1><p id="adcb" class="pw-post-body-paragraph lj lk it ll b lm nf kd lo lp ng kg lr ls nh lu lv lw ni ly lz ma nj mc md me im bi translated">通过结构学习，我们希望确定能够最好地捕捉数据集中变量之间的因果依赖关系的图的结构。换句话说:</p><blockquote class="ot"><p id="33f0" class="ou ov it bd ow ox oy oz pa pb pc me dk translated">最符合数据的DAG是什么？</p></blockquote><p id="0ef7" class="pw-post-body-paragraph lj lk it ll b lm pd kd lo lp pe kg lr ls pf lu lv lw pg ly lz ma ph mc md me im bi translated">寻找最佳DAG的一种简单的方法是创建图的所有可能的组合，即，通过制作几十个、几百个、甚至几千个不同的DAG，直到所有的组合都用尽。然后，可以根据数据的拟合度对每个DAG进行评分。最后，返回得分最高的DAG。在变量X，Y，Z的情况下，我们可以做出如图2所示的图形以及更多的图形，因为它不仅是X&gt;Z&gt;Y(图2a)，还可以是Z&gt;X&gt;Y，等等。变量X，Y，Z可以是布尔值(真或假)，<strong class="ll jd">但也可以有多种状态</strong>。Dag的搜索空间在使分数最大化的变量数量上变成所谓的超指数。这意味着对于大量节点，穷举搜索实际上是不可行的，因此，已经提出了各种贪婪策略来浏览DAG空间。使用基于优化的搜索方法，可以浏览更大的DAG空间。这种方法需要一个核函数和一个搜索策略。一个常见的评分函数是给定训练数据的结构的后验概率，如BIC或BDeu。</p><blockquote class="ot"><p id="9a3d" class="ou ov it bd ow ox oy oz pa pb pc me dk translated">大型Dag的结构学习需要评分函数和搜索策略。</p></blockquote><p id="93bd" class="pw-post-body-paragraph lj lk it ll b lm pd kd lo lp pe kg lr ls pf lu lv lw pg ly lz ma ph mc md me im bi translated">在我们进入示例之前，理解何时使用哪种技术总是好的。有两种广泛的方法来搜索整个DAG空间并找到数据的最佳拟合图。</p><ul class=""><li id="ffde" class="nk nl it ll b lm ln lp lq ls nm lw nn ma no me np nq nr ns bi translated"><strong class="ll jd">基于分数的结构学习</strong></li><li id="f031" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated"><strong class="ll jd">基于约束的结构学习</strong></li></ul><p id="f70f" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">注意，局部搜索策略进行了旨在提高结构得分的增量改变。像马尔可夫链蒙特卡罗这样的全局搜索算法可以避免陷入局部极小值，但我不会在这里讨论。</p><h2 id="e7b6" class="oe mo it bd mp pi pj dn mt pk pl dp mx ls pm pn mz lw po pp nb ma pq pr nd iz bi translated">基于分数的结构学习</h2><p id="0e3b" class="pw-post-body-paragraph lj lk it ll b lm nf kd lo lp ng kg lr ls nh lu lv lw ni ly lz ma nj mc md me im bi translated">基于分数的方法有两个主要组成部分:</p><ol class=""><li id="329e" class="nk nl it ll b lm ln lp lq ls nm lw nn ma no me pt nq nr ns bi translated">在所有可能Dag的搜索空间中进行优化的<em class="mf">搜索算法</em>；如<em class="mf">穷举搜索</em>、<em class="mf"> Hillclimbsearch </em>、<em class="mf"> Chow-Liu </em>。</li><li id="8c4e" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me pt nq nr ns bi translated"><em class="mf">评分函数</em>表示贝叶斯网络与数据的吻合程度。常用的评分函数有<em class="mf">贝叶斯狄利克雷得分</em>如<em class="mf"> BDeu </em>或<em class="mf"> K2 </em>和<em class="mf">贝叶斯信息准则</em> ( <em class="mf"> BIC </em>，也叫MDL)。</li></ol><p id="efed" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">下面描述了四种常见的基于评分的方法，但是关于贝叶斯评分方法的更多细节可以在这里找到[9]。</p><ul class=""><li id="f1f9" class="nk nl it ll b lm ln lp lq ls nm lw nn ma no me np nq nr ns bi translated"><strong class="ll jd"> <em class="mf">穷举搜索</em> </strong> <em class="mf">，</em>顾名思义，对每个可能的DAG进行评分，并返回得分最高的DAG。这种搜索方法只对非常小的网络有吸引力，并且阻止有效的局部优化算法总是找到最佳结构。因此，确定理想的结构通常是不容易的。然而，如果只涉及几个节点(例如:少于5个左右)，启发式搜索策略通常会产生好的结果。</li><li id="42c0" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated"><strong class="ll jd"><em class="mf">Hillclimbsearch</em></strong>是一种启发式搜索方法，如果使用更多的节点，可以使用这种方法。<em class="mf"> HillClimbSearch </em>执行贪婪的局部搜索，从DAG“start”(默认:断开的DAG)开始，通过迭代执行单边操作来最大限度地增加分数。一旦找到局部最大值，搜索就终止。</li><li id="ffdf" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated"><strong class="ll jd"> <em class="mf"> Chow-Liu </em> </strong>算法是一种特定类型的基于树的方法。Chow-Liu算法找到最大似然树结构，其中每个节点最多有一个父节点。可以通过限制树形结构来限制复杂度。</li><li id="0448" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated"><strong class="ll jd"> <em class="mf">树增强朴素贝叶斯(TAN) </em> </strong>算法也是一种基于树的方法，可用于对在其各种相互依赖的特征集之间涉及大量不确定性的巨大数据集进行建模[6]。</li></ul><h2 id="a843" class="oe mo it bd mp pi pj dn mt pk pl dp mx ls pm pn mz lw po pp nb ma pq pr nd iz bi translated"><strong class="ak">基于约束的结构学习</strong></h2><ul class=""><li id="93c0" class="nk nl it ll b lm nf lp ng ls pu lw pv ma pw me np nq nr ns bi translated"><strong class="ll jd"> <em class="mf">卡方检验。</em> </strong>一种不同但相当直接的方法，通过使用假设检验(如chi2检验统计量)识别数据集中的独立性来构建DAG。这种方法依赖于统计测试和条件假设来学习模型中变量之间的独立性。chi2检验的P值是观察到计算出的chi2统计值的概率，给定零假设，即X和Y是独立的，给定z。这可用于在给定的显著性水平上做出独立的判断。基于约束的方法的一个例子是PC算法，该算法从一个完整的全连通图开始，并且如果节点是独立的，则基于测试结果移除边，直到达到停止标准。</li></ul></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="8f62" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">bnlearn图书馆</h1><p id="7bf0" class="pw-post-body-paragraph lj lk it ll b lm nf kd lo lp ng kg lr ls nh lu lv lw ni ly lz ma nj mc md me im bi translated">关于本文中用于所有分析的<a class="ae li" href="https://erdogant.github.io/bnlearn" rel="noopener ugc nofollow" target="_blank"> <em class="mf"> bnlearn </em> </a>库，说几句话。<a class="ae li" href="https://erdogant.github.io/bnlearn" rel="noopener ugc nofollow" target="_blank"> <em class="mf"> bnlearn </em> </a>库旨在应对一些挑战，例如:</p><ul class=""><li id="be1a" class="nk nl it ll b lm ln lp lq ls nm lw nn ma no me np nq nr ns bi translated"><strong class="ll jd"> <em class="mf">结构学习</em> </strong>:给定数据:估计一个捕捉变量间依赖关系的DAG。</li><li id="5bc2" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated"><strong class="ll jd"> <em class="mf">参数学习</em> </strong>:给定数据和DAG:估计个体变量的(条件)概率分布。</li><li id="3476" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated"><strong class="ll jd"> <em class="mf">推论</em> </strong>:给定学习过的模型:为你的查询确定准确的概率值。</li></ul><p id="b54d" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated"><em class="mf"/><a class="ae li" href="https://erdogant.github.io/bnlearn" rel="noopener ugc nofollow" target="_blank"><em class="mf">bnlearn</em></a><em class="mf">相比其他贝叶斯分析实现有什么好处？</em></p><ul class=""><li id="6a3b" class="nk nl it ll b lm ln lp lq ls nm lw nn ma no me np nq nr ns bi translated">在pgmpy库的基础上构建</li><li id="c755" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated">包含最想要的贝叶斯管道</li><li id="1e3c" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated">简单直观</li><li id="af4d" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated"><a class="ae li" href="https://github.com/erdogant/bnlearn/" rel="noopener ugc nofollow" target="_blank">开源</a></li><li id="2482" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated"><a class="ae li" href="https://erdogant.github.io/bnlearn" rel="noopener ugc nofollow" target="_blank">文档页面</a></li></ul></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="5603" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">喷头数据集中的结构学习。</h1><p id="73dd" class="pw-post-body-paragraph lj lk it ll b lm nf kd lo lp ng kg lr ls nh lu lv lw ni ly lz ma nj mc md me im bi translated">让我们用一个简单直观的例子来演示结构学习的工作原理。假设你的后院有一个<strong class="ll jd">喷水系统</strong>，在过去的1000天里，你测量了四个变量，每个变量有两种状态:<em class="mf">雨</em>(是或否)<em class="mf">多云</em>(是或否)<em class="mf">喷水系统</em>(开或关)，以及<em class="mf">湿草</em>(对或错)。基于这四个变量和你对现实世界的概念，你可能会有一个图形应该是什么样子的直觉。对吗？对吗？如果没有，你最好读一下这篇文章，因为通过结构学习你会发现！</p><blockquote class="ot"><p id="cd2b" class="ou ov it bd ow ox oy oz pa pb pc me dk translated">用<a class="ae li" href="https://github.com/erdogant/bnlearn" rel="noopener ugc nofollow" target="_blank"><em class="lh">bn learn</em></a><em class="lh"/>只用几行代码就很容易确定因果关系。</p></blockquote><p id="d015" class="pw-post-body-paragraph lj lk it ll b lm pd kd lo lp pe kg lr ls pf lu lv lw pg ly lz ma ph mc md me im bi translated">在下面的例子中，我们将导入<a class="ae li" href="https://erdogant.github.io/bnlearn" rel="noopener ugc nofollow" target="_blank"> bnlearn </a>库，加载洒水喷头数据集，并确定哪个DAG最适合该数据。请注意，洒水喷头数据集很容易清理，不会丢失值，并且所有值都具有状态1或0。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oj ok l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi px"><img src="../Images/ec2cc7ccc2d4fca5666a5adffdb20640.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nTnSkvM_i9BHuPT6VKifDg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图3:喷水灭火系统的最佳DAG示例。它编码了以下逻辑:草地潮湿的概率取决于洒水器和雨水。洒水喷头开启的概率取决于多云天气。下雨的可能性取决于多云天气。</p></figure><p id="f71c" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">就是这样！我们已经学习了如图3所示的结构。检测到的DAG由通过边连接的四个节点组成，每个边指示一个因果关系。<em class="mf">湿草</em>的状态取决于两个节点，<em class="mf">下雨</em>和<em class="mf">洒水</em>。<em class="mf">下雨</em>的状态受<em class="mf">多云</em>的制约，另外<em class="mf">洒水器</em>的状态也受<em class="mf">多云</em>的制约。这个DAG表示(分解的)概率分布，其中<em class="mf"> S </em>是洒水喷头的随机变量，<em class="mf"> R </em>表示下雨，<em class="mf"> G </em>表示湿草地，<em class="mf"> C </em>表示多云。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi py"><img src="../Images/ca37e24baf482379e888af6bccf859b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*Z2SmNws1xuYyATwZiUGhbg.png"/></div></figure><p id="f562" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">通过检查图表，您很快就会看到模型中唯一的独立变量是<em class="mf"> C </em>。其他变量取决于多云、下雨和/或洒水的概率。通常，贝叶斯网络的联合分布是给定其父节点的每个节点的条件概率的乘积:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pz"><img src="../Images/7f1b1db10ba325cba1c8f8b7c2b6fa93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*vRY0IG1WpT4ruLt8pJpoMQ.png"/></div></figure><p id="568f" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在<a class="ae li" href="https://erdogant.github.io/bnlearn" rel="noopener ugc nofollow" target="_blank"> <em class="mf"> bnlearn </em> </a> <em class="mf"> </em>中对于结构学习的默认设置是<strong class="ll jd"> hillclimbsearch </strong>方法和<strong class="ll jd"> BIC </strong>评分。值得注意的是，可以指定不同的方法和评分类型。请参见指定搜索和评分类型的示例:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oj ok l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">bnlearn中各种结构学习方法和评分类型的示例。</p></figure><p id="b95d" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">尽管检测到的洒水喷头数据集的DAG很有见地，并显示了数据集中变量的因果相关性，但它不允许您询问所有类型的问题，例如:</p><ul class=""><li id="9fd9" class="nk nl it ll b lm ln lp lq ls nm lw nn ma no me np nq nr ns bi translated"><em class="mf">洒水装置关闭时，草地潮湿的可能性有多大？</em></li><li id="2c18" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated"><em class="mf">在洒水装置关闭且多云的情况下，下雨的可能性有多大</em>？</li></ul><p id="a29d" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在洒水喷头数据集中，根据您对世界的了解和逻辑思维，结果可能很明显。但是一旦你有了更大、更复杂的图表，它可能就不再那么明显了。有了所谓的<strong class="ll jd"> <em class="mf">推论，</em> </strong>我们就可以回答“<em class="mf">假设我们做了什么</em>”类型的问题，这些问题通常需要受控实验和明确的干预来回答。</p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="b2c5" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated"><strong class="ak">如何进行推论？</strong></h1><p id="7767" class="pw-post-body-paragraph lj lk it ll b lm nf kd lo lp ng kg lr ls nh lu lv lw ni ly lz ma nj mc md me im bi translated">为了做出推论，我们需要两个因素:<strong class="ll jd"> <em class="mf"> DAG </em> </strong>和<strong class="ll jd"> <em class="mf">条件概率表(CPTs) </em> </strong>。此时，我们将数据存储在数据帧(<em class="mf"> df </em>)中，并且我们很容易计算出描述数据结构的<em class="mf"> DAG </em>。需要CPT来定量描述每个节点与其父节点之间的统计关系。CPT可以使用<strong class="ll jd"> <em class="mf">参数学习</em> </strong>来计算，所以让我们先跳到参数学习，然后我们再回到做出推论。</p><h2 id="a5c2" class="oe mo it bd mp pi pj dn mt pk pl dp mx ls pm pn mz lw po pp nb ma pq pr nd iz bi translated">参数学习</h2><p id="97cd" class="pw-post-body-paragraph lj lk it ll b lm nf kd lo lp ng kg lr ls nh lu lv lw ni ly lz ma nj mc md me im bi translated">参数学习的任务是估计<em class="mf">条件概率表</em>的值。<a class="ae li" href="https://erdogant.github.io/bnlearn" rel="noopener ugc nofollow" target="_blank"> <em class="mf"> bnlearn </em> </a>库支持离散节点的参数学习:</p><ul class=""><li id="4680" class="nk nl it ll b lm ln lp lq ls nm lw nn ma no me np nq nr ns bi translated"><strong class="ll jd"> <em class="mf">最大似然估计</em> </strong>是利用变量状态发生的相对频率进行的自然估计。当估计贝叶斯网络的参数时，缺少数据是一个常见的问题，并且ML估计器具有过拟合数据的问题。换句话说，如果观察到的数据对于基础分布不具有代表性(或者太小),那么最大似然估计可能会非常遥远。例如，如果一个变量有3个父变量，每个父变量有10个状态，那么对于10 = 1000个父变量的配置，将分别进行状态计数。这可能使MLE对于学习贝叶斯网络参数非常脆弱。减轻MLE过拟合的一种方法是贝叶斯参数估计。</li><li id="02ed" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated"><strong class="ll jd"> <em class="mf">贝叶斯估计</em> </strong>从容易存在的先验CPT开始，这些CPT表达了我们在数据被观察到之前对变量<em class="mf">的信念。然后使用来自观测数据的状态计数来更新那些“先验”。人们可以认为先验存在于<em class="mf">伪状态计数</em>中，其在归一化之前被添加到实际计数中。一个非常简单的先验是所谓的<em class="mf"> K2 </em>先验，它简单地将“1”加到每个单个状态的计数上。更明智的先验选择是<em class="mf"> BDeu </em>(贝叶斯狄利克雷等价均匀先验)。</em></li></ul></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="c85a" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">喷头数据集上的参数学习。</h1><p id="9b77" class="pw-post-body-paragraph lj lk it ll b lm nf kd lo lp ng kg lr ls nh lu lv lw ni ly lz ma nj mc md me im bi translated">我将继续使用洒水喷头数据集来学习其参数，从而检测到<em class="mf">条件概率表(CPT)</em>。为了学习参数，我们需要一个<em class="mf">有向无环图(DAG) </em>和一个具有完全相同变量的数据集。想法是将数据集与DAG连接起来。在前面的例子中，我们很容易计算DAG(图3)。您可以在这个示例中使用它，或者，您可以基于您对世界的了解创建自己的DAG！在示例中，我将演示如何创建您自己的DAG，它可以基于专家/领域知识。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oj ok l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">使用喷头数据集进行参数学习的示例。</p></figure><p id="2476" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">如果您达到了这一点，那么您已经使用<em class="mf">最大似然估计(MLE) </em>基于<em class="mf"> DAG </em>和输入数据集<em class="mf"> df </em>计算出了<em class="mf"> CPTs </em>(图4)。注意，为了清楚起见，图4中包括了CPT。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qa"><img src="../Images/8ab6076f575332f4e4558b4e0e63dca2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TH5oP5oXkLseaOKvxalHcA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图4:CPT是使用<em class="lh">最大似然估计通过参数学习得出的。</em></p></figure><p id="57cc" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">使用MLE计算CPT很简单，让我通过手动计算节点<em class="mf">多云</em>和<em class="mf">下雨</em>的CPT来举例说明。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oj ok l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">为多云和下雨的节点手动计算最大似然的例子。</p></figure><p id="7d68" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">请注意，条件依赖可以基于有限的数据点。作为一个例子，<em class="mf"> P(Rain=1|Cloudy=0) </em>是基于91个观测值。如果<em class="mf"> Rain </em>有两个以上的状态和/或更多的依赖项，这个数字会更低。<strong class="ll jd"> <em class="mf">是更多数据的解决方案？</em> </strong>也许吧。也许不是。请记住，即使总样本量非常大，每个父配置的状态计数都是有条件的，这一事实也会导致碎片。查看CPT与MLE方法的区别。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oj ok l"/></div></figure></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="a2b7" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">关于洒水喷头数据集的推论。</h1><p id="eb81" class="pw-post-body-paragraph lj lk it ll b lm nf kd lo lp ng kg lr ls nh lu lv lw ni ly lz ma nj mc md me im bi translated">为了进行推理，它要求贝叶斯网络有两个主要组件:描述数据结构的<em class="mf">有向无环图(DAG) </em>和描述每个节点及其父节点之间的统计关系的<em class="mf">条件概率表(CPT) </em>。此时，您有了数据集，使用结构学习计算了DAG，使用参数学习估计了CPT。你现在可以做推论了！</p><p id="b2fc" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">通过推理，我们在一个叫做<a class="ae li" href="https://en.wikipedia.org/wiki/Variable_elimination" rel="noopener ugc nofollow" target="_blank">变量消除</a>的过程中边缘化变量。变量消去法是一种精确的推理算法。它还可以用于计算出网络的状态，通过简单地交换最大函数的和，具有最大概率。它的缺点是，对于大型bn，它可能在计算上很难处理。在这些情况下，可以使用近似推理算法，如<a class="ae li" href="https://en.wikipedia.org/wiki/Gibbs_sampling" rel="noopener ugc nofollow" target="_blank">吉布斯采样</a>或<a class="ae li" href="https://en.wikipedia.org/wiki/Rejection_sampling" rel="noopener ugc nofollow" target="_blank">拒绝采样</a>。</p><p id="3051" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">用<a class="ae li" href="https://erdogant.github.io/bnlearn" rel="noopener ugc nofollow" target="_blank"> <em class="mf"> bnlearn </em> </a>我们可以做出如下推论:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="7523" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">现在我们有了问题的答案:</p><pre class="ks kt ku kv gt nz oa ob oc aw od bi"><span id="fa3f" class="oe mo it oa b gy of og l oh oi"><strong class="oa jd"><em class="mf">How probable is it to have wet grass given the sprinkler is off?</em> </strong></span><span id="c680" class="oe mo it oa b gy qb og l oh oi"><em class="mf">P(Wet_grass=1 | Sprinkler=0) = 0.51</em></span><span id="4ab1" class="oe mo it oa b gy qb og l oh oi"><strong class="oa jd"><em class="mf"><br/>How probable is it have a rainy day given sprinkler is off and it is cloudy?</em></strong><br/></span><span id="a5ff" class="oe mo it oa b gy qb og l oh oi"><em class="mf">P(Rain=1 | Sprinkler=0, Cloudy=1) = 0.663</em></span></pre></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="2a19" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">我如何知道我的因果模型是正确的？</h1><p id="3b1b" class="pw-post-body-paragraph lj lk it ll b lm nf kd lo lp ng kg lr ls nh lu lv lw ni ly lz ma nj mc md me im bi translated">如果你仅仅使用数据来计算因果图，很难完全验证你的因果图的有效性和完整性。然而，一些解决方案有助于在因果图中获得更多信任。例如，有可能根据经验测试变量集之间的某些条件独立性或依赖性关系。如果它们不在数据中，则表明因果模型的正确性[8]。或者，可以添加先前的专家知识，例如DAG或CPTs，以在进行推断时获得对模型的更多信任。</p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="8be6" class="mn mo it bd mp mq mr ms mt mu mv mw mx ki my kj mz kl na km nb ko nc kp nd ne bi translated">讨论</h1><p id="1f91" class="pw-post-body-paragraph lj lk it ll b lm nf kd lo lp ng kg lr ls nh lu lv lw ni ly lz ma nj mc md me im bi translated">在本文中，我谈到了一些概念，关于为什么相关性或关联性不是因果关系，以及如何使用结构学习从数据走向因果模型。贝叶斯技术的优势总结如下:</p><ol class=""><li id="af0e" class="nk nl it ll b lm ln lp lq ls nm lw nn ma no me pt nq nr ns bi translated">后验概率分布的结果或图形允许用户对模型预测做出判断，而不是将单个值作为结果。</li><li id="4a64" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me pt nq nr ns bi translated">在DAG中整合领域/专家知识的可能性，以及不完整信息和缺失数据的推理。这是可能的，因为贝叶斯定理是建立在用证据更新先验项的基础上的。</li><li id="f8a6" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me pt nq nr ns bi translated">它有模块化的概念。</li><li id="990b" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me pt nq nr ns bi translated">复杂的系统是由简单的部分组合而成的。</li><li id="533d" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me pt nq nr ns bi translated">图论直观地提供了高度交互的变量集。</li><li id="f2b7" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me pt nq nr ns bi translated">概率论提供了结合各部分的粘合剂。</li></ol><p id="5125" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">贝叶斯网络的另一方面的弱点是寻找最优DAG在计算上是昂贵的，因为必须对所有可能的结构进行穷举搜索。穷举搜索的节点限制可能已经是大约15个节点，但是也取决于状态的数量。如果您有更多的节点，则需要具有评分功能和搜索算法的替代方法。然而，为了处理具有数百甚至数千个变量的问题，有必要采用不同的方法，例如基于树或基于约束的方法，并使用变量的黑名单/白名单。这种方法首先确定顺序，然后找到该顺序的最佳BN结构。这意味着在可能排序的搜索空间上工作，这是方便的，因为它小于网络结构的空间。</p><p id="5682" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">确定因果关系可能是一项具有挑战性的任务，但<a class="ae li" href="https://erdogant.github.io/bnlearn" rel="noopener ugc nofollow" target="_blank"> <em class="mf"> bnlearn </em> </a>库旨在应对一些挑战，如<strong class="ll jd"> <em class="mf">结构学习、参数学习、</em> </strong>和<strong class="ll jd"> <em class="mf">推理</em> </strong>。但是它也可以导出(整个)图的拓扑排序，或者比较两个图。文档可在此处<a class="ae li" href="https://erdogant.github.io/bnlearn/" rel="noopener ugc nofollow" target="_blank">找到</a>，其中还包含了<em class="mf">报警、安第斯、亚洲、探路者、萨克斯</em>车型<em class="mf">的示例。</em></p><p id="a726" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated"><em class="mf">注意安全。保持冷静。</em></p><p id="2f8a" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated"><strong class="ll jd"> <em class="mf">欢呼，E. </em> </strong></p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><p id="b000" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated"><em class="mf">如果您觉得这篇文章很有帮助，请使用我的</em> <a class="ae li" href="https://medium.com/@erdogant/membership" rel="noopener"> <em class="mf">推荐链接</em> </a> <em class="mf">继续无限制学习，并注册成为中级会员。另外，</em> <a class="ae li" href="http://erdogant.medium.com" rel="noopener"> <em class="mf">关注我</em> </a> <em class="mf">关注我的最新内容！</em></p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h2 id="b1fa" class="oe mo it bd mp pi pj dn mt pk pl dp mx ls pm pn mz lw po pp nb ma pq pr nd iz bi translated">软件</h2><ul class=""><li id="8441" class="nk nl it ll b lm nf lp ng ls pu lw pv ma pw me np nq nr ns bi translated"><a class="ae li" href="https://erdogant.github.io/bnlearn/" rel="noopener ugc nofollow" target="_blank"> bnlearn文档</a></li><li id="e462" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated"><a class="ae li" href="https://erdogant.github.io/bnlearn/pages/html/Blog.html#colab-notebook" rel="noopener ugc nofollow" target="_blank"> Colab笔记本示例</a></li></ul><h2 id="8764" class="oe mo it bd mp pi pj dn mt pk pl dp mx ls pm pn mz lw po pp nb ma pq pr nd iz bi translated">我们连线吧！</h2><ul class=""><li id="ff1c" class="nk nl it ll b lm nf lp ng ls pu lw pv ma pw me np nq nr ns bi translated"><a class="ae li" href="https://www.linkedin.com/in/erdogant/" rel="noopener ugc nofollow" target="_blank">让我们在LinkedIn上联系</a></li><li id="73b8" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated">在Github上关注我</li><li id="22f4" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me np nq nr ns bi translated"><a class="ae li" href="https://erdogant.medium.com/" rel="noopener">在媒体上跟我来</a></li></ul></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h2 id="3b5a" class="oe mo it bd mp pi pj dn mt pk pl dp mx ls pm pn mz lw po pp nb ma pq pr nd iz bi translated">参考</h2><ol class=""><li id="f6ed" class="nk nl it ll b lm nf lp ng ls pu lw pv ma pw me pt nq nr ns bi translated">麦克劳德，S. A，<em class="mf"> </em> <a class="ae li" href="https://www.simplypsychology.org/correlation.html" rel="noopener ugc nofollow" target="_blank"> <em class="mf">相关定义，例题&amp;释义</em> </a>。单纯心理学2018年1月14日</li><li id="eda4" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me pt nq nr ns bi translated">F.达布兰德，<a class="ae li" href="https://fabiandablander.com/r/Causal-Inference.html" rel="noopener ugc nofollow" target="_blank">因果推理导论，心理学方法系</a>，阿姆斯特丹大学，<a class="ae li" href="https://psyarxiv.com/b3fkw" rel="noopener ugc nofollow" target="_blank">https://psyarxiv.com/b3fkw</a></li><li id="9ae1" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me pt nq nr ns bi translated">布列塔尼·戴维斯，<a class="ae li" rel="noopener" target="_blank" href="/when-correlation-is-better-than-causation-1cbfa2708fbb">当相关性优于因果关系</a>，中等，2021</li><li id="141d" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me pt nq nr ns bi translated">保罗·金里奇<a class="ae li" href="http://uregina.ca/~gingrich/ch11a.pdf" rel="noopener ugc nofollow" target="_blank">措施协会</a>。第766–795页</li><li id="4980" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me pt nq nr ns bi translated">Taskesen，E，<a class="ae li" rel="noopener" target="_blank" href="/explore-and-understand-your-data-with-a-network-of-significant-associations-9a03cf79d254">通过一个重要关联网络探索和理解您的数据</a>。2021年8月，中等</li><li id="2e80" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me pt nq nr ns bi translated">布拉尼斯拉夫·霍兰德，<a class="ae li" rel="noopener" target="_blank" href="/introduction-to-probabilistic-graphical-models-b8e0bf459812">概率图形模型介绍</a>，中型，2020年</li><li id="5e09" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me pt nq nr ns bi translated">Harini Padmanaban，<a class="ae li" href="https://scholarworks.sjsu.edu/cgi/viewcontent.cgi?referer=&amp;httpsredir=1&amp;article=1350&amp;context=etd_projects" rel="noopener ugc nofollow" target="_blank">朴素贝叶斯和Tes的朴素分析与树增强朴素增强朴素贝叶斯模型的比较分析</a>，圣何塞州立大学，2014年</li><li id="9532" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me pt nq nr ns bi translated">胡萨尔。曲线拟合之外的ML:因果推理和微积分简介</li><li id="d184" class="nk nl it ll b lm nt lp nu ls nv lw nw ma nx me pt nq nr ns bi translated">E.巴黎水等人，<a class="ae li" href="https://www.jmlr.org/papers/volume9/perrier08a/perrier08a.pdf" rel="noopener ugc nofollow" target="_blank">给定超结构</a>寻找最优贝叶斯网络，《机器学习研究杂志》9(2008)2251–2286。</li></ol></div></div>    
</body>
</html>