<html>
<head>
<title>Predicting Win Probability</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测获胜概率</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-win-probability-910af3b48f75?source=collection_archive---------13-----------------------#2021-06-07">https://towardsdatascience.com/predicting-win-probability-910af3b48f75?source=collection_archive---------13-----------------------#2021-06-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="b8e7" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">迷你教程</h2><div class=""/><div class=""><h2 id="9ad3" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">在销售机会上使用机器学习</h2></div><p id="3dc6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">您是否曾经不得不确定在销售渠道中赢得机会的概率？营销团队创造销售线索，销售团队跟进销售线索，在此过程中，每个机会都会经历一个生命周期，从RFP阶段一直到最终成交。随着机会从一个阶段过渡到下一个阶段，联系人会分配一个将销售线索转化为销售的概率，从而赢得机会。</p><p id="3065" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">但是这个概率有多准呢？给定一个足够大的包含多个预测变量的数据集，我们可以使用机器学习来确定赢得机会的概率吗？我们在一家领先的资产管理公司建立了一个概念验证，展示让机器说话的好处:)</p><h2 id="0615" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated"><strong class="ak">特性</strong></h2><p id="6251" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">利用九个不同的数据源提取了机会级别的14个属性。这些因素包括关系持续时间、预期的机会持续时间、CRM活动数量、机会数量、机会类型(新的、交叉销售等)。)、自上次联系以来的持续时间、进行的演示次数、演示者姓名、参加的产品网络研讨会次数、管理的资产以及资产价值的增长。</p><p id="eae9" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这些被转换成单个数据框，每个记录代表一个机会，如下所示</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/c9bc793b71049a3a2d0d555129a26979.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AtsL9pAKJS7HEMRXPIB-ow.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">作者图片</p></figure><h2 id="1a82" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated">培训和测试</h2><p id="4df0" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">然后，机会数据框架被分为开放和关闭的机会。对于已结束的业务机会，最终状态是已知的——成功、失败或无效，而对于开放的业务机会，状态是预测的。状态标签转换为0或1，1表示赢得机会，0表示失去机会(包括“非活动”状态)。</p><p id="506a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">关闭的机会以75:25的比例分成培训和测试，同时使用Caret包中的createDataPartition函数维护状态标签的比例。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mx"><img src="../Images/88600cef97dd7fc46e4562bdfcc96530.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rrSC1BPzgN0obFhtd8MjmQ.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">作者图片</p></figure><pre class="mi mj mk ml gt my mz na nb aw nc bi"><span id="861f" class="lk ll iq mz b gy nd ne l nf ng">&gt; set.seed(101) <br/>&gt; intrain = createDataPartition(y=closed_opps$Label, p=0.75, list=FALSE)<br/>&gt; traindf = closed_opps[intrain,]; traindf$Label = as.factor(traindf$Label)<br/>&gt; testdf = closed_opps[-intrain,]; testdf$Label = as.factor(testdf$Label)</span></pre><h2 id="b2fb" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated">模型</h2><p id="2869" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">我使用R中的Caret、ARM和XGBoost包在训练数据上建立监督机器学习模型，并将机会分类为赢或输。</p><p id="e50c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">朴素贝叶斯:</strong>一种基于贝叶斯定理的分类算法，在给定每个预测变量取某个值的情况下，确定赢得或失去机会<em class="nh">的概率。</em></p><pre class="mi mj mk ml gt my mz na nb aw nc bi"><span id="c9ee" class="lk ll iq mz b gy nd ne l nf ng">nb_model &lt;- train(Label ~ ., data = traindf, method = “naive_bayes”, trControl = fitControl, na.action = na.pass)</span></pre><p id="98a6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">逻辑回归:</strong>具有二元结果的广义线性模型，使用sigmoid函数将其转换为概率。每个预测变量的“权重”由模型确定，以减少实际值和预测值之间的误差。</p><pre class="mi mj mk ml gt my mz na nb aw nc bi"><span id="2a2c" class="lk ll iq mz b gy nd ne l nf ng">lr_model &lt;- train(Label ~ ., data = traindf, method = “glm”, family = “binomial”, trControl = fitControl, na.action = na.pass)</span></pre><p id="587f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">贝叶斯GLM: </strong>逻辑回归模型的扩展，但它根据贝叶斯方法假设预测变量的先验分布。</p><pre class="mi mj mk ml gt my mz na nb aw nc bi"><span id="73a8" class="lk ll iq mz b gy nd ne l nf ng">bayenesian_model &lt;- train(Label ~ ., data = traindf, method = “bayesglm”, trControl = fitControl, na.action = na.pass)</span></pre><p id="695f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">增强逻辑回归:</strong>几个逻辑回归模型的集合，然后用于根据单个预测进行预测。</p><pre class="mi mj mk ml gt my mz na nb aw nc bi"><span id="cc4b" class="lk ll iq mz b gy nd ne l nf ng">boosted_lr_model &lt;- train(Label ~ ., data = traindf, method = “LogitBoost”, trControl = fitControl, na.action = na.pass)</span></pre><p id="3271" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">随机森林:</strong>决策树的集合，用作慢学习器，通过使用在每个节点提供最佳分割的特征将训练数据分成各自的状态，对每个机会进行分类。</p><pre class="mi mj mk ml gt my mz na nb aw nc bi"><span id="063a" class="lk ll iq mz b gy nd ne l nf ng">library(randomForest) # to build a random forest model<br/>rf_model = train(Label ~ ., data = traindf, method = “rf”, ntree = 30, maxdepth = 5, trControl = fitControl, na.action = na.pass)<br/>detach(“package:randomForest”, unload=TRUE) #conflicts with margin in ggplot</span></pre><p id="419b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">极端梯度推进:</strong>以连续的方式构建决策树的集合，其中每个模型的残差适合后续的模型。</p><pre class="mi mj mk ml gt my mz na nb aw nc bi"><span id="b580" class="lk ll iq mz b gy nd ne l nf ng">xgb_model &lt;-train(Label ~., data = traindf, method = “xgbTree”, trControl = fitControl, tuneGrid = xgb.grid, verbose = T, nthread = 2, na.action = na.pass)</span></pre><p id="c537" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">极限梯度提升(带DART): </strong>极限梯度提升算法的扩展，但是为了避免过度拟合的问题，在每个阶段都要丢弃树。</p><pre class="mi mj mk ml gt my mz na nb aw nc bi"><span id="7536" class="lk ll iq mz b gy nd ne l nf ng">xgbDART_model &lt;- train(Label ~ ., data = traindf, method = “xgbDART”, trControl = fitControl, na.action = na.pass)</span></pre><h2 id="4582" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated">性能指标</h2><p id="4661" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">然后，每个ML模型被部署在测试数据集上</p><pre class="mi mj mk ml gt my mz na nb aw nc bi"><span id="397a" class="lk ll iq mz b gy nd ne l nf ng">nb_predictions_test = predict(nb_model, newdata = testdf, type = “raw”)<br/>bayenesian_predictions_test = predict(bayenesian_model, newdata = testdf, type = “raw”)<br/>boosted_lr_predictions_test = predict(boosted_lr_model, newdata = testdf, type = “raw”)<br/>lr_predictions_test = predict(lr_model, newdata = testdf, type = “raw”)<br/>rf_predictions_test = predict(rf_model, newdata = testdf, type = “raw”)<br/>xgbDART_predictions_test = predict(xgbDART_model, newdata = testdf, type = “raw”)<br/>xgb_predictions_test = predict(xgb_model, newdata = testdf, type = “raw”)</span></pre><p id="2d05" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">使用3个度量来测量性能:ROC、灵敏度和特异性。ROC是接收器操作特性，即曲线下的面积，分类器的整体精度。敏感度是真正的肯定率，即被正确预测为成功的机会数量占总成功的比例。特异性是真实的负比率，即被正确预测为失去的机会数占失去的机会总数的比例。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ni"><img src="../Images/756f9b067483a66123f505b15b3c450f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wYxxrLBiCA3nlaYUAR_duA.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">作者图片</p></figure><h2 id="4445" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated">结果</h2><p id="a5e1" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">随机森林模型在测试数据集上提供了最高的灵敏度。这用于预测赢得公开机会的概率，结果以下列方式展示。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nj"><img src="../Images/7adb99389325ba3326ec9a285ddd6a0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oWW-XkQXNm41MSiz_WX_eA.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">作者图片</p></figure><p id="83f3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">该算法还用于使用Caret包中的varImp函数来确定每个输入特征的重要性。结果表明，我们假设对模型有贡献的某些特征实际上没有帮助，这就需要讨论数据是否有错，或者我们是否必须修改我们对该特征的假设。</p><h2 id="ccc8" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated">用例</h2><p id="37de" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">能够预测管道中机会的成功率将使我们能够实施“早期预警系统”，并提供一个与潜在客户互动的框架。例如，CRM活动可以基于成功概率以及机会数量来划分优先级。此模型的输出也可以成为后续细分模型的输入，该模型将客户划分为战略客户或其他客户。</p><h2 id="d8ee" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated">挑战</h2><p id="82a7" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">我们在研究这些模型时面临的主要挑战是缺乏清晰的数据。我们发现在不同的电子表格文件中维护数据的方式有几处不一致，必须手动将它们映射到中央存储库中的kID。我们还发现，ML模型需要比构建模型时更多的数据。随着我们从遗留系统过渡，并同时清理数据，我们相信这种概念验证将会出现。</p><p id="b8a6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果您有任何意见或反馈，或其他预测销售渠道中机会成功率的方法，请使用下面的评论部分。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nk"><img src="../Images/98f64fd4a02bfe9bcef78c0a8bed127e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5t3gwpjC4ETCjcendzS2SA.jpeg"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">斯蒂芬·道森在<a class="ae nl" href="https://unsplash.com/s/photos/sales?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="3d26" class="lk ll iq bd lm ln lo dn lp lq lr dp ls kx lt lu lv lb lw lx ly lf lz ma mb iw bi translated">有用的链接</h2><p id="2adc" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">以下是Caret软件包上的一个链接，您会发现它很有用:</p><p id="c75b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae nl" href="https://cran.r-project.org/web/packages/caret/vignettes/caret.html" rel="noopener ugc nofollow" target="_blank">https://cran . r-project . org/web/packages/caret/vignettes/caret . html</a></p></div></div>    
</body>
</html>