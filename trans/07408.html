<html>
<head>
<title>Cross Validation in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的交叉验证</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cross-validation-and-bootstrap-sampling-2e041fbec126?source=collection_archive---------9-----------------------#2021-07-06">https://towardsdatascience.com/cross-validation-and-bootstrap-sampling-2e041fbec126?source=collection_archive---------9-----------------------#2021-07-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="69f4" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="e64a" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">了解交叉验证过程以及为什么bootstrap样本有63.2%的原始数据</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/1326883b3f7f592aa34379778edd228e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Qe1a5NIMxxeiaZB-"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@clemhlrdt?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Clément Hélardot </a>拍摄于<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="3756" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在训练了一个机器学习模型之后，每个数据科学家总是想知道<em class="me">训练好的模型在看不见的数据上表现如何。</em>好的模型是不仅在训练中而且在测试数据中表现良好的模型。为了估计模型的性能，我们经常使用一部分数据进行训练，保留一部分数据进行测试，希望模型在测试数据上的性能能够代表宇宙中的数据。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="7fb8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面是一个简单分类问题的例子。在此示例中，Iris数据集从Sklearn模块加载，逻辑回归模型适合数据。数据包含用于训练的<code class="fe mm mn mo mp b">150</code>记录和用于测试的<code class="fe mm mn mo mp b"> 60%</code>记录。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="532c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">输出:</p><pre class="ks kt ku kv gt ms mp mt mu aw mv bi"><span id="4f24" class="mw mx it mp b gy my mz l na nb">Model 0 accuracy: 0.967<br/>Model 1 accuracy: 0.967<br/>Model 2 accuracy: 0.933<br/>Model 3 accuracy: 0.967<br/>Model 4 accuracy: 0.933<br/>Model 5 accuracy: 0.933<br/>Model 6 accuracy: 0.85<br/>Model 7 accuracy: 0.95<br/>Model 8 accuracy: 1.0<br/>Model 9 accuracy: 0.95</span></pre></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="5da6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe mm mn mo mp b">Line 1–15:</code>在这些行中，数据被加载，模块被导入。</p><p id="5ab9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe mm mn mo mp b">Line 17:</code>这是一种在每次迭代中将逻辑模型拟合到相同数据中的循环。需要注意的重要一点是，模型在每次迭代中都有不同的表现(参见上面的模型得分)。注意，差异并不归因于迭代期间的任何参数变化，因为相同的参数用于所有模型。差异的来源在于数据的分割。<code class="fe mm mn mo mp b">train_test_split</code>将数据分成<code class="fe mm mn mo mp b">2</code>，但是在每次迭代中，不同的数据被用于训练和测试，因为没有播种的洗牌。如果您想要在每次迭代中获得一致的结果，请向<a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank">sk learn . model _ selection . train _ test _ split</a>的<code class="fe mm mn mo mp b">random _state </code>参数传递一个种子值。你可以如下重写第<code class="fe mm mn mo mp b">25</code>行</p><p id="ee3f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><code class="fe mm mn mo mp b">X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.40, random_state=42)</code></p><p id="df80" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这使得模型结果是可再现的，即一致的。这是因为分裂期间的洗牌是播种的，因此用于训练和测试的数据在所有迭代中都是一致的。</p><p id="f035" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一个经典的验证过程包括完全按照上面的例子所做的事情——将数据分成两组:训练集和测试集——但是对模型评分的一次运行可能无法确定模型在生产中的表现如何。为此，我们需要一种更好的验证方式。这正是交叉验证的用武之地。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="c2a1" class="nc mx it bd nd ne nf ng nh ni nj nk nl ki nm kj nn kl no km np ko nq kp nr ns bi translated">交叉验证</h1><p id="18ed" class="pw-post-body-paragraph li lj it lk b ll nt kd ln lo nu kg lq lr nv lt lu lv nw lx ly lz nx mb mc md im bi translated">交叉验证是一种用于验证机器学习模型并估计已训练模型对未知数据的性能的技术。正如你将在下面的讨论中看到的，它比经典的评估要好。</p><h2 id="5f64" class="mw mx it bd nd ny nz dn nh oa ob dp nl lr oc od nn lv oe of np lz og oh nr iz bi translated">交叉验证程序</h2><ol class=""><li id="a5fc" class="oi oj it lk b ll nt lo nu lr ok lv ol lz om md on oo op oq bi translated">[可选]无序播放数据。</li><li id="d175" class="oi oj it lk b ll or lo os lr ot lv ou lz ov md on oo op oq bi translated">将数据分成<code class="fe mm mn mo mp b">k</code>个大小相同(或大致相同)的不同组/折叠(因此，交叉验证也称为<strong class="lk jd"><em class="me">k</em>-折叠交叉验证</strong>)。</li><li id="a96c" class="oi oj it lk b ll or lo os lr ot lv ou lz ov md on oo op oq bi translated">运行模型训练和验证的<code class="fe mm mn mo mp b">k</code>次迭代。对于<code class="fe mm mn mo mp b">1,2,…,i,…k</code>中的<code class="fe mm mn mo mp b">i</code></li></ol><p id="8be1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在<code class="fe mm mn mo mp b">k</code>文件夹中，单个文件夹(<code class="fe mm mn mo mp b">i</code>文件夹)用作保留/验证数据，其他<code class="fe mm mn mo mp b">k-1</code>文件夹用于训练模型。</p><p id="6aa5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">模型通过验证后，保留模型分数<code class="fe mm mn mo mp b">E_i</code>。</p><p id="681a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">4.合计(<code class="fe mm mn mo mp b">3</code>第二点)中获得的分数，以获得所有<code class="fe mm mn mo mp b">k</code>褶皱的模型平均性能。在大多数情况下，使用算术平均值进行汇总，因此:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ow"><img src="../Images/493500d222d9531f036519a1408038b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lFF-a5NTtCfsyw5aP-INJg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">每次迭代中模型得分的平均值。</p></figure><p id="c49b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于分类任务，可以使用准确度、精确度、召回率等指标对模型进行评分，对于回归问题，可以使用均方误差、平均绝对误差等指标在每次迭代中对模型进行评分。</p><p id="441b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">5.分析平均得分<code class="fe mm mn mo mp b">E</code>，确定它在看不见的数据(宇宙)上表现良好的可能性。</p><h2 id="eee9" class="mw mx it bd nd ny nz dn nh oa ob dp nl lr oc od nn lv oe of np lz og oh nr iz bi translated">使用Sklearn实现k-fold交叉验证的简单方法</h2><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="5c8a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">输出:</p><pre class="ks kt ku kv gt ms mp mt mu aw mv bi"><span id="8d9d" class="mw mx it mp b gy my mz l na nb">train: [ 2  3  4  5  6  7  8 11 12], test: [1  9 10]<br/>train: [ 1  3  5  6  7  9 10 11 12], test: [2 4 8]<br/>train: [ 1  2  4  5  8  9 10 11 12], test: [3 6 7]<br/>train: [ 1  2  3  4  6  7  8  9 10], test: [5 11 12]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ox"><img src="../Images/888a44cdb08f0a3ab38d8771680e9cff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bmwq9F8k8nhGO3HbAwPVjg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片:完整的k倍交叉验证程序。k=5的一种情况，即5重交叉验证。参考:Sklearn网站。</p></figure><p id="3003" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面是来自维基百科的交叉验证过程的动画。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/eac2070c01e555faab9a4937d2fdfc6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*gS98yUmJMcfvQf6QinsWyQ.gif"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">当n = 12个观察值和k = 3时，k重交叉验证的图解(3重交叉验证的一个例子)。经过数据洗牌后，共有3个模型将被训练和测试。每个文件夹将包含12/3=4个数据示例。来源:维基百科</p></figure><h2 id="7709" class="mw mx it bd nd ny nz dn nh oa ob dp nl lr oc od nn lv oe of np lz og oh nr iz bi translated"><em class="oz"> k的选择</em></h2><ul class=""><li id="4b00" class="oi oj it lk b ll nt lo nu lr ok lv ol lz om md pa oo op oq bi translated">首先，<code class="fe mm mn mo mp b">k </code>必须是介于<code class="fe mm mn mo mp b">2</code>和<code class="fe mm mn mo mp b"><em class="me">n</em></code>(观测值/记录数)之间的整数。<code class="fe mm mn mo mp b">k</code>必须至少有<code class="fe mm mn mo mp b">2</code>才能保证至少有两次折叠。</li><li id="dd0e" class="oi oj it lk b ll or lo os lr ot lv ou lz ov md pa oo op oq bi translated">对于<code class="fe mm mn mo mp b">k=2</code>，我们随机打乱数据(可选)并将其分成<code class="fe mm mn mo mp b">2</code>组— <code class="fe mm mn mo mp b">d1</code>和<code class="fe mm mn mo mp b">d2</code>，以使两组大小相等(或大致相等)。然后在<code class="fe mm mn mo mp b">d1</code>上训练模型，在<code class="fe mm mn mo mp b">d2</code>上验证模型，接着在<code class="fe mm mn mo mp b">d2</code>上训练模型，在<code class="fe mm mn mo mp b">d1</code>上验证模型。</li><li id="4cad" class="oi oj it lk b ll or lo os lr ot lv ou lz ov md pa oo op oq bi translated">选择<code class="fe mm mn mo mp b">k=n</code>可以将事情发挥到极致。在这个场景中，我们有一个特殊的交叉验证案例，叫做<strong class="lk jd">留一交叉验证(LOOCV)。</strong>该名称来源于这样一个事实，即在每次迭代中，一个数据点被遗漏用于验证，而其他的<code class="fe mm mn mo mp b">n-1</code>用于测试。</li><li id="0899" class="oi oj it lk b ll or lo os lr ot lv ou lz ov md pa oo op oq bi translated">在交叉验证中<code class="fe mm mn mo mp b">k</code>是不固定的参数，但在选择<code class="fe mm mn mo mp b">k</code>时应考虑以下几点:</li></ul><p id="8a10" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">代表性启发法 — <code class="fe mm mn mo mp b">k </code>的选择方式应确保保留数据/折叠代表整个宇宙(看不见的数据)。例如，如果我们有<code class="fe mm mn mo mp b">1000</code>记录，并且我们选择<code class="fe mm mn mo mp b">k=500</code>，那么在每次迭代中，只有<code class="fe mm mn mo mp b">1000/500=2</code>数据点用于验证。这使得验证规模非常小。非常大的<code class="fe mm mn mo mp b">k</code>值意味着跨训练折叠的差异更小，因此限制了跨迭代的模型差异。这意味着<code class="fe mm mn mo mp b">k</code>不能太大也不能太小。</p><p id="12fe" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="me">经验法则</em> —尽管<code class="fe mm mn mo mp b">k</code>是一个不固定的参数(没有特定的公式可用于确定最佳选择)，但<code class="fe mm mn mo mp b">10</code>仍被普遍使用，因为它已被实验证明在大多数情况下是一个好的选择。</p><ul class=""><li id="1065" class="oi oj it lk b ll lm lo lp lr pb lv pc lz pd md pa oo op oq bi translated">给定原始数据中的<code class="fe mm mn mo mp b">n</code>观察值，每个折叠将包含<code class="fe mm mn mo mp b">n/k</code>记录。</li></ul><p id="7c02" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里还有另一个来自维基百科的动画，展示了留一法交叉验证的概念:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/a2853bd98924a89cbb10ee498cb6b8a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*myWxiiTaohGFnk7rncGzTQ.gif"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">当n=8个观察值时，留一交叉验证(LOOCV)的图示。在交叉验证过程完成之前，总共训练和测试了8个模型。每次迭代产生一个在n-1个数据点上训练并在1个数据点上测试的模型。来源:维基百科</p></figure><h2 id="e0e7" class="mw mx it bd nd ny nz dn nh oa ob dp nl lr oc od nn lv oe of np lz og oh nr iz bi translated">使用交叉验证方法的原因</h2><ul class=""><li id="8295" class="oi oj it lk b ll nt lo nu lr ok lv ol lz om md pa oo op oq bi translated">模型在训练中的性能，甚至在验证集上运行的性能，都不能保证模型在未知数据上的最佳性能。当数据不足以代表宇宙状态时，就会发生这种情况。在这种情况下，测试数据上的模型误差可能无法反映模型在宇宙中的表现。这正是上面例子中的情况——使用<code class="fe mm mn mo mp b">150</code>数据记录来训练和测试模型产生了不一致的分数。</li><li id="73b6" class="oi oj it lk b ll or lo os lr ot lv ou lz ov md pa oo op oq bi translated">因此，在缺乏大型数据集的情况下，交叉验证是评估模型性能的最佳选择。</li></ul><h2 id="823a" class="mw mx it bd nd ny nz dn nh oa ob dp nl lr oc od nn lv oe of np lz og oh nr iz bi translated">k-Fold交叉验证的特征概述</h2><ul class=""><li id="5a09" class="oi oj it lk b ll nt lo nu lr ok lv ol lz om md pa oo op oq bi translated">在将数据分割成<code class="fe mm mn mo mp b"> k</code>个文件夹之前，进行混洗(可选操作)。这意味着给定的数据点被分配到单个文件夹中，并且在交叉验证过程的剩余部分中它保持在该组中。这也意味着一个给定的数据点被用于一次验证和<code class="fe mm mn mo mp b">k-1</code>次训练。</li><li id="40c2" class="oi oj it lk b ll or lo os lr ot lv ou lz ov md pa oo op oq bi translated">每个折叠中有<code class="fe mm mn mo mp b">n/k</code>个数据点，其中<code class="fe mm mn mo mp b">n</code>是原始数据中的观察次数，<code class="fe mm mn mo mp b">k</code>是折叠次数。</li><li id="e4f7" class="oi oj it lk b ll or lo os lr ot lv ou lz ov md pa oo op oq bi translated"><code class="fe mm mn mo mp b">k</code>可以取<code class="fe mm mn mo mp b"> 2</code>和<code class="fe mm mn mo mp b">n</code>(原始样本中的观察次数)之间的任意整数值。</li></ul></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="d77a" class="nc mx it bd nd ne nf ng nh ni nj nk nl ki nm kj nn kl no km np ko nq kp nr ns bi translated">自助抽样</h1><p id="773e" class="pw-post-body-paragraph li lj it lk b ll nt kd ln lo nu kg lq lr nv lt lu lv nw lx ly lz nx mb mc md im bi translated">Bootstrap采样是一种重采样技术，涉及<strong class="lk jd">随机采样和替换</strong>。单词resample在字面上的意思是“再次采样”，这意味着通过用“原始”样本的替换进行采样来生成自举样本。</p><p id="6f43" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">通常，通过选择用于分析的总体子集来生成采样，目的是推断总体(总体-&gt;样本)，而重采样是为了推断样本(样本-&gt;重采样数据)。</p><p id="5fac" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这里有一个简单的例子。假设从给定总体中抽取一个大小为<code class="fe mm mn mo mp b">12</code>的样本，并从这些样本中产生<code class="fe mm mn mo mp b">3</code>个引导样本。然后，我们可以将此信息表示如下:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pe"><img src="../Images/bb5961cc935b43e9f55d3546b90b0cd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y5Thf3I861v38I6Xkxx5Kw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">自举抽样(bootstrapping)的一个例子。原始数据包含<code class="fe mm mn mo mp b">12</code>数据示例，每个样本集还包括从原始数据中取样12个数据点并替换。来源:作者。</p></figure><p id="49a6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于我们是带替换的传导采样，请注意上面示例中的以下内容:</p><ul class=""><li id="7a1f" class="oi oj it lk b ll lm lo lp lr pb lv pc lz pd md pa oo op oq bi translated">一些数据点(可能)出现在多个集合中。例如<code class="fe mm mn mo mp b">6</code>出现在集合<code class="fe mm mn mo mp b">D2</code>和<code class="fe mm mn mo mp b">D3</code>中。</li><li id="a91d" class="oi oj it lk b ll or lo os lr ot lv ou lz ov md pa oo op oq bi translated">有些例子在给定的集合中会出现不止一次。例如<code class="fe mm mn mo mp b">9, 10, 4, 3</code>和<code class="fe mm mn mo mp b">7</code>在集合<code class="fe mm mn mo mp b">D1</code>中出现不止一次。</li></ul></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><blockquote class="pf"><p id="fe2f" class="pg ph it bd pi pj pk pl pm pn po md dk translated">“假设n(原始数据的大小)足够大，实际上它(引导样本)与原始‘真实’样本完全相同的概率几乎为零。”—维基百科</p></blockquote><p id="83f3" class="pw-post-body-paragraph li lj it lk b ll pp kd ln lo pq kg lq lr pr lt lu lv ps lx ly lz pt mb mc md im bi translated">事实上，</p><p id="3b37" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"/><strong class="lk jd">平均而言，63.22%的原始数据出现在任何给定的bootstrap样本中，</strong>这与所说的<strong class="lk jd">相同——一个平均bootstrap样本遗漏了原始样本中100–63.22 = 36.78%的数据。</strong></p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="3999" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们用最简单的方法证明这个数学事实。在此之前，让我们陈述一些在证明过程中有帮助的数学事实。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pu"><img src="../Images/b0a38d2b4f9968ebf9a91b2f03de66df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SK9PBRe8OWmiyyjo8U_FsQ.png"/></div></div></figure><p id="ea6e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们现在可以继续证明了。</p><p id="ba35" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">假设原始数据有<code class="fe mm mn mo mp b">n</code>个观察值，我们从数据中得到大小为<code class="fe mm mn mo mp b">n</code>的bootstrap样本，那么:</p><ul class=""><li id="335d" class="oi oj it lk b ll lm lo lp lr pb lv pc lz pd md pa oo op oq bi translated">给定观察不被选择的概率是<code class="fe mm mn mo mp b">(1–1/n)</code>，被选择的概率是<code class="fe mm mn mo mp b">(1/n)</code>。</li><li id="d9f8" class="oi oj it lk b ll or lo os lr ot lv ou lz ov md pa oo op oq bi translated">因为我们要重采样n次，所以在n次试验中观察结果未被选中的概率是<code class="fe mm mn mo mp b">(1–1/n)^n</code>。</li></ul><p id="37ec" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">根据微积分，随着<code class="fe mm mn mo mp b">n-&gt;∞</code> (n变大)，这个概率可以使用极限的概念来确定。也就是说，</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pv"><img src="../Images/77886831e294fac7da72b815cfa2ced6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zn13mWQIFW5ZASuhsbeIpg.png"/></div></div></figure><p id="7993" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从这里开始，我们需要理解和应用洛必达法则。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pw"><img src="../Images/e19d4eba5244003ef40fca8b314bf827.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*471V9RyrVELXweGdAZ4wTg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">洛必达法则声明。换句话说，该规则规定，考虑两个函数f和g，它们的导数存在于某个区间I内，但不存在于该区间内的给定点c(即，导数存在于区间内的其他任何地方，但不存在于某个点c)。如果当x接近点c时，f和g的极限(假设f和g是x的函数)等于零或无穷大，并且对于区间I中x的所有值，g的导数不等于零(这确保我们在后续运算中不会遇到被零除的问题) 并且f除以g的导数极限存在，那么f除以g的极限等于f的导数极限除以g的导数，当x接近c时，参考:维基百科</p></figure><p id="9994" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从等式<code class="fe mm mn mo mp b">(4)</code>中，我们可以证明，在应用洛必达法则之前，我们需要满足的所有条件实际上都满足如下:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi px"><img src="../Images/01ba5993b79af98fca92eab6b1dd33ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EYkovceBNS-FZBBZ7iJMxQ.png"/></div></div></figure><p id="c07c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后，我们可以将洛必达法则应用到等式<code class="fe mm mn mo mp b">4</code>中，并按如下所示进行操作</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi py"><img src="../Images/2dba103c6b00a10082d4d2678bf77f15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZATBrYoEnKdvpsbuZ8EeMg.png"/></div></div></figure><p id="dab6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这结束了我们的证明，证实随着<code class="fe mm mn mo mp b">n</code>变大，自举消除了原始样本中大约36.22%的数据。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="8bea" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">今天的文章到此结束。如果你喜欢它，请看看下面这篇关于交叉熵损失函数的文章，也读一读。下次再见，祝阅读愉快:-)</p><div class="pz qa gp gr qb qc"><a rel="noopener follow" target="_blank" href="/cross-entropy-loss-function-f38c4ec8643e"><div class="qd ab fo"><div class="qe ab qf cl cj qg"><h2 class="bd jd gy z fp qh fr fs qi fu fw jc bi translated">交叉熵损失函数</h2><div class="qj l"><h3 class="bd b gy z fp qh fr fs qi fu fw dk translated">在大多数分类问题中用于优化机器学习模型的损失函数…</h3></div><div class="qk l"><p class="bd b dl z fp qh fr fs qi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ql l"><div class="qm l qn qo qp ql qq lb qc"/></div></div></a></div></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="4206" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">加入https://medium.com/@kiprono_65591/membership<a class="ae lh" href="https://medium.com/@kiprono_65591/membership" rel="noopener">的媒体</a>，全面了解媒体上的每个故事。</p><p id="256f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你也可以在我发文章的时候通过这个链接把文章发到你的邮箱里:【https://medium.com/subscribe/@kiprono_65591 T4】</p></div></div>    
</body>
</html>