<html>
<head>
<title>1+1=3. Wait, no, 1+1=2. How to have GPT sanity check itself.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">1+1=3.等等，不，1+1=2。如何让GPT自我检查？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/1-1-3-wait-no-1-1-2-how-to-have-gpt-sanity-check-itself-136e846987bf?source=collection_archive---------31-----------------------#2021-06-30">https://towardsdatascience.com/1-1-3-wait-no-1-1-2-how-to-have-gpt-sanity-check-itself-136e846987bf?source=collection_archive---------31-----------------------#2021-06-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c9ae" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">在Colab中使用GPT-J使用GPT仔细检查其答案的Python演练</em></h2></div><p id="ee27" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">大型语言模型有一个问题，他们往往只是编造东西。这可能是因为训练数据、提示或者甚至仅仅是歧义。这可以通过设计让GPT健全检查其输出的提示来缓解，它可以与GPT3和GPT-J一起工作(后者可以免费使用)。</p><p id="86cf" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我所说的健全检查是什么意思？嗯，通过设置您的提示来仔细检查输出，结果是这样的:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="c8f7" class="ll lm iq lh b gy ln lo l lp lq">Initial Answer: 6394 + 250 = 6643<br/>Double Checking: 6643 looks wrong. 6394 + 250 = 6644</span><span id="12fe" class="ll lm iq lh b gy lr lo l lp lq">Initial Answer: {a} + {b} =</span></pre><p id="4a69" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">与使用类似于以下内容的传统提示符相比，您可以提高性能:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="7578" class="ll lm iq lh b gy ln lo l lp lq">6394 + 250 = 6644<br/>{a} + {b}=</span></pre><p id="7fed" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">此外，对于像我一样不擅长阅读的人，你可以跳过这篇文章，只需<a class="ae ls" href="https://colab.research.google.com/github/matthewlouisbrockman/LearnGPT3/blob/main/GPT_J_6B_planning_sharable1.ipynb" rel="noopener ugc nofollow" target="_blank">使用链接的colab </a>使用GPT-J自己运行代码。</p><p id="353a" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">作为背景，还有一些其他方法可以用来缓解这类问题。最流行的是手动筛选你喜欢的答案。这很无聊，而且如果您试图自动化流程，这也没有什么帮助。还有另一种方法，让一个模型通过<a class="ae ls" href="http://gptprompts.wikidot.com/linguistics:word-in-context" rel="noopener ugc nofollow" target="_blank">中间步骤</a>展示它的工作，这可以<a class="ae ls" href="https://blog.andrewcantino.com/blog/2021/05/28/how-to-dramatically-improve-the-reasoning-ability-of-GPT-3/" rel="noopener ugc nofollow" target="_blank">提高推理能力</a>，这很酷。然而，我认为值得看一看自我纠正，看看GPT能在多大程度上审视它所发表的内容，并决定它是否需要改进，因为人们似乎没有深入研究它(尽管去年有一些有趣的关于猜测和检查随机代数解决方案的很酷的推文)。</p><p id="fb40" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">举个玩具例子，我用算术。为什么是算术？首先，我们可以衡量一个答案是否正确，知道这一点是有好处的。第二，虽然有一种说法认为语言模型在算术上表现不佳的原因是由于GPT令牌的编码方式，但我怀疑多位算术存在搜索问题，你必须从右到左进行加法才能携带数字，当你只是提前预测时，很难猜测数字会被携带到哪里。GPT不擅长这种类型的搜索，如果搜索导致了这个问题，那么做双重检查应该会有所帮助。</p><p id="8ebe" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">总之，在这篇文章中，我将向您展示如何生成包含1-30个示例的上下文，使用标准的少数镜头和改进的自检少数镜头运行它们的完成，然后我们将绘制错误(图1)并看到，与传统的少数镜头相比，自检提示确实具有更低的错误和更高的精确匹配。下面是图表的样子(注意，对于精确匹配，我们获得了16%的最高准确率，而使用逗号的GPT3可以获得超过90%的最高准确率，所以可能会有很大的差异)。</p><figure class="lc ld le lf gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lt"><img src="../Images/8d047b57a12fd5c517abcac071799471.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eMCQgARRgqeBOVuRm2QWtQ.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图1:在使用GPT-J的4位数算术中，与常规的少量尝试相比，自校正提示具有更低的平均绝对百分比误差(左)和更高的精确匹配(右)</p></figure><h2 id="b269" class="ll lm iq bd mf mg mh dn mi mj mk dp ml kp mm mn mo kt mp mq mr kx ms mt mu mv bi translated">设置查询功能</h2><p id="4ef3" class="pw-post-body-paragraph kg kh iq ki b kj mw jr kl km mx ju ko kp my kr ks kt mz kv kw kx na kz la lb ij bi translated">这适用于GPT-J和GPT-3模型，您只需以不同的方式设置您的查询函数，这就是我们将要开始的地方。当我们查询这类任务的完成情况时，我们希望使用0 temperature，因为我们希望获得最有可能的令牌，而不是随机加入其他数字。下面是我在J中的查询函数的样子(借用了<a class="ae ls" href="https://colab.research.google.com/github/kingoflolz/mesh-transformer-jax/blob/master/colab_demo.ipynb" rel="noopener ugc nofollow" target="_blank"> GPT-J演示笔记本</a>中的infer函数，这个函数很酷):</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="5602" class="ll lm iq lh b gy ln lo l lp lq">def query(context, top_p=0, temp=0, gen_len=50):<br/>  tokens = tokenizer.encode(context)<br/>  provided_ctx = len(tokens)<br/>  pad_amount = seq - provided_ctx<br/>  padded_tokens = np.pad(tokens, ((pad_amount, 0),)).astype(np.uint32)<br/>  batched_tokens = np.array([padded_tokens] * total_batch)<br/>  length = np.ones(total_batch, dtype=np.uint32) * len(tokens)<br/>  output = network.generate(batched_tokens, length, gen_len, {"top_p": np.ones(total_batch) * top_p, "temp": np.ones(total_batch) * temp})<br/>  samples = []<br/>  decoded_tokens = output[1][0]<br/>  for o in decoded_tokens[:, :, 0]:<br/>    samples.append(tokenizer.decode(o))<br/>  return samples[0]</span></pre><p id="4145" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">设置提示</strong></p><p id="2e69" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">现在，我们将继续设置我们的提示。我们将随机创建30个例子作为提示，100个例子作为测试集。</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="4baa" class="ll lm iq lh b gy ln lo l lp lq">import pandas as pd, json, random</span><span id="26f7" class="ll lm iq lh b gy lr lo l lp lq">random.seed(42)</span><span id="b824" class="ll lm iq lh b gy lr lo l lp lq">fourDigitDict = []<br/>fourDigitTest = []</span><span id="13ad" class="ll lm iq lh b gy lr lo l lp lq">for i in range(30):<br/>  a = int(random.random()*10**4)<br/>  b = int(random.random()*10**4)<br/>  fourDigitDict.append({'first': a, "second": b, 'sum': a+b})<br/>fourDigitTrainDF = pd.DataFrame(fourDigitDict)</span><span id="1990" class="ll lm iq lh b gy lr lo l lp lq">for i in range(100):<br/>  a = int(random.random()*10**4)<br/>  b = int(random.random()*10**4)<br/>  fourDigitTest.append({'first': a, "second": b, 'sum': a+b})<br/>fourDigitTestDF = pd.DataFrame(fourDigitTest)</span></pre><p id="7fa5" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">对于纯/传统的情况，我们只是让所有的例子都按照提示排列起来，但是我们在这里要做的自我纠正是随机设置一些错误的例子。我们将错误的答案(或正确的答案)称为<em class="nb">原始总和</em>，这样我们可以告诉模型稍后将其纠正为正确的答案。</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="e22e" class="ll lm iq lh b gy ln lo l lp lq">fourDigitTrainDF['randomlyWrong'] = fourDigitTrainDF['sum'].apply(lambda x: random.random() &lt; .5)</span><span id="c1b2" class="ll lm iq lh b gy lr lo l lp lq">fourDigitTrainDF['offset'] = fourDigitTrainDF['randomlyWrong'].apply(lambda x: .5-random.random() if x==True else 0)</span><span id="42a8" class="ll lm iq lh b gy lr lo l lp lq">fourDigitTrainDF['offset'] = fourDigitTrainDF['offset'] * 2000</span><span id="e974" class="ll lm iq lh b gy lr lo l lp lq">fourDigitTrainDF['originalSum'] = fourDigitTrainDF['sum'] + fourDigitTrainDF['offset']</span></pre><p id="6b03" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">接下来，我们只需创建我们的提示。我们将有一组提示，一组是关于纯粹的几个镜头，另一组是关于修正后的镜头。为了了解我们需要多少个示例，我们将进行网格搜索，并从1到30个示例中尝试运行。</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="2563" class="ll lm iq lh b gy ln lo l lp lq">correctionPrompts = {}<br/>purePrompts = {}</span><span id="47cf" class="ll lm iq lh b gy lr lo l lp lq">for i in range(1,30):<br/>  correctionPrompt = ""<br/>  purePrompt = ""<br/>  for row in fourDigitTrainDF[:i].iterrows():<br/>    correctionPrompt += 'Initial Answer: {} + {} = {}'.format(row[1]['first'], row[1]['second'], int(row[1]['originalSum']))<br/>    correctionPrompt += '\n'<br/>    interjection = 'looks correct.' if not row[1]['randomlyWrong'] else 'looks off by a bit.'<br/>    correctionPrompt += 'Double Checking: {} {} {} + {} = {}'.format(int(row[1]['originalSum']), interjection, row[1]['first'], row[1]['second'], row[1]['sum'])<br/>    correctionPrompt += '\n\n'</span><span id="f0a1" class="ll lm iq lh b gy lr lo l lp lq">    purePrompt += '{} + {} = {}'.format(row[1]['first'], row[1]['second'], row[1]['sum']) + '\n'<br/>  <br/>  correctionPrompt += 'Initial Answer: '<br/>  correctionPrompts[i] = correctionPrompt<br/>  purePrompts[i] = purePrompt</span></pre><p id="4f39" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">现在我们已经设置好了所有的提示，是时候对照测试集来试试了！</p><p id="b78d" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">运行测试</strong></p><p id="1d7b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">为了运行测试，我们将开始设置实际的查询(a + b =)，然后将它添加到每个提示的末尾(有无自我纠正)。然后，我们将运行整个程序，并在它执行6000次查询时袖手旁观。我们还会在每次检查测试集时将它转储到JSON，以防出现问题，以便我们可以恢复。</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="1de6" class="ll lm iq lh b gy ln lo l lp lq">import json<br/>fourDigitTestDF['formatted'] = fourDigitTestDF.apply(lambda x: "{} + {} =".format(x['first'], x['second']), axis=1)</span><span id="1139" class="ll lm iq lh b gy lr lo l lp lq">correctionResults = {}<br/>pureResults = {}</span><span id="8c1c" class="ll lm iq lh b gy lr lo l lp lq">#for each size of example length in 1-30, run on the test set<br/>for trainSize in range(1,30):<br/>  if trainSize not in correctionResults:<br/>  print(trainSize)<br/>  correctionResults[trainSize] = []<br/>  pureResults[trainSize] = []<br/>  for example in fourDigitTestDF.formatted:<br/>    correctionResults[trainSize].append( query(correctionPrompts[trainSize]+example, gen_len=50))<br/>  pureResults[trainSize].append(<br/>query(purePrompts[trainSize]+example, gen_len=50))<br/>  with open('correctionResults.json', 'w') as fh:<br/>    json.dump(correctionResults, fh)<br/>  with open('pureResults.json', 'w') as fh:<br/>    json.dump(pureResults, fh)</span></pre><p id="9218" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">评估</strong></p><p id="bc7d" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">好，现在我们有了6000份文件，我们将对其进行评估。我首先将测试集重命名为<em class="nb"> test </em>，因为……为什么不呢。由于我还不知道如何用GPT J做一个停止序列(我的学位是新闻学，数学很难)，我们必须解析出我们想要的答案。对于传统的方法，这只是出门的第一个“字”。对于自校正方法，它是第一组输出的最后一个“单词”。</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="e705" class="ll lm iq lh b gy ln lo l lp lq">def parsePureInt(x):<br/>  base = x.split('\n')[0]<br/>  try:<br/>    return int(base)<br/>  except:<br/>    return 0</span><span id="dbcb" class="ll lm iq lh b gy lr lo l lp lq">def parseCorrectedInt(x):<br/>  base = x.split('\n\n')[0].split(' ')[-1]<br/>  try:<br/>    return int(base)<br/>  except:<br/>    return 0</span></pre><p id="b83e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">现在我们将把它应用到我们所有的结果中，并计算误差。</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="3d64" class="ll lm iq lh b gy ln lo l lp lq">for key in pureResults.keys():<br/>  test[key] = pureResults[key]<br/>  test[key] = test[key].apply(lambda x: parsePureInt(x))</span><span id="f755" class="ll lm iq lh b gy lr lo l lp lq">pureMape = pd.DataFrame()<br/>  for col in test.columns[3:]:<br/>  pureMape[col] = (abs(test[col] - test['sum']))/test['sum']</span><span id="4c04" class="ll lm iq lh b gy lr lo l lp lq">pureEM = pd.DataFrame()<br/>for col in test.columns[3:]:<br/>  pureEM[col] = test[col] == test['sum']</span><span id="f3c1" class="ll lm iq lh b gy lr lo l lp lq">for key in correctionResults.keys():<br/>  test[key] = correctionResults[key]<br/>  test[key] = test[key].apply(lambda x: parseCorrectedInt(x))</span><span id="dc92" class="ll lm iq lh b gy lr lo l lp lq">correctedMape = pd.DataFrame()<br/>for col in test.columns[3:]:<br/>  correctedMape[col] = (abs(test[col] - test['sum']))/test['sum']</span><span id="7cbb" class="ll lm iq lh b gy lr lo l lp lq">correctedeEM = pd.DataFrame()<br/>  for col in test.columns[3:]:<br/>  correctedeEM[col] = test[col] == test['sum']</span></pre><p id="6674" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">现在我们只是绘制结果</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="1f34" class="ll lm iq lh b gy ln lo l lp lq">fig, axs = plt.subplots(ncols=2, nrows=1, figsize=(12,8), facecolor='white')<br/>correctedMape.mean().plot(label='self correcting', ax=axs[0])<br/>pureMape.mean().plot(ax=axs[0], label='pure few shot')<br/>axs[0].legend()<br/>axs[0].set_xlabel('# of examples')<br/>axs[0].set_title('Mean Error')</span><span id="75c5" class="ll lm iq lh b gy lr lo l lp lq">correctedeEM.sum().plot(label='self correcting', ax=axs[1])pureEM.sum().plot(ax=axs[1], label='pure few shot')<br/>axs[1].legend()<br/>axs[1].set_xlabel('# of examples')<br/>axs[1].set_title('Exact Match')<br/>fig.suptitle('4 Digit Arithmetic on 100 Tests')</span></pre><figure class="lc ld le lf gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lt"><img src="../Images/8d047b57a12fd5c517abcac071799471.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eMCQgARRgqeBOVuRm2QWtQ.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图二。等等，不对，还是图1。</p></figure><p id="c4b0" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">在关闭</strong></p><p id="a55f" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">你可以用GPT3和J运行上面的代码，你会得到同样的改进。我把它作为一个练习留给读者，让他们也用逗号来做这件事(您可以只使用f " { x:} "来格式化带有逗号的内容)。不过，它能工作真的很酷。</p><figure class="lc ld le lf gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nc"><img src="../Images/824e23a0042f60f79af371bce82c8621.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cRveRK6FlMZIDESyWfBTgg.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">同样，如果你在GPT3中使用逗号，你会得到更多类似的东西，这取决于模型大小/微调。虽然不确定在17个例子中发生了什么。</p></figure><p id="65a9" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我认为这里发生的事情是，因为它不能提前预测，有时它开始制造随机数字，直到它到达末尾，然后这给了它检查下一次应该是什么前几个数字的上下文。虽然我不完全确定。这些模型很奇怪。</p></div></div>    
</body>
</html>