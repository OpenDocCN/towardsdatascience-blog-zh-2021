<html>
<head>
<title>Run Scrapy code from Jupyter Notebook without issues</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">运行Jupyter笔记本上的零碎代码，没有任何问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/run-scrapy-code-from-jupyter-notebook-without-issues-69b7cb79530c?source=collection_archive---------6-----------------------#2021-07-26">https://towardsdatascience.com/run-scrapy-code-from-jupyter-notebook-without-issues-69b7cb79530c?source=collection_archive---------6-----------------------#2021-07-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="d84e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://scrapy.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir"> Scrapy </strong> </a>是一个开源框架，用于从网站中提取数据。它快速、简单且可扩展。每个数据科学家都应该熟悉这一点，因为他们经常需要以这种方式收集数据。数据科学家通常更喜欢使用某种计算笔记本来管理他们的工作流程。Jupyter笔记本在数据科学家中非常受欢迎，其他选项包括<a class="ae kl" href="https://www.jetbrains.com/pycharm/" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">【py charm】</strong></a><a class="ae kl" href="https://zeppelin.apache.org/" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">zeppelin</strong></a><a class="ae kl" href="https://code.visualstudio.com/" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">VS Code</strong></a><a class="ae kl" href="https://nteract.io/" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">interact</strong></a><strong class="jp ir">、Google Colab、</strong>和<a class="ae kl" href="https://www.spyder-ide.org/" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">spyder</strong></a><strong class="jp ir"/>等等。</p><p id="fef1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用Scrapy的刮擦通常是用一个<code class="fe km kn ko kp b">.py</code>文件完成的。它也可以从笔记本电脑初始化。问题是，当代码块第二次运行时，它抛出一个错误“<code class="fe km kn ko kp b">ReactorNotRestartable</code>:”。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi kq"><img src="../Images/f5fd2dd723e8f77cb6af64343444139a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aO2XHReow66HH6CG"/></div></div><p class="lc ld gj gh gi le lf bd b be z dk translated">由<a class="ae kl" href="https://unsplash.com/@clemhlrdt?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Clément Hélardot </a>在<a class="ae kl" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="ded0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用<code class="fe km kn ko kp b"><a class="ae kl" href="https://pypi.org/project/crochet/" rel="noopener ugc nofollow" target="_blank">crochet</a></code>包可以解决这个错误。<code class="fe km kn ko kp b">ReactorNotRestartable</code>使用该软件包可以减少错误。在这篇博文中，我展示了我从Jupyter Notebook运行scrapy代码而不出错的步骤。</p><p id="3a14" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="lg">先决条件:</em> </strong></p><blockquote class="lh li lj"><p id="2318" class="jn jo lg jp b jq jr js jt ju jv jw jx lk jz ka kb ll kd ke kf lm kh ki kj kk ij bi translated">刺儿头:<code class="fe km kn ko kp b">pip install scrapy</code></p><p id="8c9a" class="jn jo lg jp b jq jr js jt ju jv jw jx lk jz ka kb ll kd ke kf lm kh ki kj kk ij bi translated"><a class="ae kl" href="https://pypi.org/project/crochet/" rel="noopener ugc nofollow" target="_blank">钩针</a> : <code class="fe km kn ko kp b">pip install crochet</code></p><p id="87d5" class="jn jo lg jp b jq jr js jt ju jv jw jx lk jz ka kb ll kd ke kf lm kh ki kj kk ij bi translated">任何适合python的笔记本，我用的是Jupyter笔记本:<code class="fe km kn ko kp b">pip install notebook</code></p></blockquote></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><p id="9617" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="lg">演示项目:</em> </strong></p><p id="6584" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了演示这些步骤，我从<a class="ae kl" href="https://en.wikiquote.org/wiki/Main_Page" rel="noopener ugc nofollow" target="_blank"> wikiquote </a>中搜集了美国摇滚歌手<a class="ae kl" href="https://en.wikiquote.org/wiki/Maynard_James_Keenan" rel="noopener ugc nofollow" target="_blank">梅纳德·詹姆斯·基南</a>的引语，并将这些信息保存为. csv文件，每次运行脚本时都会被覆盖，这对项目的重新开始很有用。这是通过使用自定义设置并传递一个以<code class="fe km kn ko kp b">FEEDS</code>为键的嵌套字典和一个以输出文件的名称为键的字典以及包含提要的不同设置的值来实现的。</p><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="lu lv l"/></div></figure><p id="c00b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了初始化这个过程，我运行下面的代码:</p><pre class="kr ks kt ku gt lw kp lx ly aw lz bi"><span id="a886" class="ma mb iq kp b gy mc md l me mf">process = CrawlerProcess()<br/>process.crawl(QuotesToCsv)<br/>process.start()</span></pre><p id="ab4a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它第一次运行时没有问题，并将csv文件保存在根目录下，但是从下一次开始会抛出以下错误。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/62f308c9e06e83062679d5362cf1bf42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*qb8sSmhVfbFjUWy_oMpdKg.png"/></div><p class="lc ld gj gh gi le lf bd b be z dk translated">` ReactorNotRestartable '错误，图片由作者提供。</p></figure><p id="9463" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要再次运行代码而不出现问题，必须重启内核。现在随着钩针的使用，这个代码可以在一个Jupyter笔记本上使用，没有问题。</p><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="lu lv l"/></div></figure><p id="86f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我调用这个函数来运行代码，没有任何问题。</p><pre class="kr ks kt ku gt lw kp lx ly aw lz bi"><span id="5b65" class="ma mb iq kp b gy mc md l me mf">run_spider()</span></pre><p id="72e1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在让我来看看这两种方法之间的区别:</p><ol class=""><li id="e654" class="mh mi iq jp b jq jr ju jv jy mj kc mk kg ml kk mm mn mo mp bi translated">用<code class="fe km kn ko kp b">CrawlerRunner</code>代替<code class="fe km kn ko kp b">CrawlerProcess</code>。</li><li id="d36e" class="mh mi iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated">从<code class="fe km kn ko kp b"><em class="lg">crochet</em></code>导入<code class="fe km kn ko kp b">setup</code>和<code class="fe km kn ko kp b">wait_for</code> <em class="lg"> </em>，并使用<em class="lg"> </em> <code class="fe km kn ko kp b">setup()</code>初始化。</li><li id="0b55" class="mh mi iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated">在从scrapy运行蜘蛛的函数上使用<code class="fe km kn ko kp b">@wait_for(10)</code> decorator。<code class="fe km kn ko kp b">@wait_for</code>用于阻塞进入扭曲反应器线程的调用。点击<a class="ae kl" href="https://crochet.readthedocs.io/en/1.5.0/api.html" rel="noopener ugc nofollow" target="_blank">此处</a>了解更多信息。</li></ol><p id="21e9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">瞧啊。不再有错误。脚本运行并将输出保存为<code class="fe km kn ko kp b">quotes.csv</code>。</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><p id="794b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果文件包含脚本，这也可以使用<code class="fe km kn ko kp b">!python scrape_webpage.py</code>从Jupyter笔记本的. py中完成。话虽如此，从笔记本上开发代码还是很方便的。此外，这种方法的一个警告是，如果使用<code class="fe km kn ko kp b">CrawlerRunner</code>而不是<code class="fe km kn ko kp b">CrawlerProcess</code>，日志会少得多。</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi mv"><img src="../Images/8438b0f51d1b8b56af3bdec8d3f6fc93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sDVEHEBn7rY_F_mS"/></div></div><p class="lc ld gj gh gi le lf bd b be z dk translated">由<a class="ae kl" href="https://unsplash.com/@synkevych?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Roman Synkevych </a>在<a class="ae kl" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="d5d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://github.com/tamjid-ahsan/Run-Scrapy-code-from-Jupyter-Notebook" rel="noopener ugc nofollow" target="_blank">这里的</a>是我用来测试我的工作流程的所有代码和笔记本的GitHub repo。</p><p id="567d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下次见！！！</p></div></div>    
</body>
</html>