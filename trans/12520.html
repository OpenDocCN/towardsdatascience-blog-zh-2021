<html>
<head>
<title>Road Map from Naive Bayes Theorem to Naive Bayes Classifier (Stat-09)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从朴素贝叶斯定理到朴素贝叶斯分类器的路线图(Stat-09)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/road-map-from-naive-bayes-theorem-to-naive-bayes-classifier-6395fc6d5d2a?source=collection_archive---------11-----------------------#2021-12-22">https://towardsdatascience.com/road-map-from-naive-bayes-theorem-to-naive-bayes-classifier-6395fc6d5d2a?source=collection_archive---------11-----------------------#2021-12-22</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="aca1" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">朴素贝叶斯分类器的完整指南，从头开始实现</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/4307ee030f5f6876e9dbc9d2ce24dea7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IcbQ-l_JBUPTaY6r"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">约翰·汤纳在<a class="ae kz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="6afa" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">朴素贝叶斯这个名字本身就表达了算法的含义。但是怎么会！我们来分析一下算法的名字，朴素贝叶斯。我们找到两个术语，一个是朴素的，另一个是贝叶斯。在这里，Naive 意味着算法中使用的所有特征都是相互独立的；而且之所以叫贝叶斯，是因为它依赖于贝叶斯定理。朴素贝叶斯分类器是分类器算法的集合，其中所有算法共享一个共同的原则，因为每个特征对都是彼此独立分类的。它基于一个对象进行预测。为了理解该算法，我们必须从一些基本术语开始，如生成模型、贝叶斯定理。有两种机器学习模型。</p><ul class=""><li id="a652" class="lw lx iu lc b ld le lg lh lj ly ln lz lr ma lv mb mc md me bi translated">生成模型</li><li id="9535" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">判别模型</li></ul><p id="2bb1" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">朴素贝叶斯分类器是生成模型的用例之一。因此，在一开始，我们将讨论生成模型。</p><p id="6c80" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><em class="mk">注意:如果你想了解概率的概念，在阅读这篇文章之前，我建议你先浏览一下下面这篇文章。] </em></p><div class="ml mm gq gs mn mo"><a rel="noopener follow" target="_blank" href="/basic-probability-concepts-for-data-science-eb8e08c9ad92"><div class="mp ab fp"><div class="mq ab mr cl cj ms"><h2 class="bd iv gz z fq mt fs ft mu fv fx it bi translated">数据科学的基本概率概念</h2><div class="mv l"><h3 class="bd b gz z fq mt fs ft mu fv fx dk translated">概率有助于预测任何事件的未知结果</h3></div><div class="mw l"><p class="bd b dl z fq mt fs ft mu fv fx dk translated">towardsdatascience.com</p></div></div><div class="mx l"><div class="my l mz na nb mx nc kt mo"/></div></div></a></div><h2 id="6ae2" class="nd ne iu bd nf ng nh dn ni nj nk dp nl lj nm nn no ln np nq nr lr ns nt nu nv bi translated">✪生成模型</h2><p id="62c3" class="pw-post-body-paragraph la lb iu lc b ld nw jv lf lg nx jy li lj ny ll lm ln nz lp lq lr oa lt lu lv in bi translated">生成模型主要关注数据的分布，并考虑分布的密度来计算类。</p><p id="bf80" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">生成模型的一些示例:</p><ul class=""><li id="bd25" class="lw lx iu lc b ld le lg lh lj ly ln lz lr ma lv mb mc md me bi translated">‌naïve·贝叶斯</li><li id="6f44" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">贝叶斯网络</li><li id="1c40" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">马尔可夫随机场</li><li id="eb1d" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">‌Hidden 马尔可夫模型</li><li id="b036" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">潜在狄利克雷分配</li><li id="b186" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">生成对抗网络</li><li id="d76e" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv mb mc md me bi translated">自回归模型</li></ul><h2 id="ca27" class="nd ne iu bd nf ng nh dn ni nj nk dp nl lj nm nn no ln np nq nr lr ns nt nu nv bi translated">✪贝叶斯定理</h2><p id="2eba" class="pw-post-body-paragraph la lb iu lc b ld nw jv lf lg nx jy li lj ny ll lm ln nz lp lq lr oa lt lu lv in bi translated">以英国数学家托马斯·贝叶斯命名的贝叶斯定理被用来寻找条件概率。条件概率用于根据前一个事件找到事件概率。贝叶斯定理产生后验概率来分解先验概率。</p><p id="ebc2" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">先验概率是在获取新数据点之前事件的相似性。</p><p id="da7d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">后验概率是在获取新数据点后对事件的推测。决定性地，贝叶斯定理试图在新的数据或信息被添加到数据集之后找到事件的可能性。贝叶斯定理的公式:</p><p id="d8ac" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">P(A|B) = P(A) * P(B|A)/P(B)</p><p id="5348" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在哪里，</p><p id="1e14" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">P(A)表示事件 A 发生的概率</p><p id="47a0" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">P(B)表示事件 B 发生的概率</p><p id="6565" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">P(A|B)表示给定 B 时发生 A 的概率</p><p id="7788" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">P(B|A)表示给定 A 时发生 B 的概率</p><h2 id="35f6" class="nd ne iu bd nf ng nh dn ni nj nk dp nl lj nm nn no ln np nq nr lr ns nt nu nv bi translated">◉朴素贝叶斯算法是如何工作的</h2><p id="5e20" class="pw-post-body-paragraph la lb iu lc b ld nw jv lf lg nx jy li lj ny ll lm ln nz lp lq lr oa lt lu lv in bi translated">一个分类问题可能有一个、两个或多个类别标签。假设我们有 m 个类别标签<strong class="lc iv"> y1，y2，…，ym，</strong>和<strong class="lc iv"> n </strong>输入变量<strong class="lc iv"> X1，X2，…，Xn。从这些数据中，我们可以计算出给定输入变量的概率。数据的公式如下</strong></p><p id="df0b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><strong class="lc iv"> P(yi | x1，x2，…，xm) = P(x1，x2，…，xn | yi) * P(yi) / P(x1，x2，…，xm)。</strong></p><p id="3b11" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们必须确定值<strong class="lc iv"> yi </strong>其中<strong class="lc iv"> i =1，2，…，m. </strong>最后将这些概率值与对应的 yi 值进行比较。最大概率值表示输出标注。</p><p id="5422" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">让我们用下面的例子简化一下。假设我们有一个由三个输入变量组成的<strong class="lc iv">‘天气状况’</strong>数据集，<strong class="lc iv">前景、温度和湿度、</strong>和相应的目标值<strong class="lc iv">‘播放’。</strong>我们试图根据输入变量找出某一天比赛的概率。假设我们要计算天气条件下打球的概率:<strong class="lc iv">前景=晴朗，温度=凉爽，湿度=正常。</strong></p><p id="d1a3" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">开始时，我们必须为特定输入变量转换频率表中的数据集，并计算可能性:</p><p id="a059" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">➣ <strong class="lc iv">为 Outlook 输入变量</strong></p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj ob"><img src="../Images/1d04e5477724f0580436b06f623fbd44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ORWQsWru-2b3LTYx7u_Wg.png"/></div></div></figure><p id="b664" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">温度输入变量的➣ <strong class="lc iv"/></p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj oc"><img src="../Images/ee70bd179667729eab1f82102fac71d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OURThx48r7Zv_HkQ0emmCw.png"/></div></div></figure><p id="ab61" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">湿度输入变量的➣ <strong class="lc iv"/></p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj od"><img src="../Images/d7cddc0b31a965df6442b91a6160876c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mao0sPQvrviA-D6Q7cDHVg.png"/></div></div></figure><p id="3845" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这里，<em class="mk"> P(播放=是)= 0.5，P(播放=否)= 0.5 </em></p><p id="534e" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">现在，我们的配方准备应用贝叶斯定理来找出在那个雨天玩家是否会玩的输出。</p><blockquote class="oe of og"><p id="ff37" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> P(是|晴，......高)=P(晴|是)*P(凉|是)*P(正常|是)*P(是)/(P(晴)*P(凉)*P(正常)</em></p><p id="64f4" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><strong class="lc iv">从上表</strong></p><p id="0aed" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> P(晴|是)= 1/4 = 0.25 </em></p><p id="1711" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> P(酷|是)=2/4 = 0.5 </em></p><p id="23ef" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> P(正常|是)=2/4 = 0.5 </em></p><p id="28b0" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> P(晴天)= 0.375 </em></p><p id="905b" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> P(酷)= 0.375 </em></p><p id="9908" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> P(正常)= 0.375 </em></p><p id="a0d8" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> P(是)=4/8 = 0.375 </em></p><p id="c321" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu">所以 P(是|晴，…..高)=(0.25 * 0.5 * 0.5 * 0.375)/(0.375 * 0.375)=</em><strong class="lc iv"><em class="iu">0.444</em></strong></p><p id="6f40" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> P(无|晴……高)= P(晴|无)*P(凉|无)*P(正常|无)*P(无)/(P(晴)*P(凉)*P(正常))</em></p><p id="34fe" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><strong class="lc iv">根据上表</strong></p><p id="e3fc" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> P(晴|否)= 1/4 = 0.25 </em></p><p id="e78f" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> P(cool|No)=2/4 = 0.5 </em></p><p id="0407" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> P(正常|否)=2/4 = 0.5 </em></p><p id="3bb9" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> P(晴天)= 0.375 </em></p><p id="1a40" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> P(冷)= 0.375 </em></p><p id="ceb2" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> P(正常)= 0.375 </em></p><p id="69d6" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> P(否)=4/8 = 0.625 </em></p><p id="7fb1" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu">所以 P(不|晴，…..高)=(0.25 * 0.5 * 0.5 * 0.625)/(0.375 * 0.375)* =</em><strong class="lc iv"><em class="iu">0.740740</em></strong></p></blockquote><p id="f2ff" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">所以，我们从上面的计算中发现。</p><p id="f4bd" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><code class="fe ok ol om on b"><strong class="lc iv"><em class="mk">P(No|sunny,…..high) &gt; P(No|sunny,…..high)</em></strong></code></p><p id="da2c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><strong class="lc iv">因此，在雨天，玩家无法玩游戏。</strong></p><h2 id="da76" class="nd ne iu bd nf ng nh dn ni nj nk dp nl lj nm nn no ln np nq nr lr ns nt nu nv bi translated">朴素贝叶斯模型的✪类型</h2><p id="4c88" class="pw-post-body-paragraph la lb iu lc b ld nw jv lf lg nx jy li lj ny ll lm ln nz lp lq lr oa lt lu lv in bi translated">朴素贝叶斯模型的类型基于它们的分布。诸如</p><p id="3109" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">◉ <strong class="lc iv">伯努利朴素贝叶斯</strong></p><p id="9cb3" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">伯努利朴素贝叶斯是一种重要的朴素贝叶斯算法。这个模型以文档分类任务而闻名，它决定一个特定的单词是否留在文档中。在这些情况下，频率的计算就不那么重要了。这是最简化的算法。该算法对于小数据集最有效。伯努利朴素贝叶斯的决策规则是</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj oo"><img src="../Images/16fa5ffbf734d2fd38b967219cfd331a.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*37yzOp2rtakAvpf4t1lQ6w.png"/></div></figure><p id="b931" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">例如，您想知道文档中是否包含特定的单词。在这类二元分类中如真或假、成功或失败、0 或 1、玩或不玩等。，使用伯努利朴素贝叶斯分类。</p><p id="5749" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">◉ <strong class="lc iv">多项式朴素贝叶斯</strong></p><p id="f3b9" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">当我们研究术语“多项式”时，它的意思与多类分类密切相关。假设你对特定输出的频率感兴趣；多项式朴素贝叶斯算法是解决这一问题的合适算法。另一个例子是，您给了一个文本文档来查找文档中某个特定单词的出现次数。在这种情况下，您必须应用多项式朴素贝叶斯算法。对于多项式朴素贝叶斯算法，使用多项式分布函数。多项式分布函数:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj op"><img src="../Images/c35ce246fdc32d27b4f907eefce96cc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*mq9K2W5OCUpkuCMGetfQ4Q.png"/></div></figure><p id="1e4c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在这里，我们将展示方程，并用下面的一个实例来找出<strong class="lc iv"> P </strong>的过程。例如，我们从城市人口<strong class="lc iv"> <em class="mk">(孟加拉达卡的拉杰巴里)</em> </strong>中收集了血型样本。此外，计算样本中每个血型的概率。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj oq"><img src="../Images/d3837239bd0228c3b97e8f857ab181e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H4A9_UP4S-j6ObLF7Yhqsw.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="d52b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">现在，你出了一道题，随机取 9 个人，计算一下。</p><blockquote class="oe of og"><p id="cf0f" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu">这里，n1 = O+的频率值，</em></p><p id="0984" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> n2 =频率值 A，</em></p><p id="d1e6" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> n3 =频率值 B，</em></p><p id="d1f0" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu"> n4 =频率值 AB </em></p><p id="2c9c" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu">这里，n=9，随机样本的总数。</em></p><p id="02e8" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu">另外，p1 = 0.44 =样本中 O+血型的概率，</em></p><p id="7833" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu">p2 = 0.42 =样本中 A 血型的概率，</em></p><p id="237a" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu">P3 = 0.10 =样本中 B 血型的概率，</em></p><p id="c9c7" class="la lb mk lc b ld le jv lf lg lh jy li oh lk ll lm oi lo lp lq oj ls lt lu lv in bi translated"><em class="iu">P3 = 0.04 =样本中 AB 血型的概率</em></p></blockquote><p id="62a4" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">现在，只要把上面的值代入方程，就会得到多项式朴素贝叶斯的概率。</p><h2 id="b28e" class="nd ne iu bd nf ng nh dn ni nj nk dp nl lj nm nn no ln np nq nr lr ns nt nu nv bi translated">◉ <strong class="ak">高斯朴素贝叶斯</strong></h2><p id="ad7b" class="pw-post-body-paragraph la lb iu lc b ld nw jv lf lg nx jy li lj ny ll lm ln nz lp lq lr oa lt lu lv in bi translated">伯努利朴素贝叶斯和多项式朴素贝叶斯用于离散类型数据集。但是我们将使用真实世界的连续数据。在这种情况下，我们需要使用高斯朴素贝叶斯定理。高斯分布或正态分布函数看起来如下:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj or"><img src="../Images/b44797d0eaab39592eb87ba1f56d1751.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*GfyosAo50C6tMkKhS9NOOw.png"/></div></figure><h2 id="49e5" class="nd ne iu bd nf ng nh dn ni nj nk dp nl lj nm nn no ln np nq nr lr ns nt nu nv bi translated">朴素贝叶斯算法的✪从头实现</h2><p id="69b6" class="pw-post-body-paragraph la lb iu lc b ld nw jv lf lg nx jy li lj ny ll lm ln nz lp lq lr oa lt lu lv in bi translated">为了从零开始实现朴素贝叶斯，我们将一步一步地接近:</p><pre class="kk kl km kn gu os on ot ou aw ov bi"><span id="73d6" class="nd ne iu on b gz ow ox l oy oz">#importing necessary libraries<br/>import numpy as np <br/>import pandas as pd</span></pre><p id="b737" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">➣从头开始创建用于实现朴素贝叶斯算法的数据集。</p><pre class="kk kl km kn gu os on ot ou aw ov bi"><span id="8a96" class="nd ne iu on b gz ow ox l oy oz">from sklearn.datasets import load_breast_cancer<br/>cancer = load_breast_cancer()</span><span id="68bb" class="nd ne iu on b gz pa ox l oy oz">data = pd.DataFrame(data=cancer.data, columns=cancer.feature_names)<br/>data['diagnosis'] = cancer.target</span><span id="b51d" class="nd ne iu on b gz pa ox l oy oz">data = data[["mean radius", "mean texture", "mean smoothness", "diagnosis"]]<br/>data.head(10)</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj pb"><img src="../Images/30525ef99e3fc5e31535be0a0054a587.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*Ikf5KC91atZCKgpOw3ivbg.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="pc pd l"/></div></figure><p id="02a1" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">➣:首先，我们要计算先验概率。我们已经创建了一个函数<strong class="lc iv">calculate _ prior _ probability</strong>，其中您将数据帧、df 和 Y 作为输入，并返回先验概率值。<em class="mk">如</em><strong class="lc iv"><em class="mk">P(Y =是)</em> </strong> <em class="mk">或</em><strong class="lc iv"><em class="mk">P(Y =否)。</em> </strong></p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="pe pd l"/></div></figure><p id="0c9b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">➣当我们创建函数<strong class="lc iv"> cal_likelihood_gau 时，我们必须计算条件概率。我们</strong>将输入必要的数据，计算给定 Y 标签时输入变量<strong class="lc iv"> X </strong>的概率，这意味着概率<strong class="lc iv"> X </strong>给定<strong class="lc iv"> Y </strong>。该函数返回将被进一步使用的<strong class="lc iv"> pro_x_given_y，</strong>。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="pe pd l"/></div></figure><p id="c1ae" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">➣最后，你必须建立模型，并使用前面的两个函数<strong class="lc iv">calculate _ prior _ probability</strong>和<strong class="lc iv"> cal_likelihood_gau 计算后验概率。</strong></p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="pe pd l"/></div></figure><p id="61a0" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">➣从上面的<code class="fe ok ol om on b">naive_bayes_gaussian() function.</code>中预测最终产量</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="pe pd l"/></div></figure><p id="5b1a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">输出</p><pre class="kk kl km kn gu os on ot ou aw ov bi"><span id="7c88" class="nd ne iu on b gz ow ox l oy oz">[[36  4]  <br/> [ 0 74]] <br/>0.9736842105263158</span></pre><h2 id="c958" class="nd ne iu bd nf ng nh dn ni nj nk dp nl lj nm nn no ln np nq nr lr ns nt nu nv bi translated">使用 Sckit-learn 的朴素贝叶斯算法的✪Implementation</h2><p id="adc4" class="pw-post-body-paragraph la lb iu lc b ld nw jv lf lg nx jy li lj ny ll lm ln nz lp lq lr oa lt lu lv in bi translated">➣使用 Sckit-learn 导入实现朴素贝叶斯算法所需的库。这里，我们将实现伯努利、高斯和多项式朴素贝叶斯算法。</p><pre class="kk kl km kn gu os on ot ou aw ov bi"><span id="857b" class="nd ne iu on b gz ow ox l oy oz">from sklearn import metrics<br/>import urllib<br/>from sklearn.naive_bayes import BernoulliNB,GaussianNB, MultinomialNB<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.model_selection import train_test_split</span></pre><p id="296c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">➣拆分数据集，用于训练、测试和转换数据以适应模型。</p><pre class="kk kl km kn gu os on ot ou aw ov bi"><span id="a4f0" class="nd ne iu on b gz ow ox l oy oz">train, test = train_test_split(data, test_size=.2, random_state=41)<br/>X_train=train.iloc[:,:-1].values<br/>y_train=train.iloc[:,-1].values<br/>X_test = test.iloc[:,:-1].values<br/>y_test = test.iloc[:,-1].values</span></pre><p id="0845" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">➣最后，训练模型，测试准确性，并显示混淆度量。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="pe pd l"/></div></figure><p id="29bf" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">输出</p><pre class="kk kl km kn gu os on ot ou aw ov bi"><span id="3e9f" class="nd ne iu on b gz ow ox l oy oz">0.6491228070175439 <br/>0.7368421052631579 <br/>0.9649122807017544 <br/>0.9736842105263158 <br/>[[36  4]  <br/> [ 0 74]]</span></pre><p id="5a83" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">上述结果清楚地表明，当数据集包含连续值时，高斯朴素贝叶斯算法优于其他朴素贝叶斯算法。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj pf"><img src="../Images/fbfa82f0910e2e2101246454c0e8d6e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/1*upqtCZ-WLLpKrQ1LbvFY4g.gif"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">来源:<a class="ae kz" href="https://upload.wikimedia.org/wikipedia/commons/b/b4/Naive_Bayes_Classifier.gif" rel="noopener ugc nofollow" target="_blank">https://upload . wikimedia . org/Wikipedia/commons/b/B4/Naive _ Bayes _ classifier . gif</a></p></figure><p id="74d4" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">上面的 gif 演示了朴素贝叶斯分类器是如何工作的。</p><h2 id="71e6" class="nd ne iu bd nf ng nh dn ni nj nk dp nl lj nm nn no ln np nq nr lr ns nt nu nv bi translated">结论</h2><p id="9297" class="pw-post-body-paragraph la lb iu lc b ld nw jv lf lg nx jy li lj ny ll lm ln nz lp lq lr oa lt lu lv in bi translated">朴素贝叶斯分类器是监督学习中一种简单易行但功能强大的分类算法。如果我们考虑数据集的分布，它在分类提供有效结果的情况下表现良好。更准确地说，当存在对事件的先前发生的依赖性时。在自然语言处理中，有时算法显示出有希望的结果。</p><p id="86aa" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><strong class="lc iv">参考文献</strong></p><p id="cbb0" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">1.<a class="ae kz" href="https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2017/09/naive-Bayes-explained/</a></p><p id="bc9e" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">2 . https://www . Java point . com/machine-learning-naive-Bayes-classifier</p></div><div class="ab cl pg ph hy pi" role="separator"><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl"/></div><div class="in io ip iq ir"><h2 id="dfd2" class="nd ne iu bd nf ng nh dn ni nj nk dp nl lj nm nn no ln np nq nr lr ns nt nu nv bi translated">关于数据科学统计学的完整系列文章</h2><ol class=""><li id="7bea" class="lw lx iu lc b ld nw lg nx lj pn ln po lr pp lv pq mc md me bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/less-is-more-the-art-of-sampling-dda8b59d399?source=your_stories_page-------------------------------------"> <em class="mk">少即是多；采样的‘艺术’(Stat-01)</em></a></li><li id="ad17" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv pq mc md me bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/get-familiar-with-the-most-important-weapon-of-data-science-variables-48cc7cd85dc5?source=your_stories_page-------------------------------------"> <em class="mk">熟悉数据科学最重要的武器~变量(Stat-02) </em> </a></li><li id="5913" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv pq mc md me bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/to-increase-data-analysing-power-you-must-know-frequency-distribution-afa438c3e7a4?source=your_stories_page-------------------------------------"> <em class="mk">要提高数据分析能力，您必须了解频率分布(Stat-03) </em> </a></li><li id="69cf" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv pq mc md me bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/find-the-patterns-of-a-dataset-by-visualizing-frequency-distribution-c5718ab1f2c2?source=your_stories_page-------------------------------------"> <em class="mk">通过可视化频率分布找到数据集的模式(Stat-04) </em> </a></li><li id="3202" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv pq mc md me bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/compare-multiple-frequency-distributions-to-extract-valuable-information-from-a-dataset-10cba801f07b?source=your_stories_page-------------------------------------"> <em class="mk">比较多个频率分布，从数据集中提取有价值的信息(Stat-05) </em> </a></li><li id="6f98" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv pq mc md me bi translated"><a class="ae kz" href="https://medium.datadriveninvestor.com/eliminate-your-misconception-about-mean-with-a-brief-discussion-a9fed67d4b08?source=your_stories_page-------------------------------------" rel="noopener ugc nofollow" target="_blank"> <em class="mk">通过简短的讨论消除你对 Mean 的误解(Stat-06) </em> </a></li><li id="ef3c" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv pq mc md me bi translated"><a class="ae kz" href="https://medium.datadriveninvestor.com/increase-your-data-science-model-efficiency-with-normalization-918484b4626f?source=your_stories_page-------------------------------------" rel="noopener ugc nofollow" target="_blank"> <em class="mk">通过规范化提高您的数据科学模型效率(Stat-07) </em> </a></li><li id="039e" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv pq mc md me bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/basic-probability-concepts-for-data-science-eb8e08c9ad92?source=your_stories_page-------------------------------------"> <em class="mk">数据科学的基本概率概念(Stat-08) </em> </a></li><li id="8f90" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv pq mc md me bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/road-map-from-naive-bayes-theorem-to-naive-bayes-classifier-6395fc6d5d2a?source=your_stories_page-------------------------------------"> <em class="mk">从朴素贝叶斯定理到朴素贝叶斯分类器的路线图(Stat-09) </em> </a></li><li id="7134" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv pq mc md me bi translated"><a class="ae kz" href="https://medium.datadriveninvestor.com/all-you-need-to-know-about-hypothesis-testing-for-data-science-enthusiasts-30cfe1dce028?source=your_stories_page-------------------------------------" rel="noopener ugc nofollow" target="_blank"> <em class="mk">数据科学爱好者需要知道的假设检验(Stat-10) </em> </a></li><li id="80fc" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv pq mc md me bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/statistical-comparison-among-multiple-groups-with-anova-d4ac27f6e59e?source=your_stories_page-------------------------------------"> <em class="mk">多组间统计比较用 ANOVA (Stat-11) </em> </a></li><li id="0f4f" class="lw lx iu lc b ld mf lg mg lj mh ln mi lr mj lv pq mc md me bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/compare-dependency-of-categorical-variables-with-chi-square-test-982baff64e81?source=your_stories_page-------------------------------------"> <em class="mk">用卡方检验比较分类变量的相关性(Stat-12) </em> </a></li></ol></div></div>    
</body>
</html>