<html>
<head>
<title>Statistics in Python — Understanding Variance, Covariance, and Correlation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的统计学-了解方差、协方差和相关性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/statistics-in-python-understanding-variance-covariance-and-correlation-4729b528db01?source=collection_archive---------4-----------------------#2021-09-29">https://towardsdatascience.com/statistics-in-python-understanding-variance-covariance-and-correlation-4729b528db01?source=collection_archive---------4-----------------------#2021-09-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="67bb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理解数据之间的关系，知道皮尔逊相关系数和斯皮尔曼等级相关系数之间的区别</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6cb0466b13706265e0b26a81a4b7fea6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xXgt_qcD3qF7ghEM"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@kirklai?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> 𝓴𝓘𝓡𝓚 𝕝𝔸𝕀 </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="2a52" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据科学家必须了解的一个主题是数据集中存在的关系。在开始机器学习过程之前，准备好数据以便只有数据集的相关部分用于训练是至关重要的。要了解数据集中的关系，您需要了解以下概念:</p><ul class=""><li id="3a5a" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">差异</li><li id="c8c1" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">协方差</li><li id="23b3" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">相互关系</li></ul><p id="d8bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">和往常一样，我的目的是让你容易消化这些话题。我们开始吧！</p><h1 id="1611" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">创建样本数据集</h1><p id="50c8" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">为了理解数据集中的关系，让我们创建一个简单的关系并加载到Pandas数据框架中:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="1687" class="nl mk it nh b gy nm nn l no np">import pandas as pd<br/>import numpy as np</span><span id="6c48" class="nl mk it nh b gy nq nn l no np">df = pd.DataFrame({<br/>    'a':[1,3,4,6,8],<br/>    'b':[2,3,5,6,8],<br/>    'c':[6,5,4,3,2],<br/>    'd':[5,4,3,4,6]<br/>})<br/>df</span></pre><p id="5c20" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据帧包含五行和四列:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/68780d211c0d85c33bf520e0366e8771.png" data-original-src="https://miro.medium.com/v2/resize:fit:224/format:webp/1*onyYm-dm9gB7MpdDpCn_NA.png"/></div></figure><h1 id="6903" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">差异</h1><p id="16be" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">方差是数据集中的值围绕其平均值的分布。它告诉你数据集中的每个数字离它的平均值有多远。方差(<strong class="lb iu"> s </strong>)的公式定义如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/13b64fa415a3c6dba4906c659ec54e6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*svs4R44GU6esJ-xYiyoIFQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><blockquote class="nt nu nv"><p id="f053" class="kz la nw lb b lc ld ju le lf lg jx lh nx lj lk ll ny ln lo lp nz lr ls lt lu im bi translated">F <!-- -->或<strong class="lb iu">样本方差</strong>，分母为<strong class="lb iu"> n-1 </strong>。对于<strong class="lb iu">人口方差</strong>，分母为<strong class="lb iu"> n </strong>。</p></blockquote><p id="4194" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">方差</strong> ( <strong class="lb iu"> s </strong>)的平方根就是<strong class="lb iu">标准差</strong> ( <strong class="lb iu"> s </strong>)。方差的计算方法是，取数据集中每个数字与平均值的差，对所有差求和，最后除以数据集中值的个数。</p><blockquote class="nt nu nv"><p id="0c90" class="kz la nw lb b lc ld ju le lf lg jx lh nx lj lk ll ny ln lo lp nz lr ls lt lu im bi translated">较大的方差表明数据集中的数字远离平均值，并且彼此远离。另一方面，较小的方差表明这些数字接近平均值并且彼此接近。方差为0表示数据集中的所有数字都相同。最后，方差的有效值总是正数(0或更大)。</p></blockquote><p id="2d0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通常，能够可视化数据集中数字的分布是很有用的，这样您可以更好地理解方差的概念。</p><p id="ee1a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用Seaborn，您可以绘制一个带状图和一个盒状图来显示列<strong class="lb iu"> a </strong>到<strong class="lb iu"> d </strong>中的数字分布:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="63fc" class="nl mk it nh b gy nm nn l no np">import seaborn as sns</span><span id="a4e8" class="nl mk it nh b gy nq nn l no np">g = sns.stripplot(data = df.melt(), <br/>                  x = 'variable', <br/>                  y = 'value', <br/>                  color = 'red')</span><span id="f7e9" class="nl mk it nh b gy nq nn l no np">sns.boxplot(data = df.melt(),<br/>            x = 'variable', <br/>            y = 'value', <br/>            color = 'yellow')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/7a47793c42902a54edd328f627e1042d.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*pbB5M2GLzveQ3rnvlB7Wxg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="cb01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如您所见，列<strong class="lb iu"> a </strong>中的值比其他列分散得多，同样，列<strong class="lb iu"> b </strong>中的值比<strong class="lb iu"> b </strong>和<strong class="lb iu"> c </strong>中的值分散得多，依此类推。与其余列相比，<strong class="lb iu"> d </strong>中的值是最接近的分组。因此，你会期望a<strong class="lb iu">的方差最大，d<strong class="lb iu">的方差最小。</strong></strong></p><h2 id="97f5" class="nl mk it bd ml ob oc dn mp od oe dp mt li of og mv lm oh oi mx lq oj ok mz ol bi translated">使用NumPy计算方差</h2><p id="0474" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">使用NumPy，很容易计算一系列数字的方差。下面是根据前面看到的公式计算列<strong class="lb iu"> a </strong>的方差的语句:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="c2d8" class="nl mk it nh b gy nm nn l no np">(np.square(df['a'] - df['a'].mean())).sum() / (df.shape[0] - 1)<br/># 7.3</span></pre><p id="6273" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，NumPy也有<strong class="lb iu"> var() </strong>函数来计算一个数组的方差。您可以直接将数据帧传递给<strong class="lb iu"> var() </strong>函数来计算数据帧中一系列列的方差:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="77d1" class="nl mk it nh b gy nm nn l no np"><strong class="nh iu">np.var(df[['a','b','c','d']], ddof=1)</strong><br/># a    7.3<br/># b    5.7<br/># c    2.5<br/># d    1.3<br/># dtype: float64</span></pre><blockquote class="nt nu nv"><p id="cf14" class="kz la nw lb b lc ld ju le lf lg jx lh nx lj lk ll ny ln lo lp nz lr ls lt lu im bi translated"><strong class="lb iu"> ddof </strong>代表<strong class="lb iu"> Delta自由度</strong>。该值用于方差计算的分母(<strong class="lb iu"> n — ddof </strong>)，其中n代表元素的数量。默认情况下，ddof为零(总体方差)。当的<strong class="lb iu">DD设置为<strong class="lb iu"> 1 </strong>时，您正在计算样本方差。</strong></p></blockquote><p id="f409" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如所料，您可以看到列<strong class="lb iu"> a </strong>的方差最大，列<strong class="lb iu"> d </strong>的方差最小。</p><h1 id="6b6c" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">协方差</h1><p id="c56e" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">既然您已经看到了每一列的差异，现在是时候看看列之间是如何相互关联的了。<strong class="lb iu">方差</strong>测量数据在其均值内的分布，<strong class="lb iu">协方差</strong>测量<em class="nw">两个</em>随机变量之间的关系。</p><blockquote class="nt nu nv"><p id="2c4b" class="kz la nw lb b lc ld ju le lf lg jx lh nx lj lk ll ny ln lo lp nz lr ls lt lu im bi translated">在统计学中，<strong class="lb iu">协方差</strong>是两个随机变量之间方向关系的度量。</p></blockquote><p id="c074" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们绘制一个散点图，看看数据框架中的列是如何相互关联的。我们将首先从<strong class="lb iu"> a </strong>和<strong class="lb iu"> b </strong>列开始:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="ff97" class="nl mk it nh b gy nm nn l no np">import matplotlib.pyplot as plt<br/>plt.scatter(df['a'], df['b'])<br/>plt.xlabel('a')<br/>plt.ylabel('b')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/b70cf9cdd903ce68e96ad40750afa6d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*svRpFFjfOrKG0RK7974q-w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="47f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如你所看到的，在<strong class="lb iu"> a </strong>和<strong class="lb iu"> b </strong>之间似乎有一种趋势——随着<strong class="lb iu"> a </strong>增加，<strong class="lb iu"> b </strong>也增加。</p><blockquote class="nt nu nv"><p id="bfc0" class="kz la nw lb b lc ld ju le lf lg jx lh nx lj lk ll ny ln lo lp nz lr ls lt lu im bi translated">在统计学中，已知<strong class="lb iu"> a </strong>和<strong class="lb iu"> b </strong>有一个<strong class="lb iu">正</strong>协方差。正协方差表示两个随机变量倾向于同时向上或向下移动。</p></blockquote><p id="2e7b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">列<strong class="lb iu"> b </strong>和<strong class="lb iu"> c </strong>怎么样？让我们看看:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="7153" class="nl mk it nh b gy nm nn l no np">plt.scatter(df['b'], df['c'])<br/>plt.xlabel('b')<br/>plt.ylabel('c')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/f47c5ed4e4c0a6257bd211fc55c81082.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*n2_jtGh3sd_0fscDw78CPA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="e621" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这一次，趋势似乎向相反的方向发展——随着<strong class="lb iu"> b </strong>增加，<strong class="lb iu"> c </strong>减少。</p><blockquote class="nt nu nv"><p id="a902" class="kz la nw lb b lc ld ju le lf lg jx lh nx lj lk ll ny ln lo lp nz lr ls lt lu im bi translated">在统计学中，<strong class="lb iu"> b </strong>和<strong class="lb iu"> c </strong>已知具有负<strong class="lb iu">协方差。负协方差表示两个变量倾向于彼此远离，当一个向上移动时，另一个向下移动，反之亦然。</strong></p></blockquote><p id="7583" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，让我们检查列<strong class="lb iu"> c </strong>和<strong class="lb iu"> d </strong>:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="5751" class="nl mk it nh b gy nm nn l no np">plt.scatter(df['c'], df['d'])<br/>plt.xlabel('c')<br/>plt.ylabel('d')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/c9b74a48082d463e25eb012389a5f892.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*HzhXjf7E8Uo4Kh6c9sR8Ww.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="34a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> c </strong>和<strong class="lb iu"> d </strong>之间似乎不存在直接的线性关系。</p><blockquote class="nt nu nv"><p id="32cc" class="kz la nw lb b lc ld ju le lf lg jx lh nx lj lk ll ny ln lo lp nz lr ls lt lu im bi translated">在统计学中，<strong class="lb iu"> c </strong>和<strong class="lb iu"> d </strong>已知有<strong class="lb iu">零</strong>协方差(或接近零)。当两个随机变量独立时，协方差将为零。<strong class="lb iu">然而，反过来就不一定了——协方差为零并不意味着两个随机变量是独立的(在协方差为零的两个随机变量之间仍然存在非线性关系)。在上面的例子中，你可以看到存在某种非线性的v形关系。</strong></p></blockquote><p id="c240" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数学上，<strong class="lb iu">协方差</strong>的公式定义如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/cefa07a77f27dc76c01be88e2b1106e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*JxqOikQflNrmsoImC_vnsQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="ea8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">计算两个随机变量之间的协方差的方法是，取每个随机变量的值与其平均值之间的差值的乘积，对所有乘积求和，最后除以数据集中值的数量。</p><p id="53f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像往常一样，让我们使用NumPy手动计算<strong class="lb iu"> a </strong>和<strong class="lb iu"> b </strong>之间的协方差:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="72f1" class="nl mk it nh b gy nm nn l no np">#---covariance for a and b---<br/>((df['a'] -  df['a'].mean()) * (df['b'] -  df['b'].mean())).sum() / (df.shape[0] - 1)<br/># 6.35</span></pre><p id="47a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像方差一样，NumPy有<strong class="lb iu"> cov() </strong>函数来直接计算两个随机变量的协方差:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="1839" class="nl mk it nh b gy nm nn l no np">np.cov(df['a'],df['b'])<br/># array([[7.3 , 6.35],<br/>#        [6.35, 5.7 ]])</span></pre><p id="958b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> cov() </strong>函数的输出是一个包含以下值的2D数组:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/b3eaf06d629ce4432c34db21d09827c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*SbnRAABBjYSUXPTUGdUDaw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="a372" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，a和b的协方差是6.35(正协方差)。</p><p id="5828" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是<strong class="lb iu"> b </strong>和<strong class="lb iu"> c </strong>的协方差(-3.75，负协方差):</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="15b6" class="nl mk it nh b gy nm nn l no np">np.cov(df['b'], df['c'])<br/># array([[ 5.7 , -3.75],<br/>#        [-3.75,  2.5 ]])</span></pre><p id="68d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以及<strong class="lb iu"> c </strong>和<strong class="lb iu"> d </strong>的协方差(-0.5，负协方差):</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="7724" class="nl mk it nh b gy nm nn l no np">np.cov(df['c'], df['d'])<br/># array([[ 2.5, -0.5],<br/>#        [-0.5,  1.3]])</span></pre><blockquote class="nt nu nv"><p id="3a06" class="kz la nw lb b lc ld ju le lf lg jx lh nx lj lk ll ny ln lo lp nz lr ls lt lu im bi translated">虽然协方差测量2个随机变量之间的方向关系，但它不显示2个随机变量之间关系的<strong class="lb iu">强度</strong>。其值不受约束，可以从-无穷大到+无穷大。</p></blockquote><p id="6380" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，协方差取决于值的比例。例如，如果您将列<strong class="lb iu"> a </strong>和<strong class="lb iu"> b </strong>中的每个值加倍，您将获得不同的协方差:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="cee0" class="nl mk it nh b gy nm nn l no np">np.cov(df['a']*2, df['b']*2)<br/># array([[29.2, <strong class="nh iu">25.4</strong>],<br/>#        [<strong class="nh iu">25.4</strong>, 22.8]])</span></pre><p id="dc22" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">测量两个随机变量强度的一个更好的方法是<em class="nw">相关性</em>，我们将在接下来讨论。</p><h1 id="6e59" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><span class="l op oq or bm os ot ou ov ow di">C</span>or关系</h1><p id="65fa" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">两个随机变量之间的相关性测量它们之间存在的线性关系的<em class="nw">强度</em>和<em class="nw">方向</em>。有两种方法来衡量相关性:</p><ul class=""><li id="2102" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">皮尔逊相关系数</strong> —捕捉两个连续变量之间的<em class="nw">线性</em>关联的强度和方向</li><li id="a9f0" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu"> Spearman等级相关系数</strong>—确定两个有序(分类)或连续变量之间存在的<em class="nw">单调</em>关系的强度和方向。</li></ul><h2 id="add9" class="nl mk it bd ml ob oc dn mp od oe dp mt li of og mv lm oh oi mx lq oj ok mz ol bi translated"><strong class="ak">皮尔逊相关系数</strong></h2><p id="e7fe" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">皮尔逊相关系数的公式为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/e9bbc1aeaae05dafc7e2922507ad1b29.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*8C_VvGhYWJFJft8vlmO3sw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="fd58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">皮尔逊相关系数</strong>定义为x和y的协方差除以每个随机变量的标准差的乘积。</p><p id="6939" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将公式中的<strong class="lb iu">协方差</strong>和标准偏差<strong class="lb iu"> x </strong>和<strong class="lb iu"> y </strong>代入，得到:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/fc586f00ec921350ce5b01ec7329ab85.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*LGFou3562E93Zl8SyHhxyw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="93e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简化后，公式现在看起来像这样:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/e222b2b6a1b4571aaba6c58f47a56b0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*2f04QlXVGUh3k56yt3PobA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="2a68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Pandas有一个函数<strong class="lb iu"> corr() </strong>计算数据帧中各列的相关性:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="7491" class="nl mk it nh b gy nm nn l no np">df[['a','b']].corr()</span></pre><p id="8986" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/b2816a4cec0490af123dd50bb63b2ed4.png" data-original-src="https://miro.medium.com/v2/resize:fit:328/format:webp/1*BDmVWVDgNMZ0cJ6wcnPaJg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="29b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对角线值为1表示每列与其自身的相关性。显然，<strong class="lb iu"> a </strong>与<strong class="lb iu"> a </strong>本身的相关性为1，对于列<strong class="lb iu"> b </strong>也是如此。<strong class="lb iu"> 0.984407 </strong>的值是<strong class="lb iu"> a </strong>和<strong class="lb iu"> b </strong>的皮尔逊相关系数。</p><p id="eb3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> b </strong>和<strong class="lb iu"> c </strong>的皮尔逊相关系数为<strong class="lb iu"> -0.993399 </strong>:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="e9d7" class="nl mk it nh b gy nm nn l no np">df[['b','c']].corr()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/213a7abb2184204a87913a98cf3769f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:336/format:webp/1*ujllEO6IOuE1Tuup1To6lw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="c73c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> c </strong>和<strong class="lb iu"> d </strong>的皮尔逊相关系数为<strong class="lb iu"> -0.27735 </strong>:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="797f" class="nl mk it nh b gy nm nn l no np">df[['c','d']].corr()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/1984eee3792f7a370af57ce14b1d6e84.png" data-original-src="https://miro.medium.com/v2/resize:fit:304/format:webp/1*WW2xAmI7V-R2b1sgLugRYA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="9888" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像协方差一样，皮尔逊相关系数的符号表示关系的方向。然而，皮尔逊相关系数的值被限制在-1和1之间。根据该值，您可以推导出以下相关度:</p><ul class=""><li id="d270" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">完美</strong> —接近1的值</li><li id="472f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">高度数</strong> —介于0.5和1之间的数值</li><li id="5750" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">中度</strong> —介于0.3和0.49之间的值</li><li id="3b08" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">低度</strong> —低于0.29的值</li><li id="e283" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">无相关性</strong> —数值接近0</li></ul><p id="482e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上面的结果可以看出，<strong class="lb iu"> a，b </strong>，和<strong class="lb iu"> b，c </strong>的相关度很高，而<strong class="lb iu"> c，d </strong>的相关度很低。</p><blockquote class="nt nu nv"><p id="e731" class="kz la nw lb b lc ld ju le lf lg jx lh nx lj lk ll ny ln lo lp nz lr ls lt lu im bi translated"><strong class="lb iu">了解数据集中各列之间的相关性是为机器学习准备数据过程中的一个重要部分。您希望使用与数据集标签相关性最高的列来定型您的模型。</strong></p></blockquote><p id="e368" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与协方差不同，相关性不受值的比例影响。作为实验，将列<strong class="lb iu"> a </strong>和<strong class="lb iu"> b </strong>相乘，您会发现它们的相关性:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="ad68" class="nl mk it nh b gy nm nn l no np">df['2a'] = df['a']*2     # multiply the values in a by 2<br/>df['2b'] = df['b']*2     # multiply the values in b by 2<br/>df[['2a','2b']].corr()   # the result is the same as<br/>                         # df[['a','b']].corr()</span></pre><p id="fb6b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果与<strong class="lb iu"> a </strong>和<strong class="lb iu"> b </strong>相同:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/aa2e33de64344546a135d1b45e7ce485.png" data-original-src="https://miro.medium.com/v2/resize:fit:326/format:webp/1*rxsmdAKMtxXfIcy6oMWTXg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h2 id="8a21" class="nl mk it bd ml ob oc dn mp od oe dp mt li of og mv lm oh oi mx lq oj ok mz ol bi translated"><strong class="ak">斯皮尔曼等级相关系数</strong></h2><p id="8c4d" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">如果你的数据不是线性分布，你应该用<strong class="lb iu"> Spearman的秩相关系数</strong>而不是<strong class="lb iu"> Pearson相关系数。</strong><strong class="lb iu">斯皮尔曼秩相关系数</strong>是为<em class="nw">单调</em>的分布设计的。</p><blockquote class="nt nu nv"><p id="ea4a" class="kz la nw lb b lc ld ju le lf lg jx lh nx lj lk ll ny ln lo lp nz lr ls lt lu im bi translated">在代数中，<strong class="lb iu">一次函数</strong>是一个梯度从不改变符号的函数。换句话说，它是一个要么总是增加，要么总是减少的函数。接下来的前两个数字是单调的，而第三个不是(因为梯度从左到右改变几次符号)。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/044902005d90b65c6b509339e3791e39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ydjx6S8a25EMMfg6auRTdQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://en.wikipedia.org/wiki/Monotonic_function" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Monotonic_function</a></p></figure><p id="15db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">斯皮尔曼等级相关系数的公式为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/7e595fc8841495a08cb0a5c43fbfdd04.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*LUC48bfZrEiEsc_qTCOXVg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="0f9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中<strong class="lb iu"> d </strong>是两个随机变量之间的等级差。举个例子就清楚了。</p><p id="231d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于本例，我将有另一个数据帧:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="c870" class="nl mk it nh b gy nm nn l no np">df = pd.DataFrame({<br/>    'math'   :[78,89,75,67,60,58,71],<br/>    'science':[91,92,90,80,60,56,84]<br/>})<br/>df</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/e65854788db5d81091e501423f7e56cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:260/format:webp/1*COt2kSVjkBqTAfLvgSb9lw.png"/></div></figure><p id="65ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先将数据可视化是有用的:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="3805" class="nl mk it nh b gy nm nn l no np">plt.scatter(df['math'], df['science'])<br/>plt.xlabel('math')<br/>plt.ylabel('science')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/34572704d7f5231d586ef22b9005684d.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*wCmq6NgEtfJn0ROa5Z3j3Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="1eb6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这看起来像是单调分布。下一步是在Pandas中使用<strong class="lb iu"> rank() </strong>函数对分数进行排序:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="4f19" class="nl mk it nh b gy nm nn l no np">df['math_rank'] = df['math'].rank(ascending=False)<br/>df['science_rank'] = df['science'].rank(ascending=False)<br/>df</span></pre><p id="b88a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，您有两个额外的列包含每个科目的排名:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/a860609e7b0af65d606d0ac28358af64.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*RnQUBX3LNXwSFtt5CuFxEg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="9ac5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们再创建两个新列来存储等级与其平方值之间的差异:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="6691" class="nl mk it nh b gy nm nn l no np">df['diff'] = df['math_rank'] - df['science_rank']<br/>df['diff_sq'] = np.square(df['diff'])<br/>df</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/33eacb9ecba941b83a602bbb477ac342.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*Nv6xKAS7VYrmmMxjUUHGRQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="b6de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，您可以使用之前定义的公式计算<strong class="lb iu">斯皮尔曼等级相关系数</strong>:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="1cdb" class="nl mk it nh b gy nm nn l no np">n = df.shape[0]<br/>p = 1 - ((6 * df['diff_sq'].sum()) / (n * (n**2 - 1)))<br/>p   # 1.0</span></pre><p id="eb18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你会得到完美的1.0分！当然，为了省去手工计算<strong class="lb iu">斯皮尔曼秩相关系数</strong>的所有工作，您可以使用<strong class="lb iu"> corr() </strong>函数，并为<strong class="lb iu">方法</strong>参数指定“<em class="nw">斯皮尔曼</em>”:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="68b0" class="nl mk it nh b gy nm nn l no np">df[['math','science']].corr(method='spearman') </span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/87176065736823121d0cd6aaaf4eecb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/format:webp/1*QnkWwy4lPjP-Bu7b1aLDBw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="e4e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们用皮尔逊相关系数来计算相关性会怎么样？</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="d2f9" class="nl mk it nh b gy nm nn l no np">df[['math','science']].corr(method='pearson')</span></pre><p id="163d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您会得到以下内容:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/14de0f99259c71ead568cff6a71f5e92.png" data-original-src="https://miro.medium.com/v2/resize:fit:392/format:webp/1*tXuxdRFgBDbYuAmCNrgXJw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><blockquote class="nt nu nv"><p id="1adc" class="kz la nw lb b lc ld ju le lf lg jx lh nx lj lk ll ny ln lo lp nz lr ls lt lu im bi translated">请注意，我上面列出的Spearman等级相关系数公式是针对不同等级的情况(意味着数学或科学分数没有关系)。在等级相同的情况下，公式稍微复杂一点。为了简单起见，我将不进入并列等级的公式。函数<strong class="lb iu"> corr() </strong>将自动处理并列的等级。</p></blockquote><h2 id="7437" class="nl mk it bd ml ob oc dn mp od oe dp mt li of og mv lm oh oi mx lq oj ok mz ol bi translated">你应该使用哪种方法？皮尔逊或斯皮尔曼的</h2><p id="c36d" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">那么应该用哪种方法呢？请记住以下几点:</p><ul class=""><li id="7ec5" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">皮尔逊相关描述了<strong class="lb iu"> <em class="nw">线性</em> </strong>关系，而斯皮尔曼相关描述了<strong class="lb iu"> <em class="nw">单调</em> </strong>关系</li><li id="9246" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">散点图将有助于可视化数据，如果分布是线性的，请使用皮尔逊相关。如果是单调的，使用Spearman相关。</li><li id="063a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">您还可以同时应用这两种方法，并检查哪种方法执行得好。例如，如果结果显示spearman等级相关系数大于Pearson系数，则意味着您的数据具有单调关系，而不是线性关系(就像上面的示例)。</li></ul><h1 id="bec7" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><strong class="ak">总结</strong></h1><p id="2a83" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我希望你现在对方差、协方差和相关性的概念有了更清晰的认识。特别是相关性让你知道你的随机变量之间关系的强度和方向，你可以利用<strong class="lb iu">皮尔逊相关系数</strong>(对于线性关系)或<strong class="lb iu">斯皮尔曼等级相关系数</strong>(对于单调关系)方法。</p><div class="pm pn gp gr po pp"><a href="https://weimenglee.medium.com/membership" rel="noopener follow" target="_blank"><div class="pq ab fo"><div class="pr ab ps cl cj pt"><h2 class="bd iu gy z fp pu fr fs pv fu fw is bi translated">加入媒介与我的介绍链接-李伟孟</h2><div class="pw l"><h3 class="bd b gy z fp pu fr fs pv fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="px l"><p class="bd b dl z fp pu fr fs pv fu fw dk translated">weimenglee.medium.com</p></div></div><div class="py l"><div class="pz l qa qb qc py qd ks pp"/></div></div></a></div></div></div>    
</body>
</html>