<html>
<head>
<title>Using Machine Learning to Generate Image Captions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习生成图像字幕</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-machine-learning-to-generate-captions-for-images-f9a5797f31d6?source=collection_archive---------6-----------------------#2021-04-24">https://towardsdatascience.com/using-machine-learning-to-generate-captions-for-images-f9a5797f31d6?source=collection_archive---------6-----------------------#2021-04-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4249" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在本文中，我们将通过Python使用机器学习来为各种图像生成标题</h2></div><p id="aba3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">图像字幕是给图像加上适当标题的过程。作为一个人，这似乎是一个简单的任务，甚至一个五岁的孩子都可以轻松完成，但我们如何编写一个计算机程序，将输入作为图像，并生成标题作为输出？</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/6b7f2dd718a9aed4dd96bb2e11a9c4fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j0PH-FYpX5NHxAR7YBkcPQ.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">照片来自<a class="ae lu" href="https://unsplash.com/photos/0E_vhMVqL9g" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="c6b8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在深度神经网络最近发展之前，这个问题对于业内最聪明的人来说是不可思议的，但在深度神经网络出现之后，如果我们有所需的数据集，这是完全可能的。</p><p id="192c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，网络可以生成与下面的图片I相关的以下任何标题，即“<strong class="kk iu"><em class="lv"/></strong>”草地上的白狗“<strong class="kk iu"> <em class="lv">带褐色斑点的白狗</em> </strong>”或者甚至“<strong class="kk iu"> <em class="lv">草地上的狗和一些粉红色的花</em> </strong>”。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi lw"><img src="../Images/0d3bef5dfa685efdf070480437084514.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*1VhVFGT7jVTeZ3eUW6a10g.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">来自开源Flikr8k数据集的图像</p></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="9d47" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated"><strong class="ak">数据集</strong></h1><p id="3088" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">我们选择的数据集是'<strong class="kk iu"> <em class="lv"> Flickr 8k '。我们选择了这个数据，因为它很容易访问，并且具有完美的大小，可以在普通的PC上训练，也足以公平地训练网络来生成适当的字幕。数据分为三组，主要是包含6k图像的训练组、包含1k图像的dev组和包含1k图像的测试组。每个图像包含5个标题。其中一个例子如下:</em></strong></p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/e119434c216a644cfbee4667ffdfd145.png" data-original-src="https://miro.medium.com/v2/resize:fit:324/format:webp/1*BVw3FshlMBX9XLujFdwT4w.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">来自开源Flikr8k数据集的图像</p></figure><ol class=""><li id="5e78" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld nh ni nj nk bi translated">一个穿着粉色连衣裙的孩子正在入口通道爬上一组楼梯。</li><li id="2e33" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">一个女孩走进一栋木制建筑。</li><li id="afe3" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">一个小女孩爬进木制玩具屋。</li><li id="cfa2" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">一个小女孩爬楼梯去她的玩具屋。</li><li id="81fd" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld nh ni nj nk bi translated">一个穿着粉色连衣裙的小女孩走进了一个小木屋。</li></ol></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="cf33" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">数据清理:</h1><p id="72e4" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">任何机器学习程序的第一步也是最重要的一步是清理数据，去掉任何不需要的数据。当我们处理字幕中的文本数据时，我们将执行基本的清理步骤，如将所有字母转换为小写字母，因为对于计算机来说，<em class="lv">‘嘿’</em>和<em class="lv">‘嘿’</em>是两个完全不同的单词，删除特殊符号和标点符号，如*、(、$、%，并删除任何包含数字的单词。</p><p id="2c0d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们首先为我们的数据集中的所有唯一图片创建一个词汇表，即8000(图片数量)* 5(每张图片的标题)= 40000个标题。我们发现它等于8763。但是这些单词中的大多数只出现一两次，我们不希望它们出现在我们的模型中，因为它不会使我们的模型对异常值具有鲁棒性。因此，我们设置了一个阈值，即一个单词在我们的词汇表中最少出现10次，这相当于1652个独特的单词。</p><p id="d46b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们做的另一件事是给每个描述添加两个标记，以指示标题的开始和结束。这两个标记是<em class="lv">‘start seq’</em>和<em class="lv">‘end seq’</em>，分别代表字幕的开始和结束。</p><p id="10b3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们从导入所有需要的库开始:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="944e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们定义一些助手函数:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="a855" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们逐一解释:</p><ul class=""><li id="61dd" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld ns ni nj nk bi translated"><code class="fe nt nu nv nw b">load_doc</code>:获取文件的路径并返回该文件中的内容</li><li id="08b5" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld ns ni nj nk bi translated"><code class="fe nt nu nv nw b">load_descriptions</code>:获取包含描述的文件内容，并生成一个字典，以图像id作为关键字，以描述作为值列表</li><li id="c1c6" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld ns ni nj nk bi translated"><code class="fe nt nu nv nw b">clean_descriptions</code>:通过使所有字母小写，忽略数字和标点符号字符，以及只有一个字符的单词来清除描述</li><li id="1aac" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld ns ni nj nk bi translated"><code class="fe nt nu nv nw b">save_descriptions</code>:将描述词典作为文本文件保存到内存中</li><li id="7cce" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld ns ni nj nk bi translated"><code class="fe nt nu nv nw b">loads_set</code>:从文本文件中加载图像的所有唯一标识符</li><li id="e18f" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld ns ni nj nk bi translated"><code class="fe nt nu nv nw b">load_clean_descriptions</code>:使用上面提取的唯一标识符加载所有清理后的描述</li></ul></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="3e0f" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">数据预处理:</h1><p id="3f10" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">接下来，我们对图像和字幕进行一些数据预处理。图像基本上是我们的特征向量，即我们对网络的输入。这就是为什么我们需要在将它们传递到神经网络之前，将它们转换为固定大小的向量。为此，我们使用由Google Research<a class="ae lu" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank">【3】</a>创建的Inception V3模型(卷积神经网络)的迁移学习。该模型在'<em class="lv"> ImageNet' </em>数据集<a class="ae lu" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank">【4】</a>上进行训练，以对1000幅图像执行图像分类，但我们的目标不是执行分类，因此我们移除了最后一个softmax层，并为每幅图像提取了2048固定矢量，如下图所示:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nx"><img src="../Images/5b61a9768d28f950d7775f13c8b05997.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*s9G0iVEqwT3saRgb"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">概念网的体系结构</p></figure><p id="bec4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">字幕是我们模型的输出，也就是我们必须预测的东西。但是这种预测不会一下子发生，我们会一个字一个字地预测我们的字幕。为此，我们需要将每个单词编码成一个固定大小的向量(这将在下一节中完成)。为此，我们首先需要创建两个字典，即'<em class="lv">单词到索引'</em>，它将每个单词映射到一个索引，在我们的例子中是从1到1652，以及'<em class="lv">单词索引'</em>，它将每个索引映射到它对应的单词。我们要做的最后一件事是计算数据集中具有最大长度的描述的长度，以便我们可以填充所有其他描述，从而保持固定的长度。在我们的例子中，这个长度等于34。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="871c" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">单词嵌入:</h1><p id="e469" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">如前所述，我们将把每个单词映射到一个固定大小的向量(即200)，我们将使用一个预先训练的手套模型。最后，我们为词汇表中的所有1652个单词创建一个嵌入矩阵，其中包含词汇表中每个单词的固定大小的向量。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="c197" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们仔细分析这段代码:</p><ul class=""><li id="84db" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld ns ni nj nk bi translated">第1–5行:将所有训练图像的所有描述提取到一个列表中</li><li id="387f" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld ns ni nj nk bi translated">第9-18行:只选择那些在词汇表中出现超过10次的单词</li><li id="7d27" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld ns ni nj nk bi translated">第21–30行:创建一个单词索引和一个单词字典索引。</li><li id="effb" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld ns ni nj nk bi translated">第33–42行:将手套嵌入加载到字典中，以单词作为关键字，嵌入向量作为值</li><li id="2360" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld ns ni nj nk bi translated">第44–52行:使用上面加载的嵌入为我们的词汇表中的单词创建一个嵌入矩阵</li></ul></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="2973" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">数据准备:</h1><p id="7f50" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">这是这个项目最重要的方面之一。对于图像，我们需要使用前面描述的Inception V3模型将它们转换成一个固定大小的向量。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nq nr l"/></div></figure><ul class=""><li id="b894" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld ns ni nj nk bi translated">第1–22行:将训练和测试图像的路径加载到单独的列表中</li><li id="1ab6" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld ns ni nj nk bi translated">第25–53行:遍历训练集和测试集中的每个图像，将它们加载到固定大小，对它们进行预处理，使用InceptionV3模型提取特征，最后对它们进行整形。</li><li id="3f04" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld ns ni nj nk bi translated">第56–63行:将提取的特征保存到磁盘</li></ul><p id="5505" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们不会一下子预测我们的标题，也就是说，我们不会只是给计算机图像，然后让它为图像生成标题。我们要做的是给它图像的特征向量和标题的第一个单词，让它预测第二个单词。然后我们给它前两个字，让它预测第三个字。让我们考虑数据集部分中给出的图像和标题<em class="lv">‘一个女孩走进一座木制建筑’</em>。在这种情况下，在添加标记'<em class="lv"> startseq' </em>和<em class="lv"> 'endseq '之后，下面将是我们在每种情况下的输入(Xi)和输出(Yi)。</em></p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ny"><img src="../Images/22b35035645d5b702034a18811109cd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SfX0aemsyilsn4PZHnYmVg.png"/></div></div></figure><p id="2e84" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这之后，我们将使用我们创建的字典'<em class="lv"> word to index '来改变输入和输出中的每个单词以映射索引。</em>因为我们要进行批处理，所以我们希望所有的序列长度相等，这就是为什么我们要在每个序列后面加上0，直到它们达到最大长度(如上计算的34)。可以看到，这是一个巨大的数据量，一次性将其加载到内存中根本不可行，为此，我们将使用一个数据生成器，将其加载到小块中，即只加载需要的数据，而不消耗所有内存。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="fd88" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面的代码遍历所有的图像和描述，并生成类似于表中的数据项。将让函数从同一行再次运行，因此，让我们批量加载数据</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="f237" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">模型架构和培训:</h1><p id="524c" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">如前所述，我们的模型在每个点都有两个输入，一个是特征图像向量，另一个是部分字幕。我们首先对图像向量应用0.5的下降，然后将其与256个神经元的层连接。对于部分字幕，我们首先用如上所述预训练的手套中的嵌入矩阵的权重将其连接到嵌入层。然后，我们应用0.5的辍学和LSTM(长短期记忆)。最后，我们将这两者结合起来，并将它们连接到一个由256个神经元组成的层，最后连接到一个softmax层，该层预测我们词汇表中每个单词的概率。可以使用下图总结高级架构:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/320f24d8c30c9d2e6126e51bb81e3a0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/0*LnEDyJ5AlF93DOZT"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">问题的定制架构</p></figure><p id="435a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是在训练期间选择的超参数:损失被选择为'<em class="lv">分类损失熵'，</em>优化器是'<em class="lv"> Adam '。模型</em>总共训练了30个时期，但前20个时期的批量和学习率分别为0.001和3，而后10个时期的批量和学习率分别为0.0001和6。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="dd46" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们稍微解释一下代码:</p><ul class=""><li id="f279" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld ns ni nj nk bi translated">第1- 11行:定义模型架构</li><li id="02ab" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld ns ni nj nk bi translated">第13–14行:将嵌入层的权重设置为上面创建的嵌入矩阵，并设置<code class="fe nt nu nv nw b">trainable=False</code>,这样，该层不再被进一步训练</li><li id="78d8" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld ns ni nj nk bi translated">第16–33行:用上面提到的超参数在两个不同的区间训练模型</li></ul></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="c939" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">推论:</h1><p id="cd3e" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">前20个时期和接下来的10个时期的训练损失如下所示:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oa"><img src="../Images/74dbabf639fa8f5027f7b70cd1299b80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*717NJ3ECUJCMgasYr_13FQ.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">培训损失</p></figure><p id="fdb0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了进行推理，我们编写了一个函数，根据我们的模型预测下一个单词是具有最大概率的单词(即，greedy)</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nq nr l"/></div></figure><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ob"><img src="../Images/a5356d88e40aff4e50badfd8df7b6121.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DIE-f56y-efPYxtEHmZaQA.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">来自开源Flikr8k数据集的图像</p></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="8bee" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated"><strong class="ak">你能做什么:</strong></h1><p id="94ea" class="pw-post-body-paragraph ki kj it kk b kl mw ju kn ko mx jx kq kr my kt ku kv mz kx ky kz na lb lc ld im bi translated">因此，总之，我们的模型在没有任何广泛的超参数调整的情况下，在为测试数据集中的图像生成标题方面表现得相当好。我们能想到的一些改进可以被使用</p><ul class=""><li id="a2f3" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld ns ni nj nk bi translated">更大的数据集</li><li id="d035" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld ns ni nj nk bi translated">进行更多的超参数调整</li><li id="801f" class="nc nd it kk b kl nl ko nm kr nn kv no kz np ld ns ni nj nk bi translated">改变模型架构。</li></ul><p id="6093" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你尝试了这些方法并得到了更好的结果，请告诉我。该项目的代码可以在这里找到<a class="ae lu" href="https://github.com/Noumanmufc1/Image-Captioning" rel="noopener ugc nofollow" target="_blank">。</a></p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><p id="4b9c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您觉得以上内容对您有用，请分享并随时支持我--&gt;</p><ul class=""><li id="86c7" class="nc nd it kk b kl km ko kp kr ne kv nf kz ng ld ns ni nj nk bi translated">https://www.buymeacoffee.com/nouman10<a class="ae lu" href="https://www.buymeacoffee.com/nouman10" rel="noopener ugc nofollow" target="_blank"/></li></ul></div></div>    
</body>
</html>