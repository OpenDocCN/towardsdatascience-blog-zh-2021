<html>
<head>
<title>Top 3 Python Packages to learn Audio Data Science Project</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">学习音频数据科学项目的前 3 个 Python 包</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/top-3-python-packages-to-learn-audio-data-science-project-cbd11c100fe7?source=collection_archive---------2-----------------------#2021-12-18">https://towardsdatascience.com/top-3-python-packages-to-learn-audio-data-science-project-cbd11c100fe7?source=collection_archive---------2-----------------------#2021-12-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5ec7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">音频数据科学项目是你可以从这些包中学到的东西。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b9e6652b37a0c00d0d4cd07ae0fc5f0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sLF5PPhgWF_zWx-7"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">凯利·西克玛在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="5e86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们谈到数据项目时，许多人首先会想到表格数据、文本数据或图像数据作为数据源。然而，数据远不止这些。现代技术使得收集和存储各种数据变得更加容易，包括音频数据。它不像其他项目那样大肆宣传，但音频数据科学项目对许多行业都是有效的。</p><p id="d203" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">音频数据科学项目的示例包括通过声音进行情感预测、语音转文本预测和音乐生成。无论您的兴趣是什么，有几个 Python 包可以帮助您了解更多关于音频数据科学项目的信息。本文将概述我的前 3 个音频数据科学项目 Python 包。让我们开始吧。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="4b60" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">1.品红</h1><p id="b1e5" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated"><a class="ae ky" href="https://magenta.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> Magenta </a>是一个开源的 Python 包，建立在 TensorFlow 之上，用来操纵图像和音乐数据，以生成模型作为输出来训练机器学习模型。</p><p id="b233" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Magenta 没有提供清晰的 API 参考供我们学习；相反，他们给了我们很多研究演示和合作者笔记本，我们可以自己尝试。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/1ac32a75b06c4e699abaca186d59157a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*ylcrt8Ru7hMaU9bTGp3sLQ.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">洋红色演示(作者提供的 GIF)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/631a88b2165d39f95fe973159066f181.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*f1ReBoIi4EBwO7KPHfjc5A.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">洋红色的 Colab 笔记本(作者 GIF)</p></figure><p id="0da5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于第一次参与音频数据科学项目的人，我建议访问他们的<a class="ae ky" href="https://colab.research.google.com/notebooks/magenta/hello_magenta/hello_magenta.ipynb" rel="noopener ugc nofollow" target="_blank"> Hello World 笔记本</a>进行音乐创作。我从他们的笔记本中学到了很多，特别是生成机器学习的部分，在那里你可以测试各种音调来产生你的音乐。让我们试试这个代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="na nb l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Magenta Hello World 测试(视频由作者提供)</p></figure><p id="c5da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们在上面的视频中看到的，音乐完全是用代码创作的。我们试着用 Magenta 做一个生成式音乐机器学习。我将使用<a class="ae ky" href="https://g.co/magenta/musicvae" rel="noopener ugc nofollow" target="_blank"> MusicVAE </a>实现 Magenta 来制作音乐。很好用，只需要改变一些超参数。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="7049" class="nh md it nd b gy ni nj l nk nl">generated_sequences = music_vae.sample(n=2, length=80, temperature=1.0)</span><span id="e29b" class="nh md it nd b gy nm nj l nk nl">for ns in generated_sequences:<br/>    # print(ns)</span><span id="b9b8" class="nh md it nd b gy nm nj l nk nl">    note_seq.plot_sequence(ns)<br/>    note_seq.play_sequence(ns, synth=note_seq.fluidsynth)</span></pre><p id="c874" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以改变 n 来表示你想要制作的音乐的数量，音乐的长度，以及温度来表示音乐的随机性。让我使用下面的参数。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="c01d" class="nh md it nd b gy ni nj l nk nl">generated_sequences = music_vae.sample(n=2, length=100, temperature=15)</span></pre><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="na nb l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">音乐生成(作者提供的视频)</p></figure><p id="018e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">生成的音乐将取决于你开始学习时使用的音频。你可以弹奏各种音乐来创造你的旋律。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="539b" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">2.利布罗萨</h1><p id="5f4f" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">Librosa 是一个为音乐和音频分析开发的 Python 包。它专门用于捕获要转换成数据块的音频信息。但是，文档和示例有助于理解如何处理音频数据科学项目。让我们尝试安装 python 包并尝试快速入门。下面的代码将安装这个包。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="dd95" class="nh md it nd b gy ni nj l nk nl">pip install librosa</span></pre><p id="eb73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">安装包后，让我们下载样本音乐。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="6f58" class="nh md it nd b gy ni nj l nk nl">import librosa<br/>filename = librosa.example('nutcracker')</span></pre><p id="7733" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用 librosa 包来捕获这个样本的音频信息。让我们用 librosa 加载音乐数据。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="a52a" class="nh md it nd b gy ni nj l nk nl">y, sr = librosa.load(filename)</span></pre><p id="d377" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们使用 librosa 加载一个音频文件时，我们获得了两个数据集；波形数据(存储在 y 中)和采样速率(存储在 sr 中)。我们来详细看看数据。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="f789" class="nh md it nd b gy ni nj l nk nl">print('waveform')<br/>print(y)<br/>print('\nsampling rate')<br/>print(sr)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/c49e1cdf1e4083df540589e41c72c081.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*3zscfFIdatOt1OXe8xUH-w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="5e66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如您所见，波形数据存储为 NumPy 数组数据。如果我们想要可视化波形，我们可以使用 librosa 显示包。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="abca" class="nh md it nd b gy ni nj l nk nl">import librosa.display<br/>import matplotlib.pyplot as plt</span><span id="653b" class="nh md it nd b gy nm nj l nk nl">fig, ax = plt.subplots(nrows=1, sharex=True)<br/>librosa.display.waveshow(y, sr=sr)<br/>ax.set(title='Envelope view, mono')<br/>ax.label_outer()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/5381de26954c792a5e4b04b8fb04a5eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*ESlTeVVb-eAHjOH68jRsZw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="8c93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以通过音乐时间看到音频波形是怎样的。这是一个伟大的探索工具。使用 librosa，我们还可以用下面的代码跟踪音频节拍时间。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="3a61" class="nh md it nd b gy ni nj l nk nl">tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)<br/>print('Estimated tempo: {:.2f} beats per minute'.format(tempo))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/6677fecc2f3f60186182d3637859c37e.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*EHpLkEOZY2J8Qz4C73rrnQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="2811" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想得到每一拍的时间，你可以用下面的代码来实现。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="6643" class="nh md it nd b gy ni nj l nk nl">beat_times = librosa.frames_to_time(beat_frames, sr=sr)</span></pre><p id="922d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">beat_times 变量将在 NumPy 数组中存储每个节拍的所有时间戳。</p><p id="33e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我建议访问他们的 API 文档和高级材料以进一步学习，因为它包含许多学习音频数据科学项目的重要工具。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/149d455dcddd0493df4d943003a077f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*7NubKV9xvF2jGq3wl2crZg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="6734" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">3.py 音频分析</h1><p id="334b" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated"><a class="ae ky" href="https://github.com/tyiannak/pyAudioAnalysis" rel="noopener ugc nofollow" target="_blank">pyaudionanalysis</a>是一个用于音频分析任务的 Python 包。它旨在进行各种分析，例如:</p><ul class=""><li id="08c7" class="nr ns it lb b lc ld lf lg li nt lm nu lq nv lu nw nx ny nz bi translated">提取音频特征</li><li id="3c6a" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">用于音频分割训练机器学习模型</li><li id="ae12" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">未知音频的分类</li><li id="a0fe" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">基于回归模型的情感识别</li><li id="acf0" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">用于音频数据可视化的降维</li></ul><p id="6c81" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还有很多。你可以用这个包做很多事情，特别是如果你是音频数据科学项目的新手。</p><p id="2e19" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您需要直接从 GitHub 页面克隆这个文件来安装这个包。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="081b" class="nh md it nd b gy ni nj l nk nl">git clone https://github.com/tyiannak/pyAudioAnalysis.git</span></pre><p id="5047" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，您需要安装需求依赖项(您克隆文件的目录)。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="b6ab" class="nh md it nd b gy ni nj l nk nl">pip install -r ./requirements.txt</span></pre><p id="da00" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后使用下面的代码开始安装整个包(参考您克隆的目录)。</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="bce1" class="nh md it nd b gy ni nj l nk nl">pip install -e .</span></pre><p id="587a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">安装包后，我建议访问<a class="ae ky" href="https://github.com/tyiannak/pyAudioAnalysis/wiki" rel="noopener ugc nofollow" target="_blank">维基</a>，所有使用的例子都写在那里。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/bd47a6c071fd441c2439181d479e4355.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Jg_gPdfFXxPAF-FqE-cDzg.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者 GIF</p></figure><p id="b10a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于初学者来说，该文档很容易阅读，尽管代码部分比较复杂，因为您需要了解如何使用 CLI 来执行代码。然而，出于学习的目的，软件包文档已经足够好了。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="b933" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">结论</h1><p id="f92d" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">数据科学项目并不总是关于表格、文本或图像数据。有时你可以使用非常规数据，如音频。在本文中，我概述了我学习音频数据科学项目的前 3 个 Python 包，它们是:</p><ol class=""><li id="b5d2" class="nr ns it lb b lc ld lf lg li nt lm nu lq nv lu og nx ny nz bi translated">品红</li><li id="7ff5" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu og nx ny nz bi translated">利布罗萨</li><li id="3208" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu og nx ny nz bi translated">py 音频分析</li></ol><p id="1352" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">希望有帮助！</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="11ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我的<a class="ae ky" href="https://www.linkedin.com/in/cornellius-yudha-wijaya/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> LinkedIn </strong> </a> <strong class="lb iu"> </strong>或<a class="ae ky" href="https://twitter.com/CornelliusYW" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Twitter </strong> </a>上访问我。</p><blockquote class="oh oi oj"><p id="83fb" class="kz la ok lb b lc ld ju le lf lg jx lh ol lj lk ll om ln lo lp on lr ls lt lu im bi translated"><em class="it">如果您喜欢我的内容，并希望获得更多关于数据或数据科学家日常生活的深入知识，请考虑在此订阅我的</em> <strong class="lb iu"> <em class="it">简讯。</em>T15】</strong></p></blockquote><blockquote class="oo"><p id="67e9" class="op oq it bd or os ot ou ov ow ox lu dk translated"><em class="oy">如果您没有订阅为中等会员，请考虑通过</em> <a class="ae ky" href="https://cornelliusyudhawijaya.medium.com/membership" rel="noopener"> <em class="oy">我的推荐</em> </a> <em class="oy">订阅。</em></p></blockquote></div></div>    
</body>
</html>