<html>
<head>
<title>How Computers See Depth: Recent Advances in Deep Learning-Based Methods</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机如何看深度:基于深度学习的方法的最新进展</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-computers-see-depth-deep-learning-based-methods-368581b244ed?source=collection_archive---------19-----------------------#2021-12-28">https://towardsdatascience.com/how-computers-see-depth-deep-learning-based-methods-368581b244ed?source=collection_archive---------19-----------------------#2021-12-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/2c65442f127ed75417bf1a936cecfdc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gZj0iBgquFcrkkeHLhrcFw.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:<a class="ae jg" href="https://unsplash.com/photos/0YQOOxNT2V4" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><h2 id="8a57" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph">从立体图像估计深度</h2><div class=""/><div class=""><h2 id="a445" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">第 1 部分:立体视觉的动机和基础</h2></div><p id="c388" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi md translated"><span class="l me mf mg bm mh mi mj mk ml di"> O </span>我们对深度的感知对于创造我们周围的 3D 世界至关重要。这种知识已经流行了几个世纪，有一个人非常了解这一点，他就是莱昂纳多·达·芬奇。他利用自己的专业知识帮助自己创作了一些艺术作品，这些作品将会名闻遐迩，如《最后的晚餐》或《萨尔瓦托勒·希泽拉》。从技术上讲，对双筒望远镜的理解可以追溯到公元 280 年，当时欧几里德意识到我们的深度知觉是人类用两只眼睛聚焦于同一物体。尽管如此，今天，立体视觉仍然是一个非常有趣的问题。我的目标是深入了解这个话题。现在，我把我的笔记转变成一个博客系列。</p><p id="159b" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">✍每篇文章都将包括一个突击测验！突击测验的目的是通过思考精选的问题集来巩固关键概念。所以，请分享你的回复吧！</p></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><h1 id="7e25" class="mt mu jj bd mv mw mx my mz na nb nc nd ky ne kz nf lb ng lc nh le ni lf nj nk bi translated">目录</h1><p id="c2c9" class="pw-post-body-paragraph lh li jj lj b lk nl kt lm ln nm kw lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated"><a class="ae jg" href="#e7c3" rel="noopener ugc nofollow">一简介</a> <br/> <a class="ae jg" href="#16d0" rel="noopener ugc nofollow">二深度感知:3D 空间中的人类</a> <br/> ∘ <a class="ae jg" href="#1096" rel="noopener ugc nofollow">二. a 为什么是立体的？</a> <br/> <a class="ae jg" href="#ef51" rel="noopener ugc nofollow"> III 立体问题</a> <br/> ∘ <a class="ae jg" href="#f194" rel="noopener ugc nofollow"> III.a 立体视觉方法论</a> <br/> ∘ <a class="ae jg" href="#213b" rel="noopener ugc nofollow"> III.b 核几何(概念)</a> <br/> ∘ <a class="ae jg" href="#7633" rel="noopener ugc nofollow"> III.c 核几何(数学)</a> <br/> <a class="ae jg" href="#538d" rel="noopener ugc nofollow"> IV 立体视觉系统的几代产品</a> <br/> <a class="ae jg" href="#2462" rel="noopener ugc nofollow"> V 未来工作</a> <br/> <a class="ae jg" href="#36ec" rel="noopener ugc nofollow"> VI 结论</a> <br/> <a class="ae jg" href="#0281" rel="noopener ugc nofollow"> 博士中等上</a> <br/> <strong class="lj jt"> </strong> <a class="ae jg" href="#2713" rel="noopener ugc nofollow"> <strong class="lj jt">突击测验</strong> </a> <br/> ∘ <a class="ae jg" href="#a52a" rel="noopener ugc nofollow"> A)捕食者对猎物</a> <br/> ∘ <a class="ae jg" href="#33c7" rel="noopener ugc nofollow"> B)立体视觉由费雪</a> <br/> ∘ <a class="ae jg" href="#a5b4" rel="noopener ugc nofollow"> C)附加题</a></p><h1 id="e7c3" class="mt mu jj bd mv mw nq my mz na nr nc nd ky ns kz nf lb nt lc nh le nu lf nj nk bi translated">一.导言</h1><p id="8af0" class="pw-post-body-paragraph lh li jj lj b lk nl kt lm ln nm kw lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">深度估计在现实世界中有许多用途，在机器人、计算机视觉和沉浸式显示中具有实际意义(见上图)。我们将深度估计视为一个多图像问题。多视图(或图像)问题跨越不同的问题领域，如(1)立体视觉，(2)运动结构，以及(3)光流。虽然每一个都在虚拟现实(V.R .)、机器人和计算机视觉问题中作为一个整体具有巨大的重要性，但在这个多部分系列中，我们将重点关注(1)立体视觉。具体来说，深度学习在立体视觉技术上的进展。首先，在<em class="nv">第一部分</em>中，我们涵盖了预备材料(即经典立体视觉理论)。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nw"><img src="../Images/34617f954a844aae6029e4dd5b4b7cfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bK3oT9PuPD_2PgvNL3lIqg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">基于深度传感技术的大量应用。图片作者。</p></figure><p id="a5e0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">人工神经网络在计算机视觉中有很长的历史，为对象检测和分类提供了一个健壮的框架。此外，深度学习通过提供网络学习的图像的更深层次的表示，彻底改变了该领域。最近这一成功的关键因素包括一个简化的网络架构，其参数更多，规则更少，以及新的训练技术，如辍学[3]和 L2 正则化[4]。</p><p id="7a68" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在我们专注于具体的深度学习解决方案之前，让我们首先通过理解为什么立体图像对可以推断深度来激发这个问题。</p></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><h1 id="16d0" class="mt mu jj bd mv mw mx my mz na nb nc nd ky ne kz nf lb ng lc nh le ni lf nj nk bi translated">深度知觉:3D 空间中的人类</h1><p id="92ee" class="pw-post-body-paragraph lh li jj lj b lk nl kt lm ln nm kw lp lq nn ls lt lu no lw lx ly np ma mb mc im bi md translated">人类的大脑在立体视觉中有一种奇妙的能力来看深度。我们使用我们的两只眼睛，它们分别位于头部的两侧，使我们能够感知物体的三维空间:高度(深度)、宽度和相对于周围环境的前后位置。然而，这项技能并不是人类独有的——许多动物都拥有它！然而，当尝试关于这个主题的计算建模研究时，仍然会出现几个挑战，主要是因为在没有输入数据集的情况下，这些挑战是困难的或不可能的，这些输入数据集包含关于您希望他们训练什么对象以及这些项目当前位置有多近/多远的信息。这个博客系列将探索这些挑战，以及基于深度学习的方法的最新进展如何克服这些挑战。</p><p id="4eb8" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以使用核几何来重建在图像捕获期间丢失的深度(即，<em class="nv"> z </em>)维度，其中图像对来自已知参数的来源:内在参数(即，透镜的焦距<em class="nv"> f </em>)和外在参数(即，称为基线<em class="nv">b】</em>的左右摄像机的光学中心之间的距离)。</p><p id="6611" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们如何从图像中自动计算三维几何图形？图像中的哪些线索提供了 3D 信息？在看双目(即立体或两个)之前，让我们先考虑一些单一视角，即单目特征。</p><p id="bf25" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们人类天生如此。下图描绘了我们自然用来感知世界深度的线索。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ob"><img src="../Images/94b73f9b7471636da023c786cb54d086.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xnqk1283a4FnnS0JHy1Q6g.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">人类用来推断深度信息的几个线索，线索列在每个样本的上面，来源在下面。</p></figure><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/4259f4604b6731187767545a75568380.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/1*-qucsgxDLR7A5rr9btx9aA.gif"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">运动是我们用来推断深度信息的另一个线索。想象一下 gif(最右边)中所示的雕像的转动。作者创建了 gif。</p></figure><ul class=""><li id="7175" class="oe of jj lj b lk ll ln lo lq og lu oh ly oi mc oj ok ol om bi translated">突出</li><li id="e5d1" class="oe of jj lj b lk on ln oo lq op lu oq ly or mc oj ok ol om bi translated">阴影</li><li id="54f1" class="oe of jj lj b lk on ln oo lq op lu oq ly or mc oj ok ol om bi translated">轮廓</li><li id="658e" class="oe of jj lj b lk on ln oo lq op lu oq ly or mc oj ok ol om bi translated">相互反射</li><li id="5565" class="oe of jj lj b lk on ln oo lq op lu oq ly or mc oj ok ol om bi translated">对称</li><li id="8ec2" class="oe of jj lj b lk on ln oo lq op lu oq ly or mc oj ok ol om bi translated">光偏振</li></ul><h2 id="1096" class="os mu jj bd mv ot ou dn mz ov ow dp nd lq ox oy nf lu oz pa nh ly pb pc nj jp bi translated">为什么是立体声？</h2><p id="af85" class="pw-post-body-paragraph lh li jj lj b lk nl kt lm ln nm kw lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">如简要提到的，深度线索可以来自单个源(即，单目视觉)。另一种方法是通过立体图像对使用同一场景的两个视觉参考(即双目视觉)。为什么要使用多个来源？通常，从单一来源推断深度信息是不可能的。还有，单目视觉任意缩放<em class="nv"> </em>。下图描述了这个概念。</p><p id="0e09" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们通过例子来看看单一观点的模糊性。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pd"><img src="../Images/4d2a7bdad5571397b59e882764518bd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dBgqMkTmucZbfRliGdBkvg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd od">深度，正如在 2D 的图像中看到的，是模糊的。</strong>因此，先前的线索不能确定地产生精确的深度信息。</p></figure><p id="f739" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">描绘这种模糊性，我们看到从光学中心(即摄像机位置)看到的<strong class="lj jt"> P1 </strong>和<strong class="lj jt"> P2 </strong>，投影到像平面上的<strong class="lj jt">P1’</strong>和<strong class="lj jt">P2’</strong>是等价的。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pe"><img src="../Images/e2f3e1618f6705492e2cdbac041882d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zy6xaybw2Nqs82iyh5uV7A.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd od">图形描绘显示了来自单目视图(即，单个图像)的深度模糊。</strong>从单个视角来看，结构和深度本质上是不明确的。上图显示，单一视图的框架和深度是模糊的。请注意，上面的示意图在本文末尾会更有意义，因此，应该在讨论核几何时返回。作者创造了它们。</p></figure></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><h1 id="ef51" class="mt mu jj bd mv mw mx my mz na nb nc nd ky ne kz nf lb ng lc nh le ni lf nj nk bi translated">三立体声问题</h1><p id="03d9" class="pw-post-body-paragraph lh li jj lj b lk nl kt lm ln nm kw lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">立体在很大程度上受到生物学的推动(即，使用左眼和右眼同时捕捉视觉信息)。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/02271af5bac116a551873d1b83c24788.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*Ndbg7U6i7VxcMHa3jdpVww.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd od"> S .伯奇菲尔德，克莱姆森大学</strong> <a class="ae jg" href="http://www.ces.clemson.edu/~stb/ece847" rel="noopener ugc nofollow" target="_blank"> <strong class="bd od"> ECE 847 </strong> </a></p></figure><p id="5877" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">经典立体声方法的灵感来自于我们感知深度的方式，如上述线索。例如，可以使用刚体解算器来求解 3D 空间中的球面坐标方程，其中图像是从现场的不同角度或视角拍摄的，从而产生视差和其他效果。然而，这个系列将更加专注于深度学习解决方案(DL)。在进入任何细节之前，我们需要对这些基本原理有一些初步的了解，所以让我们从这里开始吧！</p><p id="166e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">接下来，我们将回顾为什么立体对(即，左图像和右图像)足以解决前面提到的模糊问题。它使用两个相机都能看到的世界坐标中匹配对应点的两个图像平面的三角测量。</p><h2 id="f194" class="os mu jj bd mv ot ou dn mz ov ow dp nd lq ox oy nf lu oz pa nh ly pb pc nj jp bi translated">三.立体视觉方法</h2><p id="e5ed" class="pw-post-body-paragraph lh li jj lj b lk nl kt lm ln nm kw lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">传统算法分为两大类，具体来说是<em class="nv">局部</em>和<em class="nv">全局</em>方法，对应于步骤:</p><ol class=""><li id="7c99" class="oe of jj lj b lk ll ln lo lq og lu oh ly oi mc pg ok ol om bi translated">成本计算。</li><li id="b988" class="oe of jj lj b lk on ln oo lq op lu oq ly or mc pg ok ol om bi translated">成本汇总。</li><li id="6f0d" class="oe of jj lj b lk on ln oo lq op lu oq ly or mc pg ok ol om bi translated">视差优化/计算。</li><li id="6afe" class="oe of jj lj b lk on ln oo lq op lu oq ly or mc pg ok ol om bi translated">视差细化。</li></ol><p id="2810" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">当我们探索现代的、数据饥渴的、端到端的解决方案时，这些步骤将类似于本博客中涉及的系统的许多模块。但是，首先，让我们回顾一下立体视觉的基础。</p><h2 id="213b" class="os mu jj bd mv ot ou dn mz ov ow dp nd lq ox oy nf lu oz pa nh ly pb pc nj jp bi translated">III.b 极线几何(概念)</h2><p id="67ab" class="pw-post-body-paragraph lh li jj lj b lk nl kt lm ln nm kw lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">沿着由相交射线形成的平面的法线称为核平面。同样，我们假设立体对之间的校准图像和点对应。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ph"><img src="../Images/9e844a2851f1143a43bf5ed201e0c144.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Ska6KtnW4zXmj9GO6XVSw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd od">三角测量的原理，如上所示，允许通过光线追踪到世界坐标中的交点(又名场景点)进行 3D 重建。</strong>追踪光学中心到<em class="pi">场景点</em>是通过匹配从左到右图像(反之亦然)的对应关系来完成的——作者的照片。</p></figure><p id="19ba" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="nv">核线</em> <em class="nv">约束</em>将对应问题简化为沿<em class="nv">共轭</em> <em class="nv">核线</em>的 1D 搜索——如下图所示。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pj"><img src="../Images/08f005aaf5f940aa0475b053c5d8dbf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t8asg1-knXn3IzkPsFcn-Q.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">核线约束变换立体对，使两幅图像的核线平行。核几何将对应问题简化为 1D 搜索(即，沿着<em class="pi">共轭</em> <em class="pi">核线搜索匹配点)。作者创造了可视化。</em></p></figure><p id="bd75" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，核极约束假设校正的立体图像，意味着相同的<em class="nv">核极平面</em>(如上所示)跨行对齐。它与两者正交并彼此对齐[1]。使用基于内部和外部参数的变换来校正图像是一个可以追溯到几十年前的过程。</p><p id="ad12" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">立体像对是由相对于彼此位置已知的两个相机捕获的场景的图像。视差测量左右摄像机(即立体对)之间的水平距离(以像素为单位)。因此，使用核几何沿着校正图像的水平线约束视差。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pk"><img src="../Images/a30e7ec02a26cc797da482fe083dbca2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R749lpRCY5dyMClbGXmqJw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd od">图像矫正的过程。</strong>一个立体像对(中间的灰色图像)在校正过程中被转换。因此，核线是水平平行的(最下面的黄色照片描绘的是校正后的图像)。视差与 3D 场景中的深度有关(图中最顶端的绿色空间)。将图像平面(即立体对)重新投影到平行于光学中心之间的线的标准平面上；像素运动在此变换后是水平的(右侧视图中的黄色方块)-图片由作者提供。</p></figure><p id="b9cf" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">具体来说，左图像中的一个点(<em class="nv"> x </em>，<em class="nv"> y </em>)在右图像中的(<em class="nv"> x-d </em>，<em class="nv"> y </em>)，其中<em class="nv"> d </em>为视差(以像素为单位)。然后，像素位移通过焦距<em class="nv"> f </em>和被称为基线<em class="nv"> B 的相机之间的距离与深度相关:z = f </em> ∙ <em class="nv"> B/d </em>，其中<em class="nv"> z </em>是在三个坐标空间中恢复的深度值。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pl"><img src="../Images/a19d4b44cdbf54d952f77c88e3942749.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uj5zwpXjiFaKJBb1Paejnw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">请注意，校正后的立体图像对的核线在校正前是不平行的(顶部)。因此，扭曲图像通过变换图像对来约束点对应的搜索，使得核线平行(底部)。作者创造了这个人物。</p></figure><p id="0700" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下图描述了立体像对(即输入)和生成的视差图(即输出)。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pm"><img src="../Images/40fa4b40089b8496b33dc50629ed9b7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vXko9xQFVSyms8VILHJHEg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><em class="pi">视差(中间)表示从左到右的像素移位(即，每个对应点移位的像素数量的整数值)。作者创造了可视化。</em></p></figure><p id="5399" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们找到两幅图像中的对应点来估计相对深度。如上所述，视差和深度直接相关如下。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/b53adbd6f312ed15c9bcc64806f193a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*bYIMznbf4ngriCO8m3JUrA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">同样，我们可以将等式表示为<code class="fe po pp pq pr b">(x, y)=(x' — D(x, y), y'), as (x, y) is the point in the left image and (x', y') is the corresponding point in the right image. Hence, the magnitude of D(x, y) is the number of pixels shifted along the horizontal (i.e., x-direction). Notice the y-axis remains constant. Referring to the image of the building above, at the point marked in red, the value of D(x, y) will be the magnitude of the vector depicted in the right image. Take a minute to understand this, for it shows the very meaning of disparity.</code></p></figure><h2 id="7633" class="os mu jj bd mv ot ou dn mz ov ow dp nd lq ox oy nf lu oz pa nh ly pb pc nj jp bi translated">III.c 极线几何(数学)</h2><p id="90cb" class="pw-post-body-paragraph lh li jj lj b lk nl kt lm ln nm kw lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">我们现在将解释上面介绍的概念背后的数学原理。对于那些对为什么立体声从严格的数学角度起作用的细节不感兴趣的人，请随意跳到下一部分(这里是<a class="ae jg" href="#538d" rel="noopener ugc nofollow"/>)。</p><p id="5487" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">从校正后的图像对中，深度<em class="nv"> Z </em>可以通过其与视差<em class="nv"> d </em>的反比关系来确定，其中视差定义为比较左右对应时沿水平方向的像素差，即<strong class="lj jt"> I </strong> ( <em class="nv"> x </em>，<em class="nv">y【T32)=<strong class="lj jt">D</strong>(<em class="nv">x</em>+<em class="nv">D</em>，</em></p><p id="ebaf" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这种关系最容易从视觉上把握。</p><p id="a40f" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">提供在世界坐标(X，Y，Z)中投影的左图像平面 P_L( <em class="nv"> x </em>，<em class="nv"> y </em>)中的点作为 3D 场景中的点，我们的目标是重建提供立体对的缺失的 Z(深度)。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ps"><img src="../Images/f77dce4c8a2d7f7e1ebb2f67d074633c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VtG2-xCcRshRCnohB69QSA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">左侧图像中的点-投影到世界坐标的位置-作者提供的图像。</p></figure><p id="c4b3" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下图显示了右侧图像平面中的对应关系。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pt"><img src="../Images/47844c444edf246f4335ca49ce3a4339.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uiTgwcFuknWNkmHVayi9kg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">假设我们知道 P_L 对应 P_R. Image by Author。</p></figure><p id="258d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们设置相对世界坐标(红轴)以及两个相机中心之间的已知基线<em class="nv"> b </em>:</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pu"><img src="../Images/701eb90970ef2dd1046de873cdca8c75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j_o1TZZgIt-njUkgd_9eZA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">基线 b 代表摄像机之间的实际距离。图片作者。</p></figure><p id="6dac" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们得到了</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pv"><img src="../Images/db7b08498558f070ed6c6facbe319089.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m18aG33lSZauDipooXnx8A.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">立体视觉理论基础。图片作者。</p></figure><p id="eea8" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以用下图表示坐标。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pw"><img src="../Images/1c7fd494fe9d122f50f203cdde7607d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0RcelqWzIZDbJpdrFeLXGw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">传统立体视觉综述。图片作者。</p></figure><h1 id="538d" class="mt mu jj bd mv mw nq my mz na nr nc nd ky ns kz nf lb nt lc nh le nu lf nj nk bi translated">第四代立体视觉系统</h1><p id="d762" class="pw-post-body-paragraph lh li jj lj b lk nl kt lm ln nm kw lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">多年来，立体视觉一直是研究界感兴趣的问题。如今，人们可以把不同的方法归为三代之一。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi px"><img src="../Images/6736f21806ecff0492e570450cf860b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rgK5KUJ9CVViJ5yzp8bAPg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">第 1 代、第 2 代和第 3 代，其中第 2 代和第 3 代将包含在系列的后续部分中。图片作者。</p></figure><p id="cc33" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">关于用于视差图估计的 DL 系列，我们可以将方法描述为以下任一种。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi py"><img src="../Images/781cd066e9c66f269855a64ad16840dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cr-KFzq9g-K8gNWmfJKk4g.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><strong class="bd od">传统方法(非端到端)和现代方法(端到端)的特点。</strong>作者创建了可视化。</p></figure><p id="8ad1" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下图描述了(2)中列出的端到端系统。</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pz"><img src="../Images/f776472e0dd1faae9d7c585db45e7056.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LL_YersFRKX9pvc7VMWHlA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">学习具有权重θ的映射函数 f，使得当将预测的视差 f _θ(<strong class="bd od">I</strong>)= D’与作者的 G.T .视差 D .图像相比较时，输入图像张量<strong class="bd od"> I </strong>具有对于某个距离度量 D 最小化的损失 L。</p></figure><p id="58e8" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">正如我们将在前面的部分中看到的，代表 DL 网络的黑色(橙色)方框可以包括几个子模块，通常串联级联。不同的步骤类似于传统立体视觉系统中涉及的常规步骤。</p></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><h1 id="2462" class="mt mu jj bd mv mw mx my mz na nb nc nd ky ne kz nf lb ng lc nh le ni lf nj nk bi translated">五.未来的工作</h1><p id="441d" class="pw-post-body-paragraph lh li jj lj b lk nl kt lm ln nm kw lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">接下来，我们开始回顾基于深度学习的深度估计方法的进展。具体来说，在<em class="nv">第二部分</em>中，我们涵盖了几个跨越 2015-2020 年的基于图像的深度立体网络(即 MC CNN [1]、DispNet [2]、GC-Net [3]、PSMNet [4]、iResNet [5]和 GA-Net [6])。然后，<em class="nv">第三部分</em>、<em class="nv">第四部分</em>和<em class="nv">第五部分</em>将涵盖最新和最大的(即 2021–2022)基于视频的立体方法，称为多视图立体(MVS)，并分别在子像素级别生成置信图。</p><h1 id="36ec" class="mt mu jj bd mv mw nq my mz na nr nc nd ky ns kz nf lb nt lc nh le nu lf nj nk bi translated">六.结论</h1><p id="c688" class="pw-post-body-paragraph lh li jj lj b lk nl kt lm ln nm kw lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">随着最近深度学习的进步，立体视觉技术正在取得长足进步。<em class="nv">一个多部分系列的第一部分</em><em class="nv"/>涵盖了经典立体视觉技术的基础:草稿是一项正在进行的工作，每个草稿都应该在接下来的几周甚至几个月内完成。</p><p id="fe93" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果你想了解更多关于在工作或研究中使用深度估计的信息，请不要犹豫，直接联系我或者在下面留言！我们可以帮助您从今天开始。在第二部分中，准备学习各种用于立体视觉的图像级深度模型。</p><p id="f674" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">看看第二部分。</p><div class="is it gp gr iu qa"><a rel="noopener follow" target="_blank" href="/dl-for-depth-estimation-p2-7cb2c9ff325d"><div class="qb ab fo"><div class="qc ab qd cl cj qe"><h2 class="bd jt gy z fp qf fr fs qg fu fw js bi translated">计算机如何看深度:基于深度学习的方法的最新进展</h2><div class="qh l"><h3 class="bd b gy z fp qf fr fs qg fu fw dk translated">第 2 部分:基于图像的立体视觉</h3></div><div class="qi l"><p class="bd b dl z fp qf fr fs qg fu fw dk translated">towardsdatascience.com</p></div></div><div class="qj l"><div class="qk l ql qm qn qj qo ja qa"/></div></div></a></div></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><h1 id="0281" class="mt mu jj bd mv mw mx my mz na nb nc nd ky ne kz nf lb ng lc nh le ni lf nj nk bi translated">七参考文献</h1><p id="caba" class="pw-post-body-paragraph lh li jj lj b lk nl kt lm ln nm kw lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">[1] C. Loop 和 Z. Zhang。<a class="ae jg" href="http://research.microsoft.com/~zhang/Papers/TR99-21.pdf" rel="noopener ugc nofollow" target="_blank">计算立体视觉的矫正单应性</a>。IEEE 会议。计算机视觉和模式识别，1999。</p><p id="a4c9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[2] Zbontar、Jure 和 Yann LeCun。"立体匹配通过训练卷积神经网络来比较图像补丁."<em class="nv"> J .马赫。学习。第 17.1 号决议(2016 年):2287 至 2318。</em></p><p id="a9f9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[2] Mayer，Nikolaus 等人，“用于训练卷积网络进行视差、光流和场景流估计的大型数据集。”<em class="nv">IEEE 计算机视觉和模式识别会议论文集</em>。2016.</p><p id="b708" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[3] Kendall，Alex 等，“深度立体回归的几何和上下文的端到端学习”IEEE 计算机视觉国际会议论文集。2017.</p><p id="ba32" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[4]常、贾仁和."金字塔立体匹配网络."IEEE 计算机视觉和模式识别会议录。2018.</p><p id="fcde" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[5]梁，，等，“通过特征恒常性学习视差估计”IEEE 计算机视觉和模式识别会议论文集<em class="nv">。2018.</em></p><p id="dc72" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">[6]张，，等.“Ga-net:端到端立体匹配的引导聚合网”<em class="nv">IEEE/CVF 计算机视觉和模式识别会议论文集</em>。2019.</p></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><p id="bc73" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在<a class="ae jg" href="https://www.linkedin.com/company/superannotate/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>、<a class="ae jg" href="https://twitter.com/jrobvision" rel="noopener ugc nofollow" target="_blank"> Twitter </a>和<a class="ae jg" href="https://www.facebook.com/superannotate" rel="noopener ugc nofollow" target="_blank">脸书</a>上关注罗宾逊博士</p><div class="is it gp gr iu qa"><a href="https://www.jrobsvision.com/" rel="noopener  ugc nofollow" target="_blank"><div class="qb ab fo"><div class="qc ab qd cl cj qe"><h2 class="bd jt gy z fp qf fr fs qg fu fw js bi translated">乔·罗宾逊的主页</h2><div class="qh l"><h3 class="bd b gy z fp qf fr fs qg fu fw dk translated">Joseph P. Robinson 获得了电气和计算机工程学士学位(2014 年)和计算机工程博士学位(2020 年)…</h3></div><div class="qi l"><p class="bd b dl z fp qf fr fs qg fu fw dk translated">www.jrobsvision.com。</p></div></div><div class="qj l"><div class="qp l ql qm qn qj qo ja qa"/></div></div></a></div><h1 id="1530" class="mt mu jj bd mv mw nq my mz na nr nc nd ky ns kz nf lb nt lc nh le nu lf nj nk bi translated">阅读更多由<a class="qq qr ep" href="https://medium.com/u/8049fa781539?source=post_page-----368581b244ed--------------------------------" rel="noopener" target="_blank">约瑟夫·罗宾逊博士</a>在媒体上发表的文章</h1><div class="is it gp gr iu qa"><a rel="noopener follow" target="_blank" href="/pandas-tips-tricks-need-for-speed-54e217cc6aa0"><div class="qb ab fo"><div class="qc ab qd cl cj qe"><h2 class="bd jt gy z fp qf fr fs qg fu fw js bi translated">熊猫小贴士:需要速度</h2><div class="qh l"><h3 class="bd b gy z fp qf fr fs qg fu fw dk translated">个人最喜欢的一句俏皮话</h3></div><div class="qi l"><p class="bd b dl z fp qf fr fs qg fu fw dk translated">towardsdatascience.com</p></div></div><div class="qj l"><div class="qs l ql qm qn qj qo ja qa"/></div></div></a></div><div class="is it gp gr iu qa"><a href="https://jvision.medium.com/remote-development-with-pycharm-d741287e07de" rel="noopener follow" target="_blank"><div class="qb ab fo"><div class="qc ab qd cl cj qe"><h2 class="bd jt gy z fp qf fr fs qg fu fw js bi translated">使用 Pycharm 进行远程开发</h2><div class="qh l"><h3 class="bd b gy z fp qf fr fs qg fu fw dk translated">就是这么简单！</h3></div><div class="qi l"><p class="bd b dl z fp qf fr fs qg fu fw dk translated">jvision.medium.com</p></div></div><div class="qj l"><div class="qt l ql qm qn qj qo ja qa"/></div></div></a></div><div class="is it gp gr iu qa"><a rel="noopener follow" target="_blank" href="/a-great-tool-for-image-datasets-cb249663ca45"><div class="qb ab fo"><div class="qc ab qd cl cj qe"><h2 class="bd jt gy z fp qf fr fs qg fu fw js bi translated">对图像数据集进行重复数据删除的绝佳方式</h2><div class="qh l"><h3 class="bd b gy z fp qf fr fs qg fu fw dk translated">生产中的命令行工具</h3></div><div class="qi l"><p class="bd b dl z fp qf fr fs qg fu fw dk translated">towardsdatascience.com</p></div></div><div class="qj l"><div class="qu l ql qm qn qj qo ja qa"/></div></div></a></div><div class="is it gp gr iu qa"><a href="https://jvision.medium.com/reduce-the-clutter-adapt-the-space-6daeef2e2ca9" rel="noopener follow" target="_blank"><div class="qb ab fo"><div class="qc ab qd cl cj qe"><h2 class="bd jt gy z fp qf fr fs qg fu fw js bi translated">减少杂乱，适应空间</h2><div class="qh l"><h3 class="bd b gy z fp qf fr fs qg fu fw dk translated">变得有条理、高效甚至舒适的 3 个技巧</h3></div><div class="qi l"><p class="bd b dl z fp qf fr fs qg fu fw dk translated">jvision.medium.com</p></div></div><div class="qj l"><div class="qv l ql qm qn qj qo ja qa"/></div></div></a></div><p id="94eb" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/depth-estimation-1-basics-and-intuition-86f2c9538cd1"> <em class="nv">深度估计:基础知识和直觉</em> </a>作者<a class="qq qr ep" href="https://medium.com/u/d5d47d10c0e9?source=post_page-----368581b244ed--------------------------------" rel="noopener" target="_blank"> Daryl Tan </a>，是我在准备本系列<em class="nv">第二部分</em>时偶然发现的一篇博客，是一篇很棒的文章。它很好地补充了第一部分(即这篇博客)。此外，主题将帮助我们更深入地理解这个主题。</p><div class="is it gp gr iu qa"><a rel="noopener follow" target="_blank" href="/depth-estimation-1-basics-and-intuition-86f2c9538cd1"><div class="qb ab fo"><div class="qc ab qd cl cj qe"><h2 class="bd jt gy z fp qf fr fs qg fu fw js bi translated">深度估计:基础和直觉</h2><div class="qh l"><h3 class="bd b gy z fp qf fr fs qg fu fw dk translated">理解事物相对于相机有多远仍然是困难的，但对于激动人心的…</h3></div><div class="qi l"><p class="bd b dl z fp qf fr fs qg fu fw dk translated">towardsdatascience.com</p></div></div><div class="qj l"><div class="qw l ql qm qn qj qo ja qa"/></div></div></a></div><h1 id="2713" class="mt mu jj bd mv mw nq my mz na nr nc nd ky ns kz nf lb nt lc nh le nu lf nj nk bi translated">突击测验</h1><p id="6b57" class="pw-post-body-paragraph lh li jj lj b lk nl kt lm ln nm kw lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">这里有几个关于立体视觉的问题，如果思考和回答，将提供更大的洞察力。在下面评论你的答案和问题。利用从本系列第一部分中获得的经验:顶级答案和问题将得到认可。🏆</p><h2 id="a52a" class="os mu jj bd mv ot ou dn mz ov ow dp nd lq ox oy nf lu oz pa nh ly pb pc nj jp bi translated">a)捕食者与猎物</h2><p id="a6af" class="pw-post-body-paragraph lh li jj lj b lk nl kt lm ln nm kw lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">适者生存；生存进化的概念:我们能把立体视觉的概念与野生动物的生物构成联系起来吗？</p><p id="10fa" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">比较猎物(即羚羊)和捕食者(即猎豹)的视野有什么不同？</p><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qx"><img src="../Images/a7c3ece8d56834eeacc80b2ca5abc232.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5C5rPrpFUylssSGrFnqF7w.png"/></div></div></figure><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qy"><img src="../Images/297c53a3141bf3842d2778289b3f385d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tq7y2S-9zBTCj3N221QQRg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">动物照片由加州科学院提供。作者修改了一下。</p></figure><p id="e65a" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">该图显示了一个捕食者和它的猎物以及它们立体视觉的近似示意图。考虑深度、视野和精确度。你为什么假设这是不同的？当考虑不同的立体视图时，你会想到什么好处和问题？</p><h2 id="33c7" class="os mu jj bd mv ot ou dn mz ov ow dp nd lq ox oy nf lu oz pa nh ly pb pc nj jp bi translated">b)fisher-price 的立体视觉</h2><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi qz"><img src="../Images/14ee9a7d057a30aa9db27331cfcb6db0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yyftz702OveqHeUkGQ4UcQ.png"/></div></div></figure><figure class="nx ny nz oa gt iv gh gi paragraph-image"><div class="gh gi ra"><img src="../Images/a5c97f28171954f645979c22f5bcaf86.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*SxxKr7MDgRylzTTI1aI5Hg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图片来自 fisher-price.com</p></figure><p id="c61e" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">回想一下费雪公司的 3D 幻灯片浏览器。它到底是怎么工作的？音响起作用吗？如果有，如何实现？利用了哪些线索？从稍微不同的视点拍摄的同一主题的两幅图像如何融合产生 3D 效果？</p><h2 id="a5b4" class="os mu jj bd mv ot ou dn mz ov ow dp nd lq ox oy nf lu oz pa nh ly pb pc nj jp bi translated">c)其他问题</h2><p id="21be" class="pw-post-body-paragraph lh li jj lj b lk nl kt lm ln nm kw lp lq nn ls lt lu no lw lx ly np ma mb mc im bi translated">1.猎豹和羚羊立体看到的东西有什么区别？<br/> 2。不能用立体视觉寻找猎物的动物是什么？<br/> 3。哪些动物没有立体视觉系统，但使用其他感官(如嗅觉、听觉)来捕猎和探测猎物？<br/> 4。猫和狗谁的视力更好？</p></div></div>    
</body>
</html>