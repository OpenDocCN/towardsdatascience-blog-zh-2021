<html>
<head>
<title>Keywords to know before you start reading papers on GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在你开始阅读关于GANs的论文之前要知道的关键词</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/keywords-to-know-before-you-start-reading-papers-on-gans-8a08a665b40c?source=collection_archive---------21-----------------------#2021-03-22">https://towardsdatascience.com/keywords-to-know-before-you-start-reading-papers-on-gans-8a08a665b40c?source=collection_archive---------21-----------------------#2021-03-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="a753" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">初学者的深度学习</h2><div class=""/><div class=""><h2 id="6a1c" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">用简单的英语解释重要的重复出现的关键词/概念</h2></div><p id="810a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi ln translated">不可否认的是，甘们很棒！如果你不知道它们是什么，看看这篇文章，我<a class="ae lw" href="https://medium.com/swlh/how-i-would-explain-gans-from-scratch-to-a-5-year-old-part-1-ce6a6bccebbb" rel="noopener">从零开始向一个5岁的孩子解释GANs</a>以及<a class="ae lw" href="https://pub.towardsai.net/step-by-step-implementation-of-gans-on-custom-image-data-in-pytorch-part-2-182f2fa16114" rel="noopener ugc nofollow" target="_blank">如何在Pytorch </a>中实现GANs！简而言之，gan属于生成模型的一个类别，它让我们生成令人难以置信的真实合成数据，与基础训练数据具有相同的质量。这意味着，如果你输入一些卧室装饰的模型图像，经过几个小时的训练，它可以为你的室内设计产生前所未见的全新想法。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi lx"><img src="../Images/c0b0adea8e6f38b11fe41b37d5f06148.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vp3at7jM4nrKzBx0SVBeZg.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated"><a class="ae lw" href="https://drive.google.com/drive/folders/1ToY5P4Vvf5_c3TyUizQ8fckFFoFtBvD8" rel="noopener ugc nofollow" target="_blank">由<a class="ae lw" href="https://arxiv.org/abs/1812.04948" rel="noopener ugc nofollow" target="_blank"> StyleGAN </a>生成的卧室设计</a>【根据<a class="ae lw" href="https://creativecommons.org/licenses/by-nc/4.0/" rel="noopener ugc nofollow" target="_blank">Creative Commons BY-NC 4.0</a>许可证提供】</p></figure></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="b506" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在过去的几周里，我可能已经阅读了十几篇关于GANs(及其变体)的论文，并在自定义图像上修补了他们的代码(由开源Github repos提供)。虽然这些论文中的大部分都写得很精彩，但我希望在我投入这些学术写作的手稿之前，有几个我已经知道的关键词。下面我将讨论其中的一些，并希望当你在论文中遇到它们时，它能节省你一些时间(和挫折)。先明确一点，这不是一篇深入解释这些论文甚至如何编码的文章，只是简单解释一下某些关键词在特定语境下的含义。请放心，当我读到更多内容时，我会确保更新这个列表。</p><p id="ad04" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">至于先决条件，我假设你们大多数人已经知道什么是与GANs相关的鉴别器和发生器网络。也就这样了！对于那些可能需要回顾的人:</p><blockquote class="mv mw mx"><p id="2ce4" class="kr ks mu kt b ku kv kd kw kx ky kg kz my lb lc ld mz lf lg lh na lj lk ll lm im bi translated">一个生成器网络的目标是产生看起来像真的假图像。它接受一个随机向量作为输入(比如一个来自高斯分布的100维数组),并输出一个足够真实的图像，看起来像是属于我们的训练集！</p><p id="3c87" class="kr ks mu kt b ku kv kd kw kx ky kg kz my lb lc ld mz lf lg lh na lj lk ll lm im bi translated">鉴别器网络正确地猜测图像是假的(即由生成器生成)还是真的(即直接来自输入源)。</p></blockquote><p id="ae50" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们开始吧！</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="fbcb" class="nb nc it bd nd ne nf dn ng nh ni dp nj la nk nl nm le nn no np li nq nr ns iz bi translated">图像的潜在表示</h2><p id="3ffc" class="pw-post-body-paragraph kr ks it kt b ku nt kd kw kx nu kg kz la nv lc ld le nw lg lh li nx lk ll lm im bi translated">要理解潜在表示，请这样想:我的任何高度和宽度为100的彩色图像都可能存储在一个形状数组(100，100，3)中。为了以某种形式表现或可视化这个图像，我需要大约100*100*3 ≈ 300k的维度。哎哟，太多了！</p><p id="8dd5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">因此，现在我们试图找到一个压缩的图像表示，这样它需要少于300k的维度。假设我们用某种降维技术找到了一个仅使用5维的表示。这意味着，现在我的图像可以用一个(假设的)向量<code class="fe ny nz oa ob b">v1 = [.1,.56,.89,.34,.90]</code>(其中. 1，. 56，. 89等等)来表示。是沿着五个轴中的每一个轴的值)并且我朋友的图像可以使用向量<code class="fe ny nz oa ob b">v2 = [.20,.45,.86,.21,.32]</code>来表示。这些向量被称为图像的<strong class="kt jd">潜在表现</strong>。</p><p id="5878" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">当然，将它们可视化仍然是一个挑战，因为五维表示更难解析。然而，实际上，我们使用了比简单的5更大的表示(大约100个)。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="4b7c" class="nb nc it bd nd ne nf dn ng nh ni dp nj la nk nl nm le nn no np li nq nr ns iz bi translated">潜在空间</h2><p id="81e6" class="pw-post-body-paragraph kr ks it kt b ku nt kd kw kx nu kg kz la nv lc ld le nw lg lh li nx lk ll lm im bi translated">上面描述的两个向量(还有我的朋友、同事、家庭成员等等)。)构成了<strong class="kt jd">的潜伏空间</strong>。在这个潜在空间中，相似的图像(比如两只猫的图像)会被捆绑得更近，而显著不同的图像(猫对汽车)会被分开得更远。</p><p id="67cc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">简而言之，潜在空间可以被认为是一个图像的所有潜在表现都存在的空间。如果每个图像用两个元素的向量表示，这个空间可以是2D；如果每个图像使用三元素向量表示，则为3D；诸如此类。</p><p id="0c3e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这个空间被称为“潜在的”，意思是隐藏的，仅仅是因为在现实中很难想象这个空间。你能想象在你的头脑中想象出三维空间之外的任何东西吗，更不用说100维空间了！</p><blockquote class="mv mw mx"><p id="7ae7" class="kr ks mu kt b ku kv kd kw kx ky kg kz my lb lc ld mz lf lg lh na lj lk ll lm im bi translated">潜在空间只是包含点(表示图像)的任何假设空间，以某种方式，生成器知道如何将潜在空间中的点转换为图像(最好看起来类似于它被训练的数据集)。</p></blockquote><p id="b43b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">附:如果我没有链接到<a class="oc od ep" href="https://medium.com/u/684d91ee6205?source=post_page-----8a08a665b40c--------------------------------" rel="noopener" target="_blank"> Ekin Tiu </a>的这篇<a class="ae lw" rel="noopener" target="_blank" href="/understanding-latent-space-in-machine-learning-de5a7c687d8d">精彩文章</a>，那将是一种耻辱，这篇文章更详细地解释了潜在空间背后的直觉。此外，不要忘记看看他对包含0-9数字的潜在空间的特殊视觉表现。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="0363" class="nb nc it bd nd ne nf dn ng nh ni dp nj la nk nl nm le nn no np li nq nr ns iz bi translated">z空间</h2><p id="2c08" class="pw-post-body-paragraph kr ks it kt b ku nt kd kw kx nu kg kz la nv lc ld le nw lg lh li nx lk ll lm im bi translated">根据先前对潜在空间的定义，Z空间可以被定义为所有Z向量所在的空间。一个<em class="mu"> z </em>向量只不过是一个包含来自高斯(正态)分布的随机值的向量。</p><p id="cde6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">z向量通常作为输入传递给完全训练的GAN发生器模型，然后该模型吐出看起来真实的假图像。</p><p id="6cba" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果你在GAN的一篇论文中遇到类似“<em class="mu">从Z空间中采样一个点</em>”或“<em class="mu">从Z空间中采样一个潜在代码</em>”的内容，请将其视为从Z空间中选取一个点，即正态分布的实数向量。</p><p id="bc81" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="mu">附:在最初的GANs和DCGAN论文中，z向量是100维的！</em></p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="c274" class="nb nc it bd nd ne nf dn ng nh ni dp nj la nk nl nm le nn no np li nq nr ns iz bi translated">风格代码/风格向量</h2><p id="cfe6" class="pw-post-body-paragraph kr ks it kt b ku nt kd kw kx nu kg kz la nv lc ld le nw lg lh li nx lk ll lm im bi translated">在你学习完香草甘之后，你会发现一种新的甘，即StyleGANs。虽然GANs充其量只能完美地复制训练数据，并产生更多看起来像它的数据，但StyleGANs的酷之处在于，它们允许生成高保真图像，其中有更多的变化——各种背景、雀斑、眼镜、发型等。</p><p id="9a91" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为此，作者实现了各种架构改进。其中之一如下:不是将z向量直接传递到生成器(仅供参考，有时在StyleGANs的论文中也称为合成网络)，而是首先通过映射网络来产生<em class="mu"> w向量</em>又名<em class="mu">样式代码</em>又名<em class="mu">样式向量</em>。然后，这被注入到不同层的合成网络中(经过一些特定层的转换)，我们得到的输出是一个令人敬畏的高保真图像。</p><p id="1c65" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="mu">p . s . StyleGAN架构中Z和W空间的形状都是512-D，而且Z的分布是高斯型的，但是W空间不遵循任何特定的分布。</em></p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="6128" class="nb nc it bd nd ne nf dn ng nh ni dp nj la nk nl nm le nn no np li nq nr ns iz bi translated">W-space和扩展w-space (W+)</h2><p id="6958" class="pw-post-body-paragraph kr ks it kt b ku nt kd kw kx nu kg kz la nv lc ld le nw lg lh li nx lk ll lm im bi translated">到目前为止，希望您已经理解了如何定义空间。因此，自然地，W-space是上面定义的所有样式向量<code class="fe ny nz oa ob b">w</code>的一些假设居所，这样，如果我们从这个空间中随机选取一个向量，并将其馈送到StyleGAN生成器，它就能够产生一个看起来很真实的假图像(比如说，I)。</p><p id="2662" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">潜在空间W在StyleGANs中是一个非常重要的概念，因为它是控制图像各种属性/特征的关键。这是因为W空间被<em class="mu">解开</em>，这意味着512个维度中的每一个都编码了关于图像的独特信息——例如，第一维可能控制表情，第二维控制姿势，第三维控制照明，等等。这种知识允许我们对图像进行某些修改。例如，如果我以某种方式知道向量<code class="fe ny nz oa ob b">w</code>中要改变的<em class="mu">右</em>值，以生成<code class="fe ny nz oa ob b">w’</code>，然后将<code class="fe ny nz oa ob b">w’</code>馈送给StyleGAN生成器，它可以生成原始图像I的微笑版本(注意:我们将在教程的后面看到如何在潜在代码中找到这些要改变的“正确”值)。</p><p id="88a8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">很多时候，为了增加StyleGAN生成器的表现力(即，生成看起来与“平均”人脸不同的独特不同人脸的能力)，我们不是对所有层使用一个样式向量，而是对合成/生成器网络中的每一层使用一个独特的样式代码。这被称为W-空间的扩展，通常表示为W+。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="42ab" class="nb nc it bd nd ne nf dn ng nh ni dp nj la nk nl nm le nn no np li nq nr ns iz bi translated">在潜在空间中编码/投影/嵌入图像</h2><p id="b60f" class="pw-post-body-paragraph kr ks it kt b ku nt kd kw kx nu kg kz la nv lc ld le nw lg lh li nx lk ll lm im bi translated">虽然能够对StyleGAN生成器生成的假图像的面部特征进行修改很酷，但更酷的是，如果我们可以在你和我的真实图像上做所有这些事情。</p><p id="27a2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">要做到这一点，第一步是在StyleGAN的W空间中找到我的图像的潜在表示(这样我就可以修改那里的正确值来生成我的微笑/皱眉的图片)。这就是，在W空间中找到一个向量，当这个向量被输入到一个StyleGAN生成器时，它会输出我的精确图像。这就是所谓的在潜在空间中嵌入/投影/编码图像。</p><p id="8d77" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae lw" href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Abdal_Image2StyleGAN_How_to_Embed_Images_Into_the_StyleGAN_Latent_Space_ICCV_2019_paper.pdf" rel="noopener ugc nofollow" target="_blank">研究</a>表明，嵌入真实的输入图像在映射到预先训练的StyleGAN的扩展潜在空间(W+)时效果最佳。这意味着潜在表示将具有形状(18，512)，即18个唯一的样式代码，每个代码由512个元素嵌入组成。</p><p id="8cec" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="mu">注意:能够以1024 × 1024的分辨率合成图像的StyleGAN发生器有18个样式输入层。这就是为什么W+中的潜在代码采用(18，512)的形状。如果你的风格是以比这个更高或更低的分辨率合成图像，相应的风格输入数量可能会不同，你的潜在表现形式也会不同。</em></p><p id="f6c3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在回到主要问题:<em class="mu">我如何找到我的图像的矢量/潜在表示？</em>GAN反转就是这么回事！</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="a755" class="nb nc it bd nd ne nf dn ng nh ni dp nj la nk nl nm le nn no np li nq nr ns iz bi translated">GAN反转</h2><p id="25e9" class="pw-post-body-paragraph kr ks it kt b ku nt kd kw kx nu kg kz la nv lc ld le nw lg lh li nx lk ll lm im bi translated">GAN反转是获得给定图像的潜在代码的过程，以便当代码被馈送到生成器时，我们可以容易地重建我们的原始图像。</p><p id="b9e2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我不知道这对你来说是不是一个好消息，但如果不是，这里有另一种方式来思考GAN反转的有用性(附注:我不能对以下内容负责，我在互联网上的某个地方读到的):</p><blockquote class="oe"><p id="f44e" class="of og it bd oh oi oj ok ol om on lm dk translated">在某种程度上，任何已经出生或将要出生的人都存在于潜在空间中。(你只需要找到正确的反演)。</p></blockquote><p id="c04e" class="pw-post-body-paragraph kr ks it kt b ku oo kd kw kx op kg kz la oq lc ld le or lg lh li os lk ll lm im bi translated">文献中定义了两种用于反转图像的主要方法:</p><ul class=""><li id="a2ab" class="ot ou it kt b ku kv kx ky la ov le ow li ox lm oy oz pa pb bi translated">方法1:选择一个随机的潜在代表，并努力优化它，直到你最小化给定图像的误差。这种方法需要更长的时间，但允许更好的重建。</li><li id="1c7f" class="ot ou it kt b ku pc kx pd la pe le pf li pg lm oy oz pa pb bi translated">方法2:训练编码器，使其能够将给定图像映射到其对应的潜在代码。这种方法比它的对应方法更快，但是重新创建的图像显示出更高的失真，尽管它们被证明是高度可编辑的。</li></ul><p id="d208" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">使用这两种方法中的任何一种(或两种方法的组合)，都有可能获得看起来与原始图像相当相似的GAN反转图像，并且失真(如果有的话)几乎不明显。这里有一个例子，一个虚构的人物，希迪阿纳贡耶，从一个好地方，由威廉·杰克森·哈珀和他的甘倒置的形象。相当了不起，不是吗！</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/37bcfa3eba97576743e84c8ac3b1b701.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*yo2wUyZu1WwFJOT-TbV1sQ.jpeg"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">的原图(左图)和甘的倒像(右图)。[图片由作者使用最近发布的<a class="ae lw" href="https://arxiv.org/abs/2102.02766" rel="noopener ugc nofollow" target="_blank"> e4e编码器</a>生成]。</p></figure><p id="61ae" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">然而，在我看来，获得完美的娱乐不应该是你的最终目标。更重要的是一旦你有了GAN倒像你会怎么处理它！更重要的是，<em class="mu">我们能否利用反转来进行有意义的图像编辑</em>？接下来我们来看看！</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="0b4d" class="nb nc it bd nd ne nf dn ng nh ni dp nj la nk nl nm le nn no np li nq nr ns iz bi translated">语义编辑</h2><p id="b9dc" class="pw-post-body-paragraph kr ks it kt b ku nt kd kw kx nu kg kz la nv lc ld le nw lg lh li nx lk ll lm im bi translated">GAN反转后最常见的步骤之一是编辑潜在代码，这样就可以成功地处理图像中的一些面部特征。作为一个例子，这里有一个微笑的希迪阿纳贡耶，通过操纵GAN反转的潜在代码获得:</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/b2cbe7da0e40d1d9719e7c1be34daa7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*YljsGwjrD8QlKo5TtYYwKQ.png"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">微笑编辑在甘倒像上的应用。[图片由作者生成]</p></figure><p id="5910" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">语义编辑</strong>用一个重要的考虑来封装这样的编辑，即<em class="mu">只有</em>预期的特征必须被修改，而其余的特征必须保持不变。例如，在上面的例子中，改变一个人的表情不会改变他们的性别或姿势。</p><p id="1580" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">正是因为这个原因，我们应该瞄准一个高度解纠缠的潜在空间，正如<a class="ae lw" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Shen_Interpreting_the_Latent_Space_of_GANs_for_Semantic_Face_Editing_CVPR_2020_paper.pdf" rel="noopener ugc nofollow" target="_blank">研究</a>所指出的，与Z空间相比，StyleGAN的W空间表现出更高的解纠缠度，主要是因为“W不局限于任何特定的分布，可以更好地模拟真实数据的底层特征”。这就是为什么，你会遇到的大多数现有的研究论文会试图在W空间而不是Z空间找到一个新图像的潜在表示。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="bbd9" class="nb nc it bd nd ne nf dn ng nh ni dp nj la nk nl nm le nn no np li nq nr ns iz bi translated">潜在空间插值</h2><p id="dc25" class="pw-post-body-paragraph kr ks it kt b ku nt kd kw kx nu kg kz la nv lc ld le nw lg lh li nx lk ll lm im bi translated">用投影潜在代码实现的另一个有趣的功能是与另一个潜在代码结合使用。怎么会？你可能会问！</p><p id="0979" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">简单地采取两个潜在的代码，这可能是你和你最喜欢的名人的图像代码。现在在一个发展良好的潜在空间，这两点会很远，因为很可能，你看起来一点也不像你最喜欢的名人。但是，您可以在这两个点之间选择一个点(在空间中)，将其馈送到生成器并创建一个中间输出。有点像你和你喜欢的名人的混搭，(或者可以说是私生子)!这就是<strong class="kt jd">潜在空间插值</strong>的全部内容——潜在空间中两个潜在代码之间的平滑过渡。</p><p id="5eed" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这里有一个由麻省理工学院研究人员发布的视频短片，可以帮助你形象化插值的概念。在这里，我们可以看到一把带扶手的宽椅子是如何变成一把没有扶手的高椅子的。</p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="pj pk l"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">线性空间内插【视频在<a class="ae lw" href="https://www.youtube.com/watch?v=mfx7uAkUtCI&amp;t=64s&amp;ab_channel=ChengkaiZhang" rel="noopener ugc nofollow" target="_blank">公共领域</a>可用】</p></figure><p id="900b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">最简单的线性插值可以使用简单的矢量算法来实现。也就是说，给定两个潜在向量:<code class="fe ny nz oa ob b">a</code>和<code class="fe ny nz oa ob b">b</code>(都具有(18，512)的形状)，分别对应于你和你的名人迷恋的潜在表示:</p><ul class=""><li id="38b4" class="ot ou it kt b ku kv kx ky la ov le ow li ox lm oy oz pa pb bi translated">如果我们正好在中途进行插值，我们将使用公式<br/> <code class="fe ny nz oa ob b">a_b_half = a * 0.5 + b * 0.5</code> <br/>得到一个新的点。在将<code class="fe ny nz oa ob b">a_b_half</code>输入生成器后，合成的图像看起来50%像你，50%像你喜欢的人。</li><li id="24bd" class="ot ou it kt b ku pc kx pd la pe le pf li pg lm oy oz pa pb bi translated">如果我们插入两者之间距离的四分之一，新的点可以使用公式<br/> <code class="fe ny nz oa ob b">a_b_quarter = a * 0.25 + b * 0.75</code> <br/>获得。在将<code class="fe ny nz oa ob b">a_b_quarter</code>输入到生成器后，结果图像看起来更像你的暗恋对象(我们提取了<code class="fe ny nz oa ob b">b</code>的75%的潜在代码)，而不太像你。</li></ul><blockquote class="mv mw mx"><p id="4fa6" class="kr ks mu kt b ku kv kd kw kx ky kg kz my lb lc ld mz lf lg lh na lj lk ll lm im bi translated">线性空间插值是显示两幅图像之间的过渡和探索GAN生成的潜在空间的好方法。这种探索有助于发展直觉，并确保甘所了解的潜在空间不是古怪的东西。</p></blockquote></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="1c87" class="nb nc it bd nd ne nf dn ng nh ni dp nj la nk nl nm le nn no np li nq nr ns iz bi translated">潜在方向/语义边界</h2><p id="b77b" class="pw-post-body-paragraph kr ks it kt b ku nt kd kw kx nu kg kz la nv lc ld le nw lg lh li nx lk ll lm im bi translated">回到处理面部属性的话题，我答应解释如何在图像的潜在表示中找到“正确”的值来修改。需要注意的重要一点是，需要修改的值将取决于您要修改的属性，如微笑姿势、照明等。</p><p id="d9b2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在找到这个值类似于在潜在空间中找到一个移动的方向，(很像做一些自由式插值)来看看是什么让一张脸从微笑变成皱眉，或者从睁开眼睛变成闭上眼睛，等等。</p><blockquote class="mv mw mx"><p id="a205" class="kr ks mu kt b ku kv kd kw kx ky kg kz my lb lc ld mz lf lg lh na lj lk ll lm im bi translated">属性<code class="fe ny nz oa ob b">A</code>的潜在方向/语义边界是一个向量，当其被添加到图像的潜在代码时，生成一个新的图像，其属性<code class="fe ny nz oa ob b">A</code>被添加到原始图像。</p></blockquote><p id="05d5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">有多种方法(有监督的和无监督的)来学习这些潜在的方向，但对我们来说幸运的是，这些方向通常由许多研究人员开源提供(在这里你可以找到<a class="ae lw" href="https://github.com/genforce/interfacegan/tree/master/boundaries" rel="noopener ugc nofollow" target="_blank">样式根</a>和<a class="ae lw" href="https://twitter.com/robertluxemburg/status/1207087801344372736" rel="noopener ugc nofollow" target="_blank">样式根2 </a>模型的方向)。</p><p id="b8b1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果您想自己生成这些方向(比如“年龄”属性)，实现细节已经在<a class="ae lw" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Shen_Interpreting_the_Latent_Space_of_GANs_for_Semantic_Face_Editing_CVPR_2020_paper.pdf" rel="noopener ugc nofollow" target="_blank"> InterfaceGAN </a>文件中提供:</p><ul class=""><li id="92c7" class="ot ou it kt b ku kv kx ky la ov le ow li ox lm oy oz pa pb bi translated">来自预训练GAN模型(可以是PGGAN、StyleGAN、StyleGAN2等)的W空间的样本潜在代码。)并使用代码生成少量图像。</li><li id="fa03" class="ot ou it kt b ku pc kx pd la pe le pf li pg lm oy oz pa pb bi translated">将生成的图像通过预先训练的年龄分类器，这样每张图像都有一个标签，其中包含<code class="fe ny nz oa ob b">A</code>是老还是年轻的信息。</li><li id="aa7a" class="ot ou it kt b ku pc kx pd la pe le pf li pg lm oy oz pa pb bi translated">现在训练一个线性SVM分类器，将潜在代码作为输入，标签作为输出。</li><li id="d24d" class="ot ou it kt b ku pc kx pd la pe le pf li pg lm oy oz pa pb bi translated">SVM学习的权重对应于年龄的潜在方向。</li></ul><p id="4498" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="mu">备注:通常情况下，学习到的方向在Github repo中存储为</em> <code class="fe ny nz oa ob b"><em class="mu">.npy</em></code> <em class="mu">文件或</em> <code class="fe ny nz oa ob b"><em class="mu">.pt</em></code> <em class="mu">文件。</em></p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h2 id="d5ab" class="nb nc it bd nd ne nf dn ng nh ni dp nj la nk nl nm le nn no np li nq nr ns iz bi translated">结论</h2><p id="b53c" class="pw-post-body-paragraph kr ks it kt b ku nt kd kw kx nu kg kz la nv lc ld le nw lg lh li nx lk ll lm im bi translated">在本教程中，我们解释了GANs领域中几个常见术语/概念/关键词的含义，如潜在空间、插值、反演、扩展潜在空间等。希望当你在文学中偶然发现这些术语时，你会对它们的解释有一个公平的想法。</p><p id="cb2e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">从现在开始，我认为你已经准备好正面处理GAN的大部分论文了。我强烈建议您阅读其中的一些文章(我目前最喜欢的是<a class="ae lw" href="https://arxiv.org/abs/2102.02766" rel="noopener ugc nofollow" target="_blank">这</a>、<a class="ae lw" href="https://arxiv.org/abs/2008.02401" rel="noopener ugc nofollow" target="_blank">这</a>和<a class="ae lw" href="https://arxiv.org/abs/2012.11856" rel="noopener ugc nofollow" target="_blank">这</a>)，因为其中的实现和架构细节超出了任何文章或博客的覆盖范围。像往常一样，如果我忽略了一些重要的东西，或者你有更简单的解释，请随时告诉我。</p><p id="3c22" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">直到下次:)</p></div></div>    
</body>
</html>