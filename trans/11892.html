<html>
<head>
<title>Precision-Recall Curve is More Informative than ROC in Imbalanced Data: Napkin Math &amp; More</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在不平衡数据中，精确回忆曲线比 ROC 更能提供信息:餐巾纸数学等等</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/precision-recall-curve-is-more-informative-than-roc-in-imbalanced-data-4c95250242f6?source=collection_archive---------3-----------------------#2021-11-29">https://towardsdatascience.com/precision-recall-curve-is-more-informative-than-roc-in-imbalanced-data-4c95250242f6?source=collection_archive---------3-----------------------#2021-11-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="39da" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">当负类更普遍且真-负预测值低时，精确-回忆曲线优于 ROC 曲线</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e76120e0b7b1d8f641bced1a1196755d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dDKSk2mBDabgLGMV"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">里卡多·阿尔塞在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="41a7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">类别不平衡是二进制预测建模空间中的常见问题。这种情况发生在两个阶层之间的分布高度倾斜的时候，通常是负数多于正数。此类预测任务的示例包括罕见疾病识别、欺诈检测或网页检索。对于不平衡数据的二元分类，已经提出了许多解决方案。但是，它们大多与数据重采样或模型训练相关。本文试图把更多的重点放在选择一个合适的最终模型的性能评价方法上。</p><h2 id="887c" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">准确性具有误导性</h2><p id="c3be" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">作为不平衡数据的衡量标准，准确性的失败是众所周知的。考虑一个数据集的情况，其比率为 1 个阳性对 100 个阴性。在这项任务中，一个预测所有情况都是负面的模型的准确率为 99%。然而，这个模型是一个虚拟分类器，它总是预测多数类。</p><h2 id="d08b" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">奥罗克过于乐观了</h2><p id="f5a7" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">由于两个原因，受试者操作特征(ROC)曲线和 ROC 曲线下面积(AUROC)已经成为评估不平衡数据的分类模型的最常见的度量。第一，对阶级分布不敏感。AUROC 等于随机选择的阳性病例排在随机选择的阴性病例之上的概率。该指标不关心数据集中有多少阳性和阴性案例。第二，AUROC 是阈值不变的。为了计算度量，我们不必决定区分正类和负类的阈值应该是多少。这意味着即使当两个预测误差成本(即，假阳性和假阴性)不相等时，该度量也与之无关。然而，当负类更普遍但真-负预测值低时，ROC 可以提供对模型性能的过于乐观的测量。例如，考虑具有 10 个阳性和 100，000 个阴性的数据集的情况。我们有两种型号:</p><ul class=""><li id="dd7a" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">模型 A:预测 900 个阳性，其中 9 个是真阳性</li><li id="e97d" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">模型 B:预测 90 个阳性，其中 9 个是真阳性</li></ul><p id="cc1c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">显然，B 型的性能更好。虽然它们都预测相同数量的真阳性，但模型 B 输出的假阳性没有那么多。换句话说，B 型更“精准”。然而，考虑两个模型的 ROC 分析，其测量真阳性率(TPR)与假阳性率(FPR):</p><ul class=""><li id="6de4" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">模型 A: TPR = 9/10 = 0.9，FPR =(900–9)/100，000 = 0.00891</li><li id="c24f" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">模型 B: TPR = 9/10 = 0.9，FPR =(90–9)/100，000 = 0.00081</li></ul><p id="5127" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如所料，两种型号的 TPR 完全相同。另一方面，由于负面因素的数量在很大程度上支配着正面因素的数量，因此两个模型之间的 FPR 差异(0.00891–0.00081 = 0.0081)在某种意义上可以四舍五入到几乎为零。换句话说，假阳性数量的巨大变化导致 FPR 的微小变化，因此，在真阴性与问题无关的情况下，ROC 无法反映模型 B 的优异性能。例如，在欺诈检测的情况下，调查人员只关心潜在的欺诈交易，他们可能不喜欢来自 ML 系统的通知说交易是正常和安全的(废话！).</p><h2 id="ec16" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">精确召回曲线更能提供信息</h2><p id="3bd8" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">相比之下，精确召回(PR)曲线是专门为检测罕见事件而定制的，并且是当正面类别比负面类别更令人感兴趣时应该使用的度量。因为精度和召回率不考虑真阴性，所以 PR 曲线不受数据不平衡的影响。回到上面的例子:</p><ul class=""><li id="f5b7" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">模型 A:召回率= TPR = 0.9，精确度= 9/900 = 0.01</li><li id="7ea1" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">模型 B:召回率= TPR = 0.9，精确度= 9/90 = 0.1</li></ul><p id="cd02" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">显然，与上面的 ROC 分析相比，PR 分析提供了更多的信息。</p><p id="94ad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，虽然 ROC 的随机基线固定为 0.5，但 PR 曲线的随机基线由正类别患病率决定，即 P / (P + N)。例如，对于平衡的等级分布，我们的基线 PR 为 0.5，但是对于不平衡的等级分布，基线 PR 为 0.09，其中每一个正数都有 10 个负数。由于 PR 曲线的随机基线基于阳性类别的患病率而移动，因此将 AUPRC 与其对应的基线进行比较而不是查看其绝对值至关重要。此外，考虑到 PR 曲线对患病率的敏感性，确保测试数据尽可能地反映真实人口的阶级分布(即使这种分布通常是未知的)是一个很好的做法。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/380eaf06473f9c2163c18461d8eeed7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m4KRb4nXL0p9RRTJsj2D5A.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。当 ROC 的随机基线固定在 0.5 时，PR 曲线的随机基线由正类患病率决定。</p></figure></div><div class="ab cl nf ng hu nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="ij ik il im in"><p id="a4a0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">如果你喜欢这篇文章，你可能也会喜欢:</strong></p><div class="nm nn gp gr no np"><a rel="noopener follow" target="_blank" href="/performance-curve-more-intuitive-than-roc-prc-and-less-assumptive-than-threshold-metrics-391e777da566"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd ir gy z fp nu fr fs nv fu fw ip bi translated">性能曲线:比 ROC/PRC 更直观，比阈值指标更少假设</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">一种结合两者优点的二元分类器评价方法</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">towardsdatascience.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od kp np"/></div></div></a></div><div class="nm nn gp gr no np"><a rel="noopener follow" target="_blank" href="/the-wrong-and-right-way-to-approximate-area-under-precision-recall-curve-auprc-8fd9ca409064"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd ir gy z fp nu fr fs nv fu fw ip bi translated">精确召回曲线下面积的正确与错误</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">总结 AUPRC 的方法有很多，但并不是所有的方法都有相同的优点</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">towardsdatascience.com</p></div></div><div class="ny l"><div class="oe l oa ob oc ny od kp np"/></div></div></a></div></div></div>    
</body>
</html>