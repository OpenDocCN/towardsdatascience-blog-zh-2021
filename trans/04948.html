<html>
<head>
<title>Build Your Own Movie Recommender System Using BERT4Rec</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用BERT4Rec构建您自己的电影推荐系统</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/build-your-own-movie-recommender-system-using-bert4rec-92e4e34938c5?source=collection_archive---------9-----------------------#2021-04-30">https://towardsdatascience.com/build-your-own-movie-recommender-system-using-bert4rec-92e4e34938c5?source=collection_archive---------9-----------------------#2021-04-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="984f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">PyTorch中基于变压器的推荐系统的分步实现</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/10f359a52990646904166161627208a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PHlW0hEt0XDNEJKGoEZugQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在<a class="ae kv" href="https://unsplash.com/s/photos/movie?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae kv" href="https://unsplash.com/@myke_simon?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Myke Simon </a>拍摄的照片</p></figure><p id="99b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">推荐算法是我们每天使用的许多服务的核心部分，从YouTube上的视频推荐到亚马逊上的购物项目，不要忘记网飞。<br/>在这篇文章中，我们将实现一个简单而强大的推荐系统，名为<a class="ae kv" href="https://arxiv.org/abs/1904.06690" rel="noopener ugc nofollow" target="_blank"> BERT4Rec:来自Transformer </a>的双向<br/>编码器表示的顺序推荐。<br/>我们将在约60，000部电影的数据库上，将该模型应用于电影推荐。</p><h1 id="f75a" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">任务</h1><p id="8c64" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们的目标是向用户推荐他们过去看过的电影。该推荐直接从数据中学习，并且针对每个用户进行个性化。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/c8151fdbc07643b0a6614764895ae386.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*BiByPdyN8EaJsTwedw_sfg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="5f2e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">数据</h1><p id="356e" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们将使用MovieLens-25m数据集(<a class="ae kv" href="https://grouplens.org/datasets/movielens/25m/" rel="noopener ugc nofollow" target="_blank">https://grouplens.org/datasets/movielens/25m/</a>)。这是一个记录162541个用户和62423部电影之间互动的数据集。</p><p id="430b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以为每个用户构建他们互动的电影的时间排序序列。我们将使用这些序列来训练我们的推荐系统。</p><h1 id="e758" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">模型</h1><p id="83ea" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">BERT4Rec很像NLP的常规BERT。这是一个变形金刚网络，它被训练来从用户的历史中预测“屏蔽”的电影。</p><p id="c05d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一步是以按时间排序的电影列表的形式构建用户的历史记录。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/88924fbe8216bb16304ce4f03e84d769.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*9JpSz8BaxsR1po1jlNymAg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="ab9b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中一些电影被一个符号[面具]所取代。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/813c6720e407c8f9170c58d60a20784c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*CjIgQLlduznkoc0Ecnhq2Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="28e8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后对BERT4Rec模型的任务进行训练，以尝试预测[MASK]项的正确值。通过这样做，模型将学习每部电影的有用表示，以及电影之间存在的重要模式。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/16b5c0b54ed5c72e161faaa4f0014eb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*lqm4sPvkRw5GzqWzMVy17w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="4f4c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后为了进行推断，我们可以在用户序列的末尾添加一个[MASK]来预测他们将来最有可能想要的电影。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/5e6e7f6f5e77abd12a1b8371a3f5ce19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kbLM9-H7d48peqjxyOOPxA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="dddd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">BERT4Rec是一种常规的转换器架构，类似于NLP中使用的架构:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/68dcdcd73f5920a0a3e7ed6077849d29.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*DQhGBSMeiqFpxFlVtwVxpA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">变压器层</p></figure><p id="3d25" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">序列中的每个电影都被映射到一个嵌入向量。</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="2a06" class="mz lt iq mv b gy na nb l nc nd">src_items = self.item_embeddings(src_items)</span></pre><p id="fe81" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，自我关注是允许这种架构对输入序列的元素之间的长期依赖性进行建模的原因。</p><p id="c3b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">顺序通过位置嵌入来建模，其中我们在每个时间步学习一个“位置向量”。</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="0b72" class="mz lt iq mv b gy na nb l nc nd"><br/>batch_size, in_sequence_len = src_items.size(0), src_items.size(1)<br/>pos_encoder = (<br/>    torch.arange(0, in_sequence_len, device=src_items.device)<br/>    .unsqueeze(0)<br/>    .repeat(batch_size, 1)<br/>)<br/>pos_encoder = self.input_pos_embedding(pos_encoder)<br/><br/>src_items += pos_encoder</span></pre><p id="94b4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，在每个时间步，模型从62423部电影中输出每个可能选项的预测分数。我们使用这些分数来优化分类交叉熵损失。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/de0461820bf1ad35c2da20b7d966ae00.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*0UVwCGlAPEkJyhR9b72XQA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">培训日志</p></figure><h1 id="588d" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">模型使用示例</h1><p id="314c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">现在，我们将使用经过训练的模型，根据三种情况提出建议:</p><h2 id="e254" class="mz lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">场景1:冒险/幻想</h2><p id="f42a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">用户历史--&gt;</p><ul class=""><li id="a08d" class="nq nr iq ky b kz la lc ld lf ns lj nt ln nu lr nv nw nx ny bi translated">《哈利·波特与魔法石》(又名《哈利·波特与魔法石》)(2001年)</li><li id="2cad" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">哈利·波特与密室(2002)</li><li id="536b" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">哈利·波特与阿兹卡班的囚徒(2004)</li><li id="9823" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">哈利·波特与火焰杯(2005)</li></ul><p id="d7d2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">车型推荐-&gt;</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="81ab" class="mz lt iq mv b gy na nb l nc nd">['<strong class="mv ir">Ice Age (2002)</strong>',<br/> "<strong class="mv ir">Pirates of the Caribbean: Dead Man's Chest (2006)</strong>",<br/> '<strong class="mv ir">Avatar (2009)</strong>',<br/> 'Star Wars: Episode III - Revenge of the Sith (2005)',<br/> 'Shrek 2 (2004)',<br/> 'Ratatouille (2007)',<br/> 'Bruce Almighty (2003)',<br/> 'I, Robot (2004)',<br/> 'Last Samurai, The (2003)',<br/> 'Up (2009)',<br/> 'Matrix Revolutions, The (2003)',<br/> 'Men in Black II (a.k.a. MIIB) (a.k.a. MIB 2) (2002)',<br/> 'Iron Man (2008)',<br/> '<strong class="mv ir">Spirited Away (Sen to Chihiro no kamikakushi) (2001)</strong>',<br/> '300 (2007)',<br/> 'Big Fish (2003)',<br/> "Bridget Jones's Diary (2001)",<br/> 'My Big Fat Greek Wedding (2002)',<br/> 'Pianist, The (2002)',<br/> 'Interstellar (2014)',<br/> 'Shaun of the Dead (2004)',<br/> 'Moulin Rouge (2001)',<br/> 'Juno (2007)',<br/> 'WALL·E (2008)',<br/> 'Casino Royale (2006)',<br/> 'School of Rock (2003)',<br/> '40-Year-Old Virgin, The (2005)',<br/> '<strong class="mv ir">Harry Potter and the Order of the Phoenix (2007)</strong>',<br/> 'Bourne Supremacy, The (2004)',<br/> 'Miss Congeniality (2000)']</span></pre><p id="1692" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到，该模型在冒险/幻想流派中提出了一些有趣的建议。请注意，该模型无法访问电影的类型。</p><h2 id="e2c8" class="mz lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">场景2:动作/冒险</h2><p id="e8a6" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">用户历史--&gt;</p><ul class=""><li id="d2cc" class="nq nr iq ky b kz la lc ld lf ns lj nt ln nu lr nv nw nx ny bi translated">黑豹(2017年)</li><li id="9d06" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">复仇者联盟(2012)</li><li id="742a" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">复仇者联盟3：无限战争—第一部分(2018年)</li><li id="dfa3" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">洛根(2017)</li><li id="2781" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">蜘蛛侠(2002)</li><li id="801c" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">蜘蛛侠3 (2007)</li><li id="f39d" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">《蜘蛛侠:远离家乡》(2019)</li></ul><p id="934d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">车型推荐-&gt;</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="0e8b" class="mz lt iq mv b gy na nb l nc nd">['<strong class="mv ir">Avengers: Infinity War - Part II (2019)</strong>',<br/> '<strong class="mv ir">Deadpool 2 (2018)</strong>',<br/> '<strong class="mv ir">Thor: Ragnarok (2017)</strong>',<br/> '<strong class="mv ir">Spider-Man: Into the Spider-Verse (2018)</strong>',<br/> '<strong class="mv ir">Captain Marvel (2018)</strong>',<br/> 'Incredibles 2 (2018)',<br/> '<strong class="mv ir">Untitled Spider-Man Reboot (2017)</strong>',<br/> 'Ant-Man and the Wasp (2018)',<br/> 'Guardians of the Galaxy 2 (2017)',<br/> 'Iron Man 2 (2010)',<br/> 'Thor (2011)',<br/> 'Guardians of the Galaxy (2014)',<br/> 'Captain America: The First Avenger (2011)',<br/> 'X-Men Origins: Wolverine (2009)',<br/> "Ocean's 8 (2018)",<br/> 'Wonder Woman (2017)',<br/> 'Iron Man 3 (2013)',<br/> 'Pirates of the Caribbean: The Curse of the Black Pearl (2003)',<br/> 'Amazing Spider-Man, The (2012)',<br/> 'Aquaman (2018)',<br/> 'Dark Knight, The (2008)',<br/> 'Mission: Impossible - Fallout (2018)',<br/> 'Avengers: Age of Ultron (2015)',<br/> 'Jurassic World: Fallen Kingdom (2018)',<br/> 'Iron Man (2008)',<br/> 'Coco (2017)',<br/> 'Lord of the Rings: The Two Towers, The (2002)',<br/> 'Rogue One: A Star Wars Story (2016)',<br/> 'X-Men: The Last Stand (2006)',<br/> 'Venom (2018)']</span></pre><p id="300c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些建议完全正确！大部分来自漫威宇宙，就像用户的历史一样。</p><h2 id="867f" class="mz lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">场景3:喜剧</h2><p id="da78" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">用户历史--&gt;</p><ul class=""><li id="c5ea" class="nq nr iq ky b kz la lc ld lf ns lj nt ln nu lr nv nw nx ny bi translated">疯狂动物城(2016)</li><li id="2f71" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">玩具总动员3 (2010)</li><li id="4f18" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">玩具总动员4 (2019)</li><li id="6661" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">海底总动员(2003)</li><li id="9f7d" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">《料理鼠王》(2007)</li><li id="5850" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">乐高电影(2014)</li><li id="5b8a" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">捉鬼敢死队(又名捉鬼敢死队)(1984)</li><li id="789b" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">艾斯·文图拉:当自然召唤(1995)</li></ul><p id="634e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">车型推荐-&gt;</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="dc46" class="mz lt iq mv b gy na nb l nc nd">['<strong class="mv ir">Home Alone (1990)</strong>',<br/> "<strong class="mv ir">Bug's Life, A (1998)</strong>",<br/> '<strong class="mv ir">Toy Story 2 (1999)</strong>',<br/> 'Nightmare Before Christmas, The (1993)',<br/> 'Babe (1995)',<br/> '<strong class="mv ir">Inside Out (2015)</strong>',<br/> '<strong class="mv ir">Mask, The (1994)</strong>',<br/> '<strong class="mv ir">Toy Story (1995)</strong>',<br/> 'Back to the Future (1985)',<br/> 'Back to the Future Part II (1989)',<br/> 'Simpsons Movie, The (2007)',<br/> 'Forrest Gump (1994)',<br/> 'Austin Powers: International Man of Mystery (1997)',<br/> 'Monty Python and the Holy Grail (1975)',<br/> 'Cars (2006)',<br/> 'Kung Fu Panda (2008)',<br/> 'Groundhog Day (1993)',<br/> 'American Pie (1999)',<br/> 'Men in Black (a.k.a. MIB) (1997)',<br/> 'Dumb &amp; Dumber (Dumb and Dumber) (1994)',<br/> 'Back to the Future Part III (1990)',<br/> 'Big Hero 6 (2014)',<br/> 'Mrs. Doubtfire (1993)',<br/> 'Clueless (1995)',<br/> 'Bruce Almighty (2003)',<br/> 'Corpse Bride (2005)',<br/> 'Deadpool (2016)',<br/> 'Up (2009)',<br/> "Ferris Bueller's Day Off (1986)"]</span></pre><p id="8eba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种情况下，该模型能够推荐一些很棒的电影，如《玩具总动员1》或《独自回家》，这些电影符合用户历史的主题。</p><h1 id="ed34" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="b12d" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在这个项目中，我们构建了一个强大的电影推荐系统，名为BERT4Rec。这是一个基于transformer层的模型，使用与BERT非常相似的方案进行训练，其中我们屏蔽了用户电影历史序列的一些元素，然后尝试预测这些项目的真实值。</p><p id="f715" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你看看下面代码中的实现细节--&gt;</p><p id="ebf8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">代号:<a class="ae kv" href="https://github.com/CVxTz/recommender_transformer/blob/main/notebooks/inference.ipynb" rel="noopener ugc nofollow" target="_blank">https://github.com/CVxTz/recommender_transformer/</a></p></div></div>    
</body>
</html>