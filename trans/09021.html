<html>
<head>
<title>Choose the Best ML Model Based On Visualizations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于可视化选择最佳的ML模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/choose-best-ml-model-based-on-visualization-ed6398ac3005?source=collection_archive---------14-----------------------#2021-08-20">https://towardsdatascience.com/choose-best-ml-model-based-on-visualization-ed6398ac3005?source=collection_archive---------14-----------------------#2021-08-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2118" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Combo比较机器学习模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/2daf2fa61358cd7d3a40066199ed2e0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*7aEyYdIhjK1UTm9qDp4yWA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">来源:作者</p></figure><p id="8e04" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">比较不同的机器学习模型是一项艰巨的任务，因为我们需要创建不同的模型，拟合它们，然后评估它们。编写数百行代码，然后使用不同的可视化工具进行评估是一个耗时的过程。</p><p id="c9d5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我告诉您，您可以节省创建不同模型和评估它们的所有时间和精力，会怎么样？Combo是一个开源Python库，用于创建数据可视化，有助于轻松轻松地评估不同的机器学习。</p><p id="f082" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在本文中，我们将探索Combo并使用它创建一些可视化效果。</p><p id="caaa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们开始吧…</p><h1 id="7bf2" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">安装所需的库</h1><p id="5267" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">我们将从使用pip安装来安装Combo开始。下面给出的命令将使用pip安装Combo。</p><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="2bc2" class="ms lr it mo b gy mt mu l mv mw">pip install combo</span></pre><h1 id="a07b" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">导入所需的库</h1><p id="e1f8" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">在这一步中，我们将导入创建模型和可视化这些模型所需的所有库。</p><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="d1ba" class="ms lr it mo b gy mt mu l mv mw">import os<br/>import sys<br/>sys.path.append(<br/>    os.path.abspath(os.path.join(os.path.dirname("__file__"), '..')))<br/>import warnings<br/>warnings.filterwarnings("ignore")<br/>import numpy as np<br/>from numpy import percentile<br/>import matplotlib.pyplot as plt<br/>import matplotlib.font_manager</span><span id="4e83" class="ms lr it mo b gy mx mu l mv mw"># Import all models<br/>from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.ensemble import AdaBoostClassifier<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.naive_bayes import GaussianNB<br/>from sklearn.svm import SVC<br/>from sklearn.neighbors import KNeighborsClassifier</span><span id="ef3b" class="ms lr it mo b gy mx mu l mv mw">from combo.models.classifier_comb import SimpleClassifierAggregator<br/>from combo.models.classifier_stacking import Stacking<br/>from combo.models.classifier_dcs import DCS_LA<br/>from combo.models.classifier_des import DES_LA</span></pre><h1 id="2d5a" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">创建数据集</h1><p id="507f" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">对于本文，我们将使用2个类创建自己的数据集。在下面给出的代码中，您可以看到我们如何创建数据集。</p><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="e1d8" class="ms lr it mo b gy mt mu l mv mw"># Define the number of class 0 and class 1<br/>n_samples = 300<br/>class1_fraction = 0.5<br/>clusters_separation = [3]</span><span id="503e" class="ms lr it mo b gy mx mu l mv mw"># Compare given detectors under given settings<br/># Initialize the data<br/>xx, yy = np.meshgrid(np.linspace(-7, 7, 100), np.linspace(-7, 7, 100))<br/>n_class0 = int((1. - class1_fraction) * n_samples)<br/>n_class1 = int(class1_fraction * n_samples)<br/>ground_truth = np.zeros(n_samples, dtype=int)<br/>ground_truth[-n_class1:] = 1</span><span id="67db" class="ms lr it mo b gy mx mu l mv mw"># Show the statics of the data<br/>print('Number of Class 0: %i' % n_class0)<br/>print('Number of Class 1: %i' % n_class1)<br/>print('Ground truth shape is {shape}.\n'.format(shape=ground_truth.shape))<br/>print(ground_truth, '\n')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/3fb92f9111393ff497a970112b2f27e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*H-58r7-Vlg4uneimoo7Dgg.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">数据集(来源:作者)</p></figure><h1 id="bc4e" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">创建用于比较的模型</h1><p id="1901" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">在这里，我们将创建我们将比较的所有模型，然后，我们使用Combo来可视化模型。</p><pre class="kj kk kl km gt mn mo mp mq aw mr bi"><span id="d70d" class="ms lr it mo b gy mt mu l mv mw">random_state = np.random.RandomState(42)</span><span id="2f42" class="ms lr it mo b gy mx mu l mv mw">classifiers = [LogisticRegression(), GaussianNB(), SVC(probability=True),<br/>               KNeighborsClassifier()]</span><span id="9631" class="ms lr it mo b gy mx mu l mv mw"># Define some combination methods to be compared<br/>classifiers = {</span><span id="8f2b" class="ms lr it mo b gy mx mu l mv mw">'Logistic Regression': LogisticRegression(),<br/>    'Gaussian NB': GaussianNB(),<br/>    'Support Vector Machine': SVC(probability=True),<br/>    'k Nearst Neighbors': KNeighborsClassifier(),<br/>    'Simple Average': SimpleClassifierAggregator(base_estimators=classifiers,<br/>                                                 method='average'),<br/>    'Simple Maximization': SimpleClassifierAggregator(<br/>        base_estimators=classifiers, method='maximization'),<br/>    'Stacking': Stacking(base_estimators=classifiers, shuffle_data=True),<br/>    'Stacking_RF': Stacking(base_estimators=classifiers, shuffle_data=True,<br/>                            meta_clf=RandomForestClassifier(<br/>                                random_state=random_state)),<br/>    'DCS_LA': DCS_LA(base_estimators=classifiers),<br/>    'DEC_LA': DES_LA(base_estimators=classifiers)<br/>}</span><span id="90e1" class="ms lr it mo b gy mx mu l mv mw"># Show all classifiers<br/>for i, clf in enumerate(classifiers.keys()):<br/>    print('Model', i + 1, clf)</span><span id="42e6" class="ms lr it mo b gy mx mu l mv mw"># Fit the models with the generated data and<br/># compare model performances<br/>for i, offset in enumerate(clusters_separation):<br/>    np.random.seed(42)<br/>    # Data generation<br/>    X1 = 0.3 * np.random.randn(n_class0 // 2, 2) - offset<br/>    X2 = 0.3 * np.random.randn(n_class0 // 2, 2) + offset<br/>    X = np.r_[X1, X2]<br/>    # Add class 1<br/>    X = np.r_[X, np.random.uniform(low=-6, high=6, size=(n_class1, 2))]</span><span id="d152" class="ms lr it mo b gy mx mu l mv mw"># Fit the model<br/>    plt.figure(figsize=(15, 12))<br/>    for i, (clf_name, clf) in enumerate(classifiers.items()):<br/>        print(i + 1, 'fitting', clf_name)<br/>        # fit the data and tag class 1</span><span id="9553" class="ms lr it mo b gy mx mu l mv mw">clf.fit(X, ground_truth)<br/>        scores_pred = clf.predict_proba(X)[:, 1] * -1</span><span id="549b" class="ms lr it mo b gy mx mu l mv mw">y_pred = clf.predict(X)<br/>        threshold = percentile(scores_pred, 100 * class1_fraction)<br/>        n_errors = (y_pred != ground_truth).sum()<br/>        # plot the levels lines and the points<br/>        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1] * -1<br/>        Z = Z.reshape(xx.shape)<br/>        subplot = plt.subplot(3, 4, i + 1)<br/>        subplot.contourf(xx, yy, Z, levels=np.linspace(Z.min(), threshold, 7),<br/>                         cmap=plt.cm.Blues_r)<br/>        a = subplot.contour(xx, yy, Z, levels=[threshold],<br/>                            linewidths=2, colors='red')<br/>        subplot.contourf(xx, yy, Z, levels=[threshold, Z.max()],<br/>                         colors='orange')<br/>        b = subplot.scatter(X[:-n_class1, 0], X[:-n_class1, 1], c='white',<br/>                            s=20, edgecolor='k')<br/>        c = subplot.scatter(X[-n_class1:, 0], X[-n_class1:, 1], c='black',<br/>                            s=20, edgecolor='k')<br/>        subplot.axis('tight')<br/>        subplot.legend(<br/>            [a.collections[0], b, c],<br/>            ['learned boundary', 'class 0', 'class 1'],<br/>            prop=matplotlib.font_manager.FontProperties(size=10),<br/>            loc='lower right')<br/>        subplot.set_xlabel("%d. %s (errors: %d)" % (i + 1, clf_name, n_errors))<br/>        subplot.set_xlim((-7, 7))<br/>        subplot.set_ylim((-7, 7))<br/>    plt.subplots_adjust(0.04, 0.1, 0.96, 0.94, 0.1, 0.26)<br/>    plt.suptitle("Model Combination")<br/># plt.savefig('compare_selected_classifiers.png', dpi=300)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/2daf2fa61358cd7d3a40066199ed2e0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*7aEyYdIhjK1UTm9qDp4yWA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">模型比较(来源:作者)</p></figure><p id="6bcb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这里，您可以清楚地看到我们使用Combo创建的不同图表和绘图。继续尝试不同的数据集，创建不同的可视化效果，并让我知道您在回复部分的评论。</p><p id="bcb4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">本文是与<a class="mz na ep" href="https://medium.com/u/40808d551f5a?source=post_page-----ed6398ac3005--------------------------------" rel="noopener" target="_blank"> Piyush Ingale </a>合作完成的。</p><h1 id="df2f" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">在你走之前</h1><p id="90c2" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated"><strong class="kw iu"> <em class="nb">感谢</em> </strong> <em class="nb">的阅读！如果你想与我取得联系，请随时联系我在hmix13@gmail.com或我的</em> <a class="ae nc" href="http://www.linkedin.com/in/himanshusharmads" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> <em class="nb"> LinkedIn简介</em> </strong> </a> <em class="nb">。可以查看我的</em><a class="ae nc" href="https://github.com/hmix13" rel="noopener ugc nofollow" target="_blank"><strong class="kw iu"><em class="nb">Github</em></strong><em class="nb"/></a><em class="nb">简介针对不同的数据科学项目和包教程。还有，随意探索</em> <a class="ae nc" href="https://medium.com/@hmix13" rel="noopener"> <strong class="kw iu"> <em class="nb">我的简介</em> </strong> </a> <em class="nb">，阅读我写过的与数据科学相关的不同文章。</em></p></div></div>    
</body>
</html>