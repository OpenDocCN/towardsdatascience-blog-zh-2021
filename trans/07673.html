<html>
<head>
<title>Regional and Online Learnable Fields</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">区域和在线学习领域</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/regional-and-online-learnable-fields-cbb18b74e01e?source=collection_archive---------37-----------------------#2021-07-13">https://towardsdatascience.com/regional-and-online-learnable-fields-cbb18b74e01e?source=collection_archive---------37-----------------------#2021-07-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3004" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><strong class="ak">一种新的，不太新的聚类算法</strong></h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/9d6bb59d87a1f4dcd1ce519472f5eac3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wNmpuTSlUNaqlAG4pSfqxg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)</p></figure><p id="9a9b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这篇文章将引导你了解地区和在线学习领域。一个看似未被识别的聚类算法，它提供了k-Means和k-Nearest-neighbors的几个优点。</p><h1 id="0a5e" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">区域和在线学习领域</h1><p id="c7a1" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">首先由Rolf Schatten、Nils Goerke和Rolf Eckmiller在2005年提出，区域和在线可学习领域是一种在线和无监督的聚类技术[1]。总的想法是用所谓的ROLF神经元来近似我们的数据点，在后面的步骤中，可以将这些神经元连接起来形成簇。该算法源于k-Means和k-Nearest-Neighbors，旨在对它们进行改进。让我们先来看看，前者有哪些地方可以加强。</p><h1 id="2352" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">k-Means和KNN哪里可以改进？</h1><ol class=""><li id="8352" class="mo mp iq kx b ky mj lb mk le mq li mr lm ms lq mt mu mv mw bi translated">原始k-Means算法的一个常见问题是我们必须预先选择聚类数k。虽然有时我们可以做出有根据的猜测，但大多数时候我们不得不求助于某种形式的试错法。这需要时间，最好将k的选择合并到聚类过程本身中。</li><li id="b714" class="mo mp iq kx b ky mx lb my le mz li na lm nb lq mt mu mv mw bi translated">另一个问题是，k-Means不能聚类某些形状，如两个同心圆或两个互锁的半月形。一般来说，当聚类不是圆形或者当它们的质心彼此靠近时，k-Means失败。</li><li id="12a9" class="mo mp iq kx b ky mx lb my le mz li na lm nb lq mt mu mv mw bi translated">k-Means不是在线自适应的。假设您在两个聚类上训练了k-Means，现在用第三个聚类的数据点来呈现它。这些点将被分配给训练期间发现的两个集群。这是不希望的，并且如果该算法将为所述点创建新的聚类，或者将它们标记为“未知”会好得多。</li><li id="ce7f" class="mo mp iq kx b ky mx lb my le mz li na lm nb lq mt mu mv mw bi translated">此外，kNN还面临着复杂性的问题。为了给一个聚类分配一个数据点，我们必须计算它到所有训练点的距离。你可以想象，如果我们有大量的训练点，这将很快变得计算效率低下。因此，我们必须找到一种方法来减少距离计算的数量。</li></ol><h2 id="a6f1" class="nc ls iq bd lt nd ne dn lx nf ng dp mb le nh ni md li nj nk mf lm nl nm mh nn bi translated">ROLF神经元</h2><p id="8993" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">区域和在线可学习领域的核心是所谓的ROLF神经元。这些充当我们的数据点的原型，并且有他们负责的区域。这个区域被称为感知领域。ROLF神经元由3个参数组成:</p><ol class=""><li id="bcca" class="mo mp iq kx b ky kz lb lc le no li np lm nq lq mt mu mv mw bi translated">中心<em class="nr"> c </em>，定义神经元在空间中的位置。</li><li id="b2f2" class="mo mp iq kx b ky mx lb my le mz li na lm nb lq mt mu mv mw bi translated">宽度<em class="nr"> σ </em>，定义了每个神经元的宽度。</li><li id="4481" class="mo mp iq kx b ky mx lb my le mz li na lm nb lq mt mu mv mw bi translated">感知领域<em class="nr"> r = p </em> ⋅ <em class="nr"> σ </em>，定义其负责的区域。初始设置时，常数<em class="nr"> p </em>对所有神经元都是相等的。它定义了每个神经元的感知范围和宽度之间的比率。</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/31852a1543fddee3ec73008e60536caa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SaBLckJy-komC52-HpUgag.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd nt"> p = 2 </strong>(图片作者)</p></figure><h1 id="280e" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">学习网络</h1><p id="3400" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">这基本上分两步走，首先，我们必须在我们的训练数据中找到ROLF神经元或原型。之后，我们在它们之间构建一个邻域图，最终定义聚类。</p><h1 id="cb25" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">如何找到罗尔夫神经元？</h1><p id="9ce2" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">首先，我们反复检查所有的训练模式，看看它们是否在一个已经存在的神经元的感知范围内。如果在多个神经元的感知范围内，我们选择最接近模式的那个神经元。在我们决定了这个所谓的“获胜神经元”之后，我们调整它的中心<em class="nr"> c </em>和宽度<em class="nr"> σ </em>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/a6dcac14e42001bd6a2016b4fb7c30b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p2THuOoYz0n7a8PwqvykBQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)</p></figure><p id="14e8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果模式不在任何现有神经元的感知范围内，我们根据初始化策略创建一个新的。这个策略必须在一开始就选择。我们稍后将讨论这方面的细节。</p><h1 id="f972" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">获胜神经元如何适配？</h1><p id="c07e" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">设<em class="nr"> x </em>为训练模式，<em class="nr"> c </em>为获胜神经元的中心。为了调整中心<em class="nr"> c </em>和宽度<em class="nr"> σ </em>，我们首先必须计算<em class="nr"> c </em>和<em class="nr"> x </em>之间的距离<em class="nr"> d </em>。之后，我们将<em class="nr"> c </em>向<em class="nr"> x </em>移动，并将<em class="nr"> σ </em>向<em class="nr"> d </em>调整。最后，我们重新计算感知领域。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/e75bc9137dee7dae60ad0c328a89edc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vmgtsN5Yy0ta6StPXh-EGQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)</p></figure><p id="5b0a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从公式中，我们可以看到常量参数<em class="nr"> p </em>的使用。它允许神经元接受<em class="nr"> σ之外的模式。</em>如果x和c之间的距离大于<em class="nr"> σ，</em>前者增加<em class="nr">。在相反的情况下，它会减少。没有<em class="nr"> p，</em>感知范围只能缩小，因为只有在<em class="nr"> σ </em>内的点才会被接受。</em></p><h1 id="6b6e" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">如何初始化一个新的神经元？</h1><p id="3b56" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">当我们初始化一个新的神经元时，我们总是将<em class="nr"> c </em>设置为模式<em class="nr"> x </em>。我们改变的值是神经元的宽度<em class="nr"> σ </em>。这可以通过四种不同的方式来设置。</p><ol class=""><li id="f231" class="mo mp iq kx b ky kz lb lc le no li np lm nq lq mt mu mv mw bi translated"><strong class="kx ir"> Init-σ → </strong>将<em class="nr"> σ </em>初始化为恒定值</li><li id="2b53" class="mo mp iq kx b ky mx lb my le mz li na lm nb lq mt mu mv mw bi translated"><strong class="kx ir">最小值-σ </strong> →将<em class="nr"> σ </em>初始化为所有现有神经元的最小值<em class="nr"> σ </em></li><li id="0b6c" class="mo mp iq kx b ky mx lb my le mz li na lm nb lq mt mu mv mw bi translated"><strong class="kx ir">最大值-σ </strong> →初始化<em class="nr"> σ </em>为所有已经存在的神经元的最大值<em class="nr"> σ </em></li><li id="0ea8" class="mo mp iq kx b ky mx lb my le mz li na lm nb lq mt mu mv mw bi translated"><strong class="kx ir">均值-σ </strong> →初始化<em class="nr"> σ </em>为均值<em class="nr"> σ </em>整体已经存在的神经元</li></ol><p id="d9f7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，观察力敏锐的读者可能会想:如果我选择均值-σ作为策略，我该如何初始化第一个神经元？毕竟，没有σ值来计算平均值。嗯，这是正确的。第一个神经元的σ总是必须由预定义的值来设置。接下来的一切将由你选择的策略决定。</p><h1 id="713f" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">建设社区</h1><p id="0e74" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">在学习算法的第二步中，我们希望将我们之前发现的神经元分组为簇。这是通过构建一个邻域图来实现的，其中具有重叠感知域的神经元用一条边连接起来。从数学上来说，如果两个神经元的中心距离小于其感知范围(半径)之和，则这两个神经元是连通的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/6f258cd366893bf3c6946b4b4657159b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EtWWPO7Kss0oa1P5goi5uw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)</p></figure><p id="4823" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，所有可以通过一系列边连接的神经元都属于同一个簇。它们的感知区域的联合是总区域，其中在预测期间新的数据点被分配给所述聚类。</p><h1 id="83f6" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">ROLF的优势</h1><ol class=""><li id="4d43" class="mo mp iq kx b ky mj lb mk le mq li mr lm ms lq mt mu mv mw bi translated">该算法可以自己选择聚类数<em class="nr"> k </em>。</li><li id="9af9" class="mo mp iq kx b ky mx lb my le mz li na lm nb lq mt mu mv mw bi translated">该算法不受聚类形状的限制。特别是k-均值，连锁半月形和同心圆的问题案例可以用ROLF聚类。下一节将给出例子。</li><li id="47ba" class="mo mp iq kx b ky mx lb my le mz li na lm nb lq mt mu mv mw bi translated">通过用ROLF神经元表示训练数据点，只需对前者进行距离计算。此外，必须专门存储神经元，而模式将仅呈现一次，然后可以被丢弃。这也减少了内存的使用。</li><li id="8129" class="mo mp iq kx b ky mx lb my le mz li na lm nb lq mt mu mv mw bi translated">该算法可以自己检测异常值，然后据此采取相应的行动。</li></ol><h1 id="2941" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">表演</h1><p id="12bf" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">现在，我想向大家展示几个地区和在线可学习领域在实践中表现的例子。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/aa7ad0091b87fd10db6b380cc48e6d7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*79lxpIE01YTw908NRUdQ-g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">20000点，219个神经元(图片由作者提供)</p></figure><p id="bd84" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在给出的例子中，你可以看到ROLF是如何将k-Means的两个失败案例进行聚类的。对于这两个例子，对于<em class="nr"> c </em>和<em class="nr"> σ </em>使用了0.05的学习率。用最小σ策略初始化新的神经元。第一个神经元初始化为σ = 0.4，而<em class="nr"> p </em>设置为2。黑线显示了邻域图形。两个数据集都由20000个点组成，并减少到约1%的神经元。绿色和蓝色区域显示了点将被分配给相应的聚类的位置。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/cf7a2078c137c0d029d46fbc5ac0e6f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IyJJRnlidzO8BUWrY5g0qA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">20000点，239个神经元(图片由作者提供)</p></figure><h1 id="d3de" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">评论</h1><ol class=""><li id="694e" class="mo mp iq kx b ky mj lb mk le mq li mr lm ms lq mt mu mv mw bi translated">ROLF神经元的中心c的维数不一定是2。在最初的论文中，ROLF被用于从720维的输入空间中聚类点[1]。</li><li id="7ab7" class="mo mp iq kx b ky mx lb my le mz li na lm nb lq mt mu mv mw bi translated">用于生成示例的代码可以在<a class="ae nw" href="https://github.com/JoWohlen/Medium_Code/tree/main/ROLF" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</li></ol></div><div class="ab cl nx ny hu nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="ij ik il im in"><h1 id="3a79" class="lr ls iq bd lt lu oe lw lx ly of ma mb jw og jx md jz oh ka mf kc oi kd mh mi bi translated">来源:</h1><p id="4dc1" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">[1] Schatten R .，Goerke N .，Eckmiller R. (2005)区域和在线可学习领域。在:Singh S .，Singh M .，Apte C .，Perner P. (eds)模式识别和图像分析。ICAPR 2005。计算机科学讲义，第3687卷。斯普林格，柏林，海德堡。<a class="ae nw" href="https://doi.org/10.1007/11552499_9" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1007/11552499_9</a></p></div></div>    
</body>
</html>