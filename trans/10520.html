<html>
<head>
<title>Bilinear pooling for fine-grained visual recognition and multi-modal deep learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于细粒度视觉识别和多模态深度学习的双线性池</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bilinear-pooling-for-fine-grained-visual-recognition-and-multi-modal-deep-learning-20051c1f0e7e?source=collection_archive---------14-----------------------#2021-10-07">https://towardsdatascience.com/bilinear-pooling-for-fine-grained-visual-recognition-and-multi-modal-deep-learning-20051c1f0e7e?source=collection_archive---------14-----------------------#2021-10-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/d896197af905302924054a7555c5eddf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2RdfimeWaFU2lsGSgWVViw.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">巴德·赫利松在<a class="ae jd" href="https://unsplash.com/s/photos/interaction?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><blockquote class="kd"><p id="f200" class="ke kf jg bd kg kh ki kj kk kl km kn dk translated">高级神经网络架构通过学习特征交互来工作</p></blockquote><p id="8d88" class="pw-post-body-paragraph ko kp jg kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk kn ij bi translated">双线性池起源于计算机视觉社区，作为一种细粒度视觉识别的方法。或者用不太花哨的语言来说，一种在识别和分类视觉对象时寻找特定细节的方法。在高层次上，该方法的工作方式如下。给定一个输入图像<em class="ll"> I </em>，我们将<em class="ll"> I </em>送入两个不同的深度卷积神经网络A和B，见图1。在应用若干池化和非线性变换之后，我们从A和b输出特征图。这两个网络可以被预训练以解决不同的任务。直觉是，A和B以这种方式从输入图像中学习不同的特征。例如，A被训练来检测基本的物体形状，而B检测纹理特征。然后，来自A和B的输出特征由所谓的<em class="ll">双线性池层</em>组合。这仅仅意味着我们通过取它们的内积，将A的每个特征与B的每个特征结合起来。读者可能会注意到，这类似于支持向量机中的2次多项式核。双线性池层背后的直觉是，这些特征交互允许我们检测图像的更多特定细节。</p><figure class="ln lo lp lq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lm"><img src="../Images/de92b027a0a7e3e6794bcc95ea009da5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*avfZRosleYBVJtWCm0-NKg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图一。双线性池的整体结构。来源[1]</p></figure><h2 id="7636" class="lr ls jg bd lt lu lv dn lw lx ly dp lz kz ma mb mc ld md me mf lh mg mh mi mj bi translated">原始建筑</h2><p id="cfc6" class="pw-post-body-paragraph ko kp jg kq b kr mk kt ku kv ml kx ky kz mm lb lc ld mn lf lg lh mo lj lk kn ij bi translated">我假设读者熟悉卷积神经网络的基础知识。不然我推荐<a class="ae jd" href="https://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">这些入门讲义</a>。</p><p id="cfbd" class="pw-post-body-paragraph ko kp jg kq b kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh mt lj lk kn ij bi translated">图1中网络A的输出是一个维数为n×d的矩阵U，或n×d<em class="ll">，</em>，网络B的输出是一个维数为m×d的矩阵V，在CNN的上下文中，n和m分别是A和B的输出层中滤波器(或内核)的数量。每个滤波器的维数是<em class="ll"> d，</em>它是通过展平二维特征图获得的，即经过几次核卷积和汇集变换的输出图像。双线性池操作被定义为</p><figure class="ln lo lp lq gt is gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/1b464a28e001e2e998f04dda268577da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*CNQYggVON7_5Mr6HFKq-zQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">等式1。双线性池。</p></figure><p id="59fb" class="pw-post-body-paragraph ko kp jg kq b kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh mt lj lk kn ij bi translated">然后，矩阵Z被展平成维数为m*n的向量Z。Z和可学习向量w_k的内积被提供作为softmax激活函数的输入，其中K个类别中的类别K的概率被计算为:</p><figure class="ln lo lp lq gt is gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/aad526235e1238ae453db5a61f6d8e5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*FMJc3KxVC_1CWcHgJgZaYg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">等式2。使用双线性映射进行分类。</p></figure><p id="1b1d" class="pw-post-body-paragraph ko kp jg kq b kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh mt lj lk kn ij bi translated">在上面，w_k是维数为m*n的可学习向量，它模拟向量z属于第k类的概率，1≤k≤K。</p><h2 id="170a" class="lr ls jg bd lt lu lv dn lw lx ly dp lz kz ma mb mc ld md me mf lh mg mh mi mj bi translated">双线性池为什么有效？</h2><p id="f067" class="pw-post-body-paragraph ko kp jg kq b kr mk kt ku kv ml kx ky kz mm lb lc ld mn lf lg lh mo lj lk kn ij bi translated">如前所述，双线性池的核心是明确考虑特征交互的思想，类似于支持向量机中的多项式核。让我们考虑一个具体的例子。作为第一个应用，双线性池用于细粒度的图像分类。考虑图2，我们想解决一个鸟类分类问题。显然，这些都是彼此相似的鸟类，我们需要具体的细节来正确区分不同的物种。对于图1中的两个神经网络A和B，假设A=B，并对A和B使用<a class="ae jd" href="https://neurohive.io/en/popular-networks/vgg16/" rel="noopener ugc nofollow" target="_blank">预训练的VGG16模型</a>，VGG16是一个深度CNN模型，已经在ImageNet 2014挑战赛的大量图像上进行了训练，其中图像属于1，000个类别中的一个。很明显，VGG16可以检测鸟类羽毛、喙、颜色等形状。然而，许多鸟类都有相同的喙形。</p><figure class="ln lo lp lq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mw"><img src="../Images/d98f9d1718775746e05dd60d8ab45a54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D45ivBiYW_HJWwg4GWcqXw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图二。即使对一个人类专家来说，正确分类所有的鸟类也是一个挑战。来源[2]</p></figure><p id="6ef8" class="pw-post-body-paragraph ko kp jg kq b kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh mt lj lk kn ij bi translated">VGG16足以正确区分鸟类和猫，但要正确区分不同的鸟类是有挑战性的，差异已经非常微妙了。为了区分不同的物种，我们需要明确地考虑这些特征的<em class="ll">组合</em>。这样的组合对每个物种来说更有可能是独一无二的。羽毛颜色和鸟喙形状的结合更有可能唯一地识别一种鸟。因此，使用正确识别某些基本形状的预训练模型，我们可以了解这些形状的哪些组合对于手头的分类问题是重要的。</p><h2 id="d3ea" class="lr ls jg bd lt lu lv dn lw lx ly dp lz kz ma mb mc ld md me mf lh mg mh mi mj bi translated">用于多模态学习的双线性池</h2><p id="ddf4" class="pw-post-body-paragraph ko kp jg kq b kr mk kt ku kv ml kx ky kz mm lb lc ld mn lf lg lh mo lj lk kn ij bi translated">双线性池的另一个主要应用是结合不同领域的神经网络模型。例如，在视觉问答中，训练数据由自然语言和图像中的问题组成，参见图3中的示例。</p><figure class="ln lo lp lq gt is gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/9197b715bdcc722ad384fa17fa31e9a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*oN_icKrQYN9eNPTuZ7k5zQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图3。集合视觉和语言特征进行视觉问答。来源[3]</p></figure><h2 id="9ac5" class="lr ls jg bd lt lu lv dn lw lx ly dp lz kz ma mb mc ld md me mf lh mg mh mi mj bi translated">双线性池的变体</h2><p id="c9f9" class="pw-post-body-paragraph ko kp jg kq b kr mk kt ku kv ml kx ky kz mm lb lc ld mn lf lg lh mo lj lk kn ij bi translated">有几种不同的方法可以使用双线性池。</p><ul class=""><li id="5349" class="my mz jg kq b kr mp kv mq kz na ld nb lh nc kn nd ne nf ng bi translated"><strong class="kq jh">单个神经网络vs两个网络。</strong>网络A和B可以是相同的网络，即A=B。如在计算机视觉示例中所讨论的，我们然后从输出神经网络的不同通道学习重要的特征对。对于多模态问题，当我们组合来自不同领域的特征时，网络A和B当然彼此不同。</li><li id="963f" class="my mz jg kq b kr nh kv ni kz nj ld nk lh nl kn nd ne nf ng bi translated"><strong class="kq jh">端到端架构与预训练模型</strong>。两个网络A和B可以是像VGG16那样的具有固定权重的预训练网络。在这个设置中，新的输入通过A和B传递，然后我们只学习双线性层的权重。在端到端架构中，来自双线性层的误差反向传播到A和B，并且更新它们各自的参数。双线性层是可微分的，它可以由众所周知的深度学习框架来处理，如TensorFlow或PyTorch。</li></ul><h2 id="d449" class="lr ls jg bd lt lu lv dn lw lx ly dp lz kz ma mb mc ld md me mf lh mg mh mi mj bi translated">计算的复杂性</h2><p id="25db" class="pw-post-body-paragraph ko kp jg kq b kr mk kt ku kv ml kx ky kz mm lb lc ld mn lf lg lh mo lj lk kn ij bi translated">显然，双线性池的一个主要缺点是它的计算复杂性。矩阵乘法</p><figure class="ln lo lp lq gt is gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/1b464a28e001e2e998f04dda268577da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*CNQYggVON7_5Mr6HFKq-zQ.png"/></div></figure><p id="727f" class="pw-post-body-paragraph ko kp jg kq b kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh mt lj lk kn ij bi translated">时间复杂度为O(m*n*d)。通常，t尺寸d相当小。想象一个CNN，我们从256x256像素的图像开始逐渐粗化维度，更深的层具有16x16维度的核图。另一方面，为了获得强大的模型，核的数量需要更大。高级架构使用几千数量级的m和n。对于具有K个类别的分类问题(见等式2)，这意味着我们需要K*m*n个可学习的参数，其数量级可以是几百万。这可能使双线性池难以训练，并容易过度拟合。</p><h2 id="a06e" class="lr ls jg bd lt lu lv dn lw lx ly dp lz kz ma mb mc ld md me mf lh mg mh mi mj bi translated">可伸缩双线性池的矩阵分解</h2><p id="6360" class="pw-post-body-paragraph ko kp jg kq b kr mk kt ku kv ml kx ky kz mm lb lc ld mn lf lg lh mo lj lk kn ij bi translated">已经设计了几种旨在降低原始算法的计算复杂度的方法。我将介绍一种矩阵分解方法。</p><p id="2972" class="pw-post-body-paragraph ko kp jg kq b kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh mt lj lk kn ij bi translated">设W_k是一个m乘n矩阵，具有可学习的双线性权重。方程2中的向量w_k是平坦矩阵W_k，网络A的输出是m-次-d维的矩阵U，网络B的输出是n-次-d维的矩阵，设第I列U为u_i，V的第I列为v_i，特殊情况d=1时，矩阵U和V只是单列。</p><figure class="ln lo lp lq gt is gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/f2a773c591ab1c555f73bd258ffe402c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*un1QnNl6V1O8nluHD8Sq5A.png"/></div></figure><p id="a019" class="pw-post-body-paragraph ko kp jg kq b kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh mt lj lk kn ij bi translated">z_i是u_i和v_i的平坦的<a class="ae jd" href="https://en.wikipedia.org/wiki/Outer_product" rel="noopener ugc nofollow" target="_blank">外积</a>，我们可以证明以下等式成立:</p><figure class="ln lo lp lq gt is gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/e8b96c5c8c1a92fead76d0d84cbecc41.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/format:webp/1*y-827318s7a-rRiL6_7ORA.png"/></div></figure><p id="b54f" class="pw-post-body-paragraph ko kp jg kq b kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh mt lj lk kn ij bi translated">上面简单地写出了等式两边的量。</p><p id="4bf9" class="pw-post-body-paragraph ko kp jg kq b kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh mt lj lk kn ij bi translated">根据定义，它成立</p><figure class="ln lo lp lq gt is gh gi paragraph-image"><div class="gh gi no"><img src="../Images/1b8f5cfe78959c65c0a2d3fffa7a688a.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*35KEcFMz0F2cz9pOC0IA8g.png"/></div></figure><p id="9fb8" class="pw-post-body-paragraph ko kp jg kq b kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh mt lj lk kn ij bi translated">因此，我们可以将内积重写为</p><figure class="ln lo lp lq gt is gh gi paragraph-image"><div class="gh gi np"><img src="../Images/58b0f59759feddb5c88b0c7db4a57cda.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*zzihQ2GUGg_XLIAC3CnL4w.png"/></div></figure><p id="2dc4" class="pw-post-body-paragraph ko kp jg kq b kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh mt lj lk kn ij bi translated">为了提高计算复杂度，我们可以用低秩分解来代替双线性矩阵W_k:</p><figure class="ln lo lp lq gt is gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/5ef97113fc125ad80be0321102df216b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*lRogI3Lt02PrSm57AnXNrw.png"/></div></figure><p id="d22a" class="pw-post-body-paragraph ko kp jg kq b kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh mt lj lk kn ij bi translated">在上面，r是一个小常数，使得r &lt; min(m，n)。</p><p id="4154" class="pw-post-body-paragraph ko kp jg kq b kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh mt lj lk kn ij bi translated">因此，我们获得内积的以下表达式:</p><figure class="ln lo lp lq gt is gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/a29814766e2685437cc8d7bd92d22e2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*9cy8M3ldH5olnkTHgBOO4A.png"/></div></figure><p id="5a0f" class="pw-post-body-paragraph ko kp jg kq b kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh mt lj lk kn ij bi translated">注意，右边求和的计算复杂度是d*(m*r + n*r)。因为r是一个小常数，比m和n小得多，所以我们实现了更好的运行时间。此外，双线性池图层的可训练参数的数量从K*m*n减少到K*(m+n)*r。为了更好地了解这两个量的比较情况，请考虑一个CNN，其典型值为m=n=1，000个过滤器和K=10个类。使用r = 20，我们从10⁷到4*10⁵减少了可学习参数的数量，即因子分解双线性池中的参数数量仅为原始设置的参数数量的4%。</p><h2 id="ea61" class="lr ls jg bd lt lu lv dn lw lx ly dp lz kz ma mb mc ld md me mf lh mg mh mi mj bi translated">双线性池的缺点和限制</h2><p id="786f" class="pw-post-body-paragraph ko kp jg kq b kr mk kt ku kv ml kx ky kz mm lb lc ld mn lf lg lh mo lj lk kn ij bi translated">最后，我们应该提到双线性池的一些限制:</p><ul class=""><li id="73bb" class="my mz jg kq b kr mp kv mq kz na ld nb lh nc kn nd ne nf ng bi translated">对于两个输出，特征向量d的维数必须相同。对于两个CNN模型来说，这不是一个大问题，但是对于多模态双线性池来说，这可能是一个限制。例如，单词嵌入可以具有与CNN非常不同的最佳维度，调整这两者可能会导致信息的丢失。</li><li id="4a18" class="my mz jg kq b kr nh kv ni kz nj ld nk lh nl kn nd ne nf ng bi translated">我们仅限于考虑成对的相互作用。研究人员提出了像三线性池这样的一般化方法，其中我们考虑了三个特征。但这使得模型更难训练，容易过度拟合。</li></ul><h2 id="e69e" class="lr ls jg bd lt lu lv dn lw lx ly dp lz kz ma mb mc ld md me mf lh mg mh mi mj bi translated">履行</h2><p id="d012" class="pw-post-body-paragraph ko kp jg kq b kr mk kt ku kv ml kx ky kz mm lb lc ld mn lf lg lh mo lj lk kn ij bi translated">在FashionMNIST数据集上用于图像分类的双线性池的简单实现可以在<a class="ae jd" href="https://github.com/konstantinkutzkov/bilinear_pooling" rel="noopener ugc nofollow" target="_blank">这个Jupyter笔记本</a>中找到。请注意，双线性池并不真正适合像FashionMNIST这样的小型数据集。该实现作为一个示例，可以根据项目的需要进行调整和改进。</p></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><h2 id="f1ca" class="lr ls jg bd lt lu lv dn lw lx ly dp lz kz ma mb mc ld md me mf lh mg mh mi mj bi translated">参考</h2><p id="d251" class="pw-post-body-paragraph ko kp jg kq b kr mk kt ku kv ml kx ky kz mm lb lc ld mn lf lg lh mo lj lk kn ij bi translated">[1]宗-林玉，阿鲁尼·罗伊·乔杜里，苏博兰苏·马吉:<br/>用于细粒度视觉识别的双线性卷积神经网络。IEEE Trans。肛门模式。马赫。智能。40(6)，可用<a class="ae jd" href="https://arxiv.org/pdf/1504.07889.pdf" rel="noopener ugc nofollow" target="_blank">此处</a></p><p id="3d73" class="pw-post-body-paragraph ko kp jg kq b kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh mt lj lk kn ij bi translated">[2]舒孔，查尔斯·c·福尔克斯。用于细粒度分类的低秩双线性池。CVPR 2017。可用<a class="ae jd" href="https://arxiv.org/pdf/1611.05109.pdf" rel="noopener ugc nofollow" target="_blank">此处</a>，项目页面<a class="ae jd" href="https://www.cs.cmu.edu/~shuk/lr_bilinear.html" rel="noopener ugc nofollow" target="_blank">此处</a></p><p id="cccc" class="pw-post-body-paragraph ko kp jg kq b kr mp kt ku kv mq kx ky kz mr lb lc ld ms lf lg lh mt lj lk kn ij bi translated">[3]周瑜，，，陶大成。用于视觉问答的多模态分解双线性池联合注意学习。ICCV 2017，此处<a class="ae jd" href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Yu_Multi-Modal_Factorized_Bilinear_ICCV_2017_paper.pdf" rel="noopener ugc nofollow" target="_blank">可用</a></p></div></div>    
</body>
</html>