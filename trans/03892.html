<html>
<head>
<title>How to Train a Joint Entities and Relation Extraction Classifier using BERT Transformer with spaCy 3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用带spaCy 3的BERT变换器训练联合实体和关系提取分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-train-a-joint-entities-and-relation-extraction-classifier-using-bert-transformer-with-spacy-49eb08d91b5c?source=collection_archive---------2-----------------------#2021-04-01">https://towardsdatascience.com/how-to-train-a-joint-entities-and-relation-extraction-classifier-using-bert-transformer-with-spacy-49eb08d91b5c?source=collection_archive---------2-----------------------#2021-04-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5390" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用Transformer和spaCy3训练关系提取分类器的分步指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/fd58a76ab37a329e8db0c0e6b43e3e73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3PR7jnYFcSslvL21YRjnHQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@jjying?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> JJ英</a>在<a class="ae ky" href="https://unsplash.com/s/photos/science?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><h1 id="3ba6" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><strong class="ak">简介</strong></h1><p id="b074" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">NLP技术最有用的应用之一是从非结构化文本中提取信息，如合同、财务文档、医疗记录等。—使自动数据查询能够获得新的见解。传统上，命名实体识别被广泛用于识别文本中的实体，并存储数据以进行高级查询和过滤。然而，如果我们想从语义上理解非结构化的文本，<strong class="lt iu">仅仅NER是不够的，因为我们不知道实体是如何相互关联的</strong>。执行联合NER和关系提取将通过知识图开辟一种全新的信息检索方式，在知识图中，您可以浏览不同的节点以发现隐藏的关系。因此，联合执行这些任务将是有益的。</p><p id="3981" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在我的<a class="ae ky" rel="noopener" target="_blank" href="/how-to-fine-tune-bert-transformer-with-spacy-3-6a90bfe57647">上一篇文章</a>中，我们使用spaCy3对NER的BERT模型进行了微调，现在我们将使用spaCy的新Thinc库向管道添加关系提取。我们按照<a class="ae ky" href="https://spacy.io/usage/layers-architectures#component-rel" rel="noopener ugc nofollow" target="_blank"> spaCy的文档</a>中概述的步骤训练关系提取模型。我们将比较使用transformers和tok2vec算法的关系分类器的性能。最后，我们将在网上找到的职位描述上测试该模型。</p><h1 id="ef90" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><strong class="ak">关系分类:</strong></h1><p id="42d1" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在其核心，关系提取模型是一个分类器，它为给定的实体对<strong class="lt iu"> {e1，e2} </strong>预测关系<strong class="lt iu"> r </strong>。在变压器的情况下，该分类器被添加到输出隐藏状态的顶部。有关关系提取的更多信息，请阅读这篇出色的文章<a class="ae ky" rel="noopener" target="_blank" href="/bert-s-for-relation-extraction-in-nlp-2c7c3ab487c4">概述了关系分类的微调变压器模型的理论。</a></p><p id="6115" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们要微调的预训练模型是roberta-base模型，但是您可以使用huggingface库中可用的任何预训练模型，只需在配置文件中输入名称即可(见下文)。</p><p id="c447" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在本教程中，我们将提取两个实体{经验，技能}之间的关系作为中的<strong class="lt iu">经验，以及{文凭，文凭_专业}之间的关系作为</strong>中的<strong class="lt iu">学位。目标是提取特定技能和与所需文凭相关的文凭专业所需的经验年限。当然，您可以为自己的用例训练自己的关系分类器，例如在健康记录中查找症状的原因/结果，或者在财务文档中查找公司收购。可能性是无限的…</strong></p><p id="ae9d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在本教程中，我们将只涵盖实体关系提取部分。对于使用spaCy 3微调伯特NER，请参考我的<a class="ae ky" rel="noopener" target="_blank" href="/how-to-fine-tune-bert-transformer-with-spacy-3-6a90bfe57647">以前的文章</a>。</p><h1 id="9f1f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><strong class="ak">数据标注:</strong></h1><p id="5998" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">正如在我的<a class="ae ky" rel="noopener" target="_blank" href="/how-to-fine-tune-bert-transformer-with-spacy-3-6a90bfe57647">上一篇文章</a>中，我们使用<a class="ae ky" href="https://ubiai.tools" rel="noopener ugc nofollow" target="_blank"> UBIAI </a>文本注释工具来执行联合实体和关系注释，因为它的通用接口允许我们在实体和关系注释之间轻松切换(见下文):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/09a8fdabdf011d74b26107c7d7a1f329.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*USiz_vUfk0nLRN4GxVQ3AA.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">UBIAI的联合实体和关系注释接口</p></figure><p id="82c5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于本教程，我只注释了大约100个包含实体和关系的文档。对于生产，我们当然需要更多的带注释的数据。</p><h1 id="f721" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><strong class="ak">数据准备:</strong></h1><p id="1235" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在训练模型之前，我们需要将带注释的数据转换成二进制空间文件。我们首先将UBIAI生成的注释拆分到training/dev/test中，并分别保存它们。我们修改spaCy的教程repo中提供的<a class="ae ky" href="https://github.com/explosion/projects/blob/v3/tutorials/rel_component/scripts/parse_data.py\" rel="noopener ugc nofollow" target="_blank">代码</a>，为我们自己的注释创建二进制文件(<a class="ae ky" href="https://github.com/walidamamou/relation_extraction_transformer" rel="noopener ugc nofollow" target="_blank">转换代码</a>)。</p><p id="6356" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们对训练、开发和测试数据集重复这一步骤，以生成三个二进制空间文件(github 中提供的<a class="ae ky" href="https://github.com/walidamamou/relation_extraction_transformer" rel="noopener ugc nofollow" target="_blank">文件)。</a></p><h1 id="99b1" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><strong class="ak">关系抽取模型训练:</strong></h1><p id="750a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了训练，我们将从我们的黄金语料库中提供实体，并在这些实体上训练分类器。</p><ul class=""><li id="26e8" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">打开一个新的Google Colab项目，确保在笔记本设置中选择GPU作为硬件加速器。确保通过运行以下命令启用GPU:！英伟达-smi</li><li id="3553" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">每晚安装空间:</li></ul><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="9717" class="nm la it ni b gy nn no l np nq">!pip install -U spacy-nightly --pre</span></pre><ul class=""><li id="a69b" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">安装轮包并克隆空间的关系提取报告:</li></ul><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="4a90" class="nm la it ni b gy nn no l np nq">!pip install -U pip setuptools wheel<br/>!python -m spacy project clone tutorials/rel_component</span></pre><ul class=""><li id="da75" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">安装变压器管道和空间变压器库:</li></ul><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="c97a" class="nm la it ni b gy nn no l np nq">!python -m spacy download en_core_web_trf<br/>!pip install -U spacy transformers</span></pre><ul class=""><li id="a7b0" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">将目录更改为rel_component文件夹:cd rel_component</li><li id="7314" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">在rel_component中创建一个名为“data”的文件夹，并将培训、开发和测试二进制文件上传到其中:</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/689dcb0c27f0f13a96fc5664f5e1760b.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*Zsr3eUEDgiDODUMPnPbswA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">培训文件夹</p></figure><ul class=""><li id="3b1b" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">打开project.yml文件并更新培训、开发和测试路径:</li></ul><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="1a14" class="nm la it ni b gy nn no l np nq">train_file: "data/relations_training.spacy"</span><span id="1c5f" class="nm la it ni b gy ns no l np nq">dev_file: "data/relations_dev.spacy"</span><span id="3eac" class="nm la it ni b gy ns no l np nq">test_file: "data/relations_test.spacy"</span></pre><ul class=""><li id="0357" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">您可以通过转到configs/rel_trf.cfg并输入模型的名称来更改预训练的转换器模型(例如，如果您想要使用不同的语言):</li></ul><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="47c5" class="nm la it ni b gy nn no l np nq">[components.transformer.model]</span><span id="808b" class="nm la it ni b gy ns no l np nq">@architectures = "spacy-transformers.TransformerModel.v1"</span><span id="ce4c" class="nm la it ni b gy ns no l np nq">name = "roberta-base" # Transformer model from huggingface</span><span id="d87e" class="nm la it ni b gy ns no l np nq">tokenizer_config = {"use_fast": true}</span></pre><ul class=""><li id="d064" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">在开始训练之前，我们将把configs/rel_trf.cfg中的max_length从默认的100令牌减少到20，以提高模型的效率。max_length对应于两个实体之间的<strong class="lt iu">最大距离</strong>，超过该距离的实体将不被考虑进行关系分类。结果，来自同一文档的两个实体将被分类，只要它们在彼此的最大距离(在标记数量上)内。</li></ul><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="27c5" class="nm la it ni b gy nn no l np nq">[components.relation_extractor.model.create_instance_tensor.get_instances]</span><span id="7451" class="nm la it ni b gy ns no l np nq">@misc = "rel_instance_generator.v1"</span><span id="cb3f" class="nm la it ni b gy ns no l np nq">max_length = 20</span></pre><ul class=""><li id="f821" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">我们最终准备好训练和评估关系提取模型；只需运行以下命令:</li></ul><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="469b" class="nm la it ni b gy nn no l np nq">!spacy project run train_gpu # command to train train transformers<br/>!spacy project run evaluate # command to evaluate on test dataset</span></pre><p id="9350" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">您应该开始看到P、R和F分数开始更新:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/77dce391fda1912877e64fed8a2544e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KcgeUxF3aRzfETj6Yber8Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型培训正在进行中</p></figure><p id="af90" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">模型完成训练后，对测试数据集的评估将立即开始，并显示预测与黄金标签。该模型将与我们模型的分数一起保存在名为“training”的文件夹中。</p><p id="dd2c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">要训练非变压器模型tok2vec，请改为运行以下命令:</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="6255" class="nm la it ni b gy nn no l np nq">!spacy project run train_cpu # command to train train tok2vec<br/>!spacy project run evaluate</span></pre><p id="ff05" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们可以比较这两种模型的性能:</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="dde0" class="nm la it ni b gy nn no l np nq"># Transformer model<br/>"performance":{</span><span id="ac16" class="nm la it ni b gy ns no l np nq">"rel_micro_p":0.8476190476,</span><span id="a7dc" class="nm la it ni b gy ns no l np nq">"rel_micro_r":0.9468085106,</span><span id="6053" class="nm la it ni b gy ns no l np nq">"rel_micro_f":0.8944723618,</span><span id="cd47" class="nm la it ni b gy ns no l np nq">}<br/># Tok2vec model<br/>  "performance":{</span><span id="832d" class="nm la it ni b gy ns no l np nq">"rel_micro_p":0.8604651163,</span><span id="a164" class="nm la it ni b gy ns no l np nq">"rel_micro_r":0.7872340426,</span><span id="d0b9" class="nm la it ni b gy ns no l np nq">"rel_micro_f":0.8222222222,</span><span id="7555" class="nm la it ni b gy ns no l np nq">}</span></pre><p id="141a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">基于transformer的模型的精度和召回分数明显优于tok2vec，并证明了transformer在处理少量注释数据时的有效性。</p><h1 id="adcc" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><strong class="ak">联合实体和关系提取管道:</strong></h1><p id="3685" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">假设我们已经在我的<a class="ae ky" rel="noopener" target="_blank" href="/how-to-fine-tune-bert-transformer-with-spacy-3-6a90bfe57647">上一篇文章</a>中训练了一个transformer NER模型，我们将从网上找到的工作描述中提取实体(这不是训练的一部分，也不是开发集的一部分),并将它们提供给关系提取模型以对关系进行分类。</p><ul class=""><li id="0947" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">安装空间变压器和变压器管道</li><li id="ccac" class="mt mu it lt b lu nc lx nd ma ne me nf mi ng mm my mz na nb bi translated">加载NER模型并提取实体:</li></ul><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="4449" class="nm la it ni b gy nn no l np nq">import spacy</span><span id="31ff" class="nm la it ni b gy ns no l np nq">nlp = spacy.load("NER Model Repo/model-best")</span><span id="9f76" class="nm la it ni b gy ns no l np nq">Text=['''2+ years of non-internship professional software development experience<br/>Programming experience with at least one modern language such as Java, C++, or C# including object-oriented design.</span><span id="0042" class="nm la it ni b gy ns no l np nq">1+ years of experience contributing to the architecture and design (architecture, design patterns, reliability and scaling) of new and current systems.</span><span id="49b4" class="nm la it ni b gy ns no l np nq">Bachelor / MS Degree in Computer Science. Preferably a PhD in data science.</span><span id="e016" class="nm la it ni b gy ns no l np nq">8+ years of professional experience in software development. 2+ years of experience in project management.</span><span id="b352" class="nm la it ni b gy ns no l np nq">Experience in mentoring junior software engineers to improve their skills, and make them more effective, product software engineers.</span><span id="022a" class="nm la it ni b gy ns no l np nq">Experience in data structures, algorithm design, complexity analysis, object-oriented design.</span><span id="a059" class="nm la it ni b gy ns no l np nq">3+ years experience in at least one modern programming language such as Java, Scala, Python, C++, C#</span><span id="0540" class="nm la it ni b gy ns no l np nq">Experience in professional software engineering practices &amp; best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations</span><span id="c121" class="nm la it ni b gy ns no l np nq">Experience in communicating with users, other technical teams, and management to collect requirements, describe software product features, and technical designs.</span><span id="1df1" class="nm la it ni b gy ns no l np nq">Experience with building complex software systems that have been successfully delivered to customers</span><span id="703b" class="nm la it ni b gy ns no l np nq">Proven ability to take a project from scoping requirements through actual launch of the project, with experience in the subsequent operation of the system in production''']</span><span id="6ec8" class="nm la it ni b gy ns no l np nq">for doc in nlp.pipe(text, disable=["tagger"]):</span><span id="a706" class="nm la it ni b gy ns no l np nq">   print(f"spans: {[(e.start, e.text, e.label_) for e in doc.ents]}")</span></pre><ul class=""><li id="aa83" class="mt mu it lt b lu mn lx mo ma mv me mw mi mx mm my mz na nb bi translated">我们打印提取的实体:</li></ul><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="98af" class="nm la it ni b gy nn no l np nq">spans: [(0, '2+ years', 'EXPERIENCE'), (7, 'professional software development', 'SKILLS'), (12, 'Programming', 'SKILLS'), (22, 'Java', 'SKILLS'), (24, 'C++', 'SKILLS'), (27, 'C#', 'SKILLS'), (30, 'object-oriented design', 'SKILLS'), (36, '1+ years', 'EXPERIENCE'), (41, 'contributing to the', 'SKILLS'), (46, 'design', 'SKILLS'), (48, 'architecture', 'SKILLS'), (50, 'design patterns', 'SKILLS'), (55, 'scaling', 'SKILLS'), (60, 'current systems', 'SKILLS'), (64, 'Bachelor', 'DIPLOMA'), (68, 'Computer Science', 'DIPLOMA_MAJOR'), (75, '8+ years', 'EXPERIENCE'), (82, 'software development', 'SKILLS'), (88, 'mentoring junior software engineers', 'SKILLS'), (103, 'product software engineers', 'SKILLS'), (110, 'data structures', 'SKILLS'), (113, 'algorithm design', 'SKILLS'), (116, 'complexity analysis', 'SKILLS'), (119, 'object-oriented design', 'SKILLS'), (135, 'Java', 'SKILLS'), (137, 'Scala', 'SKILLS'), (139, 'Python', 'SKILLS'), (141, 'C++', 'SKILLS'), (143, 'C#', 'SKILLS'), (148, 'professional software engineering', 'SKILLS'), (151, 'practices', 'SKILLS'), (153, 'best practices', 'SKILLS'), (158, 'software development', 'SKILLS'), (164, 'coding', 'SKILLS'), (167, 'code reviews', 'SKILLS'), (170, 'source control management', 'SKILLS'), (174, 'build processes', 'SKILLS'), (177, 'testing', 'SKILLS'), (180, 'operations', 'SKILLS'), (184, 'communicating', 'SKILLS'), (193, 'management', 'SKILLS'), (199, 'software product', 'SKILLS'), (204, 'technical designs', 'SKILLS'), (210, 'building complex software systems', 'SKILLS'), (229, 'scoping requirements', 'SKILLS')]</span></pre><p id="3971" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们已经成功地从文本中提取了所有的技能、工作年限、文凭和文凭专业！接下来，我们加载关系提取模型，并对实体之间的关系进行分类。</p><p id="917b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">注意:确保将rel_pipe和rel_model从脚本文件夹复制到主文件夹中:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/8dac51edde140686cf1710dc7f9a8d3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:420/format:webp/1*Y7mdiEQyh7SUUThM9vfJAg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">脚本文件夹</p></figure><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="f08d" class="nm la it ni b gy nn no l np nq">import random</span><span id="42b7" class="nm la it ni b gy ns no l np nq">import typer</span><span id="0a40" class="nm la it ni b gy ns no l np nq">from pathlib import Path</span><span id="90bc" class="nm la it ni b gy ns no l np nq">import spacy</span><span id="c413" class="nm la it ni b gy ns no l np nq">from spacy.tokens import DocBin, Doc</span><span id="de04" class="nm la it ni b gy ns no l np nq">from spacy.training.example import Example</span><span id="c14c" class="nm la it ni b gy ns no l np nq">from rel_pipe import make_relation_extractor, score_relations</span><span id="cbb8" class="nm la it ni b gy ns no l np nq">from rel_model import create_relation_model, create_classification_layer, create_instances, create_tensors</span><span id="cafb" class="nm la it ni b gy ns no l np nq"># We load the relation extraction (REL) model</span><span id="b964" class="nm la it ni b gy ns no l np nq">nlp2 = spacy.load("training/model-best")</span><span id="03fd" class="nm la it ni b gy ns no l np nq"># We take the entities generated from the NER pipeline and input them to the REL pipeline</span><span id="0728" class="nm la it ni b gy ns no l np nq">for name, proc in nlp2.pipeline:<br/>          doc = proc(doc)</span><span id="3cb4" class="nm la it ni b gy ns no l np nq"># Here, we split the paragraph into sentences and apply the relation extraction for each pair of entities found in each sentence.</span><span id="ae72" class="nm la it ni b gy ns no l np nq">for value, rel_dict in doc._.rel.items():<br/>        for sent in doc.sents:<br/>          for e in sent.ents:<br/>            for b in sent.ents:<br/>              if e.start == value[0] and b.start == value[1]:<br/>                if rel_dict['EXPERIENCE_IN'] &gt;=0.9 :<br/>                  print(f" entities: {e.text, b.text} --&gt; predicted relation: {rel_dict}")</span></pre><p id="944d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在这里，我们显示了所有具有关系<strong class="lt iu"> Experience_in </strong>且置信度得分高于90%的实体:</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="47a8" class="nm la it ni b gy nn no l np nq">"entities":("2+ years", "professional software development"") --&gt; <strong class="ni iu">predicted relation</strong>":<br/>{"DEGREE_IN":1.2778723e-07,"EXPERIENCE_IN":0.9694631}</span><span id="fbaa" class="nm la it ni b gy ns no l np nq">"entities":"(""1+ years", "contributing to the"") --&gt;<br/><strong class="ni iu">predicted relation</strong>":<br/>{"DEGREE_IN":1.4581254e-07,"EXPERIENCE_IN":0.9205434}</span><span id="36b7" class="nm la it ni b gy ns no l np nq">"entities":"(""1+ years","design"") --&gt; <br/><strong class="ni iu">predicted relation</strong>":<br/>{"DEGREE_IN":1.8895419e-07,"EXPERIENCE_IN":0.94121873}</span><span id="6797" class="nm la it ni b gy ns no l np nq">"entities":"(""1+ years","architecture"") --&gt; <br/><strong class="ni iu">predicted relation</strong>":<br/>{"DEGREE_IN":1.9635708e-07,"EXPERIENCE_IN":0.9399484}</span><span id="246a" class="nm la it ni b gy ns no l np nq">"entities":"(""1+ years","design patterns"") --&gt; <br/><strong class="ni iu">predicted relation</strong>":<br/>{"DEGREE_IN":1.9823732e-07,"EXPERIENCE_IN":0.9423302}</span><span id="323b" class="nm la it ni b gy ns no l np nq">"entities":"(""1+ years", "scaling"") --&gt; <br/><strong class="ni iu">predicted relation</strong>":<br/>{"DEGREE_IN":1.892173e-07,"EXPERIENCE_IN":0.96628445}</span><span id="e4bb" class="nm la it ni b gy ns no l np nq">entities: ('2+ years', 'project management') --&gt; <br/><strong class="ni iu">predicted relation</strong>:<br/>{'DEGREE_IN': 5.175297e-07, 'EXPERIENCE_IN': 0.9911635}</span><span id="d7f2" class="nm la it ni b gy ns no l np nq">"entities":"(""8+ years","software development"") --&gt;<br/><strong class="ni iu">predicted relation</strong>":<br/>{"DEGREE_IN":4.914319e-08,"EXPERIENCE_IN":0.994812}</span><span id="7cb1" class="nm la it ni b gy ns no l np nq">"entities":"(""3+ years","Java"") --&gt;<br/><strong class="ni iu">predicted relation</strong>":<br/>{"DEGREE_IN":9.288566e-08,"EXPERIENCE_IN":0.99975795}</span><span id="69e4" class="nm la it ni b gy ns no l np nq">"entities":"(""3+ years","Scala"") --&gt; <br/><strong class="ni iu">predicted relation</strong>":<br/>{"DEGREE_IN":2.8477e-07,"EXPERIENCE_IN":0.99982494}</span><span id="2e10" class="nm la it ni b gy ns no l np nq">"entities":"(""3+ years","Python"") --&gt;<br/><strong class="ni iu">predicted relation</strong>":<br/>{"DEGREE_IN":3.3149718e-07,"EXPERIENCE_IN":0.9998517}</span><span id="9781" class="nm la it ni b gy ns no l np nq">"entities":"(""3+ years","C++"") --&gt;<br/><strong class="ni iu">predicted relation</strong>":<br/>{"DEGREE_IN":2.2569053e-07,"EXPERIENCE_IN":0.99986637}</span></pre><p id="58f5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">值得注意的是，我们能够正确地提取几乎所有年的经验以及他们各自的技能，而没有假阳性或假阴性！</p><p id="0e48" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">让我们看看具有关系<strong class="lt iu"> Degree_in: </strong>的实体</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="a287" class="nm la it ni b gy nn no l np nq">entities: ('Bachelor / MS', 'Computer Science') --&gt;<br/>predicted relation: <br/>{'DEGREE_IN': 0.9943974, 'EXPERIENCE_IN':1.8361954e-09} </span><span id="0334" class="nm la it ni b gy ns no l np nq">entities: ('PhD', 'data science') --&gt; predicted relation: {'DEGREE_IN': 0.98883855, 'EXPERIENCE_IN': 5.2092592e-09}</span></pre><p id="cc7e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">再次，我们成功提取了文凭和文凭专业的所有关系！</p><p id="9967" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这再次证明了，无论是对于NER还是关系提取，使用少量的注释数据就可以很容易地将transformer模型调整到您自己的领域特定情况。</p><p id="db05" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">只有一百个带注释的文档，我们能够训练一个性能良好的关系分类器。此外，我们可以使用这个初始模型来自动注释数百个未标记的数据，并进行最小的校正。这可以显著加快标注过程并提高模型性能。</p><h1 id="dbe1" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><strong class="ak">结论:</strong></h1><p id="99f5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">变形金刚真正改变了自然语言处理的领域，我对它们在信息提取方面的应用感到特别兴奋。我想对explosion AI(spaCy developers)和huggingface提供开源解决方案以促进变压器的采用表示感谢。</p><p id="1003" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果您的项目需要数据注释，请不要犹豫尝试<a class="ae ky" href="https://ubiai.tools" rel="noopener ugc nofollow" target="_blank"> UBIAI </a>注释工具。我们提供了许多可编程的标注解决方案(如ML自动标注、正则表达式、字典等)，以最大限度地减少手工标注。</p><p id="3483" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最后，查看<a class="ae ky" href="https://walidamamou.medium.com/building-a-knowledge-graph-for-job-search-using-bert-transformer-8677c8b3a2e7" rel="noopener">这篇文章</a>，了解如何利用NER和关系提取模型来构建知识图表并提取新的见解。</p><p id="c26d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果您有任何意见，请在下方留言或发送电子邮件至admin@ubiai.tools！</p><p id="362e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在Twitter上关注我们</p></div></div>    
</body>
</html>