<html>
<head>
<title>How to Build a Poisson Hidden Markov Model Using Python and Statsmodels</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Python和Statsmodels构建泊松隐马尔可夫模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-a-poisson-hidden-markov-model-using-python-and-statsmodels-f7aa3f46f847?source=collection_archive---------6-----------------------#2021-12-04">https://towardsdatascience.com/how-to-build-a-poisson-hidden-markov-model-using-python-and-statsmodels-f7aa3f46f847?source=collection_archive---------6-----------------------#2021-12-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/8196b7b48ed2be78a20221e3e96dcdf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nuAUiry1sew8MDkq0ortrA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">美国制造业罢工与时间的关系(数据来源:<a class="ae jd" href="https://github.com/vincentarelbundock/Rdatasets/blob/master/datasets.csv#L609" rel="noopener ugc nofollow" target="_blank"> R数据集</a>)(图片由作者提供)</p></figure><div class=""/><div class=""><h2 id="b7ad" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">使用泊松HMM的逐步教程</h2></div><p id="16d5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一个<strong class="kx jh">泊松隐马尔可夫模型</strong>是两个回归模型的混合:一个<strong class="kx jh">泊松回归模型</strong>是可见的，一个<strong class="kx jh">马尔可夫模型</strong>是“隐藏的”。在泊松HMM中，泊松模型预测的平均值不仅取决于泊松模型的回归变量，还取决于隐马尔可夫过程所处的当前状态或区域。</p><p id="07f5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在之前的一篇文章中，我们研究了泊松隐马尔可夫模型的架构，并考察了它的理论基础。如果你不熟悉马尔可夫模型或泊松模型，我鼓励你在这里回顾一下:</p><div class="ip iq gp gr ir lr"><a rel="noopener follow" target="_blank" href="/the-poisson-hidden-markov-model-for-time-series-regression-236c269914dd"><div class="ls ab fo"><div class="lt ab lu cl cj lv"><h2 class="bd jh gy z fp lw fr fs lx fu fw jf bi translated">时间序列回归的泊松隐马尔可夫模型</h2><div class="ly l"><h3 class="bd b gy z fp lw fr fs lx fu fw dk translated">如何混合使用两个强大的随机过程来模拟时间序列数据</h3></div><div class="lz l"><p class="bd b dl z fp lw fr fs lx fu fw dk translated">towardsdatascience.com</p></div></div><div class="ma l"><div class="mb l mc md me ma mf ix lr"/></div></div></a></div><p id="7905" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本文中，我们将通过Python和statsmodels 中的一步一步的教程来构建和训练一个泊松HMM，它基于美国制造业中真实世界的劳工罢工数据集，在统计建模的文献中被广泛使用。</p><h1 id="e542" class="mg mh jg bd mi mj mk ml mm mn mo mp mq km mr kn ms kp mt kq mu ks mv kt mw mx bi translated">制造业罢工数据集</h1><p id="649d" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">为了说明模型拟合过程，我们将使用以下开源数据集:</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nd"><img src="../Images/262bf0e7c0e71a26e95f165a7b906a94.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/0*5Jojg3I-huJjMIvY.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">制造业罢工(数据来源:<a class="ae jd" href="https://www.bls.gov/" rel="noopener ugc nofollow" target="_blank">美国BLS </a>通过<a class="ae jd" href="https://github.com/vincentarelbundock/Rdatasets/blob/master/datasets.csv#L609" rel="noopener ugc nofollow" target="_blank"> R数据集</a></p></figure><p id="bbc8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该数据集是一个月度时间序列，显示了从1968年到1976年每月开始的美国制造业活动与美国制造业合同罢工数量之间的关系。</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ni"><img src="../Images/aa0c04220415fd5292710859ac4f0cdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vFiamWiHlcf0Lx2J.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">STRIKES数据集(来源:<a class="ae jd" href="https://github.com/vincentarelbundock/Rdatasets/blob/master/datasets.csv#L609" rel="noopener ugc nofollow" target="_blank"> R数据集</a>)(图片由<a class="ae jd" href="https://sachin-date.medium.com/" rel="noopener">作者</a>)</p></figure><p id="1a29" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这个数据集在R中可用，可以使用Python <a class="ae jd" href="https://www.statsmodels.org/devel/datasets/index.html" rel="noopener ugc nofollow" target="_blank"> statsmodels数据集包</a>获取。</p><p id="73ee" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本文教程用的是<strong class="kx jh"> Python </strong>，不是r</p><h1 id="2e1e" class="mg mh jg bd mi mj mk ml mm mn mo mp mq km mr kn ms kp mt kq mu ks mv kt mw mx bi translated">回归目标</h1><p id="d82b" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">我们的目标是调查制造业产出(<em class="nj">产出</em>变量)对制造业罢工发生率(<em class="nj">罢工</em>变量)的影响。换句话说，制造业产出的差异是否“解释”了每月罢工次数的差异？</p><p id="72aa" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们导入所有需要的包，将strikes数据集加载到Pandas DaraFrame中，并检查<em class="nj"> strikes </em>相对于时间的曲线:</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="c853" class="np mh jg nl b gy nq nr l ns nt"><strong class="nl jh">import </strong>math<br/><strong class="nl jh">import </strong>numpy <strong class="nl jh">as </strong>np<br/><strong class="nl jh">import </strong>statsmodels.api <strong class="nl jh">as </strong>sm<br/><strong class="nl jh">from </strong>statsmodels.base.model <strong class="nl jh">import </strong>GenericLikelihoodModel<br/><strong class="nl jh">from </strong>scipy.stats <strong class="nl jh">import </strong>poisson<br/><strong class="nl jh">from </strong>patsy <strong class="nl jh">import </strong>dmatrices<br/><strong class="nl jh">import </strong>statsmodels.graphics.tsaplots <strong class="nl jh">as </strong>tsa<br/><strong class="nl jh">from </strong>matplotlib <strong class="nl jh">import </strong>pyplot <strong class="nl jh">as </strong>plt<br/><strong class="nl jh">from </strong>statsmodels.tools.numdiff <strong class="nl jh">import </strong>approx_hess1, approx_hess2, approx_hess3<br/></span><span id="0439" class="np mh jg nl b gy nu nr l ns nt"><strong class="nl jh"><em class="nj">#Download the data set and load it into a Pandas Dataframe<br/></em></strong>strikes_dataset = sm.datasets.<strong class="nl jh">get_rdataset</strong>(dataname=<strong class="nl jh">'StrikeNb'</strong>, package=<strong class="nl jh">'Ecdat'</strong>)</span><span id="7254" class="np mh jg nl b gy nu nr l ns nt"><strong class="nl jh"><em class="nj">#Plot the number of strikes starting each month</em></strong><em class="nj"><br/></em>plt.<strong class="nl jh">xlabel</strong>('Month index')<br/>plt.<strong class="nl jh">ylabel</strong>('Number of strikes beginning each month')<br/>strikes_data['strikes'].<strong class="nl jh">plot</strong>()<br/>plt.<strong class="nl jh">show</strong>()</span></pre><p id="7fd2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们看到下面的情节:</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/8196b7b48ed2be78a20221e3e96dcdf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nuAUiry1sew8MDkq0ortrA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">打击次数与时间的关系图(图片由作者提供)</p></figure><p id="3274" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">上下摆动的撞击模式表明时间序列可能是自相关的。让我们通过查看<em class="nj">撞击</em>列的<a class="ae jd" rel="noopener" target="_blank" href="/the-intuition-behind-correlation-62ca11a3c4a"> <strong class="kx jh">自相关</strong> </a>图来验证这一点:</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="201e" class="np mh jg nl b gy nq nr l ns nt">tsa.<strong class="nl jh">plot_acf</strong>(strikes_data[<strong class="nl jh">'strikes'</strong>], <strong class="nl jh">alpha</strong>=0.05)<br/>plt.<strong class="nl jh">show</strong>()</span></pre><p id="a6ec" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们看到下面的情节:</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nv"><img src="../Images/9b780b3c88e0e5bc322f8bd01fbd1f66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vNDdmy-SE3RTpscMCtFL6Q.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">走向的自相关图(图片由作者提供)</p></figure><p id="0fa2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">滞后0处的完全相关将被忽略，因为值总是与其自身完全相关。在滞后-1时有很强的相关性。滞后2和3的相关性可能是滞后1相关性的多米诺骨牌效应。这可以通过绘制<em class="nj">击</em>的<a class="ae jd" rel="noopener" target="_blank" href="/understanding-partial-auto-correlation-fa39271146ac"> <strong class="kx jh">部分自相关</strong> </a>图来确认。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="f573" class="np mh jg nl b gy nq nr l ns nt">tsa.<strong class="nl jh">plot_pacf</strong>(strikes_data['strikes'], <strong class="nl jh">alpha</strong>=0.05)<br/>plt.<strong class="nl jh">show</strong>()</span></pre><figure class="ne nf ng nh gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nw"><img src="../Images/c6c39c3723fcc4e1a2370d57a9cf8151.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*taeRJhVe2WWZQW3y8BL9cQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">走向的部分自相关图(图片由作者提供)</p></figure><p id="44f1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">部分自相关图揭示了以下内容:</p><ul class=""><li id="1389" class="nx ny jg kx b ky kz lb lc le nz li oa lm ob lq oc od oe of bi translated">在滞后-0时，部分自相关为1.0。这是意料之中的，可以忽略不计。</li><li id="1147" class="nx ny jg kx b ky og lb oh le oi li oj lm ok lq oc od oe of bi translated">PACF图在滞后-1处显示了强的部分自相关，这表明AR(1)过程。</li><li id="6766" class="nx ny jg kx b ky og lb oh le oi li oj lm ok lq oc od oe of bi translated">滞后2的相关性刚好在5%的显著性界限之外。所以，它可能重要，也可能不重要。</li></ul><p id="b436" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">总的来说，ACF和PACF曲线表明在滞后-1时有明确的强自回归影响。因此，除了<em class="nj">输出</em>变量之外，我们应该包括<em class="nj">打击</em>在滞后-1的滞后版本作为回归变量。</p><h1 id="3d90" class="mg mh jg bd mi mj mk ml mm mn mo mp mq km mr kn ms kp mt kq mu ks mv kt mw mx bi translated">回归策略</h1><p id="cb92" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">我们的策略将基于<strong class="kx jh">在<em class="nj">输出</em>和在滞后-1 </strong> <em class="nj">的<em class="nj">撞击</em>的延时副本上回归<em class="nj">撞击</em>。</em></p><p id="19ca" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于strikes包含整数数据，我们将使用<strong class="kx jh">泊松回归模型</strong>来研究<em class="nj">输出</em>和<em class="nj"> strikes </em>之间的关系。</p><p id="3fe8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将额外假设制造业在低可变性和高可变性周期之间冲击数据周期，这可以使用2状态离散马尔可夫过程来建模。</p><p id="99f2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为什么我们只为马尔可夫模型选择了两个区域？为什么不是3或4个政权？答案很简单，最好从具有最少可能状态的马尔可夫模型开始，以避免过度拟合。</p><p id="0688" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">总之，我们将使用一个<strong class="kx jh">二态泊松隐马尔可夫模型</strong>来研究制造业产量对罢工的关系。</p><p id="9f7b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，我们有:</p><h2 id="9b24" class="np mh jg bd mi ol om dn mm on oo dp mq le op oq ms li or os mu lm ot ou mw ov bi translated">因变量(内生变量)</h2><p id="55b1" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated"><strong class="kx jh"> y </strong> = <em class="nj">罢工</em></p><h2 id="7bb4" class="np mh jg bd mi ol om dn mm on oo dp mq le op oq ms li or os mu lm ot ou mw ov bi translated">回归变量(外部变量)</h2><p id="bd29" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated"><strong class="kx jh"><em class="nj">X</em></strong>=<em class="nj">【output，strikes _ LAG _ 1】+我们即将描述的隐马尔可夫模型相关变量。</em></p><p id="4151" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将首先说明模型的泊松部分，然后看看如何“混合”马尔可夫模型。</p><p id="9955" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">泊松模型的均值(不考虑马尔可夫模型的影响)可以表示如下:</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ow"><img src="../Images/78e697a782f8a9b7068ddee593f29565.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r2kRUa-b4Vogfqqn65rkVQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">时间t的预期冲击值是时间t的输出和前一时间步的冲击数(和回归截距)的函数(图片由作者提供)</p></figure><p id="a9e2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于我们假设<em class="nj">走向</em>为泊松分布，其概率质量函数如下:</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/a29bdd5afc3181483d46dd40df27a0b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*CxoSjfGNqoLBVcW2PSJxlA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">泊松分布撞击变量(图片由作者提供)</p></figure><h2 id="2a91" class="np mh jg bd mi ol om dn mm on oo dp mq le op oq ms li or os mu lm ot ou mw ov bi translated">处理“模型爆炸”和零值数据</h2><p id="32fa" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">我们的泊松模型有一个问题。让我们再来看看说明书的意思:</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ow"><img src="../Images/78e697a782f8a9b7068ddee593f29565.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r2kRUa-b4Vogfqqn65rkVQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">时间t的预期冲击值是时间t的输出和前一时间步的冲击数(和回归截距)的函数(图片由作者提供)</p></figure><p id="4534" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果<em class="nj"> (strikes)_(t-1) </em>项的系数<em class="nj"> β_2 </em>大于<em class="nj"> 0 </em>，我们将面临所谓的“模型爆炸”效应，这是由从<em class="nj"> (strikes)_(t-1) </em>到<em class="nj">(strikes)_(t)</em>的正反馈循环引起的但是<em class="nj"> (strikes)_(t-1) </em>为零时<em class="nj"> (strikes)_(t-1) </em>未定义。我们将通过做两件事来解决这个问题:</p><ol class=""><li id="7931" class="nx ny jg kx b ky kz lb lc le nz li oa lm ob lq oy od oe of bi translated">我们引入一个指示变量<em class="nj"> d_t </em>，当<em class="nj"> (strikes)_(t-1) </em>时设置为1，否则设置为<em class="nj"> 0 </em>，并且，</li><li id="5f23" class="nx ny jg kx b ky og lb oh le oi li oj lm ok lq oy od oe of bi translated">每当<em class="nj">(冲击)_(t-1) </em>为零时，我们将<em class="nj">(冲击)_(t-1) </em>设置为<em class="nj"> 1.0 </em>。</li></ol><p id="fc79" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以上两个干预的净效果是，每当原始数据集中的<em class="nj"> (strikes)_(t-1) </em>为零时，强制优化器训练<em class="nj"> d_t </em>的系数。Cameron和Trivedi在他们的书<a class="ae jd" href="http://cameron.econ.ucdavis.edu/racd/count.html" rel="noopener ugc nofollow" target="_blank"> <em class="nj">计数数据的回归分析</em> </a> <em class="nj">中详细讨论了这种方法(参见第7.5节:自回归模型)。</em></p><p id="12c1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">考虑到上述变化，泊松过程均值的一个更稳健的规范如下:</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oz"><img src="../Images/bb0999636b3a1172670e24fcfe2a08ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tNVRMRFpeN9wqfRbaog4IQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作为时间t输出、前一时间步的撞击次数的自然对数和指示变量(和回归截距)的函数的时间t的撞击期望值(图片由作者提供)</p></figure><h2 id="93a8" class="np mh jg bd mi ol om dn mm on oo dp mq le op oq ms li or os mu lm ot ou mw ov bi translated">马尔可夫模型中的混合</h2><p id="52db" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">现在，让我们注入2态马尔可夫模型的影响。这导致所有的回归系数<strong class="kx jh"><em class="nj">β_ cap</em></strong><em class="nj">=【β_ cap _ 0，β_cap_1，β_cap_2，β_ cap _ 3】</em>，因此拟合的平均值<em class="nj"> μ_cap_t </em>变成马尔可夫状态特定的，如下所示。注意附加的下标<em class="nj"> j </em>表示在时间<em class="nj"> t </em>有效的马尔可夫状态:</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pa"><img src="../Images/c46d02d8df73f5d9ba6a6565bea0eb25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dg3CeZ9RFPuIN7dTDRfoZw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">对应于state=j马尔可夫状态特定均值(图片由作者提供)</p></figure><p id="ef12" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">假设马尔可夫状态变量<em class="nj"> s_t </em>在时间<em class="nj"> t </em>处于状态<em class="nj"> j </em>中，则在时间<em class="nj"> t </em>观察到特定计数的<em class="nj">撞击</em>的相应马尔可夫特定泊松概率如下:</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/1fd39796d4b54dec46652aabda97abfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*FIQRHbGHM5q9S2s2fHQBUw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">在时间t观察到特定撞击计数的马尔可夫状态相关概率(图片由作者提供)</p></figure><p id="ec88" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其中，马尔可夫状态转移矩阵<strong class="kx jh"> <em class="nj"> P </em> </strong>为:</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/be4b6f55975f8725dbdc04fc57263180.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*ZoU_3hvWcVWpJujjjxvSHw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">2状态马尔可夫过程的状态转移矩阵(图片由作者提供)</p></figure><p id="ab3f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">并且包含在时间<em class="nj"> t </em>的状态概率分布的马尔可夫状态概率向量如下:</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/92b71af26181b4d019478eb6fbd4e445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*vDeRfcuzRSnEuPBeh2IsMA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">2态马尔可夫模型的时间相关状态概率(图片由作者提供)</p></figure><p id="97aa" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">根据上下文中的上述讨论，让我们重申<em class="nj">走向</em>数据集的泊松隐马尔可夫模型的外生和内生变量:</p><h2 id="cdf3" class="np mh jg bd mi ol om dn mm on oo dp mq le op oq ms li or os mu lm ot ou mw ov bi translated">因变量(内生变量)</h2><p id="4844" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated"><strong class="kx jh"> y </strong> = <em class="nj">打击</em></p><h2 id="a1eb" class="np mh jg bd mi ol om dn mm on oo dp mq le op oq ms li or os mu lm ot ou mw ov bi translated">回归变量(外部变量)</h2><p id="9009" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated"><strong class="kx jh"> <em class="nj"> X </em> </strong> = <em class="nj">【输出，ln (strikes_LAG_1)，d_t】和</em> <strong class="kx jh"> <em class="nj"> P </em> </strong></p><h2 id="16a6" class="np mh jg bd mi ol om dn mm on oo dp mq le op oq ms li or os mu lm ot ou mw ov bi translated">培训和优化</h2><p id="6335" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">训练泊松PMM涉及优化回归系数的马尔可夫状态相关矩阵(注意，在Python代码中，我们将使用该矩阵的转置):</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/d799fdce965aa5c2baffa5e1cdddf327.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*P-XEn_MibzWr4taxmvVOzA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">马尔可夫状态特定回归系数矩阵(图片由作者提供)</p></figure><p id="b29d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">并且还优化状态转移概率(矩阵<strong class="kx jh"> <em class="nj"> P </em> </strong>):</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/be4b6f55975f8725dbdc04fc57263180.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*ZoU_3hvWcVWpJujjjxvSHw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">2状态马尔可夫过程的状态转移矩阵(图片由作者提供)</p></figure><p id="34be" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">优化将通过<a class="ae jd" href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jh">最大似然估计</strong> </a>完成，其中优化器将找到<strong class="kx jh"><em class="nj"/></strong>和<strong class="kx jh"> <em class="nj"> P </em> </strong>的值，这将最大化观察到<strong class="kx jh"> <em class="nj"> y </em> </strong>的可能性。我们将使用statsmodels提供的<a class="ae jd" href="https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jh"> BFGS </strong> </a>优化器来执行优化。</p><p id="4f45" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有一个小问题我们需要解决。在整个优化过程中，马尔可夫状态转移概率<em class="nj"> p_ij </em>需要遵守以下约束，即所有转移概率都位于[0，1]区间内，并且跨越任意一行<strong class="kx jh"> <em class="nj"> P </em> </strong>的概率总和总是1:</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/b3ce37dbabaed9fa603ccc0ce78b3ad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*iKDt-BxfTsTi5a9bsIsz_Q.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">所有马尔可夫状态转移概率遵守的约束(图片由作者提供)</p></figure><p id="99bf" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在优化期间，我们通过定义大小为<em class="nj"> (k x k) </em>的矩阵<strong class="kx jh"> <em class="nj"> Q </em> </strong>来处理这些约束，该矩阵充当<strong class="kx jh"> <em class="nj"> P </em> </strong>的代理，如下所示:</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/61483c90860166381c1fc2e3a973d8c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*ja2L9PHPO8wc0v--mp7DCw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">代理矩阵<strong class="bd ph"> Q </strong>(图片作者提供)</p></figure><p id="4b4b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们不是优化<strong class="kx jh"> <em class="nj"> P </em> </strong>，而是通过允许<em class="nj"> q_ij </em>在-∞到+∞之间自由变化来优化<strong class="kx jh"><em class="nj"/></strong>。在每次优化迭代中，<strong class="kx jh">我们通过将</strong><em class="nj"/><strong class="kx jh">的值标准化到区间</strong><em class="nj">【0.0，1.0】</em>来获得 <em class="nj"> p_ij </em> <strong class="kx jh">，如下:</strong></p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pi"><img src="../Images/b328ee193be594d5388a67d51a8c3b23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dkz5G7MbLf2lfdZkxSalsg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">标准化<strong class="bd ph"> Q </strong>矩阵以获得<strong class="bd ph"> P </strong>矩阵(图片由作者提供)</p></figure><p id="1367" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">至此，让我们回到我们的<em class="nj">打击</em>数据集。</p><h1 id="9d68" class="mg mh jg bd mi mj mk ml mm mn mo mp mq km mr kn ms kp mt kq mu ks mv kt mw mx bi translated">准备用于培训的strikes数据集</h1><p id="a046" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">我们看到在<em class="nj">打击</em>时间序列中，在滞后-1处有很强的相关性，添加<em class="nj">打击</em>的滞后-1拷贝作为回归变量。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="b75d" class="np mh jg nl b gy nq nr l ns nt">strikes_data['strikes_lag1'] = strikes_data['strikes'].<strong class="nl jh">shift</strong>(1)</span><span id="1f8c" class="np mh jg nl b gy nu nr l ns nt"><strong class="nl jh">#Drop rows with empty cells created by the shift operation<br/></strong>strikes_data = strikes_data.<strong class="nl jh">dropna</strong>()</span></pre><p id="72eb" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">创建指标函数，计算指标变量<em class="nj"> d1 </em>的值如下:如果<em class="nj">击</em> == 0，<em class="nj"> d1 </em> = 1，否则<em class="nj"> d1 </em> = 0。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="2122" class="np mh jg nl b gy nq nr l ns nt">def <strong class="nl jh">indicator_func</strong>(x):<br/>    if x == 0:<br/>        return 1<br/>    else:<br/>        return 0</span></pre><p id="148f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">将<em class="nj"> d1 </em>的列添加到数据框中:</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="92c3" class="np mh jg nl b gy nq nr l ns nt">strikes_data['d1'] = strikes_data['strikes_lag1'].<strong class="nl jh">apply</strong>(indicator_func)</span></pre><p id="b636" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">调整滞后的<em class="nj">撞击</em>变量，当其值为0时，将其设置为1。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="ac3b" class="np mh jg nl b gy nq nr l ns nt">strikes_data['strikes_adj_lag1'] = np.<strong class="nl jh">maximum</strong>(1, strikes_data['strikes_lag1'])</span></pre><p id="c89b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">添加strikes_lag1的自然对数作为回归变量。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="32d4" class="np mh jg nl b gy nq nr l ns nt">strikes_data['ln_strikes_adj_lag1'] = np.<strong class="nl jh">log</strong>(strikes_data['strikes_adj_lag1'])</span></pre><p id="2a24" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">用<a class="ae jd" href="https://patsy.readthedocs.io/en/latest/quickstart.html" rel="noopener ugc nofollow" target="_blank"> Patsy </a>语法形成回归表达式。不需要显式指定回归截距<em class="nj"> β_0 </em>。Patsy将自动在<strong class="kx jh"> <em class="nj"> X </em> </strong>中包含一个占位符。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="2a03" class="np mh jg nl b gy nq nr l ns nt">expr = 'strikes ~ output + ln_strikes_adj_lag1 + d1'</span></pre><p id="2e20" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用Patsy雕刻出<strong class="kx jh"> <em class="nj"> y </em> </strong>和<strong class="kx jh"> <em class="nj"> X </em> </strong>矩阵。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="4717" class="np mh jg nl b gy nq nr l ns nt">y_train, X_train = <strong class="nl jh">dmatrices</strong>(expr, strikes_data, return_type='dataframe')</span></pre><p id="5549" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们看看X和y矩阵的结果:</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="4376" class="np mh jg nl b gy nq nr l ns nt"><strong class="nl jh">print</strong>(y_train)</span></pre><figure class="ne nf ng nh gt is gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/dda9803fd21c5a49e8a4dc11387e2571.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*BnNkRvjX-QThyc-KVPvGcA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">y_train(图片由作者提供)</p></figure><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="fc02" class="np mh jg nl b gy nq nr l ns nt"><strong class="nl jh">print</strong>(X_train)</span></pre><figure class="ne nf ng nh gt is gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/f0d06efe852e92eaa0eaea7de497ac1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*el9DPaq2Gw_2Z1Z2NUJxfQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">X_train(图片由作者提供)</p></figure><p id="625b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我们继续之前，我们需要构建<code class="fe pl pm pn nl b">PoissonHMM</code>类。为此，我们将使用statsmodels提供的类<code class="fe pl pm pn nl b"><a class="ae jd" href="https://www.statsmodels.org/dev/_modules/statsmodels/base/model.html#GenericLikelihoodModel" rel="noopener ugc nofollow" target="_blank"><strong class="kx jh">GenericLikelihoodModel</strong></a></code>。</p><h1 id="a64a" class="mg mh jg bd mi mj mk ml mm mn mo mp mq km mr kn ms kp mt kq mu ks mv kt mw mx bi translated">创建自定义泊松隐马尔可夫模型类</h1><p id="6514" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">我们将创建的<code class="fe pl pm pn nl b">PoissonHMM</code>类将扩展<code class="fe pl pm pn nl b">GenericLikelihoodModel</code>类，以便我们可以使用定制的对数似然函数来训练模型。让我们从定义<code class="fe pl pm pn nl b">PoissonHMM</code>类的构造函数开始。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="9932" class="np mh jg nl b gy nq nr l ns nt"><strong class="nl jh">class </strong>PoissonHMM(<strong class="nl jh">GenericLikelihoodModel</strong>):<br/>    <strong class="nl jh">def __init__</strong>(self, endog, exog, <strong class="nl jh">k_regimes</strong>=2, <strong class="nl jh">loglike</strong>=None, <br/>                 <strong class="nl jh">score</strong>=None, <strong class="nl jh">hessian</strong>=None,<br/>                 <strong class="nl jh">missing</strong>=<strong class="nl jh">'</strong>none<strong class="nl jh">'</strong>, <strong class="nl jh">extra_params_names</strong>=None, **kwds):<br/>        <strong class="nl jh">super</strong>(<strong class="nl jh">PoissonHMM</strong>, self).<strong class="nl jh">__init__</strong>(<strong class="nl jh">endog</strong>=endog, <strong class="nl jh">exog</strong>=exog, <br/>            <strong class="nl jh">loglike</strong>=loglike, <strong class="nl jh">score</strong>=score, <strong class="nl jh">hessian</strong>=hessian, <br/>            <strong class="nl jh">missing</strong>=missing, <strong class="nl jh">extra_params_names</strong>=extra_params_names, <br/>            <strong class="nl jh">kwds</strong>=kwds)</span></pre><p id="2652" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，让我们用下面几行代码填充构造函数，即PoissonHMM的<code class="fe pl pm pn nl b"><em class="nj">__init__</em> </code>方法:</p><p id="f9e0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，我们将因变量转换成statsmodels喜欢使用的numpy数组。我们还会复制政权的数量。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="1010" class="np mh jg nl b gy nq nr l ns nt">self.y = np.<strong class="nl jh">array</strong>(self.endog)<br/>self.k_regimes = k_regimes</span></pre><p id="2f32" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，设置状态特定回归系数<strong class="kx jh"> <em class="nj"> β的<em class="nj">k×m</em>大小矩阵。</em> </strong> m= <code class="fe pl pm pn nl b">self.<strong class="kx jh">exog</strong>.<strong class="kx jh">shape</strong>[1]</code>是包含截距的回归系数的个数:</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="b7b5" class="np mh jg nl b gy nq nr l ns nt">self.beta_matrix = np.<strong class="nl jh">ones</strong>([self.k_regimes, self.<strong class="nl jh">exog</strong>.<strong class="nl jh">shape</strong>[1]])</span></pre><p id="3372" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">设置代理转移概率矩阵<strong class="kx jh"> <em class="nj"> Q </em> </strong>的<em class="nj"> k x k </em>矩阵。将其初始化为<em class="nj"> 1.0/k </em>。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="430e" class="np mh jg nl b gy nq nr l ns nt">self.q_matrix = np.<strong class="nl jh">ones</strong>([self.k_regimes,self.k_regimes])*(1.0/self.k_regimes)</span><span id="a6db" class="np mh jg nl b gy nu nr l ns nt"><strong class="nl jh">print</strong>('self.q_matrix='+<strong class="nl jh">str</strong>(self.q_matrix))</span></pre><p id="6b2a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">设置泊松平均的状态矩阵。这些将在优化循环期间更新。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="deb9" class="np mh jg nl b gy nq nr l ns nt">self.mu_matrix = []</span></pre><p id="e3a2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">设置真实马尔可夫转移概率的<em class="nj"> k x k </em>矩阵，该矩阵将使用前面描述的标准化技术从q矩阵中计算出来。初始化为<em class="nj"> 1.0/k </em>。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="9e28" class="np mh jg nl b gy nq nr l ns nt">self.gamma_matrix = np.<strong class="nl jh">ones</strong>([self.k_regimes, self.k_regimes])*(1.0/self.k_regimes)</span><span id="bd54" class="np mh jg nl b gy nu nr l ns nt"><strong class="nl jh">print</strong>('self.gamma_matrix='+<strong class="nl jh">str</strong>(self.gamma_matrix))</span></pre><p id="0a92" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">设置马尔可夫状态概率(<strong class="kx jh"> <em class="nj"> π </em> </strong>向量)。但是为了避免与回归模型的平均值(也称为<strong class="kx jh"><em class="nj"/></strong>)混淆，我们将遵循<a class="ae jd" href="http://cameron.econ.ucdavis.edu/racd/count.html" rel="noopener ugc nofollow" target="_blank"> Cameron和Trivedi </a>中使用的约定，并使用符号<strong class="kx jh"> <em class="nj"> δ </em> </strong>。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="e789" class="np mh jg nl b gy nq nr l ns nt">self.delta_matrix = np.<strong class="nl jh">ones</strong>([self.<strong class="nl jh">exog</strong>.<strong class="nl jh">shape</strong>[0],self.k_regimes])*(1.0/self.k_regimes)</span><span id="4d27" class="np mh jg nl b gy nu nr l ns nt"><strong class="nl jh">print</strong>('self.delta_matrix='+<strong class="nl jh">str</strong>(self.delta_matrix))</span></pre><p id="3f31" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">初始化优化器将要优化的参数<strong class="kx jh"> <em class="nj"> β </em> </strong>和<strong class="kx jh"> <em class="nj"> Q </em> </strong>的初始值向量。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="9327" class="np mh jg nl b gy nq nr l ns nt">self.start_params = np.<strong class="nl jh">repeat</strong>(np.<strong class="nl jh">ones</strong>(self.<strong class="nl jh">exog</strong>.<strong class="nl jh">shape</strong>[1]), <strong class="nl jh">repeats</strong>=self.k_regimes)</span><span id="104e" class="np mh jg nl b gy nu nr l ns nt">self.start_params = np.<strong class="nl jh">append</strong>(self.start_params, self.q_matrix.<strong class="nl jh">flatten</strong>())</span><span id="9f51" class="np mh jg nl b gy nu nr l ns nt"><strong class="nl jh">print</strong>('self.start_params='+<strong class="nl jh">str</strong>(self.start_params))</span></pre><p id="5b97" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">初始化一个非常小的特定于机器的数字。它被我们即将编写的自定义对数似然函数所使用。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="a174" class="np mh jg nl b gy nq nr l ns nt">self.EPS = np.<strong class="nl jh">MachAr</strong>().eps</span></pre><p id="9430" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，初始化优化器的迭代计数器。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="d03d" class="np mh jg nl b gy nq nr l ns nt">self.iter_num=0</span></pre><p id="0ca9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><code class="fe pl pm pn nl b">PoissonHMM</code>类的完整构造函数如下所示:</p><figure class="ne nf ng nh gt is"><div class="bz fp l di"><div class="po pp l"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">PoissonHMM类的构造函数</p></figure><p id="ea63" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，我们将覆盖<code class="fe pl pm pn nl b">GenericLikelihoodModel</code>的<code class="fe pl pm pn nl b">nloglikeobs(self, params)</code>方法。这个方法由优化器在每次迭代中调用一次，以获得与传递给它的所有<code class="fe pl pm pn nl b">params</code>的当前值相对应的对数似然函数的当前值。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="6f6e" class="np mh jg nl b gy nq nr l ns nt"><strong class="nl jh">def </strong>nloglikeobs(self, params):</span></pre><p id="63b0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们用下面的函数来填充这个方法，我们将很快定义这些函数:</p><p id="5dbf" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从所有参数的当前值重构<strong class="kx jh"> <em class="nj"> Q </em> </strong>和<strong class="kx jh"> <em class="nj"> β </em> </strong>矩阵。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="e0d9" class="np mh jg nl b gy nq nr l ns nt">self.<strong class="nl jh">reconstitute_parameter_matrices</strong>(params)</span></pre><p id="d805" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">建立泊松平均的状态矩阵。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="3dbe" class="np mh jg nl b gy nq nr l ns nt">self.<strong class="nl jh">compute_regime_specific_poisson_means</strong>()</span></pre><p id="4c44" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">通过将所有的<strong class="kx jh"> <em class="nj"> Q </em> </strong>值标准化到0到1的范围来构建马尔可夫转移概率矩阵。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="8814" class="np mh jg nl b gy nq nr l ns nt">self.<strong class="nl jh">compute_markov_transition_probabilities</strong>()</span></pre><p id="bbe4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">建立马尔可夫状态概率分布的<em class="nj"> (len(y) x k) </em>矩阵delta。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="3e10" class="np mh jg nl b gy nq nr l ns nt">self.<strong class="nl jh">compute_markov_state_probabilities</strong>()</span></pre><p id="717c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">计算每个观察值的对数似然值。该函数返回对数似然值的大小为<em class="nj">len(</em><strong class="kx jh"><em class="nj">y</em></strong><em class="nj">)</em>的数组。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="b1f7" class="np mh jg nl b gy nq nr l ns nt">ll = self.<strong class="nl jh">compute_loglikelihood</strong>()</span></pre><p id="08cf" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">递增迭代计数。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="0d93" class="np mh jg nl b gy nq nr l ns nt">self.iter_num=self.iter_num+1</span></pre><p id="812c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">打印出迭代总结。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="ecfa" class="np mh jg nl b gy nq nr l ns nt"><strong class="nl jh">print</strong>('ITER='+<strong class="nl jh">str</strong>(self.iter_num) + ' ll='+<strong class="nl jh">str</strong>(((-ll).<strong class="nl jh">sum</strong>(0)))</span></pre><p id="c2fc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，返回求反的对数似然数组。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="f2c0" class="np mh jg nl b gy nq nr l ns nt">return -ll</span></pre><p id="00bc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面是整个<code class="fe pl pm pn nl b">nloglikeobs(self, params)</code>的方法:</p><figure class="ne nf ng nh gt is"><div class="bz fp l di"><div class="po pp l"/></div></figure><p id="058c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面是从<code class="fe pl pm pn nl b">nloglikeobs(self, params)</code>方法调用的助手方法的实现:</p><p id="3b3f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从所有参数的当前值重建<strong class="kx jh"> <em class="nj"> Q </em> </strong>和<strong class="kx jh"> <em class="nj"> β </em> </strong>矩阵:</p><figure class="ne nf ng nh gt is"><div class="bz fp l di"><div class="po pp l"/></div></figure><p id="3dc9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">建立泊松平均的状态矩阵:</p><figure class="ne nf ng nh gt is"><div class="bz fp l di"><div class="po pp l"/></div></figure><p id="eeb7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">通过将所有的<strong class="kx jh"> <em class="nj"> Q </em> </strong>值标准化到0到1的范围，构建马尔可夫转移概率<strong class="kx jh"> <em class="nj"> P </em> </strong>的矩阵:</p><figure class="ne nf ng nh gt is"><div class="bz fp l di"><div class="po pp l"/></div></figure><p id="2b6b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">建立马尔可夫状态概率分布的<em class="nj"> (len(y) x k) </em>大小<strong class="kx jh"> <em class="nj"> δ </em> </strong>矩阵。</p><figure class="ne nf ng nh gt is"><div class="bz fp l di"><div class="po pp l"/></div></figure><p id="ee05" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，计算泊松马尔可夫模型的所有对数似然值:</p><figure class="ne nf ng nh gt is"><div class="bz fp l di"><div class="po pp l"/></div></figure><p id="40c1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们重写超类中的一个方法，该方法尽力计算一个可逆Hessian，以便可以成功计算所有训练参数的标准误差和置信区间。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="1178" class="np mh jg nl b gy nq nr l ns nt">def <strong class="nl jh">hessian</strong>(self, params):<br/>    for approx_hess_func <strong class="nl jh">in </strong>[approx_hess3, approx_hess2, <br/>                            approx_hess1]:<br/>        H = approx_hess_func(<strong class="nl jh">x</strong>=params, <strong class="nl jh">f</strong>=self.loglike, <br/>            <strong class="nl jh">epsilon</strong>=self.EPS)<br/>        if np.<strong class="nl jh">linalg</strong>.<strong class="nl jh">cond</strong>(H) &lt; 1 / self.EPS:<br/>            print('Found invertible hessian using' + <br/>                str(approx_hess_func))<br/>            return H<br/>    <strong class="nl jh">print</strong>('DID NOT find invertible hessian')<br/>    H[H == 0.0] = self.EPS<br/>    return H</span></pre><p id="94cc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">综上所述，下面是PoissonHMM类的完整类定义:</p><figure class="ne nf ng nh gt is"><div class="bz fp l di"><div class="po pp l"/></div></figure><p id="a77f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在我们已经有了自定义的<code class="fe pl pm pn nl b">PoissonHMM</code>类，让我们继续在我们的<em class="nj">(</em><strong class="kx jh"><em class="nj">y _ train</em></strong><em class="nj">，</em><strong class="kx jh"><em class="nj">X _ train</em></strong><em class="nj">)</em>数据集上训练它，这个数据集是我们使用Patsy创建的。</p><p id="f8e5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们回忆一下<code class="fe pl pm pn nl b">PoissonHMM</code>的构造函数是什么样子的:</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="7848" class="np mh jg nl b gy nq nr l ns nt"><strong class="nl jh">def </strong>__init__(<strong class="nl jh">self</strong>, <strong class="nl jh">endog</strong>, <strong class="nl jh">exog</strong>, <strong class="nl jh">k_regimes</strong>=2, <strong class="nl jh">loglike</strong>=None, <br/>            <strong class="nl jh">score</strong>=None, <strong class="nl jh">hessian</strong>=None, <strong class="nl jh">missing</strong>=<strong class="nl jh">'</strong>none<strong class="nl jh">'</strong>, <br/>            <strong class="nl jh">extra_params_names</strong>=None, <strong class="nl jh">**kwds</strong>):</span></pre><p id="0f76" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将使用2状态HMM进行实验，假设数据循环通过2个不同但隐藏的区域，每个区域都会影响泊松过程的均值。所以我们将k_regimes设置为2:</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="76b7" class="np mh jg nl b gy nq nr l ns nt">k_regimes = 2</span></pre><p id="a72c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">注意，PoissonHMM带有一个<code class="fe pl pm pn nl b">extra_param_names</code>参数。除了矩阵<strong class="kx jh"> <em class="nj"> X_train </em> </strong>的列名之外，这是我们希望优化器优化的参数列表。让我们初始化并构建这个额外参数名的列表。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="7197" class="np mh jg nl b gy nq nr l ns nt">extra_params_names = []</span></pre><p id="2121" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">每个状态将有<code class="fe pl pm pn nl b">len(X_train.columns)</code>个回归系数<em class="nj">被发送到模型中进行优化。所以，总的来说，<code class="fe pl pm pn nl b">len(X_train.columns) * k_regimes</code> <em class="nj"> β </em>中的系数都要被优化。其中，对应于一个状态(比如状态1)的系数已经以回归参数的形式被烘焙到<code class="fe pl pm pn nl b">X_train</code>中。statsmodels将从<strong class="kx jh"> <em class="nj"> X_train </em> </strong>矩阵中收集它们的名称。它会自动向模型提供这组参数的名称。因此，我们需要通过<code class="fe pl pm pn nl b">extra_param_names</code>参数(因此得名<code class="fe pl pm pn nl b"><em class="nj">extra</em>_param_names</code>)告诉statsmodels剩余参数集的名称，对应于剩余的政权。因此，我们将第二种状态的平衡参数组插入<code class="fe pl pm pn nl b">extra_param_names</code>，如下所示:</em></p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="4a31" class="np mh jg nl b gy nq nr l ns nt">for regime_num <strong class="nl jh">in range</strong>(1, k_regimes):<br/>    for param_name in X_train.columns:<br/>        extra_params_names.<strong class="nl jh">append</strong>(param_name+'_R'+<strong class="nl jh">str</strong>(regime_num))</span></pre><p id="ec86" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该模型还将优化代理转移概率的<em class="nj">k×k</em>矩阵:矩阵<strong class="kx jh"> <em class="nj"> Q </em> </strong>所以也把它们发送到extra_params列表中:</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="c1af" class="np mh jg nl b gy nq nr l ns nt">for i <strong class="nl jh">in </strong>range(k_regimes):<br/>    for j <strong class="nl jh">in range</strong>(k_regimes):<br/>        extra_params_names.<strong class="nl jh">append</strong>('q'+<strong class="nl jh">str</strong>(i)+<strong class="nl jh">str</strong>(j))</span></pre><p id="eea5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="nj">注意:在Python代码中，我们选择使用基于0的马尔可夫状态索引。也就是说，我们在代码中提到的状态1是状态0。</em></p><p id="2cae" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的<code class="fe pl pm pn nl b">extra_param_names</code>名单现在准备好了。</p><p id="699d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">创建一个<code class="fe pl pm pn nl b">PoissonHMM</code>模型类的实例。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="90c1" class="np mh jg nl b gy nq nr l ns nt">poisson_hmm = <strong class="nl jh">PoissonHMM</strong>(<strong class="nl jh">endog</strong>=y_train, <strong class="nl jh">exog</strong>=X_train, <br/>                        <strong class="nl jh">k_regimes</strong>=k_regimes,<br/>                        <strong class="nl jh">extra_params_names</strong>=extra_params_names)</span></pre><p id="ebd0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">训练模型。注意，我们要求statsmodels使用BFGS优化器。</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="aa9a" class="np mh jg nl b gy nq nr l ns nt">poisson_hmm_results = poisson_hmm.<strong class="nl jh">fit</strong>(<strong class="nl jh">method</strong>=’bfgs’, <strong class="nl jh">maxiter</strong>=1000)</span></pre><p id="1e1e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">打印出拟合的马尔可夫转移概率:</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="af33" class="np mh jg nl b gy nq nr l ns nt"><strong class="nl jh">print</strong>(poisson_hmm.gamma_matrix)</span></pre><p id="080d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们看到以下输出:</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="4ded" class="np mh jg nl b gy nq nr l ns nt">[[0.96884629 0.03115371]<br/> [0.0043594  0.9956406 ]]</span></pre><p id="bdf8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这样，我们的马尔可夫状态转移矩阵<strong class="kx jh">T5【P】T6</strong>如下:</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/276f8a438098d6d5266f9fb8396ce675.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*1dB743619X6TD_s7-QSn4g.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">拟合的转移矩阵(图片由作者提供)</p></figure><p id="e12b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这对应于下面的状态转换图:</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pr"><img src="../Images/5af8253061afd56e67ea0b0a8f07a571.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lzmCDQZ-D7rCdLNMzcVL6g.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">与泊松HMM关联的2状态隐马尔可夫过程的状态转移图(图片由作者提供)</p></figure><p id="642b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">状态转换图显示，一旦系统进入状态1或2，它真的喜欢处于该状态，并且很少倾向于切换到另一个状态。</p><p id="fabe" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，打印出模型培训总结:</p><pre class="ne nf ng nh gt nk nl nm nn aw no bi"><span id="0191" class="np mh jg nl b gy nq nr l ns nt"><strong class="nl jh">print</strong>(poisson_hmm_results.<strong class="nl jh">summary</strong>())</span></pre><p id="4359" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们看到以下输出。我已经调出了与两个马尔可夫状态1和2相对应的模型参数，以及Q-matrix值(如前所述，这些值恰好索引为0)。</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ps"><img src="../Images/e1011982e5817a68e9b6d094fbb507a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m2aqCQdcMML8DboB2pxjVg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">泊松隐马尔可夫模型的训练总结(图片由作者提供)</p></figure><p id="e2d3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面是我们在输出中观察到的一些情况:</p><ol class=""><li id="e896" class="nx ny jg kx b ky kz lb lc le nz li oa lm ob lq oy od oe of bi translated">该模型适合于两个马尔可夫状态中的每一个的不同截距。在状态1和状态2中，截距(<em class="nj"> β_0 </em>)分别为2.2891和0.7355。</li><li id="5206" class="nx ny jg kx b ky og lb oh le oi li oj lm ok lq oy od oe of bi translated">产出效应(<em class="nj"> β_1 </em>)在方案1中为-2.6620，表明制造业产出的增长与罢工次数成反比关系，在方案2中为7.6534，表明随着制造业产出的增加，罢工次数也增加。</li></ol><h1 id="7f02" class="mg mh jg bd mi mj mk ml mm mn mo mp mq km mr kn ms kp mt kq mu ks mv kt mw mx bi translated">拟合优度</h1><p id="902d" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">正如我们从模型训练总结中看到的，模型无法找到<em class="nj"> β_01 </em>和<em class="nj"> q_11 </em>的有效标准误差就证明了这一点。参数<em class="nj"> β_31 </em>、β_22、<em class="nj"> β_32 </em>和<em class="nj"> q_01 </em>的p值不具有统计学意义。</p><p id="71c0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，这是一个好的开始。</p><p id="564d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了实现更好的拟合，我们可能希望用3或4状态马尔可夫过程进行实验，并且也用statsmodels提供的大量优化程序中的另一个进行实验，例如“nm”(牛顿-拉夫森)、“powell”和“basinhopping”。</p><p id="fad6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">顺便说一句，由于我们使用statsmodels的现成方法来打印训练摘要，所以训练摘要中打印的df_model值3会产生误导，应该忽略。</p><p id="1ccb" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，将该模型的拟合优度与此处描述的<strong class="kx jh">泊松自回归模型</strong>以及此处<a class="ae jd" rel="noopener" target="_blank" href="/an-introduction-to-the-poisson-integer-arima-regression-model-b66d3ff2e6e5">描述的<strong class="kx jh">泊松INAR(1) </strong>模型</a>进行比较将是有益的。所有三个模型都适用于相同的制造业罢工数据集:</p><figure class="ne nf ng nh gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pt"><img src="../Images/4191141a25cb65c3cf45dc7b89d3f85d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7n5_vi1D7_1qYdxGLE5J4Q.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">制造业罢工数据集上三个泊松时间序列模型的对数似然性比较(图片由作者提供)</p></figure><p id="4b84" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以看到<a class="ae jd" rel="noopener" target="_blank" href="/the-akaike-information-criterion-c20c8fd832f2">即使考虑到</a>泊松HMM使用的大量拟合参数，泊松HMM模型比其他两种时间序列模型更有可能观察到<em class="nj">撞击</em>数据集值。</p><h1 id="0dcf" class="mg mh jg bd mi mj mk ml mm mn mo mp mq km mr kn ms kp mt kq mu ks mv kt mw mx bi translated">从这里去哪里？</h1><p id="e9b5" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">以下是一些建立在泊松HMM工作基础上的方法:</p><ol class=""><li id="3db1" class="nx ny jg kx b ky kz lb lc le nz li oa lm ob lq oy od oe of bi translated">我们可以尝试使用不同的优化器和/或通过引入更多的马尔可夫状态来提高<code class="fe pl pm pn nl b">PoissonHMM</code>模型类的拟合度。</li><li id="96ba" class="nx ny jg kx b ky og lb oh le oi li oj lm ok lq oy od oe of bi translated">我们可能要计算PoissonHMM类的<a class="ae jd" rel="noopener" target="_blank" href="/the-complete-guide-to-r-squared-adjusted-r-squared-and-pseudo-r-squared-4136650fc06c"> <strong class="kx jh">伪R平方</strong> </a>。<a class="ae jd" rel="noopener" target="_blank" href="/the-complete-guide-to-r-squared-adjusted-r-squared-and-pseudo-r-squared-4136650fc06c">伪R平方</a>提供了一种比较非线性模型(如泊松-HMM)拟合异方差数据集的拟合优度的极好方法。</li><li id="8c22" class="nx ny jg kx b ky og lb oh le oi li oj lm ok lq oy od oe of bi translated">回想一下，我们所用的泊松模型假设，在任何马尔可夫状态下，撞击的方差与该状态下撞击的平均值相同，这是一种称为等散度的性质。我们可以通过用一个<a class="ae jd" rel="noopener" target="_blank" href="/generalized-poisson-regression-for-real-world-datasets-d1ff32607d79"> <strong class="kx jh">广义泊松</strong> </a>或一个<a class="ae jd" rel="noopener" target="_blank" href="/negative-binomial-regression-f99031bb25b4"> <strong class="kx jh">负二项回归</strong> </a>模型代替泊松模型来间接检验这个假设。这些模型没有对数据做等分散假设。如果GP-HMM或NB-HMM比直接的泊松-HMM产生更好的拟合优度，那么就有理由使用这些模型。</li></ol><p id="f596" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">快乐造型！</p></div><div class="ab cl pu pv hu pw" role="separator"><span class="px bw bk py pz qa"/><span class="px bw bk py pz qa"/><span class="px bw bk py pz"/></div><div class="ij ik il im in"><p id="3751" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下是完整的源代码:</p><figure class="ne nf ng nh gt is"><div class="bz fp l di"><div class="po pp l"/></div></figure></div><div class="ab cl pu pv hu pw" role="separator"><span class="px bw bk py pz qa"/><span class="px bw bk py pz qa"/><span class="px bw bk py pz"/></div><div class="ij ik il im in"><h1 id="15d3" class="mg mh jg bd mi mj qb ml mm mn qc mp mq km qd kn ms kp qe kq mu ks qf kt mw mx bi translated">引用和版权</h1><h2 id="3962" class="np mh jg bd mi ol om dn mm on oo dp mq le op oq ms li or os mu lm ot ou mw ov bi translated">书</h2><p id="2eff" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">Cameron A. Colin，Trivedi Pravin K .，<a class="ae jd" href="http://cameron.econ.ucdavis.edu/racd/count.html" rel="noopener ugc nofollow" target="_blank"> <em class="nj">计数数据的回归分析</em> </a>，计量经济学学会专论№30，剑桥大学出版社，1998年。国际标准书号:0521635675</p><h2 id="7214" class="np mh jg bd mi ol om dn mm on oo dp mq le op oq ms li or os mu lm ot ou mw ov bi translated">报纸</h2><p id="47df" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">凯南j .，<a class="ae jd" href="https://www.sciencedirect.com/science/article/pii/0304407685900648" rel="noopener ugc nofollow" target="_blank"> <em class="nj">美国制造业合同罢工的持续时间，计量经济学杂志</em> </a>，第28卷，1985年第1期，第5-28页，ISSN 0304-4076，<a class="ae jd" href="https://doi.org/10.1016/0304-4076(85)90064-8." rel="noopener ugc nofollow" target="_blank">https://doi . org/10.1016/0304-4076(85)90064-8。</a> <a class="ae jd" href="https://www.ssc.wisc.edu/~jkennan/research/JEM85.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jh"> PDF下载链接</strong> </a></p><p id="8ac3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Cameron C. A .，Trivedi P. K .，<a class="ae jd" href="https://www.sciencedirect.com/science/article/pii/030440769090014K" rel="noopener ugc nofollow" target="_blank"> <em class="nj">基于回归的泊松模型过度离差测试</em> </a>，《计量经济学杂志》，第46卷，第3期，1990年，第347-364页，ISSN 0304-4076，<a class="ae jd" href="https://doi.org/10.1016/0304-4076(90)90014-K." rel="noopener ugc nofollow" target="_blank">https://doi . org/10.1016/0304-4076(90)90014-k .</a></p><h2 id="be05" class="np mh jg bd mi ol om dn mm on oo dp mq le op oq ms li or os mu lm ot ou mw ov bi translated">数据集</h2><p id="a1b5" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">文章中使用的制造业罢工数据集是统计软件中可供公众使用和实验的几个数据集之一，最值得注意的是，这里的<a class="ae jd" href="https://rdrr.io/rforge/Ecdat/man/StrikeNb.html" rel="noopener ugc nofollow" target="_blank">是一个R包</a>。在GPL v3许可下，Vincent Arel-Bundock通过vincentarelbundock.github.io/rdatasets已经可以使用Python访问数据集。</p><h2 id="775d" class="np mh jg bd mi ol om dn mm on oo dp mq le op oq ms li or os mu lm ot ou mw ov bi translated">形象</h2><p id="5027" class="pw-post-body-paragraph kv kw jg kx b ky my kh la lb mz kk ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">本文中的所有图片版权归<a class="ae jd" href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener ugc nofollow" target="_blank"> CC-BY-NC-SA </a>所有，除非图片下面提到了不同的来源和版权。</p></div><div class="ab cl pu pv hu pw" role="separator"><span class="px bw bk py pz qa"/><span class="px bw bk py pz qa"/><span class="px bw bk py pz"/></div><div class="ij ik il im in"><h1 id="14ac" class="mg mh jg bd mi mj qb ml mm mn qc mp mq km qd kn ms kp qe kq mu ks qf kt mw mx bi translated">相关文章</h1><div class="ip iq gp gr ir lr"><a rel="noopener follow" target="_blank" href="/a-beginners-guide-to-discrete-time-markov-chains-d5be17cf0e12"><div class="ls ab fo"><div class="lt ab lu cl cj lv"><h2 class="bd jh gy z fp lw fr fs lx fu fw jf bi translated">离散时间马尔可夫链初学者指南</h2><div class="ly l"><h3 class="bd b gy z fp lw fr fs lx fu fw dk translated">以及如何使用Python模拟离散马尔可夫过程的教程</h3></div><div class="lz l"><p class="bd b dl z fp lw fr fs lx fu fw dk translated">towardsdatascience.com</p></div></div><div class="ma l"><div class="qg l mc md me ma mf ix lr"/></div></div></a></div><div class="ip iq gp gr ir lr"><a rel="noopener follow" target="_blank" href="/a-math-lovers-guide-to-hidden-markov-models-ad718df9fde8"><div class="ls ab fo"><div class="lt ab lu cl cj lv"><h2 class="bd jh gy z fp lw fr fs lx fu fw jf bi translated">数学爱好者的隐马尔可夫模型指南</h2><div class="ly l"><h3 class="bd b gy z fp lw fr fs lx fu fw dk translated">它们是如何工作的，以及它们为什么被“隐藏”起来。</h3></div><div class="lz l"><p class="bd b dl z fp lw fr fs lx fu fw dk translated">towardsdatascience.com</p></div></div><div class="ma l"><div class="qh l mc md me ma mf ix lr"/></div></div></a></div><div class="ip iq gp gr ir lr"><a rel="noopener follow" target="_blank" href="/a-worms-eye-view-of-the-markov-switching-dynamic-regression-model-2fb706ba69f3"><div class="ls ab fo"><div class="lt ab lu cl cj lv"><h2 class="bd jh gy z fp lw fr fs lx fu fw jf bi translated">马尔可夫转换动态回归模型的蠕虫视角</h2><div class="ly l"><h3 class="bd b gy z fp lw fr fs lx fu fw dk translated">详细解释了MSDR模型，并使用真实世界数据集介绍了关于MSDR的Python教程</h3></div><div class="lz l"><p class="bd b dl z fp lw fr fs lx fu fw dk translated">towardsdatascience.com</p></div></div><div class="ma l"><div class="qi l mc md me ma mf ix lr"/></div></div></a></div></div><div class="ab cl pu pv hu pw" role="separator"><span class="px bw bk py pz qa"/><span class="px bw bk py pz qa"/><span class="px bw bk py pz"/></div><div class="ij ik il im in"><p id="417d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="nj">感谢阅读！如果您喜欢这篇文章，请</em> <a class="ae jd" href="https://timeseriesreasoning.medium.com/" rel="noopener"> <strong class="kx jh"> <em class="nj">关注我</em> </strong> </a> <em class="nj">获取关于回归和时间序列分析的技巧、操作方法和编程建议。</em></p></div></div>    
</body>
</html>