<html>
<head>
<title>Label Bias Identification in ML model using Python code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python代码识别ML模型中的标签偏差</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/label-bias-identification-in-ml-model-using-python-code-a0fec9febaa6?source=collection_archive---------24-----------------------#2021-07-20">https://towardsdatascience.com/label-bias-identification-in-ml-model-using-python-code-a0fec9febaa6?source=collection_archive---------24-----------------------#2021-07-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7c44" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何识别机器学习模型中的偏差</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/36837d3cd1a879b9dbfa360743f17890.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m9F73SNPD4uVYqkVOSd-uw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@christianlue" rel="noopener ugc nofollow" target="_blank">克里斯蒂安·卢</a>拍摄</p></figure><p id="1db0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">机器学习领域正在不断发展，这导致了其需求和重要性的显著上升。机器学习模型的应用现在无处不在——在我们的日常生活中，从网飞的电影推荐到亚马逊的产品推荐。从雇佣新员工到金融产品审批决策，现在都是通过机器学习模型自动完成的。人们认为，通过改进的机器学习算法分析的大量数据可以在没有人工干预的情况下实时指导更好的决策和智能行动。</p><p id="f253" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，机器学习模型的这种广泛使用导致了风险——偏见的风险。仅举几个例子:</p><p id="f5ad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">亚马逊终止AI雇佣和招聘，就是一个展品AI不可能公平的例子；该算法优先选择男性候选人，而不是女性。这是因为亚马逊的系统是用10年来收集的数据训练的，这些数据主要来自男性候选人。</p><p id="b710" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种自动化的决策过程可能会导致社会歧视。其中的关键原因是有偏见的训练数据——正如上面亚马逊招聘人工智能的例子所强调的那样。因此，最重要的是确保机器学习模型预测的结果不偏向任何特定的保护类变量，如性别、种族、国籍。</p><p id="b60b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我想在这里强调两个关键指标，这将有助于确定模型结果中是否存在任何偏差。</p><p id="bac0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">a)完全不同的影响——当选择过程对不同的群体产生非常不同的结果时，就会出现这种情况。衡量的方法之一是查看特定受保护类别变量在目标群体中相对于总体人口的分布。我们将使用双样本Kolmogorov-Smirnov检验来检验两个样本是否来自同一个分布。零假设是H0:两个样本都来自同一分布的总体。</p><p id="03c4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">b)机会均等——分类器在受保护人群中的真实阳性率应与整个人群中的真实阳性率相等。这里我们将使用F1统计来计算偏差。</p><p id="cece" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">方法:让我们考虑目标是预测更有可能获得房屋贷款的客户。已经开发了分类器模型，并且已经对属于训练数据集的所有客户进行了评分。让我们假设分数范围从100到1000，任何分数大于600的人都是目标人群的一部分。现在的目标是确定在这个目标人群中是否存在任何关于年龄和性别这两个受保护阶层变量的偏见。</p><p id="e5f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们的例子中，数据<strong class="ky ir"> df </strong>看起来像下面这样——id、事件(实际目标变量)、标签(目标的预测值)和年龄</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/e2e5522577d78bfdc41425aa60544e36.png" data-original-src="https://miro.medium.com/v2/resize:fit:350/format:webp/1*b5jcgESvR80VpfhWQ03ggA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">示例数据</p></figure><pre class="kg kh ki kj gt lt lu lv lw aw lx bi"><span id="bdec" class="ly lz iq lu b gy ma mb l mc md">#code for Continuous variable like - age</span><span id="a6aa" class="ly lz iq lu b gy me mb l mc md"><strong class="lu ir">def</strong> bias_dist_test(data_df,var):<br/>    col_name=var+str('_bucket')<br/>    data_df[col_name] = pd.qcut(data_df[var], q=3)<br/>    data_df2 = data_df.groupby([col_name]).agg({'id': 'count'}).reset_index()<br/>    data_df2[col_name + str('_pop_perc')] = round(100 * data_df2['id']  / data_df2['id'].sum(),2)<br/>    data_df_target=data_df.loc[data_df['score']&gt;600]<br/>    data_df_target2 = data_df_target.groupby([col_name]).agg({'id': 'count'}).reset_index()<br/>    data_df_target2[col_name + str('_target_perc')] = round(100 * data_df_target2['id']  / data_df_target2['id'].sum(),2)<br/>    bias_data_fin=pd.merge(data_df2,data_df_target2,on=col_name,how='left')<br/>    bias_data_fin1=bias_data_fin[[col_name,col_name + str('_pop_perc'),col_name + str('_target_perc')]]<br/>    a,p=stats.ks_2samp(bias_data_fin[col_name + str('_pop_perc')], bias_data_fin[col_name + str('_target_perc')])<br/>    <strong class="lu ir">if</strong> p &lt;.1:<br/>        print("Distribution of "+ var +" is similar with 90<strong class="lu ir">% c</strong>onfidence level between the population and target base and Model is not biased ")<br/>    <strong class="lu ir">else</strong> :<br/>        print("Distribution of "+ var +" is different between the population and target base and Model is biased ")<br/>    <strong class="lu ir">return</strong> bias_data_fin1</span><span id="c605" class="ly lz iq lu b gy me mb l mc md"># Call the function -<br/>bias_dist_test(df,'AGE')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/da4cd941ff07be7bc2eae7c1cf976e6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*UkkuYvUJI5xR2DYuwUh5BQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">年龄分布相似，人群和目标人群之间的置信水平为90%,模型没有偏差</p></figure><p id="0001" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从上表可以明显看出，目标人口和总人口的年龄分布非常相似。<br/>接下来，为了衡量机会均等关键绩效指标，首先将为各个受保护类别变量创建不同的类别，然后计算F1分数。一旦F1分数被计算出来，这些分数的比率将被计算用于不同的类，然后将创建一个1比率的指数。该指数被称为偏差分数，较高的值表示模型有偏差。</p><pre class="kg kh ki kj gt lt lu lv lw aw lx bi"><span id="60f5" class="ly lz iq lu b gy ma mb l mc md">def bias_check(main_data, var, target,predicted_target):<br/>    # Initialize the empty bias matrix<br/>    bias_df = pd.DataFrame(columns = ["metric", "class1", "class2", "class1_score", "class2_score", "ratio", "bias_score"])<br/>    col_name=var+str('_bucket')<br/>    main_data[col_name] = pd.qcut(main_data[var], q=3)<br/>    class_grp = main_data[col_name].unique().tolist()<br/>    # Generate list of all combinations of classes:<br/>    class_bucket_perm = list(combinations(class_grp, 2))<br/>    <br/>    for s in class_bucket_perm:<br/>        # Create subset for each class<br/>        class1_grp = main_data[main_data[col_name] == s[0]]<br/>        class2_grp = main_data[main_data[col_name] == s[1]]</span><span id="5fa3" class="ly lz iq lu b gy me mb l mc md">init_df = {"metric" : ['F1-Score'],<br/>                    "class1" : [s[0]] ,<br/>                    "class2" : [s[1]] ,<br/>                    "class1_score" : [round(f1_score(class1_grp[target], class1_grp[predicted_target]), 4)],<br/>                    "class2_score" : [round(f1_score(class2_grp[target], class2_grp[predicted_target]), 4)]}</span><span id="b232" class="ly lz iq lu b gy me mb l mc md">metric_df = pd.DataFrame(init_df, columns = ["metric", "class1", "class2", "class1_score", "class2_score"])</span><span id="295e" class="ly lz iq lu b gy me mb l mc md">metric_df["ratio"] = round(metric_df[["class1_score", "class2_score"]].min(axis = 1) <br/>                                 / metric_df[["class1_score", "class2_score"]].max(axis = 1), 4)<br/>        <br/>        metric_df["bias_score"] = round(abs(1-metric_df["ratio"]) * 100, 1)</span><span id="b8dc" class="ly lz iq lu b gy me mb l mc md">bias_df = pd.concat([bias_df, metric_df])<br/>        bias_score= max(bias_df["bias_score"])</span><span id="7f77" class="ly lz iq lu b gy me mb l mc md">return bias_df,bias_score</span><span id="eb6e" class="ly lz iq lu b gy me mb l mc md">#Call the function -<br/>bias_df,bias_score=bias_check(df, 'AGE', 'mevent','Label')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/6b4980ed116105b0bf9ba7c73097e28d.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*taubgAw9HvZlDAfnl2vMrg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">不同年龄段的F1得分</p></figure><p id="5b8b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从上表中可以看出，F1分数在不同年龄段之间并不十分接近——1类和2类代表不同的年龄段组合。在这里，我创建了3个年龄区间，然后检查这些区间的F1分数并进行比较。在此基础上，我们创建了一个偏差分数，即1类和2类F1分数之比。<br/>根据经验，最大偏差分数&lt; 10可被视为模型中无偏差，10–25可被视为需要更多调查，而&gt; 25可被视为模型中存在偏差。</p></div></div>    
</body>
</html>