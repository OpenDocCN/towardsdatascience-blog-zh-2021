<html>
<head>
<title>Implementing Generative Adversarial Networks (GANs) for Increasing a Convolutional Neural Network’s (CNN) Performance</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实现生成对抗网络以提高卷积神经网络的性能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-generative-adversarial-networks-gans-for-increasing-a-convolutional-neural-networks-f871e17fe271?source=collection_archive---------8-----------------------#2021-09-29">https://towardsdatascience.com/implementing-generative-adversarial-networks-gans-for-increasing-a-convolutional-neural-networks-f871e17fe271?source=collection_archive---------8-----------------------#2021-09-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/55fc7ea46f424c04b28611ee7403f45a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XvWSWzhMXLTbnLkm"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">布雷特·乔丹在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="88f9" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><strong class="ak">简介</strong></h1><p id="e23e" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">机器学习已经成为分析高级数据集和推断隐藏信息的最先进领域。出于各种原因，在机器学习中创建模型，例如用于分类或预测任务。具体来说，<a class="ae kf" href="https://arxiv.org/abs/1605.09081" rel="noopener ugc nofollow" target="_blank">卷积神经网络(CNN </a> s)在图像分析和特征提取方面显示出巨大的潜力。在图像上训练机器学习模型的一个问题是使用小的和缺乏多样性的数据集导致无效和不准确的模型。为了克服这个问题，可以在小数据集中扩充图像，以增加数据集的大小，并为要完成的任务创建更有效的模型。</p><p id="cfa6" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">有多种数据扩充技术可用于创建新样本来增加影像数据集的大小。这些技术包括裁剪、添加噪声、调整大小、翻转、旋转和改变图像的颜色。使用这些技术的一个缺点是没有向模型中引入“新”数据。模型已经在不同的状态下观察到这些样本(例如:将图像旋转45度向模型显示相同的图像，只是状态不同，其中状态是图像的角度)。虽然模型可以对不同州的相同样本进行分类很重要，但使用相同的数据可能不会对模型的概化能力产生很大影响。<strong class="lg iu"> <em class="mh">概化</em> </strong>是模型正确识别和理解未观测数据样本的能力<a class="ae kf" href="http://. Goodfellow,  Y. Bengio,  and A. Courville,Deep learning.MITpress, 2016" rel="noopener ugc nofollow" target="_blank">【1】</a>。</p><p id="5983" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">生成对抗网络(GANs)是一种数据增强技术，它产生<strong class="lg iu">新的</strong>数据样本。GANs从潜在空间获取随机噪声，并生成模拟原始数据集特征分布的独特图像。一个GAN在其架构中包含两个不同的网络，它们竞争实现纳什均衡(更多关于博弈论和什么是纳什均衡可以在<a class="ae kf" href="https://www.pnas.org/content/101/12/3999" rel="noopener ugc nofollow" target="_blank">这里</a>找到)。在这项研究中，GAN网络是根据<a class="ae kf" href="https://arxiv.org/abs/1511.06434" rel="noopener ugc nofollow" target="_blank"> DCGAN </a>和<a class="ae kf" href="https://arxiv.org/abs/1701.07875" rel="noopener ugc nofollow" target="_blank"> WGAN </a>建模的，它们使用卷积神经网络作为其两个竞争模型的框架。<a class="ae kf" href="https://arxiv.org/abs/1701.07875" rel="noopener ugc nofollow" target="_blank"> WGAN </a>使用与DCGAN类似的结构，但其损失函数采用Wasserstein-1距离，将鉴别器变成预测样本来自原始数据集的可能性的“评论家”。</p><p id="176e" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">GAN中的“鉴别器”的唯一目的是分析假样本和真样本，将每个样本标记为“假”或“真”真实样本的批次从原始数据集被馈送到鉴别器，而假样本来自生成器。顾名思义，“生成器”的目的是从潜在空间获取随机噪声作为输入，并生成“假”数据提供给鉴别器。生成器的目标是创建如此逼真的图像，以至于鉴别器认为它们是真实的。通过使用反向传播来随着时间的推移更新这些模型的权重和偏差，生成器将慢慢学会创建模拟原始数据集的物理和数学分布的样本。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><p id="dd3d" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">虽然GANs的实现涉及到大量的数学知识，但我只想提供一个基本的框架(提示！关于GANs的未来文章将更深入地讨论这一数学问题！)Goodfellow等人[3]在2014年概述了GAN的一般损失函数。</p><p id="4497" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">网络的损失函数是:</p><figure class="mq mr ms mt gt ju gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/4b33db74d52335574f93a2852aa5b55f.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*JXKSllPTUUb4QeAQIIfBWg.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">等式:GAN损失函数</p></figure><p id="9176" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">其中鉴别器希望最大化函数值，而生成器希望最小化函数值。<strong class="lg iu"><em class="mh">【x】</em></strong>是样本为“真”的概率<strong class="lg iu"> <em class="mh"> D(G(z)) </em> </strong>是样本为“假”的概率。'</p><p id="63b7" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">鉴频器的损失函数为:</p><figure class="mq mr ms mt gt ju gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/372504802d08cc3b7ec02ffa99eaeb8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:480/format:webp/1*-47ZIcTIDUUTJXVR9WK2yA.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">等式:鉴别器的损失函数</p></figure><p id="7c29" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">发电机的损耗函数为:</p><figure class="mq mr ms mt gt ju gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/7594d22b8a7e3287cba8fb6d63eb47ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:420/format:webp/1*nIH2nXi8-oGNu4W_GNArug.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">等式:发电机的损耗函数</p></figure><p id="9f31" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">后来改成了:</p><figure class="mq mr ms mt gt ju gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/9367d0e5c26eccc5180364adbcf6e29f.png" data-original-src="https://miro.medium.com/v2/resize:fit:310/format:webp/1*4FcvYnl4gPz0OZwpf7v2xg.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">等式:发电机的损耗函数</p></figure><p id="03d4" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">Goodfellow后来改变了发电机的损耗函数，以提高稳定性并克服饱和问题。虽然GAN由于不稳定性而有些难以训练(更多关于GAN不稳定性的信息<a class="ae kf" href="https://developers.google.com/machine-learning/gan/problems" rel="noopener ugc nofollow" target="_blank">此处</a>)，但是如果您能够用您的给定数据训练GAN，您就可以增加更接近原始数据集的数据，以及分类模型从未见过的数据，这对于提高模型的概化能力是必要的。这就是使用GANs优于其他数据增强技术的理由。我们能够成功地为数据创建新的样本，而不必亲自出去获取，并且我们可以确信，如果经过适当的训练，扩充的数据遵循原始数据的类似概率分布。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="d9fd" class="kg kh it bd ki kj mx kl km kn my kp kq kr mz kt ku kv na kx ky kz nb lb lc ld bi translated"><strong class="ak">数据集</strong></h1><p id="31c6" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">用于该分析的数据集是手写数字的<a class="ae kf" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST </a>数据集。在此分析中，使用了两种不同大小的数据集。一个称为“原始数据集”的数据集是MNIST的原始大小，有60，000个样本用于训练，10，000个样本用于测试。称为“缩减数据集”的第二个数据集是从MNIST中随机选择的3000幅图像用于训练数据集，10000幅图像用于测试数据集。</p><figure class="mq mr ms mt gt ju gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/66d8f8929423ada2d562d25071d018c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*gEp3KHGdxEEbpjh1m7bBSw.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">表:MNIST数据集中的类分布</p></figure><h1 id="8d85" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">预处理</h1><p id="b8db" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">由于分析主要是使用<a class="ae kf" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a> API进行的，灰度、28x28图像必须首先转换为NumPy数组。然后，这些数组被转换为“float32”格式，并除以255以进行像素缩放。</p><p id="012b" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu"> CNN分类模型</strong></p><figure class="mq mr ms mt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nd"><img src="../Images/e4ddd7fcd6196c89335719f583d94321.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pAdsEZm0EOD0hIOzHl6uOA.png"/></div></div></figure><p id="790a" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">创建了两个不同的模型，一个用于原始数据集，一个用于缩减后的数据集。如上所示，除了卷积层中的神经元数量之外，这些模型在架构上非常相似。在两次实验中，模型没有改变，以观察来自GAN的增强数据将如何影响现有架构。</p><h2 id="4801" class="ne kh it bd ki nf ng dn km nh ni dp kq lp nj nk ku lt nl nm ky lx nn no lc np bi translated"><strong class="ak">生成性对抗网络</strong></h2><p id="8c20" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我大部分的GAN学习来自Jason Brownlee的书<a class="ae kf" href="https://machinelearningmastery.com/generative_adversarial_networks/" rel="noopener ugc nofollow" target="_blank">Python中的生成对抗网络</a>。(强烈推荐！超级有帮助！).我还在Coursera上学习了<a class="ae kf" href="https://www.coursera.org/specializations/generative-adversarial-networks-gans" rel="noopener ugc nofollow" target="_blank">生成对抗网络专业化课程</a>，该课程真正深入理解了GANs的理论和实现。</p><p id="af5e" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">创建了两种不同类型的gan。创建的第一种GAN是<a class="ae kf" href="https://arxiv.org/abs/1411.1784" rel="noopener ugc nofollow" target="_blank">条件GAN (cGAN) </a>，创建的第二种GAN是<a class="ae kf" href="https://arxiv.org/abs/1701.07875" rel="noopener ugc nofollow" target="_blank"> Wasserstein GAN (WGAN) </a>。虽然这些网络背后的数学公式超出了本文的范围，但我还是想介绍两种GAN框架之间的一些一般差异。使用的两种gan都以类别标签(0-9)为条件。</p><figure class="mq mr ms mt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nq"><img src="../Images/9e09f88e82c7a0d5deb98c4835c5d056.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YhdMIJZxgejGVGL6dGf9_Q.png"/></div></div></figure><h2 id="063e" class="ne kh it bd ki nf ng dn km nh ni dp kq lp nj nk ku lt nl nm ky lx nn no lc np bi translated">弗雷歇初始距离</h2><p id="8cb8" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">扩充数据的一个困难是评估数据的质量。这里的“质量”是指合成数据与原始数据集的相似程度，以及原始数据集与扩充数据集相比的概率分布的相似程度。一种用于量化图像“质量”的测量评估是弗雷歇初始距离得分度量。</p><figure class="mq mr ms mt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nr"><img src="../Images/fb28004c86cf5c2d16a904212f6438d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NF0ZFV-fc5_wyrwaSmvo1A@2x.jpeg"/></div></div></figure><p id="267d" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">FID分数比较从Inception V3模型获得的两个图像集激活的平均值和协方差。使用这种度量的一个警告是，比较的图片数量较少可能导致来自相同或相似分布的数据集的初始得分不太重要。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="1d32" class="kg kh it bd ki kj mx kl km kn my kp kq kr mz kt ku kv na kx ky kz nb lb lc ld bi translated"><strong class="ak">实验</strong></h1><p id="5639" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">进行了两个实验来分析如何通过使用用于图像数据扩充的GAN来影响模型的性能。</p><h2 id="abf7" class="ne kh it bd ki nf ng dn km nh ni dp kq lp nj nk ku lt nl nm ky lx nn no lc np bi translated"><strong class="ak">实验1:使用没有扩充数据的两个不同大小的数据集来训练CNN。</strong></h2><figure class="mq mr ms mt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ns"><img src="../Images/9b5585e332571e8efe8f0e377610e641.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cc3LfNiKSlzaUBy2T6dvAw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图:没有增加数据的两个不同模型的精确度和损失</p></figure><p id="a0d7" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">虽然可以为MNIST创建更好的模型，但目标是获得两个没有机器学习模型训练中出现的<a class="ae kf" href="https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">过拟合/欠拟合</a>问题的模型。如您所见，原始MNIST数据集达到了99.26%的准确率，较小的数据集达到了92.63%的准确率。较小的数据集也有更多的损失，这是意料之中的，因为用有限的数据量训练模型通常要困难得多(这也是我们使用数据扩充技术的原因之一！)</p><h2 id="cb25" class="ne kh it bd ki nf ng dn km nh ni dp kq lp nj nk ku lt nl nm ky lx nn no lc np bi translated">实验2:使用没有扩充数据的两个不同大小的数据集来训练CNN。</h2><p id="c144" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="lg iu">扩充数据</strong></p><p id="7ce8" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">如前所述，使用两种不同类型的天然气水合物来扩充数据。一旦数据被扩充，图像和标签就被添加到原始数据集中。在整个研究过程中，cGAN和WGAN数据从未合并到任何数据集中。以下是来自“0”类的两个合成样本，由每个GANs生成。</p><figure class="mq mr ms mt gt ju gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/9876ca574c3f8c98dfca8908b56a2f00.png" data-original-src="https://miro.medium.com/v2/resize:fit:156/format:webp/1*UKuWE5dYTqSyzvLqKaPDxg.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图:由cGAN生成的“0”</p></figure><figure class="mq mr ms mt gt ju gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/f031dbf3607afb092c7c77e5320ce13d.png" data-original-src="https://miro.medium.com/v2/resize:fit:122/format:webp/1*l3Tch1il9I6wVFEnZNjHLA.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图:WGAN生成的“0”</p></figure><p id="0cb6" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我能够成功地训练一个cGAN 100个纪元，但是，我无法让我的WGAN在Google Colab上完全训练有限的GPU空间(我已经订阅了一个Pro帐户！).</p><p id="93f2" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">弗雷歇初始距离得分</strong></p><p id="67b1" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">由于Google Colab的内存有限，我只能分析来自两个不同GANSs的多达5000张图像的FID分数。我的目标是观察100张图片和5000张图片相比，分数是否有下降的趋势(分数越低越好)。</p><figure class="mq mr ms mt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nv"><img src="../Images/5f63372dc447e6cd3be092d2df0c0cea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6RuxRm1RGrQQvN7CBJsQWg.png"/></div></div></figure><p id="5a69" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">如您所见，FID分数随着时间的推移从100张图像下降到5000张图像。虽然FID分数有些高，但随着我们添加更多图像，看到这种下降趋势，证明这些图像适合用于重新训练用于MNIST数据分类的CNN模型，特别是在添加10，000张图像时。</p><p id="b830" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">模特培训</strong></p><figure class="mq mr ms mt gt ju gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/6fa66c35b38e1e3bea64034628df6d28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*s8iiaPrxUK-lVOYxDREvqA.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图:附加cGAN样本的数据集的重新训练模型的准确性和损失</p></figure><p id="2f54" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">使用cGAN，原始数据集在准确性方面没有太大变化(增加了0.19%)。损失也几乎不受影响(培训下降1.23%，验证下降1.96%)。重要的是，GAN的使用并没有减损<strong class="lg iu"> <em class="mh">型号的性能。</em></strong>GAN的使用显示了<strong class="lg iu">小数据集的巨大</strong>改进。该模型实现了97.72%的准确率(提高了5.09%)，并显示了损失指标的巨大改善(训练损失减少了13.16%，验证损失减少了15.19%)。</p><figure class="mq mr ms mt gt ju gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/2e43ffb8abd5bd9d3d5dcddbe45774e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*DJFRSkAdhcYyickLGgTkmw.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图:附加了WGAN样本的数据集的重新训练模型的准确性和损失</p></figure><p id="bd3b" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">对于WGAN，原始模型并没有真正改变(类似于使用从cGAN扩充的数据所发生的情况)。该模型的损失指标仍有所下降，但准确性停滞不前，几乎没有提高。对于缩减的数据集模型，实现的准确度为98.00%(增加5.37%)，而损失再次降低(训练损失降低14.48%，验证损失降低10.72%)。</p><p id="36d9" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">使用由两个不同的gan生成的数据，然后添加到数据集的结果表明，gan确实有助于实现模型性能的大幅提高！正如您所看到的，较小的数据集对其大小的增加更敏感，并且他们的模型被认为从CNN训练中GAN的使用中获得了最大的积极影响。</p><h2 id="ed52" class="ne kh it bd ki nf ng dn km nh ni dp kq lp nj nk ku lt nl nm ky lx nn no lc np bi translated"><strong class="ak"><em class="ny">k</em>-褶皱分析</strong></h2><p id="fcda" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在重新训练模型之后，进行了<em class="mh">k</em>-折叠分析，以查看新训练的模型在不同折叠级别上的表现。对于这个分析，我选择了5个折叠，然而，有许多程序可以找到最佳数量的<em class="mh"> k </em>值。(一般行业标准是5或10)。结果是<em class="mh"> k </em>倍非常令人惊讶，实际上显示了与cGAN数据混合的数据集在准确性上的更大提高和模型损失的减少。</p><figure class="mq mr ms mt gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nz"><img src="../Images/4b4525caa63e946af053dd27735d9cc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iUgI8BAjuODfnZLbwbU49w.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">表:k倍分析的结果</p></figure><p id="2655" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><em class="mh"> k </em> -Folds分析反映了先前的观察结果，即增强图像对原始大小的数据集没有巨大影响。对于较小的训练集，<em class="mh">k</em>-折叠显示了与扩充数据相结合的数据集在准确性和损失方面的重大改进</p><h1 id="c325" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><strong class="ak">结论</strong></h1><p id="95fd" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">生成式对抗网络是一种强大的数据增强技术，它可以产生具有增强的概化能力的健壮模型。cGAN显示出比WGAN更有效地改进更大的数据集。cGAN高效的原因可能是它创建了一个更加多样化的图像集，并且能够针对整整100个时代进行训练。在研究的初始试验中，WGAN对于训练较小的数据集更有效，但是通过倍分析表明，WGAN对模型的影响小于cGAN。这一观察解释了GANs在其训练过程中通常产生更多时期的更高质量图像的重要性。使用GANs进行数据扩充可以提高模型精度，减少模型损失，同时克服过度拟合和欠拟合，支持其用于提高模型的概化能力。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><p id="cb8d" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">请在<a class="ae kf" href="https://www.linkedin.com/in/benjamin-mccloskey-169975a8/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上加我或者随时联系！</p><p id="a049" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">其他来源</strong></p><ol class=""><li id="0a08" class="oa ob it lg b lh mc ll md lp oc lt od lx oe mb of og oh oi bi translated">。古德费勒，y .本吉奥，和a .库维尔，深度学习。MITpress，2016年</li><li id="7de2" class="oa ob it lg b lh oj ll ok lp ol lt om lx on mb of og oh oi bi translated">重新思考电脑视觉的盗梦空间架构。<em class="mh">IEEE计算机视觉和模式识别会议论文集</em>。2016.</li><li id="e4db" class="oa ob it lg b lh oj ll ok lp ol lt om lx on mb of og oh oi bi translated">伊恩·古德菲勒、让·普吉-阿巴迪、迈赫迪·米尔扎、徐炳、戴维·沃德-法利、谢尔吉尔·奥泽尔、亚伦·库维尔和约舒阿·本吉奥。生成对抗性网络。神经信息处理系统进展，27，2014</li></ol></div></div>    
</body>
</html>