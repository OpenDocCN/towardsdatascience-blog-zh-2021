<html>
<head>
<title>Multivariate Timeseries Forecast with Lead and Lag Timesteps Using LSTM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于LSTM的超前滞后时间步长多元时间序列预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multivariate-timeseries-forecast-with-lead-and-lag-timesteps-using-lstm-1a34915f08a?source=collection_archive---------10-----------------------#2021-05-16">https://towardsdatascience.com/multivariate-timeseries-forecast-with-lead-and-lag-timesteps-using-lstm-1a34915f08a?source=collection_archive---------10-----------------------#2021-05-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/></div><div class="ab cl jn jo hu jp" role="separator"><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js jt"/><span class="jq bw bk jr js"/></div><div class="ij ik il im in"><p id="956e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">为什么是多元变量，它如何帮助做出更好的预测</strong>？</p><p id="1de6" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">时间序列预测在大多数行业的决策中起着至关重要的作用。例如，预测运输公司要购买的集装箱数量可以为公司节省数百万美元。同样，预测特定产品类型的需求在定价中扮演着非常重要的角色，因此也是电子商务公司盈利的关键。</p><p id="baf3" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在大多数情况下，是企业或运营团队知道影响需求或供应的因素。简单地根据历史模式进行预测并不总是能得到想要的结果，或者并没有考虑到未来的前景。过去的错误有可能在未来的预测中重复。考虑影响因素并让团队有能力研究和理解它们对预测的影响总是好的。</p><p id="03f6" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这就是多元时间序列预测出现的时候。让我们用下面的图片来理解多元预测</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ks"><img src="../Images/bcadd7f6c9abe632c9f914408fe7d0f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ouXxMJk8qg4HuKfL2qMM0w.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">图1:具有滞后数据的多元时间序列预测(滞后=5步)</p></figure><p id="d516" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">图1描述了因变量Y在时间t的多变量时间序列预测，滞后=5。红色单元格是时间t时的预测值，该值取决于黄色单元格中的值(t-5到t)。这些是影响预测Y at t的独立变量。</p><p id="e0a8" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们可以将多元时间序列视为回归问题，其中独立变量是前一个滞后(直到t-1)的特征，以及时间t的独立值。使用这种方法，对预测的控制远远超过了对前一个时间戳的控制。</p><p id="d3c6" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">下面是多元时间序列，它也考虑了铅值</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi li"><img src="../Images/8b124825b0c7c9bda29d26575fd45851.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JYzuRVZVWNRidCWeukDzFA.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">图2:具有超前和滞后特征的多元时间序列</p></figure><p id="70f9" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">从上图我们可以看出，除了滞后特性，lead=2 (t+2)时间步长也被认为是进行预测的时间步长。这使我们能够更好地控制影响预测的因素。在许多情况下，我们知道一些未来的因素也会影响我们当前的时间预测。通过这些方法，决策团队可以真正根据独立要素的各种输入值来模拟预测。</p><p id="60ad" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">利用LSTM实现预测模型</strong></p><p id="f750" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">现在让我们看看如何实现具有超前和滞后特性的多元时间序列。</p><ol class=""><li id="e75d" class="lj lk iq jw b jx jy kb kc kf ll kj lm kn ln kr lo lp lq lr bi translated">用提前和滞后因子准备好数据</li></ol><p id="0ac1" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">使用LSTM对时间序列执行回归任务的主要区别在于，在时间序列中，需要考虑超前和滞后时间戳数据。让我们定义一个函数，它可以基于作为参数的超前和滞后来做这件事</p><pre class="kt ku kv kw gt ls lt lu lv aw lw bi"><span id="4e05" class="lx ly iq lt b gy lz ma l mb mc"># convert series to supervised learning<br/>def series_to_supervised(data, n_lag=1, n_lead=1, dropnan=True):<br/> n_vars = 1 if type(data) is list else data.shape[1]<br/> df = DataFrame(data)<br/> cols, names = list(), list()<br/> # input sequence (t-n, … t-1)<br/> for i in range(n_lag, 0, -1):<br/> cols.append(df.shift(i))<br/> names += [(‘var%d(t-%d)’ % (j+1, i)) for j in range(n_vars)]<br/> # forecast sequence (t, t+1, … t+n)<br/> for i in range(0, n_lead):<br/> cols.append(df.shift(-i))<br/> if i == 0:<br/> names += [(‘var%d(t)’ % (j+1)) for j in range(n_vars)]<br/> else:<br/> names += [(‘var%d(t+%d)’ % (j+1, i)) for j in range(n_vars)]<br/> # put it all together<br/> agg = concat(cols, axis=1)<br/> agg.columns = names<br/> # drop rows with NaN values<br/> if dropnan:<br/> agg.dropna(inplace=True)<br/> return agg</span></pre><p id="b72d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">上面的函数将数据转换成带有定制的n_lag和n_lead步骤的时间序列。该函数的输出包含滞后和超前步骤的数据，作为具有(t-n)或(t+n)时间戳的列</p><pre class="kt ku kv kw gt ls lt lu lv aw lw bi"><span id="e3db" class="lx ly iq lt b gy lz ma l mb mc">reframed = series_to_supervised(values, n_lag, (n_lead+1))</span><span id="cc14" class="lx ly iq lt b gy md ma l mb mc">#removing the future (t+n) dependent variable (Y)</span><span id="bc7d" class="lx ly iq lt b gy md ma l mb mc">if n_lead&gt;0:<br/>  reframed= reframed.drop(reframed.iloc[:,[i for i in range(df_no.shape[1]*(n_lag+1),reframed.shape[1],df_no.shape[1])]],axis=1)</span></pre><p id="a453" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">上述代码有助于在训练模型时删除未来的Y(t+n)。一旦我们放弃了未来的Y，我们有了重构的数据，这就像训练LSTM回归问题一样简单。</p><pre class="kt ku kv kw gt ls lt lu lv aw lw bi"><span id="9505" class="lx ly iq lt b gy lz ma l mb mc"># splitting reframed to X and Y considering the first column to be out target feature</span><span id="8baf" class="lx ly iq lt b gy md ma l mb mc">X=reframed.drop(['var1(t)'],axis=1)<br/>Y=reframed['var1(t)']</span><span id="c4cd" class="lx ly iq lt b gy md ma l mb mc">X_values=X.values<br/>Y_values=Y.values</span><span id="e815" class="lx ly iq lt b gy md ma l mb mc">#n_preduct being the test length</span><span id="ac3b" class="lx ly iq lt b gy md ma l mb mc">train_X,train_Y = X_values[:(X_values.shape[0]-n_predict),:],Y_values[:(X_values.shape[0]-n_predict)]<br/>test_X,test_Y = X_values[(X_values.shape[0]-n_predict):,:],Y_values[(X_values.shape[0]-n_predict):]</span><span id="f477" class="lx ly iq lt b gy md ma l mb mc">#reshaping train and test to feed to LSTM<br/>train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))<br/>test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))</span></pre><p id="2614" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">创建一个简单的LSTM模型</p><pre class="kt ku kv kw gt ls lt lu lv aw lw bi"><span id="99ff" class="lx ly iq lt b gy lz ma l mb mc">opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.01)<br/>model = Sequential()<br/>model.add(LSTM(100,return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))<br/>model.add(Dropout(0.25))<br/>model.add(LSTM(units=50,return_sequences=True))<br/>model.add(Dropout(0.20))<br/>model.add(LSTM(units=10,return_sequences=False))<br/>model.add(Dense(units=1, activation='linear'))<br/>model.compile(loss='mae', optimizer=opt)</span></pre><p id="8f34" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">一旦模型准备就绪，我们就可以根据训练数据训练模型，并在测试中对其进行测试。下面的代码显示了一些训练检查点，可以用来帮助训练一个好的模型。</p><pre class="kt ku kv kw gt ls lt lu lv aw lw bi"><span id="101d" class="lx ly iq lt b gy lz ma l mb mc">#adding few model check points<br/>es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)<br/>  rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=10, verbose=1)<br/>  mcp = ModelCheckpoint(filepath="/test.h5", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)<br/>  tb = TensorBoard('logs')</span><span id="7249" class="lx ly iq lt b gy md ma l mb mc">history = model.fit(train_X, train_Y, epochs=50, batch_size=10,callbacks=[mcp,rlr],validation_data=(test_X, test_Y), verbose=2, shuffle=False)</span></pre><p id="2496" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">一旦模型被训练，我们就可以得到测试数据的预测</p><pre class="kt ku kv kw gt ls lt lu lv aw lw bi"><span id="80a8" class="lx ly iq lt b gy lz ma l mb mc">yhat = model.predict(test_X)</span></pre><p id="f664" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">总结</strong></p><p id="e72a" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在本文中，我们看到了什么是多元时间序列，以及如何使用超前和滞后数据进行预测。使用这种方法时，需要注意以下几点</p><ol class=""><li id="1ad1" class="lj lk iq jw b jx jy kb kc kf ll kj lm kn ln kr lo lp lq lr bi translated">随着n_lead和n_lag的增加，特定预测的特征数量也会增加。例如，如果我们在每个时间戳有5个独立的特征，并且我们认为n_lag=5并且n_lead =2，那么重构后的所有特征将是5+5*(n_lag)+5*(n_lead)，这是40个特征的情况。</li><li id="6612" class="lj lk iq jw b jx me kb mf kf mg kj mh kn mi kr lo lp lq lr bi translated">需要大量的训练数据，因为使用滞后和超前会减少训练行数。</li><li id="8b37" class="lj lk iq jw b jx me kb mf kf mg kj mh kn mi kr lo lp lq lr bi translated">每次我们改变n_lead和n_lag时，随着特征数量的增加或减少，必须明智地考虑LSTM模型结构以避免过度拟合。</li></ol></div></div>    
</body>
</html>