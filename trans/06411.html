<html>
<head>
<title>Hacking HP Tuning to perform Automatic Model Selection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">黑掉惠普调优来执行自动型号选择</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hacking-hp-tuning-to-perform-automatic-model-selection-ef11d4c08ea2?source=collection_archive---------41-----------------------#2021-06-08">https://towardsdatascience.com/hacking-hp-tuning-to-perform-automatic-model-selection-ef11d4c08ea2?source=collection_archive---------41-----------------------#2021-06-08</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><div class=""/><figure class="gl gn jt ju jv jw gh gi paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="gh gi js"><img src="../Images/e6de370e378a3ca81911aeefd538e5dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DCyJLBkjXUo24qcb"/></div></div><p class="kd ke gj gh gi kf kg bd b be z dk translated">瓦伦丁·彼得科夫在<a class="ae kh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="7999" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">超参数调整的任务是选择与目标相关的最佳模型配置。我们在之前的<a class="ae kh" rel="noopener" target="_blank" href="/automl-for-fast-hyperparameters-tuning-with-smac-4d70b1399ce6">帖子</a>中已经看到，尽管这看起来是一项具有挑战性的任务，但是当使用基于模型的方法时，编码并不困难。</p><p id="a1dc" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">但是等等！如果惠普调优可以为给定的ML任务选择最佳参数，我们是否可以重用它来选择最佳模型？也就是说，是否有可能创建一种方法，像使用其他参数一样使用模型类型作为参数，并让超级参数优化为我们选择正确的参数？</p><p id="c46c" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">这难道不是解决ML问题的巨大加速吗？答案不仅是肯定的是的！而且，实现起来也不是很复杂。</p><p id="dabd" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">我们将在本文中详细探讨这一点。</p></div><div class="ab cl lg lh hz li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="io ip iq ir is"><h1 id="29d5" class="ln lo iv bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">基于型号的惠普调整快速提醒</h1><p id="0386" class="pw-post-body-paragraph ki kj iv kk b kl ml kn ko kp mm kr ks kt mn kv kw kx mo kz la lb mp ld le lf io bi translated">超参数调整(HPT，有时也称为HPO超参数优化)的目标是找到最大化或最小化给定目标的配置。有各种方法来执行超参数调整:蛮力，随机搜索，贝叶斯搜索，或基于模型的方法。</p><p id="43fe" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">我以前提倡使用基于模型的方法，这在我遇到的一些问题上证明是非常有效的。你可以在这里找到更多关于<a class="ae kh" href="https://automl.github.io/SMAC3/master/index.html" rel="noopener ugc nofollow" target="_blank"> SMAC </a>的细节，这是一个高效的HPO图书馆:</p><div class="mq mr gp gr ms mt"><a rel="noopener follow" target="_blank" href="/automl-for-fast-hyperparameters-tuning-with-smac-4d70b1399ce6"><div class="mu ab fo"><div class="mv ab mw cl cj mx"><h2 class="bd iw gy z fp my fr fs mz fu fw iu bi translated">用SMAC进行快速超参数调整的AutoML</h2><div class="na l"><h3 class="bd b gy z fp my fr fs mz fu fw dk translated">使用AutoML在高维空间中寻找你的路径</h3></div><div class="nb l"><p class="bd b dl z fp my fr fs mz fu fw dk translated">towardsdatascience.com</p></div></div><div class="nc l"><div class="nd l ne nf ng nc nh kb mt"/></div></div></a></div><p id="cb04" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">您可能也有兴趣更好地理解这些方法是如何工作的，并构建自己的超参数优化库。</p><p id="594d" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">这里有一个有趣的方法，利用你对XGBoost、CatBoost或RandomForest等标准模型的了解:</p><div class="mq mr gp gr ms mt"><a rel="noopener follow" target="_blank" href="/tuning-xgboost-with-xgboost-writing-your-own-hyper-parameters-optimization-engine-a593498b5fba"><div class="mu ab fo"><div class="mv ab mw cl cj mx"><h2 class="bd iw gy z fp my fr fs mz fu fw iu bi translated">用XGBoost调优XGBoost:编写自己的Hyper Parameters优化引擎</h2><div class="nb l"><p class="bd b dl z fp my fr fs mz fu fw dk translated">towardsdatascience.com</p></div></div><div class="nc l"><div class="ni l ne nf ng nc nh kb mt"/></div></div></a></div><p id="893a" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">除了令人兴奋之外(使用ML模型来调整ML模型)，基于模型的超参数优化提供了一个优于其他解决方案的非常有趣的优势:它支持分类参数。这意味着我们可以将模型类型编码为分类参数。</p><p id="1546" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">也就是说，让我们看看如何破解标准的超参数调整来执行模型选择和加速模型构建。</p><h1 id="4182" class="ln lo iv bd lp lq nj ls lt lu nk lw lx ly nl ma mb mc nm me mf mg nn mi mj mk bi translated">超级模型</h1><p id="5ef6" class="pw-post-body-paragraph ki kj iv kk b kl ml kn ko kp mm kr ks kt mn kv kw kx mo kz la lb mp ld le lf io bi translated">正如介绍中所提到的，这次黑客攻击背后的想法是这样的:我们能否像其他任何一个参数一样，将<em class="no"> model_type </em>(即XGBoost，Prophet，S/ARIMA……)视为一个参数，并让Hyper Parameter Tuning方法为我们完成这项工作？</p><p id="64a2" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">令人高兴的是，如上所述，使用基于模型的方法的超参数优化支持分类参数。毕竟，他们的底层模型通常是一个增强的(或者不是)决策树。</p><p id="d928" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">这个属性的一个直接结果是，我们可以创建一个<strong class="kk iw"> <em class="no">超级模型</em> </strong>，它将由<em class="no">模型类型</em>以及其他参数来定义。<em class="no"> model_type </em>将对用于训练的底层模型进行编码。在python中，这给出了:</p><figure class="np nq nr ns gt jw"><div class="bz fp l di"><div class="nt nu l"/></div><p class="kd ke gj gh gi kf kg bd b be z dk translated">一个超级模型，它将底层模型类型作为一个参数。作者代码。</p></figure><p id="e533" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">超模型的实现遵循scikit-learn模型接口，即它提供了<em class="no"> fit、predict、set_params </em>和<em class="no"> get_params </em>方法。为了简单起见，我们只支持两个模型:XGBoost和RandomForest，但是再增加一个只会多几行。例如，您应该尝试一下SVR。</p><p id="140c" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">您可能已经注意到，我们使用白名单来只保留那些适用于给定模型的参数。这不是支持参数因模型而异这一事实的最佳方式。正确的做法是使用条件配置。ConfigSpace python库支持这一点，但scikit并不支持这一点。</p><p id="f67d" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">使用我们的新类进行训练和预测是立竿见影的。假设我们想使用XGBoost作为底层模型。这给出了:</p><figure class="np nq nr ns gt jw"><div class="bz fp l di"><div class="nt nu l"/></div><p class="kd ke gj gh gi kf kg bd b be z dk translated">用我们的超模。作者代码。</p></figure><p id="9c12" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">我们现在要做的就是在HPT/HPO步骤中使用这个模型，并让它选择最佳候选模型类型。</p><h1 id="da10" class="ln lo iv bd lp lq nj ls lt lu nk lw lx ly nl ma mb mc nm me mf mg nn mi mj mk bi translated">寻找最佳模型</h1><p id="9701" class="pw-post-body-paragraph ki kj iv kk b kl ml kn ko kp mm kr ks kt mn kv kw kx mo kz la lb mp ld le lf io bi translated">有了主参数是模型类型的超级模型，我们可以使用标准的超级参数调整方法来识别最佳模型。</p><p id="6b58" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">需要记住的重要一点是，绝对没有“最佳模式”。当我写“最佳模型”时，我指的是给定分数的最佳模型。在本文中，我们将使用平均绝对误差作为得分。</p><p id="7687" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">尽管在我之前的两篇关于这个主题的文章中，我一直在使用(并建议)SMAC或一个定制的超参数优化实现来执行HP调优，但在本文中，我们将尝试另一种方法。不要错过尝试新事物的机会:)</p><p id="5fed" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">这一次，我们将使用BayesSearchCV来探索配置空间。贝叶斯搜索的基本原理是使用高斯过程建立一个代理模型，估计模型得分。</p><p id="b92f" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">每个新的训练更新代理模型的后验知识。然后为这个代理提供随机挑选的配置，给出最佳分数的配置被保留用于训练。</p><p id="6de3" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">因为它使用高斯过程模型来学习超参数和候选模型的分数之间的关系，所以它可以被认为是基于模型的方法。</p><p id="71de" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">将所有这些放在一起会产生以下代码行:</p><figure class="np nq nr ns gt jw"><div class="bz fp l di"><div class="nt nu l"/></div><p class="kd ke gj gh gi kf kg bd b be z dk translated">使用我们的超级模型来确定波士顿数据集的最佳模式。作者的代码。</p></figure><p id="a91e" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">配置空间主要使用参数的均匀分布来定义。这意味着在给定范围内选择一个值的概率在任何地方都是相同的。例如，<em class="no"> max_features </em>、<em class="no"> n_estimators </em>或<em class="no"> max_depth </em>就是这种情况。相反，跨越多个数量级的<em class="no"> gamma </em>和<em class="no"> learning_rate </em>使用<em class="no">对数均匀分布</em>选取。</p><p id="55a3" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">运行这段代码将向您展示XGBoost似乎是这个数据集的最佳选择。</p><h1 id="fbb9" class="ln lo iv bd lp lq nj ls lt lu nk lw lx ly nl ma mb mc nm me mf mg nn mi mj mk bi translated">检查</h1><p id="ee70" class="pw-post-body-paragraph ki kj iv kk b kl ml kn ko kp mm kr ks kt mn kv kw kx mo kz la lb mp ld le lf io bi translated">像我一样，你可能不相信一个算法的结果，在执行一些检查之前。</p><p id="9a79" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">幸运的是，许多其他数据科学家已经研究了波士顿数据集挑战。更具体地说，在Kaggle <a class="ae kh" href="https://www.kaggle.com/shreayan98c/boston-house-price-prediction" rel="noopener ugc nofollow" target="_blank">这里</a>由<a class="ae kh" href="https://www.kaggle.com/shreayan98c" rel="noopener ugc nofollow" target="_blank"> Shreayan Chaudhary </a>研究过，他得出了与我们的算法相同的结论。这是好消息。</p><p id="4860" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">然而，我们再谨慎也不为过。让我们执行另一个简单的检查，以确保如果我们对HP Tuning exploration进行更多迭代，并且只针对随机森林进行优化，RandomForest不会优于XGBoost:</p><figure class="np nq nr ns gt jw"><div class="bz fp l di"><div class="nt nu l"/></div><p class="kd ke gj gh gi kf kg bd b be z dk translated">这次调优单一模型:RandomForestRegressor。作者代码。</p></figure><p id="a964" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">我们简单地重用了我们的超模型，但是这一次我们强制将探索集中在一个模型上:RandomForestRegressor。我们也允许更多的迭代:随机森林50次，而以前两个模型都是50次。</p><p id="96dd" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">结论是一样的。就平均绝对误差而言，XGboost精度保持得更好:随机森林为2.68，而XGBoost为2.57。</p><p id="4d90" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">我们也可能是“幸运的”，XGBoost优于RandomForestRegressor的事实可能完全是随机的，并且与用于初始化贝叶斯搜索的初始种子相关:<em class="no"> random_state=0。</em></p><p id="e104" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">使用各种<em class="no"> random_states </em>多次运行代码应该会让你相信我们并不幸运，在这种情况下，XGBoost是关于我们选择的分数的最佳选项:平均绝对误差。</p><h1 id="01b8" class="ln lo iv bd lp lq nj ls lt lu nk lw lx ly nl ma mb mc nm me mf mg nn mi mj mk bi translated">我们的自动模型选择丢弃坏选项的速度有多快？</h1><p id="b545" class="pw-post-body-paragraph ki kj iv kk b kl ml kn ko kp mm kr ks kt mn kv kw kx mo kz la lb mp ld le lf io bi translated">另一个要考虑的非常有趣的方面是我们的模型选择丢弃跛脚鸭的速度。为了说明这一点，我们将向超模型支持的模型列表中添加另一个模型:LinearRegression。</p><p id="e12d" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">直觉上，这是最糟糕的选择。让我们看看我们的自动模型选择花了多少时间来探索这种可能性。首先，我们将它添加到超模:</p><figure class="np nq nr ns gt jw"><div class="bz fp l di"><div class="nt nu l"/></div><p class="kd ke gj gh gi kf kg bd b be z dk translated">向超级模型添加LinearRegression。作者代码</p></figure><p id="325e" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">我们将使用一个肮脏的黑客来测量探索一个给定配置所花费的时间。我们只在第42行打印它(信不信由你)，并对它执行一些greps，得到以下统计数据:</p><ul class=""><li id="8785" class="nv nw iv kk b kl km kp kq kt nx kx ny lb nz lf oa ob oc od bi translated">线性回归研究了3次。</li><li id="c498" class="nv nw iv kk b kl oe kp of kt og kx oh lb oi lf oa ob oc od bi translated">随机森林17次。</li><li id="3b8d" class="nv nw iv kk b kl oe kp of kt og kx oh lb oi lf oa ob oc od bi translated">XGBoost 30次。</li></ul><p id="7d79" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">值得注意的是，在仅仅50次迭代中，我们的模型选择已经学会关注最有前途的模型:XGBoost，并且在仅仅3次迭代中就放弃了线性回归。</p><p id="8448" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">如果我们使用ConfigSpace的条件配置，而不是使用允许参数的白名单，我们可以更快地排除线性回归。这就人为增加了不必要的审判。</p><h1 id="29dd" class="ln lo iv bd lp lq nj ls lt lu nk lw lx ly nl ma mb mc nm me mf mg nn mi mj mk bi translated">结论</h1><p id="4515" class="pw-post-body-paragraph ki kj iv kk b kl ml kn ko kp mm kr ks kt mn kv kw kx mo kz la lb mp ld le lf io bi translated">扩展模型选择的超参数调整。用几行代码演示它非常容易。</p><p id="132f" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">我们一直使用贝叶斯搜索来探索配置空间，但我们也可以使用任何其他有效的超参数调整方法。</p><p id="7d58" class="pw-post-body-paragraph ki kj iv kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf io bi translated">另一个值得尝试的想法是使用超参数优化方法进行特征选择。很有可能它也能有效工作。</p></div></div>    
</body>
</html>