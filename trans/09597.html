<html>
<head>
<title>Future-Proof Your Data Partitions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向未来的数据分区</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/future-proof-your-data-partitions-d2047de9ead2?source=collection_archive---------32-----------------------#2021-09-06">https://towardsdatascience.com/future-proof-your-data-partitions-d2047de9ead2?source=collection_archive---------32-----------------------#2021-09-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/9f2b4e892e21dabd464b110ed90566ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gdw4PJ-bJPbPyrq6CM9v0w.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">照片由<a class="ae jd" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae jd" href="https://unsplash.com/@ijazrafi?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Ijaz Rafi </a>拍摄</p></figure><div class=""/><div class=""><h2 id="89e5" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated"><strong class="ak"> <em class="kv">数据分区和机器中的幽灵</em> </strong></h2></div><p id="1f2b" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将数据分成训练分区和测试分区是改进我们预测的重要一步。对一些数据进行建模，并通过对剩余样本的预测来测试该模型，这就是我们如何理解和补偿偏差和方差，这是机器学习的一个中心困境。</p><p id="87ae" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用Python拆分数据非常容易，scikit-learn中有train_test_split函数。除了指定训练样本(或测试样本)的大小，如果这是一个分类问题，是否对响应变量进行分层是您最需要的。剩下的工作就是设置random_state值，该值以随机的方式决定哪些行进行训练，哪些行进行测试。</p><p id="5a5f" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">过去，对于随机种子值，我使用:</p><ol class=""><li id="2ace" class="ls lt jg ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">42(向道格拉斯·亚当斯致敬)</li><li id="a0c6" class="ls lt jg ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">451(雷·布雷德伯里)</li><li id="66e2" class="ls lt jg ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">2001年、2010年和2061年(亚瑟·C·克拉克)</li><li id="3621" class="ls lt jg ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">314159(仅在圆周率日)</li><li id="bd26" class="ls lt jg ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">我最常见的随机种子= 1</li></ol><p id="6272" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个想法是，无论随机种子输入如何，分割数据都会导致训练和测试之间的值的类似分布，但我已经错误地这样做了相当长一段时间。</p><p id="70f4" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的机器(学习)里有个鬼，叫方差。</p><p id="2680" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky jh"> <em class="mg">偏差&amp;方差</em> </strong></p><p id="194b" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但在我们带上捉鬼敢死队的质子包来对付这个幽灵之前，让我们先来看看偏差和方差的数学基础，找出前进的道路。对于随机变量X的给定值，测试数据的预期残值(通常表示为均方误差)可以分解为三个要素:1)方差，2)偏差的平方，以及3)残差的方差(James，Witten，Hastie，&amp; Tibshirani，2013)。更多细节见图1。</p><figure class="mi mj mk ml gt is gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/f3ed381ac2e55ceb645c1fcb7c38db3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*zrm0CMPsJssS2YduwnBybQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图1:均方误差分解</p></figure><p id="f0ec" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">方差本身是一个随机函数，无论学习算法如何，它都会给每个预测模型增加一定程度的不确定性，我们可以利用这种随机性来构建更稳健的模型。为了实现这一飞跃，让我们考察一个解释方差的不同方程(Abu-Mostafa，Magdon-Ismail，&amp; Lin，2012)。更多详情请参见图2:</p><figure class="mi mj mk ml gt is gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/abcf09fa4c30a44a66e77ddc7a6312c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*qAWPXbZljJ49z3YHngjTXQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图2:方差还原</p></figure><p id="0d6f" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种概念化中，学习模型“g”作用于无限数量的数据集上的随机变量X的预期残差值需要从所有估计值的平均值中减去估计预测值，这就是我们的解决方案！</p><p id="a8b9" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们可以根据方差的平均值分割数据集，这既是数据也是特定于模型的，我们就可以提高模型对未来数据必然包含的偏差的稳健性。<strong class="ky jh">类似方差均值的训练和测试分区可以降低方差本身的整体效应</strong>。</p><p id="429b" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但这主要是一个概念工具，因为它意味着通过在无限数量的数据集上重复估计学习函数来收集预期残差，并且对于每个随机x。<strong class="ky jh">但还有另一种方法来使用这一概念，即通过模拟同一数据集的随机偏差的许多数据集。</strong>通过构建测试准确度/训练准确度比率作为度量，并迭代训练/测试分裂的随机种子值，我们可以可视化学习模型的不稳定性(Abu-Mostafa等人，2012年)，因为它们与特定数据集相关；这是检验方差的一种局部方法。一个纯理论的概念可以成为业务分析建模模板中重要的新步骤。</p><p id="cd8e" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky jh"> <em class="mg">求方差均值</em> </strong></p><p id="8c9b" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">方差是特定于模型的，包含可减少和不可减少的误差，因此任何可视化这种随机函数的尝试都应该使用预期的建模算法。图3展示了IBM HR Analytics员工流失和绩效二进制分类数据集200次迭代的方差均值和曲线图，该数据集采用了交叉验证的逻辑回归模型，您可以看到均值分割如何减少方差的振幅波动，以及如何缩小不同时间的偏差范围。数据预处理是最少的(丢弃低信息变量和一次性编码分类变量),并且不需要调整，因为我们不寻求准确性，而是所有预测模型中存在的不稳定性，所以使用默认的超参数设置是预期的。</p><figure class="mi mj mk ml gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mn"><img src="../Images/c53f6f88a8670cc9031aa25c30a301f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0LpVp955jyusj6g-Bs0_Yw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图3:方差图和平均值计算</p></figure><p id="21e8" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">代码块1和2显示了如何使用f1_score作为精度度量来实现二进制分类。200个模型的使用是任意的；选择它是为了在运行时和捕获全范围的方差之间取得平衡，其中最大的峰值出现在这个数据集+模型的random_state = 125以上。</p><pre class="mi mj mk ml gt mo mp mq mr aw ms bi"><span id="bd49" class="mt mu jg mp b gy mv mw l mx my"># Code Block 1</span><span id="95ac" class="mt mu jg mp b gy mz mw l mx my">from sklearn.linear_model import LogisticRegressionCV</span><span id="b85a" class="mt mu jg mp b gy mz mw l mx my">model = LogisticRegressionCV(random_state=1, max_iter=5000)<br/>size = 0.5</span></pre></div><div class="ab cl na nb hu nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="ij ik il im in"><pre class="mo mp mq mr aw ms bi"><span id="c721" class="mt mu jg mp b gy nh ni nj nk nl mw l mx my"># Code Block 2</span><span id="e8cf" class="mt mu jg mp b gy mz mw l mx my">import numpy as np<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import f1_score, balanced_accuracy_score, precision_score, recall_score<br/>import matplotlib.pyplot as plt</span><span id="149c" class="mt mu jg mp b gy mz mw l mx my">Var = []</span><span id="b667" class="mt mu jg mp b gy mz mw l mx my">for i in range(1, 200):<br/>    train_X, test_X, train_y, test_y = train_test_split(X, y,<br/>test_size = size, stratify=y, random_state = i)<br/>    model.fit(train_X, train_y)<br/>    train_pred = model.predict(train_X)<br/>    test_pred = model.predict(test_X)<br/>    train_error = f1_score(train_y, train_pred)<br/>    test_error = f1_score(test_y, test_pred)<br/>    variance = test_error/train_error<br/>    Var.append(variance)<br/>    <br/>rs_value = np.average(Var)</span><span id="ab8d" class="mt mu jg mp b gy mz mw l mx my">def find_nearest(array, value):<br/>    array = np.asarray(array)<br/>    idx = (np.abs(array - value)).argmin()<br/>    return array[idx]</span><span id="df04" class="mt mu jg mp b gy mz mw l mx my">nearest = find_nearest(Var, rs_value)</span><span id="bc5f" class="mt mu jg mp b gy mz mw l mx my">print('random_state = ', Var.index(nearest))</span></pre><figure class="mi mj mk ml gt is gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/9993cb320d71ec490c5b59dc206182db.png" data-original-src="https://miro.medium.com/v2/resize:fit:406/format:webp/1*jbcI-OUKhYrs-EAhMtuDTQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">方差均值分割的随机种子值</p></figure><pre class="mi mj mk ml gt mo mp mq mr aw ms bi"><span id="8962" class="mt mu jg mp b gy mv mw l mx my"># Code Block 3 for plotting the variance graph</span><span id="ca29" class="mt mu jg mp b gy mz mw l mx my">plt.figure(figsize=(10,8))</span><span id="b032" class="mt mu jg mp b gy mz mw l mx my">plt.plot(range(1, 200), Var, color='royalblue', label="Variance")<br/>plt.plot([0, 200], [rs_value, rs_value], color='darkorange', linewidth=3)<br/>plt.text(0,rs_value, rs_value, fontsize=15, color='black')</span><span id="43d6" class="mt mu jg mp b gy mz mw l mx my">plt.legend(loc='lower center', shadow=True, fontsize='medium')<br/>plt.show()</span></pre><p id="fb6f" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为回归模型更改此代码是一个简单的转换:从数据分区中删除“分层=y ”,并更改误差度量(例如，均方误差、平均绝对误差等。).代码块1设置建模算法和测试大小，而代码块2收集方差信息，计算其均值，并找到与方差均值最接近的随机状态值，以对训练/测试分割进行编程。代码块3绘制了方差及其均值。</p><p id="ceed" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于这种方法是否会导致信息泄露还有一个问题，但是我们没有使用测试预测的性能来改变模型拟合。相反，我们使用来自多个模型的元数据来发现方差均值，并根据该值调整初始数据分区。尽管如此，这是一个讨论的话题。</p><p id="b387" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，尽管需要更多的一次性计算资源，但根据方差的平均值分割数据应该会产生更强大的模型，在新的未来数据到来时，这些模型将保持更好的准确性。</p><p id="ea0a" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky jh">参考文献</strong></p><p id="4c2a" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Abu-Mostafa，Y. S .、Magdon-Ismail，m .、和Lin，H.-T. (2012年)。<em class="mg">从数据中学习</em>(第四卷)。美国纽约AMLBook:</p><p id="eb07" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">詹姆斯，g .，威滕，d .，哈斯蒂，t .，，蒂布拉尼，R. (2013)。<em class="mg">统计学习概论</em>(第112卷)。斯普林格。</p></div></div>    
</body>
</html>