<html>
<head>
<title>Basics of few-shot learning with optimization-based meta-learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于优化的元学习的少量学习基础</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/basics-of-few-shot-learning-with-optimization-based-meta-learning-e6e9ffd4775a?source=collection_archive---------16-----------------------#2021-08-07">https://towardsdatascience.com/basics-of-few-shot-learning-with-optimization-based-meta-learning-e6e9ffd4775a?source=collection_archive---------16-----------------------#2021-08-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b5d2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">基于优化的元学习中MAML、FOMAML和爬虫方法背后的机制概述</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/39ff86cf92082b2f9515acc374c914fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3BUtAclqS58rD-P3"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">凯利·西克玛在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="5e08" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">元学习方法可以大致分为基于度量、基于优化和基于模型的方法。在这篇文章中，我们将主要关注基于优化的元学习方法背后的数学。</p><p id="43df" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">术语。</em>元学习模型用元训练数据集(用一组任务<em class="ls"> τ </em> = { <em class="ls"> τ </em> ₁、<em class="ls"> τ </em> ₂、<em class="ls"> τ </em> ₃、…})训练，用元测试数据集(任务<em class="ls"> τₜₛ </em>)测试。每个任务<em class="ls"> τᵢ </em>由任务训练集(即支持集)<em class="ls">dᵢ</em>ᵗʳ<em class="ls">t21】和任务测试集(即查询集)<em class="ls"> Dᵢ </em> ᵗˢ.组成元学习问题的一种类型是<em class="ls">N</em>-way<em class="ls">k</em>-shot learning，其中我们在<em class="ls"> N </em>个类之间进行选择，并利用每个类的<em class="ls"> k </em>个示例进行学习。</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/2cb9edbff9ad452fe69cfcec5afb3430.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/0*AuGzBVZqwpGJyYd4.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">双向单次示例的元训练、元测试、支持和查询数据集的图示。图片作者。</p></figure><h1 id="f2e4" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">迁移学习(微调)</h1><p id="066a" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">在继续讨论元学习之前，我们将简要提及另一种常用的方法——通过微调转移学习，以<em class="ls">将知识</em>从基础模型(例如，通过识别许多不同的对象构建)转移到新任务(例如，专门识别狗)。这里的想法是建立在一般任务上预先训练的模型，并在新的特定任务上微调该模型(通过仅更新神经网络中有限的层集合和/或以较慢的学习速率)。我们将在这一节复习数学术语，这样我们就可以与后面要讨论的元学习进行比较和对比。</p><p id="f561" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在微调设置中，我们将首先导出在<em class="ls"> D </em> ᵖʳᵉ-ᵗʳ上预训练的一组优化的参数<em class="ls"> θ </em> ᵖʳᵉ-ᵗʳ，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/c42f995c64916e7a0f44133b91ec6e91.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*0VR0y6xFLOvzoqa8ZXDdbg.png"/></div></figure><p id="fd1e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在微调过程中，我们将调整使训练集<em class="ls"> D </em> ᵗʳ损失最小的参数，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/842e41ff3ac30e722e1476cc9cfff8f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*DYZs_vMMjYidqnh31mP5lQ.png"/></div></figure><p id="2cb9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该等式示出了一个梯度步骤，但是实际上这是通过多个梯度步骤来优化的。作为示例，下面显示了参数空间中从预训练参数值<em class="ls"> θ </em> ᵖʳᵉ-ᵗʳ到微调参数值<em class="ls"> θ </em>的路径。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/c868890b140c5b02da95f926fbddd4e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/0*2c0xE1l0PsfK_BhQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">微调。图片作者。</p></figure><p id="8e7f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在通过微调的迁移学习中，希望基础模型已经学习了基本模式(如形状、对比度、图像中的物体)，微调可以更快更容易地适应新的任务。然而，这种方法并不是专门围绕着<em class="ls">学习</em>而设计的。新任务可能不会与基本任务重叠，从而导致知识的<em class="ls">转移</em>性能不佳。另一方面，元学习是明确围绕构建任务和算法进行设计的，以便进行一般化的学习。</p><h1 id="6b3d" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">MAML</h1><p id="d27c" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">模型不可知元学习(MAML)是由Finn等人在2017年提出的。这是一种基于优化的元学习方法。其思想是，我们不是寻找对给定的训练数据集或经过微调的训练集有用的参数，而是寻找经过微调后可推广到其他测试集的最佳参数。</p><p id="4c1e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">为了一个任务。</strong>对于给定的任务，我们将首先在微调步骤中使用支持训练数据集<em class="ls"> D </em> ᵗʳ。<em class="ls"> D </em> ᵗʳ的最佳参数<em class="ls"> ϕ </em>为，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/6d4b67cd1aeaf14e3dee33c3cbd6bdf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*cPYXIdPPCyEkMNRmvvFrOw.png"/></div></figure><p id="5554" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">不同于微调(我们将在此停止)，我们想要计算这个最优参数<em class="ls"> ϕ </em>在查询测试数据集<em class="ls"> D </em> ᵗˢ上的表现，损失函数为<em class="ls"> L </em> ( <em class="ls"> ϕ </em>，<em class="ls"> D </em> ᵗˢ).目标是优化初始参数<em class="ls"> θ </em>,使其在给定微调的情况下在查询测试集上表现良好。换句话说，我们在元训练步骤中更新<em class="ls"> θ </em>,</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/f2852aa396e2246839ce1c7807fa5a82.png" data-original-src="https://miro.medium.com/v2/resize:fit:472/format:webp/1*Oj8XT1rzDn64o3164MJHsA.png"/></div></figure><p id="e3e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里我们需要计算∇_θ <em class="ls"> L </em> ( <em class="ls"> ϕ </em>，<em class="ls"> D </em> ᵗˢ)，它是损失函数关于<em class="ls"> θ </em>的导数。</p><p id="94be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以如下说明参数空间中的路径，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/ff1ec2ec0f421cf29059b598c57e6e09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/0*z2UBqR-AJXIuC4tg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">MAML负责一项任务。图片作者。</p></figure><p id="1e65" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，我们不是在微调步骤直接更新<em class="ls"> θ </em>，而是根据支持训练和测试数据集(灰色路径)判断最佳参数的方向，并在元训练步骤中更新<em class="ls"> θ </em>。</p><p id="9c1c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">用于任务集。不仅仅是一个任务，为了对各种任务进行归纳，我们可以通过对一组任务进行平均来执行每一步的元学习<em class="ls"> τ </em> = { <em class="ls"> τ </em> ₁，<em class="ls"> τ </em> ₂，<em class="ls"> τ </em> ₃，…}。因此支撑组任务<em class="ls"> τᵢ </em>的最佳参数<em class="ls"> ϕᵢ </em>为:</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/6fe0d3c5915e85db69abd214727ea615.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*GdVegHV8LP5NrfQGAsDfiw.png"/></div></figure><p id="23ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">元训练步骤是，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi my"><img src="../Images/f7411636cf9c82aafeb1e62f8c19da2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*Q3zRKKyJ0xJSGvhR6PhyKQ.png"/></div></figure><p id="1c5e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">术语∇_<em class="ls">θ</em>l(<em class="ls">ϕ</em>ᵢ，<em class="ls"> Dᵢ </em> ᵗˢ)$可以进一步展开。下面我们将省略下标<em class="ls"> i </em>，但是这种讨论适用于每个任务。对于链式法则，该术语可以表示为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/0b483401fc6f024cace96bdb201d7274.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*MIagy_NBl3AeMIdmzGjq6g.png"/></div></figure><p id="0d9c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以扩展早期的路径视觉效果，以包含多项任务，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/2d31af68cbea46fd8c7fd529980a1c3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/0*NyLzDP8wS4hfET3F.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">多重任务的MAML。图片作者。</p></figure><p id="8b1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，我们对每个任务的最佳参数的方向性有所了解(用不同的颜色)，并根据任务的平均值更新<em class="ls"> θ </em>(黑色路径)。</p><h1 id="d2b2" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">一阶MAML</h1><p id="a891" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">在MAML元学习步骤中，我们需要计算海森矩阵。作为替代，在一阶MAML (FOMAML)中，可以通过将∇_<em class="ls">θ</em>T4】l(<em class="ls">θ</em>，<em class="ls"> D </em> ᵗʳ)视为常数并因此忽略二阶导数项来使用一阶近似。这意味着我们将项∇_ <em class="ls"> θ ϕ </em>视为单位矩阵<em class="ls"> I </em>，从而得到:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/4d3400843123188796fa45ef3d02deb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*7gQeCov_pu1OkPn1hl5gLQ.png"/></div></figure><p id="0e6e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这可以直观地说明如下，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/e011b97af9895250ba958cfbabe2c548.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/0*1y_cXBhss9LiBhZC.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">一级MAML。图片作者。</p></figure><p id="f829" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意，我们不是通过在计算图中一路展开来执行元梯度计算，而是使用一阶近似∇_<em class="ls">ϕ</em>t16】l(<em class="ls">ϕ</em>，<em class="ls"> D </em> ᵗˢ)作为更新<em class="ls"> θ </em>的梯度。</p><h1 id="67db" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">爬行动物</h1><p id="4464" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">爬行动物(OpenAI)是一种替代方法，其性能与MAML相当，但在计算和存储方面比MAML更有效，因为没有二阶导数的显式计算。</p><p id="eb9a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我们将引入一个更新函数<em class="ls"> Uᵏ </em>，它只是MAML中微调步骤的一个重新表述(和推广),</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/339023a1dcd937cbd7b8f416ca3e92cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:346/format:webp/1*EwpPjMmIbBU22HnsoUcjZA.png"/></div></figure><p id="cc40" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中<em class="ls"> k </em>是<em class="ls"> ϕ </em>更新的次数。</p><p id="398a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于爬虫，在每次迭代中，1)任务<em class="ls"> τᵢ </em>被采样，2)在<em class="ls"> k </em>更新后，计算<em class="ls"> τᵢ </em>的最优参数<em class="ls"> ϕᵢ </em>，以及3)模型参数<em class="ls"> θ </em>被更新为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/1350d6494e2f77f9c1616c295cf1cbc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:396/format:webp/1*sXOYowCrwMyEblwhvKJckA.png"/></div></figure><p id="fe1a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">不是每个迭代一个任务，而是可以评估多个任务，产生如下的批处理版本，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/502ae25ac468ac96ad5b2e5fb9b1058b.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*DwZhg3IYY_eviqjhYLhOcg.png"/></div></figure><p id="ce4c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在哪里</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/d478dbc10db82ead6c4e63c4827c3d48.png" data-original-src="https://miro.medium.com/v2/resize:fit:336/format:webp/1*FNTutSqWHqnp7DgwT3b2CQ.png"/></div></figure><p id="efc5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">参数路径可以被示意性地可视化为，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/d1cd378a88b888ce8bb1e2cfc773d4bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/0*WPjpcE-IRWK5upj4.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">爬行动物。图片作者。</p></figure><p id="3253" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将爬行动物与不同任务间平均的规则随机梯度下降区分开来的关键区别是对<em class="ls"> ϕᵢ </em>在<em class="ls">k</em>t60】1步上的估计，并使用<em class="ls">ϕᵢ</em>θ作为更新<em class="ls"> θ </em>的梯度。在标准随机梯度下降中，在每个梯度步骤之后更新参数(<em class="ls"> U </em>，其中<em class="ls"> k </em> =1)。作者Nichol等人已经表明，当<em class="ls"> k </em> &gt; 1时，这允许算法拾取高阶导数，并且随之而来的行为类似于MAML，并且与<em class="ls"> k </em> =1时明显不同。</p><h1 id="b918" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">资源</h1><ul class=""><li id="81df" class="nh ni iq ky b kz mm lc mn lf nj lj nk ln nl lr nm nn no np bi translated"><a class="ae kv" href="https://cs330.stanford.edu/#topics" rel="noopener ugc nofollow" target="_blank">芬恩(2020) CS330讲座</a></li><li id="dab0" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated"><a class="ae kv" href="https://meta-learning.fastforwardlabs.com/" rel="noopener ugc nofollow" target="_blank">快速前进研究(2020)元学习</a></li><li id="126e" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/paper-repro-deep-metalearning-using-maml-and-reptile-fd1df1cc81b0"> Ecoffet (2018)博客文章</a></li><li id="e5fa" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated">【翁(2018)博文</li><li id="0aeb" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated"><a class="ae kv" href="https://openai.com/blog/reptile/" rel="noopener ugc nofollow" target="_blank">尼科尔&amp;舒尔曼(2018) OpenAI博客文章</a></li></ul><h1 id="0e84" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">参考</h1><ol class=""><li id="dc65" class="nh ni iq ky b kz mm lc mn lf nj lj nk ln nl lr nv nn no np bi translated">模型不可知的元学习，用于深度网络的快速适应。<em class="ls"> ICML </em> 2017。<a class="ae kv" href="https://arxiv.org/abs/1703.03400" rel="noopener ugc nofollow" target="_blank"> arXiv </a></li><li id="dc92" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nv nn no np bi translated">一阶元学习算法。<em class="ls"> arXiv </em> 2018。<a class="ae kv" href="https://arxiv.org/abs/1803.02999" rel="noopener ugc nofollow" target="_blank"> arXiv </a></li></ol></div><div class="ab cl nw nx hu ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="ij ik il im in"><p id="c532" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">原载于2021年8月7日</em><a class="ae kv" href="https://boyangzhao.github.io/posts/few_shot_learning" rel="noopener ugc nofollow" target="_blank"><em class="ls">https://boyangzhao . github . io</em></a><em class="ls">。</em></p></div></div>    
</body>
</html>