<html>
<head>
<title>Custom datasets in Pytorch — Part 2. Text (Machine Translation)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pytorch中的自定义数据集—第2部分。文本(机器翻译)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/custom-datasets-in-pytorch-part-2-text-machine-translation-71c41a3e994e?source=collection_archive---------5-----------------------#2021-09-22">https://towardsdatascience.com/custom-datasets-in-pytorch-part-2-text-machine-translation-71c41a3e994e?source=collection_archive---------5-----------------------#2021-09-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/a01eb48389ccd8578a2b39547a2a1b4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tcTN_Lzl7HNaBvQl"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><a class="ae kc" href="https://unsplash.com/@pickawood?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">皮卡伍德</a>在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="8d64" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本系列的<a class="ae kc" rel="noopener" target="_blank" href="/custom-dataset-in-pytorch-part-1-images-2df3152895">第一部分</a>中，我们学习了加载自定义图像数据集。在那篇文章中，我们还介绍了Pytorch中数据集和数据加载器的一些基本功能。我建议先浏览一下那篇文章，但是我们也会在这篇文章中为NLP的人们介绍一些基础知识。在本演练中，我们将介绍如何为机器翻译加载自定义数据集，并使其为模型做好准备。本演练的代码也可以在<a class="ae kc" href="https://github.com/UtkarshGarg-UG/Deep-Learning-Projects/blob/main/NLP/Custom%20Dataset/loading%20custom%20dataset%20(text).ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。</p><p id="9055" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用<a class="ae kc" href="https://www.kaggle.com/aiswaryaramachandran/hindienglish-corpora/kernels" rel="noopener ugc nofollow" target="_blank">英语-印地语</a>语言数据集。数据集如下所示:</p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lb"><img src="../Images/ab7f01ac4933d1d25d7c044ee8547dd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IyUhyJwa4yYlEOx-9-AvoQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图一。数据集(来源:作者图片)</p></figure><h1 id="4e5a" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">让我们编码</h1><h2 id="e40f" class="me lh iq bd li mf mg dn lm mh mi dp lq ko mj mk lu ks ml mm ly kw mn mo mc mp bi translated">1.导入库</h2><p id="c45e" class="pw-post-body-paragraph kd ke iq kf b kg mq ki kj kk mr km kn ko ms kq kr ks mt ku kv kw mu ky kz la ij bi translated">首先，我们导入必要的库。除了这些库，我们还导入了<a class="ae kc" href="https://pypi.org/project/pandarallel/" rel="noopener ugc nofollow" target="_blank">panda parallel</a>。这个库使得我们的apply函数可以利用我们所有的CPU线程并行运行，从而使进程快如闪电。</p><figure class="lc ld le lf gt jr"><div class="bz fp l di"><div class="mv mw l"/></div></figure><h2 id="5367" class="me lh iq bd li mf mg dn lm mh mi dp lq ko mj mk lu ks ml mm ly kw mn mo mc mp bi translated">2.加载数据和预处理</h2><p id="fc4a" class="pw-post-body-paragraph kd ke iq kf b kg mq ki kj kk mr km kn ko ms kq kr ks mt ku kv kw mu ky kz la ij bi translated">接下来，我们加载数据并进行一些基本的预处理，以清理数据并为自定义数据集管道做好准备。</p><figure class="lc ld le lf gt jr"><div class="bz fp l di"><div class="mv mw l"/></div></figure><h2 id="3513" class="me lh iq bd li mf mg dn lm mh mi dp lq ko mj mk lu ks ml mm ly kw mn mo mc mp bi translated">3.创建训练集和验证集</h2><p id="81d4" class="pw-post-body-paragraph kd ke iq kf b kg mq ki kj kk mr km kn ko ms kq kr ks mt ku kv kw mu ky kz la ij bi translated">接下来，我们创建训练集和有效集。我们将仅基于训练数据来创建词汇表。我们将把有效集视为拒绝集。</p><figure class="lc ld le lf gt jr"><div class="bz fp l di"><div class="mv mw l"/></div></figure><pre class="lc ld le lf gt mx my mz na aw nb bi"><span id="d518" class="me lh iq my b gy nc nd l ne nf">output: <br/>len of train:  112343<br/>len of val:  12482</span></pre><p id="4392" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在有了火车和有效的数据帧。接下来，我们为这些数据帧创建Pytorch数据集和数据加载器。</p><h2 id="da0c" class="me lh iq bd li mf mg dn lm mh mi dp lq ko mj mk lu ks ml mm ly kw mn mo mc mp bi translated">4.创建Pytorch数据集</h2><p id="7039" class="pw-post-body-paragraph kd ke iq kf b kg mq ki kj kk mr km kn ko ms kq kr ks mt ku kv kw mu ky kz la ij bi translated">我们将分两部分创建PyTorch Train_Dataset:</p><ol class=""><li id="6563" class="ng nh iq kf b kg kh kk kl ko ni ks nj kw nk la nl nm nn no bi translated">建立词汇课</li><li id="acc6" class="ng nh iq kf b kg np kk nq ko nr ks ns kw nt la nl nm nn no bi translated">构建训练数据集</li></ol><h2 id="d14c" class="me lh iq bd li mf mg dn lm mh mi dp lq ko mj mk lu ks ml mm ly kw mn mo mc mp bi translated">4.1词汇</h2><p id="333d" class="pw-post-body-paragraph kd ke iq kf b kg mq ki kj kk mr km kn ko ms kq kr ks mt ku kv kw mu ky kz la ij bi translated">在创建Train_Dataset之前，我们需要定义一个构建词汇表的过程。为此，</p><ol class=""><li id="1456" class="ng nh iq kf b kg kh kk kl ko ni ks nj kw nk la nl nm nn no bi translated">我们将创建一个“词汇”类，它将只使用我们之前创建的训练数据帧来创建单词到索引和索引到单词的映射</li><li id="db9c" class="ng nh iq kf b kg np kk nq ko nr ks ns kw nt la nl nm nn no bi translated">同样,“词汇”类返回数据帧中每个句子的数字版本。例如:['我'，'爱'，'苹果']--&gt;[23，54，1220]。我们需要将单词转换成数字，因为模型希望我们词汇表中的每个单词都用一个数字来表示</li></ol><p id="fb04" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了更好地理解代码，已经对代码进行了注释(代码有点冗长，但不要放弃！这非常简单)</p><figure class="lc ld le lf gt jr"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="321f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我希望代码足够清晰，可以遵循。如果没有，请在评论中联系我们。让我们测试这个类。我们将为几个句子创建一个虚拟词汇。</p><figure class="lc ld le lf gt jr"><div class="bz fp l di"><div class="mv mw l"/></div></figure><pre class="lc ld le lf gt mx my mz na aw nb bi"><span id="1ab5" class="me lh iq my b gy nc nd l ne nf">output:<br/>index to string:  {0: '&lt;PAD&gt;', 1: '&lt;SOS&gt;', 2: '&lt;EOS&gt;', 3: '&lt;UNK&gt;', 4: 'that', 5: 'is', 6: 'a', 7: 'cat', 8: 'not', 9: 'dog'}</span><span id="2801" class="me lh iq my b gy nu nd l ne nf">string to index: {'&lt;PAD&gt;': 0, '&lt;SOS&gt;': 1, '&lt;EOS&gt;': 2, '&lt;UNK&gt;': 3, 'that': 4, 'is': 5, 'a': 6, 'cat': 7, 'not': 8, 'dog': 9}</span><span id="5f71" class="me lh iq my b gy nu nd l ne nf">numericalize -&gt; cat and a dog:  [7, 3, 6, 9]</span></pre><p id="74c9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们得到两个(索引-单词和单词-索引)映射。同样，我们可以把一个新句子转换成它的数字格式。注意‘and’的值是3，它对应于<unk>(又名unknown)令牌，因为它不在我们的vocab中。另外，请注意，我们将在下一节中向Train_Dataset类中的数字化文本添加开始和结束标记。</unk></p><h2 id="aa45" class="me lh iq bd li mf mg dn lm mh mi dp lq ko mj mk lu ks ml mm ly kw mn mo mc mp bi translated">4.2训练数据集</h2><p id="9926" class="pw-post-body-paragraph kd ke iq kf b kg mq ki kj kk mr km kn ko ms kq kr ks mt ku kv kw mu ky kz la ij bi translated">酷！我们有积累词汇的渠道。让我们创建Train_Dataset。</p><p id="2676" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们在第1部分中讨论的，PyTorch的这个数据集类是我们定制数据集的核心。数据集类的结构如下所示:</p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/0ac66893706e4ce833f0849552ec2094.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/0*-pAuUR20of3ZyPeT.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图二。数据集类(来源:作者图片)</p></figure><p id="94e5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们通过继承Dataset类来创建Train_Dataset类:</p><pre class="lc ld le lf gt mx my mz na aw nb bi"><span id="3384" class="me lh iq my b gy nc nd l ne nf">from torch.utils.data import Dataset</span></pre><p id="e7c5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于Train_Dataset类，</p><ol class=""><li id="e8cc" class="ng nh iq kf b kg kh kk kl ko ni ks nj kw nk la nl nm nn no bi translated">我们首先继承PyTorch的Dataset类。</li><li id="27db" class="ng nh iq kf b kg np kk nq ko nr ks ns kw nt la nl nm nn no bi translated">然后，我们为训练数据帧中的源列和目标列初始化并构建vocabs。</li><li id="3439" class="ng nh iq kf b kg np kk nq ko nr ks ns kw nt la nl nm nn no bi translated">然后，我们使用getitem()方法为数据加载器(一个批量加载数据的函数)一次对一个文本示例进行数值化。在接下来的章节中会有更多的介绍)。</li></ol><figure class="lc ld le lf gt jr"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="3863" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们了解一下，一旦创建了Train_Dataset类的实例，将会发生什么。我们一创建实例，就会运行__init__方法，并创建词汇类的两个对象——source _ vocab和target_vocab。我们将能够通过这些实例访问各自的vocab映射和数值化方法。从上面可以看出，__getitem__需要一个索引。这是由数据加载器自动处理的，对于<strong class="kf ir">，批处理中的每个</strong>示例都运行__getitem__。在我们的代码中，__getitem__在连接开始和结束标记后，返回特定索引处给定示例的数字化源和目标(因此一次一个示例)。</p><p id="c739" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们测试上面的代码。</p><figure class="lc ld le lf gt jr"><div class="bz fp l di"><div class="mv mw l"/></div></figure><pre class="lc ld le lf gt mx my mz na aw nb bi"><span id="ea9d" class="me lh iq my b gy nc nd l ne nf">output:</span><span id="68cd" class="me lh iq my b gy nu nd l ne nf">english_sentence    narrowed or blocked arteries are bypassed by t...<br/>hindi_sentence      संकुचित हो गयी या अवरोधित धमनियों को टाँग से ल...</span><span id="3fd7" class="me lh iq my b gy nu nd l ne nf">(tensor([   1,    3,   24, 8001, 5987,   17,    3,   20,    4,  151,    5,    9,<br/>         7360,    5,    3,  256,   23,    4, 1826,   27,   10, 1120,    7,    4,<br/>            3,   31,   39,  189,    6,    7,    4,    3, 7360,  918,    4, 2794,<br/>           16,    4,   52,    2]),<br/> tensor([   1, 6701,   25,  162,   31,    3, 4979,   11,    3,    9,   19,  112,<br/>            3,    4, 3555,   10,  169,   23,    3,   23,   51,   42,    3,    4,<br/>           20, 3555,    4,   13, 3598,   11,    3,    9,    8,  174, 3598,   11,<br/>         4980,    4,  338, 1821,   51,   42,    6,    2]))</span></pre><p id="e1a6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">酷！我们得到了源句子和目标句子的索引。</p><h2 id="3d54" class="me lh iq bd li mf mg dn lm mh mi dp lq ko mj mk lu ks ml mm ly kw mn mo mc mp bi translated">4.3.创建验证数据集类</h2><p id="6d6d" class="pw-post-body-paragraph kd ke iq kf b kg mq ki kj kk mr km kn ko ms kq kr ks mt ku kv kw mu ky kz la ij bi translated">我们为验证创建一个单独的数据集类。为了获得验证数据框的数字文本，我们将重用训练的词汇表(因为我们将验证集视为不可见集，因此无法访问它的词汇表)。更好的做法是为验证定义一个单独的类。我们将把train_dataset实例和其他东西传递给Valid_Dataset类，以访问train_dataset源和目标词汇表。</p><figure class="lc ld le lf gt jr"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="90f1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们有了train和valid datasets对象。接下来，我们必须创建数据加载器来批量加载数据。</p><h2 id="0456" class="me lh iq bd li mf mg dn lm mh mi dp lq ko mj mk lu ks ml mm ly kw mn mo mc mp bi translated">5.创建数据加载器</h2><p id="05cc" class="pw-post-body-paragraph kd ke iq kf b kg mq ki kj kk mr km kn ko ms kq kr ks mt ku kv kw mu ky kz la ij bi translated">首先，我们了解一下校对。该函数在使用数据加载器创建批处理后运行。在我们的应用程序中，我们使用这个函数为批处理中的句子创建填充。为此，我们使用torch.nn.utils.rnn中的“pad_sequence”。它在我们的批处理中选择最大的句子，并将所有其他句子填充到这个长度。我们这样做是因为模型期望一个正方形矩阵，即每个示例在一批中应该是等长的。</p><figure class="lc ld le lf gt jr"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="f140" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在定义数据加载器时，我们使用上面的函数作为参数。</p><figure class="lc ld le lf gt jr"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="1003" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看看数据加载器的结果。我们创建一个迭代器，得到大小为32的源和目标批处理的元组。</p><figure class="lc ld le lf gt jr"><div class="bz fp l di"><div class="mv mw l"/></div></figure><pre class="lc ld le lf gt mx my mz na aw nb bi"><span id="9f78" class="me lh iq my b gy nc nd l ne nf">output:<br/>source: <br/> tensor([[   1,    1,    1,  ...,    1,    1,    1],<br/>        [4125,  420,   37,  ...,   46,   95, 5406],<br/>        [  91,   32,   17,  ..., 1407,   53,   17],<br/>        ...,<br/>        [   0,    0,    0,  ...,    0,    0,    0],<br/>        [   0,    0,    0,  ...,    0,    0,    0],<br/>        [   0,    0,    0,  ...,    0,    0,    0]])</span><span id="00e3" class="me lh iq my b gy nu nd l ne nf">source shape:  torch.Size([64, 32])<br/>target shape:  torch.Size([44, 32])</span></pre><p id="7360" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在上面的张量数组中有一个句子是垂直排列的。我们可以看到0是句子的填充。而44是目标批次中最长的句子。</p><p id="20ce" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就是这样！现在，数据已经准备好用于我们的模型了！</p><p id="7dcc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在PyTorch中加载自定义数据集感觉很多。但是这个管道为我们提供了为任何类型的数据集或问题陈述加载和创建模型就绪数据加载器的灵活性。</p><h1 id="6ad5" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">结论</h1><p id="fc1e" class="pw-post-body-paragraph kd ke iq kf b kg mq ki kj kk mr km kn ko ms kq kr ks mt ku kv kw mu ky kz la ij bi translated">在这个由两部分组成的系列的第2部分中，我们看到了如何编写自定义的机器翻译数据管道。尽管本演练是为机器翻译任务编写的，但同样的概念也可以转移到从广泛的应用程序领域加载多模式数据。这个演练的代码可以在我的<a class="ae kc" href="https://github.com/UtkarshGarg-UG/Deep-Learning-Projects/blob/main/NLP/Custom%20Dataset/loading%20custom%20dataset%20(text).ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。</p><p id="a709" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">喜欢吗？给一个👏 😄并关注更多！</p><h1 id="5a96" class="lg lh iq bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">有关系的</h1><div class="nw nx gp gr ny nz"><a rel="noopener follow" target="_blank" href="/custom-dataset-in-pytorch-part-1-images-2df3152895"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd ir gy z fp oe fr fs of fu fw ip bi translated">Pytorch中的自定义数据集—第1部分。形象</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">Pytorch有一个很好的生态系统来加载定制数据集，用于训练机器学习模型。这是…的第一部分</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">towardsdatascience.com</p></div></div><div class="oi l"><div class="oj l ok ol om oi on jw nz"/></div></div></a></div><div class="nw nx gp gr ny nz"><a rel="noopener follow" target="_blank" href="/visualizing-context-with-googles-universal-sentence-encoder-and-graphdb-c5f92b2f3db3"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd ir gy z fp oe fr fs of fu fw ip bi translated">使用Google的通用句子编码器和GraphDB可视化上下文</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">Neo4j中的句子嵌入和图形连接</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">towardsdatascience.com</p></div></div><div class="oi l"><div class="oo l ok ol om oi on jw nz"/></div></div></a></div></div></div>    
</body>
</html>