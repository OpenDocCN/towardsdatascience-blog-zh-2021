<html>
<head>
<title>Enhancing Neural Networks with Mixup in PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch中的混合增强神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/enhancing-neural-networks-with-mixup-in-pytorch-5129d261bc4a?source=collection_archive---------10-----------------------#2021-06-08">https://towardsdatascience.com/enhancing-neural-networks-with-mixup-in-pytorch-5129d261bc4a?source=collection_archive---------10-----------------------#2021-06-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cfda" class="pw-subtitle-paragraph jr is it bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">随机混合图像，效果更好？</h2></div><p id="a672" class="pw-post-body-paragraph kj kk it kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">随着深度学习的指数级改进，图像分类已经成为蓬勃发展的领域之一。传统的图像识别任务严重依赖于处理方法，例如扩展/腐蚀、核和频域变换，然而特征提取的困难最终限制了通过这些方法取得的进展。另一方面，神经网络专注于寻找输入图像和输出标签之间的关系，以为此目的“调整”架构。虽然准确性的提高非常显著，但网络通常需要大量数据来进行训练，因此许多研究现在都专注于执行数据扩充，即从预先存在的数据集增加数据量的过程。</p><p id="e7c2" class="pw-post-body-paragraph kj kk it kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">本文介绍了一个简单却惊人有效的增强策略——mixup，通过PyTorch实现并比较结果。</p><h1 id="0760" class="lf lg it bd lh li lj lk ll lm ln lo lp ka lq kb lr kd ls ke lt kg lu kh lv lw bi translated">在混淆之前——为什么要增加数据？</h1><p id="c75f" class="pw-post-body-paragraph kj kk it kl b km lx jv ko kp ly jy kr ks lz ku kv kw ma ky kz la mb lc ld le im bi translated">基于一组给定的训练数据来训练和更新神经网络架构内部的参数。然而，由于训练数据仅覆盖可能数据的整个分布的某一部分，网络可能在分布的“可见”部分上过度拟合。因此，我们用于训练的数据越多，理论上就能更好地描述整个分布。</p><p id="1827" class="pw-post-body-paragraph kj kk it kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">虽然我们拥有的数据数量有限，但我们总是可以尝试稍微改变图像，并将它们用作“新”样本，输入网络进行训练。这个过程被称为数据扩充。</p><h1 id="97d6" class="lf lg it bd lh li lj lk ll lm ln lo lp ka lq kb lr kd ls ke lt kg lu kh lv lw bi translated">什么是Mixup？</h1><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/fcccb847bc7c9275b64474033423978c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*QA3myTJbfw3Ddh3cTgLTeg.jpeg"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">图一。图像混合的简单可视化。</p></figure><p id="ab46" class="pw-post-body-paragraph kj kk it kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">假设我们正在对狗和猫的图像进行分类，给我们一组带有标签的图像(即，<em class="mo">【1，0】</em>-&gt;狗，<em class="mo">【0，1】-</em>-&gt;猫)，混合过程就是简单地平均出两幅图像及其相应的标签作为新数据。</p><p id="d313" class="pw-post-body-paragraph kj kk it kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">具体来说，我们可以用数学方法写出mixup的概念:</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/236daebd76742b5aab9660e9deb818ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:374/format:webp/1*NRXhfpu2O2WYwYexKdQ7yQ.png"/></div></figure><p id="483f" class="pw-post-body-paragraph kj kk it kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">其中<em class="mo"> x，y </em>是<em class="mo"> xᵢ </em>(标号<em class="mo"> yᵢ </em>)和<em class="mo"> xⱼ </em>(标号y <em class="mo"> ⱼ </em>)的混合图像和标号，λ是来自给定<em class="mo">β</em>分布的随机数。</p><p id="3965" class="pw-post-body-paragraph kj kk it kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">这提供了不同类别之间的连续数据样本，直观地扩展了给定训练集的分布，从而使网络在测试阶段更加健壮。</p><h2 id="c821" class="mq lg it bd lh mr ms dn ll mt mu dp lp ks mv mw lr kw mx my lt la mz na lv nb bi translated">在任何网络上使用mixup</h2><p id="e2b2" class="pw-post-body-paragraph kj kk it kl b km lx jv ko kp ly jy kr ks lz ku kv kw ma ky kz la mb lc ld le im bi translated">由于mixup仅仅是一种数据扩充方法，它与任何分类网络体系结构都是正交的，这意味着您可以在具有任何网络的数据集中实现这一点，以解决分类问题。</p><p id="0acf" class="pw-post-body-paragraph kj kk it kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">基于原论文<a class="ae nc" href="https://arxiv.org/abs/1710.09412" rel="noopener ugc nofollow" target="_blank"><em class="mo">mixup:Beyond experimental Risk Minimization</em></a>，张等人对多个数据集和架构进行了实验，经验表明mix up的好处不仅仅是一次性的特例。</p><h1 id="f09f" class="lf lg it bd lh li lj lk ll lm ln lo lp ka lq kb lr kd ls ke lt kg lu kh lv lw bi translated">计算环境</h1><h2 id="77dc" class="mq lg it bd lh mr ms dn ll mt mu dp lp ks mv mw lr kw mx my lt la mz na lv nb bi translated">图书馆</h2><p id="8fea" class="pw-post-body-paragraph kj kk it kl b km lx jv ko kp ly jy kr ks lz ku kv kw ma ky kz la mb lc ld le im bi translated">整个程序是通过PyTorch库(包括torchvision)构建的。混音的概念需要从<em class="mo"> beta </em>分布中生成样本，这可以从NumPy库中获得，我们还使用随机库来查找混音的随机图像。以下代码导入所有库:</p><figure class="md me mf mg gt mh"><div class="bz fp l di"><div class="nd ne l"/></div></figure><h2 id="e60f" class="mq lg it bd lh mr ms dn ll mt mu dp lp ks mv mw lr kw mx my lt la mz na lv nb bi translated">资料组</h2><p id="2d99" class="pw-post-body-paragraph kj kk it kl b km lx jv ko kp ly jy kr ks lz ku kv kw ma ky kz la mb lc ld le im bi translated">为了演示，我们在传统的图像分类上应用了混合的概念，CIFAR-10似乎是最可行的选择。CIFAR-10包含10个类别的60000个彩色图像(每个类别6000个),以5:1的比例分成训练集和测试集。这些图像分类起来相当简单，但比最基本的数字识别数据集MNIST还要难。</p><p id="19d1" class="pw-post-body-paragraph kj kk it kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">有许多方法可以下载<a class="ae nc" href="https://gas.graviti.com/dataset/graviti/CIFAR10?utm_medium=0608kol-1" rel="noopener ugc nofollow" target="_blank"> CIFAR-10 </a>数据集，包括从多伦多大学网站或使用torchvision数据集。值得一提的一个特定平台是<a class="ae nc" href="https://graviti.com/?utm_medium=0608kol-2" rel="noopener ugc nofollow" target="_blank"> <em class="mo"> Graviti开放数据集</em> </a>平台，它包含数百个数据集及其对应的作者，以及每个数据集的指定训练任务(即分类、对象检测)的标签。您可以下载其他分类数据集，如CompCars或SVHN，来测试mixup在不同场景中带来的改进。该公司目前正在开发他们的SDK，尽管目前直接加载数据需要额外的时间，但在不久的将来会非常有用，因为他们正在快速改进批量下载。</p><h2 id="05ad" class="mq lg it bd lh mr ms dn ll mt mu dp lp ks mv mw lr kw mx my lt la mz na lv nb bi translated">硬件要求</h2><p id="c5ef" class="pw-post-body-paragraph kj kk it kl b km lx jv ko kp ly jy kr ks lz ku kv kw ma ky kz la mb lc ld le im bi translated">最好在GPU上训练神经网络，因为它可以显著提高训练速度。但是，如果只有CPU可用，您仍然可以测试程序。要让您的程序自己决定硬件，只需使用以下代码:</p><figure class="md me mf mg gt mh"><div class="bz fp l di"><div class="nd ne l"/></div></figure><h1 id="91ba" class="lf lg it bd lh li lj lk ll lm ln lo lp ka lq kb lr kd ls ke lt kg lu kh lv lw bi translated">履行</h1><h2 id="5755" class="mq lg it bd lh mr ms dn ll mt mu dp lp ks mv mw lr kw mx my lt la mz na lv nb bi translated">网络</h2><p id="197d" class="pw-post-body-paragraph kj kk it kl b km lx jv ko kp ly jy kr ks lz ku kv kw ma ky kz la mb lc ld le im bi translated">目标是看到混合的结果，而不是网络本身。因此，为了演示的目的，实现了一个简单的4层卷积神经网络(CNN ),后面是2层全连接层。注意，对于混合和非混合训练过程，应用相同的网络来确保比较的公平性。</p><p id="1419" class="pw-post-body-paragraph kj kk it kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">我们可以构建如下的简单网络:</p><figure class="md me mf mg gt mh"><div class="bz fp l di"><div class="nd ne l"/></div></figure><h2 id="690f" class="mq lg it bd lh mr ms dn ll mt mu dp lp ks mv mw lr kw mx my lt la mz na lv nb bi translated">混合</h2><p id="dba3" class="pw-post-body-paragraph kj kk it kl b km lx jv ko kp ly jy kr ks lz ku kv kw ma ky kz la mb lc ld le im bi translated">混合阶段是在数据集加载过程中完成的。因此，我们必须编写自己的数据集，而不是使用<em class="mo"> torchvision.datasets </em>提供的默认数据集。</p><p id="ef99" class="pw-post-body-paragraph kj kk it kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">以下是通过合并NumPy的<em class="mo"> beta </em>分布函数实现的简单混合:</p><figure class="md me mf mg gt mh"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="e85a" class="pw-post-body-paragraph kj kk it kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">请注意，我们并没有对所有的图像进行混音，而是对大约五分之一的图像进行混音。我们还使用了0.2的<em class="mo">贝塔</em>分布。您可以更改不同实验的混合图像的分布和数量。也许你会取得更好的成绩！</p><h1 id="232d" class="lf lg it bd lh li lj lk ll lm ln lo lp ka lq kb lr kd ls ke lt kg lu kh lv lw bi translated">培训和评估</h1><p id="a040" class="pw-post-body-paragraph kj kk it kl b km lx jv ko kp ly jy kr ks lz ku kv kw ma ky kz la mb lc ld le im bi translated">下面的代码显示了培训过程。我们将批量大小设置为128，学习速率设置为1e-3，总的历元数设置为30。整个训练进行了两次——有和没有混淆。损失也必须由我们自己定义，因为目前BCE损失不允许带小数的标签:</p><figure class="md me mf mg gt mh"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="92d1" class="pw-post-body-paragraph kj kk it kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">为了评估混淆的影响，我们基于有和没有混淆的三次试验来计算最终精度。在没有混淆的情况下，网络在测试集上产生了大约74.5%的准确率，而在有了混淆的的<strong class="kl iu">上，准确率提升到了大约<strong class="kl iu"> 76.5% </strong>！</strong></p><h1 id="1c4c" class="lf lg it bd lh li lj lk ll lm ln lo lp ka lq kb lr kd ls ke lt kg lu kh lv lw bi translated">超越图像分类</h1><p id="5bc9" class="pw-post-body-paragraph kj kk it kl b km lx jv ko kp ly jy kr ks lz ku kv kw ma ky kz la mb lc ld le im bi translated">虽然mixup推动了图像分类的最新精度，但研究表明，它的好处扩展到了其他计算机视觉任务，如生成和对对立示例的鲁棒性。研究文献也已经将该概念扩展到3D表示中，这也被证明是非常有效的(例如，<a class="ae nc" href="https://arxiv.org/abs/2008.06374" rel="noopener ugc nofollow" target="_blank"> <em class="mo">【点混合</em> </a>)。</p><h1 id="9a7d" class="lf lg it bd lh li lj lk ll lm ln lo lp ka lq kb lr kd ls ke lt kg lu kh lv lw bi translated">结论</h1><p id="5b39" class="pw-post-body-paragraph kj kk it kl b km lx jv ko kp ly jy kr ks lz ku kv kw ma ky kz la mb lc ld le im bi translated">所以你有它！希望这篇文章给你一个基本的概述和指导，告诉你如何将mixup应用到你的图像分类网络训练中。完整的实现可以在下面的Github资源库中找到:</p><div class="nf ng gp gr nh ni"><a href="https://github.com/ttchengab/mixup.git" rel="noopener  ugc nofollow" target="_blank"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd iu gy z fp nn fr fs no fu fw is bi translated">ttchengab/mixup</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">github.com</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw mi ni"/></div></div></a></div><p id="fafc" class="pw-post-body-paragraph kj kk it kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><em class="mo">感谢您坚持到现在</em>🙏<em class="mo">！</em> <em class="mo">我会在计算机视觉/深度学习的不同领域发布更多内容。一定要看看我关于VAE的其他文章，一次学习，等等！</em></p></div></div>    
</body>
</html>