<html>
<head>
<title>Highlights from Data + AI Summit NA 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">来自数据+人工智能峰会NA 2021的亮点</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/highlights-from-data-ai-summit-na-2021-f5320f5d0fd9?source=collection_archive---------36-----------------------#2021-05-31">https://towardsdatascience.com/highlights-from-data-ai-summit-na-2021-f5320f5d0fd9?source=collection_archive---------36-----------------------#2021-05-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e190" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">与Apache Spark新特性相关的数据+人工智能峰会笔记</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3a99fb4143a014c16bc6a1a756b3891e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lVo1GiMsCIW6txuQcLpsjQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@dtravisphd" rel="noopener ugc nofollow" target="_blank">大卫·特拉维斯</a>在Unsplash上拍摄</p></figure><p id="73b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据领域最大的会议之一— <strong class="lb iu"> </strong> <a class="ae ky" href="https://databricks.com/dataaisummit/north-america-2021" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Data + AI Summit北美2021 </strong> </a>上周发生了，这次我没有用自己的演讲做出贡献，但作为一名听众，我越来越喜欢这些会议。</p><p id="b073" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇简短的报告中，我想总结一下我在<em class="lv"> Apache Spark内部和最佳实践</em>主题中讨论的Spark 3.1和即将推出的3.2中的新特性。</p><h1 id="1d27" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">禅宗项目</h1><p id="d97b" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">Zen项目开始于一年前，目标是让Spark对Python用户更加友好。</p><h2 id="df62" class="mt lx it bd ly mu mv dn mc mw mx dp mg li my mz mi lm na nb mk lq nc nd mm ne bi translated">类型提示</h2><p id="29d9" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">其中一个步骤是添加类型提示，例如允许ide和笔记本环境中的自动完成，这样可以使开发更加高效。对类型提示的完全支持是在最新版本3.1.1中添加的。</p><h2 id="3b5d" class="mt lx it bd ly mu mv dn mc mw mx dp mg li my mz mi lm na nb mk lq nc nd mm ne bi translated">星火上的熊猫</h2><p id="7faf" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">Spark 3.2的一个新特性是将考拉项目集成到Spark中。考拉允许使用Pandas API，同时将Spark作为后端，因此，如果数据科学家使用Pandas进行数据操作，并由于数据量大而遇到性能问题，那么很容易切换到考拉，代码保持不变，但在幕后，执行在Spark中进行。现在，当考拉将被集成到Spark中时，情况变得更加简单，你可以从Spark中导入熊猫并使用熊猫API，同时在引擎盖下有Spark。熊猫的绘图和可视化工具现在可以在Spark中使用了。</p><p id="59e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本次峰会讨论了Zen项目:</p><ul class=""><li id="f6eb" class="nf ng it lb b lc ld lf lg li nh lm ni lq nj lu nk nl nm nn bi translated"><a class="ae ky" href="https://databricks.com/session_na21/project-zen-making-data-science-easier-in-pyspark" rel="noopener ugc nofollow" target="_blank">Zen项目:让PySpark中的数据科学更简单</a></li></ul><h1 id="8d83" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">性能改进</h1><p id="dbf8" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">随着Spark的每一次发布，发动机的性能都在不断提高。在峰会上，我们讨论了几个与绩效相关的话题:</p><h2 id="ab02" class="mt lx it bd ly mu mv dn mc mw mx dp mg li my mz mi lm na nb mk lq nc nd mm ne bi translated">混合散列连接(SHJ)</h2><p id="f1c5" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">混合散列连接是Spark中用于连接数据的算法之一。在实践中，它被避免使用，取而代之的是更健壮的排序合并连接(SMJ)。如果数据不对称，并且其中一个分区太大，SHJ会导致OOM错误。然而，在合理的情况下，SHJ可以比SMJ执行得更快，因为它避免了这种情况。(关于Spark使用的算法和决策逻辑的更多细节，请参见我的相关文章<a class="ae ky" rel="noopener" target="_blank" href="/about-joins-in-spark-3-0-1e0ea083ea86">关于Spark 3.0中的加入的文章</a> <em class="lv"/></p><p id="3070" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.1中实现了几项增强功能，使SHJ变得更好、更可用:</p><ul class=""><li id="a950" class="nf ng it lb b lc ld lf lg li nh lm ni lq nj lu nk nl nm nn bi translated">添加代码生成(参见<a class="ae ky" href="https://issues.apache.org/jira/browse/SPARK-32421" rel="noopener ugc nofollow" target="_blank">吉拉</a>)</li><li id="018d" class="nf ng it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">支持完全外部连接(参见<a class="ae ky" href="https://issues.apache.org/jira/browse/SPARK-32399" rel="noopener ugc nofollow" target="_blank">吉拉</a></li><li id="9186" class="nf ng it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">保留分区(参见<a class="ae ky" href="https://issues.apache.org/jira/browse/SPARK-32330" rel="noopener ugc nofollow" target="_blank">吉拉</a>)</li></ul><p id="be29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这次首脑会议期间，讨论了SHJ的改进和其他改进:</p><ul class=""><li id="5fad" class="nf ng it lb b lc ld lf lg li nh lm ni lq nj lu nk nl nm nn bi translated"><a class="ae ky" href="https://databricks.com/session_na21/deep-dive-into-the-new-features-of-apache-spark-3-1" rel="noopener ugc nofollow" target="_blank">深入了解Apache Spark 3.1的新特性</a></li></ul><h2 id="d1d8" class="mt lx it bd ly mu mv dn mc mw mx dp mg li my mz mi lm na nb mk lq nc nd mm ne bi translated">…向量化…</h2><p id="ee68" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">矢量化是一种同时处理多行以加快处理速度的技术。在Spark的当前版本中，当使用矢量化读取器从parquet和orc格式读取数据时，会使用矢量化。除此之外，PySpark中的熊猫UDF也支持矢量化。</p><p id="8b61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实现矢量化的一种方法是使用现代硬件支持的<a class="ae ky" href="https://en.wikipedia.org/wiki/SIMD" rel="noopener ugc nofollow" target="_blank"> SIMD </a>指令(单指令，多数据)。当前版本的Spark没有明确使用SIMD，因为JVM中的HotSpot编译器在某些情况下会生成SIMD指令，但在某些情况下不会。然而，新的Java 16有<em class="lv"> VectorAPI </em>可用，这个API可以确保SIMD指令被使用。因此，使用这个<em class="lv"> VectorAPI </em>，可以在Spark中为生成的代码实现显式矢量化。本次峰会讨论了矢量化:</p><ul class=""><li id="1656" class="nf ng it lb b lc ld lf lg li nh lm ni lq nj lu nk nl nm nn bi translated"><a class="ae ky" href="https://databricks.com/session_na21/enabling-vectorized-engine-in-apache-spark" rel="noopener ugc nofollow" target="_blank">在Apache Spark中启用矢量化引擎</a></li></ul><h2 id="6ddc" class="mt lx it bd ly mu mv dn mc mw mx dp mg li my mz mi lm na nb mk lq nc nd mm ne bi translated">标准压缩编解码器</h2><p id="2fe9" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">Apache Spark支持各种压缩算法，例如，snappy是将数据保存到parquet文件时使用的默认算法，另一方面，lz4用于shuffle文件，也支持其他编解码器。ZStandard是一种编解码器，可以实现与gzip相当的压缩速度和压缩比。</p><p id="cd9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从Spark 3.2开始，ZStandard将在三种情况下有用，它可以带来性能优势(节省本地磁盘空间和/或外部存储以及整体查询执行速度的提高):</p><ul class=""><li id="2991" class="nf ng it lb b lc ld lf lg li nh lm ni lq nj lu nk nl nm nn bi translated">事件日志压缩(<em class="lv">spark . event log . compression . codec = zstd</em>)</li><li id="9469" class="nf ng it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">洗牌期间的I/O压缩(<em class="lv">spark . io . compression . codec = zstd</em>)</li><li id="c176" class="nf ng it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated">压缩parquet/orc文件<em class="lv">spark . conf . set(" spark . SQL . parquet . compression . codec "，" zstd") </em></li></ul><p id="eff4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相关的首脑会议是:</p><ul class=""><li id="dd86" class="nf ng it lb b lc ld lf lg li nh lm ni lq nj lu nk nl nm nn bi translated"><a class="ae ky" href="https://databricks.com/session_na21/the-rise-of-zstandard-apache-spark-parquet-orc-avro" rel="noopener ugc nofollow" target="_blank">z standard的崛起:阿帕奇Spark/Parquet/ORC/Avro </a></li></ul><h2 id="4652" class="mt lx it bd ly mu mv dn mc mw mx dp mg li my mz mi lm na nb mk lq nc nd mm ne bi translated">随机播放增强</h2><p id="8f5e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">Spark作业中的Shuffle通常是开销最大的过程，因为数据必须在集群的节点之间移动。shuffle是两个阶段之间的界限，在一个阶段完成后，输出被写入文件，然后被提取到下一个阶段。文件保存在执行器的本地磁盘上，或者当使用外部混洗系统时，可以保存到外部存储系统，例如HDFS。这些文件的数量随着任务的数量成二次方增长(更具体地说，它是上游阶段的任务数量乘以下游阶段的任务数量)，并且这些文件可能变得相当小。有一个<a class="ae ky" href="https://issues.apache.org/jira/browse/SPARK-30602" rel="noopener ugc nofollow" target="_blank">吉拉</a>正在进行中，旨在实现所谓的基于推送的洗牌，通过预合并块来优化洗牌I/O。关于这项技术的相关文章可以在<a class="ae ky" href="https://engineering.linkedin.com/blog/2020/introducing-magnet" rel="noopener ugc nofollow" target="_blank">这里</a>找到。在这次首脑会议上讨论了这个主题本身:</p><ul class=""><li id="1185" class="nf ng it lb b lc ld lf lg li nh lm ni lq nj lu nk nl nm nn bi translated"><a class="ae ky" href="https://databricks.com/session_na21/magnet-shuffle-service-push-based-shuffle-at-linkedin" rel="noopener ugc nofollow" target="_blank">磁铁洗牌服务:LinkedIn上基于推送的洗牌</a></li></ul><h2 id="d797" class="mt lx it bd ly mu mv dn mc mw mx dp mg li my mz mi lm na nb mk lq nc nd mm ne bi translated">复杂查询计划处理</h2><p id="f878" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">对于某些查询，查询计划可能会变得非常复杂，其编译可能会成为真正的瓶颈。有一个<a class="ae ky" href="https://issues.apache.org/jira/browse/SPARK-33152" rel="noopener ugc nofollow" target="_blank">吉拉</a>正在进行中，它试图简化处理带有别名的列的约束的过程，测试显示有希望加速。与这一主题相关的首脑会议是:</p><ul class=""><li id="0193" class="nf ng it lb b lc ld lf lg li nh lm ni lq nj lu nk nl nm nn bi translated"><a class="ae ky" href="https://databricks.com/session_na21/optimizing-the-catalyst-optimizer-for-complex-plans" rel="noopener ugc nofollow" target="_blank">优化复杂计划的催化剂优化器</a></li></ul><h1 id="3b62" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">ANSI SQL符合性</h1><p id="12cb" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这是spark中正在进行的项目，在3.0版本中引入了实验性配置设置<em class="lv"> spark.sql.ansi.enabled </em>，当设置为<em class="lv"> True </em>时，Spark将尝试符合ANSI SQL规范，这意味着如果输入无效，查询可能会在运行时失败，否则可能会返回空值。这方面的一个具体例子是无法安全转换或容易混淆的数据类型的转换。与此相关的一些新功能将在3.2中发布，例如，<em class="lv"> TRY_CAST </em>，<em class="lv"> TRY_ADD </em>，<em class="lv"> TRY_DIVIDE </em>如果用户希望使用ANSI模式，但如果输入无效而不是查询失败，则这些功能会很有用。</p><p id="c5cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在Spark 3.2中，将发布两种新的间隔日期类型，年-月和日-时间，这将解决当前<em class="lv"> CalendarIntervalType </em>存在的一些问题。正在进行的<a class="ae ky" href="https://issues.apache.org/jira/browse/SPARK-27790" rel="noopener ugc nofollow" target="_blank">吉拉</a>是相关子任务的保护伞。当前区间类型的问题是它不具有可比性，并且不支持排序，因此有两个区间我们无法比较它们并判断哪个更大。另一个问题是我们不能将区间类型保存为文件格式，比如parquet/orc甚至json。另一方面，将在3.2中发布的两个新类型<em class="lv"> YearMonthIntervalType </em>和<em class="lv"> DayTimeIntervalType </em>将是可比较和可订购的，并且将符合SQL标准。</p><p id="6e7b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有关ANSI SQL合规性的更多信息和细节，请参见<a class="ae ky" href="https://spark.apache.org/docs/latest/sql-ref-ansi-compliance.html" rel="noopener ugc nofollow" target="_blank">文档</a>或查看峰会中讨论这些主题的以下会议:</p><ul class=""><li id="52c4" class="nf ng it lb b lc ld lf lg li nh lm ni lq nj lu nk nl nm nn bi translated"><a class="ae ky" href="https://databricks.com/session_na21/deep-dive-into-the-new-features-of-apache-spark-3-1" rel="noopener ugc nofollow" target="_blank">深入了解Apache Spark 3.1的新特性</a></li><li id="ccf8" class="nf ng it lb b lc no lf np li nq lm nr lq ns lu nk nl nm nn bi translated"><a class="ae ky" href="https://databricks.com/session_na21/comprehensive-view-on-intervals-in-apache-spark-3-2" rel="noopener ugc nofollow" target="_blank">Apache Spark 3.2中区间的综合视图</a></li></ul><h1 id="b7da" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">DataSourceV2 API</h1><p id="23fe" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">DataSourceV2 API在过去几年中一直在开发中，它旨在解决与V1 API相关的各种问题，例如，<em class="lv">data frame writer</em>的某些模式的连接器行为不一致，在写入表之前没有模式验证，依赖于其他内部API，如<em class="lv"> SQLContext </em>，以及新功能不容易扩展。</p><p id="6068" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">V2 API使用目录来检查表是否存在，并使用一致的验证规则，与连接器的实现无关。有一个<a class="ae ky" href="https://issues.apache.org/jira/browse/SPARK-23889" rel="noopener ugc nofollow" target="_blank">吉拉</a>正在开发中，旨在支持在V2 API中更好地控制连接器的分布和订购，这应该允许更好的灵活性，并计划在Spark 3.2中发布。</p><p id="86e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本次峰会讨论了V2 API以及相关的配送和订购功能:</p><ul class=""><li id="60c6" class="nf ng it lb b lc ld lf lg li nh lm ni lq nj lu nk nl nm nn bi translated"><a class="ae ky" href="https://databricks.com/session_na21/data-distribution-and-ordering-for-efficient-data-source-v2" rel="noopener ugc nofollow" target="_blank">高效数据源V2的数据分发和排序</a></li></ul><h1 id="2950" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结论</h1><p id="4816" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">Data + AI峰会NA 2021上有很多有趣的环节。在这篇简短的报告中，我总结了我在<em class="lv"> Spark内部机制和最佳实践</em>专题的一些会议中的笔记。这些说明并不完整，我主要关注的是3.1.1中发布的新特性或者计划在3.2中发布的新特性。</p></div></div>    
</body>
</html>