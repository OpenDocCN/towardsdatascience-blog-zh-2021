<html>
<head>
<title>End-to-End Databricks-Horovod Use Case</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">端到端数据块-Horovod用例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/end-to-end-databricks-horovod-machine-learning-use-case-cdd505edc962?source=collection_archive---------24-----------------------#2021-10-06">https://towardsdatascience.com/end-to-end-databricks-horovod-machine-learning-use-case-cdd505edc962?source=collection_archive---------24-----------------------#2021-10-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/a578d3967246096c854f19aa939db38e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-3fgsfXOn2967XKJPPECIg.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://unsplash.com/photos/1lfI7wkGWZ4?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditShareLink" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/1lfI7wkGWZ4?utm_source=unsplash&amp;UTM _ medium = referral&amp;UTM _ content = creditShareLink</a></p></figure><div class=""/><p id="bfb2" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当开始一个大的机器学习项目时，有许多平台可供选择。本文将给出在数据块上使用Tensorflow &amp; Horovod训练神经网络的指南。</p><h1 id="1280" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">背景</h1><p id="25e4" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">在<a class="ae jd" href="https://surewx.com/solutions.php" rel="noopener ugc nofollow" target="_blank"> SureWx </a>(发音为“确定的天气”)，我们已经为航空应用开发了定制的天气预报。这符合我们为航空公司提供的从登机口到起飞的数据驱动产品的T4套件。在冬季，操作决策变得复杂，因为降水要求在飞机离开地面之前采取额外的清洁和安全措施。更准确的天气预报有助于确保飞机按时起飞。这就是为什么我们一直在使用来自全球传感器网络的数据结合雷达数据来训练神经网络，以预测短期天气。这篇文章包含了我们在这个过程中学到的与模型的架构和训练相关的最重要的发现。</p><h1 id="e563" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">1.将数据保存在TFRecord批中</h1><p id="83ec" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">数据从您的S3存储桶中读取，该存储桶安装在spark集群上的/dbfs中。只要您的EC2实例与您的S3时段在同一个区域，您只需为到S3的GET请求付费(但不包括数据传输)。如果您的数据没有进行批处理，GET请求会很快增加。</p><p id="1518" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">无阴影示例:</p><p id="c126" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">0.0004美元/ 1000个请求* 200，000个文件/时期* 1000个时期= 80美元</p><p id="6265" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每个模型80美元的S3成本是一笔巨大的意外成本，在某些情况下甚至可能超过GPU成本。如果您已经为定型生成了tf.data.dataset，则可以通过将数据写入TFRecords来轻松地对数据进行预批处理。您可以在这里找到编写和解析TFRecords的指南:</p><div class="ip iq gp gr ir me"><a href="https://www.tensorflow.org/tutorials/load_data/tfrecord#writing_a_tfrecord_file" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd jh gy z fp mj fr fs mk fu fw jf bi translated">TFRecord和tf.train.Example | TensorFlow核心</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">TFRecord格式是一种用于存储二进制记录序列的简单格式。协议缓冲区是跨平台的…</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">www.tensorflow.org</p></div></div><div class="mn l"><div class="mo l mp mq mr mn ms ix me"/></div></div></a></div><h1 id="f379" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak"> 2。解析时交错</strong></h1><p id="629b" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">当您进行解析时，确保使用并行化的交错来获得最佳性能。此外，为了在添加更多节点时有效地扩大培训规模，tf.data.Dataset需要在解析文件之前应用分片。这样，每个碎片只将一小部分文件读入内存。</p><pre class="mt mu mv mw gt mx my mz na aw nb bi"><span id="8db1" class="nc lc jg my b gy nd ne l nf ng">import glob<br/>import tensorflow as tf</span><span id="9436" class="nc lc jg my b gy nh ne l nf ng">def parse_fn(serialized):</span><span id="2452" class="nc lc jg my b gy nh ne l nf ng">  features = \<br/>  {<br/>  'radar': tf.io.FixedLenFeature([], tf.string),<br/>  'stationd_data': tf.io.FixedLenFeature([], tf.string),<br/>  'label': tf.io.FixedLenFeature([], tf.string)<br/>  }</span><span id="c117" class="nc lc jg my b gy nh ne l nf ng">  # Parse the serialized data so we get a dict with our data.<br/>  parsed_example = tf.io.parse_single_example(serialized=serialized, features=features)</span><span id="da95" class="nc lc jg my b gy nh ne l nf ng">  # Get the image as raw bytes.<br/>  radar_raw = parsed_example['radar']<br/>  station_data_raw = parsed_example['station_data']<br/>  label_raw = parsed_example['label']</span><span id="1cc7" class="nc lc jg my b gy nh ne l nf ng">  # Decode the raw bytes so it becomes a tensor with type.<br/>  radar = tf.io.decode_raw(radar_raw, tf.float32)<br/>  radar = tf.reshape(radar, radar_shape)</span><span id="e63a" class="nc lc jg my b gy nh ne l nf ng">  station_data = tf.io.decode_raw(station_data_raw, tf.float64)<br/>  station_data = tf.reshape(station_data, station_data_shape)</span><span id="d8c2" class="nc lc jg my b gy nh ne l nf ng">  label = tf.io.decode_raw(label_raw, tf.float32)<br/>  label = tf.reshape(label, label_shape)</span><span id="2432" class="nc lc jg my b gy nh ne l nf ng">  return (radar, station_data), label</span><span id="3937" class="nc lc jg my b gy nh ne l nf ng">files = glob.glob(f'{data_path}/*.tfrecord')</span><span id="ce89" class="nc lc jg my b gy nh ne l nf ng">files_ds = tf.data.Dataset.from_tensor_slices(files)<br/>files_ds = files_ds.shard(self.shards, shard_index)</span><span id="e364" class="nc lc jg my b gy nh ne l nf ng">ds = files_ds.interleave(lambda x: tf.data.TFRecordDataset(x)).map(lambda x: parse_fn(x), num_parallel_calls = tf.data.experimental.AUTOTUNE)</span></pre><h1 id="46a7" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">3.选择S3路径来优化S3的分片</h1><p id="0ff9" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">批量保存数据的另一个原因是为了避免S3节流和网络错误。在S3，每个前缀每秒钟最多只能有5500个请求。这可能看起来很多——但是如果你同时训练许多模型，你可以达到这个极限。用优化S3分片的文件路径保存预先批处理的TFRecords是一种很好的做法。请参见下面的指南。</p><div class="ip iq gp gr ir me"><a href="https://aws.amazon.com/premiumsupport/knowledge-center/s3-object-key-naming-pattern/" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd jh gy z fp mj fr fs mk fu fw jf bi translated">理解高请求率的S3对象键命名模式</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">我希望我的亚马逊简单存储服务(亚马逊S3)桶获得高请求率。什么对象键命名模式…</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">aws.amazon.com</p></div></div><div class="mn l"><div class="ni l mp mq mr mn ms ix me"/></div></div></a></div><h1 id="efe3" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">4.错误处理</h1><p id="5c33" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">训练可能会因为各种原因而中断:错误的数据、训练中的不稳定性、回调中的错误、点实例被取走…为了不浪费资源，您希望您的模型进行检查点检查和恢复。</p><pre class="mt mu mv mw gt mx my mz na aw nb bi"><span id="0151" class="nc lc jg my b gy nd ne l nf ng">keras.callbacks.ModelCheckpoint(f'{checkpoint_path}_{time}', save_weights_only = False, monitor='val_loss', mode='min', save_best_only=True))</span><span id="8b24" class="nc lc jg my b gy nh ne l nf ng">keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only = False, save_best_only=False, save_freq='epoch', period=3))</span></pre><p id="a6a3" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一次回调是保存培训课程中产生的最佳模型。第二个回调是每隔几个时期保存一次模型，如果训练中断，可以启动一个新的作业并加载模型。如果没有这两次复试，你会丢掉自上一个最佳模特以来的所有训练。两次回调很容易，何必浪费GPU时间？</p><h1 id="410f" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">5.多输入混合数据</h1><p id="acf5" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">处理混合数据(例如:图像和时间序列数据)的ETL可能很难设计。在我们的案例中，我们将雷达图像序列与来自传感器的时间序列数据相结合。我们使用Spark构建数据框架，将我们的图像与传感器数据对齐。例如，假设我们想要将图像与最近30分钟的传感器数据进行匹配。我们对时间序列数据应用窗口函数，将所有时间序列数据保存到单个字节数组中。</p><pre class="mt mu mv mw gt mx my mz na aw nb bi"><span id="b014" class="nc lc jg my b gy nd ne l nf ng">import pandas as pd<br/>import numpy as np<br/>from pyspark.sql.types import BinaryType<br/>from pyspark.sql.functions import pandas_udf</span><span id="3475" class="nc lc jg my b gy nh ne l nf ng">df # sensor time series data. </span><span id="692f" class="nc lc jg my b gy nh ne l nf ng"># Stack the sensor data columns together and serialize<br/><a class="ae jd" href="http://twitter.com/pandas_udf" rel="noopener ugc nofollow" target="_blank">@pandas_udf</a>(BinaryType())<br/>def serialize_udf(s1: pd.Series, s2: pd.Series) -&gt; bytearray:<br/>    """Takes multiple pandas series, stacks them, and converts the resulting array to bytes"""<br/>    data = np.dstack((s1.to_numpy(), s2.to_numpy()))<br/>    data = data.astype(np.double)<br/>    data = data[0,:,:]</span><span id="e6fa" class="nc lc jg my b gy nh ne l nf ng">return data.tobytes()</span><span id="7d2d" class="nc lc jg my b gy nh ne l nf ng">w = Window.orderBy(f.col("time").cast('long')).rangeBetween(-30*60, 0)</span><span id="e250" class="nc lc jg my b gy nh ne l nf ng">df = df.withColumn('sensor_data', serialize_udf(*config['sensor_cols']).over(w))</span><span id="8c0d" class="nc lc jg my b gy nh ne l nf ng">pdf = df.toPandas()</span></pre><p id="ccf7" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，在tf.data.dataset中读取时间序列数据之前，需要应用一个解析器。</p><pre class="mt mu mv mw gt mx my mz na aw nb bi"><span id="7c64" class="nc lc jg my b gy nd ne l nf ng">sensor_data_bytes_list = list(pdf['sensor_data'].to_numpy())<br/>sensor_data_list = list(map(lambda blob: np.frombuffer(blob, np.double), sensor_data_bytes_list))<br/>sensor_data_array = np.concatenate(sensor_data_list)<br/>ds = tf.data.Dataset.from_tensor_slices(sensor_data_array)</span></pre><h1 id="9ec8" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">逮到你了</h1><ol class=""><li id="b00b" class="nj nk jg kf b kg lz kk ma ko nl ks nm kw nn la no np nq nr bi translated">通过HorovodRunner在spark上运行Horovod，你需要支付1个不能用于计算的GPU实例——这是Spark驱动程序的开销，Horovod不能用于训练。</li><li id="8346" class="nj nk jg kf b kg ns kk nt ko nu ks nv kw nw la no np nq nr bi translated">Databricks上没有Tensorboard profiler扩展，如果您是第一次设计tensorflow数据管道，最好先在单台GPU服务器上进行优化。</li><li id="261e" class="nj nk jg kf b kg ns kk nt ko nu ks nv kw nw la no np nq nr bi translated">Databricks上的Horovod没有弹性——当spot实例被删除时，训练就会停止。如果你打算采用现货价格，你应该预料到培训会有很多中断。</li><li id="fa90" class="nj nk jg kf b kg ns kk nt ko nu ks nv kw nw la no np nq nr bi translated">获取g4dn EC2 spot实例相当困难(截至2021年)。Databricks无法在g4da实例上运行，其他EC2 GPU实例也没有这么好的价值。</li></ol><h1 id="eb7c" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论</h1><p id="fb23" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">Databricks创建了一个很好的套件，将数据、ETL和分布式培训都放在同一个地方。希望这些小技巧能让你的开发更轻松！祝你好运。</p></div></div>    
</body>
</html>