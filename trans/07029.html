<html>
<head>
<title>Put your money where your ML is: building trust in business-critical AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">把你的钱投在你的ML上:建立对商业关键人工智能的信任</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/put-your-money-where-your-ml-is-building-trust-in-business-critical-ai-f57963dc5109?source=collection_archive---------33-----------------------#2021-06-25">https://towardsdatascience.com/put-your-money-where-your-ml-is-building-trust-in-business-critical-ai-f57963dc5109?source=collection_archive---------33-----------------------#2021-06-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="3363" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/notes-from-industry" rel="noopener" target="_blank">行业笔记</a></h2><div class=""/><div class=""><h2 id="f398" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated"><strong class="ak">本文探讨了在交易处理中信任人工智能(AI)的问题。在过去的三十年中，模型治理框架已经发展，并由于模型复杂性的增加而变得紧张，使其核心方法变得站不住脚。在评估信任一个人工智能模型意味着什么时，我们将检查这个框架的现代化，其目的是使用连续统计测试的哲学来建立和维持信任。</strong></h2></div><p id="a47f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">消费者希望银行能同时保护他们的钱，并提供不受限制的资金存取，尤其是在紧急情况下。反过来，银行别无选择，只能相信他们的自动处理系统在批准交易时做出了正确的决策。这些决策必须自动化——数千个决策必须在几毫秒内完成——因此由合格人员进行人工审查是不可能的。</p><p id="d30c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">从银行的角度来看，这些决定具有深刻的财务后果。在真正购买时，一个错误的决定就可能导致一个好客户的永久流失。另一方面，在欺诈性购买上的一个错误决定可能导致数百万美元的即时损失。金融机构别无选择，只能把一个勇敢的小AI放在城门前，并相信它会完成任务。随着这些系统变得更加复杂，它们也变得更加难以用<strong class="kq ja"> <em class="lk">语义逻辑</em> </strong>来概括。最新一代的深度学习驱动的决策人工智能，如Featurespace的自动化深度行为网络，承诺了前所未有的决策准确性，但它们是以人类可理解的逻辑为代价的。鉴于对系统可能出轨的担忧，企业如何才能在一个新的复杂的人工智能系统中建立信任？它的未来取决于该系统的决策。</p><h1 id="5f5d" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">模型治理</h1><p id="79bd" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">在20世纪80年代，世界各地的银行都是简单机器学习系统的早期采用者。他们能够在这些系统中建立一定程度的信任，部分是因为逻辑可以由人类设计和审查。这个审查过程被称为<strong class="kq ja">模型治理</strong>，今天的银行通常会雇佣多个模型治理团队来独立审查在业务中部署的模型。这个过程如此重要，以至于美联储颁布了规定，概述了这个过程应该是什么样子。模型治理围绕两个过程——部署前的<strong class="kq ja">审计</strong>,以及部署后的<strong class="kq ja">监控</strong>模型。</p><p id="dfb3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">典型审计通常关注三件事:</p><p id="2790" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">1.检查编码在特性中的逻辑的充分性和相关性(例如:使用这些特性是明智的吗？)</p><p id="ab0e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">2.检查所学习的分类器，自省其所学习的逻辑，并评估其在验证数据上的性能。通常按交易的不同子群体进行细分。</p><p id="4012" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">3.检查产生分类器的训练方案。这包括检查用于训练和测试的数据(以确保其正确标记并代表真实世界的数据)，然后审查实验结果支持数据科学家所做建模决策的证据(这些决策包括分类器算法选择、超参数选择和选择作为输入的特征)。</p><p id="6a40" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">总而言之，审计的一部分是使用结果分析对建模决策进行统计评估，而另一部分是对逻辑进行定性评估。对于银行已经发展到可以使用的初级第一代机器学习系统，逻辑评估一直很简单，数学上也很好。最常见的简单分类器之一是一种被称为<em class="lk">逻辑回归</em>的算法。该分类器将未知结果的比值比的对数建模为提供给模型的<strong class="kq ja"> <em class="lk"> n </em> </strong>特征的加权和:</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/08ebd707f9bca7a112ff0273e790ba94.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*C8kK3wXatJilNWPqQiLi0g.jpeg"/></div></div></figure><p id="47aa" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这通常与一组特征<strong class="kq ja"> <em class="lk"> x1…xn </em> </strong>一起使用，这些特征本身是编码人类设计逻辑的二进制决策规则。例如，数据科学家可能会设计他们的一个功能，作为一项规则来评估交易是否代表帐户在半夜在电子商务网站上的异常高的花费:</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mv"><img src="../Images/2c9d337767bc82ddd8c3a9abbaa00fbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jkNXDDMWi-JHWAA2zypfCQ.jpeg"/></div></div></figure><p id="3f97" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了建立一个模型，数据科学家会定义数百个这样的规则。他们将使用领域知识、直觉和来自探索性数据分析的洞察力，实现用于捕捉欺诈的逻辑和用于批准真实支出的逻辑。然后，通过逻辑回归计算特征权重。拟合的权重有一个明智而有意义的解释:权重代表回归者认为交易将被证明是欺诈的可能性有多大(或有多大),假设规则中的条件为真。例如:</p><p id="1ab0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果规则的拟合权重是0.693(2的自然对数)，那么回归变量对交易的怀疑是两倍，因为规则中编码了逻辑因子。</p><p id="bb0c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">权重正好为0(1的自然对数)意味着回归变量已经学会忽略属性，因为它认为它们是不相关的。</p><p id="83bc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这种方法下，决策规则包含可以被人类审计员解析和验证的逻辑思想，分配给规则的权重准确地告诉他们如何使用该信息。如果他们不喜欢某些信息的使用方式，他们可以直接将权重归零。从这个意义上说，分类器是可组合的，规则可以独立地添加或删除。权重告诉审计员该模型的聚合逻辑，对于该交易为真的特定规则的权重告诉分析师该模型做出的每个预测背后的确切逻辑。</p><p id="b877" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">尽管这些模型很容易被信任，但它们也是初级的，不再提供让银行具有竞争力所需的保护水平。例如，在2010年<a class="ae mi" href="#_ftn2" rel="noopener ugc nofollow">【2】</a>期间，每年被骗的英国账户数量增加了55%，从180万增加到280万。银行信任了几十年的系统现在被21世纪欺诈的数量和复杂性所淹没，刺激行业采用目前已知的机器学习最强大的分支的算法，<em class="lk">深度学习</em>。</p><h1 id="590e" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">深度学习的时代</h1><p id="bc0a" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">在大多数机器学习领域，设计良好的深度学习算法已经成为最先进的技术。然而，深度学习取得成功的关键是磨练架构和组件，以充分利用数据中的结构和相关性。对于事务流，这意味着不要孤立地考虑每个事务，而是要考虑导致当前事件的一系列操作中的所有相关信息。在这个序列中，最重要的是付款人当前的意图。</p><p id="3282" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">与这种设置最相似的是自然语言处理，其中动作序列是句子中使用的单词。在我们的例子中，句子是客户的账户历史，单词是金融交易。因此，像这样处理序列信息的深度学习算法必须以两种方式之一运行。他们或者以变压器<a class="ae mi" href="#_ftn3" rel="noopener ugc nofollow">【3】</a>或卷积网络的方式读取并操作序列中的一些连续子集，或者他们读取单个事件作为输入，并利用具有内置本地存储器的神经细胞来记住序列中先前示例的相关信息。后一类称为递归神经网络，包括lst ms<a class="ae mi" href="#_ftn4" rel="noopener ugc nofollow">【4】</a>、GRUs<a class="ae mi" href="#_ftn5" rel="noopener ugc nofollow">【5】</a>和Featurespace全新的自动化深度行为网络架构等架构。</p><p id="a2f0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然而，深度学习算法的一个副作用是，它们失去了直观的可解释性。这些决定背后的逻辑超出了人类的解释能力。逻辑回归算法可能已经训练了数百个关于人类工程逻辑特征的参数，而深度学习的参数以十亿计，并且这些算法通常对原始未处理的事件数据进行操作。对逻辑特征工程步骤没有明确的要求——特征可以由架构中较低的神经层学习——它们学习的内部特征是复杂的。它们从网络中数以百万计的连接到前几层的相互影响中获取价值。</p><p id="eb59" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">传统的模型治理过程依赖于对人类逻辑的审计和常识的应用，面对这样的复杂性，这些过程完全失败了。</p><h1 id="bdaa" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">建立信任</h1><p id="2766" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">鉴于这些决策系统的成功运作关系重大，如果不建立高度的信任，企业就无法运营深度学习模型。如果模型治理框架现代化，并与深度学习模型的复杂性保持一致，那么这种信任程度就可以实现。有多种方法可以在一个不透明的模型中系统地建立信任，无法将决策简化为简单的逻辑并不意味着我们必须闭上眼睛，希望算法奏效。</p><p id="52b3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">当组织决定是否部署新系统时，有四个主要的信任和治理问题:</p><p id="3824" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">1.<strong class="kq ja">模型还能更好吗</strong>？这反映了一种焦虑，即模型开发人员本可以做得更好。正确的最关键的元素是确保训练数据和它的标记机制是真实世界的代表。在此之后，围绕模型开发的问题对于深度学习模型来说更容易明确回答，因为不依赖于数据科学家的特征工程的创造力或领域理解。取而代之的是，将特征工程融入损失函数优化的过程中，因此算法不断迭代，直到找到最佳特征。还有其他可以质疑的建模选择(数据准备、数据选择、模型超参数、架构选择等)，但与功能发明不同，这些选择是从定义的选项列表中系统选择的，每个选择的价值都由实验结果证明。Auto-ML方法甚至可以自动执行这种搜索，同时为决策生成透明的审计跟踪。</p><p id="6280" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">2.<strong class="kq ja">模型公平吗？</strong>这反映了对模型歧视受保护属性的担忧。对于深度学习模型来说，更难直观地确定这一点，因为逻辑无法手动检查禁止的推理。虽然人类偏见确实不会通过特征工程蔓延到模型设计中，但由于训练数据中虚假的或不具代表性的相关性，现实世界中过度(或不足)代表人群的有偏见的选择机制，或影响我们训练数据标签的有偏见的标签机制，偏见仍然会蔓延。即使模型对受保护的属性视而不见，它仍然可能通过在数据中找到代表受保护属性的信号而导致歧视性的结果。这是深度学习模型的治理框架必须解决的问题。</p><p id="3f92" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">3.<strong class="kq ja">每个预测都合理吗？</strong>这反映了一种焦虑，即一些预测是不合理的，依赖于虚假的相关性，或者对训练数据中的稀疏区域进行了糟糕的外推。治理过程必须通过为模型在生产中做出的每个预测提供逻辑解释来解决这个问题。对于深度学习，逻辑解释很难，因为逻辑太复杂了。治理还必须围绕每个预测的预期质量提供透明性，即:模型在多大程度上基于大量证据工作，而在多大程度上基于推断工作。必须持续评估此类措施，以控制训练和服务数据之间的系统性偏差，这种偏差往往会随着时间的推移而增长。这些是模型治理必须解决的挑战。</p><p id="6f27" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">4.<strong class="kq ja">预测稳定吗？</strong>这反映了一种焦虑，即面对数据中的真实世界影响，如事件激增、生产数据中断或数据处理的边缘情况，模型可能会偏离轨道并严重失败。这些都是合理的顾虑，最好通过了解可能的影响以及模型对这些影响的反应来解决。这意味着在离线实验中模拟这些效应，探测模型对它们的敏感性，并观察模型的恢复时间。这些信息将为模型操作员提供一份操作手册，帮助他们在出现这些问题时快速、恰当地做出反应。</p><h1 id="338d" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">治理现代化</h1><p id="1721" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">我们上面讨论的信任问题为现有模型治理框架内的深度学习带来了3个未回答的核心挑战，每个挑战都需要新的策略来提供模型用户正确需要的信任级别。这些挑战是:</p><p id="48c2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">1.如何估计我们在一个特定的预测中应该具有的置信度？</p><p id="23d9" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">2.如何解释导致特定决策的逻辑。</p><p id="4530" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">3.如何保证公平？</p><p id="2fa9" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这些挑战可以通过对模型有效性进行严格和持续的统计测试来加强我们的监控工作，或者通过将支持算法整合到我们的建模堆栈中来克服。让我们从关注改进治理测试制度开始。</p><h1 id="2f92" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">适合度</h1><p id="3bd8" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">对机器学习模型的严格测试意味着理解模型在其预测中的优势和劣势，包括在开始时和在持续的基础上，因为这些优势由于概念漂移而演变。建立信任的最直接方法是校准模型的预测，这将分数转化为概率，然后对模型的概率进行拟合优度测试。下面的例子展示了这种分析所产生的视觉化。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/1db7ea21822242f0bb3736aaca90dc20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*C_FIPRINodLcjmM8Ab4qZA.png"/></div></figure><p id="77dd" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> <em class="lk">图1: </em> </strong> <em class="lk">对信息特征的拟合优度分析(用直方图均衡化宁滨计算)。该特征在低值时显示出适度过度拟合的迹象，因为在测试集(右)中的预测和观察之间存在系统偏差，而在训练集(左)中则没有。在&gt; 1的最右边的容器也引入了复杂的结构，这需要分类器学习更多的非线性，因此应该理解这种结构的原因和含义。作者图片。</em></p><p id="1dd3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">针对拒绝验证集的模型分数被聚合到离散桶内的分数分布中，这里由落入特定范围内的特征值来定义。在该桶中，分数分布通过位置参数(平均分数)和比例参数(分数相对于平均值的标准偏差)进行总结。然后，可以将平均值及其不确定性与观察到的欺诈发生率进行比较——一个拟合良好的模型应该在平均值和观察到的发生率之间没有统计上的显著偏差。偏差的出现意味着模型预测不好，不应该被信任。在模型开发过程中，这些图有助于提高模型性能。它们允许我们清楚地查看每个特征值对分数的依赖性。如果观察到偏差，可能是由过度拟合(在这种情况下，观察到的偏差在训练集的预测中不存在)或欠拟合(在这种情况下，观察到的偏差在训练和测试数据中都存在)引起的。如果一个桶内的标准偏差很大，这告诉我们该特征在很大程度上被该桶内的模型忽略(即:其他特征支配分数)。</p><p id="0d18" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">出于治理的目的，当在持续的基础上应用于模型开发之后产生的分数时，这些分析变得特别强大。它们可以有效地检测模型退化，并识别模型退化的特征空间区域。存储桶可以由我们知道的输入数据样本的任何属性来定义，不管它是否被模型使用。这意味着我们可以监控受保护属性的适合度，或者我们在推理时不知道的属性。最有力的是，我们可以将桶定义为神经网络中神经元激活空间的高粒度集群。虽然我们可能无法解释这些分类的意义，但我们使用包含预测的分类的观察拟合优度作为代理，获得了每个预测的持续更新的拟合优度度量。对于每个聚类，偏差是对模型得分准确性的估计，标准差给出了对整个聚类得分函数的梯度和结构的估计。</p><p id="2d80" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">拟合优度分析是使用严格测试使不透明模型变得更加透明的强大而直观的方法，也是解决现代模型治理的第一个挑战的有效方法。这种思维方式正在人工智能行业获得更大的牵引力，有时会以稍微不同的形式出现，例如信任分数<a class="ae mi" href="#_ftn6" rel="noopener ugc nofollow">【6】</a>。</p><h1 id="e691" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">公平</h1><p id="d432" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">拟合优度方法还可以帮助应对公平保证的挑战——我们将能够不断测试预测的模型决策<strong class="kq ja"><em class="lk"/></strong>(公平的三种流行衡量标准之一<a class="ae mi" href="#_ftn7" rel="noopener ugc nofollow">【7】</a>)。这意味着我们不断地断言，模型的预测必须无偏差地反映原始数据中观察到的结果趋势。然而，充分性测试不能防止对受保护属性的不同影响——对大多数人来说，这是公平的最直观的伦理定义。</p><p id="c141" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在公平的其他两个定义中，不同的影响被认为是不同的。</p><p id="ed81" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">有了<strong class="kq ja"> <em class="lk">独立性</em> </strong>保证，我们要求对于受保护属性的不同可能值，模型预测没有差异。这意味着二元分类器的分数分布应该是相同的，不管受保护属性的值如何。</p><p id="2bda" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">利用<strong class="kq ja"> <em class="lk">分离</em> </strong>保证，我们要求对于受保护属性的不同值，给定底层类的样本没有差异。对于欺诈预测，这意味着欺诈和真实示例应该分别接收对于受保护属性的所有值都相同的分数分布，但是对于每个受保护属性，所有示例的组合分数分布可能不同。这相当于要求受保护属性的每个值的ROC曲线必须对齐-该模型同样擅长于分离所有受保护属性值的类。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mx"><img src="../Images/579dad5ff91e1e6af85cfc05ea5a3d83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OKHfFPxRYhaGBS7RNNKRrw.jpeg"/></div></div></figure><p id="e8c6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> <em class="lk">图2: </em> </strong> <em class="lk">在这些简单的例子中，左边的模型满足独立性保证——A、B和c组的分数分布是相同的。但是，它不满足充分性保证——A和c组的分数相对于基本事实是有偏差的。相反，右边校准良好的模型满足充分性保证，因为所有组的分数分布相对于基本事实是无偏的。作者图片。</em></p><p id="56e7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">分离的一个变体是<strong class="kq ja"> <em class="lk">机会均等</em> </strong>的概念，它要求无风险类别的分数分布对于每个受保护的属性值都是相等的——“好客户”不应因为其受保护的属性而被阻止。</p><p id="6310" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这些定义可以在持续的基础上直接测试。如果发现差异，可以通过校准分数<a class="ae mi" href="#_ftn8" rel="noopener ugc nofollow">【8】</a>来强制独立或分离。独立性也可以在训练时“嵌入”,要么通过清除不需要的相关性的训练数据，例如使用可变公平自动编码器<a class="ae mi" href="#_ftn9" rel="noopener ugc nofollow">【9】</a>，要么通过惩罚分类器损失函数中的依赖性。</p><p id="2a51" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">需要注意的一点是，这三种对公平的定义是相互排斥的。当我们谈论构建一个“公平”的分类器时，我们明确地选择了要观察的公平的定义。这种选择在行业中还没有标准化。</p><h1 id="e446" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">说明</h1><p id="c3f4" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">持续测试可能会解决接受复杂人工智能的大多数挑战，但仍然需要总结每个预测的决策逻辑——这是我们治理挑战的第三个。像这样的解释，如果准确的话，可以通过揭示特定结果背后的逻辑，在模型开发过程中防止糟糕的逻辑。当错误背后的推理能够被理解时，它会建立更大的信任。当我们能够自己判断决策者的错误是由糟糕的逻辑造成的，还是仅仅因为运气不好，我们就会信任他们。</p><p id="7f40" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">有几种算法可以将分数归属于输入要素。SHAP<a class="ae mi" href="#_ftn10" rel="noopener ugc nofollow">【10】</a>，基于博弈论的Shapley值，特别受树型模型的欢迎。尽管该算法通常随输入特征的数量呈指数缩放(使得该方法对于几乎所有真实模型都不可行)，但TreeSHAP变体具有与输入特征的对数缩放<a class="ae mi" href="#_ftn11" rel="noopener ugc nofollow">【11】</a>。一种解释方法是为深度学习模型配备“解释器模型”(explainer model)，这是一种基于树的集成模型，使用工程特征来预测深度学习模型产生的分数。来自深度模型的得分函数通常比潜在的地面真相更容易拟合<a class="ae mi" href="#_ftn12" rel="noopener ugc nofollow">【12】</a>，SHAP对这些工程特征的归因是有意义的，因为这些特征被设计成对人类有意义的编码信号。</p><p id="842b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然而，我们可以做得更好。像综合梯度<a class="ae mi" href="#_ftn13" rel="noopener ugc nofollow">【13】</a>或分层相关性传播<a class="ae mi" href="#_ftn14" rel="noopener ugc nofollow">【14】</a>这样的方法可以将神经网络得分直接归因于输入数据。在图像识别中，当归因于原始输入数据(在这种情况下，图像像素)时，这些方法是成功的，产生指示像素重要性的热图。人类分析师可以以有意义和有用的方式解释这些像素属性。对于欺诈分析，这意味着直接归因于原始输入交易流中的字段，生成客户交易历史的热图。</p><p id="004d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">热图不同于传统的解释方法，如SHAP或逻辑回归权重，因为它们不归因于人类设计的封装可解释概念的特征。相反，他们归因于原始数据。这意味着用户必须根据具体情况解释逻辑。人类已经被训练识别复杂的模式，并从交易历史中构建有意义的叙述，因此这种方法将充分支持对个体预测的彻底分析。</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/3b964a5f13ff3fa14ed2737a1bb09c9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*yam5laS0jqKkBWg0qIlW5A.png"/></div></figure><p id="7490" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> <em class="lk">图4: </em> </strong> <em class="lk">字段重要性信用卡交易序列的热图，用于解释分配给最终交易的高分。在本例中，多种因素在起作用—在不尝试地址验证(AVS匹配)的高风险商家处花费了大量资金。此外，交易之前紧接着是潜在的低价值测试交易，这是一种标准的欺诈类型。图片作者。</em></p><h1 id="2de6" class="ll lm iq bd ln lo lp lq lr ls lt lu lv kf lw kg lx ki ly kj lz kl ma km mb mc bi translated">结论</h1><p id="2e9f" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">为了在不透明的模型中建立信任，我们不仅需要证明其设计决策合理的审计跟踪，我们还需要继续相信该模型在其遇到的所有场景中都得到了很好的校准，继续相信决策是公平的，以及为个人预测可视化模式识别过程的方法。这些先决条件中的三个归结为统计测试。斯坦福大学机器学习教授、Coursera和谷歌大脑的联合创始人吴恩达认为，通过类比我们在医疗保健领域的信任机制，测试是信任人工智能的充分基础:</p><p id="3486" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> <em class="lk">“我们很多人都愿意服用生化效果无人完全了解的药用药物。我们信任这些药物，因为它们已经通过了随机临床试验，并获得了FDA的批准。同样，[不透明的]人工智能算法可能会通过严格的测试获得我们的信任。”——吴恩达。</em></strong><a class="ae mi" href="#_ftn16" rel="noopener ugc nofollow"><strong class="kq ja"><em class="lk"/></strong></a></p><p id="acbf" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果我们可以彻底测试深度学习模型，我们可以在不同条件下将透明度引入模型的结果，我们可以了解该结果的可靠性。这使我们处于一个知情的位置，我们可以负责任地使用不透明的模型，因为我们有一个在现实世界场景中信任这些模型的基础。要做到这一点，测试必须对这些场景应用预测质量的相关统计度量，以便我们了解模型在哪里有效，以及它是否公平。此外，这种测试必须是持续的——整合到我们的模型监控中，以确保我们的信任在现实世界不断变化的条件下是稳健的。模型解释通过增加单个预测的透明度在这里起到了支持作用，这对于模型预测不正确的情况尤其重要。我们可以接受模特不走运，但我们不能接受她们不明智。</p><p id="bf4f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">深度学习将在未来几年彻底改变欺诈预测，提供欺诈团队渴望和消费者期待的增强保护级别。为了消费者，我们有责任提升我们的治理框架，将这些模型投入生产。</p><p id="e7bd" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae mi" href="#_ftnref1" rel="noopener ugc nofollow">【1】</a>p . Parkinson，<a class="ae mi" href="https://www.federalreserve.gov/supervisionreg/srletters/sr1107.htm" rel="noopener ugc nofollow" target="_blank">SR 11–7:模型风险管理指南</a> (2011)美国联邦储备系统董事会</p><p id="cd78" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae mi" href="#_ftnref2" rel="noopener ugc nofollow">【2】</a><a class="ae mi" href="https://www.ukfinance.org.uk/system/files/Fraud%20The%20Facts%202021-%20FINAL.pdf" rel="noopener ugc nofollow" target="_blank">欺诈—事实2021，支付行业欺诈的权威概述</a> (2021)英国金融</p><p id="7b37" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae mi" href="#_ftnref3" rel="noopener ugc nofollow">【3】</a>a . vas Wani，N. Shazeer，N. Parmar，J. Uszkoreit，L. Jones，A. Gomez，L. Kaiser和I. Polosukhin，<a class="ae mi" href="https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" rel="noopener ugc nofollow" target="_blank">注意力是你所需要的一切</a> (2017)谷歌大脑、谷歌研究院和多伦多大学</p><p id="f1e5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae mi" href="#_ftnref4" rel="noopener ugc nofollow"/>s . hoch Reiter和J. Schmidhuber，<a class="ae mi" href="https://www.researchgate.net/publication/13853244_Long_Short-term_Memory" rel="noopener ugc nofollow" target="_blank">长短期记忆</a> (1997)神经计算，麻省理工学院出版社</p><p id="a317" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae mi" href="#_ftnref5" rel="noopener ugc nofollow">【5】</a>k . Cho，b . merrinboer，C. Gulcehre，D. Bahdanau，F. Bougares，H. Schwenk和Y. Bengio，<a class="ae mi" href="https://arxiv.org/pdf/1406.1078.pdf" rel="noopener ugc nofollow" target="_blank">使用RNN编码器-解码器学习短语表示用于统计机器翻译</a> (2014)蒙特利尔大学，雅各布大学，缅因大学</p><p id="223e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae mi" href="#_ftnref6" rel="noopener ugc nofollow">【6】</a>a . Wong，X. Wang和A. Hryniowski，<a class="ae mi" href="https://arxiv.org/abs/2009.05835" rel="noopener ugc nofollow" target="_blank">我们能真正信任你们多少？走向简单、可解释的深度神经网络信任量化指标</a> (2020)康奈尔大学</p><p id="7c6e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae mi" href="#_ftnref7" rel="noopener ugc nofollow">【7】</a>s . Barocas，M. Hardt和A. Narayanan，<a class="ae mi" href="https://fairmlbook.org/pdf/fairmlbook.pdf" rel="noopener ugc nofollow" target="_blank">机器学习中的公平:限制与机遇</a> (2020)康奈尔大学、加州大学伯克利分校和普林斯顿大学</p><p id="7999" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae mi" href="#_ftnref8" rel="noopener ugc nofollow">【8】</a>m . Hardt，E. Price和N. Srebro，<a class="ae mi" href="https://papers.nips.cc/paper/2016/file/9d2682367c3935defcb1f9e247a97c0d-Paper.pdf" rel="noopener ugc nofollow" target="_blank">监督学习中的机会平等</a> (2016)谷歌、UT Austin和TTI-芝加哥</p><p id="edfa" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae mi" href="#_ftnref9" rel="noopener ugc nofollow">【9】</a>c . Louizos，K. Swersky，Y. Li，M. Welling和R. Zemel，<a class="ae mi" href="https://arxiv.org/abs/1511.00830v6" rel="noopener ugc nofollow" target="_blank">变分公平自动编码器</a> (2016)阿姆斯特丹大学、多伦多大学、加拿大高等研究院和加州大学欧文分校</p><p id="c5e4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae mi" href="#_ftnref10" rel="noopener ugc nofollow">【10】</a>s . Lundberg和S. Lee，<a class="ae mi" href="https://papers.nips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf" rel="noopener ugc nofollow" target="_blank">解释模型预测的统一方法</a> (2017)华盛顿大学</p><p id="26a7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae mi" href="#_ftnref11" rel="noopener ugc nofollow">【11】</a>s . Lundberg，G. Erion和S. Lee，<a class="ae mi" href="https://arxiv.org/abs/1802.03888" rel="noopener ugc nofollow" target="_blank">树集合的一致个性化特征归属</a> (2018)华盛顿大学</p><p id="6063" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae mi" href="#_ftnref12" rel="noopener ugc nofollow">【12】</a>l . Ba和R. Caruana，<a class="ae mi" href="http://datascienceassn.org/sites/default/files/Do%20Deep%20Nets%20Really%20Need%20to%20be%20Deep.pdf" rel="noopener ugc nofollow" target="_blank">深网真的需要深吗？</a> (2013)多伦多大学和微软研究院</p><p id="3ef5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae mi" href="#_ftnref13" rel="noopener ugc nofollow">【13】</a>m . Sundararajan，A. Taly和Q. Yan，<a class="ae mi" href="https://arxiv.org/pdf/1703.01365.pdf" rel="noopener ugc nofollow" target="_blank">深度网络的公理化归因</a> (2017)斯坦福大学和谷歌</p><p id="adab" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae mi" href="#_ftnref14" rel="noopener ugc nofollow">【14】</a>s . Bach，A. Binder，G. Montavon，F. Klauschen，K. Müller和W. Samek等人<a class="ae mi" href="https://www.semanticscholar.org/paper/On-Pixel-Wise-Explanations-for-Non-Linear-Decisions-Bach-Binder/17a273bbd4448083b01b5a9389b3c37f5425aac0" rel="noopener ugc nofollow" target="_blank">关于通过逐层相关性传播对非线性分类器决策的逐像素解释</a> (2015) PLoS ONE</p><p id="4702" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae mi" href="#_ftnref16" rel="noopener ugc nofollow">【15】</a>a . Ng，<a class="ae mi" href="https://blog.deeplearning.ai/blog/google-ai-explains-itself-neural-net-fights-bias-ai-demoralizes-champions-solar-power-heats-up" rel="noopener ugc nofollow" target="_blank">亲爱的朋友们</a> (2019) deeplearning.ai</p></div></div>    
</body>
</html>