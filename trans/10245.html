<html>
<head>
<title>Will You Let Self-Driving Cars Make Moral Decisions?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你会让自动驾驶汽车做出道德决定吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/will-you-let-self-driving-cars-make-moral-decisions-43f23139ba5c?source=collection_archive---------31-----------------------#2021-09-28">https://towardsdatascience.com/will-you-let-self-driving-cars-make-moral-decisions-43f23139ba5c?source=collection_archive---------31-----------------------#2021-09-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="cff8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">重要的是要思考为什么无人驾驶汽车如此难以实现</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/71d7c986eb7cf6fcf1cd19f96b5512e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*sDHoDwsQ7wZjeri1"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">来源:<a class="ae kr" href="https://pixabay.com/photos/vehicle-autonomous-4759347/" rel="noopener ugc nofollow" target="_blank"> pixabay </a></p></figure><p id="0a16" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">无论你对自动驾驶汽车(AV)有什么感觉，世界上最大的公司似乎都无法投入足够的资金来实现它们。被认为处于领先地位的Waymo公司已经花费了惊人的<a class="ae kr" href="https://www.caranddriver.com/news/a30857661/autonomous-car-self-driving-research-expensive/" rel="noopener ugc nofollow" target="_blank">~ 35亿美元</a>！这是将极大改变我们日常生活方式的事情之一。</p><p id="71a4" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">随着AVs的出现，我们希望看到交通流量效率的提高和更低的碳排放。想想基本上有很多拼车，它们不会在路上暴怒，以非常可预测的方式行动，并能在突发情况下做出瞬间决定。这对鹿来说可能更好🦌宾夕法尼亚州的人口也是如此。</p><p id="81f5" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">对于像优步这样的公司来说，这意味着更可预测的司机供应，而对于司机来说，这可能意味着大规模的失业和再培训需求。但是，在我们超越自我，开始担心我们的工作，或者为路上少了一些人而庆祝之前，思考一下为什么无人驾驶汽车如此难以实现是至关重要的。</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><h1 id="e332" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">进退两难</h1><p id="1e8a" class="pw-post-body-paragraph ks kt iq ku b kv mn jr kx ky mo ju la lb mp ld le lf mq lh li lj mr ll lm ln ij bi translated">几十年前，即使是今天的智能手机也会被认为是“不可能的”。回顾技术的巨大飞跃，我们有时会忘记引领我们走到今天的渐进式变革。因此，唯一合理的假设是汽车也将演变成AVs，甚至可能是我们甚至不认为是汽车的东西。</p><p id="3f19" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">问题并不在于制造无人驾驶汽车的技术方面。那就是我们大多数人现在生活的这个世界，并不是用来对付他们的。我们设计这个世界的思想是让人们来做决定，而不是<strong class="ku ir">机器。</strong></p><h2 id="80d7" class="ms lw iq bd lx mt mu dn mb mv mw dp mf lb mx my mh lf mz na mj lj nb nc ml nd bi translated">快速决策意味着什么</h2><p id="6869" class="pw-post-body-paragraph ks kt iq ku b kv mn jr kx ky mo ju la lb mp ld le lf mq lh li lj mr ll lm ln ij bi translated">让我们假设我们有一辆汽车，一辆自动驾驶的汽车，或者一辆安全的汽车。现在<em class="ne"> Sav </em>基本上能做你作为司机能做的事，但它能做到精准，不累，用心。基本上Sav是最好的驱动。它没有任何瑕疵，它做的每一件事，采取的每一个行动都没有随机性。</p><p id="a554" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">一天，你在<em class="ne"> Sav </em>里开车，突然，刹车失灵了。<em class="ne"> Sav </em>，虽然是个完美的驾驶员，但也不是神仙，只能反应。但你应该庆幸不是你在开车，因为作为人类，我们往往会很恐慌。有压力的情况不是快速做出决定的最佳场所，尤其是那些涉及我们生活的情况。</p><p id="91cd" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">啊哦，你看到前面有一条人行横道，上面有一些人。<em class="ne"> Sav </em>也看到了这一点，并且* <strong class="ku ir">哔哔</strong> *之后，它意识到它只有两种可能的结果。要么转向一边，避免撞到行人，但对你造成致命伤害，要么直行，对随机出现的人造成致命伤害，但救了你的命。</p><p id="640f" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">谁应该优先选择生命的道德困境？如果它真的做出了选择，我们作为社会将如何应对？</p><h2 id="898c" class="ms lw iq bd lx mt mu dn mb mv mw dp mf lb mx my mh lf mz na mj lj nb nc ml nd bi translated">为什么这么重要？</h2><p id="0ef6" class="pw-post-body-paragraph ks kt iq ku b kv mn jr kx ky mo ju la lb mp ld le lf mq lh li lj mr ll lm ln ij bi translated">如果你或我在这种情况下，我们会怎么做？很有可能我们甚至无法想到所有可能的结果或确定幸存的概率。我们很可能会等太久才做出决定，然后最终做出一个不合格的决定，很可能伤害到所有相关人员。</p><p id="a0ba" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">那么，如果<em class="ne"> Sav </em>做了更优化的事情，为什么会有问题呢？首先，最优是非常主观的。在这种情况下，每个人的最佳选择至少是他们自己的生存。问题不在于我们做了一个糟糕的决定，而在于我们决定背后的意图和推理。</p><p id="d19e" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">不可否认的事实是，作为人类，我们不擅长做决定。幸运的是，Sav没有得到同样的好处。当它做出决定时，我们确切地知道它为什么做出决定。不存在随机性。如果它选择拯救一个生命而不是另一个，我们知道它做了一个计算，在那里它赋予人的生命价值。</p><p id="41b7" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">你希望这些车出现在你的街道上吗？你坐在车里舒服吗？如果Sav的公司要求你签署一份免责声明，免除他们的任何责任，你会这样做吗？或者你想预先选择Sav应该如何做出这些决定？</p><h1 id="0a46" class="lv lw iq bd lx ly nf ma mb mc ng me mf jw nh jx mh jz ni ka mj kc nj kd ml mm bi translated">把道德还给人民？</h1><p id="3d3e" class="pw-post-body-paragraph ks kt iq ku b kv mn jr kx ky mo ju la lb mp ld le lf mq lh li lj mr ll lm ln ij bi translated">好的，我们知道<em class="ne"> Sav </em>只能根据它的算法来决定生死。我们可以让Sav 在只有一两个选择的情况下随机行动。但我真的不认为我们作为社会会真的对一些被建造得更加准确和决定性的东西感到高兴，突然选择让生活在一个它完全控制的地方由随机机会决定。</p><p id="f999" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">回车，<a class="ae kr" href="https://www.moralmachine.net/" rel="noopener ugc nofollow" target="_blank"><strong class="ku ir"/></a><strong class="ku ir">。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nk"><img src="../Images/32a0490686e0d440f8280b9ad1166520.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eaHkhcGbJ4cbzXqp"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">你会选择什么？ <em class="nq">来源</em> <a class="ae kr" href="https://www.media.mit.edu/projects/moral-machine/overview/" rel="noopener ugc nofollow" target="_blank"> <em class="nq">刻字机</em> </a></p></figure><p id="1670" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">MoralMachine是麻省理工学院媒体实验室建立的一个平台，用来收集关于我们如何做出艰难决定的观点。这个想法是在我们处于能够正确思考的精神状态时问我们这些问题，就像计算机不会受到周围发生的事情的情绪影响一样。</p><p id="562f" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">该平台为每个人提供了一组场景，一个接一个，询问汽车应该采取什么行动。无论是两组行人，还是乘客对行人，每一个动作都会导致某种形式的死亡。</p><p id="45a5" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">它变得更加有趣(或令人震惊)的地方是我们被测试我们会赋予什么更多价值的地方。我们是否经常选择去拯救那些更年轻的人？我们区分动物和人类的生命吗？有人乱穿马路有关系吗？</p><p id="36df" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">由此产生的问题是，政策制定者和汽车制造商是否应该合作使用这些数据，民主地选择Sav的行为方式。在一个民主国家，我们投票给我们的政治领袖，以及他们所代表的价值观。即使这些价值观并不适合所有人，也没关系。如果大多数人希望以某种方式实现，他们就赢了。</p><blockquote class="nr ns nt"><p id="55fe" class="ks kt ne ku b kv kw jr kx ky kz ju la nu lc ld le nv lg lh li nw lk ll lm ln ij bi translated">“但是，当连伦理学家都不能就基本真理——或其近似值——达成一致时，社会怎么能达成一致呢”</p><p id="bac3" class="ks kt ne ku b kv kw jr kx ky kz ju la nu lc ld le nv lg lh li nw lk ll lm ln ij bi translated"><strong class="ku ir"> <em class="iq">“道德机器”的阴暗面和自动驾驶汽车计算伦理决策的谬误</em> </strong></p></blockquote><p id="d3e9" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这就是为什么让道德机器用于任何形式的政策制定都不是一个好主意。当然，我们可以让每个人在人口统计学上做出选择，但这总是会让一些人比其他人更不安全。根据该平台目前的结果，年轻人口可能从中受益。人们基本上不再走在马路旁边。因为总会有比你年轻的人出现在AV中，对他们来说你的生命就没那么重要了。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/c94fea3fd86ab4e0a243dedc4c0501dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*HdjpKgvneo9kVdXWGUuqkA.jpeg"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">我们看重什么？来源:<a class="ae kr" href="https://www.media.mit.edu/projects/moral-machine/overview/" rel="noopener ugc nofollow" target="_blank"> MoralMachine </a></p></figure><p id="04da" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">同样，人们必须首先权衡进入汽车的风险。这样做，他们冒着让一个更年轻的行人来到车前的风险，触发<em class="ne"> Sav </em>的生命价值分配算法，让你知道你的生命价值降低了。</p><p id="d514" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这只是我在这里关注的一个特征，想象一下其他少数民族会是什么样子？我们将开始需要一个早晨提醒，提醒我们开车或走路的风险，这取决于我们周围当前的社会人口统计。这太荒谬了。</p><h1 id="e84b" class="lv lw iq bd lx ly nf ma mb mc ng me mf jw nh jx mh jz ni ka mj kc nj kd ml mm bi translated">自驾只是白日梦吗？</h1><p id="4a0e" class="pw-post-body-paragraph ks kt iq ku b kv mn jr kx ky mo ju la lb mp ld le lf mq lh li lj mr ll lm ln ij bi translated">人工智能中的伦理和道德已成为将越来越多的人工智能融入我们生活的最大挑战之一。公司有盈利的倾向，个人有不同的价值观，他们希望保持真实。任何可用的技术都会有一定的偏见，无论是基于工程师还是组织。</p><p id="b91f" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">对于自动驾驶汽车，我们需要改变设置和评估其行为的框架。</p><h2 id="6f5c" class="ms lw iq bd lx mt mu dn mb mv mw dp mf lb mx my mh lf mz na mj lj nb nc ml nd bi translated">1.重新设计结构</h2><p id="5463" class="pw-post-body-paragraph ks kt iq ku b kv mn jr kx ky mo ju la lb mp ld le lf mq lh li lj mr ll lm ln ij bi translated">当我们想到自动驾驶时，我们想象的是世界的样子，区别在于自动驾驶汽车。相反，也许解决方案还在于更新世界，或者至少交通部门，需要看起来有点不同。人行横道、道路、交通信号灯、停车标志，所有这些都是基于这样一种假设，即人类需要相互协作来维护安全。无人驾驶汽车不一定需要同样的基础设施。类似于地铁系统如何与道路并行，也许我们也需要重新设计城市，以不同于我们目前的方式融入行人。</p><h2 id="ed07" class="ms lw iq bd lx mt mu dn mb mv mw dp mf lb mx my mh lf mz na mj lj nb nc ml nd bi translated">2.重塑我们的思维方式</h2><p id="1c49" class="pw-post-body-paragraph ks kt iq ku b kv mn jr kx ky mo ju la lb mp ld le lf mq lh li lj mr ll lm ln ij bi translated">值得注意的是，尽管道德机器让我们相信AV必须基于道德做出决定，但试图将道德和伦理纳入机器并没有真正的好处。因为我们作为人类还不能弄清楚什么是道德上正确的，我们没有办法实际上把它结合到机器中去执行。</p><blockquote class="nr ns nt"><p id="cc70" class="ks kt ne ku b kv kw jr kx ky kz ju la nu lc ld le nv lg lh li nw lk ll lm ln ij bi translated">问题不在于一辆汽车是否应该为了救五个人而杀死一个人，而是这项技术的引入将如何塑造和改变周围所有人的权利、生活和利益。</p><p id="8164" class="ks kt ne ku b kv kw jr kx ky kz ju la nu lc ld le nv lg lh li nw lk ll lm ln ij bi translated"><a class="ae kr" href="https://www.brookings.edu/research/the-folly-of-trolleys-ethical-challenges-and-autonomous-vehicles/" rel="noopener ugc nofollow" target="_blank"> <em class="iq">无轨电车的愚蠢:伦理挑战与自动驾驶汽车</em> </a></p></blockquote><p id="c878" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这里的论点是，AI的行为使用概率来确定要做什么。它将基于事件的不同概率，以及采取这些行动的结果的价值，试图最大化总收益。我们不应该也不能将不同人口统计或人口的生活价值观模型化到它的决策中。</p><p id="7e0d" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如果你看过任何机器人试图保护人类免受其害的科幻电影，如“瓦力”，给AI分配道德任务通常是事情开始出错的地方。</p><p id="2edd" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">因此，与其关注<em class="ne"> Sav </em>在这些一次性情况下会做什么，我们需要了解<em class="ne"> Sav </em>实际上是如何做出决策的，并从中消除尽可能多的偏见。思考《道德机器》中提出的道德问题会分散注意力。</p><h1 id="4515" class="lv lw iq bd lx ly nf ma mb mc ng me mf jw nh jx mh jz ni ka mj kc nj kd ml mm bi translated">资源</h1><ul class=""><li id="0dbe" class="ny nz iq ku b kv mn ky mo lb oa lf ob lj oc ln od oe of og bi translated"><a class="ae kr" href="https://spectrum.ieee.org/people-want-driverless-cars-with-utilitarian-ethics-unless-theyre-a-passenger" rel="noopener ugc nofollow" target="_blank">人们想要有功利主义道德观的无人驾驶汽车，除非他们是乘客</a></li><li id="0698" class="ny nz iq ku b kv oh ky oi lb oj lf ok lj ol ln od oe of og bi translated">无人驾驶汽车的困境揭示了道德选择并不普遍</li><li id="78db" class="ny nz iq ku b kv oh ky oi lb oj lf ok lj ol ln od oe of og bi translated"><a class="ae kr" href="https://www.brookings.edu/research/the-folly-of-trolleys-ethical-challenges-and-autonomous-vehicles/" rel="noopener ugc nofollow" target="_blank">无轨电车的愚蠢:伦理挑战和自动驾驶汽车</a></li><li id="d8e9" class="ny nz iq ku b kv oh ky oi lb oj lf ok lj ol ln od oe of og bi translated"><a class="ae kr" href="https://www.tandfonline.com/doi/abs/10.1080/17579961.2021.1898310?journalCode=rlit20" rel="noopener ugc nofollow" target="_blank">“道德机器”的阴暗面和自动驾驶汽车计算伦理决策的谬误</a></li></ul></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><p id="e234" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><em class="ne">原载于2021年9月28日https://wordsbywaseh.com</em><a class="ae kr" href="https://wordsbywaseh.com/will-you-let-self-driving-cars-make-moral-decisions/" rel="noopener ugc nofollow" target="_blank"><em class="ne"/></a><em class="ne">。</em></p></div></div>    
</body>
</html>