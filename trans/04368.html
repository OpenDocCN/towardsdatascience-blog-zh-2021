<html>
<head>
<title>Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逻辑回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/logistic-regression-cebee0728cbf?source=collection_archive---------27-----------------------#2021-04-13">https://towardsdatascience.com/logistic-regression-cebee0728cbf?source=collection_archive---------27-----------------------#2021-04-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6a5f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">或者我是如何爱上用于分类数据分类的sigmoid“变形”函数的</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/ffdf2d66230c6209a9ea55e11018f35d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*x_9HbfTvD1OpgWgAkJR4yQ.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">逻辑回归|照片由<a class="ae ku" href="https://unsplash.com/@dbossarte" rel="noopener ugc nofollow" target="_blank">丹尼斯·博萨特</a>拍摄</p></figure><p id="285e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这篇文章是我的<a class="ae ku" rel="noopener" target="_blank" href="/an-introduction-to-linear-regression-9cbb64b52d23">回归</a>系列的简要延续。</p><p id="aa84" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">到目前为止，我举例说明的回归例子都是数字:预测一个连续变量。通过高尔顿家庭身高数据集，我们预测了儿童的身高——一个不断变化的参数。然而，请注意回归线如何无法符合二元结果，分类示例:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lr"><img src="../Images/969766a81dc29829ced448e81f9f668b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_5vZcCovYSHc1sK8cuc6Ew.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">二元结果的最佳拟合线</p></figure><p id="7163" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在上面的例子中，似乎有一个影响分类结果的阈值。这个数据有一个连续的回归线是没有意义的。为什么说不通？看看两个因变量(y ):它们取两个值中的一个:0和1。没有0.25或者0.5的值，只有那两个极值。这意味着，对于这个分类问题，我们需要一个函数，它接受一个输入或一系列输入，并给出它是两个类别之一的概率:即0和1。我们可以给这些类别贴上任意标签:是或否、猫或非猫、发送促销电子邮件或不发送促销电子邮件、销售线索或不太可能的销售线索。</p><p id="bb9b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">逻辑回归对于数据科学家和机器学习工程师来说都是一个强大的工具。我会说，为了健全性检查，它应该是用于分类目的的基线模型——一个与更复杂的模型(如PCR、神经网络等)相比较的模型。</p><h1 id="2de4" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">历史</h1><ul class=""><li id="879e" class="mo mp it kx b ky mq lb mr le ms li mt lm mu lq mv mw mx my bi translated">“逻辑”一词是作为人口增长的模型发展而来的，它来自比利时数学家皮埃尔·弗朗索瓦·维赫斯特，他英年早逝，默默无闻</li><li id="80ad" class="mo mp it kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated">逻辑函数是德国化学家威廉·奥斯特瓦尔德(1883年)在化学中作为自动催化的模型独立发展起来的</li><li id="b643" class="mo mp it kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated">1920年，美国人雷蒙德·珀尔(Raymond Pearl)和洛厄尔·里德(Lowell Reed)独立地重新发现了逻辑斯蒂函数，将其作为人口增长的模型，并将其用于现代统计学。他们不知道Verhulst早期的发现，但他们不相信他，也不采用他的术语</li><li id="94c0" class="mo mp it kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated">概率单位模型是在20世纪30年代中期发展起来的，一般认为是美国生物学家切斯特·布利斯的功劳</li><li id="4635" class="mo mp it kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated">多项logit模型是由David Cox (1966)和Henri Thiel (1969)独立提出的</li></ul><h1 id="0625" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">逻辑回归</h1><p id="f677" class="pw-post-body-paragraph kv kw it kx b ky mq ju la lb mr jx ld le ne lg lh li nf lk ll lm ng lo lp lq im bi translated">为了得到逻辑回归，我们首先从经典的回归例子开始:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi nh"><img src="../Images/133157126043c8671d3e449c1494a6d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XTYpkb9w8CSLaPVC"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">经典回归</p></figure><p id="1163" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">为了开发分类模型，我们将借用数学中的sigmoid函数，通常表示如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ni"><img src="../Images/bb7ff095d9a23d069ab488e8325553a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zVc1MM0yfUo7z7Ax"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">Sigmoid公式</p></figure><p id="d545" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">重新排列并代入回归:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi nj"><img src="../Images/da23317e2037a042173caf7cd2fcc57a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JN1GwCgjAeV6G3Pw"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">逻辑回归公式</p></figure><p id="9d61" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这一系列函数的作用是给出将观察值分配给目标类的概率。一旦逻辑回归函数分配了一个概率，这就要求模型在数据集上进行拟合和训练，下面的例子是，数据点被投影到基于概率值的类中。对于大于0.5的概率值，该值被投影到1，对于我们来说是目标类，而对于小于0.5的概率值，它们被投影到0类，或者不是目标类。</p><p id="b4a0" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">标准的sigmoid函数如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/b17887e26a9ff55553f949ae284fcb48.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*5nKWsukS6lPR-7fHtlK2Rg.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">标准逻辑函数|图片来源<a class="ae ku" href="https://en.wikipedia.org/wiki/Logistic_regression#:~:text=Logistic%20regression%20is%20a%20statistical,a%20form%20of%20binary%20regression)." rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="6ba8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这将我们的原始数据集回归线转换为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi nl"><img src="../Images/6c3294bc1e0b9f7457a41160051fdc65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xBQdvDqczvLRaOhs4r8-qQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">拐点在0.5</p></figure><h2 id="6eed" class="nm lx it bd ly nn no dn mc np nq dp mg le nr ns mi li nt nu mk lm nv nw mm nx bi translated">刚刚发生了什么？</h2><p id="6bd8" class="pw-post-body-paragraph kv kw it kx b ky mq ju la lb mr jx ld le ne lg lh li nf lk ll lm ng lo lp lq im bi translated">这个“s”形是用于分类目的的强大工具。我倾向于认为给定观察值输出的给定概率值，比如0.36，逻辑回归将概率“压缩”为二进制值。解释这一点，模型是说给定的观察值属于模型被训练的目标类的概率只有36%——假设是1。这意味着有1—0.36或64%的可能性该观察值不属于目标类，因此它被标记为0 -&gt;该观察值被向下投影到因变量结果标签0。</p><p id="6242" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">逻辑回归线类似于我们之前的回归示例，但是<strong class="kx iu">我们将输出解释为将数据点分配给目标类</strong>的概率。</p><p id="1cfd" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最常见的逻辑回归是二元逻辑回归，但多项逻辑回归模型确实存在于多类回归分析中。</p><p id="7644" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">名词（noun的缩写）b:技术上可以达到0.5的数值，但是微乎其微。无论如何，你所使用的算法将会有一些关于如何分类这种边缘情况的预定义指令。</p><h2 id="baee" class="nm lx it bd ly nn no dn mc np nq dp mg le nr ns mi li nt nu mk lm nv nw mm nx bi translated">Python示例:逻辑回归</h2><p id="7394" class="pw-post-body-paragraph kv kw it kx b ky mq ju la lb mr jx ld le ne lg lh li nf lk ll lm ng lo lp lq im bi translated">为了便于说明，我将使用<code class="fe ny nz oa ob b">sklean</code>中著名的iris数据集来展示以下Jupyter笔记本单元的分类能力:</p><pre class="kj kk kl km gt oc ob od oe aw of bi"><span id="5d25" class="nm lx it ob b gy og oh l oi oj">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.metrics import accuracy_score</span><span id="ea37" class="nm lx it ob b gy ok oh l oi oj">%matplotlib inline</span></pre><p id="9770" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">创建一个df并将所有原始数据转换成<code class="fe ny nz oa ob b">sklearn:</code>熟悉的格式</p><pre class="kj kk kl km gt oc ob od oe aw of bi"><span id="526d" class="nm lx it ob b gy og oh l oi oj">from sklearn.datasets import load_iris<br/>iris = load_iris()<br/>df = pd.DataFrame(data= np.c_[iris[‘data’], iris[‘target’]],<br/> columns= [“sepel_length_cm”, “sepal_width_cm”,<br/> “petal_length_cm”, “petal_width_cm”, “target”])</span><span id="421d" class="nm lx it ob b gy ok oh l oi oj">df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/72294ebcbf57a88709f360568e6e7618.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*YAkbwj1ZDhaXpaoMJnJSug.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">数据导入良好</p></figure><pre class="kj kk kl km gt oc ob od oe aw of bi"><span id="e0c6" class="nm lx it ob b gy og oh l oi oj">df.describe()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/bab946f45334c114ed86a8e5a924310a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*CIWA71YLUQ0yo4U-Maz-Hw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">基本汇总统计</p></figure><p id="97c9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">数据集包含真正的标签，我们可以看到这三个类是多么好和可分:</p><pre class="kj kk kl km gt oc ob od oe aw of bi"><span id="e2b5" class="nm lx it ob b gy og oh l oi oj">sns.pairplot(df, height=2.5, hue=’target’)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi on"><img src="../Images/5b1a889e336aeff47f63ecd20144f7dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Z_ofh9shVH0AjMK4cDuRA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">基于可测量性的三种花的分类</p></figure><pre class="kj kk kl km gt oc ob od oe aw of bi"><span id="c774" class="nm lx it ob b gy og oh l oi oj">df[‘target’].value_counts()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/6d1531324fc12e03a98c5d148979ecd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*p2jX6HxtvU1AVw5MmqPlcw.png"/></div></figure><p id="5f44" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">注意我们有三类花，每一类有50个观察值。这个数据集非常平衡。</p><pre class="kj kk kl km gt oc ob od oe aw of bi"><span id="9ace" class="nm lx it ob b gy og oh l oi oj">X, y = load_iris(return_X_y=True)</span><span id="9994" class="nm lx it ob b gy ok oh l oi oj">X[:5]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/044e48e0c0129b13762c3480875d03a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/format:webp/1*cPbqej4xIjN_giFwD0thKw.png"/></div></figure><pre class="kj kk kl km gt oc ob od oe aw of bi"><span id="f1f4" class="nm lx it ob b gy og oh l oi oj">y[:5]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/b1fa175ce4510e5711e5562bf2bc1460.png" data-original-src="https://miro.medium.com/v2/resize:fit:354/format:webp/1*qCB4gqGzE_C_EOxrueanYA.png"/></div></figure><p id="26cc" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">以上五朵花都是0类的。</p><pre class="kj kk kl km gt oc ob od oe aw of bi"><span id="55da" class="nm lx it ob b gy og oh l oi oj">from sklearn.linear_model import LogisticRegression</span><span id="1e9a" class="nm lx it ob b gy ok oh l oi oj"># instantiate the model and fit<br/>log = LogisticRegression(multi_class=’warn’, solver=’warn’)<br/>log_reg = log.fit(X, y)</span><span id="b902" class="nm lx it ob b gy ok oh l oi oj">log_reg</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/a81687b8ca55c11ddd5425ecff8a39b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*bVOv2W3f4maK9fFhucTlGg.png"/></div></figure><pre class="kj kk kl km gt oc ob od oe aw of bi"><span id="505c" class="nm lx it ob b gy og oh l oi oj"># score the model<br/>log.score(X, y)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/89a7d6ad2b63931f3642251652ebe2fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:78/format:webp/1*Gn8a8BOg8a0vA_DRINRn3w.png"/></div></figure><p id="2827" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们可以看到，这是一个非常好的模型分数！</p><p id="3e00" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">接下来我就来说说<a class="ae ku" rel="noopener" target="_blank" href="/time-series-analysis-7138ec68754a">时间序列分析</a>！</p><p id="e165" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在<a class="ae ku" href="https://www.linkedin.com/in/james-a-w-godwin/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>上找到我</p><p id="e186" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><em class="ot">物理学家兼数据科学家——可用于新机遇| SaaS |体育|初创企业|扩大规模</em></p></div></div>    
</body>
</html>