<html>
<head>
<title>Reduced-Rank Vector Autoregressive Model for High-Dimensional Time Series Forecasting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">高维时间序列预测的降秩向量自回归模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/reduced-rank-vector-autoregressive-model-for-high-dimensional-time-series-forecasting-bdd17df6c5ab?source=collection_archive---------10-----------------------#2021-10-16">https://towardsdatascience.com/reduced-rank-vector-autoregressive-model-for-high-dimensional-time-series-forecasting-bdd17df6c5ab?source=collection_archive---------10-----------------------#2021-10-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="5624" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</h1><p id="4382" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如今，随着数据收集/可用性技术的显著发展，我们有更多的机会来处理许多科学和工业领域中的多种时间序列数据。时间序列数据有多种类型，包括单变量时间序列、多变量时间序列和多维时间序列。对于多元时间序列，数据具有多个时间相关变量，并且每个变量都依赖于其他变量。因此，向量自回归(VAR)模型是多元时间序列分析的经典方法，主要是因为它能够识别时间相关变量的共同演化模式。</p><p id="7b26" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">然而，有一种特殊情况，如果我们有大量的变量(例如，数千或数百万个变量)，但只有有限数量的时间步长，那么多元时间序列将是高维的。例如，图1直观地展示了高维时间序列数据的风险值模型。这里，高维时间序列数据被表示为<strong class="kn ir">“瘦高”矩阵</strong>。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/9b4a9c3be83dc05942e57a0fa4303b5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7lgVNlhfV7lqQf6lAjR_iw.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">图一。高维多元时间序列的VAR模型图解{ <strong class="bd me"> x </strong> 1，<strong class="bd me"> x </strong> 2，<strong class="bd me"> x </strong> 3，<strong class="bd me"> x </strong> 4}。该模型由系数矩阵<strong class="bd me"><em class="mf"/></strong>(即一个方阵)参数化。</p></figure><p id="0af6" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">在这个简单的图示中，不难看出系数矩阵中的参数很多，超过了时间序列观测值的数量。在大多数情况下，这个风险值模型是不适定的，因为它会受到<strong class="kn ir">过度参数化</strong>问题的影响。为了解决VAR中的这一问题，一个重要的方向是开发矩阵分解参数化的<strong class="kn ir">降秩VAR </strong>模型。</p><p id="86c3" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">在这篇博文中，我们介绍了一个用于多元时间序列分析的降秩VAR模型。该模型是由<em class="mg">韦卢</em>、<em class="mg">赖恩塞尔</em>和<em class="mg">威彻恩</em>于1986年提出的[1]。在此之前，<em class="mg"> Velu </em>在威斯康星大学未发表的博士论文中也讨论了某些降秩自回归模型的估计。后来在1998年，<em class="mg"> Velu </em>和<em class="mg"> Reinsel </em>出版了《多元降秩回归:理论与应用》一书[2]。</p><p id="c2b8" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">虽然降秩VAR有很长的历史，但在过去的几十年里，这篇论文并没有引起太多的关注。由于我们有许多种高维时间序列数据，许多高维VAR模型实际上持有与降秩VAR相似的思想。</p><p id="0158" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">本帖不限于之前最降级的VAR论文内容。我们还提供了降秩VAR模型的简单模型描述，并给出了一个玩具例子来说明其应用。此外，我们用Python重现了这个模型，特别是用Numpy包。</p><h1 id="0eb0" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">模型描述</h1><p id="0226" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">图1显示了VAR的基本思想。给定时间序列数据<strong class="kn ir"> <em class="mg"> X </em> </strong>的大小<em class="mg"> N </em> -by- <em class="mg"> T </em>其中<em class="mg"> N </em>是变量的数量，<em class="mg"> T </em>是时间步长的数量，则在任何时间步长<em class="mg"> t </em>中，一阶VAR或VAR(1)的形式为</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mh"><img src="../Images/f0b7130fe9ebcdb1fb2690aac73da127.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JEaVRWJMrh-uuGpn.png"/></div></div></figure><p id="5fa0" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">其中<strong class="kn ir"> <em class="mg"> x </em> </strong> <em class="mg"> t </em>表示时间<em class="mg"> t </em>的快照向量，大小为<em class="mg">N</em>-1。<strong class="kn ir"> <em class="mg"> A </em> </strong>是系数矩阵，大小为<em class="mg"> N </em> -by- <em class="mg"> N </em>。</p><p id="4d1b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">为了解决VAR中的过度参数化问题，我们可以假设系数矩阵<strong class="kn ir"><em class="mg"/></strong>具有降低的秩，并且定义两个矩阵<strong class="kn ir"><em class="mg">【W】</em></strong>(大小为<em class="mg"> N </em> -by- <em class="mg"> R </em>)和<strong class="kn ir"> <em class="mg"> V </em> </strong>(大小为<em class="mg"> R </em> -by- <em class="mg"> N </em>)，使得</p><p id="830c" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> <em class="mg">一</em></strong>=<strong class="kn ir"><em class="mg">WV</em></strong></p><p id="ebb2" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">其中系数矩阵通过矩阵分解被重新参数化。在这种情况下，它导致一个降秩的VAR模型，如图2所示。很明显，如果我们施加一个合适的降秩<em class="mg"> R </em>，分量矩阵<strong class="kn ir"> <em class="mg"> W </em> </strong>和<strong class="kn ir"> <em class="mg"> V </em> </strong>中的参数将小于系数矩阵<strong class="kn ir"><em class="mg"/></strong>中的参数。这实际上为解决高维时间序列数据中VAR的过参数化问题提供了一条技术路径。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mi"><img src="../Images/672ebcfad3913355fc303dbaf6919848.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*onpvfJ1BwamjKOKmKSHL4w.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">图二。由组件矩阵<strong class="bd me"> W </strong>和<strong class="bd me"> V </strong>参数化的降秩风险值模型的图示。这里，<strong class="bd me"> W </strong>是高瘦矩阵，而<strong class="bd me"> V </strong>是矮胖矩阵。</p></figure><p id="82fb" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">从机器学习的角度来看，为了估计降秩VAR模型中的参数，我们可以将自回归误差公式化为L2范数损失函数:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mj"><img src="../Images/6a7f00f2c7aafb39880d0adaf95d1414.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wA8y7-KKJYYo4RypFFrnFw.png"/></div></div></figure><p id="7221" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">对于这个优化问题，我们可以得到向量形式的<strong class="kn ir"> <em class="mg"> W </em> </strong>和<strong class="kn ir"> <em class="mg"> V </em> </strong>的闭式解。然而，向量形式并不是开发算法的最佳选择。这里，我们考虑一个新的优化问题:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mk"><img src="../Images/7dd008200c9b5d2cca0c586fd8d4c93c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ao9omP_Sm_amZmbFhoYVqg.png"/></div></div></figure><p id="0172" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们定义的地方</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ml"><img src="../Images/38cc418504e8f2157a3d6e85834ed437.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2_WQBJMNH4IotK2N1UvJig.png"/></div></div></figure><p id="c13c" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">并且<strong class="kn ir"> <em class="mg"> W </em> </strong>和<strong class="kn ir"> <em class="mg"> V </em> </strong>的闭合解现在由下式给出</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mm"><img src="../Images/c8472a3aef40e50155f0985c1075b366.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GXqJUNAWXvhLiJ-1tq59Nw.png"/></div></div></figure><h1 id="2d43" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">算法</h1><p id="b537" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">由于<strong class="kn ir"> <em class="mg"> W </em> </strong>的闭式解涉及<strong class="kn ir"> <em class="mg"> V </em> </strong>，而<strong class="kn ir"><em class="mg"/></strong>的闭式解涉及<strong class="kn ir"> <em class="mg"> W </em> </strong>，我们可以使用交替最小化方案。对于最小二乘解，算法实际上是交替最小二乘(ALS)。这个迭代算法只有三个主要步骤:</p><ul class=""><li id="82be" class="mn mo iq kn b ko lj ks lk kw mp la mq le mr li ms mt mu mv bi translated">用随机值初始化<strong class="kn ir"> <em class="mg"> W </em> </strong>和<strong class="kn ir"> <em class="mg"> V </em> </strong>。</li><li id="658d" class="mn mo iq kn b ko mw ks mx kw my la mz le na li ms mt mu mv bi translated">迭代第一步:用上面提到的最小二乘解更新<strong class="kn ir"> <em class="mg"> W </em> </strong>。</li><li id="1cc7" class="mn mo iq kn b ko mw ks mx kw my la mz le na li ms mt mu mv bi translated">迭代第二步:用上面提到的最小二乘解更新<strong class="kn ir"> <em class="mg"> V </em> </strong>。</li></ul><p id="ae59" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们可以在Python中为降秩VAR模型定义一个函数。</p><pre class="lp lq lr ls gt nb nc nd ne aw nf bi"><span id="58f4" class="ng jo iq nc b gy nh ni l nj nk">import numpy as np</span><span id="8924" class="ng jo iq nc b gy nl ni l nj nk">def rrvar(data, R, pred_step, maxiter = 100):<br/>    """Reduced-rank VAR algorithm."""<br/>    <br/>    N, T = data.shape<br/>    X1 = data[:, : -1]<br/>    X2 = data[:, 1 :]<br/>    V = np.random.randn(R, N)<br/>    for it in range(maxiter):<br/>        W = X2 @ np.linalg.pinv(V @ X1)<br/>        V = np.linalg.pinv(W) @ X2 @ np.linalg.pinv(X1)<br/>    mat = np.append(data, np.zeros((N, pred_step)), axis = 1)<br/>    for s in range(pred_step):<br/>        mat[:, T + s] = W @ V @ mat[:, T + s - 1]<br/>    return mat[:, - pred_step :]</span></pre><p id="d8e5" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">这是一种降秩VAR算法，其中我们有多变量时间序列数据和降秩等输入。</p><h1 id="7919" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">玩具示例</h1><p id="4fdd" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们通过考虑以下示例来评估该算法:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi nm"><img src="../Images/748cbc8126bb3ab21e486c7b642d8600.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aWpTnRQJpwGccXziIfWrMA.png"/></div></div></figure><p id="b5fb" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">示例数据的大小为20乘10，这是一个“高瘦”数据。我们将尝试将降秩设置为2，并测试算法。</p><p id="f5fa" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">用Python编写代码:</p><pre class="lp lq lr ls gt nb nc nd ne aw nf bi"><span id="50cb" class="ng jo iq nc b gy nh ni l nj nk">X = np.zeros((20, 10))<br/>for i in range(20):<br/>    X[i, :] = np.arange(i + 1, i + 11)<br/>pred_step = 2<br/>R = 2<br/>mat_hat = rrvar(X, R, pred_step)<br/>print(mat_hat)</span></pre><p id="67f9" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">结果是:</p><pre class="lp lq lr ls gt nb nc nd ne aw nf bi"><span id="d663" class="ng jo iq nc b gy nh ni l nj nk">[[11. 12.]<br/> [12. 13.]<br/> [13. 14.]<br/> [14. 15.]<br/> [15. 16.]<br/> [16. 17.]<br/> [17. 18.]<br/> [18. 19.]<br/> [19. 20.]<br/> [20. 21.]<br/> [21. 22.]<br/> [22. 23.]<br/> [23. 24.]<br/> [24. 25.]<br/> [25. 26.]<br/> [26. 27.]<br/> [27. 28.]<br/> [28. 29.]<br/> [29. 30.]<br/> [30. 31.]]</span></pre><p id="fab5" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">结果与地面真实数据完全一致。</p><h1 id="9f7f" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结论</h1><p id="e04f" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">降秩VAR是高维数据下一种重要的时间序列预测方法。它有许多优点，如压缩系数和解决VAR中的过参数化问题。除了降秩VAR中的矩阵分解工具，还有一些其他工具，如张量分解。依靠这篇文章，不难将降秩VAR模型扩展到更高阶。</p><h1 id="c484" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">参考</h1><p id="3d99" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">[1]韦卢，R. P .，赖因塞尔，G. C .，，威彻恩，D. W. (1986年)。多时间序列的降秩模型。<em class="mg">生物计量学</em>，73(1)，105–118。</p><p id="6ff9" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">[2]韦卢和赖因塞尔(1998年)。多元降秩回归:理论与应用。斯普林格科学与商业媒体。</p><p id="cccf" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">[3]陈新宇(2021)。多维时间序列预测的矩阵自回归模型。中等。网址:<a class="ae nn" rel="noopener" target="_blank" href="/matrix-autoregressive-model-for-multidimensional-time-series-forecasting-6a4d7dce5143">https://towards data science . com/matrix-auto regressive-model-for-dimensional-time-series-forecasting-6a 4d 7d ce 5143</a></p></div></div>    
</body>
</html>