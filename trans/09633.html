<html>
<head>
<title>How to Work with Million-row Datasets Like a Pro</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何像专家一样处理百万行数据集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-work-with-million-row-datasets-like-a-pro-76fb5c381cdd?source=collection_archive---------2-----------------------#2021-09-08">https://towardsdatascience.com/how-to-work-with-million-row-datasets-like-a-pro-76fb5c381cdd?source=collection_archive---------2-----------------------#2021-09-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="6dcf" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><div class=""><h2 id="b09e" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">是时候卸下你的训练轮了</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/d47a68bf267834423ffbf0ff04dfad79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bUX-lSoJ4VMQz2YnmSwgFA.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lh">图片由</strong><a class="ae li" href="https://www.pexels.com/@belart84?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"><strong class="bd lh">Artem Beliaikin</strong></a><strong class="bd lh">上的</strong> <a class="ae li" href="https://www.pexels.com/photo/aerial-photo-of-woman-standing-in-flower-field-1657974/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> <strong class="bd lh">像素组成。</strong> </a> <strong class="bd lh">除特别注明外，所有图片均为作者所有。</strong></p></figure><h1 id="dc0c" class="lj lk it bd ll lm ln lo lp lq lr ls lt ki lu kj lv kl lw km lx ko ly kp lz ma bi translated">介绍</h1><p id="2cf4" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">在我的学习旅程中，最困难的一个阶段是克服我对大规模数据集的恐惧。这并不容易，因为处理百万行的数据集与在线课程不断给我的小玩具数据集完全不同。</p><p id="be72" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">今天，我在这里分享我学到的概念和技巧，以应对具有数百万甚至数十亿行的千兆字节大小的数据集的挑战。最终，他们会让你觉得就像处理爱丽丝或者泰坦尼克号一样自然。</p><p id="1faf" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">这篇文章的笔记本可以在Kaggle <a class="ae li" href="https://www.kaggle.com/bextuychiev/how-to-work-w-million-row-datasets-like-a-pro" rel="noopener ugc nofollow" target="_blank">这里</a>或者从<a class="ae li" href="https://github.com/BexTuychiev/medium_stories/tree/master/2021/september/4_mln_row_datasets" rel="noopener ugc nofollow" target="_blank">这个</a>回购上找到。</p><div class="nc nd gp gr ne nf"><a href="https://ibexorigin.medium.com/membership" rel="noopener follow" target="_blank"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd jd gy z fp nk fr fs nl fu fw jc bi translated">通过我的推荐链接加入Medium-BEXGBoost</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">获得独家访问我的所有⚡premium⚡内容和所有媒体没有限制。支持我的工作，给我买一个…</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">ibexorigin.medium.com</p></div></div><div class="no l"><div class="np l nq nr ns no nt lb nf"/></div></div></a></div><p id="ef20" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">获得由强大的AI-Alpha信号选择和总结的最佳和最新的ML和AI论文:</p><div class="nc nd gp gr ne nf"><a href="https://alphasignal.ai/?referrer=Bex" rel="noopener  ugc nofollow" target="_blank"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd jd gy z fp nk fr fs nl fu fw jc bi translated">阿尔法信号|机器学习的极品。艾总结的。</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">留在循环中，不用花无数时间浏览下一个突破；我们的算法识别…</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">alphasignal.ai</p></div></div><div class="no l"><div class="nu l nq nr ns no nt lb nf"/></div></div></a></div></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="caad" class="lj lk it bd ll lm oc lo lp lq od ls lt ki oe kj lv kl of km lx ko og kp lz ma bi translated">读入海量数据</h1><p id="7126" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">您的第一个担忧始于加载数据时——将数据集读入工作环境所需的时间可能与您训练模型的时间一样长。在这个阶段，不要使用熊猫——有更快的替代品。我最喜欢的包之一是<code class="fe oh oi oj ok b">datatable</code>包，它读取数据的速度可以快10倍。</p><p id="e8ed" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">例如，我们将使用<code class="fe oh oi oj ok b">datatable</code>和<code class="fe oh oi oj ok b">pandas</code>加载约1M行<a class="ae li" href="https://www.kaggle.com/c/tabular-playground-series-sep-2021/data" rel="noopener ugc nofollow" target="_blank">ka ggle TPS 2021年9月</a>数据集，并比较速度:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl on"><img src="../Images/e419223504259595d669b710a5bcece8.png" data-original-src="https://miro.medium.com/v2/format:webp/1*JufGfLNrobxSo6iO2y8dIQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">来源:<a class="ae li" href="https://www.kaggle.com/c/tabular-playground-series-sep-2021/data" rel="noopener ugc nofollow" target="_blank"> Kaggle TPS九月赛</a></p></figure><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl on"><img src="../Images/a07a2087b7fa43346ef6be1c0a1ede29.png" data-original-src="https://miro.medium.com/v2/format:webp/1*tIpt3jzuQDT5feeRza6f7g.png"/></div></figure><p id="6943" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">7倍加速！用于操作数据的<code class="fe oh oi oj ok b">datatable</code> API可能不如<code class="fe oh oi oj ok b">pandas</code>直观——因此，在读取数据后调用<code class="fe oh oi oj ok b">to_pandas</code>方法将其转换为DataFrame。</p><p id="5323" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">除了<code class="fe oh oi oj ok b">datatable</code>，还有<code class="fe oh oi oj ok b">Dask</code>、<code class="fe oh oi oj ok b">Vaex</code>或<code class="fe oh oi oj ok b">cuDF</code>等。它读取数据的速度比熊猫快好几倍。如果你想看一些实际的例子，请参考Kaggle大师Rohan Rao关于阅读大数据集的笔记本。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="4af4" class="lj lk it bd ll lm oc lo lp lq od ls lt ki oe kj lv kl of km lx ko og kp lz ma bi translated">减少内存大小</h1><p id="a0e8" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">接下来，我们有记忆问题。在进行复杂计算时，即使是200k的行数据集也可能耗尽16GB的RAM。</p><p id="e745" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">这个第一手<em class="oo">我在上个月Kaggle上的TPS比赛中经历过两次</em>。第一次是当使用UMAP将训练数据投影到2D时——我用完了RAM。第二次是在用XGBoost为测试集计算SHAP值时——我用完了GPU VRAM。令人震惊的是，训练集和测试集只有250k和150k行，包含100个特性，而我使用的是Kaggle内核。</p><p id="4d6f" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">我们今天使用的数据集有大约96万行，包含120个要素，因此更有可能出现内存问题:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="5666" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">在带有<code class="fe oh oi oj ok b">deep=True</code>的数据帧上使用<code class="fe oh oi oj ok b">memory_usage</code>方法，我们可以得到每个特性消耗多少RAM的精确估计值——7 MBs。总体来说接近1GB。</p><p id="d6b8" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">现在，你可以使用一些技巧来减少高达90%的内存使用。这些技巧与尽可能将每个要素的数据类型更改为最小的子类型有很大关系。</p><p id="d238" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">Python以独特的类型表示各种数据，如<code class="fe oh oi oj ok b">int</code>、<code class="fe oh oi oj ok b">float</code>、<code class="fe oh oi oj ok b">str</code>等。相比之下，pandas对每种Python都有几种NumPy替代方案:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi op"><img src="../Images/d82bf1cb9608667f945e8f1991ad1860.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jUWj8UtW_gOYuZh0.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lh">来源:</strong><a class="ae li" href="http://pbpython.com/pandas_dtypes.html" rel="noopener ugc nofollow" target="_blank">【http://pbpython.com/pandas_dtypes.html】T21</a></p></figure><p id="ab65" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">数据类型旁边的数字指的是以该格式表示的单个数据单元消耗多少位内存。为了尽可能减少内存，请选择最小的NumPy数据格式。这里有一个很好的表格来理解这一点:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi op"><img src="../Images/36510b1e8e5d0c8b50225c4c2de3b2c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*T0KacMFCMtlSrd1l.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lh">来源:</strong><a class="ae li" href="https://docs.scipy.org/doc/numpy-1.13.0/user/basics.types.html" rel="noopener ugc nofollow" target="_blank"><strong class="bd lh">https://docs . scipy . org/doc/numpy-1 . 13 . 0/user/basics . types . html</strong></a></p></figure><p id="7d6a" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">上表中，<code class="fe oh oi oj ok b">uint</code>指无符号，仅正整数。我发现了这个方便的函数，它可以根据上表减少熊猫数据帧的内存(大声喊出<a class="ae li" href="https://www.kaggle.com/somang1418/tuning-hyperparameters-under-10-minutes-lgbm?scriptVersionId=11067143&amp;cellId=10" rel="noopener ugc nofollow" target="_blank">这个Kaggle内核</a>):</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="2342" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">基于<em class="oo">数字</em>列的最小值和最大值以及上表，该函数将其转换为可能的最小子类型。让我们将它用于我们的数据:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="2759" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">70%的内存减少令人印象深刻。但是，请注意，在大多数情况下，内存减少不会加快计算速度。如果内存大小不是问题，您可以跳过这一步。</p><p id="b429" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">关于非数值数据类型，永远不要在Pandas中使用<code class="fe oh oi oj ok b">object</code>数据类型，因为它消耗最多的内存。如果特征中的唯一值很少，使用<code class="fe oh oi oj ok b">str</code>或<code class="fe oh oi oj ok b">category</code>。事实上，使用<code class="fe oh oi oj ok b">pd.Categorical</code>数据类型可以将速度提高10倍，同时使用<a class="ae li" rel="noopener" target="_blank" href="/how-to-beat-the-heck-out-of-xgboost-with-lightgbm-comprehensive-tutorial-5eba52195997?source=your_stories_page-------------------------------------"> LightGBM的默认分类</a>处理程序。</p><p id="cae7" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">对于其他数据类型，如<code class="fe oh oi oj ok b">datetime</code>或<code class="fe oh oi oj ok b">timedelta</code>，使用<code class="fe oh oi oj ok b">pandas</code>中提供的本地格式，因为它们支持特殊的操作功能。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="138f" class="lj lk it bd ll lm oc lo lp lq od ls lt ki oe kj lv kl of km lx ko og kp lz ma bi translated">选择数据操作库</h1><p id="b422" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">到目前为止，我主要提到了<code class="fe oh oi oj ok b">pandas</code>。它可能很慢，但广泛的数据处理功能使它比竞争对手有越来越大的优势。</p><p id="da50" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">但是它的竞争对手能做什么呢？先从<code class="fe oh oi oj ok b">datatable</code>(再次)说起吧。</p><p id="d531" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated"><code class="fe oh oi oj ok b"><a class="ae li" href="https://datatable.readthedocs.io/en/latest/start/index-start.html" rel="noopener ugc nofollow" target="_blank">datatable</a></code>支持对高达100 GBs的数据集进行多线程预处理。在这样的规模下，<code class="fe oh oi oj ok b">pandas</code>开始抛出内存错误，而<code class="fe oh oi oj ok b">datatable</code>谦逊地执行。你可以阅读<a class="ae li" rel="noopener" target="_blank" href="/an-overview-of-pythons-datatable-package-5d3a97394ee9">Parul Pandey</a>的这篇优秀文章来了解这个包的介绍。</p><p id="bdf2" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">另一个替代方案是<code class="fe oh oi oj ok b"><a class="ae li" href="https://docs.rapids.ai/api/cudf/stable/" rel="noopener ugc nofollow" target="_blank">cuDF</a></code>，由RAPIDS开发。这个包有很多依赖项，可以在极端情况下使用(想想几千亿)。它支持运行分布在一个或多个GPU上的预处理功能，这是当今大多数数据应用程序的要求。与<code class="fe oh oi oj ok b">datatable</code>不同，它的API与<code class="fe oh oi oj ok b">pandas</code>非常相似。阅读来自NVIDIA博客的<a class="ae li" href="https://developer.nvidia.com/blog/pandas-dataframe-tutorial-beginners-guide-to-gpu-accelerated-dataframes-in-python/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>了解更多信息。</p><p id="a3d7" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">您也可以查看提供类似功能的<a class="ae li" href="https://dask.org/" rel="noopener ugc nofollow" target="_blank"> Dask </a>或<a class="ae li" href="https://vaex.io/docs/index.html" rel="noopener ugc nofollow" target="_blank"> Vaex </a>。</p><p id="184b" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">如果你对<code class="fe oh oi oj ok b">pandas</code>死心塌地，那么继续阅读下一节。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="8884" class="lj lk it bd ll lm oc lo lp lq od ls lt ki oe kj lv kl of km lx ko og kp lz ma bi translated">对数据进行采样</h1><p id="1b41" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">不考虑任何速度技巧或GPU类固醇包，太多的数据，嗯，太多了。当您有数百万行时，很有可能可以对它们进行采样，以便保留所有的特征分布。</p><p id="bd94" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">这样做主要是为了加快计算速度。取一个小样本，而不是对所有数据进行实验、特征工程和训练基线模型。通常，10–20%就足够了。以下是熊猫是如何做到的:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="efea" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">作为证明，我们可以根据样本和原始数据绘制单个特征的直方图:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl on"><img src="../Images/951a3447ba8bbce96444e846a66e47bd.png" data-original-src="https://miro.medium.com/v2/format:webp/1*3r1oj0yV0G9qqp3-ZJATrw.png"/></div></figure><p id="b6d1" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">如您所见，分布大致相同——您甚至可以比较方差进行检查。</p><p id="8bed" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">现在，您可以使用这个示例进行快速原型制作、实验、构建模型验证策略等等。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="8387" class="lj lk it bd ll lm oc lo lp lq od ls lt ki oe kj lv kl of km lx ko og kp lz ma bi translated">使用矢量化代替循环</h1><p id="af32" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">每当你发现自己渴望使用一些循环函数，如<code class="fe oh oi oj ok b">apply</code>、<code class="fe oh oi oj ok b">applymap</code>或<code class="fe oh oi oj ok b">itertuples</code>——停止。请改用矢量化。</p><p id="2775" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">首先，开始将DataFrame列视为巨大的n维向量。如你所知，向量运算同时影响向量中的每个元素，消除了数学循环的需要。矢量化是对数组而不是单个标量执行操作的过程。</p><p id="5df8" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">Pandas拥有大量的矢量化函数。事实上，几乎任何能够影响数组中每个元素的函数和操作符在pandas中都是向量化的。这些函数比任何循环都要快几个数量级。</p><p id="1676" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">还可以定义自定义的矢量化预处理函数，将整个数据帧列作为向量而不是标量接受。这方面令人毛骨悚然的细节超出了本文的范围。你为什么不看看这个很棒的导游？</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="ccd8" class="lj lk it bd ll lm oc lo lp lq od ls lt ki oe kj lv kl of km lx ko og kp lz ma bi translated">为基线模型或原型选择机器学习库</h1><p id="5342" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">机器学习是一个迭代的过程。当处理大型数据集时，您必须确保每次迭代都尽可能快。您想要构建基线，开发一个验证策略，检查不同的特性工程思想是否改进了基线，等等。</p><p id="a790" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">在这个阶段，不要在Sklearn中使用模型，因为它们是CPU专用的。从XGBoost、LightGBM或CatBoost中选择。这里有一个令人惊讶的事实——XGBoost比其他两个要慢得多，即使在GPU上也是如此。</p><p id="65c1" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">比LightGBM 最多慢10倍<a class="ae li" rel="noopener" target="_blank" href="/how-to-beat-the-heck-out-of-xgboost-with-lightgbm-comprehensive-tutorial-5eba52195997?source=your_stories_page-------------------------------------">。CatBoost击败了这两个库，并且随着数据集大小的变大，速度差异迅速增长。在准确性方面，它也经常胜过他们。</a></p><p id="d2da" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">当您运行多个实验、交叉验证或超参数调整时，这些速度差异会变得更加明显。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="cc49" class="lj lk it bd ll lm oc lo lp lq od ls lt ki oe kj lv kl of km lx ko og kp lz ma bi translated">杂项提示</h1><p id="f359" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">使用cy thon(C Python)——通常，它比纯Python快100倍。查看熊猫文档的这一部分。</p><p id="ea6d" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">如果你真的必须循环，在安装<a class="ae li" href="https://numba.pydata.org/numba-doc/latest/index.html" rel="noopener ugc nofollow" target="_blank"> Numba </a>后用<code class="fe oh oi oj ok b">@numba.jit</code>修饰你的自定义函数。JIT (just-in-time)编译将纯Python转换为本机机器指令，使您能够获得类似C、C++和Fortran的速度。再次检查文档中的本节。</p><p id="ec57" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">搜索除CSV文件之外的存储替代文件。像feather、parquet和jay这样的文件格式速度很快——如果存储在这些文件中，只需几秒钟就可以加载十亿行数据集。</p><p id="a17b" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">阅读关于<a class="ae li" href="https://pandas.pydata.org/pandas-docs/stable/user_guide/enhancingperf.html" rel="noopener ugc nofollow" target="_blank">增强性能</a>和<a class="ae li" href="https://pandas.pydata.org/pandas-docs/stable/user_guide/scale.html" rel="noopener ugc nofollow" target="_blank">扩展到大型数据集</a>的Pandas文档。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="5333" class="lj lk it bd ll lm oc lo lp lq od ls lt ki oe kj lv kl of km lx ko og kp lz ma bi translated">正在总结…</h1><p id="2a19" class="pw-post-body-paragraph mb mc it md b me mf kd mg mh mi kg mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">以下是这篇文章的摘要:</p><ol class=""><li id="fd63" class="os ot it md b me mx mh my mk ou mo ov ms ow mw ox oy oz pa bi translated">仅使用像<code class="fe oh oi oj ok b">datatable</code>、<code class="fe oh oi oj ok b">cuDF</code>或<code class="fe oh oi oj ok b">dask</code>这样的库加载数据。他们总是比熊猫快。</li><li id="cb7d" class="os ot it md b me pb mh pc mk pd mo pe ms pf mw ox oy oz pa bi translated">通过将每一列转换为尽可能小的子类型，可以减少高达90%的内存消耗。</li><li id="bc84" class="os ot it md b me pb mh pc mk pd mo pe ms pf mw ox oy oz pa bi translated">选择一个你熟悉的或者基于你需要的数据操作库。</li><li id="054e" class="os ot it md b me pb mh pc mk pd mo pe ms pf mw ox oy oz pa bi translated">抽取10-20%的数据样本进行快速分析和实验。</li><li id="e790" class="os ot it md b me pb mh pc mk pd mo pe ms pf mw ox oy oz pa bi translated">用向量思考，使用向量函数。</li><li id="6305" class="os ot it md b me pb mh pc mk pd mo pe ms pf mw ox oy oz pa bi translated">选择像CatBoost这样的快速ML库来构建基线和进行特征工程。</li></ol><p id="f5b2" class="pw-post-body-paragraph mb mc it md b me mx kd mg mh my kg mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">感谢您的阅读！</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl on"><img src="../Images/fb994506cb7f01448847810261a3e05c.png" data-original-src="https://miro.medium.com/v2/1*KeMS7gxVGsgx8KC36rSTcg.gif"/></div></figure></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><h1 id="d0d8" class="lj lk it bd ll lm oc lo lp lq od ls lt ki oe kj lv kl of km lx ko og kp lz ma bi translated">您可能也会感兴趣…</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://towardsdatascience.com/beginners-guide-to-umap-for-reducing-dimensionality-and-visualizing-100-dimensional-datasets-ff5590fb17be"><div class="gh gi pg"><img src="../Images/8bbce478590709d2df931885bd152d1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xUZ2RWmFdyl9O7arCh_Mbg.png"/></div></a></figure><div class="nc nd gp gr ne nf"><a rel="noopener follow" target="_blank" href="/kagglers-guide-to-lightgbm-hyperparameter-tuning-with-optuna-in-2021-ed048d9838b5"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd jd gy z fp nk fr fs nl fu fw jc bi translated">2021年使用Optuna调整LightGBM超参数的Kaggler指南</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">编辑描述</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">towardsdatascience.com</p></div></div><div class="no l"><div class="ph l nq nr ns no nt lb nf"/></div></div></a></div><div class="nc nd gp gr ne nf"><a rel="noopener follow" target="_blank" href="/how-to-beat-the-heck-out-of-xgboost-with-lightgbm-comprehensive-tutorial-5eba52195997"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd jd gy z fp nk fr fs nl fu fw jc bi translated">你错过了LightGBM。它在各个方面都击败了XGBoost</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">编辑描述</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">towardsdatascience.com</p></div></div><div class="no l"><div class="pi l nq nr ns no nt lb nf"/></div></div></a></div><div class="nc nd gp gr ne nf"><a rel="noopener follow" target="_blank" href="/tired-of-cliché-datasets-here-are-18-awesome-alternatives-from-all-domains-196913161ec9"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd jd gy z fp nk fr fs nl fu fw jc bi translated">厌倦了陈词滥调的数据集？以下是来自所有领域的18个令人敬畏的选择</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">编辑描述</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">towardsdatascience.com</p></div></div><div class="no l"><div class="pj l nq nr ns no nt lb nf"/></div></div></a></div><div class="nc nd gp gr ne nf"><a rel="noopener follow" target="_blank" href="/love-3blue1brown-animations-learn-how-to-create-your-own-in-python-in-10-minutes-8e0430cf3a6d"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd jd gy z fp nk fr fs nl fu fw jc bi translated">喜欢3Blue1Brown动画？了解如何在10分钟内用Python创建自己的</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">编辑描述</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">towardsdatascience.com</p></div></div><div class="no l"><div class="pk l nq nr ns no nt lb nf"/></div></div></a></div></div></div>    
</body>
</html>