<html>
<head>
<title>Real Time Image Segmentation Using 5 Lines of Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用5行代码的实时图像分割</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/real-time-image-segmentation-using-5-lines-of-code-7c480abdb835?source=collection_archive---------3-----------------------#2021-09-24">https://towardsdatascience.com/real-time-image-segmentation-using-5-lines-of-code-7c480abdb835?source=collection_archive---------3-----------------------#2021-09-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="71e1" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="9427" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">使用PixelLib在图像和视频中执行准确快速的对象分割</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/6c21d9121f935e2679cea07b89ee8b34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OZ7Jdf_eR_1lETNqLHvrnQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://www.pexels.com/video/cabs-passing-through-the-streets-of-new-york-city-5834623/" rel="noopener ugc nofollow" target="_blank">原始视频来源</a></p></figure><h2 id="923f" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated">目录</h2><ol class=""><li id="6e54" class="ma mb iq mc b md me mf mg lo mh ls mi lw mj mk ml mm mn mo bi translated"><a class="ae le" href="https://medium.com/p/7c480abdb835#9208" rel="noopener"> <strong class="mc ja">图像分割在计算机视觉中的应用</strong> </a></li><li id="03fb" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk ml mm mn mo bi translated"><a class="ae le" href="https://medium.com/p/7c480abdb835#d968" rel="noopener"> <strong class="mc ja">图像分割</strong> </a></li><li id="0942" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk ml mm mn mo bi translated"><a class="ae le" href="https://medium.com/p/7c480abdb835#42f1" rel="noopener"> <strong class="mc ja">批量图像分割</strong> </a></li><li id="607f" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk ml mm mn mo bi translated"><a class="ae le" href="https://medium.com/p/7c480abdb835#eaae" rel="noopener"> <strong class="mc ja">视频分割</strong> </a></li><li id="9d43" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk ml mm mn mo bi translated"><a class="ae le" href="https://medium.com/p/7c480abdb835#bbf8" rel="noopener"> <strong class="mc ja">摄像机画面分割</strong> </a></li></ol><h2 id="9208" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated"><strong class="ak">图像分割在计算机视觉中的应用</strong></h2><p id="8419" class="pw-post-body-paragraph mu mv iq mc b md me ka mw mf mg kd mx lo my mz na ls nb nc nd lw ne nf ng mk ij bi translated">计算机视觉是计算机看到并分析他们所看到的东西的能力。图像分割是计算机视觉的一个方面，它处理将计算机可视化的对象的内容分割成不同的类别以便更好地分析。图像分割过程的一个很好的例子是<strong class="mc ja"> </strong>图像中对象的前景-背景分离，这是一种将对象从其背景中分离出来以分析对象及其背景的技术。图像分割实现前景和背景分离的能力使其在解决许多计算机视觉问题中具有不可估量的价值，例如医学图像分析、背景编辑、自动驾驶汽车中的视觉和卫星图像分析。</p><p id="e501" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">PixelLib库是一个使用几行python代码就可以轻松集成图像和视频中的对象分割的库。它支持许多惊人的功能，例如:</p><ol class=""><li id="7293" class="ma mb iq mc b md nh mf ni lo nm ls nn lw no mk ml mm mn mo bi translated">图像和视频中对象的语义和实例分割。</li><li id="b48a" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk ml mm mn mo bi translated">细分模型的定制训练。</li><li id="e439" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk ml mm mn mo bi translated">图像和视频中的背景编辑。</li><li id="4e0d" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk ml mm mn mo bi translated">图像和视频中物体的提取。</li></ol><h2 id="9de3" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated">对实时图像分割应用的需求</h2><p id="01cf" class="pw-post-body-paragraph mu mv iq mc b md me ka mw mf mg kd mx lo my mz na ls nb nc nd lw ne nf ng mk ij bi translated">计算机视觉中最大的挑战之一是在实时应用的准确性和速度性能之间保持平衡。在计算机视觉领域，存在计算机视觉解决方案要么更精确和更慢，要么不太精确和更快的两难境地。之前版本的PixelLib使用tensorflow深度学习库作为其后端，该库采用Mask R-CNN来执行实例分割。Mask R-CNN是一个很好的架构，但是无法在实时应用的准确性和速度性能之间取得平衡。我太兴奋了😊宣布PixelLib现在支持pytorch后端使用<strong class="mc ja"><em class="np">point rende</em></strong>分割架构对图像和视频中的对象进行更快、更准确的分割和提取。<strong class="mc ja"> <em class="np"> PointRend </em> </strong>由<a class="ae le" href="https://arxiv.org/abs/1912.08193" rel="noopener ugc nofollow" target="_blank">亚历山大·基里洛夫等人</a>提出的对象分割架构用于代替Mask R-CNN进行对象的实例分割。<strong class="mc ja"> <em class="np"> PointRend </em> </strong>是一个用于实现对象分割的优秀的艺术级神经网络。它生成精确的分割模板，并以高推理速度运行，以满足日益增长的对精确和实时计算机视觉应用的需求。</p><h2 id="5a46" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated">多操作系统支持</h2><blockquote class="nq nr ns"><p id="e522" class="mu mv np mc b md nh ka mw mf ni kd mx nt nj mz na nu nk nc nd nv nl nf ng mk ij bi translated"><em class="iq"> PixelLib是一个为不同操作系统提供支持的库。我将PixelLib与python实现的</em><a class="ae le" href="https://github.com/facebookresearch/detectron2/tree/main/projects/PointRend" rel="noopener ugc nofollow" target="_blank"><strong class="mc ja"><em class="iq">point rend by detectron 2</em></strong></a><strong class="mc ja"><em class="iq"/></strong><em class="iq">集成，后者只支持Linux OS。</em></p></blockquote><blockquote class="nw"><p id="6e6a" class="nx ny iq bd nz oa ob oc od oe of mk dk translated">我对最初的Detectron2 PointRend实现进行了修改，以支持Windows操作系统。我很高兴告诉大家一个好消息，用于PixelLib的PointRend实现支持Linux和Windows操作系统。</p></blockquote><div class="oh oi oj ok ol ab cb"><figure class="om kt on oo op oq or paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/8e1efdca0aefe4c02f3c8eccaf1a216d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*NPPqwBYKUAbDYA0yuMD5Rw.jpeg"/></div></figure><figure class="om kt on oo op oq or paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/11495ec24ee948d294d4201b3f3509e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*RRDFksrJsCdVYEg-XXALFw.jpeg"/></div><p class="la lb gj gh gi lc ld bd b be z dk os di ot ou translated"><strong class="bd ov">面具R-CNN </strong> vs <strong class="bd ov">点趋势</strong> ( <a class="ae le" href="https://unsplash.com/photos/6UWqw25wfLI" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure></div><div class="ab cb"><figure class="om kt on oo op oq or paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/1cd6238da4f618d94494bd1607f3b9bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*QthpEjt9gWpRcAyCWGkTkw.jpeg"/></div></figure><figure class="om kt on oo op oq or paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/1b593782b4e3f8f0e05ca08de3b9fd09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*05MBWXYunimDToowFw-0Qw.jpeg"/></div><p class="la lb gj gh gi lc ld bd b be z dk os di ot ou translated"><strong class="bd ov"> <em class="og">面具R-CNN </em> </strong> vs <strong class="bd ov">点趋势</strong> ( <a class="ae le" href="https://unsplash.com/photos/rrI02QQ9GSQ" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure></div><blockquote class="nw"><p id="519b" class="nx ny iq bd nz oa ob oc od oe of mk dk translated">上面的样本图像是<strong class="ak"> <em class="og">点趋势</em> </strong>的分割结果与掩模RCNN相比的差异的例子。很明显，右边的<strong class="ak"> <em class="og">点趋势</em> </strong>图像结果与左边的掩模R-CNN结果相比是更好的分割输出。</p></blockquote><p id="171c" class="pw-post-body-paragraph mu mv iq mc b md ow ka mw mf ox kd mx lo oy mz na ls oz nc nd lw pa nf ng mk ij bi translated"><strong class="mc ja">注意:</strong>本文基于使用pytorch和<strong class="mc ja"> <em class="np"> PointRend </em> </strong>执行实例分割。如果您想了解如何使用tensorflow和Mask R-CNN执行实例分割，请阅读下面的这篇文章:</p><div class="pb pc gp gr pd pe"><a rel="noopener follow" target="_blank" href="/image-segmentation-with-six-lines-0f-code-acb870a462e8"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd ja gy z fp pj fr fs pk fu fw iz bi translated">用5行代码实现图像分割</h2><div class="pl l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">towardsdatascience.com</p></div></div><div class="pm l"><div class="pn l po pp pq pm pr ky pe"/></div></div></a></div><h2 id="0ea7" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated"><strong class="ak">下载Python </strong></h2><p id="8848" class="pw-post-body-paragraph mu mv iq mc b md me ka mw mf mg kd mx lo my mz na ls nb nc nd lw ne nf ng mk ij bi translated">PixelLib pytorch版本支持python版本3.7及以上。下载兼容的python版本。</p><div class="pb pc gp gr pd pe"><a href="https://www.python.org/" rel="noopener  ugc nofollow" target="_blank"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd ja gy z fp pj fr fs pk fu fw iz bi translated">欢迎来到Python.org</h2><div class="ps l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">Python编程语言的官方主页</h3></div><div class="pl l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">www.python.org</p></div></div><div class="pm l"><div class="pt l po pp pq pm pr ky pe"/></div></div></a></div><h2 id="96d5" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated"><strong class="ak">安装PixelLib及其依赖项</strong></h2><p id="5e4c" class="pw-post-body-paragraph mu mv iq mc b md me ka mw mf mg kd mx lo my mz na ls nb nc nd lw ne nf ng mk ij bi translated"><strong class="mc ja">安装Pytorch </strong></p><p id="202a" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">PixelLib Pytorch版本支持Pytorch的这些版本(<strong class="mc ja">、T21【1 . 6 . 0、1.7.1、1.8.0和1.9.0 、T23)。</strong></p><p id="dcb5" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">注意:</strong>Pytorch<strong class="mc ja"><em class="np">1 . 7 . 0</em></strong>不受支持，请勿使用任何低于<strong class="mc ja"> <em class="np"> 1.6.0 </em> </strong>的py torch版本。安装兼容的Pytorch版本。</p><div class="pb pc gp gr pd pe"><a href="https://pytorch.org/" rel="noopener  ugc nofollow" target="_blank"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd ja gy z fp pj fr fs pk fu fw iz bi translated">PyTorch</h2><div class="ps l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">推动自然语言处理和多任务学习的发展。利用PyTorch的灵活性有效地研究新的…</h3></div><div class="pl l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">pytorch.org</p></div></div><div class="pm l"><div class="pu l po pp pq pm pr ky pe"/></div></div></a></div><p id="8a33" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">安装Pycocotools </strong></p><ul class=""><li id="6ab4" class="ma mb iq mc b md nh mf ni lo nm ls nn lw no mk pv mm mn mo bi translated"><em class="np"> pip3安装pycocotools </em></li></ul><p id="8448" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">安装PixelLib </strong></p><ul class=""><li id="8ff7" class="ma mb iq mc b md nh mf ni lo nm ls nn lw no mk pv mm mn mo bi translated"><em class="np"> pip3安装pixellib </em></li></ul><p id="609c" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">如果已安装，使用</strong>升级至最新版本:</p><ul class=""><li id="1d61" class="ma mb iq mc b md nh mf ni lo nm ls nn lw no mk pv mm mn mo bi translated"><em class="np"> pip3安装pixellib —升级</em></li></ul><h1 id="d968" class="pw lg iq bd lh px py pz lk qa qb qc ln kf qd kg lr ki qe kj lv kl qf km lz qg bi translated">图象分割法</h1><p id="bf09" class="pw-post-body-paragraph mu mv iq mc b md me ka mw mf mg kd mx lo my mz na ls nb nc nd lw ne nf ng mk ij bi translated">PixelLib使用五行python代码，用<strong class="mc ja"> <em class="np"> PointRend </em> </strong>模型在图像和视频中进行对象分割。下载<a class="ae le" href="https://github.com/ayoolaolafenwa/PixelLib/releases/download/0.2.0/pointrend_resnet50.pkl" rel="noopener ugc nofollow" target="_blank"> <strong class="mc ja"> <em class="np">点趋势模型</em> </strong> </a>。这是图像分割的代码。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><p id="55ae" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">第1–4行:</strong> PixelLib包被导入，我们还从模块<strong class="mc ja"><em class="np">PixelLib . torch backend . instance</em></strong>中导入了类<strong class="mc ja"><em class="np">instance segmentation</em></strong><em class="np"/>(从pytorch支持中导入实例分割类)。我们创建了该类的一个实例，最后加载了我们已经下载的<strong class="mc ja"><em class="np">point rende</em></strong>模型。</p><p id="63d8" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">第5行:</strong>我们调用函数<strong class="mc ja"> <em class="np"> segmentImage </em> </strong>对图像中的物体进行分割，并为函数添加了以下参数:</p><ul class=""><li id="a4b5" class="ma mb iq mc b md nh mf ni lo nm ls nn lw no mk pv mm mn mo bi translated"><strong class="mc ja"> <em class="np"> image_path: </em> </strong>这是待分割图像的路径。</li><li id="7acc" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk pv mm mn mo bi translated"><strong class="mc ja"> <em class="np"> show_bbox: </em> </strong>这是一个可选参数，用边界框显示分割结果。</li><li id="be22" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk pv mm mn mo bi translated"><strong class="mc ja"> <em class="np">输出图像名称:</em> </strong>这是保存的分割图像的名称。</li></ul><p id="9532" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">用于分割的样本图像</strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi qj"><img src="../Images/06cc5036f52747a35c168305831e7710.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ma11ZJqWRkMBCylQGA-A1g.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://commons.wikimedia.org/wiki/File:Carspotters.jpg" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="4ad4" class="lf lg iq ql b gy qp qq l qr qs">ins.segmentImage("image.jpg",output_image_name="output.jpg")</span></pre><p id="4447" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">分割后的图像</strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi qj"><img src="../Images/fa9443ecfcdf6810a258f9b13d2752e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RLrW4IO-lKbcqyl-QyeOzQ.jpeg"/></div></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="3ab0" class="lf lg iq ql b gy qp qq l qr qs">The checkpoint state_dict contains keys that are not used by the model: proposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}</span></pre><blockquote class="nw"><p id="ba2c" class="nx ny iq bd nz oa ob oc od oe of mk dk translated">如果您运行分段代码，上面的日志可能会出现！这不是一个错误，代码将正常工作！</p></blockquote><h2 id="ffc9" class="lf lg iq bd lh li qt dn lk ll qu dp ln lo qv lq lr ls qw lu lv lw qx ly lz iw bi translated"><strong class="ak">获取分割结果</strong></h2><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="b374" class="lf lg iq ql b gy qp qq l qr qs">results, output = ins.segmentImage("image.jpg", show_bboxes=True, output_image_name="result.jpg")<br/>print(results)<br/></span></pre><p id="c72d" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">分割结果返回一个字典，该字典具有许多与图像中被分割的对象相关联的值。打印的结果将采用以下格式:</p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="33cb" class="lf lg iq ql b gy qp qq l qr qs">{'boxes':  array([[ 579,  462, 1105,  704],<br/>       [   1,  486,  321,  734],<br/>       [ 321,  371,  423,  742],<br/>       [ 436,  369,  565,  788],<br/>       [ 191,  397,  270,  532],<br/>       [1138,  357, 1197,  482],<br/>       [ 877,  382,  969,  477],),</span><span id="a314" class="lf lg iq ql b gy qy qq l qr qs">'class_ids': array([ 2,  2,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  2, 24, 24,2,  2,2,  0,  0,  0,  0,  0,  0], dtype=int64), </span><span id="a68b" class="lf lg iq ql b gy qy qq l qr qs">'class_names': ['car', 'car', 'person', 'person', 'person', 'person', 'person', 'car', 'person', 'person', 'person', 'person', 'car', 'backpack', 'backpack', 'car', 'car', 'car', 'person', 'person', 'person', 'person', 'person', 'person'],</span><span id="fde6" class="lf lg iq ql b gy qy qq l qr qs"> 'object_counts': Counter({'person': 15, 'car': 7, 'backpack': 2}), </span><span id="54c3" class="lf lg iq ql b gy qy qq l qr qs">'scores': array([100., 100., 100., 100.,  99.,  99.,  98.,  98.,  97.,  96.,  95.,95.,  95.,  95.,  94.,  94.,  93.,  91.,  90.,  88.,  82.,  72.,69.,  66.], dtype=float32), </span><span id="e1ff" class="lf lg iq ql b gy qy qq l qr qs">'masks': array([[[False, False, False, ..., False, False, False],</span><span id="5bca" class="lf lg iq ql b gy qy qq l qr qs">[False, False, False, ..., False, False, False],</span><span id="2125" class="lf lg iq ql b gy qy qq l qr qs">'extracted_objects': []</span></pre><h2 id="bf83" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated"><strong class="ak">上面打印的结果值包括:</strong></h2><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="9f4d" class="lf lg iq ql b gy qp qq l qr qs">{'boxes': array([[5.790e+02, 4.620e+02, 1.105e+03, 7.050e+02],[1.000e+00, 4.870e+02, 3.220e+02, 7.340e+02],[1.142e+03, 3.640e+02, 1.161e+03, 4.060e+02]], dtype=float32),</span></pre><p id="701d" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">框:</strong>这些是被分割对象的边界框坐标。我没有显示所有盒子的坐标，这是因为列表太长了。</p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="5f23" class="lf lg iq ql b gy qp qq l qr qs">'class_ids': array([ 2,  2,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  2, 24, 24,2,  2,2,  0,  0,  0,  0,  0,  0], dtype=int64),</span></pre><p id="ad53" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">类标识:</strong>这些是被分割对象的类标识。</p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="5b4a" class="lf lg iq ql b gy qp qq l qr qs">'class_names': ['car', 'car', 'person', 'person', 'person', 'person', 'person', 'car', 'person', 'person', 'person', 'person', 'car', 'backpack', 'backpack', 'car', 'car', 'car', 'person', 'person', 'person', 'person', 'person', 'person'],</span></pre><p id="3ceb" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">类名:</strong>这些是被分割对象的类名。</p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="5685" class="lf lg iq ql b gy qp qq l qr qs">'object_counts': Counter({'person': 15, 'car': 7, 'backpack': 2}),</span></pre><p id="98be" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja"> object_counts: </strong>这些是图像中分割的每个类别的计数。我使用了<strong class="mc ja"> python内置的计数器</strong>来计数对象。在这种情况下，图像中分割出了<strong class="mc ja"> <em class="np"> 15个人</em></strong><strong class="mc ja"><em class="np">7辆汽车</em> </strong>和<strong class="mc ja"> <em class="np"> 2个背包</em> </strong>。</p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="0806" class="lf lg iq ql b gy qp qq l qr qs">'scores': array([100., 100., 100., 100.,  99.,  99.,  98.,  98.,  97.,  96.,  95.,95.,  95.,  95.,  94.,  94.,  93.,  91.,  90.,  88.,  82.,  72.,69.,  66.], dtype=float32),</span></pre><p id="23c5" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">分数:</strong>这些是每个被分割对象的置信度分数。</p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="28af" class="lf lg iq ql b gy qp qq l qr qs">'masks': array([[[False, False, False, ..., False, False, False],</span><span id="f1d4" class="lf lg iq ql b gy qy qq l qr qs">[False, False, False, ..., False, False, False],</span></pre><p id="d0ca" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">遮罩:</strong>这些是每个被分割对象的遮罩值。我没有显示所有的掩码值，这是因为列表太长了。</p><p id="7cb6" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">注:</strong>返回的掩码默认值以bolean为单位。通过使用新的参数<strong class="mc ja"> <em class="np"> mask_points_values，可以获得掩模的坐标。</em>T59】</strong></p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="1980" class="lf lg iq ql b gy qp qq l qr qs">ins.segmentImage("sample.jpg", show_bboxes=True, mask_points_values=True,  output_image_name="output.jpg")</span></pre><p id="a61e" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja"><em class="np">mask _ points _ values</em></strong>参数<strong class="mc ja"> <em class="np"> </em> </strong>被<strong class="mc ja"> <em class="np"> </em> </strong>添加到<strong class="mc ja"> <em class="np"> segmentImage </em> </strong>函数并设置为<strong class="mc ja"> <em class="np"> True </em> </strong>，新的遮罩值将为:</p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="fa95" class="lf lg iq ql b gy qp qq l qr qs">[[array([[295, 497]])<br/>  array([[422, 114], <br/>       [421, 115],   <br/>       [417, 115],<br/>       ...,<br/>       [436, 115],<br/>       [433, 115],<br/>       [432, 114]])]]</span></pre><p id="9d9a" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja"> extracted_objects: </strong>如果我们提取对象，这是提取对象值的容器列表。它是空的，因为我们没有提取任何东西。我们将在本文后面讨论如何提取这些分割对象。</p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="c596" class="lf lg iq ql b gy qp qq l qr qs">results, output = ins.segmentImage("image.jpg", show_bboxes=True, output_image_name="result.jpg")</span></pre><h2 id="c3e8" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated"><strong class="ak">访问由分割结果呈现的值</strong></h2><p id="330e" class="pw-post-body-paragraph mu mv iq mc b md me ka mw mf mg kd mx lo my mz na ls nb nc nd lw ne nf ng mk ij bi translated"><strong class="mc ja">包围盒坐标值</strong></p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="f43a" class="lf lg iq ql b gy qp qq l qr qs">results["boxes"]</span></pre><p id="cf05" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">类id值</strong></p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="3b9f" class="lf lg iq ql b gy qp qq l qr qs">results["class_ids"]</span></pre><p id="2b72" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">类名值</strong></p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="b83a" class="lf lg iq ql b gy qp qq l qr qs">results["class_names"]</span></pre><p id="0abe" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">对象计数值</strong></p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="bb7f" class="lf lg iq ql b gy qp qq l qr qs">results["object_counts"]</span></pre><p id="eab5" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">屏蔽值</strong></p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="e03f" class="lf lg iq ql b gy qp qq l qr qs">results["masks"]</span></pre><h2 id="d71a" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated"><strong class="ak">检测阈值</strong></h2><p id="4c1f" class="pw-post-body-paragraph mu mv iq mc b md me ka mw mf mg kd mx lo my mz na ls nb nc nd lw ne nf ng mk ij bi translated">PixelLib使得确定对象分割的检测阈值成为可能。</p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="12d8" class="lf lg iq ql b gy qp qq l qr qs">ins.load_model("pointrend_resnet50.pkl", confidence = 0.3)</span></pre><p id="cbcc" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">置信度:</strong>这是<strong class="mc ja"> <em class="np"> load_model </em> </strong>函数中引入的一个新参数，设置为<strong class="mc ja"> <em class="np"> 0.3 </em> </strong>来阈值检测<strong class="mc ja"> <em class="np"> 30% </em> </strong>。我为检测阈值设置的默认值是<strong class="mc ja"> <em class="np"> 0.5 </em> </strong>，可以使用<strong class="mc ja"> <em class="np">置信度</em> </strong>参数增加或减少。</p><h2 id="c6b3" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated"><strong class="ak">速度记录</strong></h2><p id="68ff" class="pw-post-body-paragraph mu mv iq mc b md me ka mw mf mg kd mx lo my mz na ls nb nc nd lw ne nf ng mk ij bi translated">PixelLib使实时对象分割成为可能，并增加了调整推理速度以适应实时预测的能力。使用4GB容量的Nvidia GPU处理单幅图像的默认推理速度约为<strong class="mc ja"> <em class="np"> 0.26秒</em> </strong>。</p><p id="81c4" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">速度调整:</strong></p><p id="d659" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">PixelLib支持速度调节，有两种速度调节模式，分别是<strong class="mc ja"><em class="np"/></strong><em class="np"/>和<strong class="mc ja"> <em class="np">快速</em> </strong> <em class="np"> </em>模式:</p><p id="069d" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja"> 1快速模式</strong></p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="a580" class="lf lg iq ql b gy qp qq l qr qs">ins.load_model("pointrend_resnet50.pkl", detection_speed = "fast")</span></pre><p id="a979" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">在<em class="np"/><strong class="mc ja"><em class="np">load _ model</em></strong><em class="np"/>函数中，我们添加了参数<strong class="mc ja"><em class="np">detection _ speed</em></strong>并将值设置为<strong class="mc ja"> <em class="np"> fast </em> </strong>。<strong class="mc ja"> <em class="np">快速</em> </strong>模式处理单幅图像达到<strong class="mc ja"> <em class="np"> 0.20秒</em> </strong>。</p><p id="4423" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">快速模式检测的完整代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><p id="3dfe" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja"> 2快速模式</strong></p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="288d" class="lf lg iq ql b gy qp qq l qr qs">ins.load_model("pointrend_resnet50.pkl", detection_speed = "fast")</span></pre><p id="bbb6" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">在<strong class="mc ja"> <em class="np"> load_model </em> </strong>函数中，我们添加了参数<strong class="mc ja"><em class="np">detection _ speed</em></strong>，并将值设置为<strong class="mc ja"> <em class="np"> rapid </em> </strong>。<strong class="mc ja"> <em class="np">快速</em> </strong>模式处理单幅图像达到<strong class="mc ja"><em class="np"/></strong>0.15秒。</p><p id="b919" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">快速模式检测的完整代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><h2 id="db8d" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated">点趋势模型</h2><p id="d99c" class="pw-post-body-paragraph mu mv iq mc b md me ka mw mf mg kd mx lo my mz na ls nb nc nd lw ne nf ng mk ij bi translated">用于对象分割的点趋势模型有两种，分别是<strong class="mc ja"> <em class="np"> resnet50变体</em> </strong>和<strong class="mc ja"> <em class="np"> resnet101变体</em> </strong>。本文通篇使用的是<strong class="mc ja"> <em class="np"> resnet50变体</em> </strong>，因为它速度更快，准确性更好。<strong class="mc ja"> <em class="np"> resnet101变型</em> </strong>比<strong class="mc ja"> <em class="np"> resnet50变型</em> </strong>更精确但速度慢。根据Detectron2上的<a class="ae le" href="https://github.com/facebookresearch/detectron2/tree/main/projects/PointRend" rel="noopener ugc nofollow" target="_blank">官方报道</a>车型<strong class="mc ja"> <em class="np"> resnet50变种</em> </strong>在COCO上实现<strong class="mc ja"> <em class="np"> 38.3贴图</em><strong class="mc ja"><em class="np">resnet 101变种</em> </strong>在COCO上实现<strong class="mc ja"> <em class="np"> 40.1贴图</em> </strong>。</strong></p><p id="e2c9" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">resnet 101的速度记录:</strong>默认速度为<strong class="mc ja"> <em class="np"> 0.5秒</em>，<em class="np">快速</em> </strong>模式为<strong class="mc ja"> <em class="np"> 0.3秒</em> </strong>而<strong class="mc ja"> <em class="np">快速</em> </strong>模式为<strong class="mc ja"> <em class="np"> 0.25秒</em> </strong>。</p><p id="b2ff" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">resnet 101变体的代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="4041" class="lf lg iq ql b gy qp qq l qr qs">ins.load_model("pointrend_resnet101.pkl", network_backbone = "resnet101")</span></pre><p id="1d68" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">与<strong class="mc ja"> <em class="np"> resnet101 </em> </strong>模型执行推理的代码是一样的，除了我们在<strong class="mc ja"> <em class="np"> load_mode </em> l </strong>函数中加载了<strong class="mc ja"><em class="np">point rend</em></strong><strong class="mc ja"><em class="np">resnet 101模型</em> </strong>之外。从<a class="ae le" href="https://github.com/ayoolaolafenwa/PixelLib/releases/download/0.2.0/pointrend_resnet101.pkl" rel="noopener ugc nofollow" target="_blank">这里</a>下载<strong class="mc ja"> resnet101型号</strong>。我们还增加了一个额外的参数<strong class="mc ja"><em class="np">network _ backbone</em></strong>，并将值设置为<strong class="mc ja"> <em class="np"> resnet101 </em> </strong>。</p><p id="79fc" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">注:</strong>如果想达到高推理速度和良好的准确性，使用<strong class="mc ja"><em class="np">point rende resnet 50变体</em> </strong>，但如果更在意准确性，则使用<strong class="mc ja"><em class="np">point rende resnet 101变体</em> </strong>。所有这些推断报告都是基于使用4GB容量的Nvidia GPU。</p><h2 id="13db" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated">图像分割中的自定义对象检测</h2><p id="c813" class="pw-post-body-paragraph mu mv iq mc b md me ka mw mf mg kd mx lo my mz na ls nb nc nd lw ne nf ng mk ij bi translated">使用的<strong class="mc ja"> <em class="np"> PointRend </em> </strong>模型是一个预训练的COCO模型，支持80类对象。PixelLib支持自定义对象检测，这使得过滤检测和确保目标对象的分割成为可能。我们可以从支持的80类对象中进行选择，以匹配我们的目标。这些是80类受支持的对象:</p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="174d" class="lf lg iq ql b gy qp qq l qr qs">person, bicycle, car, motorcycle, airplane,</span><span id="92ff" class="lf lg iq ql b gy qy qq l qr qs">bus, train, truck, boat, traffic_light, fire_hydrant, stop_sign,</span><span id="5815" class="lf lg iq ql b gy qy qq l qr qs">parking_meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra,</span><span id="3111" class="lf lg iq ql b gy qy qq l qr qs">giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard,</span><span id="0e6b" class="lf lg iq ql b gy qy qq l qr qs">sports_ball, kite, baseball_bat, baseball_glove, skateboard, surfboard, tennis_racket,</span><span id="d48b" class="lf lg iq ql b gy qy qq l qr qs">bottle, wine_glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange,</span><span id="687f" class="lf lg iq ql b gy qy qq l qr qs">broccoli, carrot, hot_dog, pizza, donut, cake, chair, couch, potted_plant, bed,</span><span id="675f" class="lf lg iq ql b gy qy qq l qr qs">dining_table, toilet, tv, laptop, mouse, remote, keyboard, cell_phone, microwave,</span><span id="047c" class="lf lg iq ql b gy qy qq l qr qs">oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy_bear, hair_dryer,</span><span id="6755" class="lf lg iq ql b gy qy qq l qr qs">toothbrush.</span></pre><p id="233e" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">我们想要过滤我们的样本图像的检测，以便只检测图像中的<strong class="mc ja"> <em class="np">人</em> </strong>。</p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="f5e3" class="lf lg iq ql b gy qp qq l qr qs">target_classes = ins.select_target_classes(person = True)</span><span id="98ae" class="lf lg iq ql b gy qy qq l qr qs">ins.segmentImage("image.jpg", segment_target_classes = target_classes, output_image_name="output.jpg")</span></pre><p id="6be7" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">调用函数<strong class="mc ja"><em class="np">select _ target _ classes</em></strong>选择要分割的目标对象。函数<strong class="mc ja"> <em class="np"> segmentImage </em> </strong>获得了一个新参数<strong class="mc ja"><em class="np">segment _ target _ classes</em></strong>从<strong class="mc ja"> <em class="np">目标类</em> </strong>中选择，并根据它们过滤检测。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi qj"><img src="../Images/070a6df8bdc7b7cc5a3e824d02d7da0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZPZYl1rNQQnRuVki8XaoDA.jpeg"/></div></div></figure><p id="d149" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja"> <em class="np">太棒了！！！PixelLib只检测图像中出现的人。</em> </strong></p><p id="1570" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">自定义对象检测的完整代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><h2 id="24ad" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated">图像中的目标提取</h2><p id="6b5c" class="pw-post-body-paragraph mu mv iq mc b md me ka mw mf mg kd mx lo my mz na ls nb nc nd lw ne nf ng mk ij bi translated">PixelLib使得提取和分析图像中分割的对象成为可能。</p><p id="39ec" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">对象提取代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><p id="8902" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">用于图像分割的代码是相同的，除了我们在<em class="np"/><strong class="mc ja"><em class="np">segment image</em></strong>函数中添加了额外的参数来执行对象提取。</p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="959b" class="lf lg iq ql b gy qp qq l qr qs">ins.segmentImage("image.jpg", extract_segmented_objects = True, save_extracted_objects = True, output_image_name="output.jpg")</span></pre><ul class=""><li id="9fb8" class="ma mb iq mc b md nh mf ni lo nm ls nn lw no mk pv mm mn mo bi translated"><strong class="mc ja">extract _ segmented _ objects:</strong>这是处理分段对象提取的参数。使用以下方式访问提取的对象值:</li></ul><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="47b1" class="lf lg iq ql b gy qp qq l qr qs">results, output = ins.segmentImage("image.jpg", show_bboxes=True, output_image_name="result.jpg")</span><span id="1a46" class="lf lg iq ql b gy qy qq l qr qs">#access the extracted objects from the results<br/>results["extracted_objects"]</span></pre><ul class=""><li id="9e40" class="ma mb iq mc b md nh mf ni lo nm ls nn lw no mk pv mm mn mo bi translated"><strong class="mc ja">save _ extracted _ objects:</strong>这是将每个提取的对象保存为图像的参数。每个被分割的对象将被保存为<strong class="mc ja"><em class="np">segmented _ object _ index</em></strong>例如<strong class="mc ja"><em class="np">segmented _ object _ 1</em></strong>。对象是根据提取的顺序保存的。</li></ul><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="8b77" class="lf lg iq ql b gy qp qq l qr qs">segmented_object_1.jpg<br/>segmented_object_2.jpg<br/>segmented_object_3.jpg<br/>segmented_object_4.jpg<br/>segmented_object_5.jpg<br/>segmented_object_6.jpg</span></pre><div class="kp kq kr ks gt ab cb"><figure class="om kt qz oo op oq or paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/e2add07dd976231d6627563790a3f953.png" data-original-src="https://miro.medium.com/v2/resize:fit:240/format:webp/1*d9IpBdTMxhrbPUXSP0cPnA.jpeg"/></div></figure><figure class="om kt ra oo op oq or paragraph-image"><img src="../Images/665f8e7f1d6cbb8b0b5a004da6a11590.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*qH66O01CbmQSRS3eqfNOag.jpeg"/><p class="la lb gj gh gi lc ld bd b be z dk rb di rc ou translated"><strong class="bd ov">从遮罩坐标中提取物体</strong></p></figure></div><p id="b8ea" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">注意:</strong>图像中的所有物体都被提取出来，我选择只显示其中的两个。</p><h2 id="a603" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated"><strong class="ak">从包围盒坐标中提取</strong></h2><p id="6b20" class="pw-post-body-paragraph mu mv iq mc b md me ka mw mf mg kd mx lo my mz na ls nb nc nd lw ne nf ng mk ij bi translated">默认提取方法从遮罩的坐标中提取对象。提取只给我们关于物体本身的信息，而排除了它的周围环境。考虑一个问题，其中我们想要分析对象和它在图像中所处的区域。PixelLib能够通过使用边界框的坐标提取分割的对象及其在图像中的远程位置来解决这个问题。</p><p id="6cb4" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">修改了提取代码</strong></p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="34e6" class="lf lg iq ql b gy qp qq l qr qs">ins.segmentImage("image.jpg", extract_segmented_objects = True, extract_from_box = True, save_extracted_objects = True, output_image_name="output.jpg")</span></pre><p id="f82f" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">我们引入了一个新的参数<strong class="mc ja"> <em class="np"> extract_from_box </em> </strong>来提取从包围盒坐标中分割出来的对象。每个提取的对象将被保存为<strong class="mc ja"><em class="np">object _ extract _ index</em></strong>例如<strong class="mc ja"><em class="np">object _ extract _ 1</em></strong>。对象是根据提取的顺序保存的。</p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="043a" class="lf lg iq ql b gy qp qq l qr qs">object_extract1.jpg<br/>object_extract2.jpg<br/>object_extract3.jpg<br/>object_extract4.jpg<br/>object_extract5.jpg<br/>object_extract6.jpg</span></pre><div class="kp kq kr ks gt ab cb"><figure class="om kt rd oo op oq or paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/cf5671859b7389b1761b9339b04d756f.png" data-original-src="https://miro.medium.com/v2/resize:fit:248/format:webp/1*xjQb0GQmWJpjtPucct1iug.jpeg"/></div></figure><figure class="om kt re oo op oq or paragraph-image"><img src="../Images/fb93184dc0b35c00dde6dcc998ee0408.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*9AJKRZNA19_NE4aQoDKkxw.jpeg"/><p class="la lb gj gh gi lc ld bd b be z dk rb di rc ou translated">从边界框坐标中提取</p></figure></div><p id="bd14" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">使用边界框坐标提取对象的完整代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><p id="a57d" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">图像分割输出可视化</strong>。</p><p id="837d" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">PixelLib可以根据图像的分辨率来调节图像的可视化。</p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="e7e7" class="lf lg iq ql b gy qp qq l qr qs">ins.segmentImage("sample.jpg", show_bboxes=True, output_image_name= "output.jpg")</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi rf"><img src="../Images/d1e4e73bac58b6083efbe4504be9aa4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PYa2xo6e7c75QuSxzM9law.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://unsplash.com/photos/UiVe5QvOhao" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="aaa0" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">可视化效果不可见，因为文本大小<strong class="mc ja"> <em class="np">、</em> </strong>和框粗细太细。我们可以调整文本大小、粗细和框的粗细来调整可视化效果。</p><h2 id="65a3" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated">为了更好的可视化而进行的修改</h2><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="9926" class="lf lg iq ql b gy qp qq l qr qs">ins.segmentImage(“sample.jpg”, show_bboxes=True, text_size=5, text_thickness=4, box_thickness=10, output_image_name=”output.jpg”)</span></pre><p id="d074" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja"> <em class="np"> segmentImage </em> </strong>函数接受了调节文本和边界框厚度的新参数。</p><ul class=""><li id="80c7" class="ma mb iq mc b md nh mf ni lo nm ls nn lw no mk pv mm mn mo bi translated"><strong class="mc ja"> <em class="np"> text_size: </em> </strong>默认的文字尺寸是<strong class="mc ja"> <em class="np"> 0.6 </em> </strong>，中等分辨率的图片也可以。对于高分辨率的图像来说，它太小了。我把数值增加到<strong class="mc ja"> <em class="np"> 5 </em> </strong>。</li><li id="85a4" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk pv mm mn mo bi translated"><strong class="mc ja"> <em class="np">文本_粗细:</em> </strong>默认的文本粗细是<strong class="mc ja"> <em class="np"> 1 </em> </strong>。我把它增加到<strong class="mc ja"> <em class="np"> 4 </em> </strong>来匹配图像分辨率。</li><li id="ec6e" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk pv mm mn mo bi translated"><strong class="mc ja"><em class="np">box _ thickness:</em></strong>默认的盒子厚度是<strong class="mc ja"> <em class="np"> 2 </em> </strong>我把它改成了<strong class="mc ja"> <em class="np"> 10 </em> </strong>以匹配图像分辨率。</li></ul><p id="3b83" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">输出视觉效果更好的图像</strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi rf"><img src="../Images/a65ac2ac07f8eaf586167179bcb28140.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*caoPRid5QtLHAGdTpWnRMg.jpeg"/></div></div></figure><p id="42f1" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja"> <em class="np">注:</em> </strong>根据您的图像分辨率调节参数。如果您的图像分辨率较低，我对这个分辨率为<strong class="mc ja"> <em class="np"> 5760 x 3840 </em> </strong>的样本图像使用的值可能会太大。如果您有分辨率非常高的图像，您可以增加参数值，使其超过我在这个示例代码中设置的值。<strong class="mc ja"><em class="np">text _ thickness</em></strong>和<strong class="mc ja"><em class="np">box _ thickness</em></strong>参数的值必须是整数，不能用浮点数表示。<strong class="mc ja"> <em class="np"> text_size </em> </strong>值可以用整数和浮点数表示。</p><h1 id="703e" class="pw lg iq bd lh px py pz lk qa qb qc ln kf qd kg lr ki qe kj lv kl qf km lz qg bi translated">批量图像分割</h1><p id="9c48" class="pw-post-body-paragraph mu mv iq mc b md me ka mw mf mg kd mx lo my mz na ls nb nc nd lw ne nf ng mk ij bi translated">PixelLib可以对同一文件夹中的一批图像进行预测。</p><p id="7f9f" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">批量分段代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="9f36" class="lf lg iq ql b gy qp qq l qr qs">ins.segmentBatch("inputfolder",  show_bboxes=True, output_folder_name = "outputfolder")</span></pre><p id="654a" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">批量分割的代码非常类似于单个图像分割，除了我们用<strong class="mc ja"> <em class="np"> segmentBatch </em> </strong>函数替换了<strong class="mc ja"> <em class="np"> segmentImage </em> </strong>函数。我们将以下参数添加到<strong class="mc ja"> <em class="np">段批次:</em> </strong></p><ul class=""><li id="859b" class="ma mb iq mc b md nh mf ni lo nm ls nn lw no mk pv mm mn mo bi translated"><strong class="mc ja"> folder_path: </strong>这是包含我们要分割的图像的文件夹。</li><li id="7215" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk pv mm mn mo bi translated"><strong class="mc ja">输出文件夹名称:</strong>这是我们将保存所有分割图像的文件夹名称。</li></ul><p id="0358" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">样本文件夹结构</strong></p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="c48e" class="lf lg iq ql b gy qp qq l qr qs">--input_folder<br/>    --test1.jpg<br/>    --test2.jpg<br/>    --test3.jpg<br/><br/>--output_folder <br/>    --test1.jpg<br/>    --test2.jpg<br/>    --test3.jpg</span></pre><p id="64c7" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">批量图像分割对象提取代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="12e4" class="lf lg iq ql b gy qp qq l qr qs">ins.segmentBatch("inputfolder", show_bboxes=True, extract_segmented_objects=True, save_extracted_objects=True, output_folder_name="outputfolder")</span></pre><p id="c41f" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">我们在<strong class="mc ja"> segmentBatch </strong>函数中添加了<strong class="mc ja">extract _ segmented _ objects</strong>和<strong class="mc ja"> save_extracted_objects参数</strong>，分别对<strong class="mc ja"> </strong>提取和保存提取的对象。输入文件夹中每幅图像的提取对象将保存在一个单独的文件夹中，其名称为<strong class="mc ja"><em class="np">imagename _ extracts</em></strong>例如，如果图像名称为<strong class="mc ja"><em class="np"/></strong>这意味着提取的对象将保存在一个名为<strong class="mc ja"><em class="np">test1 _ extracts</em></strong>的文件夹中。</p><p id="19f4" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">注意:</strong>提取对象的文件夹在图像的相同输入文件夹中创建。<em class="np">样本文件夹结构</em></p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="8ba9" class="lf lg iq ql b gy qp qq l qr qs">--input_folder<br/>    --test1.jpg<br/>    --test1_extracts </span><span id="5874" class="lf lg iq ql b gy qy qq l qr qs">    --test2.jpg<br/>    --test2_extracts </span><span id="1983" class="lf lg iq ql b gy qy qq l qr qs">    --test3.jpg<br/>    --test3_extracts</span><span id="c00c" class="lf lg iq ql b gy qy qq l qr qs">--output_folder   <br/>    --test1.jpg<br/>    --test2.jpg<br/>    --test3.jpg</span></pre><p id="daca" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">从边界框坐标中提取对象的代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="802f" class="lf lg iq ql b gy qp qq l qr qs">ins.segmentBatch("inputfolder", show_bboxes=True, extract_segmented_objects=True, extract_from_box=True,save_extracted_objects=True, output_folder_name="outputfolder")</span></pre><p id="9349" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">我们在<strong class="mc ja"> segmentBatch </strong>函数中添加了<strong class="mc ja"> extract_from_box </strong>和<strong class="mc ja"> save_extracted_objects参数</strong>，分别对<strong class="mc ja">和</strong>提取并保存提取的对象。</p><p id="e199" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">注意:</strong>从边界框坐标中提取的对象的文件夹也在图像的相同输入文件夹中创建。<em class="np">样本文件夹结构</em></p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="2c40" class="lf lg iq ql b gy qp qq l qr qs">--input_folder<br/>    --test1.jpg<br/>    --test1_extracts</span><span id="c201" class="lf lg iq ql b gy qy qq l qr qs">    --test2.jpg<br/>    --test2_extracts</span><span id="6aad" class="lf lg iq ql b gy qy qq l qr qs">    --test3.jpg<br/>    --test3_extracts</span><span id="33e6" class="lf lg iq ql b gy qy qq l qr qs">--output_folder   <br/>    --test1.jpg<br/>    --test2.jpg<br/>    --test3.jpg</span></pre><p id="3c72" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">批量图像分割中自定义对象分割的代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="556e" class="lf lg iq ql b gy qp qq l qr qs">target_classes = ins.select_target_classes(person = True)<br/>ins.segmentBatch("inputfolder", show_bboxes=True, segment_target_classes = target_classes, output_folder_name="outputfolder")</span></pre><p id="0f7b" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">我们调用函数<strong class="mc ja"> select_target_classes </strong>来选择要分割的目标对象。函数<strong class="mc ja"> <em class="np"> segmentBatch </em> </strong>函数获得了一个新参数<strong class="mc ja"><em class="np">segment _ target _ classes</em></strong>以从<strong class="mc ja"> <em class="np">目标类</em> </strong>中进行选择，并根据它们过滤检测。</p><p id="54d0" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">批量图像分割中的快速模式检测代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="5060" class="lf lg iq ql b gy qp qq l qr qs">ins.load_model(“pointrend_resnet50.pkl”, detection_speed = "fast")</span></pre><p id="54e3" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">在<em class="np"/><strong class="mc ja"><em class="np">load _ model</em></strong><em class="np"/>函数中，我们增加了参数<strong class="mc ja"><em class="np">detection _ speed</em></strong>并将值设置为<strong class="mc ja"> <em class="np"> fast </em> </strong>。<strong class="mc ja"> <em class="np">快速</em> </strong>模式处理单幅图像达到<strong class="mc ja"> <em class="np"> 0.20秒</em> </strong>。</p><p id="c6b6" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">批量图像分割快速模式检测代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="cbf4" class="lf lg iq ql b gy qp qq l qr qs">ins.load_model(“pointrend_resnet50.pkl”, detection_speed = "rapid")</span></pre><p id="1dca" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">我们将用于推断的检测速度设置为<strong class="mc ja"> <em class="np">快速</em> </strong>模式。</p><p id="20d3" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">在<em class="np"/><strong class="mc ja"><em class="np">load _ model</em></strong><em class="np"/>函数中，我们添加了参数<strong class="mc ja"><em class="np">detection _ speed</em></strong>并将值设置为<strong class="mc ja"> <em class="np">【快速】</em> </strong>。<strong class="mc ja"> <em class="np">快速</em> </strong>模式处理单幅图像达到<strong class="mc ja"><em class="np"/></strong>0.15秒。</p><p id="abc6" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">注:</strong>除了<strong class="mc ja"> <em class="np"> segmentImage </em> </strong>函数被<strong class="mc ja"> <em class="np"> segmentBatch替代之外，PixelLib所有支持特性的批量图像分割的代码实现与单个图像分割相同。</em> </strong></p><h1 id="1006" class="pw lg iq bd lh px py pz lk qa qb qc ln kf qd kg lr ki qe kj lv kl qf km lz qg bi translated">视频和相机馈送中的对象分割</h1><p id="eb00" class="pw-post-body-paragraph mu mv iq mc b md me ka mw mf mg kd mx lo my mz na ls nb nc nd lw ne nf ng mk ij bi translated">PixelLib使实时摄像机输入和视频文件中的实时对象分割成为可能。</p><h2 id="eaae" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated"><strong class="ak">视频分割</strong></h2><p id="0f33" class="pw-post-body-paragraph mu mv iq mc b md me ka mw mf mg kd mx lo my mz na ls nb nc nd lw ne nf ng mk ij bi translated">用于视频分段的代码</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><p id="5d63" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">第1–4行:</strong> PixelLib包被导入，我们还从模块<strong class="mc ja"><em class="np">PixelLib . torch backend . instance</em><em class="np"/>中导入了类<strong class="mc ja"><em class="np">instance segmentation</em></strong><em class="np"/>(从pytorch支持中导入实例分割类)。我们创建了该类的一个实例，最后加载了<strong class="mc ja"><em class="np">point rende</em></strong>模型。如果模型尚未下载，请从<a class="ae le" href="https://github.com/ayoolaolafenwa/PixelLib/releases/download/0.2.0/pointrend_resnet50.pkl" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</strong></p><p id="680c" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">第5行:</strong>我们调用函数<strong class="mc ja"><em class="np">process _ video</em></strong>对视频中的对象进行分割，该函数增加了以下参数:</p><ul class=""><li id="993b" class="ma mb iq mc b md nh mf ni lo nm ls nn lw no mk pv mm mn mo bi translated"><strong class="mc ja"> video_path: </strong>这是要分割的视频的路径。</li><li id="cee2" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk pv mm mn mo bi translated"><strong class="mc ja"> show_bboxes: </strong>这是一个可选参数，用边界框显示结果中的分割对象。</li><li id="beb4" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk pv mm mn mo bi translated"><strong class="mc ja">每秒帧数:</strong>该参数将为保存的视频设置每秒帧数。</li><li id="96f9" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk pv mm mn mo bi translated"><strong class="mc ja">输出视频名称:</strong>这是输出分段视频的名称。</li></ul><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="fadc" class="lf lg iq ql b gy qp qq l qr qs">ins.process_video("sample_video.mp4", show_bboxes=True, frames_per_second=3, output_video_name="output_video.mp4")</span></pre><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="rg qi l"/></div></figure><p id="b62a" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">视频中物体提取的代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="a0f3" class="lf lg iq ql b gy qp qq l qr qs">ins.process_video(“sample_video.mp4”, show_bboxes=True,  extract_segmented_objectsframes_per_second=5, output_video_name=”output_video.mp4")</span></pre><p id="7624" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja"> <em class="np"> process_video </em> </strong>函数新增了参数<em class="np"/><strong class="mc ja"><em class="np">extract _ segmented _ objects</em></strong>和<strong class="mc ja"><em class="np">save _ extracted _ objects</em></strong>分别用于提取和保存分段对象。</p><div class="kp kq kr ks gt ab cb"><figure class="om kt rh oo op oq or paragraph-image"><img src="../Images/82e26d64fbb3e780cd69dd6855cd482e.png" data-original-src="https://miro.medium.com/v2/resize:fit:246/format:webp/1*QwTI7MEJ4BQXk3wl5wvSuQ.jpeg"/></figure><figure class="om kt ri oo op oq or paragraph-image"><img src="../Images/890ea4c10cc04a45aef80debb20e7fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*Xiq9aH5XKEBkGfgNC50OzA.jpeg"/></figure><figure class="om kt rj oo op oq or paragraph-image"><img src="../Images/a64acd12b9e08def5f575691c34c441d.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*vTBLdMuNrxezwnmiOEspww.jpeg"/><p class="la lb gj gh gi lc ld bd b be z dk rk di rl ou translated">提取的对象</p></figure></div><p id="7bb3" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">提取视频中的包围盒坐标</strong></p><p id="0070" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">修改了提取代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="9057" class="lf lg iq ql b gy qp qq l qr qs">ins.process_video(“sample.mp4”, show_bboxes=True, extract_segmented_objects=True, extract_from_box=True,save_extracted_objects=True, frames_per_second=5, output_video_name=”output_video.mp4")</span></pre><ul class=""><li id="9844" class="ma mb iq mc b md nh mf ni lo nm ls nn lw no mk pv mm mn mo bi translated"><strong class="mc ja"><em class="np">extract _ from _ box</em></strong>被<em class="np"> </em>添加到从包围盒坐标提取分割对象的功能中。</li></ul><div class="kp kq kr ks gt ab cb"><figure class="om kt rm oo op oq or paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/3eeed3070a34fcb0c874183891bf0194.png" data-original-src="https://miro.medium.com/v2/resize:fit:252/format:webp/1*pS7EEG8oopGrztuveQssng.jpeg"/></div></figure><figure class="om kt rn oo op oq or paragraph-image"><img src="../Images/5fab39699a7be22f72dce911121ec15f.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*lM4BafIG94t15cgLfhmKKg.jpeg"/></figure><figure class="om kt ro oo op oq or paragraph-image"><img src="../Images/cbe3d00bb9faa66ba8e4d78aeb02d45a.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*VaIGLho2PlZ0niQ613H-pA.jpeg"/><p class="la lb gj gh gi lc ld bd b be z dk rp di rq ou translated">方框摘录</p></figure></div><p id="4a60" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">自定义视频中的对象分割</strong></p><p id="e648" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">PixelLib可以在视频中执行自定义对象分割，以过滤未使用的检测和分割目标类别。</p><p id="cad8" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">视频自定义检测代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="9961" class="lf lg iq ql b gy qp qq l qr qs">target_classes = ins.select_target_classes(person = True, bicycle =True)</span><span id="641b" class="lf lg iq ql b gy qy qq l qr qs">ins.process_video("sample_video.mp4", show_bboxes=True, segment_target_classes = target_classes,frames_per_second=5, output_video_name="output_video.mp4")</span></pre><p id="24b7" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">调用函数<strong class="mc ja"><em class="np">select _ target _ classes</em></strong>选择要分割的目标对象。函数<strong class="mc ja"><em class="np">process _ video</em></strong>得到了一个新的参数<strong class="mc ja"><em class="np">segment _ target _ classes</em></strong>从<strong class="mc ja"> <em class="np">目标类</em> </strong>中选择并根据它们过滤检测。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="rg qi l"/></div></figure><p id="6965" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">视频分割中的快速模式检测代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="e59b" class="lf lg iq ql b gy qp qq l qr qs">ins.load_model(“pointrend_resnet50.pkl”, detection_speed = "fast")</span></pre><p id="007f" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">我们将视频处理的检测速度设置为<strong class="mc ja"> <em class="np">快速</em> </strong>模式。</p><p id="d6d2" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">视频分割中的快速模式检测代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="fbf0" class="lf lg iq ql b gy qp qq l qr qs">ins.load_model(“pointrend_resnet50.pkl”, detection_speed = "rapid")</span></pre><p id="89df" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">我们将视频处理的检测速度设置为<strong class="mc ja"> <em class="np">快速</em> </strong>模式。</p><h1 id="bbf8" class="pw lg iq bd lh px py pz lk qa qb qc ln kf qd kg lr ki qe kj lv kl qf km lz qg bi translated">实况摄像机馈送中的对象分割</h1><p id="e24f" class="pw-post-body-paragraph mu mv iq mc b md me ka mw mf mg kd mx lo my mz na ls nb nc nd lw ne nf ng mk ij bi translated">PixelLib为实时摄像机输入的实时分段提供了出色的支持。</p><p id="3b47" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">现场摄像机画面分割代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="4417" class="lf lg iq ql b gy qp qq l qr qs">import cv2 capture = cv2.VideoCapture(0)</span></pre><p id="8dbd" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">我们导入了cv2并包含了捕捉相机帧的代码。</p><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="9eff" class="lf lg iq ql b gy qp qq l qr qs">segment_video.process_camera(capture,  show_bboxes = True, frames_per_second= 5, check_fps=True, show_frames= True,frame_name= "frame", output_video_name="output_video.mp4")</span></pre><p id="abab" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">在执行分段的代码中，我们替换了要捕获的视频文件路径，也就是说，我们正在处理摄像机捕获的帧流。我们添加了额外的参数来显示相机的帧:</p><ul class=""><li id="e0ca" class="ma mb iq mc b md nh mf ni lo nm ls nn lw no mk pv mm mn mo bi translated"><strong class="mc ja"> show_frames <em class="np"> : </em> </strong>这是处理分段摄像机帧显示的参数。</li><li id="7d7f" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk pv mm mn mo bi translated"><strong class="mc ja"> frame_name: </strong> <em class="np"> </em>这是显示的相机帧的名称。</li><li id="7615" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk pv mm mn mo bi translated"><strong class="mc ja"> <em class="np"> check_fps: </em> </strong>该参数将在相机进给处理结束时每秒打印出帧数。</li><li id="4d2c" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk pv mm mn mo bi translated">这是一个可选参数，显示带有边界框的分段对象。</li><li id="a402" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk pv mm mn mo bi translated"><strong class="mc ja">每秒帧数:</strong>该参数设置保存的视频文件每秒帧数。在这种情况下，它被设置为5，即保存的视频文件每秒将有5帧。</li><li id="8c68" class="ma mb iq mc b md mp mf mq lo mr ls ms lw mt mk pv mm mn mo bi translated"><strong class="mc ja">输出视频名称:</strong>这是保存的分段视频的名称。</li></ul><p id="f551" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">实时摄像处理的速度调整</strong></p><p id="0436" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">默认速度模式达到<strong class="mc ja"> <em class="np"> 4fps </em> </strong>。<strong class="mc ja"> <em class="np">快速</em> </strong>速度模式达到<strong class="mc ja"><em class="np"/></strong>6 fps<em class="np"/><strong class="mc ja"><em class="np">快速</em> </strong>速度模式达到<strong class="mc ja"> <em class="np"> 9fps </em> </strong>。这些报告基于使用4GB容量的Nvidia GPU</p><p id="9d4c" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">相机进给中的快速模式检测代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="5470" class="lf lg iq ql b gy qp qq l qr qs">ins.load_model(“pointrend_resnet50.pkl”, detection_speed = "fast")</span></pre><p id="44c3" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">我们将处理实况摄像机馈送的检测速度设置为<strong class="mc ja"> <em class="np">快速</em> </strong>模式，推断速度将为<strong class="mc ja"> <em class="np"> 6fps </em> </strong>。</p><p id="390f" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">快速模式检测代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="9cc0" class="lf lg iq ql b gy qp qq l qr qs">ins.load_model(“pointrend_resnet50.pkl”, detection_speed = "rapid")</span></pre><p id="bea8" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">我们将处理实况摄像机馈送的检测速度设置为<strong class="mc ja"> <em class="np">快速</em> </strong>模式，推断速度将为<strong class="mc ja"> <em class="np"> 9fps </em> </strong>。</p><p id="2836" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">现场摄像机馈送中的自定义对象分割代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="5a8a" class="lf lg iq ql b gy qp qq l qr qs">target_classes = segment_video.select_target_classes(person=True)</span><span id="9492" class="lf lg iq ql b gy qy qq l qr qs">segment_video.process_camera(capture,  show_bboxes = True, frames_per_second= 5, segment_target_classes = target_classes,show_frames= True,frame_name= "frame", output_video_name="output_video.mp4")</span></pre><p id="6230" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">调用函数<strong class="mc ja"><em class="np">select _ target _ classes</em></strong>选择要分割的目标对象。函数<strong class="mc ja"><em class="np">process _ camera</em></strong>得到了一个新参数<strong class="mc ja"><em class="np">segment _ target _ classes</em></strong>从<strong class="mc ja"> <em class="np">目标类</em> </strong>中选择并根据它们过滤检测。</p><p id="19b5" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">现场摄像机输入中的对象提取代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="cc41" class="lf lg iq ql b gy qp qq l qr qs">segment_video.process_camera(capture,  show_bboxes = True, frames_per_second= 5, extract_segmented_objects=True, save_extracted_objects=True,show_frames= True,frame_name= "frame", output_video_name="output_video.mp4")</span></pre><p id="5e8d" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja"><em class="np">process _ camera</em></strong>函数有新的参数<em class="np"/><strong class="mc ja"><em class="np">extract _ segmented _ objects</em></strong>和<strong class="mc ja"><em class="np">save _ extracted _ objects</em></strong>来分别提取和保存分段对象。</p><ul class=""><li id="0b7c" class="ma mb iq mc b md nh mf ni lo nm ls nn lw no mk pv mm mn mo bi translated"><strong class="mc ja"><em class="np">extract _ from _ box</em></strong>被<em class="np"> </em>添加到从包围盒坐标提取分割对象的功能中。</li></ul><p id="f106" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">从现场摄像机输入的框坐标中提取目标对象的代码</strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="qh qi l"/></div></figure><pre class="kp kq kr ks gt qk ql qm qn aw qo bi"><span id="ea4f" class="lf lg iq ql b gy qp qq l qr qs">segment_video.process_camera(capture,  show_bboxes = True, frames_per_second= 5, extract_segmented_objects=True, extract_from_box=True,save_extracted_objects=True, show_frames= True,frame_name= "frame", output_video_name="output_video.mp4")</span></pre><ul class=""><li id="72e6" class="ma mb iq mc b md nh mf ni lo nm ls nn lw no mk pv mm mn mo bi translated"><strong class="mc ja"><em class="np">extract _ from _ box</em></strong>被<em class="np"> </em>添加到从包围盒坐标提取分割对象的功能中。</li></ul><p id="bf4b" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">我们在本文中详细讨论了如何使用PixelLib Pytorch版本在图像和实时摄像机馈送中执行准确快速的图像分割和对象提取。我们还描述了使用PointRend网络架构添加到PixelLib的升级，这使得该库能够满足日益增长的需求，以平衡计算机视觉中的准确性和速度性能。</p><p id="7220" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated"><strong class="mc ja">注意:</strong>PixelLib py torch版本不支持自定义训练，使用PointRend的自定义训练即将发布。</p><blockquote class="nw"><p id="ee66" class="nx ny iq bd nz oa rr rs rt ru rv mk dk translated"><a class="ae le" href="https://github.com/ayoolaolafenwa/PixelLib" rel="noopener ugc nofollow" target="_blank">访问PixelLib官方github知识库</a></p><p id="a70d" class="nx ny iq bd nz oa rr rs rt ru rv mk dk translated"><a class="ae le" href="https://pixellib.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">访问PixelLib的官方文档</a></p></blockquote><p id="8536" class="pw-post-body-paragraph mu mv iq mc b md ow ka mw mf ox kd mx lo oy mz na ls oz nc nd lw pa nf ng mk ij bi translated">通过以下方式联系我:</p><p id="5f6a" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">电子邮件:<a class="ae le" href="https://mail.google.com/mail/u/0/#inbox" rel="noopener ugc nofollow" target="_blank">olafenwaayoola@gmail.com</a></p><p id="968e" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">Linkedin: <a class="ae le" href="https://www.linkedin.com/in/ayoola-olafenwa-003b901a9/" rel="noopener ugc nofollow" target="_blank">阿尤拉·奥拉芬娃</a></p><p id="8d1b" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">推特:<a class="ae le" href="https://twitter.com/AyoolaOlafenwa" rel="noopener ugc nofollow" target="_blank"> @AyoolaOlafenwa </a></p><p id="0856" class="pw-post-body-paragraph mu mv iq mc b md nh ka mw mf ni kd mx lo nj mz na ls nk nc nd lw nl nf ng mk ij bi translated">查看这些关于如何利用PixelLib在图像和视频中进行语义分割、实例分割、对象提取和背景编辑的文章。</p><div class="pb pc gp gr pd pe"><a rel="noopener follow" target="_blank" href="/video-segmentation-with-5-lines-of-code-87f798afb93"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd ja gy z fp pj fr fs pk fu fw iz bi translated">用5行代码实现视频分割</h2><div class="ps l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">视频的语义和实例分割。</h3></div><div class="pl l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">towardsdatascience.com</p></div></div><div class="pm l"><div class="rw l po pp pq pm pr ky pe"/></div></div></a></div><div class="pb pc gp gr pd pe"><a rel="noopener follow" target="_blank" href="/semantic-segmentation-of-150-classes-of-objects-with-5-lines-of-code-7f244fa96b6c"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd ja gy z fp pj fr fs pk fu fw iz bi translated">用5行代码对150类对象进行语义分割</h2><div class="ps l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">用PixelLib对150类对象进行语义分割</h3></div><div class="pl l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">towardsdatascience.com</p></div></div><div class="pm l"><div class="rx l po pp pq pm pr ky pe"/></div></div></a></div><div class="pb pc gp gr pd pe"><a rel="noopener follow" target="_blank" href="/change-the-background-of-any-image-with-5-lines-of-code-23a0ef10ce9a"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd ja gy z fp pj fr fs pk fu fw iz bi translated">用5行代码改变任何图像的背景</h2><div class="pl l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">towardsdatascience.com</p></div></div><div class="pm l"><div class="ry l po pp pq pm pr ky pe"/></div></div></a></div><div class="pb pc gp gr pd pe"><a rel="noopener follow" target="_blank" href="/change-the-background-of-any-video-with-5-lines-of-code-7cc847394f5d"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd ja gy z fp pj fr fs pk fu fw iz bi translated">用5行代码改变任何视频的背景</h2><div class="ps l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">使用PixelLib对视频进行模糊、彩色、灰度处理并创建虚拟背景</h3></div><div class="pl l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">towardsdatascience.com</p></div></div><div class="pm l"><div class="rz l po pp pq pm pr ky pe"/></div></div></a></div><div class="pb pc gp gr pd pe"><a rel="noopener follow" target="_blank" href="/extraction-of-objects-in-images-and-videos-using-5-lines-of-code-6a9e35677a31"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd ja gy z fp pj fr fs pk fu fw iz bi translated">使用5行代码提取图像和视频中的对象。</h2><div class="ps l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">计算机视觉是计算机看到和识别物体的媒介。计算机视觉的目标是让…</h3></div><div class="pl l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">towardsdatascience.com</p></div></div><div class="pm l"><div class="sa l po pp pq pm pr ky pe"/></div></div></a></div></div></div>    
</body>
</html>