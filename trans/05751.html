<html>
<head>
<title>Explainable AI (XAI) with SHAP - regression problem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可解释人工智能(XAI)与SHAP回归问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/explainable-ai-xai-with-shap-regression-problem-b2d63fdca670?source=collection_archive---------3-----------------------#2021-05-23">https://towardsdatascience.com/explainable-ai-xai-with-shap-regression-problem-b2d63fdca670?source=collection_archive---------3-----------------------#2021-05-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5dcf" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">回归问题的SHAP XAI分析实用指南</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/eb1ef6e79cdedf92311854f85ab5dc88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NdxIFtI2AeW3WkTaFePRjA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由<a class="ae kv" href="https://www.pexels.com/@startup-stock-photos" rel="noopener ugc nofollow" target="_blank">创业股票照片</a> Sager发自<a class="ae kv" href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=2755908" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="9133" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">模型可解释性成为机器学习管道的基本部分。将机器学习模型作为“黑盒”不再是一个选项。幸运的是，有一些工具正在快速发展，变得越来越流行。本指南是XAI分析SHAP开源Python包回归问题的实用指南。</p><p id="dd37" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Lundberg和Lee ( <a class="ae kv" href="https://dl.acm.org/doi/10.5555/3295222.3295230" rel="noopener ugc nofollow" target="_blank"> 2016 </a>)的SHAP(Shapley Additive explaints)是一种解释个体预测的方法，基于博弈理论上的最优Shapley值。Shapley值是合作博弈理论中广泛使用的一种方法，它具有令人满意的性质。数据实例的特征值充当联盟中的参与者。Shapley值是一个特性值在所有可能的联合[ <a class="ae kv" href="https://christophm.github.io/interpretable-ml-book/shap.html#shap-feature-importance" rel="noopener ugc nofollow" target="_blank"> 1 </a> ]中的平均边际贡献。</p><p id="ad5e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本指南中，我们将使用来自sklearn数据集的波士顿房价数据集示例。是简单的回归问题<a class="ae kv" href="https://scikit-learn.org/stable/datasets/toy_dataset.html#boston-dataset" rel="noopener ugc nofollow" target="_blank">【2】</a>。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="91dd" class="lx ly iq lt b gy lz ma l mb mc">boston = datasets.load_boston()<br/>X_train, X_test, y_train, y_test = model_selection.train_test_split(boston.data, boston.target, random_state=0)</span></pre><p id="d23f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将数据集拆分为定型和测试数据集后，创建模型并进行拟合。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="7e78" class="lx ly iq lt b gy lz ma l mb mc">regressor = ensemble.RandomForestRegressor()<br/>regressor.fit(X_train, y_train);</span></pre><h2 id="5b65" class="lx ly iq bd md me mf dn mg mh mi dp mj lf mk ml mm lj mn mo mp ln mq mr ms mt bi translated">计算Shapley值</h2><p id="b97e" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">使用SHAP软件包，计算非常简单明了。我们只需要模型(回归量)和数据集(X_train)。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="5fc6" class="lx ly iq lt b gy lz ma l mb mc"># Create object that can calculate shap values<br/>explainer = shap.TreeExplainer(regressor)<br/># Calculate Shap values<br/>shap_values = explainer.shap_values(X_train)</span></pre><p id="a883" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">计算完SHAP值后，我们可以绘制一些分析图，帮助我们理解这个模型。</p><h1 id="1957" class="mz ly iq bd md na nb nc mg nd ne nf mj jw ng jx mm jz nh ka mp kc ni kd ms nj bi translated">SHAP特征重要性</h1><p id="6a4d" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">作为第一步，我建议查看特性的重要性。这是对模型的基本理解。在下图中，您可以看到通过SHAP值计算的特征重要性(具有大绝对沙普利值的特征是重要的)和通过每棵树内杂质减少累积的平均值和标准偏差计算的特征重要性之间的比较(使用scikit-learn<a class="ae kv" href="https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html" rel="noopener ugc nofollow" target="_blank">【3】</a>)。正如你所看到的，它们看起来非常相似，但它们并不相同。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="c300" class="lx ly iq lt b gy lz ma l mb mc">shap.summary_plot(shap_values, X_train, feature_names=features, plot_type="bar")</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/c937dc98027bece2f34b6013b3c73746.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B0HzcgvoqPccVLaXFE25dg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在左侧要素中，重要性由SHAP值计算得出。在右侧特征上，重要性通过使用scikit-learn模型来计算。作者图片</p></figure><h1 id="323e" class="mz ly iq bd md na nb nc mg nd ne nf mj jw ng jx mm jz nh ka mp kc ni kd ms nj bi translated">SHAP汇总图</h1><p id="aa13" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">摘要图结合了特征重要性和特征效果。摘要图上的每个点都是每个特性的一个实例的Shapley值。y轴上的位置由特征决定，x轴上的位置由每个实例的Shapley值决定。可以看到，LSTAT是最重要的特征，具有较高的Shapley值范围。颜色代表从低到高的特性值。重叠点在y轴方向上抖动，因此我们可以了解每个要素的Shapley值的分布情况。这些功能根据其重要性进行排序。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="d6f5" class="lx ly iq lt b gy lz ma l mb mc">shap.summary_plot(shap_values, X_train, feature_names=features)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/a24f3817fd8691c8e68fd007ec5d80c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7f9dMKTojseReLaxtUaK3w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="0b7e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在汇总图中，我们看到了特性值和对预测的影响之间关系的初步迹象。但是为了看到这种关系的确切形式，我们必须看看SHAP依赖图。</p><h1 id="c5ce" class="mz ly iq bd md na nb nc mg nd ne nf mj jw ng jx mm jz nh ka mp kc ni kd ms nj bi translated">SHAP依赖图</h1><p id="40d5" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">部分依赖图(PDP或PD图)显示了一个或两个特征对机器学习模型的预测结果的边际影响(j . h . Friedman 2001<a class="ae kv" href="https://statweb.stanford.edu/~jhf/ftp/trebst.pdf" rel="noopener ugc nofollow" target="_blank">【4】</a>)。部分相关性图可以显示目标和特征之间的关系是线性的、单调的还是更复杂的。部分相关图是一种全局方法:该方法考虑所有实例，并给出一个关于特征与预测结果的全局关系的陈述。PDP假设第一特征与第二特征不相关。如果违反了这一假设，为部分相关图计算的平均值将包括非常不可能甚至不可能的数据点。</p><p id="f188" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">相关性图是一种散点图，显示单个功能对模型所做预测的影响。在这个例子中，当每个住所的平均房间数高于6时，房产价值显著增加。</p><ul class=""><li id="1ba0" class="nm nn iq ky b kz la lc ld lf no lj np ln nq lr nr ns nt nu bi translated">每个点都是数据集中的一个预测(行)。</li><li id="b42e" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr nr ns nt nu bi translated">x轴是数据集中的实际值。</li><li id="7abb" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr nr ns nt nu bi translated">y轴是该要素的SHAP值，表示知道该要素值后该预测的模型输出会发生多大的变化。</li></ul><p id="2108" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该颜色对应于可能与我们正在绘制的特征有交互作用的第二个特征(默认情况下，该第二个特征被自动选择)。如果另一个特征和我们正在绘制的特征之间存在交互作用，它将显示为明显的垂直着色图案。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="d43f" class="lx ly iq lt b gy lz ma l mb mc">shap.dependence_plot(5, shap_values, X_train, feature_names=features)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/437aeeeea3c867b236743ec09e8b42e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*KHvXoUxb12Qfz2MHEWfJIA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="7541" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的例子中，我们可以看到每个住宅的平均房间数高于7.5，CRIM总是很低。这些病例的Shapley值很高，大大提高了结果。这种洞察力是RM、卷曲特征之间的依赖性相互作用的函数。</p><h1 id="72b7" class="mz ly iq bd md na nb nc mg nd ne nf mj jw ng jx mm jz nh ka mp kc ni kd ms nj bi translated">SHAP力图</h1><p id="58f1" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">这个图给了我们一个单一模型预测的解释能力。力图可用于误差分析，找到对具体实例预测的解释。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="9c8e" class="lx ly iq lt b gy lz ma l mb mc">i = 18<br/>shap.force_plot(explainer.expected_value, shap_values[i], X_test[i], feature_names = features)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/133b41c56b1189e35794a9ca63b9aa49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xd4y5QdaWAGwrDv4qsiL9w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="a7e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从这个情节我们可以看出:</p><ol class=""><li id="1958" class="nm nn iq ky b kz la lc ld lf no lj np ln nq lr oc ns nt nu bi translated">模型输出值:16.83</li><li id="3561" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr oc ns nt nu bi translated">基本值:这是在我们不知道当前实例的任何特性的情况下预测的值。基本值是模型输出在训练数据集上的平均值(代码中的explainer.expected_value)。</li><li id="2ce2" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr oc ns nt nu bi translated">绘图箭头上的数字是该实例的特征值。CRIM，城镇人均犯罪率= 0.06664，RM，平均房间数= 6.546</li><li id="f19f" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr oc ns nt nu bi translated">红色表示将模型得分推高的要素，蓝色表示将得分推低的要素。</li><li id="54ec" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr oc ns nt nu bi translated">箭头越大，要素对输出的影响越大。影响的减少或增加量可以在x轴上看到。</li><li id="4f2d" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr oc ns nt nu bi translated">0.066的卷曲增加属性值，6.546的RM减少属性值。</li></ol><p id="f88f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们想更全面地展示先前的预测，我们可以使用力图的变体。在这里，我们可以看到一组垂直(旋转90°)并排放置的行的预测。在下图中，我们可以看到数据集中的前5行。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="dad7" class="lx ly iq lt b gy lz ma l mb mc"># visualize the first 5 predictions explanations with a dark red dark blue color map.<br/>shap.force_plot(explainer.expected_value, shap_values[0:5,:], X_test[0:5,:], plot_cmap="DrDb", feature_names=features)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/d4636dca69a95f4ff41b04f4d12916ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A9lZ0aEGL35tHjYlJADG2A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="a6d4" class="mz ly iq bd md na nb nc mg nd ne nf mj jw ng jx mm jz nh ka mp kc ni kd ms nj bi translated">SHAP决策图</h1><p id="0d6e" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">决策图显示了与力图基本相同的信息。灰色垂直线是基值<strong class="ky ir"> </strong>，红线表示每个特征是否将输出值<strong class="ky ir"> </strong>移动到比平均预测值更高或更低的值。</p><p id="b218" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个图可以比前一个图更清晰和直观一点，尤其是当有许多特征要分析的时候。在力图中，当预测因子的数量很高时，信息可能看起来非常浓缩。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="ad3d" class="lx ly iq lt b gy lz ma l mb mc">shap.decision_plot(explainer.expected_value[0], shap_values[0], feature_names = list(features))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/156931340e53b4fa3635b67a8a8169d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uXMHHGqmzJz9iTWDLSk-AQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="4995" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">决策图的垂直直线标记了模型的基础值。这条彩色的线是预测。特征值打印在预测线旁边，以供参考。从图的底部开始，预测线显示了SHAP值如何从基础值累积到图顶部的模型最终得分。决策图是SHAP值的文字表示，使它们易于解释。</p><p id="c550" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">力图和决策图都有效地解释了前述模型的预测。主要影响的大小和方向很容易识别。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/ad0595cfb6ab69f25fd305099285f41e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_Njo9p8GbekZaTlv"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">基于SHAP值的异常值检测。来源<a class="ae kv" href="https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/decision_plot.html" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="89f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将决策图堆叠在一起有助于根据SHAP值定位异常值。在上图中，您可以看到一个不同数据集的示例，使用SHAP决策图进行异常值检测。</p><h1 id="aeca" class="mz ly iq bd md na nb nc mg nd ne nf mj jw ng jx mm jz nh ka mp kc ni kd ms nj bi translated">摘要</h1><p id="97fe" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">SHAP框架已被证明是机器学习模型解释领域的一个重要进步。SHAP结合了几种现有的方法，创造了一种直观的，理论上合理的方法来解释任何模型的预测。SHAP值量化了特征对预测<a class="ae kv" rel="noopener" target="_blank" href="/introducing-shap-decision-plots-52ed3b4a1cba">【6】</a>的影响的大小和方向(正或负)。我相信XAI分析与SHAP和其他工具应该是机器学习管道的一个组成部分。更多关于XAI与SHAP的多类分类问题，请参见<a class="ae kv" rel="noopener" target="_blank" href="/explainable-ai-xai-with-shap-multi-class-classification-problem-64dd30f97cea">链接</a>。本帖中的代码可以在<a class="ae kv" href="https://github.com/Iditc/Posts-on-Medium/blob/main/Explainable%20AI/Explainable%20AI%20(XAI)%20with%20SHAP%20-%20regression%20problem.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div></div>    
</body>
</html>