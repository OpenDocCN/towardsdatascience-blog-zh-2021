<html>
<head>
<title>Apriori Algorithm for Association Rule Learning — How To Find Clear Links Between Transactions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关联规则学习的Apriori算法——如何发现事务间的清晰联系</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/apriori-algorithm-for-association-rule-learning-how-to-find-clear-links-between-transactions-bf7ebc22cf0a?source=collection_archive---------3-----------------------#2021-07-11">https://towardsdatascience.com/apriori-algorithm-for-association-rule-learning-how-to-find-clear-links-between-transactions-bf7ebc22cf0a?source=collection_archive---------3-----------------------#2021-07-11</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><h2 id="7270" class="is it iu bd b dl iv iw ix iy iz ja dk jb translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><div class=""><h2 id="f93d" class="pw-subtitle-paragraph ka jd iu bd b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr dk translated">Python中关系数据库的频繁项集挖掘和关联规则学习的解释和示例</h2></div><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ks"><img src="../Images/427128c79a2eda9ceefcb306523922a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b1X3sV7WgElbWUZCYMOMrA.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">关联规则学习。由5个项目(A，B，C，D，E)构成的所有可能的项目集。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><h1 id="6525" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">介绍</h1><p id="11ff" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">你们中的大多数人可能已经熟悉了聚类算法，如<a class="ae li" rel="noopener" target="_blank" href="/k-means-clustering-a-comprehensive-guide-to-its-successful-use-in-python-c3893957667d"> K-Means </a>、<a class="ae li" rel="noopener" target="_blank" href="/hac-hierarchical-agglomerative-clustering-is-it-better-than-k-means-4ff6f459e390"> HAC </a>或<a class="ae li" rel="noopener" target="_blank" href="/dbscan-clustering-algorithm-how-to-build-powerful-density-based-models-21d9961c4cec"> DBSCAN </a>。然而，聚类不是发现数据点之间相似性的唯一非监督方式。您还可以使用关联规则学习技术来确定某些数据点(动作)是否更有可能一起出现。</p><p id="2955" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">一个简单的例子是超市购物篮分析。如果有人在买碎牛肉，这是否会让他们更有可能也买意大利面？我们可以通过使用Apriori算法来回答这类问题。</p><h1 id="b37f" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">内容</h1><ul class=""><li id="6fca" class="nc nd iu md b me mf mh mi mk ne mo nf ms ng mw nh ni nj nk bi translated">Apriori算法所属的类别</li><li id="2d84" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">关联规则学习介绍和Apriori算法工作原理的直观解释</li><li id="b81e" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">使用真实数据的Apriori算法的Python示例</li><li id="474c" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">结论</li></ul><h1 id="1e55" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">Apriori属于哪一类算法？</h1><p id="45a3" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">如前所述，Apriori是关联规则学习算法的一部分，属于机器学习的无监督分支。</p><p id="e6dd" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">这是因为先验并不要求我们为模型提供一个目标变量。相反，该算法根据我们指定的约束来识别数据点之间的关系。</p><p id="2df7" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">下图是<strong class="md je">交互式的，</strong>所以请点击不同的类别来<strong class="md je">放大并展示更多的</strong>👇。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="nq nr l"/></div><p class="le lf gk gi gj lg lh bd b be z dk translated">机器学习算法分类。由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>创建的互动图表。</p></figure><p id="c651" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated"><strong class="md je"> <em class="ns">如果你喜欢数据科学和机器学习</em> </strong> <em class="ns">，请</em> <a class="ae li" href="https://solclover.com/subscribe" rel="noopener ugc nofollow" target="_blank"> <em class="ns">订阅</em> </a> <em class="ns">每当我发布一个新故事时，你都会收到一封电子邮件。</em></p><h1 id="8257" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">关联规则学习和Apriori算法</h1><h2 id="31b0" class="nt lk iu bd ll nu nv dn lp nw nx dp lt mk ny nz lv mo oa ob lx ms oc od lz ja bi translated">关联规则学习</h2><p id="f689" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">如简介中所述，关联规则学习是一种基于规则的机器学习方法，用于发现大型数据库中变量之间的有趣关系。我们用一个简单的超市购物篮分析来说明关联规则是如何发现的。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj oe"><img src="../Images/ebdd089650b2468b744aa5d547c31831.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yTtuCcNJrSymJfrVj28fQg.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">购物者的超市购物清单。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="0af6" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">假设我们分析上述交易数据，找出经常购买的商品，并确定它们是否经常一起购买。为了帮助我们找到答案，我们将利用以下4个指标:</p><ul class=""><li id="0217" class="nc nd iu md b me mx mh my mk of mo og ms oh mw nh ni nj nk bi translated">支持</li><li id="e0be" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">信心</li><li id="6269" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">电梯</li><li id="1b96" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">定罪</li></ul><h2 id="f178" class="nt lk iu bd ll nu nv dn lp nw nx dp lt mk ny nz lv mo oa ob lx ms oc od lz ja bi translated">支持</h2><p id="8475" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">我们和算法的第一步是找到经常购买的物品。这是一个基于频率的简单计算:</p><pre class="kt ku kv kw gu oi oj ok ol aw om bi"><span id="775e" class="nt lk iu oj b gz on oo l op oq"><strong class="oj je">Support(A)</strong> = Transactions(A) / Total Transactions</span></pre><p id="0fc7" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">所以在我们的例子中:</p><pre class="kt ku kv kw gu oi oj ok ol aw om bi"><span id="af19" class="nt lk iu oj b gz on oo l op oq"><strong class="oj je">Support(Eggs)</strong> = 3/6 = 1/2 = 0.5<br/><strong class="oj je">Support(Bacon)</strong> = 4/6 = 2/3 = 0.667<br/>Support(Apple) = 2/6 = 1/3 = 0.333<br/>...<br/><strong class="oj je">Support(Eggs&amp;Bacon)</strong> = 3/6 = 0.5<br/>...</span></pre><p id="df94" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">在这里，我们可以通过告诉算法我们想要探索的最小支持级别来设置我们的第一个约束，这在处理大型数据集时非常有用。我们通常希望集中计算资源来搜索经常购买的商品之间的关联，同时忽略不经常购买的商品。</p><p id="9ef8" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">为了我们的例子，让我们<strong class="md je">将最小支持设置为0.5 </strong>，这使得我们在这个例子的剩余部分中处理鸡蛋和熏肉。</p><p id="60f5" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated"><strong class="md je">重要:</strong>虽然Support(Eggs)和Support(Bacon)单独满足我们的最小支持约束，但理解我们还需要它们的组合(Eggs &amp; Bacon)来通过这个约束是至关重要的。否则，我们不会有一个条目配对来创建关联规则。</p><h2 id="6908" class="nt lk iu bd ll nu nv dn lp nw nx dp lt mk ny nz lv mo oa ob lx ms oc od lz ja bi translated">信心</h2><p id="957d" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">现在我们已经确定了经常购买的商品，让我们来计算置信度。这将告诉我们(基于我们的数据)有多大的信心，我们可以相信一个项目将被购买，因为另一个项目已经被购买。</p><pre class="kt ku kv kw gu oi oj ok ol aw om bi"><span id="e8d9" class="nt lk iu oj b gz on oo l op oq"><strong class="oj je">Confidence(A→B)</strong> = Probability(A &amp; B) / Support(A)</span><span id="c38e" class="nt lk iu oj b gz or oo l op oq">Note, confidence is the same as what is also known as conditional probability in statistics:<br/>P(B|A) = P(A &amp; B) / P(A) </span><span id="e936" class="nt lk iu oj b gz or oo l op oq"><em class="ns">Please beware of the notation. The above two equeations are equivalent, although the notations are in different order: </em><strong class="oj je"><em class="ns">(A→B) </em></strong><em class="ns">is the same as</em><strong class="oj je"><em class="ns"> (B|A).</em></strong><em class="ns"> </em></span></pre><p id="e136" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">因此，让我们为我们的例子计算置信度:</p><pre class="kt ku kv kw gu oi oj ok ol aw om bi"><span id="41d3" class="nt lk iu oj b gz on oo l op oq"><strong class="oj je">Confidence(Eggs→Bacon)</strong> = P(Eggs &amp; Bacon) / Support(Eggs) = (3/6) / (3/6) = 1</span><span id="82a5" class="nt lk iu oj b gz or oo l op oq"><strong class="oj je">Confidence(Bacon→Eggs)</strong> = P(Eggs &amp; Bacon) / Support(Bacon) = (3/6) / (2/3) = 3/4 = 0.75</span></pre><p id="cfaa" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">以上告诉我们，无论什么时候买鸡蛋，培根也是100%的时候买。还有，无论什么时候买培根，75%的时候都是买鸡蛋。</p><h2 id="5d21" class="nt lk iu bd ll nu nv dn lp nw nx dp lt mk ny nz lv mo oa ob lx ms oc od lz ja bi translated">电梯</h2><p id="4f35" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">鉴于不同的商品以不同的频率被购买，我们如何知道鸡蛋和培根真的有很强的关联，我们如何衡量它？你会很高兴听到我们有办法使用<strong class="md je"> lift </strong>客观地评估这一点。</p><p id="e564" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">计算升力的公式有多种表达方式。让我先展示一下公式是什么样子的，然后我会描述一种直观的方式让你思考。</p><pre class="kt ku kv kw gu oi oj ok ol aw om bi"><span id="daf3" class="nt lk iu oj b gz on oo l op oq"><strong class="oj je">Lift(A→B)</strong> = Probability(A &amp; B) / (Support(A) * Support(B))</span><span id="b369" class="nt lk iu oj b gz or oo l op oq">You should be able to spot that we can simplify this formula by replacing P(A&amp;B)/Sup(A) with Confidence(A→B). Hence, we have:</span><span id="f3fd" class="nt lk iu oj b gz or oo l op oq"><strong class="oj je">Lift(A→B)</strong> = Confidence(A→B) / Support(B)</span></pre><p id="644c" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">让我们计算相关物品的升力:</p><pre class="kt ku kv kw gu oi oj ok ol aw om bi"><span id="dd44" class="nt lk iu oj b gz on oo l op oq"><strong class="oj je">Lift(Eggs→Bacon)</strong> = Confidence(Eggs→Bacon) / Support(Bacon) = 1 / (2/3) = 1.5</span><span id="5f15" class="nt lk iu oj b gz or oo l op oq"><strong class="oj je">Lift(Bacon→Eggs)</strong> = Confidence(Bacon→Eggs) / Support(Eggs) = (3/4) / (1/2) = 1.5</span></pre><p id="1273" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">这两个项目的升力等于1.5。注意，lift&gt;1表示两件商品更有可能一起买，lift&lt;1表示两件商品更有可能分开买。最后，lift=1意味着这两个项目之间没有关联。</p><p id="4b7a" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">理解这一点的直观方法是首先考虑鸡蛋被购买的概率:<code class="fe os ot ou oj b">P(Eggs)=Support(Eggs)=0.5</code>因为6个购物者中有3个购买了鸡蛋。</p><p id="8275" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">然后想想每当买熏肉时买鸡蛋的概率:<code class="fe os ot ou oj b">P(Eggs|Bacon)=Confidence(Bacon-&gt;Eggs)=0.75</code>因为买熏肉的4个顾客中，有3个也买了鸡蛋。</p><p id="f41b" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">现在，lift只是一个简单的度量，它告诉我们在购买培根的情况下，购买鸡蛋的概率是增加了还是减少了。由于在这种情况下购买鸡蛋的概率从0.5上升到0.75，我们看到1.5倍的正提升(0.75/0.5=1.5)。这意味着，如果你已经把熏肉放进篮子里，你购买鸡蛋的可能性会增加1.5倍(即50%)。</p><p id="2e67" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated"><em class="ns">看看你的超市附近有没有这两样东西。</em>😜</p><h2 id="fa50" class="nt lk iu bd ll nu nv dn lp nw nx dp lt mk ny nz lv mo oa ob lx ms oc od lz ja bi translated">定罪</h2><p id="11c3" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">信念是衡量联想的另一种方式，尽管要理解它有点困难。它比较了A在没有B的情况下出现的概率(如果它们是独立的)和A在没有B的情况下出现的实际频率，我们先来看看通用公式:</p><pre class="kt ku kv kw gu oi oj ok ol aw om bi"><span id="8d1a" class="nt lk iu oj b gz on oo l op oq"><strong class="oj je">Conviction(A→B)</strong> = (1 - Support(B)) / (1 - Confidence(A→B))</span></pre><p id="fa98" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">在我们的示例中，这将是:</p><pre class="kt ku kv kw gu oi oj ok ol aw om bi"><span id="836c" class="nt lk iu oj b gz on oo l op oq"><strong class="oj je">Conviction(Eggs→Bacon)</strong> = (1 - Sup(Bacon) / (1 - Conf(Eggs→Bacon)) = (1 - 2/3) / (1 - 1) = (1/3) / 0 = infinity</span><span id="61fa" class="nt lk iu oj b gz or oo l op oq"><strong class="oj je">Conviction(Bacon→Eggs)</strong> = (1 - Sup(Eggs) / (1 - Conf(Bacon→Eggs)) = (1 - 1/2) / (1 - 3/4) = (1/2) / (1/4) = 2</span></pre><p id="76b5" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">如您所见，在计算(鸡蛋→培根)的确信度时，我们除以0，这是因为我们没有一个鸡蛋被购买而没有培根的实例(置信度=100%)。</p><p id="7418" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">一般来说，对A→B的高信任度和对B的低支持度会产生高确信度。</p><p id="8ead" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">与解除相反，定罪是一种直接的措施。因此，虽然lift对于(鸡蛋→培根)和(培根→鸡蛋)来说是相同的，但两者之间的信念是不同的，Conv(鸡蛋→培根)要高得多。因此，你可以使用信念来评估你的项目之间的方向关系。</p><p id="1a8a" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">最后，与lift类似，confidence = 1表示项目没有关联，而confidence &gt; 1表示项目之间的关系(值越高，关系越强)。</p><h2 id="b2a2" class="nt lk iu bd ll nu nv dn lp nw nx dp lt mk ny nz lv mo oa ob lx ms oc od lz ja bi translated">Apriori算法</h2><p id="926f" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">Apriori是一种非常简单的算法，它执行以下一系列计算:</p><ol class=""><li id="d86a" class="nc nd iu md b me mx mh my mk of mo og ms oh mw ov ni nj nk bi translated">计算大小为1的项集的支持度。</li><li id="fa2c" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw ov ni nj nk bi translated">应用最小支持阈值并删除不符合阈值的项集。</li><li id="27c4" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw ov ni nj nk bi translated">移动到大小为2的项目集，重复步骤1和2。</li><li id="06eb" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw ov ni nj nk bi translated">继续相同的过程，直到找不到满足最小阈值的其他项目集。</li></ol><p id="3dd0" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">为了使该过程更加直观，下面的图表说明了该算法的作用:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ow"><img src="../Images/05406acab7a03c657990a23b6875c012.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PjV7oQE_RABg49Wsm2_Jdw.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">Apriori算法的进程树。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="9dd8" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">如您所见，本例中的大多数项目集都被删除了，因为它们没有达到0.5的最小支持阈值。</p><p id="e4c8" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">重要的是要认识到，通过设置更低的最小支持阈值，我们将产生更多大小为2的项目集。准确地说，在最小支持阈值为0.3的情况下，大小为1的项集都不会被删除，因此大小为2的项集总共有15个(5+4+3+2+1=15)。</p><p id="30dd" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">当我们有一个小的数据集时，这不是一个问题，但是如果你正在处理一个大的数据集，这可能成为一个瓶颈。例如，1，000个项目可以创建多达499，500个项目对。因此，仔细选择你的最低支持阈值。</p><p id="26ff" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">注意，如果你想要更多的例子，你可以参考封面图片，它显示了所有可能的项目集，这些项目集可以由5个单独的项目组成。</p><div class="kt ku kv kw gu ab cb"><figure class="ox kx oy oz pa pb pc paragraph-image"><a href="https://solclover.com/membership"><img src="../Images/63320331b74bd98eea6402472b4209ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*qkXay39OnVc2IosW6rkxtw.png"/></a></figure><figure class="ox kx oy oz pa pb pc paragraph-image"><a href="https://www.linkedin.com/in/saulius-dobilas/"><img src="../Images/60fb21d1cb2701bfb6b71f61c99403e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*vabxOXtQ4T034N_mscHSmQ.png"/></a></figure></div><h1 id="0316" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">使用真实数据的Apriori算法的Python示例</h1><p id="8cf7" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">现在让我们抛开理论，用Python对现实生活中的数据进行分析。</p><h2 id="5b51" class="nt lk iu bd ll nu nv dn lp nw nx dp lt mk ny nz lv mo oa ob lx ms oc od lz ja bi translated">设置</h2><p id="eb93" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">我们将使用以下数据和库:</p><ul class=""><li id="2ffa" class="nc nd iu md b me mx mh my mk of mo og ms oh mw nh ni nj nk bi translated">【Kaggle的购物篮优化数据</li><li id="dac8" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated"><a class="ae li" href="https://pypi.org/project/efficient-apriori/" rel="noopener ugc nofollow" target="_blank">关联规则学习的Apriori算法</a></li><li id="433d" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated"><a class="ae li" href="https://pandas.pydata.org/docs/" rel="noopener ugc nofollow" target="_blank">熊猫</a>进行数据操作</li><li id="2f65" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated"><a class="ae li" href="https://matplotlib.org/stable/contents.html" rel="noopener ugc nofollow" target="_blank"> Matplotlib </a>用于绘制频率分布图</li></ul><p id="f52b" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">让我们导入所有的库:</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pd nr l"/></div></figure><p id="98fe" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">然后我们从Kaggle下载<a class="ae li" href="https://www.kaggle.com/sindraanthony9985/marketing-data-for-a-supermarket-in-united-states" rel="noopener ugc nofollow" target="_blank">Market _ Basket _ optimization . CSV</a>并获取数据:</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pd nr l"/></div></figure><p id="d24d" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">数据看起来是这样的:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pe"><img src="../Images/f6eed814131a7845d8cad819af020b19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*leBxRbDUjvqTVLMK6N2j_A.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">超市购物篮数据的片段。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><h2 id="4647" class="nt lk iu bd ll nu nv dn lp nw nx dp lt mk ny nz lv mo oa ob lx ms oc od lz ja bi translated">探测</h2><p id="5937" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">在我们运行关联规则分析之前，让我们先来看看项目的频率分布。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pd nr l"/></div></figure><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj pf"><img src="../Images/acbd69b31b5a9e67052558d7ec768031.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*brJtDSjOWeMaBnxwKzewng.png"/></div><p class="le lf gk gi gj lg lh bd b be z dk translated">购买超市商品的频率计数片段。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="29bd" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">我们可以看到，矿泉水(1788英镑)是这家超市最受欢迎的商品，其次是鸡蛋(1348英镑)、意大利面(1306英镑)、薯条(1282英镑)和巧克力(1230英镑)。同时，可怜的老芦笋只被买过一次。</p><p id="d028" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">此外，值得注意的是，即使是最常购买的商品也只出现在略高于6%的交易中。当设置最小支持阈值时，我们可以使用该信息作为指导。</p><p id="eeee" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">让我们也在条形图中显示频率分布。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pd nr l"/></div></figure><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pg"><img src="../Images/5c8a49d4fb2b5fb1d7e5ed72da1ac17a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BJd7aGaWEnjyaePdBiA8tg.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">购买超市商品的频率分布。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><h2 id="3559" class="nt lk iu bd ll nu nv dn lp nw nx dp lt mk ny nz lv mo oa ob lx ms oc od lz ja bi translated">运行Apriori算法</h2><p id="80c5" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">在我们运行算法之前，让我们把数据放入要求的格式中。这将是一个<strong class="md je">列表</strong>列表，其中所有你在熊猫数据帧中看到的“nan”都被删除了。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pd nr l"/></div></figure><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ph"><img src="../Images/14a4edca2a106ef30cbf13245d162b90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9TjLw-mvHPzedOzHW9hyrQ.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">列表的事务列表的片段。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="9dda" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">最后，让我们运行Apriori算法并保存项目集和关联规则。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pd nr l"/></div></figure><p id="53b2" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">该算法发现了36个大小为1的项目集和18个大小为2的项目集，它们满足0.03的最小支持阈值。这些显示如下。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pi"><img src="../Images/f3921fbf8a4f3ade05ab3a6066ca6669.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oosBWs4tgoIYlPiedqw-xA.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">满足最小支持度阈值约束的所有项目集。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="1103" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">现在让我们打印算法找到的关联规则。注意，一些集合在规则生成阶段被排除，因为它们不满足我们指定的最小置信度要求(在本例中，min_confidence=0.2)。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pd nr l"/></div></figure><p id="4aed" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">上面的代码打印了满足我们的约束条件的所有关联规则，这些约束条件按最高提升和信念排序:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pj"><img src="../Images/5e3d6f796b5ab840e78c4ea011009fe7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z4kk_VvF2jnFFuCAmT_IfA.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">27关联规则产生的Apriori算法基于我们的约束。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="112a" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">正如我们所看到的，真实数据中提升最高的是碎牛肉和意大利面的组合。然而，碎牛肉的购买者更有可能同时购买意大利面条(信心:0.399，确信:1.374)，而不是相反(信心:0.225，确信:1.164)。</p><p id="ed70" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">总而言之，看起来这家超市的游客是意大利肉酱面和矿泉水的忠实粉丝。</p><h1 id="56cb" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">结论</h1><p id="5deb" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">Apriori是一种简单的算法，可以快速学习项目(数据点)之间的关联规则。虽然我已经向您介绍了它在购物篮分析中的应用，但它还有许多其他实际应用，包括生物信息学(蛋白质测序)、医学诊断(症状和疾病之间的关系)或人口普查数据分析。</p><p id="fbd1" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">在大型数据集上使用Apriori时需要注意的一点是最小支持阈值的选择。如果不小心的话，可能会因为大量大小为2的项集而很快耗尽内存。</p><p id="246b" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">我希望您和我一样发现了先验和关联规则学习。感谢您的阅读，如果您有任何问题或建议，请随时联系我们！</p><p id="76ff" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">干杯！👏<br/> <strong class="md je">索尔·多比拉斯</strong></p></div><div class="ab cl pk pl hy pm" role="separator"><span class="pn bw bk po pp pq"/><span class="pn bw bk po pp pq"/><span class="pn bw bk po pp"/></div><div class="in io ip iq ir"><p id="df3e" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated"><strong class="md je"> <em class="ns">如果你已经花光了这个月的学习预算，下次请记得我。</em> </strong> <em class="ns">我的个性化链接加入媒介是:</em></p><div class="pr ps gq gs pt pu"><a href="https://solclover.com/membership" rel="noopener  ugc nofollow" target="_blank"><div class="pv ab fp"><div class="pw ab px cl cj py"><h2 class="bd je gz z fq pz fs ft qa fv fx jd bi translated">通过我的推荐链接加入Medium索尔·多比拉斯</h2><div class="qb l"><h3 class="bd b gz z fq pz fs ft qa fv fx dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="qc l"><p class="bd b dl z fq pz fs ft qa fv fx dk translated">solclover.com</p></div></div><div class="qd l"><div class="qe l qf qg qh qd qi lc pu"/></div></div></a></div></div><div class="ab cl pk pl hy pm" role="separator"><span class="pn bw bk po pp pq"/><span class="pn bw bk po pp pq"/><span class="pn bw bk po pp"/></div><div class="in io ip iq ir"><p id="b8aa" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">您可能感兴趣的相关文章:</p><div class="pr ps gq gs pt pu"><a rel="noopener follow" target="_blank" href="/bbn-bayesian-belief-networks-how-to-build-them-effectively-in-python-6b7f93435bba"><div class="pv ab fp"><div class="pw ab px cl cj py"><h2 class="bd je gz z fq pz fs ft qa fv fx jd bi translated">BBN:贝叶斯信念网络——如何用Python有效地构建它们？</h2><div class="qb l"><h3 class="bd b gz z fq pz fs ft qa fv fx dk translated">使用真实生活数据在Python中构建模型的贝叶斯信念网络的详细解释</h3></div><div class="qc l"><p class="bd b dl z fq pz fs ft qa fv fx dk translated">towardsdatascience.com</p></div></div><div class="qd l"><div class="qj l qf qg qh qd qi lc pu"/></div></div></a></div><div class="pr ps gq gs pt pu"><a rel="noopener follow" target="_blank" href="/k-nearest-neighbors-knn-how-to-make-quality-predictions-with-supervised-learning-d5d2f326c3c2"><div class="pv ab fp"><div class="pw ab px cl cj py"><h2 class="bd je gz z fq pz fs ft qa fv fx jd bi translated">k-最近邻(kNN)-如何使用监督学习进行质量预测？</h2><div class="qb l"><h3 class="bd b gz z fq pz fs ft qa fv fx dk translated">使用kNN解决回归和分类问题的综合指南</h3></div><div class="qc l"><p class="bd b dl z fq pz fs ft qa fv fx dk translated">towardsdatascience.com</p></div></div><div class="qd l"><div class="qk l qf qg qh qd qi lc pu"/></div></div></a></div></div></div>    
</body>
</html>