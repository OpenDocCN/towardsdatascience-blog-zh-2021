<html>
<head>
<title>Serverless Model Hosting with Docker, AWS Lambda and API Gateway</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Docker、AWS Lambda和API网关的无服务器模型托管</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/serverless-model-hosting-with-docker-aws-lambda-and-api-gateway-2d79382ecb45?source=collection_archive---------6-----------------------#2021-06-20">https://towardsdatascience.com/serverless-model-hosting-with-docker-aws-lambda-and-api-gateway-2d79382ecb45?source=collection_archive---------6-----------------------#2021-06-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5e84" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">充分利用Lambda中的Docker支持来托管您的模型，而无需专用服务器。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/499680fb2999b5075a8ce5d752cc6b82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lovxQO12mwBmO3mhK2QeIg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由Markus Spiske在Unsplash上拍摄的图片</p></figure><p id="cc88" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以前，AWS Lambda部署包被限制在250MB(包括需求)的最大解压缩大小。当试图使用该服务托管机器学习模型时，这被证明是一个障碍，因为常见的ML库和复杂的模型导致部署包远远超过250MB的限制。</p><p id="3423" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而在2020年12月，AWS <a class="ae lr" href="https://aws.amazon.com/blogs/aws/new-for-aws-lambda-container-image-support/" rel="noopener ugc nofollow" target="_blank">宣布</a>支持将Lambda函数打包和部署为Docker镜像。在机器学习的背景下，这些图像的大小最大可达10GB。这意味着图像中可以包含大型依赖关系(例如张量流)和中等大小的模型，因此可以使用Lambda进行模型预测。</p><p id="26be" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本文中，我们将通过一个示例来构建和部署Lambda上的模型托管。所有使用的相关代码都可以在<a class="ae lr" href="https://github.com/jonathanreadshaw/ml-deploy-sam" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="0982" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">建筑概述</strong></p><p id="719a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该解决方案可以分为三个部分:</p><ol class=""><li id="ac13" class="ls lt iq kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated">Docker映像:Docker映像包含我们的依赖项、训练好的模型管道和功能代码。AWS为各种运行时提供了一个基本映像，可以在其上构建以确保与服务的兼容性。</li><li id="eeb4" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated"><strong class="kx ir"> Lambda Function </strong>:基于输入事件/请求运行Docker映像中的功能代码的无服务器资源。</li><li id="0d3d" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated"><strong class="kx ir"> API网关端点</strong>:用作Lambda函数的触发器和客户端请求的入口点。当在端点接收到预测请求时，Lambda函数被触发，请求体包含在发送给该函数的事件中。然后，该函数返回的值将作为响应返回给客户端。</li></ol><p id="b7a4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">型号</strong></p><p id="2fe4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这个例子中，我们的模型将是在虹膜分类数据集上训练的简单KNN实现。本文不涉及培训，但结果是一个scikit-learn Pipeline对象，由以下对象组成:</p><p id="2620" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">1.StandardScaler:根据训练样本的平均值和标准偏差标准化输入。</p><p id="5ed3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">2.KNeighborsClassifier:实际的预训练模型。用K = 5训练。</p><p id="7ec3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用scikit-learn的Joblib实现将管道保存到'<em class="mg"> model_pipeline.joblib </em>'中。</p><p id="0885" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">功能代码</strong></p><p id="d5ea" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们首先考虑Lambda将用来处理预测请求事件的函数代码(predict\app.py)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="7f76" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="mg"> Lambda_handler </em>拥有Lambda使用的函数所需的参数。管道对象在处理程序之外加载，以避免在每次调用时加载。Lambda会让容器在一段时间内保持活动状态，直到没有事件发生，所以在创建时加载一次模型意味着它可以在容器被Lambda保持活动状态时被重用。</p><p id="f1c5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">处理函数本身非常简单；从事件主体中提取所需的输入，并用于生成预测。预测作为JSON响应的一部分返回。API网关会将函数的响应返回给客户端。进行一些检查以确保输入符合预期，并捕捉和记录任何预测错误。</p><p id="c0d6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">码头工人图像</strong></p><p id="4ed7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Dockerfile文件的结构如下:</p><p id="e627" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">1.拉AWS的基本Python 3.6图像</p><p id="89f6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">2.将所需文件从本地目录复制到映像的根目录</p><p id="b299" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">3.安装要求</p><p id="769b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">4.运行处理函数</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="e28c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">部署</strong></p><p id="ec75" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了管理部署和AWS资源，我们将使用AWS无服务器应用程序管理器(SAM) CLI <em class="mg">。</em>安装SAM及其依赖项的说明可以在<a class="ae lr" href="https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-install.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="e19d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">要使用SAM进行构建和部署，必须配置模板文件。这用于指定所需的AWS资源和相关配置。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="bd41" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于此项目，SAM模板包含以下内容:</p><ul class=""><li id="a71b" class="ls lt iq kx b ky kz lb lc le lu li lv lm lw lq mj ly lz ma bi translated">杂项信息，如堆栈名称和Lambda超时的全局配置。</li><li id="7915" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq mj ly lz ma bi translated"><em class="mg"> MLPredictionFunction </em>资源:这是我们要部署的Lambda函数。本节包含所需配置的大部分内容:</li><li id="8b08" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq mj ly lz ma bi translated">属性:这里我们指定将使用Docker映像(<em class="mg"> PackageType: Image </em>)来定义该函数，并且该函数将通过API网关(<em class="mg"> Type: API </em>)来触发。API路径路由名称和类型也在这里定义。</li><li id="5574" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq mj ly lz ma bi translated">元数据包含将用于构建图像的标签和用于构建图像的docker文件的位置/名称。</li><li id="cac1" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq mj ly lz ma bi translated">Outputs列出了将由SAM创建的所有必需资源。在这种情况下，SAM需要的是API网关端点、Lambda函数和关联的IAM角色。</li></ul><p id="12c5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">运行以下命令，使用定义的SAM模板在本地构建应用程序映像:</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="bef2" class="mp mq iq ml b gy mr ms l mt mu">!sam build</span></pre><p id="3c89" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果成功，可以使用以下命令通过示例事件在本地调用该函数(参见repo中的示例事件):</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="ebb4" class="mp mq iq ml b gy mr ms l mt mu">!sam local invoke -e events/event.json</span></pre><p id="2c5c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一旦在本地测试了该功能，就需要将图像推送到AWS ECR。首先创建一个新的存储库:</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="b48b" class="mp mq iq ml b gy mr ms l mt mu">!aws ecr create-repository --repository-name ml-deploy-sam</span></pre><p id="ed4c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在推送映像之前，您需要登录ECR的托管Docker服务:</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="27e5" class="mp mq iq ml b gy mr ms l mt mu">!aws ecr get-login-password --region &lt;region&gt; | docker login --username AWS \ --password-stdin &lt;account id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com</span></pre><p id="1ed0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，您可以使用以下工具部署应用程序:</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="e717" class="mp mq iq ml b gy mr ms l mt mu">!sam deploy -g</span></pre><p id="4f5d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这将在“引导”模式下运行部署，您需要确认应用程序的名称、AWS区域和之前创建的图像存储库。在大多数情况下，接受其余设置的默认选项应该没问题。</p><p id="e607" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然后将开始部署过程，并提供AWS资源。完成后，每个资源都将显示在控制台中。</p><h2 id="12bc" class="mp mq iq bd mv mw mx dn my mz na dp nb le nc nd ne li nf ng nh lm ni nj nk nl bi translated">考虑</h2><ul class=""><li id="154d" class="ls lt iq kx b ky nm lb nn le no li np lm nq lq mj ly lz ma bi translated"><strong class="kx ir">映像更新</strong>:要部署更新的模型或功能代码，您可以简单地在本地重建映像并重新运行deploy命令。SAM将检测应用程序的哪些方面发生了变化，并相应地更新相关资源。</li><li id="54f2" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq mj ly lz ma bi translated"><strong class="kx ir">冷启动:</strong>每次Lambda使用我们的功能代码旋转一个容器时，模型将在处理开始前被加载。这导致冷启动场景，其中第一个请求将比后面的请求慢得多。解决这个问题的一个方法是使用CloudWatch定期触发函数，这样容器就可以随时加载模型。</li><li id="c219" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq mj ly lz ma bi translated"><strong class="kx ir">多个功能:</strong>可以部署多个Lambda功能，由一个API提供服务。如果您有多个模型要服务，或者如果您想要有一个单独的预处理/验证端点，这可能是有用的。要对此进行配置，您只需在SAM模板资源中包含附加功能。</li></ul></div></div>    
</body>
</html>