<html>
<head>
<title>Apache Spark 3.1 Release: Spark on Kubernetes is now Generally Available</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark 3.1发布:Kubernetes上的Spark现在已经正式发布</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/apache-spark-3-1-release-spark-on-kubernetes-is-now-generally-available-65cccbf1436b?source=collection_archive---------16-----------------------#2021-03-30">https://towardsdatascience.com/apache-spark-3-1-release-spark-on-kubernetes-is-now-generally-available-65cccbf1436b?source=collection_archive---------16-----------------------#2021-03-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="d973" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">随着2021年3月发布的<a class="ae kl" href="https://www.datamechanics.co/apache-spark" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a> 3.1，Kubernetes 项目上的<a class="ae kl" href="https://www.datamechanics.co/spark-on-kubernetes" rel="noopener ugc nofollow" target="_blank"> Spark现已正式宣布为生产就绪，并普遍可用。这是自Spark 2.3(2018年2月)添加对Spark-on-Kubernetes的初始支持以来，3年来快速增长的社区贡献和项目采用的成就。在本文中，我们将回顾Spark 3.1的主要特性，特别关注对Spark-on-Kubernetes的改进。</a></p><p id="368a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="km">相关资源:</em></p><ul class=""><li id="eff6" class="kn ko iq jp b jq jr ju jv jy kp kc kq kg kr kk ks kt ku kv bi translated"><em class="km">关于使用Kubernetes作为Spark(而不是YARN)的资源管理器的介绍，请看在Kubernetes上运行Spark的</em> <a class="ae kl" href="https://www.datamechanics.co/blog-post/pros-and-cons-of-running-apache-spark-on-kubernetes" rel="noopener ugc nofollow" target="_blank"> <em class="km">优点&amp;缺点</em> </a> <em class="km">。</em></li><li id="e7af" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated"><em class="km">有关在Kubernetes上成功使用Spark的技术指南，请查看</em> <a class="ae kl" href="https://www.datamechanics.co/blog-post/setting-up-managing-monitoring-spark-on-kubernetes" rel="noopener ugc nofollow" target="_blank"> <em class="km">设置、管理&amp;监控Kubernetes上的Spark</em></a><em class="km">。</em></li><li id="e265" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated"><em class="km">关于数据机制的背景知识，请查看Kubernetes上的</em><a class="ae kl" href="https://www.datamechanics.co/blog-post/spark-on-kubernetes-made-easy-how-data-mechanics-improves-on-spark-on-k8s-open-source" rel="noopener ugc nofollow" target="_blank"><em class="km">Spark Made Easy:Data Mechanics如何改进开源版本</em> </a></li></ul><h1 id="3eb5" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">Spark-on-Kubernetes之旅:从2.3中的beta支持到成为3.1中的新标准</h1><p id="112d" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">随着2018年初Spark 2.3的发布，Kubernetes成为了Spark的新调度程序(除了YARN、Mesos和Standalone mode之外)，这要归功于RedHat、Palantir、谷歌、彭博和Lyft等少数几家带头开展该项目的大公司。这种最初的支持是实验性的——缺乏特性，并且存在稳定性和性能问题。</p><p id="4c6c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从那时起，社区支持蓬勃发展，许多大大小小的公司都被Kubernetes的好处所吸引:</p><ol class=""><li id="7e9d" class="kn ko iq jp b jq jr ju jv jy kp kc kq kg kr kk me kt ku kv bi translated">本地集装箱化。使用<a class="ae kl" href="https://www.datamechanics.co/blog-post/spark-and-docker-your-spark-development-cycle-just-got-ten-times-faster" rel="noopener ugc nofollow" target="_blank"> Docker </a>来打包你的依赖项(和Spark本身)——<a class="ae kl" href="https://www.datamechanics.co/blog-post/optimized-spark-docker-images-now-available" rel="noopener ugc nofollow" target="_blank">查看我们为Spark </a>优化的Docker图片。</li><li id="5958" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk me kt ku kv bi translated">高效的资源共享和更快的应用启动时间。</li><li id="5c2e" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk me kt ku kv bi translated">丰富的开源生态系统减少了云提供商和供应商的束缚</li></ol><p id="8414" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个项目的主要特点是——从2.4中的PySpark &amp; R支持、客户端模式和卷挂载等基本要求，到动态分配(3.0)和更好的节点关闭处理(3.1)等强大的优化。在过去的3年中，总共有超过500个补丁(改进和错误修复)被贡献出来，使得Kubernetes上的spark更加稳定和高效。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mf"><img src="../Images/659222e88458098cf3101ea6b7f53794.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0E4so6KWhRm7B1Wg.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">Kubernetes上Spark改进的时间线从2018年的Spark 2.3，到2021年3月最新的Spark 3.1。图片作者。</p></figure><p id="b34f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，Kubernetes越来越被认为是2021年新Spark项目的标准资源管理器，我们可以从开源<a class="ae kl" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator" rel="noopener ugc nofollow" target="_blank">Spark-on-Kubernetes operator</a>项目的受欢迎程度，或者主要供应商采用Kubernetes而不是Hadoop YARN的声明中看出这一点。</p><p id="58a1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有了Spark 3.1，Spark-on-Kubernetes项目现在被认为是普遍可用和生产就绪的。在这个最新版本中，超过70个错误修复和性能改进被贡献给了这个项目。现在，让我们深入了解最具影响力的功能，也是我们的客户热切期待的功能。</p><h1 id="af84" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">更好地处理节点关闭——优雅的执行器退役(新的Spark 3.1特性)</h1><p id="fa39" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">这个功能(<a class="ae kl" href="https://issues.apache.org/jira/browse/SPARK-20624" rel="noopener ugc nofollow" target="_blank"> SPARK-20624 </a>)是由<a class="ae kl" href="https://www.twitch.tv/holdenkarau" rel="noopener ugc nofollow" target="_blank"> Holden Karau </a>实现的，目前只适用于Kubernetes和单机部署。它被称为“更好地处理节点关闭”，尽管“优雅的执行器退役”是它的另一个好名字。</p><p id="8c8d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个特性使得Spark在使用spot节点(也就是GCP上的可抢占节点)时更加健壮和高效。它确保在spot中断发生之前，移动shuffle和缓存数据，以便Spark应用程序可以在影响最小的情况下继续运行。在此功能之前，当发生定点清除时，随机文件会丢失，因此需要重新计算(通过重新运行可能非常长的任务)。此功能不需要设置外部shuffle服务(这需要昂贵的存储节点按需运行，并且与Kubernetes兼容)。这个用一张图更好描述。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mv"><img src="../Images/c5e745710bfe5a42c68762cfeba62488.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3MXBpCxPd50QjiS7.gif"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">Spark的新功能的一个例子，它可以预测当场死亡并优雅地终止执行者，而不会丢失宝贵的数据！图片作者。</p></figure><p id="8bff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">这个功能有什么作用？</strong></p><ol class=""><li id="e06f" class="kn ko iq jp b jq jr ju jv jy kp kc kq kg kr kk me kt ku kv bi translated">将要离开的执行程序被列入黑名单Spark驱动程序不会在它上面安排新的任务。当前在其上运行的Spark任务不会被强制中断，但是如果它们失败(由于执行器死亡)，这些任务将在另一个执行器上重试(与今天相同)，并且它们的失败不会计入最大失败次数(新)。</li><li id="8024" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk me kt ku kv bi translated">执行程序中的随机文件和缓存数据会迁移到另一个执行程序中。如果没有其他执行程序(例如，我们正在删除那里唯一的执行程序)，您可以配置一个对象存储(如S3)作为<a class="ae kl" href="https://github.com/apache/spark/blob/2e31e2c5f30742c312767f26b17396c4ecfbef72/core/src/main/scala/org/apache/spark/internal/config/package.scala#L474" rel="noopener ugc nofollow" target="_blank">后备存储</a>。</li><li id="2c08" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk me kt ku kv bi translated">一旦完成，执行者就死了，Spark应用程序可以不受影响地继续运行！</li></ol><p id="cf9c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">这个什么时候生效？</strong></p><ul class=""><li id="c74d" class="kn ko iq jp b jq jr ju jv jy kp kc kq kg kr kk ks kt ku kv bi translated">当您使用spot/preemptable节点时，云提供商(aws、gcp、azure)现在会提前60-120秒通知您。Spark现在可以利用这个时间段来保存我们宝贵的洗牌文件了！当云提供商实例因其他原因关闭时，如<a class="ae kl" href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-instances-status-check_sched.html" rel="noopener ugc nofollow" target="_blank"> ec2维护事件</a>，同样的机制也适用。</li><li id="51dc" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">当一个Kubernetes节点被清空(例如为了维护)或者Spark executor pod被驱逐(例如被一个更高优先级的pod抢占)时。</li><li id="f17a" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">当执行程序作为动态分配的一部分被删除时，在缩减期间，因为执行程序空闲。在这种情况下，缓存和随机文件也将被保留。</li></ul><p id="e3d5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如何打开它？</p><ul class=""><li id="18eb" class="kn ko iq jp b jq jr ju jv jy kp kc kq kg kr kk ks kt ku kv bi translated">配置标志。需要开启的4个主要Spark配置分别是<strong class="jp ir"><em class="km">Spark . dissolution . enabled</em></strong>，<strong class="jp ir"><em class="km">Spark . storage . dissolution . rddblocks . enabled</em>，<strong class="jp ir"><em class="km">Spark . storage . dissolution . shuffle blocks . enabled</em>，<strong class="jp ir"><em class="km">Spark . storage . dissolution . enabled</em></strong>。<br/>我建议直接参考<a class="ae kl" href="https://github.com/apache/spark/blob/2e31e2c5f30742c312767f26b17396c4ecfbef72/core/src/main/scala/org/apache/spark/internal/config/package.scala#L1954" rel="noopener ugc nofollow" target="_blank">源代码</a>来查看其他可用的配置。</strong></strong></li><li id="a712" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">云提供商警告节点即将离开(例如由于定点清除)的能力需要特定的集成。我们建议查看一下<a class="ae kl" href="https://github.com/aws/aws-node-termination-handler" rel="noopener ugc nofollow" target="_blank"> AWS </a>、<a class="ae kl" href="https://github.com/GoogleCloudPlatform/k8s-node-termination-handler" rel="noopener ugc nofollow" target="_blank"> GCP </a>和<a class="ae kl" href="https://github.com/diseq/k8s-azspot-termination-handler" rel="noopener ugc nofollow" target="_blank"> Azure </a>的NodeTerminationHandler项目。如果你是数据力学的客户，请注意我们正在为你做这项工作。</li></ul><h1 id="5263" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">Kubernetes上Spark的新卷选项</h1><p id="8d2c" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">从Spark 2.4开始，在Kubernetes上使用Spark时，可以挂载3种类型的卷:</p><ol class=""><li id="2ac8" class="kn ko iq jp b jq jr ju jv jy kp kc kq kg kr kk me kt ku kv bi translated">一个<a class="ae kl" href="https://kubernetes.io/docs/concepts/storage/volumes/#emptydir" rel="noopener ugc nofollow" target="_blank"> emptyDir </a>:共享一个pod生命周期的初始空目录。这对于临时存储很有用。这可以由节点的磁盘、SSD或网络存储提供支持。</li><li id="cbff" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk me kt ku kv bi translated">A <a class="ae kl" href="https://kubernetes.io/docs/concepts/storage/volumes/#hostpath" rel="noopener ugc nofollow" target="_blank"> hostpath </a>:将一个目录从底层节点挂载到您的pod。</li><li id="aca4" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk me kt ku kv bi translated">静态预创建的<a class="ae kl" href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/" rel="noopener ugc nofollow" target="_blank"> PersistentVolumeClaim </a>。这是Kubernetes对各种类型的持久存储的抽象，比如AWS <a class="ae kl" href="https://aws.amazon.com/ebs/" rel="noopener ugc nofollow" target="_blank"> EBS </a>、<a class="ae kl" href="https://azure.microsoft.com/en-us/services/storage/disks/" rel="noopener ugc nofollow" target="_blank"> Azure Disk </a>，或者GCP的<a class="ae kl" href="https://cloud.google.com/persistent-disk" rel="noopener ugc nofollow" target="_blank">持久磁盘</a>。PersistentVolumeClaim必须由用户提前创建，并且其生命周期与pod无关。</li></ol><p id="2fec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Spark 3.1支持两个新选项——NFS和动态创建的PersistentVolumeClaims。</p><p id="809c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://kubernetes.io/docs/concepts/storage/volumes/#nfs" rel="noopener ugc nofollow" target="_blank"> NFS </a>是一个可以同时由许多pod共享的卷，并且可以预先填充数据。因此，这是一种跨Spark应用程序，或者跨给定Spark应用程序中的驱动程序和执行器交换数据、代码和配置的方式。Kubernetes不运行NFS服务器，你可以自己运行，或者使用云服务(比如AWS <a class="ae kl" href="https://aws.amazon.com/efs/" rel="noopener ugc nofollow" target="_blank"> EFS </a>，GCP <a class="ae kl" href="https://cloud.google.com/filestore" rel="noopener ugc nofollow" target="_blank"> Filestore </a>，或者Azure <a class="ae kl" href="https://docs.microsoft.com/en-us/azure/storage/files/storage-files-introduction" rel="noopener ugc nofollow" target="_blank"> Files </a>)。</p><p id="afe7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦您创建了NFS共享，现在使用Spark 3.1只需使用Spark配置就可以很容易地将其安装到您的Spark应用程序中:</p><p id="8c7e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="km">spark . kubernetes . driver . volumes . NFS . my share . mount . path =/shared<br/>spark . kubernetes . driver . volumes . NFS . my share . mount . readonly = false<br/>spark . kubernetes . driver . volumes . NFS . my share . options . server = NFS . example . com<br/>spark . kubernetes . driver . volumes . NFS . my share . options . path =/storage/shared</em></p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mw"><img src="../Images/e11dec68407c54b741bdb9e917834135.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lRKG7KAEpZbwEEKr.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">NFS(网络文件系统)是在所有Spark应用程序之间共享数据的热门选择。它现在可以在Kubernetes上运行。图片作者。</p></figure><p id="28f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第二个新选项是动态PVC，这是一种更加用户友好的使用持久卷的方式。以前，您必须预先创建PVC，然后装载它们。如果你使用动态分配，你不知道在你的应用程序执行过程中会产生多少执行者，所以这很难做到。您还必须自己清理未使用的持久卷，或者接受存储资源的浪费。</p><p id="1313" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有了Spark 3.1，一切都是动态和自动化的。当您提交Spark应用程序时(或者当您在动态分配期间请求新的执行器时)，Kubernetes中会动态创建PersistentVolumeClaims，这将自动提供您所请求的<a class="ae kl" href="https://kubernetes.io/docs/concepts/storage/storage-classes/" rel="noopener ugc nofollow" target="_blank">存储类</a>的新PersistentVolumes(例如AWS <a class="ae kl" href="https://aws.amazon.com/ebs/" rel="noopener ugc nofollow" target="_blank"> EBS </a>、<a class="ae kl" href="https://azure.microsoft.com/en-us/services/storage/disks/" rel="noopener ugc nofollow" target="_blank"> Azure Disk </a>或GCP的<a class="ae kl" href="https://cloud.google.com/persistent-disk" rel="noopener ugc nofollow" target="_blank">持久性磁盘</a>)。删除pod后，关联的资源会自动销毁。</p><h1 id="9cf2" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">其他Spark 3.1特性:PySpark UX、阶段级调度、性能提升</h1><p id="9994" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">除了Kubernetes go GA上的Spark之外，Spark 3.1还带来了许多显著的功能。在这里我们将集中讨论几个主要的问题。</p><p id="c13a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">PySpark开发者UX在Spark 3.1中获得了两大改进:</p><ul class=""><li id="e322" class="kn ko iq jp b jq jr ju jv jy kp kc kq kg kr kk ks kt ku kv bi translated">PySpark <a class="ae kl" href="https://spark.apache.org/docs/latest/api/python/index.html" rel="noopener ugc nofollow" target="_blank">文档</a>已经接受了完全的重新设计，这使得它更加pythonic化和用户友好。看看吧！</li><li id="c2bc" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">类型提示支持现在意味着您应该在IDE中免费获得代码完成和静态错误检测。</li></ul><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mx"><img src="../Images/5bc7ff46f018ae2122b053bdfd94f353.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ztr8-h4wdL_v1vhg.gif"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">下面是Apache Spark 3.1中PySpark用户可以使用的IDE自动完成功能的示例。来源:https://github.com/zero323/pyspark-stubs<a class="ae kl" href="https://github.com/zero323/pyspark-stubs" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="b15e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Spark History Server可以在应用程序完成后呈现Spark UI，它现在会显示您运行的结构化流查询的统计信息。</p><p id="fb29" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">阶段级调度(<a class="ae kl" href="https://issues.apache.org/jira/browse/SPARK-27495" rel="noopener ugc nofollow" target="_blank"> SPARK-27495 </a>)仅适用于启用动态分配时的YARN和Kubernetes部署。它允许您在代码中控制在一个阶段的粒度上请求的执行器资源的数量和类型。具体来说，您可以配置您的应用程序，在应用程序的第一阶段使用带有CPU的执行器(比如说，执行ETL和准备数据)，然后在应用程序的第二阶段使用GPU(比如说，训练ML模型)。</p><p id="2cf8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在性能方面，Spark 3.1改进了混洗散列连接的性能，并在子表达式消除和catalyst优化器中添加了新规则。对于PySpark用户来说，内存中的列格式<a class="ae kl" href="https://arrow.apache.org/overview/" rel="noopener ugc nofollow" target="_blank"> Apache Arrow </a>版本2.0.0现在与Spark捆绑在一起(而不是1.0.2)，这应该会使您的应用程序更快，特别是如果您倾向于在Spark和Pandas数据帧之间转换数据。好消息是，您将免费从这些性能改进中受益，无需任何代码或配置更改。</p><h1 id="7666" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论</h1><p id="acf0" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">Spark 3.1是Apache Spark的一个激动人心的版本，庆祝了社区多年来对Spark-on-Kubernetes集成的支持，标志着它的支持已经普遍可用并可以生产。这对于我们Data Mechanics来说并不意外，因为我们一直在帮助客户迁移到Kubernetes，并在开发人员体验和性能/成本降低方面不断取得巨大成果。</p><p id="d841" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">除了即将正式上市的Kubernetes上的Spark之外，优雅的退役功能还实现了将计算资源从存储中完全分离出来的愿景，并通过Spark使经济高效的spot实例的使用更加稳定。我们对该功能的初步测试非常有希望——我们将很快发布一个我们的大客户使用该功能的故事，敬请关注！</p></div><div class="ab cl my mz hu na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="ij ik il im in"><p id="bdec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="km">本文原</em> <a class="ae kl" href="https://datamechanics.co/blog-post/apache-spark-3-1-release-spark-on-kubernetes-is-now-ga" rel="noopener ugc nofollow" target="_blank"> <em class="km">发表于数据力学博客</em> </a> <em class="km">。</em></p></div></div>    
</body>
</html>