<html>
<head>
<title>AI risk is a global problem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能风险是一个全球性问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ai-risk-is-a-global-problem-ee56b3cb8930?source=collection_archive---------33-----------------------#2021-04-28">https://towardsdatascience.com/ai-risk-is-a-global-problem-ee56b3cb8930?source=collection_archive---------33-----------------------#2021-04-28</a></blockquote><div><div class="fc ig ih ii ij ik"/><div class="il im in io ip"><h2 id="b74b" class="iq ir is bd b dl it iu iv iw ix iy dk iz translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/tds-podcast" rel="noopener" target="_blank">播客</a></h2><div class=""/><div class=""><h2 id="0740" class="pw-subtitle-paragraph jy jb is bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">Nicolas Miailhe谈人工智能的全球协调</h2></div><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="kv kw l"/></div><p class="kx ky gj gh gi kz la bd b be z dk translated"><a class="ae lb" href="https://podcasts.apple.com/ca/podcast/towards-data-science/id1470952338?mt=2" rel="noopener ugc nofollow" target="_blank">苹果</a> | <a class="ae lb" href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9hbmNob3IuZm0vcy8zNmI0ODQ0L3BvZGNhc3QvcnNz" rel="noopener ugc nofollow" target="_blank">谷歌</a> | <a class="ae lb" href="https://open.spotify.com/show/63diy2DtpHzQfeNVxAPZgU" rel="noopener ugc nofollow" target="_blank"> SPOTIFY </a> | <a class="ae lb" href="https://anchor.fm/towardsdatascience" rel="noopener ugc nofollow" target="_blank">其他</a></p></figure><p id="2223" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated"><em class="ly">编者按:这一集是我们关于数据科学和机器学习新兴问题的播客系列的一部分</em>，<em class="ly">由Jeremie Harris主持。除了主持播客，Jeremie还帮助运营一家名为</em><a class="ae lb" href="http://sharpestminds.com" rel="noopener ugc nofollow" target="_blank"><em class="ly">sharpes minds</em></a><em class="ly">的数据科学导师初创公司。</em></p><p id="3c9d" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">1938年12月，一位名叫利奥·齐拉特的沮丧的核物理学家给英国海军部写了一封信，告诉他们他已经放弃了他最伟大的发明——核链式反应。</p><blockquote class="lz ma mb"><p id="9aac" class="lc ld ly le b lf lg kc lh li lj kf lk mc lm ln lo md lq lr ls me lu lv lw lx il bi translated">核连锁反应的想法是行不通的。没有必要对这个专利保密，事实上也没有必要保留这个专利。没用的。</p><p id="c19f" class="lc ld ly le b lf lg kc lh li lj kf lk mc lm ln lo md lq lr ls me lu lv lw lx il bi translated">—利奥·齐拉特</p></blockquote><p id="60db" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Szilard舔信封时不知道的是，就在同一天，柏林的一个研究小组第一次分裂了铀原子。一年后，曼哈顿计划开始实施，到1945年，第一颗原子弹被投放到日本广岛。仅仅四年后——也就是西拉德认为不可能的十年后——俄罗斯成功试验了第一枚原子弹，开启了以各种形式延续至今的全球核军备竞赛。</p><p id="9c45" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">从尖端技术到全球范围的风险，这是一个令人惊讶的短暂跳跃。尽管核能故事是这种飞跃的一个引人注目的例子，但它远不是唯一的例子。今天，许多人认为人工智能是一种技术，其发展将导致全球风险——因此，是一种需要全球管理的技术。就像国际条约允许我们降低核战争的风险一样，我们可能需要围绕人工智能进行全球协调，以减轻其潜在的负面影响。</p><p id="aeba" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Nicolas Miailhe是人工智能全球协调问题的世界领先专家之一。Nicolas是未来社会(Future Society)的联合创始人，未来社会是一个全球性的非营利组织，其主要关注点是鼓励负责任地采用人工智能，并确保世界各国对与之相关的风险达成共识。Nicolas是著名的哈佛大学肯尼迪政府学院的资深专家，是人工智能全球伙伴关系的指定专家，并为城市、政府和国际组织提供人工智能政策方面的建议。</p><p id="958e" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">以下是我在对话中最喜欢的一些观点:</p><ul class=""><li id="415e" class="mf mg is le b lf lg li lj ll mh lp mi lt mj lx mk ml mm mn bi translated">人工智能是一种双重用途的技术:可以用于自动化撰写乏味电子邮件的相同人工智能系统也可以用于大规模定制网络钓鱼攻击。由于其通用性质，尼古拉斯认为人工智能的机遇和挑战密不可分。因此，减缓人工智能发展不仅不可行，而且不可取——监管和投资必须齐头并进。</li><li id="36ed" class="mf mg is le b lf mo li mp ll mq lp mr lt ms lx mk ml mm mn bi translated">在人工智能可以被监管之前，在我们可以制定关于人工智能的国际协议之前，我们需要建立对人工智能是什么的共同理解。这比看起来更难:对于不想在人工智能开发竞赛中落后的发展中国家来说，安全似乎不那么重要——人工智能能力下降的经济影响太严重了。但在发达国家，通用人工智能技术的突破步伐越来越快，导致人们更加关注安全、公平和人工智能对齐。至关重要的是，我们要找到一种方法，就如何实现政策的正确平衡达成一致，以获得全球的认同。</li><li id="6c43" class="mf mg is le b lf mo li mp ll mq lp mr lt ms lx mk ml mm mn bi translated">除了协调不同国家在人工智能上的议程，Nico还强调了解决人工智能时间表分歧的重要性。特别是，许多人工智能研究人员认为，我们可能在未来十年内实现人类水平的通用人工智能，因此相信人工智能安全和人工智能对齐应该是人工智能社区比他们更大的关注点。相比之下，其他人认为真正的转型人工智能系统仍有很长的路要走，用深度学习先驱和Coursera创始人吴恩达的话说，担心人工智能的安全“就像担心火星上的人口过剩”虽然这种分歧可能无法完全解决，但在这个方向上建立共识很有价值。</li><li id="7bfa" class="mf mg is le b lf mo li mp ll mq lp mr lt ms lx mk ml mm mn bi translated">有时有人认为，政府将无法有效监督和监管人工智能的发展，因为私营公司对人工智能的绝大部分进展负有责任。Nicolas认为这是一种误解，并指出了DARPA、NSF和NIH等政府资助项目在推进人工智能技术方面的作用，以及它们对私营企业的投资。他还强调，主要的国防合同(如<a class="ae lb" href="https://en.wikipedia.org/wiki/Joint_Enterprise_Defense_Infrastructure" rel="noopener ugc nofollow" target="_blank"> JEDI </a>)导致大量资本流入微软等公司，这些公司反过来将这些资源重新用于资助行业领先的人工智能研究。尼古拉斯认为，公共部门对人工智能的贡献何时结束，私营部门的贡献何时开始，并不那么明显。</li></ul><p id="9e7e" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">你可以<a class="ae lb" href="https://twitter.com/n_miailhe" rel="noopener ugc nofollow" target="_blank">在推特上关注尼古拉斯</a>，或者<a class="ae lb" href="https://twitter.com/jeremiecharris" rel="noopener ugc nofollow" target="_blank">在推特上关注我</a></p></div><div class="ab cl mt mu hw mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="il im in io ip"><h2 id="a0c1" class="na nb is bd nc nd ne dn nf ng nh dp ni ll nj nk nl lp nm nn no lt np nq nr iy bi translated">播客中引用的链接:</h2><ul class=""><li id="384d" class="mf mg is le b lf ns li nt ll nu lp nv lt nw lx mk ml mm mn bi translated"><a class="ae lb" href="https://thefuturesociety.org/" rel="noopener ugc nofollow" target="_blank">未来学会的网站在这里。</a></li></ul></div><div class="ab cl mt mu hw mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="il im in io ip"><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi nx"><img src="../Images/6596ba35b4c4c244ba92cf52851f889f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y7HWrdaVPgV3EnY65ib69Q.png"/></div></div></figure><h2 id="b26e" class="na nb is bd nc nd ne dn nf ng nh dp ni ll nj nk nl lp nm nn no lt np nq nr iy bi translated">章节:</h2><ul class=""><li id="6a62" class="mf mg is le b lf ns li nt ll nu lp nv lt nw lx mk ml mm mn bi translated">0:00介绍</li><li id="908b" class="mf mg is le b lf mo li mp ll mq lp mr lt ms lx mk ml mm mn bi translated">0:50尼古拉斯的背景</li><li id="8d56" class="mf mg is le b lf mo li mp ll mq lp mr lt ms lx mk ml mm mn bi translated">7:45人工智能安全时间表(MIRI)</li><li id="1388" class="mf mg is le b lf mo li mp ll mq lp mr lt ms lx mk ml mm mn bi translated">11:00探索人工智能安全空间</li><li id="bccd" class="mf mg is le b lf mo li mp ll mq lp mr lt ms lx mk ml mm mn bi translated">14:00 AI的各种定义</li><li id="a69e" class="mf mg is le b lf mo li mp ll mq lp mr lt ms lx mk ml mm mn bi translated">21:45人工智能研究投资</li><li id="4fa9" class="mf mg is le b lf mo li mp ll mq lp mr lt ms lx mk ml mm mn bi translated">24:40网络殖民主义与人工智能和解</li><li id="2870" class="mf mg is le b lf mo li mp ll mq lp mr lt ms lx mk ml mm mn bi translated">31:42扩散策略</li><li id="562b" class="mf mg is le b lf mo li mp ll mq lp mr lt ms lx mk ml mm mn bi translated">34:00人工智能全球伙伴关系</li><li id="4c8f" class="mf mg is le b lf mo li mp ll mq lp mr lt ms lx mk ml mm mn bi translated">37:50中国在人工智能方面的进步</li><li id="e438" class="mf mg is le b lf mo li mp ll mq lp mr lt ms lx mk ml mm mn bi translated">47:45中国企业对AI安全的思考如何？</li><li id="7686" class="mf mg is le b lf mo li mp ll mq lp mr lt ms lx mk ml mm mn bi translated">52:20政府在资助人工智能安全研究中的作用</li><li id="b8a1" class="mf mg is le b lf mo li mp ll mq lp mr lt ms lx mk ml mm mn bi translated">55:33总结</li></ul></div></div>    
</body>
</html>