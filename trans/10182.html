<html>
<head>
<title>8 Tips and Tricks for Working with Large Datasets in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在机器学习中使用大型数据集的8个技巧和诀窍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/10-tips-tricks-for-working-with-large-datasets-in-machine-learning-7065f1d6a802?source=collection_archive---------10-----------------------#2021-09-27">https://towardsdatascience.com/10-tips-tricks-for-working-with-large-datasets-in-machine-learning-7065f1d6a802?source=collection_archive---------10-----------------------#2021-09-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b4e1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">内存和代码优化基本指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/98bfcdedf2f4d01268a3580e4155bd18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*45C9xIwTtI1Lh_QtqXiNwQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://pixabay.com/users/mohamed_hassan-5229782/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=3679741" rel="noopener ugc nofollow" target="_blank">穆罕默德·哈桑</a>来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=3679741" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="233e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Pandas和Scikit-learn是数据科学社区中流行的库，因为它们具有高性能和易于使用的数据结构和函数。熊猫为数据准备和分析提供数据分析工具。这些库可以很好地处理内存中的数据集(适合RAM的数据)，但是当处理大规模数据集或内存外的数据集时，它会失败，并可能导致内存问题。</p><p id="0c88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我将讨论在处理大规模数据集时可以使用的10个技巧和诀窍。这些技巧将帮助他们在处理内存不足或大型数据集时避免内存溢出问题，并加快他们的工作流程。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="6e75" class="ma mb it lw b gy mc md l me mf"><strong class="lw iu"><em class="mg">Checklist:</em></strong><br/><strong class="lw iu">1) Read dataset in chunks with Pandas<br/>2) Optimize the datatype constraints<br/>3) Prefer Vectorization<br/>4) Multiprocessing of Functions<br/>5) Incremental Learning<br/>6) Warm Start<br/>7) Distributed Libraries<br/>8) Save objects as Pickle file</strong></span></pre><h1 id="7216" class="mh mb it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">1.)用熊猫读数据块:</h1><p id="923b" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">Pandas提供API，可以在一行Python代码中读取CSV、txt、excel、pickle和其他文件格式。它一次将全部数据加载到RAM内存中，在处理内存不足的数据集时可能会导致内存问题。</p><p id="b0b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其思想是读取/加载和处理大数据块或数据集的小样本。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nd ne l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><p id="2fa7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的代码示例以块的形式读取大型数据集(第14行)，对每个块执行处理(第15行)，并进一步保存处理后的数据块(第17行)。</p><h1 id="0a6b" class="mh mb it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">2.)优化数据类型约束:</h1><p id="0edd" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">熊猫通过观察特征值，将默认数据类型分配给数据集的每个要素。对于具有整数值的要素，数据类型为int64，而具有小数值的要素，数据类型为float64。在分配给每个要素的默认数据类型列表下找到列表。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/9806127d74e3e7e04d90836ee70443e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*latRfi-hGZu_XJ0RnIQU-g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者图片)，熊猫默认数据类型</p></figure><p id="0bf5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">int64值的范围在<code class="fe ng nh ni lw b"><strong class="lb iu">-9,223,372,036,854,775,808 to 9,223,372,036,854,775,807.</strong></code> <strong class="lb iu"> </strong>之间。对于大多数数据集，整型特征值不会超过该限制。想法是通过观察最大和最小特征值来降级特征数据类型。</p><div class="kj kk kl km gt ab cb"><figure class="nj kn nk nl nm nn no paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/db4aaaf2bfe7d0d51615ac8c31a27d60.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*K-EACCJxHdD2lBfH0O6vOQ.png"/></div></figure><figure class="nj kn np nl nm nn no paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/bdc20838c47c39be67914c430e39e70c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/1*kDjuKuUvTkBRE5cTrZnftg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk nq di nr ns translated">(作者图片)，<strong class="bd nt">左:</strong>(作者图片)，分配的默认数据类型和内存使用量，<strong class="bd nt">右:</strong>降级数据类型后的内存使用量</p></figure></div><p id="b1b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">示例数据集使用默认的数据类型约束集，占用467.4 MB内存。对数据类型进行类型转换后，内存使用减少了大约70%,为134.9 MB。</p><p id="69fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">阅读我以前的一篇文章，更好地理解通过类型转换降级的数据类型。</p><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/optimize-pandas-memory-usage-while-reading-large-datasets-1b047c762c9b"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">为大型数据集优化Pandas的内存使用</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">有效利用数据类型来防止内存崩溃</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="oh l oi oj ok og ol ks nx"/></div></div></a></div><h1 id="1efe" class="mh mb it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">3.)首选矢量化进行迭代:</h1><p id="e8d6" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">对于数据处理任务，人们总是会遇到各种需要遍历数据集的情况。Pandas提供了各种函数来使用<code class="fe ng nh ni lw b">iterrows()</code>、<code class="fe ng nh ni lw b">itertuples()</code>、<code class="fe ng nh ni lw b">iteritems()</code>循环它们的实例，其中<code class="fe ng nh ni lw b">iterrows()</code>是最慢的。</p><p id="eb27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要素的矢量化加快了迭代过程。<code class="fe ng nh ni lw b">iterrows()</code>遍历熊猫系列，因此是最慢的。<code class="fe ng nh ni lw b">itertuples()</code>遍历元组列表，因此相对更快。</p><p id="c218" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">跟随我以前的一篇文章，了解更多关于如何让熊猫的迭代速度加快400倍。</p><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/400x-time-faster-pandas-data-frame-iteration-16fb47871a0a"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">Pandas数据帧迭代速度快400倍</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">避免使用iterrows()函数</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="om l oi oj ok og ol ks nx"/></div></div></a></div><h1 id="f064" class="mh mb it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">4.)多重处理:</h1><p id="dc7e" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">与其他编程语言相比，Python相对较慢，因为代码是在运行时解释的，而不是在编译时编译成本机代码。即使在对特征向量进行矢量化之后，用于数据预处理的函数的执行也相对较慢。</p><p id="95ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个想法是利用CPU的所有内核，并在所有内核之间扩展计算，以加速工作流。Python提出了一个<a class="ae ky" href="https://docs.python.org/3/library/multiprocessing.html" rel="noopener ugc nofollow" target="_blank">多重处理模块</a>，它允许这样的功能。</p><p id="969e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">跟随我以前的一篇文章<a class="ae ky" rel="noopener" target="_blank" href="/25x-times-faster-python-function-execution-in-a-few-lines-of-code-4c82bdd0f64c">学习如何使用多处理模块扩展Python函数。</a></p><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/25x-times-faster-python-function-execution-in-a-few-lines-of-code-4c82bdd0f64c"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">用几行代码将Python函数的执行速度提高了30倍</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">Python中多重处理的基本指南</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="on l oi oj ok og ol ks nx"/></div></div></a></div><h1 id="412b" class="mh mb it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">5.)增量学习:</h1><p id="231e" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">Scikit-learn提供了各种<a class="ae ky" href="https://en.wikipedia.org/wiki/Statistical_classification" rel="noopener ugc nofollow" target="_blank">分类</a>、<a class="ae ky" href="https://en.wikipedia.org/wiki/Regression_analysis" rel="noopener ugc nofollow" target="_blank">回归</a>和<a class="ae ky" href="https://en.wikipedia.org/wiki/Cluster_analysis" rel="noopener ugc nofollow" target="_blank">聚类</a>机器学习算法的高效实现。对于新一批学习数据随时间而来的机器学习任务，重新训练模型的时间效率不高。此外，对于内存不足的数据集，一次性训练整个数据集是不可行的，因为不可能一次性将整个数据加载到RAM中</p><p id="9d69" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">增量学习可以用于这样的任务，其中模型的过去学习将被恢复，并且相同的模型将用新的一批数据来训练。Scikit-learn提供了<code class="fe ng nh ni lw b"><a class="ae ky" href="https://scikit-learn.org/0.15/modules/scaling_strategies.html" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">partial_fit()</strong></a></code>函数，该函数为核外数据集提供了<a class="ae ky" href="https://scikit-learn.org/0.15/modules/scaling_strategies.html" rel="noopener ugc nofollow" target="_blank">增量学习。</a></p><h1 id="f8b8" class="mh mb it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">6.)热启动:</h1><p id="76c7" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">Scikit-learn使用API <code class="fe ng nh ni lw b">warm_start</code>来重用从之前的参数值中学习到的模型方面。当<code class="fe ng nh ni lw b">warm_start</code>为真时，分配的模型超参数用于拟合模型。例如，warm_state可用于增加随机森林模型中的树的数量(n_estimators)。使用<code class="fe ng nh ni lw b">warm_start</code>参数时，超参数值仅在保持训练数据集或多或少不变的情况下发生变化。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="a833" class="ma mb it lw b gy mc md l me mf"><strong class="lw iu">rf = RandomForestClassifier(n_estimators=10, warm_start=True)                     <br/>rf.fit(X_train, y_train)<br/>rf.n_estimators += 5<br/>rf.fit(X_train, y_train)</strong></span></pre><p id="ac68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上面的样本代码来看，初始模型是用<code class="fe ng nh ni lw b"><strong class="lb iu">n_estimator=10</strong></code>对<code class="fe ng nh ni lw b"><strong class="lb iu">X_train</strong></code> <strong class="lb iu"> </strong>样本数据进行训练的。然后我们进一步增加5棵树<code class="fe ng nh ni lw b"><strong class="lb iu">n_estimator=5</strong></code> <strong class="lb iu"> </strong>并重新训练相同的模型。</p><blockquote class="oo op oq"><p id="78c6" class="kz la mg lb b lc ld ju le lf lg jx lh or lj lk ll os ln lo lp ot lr ls lt lu im bi translated">跟随我以前的一篇关于增量学习的文章来更好地理解增量学习和warm_state功能。</p></blockquote><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/strategies-to-train-out-of-memory-data-with-scikit-learn-7b2ed15b9a80"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">如何使用Scikit-learn训练内存不足的数据</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">使用partial_fit API进行增量学习的基本指南</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="ou l oi oj ok og ol ks nx"/></div></div></a></div><h1 id="cd19" class="mh mb it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">7.)分布式库:</h1><p id="346a" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">Pandas、Numpy、Scikit-Learn等Python包提供了高级可用且灵活的API，但在很大程度上忽略了性能和可伸缩性。在处理内存不足的数据集时，这些库可能会导致内存问题。</p><p id="920a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其思想是使用分布式库，如Dask、Vaex、Modin等，它们构建在Pandas、Numpy和Scikit-learn库的基础上，并专门设计为通过在所有CPU内核上并行化操作来扩展工作流。</p><blockquote class="oo op oq"><p id="2eff" class="kz la mg lb b lc ld ju le lf lg jx lh or lj lk ll os ln lo lp ot lr ls lt lu im bi translated">请在下面找到我以前关于分布式库的文章列表，比如<a class="ae ky" rel="noopener" target="_blank" href="/how-dask-accelerates-pandas-ecosystem-9c175062f409"> Dask </a>、<a class="ae ky" rel="noopener" target="_blank" href="/process-dataset-with-200-million-rows-using-vaex-ad4839710d3b"> Vaex </a>和<a class="ae ky" rel="noopener" target="_blank" href="/modin-speed-up-your-pandas-notebooks-scripts-and-libraries-c2ac7de45b75"> Modin </a>:</p></blockquote><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/how-dask-accelerates-pandas-ecosystem-9c175062f409"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">Dask如何加速熊猫生态系统？</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">深入了解Dask数据框架，以及它是如何工作的</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="ov l oi oj ok og ol ks nx"/></div></div></a></div><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/process-dataset-with-200-million-rows-using-vaex-ad4839710d3b"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">使用Vaex处理具有2亿行的数据集</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">使用vaex数据框对大型数据集执行操作</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="ow l oi oj ok og ol ks nx"/></div></div></a></div><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/modin-speed-up-your-pandas-notebooks-scripts-and-libraries-c2ac7de45b75"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">摩丁-加速你的熊猫笔记本，脚本和图书馆</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">使用Modin扩展Pandas工作流，只需更改一行代码</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="ox l oi oj ok og ol ks nx"/></div></div></a></div><h1 id="b8c0" class="mh mb it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">8.)将对象保存为Pickle文件:</h1><p id="eac8" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">在处理大型数据集时，读取和保存数据或临时文件是一项单调乏味的任务。CSV、TXT或excel数据格式的读写操作计算量很大。</p><p id="1b96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还有其他数据格式具有相对更快的读写操作，在处理大规模数据集时可能是首选。</p><div class="kj kk kl km gt ab cb"><figure class="nj kn oy nl nm nn no paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/8962e7e42decb92d356d56001321a66a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*ac70Yd3qJoq8RtS_sKac7g.png"/></div></figure><figure class="nj kn oz nl nm nn no paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/c7304a85b773dee0a5ee16ef30c8b0ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*ZnjPhHAyxbs7YD8mSPET8Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk pa di pb ns translated">(图片由作者提供)，<strong class="bd nt">左:</strong>读取和保存时间对比(秒)，<strong class="bd nt">右:</strong>内存消耗(MB)</p></figure></div><p id="63e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上图显示了具有1，458，644条记录和12个特性<em class="mg">的样本数据集的读取、写入操作和内存消耗的基准数据。</em></p><p id="2359" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Pickle文件可能是保存和读取数据集或临时文件的首选。Pickling可以存储列表、字典、类对象等python对象。</p><blockquote class="oo op oq"><p id="96ba" class="kz la mg lb b lc ld ju le lf lg jx lh or lj lk ll os ln lo lp ot lr ls lt lu im bi translated">阅读我的一篇<a class="ae ky" rel="noopener" target="_blank" href="/stop-saving-your-data-frame-in-csv-format-7823d3873ba2">以前的文章</a>，观察使用各种数据格式进行读取和保存操作的基准时间比较</p></blockquote><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/stop-saving-your-data-frame-in-csv-format-7823d3873ba2"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">停止以CSV格式保存数据框</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">使用各种数据格式进行读取和保存操作的基准时间比较</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="pc l oi oj ok og ol ks nx"/></div></div></a></div></div><div class="ab cl pd pe hx pf" role="separator"><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi"/></div><div class="im in io ip iq"><h1 id="440d" class="mh mb it bd mi mj pk ml mm mn pl mp mq jz pm ka ms kc pn kd mu kf po kg mw mx bi translated">结论:</h1><p id="d47f" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">在本文中，我们讨论了在处理内存不足或大型数据集时可以使用的8种不同的技术或技巧。这些技术可以加快工作流程并避免内存问题。</p><h1 id="b606" class="mh mb it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">参考资料:</h1><p id="14bb" class="pw-post-body-paragraph kz la it lb b lc my ju le lf mz jx lh li na lk ll lm nb lo lp lq nc ls lt lu im bi translated">[1] Scikit-learn文档:<a class="ae ky" href="https://scikit-learn.org/0.15/modules/scaling_strategies.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/0.15/modules/scaling _ strategies . html</a></p></div><div class="ab cl pd pe hx pf" role="separator"><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi"/></div><div class="im in io ip iq"><p id="d6a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mg">喜欢这篇文章吗？成为</em> <a class="ae ky" href="https://satyam-kumar.medium.com/membership" rel="noopener"> <em class="mg">中等会员</em> </a> <em class="mg">继续无限制学习。如果你使用下面的链接，我会收到你的一小部分会员费，不需要你额外付费。</em></p><div class="nu nv gp gr nw nx"><a href="https://satyam-kumar.medium.com/membership" rel="noopener follow" target="_blank"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">加入我的推荐链接-萨蒂扬库马尔媒体</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">satyam-kumar.medium.com</p></div></div><div class="og l"><div class="pp l oi oj ok og ol ks nx"/></div></div></a></div><blockquote class="pq"><p id="4cba" class="pr ps it bd pt pu pv pw px py pz lu dk translated">感谢您的阅读</p></blockquote></div></div>    
</body>
</html>