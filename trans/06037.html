<html>
<head>
<title>Creating Music with ML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用ML创作音乐</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/creating-music-with-ml-b1960bce3b45?source=collection_archive---------21-----------------------#2021-05-30">https://towardsdatascience.com/creating-music-with-ml-b1960bce3b45?source=collection_archive---------21-----------------------#2021-05-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4fe9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">变形金刚又来了。</h2></div><p id="7ded" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">技术设备日复一日地播放音乐。你的手机可以做到，我的电脑可以做到，智能设备根据命令播放歌曲。因此，我们为什么不让技术设备也创造音乐呢？不仅仅是回放我们的结果，而是拿出原创作品？</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/46f0154a307a2ccdb5670fd2a83e9ac9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WfMXSkTYAZwkesBP"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">韦斯顿·麦金农在<a class="ae lu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="16a0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个方向有一个正在进行的研究领域；DeepMind凭借其能够生成原始音频的<a class="ae lu" href="https://deepmind.com/blog/article/wavenet-generative-model-raw-audio" rel="noopener ugc nofollow" target="_blank"> WaveNet </a>架构做出了巨大贡献。生成原始音频(生成类似音频曲线的浮点值)的缺点是涉及巨大的计算能力。这是一个障碍，因为计算机可能并不总是可用。</p><p id="ca73" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一个效果惊人的方法是使用不同的格式来表现音乐。想想活页乐谱:虽然它本身不会发出声音，但它可以在下一步中用来产生声音。并且通过简单地生成图像，可以容易地训练ML模型来生成活页乐谱。</p><p id="7a5a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一种格式是使用MIDI文件。这种格式将音乐存储为符号表示。我们不再保留声音，而是保留产生声音的信息。乐谱将音符值放在五线谱上，而MIDI表示包含信息。这些信息包含<em class="lv">音符开</em>和<em class="lv">音符关</em>事件，指示乐器何时演奏。速度同样可以包括在内。</p><p id="62e0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">MIDI文件可以包含从C_{-1}到C_{)}范围内的音符；相比之下，一架标准钢琴有88个键，那些漂亮的大钢琴有时更多。</p><p id="760e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在MIDI文件中，音符可以有任意的持续时间，并且必须在回放前量化。然后，为了可视化(量化的)MIDI文件，我们使用钢琴卷帘窗表示。这本质上是一个矩阵，横轴是时标，纵轴是理论上可以同时演奏的音符数。下面描述了一个可视化示例:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi lw"><img src="../Images/29b6d7d2c198f59e5552c8aaede7d13e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tdWJiXirbJOXNJxVhft6Ug.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">钢琴卷帘窗的可视化示例。y轴表示音高，x轴表示时间。在时间<em class="lx"> t，如果存在蓝色标记，则演奏一个音高(或音符)。图片由作者提供。</em></p></figure><p id="daf7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，用矩阵来表示音乐有什么好处呢？首先，你需要更少的存储空间，典型的MIDI文件最多只有几千字节。其次，实际的矩阵可以是布尔型或int8型。与原始音频相比，这大大减小了张量的大小。</p><p id="081c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">简而言之:你把音乐表现为一种形象。</p><p id="d9ee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">反过来也很容易做到。网络的输出也是一个矩阵(或图像),因此可以解释为钢琴曲。然后这个钢琴卷帘窗保存了事件信息，我们用它来(重新)构建一个MIDI文件。</p><p id="d0dd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在的问题是:听起来怎么样？</p><p id="9207" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">训练越多越好。</p><p id="3bd2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是你可以在这里自己听一听。默认情况下，我们最好的模型会被选中。换一个训练步数更少的，听听区别。</p></div><div class="ab cl ly lz hx ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="im in io ip iq"><p id="b1d0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在一个项目中，我有机会成为一个使用MIDI文件的小组的一员，并尝试了各种ML模型。最初，我们训练自动编码器、变型自动编码器、生成对抗网络、它们的组合，以及不可避免的变形器。</p><p id="4620" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最终，我们选定了由谷歌大脑团队开发的<a class="ae lu" href="https://arxiv.org/pdf/1809.04281.pdf" rel="noopener ugc nofollow" target="_blank">音乐转换器</a>架构。然后我们在内部的MIDI文件数据集上训练这个模型。这个数据集包含了所有时代的音乐，但也包含了伟大的作曲家，如巴赫、柏辽兹、海顿和莫扎特。</p><p id="61d0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于我们为一个关于莫扎特的节日做了贡献，我们把重点放在了包括莫扎特在内的古典作曲家的作品上。</p><p id="a1bb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了让访问者可以选择与我们的模型进行交互，我们编写了一个web应用程序。这是在<a class="ae lu" href="http://streamlit.io" rel="noopener ugc nofollow" target="_blank"> streamlit </a>的帮助下完成的(这在大多数情况下非常方便，但在一些重要的地方使用起来<em class="lv">非常</em>)令人沮丧。</p><p id="9d23" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要摆弄模型，从头开始创作新作品，请点击此<a class="ae lu" href="https://mozartgenom.professor-x.de/?sub_page=2" rel="noopener ugc nofollow" target="_blank">链接</a>。点击按钮，让人工智能做剩下的事情。</p></div></div>    
</body>
</html>