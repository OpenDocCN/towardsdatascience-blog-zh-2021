<html>
<head>
<title>How many neurons for a neural network?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一个神经网络有多少个神经元？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-many-neurons-for-a-neural-network-2107627f7869?source=collection_archive---------28-----------------------#2021-05-10">https://towardsdatascience.com/how-many-neurons-for-a-neural-network-2107627f7869?source=collection_archive---------28-----------------------#2021-05-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8a59" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">让我们看看如何找到神经网络的最佳神经元数量</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7f3a2879de3c8a3172700b7520f89cbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yY5nMzyiJU1n3jW1.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="1513" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">神经网络是机器学习的一个迷人领域，但它们有时很难优化和解释。事实上，他们有几个超参数。要调整的最常见的超参数是隐藏层中神经元的数量。让我们看看如何为我们的数据集找到神经网络的最佳神经元数量。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="8549" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">什么是神经网络？</h1><p id="99e8" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">神经网络是一种特殊的模型，它试图捕捉特征和目标之间的相关性，根据神经元层转换数据集。有几本书是围绕神经网络写的，给你一个这种模型的完整概述不在本文的范围之内。我只能说，神经网络是由几层神经元组成的。每个神经元获得一些输入，转换它们并返回一个输出。一个神经元的输出可以成为下一层神经元的输入，以此类推，构建越来越复杂的体系结构。</p><p id="66ae" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第一层称为输入层，由神经元构成，它返回特性本身的值。然后，第一层的每个神经元与隐含层的所有神经元相连，隐含层负责网络的学习能力。隐藏层之后可以是其他几个隐藏层，这是典型的深度学习网络。最后，将最后一个隐藏层的输出提供给给出结果(即目标变量的值)的输出层。</p><p id="569a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从最简单的形式来看，神经网络只有一个隐藏层，如下图所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8620d55f24e37293089de71e839ef6fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pycBycu6tfWvNf8L.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="16a2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输入层的神经元数量等于特征的数量。根据目标变量定义输出层的神经元数量。这就出现了为隐藏层找到正确数量的神经元的问题。</p><p id="7415" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">少数可能会产生欠拟合，因为网络可能无法正确学习。高数值可能会产生过度拟合，因为网络从训练数据中学到了太多东西，而没有进行归纳。因此，必须有一个中间数量的神经元来确保良好的训练。</p><h1 id="6664" class="mb mc it bd md me my mg mh mi mz mk ml jz na ka mn kc nb kd mp kf nc kg mr ms bi translated">如何优化神经元的数量</h1><p id="5cbc" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">程序非常简单，它使用交叉验证:</p><ul class=""><li id="9ba6" class="nd ne it la b lb lc le lf lh nf ll ng lp nh lt ni nj nk nl bi translated">设置若干神经元</li><li id="6c0f" class="nd ne it la b lb nm le nn lh no ll np lp nq lt ni nj nk nl bi translated">在k倍交叉验证中计算某些性能指标的平均值</li><li id="d2bf" class="nd ne it la b lb nm le nn lh no ll np lp nq lt ni nj nk nl bi translated">用不同数量的神经元重复这个过程</li><li id="8743" class="nd ne it la b lb nm le nn lh no ll np lp nq lt ni nj nk nl bi translated">选择在k倍交叉验证中使平均值最大化的神经元数量</li></ul><p id="6a2b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">交叉验证很重要，因为使用它我们可以确保模型不会过拟合或欠拟合。</p><p id="a3e1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个过程非常类似于超参数调整，因为隐藏层中的神经元数量实际上是要调整的超参数。</p><p id="86be" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们看看如何在Python中应用这个过程。</p><h1 id="1899" class="mb mc it bd md me my mg mh mi mz mk ml jz na ka mn kc nb kd mp kf nc kg mr ms bi translated">Python中的示例</h1><p id="fb81" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">在这个例子中，我将展示如何使用scikit-learn库优化Python中的神经元数量。在现实生活的例子中，您可能会使用Keras来构建您的神经网络，但概念是完全相同的。你可以在我的<a class="ae nr" href="https://github.com/gianlucamalato/machinelearning/blob/master/Best_number_of_neurons.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中找到代码。</p><p id="bfa8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我将使用scikit-learn中包含的<em class="ns">乳腺癌</em>示例数据集。</p><p id="bc51" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，我们来导入一些有用的库。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="9509" class="ny mc it nu b gy nz oa l ob oc">import numpy as np<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.neural_network import MLPClassifier<br/>from sklearn.datasets import load_breast_cancer<br/>from sklearn.model_selection import train_test_split, GridSearchCV<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.metrics import roc_auc_score</span></pre><p id="fc6a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，我们可以加载数据集，并将其分成训练集和测试集。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="b399" class="ny mc it nu b gy nz oa l ob oc">X,y = load_breast_cancer(return_X_y=True)<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)</span></pre><p id="2224" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们必须定义我们的模型。对于这个例子，我将使用一个简单的多层感知器，只有一个隐藏层。为了简单起见，构造函数的所有参数都保持标准值。我只是设置了随机状态，以保证结果的重现性。</p><p id="f71a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在将数据集提供给神经网络之前，不要忘记缩放您的要素。为了简单起见，我将使用scikit-learn中的Pipeline对象，然后应用标准化。关于缩放技术的更多信息，你可以参考我之前的<a class="ae nr" href="https://www.yourdatateacher.com/2021/03/22/scaling-of-the-numerical-variables/" rel="noopener ugc nofollow" target="_blank">博客文章</a>和我的<a class="ae nr" href="https://yourdatateacher.teachable.com/p/data-pre-processing-for-machine-learning-in-python" rel="noopener ugc nofollow" target="_blank">预处理课程</a>。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="f79b" class="ny mc it nu b gy nz oa l ob oc">model = Pipeline([<br/>                  ('scaler',StandardScaler()),<br/>                  ('model',MLPClassifier(random_state=0))<br/>])</span></pre><p id="4ad8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们必须通过搜索最佳数量的神经元来优化我们的网络。请记住，我们会尝试几种可能的数字，并在交叉验证中计算绩效指标的平均值。最大化这样一个值的神经元的数量就是我们正在寻找的数量。</p><p id="1950" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为此，我们可以使用GridSearchCV对象。由于我们正在处理一个二元分类问题，我们要最大化的度量是AUROC。我们将以2为步长从5个神经元跨越到100个神经元。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="0abc" class="ny mc it nu b gy nz oa l ob oc">search = GridSearchCV(model,<br/>   {'model__hidden_layer_sizes':[(x,) for x in np.arange(5,100,2)]},<br/>   cv = 5, scoring = "roc_auc", verbose=3, n_jobs = -1<br/>                      <br/>)</span></pre><p id="de6d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们可以搜索神经元的最佳数量。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="ee45" class="ny mc it nu b gy nz oa l ob oc">search.fit(X_train, y_train)</span></pre><p id="7560" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">搜索结束后，我们得到最好的平均分数，即:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="2089" class="ny mc it nu b gy nz oa l ob oc">search.best_score_</span><span id="5f3c" class="ny mc it nu b gy od oa l ob oc"># 0.9947175348495965</span></pre><p id="0ab1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">神经元的最佳数量是:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="03ee" class="ny mc it nu b gy nz oa l ob oc">search.best_params_</span><span id="b936" class="ny mc it nu b gy od oa l ob oc"># {'model__hidden_layer_sizes': (75,)}</span></pre><p id="026a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们可以在测试数据集上计算这种模型的AUROC，以确保我们没有过度拟合我们的数据集。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="1104" class="ny mc it nu b gy nz oa l ob oc">roc_auc_score(y_test,search.predict_proba(X_test)[:,1])</span><span id="0a3b" class="ny mc it nu b gy od oa l ob oc"># 0.9982730973233008</span></pre><p id="0e57" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们获得的值仍然很高，因此我们非常确定优化的模型已经从它携带的信息中学习了训练数据集。</p><h1 id="8023" class="mb mc it bd md me my mg mh mi mz mk ml jz na ka mn kc nb kd mp kf nc kg mr ms bi translated">结论</h1><p id="0c39" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">优化神经网络可能是一项复杂的任务。在本文中，我解释了一种优化神经元数量的可能方法，但同样的概念甚至可以应用于其他超参数(如激活函数、最小批量、时期数、学习速率)。请记住，超参数的数量越多，优化速度越慢。</p><p id="5caf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你想了解更多关于神经网络的知识，加入我的Python 在线课程<a class="ae nr" href="https://yourdatateacher.teachable.com/p/supervised-machine-learning-with-python" rel="noopener ugc nofollow" target="_blank">监督机器学习。</a></p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><p id="8405" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="ns">原载于2021年5月10日https://www.yourdatateacher.com</em><em class="ns">的</em> <a class="ae nr" href="https://www.yourdatateacher.com/2021/05/10/how-many-neurons-for-a-neural-network/" rel="noopener ugc nofollow" target="_blank"> <em class="ns">。</em></a></p></div></div>    
</body>
</html>