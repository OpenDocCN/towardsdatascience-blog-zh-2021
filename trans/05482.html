<html>
<head>
<title>20x times faster Grid Search Cross-Validation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">网格搜索交叉验证速度提高20倍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/20x-times-faster-grid-search-cross-validation-19ef01409b7c?source=collection_archive---------4-----------------------#2021-05-15">https://towardsdatascience.com/20x-times-faster-grid-search-cross-validation-19ef01409b7c?source=collection_archive---------4-----------------------#2021-05-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fef8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过将网格搜索减半，加快交叉验证工作流程</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5e6d14f8b16452741896a18e8c620e51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*21vDp8v7pqxuzKY5-n3omA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://pixabay.com/users/anncapictures-1564471/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=2678544" rel="noopener ugc nofollow" target="_blank"> anncapictures </a>来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=2678544" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="5847" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了训练稳健的机器学习模型，必须选择正确的机器学习算法和正确的超参数组合。选择最佳参数集的过程称为超参数调整。</p><p id="6882" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">人们必须在所有机器学习算法和其超参数的不同组合上训练数据集，以提高性能度量。交叉验证技术可用于在各种机器学习算法上训练数据集，并从中选择最佳算法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/250e2bde9752781883a93961e0dc81c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*UJRWHoH3fc2JfQEMfTRJyQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，GridSearchCV和HalvingGridSearchCV的时间约束比较</p></figure><h1 id="eab1" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">什么是交叉验证？</h1><p id="85dc" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">交叉验证是一种重采样技术，可用于在有限的数据集上评估和选择机器学习算法。k折叠交叉验证是一种交叉验证，其中训练数据被分成k个折叠，并且(k-1)个折叠用于训练，第k个折叠用于模型的验证。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/82d29f893ed4781e2c5f399709bcdbbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E1e-8OmoqJaSmHxxPXcPGg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(<a class="ae ky" href="https://scikit-learn.org/stable/modules/cross_validation.html" rel="noopener ugc nofollow" target="_blank">来源</a>)，k倍交叉验证</p></figure><blockquote class="mu mv mw"><p id="204c" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">阅读<a class="ae ky" href="https://scikit-learn.org/stable/modules/cross_validation.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn交叉验证文档</a>以获得更好的理解。</p></blockquote><h1 id="b58f" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">网格搜索CV:</h1><p id="9d99" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">网格搜索交叉验证是一种选择最佳机器学习模型的技术，由超参数网格参数化。Scikit-Learn库附带网格搜索交叉验证实现。</p><p id="7077" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">网格搜索CV尝试模型的所有参数网格组合，并返回具有最佳性能分数的最佳参数集。这也是一个缺点，因为训练每个参数组合的模型增加了时间复杂度。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="53a3" class="ng lx it nc b gy nh ni l nj nk"><strong class="nc iu">param_grid </strong>= {<br/>"max_depth": [3, 4, 7, 10, 25],<br/>"gamma": [0.5, 1, 5, 10, 25],<br/>"min_child_weight": [1, 3, 5, 10, 25],<br/>"reg_lambda": [5, 10, 50, 100, 300],<br/>"scale_pos_weight": [1, 3, 5, 10, 25]<br/>}</span><span id="066f" class="ng lx it nc b gy nl ni l nj nk"># Grid Search CV implementation<strong class="nc iu"><br/>xgb_cl = xgb.XGBClassifier(objective="binary:logistic")<br/>grid_cv = GridSearchCV(xgb_cl, param_grid, scoring="roc_auc", n_jobs=-1, cv=3)<br/>grid_cv.fit(X_train, y_train)</strong></span><span id="54b4" class="ng lx it nc b gy nl ni l nj nk"># Return set of parameters with the best performance<br/><strong class="nc iu">grid_cv.best_params_</strong></span><span id="2050" class="ng lx it nc b gy nl ni l nj nk"># Return the performance metric score<br/><strong class="nc iu">grid_cv.best_score_</strong></span></pre><p id="f28f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的代码片段解释了网格搜索CV的用法，cv=3，它在所有的<code class="fe nm nn no nc b"><strong class="lb iu">param_grid </strong></code>参数组合上训练<code class="fe nm nn no nc b"><strong class="lb iu">X_train </strong></code>数据集。</p><p id="917a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于大型数据集，网格搜索CV时间复杂度呈指数增长，因此实际上不可行。</p><p id="8fc0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以转移到<strong class="lb iu">随机搜索CV </strong>，其中算法将随机选择参数的组合。随机搜索CV的性能在某种程度上等于或小于网格搜索CV，但是时间复杂度降低，并且对大规模数据集应用网格搜索变得实际可行。</p><p id="e8b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将讨论一种将网格搜索CV减半的新算法，它的性能与网格搜索CV相当，但与网格搜索相比，时间复杂度大大降低。</p><h1 id="2945" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">减半网格搜索:</h1><p id="9d64" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">虽然网格搜索CV和随机搜索CV都在整个数据上训练所有成分(参数网格的组合)，但是减半网格搜索CV或减半随机搜索CV遵循一种<strong class="lb iu"> <em class="mx">连续减半方法</em> </strong>。</p><p id="5962" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将网格搜索(HGS) CV减半的步骤如下:</p><ol class=""><li id="e550" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu nu nv nw nx bi translated">HGS将数据子集训练成所有的参数组合。</li><li id="ff8b" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">表现最好的候选人或组合被选中。</li><li id="6193" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">在表现最好的候选人身上训练更大的训练数据子集。</li><li id="0333" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">重复上述3个步骤，直到最佳超参数集保持不变。</li></ol><p id="ca4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用HGS，对于每个经过的迭代，参数分量在减少，而训练数据集在增加。由于该算法遵循连续减半的方法，因此与网格搜索CV相比，该算法的时间复杂度相对较小。</p><h2 id="a7ca" class="ng lx it bd ly od oe dn mc of og dp mg li oh oi mi lm oj ok mk lq ol om mm on bi translated">实施:</h2><p id="5080" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">Scikit-Learn库实现了减半网格搜索CV算法。下面的代码片段解释了算法的工作和实现。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="d22b" class="ng lx it nc b gy nh ni l nj nk"><strong class="nc iu">param_grid =</strong> <strong class="nc iu"><em class="mx">{<br/>"max_depth": [3, 4, 7, 10, 25],<br/>"gamma": [0.5, 1, 5, 10, 25],<br/>"min_child_weight": [1, 3, 5, 10, 25],<br/>"reg_lambda": [5, 10, 50, 100, 300],<br/>"scale_pos_weight": [1, 3, 5, 10, 25]<br/>}</em></strong></span><span id="a32d" class="ng lx it nc b gy nl ni l nj nk"># Grid Search CV implementation<strong class="nc iu"><br/>xgb_cl = xgb.XGBClassifier(objective="binary:logistic")<br/>halving_cv = HalvingGridSearchCV(xgb_cl, param_grid, scoring="roc_auc", n_jobs=-1, min_resources="exhaust", factor=3)</strong><br/><strong class="nc iu">halving_cv.fit(X_train, y_train)</strong></span><span id="48cf" class="ng lx it nc b gy nl ni l nj nk"># Return set of parameters with the best performance<br/><strong class="nc iu">halving_cv.best_params_</strong></span><span id="4f7b" class="ng lx it nc b gy nl ni l nj nk"># Return the performance metric score<br/><strong class="nc iu">halving_cv.best_score_</strong></span></pre><h1 id="785f" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">基准时间和性能分数:</h1><p id="1a14" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">现在让我们比较网格搜索CV和减半搜索CV的性能得分和时间复杂度。</p><blockquote class="mu mv mw"><p id="eb79" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated"><a class="ae ky" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank">Kaggle</a>的信用卡欺诈数据集用于计算时间数。这是一个分类问题，ROC-AUC分数被用作比较性能的度量。</p><p id="045a" class="kz la mx lb b lc ld ju le lf lg jx lh my lj lk ll mz ln lo lp na lr ls lt lu im bi translated">只有大约7.5k记录用于cv=3的训练，大约3k记录用于测试目的。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/3bff0424100bbd3d3a0846045ffb39a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r214Wy1Pty3WwvwUDZkD9g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，网格搜索(GS)和减半网格搜索(HGS)交叉验证的基准时间约束和性能AUC-ROC得分</p></figure><p id="c91e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">观察上面的时间数字，对于具有3125个组合的参数网格，网格搜索CV花费了10856秒(~3小时)，而将网格搜索CV减半花费了465秒(~8分钟)，这大约快了23倍。</p><h1 id="872a" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结论:</h1><p id="9844" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在本文中，我们讨论了一种网格搜索CV的优化方法，即将网格搜索CV减半，然后采用逐次减半的方法来提高时间复杂度。也可以尝试随机搜索CV或减半随机搜索CV，这可以进一步降低时间复杂度，但有时会以性能分数为代价。</p><p id="e738" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最好的部分是减半网格搜索CV实现附带scikit-learn包以供使用。</p><h1 id="0291" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">参考资料:</h1><p id="916a" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">[1]等分网格搜索CV文档:<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . model _ selection。HalvingGridSearchCV.html</a></p><blockquote class="op"><p id="1a18" class="oq or it bd os ot ou ov ow ox oy lu dk translated">感谢您的阅读</p></blockquote></div></div>    
</body>
</html>