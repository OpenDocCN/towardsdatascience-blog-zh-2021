<html>
<head>
<title>Variational Inference — Where old Physics Solves new Bayesian Problems</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">变分推理——旧物理学解决新的贝叶斯问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/variational-inference-c896668707aa?source=collection_archive---------29-----------------------#2021-09-21">https://towardsdatascience.com/variational-inference-c896668707aa?source=collection_archive---------29-----------------------#2021-09-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e1d9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一种新的分析方法</h2></div></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/1f4c9aef85cab70e59fbd0a9f9828de7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RiF1-JIzkhQR-KpQ"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated"><a class="ae lc" href="https://unsplash.com/photos/fBMpqsBYc3A" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/fBMpqsBYc3A</a></p></figure><h1 id="58d3" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">什么是VI？</h1><p id="44f9" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">变分推理是一种解决最常见的贝叶斯问题的方法:给定一个观察到的数据，找到控制它生成的概率函数。虽然问题及其解决方案似乎很常见，但当VI首次出现时，它被认为是极具创新性的，因为它是针对Bayes问题的第一个分析性解决方案，而不是传统的采样方法。在这篇文章中，我将介绍虚拟仪器的早期出现，描述它的数学基础，并展示这个框架的前科学链接。</p><h1 id="b78e" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">问题是</h1><p id="c146" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">我们首先描述VI旨在以一致的方式解决的问题。我们正在处理统计数据，因此期待数据样本是合理的。让我们举个例子:</p><p id="d960" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">x，x，x..，x ⁰⁰..也就是我们<strong class="lx ir">观察到的数据。</strong>问题是一般性的，即样本可以是任何类型的数据:图像、语音话语、数字、比特或向量。</p><p id="430b" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">假设这个样本是由一个随机的机器生成的，这是非常简单的。作为研究人员，我们希望揭示这台机器的统计方式。在数学上，我们假设我们的观察数据是由控制样本X生成的隐藏变量Z，Z …生成的。因此，我们要找到生成这些Z的函数。即找到P(Z|X)。</p><p id="649e" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">下面是贝叶斯公式:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/aedd0808707b184b351be2b75e9e1d77.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/1*DKnp-dsL7gqd5YwuJIgbHQ.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者</p></figure><p id="6af6" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">LHS被称为<strong class="lx ir">后验分布。我们希望在观察到的数据上找到这个函数。我们能使用RHS吗？</strong></p><p id="9da1" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">提名者可以写成我们的先验知识和获得的可能性的产物，因此它是已知的。因此，我们的问题集中在分母上。在某些情况下，这是容易处理的。然而，考虑从K高斯GMM驱动的数据。我们的隐藏变量是高斯参数和它们的权重以及分配的聚类。分母中的概率如下:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/9df51fa49eecba3514868f2ab2b1e338.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*DmbHtxKG8k6-aNSAIkJeAA.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者</p></figure><p id="d235" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">很“优雅”不是吗？这种积分通常是难以处理的。人们需要一种方法来克服这一点。然而也有好消息:<strong class="lx ir"> P(X)独立于z。</strong>我们可以以不同的方式观察贝叶斯公式</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi my"><img src="../Images/4407da8e7c9563088dc4a3080ddc2572.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*HYkhfB1985UNSkJWoQkErQ.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者</p></figure><p id="236f" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">棘手的术语不再是障碍。我们仍然需要巧妙地处理RHS。</p><p id="6ebe" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">直到1999年，解决这类问题的常用方法是使用抽样方法，如大都会、T2、黑斯廷斯、T4、吉布斯、HMC。</p><p id="1880" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">这些算法是无偏差的，但却患有采样的常规“疾病”:它们被赋予了巨大的方差。</p><p id="b695" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">1999年，著名的迈克尔·乔丹退役了。同年，不太出名的迈克尔·乔丹发表了一篇论文<a class="ae lc" href="https://people.eecs.berkeley.edu/~jordan/papers/variational-intro.pdf" rel="noopener ugc nofollow" target="_blank"/>，其中他提出了一种解决贝叶斯问题的新方法。这个想法是开发一个依赖于分析方法的解决方案。通过预先决定分布族(这一步增加了过程的偏差),我们可以构建一个对采样障碍有弹性的解决方案。在2003年，随着Blei发表了关于主题抽取的论文<a class="ae lc" href="https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf" rel="noopener ugc nofollow" target="_blank"/>并将这种方法用于LDA过程，这种方法得到了极大的发展。然后他声称最佳的工作方式是“在等待Gibbs收敛的同时使用VI”。</p><p id="06e2" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">在接下来的几节课中，我将简要描述导致这种方法发展的数学步骤。</p><h2 id="7861" class="mz le iq bd lf na nb dn lj nc nd dp ln me ne nf lp mi ng nh lr mm ni nj lt nk bi translated">寻找最佳函数</h2><p id="1242" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">为了提供后验分布的解析近似，我们需要两个工具:</p><ul class=""><li id="c60b" class="nl nm iq lx b ly mr mb ms me nn mi no mm np mq nq nr ns nt bi translated">测量两个分布函数之间距离的度量</li><li id="9d61" class="nl nm iq lx b ly nu mb nv me nw mi nx mm ny mq nq nr ns nt bi translated">在这些函数的空间上寻找极值的分析工具。</li></ul><p id="94c9" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">上面的子句非常明显，我们将使用<strong class="lx ir"> KL-Divergence。</strong>寻找函数空间的极值需要使用<strong class="lx ir">变分法中的工具。</strong>该领域处理诸如通过分析表示寻找点之间的最短路径等问题。我相信读者可以猜到这就是“<strong class="lx ir">变分推理</strong>这个术语的由来。这个领域的一个基本工具是欧拉- <a class="ae lc" href="https://en.wikipedia.org/wiki/Euler%E2%80%93Lagrange_equation" rel="noopener ugc nofollow" target="_blank">拉格朗日</a> <a class="ae lc" href="https://mathworld.wolfram.com/Euler-LagrangeDifferentialEquation.htm" rel="noopener ugc nofollow" target="_blank">方程</a></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/82fc41b6e644e18bea6ab0876f6aaf59.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*bEN9Yuerl4o9-5yzrw8Jpg.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者</p></figure><p id="92bd" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">对于<strong class="lx ir"> F </strong>实值函数、<strong class="lx ir"> x </strong>自变量和<strong class="lx ir">u</strong>x的一个可微函数，我们可以找到使J最小的u如下:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/55c9ffb5d7c4d3aa1e15e83e42a89350.png" data-original-src="https://miro.medium.com/v2/resize:fit:464/format:webp/1*nU4utjVHTiYot8_4S6ZcBQ.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者</p></figure><p id="b5c0" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">现在，当我们有了这个工具，我们可以开始逼近后验函数。</p><p id="aa45" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">因为我们希望逼近P(Z|X ),所以我们搜索一个函数<strong class="lx ir"> Q </strong> (Z ),使其与真实后验概率的KL散度最小化。显然，当我们说“最小化Q”时，这意味着我们搜索优化参数<strong class="lx ir"> Q </strong>，因此我们必须定义我们将使用哪个分布族。在大多数应用任务中，我们用指数函数来表示Q，</p><p id="17d7" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">我们可以将P(Z|X)和<strong class="lx ir"> Q </strong> (z)之间的KL散度写成如下</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ob"><img src="../Images/c46e872a3e28b356943e1cc97b19f110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vGzKoArgqUeoNwNcTvAd7w.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者</p></figure><p id="e613" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">其中，LHS中的第二个术语表示为:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/5b2b510bbdaa649df21f59589a2d0738.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*ZQa2lDqD4eppGMDU3L1Piw.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者</p></figure><p id="0b2e" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">ELBO代表<strong class="lx ir">证据下限:</strong>最小化KL散度等价于最大化ELBO，因为P(X)独立于z。</p><p id="caef" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">读者中的物理学家可能会发现这个公式类似于<a class="ae lc" href="https://en.wikipedia.org/wiki/Helmholtz_free_energy" rel="noopener ugc nofollow" target="_blank"> <strong class="lx ir">亥姆霍兹自由能</strong> </a></p><h1 id="69e8" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">解决ELBO技术</h1><p id="a3df" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">为了最大化ELBO，我们需要一些假设和数值工具。</p><h2 id="befe" class="mz le iq bd lf na nb dn lj nc nd dp ln me ne nf lp mi ng nh lr mm ni nj lt nk bi translated">平均场定理</h2><p id="50b4" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">MFT的想法来自于磁自旋的<a class="ae lc" href="https://www.intechopen.com/chapters/71210" rel="noopener ugc nofollow" target="_blank">伊辛</a>T20】模型。这个模型过于严格，超出了本文的范围。然而，总的想法是，我们有一个观察到的序列r.v X，X …接收值1和-1。我们的目标是估计一个依赖于这些观察变量的函数。它由线性和成对乘积项组成。从可以看出:<strong class="lx ir">如果我们假设r.v不相关，我们可以使用它们的平均值来估计值。</strong></p><p id="1e5f" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">我们可以将这种想法移植到VI:考虑不相关的对，我们将假设独立性，例如，考虑从高斯分布中抽取的数据，我们的Z是对的均值和方差。我们将假设这些参数是独立的，因此<strong class="lx ir"> Q </strong>可以写成如下:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi od"><img src="../Images/c2851b881056a93b72eab43d685228cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*V639wyixzxqFdrzuWWp_Cg.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者</p></figure><p id="5cd0" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">将Q写成独立函数的乘积的想法简化了ELBO优化过程。</p><h2 id="39b8" class="mz le iq bd lf na nb dn lj nc nd dp ln me ne nf lp mi ng nh lr mm ni nj lt nk bi translated">数字食谱</h2><p id="b738" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">求解ELBO有两种常用方法:</p><p id="ee17" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">坐标上升VI(CAVI)——</strong>这个算法在<a class="ae lc" href="https://arxiv.org/pdf/1601.00670.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>和<a class="ae lc" href="https://brunomaga.github.io/Variational-Inference-GMM" rel="noopener ugc nofollow" target="_blank">这里</a>有详细描述。这个想法是在每一步j中计算ELBO的P部分，以所有不是j的Z为条件。(也就是说，每一步我们只更新一个Z，而其他的Z都是已知的)。每一步的解与P项的过对数的平均值的指数(ELBO中的互概率)成正比。</p><p id="47ec" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated"><strong class="lx ir">随机VI — </strong>这个<a class="ae lc" href="https://jmlr.org/papers/volume14/hoffman13a/hoffman13a.pdf" rel="noopener ugc nofollow" target="_blank">算法</a>使用随机优化(Robbins和Monro)来求解VI。它允许一些在CAVI不存在的批处理方式，从而使它更实用，并使用关于VI参数的ELBO的衍生物。</p><h1 id="da58" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">摘要</h1><p id="88b1" class="pw-post-body-paragraph lv lw iq lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">我们介绍了虚拟仪器的数学基础。有一些应用已经使用了这种算法，最著名的有:</p><ul class=""><li id="fdba" class="nl nm iq lx b ly mr mb ms me nn mi no mm np mq nq nr ns nt bi translated"><strong class="lx ir"> GMM </strong></li><li id="8f07" class="nl nm iq lx b ly nu mb nv me nw mi nx mm ny mq nq nr ns nt bi translated"><strong class="lx ir">主题建模</strong></li></ul><p id="8abf" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">当然，这是VAE发展过程中必不可少的一部分</p><p id="cf39" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">对动手项目感兴趣的读者可以在<a class="ae lc" href="http://edwardlib.org/" rel="noopener ugc nofollow" target="_blank"> Edward </a>，在<a class="ae lc" href="https://zhiyzuo.github.io/VI/#python-implementation" rel="noopener ugc nofollow" target="_blank"> his implementation </a>和<a class="ae lc" href="https://pyro.ai/" rel="noopener ugc nofollow" target="_blank"> Pyro </a>，以及<a class="ae lc" href="https://docs.pymc.io/" rel="noopener ugc nofollow" target="_blank"> PyM </a> C3中搜索。</p><p id="7005" class="pw-post-body-paragraph lv lw iq lx b ly mr jr ma mb ms ju md me mt mg mh mi mu mk ml mm mv mo mp mq ij bi translated">关于数字逻辑，已经有一些数字逻辑应用程序用于解决虚拟仪器问题的例子(例如，使用神经网络在数据上寻找虚拟仪器参数)，但是，我相信(这也是我写这篇文章的主要动机)贝叶斯推理和数字逻辑的结合可能会提供大量的问题、机会和数学难题。我认为由DL训练高阶交换子的不太常见的分布问题非常有趣。</p></div></div>    
</body>
</html>