<html>
<head>
<title>Text-based Causal Inference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于文本的因果推理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/text-based-causal-inference-86e640efb2af?source=collection_archive---------8-----------------------#2021-11-22">https://towardsdatascience.com/text-based-causal-inference-86e640efb2af?source=collection_archive---------8-----------------------#2021-11-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="93ec" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="ffe9" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">教程分析选民欺诈假情报估计因果关系的文本作为治疗和混杂因素</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/c8c35bdaaa30c4d1712e055036d05a93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*COrhYnaKMWGsGGX3qfaH2g.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">文本的因果图(W)为治疗(T)和混杂因素(Z)，结果为Y，协变量为C，其中T和Z相关。图片作者。</p></figure><p id="af47" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">科幻小说告诉我们，猖獗的虚假信息是一个社会陷入反乌托邦的前兆。有人可能会说，虚假信息破坏了民主的稳定(<a class="ae md" href="https://www.tandfonline.com/doi/full/10.1080/23738871.2018.1462395" rel="noopener ugc nofollow" target="_blank">摩根2018 </a>、<a class="ae md" href="https://www.routledge.com/Post-Truth-Fake-News-and-Democracy-Mapping-the-Politics-of-Falsehood/Farkas-Schou/p/book/9780367322175" rel="noopener ugc nofollow" target="_blank">法卡什&amp; Schou 2019 </a>)。显而易见，人们无视医学证据对公共健康有负面影响。例如，愿意忽视证据的人可能会选择拒绝接种疫苗，从而危及他人和自己的生命。人们应该谨慎，因为科学虚假信息无处不在，但当可信的新闻材料被假新闻的涌入所破坏时，很难追究人们的责任。一种更阴险的虚假信息形式是对一小部分人的现实的颠覆；一种集体歇斯底里，抓住了那些在另一个现实中认知脆弱的人。我说的是关于上次美国大选选民欺诈的超现实说法，当时特朗普的马屁精拒绝接受他输掉了大选。不可否认，围绕选民欺诈的假新闻对接下来的1月6日起义产生了煽动性的影响，这是一个尖叫着反乌托邦社会的悲剧事件。</p><p id="8836" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">政治哲学家汉娜·阿伦特(Hannah Arendt)声称，人们有必要参与政治，将其作为美好生活的一部分。在《人类的状况》中，阿伦特说，仅仅和你所爱的人一起工作、共度时光是不够的，你还必须参与政治生活(<a class="ae md" href="https://en.wikipedia.org/wiki/The_Human_Condition" rel="noopener ugc nofollow" target="_blank">阿伦特，1958 </a>)。有许多美国人追随这种风气，参与政治；认为这是他们作为公民的权利和责任。不幸的是，他们中的一些人容易受到错误思想的影响，成为像<a class="ae md" href="https://en.wikipedia.org/wiki/QAnon" rel="noopener ugc nofollow" target="_blank">卡农</a>这样的离奇阴谋的牺牲品。在本克勒、法里斯和罗伯茨的“<a class="ae md" href="https://oxford.universitypressscholarship.com/view/10.1093/oso/9780190923624.001.0001/oso-9780190923624" rel="noopener ugc nofollow" target="_blank">网络宣传</a>”中，作者声称宣传反馈循环部分是由人们避免认知不适的愿望推动的。也就是说，人们会寻找强化他们世界观的信息，而忽视或轻视相反的证据。从流行病学的角度来看，假新闻充当了疾病的传播媒介，传播危险的虚假信息，让公共领域充斥着相互矛盾的说法，让人几乎无法辨别真相。</p><p id="07cb" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">但是政治和数据科学有什么关系呢？作为一名对虚假信息感兴趣的研究人员，我自然会寻求使用数据科学工具来回答社会和政治问题。眼前的利益，是理解社会媒体和假新闻之间的关系。有人声称，受冲击价值和向上投票驱动的社交媒体的毒性对假新闻的传播产生了影响。更具体地说，看看Twitter，我质疑假新闻是否对retweet count的结果有因果影响。分享假新闻会导致更高的转发数吗？这篇教程是我试图回答这个问题的结果，也是对上一篇关于使用NLP进行因果推理的文章的后续。</p><p id="ebcb" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这篇文章中，为了使用文本来估计因果关系，我使用了由<a class="ae md" href="https://tech.cornell.edu/jacobs-technion-cornell-institute/" rel="noopener ugc nofollow" target="_blank">Jacobs Technion-Cornell Institute</a>管理的Twitter <a class="ae md" href="https://github.com/sTechLab/VoterFraud2020" rel="noopener ugc nofollow" target="_blank"> VoterFraud2020 </a>数据集。该数据集由研究人员公开提供，并在<a class="ae md" href="https://voterfraud2020.io/" rel="noopener ugc nofollow" target="_blank">仪表板</a>上共享，原始论文归功于<a class="ae md" href="https://arxiv.org/abs/2101.08210" rel="noopener ugc nofollow" target="_blank">阿比洛夫等人(2021) </a>。我从讨论数据和描述初步分析开始。接下来，我将介绍因果文本算法，并对语言属性的因果效应进行相应的研究(<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant，2021 </a>)。此外，我还介绍了使用观察数据进行因果推断的准则，并详细说明了因果文本算法的估计过程。接下来，我列出了因果实验的框架，这直接导致了如何设置和使用因果文本工具的教程(我从最初的repo派生和改编而来)。我还介绍了用因果文本算法解决提出的因果问题所需的步骤。最后，我简要讨论了结果并考虑了可能的扩展。</p><h2 id="bef0" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated"><strong class="ak">数据描述</strong></h2><p id="2c61" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated">开源的<a class="ae md" href="https://voterfraud2020.io/" rel="noopener ugc nofollow" target="_blank">康奈尔VoterFraud2020 Twitter数据集</a>包含来自260万用户的760万条推文和2560万条转发，都与2020年10月23日至2020年12月16日之间的选民欺诈指控有关。由于Twitter的隐私政策，只有tweet ids和用户id是共享的；然而，数据集的<a class="ae md" href="https://github.com/sTechLab/VoterFraud2020" rel="noopener ugc nofollow" target="_blank"> GitHub存储库</a>包含了合成数据的脚本。在这个实验中，我只关注了760万条原始推文。一旦收集了tweet，就需要做一些预处理来清理tweet文本并提取URL。这些网址都是Twitter的缩写格式“t.co ”,因此必须被解析。为了更好地了解解析后的网址的受欢迎程度，每个网址都被赋予了一个来自亚马逊网站流量统计分析的Alexa排名。</p><p id="7ff4" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">媒体云是由哈佛大学伯克曼克莱恩互联网中心开发的开源媒体内容分析工具。该平台有<a class="ae md" href="https://sources.mediacloud.org/#/home" rel="noopener ugc nofollow" target="_blank">为美国媒体源策划的源列表</a>，按政治派别划分，涵盖<a class="ae md" href="https://sources.mediacloud.org/#/collections/200363061" rel="noopener ugc nofollow" target="_blank">左</a>、<a class="ae md" href="https://sources.mediacloud.org/#/collections/200363048" rel="noopener ugc nofollow" target="_blank">中左</a>、<a class="ae md" href="https://sources.mediacloud.org/#/collections/200363050" rel="noopener ugc nofollow" target="_blank">中右</a>、<a class="ae md" href="https://sources.mediacloud.org/#/collections/200363062" rel="noopener ugc nofollow" target="_blank">中右</a>和<a class="ae md" href="https://sources.mediacloud.org/#/collections/200363049" rel="noopener ugc nofollow" target="_blank">右</a>。使用这些美国新闻源列表，我交叉引用了从选民欺诈推特数据集中解析的URL。这是为专门链接到新闻文章的URL选择的。媒体云对新闻媒体有强大的调查能力，所以我能够使用媒体云查询来确定孤立文章的媒体内链接份额计数和脸书份额计数。除了这篇文章元数据，我还搜集了当时还在网上的所有新闻文章的全文。</p><p id="1cbf" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这些步骤给了我一个共享新闻文章的原始推文的组合数据集，其中包含新闻文章的全文、文章元数据、推文元数据和Alexa对URL的排名。需要说明的是，760万条推文的数据集被削减了，这样每条推文都有相应的新闻文章。收集文章全文的目的是使用<a class="ae md" href="https://medium.com/me/stories/public" rel="noopener">潜在狄利克雷分配(LDA) </a>进行主题建模，以查看是否有可能隔离假新闻文章。此外，260万用户的VoterFraud2020数据集还包含由社区检测算法确定的每个用户的社区或聚类(例如<a class="ae md" href="https://en.wikipedia.org/wiki/Louvain_method" rel="noopener ugc nofollow" target="_blank"> Louvain方法</a>)。考虑到产生的tweet-article数据集的多数据流和丰富性，有必要运行一些初步分析，这将在接下来介绍。</p><h2 id="f8fe" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated"><strong class="ak">初步分析</strong></h2><p id="1bc6" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated">首先，考虑到推文本身，推文的文本可能对识别假新闻有价值。因此，我开始用<a class="ae md" rel="noopener" target="_blank" href="/topic-modeling-with-latent-dirichlet-allocation-e7ff75290f8"> LDA </a>对tweet文本进行主题建模，以获得Twitter话语内容的总体感觉。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nb"><img src="../Images/41ea4d2857f1f6b837d14b762eb93f0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IclRSagb8l6jATyDNZuKmQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">2020年10月23日至12月16日期间精选VoterFraud2020推文的话题间距离图。图片作者。</p></figure><p id="4f14" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">LDA模型的结果强调了几个主题，这些主题明确涉及选民欺诈假信息对话的各个方面。例如，一个与其他主题不同的值得注意的主题是关于alt-right标签“# stopthesteal”。同样值得注意的是同样孤立的《华尔街日报》和《纽约时报》的事实核查话题。有趣的是，声称有欺诈证据的推文与福克斯新闻频道等右翼新闻媒体的推文有很大重叠。总体而言，有几个虚假信息的线索，从选票收获，关于投票软件的阴谋，断言欺诈的宣誓书，以及军方参与的谣言。</p><p id="57ca" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">使用社区检测算法对用户社区的分析提供了用户数量不同的5个不同社区，如下所示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/b3923ce0b2180b9378b0531e65c6e25e.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*JoCnI61bhSN9i6pcnYd8-g.jpeg"/></div></figure><p id="ece7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">放大集团是那些推动选民欺诈议程的人，外国集团代表着潜在的外国影响，相比之下微不足道。</p><p id="07ae" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">关注假新闻的传播，这五个社区在分享新闻文章的网址时表现不同。媒体云元数据包含媒体链接计数，该计数代表一篇文章被其他媒体源链接的次数。一篇高度内链接的文章可以被认为是更主流的。下图显示了三个最大社区的媒体链接数随时间变化的趋势。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nd"><img src="../Images/876f591490ea3eb6cb81b15c8eb6fb97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rKxg1_wKAcsr1aq2ulRV4Q.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">2020年10月23日至12月16日分享的关于选民欺诈的新闻文章的媒体内链计数。图片作者。</p></figure><p id="b225" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">上述时间序列表明，与两个放大器社区相比，中间偏左的社区倾向于分享更“主流”的文章。尽管中间偏左的社区更有可能分享主流文章，但它们并没有获得很高的转发量。这显示在下面按社区统计的平均转发次数的时间序列中。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nd"><img src="../Images/9a354e9de2ce685954ab05d04b6d2a4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zrRgqlOrRKH56tYP-DbX8g.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">一段时间内社区共享的URL的平均转发次数。图片作者。</p></figure><p id="392f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">事实上，它是第三大社区“Amplifiers_1 ”,尽管只代表11.5%的用户，却拥有最高的共享URL转发数。这里的问题是，即使中左翼试图核实那些传播选民欺诈假新闻的人，他们在Twitter上也没有得到太多的关注。同样令人吃惊的是，尽管不共享主流媒体，但相对较小的“放大器1”小组在传播信息方面具有很大的影响力。</p><p id="3426" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">人们普遍认为假新闻经常出现在边缘网站上，远离主流。在计算了每个新闻文章url的Alexa排名或受欢迎程度后，就有可能查看网站的“fringiness”与转发这些边缘网站的社区之间的关系。在下面的热图中，Alexa排名或“边缘分数”根据转发次数进行加权，并根据主题绘制了社区分布。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ne"><img src="../Images/ae0769c3895af12d5d746387551f47d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lqElpB4p3D_QZvuW2hSixA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">转发加权Alexa排名(边缘分数)热图，显示了边缘分数主题的社区分布。图片作者。</p></figure><p id="da10" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这里，我们可以看到“Amplifier_1”组不仅获得了最大的转发量份额，还分享了最多的边缘网站。由于我们对假新闻的处理是否对转发计数的结果有因果影响这一因果问题感兴趣，因此边缘分数和假新闻文章之间的关系也很有趣。</p><p id="bec7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">此时，有必要查看新闻文章的实际文本，以更好地帮助对假新闻进行分类。使用LDA对新闻文章进行主题建模的过程导致七个主题中的五个是明显的假新闻文章。这使得每个url都可以被贴上标签，因此每条推文都可以被贴上假新闻的标签。这个NLP衍生的标签被用作稍后描述的因果实验的设置中的代理标签。此外，为了测试因果文本算法的有效性，我还标记了100个最受欢迎的假新闻网址。这个标签覆盖了18%的推文-文章数据集，给了我大约28K个推文-文章对，它们既有通过主题建模的代理标签，也有通过手动标注的真实标签。具有代理治疗标签和真实治疗标签，允许对该任务的因果文本算法进行基准测试。在接下来的三节中，我将讨论因果文本算法的细节，并介绍一些理解该工具所需的因果概念。</p><h2 id="0f44" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated"><strong class="ak">因果文本算法</strong></h2><p id="6f3f" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated">本教程中使用的因果文本算法是由<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人(2021 </a>)创建的，它在一篇题为“语言属性的因果效应”的论文中被称为“文本原因”。这个因果算法使用了另一个工具——CausalBERT，它最初是由<a class="ae md" href="http://proceedings.mlr.press/v124/veitch20a.html" rel="noopener ugc nofollow" target="_blank"> Veitch等人(2020) </a>设计的。CausalBERT被开发用于产生因果推理的文本嵌入；本质上，作者设计了一种方法，在测试因果关系时，使用人工智能语言模型来调整文本。</p><p id="bc17" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因果文本算法有两个组成部分，第一，它利用远程监督来提高代理标签的质量，第二，使用CausalBERT来调整文本。Pryzant等人试图将作者意图的因果效应形式化，同时建立必要的假设以从观察数据中识别因果效应。这项工作的另一个贡献是，他们提出了一个估计量，当调整文本时，偏差是有界的。</p><p id="1ac3" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">VoterFraud2020数据集代表观察数据，其中推文是在没有干预的情况下获得的。因为，因果效应的测量需要满足其他条件不变的假设，即所有协变量保持固定，我们必须对干预进行推理。<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人</a>描述了从观测数据中估计因果效应的两个挑战。首先，有必要“通过具体说明与之相对应的假设干预，将利息的因果关系正式化。”(<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人，2021年</a>)。这一挑战可以通过想象对文本作者的干预来克服，他们被告知使用不同的语言属性。</p><p id="7e85" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因果推理的第二个挑战是识别，我们感兴趣的实际语言属性只能通过嘈杂的代理(如主题标签)来衡量。因此，该研究还建立了从嘈杂的代理标签中恢复语言属性的真实因果效应所需的假设。因果文本算法的创建者调整文本中的混杂，并证明这一过程限制了因果估计的偏差。在我之前关于因果关系和NLP的文章中，我详细讨论了文本混淆的问题。</p><h2 id="6b8c" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated"><strong class="ak">用观察数据进行因果推断</strong></h2><p id="31cb" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated">在用观察数据讨论因果推断的时候，有必要说一下平均处理效应(ATE)。如下图所示，ATE是真实世界(T=1)和反事实世界(T=0)之间潜在结果的差异。我之前在两篇文章中以直观的方式描述了潜在结果框架:<a class="ae md" rel="noopener" target="_blank" href="/causal-inference-using-natural-language-processing-da0e222b84b">使用NLP的因果推断</a>和<a class="ae md" rel="noopener" target="_blank" href="/causal-machine-learning-for-econometrics-causal-forests-5ab3aec825a7">计量经济学的因果推理:因果森林</a>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nf"><img src="../Images/1c97992c65f172ab007368d79c7e5051.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LlTY65eCb2UEQH7rJ_AAUw.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">平均治疗效果(ATE)是真实世界和反事实世界之间潜在结果的差异。图片作者。</p></figure><p id="4c10" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然而，如上所述，我们也关心混杂。为了处理混杂因素(W <em class="ng"> ᵢ </em>)，后门调整公式(Pearl，2009)可用于根据所有观察到的变量重写ate:t<em class="ng">ᵢ</em>用于治疗，Y <em class="ng"> ᵢ </em>用于结果。下图显示了这种混杂关系，混杂因素W <em class="ng"> ᵢ </em>对治疗和结果都有影响。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/4d00f6f452ca5fb19c5787bd567b7557.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*aBdiHz-DSv6aHIqmJ0cT3Q.jpeg"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">混杂Wi对治疗Ti和结果Yi都有影响。来源:<a class="ae md" href="http://proceedings.mlr.press/v124/veitch20a.html" rel="noopener ugc nofollow" target="_blank">韦奇等人(2020) </a>。</p></figure><p id="be2e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">W <em class="ng"> ᵢ </em>的混杂效应导致虚假关联，这也可以被称为“诱导非因果关联的开放后门路径”(<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人，2021 </a>)。我之前在<a class="ae md" rel="noopener" target="_blank" href="/improving-nlp-with-causality-2dec1fa90b74">一篇关于用因果关系改进NLP模型的文章</a>中讨论过伪相关性和后门路径。ATE的后门调整公式如下图所示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ni"><img src="../Images/72ecb5cda72d5cc9a0e7066c0ca22753.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rHlPHRAusSECbMxbc6l9gQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">如何用借壳调整公式计算平均治疗效果(ate)？改编自<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人(2021 </a>)。</p></figure><p id="abb0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果我们假设混杂因素W <em class="ng"> ᵢ </em>是离散的，那么数据可以分组为w的值，可以计算潜在结果的平均差异，最后，我们取w组的平均值</p><p id="b101" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Pryzant等人(2021年)提出了以下文本和结果的因果模型:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nj"><img src="../Images/6b4a8cf8c695642818b7043f5fa359ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kk7fWlPOdThfbJ-QqeFV-A.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者的意图可能与读者的观点不同，因为读者不知道作者的意图。来源:<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人(2021 </a>)。</p></figure><p id="1c98" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">文本由W表示，它具有语言属性T(作为处理)和其他属性Z(作为协变量)。这里，Z可以是文本的主题、情感、长度或其他性质。这一因果模型是建立在文学观点上的，即语言受制于两个视角:作者意图的文本和读者解释的文本。读者的第二视角由<em class="ng"> T_tilde </em>和<em class="ng"> Z_tilde </em>示出，其中<em class="ng"> T_tilde </em>表示读者所接收的处理，而<em class="ng"> Z_tilde </em>表示读者所感知的文本W的其他质量。结果Y受波浪号变量的影响，而不是直接受Z和T的影响。<em class="ng"> T_hat </em>变量表示从文本W中导出的代理标签，它可以是主题标签。</p><p id="6f3d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">假设干预的处理，是要求作者使用(或不使用)一个语言属性T，其中T是一个二元选择。不可能使用观察数据来捕捉Z的未观察到的语言特征，因为它与t相关。但是，可以估计读者感知的语言属性，这由波浪线变量表示。读者视角的比率定义为:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nk"><img src="../Images/4ccd832e555099b69164efc5c1b5c66b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d07yiMw4zyxLTybiLVlWXw.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">读者感知的平均治疗效果，<em class="nl"> T_tilde </em>替代T .改编自<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人(2021 </a>)。</p></figure><p id="f378" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了计算兴趣的因果效应，作者视角的ate，<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人(2021 </a>)开发了一个定理(定理1)，该定理利用了从<em class="ng"> T_tilde </em>计算的读者视角的ATE。他们将<em class="ng"> Z_tilde </em>定义为文本W的函数，如下图所示，其中给定W或同时给定<em class="ng"> T_tilde </em>和<em class="ng"> Z_tilde </em>，Y的潜在结果是等价的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nm"><img src="../Images/452b24af94bbb1f93d845f672f3092f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rY-q_rcD5QIbzbGZHRgNKg.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">定理1，混杂信息，<em class="nl"> Z_tilde </em>是文本的函数，w .改编自<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant et al. (2021 </a>)。</p></figure><p id="f54e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如此定义了<em class="ng"> Z_tilde </em>之后，可以将ATEᵣₑₐ定义为以下等式:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nn"><img src="../Images/e5c3e33efa2a3cefa56c1d53cf0d8dfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*534tYs6HNZ2qGUvxk5N3WQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">读者视角的ATE可以用<em class="nl"> T_tilde </em>和<em class="nl"> Z_tilde </em>来写。改编自<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人(2021 </a>)。</p></figure><p id="3573" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">据说ATEᵣₑₐ等于ATE𝓌ᵣᵢ，文本w拆分成读者用来感知波浪号变量的信息。<em class="ng"> Z_tilde </em>代表混杂属性，因为它影响结果并且与<em class="ng"> T_tilde </em>相关。明确地说，这个定理只在某些假设下成立，其中有三个假设。首先，未被观察到的混淆(w)阻塞了<em class="ng"> T_tilde </em>和结果y之间的后门路径。其次，我们需要假设T = <em class="ng"> T_tilde </em>，也就是说，存在意图(ATE𝓌ᵣᵢ)和感知(ATEᵣₑₐ).)的一致最后一个假设是阳性(或重叠)假设，即治疗的概率在0和1之间。在<a class="ae md" rel="noopener" target="_blank" href="/improving-nlp-with-causality-2dec1fa90b74">另一篇关于因果关系的文章</a>中，我提供了对积极性假设的直观解释。</p><p id="dd83" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">更复杂的是，除了不能直接观察作者的意图之外，我们不能观察读者的感知；因此，需要代理。对于<em class="ng"> T_tilde </em>，可以使用代理<em class="ng"> T_hat </em>来计算利息的因果效应，其中在前面的等式中用<em class="ng"> T_hat </em>代替<em class="ng"> T_tilde </em>来计算估计需求(ATEₚᵣₒₓᵧ).</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi no"><img src="../Images/f3c10a912fb44ca9f4ff5d5b956c839a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D1vubJkmYmjuS0fgI_waMA.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">用<em class="nl"> T_hat </em>替换<em class="nl"> T_tilde </em>允许计算代理ATE。改编自<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人(2021 </a>)。</p></figure><p id="065b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">此时，有必要调整混杂的估计要求，换句话说，调整<em class="ng"> Z_tilde </em>的ATEₚᵣₒₓᵧ。这可以通过使用CausalBERT，一个预先训练好的语言模型来测量。这种方法的另一个优点是，由代理标签引起的偏差是有限的，因此它是良性的——“它只能降低效应的幅度，但不会改变符号。”。Pryzant等人(2021 )将此称为定理2，并声明“更准确的代理将产生更低的估计偏差。”。</p><h2 id="4823" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated"><strong class="ak">因果估计</strong></h2><p id="5a1b" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated">既然我们已经讨论了如何使用观察数据进行文本因果推断，那么实际的部分就是估计过程。因果文本算法有两个重要特征:改进代理标签和调整文本。提高代理标签准确性的方法是基于偏差是有限的这一事实。使用远程监督来改进代理标签，这是受对<a class="ae md" href="https://arxiv.org/abs/1606.02820" rel="noopener ugc nofollow" target="_blank">词汇归纳</a>和标签传播的工作的启发。目标是通过训练分类器来预测代理标签，然后使用该分类器来重新标记标记为T=0但看起来像T=1的例子，从而提高代理标签的召回率。本质上，如果需要，代理标签被重新标记。</p><p id="36df" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因果文本算法的第二个特征是，它使用预先训练的语言模型针对文本进行调整。通过使用文本(w)、改进的代理标签(<em class="ng"> T_hat* </em>)和结果(y)来测量ATEₚᵣₒₓᵧ。这依赖于定理1，如前所述，它显示了如何调整文本的混淆部分。<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人(2021 </a>)使用一个<a class="ae md" href="https://arxiv.org/abs/1910.01108" rel="noopener ugc nofollow" target="_blank"> DistilBERT </a>模型来产生一个带有嵌入的文本表示，然后选择对应于一个预先考虑的分类标记【CLS】的向量。Pryzant等人使用Huggingface transformers实现了具有66M个参数的DistilBERT，而用于文本调整的向量M <em class="ng"> ₜ </em>，增加了3080个参数。然后优化该模型，使得表示<strong class="lj jd"> b </strong> (W)直接逼近混杂信息<em class="ng"> Z_tilde </em>。估计量Q是为预期的条件结果而训练的，如下图所示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi np"><img src="../Images/1d60e5e6bb8fbaca215b696c927640ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eMwtYXgt6dxfxnHa8jG4Pg.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">估计量<em class="nl"> Q_hat </em>依赖处理，<em class="nl"> t </em>，模型表示<strong class="bd nq"> b </strong> (W)，协变量，c .改编自<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant et al. (2021 </a>)。</p></figure><p id="d100" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这个等式中，当给定代理<em class="ng"> T_hat </em>时，估计量Q被显示为等价于Y的期望条件结果，代理估计量本身不仅基于处理<em class="ng"> t </em>，而且基于模型表示<em class="ng"> Z_tilde </em> ( <strong class="lj jd"> b </strong> (W))和协变量c。 相当于一个偏差项(<em class="ng"> b) </em>和两个向量(Mᵇₜ <em class="ng">、</em> Mᶜₜ)的参数化和，这依赖于表示<strong class="lj jd"> b </strong> (W) <em class="ng"> </em>和一个<strong class="lj jd"> c </strong>向量。 <strong class="lj jd"> c </strong>向量是协变量c的<a class="ae md" href="https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f" rel="noopener ugc nofollow" target="_blank">一键编码</a>向量，两个Mₜ是为治疗的值<em class="ng"> t </em>学习的。该模型的培训目标是优化:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nr"><img src="../Images/13fbbc4fa0eae7f2db6cfb6fabe093db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MKG21AjstucAJzlkttILHw.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">用于优化因果文本模型的训练目标。来源:<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人(2021 </a>)</p></figure><p id="7db6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这个方程中，<em class="ng"> 𝛩 </em>是模型的所有参数，而l(。)是交叉熵损失，其与估计器<em class="ng"> Q_hat，</em>本身一起使用，基于m个<em class="ng"> ₜ </em>向量。原始的伯特掩蔽语言建模目标(MLM)被表示为R(.)，𝛼超参数是对传销目标的惩罚。利用<em class="ng"> Q_hat </em>估计器，在改进的代理标签等同于<em class="ng"> t </em>的例子中，参数Mᵇₜ和Mᶜₜ被更新。</p><p id="fc71" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下图显示了这种设置，其中W代表文本，C代表协变量，CausalBERT模型代表文本，因此可以预测y的潜在结果。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ns"><img src="../Images/148de4db43f9c5be39c1eb5b659e7abd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4ZUxBIoez3YKbLqCxkpQMQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">使用CausalBERT进行文本调整，使用BERT单词嵌入来预测Y的潜在结果。改编自<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人(2021 </a>)。</p></figure><p id="bd26" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">总之，使用完全因果文本算法进行估计需要改进的代理标签，以及文本和结果的因果模型，该模型提取并调整<em class="ng"> Z_tilde </em>的混淆。当估计因果效应时，该算法还允许包含协变量<em class="ng"> C </em>。如上图所示，向量<strong class="lj jd"> c </strong>和模型表示<strong class="lj jd"> b </strong> ( <em class="ng"> W </em>)用于预测Y的潜在结果，同时使用来自<em class="ng"> T_hat*、</em>代理标签的信息。表示法<strong class="lj jd"> b </strong> ( <em class="ng"> W </em>)直接逼近混杂信息(<em class="ng"> Z_tilde </em>)，这允许它针对文本进行调整。</p><p id="e87c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">一旦估算器<em class="ng"> Q_hat </em>被拟合，就可以计算戴帽子的ATEₚᵣₒₓᵧ，如下式所示:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nt"><img src="../Images/cd2ba11658f07093aa7c1538cd280fa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OMoxlJ69_bciTAqenVKDeQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">戴帽子的ATEₚᵣₒₓᵧ是用代理估计量<em class="nl"> Q_hat来估计的。</em>改编自<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人(2021 </a>)。</p></figure><p id="215e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">用这种方法导出的ATE可用于确定读者视角的因果效应，其本身被假设为等同于作者视角的因果效应。这种ATE的准确性取决于代理的准确性以及CausalBERT对文本的调整程度。下一节描述了用于测试假新闻对转发量的因果影响的实验框架。</p><h2 id="02f2" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated"><strong class="ak">实验框架</strong></h2><p id="4ea9" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated">因果问题是假新闻对转发数是否有因果影响。几年前，科学杂志上一项非常受欢迎的研究声称，在社交媒体上，假新闻比真实新闻传播得更快。然而，这项研究并不依赖于因果分析。这些结果有可能是基于混杂因素和转发数之间的虚假相关性。例如，用户所属的社区没有被调查，新闻网站的受欢迎程度也没有被调查。一些社区可能更容易传播假新闻，人们可能更愿意分享热门新闻网站。此外，语言是复杂的，推文的文本可能会造成混淆，所以我们需要控制推文的主题、写作风格、语气和长度。因此，设计一项因果研究是有价值的，在这项研究中，可能的混杂因素得到了控制，推文本身也根据混杂因素进行了调整。</p><p id="981a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如前所述，从观测数据中估计因果效应有两个挑战:干预和识别。首先，我们需要对作者意图的假设干预进行推理，这样他们会使用(或不使用)特定的语言属性。有必要将假新闻的分享视为一种语言属性，代表作者的意图，然后它可以是一种可以干预的治疗方法。更简单地说，我们将链接到假新闻的url的共享视为语言属性，其中的干预将是告诉用户共享真实的新闻文章(T=0)而不是假新闻文章(T=1)。在干预这种处理时，推文的其余质量必须保持不变。我们将这些其他文本质量称为Z，因此Z代表潜在的混淆因素，如主题、风格、语气或长度。推文文本将被称为W(或简称为“文本”)，其他协变量如用户社区或Alexa排名将被表示为c。该设置如下图所示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/c8c35bdaaa30c4d1712e055036d05a93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*COrhYnaKMWGsGGX3qfaH2g.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">实验装置的因果图。w是推文文本，T是代理主题标签，Z是其他混淆性质，Y是转发计数，C代表社区或Alexa排名。图片作者。</p></figure><p id="4c2b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">代理处理是通过用LDA对文章进行主题建模来确定的假新闻标签。因为数据集有假新闻文章的金色标签，所以有两个处理变量(<em class="ng"> T_true </em>和<em class="ng"> T_proxy </em>)，这样就有可能将<em class="ng"> T_proxy </em>与<em class="ng"> T_true </em>进行基准测试。最后，结果Y是转发次数。对于第一个测试，C变量是分类的，其中一个数字用于表示用户社区。除文本外，所有其他变量都是二进制数字指示器(0或1)。对于第二个测试，Alexa排名被用作协变量C，我们专门查看单个社区:“Amplifiers_1”。在这个测试中，每个url的Alexa排名通过分位数的宁滨值转化为分类变量。下一节详细介绍了我如何在本教程中采用因果文本算法，并解释了如何解释结果。</p><h2 id="2c68" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated"><strong class="ak">估计因果关系</strong></h2><p id="3f46" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated"><a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人(2021 </a>)在GitHub上分享了<a class="ae md" href="https://github.com/rpryzant/causal-text" rel="noopener ugc nofollow" target="_blank">因果文本算法</a>，该算法利用了CausalBERT 的<a class="ae md" href="https://github.com/rpryzant/causal-bert-pytorch" rel="noopener ugc nofollow" target="_blank"> Pytorch实现。对于本教程，有必要修改原来的因果文本包，因为它是专门为介绍性论文中描述的因果实验定制的。此外，它似乎不是由作者维护(更新)的，所以我必须更新需求。我还简化了输出，并删除了本教程不需要的无关模拟部分。其余的改动很小，是在调试过程中做的。总的来说，我对原始算法做了很少的修改，我的修改可以在GitHub </a>上访问<a class="ae md" href="https://github.com/haayanau/causal-text" rel="noopener ugc nofollow" target="_blank">。如果你觉得这种算法有用，请访问star Pryzant等人关于</a><a class="ae md" href="https://github.com/rpryzant/causal-text" rel="noopener ugc nofollow" target="_blank">因果文本算法</a>的原始知识库。</p><p id="5ed3" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">该工具从命令行运行，我建议用GPU运行它，以利用深度学习的速度。在这里，我解释如何设置Colab(利用免费的GPU实例)并运行因果文本算法。首先，数据需要有正确的格式。该工具接受“.”。tsv "文件，有五列，用于五个变量:<em class="ng"> T_proxy </em>，<em class="ng"> T_true </em>，C，Y，text。协变量C必须是分类的，用简单的整数表示。<em class="ng"> T_proxy </em>，<em class="ng"> T_true </em>和outcome，Y变量必须是二进制数字指示器(0或1)。“文本”就是tweet文本。适应的因果文本算法产生七个不同的ATE结果值。</p><p id="0867" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">使用<em class="ng"> T_true </em>标签，因果文本算法计算“Oracle”ATE值；这可以被认为是作为基线的真实ATE。接下来，计算“未调整的”ATE值作为附加基线，其中ATE是以<em class="ng"> T_hat </em>为条件的结果的预期差异，不考虑协变量。接下来的两个值是“T-boost”ATE值，其中T-boost指的是通过改善代理标签来加强治疗。代理标签由两个不同的分类器以两种方式改进。一个分类器只对积极的和未标记的数据起作用，而另一个是直接的回归，特别是Sci-kit Learn的随机梯度下降分类器。下一个ATE值是文本已经调整的值，这是“W调整”值。最后两个ATE值将T-boosting与文本调整相结合，每个分类器类型一个ATE值。这最后两个值代表了由<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人(2021 </a>)设计的完整“文本原因”算法。</p><p id="2f10" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">第一步是在Colab中安装所需的包。这是通过以下单行代码完成的:</p><pre class="ks kt ku kv gt nu nv nw nx aw ny bi"><span id="542f" class="me mf it nv b gy nz oa l ob oc">!pip install sklearn transformers tensorflow</span></pre><p id="6dd0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">接下来，我们检查GPU是否可用。</p><pre class="ks kt ku kv gt nu nv nw nx aw ny bi"><span id="9b6c" class="me mf it nv b gy nz oa l ob oc">import torch</span><span id="8829" class="me mf it nv b gy od oa l ob oc">if torch.cuda.is_available():<br/>   device = torch.device("cuda")</span><span id="1f65" class="me mf it nv b gy od oa l ob oc">   print('There are %d GPU(s) available.' %       torch.cuda.device_count())<br/>   print('We will use the GPU:', torch.cuda.get_device_name(0))<br/>   !nvidia-smi</span><span id="8533" class="me mf it nv b gy od oa l ob oc">else:</span><span id="736e" class="me mf it nv b gy od oa l ob oc">   print('No GPU available, using the CPU instead.')<br/>   device = torch.device("cpu")</span></pre><p id="5ae1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">的”。tsv”文件应与数据一起保存在Google Drive中，以便于访问。我们只需安装驱动器就可以访问文件。</p><pre class="ks kt ku kv gt nu nv nw nx aw ny bi"><span id="e280" class="me mf it nv b gy nz oa l ob oc">from google.colab import drive<br/>drive.mount('/content/gdrive')</span></pre><p id="c8c9" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然后，我们导航到保存数据的文件夹。</p><pre class="ks kt ku kv gt nu nv nw nx aw ny bi"><span id="0676" class="me mf it nv b gy nz oa l ob oc">%cd gdrive/My Drive/my_folder</span></pre><p id="0cf9" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">接下来，我们从GitHub克隆了因果文本算法的改编repo。</p><pre class="ks kt ku kv gt nu nv nw nx aw ny bi"><span id="e675" class="me mf it nv b gy nz oa l ob oc">!git clone https://github.com/haayanau/causal-text.git</span></pre><p id="6564" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">克隆因果文本包后，需要导航到主脚本所在的目录。</p><pre class="ks kt ku kv gt nu nv nw nx aw ny bi"><span id="8b9d" class="me mf it nv b gy nz oa l ob oc">%cd causal-text/src</span></pre><p id="a281" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">运行算法非常简单，运行下面的命令，路径指向"。tsv”文件。“run_cb”参数意味着将使用CausalBERT来调整文本。每个模型被训练3个时期。</p><pre class="ks kt ku kv gt nu nv nw nx aw ny bi"><span id="8cf5" class="me mf it nv b gy nz oa l ob oc">!python main.py --run_cb --data /content/gdrive/MyDrive/my_folder/my_data.tsv</span></pre><p id="1740" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如前所述，该命令产生七种类型的ATE值。<a class="ae md" href="https://arxiv.org/abs/2010.12919" rel="noopener ugc nofollow" target="_blank"> Pryzant等人</a> (2021)提醒“当代理准确度低于80%时，ATE估计会失去保真度”。他们还声称，对文本的混淆部分进行调整是至关重要的，并且在没有对文本进行调整的情况下，考虑C的估计可能比未调整的估计更差。下一节简要讨论两个实验的结果，并建议一些扩展。</p><p id="6cb2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">结果和扩展</strong></p><p id="ca11" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对于第一个测试，我们正在研究转发计数(Y)上假新闻的比率(T)，用户社区(C)和推文文本是混杂因素。有15，468个观察值，结果如下所示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/82a424877a8bd3c17159314dcb24f4e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*pADXE28N6lvUD4OTbb0POw.jpeg"/></div></figure><p id="1b2c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">真实(预测)值表明实际上没有因果关系，这与假新闻比真实新闻传播更快的普遍预期相反，并会获得更高的转发数。未调整的ate值也没有显示因果效应，尽管没有考虑协变量c。就匹配真实ATE值而言，使用CausalBERT调整文本的(W adjust) ATE最接近。来自完整的“文本原因”算法(针对文本进行调整并改进标注)的值都不如不使用改进标注的W调整值那样接近真实ATE。</p><p id="b220" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">第二个测试只关注“Amplifiers_1”社区，并将Alexa排名作为潜在的混杂协变量。有1，485个观察值，结果如下所示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi of"><img src="../Images/d94bd2f4b89251fb90b4c5c3a5547f67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*zYjS0Qkr2odpUQa-jcp62Q.jpeg"/></div></figure><p id="6237" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里再次说明，一旦我们控制了Alexa的排名，假新闻对转发量似乎没有因果关系。真实的(oracle) ATE值是轻微的负值，使用“pu”分类器进行T-boosting的“TEXTCAUSE”算法的完整版本会生成与真实值最接近的ATE。这种处理提升了价值(TextCause pu)，不仅包括改进的代理标签，还针对带有CausalBERT的文本进行了调整。未调整的ATE性能最差，然而，所有其他ATE值的性能都类似地差。</p><p id="cd43" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">很有可能在本实验中存在未观察到的未被控制的混杂因素。这可能解释了为什么没有检测到因果关系，或者相反，根本没有因果关系。在这一点上，我们还没有证明假新闻对转发次数有因果关系，也没有明确证明没有因果关系。我们所做的就是质疑研究人员普遍宣称的假设，即假新闻在社交媒体上比真实新闻传播得更快。包含更多的协变量可能会改善实验，但是，要确定包含哪些协变量是很棘手的。还有一种可能是样本量不够大，特别是第二次测试只有1485个观察值。</p><p id="a0bb" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以实现几个扩展。从第一个测试开始，我们可以用Alexa rank的用户社区代替协变量c。对于第二个测试，我们可以增加样本量，甚至跨社区进行比较。如果因果文本算法可以容纳一个以上的协变量(更高维度)，这将是有帮助的。如果因果文本算法能够处理异质治疗效果并计算条件平均治疗效果(CATE ),将会更加有用。例如，我们可以以用户社区为条件，查看不同组之间的CATEs是否有差异。</p><h2 id="2ba4" class="me mf it bd mg mh mi dn mj mk ml dp mm lq mn mo mp lu mq mr ms ly mt mu mv iz bi translated"><strong class="ak">最终想法</strong></h2><p id="4f51" class="pw-post-body-paragraph lh li it lj b lk mw kd lm ln mx kg lp lq my ls lt lu mz lw lx ly na ma mb mc im bi translated">因果推理和自然语言处理的交叉是令人着迷的，因果文本算法是创造性和主动性的一个很好的例子。我的希望是，这项研究将继续推进关于用文本来估计因果关系的方法的可能的边界。在应用方面，因果文本算法可以应用于各个领域，如经济学、医疗保健、市场营销、公共政策甚至流行病学。人们对假新闻现象的看法有所转变，例如，有人呼吁将这个问题作为公共健康问题来处理。世卫组织采取了流行病学的方法，将假新闻事件称为“i <a class="ae md" href="https://www.who.int/health-topics/infodemic#tab=tab_1" rel="noopener ugc nofollow" target="_blank"> nfodemics </a>”。所有这些变化表明，现在可能是时候对虚假信息采取因果方法了。探索因果关系可能是开发一个受经济学启发的框架的一种方式，用于查看虚假信息对社会的因果影响。就个人而言，我对将这种方法应用于利用开源社交媒体数据的经济研究很感兴趣。</p><p id="be4e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我欢迎提问和反馈，请随时在<a class="ae md" href="https://www.linkedin.com/in/haaya-naushan-a4b5b61a5/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>上与我联系。</p></div></div>    
</body>
</html>