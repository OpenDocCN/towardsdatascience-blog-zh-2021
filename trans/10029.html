<html>
<head>
<title>Non-Classical Optimization Algorithms (FULL COURSE) Overview</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">非经典优化算法(全部课程)概述</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/non-classical-optimization-algorithms-full-course-overview-8ef7091905b0?source=collection_archive---------35-----------------------#2021-09-21">https://towardsdatascience.com/non-classical-optimization-algorithms-full-course-overview-8ef7091905b0?source=collection_archive---------35-----------------------#2021-09-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="2f18" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">非经典最优化课程</h2><div class=""/><div class=""><h2 id="5b76" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">简要概述一个新的完整课程，涵盖三个主要的非经典优化算法:爬山法，模拟退火，波束搜索，蛙跳和贝叶斯优化</h2></div><p id="ab64" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">大家好！我决定就五种流行的非经典算法开始一个全新系列的帖子:<strong class="kt jd">爬山法</strong>、<strong class="kt jd">模拟退火法</strong>、<strong class="kt jd">波束搜索法</strong>、<strong class="kt jd">蛙跳法、</strong>和<strong class="kt jd">贝叶斯优化法。</strong>最受欢迎的非经典优化算法是一个被称为<strong class="kt jd">进化计算</strong>的领域，我已经就此创建了一个完整的系列，所以这就是为什么它不包括在这个系列中！您可以在此查看概述:</p><div class="ln lo gp gr lp lq"><a rel="noopener follow" target="_blank" href="/evolutionary-computation-full-course-overview-f4e421e945d9"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">进化计算(完整课程)概述</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">关于我将在这个全新的系列中涉及的材料、概念和应用的介绍性帖子！</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">towardsdatascience.com</p></div></div><div class="lz l"><div class="ma l mb mc md lz me mf lq"/></div></div></a></div><p id="0ede" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">优化问题在机器学习和人工智能中大量存在。这些领域中的大多数模型都是建立在找到一组正确的参数的基础上的，这些参数可以最小化某种类型的误差函数，例如回归的平均和误差或分类的交叉熵。因此，研究这些类型的算法以理解机器学习和人工智能中使用的统计模型背后的直觉是至关重要的。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/75404d96a4c7bc8dd04464f9b7d0ee23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/0*6i2hhr8DQqJ4NksR.png"/></div><p class="mn mo gj gh gi mp mq bd b be z dk translated">作者图片</p></figure><p id="87c6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">优化算法通常可以分为三类:基于微分信息的经典方法；引导随机搜索技术；和局部贪婪搜索。如同进化算法一样，非经典优化算法对于多维问题不需要梯度或Hessian矩阵的知识；因此，当优化问题是不可微的或者当经典方法不能找到最优解时，这些类型的算法是有利的。</p><h1 id="69d6" class="mr ms it bd mt mu mv mw mx my mz na nb ki nc kj nd kl ne km nf ko ng kp nh ni bi translated">目录</h1><ul class=""><li id="6a43" class="nj nk it kt b ku nl kx nm la nn le no li np lm nq nr ns nt bi translated">要覆盖的材料</li><li id="0846" class="nj nk it kt b ku nu kx nv la nw le nx li ny lm nq nr ns nt bi translated">基准测试函数</li><li id="0a6f" class="nj nk it kt b ku nu kx nv la nw le nx li ny lm nq nr ns nt bi translated">预赛</li><li id="975a" class="nj nk it kt b ku nu kx nv la nw le nx li ny lm nq nr ns nt bi translated">结论</li></ul><h1 id="fbe0" class="mr ms it bd mt mu mv mw mx my mz na nb ki nc kj nd kl ne km nf ko ng kp nh ni bi translated">要覆盖的材料</h1><p id="70fc" class="pw-post-body-paragraph kr ks it kt b ku nl kd kw kx nm kg kz la nz lc ld le oa lg lh li ob lk ll lm im bi translated">本课程将会很简短，比之前的进化计算课程要短得多。本课程将分为三个单元，每一个非经典算法一个单元。</p><ul class=""><li id="5fe9" class="nj nk it kt b ku kv kx ky la oc le od li oe lm nq nr ns nt bi translated">单元1)爬山者</li><li id="f593" class="nj nk it kt b ku nu kx nv la nw le nx li ny lm nq nr ns nt bi translated">单元2)模拟退火</li><li id="e42e" class="nj nk it kt b ku nu kx nv la nw le nx li ny lm nq nr ns nt bi translated">单元3)波束搜索</li><li id="d414" class="nj nk it kt b ku nu kx nv la nw le nx li ny lm nq nr ns nt bi translated">第四单元)蛙跳</li><li id="919e" class="nj nk it kt b ku nu kx nv la nw le nx li ny lm nq nr ns nt bi translated">单元5)贝叶斯优化</li></ul><p id="130c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> Hill Climber </strong>是一种利用局部搜索技术的算法，它采用单点并进入比当前状态更好的搜索空间方向。<strong class="kt jd">模拟退火</strong>是一种算法，旨在通过试图找到全局最小值(最小能量状态)来模拟退火的物理过程，即液体冷却到最小能量状态的过程。<strong class="kt jd">波束搜索</strong>是爬山法或模拟退火法的一种变体，其中算法通过使用初始点群体而不是奇点来工作。<strong class="kt jd">蛙跳</strong>是一种基于种群的算法，最差的个体向最好的个体跳跃。<strong class="kt jd">贝叶斯优化</strong>是一种常见的优化技术，通过使用贝叶斯定理在给定数量的步骤中找到最小值。该算法通过从后验采样并从结果更新先验来工作。</p><h1 id="62e5" class="mr ms it bd mt mu mv mw mx my mz na nb ki nc kj nd kl ne km nf ko ng kp nh ni bi translated">基准测试函数</h1><p id="94ce" class="pw-post-body-paragraph kr ks it kt b ku nl kd kw kx nm kg kz la nz lc ld le oa lg lh li ob lk ll lm im bi translated">为了评估我们的非经典算法，我们将在三个众所周知的无约束基准测试函数上测试它们，看它们是否能找到全局最小值。这些测试函数是<strong class="kt jd">球体、舒伯特、</strong>和<strong class="kt jd">蛋架</strong>函数；除Eggholder之外的都是n维问题，其中n的取值范围可以是[1，无穷大)，我们将在n=1000上进行测试。另一方面，Eggholder只是一个二维问题。下面是上述函数的3D图:</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="og oh di oi bf oj"><div class="gh gi of"><img src="../Images/287fd7f830ea97e705b0fff658f966c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R12mHZiTKOy7cQRAuD31Lw.png"/></div></div><p class="mn mo gj gh gi mp mq bd b be z dk translated">作者图片</p></figure><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="og oh di oi bf oj"><div class="gh gi ok"><img src="../Images/fbb447ff664da6a5dd081f8f182440bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rq-qfRqliw5NNTJ0JOdEjQ.png"/></div></div></figure><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="og oh di oi bf oj"><div class="gh gi ol"><img src="../Images/4c11296ff17ba35e206029a078f69e1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ShX6xN7l699BEhLON26_Cw.png"/></div></div></figure><p id="e65f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们不仅要测试该算法是否能找到全局最小值，还要测试它需要多长时间和多少函数来计算。</p><h1 id="b51f" class="mr ms it bd mt mu mv mw mx my mz na nb ki nc kj nd kl ne km nf ko ng kp nh ni bi translated">预赛</h1><p id="cde4" class="pw-post-body-paragraph kr ks it kt b ku nl kd kw kx nm kg kz la nz lc ld le oa lg lh li ob lk ll lm im bi translated">下面是一些预备知识，我希望你应该知道，以便最好地应用材料和理解概念:</p><ul class=""><li id="48ed" class="nj nk it kt b ku kv kx ky la oc le od li oe lm nq nr ns nt bi translated">基本统计—概率分布</li><li id="5a90" class="nj nk it kt b ku nu kx nv la nw le nx li ny lm nq nr ns nt bi translated">线性代数(基本概念:矩阵乘法，欧几里德距离等…)</li><li id="a74f" class="nj nk it kt b ku nu kx nv la nw le nx li ny lm nq nr ns nt bi translated">数值方法(基本概念:为什么使用它们，为什么需要它们)</li><li id="6ec0" class="nj nk it kt b ku nu kx nv la nw le nx li ny lm nq nr ns nt bi translated">最优化理论(你可以在下面查看我以前的帖子)</li></ul><div class="ln lo gp gr lp lq"><a rel="noopener follow" target="_blank" href="/unit-1-optimization-theory-e416dcf30ba8"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">单元1)最优化理论</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">最优化理论和四种主要最优化问题的概述</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">towardsdatascience.com</p></div></div><div class="lz l"><div class="om l mb mc md lz me mf lq"/></div></div></a></div><ul class=""><li id="62f2" class="nj nk it kt b ku kv kx ky la oc le od li oe lm nq nr ns nt bi translated">如何用Python编程—使用数据结构和算法</li><li id="6c1c" class="nj nk it kt b ku nu kx nv la nw le nx li ny lm nq nr ns nt bi translated">了解Python科学库— Numpy</li></ul><h1 id="e451" class="mr ms it bd mt mu mv mw mx my mz na nb ki nc kj nd kl ne km nf ko ng kp nh ni bi translated">结论</h1><p id="6113" class="pw-post-body-paragraph kr ks it kt b ku nl kd kw kx nm kg kz la nz lc ld le oa lg lh li ob lk ll lm im bi translated">当优化问题是非微分的，因此需要梯度或Hessian矩阵的知识的经典方法不能使用时，或者当经典方法不能找到好的解决方案时，通常使用非经典优化算法。</p><p id="7647" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">好了，这应该完成了课程的基本概述！如果到目前为止所讨论的话题中有你感兴趣的，那么请不要离开，因为我们将会涵盖所有这些以及更多！在下一篇文章中，我们将从单元1)爬山者开始:</p><p id="260b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><a class="ae on" rel="noopener" target="_blank" href="/unit-1-hill-climber-optimization-985d5b79bd5">https://towards data science . com/unit-1-hill-climber-optimization-985 D5 b 79 BD 5</a></p></div></div>    
</body>
</html>