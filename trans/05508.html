<html>
<head>
<title>Hadoop with GCP Dataproc</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带有GCP Dataproc的Hadoop</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hadoop-with-gcp-data-proc-3c402065f769?source=collection_archive---------11-----------------------#2021-05-16">https://towardsdatascience.com/hadoop-with-gcp-data-proc-3c402065f769?source=collection_archive---------11-----------------------#2021-05-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a4cb" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Hadoop、其服务和架构简介</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b658a677ccaf20d89f91c5346b2701ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uM7kkVWpLb-FAWow5SjXog.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">理查德·雅各布斯在<a class="ae kv" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="bc95" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">今天，大数据分析是世界上发展最快的领域之一，因为人们可以从中获得大量好处。随着其巨大的增长和大量的好处，也带来了自己的一系列问题。存储大数据的一个主要问题是，您需要一个大空间来存储数千万亿字节的数据，这是您无法通过个人计算机实现的。即使你设法存储了大数据的一部分，也需要数年时间来处理它。作为对此的解决方案，Hadoop是由Apache软件基金会开发的。</p><h1 id="34df" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">介绍</h1><p id="9771" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">先说:Hadoop是什么？</p><p id="9a90" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Hadoop是一个开源的<strong class="ky ir">框架</strong>，为<strong class="ky ir">存储</strong>和<strong class="ky ir">处理大数据</strong>而设计。</p><p id="d5e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，Hadoop提供了两个主要功能，<strong class="ky ir">存储大数据</strong>和<strong class="ky ir">处理大数据</strong>。我们使用HDFS (Hadoop分布式文件系统)存储大数据，使用MapReduce处理大数据。在本文的其余部分，我们将更多地讨论HDFS。</p><p id="a468" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在谈论HDFS之前，让我们先来看看DFS。在分布式文件系统(DFS)中，您将数据分成小块，分别存储在几台机器上。</p><blockquote class="mp mq mr"><p id="cf2a" class="kw kx ms ky b kz la jr lb lc ld ju le mt lg lh li mu lk ll lm mv lo lp lq lr ij bi translated"><strong class="ky ir"> HDFS </strong>是专门设计的分布式文件系统，用于在商用硬件集群中存储大型数据集。</p></blockquote><p id="710f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ms">注:商品硬件是廉价硬件。比如你日常使用的笔记本电脑就是商品硬件。</em></p><p id="4534" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一般来说，你把文件和目录存储在电脑的硬盘上。一个HD分为磁道，然后是扇区，最后是块。通常，硬盘中一个这样的块的大小是4 KB。</p><p id="aa63" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ms">注意:块是操作系统可以指向的一组扇区。</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/b1e4655cf8722ce1c8393b8e65cbd8a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*8sZCQGImzl9zCYDwx8vCJw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">大小为500 GB的硬盘中的一组块(<em class="mx">图片由作者提供)</em></p></figure><p id="42ba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我想在硬盘上存储一个大小为2 KB的文件，它会存储在一个块中，但是会有剩余的2 KB空间。HD无法将剩余空间再次用于其他文件。因此，该空间将被浪费。</p><p id="461c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，在这个硬盘之上，我们将安装带有HDFS的Hadoop。</p><p id="79b2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在Hadoop 2.x中，HDFS的块大小默认为128 MB(在Hadoop 1.x中为64 MB)</p><p id="317c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我想在HDFS存储一个大小为300 MB的文件(<em class="ms"> example.txt </em>)，它将跨三个块存储，如下所示。在块3中，将只使用44 MB。它将有84 MB的可用空间，剩余的空间将被释放出来供其他文件使用。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi my"><img src="../Images/8f8ea5fd781869bbbadd540b5481d68b.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/1*MP8szasaAQOZEA5oTf-qzA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Hadoop中300 MB大小文件的数据分布(<em class="mx">作者图片)</em></p></figure><p id="1e6f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，Hadoop比HD更有效地管理数据存储。</p><p id="cdda" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ms">注意:这里我取了一个300 MB大小的文件，仅仅是为了解释这个概念。通常，Hadoop处理的是太字节大小的非常大的文件！</em></p><h1 id="e06c" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">HDFS服务</h1><p id="ceb1" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">HDFS有两个主要的服务，即<strong class="ky ir"> NameNode </strong>和<strong class="ky ir"> Datanode </strong>。</p><p id="30f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> NameNode </strong>:运行在高端主机上的主守护进程。</p><p id="7ef2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> DataNode </strong>:运行在商用硬件上的从守护进程。</p><p id="f8a1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ms">注意:我们为什么对NameNode使用高端机器是因为所有的元数据都存储在NameNode上。如果NameNode出现故障，我们将丢失有关文件每个部分存储位置的所有信息，这最终可能导致无法访问整个Hadoop集群。因此，即使数据节点处于活动状态，也不会再使用群集，因为我们将无法访问存储在那里的数据。为了解决这个问题，最常见的做法是使用第二个NameNode作为备份。</em></p><h2 id="bd75" class="mz lt iq bd lu na nb dn ly nc nd dp mc lf ne nf me lj ng nh mg ln ni nj mi nk bi translated">NameNode</h2><ul class=""><li id="9e09" class="nl nm iq ky b kz mk lc ml lf nn lj no ln np lr nq nr ns nt bi translated">主守护进程</li><li id="8a11" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">维护和管理数据节点</li><li id="4929" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">记录元数据(例如，存储块的位置、文件的大小、权限、层次结构等。)</li><li id="6941" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">从所有数据节点接收心跳和数据块报告</li></ul><p id="8b42" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ms">注意:Heartbeat告诉</em> NameNode <em class="ms">这个DataNode还活着。</em></p><h2 id="77a3" class="mz lt iq bd lu na nb dn ly nc nd dp mc lf ne nf me lj ng nh mg ln ni nj mi nk bi translated">数据节点</h2><ul class=""><li id="b941" class="nl nm iq ky b kz mk lc ml lf nn lj no ln np lr nq nr ns nt bi translated">从属守护进程</li><li id="0016" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">存储实际数据</li><li id="97df" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">为客户端发出的读写请求提供服务</li></ul><h1 id="4699" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">HDFS的街区复制</h1><p id="2145" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">为了实现容错，Hadoop在不同的数据节点上存储数据块的副本。默认情况下，复制因子为3。也就是说，它将跨数据节点保留集群中任何数据块的三份拷贝。</p><p id="7f6a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们以之前的300 MB文件为例。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/bf79d085d20303ccfb14fd468f097a8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EEdclb_1ItGEs5RvbURlUQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">HDFS数据块复制的高级表示(<em class="mx">图片由作者提供)</em></p></figure><p id="ef60" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">Hadoop如何决定将创建的块的副本存储在哪里？</strong></p><p id="0106" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它使用<strong class="ky ir">机架感知算法。</strong></p><p id="8c61" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当客户端请求在Hadoop集群中进行读/写操作时，为了最大限度地减少流量，NameNode会选择离它更近的DataNode。这称为机架感知。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/818a1881cbcd800b4e28c8941277b8bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*uL8GyTAI2qj4bxgcwWXSNA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">支持容错的块及其副本在机架中的分布(<em class="mx">作者图片)</em></p></figure><p id="c148" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">不应在原始拷贝所在的同一机架中创建数据块的副本。这里，不应在机架1中创建数据块1的副本。它们可以在机架1以外的任何其他机架中创建。如果我将数据块1的副本存储在机架1中，并且如果机架1出现故障，那么我将丢失数据块1中的数据。</p><p id="0ffc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ms">注意:机架是30或40个节点的集合，这些节点在物理上紧密地存储在一起，并且都连接到同一个网络交换机。机架中任意两个节点之间的网络带宽大于不同机架上两个节点之间的带宽。</em></p><p id="0663" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为什么将数据块1的两个副本存储在同一个机架(机架2)上？</p><p id="4219" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这有两个原因。首先，两个机架(机架1和机架2)同时出现故障的可能性最小。其次，将数据文件从一个机架中的一个数据节点移动到同一机架中的一个数据节点所需的网络带宽比将数据文件从另一个机架中的一个数据节点移动要少得多。当不需要额外带宽时，消耗额外带宽是没有意义的。</p><h1 id="5cc0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">写HDFS的建筑</h1><p id="713c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">再回到我们之前的例子，假设我们有一个客户想要存储一个名为<em class="ms"> example.txt </em>的文件，大小为300 MB。由于他在本地机器上没有足够的空间，他想把它放到Hadoop集群中，但是客户端不知道哪些数据节点有空闲空间来存储他的数据。所以客户端首先联系NameNode。客户机向NameNode发送一个请求，说他想把<em class="ms"> example.txt </em>文件放到集群中。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/828464bc0616618e2c9de2f074679721.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kRZ2mlSKxc5TlUD-LprhHw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">HDFS书写体系结构的高级视觉表示(<em class="mx">作者图片)</em></p></figure><p id="052d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，NameNode查看了<em class="ms"> example.txt </em>的文件大小，计算了需要多少个块，以及如何将该文件分割成多个128 MB的块。因此，300 MB的文件将被分成3个块，每个块分别容纳128 MB、128 MB和44 MB。我们把文件的每一个拆分叫做<em class="ms"> a.txt </em>、<em class="ms"> b.txt </em>和<em class="ms"> c.txt </em>。之后，NameNode会快速检查哪些DataNode有空闲空间，然后向客户端返回一个响应，说请将300 MB的文件存储在DataNode 1、3和5中。</p><p id="0bfd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，客户端首先直接访问DataNode1，在那里存储<em class="ms"> a.txt </em>文件。默认情况下，集群会再保留两个<em class="ms"> a.txt </em>的备份文件。一旦存储了<em class="ms"> a.txt </em>，DataNode1就将该文件的副本发送到另一个有一些空闲空间的DataNode，比如DataNode2。类似地，DataNode2将该文件的副本提供给另一个DataNode，比如DataNode4。一旦DataNode4将该文件存储在他那里，他就向DataNode2发送一个确认，表示您发送的文件已经存储在我的本地DataNode中。同样，DataNode2向DataNode1发出确认，表示您发送的文件已经存储在我的DataNode2和DataNode4中。现在，DataNode1将向客户端返回一个确认，表示发送的文件已经存储在DataNode1、2和4中。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/661a242cabdee78951819f526d424d26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UQPeu2dGYBftWJy9_9_XIg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据节点和客户端之间的相互通信(<em class="mx">作者图片)</em></p></figure><p id="c641" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是NameNode如何知道<em class="ms"> a.txt </em>文件的确切存储位置呢？所有的datanode每隔一小段时间就向NameNode提供块报告，告诉NameNode在各自的datanode中有多少块被占用。</p><p id="20be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ms">注:A </em> <strong class="ky ir"> <em class="ms"> </em> </strong> <em class="ms">块报告</em> <strong class="ky ir"> <em class="ms"> </em> </strong> <em class="ms">包含服务器托管的每个块副本的块ID、代戳和长度。</em></p><p id="16c7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过这些块报告，NameNode相应地更新元数据中的信息。同样的，<em class="ms"> b.txt </em>文件，<em class="ms"> c.txt </em>文件也会存储在集群中。</p><p id="ac06" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当一个DataNode关闭时会发生什么？</p><p id="eb2d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所有的DataNode不时地给NameNode一个<strong class="ky ir">心跳</strong>，这有助于NameNode判断DataNode是否还活着。如果任何一个DataNode没有给出正确的心跳，那么NameNode就认为这个DataNode死了。假设DataNode1死亡。然后NameNode会将它从元数据中的<em class="ms"> a.txt </em>文件中删除，并将该文件分配给另一个有空闲空间的DataNode。假设它被发送到DataNode7。然后DataNode7向NameNode发回block报告，NameNode会为<em class="ms"> a.txt </em>更新元数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/14836ccd0f4c200a1cd7a3e8e49e176e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c4xxJ6dbSx3vdE89UjVqUA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Heartbeat如何在Hadoop集群中工作(<em class="mx">作者图片)</em></p></figure><h1 id="b905" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">阅读HDFS的建筑</h1><p id="28b3" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">假设客户想要读取他之前存储的<em class="ms"> example.txt </em>文件。客户端首先联系NameNode，说他想读取<em class="ms"> example.txt </em>文件。NameNode将查看它拥有的关于所述文件的元数据，选择每个存储的分割的最接近的副本给客户端，并且将那些数据节点的相关IP地址发送回客户端。然后，客户端将直接访问存储数据块的数据节点并读取数据。一旦客户端获得所有需要的文件块，它将组合这些块以形成文件，<em class="ms"> example.txt </em>。</p><p id="146f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ms">注意:当服务于客户端的读取请求时，HDFS选择离客户端最近的副本。这减少了读取延迟和网络带宽消耗。</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/77547f682b8874810cbd181ab7e1a806.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7aE5G73BG9h_zRGIaWc7XQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">HDFS里德建筑的高级视觉表现(<em class="mx">图片由作者提供)</em></p></figure><p id="1b67" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在开始动手操作之前，让我简要地告诉您关于<a class="ae kv" href="https://cloud.google.com/dataproc" rel="noopener ugc nofollow" target="_blank"> Dataproc </a>的情况。</p><p id="24af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Dataproc是用于运行Hadoop &amp; Spark作业的托管服务(它现在支持30多种开源工具和框架)。可用于大数据处理和机器学习。</p><p id="1bf6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面的实践是关于使用GCP Dataproc创建一个云集群并在其上运行Hadoop任务。</p></div><div class="ab cl oc od hu oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="ij ik il im in"><h1 id="c481" class="ls lt iq bd lu lv oj lx ly lz ok mb mc jw ol jx me jz om ka mg kc on kd mi mj bi translated">亲自动手</h1><p id="9871" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我将使用谷歌云平台和Ubuntu 18.04.1来实现这一点。</p><p id="2c9d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，您需要设置一个Hadoop集群。</p><ul class=""><li id="5d40" class="nl nm iq ky b kz la lc ld lf oo lj op ln oq lr nq nr ns nt bi translated">选择或创建Google云平台项目</li><li id="1189" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">您需要创建一个云Bigtable实例。首先，启用<a class="ae kv" href="https://console.cloud.google.com/flows/enableapi?apiid=bigtable,bigtableadmin.googleapis.com&amp;_ga=2.256366539.-1994314811.1556263678" rel="noopener ugc nofollow" target="_blank">云Bigtable和云Bigtable管理API</a></li><li id="0f0e" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">现在通过GCloud shell创建一个云Bigtable实例</li></ul><pre class="kg kh ki kj gt or os ot ou aw ov bi"><span id="ce59" class="mz lt iq os b gy ow ox l oy oz">gcloud bigtable instances create INSTANCE_ID \<br/>    --cluster=CLUSTER_ID \<br/>    --cluster-zone=CLUSTER_ZONE \<br/>    --display-name=DISPLAY_NAME \<br/>    [--cluster-num-nodes=CLUSTER_NUM_NODES] \<br/>    [--cluster-storage-type=CLUSTER_STORAGE_TYPE] \<br/>    [--instance-type=INSTANCE_TYPE]</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pa"><img src="../Images/6369bf1e6fc6f15fa1a0bad5fe94cc47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fajknAkE8vRpHIRj9Kr9kQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="mx">通过GCloud shell创建Bigtable实例</em></p></figure><p id="b899" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ms">注意:确保使用有云Bigtable的集群区域。</em></p><ul class=""><li id="0705" class="nl nm iq ky b kz la lc ld lf oo lj op ln oq lr nq nr ns nt bi translated">启用<a class="ae kv" href="https://console.cloud.google.com/flows/enableapi?apiid=bigtable.googleapis.com,bigtableadmin.googleapis.com,dataproc.googleapis.com,storage-api.googleapis.com&amp;_ga=2.51696745.-1994314811.1556263678" rel="noopener ugc nofollow" target="_blank">云Bigtable、云Bigtable Admin、云Dataproc和云存储JSON APIs。</a></li><li id="4b5b" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">通过运行<code class="fe pb pc pd os b"><br/>gcloud components install gsutil</code>安装<code class="fe pb pc pd os b">gsutil</code>工具</li><li id="90a3" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">安装<a class="ae kv" href="https://maven.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Maven </a>，它将用于运行一个示例Hadoop作业。<br/> <code class="fe pb pc pd os b">sudo apt-get install maven</code></li><li id="5f52" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">克隆GitHub存储库<a class="ae kv" href="https://github.com/GoogleCloudPlatform/cloud-bigtable-examples/" rel="noopener ugc nofollow" target="_blank">Google Cloud platform/Cloud-bigtable-examples</a>，其中包含一个使用云Bigtable的Hadoop作业的示例。<code class="fe pb pc pd os b"><br/>git clone <a class="ae kv" href="https://github.com/GoogleCloudPlatform/cloud-bigtable-examples.git" rel="noopener ugc nofollow" target="_blank">https://github.com/GoogleCloudPlatform/cloud-bigtable-examples.git</a></code></li><li id="1f09" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">现在创建一个云存储桶。Cloud Dataproc使用一个云存储桶来存储临时文件。<code class="fe pb pc pd os b"><br/>gsutil mb -p [PROJECT_ID] gs://[BUCKET_NAME]</code></li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pe"><img src="../Images/8c79c0da552f7286532ae58812ae4364.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TbACpvxVWeY3O-baRRALyQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="mx">创建云存储桶</em></p></figure><p id="ee27" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ms">注意:云存储桶名称在所有桶中必须是全局唯一的。请确保为此使用唯一的名称。如果您得到一个</em> <code class="fe pb pc pd os b"><em class="ms">ServiceException: 409 Bucket hadoop-bucket already exists,</em></code> <em class="ms">，这意味着给定的bucket名称已经被使用。</em></p><ul class=""><li id="d5f6" class="nl nm iq ky b kz la lc ld lf oo lj op ln oq lr nq nr ns nt bi translated">您可以通过运行<code class="fe pb pc pd os b">gsutil ls</code>来检查项目中创建的存储桶</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/7291036c0e2352368b86c32bbc5b6075.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*1r9SO1P-857cAiJn-6eS1Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="mx">检查创建的Gcloud存储桶</em></p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/da8f65bf3d0378c884b534eb7f0a93bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*qvYsrl7zXLU4iFBcQPm6LA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="mx"> Gcloud存储桶</em></p></figure><ul class=""><li id="a9ab" class="nl nm iq ky b kz la lc ld lf oo lj op ln oq lr nq nr ns nt bi translated">创建一个包含三个工作节点的云Dataproc集群。</li></ul><p id="5a1a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">转到导航菜单，在“大数据”组类别下，您可以找到“Dataproc”标签。单击它并选择“集群”。单击“创建集群”按钮。为您的集群取一个合适的名称，将Worker nodes改为3。点击页面底部的“高级选项”，找到“云存储暂存桶部分”，点击“浏览”并选择您之前制作的桶。如果全部完成，单击“创建集群”并等待几分钟，直到集群创建完毕。</p><p id="7ca8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">成功创建集群后，它将显示如下。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ph"><img src="../Images/3ed02961d8017959948e0e11f46f5217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0CPuj8lrWcI9C0F2n6cZEw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="mx">创建一个Dataproc集群</em></p></figure><ul class=""><li id="6352" class="nl nm iq ky b kz la lc ld lf oo lj op ln oq lr nq nr ns nt bi translated">您可以进入创建的集群，然后单击“VM Instances”选项卡。在那里，您可以找到为集群创建的节点列表。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pi"><img src="../Images/f068d447cca9e756deaf51169150903e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y3x-Mv1QB_7R6p4R8rzAbQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="mx">集群中的主&amp;工作者节点</em></p></figure><ul class=""><li id="ef95" class="nl nm iq ky b kz la lc ld lf oo lj op ln oq lr nq nr ns nt bi translated">转到目录<code class="fe pb pc pd os b">java/dataproc-wordcount</code></li><li id="e669" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">用Maven构建项目</li></ul><pre class="kg kh ki kj gt or os ot ou aw ov bi"><span id="e607" class="mz lt iq os b gy ow ox l oy oz">mvn clean package -Dbigtable.projectID=[PROJECT_ID] \<br/>    -Dbigtable.instanceID=[BIGTABLE_INSTANCE_ID]</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pj"><img src="../Images/7c5d9d944f5a5779a2d48a09953d49a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aaflVovaoDTdDny9Eef88A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="mx">用Maven建造</em></p></figure><ul class=""><li id="a4f4" class="nl nm iq ky b kz la lc ld lf oo lj op ln oq lr nq nr ns nt bi translated">项目完全构建完成后，您会看到一条“构建成功”的消息。</li><li id="43f1" class="nl nm iq ky b kz nu lc nv lf nw lj nx ln ny lr nq nr ns nt bi translated">现在开始Hadoop作业<code class="fe pb pc pd os b"><br/>./cluster.sh start [DATAPROC_CLUSTER_NAME]</code></li></ul><pre class="kg kh ki kj gt or os ot ou aw ov bi"><span id="407c" class="mz lt iq os b gy ow ox l oy oz">gcloud dataproc jobs submit pig --cluster test-hadoop --execute ‘fs -ls /’</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pk"><img src="../Images/422dc6804cc525e93b008c20e35abde3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Eu9jDp9f_NaG1Cib7iX2jg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Hadoop作业执行的详细信息</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/1c02f82cdcffc894b7ccd6b97f0c16d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*C91eUXUAemknFQxkH_UHGA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Hadoop作业的输出</p></figure><p id="8f5f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以通过以下方式删除云Dataproc集群</p><pre class="kg kh ki kj gt or os ot ou aw ov bi"><span id="2625" class="mz lt iq os b gy ow ox l oy oz">gcloud dataproc clusters delete [DATAPROC_CLUSTER_NAME]</span></pre></div><div class="ab cl oc od hu oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="ij ik il im in"><h1 id="39a7" class="ls lt iq bd lu lv oj lx ly lz ok mb mc jw ol jx me jz om ka mg kc on kd mi mj bi translated">资源</h1><p id="ed65" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">[1] <a class="ae kv" href="https://cloud.google.com/dataproc" rel="noopener ugc nofollow" target="_blank"> GCP Dataproc文档</a></p><p id="a153" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2] <a class="ae kv" href="https://github.com/GoogleCloudPlatform/cloud-bigtable-examples/" rel="noopener ugc nofollow" target="_blank"> GCP大表例题</a></p><p id="2218" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">干杯！🙂</p></div></div>    
</body>
</html>