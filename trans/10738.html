<html>
<head>
<title>R²: An Intuitive Metric to Measure the Accuracy of a Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">r:衡量模型准确性的直观指标</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/r%C2%B2-an-intuitive-metric-to-measure-the-accuracy-of-a-model-7446c0d5d725?source=collection_archive---------12-----------------------#2021-10-16">https://towardsdatascience.com/r%C2%B2-an-intuitive-metric-to-measure-the-accuracy-of-a-model-7446c0d5d725?source=collection_archive---------12-----------------------#2021-10-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/34ed1ae735cb46bedfcb3ee47d696a3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*81t0BkW-GGrcUyI4IKX2YQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">托尔加·乌尔坎在<a class="ae jd" href="https://unsplash.com/s/photos/relative?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="5747" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">了解R指标背后的直觉，也称为<em class="kv">决定系数</em>。</h2></div><p id="bed8" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对数据建模可能是机器学习和数据科学中最频繁的任务。随着建模而来的不可避免的问题是对看不见的数据点的预测准确性。人们已经提出了各种各样的测量精度的方法，每种方法都有其优缺点。本文解释了R指标背后的直觉，也称为<em class="ls">决定系数</em>。</p><p id="5d38" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">给定具有特征x和目标y的长度为n的数据集。目标是拟合返回预测P(X)=ŷ.的预测器p我们的预测器应该尽可能精确，从而最小化均方误差</p><p id="62a1" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">MSE = 1/n∑(yᵢŷᵢ。</p><p id="5658" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那么，你能想到的最简单的预测器是什么呢？嗯，我想忽略输入X是一个很好的起点。只有使用y，才能估计目标的平均值</p><p id="b617" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky jh"> y̅ = 1/n ⋅ ∑ yᵢ </strong></p><p id="db8c" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">并为所有预测返回<strong class="ky jh"> y̅ </strong>。在本文的剩余部分，这个预测器被称为Pˢ(其中s代表简单)。现在把Pˢ的预测代入MSE方程，我们得到</p><p id="ff63" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky jh"> MSE(y，pˢ(x))= 1/n∑(yᵢpˢ(x)= 1/n∑(yᵢy̅)</strong></p><p id="d6ca" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">等一下。我以前见过这个等式。哦对了这正是<em class="ls">方差</em>的定义。因此，对于一个总是返回y̅的常数预测器，MSE等于y的方差。这是一个有趣的事实，但让我们继续。</p><figure class="lu lv lw lx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lt"><img src="../Images/75fa25a679cecc7c66811eebceb78423.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F8E7Lg4GyFo8Ner8hFy0bw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">Pˢ:是y̅.最简单的预测者(图片由作者提供)</p></figure><p id="64d3" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那么，这对于测量我的模型的性能有什么用呢？还有这个诡异的介绍和R有什么关系？引入“基线”预测值的原因是，将误差置于<em class="ls">关系</em>中会有所帮助。当两个或多个预测值在不同尺度的数据集之间进行比较时，这尤其有用。例如，假设一个数据集的y值在(-1，1)范围内，另一个数据集的y值在(-10000，10000)范围内。由于缩放，第二数据集的MSE预计会更高。因此，需要一个<em class="ls">统一/正常化</em>，否则，橙子就被比作苹果。</p><p id="ab56" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设我们拟合了一个预测值p，它提供了预测值ŷ = P(X)。那么R由下式定义</p><p id="f137" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky jh">r = 1 MSE(y，p(x))/mse(y,pˢ(x))= 1mse(y,ŷ)/mse(y,y̅)</strong></p><p id="60d8" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">哇哦。这看起来是一个相对简单的等式。基本上，我们用预测值p的均方误差除以Pˢ的均方误差，这样两个误差就有关系了。下图给出了线性预测因子p的示例。可以观察到MSE(y,ŷ比MSE(y,y̅).小因此，该分数将小于1，导致R为正值。</p><figure class="lu lv lw lx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ly"><img src="../Images/016c33e119ead9c7ca0ee6dd763ad488.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lXc-pMRgtQb-83yQuV3VjA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">r:将两个模型的误差设定成关系的准确性指标。(图片由作者提供)</p></figure><p id="d2f7" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看看还会发生什么。</p><ul class=""><li id="3d43" class="lz ma jg ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated"><strong class="ky jh"> R =1.0: </strong>假设我们已经找到MSE(y,ŷ)=0.的最佳预测值那么，0除以任何数都是零，1–0 = 1。这很酷，因为我们在这里展示的是，R的最佳可能值实际上是1.0</li><li id="a192" class="lz ma jg ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">更有可能的是，你的预测器会有一些误差。现在正R告诉我们，我们的预测器比总是预测平均值好多少。</li><li id="a946" class="lz ma jg ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">你可能会想，我的预测器怎么会比总是预测目标的平均值还要糟糕。嗯，你肯定听说过过度拟合？这正是可能发生的时间。</li></ul><p id="1408" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">讨论了这三种情况，我们也知道R的值一定在区间(-∞，1.0)内。直观上，这是因为，一方面，r没有下界，因为MSE(y,ŷ没有上界。另一方面，MSE(y,ŷ)不能小于零，这导致上限为1.0。</p><p id="8ff7" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">同样值得一提的是，因为分母等于<strong class="ky jh">var(y)</strong>，所以也可以将该指标解释为<strong class="ky jh">解释的方差</strong>。或者，换句话说，预测器可以捕获的方差的百分比。最后，我想提一下，模型相对性能的思想是可以借鉴的，你可以创建你自己的指标。假设您想要使用一个K-最近邻(KNN)预测器作为您性能的基线；然后你简单的除以MSE(y，KNN(X))而不是MSE(y,Pˢ(X)).还有维奥拉。现在你衡量与KNN相关的表现。</p><p id="7a2b" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我希望你喜欢这篇文章，并发现它是有帮助的。欢迎在下面留下一些评论。</p></div></div>    
</body>
</html>