<html>
<head>
<title>Using Regression To Understand the AlphaZero Chess Engine</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用回归来理解AlphaZero象棋引擎</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-regression-to-understand-the-alphazero-chess-engine-aba67148978b?source=collection_archive---------14-----------------------#2021-12-09">https://towardsdatascience.com/using-regression-to-understand-the-alphazero-chess-engine-aba67148978b?source=collection_archive---------14-----------------------#2021-12-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8c9a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">研究人员已经开始用人类的语言解释AlphaZero在想什么。请继续阅读，了解更多信息。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/41546bad8ec4f4013d9ab4e38f041f92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QPjA833TD09fnQNX"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">达米亚诺·林戈里在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="2bba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">神经网络的一个关键问题是所谓的“黑箱问题”。神经网络已经在许多领域(语音识别、自动驾驶汽车、游戏、蛋白质折叠等)产生了最先进的结果。)但是我们无法用人类的语言来解释他们所做的决定。让我们举一个具体的例子:象棋引擎。今天最强的两个国际象棋引擎是Stockfish和AlphaZero。</p><p id="9956" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Stockfish <em class="lv"> </em>是一个传统的引擎——它用人类创造的<strong class="lb iu">概念</strong>来评估国际象棋的位置。一个简单的概念是位置上的兵差。如果白棋的棋子比黑棋多，这个概念将为白棋返回正数，为黑棋返回负数。其他的概念更复杂，但是只要有足够的时间，任何人都可以理解所有的Stockfish概念(你可以自己查看Stockfish代码<a class="ae ky" href="https://github.com/official-stockfish/Stockfish" rel="noopener ugc nofollow" target="_blank">这里</a>)。从数学上讲，您可以将Stockfish概念想象成一个函数，该函数将国际象棋的位置作为输入，并输出一个数字来表示该位置上的概念的评估。</p><p id="fc71" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">AlphaZero与Stockfish有着本质的不同。根本没有人类创造的概念。AlphaZero通过一个大型神经网络运行每个国际象棋位置，并在最后吐出它认为最好的棋步。这是一个黑箱:我们不能像看Stockfish那样看着一些代码并理解它的思维过程。那么我们是不是注定永远无法理解AlphaZero <em class="lv"> </em>是怎么想的？直到最近，是的。然而，在过去的几年里，有几种方法已经开始破解黑盒。我想强调一个特别简单而有效的方法。这种方法的来源以及结果，见本文<a class="ae ky" href="https://arxiv.org/abs/2111.09259" rel="noopener ugc nofollow" target="_blank">的第4节</a>。</p><p id="dbbd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们所做的是获取Stockfish概念，看看AlphaZero <em class="lv"> </em>神经网络是否包含它们。我们到底该怎么做？对于AlphaZero网络中的每一层，我们在该层的激活上运行给定Stockfish概念的回归。然后，我们使用该回归的r平方来确定该图层是否与Stockfish概念相关，r平方越高，越表明该图层相关。</p><h1 id="aa2f" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">回归详细信息</h1><p id="4b23" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">上面的描述比较抽象，我们来看一个具体的回归来理清事情。首先，让我们选择一个Stockfish概念和一个AlphaZero <em class="lv"> </em>神经网络层。我们将挑选国王安全和第10层的概念。这个概念接受一个国际象棋的位置，通过几次试探返回一个代表国王安全程度的数字。接下来，因为我们在做回归，我们需要足够的数据。没问题——我们将从国际象棋数据库中随机抽取几千个位置。然后，我们在每个位置运行Stockfish king安全概念。结果是一系列数字——这些是我们回归的y(因变量)。</p><p id="db3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了获得回归的x(独立变量),我们采用相同的位置样本，并通过AlphaZero神经网络逐一运行它们。由于我们选择了第10层，所以我们不会通过网络全程运行每个位置；我们停在第10层的激活。这些激活是我们的x。注意，每个y是一个标量，每个x是一个矢量。</p><p id="ada3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，有了数据，我们需要明确我们想要什么样的回归。我们可以做一个简单的线性回归，不需要任何修饰，但是有一个问题。也就是说，AlphaZero网络中的每一层都很大(总激活数以千计)。因此，正态回归会严重过度拟合，导致人为的高r平方值。为了解决这个问题，我们做了一个<strong class="lb iu"> L1正则化回归</strong>，取结果的r平方作为我们想要的最终值。在这个特定的回归中(第10层的国王安全)，r平方为0.6。因此，我们可以得出结论，第10层AlphaZero正在计算与king safety适度相关的内容。</p><p id="209b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以对网络中的所有层进行同样的回归，以查看是否存在任何基于层的模式(例如，可能后面的层比前面的层与king safety更相关)。我们也可以在网络训练过程中进行这种回归<strong class="lb iu">，以深入了解AlphaZero如何学习不同的国际象棋概念。作为一名棋手，我对最后一个用例特别感兴趣。人类学习国际象棋从基本概念开始(例如，棋子如何移动，一步棋威胁)，然后逐渐进入更高级的概念(国王安全，棋子移动性等)。).AlphaZero也是如此吗？</strong></p><p id="8e1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们继续讨论结果之前，让我们用一些伪代码回顾一下广义回归过程:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/c171b38a80975842a36c1075266bbd35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0u9CAIDeqWn6zxeCI4nUdA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">广义回归算法。图片作者。</p></figure><h1 id="0da1" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结果</h1><p id="2a67" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">最初论文中的研究人员对93种鱼类概念进行了上述回归过程。首先，他们注意到所有概念都出现了一种模式:从训练步骤16，000到训练步骤128，000，所有层的每个概念的r平方增加最多。换句话说，AlphaZero网络中的大部分学习都发生在这个区间。早些时候，我们问了一个问题，AlphaZero是否会跟随人类，在学习复杂概念之前学习简单概念——答案似乎是否定的；<strong class="lb iu"> AlphaZero在相似的时间内学习概念，不管人为指定的难度如何</strong>。</p><p id="a3dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">研究人员还注意到，一旦网络经过大部分训练(步长&gt; 128，000)，大多数简单的概念，如国王是否在检查中或某个棋子是否可以被捕获，都具有在初始层急剧上升的r平方，然后在高r平方处稳定下来。这表明AlphaZero <strong class="lb iu">在网络早期</strong>处理简单的概念，而<strong class="lb iu"> AlphaZero同意简单的人类象棋概念</strong>。当然，当网络还没有被训练时(步骤&lt; 128，000 ),所有层的r平方都如预期的那样低。</p><div class="kj kk kl km gt ab cb"><figure class="mu kn mv mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/ac402f50592a828946ecd4de7c75b3bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*5FsLQFqdY7VkFn0HTMr15Q.png"/></div></figure><figure class="mu kn na mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/7eb46fc23ab24422e7e02d34a4ecd243.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*MjvoubOUkSepfhrpWqBIrQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk nb di nc nd translated">两个简单概念的回归结果图。左边的概念是游戏方是否可以在一步棋中被将死。正确的概念是玩的一方是否在检查。颜色越浅，r平方越高。“块”是指神经网络层。经许可从原始<a class="ae ky" href="https://arxiv.org/pdf/2111.09259.pdf" rel="noopener ugc nofollow" target="_blank">纸张</a>拍摄的图像。</p></figure></div><p id="6958" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于复杂的概念，情况就不那么清楚了。某些复杂的概念，如Stockfish材料不平衡(不仅仅是简单的棋子数差异，涉及国际象棋策略)<strong class="lb iu">实际上在后面的训练步骤</strong>(步骤&gt; 100，000)中r平方递减。这意味着AlphaZero不同意鱼群物质不平衡公式的某些内容。随着一些复杂概念的训练进展，这些较低的r平方证实了人类国际象棋大师对AlphaZero的定性观察:它下棋的方式与人类“不同”。综上所述，<strong class="lb iu"> AlphaZero并不认同一些复杂的人类象棋概念</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/2b8eb6386a4f12a0024ad13a41ca45a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*8xN9puEsmUV4lQVKo-l9Dg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一个复杂概念的回归结果:鱼群物质不平衡。请注意，在高训练步数时，r平方实际上是如何降低的。经原始<a class="ae ky" href="https://arxiv.org/pdf/2111.09259.pdf" rel="noopener ugc nofollow" target="_blank">纸张</a>许可拍摄的图像。</p></figure><p id="343a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当然，这个回归过程并没有告诉我们，例如，AlphaZero关于物质不平衡的想法与人类有何不同。然而，据我所知，这是第一次，我们找到了一种数学方法来证明存在差异，而在过去，我们所拥有的只是我们的直觉。</p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><p id="2269" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们描述了一个回归过程，该过程能够将神经网络中的层与人类概念相关联。这是朝着解决黑箱问题迈出的一步，因为神经网络的内部工作方式对于人类来说是众所周知的难以理解。在未来，我希望看到这种方法应用到国际象棋之外的更多领域。感谢阅读，并请留下任何问题/评论！</p><p id="b709" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更正:Stockfish的最新版本(从2020年8月起)现在也有一个神经网络组件<a class="ae ky" href="https://stockfishchess.org/blog/2020/introducing-nnue-evaluation/" rel="noopener ugc nofollow" target="_blank"/>。因此它们不再完全是人类可以理解的。</p></div></div>    
</body>
</html>