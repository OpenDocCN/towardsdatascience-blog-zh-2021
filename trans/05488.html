<html>
<head>
<title>Superior Feature Selection by Combining Multiple Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过组合多种模型实现卓越的功能选择</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/superior-feature-selection-by-combining-multiple-models-607002c1a324?source=collection_archive---------10-----------------------#2021-05-15">https://towardsdatascience.com/superior-feature-selection-by-combining-multiple-models-607002c1a324?source=collection_archive---------10-----------------------#2021-05-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bac7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">你最喜欢的模特自己选择特色</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4f1f97a1c48e13591b8ecb867b41f9f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eKnTmqlfmANkXZh3lw2NIg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">图片由</strong> <a class="ae kz" href="https://www.pexels.com/@olly?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> <strong class="bd ky">安德里亚</strong> </a> <strong class="bd ky">上</strong> <a class="ae kz" href="https://www.pexels.com/photo/crop-multiracial-people-joining-hands-together-during-break-in-modern-workplace-3931562/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> <strong class="bd ky">像素</strong> </a></p></figure><h2 id="c2e9" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">介绍</h2><p id="32a3" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">机器学习中有很多特征选择方法。每一种方法都可能给出不同的结果，这取决于你如何使用它们，所以很难完全信任一种方法。让多种方法投票决定我们是否应该保留一个特性，这不是很酷吗？这就像随机森林算法一样，它将多个弱学习者的预测结合起来，形成一个强学习者。事实证明，Sklearn已经给了我们工具来自己制作这样的特征选择器。</p><p id="61ba" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">通过使用这些工具，我们将一起构建一个特性选择器，它可以接受任意数量的Sklearn模型。所有这些模型将投票决定我们应该保留哪些功能，我们通过收集所有模型(民主)的投票来做出决定。</p><div class="mu mv gp gr mw mx"><a href="https://ibexorigin.medium.com/membership" rel="noopener follow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">通过我的推荐链接加入Medium-BEXGBoost</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">获得独家访问我的所有⚡premium⚡内容和所有媒体没有限制。支持我的工作，给我买一个…</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">ibexorigin.medium.com</p></div></div><div class="ng l"><div class="nh l ni nj nk ng nl ks mx"/></div></div></a></div><p id="5cf5" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">获得由强大的AI-Alpha信号选择和总结的最佳和最新的ML和AI论文:</p><div class="mu mv gp gr mw mx"><a href="https://alphasignal.ai/?referrer=Bex" rel="noopener  ugc nofollow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">阿尔法信号|机器学习的极品。艾总结的。</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">留在循环中，不用花无数时间浏览下一个突破；我们的算法识别…</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">alphasignal.ai</p></div></div><div class="ng l"><div class="nm l ni nj nk ng nl ks mx"/></div></div></a></div></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="6f60" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">构建选择器的必备知识:权重和系数</h2><p id="c8a0" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">在我们继续构建选择器之前，让我们回顾一些必要的主题。首先，几乎所有产生预测的Sklearn估计器在被拟合到训练数据之后都具有<code class="fe nu nv nw nx b">.coef_</code>和<code class="fe nu nv nw nx b">.feature_importances_</code>属性。</p><p id="01f2" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><code class="fe nu nv nw nx b">.coef_</code>属性主要出现在<code class="fe nu nv nw nx b">sklearn.linear_model</code>子模块下给出的模型中:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="8314" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">顾名思义，以上是通过拟合线性回归的最佳拟合直线计算出的<em class="oa">系数</em>。其他模型遵循类似的模式，并产生其内部方程的系数:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="4e0b" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><code class="fe nu nv nw nx b">sklearn.tree</code>和<code class="fe nu nv nw nx b">sklearn.ensemble</code>中的模型工作方式不同，它们计算<code class="fe nu nv nw nx b">.feature_importances_</code>属性下每个特征的<em class="oa">重要性</em>或<em class="oa">权重</em>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="04d7" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">与线性模型的系数不同，权重之和为1:</p><pre class="kj kk kl km gt ob nx oc od aw oe bi"><span id="5892" class="la lb it nx b gy of og l oh oi">np.sum(dt.feature_importances_)</span><span id="4804" class="la lb it nx b gy oj og l oh oi">1.0</span></pre><p id="cb01" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">无论模型如何，随着特征权重或系数的降低，特征对整体预测的贡献越来越小。这意味着我们可以丢弃系数或权重接近0的特征。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="aa8d" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">RFECV概述</h2><p id="c423" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">递归特征消除(RFE)是一种流行的特征选择算法。它会自动找到要保留的最佳特征数量，以实现给定模型的最佳性能。下面是一个简单的例子:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="b095" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">上述代码用于查找最少数量的特征，以实现<a class="ae kz" rel="noopener" target="_blank" href="/intro-to-regularization-with-ridge-and-lasso-regression-with-sklearn-edcf4c117b7a?source=your_stories_page-------------------------------------">套索回归</a>模型的最佳性能。</p><p id="3b62" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">在拟合到训练数据之后，RFECV具有<code class="fe nu nv nw nx b">.support_</code>属性，该属性给出布尔掩码，具有应该保留的特征的真值:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="ccf7" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">然后，我们可以使用该掩码对原始数据进行子集划分:</p><pre class="kj kk kl km gt ob nx oc od aw oe bi"><span id="1d4d" class="la lb it nx b gy of og l oh oi">X.loc[:, rfecv.support_]</span></pre><p id="7c88" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">定制特性选择器的核心将是这个<code class="fe nu nv nw nx b">RFECV</code>类。我没有详细介绍它是如何工作的，但我以前的文章重点介绍了它。我建议在继续之前阅读:</p><div class="mu mv gp gr mw mx"><a rel="noopener follow" target="_blank" href="/powerful-feature-selection-with-recursive-feature-elimination-rfe-of-sklearn-23efb2cdb54e"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">Sklearn的递归特征消除(RFE)功能强大的特征选择</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">编辑描述</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">towardsdatascience.com</p></div></div><div class="ng l"><div class="ok l ni nj nk ng nl ks mx"/></div></div></a></div></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="e0af" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">第一部分:选择模型</h2><p id="957c" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">我们将使用<a class="ae kz" href="https://www.kaggle.com/seshadrikolluri/ansur-ii" rel="noopener ugc nofollow" target="_blank"> Ansur Male </a>数据集，主要是因为它包含了6000名美国陆军人员的许多身体测量特征(98个数字):</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl ol"><img src="../Images/ca73576cecbbdae72b2145079ae26f58.png" data-original-src="https://miro.medium.com/v2/format:webp/1*12W3UEzDgF4Tn0ODkfJwhw.png"/></div></figure><p id="ff03" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">我们将尝试预测以磅为单位的体重，为了做到这一点，我们需要降低模型的复杂性——也就是说，使用尽可能少的特征创建一个具有尽可能多的预测能力的模型。目前有98个，我们将努力减少这个数字。此外，我们将删除以千克为单位记录重量的列。</p><pre class="kj kk kl km gt ob nx oc od aw oe bi"><span id="61ea" class="la lb it nx b gy of og l oh oi">ansur.drop("weightkg", axis=1, inplace=True)</span></pre><p id="450c" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">我们的第一个模型将是Lasso Regressor，我们将把它插入<code class="fe nu nv nw nx b">RFECV</code>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="8daa" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">我们将从套索生成的布尔遮罩存储在<code class="fe nu nv nw nx b">lasso_mask</code>中，稍后你会看到原因。</p><p id="908b" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">接下来，我们将对另外两个模型进行同样的操作:线性回归和GradientBoostingRegressor:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="297e" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">第二部分:合并投票</h2><p id="cabc" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">现在，我们将投票作为布尔掩码放在三个数组中:<code class="fe nu nv nw nx b">lasso_mask</code>、<code class="fe nu nv nw nx b">gb_mask</code>和<code class="fe nu nv nw nx b">lr_mask</code>。由于真/假值代表1和0，我们可以添加三个数组:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="7da2" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">结果将是一个数组，其中记录了所有模型选择每个特征的次数。现在，我们可以设置一个投票阈值来决定是否保留该特性。这个门槛取决于我们想保守到什么程度。我们可以设置一个严格的阈值，我们希望所有3个成员都选择该特性，或者我们可以选择1作为安全阈值:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="12d4" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">现在，<code class="fe nu nv nw nx b">final_mask</code>是一个具有真值的布尔数组，如果所有3个估计器都选择了一个特性。我们可以用它来划分原始数据的子集:</p><pre class="kj kk kl km gt ob nx oc od aw oe bi"><span id="1d2c" class="la lb it nx b gy of og l oh oi">&gt;&gt;&gt; X.loc[:, final_mask].shape</span><span id="b8ab" class="la lb it nx b gy oj og l oh oi">(4082, 39)</span></pre><p id="e928" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">如您所见，最终的掩码选择了39列，而没有选择98列。您可以使用数据集的这个子集来创建一个不太复杂的模型。例如，我们将选择线性回归模型，因为我们可以预期身体测量值是线性相关的:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="a71f" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">步骤总结</h2><p id="54d1" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">即使需要一些工作才能得到最终结果，这也是值得的，因为多个模型的组合能力可以超过任何其他特征选择方法。</p><p id="d11e" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">我们在示例中只选择了3个模型，但是您可以包含任意多的模型，以使结果更加可靠和可信。</p><p id="d3cf" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">此时，合乎逻辑的一步是将所有这些代码包装在一个函数中，甚至是一个定制的Sklearn转换器，但是定制转换器是另一篇文章的主题。为了加强上述观点并给你一个大纲，让我们回顾一下我们已经采取的步骤:</p><ol class=""><li id="40c3" class="om on it ly b lz mp mc mq lj oo ln op lr oq mo or os ot ou bi translated">选择任意数量的具有<code class="fe nu nv nw nx b">.coef_</code>或<code class="fe nu nv nw nx b">.feature_importnances_</code>属性的Sklearn估计器。估计量越多，结果就越稳健。然而，多个模型是有代价的——因为<code class="fe nu nv nw nx b">RFECV</code>在幕后使用<a class="ae kz" rel="noopener" target="_blank" href="/how-to-master-the-subtle-art-of-train-test-set-generation-7a8408bcd578">交叉验证</a>,对于集合模型和大型数据集，训练时间在计算上将是昂贵的。此外，确保根据问题的类型选择估计器——记住只传递分类或回归估计器，以便<code class="fe nu nv nw nx b">RFECV</code>工作。</li><li id="c3ee" class="om on it ly b lz ov mc ow lj ox ln oy lr oz mo or os ot ou bi translated">将所有选择的模型插入<code class="fe nu nv nw nx b">RFECV</code>类，并确保保存每一轮的布尔掩码(通过<code class="fe nu nv nw nx b">.support_</code>访问)。为了加快速度，您可以调整<code class="fe nu nv nw nx b">step</code>参数，以便在每轮淘汰中丢弃任意数量的特征。</li><li id="74dd" class="om on it ly b lz ov mc ow lj ox ln oy lr oz mo or os ot ou bi translated">对所有估计量的掩码求和。</li><li id="e101" class="om on it ly b lz ov mc ow lj ox ln oy lr oz mo or os ot ou bi translated">设置投票计数的阈值。这个门槛取决于你想保守到什么程度。使用此阈值将投票数组转换为布尔掩码。</li><li id="e173" class="om on it ly b lz ov mc ow lj ox ln oy lr oz mo or os ot ou bi translated">使用最终掩膜对原始数据进行子集化，以进行最终模型评估。</li></ol></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="9241" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">与特征选择相关的进一步阅读</h2><ul class=""><li id="b5ae" class="om on it ly b lz ma mc md lj pa ln pb lr pc mo pd os ot ou bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/how-to-use-variance-thresholding-for-robust-feature-selection-a4503f2b5c3f?source=your_stories_page-------------------------------------">如何使用方差阈值进行鲁棒特征选择</a></li><li id="8903" class="om on it ly b lz ov mc ow lj ox ln oy lr oz mo pd os ot ou bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/how-to-use-pairwise-correlation-for-robust-feature-selection-20a60ef7d10?source=your_stories_page-------------------------------------">如何使用成对相关性进行稳健的特征选择</a></li><li id="0248" class="om on it ly b lz ov mc ow lj ox ln oy lr oz mo pd os ot ou bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/powerful-feature-selection-with-recursive-feature-elimination-rfe-of-sklearn-23efb2cdb54e">强大的功能选择和递归功能消除</a></li><li id="f66a" class="om on it ly b lz ov mc ow lj ox ln oy lr oz mo pd os ot ou bi translated"><a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html" rel="noopener ugc nofollow" target="_blank"> RFECV Sklearn文档</a></li><li id="ac73" class="om on it ly b lz ov mc ow lj ox ln oy lr oz mo pd os ot ou bi translated"><a class="ae kz" href="https://scikit-learn.org/stable/modules/feature_selection.html#feature-selection" rel="noopener ugc nofollow" target="_blank"> Sklearn官方功能选择用户指南</a></li></ul></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="a574" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">您可能也会感兴趣…</h2><ul class=""><li id="982e" class="om on it ly b lz ma mc md lj pa ln pb lr pc mo pd os ot ou bi translated"><a class="ae kz" href="https://towardsdev.com/intro-to-object-oriented-programming-for-data-scientists-9308e6b726a2?source=your_stories_page-------------------------------------" rel="noopener ugc nofollow" target="_blank">面向数据科学家的面向对象编程简介</a></li><li id="d825" class="om on it ly b lz ov mc ow lj ox ln oy lr oz mo pd os ot ou bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/my-6-part-powerful-eda-template-that-speaks-of-ultimate-skill-6bdde3c91431?source=your_stories_page-------------------------------------">我的6部分强大EDA模板，讲述终极技能</a></li><li id="3699" class="om on it ly b lz ov mc ow lj ox ln oy lr oz mo pd os ot ou bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/how-to-use-sklearn-pipelines-for-ridiculously-neat-code-a61ab66ca90d?source=your_stories_page-------------------------------------">如何将Sklearn管道用于极其简洁的代码</a></li></ul></div></div>    
</body>
</html>