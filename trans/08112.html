<html>
<head>
<title>Independence, Covariance and Correlation between two Random Variables</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">两个随机变量之间的独立性、协方差和相关性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/independence-covariance-and-correlation-between-two-random-variables-197022116f93?source=collection_archive---------2-----------------------#2021-07-26">https://towardsdatascience.com/independence-covariance-and-correlation-between-two-random-variables-197022116f93?source=collection_archive---------2-----------------------#2021-07-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/7e1a8269ba718b8d4318bec6cbebd7f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PFoj3sQ4uLfAp_uc"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">马库斯·斯皮斯克在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="c408" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，我将讨论两个随机变量之间的独立性、协方差和相关性。这些是统计学中的基本概念，在数据科学中非常重要。</p><h1 id="81d1" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">介绍</h1><p id="d970" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">让我们用一个例子从随机变量的简单定义开始。</p><h1 id="c2d8" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">随机变量</h1><p id="bc18" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">随机变量，通常写成<em class="mh"> X </em>，定义为一个变量，其可能值是随机现象的数值结果[1]。给定样本空间<strong class="ki iu"> S的随机实验，</strong>随机变量<strong class="ki iu"> <em class="mh"> X </em> </strong> <em class="mh"> </em>是一个集合函数，它为属于样本空间<strong class="ki iu">S</strong>【2】<strong class="ki iu">的每个元素<strong class="ki iu"> <em class="mh"> s </em> </strong>分配一个且仅一个实数。</strong></p><p id="55d7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随机变量的一个例子可以是掷硬币，其结果可以是正面(H)或反面(T)。因此，样本空间为:</p><p id="0701" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> S = {H，T} </strong></p><p id="092f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以将随机变量X定义如下:</p><ul class=""><li id="9876" class="mi mj it ki b kj kk kn ko kr mk kv ml kz mm ld mn mo mp mq bi translated">让X = 0代表正面</li><li id="b41d" class="mi mj it ki b kj mr kn ms kr mt kv mu kz mv ld mn mo mp mq bi translated">让X = 1表示尾部</li></ul><p id="7bb7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意，随机变量给样本空间(H和T)的每个样本分配一个且仅一个实数(0和1)。在这种情况下，X的支撑或空间是{0，1}。</p><h1 id="ca0e" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">概率质量函数[2]</h1><p id="613a" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">离散随机变量X取特定值X即P(X=x)的概率用<em class="mh"> f(x) </em>表示，称为概率质量函数(p.m.f .)。它被称为连续随机变量的概率密度函数。pmf是离散随机变量的概率分布，提供可能的值及其相关概率[3]。它被定义为:</p><p id="9ed0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">p(x) = P(X=xᵢ)</p><p id="116b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">p(x)有一个性质，与所有可能值相关联的概率必须是正的，并且总和为1。</p><p id="6579" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们有了关于随机变量和pmf的背景，我们将看看独立性，协方差和相关性。</p><h1 id="e4d9" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">随机变量的独立性</h1><p id="b6c9" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">如果X和Y是两个随机变量，并且X的分布不受Y的取值影响，反之亦然，则称这两个随机变量是独立的。</p><p id="63d8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在数学上，两个离散的随机变量是独立的，如果:</p><p id="899f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">P(X=x，Y=y) = P(X=x) P(Y=y)，对于所有的X，Y。</p><p id="7dad" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">直观地说，对于独立的随机变量，知道其中一个变量的值，不会改变另一个变量的概率。X和Y的联合pmf仅仅是X和Y的个体边缘化pmf的产物。</p><p id="d769" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们解决一个示例问题，以更好地理解如何使用该公式。假设我们有两个随机变量X和Y，它们的联合概率是已知的。它可以表示为一个表格，如下所示。X的边缘化pmf值可以通过对所有Y值求和来获得[5]。对于y也可以进行类似的边缘化。在联合pmf表中，它只对应于对列求和。联合pmf表以及边际pmf值如下所示:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi gj"><img src="../Images/392e489aff89d89acacec33ff002fd14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*drkfbYVJMpmfLj5UhUuhbA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">来源:作者</p></figure><p id="ea95" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了使两个随机变量独立，联合pmf的单元条目应该等于求和行和列中表示的边缘化pmf值的乘积，即P(X=x，Y=y) = P(X=x) P(Y=y)，对于所有X，Y。</p><p id="2069" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果这种关系对于x，y对中的任何一个都不成立，那么这两个随机变量就不是独立的。所以在我们的例子中，这些对不是独立的。</p><p id="c6c2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是从分布表创建边际PMF的代码。(注意，它没有经过任何优化。)</p><figure class="mw mx my mz gt ju"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="f61e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后使用边际PMF来检查独立性:</p><figure class="mw mx my mz gt ju"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="14b5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们看两个例子，一个是独立的，另一个不是。</p><figure class="mw mx my mz gt ju"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="b157" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们从两个表中得到预期的关系:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/aadaafe3db84884238c04b32cc02954e.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*DflbGBT-BamRFZMqO2633A.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">来源:作者</p></figure><h1 id="9965" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">协方差</h1><p id="9a0d" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">协方差是两个随机变量的联合可变性的度量[5]。它显示了两个随机变量之间的线性相关程度。正协方差意味着存在直接的线性关系，即一个变量的增加对应于另一个变量的更大值。负协方差意味着一个随机变量的值越大，另一个随机变量的值越小。因此，协方差的符号显示了两个随机变量之间线性关系的性质。最后，对于两个独立的随机变量，协方差为零。然而，零协方差并不意味着两个随机变量是独立的。</p><p id="ae9b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">协方差的大小取决于变量，因为它不是一个标准化的措施。因此，这些值本身并不能清楚地表明线性关系有多强。</p><p id="329f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">协方差的公式为:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nd"><img src="../Images/bb4c03723c504fe034f4d0dbb5eec7f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*530BIijzE9Xqxd_1DBCbzg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">来源:作者</p></figure><p id="bb3f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注:E(X)是随机变量的期望值。你可以在这里了解更多:<a class="ae kf" href="https://en.wikipedia.org/wiki/Expected_value" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Expected_value</a></p><p id="44da" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除了知道联合pmf的值，我们还需要X和Y的平均值来计算协方差。以下函数计算分布表的协方差。</p><figure class="mw mx my mz gt ju"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="8aab" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们两个测试案例的协方差是:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/4c6a3b11cb0dc2304d2a782b4639db88.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*UsPv0G2jRX8n-ff8537zzA.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">来源:作者</p></figure><p id="4e9b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们确认独立情况下的协方差为零。而我们看到非独立测试用例的正协方差。这表明当X增加时，Y也会增加。</p><p id="5fa8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，让我们看看相关性。</p><h1 id="1164" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">相互关系</h1><p id="eac5" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">相关性只是协方差的缩放/标准化版本，因此值介于-1到1之间。分别使用X和Y的标准偏差进行归一化。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/e2437550239325d016622d22bc0ba543.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*W7-s-aBGrw5fuGQDXarMjQ.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">来源:作者</p></figure><p id="72b9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">自变量同时具有零协方差和相关性。相关值为1意味着与正的线斜率完全相关。而相关性为-1意味着与负的线斜率完全反相关。</p><p id="bef8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了计算相关性，除了计算协方差之外，我们还需要计算X和X的标准差。</p><figure class="mw mx my mz gt ju"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="c696" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的测试用例的相关性是:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/f5ac4de5b5192f79cdd5426e9b8d98d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*fG0u0y5FNhki0JWdLjLEgA.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">来源:作者</p></figure><p id="8b8c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如所料，我们得到了与协方差相同的相关性。独立测试用例具有零相关性。而具有正协方差的测试用例具有低于1的正相关性。</p><p id="6989" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">还有一件事，需要注意的是，协方差/相关性并不意味着因果关系，即X与Y相关并不意味着X是Y的原因。<a class="nh ni ep" href="https://medium.com/u/a1a9e99dd9df?source=post_page-----197022116f93--------------------------------" rel="noopener" target="_blank"> Seema Singh </a>就此写了一篇很棒的文章:<a class="ae kf" rel="noopener" target="_blank" href="/why-correlation-does-not-imply-causation-5b99790df07e">https://towardsdatascience . com/why-correlation-does-not-implie-causance-5b 99790 df 07 e</a></p><h1 id="0f8a" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">结论</h1><p id="8445" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">最后，我们看了什么是随机变量，什么是概率密度函数。之后，我们讨论了两个随机变量的独立性。最后，我们将协方差和相关性作为度量两个随机变量之间线性相关性的标准。后者只是前者的标准化版本。</p><h1 id="e384" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">参考</h1><p id="09b9" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">[1]http://www.stat.yale.edu/Courses/1997-98/101/ranvar.htm<a class="ae kf" href="http://www.stat.yale.edu/Courses/1997-98/101/ranvar.htm" rel="noopener ugc nofollow" target="_blank"/></p><p id="c707" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2]<a class="ae kf" href="https://online.stat.psu.edu/stat414/lesson/7/7.1" rel="noopener ugc nofollow" target="_blank">https://online.stat.psu.edu/stat414/lesson/7/7.1</a></p><p id="3c7e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://en.wikipedia.org/wiki/Probability_mass_function" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Probability_mass_function</a></p><p id="9cbb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[4]<a class="ae kf" href="https://www.math.umd.edu/~millson/teaching/STAT400fall18/slides/article16.pdf" rel="noopener ugc nofollow" target="_blank">https://www . math . UMD . edu/~ millson/teaching/stat 400 fall 18/slides/article 16 . pdf</a></p><p id="bdc0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://en.wikipedia.org/wiki/Marginal_distribution" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Marginal_distribution</a></p><p id="fd41" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://en.wikipedia.org/wiki/Covariance" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Covariance</a></p></div></div>    
</body>
</html>