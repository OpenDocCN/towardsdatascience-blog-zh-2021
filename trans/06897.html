<html>
<head>
<title>How to Use Horovod’s Large Batch Simulation to Optimize Hyperparameter Tuning for (Highly) Distributed Training</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Horovod的大批量模拟来优化(高度)分布式训练的超参数调整</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-use-horovods-large-batch-simulation-to-optimize-hyperparameter-tuning-for-highly-a815c4ab1d34?source=collection_archive---------20-----------------------#2021-06-22">https://towardsdatascience.com/how-to-use-horovods-large-batch-simulation-to-optimize-hyperparameter-tuning-for-highly-a815c4ab1d34?source=collection_archive---------20-----------------------#2021-06-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="eff8" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><div class=""><h2 id="13a4" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">一个简单的技术可以帮你省下一大笔钱，以及如何将它与混合精确学习相结合</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/718f74639c4018cffa57e785015a1baf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Id7qtDbiDf1qjEoX"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://unsplash.com/@jeremythomasphoto?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">杰瑞米·托马斯</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="2a93" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">受<a class="ae le" href="https://arxiv.org/pdf/1706.02677.pdf" rel="noopener ugc nofollow" target="_blank">加快学习速度</a>的愿望激励，今天深度学习领域的一个常见做法是将培训活动分配给多个工作人员(例如GPU)。在<em class="mb">数据分布式训练</em>中，每个工人并行地对训练数据的不同子集(本地批次)执行训练步骤，向所有其他工人广播其结果梯度，并基于所有工人计算的梯度更新其模型权重。</p><p id="d1a7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在之前的<a class="ae le" rel="noopener" target="_blank" href="/a-guide-to-highly-distributed-dnn-training-9e4814fb8bd3">帖子</a>中，我们扩展了数据分布式培训的一些复杂性和潜在挑战。在本帖中，我们将重点关注在数据分布式训练环境中执行<a class="ae le" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization" rel="noopener ugc nofollow" target="_blank">超参数调整</a>的挑战。</p><p id="5cad" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我要感谢Dennis Kreinovich对分布式训练和混合精度的贡献。</p><h1 id="d3a3" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">介绍</h1><p id="7f61" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">任何深度学习项目必不可少的一部分就是<a class="ae le" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization" rel="noopener ugc nofollow" target="_blank">超参数调优</a>。模型<em class="mb">超参数</em>是我们在运行训练算法之前修复的所有控制设置。它们不同于在训练期间学习的模型<em class="mb">参数</em>。常见超参数的示例包括:</p><ul class=""><li id="b630" class="mz na iq lh b li lj ll lm lo nb ls nc lw nd ma ne nf ng nh bi translated">优化器设置:优化器的选择和控制它的设置，例如<em class="mb">学习率</em>。</li><li id="5848" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">模型架构:模型层的选择，它们是如何组合在一起的，以及它们是如何配置的。这包括每层的通道数、卷积核的大小、正则化设置、辍学率、批量归一化设置、激活函数的选择等设置。</li><li id="ddfe" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">损失函数:损失函数的选择及其各自的配置设置。</li></ul><p id="de5b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">不用说，超参数的选择对我们训练算法的成功有决定性的影响。<em class="mb">超参数整定</em> (HPT)指的是为这些超参数寻找最优值的艺术，也就是寻找最终会导致最优训练结果的值。应当注意，对超参数的所有可行组合进行完全搜索实际上是不可能的。在实践中，大多数团队会修正大量的超参数，并将HPT限制到训练控制的子集。它们可以通过限制剩余超参数的搜索空间来进一步简化问题。</p><p id="e5b8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">每一个成功的深度学习项目都包括某种形式的HPT，即使在名称上没有明确地这样称呼。当你尝试使用额外的卷积层或信道，或者使用不同的学习率、正则化值、退出率或激活层来训练你的模型，只是为了看看它如何影响你的结果的质量时，你正在执行HPT。当然，你在HPT战略上投入的越多，你成功的可能性就越大。以下是影响HPT战略优势的一些方面。</p><p id="c641" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> 1。高级参数搜索算法</strong> <br/>给定一个参数搜索空间，有多种方法可以进行搜索。琐碎的算法有<em class="mb">随机搜索</em>和<em class="mb">网格搜索</em>。在<em class="mb">随机搜索</em>中，我们随机选择参数组合。在<em class="mb">网格搜索</em>中，我们将搜索空间分成一个网格，并在网格的交叉点上测试组合。然而，有许多基于<a class="ae le" href="https://en.wikipedia.org/wiki/Bayesian_optimization" rel="noopener ugc nofollow" target="_blank">贝叶斯优化</a>的更高级的算法，已经被证明比<em class="mb">随机搜索</em>和<em class="mb">网格搜索</em>执行得好得多(例如，参见这里的<a class="ae le" href="https://proceedings.neurips.cc/paper/2012/file/05311655a15b75fab86956663e1819cd-Paper.pdf" rel="noopener ugc nofollow" target="_blank"/>)。在撰写本文时，深度学习的HPT搜索算法仍然是一个活跃的研究领域。</p><h2 id="3fc9" class="nn md iq bd me no np dn mi nq nr dp mm lo ns nt mo ls nu nv mq lw nw nx ms iw bi translated">2.实验并行化</h2><p id="4957" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">显然，并行运行实验将加速HPT阶段，使您能够更快地得出关于最佳超参数的结论。然而，由于并行运行N个实验，潜在的好处可能比线性(乘以N)加速要大得多。这是因为并行化增加了实验提前终止的可能性。让我们通过一个简单的例子来证明这一点。假设我们将HPT算法定义如下:</p><ul class=""><li id="ccbe" class="mz na iq lh b li lj ll lm lo nb ls nc lw nd ma ne nf ng nh bi translated">每个实验最多训练8个时期(或固定步数),并在每个时期后评估准确度。</li><li id="d892" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">在每个时期之后，我们将每个实验的准确度与达到相同步骤的所有其他实验的准确度结果进行比较。任何精度比最高计算精度差10%以上的实验都将被终止。当一个实验提前停止时，它的相关资源可以用于后续的实验。</li><li id="f80a" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">如果一个实验是唯一剩下的实验，或者如果它以最高的准确度完成了8个时期，则该实验被宣布为获胜者。</li></ul><p id="f130" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，假设在我们的HPT中的给定阶段，我们正在运行4个实验，这些实验将产生下表所示的精度:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ny"><img src="../Images/b2ad1ab4afedc7c884ac6968a7689ab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WpFQvGaKOLsIcqMO3xyZdw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">样本精确度</p></figure><p id="2269" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果我们并行运行所有四个试验，我们将在1个时期后终止试验3，在2个时期后终止试验2，在4个时期后终止试验1和试验4，此时试验4将被宣布为获胜者。给定阶段将总共运行11个时期。另一方面，如果我们在实验中选择随机顺序并按顺序运行它们，通过应用简单的概率论定律，我们会发现总时期数的<em class="mb">期望值</em>将是19.6。在这种情况下，并行化带来了44%的预期节省。虽然这个例子是人为设计的，但是节省这么多钱的可能性并不遥远。节省的潜力只会随着并行化程度的增加而增加。</p><h2 id="b25e" class="nn md iq bd me no np dn mi nq nr dp mm lo ns nt mo ls nu nv mq lw nw nx ms iw bi translated">3.自动化</h2><p id="90ac" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">可以想象，人们可以定义参数搜索空间，选择HPT算法，手动实例化所有实验，并监控它们的进展。然而，HPT算法的手动实现可能缓慢、乏味，并且极易出错。更好的建议是将HPT自动化。有许多工具和库支持HPT自动化。这些不同之处在于它们为不同的训练环境、搜索算法、并行化、早期停止等提供的支持。最流行的库之一(在撰写本文时)是<a class="ae le" href="https://docs.ray.io/en/master/tune/index.html" rel="noopener ugc nofollow" target="_blank"> Ray Tune </a>，它支持各种各样的训练框架、前沿搜索算法和实验并行化。我希望在以后的文章中扩展HPT框架。</p><p id="cb5a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这篇博文的重点是实验并行化，或者更具体地说，是在分布式训练环境中运行并行实验的挑战。我们将在下一节介绍这一挑战。</p><h1 id="dbc9" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">挑战——分布式培训环境中的HPT</h1><p id="9702" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">一个强有力的HPT战略对于一般培训同样重要，对于分布式培训更是如此。这是由于以下两个因素:</p><ol class=""><li id="de55" class="mz na iq lh b li lj ll lm lo nb ls nc lw nd ma nz nf ng nh bi translated"><strong class="lh ja">调优的复杂性</strong>:数据分布式训练的净效应是训练批量的显著增加。用<em class="mb"> k </em>表示工人数量，用<em class="mb"> b </em>表示本地批量，对<em class="mb"> k </em>工人进行分布式训练的结果是，在每一个训练步骤中，模型在一个全局批量<em class="mb"> k*b </em>样本上进行训练。正如我们在<a class="ae le" rel="noopener" target="_blank" href="/a-guide-to-highly-distributed-dnn-training-9e4814fb8bd3">上一篇文章</a>中所讨论的，随着批量的增加，HPT会变得更加困难。可能需要更高级的优化器(如<a class="ae le" href="https://arxiv.org/abs/1904.00962" rel="noopener ugc nofollow" target="_blank"> LAMB </a>和<a class="ae le" href="https://arxiv.org/abs/1708.03888" rel="noopener ugc nofollow" target="_blank"> LARS </a>)，以及更精细的优化器设置调整。此外，最佳超参数可能高度依赖于全局批次的大小。大小为X的全局批次的调整结果可能与大小为y的全局批次的调整结果非常不同。</li><li id="cbda" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma nz nf ng nh bi translated"><strong class="lh ja">调整成本</strong>:在高度分散的环境中，培训的成本可能相当高。在单个GPU设置中可以容忍的HPT策略(例如使用原始搜索算法)的低效率在高成本的分布式设置中是不可原谅的。我们在这里和本文的其余部分提到的成本可以是使用基于云的培训服务的价格，也可以是过度使用公司内部培训资源的机会成本。</li></ol><p id="7bdb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">正如我们在上面看到的，强HPT策略的技术之一是并行化调优实验。并行化既可以加快整个过程，又可以通过提前终止实验来节省成本。在多员工环境中，这种成本节约非常显著。然而，当尝试并行化高度分布式的训练实验时，您可能会发现自己面临一个重大挑战，我们将通过下面的简单示例来演示这个挑战:</p><p id="ed43" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">假设，如本文中的<a class="ae le" href="https://arxiv.org/pdf/1706.02677.pdf" rel="noopener ugc nofollow" target="_blank">所示，您已经选择在256个GPU上进行训练，并且您的HPT算法的给定阶段需要并行运行8个实验。通过简单的计算，我们发现您将需要2048个GPU来并行运行您的HPT！！您可能没有这个数量的GPU，即使您有，运行您的HPT每小时的成本可能会非常高。例如，云中的2048个GPU可以轻松地花费数千美元/小时。</a></p><h2 id="d27a" class="nn md iq bd me no np dn mi nq nr dp mm lo ns nt mo ls nu nv mq lw nw nx ms iw bi translated">循环实验</h2><p id="62f3" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">您可以考虑的一个替代实验并行化的选项是以循环方式一次一个时期地执行每个实验。例如，在上面的例子中，我们将在256个GPU上运行第一个实验一个时期，然后第二个，然后第三个，直到第八个实验。此时，我们将比较中间结果，决定终止哪些实验，然后继续运行第二个时期的剩余实验，然后是第三个时期，依此类推。虽然这种方法花费的时间是完全并行化的8倍，但它能够实现相同类型的实验提前终止，并导致运行相同总数的时期。这种方法的问题是，实验之间的上下文切换(包括捕获和保存模型状态以及重建计算图)可能会引入大量开销，尤其是在分布式训练设置中。因此，早期终止实验的能力所带来的总体成本节约将低于并行化的情况。</p><p id="27ae" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们在这篇文章中提出的解决方案是通过使用<em class="mb">大批量模拟</em>在更少的工人身上运行平行实验。</p><h1 id="52ef" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">大批量模拟</h1><p id="1ac2" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">在<em class="mb">大批量模拟</em> (LBS)中，我们仅使用<em class="mb"> Y ( &lt; X) </em>工人来模拟对<em class="mb"> X </em>工人的培训，其中<em class="mb"> Y </em>是<em class="mb"> X </em>的除数，通过在<em class="mb"> Y </em>工人上运行与我们在<em class="mb"> X </em>工人上相同的全局批量。例如，假设在上一节中看到的示例中，本地(每个工作线程)批处理大小为32，全局批处理大小为8192 (32x256)。使用LBS，我们可以在32个GPU(而不是256个)上并行运行8个HPT实验中的每一个，这样每次运行都将使用大小为256(而不是32)的本地批处理。全局批处理的结果大小将是8192，与我们在256个GPU上运行时的大小相同。这样，当并行运行8个实验(每个实验使用32个GPU)时，我们在HPT期间将使用与培训期间相同的256个GPU。这里的8个实验也比完全并行化花费更多的时间(超过2048个GPU)。然而，提前终止实验所节省的成本将等同于完全并行化所节省的成本。(事实上，由于梯度共享消息数量的减少，它甚至可能会更好一点。)</p><p id="0dcb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果有可能随意增加培训工人的本地批量，实施BTS将是微不足道的。然而，在现实中，批量的大小受到培训工作者的可用内存的限制。为了克服这一点，我们将使用一种叫做<em class="mb">梯度聚合</em>的技术。</p><h2 id="5bb1" class="nn md iq bd me no np dn mi nq nr dp mm lo ns nt mo ls nu nv mq lw nw nx ms iw bi translated">梯度聚合</h2><p id="d7eb" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">在典型的训练步骤中，我们执行向前传递以计算本地批次的损失，执行向后传递以计算梯度，将结果传播给其他工人，然后根据所有工人计算的梯度更新模型权重。当我们执行梯度聚合时，我们不是立即共享和应用梯度，而是在预定义数量的步骤中收集它们，然后才广播它们的平均值并更新权重。用<em class="mb"> B </em>表示本地批量大小，在<em class="mb"> N </em>步上执行梯度累加的效果将与用本地批量大小<em class="mb"> N </em> x <em class="mb"> B </em>进行训练相同。并且在具有规模为<em class="mb"> B </em>的本地批次和具有<em class="mb"> Y </em>的工人的<em class="mb"> N </em>个步骤上运行梯度聚合，将与具有规模为<em class="mb"> B </em>的本地批次和具有<em class="mb">X</em>=<em class="mb">N</em>X<em class="mb">Y</em>个工人的培训具有相同的效果。</p><p id="c0e7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这种用于模拟大批量的技术依赖于梯度计算的线性，即依赖于批量大小<em class="mb">K</em>=<em class="mb">N</em>x<em class="mb">B</em>的梯度与批量大小<em class="mb">N</em>B<em class="mb">B</em>的梯度平均值之间的等价性。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/60053cb5ad11110d4c170ade4eb20a29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*PWehupv8-7nopMvjYu8MiQ.png"/></div></figure><p id="f10d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">总之，我们提出的解决方案是使用<em class="mb"> Y </em>工人模拟一个有<em class="mb"> N </em> x <em class="mb"> Y </em>工人的培训课程，通过对每个工人的<em class="mb"> N </em>步执行梯度聚合。</p><h2 id="7c07" class="nn md iq bd me no np dn mi nq nr dp mm lo ns nt mo ls nu nv mq lw nw nx ms iw bi translated">使用Horovod的大批量模拟</h2><p id="cc5b" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated"><a class="ae le" href="https://horovod.readthedocs.io/en/stable/index.html" rel="noopener ugc nofollow" target="_blank"> Horovod </a>是一个流行的库，用于执行分布式培训，广泛支持TensorFlow、Keras、PyTorch和Apache MXNet。Horovod的工作方式是将梯度共享引入梯度计算步骤。虽然有各种方法来实例化Horovod，但一种常见的方法是使用<em class="mb">distributed optimizer</em>API将您的训练优化器与Horovod优化器包装在一起，如下面的TensorFlow代码片段所示。更多详情参见<a class="ae le" href="https://horovod.readthedocs.io/en/stable/summary_include.html#id9" rel="noopener ugc nofollow" target="_blank"> Horovod文档</a>。</p><pre class="kp kq kr ks gt ob oc od oe aw of bi"><span id="7984" class="nn md iq oc b gy og oh l oi oj">import horovod.tensorflow.keras as hvd<br/><em class="mb"># Initialize Horovod</em><br/>hvd.init()<br/><em class="mb"># Pin GPU, build model, and configure optimizer</em><br/>opt = ...<br/><em class="mb"># Wrap optimizer with Horovod Distributed Optimizer</em><br/>opt = hvd.DistributedOptimizer(opt)</span></pre><p id="91fb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">从0.21版本开始，<em class="mb"> DistributedOptimizer </em> API新增了两个用于编程梯度聚合的标志:<em class="mb"> backward_passes_per_step </em>和<em class="mb">average _ aggregated _ gradients</em>。当<em class="mb"> backward_passes_per_step </em>设置为大于1的值时，Horovod将在后台使用一个梯度聚合器，该聚合器将在选择的步数上累积梯度，然后共享它们并使用它们将更新应用于模型权重。<em class="mb">average _ aggregated _ gradients</em>决定是否在共享累积的梯度之前对其进行平均。在下面的代码块中，我们展示了如何修改Horovod设置代码，以便将有效的全局批处理大小增加8倍:</p><pre class="kp kq kr ks gt ob oc od oe aw of bi"><span id="9331" class="nn md iq oc b gy og oh l oi oj">import horovod.tensorflow.keras as hvd<br/><em class="mb"># Initialize Horovod</em><br/>hvd.init()<br/><em class="mb"># Pin GPU, build model, and configure optimizer</em><br/>opt = ...<br/><em class="mb"># Wrap optimizer with Horovod Distributed Optimizer</em><br/>opt = hvd.DistributedOptimizer(<br/>                      opt, <br/>                      <em class="mb">backward_passes_per_step=8,                 <br/>                      average_aggregated_gradients=True</em>)</span></pre><h2 id="a051" class="nn md iq bd me no np dn mi nq nr dp mm lo ns nt mo ls nu nv mq lw nw nx ms iw bi translated">小心使用</h2><p id="99a3" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">虽然现代深度学习框架为您可能想要做的几乎所有事情提供了高级API，但深入了解正在发生的事情总是一个好主意，例如，模型层如何工作，您选择的优化器正在运行什么操作，以及在训练步骤中实际发生了什么。当你试图做一些与众不同的事情时，比如LBS，尤其如此。否则，你可能会发现你的程序失败了，却不知道为什么。以下是一些需要注意的例子:</p><p id="0cc9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">定期更新超参数</strong>:当使用<em class="mb"> Y </em>工人模拟具有<em class="mb">X</em>=<em class="mb">N</em>X<em class="mb">Y</em>的培训环境时，需要注意的是，<em class="mb"> X </em>工人环境中的每一步都相当于<em class="mb"> Y </em>工人环境中的<em class="mb"> N </em>步。一些训练算法要求对优化器超参数进行定期更新。例如，通常的做法是使用<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler" rel="noopener ugc nofollow" target="_blank">学习率调度器</a>以固定的迭代步骤调整优化器学习率。为了使模拟正常工作，我们需要通过将更新的预定步骤乘以系数<em class="mb"> N </em>来修改超参数变化的时间表。</p><p id="806f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">对梯度</strong>的非线性运算:我们所描述的LBS技术依赖于梯度计算的线性，也就是说，依赖于一批大小为<em class="mb"> N </em> x <em class="mb"> B </em>的梯度与一批大小为<em class="mb">N</em>B的梯度的平均值之间的等价性。一些训练算法可能要求对梯度执行非线性操作。非线性操作的一个例子是梯度裁剪。只要这种非线性仅在完全累积的梯度上执行(即，仅在应用梯度时在台阶上执行)，就不会有问题。请注意，TensorFlow 2.5中的默认行为是对聚集的梯度执行裁剪(参见此处的<a class="ae le" href="https://github.com/tensorflow/tensorflow/blob/114f88e75330cc9fb2201830431b5e3b8e944e53/tensorflow/python/keras/optimizer_v2/optimizer_v2.py" rel="noopener ugc nofollow" target="_blank"/>)。</p><p id="c50a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">在正向传递过程中对模型参数的更新</strong>:我们已经描述的梯度聚集技术通过<em class="mb">反向传递每一步</em>步骤来延迟梯度更新对模型权重的应用。然而，除了梯度更新，我们还需要考虑模型参数的其他更新。在正向传递期间发生的模型参数更新的一个例子是在<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization" rel="noopener ugc nofollow" target="_blank">批标准化</a>层中移动统计的重新计算。假设这些统计数据是在主要(0级)工作人员上计算的(例如，我们不<a class="ae le" href="https://horovod.readthedocs.io/en/latest/_modules/horovod/torch/sync_batch_norm.html" rel="noopener ugc nofollow" target="_blank">同步</a>跨工作人员的批处理标准化统计数据)，我们需要考虑到在模拟环境中，0级工作人员将看到的数据量将是<em class="mb">backward _ passes _ per _ step</em>乘以0级工作人员在原始环境中看到的数据量。尽管批处理规范化统计数据往往会很快被整理出来，但是这种差异可能会导致评估指标的差异。</p><p id="ca28" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这篇文章的附录中，我们描述了如何将LBS与<a class="ae le" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank">混合精度</a>训练结合起来，这个用例进一步证明了谨慎的必要性。</p><p id="2e5d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在下一节中，我们将在一些简单的实验中演示LBS的使用。</p><h1 id="2009" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">实验</h1><p id="d2e0" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">以下实验是在<a class="ae le" href="https://aws.amazon.com/ec2/instance-types/g4/" rel="noopener ugc nofollow" target="_blank"> Amazon EC2 G4 </a>实例上运行的。对于单个GPU实验，我们使用g4dn.2xlarge实例，对于四个GPU实验，我们使用g4dn.12xlarge实例。实验在TensorFlow版本2.4.1和Horovod版本0.21.0上运行。对于所有实验，我们运行了官方的<a class="ae le" href="https://github.com/horovod/horovod/blob/master/examples/tensorflow2/tensorflow2_keras_mnist.py" rel="noopener ugc nofollow" target="_blank"> Horovod tf.keras mnist </a>示例，并做了以下更改:</p><ul class=""><li id="1d0f" class="mz na iq lh b li lj ll lm lo nb ls nc lw nd ma ne nf ng nh bi translated">我们应用了附录中描述的必要更改来支持混合精度的LBS。</li><li id="e6c1" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">对于混合精度测试，我们对模型进行了以下突出显示的调整(参见<a class="ae le" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank">混合精度</a>文档以了解变化):</li></ul><pre class="kp kq kr ks gt ob oc od oe aw of bi"><span id="974e" class="nn md iq oc b gy og oh l oi oj"><strong class="oc ja">policy = tf.keras.mixed_precision.Policy('mixed_float16')<br/>tf.keras.mixed_precision.set_global_policy(policy)</strong></span><span id="2b20" class="nn md iq oc b gy ok oh l oi oj">mnist_model = tf.keras.Sequential([<br/>    tf.keras.layers.Conv2D(32, [3, 3], activation='relu'),<br/>    tf.keras.layers.Conv2D(64, [3, 3], activation='relu'),<br/>    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),<br/>    tf.keras.layers.Dropout(0.25),<br/>    tf.keras.layers.Flatten(),<br/>    tf.keras.layers.Dense(128, activation='relu'),<br/>    tf.keras.layers.Dropout(0.5),<br/>    tf.keras.layers.Dense(10),<br/>    tf.keras.layers.Activation('softmax', <br/>                               <strong class="oc ja">dtype='float32'</strong>, <br/>                               name='predictions')<br/>])</span></pre><ul class=""><li id="1fd7" class="mz na iq lh b li lj ll lm lo nb ls nc lw nd ma ne nf ng nh bi translated">为了运行LBS，我们将<em class="mb"> backward_passes_per_step </em>设置为4，并相应地更新了学习率。</li></ul><p id="f930" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在下面的图表中，我们绘制了四个实验的精度与历元数的函数关系图:在有和没有混合精度设置的情况下在4个GPU上进行分布式训练，以及在单个GPU上运行相应的大批量模拟。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/2a298813b600e1a8eb97dcd6d5a2f0bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*OxEpbBWskS6J6Sx6ZXPbXA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">每个历元的精度</p></figure><p id="cbc7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在所有情况下，我们看到精度遵循类似的收敛模式。虽然这是在一个简单的模型上演示的，但我们可以看到使用混合精度训练和大批量模拟的潜力。</p><h1 id="0865" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">结束语</h1><p id="104e" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">在本帖中，我们重点讨论了如何使用LBS来解决在高度分散的训练环境中进行HPT的挑战。LBS还可以在许多其他场景中发挥作用。这里有一些例子。</p><h2 id="b61e" class="nn md iq bd me no np dn mi nq nr dp mm lo ns nt mo ls nu nv mq lw nw nx ms iw bi translated">批量调整</h2><p id="bca0" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">在整篇文章中，我们假设培训工人的数量和全局批量大小都是固定的，并相应地解决了调整其他超参数的挑战。当然，在现实中，两者都可以被视为需要调整的超参数。我们讨论的LBS技术提供了一种调整批量大小和评估工人数量的选择如何影响培训质量的创造性方法。这可以通过在多台机器上运行平行实验来完成，每台机器的<em class="mb">向后_走刀_每步</em>设置值不同。</p><h2 id="9508" class="nn md iq bd me no np dn mi nq nr dp mm lo ns nt mo ls nu nv mq lw nw nx ms iw bi translated">增加单个实例的批量大小</h2><p id="455f" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">可能存在这样的情况，其中以大批量运行可能不是数据分布式训练的强制副作用，而是用于提高训练性能的期望工具。在这种情况下，可以使用LBS来解决内存约束带来的批量限制，并在我们想要的批量上运行训练。</p><h2 id="7936" class="nn md iq bd me no np dn mi nq nr dp mm lo ns nt mo ls nu nv mq lw nw nx ms iw bi translated">动态GPU编排</h2><p id="2f8b" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">现代人工智能公司面临的挑战之一是如何在多个团队和项目中最有效地分配培训资源。培训资源非常昂贵，而且有强烈的经济动机来最大限度地利用这些资源。一种常见的策略是根据团队的需求和项目优先级在团队之间动态分配GPU。这种策略的效果是，在培训的不同阶段，你可以接触到不同数量的工人。</p><p id="c8b6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果您依赖低成本的“现场”实例进行培训，也会出现类似的情况。许多云服务提供商为多余的计算实例提供大幅折扣。在AWS中这些被称为<a class="ae le" href="https://aws.amazon.com/ec2/spot/?cards.sort-by=item.additionalFields.startDateTime&amp;cards.sort-order=asc" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">亚马逊EC2 Spot实例</strong> </a>，在Google Cloud中它们被称为<a class="ae le" href="https://cloud.google.com/compute/docs/instances/preemptible" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">可抢占VM实例</strong> </a>，在微软Azure中它们被称为<a class="ae le" href="https://docs.microsoft.com/en-us/azure/batch/batch-low-pri-vms" rel="noopener ugc nofollow" target="_blank"> <strong class="lh ja">低优先级VM</strong></a>。代价是，如果对它们的需求增加，这样的实例可以在使用过程中终止。你会再次发现，在培训过程中，分配的员工数量在不断变化。</p><p id="c07f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">考虑到资源分配中这种变化的可能性，明智的做法是在设计培训时考虑到这种可能性。具体来说，在任何给定的时间，您都希望利用尽可能多的可用工作人员，但也不希望重新分配其中的一部分。一个策略可能是天真地培训任何数量的可用工人。然而，全球批量将根据工人数量而变化，正如我们已经看到的，在每种情况下成功的培训并不总是简单的调整<em class="mb">学习率</em>。基于LBS的另一种策略是在各种情况下保持相同的有效批量。下面是这种工作方式的一个例子:</p><p id="8c11" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">假设您设计您的模型来培训最多256名工人，本地批量为<em class="mb"> B </em>。然而，当你开始培训时，你发现只有128名工人可用。使用伦敦商学院，你可以开始对128名工人进行培训，有效的本地批次规模为<em class="mb"> 2 </em> x <em class="mb"> B </em>。现在假设培训开始一小时后，分配给你的员工数量下降到128人以下。同样，使用LBS，您可以重新设置您对64名工人的培训，进行有效的本地批量<em class="mb"> 4 </em> x <em class="mb"> B </em>培训。稍后，资源可能会开始释放，并且可能会重新设置您的培训，以便在256名员工上运行。</p><p id="0009" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">理论上，我们甚至可以通过使用<a class="ae le" href="https://horovod.readthedocs.io/en/stable/elastic_include.html" rel="noopener ugc nofollow" target="_blank"> Elastic Horovod </a>来实施这一策略，而无需停止和重新开始训练，这是Horovod的一个引人注目的功能，即使在分配的资源数量发生变化的情况下，也可以进行不间断的训练。然而，在撰写本文时，Horovod APIs不支持对<em class="mb">backward _ passes _ per _ step</em>设置的动态更新。想了解更多关于弹性按摩棒好处的信息，请看这篇<a class="ae le" rel="noopener" target="_blank" href="/cost-efficient-distributed-training-with-elastic-horovod-and-amazon-ec2-spot-instances-599ea35c0700">最近的文章</a>。</p><h1 id="0e47" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">摘要</h1><p id="ae2b" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">数据分布式培训带来了许多独特的挑战。幸运的是，这些挑战也是创新和创造力的机会。在这篇文章中，我们接受了在高度分散的训练环境中超参数调整的挑战。我们已经展示了如何使用Horovod的梯度聚合支持来实现并行实验以及随之而来的潜在成本效益。高度分散的培训可能很昂贵，应该充分探索任何降低成本的机会。</p><h1 id="c139" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">附录:结合大批量模拟和混合精度学习</h1><p id="ef04" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi translated">在<a class="ae le" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank">混合精度</a>训练中，我们在训练期间混合了16位和32位浮点类型，而不是仅使用32位浮点类型。这个特性可以显著节省运行时间和内存使用。</p><p id="74ec" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这篇文章中，我们将重点关注TensorFlow提供的<a class="ae le" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank">混合精度</a>支持，尽管我们要说的大部分内容也适用于其他框架。关于混合精度的TensorFlow <a class="ae le" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank">指南</a>很好地概述了混合精度如何工作以及如何配置。我们将提到与我们的讨论相关的一些混合精度训练的元素。</p><ul class=""><li id="2021" class="mz na iq lh b li lj ll lm lo nb ls nc lw nd ma ne nf ng nh bi translated">使用16位浮点编程时，主要关注的是由于较低的位精度导致的数值<a class="ae le" href="https://www.tensorflow.org/guide/mixed_precision#underflow_and_overflow" rel="noopener ugc nofollow" target="_blank">下溢或上溢</a>。实际上，当执行混合精度训练时，最关心的是梯度计算期间下溢的可能性。</li><li id="8ccf" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">TensorFlow支持两种16位精度浮点类型，float16和<a class="ae le" href="https://en.m.wikipedia.org/wiki/Bfloat16_floating-point_format" rel="noopener ugc nofollow" target="_blank"> bfloat16 </a>。bfloat16类型的指数位数与float32一样多，并且能够表示相同范围的数字。因此，bfloat16型不存在下溢问题。虽然有许多处理器支持bfloat16，但在撰写本文时，TensorFlow的正式版本只支持Google TPUs上的bfloat16。查看<a class="ae le" rel="noopener" target="_blank" href="/how-floating-point-numbers-work-1429907b6d1d">这篇文章</a>中关于浮点表示如何工作的有趣概述。</li><li id="9341" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">使用float16时，克服下溢可能性的方法是执行<a class="ae le" href="https://www.tensorflow.org/guide/mixed_precision#loss_scaling_overview" rel="noopener ugc nofollow" target="_blank">损失缩放</a>。当我们使用损失缩放时，我们在计算梯度之前将损失乘以一个缩放因子，然后在将它们应用于模型权重之前将结果梯度除以相同的因子。通过选择适当的比例因子，我们可以降低下溢的可能性。在TensorFlow中，该过程在<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/LossScaleOptimizer" rel="noopener ugc nofollow" target="_blank">losscale optimizer</a>中实现。执行的步骤有:<br/> 1。衡量损失<br/> 2。计算梯度<br/> 3。取消渐变比例<br/> 4。如果所有梯度都是有限的，则将它们应用于权重<br/> 5。如果需要，根据当前梯度的统计数据更新比例因子</li></ul><p id="d148" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">既然分布式训练和混合精确训练都有加速训练的共同目标，我们自然会对两者的结合感兴趣。特别是，我们需要基于LBS的解决方案来执行混合精度的HPT。遗憾的是，Horovod中LBS的当前默认实现与TensorFlow中的<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/LossScaleOptimizer" rel="noopener ugc nofollow" target="_blank">losscale optimizer</a>的默认实现不兼容。然而，幸运的是，通过对每个特性进行小的修改，这些特性可以通过编程和谐地工作。以下是将LBS与混合精度相结合时需要解决的问题:</p><ol class=""><li id="bf58" class="mz na iq lh b li lj ll lm lo nb ls nc lw nd ma nz nf ng nh bi translated"><strong class="lh ja">处理梯度中的Nan值</strong>:损失缩放的副作用之一是，由于数值溢出，我们可能偶尔会在梯度中得到Nan或Inf值。如果<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/LossScaleOptimizer" rel="noopener ugc nofollow" target="_blank"> LossScaleOptimizer </a>遇到这样的值，它简单地丢弃梯度并继续下一步。然而，目前Horovod中的梯度聚合代码没有考虑Nan值的可能性。这个问题的细节以及建议的修改可以在<a class="ae le" href="https://github.com/horovod/horovod/issues/2957" rel="noopener ugc nofollow" target="_blank">这里</a>找到，但是需要覆盖默认的Horovod行为。希望这将在Horovod的未来版本中得到解决。</li><li id="6921" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma nz nf ng nh bi translated"><strong class="lh ja">何时更新缩放系数</strong>:如上所述，<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/LossScaleOptimizer" rel="noopener ugc nofollow" target="_blank">losscale optimizer</a>基于梯度统计对缩放系数进行周期性更新。在上一节中，我们建议在LBS期间应用超参数的定期更新时要谨慎。在这种情况下，如果我们不能将缩放系数的更新与我们应用(和重置)聚集梯度的步骤对齐，我们不仅会在大批量模拟中失败，而且还可能会完全无法训练。如果梯度在其缩放状态下累积(例如TensorFlow 2.3)，并且我们在累积期间重置缩放，则聚集的梯度将具有不匹配的缩放系数。因此，得到的未缩放梯度将是不正确的。即使梯度在其未缩放的状态下被累积(例如TensorFlow 2.4和2.5)，也有可能<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/LossScaleOptimizer" rel="noopener ugc nofollow" target="_blank">losscale optimizer</a>将无法找到合适的缩放因子。<br/>为了解决这个问题，您需要覆盖由<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/LossScaleOptimizer" rel="noopener ugc nofollow" target="_blank">lossscaleproptimizer</a>调用的损失比例<a class="ae le" href="https://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/python/keras/mixed_precision/loss_scale_optimizer.py#L325" rel="noopener ugc nofollow" target="_blank">更新</a>函数，以便损失比例更新仅应用于梯度聚合器被重置的步骤。见<a class="ae le" href="https://github.com/horovod/horovod/issues/2957" rel="noopener ugc nofollow" target="_blank">这里</a>有一种方法可以解决这个问题。</li><li id="5a2e" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma nz nf ng nh bi translated"><strong class="lh ja">梯度量化的非线性</strong>:需要记住的一点是，使用低精度时固有的量化构成了对梯度的非线性操作。事实上，你很可能会发现一批尺寸为<em class="mb"> N </em> x <em class="mb"> B </em>的梯度和<em class="mb"> N </em>批尺寸为<em class="mb"> B </em>的梯度的平均值之间存在很小的数字差异。当然，即使使用32位浮点数，量化也是存在的，但是数量上的影响远没有那么明显。尽管如此，我们还没有发现由于非线性而影响训练的数值差异，但是知道这一点是有好处的。</li></ol><p id="8fbc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">请注意，根据您使用的TensorFlow版本，可能需要进行一些额外的更改，以便将这两种功能结合起来。更多详情见<a class="ae le" href="https://github.com/horovod/horovod/issues/2957" rel="noopener ugc nofollow" target="_blank">此处</a>。</p></div></div>    
</body>
</html>