<html>
<head>
<title>Bayesian Approximated Neural Network Example via JAX</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过JAX的贝叶斯近似神经网络示例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bayesian-approximated-neural-network-example-via-jax-flexible-parameter-distributions-for-odes-9b4a7f79b493?source=collection_archive---------21-----------------------#2021-10-20">https://towardsdatascience.com/bayesian-approximated-neural-network-example-via-jax-flexible-parameter-distributions-for-odes-9b4a7f79b493?source=collection_archive---------21-----------------------#2021-10-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="de83" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">常微分方程的灵活参数分布</h2></div><p id="fc42" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然存在几种已知的方法来近似ode的参数分布(特别是<a class="ae lb" href="https://docs.pymc.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> PyMC3 </a>)，但这种概念验证方法在不提供先验分布的情况下估计未知分布。使用神经网络中的漏失概念作为模型不确定性的贝叶斯近似形式，可以通过训练的神经网络的采样来近似灵活的参数分布。</p><p id="7424" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于具有由给定神经网络学习的灵活输出分布的优势，理论上预测可以更好地拟合伴随有模型不确定性而不是硬离散数字的真实生活数据。对于许多业务场景，尤其是与医疗保健行业的患者护理相关的业务场景，拥有这些预测信息是必不可少的。毕竟，当模型的可解释性或置信度未知时，医生为什么要根据给定患者的图表考虑稳健模型的输出以获得更好的药物治疗呢？在做出关键决策时，我们当然希望对模型的预测有所了解。当将这种方法与常微分方程(ODE)甚至常微分方程系统相结合时，可以更容易更有效地对复杂的真实世界动力学进行建模，而同时仍然应用一些刚性结构(以增加可解释性)。可以导出模型不确定性和灵活的ODE参数分布，而不必对潜在参数“可能”是什么做出有影响的先验假设。</p><p id="b4fc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">启发我的是这篇论文:</p><p id="6937" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">【arxiv.org T2】【1506.02142】作为贝叶斯近似的辍学:表示深度学习中的模型不确定性】</p><p id="9efb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文中的示例用于估算一个简单ODE所需的两个参数，dy/dt = -r * y。一个参数用于增长率r，另一个参数用于对某个t进行积分的初始y值。概念验证的一个期望是可视化t轴上的输出分布，并有可能在t轴上具有可变分布。通过对经过训练的贝叶斯神经网络进行采样(通过丢弃)，我们可以预期近似的ODE参数分布是灵活的，因此不能保证是一致的。我发现这对于更复杂的情况是非常强大和有用的，而不必提供一些假设的先验分布，因为神经网络将近似参数分布，并且还可以扩展以及支持连续/在线训练。</p><p id="60e7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我更喜欢将变量依赖关系保存在外部，而不是内嵌，但是我想提供一个工作的单个文件脚本，以便更容易地查看所有引用的函数和变量。下面是单个文件中的完整代码(文件:<strong class="kh ir">Bayesian _ appx _ nn _ ex _ jax . py</strong>):</p><div class="lc ld gp gr le lf"><a href="https://github.com/bmurders2/Bayesian-Approximated-Neural-Networks-for-Flexible-ODE-Parameter-Distributions" rel="noopener  ugc nofollow" target="_blank"><div class="lg ab fo"><div class="lh ab li cl cj lj"><h2 class="bd ir gy z fp lk fr fs ll fu fw ip bi translated">GitHub-bmurders 2/用于灵活模式参数分布的贝叶斯近似神经网络…</h2><div class="lm l"><h3 class="bd b gy z fp lk fr fs ll fu fw dk translated">使用贝叶斯近似神经网络的工作概念证明，通过漏失获得灵活的参数…</h3></div><div class="ln l"><p class="bd b dl z fp lk fr fs ll fu fw dk translated">github.com</p></div></div><div class="lo l"><div class="lp l lq lr ls lo lt lu lf"/></div></div></a></div><p id="e79c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Python文件依赖于以下包:</p><ul class=""><li id="6cb7" class="lv lw iq kh b ki kj kl km ko lx ks ly kw lz la ma mb mc md bi translated">numpy</li><li id="fff7" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">熊猫</li><li id="0463" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">matplotlib</li><li id="4989" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">海生的</li><li id="aa4a" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">jax[cpu] ( <a class="ae lb" href="https://github.com/google/jax" rel="noopener ugc nofollow" target="_blank"> JAX </a>)</li></ul><p id="03c5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我在执行Python脚本时的方法依赖于Tensorflow GPU Docker镜像(版本2.6.0，Python 3.6.9)进行加速的GPU CUDA训练。然而，运行这个脚本既不需要Tensorflow也不需要GPU，因为标准的基于CPU的JAX包也可以工作(用列出的包和Python 3.9成功测试)。JAX对<a class="ae lb" href="https://www.tensorflow.org/xla" rel="noopener ugc nofollow" target="_blank"> XLA </a>和<a class="ae lb" href="https://jax.readthedocs.io/en/latest/jax-101/02-jitting.html" rel="noopener ugc nofollow" target="_blank"> JIT </a>的利用甚至对于CPU来说都是惊人的！如果您在执行这个Python文件时碰巧使用了VS代码，那么有一些字符串，#%%，它们是<a class="ae lb" href="https://code.visualstudio.com/docs/python/jupyter-support-py" rel="noopener ugc nofollow" target="_blank"> VS代码的Python交互特性</a>的一部分，用于在处理Python文件时获得类似Jupyter的体验。如果这个Python文件作为Jupyter文件导出，这些字符串将自动创建它们相应的单元格(如果直接在Jupyter笔记本中运行这个带有交互单元格的文件比VS Code的交互窗口特性更好)。</p><p id="e863" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">JAX的实验包包括<a class="ae lb" href="https://github.com/google/jax/blob/main/jax/example_libraries/README.md#neural-net-building-with-stax" rel="noopener ugc nofollow" target="_blank"> Stax </a>直接在JAX境内进行神经网络开发和训练。其他强大的软件包使用JAX创建非常健壮的神经网络，如<a class="ae lb" href="https://github.com/google/trax" rel="noopener ugc nofollow" target="_blank"> Trax </a>，但我认为Stax更容易为这个演示建立原型，不需要JAX以外的其他软件包。Python文件使用以下神经网络超参数:</p><ul class=""><li id="b291" class="lv lw iq kh b ki kj kl km ko lx ks ly kw lz la ma mb mc md bi translated">辍学率值:0.1</li><li id="5b66" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">每层单位:2048</li><li id="71a8" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">隐藏层数:1</li><li id="6d6b" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">主要激活功能:MISH</li></ul><p id="ce9c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然“深”神经网络将允许更鲁棒的拟合，但是这个示例ODE对于单个隐藏层来说足够简单，但是具有“非常宽”的隐藏层(当试图通过神经网络放弃这种贝叶斯近似方法来关联或“近似”高斯过程时，这是一个重要的概念)。对于训练，在对训练数据进行全面训练之前，有一个“好的”猜测是非常重要的。这类似于大多数优化器或最小化算法，其中初始参数值的“坏”猜测可能阻止适当拟合的有效收敛。因此，训练被分成两部分，第一部分用于在对添加了噪声的训练数据进行最终训练之前“启动”神经网络以输出“好的”猜测参数值。采用这种方法将大大有助于在训练期间避免NaN值，因为给定函数的参数可能具有非常陡的梯度，这取决于参数所在的位置。为两个训练实例选择的优化器是JAX的ADAMAX，其步长为2e-3用于启动训练会话，2e-5用于针对添加噪声的训练数据的训练。对于损失训练函数，使用Huber。</p><p id="e73c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在对添加了噪声的训练数据进行训练之后，使用200个样本来确定使用任意预测区间的分位数的输出分布。在这种方法中，使用直接标准差+平均值上的分位数绘制预测区间更有用，因为您不必担心区间会忽略ODE的重要方面，例如跨越目标ODE函数的水平渐近线。<a class="ae lb" href="https://seaborn.pydata.org/index.html" rel="noopener ugc nofollow" target="_blank"> Seaborn </a>和<a class="ae lb" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank"> Matplotlib </a>用于以下地块:</p><ul class=""><li id="8d01" class="lv lw iq kh b ki kj kl km ko lx ks ly kw lz la ma mb mc md bi translated">导出跨t轴的输出样本的密度视觉。</li><li id="8e88" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">样品的外观。</li><li id="b1b9" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">单个样本的图。</li><li id="8363" class="lv lw iq kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">近似ODE参数的分布。</li></ul><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/e7ad85c6a4629a35a7fdb6f4c3609649.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1EJVKjHZvN6YJbf2PSa2ng.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">按作者分类的图像—t轴上输出分布的密度图</p></figure><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/2b371e9fb5bc50cf0fd9f440b4e50d44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uw1K75Fq4TGZIp3R86hAXg.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">按作者分类的图像-输出的等值线视图</p></figure><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi my"><img src="../Images/522e36f681214cfcc4d8a2758abd3daa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cKMVqIVvBG-cTtu1ZsYyzA.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">按作者分类的图像-带有预测间隔的单个样本视图</p></figure><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mz"><img src="../Images/6cd87b1fb9e6eccd75fddf1a9d896add.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ljtSpm7x6djWPSE_UAlyAg.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">按作者分类的图像-参数y(0)的样本分布</p></figure><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi na"><img src="../Images/cc365443134238aa1dc64982f479c44f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3giuFYaDTKgIcVh9MwSx-A.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">按作者分类的图像-参数r的样本分布</p></figure><p id="8b51" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以从近似ODE参数的密度图中看到，它们并不完全一致，这正是我在训练后想要看到的。目标ODE并不太复杂，但是演示这种方法如何灵活地获得非均匀分布才是目标。重要的是，绘制更多的样本可以影响ODE参数估计的可视化近似密度图，但是对于200个样本，对于近似ODE参数密度“是什么”应该是足够的。</p><p id="6e86" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以使用某种形式的增广神经常微分方程，通过这里提出的贝叶斯扭曲，直接逼近该函数。但是，如果我们碰巧对潜在的动态有一些合理的知识或假设，那么利用这种方法会更好。试图用黑盒模型直接模拟潜在动态的一个可能的结果是，我们将无法适当地欣赏参考常微分方程确实存在的水平渐近线。然而，这种方法允许利用神经网络来“学习”目标ODE参数的分布，并给出有用的预测区间和中值输出。我对这种方法很感兴趣，并希望其他人会受到启发，利用概率输出进行数据建模(特别是像神经网络这样的黑盒模型)。</p></div></div>    
</body>
</html>