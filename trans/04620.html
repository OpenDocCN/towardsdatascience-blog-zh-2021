<html>
<head>
<title>Getting Started with Albumentation: Winning Deep Learning Image Augmentation Technique in PyTorch example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">开始使用蛋白沉积:在PyTorch示例中赢得深度学习图像增强技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-started-with-albumentation-winning-deep-learning-image-augmentation-technique-in-pytorch-47aaba0ee3f8?source=collection_archive---------2-----------------------#2021-04-21">https://towardsdatascience.com/getting-started-with-albumentation-winning-deep-learning-image-augmentation-technique-in-pytorch-47aaba0ee3f8?source=collection_archive---------2-----------------------#2021-04-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9c20" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Kaggle CV比赛获奖秘诀？关于如何使用Albumentation库进行图像增强的教程</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/004afd946330ad93a7e235f6f504e7ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*z1tosGMU6M5nakKf"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">克里斯汀娜面粉在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="3e6b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">无论你是安静地参加Kaggle比赛，试图学习一种新的酷Python技术，还是数据科学/深度学习的新手，或者只是在这里抓取一段你想复制粘贴并立即尝试的代码集，我保证这篇文章将非常有帮助。</p><p id="fb99" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇文章中，我将全面介绍最广泛使用的(2021年和正在进行的)图像增强库之一，<a class="ae kv" href="https://albumentations.ai/" rel="noopener ugc nofollow" target="_blank"><em class="ls">albumination</em></a>，并给出示例Python代码和输出。通过这篇文章，你应该能够对<a class="ae kv" href="https://albumentations.ai/" rel="noopener ugc nofollow" target="_blank"> <em class="ls">蛋白</em> </a>有一个基本的了解，并最终在你自己的工作空间中进行尝试。任何没有(或很少)Pytorch或Python经验或接触图像增强技术本身的人也是受欢迎的。</p><p id="8384" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我个人发现这个库在我的日常使用中对任何计算机视觉相关的任务都非常有用，所以我想，‘为什么我不就此发表一篇文章呢？’？</p><p id="cf38" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">免责声明:这篇文章不是由</em><a class="ae kv" href="https://albumentations.ai/" rel="noopener ugc nofollow" target="_blank"><em class="ls">albumination</em></a><em class="ls">赞助的，也不隶属于它。</em></p><p id="82dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那么，究竟什么是<a class="ae kv" href="https://albumentations.ai/" rel="noopener ugc nofollow" target="_blank">蛋白沉积</a>？使用起来有什么特点和优势？现实世界的应用有哪些？</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="591d" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">什么是蛋白沉积？</h1><p id="7baf" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">在你了解白质化有什么帮助之前，理解图像增强在计算机视觉中的意义是至关重要的。</p><p id="2b60" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Ryan Allred的帖子有一个很好的解释。</p><blockquote class="mx my mz"><p id="fc0e" class="kw kx ls ky b kz la jr lb lc ld ju le na lg lh li nb lk ll lm nc lo lp lq lr ij bi translated">深度神经网络，尤其是<a class="ae kv" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">卷积神经网络(CNN)</a>，尤其擅长图像分类任务。最先进的CNN甚至被证明在图像识别方面超过了人类的表现(……)图像增强是获取已经存在于训练数据集中的图像并对其进行处理以创建同一图像的许多修改版本的过程。这不仅提供了更多的图像进行训练，而且还可以帮助我们的分类器暴露在更广泛的光照和颜色情况下，从而使我们的分类器更加鲁棒</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/86bb5a6851c0bf0751ed12dc1455b606.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9qscloViwNjjAj9iyPw84A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图像增强样本。图片由https://github.com/aleju/imgaug的<a class="ae kv" href="https://github.com/aleju/imgaug" rel="noopener ugc nofollow" target="_blank">提供</a></p></figure><p id="55ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">基本上，它向给定的图像/图片中定制添加各种不同的品种，以增加训练数据集的规模，最终帮助提高深度学习模型的准确性。</strong></p><p id="e7e8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Albumentation是一个工具，可以在将图像/图片放入模型之前，对其进行[ <em class="ls">弹性、网格、运动模糊、移位、缩放、旋转、转置、对比度、亮度等] </em>定制。</p><p id="e885" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://albumentations.ai/" rel="noopener ugc nofollow" target="_blank">官方蛋白网站</a>称自己为</p><blockquote class="ne"><p id="844d" class="nf ng iq bd nh ni nj nk nl nm nn lr dk translated">Albumentations是一个Python库，用于快速灵活的<a class="ae kv" href="https://albumentations.ai/#" rel="noopener ugc nofollow" target="_blank">图像增强</a>。Albumentations有效地实现了针对性能而优化的丰富多样的图像变换操作，并且同时为不同的计算机视觉任务(包括对象分类、分割和检测)提供了简洁而强大的图像增强接口。</p></blockquote><p id="7fee" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">albuminations已于2020年正式发表在信息杂志上，标题为<a class="ae kv" href="https://www.mdpi.com/2078-2489/11/2/125" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">albuminations:快速灵活的图像增强</strong> </a>，目前由来自俄罗斯的5名核心团队成员维护，功能更新一致。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="0f82" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">为什么要用白蛋白？</h1><p id="b291" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">与其他图像增强相关包不同的是，</p><p id="ec8e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">是</strong> <strong class="ky ir">快</strong></p><p id="660a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个包已经被几个基于OpenCV的库(包括NumPy，OpenCV，imgaug)优化了。</p><p id="fa6b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在你有机会面对最终的老板，而不用痛打所有的中层老板</p><p id="8239" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我的深度学习首选python框架是Pytorch，所以我最初接触了torchvision原生提供的<a class="ae kv" href="https://pytorch.org/docs/stable/torchvision/transforms.html" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">torch vision . transforms</strong></a><strong class="ky ir"/>的用法。<a class="ae kv" href="https://pytorch.org/docs/stable/torchvision/transforms.html" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">torch vision . transforms</strong></a><strong class="ky ir"/>已经给出了相当扎实的定制增强方法和文档，所以我一直坚持它的产品。</p><p id="ac52" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在寻找更好的增强开源库时，我发现了这个Albumentation包。我发现它非常快，高度可定制，最重要的是，它只需要https://github.com/albumentations-team/albumentations</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/15381c58ea4fe17f60b89c65890e7708.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FG-PEtho8BV_ouAmmzkNGg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">上图是英特尔至强白金8168 CPU的测试结果，由ImageNet中的2000个验证集映像提供。每个单元格中的值表示单个内核中处理的图像数量。你可以看到，在许多转换中，Albumentation比所有其他库至少快2倍。</p></figure><p id="2e81" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以在<a class="ae kv" href="https://github.com/albumentations-team/albumentations" rel="noopener ugc nofollow" target="_blank">albumination官方GitHub </a>中找到有关最新0.5.0版本的基准测试的更多信息。</p><p id="93e8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">怎么用白蛋白？</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="43ae" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated"><strong class="ak">教程</strong></h1><h2 id="4552" class="nu mb iq bd mc nv nw dn mg nx ny dp mk lf nz oa mm lj ob oc mo ln od oe mq of bi translated">对于这个项目的范围，我将介绍白蛋白的主要成分和用途。该代码集主要基于Albumentations团队的教程笔记本。我参考了下面的笔记本:</h2><p id="e494" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated"><a class="ae kv" href="https://github.com/albumentations-team/albumentations_examples/blob/master/notebooks/migrating_from_torchvision_to_albumentations.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">migrating _ from _ torch vision _ to _ albuminations . ipynb</strong></a></p><ul class=""><li id="5561" class="og oh iq ky b kz la lc ld lf oi lj oj ln ok lr ol om on oo bi translated">在Google Colab中安装Google Drive</li></ul><h2 id="91ad" class="nu mb iq bd mc nv nw dn mg nx ny dp mk lf nz oa mm lj ob oc mo ln od oe mq of bi translated">我坚持使用Google Colab来制作简单/可共享的笔记本原型。他们的Jupyter是免费的，你可以使用免费的GPU！</h2><p id="f775" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">你可以上传你的照片到你的Google Drive，然后用下面的代码把Google Drive挂载到Colab。</p><p id="5e4c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该单元格将返回以下内容<em class="ls">在浏览器中转到该URL</em><strong class="ky ir">。</strong>点击URL后，您可以检索授权码。复制粘贴这段代码，然后按回车键和<strong class="ky ir"> </strong>就可以了！</p><pre class="kg kh ki kj gt op oq or os aw ot bi"><span id="4b96" class="nu mb iq oq b gy ou ov l ow ox">from google.colab import drive<br/>drive.mount("/content/gdrive")</span></pre><p id="23a5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作者照片。认证后的结果</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/869db0af20e7545a9946d011977f2e25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kxjam4UhEnffYBYOdwugxg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">此外，我将导入本教程所需的所有其他Python库</p></figure><p id="6b41" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了演示的目的，我用了一张意大利威尼斯的街景照片，这是我前阵子去欧洲旅行时拍的。</p><pre class="kg kh ki kj gt op oq or os aw ot bi"><span id="d8bd" class="nu mb iq oq b gy ou ov l ow ox">from PIL import Image<br/>import time<br/>import torch<br/>import torchvision<br/>from torch.utils.data import Dataset<br/>from torchvision import transforms<br/>import albumentations<br/>import albumentations.pytorch<br/>from matplotlib import pyplot as plt<br/>import cv2<br/>import numpy as np</span></pre><p id="1a42" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作者照片。意大利威尼斯的一条街道</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/9957c07895c7059e69cb77549cd3f401.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Q6VWxCfV6bsFaivve0smQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">原始火炬视觉数据管道</p></figure><h1 id="7e9d" class="ma mb iq bd mc md pa mf mg mh pb mj mk jw pc jx mm jz pd ka mo kc pe kd mq mr bi translated">我通常使用PyTorch和Torchvision创建一个数据加载器来处理图像数据管道。在下面的代码中，它</h1><p id="d60e" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">创建一个简单的Pytorch数据集类</p><ul class=""><li id="e070" class="og oh iq ky b kz la lc ld lf oi lj oj ln ok lr ol om on oo bi translated">调用图像并进行转换</li><li id="8b39" class="og oh iq ky b kz pf lc pg lf ph lj pi ln pj lr ol om on oo bi translated">用100个循环测量整个处理时间</li><li id="4bc0" class="og oh iq ky b kz pf lc pg lf ph lj pi ln pj lr ol om on oo bi translated">首先，从torch.utils.data中获取Dataset抽象类，并创建一个TorchVision Dataset类。然后我插入图像，并使用<strong class="ky ir"> __getitem__ </strong>方法进行转换。此外，我使用<code class="fe pk pl pm oq b">total_time = (time.time() - start_t</code>来测量需要多长时间</li></ul><p id="00cc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们将图像的大小调整为256x256(高*重)，并随机裁剪为224x224。然后以50%的概率应用水平翻转，转换为张量。输入文件路径应该是你的图片所在的Google Drive的路径。</p><pre class="kg kh ki kj gt op oq or os aw ot bi"><span id="1e8e" class="nu mb iq oq b gy ou ov l ow ox">class TorchvisionDataset(Dataset):<br/>    def __init__(self, file_paths, labels, transform=None):<br/>        self.file_paths = file_paths<br/>        self.labels = labels<br/>        self.transform = transform<br/>        <br/>    def __len__(self):<br/>        return len(self.file_paths)<br/><br/>    def __getitem__(self, idx):<br/>        label = self.labels[idx]<br/>        file_path = self.file_paths[idx]<br/>        <br/>        # Read an image with PIL<br/>        image = Image.open(file_path)<br/>        <br/>        start_t = time.time()<br/>        if self.transform:<br/>            image = self.transform(image)<br/>        total_time = (time.time() - start_t)<br/><br/>        return image, label, total_time</span></pre><p id="9008" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们计算从torchvision_dataset中提取样本图像并转换它所需的时间，然后运行100次循环来检查它所需的平均毫秒数。</p><pre class="kg kh ki kj gt op oq or os aw ot bi"><span id="d217" class="nu mb iq oq b gy ou ov l ow ox">torchvision_transform = transforms.Compose([<br/>    transforms.Resize((256, 256)), <br/>    transforms.RandomCrop(224),<br/>    transforms.RandomHorizontalFlip(),<br/>    transforms.ToTensor(),<br/>])<br/><br/>torchvision_dataset = TorchvisionDataset(<br/>    file_paths=["<!-- -->/content/drive/MyDrive/img5.jpg<!-- -->"],<br/>    labels=[1],<br/>    transform=torchvision_transform,<br/>)</span></pre><p id="7961" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我的Colab环境中，Resize+RandomCrop+RandomHorizontalFlip的一百次循环大约花费了40 ms，最后一张图像花费了224x224，如您所见。你也可以看到翻转发生在第100张图片上！</p><pre class="kg kh ki kj gt op oq or os aw ot bi"><span id="d17c" class="nu mb iq oq b gy ou ov l ow ox">total_time = 0<br/>for i in range(100):<br/>  sample, _, transform_time = torchvision_dataset[0]<br/>  total_time += transform_time<br/><br/>print("torchvision time/sample: {} ms".format(total_time*10))<br/><br/>plt.figure(figsize=(10, 10))<br/>plt.imshow(transforms.ToPILImage()(sample))<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pn"><img src="../Images/4a8bb09fb877c4086f7eb15a8ac824fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RQKIHyOW5psKrCPRcjHa5Q.png"/></div></div></figure><p id="6469" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">沉淀数据管道</p><h1 id="202d" class="ma mb iq bd mc md pa mf mg mh pb mj mk jw pc jx mm jz pd ka mo kc pe kd mq mr bi translated">现在，我将重构从火炬视觉到蛋白质合成的数据管道</h1><p id="cda5" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">类似于TorchVision，我们创建了一个Albumentations数据集类。</p><p id="6467" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在在蛋白沉积中创造一个转变。在这个例子中，你可以发现一个小小的语法差异，那就是Torchvision的<strong class="ky ir"> RandomHorizontalFlip() </strong>通过<strong class="ky ir"> HorizontalFlip() </strong>在Albumentation中产生相同的结果</p><pre class="kg kh ki kj gt op oq or os aw ot bi"><span id="2d4a" class="nu mb iq oq b gy ou ov l ow ox">class AlbumentationsDataset(Dataset):<br/>    """__init__ and __len__ functions are the same as in TorchvisionDataset"""<br/>    def __init__(self, file_paths, labels, transform=None):<br/>        self.file_paths = file_paths<br/>        self.labels = labels<br/>        self.transform = transform<br/>        <br/>    def __len__(self):<br/>        return len(self.file_paths)<br/><br/>    def __getitem__(self, idx):<br/>        label = self.labels[idx]<br/>        file_path = self.file_paths[idx]<br/>        <br/>        # Read an image with OpenCV<br/>        image = cv2.imread(file_path)<br/>        <br/>        # By default OpenCV uses BGR color space for color images,<br/>        # so we need to convert the image to RGB color space.<br/>        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)<br/><br/>        start_t = time.time()<br/>        if self.transform:<br/>            augmented = self.transform(image=image) <br/>            image = augmented['image']<br/>	    total_time = (time.time() - start_t)<br/>        return image, label, total_time</span></pre><p id="8a8a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">执行相同的图像转换，获得平均时间，并可视化结果。</p><pre class="kg kh ki kj gt op oq or os aw ot bi"><span id="dea8" class="nu mb iq oq b gy ou ov l ow ox">"""<br/>torchvision_transform = transforms.Compose([<br/>    transforms.Resize((256, 256)), <br/>    transforms.RandomCrop(224),<br/>    transforms.RandomHorizontalFlip(),<br/>    transforms.ToTensor(),<br/>])<br/>"""<br/><br/># Same transform with torchvision_transform<br/>albumentations_transform = albumentations.Compose([<br/>    albumentations.Resize(256, 256), <br/>    albumentations.RandomCrop(224, 224),<br/>    albumentations.HorizontalFlip(), # Same with transforms.RandomHorizontalFlip()<br/>    albumentations.pytorch.transforms.ToTensor()<br/>])</span></pre><p id="7e7a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">令人惊讶的是，只用了1.77ms，比Torchvision快了约23倍！它甚至比我们从官方基准文档中看到的计算差距更大，而且裁剪区域似乎也略有不同。</p><pre class="kg kh ki kj gt op oq or os aw ot bi"><span id="1528" class="nu mb iq oq b gy ou ov l ow ox"># Same dataset with torchvision_dataset<br/>albumentations_dataset = AlbumentationsDataset(<br/>    file_paths=["<!-- -->/content/drive/MyDrive/img5.jpg<!-- -->"],<br/>    labels=[1],<br/>    transform=albumentations_transform,<br/>)<br/>total_time = 0<br/>for i in range(100):<br/>  sample, _, transform_time = albumentations_dataset[0]<br/>  total_time += transform_time<br/><br/>print("albumentations time/sample: {} ms".format(total_time*10))<br/><br/>plt.figure(figsize=(10, 10))<br/>plt.imshow(transforms.ToPILImage()(sample))<br/>plt.show()</span></pre><p id="f765" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">白蛋白的应用</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi po"><img src="../Images/d8c8f726011d63c66069b4f6eb42ea90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zU4hrIXIMTY5QE1qHXvxGA.png"/></div></div></figure><h1 id="7cd1" class="ma mb iq bd mc md pa mf mg mh pb mj mk jw pc jx mm jz pd ka mo kc pe kd mq mr bi translated">如你所见，它非常快，速度很重要。</h1><p id="a58a" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">在代码竞赛中，如果可以减少图像处理中的计算瓶颈，就可以将更多的资源用于其他部分(模型拟合、超参数调优等)。</p><ul class=""><li id="f826" class="og oh iq ky b kz la lc ld lf oi lj oj ln ok lr ol om on oo bi translated">在现实世界的行业中，生产数据库中新图像的流入量可能很大(即每秒1000幅图像)。想象开发一个实时深度学习模型。在该模型中，处理图像的快速方法至关重要，这可能会影响用户体验并最终影响收入/利润。</li><li id="94c6" class="og oh iq ky b kz pf lc pg lf ph lj pi ln pj lr ol om on oo bi translated">对于你的学习目的来说，接触最新的和表现最好的技术技能是有帮助的，这在你建立自己的项目时可能是有用的，也许在找工作(例如简历)时也是有用的</li><li id="ffdb" class="og oh iq ky b kz pf lc pg lf ph lj pi ln pj lr ol om on oo bi translated">更复杂的例子</li></ul><h1 id="f65a" class="ma mb iq bd mc md pa mf mg mh pb mj mk jw pc jx mm jz pd ka mo kc pe kd mq mr bi translated">最后，我将展示如何使用函数中的<strong class="ky ir">函数进行增强，我个人认为这是最复杂的，但在蛋白沉积中非常有用</strong></h1><p id="ddc6" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">它在调整大小和随机裁剪方面与之前的代码集有相同的代码。<strong class="ky ir"> OneOf </strong>在括号内随机选取一个列出的变换。我们甚至可以把发生的概率放在函数本身中。例如，如果其中一个([…]，p=0.5)，它以50%的几率跳过整个变换，并以1/6的几率随机选取三个变换中的一个。</p><pre class="kg kh ki kj gt op oq or os aw ot bi"><span id="9b65" class="nu mb iq oq b gy ou ov l ow ox">albumentations_transform_oneof = albumentations.Compose([<br/>    albumentations.Resize(256, 256), <br/>    albumentations.RandomCrop(224, 224),<br/>    albumentations.OneOf([<br/>                          albumentations.HorizontalFlip(p=1),<br/>                          albumentations.RandomRotate90(p=1),<br/>                          albumentations.VerticalFlip(p=1)            <br/>    ], p=1),<br/>    albumentations.OneOf([<br/>                          albumentations.MotionBlur(p=1),<br/>                          albumentations.OpticalDistortion(p=1),<br/>                          albumentations.GaussNoise(p=1)                 <br/>    ], p=1),<br/>    albumentations.pytorch.ToTensor()<br/>])</span></pre><p id="bc1c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我让它从水平翻转、旋转、垂直翻转中随机选择，又让它从模糊、失真、噪声中随机选择。所以在这种情况下，我们允许3x3 = 9种组合。</p><p id="f183" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">来自定义的图像变换的五个样本如下:</p><pre class="kg kh ki kj gt op oq or os aw ot bi"><span id="fad4" class="nu mb iq oq b gy ou ov l ow ox">albumentations_dataset = AlbumentationsDataset(<br/>    file_paths=["/content/gdrive/My Drive/img5.png"],<br/>    labels=[1],<br/>    transform=albumentations_transform_oneof,<br/>)<br/><br/>num_samples = 5<br/>fig, ax = plt.subplots(1, num_samples, figsize=(25, 5))<br/>for i in range(num_samples):<br/>  ax[i].imshow(transforms.ToPILImage()(albumentations_dataset[0][0]))<br/>  ax[i].axis('off')</span></pre><p id="f588" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们看到旋转360，水平翻转，垂直翻转被应用，不同的失真被应用到所有遮光罩下的图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pp"><img src="../Images/055de5d6d083e20a68961d324b7bef8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SI3nVaj-4Q7DaEPNRI-XcA.png"/></div></div></figure><p id="2a5f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除了我所解释的，还有许多例子。请参考官方<a class="ae kv" href="https://albumentations.ai/docs/" rel="noopener ugc nofollow" target="_blank">营养强化网站</a>或<a class="ae kv" href="https://github.com/albumentations-team/albumentations/" rel="noopener ugc nofollow" target="_blank">营养强化Github </a>来应用最适合自己需求的强化！</p><p id="44de" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">额外资源</p><h1 id="3e17" class="ma mb iq bd mc md pa mf mg mh pb mj mk jw pc jx mm jz pd ka mo kc pe kd mq mr bi translated"><strong class="ky ir">*注* <br/> </strong>您还可以找到Jupyter笔记本，其中包含了albumination:ka ggle竞赛的真实用法</h1><p id="caf9" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated"><a class="ae kv" href="https://www.kaggle.com/c/bengaliai-cv19" rel="noopener ugc nofollow" target="_blank">孟加拉语。AI手写字素分类</a>是一个代码竞赛，给定一个手写孟加拉字素的图像，对图像中的三个组成元素进行分类。这是一个图像分类问题，Albumentation用于转换最初存在于拼花文件中的数万张图像，大小为GB。</p><p id="b112" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">GitHub: <a class="ae kv" href="https://github.com/hyunjoonbok/bengaliai-cv19" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">孟加拉语。AI手写字素分类大赛</strong> </a></p><p id="a8a9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结论</p><h1 id="cc90" class="ma mb iq bd mc md pa mf mg mh pb mj mk jw pc jx mm jz pd ka mo kc pe kd mq mr bi translated">总之，我介绍了图像增强技术，Python中的Albumentation库，教程中有示例代码。为了这个项目，这个实验只使用了一张图像，但是可以发现速度有了很大的提高。白蛋白提供了各种各样的转换，所以我强烈推荐我的读者从今天开始使用它。</h1><p id="3f50" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated"><em class="ls">有关学习其他数据科学主题的更多详细信息，下面的Github存储库也会有所帮助</em></p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><p id="7d38" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://github.com/hyunjoonbok/amazon-sagemaker" rel="noopener ugc nofollow" target="_blank">生产中的AWS sage maker</a><br/>展示如何使用Amazon SageMaker及其ML/DL算法解决业务问题的端到端示例。</p><ul class=""><li id="c7b8" class="og oh iq ky b kz la lc ld lf oi lj oj ln ok lr ol om on oo bi translated"><a class="ae kv" href="https://github.com/hyunjoonbok/PySpark" rel="noopener ugc nofollow" target="_blank"> PySpark </a> <br/>函数和实用程序，带有真实世界的数据示例。可以用来构建一个完整的数据建模的ETL过程</li><li id="8926" class="og oh iq ky b kz pf lc pg lf ph lj pi ln pj lr ol om on oo bi translated"><a class="ae kv" href="https://github.com/hyunjoonbok/Recommendation_System-PyTorch" rel="noopener ugc nofollow" target="_blank">推荐系统</a><br/>py torch中推荐系统的生产级实现。克隆repo并通过运行“main.py”开始训练</li><li id="f63f" class="og oh iq ky b kz pf lc pg lf ph lj pi ln pj lr ol om on oo bi translated"><a class="ae kv" href="https://github.com/hyunjoonbok/natural-language-processing" rel="noopener ugc nofollow" target="_blank">自然语言处理(NLP)</a><br/>Python中几种自然语言处理方法的完整实现示例。按照学习的复杂程度排序</li><li id="9efe" class="og oh iq ky b kz pf lc pg lf ph lj pi ln pj lr ol om on oo bi translated">关于作者</li></ul></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="c332" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">贤俊是一名拥有统计学学位的数据极客。他喜欢分享数据科学/分析知识。在LinkedIn上给他发消息。</h1><p id="aa92" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated"><em class="ls">参考:<br/> </em> (1)瑞安·奥尔雷德，<a class="ae kv" rel="noopener" target="_blank" href="/image-augmentation-for-deep-learning-using-keras-and-histogram-equalization-9329f6ae5085">https://towardsdatascience . com/AWS-glue-and-you-e2e 4322 f 0805</a><br/>(2)霍亚012，<a class="ae kv" href="https://hoya012.github.io/blog/albumentation_tutorial/" rel="noopener ugc nofollow" target="_blank">https://hoya012.github.io/blog/albumentation_tutorial/</a><br/>(3)蛋白发酵官方文档，<a class="ae kv" href="https://albumentations.ai/docs/" rel="noopener ugc nofollow" target="_blank">https://albumentations.ai/docs/</a></p><p id="11f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi"><em class="ls">Reference:<br/></em>(1) Ryan Allred, <a class="ae kv" rel="noopener" target="_blank" href="/image-augmentation-for-deep-learning-using-keras-and-histogram-equalization-9329f6ae5085">https://towardsdatascience.com/aws-glue-and-you-e2e4322f0805</a><br/>(2) Hoya012, <a class="ae kv" href="https://hoya012.github.io/blog/albumentation_tutorial/" rel="noopener ugc nofollow" target="_blank">https://hoya012.github.io/blog/albumentation_tutorial/</a><br/>(3) Albumentation Official Docs, <a class="ae kv" href="https://albumentations.ai/docs/" rel="noopener ugc nofollow" target="_blank">https://albumentations.ai/docs/</a></p></div></div>    
</body>
</html>