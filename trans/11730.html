<html>
<head>
<title>Exciting Machine Learning Project On Satellite Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于卫星图像的激动人心的机器学习项目</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/exciting-machine-learning-project-on-satellite-images-a4214e275863?source=collection_archive---------9-----------------------#2021-11-22">https://towardsdatascience.com/exciting-machine-learning-project-on-satellite-images-a4214e275863?source=collection_archive---------9-----------------------#2021-11-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8e25" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用机器学习从卫星图像中检测和分类船只，并在Web应用程序中部署该模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/58afb830ca8ddeefc29609440935a418.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SfE_ZCV5ffa6kI6i"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">美国地质勘探局在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="7929" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">介绍</h2><p id="582a" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">处理卫星图像很有意思。就我个人而言，如果有人问我为什么选择在数据科学领域。我必须告诉你，在数据科学中有太多的选项可供你选择。简而言之，基本的咒语是-</p><blockquote class="mo"><p id="6ebb" class="mp mq it bd mr ms mt mu mv mw mx mn dk translated">因为数据无处不在，你可以选择成为任何东西。</p></blockquote><p id="69f2" class="pw-post-body-paragraph lv lw it lx b ly my ju ma mb mz jx md li na mf mg lm nb mi mj lq nc ml mm mn im bi translated">我觉得数据科学比其他领域给你更多的自由。例如，从卫星上获得的图像，如果我必须戴上太空研究科学家的帽子来识别海里的船只，我可以做到。在数据科学领域，如果我得到正确的数据，我肯定可以成为一名太空研究科学家。</p><p id="785b" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">当我偶然发现来自<a class="ae ky" href="https://www.esa.int/" rel="noopener ugc nofollow" target="_blank">欧洲航天局</a>的数据集时，我很好奇将机器学习应用到真实的卫星图像上，看看我能从中获得什么。</p><p id="60d2" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">这是一个简单的项目，获取图像，可视化的图像和训练神经网络模型。我们将使用哨兵2号的卫星图像。</p><p id="e8dd" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">在这个项目中，你不仅要建立一个模型来分类船只，还要部署这个模型并围绕它建立一个有趣的网络应用程序。</p><p id="de9a" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">如果你好奇，下面是用来跟踪地球的主要卫星</p><blockquote class="nj nk nl"><p id="f5c5" class="lv lw ni lx b ly nd ju ma mb ne jx md nm nf mf mg nn ng mi mj no nh ml mm mn im bi translated">哥白尼哨兵1号卫星——监测海冰、海风、石油泄漏和海上航行。</p><p id="4e4a" class="lv lw ni lx b ly nd ju ma mb ne jx md nm nf mf mg nn ng mi mj no nh ml mm mn im bi translated">哥白尼哨兵2号卫星——监测海洋和沿海地区</p><p id="8789" class="lv lw ni lx b ly nd ju ma mb ne jx md nm nf mf mg nn ng mi mj no nh ml mm mn im bi translated">哥白尼哨兵3号——收集海洋颜色和表面温度</p><p id="4afc" class="lv lw ni lx b ly nd ju ma mb ne jx md nm nf mf mg nn ng mi mj no nh ml mm mn im bi translated">哥白尼哨兵6号和杰森3号卫星——用于监测气候</p></blockquote><p id="71b4" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">现在对于这个项目，我们将使用来自Sentinal-1的图像，我们将尝试检测和分类船只类型。这个项目有许多用例。例如，您可以随时估计海上交通，从而以更好的方式设计海上导航系统。</p><p id="bb8e" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated"><a class="ae ky" href="https://www.eumetsat.int/science-blog/inspiring-ocean-projects-developed-copernicus-hackathon-weekend" rel="noopener ugc nofollow" target="_blank">深蓝全球</a>是一家初创公司，在哥白尼黑客马拉松[1]中做了类似的工作。</p><h1 id="71e2" class="np la it bd lb nq nr ns le nt nu nv lh jz nw ka ll kc nx kd lp kf ny kg lt nz bi translated">戏弄者</h1><p id="14bf" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">如果你想知道最终会是什么样子，请看下面的视频，完整的代码可以在Github上找到</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Wedapp跑步视频</p></figure><h1 id="cd6d" class="np la it bd lb nq nr ns le nt nu nv lh jz nw ka ll kc nx kd lp kf ny kg lt nz bi translated">数据</h1><p id="ecbd" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">来自sentinal-1卫星的图像已经收集并作为OPENSAR船舶数据集公开。你可以从Wekeo <a class="ae ky" href="https://jupyterhub-wekeo.apps.eumetsat.dpi.wekeo.eu/user/tejeshbat/lab?ticket=ST-e80602ca69dc4bd781c044cdb770db67-identity.apps.mercator.dpi.wekeo.eu" rel="noopener ugc nofollow" target="_blank">链接这里</a>下载数据集。(您可能需要注册才能访问数据)</p><h2 id="3989" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">数据存取</h2><p id="324c" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">“哥白尼提供的绝大多数数据/信息都是免费、完整和开放的，任何公民和世界各地的任何组织<strong class="lx iu">都可以获得。”【</strong> <a class="ae ky" href="https://www.copernicus.eu/en/access-data" rel="noopener ugc nofollow" target="_blank"> <strong class="lx iu">哥白尼官网</strong></a><strong class="lx iu">】</strong></p><p id="b42d" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">您可以前往<a class="ae ky" href="https://www.copernicus.eu/en/access-data" rel="noopener ugc nofollow" target="_blank">此链接</a>查看如何访问打开的数据集。由于卫星每天产生万亿字节的数据，你可以去<a class="ae ky" href="https://jupyterhub-wekeo.apps.eumetsat.dpi.wekeo.eu/user/tejeshbat/lab?ticket=ST-e80602ca69dc4bd781c044cdb770db67-identity.apps.mercator.dpi.wekeo.eu" rel="noopener ugc nofollow" target="_blank"> Wekeo网站</a>注册获取这个项目的处理和压缩图像。</p><p id="1065" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">该数据集由2805幅图像组成，其中每幅图像都被标记为下面三艘船中的一艘。</p><ol class=""><li id="3feb" class="oc od it lx b ly nd mb ne li oe lm of lq og mn oh oi oj ok bi translated">散装货轮</li><li id="d6ab" class="oc od it lx b ly ol mb om li on lm oo lq op mn oh oi oj ok bi translated">货柜船</li><li id="245f" class="oc od it lx b ly ol mb om li on lm oo lq op mn oh oi oj ok bi translated">邮轮；罐车；坦克手</li></ol><p id="4e07" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">样本图像可以在下面看到。虽然看起来图像中只有细微的差别，但我们希望我们的ML模型能够比人类更准确地检测和分类船只。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/61cc566b8779b14ada7dd87efab6e5f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*0WMs4krsNskNgKaNf8Tn1g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">样本图像——来自Sentinal-1的真实卫星图像[ <a class="ae ky" href="https://jupyterhub-wekeo.apps.eumetsat.dpi.wekeo.eu/user/tejeshbat/lab?ticket=ST-e80602ca69dc4bd781c044cdb770db67-identity.apps.mercator.dpi.wekeo.eu" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="24e0" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">如果你在寻找类似的项目和不同的数据集，你可以看看<a class="ae ky" href="https://www.kaggle.com/c/airbus-ship-detection/data" rel="noopener ugc nofollow" target="_blank"> Kaggle数据集</a>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/3e0b10c7924e6f29665d94e9af841b20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*u7X8LaEGqsk39TZWP8hZbQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">分割和船只检测[ <a class="ae ky" rel="noopener" target="_blank" href="/deep-learning-for-ship-detection-and-segmentation-71d223aca649">来源</a></p></figure><p id="bb71" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">Abhinav Sagar发布了一个卫星图像模型，你可以通过分割技术检测卫星图像中的船只。</p><div class="ou ov gp gr ow ox"><a rel="noopener follow" target="_blank" href="/deep-learning-for-ship-detection-and-segmentation-71d223aca649"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">用于船只检测和分割的深度学习</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">卫星图像深度学习的端到端管道</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">towardsdatascience.com</p></div></div><div class="pg l"><div class="ph l pi pj pk pg pl ks ox"/></div></div></a></div><p id="a80c" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">但是在这个项目中，我们不仅要检测船只，还要对船只进行分类。这是可能的，因为我们这里有一个带标签的数据集，因此我们将实现一个监督模型。</p><h1 id="35c0" class="np la it bd lb nq nr ns le nt nu nv lh jz nw ka ll kc nx kd lp kf ny kg lt nz bi translated">履行</h1><p id="d767" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">该项目的实施分为两个部分</p><ol class=""><li id="6706" class="oc od it lx b ly nd mb ne li oe lm of lq og mn oh oi oj ok bi translated">分类</li><li id="ec6f" class="oc od it lx b ly ol mb om li on lm oo lq op mn oh oi oj ok bi translated">Web应用程序</li></ol><p id="357d" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">在分类中，我们将研究分类神经网络模型的代码和实现技术，在web应用程序部分，我们将研究基于streamlit的web应用程序的构建，用户可以在该应用程序中与我们开发的ML模型进行对比，从卫星图像中检测船只。</p><p id="cefc" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">您可以通过点击这里的直接跳转到Colab文件中的实现</p><div class="ou ov gp gr ow ox"><a href="https://github.com/tejeshb/Satellite_Imagery_ML/blob/main/Satellite_imagery.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">Satellite _ Imagery _ ML/Satellite _ Imagery . ipynb at main tejeshb/Satellite _ Imagery _ ML</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">从卫星图像中检测和分类船只-Satellite _ Imagery _ ML/Satellite _ Imagery . ipynb at main…</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">github.com</p></div></div><div class="pg l"><div class="pm l pi pj pk pg pl ks ox"/></div></div></a></div><p id="dc46" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">我使用VGG16模型进行迁移学习，该模型已经在图像上进行了预训练。在导入必要的库之后，您可以跳到ML模型的实现，因为所提供的数据集中的数据已经被清理，并且所有图像都是大小为(128，128)的numpy格式</p><p id="ca6d" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">要实例化VGG16，请确保设置了以下参数</p><pre class="kj kk kl km gt pn po pp pq aw pr bi"><span id="a51e" class="kz la it po b gy ps pt l pu pv">vgg = VGG16(include_top=False,weights=None,<br/>            input_tensor=inputs,pooling='avg')</span></pre><p id="f7c5" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">由于图像是(128，128)形状，将输入设置为如下</p><pre class="kj kk kl km gt pn po pp pq aw pr bi"><span id="7dcc" class="kz la it po b gy ps pt l pu pv">inputs = tf.keras.layers.Input(shape=(128,128,1))</span></pre><p id="26f4" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">之后，确保创建2密集和辍学层如下</p><pre class="kj kk kl km gt pn po pp pq aw pr bi"><span id="9c50" class="kz la it po b gy ps pt l pu pv">dense1 = tf.keras.layers.Dense(512, activation='relu')(vgg.output)</span><span id="3e41" class="kz la it po b gy pw pt l pu pv">dropout1 = tf.keras.layers.Dropout(0.5)(dense1)</span><span id="40e9" class="kz la it po b gy pw pt l pu pv">dense2 = tf.keras.layers.Dense(128, activation='relu')(dropout1)</span><span id="b349" class="kz la it po b gy pw pt l pu pv">dropout2 = tf.keras.layers.Dropout(0.5)(dense2)</span><span id="c37b" class="kz la it po b gy pw pt l pu pv">pred = tf.keras.layers.Dense(3, activation='softmax')(dropout2)</span></pre><p id="8b08" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">对于密集层，使用“relu”激活函数，而对于预测或输出的最后一层，使用“softmax”激活函数。</p><p id="1abd" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">请参见下面的完整型号摘要</p><pre class="kj kk kl km gt pn po pp pq aw pr bi"><span id="01a9" class="kz la it po b gy ps pt l pu pv">Model: "model" _________________________________________________________________  Layer (type)                Output Shape              Param #    =================================================================  input_1 (InputLayer)        [(None, 128, 128, 1)]     0                                                                             block1_conv1 (Conv2D)       (None, 128, 128, 64)      640                                                                           block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928                                                                         block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0                                                                             block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856                                                                         block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584                                                                        block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0                                                                             block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168                                                                        block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080                                                                        block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080                                                                        block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0                                                                             block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160                                                                       block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808                                                                       block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808                                                                       block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0                                                                             block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808                                                                       block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808                                                                       block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808                                                                       block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0                                                                             global_average_pooling2d (G  (None, 512)              0           lobalAveragePooling2D)                                                                                                              dense (Dense)               (None, 512)               262656                                                                        dropout (Dropout)           (None, 512)               0                                                                             dense_1 (Dense)             (None, 128)               65664                                                                         dropout_1 (Dropout)         (None, 128)               0                                                                             dense_2 (Dense)             (None, 3)                 387                                                                          ================================================================= Total params: 15,042,243 Trainable params: 15,042,243 Non-trainable params: 0 _________________________________________________________________</span></pre><p id="c7dc" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">使用下面的代码训练模型</p><pre class="kj kk kl km gt pn po pp pq aw pr bi"><span id="0801" class="kz la it po b gy ps pt l pu pv">import multiprocessing<br/>from timeit import default_timer as timer</span><span id="2064" class="kz la it po b gy pw pt l pu pv">start = timer()</span><span id="cb2d" class="kz la it po b gy pw pt l pu pv">cpu_count = multiprocessing.cpu_count()<br/>print(f"cpu: {cpu_count} found")<br/>      model.fit(X_train, y_train,<br/>      batch_size=12,<br/>      epochs=50,<br/>      verbose=1,<br/>      validation_data=(X_test, y_test),<br/>      steps_per_epoch = 25,<br/>      max_queue_size=10,<br/>      workers=cpu_count,<br/>      use_multiprocessing=cpu_count &gt; 1,<br/>      callbacks=[check, log])</span><span id="ce37" class="kz la it po b gy pw pt l pu pv">end = timer()<br/>print('Elapsed time: ' + str(end - start))</span></pre><p id="6b05" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">在模型训练之后，确保下载模型— vgg.h5。</p></div><div class="ab cl px py hx pz" role="separator"><span class="qa bw bk qb qc qd"/><span class="qa bw bk qb qc qd"/><span class="qa bw bk qb qc"/></div><div class="im in io ip iq"><p id="fbf9" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">为了测试模型是如何工作和执行的，我们必须检查模型指标，比如准确性。但是我现在不在这个项目中讨论它，因为1。主要的想法不是得到最好的模型，而是学习过程。2.我有一个更好更有趣的想法来测试这个模型。</p><h1 id="d3d5" class="np la it bd lb nq nr ns le nt nu nv lh jz nw ka ll kc nx kd lp kf ny kg lt nz bi translated">有趣的部分—网络应用</h1><p id="ad6a" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">想象你自己是一名<strong class="lx iu">数据科学家，必须帮助飞行员</strong>，他试图通过发现正确的船只种类来拯救世界<br/>你得到以下信息-</p><blockquote class="nj nk nl"><p id="e27d" class="lv lw ni lx b ly nd ju ma mb ne jx md nm nf mf mg nn ng mi mj no nh ml mm mn im bi translated">1.图片中有3种类型的船<br/> 2。你的任务是正确发现船只，这样飞行员就可以只攻击战列舰。</p></blockquote><p id="54de" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">现在，你认为什么是最好的主意？使用你建立的模型或者依靠人类的专业知识。</p><p id="0b8a" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">让我们使用一个web应用程序来测试一下，您可以上传模型和您想要检查的图像。</p><p id="97a4" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">允许用户猜测图像中的船是哪一种，然后运行模型来检查谁是正确的。</p><p id="508f" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">为这项有趣的活动设计的网络应用程序如下所示</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qe"><img src="../Images/a922d1d838543bbc3d5963b9166ba76c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BPDKZRW7TqW88JttiNetjw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Web应用程序—船舶分类器</p></figure><p id="549d" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">为了构建和部署web应用程序，我使用了Streamlit库，实现代码如下所示。</p><p id="65bd" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">在这里，我上传了一个h5格式的模型压缩文件，并对文件进行了解压缩。使用<code class="fe qf qg qh po b">load_model()</code>加载模型</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="qi ob l"/></div></figure><p id="b0e0" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">之后，使用下面的代码完成图像上传后的模型预测。在这里，调整图像的大小非常重要，因为我们有模型的输入形状(128，128)，你需要确保模型预测的图像应该是准确的形状。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="qi ob l"/></div></figure><p id="496b" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">让我们来测试这个模型，你可以在这个视频中看到最终的结果</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Wedapp跑步视频</p></figure><p id="bffa" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">我希望你有这个有趣的项目建设的乐趣，如果你对此有任何问题，请随时留下评论。</p><h1 id="6b66" class="np la it bd lb nq nr ns le nt nu nv lh jz nw ka ll kc nx kd lp kf ny kg lt nz bi translated">参考:</h1><ol class=""><li id="b1f0" class="oc od it lx b ly lz mb mc li qj lm qk lq ql mn oh oi oj ok bi translated"><a class="ae ky" href="https://www.eumetsat.int/science-blog/inspiring-ocean-projects-developed-copernicus-hackathon-weekend" rel="noopener ugc nofollow" target="_blank">https://www . eumetsat . int/science-blog/inspiring-ocean-projects-developed-Copernicus-hackathon-weekend</a></li><li id="7a94" class="oc od it lx b ly ol mb om li on lm oo lq op mn oh oi oj ok bi translated">数据来源—<a class="ae ky" href="https://www.copernicus.eu/en/access-data" rel="noopener ugc nofollow" target="_blank">https://www.copernicus.eu/en/access-data</a></li><li id="358b" class="oc od it lx b ly ol mb om li on lm oo lq op mn oh oi oj ok bi translated">数据集使用许可-<a class="ae ky" href="https://www.copernicus.eu/en/access-data/dias" rel="noopener ugc nofollow" target="_blank">https://www.copernicus.eu/en/access-data/dias</a></li></ol></div></div>    
</body>
</html>