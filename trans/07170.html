<html>
<head>
<title>6 Top Python Packages for Machine Learning Interpretability</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习可解释性的6个顶级Python包</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/6-top-python-packages-for-machine-learning-interpretability-f9fec3c2d1e9?source=collection_archive---------15-----------------------#2021-06-29">https://towardsdatascience.com/6-top-python-packages-for-machine-learning-interpretability-f9fec3c2d1e9?source=collection_archive---------15-----------------------#2021-06-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8446" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">你需要解释你的机器学习模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9ed8aab169728f7724b2b0103c7f8301.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3kcN6bMVRhnl6LqByZxZfw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><blockquote class="ky kz la"><p id="b63d" class="lb lc ld le b lf lg ju lh li lj jx lk ll lm ln lo lp lq lr ls lt lu lv lw lx im bi translated">如果您喜欢我的内容，并希望获得更多关于数据或数据科学家日常生活的深入知识，请考虑在此订阅我的<a class="ae ly" href="https://cornellius.substack.com/welcome" rel="noopener ugc nofollow" target="_blank">简讯。</a></p></blockquote><p id="b54f" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">开发机器学习模型是任何数据科学家都应该做的事情。我遇到过许多数据科学研究，它们只关注建模方面和评估，而没有解释。</p><p id="39e7" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">然而，许多人还没有意识到机器学习可解释性在业务流程中的重要性。根据我的经验，业务人员会想知道模型是如何工作的，而不是度量评估本身。</p><p id="1364" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">这就是为什么在这篇文章中，我想向你介绍我的一些顶级的机器学习可解释性python包。让我们开始吧！</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="d31b" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">1.黄砖</h1><p id="6ee8" class="pw-post-body-paragraph lb lc it le b lf nb ju lh li nc jx lk lz nd ln lo ma ne lr ls mb nf lv lw lx im bi translated"><a class="ae ly" href="https://www.scikit-yb.org/en/latest/about.html" rel="noopener ugc nofollow" target="_blank"> Yellowbrick </a>是一个开源的Python包，它用可视化分析和诊断工具扩展了scikit-learn <a class="ae ly" href="http://scikit-learn.org/stable/modules/classes.html" rel="noopener ugc nofollow" target="_blank"> API </a>。对于数据科学家，Yellowbrick用于评估模型性能和可视化模型行为。</p><p id="9e67" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">Yellowbrick是一个多用途的软件包，您可以在日常建模工作中使用。尽管Yellowbrick的大部分解释API都是基础级别的，但它对于我们的第一个建模步骤仍然很有用。</p><p id="bef1" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">让我们用一个数据集例子来试试Yellowbrick包。首先，让我们安装软件包。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="7093" class="nl mk it nh b gy nm nn l no np">pip install yellowbrick</span></pre><p id="ae90" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">安装完成后，我们可以使用Yellowbrick中的数据集示例来测试这个包。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="e8cb" class="nl mk it nh b gy nm nn l no np">#Pearson Correlation<br/><br/>from yellowbrick.features import rank2d<br/>from yellowbrick.datasets import load_credit<br/><br/><br/>X, _ = load_credit()<br/>visualizer = rank2d(X)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/b76182c805e60e3aed4e674b96fa8c71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/0*zkfVMQwbzLdc5-ib.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用Yellowbrick rank2d函数的Pearson相关性(图片由作者提供)</p></figure><p id="0e27" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">通过一条线，我们能够使用皮尔逊相关方法来可视化特征之间的相关性。它是可定制的，因此您可以使用另一个相关函数。</p><p id="315d" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">让我们尝试开发模型来评估模型性能和解释模型。我将使用Yellowbrick用户指南中的示例数据集，并生成一个区分阈值图，以找到区分二进制类的最佳阈值。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="ab5c" class="nl mk it nh b gy nm nn l no np">from yellowbrick.classifier import discrimination_threshold<br/>from sklearn.linear_model import LogisticRegression<br/>from yellowbrick.datasets import load_spam</span><span id="36cc" class="nl mk it nh b gy nr nn l no np">X, y = load_spam()<br/>visualizer = discrimination_threshold(LogisticRegression(multi_class="auto", solver="liblinear"), X,y)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/34ba9478dfc3017c1e8aa1f990a18024.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/0*aPk1lh4ddsWuDeiJ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由Yellowbrick绘制的阈值图(图片由作者提供)</p></figure><p id="0cc7" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">使用黄砖阈值图，我们可以解释该模型在概率阈值为0.4时表现最佳。</p><p id="97cb" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">如果你好奇Yellowbrick能做什么，请访问<a class="ae ly" href="https://www.scikit-yb.org/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">主页</a>了解更多信息。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="bb00" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">2.ELI5</h1><p id="ea7d" class="pw-post-body-paragraph lb lc it le b lf nb ju lh li nc jx lk lz nd ln lo ma ne lr ls mb nf lv lw lx im bi translated"><a class="ae ly" href="https://github.com/TeamHG-Memex/eli5" rel="noopener ugc nofollow" target="_blank"> ELI5 </a>是一个帮助机器学习可解释性的Python包。取自Eli5包，该包的基本用途是:</p><ol class=""><li id="b47f" class="nt nu it le b lf lg li lj lz nv ma nw mb nx lx ny nz oa ob bi translated">检查模型参数，并尝试弄清楚模型如何全局工作；</li><li id="23c4" class="nt nu it le b lf oc li od lz oe ma of mb og lx ny nz oa ob bi translated">检查模型的单个预测，并找出模型做出决策的原因。</li></ol><p id="7f95" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">如果说Yellowbrick侧重于特征和模型性能解释，那么ELI5侧重于模型参数和预测结果。就我个人而言，我更喜欢ELI5，因为它的解释足够简单，商务人士可以理解。</p><p id="2645" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">让我们用一个样本数据集和随机森林模型分类器来试试ELI5包。我会使用seaborn包中的数据集，因为它是最简单的。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="dde1" class="nl mk it nh b gy nm nn l no np">#Preparing the model and the dataset<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.model_selection import train_test_split</span><span id="fc37" class="nl mk it nh b gy nr nn l no np">mpg = sns.load_dataset('mpg').dropna()<br/>mpg.drop('name', axis =1 , inplace = True)</span><span id="5b33" class="nl mk it nh b gy nr nn l no np">#Data splitting<br/>X_train, X_test, y_train, y_test = train_test_split(mpg.drop('origin', axis = 1), mpg['origin'], test_size = 0.2, random_state = 121)</span><span id="a0ee" class="nl mk it nh b gy nr nn l no np">#Model Training<br/>clf = RandomForestClassifier()<br/>clf.fit(X_train, y_train)</span></pre><p id="a3df" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">最基本的ELI5功能是显示分类器权重和分类器预测结果。让我们尝试这两个函数来理解解释是如何产生的。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="6a34" class="nl mk it nh b gy nm nn l no np">import eli5<br/>eli5.show_weights(clf, feature_names = list(X_test.columns))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/0551b56a1acae182ab6fd80a8a17e345.png" data-original-src="https://miro.medium.com/v2/resize:fit:486/format:webp/0*hKNUW2wmuidC8Y02.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">分类器特征重要性权重(作者图片)</p></figure><p id="fe48" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">从上面的图像中，您可以看到分类器显示了分类器特征的重要性及其偏差。您可以看到位移特征是最重要的特征，但是它们有很高的偏差，表明模型中存在偏差。让我们试着展示一下预测结果的可解释性。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="a9c6" class="nl mk it nh b gy nm nn l no np">eli5.show_prediction(clf, X_train.iloc[0])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/88a7f4cb515090fb44498566dd566d0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vdY2vOP6hpUVvNG4.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">预测结果贡献(图片由作者提供)</p></figure><p id="9a96" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">使用ELI5的显示预测功能，我们可以获得特征贡献信息。哪些特征有助于某些预测结果，这些特征对概率的影响有多大。这是一个很好的功能，您可以轻松地向业务人员解释模型预测。</p><p id="633a" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">然而，最好记住上面的函数是基于树的解释(因为我们使用随机森林模型)。给你一个商业人士的解释可能就足够了；但是，由于模型的原因，可能会有偏差。这就是为什么ELI5提供了另一种方法来解释基于模型度量的黑盒模型——它被称为排列重要性。</p><p id="8384" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">让我们先试试排列重要性函数。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="42c1" class="nl mk it nh b gy nm nn l no np">#Permutation Importance<br/>perm = PermutationImportance(clf, scoring = 'accuracy',<br/>random_state=101).fit(X_test, y_test)<br/>show_weights(perm, feature_names = list(X_test.columns))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/d5a5c9b3673747fbcba5223bc73cd783.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/0*udNolE4ryTrguyMF.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">排列重要性结果(图片由作者提供)</p></figure><p id="9fff" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">排列重要性背后的思想是如何评分(准确度、精确度、召回率等。)随着特征的存在或不存在而移动。在上面的结果中，我们可以看到displacement的得分最高，为0.3013。当我们改变位移特征时，它将改变模型的精度高达0.3013。正负符号后的值是不确定度值。排列重要性方法本质上是一个随机过程；这就是为什么我们有不确定值。</p><p id="4e3e" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">位置越高，这些特征对得分的影响越大。底部的一些特征显示了一个负值，这很有趣，因为这意味着当我们改变特征时，该特征增加了得分。发生这种情况是因为，偶然地，特征排列实际上提高了分数。</p><p id="27e4" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">就我个人而言，ELI5已经给了我足够的机器学习可解释性，但我仍然想向您介绍一些Python包。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="5e23" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">3.SHAP</h1><p id="fa95" class="pw-post-body-paragraph lb lc it le b lf nb ju lh li nc jx lk lz nd ln lo ma ne lr ls mb nf lv lw lx im bi translated">如果我们在谈论机器学习的可解释性时不提及<a class="ae ly" href="https://shap.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> SHAP </a>，那就不完整。对于那些从未听说过它的人来说，SHAP或<strong class="le iu">(SHapley Additive explaints)</strong>是一种解释任何机器学习模型输出的博弈论方法。用一个更简单的术语来说，SHAP用SHAP值来解释每个特征的重要性。SHAP利用SHAP值之间的差异对模型的预测和零模型进行了开发。SHAP是模型不可知的，类似于排列重要性，所以它对任何模型都是有用的。</p><p id="d498" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">让我们尝试使用样本数据集和模型来更详细地解释SHAP。首先，我们需要安装SHAP软件包。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="c129" class="nl mk it nh b gy nm nn l no np">#Installation via pip<br/>pip install shap </span><span id="235e" class="nl mk it nh b gy nr nn l no np">#Installation via conda-forge <br/>conda install -c conda-forge shap</span></pre><p id="8daa" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">在这个示例中，我将使用titanic示例数据集，并且只依赖数字列。这仅用于示例目的，不应成为数据分析的标准。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="2075" class="nl mk it nh b gy nm nn l no np">#Preparing the model and the dataset <br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.model_selection import train_test_split  </span><span id="0469" class="nl mk it nh b gy nr nn l no np">titanic = sns.load_dataset('titanic').dropna() <br/>titanic = titanic[['survived', 'age', 'sibsp', 'parch']]  </span><span id="56b3" class="nl mk it nh b gy nr nn l no np">#Data splitting for rfc </span><span id="f06f" class="nl mk it nh b gy nr nn l no np">X_train, X_test, y_train, y_test = train_test_split(titanic.drop('survived', axis = 1), titanic['survived'], test_size = 0.2, random_state = 121)  </span><span id="62b8" class="nl mk it nh b gy nr nn l no np">#Model Training <br/>clf = RandomForestClassifier() clf.fit(X_train, y_train)</span></pre><p id="4236" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">我们已经用泰坦尼克号的数据训练了我们的数据，现在我们可以试着用SHAP来解释这些数据。让我们利用模型的全局可解释性来理解SHAP是如何工作的。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="5412" class="nl mk it nh b gy nm nn l no np">import shap <br/>shap_values = shap.TreeExplainer(clf).shap_values(X_train) shap.summary_plot(shap_values, X_train)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/7710d553b86c021a0861e37e1031d2d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/0*ArCSda4aHw7gh4ir.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">要素对预测结果的总体影响(图片由作者提供)</p></figure><p id="7532" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">从结果可以看出，年龄特征对预测结果的贡献最大。如果您想查看特定类对预测的贡献，我们只需要稍微调整一下代码。假设我们要查看类0，这意味着我们使用下面的代码。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="27c9" class="nl mk it nh b gy nm nn l no np">shap.summary_plot(shap_values[0], X_train)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/1f99f58fce8021f091c441a0d3600ba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/0*F0ifGrirunC2Hmtx.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">功能对类0的影响(图片由作者提供)</p></figure><p id="1579" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">从上图中，我们可以看到每个数据对预测概率的贡献。颜色越红，数值越高，反之亦然。此外，当该值在正侧时，它有助于类0预测结果概率，反之亦然。</p><p id="4168" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">SHAP不局限于全球可解释性；它还为您提供了解释单个数据集的功能。让我们尝试解释第一行的预测结果。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="cdae" class="nl mk it nh b gy nm nn l no np">explainer = shap.TreeExplainer(clf)<br/>shap_value_single = explainer.shap_values(X = X_train.iloc[0,:])<br/>shap.force_plot(base_value = explainer.expected_value[1],<br/>                shap_values = shap_value_single[1],<br/>                features = X_train.iloc[0,:])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/2238c6a44a185fbc1e2b859c3544b707.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kmwgJBNpyfTHfYZv.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">第一行的单个预测结果解释(图片由作者提供)</p></figure><p id="d99f" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">从上图中可以看出，预测更接近于0类，因为它是由age和sibsp功能推动的，而parch功能的贡献很小。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="6cce" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">4.Mlxtend</h1><p id="2616" class="pw-post-body-paragraph lb lc it le b lf nb ju lh li nc jx lk lz nd ln lo ma ne lr ls mb nf lv lw lx im bi translated">Mlxtend或<strong class="le iu">机器学习扩展</strong>是一个用于数据科学日常工作生活的Python包。包中的API并不局限于可解释性，而是扩展到各种功能，比如统计评估、数据模式、图像提取等等。然而，我们将讨论我们当前文章的可解释性API绘制的<strong class="le iu">决策区域。</strong></p><p id="70a3" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">决策区域图API将生成一个决策区域图，以可视化该特征如何决定分类模型预测。让我们尝试使用示例数据和来自Mlxtend的指南。</p><p id="eaab" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">首先，我们需要安装Mlxtend包。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="0e2a" class="nl mk it nh b gy nm nn l no np">pip install Mlxtend</span></pre><p id="c5ee" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">然后，我们使用示例数据集并开发一个模型来查看Mlxtend的运行情况。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="6d7a" class="nl mk it nh b gy nm nn l no np">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import matplotlib.gridspec as gridspec<br/>import itertools<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.svm import SVC<br/>from sklearn.ensemble import RandomForestClassifier<br/>from mlxtend.classifier import EnsembleVoteClassifier<br/>from mlxtend.data import iris_data<br/>from mlxtend.plotting import plot_decision_regions</span><span id="a541" class="nl mk it nh b gy nr nn l no np"># Initializing Classifiers<br/>clf1 = LogisticRegression(random_state=0)<br/>clf2 = RandomForestClassifier(random_state=0)<br/>clf3 = SVC(random_state=0, probability=True)<br/>eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[2, 1, 1], voting='soft')</span><span id="a1d8" class="nl mk it nh b gy nr nn l no np"># Loading some example data<br/>X, y = iris_data()<br/>X = X[:,[0, 2]]</span><span id="307c" class="nl mk it nh b gy nr nn l no np"># Plotting Decision Regions<br/>gs = gridspec.GridSpec(2, 2)<br/>fig = plt.figure(figsize=(10, 8))</span><span id="96d9" class="nl mk it nh b gy nr nn l no np">for clf, lab, grd in zip([clf1, clf2, clf3, eclf],<br/>                         ['Logistic Regression', 'Random Forest', 'RBF kernel SVM', 'Ensemble'],<br/>                         itertools.product([0, 1], repeat=2)):<br/>    clf.fit(X, y)<br/>    ax = plt.subplot(gs[grd[0], grd[1]])<br/>    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)<br/>    plt.title(lab)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/3266425cae9e6de982f7736eff2a47c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Ydrsu1VjE8yUQAQ8.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">基于不同机器学习分类器的决策区域绘制(图片由作者提供)</p></figure><p id="5a42" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">从上面的图中，我们可以解释模型做出的决定。当他们做出预测时，你可以看到每个模型之间的差异。例如，X轴值越高，类1的逻辑回归模型预测结果越大，但Y轴上没有太大变化。它与随机森林模型形成对比，在随机森林模型中，划分不会随着X轴值发生很大变化，而Y轴值对于每个预测都似乎是恒定的。</p><p id="e69a" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">决策区域的唯一缺点是它仅限于二维特征，因此它对于预分析比实际模型本身更有用。然而，它对于与商务人士的交谈仍然是有用的。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="a2da" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">5.PDPBox</h1><p id="81f1" class="pw-post-body-paragraph lb lc it le b lf nb ju lh li nc jx lk lz nd ln lo ma ne lr ls mb nf lv lw lx im bi translated">PDP或<strong class="le iu">部分依赖图</strong>是显示特征对机器学习模型的预测结果的边际效应的图。它用于评估特征和目标之间的相关性是线性的、单调的还是更复杂的。</p><p id="fb52" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">用部分依赖情节来解释的好处是对于商务人士来说很容易解释。这是因为部分相关函数的计算足够直观，人们可以理解:当我们干预一个特征时，部分相关图的计算具有因果解释，并且我们测量预测中的变化；这是我们可以衡量解释的时候。</p><p id="1a03" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">让我们尝试使用用户指南中的样本数据来更好地理解<a class="ae ly" href="https://github.com/SauceCat/PDPbox" rel="noopener ugc nofollow" target="_blank"> PDPBox </a>。首先，我们需要安装PDPBox包。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="94af" class="nl mk it nh b gy nm nn l no np">pip install pdpbox</span></pre><p id="b838" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">然后，我们可以尝试按照<a class="ae ly" href="https://github.com/SauceCat/PDPbox/blob/master/tutorials/pdpbox_binary_classification.ipynb" rel="noopener ugc nofollow" target="_blank">用户指南</a>了解更多关于PDPBox如何帮助我们创建可解释的机器学习的信息。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="6173" class="nl mk it nh b gy nm nn l no np">import pandas as pd<br/>from pdpbox import pdp, get_dataset, info_plots</span><span id="3f7e" class="nl mk it nh b gy nr nn l no np">#We would use the data and model from the pdpbox</span><span id="30ab" class="nl mk it nh b gy nr nn l no np">test_titanic = get_dataset.titanic()</span><span id="cc23" class="nl mk it nh b gy nr nn l no np">titanic_data = test_titanic['data']<br/>titanic_features = test_titanic['features']<br/>titanic_model = test_titanic['xgb_model']<br/>titanic_target = test_titanic['target']</span></pre><p id="2f1e" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">当我们有了数据和模型后，让我们尝试使用info plots函数来检查特征和目标之间的信息。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="d5e8" class="nl mk it nh b gy nm nn l no np">fig, axes, summary_df = info_plots.target_plot(<br/>    df=titanic_data, feature='Sex', feature_name='gender', target=titanic_target<br/>)<br/>_ = axes['bar_ax'].set_xticklabels(['Female', 'Male'])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/6450f0df67099f86a129eb9fc973cb2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9FnJy7cx3aX2PiCr.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">二进制特征的目标图(来源:<a class="ae ly" href="https://github.com/SauceCat/PDPbox/blob/master/tutorials/pdpbox_binary_classification.ipynb)" rel="noopener ugc nofollow" target="_blank">https://github . com/sauce cat/PDPbox/blob/master/tutorials/PDPbox _ binary _ class ification . ipynb)</a></p></figure><p id="176f" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">用一个函数就可以得到目标和特征的统计信息。使用该功能很容易向商务人士解释。让我们一起检查模型预测分布函数和特征。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="1137" class="nl mk it nh b gy nm nn l no np">fig, axes, summary_df = info_plots.actual_plot(<br/>    model=titanic_model, X=titanic_data[titanic_features], feature='Sex', feature_name='gender')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/a4f5067353b1b40b26952d229b1f91b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dTXZrwnX7LQG0K7F.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">二元特征的实际预测图(来源:<a class="ae ly" href="https://github.com/SauceCat/PDPbox/blob/master/tutorials/pdpbox_binary_classification.ipynb)" rel="noopener ugc nofollow" target="_blank">https://github . com/sauce cat/PDP box/blob/master/tutorials/PDP box _ binary _ class ification . ipynb)</a></p></figure><p id="3549" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">现在，让我们继续使用PDP绘图功能来解释我们的模型预测。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="92c7" class="nl mk it nh b gy nm nn l no np">pdp_sex = pdp.pdp_isolate(<br/>    model=titanic_model, dataset=titanic_data, model_features=titanic_features, feature='Sex')</span><span id="252e" class="nl mk it nh b gy nr nn l no np">fig, axes = pdp.pdp_plot(pdp_sex, 'Sex')<br/>_ = axes['pdp_ax'].set_xticklabels(['Female', 'Male'])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/77998d81d45c35673340ebba56621f87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2aG1TapFg4rPzaMZ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">性特征PDP剧情(来源:<a class="ae ly" href="https://github.com/SauceCat/PDPbox/blob/master/tutorials/pdpbox_binary_classification.ipynb)" rel="noopener ugc nofollow" target="_blank">https://github . com/sauce cat/PDP box/blob/master/tutorials/PDP box _ binary _ class ification . ipynb)</a></p></figure><p id="ede2" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">从上图中，我们可以理解为，当性别特征为男性时，预测概率会降低(意味着男性存活的可能性更小)。这就是我们如何使用PDPbox来获得模型可解释性。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="b350" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">6.解释性语言</h1><p id="fe91" class="pw-post-body-paragraph lb lc it le b lf nb ju lh li nc jx lk lz nd ln lo ma ne lr ls mb nf lv lw lx im bi translated"><a class="ae ly" href="https://interpret.ml/docs/getting-started.html" rel="noopener ugc nofollow" target="_blank"> InterpretML </a>是一个Python包，包含了很多机器学习可解释性API。这个软件包的目的是给你一个基于plotly的交互式绘图，以了解你的预测结果。</p><p id="6c2c" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">通过使用我们已经讨论过的许多技术——即SHAP和PDP，InterpretML为您提供了许多解释您的机器学习(全局和局部)的方法。此外，这个包拥有一个Glassbox模型API，当您开发模型时，它为您提供了一个可解释性函数。</p><p id="f6a4" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">让我们用一个样本数据集来试试这个包。首先，我们需要安装InterpretML。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="e265" class="nl mk it nh b gy nm nn l no np">pip install interpret</span></pre><p id="b446" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">我想用解释的玻璃盒子模型给你一个例子，因为，对我个人来说，使用起来很有趣。让我们尝试使用titanic数据集样本来开发模型。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="56ba" class="nl mk it nh b gy nm nn l no np">from sklearn.model_selection import train_test_split<br/>from interpret.glassbox import ExplainableBoostingClassifier<br/>import seaborn as sns</span><span id="991a" class="nl mk it nh b gy nr nn l no np">#the glass box model (using Boosting Classifier)<br/>ebm = ExplainableBoostingClassifier(random_state=120)</span><span id="9735" class="nl mk it nh b gy nr nn l no np">titanic = sns.load_dataset('titanic').dropna()</span><span id="45a3" class="nl mk it nh b gy nr nn l no np">#Data splitting<br/>X_train, X_test, y_train, y_test = train_test_split(titanic.drop(['survived', 'alive'], axis = 1), <br/>                                                    titanic['survived'], test_size = 0.2, random_state = 121)<br/>#Model Training<br/>ebm.fit(X_train, y_train)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/d153c4cae3d1c469ca9fb72dfb7a864d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1CYG_gm8_wJO6zwD.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由玻璃盒模型开发的模型和特征结果(图片由作者提供)</p></figure><p id="6bdd" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">使用InterpretML中的玻璃盒模型，它会自动对您的特征进行热编码，并为您设计交互特征。让我们试着为这个模型找到一个全局的解释。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="0a09" class="nl mk it nh b gy nm nn l no np">from interpret import set_visualize_provider<br/>from interpret.provider import InlineProvider<br/>set_visualize_provider(InlineProvider())</span><span id="47b8" class="nl mk it nh b gy nr nn l no np">from interpret import show</span><span id="5ab2" class="nl mk it nh b gy nr nn l no np">ebm_global = ebm.explain_global()<br/>show(ebm_global)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/1c75f2c2486c8c2319f3977c91815532.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4MF-9anr3Qdkd9gn.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">玻璃盒子全球解读(图片由作者提供)</p></figure><p id="dcac" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">从上图中，我们可以看到模型特征重要性的总结。它显示了基于模型特征重要性的所有被认为重要的特征。</p><p id="a6af" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">可解释的是一个交互式的图，您可以用它来更具体地解释模型。如果我们只看到上图中的摘要，我们可以选择另一个组件来指定您想要看到的特性。这样，我们可以解释模型中的特征如何影响预测。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/5e930f855d9690fbbb9c551c88fa366e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*68Dse-te2U7P0JLu.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">票价全球可解释性(图片由作者提供)</p></figure><p id="db13" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">在上图中，我们可以看到低票价降低了生存的机会，但随着票价变高，它增加了生存的机会。然而，你可以看到密度和条形图-许多人来自一个较低的票价。</p><p id="92e4" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">很多时候，我们不仅对全局的可解释性感兴趣，也对局部的可解释性感兴趣。在这种情况下，我们可以使用下面的代码来解释它。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="ac09" class="nl mk it nh b gy nm nn l no np">#Select only the top 5 rows from the test data<br/>ebm_local = ebm.explain_local(X_test[:5], y_test[:5])<br/>show(ebm_local)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/9df820535d8245f4b423f60ee44d1d18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9fYE7znpudzgbCp1.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">首行局部可解释性(图片由作者提供)</p></figure><p id="cd99" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated"><strong class="le iu">局部可解释性</strong>显示了单个预测是如何做出的。根据用户指南，这里显示的值是来自模型的<strong class="le iu">对数优势</strong>分数，它们被相加并通过逻辑连接函数得到最终预测。我们可以看到，在这个预测中，男性性工作者对降低生存几率的贡献最大。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="d005" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">结论</h1><p id="eca5" class="pw-post-body-paragraph lb lc it le b lf nb ju lh li nc jx lk lz nd ln lo ma ne lr ls mb nf lv lw lx im bi translated">机器学习的可解释性对于任何数据科学家来说都是一个重要的工具，因为它允许您更好地向业务用户传达您的结果。</p><p id="7bab" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">在这篇文章中，我已经概述了另一个6ML可解释性Python包:</p><ol class=""><li id="41a2" class="nt nu it le b lf lg li lj lz nv ma nw mb nx lx ny nz oa ob bi translated"><strong class="le iu">黄砖</strong></li><li id="acc3" class="nt nu it le b lf oc li od lz oe ma of mb og lx ny nz oa ob bi translated"><strong class="le iu"> ELI5 </strong></li><li id="769a" class="nt nu it le b lf oc li od lz oe ma of mb og lx ny nz oa ob bi translated"><strong class="le iu"> SHAP </strong></li><li id="c79f" class="nt nu it le b lf oc li od lz oe ma of mb og lx ny nz oa ob bi translated"><strong class="le iu"> Mlxtend </strong></li><li id="0fa1" class="nt nu it le b lf oc li od lz oe ma of mb og lx ny nz oa ob bi translated"><strong class="le iu"> PDPBox </strong></li><li id="b653" class="nt nu it le b lf oc li od lz oe ma of mb og lx ny nz oa ob bi translated"><strong class="le iu"> InterpretML </strong></li></ol><p id="f5a3" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">希望有帮助！</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><p id="2306" class="pw-post-body-paragraph lb lc it le b lf lg ju lh li lj jx lk lz lm ln lo ma lq lr ls mb lu lv lw lx im bi translated">访问我的<a class="ae ly" href="https://www.linkedin.com/in/cornellius-yudha-wijaya/" rel="noopener ugc nofollow" target="_blank"><strong class="le iu">LinkedIn</strong></a><strong class="le iu"/>或<a class="ae ly" href="https://twitter.com/CornelliusYW" rel="noopener ugc nofollow" target="_blank"> <strong class="le iu"> Twitter </strong> </a> <strong class="le iu">。</strong></p><blockquote class="ou"><p id="4a58" class="ov ow it bd ox oy oz pa pb pc pd lx dk translated">如果您没有订阅为中等会员，请考虑通过<a class="ae ly" href="https://cornelliusyudhawijaya.medium.com/membership" rel="noopener">我的推荐</a>订阅。</p></blockquote></div></div>    
</body>
</html>