<html>
<head>
<title>What are RMSE and MAE?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">RMSE和梅是什么？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-are-rmse-and-mae-e405ce230383?source=collection_archive---------3-----------------------#2021-05-14">https://towardsdatascience.com/what-are-rmse-and-mae-e405ce230383?source=collection_archive---------3-----------------------#2021-05-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4777" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">评估指标的简单指南</h2></div><p id="ac17" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">均方根误差(RMSE)和平均绝对误差(MAE)是用于评估回归模型的指标。这些指标告诉我们我们的预测有多准确，以及与实际值的偏差有多大。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lb"><img src="../Images/9c8324d4a39c08aabe21edcbcf612ab2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*8TAmOMfi233bfH_p4nO4vA.jpeg"/></div><p class="lj lk gj gh gi ll lm bd b be z dk translated">帕特丽夏·塞尔纳在<a class="ae ln" href="https://unsplash.com/s/photos/inch?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="7275" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从技术上来说，RMSE是<strong class="kh ir"> E </strong>错误的<strong class="kh ir"> S </strong>方的<strong class="kh ir"> R </strong> oot，而MAE是<strong class="kh ir">A</strong>b错误的<strong class="kh ir"> M </strong> ean。在这里，误差是一个变量的预测值(由我们的回归模型预测的值)和实际值之间的差异。它们的计算方法如下:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/b0d25d333bdeefd24da0ca4309a35b9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*5OQunI-NR-S0gAZFIit1Rw.png"/></div></figure><p id="8415" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">仔细观察，你会发现两者都是误差的平均值。</p><p id="d81d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们用一个例子来理解这个。比如说，我想根据经验的年数来预测一个数据科学家的工资。所以，工资是我的目标变量(Y)，经验是自变量(X)。我有一些关于X和Y的随机数据，我们将使用<a class="ae ln" href="https://en.wikipedia.org/wiki/Linear_regression" rel="noopener ugc nofollow" target="_blank">线性回归</a>来预测工资。让我们使用<a class="ae ln" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank">熊猫</a>和<a class="ae ln" href="https://scikit-learn.org/stable/getting_started.html" rel="noopener ugc nofollow" target="_blank"> scikit-lear </a> n进行数据加载和创建线性模型。</p><pre class="lc ld le lf gt lp lq lr ls aw lt bi"><span id="5d76" class="lu lv iq lq b gy lw lx l ly lz">import pandas as pd<br/>from sklearn.linear_model import LinearRegression</span><span id="9cd3" class="lu lv iq lq b gy ma lx l ly lz">sal_data={"Exp":[2,2.2, 2.8, 4, 7, 8, 11, 12, 21, 25], <br/>          "Salary": [7, 8, 11, 15, 22, 29, 37 ,45.7, 49, 52]}</span><span id="107d" class="lu lv iq lq b gy ma lx l ly lz">#Load data into a pandas Dataframe<br/>df=pd.DataFrame(sal_data)<br/>df.head(3)</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/b6773ffb6ed7f368cd31d0d0ecdba8ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*2iXl5gr1bD2UiG5w6Ou7QQ.png"/></div></figure><pre class="lc ld le lf gt lp lq lr ls aw lt bi"><span id="3752" class="lu lv iq lq b gy lw lx l ly lz">#Selecting X and y variables</span><span id="365e" class="lu lv iq lq b gy ma lx l ly lz">X=df[['Experience']]<br/>y=df.Salary</span><span id="0b01" class="lu lv iq lq b gy ma lx l ly lz">#Creating a Simple Linear Regression Model to predict salaries</span><span id="c51c" class="lu lv iq lq b gy ma lx l ly lz">lm=LinearRegression()<br/>lm.fit(X,y)</span><span id="1a79" class="lu lv iq lq b gy ma lx l ly lz">#Prediction of salaries by the model<br/>yp=lm.predict(X)<br/>print(yp)</span><span id="1a4f" class="lu lv iq lq b gy ma lx l ly lz">[12.23965934 12.64846842 13.87489568 16.32775018 22.45988645 24.50393187 30.63606813 32.68011355 51.07652234 59.25270403]</span></pre><p id="7796" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们有了“yp”——我们的工资预测数组，我们将通过绘制预测工资(yp)和实际工资(y)来评估我们的模型。我正在用<a class="ae ln" href="https://docs.bokeh.org/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> bohek </a>进行我的可视化。</p><pre class="lc ld le lf gt lp lq lr ls aw lt bi"><span id="fc24" class="lu lv iq lq b gy lw lx l ly lz">from bokeh.plotting import figure, show, output_file</span><span id="43f9" class="lu lv iq lq b gy ma lx l ly lz">p=figure(title="Actual vs Predicted Salary", width=450, height=300)<br/>p.title.align = 'center'<br/>p.circle(df.Exp, df.Salary)<br/>p.line(df.Exp, df.Salary, legend_label='Actual Salary', line_width=3, line_alpha=0.4)<br/>p.circle(df.Exp, yp, color="red")<br/>p.line(df.Exp,yp, color="red",legend_label='Predicted Salary', line_width=3, line_alpha=0.4)</span><span id="bbdf" class="lu lv iq lq b gy ma lx l ly lz">p.xaxis.axis_label = 'Experience'<br/>p.yaxis.axis_label = 'Salary'</span><span id="02dc" class="lu lv iq lq b gy ma lx l ly lz">show(p)</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/30f44dea6e2a426512a3b74e2cb1d1c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Igk3wrNYCwkLnwNb2_ulfQ.png"/></div></figure><p id="2cd3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从上图中，我们看到预测数据点和实际数据点之间存在差距。在统计学上，这种差距/差异被称为残差，通常被称为误差，用于RMSE和MAE。Scikit-learn提供了<a class="ae ln" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" rel="noopener ugc nofollow" target="_blank">度量</a>库来计算这些值。然而，我们将通过使用上面的数学表达式来计算RMSE和MAE。这两种方法会给你同样的结果。</p><pre class="lc ld le lf gt lp lq lr ls aw lt bi"><span id="3b71" class="lu lv iq lq b gy lw lx l ly lz">import numpy as np<br/>print(f'Residuals: {y-yp}')<br/>np.sqrt(np.mean(np.square(y-yp)))  #RMSE</span><span id="bb9c" class="lu lv iq lq b gy ma lx l ly lz">np.mean(abs(y-yp))                 #MAE</span><span id="d39c" class="lu lv iq lq b gy ma lx l ly lz">#RMSE/MAE computation using sklearn library<br/>from sklearn.metrics import mean_squared_error, mean_absolute_error</span><span id="5ede" class="lu lv iq lq b gy ma lx l ly lz">np.sqrt(mean_squared_error(y, yp))<br/>mean_absolute_error(y, yp)</span><span id="c0d7" class="lu lv iq lq b gy ma lx l ly lz"><strong class="lq ir">6.48<br/>5.68</strong></span></pre><p id="c43a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是我们的基线模型。MAE约为5.7——似乎更高。现在我们的目标是通过减少这个误差来改进这个模型。</p><p id="214b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们用同样的模型对“experience”(X)进行多项式变换，看看我们的误差是否减少了。</p><pre class="lc ld le lf gt lp lq lr ls aw lt bi"><span id="328a" class="lu lv iq lq b gy lw lx l ly lz">from sklearn.preprocessing import PolynomialFeatures<br/>pf=PolynomialFeatures()     #Linear Equation of degree 2<br/>X_poly=pf.fit_transform(X) <br/></span><span id="95cc" class="lu lv iq lq b gy ma lx l ly lz">lm.fit(X_poly, y)<br/>yp=lm.predict(X_poly)</span></pre><p id="8d6a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我已经使用Scikit-learn <a class="ae ln" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html" rel="noopener ugc nofollow" target="_blank">多项式特性</a>创建了一个1、X和X2的矩阵，并将其作为输入传递给我的模型。</p><p id="0b61" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">计算我们的误差指标和…</p><pre class="lc ld le lf gt lp lq lr ls aw lt bi"><span id="e67d" class="lu lv iq lq b gy lw lx l ly lz">#RMSE and MAE<br/>np.sqrt(np.mean(np.square(y-yp)))<br/>np.mean(abs(y-yp))</span><span id="0f15" class="lu lv iq lq b gy ma lx l ly lz"><strong class="lq ir">2.3974<br/>1.6386</strong></span></pre><p id="8106" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">瞧……他们这次低多了。它比我们的基线模型更适合！让我们画出y和yp(就像我们之前做的那样)来检查重叠部分。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi md"><img src="../Images/03f2928c8df7f9b8af46518fbcb20c04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*1qYTIMbMdHFHkVutivc5ew.png"/></div></figure><p id="0175" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">两条线之间的间隙已经减小。让我们使用seaborn的<a class="ae ln" href="https://seaborn.pydata.org/generated/seaborn.residplot.html" rel="noopener ugc nofollow" target="_blank">残差</a>绘图函数来观察残差或误差(y-yp)的分布</p><pre class="lc ld le lf gt lp lq lr ls aw lt bi"><span id="3b51" class="lu lv iq lq b gy lw lx l ly lz">print(y-yp)   #residuals<br/>[ 0.333921 0.447306  0.84028668 -0.136044 -4.190238 -0.434767<br/> -0.847751  5.488121 -2.584481  1.083648]</span><span id="ba30" class="lu lv iq lq b gy ma lx l ly lz">import seaborn as sns<br/>sns.residplot(y, yp)  <br/>plt.show()</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi me"><img src="../Images/005e9a4753a104f8d29cdd4ffa0b1fb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*z_iLhnb7pHTcTuW5JQCMrg.png"/></div></figure><p id="e0ae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们看到残差往往集中在x轴周围，这是有意义的，因为它们可以忽略不计。</p><p id="a679" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">还有第三个指标——R平方得分，通常用于回归模型。这衡量了我们的模型可以解释的变化量，即我们的模型返回的正确预测的百分比。它也被称为决定系数，通过以下公式计算:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/c9c8257bf7a556b4a5da119d261efbc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*H3D-sstHHXEPEtZuntFu7Q.png"/></div></figure><p id="9e83" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们使用公式和sklearn库来计算R2，并比较这些值。这两种方法应该给你相同的结果。</p><pre class="lc ld le lf gt lp lq lr ls aw lt bi"><span id="7b68" class="lu lv iq lq b gy lw lx l ly lz">#Calculating R-Squared manually<br/>a=sum(np.square(y-yp))           # a -&gt; sum of square of residuals<br/>b=sum(np.square(y-np.mean(y)))   # b -&gt; total sum of sqaures</span><span id="3f01" class="lu lv iq lq b gy ma lx l ly lz">r2_value = 1-(a/b)<br/><strong class="lq ir">0.979</strong></span><span id="4bcb" class="lu lv iq lq b gy ma lx l ly lz">#calculating r2 using sklearn<br/>from sklearn.metrics import r2_score<br/>print(r2_score(y, yp))<br/><strong class="lq ir">0.979</strong></span></pre><p id="1403" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，总的来说，我们可以认为98%的模型预测是正确的，误差的变化在2个单位左右。对于一个理想的模型，RMSE/梅=0，R2分数= 1，所有的剩余点都在X轴上。对于任何业务解决方案来说，实现这样的价值几乎是不可能的！</p><p id="3ec5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以用来提高模型准确性的一些技术包括:</p><ul class=""><li id="25f4" class="mg mh iq kh b ki kj kl km ko mi ks mj kw mk la ml mm mn mo bi translated">变换/缩放功能</li><li id="05f1" class="mg mh iq kh b ki mp kl mq ko mr ks ms kw mt la ml mm mn mo bi translated">处理异常值(如果有)</li><li id="428d" class="mg mh iq kh b ki mp kl mq ko mr ks ms kw mt la ml mm mn mo bi translated">添加新功能/功能工程</li><li id="ed33" class="mg mh iq kh b ki mp kl mq ko mr ks ms kw mt la ml mm mn mo bi translated">使用不同的算法</li><li id="de5e" class="mg mh iq kh b ki mp kl mq ko mr ks ms kw mt la ml mm mn mo bi translated">模型超参数调谐</li></ul><p id="cbb4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我的下一篇文章中，我将详细解释上面的一些概念。以上代码可以参考我的笔记本<a class="ae ln" href="https://github.com/sacharya225/data-expts/blob/master/SalaryPrediction_Regression.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>。</p></div></div>    
</body>
</html>