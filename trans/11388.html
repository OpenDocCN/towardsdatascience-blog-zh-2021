<html>
<head>
<title>Penalised Regression With The New ASGL Python Module</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用新的 ASGL Python 模块惩罚回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/penalised-regression-with-the-new-asgl-python-module-9a4c36b13e02?source=collection_archive---------33-----------------------#2021-11-08">https://towardsdatascience.com/penalised-regression-with-the-new-asgl-python-module-9a4c36b13e02?source=collection_archive---------33-----------------------#2021-11-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9b1d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">随身携带的新 Python 模块</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0d467fce16bd5f55cc831216ddc26731.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JA88wiEfzkGXLMCBZ6j7iw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">伊利亚·巴甫洛夫在<a class="ae ky" href="https://unsplash.com/s/photos/coding?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="0211" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有几个用于回归的 Python 模块，每个模块都有其特殊性和局限性。现有 Python 模块的使用很大程度上取决于用户想要执行的回归类型及其目标。如果回归是简单的，并且变量是连续的，在许多情况下 NumPy 库有特定的方法来处理这个问题。另一方面，如果您对更复杂的定量和定性变量回归问题感兴趣，则 Scikit-learn 模块可根据具体情况和问题为用户提供多种选择。</p><p id="56c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最近，一个新的 Python 模块已经向公众开放，其目的是改善当前 Python 模块在惩罚回归方面的一些限制，并提高操作性能。模块的名称是<a class="ae ky" href="https://github.com/alvaromc317/asgl" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> asgl(自适应稀疏组套索)</strong> </a> <strong class="lb iu">。在这篇文章中，我讨论了这个模块是关于什么的，它应该做什么，以及你是否应该在你的回归问题中使用它。</strong></p><h1 id="1c62" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">当前的事态</h1><p id="ee23" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">许多软件为用户提供了根据具体问题以不同尺度进行回归的可能性。人们可以用 Python、Mathematica、R 和 Matlab 进行回归，这里仅举几个例子。</p><p id="026d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">回归可以分为几类，其中最重要的一类是<strong class="lb iu">惩罚回归</strong>。当预测值的数量(<em class="ms"> p </em>)远大于观察数据的数量(<em class="ms"> n </em>)时，这种类型的回归通常在高维数据中非常重要。</p><p id="a31c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">惩罚过程包括向最小平方成本函数添加正则化器<em class="ms">C(</em><strong class="lb iu"><em class="ms">x</em></strong><em class="ms">)；D) </em>。LASSO 是最重要的正则化方法之一，它给最小二乘代价函数增加了一个正则化惩罚。LASSO 的目标是提供线性模型系数的稀疏估计。套索的其他重要品种包括群套索和稀疏群套索。</p><p id="06a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">稀疏组套索是套索和套索组的概括，其目标是生成稀疏组之间和之内的回归解。</p><p id="a6bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上述所有基于套索的方法的共同问题是，它们都使用恒定的惩罚率<em class="ms"> 𝛌 </em>，这有可能严重影响变量选择的质量和准确性。为了解决这个问题，一些研究者提出了所谓的自适应群套索(asgl)方法来计算成本函数<em class="ms">C(</em><strong class="lb iu"><em class="ms">x</em></strong><em class="ms">；d)。</em>读者可以在这篇<a class="ae ky" href="https://link.springer.com/article/10.1007%2Fs11634-020-00413-8" rel="noopener ugc nofollow" target="_blank">文章</a>中找到这种方法的数学描述。该方法的目标是在高维度和低维度数据集中提供非常好的误差估计。</p><p id="811f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我上面提到的，可以做不同的层次(套索等。)使用 Scikit-learn 和 Statsmodel 进行回归。然而，由于 asgl 误差估计器是一个相对较新的概念，这个估计器不包括在上面提到的 Python 模块中。asgl Python 模块将标准套索和组套索扩展到适用于线性和分位数回归的情况，我将在下面进行描述。</p><h1 id="939c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">线性和分位数回归的 asgl</h1><p id="437c" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我假设读者知道什么是线性回归，以及它是如何正式完成的。然而，读者可能不太熟悉分位数回归。这种类型的回归是由 Koenker 和 Basset 在 1978 年提出的，它适用于存在异方差和异常值的情况。该方法的目标是提供自变量条件分位数作为协变量函数的估计值。</p><p id="b41f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当仅在线性和分位数回归的情况下可以使用自适应方法时，asgl 误差估计器提供了一个框架。正如我上面提到的，在线性和分位数回归的情况下，Statsmodel 和 Scikit-learn 中不存在自适应方法。例如，Scikit-learn Python 模块根本没有给用户提供执行分位数回归的可能性，更不用说自适应情况了。</p><p id="1009" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在 asgl 方法中，通过使用惩罚自适应方法找到的参数向量𝜷的解是由给出的<a class="ae ky" href="https://link.springer.com/article/10.1007%2Fs11634-020-00413-8" rel="noopener ugc nofollow" target="_blank">:</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/eabe28427fcc85a4494f29105c3bf72b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*td2FEe8jzB_cZwOqVPdXpA.png"/></div></div></figure><p id="0cc9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中<em class="ms"> R( </em> 𝜷 <em class="ms"> ) </em>是仅用于线性和分位数回归的风险函数。在线性回归的情况下，该函数由下式给出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/799b4cf49b986b0c9a9c66d6a9b06471.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ODx58M6uS9_vaehXff7foA.png"/></div></div></figure><p id="9c9b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一方面，在分位数回归的情况下，它由下式给出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/2697cd6c96014b56bb0026dc6d0b6554.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5X4ByRyQnnVI1bQef0UYYA.png"/></div></div></figure><p id="dc97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中函数𝜌_𝜏是所谓的损失检查函数。在上面的参数向量方程中，<em class="ms"> 𝛌 </em>是控制惩罚权重的惩罚率，<em class="ms"> K </em>是组的数量，𝜷^l 是从第<em class="ms"> l 到第</em>组的𝜷分量的向量，在组套索中，<em class="ms"> p_l </em>是每个<em class="ms"> l 到第</em>组的大小，𝛼是控制套索和组套索之间的平衡的参数。波浪号矢量<strong class="lb iu"> <em class="ms"> v </em> </strong>和<strong class="lb iu"> <em class="ms"> w </em> </strong>是 asgl 模型中定义的权重矢量。更多细节可以在原研<a class="ae ky" href="https://link.springer.com/article/10.1007%2Fs11634-020-00413-8" rel="noopener ugc nofollow" target="_blank">文章</a>中找到。</p><p id="bf27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">asgl 方法带来的关键概念，即包含在<strong class="lb iu"> <em class="ms"> v </em> </strong>和<strong class="lb iu"> <em class="ms"> w、</em> </strong>中的关键概念是，重要的变量必须具有较小的权重，因此处罚较轻，而不太重要的变量必须具有较大的权重，并且处罚较重。这种方法通过提高准确性和变量选择为用户提供了更多的灵活性。</p><h1 id="f02e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">如何用 Python 实现 asgl？</h1><p id="5242" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">与其他 Python 包一样，使用 asgl 模块/包非常简单。可以使用以下命令完成安装:</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="a0a8" class="nb lw it mx b gy nc nd l ne nf">pip install asgl</span></pre><p id="5229" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">aslg 模块基于其他 python 模块，如 NumPy(1.15 版或更高版本)、Scikit-learn(0 . 23 . 1 版或更高版本)、cvx py(1 . 1 . 0 版或更高版本)。该模块还需要 Python 版本 3.5 或更高版本。</p><p id="aeda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一种可能是使用 GitHub 并提取以下存储库:</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="9703" class="nb lw it mx b gy nc nd l ne nf">git clone https://github.com/alvaromc317/asgl.git</span></pre><p id="8310" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，在存储库提取之后，您必须运行以下代码来执行 setup.py 文件:</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="1052" class="nb lw it mx b gy nc nd l ne nf">cd asgl<br/>Python setup.py</span></pre><h1 id="459d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">你能用 asgl 做什么？</h1><p id="e9a9" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">asgl 模块使用四个主要的类对象:ASGL 类、重量类、CV 类和 TVT 类。有了这些类，就可以使用上面描述的自适应方法来解决实际的线性和分位数回归问题。</p><p id="4986" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ASGL 类是最重要的一个，它可以用来执行套索、群组套索、稀疏套索和自适应稀疏套索。asgl 类的缺省参数是(更多细节请参见 ASGL 模块作者撰写的这篇<a class="ae ky" href="https://arxiv.org/pdf/2111.00472.pdf" rel="noopener ugc nofollow" target="_blank"> arXiv 文章</a>):</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="624b" class="nb lw it mx b gy nc nd l ne nf">model = asgl.ASGL(model, penalization, intercept=True, tol=1e-5,lambda1=1, alpha=0.5, tau=0.5, lasso_weights=None,gl_weights=None, parallel=False, num_cores=None, solver=None,max_iters=500)</span></pre><p id="7844" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ASGL 类有三个主要方法，分别是:<strong class="lb iu">拟合</strong>、<strong class="lb iu">预测、</strong>和<strong class="lb iu">检索参数值。</strong><strong class="lb iu">配合</strong>功能的调用方法是:</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="6262" class="nb lw it mx b gy nc nd l ne nf">fit(x, y, group_index)</span></pre><p id="db68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中<em class="ms"> x </em>是预测向量的 2D NumPy 数组，<em class="ms"> y </em>是 1D 独立变量向量，group_index 是长度等于问题中存在的变量数量的 1D NumPy 数组。</p><p id="b3d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">预测</strong>函数的调用方法是:</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="c78d" class="nb lw it mx b gy nc nd l ne nf">predict(x_new)</span></pre><p id="5321" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中 x_new 是一个 2D NumPy 数组，其列数等于原始矩阵<strong class="lb iu"><em class="ms"/></strong>中的列数。为了进行预测，用户必须运行以下命令:</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="8854" class="nb lw it mx b gy nc nd l ne nf">predictions = model.predict(x_new)</span></pre><p id="c5f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我们可以看到，这些模块的使用方式与其他 Python 模块(如 Statsmodel 或 Scikit-learn)相当标准。</p><p id="038e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个重要的方法是<strong class="lb iu">retrieve _ parameter _ values</strong>，它的作用是给出用 asgl 方法求解最小二乘回归得到的模型参数。要运行它，需要调用方法:</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="f038" class="nb lw it mx b gy nc nd l ne nf">retrieve_parameters_value(param_index)</span></pre><p id="38e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中，param_index 是不大于 model.coef_ list 长度的整数。要显示参数的解，需要运行:</p><pre class="kj kk kl km gt mw mx my mz aw na bi"><span id="6001" class="nb lw it mx b gy nc nd l ne nf">N <br/>model.retrieve_parameters_value(param_index = N)</span></pre><p id="b6e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中 N 是整数。</p><p id="89b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我上面讨论的，asgl 包有另外三个主要的类，每个类都有自己的重要性，可以根据用户的需要来使用。我在这里不讨论这些其他的类，读者可以参考 asgl 包存储库来获得更多的信息。</p><h1 id="bb51" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="12f6" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">上面我简要讨论了新的 asgl Python 包及其主要用途和特性。该软件包为用户提供了使用自适应方法进行线性和分位数回归的可能性。</p><p id="f2af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你应该使用 asgl 模块吗？这个问题的简短回答是:是的，你应该试一试。但是，我建议您首先了解 asgl 方法背后的理论，看看是否可以将其应用于您的数据科学和机器学习问题。正如作者所述，这个新模块让用户有可能首次在 Python 中执行分位数回归，并使用 asgl 包提供的自适应方法来改进变量选择和预测。</p></div><div class="ab cl ng nh hx ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="im in io ip iq"><h1 id="cdbf" class="lv lw it bd lx ly nn ma mb mc no me mf jz np ka mh kc nq kd mj kf nr kg ml mm bi translated">如果你喜欢我的文章，请与你可能对这个话题感兴趣的朋友分享，并在你的研究中引用/参考我的文章。不要忘记订阅将来会发布的其他相关主题。</h1></div></div>    
</body>
</html>