<html>
<head>
<title>How Well Does Self-Supervised Learning Perform In The Real World?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自我监督学习在现实世界中表现如何？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-well-does-self-supervised-learning-perform-in-the-real-world-ece18b2d45f6?source=collection_archive---------26-----------------------#2021-12-15">https://towardsdatascience.com/how-well-does-self-supervised-learning-perform-in-the-real-world-ece18b2d45f6?source=collection_archive---------26-----------------------#2021-12-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d580" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在随机互联网图像而不是ImageNet上预先训练模型</h2></div><p id="96fd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你一直在阅读最近关于自我监督预培训的出版物，你可能会注意到所有的新方法和技术大多是在ImageNet上评估的。ImageNet数据集高度多样化，规模庞大，包含大量的类。它是专门为评估图像处理模型的性能而策划的，因此它无疑非常适合这项任务。但是相对来说，很少有人强调这些自我监督技术在其他图像数据集上的表现。未切割且包含大量随机影像的数据集。在他们的论文<em class="le">“野外视觉特征的自我监督预训练”</em>中，Goyal等人着手调查<strong class="kk iu">当在一组随机、未切割的图像上进行训练时，自我监督预训练技术的感知性能是否成立</strong>。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/6b78885cb6ef1b8fca19e5d90d46924f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-qx84N7ropPj7BQwMtf3cQ.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">此图显示本文的主要模型SEER优于所有其他架构。来源:<a class="ae lv" href="https://arxiv.org/pdf/2103.01988.pdf" rel="noopener ugc nofollow" target="_blank">【1】</a></p></figure><h1 id="ebb4" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">先决条件</h1><p id="c3c9" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">本文中介绍的SEER模型结合了计算机视觉的多项最新进展。</p><p id="ce1e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，它利用了一个新颖且可扩展的架构，名为<strong class="kk iu"> RegNet </strong>。RegNet由<strong class="kk iu">量化的线性函数定义，以形成具有最佳宽度和深度的多个块的网络</strong>。RegNet有两种变体:RegNetX使用传统ResNet的剩余块，RegNetY利用挤压和激励块。我写了一整篇关于RegNet架构的文章，可以在这里随意阅读。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mt"><img src="../Images/b3dd013a82cff60ab94a8539c33f752c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7PGJzWFw-A50MUCULP-dwA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">RegNet各部分的图解。它由茎、体和头组成，如(a)所示。插图(b)和(c)更详细地展示了各个阶段和模块。来源:<a class="ae lv" href="https://arxiv.org/pdf/2003.13678.pdf" rel="noopener ugc nofollow" target="_blank">【2】</a></p></figure><p id="f0c4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">SEER论文的另一个重要组成部分是一种自我监督的预训练技术，称为<strong class="kk iu"> SwAV </strong>。这种技术用于SEER模型和进行比较。<strong class="kk iu"> SwaV使用数据增强来形成同一图像的多个不同版本</strong>。这些然后通过卷积神经网络创建一个潜在的表示。<strong class="kk iu">然后，通过公式化<strong class="kk iu">交换预测问题</strong>，该向量被学习分配给<em class="le"> K </em>个原型向量</strong>之一。如果你想更新你在SwAV上的知识，请在这里随意阅读我在报纸<a class="ae lv" href="https://medium.com/towards-data-science/paper-explained-unsupervised-learning-of-visual-features-by-contrasting-cluster-assignments-f9e87db3cb9b" rel="noopener">上的故事。</a></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mu"><img src="../Images/3b5590ca83c9e62e19d85889c90a854d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cTlnpvwz2LbdR_NwgPkCwA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">SwAV训练过程的图解。来源:<a class="ae lv" href="https://arxiv.org/pdf/2006.09882.pdf" rel="noopener ugc nofollow" target="_blank">【3】</a></p></figure><p id="f1f0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，SEER论文比较了它与另一种自我监督预训练技术<strong class="kk iu"> SimCLR </strong>的性能。SimCLR就像SwAV一样，使用<strong class="kk iu">数据增强来形成同一图像的增强版本对</strong>。这些然后被传递到一个卷积神经网络，形成一个特征向量。然后，这个矢量进入MLP，形成最终的网络输出。SimCLR使用了一种叫做<strong class="kk iu"> NT-Xent </strong>的新型损失函数，它寻求吸引同一物体的不同表示。同样，如果你想更深入地了解SimCLR，我在报纸上有一篇文章，你可以在这里阅读<a class="ae lv" href="https://medium.com/towards-data-science/paper-explained-a-simple-framework-for-contrastive-learning-of-visual-representations-6a2a63bfa703" rel="noopener">。</a></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mv"><img src="../Images/42967ebbe6be100b3c9505bb704b8ed0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RFILaYrPribmV3rP-lwA2w.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">显示SimCLR训练过程的图。来源:<a class="ae lv" href="https://arxiv.org/pdf/2002.05709.pdf" rel="noopener ugc nofollow" target="_blank">【4】</a></p></figure><h1 id="de69" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">开发可受益于大型未切割图像数据集的模型</h1><p id="6511" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">现在来看这篇论文的主要贡献。如前所述，<strong class="kk iu">本文的一个主要目标是找出一个大的、未切割的图像数据集将如何影响自监督方法的性能</strong>。此外，作者旨在开发一种方法，以超越其他当前最先进的技术。</p><p id="dbe7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了实现这一点，<strong class="kk iu">他们使用SwAV技术</strong>来定义预训练流程。更具体地说，他们创建了分辨率为2 x 224和4 x 96的图像对，并将许多不同的数据放大传递到模型中。他们还定义SwAV具有16K原型向量，这是为该技术设置的一个重要的超参数。</p><p id="8ce6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于模型架构，他们选择了前面提到的<strong class="kk iu"> RegNet </strong>，具体来说，他们试验了一系列网络，即使用前面提到的<strong class="kk iu">挤压和激励模块</strong>的<strong class="kk iu"> RegNetY-{8，16，32，64，128，256}GF </strong>。只有RegNet架构的巨大灵活性才能实现这种规格范围。在这个RegNet之上，他们定义了一个3层MLP投影头，以形成一个256维的输出向量</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mw"><img src="../Images/bdac20a79eaad2c51adc39b8d6cf2734.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wq-V9-g5FAft60QJT7qUQg.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">“SEER将最近的架构家族RegNet与在线自我监督训练相结合，以在数十亿张随机图像上对数十亿个参数进行预训练。”。来源:<a class="ae lv" href="https://ai.facebook.com/blog/seer-the-start-of-a-more-powerful-flexible-and-accessible-era-for-computer-vision/" rel="noopener ugc nofollow" target="_blank">【5】</a></p></figure><p id="8bf9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">整个SEER模型(SwAV with RegNet)是在<strong class="kk iu">多个不同的数据集</strong>上训练的，我们将在“结果”部分获得这些数据集<strong class="kk iu">，其中最值得注意的是来自Instagram </strong>的10亿张未切割图像。为了训练模型，作者使用了令人惊叹的<strong class="kk iu">512 NVIDIA V100 32GB GPU</strong>并训练了122K次迭代。现在，让我们看看SEER模型如何针对其他技术和不同的数据集进行测量。</p><h1 id="fe31" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结果</h1><p id="4786" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">这里有很多东西要打开。让我们从自我监督学习模型的经典评估开始。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mx"><img src="../Images/abfbccdd295653912ba62d243099f0d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wDfnO5m0BlmWIi7BGGF9iA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">在不同数据集上进行预训练并在ImageNet上进行微调时，不同自我监督预训练方法的结果表。来源:<a class="ae lv" href="https://arxiv.org/pdf/2103.01988.pdf" rel="noopener ugc nofollow" target="_blank">【1】</a></p></figure><p id="cdcc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作为第一个实验的一部分，<strong class="kk iu"> SEER在Instagram的10亿张随机图片上进行了预训练，然后在ImageNet上进行微调</strong>。令人难以置信的是，<strong class="kk iu"> SEER能够在ImageNet top-1精度上胜过所有其他方法</strong>。值得注意的是，它可以胜过原始的SwAV论文，即使它使用了自我监督的预训练技术，只是使用了不同的网络架构。此外，<strong class="kk iu">它的性能优于SimCLRv2模型，后者的参数比它的前身</strong>更大。顶级精度和参数数量之间似乎也有关联:模型越大，性能越好。<strong class="kk iu">有趣的是，SEER优于所有其他方法，尽管它是唯一一种在随机图像上预先训练的方法</strong>。SimCLRv2甚至在ImageNet上进行了预训练，后来用于评估。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi my"><img src="../Images/586bed64f1f7c093558c9930fd2c786c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*noWXeCq0feX5ele8874_Uw.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">一个显示低镜头学习场景结果的表格。来源:<a class="ae lv" href="https://arxiv.org/pdf/2103.01988.pdf" rel="noopener ugc nofollow" target="_blank">【1】</a></p></figure><p id="c9e5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作者还定义了一个所谓的低镜头学习场景，即在预训练后，<strong class="kk iu">仅使用ImageNet数据集</strong>的1%或10%对模型进行微调(相比之下，第一次评估为100%)。虽然SimCLRv2似乎是性能最好的模型，但由于在ImageNet上进行了预训练，<strong class="kk iu"> SEER尽管之前没有见过ImageNet中的任何图像(在随机图像上进行了预训练)，但其性能几乎可以与之匹敌</strong>。这再次表明，SEER能够学习足够多的关于它在预训练期间所看到的视觉世界的知识，以将其知识足够好地转移到ImageNet分类任务。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mz"><img src="../Images/e728f4c21a9e988e635193f2d0a5b91d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h51r1IbF2h2TvI9krMdeNQ.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">显示正则分类精度与模型中参数数量关系的图表。来源:<a class="ae lv" href="https://arxiv.org/pdf/2103.01988.pdf" rel="noopener ugc nofollow" target="_blank">【1】</a></p></figure><p id="769c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一个与论文高度相关的发现是，<strong class="kk iu">随着RegNet中参数数量的增加，预训练模型相对于从头开始训练的RegNet的优势显著增加</strong>。换句话说，如果您正在训练一个非常大的模型，那么与较小的模型相比，它更有可能受益于(自我监督的)预训练。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mz"><img src="../Images/014a29c0e852fc75ee0a22d51a6908a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AMUdvX9zP2I2iVIFcEa4aw.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">该表显示了使用SEER对下游任务(如对象检测和语义分割)进行预训练的性能。来源:<a class="ae lv" href="https://arxiv.org/pdf/2103.01988.pdf" rel="noopener ugc nofollow" target="_blank">【1】</a></p></figure><p id="c45e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，让我们看看<strong class="kk iu"> SEER对下游任务</strong>的影响。作者还在MS COCO数据集上使用预训练的RegNet主干训练了一个<strong class="kk iu"> Mask R-CNN，用于对象检测和语义分割</strong>。他们表明，与使用标签从零开始训练模型相比，<strong class="kk iu">使用SEER RegNet主干</strong>的模型在随机互联网图像<strong class="kk iu">上预先训练，导致两个下游任务</strong>的性能提高。</p><h1 id="c7e6" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">包装它</h1><p id="e69b" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">在本文中，您了解了SEER，以及自我监督的预训练即使不与精选数据集结合使用也是有效的。这一点的含义相当深远:<strong class="kk iu">我们可能离图像模型的完全无监督训练更近了一步</strong>。虽然我希望这个故事让你对这篇论文有了一个很好的初步了解，但仍然有很多东西需要发现，特别是在结果和消融研究方面。因此，我会鼓励你自己阅读这篇论文，即使你是这个领域的新手。你必须从某个地方开始；)</p><p id="3c00" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你对论文中介绍的方法有更多的细节感兴趣，请随时在Twitter上给我留言，我的账户链接在我的媒体简介上。</p><p id="7087" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我希望你喜欢这篇论文的解释。如果你对这篇文章有任何意见，或者如果你看到任何错误，请随时留下评论。</p><p id="b333" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">最后但同样重要的是，如果你想在高级计算机视觉领域更深入地探索，考虑成为我的追随者</strong>。我试着每周发一篇文章，让你和其他人了解计算机视觉研究的最新进展。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><p id="0255" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">参考资料:</p><p id="aaca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[1] Goyal，Priya等人，“野外视觉特征的自我监督预训练”<em class="le"> arXiv预印本arXiv:2103.01988 </em> (2021)。【https://arxiv.org/pdf/2103.01988.pdf T4】</p><p id="8c80" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2] Radosavovic，Ilija等人，“设计网络设计空间”IEEE/CVF计算机视觉和模式识别会议文集。2020.<a class="ae lv" href="https://arxiv.org/pdf/2003.13678.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2003.13678.pdf</a></p><p id="fd52" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[3]卡隆、玛蒂尔德等人，“通过对比聚类分配对视觉特征进行无监督学习。”<em class="le"> arXiv预印本arXiv:2006.09882 </em> (2020)。<a class="ae lv" href="https://arxiv.org/pdf/2006.09882.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2006.09882.pdf</a></p><p id="185f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[4]陈，丁等:“视觉表征对比学习的一个简单框架。”<em class="le">机器学习国际会议</em>。PMLR，2020年。<a class="ae lv" href="https://arxiv.org/pdf/2002.05709.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2002.05709.pdf</a></p><p id="b895" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[5]脸书人工智能研究博客文章:SEER:计算机视觉一个更强大、更灵活、更容易进入的时代的开始。<a class="ae lv" href="https://ai.facebook.com/blog/seer-the-start-of-a-more-powerful-flexible-and-accessible-era-for-computer-vision/" rel="noopener ugc nofollow" target="_blank">https://ai . Facebook . com/blog/seer-the-start-of-a-more-powerful-flexible-and-access-era-for-computer-vision/</a></p></div></div>    
</body>
</html>