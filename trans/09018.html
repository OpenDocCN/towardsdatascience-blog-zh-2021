<html>
<head>
<title>TensorFlow Decision Forests — Train Your Favorite Tree-Based Models Using Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow决策森林—使用Keras训练您最喜欢的基于树的模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tensorflow-decision-forests-train-your-favorite-tree-based-models-using-keras-875d05a441f?source=collection_archive---------11-----------------------#2021-08-20">https://towardsdatascience.com/tensorflow-decision-forests-train-your-favorite-tree-based-models-using-keras-875d05a441f?source=collection_archive---------11-----------------------#2021-08-20</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><figure class="iu iv gp gr iw ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi it"><img src="../Images/60053a226e91a2a03f8a9efa18872785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bOokbEeXpF1Z4gd_BpL93w.jpeg"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated"><a class="ae ji" href="https://unsplash.com/@veeterzy?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">维特齐</a>在<a class="ae ji" href="https://unsplash.com/s/photos/forest?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><div class=""/><div class=""><h2 id="f834" class="pw-subtitle-paragraph ki jk jl bd b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dk translated">是的，你没看错——神经网络和基于树的模型使用相同的API！</h2></div><p id="5f47" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">在本文中，我将简要描述什么是决策森林，以及如何使用通常用于神经网络的相同Keras API来训练基于树的模型(如随机森林或梯度增强树)。让我们开始吧！</p><h1 id="5c3c" class="lw lx jl bd ly lz ma mb mc md me mf mg kr mh ks mi ku mj kv mk kx ml ky mm mn bi translated">什么是决策森林？</h1><p id="dff3" class="pw-post-body-paragraph la lb jl lc b ld mo km lf lg mp kp li lj mq ll lm ln mr lp lq lr ms lt lu lv io bi translated">我将直奔主题，它不是另一个像XGBoost、LightGBM或CatBoost这样的花哨算法。<strong class="lc jm">决策树</strong>就是从许多决策树中构建的一系列机器学习算法。这包括许多你最喜欢的，如随机森林和各种口味的梯度增强树。</p><h1 id="999d" class="lw lx jl bd ly lz ma mb mc md me mf mg kr mh ks mi ku mj kv mk kx ml ky mm mn bi translated">张量流决策森林</h1><p id="db72" class="pw-post-body-paragraph la lb jl lc b ld mo km lf lg mp kp li lj mq ll lm ln mr lp lq lr ms lt lu lv io bi translated">到目前为止，机器和深度学习库之间存在明显的分歧。传统的机器学习，用<code class="fe mt mu mv mw b">scikit-learn</code>。深度学习用TensorFlow/PyTorch。如果你真的想吹毛求疵，在<code class="fe mt mu mv mw b">scikit-learn</code>中有一个<code class="fe mt mu mv mw b">neural_network</code>模块，它包含多层感知器。然而，这更多的是一个有趣的事实，而不是在实践中广泛使用的东西。</p><p id="553d" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">结束这个小小的题外话，TensorFlow决策森林迈出了弥合框架之间差距的第一步。该库的<a class="ae ji" href="https://blog.tensorflow.org/2021/05/introducing-tensorflow-decision-forests.html" rel="noopener ugc nofollow" target="_blank">发行说明</a>中的以下段落非常简洁地描述了主要思想:</p><blockquote class="mx my mz"><p id="87da" class="la lb na lc b ld le km lf lg lh kp li nb lk ll lm nc lo lp lq nd ls lt lu lv io bi translated">TF-DF是用于训练、服务和解释决策森林模型(包括随机森林和梯度提升树)的生产就绪的最先进算法的集合。借助TensorFlow和Keras的灵活性和可组合性，您现在可以将这些模型用于分类、回归和排名任务。</p></blockquote><p id="85db" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">这听起来很不错，但是为什么要用另一个库来训练相同的模型呢？好问题。在同一个API中提供不同类别的模型有一些优点:</p><ul class=""><li id="98de" class="ne nf jl lc b ld le lg lh lj ng ln nh lr ni lv nj nk nl nm bi translated">如果您已经在TensorFlow中使用神经网络为某个项目构建了一个架构，现在您可以轻松地用一个完全不同的模型类别进行实验。基于树的模型通常比NNs更受青睐(在性能和速度方面)，尤其是在处理结构化表格数据时。</li><li id="cdee" class="ne nf jl lc b ld nn lg no lj np ln nq lr nr lv nj nk nl nm bi translated">您可以使用同一套工具部署各种模型，例如TensorFlow Serving。</li><li id="8f00" class="ne nf jl lc b ld nn lg no lj np ln nq lr nr lv nj nk nl nm bi translated">您可以使用各种可用于基于树的模型的可解释性工具和技术。</li><li id="e231" class="ne nf jl lc b ld nn lg no lj np ln nq lr nr lv nj nk nl nm bi translated">使用该库，很容易将神经网络和决策树结合起来，例如，基于树的模型可以使用神经网络的输出。</li><li id="ead8" class="ne nf jl lc b ld nn lg no lj np ln nq lr nr lv nj nk nl nm bi translated">在引擎盖下，TF-DF是一个包装器，包裹着<a class="ae ji" href="http://om/google/yggdrasil-decision-forests" rel="noopener ugc nofollow" target="_blank">ygdrasil决策森林</a>，一个包含许多决策森林算法的C++框架。</li><li id="b34b" class="ne nf jl lc b ld nn lg no lj np ln nq lr nr lv nj nk nl nm bi translated">模型的TF-DF实现不仅可以进行分类和回归，还可以解决排序问题。</li></ul><h1 id="f117" class="lw lx jl bd ly lz ma mb mc md me mf mg kr mh ks mi ku mj kv mk kx ml ky mm mn bi translated">实践中的决策森林</h1><h2 id="2996" class="ns lx jl bd ly nt nu dn mc nv nw dp mg lj nx ny mi ln nz oa mk lr ob oc mm od bi translated">设置</h2><p id="e0ce" class="pw-post-body-paragraph la lb jl lc b ld mo km lf lg mp kp li lj mq ll lm ln mr lp lq lr ms lt lu lv io bi translated">不幸的是，在撰写本文的时候，安装并不像安装和导入库那么简单。截至2021年8月，无法在macOS和Windows上安装该库。该库的作者目前正在努力使之成为可能。</p><p id="0be2" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">同时，使用TF-DF最简单的方法是使用<a class="ae ji" href="https://colab.research.google.com" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>。我们需要首先安装两个库:<code class="fe mt mu mv mw b">tensorflow_decision_forests</code>和<code class="fe mt mu mv mw b">wurlitzer</code>。</p><p id="4dbf" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">注意:如果在Colab上安装库有问题，请将TensorFlow降级为<code class="fe mt mu mv mw b">tensorflow==2.5.1</code>。</p><p id="b261" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">这样做之后，我们就可以像往常一样导入所需的库了。</p><figure class="oe of og oh gt ix"><div class="bz fp l di"><div class="oi oj l"/></div></figure><figure class="oe of og oh gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi ok"><img src="../Images/550dace99547bdcc003e8a56d2d1e184.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qrXc4GekVw5sAc3mgzbmMA.jpeg"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated">迈克尔·里维拉·🇵🇭在<a class="ae ji" href="https://unsplash.com/s/photos/pokemon?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="ccff" class="ns lx jl bd ly nt nu dn mc nv nw dp mg lj nx ny mi ln nz oa mk lr ob oc mm od bi translated">数据</h2><p id="0a4d" class="pw-post-body-paragraph la lb jl lc b ld mo km lf lg mp kp li lj mq ll lm ln mr lp lq lr ms lt lu lv io bi translated">我们将再次使用<a class="ae ji" href="https://www.kaggle.com/cristobalmitchell/pokedex" rel="noopener ugc nofollow" target="_blank">神奇宝贝数据集</a>。它包含了八代的所有神奇宝贝，包括它们的类型，战斗统计，和一些更多的元信息。<a class="ae ji" rel="noopener" target="_blank" href="/phik-k-get-familiar-with-the-latest-correlation-coefficient-9ba0032b37e7">在之前的</a>中，我们已经使用新的相关性指标——𝜙k.探讨了该数据集特征之间的相关性。我们可以按如下方式加载数据。</p><figure class="oe of og oh gt ix"><div class="bz fp l di"><div class="oi oj l"/></div></figure><figure class="oe of og oh gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi ol"><img src="../Images/413e314221c523f82ed32193e204df9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VgbcPksrR4jmaztltwkFiQ.png"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated">作者图片</p></figure><p id="6e85" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我们只保留一些可能与构建机器学习模型相关的列。至于目标本身，这里有几个选项。我们可以尝试建立一个分类器来识别一个给定的神奇宝贝是否是传奇，或者可能解决一个多类问题来识别给定的神奇宝贝来自哪一代。然而，基于相关性分析，尝试一个回归问题并根据其余的统计数据和信息预测神奇宝贝的<code class="fe mt mu mv mw b">attack</code>也可能是有趣的。</p><p id="2c80" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">作为第一步，我们将数据分成训练集和测试集，同时按代分层。</p><figure class="oe of og oh gt ix"><div class="bz fp l di"><div class="oi oj l"/></div></figure><h2 id="979d" class="ns lx jl bd ly nt nu dn mc nv nw dp mg lj nx ny mi ln nz oa mk lr ob oc mm od bi translated">训练决策森林模型</h2><p id="8bfa" class="pw-post-body-paragraph la lb jl lc b ld mo km lf lg mp kp li lj mq ll lm ln mr lp lq lr ms lt lu lv io bi translated">TD-DF的一个非常好且方便的特性是它不需要对数据进行任何预处理。它自动处理数字和分类特征，以及缺失值。我们的数据集在<code class="fe mt mu mv mw b">secondary_type</code>特性中有缺失值，因为不是所有的神奇宝贝都有两种类型。</p><p id="8c3b" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">为了使用决策森林的模型，我们只需要将熊猫数据帧转换成张量流数据集。在这样做的时候，我们指出哪一列包含目标以及我们正在处理哪种任务。默认是分类，但是对于我们的用例，我们需要切换到回归。</p><figure class="oe of og oh gt ix"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="bfdd" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">然后，我们实例化了决策森林模型。对于这个例子，我们使用随机森林模型(目前，我们也可以使用梯度增强树或CART)。我们完成了可选的编译步骤，其中我们添加了一些感兴趣的额外指标——MSE和MAPE。然后，我们将模型与训练数据进行拟合。除非另有说明，否则训练将使用数据集中可用的所有特征。</p><figure class="oe of og oh gt ix"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="978a" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">在日志中，我们可以看到一些关于用于训练的特性的有用信息，包括汇总统计、丢失值的百分比等。在日志的后面(为了简洁起见，没有包括)，我们还可以看到用于训练模型的超参数(默认参数)，RMSE(默认度量)在拟合X树后如何变化，以及随机得分。</p><figure class="oe of og oh gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi om"><img src="../Images/44b5800b00f304e8ee6a5bbab174ed8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bmz7iYonCDR5hyQB1qi_jQ.png"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated">作者图片</p></figure><h2 id="fac3" class="ns lx jl bd ly nt nu dn mc nv nw dp mg lj nx ny mi ln nz oa mk lr ob oc mm od bi translated">评估结果</h2><p id="f62d" class="pw-post-body-paragraph la lb jl lc b ld mo km lf lg mp kp li lj mq ll lm ln mr lp lq lr ms lt lu lv io bi translated">下一步是在测试集上评估拟合模型的性能。为此，我们使用了<code class="fe mt mu mv mw b">evaluate</code>方法。</p><figure class="oe of og oh gt ix"><div class="bz fp l di"><div class="oi oj l"/></div></figure><p id="73df" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">什么会返回以下分数:</p><pre class="oe of og oh gt on mw oo op aw oq bi"><span id="5371" class="ns lx jl mw b gy or os l ot ou">{'loss': 0.0, 'mse': 431.4039611816406, 'mape': 24.62486457824707}<br/>MSE: 431.40<br/>RMSE: 20.77<br/>MAPE: 24.62</span></pre><p id="e46c" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">请注意，如果我们使用<code class="fe mt mu mv mw b">predict</code>方法创建预测，然后手动计算分数，例如使用<code class="fe mt mu mv mw b">scikit-learn</code>的函数，结果将是相同的。</p><p id="a80e" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">注意:我们不会花太多时间来分析模型的性能，因为本文的目标只是展示一个新的库，而不是实现手头任务的最佳性能。</p><h2 id="70ae" class="ns lx jl bd ly nt nu dn mc nv nw dp mg lj nx ny mi ln nz oa mk lr ob oc mm od bi translated">解释模型</h2><p id="cd6c" class="pw-post-body-paragraph la lb jl lc b ld mo km lf lg mp kp li lj mq ll lm ln mr lp lq lr ms lt lu lv io bi translated">TF-DF提供了一些很好的功能来解释模型。在我们拟合一个模型之后，有很多原因可以解释为什么可解释性应该在我们应该分析的事物的顶部。其中一些包括理解模型决策的能力，并可能向利益相关者解释这些决策，或者当我们看到“奇怪”的预测时调试模型。我已经在另一篇文章中广泛讨论了随机森林特性重要性的主题。</p><p id="01a7" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我们从随机森林中绘制一个决策树开始。我们可以使用下面的代码片段来做到这一点:</p><figure class="oe of og oh gt ix"><div class="bz fp l di"><div class="oi oj l"/></div></figure><figure class="oe of og oh gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi ov"><img src="../Images/3220e0b52881f7f4ea00be4d10c209ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4hal7uhPBEAA9MsNqcjHKg.png"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated">作者图片</p></figure><p id="a8b0" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我们只绘制了前3层，因为<code class="fe mt mu mv mw b">RandomForestModel</code>的默认设置允许最大深度为16。非常有趣的是类别被分组在一起。例如，图像顶部的<code class="fe mt mu mv mw b">primary_type</code>显示了基于4个可能组的分割，而不像在<code class="fe mt mu mv mw b">scikit-learn</code>实现中显示的是单个、一个热码编码的<code class="fe mt mu mv mw b">primary_type</code>。</p><p id="b4dd" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">对于一个CART模型或者检查一个GBT模型的第一棵树来说，这样的绘图可能特别有趣。</p><p id="73a0" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我们可以更深入地研究特性的重要性，并使用<code class="fe mt mu mv mw b">summary</code>方法分析模型的结构。然而，输出可能有点多，所以我们将一步一步地访问完全相同的元素。</p><p id="1aa5" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我们首先检查模型中使用的特性。</p><pre class="oe of og oh gt on mw oo op aw oq bi"><span id="1b6d" class="ns lx jl mw b gy or os l ot ou"># inspect the features used in the model<br/>model_rf.make_inspector().features()</span></pre><figure class="oe of og oh gt ix gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/58f8199977952d86d042e5f26ec1d6f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*1C3tzHVcIme8wfUgphfHug.png"/></div><p class="je jf gj gh gi jg jh bd b be z dk translated">作者图片</p></figure><p id="f91f" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">然后，我们前进到特性重要性。TF-DF提供了几种不同的方法来计算依赖于模型类型的特征重要性。第一个可用于随机森林的是基于<code class="fe mt mu mv mw b">MEAN_MIN_DEPTH</code>的。树中特征的最小深度对应于节点的深度，该节点分割对该特征的观察，并且最接近树的根。较低的值表示许多观察结果都是基于该特征进行分类的。</p><figure class="oe of og oh gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi ox"><img src="../Images/88cb7a4bb1baa72c5c873caaac426d82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u6NKr8xJ4amOkYjz09CqfQ.png"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated">作者图片</p></figure><p id="ffd5" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">平均最小深度越小，变量越重要。从上图我们可以看到<code class="fe mt mu mv mw b">HP</code>(生命值)似乎是最重要的特征，至少在使用这个标准的时候是这样的。</p><p id="1c41" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">下一个可用的度量是<code class="fe mt mu mv mw b">NUM_AS_ROOT</code>，它简单地指出了给定特性作为树的根的次数。在这种情况下，越高越好，而<code class="fe mt mu mv mw b">HP</code>又是最重要的一个。快速的完整性检查显示，在RF模型中总共有300棵树，这确实是默认的超参数值。</p><figure class="oe of og oh gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi oy"><img src="../Images/f8c19004519f6dda8c71c2a2416b592b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mI8YyFZs4nXju-IN6Hf1xw.png"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated">作者图片</p></figure><p id="9f6a" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">最后，还有<code class="fe mt mu mv mw b">NUM_NODES</code>指标。它显示了给定要素作为节点在树中拆分观测值的次数。自然地，一个特性可以在一个树中多次使用，所以这些并不等于树的总数。使用这个指标，<code class="fe mt mu mv mw b">primary_type</code>是最重要的特征。</p><figure class="oe of og oh gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi oz"><img src="../Images/ce428f09a7fe2fe2d55dec2b4ac2c76e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ks9Zi9HBfmbIhlpwoxbuQ.png"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated">作者图片</p></figure><p id="f7c9" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我们也可以看一看出袋RMSE。要获得该值，我们可以使用下面的代码片段:</p><pre class="oe of og oh gt on mw oo op aw oq bi"><span id="4c78" class="ns lx jl mw b gy or os l ot ou"># get the out-of-bag score<br/>model_rf.make_inspector().evaluation()</span></pre><p id="bf1d" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">什么会返回以下内容:</p><pre class="oe of og oh gt on mw oo op aw oq bi"><span id="6bef" class="ns lx jl mw b gy or os l ot ou">Evaluation(num_examples=718, accuracy=None, loss=None, rmse=20.664861230679822, ndcg=None, aucs=None)</span></pre><p id="0a94" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">最后，我们还可以深入一点，看看RMSE是如何随着训练的树的数量而进化的。为此，我们需要访问培训日志，同样使用<code class="fe mt mu mv mw b">make_inspector</code>方法。</p><figure class="oe of og oh gt ix"><div class="bz fp l di"><div class="oi oj l"/></div></figure><figure class="oe of og oh gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi pa"><img src="../Images/661224b730b53feed5ac970a65de8bdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6teZ-ZSNF0dJ4kfG-2Vteg.png"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated">作者图片</p></figure><p id="8aba" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">从上面的图片中我们可以看到，大约100棵树后，分数稳定下来。</p><p id="6fed" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">一般来说，训练日志显示了模型的质量，因为模型不断地生长树。我们可以使用这些信息来评估模型大小和模型质量之间的平衡。</p><p id="6e2e" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">在<code class="fe mt mu mv mw b">summary</code>方法的输出中有更多可用的信息，我强烈建议尝试一下。</p><h1 id="5c85" class="lw lx jl bd ly lz ma mb mc md me mf mg kr mh ks mi ku mj kv mk kx ml ky mm mn bi translated">TensorFlow与scikit-learn</h1><p id="9ebf" class="pw-post-body-paragraph la lb jl lc b ld mo km lf lg mp kp li lj mq ll lm ln mr lp lq lr ms lt lu lv io bi translated">TensorFlow决定森林将取代好的，旧的<code class="fe mt mu mv mw b">scikit-learn</code>？大概不会。支持这种说法的主要原因是:</p><ul class=""><li id="93b4" class="ne nf jl lc b ld le lg lh lj ng ln nh lr ni lv nj nk nl nm bi translated">不像<code class="fe mt mu mv mw b">scikit-learn</code>那么直白，</li><li id="2328" class="ne nf jl lc b ld nn lg no lj np ln nq lr nr lv nj nk nl nm bi translated">用于调整模型的现成功能较少(考虑网格搜索)，</li><li id="792d" class="ne nf jl lc b ld nn lg no lj np ln nq lr nr lv nj nk nl nm bi translated">文档远没有那么全面，</li><li id="df27" class="ne nf jl lc b ld nn lg no lj np ln nq lr nr lv nj nk nl nm bi translated">到目前为止，还没有那么多可用的模型(在<a class="ae ji" href="http://om/google/yggdrasil-decision-forests" rel="noopener ugc nofollow" target="_blank">ygdrasil决策森林</a>中有更多可用的，可能很快就会添加)。</li></ul><p id="8e85" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我想说，对于那些已经在TensorFlow中建立了一个项目，并且希望轻松地将他们当前的神经网络解决方案与完全不同类别的模型进行比较的人来说，决策森林将非常有用。然后，他们可以使用新的库轻松地做到这一点，同时保持他们的整个体系结构几乎相同。</p><h1 id="2995" class="lw lx jl bd ly lz ma mb mc md me mf mg kr mh ks mi ku mj kv mk kx ml ky mm mn bi translated">外卖食品</h1><ul class=""><li id="077d" class="ne nf jl lc b ld mo lg mp lj pb ln pc lr pd lv nj nk nl nm bi translated">决策森林是由许多决策树构建而成的算法家族，</li><li id="22ae" class="ne nf jl lc b ld nn lg no lj np ln nq lr nr lv nj nk nl nm bi translated">张量流决策森林允许我们使用熟悉的张量流API来训练随机森林或梯度增强树，</li><li id="5d20" class="ne nf jl lc b ld nn lg no lj np ln nq lr nr lv nj nk nl nm bi translated">虽然这个库中提供了很多功能，但是抛弃<code class="fe mt mu mv mw b">scikit-learn</code>来支持新的库可能还不够。对于那些已经为某个项目建立了TensorFlow架构的人来说，这更多的是一个额外的机会。</li></ul><p id="18b5" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">您可以在我的<a class="ae ji" href="https://github.com/erykml/medium_articles/blob/master/Machine%20Learning/decision_forests.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到本文使用的代码。此外，欢迎任何建设性的反馈。你可以在<a class="ae ji" href="https://twitter.com/erykml1?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">推特</a>或评论中联系我。</p><p id="1e03" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">喜欢这篇文章吗？成为一个媒介成员，通过无限制的阅读继续学习。如果你使用<a class="ae ji" href="https://eryk-lewinson.medium.com/membership" rel="noopener">这个链接</a>成为会员，你将支持我，而不需要额外的费用。提前感谢，再见！</p><p id="b5b1" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">您可能还会对以下内容感兴趣:</p><div class="iu iv gp gr iw pe"><a rel="noopener follow" target="_blank" href="/phik-k-get-familiar-with-the-latest-correlation-coefficient-9ba0032b37e7"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd jm gy z fp pj fr fs pk fu fw jk bi translated">菲克(𝜙k)——熟悉最新的相关系数</h2><div class="pl l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">这在分类变量、序数变量和区间变量之间也是一致的！</h3></div><div class="pm l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">towardsdatascience.com</p></div></div><div class="pn l"><div class="po l pp pq pr pn ps jc pe"/></div></div></a></div><div class="iu iv gp gr iw pe"><a rel="noopener follow" target="_blank" href="/9-useful-pandas-methods-you-probably-have-not-heard-about-28ff6c0bceee"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd jm gy z fp pj fr fs pk fu fw jk bi translated">你可能没听说过的9种有用的熊猫方法</h2><div class="pl l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">它们可以让你的日常工作更容易、更快捷。</h3></div><div class="pm l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">towardsdatascience.com</p></div></div><div class="pn l"><div class="pt l pp pq pr pn ps jc pe"/></div></div></a></div><div class="iu iv gp gr iw pe"><a rel="noopener follow" target="_blank" href="/chefboost-an-alternative-python-library-for-tree-based-models-f46af028a348"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd jm gy z fp pj fr fs pk fu fw jk bi translated">chef boost——基于树的模型的替代Python库</h2><div class="pl l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">与scikit-learn的主要区别概述</h3></div><div class="pm l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">towardsdatascience.com</p></div></div><div class="pn l"><div class="pu l pp pq pr pn ps jc pe"/></div></div></a></div><h1 id="2e73" class="lw lx jl bd ly lz ma mb mc md me mf mg kr mh ks mi ku mj kv mk kx ml ky mm mn bi translated">参考</h1><ul class=""><li id="3e8c" class="ne nf jl lc b ld mo lg mp lj pb ln pc lr pd lv nj nk nl nm bi translated"><a class="ae ji" href="https://www.youtube.com/watch?v=5qgk9QJ4rdQ" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=5qgk9QJ4rdQ</a></li><li id="3083" class="ne nf jl lc b ld nn lg no lj np ln nq lr nr lv nj nk nl nm bi translated"><a class="ae ji" href="https://blog.tensorflow.org/2021/05/introducing-tensorflow-decision-forests.html" rel="noopener ugc nofollow" target="_blank">https://blog . tensor flow . org/2021/05/introducing-tensor flow-decision-forests . html</a></li><li id="4070" class="ne nf jl lc b ld nn lg no lj np ln nq lr nr lv nj nk nl nm bi translated"><a class="ae ji" href="https://github.com/tensorflow/decision-forests" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/decision-forests</a></li></ul></div></div>    
</body>
</html>