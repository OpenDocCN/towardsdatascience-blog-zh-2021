<html>
<head>
<title>A Zero Maths Understanding of Bayesian Optimization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对贝叶斯优化的零数学理解</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-zero-maths-understanding-of-bayesian-optimization-e064a957a124?source=collection_archive---------14-----------------------#2021-09-01">https://towardsdatascience.com/a-zero-maths-understanding-of-bayesian-optimization-e064a957a124?source=collection_archive---------14-----------------------#2021-09-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="321c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为机器学习的贝叶斯优化建立简单的直觉</h2></div><p id="7923" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我送给你一台复杂的假想咖啡机，让你通过调节机器上的数千个转盘来为自己调制最好的咖啡。你是一个聪明的家伙，很快意识到这是一个优化问题。你有两个选择:</p><ol class=""><li id="d8b2" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">无数次地改变转盘的设置，冲泡不同类型的咖啡，品尝所有的咖啡，找到你最好的咖啡，然后死于过量摄入咖啡因。</li><li id="5ac6" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">尝试通过量化所涉及的各种因素来找到函数<strong class="kk iu">brew-quality = f(brew-styles)</strong>，并通过计算函数的导数，使用梯度下降法来找到全局最大值。</li></ol><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ls"><img src="../Images/d909885d1f852a529a4b89f5078bd343.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*onU2cfrOu5CTLDsI15aWbw.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">资料来源:联合国人类住区规划署</p></figure><p id="3846" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里有两点需要注意:</p><ol class=""><li id="f1ae" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">我们真的不知道这个函数是什么，它是一个黑盒。我们通过调节转盘来煮咖啡，我们得到咖啡作为输出，机器内部发生了什么，我们真的不知道。我们仅有的信息是在机器的特定设置下咖啡的味道如何。</li><li id="a156" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">即使我们知道<strong class="kk iu">的酿造质量</strong>功能是什么，评估它也是昂贵的，因为考虑到胃容量和健康危害，我们不能有几千杯咖啡。</li></ol><p id="fe79" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">那么，我们该怎么办？</p><p id="9187" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有一个框架可以解决这个问题，那就是贝叶斯优化。</p><blockquote class="mi"><p id="a06a" class="mj mk it bd ml mm mn mo mp mq mr ld dk translated">当函数是一个黑盒，因此梯度下降不是一个选项和/或函数是昂贵的评估时，它是适用的。这两个标准在这里都得到满足。</p></blockquote><h1 id="f551" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">贝叶斯优化</h1><p id="f430" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">让我们假设酿造质量的黑盒函数是:</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi np"><img src="../Images/90d277dafa1a8e7d4aca9911434a9a98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VzxkEBmGv8OsSUePmI6Jiw.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">原始功能，对用户隐藏。这是一个黑盒函数(图片由作者提供)</p></figure><p id="4511" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该函数是一个黑盒，我们只能对不同的输入(brew风格)进行评估。</p><p id="c20d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="nq">假设我们想在只对15杯咖啡</em> </strong>进行采样后找到最佳的冲泡方式，我们要做的是冲泡几杯咖啡&lt; 15，在这种情况下，我们冲泡了6)并有一个如下红色所示的估算函数。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi nr"><img src="../Images/3ac7856ee9df2bec8df0d8da4bd5136d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sop5h7xJHtE8G50X3VFrZA.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">第一次迭代中的估计函数(图片由作者提供)</p></figure><p id="97a3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们将使用这个估计函数来确定下一步在哪里求值。</p><blockquote class="mi"><p id="7955" class="mj mk it bd ml mm mn mo mp mq mr ld dk translated">这个由估计函数对原函数的估计是一个<em class="ns">高斯过程(暂时不需要了解)。</em>另一方面，估计函数被称为<em class="ns">替代函数(只是命名)</em></p></blockquote><figure class="nu nv nw nx ny lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi nt"><img src="../Images/ce0c597a8441b6e8fe6af0182818369e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kF505Yg6U3kj_-kV9n9YYA.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">第二次迭代中的估计函数(图片由作者提供)</p></figure><p id="4b7a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">借助新生成的数据创建新的估计函数。</p><p id="07bf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从新估计的函数中估计新的评估点(第三次迭代)。继续重复这个过程，直到你完成了所有的评估(在我们的例子中是15次)。并希望在15次迭代结束时，估计的函数是原函数的良好逼近。</p><p id="9b48" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果估计的函数足够好，那么这种方法将会有效并节省你很多时间。</p><p id="7772" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种方法比评估每一杯<em class="nq">咖啡的冲泡质量</em>更直观，更能模拟现实生活。它本质上是贝叶斯理论(下面讨论)。比方说，对于一杯100毫升的特定风格的饮料，你可以以1毫升的增量将牛奶量从15毫升调节到50毫升。如果你已经知道加了20毫升牛奶的咖啡太淡了，不适合你的口味，那么你为什么还要评价一杯加了20到50毫升牛奶的咖啡呢？</p><p id="d9f7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一方面，<em class="nq">随机搜索</em>可能会评估许多从20到50毫升牛奶含量的杯子，从而浪费评估。</p><p id="6829" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，我们的目标不是确定orange函数，而是确定采集函数的值，这将有助于以最少的计算次数来确定代理。</p><blockquote class="mi"><p id="0975" class="mj mk it bd ml mm mn mo mp mq mr ld dk translated"><em class="ns">写报告的零数学部分到此结束。我将继续讲述更多的细节，并尽可能远离复杂的方程。</em></p></blockquote><h1 id="f573" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">关于高斯过程的一个注记</h1><p id="8165" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">如上所述，从替代物对原始函数的估计是一种高斯过程。让我们试着理解它的意思。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi nt"><img src="../Images/619cdc3c289eaa8c61d4e07359db7fd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M90lmd0_-sgQbxqdaHfg_A.png"/></div></div></figure><p id="76ae" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们使用估计函数(蓝线)来确定评估点(接下来要品尝什么类型的咖啡)，从而改进估计函数(尽可能接近橙色虚线函数)。</p><p id="6de1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，基于蓝线，我们如何推断出更多关于橙线的信息？</p><p id="2d3f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们想要两样东西:</p><ol class=""><li id="7a14" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">我们希望在产量高的点进行评估(记住，我们是在最大限度地提高酿造质量，因此高价值是受欢迎的)。这是<strong class="kk iu"> <em class="nq">剥削</em> </strong></li><li id="edf0" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">我们应该探索我们了解较少的曲线区域，例如，我们不太了解2和3之间或5和10之间的情况，因此新的评估点应该来自那里。这是<strong class="kk iu"> <em class="nq">探索</em> </strong>。</li></ol><p id="4028" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种新点的估计是通过称为<em class="nq">采集功能</em>的功能完成的。该功能负责平衡勘探和开发之间的权衡，并让我们知道我们在实现这种平衡方面做得如何。</p><p id="47c4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">(以下等式在Quora 的一篇文章中讨论过)</p><p id="e16a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="nq">常见的获取函数包括期望改善和最大改善概率</em>。</p><p id="f51d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个获取函数并不大，评估它要便宜得多，因此优化它比做其他事情要容易得多。</p><p id="6192" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们定义两个值，</p><p id="ee28" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="nq"> μ(x) </em> =任意输入x的函数估计值(蓝线)</p><p id="2867" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="nq">∑(x)</em>=不同x值的标准偏差(标准偏差w.r.t蓝线)</p><p id="c809" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们定义一个函数，ζ(x)</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/643aaa3b868979ebae25d6dc429b41c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*hCASj0n2F3AauwKux6WLlg.png"/></div></figure><p id="f99e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个ζ函数的基础上，我们可以定义一个(x)获取函数。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/690c524f89c8a9f49f15341d9eb169cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*7IsmaOe1fKwHmh9Dwmebow.png"/></div></figure><blockquote class="mi"><p id="2247" class="mj mk it bd ml mm oc od oe of og ld dk translated"><em class="ns">a(x)内部发生的事情超出了这篇简单文章的范围，但a(x)本质上所做的是试图在低μ(x)和高σ(x)之间取得平衡。μ(x)表示开采，σ(x)表示勘探。</em></p></blockquote><p id="ba5c" class="pw-post-body-paragraph ki kj it kk b kl oh ju kn ko oi jx kq kr oj kt ku kv ok kx ky kz ol lb lc ld im bi translated">这个<a class="ae nz" href="https://www.youtube.com/watch?v=jtRPxRnOXnk&amp;t=1057s" rel="noopener ugc nofollow" target="_blank"> pyData </a>演讲对于理解高斯过程非常有用。</p><p id="db97" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae nz" rel="noopener" target="_blank" href="/an-intuitive-guide-to-gaussian-processes-ec2f0b45c71d">这篇关于TDS的文章</a>也讨论了这个问题。</p><h1 id="5820" class="ms mt it bd mu mv mw mx my mz na nb nc jz om ka ne kc on kd ng kf oo kg ni nj bi translated">贝叶斯优化的贝叶斯是什么？</h1><p id="d5d3" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">(以下部分摘自我在<a class="ae nz" href="https://medium.com/me/stats/post/4ad3aa1f09df" rel="noopener">贝叶斯统计</a>上的旧帖子)</p><p id="25ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="nq">贝叶斯</em> </strong> <em class="nq"> </em>方法<em class="nq"> </em>考虑系统的先验知识。贝叶斯主义者认为，我们对这个系统总是有所了解，所以，为什么不用它来对这个系统做出更好的猜测呢。</p><p id="3300" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据(在这种情况下是函数评估)与<em class="nq">先验</em>知识一起被用来估计所谓的<em class="nq">后验</em>，它不是一个单一的值，而是一个分布。</p><p id="0454" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">贝叶斯定理的通俗说法是:</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi op"><img src="../Images/12de6befaeba76bd9db533ae95ebde8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8P6wYYNfwdXytOST4zWgwQ.png"/></div></div></figure><p id="2167" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">P(β|y，X)称为需要评估的值的后验分布，β，给定数据X和y，其中X为输入，y为输出。</p><p id="c07e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">P(y|β，X)是数据的似然性，它乘以参数P(β|X)的<em class="nq">先验概率</em>，再除以P(y | X ), P(y | X)被称为归一化常数。需要此归一化参数来使P(β|y，X)中的值之和等于1。</p><p id="0d8a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">简而言之，我们正在使用我们关于替代函数的先验信息来估计后验概率。</p><p id="16b8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在贝叶斯优化的情况下:</p><ol class=""><li id="11ca" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">我们在代理函数上放置一个先验(由试图捕捉我们对函数行为的信念的高斯过程定义)。</li><li id="c539" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">函数评估被视为数据并用于更新先验以获得目标函数的后验分布。</li></ol><h1 id="6f16" class="ms mt it bd mu mv mw mx my mz na nb nc jz om ka ne kc on kd ng kf oo kg ni nj bi translated">结论</h1><p id="f127" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">BO是直观的，因为它模拟了现实生活，我们有我们的先验信念，我们用它们来估计输出，估计成为新的先验，我们得到更新的后验。当我们处理昂贵的计算和问题空间太大的时候，使用BO比梯度下降和它的变种要好得多。</p><p id="3762" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在机器学习中，BO用于超参数优化，例如，可以在BO的帮助下调整随机森林中的树木数量、深度、树叶等。有许多语言的许多库可用于进一步探索概念，如hyperopt、botorch、bayes-optim等，并且可以亲眼目睹强大的功能。</p><blockquote class="mi"><p id="6c40" class="mj mk it bd ml mm mn mo mp mq mr ld dk translated">我们试图借助一个更接近日常生活的场景来介绍一个困难而简洁的数学过程。</p><p id="944d" class="mj mk it bd ml mm mn mo mp mq mr ld dk translated">好吧，不完全是！这种假设的咖啡机并不存在，但尽管如此，你有工具在数学方法的帮助下找到最好的咖啡。</p></blockquote><h1 id="0637" class="ms mt it bd mu mv mw mx my mz na nb nc jz nd ka ne kc nf kd ng kf nh kg ni nj bi translated">来源:</h1><p id="bd74" class="pw-post-body-paragraph ki kj it kk b kl nk ju kn ko nl jx kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated"><a class="ae nz" href="https://static.sigopt.com/773979031a2d61595b9bda23bb81a192341f11a4/pdf/SigOpt_Bayesian_Optimization_Primer.pdf" rel="noopener ugc nofollow" target="_blank">https://static . SigOpt . com/773979031 a2 d 61595 B9 BDA 23 bb 81 a 192341 F11 a 4/pdf/SigOpt _ Bayesian _ Optimization _ primer . pdf</a></p><p id="a962" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">创建图表的github:【https://github.com/Prashantmdgl9/Bayesian_Optimization T2】</p></div></div>    
</body>
</html>