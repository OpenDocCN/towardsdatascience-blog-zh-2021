<html>
<head>
<title>Plant Disease Detection using Advanced Deep Learning and ReactJS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用先进的深度学习和反应技术进行植物病害检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/plant-disease-detection-using-advanced-deep-learning-and-reactjs-6bb913d9e8a8?source=collection_archive---------8-----------------------#2021-06-11">https://towardsdatascience.com/plant-disease-detection-using-advanced-deep-learning-and-reactjs-6bb913d9e8a8?source=collection_archive---------8-----------------------#2021-06-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="dbc5" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">高级深度学习| FLASK | REACTJS</h2><div class=""/><div class=""><h2 id="06d0" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">用于可视化和诊断植物疾病的最新架构！</h2></div><p id="4795" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">大量的论文和文章可用于使用深度学习来检测叶子或植物疾病。卷积神经网络通过提供有助于准确检测植物疾病的模型，彻底改变了农业领域。但是检测疾病是不够的，人们还应该了解叶子或植物图像中的疾病症状。为了通过目标检测定位工厂中受影响的区域，使用了单触发多盒检测器(SSD)、更快的基于区域的卷积神经网络(更快的RCNN)和基于区域的完全卷积网络(R-FCN)。此外，对于实时对象检测，采用了只看一次(YOLO)算法。所有这些算法都可以用于植物疾病的诊断和受影响区域的可视化，但是它们缺乏透明度，并且在实践中充当黑箱。</p><p id="5ca6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在开始我最新研究的文章之前，我想分享一个好消息:</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/de93c0d68f7dc8e2af3247b3f188df83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*7E7sKIwSjB-JygColBfzZQ.png"/></div><p class="ls lt gj gh gi lu lv bd b be z dk translated"><a class="ae lw" href="https://www.linkedin.com/posts/laurence-moroney_research-innovation-datascience-activity-6810576125337718784-pblm" rel="noopener ugc nofollow" target="_blank">https://www . LinkedIn . com/posts/Laurence-moroney _ research-innovation-data science-activity-6810576125337718784-pblm</a></p></figure><p id="b79b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这篇文章中，一个可解释的国家最先进的方法被采用，超越了所有以前提出的方法。最近在线发表在Scopus索引期刊《农业信息处理》上的一篇影响因子为6.41的研究论文被用作本文的基础。</p><div class="lx ly gp gr lz ma"><a href="https://www.sciencedirect.com/science/article/pii/S2214317321000482" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd ja gy z fp mf fr fs mg fu fw iz bi translated">ResTS:植物病害检测的剩余深度可解释体系结构</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">近年来，受深层神经网络在植物病害检测中的影响，出现了许多方法</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">www.sciencedirect.com</p></div></div><div class="mj l"><div class="mk l ml mm mn mj mo lq ma"/></div></div></a></div><p id="1871" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">本文提出了一种高级深度学习架构ResTS，Residual Teacher/Student的缩写。它包含两个分类器，即ResTeacher和ResStudent以及一个解码器。rest teacher+Decoder用作自动编码器，从输入图像中移除非鉴别特征，而ResStudent分类器有助于改善这种架构的重建损失。ResTS输出一个热图，只突出显示叶部疾病和疾病类别的区别特征。它是在PlantVillage数据集(分段版本)上训练的。这种提出的结构优于先前发现的用于植物疾病的诊断和可视化的架构，最高F1分数为0.991。figure 1–4描述了休止符如何操纵输入图像。以下部分解释了这些图像是如何由模型构建的，以及如何通过几个重要的公式进行后处理的。</p><div class="ll lm ln lo gt ab cb"><figure class="mp lp mq mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><img src="../Images/d8120a093b57f0713e11cde55553355b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*dXPlRGe5Zate72OL9mZnug.png"/></div></figure><figure class="mp lp mz mr ms mt mu paragraph-image"><img src="../Images/ef9c0ec77515f27c4d11a386da0f8d81.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*4hCrEZKL6lMNkxffgb5MrA.jpeg"/></figure><figure class="mp lp mz mr ms mt mu paragraph-image"><img src="../Images/9fbef5b28ba193dee58964d8dc962b78.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*273ND68456LIZMDOzXXY4Q.png"/><p class="ls lt gj gh gi lu lv bd b be z dk na di nb nc translated"><strong class="bd nd">图一。</strong>输入图像<strong class="bd nd"> 2。</strong>解码器用matplotlib(范围0..<strong class="bd nd">①浮舟③。</strong>解码器通过OpenCV重建的图像(范围0..255浮球)<strong class="bd nd"> 4。</strong> <strong class="bd nd">来自matplotlib的热图</strong>由<strong class="bd nd">(cmap = ' red ')</strong></p></figure></div><p id="ebfb" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">本文将构建一个React应用程序作为我们的前端，并在后端运行来自研究论文的高级深度学习架构- <strong class="kq ja"> ResTS </strong>。作为回应，系统将如图5所示进行机动。我们将创建整个系统并运行它，最后，看看是否所有的部分都适合在一起。</p><blockquote class="ne nf ng"><p id="63b3" class="ko kp nh kq b kr ks ka kt ku kv kd kw ni ky kz la nj lc ld le nk lg lh li lj ij bi translated"><strong class="kq ja">要访问已训练的ResTS模型，请参见下一节末尾的说明。</strong></p></blockquote><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi nl"><img src="../Images/95b0ab6b33557914fc88048bb854fcbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L0ONOjdMPsaNSsQ9K-xKRQ.png"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">图5。系统的一般流程</p></figure><p id="cb35" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">首先，我们将设计Flask服务器来适应预先训练好的ResTS架构。服务器将合并一个路由来处理来自应用程序的输入图像，并将返回一个新的图像，该图像仅包含显著特征以及疾病名称和概率。其次，我们将开发一个简单的React应用程序，可以上传和显示图像。我们不会深入研究ResTS架构的细节。请参考原始论文，以了解该架构如何操作来诊断植物疾病。</p></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><h1 id="7ccc" class="nt nu iq bd nv nw nx ny nz oa ob oc od kf oe kg of ki og kj oh kl oi km oj ok bi translated">要访问预训练的ResTS模型，</h1><p id="e641" class="pw-post-body-paragraph ko kp iq kq b kr ol ka kt ku om kd kw kx on kz la lb oo ld le lf op lh li lj ij bi translated"><strong class="kq ja"> 1。在LinkedIn上的以下帖子中对您的请求提出适当的理由，我将分享个人链接，以各种格式访问预先培训的已保存模型:</strong></p><div class="lx ly gp gr lz ma"><a href="https://www.linkedin.com/posts/dhruvilshah28_research-innovation-datascience-activity-6809383337841434624-b4b-" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd ja gy z fp mf fr fs mg fu fw iz bi translated">LinkedIn上的Dhruvil Shah研究#创新#数据科学</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">我很高兴与大家分享我的研究论文“ResTS:植物病害的剩余深度可解释架构…</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">www.linkedin.com</p></div></div><div class="mj l"><div class="oq l ml mm mn mj mo lq ma"/></div></div></a></div><h2 id="10fe" class="or nu iq bd nv os ot dn nz ou ov dp od kx ow ox of lb oy oz oh lf pa pb oj iw bi translated">2.按照这里的指示引用论文:<a class="ae lw" href="https://doi.org/10.1016/j.inpa.2021.06.001" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1016/j.inpa.2021.06.001</a></h2><h2 id="3318" class="or nu iq bd nv os ot dn nz ou ov dp od kx ow ox of lb oy oz oh lf pa pb oj iw bi translated">3.只有当你的请求是可信的，并且论文被恰当地引用和注明时，你才会被授予访问权。</h2></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><h1 id="490b" class="nt nu iq bd nv nw nx ny nz oa ob oc od kf oe kg of ki og kj oh kl oi km oj ok bi translated">1.创建包含ResTS(剩余教师/学生)模型的服务器</h1><p id="cc28" class="pw-post-body-paragraph ko kp iq kq b kr ol ka kt ku om kd kw kx on kz la lb oo ld le lf op lh li lj ij bi translated">架构代码需要与服务器放在同一个文件中。然而，这是可以改变的，但由于一些错误，我决定把整个架构的代码放在同一个文件中，并加载权重。此外，只运行一个文件而不是管理多个文件也很好。</p><p id="33b7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">源代码访问:你可以从上面提到的文章中找到这篇文章的全部源代码和ResTS架构的链接。</p><p id="40d3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">首先，我们将所有必需的库导入到我们的Flask服务器文件中。</p><pre class="ll lm ln lo gt pc pd pe pf aw pg bi"><span id="6a86" class="or nu iq pd b gy ph pi l pj pk">import os<br/>from flask import Flask, request<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import tensorflow as tf<br/>import pandas as pd<br/>import gevent.pywsgi<br/>from flask_cors import CORS<br/>from datetime import datetime<br/>from tensorflow.python.keras.backend import set_session<br/>from keras import backend as K<br/>import tensorflow.compat.v1 as tf<br/>import keras_preprocessing<br/>from keras.applications.xception import preprocess_input as xception_preprocess_input<br/>from keras_preprocessing import image<br/>import json<br/>from PIL import Image<br/>from hashlib import sha256<br/>###########################<br/>from tensorflow.keras.layers import Input, Dense, Conv2D, Activation, MaxPool2D<br/>from tensorflow.keras.layers import *<br/>from tensorflow.keras.models import Model, Sequential<br/>from tensorflow.keras.optimizers import Adam, SGD<br/>import glob<br/>import argparse<br/>from keras import __version__<br/>from keras.applications.xception import preprocess_input as xception_preprocess_input<br/>from keras.preprocessing.image import ImageDataGenerator<br/>from keras.optimizers import SGD<br/>from keras import optimizers<br/>from keras import callbacks<br/>from keras.callbacks import ModelCheckpoint, LearningRateScheduler<br/>from keras import backend as keras<br/>from keras.regularizers import l2,l1<br/>import pandas as pd</span></pre><p id="5e7d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这将需要巨大的处理能力。下一步是用一些其他重要的变量和使用<em class="nh"> tf.session </em>的会话来定义‘app’变量。<em class="nh">运行服务器时需要tf.disable_v2_behavior() </em>和<em class="nh"> tf.get_default_graph() </em>来避免任何与图形相关的错误。</p><pre class="ll lm ln lo gt pc pd pe pf aw pg bi"><span id="ef71" class="or nu iq pd b gy ph pi l pj pk">input_shape = (224,224,3)<br/>nbr_of_classes=38<br/>tf.disable_v2_behavior()<br/>graph = tf.get_default_graph()</span><span id="f0a0" class="or nu iq pd b gy pl pi l pj pk">app = Flask(__name__)<br/>CORS(app)<br/>sess = tf.Session()<br/>set_session(sess)</span></pre><p id="1a4b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="nh">注意:如果在服务器启动阶段仍然出现错误，很有可能是由于TensorFlow的版本错误。在这种情况下，尝试搜索Stackoverflow。</em></p><p id="8ef6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">定义会话后，将实现架构代码。ResTS使用标准Xception架构作为ResTeacher和ResStudent，解码器以与Xception架构完全相反的方式生成，以再现图像。深入讨论ResTS架构超出了本文的范围。要正确理解下面的代码，请参考原文。</p><pre class="ll lm ln lo gt pc pd pe pf aw pg bi"><span id="83d0" class="or nu iq pd b gy ph pi l pj pk"><strong class="pd ja">#ResTS ARCHITECTURE</strong></span><span id="1bc6" class="or nu iq pd b gy pl pi l pj pk"><strong class="pd ja">#RESTEACHER<br/></strong>base_model1 = tf.keras.applications.Xception(include_top=False, weights='imagenet',input_shape = input_shape)<br/>x1_0 = base_model1.output<br/>x1_0 = Flatten(name='Flatten1')(x1_0)<br/>dense1 = Dense(256, name='fc1',activation='relu')(x1_0) <br/>x = classif_out_encoder1 = Dense(38, name='out1', activation = 'softmax')(dense1) # Latent Representation / Bottleneck</span><span id="13e7" class="or nu iq pd b gy pl pi l pj pk">#Get Xception's tensors for skip connection.<br/>...</span><span id="7e28" class="or nu iq pd b gy pl pi l pj pk"><strong class="pd ja">#DECODER</strong><br/>dense2 = Dense(256, activation='relu')(x)</span><span id="22e0" class="or nu iq pd b gy pl pi l pj pk">x = Add(name='first_merge')([dense1, dense2])<br/>x = Dense(7*7*2048)(x)<br/>reshape1 = Reshape((7, 7, 2048))(x)</span><span id="dc2d" class="or nu iq pd b gy pl pi l pj pk">#BLOCK 1<br/>...</span><span id="4cac" class="or nu iq pd b gy pl pi l pj pk">#BLOCK 2<br/>...</span><span id="ed08" class="or nu iq pd b gy pl pi l pj pk">#BLOCK 3-10<br/>...</span><span id="d796" class="or nu iq pd b gy pl pi l pj pk">#BLOCK 11<br/>...</span><span id="6d80" class="or nu iq pd b gy pl pi l pj pk">#BLOCK 12<br/>...</span><span id="f4ff" class="or nu iq pd b gy pl pi l pj pk">#BLOCK 13<br/>...</span><span id="a7b1" class="or nu iq pd b gy pl pi l pj pk">#BLOCK 14<br/>...</span><span id="dee7" class="or nu iq pd b gy pl pi l pj pk">x = Conv2D(2, 3, activation = 'relu', padding = 'same',)(x)<br/>mask = x = Conv2D(3, 1, activation = 'sigmoid',name='Mask')(x)</span><span id="f2c9" class="or nu iq pd b gy pl pi l pj pk"><strong class="pd ja">#RESSTUDENT</strong><br/>base_model2 = tf.keras.applications.Xception(include_top=False, weights='imagenet',input_shape = (224,224,3))<br/>x2_0 = base_model2(mask)<br/>x2_0 = Flatten(name='Flatten2')(x2_0)<br/>x2_1 = Dense(256, name='fc2',activation='relu')(x2_0) <br/>classif_out_encoder2  = Dense(nbr_of_classes, name='out2',activation='softmax')(x2_1)</span><span id="7e12" class="or nu iq pd b gy pl pi l pj pk">#Create ResTS Model and Load Pre-trained weights<br/>ResTS = Model(base_model1.input, [classif_out_encoder1, classif_out_encoder2])<br/>ResTS.load_weights('tf/RTS')</span></pre><p id="ff55" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">ResTS架构的设计方式是，在自动编码器的帮助下，从树叶的输入图像中筛选出噪声区域。<em class="nh">遮罩</em>层是解码器的输出，用于可视化叶子图像的重要区域。ResTeacher的输出classif_out_encoder1 在<em class="nh"> softmax </em>函数的帮助下，协助对疾病类别进行分类。</p><pre class="ll lm ln lo gt pc pd pe pf aw pg bi"><span id="a7c1" class="or nu iq pd b gy ph pi l pj pk">#For visualization impetus</span><span id="cc5f" class="or nu iq pd b gy pl pi l pj pk">layer_name ='Mask'<br/>NewInput = ResTS.get_layer(layer_name).output<br/>visualization = K.function([ResTS.input], [NewInput])</span></pre><p id="70ce" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在上面的代码中，<em class="nh"> visualization </em>是一个函数，它帮助获得只包含叶子图像的重要特征的图像。接下来，我们将定义一些重要的函数，用于对从<em class="nh">可视化</em>函数接收到的图像的特征进行可视化。</p><pre class="ll lm ln lo gt pc pd pe pf aw pg bi"><span id="ca16" class="or nu iq pd b gy ph pi l pj pk">def reduce_channels_sequare(heatmap):<br/>    channel1 = heatmap[:,:,0]<br/>    channel2 = heatmap[:,:,1]<br/>    channel3 = heatmap[:,:,2]<br/>    new_heatmap = np.sqrt(((channel1-0.149)*(channel1-0.149))+((channel2-0.1529)*(channel2-0.1529))+((channel3-0.3412)*(channel3-0.3412)))<br/>    return new_heatmap</span></pre><p id="ce13" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">需要<em class="nh">reduce _ channels _ se quare</em>函数将重建的RGB图像转换为单通道图像。它间接找到重建图像中主色之间的距离(在此功能中称为热图)。</p><pre class="ll lm ln lo gt pc pd pe pf aw pg bi"><span id="a6ba" class="or nu iq pd b gy ph pi l pj pk">def postprocess_vis(heatmap1,threshould = 0.9):<br/>    heatmap = heatmap1.copy()<br/>    heatmap = (heatmap - heatmap.min())/(heatmap.max() - heatmap.min())<br/>    heatmap = reduce_channels_sequare(heatmap)<br/>    heatmap = (heatmap - heatmap.min())/(heatmap.max() - heatmap.min())<br/>    heatmap[heatmap&gt;threshould] = 1<br/>    <strong class="pd ja">heatmap = heatmap*255</strong><br/>    return heatmap</span></pre><p id="19cd" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="nh"> postprocess_vis </em>函数执行基本的二进制阈值处理，将值大于0.9的像素设置为1。热图(重建图像)然后乘以255，这样我们就得到范围[0，255]内的值。</p><p id="ce25" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">注意:我们现在只处理单通道图像，而不是RGB通道。有必要在减少通道之前和之后标准化热图中的值，以便使用OpenCV获得如图6所示的最终热图。</strong></p><p id="1b6a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">注意，如果使用OpenCV:如果我们没有乘以255，我们将得到图6中的大部分黑色图像，因为像素值在范围[0，1]内。因为OpenCV考虑范围[0，255]并相应地输出图像。</strong></p><p id="1a50" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">注意，如果使用Matplotlib (cmap= 'Reds '):如果我们没有乘以255，那么使用<em class="nh"> cmap= 'Reds' </em>，我们将得到与图4相同的输出。因为matplotlib在显示RGB图像时只要求特定的范围。</strong></p><pre class="ll lm ln lo gt pc pd pe pf aw pg bi"><span id="1444" class="or nu iq pd b gy ph pi l pj pk">def visualize_image(img_name):<br/>    image_size = (224,224)<br/>    original_image = image.load_img(img_name, target_size=image_size)<br/>    img = image.img_to_array(original_image)<br/>    img = np.expand_dims(img, axis=0)<br/>    img = xception_preprocess_input(img)<br/>    global sess<br/>    global graph<br/>    with graph.as_default():<br/>        set_session(sess)<br/>        <strong class="pd ja">vis = visualization([img])[0][0]</strong><br/>        disease = ResTS.predict(img)[0]<br/>        probab = max(disease[0])<br/>        disease = np.argmax(disease)<br/>        heatmap = postprocess_vis(vis)<br/>    img = plt.imshow(heatmap, cmap='Reds')<br/>    plt.axis('off')<br/>    plt.savefig(img_name, bbox_inches='tight')<br/>    return disease, probab</span></pre><p id="a4d1" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这里，<em class="nh"> vis </em>变量由范围[0，1]内的浮点值组成。因此，如果您想对<em class="nh"> vis </em>变量运行<em class="nh"> plt.imshow() </em>方法，它将给出如图2所示的重建图像输出。<strong class="kq ja">如果将<em class="nh"> vis </em>变量乘以255，浮点值将出现在【0，255】范围内，这是<em class="nh"> plt.imshow() </em>方法不支持的，因为它要求“RGB”图像的浮点值在[0，1]范围内，整数值在[0，255]范围内。</strong>现在，获得如图3所示的输出。，只需将<em class="nh"> vis </em>乘以255，使用OpenCV保存即可，如下所述。</p><pre class="ll lm ln lo gt pc pd pe pf aw pg bi"><span id="e917" class="or nu iq pd b gy ph pi l pj pk">#cv2.imwrite('vis.jpg',vis)</span></pre><p id="4446" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">Matplotlib的<em class="nh">cmap = ' red '</em>给出了如图4所示的红色热图。<em class="nh"> visualize_image </em>函数用热图覆盖输入图像(具有相同的文件名)。</p><p id="7b79" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">注意:如果我们不使用plt.imshow(heatmap，cmap = ' Reds ')，而是使用cv2.imwrite(heatmap)，我们将得到如下输出图像。原因是我们已经在<em class="nh">后处理_vis </em>函数中生成了一个“单通道”热图，并且应用了二进制阈值。OpenCV将根据像素值写入图像(255像素值= '白色'区域，0像素值= '黑色'区域，其他值为'浅灰色'区域)。</strong></p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/7ee8653aef00e72d5f2e94bb057c93c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*K-mcSqQbZvNroECqRBuQzg.jpeg"/></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">图6。带OpenCV的热图(不带cmap = ' Reds ')</p></figure><p id="4b1b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">visualize_image功能是这个系统的主干。它处理疾病的预测以及疾病症状可视化的生成。首先，通过从“/detect”路径传递的名称读取输入图像，并通过来自标准<em class="nh">异常</em>架构的默认<em class="nh">异常_预处理_输入</em>函数进行预处理。<em class="nh">可视化</em>函数被调用，得到解码器的输出，即重建图像。<em class="nh">。在模型上调用predict() </em>方法来获得ResTeacher的输出，即疾病的类别。它返回预测的疾病名称及其概率(表明模型对预测的置信度)。它保存具有相同文件名的<em class="nh">热图</em>，即覆盖原始文件。</p><h2 id="1f4a" class="or nu iq bd nv os ot dn nz ou ov dp od kx ow ox of lb oy oz oh lf pa pb oj iw bi translated">创建路线'/detect '</h2><p id="6621" class="pw-post-body-paragraph ko kp iq kq b kr ol ka kt ku om kd kw kx on kz la lb oo ld le lf op lh li lj ij bi translated">/detect' route从React应用程序获取图像，生成突出显示疾病鉴别特征的热图，并将其与疾病类别一起返回给应用程序。它还返回预测的概率。图7。决定了这条路线的流向。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/1d90e87b082a91ca0ca11384b4d8e42a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*eGxYnFIAd7aBhJMz18oVTw.png"/></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">图7。“/detect”路线的流程</p></figure><p id="c0a8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下面是这条路线的代码改编。它以与图7所示完全相同的方式工作。因此，下面的代码是不言自明的。</p><pre class="ll lm ln lo gt pc pd pe pf aw pg bi"><span id="d0f2" class="or nu iq pd b gy ph pi l pj pk">@app.route('/detect', methods=['POST'])<br/>def change():<br/>    image_size = (224,224)<br/>    img_data = request.get_json()['image']<br/>    img_name = str(int(datetime.timestamp(datetime.now()))) + str(np.random.randint(1000000000))<br/>    img_name = sha256(img_name.encode()).hexdigest()[0:12]<br/>    img_data = np.array(list(img_data.values())).reshape([224, 224, 3])<br/>    im = Image.fromarray((img_data).astype(np.uint8))<br/>    im.save(img_name+'.jpg')<br/>    disease, probab = visualize_image(img_name+'.jpg')<br/>    img = cv2.imread(img_name+'.jpg')<br/>    img = cv2.resize(img, image_size) / 255.0<br/>    img = img.tolist()<br/>    os.remove(img_name+'.jpg')<br/>    return json.dumps({"image": img, "disease":int(disease), "probab":str(probab)})</span></pre></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><h1 id="a4a0" class="nt nu iq bd nv nw nx ny nz oa ob oc od kf oe kg of ki og kj oh kl oi km oj ok bi translated">1.1要访问预训练的ResTS模型，</h1><p id="cd2a" class="pw-post-body-paragraph ko kp iq kq b kr ol ka kt ku om kd kw kx on kz la lb oo ld le lf op lh li lj ij bi translated"><strong class="kq ja"> 1。在LinkedIn上的以下帖子中对您的请求提出适当的理由，我将分享个人链接，以访问各种格式的预培训保存模型:</strong></p><div class="lx ly gp gr lz ma"><a href="https://www.linkedin.com/posts/dhruvilshah28_research-innovation-datascience-activity-6809383337841434624-b4b-" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd ja gy z fp mf fr fs mg fu fw iz bi translated">LinkedIn上的Dhruvil Shah研究#创新#数据科学</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">我很高兴与大家分享我的研究论文“ResTS:植物病害的剩余深度可解释架构…</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">www.linkedin.com</p></div></div><div class="mj l"><div class="oq l ml mm mn mj mo lq ma"/></div></div></a></div><h2 id="2ea5" class="or nu iq bd nv os ot dn nz ou ov dp od kx ow ox of lb oy oz oh lf pa pb oj iw bi translated">2.按此处说明引用论文:【https://doi.org/10.1016/j.inpa.2021.06.001 T2】</h2><h2 id="4e2d" class="or nu iq bd nv os ot dn nz ou ov dp od kx ow ox of lb oy oz oh lf pa pb oj iw bi translated">3.只有当你的请求是可信的，并且论文被恰当地引用和注明时，你才会被授予访问权。</h2></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><h1 id="47e5" class="nt nu iq bd nv nw nx ny nz oa ob oc od kf oe kg of ki og kj oh kl oi km oj ok bi translated">2.创建简单的ReactJS应用程序</h1><p id="8094" class="pw-post-body-paragraph ko kp iq kq b kr ol ka kt ku om kd kw kx on kz la lb oo ld le lf op lh li lj ij bi translated">让我们直接进入React中的编码部分(App.js)文件。</p><p id="a64d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">首先，我们将导入一些库并定义全局变量。</p><pre class="ll lm ln lo gt pc pd pe pf aw pg bi"><span id="f5a6" class="or nu iq pd b gy ph pi l pj pk">import logo from './logo.svg';<br/>import './App.css';<br/>import React from 'react';<br/>import * as tf from '@tensorflow/tfjs';<br/>import cat from './cat.jpg';<br/>import {CLASSES} from './imagenet_classes';<br/>const axios = require('axios');</span><span id="3685" class="or nu iq pd b gy pl pi l pj pk">const IMAGE_SIZE = 224;<br/>let mobilenet;<br/>let demoStatusElement;<br/>let status;<br/>let mobilenet2;</span></pre><p id="abf8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="nh"> imagenet_classes </em>是一个包含所有类的名称和字典中相应数字的文件。不要介意变量名！这段代码经历了多次尝试，以获得手头任务的完美应用程序。接下来，我们将从“App”类开始。类中的第一个方法是构造函数方法。</p><pre class="ll lm ln lo gt pc pd pe pf aw pg bi"><span id="9993" class="or nu iq pd b gy ph pi l pj pk">constructor(props){<br/>    super(props);<br/>    this.state = {<br/>      load:false,<br/>      status: "F1 score of the model is: 0.9908 ",<br/>      probab: ""<br/>     };<br/>     this.mobilenetDemo = this.mobilenetDemo.bind(this);<br/>     this.predict = this.predict.bind(this);<br/>     this.showResults = this.showResults.bind(this);<br/>     this.filechangehandler = this.filechangehandler.bind(this);<br/>  }</span></pre><p id="61ad" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="nh">加载</em>状态是针对加载图像之前的动画。<em class="nh">状态</em>是应用程序中的默认声明。<em class="nh">概率</em>每次图像通过时，状态都会发生变化，包含其预测的准确性。下面几节将讨论这四种方法。</p><p id="0cb0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，我们将为特定任务定义所有这4种方法。正如我之前提到的变量名，忽略它们。ResTS架构使用<em class="nh">异常</em>架构，即使有些变量说<em class="nh"> mobilenet </em>。</p><pre class="ll lm ln lo gt pc pd pe pf aw pg bi"><span id="d7e5" class="or nu iq pd b gy ph pi l pj pk">async mobilenetDemo(){<br/>    const catElement = document.getElementById('cat');<br/>    if (catElement.complete &amp;&amp; catElement.naturalHeight !== 0) {<br/>      this.predict(catElement);<br/>      catElement.style.display = '';<br/>    } else {<br/>      catElement.onload = () =&gt; {<br/>        this.predict(catElement);<br/>        catElement.style.display = '';<br/>      }<br/>    }</span><span id="1783" class="or nu iq pd b gy pl pi l pj pk">};</span></pre><p id="39cf" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="nh"> mobilenetDemo() </em> async方法通过调用<em class="nh"> prediction() </em>方法，加载app第一次渲染时的第一张图片及其预测。<em class="nh"> prediction() </em>方法以图像元素为输入，调用Flask服务器进行相关预测。服务器返回3个参数——疾病、概率和热图。</p><pre class="ll lm ln lo gt pc pd pe pf aw pg bi"><span id="2842" class="or nu iq pd b gy ph pi l pj pk">async predict(imgElement) {<br/>    let img = tf.browser.fromPixels(imgElement).toFloat().reshape([1, 224, 224, 3]);<br/>    //img = tf.reverse(img, -1);<br/>    this.setState({<br/>            load:true<br/>    });<br/>    const image = await axios.post('http://localhost:5000/detect', {'image': img.dataSync()});<br/>    this.setState({<br/>            load:false<br/>    });<br/>    // // Show the classes in the DOM.<br/>    this.showResults(imgElement, image.data['disease'], image.data['probab'], tf.tensor3d([image.data['image']].flat(), [224, 224, 3]));<br/>  }</span></pre><p id="650d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">最后，调用<em class="nh"> showResults() </em>方法在app中显示结果。<em class="nh"> showResults() </em>方法从<em class="nh"> prediction() </em>方法中取4个值作为参数。该方法执行一些基本的HTML操作，将结果从服务器描绘到应用程序中。</p><pre class="ll lm ln lo gt pc pd pe pf aw pg bi"><span id="7f4b" class="or nu iq pd b gy ph pi l pj pk">async showResults(imgElement, diseaseClass, probab, tensor) {<br/>    const predictionContainer = document.createElement('div');<br/>    predictionContainer.className = 'pred-container';</span><span id="c351" class="or nu iq pd b gy pl pi l pj pk">    const imgContainer = document.createElement('div');<br/>    imgContainer.appendChild(imgElement);<br/>    predictionContainer.appendChild(imgContainer);</span><span id="2823" class="or nu iq pd b gy pl pi l pj pk">    const probsContainer = document.createElement('div');<br/>    const predictedCanvas = document.createElement('canvas');<br/>    probsContainer.appendChild(predictedCanvas);</span><span id="8de2" class="or nu iq pd b gy pl pi l pj pk">    predictedCanvas.width = tensor.shape[0];<br/>    predictedCanvas.height = tensor.shape[1];<br/>    tensor = tf.reverse(tensor, -1);<br/>    await tf.browser.toPixels(tensor, predictedCanvas);<br/>    console.log(probab);<br/>    this.setState({<br/>      probab: "The last prediction was " + parseFloat(probab)*100 + " % accurate!"<br/>    });<br/>    const predictedDisease = document.createElement('p');<br/>    predictedDisease.innerHTML = 'Disease: ';<br/>    const i = document.createElement('i');<br/>    i.innerHTML = CLASSES[diseaseClass];<br/>    predictedDisease.appendChild(i);<br/>    <br/>    //probsContainer.appendChild(predictedCanvas);<br/>    //probsContainer.appendChild(predictedDisease);</span><span id="f525" class="or nu iq pd b gy pl pi l pj pk">    predictionContainer.appendChild(probsContainer);<br/>    predictionContainer.appendChild(predictedDisease);<br/>    const predictionsElement = document.getElementById('predictions');<br/>    predictionsElement.insertBefore(<br/>        predictionContainer, predictionsElement.firstChild);<br/>  }</span></pre><p id="cd47" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">每当通过上传按钮上传图像时，就会触发<em class="nh"> filechangehandler() </em>方法。</p><pre class="ll lm ln lo gt pc pd pe pf aw pg bi"><span id="46aa" class="or nu iq pd b gy ph pi l pj pk">filechangehandler(evt){<br/>    let files = evt.target.files;<br/>    for (let i = 0, f; f = files[i]; i++) {<br/>      // Only process image files (skip non image files)<br/>      if (!f.type.match('image.*')) {<br/>        continue;<br/>      }<br/>      let reader = new FileReader();<br/>      reader.onload = e =&gt; {<br/>        // Fill the image &amp; call predict.<br/>        let img = document.createElement('img');<br/>        img.src = e.target.result;<br/>        img.width = IMAGE_SIZE;<br/>        img.height = IMAGE_SIZE;<br/>        img.onload = () =&gt; this.predict(img);<br/>      };</span><span id="2c2e" class="or nu iq pd b gy pl pi l pj pk">// Read in the image file as a data URL.<br/>      reader.readAsDataURL(f);<br/>    }<br/>  }</span></pre><p id="c881" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">最后，我们要调用<em class="nh"> mobilenetDemo() </em>方法来加载第一幅图像及其预测。对于此任务，我们将使用<em class="nh"> componentDidMount() </em>生命周期方法。</p><pre class="ll lm ln lo gt pc pd pe pf aw pg bi"><span id="7b8c" class="or nu iq pd b gy ph pi l pj pk">componentDidMount(){<br/>    this.mobilenetDemo();<br/>  }</span><span id="0ad5" class="or nu iq pd b gy pl pi l pj pk">render(){<br/>    return (<br/>        &lt;div className="tfjs-example-container"&gt;<br/>        &lt;section className='title-area'&gt;<br/>          &lt;h1&gt;ResTS for Plant Disease Diagnosis&lt;/h1&gt;<br/>        &lt;/section&gt;</span><span id="c289" class="or nu iq pd b gy pl pi l pj pk">&lt;section&gt;<br/>          &lt;p className='section-head'&gt;Description&lt;/p&gt;<br/>          &lt;p&gt;<br/>            This WebApp uses the ResTS model which will be made available soon for public use.</span><span id="4fa4" class="or nu iq pd b gy pl pi l pj pk">It is not trained to recognize images that DO NOT have BLACK BACKGROUNDS. For best performance, upload images of leaf\/Plant with black background. You can see the disease categories it has been trained to recognize in &lt;a<br/>              href="https://github.com/spMohanty/PlantVillage-Dataset/tree/master/raw/segmented"&gt;this folder&lt;/a&gt;.<br/>          &lt;/p&gt;<br/>        &lt;/section&gt;</span><span id="7f18" class="or nu iq pd b gy pl pi l pj pk">&lt;section&gt;<br/>          &lt;p className='section-head'&gt;Status&lt;/p&gt;<br/>          {this.state.load?&lt;div id="status"&gt;{this.state.status}&lt;/div&gt;:&lt;div id="status"&gt;{this.state.status}&lt;br&gt;&lt;/br&gt;{this.state.probab}&lt;/div&gt;}<br/>        &lt;/section&gt;</span><span id="4dd8" class="or nu iq pd b gy pl pi l pj pk">&lt;section&gt;<br/>          &lt;p className='section-head'&gt;Model Output&lt;/p&gt;</span><span id="7ecf" class="or nu iq pd b gy pl pi l pj pk">&lt;div id="file-container"&gt;<br/>            Upload an image: &lt;input type="file" id="files" name="files[]" onChange={this.filechangehandler} multiple /&gt;<br/>          &lt;/div&gt;<br/>          {this.state.load?&lt;div className="lds-roller"&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;&lt;/div&gt;:''}</span><span id="9fab" class="or nu iq pd b gy pl pi l pj pk">&lt;div id="predictions"&gt;&lt;/div&gt;</span><span id="a0ea" class="or nu iq pd b gy pl pi l pj pk">&lt;img id="cat" src={cat}/&gt;<br/>        &lt;/section&gt;<br/>      &lt;/div&gt;</span><span id="d40b" class="or nu iq pd b gy pl pi l pj pk">);<br/>}</span></pre><p id="269c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="nh"> render() </em>方法包含不言自明的HTML元素。</p><h1 id="f8e3" class="nt nu iq bd nv nw po ny nz oa pp oc od kf pq kg of ki pr kj oh kl ps km oj ok bi translated">3.集成先进的深度学习和ReactJS用于植物病害诊断</h1><p id="f1e2" class="pw-post-body-paragraph ko kp iq kq b kr ol ka kt ku om kd kw kx on kz la lb oo ld le lf op lh li lj ij bi translated">下面的Gif描述了与flask服务器连接的web应用程序的工作方式，该服务器包括预训练的ResTS模型。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi pt"><img src="../Images/5660d98f77a731e5f2c01f95d71611bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*pyVNRgO8JaB4d5XFfE8eEQ.gif"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">Gif 1。反应应用程序</p></figure><h2 id="61b3" class="or nu iq bd nv os ot dn nz ou ov dp od kx ow ox of lb oy oz oh lf pa pb oj iw bi translated">从<a class="ae lw" href="http://linkedin.com/in/dhruvilshah28" rel="noopener ugc nofollow" target="_blank">这里</a>在LinkedIn上与我联系。</h2><h1 id="2901" class="nt nu iq bd nv nw po ny nz oa pp oc od kf pq kg of ki pr kj oh kl ps km oj ok bi translated">参考</h1><ol class=""><li id="2ecb" class="pu pv iq kq b kr ol ku om kx pw lb px lf py lj pz qa qb qc bi translated">D.Shah，V. Trivedi，V. Sheth，A. Shah，U. Chauhan，ResTS:植物病害检测的剩余深度可解释体系结构，农业信息处理(2021)，doi:https://doi.org/10.1016/j.inpa.2021.06.001</li></ol></div></div>    
</body>
</html>