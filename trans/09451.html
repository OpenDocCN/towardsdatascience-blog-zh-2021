<html>
<head>
<title>How To Tune HDBSCAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何调整HDBSCAN</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tuning-with-hdbscan-149865ac2970?source=collection_archive---------3-----------------------#2021-09-02">https://towardsdatascience.com/tuning-with-hdbscan-149865ac2970?source=collection_archive---------3-----------------------#2021-09-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2422" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何调整基于密度的沟道聚类的快速示例</h2></div><p id="f55b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">聚类是一个非常困难的问题，因为当标签不存在时，永远不会有真正的“正确”答案。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/5f4012b38b0d9b57742aa7d21444947c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fI1r7zSY71B3ujgW"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">Tengyart通过<a class="ae lr" href="https://unsplash.com/photos/DoqtEEn8SOo" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="6114" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是由各种技术和各种假设造成的。如果一项技术运行不正确，违反了一个假设，这将导致不正确的(完全错误的)结果。</p><p id="d9f5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇博文中，我们将深入探讨为什么集群变得复杂，然后深入研究如何利用<a class="ae lr" href="https://github.com/awslabs/amazon-denseclus" rel="noopener ugc nofollow" target="_blank">亚马逊DenseClus </a>库在<a class="ae lr" href="https://github.com/scikit-learn-contrib/hdbscan" rel="noopener ugc nofollow" target="_blank"> HDBSCAN </a>中适当地调优基于密度的集群。</p><h1 id="4548" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">背景:聚类是复杂的😬</h1><p id="dbfd" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">聚类算法没有免费的午餐，虽然一种算法可能很适合某个数据集，但不能保证它会以完全相同的方式在不同的数据集上工作。同样，聚类“强烈依赖于研究人员的背景、目标和决策”，这为Henning在<a class="ae lr" href="https://arxiv.org/abs/1502.02555" rel="noopener ugc nofollow" target="_blank">什么是真正的聚类中指出的“普遍最优的方法只会产生自然的聚类”这一说法火上浇油。亨宁2015 </a>。</p><p id="2789" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，KMeans等常用技术假设数据是数值型和球形的。当数据具有高维数并且包括分类值时，这些类型的假设不太合理。</p><p id="4d41" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">违反假设的聚类数据以两种方式给从业者带来难题:</p><ol class=""><li id="676d" class="mp mq iq kh b ki kj kl km ko mr ks ms kw mt la mu mv mw mx bi translated">如何形式化一个具体的特化方案？</li><li id="ca36" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated">选择什么样的聚类技术？</li></ol><p id="9090" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这两者都必须公式化，以便不违反任何假设。实际上，这可能导致一个排除过程，不违反算法假设的算法和特征方案是唯一的选择。</p><h1 id="4c0d" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">警惕你的度量标准📈</h1><p id="9802" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">当没有标签可用时，通常选择一个客观的度量，如<a class="ae lr" href="https://en.wikipedia.org/wiki/Silhouette_(clustering)" rel="noopener ugc nofollow" target="_blank">轮廓分数</a>来评估，然后决定最终的聚类结果。剪影分数用介于-1到1之间的指数来衡量集群的内聚性和分离性。它不<em class="nd">不</em>在指数计算中考虑噪音，并利用距离。距离不适用于基于密度的技术。在客观度量计算中不包括噪声违反了基于密度的聚类中的固有假设。</p><p id="b77f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">这意味着剪影分数和类似的指数不适合测量基于密度的技术！！！</strong>(我自己强调了这一点，因为我已经看到很多博客都在这么做——这很危险。)</p><h1 id="f0cc" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">基于密度的聚类验证对救援🌈</h1><p id="a1cf" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">基于密度的聚类验证或DBCV适用于基于密度的聚类算法，因为它考虑了噪声，并通过密度而不是距离来捕获聚类的形状属性(参见<a class="ae lr" href="https://www.dbs.ifi.lmu.de/~zimek/publications/SDM2014/DBCV.pdf" rel="noopener ugc nofollow" target="_blank">原始论文</a></p><p id="f7f3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如论文所解释的，DBCV的最终结果是聚类的“有效性指数”值的加权和。这会产生一个介于-1到1之间的分数，该值越大，聚类解决方案越好。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ne"><img src="../Images/a97dd6032f59062cddfbe5c8adb496df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4FEpIh4FwKTvJwyhNwSazA.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">来源:基于密度的聚类验证，Moulavi等人，2014年</p></figure><p id="51a6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">深入的讨论超出了这里的范围，但请参阅原始文件的更多细节。</p><p id="7e4c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，DBCV确实有<a class="ae lr" href="https://github.com/scikit-learn-contrib/hdbscan/issues/283" rel="noopener ugc nofollow" target="_blank">缺点</a>。像所有其他度量和技术一样，DBCV也不能避免前面提到的聚类中的复杂性和度量问题。</p><p id="ed15" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，除了有基础事实标签之外，它还提供了一个客观标准来判断基于密度的技术集群的分离程度。</p><h1 id="98eb" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">真实的例子🚀</h1><p id="0fd1" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">说够了，让我们深入一个真实的例子。</p><p id="52fd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lr" href="https://github.com/awslabs/amazon-denseclus/blob/main/notebooks/Validation%20For%20UMAP.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>可以在<a class="ae lr" href="https://github.com/awslabs/amazon-denseclus" rel="noopener ugc nofollow" target="_blank">亚马逊Denseclus图书馆</a>中找到。</p><p id="5c51" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本例中，您将使用一个虚构的电信公司的合成客户流失数据集，其结果是客户流失？标记为真(已搅动)或假(未搅动)。功能包括客户详细信息，如计划和使用信息。客户流失数据集是公开可用的，并在丹尼尔·t·拉罗斯的《从数据中发现知识》一书中提到。作者将其归功于加州大学欧文分校的机器学习数据集仓库。</p><p id="4760" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些数据包括数值和分类特征，但将使用Denseclus将其转换到低维、密集的空间，以在其上形成聚类。更多关于DenseClus <a class="ae lr" href="https://aws.amazon.com/blogs/opensource/introducing-denseclus-an-open-source-clustering-package-for-mixed-type-data/" rel="noopener ugc nofollow" target="_blank">的信息，请看这里</a>。所有需要的转换都在幕后处理。你只需要打电话给<code class="fe nf ng nh ni b">fit</code>。</p><pre class="lc ld le lf gt nj ni nk nl aw nm bi"><span id="f091" class="nn lt iq ni b gy no np l nq nr"># This runs in about a minute or two<br/>from denseclus import DenseClus<br/><br/>import logging # to further silence deprecation warnings<br/><br/>logging.captureWarnings(True)<br/>clf = DenseClus(<br/>    random_state=SEED,<br/>    umap_combine_method="intersection_union_mapper"<br/>)<br/><br/>clf.fit(df)</span></pre><p id="990d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在其他步骤中，Denseclus使用HDBSCAN对数据进行聚类。</p><p id="87ae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看看数据是如何分割的。</p><pre class="lc ld le lf gt nj ni nk nl aw nm bi"><span id="c6e9" class="nn lt iq ni b gy no np l nq nr">embedding = clf.mapper_.embedding_<br/>labels = clf.score()<br/>clustered = (labels &gt;= 0)<br/><br/>cnts = pd.DataFrame(labels)[0].value_counts()<br/>cnts = cnts.reset_index()<br/>cnts.columns = ['cluster','count']<br/>print(cnts.sort_values(['cluster']))</span><span id="a577" class="nn lt iq ni b gy ns np l nq nr">cluster  count<br/>4       -1      9<br/>3        0   1234<br/>0        1   1265<br/>1        2   1253<br/>2        3   1239</span></pre><p id="37ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">经检查，正好有4个几乎均匀分布的聚类，其中-1表示在数据中发现的噪声。</p><p id="43b3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，为了简单地观察它们的分布，另一种评估集群的方法是将它们可视化。</p><pre class="lc ld le lf gt nj ni nk nl aw nm bi"><span id="4b25" class="nn lt iq ni b gy no np l nq nr">_=sns.jointplot(<br/>    x=embedding[clustered, 0], y=embedding[clustered, 1], hue=labels[clustered], kind="kde"<br/>)</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="ab gu cl nt"><img src="../Images/861d1528f5a4fcf21857284420e10b3e.png" data-original-src="https://miro.medium.com/v2/format:webp/1*v2rDiz6Zx1anX3ZX2XkBvg.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">照片由Auhtor拍摄</p></figure><p id="32e2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如您所见，我们在这个数据切片中形成了4个不同的孤岛。在这些密度周围形成了团簇，这正是我们所期望的DenseClus的行为。</p><p id="709f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以通过绘制密度被分割的树来进一步确认结果。</p><p id="2d5f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是我们看到的包含更多信息的计数的图形视图。例如，您可以看到双集群解决方案也是可行的，因为两个密度代表集群的基本分割。</p><pre class="lc ld le lf gt nj ni nk nl aw nm bi"><span id="f8b9" class="nn lt iq ni b gy no np l nq nr">_=clf.hdbscan_.condensed_tree_.plot(<br/>    select_clusters=True,<br/>    selection_palette=sns.color_palette("deep", np.unique(clusters).shape[0]),<br/>)</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="ab gu cl nt"><img src="../Images/b02bd91b9003ed27954371a2a8ca0f11.png" data-original-src="https://miro.medium.com/v2/format:webp/1*H3U6EjtT3mW9JOLi1UjgYA.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者照片</p></figure><p id="e400" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，让我们确认大部分数据点被我们的聚类(提示:只有9个没有)和DBCV分数覆盖。</p><pre class="lc ld le lf gt nj ni nk nl aw nm bi"><span id="c6e5" class="nn lt iq ni b gy no np l nq nr">coverage = np.sum(clustered) / embedding.shape[0]<br/><br/>print(f"Coverage {coverage}")<br/>print(f"DBCV score {clf.hdbscan_.relative_validity_}")</span><span id="0b2e" class="nn lt iq ni b gy ns np l nq nr">Coverage 0.9982<br/>DBCV score 0.2811143727637039</span></pre><p id="8882" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在-1比1的范围内，DBCV系数为0.28。</p><p id="ebc5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这不太好，但还可能更糟。让我们优化分数，找出要通过的最佳HDBSCAN超参数。</p><h1 id="49ee" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">超参数调谐🦾</h1><p id="8c74" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">进一步改善结果的两个主要超参数是<code class="fe nf ng nh ni b">min_samples</code>和<code class="fe nf ng nh ni b">min_cluster_size</code>，如<a class="ae lr" href="https://hdbscan.readthedocs.io/en/latest/parameter_selection.html" rel="noopener ugc nofollow" target="_blank"> HDBSCAN文档</a>中所述。</p><p id="072c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您将运行这些的多个组合，以找到产生高DBCV分数的结果。</p><p id="2120" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">除了查看这些超参数外，您还将查看具有大规模eom预期的聚类选择方法，以及使用树叶沿树分割聚类(详情请参见hdbscan:麦金尼斯j . Healy s . Astels 2017中的基于分层密度的聚类)。</p><p id="502d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如HDBSCAN的文档所指出的，eom方法只从树中提取最稳定、最精简的集群，而leaf方法也从叶节点的底部选择集群。</p><p id="0f5a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这导致更小、更同质的集群，更有可能是细粒度的。</p><pre class="lc ld le lf gt nj ni nk nl aw nm bi"><span id="e462" class="nn lt iq ni b gy no np l nq nr">from sklearn.model_selection import RandomizedSearchCV<br/>import hdbscan<br/>from sklearn.metrics import make_scorer<br/><br/><br/>logging.captureWarnings(True)<br/>hdb = hdbscan.HDBSCAN(gen_min_span_tree=True).fit(embedding)<br/><br/># specify parameters and distributions to sample from<br/>param_dist = {'min_samples': [10,30,50,60,100],<br/>              'min_cluster_size':[100,200,300,400,500,600],  <br/>              'cluster_selection_method' : ['eom','leaf'],<br/>              'metric' : ['euclidean','manhattan'] <br/>             }<br/><br/>#validity_scroer = "hdbscan__hdbscan___HDBSCAN__validity_index"<br/>validity_scorer = make_scorer(hdbscan.validity.validity_index,greater_is_better=True)<br/><br/><br/>n_iter_search = 20<br/>random_search = RandomizedSearchCV(hdb<br/>                                   ,param_distributions=param_dist<br/>                                   ,n_iter=n_iter_search<br/>                                   ,scoring=validity_scorer <br/>                                   ,random_state=SEED)<br/><br/>random_search.fit(embedding)<br/><br/><br/>print(f"Best Parameters {random_search.best_params_}")<br/>print(f"DBCV score :{random_search.best_estimator_.relative_validity_}")</span><span id="10d9" class="nn lt iq ni b gy ns np l nq nr">Best Parameters {'min_samples': 100, 'min_cluster_size': 300, 'metric': 'manhattan', 'cluster_selection_method': 'eom'}<br/>DBCV score :0.48886415007392386</span></pre><p id="2453" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">DBCV得分现在已经从0.28上升到0.488。</p><p id="7560" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">DenseClus默认<code class="fe nf ng nh ni b">min_samples</code>为15，<code class="fe nf ng nh ni b">min_cluster_size</code>为100。随机搜索结果具有更大和更严格的聚类，这导致更高的密度和更高的分数:)城市街区距离或曼哈顿距离似乎也有助于增加。</p><p id="48f8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在实践中，我们希望分数超过0.45，以确保聚类被很好地分离，这个分数表明了这一点。</p><p id="0114" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们通过观察集群是如何分裂的并再次可视化结果来确认这一点。</p><pre class="lc ld le lf gt nj ni nk nl aw nm bi"><span id="644c" class="nn lt iq ni b gy no np l nq nr"># evalute the clusters<br/>labels = random_search.best_estimator_.labels_<br/>clustered = (labels &gt;= 0)<br/>    <br/>coverage = np.sum(clustered) / embedding.shape[0]<br/>total_clusters = np.max(labels) + 1<br/>cluster_sizes = np.bincount(labels[clustered]).tolist()<br/><br/>print(f"Percent of data retained: {coverage}")<br/>print(f"Total Clusters found: {total_clusters}")<br/>print(f"Cluster splits: {cluster_sizes}")<br/><br/><br/>_=sns.jointplot(<br/>    x=embedding[clustered, 0], y=embedding[clustered, 1], hue=labels[clustered], kind="kde"<br/>)</span><span id="33df" class="nn lt iq ni b gy ns np l nq nr">Percent of data retained: 1.0<br/>Total Clusters found: 3<br/>Cluster splits: [2501, 1236, 1263]</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="ab gu cl nt"><img src="../Images/6362e9d185c1f8cb155c0d1fbcc85a52.png" data-original-src="https://miro.medium.com/v2/format:webp/1*l59et0ukJoJUW6pl3dHT3A.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者照片</p></figure><p id="2c09" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有趣的是，足够没有发现噪音。两个星团完全相同，其中一个的大小几乎是它们的总和。</p><p id="df33" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将同一切片上的数据可视化给了我们一个线索，让我们知道这里发生了什么。我们之前运行的编号为3和2的集群现在合并在一起了。</p><p id="4b92" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">转移到不同的维度切片有时可以帮助解释这里的事情，下图显示了一个更好的视图。</p><pre class="lc ld le lf gt nj ni nk nl aw nm bi"><span id="193b" class="nn lt iq ni b gy no np l nq nr">_=sns.jointplot(<br/>    x=embedding[clustered, 1], y=embedding[clustered, 2], hue=labels[clustered], kind="kde"<br/>)</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="ab gu cl nt"><img src="../Images/d78132cb89bd8e5966c926809fc014f4.png" data-original-src="https://miro.medium.com/v2/format:webp/1*uvY0DUT5Ea0gasTpU0D1ug.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者照片</p></figure><h1 id="b944" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">总结🥂</h1><p id="fa9b" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">我希望您喜欢仔细研究如何为HDBSCAN调优超参数！！！</p><p id="cc45" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，您了解了为什么聚类和聚类指标会变得复杂，然后了解了作为客观指标的DBCV，然后使用Amazon Denseclus和HDBSCAN应用了它。</p><p id="8a3c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们在这里只讨论了表面。要深入了解，您可以查看以下内容:</p><ul class=""><li id="4d2e" class="mp mq iq kh b ki kj kl km ko mr ks ms kw mt la nu mv mw mx bi translated">你能使用什么其他类型的优化框架来代替随机搜索？</li><li id="09de" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la nu mv mw mx bi translated">有哪些其他类型的超参数可以用于优化？</li><li id="73da" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la nu mv mw mx bi translated">对于进一步的聚类验证，还有什么其他的方法？</li><li id="d4f8" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la nu mv mw mx bi translated">Denseclus中的任何其他底层超参数可以调整以获得更高的分数吗？</li></ul><h2 id="f544" class="nn lt iq bd lu nv nw dn ly nx ny dp mc ko nz oa me ks ob oc mg kw od oe mi of bi translated">参考</h2><p id="cfbe" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">“轮廓:聚类分析解释和验证的图形辅助”，Rousseeuw，1987年</p><p id="05e6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">“基于密度的聚类验证”，Moulavi等人，2014年</p><p id="0966" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">“hdbscan:基于分层密度的聚类”，麦金尼斯，J. Healy，S. Astels 2017</p></div></div>    
</body>
</html>