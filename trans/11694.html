<html>
<head>
<title>Generating Synthetic Images of Marine Plastic Using Deep Convolutional Generative Adversarial Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度卷积生成对抗网络生成海洋塑料的合成图像</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generating-synthetic-images-of-marine-plastic-using-deep-convolutional-generative-adversarial-60e6178c5aa6?source=collection_archive---------21-----------------------#2021-11-19">https://towardsdatascience.com/generating-synthetic-images-of-marine-plastic-using-deep-convolutional-generative-adversarial-60e6178c5aa6?source=collection_archive---------21-----------------------#2021-11-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="66ae" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">建立一种能够使用GANs合成海洋塑料图像的生成方法</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/84e8bb44e2ea5caeb1adc5ecd86bda9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Escb4m3bngVxCZTMIfoazA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">训练我们的DCGAN模型后生成的合成图像</p></figure><h1 id="effa" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">问题陈述</h1><p id="5bb0" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">过去十年，海洋塑料污染一直处于气候问题的前沿。海洋中的塑料不仅能够通过窒息或饥饿杀死海洋生物，而且也是通过捕集二氧化碳使海洋变暖的主要因素。近年来，已经有很多尝试来清理环绕我们海洋的塑料，例如非营利组织海洋清理。大量清理过程的问题是，它需要人力，并且不具有成本效益。已经有很多研究通过使用计算机视觉和深度学习来自动完成这一过程，以检测海洋废弃物，利用ROV和AUV进行清理。</p><p id="6ca9" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">注意:这是理论上的，我们正在努力发表我们的论文。一旦它被同行评审并在杂志上发表，我会更新这篇文章。所以，请关注我们学术论文的发布空间！</p><p id="a5c1" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir">阅读资源</strong> : <a class="ae mo" href="https://arxiv.org/abs/2105.01882" rel="noopener ugc nofollow" target="_blank">我们关于使用CV和DL检测表层塑料的论文</a>，<a class="ae mo" href="https://arxiv.org/abs/1804.01079" rel="noopener ugc nofollow" target="_blank">明尼苏达大学关于通用海洋垃圾检测算法的论文</a>，以及<a class="ae mo" href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019EA000960" rel="noopener ugc nofollow" target="_blank">海洋清洁组织关于河流上漂浮塑料检测的论文。</a></p><p id="582f" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">这种方法的主要问题是关于训练计算机视觉模型的数据集的可用性。JAMSTEC-JEDI数据集是日本沿海海底海洋废弃物的良好集合。但是，除了这个数据集之外，数据集的可用性存在巨大差异。为此，我利用了生成性对抗网络的帮助；具体来说，DCGAN可以筛选合成数据集，这些数据集在理论上可以是真实数据集的近似副本。(我是从理论上写的，因为有很多变量，如可用的真实图像的质量、GANs的进展、培训等)。</p><h2 id="fdce" class="mp kw iq bd kx mq mr dn lb ms mt dp lf lw mu mv lh ma mw mx lj me my mz ll na bi translated">GAN和DCGAN</h2><p id="0af5" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">GANs或生成对抗网络是由Ian Goodfellow等人在2014年提出的。GANs由两个简单的组件组成，称为生成器和鉴别器。该过程的一个过度简化如下:生成器的作用是生成新数据，鉴别器的作用是区分生成的数据和实际数据。在理想情况下，鉴别器无法区分生成的数据和真实数据，从而产生理想的合成数据点。</p><p id="162f" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">DCGAN是上述GAN架构的直接扩展，只是它分别在鉴别器和发生器中使用了深度卷积层。最早是由拉德福德等人描述的。al在论文<a class="ae mo" href="https://arxiv.org/pdf/1511.06434.pdf" rel="noopener ugc nofollow" target="_blank">中用深度卷积生成对抗网络进行无监督表示学习</a>。鉴别器由步进卷积层组成，而发生器由卷积转置层组成。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/c6cd4b5203d50d5cb4c91fee7972dc2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*A84kG-LUQpSx1Ry7JzuXEA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">甘建筑(来源:<a class="ae mo" href="https://sigmoidal.io/beginners-review-of-gan-architectures/" rel="noopener ugc nofollow" target="_blank">此处</a>)</p></figure><h1 id="abb1" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">PyTorch实现</h1><p id="e5d3" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在这个方法中，我们将在<a class="ae mo" href="https://zenodo.org/record/5562940#.YWSaTNnMK3I" rel="noopener ugc nofollow" target="_blank"> DeepTrash </a>数据集<strong class="lp ir">(引用链接:</strong><a class="ae mo" href="https://zenodo.org/record/5562940#.YZa9Er3MI-R" rel="noopener ugc nofollow" target="_blank"><strong class="lp ir">https://zenodo.org/record/5562940#.YZa9Er3MI-R</strong></a><strong class="lp ir">)上应用DCGAN架构，在</strong> <a class="ae mo" href="https://creativecommons.org/licenses/by/4.0/legalcode" rel="noopener ugc nofollow" target="_blank"> <strong class="lp ir">知识共享署名4.0国际</strong> </a> <strong class="lp ir">许可下发布</strong>。如果你不熟悉DeepTrash数据集，可以考虑阅读我的论文<a class="ae mo" href="https://arxiv.org/abs/2105.01882" rel="noopener ugc nofollow" target="_blank">一种使用深度视觉模型量化表层绑定塑料的机器人方法</a>。DeepTrash是海洋表层和深海层塑料图像的集合，用于使用计算机视觉进行海洋塑料检测。</p><p id="92dd" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">让我们开始编码吧！</p></div><div class="ab cl nc nd hu ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="ij ik il im in"><h1 id="d3d3" class="kv kw iq bd kx ky nj la lb lc nk le lf jw nl jx lh jz nm ka lj kc nn kd ll lm bi translated">代码</h1><h2 id="6ed3" class="mp kw iq bd kx mq mr dn lb ms mt dp lf lw mu mv lh ma mw mx lj me my mz ll na bi translated">安装要求</h2><p id="cd9f" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我们首先安装构建GAN模型的所有基本需求，比如Matplotlib和Numpy。我们还将利用Pytorch的所有工具(如神经网络、转换)。如果您不熟悉PyTorch，我建议您阅读这篇文章:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="no np l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">基本安装要求</p></figure><h2 id="00c8" class="mp kw iq bd kx mq mr dn lb ms mt dp lf lw mu mv lh ma mw mx lj me my mz ll na bi translated">初始化我们的超参数</h2><p id="f2fe" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">这一步相当简单。我们要设置超参数来训练神经网络。这些超参数直接从论文和PyTorch关于训练GANs的教程中借用。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="no np l"/></div></figure><h2 id="3ad8" class="mp kw iq bd kx mq mr dn lb ms mt dp lf lw mu mv lh ma mw mx lj me my mz ll na bi translated">发生器和鉴别器架构</h2><p id="877e" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">现在，我们定义生成器和鉴别器的架构。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="no np l"/></div></figure><h2 id="b4e9" class="mp kw iq bd kx mq mr dn lb ms mt dp lf lw mu mv lh ma mw mx lj me my mz ll na bi translated">定义培训功能</h2><p id="598e" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在定义了生成器和鉴别器类之后，我们继续定义训练函数。训练函数接受生成器、鉴别器、优化函数和历元数作为参数。我们通过递归调用训练函数来训练生成器和鉴别器，直到达到所需的历元数。我们通过遍历数据加载器，用来自生成器的新图像更新鉴别器，并计算和更新损失函数来实现这一点。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="no np l"/></div></figure><h2 id="cf57" class="mp kw iq bd kx mq mr dn lb ms mt dp lf lw mu mv lh ma mw mx lj me my mz ll na bi translated">监控和培训DCGAN</h2><p id="a13b" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在我们建立了生成器、鉴别器和train函数之后，最后一步是简单地调用Train函数来获得我们定义的历元数。我还使用了<a class="ae mo" href="https://wandb.ai/site" rel="noopener ugc nofollow" target="_blank"> Wandb </a>来监控我们的训练。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="no np l"/></div></figure><h2 id="3063" class="mp kw iq bd kx mq mr dn lb ms mt dp lf lw mu mv lh ma mw mx lj me my mz ll na bi translated">结果</h2><p id="768b" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我们绘制了培训过程中发生器和歧视造成的损失。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/9ed42e9a38221725dbbb2b886bca378e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*PbeEh45NvxQoMDiMix4RUg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">训练期间发生器和鉴别器损耗</p></figure><p id="2939" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">我们还可以调出生成器如何生成图像的动画，看看真实图像和虚假图像之间的区别。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="e55c" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">大概是这样的:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nr np l"/></div></figure><p id="e86c" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">以及训练后的最终结果图像(与上述图像相同)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/84e8bb44e2ea5caeb1adc5ecd86bda9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Escb4m3bngVxCZTMIfoazA.png"/></div></div></figure><h1 id="b6f0" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">结论</h1><p id="a082" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在本文中，我们讨论了使用深度卷积生成对抗网络来生成海洋塑料的合成图像，研究人员可以使用这些图像来扩展他们当前的海洋塑料数据集。这有助于让研究人员能够通过混合真实和合成图像来扩展他们的数据集。正如你所看到的结果，GAN仍然需要大量的工作。海洋是一个复杂的环境，具有变化的光照、混浊度、模糊度等。但这是一个理论起点，其他研究人员可以以此为基础。如果您对改善结果和构建更好的网络架构感兴趣，请联系gautamtata.blog@gmail.com大学的我。</p></div></div>    
</body>
</html>