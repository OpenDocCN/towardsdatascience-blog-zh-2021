<html>
<head>
<title>How to Add Uncertainty Estimation to your Models with Conformal Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用共形预测将不确定性估计添加到模型中</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-add-uncertainty-estimation-to-your-models-with-conformal-prediction-a5acdb86ea05?source=collection_archive---------5-----------------------#2021-07-25">https://towardsdatascience.com/how-to-add-uncertainty-estimation-to-your-models-with-conformal-prediction-a5acdb86ea05?source=collection_archive---------5-----------------------#2021-07-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3997" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为什么不确定性估计的共形预测可以改善您的预测</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a52a1076378666e6659efb11e515f396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XG192viu0eboZPqj"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@zachsavinar?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">扎克·萨维纳尔</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">号航天飞机</a>上的照片</p></figure><p id="fc8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">预测建模在社会中的流行正在增加，并且这些算法在我们的社会中的角色正在改变。许多人关心对这些算法的信任程度。<strong class="lb iu">欧洲引入GDPR等政策变化</strong>表明，人们想知道这些对我们生活有如此大影响的算法是如何工作的。</p><p id="6f25" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">点预测对回归问题意味着什么？在训练过程中对数据的微小改变会对输出产生很大的影响吗？<strong class="lb iu">您有多确定点估计是您试图预测的实际值？</strong></p><p id="4fcc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，对于分类，在二元问题中，预测是0还是1是什么意思？你的模型能预测相反的等级吗？还是它如此确信实际值是您可以确定的1类？</p><p id="edd0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于任何一个有监督的问题，输出只是整体解决方案的一部分。了解不确定性在预测建模中是如何工作的，这就引出了本文的主题，共形预测。</p><p id="0086" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">我在这篇文章中加入了共形预测的背景信息。所以对于那些寻找复制粘贴代码的人来说，向下滚动并复制。</em></p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="cf10" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated"><strong class="ak">保形预测</strong></h1><p id="9a12" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">共形预测是一种模型不可知的方法，用于计算监督问题的不确定性估计。本文将在归纳共形预测(ICP)的背景下讨论共形预测，但我们知道还有另一种形式，即转导共形预测(TCP)。</p><p id="c93d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">由于模型不可知，任何模型都可以包含共形预测</strong>。因此，无论您有复杂的深度学习分类器还是具有1000个估计量的随机森林，共形预测都可以包含在模型中。这一方面使得共形预测模型不可知。</p><p id="7417" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">无论问题是回归问题还是分类问题，不确定性估计都有不同的形式。</p><p id="5137" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于回归问题，共形预测会将点预测更改为预测间隔。这些间隔围绕着您的模型所做的点估计，间隔的<strong class="lb iu">大小直接与您想要的模型确定程度相关联。</strong></p><p id="e8fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于分类问题，保形预测将单类预测变为集合预测。这些集合可以包括您试图预测的每个可能的类。<strong class="lb iu">当存在多个类别时，这表明您的模型对预测</strong>不太确定。而且，集合也可以是空的。如果是这种情况，那么您的模型确实不确定要预测什么类。当您希望您的预测更有把握时，更多的类将出现在您的预测集中。</p><p id="19a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在问题的回归和分类版本中，输出的大小由用户控制。这个影响输出的参数被称为重要性。</p><p id="aa83" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">保形预测在统计上是有效的。例如，如果将显著性设置为0.1，则集合和区间将在90%的时间内包含实际类或真值。这个属性意味着一个测试实例的真实值在90%的时间内将会落在您的区间内，或者测试实例的真实值将会在预测中。</p><p id="eb66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">计算这些区间和集合的方法遵循三个步骤。对于ICP，数据分为三组:训练、校准和测试。具体做什么的细节将在下面讨论。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="4001" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated"><strong class="ak">缺点和顾虑</strong></h1><p id="e243" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">听起来不错。好吧，这些统计保证有两大警告。第一个是保形预测是在可交换性假设下定义的。这种假设意味着保形预测假设您用来训练数据、验证和测试数据的数据是可交换的。这有一个详细的数学公式，但本质上，这就是它的意思。</p><p id="7705" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为训练模型而选择的数据可以放入测试集中。或者考虑您用于校准的数据。同样，这些数据可以用于训练或测试。</p><p id="d08b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">每个记录都可以与另一个记录交换。</strong></p><p id="49d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是可交换性有更强的含义。对于可交换的数据，整个数据集必须来自同一分布。虽然对于许多数据集和将来的实例来说，这一方面是已知的，但是对于其他数据集来说，数据分布会随着时间而变化。在这些情况下，保形预测仍然可以提供一些不确定性估计，但理论上的保证不再可靠。</p><p id="2b9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第二个警告是不确定性估计有一个权衡。例如，假设您希望90%地保证您的预测区间包含真实值。在这种情况下，你会有更大的间隔。但是如果你只想有50%的把握，那么你的间隔时间会长很多。</p><p id="0617" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分类类似。更多的信心，更大的集合。信心更少，套数更少。</p><p id="58c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，这些集合和间隔大小并不简单地线性缩放。相反，它们与您的模型的性能直接相关。所以显著性为0.5的区间可能比显著性为0.1的区间小很多。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/36262f110842fd26ff83b27538f0f045.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yPme7dXIALI4hdr7"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">戴维·罗蒂米在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="a587" class="md me it bd mf mg na mi mj mk nb mm mn jz nc ka mp kc nd kd mr kf ne kg mt mu bi translated"><strong class="ak">符合与不符合</strong></h1><p id="9b5f" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">保形预测的中心思想是围绕着一致性的概念。或者反过来说，不合规。这个概念是预测区间和预测集的核心。但它到底是什么？</p><p id="d3d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">不一致分数衡量每条记录与其余数据不一致的程度。</strong></p><p id="32a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于回归，非一致性分数通常被测量为模型预测和校准实例的真实值之间的差异。</p><p id="1fa7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不一致分数是二元分类的校准数据上与您的分类器相反类别的预测概率。</p><p id="c271" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意这里校准数据集的使用。首先，根据一组数据训练模型，然后根据校准集计算不合格分数。接下来，根据这些校准分数和用户指定的显著性水平，保形预测构建区间或调整如何将类添加到分类集中。</p><p id="0088" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用显著性水平以及一组不一致性分数来确定预测区间。基于用户重要性，通过取分数的第n个百分点来粗略计算区间。因为回归的不一致性分数是预测校准和真实校准之间的差异，所以一致性分数是误差。</p><p id="6de0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于分类，事情的安排略有不同。不一致性分数代表每个类别的预测概率。如果对于用户指定的显著性水平，预测的概率与该显著性一致，则每个类别被包括在该集合中。此处的细节根据所使用的确切不合格分数而有所不同。然而，选择在集合中保留哪些类的过程仍然是相同的。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="870e" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated"><strong class="ak">测试和校准</strong></h1><p id="b098" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">执行校准后，模型可以预测不确定性。</p><p id="0484" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是剩下的工作是测试保形预测器是否正常工作。比如预测类集中是否存在真实类？真值存在于预测区间吗？</p><p id="66bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了回答这两个问题，共形预测器具有它们的校准曲线形式，因为估计的不确定性取决于显著性水平，模型的性能随着该显著性而变化。</p><p id="1d97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在不同的显著性水平上评估性能，以确保具有不确定性的预测在多个显著性水平上是一致的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/6d7f4205dc11c24b59b1561fe93a2cce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H_H7QupMQAbbvflvD33_dA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">校准曲线(作者照片)</p></figure><p id="4be5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据设计，显著性水平为0.1的共形预测值应该在90%的时间里包含实际值。因此，通过用0和1之间的值改变显著性来评估性能<strong class="lb iu">应该与从0到1的线性线对齐。</strong></p><p id="1787" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通常情况下，情况并非如此。然而，对于越来越大的数据集(完全代表其分布的数据集)和性能良好的模型，校准曲线接近完美的线性。</p><p id="0e46" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当校准曲线不完全一致时，这意味着一些事情。数据可能不是来自同一个分布。如果数据是真正可交换的，那么根据保形预测的定义，你应该看到校准。</p><p id="5fe0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了具有校准良好的共形预测器之外，另一个方面值得评估— <strong class="lb iu">区间的大小和集合的大小。</strong></p><p id="e0b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当一个模型在统计上保证了分类和回归的不确定性估计时，这是很好的，但是大小很重要。例如，如果每个预测集包含所有类，则该模型没有帮助。类似地，对于回归，如果每个区间都是巨大的，那么，当然，真实值会落在其中的某个地方。</p><p id="485b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于这些原因，通常显示保形预测器的区间大小和预测集的平均大小。</p><p id="e4e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此处未显示但值得查看的一些其他度量是共形分类器的单线数和共形预测器的p值分布。</p><p id="ba49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当你的分类器非常确定时，单态的数量给你一个概念。</p><p id="9ef0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并且p值的分布类似于校准曲线。因此，当一个图被完美校准时，p值的分布应该是均匀的。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="323b" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated"><strong class="ak">应用保形预测</strong></h1><p id="451e" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">对于这篇文章，我将使用库‘nonconformist ’,它实现了保形预测的几种算法。此外，我添加了一些扩展来展示保形预测的一些属性。</p><p id="8ed8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意，在撰写本文时，nonconformist的基本安装是建立在旧版本的sklearn上的。有些模块导入sklearn.cross_validation，需要修改为导入sklearn.model_selection。您可以在您的环境中的“site-packages”下找到该包。T9】</p><p id="fc88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这第一部分代码有一些通用的导入和用于校准图的函数。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="30f9" class="nl me it nh b gy nm nn l no np">import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.datasets import load_iris, load_boston<br/>from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor<br/>from nonconformist.icp import IcpClassifier, IcpRegressor<br/>from nonconformist.nc import ClassifierNc, MarginErrFunc, ClassifierAdapter, RegressorNc, AbsErrorErrFunc<br/>from sklearn.model_selection import train_test_split</span><span id="a506" class="nl me it nh b gy nq nn l no np">def regression_calibration_curve(estimator, X, y, alphas=np.linspace(0.1,1,10, endpoint=True)):<br/>    errors = []<br/>    interval_sizes = []<br/>    for a in alphas:<br/>        pred = estimator.predict(X, significance=a)<br/>        interval_sizes.append(np.mean([y-x for x, y in pred]))<br/>        errors.append( 1 — np.mean([x &lt;= z and z &lt;= y for (x,y), z in zip(pred, y)]))<br/>    return errors, interval_sizes</span><span id="ee77" class="nl me it nh b gy nq nn l no np">def regression_calibration_plot(estimator, X, y, alphas=np.linspace(0.1,1,10, endpoint=True)):<br/>    errors, interval_sizes = regression_calibration_curve(estimator,X,y,alphas)<br/>    fig, ax1 = plt.subplots()<br/>    ax2 = ax1.twinx()<br/>    ax1.plot([0,1], [0,1])<br/>    ax1.plot(alphas, errors, ‘o’)<br/>    ax2.plot(alphas, interval_sizes, ‘ — ‘)<br/>    ax1.set_xlabel(‘Significance’)<br/>    ax1.set_ylabel(‘Error Rate’)<br/>    ax2.set_ylabel(‘Avg. Interval Size’)<br/>    plt.title(‘Regression Conformal Calibration Curve’)<br/>    plt.show()</span><span id="5573" class="nl me it nh b gy nq nn l no np">def classifier_calibration_curve(estimator, X, y, alphas =np.linspace(0,1,10, endpoint=True)):<br/>    errors = []<br/>    set_sizes = []<br/>    for a in alphas:<br/>        pred = estimator.predict(X, significance=a)<br/>        set_sizes.append(np.mean([np.sum(set) for set in pred]))<br/>        errors.append(1 — np.mean([set[t] for set, t in zip(pred, y)]))<br/>    return errors, set_sizes</span><span id="43a1" class="nl me it nh b gy nq nn l no np">def classification_calibration_plot(estimator, X, y, alphas=np.linspace(0,1,10, endpoint=True)):<br/>    errors, sizes = classifier_calibration_curve(estimator,X,y,alphas)<br/>    fig, ax1 = plt.subplots()<br/>    ax2 = ax1.twinx()<br/>    ax1.plot([0,1], [0,1])<br/>    ax1.plot(alphas, errors, ‘o’)<br/>    ax2.plot(alphas, sizes, ‘ — ‘)<br/>    ax1.set_xlabel(‘Significance’)<br/>    ax1.set_ylabel(‘Error Rate’)<br/>    ax2.set_ylabel(‘Avg. Set Size’)<br/>    plt.title(‘Classification Conformal Calibration Curve’)<br/>    plt.show()</span></pre><p id="1f1f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里我使用不同的领域进行回归和分类。当库的重要性设置为0时，预测间隔似乎有问题。</p><p id="c579" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下示例使用iris数据集进行分类，使用Boston housing数据集进行回归。使用的基本模型是决策树，但是nonconformist允许任何sklearn模型。目前，该包不支持TensorFlow。</p><h1 id="2070" class="md me it bd mf mg na mi mj mk nb mm mn jz nc ka mp kc nd kd mr kf ne kg mt mu bi translated">回归</h1><p id="07da" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">对于回归，校准图显示在间隔大小的旁边。对于波士顿住房数据集，目标变量的标准偏差约为9。因此，在这种情况下，这些间隔并不太大。您还可以在这里看到，这个模型经过了很好的校准。</p><p id="e1b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">此处使用的不合格度量是绝对误差。</strong></p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="66c0" class="nl me it nh b gy nm nn l no np">data = load_boston()<br/>y = data.target<br/>X = data.data<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)<br/>X_calibration, X_test, y_calibration, y_test = train_test_split(X_test, y_test, test_size=0.4, random_state=42)</span><span id="f703" class="nl me it nh b gy nq nn l no np">estimator = DecisionTreeRegressor(random_state=10)<br/>icp = IcpRegressor( RegressorNc(estimator, AbsErrorErrFunc()))<br/>icp.fit(X_train, y_train)<br/>icp.calibrate(X_calibration, y_calibration)<br/>regression_calibration_plot(icp, X_test, y_test)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/6d7f4205dc11c24b59b1561fe93a2cce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H_H7QupMQAbbvflvD33_dA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">回归模型的校准曲线(作者照片)</p></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="de46" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">分类</h1><p id="accc" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">这里，校准图包括平均器械包大小。对于虹膜数据集，有三个类别。如你所见，随着重要性的增加，集合的大小会减小。在这种情况下，该模型相当好，集合大小迅速下降到1左右。但是，您可以看到这些集合大小开始下降。这种下降是因为，在不同的显著性水平上，模型对预测任何类别都没有信心。这种模式随着所选显著性的增加而增加。无论如何，你可以看到这个模型是相对校准良好的。</p><p id="3e5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">此处使用的不合格指标是误差。</strong></p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="bb39" class="nl me it nh b gy nm nn l no np">data = load_iris()<br/>y = data.target<br/>X = data.data<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=2)<br/>X_calibration, X_test, y_calibration, y_test = train_test_split(X_test, y_test, test_size=0.4, random_state=2)</span><span id="a5de" class="nl me it nh b gy nq nn l no np">estimator = DecisionTreeClassifier(random_state=10)<br/>icp = IcpClassifier(ClassifierNc(ClassifierAdapter(estimator), MarginErrFunc()))<br/>icp.fit(X_train, y_train)<br/>icp.calibrate(X_calibration, y_calibration)<br/>prediction = icp.predict(X_test, 0.1)<br/>classification_calibration_plot(icp, X_test, y_test)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/7997587f7a8fd2fc20460a33c3fb50e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1QJ33U7JpaZL8Rseboxtew.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">分类模型的校准曲线(作者提供照片)</p></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="1307" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated"><strong class="ak">结论</strong></h1><p id="95c3" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">保形预测的好处是所做的预测有统计置信度支持。您可以为分类器和回归器提供不确定性估计值。</p><p id="164b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个框架是一般化的，因此不管你的监督模型如何，你都可以将你的模型转换成一个共形预测器。</p><p id="0612" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章简要介绍了共形预测。训练和校准的方法有许多变体。例如，一些变体减小了预测区间和集合的大小。所使用的符合性和不符合性分数也有许多变体。有些分数甚至包含了预测的难度。</p><p id="d1f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总体保形预测是一个相当简单的过程。但这正是它如此有效的原因。它产生的预测具有可控的不确定性。最重要的是，预测集和区间在统计上是有效的。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="f694" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">如果你有兴趣阅读关于新颖的数据科学工具和理解机器学习算法的文章，可以考虑在Medium上关注我。</em></p><p id="4f22" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你对我的写作感兴趣，想直接支持我，请通过以下链接订阅。这个链接确保我会收到你的会员费的一部分。</p><div class="ns nt gp gr nu nv"><a href="https://zjwarnes.medium.com/membership" rel="noopener follow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">通过我的推荐链接加入Medium-Zachary Warnes</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">阅读扎卡里·沃恩斯(以及媒体上成千上万的其他作家)的每一个故事。您的会员费直接支持…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">zjwarnes.medium.com</p></div></div><div class="oe l"><div class="of l og oh oi oe oj ks nv"/></div></div></a></div></div></div>    
</body>
</html>