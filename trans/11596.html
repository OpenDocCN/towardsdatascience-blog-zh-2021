<html>
<head>
<title>Adversarial Examples to Break Deep Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">打破深度学习模型的反面例子</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/adversarial-examples-to-break-deep-learning-models-e7f543833eae?source=collection_archive---------22-----------------------#2021-11-16">https://towardsdatascience.com/adversarial-examples-to-break-deep-learning-models-e7f543833eae?source=collection_archive---------22-----------------------#2021-11-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9671" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何用一点Python来愚弄一个27M参数的模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/163c9e7fbad0cabc6928df33817df079.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s-klO2r0XAbiNL7tkuesyA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://www.pexels.com/@george-lebada-175028?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">乔治·勒巴达</a>从<a class="ae ky" href="https://www.pexels.com/photo/red-chameleon-567540/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">派克斯</a>拍摄</p></figure><p id="cd8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你以为骗过自动驾驶特斯拉汽车的视觉系统是不可能的吗？</p><p id="7779" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者说恶意软件检测软件中使用的机器学习模型太好了，无法被黑客规避？</p><p id="d8e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者机场的人脸识别系统是防弹的？</p><p id="237e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像我们任何一个机器学习爱好者一样，你可能会陷入这样一个陷阱，认为现有的深度模型是完美的。</p><p id="c387" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">嗯，你错了。</p><p id="8b11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有一些简单的方法可以建立<em class="lv">对抗的例子</em>，可以欺骗任何深度学习模型，并产生安全问题。在本帖中，我们将涵盖以下内容:</p><ol class=""><li id="f581" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">什么是对立的例子？</li><li id="8e54" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">你如何产生对立的例子？</li><li id="3eee" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">动手例子:让我们打破盗梦空间3</li><li id="e208" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">如何保护你的模型免受反面例子的攻击</li></ol><p id="0fa8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">开始吧！</p><h1 id="ae31" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">1.什么是对立的例子？😈</h1><p id="c5ca" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">最近10年，深度学习模型已经离开了学术幼儿园，成为大男孩，并改造了许多行业。对于计算机视觉模型来说尤其如此。当<a class="ae ky" href="https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> AlexNet </strong> </a>在2012年登上排行榜，深度学习时代正式开始。</p><p id="585d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如今，计算机视觉模型与人类视觉一样好，甚至更好。您可以在无数地方找到它们，包括…</p><ul class=""><li id="c838" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu nh mc md me bi translated">无人驾驶汽车</li><li id="fd04" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu nh mc md me bi translated">人脸识别</li><li id="9da1" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu nh mc md me bi translated">医疗诊断</li><li id="192c" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu nh mc md me bi translated">监控系统</li><li id="b20c" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu nh mc md me bi translated">恶意软件检测</li><li id="5287" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu nh mc md me bi">…</li></ul><p id="10ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">直到最近，研究人员还在一个<em class="lv">实验室</em>环境中训练和测试机器学习模型，比如机器学习竞赛和学术论文。如今，当部署到现实场景中时，来自模型错误的安全漏洞已经成为一个真正的问题。</p><p id="2aa6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">想象一下，你的自动驾驶汽车的最先进的超级花哨的深度学习视觉系统无法将<a class="ae ky" href="https://spectrum.ieee.org/cars-that-think/transportation/sensors/slight-street-sign-modifications-can-fool-machine-learning-algorithms" rel="noopener ugc nofollow" target="_blank">这个停车标志</a>识别为停车标志。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/fae363b516ee91d440c573d377e1c389.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*6Ruip8Au-rP0k1GfIF4LkA.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://arxiv.org/abs/1707.08945" rel="noopener ugc nofollow" target="_blank">对深度学习视觉分类的强大物理世界攻击</a>eyk Holt et altri。</p></figure><p id="e597" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">嗯，<a class="ae ky" href="https://spectrum.ieee.org/cars-that-think/transportation/sensors/slight-street-sign-modifications-can-fool-machine-learning-algorithms" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">这是</strong> <strong class="lb iu">到底是</strong> <strong class="lb iu">发生了什么事情</strong> </a>。这个停车标志图像是一个<em class="lv">反面例子</em>。就当是模型的视错觉吧。</p><p id="0e65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看另一个例子。下面你有两张狗的图片，人眼无法分辨。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/f2e66fd1f11ddb233fb97a7c5d17e4c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CUK-RuWDm4V5hWV7VVeBBw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">敌对的小狗(图片由作者提供)</p></figure><p id="f8ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">左边的图片是Dominika rose clay<a class="ae ky" href="https://www.pexels.com/photo/soft-focus-photo-of-dachshund-895259/" rel="noopener ugc nofollow" target="_blank">拍摄的一只小狗的原始照片。右边的是对第一个的一点修改，我在中间的图像中添加了噪声向量。</a></p><p id="9fbb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Inception v3正确地将原始图像分类为狗的品种(红骨头)。然而，同一个模型非常自信地认为，我创建的修改图像是一张纸巾。</p><p id="0ef5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">换句话说，我创造了一个对立的例子。您也会看到，因为这是我们将在第3节后面讨论的示例。</p><blockquote class="nk nl nm"><p id="0b7f" class="kz la lv lb b lc ld ju le lf lg jx lh nn lj lk ll no ln lo lp np lr ls lt lu im bi translated">计算机视觉模型的一个<strong class="lb iu">对抗示例</strong>是具有人眼察觉不到的小扰动的输入图像，这导致错误的模型预测。</p></blockquote><p id="327b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不要认为这两个例子是在花费大量时间和计算资源后发现的罕见的边缘例子。有很容易的方法来生成对立的例子，这为生产中的机器学习系统的严重漏洞打开了大门。</p><p id="a427" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看如何生成一个对立的例子，并愚弄一个最先进的图像分类模型。</p><h1 id="9e72" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">2.如何生成对抗性的例子？</h1><p id="cc21" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">对立的例子😈是通过拍摄清晰的图像产生的👼该模型正确分类，并找到导致新图像被ML模型错误分类的小扰动。</p><h2 id="d315" class="nq ml it bd mm nr ns dn mq nt nu dp mu li nv nw mw lm nx ny my lq nz oa na ob bi translated">白盒场景</h2><p id="019c" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">让我们假设您有关于您想要愚弄的模型的完整信息。在这种情况下，您可以计算模型的损失函数</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/cd8da409488608b73f707cffb0d7a461.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*QEZer9MZLj2MiI8WwQMzmg.png"/></div></figure><p id="03ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在哪里</p><ul class=""><li id="34d8" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu nh mc md me bi translated"><em class="lv"> X </em>是输入图像</li><li id="ab48" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu nh mc md me bi translated"><em class="lv"> y </em>是输出类，</li><li id="7dd5" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu nh mc md me bi translated">并且<em class="lv"> θ </em>是网络参数的向量。</li></ul><p id="b384" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该损失函数通常是分类方法的负对数似然。</p><p id="87aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你的目标是找到一个新的图像<strong class="lb iu"><em class="lv">X’</em></strong>，它接近原始的<strong class="lb iu"> <em class="lv"> X </em> </strong>并且在损失函数值上产生一个大的变化。</p><p id="0176" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">想象你在所有可能的输入图像的空间里，坐在原始图像的上面。这个空间有尺寸<em class="lv">宽x高x通道</em>，所以如果你不能很好地想象它，我会原谅你😜。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/1c592250ec025578a87ca19e2e41a848.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hTb5tIlZrYF4j5hBgMygqw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">行走在输入图像空间(图片由作者提供)</p></figure><p id="1078" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了找到一个对立的例子，你需要在这个空间中向某个方向走一点，直到你找到另一个损失显著不同的图像<strong class="lb iu">X’</strong>。对于固定的小步长<strong class="lb iu">ε</strong>，你要选择使损失函数<strong class="lb iu">T3【JT5】变化最大的方向。</strong></p><p id="f060" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，如果你稍微复习一下你的数学微积分课程，损失函数在<em class="lv"> X </em>空间中变化最大的方向就是<em class="lv"> J </em>相对于<em class="lv"> X </em>的梯度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/3fcc382d54d94f03d702ac118ce9600a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*Tssj7pC-8n13pkQpBd1nsA.png"/></div></figure><p id="4745" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个函数相对于它的一个变量的梯度恰好是最大变化的方向。顺便说一下，这就是为什么人们用随机梯度下降法而不是随机方向下降法来训练神经网络。</p><h2 id="2d5e" class="nq ml it bd mm nr ns dn mq nt nu dp mu li nv nw mw lm nx ny my lq nz oa na ob bi translated">快速梯度符号法</h2><p id="4fd4" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">形式化这种直觉的一种简单方法如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/cd7c59a806465276eb3962236f4e71a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*KjhWovCfFL5oVAwWNXmTjw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">快速梯度符号法</p></figure><p id="940b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们仅采用梯度的符号，并使用小参数ε对其进行缩放，以保证<em class="lv"> X </em>和<em class="lv"> X </em>之间的失真小到人眼察觉不到。这种方法被称为<strong class="lb iu">快速梯度符号法</strong>。</p><h1 id="307f" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">黑盒攻击</h1><p id="7458" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">在大多数情况下，您很可能没有关于模型的完整信息。因此，前面的方法是没有用的，因为你不能计算梯度。</p><p id="4a3f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，有一个显著的属性叫做对立例子的<em class="lv">可转移性</em>，恶意代理可以利用它来破坏一个模型，即使他们不知道它的内部架构和参数。</p><blockquote class="nk nl nm"><p id="e021" class="kz la lv lb b lc ld ju le lf lg jx lh nn lj lk ll no ln lo lp np lr ls lt lu im bi translated">研究人员反复观察到<strong class="lb iu">对立的例子在模型之间转移</strong>相当好，这意味着它们可以为目标模型A设计，但最终对在类似数据集上训练的任何其他模型都有效。</p></blockquote><p id="1149" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对立的例子可以如下产生:</p><ol class=""><li id="8077" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">对于i = 1 … n，用输入X_i查询目标模型，并存储输出y_i。</li><li id="6a27" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">使用训练数据(X_i，y_i)建立另一个模型，称为<em class="lv">替代模型。</em></li><li id="023b" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">使用白盒算法，如快速梯度符号，为替代模型生成对立的示例。他们中的许多人将成功地转移，并成为目标模式的反面例子。</li></ol><p id="ba2c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<a class="ae ky" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Arjun_Nitin_Bhagoji_Practical_Black-box_Attacks_ECCV_2018_paper.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">这篇计算机视觉基础论文</strong> </a> <strong class="lb iu">中介绍了这种策略在一个商业机器学习模型中的成功应用。</strong></p><h1 id="27fe" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">3.动手例子:让我们打破盗梦空间3</h1><p id="1a73" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">让我们动手使用Python和伟大的PyTorch库实现一些攻击。知道攻击者的想法总是很方便的。</p><p id="6eb1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在<a class="ae ky" href="https://github.com/Paulescu/adversarial-machine-learning" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">这个Github回购</strong> </a> <strong class="lb iu">中找到完整的代码。</strong></p><p id="530c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的目标模型将是Inception V3，这是一个由谷歌开发的强大的图像分类模型，它有大约2700万个参数，并在属于20000个类别的大约1400万张图像上进行训练。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="2c01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们下载模型被训练的类的列表，并构建一个将类id映射到标签的辅助字典。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="2950" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们以一只无辜的红骨狗的图像作为开始的图像，我们将仔细地修改它以构建对立的例子:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/f1627a342a269837352d746cd2e09ccf.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*s5lVGuWdwbsGqv-RFqmYmA.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://www.pexels.com/photo/soft-focus-photo-of-dachshund-895259/" rel="noopener ugc nofollow" target="_blank">照片由Pexels的Dominika Roseclay拍摄</a></p></figure><p id="b2b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Inception V3期望图像的尺寸为299 x 299，归一化像素范围在-1和1之间。</p><p id="ebaa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们预处理一下我们漂亮的狗狗形象:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="51d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并检查该模型是否正确地对该图像进行了分类。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="27da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">很好。模型按预期工作，并且<em class="lv">红骨</em>狗被归类为<em class="lv">红骨</em>狗:-)。</p><p id="1445" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们转到有趣的部分，用快速梯度符号法产生对立的例子。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="6dbd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我已经创建了一个辅助函数来<em class="lv">可视化</em>原始图像和敌对图像。你可以在这个<a class="ae ky" href="https://github.com/Paulescu/adversarial-machine-learning/blob/main/adversarial_example_generation.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> GitHub库</strong> </a>中看到完整的实现。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/817a3753f363cc6e616f2cbfdb76ab2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hYpK6ip91BxUrQDSHyK9Cg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们第一次尝试愚弄概念3(图片由作者提供)</p></figure><p id="3daf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好吧。有趣的是，新图像的模型预测是如何变化的，这与原始图像几乎无法区分。新预测的是一只<em class="lv">寻血犬</em>，是另一个肤色非常相似、耳朵很大的犬种。由于有问题的小狗可能是混种，模型错误似乎很小，所以我们想进一步工作，真正打破这个模型。</p><p id="2e0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一种可能性是尝试不同的T21值，并试图找到一个明显给出错误预测的值。让我们试试这个。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/4164adcb0d3c57de27a536b77a3f1f31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DD8szjyMUOgJI3kRwkKLlQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们第二次试图愚弄盗梦空间3(图片由作者提供)</p></figure><p id="40d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着ε增加，图像中的变化变得可见。不过模型预测的还是其他犬种:<em class="lv"> bloodhound </em>和<em class="lv"> basset </em>。我们需要比这更聪明来打破这个模式。</p><p id="ae37" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">记住快速梯度符号方法背后的直觉，即想象自己在所有可能图像的空间内(尺寸为299 x 299 x 3)，就在原始图像X所在的位置。损失函数的梯度告诉您需要增加其值的方向，并使模型对正确的预测不太确定。步长为ε。你走一步，检查你现在是否坐在一个对立的例子上。</p><p id="d9fc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法的延伸是采取许多更小的步骤，而不是一步到位。每走一步，你都要重新评估坡度，决定你要走的新方向</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/233d3499d773f5ff4eefc91d295d3ba8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TUcayPgP2BP6zWOYHMtzrA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">迭代快速梯度符号法(图片由作者提供)</p></figure><p id="7dd7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法称为迭代快速梯度法。多么原始的名字！</p><p id="6d61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更正式地说:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/fb0638f6873d31a4a5acd98809549a50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tFOwEg78xsDgGt1jnH3fgA.png"/></div></div></figure><p id="e642" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中<em class="lv"> X0 = X </em>，而<em class="lv">削波X,ϵ </em>表示在【x+ϵ].x−ϵ】范围内对输入的削波</p><p id="c2a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PyTorch中的一个实现如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="48b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们再次尝试从我们无辜的小狗开始，创造一个好的反面例子。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="3cf0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一步:又是猎犬</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/ddf01dbd78115f738c352550dcc1d8e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*M_0wavCy4gMurpTS.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">第一步(作者图片)</p></figure><p id="f596" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">再次比格犬</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/484546f92e71df91fb929bc752d4403f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Gyd3OmQXKQ5s1-0u.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">第二步(作者图片)</p></figure><p id="1851" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第三步:捕鼠器？有意思。然而，该预测的模型置信度仅为16%。让我们更进一步。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/7aaba84678cbc1e51a569c623f7da48b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yeegReGZF55sMUy6.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">第三步(作者图片)</p></figure><p id="8551" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第四步:多一个犬种，无聊…</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/a5c3e93cae174324821f5b94fb6f52f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pSnOVybnggxK18-f.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">第四步(作者图片)</p></figure><p id="3d49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第五步:再次比格犬..</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/95c1c868486e0e3c6743b2079f440791.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oYCkJQkCMwX5-Oj0.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">第五步(作者图片)</p></figure><p id="4a6a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第六步:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/acb0560309548e784c4df299d00cc6af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GVnrPi09qxzDeFsT.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">第六步(作者图片)</p></figure><p id="f14e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第七步:再次红骨。<em class="lv">保持冷静，继续在影像空间中行走。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/344d5d60429a8389203cebf569372d3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eIA0vajnM5wbGdF2.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">第七步(作者图片)</p></figure><p id="9422" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第八步:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/9f784ccfcf2340fed15d90628757895a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DMMPQiH-N5CztFZu.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">第八步(作者图片)</p></figure><p id="c644" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第九步:宾果！🔥🔥🔥</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/2cba81a46d0ccb9c336cded271fbed3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dHSzZXC4keP5g148.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">第九步(作者图片)</p></figure><p id="4eae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">多么奇特的纸巾啊。这个模型对它的预测相当有信心，几乎有99%。</p><p id="763a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您比较我们在步骤9中找到的初始图像和最终图像</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/f2e66fd1f11ddb233fb97a7c5d17e4c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CUK-RuWDm4V5hWV7VVeBBw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">第九步(作者图片)</p></figure><p id="4920" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以看到它们本质上是一样的，一只<em class="lv">小狗</em>，但是对于Inception V3模型来说，它们是两个非常不同的东西。</p><p id="3671" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我第一次看到这样的东西，非常惊讶。对图像的微小修改会导致这样的模型错误行为。这个例子很有趣，但如果你想到自动驾驶汽车愿景的含义，你可能会开始有点担心。</p><p id="598c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">部署在关键任务中的深度学习模型需要正确处理对立的例子，但如何处理呢？</p><h1 id="b52b" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">4.如何为你的模型辩护对抗的例子？</h1><p id="3564" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">截至2021年11月，没有一个通用的防御策略可以让你抵御敌对的例子。换句话说，用对立的例子攻击一个模型比保护它更容易。</p><p id="688d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以抵御任何已知攻击的最佳通用策略是在训练模型时使用对立的示例。</p><p id="d840" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果模型<em class="lv">在训练过程中看到</em>的对立实例，那么对于以相同方式生成的对立实例，其在预测时的性能会更好。这种技术被称为<strong class="lb iu">对抗训练</strong>。</p><p id="c233" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以在训练模型时动态生成它们，并调整损失函数以查看干净的和敌对的输入。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/12c14858058647e14242d76a9b7a70fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zob43Qw87LxJFadqJ2EeIw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用对抗训练时的损失函数(图片由作者提供)</p></figure><p id="2992" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，如果我们将10+个例子添加到训练集中，并将它们都标记为<em class="lv"> redbone </em>，我们可以消除在上一节中发现的对立例子。</p><p id="481b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种防御对于使用快速梯度符号方法的攻击非常有效。然而，还有更强大的攻击，我们在这篇文章中没有提到，可以绕过这种防御。如果你想知道更多，我鼓励你读一读尼古拉斯·卡里尼和戴维·瓦格纳写的这篇令人惊叹的论文<a class="ae ky" href="https://arxiv.org/abs/1608.04644" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"/></a>。</p><p id="bacd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是为什么对抗性防御是机器学习和网络安全中的一个公开问题的原因。</p><h1 id="50b9" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">结论</h1><p id="72c1" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">对抗性的例子是网络安全和机器学习交汇处的一个有趣的话题。然而，这仍然是一个有待解决的开放性问题。</p><p id="2fc5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我用代码示例对这个主题进行了实际介绍。如果你想进一步工作，我推荐<a class="ae ky" href="https://github.com/cleverhans-lab/cleverhans" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> cleverhans </strong> </a>，这是一个由伟大的Ian Goodfellow和Nicolas Papernot开发的用于对抗性机器学习的Python库，目前由多伦多大学<a class="ae ky" href="https://cleverhans-lab.github.io/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"/></a>维护。</p><p id="cbd7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文中我展示的所有源代码都在<a class="ae ky" href="https://github.com/Paulescu/adversarial-machine-learning" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">这个Github repo </strong> </a>中。</p><div class="on oo gp gr op oq"><a href="https://github.com/Paulescu/adversarial-machine-learning" rel="noopener  ugc nofollow" target="_blank"><div class="or ab fo"><div class="os ab ot cl cj ou"><h2 class="bd iu gy z fp ov fr fs ow fu fw is bi translated">GitHub-Paulescu/adversarial-machine-learning:我关于“打破…</h2><div class="ox l"><h3 class="bd b gy z fp ov fr fs ow fu fw dk translated">“也可能只是美好的东西太容易被世界打破了。”卡桑德拉·克莱尔，堕落天使之城…</h3></div><div class="oy l"><p class="bd b dl z fp ov fr fs ow fu fw dk translated">github.com</p></div></div><div class="oz l"><div class="pa l pb pc pd oz pe ks oq"/></div></div></a></div><p id="214c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">你想成为(甚至)更好的数据科学家，接触机器学习和数据科学的顶级课程吗？</em></p><p id="647c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">👉🏽订阅<a class="ae ky" href="https://datamachines.xyz/subscribe/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="lv">数据机</em>通迅</strong> </a> <strong class="lb iu">。</strong></p><p id="fb26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">👉🏽给我很多掌声👏🏿👏🏽👏在下面</p><p id="564d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">👉🏽<a class="ae ky" href="https://medium.com/@pau-labarta-bajo" rel="noopener"> <strong class="lb iu">跟着我</strong> </a>上媒。</p><p id="df2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">祝你愉快，🧡</p><p id="8526" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">避寒胜地</p></div></div>    
</body>
</html>