<html>
<head>
<title>Feedback Alignment Methods</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">反馈校准方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/feedback-alignment-methods-7e6c41446e36?source=collection_archive---------14-----------------------#2021-09-16">https://towardsdatascience.com/feedback-alignment-methods-7e6c41446e36?source=collection_archive---------14-----------------------#2021-09-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="53c8" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><div class=""><h2 id="3ad5" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">生物驱动的反向传播替代方案</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/a27bf3b7ad5e8f47db2fc50b5cd414c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*n5oZsi4d0HC2m2lw"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@averey?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Robina Weermeijer </a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="6f9b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">反向传播的简单、高效、高精度和收敛速度，使其成为训练神经网络的实际算法。然而，有证据表明，这种算法不能由人脑在生物学上实现[1]。其中一个主要原因是反向传播需要前向和后向路径中的突触对称。由于突触在大脑中是单向的，前馈和反馈连接在物理上必须是不同的。这就是所谓的重量运输问题。</p><p id="1f4a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了克服这一限制，最近对学习算法的研究通过研究更具生物学意义的算法，专注于神经科学和机器学习之间的交叉。其中一个主要的方法被称为反馈校准，它采用不同的前向和反馈突触权重。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi mb"><img src="../Images/be057b855a541069b63b348189f64355.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UHbS3udkU_NQatoDDUYMOg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">不同学习算法的比较:反向传播、FA和DFA——作者图片</p></figure><p id="8fe0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">除了提供更具生物合理性的训练方案之外，已经表明对齐方法可以提高深度学习模型对抗敌对攻击的鲁棒性。最后，对反馈对准的额外兴趣还受到它们允许前向和反馈权重在专用集成电路(ASICs)中本地存在的能力的驱动，这最终允许节省时间和能量。</p><p id="0a24" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这篇文章中，我将描述主要的反馈校准方法，并展示一个比较它们的准确性和鲁棒性与反向传播的基准。</p><h1 id="f674" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">反馈校准方法介绍</h1><h2 id="7ac6" class="mu md iq bd me mv mw dn mi mx my dp mm lo mz na mo ls nb nc mq lw nd ne ms iw bi translated">反向传播在生物学上是不合理的</h2><p id="2ca2" class="pw-post-body-paragraph lf lg iq lh b li nf ka lk ll ng kd ln lo nh lq lr ls ni lu lv lw nj ly lz ma ij bi translated">使用反向传播的N层神经网络的训练在前向传递和后向传递之间交替，前向传递用于执行推理和计算误差信号，后向传递用于发送误差信号和更新权重。</p><p id="52be" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们可以观察下面的权重更新规则:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nl"><img src="../Images/1c7ccf0c282b7300b1e4ac53a62d65d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a0xUqNKoXzR2DSu_0VTbow.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">反向传播权重更新规则</p></figure><p id="eb01" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">层<em class="nk"> i </em>的权重更新需要前向权重矩阵<em class="nk"> W_(i+1)的知识。</em>那个<em class="nk"> </em>在生物学上是不可信的，因为它要求神经元互相发送大量的突触权重来执行反向传递。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nm"><img src="../Images/81d8bc8934c43875024d6eecbbad407d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Pf1u0D6z3R9OdJn_"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">重量运输问题——图片由<a class="ae le" href="https://unsplash.com/@carrier_lost?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">伊恩·泰勒</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h2 id="956a" class="mu md iq bd me mv mw dn mi mx my dp mm lo mz na mo ls nb nc mq lw nd ne ms iw bi translated">反馈校准算法避免了重量转移问题</h2><p id="d3af" class="pw-post-body-paragraph lf lg iq lh b li nf ka lk ll ng kd ln lo nh lq lr ls ni lu lv lw nj ly lz ma ij bi translated">反馈对准算法提出在后向传递中替换前向权重矩阵<em class="nk"> W </em>信息，消除了传输权重的需要。不同方法之间的差异包括如何计算后向传递以及如何构建后向权重矩阵<em class="nk"> B </em>。</p><p id="abb8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">反馈校准(FA): </strong>权重更新的计算方式与反向传播相同，但反向权重矩阵是随机矩阵[2]。将<em class="nk"> B </em>初始化为与<em class="nk"> W </em>具有相同的分布和数量级有助于提高网络训练的收敛性。下面的公式描述了FA的权重更新规则:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nn"><img src="../Images/4f536525aedda589e87c0ac31d09efb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pmvQDIQQ7Dwf8-F0RCzjMw.png"/></div></div></figure><p id="fab8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">一致符号一致反馈(uSF): </strong>这种权重更新方法类似于FA，但是它通过假设单位幅度的突触权重来传输前向矩阵的符号[3]。因此，<em class="nk"> B </em>矩阵为:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi no"><img src="../Images/e44493e31caa6cc86a15aa6089d0ff96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4tjI5pZA321qbmJhGqyezQ.png"/></div></div></figure><p id="cef8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">分批随机幅度符号一致反馈(brSF): </strong>该方法不是为第<em class="nk"> i </em>层的后向权重假设一个单位幅度，而是在每次更新后重新绘制它们的幅度|<em class="nk">R _ I</em>|,使得:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi no"><img src="../Images/047760ebf7cffc500a842d4ea5f67a60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4WsbSO7EhQvEQaFNpKDkUA.png"/></div></div></figure><p id="ff86" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">固定随机幅度符号一致反馈(frSF): </strong>这是brSF方法的变体，其中权重的幅度|<em class="nk">R _ I</em>|不是在每次更新后重新绘制，而是在训练开始时固定和初始化。</p><p id="fe3d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">直接反馈校准(DFA) </strong>:虽然FA中的权重更新是跨层递归计算的，但是可以通过直接将最后一层的损耗导数<em class="nk"> 𝛿z_N </em>向后推至所有层来预测误差传播【4】。这将导致以下更新:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi np"><img src="../Images/7f9d347029c6a18e0bd8fe560c843619.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9bznchlK59xwvkYDkinDUg.png"/></div></div></figure><p id="13d5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">其中<em class="nk"> B_i </em>是一个适当形状的固定随机矩阵(即<em class="nk"> layer_i </em>的输入维数×<em class="nk">layer _ N</em>的输出维数)。</p><h1 id="a2cf" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">算法基准</h1><p id="ed0b" class="pw-post-body-paragraph lf lg iq lh b li nf ka lk ll ng kd ln lo nh lq lr ls ni lu lv lw nj ly lz ma ij bi translated">在本节中，我将解释在<em class="nk">反馈校准算法</em>【5】的准确性和鲁棒性基准测试中进行的实验。我们使用了<a class="ae le" href="https://github.com/jsalbert/biotorch" rel="noopener ugc nofollow" target="_blank"> <em class="nk"> BioTorch </em> </a>开源框架来进行基准测试。</p><p id="034e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们使用Xavier uniform初始化我们的层的前向和后向权重，W和T2。使用这种方差保持初始化允许我们将权重保持在相同的数量级，并且改进了不对称条件下的训练。对于uSF方法，我们通过Xavier初始化的标准偏差来缩放权重的符号。</p><p id="8166" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们的实验表明，根据优化器的选择，模型的分类准确性存在显著差异，特别是对于FA和DFA，即使在调整了它们各自的学习速率之后。为此，我们展示了SGD和Adam优化器的实验结果。</p><h2 id="5c89" class="mu md iq bd me mv mw dn mi mx my dp mm lo mz na mo ls nb nc mq lw nd ne ms iw bi translated"><strong class="ak"> MNIST &amp;时尚MNIST </strong></h2><p id="5279" class="pw-post-body-paragraph lf lg iq lh b li nf ka lk ll ng kd ln lo nh lq lr ls ni lu lv lw nj ly lz ma ij bi translated">我们通过在MNIST和时尚MNIST数据集上对LeNet的所有对齐方法进行基准测试来开始我们的实证研究。用设置动量为0.9的SGD优化器和10^(−3).的权重衰减来训练网络我们训练了100个时期，在第50个和第75个时期将初始学习率降低了2倍。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nq"><img src="../Images/59fe2a398f5b45778c2863da325f7b65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kA6nDpWJ-5ZSE0ESsJN7oQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">MNIST和时尚MNIST LeNET网络的最大错误率(%)</p></figure><p id="3e37" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们观察到FA和DFA的性能接近BP，并且符号一致性方法在MNIST上匹配BP性能。如果我们增加数据集的难度(时尚MNIST)，反向传播和其他方法之间的性能差距，特别是那些不使用符号一致反馈的方法，也会增加。</p><h2 id="1e29" class="mu md iq bd me mv mw dn mi mx my dp mm lo mz na mo ls nb nc mq lw nd ne ms iw bi translated">CIFAR-10</h2><p id="8807" class="pw-post-body-paragraph lf lg iq lh b li nf ka lk ll ng kd ln lo nh lq lr ls ni lu lv lw nj ly lz ma ij bi translated">为了将对齐方法的应用扩展到更深层次的架构和更具挑战性的任务，我们在CIFAR-10中对ResNet-20和ResNet-56进行了基准测试。使用SGD优化器的网络以0.9的动量和10^(−4的权重衰减来训练)。使用Adam的网络用相同的权重衰减和等于[0.9，0.999]的betas参数来训练。我们以128的批量进行250个时期的训练，在第100、150和200个时期将初始学习率降低10倍。我们使用网格搜索来选择每种方法的最佳学习率。</p><p id="9639" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在FA和DFA方法的两种网络配置中，Adam使用的自适应参数独立优化器都优于SGD，如下所示。这些方法是反向通道中的不对称性较大的方法。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nr"><img src="../Images/0ce7497aae66856adc298774d7b66396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SigXx-idAJmMy1JZSVzypQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">使用SGD和Adam训练的每个方法的ResNet-20和ResNet-56的CIFAR-10中的前1名错误(%)</p></figure><p id="3aa4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Adam带来的显著改进是可以预期的，因为它保持了基于从RMSProp继承的梯度的二阶矩的平均值而调整的每个参数的学习率。因此，它在噪声梯度下产生更好的性能。为了证实这一观察，我们为SGD和Adam优化器绘制了DFA方法的后向-前向范数权重比。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ns"><img src="../Images/a8f7ebfdb3625373c047684705024642.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fh7Ny0tOeKnYMS6yTsypKA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">在CIFAR-10上为SGD和Adam训练ResNet56时，方法FA和DFA的权重比</p></figure><p id="879d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">可以观察到，SGD已经驱动网络的第一层的范数权重比非常接近0，这意味着前向权重矩阵<em class="nk"> W_i </em>被更新以达到比后向权重矩阵<em class="nk"> B_i </em>中的值大得多的值。这是由于在DFA方法中误差从最后一层到每一层的直接误差投影，从而避开了使用链规则计算的梯度的小范数。</p><p id="cc2e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">同样的观察结果不适用于FA方法，其中第一层的权重范数比不为零，如下所示。然而，我们看到，与SGD相比，Adam实现了更小的前后重量排列角度。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nt"><img src="../Images/a9ba737c60fd25b873e9afd30d019152.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q_IbBJd5mhveAB3W-I2o8w.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">用带SGD (a)和Adam (b)的FA训练的ResNet-20的矩阵排列(左)和重量比(右)</p></figure><h2 id="c23a" class="mu md iq bd me mv mw dn mi mx my dp mm lo mz na mo ls nb nc mq lw nd ne ms iw bi translated">ImageNet</h2><p id="3913" class="pw-post-body-paragraph lf lg iq lh b li nf ka lk ll ng kd ln lo nh lq lr ls ni lu lv lw nj ly lz ma ij bi translated">最后，我们在ImageNet上对所有训练ResNet-18网络的方法进行了基准测试。我们使用256的批量大小，并使用初始学习率为0.1的SGD训练75个时期。调度器在第20、40和60个时期将学习速率降低10倍。我们使用10^(−4的重量衰减)和0.9的动量。对于DFA，我们使用初始学习率为0.001的Adam。我们的结果可以在下图中看到:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nu"><img src="../Images/4f45ee2b54dfd5be18636ec4758b4987.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ekoVfXhgt16MN41JpfIeow.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">用所有反馈校准方法训练的ResNet-18网络的前1名ImageNet验证误差(%)</p></figure><p id="90ae" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们可以观察到，就性能而言，没有一种比对方法可以与反向传播相比。虽然符号一致反馈方法在精度上更接近，但是仍然有小的差距。对于FA和DFA方法，差距要大得多，这意味着在训练过程中反馈权重不能与反向权重对齐。</p><h1 id="aa93" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">结论</h1><p id="62d7" class="pw-post-body-paragraph lf lg iq lh b li nf ka lk ll ng kd ln lo nh lq lr ls ni lu lv lw nj ly lz ma ij bi translated">反馈比对算法是一种比反向传播更具生物合理性的替代方法，因为它们避免了重量转移问题。在整个基准测试中，我们已经看到，尽管它们的性能与MNIST和CIFAR-10相当，但它们无法扩展到ImageNet之类的困难任务。然而，在使用ASICs的应用中，它们的应用可以有助于降低成本，因为反馈和反向权重是独立的。此外，这些方法的研究仍然很重要，因为在神经科学的帮助下，有助于我们揭示和了解更多关于人类大脑学习过程的信息。</p><p id="734b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">感谢阅读，希望你喜欢这篇文章，并学到一些新东西！</strong></p><h1 id="c24d" class="mc md iq bd me mf mg mh mi mj mk ml mm kf mn kg mo ki mp kj mq kl mr km ms mt bi translated">参考</h1><p id="b9c8" class="pw-post-body-paragraph lf lg iq lh b li nf ka lk ll ng kd ln lo nh lq lr ls ni lu lv lw nj ly lz ma ij bi translated">[1]蒂莫西·P·莉莉卡普、亚当·桑托罗、卢克·马里斯、科林·J·阿克曼和杰弗里·辛顿，<a class="ae le" href="https://www.nature.com/articles/s41583-020-0277-3" rel="noopener ugc nofollow" target="_blank">反向传播和大脑</a> (2020年)，《自然评论神经科学》。</p><p id="19f2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[2] Timothy P Lillicrap，Daniel Cownden，Douglas B Tweed和Colin J Akerman，<a class="ae le" href="https://www.nature.com/articles/ncomms13276" rel="noopener ugc nofollow" target="_blank">随机突触反馈权重支持深度学习的误差反向传播</a> (2016)，自然通讯。</p><p id="b3b3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[3]李倩·廖、乔尔·雷博和托马索·波吉奥，<a class="ae le" href="https://arxiv.org/abs/1510.05067" rel="noopener ugc nofollow" target="_blank">权重对称在反向传播中有多重要？</a> (2016)，《AAAI人工智能会议论文集》。</p><p id="00dc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[4]Arild nkland，<a class="ae le" href="https://arxiv.org/pdf/1609.01596.pdf" rel="noopener ugc nofollow" target="_blank">直接反馈对齐提供深度神经网络中的学习</a> (2016)，神经信息处理系统。</p><p id="cc0c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[5] Sanfiz，Albert Jiménez和Mohamed Akrout，<a class="ae le" href="https://arxiv.org/pdf/2108.13446.pdf" rel="noopener ugc nofollow" target="_blank">对反馈对齐算法的准确性和鲁棒性进行基准测试</a> (2021)，<em class="nk"> arXiv预印本arXiv:2108.13446 </em>。</p></div></div>    
</body>
</html>