<html>
<head>
<title>Stepping into the magical world of GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">走进甘斯的神奇世界</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/stepping-into-the-magical-words-of-gan-f16d3e8e8fe0?source=collection_archive---------16-----------------------#2021-04-29">https://towardsdatascience.com/stepping-into-the-magical-words-of-gan-f16d3e8e8fe0?source=collection_archive---------16-----------------------#2021-04-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="081b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">甘的一步一步教程</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a7fb0420a030c2fad8c4de50a70094f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NaHG_JzAK4mjFeob"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/photos/6dN9l-gopyo" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/6dN9l-gopyo</a></p></figure><p id="802c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di">一个</span>生成模型有潜在的魔力，如果训练得当，它可以像专家一样写诗、创作音乐、绘制图像。GAN的目标是生成非常逼真的合成样本。甘模型在对抗环境中学习技巧。有两个多层神经网络，一个作为发生器，另一个作为其对手，称为鉴别器。两者都使用常规反向传播方法训练，尽管具有不同的和冲突的损失函数(对抗性设置)。<strong class="ky ir">一旦训练完成，鉴频器被移除，生成器被用于产生样本。</strong></p><p id="5a15" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图对此进行了说明。这里的任务是能够创建像MNIST手写数字。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mb"><img src="../Images/872d3bcd904ca1affa9cdf94d0b30df4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q488WN--5xS8f2BmfTF6Tg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图1a:GAN的训练阶段(图片来源:作者)</p></figure><p id="6ae5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该图有两个神经网络，第一个是生成器，第二个是鉴别器。</p><p id="2999" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">生成器将随机噪声向量作为输入，并生成与真实数据维数相同的图像。为什么用噪声作为输入？这确保了生成器不会产生真实数据中已有数据的副本。</p><p id="a782" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">鉴别器是一个进行二元分类的简单分类器。来自生成器的类“0”或假类，以及来自真实图像的类“1”，在本例中为MNIST。</p><blockquote class="mc md me"><p id="b7a4" class="kw kx mf ky b kz la jr lb lc ld ju le mg lg lh li mh lk ll lm mi lo lp lq lr ij bi translated">鉴别器使用交叉熵的常规损失函数，而生成器训练通过鉴别器，保持其权重恒定(否则收敛将像移动目标一样),并且这里损失函数测量具有1类概率的伪图像。这就是冲突的来源。鉴别器希望真实类被分类为真实类，假类被分类为假类，生成器希望假类被分类为真实类。</p></blockquote><p id="1214" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦训练完成，鉴别器可以丢弃，生成器可以用来产生真实的样本，如下图所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/d8d30fb35fc7d1f3316c80bf73b5f92c.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*NPBzyYDyx8UbsGWlghoHcA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图1b:氮化镓的生成阶段</p></figure><p id="c2dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在是实现部分，编码是根据Jason Brownlee的博客完成的。</p><p id="867f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">步骤1:定义生成器</strong></p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="d086" class="mp mq iq ml b gy mr ms l mt mu">def define_generator(latent_dim):<br/>	model = Sequential()<br/>	<em class="mf"># foundation for 7x7 image</em><br/>	n_nodes = 128 * 7 * 7<br/>	model.add(Dense(n_nodes, input_dim=latent_dim))<br/>	model.add(LeakyReLU(alpha=0.2))<br/>	model.add(Reshape((7, 7, 128)))<br/>	<em class="mf"># upsample to 14x14</em><br/>	model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))<br/>	model.add(LeakyReLU(alpha=0.2))<br/>	<em class="mf"># upsample to 28x28</em><br/>	model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))<br/>	model.add(LeakyReLU(alpha=0.2))<br/>	model.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))<br/>	return model</span></pre><p id="287c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">生成器将噪声向量作为输入，并生成28 X 28的图像。下面是测试生成器的代码</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="7f32" class="mp mq iq ml b gy mr ms l mt mu">noise = tf.random.normal([1, 100])<br/>generator = define_generator(100)<br/>generated_image = generator(noise, training=False)<br/>plt.imshow(generated_image[0, :, :, 0], cmap='gray')</span></pre><p id="85e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">生成的图像如下</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/05b40f68ebfb8bb3df4402dd265692c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/0*d6LnYnPl12ZG8S6Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图2:产生的随机噪声(图片来源:作者)</p></figure><p id="43d2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">步骤2:定义鉴别器模型</strong></p><p id="ca34" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是一个简单的二元分类网络。</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="62bf" class="mp mq iq ml b gy mr ms l mt mu">def define_discriminator(in_shape=(28,28,1)):<br/>	model = Sequential()<br/>	model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))<br/>	model.add(LeakyReLU(alpha=0.2))<br/>	model.add(Dropout(0.4))<br/>	model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))<br/>	model.add(LeakyReLU(alpha=0.2))<br/>	model.add(Dropout(0.4))<br/>	model.add(Flatten())<br/>	model.add(Dense(1, activation='sigmoid'))<br/>	<em class="mf"># compile model</em><br/>	opt = Adam(lr=0.0002, beta_1=0.5)<br/>	model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])<br/>	return model</span></pre><p id="f767" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">步骤3:创建组合模型</strong></p><p id="dfdc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里的目的是训练发生器模型，鉴别器权重不会改变或者不可训练。</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="c708" class="mp mq iq ml b gy mr ms l mt mu">def define_gan(g_model, d_model):<br/>	<em class="mf"># make weights in the discriminator not trainable</em><br/>	<strong class="ml ir">d_model.trainable = False</strong><br/>	<em class="mf"># connect them</em><br/>	model = Sequential()<br/>	<em class="mf"># add generator</em><br/>	model.add(g_model)<br/>	<em class="mf"># add the discriminator</em><br/>	model.add(d_model)<br/>	<em class="mf"># compile model</em><br/>	opt = Adam(lr=0.0002, beta_1=0.5)<br/>	model.compile(loss='binary_crossentropy', optimizer=opt)<br/>	return model</span></pre><p id="a9b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">第四步:搭建舞台。</strong></p><ul class=""><li id="6fb0" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated"><strong class="ky ir">加载真实数据:</strong> —从MNIST获取数据</li><li id="e005" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><strong class="ky ir">生成真实数据:</strong> —从真实数据集中获取一个样本，并附加类标签‘1’</li><li id="282d" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><strong class="ky ir">生成噪声数据:- </strong>生成随机噪声作为发生器的输入</li><li id="bee7" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><strong class="ky ir">生成假日期:- </strong>从生成器获取一个样本，并附加类标签‘0’</li></ul><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="310a" class="mp mq iq ml b gy mr ms l mt mu">def load_real_samples():<br/>	<em class="mf"># load mnist dataset</em><br/>	(trainX, _), (_, _) = mnist.load_data()<br/>	<em class="mf"># expand to 3d, e.g. add channels dimension</em><br/>	X = expand_dims(trainX, axis=-1)<br/>	<em class="mf"># convert from unsigned ints to floats</em><br/>	X = X.astype('float32')<br/>	<em class="mf"># scale from [0,255] to [0,1]</em><br/>	X = X / 255.0<br/>	return X</span><span id="5a24" class="mp mq iq ml b gy nk ms l mt mu">def generate_real_samples(dataset, n_samples):<br/>	<em class="mf"># choose random instances</em><br/>	ix = randint(0, dataset.shape[0], n_samples)<br/>	<em class="mf"># retrieve selected images</em><br/>	X = dataset[ix]<br/>	<em class="mf"># generate 'real' class labels (1)</em><br/>	y = ones((n_samples, 1))<br/>	return X, y</span><span id="b3c8" class="mp mq iq ml b gy nk ms l mt mu">def generate_latent_points(latent_dim, n_samples):<br/>	<em class="mf"># generate points in the latent space</em><br/>	x_input = randn(latent_dim * n_samples)<br/>	<em class="mf"># reshape into a batch of inputs for the network</em><br/>	x_input = x_input.reshape(n_samples, latent_dim)<br/>	return x_input</span><span id="65fe" class="mp mq iq ml b gy nk ms l mt mu"><br/>def generate_fake_samples(g_model, latent_dim, n_samples):<br/>	<em class="mf"># generate points in latent space</em><br/>	x_input = generate_latent_points(latent_dim, n_samples)<br/>	<em class="mf"># predict outputs</em><br/>	X = g_model.predict(x_input)<br/>	<em class="mf"># create 'fake' class labels (0)</em><br/>	y = zeros((n_samples, 1))<br/>	return X, y</span></pre><p id="634f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">第五步:训练方法甘</strong></p><p id="8e49" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面的代码是重要的一部分，有两个循环，外部的一个用于Epochs，内部的一个用于batches。正在训练两个模型，一个是鉴别器模型，另一个是具有鉴别器权重常数的组合模型。Epoch的数量被设置为5，这不会给出一个好的结果，但会让你知道它是否工作。</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="7c6e" class="mp mq iq ml b gy mr ms l mt mu">def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=5, n_batch=256):<br/>	bat_per_epo = int(dataset.shape[0] / n_batch)<br/>	half_batch = int(n_batch / 2)<br/>	<em class="mf"># manually enumerate epochs</em><br/>	for i <strong class="ml ir">in</strong> range(n_epochs):<br/>		<em class="mf"># enumerate batches over the training set</em><br/>		for j <strong class="ml ir">in</strong> range(bat_per_epo):<br/>			<em class="mf"># get randomly selected 'real' samples</em><br/>			X_real, y_real = generate_real_samples(dataset, half_batch)<br/>			<em class="mf"># generate 'fake' examples</em><br/>			X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)<br/>			<em class="mf"># create training set for the discriminator</em><br/>			X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))<br/>			<em class="mf"># update discriminator model weights</em><br/>			d_loss, _ = d_model.train_on_batch(X, y)<br/>			<em class="mf"># prepare points in latent space as input for the generator</em><br/>			X_gan = generate_latent_points(latent_dim, n_batch)<br/>			<em class="mf"># create inverted labels for the fake samples</em><br/>			y_gan = ones((n_batch, 1))<br/>			<em class="mf"># update the generator via the discriminator's error</em><br/>			g_loss = gan_model.train_on_batch(X_gan, y_gan)<br/>			<em class="mf"># summarize loss on this batch</em><br/>			print('&gt;<strong class="ml ir">%d</strong>, <strong class="ml ir">%d</strong>/<strong class="ml ir">%d</strong>, d=<strong class="ml ir">%.3f</strong>, g=<strong class="ml ir">%.3f</strong>' % (i+1, j+1, bat_per_epo, d_loss, g_loss))</span></pre><p id="f129" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">步骤6:使用参数运行训练方法</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="f972" class="mp mq iq ml b gy mr ms l mt mu"><em class="mf"># size of the latent space</em><br/>latent_dim = 100<br/><em class="mf"># create the discriminator</em><br/>d_model = define_discriminator()<br/><em class="mf"># create the generator</em><br/>g_model = define_generator(latent_dim)<br/><em class="mf"># create the gan</em><br/>gan_model = define_gan(g_model, d_model)<br/><em class="mf"># load image data</em><br/>dataset = load_real_samples()<br/><em class="mf"># train model</em><br/>train(g_model, d_model, gan_model, dataset, latent_dim)</span></pre><p id="bef2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">生成阶段:</strong></p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="e2ff" class="mp mq iq ml b gy mr ms l mt mu">seed = tf.random.normal([num_examples_to_generate, noise_dim])<br/>predictions = g_model(seed, training=False)<br/><br/>fig = plt.figure(figsize=(4, 4))<br/>for i <strong class="ml ir">in</strong> range(predictions.shape[0]):<br/>      plt.subplot(4, 4, i+1)<br/>      plt.imshow(predictions[i, :, :, 0] , cmap='gray')<br/>      plt.axis('off')</span></pre><p id="1789" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是5个时期后生成的图像，当然，如果我们训练更多的时期，这将给出一些有意义的东西。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/622ef5ee376facaee5f8dbd2e1052879.png" data-original-src="https://miro.medium.com/v2/resize:fit:472/format:webp/0*IRPlA_mbRTt07vAT.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图3:生成器生成的图像(图像来源:作者)</p></figure><p id="fae6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">结论</strong>:</p><p id="9586" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">GAN是最酷的一个，具有很大的潜力和积极的发展，这个入门只是让你开始。关于鉴别器的收敛性和严格性还存在一些问题，有兴趣的读者可以进一步深入了解。</p><p id="15ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你也可以从我们的视频<a class="ae kv" href="https://www.youtube.com/watch?v=8iBNy0FhyDw" rel="noopener ugc nofollow" target="_blank">讲座</a>开始。</p></div></div>    
</body>
</html>