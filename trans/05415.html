<html>
<head>
<title>Creating Synthetic Data for Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为机器学习创建合成数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/creating-synthetic-data-for-machine-learning-dab5728f6411?source=collection_archive---------14-----------------------#2021-05-13">https://towardsdatascience.com/creating-synthetic-data-for-machine-learning-dab5728f6411?source=collection_archive---------14-----------------------#2021-05-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/0af3184191ae27081b134c7f8bdb13b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FeurPWXj-q_rhOCSss1g7A.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="55b6" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">本教程旨在探索如何创建合成数据来训练对象检测模型</h2></div><p id="1292" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">训练本身基于Jacob Solawetz关于用YOLOv5 训练自定义对象的教程<a class="ae lm" rel="noopener" target="_blank" href="/how-to-train-a-custom-object-detection-model-with-yolo-v5-917e9ce13208"/></p><p id="22d9" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">所以我将使用<a class="ae lm" href="https://www.ultralytics.com/" rel="noopener ugc nofollow" target="_blank"> Ultralytics </a>的<a class="ae lm" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank"> YOLOv5库</a>。</p><p id="fcb2" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">本教程将指导您完成创建合成数据所需的步骤，并展示如何使用YOLOv5对其进行训练，以便处理真实图像。</p><p id="6c01" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">如果您想访问完整的脚本或下载数据集，您可以在这个<a class="ae lm" href="https://github.com/Amizorach/FruitSyntheticDataset" rel="noopener ugc nofollow" target="_blank"> Git资源库</a>中找到所有内容。</p><p id="cd5d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">例如，我将训练分类器来检测树上的橙子。</p><h1 id="49eb" class="ln lo jb bd lp lq lr ls lt lu lv lw lx kh ly ki lz kk ma kl mb kn mc ko md me bi translated">什么是合成数据，我们为什么需要它？</h1><p id="74aa" class="pw-post-body-paragraph kq kr jb ks b kt mf kc kv kw mg kf ky kz mh lb lc ld mi lf lg lh mj lj lk ll ij bi translated">在一个完美的世界中，数据集将是丰富的，我们可以继续在真实图像上训练我们的模型，以便做出更好的预测。然而在现实中，ML编码者的大部分时间将花费在收集数据和正确注释上。</p><p id="effb" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">像谷歌/脸书/亚马逊/苹果这样的大公司，甚至拥有资源的中型公司，都可以着手启动这样的项目。首先，因为他们有数据本身——在我们的例子中是图像。其次，因为他们有能力对数据进行注释，以创建无错误的数据集。但是，即使这些公司也不能确定数据是否被正确标注，所以正常的流程是对每张图片进行多次标注，然后寻找差异。</p><p id="ece4" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">对于一个小公司或者像我这样试图从头开始构建一个ML项目的人来说，这是一个太大的任务。所以我发现自己在使用网上的一个数据集。有许多很好的数据集，在某些情况下，创建一个新的数据集真的没有必要。但是过了一段时间，我开始意识到我所有的项目都没有完全按照我的要求去做，因为它们是在一种不同的数据上被训练的。</p><p id="fcc9" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">对于这个项目，我想在树上数橘子，但找不到合适的数据集。</p><p id="558a" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">所以我开始下载图片，并试图给它们加注释。</p><p id="6461" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">举个例子，我从维基媒体的下面这张图片开始。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/4d0fb6949c908dbd628a2c52564e07a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wYYc5yj1AN7v3nwrJ7cXgA.jpeg"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图片来自<a class="ae lm" href="https://commons.wikimedia.org/wiki/Category:Orange_trees#/media/File:Lets_become_orange.jpg" rel="noopener ugc nofollow" target="_blank">维基媒体</a></p></figure><p id="71b0" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这不是一棵完整的树，但是很快我就明白了，我不能给这张图片做注释。</p><p id="d929" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我想我可以试着选择简单的图像，但我不确定在训练网络时它们会如何站起来。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/8c3b2ef7c1805e77dbc4c067500fd7bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/format:webp/1*fQUneVwGoKSSgCGH7sAY4g.jpeg"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图片来自<a class="ae lm" href="https://commons.wikimedia.org/wiki/Category:Orange_trees#/media/File:Nature_at_his_best.jpg" rel="noopener ugc nofollow" target="_blank">维基媒体</a></p></figure><p id="d9f3" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">继续看更复杂的图片，比如这张(也来自维基媒体)，我明白这不再是一个选项，并开始摆弄我可以在网上找到的不同数据集。</p><p id="3673" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这不是我想做的，很快我就泄气了。</p><p id="2257" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这是我发现自己在寻找一种不同的解决方案，并观看了亚当·凯利斯(我<a class="ae lm" href="https://www.youtube.com/channel/UC1c0mDkk8R5sqhXO0mVJO3Q" rel="noopener ugc nofollow" target="_blank">默塞里极限</a>)的伟大教程，他在其中训练了一个网络，使用合成数据识别杂草。你可以在这里观看他的视频<a class="ae lm" href="https://www.youtube.com/watch?v=3O42e4-u7hM" rel="noopener ugc nofollow" target="_blank"> AI杂草探测器</a>。</p><p id="3aa6" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">虽然我对结果没有太多印象(他似乎有),因为我需要更好的结果，我意识到如果我要继续这个项目，这是要走的路。</p><p id="b9f0" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">因此，为了适应我需要的新关键词，我开始在谷歌上搜索，找到了下面这篇由Maryam Rahnemoonfar和Clay Sheppard撰写的论文</p><p id="432a" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在他们继续进行并根据无需起身开始拍摄图像就能生成的数据训练他们的网络之后，这篇论文似乎正是我想要的。更有甚者，他们试图做一些和我正在做的事情非常相似的事情。</p><p id="a0ab" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">他们没有提供数据集，看着他们的照片，我想我可以做得更好。</p><p id="c85f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">总的来说，他们建议采取以下步骤</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mt"><img src="../Images/f11026989ef83781ff17a4c452d0f481.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BvT8567JmHtvQZUScQKxfA.jpeg"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图片来自<a class="ae lm" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5426829/" rel="noopener ugc nofollow" target="_blank">文章</a></p></figure><p id="bd5e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">但在我看来，他们没有考虑到水果可能被树叶遮挡的事实，他们也没有计算边界框。</p><p id="d849" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">尽管如此，当我被这个成功的事实所鼓舞时，我开始创建我自己的合成数据。</p><h1 id="7d05" class="ln lo jb bd lp lq lr ls lt lu lv lw lx kh ly ki lz kk ma kl mb kn mc ko md me bi translated">步伐</h1><p id="5927" class="pw-post-body-paragraph kq kr jb ks b kt mf kc kv kw mg kf ky kz mh lb lc ld mi lf lg lh mj lj lk ll ij bi translated">我意识到，为了让网络能够统计真实数据，我需要做以下事情</p><ol class=""><li id="99f6" class="mu mv jb ks b kt ku kw kx kz mw ld mx lh my ll mz na nb nc bi translated">收集关于我可能遇到的背景的信息</li></ol><p id="52d8" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">2.创建一个由这些颜色构成的背景图像</p><p id="ab69" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">3.创建不同大小的圆圈来代替橙子</p><p id="4cd9" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">4.创建一个前景，从树叶的颜色，将阻碍一些橙子</p><p id="6e02" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">为此，我编写了一个简单的python程序，它将为我创建图像—(代码被简化了，所以如果你想下载完整的代码，读者可以很容易地阅读它)</p><pre class="mk ml mm mn gt nd ne nf ng aw nh bi"><span id="db5b" class="ni lo jb ne b gy nj nk l nl nm">from PIL import Image, ImageDraw<br/>from PIL import ImageFilter<br/>from PIL import ImageColor<br/>from pascal import PascalVOC, PascalObject, BndBox, size_block<br/>from pathlib import Path<br/>import cv2<br/>import numpy as np<br/>import random</span></pre><p id="2e12" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们从一些导入开始，我使用PIL (pillow)来创建图像，使用pascal (PascalVoc)来保存信息作为注释。</p><p id="6a89" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我从网上下载了一些橘子树的图片，并开始采样像素。他们的颜色被保存到三个数组中的一个</p><p id="36bf" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">树叶，天空，地面</p><p id="74be" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">此时，我没有对橙子取样，因为我对它们使用了不同的方法</p><pre class="mk ml mm mn gt nd ne nf ng aw nh bi"><span id="13eb" class="ni lo jb ne b gy nj nk l nl nm">def prepare_colors():<br/>    txt_leaves = ['#608d2a', '#a8b146', '#ccf0bc']<br/>    txt_sky = ['#e9e3c3', '#99949e', '#9bb5cf']<br/>    txt_ground = ['#3d2c15', '#dfcba6']</span><span id="b380" class="ni lo jb ne b gy nn nk l nl nm">    bg_colors = []<br/>    fg_colors = []</span><span id="7465" class="ni lo jb ne b gy nn nk l nl nm">    for t in txt_leaves:<br/>        bg_colors.append(ImageColor.getrgb(t))<br/>        fg_colors.append(ImageColor.getrgb(t))<br/>    for t in txt_sky:<br/>        bg_colors.append(ImageColor.getrgb(t))<br/>    for t in txt_ground:<br/>        bg_colors.append(ImageColor.getrgb(t))</span><span id="4610" class="ni lo jb ne b gy nn nk l nl nm">    return bg_colors, fg_colors</span></pre><p id="881b" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这很简单，但值得一提的是，我采样的颜色比上面代码中的多(你可以在<a class="ae lm" href="https://github.com/Amizorach/FruitSyntheticDataset" rel="noopener ugc nofollow" target="_blank"> Git </a>中找到我采样的所有颜色)，但为了清晰起见，我减少了采样</p><p id="4764" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">下一步是编写一个函数，将颜色随机放置在图层上</p><pre class="mk ml mm mn gt nd ne nf ng aw nh bi"><span id="2b45" class="ni lo jb ne b gy nj nk l nl nm">def plot_random_color_blobs(draw, colors, count, mins, maxs):<br/>    for i in range(count):<br/>        x = random.randint(0,width)<br/>        y = random.randint(0,height)<br/>        w = random.randint(mins,maxs)<br/>        l = random.randint(mins,maxs)<br/>        c = bg_colors[random.randint(0,len(colors)-1)]<br/>        draw.ellipse((x, y, x+w, y+l), fill=c, outline=None)</span></pre><p id="6392" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这个函数接收一个ImageDraw。从PIL绘制对象，并在随机点添加椭圆计数</p><p id="e730" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">假设我们使用了红色、绿色和蓝色，并且使用了大量的计数(在本例中为1500 ),那么图层的结果可能看起来像这样</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi no"><img src="../Images/2be807b36d24c94a54cf1f97e7212f7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*Cr8epzvvGGdtxE2y78DmPw.png"/></div></figure><p id="5ead" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">所以现在是时候构建背景层了</p><pre class="mk ml mm mn gt nd ne nf ng aw nh bi"><span id="2173" class="ni lo jb ne b gy nj nk l nl nm">def create_bg(colors, width, height):<br/>    im_bg = Image.new('RGBA', (width, height), <br/>                      ImageColor.getrgb('#7FCBFDFF'))<br/>    draw_bg = ImageDraw.Draw(im_bg)<br/>    plot_random_blobs(draw_bg, colors, 1500, 10, 25)<br/>    im_bg = im_bg.filter(ImageFilter.MedianFilter(size=9))<br/>    return im_bg</span></pre><p id="a9cc" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">正如你所看到的，图像是用浅蓝色背景创建的，以消除随机椭圆没有瞄准的任何区域。</p><p id="97bf" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">绘制完斑点后，我使用模糊滤镜来模糊图像，结果是这样的</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi no"><img src="../Images/f7c685d85bd745698a9204a31e7f3510.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*32igu0k9U4eXBqbdSJg9Og.png"/></div></figure><p id="c1de" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这开始看起来好像我是在正确的方向。</p><p id="2c28" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">但我担心网络会学会如何区分图像的模糊部分和非模糊部分，在我们的例子中是水果，所以我调低了它，并转移到一个MedianFilter，它允许合并颜色，但仍保留背景的整体清晰度。</p><p id="9aed" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">接下来，我创建了前景层——这一层将被放置在水果层，以掩盖一些水果</p><pre class="mk ml mm mn gt nd ne nf ng aw nh bi"><span id="1a55" class="ni lo jb ne b gy nj nk l nl nm">def create_fg(colors, width, height):<br/>    im_fg = Image.new('RGBA', (width, height), (0, 0, 0, 0))<br/>    draw_fg = ImageDraw.Draw(im_fg)<br/>    plot_random_el(draw_fg, colors, 40, 10, 25)<br/>    im_fg = im_fg.filter(ImageFilter.MedianFilter(size=9))<br/>    return im_fg</span></pre><p id="7126" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">正如你所看到的，这个函数几乎是相同的，除了我将背景设置为透明，并使用了更少的斑点(40个)来确保大部分水果都能被看到</p><p id="5187" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">最后，是时候创建水果层了</p><pre class="mk ml mm mn gt nd ne nf ng aw nh bi"><span id="b058" class="ni lo jb ne b gy nj nk l nl nm">def plot_random_fruit(color_range, count, width, height, mins, <br/>                       maxs):<br/>    im_fruit = Image.new('RGBA', (width, height), (0, 0, 0, 0))<br/>    draw_fruit = ImageDraw.Draw(im_fruit)</span><span id="1c77" class="ni lo jb ne b gy nn nk l nl nm">    fruit_info = []<br/>    for i in range(count):<br/>        x = random.randint(0,width-10)<br/>        y = random.randint(0,height-10)<br/>        w = random.randint(mins,maxs)<br/>        c = (random.randint(color_range[0][0],color_range[0][1]),<br/>             random.randint(color_range[1][0], color_range[1][1]),<br/>             random.randint(color_range[2][0], color_range[2][1]))<br/>        fruit_info.append([x, y, w, w, c])<br/>        draw_fruit.ellipse((x, y, x+w, y+w), fill=c, outline=None)<br/>    return im_fruit, fruit_info</span></pre><p id="cac9" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">与其他图层相似，这一层在图像周围随机地点绘制水果。然而，这一层有四点不同。</p><ol class=""><li id="e542" class="mu mv jb ks b kt ku kw kx kz mw ld mx lh my ll mz na nb nc bi translated">绘图总是一个圆形，因为这是水果更常见的形状。</li><li id="44fb" class="mu mv jb ks b kt np kw nq kz nr ld ns lh nt ll mz na nb nc bi translated">它使用一系列颜色(在我的例子中是所有的橙色变体)来随机选择一种颜色。</li><li id="17f7" class="mu mv jb ks b kt np kw nq kz nr ld ns lh nt ll mz na nb nc bi translated">没有给图像分配滤镜。</li><li id="793d" class="mu mv jb ks b kt np kw nq kz nr ld ns lh nt ll mz na nb nc bi translated">该图像将水果的边界框及其颜色存储在一个数组中，该数组作为水果信息返回。</li></ol><pre class="mk ml mm mn gt nd ne nf ng aw nh bi"><span id="ab6b" class="ni lo jb ne b gy nj nk l nl nm">def create_layered_image(im_bg, im_fruit, im_fg):<br/>    img = im_bg.copy()<br/>    img.paste(im_fruit, (0, 0), im_fruit)<br/>    img.paste(im_fg, (0, 0), im_fg)<br/>    return img</span></pre><p id="6d12" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">最后一个函数只是将图像一个接一个地粘贴起来</p><p id="d593" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">结果会像这样</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi no"><img src="../Images/52be91567b33c5db33f351baaa16efe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*pQWOa4GD07iTVbhFfoboXw.png"/></div></figure><p id="794c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">显然，这看起来不像一棵果树，但它包括网络可能需要看到的正确颜色和情况，以便能够正确训练。</p><p id="d171" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">下一步是创建一个注释文件，我决定使用PascalObject，因为我对它更熟悉，但是其他任何注释都可以。</p><pre class="mk ml mm mn gt nd ne nf ng aw nh bi"><span id="6e00" class="ni lo jb ne b gy nj nk l nl nm">def create_annotation(img, fruit_info, obj_name,<br/>                      img_name ,ann_name):<br/>    pobjs = []<br/>    for i in range(len(fruit_info)):<br/>        pct = 0<br/>        circle = fruit_info[i]<br/>        color = circle[4]<br/>        for i in range(circle[2]):<br/>            if (circle[0]+i &gt;= width):<br/>                continue;<br/>            for j in range(circle[3]):<br/>                if (circle[1]+j &gt;= height):<br/>                    continue;<br/>                r = img.getpixel((circle[0]+i, circle[1]+j))<br/>                if (r[0] == color[0]):<br/>                    pct = pct +1<br/>        diffculty = pct/(circle[2]*circle[3])</span><span id="f15f" class="ni lo jb ne b gy nn nk l nl nm">        if (diffculty &gt; 0.1):<br/>            dif = True<br/>            if (diffculty &gt; 0.4):<br/>                dif = False<br/>            pobjs.append(<br/>                PascalObject(obj_name, "", truncated=False,<br/>                             difficult=dif,<br/>                             bndbox=BndBox(circle[0], circle[1],<br/>                                           circle[0]+circle[2],<br/>                                           circle[1]+circle[3])))<br/>    pascal_ann = PascalVOC(img_name,<br/>                           size=size_block(width, height, 3),<br/>                           objects=pobjs)<br/>    pascal_ann.save(ann_name)</span></pre><p id="d88c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在将边界框添加到注释之前，该函数检查有多少水果没有被前景遮挡。这使得网络可以决定在计算这个水果时的错误是否严重。</p><p id="2150" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">然而，PascalObject中的难度参数是一个布尔值，所以我选择以下3个截止点。如果看到的水果少于10%，我就简单地忽略该信息，任何被遮挡超过40%的水果都被认为是困难的。</p><p id="72d1" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">把所有这些放在一起，我现在准备开始生成图像</p><pre class="mk ml mm mn gt nd ne nf ng aw nh bi"><span id="06b9" class="ni lo jb ne b gy nj nk l nl nm">def create_training_image(counter, bg_colors, fg_colors,<br/>                          fruit_color_range):<br/>    fruit_count = random.randint(0, 20)<br/>    ext = '{}_{}'.format(counter, fruit_count)<br/>    img_name = '{}/fruit_{}.png'.format(img_path, ext)<br/>    ann_name = '{}/ann_{}.xml'.format(ann_path, ext)</span><span id="a286" class="ni lo jb ne b gy nn nk l nl nm">    im_bg = create_bg(bg_colors, width, height)<br/>    im_fg = create_fg(fg_colors, width, height)<br/>    im_fruit, fruit_info = plot_random_fruit(fruit_color_range,<br/>                                             fruit_count, width, <br/>                                             height, 10, 25)<br/>    img = create_layered_image(im_bg, im_fruit, im_fg)</span><span id="814c" class="ni lo jb ne b gy nn nk l nl nm">    #create the anootation File<br/>    create_annotation(img, fruit_info, 'oranges',<br/>                      img_name, ann_name)<br/>    img.save(img_name)<br/>    return img, img_name, ann_name</span></pre><p id="2b77" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这个函数现在应该是不言自明的，并且创建一个单独的图像及其注释文件。</p><p id="65b0" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">现在为了制作更多的图像，我补充道</p><pre class="mk ml mm mn gt nd ne nf ng aw nh bi"><span id="416d" class="ni lo jb ne b gy nj nk l nl nm">def create_training_set(num, start_at=0):<br/>    bg_colors, fg_colors = prepare_colors()<br/>    fruit_color_range = [[180,230],[50,130],[0,5]]<br/>    for i in range(num):<br/>        create_training_image(num+start_at, bg_colors,<br/>                              fg_colors, fruit_color_range)</span></pre><p id="bc14" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">结果是</p><div class="mk ml mm mn gt ab cb"><figure class="nu is nv nw nx ny nz paragraph-image"><img src="../Images/c1ce32222c84fa71041e5261b4a5e708.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*M0l0esWVX4ch_vPgHXwzmw.png"/></figure><figure class="nu is nv nw nx ny nz paragraph-image"><img src="../Images/20af8922557c95de9518107f469285ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*hwzQcSB4HIdGU4zVBeLmMg.png"/></figure><figure class="nu is nv nw nx ny nz paragraph-image"><img src="../Images/3144fba8302cd6c6045da23456604f8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*YnJcHqcXp8Gc_LLYdwSSfg.png"/><p class="mo mp gj gh gi mq mr bd b be z dk oa di ob oc translated">为测试而创建的批次中的3个样品</p></figure></div></div><div class="ab cl od oe hu of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="ij ik il im in"><h1 id="e4c9" class="ln lo jb bd lp lq ok ls lt lu ol lw lx kh om ki lz kk on kl mb kn oo ko md me bi translated">创建数据集</h1><p id="bc51" class="pw-post-body-paragraph kq kr jb ks b kt mf kc kv kw mg kf ky kz mh lb lc ld mi lf lg lh mj lj lk ll ij bi translated">一旦我准备好了图像和注释，我就按照Solawetz <a class="ae lm" rel="noopener" target="_blank" href="/how-to-train-a-custom-object-detection-model-with-yolo-v5-917e9ce13208">教程</a>进行操作，并使用Roboflow将其转换为YOLOv5的可读数据集——由于Roboflow免费使用的最大图像量是1000张图像，我确保不要创建太多图像，未来我将尝试通过简单地在代码中创建数据集来克服这一点，但现在应该可以了。</p><p id="81d7" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">按照<a class="ae lm" href="https://roboflow.com/" rel="noopener ugc nofollow" target="_blank"> Roboflow </a>设置中简单的5个步骤，我能够在几分钟内构建数据集。</p><p id="bd29" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我选择在这一点上不创建增强，但最终将它们用于缩放目的，以允许网络检测更大的对象。</p></div><div class="ab cl od oe hu of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="ij ik il im in"><h1 id="efc8" class="ln lo jb bd lp lq ok ls lt lu ol lw lx kh om ki lz kk on kl mb kn oo ko md me bi translated">训练网络</h1><p id="1eea" class="pw-post-body-paragraph kq kr jb ks b kt mf kc kv kw mg kf ky kz mh lb lc ld mi lf lg lh mj lj lk ll ij bi translated">根据Solawetz的教程设置环境后，培训减少到一行代码</p><pre class="mk ml mm mn gt nd ne nf ng aw nh bi"><span id="9852" class="ni lo jb ne b gy nj nk l nl nm">%%time<br/>%cd /content/yolov5/</span><span id="445f" class="ni lo jb ne b gy nn nk l nl nm">!python train.py --img 416 --batch 16 --epochs 100 --data '../data.yaml' --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache</span></pre><p id="f116" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">为了训练你自己的模型，我建议看看<a class="ae lm" href="https://colab.research.google.com/drive/1gDZ2xcTOgR39tGGs-EZ6i3RTs16wmzZQ#scrollTo=dOPn9wjOAwwK" rel="noopener ugc nofollow" target="_blank">罗博弗洛的笔记本</a>。</p><p id="d31c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我最初写了我自己的笔记本，可以在Git资源库中找到，但在查看后，我发现上面的笔记本只是写得更好，所以向他们致敬:)。</p><p id="9f65" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">由于我更习惯于使用Tensorflow，而不太熟悉PyTorch，并且由于培训的目的是测试合成数据，所以我选择不更改培训代码，也不尝试调整它。将来，我也打算探索这个问题。</p><p id="5643" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">仅仅过了几分钟(在使用Collab的GPU上运行)和仅仅运行100个epochs，我就获得了精度接近91%的训练结果。事实上，该网络能够在不到40个纪元的时间内收敛到这样的精度。<strong class="ks jc">惊艳。</strong></p><p id="eff1" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">但是当然，这都是基于合成数据。</p><p id="5269" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">是检验真实数据的时候了。</p><p id="eef6" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">一如既往，图片胜过1000字。</p><div class="mk ml mm mn gt ab cb"><figure class="nu is op nw nx ny nz paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/341d668f53ba3cf32bd462347810b963.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*FeurPWXj-q_rhOCSss1g7A.jpeg"/></div></figure><figure class="nu is oq nw nx ny nz paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/2ba50a22c846e0eb2c5bfd35c8d460dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*1r6QRyRKqpADYpQVZ-i47w.jpeg"/></div><p class="mo mp gj gh gi mq mr bd b be z dk or di os oc translated">对真实图像的推理结果</p></figure></div></div><div class="ab cl od oe hu of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="ij ik il im in"><h1 id="e8ba" class="ln lo jb bd lp lq ok ls lt lu ol lw lx kh om ki lz kk on kl mb kn oo ko md me bi translated">警告</h1><p id="9170" class="pw-post-body-paragraph kq kr jb ks b kt mf kc kv kw mg kf ky kz mh lb lc ld mi lf lg lh mj lj lk ll ij bi translated">并不是所有的都很完美。</p><p id="ee41" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">具有占据屏幕大部分的大橙子的图像效果不好，我猜这是因为我的训练集中的所有橙子都相对较小。我使用带有zoom增强功能的Roboflows增强功能重新训练了数据集，并获得了更好的结果。但在进一步的测试中，我计划创建包括更大范围的斑点和橙色尺寸的图像。</p><p id="ac48" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">为背景选择的颜色可能是至关重要的——在我的第一次测试中，我没有添加任何可能出现在图像中的通用颜色，如肤色，在某些情况下，它选择了橙色。但是在背景色中加入一些肤色之后，这个问题似乎就消失了。</p><h1 id="a982" class="ln lo jb bd lp lq lr ls lt lu lv lw lx kh ly ki lz kk ma kl mb kn mc ko md me bi translated">结论</h1><p id="79a7" class="pw-post-body-paragraph kq kr jb ks b kt mf kc kv kw mg kf ky kz mh lb lc ld mi lf lg lh mj lj lk ll ij bi translated">总之，使用合成数据被证明是有用和容易的。</p><p id="505f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我可以很容易地在视频上运行它，因为Yolov5s非常快，它实际上可以实时运行。</p><p id="4a58" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">如果你想下载完整的代码和数据集，你可以查看我的<a class="ae lm" href="https://github.com/Amizorach/FruitSyntheticDataset" rel="noopener ugc nofollow" target="_blank"> Git </a></p><p id="57ab" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我现在进入下一步，将通过许多不同的框架跟踪这些橙子，以允许在不同的视图中进行更强的验证，并最终进行作物估计。</p><p id="661a" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">诚挚的问候</p><p id="3138" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">大阿米佐拉赫</p></div></div>    
</body>
</html>