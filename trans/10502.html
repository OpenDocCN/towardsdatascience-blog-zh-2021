<html>
<head>
<title>What is Really “Fair” in Machine Learning?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中真正“公平”的是什么？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-is-really-fair-in-machine-learning-1fcdb6f35313?source=collection_archive---------25-----------------------#2021-10-06">https://towardsdatascience.com/what-is-really-fair-in-machine-learning-1fcdb6f35313?source=collection_archive---------25-----------------------#2021-10-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="47b7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">寻找衡量和想象公平的方法</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/6d0064da5c899c3365e5cdb1c2c5832c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o-qfSkFXpT-cMf2uJdhTFA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/photos/FO7bKvgETgQ" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h1 id="00a7" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">机器学习中的平等</h1><p id="05fe" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi mk translated"><span class="l ml mm mn bm mo mp mq mr ms di">答</span>随着机器学习领域的扩大，人工智能的力量被用于做出关键决策，我们开始怀疑机器学习算法是否真的“公平”机器学习算法正在影响存在歧视和偏见的决策；我们的目标是衡量这种决策的结果，并确保我们的预测是平等的。尽管机器学习模型可能有助于人类决策，同时节省时间，但ML算法产生的结果也可能显示出有利于特定群体的偏差。随着衡量和维护公平的需求变得越来越重要，机器学习中的平等是研究人员不断探索的新领域。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><p id="962f" class="pw-post-body-paragraph lo lp iq lq b lr na jr lt lu nb ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">没有数据，机器学习算法就无法运行。数据是机器学习中决策的关键；因此，训练数据中出现了许多偏差。数据中的偏差主要是由<em class="nf">人类收集方法</em>和<em class="nf">对少数群体的错误信息或极少信息</em>造成的。虽然有些人可能认为改变数据收集方法会降低一个群体对另一个群体的偏好，但事实是，在大多数情况下，无法确保数据收集过程中的平等。相反，我们需要让模型产生不受种族或性别等潜在偏见因素影响的输出。仅仅知道数据可能不公平是远远不够的，<strong class="lq ir">我们需要能够通过我们预测的这些敏感属性来衡量和表示关系。</strong>这些关系可以通过工具和指标计算甚至可视化，从而更好地帮助我们理解模型和数据中的不平等。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/0a8b192da3a9a6983f3a966164548395.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-0iCUa8XOvAmGLgsY0nRlQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者使用Canva创建的图像</p></figure><h1 id="9e57" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">定义问题</h1><p id="98b1" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">如前所述，对某些群体的不公平是由“<strong class="lq ir">敏感属性</strong>造成的，这些属性可能会将一个类别与另一个类别区分开来，如种族或性别。在一个完美的场景中，一个模型将基于对任何群体都一视同仁地提供的特征来预测一些目标。最简单的解决方案是删除这些“敏感属性”。然而，简单地取消这些功能并没有多大作用。由于大多数敏感属性在人与人之间是非常<em class="nf">独特的</em>，该模型仍然能够根据提供的其他信息推断出被移除的特征。预测或数据必须满足某些测量或统计特性，才能被认为是“公平的”。</p><p id="0d1c" class="pw-post-body-paragraph lo lp iq lq b lr na jr lt lu nb ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">想象一下这样一种情况，很多人都在申请一份有着不同经历的工作。我们的目标是根据一个人的特征来预测他是否会被录用。这里，<strong class="lq ir"><em class="nf"/></strong>将代表敏感或受保护的特征，<strong class="lq ir"> <em class="nf"> X </em> </strong>将是告诉我们关于申请人的任何其他信息，<strong class="lq ir"> <em class="nf"> Y </em> </strong>是基本事实，<strong class="lq ir"><em class="nf">ŷ</em></strong>是我们的预测。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="38e5" class="pw-post-body-paragraph lo lp iq lq b lr na jr lt lu nb ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">我们可以通过估计给定特征<strong class="lq ir"> <em class="nf"> X </em> </strong>和<strong class="lq ir"> <em class="nf"> A. </em> </strong>的概率分布来表述这个问题</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="c9d6" class="pw-post-body-paragraph lo lp iq lq b lr na jr lt lu nb ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">当地面真值为1关于特征<strong class="lq ir"> <em class="nf"> X </em> </strong>和被保护属性<strong class="lq ir"> <em class="nf"> A </em> </strong>时。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="c4b6" class="kw kx iq bd ky kz nj lb lc ld nk lf lg jw nl jx li jz nm ka lk kc nn kd lm ln bi translated">评估方法和指标</h1><p id="9e96" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">测量模型预测最广泛使用的标准之一是<strong class="lq ir">人口统计均等</strong>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="no ni l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">人口均等</p></figure><p id="6cd2" class="pw-post-body-paragraph lo lp iq lq b lr na jr lt lu nb ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">为了满足这个性质，<strong class="lq ir"><em class="nf"/></strong>必须在统计上独立于<strong class="lq ir"><em class="nf"/></strong>。简单来说，<strong class="lq ir"> <em class="nf"> A </em> </strong>无论如何都无法与<strong class="lq ir"> <em class="nf"> Y </em> </strong>的预测联系起来，无论地面真值如何。</p><p id="185c" class="pw-post-body-paragraph lo lp iq lq b lr na jr lt lu nb ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">人口均等可以进一步扩展为<strong class="lq ir">强人口均等</strong>。在前面的人口统计均等的情况下，我们声明<strong class="lq ir">二元</strong>模型输出必须独立于敏感属性。二元结果由模型连续输出的阈值决定，如果预测值大于阈值，我们将其视为1。可以对某个阈值实施人口统计均等，但不能确保它适用于所有情况。另一方面，强人口统计奇偶校验在<strong class="lq ir"><em class="nf"/></strong>和模型的连续输出之间强加了统计独立性，进一步确保无偏性。在我们的场景中，没有任何其他特征，每个人都应该有相同的机会获得工作，不管他们的敏感属性如何。</p><p id="c746" class="pw-post-body-paragraph lo lp iq lq b lr na jr lt lu nb ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">类似于人口均等，还有机会均等。机会平等只会限制优势群体的平等。在我们的情况下，它被提供了工作。机会均等允许预测依赖于<strong class="lq ir"><em class="nf"/></strong>而<em class="nf">只能通过地面真相</em>。请注意，该方法允许使用与结果直接相关的特征，但不允许使用<strong class="lq ir"><em class="nf"/></strong>来表示结果。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np ni l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">机会均等</p></figure><p id="abee" class="pw-post-body-paragraph lo lp iq lq b lr na jr lt lu nb ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">对于优势结果中的<strong class="lq ir"><em class="nf"/></strong>的所有值，真实阳性率应保持相同。它没有人口统计的奇偶校验严格，这确保了我们的预测成为某一类的概率在A的所有值中保持不变，而不管地面是否真实。简而言之，对于一群具有相同资历的人来说，无论他们的“敏感属性”如何，他们都有同等的<strong class="lq ir"/><strong class="lq ir">机会</strong>被录用。这具有更广泛的应用，因为大多数人只关心“积极群体”中的不歧视。</p><p id="b4a0" class="pw-post-body-paragraph lo lp iq lq b lr na jr lt lu nb ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">最后，还有预测奇偶校验。预测奇偶性，或者有时称为结果测试，更侧重于<strong class="lq ir"> <em class="nf"> Y </em> </strong>的地面真相。它要求给定我们的预测y-hat，地面真理不能依赖于<strong class="lq ir"><em class="nf"/></strong>与机会均等相对的是我们的预测<strong class="lq ir"><em class="nf"/></strong><strong class="lq ir"><em class="nf"/></strong>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq ni l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">给定Y-hat，a在统计上独立于Y</p></figure><p id="252e" class="pw-post-body-paragraph lo lp iq lq b lr na jr lt lu nb ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">这表明我们的模型的精度，或者说<strong class="lq ir"><em class="nf"/></strong>为正并且它确实属于正类的概率，应该在<strong class="lq ir"> <em class="nf"> A </em>的所有值上保持相同。</strong></p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="2656" class="kw kx iq bd ky kz nj lb lc ld nk lf lg jw nl jx li jz nm ka lk kc nn kd lm ln bi translated">对CBNs的温和介绍</h1><p id="0925" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">既然我们已经建立了如何通过我们的预测来衡量和评估公平性的意识，我们将手转向可视化。因果贝叶斯网络可以表示场景，并通过箭头和图表来说明公平性。回到我们的情况:</p><ul class=""><li id="99b1" class="nr ns iq lq b lr na lu nb lx nt mb nu mf nv mj nw nx ny nz bi translated">对每个人来说，我们有x个特征，这些特征在某些方面告诉我们这个人的情况。</li><li id="d166" class="nr ns iq lq b lr oa lu ob lx oc mb od mf oe mj nw nx ny nz bi translated">我们还有<strong class="lq ir"> <em class="nf">一个</em> </strong>，受保护的属性，在我们的例子中，它将是性别。</li><li id="bb53" class="nr ns iq lq b lr oa lu ob lx oc mb od mf oe mj nw nx ny nz bi translated">我们的预测<strong class="lq ir"><em class="nf">ŷ</em></strong>将产生一个介于0和1之间的概率，代表这个人是否会被提供一份工作。</li></ul><p id="911d" class="pw-post-body-paragraph lo lp iq lq b lr na jr lt lu nb ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">这种情况可以使用一个带有节点和边的有向无环图来表示，称为因果贝叶斯网络(CBN)。在贝叶斯网络中，节点代表与问题相关的随机变量或特征，而它们之间的边显示它们的统计依赖性。</p><p id="89b5" class="pw-post-body-paragraph lo lp iq lq b lr na jr lt lu nb ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">如下右图所示，<strong class="lq ir"> <em class="nf"> A </em> </strong>被认为是直接影响<strong class="lq ir"> <em class="nf"> Y </em> </strong>如果路径直接指向<strong class="lq ir"> <em class="nf"> Y. </em> </strong>这被认为是一条随意的路径。另一方面(左图)，如果<strong class="lq ir"> A </strong>不直接指向<strong class="lq ir"> <em class="nf"> Y </em> </strong>，则表明对于<strong class="lq ir"> <em class="nf"> A </em> </strong>要潜在地影响<strong class="lq ir"> <em class="nf"> Y </em> </strong>，必须经过<strong class="lq ir"> <em class="nf"> X </em> </strong>。当敏感属性的影响通过其他特征<strong class="lq ir"> <em class="nf"> X </em> </strong>表示时，被认为是公平的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/7794617008bfcb38936ef72d17c589e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Dh7uYuyqzMbpDcCERi9mg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">CBNs，图片由作者使用LucidChart提供</p></figure><p id="9d88" class="pw-post-body-paragraph lo lp iq lq b lr na jr lt lu nb ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">在这个特定的图中，从<strong class="lq ir"> <em class="nf"> A </em> </strong>到<strong class="lq ir"> <em class="nf"> X </em> </strong>的路径代表基于<strong class="lq ir"><em class="nf"/></strong>A<strong class="lq ir"><em class="nf">p(X | A)</em></strong>X的概率。从<strong class="lq ir"> <em class="nf"> X </em> </strong>再到<strong class="lq ir"> <em class="nf"> Y </em> </strong>的路径，就是基于X，<strong class="lq ir"><em class="nf">p(Y | X)</em></strong>Y为真的几率。在从A到X没有偶然路径的情况下，3个变量的<strong class="lq ir">联合分布</strong>为</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="a26d" class="pw-post-body-paragraph lo lp iq lq b lr na jr lt lu nb ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated"><strong class="lq ir"> <em class="nf"> A </em> </strong>可能会影响<strong class="lq ir"> <em class="nf"> Y </em> </strong>，但不会直接影响。</p><p id="df00" class="pw-post-body-paragraph lo lp iq lq b lr na jr lt lu nb ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">当在A和Y之间建立任何偶然路径时，上面提到的度量不能被满足。CBNs还有很多功能，甚至可以用它来量化不公平，但是，它的基本功能就像上面描述的一样简单。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="e649" class="kw kx iq bd ky kz nj lb lc ld nk lf lg jw nl jx li jz nm ka lk kc nn kd lm ln bi translated">结论</h1><p id="2b1d" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在这篇文章中，我们讨论了各种方法来衡量公平，甚至可视化与它相关的关系。数据中的不公平可能很难甚至不可能消除，因此我们需要能够发现这种不平等，并能够解释它对我们的模型预测的影响。</p></div></div>    
</body>
</html>