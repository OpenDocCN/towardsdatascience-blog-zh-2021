<html>
<head>
<title>Attacking Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">攻击神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/make-your-neural-net-confuse-dogs-with-pelicans-af7ad6ec95a5?source=collection_archive---------24-----------------------#2021-09-04">https://towardsdatascience.com/make-your-neural-net-confuse-dogs-with-pelicans-af7ad6ec95a5?source=collection_archive---------24-----------------------#2021-09-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a10a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用PGD攻击为神经网络制造视错觉。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1bcdad28022ecefda5771942fbede508.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HNLsKrttJucVmPOmsBuzrA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图标由<a class="ae ky" href="https://www.flaticon.com/free-icon/dog_1998627?term=dog&amp;page=1&amp;position=6&amp;page=1&amp;position=6&amp;related_id=1998627&amp;origin=search" rel="noopener ugc nofollow" target="_blank">平面图标</a>和<a class="ae ky" href="https://www.flaticon.com/free-icon/ai_1693857?term=ai&amp;page=1&amp;position=13&amp;page=1&amp;position=13&amp;related_id=1693857&amp;origin=search" rel="noopener ugc nofollow" target="_blank"> photo3idea-studio </a>组合而成，作者(【marcelmoos.com】T4</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="d546" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们来看看下面两张图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/9cb7dfdf399a62900faa819a8e462abb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*ljBdZ9zCpD3xKA7zWhum5g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自安娜·杜德科娃的<a class="ae ky" href="https://unsplash.com/photos/asW9idv3HMM" rel="noopener ugc nofollow" target="_blank">Unsplash</a></p></figure><p id="3c44" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">左图是一只德国牧羊犬，右图是一只美丽的鹈鹕……</strong>至少根据最先进的神经网络来看是这样的。我们将探索如何从左边的图片为右边的神经网络创建<strong class="li iu">视错觉。您甚至可以创建我们的狗图像的版本，顶级图像分类器可以将它与您喜欢的任何东西相混淆，从花椰菜到敞篷车。如果你更喜欢代码而不是文字，这里有一个交互式Jupyter笔记本。通过它，你可以关注和调整这个故事的一切:<a class="ae ky" href="https://colab.research.google.com/drive/1fL0pX0g4ppdLlYCmrERP-PSbLF4fTZug?usp=sharing" rel="noopener ugc nofollow" target="_blank">colab . research . Google . com/drive/1 fl 0 px 0g 4 ppdlycmrerp-PS blf 4 ftzug？usp =共享</a></strong></p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="eaea" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi md translated"><span class="l me mf mg bm mh mi mj mk ml di">答</span>几年前，我在学习神经网络时做的第一件事就是训练一个简单的图像分类器。神经网络可以很好地分辨图像中的内容。然而，有一件事我当时没有问过自己:<strong class="li iu">“这些网络到底在学什么？”</strong></p><p id="4903" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">让我用一个例子来解释我的意思:我们人类是如何识别狗是狗的？我认为我们应该寻找一些与众不同的特征，比如尖耳朵、鼻子、尾巴、四条腿以及类似的东西。然而，对于神经网络来说，其他东西可能是必不可少的。他们在寻找什么，比如一只狗，这可能是一个相当神秘的事情。这种现象在我称之为<strong class="li iu">神经网络的视错觉</strong>中变得非常明显。令人着迷的是，它们是<strong class="li iu"> <em class="mm">而不是</em> </strong>对人类的幻觉。</p><p id="4a27" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">下图包含一只漂亮的德国牧羊犬。神经网络不仅正确地将它归类为狗，甚至将其归类为正确的品种。而且它对自己的决定有93 %以上的把握，所以这里一切都好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mn"><img src="../Images/826c00f627d1a115ed4c237000a975c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ugp7FaBQmUzJ7pLC.gif"/></div></div></figure><p id="7089" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">现在问题来了。我们来看看下面这张图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/f056db38617c05da6a4c7f64d6f76834.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*gpvCR4qzbIxI4MoTroogiw.png"/></div></figure><p id="b13b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">该图像几乎是前一个图像的完美副本。<strong class="li iu">剧透:不是！</strong>你必须非常仔细地观察才能看出不同。背景不是绿色的，画面似乎有点嘈杂。但对人类来说几乎是察觉不到的。我想我们都同意，每一个接受第一张图片显示的是一只德国牧羊犬的人都会对这张图片说同样的话。所以我们的神经网络也应该仍然声明它看到一只德国牧羊犬有大约93 %的把握，对吗？<strong class="li iu">错了。我们的神经网络现在100%确定它看到了一只鹈鹕:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mn"><img src="../Images/b731515fa7280952fbf3cb8f1c082205.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*05fleED4bYivj8tP.gif"/></div></div></figure><p id="98e8" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">好吧，这里发生了什么？我们使用的分类器是一个50层的<a class="ae ky" href="https://en.wikipedia.org/wiki/Residual_neural_network" rel="noopener ugc nofollow" target="_blank"> <strong class="li iu">残差神经网络</strong> </a> <strong class="li iu"> (resnet)。</strong>它在<a class="ae ky" href="https://image-net.org/index.php" rel="noopener ugc nofollow" target="_blank"> ImageNet数据集</a>上进行了预训练，这是一个包含1000个不同对象类的庞大图像集合。接下来，我们使用了一张我们的resnet正确分类的德国牧羊犬的图片。</p><blockquote class="mp mq mr"><p id="b16f" class="lg lh mm li b lj lk ju ll lm ln jx lo ms lq lr ls mt lu lv lw mu ly lz ma mb im bi translated">为了给我们的resnet创建视错觉，我们取原始图像并稍微改变原始图像的像素。我们只改变正确的像素，resnet对我们可爱的狗最敏感的像素。</p></blockquote><p id="16d9" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">下图显示了我们需要改变多少像素来欺骗我们的分类器。<strong class="li iu">因为像素变化非常小，我把它们放大了10倍，所以我们可以看得更清楚:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/c2256c0d466053e985d239d2456339be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kBDwQ_C9nHdlmtmz1aLpAQ.png"/></div></div></figure><p id="09ee" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">因此，我们改变了原始图像稍微偏蓝和偏红。还有，一些像素点变亮了一点。在我们看来，这些变化几乎不存在。但是对我们的resnet来说…哦，天哪…它改变了一切。现在看到鹈鹕就彻底服气了。最棒的是，它不一定是鹈鹕。这一招基本上适用于任何职业。我们可以欺骗神经网络，让它认为我们的狗是花椰菜、打印机或其他任何东西。此外，<strong class="li iu">每一个像样的图像分类器都容易受到这些视错觉</strong>或者——它们在文献中如何被称为——<strong class="li iu"/><em class="mm">对抗性图像的影响。</em></p><p id="a6fe" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">现在的问题是，我们如何找到这些混淆我们的分类器的像素变化？我们如何自动创造这些视错觉？</p><h1 id="5eee" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">自动愚弄神经网络</h1><p id="42fd" class="pw-post-body-paragraph lg lh it li b lj no ju ll lm np jx lo lp nq lr ls lt nr lv lw lx ns lz ma mb im bi translated">我们对狗的形象所做的改变非常微小，但也非常具体。手动寻找这些扰动是不可行的。幸运的是，有各种不同的技术，也称为<strong class="li iu">攻击，可以自动创建这些视错觉。</strong>其中一种攻击叫做<strong class="li iu">投影梯度下降(PGD) </strong>。为了理解PGD，我们首先需要快速提醒自己神经网络是如何使用梯度下降进行学习的。</p><h2 id="4e98" class="nt mx it bd my nu nv dn nc nw nx dp ng lp ny nz ni lt oa ob nk lx oc od nm oe bi translated">梯度下降</h2><p id="1e45" class="pw-post-body-paragraph lg lh it li b lj no ju ll lm np jx lo lp nq lr ls lt nr lv lw lx ns lz ma mb im bi translated">神经网络包含权重。改变权重会影响神经网络的输出。为了训练一个神经网络，我们需要<strong class="li iu">量化它的答案与正确答案的偏差程度。这是通过损失函数来完成的。</strong>一旦定义了损失函数，我们就可以计算损失函数相对于网络权重的梯度。直观地说，<strong class="li iu">(负)梯度告诉我们如何改变网络的权重，以使损耗尽可能快地减少</strong>，这意味着它的答案尽可能快地变得更正确。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/c2dbe68f810c24e6f4f19672e491b743.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L2esFNzuFoxg0pcI95aaVw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">基于梯度下降的学习图解。(图片由作者提供)</p></figure><p id="933b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">对训练集中的所有图像反复进行这种操作会得到一个训练好的网络。在高层次上，这概括了基于梯度体面的学习。</p><h2 id="9768" class="nt mx it bd my nu nv dn nc nw nx dp ng lp ny nz ni lt oa ob nk lx oc od nm oe bi translated">PGD攻击</h2><p id="42b8" class="pw-post-body-paragraph lg lh it li b lj no ju ll lm np jx lo lp nq lr ls lt nr lv lw lx ns lz ma mb im bi translated">恭喜，如果你理解梯度下降，你就已经理解了PGD攻击。对于PGD攻击，<strong class="li iu">我们采用网络并定义一个新的损失函数</strong>。对于我们的德国牧羊犬形象，我们希望它被归类为鹈鹕(或任何你喜欢的)。现在，类似于基于梯度下降的训练，我们计算梯度。</p><blockquote class="mp mq mr"><p id="7be6" class="lg lh mm li b lj lk ju ll lm ln jx lo ms lq lr ls mt lu lv lw mu ly lz ma mb im bi translated">然而，我们不是根据网络的权重(那些是固定的)来计算梯度，而是根据图像的像素来计算梯度。直观上，这种梯度告诉我们如何改变图像的像素，以便网络尽快认为这是一只鹈鹕。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/9a51be968beef6ffc78b0d079bbc2786.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gkCwc3QM2d-VyxT41eiF1A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PGD攻击的插图(没有最终投影)。(图片由作者提供)</p></figure><p id="1cea" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">差不多就这样了。我们应用这些变化并继续，直到神经网络实际上将我们的图像分类为一只鹈鹕。</p><p id="42e2" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">你可能会问，PGD的<em class="mm"> P </em>、投影<em class="mm"/>在哪里发挥作用。PGD攻击允许我们为每个像素定义一个变化极限。每个像素的所有颜色通道都采用0到255之间的值。<strong class="li iu">对于PGD攻击，我们可以指定任何像素都不应该改变超过10个点。</strong>每当一个像素受到超过10个点的干扰时，该像素被投影到其允许的一组值。</p><h2 id="61e6" class="nt mx it bd my nu nv dn nc nw nx dp ng lp ny nz ni lt oa ob nk lx oc od nm oe bi translated">Python包</h2><p id="6eee" class="pw-post-body-paragraph lg lh it li b lj no ju ll lm np jx lo lp nq lr ls lt nr lv lw lx ns lz ma mb im bi translated">幸运的是，我们不需要了解所有的细节并从头开始重新实施PGD袭击。有一个令人惊叹的python包叫做<em class="mm">fool box</em>(【github.com/bethgelab/foolbox】T2)，它支持PGD攻击(以及更多)并兼容TensorFlow和PyTorch。使用Foolbox，从德国牧羊犬图片生成我们的鹈鹕敌对图像既简单又快捷:</p><pre class="kj kk kl km gt of og oh oi aw oj bi"><span id="5222" class="nt mx it og b gy ok ol l om on">criterion = TargetedMisclassification(pelican_label)<br/>attack = PGD()<br/>adv_input = attack.run(net, german_shepherd, criterion, epsilon=10)</span></pre><p id="0a13" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果你想自己生成对抗性的图像并运行和调整代码，我强烈建议查看Jupyter笔记本:<a class="ae ky" href="https://colab.research.google.com/drive/1fL0pX0g4ppdLlYCmrERP-PSbLF4fTZug?usp=sharing" rel="noopener ugc nofollow" target="_blank">colab . research . Google . com/drive/1 fl 0 px 0g 4 ppdlycmrerp-PS blf 4 ftzug？usp =分享</a></p><h1 id="5d3e" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">结论</h1><p id="78bc" class="pw-post-body-paragraph lg lh it li b lj no ju ll lm np jx lo lp nq lr ls lt nr lv lw lx ns lz ma mb im bi translated">从一张我们的分类器正确标记为德国牧羊犬的照片中，我们创建了一张敌对的图像——神经网络的一种视错觉——显示了同一只狗，但被我们的网络误分类为鹈鹕。创造这些视错觉可能是一项有趣的练习。然而，在现实生活中，敌对的图像可能会产生严重的后果。试想一下，一辆自动驾驶汽车将停车标志误标为限速标志。有一些技术可以抵御敌对的图像，但那是另外一个故事了。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="d6d7" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">觉得这个故事有趣？你可以在这里成为一个中等会员来支持我的写作:<a class="ae ky" href="https://medium.com/@mmsbrggr/membership" rel="noopener">medium.com/@mmsbrggr/membership</a>。你将获得所有媒体的访问权，你的部分会员费将直接支持我的写作。</p><p id="d8a4" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">欢迎在LinkedIn<a class="ae ky" href="https://www.linkedin.com/in/marcel-moosbrugger/" rel="noopener ugc nofollow" target="_blank">上向我提出私人问题和评论。如果你喜欢这篇文章，让我告诉你我的时事通讯:</a><a class="ae ky" href="https://marcelmoos.com/newsletter" rel="noopener ugc nofollow" target="_blank">marcelmoos.com/newsletter</a>。</p><p id="9a6d" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">以下是另外三个你可能感兴趣的故事:</p><div class="oo op gp gr oq or"><a rel="noopener follow" target="_blank" href="/why-your-neural-net-is-uncertain-in-different-ways-a125ce1fa4e5"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd iu gy z fp ow fr fs ox fu fw is bi translated">为什么你的神经网络以不同的方式不确定</h2><div class="oy l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">towardsdatascience.com</p></div></div><div class="oz l"><div class="pa l pb pc pd oz pe ks or"/></div></div></a></div><div class="oo op gp gr oq or"><a rel="noopener follow" target="_blank" href="/five-paradoxes-with-probabilities-that-will-puzzle-you-2f71201d6ee8"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd iu gy z fp ow fr fs ox fu fw is bi translated">可能会让你困惑的五个悖论</h2><div class="oy l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">towardsdatascience.com</p></div></div><div class="oz l"><div class="pf l pb pc pd oz pe ks or"/></div></div></a></div><div class="oo op gp gr oq or"><a rel="noopener follow" target="_blank" href="/what-really-is-a-matrix-determinant-89c09884164c"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd iu gy z fp ow fr fs ox fu fw is bi translated">什么是矩阵行列式？</h2><div class="pg l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">行列式背后的几何直觉会改变你对它们的看法。</h3></div><div class="oy l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">towardsdatascience.com</p></div></div><div class="oz l"><div class="ph l pb pc pd oz pe ks or"/></div></div></a></div></div></div>    
</body>
</html>