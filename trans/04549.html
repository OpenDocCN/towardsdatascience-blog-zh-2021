<html>
<head>
<title>Boosting Natural Language Processing with Wikipedia</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用维基百科推进自然语言处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/boosting-natural-language-processing-with-wikipedia-b779103ba396?source=collection_archive---------15-----------------------#2021-04-19">https://towardsdatascience.com/boosting-natural-language-processing-with-wikipedia-b779103ba396?source=collection_archive---------15-----------------------#2021-04-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="4d12" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="ac58" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated"><em class="ko">使用维基百科改进自然语言处理任务，如命名实体识别和主题建模</em></h2></div><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/6d3698565578d3937aeef55aac89a22b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kaKu9acRheF5FJN7"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">照片由<a class="ae lf" href="https://unsplash.com/@art_maltsev?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Artem Maltsev </a>在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><h1 id="4221" class="lg lh iq bd li lj lk ll lm ln lo lp lq kf lr kg ls ki lt kj lu kl lv km lw lx bi translated">介绍</h1><p id="d556" class="pw-post-body-paragraph ly lz iq ma b mb mc ka md me mf kd mg mh mi mj mk ml mm mn mo mp mq mr ms mt ij bi translated">自然语言处理(NLP)正在兴起。计算语言学和人工智能正在联手培育突破性发现。当研究集中于显著改进NLP技术时，企业将该技术视为战略资产。这种由NLP引导的彻底革新的主要作用是由文本数据的大量可用性发挥的。当谈到数字化时，尤其是对企业而言，重要的是要记住文档本身就是数字化的，因此，文本数据是知识的主要来源。</p><p id="7fe1" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">然而，当寻求磨练自然语言处理任务时，最大的瓶颈之一是关于数据的训练。当涉及到真实世界的应用时，比如在特定的领域，我们面临着低资源数据的问题。训练数据有两个主要问题:(I)难以获得大量数据，以及(ii)注释用于训练和测试的可用数据的耗时过程。</p><p id="1a21" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">面对这些问题，计算机科学已经投入了大量的注意力。特别是，最新的计算进展提出了两种方法来克服低资源数据问题:</p><ul class=""><li id="51f2" class="mz na iq ma b mb mu me mv mh nb ml nc mp nd mt ne nf ng nh bi translated">微调预先训练的语言模型，如BERT或GPT-3；</li><li id="9528" class="mz na iq ma b mb ni me nj mh nk ml nl mp nm mt ne nf ng nh bi translated">利用高质量的开放式数据存储库，如维基百科或概念网。</li></ul><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nn"><img src="../Images/96bcf192cca575069aecd6ed00087d5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0Faw8-iFTbgxKh7c.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">维基百科标志(图片来自<a class="ae lf" href="https://it.wikipedia.org/wiki/Wikipedia_in_inglese#/media/File:Wikipedia-logo-v2-en.svg" rel="noopener ugc nofollow" target="_blank">维基百科</a>)</p></figure><p id="e8be" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">大多数现有的计算语言学开放库都提供了基于这两种方法之一开发NLP工具的架构。我们现在演示如何利用维基百科来提高两个NLP任务的性能:<strong class="ma ja">命名实体识别</strong>和<strong class="ma ja">主题建模</strong>。</p><h2 id="de39" class="no lh iq bd li np nq dn lm nr ns dp lq mh nt nu ls ml nv nw lu mp nx ny lw iw bi translated">从句子中提取维基百科信息</h2><p id="6049" class="pw-post-body-paragraph ly lz iq ma b mb mc ka md me mf kd mg mh mi mj mk ml mm mn mo mp mq mr ms mt ij bi translated">有几种工具可以用来处理来自维基百科的信息。关于文本数据的自动处理，我们使用spaCy的一个开放项目<a class="ae lf" href="https://spacy.io/universe/project/spikex" rel="noopener ugc nofollow" target="_blank"> SpikeX </a>。</p><p id="c97e" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">SpikeX是准备插入spaCy管道的管道集合，spaCy管道是NLP的python库。SpikeX由一家意大利公司(<a class="ae lf" href="https://www.errequadrosrl.com/" rel="noopener ugc nofollow" target="_blank"> Erre Quadro Srl </a>)开发，旨在帮助构建知识提取工具，几乎不费吹灰之力。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="e579" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">SpikeX有两个主要特点:</p><ol class=""><li id="2fab" class="mz na iq ma b mb mu me mv mh nb ml nc mp nd mt ob nf ng nh bi translated">给定一个维基百科页面，它提取所有相应的类别。</li></ol><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nz oa l"/></div></figure><pre class="kq kr ks kt gt oc od oe of aw og bi"><span id="c1e3" class="no lh iq od b gy oh oi l oj ok">Categories for `Natural_Language_Processing`:<br/>  Category:Artificial_intelligence<br/>  -&gt; Category:Emerging_technologies<br/>  -&gt; Category:Cybernetics<br/>  -&gt; Category:Subfields_of_computer_science<br/>  -&gt; Category:Computational_neuroscience<br/>  -&gt; Category:Futures_studies<br/>  -&gt; Category:Cognitive_science<br/>  -&gt; Category:Personhood<br/>  -&gt; Category:Formal_sciences<br/>  Category:Speech_recognition<br/>  -&gt; Category:Artificial_intelligence_applications<br/>  -&gt; Category:Computational_linguistics<br/>  -&gt; Category:Human–computer_interaction<br/>  -&gt; Category:Digital_signal_processing<br/>  -&gt; Category:Speech<br/>  Category:Natural_language_processing<br/>  -&gt; Category:Artificial_intelligence_applications<br/>  -&gt; Category:Computational_linguistics<br/>  Category:Computational_linguistics<br/>  -&gt; Category:Computational_social_science</span></pre><p id="15f2" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">2.给定一个句子，它会在文本中找到匹配维基百科页面标题的组块。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nz oa l"/></div></figure><pre class="kq kr ks kt gt oc od oe of aw og bi"><span id="db12" class="no lh iq od b gy oh oi l oj ok">Elon Musk <br/>('Elon_Musk', 'Elon_musk', 'Elon_Musk_(book)', 'Elon_Musk_(2015_book)', 'Elon_Musk_(2015)', 'Elon_Musk_(biography)', 'Elon_Musk_(2015_biography)', 'Elon_Musk_(Ashlee_Vance)') <br/>------ <br/>Elon <br/>('Elon_(Judges)', 'Elon_(name)', 'Elon_(Hebrew_Judge)', 'Elon_(Ilan)', 'Elon_(disambiguation)', 'Elon_(biblical_judge)', 'Elon_(chemical)', 'Elon') <br/>------ <br/>Musk <br/>('Musk', 'MuSK', 'Musk_(wine)', 'Musk_(song)', 'Musk_(Tash_Sultana_song)', 'Musk_(disambiguation)') <br/>------ <br/>runs<br/>('Runs_(baseball_statistics)', 'Runs', 'Runs_(cricket)', 'Runs_(music)', 'Runs_(baseball)', 'Runs_(Baseball)', 'Runs_(musical)') <br/>------<br/>Tesla Motors <br/>('Tesla_motors', 'Tesla_Motors')<br/>------ <br/>Tesla <br/>('Tesla_(band)', 'Tesla_(unit)', 'Tesla_(Czechoslovak_company)', 'Tesla_(crater)', 'Tesla_(microarchitecture)', 'Tesla_(2020_film)', 'Tesla_(car)', 'Tesla_(GPU)', 'TESLA', 'Tesla_(physicist)', 'Tesla_(group)', 'Tesla_(opera)', 'Tesla_(Bleach)', 'Tesla_(company)', 'Tesla_(disambiguation)', 'Tesla_(2016_film)', 'TESLA_(Czechoslovak_company)', 'Tesla_(unit_of_measure)', 'Tesla_(vehicles)', 'Tesla_(vehicle)', 'Tesla_(film)', 'Tesla_(album)', 'Tesla_(Flux_Pavilion_album)', 'Tesla_(surname)', 'Tesla') <br/>------ <br/>Motors ('Motors')</span></pre><p id="aff7" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">我们可以看到，在第一个例子中，SpikeX提取了维基百科页面“自然语言处理”所属的所有类别。例如，“<em class="ol">自然_语言_处理</em>”属于“<em class="ol">人工_智能</em>”、“<em class="ol">语音_识别</em>”、“<em class="ol">计算_语言学</em>”的范畴。Wiki类别的树形结构可以通过更深层次的检查来进一步探究。</p><p id="a919" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">在第二个例子中，对于句子“<em class="ol">埃隆·马斯克(Elon Musk)经营特斯拉汽车公司”</em>，SpikeX提取句子中所有可能在维基百科上有页面的页面。</p><p id="9fbe" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">我们现在看到这两个处理特性如何被用来执行<strong class="ma ja">命名实体识别</strong>和<strong class="ma ja">主题建模</strong>。</p><h2 id="8478" class="no lh iq bd li np nq dn lm nr ns dp lq mh nt nu ls ml nv nw lu mp nx ny lw iw bi translated">命名实体识别</h2><p id="59dc" class="pw-post-body-paragraph ly lz iq ma b mb mc ka md me mf kd mg mh mi mj mk ml mm mn mo mp mq mr ms mt ij bi translated">命名实体识别(NER)是一项自然语言处理任务，旨在定位文本中提到的实体并将其分类到预定义的类别中(如人名、组织、位置等)。不同的方法处理这一任务以实现高精度:基于规则的系统，训练深度神经网络的方法或精细运行预训练语言模型的方法。例如，Spacy嵌入了一个预先训练的命名实体识别系统，该系统能够从文本中识别常见类别。</p><p id="1d68" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">我们现在着手建立一个NER系统，能够识别属于某个维基百科类别的文本片段。让我们考虑下面的例句:</p><p id="4e5a" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated"><em class="ol">“命名实体识别和主题建模是自然语言处理的两项任务”</em></p><p id="bf90" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">这句话潜在地包含了三个实体:<em class="ol">命名实体识别</em>、<em class="ol">主题建模</em>、<em class="ol">自然语言处理</em>。这三个实体都有属于特定类别的各自的维基百科页面。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi om"><img src="../Images/b8278f59f76d4db21cbb6972c584d73a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*N29S0mFlMbEmC1A9VKgmnA.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">维基百科类别结构示例(图片由作者提供)</p></figure><p id="7757" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">在这张图片中，我们可以看到不同的类别是如何分布在三个实体中的。在这种情况下，类别可以被看作是我们想要从文本中提取的实体的标签。我们现在可以利用SpikeX的两个特性来构建一个定制的NER系统，该系统接受两个输入变量:句子的(I)文本和我们想要检测的(ii)类别。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nz oa l"/></div></figure><pre class="kq kr ks kt gt oc od oe of aw og bi"><span id="017b" class="no lh iq od b gy oh oi l oj ok">Named Entity Recognition - COMPUTATIONAL LINGUISTIC<br/>Topic Modeling - COMPUTATIONAL LINGUISTIC<br/>Natural Language Processing - COMPUTATIONAL LINGUISTIC</span></pre><p id="8a5d" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">将维基百科的类别定义为NER任务的标签，使得定义NER系统避免数据训练问题成为可能。通过使用<em class="ol"> displacy </em>来表示我们基于维基百科类别的NER系统提取的实体，展示了另一个例子。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi on"><img src="../Images/f7d615241c9b2c73056ba48369da8132.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jQnQzXVxvYh7ZvbfJO_YQA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">NER摘录示例(图片由作者提供)</p></figure><p id="c2cd" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">在这个例子中，类别“编程语言”和“计算语言学”作为输入给出，然后在文本中搜索。</p><h2 id="6339" class="no lh iq bd li np nq dn lm nr ns dp lq mh nt nu ls ml nv nw lu mp nx ny lw iw bi translated">主题建模</h2><p id="26c4" class="pw-post-body-paragraph ly lz iq ma b mb mc ka md me mf kd mg mh mi mj mk ml mm mn mo mp mq mr ms mt ij bi translated">当谈到<strong class="ma ja">主题建模</strong>时，我们通常指的是能够发现文本主体的“隐藏语义结构”的NLP工具。最近，人们讨论到“为了自动文本分析的目的，主题的定义在某种程度上取决于所采用的方法”[1]。<strong class="ma ja">潜在狄利克雷分配(LDA) </strong>是流行的主题建模方法，使用概率模型从<em class="ol">组文档</em>中提取主题。另一个著名的方法是<strong class="ma ja"> TextRank </strong>，这是一种使用网络分析来检测单个文档中的主题的方法。最近，NLP中的高级研究还引入了能够在<em class="ol">句子级别</em>提取主题的方法。一个例子是<a class="ae lf" href="https://graphbrain.net/overview/hypergraph.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ma ja">语义超图</strong> </a> <strong class="ma ja">，</strong>“一种结合了机器学习和符号方法的优势，从句子的意思推断主题的新技术”[1]。</p><p id="9bef" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">我们现在看到如何使用维基百科在<em class="ol">句子</em>和<em class="ol">文档</em>级别执行主题建模。</p><p id="e9f7" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">让我们考虑来自专利<a class="ae lf" href="https://patents.google.com/patent/US20130097769A1/en" rel="noopener ugc nofollow" target="_blank"> US20130097769A1 </a>的以下文本。</p><blockquote class="oo op oq"><p id="b855" class="ly lz ol ma b mb mu ka md me mv kd mg or mw mj mk os mx mn mo ot my mr ms mt ij bi translated">封装的防护服可以在污染区域穿着，以保护该防护服的穿着者。例如，当在核动力发电厂内工作或在存在放射性物质的情况下工作时，工人可能穿着密封防护服。封装的防护服可以是一次性使用类型的系统，其中在一次使用后该防护服被丢弃。在正常操作条件下，封装的防护服可以通过连接到防护服的外部气流软管接收呼吸空气。例如，空气可以由用户携带的动力空气净化呼吸器(PAPR)提供。</p></blockquote><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nz oa l"/></div></figure><pre class="kq kr ks kt gt oc od oe of aw og bi"><span id="4d6b" class="no lh iq od b gy oh oi l oj ok">Sentence:<br/>Encapsulated protective suits may be worn in contaminated areas to protect the wearer of the suit. </span><span id="7c1b" class="no lh iq od b gy ou oi l oj ok">Topics in the sentence:<br/>   Safety -&gt; 1<br/>   Euthenics -&gt; 1 </span><span id="7a18" class="no lh iq od b gy ou oi l oj ok">----</span><span id="8e14" class="no lh iq od b gy ou oi l oj ok">Sentence:<br/>For example, workers may wear an encapsulated protective suit while working inside of a nuclear powered electrical generating plant or in the presence of radioactive materials.<br/>Topics in the sentence:<br/>   Safety -&gt; 1<br/>   Euthenics -&gt; 1<br/>   Electricity -&gt; 1<br/>   Electromagnetism -&gt; 1<br/>   Locale_(geographic) -&gt; 1<br/>   Electric_power_generation -&gt; 1<br/>   Power_stations -&gt; 1<br/>   Infrastructure -&gt; 1<br/>   Energy_conversion -&gt; 1<br/>   Chemistry -&gt; 1<br/>   Radioactivity -&gt; 1<br/>---- </span><span id="aa03" class="no lh iq od b gy ou oi l oj ok">Sentence:<br/>An encapsulated protective suit may be a one-time use type of system, wherein after a single use the suit is disposed of. </span><span id="2dc5" class="no lh iq od b gy ou oi l oj ok">Topics in the sentence:   <br/>   Safety -&gt; 1<br/>   Euthenics -&gt; 1<br/>   Transportation_planning -&gt; 1<br/>   Feminist_economics -&gt; 1<br/>   Schools_of_economic_thought -&gt; 1<br/>   Land_management -&gt; 1<br/>   Architecture -&gt; 1<br/>   Planning -&gt; 1<br/>   Transport -&gt; 1<br/>   Feminism -&gt; 1<br/>   Urban_planning -&gt; 1<br/>   Feminist_theory -&gt; 1<br/>   Urbanization -&gt; 1<br/>   Spatial_planning -&gt; 1<br/>   Social_sciences -&gt; 1<br/>----</span><span id="9740" class="no lh iq od b gy ou oi l oj ok">Sentence:<br/>An encapsulated protective suit may receive breathing air during normal operating conditions via an external air flow hose connected to the suit. </span><span id="9e5e" class="no lh iq od b gy ou oi l oj ok">Topics in the sentence:<br/>   Safety -&gt; 1<br/>   Euthenics -&gt; 1<br/>   Chemical_industry -&gt; 1<br/>   Gases -&gt; 1<br/>   Industrial_gases -&gt; 1<br/>   Breathing_gases -&gt; 1<br/>   Diving_equipment -&gt; 1<br/>   Respiration -&gt; 1<br/>   Electromechanical_engineering -&gt; 1<br/>   Heat_transfer -&gt; 1<br/>   Home_appliances -&gt; 1<br/>   Engineering_disciplines -&gt; 1<br/>   Automation -&gt; 1<br/>   Building_engineering -&gt; 1<br/>   Temperature -&gt; 1<br/>   Heating,_ventilation,_and_air_conditioning -&gt; 1   <br/>---- </span><span id="851f" class="no lh iq od b gy ou oi l oj ok">Sentence:<br/>The air may be supplied, for example, by a power air purifying respirator (PAPR) that may be carried by the user.</span><span id="9e1f" class="no lh iq od b gy ou oi l oj ok">Topics in the sentence:<br/>   Personal_protective_equipment -&gt; 1<br/>   Air_filters -&gt; 1<br/>   Respirators -&gt; 1<br/>   Protective_gear -&gt; 1<br/>----</span></pre><p id="efb3" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">专利文本的每个句子都用SpikeX处理，并从句子中检测到的相应维基百科页面中提取类别。我们认为主题是维基百科的类别。这样我们就有了第一个天真的话题检测。与语义超图、文本排名或LDA不同，这种方法在不直接引用术语的情况下找到句子主题的标签。所提取的主题标签指的是SpikeX匹配的维基百科页面的类别。如果我们使用这种方法来聚合每个句子的主题，我们就可以更好地表示整个文档。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ov"><img src="../Images/1ca294e8e198bc9c908f0a2d5af13476.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AWZAvBL5XRI8ci45qYvjVg.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">段落级别的主题检测(作者图片)</p></figure><p id="1bc7" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">对句子中类别的频率进行分类可以更广泛地查看文本的主题分布。“安全性”和“优效性”比其他类别出现得更频繁。</p><p id="9781" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">我们现在使用整个专利文本(可以在Google Patent中找到)来找到分类分布。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ow"><img src="../Images/96412633d19226dc75aa5cd79e387638.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E15UOhr-0TQ_b7o_NPGPrw.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">文档级别的主题检测(按作者分类的图片)</p></figure><p id="8cd7" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">正如我们所看到的，我们可以自动检测整个文档的主题(或类别)(在本例中是专利)。查看前5个类别，我们可以推断出专利是关于什么的。这是在没有任何培训前任务的情况下完成的。</p><h1 id="64d1" class="lg lh iq bd li lj lk ll lm ln lo lp lq kf lr kg ls ki lt kj lu kl lv km lw lx bi translated">结论</h1><p id="63f2" class="pw-post-body-paragraph ly lz iq ma b mb mc ka md me mf kd mg mh mi mj mk ml mm mn mo mp mq mr ms mt ij bi translated">十多年来，维基百科一直被用作知识的来源，并在各种应用中反复使用:文本注释、分类、索引、聚类、搜索和自动分类生成。事实上，维基百科的结构有许多有用的特性，使它成为这些应用程序的良好候选。</p><p id="ca40" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">这篇文章展示了如何通过使用这个强大的资源来改进简单的NLP任务。然而，这并不是说这种方法优于其他现有技术的方法。评估自然语言处理任务准确性的典型方法<em class="ol">精确度</em>和<em class="ol">召回率</em>在这篇文章中没有给出。</p><p id="b939" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">此外，这种方法有优点也有缺点。主要优点是避免了培训，从而减少了耗时的注释任务。可以将维基百科视为一个巨大的训练集，其贡献者来自世界各地。对于有监督的任务(如NER)和无监督的任务(如主题建模)都是如此。这种方法的缺点是双重的。首先，维基百科是一项公共服务，是一个由专家和非专家贡献的知识库。第二，从主题建模结果可以看出，自然语言的歧义性会导致有偏的表现。词义消歧和非专家驱动的数据管理显然会影响整个系统的可靠性。</p><p id="6855" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">然而，还有很大的改进余地。将维基百科视为NLP任务的大型开放知识库与即将到来的新范式转变相一致:所谓的<strong class="ma ja">人工通用智能</strong> ( <strong class="ma ja"> AGI </strong>)，即系统理解或学习人类可以完成的任何智力任务的假设能力。</p><p id="a6c5" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated">[1]梅内塞斯，特尔莫，和卡米尔罗斯。“语义超图。”<em class="ol"> arXiv预印本arXiv:1908.10784 </em> (2019)。</p></div><div class="ab cl ox oy hu oz" role="separator"><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc pd"/><span class="pa bw bk pb pc"/></div><div class="ij ik il im in"><p id="fe4a" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated"><em class="ol">我要感谢</em><a class="ae lf" href="https://www.errequadrosrl.com/" rel="noopener ugc nofollow" target="_blank"><strong class="ma ja"><em class="ol">Erre Quadro Srl</em></strong></a><em class="ol">，特别要感谢Paolo Arduin，他开发了SpikeX项目，使其成为开放访问项目。</em></p><p id="3a98" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated"><em class="ol">这个帖子是在研究实验室</em> <a class="ae lf" href="http://b4ds.unipi.it/" rel="noopener ugc nofollow" target="_blank"> <strong class="ma ja"> <em class="ol"> B4DS(数据科学的商业工程)</em> </strong> </a> <em class="ol">的帮助下概念化和设计的。我要感谢团队，我的博士同事和导师，他们帮助我写了这篇文章。</em></p><p id="6202" class="pw-post-body-paragraph ly lz iq ma b mb mu ka md me mv kd mg mh mw mj mk ml mx mn mo mp my mr ms mt ij bi translated"><em class="ol">见我最新发表在PlOs one上的《</em> <a class="ae lf" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0244175" rel="noopener ugc nofollow" target="_blank"> <em class="ol">快速检测压力下的快速创新新冠肺炎</em> </a> <em class="ol">》。</em></p></div></div>    
</body>
</html>