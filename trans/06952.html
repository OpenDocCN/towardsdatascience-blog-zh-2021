<html>
<head>
<title>Wav2Vec 2.0: A Framework for Self-Supervised Learning of Speech Representations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Wav2Vec 2.0:语音表示的自我监督学习框架</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/wav2vec-2-0-a-framework-for-self-supervised-learning-of-speech-representations-7d3728688cae?source=collection_archive---------1-----------------------#2021-06-24">https://towardsdatascience.com/wav2vec-2-0-a-framework-for-self-supervised-learning-of-speech-representations-7d3728688cae?source=collection_archive---------1-----------------------#2021-06-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="9868" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><div class=""><h2 id="0242" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">解释语音识别模型</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/cd113c0b004a112471169cf510c6bb50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bfdCDegptoeb0SKcpoFn8g.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片由<a class="ae le" href="https://pl.freepik.com/snowing" rel="noopener ugc nofollow" target="_blank">下雪</a>发自<a class="ae le" href="https://pl.freepik.com/darmowe-zdjecie/pojecie-audiobooku-ksiazki-na-stol-ze-sluchawkami-na-nich_1203112.htm#page=1&amp;query=audiobook&amp;position=0" rel="noopener ugc nofollow" target="_blank">Freepik.com</a></p></figure><p id="f714" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Wav2Vec 2.0是自动语音识别的当前最新模型之一，这是由于在该领域中自我监督训练是一个相当新的概念。这种训练方式允许我们在未标记的数据上预先训练模型，这总是更容易获得。然后，可以针对特定目的在特定数据集上对模型进行微调。正如以前的作品所显示的，这种训练方式是非常有力的[4]。</p><h1 id="ffe6" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">主要思想</h1><p id="6885" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">如下图所示，模型分两个阶段进行训练。第一阶段是在自我监督模式下，这是使用未标记的数据完成的，其目的是尽可能实现最佳的语音表示。你可以用类似于思考单词嵌入的方式来思考这个问题。单词嵌入还旨在实现自然语言的最佳表示。主要区别在于Wav2Vec 2.0处理的是音频而不是文本。训练的第二阶段是监督微调，在此期间，标记的数据被用来教导模型预测特定的单词或音素。如果你不熟悉“音素”这个词，你可以把它想成特定语言中最小的声音单位，通常用一两个字母来表示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi my"><img src="../Images/fcc5c886fba3bcfbe5bcc9c7e2bd7ad1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cB8LcWJAalOTXZCL3Ig9TA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图一。Wav2Vec 2.0的训练阶段(图片由作者提供)</p></figure><p id="7088" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第一阶段的培训是这种模式的主要优势。学习一个非常好的语音表示能够在少量的标记数据上实现最先进的结果。例如，该论文的作者已经在一个巨大的LibriVox数据集上对模型进行了预训练。然后，他们使用整个Libri语音数据集进行微调，在测试清理子集上产生了1.8% <em class="mz">的单词错误率(WER) </em>，在测试其他子集上产生了3.3%的WER。使用少了近10倍的数据，允许在测试-清理上获得2.0%的WER，在测试-其他上获得4.0%。仅使用10分钟的标记训练数据(几乎没有数据)，在Libri语音的test-clean / test-other子集上产生4.8% / 8.2%的WER。根据代码为的<em class="mz">论文，它在2018年1月将会达到最先进的水平[5]。</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi na"><img src="../Images/7d86718e2342f2606400f15345b5acfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KwSxR7FEf5AKsJze5z7jOQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图二。Wav2Vec 2.0的结果(图片由作者提供)</p></figure><h1 id="484e" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">Wav2Vec 2.0模型架构</h1><p id="75d8" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">用于预测的最终模型的架构包括三个主要部分:</p><ul class=""><li id="7782" class="nb nc iq lh b li lj ll lm lo nd ls ne lw nf ma ng nh ni nj bi translated">处理原始波形输入以获得潜在表示的卷积层-<strong class="lh ja"><em class="mz"/></strong>，</li><li id="b627" class="nb nc iq lh b li nk ll nl lo nm ls nn lw no ma ng nh ni nj bi translated">变形金刚图层，创造情境化的表现- <strong class="lh ja"> <em class="mz"> C </em> </strong>，</li><li id="650d" class="nb nc iq lh b li nk ll nl lo nm ls nn lw no ma ng nh ni nj bi translated">线性投影到输出-<strong class="lh ja"><em class="mz"/></strong>。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi np"><img src="../Images/9a0c97c1ea8a684522ea825343b3faf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZM1_82T5btyH7pzDPkBjjw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图3。微调的Wav2Vec 2.0模型架构(图片由作者提供，基于wav2vec 2.0:语音表示的自我监督学习框架)</p></figure><p id="411c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这就是模型经过最终微调后的样子，可以在生产环境中开发了。整个魔术发生在训练的第一阶段，在自我监督模式下，当模型看起来有点不一样。该模型在没有线性投影生成输出预测的情况下被训练。</p><p id="bff3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">基本上，本文<em class="mz">主旨</em>部分提到的语音表征对应于图4中的‘语境表征<strong class="lh ja"><em class="mz">C</em></strong>’。预训练的主要思想类似于BERT:变换器的部分输入被屏蔽，目的是猜测屏蔽的潜在特征向量表示<strong class="lh ja"><em class="mz"/></strong>。然而，作者用对比学习改进了这个简单的想法。</p><h2 id="9004" class="nq mc iq bd md nr ns dn mh nt nu dp ml lo nv nw mn ls nx ny mp lw nz oa mr iw bi translated">对比学习</h2><p id="50c1" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">对比学习是一个输入以两种不同方式转化的概念。之后，模型被训练以识别输入的两个变换是否仍然是相同的对象。在Wav2Vec 2.0中，变换层是第一种变换方式，第二种方式是通过量化，这将在本文的后续部分进行解释。更正式地说，对于一个被掩蔽的潜在表征<strong class="lh ja"><em class="mz">【zₜ】</em></strong>，我们希望得到这样一个上下文表征<strong class="lh ja"><em class="mz">【cₜ】</em></strong>以便能够在其他量化表征中猜出正确的量化表征<strong class="lh ja"><em class="mz">【qₜ】</em></strong>。很好地理解前面的句子是很重要的，所以如果你需要的话，不要犹豫就此打住:-)用于自我监督训练的Wav2Vec 2.0版本如图4所示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ob"><img src="../Images/14be05c26a11c321f5ac78ec89a84732.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P38rp1OvC5evoiNuceHS6g.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图4。用于自我监督训练的Wav2Vec 2.0模型架构(图片由作者提供，基于wav2vec 2.0:语音表示的自我监督学习框架)</p></figure><p id="d824" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了总结我们到目前为止所学的内容，请看看表1。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oc"><img src="../Images/2065d7e77eaec8e7c483dd84b593eb9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l56ATz8kjlYP0SW2tl1JlA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">表1。Wav2Vec 2.0自我监督学习和监督学习的比较</p></figure><h2 id="550c" class="nq mc iq bd md nr ns dn mh nt nu dp ml lo nv nw mn ls nx ny mp lw nz oa mr iw bi translated">量化</h2><p id="29ea" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">量化是将连续空间中的值转换为离散空间中有限的一组值的过程。</p><p id="1de2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">但是我们如何在自动语音识别中实现这一点呢？让我们假设一个潜在语音表示向量<strong class="lh ja"> <em class="mz">、zₜ </em> </strong>覆盖两个音素。一种语言中音位的数量是有限的。此外，所有可能的音素对的数量是有限的。这意味着它们可以被相同的潜在语音表征完美地表征。此外，它们的数量是有限的，所以我们可以创建一个包含所有可能的音素对的码本。然后，量化归结为从码本中选择正确的码字。然而，你可以想象所有可能的声音的数量是巨大的。为了更容易训练和使用，Wav2Vec 2.0的作者创建了<em class="mz"> G </em>码书，每个码书都由<em class="mz"> V </em>码字组成。为了创建量化表示，应该从每个码本中选择最佳字。然后，将选择的向量连接起来，用线性变换进行处理，以获得量化的表示。该过程如图5所示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi od"><img src="../Images/4e4143887a07a2a6935194aa3f57585a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YpuCXk6Q_6wvDD2T7tI3QQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图5。量化(作者图片)</p></figure><p id="f6c7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们如何从每个码本中选择最佳码字？答案是<strong class="lh ja"> Gumbel softmax </strong>:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/1bbacf3533762de43d45840deb21fa80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*xCvPxHSFXqvqQ6TuG0Kw2A.png"/></div></figure><p id="dfdd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">其中:</p><ul class=""><li id="1676" class="nb nc iq lh b li lj ll lm lo nd ls ne lw nf ma ng nh ni nj bi translated"><strong class="lh ja"><em class="mz">sim</em></strong>——<em class="mz">余弦相似度</em>，</li><li id="f60c" class="nb nc iq lh b li nk ll nl lo nm ls nn lw no ma ng nh ni nj bi translated"><strong class="lh ja"><em class="mz">l</em></strong><em class="mz">ϵℝ</em><strong class="lh ja"><em class="mz">ᴳˣ</em></strong><em class="mz">ⱽ</em>—logits由<strong class="lh ja"> <em class="mz"> z </em> </strong>计算得出，</li><li id="6485" class="nb nc iq lh b li nk ll nl lo nm ls nn lw no ma ng nh ni nj bi translated"><strong class="lh ja"><em class="mz"/></strong><em class="mz">=-log(-log(uₖ)、</em></li><li id="b7a5" class="nb nc iq lh b li nk ll nl lo nm ls nn lw no ma ng nh ni nj bi translated"><strong class="lh ja"> <em class="mz"> uₖ </em> </strong> <em class="mz"> </em>从均匀分布<em class="mz"> U(0，1) </em>中取样，</li><li id="2c71" class="nb nc iq lh b li nk ll nl lo nm ls nn lw no ma ng nh ni nj bi translated">𝜏——温度。</li></ul><p id="2aa0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">由于这是一项分类任务，softmax函数似乎是在每个码本中选择最佳码字的自然选择。为什么在我们的例子中，<em class="mz"> Gumbel softmax </em>比普通的<em class="mz"> softmax </em>好？它有两个改进:随机化和温度<strong class="lh ja"> 𝜏 </strong>。由于随机化，模型更愿意在训练期间选择不同的码字，然后更新它们的权重。重要的是，特别是在训练的开始，防止只使用代码簿的子集。温度随着时间从2降低到0.5，因此随机化的影响随着时间变小。</p><h2 id="fe94" class="nq mc iq bd md nr ns dn mh nt nu dp ml lo nv nw mn ls nx ny mp lw nz oa mr iw bi translated">掩饰</h2><p id="5e0b" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">让我们深入到掩蔽的细节。它由两个超参数定义:<strong class="lh ja"><em class="mz">p</em></strong>= 0.065<strong class="lh ja"><em class="mz"/></strong>和<strong class="lh ja"> <em class="mz"> M </em> </strong> = 10，并按以下步骤进行:</p><ol class=""><li id="a93f" class="nb nc iq lh b li lj ll lm lo nd ls ne lw nf ma of nh ni nj bi translated">从潜在言语表征的空间中取出所有时间步骤<strong class="lh ja"> <em class="mz"> Z </em> </strong>。</li><li id="8eed" class="nb nc iq lh b li nk ll nl lo nm ls nn lw no ma of nh ni nj bi translated">样品没有替换比例<strong class="lh ja"> <em class="mz"> p </em> </strong>来自上一步的向量。</li><li id="89a6" class="nb nc iq lh b li nk ll nl lo nm ls nn lw no ma of nh ni nj bi translated">选择的时间步长是起始索引。</li><li id="c581" class="nb nc iq lh b li nk ll nl lo nm ls nn lw no ma of nh ni nj bi translated">对于每个索引<strong class="lh ja"> <em class="mz"> i </em> </strong>，连续的<strong class="lh ja"> <em class="mz"> M </em> </strong>时间步长被屏蔽。</li></ol><p id="a7d9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如下图所示，我们采样了两个标有橙色的向量作为起始索引。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi og"><img src="../Images/4c0a07d3034d8121a6181c5cd3faa0ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aRt-1nIMNiIwDVxio0sIIQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图6。选择蒙版的起始索引(图片由作者提供)</p></figure><p id="61bf" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后，从每个选择的向量开始，<strong class="lh ja"> <em class="mz"> M </em> </strong> = 10个连续的时间步长被屏蔽。跨度可能重叠，由于它们之间的间隙等于3个时间步长，我们屏蔽了14个连续的时间步长。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oh"><img src="../Images/4735ac48a96336384e6d16f7d1b89fda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dZxI9UHaYqA0U2x3o3Lw8g.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图7。屏蔽M个连续的时间步长(图片由作者提供)</p></figure><p id="8202" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后，对比损失仅针对掩模的中心时间步长进行计算。</p><h2 id="eb24" class="nq mc iq bd md nr ns dn mh nt nu dp ml lo nv nw mn ls nx ny mp lw nz oa mr iw bi translated">培训目标</h2><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/8fa250d41e6ad71c26454aef82f660f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*RrVVQmLzy_61lu8C7spddA.png"/></div></figure><p id="c74c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">训练目标是两个损失函数之和:<strong class="lh ja">对比损失</strong>和<strong class="lh ja">多样性损失</strong>。目前，只提到了对比损失。它负责训练模型来预测<em class="mz"> K + 1 </em>量化候选表示<strong class="lh ja"><em class="mz">q’</em></strong><em class="mz">∈</em><strong class="lh ja"><em class="mz">qₜ.中正确的量化表示<strong class="lh ja"> <em class="mz"> qₜ </em> </strong></em> </strong>集合<strong class="lh ja"> <em class="mz"> Qₜ </em> </strong>由目标<strong class="lh ja"> <em class="mz"> qₜ </em> </strong>和<em class="mz"> K </em>干扰子组成，这些干扰子是从其他掩码时间步中均匀采样的。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/02d3c77b1928e0f21df11d7e1f5d66ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*w9sohMXQgqCuO9ZM0Dzbiw.png"/></div></figure><p id="36f7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">字母<strong class="lh ja"> κ </strong>是训练过程中恒定的温度。<em class="mz"> Sim </em>代表<em class="mz">余弦相似度</em>。函数的主要部分<strong class="lh ja"><em class="mz"/></strong>类似于softmax，但是我们取上下文表示<strong class="lh ja"><em class="mz">【cₜ</em></strong>和量化表示<strong class="lh ja"> <em class="mz"> q </em> </strong>之间的<em class="mz">余弦相似度</em>。为了更容易优化，我们还将<em class="mz"> -log </em>放在那个分数上。</p><p id="79b1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">多样性损失</strong>是一种正则化技术。作者设置了<strong class="lh ja"> <em class="mz"> G </em> </strong> =2个码本，每个码本中有<strong class="lh ja"> <em class="mz"> V </em> </strong> =320个码字。理论上它给出了320*320=102400个可能的量化表示。然而，我们不知道该模型是否真的会使用所有这些可能性。否则，它将仅学习使用例如来自每个码本的100个码字，并且它将浪费码本的全部潜力。这就是多样性损失有用的原因。它基于熵，熵可通过以下公式计算:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/9047d6b97ce06bab96cd88dc1faeb088.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9sAC9Kqgg3zjXJCBFtTu7g.png"/></div></div></figure><p id="13ad" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">其中:</p><ul class=""><li id="70f9" class="nb nc iq lh b li lj ll lm lo nd ls ne lw nf ma ng nh ni nj bi translated"><strong class="lh ja"> <em class="mz"> x </em> </strong> —离散随机变量𝒳的一种可能结果，</li><li id="9f9f" class="nb nc iq lh b li nk ll nl lo nm ls nn lw no ma ng nh ni nj bi translated"><strong class="lh ja"> <em class="mz"> P(x) </em> </strong> —事件发生的概率<strong class="lh ja"> <em class="mz"> x </em> </strong>。</li></ul><p id="850b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当数据分布均匀时，熵取最大值。在我们的例子中，这意味着所有的码字都以相同的频率使用。这样，我们可以在整批训练样本上计算每个码本的熵，以检查码字是否以相同的频率使用。这个熵的最大化将鼓励模型利用所有码字。最大化等于负熵最小化，负熵是多样性损失。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ol"><img src="../Images/7658e3e8b12367322730d022cd3c283e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MR3ZHLpDZu0RiPHa9U_BjA.png"/></div></div></figure><h2 id="202d" class="nq mc iq bd md nr ns dn mh nt nu dp ml lo nv nw mn ls nx ny mp lw nz oa mr iw bi translated">微调</h2><p id="f22f" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">由于Wav2Vec 2.0的微调阶段并不包含任何突破性的发现，所以作者并没有太关注他们论文的这一部分。在训练的这个阶段，不使用量化。取而代之的是，在上下文表示<strong class="lh ja"> <em class="mz"> C </em> </strong>的顶部添加一个随机初始化的线性投影层。然后用标准的<em class="mz">连接主义者时态分类(CTC) </em> loss和一个修改版本的<em class="mz"> SpecAugment </em>对模型进行微调，这超出了本文的范围。有趣的是，作者并没有放弃掩蔽，因为它仍然可以作为一种正则化技术。</p><h1 id="c6ad" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">结论</h1><p id="d01f" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">Wav2Vec 2.0使用自我监督的训练方法进行自动语音识别，该方法基于<em class="mz">对比学习</em>的思想。在巨大的原始(未标记)数据集上学习语音表示减少了获得满意结果所需的标记数据量。</p><p id="3a46" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这篇文章的要点是:</p><ul class=""><li id="16db" class="nb nc iq lh b li lj ll lm lo nd ls ne lw nf ma ng nh ni nj bi translated">Wav2Vec 2.0利用了自我监督的训练，</li><li id="b059" class="nb nc iq lh b li nk ll nl lo nm ls nn lw no ma ng nh ni nj bi translated">它使用卷积层来预处理原始波形，然后应用变换器来增强具有上下文的语音表示，</li><li id="f830" class="nb nc iq lh b li nk ll nl lo nm ls nn lw no ma ng nh ni nj bi translated">其目标是两个损失函数的加权和:</li><li id="37e0" class="nb nc iq lh b li nk ll nl lo nm ls nn lw no ma ng nh ni nj bi translated">对比损失，</li><li id="d70e" class="nb nc iq lh b li nk ll nl lo nm ls nn lw no ma ng nh ni nj bi translated">多样性丧失，</li><li id="f466" class="nb nc iq lh b li nk ll nl lo nm ls nn lw no ma ng nh ni nj bi translated">量化用于在自我监督学习中创建目标。</li></ul><p id="2547" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我希望你喜欢我的文章，它能帮助你理解Wav2Vec 2.0的思想。要了解更多细节，我鼓励你阅读原文[1]。</p><h1 id="f952" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">参考</h1><p id="16dc" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">[1] A. Baevski，H. Zhou，A. Mohamed和M. Auli，<a class="ae le" href="https://arxiv.org/pdf/2006.11477.pdf" rel="noopener ugc nofollow" target="_blank"> wav2vec 2.0:语音表征的自我监督学习框架</a> (2020)，CoRR</p><p id="21be" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[2] A. Kim，<a class="ae le" rel="noopener" target="_blank" href="/the-intuition-behind-shannons-entropy-e74820fe9800">香农熵背后的直觉</a> (2018)，走向数据科学</p><p id="d761" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[3] <a class="ae le" href="https://en.wikipedia.org/wiki/Entropy_(information_theory)" rel="noopener ugc nofollow" target="_blank">熵(信息论)</a>，维基百科。</p><p id="d1fc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[4] J. Devlin，M. Chang，K. Lee，K. Toutanova，<a class="ae le" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank"> BERT:用于语言理解的深度双向变压器的预训练</a> <em class="mz"> </em> (2019) <em class="mz">。</em></p><p id="ffa1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[5]<a class="ae le" href="https://paperswithcode.com/sota/speech-recognition-on-librispeech-test-clean" rel="noopener ugc nofollow" target="_blank">LibriSpeech上的语音识别测试-clean </a>，<em class="mz"> </em>试卷用代码。</p></div></div>    
</body>
</html>