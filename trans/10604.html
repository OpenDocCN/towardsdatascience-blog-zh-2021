<html>
<head>
<title>Automatic Video Editing using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python自动编辑视频</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automatic-video-editing-using-python-324e5efd7eba?source=collection_archive---------11-----------------------#2021-10-11">https://towardsdatascience.com/automatic-video-editing-using-python-324e5efd7eba?source=collection_archive---------11-----------------------#2021-10-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6df6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用Python库moviepy和vosk实现语音控制或删除视频中的无声片段</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/487036b5d0c976d699eb444e4cba7b50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LetzUw2pVvoi9jRLkBJcNA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@peter_s?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Peter Stumpf </a>在<a class="ae ky" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="1728" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">视频剪辑总是很繁琐。移除不必要的视频片段并不是一项困难的任务，而是一项漫长的任务。您需要完整地查看视频(可能不止一次！)，选择所有你需要的片段，加入它们然后渲染视频很长时间。简单剪辑一个小时的视频一般要三个多小时！所以我才有了这个想法。</p><p id="a679" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当然，替代方案是存在的。比如<a class="ae ky" href="https://www.wisecat.video/" rel="noopener ugc nofollow" target="_blank"> wisecat </a>，它能做的远不止“视频剪辑”。但是我想做一个快速、简单、免费的程序。Python库<a class="ae ky" href="https://zulko.github.io/moviepy/" rel="noopener ugc nofollow" target="_blank"> moviepy </a>和<a class="ae ky" href="https://alphacephei.com/vosk/" rel="noopener ugc nofollow" target="_blank"> vosk </a>会帮我做这件事。</p><h1 id="0827" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">问题陈述</h1><p id="443e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我想建立一个程序，它会自动剪切一些视频片段，然后将这些片段连接在一起。它必须以两种方式接收关于这些片段的数据:</p><ul class=""><li id="f7f6" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">自动(<em class="nb">部分自动</em>，有一些人工干预)——识别控制字，以及</li><li id="dfe1" class="ms mt it lb b lc nc lf nd li ne lm nf lq ng lu mx my mz na bi translated">自动(<em class="nb">全自动</em>，无需人工干预)——识别长时间的静默</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/37f96278b36e5c1ac10cb53bacade108.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LoI9Kwl3eVgLvtQ_5swkZQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">解决视频自动编辑问题的两种方法。作者图片</p></figure><p id="caa1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该任务可分为以下子任务:</p><ol class=""><li id="a566" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu ni my mz na bi translated">了解如何使用moviepy编辑视频</li><li id="17fe" class="ms mt it lb b lc nc lf nd li ne lm nf lq ng lu ni my mz na bi translated">识别控制字/静音及其时间戳</li><li id="26e4" class="ms mt it lb b lc nc lf nd li ne lm nf lq ng lu ni my mz na bi translated">将这两个部件连接在一起</li></ol><h1 id="c661" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">使用Moviepy编辑视频</h1><p id="58ac" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">首先，让我们尝试使用<em class="nb"> moviepy </em>库裁剪并加入视频。</p><p id="460a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这非常简单——将源视频读入一个<code class="fe nj nk nl nm b">VideoFileClip</code>对象后，我们可以用构建的方法做很多事情。我们将需要下列各项:</p><ul class=""><li id="6707" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated"><code class="fe nj nk nl nm b">video.subclip(start_seconds, end_seconds)</code>返回视频片段，从<code class="fe nj nk nl nm b">start_seconds</code>的<code class="fe nj nk nl nm b">video</code>切到<code class="fe nj nk nl nm b">end_seconds</code></li><li id="b27f" class="ms mt it lb b lc nc lf nd li ne lm nf lq ng lu mx my mz na bi translated">和<code class="fe nj nk nl nm b">concatenate_videoclips(clips)</code>，它们加入来自<code class="fe nj nk nl nm b">clips</code>列表的所有视频片段。</li></ul><p id="5921" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将您需要的所有<code class="fe nj nk nl nm b">(start_seconds, end_seconds)</code>对的列表放入<code class="fe nj nk nl nm b">segments</code>变量中。现在，您可以使用下面的代码从片段中制作一个视频。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="583b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事实上，这个简单的程序已经非常有用了。它可以处理简单的任务(修剪视频的开头/结尾，剪切所需的片段)，比专业的视频编辑程序(索尼维加斯等)快得多。</p><p id="be06" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们所要做的就是从一个智能系统中得到这些配对(<code class="fe nj nk nl nm b">segments</code>)。</p><h1 id="3885" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">带时间戳的语音识别概述</h1><p id="c555" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这项任务更加复杂。作为搜索和试验的结果，我决定使用<a class="ae ky" href="https://alphacephei.com/vosk/" rel="noopener ugc nofollow" target="_blank"> vosk API </a>。在本文的<a class="ae ky" rel="noopener" target="_blank" href="/speech-recognition-with-timestamps-934ede4234b2">中，我描述了一个关于如何用时间戳实现语音识别的详细教程。但是我也将在这里简要地描述一下最重要的几点。</a></p><div class="np nq gp gr nr ns"><a rel="noopener follow" target="_blank" href="/speech-recognition-with-timestamps-934ede4234b2"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd iu gy z fp nx fr fs ny fu fw is bi translated">带有时间戳的语音识别</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">使用Python和vosk API进行离线和免费语音识别</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">towardsdatascience.com</p></div></div><div class="ob l"><div class="oc l od oe of ob og ks ns"/></div></div></a></div><p id="2cc6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们需要从视频文件中识别语音。正如我在上面的文章中解释的，vosk语音识别模型输出一个JSON字典列表，其中包含每个识别单词的四个参数— <code class="fe nj nk nl nm b">confidence</code>、<code class="fe nj nk nl nm b">start time</code>、<code class="fe nj nk nl nm b">end time</code>和识别的<code class="fe nj nk nl nm b">word</code>(文本)。我创建了一个自定义的<code class="fe nj nk nl nm b">Word</code>类，按照这个格式描述单词。</p><p id="e35a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面的代码使用<code class="fe nj nk nl nm b">model_path</code> vosk模型识别<code class="fe nj nk nl nm b">audio_filename</code>文件，并输出一个<code class="fe nj nk nl nm b">Word</code>对象列表。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><h1 id="ba16" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">识别控制字</h1><p id="fbd5" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我们知道每个单词的发音时间。太好了！现在我们需要选择控制词——这里有发挥创造力的空间。</p><p id="84a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们需要两个——剪切片段的开始和结束。不能只用<em class="nb">启动</em>和<em class="nb">停止</em>。其实当然可以，只是不能确定在平时的讲话中不会说这些话。如果你说，程序将无法正常运行。最初，我决定使用一些罕见的英语单词，如<em class="nb">睿智</em>和<em class="nb">过分</em>。但结果是生僻字识别更差，非常生僻的可能根本不在字典里。也是在这一刻，我意识到口音对语音识别质量的影响有多大。因为我的母语不是英语，所以我决定采用更简单的解决方案。</p><p id="49da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我决定只使用我的母语中的单词<em class="nb">开始</em>和<em class="nb">结束</em>。由于vosk有国外的模型，你可以用你的母语模型识别英语语音。文字会被认定为废话，但我们不需要，对吧？主要是<em class="nb">控制字将被正确识别</em>。在俄语中，它们分别被写成<strong class="lb iu"> начало </strong>和<strong class="lb iu"> конец </strong>，读作<strong class="lb iu">纳哈罗</strong>和<strong class="lb iu"> konets </strong>。第一个字表示要剪切的片段的开始，第二个字表示其结束。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/c3988e1e997abf372cd1bd5ccf3bd408.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eyGsrehpxSTPTqGFIaQNcw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用俄语模型的英语语音识别示例。作者图片</p></figure><p id="de89" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">也可以将英文单词的<em class="nb">组合识别为控制命令。你甚至可以进一步识别声音——例如，手指点击或鼓掌。然而，它对我来说似乎不太方便。</em></p><p id="a317" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们需要迭代<code class="fe nj nk nl nm b">list_of_words</code>并检查识别的单词是否是控制单词之一。如果是，那么我们记住时间(开始时间为<code class="fe nj nk nl nm b">start_word</code>，结束时间为<code class="fe nj nk nl nm b">end_word</code>)。我还创建了<code class="fe nj nk nl nm b">offset</code>变量来确保视频的裁剪不会太尖锐。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="a949" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，剩下的就是将<code class="fe nj nk nl nm b">segments</code>变量传递给<strong class="lb iu">用Moviepy </strong>编辑视频部分的代码片段！</p><h1 id="6b44" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">识别沉默</h1><p id="cee8" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">另一种选择是删除静默持续时间超过某个阈值(例如2秒)的时刻。这里几乎所有的东西我们都已经很熟悉了。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><blockquote class="oi"><p id="b47d" class="oj ok it bd ol om on oo op oq or lu dk translated">这种方法是完全自动化的，在视频记录期间或之后不需要任何人工干预。你只要指定视频的路径，就能获得没有静默瞬间的视频。</p></blockquote><h1 id="5601" class="lv lw it bd lx ly lz ma mb mc md me mf jz os ka mh kc ot kd mj kf ou kg ml mm bi translated">最终计划</h1><p id="dc7d" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">程序的两个主要部分已经准备好了，我们只需要把它们连接起来。唯一没有描述的是视频到单声道音频的转换。但是moviepy可以轻松应对这种情况。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><h2 id="6e53" class="ov lw it bd lx ow ox dn mb oy oz dp mf li pa pb mh lm pc pd mj lq pe pf ml pg bi translated">项目结构</h2><p id="fbb3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">带有详细注释的完整程序可在<a class="ae ky" href="https://gitlab.com/Winston-90/automatic_video_editing/" rel="noopener ugc nofollow" target="_blank">本GitLab报告</a>中获得。</p><div class="np nq gp gr nr ns"><a href="https://gitlab.com/Winston-90/automatic_video_editing/" rel="noopener  ugc nofollow" target="_blank"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd iu gy z fp nx fr fs ny fu fw is bi translated">Dmytro Nikolaiev /自动视频编辑</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">使用Python、moviepy和vosk进行自动视频编辑</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">gitlab.com</p></div></div><div class="ob l"><div class="ph l od oe of ob og ks ns"/></div></div></a></div><p id="c31a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该项目的结构如下:</p><pre class="kj kk kl km gt pi nm pj pk aw pl bi"><span id="4f0f" class="ov lw it nm b gy pm pn l po pp">automatic_video_editing<br/>├───article<br/>├───models<br/>│   ├───vosk-model-en-us-0.21<br/>│   └───vosk-model-ru-0.10<br/>├───videos<br/>│   .gitignore<br/>│   <br/>│   automatic_video_cutter.ipynb<br/>│   automatic_video_cutter.py<br/>│   Word.py<br/>│<br/>│   README.md<br/>└── requirements.txt</span></pre><p id="1a85" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它包含以下文件夹:</p><ul class=""><li id="346f" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated"><code class="fe nj nk nl nm b">article</code>文件夹包含本教程的数据。</li><li id="63aa" class="ms mt it lb b lc nc lf nd li ne lm nf lq ng lu mx my mz na bi translated"><code class="fe nj nk nl nm b">models</code>文件夹包含从<a class="ae ky" href="https://alphacephei.com/vosk/models" rel="noopener ugc nofollow" target="_blank">官方网站</a>下载的vosk模型。</li><li id="3781" class="ms mt it lb b lc nc lf nd li ne lm nf lq ng lu mx my mz na bi translated"><code class="fe nj nk nl nm b">videos</code>文件夹包含要处理的视频。</li></ul><p id="8432" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">和代码文件:</p><ul class=""><li id="19b8" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated"><code class="fe nj nk nl nm b">Word.py</code>文件描述了<code class="fe nj nk nl nm b">Word</code>类。</li><li id="9ba4" class="ms mt it lb b lc nc lf nd li ne lm nf lq ng lu mx my mz na bi translated"><code class="fe nj nk nl nm b">automatic_video_cutter.ipynb</code>笔记本包含一个完整的程序。</li><li id="8635" class="ms mt it lb b lc nc lf nd li ne lm nf lq ng lu mx my mz na bi translated"><code class="fe nj nk nl nm b">automatic_video_cutter.py</code>文件包含相同的完整程序，但以python脚本的形式。不用<a class="ae ky" href="https://jupyter.org/" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a>也能用来运行程序。</li></ul><p id="4de5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">参见<code class="fe nj nk nl nm b">README.md</code>获取用户手册。</p><h1 id="b05b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结果和结论</h1><p id="5e1c" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">因此，程序的工作方式如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pq no l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用Python自动编辑视频Youtube上的控制词</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pq no l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用Python自动编辑视频——消除Youtube上的静默时刻</p></figure><p id="c00c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我对结果很满意，但是还有很多时间需要讨论。</p><h2 id="25f1" class="ov lw it bd lx ow ox dn mb oy oz dp mf li pa pb mh lm pc pd mj lq pe pf ml pg bi translated">支持的视频格式</h2><p id="0d3e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">首先，关于<strong class="lb iu">支持的格式</strong>。该程序使用<em class="nb"> moviepy </em>，并且<em class="nb"> moviepy </em>支持<em class="nb"> ffmpeg </em>支持的所有视频扩展。ogv，. mp4，.mpeg，。avi，。mov，。mkv等。</p><h2 id="7ad0" class="ov lw it bd lx ow ox dn mb oy oz dp mf li pa pb mh lm pc pd mj lq pe pf ml pg bi translated">执行时间</h2><p id="6486" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">接下来，关于执行时间。我用不同长度的视频(从1分钟到17分钟)测试了这个程序几次。基于这些实验，我可以说<strong class="lb iu">完整视频处理的时间小于原始视频文件</strong>的长度。执行时间可能因硬件而异，但比例将保持不变。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pr"><img src="../Images/c8632271a0567ea7e9f2c5d1c5daba25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EPhdNuFn1-rF_uQr5OEOjQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">17分钟视频的程序执行时间。作者图片</p></figure><p id="d367" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，你需要阅读沃斯克模型。但是这个阶段是恒定的(不依赖于视频的长度)，大约需要30秒。该计划有四个主要阶段:</p><ul class=""><li id="9a03" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated"><strong class="lb iu">将视频转换为音频</strong> —不是在固定时间内执行，而是非常快速地执行(不到视频初始长度的1%)</li><li id="604b" class="ms mt it lb b lc nc lf nd li ne lm nf lq ng lu mx my mz na bi translated"><strong class="lb iu">使用Vosk型号的语音识别</strong> —实验表明，你需要大约<code class="fe nj nk nl nm b">0.2*X</code>秒来识别持续时间<code class="fe nj nk nl nm b">X</code>秒的音频。</li><li id="737e" class="ms mt it lb b lc nc lf nd li ne lm nf lq ng lu mx my mz na bi translated"><strong class="lb iu">分析识别出的文本，得到</strong> <code class="fe nj nk nl nm b">segments</code> —立即执行。在处理一分钟长的视频和17分钟长的视频时，我没有注意到区别。</li><li id="9dd3" class="ms mt it lb b lc nc lf nd li ne lm nf lq ng lu mx my mz na bi translated"><strong class="lb iu">渲染</strong> —最长的阶段。使用默认参数，它的执行需要大约<code class="fe nj nk nl nm b">0.5*X</code>时间。</li></ul><h2 id="a8c7" class="ov lw it bd lx ow ox dn mb oy oz dp mf li pa pb mh lm pc pd mj lq pe pf ml pg bi translated">视频质量</h2><p id="e246" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">探究执行时间后产生的问题是——质量呢？毕竟渲染越快，质量越差。这里的渲染速度非常快。</p><p id="c92e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">是的，它是。渲染是使用<code class="fe nj nk nl nm b">write_videofile</code> <em class="nb"> moviepy </em>方法完成的，它有很多参数。我使用了它的默认值。</p><p id="afb4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">渲染我就不多说了，最重要的参数就是<code class="fe nj nk nl nm b">bitrate</code>。比特率是单位时间内用于处理信息的位数<strong class="lb iu">。使用的比特率越多，质量就越好。同时，你的文件也会变大。</strong></p><p id="df14" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">默认的<code class="fe nj nk nl nm b">bitrate</code>值是<code class="fe nj nk nl nm b">None</code>，大约是<code class="fe nj nk nl nm b">'2000k'</code>(我在文档中找不到确切的值，通过实验找到了这个值)。使用这个值，视频被<strong class="lb iu">压缩了一点</strong> <strong class="lb iu">，但是我没有注意到任何特别的质量损失</strong>。</p><p id="d8de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以设置更高的值来获得更好的质量。这也会降低渲染速度(但不会太慢)。我进行了一个实验，以从<code class="fe nj nk nl nm b">'1000k'</code>到<code class="fe nj nk nl nm b">'10000k'</code>的比特率渲染了一个视频——最小和最大值的渲染时间相差50%。我就是这样算出大概的默认值的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ps"><img src="../Images/7b69e1597061d22b2c57e1cf5f8e21cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NEFN94v4OymXlAB0b31Jqw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">不同的比特率值和输出文件大小。作者图片</p></figure><p id="8b64" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们按比例计算文件大小(最初的视频持续61秒，为11.6 MB，处理后的视频持续24秒)，我们得到的值为4.5 MB。所以默认比特率就足够了。</p><p id="4d05" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这也可能与初始视频质量有关。我用我的网络摄像头录的视频，所以不是很好。下面可以看到质量对比。如果网络摄像头有所不同，那么对于屏幕捕捉，即使是最低的比特率也能显示出良好的效果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pt"><img src="../Images/a93fd2883d142d644956a88010975e34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QMZclzWrCoueRUeYBX8nQQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">不同比特率的质量比较。作者图片</p></figure><p id="8b9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想深入了解这个，你可以从<a class="ae ky" href="https://zulko.github.io/moviepy/ref/VideoClip/VideoClip.html#moviepy.video.VideoClip.VideoClip.write_videofile" rel="noopener ugc nofollow" target="_blank"> moviepy write_videofile方法文档</a>开始。</p></div><div class="ab cl pu pv hx pw" role="separator"><span class="px bw bk py pz qa"/><span class="px bw bk py pz qa"/><span class="px bw bk py pz"/></div><div class="im in io ip iq"><h1 id="dede" class="lv lw it bd lx ly qb ma mb mc qc me mf jz qd ka mh kc qe kd mj kf qf kg ml mm bi translated">感谢您的阅读！</h1><ul class=""><li id="50c9" class="ms mt it lb b lc mn lf mo li qg lm qh lq qi lu mx my mz na bi translated">我希望这些材料对你有用。<a class="ae ky" href="https://medium.com/@andimid" rel="noopener">在Medium上关注我</a>获取更多这样的文章。</li><li id="4deb" class="ms mt it lb b lc nc lf nd li ne lm nf lq ng lu mx my mz na bi translated">如果您有任何问题或意见，我将很高兴得到任何反馈。在评论中问我，或者通过<a class="ae ky" href="https://www.linkedin.com/in/andimid/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae ky" href="https://twitter.com/dimid_ml" rel="noopener ugc nofollow" target="_blank"> Twitter </a>联系。</li><li id="5b9f" class="ms mt it lb b lc nc lf nd li ne lm nf lq ng lu mx my mz na bi translated">为了支持我作为一名作家，并获得数以千计的其他媒体文章，使用<a class="ae ky" href="https://medium.com/@andimid/membership" rel="noopener">我的推荐链接</a>获得媒体会员资格(不收取额外费用)。</li></ul></div></div>    
</body>
</html>