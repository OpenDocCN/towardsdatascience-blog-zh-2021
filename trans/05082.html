<html>
<head>
<title>What’s Explainable AI?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是可解释的人工智能？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/whats-explainable-ai-fff416111830?source=collection_archive---------33-----------------------#2021-05-04">https://towardsdatascience.com/whats-explainable-ai-fff416111830?source=collection_archive---------33-----------------------#2021-05-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="53f9" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/model-interpretability" rel="noopener" target="_blank">模型可解释性</a></h2><div class=""/><div class=""><h2 id="841f" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">揭秘AI输出，建立信任</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/794aa88506200d0f8cd2ad9f87229c18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ln5n0XzolCg8tmU9Ydih8Q.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@vldfr?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">弗拉德·法拉</a>在<a class="ae lh" href="https://unsplash.com/s/photos/fog-clearing?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="c585" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">TL；速度三角形定位法(dead reckoning)</h1><ul class=""><li id="a337" class="ma mb it mc b md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">人工智能系统的有效性和广泛接受度取决于它们的可信度，尤其是领域专家和最终用户的可信度。</li><li id="56f8" class="ma mb it mc b md ms mf mt mh mu mj mv ml mw mn mo mp mq mr bi translated">反过来，信任可能会受到我们无法理解和解释人工智能解决方案工作或失败的原因和方式的限制。</li><li id="0665" class="ma mb it mc b md ms mf mt mh mu mj mv ml mw mn mo mp mq mr bi translated">人工智能可解释性是指易于理解的信息，解释人工智能系统做出决策的原因和方式。</li></ul><h1 id="ecb1" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">🚣🏼我们是如何来到这里的</h1><h2 id="440f" class="mx lj it bd lk my mz dn lo na nb dp ls mh nc nd lu mj ne nf lw ml ng nh ly iz bi translated">机器学习已经进化了</h2><p id="8bc4" class="pw-post-body-paragraph ni nj it mc b md me kd nk mf mg kg nl mh nm nn no mj np nq nr ml ns nt nu mn im bi translated">自20世纪60年代开发出第一个专家系统以来，更容易获得的计算资源和不断增长的训练数据集规模使机器学习(ML)模型能够为人工智能提供强大动力，并取得了长足的进步[1]。</p><p id="bee1" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">在我们寻求推动人工智能边界的过程中，从基于规则的系统到线性模型和决策树、神经网络和深度学习模型，再到最近的元学习模型或“创建其他ML模型的ML”，一直在稳步发展。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/43645a40c26bd97995bf542f4da36ed0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DZah8ygzevWzTRiZwjqkVw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><em class="ob">图1:机器学习的演变，改编自《人工智能可解释白皮书》【2】</em></p></figure><p id="e7fa" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">这些新的更精确的模型实现了:</p><ul class=""><li id="3635" class="ma mb it mc b md nv mf nw mh oc mj od ml oe mn mo mp mq mr bi translated"><strong class="mc jd">更广泛更高级的用例</strong>，比如自动驾驶、<a class="ae lh" href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology" rel="noopener ugc nofollow" target="_blank">蛋白质折叠</a>，以及药物发现。</li><li id="bb73" class="ma mb it mc b md ms mf mt mh mu mj mv ml mw mn mo mp mq mr bi translated"><strong class="mc jd">数据类型的多功能性</strong>，这意味着使用图像、音频、语音、文本、表格和时间序列数据的组合来训练模型的能力。</li><li id="bdbd" class="ma mb it mc b md ms mf mt mh mu mj mv ml mw mn mo mp mq mr bi translated"><strong class="mc jd">更强的适应性</strong>，这是使用<a class="ae lh" href="https://en.wikipedia.org/wiki/Transfer_learning" rel="noopener ugc nofollow" target="_blank">转移学习</a>等技术快速构建通用模型的能力，无需从头开始训练。</li></ul><p id="8b69" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">但是有一个权衡。以下是一些常见的挑战:</p><ul class=""><li id="041a" class="ma mb it mc b md nv mf nw mh oc mj od ml oe mn mo mp mq mr bi translated"><strong class="mc jd">透明度和调试能力的丧失</strong>，随着复杂性的增加，理解一个模型如何做出预测变得越来越困难，因此也更难修复。这种缺乏透明度的情况确实会减缓这些模型的采用，尤其是在金融服务和医疗保健等受到严格监管的行业。</li><li id="2979" class="ma mb it mc b md ms mf mt mh mu mj mv ml mw mn mo mp mq mr bi translated"><strong class="mc jd">数据偏见的放大</strong>，数据中的人类和社会偏见，如历史不公平、隐含的刻板印象和偏见，可能会被放大，更难确定。</li></ul></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><h1 id="ca7b" class="li lj it bd lk ll om ln lo lp on lr ls ki oo kj lu kl op km lw ko oq kp ly lz bi translated">🤯对可解释人工智能的需求</h1><p id="b8dc" class="pw-post-body-paragraph ni nj it mc b md me kd nk mf mg kg nl mh nm nn no mj np nq nr ml ns nt nu mn im bi translated">机器学习的发展意味着，在理解人工智能系统如何做出决策时，我们需要找到建立信任和透明度的方法。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi or"><img src="../Images/3f4f7fa1d3fbdb7afa8db1abe802b2b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nBozEDSeKhiC0-AFqFl_2w.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">2021 Marketoonist。经Marketoonist LLC许可使用。</p></figure><p id="5116" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">今天，有越来越多的用例具有真实世界的结果，这反过来需要清晰和相关的解释——那么可解释的人工智能如何满足这种需求？</p><p id="7523" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">它提供了以下功能:</p><p id="5668" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated"><strong class="mc jd"> 1-解释</strong>一个模型如何得出一个预测，甚至是一个特定的数据点。<strong class="mc jd"> </strong>例如，图2中的截图显示了H2O.ai中的一个模型解释工具，一个云不可知的AutoML产品。</p><p id="0bb8" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">在这种情况下，我在贷款违约数据集上训练了一个模型[3]。对于突出显示的行，您可以看到哪些功能和值导致了模型的预测，即0 =客户持续付款，1 =客户违约。</p><p id="4cf6" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">解释预测的能力有一些重要的含义；我们可以开始证明决策的合理性，并提供如何影响结果的建议。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi os"><img src="../Images/153d1a24489f10940be9b22bafe36685.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D8CCEdH2OVO8gSCQfZv6eQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><em class="ob">图2: H2O.ai，k-LIME模型解释工具</em></p></figure><p id="2bf2" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated"><strong class="mc jd"> 2-调试</strong>以隔离模型中的异常行为，并<strong class="mc jd">优化</strong>数据收集过程。<a class="ae lh" href="https://cloud.google.com/blog/products/ai-machine-learning/explaining-model-predictions-on-image-data" rel="noopener ugc nofollow" target="_blank">调试工具</a>，比如那些基于谷歌综合梯度研究所发表的论文【4】的调试工具，可以返回表示模型预测的单个像素。</p><p id="6142" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">例如，图3说明了一个场景，其中一个模型使用胸部X射线图像重复错误分类疾病。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ot"><img src="../Images/27bf068db87e4305611d6e49b6a99894.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wkmgJLj11NEYvJaOtS4P0w.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><em class="ob">图3:使用胸部x光图像时的误分类疾病。作者插图。</em></p></figure><p id="9626" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">经过更仔细的检查，发现这个模型把医生在x光片上的记录误解为疾病的征兆。这种可解释性使得采取纠正措施变得容易，在我们的例子中，清理图像并重新训练模型。</p><p id="c680" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated"><strong class="mc jd"> 3-验证</strong>模型的行为是可接受的。例如，用于识别博客帖子中有毒评论的自然语言处理(NLP)模型可能会对敏感术语赋予过多的权重。</p><p id="660f" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">有毒评论有时会使用人们用来识别自己的词语，如种族、宗教和性别，以贬损他人。因此，包含这些术语的评论可能会被误归类为“有毒”。</p><p id="0c70" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">第一步可以是确定模型分配给特定特征的权重，然后调整(应用<a class="ae lh" href="https://machinelearningmastery.com/weight-regularization-to-reduce-overfitting-of-deep-learning-models/" rel="noopener ugc nofollow" target="_blank">正则化</a>)以减少分配给包含与个人身份相关的术语的特征的权重，如图4所示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ou"><img src="../Images/7428e4ae11782dad61f9f33dec3247c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qHs84ZRCc7UqN-Ca_JES0g.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><em class="ob">图4:验证模型行为。作者插图。</em></p></figure><p id="4020" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated"><strong class="mc jd"> 4-至今</strong>一款车型的“要旨”。例如，图5中的屏幕截图是H2O.ai中的可解释性工具的另一个示例。同样，使用贷款默认数据集，它生成一个决策树，描述通向模型预测输出的输入和路径。</p><p id="0acf" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">也许与直觉相反，一条路径表明，有工作的人比没有工作的人拖欠还款的可能性更高。但是有人可能会说，一个没有工作的人不可能首先获得贷款！</p><p id="10e5" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">但是严肃地说，这种能力对于向最终用户概括模型如何工作非常有用，而不需要进入复杂的代码。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ov"><img src="../Images/f5b7c6755460df93c0f25481f332837d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SoFR3bSl9z-BYyItN3hWmw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><em class="ob">图5: H2O.ai，决策树代理模型解释工具</em></p></figure></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><h1 id="2e2e" class="li lj it bd lk ll om ln lo lp on lr ls ki oo kj lu kl op km lw ko oq kp ly lz bi translated">👷🏾‍♀️:那我该如何开始呢？</h1><p id="df1f" class="pw-post-body-paragraph ni nj it mc b md me kd nk mf mg kg nl mh nm nn no mj np nq nr ml ns nt nu mn im bi translated">这篇文章的目的是介绍可解释人工智能的概念，但显然这是一个非常广泛的话题。从如何使用它来帮助建立信任、解决偏见和确保公平，到大量可用的工具和技术。这超出了我在这里打算涵盖的范围，所以我在进一步阅读下面添加了一些建议。</p><p id="4177" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">➡️:对于那些想直接进入的人，我根据你的专业知识水平和建立模型的经验，对“如何开始”将可解释的人工智能添加到你的ML工作流程中的选项进行了细分(点击放大):</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ow"><img src="../Images/fadcc051d3949b4e60d74f3ad5af648e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dYw0CaGwL17DUR9vaYiZ4A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><em class="ob">图6:如何入门可解释的AI。作者插图。</em></p></figure><p id="d2a5" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">我希望这篇文章对你有用，如果有用，请给它一个👏而且一定要分享。我也很想知道你对这个帖子和格式的想法，所以请使用下面的评论或<a class="ae lh" href="https://twitter.com/theomermahmood" rel="noopener ugc nofollow" target="_blank"> twitter </a>来联系！</p><p id="02bf" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">🙏🏼最后，非常感谢<a class="ae lh" href="https://www.linkedin.com/in/tahir-m-cfa/" rel="noopener ugc nofollow" target="_blank">塔希尔·马哈茂德</a>的内容建议！</p></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><h1 id="b037" class="li lj it bd lk ll om ln lo lp on lr ls ki oo kj lu kl op km lw ko oq kp ly lz bi translated">📇参考</h1><p id="bbd6" class="pw-post-body-paragraph ni nj it mc b md me kd nk mf mg kg nl mh nm nn no mj np nq nr ml ns nt nu mn im bi translated">[1]<strong class="mc jd">Britannica.com，专家系统，计算机科学，弗拉基米尔·兹沃斯:</strong><a class="ae lh" href="https://www.britannica.com/technology/expert-system" rel="noopener ugc nofollow" target="_blank">https://www.britannica.com/technology/expert-system</a></p><p id="9a80" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">[2] <strong class="mc jd"> Google Cloud，AI Explainability白皮书:</strong><a class="ae lh" href="https://storage.googleapis.com/cloud-ai-whitepapers/AI%20Explainability%20Whitepaper.pdf" rel="noopener ugc nofollow" target="_blank">https://storage . Google APIs . com/Cloud-AI-whites/AI % 20 explaibility % 20 white page . pdf</a></p><p id="7690" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">【3】【https://www.kaggle.com/kmldas/loan-default-prediction】贷款违约预测，金融分析初学者资料集，卡迈勒达斯:<a class="ae lh" href="https://www.kaggle.com/kmldas/loan-default-prediction" rel="noopener ugc nofollow" target="_blank"/></p><p id="9553" class="pw-post-body-paragraph ni nj it mc b md nv kd nk mf nw kg nl mh nx nn no mj ny nq nr ml nz nt nu mn im bi translated">[4] <strong class="mc jd">深度网络的公理化归属</strong>，穆昆德·孙达拉拉詹，安库尔·塔利，奇奇·严，2017年6月12日:<a class="ae lh" href="https://arxiv.org/abs/1703.01365" rel="noopener ugc nofollow" target="_blank"/></p><h1 id="68cf" class="li lj it bd lk ll lm ln lo lp lq lr ls ki lt kj lu kl lv km lw ko lx kp ly lz bi translated">📚进一步阅读</h1><ul class=""><li id="6463" class="ma mb it mc b md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated"><strong class="mc jd">可解释的机器学习，让黑盒模型变得可解释的指南，</strong>作者Christoph Molnar，2021年4月26日:<a class="ae lh" href="https://christophm.github.io/interpretable-ml-book/" rel="noopener ugc nofollow" target="_blank">https://christophm.github.io/interpretable-ml-book/</a></li><li id="2ccc" class="ma mb it mc b md ms mf mt mh mu mj mv ml mw mn mo mp mq mr bi translated"><strong class="mc jd">tensor flow的责任AI工具包:</strong><a class="ae lh" href="https://www.tensorflow.org/responsible_ai" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/responsible_ai</a></li><li id="1566" class="ma mb it mc b md ms mf mt mh mu mj mv ml mw mn mo mp mq mr bi translated">对于人工智能中的偏见，我们该做些什么？作者:詹姆斯·曼尼卡、杰克·西尔伯格和布列塔尼·普雷斯滕，2019年10月25日:<a class="ae lh" href="https://hbr.org/2019/10/what-do-we-do-about-the-biases-in-ai" rel="noopener ugc nofollow" target="_blank">https://HBR . org/2019/10/what-do-we-do-the-bias-in-ai</a></li><li id="22b5" class="ma mb it mc b md ms mf mt mh mu mj mv ml mw mn mo mp mq mr bi translated"><strong class="mc jd"> SHAP和莱姆Python库:第一部分</strong>，作者约书亚·波杜斯卡，2018年12月5日:<a class="ae lh" href="https://blog.dominodatalab.com/shap-lime-python-libraries-part-1-great-explainers-pros-cons/" rel="noopener ugc nofollow" target="_blank">https://blog . dominodatalab . com/shap-LIME-Python-Libraries-Part-1-great-explainers-pros-consenses/</a></li></ul></div></div>    
</body>
</html>