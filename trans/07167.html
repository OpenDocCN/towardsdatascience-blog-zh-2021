<html>
<head>
<title>6 Things I Do to Consistently Improve My Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我做了6件事来持续改进我的机器学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/6-things-i-do-to-consistently-improve-my-machine-learning-models-36cd87aaf9fd?source=collection_archive---------12-----------------------#2021-06-29">https://towardsdatascience.com/6-things-i-do-to-consistently-improve-my-machine-learning-models-36cd87aaf9fd?source=collection_archive---------12-----------------------#2021-06-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="76c1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">…接近并超越90分的绩效</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c2724e55c94a38ed517596061d044733.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RnwzhaOjWynmCz7E"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">玛利亚·特内娃在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="4ce8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我记得我在Kaggle上的第一堂ML课程。我接触了决策树，并在过度使用的Ames Housing数据集上执行了我的第一个“严肃的”回归任务。我太高兴了！我甚至认为机器学习并没有那么难……多么愚蠢！</p><p id="5538" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事实证明，决策树就像是ML中的“Hello World ”,而我只是把我的小脚趾伸进了美丽的数学和数据世界。从那以后，我学到了很多，也提高了很多(或者说我认为我做到了)。</p><p id="2a78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我不仅仅是根据目标盲目训练我喜欢的模特。我已经不再编写模板代码，开始更加认真地对待数据预处理。由于这些变化和许多其他变化，我的模型开始取得稳健的结果，甚至在大型数据集上也经常达到85点以上的性能。</p><p id="18f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，在本文中，我将列出我学到的6件最重要的事情，以持续推动我的模型实现最佳性能。</p><div class="lv lw gp gr lx ly"><a href="https://ibexorigin.medium.com/membership" rel="noopener follow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">通过我的推荐链接加入Medium-BEXGBoost</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">获得独家访问我的所有⚡premium⚡内容和所有媒体没有限制。支持我的工作，给我买一个…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">ibexorigin.medium.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div><p id="9615" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">获得由强大的AI-Alpha信号选择和总结的最佳和最新的ML和AI论文:</p><div class="lv lw gp gr lx ly"><a href="https://alphasignal.ai/?referrer=Bex" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">阿尔法信号|机器学习的极品。艾总结的。</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">留在循环中，不用花无数时间浏览下一个突破；我们的算法识别…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">alphasignal.ai</p></div></div><div class="mh l"><div class="mn l mj mk ml mh mm ks ly"/></div></div></a></div></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h2 id="15e7" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">1️⃣.找出控制过拟合/欠拟合的超参数</h2><p id="445e" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">毫不奇怪，我对ML世界了解的第一件事是过度拟合的问题以及如何与之斗争。生成一个具有良好通用性的健壮模型是一个循序渐进的过程，初始阶段从模型初始化开始。</p><p id="b2a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">选择基线模型后，搜索对其目标函数影响最大的参数。通常，这些超参数直接影响模型的学习，最重要的是，它如何推广。</p><p id="7ff7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最好的方法是通读模型的文档。在阅读了足够多的文档后，您会发现某些关键字会立即暗示该参数与控制过拟合有关。</p><p id="73c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，基于树的模型和集合模型使用术语“修剪”来控制每棵树的深度。随机森林有<code class="fe nt nu nv nw b">n_estimators</code>，<code class="fe nt nu nv nw b">max_features</code>影响每棵树的建造。Sklearn用户指南也说<code class="fe nt nu nv nw b">max_depth</code>和<code class="fe nt nu nv nw b">min_samples_split</code>很重要。</p><p id="9619" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于线性模型，最常见的关键词有<em class="nx">正则化</em>、<em class="nx">惩罚</em>等。逻辑回归和线性支持向量机具有<code class="fe nt nu nv nw b">C</code>——正则化强度的逆，或存在于所有支持向量机中的<code class="fe nt nu nv nw b">alpha</code>和<code class="fe nt nu nv nw b">gamma</code>超参数。常见的惩罚类型被称为“L1”和“L2”，并且<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html" rel="noopener ugc nofollow" target="_blank">山脊</a> / <a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html" rel="noopener ugc nofollow" target="_blank">套索</a>算法本身就支持它们。</p><p id="d970" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要建立基本性能，您可以使用默认值或文档中建议的值。通常，这些值不是最佳的，应该在工作流程的最后阶段使用超参数优化器进行调整。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h2 id="790d" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">2️⃣.将数据分成3组，而不是2组</h2><p id="3a72" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">除非您仍在使用玩具数据集，否则真实世界的数据通常数量庞大。在这种情况下，您可以将数据分为3组(1组训练，2组验证)，以生成更可靠的结果。</p><p id="066b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果不使用交叉验证，那么1个训练和1个测试集的问题又是过度拟合。你要做的所有工作都将依赖于以随机种子分割的那一对训练/测试集。在模型从训练集学习之后，您可以调整它的超参数，直到它为您的测试集提供最佳的可能得分。</p><p id="22dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种情况下的最高分并不一定意味着您的模型现在可以很好地概括看不见的数据。这个特殊的分数只能告诉你的模型在那一小部分随机选择的样本上做得有多好。这是又一次过度拟合，只是在伪装。</p><p id="ffc4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个简单的解决办法是使用另一套坚持己见的办法。模型从训练中学习，您在测试中优化它，最后，您使用第三个验证集检查它在看不见的数据上的真实性能。这里有一个帮助器函数来完成这项工作:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h2 id="35c2" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">3️⃣.广泛使用交叉验证</h2><p id="fed9" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">当您的机器上没有10+内核，并且您的数据集非常大时，最好使用最后一个技巧。</p><p id="f1d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不过，如果你<em class="nx">真的</em>有这种奢侈，那就广泛使用交叉验证。了解不同类型的交叉验证，并找到适合您独特情况的交叉验证。例如，Sklearn提供了<a class="ae ky" href="https://scikit-learn.org/stable/modules/cross_validation.html" rel="noopener ugc nofollow" target="_blank"> 12个独特的交叉验证分裂器</a>，每个分裂器都有一个共同的目的——防止我使用几个模型为每个样本生成多个预测的过度拟合。通过使用交叉验证，您可以获得以下好处:</p><ol class=""><li id="7c19" class="oa ob it lb b lc ld lf lg li oc lm od lq oe lu of og oh oi bi translated">不浪费任何数据—所有折叠完成后，所有数据都被用作训练集和测试集。</li><li id="dfea" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated">消除了由于意外地在过于有利的训练/测试集上进行训练而导致模型表现过于乐观的可能性。</li><li id="e35d" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated">报告ML带来的内在不确定性——通过获得几个分数，您可以计算平均分数来查看总体性能，并查看标准偏差来了解结果可能有多大差异。</li></ol><p id="be2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管交叉验证在每个折叠中内部使用2个集合来评估模型性能，但您仍应保留一个集合用于最终测试，如Sklearn用户指南中所述:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl oo"><img src="../Images/8866fa469f57a952ac47d81821fbd207.png" data-original-src="https://miro.medium.com/v2/format:webp/1*E1e-8OmoqJaSmHxxPXcPGg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由Sklearn提供</p></figure></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h2 id="5a76" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">5️⃣.超越简单的估算技术</h2><p id="7021" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">当我刚开始的时候，我并不真正关心丢失的值。我玩的大多是玩具数据集，简单的均值/模式插补技术绰绰有余(谁能怪我？).</p><p id="e392" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在处理了更大的数据集之后，我的方法改变了。首先，我不再盲目地应用插补技术，而是开始问为什么数据首先会丢失。更广泛地说，我探索了想念的类型。一般来说，有三种:</p><ol class=""><li id="a309" class="oa ob it lb b lc ld lf lg li oc lm od lq oe lu of og oh oi bi translated">完全随机失踪(MCAR)</li><li id="fe73" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated">随机失踪(三月)</li><li id="9095" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated">非随机缺失(MNAR)</li></ol><p id="72b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这三种类型的名称非常相似，但有细微的区别。找出丢失的数据属于哪一类可以缩小你可以用来估算它的技术。</p><p id="ea29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了均值/中值插补等简单技术之外，还有两种基于模型的方法。在Sklearn中，这些是:</p><ol class=""><li id="077e" class="oa ob it lb b lc ld lf lg li oc lm od lq oe lu of og oh oi bi translated">KNN插补(<code class="fe nt nu nv nw b">sklearn.impute.KNNImputer</code>)</li><li id="6d86" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated">迭代插补(<code class="fe nt nu nv nw b">sklearn.impute.IterativeImputer</code>)</li></ol><p id="2e08" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">两者都在R中有实现，我惊讶地发现，用于输入缺失值的R生态系统更加成熟。在这里讨论这些方法会偏离本文的最初目的，所以我可以向你推荐我的另一篇文章:</p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/going-beyond-the-simpleimputer-for-missing-data-imputation-dd8ba168d505"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">超越缺失数据插补的简单插补</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">编辑描述</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="op l mj mk ml mh mm ks ly"/></div></div></a></div><p id="9e36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还有一个问题是哪种技术更好，效果如何。您可以使用多种技术并评估一个估计量来查看每种技术对预测的影响，但这种方法不适用于大型数据集。</p><p id="7bab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我最喜欢的是绘制插补完成前后的特征分布图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl oo"><img src="../Images/971a2c72ef6f83f240831f89a309112c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*wEcE5Tc4mHGMkxeHhiX-RA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="dd40" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不同K值的KNN插补比较。如您所见，K=2时，橙色线更接近原始(蓝色)分布。</p><p id="fa0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">估算分布越接近原始分布，技术就越好。当然，这种方法也有缺点，尤其是当缺失值的比例很大时。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h2 id="47dc" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">5️⃣.执行特征选择或降维</h2><p id="77f0" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">拥有更多数据并不总是更好。当数据具有不必要数量的预测变量(特征)时，情况肯定如此。</p><p id="efa8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">具有太多对估计器的预测能力没有太大贡献的特征会导致过度拟合、更多的计算成本和增加的模型复杂性。这些特征往往具有较低的方差，或者彼此之间高度相关。您可以使用PCA的特征选择或维度缩减来移除数据集中的冗余变量。</p><p id="e1ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">特性选择</strong>当你对每一个特性都有了深刻的理解时，技术有时是首选。甚至在应用复杂的算法之前，你可以利用你的领域知识或者仅仅通过探索每个变量是如何和为什么被收集来丢弃一些。然后，您可以使用其他技术，如基于模型的特征选择。</p><p id="ea4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，Sklearn提供了<code class="fe nt nu nv nw b">SelectFromModel</code>或递归特征消除(RFE)包装算法来自动找到最重要的预测变量集。为了实现更高的性能，passing ensemble算法在这里也能很好地工作。</p><p id="d80e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">PCA降维</strong>是减少特征数量最有力的技术之一。它获取高维数据，并通过尽可能多地保留原始方差，将其投影到更低的维度(更少的特征)。Sklearn实现的PCA ( <code class="fe nt nu nv nw b">sklearn.decomposition.PCA</code>)在Kaggle比赛中往往表现相当不错。</p><p id="ae6f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以直接指定想要保留的要素数量或通常执行的操作-传递一个介于0和1之间的百分比来表示想要保留的变化量。PCA会自动找到能够解释传递方差的最小特征数。</p><p id="7a13" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PCA的一个缺点是涉及到大量的数学运算，而且你会牺牲可解释性，因为在PCA之后，你将无法解释这些特征。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h2 id="f0ad" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">6️⃣.特征工程</h2><p id="790a" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">一旦你在ML世界中走得足够久，你将开始越来越多地听到关于特征工程的激动人心的讨论。大多数专业人士声称特征工程是一门艺术，这是理所当然的！</p><p id="e56c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特征工程是数据预处理的广义术语。它涉及的操作范围从基本的数据清理到转换现有数据，以显示特征中看不见的结构和模式。这就是为什么它被称为一门艺术——你能想出的东西没有限制，只有你的创造力和领域知识。</p><p id="5a29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">许多Kaggle大师和行业内的从业者表示，他们大部分时间都在做特征工程。在许多采访中，Kaggle竞赛的获胜者声称特征工程是他们成功的关键(我特别听到一位Kaggle特级大师在被问及他如何赢得比赛时使用了“特征工程超越所有人”这一短语)。</p><p id="648d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特征工程就是充分利用你所拥有的东西。通过将给定的数据转换为其最佳形式，可以确保您执行的所有其他操作都将达到其最佳性能。机器学习大师的杰森·布朗利说得好:</p><blockquote class="oq or os"><p id="63c3" class="kz la nx lb b lc ld ju le lf lg jx lh ot lj lk ll ou ln lo lp ov lr ls lt lu im bi translated">当您的目标是从预测模型中获得尽可能好的结果时，您需要充分利用现有资源。这包括从您使用的算法中获得最佳结果。它还包括最大限度地利用数据，以供算法使用。</p></blockquote><p id="4f7b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">顺便说一句，你可以看看他关于这个话题的<a class="ae ky" href="https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/" rel="noopener ugc nofollow" target="_blank">世界级文章</a>来了解关于特性工程的炒作到底是怎么回事。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h2 id="a5cb" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">感谢您的阅读！！！</h2><p id="18e4" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">我希望本文中讨论的技巧能让初学者大开眼界。我通过反复试验和阅读许多其他人的作品来学习每一种语言。通过在您自己的实践中正确地应用它们，您应该能够将您的模型的性能扩展到接近90点性能甚至更高！</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h2 id="6bd0" class="mv mw it bd mx my mz dn na nb nc dp nd li ne nf ng lm nh ni nj lq nk nl nm nn bi translated">您可能也会感兴趣…</h2><ul class=""><li id="ca65" class="oa ob it lb b lc no lf np li ow lm ox lq oy lu oz og oh oi bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/19-sklearn-features-you-didnt-know-existed-p-guarantee-0-75-79a5e9704dad?source=your_stories_page-------------------------------------"> 19个你不知道存在的Sklearn功能| P(保证)= 0.75 </a></li><li id="f366" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu oz og oh oi bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/19-sklearn-features-you-didnt-know-existed-p-guarantee-0-75-79a5e9704dad?source=your_stories_page-------------------------------------"> 6 Sklearn默默告诉你是菜鸟的错误</a></li><li id="9ca2" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu oz og oh oi bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/5-short-but-super-productive-things-to-do-during-model-training-b02e2d7f0d06?source=your_stories_page-------------------------------------">训练机器学习模型时要做的5件超级高效的事情</a></li></ul></div></div>    
</body>
</html>