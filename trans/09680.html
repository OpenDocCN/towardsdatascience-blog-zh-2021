<html>
<head>
<title>Machine Learning on Graphs, Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图上的机器学习，第1部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-on-graphs-part-1-9ec3b0bd6abc?source=collection_archive---------14-----------------------#2021-09-09">https://towardsdatascience.com/machine-learning-on-graphs-part-1-9ec3b0bd6abc?source=collection_archive---------14-----------------------#2021-09-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/98e835adac456ab74c518b877dbb07b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YECeOxlko9KoOJNw8RNm3A.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">艾莉娜·格鲁布尼亚克在<a class="ae jd" href="https://unsplash.com/s/photos/network?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="6228" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">收集基本统计数据</h2></div><p id="c1f2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在一系列帖子中，我将概述几种从图形数据中学习的机器学习方法。从用于描述图形的基本统计开始，我将通过讨论节点嵌入、图形核、图形信号处理以及最终的图形神经网络来深入探讨这个主题。这些帖子旨在反映我在学术界和工业界的个人经历，包括我的一些研究论文。我的主要动机是首先介绍一些关于图的机器学习的基本方法，这些方法应该在深入研究像图神经网络这样的高级算法之前使用。</p><p id="0149" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在第一篇文章中，我介绍了一些常见的图表分析技术，这些技术应该可以帮助我们更好地理解我们的数据。</p><h2 id="da2a" class="lr ls jg bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">预赛</h2><p id="e301" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">我假设你熟悉基本的图形概念。我将考虑没有自环的无向图(节点通过一条边连接到自己)，但这只是为了便于展示。一个图用<em class="mp"> G=(V，E) </em>表示，其中<em class="mp"> V </em>是节点或顶点的集合，<em class="mp"> E </em>是边的集合。节点的数量由<em class="mp"> n = |V| </em>表示，边的数量由<em class="mp"> m = |E|表示。</em></p><h2 id="2680" class="lr ls jg bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">要寻找什么图形统计？</h2><p id="0273" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">在着手解决一个问题之前，我们通常会花一些时间进行探索性的数据分析。这为我们提供了对数据的洞察，这些数据可能对我们以后的工作至关重要。理想情况下，我们会像绘制地铁图一样绘制图表，但大多数现实生活中的图表都很大，很容易可视化。相反，下面是一些重要的统计数据:</p><ul class=""><li id="d2f3" class="mq mr jg kx b ky kz lb lc le ms li mt lm mu lq mv mw mx my bi translated"><strong class="kx jh">程度分布。</strong>两个现实网络的度分布如图1所示。第一张<a class="ae jd" href="https://snap.stanford.edu/data/email-EuAll.html" rel="noopener ugc nofollow" target="_blank">图</a>来自欧盟机构的电子邮件通信，第二张<a class="ae jd" href="https://snap.stanford.edu/data/com-DBLP.html" rel="noopener ugc nofollow" target="_blank">图</a>是来自DBLP数据库的合著图。我们观察到电子邮件图中最常见的节点度是1，意味着大多数人只与一个人交流。在合著图中，大多数作者都有两到三个合著者。</li></ul><div class="mz na nb nc gt ab cb"><figure class="nd is ne nf ng nh ni paragraph-image"><img src="../Images/003a1c11739175ecfc6b639ad0ea5854.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*5Gwot9q5lzp0P3Lako9aFw.png"/></figure><figure class="nd is nj nf ng nh ni paragraph-image"><img src="../Images/5f300cd14f8e36421a51cbb7ba594e33.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*mT5Y66MnBQhUPPBZIL_BwQ.png"/><p class="iz ja gj gh gi jb jc bd b be z dk nk di nl nm translated">图1:学位分布。图片作者。</p></figure></div><ul class=""><li id="59c1" class="mq mr jg kx b ky kz lb lc le ms li mt lm mu lq mv mw mx my bi translated"><strong class="kx jh">图形密度</strong>。数量定义为</li></ul><figure class="mz na nb nc gt is gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/e8e94faf0b133153e6ec7e3816309f92.png" data-original-src="https://miro.medium.com/v2/resize:fit:472/format:webp/1*oIWc8yx2_F1MFv0WfTqaYw.png"/></div></figure><p id="24a8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">解释很简单:边的最大可能数量是n*(n-1)/2，因为每个节点可以恰好连接到n-1个其他节点，并且边是无向的。它衡量一个图与一个完全连通的图或者一个<em class="mp">集团</em>的接近程度。大多数现实生活中的网络是非常稀疏的，因此在大多数情况下，这种方法不能提供很多信息。</p><ul class=""><li id="90a7" class="mq mr jg kx b ky kz lb lc le ms li mt lm mu lq mv mw mx my bi translated"><strong class="kx jh">连接组件。</strong>我们说，如果在<em class="mp"> u </em>和<em class="mp"> v </em>之间存在一条路径，即一系列边，那么从节点<em class="mp"> v </em>可以到达节点<em class="mp"> u </em>。在连通组件中，每个节点都可以从该组件中的所有其他节点到达。连通分量的数量和相应的大小可以提供关于图形的信息。然而，在大多数情况下，我们感兴趣的是由单个连通分量组成的连通图。</li><li id="ab3d" class="mq mr jg kx b ky no lb np le nq li nr lm ns lq mv mw mx my bi translated"><strong class="kx jh">图形直径。</strong>两个节点<em class="mp"> u </em>和<em class="mp"> v </em>之间的最短路径是从<em class="mp">u</em>开始到达<em class="mp"> v </em>需要遍历的最小边数。图直径是图中任意两个节点之间的最大最短路径长度。如果图有多个连通分支，那么它的直径是无穷大。在这种情况下，我们感兴趣的是每个连通分量的直径。图的直径可以用来区分不同类型的网络。例如，地铁网络可能比小型社交网络具有更大的直径。</li><li id="8a86" class="mq mr jg kx b ky no lb np le nq li nr lm ns lq mv mw mx my bi translated"><strong class="kx jh">三角形的数量和传递系数。</strong>在图论中，有<a class="ae jd" href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93R%C3%A9nyi_model" rel="noopener ugc nofollow" target="_blank">erdős–rényi图</a>的基本概念。这是一个理论模型，其中节点之间的边是随机生成的，每个边都有固定的概率<em class="mp"> p </em>，独立于其他边。现实生活中的图与erdős–rényi图非常不同，因为边不是随机独立创建的。特别是，对于大多数真实的图，它通常认为“我的朋友的朋友也是我的朋友”。这使得研究人员认为三角形是图形分析的基本单位[1]。在高层次上，三角形的数量显示了我们的图形与随机图形的不同之处。</li></ul><p id="f945" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">图的传递系数定义为</p><figure class="mz na nb nc gt is gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/b90e0d19514274ceae4e993da9524be2.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/format:webp/1*a90UYtBxH46coOnnLfT61g.png"/></div></figure><p id="284b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在上面的例子中，分子是三角形的数量乘以3，分母表示图中2-路径的数量，可以计算如下:</p><figure class="mz na nb nc gt is gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/075228aaeaefffcdf51c8eaafb3b3fc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*keZDcttkzEqP4GCO-mctbg.png"/></div></figure><p id="612f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在图2的图形中，有两个三角形，分别是<em class="mp"> (u，v，w) </em>和<em class="mp"> (u，v，z) </em>。2-路径是由en边连接的3节点序列，例如<em class="mp"> z-u-w </em>。观察到给定节点的每对邻居都产生一条2-路径，因此得到了上面的2-路径总数公式。我们将三角形的数量乘以3，因为我们计算了它的3 2条路径中的每一条。因此，传递系数是介于0(完全没有三角形)和1(完全连通图)之间的值。</p><p id="b370" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在图2中，2-路径的数量是8，因此传递系数是0.75。</p><p id="6ec1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在大多数真实的图中，传递系数是常数。传递系数越大，网络连接越紧密。事实上，它在1998年被引入来描述小世界网络模型。</p><figure class="mz na nb nc gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nv"><img src="../Images/6230408f168f1e55729ace394852fe8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LZwc9nERFfzKBpz_hCH0rw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图二。一个紧密连接的图。图片作者。</p></figure><ul class=""><li id="454f" class="mq mr jg kx b ky kz lb lc le ms li mt lm mu lq mv mw mx my bi translated"><strong class="kx jh">三角形的局部数量和聚类系数。</strong>定义节点<em class="mp"> u </em>的局部聚类系数</li></ul><figure class="mz na nb nc gt is gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/e0acd8a5327cc424e736a4459f7ff920.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*tZOqfBtaN7hjGrAQ7KdB1A.png"/></div></figure><p id="974b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">即以u为节点的三角形的数量除以以<em class="mp"> u </em>为中心的2-路径的数量。</p><p id="d07c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然后将其推广到全局聚类系数</p><figure class="mz na nb nc gt is gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/68727666c5a58011e16d6ef96a72eb17.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*qiv4Sizp3uHVb-QME4J97A.png"/></div></figure><p id="a52d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在图2中，节点u的局部聚集系数为2/3，图的全局聚集系数为(2/3+2/3+1+1)/4 =0.833。</p><p id="5320" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，我们希望指出，在文献中，传递性系数有时被称为聚类系数，而如上定义的全局聚类系数被称为平均聚类系数。符号的混乱源于Watts和Strogatz在他们的开创性论文[1]中错误地声称及物性系数和聚类系数是相同的。</p><h2 id="6531" class="lr ls jg bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">怎么数三角形的个数？</h2><p id="7ef2" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">从上面的讨论可以明显看出，最重要的图统计似乎是三角形的数量以及相应的传递性和聚类系数。让我们看看如何计算它。我推荐在处理图形时使用Python的<a class="ae jd" href="https://networkx.org/" rel="noopener ugc nofollow" target="_blank"> networkx库</a>。它使用起来简单直观，并提供了许多基本的图形算法，如最短路径、连通分量数，甚至传递系数。</p><pre class="mz na nb nc gt ny nz oa ob aw oc bi"><span id="e965" class="lr ls jg nz b gy od oe l of og">import networkx as nx<br/>import numpy as np</span><span id="9267" class="lr ls jg nz b gy oh oe l of og">G = nx.Graph()<br/>for u, v in &lt;list of edges or edge generator&gt;:<br/>      G.add_edge(u, v)</span></pre><p id="83f4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以用图的邻接矩阵的三次方来计数三角形。精确的公式是</p><figure class="mz na nb nc gt is gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/f30e1806878e3687faa3b2172c14f9df.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*oWyjsRBSxe3ysboZ10nPHw.png"/></div></figure><p id="d15f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">迹被定义为矩阵中对角线元素的和。中的每个对角线条目测量从相应节点到其自身的长度恰好为3的路径的数量。考虑三个节点(u，v，w)之间的三角形。这三个节点有6种排列，这就是为什么我们需要将轨迹除以6。在Python中，代码看起来像</p><pre class="mz na nb nc gt ny nz oa ob aw oc bi"><span id="a54c" class="lr ls jg nz b gy od oe l of og">def count_triangles(G):<br/>   A = nx.to_scipy_sparse_matrix(G)<br/>   A2 = A.dot(A)<br/>   A3 = A2.dot(A)<br/>   return A3.diagonal().sum()/6</span></pre><p id="f061" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">注意，上面使用了稀疏矩阵乘法。然而，邻接矩阵的三次幂不能保证是稀疏的，特别是对于小直径的图，计算可能成为瓶颈。在这种情况下，我建议使用Doulion算法[2]。Doulion的工作原理是对原始图形的边进行采样。每个边缘以概率<em class="mp"> p </em>保持。因此，一个三角形以概率p存在于稀疏图中。我们通过将稀疏图中的三角形数量乘以1/p来估计原始图中的三角形数量。</p><pre class="mz na nb nc gt ny nz oa ob aw oc bi"><span id="28cf" class="lr ls jg nz b gy od oe l of og">def sparsify_graph(G, p):<br/>    G_sparse = nx.Graph()<br/>    for u,v in G.edges():<br/>        if np.random.random() &lt;= p:<br/>            G_sparse.add_edge(u,v)<br/>    return G_sparse</span></pre><p id="f887" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我在从DBLP网络获得的<a class="ae jd" href="https://snap.stanford.edu/data/com-DBLP.html" rel="noopener ugc nofollow" target="_blank">图上运行了一个实验。该图由317，080个节点组成，边数刚刚超过100万。通过以10%的概率对边缘进行采样，我获得了精确计数算法和Doulion的以下运行时间。并且所获得的三角形数量的近似值非常好。</a></p><pre class="mz na nb nc gt ny nz oa ob aw oc bi"><span id="85de" class="lr ls jg nz b gy od oe l of og">Elapsed time exact:   13.21 secs<br/>Elapsed time Doulion: 1.19 secs<br/>Approximation exact/estimated: 1.030</span></pre><h2 id="3889" class="lr ls jg bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">一些更高级的统计数据。</h2><p id="3b93" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">让我们简单提一下还有更高级的图表统计。</p><ul class=""><li id="e441" class="mq mr jg kx b ky kz lb lc le ms li mt lm mu lq mv mw mx my bi translated"><strong class="kx jh">介数中心性。</strong>这个<a class="ae jd" href="https://en.wikipedia.org/wiki/Betweenness_centrality" rel="noopener ugc nofollow" target="_blank">度量</a>捕获了图中节点的影响。对于每个节点<em class="mp"> u </em>，我们计算节点对之间有多少条最短路径经过<em class="mp">u。</em>具有高介数中心性的节点被认为在网络中更重要。介数中心性分数的分布为我们提供了对图结构的进一步了解。然而，计算所有节点的中心性的计算复杂度是O(m*n)。</li><li id="15ee" class="mq mr jg kx b ky no lb np le nq li nr lm ns lq mv mw mx my bi translated"><strong class="kx jh">稠密连接的子图。</strong>一个重要的研究课题是密集连通子图的检测【3】。这些是原始图中的子图，其中几乎所有的节点对都由一条边连接。这是社区检测算法的基础。但是这些致密成分的数量和密度也是重要的统计数据。</li><li id="e0d8" class="mq mr jg kx b ky no lb np le nq li nr lm ns lq mv mw mx my bi translated"><strong class="kx jh">挖掘图形主题。</strong>检测频繁图模式是一个活跃的研究领域[4]。它将三角形计数算法推广到挖掘和计数更复杂的子图，或<em class="mp">主题。</em>这些计数可用于图形分类任务。在图3中，我在4个节点上展示了三个不同的主题。然而，对基序进行计数在计算上可能是昂贵的，并且仅限于小的子图。有人可能会认为，图形神经网络的成功是基于它们学习与手头问题相关的复杂主题的能力。</li></ul><figure class="mz na nb nc gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oj"><img src="../Images/c79cda1919b2af9778799779d27203af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e-MudfT-EHsQIAM3KzPzpQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图3。4个节点上的子图主题。</p></figure><h2 id="5ff9" class="lr ls jg bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">密码</h2><p id="a81d" class="pw-post-body-paragraph kv kw jg kx b ky mk kh la lb ml kk ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">以上例子的代码可以在:<a class="ae jd" href="https://github.com/konstantinkutzkov/ML_on_graphs/blob/main/basic_graph_statistics.ipynb" rel="noopener ugc nofollow" target="_blank">https://github.com/konstantinkutzkov/ML_on_graphs/</a>找到</p></div><div class="ab cl ok ol hu om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="ij ik il im in"><p id="ad65" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[1]邓肯·j·瓦茨，史蒂文·h·斯特罗加兹。<a class="ae jd" href="https://www.nature.com/articles/30918" rel="noopener ugc nofollow" target="_blank">小世界网络的集体动力学</a>。自然393，1998。</p><p id="4909" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[2]查拉兰波斯·e·措拉卡基斯、U·康、加里·米勒和克里斯特斯·法卢特索斯。<a class="ae jd" href="http://www.cs.cmu.edu/~ukang/papers/kdd09.pdf" rel="noopener ugc nofollow" target="_blank"> DOULION:用一枚硬币数海量图形中的三角形</a>。KDD 2009。</p><p id="8e04" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[3]查拉兰波斯·祖拉卡基斯、弗朗切斯科·邦奇、阿里斯蒂德斯·乔尼斯、<br/>弗朗切斯科·古罗和玛丽亚·齐阿利。<a class="ae jd" href="http://www.francescobonchi.com/denserthanthedensest.pdf" rel="noopener ugc nofollow" target="_blank">比最密子图更密:<br/>提取质量有保证的最优拟团</a>。KDD 2013。</p><p id="5cf8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[4]古越汉和哈里什塞图。<a class="ae jd" href="https://arxiv.org/pdf/1605.09776.pdf" rel="noopener ugc nofollow" target="_blank">蹒跚随机行走:在大图中快速准确挖掘模体统计</a>。ICDM 2016。</p></div></div>    
</body>
</html>