<html>
<head>
<title>Existential risk from AI: A skeptical perspective</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能的生存风险:一个怀疑的视角</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/existential-risk-from-ai-a-skeptical-perspective-35f0cd7c9fa4?source=collection_archive---------30-----------------------#2021-04-07">https://towardsdatascience.com/existential-risk-from-ai-a-skeptical-perspective-35f0cd7c9fa4?source=collection_archive---------30-----------------------#2021-04-07</a></blockquote><div><div class="fc ig ih ii ij ik"/><div class="il im in io ip"><h2 id="064c" class="iq ir is bd b dl it iu iv iw ix iy dk iz translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/tds-podcast" rel="noopener" target="_blank">播客</a></h2><div class=""/><div class=""><h2 id="0740" class="pw-subtitle-paragraph jy jb is bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">梅勒妮·米切尔解释了为什么超人人工智能不会出现的原因</h2></div><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="kv kw l"/></div><p class="kx ky gj gh gi kz la bd b be z dk translated"><a class="ae lb" href="https://podcasts.apple.com/ca/podcast/towards-data-science/id1470952338?mt=2" rel="noopener ugc nofollow" target="_blank">苹果</a> | <a class="ae lb" href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9hbmNob3IuZm0vcy8zNmI0ODQ0L3BvZGNhc3QvcnNz" rel="noopener ugc nofollow" target="_blank">谷歌</a> | <a class="ae lb" href="https://open.spotify.com/show/63diy2DtpHzQfeNVxAPZgU" rel="noopener ugc nofollow" target="_blank"> SPOTIFY </a> | <a class="ae lb" href="https://anchor.fm/towardsdatascience" rel="noopener ugc nofollow" target="_blank">其他</a></p></figure><p id="2223" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated"><em class="ly">编者按:这一集是我们关于数据科学和机器学习新兴问题的播客系列的一部分</em>，<em class="ly">由Jeremie Harris主持。除了主持播客，Jeremie还帮助运营一家名为</em><a class="ae lb" href="http://sharpestminds.com" rel="noopener ugc nofollow" target="_blank"><em class="ly">sharpes minds</em></a><em class="ly">的数据科学导师初创公司。</em></p><p id="3c9d" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">随着人工智能系统变得越来越强大，越来越多的人对其潜在的长期风险发出了警告。正如我们之前在播客中报道的那样，许多人现在认为，这些风险甚至可能延伸到与人类价值观略有偏差的超人人工智能系统对我们物种的灭绝。</p><p id="73dc" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">严肃对待这一风险的作家、研究人员和技术专家不乏其人——他们包括像<a class="ae lb" href="https://en.wikipedia.org/wiki/Eliezer_Yudkowsky" rel="noopener ugc nofollow" target="_blank">埃利泽·尤德科夫斯基</a>、埃隆·马斯克、比尔·盖茨<a class="ae lb" href="https://en.wikipedia.org/wiki/Stuart_J._Russell" rel="noopener ugc nofollow" target="_blank">斯图尔特·罗素</a>和<a class="ae lb" href="https://en.wikipedia.org/wiki/Nick_Bostrom" rel="noopener ugc nofollow" target="_blank">尼克·博斯特罗姆</a>这样的杰出人物。虽然我认为人工智能存在风险的论点是合理的，并且没有得到足够广泛的理解，但我也认为探索更多怀疑的观点是重要的。</p><p id="2ddc" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔是这场争论中持怀疑态度的一方的重要声音，她非常友好地和我一起参加了本期播客。梅勒妮是圣达菲研究所(Santa Fe Institute)戴维斯复杂性教授、波特兰州立大学(Portland State University)计算机科学教授，也是《人工智能:思考人类指南》(Artificial Intelligence:a Guide for Thinking Humans)的作者，在这本书里，她通过批判性的视角探讨了人工智能存在风险的论点。她是存在主义风险对话中的积极参与者，最近参加了与斯图尔特·罗素的高调辩论，反对他的人工智能风险立场。</p><p id="958e" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">以下是我在对话中最喜欢的一些观点:</p><ul class=""><li id="415e" class="lz ma is le b lf lg li lj ll mb lp mc lt md lx me mf mg mh bi translated">梅勒妮怀疑我们是否应该担心来自人工智能的存在风险，原因有几个。首先，她怀疑我们是否理解什么样的智能是足以创造超智能人工智能的智能——与许多人工智能风险倡导者不同，她认为如果没有对智能的正确理解，我们将无法制造真正智能的系统。</li><li id="33b4" class="lz ma is le b lf mi li mj ll mk lp ml lt mm lx me mf mg mh bi translated">她持怀疑态度的第二个原因是:梅勒妮认为智力不能与社交分开。可以说，人类的大部分智力是通过社会压力进化而来的，人类智力的发展从出生开始就围绕着社会互动。因为人工智能最终将被构建为向人类传递价值，所以Melanie相信它们也将被“社会化”。因此，她认为，真正智能的人工智能系统可能会获得“常识”和“伦理”作为其发展的副产品，因此可能是安全的。</li><li id="047c" class="lz ma is le b lf mi li mj ll mk lp ml lt mm lx me mf mg mh bi translated">然而，Melanie确实承认，开发能够提出危险的创造性解决方案的人工智能系统是有风险的，这些解决方案是实现人类程序员可能没有预料到或希望实现的目标的方法。虽然她同意这可能是严重风险的来源，但她不同意斯图尔特·拉塞尔(Stuart Russell)等人对人工智能风险的描述，她认为，这些人错误地认为智力可以在没有社会化的情况下发展。</li><li id="de9e" class="lz ma is le b lf mi li mj ll mk lp ml lt mm lx me mf mg mh bi translated">虽然Melanie不认为存在性人工智能风险是值得担心的事情，但她确实同意人工智能技术在短期内可能会产生重大的非存在性风险。恶意使用、事故或人工智能驱动的自动武器系统的部署都可能给我们带来严峻的挑战Melanie认为有理由在此基础上呼吁更多的人工智能监管。</li><li id="c029" class="lz ma is le b lf mi li mj ll mk lp ml lt mm lx me mf mg mh bi translated">梅勒妮担心人工智能技术的发展速度，并不认为法律和监管将能够跟上。出于这个原因，她认为研究人员有更大的负担来确保他们正在尽他们所能引导人工智能技术朝着安全和积极的方向发展。</li></ul><p id="9e7e" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">你可以<a class="ae lb" href="https://twitter.com/MelMitchell1" rel="noopener ugc nofollow" target="_blank">在推特上关注梅勒妮</a>，或者<a class="ae lb" href="https://twitter.com/jeremiecharris" rel="noopener ugc nofollow" target="_blank">在推特上关注我</a></p></div><div class="ab cl mn mo hw mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="il im in io ip"><h2 id="a0c1" class="mu mv is bd mw mx my dn mz na nb dp nc ll nd ne nf lp ng nh ni lt nj nk nl iy bi translated">播客中引用的链接:</h2><ul class=""><li id="384d" class="lz ma is le b lf nm li nn ll no lp np lt nq lx me mf mg mh bi translated"><a class="ae lb" href="https://melaniemitchell.me/aibook/" rel="noopener ugc nofollow" target="_blank">梅勒妮的书在这里</a>。</li></ul></div><div class="ab cl mn mo hw mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="il im in io ip"><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="ns nt di nu bf nv"><div class="gh gi nr"><img src="../Images/40ccf37e15a4952ca2bc38b9a4e113aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uOg9bbuwKBtfdFmwOemrfw.png"/></div></div></figure><h2 id="b26e" class="mu mv is bd mw mx my dn mz na nb dp nc ll nd ne nf lp ng nh ni lt nj nk nl iy bi translated">章节:</h2><ul class=""><li id="6ff3" class="lz ma is le b lf nm li nn ll no lp np lt nq lx me mf mg mh bi translated">0:00介绍</li><li id="72a2" class="lz ma is le b lf mi li mj ll mk lp ml lt mm lx me mf mg mh bi translated">1:07人工智能能力的盲点</li><li id="7c1d" class="lz ma is le b lf mi li mj ll mk lp ml lt mm lx me mf mg mh bi translated">9:00人类和灾难</li><li id="9c07" class="lz ma is le b lf mi li mj ll mk lp ml lt mm lx me mf mg mh bi translated">11:44理解智能</li><li id="e534" class="lz ma is le b lf mi li mj ll mk lp ml lt mm lx me mf mg mh bi translated">17:58人类与情感</li><li id="bc54" class="lz ma is le b lf mi li mj ll mk lp ml lt mm lx me mf mg mh bi translated">23:09存在风险</li><li id="ccf1" class="lz ma is le b lf mi li mj ll mk lp ml lt mm lx me mf mg mh bi translated">26:32需要与充足</li><li id="9d9a" class="lz ma is le b lf mi li mj ll mk lp ml lt mm lx me mf mg mh bi translated">28:42图灵测试</li><li id="48da" class="lz ma is le b lf mi li mj ll mk lp ml lt mm lx me mf mg mh bi translated">34:19易受恶意攻击</li><li id="e294" class="lz ma is le b lf mi li mj ll mk lp ml lt mm lx me mf mg mh bi translated">40:02让社会适应变化</li><li id="b998" class="lz ma is le b lf mi li mj ll mk lp ml lt mm lx me mf mg mh bi translated">44:04总结</li></ul><h2 id="cf61" class="mu mv is bd mw mx my dn mz na nb dp nc ll nd ne nf lp ng nh ni lt nj nk nl iy bi translated">请查看下面的文字记录:</h2><p id="6a62" class="pw-post-body-paragraph lc ld is le b lf nm kc lh li nn kf lk ll ny ln lo lp nz lr ls lt oa lv lw lx il bi translated">杰里米·哈里斯(00:00): <br/>大家好，我是杰里米。欢迎回到迈向数据科学播客。今天的这一集会有点特别，因为我们要和Melanie Mitchell谈谈，她除了是圣达菲研究所的戴维斯复杂性教授和波特兰州立大学的计算机科学教授之外，还是人工智能安全领域的著名作者，也是我们在播客中探讨的许多人工智能存在风险论点的著名怀疑论者。正如你们中的许多人所知，特别是如果你是播客的长期听众，我本人实际上非常担心高级人工智能系统的存在风险，这正是为什么我发现这次对话如此有用和富有成效。和与你意见不同的人交谈总是很棒的，尤其是如果他们像梅勒妮一样体贴的话。</p><p id="bf27" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (00:43): <br/>最后，如果你在听完这个播客后，想更深入地了解Melanie对人工智能存在风险的看法，我推荐她2019年的书《人工智能:思考人类的指南》和她在Munk辩论上与Stuart Russell的播客。所以没有其他办法，我会站到一边，让你享受谈话。好的，梅勒妮，非常感谢你参加我的播客。</p><p id="39f1" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(01:05): <br/>哦，我很高兴来到这里。谢谢邀请我。</p><p id="70d8" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (01:07): <br/>你能来我真的很兴奋。你2019年的书《人工智能:思考人类的指南》提供了一个视角，我认为这与我们迄今为止在播客上看到的许多观点截然不同。我认为你真的是人工智能存在风险论点中最有意思的怀疑论支持者之一，这也是为什么今天你能来这里让我如此激动。现在，AI安全是一个大话题。我认为我们可以从很多地方开始，但我想从你对我们今天在人工智能领域所处位置的评估开始，人工智能今天可以做的事情有哪些可能让你印象深刻，但也有哪些是我们在人工智能能力方面的盲点？</p><p id="2307" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(01:47): <br/>所以人工智能显然在许多相对狭窄的领域表现出色，语音识别，机器翻译，我说的狭窄，是指与人类智力的普遍性相比的狭窄，对吗？因此，这些系统中的每一个都能够完成特定的任务，并且能够做得很好，但具有挑战性的事情是让机器能够将它们的知识用于一种任务，并将其应用于另一种任务，或者能够处理它们的训练数据分布之外的新情况等等。因此，这些是该领域众所周知的挑战，它们确实会产生一些人们所说的脆性，这意味着经过训练来完成某些任务的机器可能会出现不可预测的故障，非常不人道的故障，这可能会导致风险。这可能会导致风险，就像我们在自动驾驶汽车中看到的那样，例如，可能会犯错误，比如看到公共汽车后座上的一张照片，认为这是一个真实的行人，或者识别，认为一辆侧着的半挂卡车实际上只是地平线，或者其他任何不同的错误，人类不会犯的错误。当然，人类在驾驶时会犯不同种类的错误。</p><p id="338a" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (03:21): <br/>但这只是给你一个例子，说明了让我们很难在生活中信任这些人工智能系统的风险。此外，我们还看到了对抗攻击的漏洞，这使得现在在任何生命危急的情况下使用这些系统都有些困难，因为这些系统确实存在漏洞。</p><p id="2505" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (03:55): <br/>如果人工智能技术的故障模式更像人类，您会对它印象更深刻吗？</p><p id="2e20" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (04:00): <br/>如果它的故障模式更像人类，我会印象更深刻，因为这样我就能更好地知道什么时候该相信它，什么时候不该相信它。这将使我们更容易找到如何安全使用它的方法。</p><p id="330a" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">杰里米·哈里斯(04:16): <br/>正是如此。</p><p id="92b7" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(04:16): <br/>人类有自己的失败模式和偏见等等，但是如果你愿意，我们已经开发了一些基础设施来处理其中的一些问题。现在，我们采用人工智能系统，并试图重组我们的基础设施，以处理它们的各种故障模式。因此，如果机器能够更好地像人类一样，显然是为了…</p><p id="63cb" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (04:43): <br/>这些都暗示了这些人工智能系统对世界的推理方式，这很有趣，如果这是一个合适的词的话。事实上，这些故障模式是如此不同，似乎暗示着还有别的事情在发生。也许这将是我接下来要问的问题的一个很好的基础，这是关于人工智能存在风险的论点。所以我之前提到过，我的意思是，你确实是一个众所周知的人工智能存在风险怀疑论者，尽管你肯定已经强调了这项技术的一些风险。你对存在风险的论点有什么看法？在你的世界模型中，为什么人们会关注存在风险，而这些人又忽略了什么？</p><p id="35c5" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (05:22): <br/>我对一些担心存在风险的人的理解是……这是我对他们观点的一些看法。我们不知道多久我们会得到人类水平的人工智能或超级智能人工智能，有人担心这样的系统可能会做出影响人类生存的决定。存在风险是因为他们不认同我们的价值观，或者不具备我们的常识能力。所以我们现在应该开始为此做准备。这是我对斯图尔特·罗素的书《人类相容性》的总结，还有博斯特罗姆和其他一些著名的存在主义风险人士的工作。</p><p id="ec0c" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (06:18): <br/>从表面上看，这听起来让我夜不能寐。你强调了很多非常有趣的地方，我认为以这种方式思考的人往往对他们的考虑不太了解，他们没有尽可能地重视。我很想听听你在这方面的想法。</p><p id="6009" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (06:34): <br/>我对一些存在主义风险的作品中的例子感到特别震惊，我不知道该怎么称呼他们，支持者战士。他们有这样的例子，这里有一个场景，我们有一个超级智能机器，我们委托它解决气候变化的问题。它认为解决碳排放问题的最好方法是杀死所有的人类。所以对我来说，这看起来很疯狂。这就像说你可以拥有一台超级智能机器，但它没有任何常识。人类的生命对人类来说是有价值的，这是毫无意义的。对我来说，要使这些事情正交，误解了智慧的含义。</p><p id="3e13" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(07:31): <br/>所以这真的是…我觉得超级智能本身，这个概念很难定义，人们的意思是什么，以及是否有可能像人们所说的那样，比任何人都聪明得多。因为智能是如此复杂，如此多维。它的维度是如此纠缠不清，或者我相信，我不认为你能把这些东西分开。比如波士顿，有他所谓的正交原则，即智力与目标和价值观是正交的，我根本不相信。</p><p id="62cb" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (08:20): <br/>关于你提到的Stuart Russell和气候变化人工智能的例子，我想知道的一件事是，它会摧毁一切。我解释他的说法的方式不一定是人工智能犯的错误会那么明显，而是系统非常复杂。一般来说，一个人开发的人工智能可以用我们想不到的方式解决问题，风险是这些解决方案有点危险的创造性，我们可能会指定人工智能要完成的目标，但有点像迈达斯国王，他触摸的任何东西都变成黄金，这是他想要的，但他最终会把他的整个家庭变成黄金，等等。</p><p id="e46c" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (09:00): <br/>你最终会遇到这样一种情况，由于微妙的原因，不一定像减少二氧化碳排放那样明显，好吧，让我们杀死所有人，但是人工智能提出了一个复杂的解决方案，在解决问题的可能方法中，我想，当你根据一个指标进行优化时，这个空间中的绝大多数点实际上会导致人类的灾难。我很想听听你的想法，因为我肯定你有一些想法。</p><p id="c6d8" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (09:29): <br/>我在Russell的论点中没有看到这种微妙之处，但我认为这是对我所说的很好的反驳。我认为我们确实看到了那种事情，不仅是机器，还有人类，那种，例如，比特币的现象，它被创造来分散货币，增强自由和隐私等等。但有一个副作用，我认为人们直到很久以后才真正理解，那就是正在进行的所有比特币采矿对环境的影响。这可能会对生存构成威胁。所以开发比特币的人，显然是超级聪明的人，我不知道他们是否预见到了这一点。所以你可以说，机器可以做类似的事情。它可以想出一个解决这些意想不到的负面影响的方法。</p><p id="ad8a" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(10:31): <br/>但是今天机器可以做到这一点，我们看到今天发生的事情，如股票市场的闪电崩盘，以及我们给机器设定的某些目标，消极的事情可能会发生。我的反对意见更多的是关于超级智能的想法以及这意味着什么，如果…当然我们应该对机器如何运行以及我们给它们的目标如何产生不同的效果有更多的了解，但我不认为争论在于将会有一些引用的，未引用的，超级智能人工智能。我们说，哦，让我们把它释放到这个世界上，让它拥有摧毁一切的力量。我只是不认为这是对社会的直接威胁。这更像是使用这些非智能的，一点也不智能的机器，让它们拥有某种自主性。这是更大的威胁。</p><p id="0ca2" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">耶雷米·哈里斯(11:44): <br/>对。我认为，这是两种风险类别之间的一种有趣的区别，你很擅长区分这两种问题，我认为这也是健康的，因为很容易将无人驾驶汽车的风险与人们在这一领域谈论的更多存在性风险相混淆。当谈到存在主义风险时，我想我倾向于看到的论点，确实，你是对的，来自一个固有的地方，我不想说技术乐观主义，但至少相信超级智能是可能的，这绝对是一个核心假设。是什么原因让你认为超级智能是一种极不可能的事情？这是一个公平的描述吗？</p><p id="cd40" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (12:24): <br/>嗯，我想说的是更不明确。我不认为我们在科学上非常了解智力。这个词有很多含义。在计算机科学领域有这样一种观点，我们可以把人工智能发展成缸中的大脑，如果你愿意的话，它可以从一切事物中分离出来，获得一些感官输入，然后进行一些输出。没有发展的概念，我们让孩子学习和社会互动的方式，成为文化的一部分，作为文化的一部分成长。我认为当你谈论智力的时候，你不能轻易地把这些问题分开。从某种意义上说，所有的智能，至少是我们希望人工智能模仿的那种智能，都是基于社会的。我们人类大脑大的原因很可能是为了应对复杂的社会环境。</p><p id="bee5" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (13:34): <br/>人工智能领域的人们认为，这可以从更纯粹的智能概念中分离出来。应该说，人们会说，“哦，我们将拥有这些人工智能系统。他们将会超级聪明，但是他们不会有任何我们的认知偏见。他们不会有我们的任何缺点，比如疲倦、睡觉、情绪化或诸如此类的事情。”我对智力的所有这些方面之间存在这种可分性的观点持怀疑态度。也许我错了，但我觉得我们对智能的理解还不够，无法假设存在某种纯粹的智能概念，可以被灌输或让机器以某种方式学习，这与所有其他方面都是分开的。</p><p id="79d6" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (14:34): <br/>听起来你非常怀疑要达到一般的智力需要一定程度的社会化。这样说公平吗？</p><p id="d99a" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅拉妮·米切尔(14:43): <br/>这是我的怀疑。</p><p id="4700" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">杰里米·哈里斯(14:46): <br/>好的。</p><p id="2861" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅拉妮·米切尔(14:46): <br/>绝对是。一般智力也是很难定义的术语之一，因为我们并不知道自己的意思。有人说没有这回事。有些人认为不存在一般智力。人类有一种特殊的智能，或者他们有某种特定的技能，没有一般性的概念。现在，我不一定同意，但我认为这个术语本身确实需要充实。</p><p id="3759" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">杰里米·哈里斯(15:12): <br/>在人工智能风险方面，有点像我们应该做什么，我想这在某种程度上变成了一个概率游戏。所以我们赋予智力需要社会化这个论点多大的概率呢？我们赋予相反的论点多大的概率，“是的，实际上我们可以用任何东西建造任何东西？”然后我们应该如何根据，我想类似于预期收益来行动呢？如果有1%的可能性出现类似人工智能的启示录，那么，很可能这是值得采取行动的，而且这种可能性很重要。所以为了谈论概率，你对没有社交的超级智能是否可能的直觉是什么？</p><p id="5215" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(15:51): <br/>当我甚至不确定超级智慧是什么意思的时候，很难去推测它。但我认为波士顿有一个定义，我不能准确引用，但它就像一个系统，能够做任何人类可以做的事情，并超越，做得更快，更好，更准确等等。所以我相信，如果没有生活在人类的社会、文化世界中，没有在其中成长，我敢打赌，不可能达到那样的人类智慧。</p><p id="0d17" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">杰里米·哈里斯(16:44): <br/>你认为反社会者会是一个很好的对比吗？在这一点上，我不直接说希特勒，但是阿道夫·希特勒，很不幸，可能是一个非常聪明的人，但是很明显他有各种各样的…他不像一个人应该做的那样与人相处。</p><p id="bfb3" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(17:00): <br/>我不认为这是一个有效的观点，因为即使是一个反社会的人，如果你愿意的话，我肯定不是这方面的专家，但他们并不是没有情感。他们并不缺乏社会性。他们并不是没有像其他人类那样成长和发展。只是有些赤字。我不知道它到底是什么，但他们，像那样的人可以在社会中很好地发挥作用，可以相当聪明，但他们也可以造成巨大的破坏。但我认为这不是一个很好的机器类比。机器至少现在他们什么都没有，我的意思是，他们只是远离任何生物智能。</p><p id="d472" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (17:58): <br/>我想我只是想知道社交和关心之间的脱钩。是关心别人吗？那会是你认为是这种普遍智慧的关键部分的主要东西吗？</p><p id="38fe" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (18:10): <br/>更多的是理解，关心他人，但也理解他人的一种心理理论，理解他们的目标，理解他们的动机，理解为什么，能够预测他们，为他们建模。我想很多人都认为这就是我们人类变得如此聪明的原因，这是为了能够成功地模拟和预测我们群体中的其他人在做什么，或者为什么他们在做他们正在做的事情。这是机器所缺乏的，当然也是机器所缺乏的。关于机器的事情是，我们希望它们做需要与我们互动的事情，比如驾驶或打扫我们的房子，或者一个可怕但非常及时的例子，打我们的战争。有很多关于自主战斗机和诸如此类的东西的讨论。从根本上涉及到与人交往和理解他人。所以，我认为这是人们现在试图让人工智能系统做的事情，但这非常困难，没有人真正知道如何做好。</p><p id="c7e4" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (19:35): <br/>在很多这种灾难性的场景中，当你把人工智能放在盒子里时，它肯定会找到一种方法爆发出来，这是她在人工智能安全方面的经典爆发场景，这确实需要某种思维理论，就像你说的，因为你要如何操纵？我想其中一个经典的例子，可能是Max Tegmark，可能用过这个，但是一个经过的看门人，然后被拉去帮助这个东西爆发，你需要一个看门人的思维理论来说服他们做X，Y，Z等等。在某种程度上，人工智能系统可以做到这一点，如果一个人工智能系统可以预测的行为，这也是模糊的，但在一些有意义的背景下，人类的中位数或类似的东西，会为你移动指针吗？如果你看到这一点，你会说，“好吧，我认为这是可以做到的，然后脱离社交方面的排序。”</p><p id="c962" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (20:22): <br/>我们已经有了可以对我们进行某种预测的系统，对吗？</p><p id="0a6f" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">耶雷米·哈理斯(20:25): <br/>对。</p><p id="e3e3" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (20:26): <br/>我的意思是，就像我们的社交媒体平台一样，它们对我们的预测太准确了。但我认为他们是以这种联想的方式来做的，他们没有丰富的人类行为模型。我不知道这是否会改变现状。我认为这对智力是必不可少的，对在这个世界上聪明地存在和行动是必不可少的。所以我认为我们必须能够让我们的系统做到这一点。我们必须让我们的自动驾驶汽车能够预测人类行人将要做什么，或者他们为什么要这样做。我会觉得这样更冒险吗？嗯，我想是，随着系统变得越来越智能，我们必须考虑它们能自主做什么，以及我们能在多大程度上信任它们。</p><p id="2d87" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (21:25): <br/>但我想我的观点是，为了让系统能够做到这一点，我认为在某种意义上，它们必须像我们的孩子一样成长，在一种文化和社会中成长。在这样做的时候，他们会吸收自己的价值观和目标。我不认为你可以拥有这种超级智能但奇怪的被动可编程系统，这种想法，就像斯图尔特·罗素的想法，我们将拥有一个超级智能系统，但我们必须让它吸收，学习我们的价值观。嗯，有一种方法可以做到这一点，比如对孩子，对吗？那叫养孩子。但是抚养孩子需要一个有合适的架构和合适的学习环境的代理，并允许他们自主。他们不是被动的，他们是主动的，他们不只是等着模仿我们。他们有自己的自主权。</p><p id="ef4e" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">杰瑞米·哈里斯(22:38): <br/>我想，在某种程度上，你有，让我们说超级智能系统正在兴起，我在这里用了很多引号，因为我不知道我在说什么。但不管怎样，这很符合你的观点。在某种程度上，我们有这样的系统，以这种方式培养，我想我们确实看到了类似的不端行为，同样，阿道夫·希特勒有父母，保罗[听不清00:22:57]也有父母，你能看到一个满足所有这些标准的超级智能系统产生的存在风险吗，但只是让我们说不恰当地培养，这可能是不恰当地结合的另一种说法？</p><p id="bd7a" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(23:09): <br/>有可能。我只是认为这是一种非常遥远的风险。我当然不认为这种存在的风险是不可能的，任何技术都是如此，对吗？但我只是认为，我们应该关注许多短期风险，而不是我认为的非常长期的风险，我们甚至不知道如何准确地描述这个问题。</p><p id="51cd" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (23:44): <br/>我认为有一件事可能会发生，我想听听你对我们应该关注的近期风险的看法。我怀疑我们会在很多事情上达成一致。但对我来说，跨越近和远之间界限的东西，我认为是非常有趣的，看到人们对它的反应是很有趣的，这就是GPT3，开放人工智能的大型语言模型，显然从那以后谷歌推出了一个更大的模型等等。但是这种缩放模型的想法似乎会带来更多的通用性，更多的灵活性，至少在用例方面。我不相信GPT3，我不知道告诉医生做手术的步骤，但你可以想象一些[听不清00:24:23] GPT4系统会改善。对一些人来说，他们已经看到了这一点，好吧，看起来我们只是通过扩大现有系统的规模，并可能在其中添加一些香料和盐来增加额外的味道，就可以实现通用性。但是你看到这种情况发生了吗？这有说服力吗？你对GPT3的表现感到惊讶吗？</p><p id="2d1e" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (24:39): <br/>我对GPT3并不感到惊讶。我在某些方面对它感到惊讶，因为我认为GPT3是一种语言模型。它没有任何丰富的世界内部模型。它不知道这个世界是如何运作的。你可以看到，通过对这个世界的质疑，许多人已经发表了关于这类事情的论文，它可以说出完全和完全的废话和关于这个世界的事实上错误的事情，没有孩子会说。我对它在生成看似连贯的文本方面的出色表现感到惊讶。那就是…我认为它是通过统计关联来完成的，就像你手机上的语音识别程序已经学习了很多声音和单词之间的统计关联。我很惊讶基于这种方法他们能做得这么好。</p><p id="133c" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (25:44): <br/>所以我总是对这种将这些模型扩展到非常大的数据集和非常大的网络可以改善它们感到惊讶。我不相信如果你继续扩展GPT3，让它记住所有的人类语言，无论什么，它会成为一种普遍的智能。我认为这还不够。也许这听起来很有说服力，但是它不能做我们人类能做的事情。它将无法像我们人类那样交流。所以还有待观察，但我不相信会发生。</p><p id="b332" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">耶雷米·哈里斯(26:32): <br/>这是一个有趣的问题。我们能说的标准是什么，这里有实际的推理在进行？这是否足以说明一些例子，GBT3似乎可以在训练集之外进行推断，似乎可以用三位数做数字加法之类的事情，尽管它在更多位数时会失败，但在一些情况下，它似乎很明显没有看到某些东西的组合，但它仍然可以正确地完成这些事情。但是就像你说的，有一些明显的反例，你连续给它两个事实，然后它不能以不同的方式把两者联系起来。所以你认为这个必要性和充足性的问题是我们应该讨论的重要问题吗？在我们宣布这些模型正在做一些有趣的事情之前，它们表现出一些推理能力就足够了吗，或者它们需要更健壮吗？</p><p id="7d1e" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(27:22): <br/>我想这取决于你的目标是什么。如果你的目标是构建能够转化为产品的人工智能系统，那么对于某些事情来说，这可能就足够了。它可能不像你希望的那样可靠，但它在很多时候是可靠的，如果有人在循环中，那就太好了。但是，如果你的目标是理解智能或获得某种一般智能，这是不够的，它必须更加强大。这就带来了一个问题，我们如何判断，我们如何知道某样东西通常是智能的？我在人工智能领域的大多数同事绝对讨厌图灵测试，但实际上我比我认识的大多数人更喜欢它。</p><p id="2fcb" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">耶雷米哈里斯(28:13): <br/>哦，酷。好吧。我很想听听你的[听不清00:28:15]。</p><p id="b2a2" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (28:17): <br/>到目前为止，我认为它的执行方式有很大的缺陷。很容易忽悠人。很容易糊弄法官。几十年来，我们在AI中已经看到了这一点，追溯到伊莱扎，它愚弄了很多人。</p><p id="7b7a" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">杰瑞米·哈里斯(28:31): <br/>对于那些可能没有深入研究过图灵测试的人来说，我想大多数人对它的工作原理都有一个模糊的概念，但是你能不能介绍一下图灵测试的标准版本，也许是伊莱扎版本？</p><p id="a278" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(28:42): <br/>对。所以图灵自己写了一篇关于这个的论文，提出你有一台机器和一个人，他们互相竞争来说服法官他们是人类。好吧。他们只能用语言交流，你也看不见，因为你不想让他们的样子影响你。所以法官图灵提出，在他的论文中，他认为五分钟的谈话可能会有所启发。事实证明，聊天机器人很容易就能创造出五分钟的对话，而不一定是专家判断，也不一定能骗过法官。伊莱扎是20世纪70年代发展起来的模拟精神分析学家，我想，只是用了非常简单的小模板和回复。这是最早的聊天机器人之一。实际上，人们和它交谈，他们认为它在理解他们。因为人们非常倾向于拟人化，并给他们交流的东西某种代理。</p><p id="c383" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(30:05): <br/>所以我不认为那种图灵测试能告诉我们太多，除了关于人类的易受骗性。但我确实认为，我们也许能够构建出一些图灵测试的版本，它们将会告诉你更多的东西。雷·库兹韦尔和米切尔·卡泊尔之间有一个著名的长期赌注。因此，到2029年，一个人工智能系统是否能够通过图灵测试，他们将每个人赌20，000美元或类似的东西。这是很多年前，他们打赌。但是他们用非常专业的评委进行了这个极其严格的图灵测试，它会持续几个小时，你可以用许多不同的方法来探索它。我读了他们的图灵测试的全部描述，我想，有东西通过了那个测试，我会非常惊讶，但这也让我相信这个系统有一些普遍的智能。</p><p id="cb8d" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (31:09): <br/>事实上，你是在考虑哪些事情可以说服我？我的意思是，这是我希望在这个领域看到更多的东西，因为人们的审美偏好往往是主导因素。我是一个倾向于担心未来的人。因此，我当然会对AGI的生存风险感到担忧。我更容易接受这种观点。在那里看到它真的很酷。而GPT3的角度，我的意思是，在我看来，这似乎是一个有趣的联系到你的一些更当前的问题。因此，在某种程度上，我们担心人工智能的存在风险，这确实会将资源从当前的关注中抽离出来，我认为强调这种权衡是重要的。你是否介意列出你对当前技术使用的最突出的担忧，最严重的担忧？</p><p id="b354" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (31:54): <br/>我的意思是，GPT3是一个很好的起点，因为这种创造虚假媒体、虚假文本或图像、视频、音频等的能力正在以惊人的速度变得越来越好。我们已经看到这些深层的假货有了很大的改进，并且很容易欺骗人们。因此，这可能是一个真正的…我觉得这将是一个非常困难的问题，传播虚假信息，宣传，等等，很快，也许它已经开始了。所以我认为这是一个迫在眉睫的风险。而这些，创造这些假媒体的机器一般都不是智能的，它们不是超级智能的，它们只是日常的深度神经网络。所以我觉得这是个大问题。在这些系统中还有一个很大的问题，种族和性别偏见以及其他种类的偏见，很多人都在试图找出现在该怎么办。</p><p id="0dac" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(33:09): <br/>我认为，还有一个问题是我们对这些系统的可靠性过于信任和乐观。最近有一个委员会发布了一份重要报告，该委员会正在研究自主武器，其中包括谷歌前首席执行官埃里克·施密特和其他技术专家，他们真的觉得我们就要到了，我们几乎到了可以部署自主武器的地步，我们将找出如何证明它们是可靠的等等。我觉得这种过度的技术乐观主义可能会给我们带来一些真正的问题。所以我认为这些是更直接的风险。还有其他类型的关于隐私和监控的公民权利问题，以及许多正在发生的和与国际打交道的事情，弄清楚关于这些技术的国际法规是一个大问题。</p><p id="8945" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (34:19): <br/>实际上，我想这让我想起了另一个关于存在主义风险论点的变体，你可能会觉得更有说服力或更有趣。这只是一个想法，随着这项技术的改进，恶意行为者的破坏性足迹开始增加，我们作为一个物种对自己做可怕事情的能力就像核武器给了我们一种不公平的方式来杀死彼此，也许这最终会导致一些真正灾难性的事情。你认为这可能吗？</p><p id="2179" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(34:48): <br/>当然。我认为存在对恶意行为者的脆弱性。我们已经一次又一次地看到这一点，像网络安全和在我们的汽车、电网和一切事物中部署所有这些人工智能系统和我们所有的设备，这只是让我们暴露在许多漏洞面前。</p><p id="1334" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (35:08): <br/>你如何看待【听不清00:35:10】？你提到了监管，我认为，我非常支持我们必须以某种方式监管这个空间的想法。我想，如何做到这一点是一个复杂的问题，但也是在这个可怕的博弈论困境的背景下，你有美国，你有中国，各种其他全球大国，都在争夺主导地位，都在发展这项技术。他们中的一个当然可以后退一步说，“我们不会发展自主武器，”但当然为什么其他人？这可能是一个像人工智能政策行走一样的问题，但正因为你在这个领域做了这么多思考，你是否有任何直觉，知道在解决这个问题上可能会有一些牵引？</p><p id="9dd5" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(35:49): <br/>这是一个非常困难的问题。正如你所说，这不是我的专业领域，但我认为，就像核武器一样，你必须使用……我们必须有条约、外交和国际压力。对我来说，这有点类似于生物工程，基因工程，这是另一个可能存在风险的来源，如果你愿意的话。我们正在努力解决如何监管这一问题，如何利用联合国和其他国际机构进行国际监管。我认为同样的事情也会发生在人工智能技术上，但这是一个非常困难的问题。</p><p id="8109" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (36:42): <br/>技术人员可以做些什么，比如研究人员，将他们的研究工作集中在你认为可能有帮助的特定方向上吗？人工智能能像解决问题一样成为解决方案的一部分吗？</p><p id="ab62" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(36:53): <br/>是的。我认为人们可以做很多事情，让人工智能更强大，更值得信赖，这是多维度的，但更透明。其中一个问题是，这些人工智能系统是黑匣子。很难弄清楚他们在做什么，如何证明他们和你一样。有人提议让食品和药物管理局负责算法。你如何证明一种算法是安全的，就像你对一种新药或类似药物所做的那样？这将涉及到很多突破，这将是做那种事情所需要的。但这是计算机科学已经研究了很长时间的东西，如何对算法进行验证，并证明他们正在做他们应该做的事情。在这个领域有很多研究可以做。</p><p id="5e45" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (38:01): <br/>在你的书里，我想你也提到了GDPR，也提到了解释权在其中的作用。我很想听听你对此的看法，因为我认为有些人认为GDPR的事情很霸道，但其他人认为这是必要的。然后，看起来你对什么是解释有了一个非常微妙的理解，并由此引发了很多哲学问题。</p><p id="8bcf" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(38:22): <br/>嗯，这是一个困难的问题，因为GDPR是欧盟的法律，其中一部分说，“如果一个算法将影响你的生活，决定你是否会获得贷款，或者你是否会获得住房批准，或者你是否会进监狱或其他什么，它需要能够解释它的推理。”所以如果你有一个十亿参数的深度神经网络，很难说这个东西除了给，还有什么推理，这里是所有的权重。我就知道这么多。对吗？</p><p id="96de" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">杰里米·哈里斯(38:57): <br/>【听不清00:38:57】。</p><p id="a85a" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(38:58): <br/>对。这对我们没有帮助。我们不是这样理解事物的。这种解释必须适合特定人的理解。这是一个哲学问题，对吗？我不认为这对法律职业来说是一个真正的困境，如果他们要提起诉讼，说，“这个算法必须解释它自己。”那到底是什么意思？让我们找一些专家证人哲学家来谈谈解释的本质和[听不清00:39:30]等等。会很乱的。我不知道事情会如何发展。真的很有意思。但他们谈论人工智能夺走工作，但我认为它将创造许多新的工作，因为它将创造一个全新的法律、哲学领域，一种人们评估风险的道德哲学，诸如此类。</p><p id="2c58" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (40:02): <br/>我经常听到这样的说法，我想软件会吃掉这个世界，不要担心，我们会有更多的开发人员，但不可避免的是，开发人员的时间比它自动化的任务更有价值，这就是为什么它在经济上有利可图。但在这种情况下，我想我们真的发现我们必须在一个期限内完成哲学，我们必须开始加大努力。你乐观吗，总的来说，我的意思是，你沉浸在技术方面，但在人类方面，你认为我们能够及时适应我们的社会来适应这些变化吗？</p><p id="97b9" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(40:36): <br/>不，我的意思是，已经表明我们不能。</p><p id="eefc" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">杰瑞米·哈里斯(40:39): <br/>嗯，我希望能有更乐观的结果。</p><p id="39ca" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (40:42): <br/>不，不，我们还没有适应我们的社会。我们遇到了社交媒体上这种虚假信息的流行，这在现实世界中产生了极端的后果。我们还没能适应。甚至科技公司也在努力适应。他们试图规范自己。这比任何人想象的都要困难得多。光靠技术是解决不了问题的，我认为我们必须有政策和法规。但这意味着要教育一大批非技术人员，让他们能够理解这些领域正在发生的事情。我刚刚在一所法学院的课堂上做了一个客座演讲，学生们正在思考技术和法律，并意识到这在不久的将来将是一个爆炸性的领域。所以他们必须对此有所了解。</p><p id="3045" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Jeremie Harris (41:45): <br/>每次我和人工智能政策方面的人交谈时，我们都会做一些播客，我想他们称之为节奏问题。只是认为政策和监管很难跟上技术的步伐，尤其是当它驾驭这些指数曲线时。似乎在很多情况下，人们都想知道，在系统如何为政策制定工作方面，一个非常基本的界限的重新划定，只是为了使它们更具响应性。你认为这样的事情会发生吗？我们是不是必须以一种启动的速度重复我们的法律，这听起来真的很可怕，但这是你看到发生的事情吗？</p><p id="af3a" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(42:22): <br/>我不知道，因为法律法规似乎进展得非常非常慢。你会看到国会关于社交媒体和算法偏见等的听证会。议员们只是抓耳挠腮，因为他们一点也不明白。他们不知道它是如何工作的。</p><p id="916e" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">耶雷米哈里斯(42:41): <br/>非常令人欣慰。</p><p id="f3ad" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(42:44): <br/>所以我无法想象法律法规能跟上技术的发展。</p><p id="cd6a" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">耶雷米·哈里斯(42:53): <br/>既然如此，研究人员的肩上似乎肩负着很大的责任，因为他们似乎是最适合做这方面工作的人。作为一名研究人员，这种想法如何影响你的注意力，你试图引起注意的事情的种类？</p><p id="d86b" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (43:10): <br/>首先，这让我意识到我作为一名技术人员所受的教育几乎完全没有关于技术的社会影响的任何内容。我认为，也许比法律法规更快的是，技术教育将尝试更多地强调社会影响。我看到全国各地的计算机科学系都在这样做，至少，伦理和社会影响正在成为课程的一部分。人们开始真正关注这一点。我不知道这会有多大帮助。我想我们会看到的。但是至少让人们意识到这些问题是非常重要的。</p><p id="bb66" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">杰里米·哈里斯(44:04): <br/>我想，就像你说的法律，教育进展缓慢，在某些情况下，有点像一代人的时间。希望我们会继续下去。希望我们的人工智能可以帮助我们学得更快。伙计，这就成了一整件事。梅勒妮，非常感谢。我真的很感激。我真的很欣赏你所有的见解。顺便说一句，我想推荐你的书，特别是对那些正在听播客的人，他们是你的长期听众。我们确实谈论了很多关于人工智能风险方面的事情。如果你想换个角度，我真的建议你出去买本书。它叫做《人工智能:思考人类的指南》。我想，梅勒妮，你的网站上有。</p><p id="a8bc" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">Melanie Mitchell (44:40): <br/>他们可以找到从哪里到哪里得到它。是的，绝对的。</p><p id="ded4" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">耶雷米·哈里斯(44:43): <br/>好的。所以我们会在博文中提供一个链接，还会附带一个播客。梅勒妮，再次感谢你。</p><p id="fe4b" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">梅勒妮·米切尔(44:48): <br/>谢谢。这是一次很棒的谈话。</p></div></div>    
</body>
</html>