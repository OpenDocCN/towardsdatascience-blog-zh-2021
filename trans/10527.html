<html>
<head>
<title>Getting Started in Data Science Means Cleaning Up Your Data “Act” First</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">开始学习数据科学意味着首先清理您的数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-started-in-data-science-means-cleaning-up-your-data-act-first-6326bcf4f33b?source=collection_archive---------21-----------------------#2021-10-07">https://towardsdatascience.com/getting-started-in-data-science-means-cleaning-up-your-data-act-first-6326bcf4f33b?source=collection_archive---------21-----------------------#2021-10-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="5c71" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/getting-started" rel="noopener" target="_blank">入门</a></h2><div class=""/><div class=""><h2 id="9b3a" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">用于减少数据混乱的探索性数据分析(EDA)工作流</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/38e676d8523234a1cf216a2bf75c25ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UM6gWHcOMQ-FgDELFJlxVA.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片由<a class="ae lh" href="https://pixabay.com/users/blickpixel-52945/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=568039" rel="noopener ugc nofollow" target="_blank">迈克尔·施瓦森伯格</a>从<a class="ae lh" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=568039" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a>拍摄</p></figure><p id="60d6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在阿姆主演的电影<em class="me"> 8 Mile </em>中，歌曲<a class="ae lh" href="https://www.stlyrics.com/lyrics/8mile/loseyourself.htm" rel="noopener ugc nofollow" target="_blank"> <em class="me"> Lose Yourself </em> </a>抓住了电影的整体构思。你知道我指的是哪一个。像这样开始的那个…</p><blockquote class="mf"><p id="7092" class="mg mh it bd mi mj mk ml mm mn mo md dk translated">“他手心出汗，膝盖发软，手臂沉重。</p><p id="8f5e" class="mg mh it bd mi mj mk ml mm mn mo md dk translated">他的毛衣上已经有呕吐物了，妈妈做的意大利面。</p><p id="a091" class="mg mh it bd mi mj mk ml mm mn mo md dk translated">他很紧张，但表面上看起来很平静，准备好了”</p></blockquote><p id="8b62" class="pw-post-body-paragraph li lj it lk b ll mp kd ln lo mq kg lq lr mr lt lu lv ms lx ly lz mt mb mc md im bi translated">是的，这就是我在新工作中第一次坐在我的新房间时的感觉。铭牌上贴着令人垂涎的头衔“数据科学家”看起来很自信，但是感觉…嗯…紧张。</p><p id="0558" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">有点戏剧性？也许吧。</p><p id="37ba" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但是这种感觉和我的经理给我第一个项目任务时的感觉一点也不一样。</p><blockquote class="mu mv mw"><p id="548a" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">“嘿布兰登。欢迎来到公司。您现在会开发我们的企业微细分模型吗？有你加入，每个人都很兴奋。再见了。”</p></blockquote><p id="4fff" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我从紧张到害怕。我的手心不只是出汗，而是湿透了。为什么我会如此紧张？嗯，这里只是几个原因。</p><p id="f8a8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第一，我生活在学术界回归模型的世界里。我以前从未用聚类分析对数据建模，聚类分析对于细分是必要的。是的，我知道…完全没有…说真的，我是怎么得到这份工作的？</p><p id="24a5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第二，也是这里最重要的一点，我得到了一个相当于SELECT * FROM TABLE_A，TABLE_B，TABLE_C内部连接blah，blah，blah的数据集，它包含300多万行和200多列。</p><p id="dba7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当然，用200个变量建立一个有意义的聚类分析？对吗？我会在后面尖叫。</p><p id="ad97" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">顺便提一句，如果你一直在关注我，你可能也知道我实际上试图一次分析20或30个东西，但很快发现这很痛苦，而且完全没有意义。</p><p id="16ac" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">无论如何，如果不是因为下面的EDA技术，我可能还在研究那个问题。这个特定用例的主要目标是减少数据中可用的维度数量。</p><p id="2dd2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，我们希望评估每一列对于像这样的数据科学问题可能具有的潜在信息价值。因为模型是为了模拟数据中的变化而构建的，所以我们的大部分数据减少和清理都围绕着确定变量是否具有良好的变化。</p><p id="4de7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文中，我将带您了解一个典型的EDA过程，该过程提供了一些常用工具，用于使用Python和Pandas执行数据简化。最终，这些工作使我们能够在数据科学生命周期的后期为更复杂的数据建模准备数据。我们开始吧！</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><p id="655e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这里，我们使用一个常见的表格样式的数据集，包括行和列，来应用一系列重要的任务，帮助我们更深入地理解数据中不同列的潜在价值。</p><h1 id="eeef" class="nh ni it bd nj nk nl nm nn no np nq nr ki ns kj nt kl nu km nv ko nw kp nx ny bi translated">步骤0:加载数据</h1><p id="b10e" class="pw-post-body-paragraph li lj it lk b ll nz kd ln lo oa kg lq lr ob lt lu lv oc lx ly lz od mb mc md im bi translated">这看起来很简单，但是在进行数据分析时需要考虑的一件事是将所需的数据加载到内存中的重要性。因为我们使用的计算机容量有限，所以确保我们的系统大小适合数据分析非常重要。</p><p id="b952" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果处理的数据对于您的系统内存来说太大了，那么使用向下采样来抽取数据的随机样本或者利用本文<a class="ae lh" rel="noopener" target="_blank" href="/what-to-do-when-your-data-is-too-big-for-your-memory-65c84c600585">这里</a>中详细介绍的其他技术是很重要的。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="73a8" class="oj ni it of b gy ok ol l om on">import pandas as pd<br/>import numpy as np</span><span id="13b4" class="oj ni it of b gy oo ol l om on">path = '/path/to/data/'<br/>df = pd.read_csv(path+'data.csv')</span></pre><p id="86be" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面是我们正在处理的数据的样子:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi op"><img src="../Images/05a3a87dae2d2a941e2d61becccaf39b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*COK8N0UTgdzJ2AmbKPPoqw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><h1 id="61a0" class="nh ni it bd nj nk nl nm nn no np nq nr ki ns kj nt kl nu km nv ko nw kp nx ny bi translated">步骤1:信号</h1><p id="5e11" class="pw-post-body-paragraph li lj it lk b ll nz kd ln lo oa kg lq lr ob lt lu lv oc lx ly lz od mb mc md im bi translated">一旦数据在内存中，我们需要元数据信号，使我们能够快速识别变量的信息值。初始清单应该包括检查每一列的数据类型。</p><p id="0fd4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我喜欢构建一个包含所有元数据信号的数据框架，让我能够快速识别有意义的变量。</p><p id="c5d9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在下面的代码中，我们首先创建一个数据帧，其中每一行都是原始数据帧中的一列。然后，我们的代码继续向这些变量添加不同的元数据信号，例如空值的数量、空值的百分比以及使用describe()方法的描述性统计数据。以下是我们纳入元数据数据帧的完整信号列表:</p><blockquote class="mu mv mw"><p id="87b6" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">-变量名</p><p id="84f3" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">-空值的数量</p><p id="ba4b" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">-空值百分比</p><p id="6a69" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">-数据类型</p><p id="931f" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">-数数</p><p id="2618" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">-卑鄙</p><p id="83fa" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">-标准偏差</p><p id="576b" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">-最小值</p><p id="af4d" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">- 25%、50%和75%四分位数</p><p id="2222" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">-最大值</p><p id="4bb1" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">-出现频率最高的变量的值</p><p id="0b96" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">-该变量最频繁值出现的时间百分比</p></blockquote><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="e801" class="oj ni it of b gy ok ol l om on">meta_df = df.isna().sum().reset_index()<br/>meta_df['percent'] = meta_df[0]/len(df)<br/>meta_df = pd.concat([meta_df, pd.DataFrame(df.dtypes, columns=['dtypes']).reset_index(drop=True)], axis=1)</span><span id="2abc" class="oj ni it of b gy oo ol l om on">d = df.describe().T.reset_index()</span><span id="0bb6" class="oj ni it of b gy oo ol l om on">meta_df = meta_df.merge(d, on=['index'], how='left')</span><span id="0e60" class="oj ni it of b gy oo ol l om on">vcs = [pd.DataFrame(df[x].value_counts(normalize=True)).T for x in <br/> list(df.columns)]</span><span id="d0bd" class="oj ni it of b gy oo ol l om on">vcs= [pd.DataFrame((x.idxmax(axis=1), x.max(axis=1))).T.reset_index() for x in vcs if len(list(x.columns)) &gt; 0]</span><span id="450d" class="oj ni it of b gy oo ol l om on">meta_df = meta_df.merge(pd.concat(vcs), on=['index'], how='left') </span><span id="87d9" class="oj ni it of b gy oo ol l om on">meta_df.columns = ['index', '0_x', 'percent', 'dtypes', 'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'max_value','max_percent']</span></pre><p id="0781" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一旦我们的元数据dataframe构建完成，我们就可以构建一个函数，其中包含一系列规则，用于确定任何变量是否可能是坏的。</p><p id="5da5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第一个规则确保至少有一些可变性，因此我们寻找标准偏差等于0的任何列。</p><p id="9163" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第二个规则确保数据的某种分布，因此我们比较四分位数以确保它们不都等于相同的值。</p><p id="70e1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">根据这个建议<a class="ae lh" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3701793/#:~:text=Proportion%20of%20missing%20data,-The%20proportion%20of&amp;text=For%20example%2C%20Schafer%20(%201999%20),10%25%20of%20data%20are%20missing" rel="noopener ugc nofollow" target="_blank">这里</a>，下一个规则标记具有超过10%空值的变量。类似地，我们也标记那些出现频率超过80%的单值变量。</p><p id="9bb1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最后，如果没有最大值，我们也标记变量，这意味着变量没有值。显然，这些规则可以根据不同的值或信号来定制。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="de89" class="oj ni it of b gy ok ol l om on">def bad_flag(row):<br/>    if row['std'] == 0:<br/>        return True<br/>    elif (row['25%'] == row['50%']) and (row['50%'] == row['75%']):<br/>        return True<br/>    elif row['percent'] &gt; .10:<br/>        return True<br/>    elif row['max_percent'] &gt; .80:<br/>        return True<br/>    elif pd.isnull(row['max_percent']):<br/>        return True<br/>    else:<br/>        return False<br/> <br/>meta_df['bad_var'] = meta_df.apply(lambda r: bad_flag(r), axis=1)</span></pre><p id="f742" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在我们已经有了自己的标志，下一步是从主数据帧中删除那些变量。为此，我们列出了“bad_var”值设置为NOT True(！idspnonenote)的列名。=).接下来，我们用一个新的dataframe替换我们的dataframe，该data frame此时只包含感兴趣的列。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="0e0a" class="oj ni it of b gy ok ol l om on">keep = (meta_df['index'].loc[meta_df['bad_var'] != True]).tolist()</span><span id="d498" class="oj ni it of b gy oo ol l om on">df = df[keep]</span></pre><p id="b6ee" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们表现如何？我们从150个变量开始，现在减少到113个，我们已经能够从数据框架中删除37列。</p><h1 id="0c41" class="nh ni it bd nj nk nl nm nn no np nq nr ki ns kj nt kl nu km nv ko nw kp nx ny bi translated">第二步:可视化</h1><p id="af76" class="pw-post-body-paragraph li lj it lk b ll nz kd ln lo oa kg lq lr ob lt lu lv oc lx ly lz od mb mc md im bi translated">上面的步骤很快也很容易完成，因为我们依靠数字表示来帮助评估每个变量的可变性程度。对于一些变量，我们可能仍然不确定它们的信息价值。</p><p id="fd0d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">例如，有些变量在70%的行中只有一个值。如果只有两个选项，这可能没问题，但是如果有两个以上的选项，则剩余值的可变性可能不足以对模型有用。在这些情况下，使用数据的可视化表示可以帮助我们进一步决定保留什么，去掉什么。</p><p id="98f6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第一步是查看我们的元数据数据帧，检查任何异常或可疑的东西。例如，我们的一个变量有超过75%的行被标记为“未知”</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/aae7e100cc94fe86d9c94899360d2d90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*J9G1X0GKenkZrLW0USUYTg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="bbb0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们看看这个变量的条形图:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi or"><img src="../Images/7f0f10f174b4d90cec175ac81b2baf18.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*gbDC00A5iSIZMnCDUl6g4A.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="1c58" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">根据条形图，变量“Variable_2”有两个值，“未知”和“是”在这种情况下，不清楚“未知”值和“是”值之间的差异意味着什么(一些“未知”可能是“是”)，因此我们可以决定消除这个变量。</p><p id="0bf0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们对数据的直观检查揭示的其他观察结果包括“年龄”被默认值“-1”填充，并且相当多的变量具有“未知”的值。虽然对特征工程的正确处理超出了本文的范围，但是这些额外的观察表明需要对特征进行额外的工程处理，以便为模型产生更多有用的数据。</p><p id="6f36" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当执行EDA以进行数据简化时，查看相关矩阵也可能是有用的，因为一些变量可能高度相关，以至于表明它们本质上是相同的变量，因此可以从分析中移除一个或多个变量。换句话说，变量没有给模型增加任何独特的东西。</p><p id="9ca1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">快速目视检查将生成热图。要做到这一点，你需要做的就是遵循代码<a class="ae lh" href="https://seaborn.pydata.org/examples/many_pairwise_correlations.html" rel="noopener ugc nofollow" target="_blank">这里</a>。这是我们使用相同代码的热图:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/3315d9116825fbbe980c5823043888c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*tgnPIef4PJgByVsWt-XiOA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="eee6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">例如，在Variable _ 30-Variable _ 50范围内似乎有一大块变量具有非常高的相关性，保留这些变量可能没有用。</p><p id="8391" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在下面的代码块中，我们更深入地研究了相关性矩阵，只提取了那些相关性高于. 90的变量。</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="ed32" class="oj ni it of b gy ok ol l om on">high_corrs = corr[corr.iloc[:,:] &gt; .90]<br/>meta_corr = high_corrs.isna().sum().reset_index()<br/>potential_drops = meta_corr.loc[(meta_corr[0] &lt; meta_corr[0].mode()[0])]</span></pre><p id="c3ca" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从这里开始，由数据科学家来评估这些变量中哪些应该删除，哪些应该保留。</p><h1 id="494d" class="nh ni it bd nj nk nl nm nn no np nq nr ki ns kj nt kl nu km nv ko nw kp nx ny bi translated">第三步:降维</h1><p id="31e6" class="pw-post-body-paragraph li lj it lk b ll nz kd ln lo oa kg lq lr ob lt lu lv oc lx ly lz od mb mc md im bi translated">如果在执行上述步骤后，我们仍然发现自己有太多的变量，EDA的最后一点是使用探索性因子分析或主成分分析，这对于减少变量的数量同时仍然保持其潜在的信息价值是有用的。这些分析类似于我们在步骤2中生成的关联热图，但更进一步，寻找相关变量组，而不是简单的双变量关联。</p><p id="7293" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因子分析帮助我们识别变量是否有足够的方差，我们可以做两件事情中的一件；将它们组合成它们平均值的一个指数(探索性因子分析)或者只关注一个因子中最重要的变量而忽略其余的(主成分分析)。你可以利用因子分析的结果做更多的事情，但这是我在野外处理数据时最常做的两件事。</p><p id="2200" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">虽然这些技术通常被认为是“无监督的”，因为我们允许算法识别数据的自然分组，但现实是数据科学家必须在执行分析之前应用一些有意义的框架来分组数据。</p><p id="7487" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我说的有意义的框架是什么意思？</p><p id="ad74" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">例如，假设一组变量代表健康的不同方面，而其他变量是来自客户满意度调查的项目。寻找跨越这两个独立数据领域的因素并没有多大意义。因此，我经常发现执行聚类分析的多次迭代来识别可能确实有自然分组的数据的自然分组更有用。</p><p id="f615" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在下面的代码中，我们通过对我们一直在使用的演示数据集执行示例因子分析来完成我们的数据缩减。代码是从这个伟大的因子分析教程<a class="ae lh" href="https://www.datacamp.com/community/tutorials/introduction-factor-analysis" rel="noopener ugc nofollow" target="_blank">这里</a>派生出来的，并应用于我们的数据。以下是对相关步骤的简要概述:</p><blockquote class="mu mv mw"><p id="babf" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">首先，我们列出想要包含的特定列。</p><p id="6c53" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">其次，我们执行充分性测试，以确保因子分析对于给定的数据是可行的。请注意，我们正在寻找小于0.05的p值，这表明相关矩阵不是单位矩阵。</p><p id="28ca" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">第三，我们进行因子分析。</p><p id="b182" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">第四，我们可视化特征值，并在图中寻找“肘”，以帮助我们决定我们的模型应该包括多少因素。</p><p id="c41f" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">接下来，我们重新进行因子分析，并根据我们的“肘”图分析设置因子的数量。</p><p id="97b4" class="li lj me lk b ll lm kd ln lo lp kg lq mx ls lt lu my lw lx ly mz ma mb mc md im bi translated">最后，我们提取因子负载并查看它们，以确定我们可能希望如何组合我们的变量。</p></blockquote><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="c2fa" class="oj ni it of b gy ok ol l om on">#subset our dataframe to focus only on domain relevant variables<br/>df_fac = df.iloc[:,98:]</span><span id="cca0" class="oj ni it of b gy oo ol l om on">import pandas as pd<br/>from factor_analyzer import FactorAnalyzer<br/>import matplotlib.pyplot as plt</span><span id="4ff2" class="oj ni it of b gy oo ol l om on">from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity</span><span id="530e" class="oj ni it of b gy oo ol l om on">#df_fac from optum_data_segmentation.py<br/>df_fac = df_fac.dropna()</span><span id="e10a" class="oj ni it of b gy oo ol l om on">chi_square_value,p_value=calculate_bartlett_sphericity(df_fac)<br/>chi_square_value, p_value</span><span id="2d96" class="oj ni it of b gy oo ol l om on"># Create factor analysis object and perform factor analysis<br/>fa = FactorAnalyzer()<br/>fa.fit(df_fac)<br/># Check Eigenvalues<br/>ev, v = fa.get_eigenvalues()<br/>ev</span><span id="c2ee" class="oj ni it of b gy oo ol l om on"># Create scree plot using matplotlib<br/>plt.scatter(range(1,df_fac.shape[1]+1),ev)<br/>plt.plot(range(1,df_fac.shape[1]+1),ev)<br/>plt.title('Scree Plot')<br/>plt.xlabel('Factors')<br/>plt.ylabel('Eigenvalue')<br/>plt.grid()<br/>plt.show()</span><span id="5991" class="oj ni it of b gy oo ol l om on"># Create factor analysis object and perform factor analysis<br/>fa = FactorAnalyzer()<br/>fa.set_params(n_factors=2, rotation="varimax")<br/>fa.fit(df_fac)</span><span id="323e" class="oj ni it of b gy oo ol l om on">loads = pd.DataFrame(fa.loadings_)<br/>loads_df = pd.concat([loads, pd.DataFrame(list(df_fac.columns))], axis=1)<br/>loads_df.columns = ['Factor_1','Factor_2','Variable']</span></pre><p id="7cc1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">以下是“负载_df”数据帧的样子:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/cdf01521cacf061e5f1675c75450c3c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*Wt_9Ss80KBvZM_mLy7UfpQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="ba08" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在因子负荷的输出中，我们看到大多数变量对因子1的负荷比因子2重。也就是说，我们看到“变量_141”和“变量_143”在因子2上的负载更重。</p><p id="e135" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从这一点来看，降维的下一步是通过平均每个因子上加载的变量来为每个因子创建指数。</p><p id="4ec1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">例如，如果我们想使用“变量_141”和“变量_143”为因子2创建一个索引，我们首先需要注意“变量_143”有一个负负载。因此，在对“Variable_141”进行平均之前，我们需要对该变量进行反向编码。</p><p id="2fff" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">反向编码的一个快速技巧是在平均之前将变量乘以-1。但是，请注意，只有当我们还打算在建模之前对数据进行规范化时，我们才会这样做(对于大多数数据科学模型，这是一个强烈推荐的过程)。</p><p id="d18c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面是创建因子2指数的一些示例代码:</p><pre class="ks kt ku kv gt oe of og oh aw oi bi"><span id="67e1" class="oj ni it of b gy ok ol l om on">df['Variable_143_R'] = -1*df['Variable_143']</span><span id="7763" class="oj ni it of b gy oo ol l om on">df['Factor2'] = df[['Variable_141','Variable_143_R']].mean()</span></pre><p id="de42" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们的清洁行动现在需要2分钟</p><p id="8257" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">既然我们已经花时间减少了数据集中的维度数量，我们就准备将数据传递给更复杂的特征工程，并最终进行下游建模。</p><p id="62f9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">总共减少了50%以上的可用数据，现在我的手心出汗少多了。所以我留给你们这个:</p><blockquote class="mf"><p id="0299" class="mg mh it bd mi mj mk ml mm mn mo md dk translated">“他最好去捕捉这一刻，并希望它不会错过”</p></blockquote><p id="b3c1" class="pw-post-body-paragraph li lj it lk b ll mp kd ln lo mq kg lq lr mr lt lu lv ms lx ly lz mt mb mc md im bi translated">前进！</p><p id="a80b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">比如参与学习数据科学、职业发展或糟糕的商业决策？<a class="ae lh" href="https://www.facebook.com/groups/thinkdatascience" rel="noopener ugc nofollow" target="_blank">加入我</a>。</p></div></div>    
</body>
</html>