<html>
<head>
<title>Addressing the Issue of “Black Box” in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解决机器学习中的“黑箱”问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/addressing-the-issue-of-black-boxes-in-machine-learning-f86429acbb2a?source=collection_archive---------18-----------------------#2021-07-03">https://towardsdatascience.com/addressing-the-issue-of-black-boxes-in-machine-learning-f86429acbb2a?source=collection_archive---------18-----------------------#2021-07-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="2548" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/model-interpretability" rel="noopener" target="_blank">模型可解释性</a></h2><div class=""/><div class=""><h2 id="90b3" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">在模型预测中创造更多透明度和可解释性的4个必须知道的技术</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/9a31c312204bf9556bdd9fdf36e3a499.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_2U43_mr-l6818Vc"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@will0629?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">威尔·波拉达</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="3875" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">毫无疑问，近几十年来，机器学习模型席卷了整个世界。他们识别模式和生成预测的能力远远超过任何其他形式的统计技术，这是真正了不起的，很难与之抗衡。</p><p id="df0e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，尽管它有很多有希望的优势，许多人仍然持怀疑态度。具体来说，机器学习模型面临的主要挫折之一是缺乏透明度和可解释性。</p><p id="071c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">换句话说，尽管机器学习模型非常能够生成非常稳健和准确的预测，但当人们试图检查和理解这些预测背后的逻辑时，往往会以复杂性为代价。</p><p id="cddb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文中，我们的目标是通过回答两个基本问题来解开和解决黑盒模型的问题:</p><ul class=""><li id="d6c4" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">模型认为数据中的哪些特征最重要？</li><li id="6f36" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">在宏观意义上以及在个案基础上，每个特征如何影响模型的预测？</li></ul><p id="aa2f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了帮助我们回答这些问题，我们将探索4种独特的技术，并讨论如何使用每种技术来提高模型预测的透明度:</p><ul class=""><li id="2c47" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">特征重要性</li><li id="94a9" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">排列重要性</li><li id="0121" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">部分相关图</li><li id="05b3" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">SHAP价值观</li></ul><p id="1e21" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，如果您准备好开始剥离并检查您的模型如何准确地使用输入数据进行预测，让我们开始吧！</p><p id="1f35" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这篇文章的参考笔记本可以在<a class="ae lh" href="https://www.kaggle.com/jasonchong914/ml-transparency-and-explainability" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="ad98" class="mz na it bd nb nc nd ne nf ng nh ni nj ki nk kj nl kl nm km nn ko no kp np nq bi translated">数据描述和准备</h1><p id="54b8" class="pw-post-body-paragraph li lj it lk b ll nr kd ln lo ns kg lq lr nt lt lu lv nu lx ly lz nv mb mc md im bi translated">医疗费用个人<a class="ae lh" href="https://www.kaggle.com/mirichoi0218/insurance" rel="noopener ugc nofollow" target="_blank">数据集</a>提供了居住在美国的1，338名投保人的保险费用及其个人信息，例如:</p><ul class=""><li id="84f2" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">年龄</li><li id="bd98" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">性</li><li id="9cdb" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">身体质量指数(身体质量指数)</li><li id="198e" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">儿童人数</li><li id="f6d0" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">吸烟状况</li><li id="f39b" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">居住区</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nw"><img src="../Images/2d53cb2926ef20ccc480965db99c5fd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GTYkrdWy0ZwInzhfijJ7Bw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">数据的前5行</p></figure><p id="447e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于保险费用是一个连续变量，这是一个回归问题。我还决定使用随机森林回归作为我们的选择模型。</p><p id="0fd9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">出于本文的目的，让我们不要太担心使用哪个模型，而是将我们的注意力更多地放在学习如何解释我们的模型预测的结果上。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="9624" class="oc na it ny b gy od oe l of og"># Feature encoding <br/>data['sex'] = data['sex'].map({'female': 1, 'male': 0})<br/>data['smoker'] = data['smoker'].map({'yes': 1, 'no': 0})<br/>data = pd.get_dummies(data)</span><span id="fe0a" class="oc na it ny b gy oh oe l of og"># Predictor and target variables<br/>X = data.drop('charges', axis = 1)<br/>y = data.charges</span><span id="e713" class="oc na it ny b gy oh oe l of og"># Train test split<br/>X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 42)</span><span id="54d0" class="oc na it ny b gy oh oe l of og"># Fit random forest model<br/>rf = RandomForestRegressor(random_state = 42).fit(X_train, y_train)</span></pre></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="9252" class="mz na it bd nb nc nd ne nf ng nh ni nj ki nk kj nl kl nm km nn ko no kp np nq bi translated">特征重要性</h1><p id="4475" class="pw-post-body-paragraph li lj it lk b ll nr kd ln lo ns kg lq lr nt lt lu lv nu lx ly lz nv mb mc md im bi translated">几个月前我写过一篇<a class="ae lh" rel="noopener" target="_blank" href="/feature-selection-dimensionality-reduction-techniques-to-improve-model-accuracy-d9cb3e008624">文章</a>，题目是特征选择降维。那篇文章中讨论的技术之一叫做特性重要性。</p><p id="c30f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">本质上，当使用任何基于树的模型时，例如决策树、随机森林或梯度推进，每个特征将被分配一个“特征重要性”,其强调该特征在进行预测时对模型的重要性。</p><p id="0a0e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了理解特征重要性背后的直觉，我们首先讨论决策树算法实际上是如何工作的是很重要的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/b6b3bbc1c1a50759120ab14580220361.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*khuZSO9GosfXsrjJ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片来源<a class="ae lh" href="https://www.kaggle.com/dansbecker/how-models-work" rel="noopener ugc nofollow" target="_blank">丹·贝克尔，卡格尔</a></p></figure><p id="cbf8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">回想一下，当决策树模型适合定型数据时，决策树中的每个节点都表示模型用来将数据分成组的单个功能。这里的目标是以这样一种方式分割数据，即在每次分割后，目标变量中具有相似值的数据最终出现在同一个组中。</p><p id="d7d4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">换句话说，我们希望表现出相同特征的数据被分组在一起，以便当新的看不见的数据进来时，我们的模型将能够通过从树的顶部向下遍历到树的底部来预测其最终值。</p><p id="0981" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">模型是如何决定每个节点使用哪个特性的？嗯，决策树算法经过优化，减少了基尼杂质(分类)和方差(回归)。基尼系数表明了一个观察值被错误分类的概率，而方差表明了一组观察值离均值有多远。因此，在树的每一层，模型将确定给出最低杂质分数或最低方差的特征。</p><p id="2ff2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你想了解更多关于基于树的模型是如何工作的，可以看看我下面的文章:</p><div class="oj ok gp gr ol om"><a rel="noopener follow" target="_blank" href="/battle-of-the-ensemble-random-forest-vs-gradient-boosting-6fbfed14cb7"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd jd gy z fp or fr fs os fu fw jc bi translated">整体之战——随机森林vs梯度推进</h2><div class="ot l"><p class="bd b dl z fp or fr fs os fu fw dk translated">towardsdatascience.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz lb om"/></div></div></a></div><p id="c12d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，回到特征重要性。特征重要性衡量特定特征在帮助我们的模型最小化损失函数方面的有用程度。一个特征在将数据点分成不同的类别方面做得越好，该特征对模型就越重要。</p><p id="ecfe" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面是如何在实践中计算和可视化特征重要性。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="33a2" class="oc na it ny b gy od oe l of og"># Calculate feature importance<br/>importances = rf.feature_importances_<br/>std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis = 0)<br/>indices = np.argsort(importances)[::-1]</span><span id="f22d" class="oc na it ny b gy oh oe l of og"># Plot feature importance<br/>plt.figure(figsize = (10, 5))<br/>plt.title("Feature importances")<br/>plt.bar(range(X_train.shape[1]), importances[indices], yerr = std[indices])<br/>plt.xticks(range(X_train.shape[1]), X_train.columns[indices], rotation = 90)<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pa"><img src="../Images/6629466680ff0c1e65316fa3d6f4c248.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ydgi7V5w_BugSDv_Fk1-oQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">特征重要性</p></figure><p id="578f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正如我们从图表中看到的，3个最重要的特征是:</p><ul class=""><li id="74a9" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">吸烟者</li><li id="b3cf" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">身体质量指数</li><li id="8d9a" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">年龄</li></ul><p id="8443" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这一结果似乎是合理的，因为吸烟习惯、身体质量指数和年龄都是一个人健康状况的常见指标，因此也是他们支付健康保险费的常见指标。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="8018" class="mz na it bd nb nc nd ne nf ng nh ni nj ki nk kj nl kl nm km nn ko no kp np nq bi translated">排列重要性</h1><p id="2fe6" class="pw-post-body-paragraph li lj it lk b ll nr kd ln lo ns kg lq lr nt lt lu lv nu lx ly lz nv mb mc md im bi translated">另一种类似于特征重要性的技术叫做排列重要性。</p><p id="fe02" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">实际上，一旦我们的模型被训练好，排列重要性包括在验证数据中改组单个特征，将目标和其他列留在原位，并随后评估现在改组的数据中预测的准确性。</p><p id="42c2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这种方法有效的潜在原因是，如果我们在进行预测时打乱一个对我们的模型不重要的特征，准确性将在整个排列过程中保持相当一致。另一方面，如果由于重新混合而导致精度下降，则表明该特征对模型很重要。</p><p id="6688" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们看看这在实践中是如何工作的。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="0f52" class="oc na it ny b gy od oe l of og"># Permutation importance <br/>perm = PermutationImportance(rf, random_state = 42).fit(X_val, y_val)<br/>eli5.show_weights(perm, feature_names = X_val.columns.tolist())</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/2a9ff16206190ddef0396520d6420f34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*bRmShOV8J8zUNnHm-5zFDg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">排列重要性</p></figure><p id="cd8f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正如我们所看到的，我们从排列重要性中得到的结果与在特征重要性中得到的结果几乎相同。表顶部的值是最重要的特性，底部的值最不重要。</p><p id="38cb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">作为重新洗牌的结果，将会有一定程度的随机性。因此，正负符号后的数字说明了这种随机性，因为它衡量了一次重组与下一次重组之间的性能差异。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="13a7" class="mz na it bd nb nc nd ne nf ng nh ni nj ki nk kj nl kl nm km nn ko no kp np nq bi translated">部分相关图</h1><p id="5385" class="pw-post-body-paragraph li lj it lk b ll nr kd ln lo ns kg lq lr nt lt lu lv nu lx ly lz nv mb mc md im bi translated">到目前为止，我们已经接触了两种技术，帮助我们确定哪些<strong class="lk jd"><em class="pc"/></strong>变量对模型预测影响最大。</p><p id="a900" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果我们想进一步研究<strong class="lk jd"> <em class="pc">和</em> </strong>如何影响预测呢？接下来我们将探讨的两项技术可以帮助我们完成这项任务。</p><p id="aa5a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了绘制部分相关图，我们反复改变我们感兴趣的变量的值，并基于这些值进行一系列预测。</p><p id="8fed" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在让我们看两个实际的例子。假设我们想知道身体质量指数和年龄如何影响投保人的保险费。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="0663" class="oc na it ny b gy od oe l of og"># Create data to plot <br/>pdp_bmi = pdp.pdp_isolate(model = rf, dataset = X_val, model_features = X_train.columns, feature = 'bmi')</span><span id="824e" class="oc na it ny b gy oh oe l of og"><em class="pc"># Plot data</em><br/>pdp.pdp_plot(pdp_bmi, 'bmi')<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pd"><img src="../Images/c4b307509b1ded629332b97f5f491b59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ICftExVbmm3aC9JpugbOLQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">身体质量指数特征的部分相关图</p></figure><p id="e7ba" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正如我们所见，溢价水平在身体质量指数= 25左右开始上升，在再次上升之前略有下降。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="1abb" class="oc na it ny b gy od oe l of og"><em class="pc"># Create data to plot</em><br/>pdp_age = pdp.pdp_isolate(model = rf, dataset = X_val, model_features = X_train.columns, feature = 'age')<br/><br/><em class="pc"># Plot data</em><br/>pdp.pdp_plot(pdp_age, 'age')<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pe"><img src="../Images/9d75fb3a70cc93efa1812d366360e7f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jimK-VoILNPkuJadLkpc7A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">年龄特征的部分相关图</p></figure><p id="7099" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">另一方面，我们看到保费水平随着年龄的增长而不断增长，尽管增长速度不同:</p><ul class=""><li id="ec3a" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">40岁前</li><li id="d1e7" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">年龄在40-60岁之间</li><li id="d400" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">60岁及以上</li></ul><p id="7055" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们还可以执行二元或二维PDP，向我们展示两个特征之间的相互作用。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="08fa" class="oc na it ny b gy od oe l of og"># 2D partial dependence plot <br/>features_to_plot = ['bmi', 'age']<br/>inter = pdp.pdp_interact(model = rf, dataset = X_val, model_features = X_train.columns, features = features_to_plot)<br/>pdp.pdp_interact_plot(pdp_interact_out = inter, feature_names = X_train.columns, plot_type = 'contour')<br/>plt.show()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/2fc475462c125eb88617d681ef6c5108.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*V-ABjLIMqd3sPbGwr1WDjg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">2D部分相关图</p></figure><p id="32fe" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我希望现在你能看到并理解部分依赖图所提供的额外的复杂性。</p><p id="34e1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用这种技术，我们现在不仅知道哪些特征对我们的模型是重要的，而且更重要的是，这些特征实际上如何影响模型预测。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="dd54" class="mz na it bd nb nc nd ne nf ng nh ni nj ki nk kj nl kl nm km nn ko no kp np nq bi translated">SHAP价值观</h1><p id="8e40" class="pw-post-body-paragraph li lj it lk b ll nr kd ln lo ns kg lq lr nt lt lu lv nu lx ly lz nv mb mc md im bi translated">SHAP是沙普利附加解释的简称。它分解了一个单独的预测，以展示每个起作用的特征的影响。这使我们能够在更具体的基础上研究模型预测。</p><p id="5809" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">例如，这种技术对于银行和保险公司等金融机构特别有用。如果银行拒绝客户的贷款，法律要求银行解释拒绝贷款的依据。同样，如果保险公司选择不承保某人的保险，该公司有义务向该人说明理由。</p><p id="465f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">SHAP值解释了某个特征具有某个值与该特征具有某个基线值的预测相比所产生的影响。</p><p id="4103" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，数据集中的每个要素都有自己的SHAP值，所有SHAP值的总和将解释特定预测和基础值之间的差异，其中基础值是模型输出对训练数据的平均值。此外，我们还可以使用图形来可视化SHAP值的分解。</p><p id="0bd9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">假设我们想要检查验证数据的前3行的SHAP值。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pg"><img src="../Images/a96cd9d3abd74be5bc9e0e1ed200e614.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IsoS90bHro_wiFjumvKb9A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">验证数据的前3行</p></figure><p id="ca7c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先，我们需要定义一个函数来计算和可视化SHAP值分解。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="7d7a" class="oc na it ny b gy od oe l of og"># Define SHAP plot function <br/>shap.initjs()<br/>def shap_plot(index):<br/>    explainer = shap.TreeExplainer(rf)<br/>    shap_values = explainer.shap_values(X_val)<br/>    res = shap.force_plot(explainer.expected_value, shap_values[index], X_val.iloc[index])<br/>    return res</span></pre><p id="d4aa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一旦我们的函数准备好了，我们只需要简单地传入我们想要调查的行的索引。让我们从验证数据的第一行开始。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="c83a" class="oc na it ny b gy od oe l of og"># First row <br/>shap_plot(0)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ph"><img src="../Images/3ab16c67b4ebe36b68edc5ceabb6d392.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4uP1TE9IfFBmdDKocL15Ng.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">验证数据的第一行</p></figure><p id="85b2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">那么，你到底是怎么解读这个的？</p><p id="2363" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先，模型预测保险费用为9，543.19，低于基础值1.355e+4。</p><p id="3389" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">导致预测增加的特征值用粉色表示，而导致预测减少的特征值用蓝色表示。每个彩色条的长度显示了该特征对最终预测的影响程度。</p><p id="c825" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这个特定的场景中，因为预测值低于基准值，所以所有蓝色条的长度加起来都大于粉色条的长度。具体来说，如果从蓝色条减去粉色条，它等于从基础值到预测值的距离。</p><p id="1d98" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">此外，我们还可以观察到，吸烟者= 0(即不吸烟者)是降低该特定个人的保险费用的最重要因素。</p><p id="cb79" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在让我们再看两个例子。</p><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="602f" class="oc na it ny b gy od oe l of og"># Second row<br/>shap_plot(1)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pi"><img src="../Images/597d35b02cb204e18db969894556b4d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KtN6OduQJbY1_eOw7rTmSw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">验证数据的第二行</p></figure><pre class="ks kt ku kv gt nx ny nz oa aw ob bi"><span id="fb6e" class="oc na it ny b gy od oe l of og"># Third row<br/>shap_plot(2)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pj"><img src="../Images/82947a7f67d3dbcfede2066f1ce82c6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mzStnkmBI9-ILLfENgDkoQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">验证数据的第三行</p></figure></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><p id="4419" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">总之，在本文中，我们讨论了4种不同的技术来检查和解释模型预测:</p><ul class=""><li id="3023" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">特征重要性</li><li id="d130" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">排列重要性</li><li id="8dfd" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">部分相关图</li><li id="5c88" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">SHAP价值观</li></ul><p id="6b79" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">希望有了这些新知识，您现在不仅可以开始检查哪些特征对您的模型很重要，还可以检查它们对模型预测的确切影响。</p><p id="7e6d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我想机器学习毕竟是一个黑箱，是吗？</p><p id="cf9b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">非常感谢您的阅读。欢迎随时连接或关注我，了解更多未来内容！</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="da3c" class="mz na it bd nb nc nd ne nf ng nh ni nj ki nk kj nl kl nm km nn ko no kp np nq bi translated">跟我来</h1><ul class=""><li id="c079" class="me mf it lk b ll nr lo ns lr pk lv pl lz pm md mj mk ml mm bi translated"><a class="ae lh" href="https://github.com/chongjason914" rel="noopener ugc nofollow" target="_blank"> GitHub </a></li><li id="57d4" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated"><a class="ae lh" href="https://www.linkedin.com/in/chongjason914/" rel="noopener ugc nofollow" target="_blank">领英</a></li><li id="6529" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated"><a class="ae lh" href="https://www.youtube.com/jasonchong914" rel="noopener ugc nofollow" target="_blank"> YouTube </a></li><li id="15ca" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated"><a class="ae lh" href="https://chongjason.medium.com/" rel="noopener">中型</a></li></ul></div></div>    
</body>
</html>