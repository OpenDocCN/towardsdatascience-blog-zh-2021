<html>
<head>
<title>Data Optimization for Compacted Partitions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">压缩分区的数据优化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-optimization-for-compacted-partitions-7ef1c8a89419?source=collection_archive---------44-----------------------#2021-07-22">https://towardsdatascience.com/data-optimization-for-compacted-partitions-7ef1c8a89419?source=collection_archive---------44-----------------------#2021-07-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="7789" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">TL；速度三角形定位法(dead reckoning)</h1><p id="2f80" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">借助基于使用模式和领域专家确定的高优先级列的智能数据优化，ORC和Parquet等列数据能够创建更小的数据占用空间。这个存储操作是幂等的，不变的。根据数据当前的存储方式，节省的成本可能非常可观。在下面的案例中，我们在存储大小和查询持续时间方面实现了高达70%的缩减。</p><h1 id="9ab2" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</h1><p id="0836" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">因此，您已经创建了一个表。花了几个小时和几天来设置流和/或批处理管道，定义逻辑，解决错误和边缘情况，您已经成功了，祝贺您！您已经有了生产就绪的代码，并且正在用数据填充表分区。剩下的工作就是监控管道，收集统计数据，让用户构建他们的模型并报告任何问题，对吗？在这篇博文中，我们将在这样的假设下工作</p><ol class=""><li id="f651" class="lj lk iq kn b ko ll ks lm kw ln la lo le lp li lq lr ls lt bi translated">我们正在处理Pb级的大型数据湖:具有许多GB的分区和TB级的目录，</li><li id="26f6" class="lj lk iq kn b ko lu ks lv kw lw la lx le ly li lq lr ls lt bi translated">潜在的问题与小的非最佳叶文件有关，与集群设置、架构等无关。</li></ol><h1 id="6d36" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">小活页文件</h1><p id="5b1b" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">过了一段时间，我们的表已经写了许多小时、天、月等。我们的用户报告说，即使在访问单个分区时，表也很慢。经过调查，我们注意到管道正在分区中写入许多小的叶子文件。</p><p id="ff7a" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">小叶子文件问题是什么？</p><p id="893f" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">小文件是指比HDFS块大小小得多的文件。对于parquet和orc文件，大型数据的最佳文件大小在512MB到1024MB之间。由于我们处理的是大数据，我们的HDFS块大小将是256MB。也就是说，我们的叶文件是块大小的2–4倍，这是最佳设置。</p><p id="0a9c" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">为什么我们会看到非最佳分区大小？</p><p id="43d7" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">默认情况下，Spark将在每个分区写入200个文件，因为<code class="fe mc md me mf b">spark.sql.shuffle.partitions=200</code>会引入一个会产生混洗的动作。在仅映射写入中，文件的数量将与初始分区的数量相关。在下面的示例中，假设正在从数据工程/模型管道写入数据，该管道在写入数据之前应用了一些逻辑，从而引入了洗牌(对于大多数产生业务使用表的管道逻辑来说是常见的)。</p><p id="ebdb" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">但是，根据您的集群设置或用户指定的设置，该数字可能会更高或更低。假设我们的表是按日和小时划分的。对于给定的一天，我们有24个小时，每个分区在10GB到25GB之间。我们的叶文件将在51.2MB和128MB之间。</p><h1 id="dcc0" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">天真的方法</h1><p id="b47a" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">对于此表，我们保留了90天的滚动数据。该表包含432，000个不大于128MB的叶文件，我们知道平均每天的数据量约为2TB，因此该目录约为180TB。使用3因子复制，我们看到的数据占用空间为540TB。根据我们的同事和/或以前的经验，我们知道我们需要建立一个数据压缩工作。要做到这一点，我们可以使用联合或重新划分，但重新划分的使用将涉及洗牌。我们应该使用哪一个？因为不需要洗牌而合并？考虑8GB的分区:</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mg"><img src="../Images/15d683f67a494b22c7f519d043c9558b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fu1bC3WqZkvS4HtKCDuzfA.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">图片拍摄于<a class="ae mw" href="https://tech.trueanalytics.ai/posts/data-optimization-for-compacted-partitions/" rel="noopener ugc nofollow" target="_blank">https://tech . true analytics . ai/posts/data-optimization-for-compacted-partitions/</a></p></figure><p id="1466" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">在简单的方法中，我们设置一个全局联合或重新分区值，而不是每个分区的值。</p><p id="cb42" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">有了coalesce，我们的运行时间会更快，因为它不需要洗牌，数据大小也不会改变。但是，coalesce不能保证它将数据平均分配到文件中，因此，我们不能使用值8，这将导致文件大小介于128MB和1024MB++之间，具体取决于使用全局值的最佳分区。</p><h1 id="1c90" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">再分</h1><p id="3bb6" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">对于重新分配，我们引入洗牌。不过，混洗的好处是，当Spark写入数据时，叶文件的大小将相对相等。一个有趣的值是分区的数量。如果重新分区将产生相同大小的叶文件，为什么我们不应该使用8？由于重新分区会改变数据，如果数据有自然的顺序，列压缩的好处可能会被破坏。这意味着重新分区会产生3种潜在结果，它可以将数据打乱更好的自然顺序，数据将会减少，它可能不会立即影响数据大小，或者它可能会使数据变得更糟，实际上导致数据大小增加。</p><h1 id="9b95" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">优化方法</h1><p id="33fa" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">怎样才能做得更好？首先，我们需要了解我们的数据。由此，哪些列对于模型构建、数据分析、过滤等是最重要的。使用该表时，某些列是否比其他列更重要？在过滤的情况下，我们不考虑分区列，因为当用户指定where <code class="fe mc md me mf b">partition_col = some_partition</code>时，分区修剪会处理这些列。</p><h1 id="e45c" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">线性排序</h1><p id="466a" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">对于线性排序，我们希望按照层次结构中最有影响力的列来编写数据。要确定感兴趣的列，最好咨询表所有者、该表的高级用户以及这些数据源的主题专家(SME)。此外，对多列进行线性排序时，优先级基于它们在子句中的指定顺序，也就是说，列表中第一列的影响比最后一列大。因此，只需要挑选少数几个(不超过10个，但我建议少于10个)列。</p><p id="6ceb" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">大约在2020年3月至4月，我们True Analytics Tech在我们最大的数据集上展示了线性排序的优势。我们查看了两周的数据。当我们在下图中谈论运行时间时，这是为了运行计数。在每种情况下，我们在JVM预热后收集10次运行的结果。在一个更复杂的运行时测试中，这里没有显示，我们聚集了一些数据，并将其连接回原始数据2周。在优化的数据上，它运行了大约5到10分钟。然后，我们用克隆数据(2周)和表中的数据对它进行了测试。两者都花了1个小时才完成50%。我们克隆了2周的数据来运行，因此我们可以确定较长的运行时间与表的完整大小无关。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mx"><img src="../Images/ebff5f7be6380f3f2706dc8c1490c29f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uSEuV_FrCQj_BzXstu5mMw.png"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">图片取自<a class="ae mw" href="https://tech.trueanalytics.ai/posts/data-optimization-for-compacted-partitions/" rel="noopener ugc nofollow" target="_blank">https://tech . true analytics . ai/posts/data-optimization-for-compacted-partitions/</a></p></figure><p id="45b5" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">我们的数据占用空间减少了77%,在2周的采样数据中，运行时间减少了约90%。由于这一结果，我们决定在我们最大的数据集上全面应用这一点，并在2020年优化我们的传入数据和旧数据。</p><p id="f55b" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">该表中的数据已经增长到每天大约2TB，通过应用线性排序，我们每天能够减少1.5TB的数据占用空间，并且通过3因子复制，我们每天可以节省4.5TB的数据。下面，您将看到由数据模型团队生成的数据监控，他们对我们的一个较大的数据集进行压缩。我们在删除非最佳数据之前等待了8天，因此尚未清理的数据将显示大约2.5TB，因为两个源都存在。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi my"><img src="../Images/4e3f9a1d3c7262227f386bf415990170.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FEz_6_T2q7Pkfqd9.png"/></div></div></figure><p id="15d6" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">我们对此基础层的保留策略是90天，由此，我们有3个按小时、天、月派生的聚合层，目前我们将保留大约1-2年。我们在这张单个表格上展示的累计节省为1.322PB。此外，我们的受众团队还优化了他们的数据存储，又节省了1PB。也就是说，截至2021年6月17日，我们已经保存了2.331PB的数据。</p><p id="39ff" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">在True Analytics，我们在内部存储数据。然而，为了说明优化压缩流程的好处，我们来看看<a class="ae mw" href="https://aws.amazon.com/s3/pricing/" rel="noopener ugc nofollow" target="_blank">亚马逊的定价层</a>。我们将只关注存储节省，但请记住，最终用户将体验到运行时间的减少。对于新加坡地区，标准S3的成本是第一个50TB 0.025美元，第二个450 TB 0.024美元，之后0.023美元，这是每月的费用。对于亚马逊定价，我们基于1个因素；即2.331 * 1024 / 3 = 795TB。通过减少数据占用空间，我们每月将节省19，287.04美元(623，164泰铢)的成本。</p><h1 id="60a1" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">空间填充曲线</h1><p id="fb2a" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">空间填充曲线是我们可以用来优化数据的另一种广泛使用的方法。同样，我们希望确定最有影响的列，使用的列数规则在这里仍然适用。</p><p id="ad5b" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">空间填充曲线有多种风格:</p><ul class=""><li id="36db" class="lj lk iq kn b ko ll ks lm kw ln la lo le lp li mz lr ls lt bi translated">阿砣</li><li id="92b1" class="lj lk iq kn b ko lu ks lv kw lw la lx le ly li mz lr ls lt bi translated">科赫</li><li id="8f17" class="lj lk iq kn b ko lu ks lv kw lw la lx le ly li mz lr ls lt bi translated">希尔伯特</li><li id="c2f4" class="lj lk iq kn b ko lu ks lv kw lw la lx le ly li mz lr ls lt bi translated">莫顿</li></ul><p id="fc91" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">举几个大的例子。</p><p id="9423" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">为什么我们要使用空间填充曲线，而不仅仅是使用线性排序？如上所述的线性排序涉及多维索引，其中每个索引对查询结果的权重越来越小。如果您正在寻找存储数据的最佳方式，那么我们需要做的就是减少数据占用空间并能够将多维索引映射到一维。这就是空间填充曲线发挥作用的地方。这里我们来看一个在一组<code class="fe mc md me mf b">(x, y)</code>坐标上使用莫顿曲线(Z排序)的例子。考虑设置<code class="fe mc md me mf b">{(1, 1), (1, 8), (2, 1), (3, 1)}</code>。这个集合目前按x，y线性排序，在Z排序中，会发生什么？</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi na"><img src="../Images/bd7821d987401bb4171c4645876f8233.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*SrMje2_PtV28okpwUck1Gg.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">图片摘自<a class="ae mw" href="https://tech.trueanalytics.ai/posts/data-optimization-for-compacted-partitions/" rel="noopener ugc nofollow" target="_blank">https://tech . true analytics . ai/posts/data-optimization-for-compacted-partitions/</a></p></figure><p id="135b" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">如果我们根据比特交织的结果对数据进行排序，我们将得到<code class="fe mc md me mf b">{(1, 1), (2, 1), (3, 1), (1, 8)}</code>。在x完全排序之前，y在排序中起作用，允许其他变量列对排序后的数据产生影响。</p><p id="649a" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">当与表列统计一起使用时，空间填充曲线可以加快数据检索速度。发生这种情况时，查询可以跳过较大的数据块，从而最大限度地减少需要遍历的文件数量。在这里，在分析平台上，我们运行了Z排序，并将其与我们的原始和线性结果进行了比较。我们看到线性排序的数据占用空间减少了16%。在这种情况下，我们的原始数据是1.5TB，线性数据是398GB，应用Z排序时是334GB。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nb"><img src="../Images/ff68f388d9b26bbc7196e7156e83447d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*73edfFysq0J69Xxk.png"/></div></div></figure><p id="a7e6" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated">我们还没有对带有表统计的大型数据集进行完整的性能测试。我们无法显示使用Z排序对数据的好处。然而，Amazon和Databricks都有文章概述了使用Z排序时的性能提升。对于我们的用例，我们既没有使用Amazon集群，也没有在Deltalake中使用Databricks优化。一切都是内部构建的，用于我们的内部集群。</p><h1 id="328e" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">确认</h1><p id="318d" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们运行了一个验证套件来验证数据优化在数据方面是一个等幂变换。首先，我们在原始数据和优化数据的列上运行计数、最小值、最大值等标准指标，最后对两个数据集进行哈希运算以生成校验和。</p><h1 id="d061" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结论</h1><p id="f132" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在我们开始使用这种优化压缩的一年半时间里，我们已经在最大的数据集上节省了50–70%的数据。这提高了我们的集群利用率，减缓了我们的服务器扩展速度，使我们的运营团队不必经常重新平衡节点，并实现了性能提升，使我们的数据模型和数据科学团队能够以更少的资源更快地运行他们的管道。然而，我们还没有完成。我们正在将数据压缩扩展到本地集群中的大多数数据集。</p></div><div class="ab cl nc nd hu ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="ij ik il im in"><p id="00ec" class="pw-post-body-paragraph kl km iq kn b ko ll kq kr ks lm ku kv kw lz ky kz la ma lc ld le mb lg lh li ij bi translated"><em class="nj">原载于2021年7月22日</em><a class="ae mw" href="https://tech.trueanalytics.ai/posts/data-optimization-for-compacted-partitions/" rel="noopener ugc nofollow" target="_blank"><em class="nj">https://tech . true analytics . ai</em></a><em class="nj">。</em></p></div></div>    
</body>
</html>