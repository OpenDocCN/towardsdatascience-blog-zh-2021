<html>
<head>
<title>Learn How To Use Spark ML and Spark Streaming</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解如何使用Spark ML和Spark流</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learn-how-to-use-spark-ml-and-spark-streaming-3a731485d052?source=collection_archive---------9-----------------------#2021-06-13">https://towardsdatascience.com/learn-how-to-use-spark-ml-and-spark-streaming-3a731485d052?source=collection_archive---------9-----------------------#2021-06-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0522" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">关于如何使用SparkML对使用PySpark的流数据进行预测的教程</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/00cbe32125f169231a46905daecbb0ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cKBWrL5qgeOKB_hoPQ-Tsg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">马库斯·温克勒在<a class="ae kv" href="https://unsplash.com/s/photos/tutorial?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="5368" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">目标:</strong></h1><p id="f779" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在本文中，我将通过一个例子来说明如何使用Spark ML来预测流数据。请注意，我们不会将重点放在比较不同的模型和调整模型上。主要的焦点将是我们如何能够结合火花流来使用数据块进行预测。除此之外，您应该对如何使用Spark ML有一些基本的了解。如果你对Spark ML不熟悉，可以看看下面的视频。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mk ml l"/></div></figure><p id="028b" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">对于这个例子，我们将根据某人的年龄、性别和医疗状况来预测他是否会心脏病发作。逻辑回归将被训练，我们流入看不见的数据来做预测。</p><h1 id="0c9c" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">数据收集:</strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/122ce65a08fc43fdc32475ae8f0e4bb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v-V9b7CSvcQgOjidKNBcZw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">杰西·奥里科在<a class="ae kv" href="https://unsplash.com/s/photos/heart-attack?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="8bc2" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">对于这个项目，我使用了Kaggle上可用的数据集。如果您想跟进，请点击此处的<a class="ae kv" href="https://www.kaggle.com/rashikrahmanpritom/heart-attack-analysis-prediction-dataset" rel="noopener ugc nofollow" target="_blank"/>。数据由303行和14列组成。每行代表一名患者的信息。此数据集的要素由以下各列组成:</p><ul class=""><li id="352c" class="ms mt iq lq b lr mm lu mn lx mu mb mv mf mw mj mx my mz na bi translated">年龄:以年为单位的年龄1。年龄:以年为单位的年龄</li><li id="059e" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">性别:性别(1 =男性；0 =女性)</li><li id="1b71" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">cp:胸痛型(1 =典型心绞痛；2 =不典型心绞痛；3 =非<br/>心绞痛；0 =无症状)</li><li id="7299" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">trtbps:静息血压(入院时以毫米汞柱为单位)</li><li id="b679" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">chol:血清胆固醇，单位为毫克/分升</li><li id="5798" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">fbs:空腹血糖&gt; 120 mg/dl (1 =真；0 =假)</li><li id="e9f3" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">restecg:静息心电图结果(1 =正常；2 = ST-T<br/>波异常；0 =肥大)</li><li id="c732" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">thalachh:达到最大心率</li><li id="99a2" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">exng:运动诱发心绞痛(1 =是；0 =否)</li><li id="d916" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">oldpeak:相对于静息运动诱发的ST段压低</li><li id="8ff3" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">slp:运动ST段峰值的斜率(2 =上坡；1 =平坦；<br/> 0 =下降)</li><li id="79ec" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">caa:透视着色的主要血管数(0-3)</li><li id="80f7" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">thall: 2 =正常；1 =固定缺陷；3 =可逆缺陷</li></ul><p id="2e75" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">目标列如下:</p><ul class=""><li id="e784" class="ms mt iq lq b lr mm lu mn lx mu mb mv mf mw mj mx my mz na bi translated">输出:0=心脏病发作几率降低，1=心脏病发作几率增加。</li></ul><p id="0c0b" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">第一步是创建一个模式，以确保在读取csv文件时数据包含正确的数据类型。接下来，我们将使用spark.read.format()函数，以“csv”作为参数，添加选项以读入标头，并将我们创建的模式分配给数据框。最后，我们加载数据，我们还将目标列更改为label，以便我们的逻辑回归可以识别目标变量是哪一列。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="ed5c" class="nl kx iq nh b gy nm nn l no np">from pyspark.ml import Pipeline<br/>from pyspark.sql.types import StructType,StructField,LongType, StringType,DoubleType,TimestampType</span><span id="e8fe" class="nl kx iq nh b gy nq nn l no np"># We use the following schema<br/>schema = StructType( \<br/>                     [StructField("age", LongType(),True), \<br/>                      StructField("sex", LongType(), True), \<br/>                      StructField("cp", LongType(), True), \<br/>                      StructField('trtbps', LongType(), True), \<br/>                      StructField("chol", LongType(), True), \<br/>                      StructField("fbs", LongType(), True), \<br/>                      StructField("restecg", LongType(), True), \<br/>                      StructField("thalachh", LongType(), True),\<br/>                      StructField("exng", LongType(), True), \<br/>                      StructField("oldpeak", DoubleType(), True), \<br/>                      StructField("slp", LongType(),True), \<br/>                      StructField("caa", LongType(), True), \<br/>                      StructField("thall", LongType(), True), \<br/>                      StructField("output", LongType(), True), \<br/>                        ])</span><span id="c8ec" class="nl kx iq nh b gy nq nn l no np">data = "dbfs:/FileStore/tables/heart.csv"<br/>df=spark.read.format('csv').option('header',True).schema(schema).load(data)<br/>df = df.withColumnRenamed("output","label")<br/>df.display()<br/>df.printSchema()</span></pre><p id="7ecf" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">一旦我们运行上面的代码，我们会得到下面的输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/58393c6006aa43a2b5ad0b387511804f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nEe4z484FGTzVm1_pO124A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="17ee" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">机器学习:</strong></h1><p id="c0d0" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">说到数据预处理步骤，我首先将数据分为训练集(70%)和测试集(30%)。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="6433" class="nl kx iq nh b gy nm nn l no np">testDF, trainDF = df.randomSplit([0.3, 0.7])</span></pre><p id="e913" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">之后，我创建了一个包含五个阶段的管道。第一阶段是一个向量汇编器，它接收age、trtbps、chol、thalachh、oldpeak列，并将它们转换成一个向量。第二阶段需要上述特征的缩放过程。我使用pyspark.ml.feature库中的MinMaxScaler()函数。之后，我一次性编码了sex、cp、fbs、restecg、slp、exng、caa和thall列，因为它们是名义上的分类变量。接下来，我创建了第二个矢量组装器，并将一个hot编码列和缩放特征添加到一个矢量中。最后但并非最不重要的是，最后一个阶段由具有以下参数的逻辑回归组成:</p><ul class=""><li id="118f" class="ms mt iq lq b lr mm lu mn lx mu mb mv mf mw mj mx my mz na bi translated">maxIter = 10</li><li id="c495" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">regParam = 0.01</li></ul><p id="c379" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">我选择了逻辑回归算法，因为我们的目标由二进制数(0和1)组成。一旦创建了管道，我就调整并转换训练集。之后，我选择标签、概率和预测列。训练模型时，请参见下面管道施工和预测的片段。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="4998" class="nl kx iq nh b gy nm nn l no np">from pyspark.ml.feature import OneHotEncoder<br/>from pyspark.ml.feature import MinMaxScaler<br/>from pyspark.ml.feature import StringIndexer<br/>from pyspark.ml.feature import VectorAssembler<br/>from pyspark.ml.feature import OneHotEncoder<br/>from pyspark.ml.classification import LogisticRegression</span><span id="5ec3" class="nl kx iq nh b gy nq nn l no np"># Create the logistic regression model<br/>lr = LogisticRegression(maxIter=10, regParam= 0.01)</span><span id="2021" class="nl kx iq nh b gy nq nn l no np"># We create a one hot encoder.<br/>ohe = OneHotEncoder(inputCols = ['sex', 'cp', 'fbs', 'restecg', 'slp', 'exng', 'caa', 'thall'], outputCols=['sex_ohe', 'cp_ohe', 'fbs_ohe', 'restecg_ohe', 'slp_ohe', 'exng_ohe', 'caa_ohe', 'thall_ohe'])</span><span id="9707" class="nl kx iq nh b gy nq nn l no np"># Input list for scaling<br/>inputs = ['age','trtbps','chol','thalachh','oldpeak']</span><span id="d013" class="nl kx iq nh b gy nq nn l no np"># We scale our inputs<br/>assembler1 = VectorAssembler(inputCols=inputs, outputCol="features_scaled1")<br/>scaler = MinMaxScaler(inputCol="features_scaled1", outputCol="features_scaled")</span><span id="d432" class="nl kx iq nh b gy nq nn l no np"># We create a second assembler for the encoded columns.<br/>assembler2 = VectorAssembler(inputCols=['sex_ohe', 'cp_ohe', 'fbs_ohe', 'restecg_ohe', 'slp_ohe', 'exng_ohe', 'caa_ohe', 'thall_ohe','features_scaled'], outputCol="features")</span><span id="a25a" class="nl kx iq nh b gy nq nn l no np"># Create stages list<br/>myStages = [assembler1, scaler, ohe, assembler2,lr]</span><span id="c5ab" class="nl kx iq nh b gy nq nn l no np"># Set up the pipeline<br/>pipeline = Pipeline(stages= myStages)</span><span id="2e37" class="nl kx iq nh b gy nq nn l no np"># We fit the model using the training data.<br/>pModel = pipeline.fit(trainDF)</span><span id="0752" class="nl kx iq nh b gy nq nn l no np"># We transform the data.<br/>trainingPred = pModel.transform(trainDF)</span><span id="ac4f" class="nl kx iq nh b gy nq nn l no np"># # We select the actual label, probability and predictions<br/>trainingPred.select('label','probability','prediction').show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/eee9c773a884f0e21eed64a785f2f15b.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*zuboUVehkooeOcT86r6bIA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="acdd" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">正如我们在上面看到的，标记的黄色行表明概率越低，模型越有信心预测为1。另一方面，标记的红色行显示概率越高，它预测输出为零就越确定。除此之外，我还评估了模型的性能，计算了总的准确度分数。请看下面我如何计算准确度分数的代码片段。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/6f621f037c98f2ff6df3c2cb9a9079ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*APtDWELUtPh2q4eCeBs3WQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="5f7f" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">在对训练数据进行模型训练时，准确率达到了0.902913%，这是一个令人满意的结果。</p><h1 id="741c" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">流媒体:</strong></h1><p id="b4ba" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">为了合并Spark流，我将测试数据集重新划分为十个不同的文件来复制流模拟。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="b04f" class="nl kx iq nh b gy nm nn l no np"># We now repartition the test data and break them down into 10 different files and write it to a csv file.<br/>testData = testDF.repartition(10)</span><span id="5f63" class="nl kx iq nh b gy nq nn l no np">#Remove directory in case we rerun it multiple times.<br/>dbutils.fs.rm("FileStore/tables/HeartTest/",True)</span><span id="20c6" class="nl kx iq nh b gy nq nn l no np">#Create a directory<br/>testData.write.format("CSV").option("header",True).save("FileStore/tables/HeartTest/")</span></pre><p id="8346" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">之后，我首先创建了一个源代码，它由以下代码行组成。</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="78ca" class="nl kx iq nh b gy nm nn l no np"># Source<br/>sourceStream=spark.readStream.format("csv").option("header",True).schema(schema).option("ignoreLeadingWhiteSpace",True).option("mode","dropMalformed").option("maxFilesPerTrigger",1).load("dbfs:/FileStore/tables/HeartTest").withColumnRenamed("output","label")</span></pre><p id="bfce" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">从上面可以看到，我使用spark.readStream，读入一个格式为“csv”的文件。除此之外，我还添加了我在开始读取文件时创建的模式，后面是多个选项，例如:</p><ul class=""><li id="1134" class="ms mt iq lq b lr mm lu mn lx mu mb mv mf mw mj mx my mz na bi translated">ignoreleeadingwhitespace:True→删除前导空格。</li><li id="6211" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">模式:drop formattered→当设置为drop formattered时，将忽略所有损坏的记录。</li><li id="f548" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">maxFilesPerTrigger: 1 →每个触发器中要考虑的新文件的最大数量。</li></ul><p id="9555" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">之后，我从重新划分测试数据的目录中加载数据，以复制流的模拟。最后但同样重要的是，为了实现逻辑回归，我将输出列更改为label。</p><p id="fd43" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">最后一步是建立测试数据的流。我使用适合训练集(pModel)的管道，并使用带有参数“sourceStream”的转换功能，这是我之前创建的源。最后，我选择标签、概率和预测列。请参见下面的代码片段。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/8a2c85b06609d581668f89ef934078f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zQqrQ5VBZHp1OvP3EyU75g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="991d" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">正如我们所看到的，绿灯亮了，这表明我们正在传输看不见的数据，这些数据来自为了传输而重新划分以复制模拟的测试数据。下面是我们的流输出示例，它向我们展示了测试数据的实际标签、概率以及模型对未知数据的预测。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/8d000e0ee786c5d7d6c5423f150846e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y5G_eAgMBpPbcGeUzBq9aQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="f800" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">为了评估对测试数据的预测，我们可以看到流数据属于哪一类的概率。例如，当我们看第1行时，我们可以看到概率列中的向量，它由[0.06936682704327157，0.93631729567284]组成。向量中的第一个元素表示0级(没有心脏病发作)的概率，第二个元素表示1级(心脏病发作)的概率。该模型选取较高的概率值，并将流数据分配给具有较高概率的类。在第一个示例中，模型预测1，当与实际标签进行比较时，这是正确的。</p><h1 id="7ffb" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">最后的话:</strong></h1><p id="ac53" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我希望这个例子能帮助您更好地理解如何使用Spark的流数据进行预测。同样，本文的主要焦点不是关于模型的性能，而是关于我们如何在我们的机器学习模型中使用看不见的流数据。如果您对将Spark流合并到Spark ML有更多的问题，我强烈建议您仔细阅读databricks文档。请查看下面的链接:</p><div class="nw nx gp gr ny nz"><a href="https://docs.databricks.com/_static/notebooks/using-mllib-with-structured-streaming.html" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd ir gy z fp oe fr fs of fu fw ip bi translated">using-mllib-with-structured-streaming.html-数据布里克斯</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">编辑描述</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">docs.databricks.com</p></div></div></div></a></div><p id="53ac" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx mo lz ma mb mp md me mf mq mh mi mj ij bi translated">如果你对这个话题有任何问题或者有任何反馈，请随时联系我。如果你能在任何社交媒体平台上分享这篇文章，我将不胜感激。谢谢，下次再见！✌️</p><div class="nw nx gp gr ny nz"><a href="https://www.navidma.com/" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd ir gy z fp oe fr fs of fu fw ip bi translated">纳维德·马辛奇作品集</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">我已经在分析行业工作了四年多，并且热爱其中的每一秒钟。我是一个高度…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">www.navidma.com</p></div></div><div class="oi l"><div class="oj l ok ol om oi on kp nz"/></div></div></a></div></div></div>    
</body>
</html>