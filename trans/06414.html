<html>
<head>
<title>AutoML Is Not Enough — The Best Analyses Still Need Humans</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AutoML是不够的，最好的分析仍然需要人</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/as-organizations-try-and-empower-democratized-analytics-they-must-consciously-recognize-where-3c73398a9065?source=collection_archive---------44-----------------------#2021-06-08">https://towardsdatascience.com/as-organizations-try-and-empower-democratized-analytics-they-must-consciously-recognize-where-3c73398a9065?source=collection_archive---------44-----------------------#2021-06-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4ce1" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">减少对编码的需求和向更广泛的受众展示数据并没有使探索数据时对人类直觉的需求失效。</h2></div><p id="c816" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">让我们从肯定AutoML工具的威力开始。任何用户，无论技术能力如何，现在都可以在几分钟内建立模型，而以前需要专家数据科学家使用数百行Python。AutoML加速了逐步完成特征工程的过程，尝试许多不同的算法，调整参数，并最终确定一个准确的模型。</p><p id="8bac" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">因此，它已经成为数据科学民主化的重要支柱，因为它从可生产模型的奖励中抽象出编码和算法函数调用。在Einblick，我们亲眼目睹了我们的AutoML工具如何让非技术分析师和运营经理开始用精确的模型取代“直觉”。</p><p id="e26e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">但是对我们来说，AutoML代表了一种工具上的增强，以实现加速模型构建和数据科学民主化的目标。然而，它不是一根魔杖，一挥就能立刻创造出数据科学。一个更现实的类比可能是，自动化工具是电动开罐器。它们可以解放双手使用，比手动启动更快更干净地完成目标。</p><p id="6fc7" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">因此，对组织领导的一个重要提醒是，不要过度投资于技术自动化解决方案，而是应该更多地投资于人和过程。</p><h2 id="1f4e" class="lc ld iq bd le lf lg dn lh li lj dp lk kp ll lm ln kt lo lp lq kx lr ls lt lu bi translated"><strong class="ak"> 1。领域知识提高了投入</strong></h2><p id="be58" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated">基本的特征工程和数据清理工具已经融入了大多数AI / ML工具。领先的AutoML平台(简单而无耻地宣传我自己的产品，<a class="ae ma" href="https://einblick.ai/product/" rel="noopener ugc nofollow" target="_blank"> Einblick </a> here <em class="mb"> ) </em>将包括一组类似的候选转换，包括一次性编码(分类变量到1/0)、插补、缩放、比率、NLP文本特征提取。然而，这些方法是一种“看棍子”的方法。</p><p id="abcd" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">然而，基于人类的领域知识具有一些比较优势，这些优势增强了自动特征工程，包括以下内容:</p><ul class=""><li id="2830" class="mc md iq ki b kj kk km kn kp me kt mf kx mg lb mh mi mj mk bi translated"><strong class="ki ir">对模式</strong>的真实世界激励变化的检测:人类可能识别出数据集的变化，其代表发生的可命名事件。例如，组织启动了一项新计划、发生了战略转移、发生了自然灾害、发生了金融危机等。该模型只能从数据中的低级统计模式所揭示的信息中进行推断。而人类的直觉依赖于大量的额外知识来解释数据。</li><li id="c25b" class="mc md iq ki b kj ml km mm kp mn kt mo kx mp lb mh mi mj mk bi translated"><strong class="ki ir">基于期望值的异常值识别</strong>:AutoML算法可能能够识别3个标准差之外的变量，并消除它们。然而，与上面类似，理解价值观是否合法是人类的任务。以一家零售银行为例:900分的信用评分似乎是可行的，但不在标准评分300-850分的可能范围内。相比之下，100万美元的支票账户很少，比平均水平高得多，但我们马上知道这是可能的。领域知识允许分析师对无关值是否合法进行分类。</li><li id="2c38" class="mc md iq ki b kj ml km mm kp mn kt mo kx mp lb mh mi mj mk bi translated"><strong class="ki ir">智能和可解释的数据转换</strong>:一个经典的例子是体重和心脏病发作之间的关系。虽然[<em class="mb">体重</em>与[<em class="mb">心脏病发作</em>正相关，但更好的预测可能是[<em class="mb">体重</em>/[<em class="mb">身高</em>]，因为非常高和重的人可能仍然健康。更多的专业知识可以告诉你，分母的平方就是身体质量指数——这是一个常用的指标。</li></ul><h2 id="234d" class="lc ld iq bd le lf lg dn lh li lj dp lk kp ll lm ln kt lo lp lq kx lr ls lt lu bi translated"><strong class="ak"> 2。可解释性工具必须创建讨论，然后是迭代</strong></h2><p id="a38c" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated">模型只有在实现时才有帮助。通过能够清楚地传达模型正在做什么，解决问题，并解决关于输入驱动因素和输出影响的任何分歧点，可以赢得认同。</p><p id="7ad5" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">AutoML确实有一系列可用的模型解释功能，从对变量重要性进行排序和让用户处理数据，到部分依赖图和独立条件期望的可视化。但这些是数据科学家的工具。它们没有帮助传播信息，也没有向与分析相关的广泛的利益相关者解释模型。团队和工具必须超越固定的包，以促进涉众更好地理解来驱动迭代:</p><ul class=""><li id="db6d" class="mc md iq ki b kj kk km kn kp me kt mf kx mg lb mh mi mj mk bi translated"><strong class="ki ir">预测结果的描述性可视化</strong>:虽然有用，但代表最佳模型可解释性工具的预装箱输出需要对过程的信任而不需要理解，或者潜在地需要太多先前的数据科学知识。相反，实际的描述性分析应该在模型上运行。价值是否有意义，细分是否如我所料存在，当我可视化针对关键驱动因素的预测时，是否有任何无法解释的模式，等等？被确定为重要的变量可以通过驾驶员分解的目标响应变量的快速标准化直方图来确认。</li><li id="3f00" class="mc md iq ki b kj ml km mm kp mn kt mo kx mp lb mh mi mj mk bi translated"><strong class="ki ir">快速评估变更的影响</strong>:模型需要一次又一次的运行。基于这些结果，用户应该能够灵活地跳回到数据流任务来扩充数据集，转向描述性的视觉效果来检查假设，或者只是重新运行没有坏变量的模型。AutoML工具是找到好模型的好方法，但这并不意味着它们足以一次性解决问题。</li></ul><p id="9078" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">总之，不要只关注自动模型，而忽略了在模型创建后与数据进行人工交互的需要。许多AutoML工作流隐含地断言“信任我们”如果模型的统计数据看起来不错，并且是由智能工具生成的，那么实现它肯定是有意义的！数据科学的民主化并不意味着用户应该放弃创建易于理解和解释的模型。</p><p id="7b97" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="mb">原载于https://einblick.ai/automl-not-enough-citizen-data-science/ Einblick:</em><a class="ae ma" href="https://einblick.ai/automl-not-enough-citizen-data-science/" rel="noopener ugc nofollow" target="_blank"/></p><p id="d126" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="mb">尝试一种新的、更加动态的方式将AutoML集成到您的数据科学工作流中</em><a class="ae ma" href="https://einblick.ai/try-einblick/" rel="noopener ugc nofollow" target="_blank">https://einblick.ai/try-einblick/</a></p></div></div>    
</body>
</html>