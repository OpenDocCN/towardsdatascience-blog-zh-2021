<html>
<head>
<title>Sequence Dreaming with Depth Estimation in PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch中带深度估计的序列做梦</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sequence-dreaming-with-depth-estimation-in-pytorch-d754cba14d30?source=collection_archive---------23-----------------------#2021-03-20">https://towardsdatascience.com/sequence-dreaming-with-depth-estimation-in-pytorch-d754cba14d30?source=collection_archive---------23-----------------------#2021-03-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/2283d6e54f1c8e64aea285bdb63fbb6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QnN1knPmzVfUUkJD-Oxl2g.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">梦境类:图腾柱+减噪。作者图片</p></figure><div class=""/><div class=""><h2 id="e113" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">人工艺术合成</h2></div><p id="5f0e" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">虽然“沉睡”仍然是reddit上的大炒作，但我决定在连续帧(即视频)的深度做梦背景下，再看看开放性问题。受之前工作的启发，例如<a class="ae lq" href="https://github.com/samim23/DeepDreamAnim" rel="noopener ugc nofollow" target="_blank">这个Caffe实现</a>，除了将所有东西集成到最新的PyTorch框架中，我还想包含更多关于单类做梦(见我之前的<a class="ae lq" rel="noopener" target="_blank" href="/deep-lucid-dreaming-94fecd3cd46d">帖子</a>)和深度估计的最新见解。</p><figure class="lr ls lt lu gt is"><div class="bz fp l di"><div class="lv lw l"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">三轮车系列梦。</p></figure><p id="7c95" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">你可以在这里找到我的回购</strong>(っ◔◡◔)っ♥<a class="ae lq" href="https://github.com/Beinabih/Pytorch-HeadTrip" rel="noopener ugc nofollow" target="_blank"><strong class="kw jg"/></a><strong class="kw jg"/>♥</p><p id="5499" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">与我以前使用的一些类似的代码相比，我的实现大大改善了梦模式的闪烁。这个问题的发生通常是因为光流算法计算的矢量场在变化很小的区域接近于零，这导致了后续帧之间相应的梦内容的较大差异。这可能导致模式以高达每秒帧数的频率变化。我通过将前一个梦的模式扭曲到下一帧，并用流矢量场来参数化更新的强度，来解决这个问题。这种方法可以跟踪场景中运动的物体，还可以平稳地梦到新出现的物体和背景。目前，场景切换仍然必须手动处理，否则结果通常会显示不同场景之间梦境内容的不自然重叠。这个问题将来会得到解决。</p><p id="4849" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在每一步中，使用<a class="ae lq" href="https://link.springer.com/chapter/10.1007%2F3-540-45103-X_50" rel="noopener ugc nofollow" target="_blank"> Farneback方法</a>(由opencv2提供)或可选的<a class="ae lq" href="https://arxiv.org/abs/1611.0085" rel="noopener ugc nofollow" target="_blank">空间金字塔网络</a> (SPyNet)计算矢量场。为了获得更高的流量预测精度，应该使用SPyNet。</p><p id="d3ee" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我的代码可以用PyTorch 1.8运行。实现了以下附加功能:</p><ul class=""><li id="12e3" class="lx ly jf kw b kx ky la lb ld lz lh ma ll mb lp mc md me mf bi translated">单一阶层做梦</li><li id="7748" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">用Pytorch MiDas进行深度估计</li><li id="8d6e" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">各种分类模型(resnet、vgg19、inception……)</li><li id="bc26" class="lx ly jf kw b kx mg la mh ld mi lh mj ll mk lp mc md me mf bi translated">带SPyNet或Farneback的光流(opencv2)</li></ul><figure class="lr ls lt lu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/50ac4e7be1579bf32b3063601d330be0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rqJTdjnq8da6I9uI6-5Csw.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">睡袋海洋与深度估计。作者图片</p></figure><h1 id="ba77" class="ml mm jf bd mn mo mp mq mr ms mt mu mv kl mw km mx ko my kp mz kr na ks nb nc bi translated"><strong class="ak">设置</strong></h1><p id="6da6" class="pw-post-body-paragraph ku kv jf kw b kx nd kg kz la ne kj lc ld nf lf lg lh ng lj lk ll nh ln lo lp ij bi translated">config文件夹中提供了一个基本配置文件。它包含了做梦所需的所有参数。</p><p id="ce66" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">视觉表现</strong></p><p id="55df" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">输入图像被二次抽样到更小的分辨率，以便在许多不同的尺度上生成梦的结构。在较高分辨率下做梦会给在较低分辨率下产生的粗糙结构增加细节。参数<strong class="kw jg"> num_octaves </strong>和<strong class="kw jg"> octave_scale </strong>表征图像金字塔。<strong class="kw jg"> num_iterations </strong>表示网络处理输入的次数。以下是将<strong class="kw jg"> num_iterations </strong>或学习率(<strong class="kw jg"> lr </strong>)设置为非常大的值时获得的示例结果:</p><figure class="lr ls lt lu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ni"><img src="../Images/3304fc6636e98aa274158b4d437cfe93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QlGoFRRVHHxW9Rd5U7Tcfg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">涉及到一些后期处理步骤，如改变颜色和锐化。作者图片</p></figure><p id="634d" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们可以观察到大量的细节，然而，图像的原始内容已经完全消失了。通过将<strong class="kw jg"> random </strong>设置为True，可以使上述参数随机化。</p><p id="507e" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">梦的内容</strong></p><p id="9f2f" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">如果你想对你一直看到的狗的典型眼睛和脸之外的梦的特征有更多的控制，你可以将<strong class="kw jg">引导的</strong>参数设置为<em class="nj">真</em>以启用特定类的梦。这是我在之前的<a class="ae lq" rel="noopener" target="_blank" href="/deep-lucid-dreaming-94fecd3cd46d">帖子</a>中提到过的一个话题。通过将相应的索引添加到<strong class="kw jg"> channel_list </strong>中，您可以从<a class="ae lq" href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a" rel="noopener ugc nofollow" target="_blank">该列表</a>中选择并混合任意数量的ImageNet类。在下面的示例视频中，我使用了三个类:蘑菇、天鹅绒和雨伞。</p><figure class="lr ls lt lu gt is"><div class="bz fp l di"><div class="lv lw l"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">在蘑菇、天鹅绒和雨伞上做梦</p></figure><p id="4fcf" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">相反，如果您希望算法动态选择模型分配最高概率的类别，请将<strong class="kw jg"> max_output </strong>设置为<em class="nj"> True </em>。一个实验特性是<strong class="kw jg">金字塔_最大值</strong>参数，当设置为真时，在每个八度音阶中独立选择最可能的类别。</p><p id="bdd8" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">深度估计</strong></p><p id="1609" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">还可以将梦的内容与感知的图像深度联系起来。首先，使用PyTorch MiDas模块计算图像的相对逆深度。深度图随后被归一化到区间[0，1]中，用于放大或抑制做梦。通过将<strong class="kw jg">使用深度</strong>设置为<em class="nj">真</em>可以激活深度估计。您还可以通过设置<strong class="kw jg"> depth_str </strong>为遮罩指定一个倍增强度因子。</p><p id="12d5" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">将<strong class="kw jg"> use_threshold </strong>设置为真会将低于阈值<strong class="kw jg"> th_val </strong>的所有内容归零。通过更改此参数，可以根据预测深度动态指定排除距离。如果你想排除前景，设置<strong class="kw jg">反转深度</strong>为<em class="nj">真</em>。</p><figure class="lr ls lt lu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nk"><img src="../Images/aecfbcaa07cf9aa0ab1fd7f3fd488956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-qOHdoJF8vCpNk0r2Q8qhA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">前景(左)和背景(右)做梦。作者图片</p></figure><p id="374f" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">太棒了。</p><p id="4173" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">对于非常大的输入，通过利用兼容硬件上的Nvidia Apex模块提供的混合精度算法，还可以减少所需的内存并加快推理速度。好在已经在PyTorch中实现了，所以只需要设置<strong class="kw jg"> fp16 </strong>为<em class="nj"> True </em>即可。</p><p id="4d5c" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">现在发挥创意，制作一些很酷的图片和视频吧！</p></div></div>    
</body>
</html>