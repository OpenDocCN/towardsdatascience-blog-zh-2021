<html>
<head>
<title>Comparing Facebook’s M2M to mT5 in low resources translation (English-Yoruba).</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在低资源翻译(英语-约鲁巴语)中比较脸书的M2M和mT5。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/comparing-facebooks-m2m-to-mt5-in-low-resources-translation-english-yoruba-ef56624d2b75?source=collection_archive---------19-----------------------#2021-06-25">https://towardsdatascience.com/comparing-facebooks-m2m-to-mt5-in-low-resources-translation-english-yoruba-ef56624d2b75?source=collection_archive---------19-----------------------#2021-06-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/9f2ef5b31c862a0a91bd4c8e6e83bedc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ItXCLNMd1Po5lsN8"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">Muhammadtaha Ibrahim Ma'aji 在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><div class=""/><div class=""><h2 id="0851" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">寻找使用稀有语言对微调翻译任务的最佳模式。</h2></div><p id="3390" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TLDR；M2M的表现确实比mT5好。</p><h1 id="a160" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">灵感</h1><p id="4909" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">两个月前，我开始致力于低资源语言的神经机器翻译(NMT)<a class="ae jd" href="https://zindi.africa/competitions/ai4d-yoruba-machine-translation-challenge" rel="noopener ugc nofollow" target="_blank">津迪竞赛</a>。挑战是使用一种罕见的语言对训练一个胭脂分数最高的NMT模型:约鲁巴语到英语。</p><p id="6dda" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">约鲁巴语是尼日利亚南部约鲁巴族使用的一种语言。它是超过4000万人的母语，也是非洲最大城市拉各斯最常用的语言。由于西非的语言多样性，约鲁巴语被认为是方言的连续体，而不是一种标准语言。这对像我这样的NLP从业者来说是一个严重的问题。这让工作变得更加困难。</p><h1 id="ca77" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated"><strong class="ak">数据集</strong></h1><p id="eeb0" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">更糟糕的是，几乎没有任何将英语映射到约鲁巴语的数据集。我所知道的最大的数据集是JW300数据集(40万句)，它主要包含宗教文本。它肯定可以用来提高ROUGE评分，但如果它是训练的唯一参考，翻译将是倾斜的，只会产生圣经风格的句子。然而，在Zindi竞赛中，我们提供了一个非常小的数据集(10k个句子)，我用它来从JW300的句子风格中去偏模型。</p><p id="0fdb" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我最初的解决方案中，我使用了两个数据集来提高我的分数，但是在这里，为了简洁起见，我将只使用较小的数据集(10k)。你可以在<a class="ae jd" href="https://zindi.africa/competitions/ai4d-yoruba-machine-translation-challenge" rel="noopener ugc nofollow" target="_blank">比赛页面</a>找到数据集。你需要注册才能下载。</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><p id="5f48" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">正如已经提到的，解决这个问题的资源是稀缺的，并且基于变压器的模型在数据不足的情况下表现不好。为此，我将利用迁移学习来加快学习过程。</p><p id="00e0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">可用于微调的条件文本生成(CTG)多语言模型不如基于编码器的模型常见。然而，经过广泛的搜索，我只剩下两个同样有趣的候选人。</p><h1 id="19b0" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">mT5</h1><p id="b452" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">mT5车型<a class="ae jd" href="https://arxiv.org/pdf/2010.11934.pdf" rel="noopener ugc nofollow" target="_blank">于2020年作为<a class="ae jd" href="https://arxiv.org/pdf/1910.10683.pdf" rel="noopener ugc nofollow" target="_blank"> T5 </a>车型的多语言合法继承人</a>推出。m代表多语言。</p><p id="7d6c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">mT5和T5都以相似的方式训练。唯一的区别是mT5是在多语言数据上训练的，并且有更多的令牌嵌入(250k)。两者最初都在跨度破坏的目标上被训练:“用屏蔽记号替换输入记号的连续跨度<em class="mv">，并且模型被训练来重建屏蔽记号</em>”。</p><p id="fd8a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">用于训练模型的数据集有107种语言的6.3万亿个标记。幸运的是，约鲁巴语是这些语言中的一种，因为它占整个数据集的0.2%(5000万个令牌，而我们的数据集只有60万个)。该模型有不同的尺寸:从300米参数(小)到13B参数(XXL)。就我们的目的而言，我们将选择较小的一个。</p><h1 id="f074" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">M2M</h1><p id="d679" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">M2M也是和mT5 (2020)同年<a class="ae jd" href="https://about.fb.com/news/2020/10/first-multilingual-machine-translation-model/" rel="noopener ugc nofollow" target="_blank">开源</a>。它们之间的主要区别是<a class="ae jd" href="https://arxiv.org/pdf/2010.11125.pdf" rel="noopener ugc nofollow" target="_blank"> M2M模型</a>仅在翻译任务上接受训练，在两个方向上使用来自100种语言的句子对。这意味着，与其他翻译模型不同，M2M不是以英语为中心的翻译模型，翻译可以从多个方向流动，从而为低资源对带来更好的性能。</p><p id="6b69" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">M2M接受训练的数据集包含2200个不同方向的75亿个句子对。约鲁巴语是这100种语言中的一种。M2M有418M参数配置，最高可达14B参数。我们将使用418米的。</p><h1 id="047f" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated"><strong class="ak">环境</strong></h1><p id="55b4" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">由于训练如此巨大的模型的硬件要求，我无法在本地训练它们——相反，我使用了Kaggle笔记本中提供的免费P100 GPU。</p><p id="bd8a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，我们安装所需的库:</p><figure class="mw mx my mz gt is"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="8034" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> Fairseq库:</strong> Fairseq是一个面向序列模型的脸书库。这自然需要神经机器翻译、语音识别模型和条件文本生成等技术的支持。许多最先进的NLP模型都是使用fairseq生成的，因为它为许多重复性任务提供了灵活性和抽象性(此处提供了示例<a class="ae jd" href="https://github.com/pytorch/fairseq/tree/master/examples" rel="noopener ugc nofollow" target="_blank"/>)。然而，尽管fairseq在研究中无处不在，但对于学术界以外的人来说，它仍然很难理解。对于那些想在项目中使用最先进模型的人来说，这是不幸的。</p><p id="b997" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">变形金刚和简单变形金刚:Huggingface transformers是迄今为止最流行的NLP库。在分类、文本生成和摘要等任务上，只需要很少甚至不需要任何努力就可以微调最先进的基于transformer的模型。Simpletransformers只是建立在它之上的一个小库，用来加速原型和测试。</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h1 id="1c16" class="lr ls jg bd lt lu nc lw lx ly nd ma mb km ne kn md kp nf kq mf ks ng kt mh mi bi translated">正在准备数据集</h1><figure class="mw mx my mz gt is"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="75c8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里的数据集预处理很少，源文本和目标文本都是小写的，并且删除了尾随空格。验证由数据集的5%组成(500个句子)。</p><h1 id="eecb" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">培训mT5模型</h1><p id="23f3" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">当微调T5 / mT5模型时，Simpletransformers使我们的生活简单多了，因为它们<a class="ae jd" href="https://simpletransformers.ai/docs/t5-model/" rel="noopener ugc nofollow" target="_blank">完全支持这两种</a>。我们只需要设置所需的超参数、模型名称和数据。</p><p id="8bd9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该库要求数据集为Pandas dataframe格式，有三列:<em class="mv"> input_text </em>、<em class="mv"> target_text </em>和<em class="mv">前缀。前缀</em>是在mT5的训练过程中使用的列，用于指定模型应该做的任务(总结、分类…)。我们的案例不需要它，我们创建了它并将其留空。</p><figure class="mw mx my mz gt is"><div class="bz fp l di"><div class="na nb l"/></div></figure><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nh"><img src="../Images/6cf8aa85cc064a98ae65e61d922afb86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-jFK1QIvwQrUb6C-lTGTFA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">列车损失(蓝色)与有效损失(橙色)WANDB</p></figure><h1 id="4b54" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">训练M2M模型</h1><p id="3bf3" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">Fairseq库更面向CLI，而不是pythonic。要微调M2M模型，我们需要:</p><ul class=""><li id="09d7" class="ni nj jg kx b ky kz lb lc le nk li nl lm nm lq nn no np nq bi translated">首先下载418M参数模型，以及记号赋予器和词汇文件。</li><li id="0c36" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">将训练和验证句子对导出到文本文件。</li><li id="5edb" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">使用fairseq/scripts/spm_encode.py下的脚本标记句子</li><li id="955e" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">将句子二进制化，以加快数据加载和训练。</li><li id="c381" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">微调模型！</li></ul><figure class="mw mx my mz gt is"><div class="bz fp l di"><div class="na nb l"/></div></figure><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nw"><img src="../Images/2e0f750286abb05384188297713adf64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yAH1Z5qZDChVTkMV8e_tHw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">列车损失(蓝色)与有效损失(橙色)WANDB</p></figure><p id="2e23" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了公平的比较，我试图保持相似的超参数。两个模型都使用了自适应因子优化器、余弦调度器，并且被训练了十个时期。M2M的学习率较低，因为它的面积较大。</p><h1 id="3d3e" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">估价</h1><p id="3794" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">为了评估测试集中产生的翻译，我使用了<a class="ae jd" href="https://www.aclweb.org/anthology/W04-1013.pdf" rel="noopener ugc nofollow" target="_blank"> ROUGE </a>度量标准(<strong class="kx jh">R</strong>ecall-<strong class="kx jh">O</strong>oriented<strong class="kx jh">U</strong>ndersetry for<strong class="kx jh">G</strong>isting<strong class="kx jh">E</strong>evaluation)。ROUGE 有两个主要的变体:ROUGE-n用于计算ngrams共现的召回率，ROUGE-L用于测量最长的公共子序列。</p><p id="78e5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这种情况下，我将使用ROUGE-2(使用二元模型)，并将f1分数作为参考(我也将显示其他指标)。</p><p id="368f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了计算ROUGE得分，我使用了<a class="ae jd" href="https://pypi.org/project/rouge/" rel="noopener ugc nofollow" target="_blank"> ROUGE </a>库，它抽象出了实现:</p><figure class="mw mx my mz gt is"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="6bda" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于解码器文本生成，我在两个模型中使用了以下超参数:</p><ul class=""><li id="fd67" class="ni nj jg kx b ky kz lb lc le nk li nl lm nm lq nn no np nq bi translated">最大长度:100</li><li id="bd9c" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">长度惩罚:2.5</li><li id="dadf" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">留级惩罚:1.5分</li><li id="d590" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">光束尺寸:5</li></ul><p id="a332" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> mT5推断:</strong></p><p id="fb77" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用mT5的推断很简单:</p><figure class="mw mx my mz gt is"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="2b9a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用胭脂库时，get_scores返回一个包含不同胭脂分数的字典:["胭脂-1 "，"胭脂-2 "，"胭脂-L"]。正如我们之前所说的，我们将使用ROUGE-2来评估模型的性能，即f1分数(因此它更能代表模型的整体性能)。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nx"><img src="../Images/a6909b8b6304f36928fae45d57a63d2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4y0P0eG-s7bQPQ3XuaVeRw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">T5 —胭脂分数</p></figure><p id="a017" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">正如我们所见，T5在rouge-2 f1得分上给出了11(标准化)rouge得分。我们将为M2M模型计算相同的分数。</p><p id="0ee5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> M2M推断:</strong></p><p id="7a4a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">用M2M生成翻译有点复杂。首先，我们必须重复相同的预处理步骤来训练验证文本，然后使用这个命令行“fairseq-generate”来生成表格格式的翻译。最后，我们使用<em class="mv"> grep </em>和<em class="mv"> cut </em>的组合从输出生成的文件中提取翻译后的文本(<a class="ae jd" href="https://www.geeksforgeeks.org/grep-command-in-unixlinux/" rel="noopener ugc nofollow" target="_blank"> grep </a>，<a class="ae jd" href="https://www.geeksforgeeks.org/cut-command-linux-examples/" rel="noopener ugc nofollow" target="_blank"> cut </a>)。</p><figure class="mw mx my mz gt is"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="79bc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">请注意，为了使这个脚本能够工作，它必须运行在培训模型的同一个目录中。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ny"><img src="../Images/0ccd25f0ef29192ada0808f6efe324aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8YymuWczEPUSVIDyf9TiIQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">M2M-胭脂分数</p></figure><p id="daab" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">M2M模型的rouge-2得分为23，rouge-1得分为45。</p><h1 id="4ce6" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">比较</h1><p id="cbee" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">M2M的表现明显优于mT5车型，其rouge得分(所有车型)是mT5的两倍多。这让我感到惊讶:当看损失演变图时，似乎mT5收敛得更好，损失最小，M2M的表现会更差。显然，我错了。</p><p id="d487" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">请注意，在数据集非常小(10k)的情况下，这种性能对于两种模型来说都令人印象深刻。如果没有迁移学习的帮助，这样的成绩是不可能达到的。</p><p id="80ff" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下是一些例句:</p><p id="f2e8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">约鲁巴语</strong>:lẹ在ẹlẹ́rìí耶霍法？<br/> <strong class="kx jh">目标</strong>:你什么时候成为耶和华见证人的一员？</p><p id="72fd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">M2M:你什么时候成为耶和华见证人的一员？<br/> <strong class="kx jh"> mT5 </strong>:耶和华的话是什么意思？</p><p id="ac1b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi">— — — -</p><p id="f7b4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">约鲁巴语:拉ẹ语:lè bá a sọ̀rọ̀语:不，你不能</p><p id="5aa1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">M2M:抱歉，你不能告诉我</p><p id="8032" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi">— — — -</p><p id="febd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">约鲁巴语</strong>:莫mọ̀èyíkín tóníkíofẹ́米<br/> <strong class="kx jh">目标</strong>:在我告诉你嫁给我之前我就知道了</p><p id="27bf" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> M2M </strong>:我知道在我不得不嫁给我之前<br/> <strong class="kx jh"> mT5 </strong>:我知道这就是我想见你的原因</p><p id="d851" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi">— — — -</p><p id="c8e4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">约鲁巴语:àwọnìfẹsẹ̀wọnsẹ̀·蒂伊奥·马阿·瓦耶尼·尼·迪耶·orílẹ̀-èdè尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日尼日的比赛如下:</p><p id="9e42" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> M2M </strong>:以下是今天将在尼日利亚npfl进行的比赛:<br/> <strong class="kx jh"> mT5 </strong>:以下是尼日利亚足球联赛(npfl)的比赛结果:</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h1 id="a47a" class="lr ls jg bd lt lu nc lw lx ly nd ma mb km ne kn md kp nf kq mf ks ng kt mh mi bi translated">结论</h1><p id="3d47" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">尽管M2M的表现优于mT5，但后者更灵活，因为它接受了多种任务的训练。此外，使用mT5更容易，因为它可在<a class="ae jd" href="https://huggingface.co/google/mt5-small" rel="noopener ugc nofollow" target="_blank"> huggingface hub </a>上获得。</p><p id="2a76" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们取得的进步真的令人惊讶:我们如何从10k句子对数据集中获得像样的翻译。几年前，我们只能梦想。</p><p id="0a3a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这个项目在Github和colab上都有(请从<a class="ae jd" href="https://zindi.africa/competitions/ai4d-yoruba-machine-translation-challenge" rel="noopener ugc nofollow" target="_blank">这里</a>下载数据集)。发现有用就启动回购。联系我:boukil98@gmail.com</p><div class="ip iq gp gr ir nz"><a href="https://github.com/maroxtn/mt5-M2M-comparison" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jh gy z fp oe fr fs of fu fw jf bi translated">maro xtn/mt5-M2M-比较</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">在一个罕见的语言对上比较M2M和mT5，博客帖子:-maro xtn/mT5-M2M-比较</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">github.com</p></div></div><div class="oi l"><div class="oj l ok ol om oi on ix nz"/></div></div></a></div><div class="ip iq gp gr ir nz"><a href="https://colab.research.google.com/drive/1_1QbvXQllO1rL88shNvcOFz8H590ktax?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jh gy z fp oe fr fs of fu fw jf bi translated">Fairseq培训和评估</h2><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">colab.research.google.com</p></div></div><div class="oi l"><div class="oo l ok ol om oi on ix nz"/></div></div></a></div><div class="ip iq gp gr ir nz"><a href="https://colab.research.google.com/drive/1ZOhDhl1d1khVwCY5hzXwezx6ETGi2P2f?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd jh gy z fp oe fr fs of fu fw jf bi translated">mT5培训和评估</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">编辑描述</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">colab.research.google.com</p></div></div><div class="oi l"><div class="op l ok ol om oi on ix nz"/></div></div></a></div></div></div>    
</body>
</html>