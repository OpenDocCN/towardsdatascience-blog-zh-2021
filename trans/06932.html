<html>
<head>
<title>ML Classifier Performance Comparison for Spam Emails Detection- Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">垃圾邮件检测的ML分类器性能比较-第1部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ml-classifier-performance-comparison-for-spam-emails-detection-77749926d508?source=collection_archive---------20-----------------------#2021-06-23">https://towardsdatascience.com/ml-classifier-performance-comparison-for-spam-emails-detection-77749926d508?source=collection_archive---------20-----------------------#2021-06-23</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="3ff4" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">应用朴素贝叶斯、SVC和随机森林进行邮件分类</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj kj"><img src="../Images/6039122dd3e529093bbd0dd365dad24a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*DqJ0Ew03pn0UvqZT83oe0w.png"/></div><p class="kr ks gk gi gj kt ku bd b be z dk translated">作者图片</p></figure><p id="0ad0" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi lr translated">pam邮件检测是机器学习算法的一个重要应用，用于过滤掉不想要的邮件。在自然语言处理领域，对于这种类型的分类有几种算法。通常垃圾邮件有一些典型的词，这使得这封邮件很明显是垃圾邮件。在本文中，我们将使用nltk包完成垃圾邮件和非垃圾邮件的文本处理。特别是，我们将看到NLP的词干化和词汇化过程。我们还将实现NB分类器以及SVC和随机森林分类器来检测垃圾邮件，并比较分类器的准确性。让我们开始吧。</p><p id="9251" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">根据<a class="ae ma" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> nltk文档</a>，“nltk是构建Python程序来处理人类语言数据的领先平台”。使用nltk处理和标记文本是非常简单的，比如我们将在后面看到的词干化和词汇化。</p><p id="1144" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">首先，我们需要导入必要的包。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="mb mc l"/></div></figure><blockquote class="md me mf"><p id="0d05" class="kv kw mg kx b ky kz jv la lb lc jy ld mh lf lg lh mi lj lk ll mj ln lo lp lq in bi translated">数据记录单</p></blockquote><p id="0d27" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">导入包含垃圾邮件和非垃圾邮件标签文本的csv文件后，我创建了两个数据框:一个用于真实电子邮件，另一个用于垃圾邮件，我们将利用它们进行分析。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="mb mc l"/></div></figure><blockquote class="md me mf"><p id="5fca" class="kv kw mg kx b ky kz jv la lb lc jy ld mh lf lg lh mi lj lk ll mj ln lo lp lq in bi translated">词干和词尾</p></blockquote><p id="6db1" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">让我们先做词干，然后再把这袋单词做词条整理。根据斯坦福大学NLP小组的说法，“词干通常指的是一种粗糙的启发式过程，即砍掉单词的结尾，希望在大多数情况下正确实现这一目标，并且通常包括去除派生词缀。词汇化通常是指使用词汇和词的形态分析来正确地做事情，通常旨在只删除屈折词尾，并返回词的基本形式或词典形式，这就是所谓的词汇。这里，词干分析分别应用于所有数据、垃圾邮件数据和真实数据。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="mb mc l"/></div></figure><p id="0817" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">然后将该分类器分别应用于所有数据、垃圾数据和真实数据。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="mb mc l"/></div></figure><p id="5f32" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">如果我们查看第一个数据文本的主干，我们会得到:</p><blockquote class="mk"><p id="ddef" class="ml mm iu bd mn mo mp mq mr ms mt lq dk translated"><em class="mu">‘去句容点吧，去大世界吃自助餐，看电影’。</em></p></blockquote><p id="75f0" class="pw-post-body-paragraph kv kw iu kx b ky mv jv la lb mw jy ld le mx lg lh li my lk ll lm mz lo lp lq in bi translated">lemmatizer提供了:</p><blockquote class="mk"><p id="1802" class="ml mm iu bd mn mo mp mq mr ms mt lq dk translated"><em class="mu">‘去句容点疯狂可用bugis n大世界la e buffet cine more wat’</em></p></blockquote><p id="43d9" class="pw-post-body-paragraph kv kw iu kx b ky mv jv la lb mw jy ld le mx lg lh li my lk ll lm mz lo lp lq in bi translated">从第一个数据可以明显看出，词干和引理以不同的方式工作。例如，单词“availability”有词干“avail ”,但有引理“available”。</p><blockquote class="md me mf"><p id="9aad" class="kv kw mg kx b ky kz jv la lb lc jy ld mh lf lg lh mi lj lk ll mj ln lo lp lq in bi translated">Wordcloud</p></blockquote><p id="96ab" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">用数值标注后，让我们创建wordcloud来查看最常用的单词。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="mb mc l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj na"><img src="../Images/31c40a648671de8889f44fd667bbd76b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*waExIZCPhDxfoDii9b2DVQ.png"/></div><p class="kr ks gk gi gj kt ku bd b be z dk translated">作者图片</p></figure><p id="ebbc" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">垃圾邮件中有很多吸引人的词语，而真实邮件中的文字则非常随意，如下所示。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nb"><img src="../Images/f26d274d1c8d95b11ad57e5dae96e719.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*DlTuYpdgHxNvCxL3BcxPvA.png"/></div><p class="kr ks gk gi gj kt ku bd b be z dk translated">作者图片</p></figure><blockquote class="md me mf"><p id="f0d7" class="kv kw mg kx b ky kz jv la lb lc jy ld mh lf lg lh mi lj lk ll mj ln lo lp lq in bi translated">频数分布</p></blockquote><p id="077e" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">我们可能有兴趣看到垃圾邮件中最常用的词的最高谱。它可以通过如下的频率分布获得</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="mb mc l"/></div></figure><blockquote class="mk"><p id="a206" class="ml mm iu bd mn mo nc nd ne nf ng lq dk translated">FreqDist({ ' . ':1004，“到”:608，“到”:542，'，':371，' a': 358，'你':189，' call': 187，'你':187，' or': 185，' &amp;': 178，...})</p></blockquote><p id="bd97" class="pw-post-body-paragraph kv kw iu kx b ky mv jv la lb mw jy ld le mx lg lh li my lk ll lm mz lo lp lq in bi translated">在其他时候，我们可能会关注垃圾邮件中最常见的重复句子部分。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="mb mc l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gi gj nh"><img src="../Images/264b1ce3b214cea238987e80d3d06a8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s5ryGipx2f7928F7vdyQnA.png"/></div></div><p class="kr ks gk gi gj kt ku bd b be z dk translated">作者图片</p></figure><p id="abf3" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">很明显，像“私人账户声明”或“秘密崇拜者”这样的句子是垃圾邮件中最吸引人的短语。</p><blockquote class="md me mf"><p id="3916" class="kv kw mg kx b ky kz jv la lb lc jy ld mh lf lg lh mi lj lk ll mj ln lo lp lq in bi translated">离差图</p></blockquote><p id="cd78" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">我们可以获得目标词的离差图来查看分布。它将提供特定单词在单词总数中出现的信息。我选择了像“免费”、“私人”、“帐户”、“联系”这样的词来演示。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nm"><img src="../Images/22748fbb82e6f59136362885ce55fcf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*67nHn4LEFwa0LY-4_GsJ2w.png"/></div><p class="kr ks gk gi gj kt ku bd b be z dk translated">作者图片</p></figure><blockquote class="md me mf"><p id="6026" class="kv kw mg kx b ky kz jv la lb lc jy ld mh lf lg lh mi lj lk ll mj ln lo lp lq in bi translated">分类者</p></blockquote><p id="58db" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">这里我从scikit-learn库中创建了一个分类器。我们需要将文本转换成令牌计数矩阵，scikit-learn的CountVectorizer()可以方便地完成这项工作。我们将首先尝试朴素贝叶斯函数，它实现简单，训练时间也较少。出于训练的目的，我选择了80%的数据。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="mb mc l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nn"><img src="../Images/39ca46e156f9ad4f49f80b7df4b7b238.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*oEkQHplLtXXPEYdARq_KlQ.png"/></div><p class="kr ks gk gi gj kt ku bd b be z dk translated">作者图片</p></figure><p id="4624" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">我总是需要一个精确和回忆的复习。精度是TP(真阳性)与TP和FP(假阳性)之和的比值。召回率是TP与TP和FN之和的比值(假阴性)。如果一个真正的垃圾邮件被错误地识别为真正的电子邮件，那就是假阳性。另一方面，如果一封真实的电子邮件被识别为垃圾邮件，那就是假阴性。</p><p id="e03f" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">报告显示，该模型在检测垃圾邮件方面表现良好，但在检测垃圾邮件方面表现不佳。垃圾邮件的精度约为0.38，表明从该模型中获得了大量假阳性。尽管模型精度为0.79，但这可能会产生误导，因为垃圾邮件的召回率很高，而精度却很低。这表明该模型偏向于垃圾邮件。它能够正确识别大多数垃圾邮件，但也会错误地将一些火腿识别为垃圾邮件。</p><pre class="kk kl km kn gu no np nq nr aw ns bi"><span id="6790" class="nt nu iu np b gz nv nw l nx ny">array([[744, 224],<br/>       [ 12, 135]], dtype=int64)</span></pre><p id="fb41" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">混淆矩阵也显示了类似的情况。对角线没有最高的数字。这意味着朴素贝叶斯的性能不够好。</p><p id="0788" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">让我们试试支持向量分类以及随机森林算法。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="mb mc l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gi gj nz"><img src="../Images/2c64fa8ffb61a78fc3ac8b379d869957.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*HMZGmXVhtL9byuRutH_3Ww.png"/></div></div><p class="kr ks gk gi gj kt ku bd b be z dk translated">作者图片</p></figure><p id="78f9" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">模型性能良好。火腿和垃圾邮件准确率和召回率都很高。最后让我们尝试随机森林作为一个分类器。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="mb mc l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj oa"><img src="../Images/d9ba16659308d5c368182ab8ded7f332.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*x4nGpewAmOPtPZylkqgd3A.png"/></div><p class="kr ks gk gi gj kt ku bd b be z dk translated">作者图片</p></figure><p id="01fe" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">随机森林在垃圾邮件检测案例中也是一个很好的分类器，对真实邮件和垃圾邮件都有很高的精确度和召回率。</p><blockquote class="md me mf"><p id="d9db" class="kv kw mg kx b ky kz jv la lb lc jy ld mh lf lg lh mi lj lk ll mj ln lo lp lq in bi translated">结论</p></blockquote><p id="a476" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">本文使用nltk库演示了自然语言处理的词干化和词汇化过程，并比较了几种二元分类算法。朴素贝叶斯产生较低的精确度，而SVC和随机森林提供较高的精确度、召回率以及精确度。交叉验证技术可以评估这些分类器的技能。现在，有许多开源平台可以进行训练和交叉验证，而不需要任何代码，我将在另一篇文章中讨论。</p><p id="c067" class="pw-post-body-paragraph kv kw iu kx b ky kz jv la lb lc jy ld le lf lg lh li lj lk ll lm ln lo lp lq in bi translated">我的<a class="ae ma" href="https://mdsohelmahmood.github.io/2021/06/23/Spam-email-classification-using-NB-SVC-Random-Forest.html" rel="noopener ugc nofollow" target="_blank"> github页面</a>提供了代码块。</p></div></div>    
</body>
</html>