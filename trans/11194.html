<html>
<head>
<title>How to Deploy a TensorFlow Model to Vertex AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何将张量流模型部署到 Vertex AI</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-deploy-a-tensorflow-model-to-vertex-ai-87d9ae1df56?source=collection_archive---------11-----------------------#2021-11-02">https://towardsdatascience.com/how-to-deploy-a-tensorflow-model-to-vertex-ai-87d9ae1df56?source=collection_archive---------11-----------------------#2021-11-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3455" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在 Vertex AI 中使用保存的模型和端点</h2></div><p id="6d38" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本文中，我将带您了解如何将 TensorFlow/Keras 模型部署到 Vertex AI 中，并从中获得预测。</p><h2 id="1f1a" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">概念</h2><p id="e9a6" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">这里有几个重要的概念，所以我们进行的时候可以参考这个图表。代码片段来自 GitHub 中的这个<a class="ae lz" href="https://github.com/GoogleCloudPlatform/data-science-on-gcp/blob/edition2/09_vertexai/flights_model_tf2.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本。</a></p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi ma"><img src="../Images/77cdde847047ca41de3caf049c0f3643.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nLKsf2NI2xpiLy89HABM8w.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">向 Vertex AI 部署模型的步骤。由我图解。</p></figure><p id="17eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基本思想是客户端访问端点。每个端点都与一个 URL 相关联。客户端发送一个带有 JSON 有效负载的 HTTP Post 请求，其中包含预测方法的输入。</p><p id="f8e1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">端点包含许多顶点 AI 模型对象，它在这些对象之间划分流量。在上图中，80%的流量流向模型 1，10%流向模型 2，其余流向模型 3。</p><p id="030c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">顶点 AI 模型是一个对象，它引用了在各种框架(TensorFlow、PyTorch、XGBoost 等)中构建的模型。).每个框架都有预构建的容器映像。如果你使用的是不被 Vertex AI 直接支持的 ML 框架，你也可以引入你的容器。</p><p id="3845" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">TensorFlow 容器图像会查找已保存的 Model 文件，当您从训练代码中调用 model.save(…)时，默认情况下 Keras/TensorFlow 2.0 模型会导出为这种格式。</p><h2 id="0f56" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">第一步。在 Keras 中保存训练模型</h2><p id="8c6a" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">在 TensorFlow 2.0 中编写机器学习模型的推荐方法是使用 Keras API。简而言之，它包括以下步骤:</p><pre class="mb mc md me gt mq mr ms mt aw mu bi"><span id="1a35" class="lb lc iq mr b gy mv mw l mx my"># 1. Create a tf.data Dataset<br/>train_dataset = read_dataset(training_data_uri, train_batch_size)<br/>eval_dataset = read_dataset(validation_data_uri, eval_batch_size)</span><span id="4956" class="lb lc iq mr b gy mz mw l mx my"># 2. Create a Keras Model<br/>inputs = tf.keras.layers.Input(...)<br/>layer_1 = tf.keras.layers.... (inputs) <br/>...<br/>outputs = tf.keras.layers.Dense(...)(layer_n)<br/>model = tf.keras.Model(inputs, output)<br/>model.compile(optimizer='adam',<br/>              loss='binary_crossentropy',<br/>               metrics=['accuracy'])</span><span id="287f" class="lb lc iq mr b gy mz mw l mx my"># 3. Train<br/>model.fit(train_dataset, validation_data=eval_dataset, ...)</span><span id="0ce9" class="lb lc iq mr b gy mz mw l mx my"># 4. Save model<br/>EXPORT_PATH = 'gs://{}/export/flights_{}'.format(bucket,<br/>                                     time.strftime("%Y%m%d-%H%M%S"))<br/>model.save(EXPORT_PATH)</span></pre><p id="a5db" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面的关键步骤是，你的训练程序将训练好的模型保存到谷歌云存储的一个目录中。</p><h2 id="9e30" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">第二步。上传模型</h2><p id="e1eb" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">我建议您为每个模型使用一个唯一的显示名称(Vertex AI 确实分配了一个唯一的模型 id，但它是一个不透明的数字，不可读)。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi na"><img src="../Images/5862066bc391904074f3f725db204f52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*91fde2A4VDZrwO13StYw-w.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">给模型分配一个唯一的名称，因为顶点 AI 分配的唯一 ID 不是人类可以理解的</p></figure><p id="26cb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一种简单的方法是在您想要使用的名称后面附加一个时间戳，这样每次您上传一个模型时，您就有了一个新的名称:</p><pre class="mb mc md me gt mq mr ms mt aw mu bi"><span id="e62e" class="lb lc iq mr b gy mv mw l mx my">TIMESTAMP=$(date +%Y%m%d-%H%M%S)<br/>MODEL_NAME=flights-${TIMESTAMP}</span></pre><p id="1898" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，将保存的模型文件上传到上面的模型，为您的 ML 框架指定<a class="ae lz" href="https://cloud.google.com/vertex-ai/docs/training/pre-built-containers" rel="noopener ugc nofollow" target="_blank">预建顶点容器</a>:</p><pre class="mb mc md me gt mq mr ms mt aw mu bi"><span id="34f9" class="lb lc iq mr b gy mv mw l mx my">gcloud beta ai models upload --region=$REGION \<br/>     --display-name=$MODEL_NAME \<br/>     --container-image-uri=us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-6:latest \<br/>     --artifact-uri=$EXPORT_PATH</span></pre><h2 id="8598" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">第三步。创建端点</h2><p id="0611" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">您还希望端点有一个唯一的名称，但是您不会创建多个端点。只有一个。因此，不需要时间戳。在创建端点之前，只需验证它不存在:</p><pre class="mb mc md me gt mq mr ms mt aw mu bi"><span id="897d" class="lb lc iq mr b gy mv mw l mx my">ENDPOINT_NAME=flights<br/>if [[ $(gcloud ai endpoints list --region=$REGION \<br/>        --format='value(DISPLAY_NAME)' --filter=display_name=${ENDPOINT_NAME}) ]]; then<br/>    echo "Endpoint $ENDPOINT_NAME already exists"<br/>else<br/>    # create model<br/>    echo "Creating Endpoint $ENDPOINT_NAME for $MODEL_NAME"<br/>    gcloud ai endpoints create --region=${REGION} --display-name=${ENDPOINT_NAME}<br/>fi</span></pre><h2 id="ca37" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">第四步。将模型部署到端点</h2><p id="20ee" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">将模型部署到端点，确保指定您需要的机器类型(包括 GPU 等。)和流量分流:</p><pre class="mb mc md me gt mq mr ms mt aw mu bi"><span id="78f4" class="lb lc iq mr b gy mv mw l mx my">gcloud ai endpoints deploy-model $ENDPOINT_ID \<br/>  --region=$REGION \<br/>  --model=$MODEL_ID \<br/>  --display-name=$MODEL_NAME \<br/>  --machine-type=n1-standard-2 \<br/>  --min-replica-count=1 \<br/>  --max-replica-count=1 \<br/>  --traffic-split=0=100</span></pre><p id="c78e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为这是第一个模型，我们发送 100%的流量到这个模型</p><pre class="mb mc md me gt mq mr ms mt aw mu bi"><span id="a407" class="lb lc iq mr b gy mv mw l mx my">— traffic-split=0=100</span></pre><p id="4466" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们有一个旧的模型，我们将指定两个模型之间的相对分割。要将 10%的流量发送到新型号，将 90%的流量发送到旧型号，我们需要:</p><pre class="mb mc md me gt mq mr ms mt aw mu bi"><span id="70cc" class="lb lc iq mr b gy mv mw l mx my">--traffic-split=0=10,OLD_DEPLOYED_MODEL_ID=90</span></pre><p id="fe87" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，所有这些命令都需要模型 ID 和端点 ID(而不是模型名称和端点名称)。要从名称中获取 ID(假设您使用了我推荐的唯一名称):</p><pre class="mb mc md me gt mq mr ms mt aw mu bi"><span id="e05b" class="lb lc iq mr b gy mv mw l mx my">MODEL_ID=$(gcloud ai models list --region=$REGION \<br/>           --format='value(MODEL_ID)' \<br/>           --filter=display_name=${MODEL_NAME})</span><span id="fcdb" class="lb lc iq mr b gy mz mw l mx my">ENDPOINT_ID=$(gcloud ai endpoints list --region=$REGION \<br/>              --format='value(ENDPOINT_ID)' \<br/>              --filter=display_name=${ENDPOINT_NAME})</span></pre><p id="e82e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你没有使用唯一的名字(坏主意！)，您可以获得最近部署的模型或端点的 id:</p><pre class="mb mc md me gt mq mr ms mt aw mu bi"><span id="03b6" class="lb lc iq mr b gy mv mw l mx my">ENDPOINT_ID=$(gcloud ai endpoints list --region=$REGION \<br/>              --format='value(ENDPOINT_ID)'\<br/>              --filter=display_name=${ENDPOINT_NAME} \<br/>              <strong class="mr ir">--sort-by=creationTimeStamp | tail -1</strong>)</span></pre><h2 id="bf2d" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">把这些放在一起。</h2><p id="a732" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">下面是上面的所有代码片段，便于复制粘贴:</p><pre class="mb mc md me gt mq mr ms mt aw mu bi"><span id="ee93" class="lb lc iq mr b gy mv mw l mx my">## CHANGE<br/>EXPORT_PATH=gs://some-bucket/some-model-dir<br/>TF_VERSION=2-6<br/>ENDPOINT_NAME=flights<br/>REGION=us-central1</span><span id="e0d3" class="lb lc iq mr b gy mz mw l mx my">##</span><span id="24bf" class="lb lc iq mr b gy mz mw l mx my">TIMESTAMP=$(date +%Y%m%d-%H%M%S)<br/>MODEL_NAME=${ENDPOINT_NAME}-${TIMESTAMP}<br/>EXPORT_PATH=$(gsutil ls ${OUTDIR}/export | tail -1)<br/>echo $EXPORT_PATH</span><span id="9867" class="lb lc iq mr b gy mz mw l mx my">if [[ $(gcloud ai endpoints list --region=$REGION \<br/>        --format='value(DISPLAY_NAME)' --filter=display_name=${ENDPOINT_NAME}) ]]; then<br/>    echo "Endpoint for $MODEL_NAME already exists"<br/>else<br/>    # create model<br/>    echo "Creating Endpoint for $MODEL_NAME"<br/>    gcloud ai endpoints create --region=${REGION} --display-name=${ENDPOINT_NAME}<br/>fi</span><span id="e20a" class="lb lc iq mr b gy mz mw l mx my">ENDPOINT_ID=$(gcloud ai endpoints list --region=$REGION \<br/>              --format='value(ENDPOINT_ID)' --filter=display_name=${ENDPOINT_NAME})<br/>echo "ENDPOINT_ID=$ENDPOINT_ID"</span><span id="ae30" class="lb lc iq mr b gy mz mw l mx my"># delete any existing models with this name<br/>for MODEL_ID in $(gcloud ai models list --region=$REGION --format='value(MODEL_ID)' --filter=display_name=${MODEL_NAME}); do<br/>    echo "Deleting existing $MODEL_NAME ... $MODEL_ID "<br/>    gcloud ai models delete --region=$REGION $MODEL_ID<br/>done</span><span id="b371" class="lb lc iq mr b gy mz mw l mx my"># upload model<br/>gcloud beta ai models upload --region=$REGION --display-name=$MODEL_NAME \<br/>     --container-image-uri=us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.${TF_VERSION}:latest \<br/>     --artifact-uri=$EXPORT_PATH<br/>MODEL_ID=$(gcloud ai models list --region=$REGION --format='value(MODEL_ID)' --filter=display_name=${MODEL_NAME})<br/>echo "MODEL_ID=$MODEL_ID"</span><span id="a646" class="lb lc iq mr b gy mz mw l mx my"># deploy model to endpoint<br/>gcloud ai endpoints deploy-model $ENDPOINT_ID \<br/>  --region=$REGION \<br/>  --model=$MODEL_ID \<br/>  --display-name=$MODEL_NAME \<br/>  --machine-type=n1-standard-2 \<br/>  --min-replica-count=1 \<br/>  --max-replica-count=1 \<br/>  --traffic-split=0=100</span></pre><h2 id="b75b" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">第五步。调用模型</h2><p id="1038" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">下面是客户端如何调用您已经部署的模型。假设他们在一个名为 example_input.json 的 JSON 文件中有输入数据:</p><pre class="mb mc md me gt mq mr ms mt aw mu bi"><span id="ee03" class="lb lc iq mr b gy mv mw l mx my">{"instances": [<br/>  {"dep_hour": 2, "is_weekday": 1, "dep_delay": 40, "taxi_out": 17, "distance": 41, "carrier": "AS", "dep_airport_lat": 58.42527778, "dep_airport_lon": -135.7075, "arr_airport_lat": 58.35472222, "arr_airport_lon": -134.57472222, "origin": "GST", "dest": "JNU"},<br/>  {"dep_hour": 22, "is_weekday": 0, "dep_delay": -7, "taxi_out": 7, "distance": 201, "carrier": "HA", "dep_airport_lat": 21.97611111, "dep_airport_lon": -159.33888889, "arr_airport_lat": 20.89861111, "arr_airport_lon": -156.43055556, "origin": "LIH", "dest": "OGG"}<br/>]}</span></pre><p id="48a9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">他们可以发送 HTTP 帖子:</p><pre class="mb mc md me gt mq mr ms mt aw mu bi"><span id="3fea" class="lb lc iq mr b gy mv mw l mx my">PROJECT=$(gcloud config get-value project)<br/>ENDPOINT_ID=$(gcloud ai endpoints list --region=$REGION \<br/>              --format='value(ENDPOINT_ID)' --filter=display_name=${ENDPOINT_NAME})</span><span id="ba85" class="lb lc iq mr b gy mz mw l mx my">curl -X POST \<br/>  -H "Authorization: Bearer "$(gcloud auth application-default print-access-token) \<br/>  -H "Content-Type: application/json; charset=utf-8" \<br/>  -d <a class="ae lz" href="http://twitter.com/example_input" rel="noopener ugc nofollow" target="_blank">@example_input</a>.json \<br/>  "<a class="ae lz" href="https://${REGION}-aiplatform.googleapis.com/v1/projects/${PROJECT}/locations/${REGION}/endpoints/${ENDPOINT_ID}:predict" rel="noopener ugc nofollow" target="_blank">https://${REGION}-aiplatform.googleapis.com/v1/projects/${PROJECT}/locations/${REGION}/endpoints/${ENDPOINT_ID}:predict</a>"</span></pre><p id="6c13" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">他们将得到 JSON 格式的结果:</p><pre class="mb mc md me gt mq mr ms mt aw mu bi"><span id="ccdc" class="lb lc iq mr b gy mv mw l mx my">{<br/>  "predictions": [<br/>    [<br/>      0.228779882<br/>    ],<br/>    [<br/>      0.766132474<br/>    ]<br/>  ],<br/>  "deployedModelId": "2339101036930662400",<br/>  "model": "projects/379218021631/locations/us-central1/models/3935868997391613952",<br/>  "modelDisplayName": "flights-20211102-064051"<br/>}</span></pre><p id="8ee3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当然，它是一个 REST API，所以您可以从几乎任何语言中调用它。也有可用的客户端 API 库。</p><h2 id="ab84" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">利益</h2><p id="a2a1" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">在本文中，我向您展示了如何在 Vertex AI 上部署一个经过训练的 TensorFlow 模型。</p><p id="2be1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Vertex AI 为机器学习模型提供了一个完全管理的、自动缩放的、无服务器的环境。只有在您使用 GPU 时，您才能享受到为其付费的好处。因为模型是容器化的，所以依赖关系管理得到了关注。端点负责流量分流，允许您以方便的方式进行 A/B 测试。</p><p id="4571" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好处不仅仅是不必管理基础架构。一旦你的模型被部署到 Vertex AI，你无需任何额外的代码就可以获得许多简洁的功能——可解释性、漂移检测、监控等等。</p><p id="d776" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽情享受吧！</p><h1 id="9e3e" class="nb lc iq bd ld nc nd ne lg nf ng nh lj jw ni jx lm jz nj ka lp kc nk kd ls nl bi translated">更多关于 Vertex AI 的阅读:</h1><ol class=""><li id="f4a8" class="nm nn iq kh b ki lu kl lv ko no ks np kw nq la nr ns nt nu bi translated"><a class="ae lz" rel="noopener" target="_blank" href="/giving-vertex-ai-the-new-unified-ml-platform-on-google-cloud-a-spin-35e0f3852f25">给谷歌云上的新统一 ML 平台 Vertex AI 一个旋转</a> : <br/>我们为什么需要它，无代码 ML 培训到底有多好，所有这些对数据科学工作意味着什么？</li><li id="d69b" class="nm nn iq kh b ki nv kl nw ko nx ks ny kw nz la nr ns nt nu bi translated"><a class="ae lz" rel="noopener" target="_blank" href="/how-to-deploy-a-tensorflow-model-to-vertex-ai-87d9ae1df56">如何将 TensorFlow 模型部署到 Vertex AI </a>:在 Vertex AI 中使用保存的模型和端点</li><li id="8ba2" class="nm nn iq kh b ki nv kl nw ko nx ks ny kw nz la nr ns nt nu bi translated"><a class="ae lz" href="https://medium.com/@lakshmanok/developing-and-deploying-a-machine-learning-model-on-vertex-ai-using-python-865b535814f8" rel="noopener">使用 Python 在 Vertex AI 上开发和部署机器学习模型</a>:编写让你的 MLOps 团队满意的训练管道</li><li id="62ef" class="nm nn iq kh b ki nv kl nw ko nx ks ny kw nz la nr ns nt nu bi translated"><a class="ae lz" href="https://lakshmanok.medium.com/how-to-build-an-mlops-pipeline-for-hyperparameter-tuning-in-vertex-ai-45cc2faf4ff5" rel="noopener">如何在 Vertex AI 中为超参数调整构建 MLOps 管道</a> : <br/>为超参数调整设置模型和协调器的最佳实践</li></ol></div></div>    
</body>
</html>