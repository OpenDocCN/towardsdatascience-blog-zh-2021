<html>
<head>
<title>Who’s Who and What’s What: Advances in Biomedical Named Entity Recognition (BioNER)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谁是谁，什么是什么:生物医学命名实体识别进展</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/whos-who-and-what-s-what-advances-in-biomedical-named-entity-recognition-bioner-c42a3f63334c?source=collection_archive---------20-----------------------#2021-05-04">https://towardsdatascience.com/whos-who-and-what-s-what-advances-in-biomedical-named-entity-recognition-bioner-c42a3f63334c?source=collection_archive---------20-----------------------#2021-05-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/8d2e84a73749361d0b2b2f5c8bafa2fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YjidmfalNmZG0zJV"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://unsplash.com/@nci?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">国家癌症研究所</a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="fb63" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想与理论</a></h2><div class=""/><div class=""><h2 id="cd68" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">命名实体识别研究概述，以帮助解决与生物医学领域相关的挑战。</h2></div><h1 id="984e" class="le lf jg bd lg lh li lj lk ll lm ln lo kv lp kw lq ky lr kz ls lb lt lc lu lv bi translated">介绍</h1><p id="0fc9" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">在<a class="ae jd" href="https://www.slimmer.ai/" rel="noopener ugc nofollow" target="_blank"> Slimmer AI </a>，我们一直在探索生物医学领域的NER(BioNER)。这种探索很重要，因为有一些挑战在其他领域并不总是存在，包括:</p><ul class=""><li id="74e7" class="ms mt jg ly b lz mu mc mv mf mw mj mx mn my mr mz na nb nc bi translated">数据通常不能自由获取，尤其是在临床病例中。</li><li id="4a7f" class="ms mt jg ly b lz nd mc ne mf nf mj ng mn nh mr mz na nb nc bi translated">数据注释需要专业知识。</li><li id="3cd3" class="ms mt jg ly b lz nd mc ne mf nf mj ng mn nh mr mz na nb nc bi translated">生物医学概念的空间是巨大的，这使得NER系统不太可能超越它们被注释的特定设置。</li></ul><p id="e709" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">本文概述了命名实体识别工作和研究，以帮助解决与生物医学领域相关的挑战，如生物医学数据集和处理它们的技术。我还将讨论迁移学习和多任务学习在这一领域的重要性。我将快速介绍一些BioNER的替代方法，与基于深度学习的流行模型(如BERT)进行比较。</p></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h1 id="a064" class="le lf jg bd lg lh ns lj lk ll nt ln lo kv nu kw lq ky nv kz ls lb nw lc lu lv bi translated">NER发展概述</h1><p id="7ec9" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">命名实体识别(NER)是自然语言处理的组成部分之一，被用于许多下游任务，如问题回答、主题建模和信息检索。<strong class="ly jq">【1】</strong>该任务涉及使用诸如人、组织、位置等类别来标记非结构化文本中的实体。</p><figure class="ny nz oa ob gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nx"><img src="../Images/c065bf173177f7c28011e6062f40c1e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*khOcFo2bEJR-GDVLJgiRUA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">命名实体识别的目标是将单词识别为实体，并对它们所属的实体类型进行分类。图片作者，灵感来自<a class="ae jd" href="https://monkeylearn.com/blog/named-entity-recognition/" rel="noopener ugc nofollow" target="_blank"> MonkeyLearn </a>。</p></figure><p id="d00e" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">早期的NER系统使用手工制作的规则、词汇、拼写特征和本体。<strong class="ly jq">【1，2】</strong>诸如此类的模型有一些好处，比如它们不需要带注释的训练数据。然而，这些模型有几个缺点。例如，词典需要详尽，相关词典需要由领域专家主动更新。</p><p id="44e3" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">随着这一领域的发展，人们开始使用机器学习，但这种方法也有其缺点，如费力的特征工程。最近，引入了端到端深度学习方法，并消除了对每个特定数据集手动设计特征的需要。尽管缺乏特定领域的规则和知识，这些特征推断网络优于特征工程系统。<strong class="ly jq">【1】</strong></p></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h1 id="d23e" class="le lf jg bd lg lh ns lj lk ll nt ln lo kv nu kw lq ky nv kz ls lb nw lc lu lv bi translated">数据集噪声和偏差</h1><p id="7696" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">许多带注释的数据集已被引入生物医学领域，包括实体类别，如细胞系、化学、疾病、基因、蛋白质和物种。他们中的大多数使用<a class="ae jd" href="https://pubmed.ncbi.nlm.nih.gov/" rel="noopener ugc nofollow" target="_blank"> PubMed </a>的文章作为他们的来源，这已经被一些领域专家注释过了。对于流行的BioNER数据集的概述，GitHub上由<a class="ae jd" href="https://github.com/flairNLP/flair/blob/master/resources/docs/HUNFLAIR_CORPORA.md" rel="noopener ugc nofollow" target="_blank"> Flair </a>或<a class="ae jd" href="https://github.com/bionlp-hzau/BioNLP-Corpus" rel="noopener ugc nofollow" target="_blank">this overview</a>所做的评论是很好的参考。</p><p id="289a" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">NER数据集最突出的问题之一是数据集是不完美的，这并不局限于生物医学领域。例如，大多数人——如果不是全部的话——都会遇到注释者不同意或者缺少注释的问题。</p><p id="48cd" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">李等人强调数据注记质量是领域的主要挑战之一。<strong class="ly jq">【2】</strong>举几个例子，MedMentions语料库的创建者通过让生物学家审查专业注释者所做的注释来评估注释质量，并报告了97.3%的一致性。<strong class="ly jq">【3】</strong>2004年的JNLPBA任务在2019年有了一个修订版，试图修复原始语料库中的不完善之处。<strong class="ly jq">【4，5】</strong>有两轮注释，注释者在两轮之间讨论了一些分歧。在第一轮中，注释的一致性为79.5%，而在第二轮中为91.4%。这离100%还是挺远的。Wang等人分析了广泛采用的CoNLL03数据集，能够在大约5.38%的测试句子中识别错误。鉴于最先进的测试分数已经达到93%左右，他们进一步强调了这一点的重要性。</p><figure class="ny nz oa ob gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oc"><img src="../Images/a470032d9c30e699c3fae5bfd9a5845d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bn-RfBect3c-xa9w5NdYIA.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">根据知识或视角，插图或文字可以有不同的解释。这可能导致注释者不同意和不完善的数据集。图片由<a class="ae jd" href="https://pixy.org/4537282/" rel="noopener ugc nofollow" target="_blank"> Pixy </a>提供。</p></figure><p id="01b2" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">发现注释错误需要深厚的专业知识和大量的时间投入。为了用另一种方式处理它们，王等人引入了一个叫做CrossWeigh的框架。他们的解决方案很简单，但确实需要相当长的运行时间。想法是训练多个模型，每个模型基于训练数据的不同分割。分割或折叠是以这样的方式建立的，即训练集不包含来自相应测试集的任何术语。不正确的预测在所有测试集上聚集，并且这个过程重复几次迭代(给定不同的随机种子来创建折叠)。直觉告诉我们，如果一个术语在每个文件夹中都被错误分类，那么这个注释可能是不正确的。然后通过在训练期间给它们较小的权重来抑制这些注释。随着F1分数提高0.2-0.4%，他们注意到他们的模型变得更加稳定，在多次运行中F1分数的标准偏差更低。</p><p id="c73a" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">正如在许多机器学习任务中显而易见的那样，数据集通常包含偏见。NER也不例外。识别在训练(记忆)期间看到的实体提及和处理形态变化(同义词概括)通常不会对像(生物)BERT这样的大模型造成问题。<strong class="ly jq">【8】</strong>然而，Kim和Kang发现，BioNER模型经常利用数据集偏差，并且未能归纳出在训练期间未见过的概念。<strong class="ly jq">【8】</strong>他们分析了BC5CDR数据集中的50个分类错误，发现BioBERT在其中34%的情况下使用了统计线索。</p><p id="6540" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">为了解释他们滥用了什么样的线索，让我们首先快速查看一下NER数据集中最常用的格式:<a class="ae jd" href="https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging))" rel="noopener ugc nofollow" target="_blank">内-外-开始注释模式</a> (IOB)。当一个实体由多个(子)字组成时，例如组织' Slimmer AI '，第一个字'<em class="od"> Slimmer </em>'以<strong class="ly jq"> <em class="od"> B- </em> </strong>为前缀，表示一个实体的开始，<em class="od"> 'AI' </em>以<strong class="ly jq"> <em class="od"> I- </em> </strong>为前缀，表示一个字是前面实体的一部分。不属于实体的单词用<strong class="ly jq"> <em class="od"> O </em> </strong>标注。这种格式有助于区分文本中的连续实体。</p><figure class="ny nz oa ob gt is gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/0bf2225178e8ea0539857e95c3c9ce94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*4S_TDnYJrPNZ9Tuvn6T8Ug.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">用IOB-scheme注释的例句。<em class="of"> Slimmer AI </em>是一个组织实体，由两部分组成:<em class="of"> Slimme </em> r，前缀为<em class="of"> B- </em>和<em class="of"> AI </em>，前缀为<em class="of"> I- </em>。其他单词不是实体，用<em class="of">或</em>标注。图片作者。</p></figure><p id="d3fa" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">Kim和Kang发现，一些单词只在训练集中与<strong class="ly jq"> <em class="od"> B- </em> </strong>一起出现，因此在测试集中总是被归类为<strong class="ly jq"> <em class="od"> B- </em> </strong>，导致不正确的预测。<strong class="ly jq">【8】</strong>为了解决这种偏差，他们提出了基于偏差乘积法的去偏差程序。<strong class="ly jq">【9】</strong>结果，这些模型确实对记忆性能产生了一点影响，但它们在同义词和概念概括方面有所改善。然而，他们的去偏置方法可能会减少在实体中使用有效模式的机会。这种模式的例子有“__ street”和“__ disease”，它们是非常相关的模式，可以用来促进概念的泛化。作者指出这是未来的工作。</p><p id="221a" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">生物医学领域的另一个大问题是，通常很难获得由专家注释的大型数据集。如果你碰巧找到这样一个黄金标准的语料库，它们通常都很小。为了解决小数据集的问题，你可以利用迁移学习、多任务学习或少量学习。</p></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h1 id="94f6" class="le lf jg bd lg lh ns lj lk ll nt ln lo kv nu kw lq ky nv kz ls lb nw lc lu lv bi translated">迁移和少量学习</h1><p id="94d1" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">使用预先训练的模型和应用迁移学习技术是当今NLP社区的常见做法，可以显著提高下游任务的性能。将它应用于BioNER任务也不例外，因为基于大量生物医学数据训练的几个模型已经开源并被频繁使用。最突出的模型之一是BioBERT，首先在一般领域语料库上进行预训练，随后在PubMed等生物医学领域语料库上进行预训练。<strong class="ly jq">【10】</strong>为了说明开源这些模型如此重要的原因，仅生物医学领域预培训的后半部分就花费了23天时间，使用了8个Nvidia V100 GPUs。这对中小型企业来说是一笔不小的投资。另一个取得显著成功的模型是HunFlair模型，它在23个生物医学数据集上进行训练，远远超过SciSpaCy和HUNER等BioNER模型。<strong class="ly jq">【11，12，13】</strong>使用领域特定模型而不是普通模型提高下游任务性能的证据是压倒性的。<strong class="ly jq">【8，10，11，14–18】</strong></p><figure class="ny nz oa ob gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi og"><img src="../Images/bfd77a6240e60863e087d0fa4408d1a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wI8wAKYAd9x2g7DIV0nhpA.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">展示迁移学习概念的高级概述。在一个数据集上训练的模型的一部分被转移，并在另一个任务上进一步微调。图片由作者提供，灵感来自<a class="ae jd" href="https://www.topbots.com/transfer-learning-in-nlp/" rel="noopener ugc nofollow" target="_blank"> TopBots </a>。</p></figure><p id="22da" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">与随机初始化的LSTM相比，HunFlair模型利用预训练，在不同类别的F1分数上提高了0.80-4.75%。观察到的增加主要是由更高的回忆引起的。他们的模型和训练数据可以在<a class="ae jd" href="https://github.com/flairNLP/flair/blob/master/resources/docs/HUNFLAIR.md" rel="noopener ugc nofollow" target="_blank">他们的GitHub </a>页面上找到，而且，由于它是流行的<a class="ae jd" href="https://github.com/flairNLP/flair" rel="noopener ugc nofollow" target="_blank">风格</a> Python库的一部分，你可以很容易地根据自己的喜好扩展这个模型。<strong class="ly jq">【19】</strong></p><p id="5af9" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">Peng等人引入了生物医学语言理解评估(BLUE)基准，其中BioNER是标准之一，以促进预训练模型开发中的研究(有关BLUE的更多信息，请查看各自的<a class="ae jd" href="https://github.com/ncbi-nlp/BLUE_Benchmark" rel="noopener ugc nofollow" target="_blank"> GitHub页面</a>)。<strong class="ly jq">【16】</strong>他们评估了几个BERT和ELMo基线，发现根据PubMed摘要和MIMIC-III临床笔记预先训练的BERT模型取得了最好的结果。<strong class="ly jq">【20】</strong>他们的模型被恰如其分地命名为BlueBERT，在所有数据集上均优于ELMo、BioBERT和其他最先进的模型。最佳模型设置在BioBERT上提高了8.9 F1分，单个数据集平均提高了1.8分。</p><p id="e7e5" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">Giorgi和Bader利用银标准语料库，这些语料库往往更大，但质量较低。<strong class="ly jq">【17】</strong>这样的语料库可以通过使用现有的NER模型来标注大的、未标记的语料库来生成。作者通过首先在这些银标准语料库上进行训练，然后在金标准语料库上进行微调，在几个数据集上实现了11%的错误减少。对于注释很少的数据集(&lt; 6000)，改进特别大。</p><p id="87b5" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">预培训也带来了应用一些技术的机会，比如少量学习:只使用少量标签来微调你的模型。这是一项非常有用的技术，尤其是在缺少带注释数据的领域。Hofer等人评估了在医学领域中处理这种小数据集的五种技术，直到仅使用10个训练样本。<strong class="ly jq">【21】</strong>作为基线，他们使用了一个基于当时为CoNLL-2003和OntoNotes 5.0调整的最先进模型的模型。<strong class="ly jq">【7，22】</strong>改善他们的少数镜头学习任务的技术之一涉及使用更多样本对相关数据集进行预训练。在对几个数据集进行测试后，他们在最佳设置下的F1分数比基线提高了4.52%。使用同一个域中的数据集明显优于使用另一个域中的数据集。</p><p id="811b" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">另一种设置利用多个单独的数据集，并对所有数据集进行组合预训练。有趣的是，与使用单一数据集进行预训练相比，作者报告了-1.66%的负面影响。作者指出，这可能是由他们的训练策略引起的，因为他们使用了针对单独数据集优化的超参数。他们进一步认为，通过对第一个数据集进行预训练获得的权重可能不适合第二个数据集。值得注意的最后一种技术是使用专门在生物医学文本上训练的单词嵌入作为输入，而不是使用普通的手套嵌入。<strong class="ly jq">【23】</strong>这让他们的F1得分又提高了3.78%。所有技术的结合使他们的F1分数从69.30%提高到78.87%，这是一个很好的提高。</p></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h1 id="cfa9" class="le lf jg bd lg lh ns lj lk ll nt ln lo kv nu kw lq ky nv kz ls lb nw lc lu lv bi translated">多任务学习</h1><p id="6d3e" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">除了应用迁移学习，另一种流行的方法是使用多任务学习:不仅训练手头的任务，还包括其他相关任务，以提高主要任务的表现。这背后的概念是，相似的任务或数据集具有语义和语法的相似性，这有助于为手头的任务训练更优化的模型。此外，它可以减少过度拟合的机会。常见的任务包括标注词性(POS)标签、句法成分和依赖关系。<strong class="ly jq">【2，14】</strong>此外，这些任务的数据相对容易获得，因为语法特征可以使用现成的工具包获得，如<a class="ae jd" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> NLTK </a>或<a class="ae jd" href="https://stanfordnlp.github.io/CoreNLP/" rel="noopener ugc nofollow" target="_blank"> Stanford CoreNLP </a>。</p><figure class="ny nz oa ob gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi og"><img src="../Images/6372e6285e6ce5cef098a91c30c65a2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5sIg-uC8azQJR4y_P3pzdw.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">应用多任务学习的示例架构。第一层由不同但相关的任务共享。图片由作者提供，灵感来自<a class="ae jd" href="https://ruder.io/multi-task/" rel="noopener ugc nofollow" target="_blank"> Ruder.io </a>。</p></figure><p id="622f" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">Tian等人尝试使用键值记忆网络将句法特征结合到BioBERT模型中，并看到其性能提高了约0.2–0.9% F1。这听起来可能不多。然而，当考虑到一些数据集上的一些模型已经在90%以上的范围内执行时，这样的增加可能是显著的。</p><p id="70a3" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">Wang等人将使用具有不同实体类型的多个数据集的训练视为多任务问题。<strong class="ly jq">【18】</strong>他们通过迭代遍历数据集来训练不同的BioNER模型，同时在这些模型之间共享一些参数。在15个数据集的14个数据集上，它们优于之前的最先进水平，f 1得分提高了0.2%至1.8%。</p><p id="6fe4" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">Khan等人采用了类似的方法，但他们将他们的模型视为一个单一的模型，每个任务都有共享的底层和特定的顶层。<strong class="ly jq">【15】</strong>对于下层，他们使用了预训练的BioBERT模型。在三个数据集上的训练产生了最佳性能，与单任务学习模型相比，F1分数提高了0.2-1.3%，并在王等人的模型上进一步提高了0.7-2.3% F1。</p><p id="bb4b" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">应用多任务学习的一种独特方式是让多个单一模型进行协作。CollaboNet是一个应用这一技巧的框架，它使用在不同数据集上训练的特定模型来完成不同的任务。<strong class="ly jq">【24】</strong>作者指出，常规的多任务学习产生的模型在回忆上得分较高，但精确度较低。因为这些模型是针对几种不同的实体类型进行训练的，所以它们在预测正确的实体类型时往往会有困难。此外，作者确定了生物医学领域的一个问题，即实体可以根据上下文被标记为不同的实体类型。有些词在一种语境中可以表示基因，在另一种语境中可以表示疾病。</p><p id="1c5a" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">使用CollaboNet，他们试图通过为协作的每种实体类型建立专家模型来解决这个问题。在训练期间，这些模型轮流被更新或作为合作者。每个模型接收协作者模型的输出，并将其用作辅助输入。因此，每个模型都被认为是自己领域的专家，同时通过利用多领域信息来提高其他模型的性能。与王等人相比，CollaboNet的F1得分提高了0.2-5.0%。<strong class="ly jq">【18】</strong>值得注意的是，使用BiLSTM-CRF架构的CollaboNet已经被BioBERT超越。然而，该框架本身仍然可以应用于更先进的模型，进一步提高它们的分数。然而，人们需要足够的记忆和时间来应用它。</p><p id="0b2c" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">缓解内存和时间问题的一种方法是使用较小的网络，或者使用利用权重共享的网络。一个很有前途的模型是生物阿尔伯特，基于(你猜对了):阿尔伯特。除了他们的参数缩减技术来加速模型，作者不仅在NER的任务上训练他们的模型，而且还应用了句序预测。这种技术从训练数据中提取两个连续的句子和两个随机的句子，并尝试预测一个句子是否跟随另一个句子。这允许模型更好地学习依赖于上下文的表示。</p><p id="6138" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">BioALBERT在几个数据集上的表现一直优于BioBERT，而且常常是大幅度领先，他们报告的分数相当可观。随着参数的减少，训练时间减少了大约2-3倍:这是一个巨大的胜利！作者在<a class="ae jd" href="https://github.com/usmaann/BioALBERT" rel="noopener ugc nofollow" target="_blank"> Github </a>上公开了他们的模型。</p></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h1 id="2d18" class="le lf jg bd lg lh ns lj lk ll nt ln lo kv nu kw lq ky nv kz ls lb nw lc lu lv bi translated">基于知识的NER和本体论</h1><p id="2b61" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">当您由于昂贵且劳动密集型的标注过程而没有大量已标记数据时，可能有另一种训练模型的方法:基于知识的NER。基于知识的NER模型基于与本体和注释的对应关系进行分类。</p><figure class="ny nz oa ob gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oh"><img src="../Images/476515d8ff544c05eb4de5e018576ba8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yiXNscEBFYOVJpYH"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">照片由<a class="ae jd" href="https://unsplash.com/@lightrisephoto?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">德文神</a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="11a8" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">具有挑战性的MedMentions数据集将他们的注释建立在广泛的<a class="ae jd" href="https://www.nlm.nih.gov/research/umls/index.html" rel="noopener ugc nofollow" target="_blank"> UMLS </a>本体论的基础上。<strong class="ly jq">【3】</strong>这个丰富的本体包含了数百万个概念，在几个专注于创建仿生系统的研究中使用。MedMentions数据集“仅”标注了35.2万次UMLS概念，但它仍然是最具挑战性的数据集之一。大量的概念使得任何模型都难以记忆或概括。因此，在这个数据集上表现最好的基于BERT的模型达到大约56% F1的测试分数就不足为奇了。<strong class="ly jq">【27】</strong>我的同事<a class="oi oj ep" href="https://medium.com/u/d4d520c0dfe?source=post_page-----c42a3f63334c--------------------------------" rel="noopener" target="_blank"> Stephan Tulkens </a>的后续博客文章将尝试使用无监督方法处理MedMentions数据集，敬请关注！</p><p id="9e61" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">回到基于知识的:2013年，Zhang和Elhadad通过对语料库中每个出现的TF-IDF向量进行平均，为每个出现的实体类型创建了签名向量。然后，将这些向量与所有名词短语块的向量进行比较，以识别所有实体。它优于传统的基于字典的方法，但低于最近的监督方法。</p><p id="d1f9" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">吉亚斯万德和凯特通过几项改进超过了张和艾尔哈达德。【28,29，29】他们只使用明确的UMLS项作为种子项来生成正反例。这些例子的句法和语义特征被用于训练决策树的集合。这个模型的输出然后被用来扩展例子，以包括模糊的UMLS术语。这个循环重复了几次。该方法优于其他非监督方法，并且在一些实体类上，它的性能与使用手动注释的监督系统相当。</p><p id="a4cd" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">类似地，De Vine等人从自由文本笔记中学习概念嵌入，首先使用UMLS附带的匹配器提取概念。<strong class="ly jq">【30】</strong>然后，他们用概念的ID替换文本中的任何跨度，然后通过应用skip-gram(例如，word2vec)学习概念嵌入。通过在两个小数据集上将概念之间的余弦距离与人类判断相关联来评估这些概念，并获得了积极的结果。</p><p id="222b" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">Beam等人采用了类似的方法，后来他们的嵌入技术<a class="ae jd" href="http://cui2vec.dbmi.hms.harvard.edu/" rel="noopener ugc nofollow" target="_blank">公开发布</a>。<strong class="ly jq">【31】</strong>Phan等人通过使用一种“暹罗”网络来学习姓名嵌入:他们使用预先训练的单词嵌入和字符嵌入作为BiLSTM的输入。<strong class="ly jq">【32】</strong>然后使用BiLSTM的输出来计算三个损失:一个损失是惩罚同义词之间的距离(即同义词应该靠得很近)，一个损失是惩罚名称和概念(即由名称表示的概念)之间的距离，一个损失是惩罚到“局部上下文”的距离(即概念出现在其中的单词嵌入的平均值)。).他们的模型在许多检索、相似性和关联性任务上优于其他基线。</p><p id="dbb9" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">脸书人工智能的研究人员提出了无监督知识增强语言模型(KALM)，它用知识库增强了传统的语言模型，端到端地训练以优化<a class="ae jd" href="https://en.wikipedia.org/wiki/Perplexity" rel="noopener ugc nofollow" target="_blank">困惑</a>。<strong class="ly jq">【33】</strong>在训练过程中，在给定目前观察到的上下文和作为输入的知识库的情况下，它使用门控机制来控制一个单词是一般单词还是应该被建模为对实体的引用。它随后在预测时间期间使用这种门控机制来预测一个单词是否是一个实体。它不需要任何额外的信息，例如在文本语料库中标记的命名实体标签，并且仍然实现了与现有技术的监督模型相当的性能。</p><p id="3cf2" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">Karadeniz和ozgür解决了实体规范化的问题:将实体映射到一个本体/字典，这对理解被识别的实体是必要的。<strong class="ly jq">【34】</strong>由于几个原因，这在生物医学领域不是一个要解决的小问题。如前所述，通常存在歧义问题——实体可能根据上下文具有不同的语义。此外，还存在识别在文本中以不同表面形式出现的概念(例如，现在和过去时态，或缩写)的挑战。</p><p id="0540" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">作者通过使用带有句法分析信息的预训练单词嵌入，以无监督的方式利用语义和句法信息。他们获得了一个新的最先进的精确分数，以2.9个百分点的优势击败了之前的最先进分数。</p><p id="7f92" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">但是，当您想要提取的实体没有在文本中明确提到，而是；含蓄？举个例子，假设一个句子包含<em class="od">水解</em>这个词。单词<em class="od">水</em>或<em class="od"> H2O </em>没有被明确地提到，但是你可以推断水参与了这个过程。</p><p id="f777" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">Shoshan和Radinsky创造了潜在实体提取(LEE)的任务，在这里你试图识别这些隐含的实体。<strong class="ly jq">【35】</strong>在他们的研究中，作者使用<a class="ae jd" href="https://reactome.org/" rel="noopener ugc nofollow" target="_blank">反应体</a>本体集中于生化反应领域。他们使用预训练的单词嵌入和顶部的BiLSTM分类器训练了几个一对一对所有分类器，一个分类器用于一种类型的实体。这里还应用了多任务学习，不仅训练每个分类器的指定实体类型，还训练其他相关类型。作者表明，他们的模型在识别这些潜在实体方面达到了很高的性能。作者得出结论，LEE任务将显著改进许多NER系统和基于它们构建的应用程序。</p></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h1 id="b858" class="le lf jg bd lg lh ns lj lk ll nt ln lo kv nu kw lq ky nv kz ls lb nw lc lu lv bi translated">结束语</h1><p id="1685" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated">生物医学命名实体识别的挑战是不可低估的。幸运的是，对于我们所有在软件产品开发中积极应用人工智能的人来说，有许多聪明的头脑帮助我们处理这个复杂的领域。</p><p id="7aa4" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">我被我们可以用来走得更远的许多“技巧”所鼓舞。例如，您可以使用CrossWeigh框架来处理嘈杂的注释，识别和去偏差您的数据，或者使用银标准语料库来预训练您的模型。如果有机会的话，你当然应该在相关的任务中利用迁移学习和多任务学习。</p><p id="89cf" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">有许多预先训练的模型可用，您可以从多任务学习方案中进行选择。而且，如果你没有可用的带注释的数据，我建议求助于基于知识的系统，它利用本体论或任何其他种类的知识库。最后，考虑在你的文本中是否有隐含的实体。如果是这样，一定不要忽视它们，无论如何都要尝试提取它们。</p><p id="7067" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">最后一点:我确信我们已经错过了文献中一些有趣和有前途的技术。如果你知道任何，请在评论中留下回复，与社区的其他人分享(你太棒了)。祝你的BioNER之旅好运！感谢我的同事<a class="oi oj ep" href="https://medium.com/u/c5b3cf7064de?source=post_page-----c42a3f63334c--------------------------------" rel="noopener" target="_blank">米歇尔·范·德·斯蒂格</a>和<a class="oi oj ep" href="https://medium.com/u/d4d520c0dfe?source=post_page-----c42a3f63334c--------------------------------" rel="noopener" target="_blank">斯蒂芬·图尔肯斯</a>为这项研究做出的贡献。</p></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h1 id="22ec" class="le lf jg bd lg lh ns lj lk ll nt ln lo kv nu kw lq ky nv kz ls lb nw lc lu lv bi translated">参考</h1><p id="6be0" class="pw-post-body-paragraph lw lx jg ly b lz ma kq mb mc md kt me mf mg mh mi mj mk ml mm mn mo mp mq mr ij bi translated"><strong class="ly jq">【1】</strong>v . Yadav和S. Bethard，<a class="ae jd" href="https://www.aclweb.org/anthology/C18-1182/" rel="noopener ugc nofollow" target="_blank">深度学习模型命名实体识别近期进展综述</a> (2018)，第27届计算语言学国际会议论文集。</p><p id="7a4b" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【2】</strong>j . Li，A. Sun，J. Han，C. Li，<a class="ae jd" href="https://ieeexplore.ieee.org/abstract/document/9039685" rel="noopener ugc nofollow" target="_blank">面向命名实体识别的深度学习综述</a> (2020)，IEEE知识与数据工程汇刊。</p><p id="d43f" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【3】</strong>s . Mohan和D. Li，<a class="ae jd" href="https://arxiv.org/abs/1902.09476" rel="noopener ugc nofollow" target="_blank"> MedMentions:一个用概念标注的大型生物医学语料库</a> (2019)，2019年自动化知识库构建会议论文集。</p><p id="2a8a" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【4】</strong>j . d . Kim，T. Ohta，Y. Tsuruoka，Y. Tateisi和N. Collier，<a class="ae jd" href="https://www.aclweb.org/anthology/W04-1213/" rel="noopener ugc nofollow" target="_blank">jnl PBA生物实体识别任务介绍</a> (2004)，生物医学自然语言处理及其应用国际联合研讨会会议录。</p><p id="9a15" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq"/>【m . Huang，P. Lai，R.T. Tsai，W. Hsu，<a class="ae jd" href="https://arxiv.org/abs/1901.10219" rel="noopener ugc nofollow" target="_blank">修订版JNLPBA语料库:用于关系抽取任务的生物医学NER语料库修订版</a> (2019)，arXiv:1901.10219【cs .IR】。</p><p id="8965" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【6】</strong>z . Wang，J. Shang，L. Liu，L. Lu，J. Liu，J. Han，<a class="ae jd" href="https://arxiv.org/abs/1909.01441" rel="noopener ugc nofollow" target="_blank"> CrossWeigh:从不完全标注训练命名实体标记器</a> (2019)，arXiv:1909.01441【cs .CL】。</p><p id="bf2f" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【7】</strong>e . f . Tjong Kim Sang和F. De Meulder，<a class="ae jd" href="https://www.aclweb.org/anthology/W03-0419/" rel="noopener ugc nofollow" target="_blank">CoNLL-2003共享任务介绍:独立于语言的命名实体识别</a> (2003)，HLT-NAACL 2003第七届自然语言学习会议论文集。</p><p id="119a" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【8】</strong>h . Kim和J. Kang，<a class="ae jd" href="https://arxiv.org/abs/2101.00160" rel="noopener ugc nofollow" target="_blank">你们的生物医学命名实体模型是如何推广到小说实体的？</a> (2021)，arXiv:2101.00160【cs。CL】。</p><p id="386b" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【9】</strong>c . Clark，M. Yatskar和L. Zettlemoyer，<a class="ae jd" href="https://www.aclweb.org/anthology/D19-1418/" rel="noopener ugc nofollow" target="_blank">不要走捷径:基于集成的避免已知数据集偏差的方法</a> (2019)，2019年自然语言处理经验方法会议和第九届自然语言处理国际联合会议论文集。</p><p id="2174" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【10】</strong>j . Lee，W. Yoon，S. Kim，D. Kim，S. Kim，C. Ho So和J. Kang，<a class="ae jd" href="https://academic.oup.com/bioinformatics/article/36/4/1234/5566506" rel="noopener ugc nofollow" target="_blank"> BioBERT:一种用于生物医学文本挖掘的预训练生物医学语言表示模型</a> (2020)，生物信息学。</p><p id="8b8a" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【11】</strong>l . Weber，m . singer，J. Münchmeyer，M. Habibi，U. Leser和A. Akbik，<a class="ae jd" href="https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/btab042/6122692" rel="noopener ugc nofollow" target="_blank"> HunFlair:一种用于最新生物医学命名实体识别的易用工具</a> (2021)，生物信息学。</p><p id="8e34" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【12】</strong>m . Neumann，D. King，I. Beltagy和W. Ammar，<a class="ae jd" href="https://arxiv.org/abs/1902.07669" rel="noopener ugc nofollow" target="_blank"> ScispaCy:生物医学自然语言处理的快速鲁棒模型</a> (2019)，arXiv:1902.07669【cs .CL】。</p><p id="fe6e" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq"/>l . Weber，J. Münchmeyer，t . rocktschel，M. Habibi，U. Leser，<a class="ae jd" href="https://academic.oup.com/bioinformatics/article/36/1/295/5523847" rel="noopener ugc nofollow" target="_blank"> HUNER:用预训练改善生物医学NER</a>(2019)，生物信息学。</p><p id="0396" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【14】</strong>【2020】田永辉，沈文伟，宋永辉，夏，何，李，<a class="ae jd" href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-020-03834-6" rel="noopener ugc nofollow" target="_blank">利用句法信息改进生物医学命名实体识别，BMC生物信息学。</a></p><p id="19a6" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【15】</strong>m . r . Khan，M. Ziyadi和M. Abdelhady，<a class="ae jd" href="https://arxiv.org/abs/2001.08904" rel="noopener ugc nofollow" target="_blank"> MT-BioNER:使用深度双向变换器的生物医学命名实体识别的多任务学习</a> (2020)，arXiv:2001.08904 [cs .CL】。</p><p id="f2ad" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【16】</strong>【y . Peng，S. Yan，和Z. Lu，<a class="ae jd" href="https://www.aclweb.org/anthology/W19-5006/" rel="noopener ugc nofollow" target="_blank">生物医学自然语言处理中的迁移学习:在十个基准数据集上对BERT和ELMo的评估</a> (2019)，第18届BioNLP研讨会和共享任务会议录。</p><p id="a278" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【17】</strong>j . m . Giorgi和G.D. Bader，<a class="ae jd" href="https://www.aclweb.org/anthology/L18-1708/" rel="noopener ugc nofollow" target="_blank">用神经网络进行命名实体识别的迁移学习</a> (2018)，第十一届语言资源与评价国际会议论文集。</p><p id="eb44" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【18】</strong>x . Wang，Y. Zhang，X. Ren，Y. Zhang，M. Zitnik，J. Shang，C. Langlotz，J. Han，<a class="ae jd" href="https://academic.oup.com/bioinformatics/article/35/10/1745/5126922" rel="noopener ugc nofollow" target="_blank">深度多任务学习的跨类型生物医学命名实体识别</a> (2018)，生物信息学。</p><p id="4c2f" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【19】</strong>a . AK bik，D.A. Blythe和R. Vollgraf，<a class="ae jd" href="https://www.aclweb.org/anthology/C18-1139/" rel="noopener ugc nofollow" target="_blank">用于序列标注的上下文字符串嵌入</a> (2018)，第27届计算语言学国际会议论文集。</p><p id="b0fb" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【20】</strong>a . e . w . Johnson，T.J. Pollard，L. Shen，L.H. Lehman，M. Feng，M. Ghassemi，B. Moody，P. Szolovits，L.A和R.G. Mark，<a class="ae jd" href="https://www.nature.com/articles/sdata201635" rel="noopener ugc nofollow" target="_blank"> MIMIC-III，一个可免费访问的危重病数据库</a> (2016)，科学数据。</p><p id="459e" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq"/>m . Hofer，A. Kormilitzin，P. Goldberg和A. Nevado-Holgado，<a class="ae jd" href="https://arxiv.org/pdf/1811.05468.pdf" rel="noopener ugc nofollow" target="_blank">医学文本中命名实体识别的少镜头学习</a> (2018)，arXiv:1811.05468【cs .CL】。</p><p id="3b1d" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated">E. Hovy，M. Marcus，M. Palmer，L. Ramshaw和R Weischedel，<a class="ae jd" href="https://www.aclweb.org/anthology/N06-2015/" rel="noopener ugc nofollow" target="_blank">onto notes:90%解决方案</a> (2006)，NAACL人类语言技术会议论文集。</p><p id="9f30" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【23】</strong>j . Pennington，R. Socher和C.D. Manning，<a class="ae jd" href="https://www.aclweb.org/anthology/D14-1162/" rel="noopener ugc nofollow" target="_blank"> GloVe:单词表示的全局向量</a> (2014)，2014年自然语言处理经验方法会议论文集。</p><p id="da0f" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【24】</strong>w . Yoon，C. So和J. Lee，<a class="ae jd" href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2813-6" rel="noopener ugc nofollow" target="_blank"> CollaboNet:用于生物医学命名实体识别的深度神经网络协作</a> (2019)，BMC生物信息学。</p><p id="4087" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【25】</strong>u . Naseem，M. Khushi，V. Reddy，S. Rajendran，I. Razzak和J，Kim，<a class="ae jd" href="https://arxiv.org/abs/2009.09223" rel="noopener ugc nofollow" target="_blank"> BioALBERT:一种简单有效的生物医学命名实体识别预训练语言模型</a> (2020)，arXiv:2009.09223【cs .CL】。</p><p id="fe7f" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【26】</strong>z . Lan，M. Chen，S. Goodman，K. Gimpel，P. Sharma和R. Soricut，<a class="ae jd" href="https://arxiv.org/abs/1909.11942" rel="noopener ugc nofollow" target="_blank"> ALBERT:一个用于语言表征自我监督学习的Lite BERT</a>(2019)，arXiv:1909.11942【cs .CL】。</p><p id="59a5" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【27】</strong>k . c . Fraser，I. Nejadgholi，B. Bruijn，M. Li，A. LaPlante和K.Z. Abidine，<a class="ae jd" href="https://arxiv.org/abs/1910.01274" rel="noopener ugc nofollow" target="_blank">使用通用和特定领域深度学习模型从医学文本中提取UMLS概念</a> (2019)，arXiv:1910.01274【cs .CL】。</p><p id="5b92" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【28】</strong>s . Zhang和N. Elhadad，<a class="ae jd" href="https://www.sciencedirect.com/science/article/pii/S1532046413001196" rel="noopener ugc nofollow" target="_blank">无监督生物医学命名实体识别:临床和生物文本实验</a> (2013)，生物医学信息学杂志。</p><p id="1757" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【29】</strong>o . Ghiasvand和R.J. Kate，<a class="ae jd" href="https://www.sciencedirect.com/science/article/pii/S2352914818301965" rel="noopener ugc nofollow" target="_blank">无人工标注的临床命名实体识别的学习</a> (2018)，医学信息学解锁。</p><p id="1731" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【30】</strong>l . De Vine，G. Zuccon，B. Koopman，L. Sitbon和P. Bruza，<a class="ae jd" href="https://dl.acm.org/doi/10.1145/2661829.2661974" rel="noopener ugc nofollow" target="_blank">用神经语言模型进行医学语义相似度</a> (2014)，第23届ACM信息与知识管理国际会议论文集。</p><p id="4d31" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【31】</strong>a . l . Beam，B. Kompa，A. Schmaltz，I. Fried，G. Weber，N. Palmer，X. Shi，T. Cai和I.S. Kohane，<a class="ae jd" href="https://pubmed.ncbi.nlm.nih.gov/31797605/" rel="noopener ugc nofollow" target="_blank">从多模态医学数据的海量来源中学习的临床概念嵌入</a> (2018)，太平洋生物计算研讨会。</p><p id="913a" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【32】</strong>m . c . Phan，A. Sun，Y. Tay，<a class="ae jd" href="https://www.aclweb.org/anthology/P19-1317/" rel="noopener ugc nofollow" target="_blank">生物医学名称的鲁棒表征学习</a> (2019)，计算语言学协会第57届年会论文集。</p><p id="f8da" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【33】</strong>a . Liu，J. Du，V. Stoyanov，<a class="ae jd" href="https://www.aclweb.org/anthology/N19-1117/" rel="noopener ugc nofollow" target="_blank">知识增强语言模型及其在无监督命名实体识别中的应用</a> (2019)，计算语言学协会北美分会2019年会议论文集:人类语言技术。</p><p id="8819" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【34】</strong>i̇.Karadeniz和a . ozgür，<a class="ae jd" href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2678-8" rel="noopener ugc nofollow" target="_blank">使用单词嵌入和句法重排通过本体链接实体</a> (2019)，BMC生物信息学。</p><p id="6093" class="pw-post-body-paragraph lw lx jg ly b lz mu kq mb mc mv kt me mf ni mh mi mj nj ml mm mn nk mp mq mr ij bi translated"><strong class="ly jq">【35】</strong>e . Shoshan和K. Radinsky，<a class="ae jd" href="https://www.aclweb.org/anthology/K18-1020/" rel="noopener ugc nofollow" target="_blank">潜在实体提取:如何提取文本中没有出现的实体？</a> (2018)，第22届计算自然语言学习会议论文集。</p></div></div>    
</body>
</html>