<html>
<head>
<title>3D Object Classification and Segmentation with MeshCNN and PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于MeshCNN和PyTorch的三维物体分类与分割</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/3d-object-classification-and-segmentation-with-meshcnn-and-pytorch-3bb7c6690302?source=collection_archive---------8-----------------------#2021-06-02">https://towardsdatascience.com/3d-object-classification-and-segmentation-with-meshcnn-and-pytorch-3bb7c6690302?source=collection_archive---------8-----------------------#2021-06-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f9a7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">MeshCNN引入了网格池操作，使我们能够将CNN应用于3D模型。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2b79de820b72257ebbe6d7ad2c4dc5f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LWZrXGxFTck_2rTb7GMFLg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">连续的网格池操作应用于一个半人马的3D模型【来自<a class="ae ky" href="https://ranahanocka.github.io/MeshCNN/" rel="noopener ugc nofollow" target="_blank"> MeshCNN项目页面</a>】。</p></figure><p id="ed79" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对3D数据应用机器学习不像对图像那样简单。3D数据有多种表示方式，但选择决定了您可以采用哪种学习策略。在这篇文章中我讲述了一个特别有趣的(至少对我来说😆)战略叫做<a class="ae ky" href="https://paperswithcode.com/paper/meshcnn-a-network-with-an-edge" rel="noopener ugc nofollow" target="_blank"> MeshCNN:一个有优势的网络</a>。本文描述了一个通用框架，用于处理分类和分割任务的三维模型。也许它最有趣的特征是它的<strong class="lb iu">网格汇集</strong>操作，这使我们能够在多个尺度上组合网格的特征(类似于视觉CNN)。这是一个学习的操作，逐渐将模型减少到对给定任务最有用的边缘。MeshCNN结合了每种流行的3D表示的许多最佳特性。然而，在我们进入细节之前，让我们通过对3D表示的简要回顾来了解那些属性是什么。</p><h1 id="9b33" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">3D数据表示</h1><p id="c0fc" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">深度学习的3D网格表示方式最好是什么？与2D RGB图像不同，对于最佳表现形式并没有共识。这个问题很难回答，因为表征的选择决定了我们必须采取的学习方法。对于分类示例，您可以将模型从3D空间投影到2D影像中，并应用标准的2D卷积。您可以将模型占据的3D空间表示为体素网格，从而允许您应用3D卷积。您可以简单地将网格的顶点作为3D点云进行采样，并应用专门的方法，如<a class="ae ky" href="https://paperswithcode.com/paper/pointnet-deep-hierarchical-feature-learning" rel="noopener ugc nofollow" target="_blank"> PointNet++或</a><a class="ae ky" href="https://paperswithcode.com/paper/3d-point-capsule-networks" rel="noopener ugc nofollow" target="_blank"> 3D点胶囊网络</a>。甚至还有像<a class="ae ky" href="https://arxiv.org/abs/2002.10880" rel="noopener ugc nofollow" target="_blank"> PolyGen </a>这样的方法可以直接处理模型的顶点和面，我在之前的文章<a class="ae ky" rel="noopener" target="_blank" href="/generating-3d-models-with-polygen-and-pytorch-4895f3f61a2e">用PolyGen和PyTorch </a>生成3D模型中提到过。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/1d646fdf13508e85757711216294dc99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*03AYAhwY1ryalPiANwpB0g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">3D网格的最典型表示[来自NVIDIA 的<a class="ae ky" href="https://github.com/NVIDIAGameWorks/kaolin" rel="noopener ugc nofollow" target="_blank">高岭土库，根据</a><a class="ae ky" href="https://www.apache.org/licenses/LICENSE-2.0.html" rel="noopener ugc nofollow" target="_blank"> Apache许可证版本授权。2.0 </a>并编辑添加文字】。</p></figure><h2 id="7e93" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">推断</h2><p id="2ed2" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">一些最早的3D深度学习研究直接绕过3D表示问题，并简单地将3D模型投影到2D图像中。这使得3D数据服从于经典的视觉CNN方法。例如，<a class="ae ky" href="https://arxiv.org/abs/1505.00880" rel="noopener ugc nofollow" target="_blank">中描述的用于3D形状识别的多视图卷积神经网络</a>的方法将一个模型投射到12个独特的视点中，并汇集它们的激活以产生一个softmax分数。在ModelNet40数据集上，他们报告了90.1%的可靠分类准确率。根据<a class="ae ky" href="https://modelnet.cs.princeton.edu/" rel="noopener ugc nofollow" target="_blank">项目网站</a>的说法，ModelNet40数据集上迄今为止的最佳性能为97.37%，这来自一篇名为<a class="ae ky" href="https://arxiv.org/abs/1603.06208" rel="noopener ugc nofollow" target="_blank"> RotationNet:使用来自无监督视点的多视图进行联合对象分类和姿态估计</a>的论文。与上一篇论文类似，它在多个视图上训练以预测对象类别，但同时也预测视点，将其视为潜在变量。它能够有效地预测对象类别和视点，甚至对真实世界的对象也是如此。</p><p id="b627" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然简单而优雅，但是投影表示a)没有考虑模型的完整拓扑结构，b)对应该如何查看模型做出假设，以及c)没有为分割之类的非全局任务提供直接的解决方案。</p><h2 id="5d54" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">三维像素</h2><p id="b419" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">体素方法在不牺牲卷积的情况下解决了投影方法的许多问题。通过将3D空间划分为多个面元来创建密集的占用网格，如果每个面元位于模型内，则为每个面元分配一个布尔值。网格布局很容易应用3D卷积。可能最早使用这种表示的论文是<a class="ae ky" href="https://arxiv.org/abs/1406.5670" rel="noopener ugc nofollow" target="_blank"> 3D ShapeNets:一种体积形状的深度表示</a>，该论文实际上介绍了ModelNet40数据集。在这项研究中，他们试图通过从单个深度图像预测3D体素来恢复对象的3D结构，并取得了非常显著的结果。</p><p id="a4e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从3D体素分类是另一回事。虽然您可以获得不错的结果，但缺点是在空白空间上有过多的卷积，因为空间的占用率非常低。最重要的是，模型分辨率会对权重的数量进行立体缩放，因此在大多数情况下，大于256x256x256的大小是不切实际的，即使是在显著利用空间稀疏性的情况下，例如在<a class="ae ky" href="https://arxiv.org/abs/1611.05009" rel="noopener ugc nofollow" target="_blank"> OctNet:在高分辨率下学习深度3D表示</a>中。在这篇论文中，他们在ModelNet40上实现了大约86%的准确率，并在速度和内存消耗方面有了很大的改进。高分辨率体素空间是昂贵的，但是低分辨率体素空间挤压了模型拓扑的潜在有用的精细细节。</p><h2 id="2394" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">点云</h2><p id="b43e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">很多方法侧重于直接处理矢量点云。例如，在2019年的论文<a class="ae ky" href="https://paperswithcode.com/paper/spherical-kernel-for-efficient-graph" rel="noopener ugc nofollow" target="_blank">中，作者使用他们的方法在ModelNet40任务上实现了89.3%的准确率。3D点云表示的优势在于其多功能性，因为从激光雷达扫描到创作的3D模型，一切都可以表示为3D点云。即使是经典的PointNet和PointNet++模型也可以在分类任务上取得相当好的结果(在上面的论文中为88.0%)。缺点是大多数点云方法完全忽略了表面。如果没有面，就无法知道网格的真实拓扑，因为任何向量集都不会唯一地定义一组面。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nf"><img src="../Images/d2543eb0e8e5cc2bf66673045bae06e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9mMQGzyphfyQjwPoXaSnhg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">这只骆驼的膝盖如此之近，以至于在不知道模型表面的情况下，它们可能无法分开，也就是它的脸【来自<a class="ae ky" href="https://ranahanocka.github.io/MeshCNN/" rel="noopener ugc nofollow" target="_blank"> MeshCNN论文</a>的图3】。</p></figure><p id="305f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ModelNet40上表现最好的方法之一来自一种称为<a class="ae ky" href="https://arxiv.org/abs/1904.07601" rel="noopener ugc nofollow" target="_blank">关系形状卷积神经网络的方法，用于点云分析</a>，达到93.6%的准确率。这种方法被称为RS-CNN，它试图从几何先验中推断给定点云的底层拓扑结构，从而赋予模型对其输入点的空间感知能力。该模型取得了良好的性能，可以应用于点云和网格。然而，即使网格信息可用，它也没有利用网格信息的机制。</p><h1 id="a145" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">MeshCNN</h1><p id="5a15" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">有没有一种方法可以直接研究网格，而不牺牲有价值的拓扑信息，不增加体素的计算成本，或者对如何查看它做出假设？MeshCNN提出的解决方案是通过将3D模型视为图形或流形来共同研究顶点及其连接或边。这种方法定义了3D网格边缘上的卷积和池层，允许我们或多或少地使用卷积神经网络的标准工具集。最终，他们能够在来自<a class="ae ky" href="http://reuter.mit.edu/blue/papers/shrec11/shrec11.pdf" rel="noopener ugc nofollow" target="_blank"> SHREC 11数据集</a>的30个类别上实现98.6%的准确性(他们没有报告ModelNet40的准确性)，以及在对象部分和人体数据集上令人印象深刻的分割性能。<a class="ae ky" href="https://github.com/ranahanocka/MeshCNN" rel="noopener ugc nofollow" target="_blank"> MeshCNN源代码</a>由作者提供，如果你想参考他们的实现。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/346502dbebefc305d9eb1e53d4122587.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mpzVRQY0NPASoHR1NrZ2XA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">网格汇集操作的描述【来自<a class="ae ky" href="https://ranahanocka.github.io/MeshCNN/" rel="noopener ugc nofollow" target="_blank"> MeshCNN论文</a>的图2】。A)三角形网格的给定边(红色)正好有4个邻居(蓝色)。b)池化操作通过合并其两个顶点来溶解该边，这又合并了溶解边的任一侧的边对，c)产生2条边。</p></figure><p id="a410" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">任何防水3D网格的边恰好入射到两个面上(边界或非流形边除外)。如果网格是三角形的(即它的所有面正好有3条边)，那么连接到任何边的两个入射面将总是接触总共5条边。这种一致性使得三角形网格对于机器学习技术特别方便。因此，MeshCNN假设我们的模型都是三角形的流形网格。典型的3D重建方法如摄影测量、结构光扫描和激光扫描产生三角形网格，因此该方法可以直接应用于这种数据。创作的网格通常包含四边形或n边形，通常在Maya或Blender中单击几下就可以转化为三角形网格。</p><p id="d786" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们可以定义一条边和它的4个邻居的卷积，我们可以随后建立一个卷积神经网络来处理整个网格。面临的挑战是定义一组具有以下属性的操作:</p><ul class=""><li id="b6d4" class="nh ni it lb b lc ld lf lg li nj lm nk lq nl lu nm nn no np bi translated">必须对顶点或边顺序保持不变(局部或全局)。</li><li id="5d8f" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">必须对相似性变换(即网格平移、旋转和缩放)保持不变。</li><li id="1ab2" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">必须传达给定顶点或边与其邻居的关系及其在网格全局结构中的位置。</li></ul><h2 id="de1e" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">网格卷积</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/2760a7dea5bd5c6d05b1b5901e20b551.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*Jsy3vMNy9OMtME107UAFsg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">边缘及其邻居(左)【来自<a class="ae ky" href="https://ranahanocka.github.io/MeshCNN/" rel="noopener ugc nofollow" target="_blank"> MeshCNN论文</a>的图4】。边缘<em class="nw"> a、c(红色)和b、d(蓝色)是相对的一对。</em>注意逆时针符号表示边缘对的严格排序，这样a <em class="nw">总是在b之前，c在d </em>之前。给定边(右侧)的输入要素也被设计为对于边的排序不变。</p></figure><p id="a8eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先让我们看看卷积运算本身。给定一条边和4个邻居，每个邻居都有自己的特征，卷积需要对这些边的顺序保持不变。本文采用的简单解决方案是使用对称函数定义卷积。它们处理相对于中心边缘<em class="nx"> e </em>逆时针排序的相对边缘对(例如<em class="nx"> a、c </em>和<em class="nx"> b、d </em>，并在应用卷积之前取它们的有限和与差:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/d5cb0677e03955c2e6278adb08a7a4de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XLjwVL0Nm9LlpVhFZ_q68w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等变特征组合的公式[等式。2摘自<a class="ae ky" href="https://ranahanocka.github.io/MeshCNN/" rel="noopener ugc nofollow" target="_blank"> MeshCNN论文</a>。</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nz oa l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等变卷积码。</p></figure><h2 id="60c5" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">网格输入特征</h2><p id="e419" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">然而，我们还没有解决一个关键问题。我们从什么特征开始？在应用第一次卷积之前，我们必须创建一个类似于2D影像中RGB通道的输入要素表示。为此，作者简单地为总共5个输入特征的每个面定义了<em class="nx">二面角</em>(两个邻接面之间的角度)<em class="nx">对称对角</em>(对角的角度，已排序以保持顺序不变)，以及两个<em class="nx">边长比</em>(每个三角形的高/底比，也已排序)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nz oa l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">输入要素的代码。</p></figure><h2 id="7935" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">网状池</h2><p id="f748" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">最后，让我们看看池操作。池只是将边的两个顶点合并在一起，将给定邻域的5条边折叠成2条。两个新边的特征仅仅是它们以前的边的特征的平均值。例如，上图中我们的两条新边的特征将是<em class="nx"> avg(a，b，e) </em>和<em class="nx"> avg(c，d，e) </em>。</p><p id="854d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是我们如何决定哪些边应该折叠呢？每个网格池层都使用要保留的目标边数进行实例化(使用代码中的<code class="fe ob oc od oe b">--pool_res</code>参数)。网格池图层只是根据边要素的平方大小对边进行排序。然后，它反复折叠网格边，直到达到目标边数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/b9b7993a094ceab0ff218c10c05b0d93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1-6bl9eozl0QbbEpxTgkmw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">网状池学习保留对给定任务最有信息的边[来自MeshCNN论文的图1]。“有柄或无柄”任务(顶部)的池保留花瓶中的柄，而“有颈或无颈”任务保留花瓶的颈部。</p></figure><p id="5eb4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于网格池操作是学习的，它授予模型学习权重的自由，该权重为给定的任务进行优化。还有一个恢复池化的网格取消池化操作，这对于分段任务是必不可少的。这意味着网络必须跟踪在U-Net型分段网络的编码器阶段完成的汇集操作。MeshCNN通过跟踪网格的<code class="fe ob oc od oe b">history_data</code>属性中的边折叠操作来实现这一点。</p><h2 id="7552" class="mt lw it bd lx mu mv dn mb mw mx dp mf li my mz mh lm na nb mj lq nc nd ml ne bi translated">体系结构</h2><p id="c9ce" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">网络架构由<code class="fe ob oc od oe b">MResConv</code>层组成，每一层由一个初始网格卷积(MeshConv)、几个连续的ReLU+BatchNorm+MeshConv层、一个残差连接和后面的另一个ReLU组成。网络遵循一个<code class="fe ob oc od oe b">MResConv</code> +Norm+ <code class="fe ob oc od oe b">MeshPool</code>的模式数次，才在任务层结束。对于分类，任务层是简单的全局平均池，后面是两个完全连接的层。分段网络是一个U-Net类型的编码器-解码器。</p><h1 id="0d30" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="8421" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">等变卷积运算、不变输入特征和学习网格池运算使MeshCNN成为一个特别有趣的模型，具有以下主要优势:</p><ul class=""><li id="3cbf" class="nh ni it lb b lc ld lf lg li nj lm nk lq nl lu nm nn no np bi translated">比旧方法更有效，参数更少。</li><li id="6d32" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">利用网格的拓扑结构(即顶点和面信息)，而不是将其视为点云。</li><li id="ab85" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">网格卷积保留了卷积的便利属性，但允许应用于图形数据。3D网格的5个输入特征类似于输入图像的RGB特征。</li><li id="90e8" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">对旋转、平移和缩放不变(参见论文的第5.4节)。</li><li id="2260" class="nh ni it lb b lc nq lf nr li ns lm nt lq nu lu nm nn no np bi translated">网格池(即学习的边折叠)允许网络通过将5个边折叠成2个边并溶解两个面来学习任务特定的池。</li></ul><p id="23da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您渴望亲自尝试，我鼓励您查看作者提供的<a class="ae ky" href="https://github.com/ranahanocka/MeshCNN" rel="noopener ugc nofollow" target="_blank"> MeshCNN </a>源代码。它是用PyTorch编写的，并提供了许多有用的脚本来在本文讨论的各种数据集上试用该模型。我发现它很干净，很容易使用，所以如果你很好奇想看看引擎盖下的话，值得看一看。一如既往，感谢阅读，继续学习！</p></div></div>    
</body>
</html>