<html>
<head>
<title>Spark MultiLayer Perceptron Classifier for POI Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于兴趣点分类的火花多层感知器分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/spark-multilayer-perceptron-classifier-for-poi-classification-99e5c68b4a77?source=collection_archive---------15-----------------------#2021-07-20">https://towardsdatascience.com/spark-multilayer-perceptron-classifier-for-poi-classification-99e5c68b4a77?source=collection_archive---------15-----------------------#2021-07-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="000a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用Spark深度学习模型将兴趣点分类为机场、公交车站和火车站</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/3e5e668685af9264723cc5b351cd1eae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TAvnX7AtIUK9Y5v9VzHC-Q.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">尼克·奥瓦尔在<a class="ae kv" href="https://unsplash.com/s/photos/space?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="41ae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="ls">注</em> </strong> <em class="ls">:本文是关于交通POI数据分类系列文章的第三篇。</em> <a class="ae kv" rel="noopener" target="_blank" href="/poi-classification-using-visit-and-popularity-metrics-part-1-ae5e94f92077"> <em class="ls">第一篇文章</em> </a> <em class="ls">试图使用各种机器学习模型将记录分类为机场、公交车站和火车站。</em> <a class="ae kv" rel="noopener" target="_blank" href="/pca-lda-and-svd-model-tuning-through-feature-reduction-for-transportation-poi-classification-8d20501ee255"> <em class="ls">第二篇文章</em> </a> <em class="ls">的中心思想是使用特征约简算法来调整第一篇文章中的模型，以提供更高的精度。查看这些文章，了解该项目在寻找POI数据分类的最佳方法方面是如何发展的。</em></p><p id="6522" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文将使用Spark MLlib包——特别是多层感知器分类器，使用步行交通模式对来自<a class="ae kv" href="http://Safegraph.com" rel="noopener ugc nofollow" target="_blank"> SafeGraph </a>的POI记录进行正确分类。SafeGraph是一家数据提供商，为数百家企业和类别提供POI数据。它向学术界免费提供数据。对于这个项目，我选择使用SafeGraph模式数据将记录分类为不同的兴趣点。模式数据的模式可以在这里找到:<a class="ae kv" href="https://docs.safegraph.com/v4.0/docs/places-schema#section-patterns" rel="noopener ugc nofollow" target="_blank">模式信息</a></p><h1 id="12d0" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">Spark简介</h1><p id="572e" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">Apache Spark是一个开源框架，旨在处理大数据。该框架之所以出名，是因为它能够通过使用并行(或分布式)计算来大幅提高性能并减少运行时间。</p><p id="9d89" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">为什么要火花MLlib？</strong></p><ol class=""><li id="f752" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">支持Statsmodels和Scikit-Learn等软件包支持的许多流行的机器学习算法</li><li id="8e70" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">允许构建复杂的机器学习管道</li><li id="8f9f" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">允许保存和重用算法和ML管道</li><li id="762b" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">支持分布式计算技术，通过将任务分成块并将其分配给多个节点并行执行，极大地减少了运行时间并提高了所有算法的性能</li></ol><p id="1788" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Spark MLlib确实是一个非常有趣和简单易懂的包，可以在很短的时间内提供一些非常有趣的见解，在运行时和性能方面提供了最好的东西。</p><p id="e467" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">火花深度学习</strong></p><p id="4347" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">MLlib包很少容纳深度学习。从Spark 3.0开始，该包不支持许多深度学习模型，而是更专注于回归、分类和聚类的概念。这个缺点的一个例外是多层感知器分类器。</p><p id="a912" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">为什么是多层感知器分类器？</strong></p><p id="bf1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">MLlib包中的每个分类模型都有其优点和缺点，不同的数据可能需要使用不同的模型来获得最大的效率。MLPC优于Spark MLlib包中提供的其他监督分类算法，因为它能够自行查找要素之间的相关性。此外，分类器适用于多类分类，并且不需要像传统算法(如Spark接口中的SVM算法)那样多的预处理和管道创建。最后，对于足够大和足够多样化的数据集，MLPC算法可以比大多数分类器表现得更好。</p><p id="2257" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有了这个介绍，让我们看看火花MLPC分类器是否能比本系列第1部分中的分类器表现得更好</p></div><div class="ab cl ne nf hu ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="ij ik il im in"><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/665d46a455b7e00c692191ee13a760ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z-JzSY2_f0UZjxAtNuwoIA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/@corella?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">胡安乔·科雷拉</a>在<a class="ae kv" href="https://unsplash.com/s/photos/land-and-sky?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="838e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们开始深度学习之前，我们必须首先加载数据。这个特殊的步骤在本系列的第一篇文章和第二篇文章中都有涉及。满足本文需求的数据加载和预处理的基本步骤是:</p><p id="7923" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们进入特征缩减概念的第一步之前，我们必须首先加载我们将用于这个项目的数据:加载数据的过程可以在<a class="ae kv" href="https://colab.research.google.com/drive/1A6ZZ0WZX3v4N5sN4pU5Yz_gxx2gThVqd?usp=sharing" rel="noopener ugc nofollow" target="_blank">笔记本</a>中找到，并且已经在系列的<a class="ae kv" rel="noopener" target="_blank" href="/poi-classification-using-visit-and-popularity-metrics-part-1-ae5e94f92077">第一部分中详细解释。就我们的目的而言，所需要的只是对所采取的步骤和结果数据框架的简要概述:</a></p><ol class=""><li id="9206" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">删除不必要的列- ['parent_safegraph_place_id '，' placekey '，' safegraph_place_id '，' parent_placekey '，' parent_placekey '，' safegraph_brand_ids '，' brands '，' poi_cbg']</li><li id="69bb" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">创建地面实况列，将每个记录建立为机场、汽车站、机场或未知</li><li id="7457" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">删除未知记录以清除无法识别的记录</li><li id="fd7c" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">使用pyspark水平分解JSON字符串的列</li><li id="5ce2" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">阵列的水平分解列</li><li id="b06a" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">使用Sklearn LabelEncoder包转换类列</li></ol><p id="955b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为这些转换的结果，输出的数据如下所示，并具有以下各列:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/331f85d2abcf4a528482a1f24c0a515c.png" data-original-src="https://miro.medium.com/v2/resize:fit:120/0*U1wUGTphSftXjNmo"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/e29a654244cd9ea84ce7ba77fb643cc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LeBbxsjVLdtUgwxY.png"/></div></div></figure><p id="3a8e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> Raw_visit_counts: </strong>在日期范围内，我们的小组中对此兴趣点的访问次数。</p><p id="c584" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> Raw_visitor_counts: </strong>在日期范围内从我们的面板访问该兴趣点的独立访问者的数量。</p><p id="db23" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> Distance_from_home: </strong>访客(我们已确定其住所的访客)离家的中间距离，以米为单位。</p><p id="b221" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">中值_停留:</strong>中值最小停留时间，以分钟为单位。</p><p id="e6ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">分时段停留(分解为&lt; 5，5–10，11–20，21–60，61–120，121–240):</strong>键是分钟的范围，值是在该持续时间内的访问次数</p><p id="89f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> Popularity_by_day(分解到周一至周日):</strong>一周中的某一天到日期范围内每天(当地时间)的访问次数的映射</p><p id="00e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> Popularity_by_hour(分解为Popularity _ 1-Popularity _ 24):</strong>一天中的某个小时到当地时间日期范围内每小时的访问次数的映射。数组中的第一个元素对应于从午夜到凌晨1点的时间</p><p id="5024" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> Device_type(分解为ios和Android): </strong>使用Android和IOS的POI的访客数量。仅显示至少包含2个设备的设备类型，包含少于5个设备的任何类别都报告为</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/84c09e68e70dbb05a5a016e1c3811e43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5mvZ_koPpaa0KY3ccbquYw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@aldebarans?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">阿鲁迪巴S </a>在<a class="ae kv" href="https://unsplash.com/s/photos/space?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><h1 id="a31b" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">POI记录的深度学习分类</h1><p id="ec16" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">现在数据已经准备好了，我们可以开始深度学习方面了。</p><p id="05c3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Spark MLlib包执行ML函数的方式与用Sci-kit Learn等包编写的传统代码片段略有不同。该软件包要求使用<strong class="ky ir">矢量汇编器</strong>转换器将所有用于预测的特征编译成一列单独的矢量。这要求事先将标注列与要素列分开，这一步预处理的代码如下所示:</p><p id="5bf1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">步骤1:将标签列与特征列分离，并将熊猫DF转换为火花DF </strong></p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="f28b" class="nu lu iq nq b gy nv nw l nx ny">from pyspark.ml.classification import MultilayerPerceptronClassifier</span><span id="8aed" class="nu lu iq nq b gy nz nw l nx ny">from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><span id="95a0" class="nu lu iq nq b gy nz nw l nx ny">label = transportation_df[‘Class’]</span><span id="5258" class="nu lu iq nq b gy nz nw l nx ny">transportation_df = spark.createDataFrame(transportation_df)</span><span id="7e41" class="nu lu iq nq b gy nz nw l nx ny">transportation_df.show(5)</span></pre><p id="d452" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">第二步:使用矢量汇编程序创建特征列</strong></p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="8175" class="nu lu iq nq b gy nv nw l nx ny">from pyspark.ml.feature import VectorAssembler</span><span id="7f9a" class="nu lu iq nq b gy nz nw l nx ny">transportation_df = transportation_df.drop(‘Class’)</span><span id="2f41" class="nu lu iq nq b gy nz nw l nx ny">assembler = VectorAssembler().setInputCols(transportation_df.columns[1:]).setOutputCol(“features”)</span><span id="340c" class="nu lu iq nq b gy nz nw l nx ny">transportation_df = assembler.transform(transportation_df)</span><span id="6822" class="nu lu iq nq b gy nz nw l nx ny">transportation_df.show(10)</span></pre><p id="656e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这样做的最终结果应该是将所有特性都编译到一个列中，如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/f6798be8e2bdd0905732f5a1cc873abf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*idmkHe0hv4v9jpjPUNSk5Q.png"/></div></div></figure><p id="436d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从这里开始，下一步是将这些数据与标签列结合起来。因为不再需要其他列(它们已经被编译到features列中)，所以运行我们的模型只需要features和label列</p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="d0e8" class="nu lu iq nq b gy nv nw l nx ny">transportation_df = transportation_df.toPandas()</span><span id="18c2" class="nu lu iq nq b gy nz nw l nx ny">features = transportation_df[‘features’]</span><span id="1bfc" class="nu lu iq nq b gy nz nw l nx ny">features_df = pd.DataFrame(data = {‘features’: features})</span><span id="3b34" class="nu lu iq nq b gy nz nw l nx ny">features_df = features_df.loc[~features_df.index.duplicated(), :]</span><span id="1e07" class="nu lu iq nq b gy nz nw l nx ny">label_df = pd.DataFrame(data = {‘label’: label})</span><span id="ba92" class="nu lu iq nq b gy nz nw l nx ny">label_df = label_df.loc[~label_df.index.duplicated(), :]</span><span id="987d" class="nu lu iq nq b gy nz nw l nx ny">transportation_df = pd.concat([features_df, label_df], axis= 1).dropna()</span><span id="e921" class="nu lu iq nq b gy nz nw l nx ny">transportation_df.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/de6758705c5cc862a5905b3798ce1428.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dFrok4rBVH1HRV_NOk2tCQ.png"/></div></div></figure><p id="42a2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一步是将数据分成训练和测试数据:</p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="2b77" class="nu lu iq nq b gy nv nw l nx ny">transportation_df = spark.createDataFrame(transportation_df)</span><span id="f669" class="nu lu iq nq b gy nz nw l nx ny">trainSet, testSet = transportation_df.randomSplit([0.8, 0.2])</span></pre><p id="cfe5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在是时候创建分类器模型了。该模型有许多我们需要了解和调整的超参数，以便最大限度地提高模型性能:</p><p id="9df1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> Tol: </strong>该参数指的是收敛容差或权重开始向预测答案收敛的值。该参数的默认值是. 000001。该参数的较小值可能会导致过度拟合，而较大值可能会导致更精确的结果</p><p id="c576" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">种子:</strong>模型随机生成值的随机种子</p><p id="da19" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> Blocksize: </strong>该参数是指模型每次迭代将包含的记录数。该参数的默认值是128。较大的块大小将导致过度拟合，而较小的块大小将以运行时间为代价提供更精确的结果</p><p id="8bcf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">步长:</strong>该参数是指模型的学习速率。该参数的默认值是. 03。较小的步长将以较大的运行时间为代价得到更精确的模型，而较大的步长将导致过拟合</p><p id="c265" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> Layers: </strong>也许是所有超参数中最重要的，这个参数指的是这个模型中将要出现的层数和每层的节点数。第一个图层必须始终是数据中存在的要素的数量，最后一个图层必须始终是可用的输出标注的数量。在这个图层阵列中必须至少有一个隐藏图层。</p><p id="718a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">考虑到这些需求，让我们看看MLPC模型的代码:</p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="b470" class="nu lu iq nq b gy nv nw l nx ny">layers = [44,50,50,3]</span><span id="f5ec" class="nu lu iq nq b gy nz nw l nx ny">mlpc = MultilayerPerceptronClassifier(layers = layers, solver=’gd’, tol=.0000001, stepSize=.00001, blockSize= 30).setLabelCol(“label”).setFeaturesCol(“features”).setSeed(20).setMaxIter(500)</span><span id="5730" class="nu lu iq nq b gy nz nw l nx ny">model = mlpc.fit(trainSet)</span></pre><p id="d71a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，我们制作了一个具有两个隐藏层的神经网络，每个隐藏层有50个节点。该模型使用梯度下降来训练，并且具有非常高的收敛容限和步长。让我们看看结果:</p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="6f3d" class="nu lu iq nq b gy nv nw l nx ny">result = model.transform(testSet)</span><span id="783a" class="nu lu iq nq b gy nz nw l nx ny">result.show(10)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/3965fc08d7a605555a847c8b29e76d43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hwfH6Pt9_nlqhkPIRMiilg.png"/></div></div></figure><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="c68f" class="nu lu iq nq b gy nv nw l nx ny">from pyspark.ml.evaluation import MulticlassClassificationEvaluator</span><span id="cda2" class="nu lu iq nq b gy nz nw l nx ny">evaluator = MulticlassClassificationEvaluator(labelCol = ‘label’, predictionCol = ‘prediction’, metricName = ‘accuracy’)</span><span id="c08f" class="nu lu iq nq b gy nz nw l nx ny">mlpacc = evaluator.evaluate(result)</span><span id="4268" class="nu lu iq nq b gy nz nw l nx ny">mlpacc</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/b73dcc5eeabc75fcbc468f2251a98c71.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*2mpKeci38I2HGY1glffxrQ.png"/></div></figure><p id="d66d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">整体精度…不令人满意，但这是我们必须用这些数据运行的许多实验中的第一个，以便找到最有效的层数和节点数来提供更好的结果。下表列出了尝试的图层和精度。如果您想尝试这段代码，请不要犹豫，查看笔记本并亲自运行它。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/416b7c047eccc2d7cfa8c5a579a8f614.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mx7MzKW8VdUUwPD-3jJhNw.png"/></div></div></figure><p id="9aae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这项实验的直接收获是:</p><ol class=""><li id="5435" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">更多的隐藏层不一定意味着更好的准确性</li><li id="9455" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">更深的隐藏层不一定意味着更好的准确性</li></ol><p id="28c7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从上表中我们可以看出，当模型保持简单而不是复杂时，它的性能最好。尽管如此，我们看到这个特定数据集的准确性仅仅超过了来自系列第一部分<a class="ae kv" rel="noopener" target="_blank" href="/poi-classification-using-visit-and-popularity-metrics-part-1-ae5e94f92077">的高斯朴素贝叶斯模型。为什么会这样呢？好吧，简单的答案就是数据的不平衡。从</a><a class="ae kv" href="http://safegraph.com" rel="noopener ugc nofollow" target="_blank"> SafeGraph </a>中提取该数据时，使用了三个NAICS码来检索数据，输出的数据严重不平衡，机场记录的数量几乎是公交车站记录数量的4倍。这种不平衡已经成为贯穿本系列的一个问题，并对我们根据数据训练的许多模型的结果产生了不利影响。为了纠正这种不平衡，对不同类别的数据进行了随机抽样，但这样做会导致机场和火车站的数据代表性不足，从而仍然损害了模型的准确性。</p><h1 id="fa2a" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">结论</h1><p id="962f" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">不管结果如何，这篇文章通过MLPC模型介绍了Spark深度学习的概念。本文展示了Spark为创建深度学习模型带来的便利，并进一步展示了在真实世界数据集(如SafeGraph模式数据)上使用这样一个复杂模型的优点和缺点。</p><p id="0e5e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本系列的下一篇也是最后一篇文章中，我们将研究集成分类在这种模式数据上的应用，并看到使用多层分类器有助于提供最佳结果。</p><p id="79b2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="ls">提问？</em>T3】</strong></p><p id="8d58" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我邀请你在<a class="ae kv" href="https://www.safegraph.com/academics" rel="noopener ugc nofollow" target="_blank"> SafeGraph社区</a>的<strong class="ky ir"> #safegraphdata </strong>频道问他们，这是一个面向数据爱好者的免费Slack社区。获得支持、共享您的工作或与GIS社区中的其他人联系。通过SafeGraph社区，学者们可以免费访问美国、英国和加拿大700多万家企业的数据。</p></div></div>    
</body>
</html>