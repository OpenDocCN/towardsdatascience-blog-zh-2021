<html>
<head>
<title>Speed up Linear Regression with Matrix Math</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用矩阵数学加速线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/speed-up-linear-regression-with-matrix-math-fe5ff7f2b53b?source=collection_archive---------29-----------------------#2021-11-24">https://towardsdatascience.com/speed-up-linear-regression-with-matrix-math-fe5ff7f2b53b?source=collection_archive---------29-----------------------#2021-11-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0f07" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 Numpy 和线性代数拟合多元回归模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/980b4868412a46e351689386e079cc53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aD7b2Jb6_uy6DepU"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@jan_huber?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">简·侯伯</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="8df5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">线性回归是一个非常流行和有用的模型。它被 Excel 专家和数据科学家等使用——但是我们如何快速拟合大量的回归模型呢？本文介绍了拟合线性回归模型的各种方法，以及如何使用线性代数来加快速度。</p><p id="713b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我将介绍普通最小二乘线性回归的几种不同方法。</p><ol class=""><li id="c6a1" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">使用</strong><a class="ae ky" href="https://www.statsmodels.org/stable/index.html" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">stats models</strong></a><strong class="lb iu">库</strong>拟合一个模型</li><li id="9a55" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">仅使用 Numpy 拟合简单的线性回归</strong></li><li id="54b7" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">使用矩阵公式</strong></li><li id="2a07" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">如何一次通过分组数据拟合多个模型</strong></li><li id="6a2c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">比较循环与矩阵方法的性能</strong></li></ol><h1 id="c33d" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">数据概述</h1><p id="dfb3" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">本文中使用的数据将是生成的样本数据。使用 numpy +引入一些随机噪声，创建了以下数据集，用于演示 OLS 拟合技术。在接下来的几个示例中，这些数据将存储在和变量中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/a5304b9abb86d9516cea4a503df9cf6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/0*MU9zbBaUaeIKx80F.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据概述，按作者分类的图像</p></figure><h1 id="de88" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">OLS 统计模型公司</h1><p id="7a0b" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">拟合线性模型的一个很好的方法是利用<a class="ae ky" href="https://www.statsmodels.org/stable/examples/notebooks/generated/ols.html" rel="noopener ugc nofollow" target="_blank"> statsmodels 库</a>。我们只需传入两个变量，调用 fit 方法，并通过调用<em class="nh"> summary() </em>来检索结果。注意——这些参数也可以使用<em class="nh"> fit.params </em>直接访问。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/096eac513badd7bf2bb46e6d77f56536.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/0*cL2cZINZyW2iYV8W.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Statsmodels OLS 线性回归结果，图片由作者提供</p></figure><p id="b890" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上述结果显示了许多细节，但对于本演练，我们将重点关注系数。在列的<strong class="lb iu"> ceof 下，你会看到 y 截距(标为 const)约为 211.62，我们的 x 回归系数为 101.65。考虑到初始数据集引入的参数和随机性，这非常符合预期。</strong></p><h1 id="ba15" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">简单线性回归的 Numpy 算法解</h1><p id="ebcc" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">如果我们只处理一个回归变量/独立变量(类似于本例)，那么直接求解斜率和截距就相当简单了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/eecbf5f03f65c660b1c143f67847cc35.png" data-original-src="https://miro.medium.com/v2/resize:fit:274/format:webp/0*LUmyjJxXnVQLCoWm.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">简单线性回归-斜率(系数)公式，图片由作者提供</p></figure><p id="5af4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看上面的公式，它是 x 减去它的平均值乘以 y 减去它的平均值，除以 x 计算的平方。第二步，也可以用这个斜率和 x、y 的平均值来求出截距。</p><p id="8d50" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个系数公式很简单，只需几行代码就可以在 numpy 中直接实现。numpy 中的<a class="ae ky" href="https://numpy.org/doc/stable/reference/generated/numpy.dot.html" rel="noopener ugc nofollow" target="_blank">点</a>函数将负责我们的 sumproducts，我们可以调用<em class="nh">。mean() </em>直接在向量上寻找各自的平均值。</p><p id="014b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们使用<a class="ae ky" href="https://numpy.org/doc/stable/reference/generated/numpy.allclose.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> allclose </strong> </a>函数检查 numpy 解决方案的结果是否与 statsmodels 版本完全匹配。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ni nj l"/></div></figure><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="b6e1" class="nr mk it nn b gy ns nt l nu nv">Output:<br/>Simple linear regression arithmetic slope of 101.65 vs. statsmodels ols fit slope of 101.65. </span><span id="588f" class="nr mk it nn b gy nw nt l nu nv">Results equal: True</span></pre><h1 id="759b" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">矩阵公式</h1><p id="5c9f" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">矩阵公式进一步扩展了 OLS 线性回归——允许我们直接从 X 和 y 得出截距和斜率，即使是多个回归变量。这个公式如下，详细的推导过程请看经济理论博客的这篇文章。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/7cc26428c02a043ccc1a5a361b049d4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:350/format:webp/0*lmWODhn8qvrDalIY.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">OLS 矩阵公式，图片作者</p></figure><p id="8a11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面的 numpy 代码非常直接地反映了这个公式。这里也可以使用点积，但是使用 matmul 是因为当扩展到三维时，它更适合我们的下一个场景(一次拟合多个模型)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="fa3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在使用新数据集进行下一步之前，快速检查每种方法会发现相同的截距和斜率——对于简单线性回归用例，这是实现相同目标的三种不同方式。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/9354dc8ef4a3471c64adcbf63c3cf90f.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/0*hhLadGpfc24uCOJo.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">OLS 结果三种方式，由作者形象</p></figure><h1 id="daa4" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">一次多重回归</h1><h2 id="2c4d" class="nr mk it bd ml nz oa dn mp ob oc dp mt li od oe mv lm of og mx lq oh oi mz oj bi translated">用例示例</h2><p id="bcb2" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">继续我们的下一个用例，如果你想一次运行多个回归怎么办？假设您有一个包含各种商店的零售数据集，并且您希望对每个商店独立运行 ols 回归，这可能是为了比较系数或获得更细粒度的线性模型拟合。</p><p id="68ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个使用案例示例—一家电子商务商店可能希望按产品对每月销售数据进行多次 ols 线性回归。他们希望独立地拟合线性模型，以便通过观察各种模型的系数来获得方向性和趋势的粗略感觉。</p><h2 id="fdfc" class="nr mk it bd ml nz oa dn mp ob oc dp mt li od oe mv lm of og mx lq oh oi mz oj bi translated">数据形状和多重矩阵公式</h2><p id="b2a7" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">为了进行演示，创建了一个包含 2 组 50 个数据点的数据集。两者都有 2 个回归变量/独立变量，但我们想分别拟合两个分组的线性模型。</p><p id="b6b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据的形状为—代表 2 个分组，每个分组有 50 个数据点，每个分组有 2 个自变量(+截距)。我们的 Y 变量现在是——2 个分组，50 个数据点。</p><p id="7eb9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们试图将它插入到我们的 statsmodels ols 函数中，我们将得到一个错误。然而，我们可以扩展我们的矩阵公式，在一次通过中找到每个模型的截距/斜率。让我们从数学上定义我们试图实现的目标:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/81fff4cbe1d883cbd6585d3c89bdd700.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/0*AA1kbiP28UxGNkyb.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">多组矩阵公式，作者图片</p></figure><p id="fa0f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于由<strong class="lb iu"> k </strong>表示的每个数据回归分组的<strong class="lb iu"> n 个回归</strong>(本例中为 2)，我们想要运行我们在上一节中执行的 ols 线性回归的矩阵版本。你会看到这是与前一节相同的公式，我们只是介绍执行多次迭代(<strong class="lb iu"> k </strong> = 1 到<strong class="lb iu"> n </strong>)，每个分组一组矩阵乘法。</p><h2 id="9674" class="nr mk it bd ml nz oa dn mp ob oc dp mt li od oe mv lm of og mx lq oh oi mz oj bi translated">Numpy 移调调整</h2><p id="1d7f" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">在 numpy 中实现这一点需要一些简单的修改。如果我们只是将我们的<strong class="lb iu"> X </strong>和<strong class="lb iu"> y </strong>变量直接插入到之前的公式中，维度不会按照我们想要的方式排列。发生这种情况的原因是使用了相同的转置函数(<strong class="lb iu">)。T </strong> in numpy)会把我们的形状从变成。不完全是我们想要的…</p><p id="e37b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">numpy matmul 文档规定，如果有两个以上的维度通过任一参数传入，则运算将被视为驻留在最后两个索引中的矩阵堆栈。这是我们正在寻找的行为，所以第一维应该保持为 2(堆叠我们的分组)，我们只是想转置 50 和 3。</p><p id="15ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用<a class="ae ky" href="https://numpy.org/doc/stable/reference/generated/numpy.transpose.html" rel="noopener ugc nofollow" target="_blank">转置功能</a>并指定如何准确转置我们的轴以获得正确的形状。传入轴将得到想要的形状——将最后一个交换到轴，但保持我们的<strong class="lb iu"> n </strong>回归维度不变，直到<em class="nh">堆栈</em>结束。</p><p id="ac27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于下面的代码示例，X 现在将被称为 X_many，类似地，y 也被称为 X _ many，以便与前面的示例相区别。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ni nj l"/></div></figure><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="558d" class="nr mk it nn b gy ns nt l nu nv">Output: (2, 3, 50)</span></pre><h2 id="2c50" class="nr mk it bd ml nz oa dn mp ob oc dp mt li od oe mv lm of og mx lq oh oi mz oj bi translated">修订的数字操作</h2><p id="4377" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">记住这个转置知识，是时候做出改变来解决这个分组版本了。为了可读性，numpy 代码被分成两行。Transpose 被修改为沿正确的尺寸工作，一个额外的空轴被添加到<strong class="lb iu"> y_many </strong>只是为了排列 matmul 操作。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ni nj l"/></div></figure><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="4eb7" class="nr mk it nn b gy ns nt l nu nv">Output:<br/>array([[209.9240413375,  95.3254823487,  61.4157238175],<br/>       [514.164936664 ,   8.1355322839,   4.3353162671]])</span></pre><p id="83d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们得到一个数组，其中包含每个独立变量的截距和系数。使用 statsmodels 执行类似的(但循环的)操作，并使用<strong class="lb iu"> numpy.allclose </strong>进行检查，发现系数是相同的。</p><p id="1cc3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们能够一次拟合许多回归。在我们希望拟合一组线性模型的情况下，这种方法会很有帮助，这些模型是按一个特定的维度分组和划分的，并且是独立求解的。</p><h2 id="9e80" class="nr mk it bd ml nz oa dn mp ob oc dp mt li od oe mv lm of og mx lq oh oi mz oj bi translated">Einsum 符号</h2><p id="f9ec" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们也可以用 numpy 中的<a class="ae ky" href="https://numpy.org/doc/stable/reference/generated/numpy.einsum.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> einsum </strong> </a>函数来解决这个问题。这使用爱因斯坦求和约定来指定如何执行操作。在高层次上，我们将每个矩阵的下标定义为一个字符串——如果指定转置的顺序被交换，并且乘法发生在共同的字母上。要了解更多信息，请查看 numpy 文档，因为它们提供了一些示例。</p><p id="17b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了可读性，einsum 版本被分成了几个步骤。在符号串中，我们指定了转置以及要执行的矩阵乘法。这也允许我们通过指定输出维度来处理<strong class="lb iu"> np.newaxis </strong>段代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ni nj l"/></div></figure><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="2805" class="nr mk it nn b gy ns nt l nu nv">Output:<br/>[[209.9240413375  95.3254823487  61.4157238175]<br/> [514.164936664    8.1355322839   4.3353162671]]</span></pre><p id="17d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这给了我们与前一版本相同的结果，虽然性能可能稍慢。如果您熟悉 einsum 符号，这可能是一个有用的实现。</p><h1 id="9268" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">速度比较</h1><h2 id="5641" class="nr mk it bd ml nz oa dn mp ob oc dp mt li od oe mv lm of og mx lq oh oi mz oj bi translated">分组依据/应用模式</h2><p id="0b47" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我见过的一种一次性实现多重回归的方法是使用 pandas 数据框架和 groupby/apply 方法。在这种方法中，我们定义一个函数，pandas 会将数据集分成几个组，并应用该函数—根据需要返回和减少结果。</p><p id="2a6a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是我们“分组回归”中的用例。将我们的 numpy 数组切换到一个 dataframe 中，通过一个<strong class="lb iu"> regression_number </strong>列进行分组，并应用一个定制的 ols 函数来拟合和返回结果，这将提供相同的系数(尽管 pandas 显示了一些小数点)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ni nj l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/42554b099ce47081ee6b7b88d36a4c94.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/0*v9MGPri6F6jqcxWt.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按作者分组/应用回归结果、图像</p></figure><h2 id="87e5" class="nr mk it bd ml nz oa dn mp ob oc dp mt li od oe mv lm of og mx lq oh oi mz oj bi translated">比较性能</h2><p id="c408" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">现在，我们有两种不同的方法在多个分组中执行 OLS，它们的表现如何呢？</p><p id="c674" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于这个测试，我们将扩展到 100 个分组和 3 个回归变量——( 100，50，4)的形状，而不是 50 个点和 2 个回归变量的 2 个分组，作为一个更现实的场景。</p><p id="ed1e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用<em class="nh"> %%timeit </em>魔术命令在我们的笔记本中运行<a class="ae ky" href="https://docs.python.org/3/library/timeit.html" rel="noopener ugc nofollow" target="_blank"> timeit </a>测试显示，pandas groupby/apply 方法需要 120 毫秒，而 numpy matrix 版本只需要 0.151 毫秒。<strong class="lb iu"> <em class="nh">矩阵乘法几乎快了 800 倍！</em>T15】</strong></p><p id="ee48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当然，我确信有方法可以优化 pandas 的实现，但是 matrix 版本的好处是直接在 numpy 中的几行代码已经很快了。</p><h1 id="4c96" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">摘要</h1><p id="6f15" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">理解机器学习的某些基本方法背后的数学可以让你在需要的地方定制和扩展方法。许多开源库速度很快，经过良好的测试，并且经常做您需要它们做的事情。</p><p id="3f72" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，可能存在这样的一次性情况，即使用 numpy 实现简单但易于理解的方法(如线性回归)可以在不增加太多复杂性的情况下产生更好的性能。</p><p id="25f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nh">所有的例子和文件都可以在</em> <a class="ae ky" href="https://github.com/bstuddard/python-examples/tree/master/vectorized_linear_regression/demo.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="nh"> Github </em> </a> <em class="nh">上找到。</em></p></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><p id="18bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nh">原发布于</em><a class="ae ky" href="https://datastud.dev/posts/ols" rel="noopener ugc nofollow" target="_blank"><em class="nh">https://data stud . dev</em></a><em class="nh">。</em></p></div></div>    
</body>
</html>