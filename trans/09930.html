<html>
<head>
<title>Dimensionality Reduction for Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的降维</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dimensionality-reduction-for-machine-learning-ef20d8a108d?source=collection_archive---------23-----------------------#2021-09-18">https://towardsdatascience.com/dimensionality-reduction-for-machine-learning-ef20d8a108d?source=collection_archive---------23-----------------------#2021-09-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/7ff60aad470fc2dddfc11cf32090af46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*A8aOCDcwIAYor2l9"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://unsplash.com/@siora18?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Siora摄影</a>在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h2 id="0a6d" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><div class=""><h2 id="9eb8" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">Python中特征约简和选择的初学者指南</h2></div><p id="96a9" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">什么是高维数据？它如何影响你的机器学习模型？你有没有想过为什么你的模型不符合你的期望，你已经尝试超调参数，直到地球的尽头，没有改善？理解您的数据和模型可能是关键。在这样一个巨大而复杂的罩下，您可能会担心很少有甚至没有方法来获得对您的数据以及您的模型的更多洞察。虽然这看起来令人生畏，但最重要的是，您使用成功的、经过验证的方法来理解正在发生的事情，以使您的模型按照它的方式运行。这将焦点放在降维、预处理和特征工程上。</p><p id="5bb7" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在我开始调试一个模型或者对它进行超调优化之前，我总是处理我的数据。我发现理解我的数据并以一种使我的模型具有最佳性能的方式处理它将最终决定我的模型参数，甚至在某些情况下决定我的整个模型。虽然预处理和特征工程是它们自己的主题，但我将在本文中讨论降维和选择。</p><p id="de60" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在整篇文章中，我将使用sklearn库，因此拥有sklearn经验将是一个优势，但不是必需的。此外，对Python编程语言以及基本的数据科学/机器学习知识有相当好的理解是理解本文的先决条件。如果你还不知道这两个网站，你可以在我下面的主页上了解它们。我还将提到我为本文创建的Kaggle笔记本，它可以在下面列出的链接中找到。</p><div class="is it gp gr iu md"><a href="https://scikit-learn.org/" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jt gy z fp mi fr fs mj fu fw js bi translated">sci kit-学习</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">“我们使用scikit-learn来支持前沿基础研究[...]" "我认为这是我设计过的最棒的ML套装…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">scikit-learn.org</p></div></div><div class="mm l"><div class="mn l mo mp mq mm mr ja md"/></div></div></a></div><div class="is it gp gr iu md"><a href="https://medium.com/@third_eye_cyborg" rel="noopener follow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jt gy z fp mi fr fs mj fu fw js bi translated">丹·鲁特-中等</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">Anaconda是科学Python包、工具、资源和ide的惊人集合。该包装包括许多…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">medium.com</p></div></div><div class="mm l"><div class="ms l mo mp mq mm mr ja md"/></div></div></a></div><div class="is it gp gr iu md"><a href="https://www.kaggle.com/thirdeyecyborg/house-price-rfe-pca" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jt gy z fp mi fr fs mj fu fw js bi translated">房价RFE和PCA</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">使用Kaggle笔记本探索和运行机器学习代码|使用房价数据-高级回归…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">www.kaggle.com</p></div></div></div></a></div><p id="8cac" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">数据集引用:</strong></p><p id="b3e0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Dean De Cock (2011)爱荷华州埃姆斯:波士顿住房数据作为期末回归项目的替代方案，统计教育杂志，19:3，DOI:<a class="ae jg" href="https://doi.org/10.1080/10691898.2011.11889627" rel="noopener ugc nofollow" target="_blank">10.1080/10691898 . 11</a></p><h2 id="69ad" class="mt mu jj bd mv mw mx dn my mz na dp nb lq nc nd ne lu nf ng nh ly ni nj nk jp bi translated">那么，什么是高维数据呢？</h2><figure class="nm nn no np gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nl"><img src="../Images/09d21ab68967d6975731200b5316e590.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pfb0K0XtVBE-aRYW"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">由<a class="ae jg" href="https://unsplash.com/@joelfilip?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">乔尔·菲利普</a>在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="3d1d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">简而言之，高维数据是带有许多特征的数据。如果数据有十个以上的特征，通常被认为是高维的。这些数据集有时会降低您的模型性能，并耗费您宝贵的计算/内存资源。对整个模型没有任何价值的特征也会增加噪音，使模型更难以最佳方式运行。为了解决这个问题，人们开发了许多工具来帮助解决这个问题。其中一些工具我将简单介绍一下。我们将使用RFE(递归特征消除)模型删除特征行，并在Kaggle数据集上使用PCA(主成分分析)模型选择关键特征，以提供一些常用工具的清晰度，帮助降低数据维数，同时保持模型的性能和准确性。我将在XGBoost回归模型上进行这项工作，但是也可以随意使用这些工作流来减少其他模型类型上的数据维数。之后，我会将我们的模型提交给<a class="ae jg" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jt"> <em class="nq"> Kaggle竞争房价——高级回归技术。</em> </strong> </a></p><div class="is it gp gr iu md"><a href="https://xgboost.readthedocs.io/en/latest/index.html#" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jt gy z fp mi fr fs mj fu fw js bi translated">XGBoost文档-XGBoost 1 . 5 . 0-开发文档</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">XGBoost是一个优化的分布式梯度增强库，旨在高效、灵活和可移植…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">xgboost.readthedocs.io</p></div></div></div></a></div><p id="4897" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">理解特征约简(RFE)和特征选择(PCA)不同于特征提取是非常重要的。特征提取试图从现有特征中创建新的有意义的特征，而特征缩减试图通过丢弃对整体模型精度或性能不重要的特征数据的列或行来减少特征的数量。而特征选择试图找到属于数据的最关键特征，当涉及目标变量预测时，该数据解释了模型的大部分准确性或性能。找到这些较少的关键特征听起来可能很容易，但可能相当复杂。第一种可进行的要素缩减是通过任意丢弃您认为对模型整体精度不重要的要素来缩减要素。当某个要素的值很明显时，这种要素约简方法会很有用，但在更复杂的数据集上就没那么有用了。</p><p id="ac64" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我将利用这个笔记本的<a class="ae jg" href="https://www.kaggle.com/billyfeng/house-price-test" rel="noopener ugc nofollow" target="_blank">副本，首先添加RFE，然后添加PCA来观察和分析结果，然后将它们与不运行的结果进行比较。在本教程中，我将主要关注RFE &amp; PCA模型的架构、差异和结果。如果你想更好地理解数据集和数据的格式化/处理，请浏览我附带的Kaggle笔记本。</a></p><h2 id="8f38" class="mt mu jj bd mv mw mx dn my mz na dp nb lq nc nd ne lu nf ng nh ly ni nj nk jp bi translated">原始模型</h2><p id="83cc" class="pw-post-body-paragraph lh li jj lj b lk nr kt lm ln ns kw lp lq nt ls lt lu nu lw lx ly nv ma mb mc im bi translated"><code class="fe nw nx ny nz b">xgb = XGBRegressor(objective=’reg:squarederror’)</code></p><p id="0651" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">原模型输出:</strong></p><pre class="nm nn no np gt oa nz ob oc aw od bi"><span id="571a" class="mt mu jj nz b gy oe of l og oh">output:<br/>17662.736729452055</span></pre><h1 id="d34e" class="oi mu jj bd mv oj ok ol my om on oo nb ky op kz ne lb oq lc nh le or lf nk os bi translated">递归特征消除</h1><div class="is it gp gr iu md"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jt gy z fp mi fr fs mj fu fw js bi translated">sklearn.feature_selection。RFE-sci kit-学习0.24.2文档</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">递归特征消除的特征排序。给定一个为特征分配权重的外部估计器(例如…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">scikit-learn.org</p></div></div><div class="mm l"><div class="ot l mo mp mq mm mr ja md"/></div></div></a></div><p id="0229" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">顾名思义，RFE模型本质上是递归的。他们试图通过用所有原始特征训练一个估计器，然后用较少的特征重新训练来减少特征。它重复这个过程，直到找到最佳数量的特征。这种类型的特征约简很受欢迎，因为它实现起来非常简单和有效。RFE模型的应用可以远远超出本教程所涵盖的内容，因为这只是一个初学者的基本例子。</p><p id="14db" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">RFE模型采用估计量(又名。模型)作为第一个参数自变量。然后将特征的数量减少到。在示例代码中，我选择将特性从36个减少到30个。可以通过<code class="fe nw nx ny nz b">.ranking_</code>属性得到排名。您也可以通过<code class="fe nw nx ny nz b">.support_</code>获得选择的列。由于RFE模型的递归性质，它们通常有运行较慢的趋势。</p><figure class="nm nn no np gt iv"><div class="bz fp l di"><div class="ou ov l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者的RFE模型</p></figure><pre class="nm nn no np gt oa nz ob oc aw od bi"><span id="490e" class="mt mu jj nz b gy oe of l og oh">output: <br/>{'MSSubClass': 100, 'LotFrontage': 42, 'LotArea': 4, 'OverallQual': 1, 'OverallCond': 1, 'YearBuilt': 2, 'YearRemodAdd': 1, 'MasVnrArea': 6, 'BsmtFinSF1': 1, 'BsmtFinSF2': 12, 'BsmtUnfSF': 18, 'TotalBsmtSF': 1, '1stFlrSF': 11, '2ndFlrSF': 1, 'LowQualFinSF': 60, 'GrLivArea': 1, 'BsmtFullBath': 24, 'BsmtHalfBath': 79, 'FullBath': 54, 'HalfBath': 51, 'BedroomAbvGr': 23, 'KitchenAbvGr': 1, 'TotRmsAbvGrd': 47, 'Fireplaces': 1, 'GarageYrBlt': 5, 'GarageCars': 1, 'GarageArea': 1, 'WoodDeckSF': 43, 'OpenPorchSF': 52, 'EnclosedPorch': 21, '3SsnPorch': 57, 'ScreenPorch': 8, 'PoolArea': 1, 'MiscVal': 90, 'MoSold': 39, 'YrSold': 78, 'MSZoning_C (all)': 1, 'MSZoning_FV': 3, 'MSZoning_RH': 96, 'MSZoning_RL': 110, 'MSZoning_RM': 1, 'Street_Grvl': 146, 'Street_Pave': 147, 'Alley_Grvl': 9, 'Alley_Pave': 89, 'LotShape_IR1': 74, 'LotShape_IR2': 82, 'LotShape_IR3': 91, 'LotShape_Reg': 1, 'LandContour_Bnk': 1, 'LandContour_HLS': 62, 'LandContour_Low': 121, 'LandContour_Lvl': 64, 'Utilities_AllPub': 158, 'Utilities_NoSeWa': 164, 'LotConfig_Corner': 33, 'LotConfig_CulDSac': 50, 'LotConfig_FR2': 27, 'LotConfig_FR3': 190, 'LotConfig_Inside': 86, 'LandSlope_Gtl': 45, 'LandSlope_Mod': 56, 'LandSlope_Sev': 166, 'Condition1_Artery': 1, 'Condition1_Feedr': 113, 'Condition1_Norm': 13, 'Condition1_PosA': 126, 'Condition1_PosN': 1, 'Condition1_RRAe': 30, 'Condition1_RRAn': 16, 'Condition1_RRNe': 118, 'Condition1_RRNn': 191, 'Condition2_Artery': 193, 'Condition2_Feedr': 196, 'Condition2_Norm': 195, 'Condition2_PosA': 182, 'Condition2_PosN': 162, 'Condition2_RRAe': 172, 'BldgType_1Fam': 177, 'BldgType_2fmCon': 178, 'BldgType_Duplex': 116, 'BldgType_Twnhs': 114, 'BldgType_TwnhsE': 88, 'HouseStyle_1.5Fin': 97, 'HouseStyle_1.5Unf': 122, 'HouseStyle_1Story': 66, 'HouseStyle_2.5Fin': 155, 'HouseStyle_2.5Unf': 168, 'HouseStyle_2Story': 125, 'HouseStyle_SFoyer': 123, 'HouseStyle_SLvl': 46, 'RoofStyle_Flat': 37, 'RoofStyle_Gable': 36, 'RoofStyle_Gambrel': 159, 'RoofStyle_Hip': 140, 'RoofStyle_Mansard': 134, 'RoofStyle_Shed': 169, 'RoofMatl_CompShg': 138, 'RoofMatl_Membran': 141, 'RoofMatl_Metal': 173, 'RoofMatl_Roll': 136, 'RoofMatl_Tar&amp;Grv': 115, 'RoofMatl_WdShake': 143, 'RoofMatl_WdShngl': 14, 'MasVnrType_BrkCmn': 148, 'MasVnrType_BrkFace': 80, 'MasVnrType_None': 152, 'MasVnrType_Stone': 68, 'ExterQual_Ex': 93, 'ExterQual_Fa': 179, 'ExterQual_Gd': 104, 'ExterQual_TA': 71, 'ExterCond_Ex': 197, 'ExterCond_Fa': 7, 'ExterCond_Gd': 32, 'ExterCond_Po': 176, 'ExterCond_TA': 26, 'Foundation_BrkTil': 69, 'Foundation_CBlock': 94, 'Foundation_PConc': 98, 'Foundation_Slab': 153, 'Foundation_Stone': 132, 'Foundation_Wood': 192, 'BsmtQual_Ex': 1, 'BsmtQual_Fa': 73, 'BsmtQual_Gd': 15, 'BsmtQual_TA': 150, 'BsmtCond_Fa': 76, 'BsmtCond_Gd': 112, 'BsmtCond_Po': 175, 'BsmtCond_TA': 106, 'BsmtExposure_Av': 84, 'BsmtExposure_Gd': 1, 'BsmtExposure_Mn': 61, 'BsmtExposure_No': 1, 'BsmtFinType1_ALQ': 63, 'BsmtFinType1_BLQ': 101, 'BsmtFinType1_GLQ': 1, 'BsmtFinType1_LwQ': 95, 'BsmtFinType1_Rec': 83, 'BsmtFinType1_Unf': 174, 'BsmtFinType2_ALQ': 77, 'BsmtFinType2_BLQ': 99, 'BsmtFinType2_GLQ': 185, 'BsmtFinType2_LwQ': 120, 'BsmtFinType2_Rec': 187, 'BsmtFinType2_Unf': 171, 'Heating_Floor': 183, 'Heating_GasA': 181, 'Heating_GasW': 188, 'Heating_Grav': 194, 'Heating_OthW': 17, 'Heating_Wall': 189, 'HeatingQC_Ex': 34, 'HeatingQC_Fa': 102, 'HeatingQC_Gd': 72, 'HeatingQC_Po': 180, 'HeatingQC_TA': 105, 'CentralAir_N': 1, 'CentralAir_Y': 161, 'Electrical_FuseA': 87, 'Electrical_FuseF': 20, 'Electrical_FuseP': 157, 'Electrical_Mix': 170, 'Electrical_SBrkr': 108, 'KitchenQual_Ex': 1, 'KitchenQual_Fa': 1, 'KitchenQual_Gd': 38, 'KitchenQual_TA': 10, 'Functional_Maj1': 186, 'Functional_Maj2': 184, 'Functional_Min1': 1, 'Functional_Min2': 25, 'Functional_Mod': 107, 'Functional_Typ': 19, 'FireplaceQu_Ex': 167, 'FireplaceQu_Fa': 35, 'FireplaceQu_Gd': 44, 'FireplaceQu_Po': 165, 'FireplaceQu_TA': 92, 'GarageType_2Types': 124, 'GarageType_Attchd': 1, 'GarageType_Basment': 156, 'GarageType_BuiltIn': 85, 'GarageType_CarPort': 154, 'GarageType_Detchd': 48, 'GarageFinish_Fin': 55, 'GarageFinish_RFn': 53, 'GarageFinish_Unf': 75, 'GarageQual_Ex': 135, 'GarageQual_Fa': 70, 'GarageQual_Gd': 40, 'GarageQual_Po': 133, 'GarageQual_TA': 1, 'GarageCond_Ex': 163, 'GarageCond_Fa': 28, 'GarageCond_Gd': 160, 'GarageCond_Po': 151, 'GarageCond_TA': 109, 'PavedDrive_N': 22, 'PavedDrive_P': 149, 'PavedDrive_Y': 41, 'PoolQC_Ex': 145, 'PoolQC_Fa': 139, 'PoolQC_Gd': 119, 'Fence_GdPrv': 29, 'Fence_GdWo': 59, 'Fence_MnPrv': 67, 'Fence_MnWw': 65, 'MiscFeature_Gar2': 144, 'MiscFeature_Othr': 131, 'MiscFeature_Shed': 130, 'SaleType_COD': 49, 'SaleType_CWD': 142, 'SaleType_Con': 127, 'SaleType_ConLD': 128, 'SaleType_ConLI': 103, 'SaleType_ConLw': 58, 'SaleType_New': 1, 'SaleType_Oth': 129, 'SaleType_WD': 111, 'SaleCondition_Abnorml': 1, 'SaleCondition_AdjLand': 117, 'SaleCondition_Alloca': 137, 'SaleCondition_Family': 81, 'SaleCondition_Normal': 31, 'SaleCondition_Partial': 198}</span><span id="ed94" class="mt mu jj nz b gy ow of l og oh">output:<br/>16787.60477311644</span></pre><p id="0467" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">产量大，比原来的型号好，功能少！</p><h1 id="7a7e" class="oi mu jj bd mv oj ok ol my om on oo nb ky op kz ne lb oq lc nh le or lf nk os bi translated">主成分分析</h1><div class="is it gp gr iu md"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fo"><div class="mf ab mg cl cj mh"><h2 class="bd jt gy z fp mi fr fs mj fu fw js bi translated">sk learn . decomposition . PCA-sci kit-learn 0 . 24 . 2文档</h2><div class="mk l"><h3 class="bd b gy z fp mi fr fs mj fu fw dk translated">主成分分析。使用数据的奇异值分解进行线性降维…</h3></div><div class="ml l"><p class="bd b dl z fp mi fr fs mj fu fw dk translated">scikit-learn.org</p></div></div><div class="mm l"><div class="ox l mo mp mq mm mr ja md"/></div></div></a></div><p id="5d31" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">PCA模型试图选择最佳的关键特征。首先创建一个模型，然后用它进行拟合和预测。请注意申请是多么简单。此外，PCA模型被认为速度更快。同样，存在更复杂的PCA架构，应予以考虑。我总是建议好好阅读这些文件。</p><figure class="nm nn no np gt iv"><div class="bz fp l di"><div class="ou ov l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者的五氯苯甲醚模型</p></figure><pre class="nm nn no np gt oa nz ob oc aw od bi"><span id="4c58" class="mt mu jj nz b gy oe of l og oh">output:<br/>18985.349823416094</span></pre><p id="5646" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">不是很好的输出，但很接近，我们的数据噪音较小。让我们看看现在是否可以用减少的数据获得更好的MAE评分。</p><p id="67f4" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">让我们加快速度</strong></p><figure class="nm nn no np gt iv"><div class="bz fp l di"><div class="ou ov l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者提出的更好的PCA模型</p></figure><pre class="nm nn no np gt oa nz ob oc aw od bi"><span id="b19b" class="mt mu jj nz b gy oe of l og oh">output:<br/>17447.526995933218</span></pre><p id="0fa0" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">很好！该模型比具有较少特征的原始数据集获得了更好的结果！</p><h2 id="a20b" class="mt mu jj bd mv mw mx dn my mz na dp nb lq nc nd ne lu nf ng nh ly ni nj nk jp bi translated">臣服于Kaggle</h2><p id="ef7b" class="pw-post-body-paragraph lh li jj lj b lk nr kt lm ln ns kw lp lq nt ls lt lu nu lw lx ly nv ma mb mc im bi translated">虽然这不一定会是一个好成绩，但它将演示如何在Kaggle竞争数据集上进行降维。我将提交RFE模型的结果，因为它产生最低的平均绝对误差。</p><figure class="nm nn no np gt iv"><div class="bz fp l di"><div class="ou ov l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者提交的Kaggle文件</p></figure><figure class="nm nn no np gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/66a80cfc39a04836ba832f42d1599305.png" data-original-src="https://miro.medium.com/v2/resize:fit:328/format:webp/1*NKV0il8Cbq_qfd8KHBm3Lg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">按作者输出</p></figure><p id="ea83" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jt">得分</strong></p><p id="212d" class="pw-post-body-paragraph lh li jj lj b lk ll kt lm ln lo kw lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">总的竞争分数只有<code class="fe nw nx ny nz b">0.15381</code>，这并不是什么了不起的事情，但是很高兴知道，如果你正在处理高定义的数据，你总是可以将它减少到重要的特征，并剔除其余的。</p><h1 id="10fd" class="oi mu jj bd mv oj ok ol my om on oo nb ky op kz ne lb oq lc nh le or lf nk os bi translated">结论</h1><p id="f0f8" class="pw-post-body-paragraph lh li jj lj b lk nr kt lm ln ns kw lp lq nt ls lt lu nu lw lx ly nv ma mb mc im bi translated">降维的应用远远超出了本文所包含的内容。我推荐阅读关于RFE模型和PCA模型的文档。模型选择、结构、体系结构、参数调整以及对输出进行详细分析，这些都是能够产生比示例中更好结果的方法。此外，如果你看到我犯的任何错误，请随时给我发信息、回复或给我发电子邮件<em class="nq">info@thirdeyecyborg.com</em>，我会尽快改正。感谢您的阅读和快乐编码！</p></div></div>    
</body>
</html>