<html>
<head>
<title>36 Questions to Fall in Love With AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">爱上AI的36个问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/36-questions-to-fall-in-love-with-ai-89037cc040ab?source=collection_archive---------24-----------------------#2021-05-18">https://towardsdatascience.com/36-questions-to-fall-in-love-with-ai-89037cc040ab?source=collection_archive---------24-----------------------#2021-05-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/ee730fc70daa9fe9de1f39633fd6745b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tv8M-Tk3LOaZVNpb"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Amy Shamblen 在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="22c4" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">我问了DialoGPT和BlenderBot“谈恋爱的36个问题”。他们的回答出奇的连贯有趣。</h2></div><p id="0f40" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">基于Transformer的语言模型在生成语法正确的中短文本方面取得了<strong class="la jk">的惊人成果</strong>。然而，一个常见的问题是它们生成的内容没有太多意义。我想测试这些模型在回答问题方面有多好，并从人工智能生成的无意义中获得乐趣。</p><p id="de81" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个项目中使用的问卷——通常名为“<em class="lu"> 36个坠入爱河的问题</em>”——最初是由心理学家<a class="ae jg" href="https://journals.sagepub.com/doi/pdf/10.1177/0146167297234003" rel="noopener ugc nofollow" target="_blank"> Aron等人(1997) </a>开发的，他们调查了<strong class="la jk">个体之间的亲密关系是否可以在实验环境中产生</strong>。这份问卷稍加修改的版本已经在无数的<a class="ae jg" href="https://www.nytimes.com/2015/01/09/style/no-37-big-wedding-or-small.html" rel="noopener ugc nofollow" target="_blank">报纸</a>、<a class="ae jg" href="https://www.readersdigest.co.uk/lifestyle/dating-relationships/36-questions-that-will-make-you-fall-in-love" rel="noopener ugc nofollow" target="_blank">杂志</a>和<a class="ae jg" href="http://36questionsinlove.com/" rel="noopener ugc nofollow" target="_blank">网站</a>上发表，都承诺帮助你与另一个人建立深刻的联系。</p><p id="dbaf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是如果你不是问人类而是问人工智能这些问题呢？ <em class="lu">剧透提醒</em>:你可能不会爱上它。但是，对于生活中最快乐的记忆，它会说些什么呢？或者它认为是完美的一天？本文首先简要概述了两种对话响应生成模型的功能。然后，我们将直接进入人工智能生成的答案，并简要触及有毒内容生成的问题。如果你来这里只是为了好玩，请跳到第四部分。</p><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lv"><img src="../Images/ab62622521b2e6801de8eec50e3be9b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FYZQQlawVOV9hXeFXJnuMA.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Brooke Lark在Unsplash上的照片由Julia Nikulski添加。</p></figure><h1 id="cb06" class="ma mb jj bd mc md me mf mg mh mi mj mk kp ml kq mm ks mn kt mo kv mp kw mq mr bi translated">1.DialoGPT</h1><p id="8606" class="pw-post-body-paragraph ky kz jj la b lb ms kk ld le mt kn lg lh mu lj lk ll mv ln lo lp mw lr ls lt im bi translated"><a class="ae jg" href="https://arxiv.org/pdf/1911.00536.pdf" rel="noopener ugc nofollow" target="_blank"> DialoGPT </a>是微软的一个团队在2020年开发的。这个<strong class="la jk">会话响应生成模型</strong> <strong class="la jk">使用了与</strong> <a class="ae jg" href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk"> GPT-2 </strong> </a>相同的模型架构，即一个基于<a class="ae jg" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">变压器的结构</a>具有多头自关注。使用语言建模目标训练模型<strong class="la jk">，其中预测了序列中的下一个标记。它使用2005年至2017年间的<a class="ae jg" href="https://www.reddit.com/" rel="noopener ugc nofollow" target="_blank"> Reddit </a>讨论作为训练数据。可能包含有毒语言的子编辑以及所有包含某些有毒词语的讨论都被删除。</strong></p><p id="ef64" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由于语言模型在生成文本时往往缺乏明确性，因此<strong class="la jk"> DialoGPT的创建者集成了一个互信息最大化评分功能</strong>。这确保了模型选择最有可能与特定输入提示(例如，询问的问题)相关的一系列生成的文本。如果您有兴趣了解更多信息，请参考<a class="ae jg" href="https://arxiv.org/pdf/1911.00536.pdf" rel="noopener ugc nofollow" target="_blank">介绍该型号的学术论文</a>。</p><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lv"><img src="../Images/a8edc023fcce2c3b43e39262406c038d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bOqd0aie4pPWBNX6UfirJA.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://unsplash.com/@icons8?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Icons8团队</a>在<a class="ae jg" href="https://unsplash.com/s/photos/pastel?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄，文字由Julia Nikulski添加。</p></figure><h1 id="b084" class="ma mb jj bd mc md me mf mg mh mi mj mk kp ml kq mm ks mn kt mo kv mp kw mq mr bi translated">2.搅拌机机器人</h1><p id="6605" class="pw-post-body-paragraph ky kz jj la b lb ms kk ld le mt kn lg lh mu lj lk ll mv ln lo lp mw lr ls lt im bi translated">脸书的一个团队在2020年创造了开放域聊天机器人。它被特别训练来增强它的参与性、知识性、同理心和个性，使它成为一个令人向往的健谈者。该模型还利用了变压器架构。</p><p id="2464" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">BlenderBot在Reddit对话上进行了预训练，类似于DialoGPT。然而，<strong class="la jk">它随后在四个不同的数据集和任务上进行微调</strong> : CovAI2创造一个迷人的个性；共情对话，学习共情；显示专家知识的维基百科向导；混合技能谈话将前面的三个特征混合成一个人物角色。</p><p id="5f56" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这些更小、更精确的数据集上对模型进行微调<strong class="la jk">也有助于缓解涉及有毒语言的问题</strong>。研究人员开发最终模型的实验——包括他们测试的不同模型架构和解码方法——相当复杂，无法在这篇简短的文章中全面总结。关于这个模型的更多细节，请看<a class="ae jg" href="https://arxiv.org/pdf/2004.13637.pdf" rel="noopener ugc nofollow" target="_blank">介绍它的文章</a>。</p><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mx"><img src="../Images/d1084e05844453d739c867fc7bd2c75c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Oe8N-XTix-s0dtKqYp2mg.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://unsplash.com/@nordwood?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> NordWood Themes </a>在<a class="ae jg" href="https://unsplash.com/s/photos/glasses-simple?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄，文字由Julia Nikulski添加。</p></figure><h1 id="5fda" class="ma mb jj bd mc md me mf mg mh mi mj mk kp ml kq mm ks mn kt mo kv mp kw mq mr bi translated">3.我是如何实现这些推理模型的</h1><p id="fdf7" class="pw-post-body-paragraph ky kz jj la b lb ms kk ld le mt kn lg lh mu lj lk ll mv ln lo lp mw lr ls lt im bi translated">以上两个模型可以使用<strong class="la jk"/><a class="ae jg" href="https://huggingface.co/transformers/" rel="noopener ugc nofollow" target="_blank"><strong class="la jk">变形金刚库</strong> </a> <strong class="la jk">通过</strong> <a class="ae jg" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk">抱紧脸</strong> </a> <strong class="la jk">进行推理。其他预先训练的会话响应生成模型存在于变形金刚库之外，例如谷歌的Meena。然而，我想要一个简单的接入点来实现这个有趣的项目。因此，我选择了DialoGPT和BlenderBot，因为它们与transformers库兼容。</strong></p><p id="a7e0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我通过 <a class="ae jg" href="https://huggingface.co/transformers/main_classes/pipelines.html#transformers.ConversationalPipeline" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk">变形金刚对话管道</strong> </a>将问题传递给<a class="ae jg" href="https://huggingface.co/transformers/model_doc/dialogpt.html" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk"> DialoGPT </strong> </a> <strong class="la jk">模型。我使用<a class="ae jg" href="https://huggingface.co/transformers/model_doc/blenderbot.html#blenderbotmodel" rel="noopener ugc nofollow" target="_blank">模型和transformers </a>的tokenizer对象为<a class="ae jg" href="https://huggingface.co/transformers/model_doc/blenderbot.html" rel="noopener ugc nofollow" target="_blank"> BlenderBot </a>实现了推理，因为这个模型目前不被管道支持。你可以在我的<a class="ae jg" href="https://github.com/julianikulski/ai-36-questions" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到用来生成以下答案的代码。</strong></p><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi my"><img src="../Images/7db60f5f824fa9017f44cac7fe8f2ed7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XMIKiNHaZAIE9H0Vr2BCwg.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">斯科特·韦伯在<a class="ae jg" href="https://unsplash.com/s/photos/simple?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片，文字由朱莉娅·尼库尔斯基添加。</p></figure><h1 id="9158" class="ma mb jj bd mc md me mf mg mh mi mj mk kp ml kq mm ks mn kt mo kv mp kw mq mr bi translated">4.谈恋爱的36个问题</h1><p id="aa54" class="pw-post-body-paragraph ky kz jj la b lb ms kk ld le mt kn lg lh mu lj lk ll mv ln lo lp mw lr ls lt im bi translated">我在这里列出了最搞笑或最可信的答案。本文中的照片显示了一些答案。随着我们在问卷中的进展，问题变得更加个人化和试探性。完整的问题和答案列表在我的GitHub上。先说第一个问题(Q1):</p><blockquote class="mz na nb"><p id="f633" class="ky kz lu la b lb lc kk ld le lf kn lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated">我:如果你可以邀请世界上任何一个人来参加<strong class="la jk">晚餐</strong>，你会邀请谁？对话我想请自己吃饭。我想我会和我妈妈一起去。她一直都在我身边。</p></blockquote><p id="987e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在信心方面，DialoGPT确实击败了BlenderBot，但BlenderBot在这里肯定更讨人喜欢，更有关联。这种自信也适用于电话排练吗(第三季度)？</p><blockquote class="mz na nb"><p id="3b5c" class="ky kz lu la b lb lc kk ld le lf kn lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated">我:在打<strong class="la jk">电话</strong>之前，你有没有排练过你要说的话？为什么？我不排练，但我会准备。<br/><strong class="la jk">【blender bot:</strong>有时候我会，但我通常会说一些我不想说的话。</p></blockquote><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nf"><img src="../Images/b833a8c037bbf11427d897ff1215f6c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kLZqz8ragWLlPNlp0O696g.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Amy Shamblen 在<a class="ae jg" href="https://unsplash.com/s/photos/color-heart?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片，文字由Julia Nikulski添加。</p></figure><p id="5079" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我对BlenderBot的回答印象深刻，我觉得它非常像人类。DialoGPT的回答稍微不太具体，但还是有道理的。下一个问题(Q13)实际上是<strong class="la jk">给出了我最喜欢的答案:</strong></p><blockquote class="mz na nb"><p id="877f" class="ky kz lu la b lb lc kk ld le lf kn lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated">我:如果一个<strong class="la jk">水晶球</strong>可以告诉你关于你自己、你的生活、未来或其他任何事情的真相，你想知道什么？<br/> <strong class="la jk"> DialoGPT: </strong>我想知道我是不是一个好人。我想知道我是否能够还清我的学生贷款。</p></blockquote><p id="d564" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">DialoGPT的回答实际上听起来像是在试图获得自我意识。(但我现在还不担心DialoGPT接管世界的能力。BlenderBot正在用它的评论解决美国的学生贷款危机，我对这种难以置信的特殊性和知识与个性的展示印象深刻。另一方面，Q20表明，这些模型有时过于字面理解某些单词。我猜这些<strong class="la jk">定义式的答案</strong>是因为单词<em class="lu">的意思是</em>而引发的:</p><blockquote class="mz na nb"><p id="9b5f" class="ky kz lu la b lb lc kk ld le lf kn lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated"><strong class="la jk">我:</strong><strong class="la jk">友谊</strong>对你意味着什么？这意味着你是一个好朋友。<br/> <strong class="la jk"> BlenderBot: </strong>友谊是一个人和另一个人之间的纽带。可以是友谊，也可以是浪漫。</p></blockquote><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ng"><img src="../Images/ce20a3d7a8a2c5bb5fc16396bea7bec3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vNxmGipcfA6l_bZhPgNlDg.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://unsplash.com/@worthyofelegance?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Alex </a>在<a class="ae jg" href="https://unsplash.com/s/photos/color-shape?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄，文字由Julia Nikulski添加。</p></figure><p id="eda2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">关于与母亲关系的问题再次得出可信的答案，尽管有趣的是两个模型走向相反的方向(Q24):</p><blockquote class="mz na nb"><p id="6275" class="ky kz lu la b lb lc kk ld le lf kn lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated"><strong class="la jk">我:</strong>你觉得你和你<strong class="la jk">妈妈</strong>的关系怎么样？<br/> <strong class="la jk">对话:</strong>我不认识她。<br/> <strong class="la jk"> BlenderBot: </strong>我好爱她。在我最需要她的时候，她总是在我身边。</p></blockquote><p id="1f82" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们越来越接近问卷的末尾，而<strong class="la jk">问题变得越来越个人化</strong>。DialoGPT对下一个问题的回答也很有说服力，很有道理(Q29):</p><blockquote class="mz na nb"><p id="d98c" class="ky kz lu la b lb lc kk ld le lf kn lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated"><strong class="la jk">我:</strong>和你的另一半分享你人生中一个<strong class="la jk">尴尬的</strong>时刻。我不确定是否要和她分享这些。我知道，我为我做了那件事感到很惭愧。我不知道我为什么这么做。</p></blockquote><p id="6889" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">谁想和一个陌生人分享这个？！然而，BlenderBot并没有以一种有意义的方式做出响应，它的答案并不真正符合要求。Q35非常深奥，人类可能很难有意义地回答这个问题。DialoGPT在特异性方面比BlenderBot做得更好，尽管它避免回答“<em class="lu">为什么</em>”:</p><blockquote class="mz na nb"><p id="6ff0" class="ky kz lu la b lb lc kk ld le lf kn lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated"><strong class="la jk">我:</strong>在你们家所有人当中，谁的<strong class="la jk">去世</strong>你会觉得最不安？为什么？我想说是我的父亲，但我不知道为什么。<br/> <strong class="la jk"> BlenderBot: </strong>我不知道，我猜只是事实太出乎意料了。</p></blockquote><p id="4122" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">考虑到所有的答案，<strong class="la jk"> BlenderBot比DialoGPT </strong>提供了更多显示同理心和个性的答案。然而，DialoGPT的许多回答确实有道理，也很具体。在这篇博文中，这两个模型之间的比较不是很有分析性，因为这不是这个项目的目标。未来的文章可以关注应用<a class="ae jg" href="https://ai.googleblog.com/2020/05/evaluating-natural-language-generation.html" rel="noopener ugc nofollow" target="_blank">评估指标</a>来确定哪个模型更好地生成类似人类的答案。</p><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nh"><img src="../Images/20a2936bd7ec16ee4cd2ec47035b3602.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2wAvscOSSLuDCxbLNQueOw.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图片由<a class="ae jg" href="https://unsplash.com/@lianamikah?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Liana Mikah </a>在<a class="ae jg" href="https://unsplash.com/s/photos/pastel?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄，文字由Julia Nikulski添加。</p></figure><h1 id="428e" class="ma mb jj bd mc md me mf mg mh mi mj mk kp ml kq mm ks mn kt mo kv mp kw mq mr bi translated">5.生成的答案中的有毒内容</h1><p id="f5da" class="pw-post-body-paragraph ky kz jj la b lb ms kk ld le mt kn lg lh mu lj lk ll mv ln lo lp mw lr ls lt im bi translated">虽然这个项目开始时是一个有趣的想法，但我很快意识到这两个模型有时会产生有毒的答案。我最初想使用GPT-2作为第三个模型来生成36个问题的答案。然而，<strong class="la jk"> GPT-2更频繁地产生更强烈的毒性结果</strong>。</p><p id="fa46" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">文本生成中的毒性仍然是一个大问题。语言模型会产生有毒的句子，因为它们经常在互联网上的大量文本数据上进行训练，正如我们所知，这些数据确实含有相当多的毒性。研究人员正在努力全面解决这个问题，因为解决方案需要<a class="ae jg" href="https://toxicdegeneration.allenai.org/" rel="noopener ugc nofollow" target="_blank">高昂的计算成本，或者使训练数据选择更加复杂</a>。<strong class="la jk">这个毒性问题比这篇简短的文章更值得关注。然而，在亲眼目睹之后，我想提高人们的认识。</strong></p><figure class="lw lx ly lz gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ni"><img src="../Images/9ed64f8a4ffbefb24c90810b36546f53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CNhxJySdLDr9T3o0b0rTLg.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">照片由Corey Agopian 在<a class="ae jg" href="https://unsplash.com/s/photos/palm-trees?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄，文字由Julia Nikulski添加。</p></figure><h1 id="de04" class="ma mb jj bd mc md me mf mg mh mi mj mk kp ml kq mm ks mn kt mo kv mp kw mq mr bi translated">最后的想法</h1><p id="d124" class="pw-post-body-paragraph ky kz jj la b lb ms kk ld le mt kn lg lh mu lj lk ll mv ln lo lp mw lr ls lt im bi translated">人工智能肯定还没有达到这样的地步，即它可以持续地为需要情商和一致个性的个人问题提供有意义的答案。然而，<strong class="la jk">我对这两个模型提供的有时非常可信——即具体而明智——的答案感到惊讶。</strong>虽然人工智能文本生成很有趣，但它也突出了所有这些模型中仍然普遍存在的毒性问题，以及需要做的工作，以遏制人工智能中的社会偏见和仇恨。</p></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><p id="2fe8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你想在媒体上阅读更多高质量的故事吗？考虑注册一个支持我和其他媒体作者的会员。</p><div class="is it gp gr iu nq"><a href="https://medium.com/@julia.nikulski/membership" rel="noopener follow" target="_blank"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd jk gy z fp nv fr fs nw fu fw ji bi translated">通过我的推荐链接加入Medium-Julia Nikulski</h2><div class="nx l"><h3 class="bd b gy z fp nv fr fs nw fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">medium.com</p></div></div><div class="nz l"><div class="oa l ob oc od nz oe ja nq"/></div></div></a></div></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><p id="f49a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你是第一次接触基于Transformer的NLP模型吗，或者你想复习一下如何使用这些模型？查看我的<strong class="la jk">基于变压器的NLP模型初学者指南</strong>:</p><div class="is it gp gr iu nq"><a rel="noopener follow" target="_blank" href="/how-to-use-transformer-based-nlp-models-a42adbc292e5"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd jk gy z fp nv fr fs nw fu fw ji bi translated">如何使用基于变压器的NLP模型</h2><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">towardsdatascience.com</p></div></div><div class="nz l"><div class="of l ob oc od nz oe ja nq"/></div></div></a></div></div></div>    
</body>
</html>