<html>
<head>
<title>Spark MLlib on AWS Glue</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AWS胶水上的火花MLlib</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/spark-mllib-in-aws-glue-1416b3b5ffe6?source=collection_archive---------23-----------------------#2021-06-27">https://towardsdatascience.com/spark-mllib-in-aws-glue-1416b3b5ffe6?source=collection_archive---------23-----------------------#2021-06-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="b89b" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><div class=""><h2 id="cbb8" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">准备就绪的AWS上的分布式ML</h2></div><p id="7a7b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">AWS力推Sagemaker作为其机器学习平台。然而，Spark的MLlib是一个全面的库，它在AWS Glue上本地运行分布式ML——并为他们的主要ML平台提供了一个可行的替代方案。</p><p id="c4e9" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">Sagemaker的一大优势是，它可以通过Jupyter笔记本轻松支持实验。但是操作您的Sagemaker ML可能很困难，特别是如果您需要在管道的开始包含ETL处理。在这种情况下，<a class="ae lk" href="https://spark.apache.org/docs/latest/ml-guide.html" rel="noopener ugc nofollow" target="_blank">运行在AWS Glue上的Apache Spark的MLlib </a>可能是一个很好的选择——就其本质而言，它可以立即操作化，与ETL预处理集成，并准备好在生产中用于端到端的机器学习管道。</p><blockquote class="ll lm ln"><p id="bef2" class="ko kp lo kq b kr ks ka kt ku kv kd kw lp ky kz la lq lc ld le lr lg lh li lj ij bi translated">就其本质而言，[AWS Glue]是<strong class="kq ja">立即可操作的，与ETL预处理集成，并随时可用于端到端机器学习管道的生产中</strong></p></blockquote><p id="6857" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lk" href="https://docs.aws.amazon.com/glue/index.html" rel="noopener ugc nofollow" target="_blank"> AWS Glue </a>是一个托管Spark ETL平台，用于通过分布式机器处理大量数据。MLlib是Spark 2.4的一部分，Spark 2.4是AWS Glue的默认版本。在AWS Glue中使用MLlib不需要添加库。</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ls"><img src="../Images/f3cb54be3d35b00dab8819615267b112.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rmUJWjf80-RiqF1UadVL2w.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">AWS Glue Studio图表显示了通过ETL的数据流(图片由作者提供)</p></figure><h2 id="a62d" class="mi mj iq bd mk ml mm dn mn mo mp dp mq kx mr ms mt lb mu mv mw lf mx my mz iw bi translated">ETL预处理到训练和推理一气呵成</h2><p id="1b9d" class="pw-post-body-paragraph ko kp iq kq b kr na ka kt ku nb kd kw kx nc kz la lb nd ld le lf ne lh li lj ij bi translated">作为一个分布式ETL平台，AWS Glue(通过Spark)允许您轻松地执行大规模的数据预处理。Glue Studio提供了一个很好的UI来构建有向无环图，这些图表示每个预处理步骤中的数据流(参见上图中的示例)。从图形用户界面，您可以重命名字段，转换类型，过滤记录和删除列。然而，一些更复杂的数据处理活动需要添加“自定义转换”。需要自定义转换的操作包括:</p><ol class=""><li id="2522" class="nf ng iq kq b kr ks ku kv kx nh lb ni lf nj lj nk nl nm nn bi translated">运行MLlib函数，如<a class="ae lk" href="https://spark.apache.org/docs/latest/ml-features.html#tf-idf" rel="noopener ugc nofollow" target="_blank"> TF-IDF </a>或模型，如随机森林或<a class="ae lk" href="https://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-tree-regression" rel="noopener ugc nofollow" target="_blank">梯度提升树</a>算法</li><li id="a67c" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">聚合值，例如生成计数、平均值和总和值</li><li id="ed43" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">复杂的列转换，如一键编码或连接值</li></ol><p id="6026" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在使用ETL转换执行预处理和特征化之后，您需要训练您的数据。要在AWS Glue中访问MLlib，您只需要添加导入语句，就可以开始了。下面是如何使用PySpark在AWS Glue Studio自定义转换中训练回归决策树模型的示例:</p><pre class="lt lu lv lw gt nt nu nv nw aw nx bi"><span id="b04f" class="mi mj iq nu b gy ny nz l oa ob"># Get the dataframe. Ensure there's a 'features' column.<br/>df = dfc.select(list(dfc.keys())[0]).toDF()</span><span id="9a6f" class="mi mj iq nu b gy oc nz l oa ob"># Get the logger for Cloudwatch Logs<br/>logger = glueContext.get_logger()</span><span id="ee5d" class="mi mj iq nu b gy oc nz l oa ob">from pyspark.ml import Pipeline<br/>from pyspark.ml.regression import DecisionTreeRegressor<br/>from pyspark.ml.evaluation import RegressionEvaluator<em class="lo"><br/></em><br/><em class="lo"># Split data into training and test sets<br/></em>(trainingData, testData) = <!-- -->df<!-- -->.randomSplit([0.7, 0.3])<br/><br/><em class="lo"># Create a DecisionTree model.<br/></em>dt = DecisionTreeRegressor(featuresCol="features")</span><span id="5b2a" class="mi mj iq nu b gy oc nz l oa ob"><em class="lo"># Create a pipeline to wrap the DecisionTree <br/></em>pipeline = Pipeline(stages=[dt])</span><span id="ad7d" class="mi mj iq nu b gy oc nz l oa ob"><em class="lo"># Train model.<br/></em>model = <!-- -->pipeline<!-- -->.fit(trainingData)<br/><br/><em class="lo"># Make predictions.<br/></em>predictions = model.transform(testData)<br/><br/><em class="lo"># Select (prediction, true label) and compute test error<br/></em>evaluator = RegressionEvaluator(<br/>    labelCol="label", predictionCol="prediction", metricName="rmse")<br/>rmse = evaluator.evaluate(predictions)<br/>logger.info<!-- -->("Root Mean Squared Error (RMSE) on test data = %g" % rmse)</span></pre><p id="94f7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在上面的代码中，均方根误差(RMSE)被记录到Cloudwatch日志中。要使用模型进行预测，最简单的选择是使用相同的自定义转换，并在看不见的推理数据的数据帧上运行<em class="lo"> model.transform </em>。为了使用这些预测，您需要在一个<em class="lo"> DynamicFrameCollection </em>中从自定义转换中返回它们(参见本文底部的代码片段)。</p><h2 id="0af1" class="mi mj iq bd mk ml mm dn mn mo mp dp mq kx mr ms mt lb mu mv mw lf mx my mz iw bi translated">在AWS Glue中运行MLlib的技巧</h2><p id="7a76" class="pw-post-body-paragraph ko kp iq kq b kr na ka kt ku nb kd kw kx nc kz la lb nd ld le lf ne lh li lj ij bi translated">在AWS Glue中运行Spark的MLlib时，需要注意一些问题:</p><ol class=""><li id="7986" class="nf ng iq kq b kr ks ku kv kx nh lb ni lf nj lj nk nl nm nn bi translated">实验可能是缓慢而困难的。迭代和调试可能会令人沮丧，因为每个作业至少需要一分钟来运行。实验时，在缩减的数据集上运行以加快过程(仍然需要1分钟以上)。把工人减少到2个，用G.1X省钱。禁用书签和重试。</li><li id="702e" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">为了帮助调试，您可以从您的定制转换中注销信息到Cloudwatch。你必须进入Cloudwatch上的<a class="ae lk" href="https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logsV2:log-groups/log-group/$252Faws-glue$252Fjobs$252Flogs-v2" rel="noopener ugc nofollow" target="_blank"> /aws-glue/jobs/logs-v2 </a>日志组，然后打开以'-driver '结尾的日志流来查看注销的值。下面是Glue Studio定制转换的PySpark示例，设置了Cloudwatch日志记录。</li><li id="c830" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">AWS Glue开发人员端点可能有助于实验和调试。这些允许您在Spark集群上运行开发笔记本，并在编写代码时加速开发迭代。主要缺点是价格昂贵(可能需要5-15分钟来启动集群)。请注意，它们是按秒计费的，因此可能比直接执行作业要贵得多。一种选择是在学习Spark时使用开发人员端点，然后在熟悉编写Spark代码后直接在AWS Glue中执行作业。</li><li id="4027" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">虽然您可以在与特性化ETL相同的作业中运行ML训练和预测，但是您可能希望将它们分成两个作业。通过将它们分成两个作业，您可以分离它们的配置。AWS Glue提供了两种工作器类型:G.1X和G.2X。您可能会发现G.1X对于ETL来说已经足够了，但是G.2X可能更适合ML训练和推理，因为每个工作器都有两倍的可用内存。</li><li id="f8a9" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">只有批量推理可以在AWS Glue上工作——实时推理在这里不是一个选项。将Sagemaker端点用于该用例。</li><li id="aa6d" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">AWS Glue上的MLlib允许您轻松地重新训练整个数据集，然后在单个作业中执行推理。训练可能是最昂贵的步骤，但是，在批量推断之前，通过再训练，您可以从更好的预测中受益</li><li id="08ac" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">尝试使用本地Spark数据帧和库，而不是例如Pandas数据帧。这将允许您更好地利用Spark的分布式功能。</li><li id="61c7" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">MLlib中有两种可用的API——基于数据帧的API和基于RDD的API。您应该尽可能使用基于数据框架的方法。同样，尽量避免使用用户定义的函数(UDF)。UDF和基于RDD的功能都比本地数据帧方法慢。</li><li id="02bc" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated"><em class="lo"> SparseVector </em>是一种表示稀疏数据集(即具有大量列且大多数值为零的数据源)的有效方式。一个常见的例子是执行自然语言处理时TF-IDF的输出。使用<em class="lo"> SparseVector </em>列可以避免向dataframe添加成百上千的列(这很可能会导致您的作业因内存不足或超时而失败)。</li><li id="2674" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">由MLlib创建的某些dataframe列类型如果不先转换为整数或字符串，就无法写出自定义转换。当这种情况发生时，您可能会得到一个错误，如“<em class="lo">调用o341 . todf . org . Apache . spark . ml . Lina LG . vector udt @ 3 bfc 3 ba 7(org . Apache . spark . ml . Lina LG . vector udt的类)</em>时出错”。</li><li id="d997" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">在AWS中，从S3读取数据比从其他数据源/目的地读取数据要容易得多。直接连接到数据库可能比它的价值更麻烦。</li><li id="90b9" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">您很可能需要使用Glue爬虫来学习您在S3上的模式。每次数据发生变化时，您都需要重新运行crawler。使用S3路径/键中的分区键和AWS Glue“S3数据源”输入节点上的分区谓词来过滤特定日期的数据。</li><li id="f411" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">JSON和CSV在开发时可能是有用的数据类型，因为您可以看到输入和输出。然而，它们又慢又大。对于生产，考虑切换到拼花格式的输入和输出。</li><li id="2720" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">将<em class="lo"> SparseVector </em>列(已经转换为字符串)导出到CSV会导致无效的CSV结构。拼花格式可以替代。</li><li id="67aa" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">注意区分新的基于数据框架的API和旧的基于RDD的API。确保导入正确的类。在PySpark中，你应该导入'<em class="lo"> pyspark.ml.linalg </em>'而不是'<em class="lo"> pyspark.mllib.linalg </em>'来访问更新的API。如果您混淆了类型，您可能会得到奇怪的错误，如"<em class="lo"> IllegalArgumentException:'要求失败:列特征必须是struct类型&lt; type:tinyint，size:int，indexes:array&lt;int&gt;，values:array&lt;double&gt;&gt;，但实际上是struct &lt; type:tinyint，size:int，indexes:array&lt;int&gt;，values:array&lt;double&gt;&gt;</em>。这两个值看起来是一样的，但是区别在于它们使用了来自错误API的对象的不兼容版本。</li></ol><h2 id="cc47" class="mi mj iq bd mk ml mm dn mn mo mp dp mq kx mr ms mt lb mu mv mw lf mx my mz iw bi translated">能否将AWS胶水与Sagemaker整合？</h2><p id="ae3f" class="pw-post-body-paragraph ko kp iq kq b kr na ka kt ku nb kd kw kx nc kz la lb nd ld le lf ne lh li lj ij bi translated">是的，通过AWS Glue的Spark ETL可以与Amazon Sagemaker集成。典型的工作流可能是:</p><ol class=""><li id="4bd4" class="nf ng iq kq b kr ks ku kv kx nh lb ni lf nj lj nk nl nm nn bi translated">使用Jupyter笔记本在Sagemaker中试验和训练模型</li><li id="5a2b" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">通过从Sagemaker笔记本中部署一个批量推理模型来生产模型</li><li id="be84" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">在AWS Glue中使用ETL进行生产化预处理和特征化</li><li id="d9f0" class="nf ng iq kq b kr no ku np kx nq lb nr lf ns lj nk nl nm nn bi translated">计划/触发批处理推理模型在AWS Glue ETL完成后运行</li></ol><p id="c4ed" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">上述方法似乎是AWS服务的最佳用途。然而，在走这条路之前，你确实需要注意一些事情。例如，有些列类型在Spark MLlib和Sagemaker模型之间不兼容。例如，Sagemaker XGBoost要求其输入为特定格式，并且不能从Spark读取<em class="lo"> SparseVector </em>列。</p><h2 id="7f64" class="mi mj iq bd mk ml mm dn mn mo mp dp mq kx mr ms mt lb mu mv mw lf mx my mz iw bi translated">注销到Cloudwatch的示例</h2><p id="eea9" class="pw-post-body-paragraph ko kp iq kq b kr na ka kt ku nb kd kw kx nc kz la lb nd ld le lf ne lh li lj ij bi translated">下面是AWS Glue Studio上的PySpark自定义转换示例，用于注销到<a class="ae lk" href="https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logsV2:log-groups/log-group/$252Faws-glue$252Fjobs$252Flogs-v2" rel="noopener ugc nofollow" target="_blank"> /aws-glue/jobs/logs-v2 </a>日志流下的“<em class="lo"> -driver </em>”日志流。</p><pre class="lt lu lv lw gt nt nu nv nw aw nx bi"><span id="03d6" class="mi mj iq nu b gy ny nz l oa ob">def MyTransform (glueContext, dfc) -&gt; DynamicFrameCollection:<br/>     <strong class="nu ja">logger = glueContext.get_logger()</strong><br/>     df = dfc.select(list(dfc.keys())[0]).toDF()<br/>     <strong class="nu ja">logger.info("Number of df rows:" + str(df.count()))</strong><br/>     dyf = DynamicFrame.fromDF(df, glueContext, "df")  <br/>     return DynamicFrameCollection({"CustomTransform": dyf}, glueContext)</span></pre><h2 id="f190" class="mi mj iq bd mk ml mm dn mn mo mp dp mq kx mr ms mt lb mu mv mw lf mx my mz iw bi translated">在传递自定义转换之前转换dataframe列的示例</h2><p id="4681" class="pw-post-body-paragraph ko kp iq kq b kr na ka kt ku nb kd kw kx nc kz la lb nd ld le lf ne lh li lj ij bi translated">如果不先将一些MLlib列类型转换为字符串或整数，则在尝试从自定义转换返回dataframe时会出现错误。VectorUDT是一种“用户定义类型”的列，通常由MLlib转换生成。下面是一个在返回之前将列转换为字符串的示例。</p><pre class="lt lu lv lw gt nt nu nv nw aw nx bi"><span id="4e93" class="mi mj iq nu b gy ny nz l oa ob"># Cast VectorUDT column to String<br/>rescaledData=rescaledData.withColumn("features",rescaledData["features"].cast("String"))</span><span id="aed1" class="mi mj iq nu b gy oc nz l oa ob"># Reduce the number of columns being returned<br/>rescaledData = rescaledData.selectExpr("labels", "features")</span><span id="db1d" class="mi mj iq nu b gy oc nz l oa ob"># Convert from Spark dataframe to AWS Glue DynamicFrame<br/>dyf_out = DynamicFrame.fromDF(rescaledData, glueContext, "rescaledData")   </span><span id="5210" class="mi mj iq nu b gy oc nz l oa ob"># Wrap the DynamicFrame in a DynamicFrameCollection and return<br/>return DynamicFrameCollection({"CustomTransform": dyf_out}, glueContext)</span></pre></div></div>    
</body>
</html>