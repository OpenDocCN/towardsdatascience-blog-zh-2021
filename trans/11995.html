<html>
<head>
<title>Review of re:Invent 2021 AI/ML Releases by a Former SageMaker PM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一位前SageMaker项目经理关于re:Invent 2021 AI/ML发布的评论</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-of-re-invent-2021-ai-ml-releases-by-a-former-sagemaker-pm-cc416ed32d94?source=collection_archive---------16-----------------------#2021-12-02">https://towardsdatascience.com/review-of-re-invent-2021-ai-ml-releases-by-a-former-sagemaker-pm-cc416ed32d94?source=collection_archive---------16-----------------------#2021-12-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="4cbe" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">意见</h2><div class=""/><div class=""><h2 id="f64d" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">AWS对所有新MLOps工具的深入分析</h2></div><p id="d7ea" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">每年12月，亚马逊网络服务(AWS)都会为客户发布新的机器学习(ML)功能。这是拉斯维加斯的一项激动人心的活动，门票通常会销售一空。有很多新闻，我将为数据科学社区提炼出来。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lk"><img src="../Images/d7e09a23d7afa3556ca61638a2229fd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TLPOLScECDFTxo_O8LanUw.jpeg"/></div></div><p class="lw lx gj gh gi ly lz bd b be z dk translated">来自Unsplash的会议图像</p></figure><p id="49eb" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我之前在《走向数据科学》上写过<a class="ae ma" rel="noopener" target="_blank" href="/comparing-cloud-mlops-platform-from-a-former-aws-sagemaker-pm-115ced28239b">云MLOps平台</a>，目前我正在创建一家应用ML stealth初创公司。我之前是AWS SageMaker的高级产品经理，脸书的计算机视觉(AR/VR)数据、工具和运营主管，以及投资新兴市场债券的applied ML对冲基金的创始人。欢迎<a class="ae ma" href="https://twitter.com/alxchung" rel="noopener ugc nofollow" target="_blank">发微博</a>或<a class="ae ma" href="https://www.linkedin.com/in/alex-chung-gsd/" rel="noopener ugc nofollow" target="_blank">在LinkedIn上给我发信息</a>你的评论。</p><p id="3ebc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在过去的两年里，我观察到有一个简单的框架来应用ML产品:应用AI/ML服务、MLOps平台和ML框架。最底层是<strong class="kq ja"> <em class="mb">框架</em> </strong>，跨越ML库(PyTorch、Jax、XGBoost)到编译器和计算芯片(GPU、ARM、TPU、ASICs)。中间是<strong class="kq ja"> <em class="mb"> MLOps平台SDK</em></strong>像训练、推理系统、元数据管理、数据处理、工作流引擎和笔记本环境。最后在最顶层的是<strong class="kq ja"> <em class="mb"> AI/ML服务</em> </strong>，它抽象了下面的层。AWS很乐意通过understand of Textract向您销售人工智能服务，但我采访的几乎每个企业都喜欢拥有自己的ML团队来管理复杂性并将正确的工具粘合在一起。我的框架分解实际上在一个标准的AWS AI/ML营销幻灯片中使用。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mc"><img src="../Images/931ebb4f533890b9cfbd286a74555396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3uYdv8kLwZtN403ozgYX6w.jpeg"/></div></div><p class="lw lx gj gh gi ly lz bd b be z dk translated">图片来自Unsplash</p></figure><p id="47f2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">SageMaker产品从底层框架到AI服务都有。他们的产品定位旨在成为万金油，这在<a class="ae ma" href="https://virtualizationreview.com/articles/2021/03/15/gartner-cloud-aidev.aspx" rel="noopener ugc nofollow" target="_blank"> Gartner魔力象限</a>中得分很高，但仍受到首席信息官和ML团队经理对功效的广泛争论。然而，在2021 re:Invent上，SageMaker模糊了MLOps平台和人工智能服务之间的界限，同时还在框架上发布了新的深度学习工具。</p><p id="15ce" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">毫无疑问，SageMaker今年非常重视深度学习(DL)能力。早在7月份，他们的领导层做了一件前所未有的事情，与拥抱脸合作，进行直接的培训和推理产品合作。与其他云提供商相比，AWS与开源初创公司合作的记录参差不齐，但HuggingFace在自然语言处理(NLP)库中的主导地位使得这种协同作用非常值得期待。</p><p id="0624" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae ma" href="https://docs.aws.amazon.com/sagemaker/latest/dg/training-compiler.html" rel="noopener ugc nofollow" target="_blank">训练编译器</a> —该产品旨在通过使用不同的AWS专有库运行张量运算，减少DL模型的训练时间。DL模型由一个多维矩阵组成，神经网络的每一层都在训练过程中运行一系列数学运算。每种运算(加、减等)都可以归类为一个运算符。在Numpy，有超过1000个运营商，你可以从我的朋友<a class="ae ma" href="https://huyenchip.com/2021/09/07/a-friendly-introduction-to-machine-learning-compilers-and-optimizers.html" rel="noopener ugc nofollow" target="_blank">芯片</a>那里了解更多这个话题。AWS选择强调NLP模型，这是在打赌客户对文本深度学习的使用最多。在我自己的CIO电话中，我看到了类似的趋势。然而，为一系列NLP客户提供一个普遍可用的产品有几个挑战，我怀疑这些挑战已经被克服了。</p><p id="bf91" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">首先，SageMaker有自己的运行培训作业所需的容器。如果缺少操作员，您将无法运行培训作业，直到库支持优化版本。后备机制引入了会降低工作速度的巨大瓶颈。培训产品的常见问题强调了这些问题，“<em class="mb">使用SageMaker Training Compiler，我总能获得更快的培训工作吗？不，不一定”。</em>其次，如果你需要完全控制容器和它安装的东西，你需要AWS团队的白手套服务。第三，如果你在实验阶段对模型进行多次迭代，这将增加你培训工作的开始时间，从而降低开发速度。我很难向任何一个ML团队推荐这个。对于大多数深度学习用例来说，即使运行POC也不太可能值得付出努力。</p><p id="1109" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae ma" href="https://aws.amazon.com/blogs/aws/announcing-amazon-sagemaker-ground-truth-plus/" rel="noopener ugc nofollow" target="_blank">Ground Truth Plus</a>—Ground Truth Plus允许公司提交项目请求，SageMaker项目经理会将项目与他们管理的一组工人进行匹配。Plus和standard Ground Truth之间的唯一区别是工人管理。在大多数深度学习数据需求中，如音频转录、分割、分类，甚至3D点云标签，许多创业公司都有多年提供这些服务的经验。例子包括私人创业规模。AI、社会责任数据标注厂商Samasource、加拿大Telus(通过收购Lionbridge)。</p><p id="95a2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">SageMaker还为他们的工作室笔记本发布了一些新功能。</p><p id="9471" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae ma" href="https://aws.amazon.com/blogs/aws/now-in-preview-amazon-sagemaker-studio-lab-a-free-service-to-learn-and-experiment-with-ml/" rel="noopener ugc nofollow" target="_blank">sage maker Studio Lab</a>——类似谷歌Colab的运行笔记本的免费服务。该产品非常适合希望了解更多关于ML和免费计算的爱好者社区。然而，这并不能帮助大多数企业客户。我在使用该产品的等待名单上，所以我会保留更深入的评论，直到我使用它之后。</p><p id="9413" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae ma" href="https://aws.amazon.com/blogs/aws/announcing-amazon-sagemaker-canvas-a-visual-no-code-machine-learning-capability-for-business-analysts/" rel="noopener ugc nofollow" target="_blank">sage maker Canvas</a>——如果你使用过SageMaker Autopilot，Canvas用更多的工作室图形工具包装该产品，以最大限度地减少组织中没有Python数据科学经验的业务分析师的编码，他们希望进行快速的ML实验，我可以看到向他们展示该功能的明显好处。换句话说，任何拥有大量雪花和红移用户群的公司都有可能优化TCO，方法是让他们的数据分析师先用Canvas运行POCs，然后再让数据科学家提供支持。这里的挑战仍然是，这些千篇一律的模型可以解决的问题的类型很窄，并且基于表格数据的ML的大部分问题在数据处理中。截至发稿时，Canvas在US-West-1上还不可用，我可以在体验后分享更多细节。</p><p id="6833" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae ma" href="https://aws.amazon.com/blogs/aws/new-create-and-manage-emr-clusters-and-spark-jobs-with-amazon-sagemaker-studio/" rel="noopener ugc nofollow" target="_blank">sage maker Studio Spark Connector</a>—Spark可能是有史以来使用最广泛的分布式数据处理系统之一。对于ML之前的数据预处理，这是简化开发人员体验的起点。大多数财富500强公司都在Spark上有一些部署，部署从on instance(裸机)、Kubernetes (Spark运营商)、Databricks到AWS的EMR都有。虽然我看到的数据块比EMR客户多，但非EMR Spark支持可能会出现。值得注意的是，这是开发人员体验的增强，对性能没有好处。当数据和计算位于同一位置时，大规模分布式处理作业通常运行得最好。然而，用于数据处理的EMR和用于ML模型训练的SageMaker是在两个完全独立的计算环境中运行的。</p><p id="ade3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">最后，还有一个<a class="ae ma" href="https://aws.amazon.com/blogs/aws/announcing-amazon-sagemaker-inference-recommender/" rel="noopener ugc nofollow" target="_blank"> SageMaker推理推荐器</a>。SageMaker和大多数AWS产品依赖于实例的概念。SageMaker计算作业本质上是在标准EC2节点池上运行的，带有一个定制的运行时、AMI和容器。因为实例是离散的，但是流量和工作负载是连续分布的，所以我工作过的许多企业都使用Kubernetes运行ML工作负载。Kubernetes上有像<a class="ae ma" href="https://knative.dev/docs/" rel="noopener ugc nofollow" target="_blank"> knative </a>这样的工具，它们可以从零开始弹性地扩展持久性服务，通过资源配置文件使用spot实例。像<a class="ae ma" href="https://github.com/SeldonIO/seldon-core" rel="noopener ugc nofollow" target="_blank"> Seldon Core </a>和<a class="ae ma" href="https://github.com/kserve/kserve" rel="noopener ugc nofollow" target="_blank"> KServe </a>这样的库将这些特性和其他特性一起打包在一个可安装的Kubernetes清单中。</p><p id="1ef6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">SageMaker推理推荐器试图通过提供每种实例类型的延迟和吞吐量指标来缩小这一差距。您必须支付实例计算成本。SageMaker选择了创可贴，而不是进行更大的投资来制造无服务器或绑定到公司现有计算集群的模型服务。如果客户真的需要这个特性，那么编写一个脚本来实现这个推理推荐器所提供的功能是非常简单的。事实上，它的主要客户Intuit就是这么做的，你可以在今年早些时候在Github 上看到他们的<a class="ae ma" href="https://github.com/intuit/perfsizesagemaker" rel="noopener ugc nofollow" target="_blank">开源代码。</a></p><p id="0681" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">托管服务仍然为公司提供巨大的价值。它们通过卸载普通的配置和设置，降低了IT组织的总拥有成本。然而，该领域变化太快，在这一点上只有一个真正的SageMaker和其他主要MLOps平台的最终游戏。他们需要在Kubernetes上运行他们的工具和计算引擎。微软Azure和GCP已经在他们的ML平台中提供了这种形式。</p><p id="68c2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">Kubernetes开源工具中的MLOps工具生态系统发展迅速。一些大品牌，如Kubeflow Pipelines，已经成为企业中非常受欢迎的产品。SageMaker可以在MLOps馅饼中占有很大份额，但今天他们已经采取了一种几乎是围墙花园的方法。不幸的是，这意味着ML团队将不得不继续混合和匹配开源、自主开发和多个供应商的服务，以使端到端的ML工作流运行良好。</p><p id="f7a8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">简而言之，至少可以说，2021年人工智能/人工智能领域的公告乏善可陈。这也不是因为缺乏客户需求——摩根士丹利首席信息官调查显示，分析(AI/ML)仍然是每个季度的前五大考虑因素。企业应该继续投资于他们自己的MLOps团队，该团队可以有选择地挑选出对他们的公司有意义的解决方案。所有拥有超过25名数据科学家的企业将无法单独在AWS SageMaker这样的工具上运行。查看我之前的帖子，深入了解工具选项和生态系统的状态。</p><p id="d1c6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">尽管如此，作为一个与SageMaker的许多工程师一起工作过的人，我相信他们正在为这个行业进行改变游戏规则的长期投资。然而，似乎他们中的许多人还没有为2021年的重新发明做好准备。</p></div></div>    
</body>
</html>