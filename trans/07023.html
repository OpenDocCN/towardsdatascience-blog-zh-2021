<html>
<head>
<title>NLP on Data Science Interview Questions &amp; Answers Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学面试问答数据集上的NLP</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nlp-on-data-science-interview-questions-answers-dataset-5e7b31f749cf?source=collection_archive---------27-----------------------#2021-06-25">https://towardsdatascience.com/nlp-on-data-science-interview-questions-answers-dataset-5e7b31f749cf?source=collection_archive---------27-----------------------#2021-06-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6c33" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">超过300个数据科学面试问题和答案的数据集</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/832b04a53306d8073129e543e2389b52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3GEub2K2ohqP_Qht"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@mrtt?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">TT先生</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="6b66" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">项目陈述</h1><p id="43c4" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">最近我有一个随机问题，如果有一个数据集包含数据科学面试问题和答案的集合？目前，我没有找到任何，所以我决定自己创造！🥳</p><p id="efeb" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我花了几天时间从许多主要的数据科学学习平台收集了300多个数据科学面试问题和答案，我在文章结尾列出了这些问题和答案。最后，我建立了一个足够大的数据集来探索。</p><p id="538c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我发现，在阅读了网站上的数百个数据科学问题后，比如</p><ul class=""><li id="6b35" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated">Simplilearn</li><li id="81e4" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">跳板</li><li id="57ac" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">走向数据科学</li><li id="4562" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">爱德华卡</li><li id="4a23" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">分析Vidhya</li><li id="ffb4" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">其他Github回购</li></ul><p id="f987" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">有很多问题非常相似，甚至基本相同。所以经过仔细的选择和重新分类，我用这个数据集完成了一个NLP项目，希望能发现一些真知灼见。希望你会喜欢阅读它！</p><h1 id="a126" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">NLP第一部分:数据清理</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/b2db65421de04bd655f32ca842e78751.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_cqQb1v85BxpNTWy3xpYfA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据集看起来像什么</p></figure><p id="bb10" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">首先，让我们看看数据集是什么样子的。</p><p id="ea35" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">它有三列:</p><ul class=""><li id="11c5" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated">种类</li><li id="2166" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">问题</li><li id="0b22" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">答案</li></ul><p id="abe8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在类别方面，我<strong class="lt iu">手动</strong>浏览每个问题，并将其归类为EDA、方法论、统计学或模型指定类型。然而，在项目的后期，我将进一步简化该类别，仅分为4个主要类型，即<strong class="lt iu"> EDA </strong>、<strong class="lt iu">方法论</strong>、<strong class="lt iu">统计</strong>和<strong class="lt iu">模型</strong>。</p><p id="7af8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了清理问题和答案列，我使用了NLTK。清洗步骤包括:</p><ul class=""><li id="2942" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated">降低外壳</li><li id="9121" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">替换特殊字符</li><li id="8171" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">单词标记化</li><li id="df38" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">删除停用词</li><li id="6c88" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">WordNet词汇化</li></ul><p id="cb89" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">关于去掉停用词这一步，我没有用NLTK库提供的，因为我觉得词表不够长。所以我在下面Github repo的帮助下，自己创建了一个停用词列表:</p><div class="nh ni gp gr nj nk"><a href="https://github.com/first20hours/google-10000-english" rel="noopener  ugc nofollow" target="_blank"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">前20小时/谷歌-10000-英语</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">这份报告包含了10，000个最常见的英语单词的列表，按照n-gram确定的频率排序…</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">github.com</p></div></div><div class="nt l"><div class="nu l nv nw nx nt ny ks nk"/></div></div></a></div><p id="fa90" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">基本上，这个repo包含一个按频率排列的10，000个最常见英语单词的列表，这是通过对Google的万亿单词语料库进行n-gram频率分析确定的。我用其中的前500个词来建立我的停用词列表。</p><p id="c615" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">此外，WordNet Lemmatizer用于将单词链接回其语义公共基础形式。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="6e18" class="oe la it oa b gy of og l oh oi"># WordNet Examples: <br/>#&gt; kites ---&gt; kite</span><span id="378f" class="oe la it oa b gy oj og l oh oi">#&gt; babies ---&gt; baby</span><span id="5893" class="oe la it oa b gy oj og l oh oi">#&gt; dogs ---&gt; dog</span><span id="5baf" class="oe la it oa b gy oj og l oh oi">#&gt; flying ---&gt; flying</span><span id="efa3" class="oe la it oa b gy oj og l oh oi">#&gt; smiling ---&gt; smiling</span><span id="ab66" class="oe la it oa b gy oj og l oh oi">#&gt; feet ---&gt; foot</span></pre><div class="nh ni gp gr nj nk"><a href="https://gaurav5430.medium.com/using-nltk-for-lemmatizing-sentences-c1bfff963258" rel="noopener follow" target="_blank"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">使用NLTK对句子进行词汇化</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">在这篇文章中，我们将使用NLTK WordNet词条分类器对句子进行词条分类。默认情况下，lemmatizer采用…</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">gaurav5430.medium.com</p></div></div><div class="nt l"><div class="ok l nv nw nx nt ny ks nk"/></div></div></a></div><p id="7f34" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最后，我们可以将上述所有清理步骤集成到一个名为<strong class="lt iu"> nlp_process </strong>的清理函数中:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div></figure><h1 id="6622" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">NLP第二部分:数据可视化</h1><p id="1b7a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在数据可视化方面，我使用了word clouds来演示我的发现。</p><p id="43b3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">单词云的想法是找到面试问题和答案中最常见的n-gram单词。对于EDA、方法论、统计学和模型中的每一个类别，我都制作了一对单词云图来进行比较。有趣的是，我们可以看到最常被问到和回答的单词是什么。</p><p id="3ec8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于双字母词云，我首先使用<strong class="lt iu">计数矢量器</strong>为双字母词生成频率字典，并使用<strong class="lt iu">generate _ from _ frequency</strong>进行绘图。您可以按如下方式查看详细的代码和图形:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div></figure><div class="kj kk kl km gt ab cb"><figure class="on kn oo op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/bc9dbefe7a271072de5b1f054dd0e3d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*YTVUO1AVlatzofzpxvtytA.png"/></div></figure><figure class="on kn ot op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/e4aedd05375f0255b8fad871e61b56a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*V81R-9dadZ-4cn3AcPvIrw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk ou di ov ow translated">EDA-问题与答案</p></figure></div><div class="ab cb"><figure class="on kn ox op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/ee1eabef685b83a1ffccd68608be34dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*_e5sSUrZGsc0HAjVt1--qQ.png"/></div></figure><figure class="on kn oy op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/eba1938ca36bd5a5680badbca2ac80ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*E9rhDY16j-nC4UQJ8-JXYg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk ou di ov ow translated">方法论-问题与答案</p></figure></div><div class="ab cb"><figure class="on kn oz op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/85e8441ef7e32f2b624c7102536684c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*I57X5SF-qXX5wBWA0_CBUA.png"/></div></figure><figure class="on kn pa op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/5f0bd80956f082d8436db27a183eeeb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*X3k0zMy-1BwmQsHuGPdORA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk ou di ov ow translated">模型-问题与答案</p></figure></div><div class="ab cb"><figure class="on kn pb op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/3bfc20adb19d9b672ef283f8c48942fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*vNURvNesmIroKdfSS2pjig.png"/></div></figure><figure class="on kn pc op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/d4c9557b8e932d471da0c7c2c73a1172.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*sGJflv1-ERfP-LGmvMx5aA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk ou di ov ow translated">统计-问题与答案</p></figure></div><h1 id="7b78" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">NLP第三部分:数据建模</h1><p id="34b3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">最后，由于我们已经完成了数据清理和将文本矢量化为字数，我认为我们可以继续构建数据科学面试问题分类器，作为这个NLP项目的结论。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/76cc6a8e81155a576303d7b7feb679aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yCA9pKE8SKXpUJBH6DiIyQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">处理后的数据集现在是什么样子</p></figure><p id="3c9b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">目前，经过清理和重新分类的数据集看起来如上图所示。而且我们只会使用<strong class="lt iu">问题</strong>列来预测<strong class="lt iu">类别</strong>。我使用CountVectorizer将文本转换成数字特征。(TF-IDF矢量器也可以！)</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="2e55" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">到目前为止，我们已经使用<strong class="lt iu"> CountVectorizer </strong>成功地将问题列中的文本转换为字数向量。还有一个可选步骤，可以通过执行<strong class="lt iu">卡方</strong>测试来帮助我们降低单词特征的维数。</p><blockquote class="pe pf pg"><p id="b82a" class="lr ls ph lt b lu mn ju lw lx mo jx lz pi mp mc md pj mq mg mh pk mr mk ml mm im bi translated">将每个类别视为二进制(例如，“EDA”类别对于EDA问题为1，对于其他问题为0)。</p><p id="ced0" class="lr ls ph lt b lu mn ju lw lx mo jx lz pi mp mc md pj mq mg mh pk mr mk ml mm im bi translated">执行<a class="ae ky" href="https://en.wikipedia.org/wiki/Chi-squared_test" rel="noopener ugc nofollow" target="_blank">卡方测试</a>以确定特征和二元目标是否独立。</p><p id="5403" class="lr ls ph lt b lu mn ju lw lx mo jx lz pi mp mc md pj mq mg mh pk mr mk ml mm im bi translated">仅保留卡方检验中具有特定p值的要素。</p></blockquote><p id="c104" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我从这篇惊人的文章中学到了上面的方法:</p><div class="nh ni gp gr nj nk"><a rel="noopener follow" target="_blank" href="/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">基于自然语言处理的文本分类:Tf-Idf vs Word2Vec vs BERT</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">预处理、模型设计、评估、词袋的可解释性、词嵌入、语言模型</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">towardsdatascience.com</p></div></div><div class="nt l"><div class="pl l nv nw nx nt ny ks nk"/></div></div></a></div><p id="d00d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">通过遵循精确的卡方检验<strong class="lt iu">特征选择</strong>步骤，以下是各类面试问题的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/3a35f5c515473a2c75fe344fd3f12647.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sZ06FGfL5kndRcLYWTcyAA.png"/></div></div></figure><p id="847d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因此，现在我们可以继续使用所选的单词特征进行数据建模。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="56b3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我选择的ML模型包括:</p><ul class=""><li id="a175" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated">多项式朴素贝叶斯分类器</li><li id="4816" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">随机森林分类器</li><li id="60b2" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">决策树分类器</li></ul><p id="5221" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我特别选择了<strong class="lt iu">多项式</strong> <strong class="lt iu">朴素贝叶斯</strong>分类器，因为它适用于具有离散特征的分类(例如文本分类的字数)。</p><p id="3016" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们可以检查结果如下:</p><div class="kj kk kl km gt ab cb"><figure class="on kn pn op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/87f4be2a5471f0092705dca21c2c36ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*8IKIH4I9DA0tyAtLjHE_IQ.png"/></div></figure><figure class="on kn po op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/2fd8da8f2c74cdf1d4f3943db701e087.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*JCD35GO4O4iepAFT0yR3Jw.png"/></div></figure><figure class="on kn pp op oq or os paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/0f1c1d6ff8b394d2dd03b05670a9bff2.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*_b8s2V-DnEk0LrMtxZzQMQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk pq di pr ow translated">多项式树vs随机森林vs决策树</p></figure></div><h1 id="7879" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">总结:</h1><p id="a261" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">谢谢你的阅读。我相信将数据科学面试问题收集到一个数据集的目的是为了帮助每个人为面试做好准备，并提高学习效率！</p><p id="6c19" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我喜欢阅读每一个问题，并把它归入不同的类别。在准备数据集和撰写这篇文章的过程中，我也学到了很多。希望你也喜欢这篇文章！</p><p id="2219" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">此外，我还找到了另一篇关于用LDA  进行<a class="ae ky" rel="noopener" target="_blank" href="/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"> <strong class="lt iu">主题建模的文章，我认为它可能也适用于数据集。如果数据集大得多就更好了。</strong></a></p><p id="48c2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">无论如何，再次感谢你的时间！🥳</p><p id="5200" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">👉<a class="ae ky" href="https://github.com/kyoto-cheng/NLP-on-Data-Science-Interviews-Questions" rel="noopener ugc nofollow" target="_blank"> Github回购</a></p><h1 id="03cc" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">阅读材料:</h1><div class="nh ni gp gr nj nk"><a rel="noopener follow" target="_blank" href="/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">Python中的主题建模和潜在狄利克雷分配</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">主题建模是一种统计建模，用于发现出现在一个集合中的抽象“主题”</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">towardsdatascience.com</p></div></div><div class="nt l"><div class="ps l nv nw nx nt ny ks nk"/></div></div></a></div><div class="nh ni gp gr nj nk"><a rel="noopener follow" target="_blank" href="/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794"><div class="nl ab fo"><div class="nm ab nn cl cj no"><h2 class="bd iu gy z fp np fr fs nq fu fw is bi translated">基于自然语言处理的文本分类:Tf-Idf vs Word2Vec vs BERT</h2><div class="nr l"><h3 class="bd b gy z fp np fr fs nq fu fw dk translated">预处理、模型设计、评估、词袋的可解释性、词嵌入、语言模型</h3></div><div class="ns l"><p class="bd b dl z fp np fr fs nq fu fw dk translated">towardsdatascience.com</p></div></div><div class="nt l"><div class="pl l nv nw nx nt ny ks nk"/></div></div></a></div><h1 id="7602" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">数据科学面试问题资源:</h1><ul class=""><li id="606b" class="ms mt it lt b lu lv lx ly ma pt me pu mi pv mm mx my mz na bi translated"><a class="ae ky" href="https://www.simplilearn.com/tutorials/data-science-tutorial/data-science-interview-questions" rel="noopener ugc nofollow" target="_blank"><em class="ph">https://www . simpli learn . com/tutorials/data-science-tutorial/data-science-interview-questions</em></a></li><li id="2423" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><a class="ae ky" href="https://www.edureka.co/blog/interview-questions/data-science-interview-questions/" rel="noopener ugc nofollow" target="_blank"><em class="ph">https://www . edureka . co/blog/interview-questions/data-science-interview-questions/</em></a></li><li id="3c9e" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><a class="ae ky" href="https://www.springboard.com/blog/data-science/data-science-interview-questions/" rel="noopener ugc nofollow" target="_blank"><em class="ph">https://www . springboard . com/blog/data-science/data-science-interview-questions/</em></a></li><li id="3d8c" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/over-100-data-scientist-interview-questions-and-answers-c5a66186769a"><em class="ph">https://towards data science . com/over-100-data-scientist-interview-question-and-answers-c5a 66186769 a</em></a></li><li id="44dd" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/120-data-scientist-interview-questions-and-answers-you-should-know-in-2021-b2faf7de8f3e"><em class="ph">https://towards data science . com/120-data-scientist-interview-question-and-answers-you-should-know-in-2021-B2 faf 7 de 8 f3e</em></a></li><li id="d319" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">【https://github.com/alexeygrigorev/data-science-interviews】T5<a class="ae ky" href="https://github.com/alexeygrigorev/data-science-interviews" rel="noopener ugc nofollow" target="_blank">T6</a></li><li id="93a5" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><a class="ae ky" href="https://github.com/kojino/120-Data-Science-Interview-Questions" rel="noopener ugc nofollow" target="_blank"><em class="ph">https://github . com/koji no/120-数据-科学-面试-提问</em> </a></li><li id="1195" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><a class="ae ky" href="https://github.com/khanhnamle1994/cracking-the-data-science-interview" rel="noopener ugc nofollow" target="_blank"><em class="ph">https://github . com/khanhnamle 1994/cracking-the-data-science-interview</em></a></li></ul></div></div>    
</body>
</html>