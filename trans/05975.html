<html>
<head>
<title>Understanding the Process of Building a Machine Learning Model for a Real World Scenario</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解为真实世界场景构建机器学习模型的过程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-the-process-of-building-a-machine-learning-model-for-a-real-world-scenario-30a50fc12f7f?source=collection_archive---------31-----------------------#2021-05-28">https://towardsdatascience.com/understanding-the-process-of-building-a-machine-learning-model-for-a-real-world-scenario-30a50fc12f7f?source=collection_archive---------31-----------------------#2021-05-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8973" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">构建线性回归模型以根据天气历史数据预测表观温度的实用分步指南</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/9c9fbf553b9b8b73364ab7ffa845c548.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zPAMHi6fnxuK23R1"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/@kmuza?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">卡洛斯·穆扎</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="27c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文的重点是找出特定要素之间的关系，并在经历了所有必要的步骤后使用天气历史数据集进行预测，</p><ul class=""><li id="46b8" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">数据清理</li><li id="0c32" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">数据转换</li><li id="aeff" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">特征编码</li><li id="0a89" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">特征缩放</li><li id="516e" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">特征离散化</li><li id="4daf" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">降维</li><li id="5a35" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">线性回归模型</li><li id="ced5" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">模型评估</li></ul><p id="2cf9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里的目标是发现，湿度和温度之间是否存在<strong class="ky ir">关系，湿度和表观温度</strong>之间是否存在<strong class="ky ir">关系？并且还发现<strong class="ky ir">在给定的湿度下是否可以预测表观温度。</strong></strong></p><p id="18e3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里使用的数据集是Kaggle的天气历史数据集。点击<a class="ae kv" href="https://www.kaggle.com/budincsevity/szeged-weather" rel="noopener ugc nofollow" target="_blank">这里</a>可以找到。</p><p id="8b1d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，导入所需的python库。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="fdb3" class="ml mm iq mh b gy mn mo l mp mq">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import scipy.stats as stats<br/>import seaborn as sns<br/>from sklearn import preprocessing<br/>from sklearn.decomposition import PCA<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.preprocessing import KBinsDiscretizer<br/>from sklearn import linear_model<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import mean_squared_error<br/>from math import sqrt<br/>from sklearn.model_selection import cross_val_score,     cross_val_predict<br/>from sklearn import metrics</span></pre><p id="2c89" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后将数据集导入Colab并读取。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="1736" class="ml mm iq mh b gy mn mo l mp mq">from google.colab import drive<br/>drive.mount("/content/gdrive")</span><span id="f7ae" class="ml mm iq mh b gy mr mo l mp mq">data_set = pd.read_csv('/content/gdrive/My Drive /data            /weatherHistory.csv')<br/>data_set.tail(10)</span></pre><p id="44fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据集中的最后10行可以用下面的<code class="fe ms mt mu mh b"><em class="mv">data_set.tail(10)</em></code>进行检查。</p><p id="decc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/a9b725bd239282fe31be471708e0d861.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nv66eqfzZ_vSOw9JNq8ztA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">资料组</p></figure><p id="2a00" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那么原始数据集的副本被创建为x。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="a9cd" class="ml mm iq mh b gy mn mo l mp mq">X = data_set.copy()</span></pre><h1 id="16cf" class="mx mm iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">1.数据清理—处理缺失值、异常值和异常值</h1><p id="595a" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">应该检查数据集是否有缺失值，下面的代码将返回<em class="mv"> True </em>如果有任何缺失值，否则返回<em class="mv"> False </em>。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="5443" class="ml mm iq mh b gy mn mo l mp mq">X.isnull().values.any()</span></pre><p id="e139" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的代码输出<em class="mv"> True </em>，表示数据集中有缺失的值。因此需要识别出缺少值的列。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="9c14" class="ml mm iq mh b gy mn mo l mp mq">X.isnull().any()</span></pre><p id="ec76" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/5b931d746ca6eff3bf7927d8334721cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*LOlmTv-NC2_0XLzJQGX33A.png"/></div></figure><p id="eb60" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这意味着，只有Precip类型列有缺失值，所有其他列没有任何缺失值。</p><p id="88ab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">缺失值的百分比可按如下方式检查。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="ddfb" class="ml mm iq mh b gy mn mo l mp mq">print(X.isnull().sum() * 100 / len(X))</span></pre><p id="71ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/e26204b26fbcb687623ddd0a3bc96185.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*3UAM7LkxpAZegDXhuUxsyg.png"/></div></figure><p id="eb23" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到百分比非常低，所以我们可以用下面的代码删除数据集中所有缺失的值。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="a4c4" class="ml mm iq mh b gy mn mo l mp mq">X = X.dropna()</span></pre><p id="4c93" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">既然缺失值问题已经解决，接下来，我们应该检查异常值或异常值。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="168c" class="ml mm iq mh b gy mn mo l mp mq">X.boxplot(figsize=(18,8))</span></pre><p id="67c7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/7216dab8a7c8924bbddb5a8af4517879.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MVNFW71SerhlZnaRLLQLnw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">所有特征的箱线图</p></figure><p id="15d0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到压力特征的数据分布是异常的，因为压力已经为0。我们可以检查有多少数据显示异常。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="51f1" class="ml mm iq mh b gy mn mo l mp mq">X[X['Pressure (millibars)'] == 0].shape[0]</span></pre><p id="9be8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">产量:1288</p><p id="79f6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以这些都不是离群值。这些值可能是一些人为错误或系统故障的结果。因此，我们不能简单地接受它们，也不能放弃它们，因为那样我们会错过其他功能数据。所以我们可以利用IQR。</p><blockquote class="nw nx ny"><p id="5e2d" class="kw kx mv ky b kz la jr lb lc ld ju le nz lg lh li oa lk ll lm ob lo lp lq lr ij bi translated">IQR或四分位数范围是基于将数据集划分为不同分位数的变异性度量。</p></blockquote><p id="8177" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以用分位数来计算下限和上限。然后我们用下限代替小于下限的值，用上限代替大于上限的值。这也适用于左偏或右偏的数据。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="0b65" class="ml mm iq mh b gy mn mo l mp mq">fig, axes = plt.subplots(1,2)<br/>plt.tight_layout(0.2)<br/>print("Previous Shape With Outlier: ",X.shape)<br/>sns.boxplot(X['Pressure (millibars)'],orient='v',ax=axes[0])<br/>axes[0].title.set_text("Before")</span><span id="5d6b" class="ml mm iq mh b gy mr mo l mp mq">Q1 = X["Pressure (millibars)"].quantile(0.25)<br/>Q3 = X["Pressure (millibars)"].quantile(0.75)</span><span id="ed4d" class="ml mm iq mh b gy mr mo l mp mq">print(Q1,Q3)<br/>IQR = Q3-Q1<br/>print(IQR)</span><span id="38e6" class="ml mm iq mh b gy mr mo l mp mq">lower_limit = Q1 - 1.5*IQR<br/>upper_limit = Q3 + 1.5*IQR<br/>print(lower_limit,upper_limit)</span><span id="6445" class="ml mm iq mh b gy mr mo l mp mq">X2 = X</span><span id="8a56" class="ml mm iq mh b gy mr mo l mp mq">X2['Pressure (millibars)'] = np.where(X2['Pressure  (millibars)']&gt;upper_limit,upper_limit,X2['Pressure (millibars)'])</span><span id="3c72" class="ml mm iq mh b gy mr mo l mp mq">X2['Pressure (millibars)'] = np.where(X2['Pressure (millibars)'] &lt;lower_limit,lower_limit,X2['Pressure (millibars)'])</span><span id="d779" class="ml mm iq mh b gy mr mo l mp mq">print("Shape After Removing Outliers:", X2.shape)<br/>sns.boxplot(X2['Pressure (millibars)'],orient='v',ax=axes[1])<br/>axes[1].title.set_text("After")<br/>plt.show()</span></pre><p id="6d03" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/0bf45aab111f1afb3964381ab5b5795f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*U-UFwETO6FIC8g9ROmTreA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">施加IQR压力前后的箱线图</p></figure><p id="dc50" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们需要通过绘制箱线图来检查湿度中的异常值或异常值。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="d7a2" class="ml mm iq mh b gy mn mo l mp mq">humidity_df = pd.DataFrame(X2["Humidity"])<br/>humidity_df.boxplot()</span></pre><p id="8788" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/67667b879d7e724a87dc0e7685979d30.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*CPoc-iOVLYRHGm5GOXog9Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">湿度箱线图</p></figure><p id="c511" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到湿度为0.0。所以我们要检查有多少数据值是0.0。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="bb25" class="ml mm iq mh b gy mn mo l mp mq">X2[X2['Humidity'] == 0].shape[0]</span></pre><p id="39e3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">产量:22</p><p id="f663" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">鉴于地球的气候和天气条件，湿度不可能为零。出现这种异常的数据点数量也非常少，因此我们可以简单地删除它们。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="b1bf" class="ml mm iq mh b gy mn mo l mp mq">X2 = X2.drop(X2[X2['Humidity'] == 0].index)</span></pre><p id="9f40" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们完成了数据清理。</p><p id="91ad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通常，在数据清理之后，您可以继续进行数据转换。但在这里，我在分割数据之前进行了特征编码，因为这将消除为训练和测试数据单独进行特征编码的需要。稍后将解释在应用任何变换之前拆分数据集的原因。</p><h1 id="94ff" class="mx mm iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">2.特征编码-处理分类特征</h1><p id="3b97" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">分类特征是可以分组到类别中的数据。举个例子，我们可以拿性别、肤色等。我们需要将那些非数值转换成数值，以便训练机器学习模型。有两种处理分类数据的传统技术。</p><ol class=""><li id="5962" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr oe ly lz ma bi translated">一键编码</li><li id="3b58" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr oe ly lz ma bi translated">标签(整数)编码</li></ol><p id="5c58" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我将用天气历史数据集中的例子来解释这两点。我们的数据集中有两个分类列，Precip Type和Summary。让我们以“Precip类型”为例。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="f54c" class="ml mm iq mh b gy mn mo l mp mq">X2['Precip Type'].value_counts()</span></pre><p id="ee14" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/a9deaab3da181b03845237be5d3ff51c.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*cfv6BwQJED-r1-PW8LRiwQ.png"/></div></figure><p id="fda4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到‘Precip Type’中的数据值不是雨就是雪。所以Precip类型’是一个分类特征。</p><h2 id="52d6" class="ml mm iq bd my og oh dn nc oi oj dp ng lf ok ol ni lj om on nk ln oo op nm oq bi translated">一键编码</h2><p id="abb2" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">在这种方法中，分类特征被值为0或1的新特征所取代。Precip类型被新的特征雨和雪所取代，如下图所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/5fcc9a2389a9fc9c53badbcf98318cd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*mnzTeuhearJkEhr4x5I3gA.png"/></div></figure><h2 id="99d6" class="ml mm iq bd my og oh dn nc oi oj dp ng lf ok ol ni lj om on nk ln oo op nm oq bi translated">标签编码</h2><p id="9852" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">在这种技术中，每个分类值都被转换成一个数值。如下图所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/02877221acc2b80f4956779ea8949dcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*NDNOLxkdSQQiTnEPkcH_mg.png"/></div></figure><p id="80b3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于线性模型，一键编码更合适。如果我们对这种情况应用标签编码，那么模型将试图识别顺序，因为特征值类似于0、1、2、3等。但是如果是二进制类别，我们可以使用标签编码。</p><p id="a5aa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，因为Precip类型只有2个值，所以我可以使用标签编码。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="ab82" class="ml mm iq mh b gy mn mo l mp mq">X2['Precip Type']=X2['Precip Type'].astype('category')<br/>X2['Precip Type']=X2['Precip Type'].cat.codes</span></pre><p id="7736" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是如下图所示，summary有许多类别。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="c098" class="ml mm iq mh b gy mn mo l mp mq">final['Summary'].value_counts()</span></pre><p id="845e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/273b15ff24a2f75bbfa2cae2d682b213.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*PeFvbch_01uqH58zO1BIPw.png"/></div></figure><p id="88bf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以我们需要对汇总列进行一次性编码。<code class="fe ms mt mu mh b"><em class="mv">pd.get_dummies</em></code>将根据每个类别创建新的特性列，然后我们需要合并新的特性列并删除摘要列，如下面的代码所示。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="581c" class="ml mm iq mh b gy mn mo l mp mq">dummies_summary = pd.get_dummies(X2['Summary'])<br/>merged_summary = pd.concat([X2,dummies_summary],axis='columns')<br/>X2 = merged_summary.drop(['Summary'], axis='columns')<br/>X2</span></pre><p id="025e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ou"><img src="../Images/57e6097ac108bf3764f654508107923e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u8wvBqHrmnAkqKQcmv4dDQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">应用要素编码后的数据集</p></figure><h1 id="edb3" class="mx mm iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">3.分割数据集</h1><blockquote class="nw nx ny"><p id="91cb" class="kw kx mv ky b kz la jr lb lc ld ju le nz lg lh li oa lk ll lm ob lo lp lq lr ij bi translated">数据泄漏是指机器学习模型的创建者犯下的错误，其中他们意外地在测试和训练数据集之间共享信息。</p></blockquote><p id="3834" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我们对训练和测试数据集一起(对整个数据集)应用变换、离散化和缩放等时，可能会导致数据泄漏。为了缓解这个问题，我在转换之前分割数据集，以避免模型过度拟合。</p><p id="0fea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">表观温度是目标特征。因此，我们需要将其从要素数据集中分离并移除。这里，数据集分为80%用于训练，20%用于测试。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="efcd" class="ml mm iq mh b gy mn mo l mp mq">target_column = pd.DataFrame(final_summary['Apparent Temperature (C)'])</span><span id="4c10" class="ml mm iq mh b gy mr mo l mp mq">final_summary = final_summary.drop(['Apparent Temperature (C)'], axis='columns')</span><span id="5be0" class="ml mm iq mh b gy mr mo l mp mq">X_train, X_test, y_train, y_test = train_test_split(final_summary, target_column, test_size=0.2)</span></pre><p id="9cde" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">拆分数据集后，需要重置索引。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="fd58" class="ml mm iq mh b gy mn mo l mp mq">X_train=X_train.reset_index(drop=True)<br/>X_test=X_test.reset_index(drop=True)<br/>y_train=y_train.reset_index(drop=True)<br/>y_test=y_test.reset_index(drop=True)</span></pre><p id="ce3d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们可以分别对训练和测试数据集应用转换。</p><h1 id="79b4" class="mx mm iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">4.数据转换</h1><p id="eff2" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">真实数据集中的变量将遵循更偏态的分布。但是如果数据来自正态分布，那么机器学习模型可以学习得很好。因此，我们应该使用直方图和Q-Q图来检查这些变量是如何分布的。这里我只解释训练数据集的转换。同样的过程也应该应用于测试数据集。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="7b98" class="ml mm iq mh b gy mn mo l mp mq">X3 = X_train.copy() #copy of the training dataset <br/>Y3 = X_test.copy() #copy of the testing dataset </span><span id="eefc" class="ml mm iq mh b gy mr mo l mp mq">stats.probplot(X3["Temperature (C)"], dist="norm", plot=plt)plt.show()</span></pre><p id="711e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/3fcec0d3c647b747d97dac8ad74c7f7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*TJ3GFNwNWL2j6Rpdist7dQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">温度的Q-Q图</p></figure><p id="4a26" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">同样，对于所有特性，我们可以使用Q-Q图分析数据分布，以查看数据是否偏离了预期分布(红线)。这里我们可以看到温度呈正态分布。</p><p id="dadc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是当我们看到风速的Q-Q图时，我们可以看到数据是倾斜的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/b7fa07f98312bbcc33f17a6af2ae948b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*7DkNddAMEqeJfHLV4L0MPQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">风速的Q-Q图</p></figure><p id="2870" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后我们也可以绘制直方图。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="86ff" class="ml mm iq mh b gy mn mo l mp mq">X3.hist(figsize=(15,10))</span></pre><p id="910f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/2c64a977a3c9397e5d6a3b5d951fecf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TVjsVpuMhDV2pK0eVbQfmA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">训练数据的直方图</p></figure><p id="b974" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到湿度是左偏的，风速是右偏的。可见性也显示了一些左偏，但是在应用变换之后，它没有显示正态分布。所以我没有应用可见性的转换。</p><p id="eebb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于右偏的数据，我们应用对数变换，对于左偏的数据，我们可以应用指数变换。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="4062" class="ml mm iq mh b gy mn mo l mp mq">logarithm_transformer = FunctionTransformer(np.log1p)<br/>data_new1 = logarithm_transformer.transform(X3['Wind Speed (km/h)'])<br/>X3['Wind Speed (km/h)']=data_new1<br/>X3['Wind Speed (km/h)'].hist()</span></pre><p id="5156" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里我使用了<code class="fe ms mt mu mh b"><em class="mv">np.log1p</em></code>，因为风速值为0.0，而<em class="mv"> np.log </em>仅用于正数。</p><p id="d587" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/850a6177ad62f197f4c217b498c601c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*57BLGnD1PGPeMAMJh_3OTA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">应用对数变换后的风速直方图</p></figure><p id="d9a5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们可以看到风速呈正态分布。</p><p id="a8ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于湿度是左偏的，我们应用指数变换。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="7092" class="ml mm iq mh b gy mn mo l mp mq">exp_transformer = FunctionTransformer(np.exp)<br/>data_new2 = exp_transformer.transform(X3['Humidity'])<br/>X3['Humidity']=data_new2<br/>X3['Humidity'].hist()</span></pre><p id="d128" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/96c7c61d2113b6709fb77f6ddbc460ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*RdekQpvCKdDQmoAoAyzEVg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">应用指数变换后的湿度直方图</p></figure><p id="f499" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，我展示了直方图在转换后是如何变化的。</p><p id="8b82" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">风速:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pa"><img src="../Images/05e747a28a1fb68214aca3c8a05f1af0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eJccPU-uMskSo-P_kATl4g.png"/></div></div></figure><p id="feff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">湿度:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pb"><img src="../Images/0a7067431d7c411df2750b61873c398e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Uyqr9V63IuoPf_QxuCzZw.png"/></div></div></figure><p id="d5fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以从Q-Q图和直方图中看到，大声覆盖始终为0.0。因此，由于它没有影响，我们需要在训练和测试数据中消除噪声。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="382f" class="ml mm iq mh b gy mn mo l mp mq">X3 = X3.drop(['Loud Cover'], axis='columns')<br/>Y3 = Y3.drop(['Loud Cover'], axis='columns')</span></pre><p id="0e35" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于格式化日期是一个唯一的值，而每日摘要不是一个数值，它有如此多的不同值，我们可以将它们都删除。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="90f9" class="ml mm iq mh b gy mn mo l mp mq">X3 = X3.drop(columns=['Daily Summary','Formatted Date'])<br/>Y3 = Y3.drop(columns=['Daily Summary','Formatted Date'])</span></pre><h1 id="e63e" class="mx mm iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">5.特征缩放—标准化</h1><blockquote class="nw nx ny"><p id="6f10" class="kw kx mv ky b kz la jr lb lc ld ju le nz lg lh li oa lk ll lm ob lo lp lq lr ij bi translated">特征缩放指的是用于归一化独立变量的值的范围的方法。</p></blockquote><p id="4f47" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里我使用了标准化来进行缩放。标准化将数据转换为平均值0和单位标准差。这一步至关重要，因为它避免了模型受到大幅度变量显著影响的机会。</p><p id="3b9a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">标准化不适用于分类变量。因此，在对数字特征进行标准化之前，应该将它们放在一边。标准化也应该分别应用于训练和测试数据。</p><p id="f5eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，请注意，我仅将<code class="fe ms mt mu mh b"><em class="mv">scaler.fit()</em></code>用于训练数据，因为我们需要将用于训练数据集的相同参数(平均值和标准偏差)应用于训练数据集。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="c6e2" class="ml mm iq mh b gy mn mo l mp mq">X4 = X3.copy()<br/>Y4 = Y3.copy()</span><span id="b339" class="ml mm iq mh b gy mr mo l mp mq">to_std_train = X4[['Temperature (C)', 'Humidity','Wind Speed (km/h)', 'Wind Bearing (degrees)', 'Visibility (km)','Pressure (millibars)']].copy()<br/>to_std_test = Y4[['Temperature (C)', 'Humidity','Wind Speed (km/h)', 'Wind Bearing (degrees)', 'Visibility (km)','Pressure (millibars)']].copy()</span><span id="031b" class="ml mm iq mh b gy mr mo l mp mq">scaler = StandardScaler()<br/>scaler.fit(to_std_train)</span><span id="a09a" class="ml mm iq mh b gy mr mo l mp mq">train_scaled = scaler.transform(to_std_train)<br/>test_scaled = scaler.transform(to_std_test)</span><span id="c794" class="ml mm iq mh b gy mr mo l mp mq">std_df_train = pd.DataFrame(train_scaled, columns = to_std_train.columns)<br/>std_df_test = pd.DataFrame(test_scaled, columns = to_std_test.columns)</span><span id="33ec" class="ml mm iq mh b gy mr mo l mp mq">X4[['Temperature (C)', 'Humidity','Wind Speed (km/h)','Wind Bearing (degrees)','Visibility (km)','Pressure (millibars)']]=std_df_train<br/>Y4[['Temperature (C)', 'Humidity','Wind Speed (km/h)','Wind Bearing (degrees)','Visibility (km)','Pressure (millibars)']]=std_df_test</span></pre><p id="0bfd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">标准化数据后，我们可以使用相关矩阵进行相关分析。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="31ba" class="ml mm iq mh b gy mn mo l mp mq">sns.heatmap(std_df_train.corr(),annot=True);</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/2e8f2867bce3dcca5f2688bfddf10b64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*KL50uDOxzlJhXSYwyTmEEQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">相关矩阵</p></figure><p id="f934" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以知道湿度和温度之间有负相关关系。所以要回答这个问题<strong class="ky ir">湿度和温度之间有</strong>和<strong class="ky ir">的关系吗？是的。湿度和温度呈负相关。</strong></p><h1 id="75d6" class="mx mm iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">6.[数]离散化</h1><p id="4439" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">离散化用于将连续变量转换为离散变量。这里我们可以看到，当绘制风向直方图时，它不符合正态分布。当具有非标准概率分布的数值变量被离散化时，机器学习模型可以表现得更好。我已经用K-means离散化了风向。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="e710" class="ml mm iq mh b gy mn mo l mp mq">X5 = X4.copy()<br/>Y5 = Y4.copy()</span><span id="d407" class="ml mm iq mh b gy mr mo l mp mq">data1 = pd.DataFrame(X5, columns=['Wind Bearing (degrees)'])<br/>data1 = data1.dropna()<br/>data2 = pd.DataFrame(Y5, columns=['Wind Bearing (degrees)'])<br/>data2 = data2.dropna()</span><span id="643b" class="ml mm iq mh b gy mr mo l mp mq">discretizer = KBinsDiscretizer(n_bins=8, encode='ordinal', strategy='uniform')</span><span id="2c90" class="ml mm iq mh b gy mr mo l mp mq">discretizer.fit(data1)<br/>_discretize1 = discretizer.transform(data1)<br/>_discretize2 = discretizer.transform(data2)<br/>X_dis = pd.DataFrame(_discretize1)<br/>Y_dis = pd.DataFrame(_discretize2)<br/>X_dis.hist()</span></pre><p id="9476" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/1b846c9aa8410162e5b5b2f850e4d81d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*LcOcJVdcFGgLC7jcFdZH1A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">离散化后的风向直方图</p></figure><p id="3a10" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以绘制一个相关矩阵，以确定目标列(表观温度)的特征的重要性。</p><blockquote class="nw nx ny"><p id="9d52" class="kw kx mv ky b kz la jr lb lc ld ju le nz lg lh li oa lk ll lm ob lo lp lq lr ij bi translated">相关性是一种统计度量，表示两个或多个变量一起波动的程度。</p></blockquote><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="67b1" class="ml mm iq mh b gy mn mo l mp mq">X5['Wind Bearing (degrees)'] = X_dis</span><span id="841c" class="ml mm iq mh b gy mr mo l mp mq">d_data = X5[['Temperature (C)', 'Humidity','Wind Speed (km/h)','Wind Bearing (degrees)','Visibility (km)','Pressure (millibars)']].copy()</span><span id="22b0" class="ml mm iq mh b gy mr mo l mp mq">d_data['Apparent Temperature (C)'] = y_train<br/>d_data.head(10)<br/>print(d_data.corr())<br/>sns.heatmap(d_data.corr(),annot=True)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/aca0b9a0ecb5acfe3a72139f69bada3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*AZDoiXq5mmX6nuHzaqTNzg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">相关矩阵</p></figure><p id="d8c4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到，湿度和目标变量表观温度有着显著的高度相关性。所以回答问题<strong class="ky ir">湿度和表观温度之间有</strong> <strong class="ky ir">关系吗？是的。湿度和表观温度呈负相关。</strong></p><h1 id="bec7" class="mx mm iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">7.降维—主成分分析</h1><p id="07be" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">降维的重要性在于，我们可以通过去除冗余，只保留有用的信息来压缩数据集。太多的输入变量可能会导致维数灾难，然后模型将无法很好地执行，因为模型还会从训练数据集中的噪声中学习并过度拟合。</p><p id="2324" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">主成分分析是一种用于降维的强大技术，增加了可解释性，但同时最小化了信息损失。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="7d20" class="ml mm iq mh b gy mn mo l mp mq">pca = PCA(n_components=12)<br/>pca.fit(X5)<br/>X_train_pca = pca.transform(X5)<br/>X_test_pca = pca.transform(Y5)<br/>principalDf = pd.DataFrame(data = X_train_pca)<br/>principalDf.head(20)</span></pre><p id="85d9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pe"><img src="../Images/3624aa10ca7fa307dbe069ade14c4c26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_XF6LKG-Js8PfdCTWzyAgw.png"/></div></div></figure><p id="d06b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">参数<code class="fe ms mt mu mh b"><em class="mv">n_components</em></code>的值通过分析下面的<code class="fe ms mt mu mh b"><em class="mv">explained_component_ratio_</em></code>来决定。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="f080" class="ml mm iq mh b gy mn mo l mp mq">pca.explained_variance_ratio_</span></pre><p id="9e34" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pf"><img src="../Images/077773d0fc1ae0efb3d52bdb63eeba87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IqXmrYwNqWBW6_XcFycSIg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">PCA解释的方差比</p></figure><p id="3b74" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当决定使用主成分的数量时，我们应该考虑上述值。数组的第一个元素是高方差维数，我们应该认为高方差维数的总和约为0.95。这里我用了12个主要成分。</p><h1 id="05a6" class="mx mm iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">8.线性回归模型</h1><p id="f5fd" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">完成所有上述步骤后，将线性回归模型应用于数据集。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="0705" class="ml mm iq mh b gy mn mo l mp mq">lm = linear_model.LinearRegression()<br/>model = lm.fit(X_train_pca,y_train)</span></pre><h1 id="e621" class="mx mm iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">9.模型评估</h1><p id="5c9d" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">当我们评估我们的模型时，可以看到精度为0.990223。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="4af4" class="ml mm iq mh b gy mn mo l mp mq">accuracy = model.score(X_test_pca, y_test)<br/>print("Accuracy:", accuracy)</span></pre><p id="b860" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/d606c75aaa7f34bcba235d3f54004762.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*SsQNn8Wmv0L_LkBnglwt-w.png"/></div></figure><p id="160d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了进一步评估模型，我们使用均方差(MSE)。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="ca1c" class="ml mm iq mh b gy mn mo l mp mq">predictions = lm.predict(X_test_pca)<br/>y_hat = pd.DataFrame(predictions, columns=["predicted"])<br/>mse = mean_squared_error(y_test, y_hat)<br/>print('Test MSE: %.3f' % mse)</span></pre><p id="2b4d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/f37e48eb114c320935c086d061a614da.png" data-original-src="https://miro.medium.com/v2/resize:fit:426/format:webp/1*kWVvfbTTg9A4afLT_ZxL0w.png"/></div></figure><p id="ccc7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们也使用了计算的均方根误差(RMSE)。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="0e2a" class="ml mm iq mh b gy mn mo l mp mq">rmse = sqrt(mean_squared_error(y_test, y_hat))<br/>print('Test RMSE: %.3f' % rmse)</span></pre><p id="674c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/ae99fc182577bbfacba7a68fef13b162.png" data-original-src="https://miro.medium.com/v2/resize:fit:386/format:webp/1*k7vrUoYqMRJBIHxhVGqX5w.png"/></div></figure><p id="605b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以进行6重交叉验证。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="e0a2" class="ml mm iq mh b gy mn mo l mp mq">scores = cross_val_score(model, X_test_pca, y_test, cv=6)<br/>print("Cross-validated scores:", scores)</span></pre><p id="e013" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pj"><img src="../Images/d69b38e89e0c14e30d849f6e1a53740f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2wBYpoHY1u4O26mny8SuJQ.png"/></div></div></figure><p id="5ec6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">用下面的代码，我计算了交叉预测的准确性。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="0f60" class="ml mm iq mh b gy mn mo l mp mq">predictions = cross_val_predict(model, X_test_pca, y_test, cv=6)<br/>accuracy = metrics.r2_score(y_test, predictions)<br/>print("Cross-Predicted Accuracy:", accuracy)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/e586f4796a049a710e532c6df7582341.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*2zGswLTgUd1hqBzjAjPrkQ.png"/></div></figure><p id="3c62" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">模型的精度是好的。但是检查重量参数也很重要。</p><p id="400e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">权重参数是模型在新数据下表现良好的一个重要指标。如果权重参数较小，则意味着您的模型非常好，在没有数据的情况下会表现得更好。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="d249" class="ml mm iq mh b gy mn mo l mp mq">#W parameters of the model<br/>print(lm.coef_)</span></pre><p id="0ed9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pl"><img src="../Images/7a3266dc35dbf74ea71025e12671146a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5weN1oXdlQMBBhL6s1q3Iw.png"/></div></div></figure><p id="3e46" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，权重参数不是很低。但是我们可以通过识别和改变我们在预处理、转换等过程中所做的一些步骤来进一步减少它们。</p><p id="533d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以将模型的预测可视化如下。这里我只绘制了100个数据点的图表。</p><pre class="kg kh ki kj gt mg mh mi mj aw mk bi"><span id="4617" class="ml mm iq mh b gy mn mo l mp mq">plt.figure(figsize=(15, 7))<br/>plt.plot(y_hat[:100], label = "Predicted")<br/>plt.plot(y_test[:100], label = "Actual")<br/>plt.title('Predictions Vs Actual')<br/>plt.legend()<br/>plt.show()</span></pre><p id="cadf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pm"><img src="../Images/2f199ff0348dc9620296fc0ef1df523f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-UgTodn_p9dA6dtxRZf-qA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">预测与实际数据图</p></figure><h1 id="4a58" class="mx mm iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">10.结论</h1><p id="b5fd" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">在本文中，我向您提供了如何通过应用数据清理、数据转换、特征编码、特征缩放、离散化、维度缩减来构建机器学习模型的分步指南，并且我还评估了线性回归模型。</p><p id="50bf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我希望这篇文章能帮助你很好地理解我们应该遵循的重要步骤以及它们背后的主要概念，以建立一个好的机器学习模型。</p><p id="c771" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">编码快乐！</p><h1 id="0315" class="mx mm iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">11.Colab代码</h1><div class="pn po gp gr pp pq"><a href="https://colab.research.google.com/drive/1C4GlUeLKhiC-1aX0D63M88_Rw-K7nCTc?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="pr ab fo"><div class="ps ab pt cl cj pu"><h2 class="bd ir gy z fp pv fr fs pw fu fw ip bi translated">谷歌联合实验室</h2><div class="px l"><h3 class="bd b gy z fp pv fr fs pw fu fw dk translated">构建机器学习模型</h3></div><div class="py l"><p class="bd b dl z fp pv fr fs pw fu fw dk translated">colab.research.google.com</p></div></div><div class="pz l"><div class="qa l qb qc qd pz qe kp pq"/></div></div></a></div></div></div>    
</body>
</html>