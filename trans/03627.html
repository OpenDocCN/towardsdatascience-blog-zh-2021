<html>
<head>
<title>Pytorch Training Tricks and Tips</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pytorch培训技巧和提示</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pytorch-training-tricks-and-tips-a8808ebf746c?source=collection_archive---------15-----------------------#2021-03-24">https://towardsdatascience.com/pytorch-training-tricks-and-tips-a8808ebf746c?source=collection_archive---------15-----------------------#2021-03-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d978" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在Pytorch中优化深度学习模型训练的技巧/提示</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4b3828f332c6a048d6083bdfa6adc536.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9SmiFD9jYtYzbFtf"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae ky" href="https://unsplash.com/@actionvance?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> ActionVance </a>拍照</p></figure><p id="563d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我将描述并展示我个人发现的4种不同Pytorch训练技巧的代码，以改善我的深度学习模型的训练。</p><h2 id="f7cb" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">16位精度</h2><p id="1bdd" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在常规训练循环中，PyTorch以32位精度存储所有浮点变量。对于使用严格约束来训练他们的模型的人来说，有时，这可能导致他们的模型占用太多的内存，迫使他们使用较小的模型和较小的批量进行较慢的训练过程。但是，以16位精度存储模型中的所有变量/数字可以改善并修复大多数这些问题，例如显著降低模型的内存消耗并加快训练循环，同时仍然保持模型的相同性能/准确性。</p><p id="dd78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在Pytorch中将所有计算转换为16位精度非常简单，只需要几行代码。以下是方法:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="2393" class="lv lw it mu b gy my mz l na nb">scaler = torch.cuda.amp.GradScaler()</span></pre><p id="3153" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用和我上面一样的方法创建一个渐变缩放器。在你写你的训练循环之前这样做。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="cd48" class="lv lw it mu b gy my mz l na nb">optimizer.zero_grad()<br/>with torch.cuda.amp.autocast():<br/>   output = model(input).to(device)<br/>   loss = criterion(output, correct_answer).to(device)<br/>scaler.scale(loss).backward()<br/>scaler.step(optimizer)<br/>scaler.update()</span></pre><p id="b48e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当您使用loss和优化器进行反向传播时，您需要执行scaler.scale(loss)，而不是loss.backward()和optimizer.step()。向后和scaler.step(优化器)。这使得您的定标器可以转换所有梯度，并以16位精度进行所有计算。</p><p id="13af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当您以16位精度执行所有操作时，可能会出现一些数值不稳定的情况，从而导致您可能使用的一些函数无法正常工作。在16位精度下，只有某些操作才能正常工作。<a class="ae ky" href="https://pytorch.org/docs/stable/amp.html#ops-that-can-autocast-to-float16" rel="noopener ugc nofollow" target="_blank">这里</a>是这方面的更多信息。</p><h2 id="bdf8" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">进度条</h2><p id="28e3" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">有一个进度条来表示每个时期已经完成的训练的百分比是非常有用的。为了获得进度条，我们将使用tqdm库。以下是下载和导入它的方法:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="a7ea" class="lv lw it mu b gy my mz l na nb">pip install tqdm</span><span id="d223" class="lv lw it mu b gy nc mz l na nb">from tqdm import tqdm</span></pre><p id="8db6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在培训和验证循环中，您必须这样做:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="66f3" class="lv lw it mu b gy my mz l na nb">for index, batch in tqdm(enumerate(loader), total = len(loader), position = 0, leave = True):</span></pre><p id="6b3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">仅此而已。一旦您为您的训练和验证循环做了这些，您将得到一个进度条，它代表您的模型已经完成的训练的百分比。它应该是这样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/e9c2c37cee268bfcd05e0e3df78d23b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*Z3s4mejikjwKLyRQEwrz0w.png"/></div></figure><p id="774a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在图中，691表示我的模型必须完成多少批，7:28表示我的模型在691批上训练/评估所用的总时间，1.54 it/s表示我的模型一批所用的平均时间。</p><h2 id="7911" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">梯度累积</h2><p id="8151" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">如果您遇到CUDA内存不足错误，这意味着您已经超出了您的计算资源。要解决这个问题，您可以做几件事情，包括将所有内容转换为16位精度，正如我上面提到的，减少模型的批量大小，以及在创建数据加载器时减少num_workers参数:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="171b" class="lv lw it mu b gy my mz l na nb">train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, num_workers=0)</span></pre><p id="491d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，有时，切换到16位精度并减少num_workers可能无法完全解决问题。解决这个问题最直接的方法是减少批量，但是假设你不想减少批量。如果你不想减少你的批量，你可以使用梯度积累来刺激你想要的批量。请注意，CUDA内存不足问题的另一个解决方案是简单地使用多个GPU，但这是许多人无法实现的选项。</p><p id="58ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设您的机器/型号只能支持16的批处理大小，增加它会导致CUDA内存不足错误，而您想要32的批处理大小。梯度累积的工作方式是，以16的批量运行模型两次，累积为每批计算的梯度，最后在这两次正向传递和梯度累积后执行优化步骤。</p><p id="e34e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了理解梯度累积，重要的是理解在训练神经网络中完成了什么特定功能。假设您有以下训练循环:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="2923" class="lv lw it mu b gy my mz l na nb">model = model.train()<br/>for index, batch in enumerate(train_loader):<br/>    input = batch[0].to(device)<br/>    correct_answer = batch[1].to(device)<br/>    optimizer.zero_grad()<br/>    output = model(input).to(device)<br/>    loss = criterion(output, correct_answer).to(device)<br/>    loss.backward()<br/>    optimizer.step()</span></pre><p id="cacb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">查看上面的代码，需要记住的关键是loss.backward()创建并存储模型的渐变，但是optimizer.step()实际上更新权重。在调用optimizer累积梯度之前，调用loss.backward()两次。以下是如何在PyTorch中实现渐变累积:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="514e" class="lv lw it mu b gy my mz l na nb">model = model.train()<br/>optimizer.zero_grad()<br/>for index, batch in enumerate(train_loader):<br/>    input = batch[0].to(device)<br/>    correct_answer = batch[1].to(device)<br/>    output = model(input).to(device)<br/>    loss = criterion(output, correct_answer).to(device)<br/>    loss.backward()<br/>    if (index+1) % 2 == 0:<br/>       optimizer.step()<br/>       optimizer.zero_grad()</span></pre><p id="3de8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如您所见，以上面的例子为例，我们的机器只能支持16个批次，而我们想要32个批次，我们实际上是计算2个批次的梯度，然后更新实际重量。这导致有效的批量大小为32。</p><p id="63b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">做16位精度的梯度累加很像。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="ac68" class="lv lw it mu b gy my mz l na nb">model = model.train()<br/>optimizer.zero_grad()<br/>for index, batch in enumerate(train_loader):<br/>    input = batch[0].to(device)<br/>    correct_answer = batch[1].to(device)<br/>    with torch.cuda.amp.autocast():<br/>         output = model(input).to(device)<br/>         loss = criterion(output, correct_answer).to(device)<br/>    scaler.scale(loss).backward()<br/>    if (index+1) % 2 == 0:<br/>       scaler.step(optimizer)<br/>       scaler.update()<br/>       optimizer.zero_grad()</span></pre><h2 id="b6e8" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">对结果的评估</h2><p id="f14b" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在大多数机器学习项目中，人们倾向于手动计算他们用于评估的指标，然后报告它们。尽管计算准确度、精确度、召回率和F1等指标并不难，但在某些情况下，您可能希望使用这些指标的某些变体，如宏观/微观精确度、召回率和F1，或者加权精确度、召回率和F1。计算这些可能需要更多的工作，有时，您的实现可能是不正确的。要高效、快速、无误地计算所有这些指标，可以使用sklearns classification_report库。这是一个专门为计算这些指标而设计的库。这是你如何使用它。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="2a94" class="lv lw it mu b gy my mz l na nb">from sklearn.metrics import classification_report<br/>y_pred = [0, 1, 0, 0, 1]<br/>y_correct = [1, 1, 0, 1, 1]</span><span id="0dbe" class="lv lw it mu b gy nc mz l na nb">print(classification_report(y_correct, y_pred))</span></pre><p id="5085" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的代码是用于二进制分类的。您可以为更多目的配置/使用该功能。第一个列表代表模型的预测，第二个列表代表正确答案。上面的代码会输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/dbed13cc77aa7949be3c3a925b5c4c7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*CEwVZrN7kePYfwtrUwgbYQ.png"/></div></figure></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h2 id="255b" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">结论</h2><p id="632e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在这篇文章中，我讨论了4种优化深度神经网络训练的方法。16位精度减少了内存消耗，梯度累积允许您通过模拟更大的批处理大小来解决任何内存限制，tqdm进度条和sklearns分类报告库是两个方便的库，允许您轻松跟踪模型的训练并评估模型的性能。就我个人而言，我总是用上面所有的训练技巧来训练我的神经网络，并且在必要的时候使用梯度累积。</p><p id="929f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望您发现这些内容易于理解且信息丰富。如果你有任何问题，请在评论中告诉我。</p></div></div>    
</body>
</html>