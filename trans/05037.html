<html>
<head>
<title>Beginner guide to Variational Autoencoders (VAE) with PyTorch Lightning (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用PyTorch Lightning的可变自动编码器(VAE)初学者指南(第2部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/beginner-guide-to-variational-autoencoders-vae-with-pytorch-lightning-part-2-6b79ad697c79?source=collection_archive---------14-----------------------#2021-05-03">https://towardsdatascience.com/beginner-guide-to-variational-autoencoders-vae-with-pytorch-lightning-part-2-6b79ad697c79?source=collection_archive---------14-----------------------#2021-05-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/e88d994c515e85f67033405861c47571.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eFzoUZatvbK4m3zK"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">由<a class="ae kf" href="https://unsplash.com/@marcojodoin?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马克-奥利维尔·乔多因</a>在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="2f73" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇博客文章是一个迷你系列的一部分，该系列讨论了使用可变自动编码器构建PyTorch深度学习项目的不同方面。</p><blockquote class="le lf lg"><p id="1832" class="kg kh lh ki b kj kk kl km kn ko kp kq li ks kt ku lj kw kx ky lk la lb lc ld im bi translated"><a class="ae kf" rel="noopener" target="_blank" href="/beginner-guide-to-variational-autoencoders-vae-with-pytorch-lightning-13dbc559ba4b">第1部分</a>:数学基础与实现<br/> <a class="ae kf" rel="noopener" target="_blank" href="/beginner-guide-to-variational-autoencoders-vae-with-pytorch-lightning-part-2-6b79ad697c79">第2部分</a>:用PyTorch Lightning <br/> <a class="ae kf" rel="noopener" target="_blank" href="/beginner-guide-to-variational-autoencoders-vae-with-pytorch-lightning-part-3-9d686d0d85d9#1921-b4c73b02c87">增压第3部分</a>:卷积VAE、继承与单元测试<br/> <a class="ae kf" rel="noopener" target="_blank" href="/building-a-vae-playground-with-streamlit-aa88a3394c04">第4部分</a> : Streamlit Web App与部署</p></blockquote></div><div class="ab cl ll lm hx ln" role="separator"><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq lr"/><span class="lo bw bk lp lq"/></div><div class="im in io ip iq"><p id="1925" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在第1部分的<a class="ae kf" rel="noopener" target="_blank" href="/beginner-guide-to-variational-autoencoders-vae-with-pytorch-lightning-13dbc559ba4b">中，我们看了变分自动编码器，这是一个基于自动编码器的模型，但允许数据生成。我们了解了整体架构和实现细节，使它能够成功地学习。在这一节中，我们将讨论PyTorch Lightning (PL)，它为什么有用，以及我们如何使用它来构建我们的VAE。</a></p><h1 id="5854" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">PyTorch闪电是什么，为什么要用？</h1><p id="8661" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">简而言之，PyTorch lightning是PyTorch的一个附件，它使得训练模型更加简单。PyTorch Lightning模块具有默认的类方法，可以减少训练模型时所需的不必要的样板代码。在进行实验时，我们通常想做一些小的改变，这对于大的模型来说是非常困难的。除了简化代码，Pytorch Lightning还包含许多有用的功能，例如自动学习率查找。让我们看看如何将Pytorch代码翻译成Pytorch Lightning。</p><h1 id="f206" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">培训和验证步骤</h1><p id="a230" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">在一个标准的PyTorch类中，只有2个方法必须被定义:定义模型架构的<code class="fe mv mw mx my b">__init__</code>方法和定义向前传递的<code class="fe mv mw mx my b">forward</code>方法。所有其他操作(如数据集加载、训练和验证)都是在类外部运行的函数。</p><p id="c070" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在PyTorch Lightning中，我们使用<code class="fe mv mw mx my b">training_step</code>来定义训练步骤中发生的操作。这可能包括日志记录、损失计算和反向传播等操作。然而，当使用PyTorch Lightning时，所需的代码大大减少了，重用已经定义的类方法相当简单。</p><figure class="mz na nb nc gt ju"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="45bc" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">PL将调用<code class="fe mv mw mx my b">training_step</code>方法。基于在<code class="fe mv mw mx my b">training_step</code>中计算的损失，PL将反向传播损失，并计算梯度和优化模型权重。在上面的代码中，我们看到有一个<code class="fe mv mw mx my b">configure_optimizers</code>方法，这是一个简单的类方法，它返回将用于模型训练的优化器。与需要<code class="fe mv mw mx my b">optimizer.step()</code>和<code class="fe mv mw mx my b">loss.backward()</code>的普通PyTorch不同，这些步骤被抽象出来，作为<code class="fe mv mw mx my b">training_step</code>方法的一部分自动运行。</p><p id="b85f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">执行验证步骤几乎是相同的代码。函数反向传播将计算并返回验证损失，并且不会进行参数更新。</p><h1 id="0c88" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">PL培训师</h1><p id="667a" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">了解如何使用PyTorch Lightning的另一个重要补充是训练师课程。这个类对于将任何数据拟合到模型中是必不可少的。使用<code class="fe mv mw mx my b">trainer.fit(model,dataloader)</code>我们指定训练模型的数据。在实例化trainer对象时，我们还可以传递一些不同的参数来定义培训过程。</p><ul class=""><li id="e21c" class="nf ng it ki b kj kk kn ko kr nh kv ni kz nj ld nk nl nm nn bi translated">训练参数</li><li id="b250" class="nf ng it ki b kj no kn np kr nq kv nr kz ns ld nk nl nm nn bi translated">时代数</li><li id="89ab" class="nf ng it ki b kj no kn np kr nq kv nr kz ns ld nk nl nm nn bi translated">用于训练的GPU数量</li><li id="c53f" class="nf ng it ki b kj no kn np kr nq kv nr kz ns ld nk nl nm nn bi translated">auto _ lr _ find自动确定要使用的学习率。在不需要任何额外实验的情况下，快速建立基线和训练模型非常有用。</li></ul><figure class="mz na nb nc gt ju"><div class="bz fp l di"><div class="nd ne l"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">使用PyTorch闪电训练器拟合模型</p></figure><h1 id="f1fc" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">数据集加载</h1><p id="c883" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">例如，用于训练、验证和测试的数据源是固定的，我们可以通过在类中定义DataLoaders <strong class="ki iu">来进一步扩充LightningModule。</strong> PyTorch Lightning将自动从相应的数据加载器获取数据，并将其用于模型训练。</p><figure class="mz na nb nc gt ju"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="558a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意，我们可以简单地使用<code class="fe mv mw mx my b">trainer.fit(model)</code>，而不必为训练或验证指定数据加载器。在这种情况下，由于MNIST是一个公共数据集，<code class="fe mv mw mx my b">train_dataloader</code>的代码相对较短，但对于更复杂的例子，在将数据加载器转换成适合训练的格式之前，该步骤可能包括几个预处理操作。</p><h1 id="f82b" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">其他方法和回调</h1><p id="d6c5" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">现在你可能会想。</p><p id="9660" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">“我试图解决的问题并不简单，如果我需要解决该怎么办？”</p><ul class=""><li id="9a7b" class="nf ng it ki b kj kk kn ko kr nh kv ni kz nj ld nk nl nm nn bi translated">每个历元改变数据集</li><li id="b0c5" class="nf ng it ki b kj no kn np kr nq kv nr kz ns ld nk nl nm nn bi translated">降低学习率</li><li id="2518" class="nf ng it ki b kj no kn np kr nq kv nr kz ns ld nk nl nm nn bi translated">保存一些输出</li></ul><p id="3cf5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">幸运的是，<code class="fe mv mw mx my b">pl.LightningModule</code>基类有许多额外的方法来帮助执行任何可能有助于训练神经网络的操作。这里我们将实现<code class="fe mv mw mx my b">validation_epoch_end</code>。这将在每个时期后保存图像样本，以便我们验证我们的VAE模型是否训练正确。</p><p id="0bb6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe mv mw mx my b">validation_epoch_end</code>接收<code class="fe mv mw mx my b">validation_step</code>的所有输出。在<code class="fe mv mw mx my b">validation_step</code>中，前向调用的输出与损失一起返回。我们可以简单地从<code class="fe mv mw mx my b">x_out</code>中提取一个样本，将其重新整形为合适的大小，并将数组保存为图像。</p><figure class="mz na nb nc gt ju"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="1092" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除了使用额外的类方法，另一种定制训练过程的方法是使用回调。与类函数相比，回调包含非常相似的方法，但是更具可配置性。如果在整个训练周期的多个不同点调用回调，应该使用回调来防止重复相同的代码块。还有一些预构建的回调函数，可以执行常见的操作，比如保存模型检查点或执行提前停止。</p><h1 id="ccae" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">张量板跟踪</h1><p id="10aa" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">如果您之前注意到了，对于训练和验证步骤，我们使用<code class="fe mv mw mx my b">self.log()</code>。PyTorch Lightning使记录训练期间的不同指标变得极其容易，并且可以使用TensorBoard轻松访问这些数据。训练循环期间记录的所有值将存储在<code class="fe mv mw mx my b">lightning_logs</code>中。</p><figure class="mz na nb nc gt ju gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/36d25b6490f472cf2c5f2f02db0a809a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*IDWKLfpuiZ6cYCJmPy97Bg.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">使用张量板跟踪损失函数</p></figure><p id="b73f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过在终端中运行<code class="fe mv mw mx my b">tensorboard --logdir lightning_logs/</code>，可以可视化和监控记录的所有指标/损失。这有助于您跟踪不同的实验，并调整正在使用的一些超参数。</p><h1 id="f8d6" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">最终输出</h1><div class="mz na nb nc gt ab cb"><figure class="nu ju nv nw nx ny nz paragraph-image"><img src="../Images/050ff2bf9ae655e7887120a4b382d709.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*TwErmNaLLFdRHWcwtamgAg.png"/></figure><figure class="nu ju nv nw nx ny nz paragraph-image"><img src="../Images/1624b8eb9a33e676686049067e00d3f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*0yLwZQEs6b8Ni40SqfQqzA.png"/><p class="kb kc gj gh gi kd ke bd b be z dk oa di ob oc translated">比较第一个时期(左)和最后一个时期(右)期间的图像样本</p></figure></div><p id="0310" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">比较第一个和最后一个时期的图像，我们可以看到模型已经成功地从图像中学习。在左图中，大多数项目是模糊的，而右图中的数字明显更清晰。值得注意的一点是，图像仍然很模糊。关于VAEs的一个有趣的事情是，它们可以与更适合该任务的特性选择架构一起使用。在这个例子中，我们使用MNIST数字的扁平矢量表示，但这肯定不是最好的方法。对于计算机视觉任务，使用几个卷积层将允许更好的特征提取，并帮助模型获得明显更好的结果。在这种情况下，我们仍然能够获得不错的性能，因为MNIST是一个“简单”的数据集。使用卷积VAE将获得明显更好的娱乐损失性能，因为从瓶颈中提取的特征将更有用。</p><p id="97a0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">构建图像的VAE，可以从几层卷积步骤开始，取特征max展平矢量，用这个矢量获得瓶颈中的μ和σ矢量(参考<a class="ae kf" rel="noopener" target="_blank" href="/beginner-guide-to-variational-autoencoders-vae-with-pytorch-lightning-13dbc559ba4b"> Part 1 </a>)。为VAE执行正则化的神经网络架构仅出现在瓶颈处，并且该组件可以用于其他神经网络架构中。</p><p id="37f6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除了图像之外，VAEs还被成功地应用于许多不同的数据集，并且在自然语言处理(NLP)任务中取得了非常显著的效果。最近对VAEs的研究也产生了新的架构，如MMD-VAE和VQ-VAE，它们实现了更好的性能。有关不同VAE架构的更多信息，请查看下面的链接。</p><p id="465c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请随意查看GitHub上的完整代码，非常感谢您的任何反馈！</p><p id="826e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">github:【https://github.com/reoneo97/pytorch-lightning-vaeT2<br/>LinkedIn:<a class="ae kf" href="https://www.linkedin.com/in/reo-neo/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/reo-neo/</a></p><h1 id="89d2" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">有用的资源</h1><p id="2d54" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated"><strong class="ki iu"> (1)不同VAE架构的PyTorch实现</strong></p><div class="od oe gp gr of og"><a href="https://github.com/AntixK/PyTorch-VAE" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd iu gy z fp ol fr fs om fu fw is bi translated">安蒂克/皮托尔赫-VAE</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">pytorch中实现的一组可变自动编码器(vae ),重点关注再现性。这个的目的是…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">github.com</p></div></div><div class="op l"><div class="oq l or os ot op ou jz og"/></div></div></a></div><p id="0fb8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不同VAE架构的有用汇编，显示了各自的PyTorch实现和结果。</p><p id="a16f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> (2)神经离散表示学习</strong></p><div class="od oe gp gr of og"><a href="https://arxiv.org/abs/1711.00937" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd iu gy z fp ol fr fs om fu fw is bi translated">神经离散表示学习</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">在没有监督的情况下学习有用的表示仍然是机器学习中的一个关键挑战。在本文中，我们…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">arxiv.org</p></div></div></div></a></div><p id="b6f8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">关于矢量量化VAE (VQ-VAE)的论文。关于如何进一步改进离散数据的VAEs的有趣论文。强调VAEs存在的一些问题以及VQ-VAEs如何解决这些问题</p><p id="1ef6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> (3) MMD-VAE </strong></p><div class="od oe gp gr of og"><a href="https://ermongroup.github.io/blog/a-tutorial-on-mmd-variational-autoencoders/" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd iu gy z fp ol fr fs om fu fw is bi translated">信息最大化变分自动编码器教程</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">本教程讨论了MMD变分自动编码器(简称MMD-VAE)，InfoVAE家族的成员。这是一个…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">ermongroup.github.io</p></div></div><div class="op l"><div class="ov l or os ot op ou jz og"/></div></div></a></div><p id="0942" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一篇有趣的博文，讲述了一种不依赖KL散度损失函数来正则化潜在概率分布的不同方法。</p></div></div>    
</body>
</html>