<html>
<head>
<title>An Introduction to the Poisson Integer ARIMA Regression model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">泊松整数ARIMA回归模型简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-introduction-to-the-poisson-integer-arima-regression-model-b66d3ff2e6e5?source=collection_archive---------10-----------------------#2021-09-23">https://towardsdatascience.com/an-introduction-to-the-poisson-integer-arima-regression-model-b66d3ff2e6e5?source=collection_archive---------10-----------------------#2021-09-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/17d33ac3d2f62fb845076e18e8e2a6f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZLbEpuzjTm292W4LN3RiVQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片由<a class="ae jd" href="https://pixabay.com/users/clker-free-vector-images-3736/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=35104" rel="noopener ugc nofollow" target="_blank"> Clker-Free-Vector-Images </a>来自<a class="ae jd" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=35104" rel="noopener ugc nofollow" target="_blank"> Pixabay </a> ( <a class="ae jd" href="https://pixabay.com/service/license/" rel="noopener ugc nofollow" target="_blank"> Pixabay许可</a>)</p></figure><div class=""/><div class=""><h2 id="60aa" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">以及如何使用Python和statsmodels实现泊松INAR(1)回归模型的教程</h2></div><p id="6ef0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">整数ARIMA模型用于建模由整数计数组成的时间序列数据。</p><p id="90cd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这些数据集带来了一些独特的挑战:</p><p id="70dd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">数据是自相关的:</strong>时间序列数据通常是自相关的。我们为这些数据建立的任何模型都需要考虑这些序列相关性。ARIMA(自回归综合移动平均)模型旨在捕捉时间序列数据中的自相关性。</p><p id="1b7d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">数据仅由整数计数0、1、2、3…等组成。:</strong> ARIMA模型设计用于模拟实值时间序列数据，而不是基于计数的时间序列数据。基于计数的数据可以使用<a class="ae jd" rel="noopener" target="_blank" href="/an-illustrated-guide-to-the-poisson-regression-model-50cccba15958">泊松</a>和<a class="ae jd" rel="noopener" target="_blank" href="/generalized-poisson-regression-for-real-world-datasets-d1ff32607d79">类泊松</a>模型进行建模，例如<a class="ae jd" rel="noopener" target="_blank" href="/generalized-poisson-regression-for-real-world-datasets-d1ff32607d79">负二项式</a>和广义泊松模型。不幸的是，泊松和类泊松模型是静态模型，不是为处理相关时间序列数据而设计的。</p><blockquote class="lr"><p id="f4b3" class="ls lt jg bd lu lv lw lx ly lz ma lq dk translated">泊松整数ARIMA模型弥补了时间序列数据的ARIMA模型与基于计数的数据集的泊松和类泊松模型之间的差距。</p></blockquote><p id="50ec" class="pw-post-body-paragraph kv kw jg kx b ky mb kh la lb mc kk ld le md lg lh li me lk ll lm mf lo lp lq ij bi translated">正如我们将在下面看到的，在结构上，泊松风险模型的构建与ARIMA或泊松模型非常不同。</p><p id="24b4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本文中，我们将重点关注Brannas在<em class="mg">“AR(1)模型中的解释变量”</em>中介绍的<strong class="kx jh">泊松INAR(1) </strong>模型(参见文章底部的论文链接)。INAR(1)是具有1阶自回归分量的整数ARIMA模型，即，它仅使用第一时间滞后分量，<em class="mg"> y_(t-1)。泊松AR(1)使用泊松过程对误差分量建模。</em></p><p id="cef6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们检查泊松整数AR(1)模型的结构。我们将经常使用Cameron A.C .和P.K. Trivedi的《计数数据的回归分析》一书中所遵循的符号约定，以及该主题的一些原始论文。文章最后提到了书和论文的链接。</p><h1 id="abc1" class="mh mi jg bd mj mk ml mm mn mo mp mq mr km ms kn mt kp mu kq mv ks mw kt mx my bi translated">泊松INAR(1)模型的结构</h1><p id="e6eb" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">通用整数AR(1)模型表示如下:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/035d9f467ab21c7d050e4968b6cd98d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1xdHMahspz0J0-lvJi9tMw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">通用整数INAR(1)回归模型(图片由作者提供)</p></figure><p id="7754" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在INAR(1)模型中，我们将时间序列在时间<em class="mg"> t </em>的值express <em class="mg"> y_t </em>表示为两个量的和:</p><p id="ca7a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> <em class="mg"> ρ ○ y_(t-1): </em> </strong>这一项是时间序列在前一时间步<em class="mg"> (t-1)的值的函数。</em></p><p id="055a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> <em class="mg"> ε_t: </em> </strong>这是一个随机变量，代表隐藏的，因此也是未知的变量。我们将选择通过假设随机变量<em class="mg"> ε_t. </em>的某种已知概率分布(如正态分布或泊松分布)来模拟潜在变量的影响</p><p id="b005" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">第一项，<strong class="kx jh"><em class="mg">ρ○y _(t-1)</em></strong><em class="mg"/>值得补充说明。理解这个量的方法如下:</p><p id="316a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">假设我们正在对一个电子商务网站每天的点击数进行建模。这是计数的时间序列数据，人们可以合理地预期第<em class="mg"> t </em>天的点击次数与前几天的点击次数相关。</p><p id="17ab" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在假设在某一天<em class="mg"> t </em>，点击次数<em class="mg"> y_t =1000 </em>。再假设我们把这个数字1000看做1000个独立的，同分布的随机变量:<em class="mg"> b_1，b_2，b_3，…b_1000 </em>。每个变量<em class="mg"> b_i </em>遵循以下伯努利分布:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/b974a6e88aa33feb40c564dfb703c851.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*5wqbhKgKOvu98Lab-W6P9A.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">伯努利随机变量b_i(图片由作者提供)</p></figure><p id="c7b5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">所以我们可以把<em class="mg"> y_t=1000 </em>的值看做<em class="mg"> 1000次</em>独立伯努利试验，每一次的成功概率为<em class="mg"> ρ。</em>如果一次试验<em class="mg">‘成功’</em>，网站上就会记录一次点击。因此，一天t的预期点击数就是<em class="mg"> ρ乘以y _ t</em></p><p id="7d38" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在我们可以看到INAR(1)方程是如何模拟在时间索引<em class="mg"> t </em>的网站点击量的，即:</p><ul class=""><li id="46d5" class="nk nl jg kx b ky kz lb lc le nm li nn lm no lq np nq nr ns bi translated">在前一时间步<em class="mg"> (t-1) </em>的预期网站点击数，以及</li><li id="b939" class="nk nl jg kx b ky nt lb nu le nv li nw lm nx lq np nq nr ns bi translated">由随机变量<em class="mg"> ε_t. ε_t的实现值提供的对该期望值的<em class="mg">调整</em>用于对一些潜在数据生成过程建模。</em></li></ul><h2 id="68b1" class="ny mi jg bd mj nz oa dn mn ob oc dp mr le od oe mt li of og mv lm oh oi mx oj bi translated">泊松INAR(1)模型</h2><p id="ba8c" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">由于我们希望对整数计数的时间序列数据进行建模，因此假设基础(未知)数据生成过程是泊松过程是合适的。因此，<em class="mg">εt</em>是一个泊松分布的随机变量。</p><p id="8e12" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，<strong class="kx jh">泊松INAR(1)模型</strong>可以表示如下:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/321f0af2d5b2aedadf76d8464355d31f.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*2ZxLTEtNGblHdWcsOmuCCg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">泊松INAR(1)模型</p></figure><p id="e2ad" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">基本上，我们所说的是在时间<em class="mg"> t </em>观察到的值是前一时间步的期望值和假设泊松比为<em class="mg">μt</em>的泊松分布计数的组合。</p><h2 id="6fa2" class="ny mi jg bd mj nz oa dn mn ob oc dp mr le od oe mt li of og mv lm oh oi mx oj bi translated">如何处理回归变量</h2><p id="2f87" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">假设<strong class="kx jh"> <em class="mg"> X </em> </strong>为回归变量的矩阵，<strong class="kx jh"> <em class="mg"> β </em> </strong>为回归系数的向量，如下:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/4c7729a2ba09a0b63ff56dc1ba683936.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*BoEpz6NPfrs-bzTPUnPuHw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">回归变量矩阵<strong class="bd om"> <em class="on"> X </em> </strong>和回归系数向量<strong class="bd om"> β </strong>(图片由作者提供)</p></figure><p id="4856" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将泊松过程的平均发生率<em class="mg">μt</em>表示为下面的函数<strong class="kx jh"> <em class="mg"> X </em> </strong>和回归系数<strong class="kx jh"> <em class="mg"> β </em> </strong>如下:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/1d1f5f99590d8bb9c2346ad257a9a830.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*3387y37xdo-usCXqpMIdqA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">泊松平均指数(图片由作者提供)</p></figure><h1 id="fd2c" class="mh mi jg bd mj mk ml mm mn mo mp mq mr km ms kn mt kp mu kq mv ks mw kt mx my bi translated">估计</h1><p id="4bbb" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">估算包括估算<em class="mg"> ρ和</em> <strong class="kx jh"> <em class="mg"> β </em> </strong> <em class="mg">。</em>该领域的各种研究提出了许多估计技术，如最大似然估计、条件最小二乘法、加权最小二乘法和广义矩法。在<em class="mg">“AR(1)模型中的解释变量”</em>中，Brannas使用条件最小二乘法和条件广义矩方法技术进行参数估计。</p><p id="89ba" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本文中，我们将探讨使用最大似然估计(MLE)方法来估计<em class="mg"> ρ和</em><strong class="kx jh">β。 </strong>我们对MLE的选择很大程度上取决于<a class="ae jd" href="https://www.statsmodels.org/stable/index.html" rel="noopener ugc nofollow" target="_blank"> statsmodels </a>库中<a class="ae jd" href="https://www.statsmodels.org/stable/dev/generated/statsmodels.base.model.GenericLikelihoodModel.html" rel="noopener ugc nofollow" target="_blank"><strong class="kx jh">GenericLikelihoodModel</strong></a>类的存在。GenericLikelihoodModel类允许您指定您选择的自定义MLE函数，statsmodels将很乐意为您最大化该函数。</p><h2 id="cc72" class="ny mi jg bd mj nz oa dn mn ob oc dp mr le od oe mt li of og mv lm oh oi mx oj bi translated">泊松INAR(1)模型的极大似然估计</h2><p id="fc22" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">在最大似然法中，我们寻求将观察整个训练数据集的可能性最大化的值<em class="mg"> ρ和</em><strong class="kx jh"><em class="mg">【β】</em></strong>。具体来说，我们希望找到<em class="mg"> ρ和</em> <strong class="kx jh"> <em class="mg"> β </em> </strong>，这将最大化<em class="mg"> t=1到n </em> <strong class="kx jh"> <em class="mg">中<em class="mg"> y_t </em>的联合出现概率的自然对数。</em> </strong>就符号而言，我们希望最大化以下对数似然函数:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi op"><img src="../Images/347ccee7d4d738cab282b854d5b80a65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*Y3Nde14JowRENZuPDxZ-aw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">对数似然函数(作者图片)</p></figure><p id="936c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在实践中，我们通过使用以下规则将乘积的对数转换为各个概率的对数之和:</p><p id="163d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="mg">ln(A * B * C * D *……)= ln(A)+ln(B)+ln(C)+ln(D)+……</em></p><p id="ea97" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最大化<em class="mg">ℓ(⍴；</em><strong class="kx jh"><em class="mg">β</em></strong><em class="mg">|</em><strong class="kx jh"><em class="mg">y</em></strong><em class="mg">)</em>，我们需要构造条件概率分布<em class="mg"> P(y_t|y_(t-1)) </em>。让我们看看如何做到这一点。</p><h2 id="842a" class="ny mi jg bd mj nz oa dn mn ob oc dp mr le od oe mt li of og mv lm oh oi mx oj bi translated">泊松INAR(1)分布随机变量的概率质量函数</h2><p id="b868" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">让我们来看看泊松INAR(1)模型的方程:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/321f0af2d5b2aedadf76d8464355d31f.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*2ZxLTEtNGblHdWcsOmuCCg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">泊松INAR(1)模型</p></figure><p id="81fa" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们看到<em class="mg"> y_t </em>由两部分组成:y_(t-1) 的期望值和一个泊松分布变量<em class="mg"> ε_t </em>。因此，给定<em class="mg"> y_(t-1) </em>，观察到<em class="mg"> y_t </em>的概率可以表示为两个概率的乘积:</p><ol class=""><li id="8833" class="nk nl jg kx b ky kz lb lc le nm li nn lm no lq oq nq nr ns bi translated">从<em class="mg"> y_(t-1) </em>个可能事件中观察到<em class="mg"> j </em>个‘事件’的二项概率，接下来，</li><li id="5889" class="nk nl jg kx b ky nt lb nu le nv li nw lm nx lq oq nq nr ns bi translated">观察<em class="mg">(y _ t—j)</em>‘事件’的泊松概率。</li></ol><p id="0f2f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于我们不知道<em class="mg"> j </em>是什么，所以我们允许<em class="mg"> j </em>的范围从<em class="mg"> 0 </em>到<em class="mg"> y_t(实际上是</em>，从<em class="mg"> 0 </em>到<em class="mg"> min(y_t，y_(t-1) </em>，但这是一个技术问题，所以一切仍然有意义)。对于<em class="mg"> j </em>的每个值，我们在(1)和(2)中计算上述两个概率的乘积。最后，我们将所有单个产品总结如下:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi or"><img src="../Images/eaf7e87584d90c822c3854b5bbe618e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FNjC7tMkbM6Whz6cYHCT4Q.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">泊松INAR(1)分布随机变量的PMF(图片由作者提供)</p></figure><p id="40bd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">上面的等式所表示的是，在时间步长<em class="mg"> t </em>观察到前一时间步长<em class="mg"> y_(t-1) </em>的<em class="mg"> y_t </em>的概率，等于观察到<em class="mg"> y_(t-1) </em>事件中的<em class="mg"> 0 </em>事件的二项式概率和观察到<em class="mg"> y_t </em>事件的泊松概率，或者说，观察到<em class="mg"> 1 </em>事件中的二项式概率</p><p id="a93f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们回忆一下，在上面的等式中，泊松过程的平均发生率<em class="mg"> μ_t是</em>表示为<em class="mg">回归变量</em> <strong class="kx jh"> <em class="mg"> x_t </em> </strong>和回归系数<strong class="kx jh"> <em class="mg"> β </em> </strong>的如下函数:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/1d1f5f99590d8bb9c2346ad257a9a830.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*3387y37xdo-usCXqpMIdqA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">泊松平均指数(图片由作者提供)</p></figure><p id="23d9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们还记得<em class="mg"> ρ </em>是二项概率，在做MLE时，我们不希望<em class="mg"> ρ </em>出界。因此，我们定义另一个变量γ，使得:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi os"><img src="../Images/74262913397e9bd86649f8d588f40e8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*xMxQEqcc5IA5HiomqFdEmQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">逻辑函数(图片由作者提供)</p></figure><p id="3966" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">上述逻辑函数确保当γ的范围从-∞到+∞时，伯努利概率<em class="mg"> ρ </em>保持有界在<em class="mg"> [0，1]内。</em></p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ot"><img src="../Images/fbf1471eaefebe844aa71e8002d15db9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GeHltxYP7GHxeo8_LBvQ5Q.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">逻辑函数(图片由作者提供)</p></figure></div><div class="ab cl ou ov hu ow" role="separator"><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz"/></div><div class="ij ik il im in"><h1 id="fb3a" class="mh mi jg bd mj mk pb mm mn mo pc mq mr km pd kn mt kp pe kq mv ks pf kt mx my bi translated">如何使用Python和Statsmodels构建和训练泊松INAR(1)</h1><p id="ef12" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">我们将使用STRIKES数据集说明泊松INAR(1)模型的使用过程:</p><h2 id="8e4a" class="ny mi jg bd mj nz oa dn mn ob oc dp mr le od oe mt li of og mv lm oh oi mx oj bi translated">制造业罢工数据集</h2><p id="6927" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">为了说明模型拟合过程，我们将使用以下在回归建模文献中广泛使用的开源数据集:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pg"><img src="../Images/99b6110b1a9f623b729774b48757d5f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*UAq9UvItuyUVKm2llWDWTg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">制造业罢工(数据来源:<a class="ae jd" href="https://www.bls.gov/" rel="noopener ugc nofollow" target="_blank">美国BLS </a>通过<a class="ae jd" href="https://github.com/vincentarelbundock/Rdatasets/blob/master/datasets.csv#L609" rel="noopener ugc nofollow" target="_blank"> R数据集</a>)</p></figure><p id="f968" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该数据集是一个月度时间序列，显示了从1968年到1976年每月开始的美国制造业活动与美国制造业合同罢工数量之间的关系。</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ph"><img src="../Images/e9849fc4461ddf78fbffe14dd2a18de4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XtJIyBpMIvNJxT9ZUTZgww.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">STRIKES数据集(来源:<a class="ae jd" href="https://github.com/vincentarelbundock/Rdatasets/blob/master/datasets.csv#L609" rel="noopener ugc nofollow" target="_blank"> R数据集</a>)(图片由<a class="ae jd" href="https://sachin-date.medium.com/" rel="noopener">作者</a>)</p></figure><p id="e9c6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这个数据集在R中可用，可以使用<a class="ae jd" href="https://www.statsmodels.org/devel/datasets/index.html" rel="noopener ugc nofollow" target="_blank"> statsmodels数据集包</a>获取。</p><p id="0324" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因变量<strong class="kx jh"> <em class="mg"> y </em> </strong>为<em class="mg">击</em>。</p><p id="64b0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将从导入所有必需的包开始:</p><pre class="nf ng nh ni gt pi pj pk pl aw pm bi"><span id="625f" class="ny mi jg pj b gy pn po l pp pq"><strong class="pj jh">import </strong>math<br/><strong class="pj jh">import </strong>numpy <strong class="pj jh">as </strong>np<br/><strong class="pj jh">import </strong>statsmodels.api <strong class="pj jh">as </strong>sm<br/><strong class="pj jh">from </strong>statsmodels.base.model <strong class="pj jh">import </strong>GenericLikelihoodModel<br/><strong class="pj jh">from </strong>scipy.stats <strong class="pj jh">import </strong>poisson<br/><strong class="pj jh">from </strong>scipy.stats <strong class="pj jh">import </strong>binom<br/><strong class="pj jh">from </strong>patsy <strong class="pj jh">import </strong>dmatrices<br/><strong class="pj jh">import </strong>statsmodels.graphics.tsaplots <strong class="pj jh">as </strong>tsa<br/><strong class="pj jh">from </strong>matplotlib <strong class="pj jh">import </strong>pyplot <strong class="pj jh">as </strong>plt</span></pre><p id="a0a9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们使用statsmodels将数据集加载到内存中:</p><pre class="nf ng nh ni gt pi pj pk pl aw pm bi"><span id="df36" class="ny mi jg pj b gy pn po l pp pq">strikes_dataset = sm.datasets.<strong class="pj jh">get_rdataset</strong>(dataname=<strong class="pj jh">'StrikeNb'</strong>, package=<strong class="pj jh">'Ecdat'</strong>)</span></pre><p id="9834" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">打印出数据集:</p><pre class="nf ng nh ni gt pi pj pk pl aw pm bi"><span id="3967" class="ny mi jg pj b gy pn po l pp pq"><strong class="pj jh">print</strong>(strikes_dataset.<strong class="pj jh">data</strong>)</span></pre><p id="bad4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们看到以下输出:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pg"><img src="../Images/75e29ce0b4d6a74bcc163a48b92e1772.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*NkHEbEXkp2IcsOhMOZePpg.png"/></div></div></figure><p id="5d05" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将前92个数据点视为训练集，其余16个数据点视为测试数据集:</p><pre class="nf ng nh ni gt pi pj pk pl aw pm bi"><span id="9ca1" class="ny mi jg pj b gy pn po l pp pq">strikes_data = strikes_dataset.<strong class="pj jh">data</strong>.<strong class="pj jh">copy</strong>()<br/>strikes_data_train = strikes_data.<strong class="pj jh">query</strong>(<strong class="pj jh">'time&lt;=92'</strong>)</span><span id="d3aa" class="ny mi jg pj b gy pr po l pp pq">strikes_data_test = strikes_data.<strong class="pj jh">query</strong>(<strong class="pj jh">'time&gt;92'</strong>).<strong class="pj jh">reset_index</strong>().<strong class="pj jh">drop</strong>(<strong class="pj jh">'index'</strong>, <strong class="pj jh">axis</strong>=1)</span></pre><p id="c6be" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这是我们的回归表达式。<em class="mg">罢工</em>是因变量，<em class="mg">产出</em>是我们的解释变量。假设回归截距存在:</p><pre class="nf ng nh ni gt pi pj pk pl aw pm bi"><span id="756f" class="ny mi jg pj b gy pn po l pp pq">expr = <strong class="pj jh">'strikes ~ output'</strong></span></pre><p id="9914" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将使用<a class="ae jd" href="https://patsy.readthedocs.io/en/latest/quickstart.html" rel="noopener ugc nofollow" target="_blank"> Patsy </a>来雕刻出<strong class="kx jh"> <em class="mg"> X </em> </strong>和<strong class="kx jh"> <em class="mg"> y </em> </strong>矩阵。Patsy将自动添加一个回归截距列到<strong class="kx jh"> <em class="mg"> X </em> </strong>:</p><pre class="nf ng nh ni gt pi pj pk pl aw pm bi"><span id="904e" class="ny mi jg pj b gy pn po l pp pq">y_train, X_train = <strong class="pj jh">dmatrices</strong>(expr, strikes_data_train, <strong class="pj jh">return_type</strong>=<strong class="pj jh">'</strong>dataframe<strong class="pj jh">'</strong>)<br/><strong class="pj jh">print</strong>(y_train)<br/><strong class="pj jh">print</strong>(X_train)</span><span id="c02d" class="ny mi jg pj b gy pr po l pp pq">y_test, X_test = <strong class="pj jh">dmatrices</strong>(expr, strikes_data_test, <strong class="pj jh">return_type</strong>=<strong class="pj jh">'</strong>dataframe<strong class="pj jh">'</strong>)<br/><strong class="pj jh">print</strong>(y_test)<br/><strong class="pj jh">print</strong>(X_test)</span></pre><p id="2212" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，我们将扩展GenericLikelihoodModel:</p><pre class="nf ng nh ni gt pi pj pk pl aw pm bi"><span id="b8e0" class="ny mi jg pj b gy pn po l pp pq"><strong class="pj jh">class </strong>INAR(GenericLikelihoodModel):<br/>    <strong class="pj jh">def </strong>__init__(self, endog, exog, **kwds):<br/>        super(INAR, self).__init__(endog, exog, **kwds)</span></pre><p id="3687" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我们的扩展中，我们将覆盖<em class="mg"> nloglikeobs() </em>和<em class="mg"> fit() </em>方法。statsmodels调用<em class="mg"> nloglikeobs() </em>方法来获取每个观测值的对数似然值<em class="mg"> y_t. </em>因此，我们之前描述的泊松INAR(1)的似然函数进入该方法。该方法返回一个对数似然数组，由statsmodels提供的超类对该数组中的所有值求和，以获得由statsmodels的优化器优化的总对数似然值。</p><pre class="nf ng nh ni gt pi pj pk pl aw pm bi"><span id="5b8b" class="ny mi jg pj b gy pn po l pp pq"><strong class="pj jh">class PoissonINAR</strong>(GenericLikelihoodModel):<br/>    <strong class="pj jh">def </strong>__init__(self, endog, exog, **kwds):<br/>        super(INAR, self).__init__(endog, exog, **kwds)<br/><br/>    <strong class="pj jh">def </strong>nloglikeobs(self, params):<br/>        <strong class="pj jh"><em class="mg">#Fetch the parameters gamma and beta <br/>        #that we would be optimizing</em></strong><em class="mg"><br/>        </em>gamma = params[-1]<br/>        beta = params[:-1]<br/>        <br/><strong class="pj jh">        <em class="mg">#Set y and X<br/></em></strong><em class="mg">        </em>y = self.endog<br/>        y = np.array(y)<br/>        X = self.exog<br/>        <br/><strong class="pj jh">        <em class="mg">#Compute rho as a function of gamma<br/></em></strong><em class="mg">        </em>rho = 1.0/(1.0+math.exp(-gamma))<br/>        <br/><strong class="pj jh">        <em class="mg">#Compute the Poisson mean mu as a dot <br/>        #product of X and Beta<br/></em></strong><em class="mg">        </em>mu = np.exp(X.dot(beta))<br/><br/><strong class="pj jh">        <em class="mg">#Init the list of log-likelihhod values, <br/>        #one value for each y<br/></em></strong><em class="mg">        </em>ll = []<br/><br/><strong class="pj jh">        <em class="mg">#Compute all the log-likelihood values for <br/>        #the Poisson INAR(1) model<br/></em></strong><em class="mg">        </em><strong class="pj jh">for </strong>t <strong class="pj jh">in </strong>range(len(y)-1,0,-1):<br/>            prob_y_t = 0<br/>            <strong class="pj jh">for </strong>j <strong class="pj jh">in </strong>range(int(min(y[t], y[t-1])+1)):<br/>                prob_y_t += poisson.pmf((y[t]-j), mu[t]) *  <br/>                            binom.pmf(j, y[t-1], rho)<br/>            ll.append(math.log(prob_y_t))<br/>        ll = np.array(ll)</span><span id="bf32" class="ny mi jg pj b gy pr po l pp pq"><strong class="pj jh">        <em class="mg">#return the negated array of log-likelihoods<br/></em></strong><em class="mg">        </em><strong class="pj jh">return </strong>-ll</span></pre><p id="f7b3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们也实现一下<em class="mg"> model.fit() </em>方法:</p><pre class="nf ng nh ni gt pi pj pk pl aw pm bi"><span id="0ce7" class="ny mi jg pj b gy pn po l pp pq"><strong class="pj jh">def </strong>fit(self, <strong class="pj jh">start_params</strong>=None, <strong class="pj jh">maxiter</strong>=1000, <strong class="pj jh">maxfun</strong>=5000, **kwds):<br/><strong class="pj jh">    <em class="mg">#Add the gamma parameter to the list of <br/>    #exogneous variables that the model will optimize<br/></em></strong><em class="mg">    </em>self.exog_names.append(<strong class="pj jh">'gamma'</strong>)</span><span id="ebe0" class="ny mi jg pj b gy pr po l pp pq">    <strong class="pj jh">if </strong>start_params == <strong class="pj jh">None</strong>:<br/><strong class="pj jh">        <em class="mg">#Start with some initial values of Beta and gamma<br/></em></strong><em class="mg">        </em>start_params = np.append(np.ones(self.exog.shape[1]), 1.0)</span><span id="0a69" class="ny mi jg pj b gy pr po l pp pq"><strong class="pj jh"><em class="mg">#Call super.fit() to start the training<br/></em></strong><em class="mg">    </em><strong class="pj jh">return </strong>super(<strong class="pj jh">PoissonINAR</strong>, self).fit(<strong class="pj jh">start_params</strong>=start_params,<br/>               <strong class="pj jh">maxiter</strong>=maxiter, <strong class="pj jh">maxfun</strong>=maxfun, **kwds)</span></pre><p id="19c2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们创建泊松INAR(1)模型类的实例，并在训练数据集上对其进行训练:</p><pre class="nf ng nh ni gt pi pj pk pl aw pm bi"><span id="ae32" class="ny mi jg pj b gy pn po l pp pq">inar_model = <strong class="pj jh">PoissonINAR</strong>(y_train, X_train)<br/>inar_model_results = inar_model.<strong class="pj jh">fit</strong>()</span></pre><p id="299f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">打印模型培训总结:</p><pre class="nf ng nh ni gt pi pj pk pl aw pm bi"><span id="d071" class="ny mi jg pj b gy pn po l pp pq"><strong class="pj jh">print</strong>(inar_model_results.<strong class="pj jh">summary</strong>())</span></pre><p id="540f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们看到以下输出:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ps"><img src="../Images/1ede51aff0437450dffe460713fd22b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oCl_f2nZy9XPu61-Cxi1AA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">泊松INAR(1)模型的训练总结(图片由作者提供)</p></figure><h2 id="fc47" class="ny mi jg bd mj nz oa dn mn ob oc dp mr le od oe mt li of og mv lm oh oi mx oj bi translated">回归系数的显著性</h2><p id="60da" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">输出变量和gamma的系数在95%的置信区间都是显著的，正如它们的p值小于0.05所证明的。显著不同于零的回归截距也是如此:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pt"><img src="../Images/9f8a009531ae78bbf2016cd66e7bd969.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FGi0LvNFHQRy_sfO-BJlYw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">回归系数的重要性(图片由作者提供)</p></figure><h2 id="5359" class="ny mi jg bd mj nz oa dn mn ob oc dp mr le od oe mt li of og mv lm oh oi mx oj bi translated">回归系数的解释</h2><p id="5a1a" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">系数的解释是<em class="mg">而不是</em>简单明了。伽马为-0.7039，对应于1/(1+exp(0.7039)) = 0.33095的<em class="mg"> ρ </em>。</p><p id="5219" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">估算的<em class="mg"> β </em> <strong class="kx jh"> <em class="mg"> </em> </strong>为2.6215。</p><p id="6ef3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">拟合模型的方程式为:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pu"><img src="../Images/8e6cc839b3eaff379e7cad5db1efaf8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yko4oZq2Kos4Y0JYA8tolg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">拟合泊松INAR(1)回归模型的方程(图片由作者提供)</p></figure><p id="a9a1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于任意给定的<em class="mg"> t </em>，0.33095(大约33%)的<em class="mg"> y_(t-1) </em>构成<em class="mg"> y_t </em>。其余的来自泊松过程的估计平均值<em class="mg"> μ_t </em>，它是时间<em class="mg"> t </em>的输出和估计的<strong class="kx jh"> <em class="mg"> β </em> </strong>向量的函数。</p><h2 id="76cb" class="ny mi jg bd mj nz oa dn mn ob oc dp mr le od oe mt li of og mv lm oh oi mx oj bi translated">测量产量变化对罢工频率的影响</h2><p id="ad60" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">从模型方程中，很容易看出，观察到的撞击次数随着制造产量的增加而增加。我们可能想通过它们增加了多少来衡量。</p><p id="912f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在训练数据集中，“输出”变量的标准偏差为0.05654。通过打印以下内容可以看到这一点:</p><pre class="nf ng nh ni gt pi pj pk pl aw pm bi"><span id="9d01" class="ny mi jg pj b gy pn po l pp pq">strikes_data_train['output'].<strong class="pj jh">std</strong>()</span></pre><p id="e9e5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在假设我们考虑<em class="mg"> y_t </em>的两个假设值，即<em class="mg"> y_t1 </em>和<em class="mg"> y_t2 </em>，使得它们各自之前的值<em class="mg">y _(T1–1)</em>和<em class="mg">y _(T2–1)</em>恰好相同。由于<em class="mg"> β </em> =2.6215 <strong class="kx jh"> <em class="mg">，</em> </strong>“输出”增加一个标准差，将导致泊松过程的估计均值波动e^(2.6215*0.05654) = 1.15977，即大约16%。因此，产量中一个标准差的增加会导致每月观察到的罢工次数增加16%。</p><h2 id="e424" class="ny mi jg bd mj nz oa dn mn ob oc dp mr le od oe mt li of og mv lm oh oi mx oj bi translated">泊松INAR(1)模型的拟合优度</h2><p id="82c6" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">模型方程中的滞后项<em class="mg"> y_(t-1) </em>使得拟合优度的确定变得复杂。泊松INAR(1)模型的非线性排除了使用基于均方误差的测量，例如R平方。另一方面，由于MLE用于模型拟合，基于偏差的测量，例如<a class="ae jd" rel="noopener" target="_blank" href="/the-complete-guide-to-r-squared-adjusted-r-squared-and-pseudo-r-squared-4136650fc06c"><strong class="kx jh"/></a>和<a class="ae jd" href="https://en.wikipedia.org/wiki/Likelihood-ratio_test" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jh">卡方分布似然比(LR)测试</strong> </a>可用于判断拟合优度。然而，伪r平方和LR检验都需要计算零模型(也称为仅截距模型)的对数似然(LL)。在泊松INAR(1)模型中，由于模型方程中滞后项<em class="mg"> y_(t-1) </em>的存在，零模型的构成并不十分明显，还存在争议。</p><p id="a317" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">考虑到这些困难，人们可能希望通过间接方式判断拟合优度，特别是通过检查拟合模型参数的标准误差和相应的95%置信区间。</p><p id="5f91" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在对“罢工”模型采用这种方法时，我们观察到以下情况:</p><p id="7bdc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="mg"> ρ </em>的95%置信区间范围为1/(1+exp(1.174))=0.23613至1/(1+exp(0.233))=0.44201，与1/(1+exp(0.7039)) = 0.33095的<em class="mg"> ρ </em>拟合值相当接近。</p><p id="af8d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">不幸的是,“输出”变量有一个相当大的标准误差1.126和相应的宽置信区间0.415到4.828。正如我们在上一节所看到的，它对“打击”的影响很弱。这对模型的拟合优度有不利影响。</p><h2 id="c713" class="ny mi jg bd mj nz oa dn mn ob oc dp mr le od oe mt li of og mv lm oh oi mx oj bi translated">预言；预测；预告</h2><p id="87f4" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">该模型允许提前一步做出预测。预测包括在<strong class="kx jh"> <em class="mg"> X </em> </strong>矩阵和<strong class="kx jh"> <em class="mg"> y </em> </strong>的滞后值上运行拟合的模型。我们将在<strong class="kx jh"> <em class="mg"> X_test </em> </strong>和<strong class="kx jh"> <em class="mg"> y </em> </strong> <em class="mg">的滞后值上运行拟合的模型。</em>为此，我们将在statsmodels中的model.py上实现<em class="mg"> predict() </em>方法，如下所示:</p><pre class="nf ng nh ni gt pi pj pk pl aw pm bi"><span id="d960" class="ny mi jg pj b gy pn po l pp pq"><strong class="pj jh">def </strong>predict(self, <strong class="pj jh">params</strong>, <strong class="pj jh">exog</strong>=None, *<strong class="pj jh">args</strong>, **<strong class="pj jh">kwargs</strong>):<br/><strong class="pj jh">    <em class="mg">#Fetch the optimized values of parameters gamma and beta<br/></em></strong><em class="mg">    </em>fitted_gamma = params[-1]<br/>    fitted_beta = params[:-1]</span><span id="6fb3" class="ny mi jg pj b gy pr po l pp pq"><strong class="pj jh">    <em class="mg">#Compute rho as a function of gamma<br/></em></strong><em class="mg">    </em>rho = 1.0/(1.0+math.exp(-fitted_gamma))</span><span id="06ed" class="ny mi jg pj b gy pr po l pp pq"><strong class="pj jh">    <em class="mg">#Get the Intercept and the regression variables,<br/>    #Don't get the last column which contains the lagged y values<br/></em></strong><em class="mg">    </em>X = exog[:,:-1]<br/><strong class="pj jh">    <em class="mg">#Fetch the lagged y values<br/></em></strong><em class="mg">    </em>y_lag_1 = exog[:,-1]</span><span id="bf45" class="ny mi jg pj b gy pr po l pp pq"><strong class="pj jh">    <em class="mg">#Compute the predicted y using the fitted Poisson INAR(1) <br/>    #model's equation<br/></em></strong><em class="mg">    </em>y_pred = rho * y_lag_1 + np.exp(X.dot(fitted_beta))</span><span id="1794" class="ny mi jg pj b gy pr po l pp pq">    <strong class="pj jh">return </strong>y_pred</span></pre><p id="c8f8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们准备<strong class="kx jh"> <em class="mg"> X </em> </strong>矩阵进行预测</p><pre class="nf ng nh ni gt pi pj pk pl aw pm bi"><span id="c34f" class="ny mi jg pj b gy pn po l pp pq">X_test[<strong class="pj jh">'y_lag_1'</strong>] = y_test.<strong class="pj jh">shift</strong>(1)<br/>X_test = X_test.<strong class="pj jh">fillna</strong>(0)</span></pre><p id="3b13" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">根据测试数据集生成预测。由于我们对计数感兴趣，我们将对预测进行四舍五入。</p><pre class="nf ng nh ni gt pi pj pk pl aw pm bi"><span id="e4c1" class="ny mi jg pj b gy pn po l pp pq">inar_predictions = np.<strong class="pj jh">round</strong>(inar_model_results.<strong class="pj jh">predict</strong>(<strong class="pj jh">exog</strong>=X_test))<br/><strong class="pj jh">print</strong>(inar_predictions)</span></pre><p id="a575" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们得到以下输出:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/949ca175b2e4c0a2eb34b840e913b640.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*b5YnSp_4n1pKTYdDlff_Jw.png"/></div></figure><p id="80a9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们为<em class="mg"> y_test </em>绘制一步预测图:</p><pre class="nf ng nh ni gt pi pj pk pl aw pm bi"><span id="c571" class="ny mi jg pj b gy pn po l pp pq">predicted_counts=inar_predictions<br/>actual_counts = y_test[<strong class="pj jh">'strikes'</strong>]</span><span id="8bb9" class="ny mi jg pj b gy pr po l pp pq">fig = plt.<strong class="pj jh">figure</strong>()<br/>fig.suptitle(<strong class="pj jh">'Predicted versus actual strike counts'</strong>)</span><span id="3d85" class="ny mi jg pj b gy pr po l pp pq">predicted, = plt.<strong class="pj jh">plot</strong>(X_test.index, predicted_counts, 'go-', <strong class="pj jh">label</strong>='Predicted counts')</span><span id="2d7a" class="ny mi jg pj b gy pr po l pp pq">actual, = plt.<strong class="pj jh">plot</strong>(X_test.index, actual_counts, 'ro-', <strong class="pj jh">label</strong>='Actual counts')</span><span id="725d" class="ny mi jg pj b gy pr po l pp pq">plt.<strong class="pj jh">legend</strong>(<strong class="pj jh">handles</strong>=[predicted, actual])</span><span id="d552" class="ny mi jg pj b gy pr po l pp pq">plt.<strong class="pj jh">show</strong>()</span></pre><p id="83d1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们看到的是:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pw"><img src="../Images/3e1180f97a666d14541cc3ae8fb7947c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1IXjJfBPaGZYNC2T53UDDA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">泊松IINAR(1)模型创建的一步预测罢工数量(图片由作者提供)</p></figure><p id="5df2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">提前一步预测的质量证实了我们之前通过泊松INAR(1)模型的拟合优度强调的问题。</p><p id="cb21" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下是完整源代码的链接:</p><figure class="nf ng nh ni gt is"><div class="bz fp l di"><div class="px py l"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">使用Python和statsmodels的泊松整数ARIMA模型</p></figure></div><div class="ab cl ou ov hu ow" role="separator"><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz"/></div><div class="ij ik il im in"><h1 id="be25" class="mh mi jg bd mj mk pb mm mn mo pc mq mr km pd kn mt kp pe kq mv ks pf kt mx my bi translated">引用和版权</h1><h2 id="ea70" class="ny mi jg bd mj nz oa dn mn ob oc dp mr le od oe mt li of og mv lm oh oi mx oj bi translated">书</h2><p id="2eff" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">Cameron A. Colin，Trivedi Pravin K .，<a class="ae jd" href="http://cameron.econ.ucdavis.edu/racd/count.html" rel="noopener ugc nofollow" target="_blank"> <em class="mg">计数数据回归分析</em> </a>，计量经济学会专论№30，剑桥大学出版社，1998年。国际标准书号:0521635675</p><h2 id="6d11" class="ny mi jg bd mj nz oa dn mn ob oc dp mr le od oe mt li of og mv lm oh oi mx oj bi translated">报纸</h2><p id="1076" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">布朗恩斯，科特。(1995).<a class="ae jd" href="https://www.researchgate.net/publication/254848069_EXPLANATORY_VARIABLES_IN_THE_AR1_COUNT_DATA_MODEL" rel="noopener ugc nofollow" target="_blank">AR(1)计数数据模型中的解释变量</a> <a class="ae jd" href="http://www.usbe.umu.se/digitalAssets/39/39103_ues381.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jh"> PDF下载链接</strong> </a></p><p id="08b2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">荣，罗伯特c和a。整数时间序列的二项式稀疏模型。<em class="mg">统计建模</em>6(2006):81–96。，DOI:<a class="ae jd" href="https://doi.org/10.1191/1471082X06st114oa" rel="noopener ugc nofollow" target="_blank">10.1191/1471082 x 06 ST 114 OA</a><a class="ae jd" href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.914.8707&amp;rep=rep1&amp;type=pdf" rel="noopener ugc nofollow" target="_blank"><strong class="kx jh">PDF下载链接</strong> </a></p><p id="47df" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">凯南j .，<a class="ae jd" href="https://www.sciencedirect.com/science/article/pii/0304407685900648" rel="noopener ugc nofollow" target="_blank"> <em class="mg">美国制造业的合同罢工持续时间，计量经济学杂志</em> </a>，第28卷，1985年第1期，第5-28页，ISSN 0304-4076，<a class="ae jd" href="https://doi.org/10.1016/0304-4076(85)90064-8." rel="noopener ugc nofollow" target="_blank">https://doi . org/10.1016/0304-4076(85)90064-8。</a> <a class="ae jd" href="https://www.ssc.wisc.edu/~jkennan/research/JEM85.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jh"> PDF下载链接</strong> </a></p><h2 id="7a64" class="ny mi jg bd mj nz oa dn mn ob oc dp mr le od oe mt li of og mv lm oh oi mx oj bi translated">数据集</h2><p id="a1b5" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">文章中使用的制造业罢工数据集是统计软件中可供公众使用和实验的几个数据集之一，最值得注意的是，这里的<a class="ae jd" href="https://rdrr.io/rforge/Ecdat/man/StrikeNb.html" rel="noopener ugc nofollow" target="_blank">是R包</a>。在<a class="ae jd" href="https://github.com/vincentarelbundock/Rdatasets/blob/master/LICENSE.md" rel="noopener ugc nofollow" target="_blank"> GPL v3许可</a>下，<a class="ae jd" href="https://github.com/vincentarelbundock" rel="noopener ugc nofollow" target="_blank"> Vincent Arel-Bundock </a>通过<a class="ae jd" href="https://vincentarelbundock.github.io/Rdatasets" rel="noopener ugc nofollow" target="_blank">vincentarelbundock.github.io/rdatasets</a>已经可以使用Python访问数据集。</p><h2 id="775d" class="ny mi jg bd mj nz oa dn mn ob oc dp mr le od oe mt li of og mv lm oh oi mx oj bi translated">形象</h2><p id="5027" class="pw-post-body-paragraph kv kw jg kx b ky mz kh la lb na kk ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">本文中的所有图片版权归<a class="ae jd" href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener ugc nofollow" target="_blank"> CC-BY-NC-SA </a>所有，除非图片下面提到了不同的来源和版权。</p></div><div class="ab cl ou ov hu ow" role="separator"><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz"/></div><div class="ij ik il im in"><h1 id="14ac" class="mh mi jg bd mj mk pb mm mn mo pc mq mr km pd kn mt kp pe kq mv ks pf kt mx my bi translated">相关文章</h1><div class="ip iq gp gr ir pz"><a rel="noopener follow" target="_blank" href="/the-complete-guide-to-r-squared-adjusted-r-squared-and-pseudo-r-squared-4136650fc06c"><div class="qa ab fo"><div class="qb ab qc cl cj qd"><h2 class="bd jh gy z fp qe fr fs qf fu fw jf bi translated">R平方、调整R平方和伪R平方完全指南</h2><div class="qg l"><h3 class="bd b gy z fp qe fr fs qf fu fw dk translated">了解如何使用这些方法来评估线性和某些非线性回归模型的拟合优度</h3></div><div class="qh l"><p class="bd b dl z fp qe fr fs qf fu fw dk translated">towardsdatascience.com</p></div></div><div class="qi l"><div class="qj l qk ql qm qi qn ix pz"/></div></div></a></div><div class="ip iq gp gr ir pz"><a rel="noopener follow" target="_blank" href="/an-illustrated-guide-to-the-poisson-regression-model-50cccba15958"><div class="qa ab fo"><div class="qb ab qc cl cj qd"><h2 class="bd jh gy z fp qe fr fs qf fu fw jf bi translated">泊松回归模型图解指南</h2><div class="qg l"><h3 class="bd b gy z fp qe fr fs qf fu fw dk translated">和使用Python的泊松回归教程</h3></div><div class="qh l"><p class="bd b dl z fp qe fr fs qf fu fw dk translated">towardsdatascience.com</p></div></div><div class="qi l"><div class="qo l qk ql qm qi qn ix pz"/></div></div></a></div><div class="ip iq gp gr ir pz"><a rel="noopener follow" target="_blank" href="/negative-binomial-regression-f99031bb25b4"><div class="qa ab fo"><div class="qb ab qc cl cj qd"><h2 class="bd jh gy z fp qe fr fs qf fu fw jf bi translated">负二项式回归:逐步指南</h2><div class="qg l"><h3 class="bd b gy z fp qe fr fs qf fu fw dk translated">外加一个关于负二项式回归的Python教程</h3></div><div class="qh l"><p class="bd b dl z fp qe fr fs qf fu fw dk translated">towardsdatascience.com</p></div></div><div class="qi l"><div class="qp l qk ql qm qi qn ix pz"/></div></div></a></div><div class="ip iq gp gr ir pz"><a rel="noopener follow" target="_blank" href="/generalized-poisson-regression-for-real-world-datasets-d1ff32607d79"><div class="qa ab fo"><div class="qb ab qc cl cj qd"><h2 class="bd jh gy z fp qe fr fs qf fu fw jf bi translated">真实世界数据集的广义泊松回归</h2><div class="qg l"><h3 class="bd b gy z fp qe fr fs qf fu fw dk translated">以及用Python进行广义泊松回归的分步指南</h3></div><div class="qh l"><p class="bd b dl z fp qe fr fs qf fu fw dk translated">towardsdatascience.com</p></div></div><div class="qi l"><div class="qq l qk ql qm qi qn ix pz"/></div></div></a></div></div><div class="ab cl ou ov hu ow" role="separator"><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz"/></div><div class="ij ik il im in"><p id="c621" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="mg">感谢阅读！如果您喜欢这篇文章，请</em> <a class="ae jd" href="https://timeseriesreasoning.medium.com" rel="noopener"> <strong class="kx jh"> <em class="mg">关注我</em> </strong> </a> <em class="mg">获取关于回归和时间序列分析的提示、操作方法和编程建议。</em></p></div></div>    
</body>
</html>