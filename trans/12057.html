<html>
<head>
<title>Setting up a Text Summarisation Project (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">建立文本摘要项目(第2部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/setting-up-a-text-summarisation-project-part-2-a2a8c49193e2?source=collection_archive---------12-----------------------#2021-12-05">https://towardsdatascience.com/setting-up-a-text-summarisation-project-part-2-a2a8c49193e2?source=collection_archive---------12-----------------------#2021-12-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d412" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利用拥抱脸的管道API利用零射击学习进行文本摘要</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/490dd83dda012f5f79db8a3bd7a1899e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gRcFadbATJTdXtIW"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">戴维·dvořáček在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="80c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">更新(2021年12月14日)</strong>:该教程现已作为一篇长文<a class="ae kv" href="https://heiko-hotz.medium.com/daae41a1aaa3" rel="noopener">发布于此</a>。</p><h1 id="4a7e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">这是怎么回事？</h1><p id="e675" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">这是建立文本摘要项目教程的第二部分。有关本教程的更多内容和概述，请参考<a class="ae kv" rel="noopener" target="_blank" href="/setting-up-a-text-summarisation-project-introduction-526622eea4a8">简介</a>以及<a class="ae kv" rel="noopener" target="_blank" href="/setting-up-a-text-summarisation-project-part-1-45553f751e14">第1部分</a>，在其中我们为我们的项目创建了一个基线。</p><p id="2a87" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇博文中，我们将利用<a class="ae kv" href="https://en.wikipedia.org/wiki/Zero-shot_learning" rel="noopener ugc nofollow" target="_blank">零射击学习</a> (ZSL)的概念，这意味着我们将使用一个经过训练的模型来总结文本，但尚未看到任何<a class="ae kv" href="https://www.kaggle.com/Cornell-University/arxiv" rel="noopener ugc nofollow" target="_blank"> arXiv数据集的示例</a>。这有点像当你这辈子一直在做的都是风景画的时候，试图去画一幅肖像。你知道如何绘画，但你可能不太熟悉肖像绘画的复杂性。</p><p id="9767" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">整个教程的代码可以在这个<a class="ae kv" href="https://github.com/marshmellow77/text-summarisation-project" rel="noopener ugc nofollow" target="_blank"> Github repo </a>中找到。今天我们将特别使用<a class="ae kv" href="https://github.com/marshmellow77/text-summarisation-project/blob/main/2_zero_shot.ipynb" rel="noopener ugc nofollow" target="_blank">这个笔记本</a>。</p><h1 id="8bf4" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">为什么零起点学习(ZSL)？</h1><p id="33a4" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">ZSL在过去几年中变得流行起来，因为它允许在没有培训的情况下利用最先进的NLP模型。他们的表现有时相当惊人:<a class="ae kv" href="https://bigscience.huggingface.co/" rel="noopener ugc nofollow" target="_blank">大型科学研究工作组</a>最近发布了他们的T0pp(发音为“T Zero组合+”)模型，该模型经过专门训练，用于研究零射击多任务学习。在<a class="ae kv" href="https://github.com/google/BIG-bench" rel="noopener ugc nofollow" target="_blank">大工作台</a>基准测试中，它经常超过6倍大的模型，在其他几个NLP基准测试中，它也超过16倍大的<a class="ae kv" href="https://github.com/openai/gpt-3" rel="noopener ugc nofollow" target="_blank"> GPT-3 </a>。</p><p id="edd8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">ZSL的另一个好处是使用它只需要两行代码。通过尝试，我们可以创建第二个基线，一旦我们在数据集上对模型进行了微调，就可以用它来量化模型性能的提高。</p><h1 id="dc8c" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">建立零起点学习管道</h1><p id="c90b" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">为了利用ZSL模型，我们可以使用Hugging Face的<a class="ae kv" href="https://huggingface.co/docs/transformers/main_classes/pipelines" rel="noopener ugc nofollow" target="_blank"> <em class="mp">管道</em> API </a>。这个API使我们能够使用只有两行代码的文本摘要模型，同时它负责NLP模型中的主要处理步骤:</p><ol class=""><li id="aaa6" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">文本被预处理成模型可以理解的格式。</li><li id="abd0" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">预处理后的输入被传递给模型。</li><li id="f445" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">模型的预测是后处理的，所以你可以理解它们。</li></ol><p id="c0af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它利用了<a class="ae kv" href="https://huggingface.co/models?pipeline_tag=summarization&amp;sort=downloads" rel="noopener ugc nofollow" target="_blank">拥抱面部模型中枢</a>上已经可用的总结模型。</p><p id="185d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以，下面是如何使用它:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="ae0d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">就是这样，信不信由你。这段代码将下载一个汇总模型，并在您的机器上本地创建汇总。如果您想知道它使用的是哪种模型，您可以在<a class="ae kv" href="https://github.com/huggingface/transformers/blob/master/src/transformers/pipelines/__init__.py" rel="noopener ugc nofollow" target="_blank">源代码</a>中查找或者使用以下命令:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="70a1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我们运行这个命令时，我们看到用于文本摘要的defaukt模型被称为<em class="mp">sshleifer/distilbart-CNN-12–6</em>:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/45c2920d300e4a53f142540dc246596d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1hFT-vqRlDW3blO1wVqiRA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="ea76" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以在拥抱脸网站上找到该模型的<a class="ae kv" href="https://huggingface.co/sshleifer/distilbart-cnn-12-6" rel="noopener ugc nofollow" target="_blank">模型卡</a>，在那里我们还可以看到该模型已经在两个数据集上进行了训练:<a class="ae kv" href="https://huggingface.co/datasets/cnn_dailymail" rel="noopener ugc nofollow" target="_blank"> CNN Dailymail数据集</a>和<a class="ae kv" href="https://huggingface.co/datasets/xsum" rel="noopener ugc nofollow" target="_blank">极端摘要(XSum)数据集</a>。值得注意的是，该模型不熟悉arXiv数据集，仅用于总结与其训练过的文本相似的文本(主要是新闻文章)。型号名称中的数字12和6分别指编码器层数和解码器层数。解释这些是什么超出了本教程的范围，但是你可以在Sam Shleifer的博客文章中读到更多关于它的内容，他创建了这个模型。</p><p id="0b57" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将继续使用默认模型，但我鼓励您尝试不同的预培训模型。所有适合总结的模型都可以在<a class="ae kv" href="https://huggingface.co/models?pipeline_tag=summarization&amp;sort=downloads" rel="noopener ugc nofollow" target="_blank">这里</a>找到。要使用不同的模型，您可以在调用管道API时指定模型名称:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure><h2 id="7a6f" class="nh lt iq bd lu ni nj dn ly nk nl dp mc lf nm nn me lj no np mg ln nq nr mi ns bi translated">侧边栏:提取与抽象总结</h2><p id="86a4" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们还没有谈到两种可能但不同的文本摘要方法:<em class="mp">提取</em> vs <em class="mp">抽象</em>。摘要概括是将从文本中提取的内容连接成一个摘要的策略，而抽象概括包括用新句子解释语料库。大多数摘要模型都是基于生成新文本的模型(它们是自然语言生成模型，例如，<a class="ae kv" href="https://github.com/openai/gpt-3" rel="noopener ugc nofollow" target="_blank"> GPT-3 </a>)。这意味着总结模型也会产生新的文本，这使得它们成为抽象的总结模型。</p><h1 id="4628" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">生成零镜头摘要</h1><p id="475f" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">现在我们知道了如何使用它，我们想在我们的测试数据集上使用它，与我们在第1部分中用来创建基线的数据集完全相同。我们可以用这个循环来实现:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="4b51" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意，我们有<em class="mp">最小长度</em>和<em class="mp">最大长度</em>参数来控制模型生成的摘要。在这个例子中，我们将<em class="mp">的最小长度</em>设置为5，因为我们希望标题至少有5个单词长。通过查看参考摘要(即研究论文的实际标题),看起来20可能是<em class="mp"> max_length </em>的合理值。但同样，这只是第一次尝试，一旦项目进入实验阶段，这两个参数可以而且应该改变，以查看模型性能是否发生变化。</p><h2 id="3de4" class="nh lt iq bd lu ni nj dn ly nk nl dp mc lf nm nn me lj no np mg ln nq nr mi ns bi translated">侧边栏:波束搜索、采样等。</h2><p id="5622" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">如果您已经熟悉文本生成，您可能知道还有许多参数会影响模型生成的文本，如光束搜索、采样和温度。这些参数使您能够更好地控制正在生成的文本，例如，使文本更加流畅，减少重复等。这些技术在管道API中是不可用的——你可以在<a class="ae kv" href="https://github.com/huggingface/transformers/blob/master/src/transformers/pipelines/text2text_generation.py#L151" rel="noopener ugc nofollow" target="_blank">源代码</a>中看到<em class="mp"> min_length </em>和<em class="mp"> max_length </em>是唯一要考虑的参数。然而，一旦我们训练并部署了我们自己的模型，我们就可以访问那些参数了。在本系列的第4部分中会有更多的介绍。</p><h1 id="9457" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">模型评估</h1><p id="603c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">一旦我们生成了零镜头摘要，我们可以再次使用我们的ROUGE函数来比较候选摘要和参考摘要:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="5d33" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对使用ZSL模型生成的摘要运行此计算，我们得到以下结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/8e8c3bb7f6e3ae5970b30662c2efdf4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*HIzq5RqiOFuJ0dC-EFiJXA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="53e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我们将这些与第一部分的基线进行比较时，我们看到这个ZSL模型实际上比我们简单的只取第一句话的试探法表现得更差。同样，这并不出人意料:尽管这个模型知道如何总结新闻文章，但它从未见过总结学术研究论文摘要的例子。</p><h1 id="06e7" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="8180" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们现在已经创建了两条基线，一条使用简单的启发式方法，另一条使用ZSL模型。通过比较ROUGE分数，我们看到简单启发式算法目前优于深度学习模型:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/99822888266b405c5c5f05e520b0e1f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5jhhhGyOfGQRE-kURR7J8g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="3f79" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在下一部分中，我们将采用这种完全相同的深度学习模型，并尝试提高其性能。我们将通过在arXiv数据集上训练它来做到这一点(这一步也被称为<em class="mp">微调</em>):我们利用了它已经知道如何概括文本的事实。然后，我们向它展示了大量arXiv数据集的示例。深度学习模型一旦接受训练，就非常擅长识别数据集中的模式，因此我们确实希望该模型在这项特定任务中变得更好。</p></div></div>    
</body>
</html>