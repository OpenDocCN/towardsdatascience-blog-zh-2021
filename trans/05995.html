<html>
<head>
<title>Tuning XGBoost with XGBoost: Writing your own Hyper Parameters Optimization engine</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用XGBoost调优XGBoost:编写自己的Hyper Parameters优化引擎</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tuning-xgboost-with-xgboost-writing-your-own-hyper-parameters-optimization-engine-a593498b5fba?source=collection_archive---------7-----------------------#2021-05-29">https://towardsdatascience.com/tuning-xgboost-with-xgboost-writing-your-own-hyper-parameters-optimization-engine-a593498b5fba?source=collection_archive---------7-----------------------#2021-05-29</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><div class=""/><blockquote class="js jt ju"><p id="e6ca" class="jv jw jx jy b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt io bi translated"><strong class="jy iw">更新</strong>:发现我关于渐变提升的新书，<a class="ae ku" href="https://amzn.to/3is9IwR" rel="noopener ugc nofollow" target="_blank">实用渐变提升</a>。这是用python中的许多例子对渐变增强的深入探究。</p></blockquote><div class="kv kw gp gr kx ky"><a href="https://www.amazon.com/dp/B0BJ82S916" rel="noopener  ugc nofollow" target="_blank"><div class="kz ab fo"><div class="la ab lb cl cj lc"><h2 class="bd iw gy z fp ld fr fs le fu fw iu bi translated">实用的渐变增强:深入探究Python中的渐变增强</h2><div class="lf l"><h3 class="bd b gy z fp ld fr fs le fu fw dk translated">这本书的梯度推进方法是为学生，学者，工程师和数据科学家谁希望…</h3></div></div><div class="lg l"><div class="lh l li lj lk lg ll lm ky"/></div></div></a></div><p id="b0cd" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated"><strong class="jy iw">更新</strong>:了解如何重用下面详述的方法来执行模型选择(向AutoML迈进的又一步):</p><div class="kv kw gp gr kx ky"><a rel="noopener follow" target="_blank" href="/hacking-hp-tuning-to-perform-automatic-model-selection-ef11d4c08ea2"><div class="kz ab fo"><div class="la ab lb cl cj lc"><h2 class="bd iw gy z fp ld fr fs le fu fw iu bi translated">黑掉惠普调优来执行自动型号选择</h2><div class="lf l"><h3 class="bd b gy z fp ld fr fs le fu fw dk translated">超参数调整可用于执行模型选择并加速高效的ML模型创建。</h3></div><div class="lq l"><p class="bd b dl z fp ld fr fs le fu fw dk translated">towardsdatascience.com</p></div></div><div class="lg l"><div class="lr l li lj lk lg ll lm ky"/></div></div></a></div></div><div class="ab cl ls lt hz lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="io ip iq ir is"><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi lz"><img src="../Images/b5b3147995ce23f5965ff1bc46242b9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wKWPYd4I0ow_NX5O"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">照片由<a class="ae ku" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ku" href="https://unsplash.com/@indraddd?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Indra Utama </a>拍摄</p></figure><p id="fd7c" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">编写一个超参数调整引擎似乎是一个巨大的挑战。我们开始吧！</p></div><div class="ab cl ls lt hz lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="io ip iq ir is"><p id="7cad" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">正如你可能知道的，如果你熟悉数据科学、机器学习、数据科学或我以前关于这个主题的文章，微调你的模型对获得最佳性能至关重要。你不能依赖默认值。</p><p id="8e8f" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">正如<a class="mo mp ep" href="https://medium.com/u/3d8bf96a415f?source=post_page-----a593498b5fba--------------------------------" rel="noopener" target="_blank"> Satyam Kumar </a>在他的上一篇<a class="ae ku" href="https://satyam-kumar.medium.com/7-hyperparameter-optimization-techniques-every-data-scientist-should-know-12cdebe713da" rel="noopener">文章</a>中所说，有几种方法可以实现这种优化。它们的范围从手动调整、随机搜索、暴力到贝叶斯搜索。这些方法各有优缺点。</p><p id="ff07" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">本文将重点介绍一种最近的执行HP优化的方法:基于模型的HP调优。</p><p id="3b72" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">这种方法非常有趣，因为它使用ML方法来调优ML模型。我们可以重用我们熟悉的工具来优化我们熟悉的工具:)令人目不暇接，不是吗？</p><p id="dabb" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">超参数可以被视为结构化的表格数据，对于结构化的表格数据，我们所知道的最通用的ML算法是什么？卡格尔竞赛的无争议冠军？XGBoost！</p><p id="b34f" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">让我们看看我们可以用它做什么，并尝试使用它来调整自己。</p><h1 id="5f3d" class="mq mr iv bd ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn bi translated">基于模型的惠普调整</h1><p id="2e01" class="pw-post-body-paragraph jv jw iv jy b jz no kb kc kd np kf kg ln nq kj kk lo nr kn ko lp ns kr ks kt io bi translated">基于模型的调优背后的想法非常简单:为了加速收敛到给定用例的最佳参数，我们需要一种方法来引导超参数优化到最佳解决方案。事实上，训练一个模型可能很耗时，这取决于训练集的大小，以及通常非常大的配置空间的组合学。</p><p id="daf9" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">这意味着我们需要一种方法来确定最有前途的配置进行评估。为什么不简单地使用一个模型来学习一个给定配置的分数估计值呢？每一次训练都将被用来改进潜在的模型，并给我们一些探索方向的洞察力。这是基于模型的超参数优化的主导思想。</p><p id="95aa" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">如果你对这个想法背后的理论感兴趣，我强烈建议你阅读这篇学术论文。您可能也很想看看使用这种方法的<a class="ae ku" href="https://github.com/automl/SMAC3" rel="noopener ugc nofollow" target="_blank"> SMAC </a>的实现。</p><h1 id="1f4a" class="mq mr iv bd ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn bi translated">总体方法</h1><p id="5452" class="pw-post-body-paragraph jv jw iv jy b jz no kb kc kd np kf kg ln nq kj kk lo nr kn ko lp ns kr ks kt io bi translated">基于模型优化超参数的整体算法非常简单:</p><ol class=""><li id="f312" class="nt nu iv jy b jz ka kd ke ln nv lo nw lp nx kt ny nz oa ob bi translated">随机选择n个配置</li><li id="11ac" class="nt nu iv jy b jz oc kd od ln oe lo of lp og kt ny nz oa ob bi translated">使用对配置进行评分的内部评估器来评估这些配置</li><li id="6377" class="nt nu iv jy b jz oc kd od ln oe lo of lp og kt ny nz oa ob bi translated">保留给出最佳分数估计的配置，丢弃所有其他配置</li><li id="3b3e" class="nt nu iv jy b jz oc kd od ln oe lo of lp og kt ny nz oa ob bi translated">使用此配置训练模型</li><li id="8d15" class="nt nu iv jy b jz oc kd od ln oe lo of lp og kt ny nz oa ob bi translated">将当前配置和分数存储到内部评估器的训练集中</li><li id="0d9b" class="nt nu iv jy b jz oc kd od ln oe lo of lp og kt ny nz oa ob bi translated">重新训练内部评估者</li><li id="3559" class="nt nu iv jy b jz oc kd od ln oe lo of lp og kt ny nz oa ob bi translated">回到步骤1。如果尚未达到最大迭代次数或最小分数。</li></ol><p id="d8ec" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">让我们看看如何实现这一点。</p><h1 id="e589" class="mq mr iv bd ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn bi translated">采样配置空间</h1><p id="ff2b" class="pw-post-body-paragraph jv jw iv jy b jz no kb kc kd np kf kg ln nq kj kk lo nr kn ko lp ns kr ks kt io bi translated">我们要回答的第一个问题是:我们如何对配置空间进行采样？即:我们如何在配置空间中随机挑选一个合格的配置？</p><p id="cfd8" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">这不是一个非常困难的任务，我们可以自己编写一些代码来解决这个问题，但幸运的是，有一个库可以为我们处理所有的负担:<a class="ae ku" href="https://automl.github.io/ConfigSpace/master/" rel="noopener ugc nofollow" target="_blank">配置空间</a>。更具体地说，ConfigurationSpace可以处理条件配置。我们在这里不会用到这个特性，但是它在很多情况下非常有帮助。</p><p id="1886" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">以下示例显示了如何使用ConfigurationSpace随机生成RandomForest配置:</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="oh oi l"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">在几行代码中，我们可以轻松地生成随机配置。作者的代码。</p></figure><h1 id="c902" class="mq mr iv bd ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn bi translated">选择正确的模型</h1><p id="b880" class="pw-post-body-paragraph jv jw iv jy b jz no kb kc kd np kf kg ln nq kj kk lo nr kn ko lp ns kr ks kt io bi translated">和数据科学一样，现在的下一个问题是:我们应该使用什么模型来构建一个可信的估计器？</p><p id="b1ea" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">最初，基于模型的优化使用<a class="ae ku" href="https://scikit-learn.org/stable/modules/gaussian_process.html" rel="noopener ugc nofollow" target="_blank">高斯过程</a>来估计配置得分，但是最近<a class="ae ku" href="https://medium.com/r?url=https%3A%2F%2Fml.informatik.uni-freiburg.de%2Fpapers%2F11-LION5-SMAC.pdf" rel="noopener">的论文</a>显示基于树的模型是一个很好的选择。放弃高斯过程的主要原因是它们不支持分类特征。</p><p id="c039" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">正如上面几行所述，当谈到基于树的模型时，最直接的(但可能不总是最好的)答案是XGBoost！</p><p id="6741" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">为什么使用XGBoost？不仅因为XGBoost和梯度增强方法非常有效，是Kaggle竞赛中最常获胜的方法之一，还因为它们非常通用，不需要太多预处理:不需要特征归一化，缺失值可以自动处理，…</p><p id="921e" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">说实话，用XGBoost来优化XGBoost也很搞笑。然而，我们还会考虑另一个选项，它与XGBoost非常相似，但具有明显的原生支持类别的优势:C <a class="ae ku" href="https://catboost.ai/" rel="noopener ugc nofollow" target="_blank"> atBoost </a>。</p><p id="a9a7" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">处理分类特征是一个非常方便的功能，因为许多模型参数都是分类的。认为XGBoost <em class="jx">目标</em>，<em class="jx">助推器</em>或<em class="jx"> tree_method </em>参数为例。</p><p id="fb4e" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">LightGBM 也是一个完美的选择。</p><h1 id="cf23" class="mq mr iv bd ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn bi translated">调整模型超参数</h1><p id="c142" class="pw-post-body-paragraph jv jw iv jy b jz no kb kc kd np kf kg ln nq kj kk lo nr kn ko lp ns kr ks kt io bi translated">我们现在拥有创建我们自己的超参数优化引擎所需的所有元素。为此，我们创建一个由四个参数配置的<strong class="jy iw">优化器</strong>类:</p><ul class=""><li id="ca72" class="nt nu iv jy b jz ka kd ke ln nv lo nw lp nx kt oj nz oa ob bi translated"><em class="jx"> algo_score </em>:用于给给定配置的模型或算法评分的方法。</li><li id="f480" class="nt nu iv jy b jz oc kd od ln oe lo of lp og kt oj nz oa ob bi translated"><em class="jx"> max_iter </em>:要执行的最大训练次数</li><li id="4dd3" class="nt nu iv jy b jz oc kd od ln oe lo of lp og kt oj nz oa ob bi translated"><em class="jx">max _ enhancement</em>:随机抽样的候选配置的最大数量</li><li id="28dd" class="nt nu iv jy b jz oc kd od ln oe lo of lp og kt oj nz oa ob bi translated"><em class="jx">模型</em>:用作分数估计器的内部模型的类别</li><li id="9742" class="nt nu iv jy b jz oc kd od ln oe lo of lp og kt oj nz oa ob bi translated"><em class="jx"> cs </em>:探索的配置空间</li></ul><p id="5d2f" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">正如您在下面看到的，这不需要太多行:</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="oh oi l"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">这个类使用一个模型实现HP调优。来自作者的代码</p></figure><p id="23a7" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">上面代码的关键部分在于<em class="jx">优化</em>函数。这个函数做三件事:</p><ul class=""><li id="7d96" class="nt nu iv jy b jz ka kd ke ln nv lo nw lp nx kt oj nz oa ob bi translated">它将探索的配置存储在列表<em class="jx">CFG中。</em></li><li id="6bbd" class="nt nu iv jy b jz oc kd od ln oe lo of lp og kt oj nz oa ob bi translated">它将选择的配置存储在列表<em class="jx">轨迹</em>中</li><li id="c347" class="nt nu iv jy b jz oc kd od ln oe lo of lp og kt oj nz oa ob bi translated">它使用内部模型<em class="jx">提供的分数估计选择候选配置进行探索。</em></li><li id="5aaa" class="nt nu iv jy b jz oc kd od ln oe lo of lp og kt oj nz oa ob bi translated">它使用过去的训练分数来训练估计器</li></ul><h1 id="e68f" class="mq mr iv bd ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn bi translated">性能分析</h1><p id="f8e4" class="pw-post-body-paragraph jv jw iv jy b jz no kb kc kd np kf kg ln nq kj kk lo nr kn ko lp ns kr ks kt io bi translated">为了评估我们基于模型的超参数引擎的效率，我们将使用<a class="ae ku" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html" rel="noopener ugc nofollow" target="_blank">波士顿</a>数据集。您可能已经知道，这个数据集包含波士顿房价的信息。我们的模型的目标是估计给定特征的房价。首先，我们将使用RandomForest作为我们的基本模型。我们将在这个模型上评估我们基于模型的方法。</p><p id="b23f" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">首先，让我们确保我们的引擎确实有助于更快地收敛到更好的配置。为此，我们比较了使用RandomSearch和我们的引擎时的学习进度。在下面的代码中，我们使用sci kit learn<em class="jx">RandomizedSearchCV</em>和我们的<em class="jx">优化器</em>来随机探索配置空间:</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="oh oi l"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">将RandomizedSearchCV与我们的引擎进行比较。作者代码。</p></figure><p id="162b" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">看下图，毫无疑问，我们的引擎比随机搜索更有效。更准确地说，很明显，我们的引擎随着迭代不断学习和改进:</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi ok"><img src="../Images/bbf26a9898d6b2afb52257ca486ffae1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*num0Xw6Dd6Pt1PrBx7swtQ.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">RandomizedSearchCV vs我们的引擎。作者的情节。</p></figure><p id="e14c" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">随机搜索不出所料明显不稳定。</p><p id="2f16" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">由于您的代码(相对)独立于用作分数估计器的模型，我们还可以比较XGBoost和Catboost的收敛速度。代码如下:</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="oh oi l"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">比较CatBoost与categories、XGBoost和CatBoost一起使用时的收敛性。作者代码。</p></figure><p id="e6a5" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">生成的图显示在下图中:</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi ol"><img src="../Images/14ca88a8f44367b69f4a54066ada34ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CLOIT0jNM_t2gwqiQPjdPw.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">CatBost(有和没有分类特征)与XGBoost。作者的情节。</p></figure><p id="9994" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">这两种情况下的表现看起来非常相似。请记住，score estimator的XGBoost和CatBoost Hyper参数都没有优化:都使用默认配置。我们可以尝试使用另一个评分模型来调整评分模型，但是这篇文章看起来会像盗梦空间电影一样复杂；)</p><p id="891b" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">另一个值得分析的方面是强化步骤持续时间的影响。当在探索空间中挑选随机候选者时，我们可以增加候选者的数量。在下面的图中，我们分别用25、250和2500个强化候选对象来训练我们的模型。代码和前面的类似。我们只是对<em class="jx">优化器</em>进行了不同的配置:</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="oh oi l"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">比较不同程度的强化。作者代码</p></figure><p id="5015" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">结果图如下:</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi om"><img src="../Images/cf329eabbc1d2844bf4f53e6f02fd2a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1VkffkbVCSFIAmCbKMvK0g.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">强化步骤的数量似乎不影响收敛速度。作者的情节。</p></figure><p id="bb31" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">在这种情况下，强化似乎没有什么影响。</p><p id="4760" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">最后，正如承诺的那样，我们将使用XGBoost来调优XGBoost。代码与RandomForest的代码完全相同，只是我们使用XGBoost作为主模型。参见下面的代码:</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="oh oi l"/></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">使用XGBoost调优XGBoost。作者代码。</p></figure><p id="1c7b" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">请注意，我们还使用CatBoost作为内部评分估计器，以便进行比较。看下面的图，似乎在这种情况下，XGBoost比CatBoost略胜一筹:</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi on"><img src="../Images/5af44552ddbf59f5d3a3bd0d61ab45e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eaQv9UpfEVeDwH0hxVVWaQ.png"/></div></div><p class="mk ml gj gh gi mm mn bd b be z dk translated">使用XGBoost调优XGBoost。图片由作者提供。</p></figure><h1 id="3c44" class="mq mr iv bd ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn bi translated">更进一步</h1><p id="6a67" class="pw-post-body-paragraph jv jw iv jy b jz no kb kc kd np kf kg ln nq kj kk lo nr kn ko lp ns kr ks kt io bi translated">我们已经在这篇文章中表明，建立一个像样的超参数优化引擎并不复杂。通过几行代码，有可能大大加快模型训练的速度。</p><p id="8fd1" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">可笑的是，你不需要使用外部库。重用现有的模型是可行的。XGBoost可以用来调优XGBoost，CatBoost可以用来调优CatBoost，RandonForest可以调优RandomForest。也可以混合使用。</p><p id="ec55" class="pw-post-body-paragraph jv jw iv jy b jz ka kb kc kd ke kf kg ln ki kj kk lo km kn ko lp kq kr ks kt io bi translated">虽然我们的模型工作得很好，但一个非常有趣的改进是更新随机样本，使用贝叶斯策略来生成候选人，使用学习分布而不是随机采样。</p></div></div>    
</body>
</html>