<html>
<head>
<title>Can LightGBM Outperform XGBoost?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">LightGBM 能跑赢 XGBoost 吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/can-lightgbm-outperform-xgboost-d05a94102a55?source=collection_archive---------24-----------------------#2021-10-29">https://towardsdatascience.com/can-lightgbm-outperform-xgboost-d05a94102a55?source=collection_archive---------24-----------------------#2021-10-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="c2d2" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">助推技术</h2><div class=""/><div class=""><h2 id="ffa0" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">机器学习中的助推算法——第五部分</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/c83731fecd3464e0fe64606ee21ee5d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ti1ZuV-jXuGwvG2NaRxkLQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">道格·达菲在<a class="ae lh" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="b938" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">到目前为止，我们已经讨论了 3 种增强技术:<a class="ae lh" rel="noopener" target="_blank" href="/how-do-you-implement-adaboost-with-python-a76427b0fa7a"> AdaBoost </a>、<a class="ae lh" rel="noopener" target="_blank" href="/under-the-hood-of-gradient-boosting-and-its-python-implementation-99cc63efd24d">梯度增强</a>和<a class="ae lh" href="https://rukshanpramoditha.medium.com/unlock-the-power-of-xgboost-738536b9f36f" rel="noopener"> XGBoost </a>。我们已经知道 XGBoost 比我们到目前为止讨论过的其他 boosting 算法更强大。</p><p id="cd30" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">LightGBM(光梯度增强机)是 XGBoost 的一个很好的替代品。它是由微软开发的，在几年前的 2016 年发布。</p><p id="b398" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于 LightGBM 在集合中创建新树时采用了不同的方法，因此 LightGBM 具有以下独特的功能:</p><ul class=""><li id="5cdf" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">运行速度比 XGBoost 快</li><li id="903d" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">使用较少的内存</li><li id="bda0" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">可以处理大型数据集</li><li id="212b" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">可以处理数据集中缺失的值</li><li id="e854" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">可以处理尚未编码的分类特征</li></ul><p id="b925" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">今天，我们将学习 LightGBM 库的安装，并探索它的 Python API。关键部分是我们将使用 XGBoost 和 LightGBM 算法在同一个数据集上创建两个模型，并比较每个算法的性能和执行时间。</p><p id="d1a5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们开始吧！</p><h1 id="1da1" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">照明设备的安装</h1><p id="fa37" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">我们可以通过在 Anaconda 提示符或 Google Colab 编辑器中运行以下命令来安装 LightGBM。</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="31bf" class="nu mt it nq b gy nv nw l nx ny"><strong class="nq jd">pip install lightgbm</strong></span></pre><p id="8c2f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后运行以下命令并验证安装。</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="3e99" class="nu mt it nq b gy nv nw l nx ny"><strong class="nq jd">import lightgbm</strong></span></pre><p id="0e41" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果您没有收到任何错误消息，那么您已经成功安装了 LightGBM！</p><h1 id="2b56" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">LightGBM 的 Python API</h1><p id="af9f" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">LightGBM 的 Python API 由几个子 API 组成。我们将讨论其中的两个:</p><h2 id="a506" class="nu mt it bd mu nz oa dn my ob oc dp nc lr od oe ne lv of og ng lz oh oi ni iz bi translated">sci kit-学习 API</h2><p id="049f" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">该 API 用于通过 Scikit-learn <strong class="lk jd">实现 LightGBM 算法。fit()/。预测()</strong>范式。这个 API 中最重要的类是:</p><ul class=""><li id="9d72" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated"><a class="ae lh" href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html" rel="noopener ugc nofollow" target="_blank">LGBMClassifier()</a><strong class="lk jd"/>—light GBM 用于分类</li><li id="56d9" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated"><a class="ae lh" href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html" rel="noopener ugc nofollow" target="_blank">LGBMRegressor()</a><strong class="lk jd"/>—light GBM 用于回归</li></ul><h2 id="1a3c" class="nu mt it bd mu nz oa dn my ob oc dp nc lr od oe ne lv of og ng lz oh oi ni iz bi translated">绘图 API</h2><p id="b7fb" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">LightGBM 包在这个 API 下提供了一些绘图方法:</p><ul class=""><li id="2b41" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated"><a class="ae lh" href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.plot_importance.html" rel="noopener ugc nofollow" target="_blank"> plot_importance() </a> —绘制 LightGBM 模型的特征重要性</li><li id="61e4" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated"><a class="ae lh" href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.plot_metric.html" rel="noopener ugc nofollow" target="_blank"> plot_metric() </a> —在训练期间绘制一个度量</li></ul><h1 id="f742" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">LightGBM 与 XGBoost</h1><p id="1c45" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">现在我们就来对比一下 LightGBM 和 XGBoost 的<strong class="lk jd"> <em class="oj">性能</em> </strong>和<strong class="lk jd"> <em class="oj">执行时间</em> </strong>。为此，我们使用<a class="ae lh" href="https://drive.google.com/file/d/1Kees3lk-Zo7AsrYz7svcj8Hnbr6gHok6/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">加州房价数据集</a>执行回归任务。</p><h2 id="1a10" class="nu mt it bd mu nz oa dn my ob oc dp nc lr od oe ne lv of og ng lz oh oi ni iz bi translated">LightGBM</h2><p id="c483" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">这里，我们使用<strong class="lk jd"> LGBMRegressor() </strong>类及其相关的超参数。我们还使用五重交叉验证来评估模型的性能。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">LightGBM —性能和执行时间</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi om"><img src="../Images/8c5021825f95362bb604cbaf109aa8ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*uvzz-m6v_3tsvugUqpWymw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="6df5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">LightGBM 的执行时间是 0.608 秒。数据集有 20640 行和 8 个特征！所以，LightGBM 真的很快。</p><h2 id="3400" class="nu mt it bd mu nz oa dn my ob oc dp nc lr od oe ne lv of og ng lz oh oi ni iz bi translated">XGBoost</h2><p id="5ec9" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">这里，我们使用<strong class="lk jd"> XGBRegressor() </strong>类及其相关的超参数。我们还使用五重交叉验证来评估模型的性能。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ok ol l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">XGBoost —性能和执行时间</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi on"><img src="../Images/954c2127873c59615605eafad010291e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*DymTgSmbn4azKsQ2pqYnPA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="c4d4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">XGBoost 给出的 RMSE 略好于 LightGBM 给出的 RMSE。但是，XGBoost 任务需要 4.660 秒才能执行。比 LightGBM 慢了 7.66 倍！</p><h1 id="453b" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">LightGBM 的绘图功能重要性</h1><p id="68c2" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">这里，我们使用 LightGBM 绘图 API 的<strong class="lk jd"> plot_importance() </strong>类来绘制我们之前创建的 LightGBM 模型的特性重要性。</p><pre class="ks kt ku kv gt np nq nr ns aw nt bi"><span id="2230" class="nu mt it nq b gy nv nw l nx ny">lgbm.fit(X, y)<br/>lightgbm.plot_importance(lgbm)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/04a1f53b01b0e54d25414924fbff2fca.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*7IIX_rowi2PmbMBkdn54oA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="d831" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">特征<strong class="lk jd">人口</strong>和<strong class="lk jd"> AveBedrms </strong>对模型来说似乎不太重要。因此，您可以删除这些要素并重新构建模型以降低 RMSE。</p><h1 id="f65c" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">结论</h1><p id="cfdb" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated"><strong class="lk jd">light GBM 能跑赢 XGBoost 吗？</strong> <em class="oj"> </em>答案在这里。</p><blockquote class="op oq or"><p id="129b" class="li lj oj lk b ll lm kd ln lo lp kg lq os ls lt lu ot lw lx ly ou ma mb mc md im bi translated">就性能而言，LightGBM 并不总是优于 XGBoost，但它有时会优于 XGBoost。至于执行时间，LightGBM 比 XGBoost 快 7 倍左右！</p></blockquote><p id="a2d6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">除了更快的执行时间，LightGBM 还有另一个很好的特性:我们可以在 LightGBM 中直接使用分类特性(不需要编码)。但是，数据类型转换(<em class="oj">对象</em>数据类型→ <em class="oj">类别</em>数据类型)需要手动完成。</p><p id="469a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在下列情况下，LightGBM 优于 XGBoost。</p><ul class=""><li id="cd46" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">你想在比赛中快速训练模型。</li><li id="9864" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">数据集很大。</li><li id="d93a" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">您没有时间对数据集中的分类要素(如果有)进行编码。</li></ul><p id="d384" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">今天的帖子到此结束。在第 6 部分的<a class="ae lh" rel="noopener" target="_blank" href="/how-do-you-use-categorical-features-directly-with-catboost-947b211c2923">中，我们将讨论<strong class="lk jd"> CatBoost(分类增强)</strong>，XGBoost 的另一种替代方案。下一个故事再见。祝大家学习愉快！</a></p></div><div class="ab cl ov ow hx ox" role="separator"><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa"/></div><div class="im in io ip iq"><p id="f7f7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我的读者可以通过下面的链接注册成为会员，以获得我写的每个故事的全部信息，我将收到你的一部分会员费。</p><div class="pc pd gp gr pe pf"><a href="https://rukshanpramoditha.medium.com/membership" rel="noopener follow" target="_blank"><div class="pg ab fo"><div class="ph ab pi cl cj pj"><h2 class="bd jd gy z fp pk fr fs pl fu fw jc bi translated">通过我的推荐链接加入 Medium</h2><div class="pm l"><h3 class="bd b gy z fp pk fr fs pl fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pn l"><p class="bd b dl z fp pk fr fs pl fu fw dk translated">rukshanpramoditha.medium.com</p></div></div><div class="po l"><div class="pp l pq pr ps po pt lb pf"/></div></div></a></div><p id="5f58" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">非常感谢你一直以来的支持！</p><p id="84e3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">特别要感谢 Unsplash 网站上的<strong class="lk jd">道格·达菲</strong>，<strong class="lk jd"> </strong>为我提供了这篇文章的封面图片。</p><p id="b379" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="pu pv ep" href="https://medium.com/u/f90a3bb1d400?source=post_page-----d05a94102a55--------------------------------" rel="noopener" target="_blank">鲁克山普拉莫迪塔</a><br/><strong class="lk jd">2021–10–29</strong></p></div></div>    
</body>
</html>