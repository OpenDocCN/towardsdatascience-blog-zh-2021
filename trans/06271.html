<html>
<head>
<title>Building Neural Network in Swift using Metal shaders</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用金属着色器在Swift中构建神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-neural-network-in-swift-using-metal-shaders-aa1fd75d715b?source=collection_archive---------12-----------------------#2021-06-05">https://towardsdatascience.com/building-neural-network-in-swift-using-metal-shaders-aa1fd75d715b?source=collection_archive---------12-----------------------#2021-06-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="58eb" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用金属性能着色器框架构建神经网络</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/10d5fa8436312217dfa4783d73ac5cd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eWmKMGwl6oqe6o53"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">克里希纳·潘迪在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="b68b" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="a00d" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在<a class="ae kv" rel="noopener" target="_blank" href="/neural-networks-on-swift-ba181dcdfde5">上一篇文章</a>中，我从零开始实现了神经网络框架。它支持CPU多线程，但不支持GPU计算。在这篇文章中，我将实现类似的框架，但使用<em class="mk">金属性能着色器</em>。<a class="ae kv" href="https://developer.apple.com/wwdc19/614" rel="noopener ugc nofollow" target="_blank"> WWDC19 session 614 </a>启发我写这篇文章。</p><blockquote class="ml mm mn"><p id="5907" class="lo lp mk lq b lr mo jr lt lu mp ju lw mq mr lz ma ms mt md me mu mv mh mi mj ij bi translated">Metal性能着色器框架包含一组高度优化的计算和图形着色器，旨在轻松高效地集成到您的Metal应用程序中。这些数据并行原语经过专门调整，以利用每个GPU系列的独特硬件特征来确保最佳性能。</p></blockquote><p id="5bb0" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated"><em class="mk">金属性能着色器</em>提供了高度灵活的神经网络编程。</p><h1 id="b3f7" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">神经网络数据模型</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/919953b6523f21ee8bc48253d32b534c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g-Y1-7BUW6ChsNhGSY5u9Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据模型。图片由Yauheni Stsefankou提供。</p></figure><p id="3b5c" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">我们的神经网络模型由模型的层、图和参数组成。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/c5d540c8a86fcf0082e0d654e65cbacf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*B5EkZVkQeobgY_DVc-EEtg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">神经网络的参数。图片由Yauheni Stsefankou提供。</p></figure><p id="5719" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">参数是批量大小和每次训练的时期数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/b788a1d46525cac6b270454538ca8288.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NLjOYKUFlQ1GUruSbqmU8w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">神经网络图。图片由Yauheni Stsefankou提供。</p></figure><p id="cc06" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">在我们的模型中有两个图:训练图和推理图。两者重量相同。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="dab3" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">我们的神经网络框架将有很多层，如密集，下降，平坦，卷积2D，汇集最大值和平均值，Sigmoid和ReLU激活。</p><p id="20de" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">为了方便起见，你可以在<a class="ae kv" href="https://github.com/stefjen07/ShadersNeuralNetwork" rel="noopener ugc nofollow" target="_blank">我的GitHub库</a>中找到所有代码。</p><h1 id="4101" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">不可训练层</h1><p id="1e35" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">这些层的实现非常简单，因为它们没有权重。他们在不改变策略的情况下不断转换输入。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="d091" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">基本图层类为空，因为所有图层没有共同点。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="e9a4" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">池层有填充和池模式、过滤器大小和步幅。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="4d90" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">漏失层非常简单，它只有一个保持输入值的概率。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="953e" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">展平图层也很简单。我们必须提供展平宽度(输入尺寸)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="aabc" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">激活层不需要存储任何数据，所以它们会像基本层类一样为空。</p><p id="5ad3" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">只剩下两个未实现的层:密集和卷积2D。对于它们，我们需要实现数据源类。它包括神经元的权重、偏差和层参数。</p><h1 id="04e7" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">卷积和密集图层的数据源</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="d25d" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">我们必须在特定的金属向量中存储重量、偏差及其速度和动量。此外，我们在这些向量和优化器的参数上保留指针。</p><p id="c74b" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">MPSCNNConvolutionDataSource协议正在强制我们实现一些功能。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="f2fe" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">第一个函数返回权重的数据类型。我们将保持权重值为32位浮点数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="985b" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">第二个函数返回卷积描述符，它是在类初始化时用给定的参数创建的。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="5cc3" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">这些函数返回指向带有层权重和偏差的向量的指针。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="81a5" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">该方法加载权重和偏差。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="e49b" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">这两个函数是插头，因为它们对于我们的任务是不必要的。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="5035" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">而这是<code class="fe nb nc nd ne b">ConvDataSource</code>类中的最后一个函数。它返回数据源的标签。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="9f08" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">卷积和密集层的权重使用公共卷积参数初始化，例如内核大小、输入通道和滤波器的数量、步幅和学习速率。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="c9e3" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">这里最基本的东西是优化器和卷积描述符。它们存储我们的层的主要参数，并在用它们训练时更新权重。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="5101" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">在初始化权重和偏差向量之前，我们必须计算它们的长度并为它们创建描述符。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="767f" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">现在，当我们有了描述符，我们可以初始化重量，速度和动量的向量。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="c2fa" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">然后，我们对偏差向量做同样的处理。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="106e" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">我们使用内核的glorot初始化。这意味着我们在-limit到limit的范围内随机生成内核权重，其中limit是sqrt(6/(inputFeatureChannels+outputFeatureChannels))</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="9afa" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">内核生成后，我们初始化权重和偏差状态和命令缓冲区，所有的初始化都将在这里执行。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="247e" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">然后，我们运行命令完成，并等待它完成。</p><h1 id="4667" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">卷积和密集层</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="98f3" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">密集层就大不一样了，不需要填充。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><h1 id="b9a1" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">图形生成</h1><p id="3d36" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">为了从层中创建图形，我们需要实现函数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="0ac8" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">图形是在将节点修补到其他节点时创建的。我们需要存储最后一个节点的结果图像作为新节点的源。</p><p id="c23a" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">在switch-case语句中，我们将为层创建节点。每个节点在初始化时都需要源。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="591e" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">卷积节点需要权重的数据源和填充策略。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="dc93" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">激活函数不需要任何参数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="0a37" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">展平图层需要平面输入大小(您可以通过运行getOutputSize方法而无需展平和下一个图层来获得)。该层将输入转换为1x1矩阵，其通道数等于平面输入大小。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="3635" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">脱落节点仅包含在训练图中。它需要保值的概率。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="1f58" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">密集层结构类似于卷积层，但不需要填充策略。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="4298" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">最后一种情况是默认的，所以如果当前图层不是图层类的子类，那么我们就不会在图中包含任何节点。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="ef3b" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">我们的神经网络框架将仅支持神经网络模型末端的softmax激活函数。我们将softmax的损失节点添加到训练图中，并将softmax节点添加到推理图中。</p><h1 id="deb7" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">神经网络模型初始化</h1><p id="0409" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在我们实现了为我们的模型创建节点的方法之后，我们可以实现我们的NN模型的初始化。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="b769" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">那么，我们需要什么来初始化模型呢？首先，我们需要<code class="fe nb nc nd ne b">MTLDevice</code>。</p><blockquote class="ml mm mn"><p id="3827" class="lo lp mk lq b lr mo jr lt lu mp ju lw mq mr lz ma ms mt md me mu mv mh mi mj ij bi translated"><code class="fe nb nc nd ne b">MTLDevice</code>协议定义了GPU的接口。你可以向<code class="fe nb nc nd ne b">MTLDevice</code>查询它为你的金属应用提供的独特功能，并使用<code class="fe nb nc nd ne b">MTLDevice</code>发布你所有的金属命令。</p></blockquote><p id="959e" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">我们需要的第二样东西是来自我们<code class="fe nb nc nd ne b">MTLDevice</code>的<code class="fe nb nc nd ne b">MTLCommandQueue</code>。</p><blockquote class="ml mm mn"><p id="ce43" class="lo lp mk lq b lr mo jr lt lu mp ju lw mq mr lz ma ms mt md me mu mv mh mi mj ij bi translated">一个<code class="fe nb nc nd ne b">MTLCommandQueue</code>对象将命令缓冲区的有序列表排队等待<code class="fe nb nc nd ne b"><a class="ae kv" href="https://developer.apple.com/documentation/metal/mtldevice" rel="noopener ugc nofollow" target="_blank">MTLDevice</a></code>执行。命令队列是线程安全的，允许多个未完成的命令缓冲区同时编码。</p></blockquote><p id="2472" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">第三个是层数组，我们将在<code class="fe nb nc nd ne b">createNodes()</code>函数中使用它来构建我们的图表。</p><p id="92e5" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">最后两个参数是基本的模型参数:时期数和批量大小。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="e99c" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">首先，我们将初始化的参数复制到模型的本地存储中。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="24b2" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">为了得到最终节点，我们运行<code class="fe nb nc nd ne b">createNodes()</code>方法。但是在方法运行之后，我们得到了没有丢失节点的节点(除了softmax丢失节点)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="88c5" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">为了创建训练图，我们需要添加损失节点并获得损失出口，因此我们运行<code class="fe nb nc nd ne b">trainingGraph</code>方法。它返回图形的亏损退出点。在我们的例子中，它必须只包含一个止损点。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="6192" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">在得到损失退出点后，我们可以用它来创建训练图。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="2d80" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">推理图初始化类似于训练图。这种初始化更容易，因为我们不必创建丢失节点。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="af90" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">创建推理图与创建训练图非常相似。</p><h1 id="ab1a" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">数据集实现</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="bb93" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">我们的数据集支持两种类型的数据:图像和字节。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="35e6" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">数据集包括样本数组、图像大小参数(如果数据类型是图像)、类别标签(我们的神经网络模型应该是分类器)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="3365" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">为了方便使用，数据示例复制了数据类型。此外，它将标签索引存储在数据集中的<code class="fe nb nc nd ne b">classLabels</code>数组中。样本的主体取决于数据类型。如果数据类型是图像，那么样本存储<code class="fe nb nc nd ne b">CGImage</code>及其<code class="fe nb nc nd ne b">MTLTexture</code>。</p><p id="0253" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">在数据样本初始化之前，我们需要创建从CGImage到MTLTexture的convert方法。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="9b9a" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">我将convert方法实现为一个可计算的变量。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="7715" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">正因为如此，我不得不再次得到default <code class="fe nb nc nd ne b">MTLDevice</code>。金属编码中最常见的事情就是使用描述符。我们需要创建纹理描述符。我们纹理的像素格式是<code class="fe nb nc nd ne b">r8Unorm</code>。这意味着这里只有红色通道(灰度),值表示为无符号的8位规范化整数。此外，我们将CGImage的宽度和高度复制到描述符中。我们的纹理区域的原点为零，大小等于CGImage的大小。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="8413" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">我们颜色空间使用每个分量8位，每个像素一个分量(红色通道)。另外，我们的颜色空间不使用alpha通道。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="ab3a" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">我们使用加速框架使图像符合我们的纹理格式。之后，我们使用图像来获取可以写入纹理的数据。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="d7bb" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">这种方法有助于我们更容易地创建数据样本。数据样本的初始化是定义类型，从实参中复制参数并获取纹理(如果类型是图像)。</p><p id="6bb0" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">但是我们不能用我们的数据样本来构建模型。所以，我们必须实现向<code class="fe nb nc nd ne b">MPSImage</code>的转换。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="1a4c" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated"><code class="fe nb nc nd ne b">MPSImage</code>可以用纹理轻松初始化。当数据类型是字节时，我们用描述符创建平面<code class="fe nb nc nd ne b">MPSImage</code>，并向其中写入字节。</p><p id="afed" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">好的。我们实现了数据样本类。现在我们必须实现数据集初始化。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="4260" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">用字节初始化数据集非常简单。我们所要做的就是为每个样本提供带有字节数组和标签的初始化器。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="e8be" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">此外，我们将从包含图像的子文件夹的文件夹中编写初始化程序。要处理文件夹和文件，我们必须使用默认的<code class="fe nb nc nd ne b">FileManager</code>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="98ab" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">然后，我们实现我们的文件结构。首先，我们在给定的文件夹中寻找子文件夹。每个子文件夹代表一个唯一的类。然后，我们在每个子文件夹中寻找文件。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="95d1" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">之后，我们尝试从每个文件中读取图像。如果我们成功读取图像，那么我们可以使用<code class="fe nb nc nd ne b">CGContext</code>将图像调整到格式。最后一件事是从图像中创建<code class="fe nb nc nd ne b">DataSample</code>并将其添加到samples数组中。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="c59b" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">对于这种情况，当我们只有一个数据集，并希望将其分为训练集和测试集时，我们必须编写一个适当的方法。它复制所有的公共参数，如类标签数组、图像大小和数据类型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="b003" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">之后，它使用<code class="fe nb nc nd ne b">Dictionary</code>按类划分样本。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="f71b" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">然后，它使用给定的测试集百分比划分样本的所有类别。</p><h1 id="aff3" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">培养</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="238c" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">我们的训练过程分为几个时期。在开始新的纪元之前，我们必须等到前一个纪元完成。我们在训练之前和每个时期之后评估我们的模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="e950" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">在每一个时期，我们都把所有的样本分批送去训练。</p><p id="d3d1" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">但是在实现<code class="fe nb nc nd ne b">trainIteration</code>方法之前，我们必须实现从数据集获取训练批次。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="f50c" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">获取训练批次并不难，因为我们实现了从样本中获取<code class="fe nb nc nd ne b">MPSImage</code>。Batch是这些图像的数组。我们还必须用标签改变损失状态批次。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="46bd" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">丢失数据是float类型的数组，其中除了正确的变量之外，所有变量都等于0。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="6482" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">得到训练批次后，我们必须将其编码为<code class="fe nb nc nd ne b">MTLCommandBuffer</code>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="6201" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">在训练迭代中，我们得到训练批次及其期望值。使用双缓冲信号量导致永久的100% GPU负载。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="1198" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">我们必须将完整的处理程序添加到命令缓冲区中。训练迭代结束后，统计训练损失并输出到终端。我们使用<code class="fe nb nc nd ne b">fflush</code>来替换先前的迭代状态。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="e934" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">为了得到训练损失，我们将一个批次中的所有损失相加，然后除以批次大小。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="702d" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">最后，我们用命令缓冲区同步批处理，启动缓冲区中的命令并返回它。</p><h1 id="d708" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">估价</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="f0b9" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">在评估时，我们计算正确答案并除以测试集中的样本数。然后，我们从数据源重新加载推理图，因为在训练过程中权重只在训练图中改变，而不在推理图中改变。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="7f17" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">评估也将有双缓冲信号量。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="d764" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">批量备考甚至比在培训中还要容易。我们只需要一组数据样本。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="487b" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">然后我们将使用<code class="fe nb nc nd ne b">predict</code>方法，因为我们需要实现它。它返回一个标签预测数组。我们将预期与预测进行比较，并评估模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="9f65" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">为了预测，我们必须准备数据样本。我们将它们转换成MPSImages并编码到命令缓冲区。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="d4e1" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">将推理批次编码到命令缓冲区非常类似于将训练批次编码。唯一的区别是，我们对推理图进行批量编码，而不是训练。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="1a5c" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">当GPU上的操作完成后，我们可以检查批处理中每个项目的输出。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="7feb" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">然后，我们读取批处理中每一项的输出，并通过最大值的索引追加一组答案。这就是分类器的工作方式。</p><h1 id="317a" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">例子</h1><p id="0af8" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我尝试了使用ETL数据集的平假名分类和使用MNIST的数字分类。经过10分钟的训练，平假名分类器的准确率达到75%，数字分类器的准确率达到98%。</p><h1 id="0a1e" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><p id="5697" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">这个神经网络框架比我们之前做的版本快多了。然而，我们的实现只支持分类器。如果你真的对用金属性能着色器构建其他神经网络模型感兴趣，我们的框架很灵活，你也可以修改它。保存模型是一件很平常的事情，这就是为什么我在这篇文章中没有考虑它。你可以在<a class="ae kv" href="https://github.com/stefjen07/ShadersNeuralNetwork" rel="noopener ugc nofollow" target="_blank">我的GitHub库</a>中找到保存有模型的源代码。</p><p id="dea1" class="pw-post-body-paragraph lo lp iq lq b lr mo jr lt lu mp ju lw lx mr lz ma mb mt md me mf mv mh mi mj ij bi translated">感谢阅读。如果你有任何建议或者你在这篇文章中发现了错误，请在评论中留下你的反馈。我已经准备好改善我的读者的体验。</p></div></div>    
</body>
</html>