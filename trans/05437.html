<html>
<head>
<title>How Computers Play the Imitation Game: From Autoencoders to StyleGAN2s in Less Than 10 Minutes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机如何玩模仿游戏:不到10分钟从自动编码器到StyleGAN2s</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-computers-play-the-imitation-game-from-autoencoders-to-stylegan2s-in-less-than-10-minutes-d0a89507cc04?source=collection_archive---------36-----------------------#2021-05-13">https://towardsdatascience.com/how-computers-play-the-imitation-game-from-autoencoders-to-stylegan2s-in-less-than-10-minutes-d0a89507cc04?source=collection_archive---------36-----------------------#2021-05-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4318" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">非极客的(小说)图像生成指南</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f44c35840865e9cae527ee9a97eea4a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yzsem2kpnLi6Dg7z"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">威廉·冈克尔在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="c1bf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这一切都始于1950年三个受试者玩的一个游戏。c会坐在一个单独的房间里，向A和B提出开放性的问题，接受书面回答，并试图从中辨别A和B是人还是机器。C的目标是把它做对，而A和B的目标是愚弄C。</p><p id="0559" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">自从机器开始研究如何通过图灵测试以来，已经过去了70年，它们已经走过了漫长的道路。</p><p id="7d18" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我是一名投资者，在游戏中呆了15年，对金融服务有一定程度的了解，是一名机器学习和Tensorflow免费击球手，但绝不是机器学习工程师。尽管如此，我认为内容生成技术告诉了我们很多关于计算机在模仿人类方面有多好的信息——并且可以在这个过程中教会我们一些谦逊和自我意识。</p><p id="5440" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">这篇文章的目标是在不到10分钟的时间里总结玩模仿游戏</strong>的最新计算机技术的发展。我同意，图灵将这个简单游戏的成功与回答更深层次的问题“<em class="ls">机器能思考吗？”</em>是一个很大的假设，但另一个时间。10分钟现在开始。</p><h1 id="72ee" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated"><strong class="ak">第一步:自动编码器和降维</strong></h1><p id="954b" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">为了公平地复制人类生产的东西(以及我们认为是人类生产的东西)，计算机应该首先学会理解，或者至少(让我们尽可能远离意识和自我意识这些令人毛骨悚然的概念)通过综合其核心维度来概括内容。</p><p id="cf3b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在现实生活中，通常可以在不丢失太多信息的情况下显著减少一个集合的特征数量。看下面的自然数序列。</p><p id="193d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">顺序= [1，2，4，8，16，32，64，128，256，512] </em></p><p id="3196" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然该序列包括10个数字，但显然该列表代表序列2ⁿ的前10个实例，其中<em class="ls"> n </em>从0开始。对于一个人来说，最多装备笔和纸，复制这样的序列的前10、20、50个成员而不全部记住是微不足道的。换句话说，我们已经确定了序列固有的低维特征，这些特征足以进行完美的复制。或者，更简单地说，我们发现了一种模式。但是机器也能做到这一点吗？</p><p id="d8ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你不会感到惊讶，他们可以，通过同样的测试和学习的方法，人类将适用于这个和更复杂的序列。这正是自动编码器所做的。</p><p id="9a19" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">什么是自动编码器？自动编码器是一种模型，它查看输入，提取有效的潜在表示(编码器)，并吐出希望看起来尽可能与输入相似的东西(解码器)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/ededcc6856a70afe01efdf81fdefe714.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P7aFcjaMGLwzTvjW3sD-5Q.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">自动编码器的图形表示:从输入到重构</p></figure><p id="737b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们来拍几张低分辨率的图片。编码器的工作是将(32高x 32宽x 3 RGB通道)像素中的信息压缩到更低的维度；解码器的任务是获取该表示，并尽可能地再现与原始图像接近的内容。第一次，我们的模型通过随机猜测做得很差，然后它做得好一点，然后再好一点，直到希望在多次迭代后它变得非常好，这取决于我们想要压缩原始信息的程度。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/4a1094d6a76a301be02938cdd65ab45a.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*FpJpCErp9efFh4vNuNElJQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">原始图像<em class="ms">与使用1个中间层和10个神经元的重建图像——实际上是将32x32x3像素中包含的信息压缩到10个感知器中。结果不出所料的差(卢瑟激活和极客的20个纪元)</em></p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/178f3254fa3cc1bc398fcd0dc9561475.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*uaPgMxNCptmagxGWNkKmSw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用具有100个神经元的1个中间层重建的图像—结果明显好得多(架构和其他参数保持不变)</p></figure><p id="b6d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您想要编码的信息非常(非常)大，或者非常混乱，并且模式很难被识别，那么我们简单的架构就不能令人满意地执行，并且需要扩展。但总是一样的东西。你扩展编码/解码层中的单元数量，你将这些层一层一层地堆叠起来，你玩被称为激活函数或超参数的东西，你不断地从输入到重建。你得到了<strong class="ky ir">深度自动编码器</strong>(它包括许多层)<strong class="ky ir">卷积自动编码器</strong>(它包括通过特殊过滤器过滤信息的层)<strong class="ky ir">递归自动编码器</strong>(它对它们所做的事情保持某种记忆)等等。但是如果你得到了最初架构的想法，基本上是一样的。</p><h1 id="d785" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated"><strong class="ak">第二步:变化的自动编码器和新东西的创造</strong></h1><p id="1615" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">但是有一类自动编码器，所谓的<strong class="ky ir">变型自动编码器</strong>，它的行为与其他编码器不同，并且<strong class="ky ir">不是尽可能接近你输入的内容，而是生成一些全新的东西，但可能类似于原始输入</strong>。你给模型1，000，000张雨伞的照片，然后(经过大量学习)它会产生一张真正像雨伞的照片，但那不是你分享的照片之一。这是赢得模仿游戏的第一步。</p><p id="d07f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一个可变的自动编码器在这个过程中引入了一点随机性。研究输入后，编码器生成输入(理论)分布的均值μ和标准差σ，而不是为其生成编码，即假设输入<em class="ls"> </em>呈正态分布时的均值和标准差。如果听起来很复杂，让我们一步一步来分析:</p><ol class=""><li id="bdb2" class="mt mu iq ky b kz la lc ld lf mv lj mw ln mx lr my mz na nb bi translated">编码器接收输入列表，并猜测μ和σ的两个值，假设两者都是0.5</li><li id="a814" class="mt mu iq ky b kz nc lc nd lf ne lj nf ln ng lr my mz na nb bi translated">然后，从μ = sigma = 0.5的正态分布中随机抽取一系列数字</li><li id="6c50" class="mt mu iq ky b kz nc lc nd lf ne lj nf ln ng lr my mz na nb bi translated">随后，解码器试图基于这些随机数再现输入(我们的图像)，并将其呈现给陪审团(一个客观函数)</li><li id="52fe" class="mt mu iq ky b kz nc lc nd lf ne lj nf ln ng lr my mz na nb bi translated">陪审团很可能会发现结果非常糟糕(这只是随机噪声),并将其退回</li><li id="33e0" class="mt mu iq ky b kz nc lc nd lf ne lj nf ln ng lr my mz na nb bi translated">结果很糟糕，原因有两个:输出看起来不像输入(即<strong class="ky ir">重建损失</strong>很高)，采样像素看起来不像是从正态分布中随机采样的(即<strong class="ky ir">潜在损失</strong>很高)——如果输入实际上是具有均值μ和标准差σ的正态分布，那么这些参数很可能不同于0.5</li><li id="f6e2" class="mt mu iq ky b kz nc lc nd lf ne lj nf ln ng lr my mz na nb bi translated">编码器更新他对μ和σ的估计，并对一组新的随机数进行采样，试图减少潜在损失</li><li id="bc97" class="mt mu iq ky b kz nc lc nd lf ne lj nf ln ng lr my mz na nb bi translated">然后，解码器产生一个新的估计，试图减少重建损失，并再次发送给陪审团</li></ol><p id="6067" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">很长一段时间后，我们将拥有足够好的模型参数来产生全新的图像——类似于模型被训练的输入。我们只需向模型输入随机噪声(正态分布)，并使用学习到的参数对其进行解码。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/f718cb812a624920c1bb3927d9fa54dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JiS5h0haNJsCFl8fHUFeEA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由一个变化的自动编码器生成的新的动画脸——图像很模糊，需要很长时间来训练，但结果很好，它们真正提醒我们由人类绘制的动画脸</p></figure><h1 id="4930" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">第三步:生成对手网络背后的思想</h1><p id="f94f" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">2014年，一组人工智能研究人员意识到，设计两个不同的模型试图愚弄对方，而不是让他们为同一支球队效力，结果将会显著改善。这个想法既简单又天才。</p><p id="d43c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们有一个发生器和一个鉴别器，它们互相对抗。<strong class="ky ir">发生器</strong>将随机噪声作为输入并输出图像(与解码器在上述可变自动编码器架构中工作的方式相同)。相反，<strong class="ky ir">鉴别器</strong>接收一组图像，并试图识别图像是真的还是伪造的。这是<em class="ls">事实上的</em>，一个在机器学习环境中重建的模仿游戏。</p><p id="3e17" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一阶段:给自己找一个好的鉴别者。我们首先训练鉴别器，目的是让它相当好地识别真实和伪造的图像。开始时这很容易，因为发生器只看到真实图像和发生器产生的初始假图像(看起来真的像噪声)。</p><p id="b3a2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">第二阶段:教发电机学会作弊</strong>。然后，我们训练生成器产生图像，鉴别器会错误地将这些图像归类为真实图像。生成者从来看不到任何真实的图像，而只是根据鉴别者识别伪造图像的能力来接收对其工作的间接反馈。鉴别器的好处是可以看到真实图像的样子。</p><p id="e2d4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">再现的图像很快变得相当好(比可变自动编码器的情况快得多)，但几乎同样快地停止改善。其背后的原因是，他们不断试图智胜对方，最终选择了相当成功的技术。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/2d08397bebd1fa7e98dfb1b6d00b6f80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MJ4Nrr_EeJUZRfZA"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@coachedwin?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">蔻驰·埃德温·因达尔托</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="d8fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">让我们假设，例如，我们正在训练GAN生成假的石头剪刀布图像</strong>。在开始时，生成器非常糟糕，然后它变得更好，然后最可能理解的是，用岩石图像(一个拳头)欺骗鉴别器比用手指开发一只完整的手容易得多——所以它不断生成许多拳头，可能没有太大改善，以及一些非常糟糕的纸和剪刀。最终，鉴别者赶上来，并开始区分假石头和真石头，如此之好，以至于在某一点上，生成器尝试另一种策略，即展示纸或剪刀。开始时，它们是如此糟糕，以至于鉴别者发现了它们，但后来是鉴别者忘记了如何识别假纸和假剪刀(记住，它已经在岩石上训练了一段时间，以便智胜生成器)，生成器开始获胜。GAN可能会在一段时间内陷入这种轮换策略，而没有真正的改善。电脑也很懒。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/185915a2b19645f1bb3acb5378889839.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YAKd69q_VaXz3CIZve7KhA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用StyleGAN架构生成的手语图像——经过50个时代后，拳头或拳头状图像的趋势显而易见</p></figure><p id="ff11" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">深度卷积GANs </strong> (DCGANs)来帮忙了，一层一层的叠加，包括滤波器，随机漏失，以及其他限制GANs不稳定性的技术。小图像的结果有所改善，但结果并不完美。在较大图像的情况下，重建可能会在某些细节上产生局部令人信服的结果，但整体效果不佳。</p><p id="1efa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2018年，英伟达的一个团队提议使用DCGANs来产生小图像，然后通过特定的过滤器(卷积层)在一个称为渐进增长(<strong class="ky ir"> ProGANs </strong>)的过程中逐步扩展它们。为了避免模式崩溃(即上述gan的懒惰/不稳定问题)和增加多样性，引入了一些其他创新。所有这些技术的结合为高质量的图像提供了非常好的结果。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/22312f4e840cbc061c410f6e4aa90e62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LesJoTSAQACNCwLA1HUnGA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://arxiv.org/pdf/1710.10196.pdf" rel="noopener ugc nofollow" target="_blank">为提高质量、稳定性和多样性而逐步种植的GANS</a>。使用CELEBA-HQ数据集生成的1024×1024图像(经过多天的训练)</p></figure><p id="3f8f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">研究小组通过比较每一层的风格，分析了生成的图片与原始图片的相似程度。这种比较程序提供了StyleGANs的想法，StyleGANs是目前小说图像生成中最先进的技术。</p><h1 id="09af" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">步骤4: StyleGANs和没有名字的人</h1><p id="5ee2" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">正是同一个Nvidia团队引入了StyleGANs的想法，即GANs，其中生成器被修改为使用样式转移技术，以便在局部和全局都具有与原始图像相似的结构。高质量图像的结果是惊人的。</p><p id="b10d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Rani Horev在StyleGANs 上的帖子提供了一个精彩的解释，但以下是他们主要特征的总结:</p><ul class=""><li id="c411" class="mt mu iq ky b kz la lc ld lf mv lj mw ln mx lr nl mz na nb bi translated"><strong class="ky ir">映射网络</strong>将输入编码成控制不同视觉特征的中间向量</li><li id="72e5" class="mt mu iq ky b kz nc lc nd lf ne lj nf ln ng lr nl mz na nb bi translated"><strong class="ky ir">风格模型</strong>将由映射网络编码的特征转移到每个分辨率级别的生成图像中(即，对于低级和高级图像特征)</li><li id="448e" class="mt mu iq ky b kz nc lc nd lf ne lj nf ln ng lr nl mz na nb bi translated">使用<strong class="ky ir">随机变化</strong>来生成不确定的或不能被映射网络映射的特征(如头发、雀斑、皱纹等)。)</li><li id="a260" class="mt mu iq ky b kz nc lc nd lf ne lj nf ln ng lr nl mz na nb bi translated"><strong class="ky ir">在生成图像的每个级别进行风格混合</strong>,以避免级别之间的相关性，这可能导致生成的图像遵循特定(且不一定真实)的模式</li></ul><p id="24a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种方法在生成新颖的逼真图像方面具有开创性，并在2020年的另一篇论文中得到进一步改进(该论文介绍了StyleGAN2s)。结果呢？自己判断。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/58b47ff743ab0b98aa46502877f36ef1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B32YFlvbHQ5snxVDWbHv2Q.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由StyleGAN2架构生成的图像—归功于<a class="ae kv" href="https://thispersondoesnotexist.com/" rel="noopener ugc nofollow" target="_blank">thispersondoesnotexist.com</a></p></figure><p id="a348" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你像我一样，想象照片上的人的生活，他的童年，他的青年，他的爱和恐惧，痛苦和快乐，然后提醒自己这实际上只是随机像素的集合，那么计算机真的在模仿游戏中走了很长的路。</p><p id="ab7f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我希望你喜欢这次短暂而紧张的旅程。应用程序的数量是巨大的，你可以选择是被它吓倒还是被它激励。这是你的选择。我们才刚刚开始。</p></div></div>    
</body>
</html>