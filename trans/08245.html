<html>
<head>
<title>Handling “Missing Data” Like a Pro — Part 3: Model-Based &amp; Multiple Imputation Methods</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">像专家一样处理“缺失数据”——第3部分:基于模型的多重插补方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/handling-missing-data-like-a-pro-part-3-model-based-multiple-imputation-methods-bdfe85f93087?source=collection_archive---------9-----------------------#2021-07-29">https://towardsdatascience.com/handling-missing-data-like-a-pro-part-3-model-based-multiple-imputation-methods-bdfe85f93087?source=collection_archive---------9-----------------------#2021-07-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="b69b" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><strong class="ak">数据科学。分析。PYTHON </strong></h2><div class=""/><div class=""><h2 id="15f3" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">面向21世纪数据科学家的基本和高级技术</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/131fbf6c21946bdfeba4695f3a31e1cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*r4n2CO_IToyXhuSw"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@two_tees?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">迈特·沃尔什</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="ecad" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正如我们在专门研究缺失数据系列的第一篇文章<a class="ae lh" rel="noopener" target="_blank" href="/the-three-types-of-missing-data-every-data-professional-should-know-d988e17d6ace">中所提到的，关于“缺失”的机制或结构的知识是至关重要的，因为我们的处理方法将主要依赖于它。</a></p><p id="17d7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在<a class="ae lh" rel="noopener" target="_blank" href="/handling-missing-data-like-a-pro-part-1-deletion-methods-9f451b475429">像专家一样处理“缺失数据”——第1部分——删除方法</a>中，我们已经讨论了删除方法。</p><p id="1d49" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在<a class="ae lh" rel="noopener" target="_blank" href="/handling-missing-data-like-a-pro-part-2-imputation-methods-eabbf10b9ce4">像专家一样处理“缺失数据”——第2部分:插补方法</a>中，我们讨论了简单的<strong class="lk jd">插补方法</strong>。虽然某些插补方法被认为适用于特定类型的数据，例如n <em class="me">正态分布数据、MCAR缺失等。</em>，这些方法主要是因为我们的估计和模型有偏差而受到批评。因此，有些人认为删除方法在某些情况下更安全。</p><p id="5fe4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">幸运的是，新的插补方法类别<strong class="lk jd">解决了简单插补和删除方法</strong>的这些弱点。</p><p id="f1cb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些是基于模型的多重插补方法。</p><h1 id="d008" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">加载数据集并模拟缺失</h1><p id="d4d8" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">加载成人数据集并模拟本文<a class="ae lh" rel="noopener" target="_blank" href="/handling-missing-data-like-a-pro-part-1-deletion-methods-9f451b475429">中的MCAR数据集。</a></p><h1 id="9540" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">基于模型的插补方法</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/1c3c95e448a56dda702d9a68756b1a2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*2ERnzXC_h2LobKL4kGXVow.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">本文中讨论的方法的总结</p></figure><p id="e071" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在我们的主要参考文献中，McKnight (2007)对基于模型的方法进行了不同的定义。在这种情况下，使用这些方法不是为了估计缺失数据，而是为了生成参数估计，就像观察到缺失数据一样。因此，它们被更恰当地称为<em class="me">数据增强方法</em>。</p><p id="8e83" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对我们来说，我们称之为基于模型，因为它们使用机器学习/统计模型来估计缺失数据。事实上，回归估计应该属于这里(来自我们的上一篇文章)，但我们已经将下面的方法分开，因为它们被视为复杂得多(因此数据科学家较少使用)。</p><p id="3505" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们已经开始讨论最大似然均值的产生。让我们再讨论其中的两种，EM算法和马尔可夫链蒙特卡罗方法。</p><h2 id="9a83" class="nd mg it bd mh ne nf dn ml ng nh dp mp lr ni nj mr lv nk nl mt lz nm nn mv iz bi translated">期望值最大化算法</h2><p id="05af" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">EM算法是在数据缺失时获得最大似然估计的通用方法(Dempster，Laird &amp; Rubin，1977)。</p><p id="7b77" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">基本上，EM算法由两个步骤组成:期望步骤(E)和最大化步骤(M)。这是一个为处理潜在(未观察到的)变量而设计的漂亮算法，因此适用于缺失数据。</p><p id="58dd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">要执行此算法:</p><ol class=""><li id="25f3" class="no np it lk b ll lm lo lp lr nq lv nr lz ns md nt nu nv nw bi translated">使用最大似然法估算缺失数据的值。使用每个观察值的<strong class="lk jd">非缺失</strong>变量计算缺失值的最大似然估计。</li><li id="5869" class="no np it lk b ll nx lo ny lr nz lv oa lz ob md nt nu nv nw bi translated">根据步骤1为“模拟的”完整数据集生成参数估计值。</li><li id="b64f" class="no np it lk b ll nx lo ny lr nz lv oa lz ob md nt nu nv nw bi translated">基于从步骤2获得的参数估计值(或“更新的”参数估计值)重新估算值。</li><li id="f845" class="no np it lk b ll nx lo ny lr nz lv oa lz ob md nt nu nv nw bi translated">根据步骤3中的估算数据重新估计参数。</li></ol><p id="daec" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当我们的参数估计“不再改变”或不再更新时，迭代过程停止。(<em class="me">技术术语是，当前值减去更新值的误差小于某个ε。</em>)</p><p id="3b77" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">与许多使用迭代的机器学习方法一样，EM算法产生的估计偏差较小。</p><p id="06e7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">要用一个包来估算，首先安装<code class="fe oc od oe of b">impyute</code>到<code class="fe oc od oe of b">pip install impyute.</code></p><p id="2b8a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">与我们的线性回归一样，最好在计算最大似然估计值时包括您的研究中没有包括的变量，以免使模型产生偏差。</p><p id="268d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">假设像KNN一样，我们希望使用下列项目的观测值来估计缺失数据:'<strong class="lk jd">年龄</strong>'、<strong class="lk jd"> fnlwgt </strong>'、<strong class="lk jd">教育人数</strong>'和'<strong class="lk jd">每周工作时间</strong>'。</p><p id="3edb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">代码应该是:</p><pre class="ks kt ku kv gt og of oh oi aw oj bi"><span id="ec20" class="nd mg it of b gy ok ol l om on">df10 = df.copy()</span><span id="41b2" class="nd mg it of b gy oo ol l om on"># importing the package<br/>import impyute as impy</span><span id="8382" class="nd mg it of b gy oo ol l om on"># imputing the missing value but ensure that the values are in matrix form</span><span id="caff" class="nd mg it of b gy oo ol l om on">df10[['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss',<br/>       'hours-per-week']] = \<br/>    impy.em(df10[['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss',<br/>       'hours-per-week']].values, loops=100)</span><span id="e21d" class="nd mg it of b gy oo ol l om on">#Simulate New Comparison Container (So we can separate these new categories)<br/>comparison_df = pd.concat([orig_df[['age', 'fnlwgt']], X], axis=1)</span><span id="a70d" class="nd mg it of b gy oo ol l om on">#Rename so We can Compare Across Datasets<br/>comparison_df.columns = ["age_orig", "fnlwgt_orig", "age_MCAR", "fnlwgt_MCAR"]<br/>cols = comparison_df.columns.to_list()</span><span id="06d2" class="nd mg it of b gy oo ol l om on">comparison_df = pd.concat([comparison_df, df10[['age', 'fnlwgt']]], axis=1)<br/>comparison_df.columns =  [*cols,'age_EM.imp', 'fnlwgt_EM.imp']</span><span id="ab08" class="nd mg it of b gy oo ol l om on">#View the comparison across dataset<br/>comparison_df.loc[fnlwgt_missing,["fnlwgt_orig","fnlwgt_MCAR",<br/>                              'fnlwgt_EM.imp']]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi op"><img src="../Images/d870a27eb2ed6c4d255c180bf732b468.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*yKlD-TCwnCMRKh5AIpEoYg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">与EM算法插补的比较。</p></figure><p id="a8cc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如我们所见，只需几行代码，我们就能执行EM插补。那些一直关注这个系列的人会立即看到，这是最接近我们理想想要的标准差参数的方法。</p><p id="93bc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，这种特殊的方法假设我们的数据是多元正态的。然而，我们缺少值的特征不能被假定为正态分布。年龄和最终体重通常是正偏的，不会变成负的。</p><blockquote class="oq or os"><p id="5ef7" class="li lj me lk b ll lm kd ln lo lp kg lq ot ls lt lu ou lw lx ly ov ma mb mc md im bi translated"><strong class="lk jd">因此，盲目应用代码导致年龄和最终体重的插补值为负值，这是不可能的！</strong></p></blockquote><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ow"><img src="../Images/830efcfb2f3f2c3362f1c0070e93ef7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*4mieX7Kd_Li3RK629G_F_g.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">EM方法估算的负最终权重</p></figure><p id="a024" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，在应用上面的代码之前，我们必须找到一种规范化值的方法。</p><p id="55fb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以简单地应用对数变换，并检查我们的算法对这些新变换的变量的效果。</p><pre class="ks kt ku kv gt og of oh oi aw oj bi"><span id="eb1a" class="nd mg it of b gy ok ol l om on">df11 = df.copy()</span><span id="8379" class="nd mg it of b gy oo ol l om on"># imputing the missing value but ensure that the values are in matrix form</span><span id="d9bf" class="nd mg it of b gy oo ol l om on">df11[['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss',<br/>       'hours-per-week']] = \<br/>    np.exp(impy.em(np.log(df10[['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss',<br/>       'hours-per-week']].values), loops=100))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ox"><img src="../Images/e282181d34d9497cd623d9d89eee00d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*dlKG37OW2SPJ6RAKn1aehQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">原始数据集和对数变换数据集上EM代码的比较。</p></figure><p id="b98c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">虽然我们的标准差较低，但与我们讨论过的其他单一插补方法相比，它仍具有更好的估计值。平均估计值也更接近原始值。</p><h2 id="4814" class="nd mg it bd mh ne nf dn ml ng nh dp mp lr ni nj mr lv nk nl mt lz nm nn mv iz bi translated">马尔可夫链蒙特卡罗方法</h2><p id="200e" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">基于最大似然法的模型的一个局限性是，它们需要数据的分布假设(例如多元正态性)。</p><p id="bc4b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">越来越流行的马尔可夫链蒙特卡罗(MCMC)程序可以在缺乏这种知识的情况下使用。该过程本质上是贝叶斯过程，最终目标是获得后验分布。</p><p id="1220" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们需要把这个概念分解成什么是马尔可夫链，蒙特卡洛与它有什么关系，但是我们把这个问题留给另一篇文章，这样这篇文章就简短了。但是像EM算法一样，MCMC增加了观测数据来处理参数的估计。</p><p id="2659" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从<code class="fe oc od oe of b">NumPyro</code>开始，这些也可以采用一个包。由于这种方法使用的代码比其他方法长得多，我们将读者引向NumPyro的官方文档:<a class="ae lh" href="http://num.pyro.ai/en/latest/tutorials/bayesian_imputation.html" rel="noopener ugc nofollow" target="_blank">http://num . pyro . ai/en/latest/tutorials/Bayesian _ attribute . html</a></p><h2 id="6642" class="nd mg it bd mh ne nf dn ml ng nh dp mp lr ni nj mr lv nk nl mt lz nm nn mv iz bi translated">其他SCIKIT估算器:贝叶斯岭、决策树、额外树、K邻居</h2><p id="dd1b" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">对本文中讨论的所有方法进行分类的一种方法是称它们为“多元估算器”。也就是说，它们基于数据集中存在的所有其他变量的值进行估算。</p><p id="8e00" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">由于大多数读者被认为熟悉机器学习，另一种看待它的方式是使用数据集内的可用数据作为预测器来估算缺失数据的机器学习模型。</p><p id="7727" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因为每个方法的过程都非常相似，所以让我们简单地为上面的四个方法创建一个循环。</p><pre class="ks kt ku kv gt og of oh oi aw oj bi"><span id="0548" class="nd mg it of b gy ok ol l om on">from sklearn.experimental import enable_iterative_imputer #MUST IMPORT THIS<br/>from sklearn.impute import IterativeImputer</span><span id="d0f9" class="nd mg it of b gy oo ol l om on">from sklearn.linear_model import BayesianRidge<br/>from sklearn.tree import DecisionTreeRegressor<br/>from sklearn.ensemble import ExtraTreesRegressor<br/>from sklearn.neighbors import KNeighborsRegressor</span><span id="3907" class="nd mg it of b gy oo ol l om on">#STEP 1 - Choosing Variables and Create a Matrix of Values<br/>df12 = df.copy()[['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss',<br/>       'hours-per-week']]</span><span id="3ddc" class="nd mg it of b gy oo ol l om on">X = df12.values #Matrix of Values</span><span id="373d" class="nd mg it of b gy oo ol l om on"># STEP 2 - INITIALIZE ESTIMATORS<br/>estimators = {<br/>    "bayesianridge":BayesianRidge(),<br/>    "DTrees": DecisionTreeRegressor(max_features='sqrt'),<br/>    "ETrees":ExtraTreesRegressor(n_estimators=10),<br/>    "KNreg":KNeighborsRegressor(n_neighbors=15)<br/>}</span><span id="89ea" class="nd mg it of b gy oo ol l om on"># STEP 3 - RUN IMPUTATIONS AND STORE IMPUTED VALUES<br/>for key, value in estimators.items():<br/>    imputer = IterativeImputer(random_state=19, estimator=estimators[key])<br/>    imputer.fit(X)<br/>    transformed = imputer.transform(X)<br/>    <br/>    #Temporarily Store<br/>    temp_df = pd.DataFrame(np.column_stack(list(zip(*transformed))), columns=df12.columns)<br/>    #Get updated columns list<br/>    <br/>    cols = comparison_df.columns.to_list()<br/>    <br/>    #Combine for Comparison <br/>    comparison_df = pd.concat([comparison_df, temp_df[['age', 'fnlwgt']]], axis=1)<br/>    comparison_df.columns =  [*cols,f'age_{key}.imp', f'fnlwgt_{key}.imp']</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/10023e550adb583e9a97a6b62401fe25.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*noSS7ZQoyAhDuv6z41J5xQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">不同scikit插补的比较。</p></figure><p id="4d1c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">请注意，我们可以尝试的估计量并不局限于上面的估计量。这些只是在这里找到的官方文档中讨论的:<a class="ae lh" href="https://scikit-learn.org/stable/auto_examples/impute/plot_iterative_imputer_variants_comparison.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/auto _ examples/impute/plot _ iterative _ import _ variants _ comparison . html</a></p><h1 id="7c93" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">多重插补方法</h1><p id="deb5" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">多重插补(MI)是目前处理缺失数据最受欢迎的方法。这些方法提供了无偏的(因此是可推广的)估计，并恢复了总体方差，这对于统计推断是至关重要的。</p><p id="0d03" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">单一插补方法的主要区别在于，不是为缺失的观察值输入一个值，而是输入几个值(比如3到10)。<strong class="lk jd">其平均值被视为最终估算值。</strong></p><p id="019a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">MI不仅仅是一种方法，而是处理多重价值估算的许多方法的术语。这些多个值是从一个迭代过程中得到的，该迭代过程使用了:<br/> <br/> 1。观察数据和<br/> 2。迭代期间生成的样本值。<br/> <br/>每组估算值随后被用来替换缺失值以创建一个完整的数据集。因此，如果我们选择估算3个值，这些值会产生三个完整的数据集。<br/> <br/>这些多个估计值被组合以获得感兴趣的参数的单个最佳估计值。例如，如果我们的方法是多元回归模型，则构建三个回归模型，每个完整数据集一个。得到的模型有它们相应的参数和系数估计值，这些估计值的平均值将是我们的最终值。</p><p id="ff63" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在Python中实现这一点的一个包是<strong class="lk jd"> MICEFOREST。—通过链式方程(小鼠)</strong>和随机森林(<code class="fe oc od oe of b">pip install miceforest</code>)进行多重插补。</p><p id="6f12" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">回想一下，在我们之前的例子中，决策树在恢复群体特征方面表现相对较好。因此，该软件包将使用随机森林方法应用多重插补，因此，让我们希望这将产生比我们之前更好的性能。</p><pre class="ks kt ku kv gt og of oh oi aw oj bi"><span id="fcdf" class="nd mg it of b gy ok ol l om on">import miceforest as mf</span><span id="8a5f" class="nd mg it of b gy oo ol l om on">df13 = df.copy()</span><span id="d03b" class="nd mg it of b gy oo ol l om on">df13 = df.copy()[['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss',<br/>       'hours-per-week']]</span><span id="a84d" class="nd mg it of b gy oo ol l om on"># Create kernel. <br/>kernel = mf.MultipleImputedKernel(<br/>  df13,<br/>  datasets=4,<br/>  save_all_iterations=True,<br/>  random_state=1989<br/>)</span><span id="b86b" class="nd mg it of b gy oo ol l om on"># Run the MICE algorithm for 3 iterations on each of the datasets<br/>kernel.mice(3)</span><span id="25d9" class="nd mg it of b gy oo ol l om on">#View Last Dataset Imputed</span><span id="a5ca" class="nd mg it of b gy oo ol l om on">kernel.complete_data(2).loc[fnlwgt_missing]</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/37097f35a4ab5b03dcc031b8b1558a0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*dVrmnOK_xhLlQUlVrNSShw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">来自MICEFOREST的结果</p></figure><p id="dd5f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在生成这些多次迭代之后，我们还需要做一件事:<strong class="lk jd">我们需要对它们进行平均</strong>。</p><pre class="ks kt ku kv gt og of oh oi aw oj bi"><span id="3ae1" class="nd mg it of b gy ok ol l om on">mi_results = pd.concat([kernel.complete_data(i).loc[:,["age", 'fnlwgt']] for i in range(3)]).groupby(level=0).mean()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/853985a494f8ad6f0d39efcbbb76d28f.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*unRHwg671yqVEUvzFJ14Pg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">最终比较，包括MICE森林估算</p></figure><p id="8879" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正如我们所看到的，我们的MI程序在恢复群体参数方面做得非常好。MI的一个不言而喻的优点是，我们摆脱了上面讨论的一些方法，特别是ML方法所带来的分布假设。</p><p id="0e78" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因为MI方法产生渐近无偏的估计，所以它们可以被实现用于MAR和MNAR机制！这对我们数据科学家来说是一个巨大的胜利。</p><p id="9c9d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">还有很多关于MICE方法的讨论，我们可以在这里回顾一下:<a class="ae lh" href="https://onlinelibrary.wiley.com/doi/epdf/10.1002/sim.4067" rel="noopener ugc nofollow" target="_blank">https://onlinelibrary.wiley.com/doi/epdf/10.1002/sim.4067</a></p><h1 id="e650" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">结束语</h1><p id="4947" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">虽然我们在这一系列文章中展示了许多备受推崇的现代技术，但我们必须记住以下几点:</p><ol class=""><li id="4b08" class="no np it lk b ll lm lo lp lr nq lv nr lz ns md nt nu nv nw bi translated">这些技术并不全面。新技术不断发展，推进了我们处理缺失数据的方式；</li><li id="d24f" class="no np it lk b ll nx lo ny lr nz lv oa lz ob md nt nu nv nw bi translated">该应用因用例及研究目标而异；在我们的案例中，我们只是通过参数估计来进行研究。</li><li id="07bb" class="no np it lk b ll nx lo ny lr nz lv oa lz ob md nt nu nv nw bi translated">尽管我们在这里讨论的方法很复杂，但是没有比避免缺失数据更好的方法来处理缺失数据。研究者应该对适当的研究设计、收集、储存和提取给予适当的考虑。</li></ol><p id="9ab2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">完整代码可以在我的<a class="ae lh" href="https://github.com/francisadrianviernes/Data-Preprocessing-and-Feature-Engineering/blob/master/Handling%20Missing%20Data%20Like%20a%C2%A0Pro.ipynb" rel="noopener ugc nofollow" target="_blank"> Github页面</a>找到。</p><h1 id="a714" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">参考</h1><p id="d3cc" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">麦克奈特，P. E. (2007)。<em class="me">缺失数据:温柔的介绍</em>。吉尔福德出版社。</p><div class="pb pc gp gr pd pe"><a href="https://github.com/AnotherSamWilson/miceforest#Simple-Example-Of-Multiple-Imputation" rel="noopener  ugc nofollow" target="_blank"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd jd gy z fp pj fr fs pk fu fw jc bi translated">GitHub-AnotherSamWilson/mice forest:Python中随机森林的多重插补</h2><div class="pl l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">通过具有随机森林的链式方程(小鼠)的快速、记忆有效的多重插补。它可以估算分类…</h3></div><div class="pm l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">github.com</p></div></div><div class="pn l"><div class="po l pp pq pr pn ps lb pe"/></div></div></a></div><div class="pb pc gp gr pd pe"><a href="https://onlinelibrary.wiley.com/doi/epdf/10.1002/sim.4067" rel="noopener  ugc nofollow" target="_blank"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd jd gy z fp pj fr fs pk fu fw jc bi translated">使用链式方程的多重插补:问题和实践指南</h2><div class="pl l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">生物统计学教程，通讯作者MRC生物统计学单位，公共卫生研究所，罗宾逊路…</h3></div><div class="pm l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">onlinelibrary.wiley.com</p></div></div><div class="pn l"><div class="pt l pp pq pr pn ps lb pe"/></div></div></a></div></div></div>    
</body>
</html>