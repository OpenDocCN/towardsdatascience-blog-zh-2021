<html>
<head>
<title>Davies-Bouldin Index for K-Means Clustering Evaluation in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中K-Means聚类评估的Davies-Bouldin索引</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/davies-bouldin-index-for-k-means-clustering-evaluation-in-python-57f66da15cd?source=collection_archive---------37-----------------------#2021-06-02">https://towardsdatascience.com/davies-bouldin-index-for-k-means-clustering-evaluation-in-python-57f66da15cd?source=collection_archive---------37-----------------------#2021-06-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8154" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在本教程中，我们将探索Davies-Bouldin索引及其在Python中K-Means聚类评估中的应用。</h2></div><p id="3646" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">目录</strong></p><ul class=""><li id="e5c4" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">介绍</li><li id="172b" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">戴维斯-波尔丁指数</li><li id="18c0" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">步骤1:计算组内离差</li><li id="13af" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">步骤2:计算分离度量</li><li id="8b43" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">步骤3:计算聚类之间的相似性</li><li id="4362" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">步骤4:为每个聚类<em class="ls"> i </em>找到最相似的聚类</li><li id="711c" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">步骤5:计算戴维斯-波尔丁指数</li><li id="57e6" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">Python中的Davies-Bouldin索引示例</li><li id="d6d9" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">结论</li></ul></div><div class="ab cl lt lu hx lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="im in io ip iq"><h1 id="31ad" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">介绍</h1><p id="e5cd" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr mu kt ku kv mv kx ky kz mw lb lc ld im bi translated">戴维斯-波尔丁指数(DBI)是聚类算法的评价指标之一。它最常用于通过K-Means聚类算法对给定数量的聚类评估分割的良好性。</p><p id="e67c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">简言之，分数(DBI)被计算为每个聚类与最相似的聚类的平均相似性。平均相似度越低，聚类分离得越好，执行聚类的结果也越好。</p><p id="008e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在下一节中，将通过几个示例详细描述计算DBI的过程。</p></div><div class="ab cl lt lu hx lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="im in io ip iq"><h1 id="b0b0" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">戴维斯-波尔丁指数</h1><p id="dfad" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr mu kt ku kv mv kx ky kz mw lb lc ld im bi translated">聚类分离度量的研究早在1979年就发表了。所提供的材料描述了作为群内分散和群间分离的函数的群间相似性的度量。</p><p id="a200" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这一部分中，我们将介绍计算的每一步，并提供有意义的示例来帮助更好地理解公式。</p><h2 id="3c74" class="mx mb it bd mc my mz dn mg na nb dp mk kr nc nd mm kv ne nf mo kz ng nh mq ni bi translated">步骤1:计算组内离差</h2><p id="d95d" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr mu kt ku kv mv kx ky kz mw lb lc ld im bi translated">考虑由Davies，d .，&amp; Bouldin，D. (1979)定义的下列方程，该方程计算集群<em class="ls"> i </em>的分散:</p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/3b8aab5a396df0963f2919d53f7a1a15.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*YKThP0JHb5g26BvfVEi_Sg.png"/></div></figure><p id="4620" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中:<br/> i:特定识别的簇<br/> T_i:簇<em class="ls">I</em>T10】X _ j:<em class="ls">j</em>簇<em class="ls">I</em>T15】A _ I:簇<em class="ls"> i </em>的质心</p><p id="4332" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">基本上，为了获得类内离差，我们计算类内每个观察值与其质心之间的平均距离。</p><p id="6821" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意:通常值<em class="ls"> q </em>被设置为2 ( <em class="ls"> q </em> = 2)，它计算聚类的质心和每个单独的聚类向量(观察)之间的欧几里德距离。</p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/8a5bed773e686b89ba4db5f563243b57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/0*dBx5bc4U2hco6mVy"/></div></figure><p id="9964" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设对某个数据集执行的K均值聚类生成了三个聚类。使用上面的公式，将为每个集群计算集群内离差，并且我们将得到<em class="ls">S1</em>、<em class="ls">S2</em>和<em class="ls">S3</em>的值。</p><h2 id="16ca" class="mx mb it bd mc my mz dn mg na nb dp mk kr nc nd mm kv ne nf mo kz ng nh mq ni bi translated">步骤2:计算分离度量</h2><p id="0faa" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr mu kt ku kv mv kx ky kz mw lb lc ld im bi translated">考虑由Davies，d .，&amp; Bouldin，D. (1979)定义的下列方程，该方程计算集群<em class="ls"> i </em>和<em class="ls"> j </em>之间的间隔:</p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/62e45b8a41f5bf3d9260fecc8d078d8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*auvK1BBYDjRxWTZbzuB8pg.png"/></div></figure><p id="abe2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中:<br/>A _ { ki }:<em class="ls">k</em>-<em class="ls">N</em>的第个分量-维质心<em class="ls">A _ I</em><br/>A _ { kj }:<em class="ls">k</em>-<em class="ls">N</em>的第个分量-维质心<em class="ls"> A_j </em> <br/> N:总簇数</p><p id="3ba5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上述公式也可以写成:</p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/49b381f26acbda0375b6b8610b934e84.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*RZHqJFqJzN3FEEyO8O5CSg.png"/></div></figure><p id="b186" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意:当<em class="ls"> p </em>设置为2 ( <em class="ls"> p </em> = 2)时，上式计算的是簇<em class="ls"> i </em>和<em class="ls"> j </em>的质心之间的欧氏距离。</p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/f68ea5ca3a95f0ebb3384d12886ca038.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/0*L4VhJ58hGWb--Jfe"/></div></figure><p id="ff3b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">继续假设我们正在处理三个集群。使用上面的公式，我们将计算两个集群的每个可能组合的分离度量:<em class="ls"> M_{11} </em>、<em class="ls"> M_{12} </em>、<em class="ls"> M_{13} </em>、<em class="ls"> M_{21} </em>、<em class="ls"> M_{22} </em>、<em class="ls"> M_{23} </em>、<em class="ls"> M_{31} </em>、</p><p id="f4d8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当然我们还有<em class="ls">M _ { 12 }</em>=<em class="ls">M _ { 21 }</em>，<em class="ls">M _ { 13 }</em>=<em class="ls">M _ { 31 }</em>，<em class="ls">M _ { 23 }</em>=<em class="ls">M _ { 32 }</em>。</p><h2 id="be14" class="mx mb it bd mc my mz dn mg na nb dp mk kr nc nd mm kv ne nf mo kz ng nh mq ni bi translated">步骤3:计算聚类之间的相似性</h2><p id="c1e9" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr mu kt ku kv mv kx ky kz mw lb lc ld im bi translated">考虑由Davies，d .，&amp; Bouldin，D. (1979)定义的下列等式，该等式计算集群<em class="ls"> i </em>和<em class="ls"> j </em>之间的相似性:</p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div role="button" tabindex="0" class="nw nx di ny bf nz"><div class="gh gi nv"><img src="../Images/760d0e8dda101b6e5f247138cd8fee96.png" data-original-src="https://miro.medium.com/v2/resize:fit:336/format:webp/1*St_lF8EDTOMv3Sv6h4r5mw.png"/></div></div></figure><p id="90f7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中:<br/> S_i:簇的簇内离差<em class="ls"> i </em> <br/> S_j:簇的簇内离差<em class="ls"> j </em> <br/> M_{ij}:簇的质心<em class="ls"> i </em>和<em class="ls"> j </em></p><p id="3443" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">基本上，我们在这里将聚类之间的相似性计算为两个聚类内离差之和除以分离度。<em class="ls"> R_{ij} </em>越大，相似簇<em class="ls"> i </em>和<em class="ls"> j </em>越多。你可能已经知道最好的情况是当这些数字尽可能低的时候。</p><p id="7e6a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">类似于<em class="ls">步骤2 </em>中的逻辑，继续假设我们正在处理三个集群。使用上面的公式，我们将计算两个集群的每个可能组合的相似性:<em class="ls"> R_{11} </em>，<em class="ls"> R_{12} </em>，<em class="ls"> R_{13} </em>，<em class="ls"> R_{21} </em>，<em class="ls"> R_{22} </em>，<em class="ls"> R_{23} </em>，<em class="ls"> R_{31} </em></p><p id="94ee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里，<em class="ls">R _ { 11 }</em>=<em class="ls">R _ { 22 }</em>=<em class="ls">R _ { 12 }</em>是每个簇与自身的相似度。而且我们还有<em class="ls">R _ { 12 }</em>=<em class="ls">R _ { 21 }</em>、<em class="ls">R _ { 13 }</em>=<em class="ls">R _ { 31 }</em>、<em class="ls">R _ { 23 }</em>=<em class="ls">R _ { 32 }</em>。</p><h2 id="643c" class="mx mb it bd mc my mz dn mg na nb dp mk kr nc nd mm kv ne nf mo kz ng nh mq ni bi translated">步骤4:为每个聚类<em class="oa"> i </em>找到最相似的聚类</h2><p id="ee37" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr mu kt ku kv mv kx ky kz mw lb lc ld im bi translated">戴维斯博士和波尔丁博士(1979年)定义:</p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/2cde66b384eacfd9b481d5b36d4ecf23.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*VZd1H0ZpkBt5zhDhQ2zcfw.png"/></div></figure><p id="f1fd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有:<em class="ls">I</em>≦<em class="ls">j</em></p><p id="55ef" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于每个集群<em class="ls"> i </em>，我们从所有计算的<em class="ls"> R_{ij} </em>中找到最高的比率。</p><p id="814c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，对于集群<em class="ls"> i </em> = 1，我们计算了<em class="ls"> R_{11} </em>、<em class="ls"> R_{12} </em>和<em class="ls"> R_{13} </em>。继续<em class="ls"> R_{12} </em>和<em class="ls"> R_{13} </em>(由于<em class="ls"> R_{11} </em>不满足约束<em class="ls">I</em>≦<em class="ls">j</em>，将集群与自身进行比较没有意义)。</p><p id="0e8f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，有了<em class="ls"> R_{12} </em>(这是聚类1和2之间的相似性)和<em class="ls"> R_{13} </em>(这是聚类1和3之间的相似性)。从这两个度量值中，我们将选择最大的一个，并将最大度量值称为<em class="ls"> R_{1} </em>。按照同样的逻辑，我们会发现<em class="ls"> R_{2} </em>和<em class="ls"> R_{3} </em>。</p><h2 id="0408" class="mx mb it bd mc my mz dn mg na nb dp mk kr nc nd mm kv ne nf mo kz ng nh mq ni bi translated">步骤5:计算戴维斯-波尔丁指数</h2><p id="4465" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr mu kt ku kv mv kx ky kz mw lb lc ld im bi translated">将戴维斯-波尔丁指数计算如下:</p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/a8484b4cf407dc2db57471fbe27b5d1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/format:webp/1*mZPGmTGSck3m0uUQxZW6gw.png"/></div></figure><p id="7213" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其简单地是每个聚类与最相似的聚类的相似性度量的平均值。</p><p id="7bb0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意:聚类的最佳选择是平均相似性最小化的地方，因此较小的<em class="ls"> R </em>条代表定义更好的聚类。</p></div><div class="ab cl lt lu hx lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="im in io ip iq"><h1 id="d9e4" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">Python中的Davies-Bouldin索引示例</h1><p id="eb83" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr mu kt ku kv mv kx ky kz mw lb lc ld im bi translated">在这一节中，我们将通过一个例子来计算Python中K-Means聚类算法的Davis-Bouldin指数。</p><p id="cdbc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，导入依赖项:</p><figure class="nk nl nm nn gt no"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="b08b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以通过下面的代码使用任何数据。为了简单起见，我们将使用内置的虹膜数据集，特别是前两个特征:<em class="ls">【萼片宽度】</em>和<em class="ls">【萼片长度】</em>:</p><figure class="nk nl nm nn gt no"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="f2f3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们从3个集群的K均值目标开始:</p><figure class="nk nl nm nn gt no"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="71bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">并检查上述结果的戴维斯-波尔丁指数:</p><figure class="nk nl nm nn gt no"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="b628" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您应该会看到结果分数:<strong class="kk iu"> 0.7675522686571647 </strong>或大约<strong class="kk iu"> 0.77 </strong>。</p><p id="bcf4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了更好地理解集群的外观，让我们将它们形象化:</p><figure class="nk nl nm nn gt no"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="a1e3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们应该看到以下3个集群:</p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div class="gh gi of"><img src="../Images/8df2744b8b0b0f0ae7f144bf887b95fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/0*2T_oscRbNxoelwHS"/></div></figure><p id="129a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">看起来有些集群比其他集群定义得更好。</p><p id="894c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">到目前为止，我们只计算了3个团簇的戴维斯-波尔丁指数。这种方法与肘方法类似，有助于确定最佳的聚类数。</p><p id="e439" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以对大于或等于2的任意数量的集群进行计算。让我们尝试多达10个集群:</p><figure class="nk nl nm nn gt no"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="62c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">想象一下:</p><figure class="nk nl nm nn gt no"><div class="bz fp l di"><div class="od oe l"/></div></figure><figure class="nk nl nm nn gt no gh gi paragraph-image"><div class="gh gi og"><img src="../Images/308c276e49ad1b1959f6c7643c760878.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/0*ngy-AVeM3YWVwhxN"/></div></figure><p id="ecfa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然在这个例子中，度量彼此非常接近，但是我们仍然可以观察到选择3个聚类最小化了相似性度量。</p></div><div class="ab cl lt lu hx lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="im in io ip iq"><h1 id="b1fc" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">结论</h1><p id="baee" class="pw-post-body-paragraph ki kj it kk b kl ms ju kn ko mt jx kq kr mu kt ku kv mv kx ky kz mw lb lc ld im bi translated">在本文中，我们讨论了如何使用sklearn库在Python中计算用于聚类评估的<a class="ae oh" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.davies_bouldin_score.html" rel="noopener ugc nofollow" target="_blank"> Davies-Bouldin指数</a>。</p><p id="082c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你有任何问题或者对编辑有任何建议，欢迎在下面留下评论，并查看我的更多<a class="ae oh" href="https://pyshark.com/category/python-programming/" rel="noopener ugc nofollow" target="_blank"> Python编程</a>文章。</p><p id="6edd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">参考文献:<br/>戴维斯博士，&amp;波尔丁博士(1979)。一种聚类分离度量。IEEE模式分析和机器智能汇刊，PAMI-1(2)，224–227。<a class="ae oh" href="https://doi.org/10.1109/TPAMI.1979.4766909" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1109/TPAMI.1979.4766909</a></p></div><div class="ab cl lt lu hx lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="im in io ip iq"><p id="e5df" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="ls">原载于2021年6月2日</em><a class="ae oh" href="https://pyshark.com/davies-bouldin-index-for-k-means-clustering-evaluation-in-python/" rel="noopener ugc nofollow" target="_blank"><em class="ls">https://pyshark.com</em></a><em class="ls">。</em></p></div></div>    
</body>
</html>