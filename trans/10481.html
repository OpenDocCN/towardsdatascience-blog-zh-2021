<html>
<head>
<title>HRNet explained: Human Pose Estimation, Semantic Segmentation and Object Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">HRNet解释道:人体姿态估计、语义分割和物体检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hrnet-explained-human-pose-estimation-sematic-segmentation-and-object-detection-63f1ce79ef82?source=collection_archive---------4-----------------------#2021-10-06">https://towardsdatascience.com/hrnet-explained-human-pose-estimation-sematic-segmentation-and-object-detection-63f1ce79ef82?source=collection_archive---------4-----------------------#2021-10-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a4d3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">揭示最先进的算法HRNet背后的东西</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c4572a3c7a7feafd85e6491ce54d0242.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rLhbwmHhjFF2u9NrO3iWpg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">克里斯蒂安·卢在<a class="ae ky" href="https://unsplash.com/s/photos/eye?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="4cbc" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mc">HRNet讲解概要:</em></p><ol class=""><li id="2cec" class="md me it li b lj lk lm ln lp mf lt mg lx mh mb mi mj mk ml bi translated">什么是<strong class="li iu"> HRNet </strong>？(简短解释，再往下就是完整解释)</li><li id="6a19" class="md me it li b lj mm lm mn lp mo lt mp lx mq mb mi mj mk ml bi translated"><strong class="li iu">应用领域</strong></li><li id="fb16" class="md me it li b lj mm lm mn lp mo lt mp lx mq mb mi mj mk ml bi translated">让我们深入研究<strong class="li iu">卷积神经网络</strong></li><li id="df0c" class="md me it li b lj mm lm mn lp mo lt mp lx mq mb mi mj mk ml bi translated">人力资源网如何工作？</li><li id="5c08" class="md me it li b lj mm lm mn lp mo lt mp lx mq mb mi mj mk ml bi translated"><strong class="li iu">结论</strong></li></ol><p id="12dc" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">如果你已经知道了基本知识(CNN +应用领域)，跳到第3节或第4节。</strong></p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="bde1" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">HRNet是什么？</h1><p id="f145" class="pw-post-body-paragraph lg lh it li b lj nj ju ll lm nk jx lo lp nl lr ls lt nm lv lw lx nn lz ma mb im bi translated">HRNet是语义分割、面部标志检测和人体姿态估计领域中最先进的算法。它在PASCAL Context、LIP、Cityscapes、AFLW、COFW和300W等数据集上显示出优越的语义分割结果。</p><p id="c6c9" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">但首先让我们了解一下字段的含义，以及HRNet背后隐藏着什么样的算法。</p><h1 id="f907" class="mr ms it bd mt mu no mw mx my np na nb jz nq ka nd kc nr kd nf kf ns kg nh ni bi translated">应用领域</h1><h2 id="cf49" class="nt ms it bd mt nu nv dn mx nw nx dp nb lp ny nz nd lt oa ob nf lx oc od nh oe bi translated">语义分割</h2><p id="eea6" class="pw-post-body-paragraph lg lh it li b lj nj ju ll lm nk jx lo lp nl lr ls lt nm lv lw lx nn lz ma mb im bi translated">语义分割<strong class="li iu">用于将图像的结构分类成特定的类别</strong>。这是通过用某一类标记每个像素来完成的[3]。在下面的示例中，表示骑自行车的所有像素都是类person，表示自行车的所有像素都是类bicycle [3]。图像分割的目的是让算法将图像分割成类别，从而分割成特定的结构。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/1afe2a2e73137b94823a12d7d8c031a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9ATXgoGvrOXukaOAgyWuCQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/#devkit" rel="noopener ugc nofollow" target="_blank">http://host.robots.ox.ac.uk/pascal/VOC/voc2012/#devkit</a></p></figure><p id="6c86" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">语义分割是用来做什么的？</p><p id="531e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">有各种各样的使用案例，图像分割才刚刚开始。它应用于自动驾驶、医学图像诊断、手写识别。</p><h2 id="d89b" class="nt ms it bd mt nu nv dn mx nw nx dp nb lp ny nz nd lt oa ob nf lx oc od nh oe bi translated">面部标志检测</h2><p id="a5d0" class="pw-post-body-paragraph lg lh it li b lj nj ju ll lm nk jx lo lp nl lr ls lt nm lv lw lx nn lz ma mb im bi translated">面部标志检测<strong class="li iu">用于识别和定位面部的某些区域</strong>，如鼻子、嘴、眼睛或眉毛【2】。在下图中，你可以看到使用OpenCV可以检测眉毛、鼻子和嘴(通过左图中的红点可以看到)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/befe81db412de1f83e932bece7355b6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rekAeufx3gMVi3qUL3_UEw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://learnopencv.com/face-swap-using-opencv-c-python/" rel="noopener ugc nofollow" target="_blank">https://learnopencv.com/face-swap-using-opencv-c-python/</a></p></figure><p id="2d50" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">面部标志检测</strong>是用来做什么的？</p><p id="406a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">你可能知道Snapchat或Instagram中的面部交换滤镜。或者其他一些改变你眼睛、鼻子或嘴巴的滤镜。所有这些过滤器与面部标志检测一起工作，以检测面部的某个部分位于何处。此外，它还用于人脸变形和头部姿态估计。</p><h2 id="07b1" class="nt ms it bd mt nu nv dn mx nw nx dp nb lp ny nz nd lt oa ob nf lx oc od nh oe bi translated">人体姿态估计</h2><p id="ab8a" class="pw-post-body-paragraph lg lh it li b lj nj ju ll lm nk jx lo lp nl lr ls lt nm lv lw lx nn lz ma mb im bi translated">人体姿态估计类似于面部标志检测，除了它是应用于整个身体的<strong class="li iu">，并且它与运动有更多的关系。它检测的不是面部区域，而是<strong class="li iu">语义关键点</strong>，如左肩、右膝等。[4].下图很好地描绘了线条如何绘制身体并识别某些点，通常是关节，如髋、膝、肩和肘。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/57d172030fc150130f24f97d7ae34664.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pcvyvpgNMuy4MCOG5ecKbw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:https://arxiv.org/abs/2103.02440<a class="ae ky" href="https://arxiv.org/abs/2103.02440" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="538b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">姿态估计</strong>集成在哪些应用中？</p><p id="af34" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">它应用于训练机器人，例如人形机器人。为了学习某些动作，人的动作是可以学习的。就在几天前，特斯拉宣布，它希望成为人形机器人领域的重要参与者，这表明这是一个未来的重要话题，可能会改变整个行业。</p><p id="c241" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">再者，应用于交互式运动游戏，如微软Kinect或其他VR应用[4]。</p><p id="a021" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">所有这些应用和方法都依赖于卷积神经网络，它是HRNet的基础。</strong></p><div class="oi oj gp gr ok ol"><a href="https://medium.com/@hucker.marius/membership" rel="noopener follow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">通过我的推荐链接加入Medium-Hucker Marius</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">medium.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz ks ol"/></div></div></a></div><h2 id="0b37" class="nt ms it bd mt nu nv dn mx nw nx dp nb lp ny nz nd lt oa ob nf lx oc od nh oe bi translated">让我们深入了解卷积神经网络</h2><p id="9c1a" class="pw-post-body-paragraph lg lh it li b lj nj ju ll lm nk jx lo lp nl lr ls lt nm lv lw lx nn lz ma mb im bi translated">一个<strong class="li iu">卷积神经网络(常为ConvNet或CNN) </strong>是计算机视觉领域经常应用的神经网络的特例。深度学习算法将图像作为输入，并为其对象分配重要性(由偏差和权重组成)[5]。</p><p id="4eda" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">好吧，这很肤浅。让我们看看为什么CNN是最先进的。</p><h2 id="ce9d" class="nt ms it bd mt nu nv dn mx nw nx dp nb lp ny nz nd lt oa ob nf lx oc od nh oe bi translated">正常的神经网络和CNN有什么区别？</h2><p id="f0c9" class="pw-post-body-paragraph lg lh it li b lj nj ju ll lm nk jx lo lp nl lr ls lt nm lv lw lx nn lz ma mb im bi translated">首先，HRNet中使用的卷积神经网络类似于普通的神经网络。两者都是基于神经元的，都有权重和偏差。主要区别在于架构。正常的神经网络不能很好地缩放，因此对图像没有用。图像并不像大多数人想象的那样平坦。图像是三维的，例如32×32×3。32x32是使图像成为二维的像素，x3是每个通道的颜色(RGB)。在普通的神经网络中，一个(隐藏)层的每一个节点都与前一层或下一层的所有节点相连。对于大小为32x32x3的图像，这将导致3072(=32x32x3)个权重。而往往图像并没有那么小，所以将其进一步缩放到高分辨率图像(如1000x1000x3)，构建全连接神经网络的权值和连接数会爆炸，降低神经网络的速度[7]。</p><p id="e33e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这就是卷积神经网络的用武之地。它不是构建平面层，而是将神经元排列成具有深度、高度和宽度维度的3D对象[7]。一个主要的优点是它保持了输出的尺寸。一个普通的神经网络会将维数减少到一个平坦的输出。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/9b611081bb89a4ff2b6b440a80f392fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4U2mB9ZE46Uj2LQz989MHQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">https://cs231n.github.io/convolutional-networks/</a>[7]</p></figure><p id="58c6" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">conv net有哪几层？</strong></p><p id="1f71" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mc">卷积层</em> —使用过滤器计算图像局部区域的输出</p><p id="051e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mc">池层</em> —沿空间维度执行缩减采样</p><p id="7bcd" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mc">全连接层</em> —计算最终的班级分数</p><h2 id="e141" class="nt ms it bd mt nu nv dn mx nw nx dp nb lp ny nz nd lt oa ob nf lx oc od nh oe bi translated">CNN的卷积层会发生什么？</h2><p id="7262" class="pw-post-body-paragraph lg lh it li b lj nj ju ll lm nk jx lo lp nl lr ls lt nm lv lw lx nn lz ma mb im bi translated">出于演示目的，我们假设输入图像的大小为5x5x1，如下图gif所示。卷积层的神奇之处在于过滤器(也称为内核)。在我们的示例中，过滤器的大小为3x3x1。这个内核/过滤器在整个图像上一小步一小步地移动(在我们的例子中是9步)并建立一个卷积特征。这降低了维度，并产生了一个激活图[5]。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/1daa4a69b5dc1efeb6f92f9f27dd78f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/1*Z87z69ufkGnNolH6R_Ln_w.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/" rel="noopener ugc nofollow" target="_blank">https://Daniel nouri . org/notes/2014/12/17/使用卷积神经网络检测面部关键点-教程/ </a></p></figure><p id="f6b2" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">为了覆盖所有特征和形状，应用了不止一个而是不同的过滤器(例如，5个不同的过滤器)。然后，网络将学习过滤器，当它们识别某种类型的视觉形状(例如，角或线)时，过滤器将激活。在分辨率更高的图像中，大小为5x5x1的滤镜可能会检测到其他形状，而大小为30x30x1的滤镜则不会。</p><p id="b84f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">每个过滤器产生一个激活图，识别某些形状和模式。所有这些激活图沿着深度维度堆叠，并产生输出矩阵[6]。</p><h2 id="9438" class="nt ms it bd mt nu nv dn mx nw nx dp nb lp ny nz nd lt oa ob nf lx oc od nh oe bi translated">在池层中会发生什么？</h2><p id="299e" class="pw-post-body-paragraph lg lh it li b lj nj ju ll lm nk jx lo lp nl lr ls lt nm lv lw lx nn lz ma mb im bi translated">通常在卷积层之间使用池层。它用于减少必要的参数和空间大小。这再次有助于降低所需的计算能力。有两种类型的池:最大池和平均池[7]。</p><p id="6593" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">最大池取过滤器/内核的最大值，而平均池计算内核所有值的平均值。</p><h2 id="0068" class="nt ms it bd mt nu nv dn mx nw nx dp nb lp ny nz nd lt oa ob nf lx oc od nh oe bi translated">全连接层会发生什么？</h2><p id="e3ce" class="pw-post-body-paragraph lg lh it li b lj nj ju ll lm nk jx lo lp nl lr ls lt nm lv lw lx nn lz ma mb im bi translated">这是一个层，你可能从传统的基本神经网络中知道它。完全连接的层与前一层的所有激活具有完全连接，并且在CNN中，它可以用作用于分类的最终层[7]。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/02e6c2f8d82d8f4db3e227b19245cfe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*TCGAV3JvaWABGC34jaN4LQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">https://cs231n.github.io/convolutional-networks/</a>[7]</p></figure><p id="f6c2" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">现在你应该知道深入HRNet的基本知识了。</p></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="5ee5" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">人力资源网是如何工作的？</h1><p id="7ba6" class="pw-post-body-paragraph lg lh it li b lj nj ju ll lm nk jx lo lp nl lr ls lt nm lv lw lx nn lz ma mb im bi translated">HRNet代表高分辨率网络，指的是正在处理的图像的高分辨率。<em class="mc">强高分辨率表示在像素和区域标记问题中起着重要作用，例如语义分割、人体姿态估计、面部标志检测和物体检测[1]随着像素的增长和更多基于视频的问题，高分辨率在未来可能会发挥越来越大的作用。</em></p><p id="a92f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">HRNet背后的网络称为HRNetV1，它“通过并行连接高分辨率到低分辨率的卷积来保持高分辨率的表示，其中并行卷积之间存在重复的多尺度融合。”<em class="mc">【1】</em></p><h2 id="32ab" class="nt ms it bd mt nu nv dn mx nw nx dp nb lp ny nz nd lt oa ob nf lx oc od nh oe bi translated">那么，这意味着什么呢？</h2><p id="e5f4" class="pw-post-body-paragraph lg lh it li b lj nj ju ll lm nk jx lo lp nl lr ls lt nm lv lw lx nn lz ma mb im bi translated">为了回答这个问题，让我们仔细看看下图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/8b730a167894b6abff4c6eb987a200e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SGjMTghF8SQdD2l-DDD9vQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://arxiv.org/pdf/1904.04514.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1904.04514.pdf</a></p></figure><p id="a93f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">你可以看到四个浅蓝色的方块。每个表示如上所述的多分辨率块，一个连接“高到低分辨率卷积<strong class="li iu"/><em class="mc">【1】</em>”的块。并行处理由多个通道映射线在彼此下方展示。黄色通道图代表最高分辨率，而红色小通道图代表最低分辨率。第四个模块并行处理4个分辨率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/a993ba9de5ef739a9e8623b11dfe1c4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*BIYwJGwbm4VGQAOoazg5SQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">资料来源:https://arxiv.org/pdf/1904.04514.pdf</p></figure><p id="0e1c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">多分辨率群卷积会发生什么？</strong></p><p id="e74c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">它<em class="mc">"是组卷积"</em>[这将是单行的方框，例如只有黄线] <em class="mc">"的简单扩展，它将输入通道分成几个通道子集，并分别在不同的空间分辨率上对每个子集执行常规卷积。"[1] </em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/9b3eb4e2576ba17627837f878d60c06b.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*5lhntnXLH1YUTJKpX5-EqA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:https://arxiv.org/pdf/1904.04514.pdf<a class="ae ky" href="https://arxiv.org/pdf/1904.04514.pdf" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="465c" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在每个阶段结束时，您可以看到<strong class="li iu">与下一阶段的多分辨率组</strong>的完全连接，看起来就像左侧的图像。HRNet的这一部分称为多分辨率卷积。</p><p id="1191" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="mc">“类似于规则卷积的多分支全连接方式。”[1] </em></p><p id="a479" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">换句话说，它将一级的规则盘旋(可能只是一条线)与下一级的所有平行盘旋连接起来。</p><p id="0a68" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu">HRNet的优势是什么，为什么它的性能优于以前的模型(AlexNet、GoogleNet、VGGNet、ResNet、DenseNet)？</strong></p><p id="caef" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">语义强大且空间精确:</p><ol class=""><li id="fef8" class="md me it li b lj lk lm ln lp mf lt mg lx mh mb mi mj mk ml bi translated">诸如低分辨率网络的传统卷积神经网络串联工作，因此从低分辨率恢复高分辨率。</li><li id="1437" class="md me it li b lj mm lm mn lp mo lt mp lx mq mb mi mj mk ml bi translated">HRNet的并行方法允许在整个神经网络中保持高分辨率，因此表示更加精确。</li><li id="e87b" class="md me it li b lj mm lm mn lp mo lt mp lx mq mb mi mj mk ml bi translated">其他方法聚集高分辨率和上采样的低分辨率表示。HRNet重复多分辨率并在语义上加强由高到低的表示。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/d8fcac8a3aea3ddb523c183d439c2d70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W2DJWlD--JgtgVLoz_03EA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">以前的CNN有串行卷积，没有并行。来源:<a class="ae ky" href="https://arxiv.org/pdf/1904.04514.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1904.04514.pdf</a></p></figure><h1 id="7b0e" class="mr ms it bd mt mu no mw mx my np na nb jz nq ka nd kc nr kd nf kf ns kg nh ni bi translated">HRNet及其变体</h1><p id="00bd" class="pw-post-body-paragraph lg lh it li b lj nj ju ll lm nk jx lo lp nl lr ls lt nm lv lw lx nn lz ma mb im bi translated">在HRNetV1中，只有高分辨率表示会产生输出(如下所示)。因此，低分辨率卷积的子集会丢失，并且不会完全包含在输出中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/ff89ac3ea10aaf680896a847e7006a91.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*vh1XNEWgUxn5vF0aP7BjCQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">HRNetV1插图。资料来源:https://arxiv.org/pdf/1904.04514.pdf</p></figure><p id="6add" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这就是为什么HRNet的发明者进行了修改，允许输出从高到低分辨率的所有子集。</p><p id="6f56" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">“好处是充分利用了多分辨率卷积的能力。”<em class="mc">【1】</em></p><p id="0e51" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">这是通过将低分辨率表示上采样到最高分辨率并连接所有结果子集来实现的。这个模型叫做<strong class="li iu"> HRNetV2 </strong>，主要用于估计分割图/面部地标热图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/3be261b20a47cddf9bee3e64b936ef92.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*Fq-e4ExsbpZKAJxaN3sR8A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">HRNetV2图示。来源:<a class="ae ky" href="https://arxiv.org/pdf/1904.04514.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1904.04514.pdf</a></p></figure><p id="acc9" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">另一个模型是HRNetV2，它是为对象检测而制造的。在这里，作者增加了一个步骤:“我们通过对多级平均汇集的高分辨率表示进行下采样来构建多级表示。”<em class="mc">【1】</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/3a9c8d7b5050d1dee83f08ab1744061e.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*keRNOE64DQXTthrITaGOOQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">HRNetV2p图解。来源:https://arxiv.org/pdf/1904.04514.pdf<a class="ae ky" href="https://arxiv.org/pdf/1904.04514.pdf" rel="noopener ugc nofollow" target="_blank"/></p></figure><h1 id="0f9d" class="mr ms it bd mt mu no mw mx my np na nb jz nq ka nd kc nr kd nf kf ns kg nh ni bi translated">结论</h1><p id="f3f0" class="pw-post-body-paragraph lg lh it li b lj nj ju ll lm nk jx lo lp nl lr ls lt nm lv lw lx nn lz ma mb im bi translated">HRNet及其变体(HRNetV1、HRNetV2、HRNetV2p)是计算机视觉领域中许多机器学习学科的最先进技术。作者将传统的串行卷积结构改为多组卷积的并行结构。这种架构允许高分辨率，并提高精度和语义连接。</p><p id="ccc9" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">人力资源网再次表明，打破常规的思维是实现最先进成果的必要条件。作者没有试图像AlexNet和co .那样改进现有的串行方法，但他们试图用一种更智能的方法彻底重建它，从而获得更高的结果。我很确定这只是将来有一天会取代HRNet的更复杂架构的开始。</p><div class="oi oj gp gr ok ol"><a href="https://medium.com/@hucker.marius/membership" rel="noopener follow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">通过我的推荐链接加入Medium-Hucker Marius</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">medium.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz ks ol"/></div></div></a></div><h2 id="de5f" class="nt ms it bd mt nu nv dn mx nw nx dp nb lp ny nz nd lt oa ob nf lx oc od nh oe bi translated"><a class="ae ky" href="https://medium.com/@hucker.marius/membership" rel="noopener">阅读更多像这样的</a></h2></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="8bec" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><strong class="li iu"> <em class="mc">来源</em> </strong></p><ol class=""><li id="2ef0" class="md me it li b lj lk lm ln lp mf lt mg lx mh mb mi mj mk ml bi translated">王等(2020)。用于视觉识别的深度高分辨率表征学习。<a class="ae ky" href="https://arxiv.org/pdf/1908.07919.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1908.07919.pdf</a></li></ol><p id="d9d8" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">2.Shakhadri，S. (2021年)。用Opencv简化面部标志检测。<a class="ae ky" href="https://www.analyticsvidhya.com/blog/2021/07/facial-landmark-detection-simplified-with-opencv/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2021/07/face-landmark-detection-simplified-with-opencv/</a></p><p id="2930" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">3.Jordan，J. (2018)。语义图像分割综述。<a class="ae ky" href="https://www.jeremyjordan.me/semantic-segmentation/" rel="noopener ugc nofollow" target="_blank">https://www.jeremyjordan.me/semantic-segmentation/</a></p><p id="6faa" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">4.奥德梅金德，E. (2021)。利用深度学习进行人体姿态估计——2021年终极概览。<a class="ae ky" href="https://viso.ai/deep-learning/pose-estimation-ultimate-overview/" rel="noopener ugc nofollow" target="_blank">https://viso . ai/deep-learning/pose-estimation-ultimate-overview/</a></p><p id="6cc9" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">5.萨哈，S. (2018)。卷积神经网络综合指南ELI5方法。<a class="ae ky" rel="noopener" target="_blank" href="/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">https://towards data science . com/a-comprehensive-guide-to-convolutionary-neural-networks-the-Eli 5-way-3bd2b 1164 a53</a></p><p id="116d" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">6.微软研究博客(2020)。高分辨率网络:用于视觉识别的通用神经结构。<a class="ae ky" href="https://www.microsoft.com/en-us/research/blog/high-resolution-network-a-universal-neural-architecture-for-visual-recognition/" rel="noopener ugc nofollow" target="_blank">https://www . Microsoft . com/en-us/research/blog/high-resolution-network-a-universal-neural-architecture-for-visual-recognition/</a></p><p id="e7b8" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">7.无作者(未注明)。卷积神经网络【https://cs231n.github.io/convolutional-networks/ T4】</p></div></div>    
</body>
</html>