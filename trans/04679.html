<html>
<head>
<title>Using Big Transfer to predict malaria</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用大转移预测疟疾</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-big-transfer-to-predict-malaria-9e4d1b1e6f02?source=collection_archive---------26-----------------------#2021-04-22">https://towardsdatascience.com/using-big-transfer-to-predict-malaria-9e4d1b1e6f02?source=collection_archive---------26-----------------------#2021-04-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="31ae" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用迁移学习将血液涂片分类为未感染或感染了引起疟疾的寄生虫</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/5cb6155b4ec8e2f83b438877e6cf19b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bZHMZtnxtOgZijbrbKlExQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Pixabay在<a class="ae kv" href="https://www.pexels.com/photo/black-white-mosquito-86722/" rel="noopener ugc nofollow" target="_blank">像素上拍摄的照片</a></p></figure><p id="16a7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">迁移学习是利用在一项任务中获得的知识来解决另一项任务的过程。先前训练的模型被用作基础，在其上添加一个层来微调模型以解决新的任务。</p><p id="e282" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本博客的主要目的是让读者了解什么是大转移，以及如何以最小的努力将它微调并应用于与预训练模型完全不同的领域中的问题。</p><p id="8e6f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<a class="ae kv" href="https://arxiv.org/pdf/2101.05913v3.pdf" rel="noopener ugc nofollow" target="_blank">的论文</a>“医学成像规模的监督转移学习”中，来自谷歌的研究人员证明，使用大转移(<a class="ae kv" href="https://arxiv.org/pdf/1912.11370.pdf" rel="noopener ugc nofollow" target="_blank"> BiT </a>)，可以提高各种医疗任务的准确性，如乳房x线摄影癌症识别、胸部x射线解释和皮肤状况分类。该论文还发现，使用BiT模型，他们仅使用30%-60%的训练数据就能够实现基线性能。</p><p id="b593" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在此之前，研究人员不清楚对一组自然图像的迁移学习如何适用于医学图像，因为图像大小的差异、域的差异以及使用医学图像中纹理的局部变化来检测感兴趣的病理。</p><p id="61fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我看到了Mark Rober的视频，讲述了斯坦福大学的一个团队如何开发了一台显微镜(<a class="ae kv" href="https://www.foldscope.com/" rel="noopener ugc nofollow" target="_blank"> Foldscope </a>)和一台纸离心机(<a class="ae kv" href="https://news.stanford.edu/2017/01/10/whirligig-toy-bioengineers-develop-20-cent-hand-powered-blood-centrifuge/" rel="noopener ugc nofollow" target="_blank"> Paperfuge </a>)，总共花费68美分，可以由一名训练有素的专业人员用来查看幻灯片和检测疟疾等疾病。虽然我没有设法得到从Foldscope收集的幻灯片图像数据集，但我发现了另一个<a class="ae kv" href="https://lhncbc.nlm.nih.gov/LHC-publications/pubs/MalariaDatasets.html" rel="noopener ugc nofollow" target="_blank">数据集</a>，其中幻灯片图像是由连接到传统光学显微镜的智能手机收集的。这一点很重要，因为在最需要这些检测的贫困社区，缺乏设备和资源是这些检测不容易获得的主要原因。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/77bb2983f0be2a6737d003f67152a204.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RO5Qw-5osnI2bsMjWH2Rsw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据集的未感染(左)和寄生(右)载玻片示例</p></figure><p id="cb1a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将所有这些放在一起，以及我对测试在医学图像数据集上微调BiT有多容易的兴趣，我决定在这个疟疾数据集上尝试大转移。</p><p id="e89e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本博客将让您了解使用位超规则(BiT-HyperRule)对特定任务的位模型进行微调是多么容易，位超规则是一种启发式方法，用于确定所有用于微调的超参数，并获得很好的结果。比特超规则是一个很好的起点，这也是我将在本教程中经历的。我假设读者具备深度学习的基础知识。你可以在这里查看这个教程的Jupyter笔记本。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h2 id="a289" class="ma mb iq bd mc md me dn mf mg mh dp mi lf mj mk ml lj mm mn mo ln mp mq mr ms bi translated">大传输(位)</h2><p id="6fab" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">BiT的主要特点是使用ImageNet-21k和JFT-300M等大型数据集进行预训练。本教程中使用的模型是BiT-M，它已经在ImageNet 21k上进行了预训练，ImageNet 21k是一个数据集，包含21，843个不同类别的1，400万张图像，并基于ResNet-50x1架构。还有其他变化的钻头可用，这里列出了<a class="ae kv" href="https://tfhub.dev/google/collections/bit/1" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="24a5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">BiT的优点是:</p><ol class=""><li id="fb79" class="my mz iq ky b kz la lc ld lf na lj nb ln nc lr nd ne nf ng bi translated">适用于各种各样的任务，甚至是那些领域不匹配的任务，如医学成像</li><li id="823e" class="my mz iq ky b kz nh lc ni lf nj lj nk ln nl lr nd ne nf ng bi translated">使用位超规则，可以获得很好的结果，并且可以通过进一步调整超参数来改善这一点(下面将详细介绍)</li><li id="1106" class="my mz iq ky b kz nh lc ni lf nj lj nk ln nl lr nd ne nf ng bi translated">模型的快速收敛。</li></ol><p id="6d52" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">记住这一点，让我们开始吧。</p><p id="65ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我建议在阅读本教程之前，先浏览一下在这里找到的<a class="ae kv" href="https://arxiv.org/pdf/1912.11370.pdf" rel="noopener ugc nofollow" target="_blank">的比特文件。</a></p><h2 id="09ec" class="ma mb iq bd mc md me dn mf mg mh dp mi lf mj mk ml lj mm mn mo ln mp mq mr ms bi translated">数据预处理:</h2><p id="7785" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">该数据集包含27558个图像，未感染和寄生的载玻片图像之间平分。然后，我们将数据集分成3个不同的子集:训练集、验证集和测试集。训练集用于训练模型，然后基于验证集的结果，选择最佳模型。通常，模型的超参数将使用验证集进行调整，但是因为我们使用位超规则，所以我们将只使用验证集来选择最佳模型。最后，测试集用于评估模型的最终性能。请注意，测试集应该是独立的，永远不要用于调整模型。</p><p id="9be4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种情况下，训练集包含90%的图像，验证集包含9%的图像，最后测试集包含1%的图像。</p><pre class="kg kh ki kj gt nm nn no np aw nq bi"><span id="fe21" class="ma mb iq nn b gy nr ns l nt nu">train_size = int(0.90 * num_examples)<br/>val_size = int(0.09* num_examples)<br/>test_size = int(0.01 * num_examples)</span><span id="b70a" class="ma mb iq nn b gy nv ns l nt nu">full_dataset = ds.shuffle(reshuffle_each_iteration=False, buffer_size=len(ds))<br/>train_dataset = full_dataset.take(train_size)<br/>test_val_dataset = full_dataset.skip(train_size)<br/>val_dataset = test_val_dataset.take(val_size)<br/>test_dataset = test_val_dataset.skip(val_size)</span></pre><h2 id="fc76" class="ma mb iq bd mc md me dn mf mg mh dp mi lf mj mk ml lj mm mn mo ln mp mq mr ms bi translated">数据扩充和标准化；</h2><p id="8f08" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">收集和标记数据是一个昂贵的过程。数据扩充是用现有数据毫不费力地创建更多数据的方法。通过修改现有图像，如旋转、翻转，可以从现有图像生成新图像。其他数据扩充方法包括裁剪等技术，但在这种情况下不使用，因为它可能会导致图像的主要特征被删除。</p><pre class="kg kh ki kj gt nm nn no np aw nq bi"><span id="4eb3" class="ma mb iq nn b gy nr ns l nt nu">features['image'] = tf.image.random_flip_left_right(features['image'])<br/>features['image'] = tf.image.random_flip_up_down(features['image'])</span></pre><p id="4bb7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还对图像数据进行了归一化处理，使该值介于0-1之间。这有助于确保数据具有相似的分布，从而有助于模型更快地收敛。这也有助于提高模型的稳定性。</p><pre class="kg kh ki kj gt nm nn no np aw nq bi"><span id="42ba" class="ma mb iq nn b gy nr ns l nt nu">features['image'] = tf.cast(features['image'], tf.float32) / 255.0</span></pre><h2 id="8545" class="ma mb iq bd mc md me dn mf mg mh dp mi lf mj mk ml lj mm mn mo ln mp mq mr ms bi translated">添加输出图层:</h2><p id="2aae" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">因为我们将使用的位模型是一个特征提取器，所以我们需要添加一个输出层，神经元的数量等于类的数量(本例中为2)。然后，我们将该层的权重初始化为0。</p><pre class="kg kh ki kj gt nm nn no np aw nq bi"><span id="ea0a" class="ma mb iq nn b gy nr ns l nt nu">class MyBiTModel(tf.keras.Model):<br/>  """BiT with a new head."""</span><span id="e618" class="ma mb iq nn b gy nv ns l nt nu">def __init__(self, num_classes, module):<br/>    super().__init__()</span><span id="69c7" class="ma mb iq nn b gy nv ns l nt nu">    self.num_classes = num_classes<br/>    <strong class="nn ir">self.head = tf.keras.layers.Dense(num_classes, kernel_initializer='zeros')</strong> <br/>    self.bit_model = module</span></pre><h2 id="e9dc" class="ma mb iq bd mc md me dn mf mg mh dp mi lf mj mk ml lj mm mn mo ln mp mq mr ms bi translated">使用位超规则设置超参数:</h2><ol class=""><li id="355d" class="my mz iq ky b kz mt lc mu lf nw lj nx ln ny lr nd ne nf ng bi translated">批量:512个</li><li id="ff58" class="my mz iq ky b kz nh lc ni lf nj lj nk ln nl lr nd ne nf ng bi translated">学习率:0.003</li><li id="10be" class="my mz iq ky b kz nh lc ni lf nj lj nk ln nl lr nd ne nf ng bi translated">计划长度:500</li><li id="f215" class="my mz iq ky b kz nh lc ni lf nj lj nk ln nl lr nd ne nf ng bi translated">计划界限= 720，1440，2160</li></ol><p id="4f62" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">比特超规则规定，对于具有小于20 k的标记示例的数据集，调度长度应该是500步，而那些具有小于500 k的标记示例的数据集应该是10 k步。因为这个问题中的标记示例数是27558，刚好超过20 k标记示例边界，所以我决定坚持500步。</p><p id="4663" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">初始学习率是0.003，并且在步骤720、1440、2160中衰减10倍。这些步骤分别占整个训练步骤的30%、60%和90%</p><p id="e27e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">提前停止回调以防止过拟合:</strong></p><p id="39a4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了防止过度拟合，使用了早期停止，这是一种在被监视的度量没有按预期表现时停止训练的方法。在这种情况下，如果验证损失连续10个时期没有减少，则停止训练，并且恢复来自具有最小验证损失的时期的模型权重。</p><pre class="kg kh ki kj gt nm nn no np aw nq bi"><span id="451f" class="ma mb iq nn b gy nr ns l nt nu">es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10,restore_best_weights=True)</span></pre><h2 id="0472" class="ma mb iq bd mc md me dn mf mg mh dp mi lf mj mk ml lj mm mn mo ln mp mq mr ms bi translated">优化器和损失函数:</h2><p id="0ed1" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">使用带动量的随机梯度下降优化器。选择的损失函数是稀疏分类损失函数。当标签的数量为2或更多时，使用该损失函数，并且它期望类别标签是整数。</p><pre class="kg kh ki kj gt nm nn no np aw nq bi"><span id="3bfd" class="ma mb iq nn b gy nr ns l nt nu">optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)<br/>loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)</span></pre><h2 id="8055" class="ma mb iq bd mc md me dn mf mg mh dp mi lf mj mk ml lj mm mn mo ln mp mq mr ms bi translated">训练模型:</h2><p id="2352" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">现在是激动人心的部分，按回车键+回车，让模型训练！完成这一步后，去给自己做一杯热饮吧，这是你应得的！</p><pre class="kg kh ki kj gt nm nn no np aw nq bi"><span id="420a" class="ma mb iq nn b gy nr ns l nt nu">model.compile(optimizer=optimizer,loss=loss_fn,metrics=['accuracy'])</span></pre><p id="0757" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种情况下，验证损失在时段31之后没有减少，因此从时段31开始恢复并使用。</p><p id="7ab8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">列车运行前检查:</strong></p><p id="04a5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在花费时间和资源在<em class="nz"> x </em>时代上训练模型之前，重要的是执行某些健全性检查以确保模型按预期执行。</p><p id="8a31" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最重要的是检查输出值是否有意义。在分类模型的情况下，概率的总和值应该是1。</p><pre class="kg kh ki kj gt nm nn no np aw nq bi"><span id="bacf" class="ma mb iq nn b gy nr ns l nt nu">test_logits = model(test_image) #running the model on a test image<br/><strong class="nn ir">sum_proba = (np.sum(tf.nn.softmax(test_logits).numpy()[0]))</strong> #summimg the probabilities <br/>#sum_proba should be 1. </span></pre><p id="0d70" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">列车运行后检查:</strong></p><p id="b03e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">重要的是，对于特定的图像，当图像稍微改变时，例如旋转或翻转，模型输出不会改变。这被称为不变性检查。为了测试这一点，我们增加了测试集中的图像，并检查模型的预测在单个图像的所有不同变化中是否一致。</p><pre class="kg kh ki kj gt nm nn no np aw nq bi"><span id="202a" class="ma mb iq nn b gy nr ns l nt nu">Pseudocode for post-train check: <br/>1. Classify image with the trained model <br/>2. Augment the image (rotate/ flip) and then classify it again <br/>if result from 1 == result from 2:<br/>   Model passes post-train check<br/>else:<br/>   Retrain model such that it is invariant to augmentations which does not change the main features of the image.</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/08933b04c97c75b94d4d7662c8a1e396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*he8cVdFLZy4YXtdTnxOjTQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">用于不变性检查的旋转图像</p></figure><h2 id="6f4d" class="ma mb iq bd mc md me dn mf mg mh dp mi lf mj mk ml lj mm mn mo ln mp mq mr ms bi translated">评估模型:</h2><p id="4ddc" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">一旦训练完成，我们确保用来自最佳时期的权重来拟合模型。在这种情况下，这是验证损失最小的模型。</p><pre class="kg kh ki kj gt nm nn no np aw nq bi"><span id="6822" class="ma mb iq nn b gy nr ns l nt nu">model.load_weights('best_model')</span></pre><p id="1193" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们可以通过查看以下指标来继续分析该模型:</p><ol class=""><li id="8f75" class="my mz iq ky b kz la lc ld lf na lj nb ln nc lr nd ne nf ng bi translated"><strong class="ky ir">测试集上的准确性</strong>:使用274幅图像的整个测试集，我们测试它的准确性。我们发现准确率高达97.46%</li></ol><p id="2c5f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2.<strong class="ky ir">混乱矩阵:</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/ff954071ad154c3b138a0ece49995d85.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*090k68v29IevnEr4Xwr_0w.png"/></div></figure><p id="2857" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">混淆矩阵允许我们以NxN矩阵的形式评估模型，其中N是类的数量。它让我们很好地了解模型的性能以及真阳性、真阴性、假阳性和假阴性的数量。该数据还可以用于重新训练模型，以改进特定类别的结果。例如，在医疗保健环境中，假阴性(当患者实际上患有疾病时，他/她被确定为健康)比假阳性(当他/她实际上没有疾病时，患者被检测为患有疾病)成本更高。</p><p id="f57a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，错误分类的例子的数量是7，其中5个被错误地预测为寄生。其他两个图像被预测为未感染，而它们实际上是寄生图像。</p><p id="b22a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 3。ROC-AUC: </strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/28b31a8c75ec3a7201e22d0d4dfe4250.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*IdUGxwxDHf5A7rUNSdHOKw.png"/></div></figure><p id="9dcb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">受试者工作特征(ROC)曲线下的面积是衡量模型性能的一个非常重要的指标。以下摘录来自对ROC-AUC曲线的简单解释<a class="ae kv" rel="noopener" target="_blank" href="/understanding-auc-roc-curve-68b2303cc9c5">此处</a>:<br/>“AUC-ROC曲线是在各种阈值设置下对分类问题的性能测量。ROC是概率曲线，AUC代表可分性的程度或度量。它告诉我们这个模型在多大程度上能够区分不同的类。AUC越高，模型预测0为0和1为1的能力越强。以此类推，AUC越高，模型在区分患病和未患病患者方面就越好”</p><h2 id="5a54" class="ma mb iq bd mc md me dn mf mg mh dp mi lf mj mk ml lj mm mn mo ln mp mq mr ms bi translated">结论:</h2><p id="5870" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">使用BiT-HyperRule得到的模型在验证集上的准确率为96.81%，在测试集上的准确率为97.46%，ROC-AUC为0.99。这表明BiT在对医疗数据集进行分类时表现出色，即使它所训练的图像在性质上非常不同。</p><p id="c485" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一个有趣的观察是，在开始稳定之前，验证损失和准确性在最初的几个时期急剧下降。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/4970f85a2af9853a8243994d689dc198.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*8p2oxdgSMPPPGnVOxAvBVA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">验证损失与纪元图</p></figure><p id="56ae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这可能是由于学习率和批量大小。当用不同的超参数进行试验时，即通过将批量减少到64(而不是512)并将学习率从0.003降低到0.0001，发现验证损失遵循递减趋势，并且不像上图那样波动。但是，在得出任何结论之前，还需要进行进一步的实验。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><p id="af46" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">人工智能有助于让这些疾病的诊断变得更便宜、更容易，当大规模应用时，这将产生巨大的影响。我很乐观，并且真的相信人工智能可以真正彻底改变医疗保健的状况，特别是在发展中国家和不发达国家，那里最需要廉价和容易获得的医疗保健，而且疟疾等致命疾病仍然存在。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><p id="cd5f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢谷歌的研究人员，他们研究了比特技术，也感谢谷歌实验室<a class="ae kv" href="https://colab.research.google.com/github/google-research/big_transfer/blob/master/colabs/big_transfer_tf2.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>的作者展示了如何使用比特技术。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><p id="6340" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">“医学成像规模的监督迁移学习”的作者指出，模型可以通过超参数优化进一步改进。在下一篇博客中，我将尝试通过使用定制的超参数来提高模型的性能。所以请继续关注第2部分！</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><p id="d635" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nz">感谢阅读。如果你有任何问题，请在下面评论。当这个博客的第二部分出来的时候，请跟随我在Medium上阅读它。我在</em><a class="ae kv" href="https://www.linkedin.com/in/bikramb/" rel="noopener ugc nofollow" target="_blank"><em class="nz">LinkedIn</em></a><em class="nz">和</em><a class="ae kv" href="https://twitter.com/baruahbikram05" rel="noopener ugc nofollow" target="_blank"><em class="nz">Twitter</em></a><em class="nz">上也有空。希望你有美好的一天</em>🙂</p></div></div>    
</body>
</html>