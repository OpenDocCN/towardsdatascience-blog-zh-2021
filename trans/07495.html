<html>
<head>
<title>July 2021: ML News and Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2021年7月:ML新闻与代码</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/july-2021-ml-news-and-code-367f7d09a77e?source=collection_archive---------29-----------------------#2021-07-08">https://towardsdatascience.com/july-2021-ml-news-and-code-367f7d09a77e?source=collection_archive---------29-----------------------#2021-07-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1f11" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">全球范围内对更大的语言模型的竞赛，由专家组成，从Yandex和Huggingface、SpeechBrain等处进行分布式学习。而OpenAI驱动的GitHub Copilot会改变计算机编程吗？以下是我们每月精选的最新ML新闻、研究和代码:</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c7c51a9415af6198739e2574f208cc00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x2wF3ETkN1l47afRJkRWtA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="f501" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们已经到了2021年的中途，ML领域还在继续旋转:关于<a class="ae lr" href="http://cvpr2021.thecvf.com/" rel="noopener ugc nofollow" target="_blank">计算机视觉和模式识别(CVPR 2021) </a>的会议刚刚召开，Github和OpenAI发布了Copilot，这是一款前所未有的智能代码完成助手，在过去几周还发生了更多事情。<a class="ae lr" href="http://www.zeta-alpha.com/" rel="noopener ugc nofollow" target="_blank">泽塔阿尔法</a>很乐意帮助你发现最新的人工智能研究和软件，并让你保持最新。尽情享受吧！</p><h1 id="2f62" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">🗞有些消息</h1><p id="41f5" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">超大型模特的趋势还远未结束。一年前<a class="ae lr" href="https://arxiv.org/abs/2005.14165" rel="noopener ugc nofollow" target="_blank"> OpenAI的GPT-3 </a>发布了1750亿个参数，让AI社区大吃一惊。本月是武道2.0打破记录的时候，这表明中国在人工智能研究方面一点也不落后。悟道是一个多模态(文本和图像)大规模模型，具有1.75万亿个参数，基于混合专家架构(稍后将详细介绍！).虽然官方新闻稿只触及了模型的表面，并没有太多关于它的公开信息，但论文概述了用于训练模型的系统:<a class="ae lr" href="https://arxiv.org/abs/2103.13262" rel="noopener ugc nofollow" target="_blank"> FastMoE:一个快速的专家混合训练系统</a>在arXiv上，代码在GitHub上开源。希望OpenAI能做得更多。</p><p id="dd78" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">虽然武道没有公开，<a class="ae lr" href="https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/" rel="noopener ugc nofollow" target="_blank"> GPT-J </a>是:迄今为止最佳零拍表演，表演公开可用的GPT变形金刚(在6B参数)，最近由<a class="ae lr" href="https://github.com/kingoflolz" rel="noopener ugc nofollow" target="_blank">王贲</a>和<a class="ae lr" href="https://twitter.com/arankomatsuzaki" rel="noopener ugc nofollow" target="_blank">阿兰小松崎</a>发布。由JAX建造，这是对图书馆的又一次推动，在过去的两年里，图书馆缓慢但稳定地受到欢迎。</p><p id="31f3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，<a class="ae lr" href="https://copilot.github.com/" rel="noopener ugc nofollow" target="_blank"> Github Copilot </a>几天前刚刚发布:一个带来下一代代码合成的插件，基于Codex，一个来自OpenAI的类似GPT的模型，在公共Github代码的大规模数据集上训练。但是该公告导致了一个醒目的登录页面，上面有精选的示例，并且公开演示仍然不可用。很多问题还悬而未决:这个模型能做多大、多快推断？使用的训练数据集的细节是什么？我们是否应该担心受版权保护的数据会像在previously⁵展示的那样被模型意外地暴露出来？这个<a class="ae lr" href="https://twitter.com/Skiminok/status/1409961744294838273?s=20" rel="noopener ugc nofollow" target="_blank"> twitter帖子</a>揭示了这个话题，我们迫不及待地想亲自尝试一下……它有可能使编程效率提高10倍，并使编写代码民主化，但它必须非常非常好地工作。我们知道无bug代码是不存在的。会比带自动驾驶汽车上路容易吗？</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="a929" class="ls lt iq bd lu lv mw lx ly lz mx mb mc jw my jx me jz mz ka mg kc na kd mi mj bi translated">🐍密码</h1><p id="9756" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">这里有一些值得一试的库和资源。</p><h2 id="4425" class="nb lt iq bd lu nc nd dn ly ne nf dp mc le ng nh me li ni nj mg lm nk nl mi nm bi translated">👾<a class="ae lr" href="https://github.com/learning-at-home/hivemind" rel="noopener ugc nofollow" target="_blank">在家学习/hivemind </a> ⭐️ 715 |📄<a class="ae lr" href="https://arxiv.org/abs/2002.04013" rel="noopener ugc nofollow" target="_blank">论文</a></h2><p id="2ac1" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated"><em class="nn">👉想通过众包计算用专有技术训练像Google和OpenAI那样的大型模型吗？别再看了。</em></p><div class="no np gp gr nq nr"><a href="https://github.com/learning-at-home/hivemind" rel="noopener  ugc nofollow" target="_blank"><div class="ns ab fo"><div class="nt ab nu cl cj nv"><h2 class="bd ir gy z fp nw fr fs nx fu fw ip bi translated">在家学习/业余学习</h2><div class="ny l"><h3 class="bd b gy z fp nw fr fs nx fu fw dk translated">Hivemind是一个PyTorch库，用于在互联网上训练大型神经网络。它的预期用途是训练和…</h3></div><div class="nz l"><p class="bd b dl z fp nw fr fs nx fu fw dk translated">github.com</p></div></div><div class="oa l"><div class="ob l oc od oe oa of kp nr"/></div></div></a></div><p id="c166" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">🚀主要功能(来自自述文件)</p><ul class=""><li id="f135" class="og oh iq kx b ky kz lb lc le oi li oj lm ok lq ol om on oo bi translated">训练任意大小的神经网络。</li><li id="12a5" class="og oh iq kx b ky op lb oq le or li os lm ot lq ol om on oo bi translated">没有主节点的分布式训练:分布式哈希表允许连接分散网络中的计算机。</li><li id="c3d0" class="og oh iq kx b ky op lb oq le or li os lm ot lq ol om on oo bi translated">容错反向传播:即使某些节点没有响应或响应时间过长，向前和向后传递也会成功。</li><li id="e93f" class="og oh iq kx b ky op lb oq le or li os lm ot lq ol om on oo bi translated">分散的参数平均:迭代地聚集来自多个工作者的更新，而不需要在整个网络上同步。</li></ul><h2 id="cb1f" class="nb lt iq bd lu nc nd dn ly ne nf dp mc le ng nh me li ni nj mg lm nk nl mi nm bi translated">📈更多用于分布式培训的框架和库…</h2><p id="ef3f" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">👾<a class="ae lr" href="https://github.com/microsoft/DeepSpeed" rel="noopener ugc nofollow" target="_blank">微软/DeepSpeed </a> ⭐️ 5.2k|🌐<a class="ae lr" href="https://www.deepspeed.ai/" rel="noopener ugc nofollow" target="_blank">网站</a> <em class="nn">👉为极端规模的机器学习模型(如微软的图灵-NLG (17B参数))执行分布式训练的框架。</em></p><p id="a510" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">👾<a class="ae lr" href="https://github.com/horovod/horovod" rel="noopener ugc nofollow" target="_blank"> horovod/horovod </a> ⭐️ 11.4k |🌐<a class="ae lr" href="https://horovod.ai/" rel="noopener ugc nofollow" target="_blank">网站</a> |📄<a class="ae lr" href="https://arxiv.org/abs/1802.05799" rel="noopener ugc nofollow" target="_blank">论文</a> <em class="nn">👉用于TensorFlow、Keras、PyTorch和Apache MXNet的分布式深度学习培训框架。</em></p><p id="b871" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">👾<a class="ae lr" href="https://github.com/facebookresearch/fairscale" rel="noopener ugc nofollow" target="_blank">Facebook research/fair scale</a>⭐️1.2k<em class="nn">👉用于高性能和大规模培训的PyTorch扩展库。</em></p><p id="eaf0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">👾<a class="ae lr" href="https://github.com/pytorch/xla" rel="noopener ugc nofollow" target="_blank"> pytorch/xla </a> ⭐️ 1.4k <em class="nn">👉使用</em> <a class="ae lr" href="https://www.tensorflow.org/xla" rel="noopener ugc nofollow" target="_blank"> <em class="nn"> XLA深度学习编译器</em> </a> <em class="nn">连接</em> <a class="ae lr" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> <em class="nn"> PyTorch深度学习框架</em> </a> <em class="nn">和</em><a class="ae lr" href="https://cloud.google.com/tpu/" rel="noopener ugc nofollow" target="_blank"><em class="nn">Cloud TPUs</em></a><em class="nn">的Python包。</em></p><h2 id="6e21" class="nb lt iq bd lu nc nd dn ly ne nf dp mc le ng nh me li ni nj mg lm nk nl mi nm bi translated">👾⭐️ 2.5k</h2><p id="0bce" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated"><em class="nn">👉基于PyTorch的开源一体化语音工具包。</em></p><div class="no np gp gr nq nr"><a href="https://github.com/speechbrain/speechbrain" rel="noopener  ugc nofollow" target="_blank"><div class="ns ab fo"><div class="nt ab nu cl cj nv"><h2 class="bd ir gy z fp nw fr fs nx fu fw ip bi translated">言语大脑/言语大脑</h2><div class="ny l"><h3 class="bd b gy z fp nw fr fs nx fu fw dk translated">SpeechBrain是一个基于PyTorch的开源一体化语音工具包。目标是创建一个单一、灵活的…</h3></div><div class="nz l"><p class="bd b dl z fp nw fr fs nx fu fw dk translated">github.com</p></div></div><div class="oa l"><div class="ou l oc od oe oa of kp nr"/></div></div></a></div><p id="3233" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">🚀主要功能(来自自述文件)</p><ul class=""><li id="0e1c" class="og oh iq kx b ky kz lb lc le oi li oj lm ok lq ol om on oo bi translated">涵盖的领域和任务:语音识别、特征提取和增强、说话人识别、身份识别和二进制化、语音增强和分离以及多麦克风处理。</li><li id="d094" class="og oh iq kx b ky op lb oq le or li os lm ot lq ol om on oo bi translated">集成了多个预训练模型🤗拥抱脸。</li><li id="77ef" class="og oh iq kx b ky op lb oq le or li os lm ot lq ol om on oo bi translated">抽象，如Brain类，删除模式的不必要的细节，同时完全可定制的定价和评估。</li><li id="1311" class="og oh iq kx b ky op lb oq le or li os lm ot lq ol om on oo bi translated">通过PyTorch数据并行或分布式数据并行和混合精度训练进行多GPU训练。</li><li id="61d7" class="og oh iq kx b ky op lb oq le or li os lm ot lq ol om on oo bi translated">透明且可定制的输入和输出管道:原生PyTorch数据加载器、缩减采样、BPE标记化等。</li></ul><p id="39f1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">➕:一个新的类似的库值得一试:<a class="ae lr" href="https://github.com/sooftware/OpenSpeech" rel="noopener ugc nofollow" target="_blank">软件/OpenSpeech </a></p><h2 id="22f5" class="nb lt iq bd lu nc nd dn ly ne nf dp mc le ng nh me li ni nj mg lm nk nl mi nm bi translated">🤖最近流行的变压器实现…</h2><p id="0b3e" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">👾Facebook research/xcit⭐️415 |📄<a class="ae lr" href="https://arxiv.org/abs/2106.09681" rel="noopener ugc nofollow" target="_blank">论文</a>👉交叉协方差图像变换器的实现(XCiT)⁸</p><p id="7023" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">👾<a class="ae lr" href="https://github.com/kzl/decision-transformer" rel="noopener ugc nofollow" target="_blank">kzl/决策变压器</a> ⭐️ 661 |📄<a class="ae lr" href="https://sites.google.com/berkeley.edu/decision-transformer" rel="noopener ugc nofollow" target="_blank">论文</a>👉通过序列建模的强化学习。</p><p id="c89c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">👾<a class="ae lr" href="https://github.com/NVlabs/SegFormer" rel="noopener ugc nofollow" target="_blank"> NVlabs/SegFormer </a> ⭐️ 403 |📄<a class="ae lr" href="https://arxiv.org/abs/2105.15203" rel="noopener ugc nofollow" target="_blank">论文</a>👉用变形金刚进行语义分割。</p><p id="2ed9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">👾<a class="ae lr" href="https://github.com/OATML/non-parametric-transformers" rel="noopener ugc nofollow" target="_blank">oatml/非参数变压器</a> ⭐️ 217 |📄<a class="ae lr" href="https://arxiv.org/abs/2106.09681" rel="noopener ugc nofollow" target="_blank">论文</a>👉一次处理整个数据集，并使用数据点而不是参数。</p><h2 id="c414" class="nb lt iq bd lu nc nd dn ly ne nf dp mc le ng nh me li ni nj mg lm nk nl mi nm bi translated">👾<a class="ae lr" href="https://github.com/compphoto/BoostingMonocularDepth" rel="noopener ugc nofollow" target="_blank">comp photo/BoostingMonocularDepth</a>@ cvpr 21 | P<a class="ae lr" href="http://yaksoy.github.io/highresdepth/" rel="noopener ugc nofollow" target="_blank">项目页面</a></h2><p id="01dc" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated"><em class="nn">👉高分辨率单目深度估计。</em></p><div class="no np gp gr nq nr"><a href="https://github.com/compphoto/BoostingMonocularDepth" rel="noopener  ugc nofollow" target="_blank"><div class="ns ab fo"><div class="nt ab nu cl cj nv"><h2 class="bd ir gy z fp nw fr fs nx fu fw ip bi translated">comp photo/boosting monoculardepth</h2><div class="ny l"><h3 class="bd b gy z fp nw fr fs nx fu fw dk translated">这个库包含我们的CVPR2021出版物的实现:提升单目深度估计模型以…</h3></div><div class="nz l"><p class="bd b dl z fp nw fr fs nx fu fw dk translated">github.com</p></div></div><div class="oa l"><div class="ov l oc od oe oa of kp nr"/></div></div></a></div><p id="fbe1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">🚀这个实现太酷了，我们不得不包括它。它实现了CVPR 2021论文<a class="ae lr" href="https://arxiv.org/abs/2105.14021" rel="noopener ugc nofollow" target="_blank">通过内容自适应多分辨率合并</a> ⁰.将单目深度估计模型提升到高分辨率</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="b6d0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的每月选择到此结束，如果你想了解更多关于事物的研究方面，请查看2021年7月arXiv的最佳，这是最近ML学术文献的选择。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="8635" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="nn">参考文献</em></p><p id="53af" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[1] <a class="ae lr" href="https://arxiv.org/abs/2101.03961" rel="noopener ugc nofollow" target="_blank"> <em class="nn">开关变压器:以简单有效的稀疏性缩放至万亿参数模型</em></a>——William Fedus，Barret Zoph和Noam Shazeer，2021。</p><p id="a50e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[2] <a class="ae lr" href="https://arxiv.org/abs/2103.13262" rel="noopener ugc nofollow" target="_blank"> <em class="nn"> FastMoE:一种快速的专家混合训练系统</em> </a> —何家傲等，2021。</p><p id="fe25" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[3] <a class="ae lr" href="https://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank"> <em class="nn">一幅图像抵得上16x16个字:大规模图像识别的变形金刚</em></a>——作者阿列克谢·多索维茨基、卢卡斯·拜尔、亚历山大·科列斯尼科夫、德克·韦森博恩、翟晓华等人2021。</p><p id="1e92" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[4] <a class="ae lr" href="https://projecteuclid.org/journals/annals-of-statistics/volume-29/issue-5/Greedy-function-approximation-A-gradient-boostingmachine/10.1214/aos/1013203451.full" rel="noopener ugc nofollow" target="_blank"> <em class="nn">贪婪函数逼近:一个梯度推进机</em></a>—j . h . Friedman著，2001。</p><p id="49ba" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[5] <a class="ae lr" href="https://arxiv.org/abs/2012.07805" rel="noopener ugc nofollow" target="_blank"> <em class="nn">从大型语言模型中提取训练数据</em></a><em class="nn">——</em>Nicholas Carlini等人2020。</p><p id="1b80" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[6] <a class="ae lr" href="https://arxiv.org/abs/2105.13626" rel="noopener ugc nofollow" target="_blank"> <em class="nn"> ByT5:用预先训练好的字节到字节模型</em></a><em class="nn">——作者:</em>薛，阿迪蒂亚·巴鲁阿，诺亚·康斯坦特，拉米·阿尔-Rfou等人2021。</p><p id="02fe" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[7] <a class="ae lr" href="https://arxiv.org/abs/1603.02754" rel="noopener ugc nofollow" target="_blank"> <em class="nn"> XGBoost:一个可扩展的树提升系统</em> </a> —陈天琦，Carlos Guestrin，2016。</p><p id="54cd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[8] <a class="ae lr" href="https://arxiv.org/abs/2106.09681" rel="noopener ugc nofollow" target="_blank"> <em class="nn"> XCiT:互协方差图像变换器</em></a><em class="nn">—</em>Alaaeldin El-Nouby等人2021。</p><p id="419e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[9] <a class="ae lr" href="https://jmlr.org/papers/v22/20-302.html" rel="noopener ugc nofollow" target="_blank"> <em class="nn">注意力是图灵——完成</em></a><em class="nn">——</em>豪尔赫·佩雷斯、巴勃罗·巴塞洛和哈维尔·马林科维奇，2021。</p><p id="5bb9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[10] <a class="ae lr" href="https://arxiv.org/abs/2105.14021" rel="noopener ugc nofollow" target="_blank"> <em class="nn">通过内容自适应多分辨率合并将单目深度估计模型提升到高分辨率</em> </a> <em class="nn"> — </em>作者:S. Mahdi H. Miangoleh，Sebastian Dille，龙脉，Sylvain Paris和yaz Aksoy，2021。</p></div></div>    
</body>
</html>