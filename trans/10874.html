<html>
<head>
<title>Workout Monitoring Using Optical-Flow — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用光流监测健身程序—第1部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/workout-monitoring-using-optical-flow-part-1-4fa81f8cb56e?source=collection_archive---------23-----------------------#2021-10-21">https://towardsdatascience.com/workout-monitoring-using-optical-flow-part-1-4fa81f8cb56e?source=collection_archive---------23-----------------------#2021-10-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="dc13" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一份关于图像处理项目的详细报告，该项目始于学术界，并在一次行业会议上发表</h2></div></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi km"><img src="../Images/61cfbc4a804bcbcc6b0960947454d132.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*ZdvqEgcjtDoHnJ6dHA5obQ.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">光流叠加示例练习(作者提供GIF)</p></figure><p id="e4c3" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">这是我和我的团队Shaked Cohen，Inbal Rimon和Hagai Michel构建的图像处理项目系列文章的第一部分。本部分将提供项目概述以及工作流程描述。未来的部分将深入系统的不同组件:</p><p id="6a16" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">第1部分:项目概述和工作流程</p><p id="5b7b" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated"><a class="ae lu" rel="noopener" target="_blank" href="/workout-monitoring-using-optical-flow-part-2-8cd55e55fbe5">第二部分:光流和举重</a></p><p id="227e" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">第三和第四部分:TBD</p><p id="00bc" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">这个项目是作为一门名为“数字图像处理”(DIP)的学术课程的一部分完成的，由教授<em class="lv">塔米·瑞克林·拉维夫</em>领导，我之前在<a class="ae lu" rel="noopener" target="_blank" href="/lessons-i-learnt-from-my-first-image-processing-hackathon-f3f8ae6ae748">这里</a>写过。这个项目，以及同一课程的其他项目，也在<a class="ae lu" href="https://www.systematics.co.il/matlab-simulink-blog/bgu-students/" rel="noopener ugc nofollow" target="_blank">系统学网站</a>(以色列MATLAB经销商，希伯来文)上有所介绍。</p></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><h1 id="f947" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">一些背景</h1><p id="85d3" class="pw-post-body-paragraph ky kz iq la b lb mo jr ld le mp ju lg lh mq lj lk ll mr ln lo lp ms lr ls lt ij bi translated">我们在2020年初开始从事这个项目，就在COVID成为现实的几个月前。为什么我们在将近2年后现在写它？因为我们终于找到时间了。哦，可能是因为该项目被接受作为以色列机器视觉大会(<a class="ae lu" href="https://www.imvc.co.il/" rel="noopener ugc nofollow" target="_blank"> IMVC2021 </a>)的现场演示。</p><p id="f52f" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">该项目的目标是实现一个基于经典图像处理和计算机视觉工具的实时视频处理系统。</p><blockquote class="mt mu mv"><p id="2af3" class="ky kz lv la b lb lc jr ld le lf ju lg mw li lj lk mx lm ln lo my lq lr ls lt ij bi translated">等等，没有深度学习？那我为什么要在乎？！</p></blockquote><p id="64d9" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">这是一个很好的问题。如果你对SoTA结果或一些新颖的方法感兴趣，那么你可能不应该这样做，但是如果你有兴趣了解图像处理的核心工具以及如何用它们解决现实世界的问题，你应该继续读下去。</p><p id="bd1c" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">对于我们的项目，我们选择关注对人类运动的实时监控。我们选择这个主题是因为它提出了一个巨大的挑战:</p><ul class=""><li id="4aa6" class="mz na iq la b lb lc le lf lh nb ll nc lp nd lt ne nf ng nh bi translated">运动过程中的人体运动相对较快，需要允许实时处理速度(10~30 FPS)的高效算法。</li><li id="2511" class="mz na iq la b lb ni le nj lh nk ll nl lp nm lt ne nf ng nh bi translated">人体是一个高度可变形的形状，尤其是在运动时。这意味着我们识别和跟踪受训者的方法不能依赖于每个框架内的固定形状或位置。</li><li id="b17b" class="mz na iq la b lb ni le nj lh nk ll nl lp nm lt ne nf ng nh bi translated">练习和正确练习之间的区别是微妙的。这需要足够灵敏的运动和姿态跟踪方法来注意到这种差异。</li></ul></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><h1 id="a2e6" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">项目概述</h1><p id="09c4" class="pw-post-body-paragraph ky kz iq la b lb mo jr ld le mp ju lg lh mq lj lk ll mr ln lo lp ms lr ls lt ij bi translated">我们的系统——蔻驰健身中心——为4种不同的锻炼提供反馈:仰卧起坐、深蹲、单人举重和双人举重。一旦开始练习，将受训者从背景中分割出来，并进行进一步的裁剪和遮罩细化，以仅保留感兴趣的对象。然后屏蔽的视频被用于监控正在进行的锻炼。最后，在输入视频之上生成反馈，以通知受训者他们的进度并添加任何姿势校正(如果必要)。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi nn"><img src="../Images/c5a03fe0fd396945adf1c9afc389b1e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e13c5f_0OqK2642obkBR2A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">系统流程图(作者提供的图表)</p></figure><p id="89a0" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">每个练习都提出了独特的挑战，需要实施四个独立的反馈机制:</p><p id="2790" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated"><strong class="la ir">单次举重:</strong>检测帧中的径向运动，估计手臂角度。</p><p id="be90" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated"><strong class="la ir">双人举重:</strong>使用面部检测算法定位受训者，并利用达芬奇的身体比例来设置最佳运动范围。</p><p id="00cf" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated"><strong class="la ir">深蹲:L </strong>通过计算给定面具的重心来定位受训者的下半身。</p><ul class=""><li id="7f51" class="mz na iq la b lb lc le lf lh nb ll nc lp nd lt ne nf ng nh bi translated"><strong class="la ir">仰卧起坐:</strong>使用智能裁剪和几何变换最大化FPS。</li></ul><p id="3c83" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">下图展示了不同的练习和一些给用户反馈的例子。是的，我们知道UI是可怕的，我们做了最少的工作，以便将大部分时间投入到系统的大脑上，而不是美化它。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi ns"><img src="../Images/22d5371355bac2e8e679350f158873df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DyWxkrhTmWDuWCSA4rDNQw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者供图)</p></figure><p id="53ac" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">每个练习使用的逻辑和算法将在本系列的未来部分详细解释，但现在我们想分享我们的工作过程以及我们如何结束使用光流。</p><h1 id="9af8" class="lw lx iq bd ly lz nt mb mc md nu mf mg jw nv jx mi jz nw ka mk kc nx kd mm mn bi translated">通往最佳细分的漫长道路</h1><p id="2839" class="pw-post-body-paragraph ky kz iq la b lb mo jr ld le mp ju lg lh mq lj lk ll mr ln lo lp ms lr ls lt ij bi translated">由于所有四个练习都依赖于良好的分割，这项任务在早期就成为我们项目的主要焦点。我们对现有方法进行了文献回顾，并测试了不同的实现，直到找到最佳解决方案。我们训练了基于特征的对象检测器，使用休变换来检测图像中的线条和圆形，以及许多其他方法，这些方法提供的结果很差，并且计算量很大(远非实时)。</p><p id="fe4f" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">我们尝试过使用基于颜色的过滤，但是我们很快排除了它，因为它需要使用绿色屏幕或者强迫受训者穿非常特殊的颜色。面对现实吧，基本上就是作弊，没有挑战性。</p><p id="3433" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">那时，我们开始提出自己的算法，这些算法都基于两个主要概念:</p><ol class=""><li id="f3ef" class="mz na iq la b lb lc le lf lh nb ll nc lp nd lt ny nf ng nh bi translated"><em class="lv">简单性</em>:解决方案必须足够简单，以便我们能够实时提供反馈。</li><li id="eefc" class="mz na iq la b lb ni le nj lh nk ll nl lp nm lt ny nf ng nh bi translated"><em class="lv">基于运动的</em>:解决方案应该利用受训者是帧中唯一的运动对象这一事实。</li></ol><p id="7d67" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在实践中，这些算法对两个连续的帧执行一些操作，并试图通过减去处理过的帧来检测运动。我们尝试使用空间导数，索贝尔过滤器，Canny边缘检测和更多。尽管如此，我们仍然非常依赖于这样的想法，即最好的分割依赖于捕捉时间轴上的运动。</p><p id="dd88" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">这是其中一种算法的简化版本:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="e59e" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">这里的主要思想是:</p><ol class=""><li id="e14c" class="mz na iq la b lb lc le lf lh nb ll nc lp nd lt ny nf ng nh bi translated">将两个连续帧转换成二进制边缘图像:</li></ol><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="no np di nq bf nr"><div class="gh gi ob"><img src="../Images/a7c64512500e7bfa92955976aab6e56d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JS-sVnhdNFYFDD80LQTdHQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">两个连续画面的锐利边缘(作者提供照片)</p></figure><p id="9ade" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">2.减去图像以捕捉视频中的运动物体(中值滤波用于降低噪声):</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/0ea90b0e8575537fcfb49f4cab29cf9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*_5xJBN4TG1zqlsd_jBybFg.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我不是在黑暗中举重，这是时间导数(视频由作者提供)</p></figure><p id="64af" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">重要的是要注意，边缘检测在许多方面是图像空间梯度的近似，减去两帧是图像时间梯度的近似。我们将在第2部分详细阐述这些概念。</p><p id="dd0a" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">这些帧差算法比我们以前尝试的解决方案好得多，但它们仍然不够好，主要是由于灵敏度问题。我们的算法要么检测到太多的运动，要么检测到太少的运动，如果不包括灯的闪烁或其他背景噪声，很难提供对受训者的一致检测。</p><p id="9a6a" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">就在我们准备放弃的时候，我们偶然发现了一种算法，它正好给出了我们需要的东西——一种以实时速度检测运动并提供稳健结果的算法。</p></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><h1 id="e635" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">光流</h1><p id="e6bd" class="pw-post-body-paragraph ky kz iq la b lb mo jr ld le mp ju lg lh mq lj lk ll mr ln lo lp ms lr ls lt ij bi translated">经过冗长的文献回顾和其他方法的大量反复试验，我们发现在帧中分割受训者的最佳解决方案是使用光流。简而言之，这是一种估计视频中运动的方法，这对我们来说很好，因为我们视频中唯一的运动来自于受训者。</p><p id="1375" class="pw-post-body-paragraph ky kz iq la b lb lc jr ld le lf ju lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">阅读第2部分，了解我们解决方案的更多细节。</p></div></div>    
</body>
</html>