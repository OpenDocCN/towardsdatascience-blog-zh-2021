<html>
<head>
<title>A better way to visualize Decision Trees with the dtreeviz library</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用dtreeviz库可视化决策树的更好方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-better-way-to-visualize-decision-trees-with-the-dtreeviz-library-758994cdf05e?source=collection_archive---------6-----------------------#2021-05-18">https://towardsdatascience.com/a-better-way-to-visualize-decision-trees-with-the-dtreeviz-library-758994cdf05e?source=collection_archive---------6-----------------------#2021-05-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="ad38" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="70d9" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">一个用于决策树可视化和模型解释的开源包</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/87741032fc8395549b155cd799383b12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U70J5X9e3PRbjYssNd5K7A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="02e6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">一幅画胜过千言万语，这是正确的说法。这个公理同样适用于机器学习模型。如果一个人能够可视化和解释结果，它会给模型的预测注入更多的信心。可视化机器学习模型如何工作也使得向具有较少或没有机器学习技能的人解释结果成为可能。Scikit-learn库天生具有绘制决策树的能力。但是，与默认选项有一些不一致。本文将着眼于一种叫做<a class="ae md" href="https://github.com/parrt/dtreeviz" rel="noopener ugc nofollow" target="_blank"> dtreeviz </a>的替代方案，它可以呈现更好看、更直观的可视化效果，同时提供更好的可解释性选项。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="4775" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">用于可视化基于树的模型的dtreeviz库</h1><p id="f3c7" class="pw-post-body-paragraph lh li it lj b lk nd kd lm ln ne kg lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated"><strong class="lj jd"> dtreeviz </strong>是一个用于决策树可视化和模型解释的python库。根据其<a class="ae md" href="https://github.com/parrt/dtreeviz" rel="noopener ugc nofollow" target="_blank"> Github repo </a>上的可用信息，该库目前支持<a class="ae md" href="https://scikit-learn.org/stable" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>、<a class="ae md" href="https://xgboost.readthedocs.io/en/latest" rel="noopener ugc nofollow" target="_blank"> XGBoost </a>、<a class="ae md" href="https://spark.apache.org/mllib/" rel="noopener ugc nofollow" target="_blank"> Spark MLlib </a>和<a class="ae md" href="https://lightgbm.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> LightGBM </a>树。</p><p id="56d8" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">下面是在著名的<a class="ae md" href="https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009" rel="noopener ugc nofollow" target="_blank">葡萄酒质量数据集</a>上，从默认scikit-learn和从dtreeviz生成的可视化的视觉比较。该数据集包括178个实例和13个数字预测属性。每个数据点可以属于名为class_0、class_1和class_2的三个类之一。</p><div class="ks kt ku kv gt ab cb"><figure class="ni kw nj nk nl nm nn paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/55ceadbfba4df37f31baa24ac86e4043.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*uLzUvEtAXR2ZFbUTK88_hA.png"/></div></figure><figure class="ni kw no nk nl nm nn paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><img src="../Images/5588fb704637f0cf98ba264f11e9aefc.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*70FQswUgOv2B5QXGcld1vQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk np di nq nr translated">在著名的<a class="ae md" href="https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009" rel="noopener ugc nofollow" target="_blank">葡萄酒质量数据集</a> |作者提供的图片上，对默认scikit-learn(左)和dtreeviz(右)生成的可视化效果进行视觉比较</p></figure></div><p id="c52e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">从上面的图片可以明显看出，右边的图比左边的图提供了更多的信息。默认的scikit学习可视化存在一些明显的问题，例如:</p><ul class=""><li id="9c6f" class="ns nt it lj b lk ll ln lo lq nu lu nv ly nw mc nx ny nz oa bi translated">目前还不清楚不同的颜色代表什么。</li><li id="84d6" class="ns nt it lj b lk ob ln oc lq od lu oe ly of mc nx ny nz oa bi translated">目标类没有图例。</li><li id="67b1" class="ns nt it lj b lk ob ln oc lq od lu oe ly of mc nx ny nz oa bi translated">可视化返回样本的计数，并且不容易可视化分布。</li><li id="b6d9" class="ns nt it lj b lk ob ln oc lq od lu oe ly of mc nx ny nz oa bi translated">无论样本数量多少，每个决策节点的大小都是相同的。</li></ul><p id="5934" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">dtreeviz库填补了这些漏洞，提供了一个更清晰、更容易理解的画面。以下是作者要说的话:</p><blockquote class="og oh oi"><p id="ecfe" class="lh li oj lj b lk ll kd lm ln lo kg lp ok lr ls lt ol lv lw lx om lz ma mb mc im bi translated">可视化效果的灵感来自<a class="ae md" href="http://www.r2d3.us/" rel="noopener ugc nofollow" target="_blank"> R2D3 </a>的教育动画；<a class="ae md" href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/" rel="noopener ugc nofollow" target="_blank">机器学习的可视化介绍</a>。使用<code class="fe on oo op oq b">dtreeviz</code>，您可以可视化特征空间如何在决策节点上分割，训练样本如何在叶节点上分布，树如何对特定观察进行预测等等。这些操作对于理解分类或回归决策树的工作方式至关重要。</p></blockquote><p id="a28a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在接下来的几节中，我们将通过一些常见的例子来看看dtreeviz如何优于其他可视化库。关于<strong class="lj jd">安装说明，</strong>请参考官方<a class="ae md" href="https://github.com/parrt/dtreeviz#install" rel="noopener ugc nofollow" target="_blank"> Github页面</a>。可以安装<code class="fe on oo op oq b">pip install dtreeviz but</code>需要预装<code class="fe on oo op oq b">graphviz</code>。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="f8cc" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">dtreeviz的卓越可视化</h1><p id="35cd" class="pw-post-body-paragraph lh li it lj b lk nd kd lm ln ne kg lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">在可视化决策树之前，理解它是如何工作的也是很重要的。决策树是一种监督学习预测模型，它使用一组二元规则来计算目标值。它可用于回归和分类任务。决策树有三个主要部分:</p><ul class=""><li id="9411" class="ns nt it lj b lk ll ln lo lq nu lu nv ly nw mc nx ny nz oa bi translated"><strong class="lj jd">根节点:</strong>执行第一次拆分的节点。</li><li id="5d51" class="ns nt it lj b lk ob ln oc lq od lu oe ly of mc nx ny nz oa bi translated"><strong class="lj jd">终端节点/叶节点:</strong>预测结果的节点。</li><li id="6ea3" class="ns nt it lj b lk ob ln oc lq od lu oe ly of mc nx ny nz oa bi translated"><strong class="lj jd">分支:</strong>箭头连接节点，显示从问题到答案的流程。</li></ul><p id="cc0a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">决策树模型的算法通过重复地将数据划分到多个子空间中来工作，使得每个最终子空间中的结果尽可能地相似。这种方法在技术上被称为<em class="oj">递归分区</em>。该算法试图将数据分成子集，以使每个子组尽可能纯净或同质。</p><p id="ed92" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">以上摘录摘自我写的一篇关于理解决策树的文章。本文深入解释了算法通常如何做出决策。</p><div class="or os gp gr ot ou"><a href="https://medium.com/analytics-vidhya/a-guide-to-machine-learning-in-r-for-beginners-decision-trees-c24dfd490abb" rel="noopener follow" target="_blank"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd jd gy z fp oz fr fs pa fu fw jc bi translated">理解决策树</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">我在“分析优势”课程中关于决策树的笔记</h3></div></div><div class="pc l"><div class="pd l pe pf pg pc ph lb ou"/></div></div></a></div><p id="516d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在让我们回到dtreeviz库，使用上面提到的葡萄酒数据绘制其中的几个。</p><h2 id="6939" class="pi mm it bd mn pj pk dn mr pl pm dp mv lq pn po mx lu pp pq mz ly pr ps nb iz bi translated">资料组</h2><p id="d9f1" class="pw-post-body-paragraph lh li it lj b lk nd kd lm ln ne kg lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">我们将使用来自<a class="ae md" href="https://archive.ics.uci.edu/ml/datasets/wine+quality" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jd">葡萄酒质量数据集</strong> </a> <strong class="lj jd">的著名红酒数据集。</strong>数据集由与葡萄牙“Vinho Verde”葡萄酒红色变种相关的几项理化测试组成。目标是在这些测试的基础上建立葡萄酒质量模型。由于该数据集可以被视为分类和回归任务，因此它适合我们的用例。我们将不必使用单独的数据集来演示分类和回归示例。</p><blockquote class="og oh oi"><p id="b426" class="lh li oj lj b lk ll kd lm ln lo kg lp ok lr ls lt ol lv lw lx om lz ma mb mc im bi translated"><strong class="lj jd">这里是</strong> <a class="ae md" href="https://nbviewer.jupyter.org/github/parulnith/Data-Science-Articles/blob/main/A%20better%20way%20to%20visualize%20Decision%20Trees%20with%20the%20dtreeviz%20library/A%20better%20way%20to%20visualize%20Decision%20Trees%20with%20the%20dtreeviz%20library.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jd"> nbviewer链接</strong> </a> <strong class="lj jd">到笔记本incase你想跟着走。</strong></p></blockquote><p id="f0d8" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们看看数据集的前几行:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pt"><img src="../Images/bd7ff8a4809056251120188496e1e1d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9_4BRH_RMVmkrYcTZHyh4A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">数据集一瞥|作者图片</p></figure><p id="0fd3" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><code class="fe on oo op oq b">quality</code>参数是指葡萄酒的质量，是一个介于0和10之间的分数</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pu"><img src="../Images/95e399f3fd6ec208e891b4b266d38103.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7lVBiek6NE6DopRxJ8Z9Ow.png"/></div></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="5781" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">形象化</h1><p id="70ec" class="pw-post-body-paragraph lh li it lj b lk nd kd lm ln ne kg lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">轻松创建特性和目标变量。</p><pre class="ks kt ku kv gt pv oq pw px aw py bi"><span id="ea19" class="pi mm it oq b gy pz qa l qb qc">features = wine.drop('quality',axis=1)<br/>target = wine['quality']</span></pre><h2 id="4532" class="pi mm it bd mn pj pk dn mr pl pm dp mv lq pn po mx lu pp pq mz ly pr ps nb iz bi translated"><strong class="ak">回归决策树</strong></h2><p id="bf4f" class="pw-post-body-paragraph lh li it lj b lk nd kd lm ln ne kg lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">对于回归示例，我们将预测葡萄酒的<code class="fe on oo op oq b">quality</code>。</p><pre class="ks kt ku kv gt pv oq pw px aw py bi"><span id="91cc" class="pi mm it oq b gy pz qa l qb qc"># Regression tree on Wine data</span><span id="3fba" class="pi mm it oq b gy qd qa l qb qc">fig = plt.figure(figsize=(25,20))<br/>regr= tree.DecisionTreeRegressor(max_depth=3)  </span><span id="acde" class="pi mm it oq b gy qd qa l qb qc">regr.fit(features, target)</span><span id="bc0e" class="pi mm it oq b gy qd qa l qb qc">viz = dtreeviz(regr,<br/>               features,<br/>               target,<br/>               target_name='wine quality',<br/>               feature_names=features.columns,<br/>               title="Wine data set regression",<br/>               fontname="Arial",<br/>               colors = {"title":"purple"},<br/>               scale=1.5)<br/>viz</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qe"><img src="../Images/4b920b06e1e97582fccbd68b4c6a78db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qzLs2IBAYSEJwycZ0rc7mg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">回归决策树|作者图片</p></figure><ul class=""><li id="d53a" class="ns nt it lj b lk ll ln lo lq nu lu nv ly nw mc nx ny nz oa bi translated">水平虚线表示决策节点中左右桶的目标平均值；</li><li id="35c9" class="ns nt it lj b lk ob ln oc lq od lu oe ly of mc nx ny nz oa bi translated">垂直虚线表示特征空间中的分割点。</li><li id="5cfb" class="ns nt it lj b lk ob ln oc lq od lu oe ly of mc nx ny nz oa bi translated">黑色楔形突出显示分割点，并确定精确的分割值。</li><li id="0cd2" class="ns nt it lj b lk ob ln oc lq od lu oe ly of mc nx ny nz oa bi translated">叶节点用虚线表示目标预测值(平均值)。</li></ul><p id="9458" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">分类决策树</strong></p><p id="033f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">对于分类示例，我们将从给定的六个类别中预测葡萄酒的<code class="fe on oo op oq b">class</code>。这里的目标也是质量变量。</p><pre class="ks kt ku kv gt pv oq pw px aw py bi"><span id="a9a6" class="pi mm it oq b gy pz qa l qb qc"># Classification tree on Wine data</span><span id="8b40" class="pi mm it oq b gy qd qa l qb qc">fig = plt.figure(figsize=(25,20))<br/>clf = tree.DecisionTreeClassifier(max_depth=3)</span><span id="035d" class="pi mm it oq b gy qd qa l qb qc">clf.fit(features, target)</span><span id="6c9d" class="pi mm it oq b gy qd qa l qb qc"># pick random X observation for demo<br/>#X = wine.data[np.random.randint(0, len(wine.data)),:]</span><span id="fc20" class="pi mm it oq b gy qd qa l qb qc">viz = dtreeviz(clf,<br/>               features,<br/>               target,<br/>               target_name='wine quality',<br/>               feature_names=features.columns,<br/>               title="Wine data set classification",<br/>               class_names=['5', '6', '7', '4', '8', '3'],<br/>               histtype='barstacked', # default <br/>               scale=1.2)<br/>viz</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qf"><img src="../Images/07a4f2139ef6c6725f102e151606df5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uTuE2EtGgpG2VFMQZNKzkw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">葡萄酒数据分类树|按作者分类的图片</p></figure><p id="bb7e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">与回归变量不同，目标是分类器的类别。因此，直方图用于说明特征-目标空间。当类别数量增加时，堆叠直方图可能难以读取。在这种情况下，<code class="fe on oo op oq b">histogram type</code>参数可以从默认的<code class="fe on oo op oq b">barstacked,</code>更改为<code class="fe on oo op oq b">bar</code>。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="011a" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">自定义</h1><p id="cb33" class="pw-post-body-paragraph lh li it lj b lk nd kd lm ln ne kg lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">dtreeviz库还提供了一系列定制。我将在这里展示其中的一些:</p><h2 id="30cf" class="pi mm it bd mn pj pk dn mr pl pm dp mv lq pn po mx lu pp pq mz ly pr ps nb iz bi translated">缩放图像</h2><p id="5639" class="pw-post-body-paragraph lh li it lj b lk nd kd lm ln ne kg lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">缩放参数可用于缩放整个图像。</p><h2 id="67a8" class="pi mm it bd mn pj pk dn mr pl pm dp mv lq pn po mx lu pp pq mz ly pr ps nb iz bi translated">从左到右对齐的树</h2><p id="dace" class="pw-post-body-paragraph lh li it lj b lk nd kd lm ln ne kg lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">可以将<code class="fe on oo op oq b">orientation</code>参数设置为<code class="fe on oo op oq b">LR</code>来从左到右显示树，而不是从上到下</p><pre class="ks kt ku kv gt pv oq pw px aw py bi"><span id="4ea3" class="pi mm it oq b gy pz qa l qb qc">fig = plt.figure(figsize=(25,20))<br/>clf = tree.DecisionTreeClassifier(max_depth=2)</span><span id="e55b" class="pi mm it oq b gy qd qa l qb qc">clf.fit(features, target)</span><span id="8c4b" class="pi mm it oq b gy qd qa l qb qc"># pick random X observation for demo</span><span id="fadb" class="pi mm it oq b gy qd qa l qb qc">viz = dtreeviz(clf,<br/>               features,<br/>               target,<br/>               target_name='wine quality',<br/>               feature_names=features.columns,<br/>               title="Wine data set classification",<br/>               class_names=['5', '6', '7', '4', '8', '3'],<br/>               <strong class="oq jd">orientation='LR',</strong> <br/>               scale=1.2)<br/>viz</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qg"><img src="../Images/02e409bb549e00fdebef08935d3e19fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NRK-fvUXv0C-F_ZJMqyGUw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">从左到右对齐的树|作者图片</p></figure><h2 id="42fa" class="pi mm it bd mn pj pk dn mr pl pm dp mv lq pn po mx lu pp pq mz ly pr ps nb iz bi translated">单次观测的预测路径</h2><p id="c1ee" class="pw-post-body-paragraph lh li it lj b lk nd kd lm ln ne kg lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">该库还有助于隔离和理解特定测试观察遵循的决策路径。这对于向他人解释预测或结果非常有用。例如，让我们从数据集中挑选一个随机样本，并遍历它的决策路径。</p><pre class="ks kt ku kv gt pv oq pw px aw py bi"><span id="6c3b" class="pi mm it oq b gy pz qa l qb qc">fig = plt.figure(figsize=(25,20))<br/>clf = tree.DecisionTreeClassifier(max_depth=3)</span><span id="e28c" class="pi mm it oq b gy qd qa l qb qc">clf.fit(features, target)</span><span id="bb57" class="pi mm it oq b gy qd qa l qb qc"><strong class="oq jd"># pick random X observation for demo<br/>X = features.iloc[np.random.randint(0, len(features)),:].values</strong></span><span id="7c45" class="pi mm it oq b gy qd qa l qb qc">viz = dtreeviz(clf,<br/>               features,<br/>               target,<br/>               target_name='wine quality',<br/>               feature_names=features.columns,<br/>               title="Wine data set classification",<br/>               class_names=['5', '6', '7', '4', '8', '3'],<br/>               scale=1.3,<br/>               X=X)<br/>viz</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi qh"><img src="../Images/f2dbc19998a4aa8d831a17857db5baba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6opIcPQ1sQOUFClZ6C_FzQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">单次观察的预测路径|作者提供的图像</p></figure><h2 id="0bf3" class="pi mm it bd mn pj pk dn mr pl pm dp mv lq pn po mx lu pp pq mz ly pr ps nb iz bi translated">保存图像</h2><p id="9ad1" class="pw-post-body-paragraph lh li it lj b lk nd kd lm ln ne kg lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">输出图形可以保存为SVG格式，如下所示:</p><pre class="ks kt ku kv gt pv oq pw px aw py bi"><span id="5956" class="pi mm it oq b gy pz qa l qb qc">viz.save_svg()</span></pre></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="be73" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">结论</h1><p id="ae76" class="pw-post-body-paragraph lh li it lj b lk nd kd lm ln ne kg lp lq nf ls lt lu ng lw lx ly nh ma mb mc im bi translated">在绘制决策树时，dtreeviz库比其他库得分更高。使结果可解释的额外能力是一个极好的附加功能；您可以隔离单个数据点，并在微观层面上理解预测。这有助于更好地理解模型的预测，也便于将发现传达给其他人。我在这里所触及的只是冰山一角。Github库和作者的附带文章更详细，我强烈推荐浏览它们。链接在下面的参考资料部分。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="1baf" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">参考资料和进一步阅读:</h1><ul class=""><li id="3410" class="ns nt it lj b lk nd ln ne lq qi lu qj ly qk mc nx ny nz oa bi translated"><a class="ae md" href="https://github.com/parrt/dtreeviz/" rel="noopener ugc nofollow" target="_blank">dtre eviz的官方Github库。</a></li><li id="2a34" class="ns nt it lj b lk ob ln oc lq od lu oe ly of mc nx ny nz oa bi translated"><a class="ae md" href="https://explained.ai/decision-tree-viz/index.html#sec:1.4" rel="noopener ugc nofollow" target="_blank">如何可视化决策树</a>——dtre eviz的创建者们对决策树可视化的一个很好的阅读。</li><li id="7d9d" class="ns nt it lj b lk ob ln oc lq od lu oe ly of mc nx ny nz oa bi translated"><a class="ae md" href="https://medium.com/analytics-vidhya/a-guide-to-machine-learning-in-r-for-beginners-decision-trees-c24dfd490abb" rel="noopener">了解决策树</a></li></ul></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="91f9" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="oj">👉有兴趣看我写的其他文章。这个</em> <a class="ae md" href="https://github.com/parulnith/Data-Science-Articles/blob/main/README.md" rel="noopener ugc nofollow" target="_blank"> <em class="oj">回购</em> </a> <em class="oj">包含了我分类写的所有文章。</em></p></div></div>    
</body>
</html>