<html>
<head>
<title>Creating Convolutional Neural Network From Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始创建卷积神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/creating-convolutional-neural-network-from-scratch-d3a8389dfb80?source=collection_archive---------16-----------------------#2021-11-10">https://towardsdatascience.com/creating-convolutional-neural-network-from-scratch-d3a8389dfb80?source=collection_archive---------16-----------------------#2021-11-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0fdc" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在 Graviti 数据平台上使用 CNN 建立图像分类模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1b2daebbd151da100e01ad1fb86dc3f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5-Zb9_R0yzNUZOSO"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">艾莉娜·格鲁布尼亚克在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="565f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图像分类基本上帮助我们将图像分类到不同的标签中。这就像将不同的图像放入它们所属的桶中。例如，被训练来识别猫和狗的图像的模型将有助于分别分离不同的猫和狗的图像。有多种深度学习框架，如 Tensorflow、Keras、Theano 等，可用于创建图像分类模型。今天我们将使用 Keras 和 Tensorflow 从头开始创建一个图像分类模型。</p><p id="92b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用于创建图像的相关建模可以使用 CNN 来完成。卷积神经网络主要用于图像相关的建模。它是执行图像分类、图像检测、图像分割等的最简单的方法之一。它包含不同类型的卷积层，有助于使用不同大小的内核过滤掉图像中最重要的特征。一些最重要的层是:</p><ol class=""><li id="c272" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu"> Conv2D </strong></li></ol><p id="f203" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它用于创建卷积核，卷积核与输入层卷积以产生输出张量。</p><p id="31a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2。MaxPooling2D </strong></p><p id="8406" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一种缩减采样技术，根据池大小取最大值。</p><p id="90c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.<strong class="lb iu">展平</strong></p><p id="4656" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它使输入变平并创建一维输出。</p><p id="ffc9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有多个超参数可以用来相应地提高模型性能。这些超参数可以包括神经元的数量、内核大小、池大小、激活函数等。</p><p id="f420" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将从头开始使用 CNN 创建一个网络。我将向您展示如何从在线数据源加载数据，预处理数据并为建模做好准备，最后设计模型架构。</p><p id="ca68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们开始吧…</p><h1 id="eaf0" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">安装所需的库</h1><p id="69bd" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">我们将从安装所有需要的库开始。我们将安装 Keras、TensorFlow，还将安装用于加载数据集的<a class="ae ky" href="https://docs.graviti.com/guide/tensorbay?utm_source=medium&amp;utm_medium=referral&amp;utm_campaign=20211108-himanshu-doc" rel="noopener ugc nofollow" target="_blank"> TensorBay </a>(在<a class="ae ky" href="https://www.graviti.com/?utm_source=medium&amp;utm_medium=referral&amp;utm_campaign=20211109-himanshu-blog" rel="noopener ugc nofollow" target="_blank"> Graviti </a>数据平台上的 SDK)。下面给出的命令可以做到这一点。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="a5b9" class="ng mf it nc b gy nh ni l nj nk">!pip install tensorflow<br/>!pip install tensorbay<br/>!pip install keras</span></pre><h1 id="f60c" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">导入所需的库</h1><p id="abc5" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">在这一步中，我们将导入所有必需的库和函数来加载数据、预处理数据并创建模型。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="b8e1" class="ng mf it nc b gy nh ni l nj nk"># Library imports<br/>from tensorbay import GAS<br/>from PIL import Image<br/>import matplotlib.pyplot as plt<br/>from tensorbay.dataset import Data, Dataset<br/>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>from matplotlib.image import imread<br/>import cv2<br/>import random<br/>from os import listdir<br/>from sklearn.preprocessing import LabelBinarizer<br/>from keras.preprocessing import image<br/>from keras.preprocessing.image import img_to_array, array_to_img<br/>from tensorflow.keras.optimizers import Adam<br/>from keras.models import Sequential<br/>from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense<br/>from sklearn.model_selection import train_test_split</span></pre><h1 id="c446" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">加载数据集</h1><p id="0847" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">这是第一步，我们将从 TensorBay 加载数据。为了从 TensorBay 下载数据集，我们需要创建一个帐户，并派生出一个我们想要处理的数据集，它包含大量不同的图像数据集。为了在我们的 Jupyter 笔记本中加载数据集，我们需要有 TensorBay 的访问密钥，我们可以从我们的帐户中的开发者工具下载该密钥。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="8af9" class="ng mf it nc b gy nh ni l nj nk">gas = GAS("&lt;Your Key&gt;")<br/>dataset = Dataset("Flower17–1", gas)<br/>segment = dataset[1]</span></pre><p id="00d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于这篇文章，我使用的是<a class="ae ky" href="https://gas.graviti.com/dataset/hellodataset/Flower17?utm_source=medium&amp;utm_medium=referral&amp;utm_campaign=20211108-himanshu-datasets" rel="noopener ugc nofollow" target="_blank"> Flower 17 数据集</a>，你可以看到我已经用 TensorBay 加载了它。</p><h1 id="ae7c" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated"><strong class="ak">预处理数据集</strong></h1><p id="708e" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">在这一步，我们将预处理数据，并为建模做好准备。我们将从创建图像和标签列表并向其中加载数据开始。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="48a6" class="ng mf it nc b gy nh ni l nj nk">image_list, label_list = [], []<br/>for data in segment:<br/>with data.open() as fp:<br/>image_list.append(img_to_array(Image.open(fp).resize((500, 500))))<br/>label_list.append(data.label.classification.category)</span></pre><p id="c3d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们直观地看到这个数据集中的类的数量。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="899a" class="ng mf it nc b gy nh ni l nj nk"># Visualize the number of classes count<br/>label_counts = pd.DataFrame(label_list).value_counts()<br/>label_counts</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/e3c13c7de63b6c94a5c63e043a1f37a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:318/0*254EveIV0PXCa4Wv"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据标签(来源:作者)</p></figure><p id="dc4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将分割数据集，对其进行规范化，并对标签进行二值化。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="7996" class="ng mf it nc b gy nh ni l nj nk"># Splitting dataset<br/>x_train, x_test, y_train, y_test = train_test_split(image_list, label_list, test_size=0.2, random_state = 10)<br/># Normalize and reshape data<br/>x_train = np.array(x_train, dtype=np.float16) / 225.0<br/>x_train = x_train.reshape( -1,500,500,3)<br/>x_test = np.array(x_test, dtype=np.float16) / 225.0<br/>x_test = x_test.reshape( -1,500,500,3)<br/># Label binarizing<br/>lb = LabelBinarizer()<br/>y_train = lb.fit_transform(y_train)<br/>y_test = lb.fit_transform(y_test)<br/>print(lb.classes_)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/23f443a2bf2ee07612c0730799b8d34b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/0*lqkdv63XN0AJ3Fpy"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">标签二进制化(来源:作者)</p></figure><h1 id="b015" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated"><strong class="ak">创建模型</strong></h1><p id="3877" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">这是最后一步，我们将创建模型架构，编译模型并训练它。在创建模型架构之前，让我们将训练数据分为训练和验证。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="8f11" class="ng mf it nc b gy nh ni l nj nk"># Splitting the training data set into training and validation data sets<br/>x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2)<br/># Building model architecture<br/>model = Sequential()<br/>model.add(Conv2D(8, (3, 3), padding="same",input_shape=(500,500,3), activation="relu"))<br/>model.add(MaxPooling2D(pool_size=(3, 3)))<br/>model.add(Conv2D(16, (3, 3), padding="same", activation="relu"))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Conv2D(32, (3, 3), padding="same", activation="relu"))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))<br/>model.add(Flatten())<br/>model.add(Dense(32, activation="relu"))<br/>model.add(Dense(num_classes, activation="softmax"))<br/>model.summary()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/b84c1ae5cff7ccab54df26deff8775aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/0*gaAe-D4T2f9ww7Vk"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型架构(来源:作者)</p></figure><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="7abd" class="ng mf it nc b gy nh ni l nj nk"># Compiling model<br/>model.compile(loss = 'categorical_crossentropy', optimizer = Adam(0.0005),metrics=['accuracy'])<br/># Training the model<br/>epochs = 20<br/>batch_size = 128<br/>history = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, validation_data = (x_val, y_val))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/16aadf5ed971af9693738f2d9ff068a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yEpgn-Ymyb2PEN0N"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">培训(来源:作者)</p></figure><p id="ba28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如您在上面看到的，我们已经使用一些超参数创建并训练了模型，模型精度不是很好，但您可以随时调整超参数以提高性能。我们也可以使用下面给出的命令保存模型。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="4bfc" class="ng mf it nc b gy nh ni l nj nk"># Saving model<br/>model.save("/content/flower_species.h5")<br/>Let's visualize the model training and loss history.<br/>#Plot the training history<br/>plt.figure(figsize=(12, 5))<br/>plt.plot(history.history['accuracy'], color='r')<br/>plt.plot(history.history['val_accuracy'], color='b')<br/>plt.title('Model Accuracy')<br/>plt.ylabel('Accuracy')<br/>plt.xlabel('Epochs')<br/>plt.legend(['train', 'val'])<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/526e5b392df9e4d54ba452aa8e4167e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HWS3fhlp7-FNQmX_"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">准确性(来源:作者)</p></figure><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="7850" class="ng mf it nc b gy nh ni l nj nk">#Plot the loss history<br/>plt.figure(figsize=(12, 5))<br/>plt.plot(history.history['loss'], color='r')<br/>plt.plot(history.history['val_loss'], color='b')<br/>plt.title('Model Loss')<br/>plt.ylabel('Loss')<br/>plt.xlabel('Epochs')<br/>plt.legend(['train', 'val'])<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/a14841d969f3bd39aeee639b72f177c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DF4d4O5BYaFpbW3Z"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">损失(来源:作者)</p></figure><p id="e0dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，让我们也使用该模型创建一些预测。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="73db" class="ng mf it nc b gy nh ni l nj nk"># Storing predictions<br/>y_pred = model.predict(x_test)<br/>Let's verify one of the predictions.<br/># Plotting image to compare<br/>img = array_to_img(x_test[4])<br/>img</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/702b4c45e2ddab9f5448dcfe2c56417f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/0*ByCnxuc0TcUm93q9"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">花卉图像(来源:作者)</p></figure><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="2638" class="ng mf it nc b gy nh ni l nj nk"># Finding max value from prediction list and comparing original value vs predicted<br/>labels = lb.classes_<br/>print(labels)<br/>print("Originally : ",labels[np.argmax(y_test[4])])<br/>print("Predicted : ",labels[np.argmax(y_pred[4])])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/366f7af506e8011a9f21e447dde86c91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/0*6aNR7BRD8YyhHE8p"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">预测(来源:作者)</p></figure><p id="a392" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">继续，使用不同的数据集尝试这种方法，并按照本文轻松创建 CNN 模型。如果您发现任何困难，请在回复部分告诉我。</p><h1 id="c1de" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">在你走之前</h1><p id="b072" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated"><strong class="lb iu"> <em class="nt">感谢</em> </strong> <em class="nt">的阅读！如果你想与我取得联系，请随时通过 hmix13@gmail.com 联系我或我的</em><a class="ae ky" href="http://www.linkedin.com/in/himanshusharmads" rel="noopener ugc nofollow" target="_blank"><em class="nt"/><strong class="lb iu"><em class="nt">LinkedIn 个人资料</em> </strong> </a> <em class="nt">。可以查看我的</em><a class="ae ky" href="https://github.com/hmix13" rel="noopener ugc nofollow" target="_blank"><em class="nt"/><strong class="lb iu"><em class="nt">Github</em></strong></a><em class="nt">简介针对不同的数据科学项目和包教程。还有，随意探索</em> <a class="ae ky" href="https://medium.com/@hmix13" rel="noopener"> <em class="nt"> </em> <strong class="lb iu"> <em class="nt">我的简介</em> </strong> </a> <em class="nt">阅读我写过的与数据科学相关的不同文章。</em></p></div></div>    
</body>
</html>