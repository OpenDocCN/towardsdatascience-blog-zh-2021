<html>
<head>
<title>Distributed Biomedical Text Mining using PySpark for Classification of Cancer Gene Mutations At-scale — Part II: Multinomial Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于PySpark的分布式生物医学文本挖掘在癌症基因突变分类中的应用——第二部分:多项式逻辑回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/distributed-biomedical-text-mining-using-pyspark-for-classification-of-cancer-gene-mutations-bd3b2ca05a9c?source=collection_archive---------28-----------------------#2021-05-08">https://towardsdatascience.com/distributed-biomedical-text-mining-using-pyspark-for-classification-of-cancer-gene-mutations-bd3b2ca05a9c?source=collection_archive---------28-----------------------#2021-05-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5929" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">分布式机器学习使用Apache Spark对癌症肿瘤基因突变进行大规模分类</em></h2></div><p id="37db" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在<a class="ae lc" href="https://bharatss.medium.com/distributed-biomedical-text-mining-using-pyspark-for-classification-of-cancer-gene-mutations-3e11507b2450" rel="noopener"> <strong class="ki ir">第一部分</strong> </a>中，我讨论了探索性数据分析和将逐点互信息应用于突变对，以找出PMI分数和突变类相似性之间是否存在任何相关性。在这一部分中，我将讨论训练一个分布式多项逻辑回归(MLR)模型，并将其应用于测试数据集以确定突变的类别。</p><p id="216c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">同样，为了简洁起见，我在本文中只分享代码的某些部分。完整代码请查看GitHub链接<a class="ae lc" href="https://github.com/bsets/Distributed_ML_with_PySpark_for_Cancer_Tumor_Classification/tree/main/Tumor_Gene_Classification_using_Multinomial_Logistic_Regression" rel="noopener ugc nofollow" target="_blank"> <strong class="ki ir">这里</strong> </a> <strong class="ki ir"> </strong>。我还准备了一个5分钟的视频，你可以在这里找到<a class="ae lc" href="https://www.youtube.com/watch?v=LRp75Ku8Hc4" rel="noopener ugc nofollow" target="_blank"><strong class="ki ir"/></a>。</p><p id="2d73" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在继续在MLlib中训练模型之前，需要几个预处理步骤:</p><p id="4d8d" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">数据预处理</strong></p><ol class=""><li id="cb82" class="ld le iq ki b kj kk km kn kp lf kt lg kx lh lb li lj lk ll bi translated"><strong class="ki ir">处理缺失值</strong>:正如我们在第一部分中看到的，训练数据集中有5个条目没有相关的研究论文文本。这些在文本列中有NaN值。我把这些NaN值换成了基因+突变值的组合。</li><li id="8887" class="ld le iq ki b kj lm km ln kp lo kt lp kx lq lb li lj lk ll bi translated"><strong class="ki ir">执行基本的NLP操作</strong>:我在研究论文文本(每行的文本列)上执行了一些基本的NLP操作，以标准化跨行的值，并在不丢失有价值信息的情况下减小数据集的大小。这些行动是:</li></ol><p id="cfae" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">A.用一个空格替换文本中的特殊字符，如*、@等</p><p id="ffd4" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">B.用单个空格替换多个空格</p><p id="e36b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">C.将所有字符转换为小写</p><p id="64c3" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">D.仅存储文本中非停用词的那些词。像and、the、the等这样的词称为停用词。它们对于使句子语法正确至关重要，但在大多数情况下并不包含有用的信息。例如，考虑句子“药物阿司匹林已经被用作止痛药很长时间了”。这两个词中哪个是关键词:“阿司匹林”还是“as”？停用词数量众多，虽然移除停用词会造成一些意义的损失，但这种损失通常是最小的，并且所获得的数据压缩是巨大的，因为停用词是任何文档中最频繁出现的词。</p><p id="9e18" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">下面的代码片段执行这四个操作:</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="lw lx l"/></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">对数据集执行基本的NLP预处理操作(图片由作者提供)</p></figure><p id="2f02" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">如下所示，这些预处理步骤的分布式实现花了8秒钟，而我在单台机器上完成时只花了30秒钟。</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="lw lx l"/></div></figure><p id="c3ad" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">3.<strong class="ki ir">矢量化基因、突变(变异)和文本特征:</strong>我为基因、突变和训练数据集中的所有文本创建了一个热编码。在训练数据集中的所有文章中有65946个唯一单词。</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="lw lx l"/></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">在训练数据集论文中矢量化基因、突变和单词(图片由作者提供)</p></figure><p id="d45b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">4.<strong class="ki ir">组合所有编码以创建合并的训练数据集:</strong></p><p id="fca0" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">对于每一行，我组合了基因、突变和文本one-hot-encoding来创建一个表示这些信息的合并向量。</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="lw lx l"/></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">创建合并的编码训练数据集(图片由作者提供)</p></figure><p id="7db8" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">每行有69229个二进制条目，如下图所示:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mc"><img src="../Images/7517533f14fa2edaa4f4a4f24f230abc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g9zeEWqwGXyqBRbT6v_AAg.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">训练数据集的矢量化表示(图片由作者提供)</p></figure><p id="9e82" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">5.<strong class="ki ir">将数据帧转换为Spark MLlib友好格式:</strong></p><p id="7111" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">为了训练分布式ML模型，我在上图中显示的训练数据集panda dataframe需要转换为特定的格式，这是通过我在GitHub文件夹中共享的csvlibsvm1.py程序文件来完成的。</p><p id="fd65" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">训练MLR模型</strong></p><p id="e0d2" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这是我用来训练MLR模型的代码片段。我设置了超参数值(正则化常数=0.01，弹性参数=1)，在手动调整这些值并观察结果后，产生了良好的结果。更系统的方法是GridsearchCV，一旦我做到了并得到更好的结果，我会更新这篇文章。</p><figure class="lr ls lt lu gt lv"><div class="bz fp l di"><div class="lw lx l"/></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">Spark MLLib中多项式逻辑回归模型的分布式训练(图片由作者提供)</p></figure><p id="0618" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">结果</strong></p><p id="6348" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我得到了64%的总体分类准确率和1.12的多项式对数损失，这与Kaggle竞赛中最佳表演者报告的值相当。他们得到了2.03的多项式对数损失，尽管<br/>他们的测试数据集与我的不同，因为我在分割训练数据集后准备了我的测试数据集。尽管如此，总体而言，MLR似乎对该数据集工作得很好<br/>。</p><p id="cc1d" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这是回忆矩阵:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mj"><img src="../Images/082fb0b3bacbdc3b050bf4049a98d84d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pdY0rvBHAF0bjraNHS4B9w.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">回忆矩阵(作者的图像)</p></figure><p id="c071" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">令人鼓舞的是，该模型可以很好地预测实际的班级。2–7、3–7和8–7的标签错误非常严重，需要进一步调查。这可能是由于高偏差导致模型将少数类(2，3，8)分类为多数类(7)。</p><p id="0450" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">精度矩阵如下所示:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mj"><img src="../Images/d2a517fbae490a4d4775a2d0649f91b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A_egOlAPSIEd67C4hOZjmA.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">精确矩阵(作者提供的图像)</p></figure><p id="7d42" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">该模型总体上具有良好的精度，因为它可以从对角线上呈现的相当高的值得到。3级和5级的精度低于标准，这表明了进一步工作的方向。</p><p id="6ecb" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">混淆矩阵如下所示:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mk"><img src="../Images/49af8dcd0316bb26f3bfce89407e4fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NouLc9rEP3pLtzwyp8QdKQ.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">困惑矩阵(图片由作者提供)</p></figure><p id="4516" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">再次，该模型在预测突变类别方面具有良好的准确性。有明显的2–7和1–4错配需要进一步调查。</p><p id="923b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">结论</strong></p><p id="a506" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我发现分布式计算可以显著加速生物医学文本挖掘，这对于大数据尤其重要。我可以想到几个改进领域，包括通过超参数调整进一步提高精度和召回率，使用深度学习(特别是基于BERT的模型)，通过检查学习到的系数了解模型学习到的内容，提出更好的方法来表示数据，并将此方法应用于生物医学文本挖掘的其他领域以检查其性能。当我得到一些有趣的结果与大家分享时，我会在未来就其中的一些话题发表文章。</p><p id="f677" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">希望你觉得这个两部分的系列有用。如果您想了解本研究的任何部分或想与我合作，请随时联系我们。</p><p id="4613" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">(再次感谢Namratesh关于这个数据集的<a class="ae lc" href="https://medium.datadriveninvestor.com/personalized-cancer-diagnosis-aea93bad0587" rel="noopener ugc nofollow" target="_blank">帖子</a>，它帮助指导了我的数据预处理的最初部分。)</p></div></div>    
</body>
</html>