<html>
<head>
<title>Principal Component Analysis vs. ExtraTreesClassifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">主成分分析与提取树分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/principal-component-analysis-vs-extratreesclassifier-d0217bbcc9a8?source=collection_archive---------19-----------------------#2021-10-02">https://towardsdatascience.com/principal-component-analysis-vs-extratreesclassifier-d0217bbcc9a8?source=collection_archive---------19-----------------------#2021-10-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1c40" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一种特征选择方法比另一种更好吗？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0f201c1e4dc2ce05a9294977ffe77900.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9M7JTXeuyK3bfxdmybESsQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:图片来自<a class="ae ky" href="https://pixabay.com/illustrations/question-mark-important-sign-1872665/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="a99f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主成分分析(PCA)的目的是识别在训练集中表现出最大变化量的特征。</p><p id="00e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这被用作特征选择方法，以识别影响结果变量的最重要的属性，从而允许丢弃没有显示出太多变化的变量。</p><p id="d5c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，研究了一个酒店取消数据集，以确定1)根据PCA分析，哪些特征显示出最大的变化(因此是最重要的),以及2)使用这些特征的分类模型的准确性结果与extra tree分类器选择的结果相比如何。</p><h1 id="1877" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">主成分分析</h1><p id="449e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在Antonio，Almeida和Nunes (2019)提供的原始酒店取消<a class="ae ky" href="https://www.sciencedirect.com/science/article/pii/S2352340918315191" rel="noopener ugc nofollow" target="_blank">数据集</a>中，如果客户取消其酒店预订，酒店取消(IsCanceled)的结果变量被列为<strong class="lb iu"> 1 </strong>，如果客户不取消，则列为<strong class="lb iu"> 0 </strong>。</p><p id="373b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，还为每个客户提供了一系列不同的功能，其中包括:</p><ul class=""><li id="2e2c" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">交付周期(从预订到顾客入住酒店之间的时间)</li><li id="5254" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">原产国</li><li id="f632" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">细分市场</li><li id="d445" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">存款类型</li><li id="e0e4" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">抵达月份</li></ul><p id="234b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">目的是识别数据集中显示与结果变量(酒店取消)相关的最易解释的差异的要素。</p><p id="3580" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为此，PCA用于识别解释95%的变化的成分的数量，或者换句话说，总计95%的变化的维度的数量。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="bac1" class="nl lw it nh b gy nm nn l no np">&gt;&gt;&gt; from sklearn.decomposition import PCA<br/>&gt;&gt;&gt; pca = PCA()<br/>&gt;&gt;&gt; pca.fit(x1_train)<br/>&gt;&gt;&gt; cumsum = np.cumsum(pca.explained_variance_ratio_)<br/>&gt;&gt;&gt; d=np.argmax(cumsum &gt;= 0.95) + 1</span><span id="e303" class="nl lw it nh b gy nq nn l no np">&gt;&gt;&gt; d<br/>3</span></pre><p id="8140" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<strong class="lb iu"> d=3 </strong>的情况下，这表明所有列出的特征中的三个特征估计会贡献95%的方差。</p><p id="044f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在已经获得了<strong class="lb iu"> d </strong>的值，可以再次运行具有三个指定组件的PCA模型，并识别最重要的特征。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="02ae" class="nl lw it nh b gy nm nn l no np">&gt;&gt;&gt; model = PCA(n_components=3).fit(x1_train)<br/>&gt;&gt;&gt; X_pc = model.transform(x1_train)</span><span id="3f55" class="nl lw it nh b gy nq nn l no np">&gt;&gt;&gt; # number of components<br/>&gt;&gt;&gt; n_pcs= model.components_.shape[0]</span></pre><p id="6d78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，特征名称被指定为<a class="ae ky" href="https://stackoverflow.com/questions/47370795/pca-on-sklearn-how-to-interpret-pca-components" rel="noopener ugc nofollow" target="_blank">生成</a>一个指示最重要特征的数据帧。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="4d2f" class="nl lw it nh b gy nm nn l no np">&gt;&gt;&gt; most_important = [np.abs(model.components_[i]).argmax() for i in range(n_pcs)]<br/>&gt;&gt;&gt; most_important</span><span id="a7a9" class="nl lw it nh b gy nq nn l no np">[1, 23, 11]</span><span id="e375" class="nl lw it nh b gy nq nn l no np">&gt;&gt;&gt; initial_feature_names = ['leadtime','arrivaldatemonthcat','arrivaldateweekno','arrivaldatedayofmonth','staysweekendnights','staysweeknights','adults','children','babies','mealcat','countrycat','marketsegmentcat','distributionchannelcat','isrepeatedguestcat','previouscancellations','previousbookingsnotcanceled','reservedroomtypecat','assignedroomtypecat','bookingchanges','deposittypecat','dayswaitinglist','customertypecat','adr','rcps','totalsqr','reservationstatuscat']</span><span id="98f8" class="nl lw it nh b gy nq nn l no np">&gt;&gt;&gt; most_important_names = [initial_feature_names[most_important[i]] for i in range(n_pcs)]<br/>&gt;&gt;&gt; dic = {'PC{}'.format(i): most_important_names[i] for i in range(n_pcs)}<br/>&gt;&gt;&gt; df = pd.DataFrame(dic.items())<br/>&gt;&gt;&gt; df</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/493b8ad1e27721dfc2b5d5dc62601905.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*VMxKBR54V48_6niTWP_LOw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:Jupyter笔记本输出</p></figure><p id="daa9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据以上所述，抵达月份、所需的停车位和市场细分解释了酒店取消的95%的变化。</p><p id="8d74" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用这些特征，建立了SVM(支持向量机)分类模型，并比较了验证集和测试集的预测精度。</p><h2 id="0c51" class="nl lw it bd lx ns nt dn mb nu nv dp mf li nw nx mh lm ny nz mj lq oa ob ml oc bi translated">验证结果</h2><p id="40ab" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">使用PCA，总体上获得了59%的准确率，而获得了73%的召回率。73%的召回率表明，在取消预订的所有客户中，该模型正确识别了73%。在这点上，在这种情况下，该度量被认为比整体准确性更重要。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="e88f" class="nl lw it nh b gy nm nn l no np">&gt;&gt;&gt; from sklearn import svm<br/>&gt;&gt;&gt; clf = svm.SVC(gamma='scale', <br/>&gt;&gt;&gt;             class_weight='balanced')<br/>&gt;&gt;&gt; clf.fit(x1_train, y1_train)  <br/>&gt;&gt;&gt; prclf = clf.predict(x1_val)<br/>&gt;&gt;&gt; prclf</span><span id="d43c" class="nl lw it nh b gy nq nn l no np">array([0, 0, 1, ..., 0, 0, 1])</span><span id="b705" class="nl lw it nh b gy nq nn l no np">&gt;&gt;&gt; from sklearn.metrics import classification_report,confusion_matrix<br/>&gt;&gt;&gt; print(confusion_matrix(y1_val,prclf))<br/>&gt;&gt;&gt; print(classification_report(y1_val,prclf))</span><span id="1cf4" class="nl lw it nh b gy nq nn l no np">[[3950 3316]<br/> [ 755 1994]]<br/>              precision    recall  f1-score   support<br/><br/>           0       0.84      0.54      0.66      7266<br/>           1       0.38      0.73      0.49      2749<br/><br/>    accuracy                           0.59     10015<br/>   macro avg       0.61      0.63      0.58     10015<br/>weighted avg       0.71      0.59      0.61     10015</span></pre><h2 id="a78d" class="nl lw it bd lx ns nt dn mb nu nv dp mf li nw nx mh lm ny nz mj lq oa ob ml oc bi translated">试验结果</h2><p id="c3ed" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">当将预测与测试结果进行比较时，获得了55%的准确率和81%的召回率。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="99f9" class="nl lw it nh b gy nm nn l no np">&gt;&gt;&gt; a = np.column_stack((t_arrivaldatemonthcat,t_marketsegmentcat,t_rcps))<br/>&gt;&gt;&gt; a = sm.add_constant(a, prepend=True)<br/>IsCanceled = h2data['IsCanceled']<br/>&gt;&gt;&gt; b = IsCanceled<br/>&gt;&gt;&gt; b=b.values</span><span id="7c19" class="nl lw it nh b gy nq nn l no np">&gt;&gt;&gt; prh2 = clf.predict(a)<br/>&gt;&gt;&gt; prh2</span><span id="f76c" class="nl lw it nh b gy nq nn l no np">array([1, 1, 1, ..., 1, 1, 1])</span><span id="e736" class="nl lw it nh b gy nq nn l no np">&gt;&gt;&gt; from sklearn.metrics import classification_report,confusion_matrix<br/>&gt;&gt;&gt; print(confusion_matrix(b,prh2))<br/>&gt;&gt;&gt; print(classification_report(b,prh2))</span><span id="e785" class="nl lw it nh b gy nq nn l no np">[[ 9028 37200]<br/> [ 6274 26828]]<br/>              precision    recall  f1-score   support<br/><br/>           0       0.59      0.20      0.29     46228<br/>           1       0.42      0.81      0.55     33102<br/><br/>    accuracy                           0.45     79330<br/>   macro avg       0.50      0.50      0.42     79330<br/>weighted avg       0.52      0.45      0.40     79330</span></pre><h1 id="bfe7" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">树外分级机</h1><p id="c784" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">正如我们已经看到的，标准PCA方法旨在将特征数量<em class="od"> n </em>减少到更少数量的主成分<em class="od"> d </em>。</p><p id="5dad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，值得注意的是，还可以使用其他特征选择方法。在这种情况下，我们将探讨<strong class="lb iu">提取树分类器</strong>的特征选择方法。</p><p id="461b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ExtraTreesClassifier是一种形式的<strong class="lb iu">集成</strong>方法，其中许多随机决策树适合数据，这实质上是将许多弱学习者组合成一个强学习者。</p><p id="513d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用x和y数据，每个特征的重要性可以通过分数来计算。通过将这些分数分类到一个数据框架中，可以按升序查看每个分数的重要性。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="f186" class="nl lw it nh b gy nm nn l no np">&gt;&gt;&gt; from sklearn.ensemble import ExtraTreesClassifier<br/>&gt;&gt;&gt; model = ExtraTreesClassifier()<br/>&gt;&gt;&gt; model.fit(x, y)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/423ba80ff2bf04826205f62b3a70d5ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:226/format:webp/1*NbMJP8HsIvwg7bbFhz3ahQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:Jupyter笔记本输出</p></figure><p id="5291" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最重要的特征被确定为1、12、13、21、23、25(交付周期、原产国、市场细分、存款类型、客户类型和所需停车位)。特征27(预订状态)因不相关而被丢弃，因为该变量本质上揭示了客户是否取消了预订，并且具有误导性。</p><p id="7597" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用这些特征再次运行SVM模型，并且在如下分类矩阵中输出相对于测试集的准确度:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="a320" class="nl lw it nh b gy nm nn l no np">[[34581 11647]<br/> [11247 21855]]<br/>              precision    recall  f1-score   support<br/><br/>           0       0.75      0.75      0.75     46228<br/>           1       0.65      0.66      0.66     33102<br/><br/>    accuracy                           0.71     79330<br/>   macro avg       0.70      0.70      0.70     79330<br/>weighted avg       0.71      0.71      0.71     79330</span></pre><p id="3842" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用提取树分类器指定的特征，获得了71%的准确率和66%的召回率。注意，当使用PCA指定的特征时，获得了55%的准确率和81%的召回率。</p><h1 id="7dd2" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">比较</h1><p id="3288" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">那么，主成分分析或提取树分类器在选择最相关的特征方面做得更好吗？</p><p id="c62c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，虽然我们不希望整体准确性太低，但回忆是一种更好地表明该模型在预测取消酒店预订的客户方面有多准确的指标。在数据集本身，大多数客户没有取消。因此，准确性本身会产生误导，因为高准确性可能表明该模型非常擅长预测那些没有取消<strong class="lb iu">的客户，但不太擅长预测那些取消</strong>的客户。</p><p id="ef74" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">鉴于此，有人可能会认为PCA在此基础上表现得更好——因为召回率更高，而模型使用更少的特征来解释酒店取消的大多数变化。</p><p id="4096" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">也就是说，理解每个特性的理论相关性是很重要的。在这方面，运行多种特性选择方法并确定哪种方法最适合特定的用例始终是一种好的做法。</p><h1 id="ac8d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="b2a9" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在本文中，您已经看到:</p><ul class=""><li id="962a" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">如何实现PCA模型</li><li id="cd8b" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">在数据集中选择正确要素的重要性</li><li id="d8dd" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">主成分分析和树外分类器在特征选择中的比较</li></ul><p id="d619" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">非常感谢您的宝贵时间，非常感谢您的任何问题或反馈。您还可以在这里找到这个例子<a class="ae ky" href="https://github.com/MGCodesandStats/hotel-modelling" rel="noopener ugc nofollow" target="_blank">的相关GitHub库。</a></p><h1 id="cbb6" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">参考</h1><ul class=""><li id="1f16" class="ms mt it lb b lc mn lf mo li of lm og lq oh lu mx my mz na bi translated"><a class="ae ky" href="https://www.sciencedirect.com/science/article/pii/S2352340918315191" rel="noopener ugc nofollow" target="_blank">安东尼奥、阿尔梅迪亚、努内斯(2019)。酒店预订需求数据集。</a></li><li id="52d6" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">Aurélien Geron (O'Reilly Media):使用Scikit-Learn和TensorFlow进行机器学习</li><li id="08b0" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated"><a class="ae ky" href="https://stackoverflow.com/questions/47370795/pca-on-sklearn-how-to-interpret-pca-components" rel="noopener ugc nofollow" target="_blank">堆栈溢出:sklearn上的PCA如何解释pca.components_ </a></li><li id="c36d" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/feature-selection-techniques-in-python-predicting-hotel-cancellations-48a77521ee4f">走向数据科学:Python中的特征选择技术——预测酒店取消预订</a></li></ul><p id="9954" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="od">免责声明:本文是在“原样”的基础上编写的，没有任何担保。它旨在提供数据科学概念的概述，不应被解释为专业建议。本文中的发现和解释是作者的发现和解释，不被本文中提到的任何第三方认可或隶属于任何第三方。作者与本文提及的任何第三方无任何关系。</em></p></div></div>    
</body>
</html>