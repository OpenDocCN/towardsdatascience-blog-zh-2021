<html>
<head>
<title>How to Handle Missing Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何处理丢失的数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-handle-missing-data-b557c9e82fa0?source=collection_archive---------16-----------------------#2021-08-16">https://towardsdatascience.com/how-to-handle-missing-data-b557c9e82fa0?source=collection_archive---------16-----------------------#2021-08-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e90b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用XGBoost的最快多重插补方法</h2></div><p id="8c6f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">丢失数据太糟糕了。它阻止了某些模型的使用，并且经常需要工程师进行复杂的判断。然而，在2021年，奥克兰大学的研究人员开发了一种解决方案…</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/9ba9f3db48feebf0b07b65002511f10c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vA396Kygvl_ZrhBqNLUvyw.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图1:大型数据集的缺失数据。图片作者。</p></figure><p id="734a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">他们的方法利用世界闻名的XGBoost算法来估算缺失数据。依靠一个针对速度优化的模型，我们可以看到相对于传统插补方法10-100倍的性能提升。XGBoost还几乎不需要超参数调整，这大大减少了工程师的工作量。XGBoost还能够维护数据中观察到的复杂关系，比如交互和非线性关系。</p><p id="c7d2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，如果数据集超过3000行，您可以考虑使用XGBoost来估算缺失数据。下面是该方法的工作原理…</p><h1 id="dbb3" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">技术TLDR</h1><ol class=""><li id="c4c5" class="mj mk iq kh b ki ml kl mm ko mn ks mo kw mp la mq mr ms mt bi translated"><strong class="kh ir">使用XGBoost进行多重插补。</strong>它是在MICE框架中实现的——我们不使用线性/逻辑回归，而是使用XGBoost。</li><li id="4690" class="mj mk iq kh b ki mu kl mv ko mw ks mx kw my la mq mr ms mt bi translated"><strong class="kh ir">使用预测均值匹配(PMM)来改善我们的方差估计。</strong> PMM是必需的，因为XGBoost低估了估算数据的方差，导致置信区间的覆盖范围很小。</li></ol><h1 id="f7f2" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">好的，这很好，但是这个方法实际上是如何工作的呢？</h1><p id="46a0" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mz kq kr ks na ku kv kw nb ky kz la ij bi translated">我们稍微慢一点，理解一下为什么这个方法这么有效。</p><h2 id="ed65" class="nc ls iq bd lt nd ne dn lx nf ng dp mb ko nh ni md ks nj nk mf kw nl nm mh nn bi translated">我们的目标</h2><p id="2b13" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mz kq kr ks na ku kv kw nb ky kz la ij bi translated">首先，从我们的目标开始。许多真实世界的数据集都有缺失数据，这会给建模和分析带来问题。为了让我们的生活更轻松，我们将尝试用现实的预测来填补那些缺失的价值。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi no"><img src="../Images/73e0f56fb41c575f9254fb744b24b544.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1OjNoQumsn4OfIbAafaDGw.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图2:大型数据集缺失数据插补可视化。图片作者。</p></figure><p id="8e09" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">填充缺失数据的一种常用方法是简单地输入平均值、中值或众数。然而，正如你所料，我们获得的信号很少，而且这些估计的方差往往太低。</p><h2 id="4022" class="nc ls iq bd lt nd ne dn lx nf ng dp mb ko nh ni md ks nj nk mf kw nl nm mh nn bi translated">方差的重要性</h2><p id="abb0" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mz kq kr ks na ku kv kw nb ky kz la ij bi translated">但是我们为什么要在乎呢？嗯，方差是所有统计显著性和置信区间计算的基础。</p><p id="a07a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基于中心极限定理，我们知道许多样本的平均值将类似于正态分布。如果我们观察一个样本，它的平均值远离这个理论分布(总体)的中心，我们可以认为这是极不可能的，因此具有统计学意义。并且，我们<strong class="kh ir">不会</strong>称之为统计显著的范围被称为我们的置信区间。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi np"><img src="../Images/6593c6ebd2151ce8dc7e12ebc008a036.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*Tbwj7pMlpJHVQ6sSvtTXtg.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图3:样本方差公式。图片作者。</p></figure><p id="f3ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了估计这一理论总体的分布，我们使用数据的标准差，即数据方差的平方根，如图3所示。因此，方差是所有基于信心的计算的基础。</p><h2 id="17d6" class="nc ls iq bd lt nd ne dn lx nf ng dp mb ko nh ni md ks nj nk mf kw nl nm mh nn bi translated">估算数据的方差</h2><p id="6ef6" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mz kq kr ks na ku kv kw nb ky kz la ij bi translated">当输入数据时，我们希望使用观察到的数据来估计未观察到的数据。如果我们有一个完美的代表性样本，我们可以完美地估算缺失数据。然而，样本从来都不是完美的，经常会丢失关于丢失数据的关键信息。</p><p id="a334" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于这个事实，大多数数据插补方法低估了缺失数据的方差。</p><p id="20f9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，以正确的方式系统地引入方差真的很难。一种简单的方法是简单地给每个估算值添加一些随机噪声。这肯定会使我们的数据更加多样化，并可能增加方差。但是，这种均匀分布的噪声可能并不代表我们的总体。</p><p id="c1fe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是<em class="nq">mixb</em>的用武之地…</p><h1 id="06bf" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">该方法</h1><p id="1027" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mz kq kr ks na ku kv kw nb ky kz la ij bi translated">奥克兰大学的研究人员提出的方法使用流行的建模技术<em class="nq"> XGBoost </em>和预测均值匹配(PMM)来估算数据。让我们依次看一看每一个。</p><h2 id="a288" class="nc ls iq bd lt nd ne dn lx nf ng dp mb ko nh ni md ks nj nk mf kw nl nm mh nn bi translated">1—MICE框架中的XGBoost</h2><p id="e2d4" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mz kq kr ks na ku kv kw nb ky kz la ij bi translated">XGBoost是一种非常流行的基于树的算法，因为它速度快，通用性强，并且具有开箱即用的准确性。评论中有一个惊人的解释，但对于这篇文章，你可以把XGBoost想象成一个黑盒，它接收预测值并输出我们缺失数据的估计值。</p><p id="6223" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一方面，我们将讨论MICE框架。MICE代表通过链式方程的多重插补。没有听起来那么糟糕。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nr"><img src="../Images/aaba73d66bca4eda608112402fa1f22e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8YOl4GCj5iGbq_OUHh5DuQ.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图4:具有4个插补集的MICE框架。图片作者。</p></figure><p id="999a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">MICE的工作方式是创建数据的M份副本。然后，它依次遍历第一个复制的数据集中的列(图4中的M1 ),并使用线性模型来预测缺失的值。预测值是该行中的所有其他变量。然后MICE对其余的<em class="nq"> M </em>数据集重复这个过程，产生M个完整的数据集。</p><p id="d0ef" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从那里，我们取所有<em class="nq"> M </em>数据集的每个指数值的平均值，这些平均值成为我们的最终估算数据集。</p><p id="f8ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，如果你仔细观察，你会发现所有的数据集都是一样的。因此，为了给外观自然的变化，我们只是添加一些随机噪声到每个预测。</p><p id="451a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">很直接，对吧？</p><p id="df0b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，线性回归有其局限性——它不允许非线性关系，并且需要人工干预来处理交互。XGBoost在非线性关系和交互方面都很棒，所以我们只是使用XGBoost而不是线性回归来预测我们的缺失数据。</p><h2 id="ac04" class="nc ls iq bd lt nd ne dn lx nf ng dp mb ko nh ni md ks nj nk mf kw nl nm mh nn bi translated">2 —预测均值匹配处理低方差</h2><p id="0cb7" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mz kq kr ks na ku kv kw nb ky kz la ij bi translated">现在，XGBoost受限于我们给它的数据，所以它经常低估我们预测的方差。为了增加方差，我们实施了一种称为预测均值匹配(PMM)的方法。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ns"><img src="../Images/747f8f6de7eec2f01be147c265255091.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yb8ysa-YIKcAkRriZuuBKQ.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图5:二维预测平均匹配。图片作者。</p></figure><p id="5142" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">PMM随机选择五个最接近我们预测的观察数据点之一。因此，在上面的图5中，绿点是我们的预测值，它周围突出显示的圆圈是我们的预测将成为的候选值。</p><p id="bc68" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过用观察到的数据点替换预测，我们确保引入的方差与我们总体中的方差具有相同的结构。</p><p id="dcfb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们对所有预测值重复这一过程，直到我们用预测值附近的观察数据点替换了所有空的数据点。</p><h2 id="d1f3" class="nc ls iq bd lt nd ne dn lx nf ng dp mb ko nh ni md ks nj nk mf kw nl nm mh nn bi translated">摘要</h2><p id="ecb1" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mz kq kr ks na ku kv kw nb ky kz la ij bi translated">现在，你知道了。快速总结一下…</p><ul class=""><li id="d712" class="mj mk iq kh b ki kj kl km ko nt ks nu kw nv la nw mr ms mt bi translated">XGBoost是一种高性能算法，可以对数据中的复杂关系进行建模。</li><li id="f486" class="mj mk iq kh b ki mu kl mv ko mw ks mx kw my la nw mr ms mt bi translated"><em class="nq"> mixgb </em>包利用XGBoost来估算缺失数据。</li><li id="0597" class="mj mk iq kh b ki mu kl mv ko mw ks mx kw my la nw mr ms mt bi translated">为了确保我们可以计算准确的置信区间，我们使用预测均值匹配来增加估算数据的方差。</li></ul><h1 id="64c9" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">实施说明</h1><ul class=""><li id="37ad" class="mj mk iq kh b ki ml kl mm ko mn ks mo kw mp la nw mr ms mt bi translated">在更小的数据集上，XGBoost在计算速度上更胜一筹。主要的竞争来自于<a class="ae nx" href="https://www.rdocumentation.org/packages/missRanger/versions/2.1.1/topics/missRanger" rel="noopener ugc nofollow" target="_blank">随机森林实现</a>，但是XGBoost在大于3000 X 20的数据集上表现更好。</li><li id="9785" class="mj mk iq kh b ki mu kl mv ko mw ks mx kw my la nw mr ms mt bi translated">对PMM来说，有几种不同的方法，但没有一种方法局限于5人的捐献者人数。其他常见的值有2、3和10。</li><li id="d290" class="mj mk iq kh b ki mu kl mv ko mw ks mx kw my la nw mr ms mt bi translated">目前，我还不知道有哪个python包支持这种方法。</li><li id="53fe" class="mj mk iq kh b ki mu kl mv ko mw ks mx kw my la nw mr ms mt bi translated">在论文中，我们开始看到mixgb在3915 x 20数据集上在计算速度方面优于所有其他方法。对于所有较大的数据集，XGBoost是明显的赢家。</li></ul></div><div class="ab cl ny nz hu oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="ij ik il im in"><p id="56e1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="nq">感谢阅读！我会再写39篇文章，把学术研究带到DS行业。查看我的评论，链接到这篇文章的主要来源以及R包。</em></p></div></div>    
</body>
</html>