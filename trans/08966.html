<html>
<head>
<title>HuggingFace Processing Jobs on Amazon SageMaker</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">亚马逊SageMaker上的拥抱脸处理工作</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/huggingface-processing-jobs-on-amazon-sagemaker-b1f5af97b663?source=collection_archive---------29-----------------------#2021-08-18">https://towardsdatascience.com/huggingface-processing-jobs-on-amazon-sagemaker-b1f5af97b663?source=collection_archive---------29-----------------------#2021-08-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d622" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">以可扩展和可再现的方式为NLP管道准备文本数据</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/6e9bef3198478e76bc64616230dcb606.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BflEAtwR4PXyFgtU"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae kv" href="https://unsplash.com/@wonderlane?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Wonderlane </a>拍摄的照片</p></figure><h1 id="9684" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">这是怎么回事？</h1><p id="e3ef" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">最新版本的<a class="ae kv" href="https://github.com/aws/sagemaker-python-sdk" rel="noopener ugc nofollow" target="_blank">SageMaker Python SDK</a>(v 2 . 54 . 0)引入了HuggingFace处理器，用于<a class="ae kv" href="https://sagemaker.readthedocs.io/en/stable/amazon_sagemaker_processing.html" rel="noopener ugc nofollow" target="_blank">处理作业</a>。这些处理作业可用于在Amazon SageMaker上运行数据预处理或后处理、特征工程、数据验证或模型评估的步骤。</p><p id="1c9e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">HuggingFace处理器对于基于HuggingFace的Transformer模型的NLP管道非常有用。深度学习容器(DLC)预装了所有必需的依赖项，并针对典型的HuggingFace数据转换(如标记化)进行了优化。在本教程中，我们将看看这些处理器，并了解如何利用它们来准备文本数据，以训练变压器模型。</p><p id="8e7f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">和往常一样，本教程的<a class="ae kv" href="https://github.com/marshmellow77/sm-hf-processor" rel="noopener ugc nofollow" target="_blank">代码</a>可以在GitHub上获得。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="896c" class="kw kx iq bd ky kz mw lb lc ld mx lf lg jw my jx li jz mz ka lk kc na kd lm ln bi translated">拥抱脸+ SageMaker:简要概述</h1><p id="70d2" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">2021年3月，Huggingface和AWS宣布了一项<a class="ae kv" href="https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face" rel="noopener ugc nofollow" target="_blank">合作伙伴关系</a>，这使得在亚马逊SageMaker上训练最先进的NLP模型变得更加容易。有了新的拥抱脸训练DLCs，训练基于变形金刚的NLP模型变得简单多了。7月，这种集成<a class="ae kv" href="https://huggingface.co/blog/deploy-hugging-face-models-easily-with-amazon-sagemaker" rel="noopener ugc nofollow" target="_blank">得到了扩展</a>,在SageMaker上增加了变形金刚模型的简单部署和推断。现在，在2021年8月，Sagemaker Python SDK为这种集成添加了另一个构件，<a class="ae kv" href="https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/huggingface/processing.py" rel="noopener ugc nofollow" target="_blank"> Huggingface处理器</a>。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="7eea" class="kw kx iq bd ky kz mw lb lc ld mx lf lg jw my jx li jz mz ka lk kc na kd lm ln bi translated">为什么这很重要？</h1><p id="39aa" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">HuggingFace处理器允许我们在容器化的图像中准备文本数据，该图像将在专用的EC2实例上运行。这有两个主要好处:(1)对于大型数据集，数据准备可能需要很长时间。选择专用的EC2实例允许我们为手头的任务选择合适的处理能力。(2)通过处理作业对数据准备进行编码，使我们能够以可扩展和可再现的方式将数据处理步骤集成到用于NLP任务的CI/CD管道中。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="c707" class="kw kx iq bd ky kz mw lb lc ld mx lf lg jw my jx li jz mz ka lk kc na kd lm ln bi translated">下载和检查数据集</h1><p id="6de4" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">既然已经说了，让我们开始吧！我们的目标是准备一个数据集，以便在稍后的某个时刻，可以用这个数据训练一个二元情感分类器。该分类器将文本作为输入，并预测文本中的情感是积极的还是消极的。为此，我们将在本教程中利用<a class="ae kv" href="https://s3.amazonaws.com/amazon-reviews-pds/readme.html" rel="noopener ugc nofollow" target="_blank">亚马逊客户评论数据集</a>。</p><p id="48df" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">该数据集包含各种类别的评论，在本教程中，我们将使用数字软件的评论。我们可以从一个公开的S3文件夹中下载数据，先看一看:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/ec2111daa1ce2cefd6e97fbb7df72a0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p5uNDhw3EVys8yb_2DM15A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="531b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们可以看到在这个数据集中有相当多的列，其中大部分在我们的模型中并不需要。这意味着我们将不得不丢弃这些列。由于我们希望训练一个二进制分类器，我们还需要将星级转换为二进制值，即0和1，它们将分别代表负面和正面的评论。在本教程中，我们将使用4颗星的阈值将评级转换为二进制值。这意味着，每一个4或5星的评分将被标记为正面评价，而每一个低于4星的评分将被视为负面评价。为了准备Transformers模型的数据，我们还想对数据进行标记。最后，我们希望将数据分成训练、验证和测试数据。</p><p id="0b5c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">所有这些逻辑都将被捕获到处理脚本中，你可以在这里找到<a class="ae kv" href="https://github.com/marshmellow77/sm-hf-processor/blob/main/scripts/preprocessing-hf.py" rel="noopener ugc nofollow" target="_blank"/>。本教程的重点是利用HuggingFace处理器，而不是数据准备本身，所以我不会深入讨论处理脚本的细节。但是，如果你对剧本有任何疑问，请随时联系我们！</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="e34d" class="kw kx iq bd ky kz mw lb lc ld mx lf lg jw my jx li jz mz ka lk kc na kd lm ln bi translated">使用HuggingFace处理器</h1><p id="d3eb" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">既然我们已经开发了处理脚本，我们可以使用Sagemaker Python SDK来启动处理作业。首先，我们需要定义处理作业</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="3fa1" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们定义要运行它的实例，以及需要多少个实例。如果数据处理任务繁重，并且有大量数据，那么提供多个实例可能是有意义的。</p><p id="dae7" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">接下来，我们需要定义处理作业的输入和输出，以及作业的参数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="4121" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">最后，我们可以开始培训工作了:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="2684" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">作业启动后，我们可以在Sagemaker控制台中看到它正在运行:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/0ed9aef5232c3fd49f1945b105bb24a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K9JqQNelomwLTRPIHlPweQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="d874" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">几分钟后，工作完成了。控制台将提供关于处理作业的许多细节，例如使用了哪个容器映像，以及处理后的数据存储在S3的什么位置。我们还可以通过SageMaker Python SDK API以编程方式收集这些数据点。例如，我们可以轻松地检索已处理数据的S3位置:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/168f2467f04fe11b695aa613c7c01acd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D0-_qV3xjm9QJao-LZlTKg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="6bc0" class="kw kx iq bd ky kz mw lb lc ld mx lf lg jw my jx li jz mz ka lk kc na kd lm ln bi translated">结论</h1><p id="33c9" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在本教程中，我们成功地利用Sagemaker处理作业来处理Transformer模型的数据。这个处理作业现在可以合并到NLP管道中，每次新的训练数据到达时，处理作业就开始。现在，数据已经过处理和标记化，可以很容易地用于训练HuggingFace Transformer模型。</p></div></div>    
</body>
</html>