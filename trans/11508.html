<html>
<head>
<title>Implementing a character-level trigram language model from scratch in python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用python从头开始实现字符级三元模型语言模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-a-character-level-trigram-language-model-from-scratch-in-python-27ca0e1c3c3f?source=collection_archive---------7-----------------------#2021-11-13">https://towardsdatascience.com/implementing-a-character-level-trigram-language-model-from-scratch-in-python-27ca0e1c3c3f?source=collection_archive---------7-----------------------#2021-11-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="06b9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">预测是困难的，但它可以在小的方面得到解决，比如预测某人将要说的下几个单词或完成正在键入的单词或句子的下几个字符。这就是我们将要尝试去做的。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/174a77e657b7a2e85147110ff9149a6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NOFseP-vGYmh93iDqi2y1A@2x.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="39c5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本文的完整代码可以在<a class="ae lr" href="https://github.com/cleopatra27/Ngram-Model/blob/main/trigram_modelling.py" rel="noopener ugc nofollow" target="_blank">这里</a>找到</p><h1 id="b9b8" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">什么是N-gram</h1><p id="7d34" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">N-gram是来自给定文本或语音样本的N个项目(在这种情况下是单词)的序列。例如，给定文本“Susan是一个善良的灵魂，她会帮助你，只要这是在她的界限之内”从开头开始的上述文本的样本n-gram是:</p><p id="aa6d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> unigram </strong> : ['苏珊'，'是'，' a '，'善良'，'灵魂'，'她'，'意志'，'帮助'…………。]</p><p id="ee38" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> bigram </strong> : ['苏珊是'，'是一个'，'一个善良'，'善良的灵魂'，'灵魂她'，'她会'，'会帮助'，'帮助你'…………。]</p><p id="e76a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">三元组</strong> : ['苏珊是一个'，'是一种'，'一个善良的灵魂'，'善良的灵魂她'，'灵魂她会'，'她会帮助你'…………。]</p><p id="3cb0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从上面的例子中，我们可以看到n-grams中的<strong class="kx ir"> <em class="mp"> n </em> </strong>可以是不同的值，1个gram的序列称为一元gram，2个gram的序列称为二元gram，3个gram的序列称为三元gram。</p><h1 id="160b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">三元模型</h1><p id="505d" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">我们将在本文中讨论三元模型。</p><p id="28f9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">二元模型</strong>通过仅使用前面单词的条件概率来近似给定所有前面单词的单词的概率，而<strong class="kx ir">三元模型</strong>查看过去的两个单词。</p><p id="cb8f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，基于以上所述，为了计算给定先前单词x，z的单词y的特定三元模型概率，我们将计算三元模型C(xzy)的计数，并通过共享相同单词x和z的所有三元模型的总和进行归一化，这可以使用以下等式来简化:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/00786b7fc7997bf20e814208a64ae91a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*u-g-Fze0_zZeIauM-b9U0g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="e819" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">也就是说，为了计算单词“soul”的特定三元模型概率，给定前面的单词“kind”、“hearted”，我们将计算三元模型C(“kind hearted soul”)的计数，并通过共享相同第一单词“kind hearted”的所有三元模型的总和进行归一化。</p><p id="52b9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们总是以对数概率的形式表示和计算语言模型的概率。因为概率(根据定义)小于或等于1，所以我们相乘的概率越多，乘积就越小。将足够多的n元文法相乘会导致数字下溢，所以我们使用对数概率，而不是原始概率。对数空间中的相加相当于线性空间中的相乘，所以我们通过相加来组合对数概率。</p><h1 id="42ee" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">密码</h1><p id="d48c" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">我们将使用来自古腾堡项目的大量数据。这包含了来自不同书籍的段落。我们将以预测人物的人物级三元模型语言模型为例，考虑奥斯汀的这句话:<br/> <strong class="kx ir"> <em class="mp">艾玛·伍德豪斯，英俊、聪明、富有，拥有舒适的家庭和快乐的性情，似乎联合了一些最好的存在的祝福；在这个世界上生活了近21年，很少让她苦恼或烦恼。</em> </strong> <em class="mp"> </em> <br/> <br/>下面是这个句子中字符级三元组的一些例子:<br/> <em class="mp"> </em> <strong class="kx ir"> <em class="mp"> Emm，mma，Woo，ood，… </em> </strong></p><p id="aa27" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，我们将对我们的数据做一些预处理，我们将把所有段落中的单词组合成一个大的语料库，删除数字值(如果有的话)，并加双空格。</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="d564" class="mw lt iq ms b gy mx my l mz na">def preprocess(self):<br/>    output = ""<br/>    for file in self.texts:<br/>        with open(os.path.join(os.getcwd(), file), 'r', encoding="utf-8-sig", errors='ignore') as suffix:<br/>            sentence = suffix.read().split('\n')<br/>            for line in sentence:<br/>                output += " " + line<br/>    return output</span></pre><p id="0741" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来是生成n元文法的代码，我们将编写一个通用函数，它接受我们的语料库以及描述我们希望如何划分n元文法的值。见下文:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="cd71" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，我们构建一个计算词频的函数，当看不到这个词时，我们将通过用一个普通字符替换频率低于5的词来平滑这个例子，在这个例子中，<strong class="kx ir"> UNK </strong>。</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="36ce" class="mw lt iq ms b gy mx my l mz na">def UNK_treated_ngram_frequency(self, ngram_list):<br/>    frequency = {}<br/>    for ngram in ngram_list:<br/>        if ngram in frequency:<br/>            frequency[ngram] += 1<br/>        else:<br/>            frequency[ngram] = 1<br/><br/>    sup = 0<br/>    result = {}<br/><br/>    for k, v in frequency.items():<br/>        if v &gt;= 5:<br/>            result[k] = v<br/>        else:<br/>            sup += v<br/>    result["UNK"] = sup<br/>    return result</span></pre><p id="477e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，我们有了三元模型，我们将对未知概率使用拉普拉斯加一平滑，我们还将把所有概率(在对数空间中)加在一起:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><h1 id="4c73" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">评估我们的模型</h1><p id="2b9d" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">有两种不同的方法来评估和比较语言模型，<strong class="kx ir">外在评估</strong>和<strong class="kx ir">内在评估。</strong>我们将从本质上进行评估，因为这是一种<strong class="kx ir">快速</strong>评估模型的有用方式。我们将用一种叫做<strong class="kx ir">困惑的度量来评估，这是一种内在的评估方法，虽然</strong>不如内在评估好，但是<a class="ae lr" rel="noopener" target="_blank" href="/perplexity-in-language-models-87a196019a94">这篇文章</a>可以更好地解释评估概念。</p><p id="4126" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将通过模型在一些测试数据上的表现来衡量模型的质量。语言模型在测试集上的困惑度是测试集的逆概率，用单词数归一化。因此单词序列的条件概率越高，困惑度越低，并且最大化困惑度等同于根据语言模型最大化测试集概率。</p><p id="f044" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于我们的例子，我们将使用困惑来比较我们的模型和两个测试句子，一个是英语，另一个是法语。</p><p id="31ef" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">困惑度的计算方法如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/9cd9e165008d52f59160243a4c2bdec0.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*zpgwk3YQOlDpnPI7diXMzw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="cc71" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">实现为:</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="3ef8" class="mw lt iq ms b gy mx my l mz na">def perplexity(total_log_prob, N):<br/>    perplexity = total_log_prob ** (1 / N)<br/>    return perplexity</span></pre><p id="4b15" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">测试下面的两个句子，我们得到以下困惑:</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="62be" class="mw lt iq ms b gy mx my l mz na">perp = self.perplexity(sum_prob, len(trigram_value))<br/>print("perplexity ==&gt; ", perp)</span></pre><p id="6ead" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">英语句子:0.1的困惑。36860.68868688661</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="ceab" class="mw lt iq ms b gy mx my l mz na">If we do not change our economic and social policies, we will be in danger of undermining solidarity, the very value on which the European social model is based.<br/>The rapid drift towards an increasingly divided society is happening not only in Europe but also on a much wider scale. An entire continent, Africa - about which you made a highly relevant point in your speech, Prime Minister - has lost contact even with the developing world.<br/>We must do everything in our power to stop this unjust development model and to give voices and rights to those who have neither.<br/>Ladies and gentlemen, Prime Minister, the Laeken Summit and declaration are also vitally important for another reason.<br/>Laeken must determine how we are to structure the second stage of the 'Future of Europe' debate.</span></pre><p id="5f7d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">法语句子:0.2的困惑。56860.68868888661</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="de51" class="mw lt iq ms b gy mx my l mz na">Je suis reconnaissante Ã  la Commission d' avoir adoptÃ© ce plan d' action.<br/>Cependant, la condition de son applicabilitÃ© est que les personnes atteintes d' un handicap puissent disposer des moyens financiers nÃ©cessaires, et qu' elles aient la possibilitÃ© purement physique de passer les frontiÃšres.<br/>Il serait intÃ©ressant de savoir si la Commission est aussi disposÃ©e Ã  dÃ©bloquer des fonds en faveur des personnes handicapÃ©es, pour qu' elles puissent, elles aussi, parcourir le monde, aussi loin que pourra les emmener le fauteuil roulant.<br/>J'ai mentionnÃ© la directive que la Commission a proposÃ©e pour l'amÃ©nagement des moyens de transport collectifs, afin que les handicapÃ©s puissent les utiliser.<br/>Le Conseil n'a pas encore fait avancer cette question, qui en est au stade de la concertation.</span></pre><p id="0ca2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">不出所料，我们的模型被法语句子搞糊涂了，目前这已经足够好了，但是，我们的模型还可以改进。</p><p id="4edc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">欢迎评论和反馈。</p><p id="4543" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">不要忘记点击“关注”按钮。</p></div></div>    
</body>
</html>