<html>
<head>
<title>Speed Cubing for Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的速度立方</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/speed-cubing-for-machine-learning-4bf90170e2ee?source=collection_archive---------44-----------------------#2021-03-22">https://towardsdatascience.com/speed-cubing-for-machine-learning-4bf90170e2ee?source=collection_archive---------44-----------------------#2021-03-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="44ac" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">第3集:使用多GPU、Dask和CuPy</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/7d456b61bd718e2f2d0b47b493fbcec7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Y-X8uwybwzQcSVP0"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">布莱斯·巴克在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><h1 id="3ef1" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="7b54" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">《机器学习的速度立方》前情提要……</p><p id="55ec" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">在第1集<strong class="lq ir"/>【1】中，我们描述了如何使用CPU、多线程和云资源，尽可能快地生成3D数据，以最终养活一些生成性对抗网络。我们达到了每秒20亿个数据点的速度。</p><p id="68a4" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">在第2集[2]中，我们使用了一个本地GPU，一个名为<em class="mk"> RAPIDS </em>的框架，以及<em class="mk"> CuPy </em>和<em class="mk"> VisPy </em>等库。我们的速度甚至更快，几乎达到了每秒50亿个数据点！</p><p id="4251" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">在这最后一集，我们仍将关注速度，但这一次，我们将在<strong class="lq ir">几个GPU</strong>的帮助下执行<em class="mk">实际计算</em>。</p><h1 id="ab4d" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">技术设置</h1><p id="1793" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">所有实验都将通过JupyterLab笔记本电脑在云中实例化的虚拟机(VM)上进行。该虚拟机具有16个英特尔至强vCPUs @ 2.30GHz、60 GB内存和8个NVIDIA Tesla K80 GPUs(图1)。虚拟机预先配置了所有必要的NVIDIA驱动程序和CUDA 11.0工具包。操作系统是Linux (Debian 4.19 64位)，安装了Python 3.7。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/fcf6da85e83ca1af3fcc5a6737da151a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*qOD3yW7jyEgS5fyl81H2PA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mr">图一</strong> : NVIDIA Tesla K80，24GB GDDR5，4992个CUDA核心(来源:nvidia.com)。</p></figure><p id="fc9e" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">我们还需要以下额外的图书馆/包:</p><ul class=""><li id="90bd" class="ms mt iq lq b lr ml lu mm lx mu mb mv mf mw mj mx my mz na bi translated"><strong class="lq ir">Dask</strong>:Python中并行计算的开源库[3]。使用命令<code class="fe nb nc nd ne b">python -m pip install "dask[complete]"</code> <em class="mk">进行安装。</em></li><li id="bbb7" class="ms mt iq lq b lr nf lu ng lx nh mb ni mf nj mj mx my mz na bi translated"><strong class="lq ir"> CuPy </strong>:用NVIDIA CUDA加速的开源阵列库[4]。它相当于GPU的NumPy。使用命令<code class="fe nb nc nd ne b">pip install cupy-cuda110</code>进行安装(以匹配我们的CUDA版本)。</li><li id="19e7" class="ms mt iq lq b lr nf lu ng lx nh mb ni mf nj mj mx my mz na bi translated"><strong class="lq ir"> Dask CUDA </strong>:由<em class="mk">rapidsai</em>【5】托管的实验性开源库，帮助多GPU系统中Dask workers的部署和管理。使用命令<code class="fe nb nc nd ne b">pip install dask-cuda</code>进行安装。</li></ul><p id="3745" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">安装完成后，我们可以像这样导入库:</p><pre class="kg kh ki kj gt nk ne nl nm aw nn bi"><span id="26d1" class="no kx iq ne b gy np nq l nr ns"><strong class="ne ir">import</strong> dask.array <strong class="ne ir">as</strong> da<br/><strong class="ne ir">import</strong> cupy<br/><strong class="ne ir">from</strong> dask_cuda <strong class="ne ir">import</strong> LocalCUDACluster<br/><strong class="ne ir">from</strong> dask.distributed <strong class="ne ir">import</strong> Client</span></pre><h1 id="424e" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">我们开始吧！</h1><p id="d155" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我必须承认，成功运行多GPU数值模拟是一段不平凡的旅程。事实上，大多数在线材料都专注于专门用于加速深度学习模型训练的内置方法。然而，当计算在这个框架之外执行时，我缺乏完整的文档。此外，多GPU计算比多CPU计算更棘手:内存分配和数据管理可能难以处理。这就是达斯克的用武之地。</p><h1 id="b55b" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">存储数据:Dask数组</h1><p id="0f27" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">Dask数组协调许多数组(在API中足够“像NumPy ”,比如CuPy数组),在一个网格中排列成块(图2)。将大数组分割成许多小数组，可以让我们使用所有内核在比可用内存更大的数组上执行计算。Dask数组受益于多维<em class="mk">阻塞</em> <em class="mk">算法</em>和<em class="mk">任务</em> <em class="mk">调度</em>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/5c73e0a66db55c59faa5889448483b6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*HqYBfmUtdDFNyIicNrt3EQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mr">图2</strong>:Dask阵列的结构。</p></figure><h1 id="f0cd" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">第一个实验:单CPU</h1><p id="63b3" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们首先生成一个二维Dask数组，其中的数据是从高斯分布中抽取的随机样本。我们将平均值设为10，标准差设为1。分布大小是sz=100000，块大小是ch=10000。这导致一个80 GB的Dask数组包含100个块，每个块是一个800 MB的numpy数组。当您在笔记本中打印Dask数组时，Dask会自动显示数据的图形表示以及有关其体积、形状和类型的信息(图3)。这个过程完全是“懒惰”的，这意味着还没有数据被加载到内存中。请注意，dask需要执行100个任务来创建Dask数组。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/490d7ad0b6fb787ad3851505d1ebe2de.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*gr7_4tCcIVulxMZ0u2zprQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mr">图3 </strong>:分块随机<strong class="bd mr"> numpy </strong>数组的Dask数组。</p></figure><blockquote class="nv nw nx"><p id="c7e0" class="lo lp mk lq b lr ml jr lt lu mm ju lw ny mn lz ma nz mo md me oa mp mh mi mj ij bi translated">对于我们的基准测试，我们希望执行下面的简单计算:<strong class="lq ir">获取数据的一个子集，将所有值递增1，然后计算平均值</strong>。</p></blockquote><p id="a76f" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">图4显示了我们将要计算平均值的子集的信息。我们可以看到，Dask现在需要执行300个任务来获得该子集，这是一个20GB的Dask数组，有100个块，每个块是一个200 MB的numpy数组。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/ac834eb0c468513b19bd348135efb8cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*YvA9Q7zjiRSuLzMoTvWAtw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mr">图4 </strong>:原始数据子集(类型为<strong class="bd mr"> numpy.ndarray </strong>)。</p></figure><p id="8046" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">现在，实际的计算可以使用<code class="fe nb nc nd ne b">.compute()</code>方法来完成。我们还将调度器参数指定为<code class="fe nb nc nd ne b">'single-threaded'</code>，因此Dask将在一个<strong class="lq ir">单CPU </strong>上执行任务。整个过程用时<strong class="lq ir"> 11分41秒。</strong>最终值与预期值接近(1.0e-5)移动平均值(图5)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/d9e39124858a0aec7b46c36322cb88e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*rLUGgPwts839eVW8eewaAg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mr">图5 </strong>:单个CPU上的计算:耗时701秒。</p></figure><h1 id="77d6" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">第二个实验:多CPU</h1><p id="2bcb" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在Dask中，从单个CPU到多个CPU非常简单:您所要做的就是将调度器的参数改为<code class="fe nb nc nd ne b">'threads'</code>。这样，Dask将使用所有可用的内核来执行并行计算(图6)。这一次，使用我们VM的<strong class="lq ir"> 16核</strong>，只需要<strong class="lq ir"> 55秒</strong>就可以完成任务。计算出的平均值仍然接近(1.7e-5)预期值11(图7)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/9bd8a626c869b552f763b31b55c4ac65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MytOOXe9OB_sPsWlAbLfag.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mr">图6 </strong>:运行中的16个内核(<em class="oe">使用‘htop’</em>命令)。</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/6386185de0053dd44b72f4b86d0778d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*qhfUvKZCKgW31LXUqfgqfQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mr">图7</strong>:16核计算:耗时55秒。</p></figure><h1 id="4e4c" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">第三个实验:单个GPU</h1><p id="e865" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">从CPU切换到GPU非常容易。只需要知道一个小技巧，这就是CuPy库的用武之地。在第2集[2]中，我们将我们的numpy数组移动到我们的GPU设备中(我们将这个操作称为<em class="mk">数据</em> <em class="mk">传输</em>)。这里我们用参数<code class="fe nb nc nd ne b">cupy.random.RandomState</code>直接在随机状态下指定数组的类型。因此，我们告诉Dask，我们使用cupy数组而不是numpy数组，以确保计算将在GPU上完成(图8)。同样，这是一个“懒惰”的操作，还没有数据被加载到视频存储器中。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/c7a490605f44e1b21269debe80d7a741.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*sH7GhJWkCFKOqMZsOtIpAw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mr">图8 </strong>:分块随机<strong class="bd mr"> cupy </strong>数组的Dask数组。</p></figure><p id="b3ba" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">子集完全相同，只是块的数据类型发生了变化，现在是<em class="mk"> cupy.ndarray </em>而不是之前的<em class="mk"> numpy.ndarray </em>(图9)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/f1b6db94f579b79e4cbb083d720362fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*7nOwJrNKbXnF6gJP2NtXbQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mr">图9 </strong>:数据子集(类型为<strong class="bd mr"> cupy.ndarray </strong>)。</p></figure><p id="55f3" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">对于实际计算，使用第一个实验中的相同调度程序参数(单个CPU)。在一个<strong class="lq ir">单GPU </strong>上，它需要将近<strong class="lq ir"> 12秒</strong>，因此几乎比16个内核快4.6倍。计算出的平均值仍然很好(1.8e-5)(图10)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/4026d1e87da2742270f023959146d24c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*Oglluv4_7QzqHnaiZaQ-pA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mr">图10 </strong>:单个GPU (1x Tesla K80)上的计算:几乎需要12秒。</p></figure><h1 id="6a9f" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">第四个实验:多GPU</h1><p id="6927" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">对于最后这个实验，我们首先必须定义一个支持GPU的集群，这就是Dask CUDA库的用武之地。我们从Dask CUDA库中导入<code class="fe nb nc nd ne b">LocalCUDACluster</code>,并设置参数<code class="fe nb nc nd ne b">CUDA_VISIBLE_DEVICES</code>,这样我们就可以选择特定的GPU。然后，我们为该集群构建一个<strong class="lq ir">分布式客户端</strong>(图11)。总而言之，Dask创建了两个对象:</p><ul class=""><li id="392f" class="ms mt iq lq b lr ml lu mm lx mu mb mv mf mw mj mx my mz na bi translated"><strong class="lq ir">集群</strong>:由8个workers和8个cores组成(都是我们的GPU)。</li><li id="e390" class="ms mt iq lq b lr nf lu ng lx nh mb ni mf nj mj mx my mz na bi translated"><strong class="lq ir">客户端</strong>:通过本地url访问(此处<a class="ae kv" href="http://127.0.0.1:8787/status)" rel="noopener ugc nofollow" target="_blank"><em class="mk">http://127 . 0 . 0 . 1:8787/status</em>)</a>。您可以使用一个非常丰富的仪表板来监控整个过程。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/3ac89b8b672f0c4fee1a6526705e59d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*Ole3FubriG4_ME10Gad29Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mr">图11 </strong>:本地CUDA集群及其DASK分布式客户端。</p></figure><p id="e88e" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">从那里，我们可以像以前一样执行相同的表达式(不需要在这里指定scheduler参数)。最后，<strong class="lq ir"> 8个GPU</strong>上的计算非常快，花费<strong class="lq ir">不到2秒</strong>，因此与单个GPU相比<strong class="lq ir">加速了6.26倍</strong>。计算的平均值也非常接近(2.2e-6)预期值(图12)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/21b5551a616bcfed0dd424102045e57d.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*WmcfNjEx_YI9Z-TpZCmAWw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mr">图12 </strong>:使用全套GPU(<strong class="bd mr">8x</strong>Tesla K80)的计算:仅需2秒。</p></figure><p id="2632" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">图13描述了我们全套GPU的GPU活动。实际上，谷歌云实际上将特斯拉K80的显存分成了两半。这就是为什么我们只有12 GB的可用内存，而不是24 GB。这也意味着我们“只”拥有每个GPU 2496个CUDA核心。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/a9bc964d18ac15a592b27bf614078b4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*P4NP20XMTaFll3Pqryi1Og.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mr">图十三</strong>:特斯拉k80正在摇滚。</p></figure><h1 id="56ca" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><p id="932a" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">通过Dask阵列上的简单数值模拟，我们从使用单个CPU的几乎<strong class="lq ir"> 12分钟</strong>的计算时间，到在8特斯拉K80 GPUs上的几乎<strong class="lq ir"> 2秒</strong>的闪电般速度，因此有了<strong class="lq ir">360倍的加速比</strong>！计算时间的巨大增长并不是以准确性为代价的。这些实验在很大程度上受到了来自Matthew Rocklin的帖子的启发，他是Dask的最初作者，现任Coiled computing的首席执行官。我们希望能够在使用多GPU系统执行更复杂的任务之前，重现简单方法的速度结果，例如我们正在处理的生成模型的快速训练。多GPU计算乍一看似乎令人生畏，但使用正确的工具时，它会变得非常容易。</p><p id="2f0a" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">我们的三部曲到此结束，希望你喜欢，我会很快回来的。</p><h1 id="c1b2" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">感谢</h1><p id="dad2" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我要感谢<a class="om on ep" href="https://medium.com/u/8dd41142f97f?source=post_page-----4bf90170e2ee--------------------------------" rel="noopener" target="_blank">克里斯托夫</a>、<a class="om on ep" href="https://medium.com/u/e77161de2cb4?source=post_page-----4bf90170e2ee--------------------------------" rel="noopener" target="_blank">马特奥</a>、<a class="om on ep" href="https://medium.com/u/4b708f6ba2df?source=post_page-----4bf90170e2ee--------------------------------" rel="noopener" target="_blank">菲利普</a>和<a class="om on ep" href="https://medium.com/u/7227db78307a?source=post_page-----4bf90170e2ee--------------------------------" rel="noopener" target="_blank">佩瑟瓦尔</a>在本研究实现过程中给予的支持，以及他们对本文草稿的反馈。</p><h1 id="1631" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">参考</h1><p id="4b7c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">[1] <a class="ae kv" rel="noopener" target="_blank" href="/speed-cubing-for-machine-learning-a5c6775fff0b"> N. Morizet，“机器学习的速度立方—第1集”，走向数据科学，2020年9月15日。</a><br/>【2】<a class="ae kv" rel="noopener" target="_blank" href="/speed-cubing-for-machine-learning-8d32a40aa474">n . Morizet，《机器学习的速度立方——第二集》，迈向数据科学，2020年11月20日。</a><br/>【3】<a class="ae kv" href="https://dask.org/" rel="noopener ugc nofollow" target="_blank">Dask:Python中并行计算的开源库</a>。<br/>【4】<a class="ae kv" href="https://cupy.dev/" rel="noopener ugc nofollow" target="_blank">CuPy:用NVIDIA CUDA加速的开源阵列库。</a><br/><a class="ae kv" href="https://github.com/rapidsai/dask-cuda" rel="noopener ugc nofollow" target="_blank">【5】Dask CUDA:一个实验性的开源库，帮助多GPU系统中Dask workers的部署和管理。</a><br/>【6】<a class="ae kv" href="https://blog.dask.org/2019/01/03/dask-array-gpus-first-steps" rel="noopener ugc nofollow" target="_blank">m . Rocklin，“GPU Dask数组，第一步把Dask和CuPy扔在一起”，matthewrocklin.com，2019。</a></p><h1 id="96db" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">关于我们</h1><p id="9fa3" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><a class="ae kv" href="https://www.advestis.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir"> Advestis </strong> </a>是一家欧洲合同研究组织(CRO)，对统计学和可解释的机器学习技术有着深刻的理解和实践。Advestis的专长包括复杂系统的建模和时间现象的预测分析。<br/> <em class="mk">领英</em>:<a class="ae kv" href="https://www.linkedin.com/company/advestis/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/company/advestis/</a></p></div></div>    
</body>
</html>