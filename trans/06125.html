<html>
<head>
<title>Almost Free Inductive Embeddings Out-Perform Trained Graph Neural Networks in Graph Classification in a Range of Benchmarks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在一系列基准测试中，几乎自由归纳嵌入在图分类中的表现优于训练过的图神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/almost-free-inductive-embeddings-out-perform-trained-graph-neural-networks-in-graph-classification-651ace368bc1?source=collection_archive---------26-----------------------#2021-06-01">https://towardsdatascience.com/almost-free-inductive-embeddings-out-perform-trained-graph-neural-networks-in-graph-classification-651ace368bc1?source=collection_archive---------26-----------------------#2021-06-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b7d3" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">训练还是不训练——这不是问题<br/>(匿名)</em></h2></div><p id="231d" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">具有随机分配的权重的未训练的图卷积网络[1] (uGCN)由于极低的成本、实现的简单性和相当明显的优雅性，已经成为我在一系列图数据任务中的主要基线编码器。然而，没有人(据我所知)报告过这个简单模型相对于它的姐姐(一个在监督设置下完全成熟(端到端训练)的图卷积网络(CGN))的实际性能基准。于是我照做了。</p><p id="1a81" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">动机:找出uGCN是否产生高质量的表示，可以在归纳设置中的图<strong class="ki ir">上的一系列下游任务中使用，以便训练的模型可以归纳到以前看不到的数据(受最近报道的直推设置结果的启发[2])。</strong></p><p id="03c4" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">结果很有趣。在最坏的情况下，简单模型(uGCN + degree kernel + random forest)与端到端训练的GCN相比，得分为54:90，而更现实的情况导致了毁灭性的93:51，这表明<strong class="ki ir">我们可以几乎免费的嵌入，在图形分类任务中表现优于或接近匹配端到端训练的gcn，而成本只有一小部分</strong>。小模型的训练只花了10分钟，而整个实验持续了4个小时。让我们详细了解一下，看看发生了什么事！</p><p id="3101" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">万一你的阅读偏好是喜欢代码而不是文章，请随意使用附带的<a class="ae lc" href="https://colab.research.google.com/drive/1HjQiL1iTjfxnB8xiAAT2fkNlj_u3kuLL?usp=sharing" rel="noopener ugc nofollow" target="_blank"> colab笔记本</a>进行实验。</p><h1 id="96cf" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated"><strong class="ak">预赛</strong></h1><p id="57c4" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated">许多重要的现实世界数据集以图形或网络的形式出现:社会网络、知识图、蛋白质相互作用网络、万维网等。(仅举几例)[1]。</p><p id="56a2" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">通常写为G=(V，E)的图是一个数学模型，由一组顶点V和一组边E组成——顶点I和j之间的成对连接e(i，j)。图的扩展是一个带标签的属性图，允许将特征向量xi分配给顶点vi(我们也可以将特征分配给边，但这超出了今天实验的范围)。</p><p id="df68" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">图形神经网络[3] (GNN)是一个机器学习模型(一个参数函数，用于调整或从数据中学习参数)，它将一个众所周知的生物启发算法家族扩展到非结构化图形数据领域。依我看，对于GNNs的机制来说，信息传递是最简单的直觉，参考记忆法则“告诉我谁是你的朋友，我会告诉你你是谁”是合理的。图卷积网络(gcn)被它的发明者(<a class="ae lc" href="https://tkipf.github.io/graph-convolutional-networks/" rel="noopener ugc nofollow" target="_blank">https://tkipf.github.io/graph-convolutional-networks/</a>)很好地描述了，我发现更好地讲述这个故事很有挑战性。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi ma"><img src="../Images/3176505752bc90335fb4b69148988b61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GjqB217fVYifXIF9J_FOcA.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">带一阶滤波器的多层GCN。作者图片</p></figure><h1 id="3c24" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated"><strong class="ak">数据</strong></h1><p id="2cbb" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated">让我们对公开可用的数据进行一系列实验。我们将(I)从数据集[4](一组基准数据集)中获取数据，以及(ii)将我们的练习限制在小分子的二元分类(性质预测)上。我们努力的另一个限制是(iii)使用带标号顶点的图。</p><p id="f08a" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">归纳约束留给我们一个广泛用于测试新算法的数据集列表。这些是:艾滋病，BZR，二氧化碳，DHFR，穆塔格和蛋白质。所有这些数据都已经作为Pytorch Geometric [5](一个用于图形深度学习的库)的一部分，有两个版本:原始版本和清除重复版本[6]。这样我们手头就有12个数据集了。</p><h2 id="8dd1" class="mq le iq bd lf mr ms dn lj mt mu dp ln kp mv mw lp kt mx my lr kx mz na lt nb bi translated"><strong class="ak">艾滋病抗病毒筛查数据[7] </strong></h2><p id="71c8" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated">DTP艾滋病抗病毒筛查已经检查了数万种化合物的抗HIV活性证据。可以获得保密协议未涵盖的化合物的筛选结果和化学结构数据。原始数据集包含2000个分子，其清理后的版本留给我们1110个数据点。</p><h2 id="cbef" class="mq le iq bd lf mr ms dn lj mt mu dp ln kp mv mw lp kt mx my lr kx mz na lt nb bi translated"><strong class="ak">苯二氮卓受体(BZR)配体【8】</strong></h2><p id="913e" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated">原始数据集包含405个分子，其清理后的版本留给我们276个数据点。</p><h2 id="4962" class="mq le iq bd lf mr ms dn lj mt mu dp ln kp mv mw lp kt mx my lr kx mz na lt nb bi translated"><strong class="ak">环氧合酶-2 (COX-2)抑制剂【8】</strong></h2><p id="b058" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated">原始数据集包含467个分子，其清理后的版本留给我们237个数据点。</p><h2 id="2ba1" class="mq le iq bd lf mr ms dn lj mt mu dp ln kp mv mw lp kt mx my lr kx mz na lt nb bi translated"><strong class="ak">二氢叶酸还原酶(DHFR)抑制剂【8】</strong></h2><p id="8c9e" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated">原始数据集包含756个分子，其清理后的版本留给我们578个数据点。</p><h2 id="8c50" class="mq le iq bd lf mr ms dn lj mt mu dp ln kp mv mw lp kt mx my lr kx mz na lt nb bi translated"><strong class="ak">穆塔格【9】</strong></h2><p id="1795" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated">MUTAG数据集由188种化合物组成，根据它们对细菌的诱变作用分为两类。它的净化版本留给我们135个结构。</p><h2 id="4907" class="mq le iq bd lf mr ms dn lj mt mu dp ln kp mv mw lp kt mx my lr kx mz na lt nb bi translated"><strong class="ak">蛋白质类【10】</strong></h2><p id="314c" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated">来自蛋白质数据库(PDB)蛋白质文件的蛋白质图——一个酶和非酶的数据集。原始数据集包含1113个分子，其清理后的版本留给我们975个数据点。</p><h1 id="5dbf" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated"><strong class="ak">实验设计</strong></h1><p id="0201" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated">锦标赛就是这样！</p><p id="b33f" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">对于每个数据集，我们运行12轮训练和测试。</p><p id="79fc" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">对于每一轮，我们:</p><p id="31a4" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">我</strong></p><p id="e6d1" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在Pytorch Geometric中进行随机的80/20分割(从随机种子= 42开始，并且对于接下来的每一轮将种子增加1)，使得80%的数据点(图形)被分配到训练集中，而剩余的20%进入测试集；</p><p id="bcc2" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> II </strong></p><p id="2443" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在训练集上训练模型，在测试集上评估<strong class="ki ir">精度</strong>。</p><p id="75db" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">对于微小的模型，这意味着预处理，以生成输入分类器的特征。</p><p id="0dda" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">对于gcn，我们运行200个时期的训练和测试，学习率= 0.01，并报告:</p><p id="a653" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">(A)10个最终时期的平均精度</strong> —一个现实的场景；</p><p id="829a" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir"> (B)在训练过程中达到的最佳精度</strong>(就好像我们保存中间状态以便挑选最佳性能的模型)GCNs的最佳情况(以及我们的小模型的最差情况)；</p><p id="6774" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">三</strong></p><p id="98d7" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">最佳模特得1分；</p><p id="68c7" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">四</strong></p><p id="f735" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">如果出现平局的情况，问题就出在最小的模特身上。</p></div><div class="ab cl nc nd hu ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="ij ik il im in"><p id="842c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">有288个点要奖励:12个数据集* 12轮* 2个场景。</p><h1 id="b9da" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated"><strong class="ak">型号</strong></h1><p id="dfef" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated"><strong class="ki ir">度核(DK) </strong> —节点度(与特定顶点关联的边的数量)的直方图，归一化为给定图中的节点数量(使得每个图的特征向量由具有特定数量连接的节点的分数大小组成——这些总和为1)。</p><pre class="mb mc md me gt nj nk nl nm aw nn bi"><span id="08d9" class="mq le iq nk b gy no np l nq nr">import networkx as nx <br/>import numpy as np  <br/>from scipy.sparse import csgraph </span><span id="43f0" class="mq le iq nk b gy ns np l nq nr"><em class="nt"># g - a NetworkX</em> graph<br/>numNodes = len(g.nodes) <br/>degreeHist = nx.degree_histogram(g) <br/><em class="nt"># normalize</em><br/>degreeKernel = [x/numNodes for x in degreeHist]</span></pre></div><div class="ab cl nc nd hu ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="ij ik il im in"><p id="3c1b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">未训练的图形卷积网络(uGCN) </strong> —一种前馈图形卷积网络，具有为3层随机分配的权重，其间具有ReLU激活。我们将全局平均池应用于输出的64维向量(节点嵌入)，以便获得图形的表示。</p><pre class="mb mc md me gt nj nk nl nm aw nn bi"><span id="a487" class="mq le iq nk b gy no np l nq nr"><em class="nt"># INPUT<br/># g - a NetworkX</em> graph<br/><em class="nt"># X - node features of a graph g (np.array)</em> <br/><em class="nt"># W0, W1, W2 - randomly assigned weights</em></span><span id="4ca9" class="mq le iq nk b gy ns np l nq nr"># PREPROCESSING<br/><em class="nt"># A - adjacency matrix of a graph g</em><br/>A = nx.convert_matrix.to_scipy_sparse_matrix(g)<br/># D - normalized laplacian matrix of a graph g derived from A<br/>D = sparse.csgraph.laplacian(A, normed=True) </span><span id="8286" class="mq le iq nk b gy ns np l nq nr"># GRAPH CONVOLUTIONAL NETWORK - FORWARD PASS<br/><em class="nt"># Layer 0</em> <br/>Xc = D @ X @ W0 <br/><em class="nt"># ReLU</em> <br/>Xc = Xc * (Xc&gt;0) <br/><em class="nt"># concatenation of node features with those aggregated of neighbors</em><br/>Xn = np.hstack((X, Xc)) <br/><em class="nt"># Layer 1</em><br/>Xc = D @ Xn @ W1 <br/><em class="nt"># ReLU</em> <br/>Xc = Xc * (Xc&gt;0) <br/>Xn = np.hstack((Xn, Xc)) <br/><em class="nt"># Layer 2 - node embeddings</em><br/>Xc = D @ Xn @ W2 <br/><em class="nt"># global mean pooling - graph embedding</em> <br/>embedding = Xc.sum(axis=0) / Xc.shape[0]</span></pre></div><div class="ab cl nc nd hu ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="ij ik il im in"><p id="6352" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">DK和uGCN (Mix) </strong>的组合——由DK和uGCN模型获得的图形表示的串联。</p><pre class="mb mc md me gt nj nk nl nm aw nn bi"><span id="f6d4" class="mq le iq nk b gy no np l nq nr">mix = degreeKernel + list(embedding)</span></pre></div><div class="ab cl nc nd hu ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="ij ik il im in"><p id="0ef3" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">具有最大深度17的100棵树的随机森林(RF) </strong>分类器(来自Scikit-learn [11]包)在上面被训练。</p></div><div class="ab cl nc nd hu ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="ij ik il im in"><p id="9c39" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">图卷积网络(CGN) </strong> —一个端到端分类器，由3个卷积层(64维)组成，其间有ReLU激活，一个全局平均池层(直到此刻GCN与uGCN非常匹配)，后面是一个丢弃层和一个线性分类器。我们将把最佳情况场景(B)中的模型称为GCN-B，将现实场景(A)中的模型称为GCN-A。我们将使用Pytorch Geometric的参考实现<a class="ae lc" href="https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing" rel="noopener ugc nofollow" target="_blank">和GCN的</a>，以使比赛尽可能公平。</p></div><div class="ab cl nc nd hu ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="ij ik il im in"><h1 id="fa94" class="ld le iq bd lf lg nu li lj lk nv lm ln jw nw jx lp jz nx ka lr kc ny kd lt lu bi translated"><strong class="ak">结果</strong></h1><p id="fe9c" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated">在简单模型和端到端训练的gcn之间的144轮(12个数据集* 12轮)基准测试之后，总计288点分布如下:</p><h1 id="25d3" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated"><strong class="ak"> 147:141 </strong></h1><p id="09ec" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated">测试集的准确性在不同的分裂之间有所不同，并且存在微小模型支配复杂竞争者的情况。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nz"><img src="../Images/0e45b16badfe16bf6fd0b0691aeb6d47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R1clGHKBP9FobF-ZMqdp2A.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated"><strong class="bd oa">小模特胜出的数据集:</strong>艾滋病、DHFR(A)、穆塔格。图片由作者提供，使用Matplotlib [13]的Seaborn [12]扩展制作</p></figure><p id="feba" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">例如，degree内核采用了AIDS数据集上的所有48个点，证明比端到端训练的GCN高10%以上的准确性。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nz"><img src="../Images/4fc3f827bf43830d3673d04c5b95ab8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wP4EFzDDaPsXz5bK_jyb1g.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated"><strong class="bd oa">gcn大放异彩的数据集:</strong> BZR、COX2和蛋白质。作者图片</p></figure><p id="50b3" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">收集的点数:</strong></p><p id="021d" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">90—GCN-B；</p><p id="fb4e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">71—DK；</p><p id="0378" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">51—GCN—A；</p><p id="2c13" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">21 — uGCN。</p><pre class="mb mc md me gt nj nk nl nm aw nn bi"><span id="c462" class="mq le iq nk b gy no np l nq nr">Clean wins:</span><span id="5401" class="mq le iq nk b gy ns np l nq nr">DK in all versions of AIDS dataset in both scenarios (48 points);<br/>GCN-B (scenario B) has championed in cleaned BZR (12), COX2 (24) and PROTEINS (24) - all versions;</span><span id="f97e" class="mq le iq nk b gy ns np l nq nr">The rest of the points distributed as follows.</span><span id="d0de" class="mq le iq nk b gy ns np l nq nr">-----------------<br/>Dataset: BZR, cleaned: yes<br/>Scenario: A<br/>DK      0<br/>uGCN    3<br/>Mix     1<br/>GCN     8</span><span id="1979" class="mq le iq nk b gy ns np l nq nr">-----------------<br/>Dataset: BZR, cleaned: no<br/>Scenario: A<br/>DK      4<br/>uGCN    1<br/>Mix     4<br/>GCN     3</span><span id="6e92" class="mq le iq nk b gy ns np l nq nr">-----------------<br/>Dataset: BZR, cleaned: no<br/>Scenario: B<br/>DK       1<br/>uGCN     0<br/>Mix      1<br/>GCN     10</span><span id="5b46" class="mq le iq nk b gy ns np l nq nr">-----------------<br/>Dataset: COX2, cleaned: yes<br/>Scenario: A<br/>DK      0<br/>uGCN    3<br/>Mix     1<br/>GCN     8</span><span id="67c9" class="mq le iq nk b gy ns np l nq nr">-----------------<br/>Dataset: COX2, cleaned: no<br/>Scenario: A<br/>DK       0<br/>uGCN     1<br/>Mix      1<br/>GCN     10</span><span id="605b" class="mq le iq nk b gy ns np l nq nr">-----------------<br/>Dataset: DHFR, cleaned: yes<br/>Scenario: A<br/>DK      1<br/>uGCN    1<br/>Mix     4<br/>GCN     6</span><span id="7578" class="mq le iq nk b gy ns np l nq nr">-----------------<br/>Dataset: DHFR, cleaned: yes<br/>Scenario: B<br/>DK      0<br/>uGCN    0<br/>Mix     3<br/>GCN     9</span><span id="7f13" class="mq le iq nk b gy ns np l nq nr">-----------------<br/>Dataset: DHFR, cleaned: no<br/>Scenario: A<br/>DK      2<br/>uGCN    4<br/>Mix     5<br/>GCN     1</span><span id="e750" class="mq le iq nk b gy ns np l nq nr">-----------------<br/>Dataset: DHFR, cleaned: no<br/>Scenario: B<br/>DK      0<br/>uGCN    1<br/>Mix     5<br/>GCN     6</span><span id="2ee6" class="mq le iq nk b gy ns np l nq nr">-----------------<br/>Dataset: MUTAG, cleaned: yes<br/>Scenario: A<br/>DK      2<br/>uGCN    3<br/>Mix     6<br/>GCN     1</span><span id="e82b" class="mq le iq nk b gy ns np l nq nr">-----------------<br/>Dataset: MUTAG, cleaned: yes<br/>Scenario: B<br/>DK      1<br/>uGCN    2<br/>Mix     5<br/>GCN     4</span><span id="b4df" class="mq le iq nk b gy ns np l nq nr">-----------------<br/>Dataset: MUTAG, cleaned: no<br/>Scenario: A<br/>DK      5<br/>uGCN    0<br/>Mix     7<br/>GCN     0</span><span id="94a8" class="mq le iq nk b gy ns np l nq nr">-----------------<br/>Dataset: MUTAG, cleaned: no<br/>Scenario: B<br/>DK      5<br/>uGCN    0<br/>Mix     6<br/>GCN     1</span><span id="2f13" class="mq le iq nk b gy ns np l nq nr">-----------------<br/>Dataset: PROTEINS, cleaned: yes<br/>Scenario: A<br/>DK      2<br/>uGCN    1<br/>Mix     0<br/>GCN     9</span><span id="b9ca" class="mq le iq nk b gy ns np l nq nr">-----------------<br/>Dataset: PROTEINS, cleaned: no<br/>Scenario: A<br/>DK      0<br/>uGCN    1<br/>Mix     6<br/>GCN     5</span><span id="6ab7" class="mq le iq nk b gy ns np l nq nr">-----------------</span></pre><p id="6b40" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">请查看<a class="ae lc" href="https://colab.research.google.com/drive/1HjQiL1iTjfxnB8xiAAT2fkNlj_u3kuLL?usp=sharing" rel="noopener ugc nofollow" target="_blank"> colab笔记本</a>了解详细的性能报告，或者参考<a class="ae lc" href="https://github.com/saffronoff/opendata/blob/master/statisticsDF.csv" rel="noopener ugc nofollow" target="_blank">本回合摘要</a> (csv)或<a class="ae lc" href="https://docs.google.com/spreadsheets/d/1WFszJpioJZPUC2hd6FJzu3vFp6DLGjLcb0DiU1dvmMw/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="ki ir">本谷歌电子表格</strong> </a>。</p><p id="e7d1" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">总体而言，数据集的清理版本和原始版本之间的性能一直存在差异。这提醒了拥有高质量数据对于相当好的基准的价值。毕竟，数据很少，这可能是我们得到如此不稳定结果的原因。好消息是，研究界有解决这一问题的趋势，并且做了大量工作来实现公平的基准测试。</p><h1 id="ceb3" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated"><strong class="ak">结论</strong></h1><p id="2ae5" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated">正如我们所看到的，实验证明了这样一个猜想，即在小分子的图属性预测设置中<strong class="ki ir">，我们可以以很小的成本</strong>获得几乎免费的嵌入，这些嵌入在图分类任务中胜过或接近匹配端到端训练的gcn。这些发现与[2]的结果一致，因为在概念上，标签传播非常类似于图卷积网络中的消息传递。对这种良好性能的解释，也许是植根于两难境地:我们是否应该调整光谱滤波器参数，以便输出嵌入变得线性可分，或者只是选择一个更鲁棒的分类器，就像我们刚才做的那样。</p><p id="c42f" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">各轮之间的表现差异再次提醒我们，每个基准都是不稳定的。值得一提的是免费午餐定理，并指出使用几个模型很可能是一个很好的选择。同样值得注意的是，分割确实会影响性能——对于相同的数据集，相同的模型表现出明显不同的决策质量。这就是为什么当在模型之间进行基准测试时，请确保在相同的数据上进行训练和测试。另外，设置随机种子并不是万能的…</p><p id="aaf7" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">下一步可能是在更大的数据集上进行基准测试。同样值得探索的是不同的问题，例如:链接预测、节点和链接分类、图上的回归等等——图卷积网络(训练过的，没有那么多)是非常有能力的模型。</p><h1 id="c2e1" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated"><strong class="ak">后记</strong></h1><p id="df4b" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated">两年前，在<a class="ae lc" href="https://www.meetup.com/ru-RU/PyData-Lisbon/events/260477711/" rel="noopener ugc nofollow" target="_blank"> PyData-Lisbon Meetup </a>上，我第一次公开谈论uGCN作为一种几乎适用于所有解决方案，将它命名为通过傅立叶空间的皇家宏伟捷径，并在那时组装了第一个图形分类管道，以便向一个渴望启动她的航空航天初创公司的女孩展示图形卷积的力量。这篇文章是一个真实实验(基于私人数据)的副产品，在这个实验中，经过数小时的训练后，我们可以超越微小模型设定的性能。</p><p id="0e91" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">如今，随着图的机器学习成为名人，每周都有新的图神经网络架构出现。然而，对于gnn为什么在实践中是成功的以及它们是否是良好性能的必要条件的理解相对较少[2]。</p><p id="7641" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在您进入图形机器学习的奇妙世界之前，请熟悉一些基础知识。有很大的努力投入到使最新的发现(以及经典方法)免费提供给更广泛的受众。仅举几个值得关注的努力:cs224w <a class="ae lc" href="http://web.stanford.edu/class/cs224w/" rel="noopener ugc nofollow" target="_blank">课程</a>和<a class="ae lc" href="https://www.youtube.com/playlist?list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn" rel="noopener ugc nofollow" target="_blank">讲座</a>、<a class="ae lc" href="https://ogb.stanford.edu/" rel="noopener ugc nofollow" target="_blank">开放图基准</a>【14】，以及最近关于<a class="ae lc" href="https://arxiv.org/abs/2104.13478" rel="noopener ugc nofollow" target="_blank">几何深度学习</a>【15】基础的工作，为尚未开发的新架构提供了一个清晰的框架。还有一点——一定要从简单的基线开始，如核方法或无监督图卷积网络——通常这些微小的模型很出色。</p><p id="e768" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">可持续发展，使用高效的算法。有时候不学就是力量。</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi ob"><img src="../Images/095e822f3b5edf6d9e207151aeb5e29c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BoRJZ1ujzYBD0ZtLQZfVPQ.jpeg"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">2018年8月，在瑞典议会大楼外，格里塔·图恩伯格(Greta Thunberg)开始了一场针对气候的学校罢工。她的标牌上写着，“Skolstrejk fr klim atet”，意思是“学校为气候罢工”。图片由Anders Hellberg提供，根据<a class="ae lc" href="https://en.wikipedia.org/wiki/en:Creative_Commons" rel="noopener ugc nofollow" target="_blank">知识共享</a> <a class="ae lc" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en" rel="noopener ugc nofollow" target="_blank">署名-分享相似4.0国际</a>许可协议授权。</p></figure><h1 id="a855" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">参考</h1><p id="9db7" class="pw-post-body-paragraph kg kh iq ki b kj lv jr kl km lw ju ko kp lx kr ks kt ly kv kw kx lz kz la lb ij bi translated">[1] Kipf &amp; Welling，用图卷积网络进行半监督分类(2017)，国际学习表示会议；<br/> [2]黄等，结合标签传播和简单模型优于图神经网络(2021)，学习表征国际会议；<br/> [3]斯卡塞利等，图神经网络模型(2009)，IEEE神经网络汇刊(第20卷，第1期，2009年1月)；<br/> [4] Morris et al .，TUDataset:用图学习的基准数据集集合(2020)，ICML 2020图表示学习研讨会及以后；<br/>【5】Fey&amp;Lenssen，PyTorch Geometric快速图表示学习(2019)，ICLR关于图和流形上的表示学习研讨会；<br/>【6】Ivanov，Sviridov &amp; Burnaev，理解图数据集中的同构偏差(2019)，arXiv预印本arXiv:1910.12091；<br/>【7】Riesen&amp;Bunke，IAM基于图形的模式识别和机器学习图形数据库库(2008)，载于:da Vitora Lobo，n .等人(编辑。)，SSPR&amp;2008年春季，LNCS，第5342卷，第287–297页；<br/> [8] Sutherland等人，用遗传算法进行样条拟合:开发分类结构-活性关系的方法(2003)，化学杂志。Inf。计算机。Sci。, 43, 1906–1915;<br/>【9】deb Nath等，诱变芳香和杂芳香硝基化合物的构效关系(1991)，医学杂志。化学。34(2):786–797;<br/>【10】Dobson&amp;Doig，在没有比对的情况下区分酶结构与非酶(2003)，J. Mol .生物。, 330(4):771–783;<br/> [11] Pedregosa等人，sci kit-learn:Python中的机器学习(2011)，JMLR 12，第2825–2830页；<br/>【12】was kom，seaborn:统计数据可视化(2021)，开源软件杂志，6(60)，3021；<br/>【13】Hunter，Matplotlib:2D图形环境(2007)，科学计算&amp;工程，第9卷，第3期，第90–95页；<br/> [14]胡等，开放图基准:图上机器学习的数据集(2020)，arXiv预印本arXiv:2005.00687；<br/>【15】布朗斯坦等，几何深度学习:网格、组、图、测地线和量规(2021)，arXiv预印本arXiv:2104.13478。</p></div></div>    
</body>
</html>