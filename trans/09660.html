<html>
<head>
<title>Topic Modeling Analysis for Small Businesses</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向小型企业的主题建模分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/topic-modeling-analysis-for-small-businesses-73ba23474261?source=collection_archive---------29-----------------------#2021-09-08">https://towardsdatascience.com/topic-modeling-analysis-for-small-businesses-73ba23474261?source=collection_archive---------29-----------------------#2021-09-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/2e2a1a3bae1918191fcec2cb8d2cd091.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Q38x9HiS6JqPCU_z"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">Pennslyvania doyles town alto Monte的意大利市场(使用经业主批准的图片)。</p></figure><h1 id="dfe3" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">介绍</h1><p id="1494" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">机器学习正在小企业食品行业发展，并已显示出为提高企业生产率提供了成果。今天的分析源于我的调查的第一部分，包括对位于宾夕法尼亚州费城附近的<a class="ae mb" href="https://altomontes.com/" rel="noopener ugc nofollow" target="_blank">阿尔托蒙特的意大利市场</a>的在线评论。使用自然语言处理帮助这家规模虽小但呈指数级增长的食品行业企业更深入地了解了客户对Altomonte及其运营的看法。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="7ed0" class="kf kg it bd kh ki mj kk kl km mk ko kp kq ml ks kt ku mm kw kx ky mn la lb lc bi translated"><strong class="ak">自然语言处理</strong></h1><p id="e4fe" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">自然语言处理是机器学习的一个领域，旨在揭示文本数据中隐藏的意义和情感。如果你想了解更多，Dan Juurafsky和James H. Martin有一本免费的教科书<a class="ae mb" href="https://web.stanford.edu/~jurafsky/slp3/" rel="noopener ugc nofollow" target="_blank"/>,它很好地深入研究了NLP的理论和过程。在这次分析中主要使用的技术是<a class="ae mb" href="https://dl.acm.org/doi/abs/10.1145/1964858.1964870?casa_token=rnfXx41QP28AAAAA:-IdKIGdLfsum3jzHh9TYmULn3XZx22d3EJ7J_B_sOd9uwZ1nW60R19fABvfFMM67Z0r2MqBLRA" rel="noopener ugc nofollow" target="_blank"> <strong class="lf iu">主题模型分析</strong> </a>。主题建模分析是自然语言处理中的一种无监督的机器学习技术，可以揭示文本语料库的潜在意义。主题建模分析可以用于小型企业的评论，以帮助揭示客户对企业的集体看法和感受，从而使企业更好地塑造其声誉。</p><h1 id="b92f" class="kf kg it bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc bi translated">分析</h1><p id="35a5" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">分析过程中使用的各种软件包列表:</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="4023" class="mx kg it mt b gy my mz l na nb">import pandas as pd<br/>import numpy as np<br/>import nltk<br/>from nltk import FreqDist, PorterStemmer<br/>from nltk.corpus import stopwords<br/>stop_words = stopwords.words('english')<br/>import re<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>from nltk.tokenize import word_tokenize,sent_tokenize<br/>from wordcloud import WordCloud<br/>from gensim import corpora<br/>import gensim<br/>import spacy<br/>from gensim.models.coherencemodel import CoherenceModel<br/>from gensim.models import LdaMulticore<br/>from gensim import models<br/>import pprint<br/>import tqdm</span></pre></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="550d" class="kf kg it bd kh ki mj kk kl km mk ko kp kq ml ks kt ku mm kw kx ky mn la lb lc bi translated">资料组</h1><p id="6e97" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">使用的数据集是一个语料库，其中包含从Yelp、猫途鹰和谷歌评论中收集的关于Altomonte意大利市场的评论。这些评论可以追溯到10年前。有些评论甚至可以追溯到更早以前；然而，我觉得10年后的任何评论都不太适用于Altomonte，因为过去10年该公司的业务增长迅猛。这些评论被清理并分类到一个熊猫数据框中。数据框的列是“月”、“年”、“回顾”、“评级”和“平台”。</p><figure class="mo mp mq mr gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nc"><img src="../Images/bdc72addc3ad06fc963d777a4cd54f05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YttE_GvFNX1CYpPfGZy4sA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图:数据帧中前5个条目的示例。</p></figure><p id="0732" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated"><strong class="lf iu">数据集统计</strong></p><p id="183a" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">在深入主题建模分析之前，提取了关于数据集的各种统计数据。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="0bee" class="mx kg it mt b gy my mz l na nb">print("Average Rating for All Online Reviews :" ,df['Rating'].mean())</span></pre><p id="8f9a" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">所有评论的平均评分为<strong class="lf iu"> 4.23 </strong>分(满分5分)。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="8bd3" class="mx kg it mt b gy my mz l na nb">print("Number of each Rating for all of the reviews")<br/>df['Rating'].value_counts()</span></pre><p id="0e5d" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">按评级分列的审查细目如下:</p><figure class="mo mp mq mr gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ni"><img src="../Images/3d51c8e25178e3e3986585e3be9eb212.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*-6-qpIhqwXA1e18i0KGAgw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图:按评级分列的评论数量</p></figure><figure class="mo mp mq mr gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nj"><img src="../Images/6a889233ccaac24932621a651287aea4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZFUuc4xM76ocrFcG7tcB9Q.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图:评级在全部语料库中所占的百分比</p></figure><p id="9e8d" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated"><strong class="lf iu">词频</strong></p><p id="014f" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">提取单词的频率，看看是否可以从语料库中最频繁出现的单词中获得任何意义。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="7521" class="mx kg it mt b gy my mz l na nb"># function to plot most frequent terms<br/>def frequent_words(x, terms = 20):<br/>    totalwords = ' '.join([text for text in x])<br/>    totalwords = totalwords.split()</span><span id="88ff" class="mx kg it mt b gy nk mz l na nb">fdist = FreqDist(allwords)<br/>    words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})</span><span id="ef3e" class="mx kg it mt b gy nk mz l na nb"># selecting top 20 most frequent words<br/>    d = words_df.nlargest(columns="count", n = terms) <br/>    plt.figure(figsize=(20,5))<br/>    ax = sns.barplot(data=d, x= "word", y = "count")<br/>    ax.set(ylabel = 'Count')<br/>    plt.show()</span></pre><p id="34f1" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">首先，创建一个函数，找出20个最常用的单词，并将它们的频率绘制成条形图。然后，删除所有不需要的符号、数字和字符。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="588d" class="mx kg it mt b gy my mz l na nb"># remove unwanted characters, numbers and symbols<br/>df['Review'] = df['Review'].str.replace("[^a-zA-Z#]", " ")</span></pre><p id="772e" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">最后，从数据集中删除停用词，并对整个数据集进行小写规范化。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="f4ee" class="mx kg it mt b gy my mz l na nb">def remove_stopwords(onl_rev):<br/>    new_review = " ".join([i for i in onl_rev if i not in stop_words])<br/>    return new_review</span><span id="698f" class="mx kg it mt b gy nk mz l na nb"># remove short words (length &lt; 3)<br/>df['Review'] = df['Review'].apply(lambda x: ' '.join([w for w in x.split() if len(w)&gt;2]))</span><span id="d175" class="mx kg it mt b gy nk mz l na nb"># remove stopwords from the text<br/>Reviews = [remove_stopwords(r.split()) for r in df['Review']]</span><span id="6305" class="mx kg it mt b gy nk mz l na nb"># make entire text lowercase<br/>Reviews = [r.lower() for r in Reviews]</span></pre><p id="2ee9" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated"><strong class="lf iu">词汇化</strong></p><p id="dcfa" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">在评论被清理之后，数据集被词条化。<a class="ae mb" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lf iu">词汇化</strong> </a> <strong class="lf iu"> </strong>就是把一个词分解到它的基础的过程。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="ac70" class="mx kg it mt b gy my mz l na nb">nlp =spacy.load('en_core_web_sm',disable=['parser','ner'])<br/>def lemmatization(texts, tags=['NOUN', 'ADJ']): # filter noun and adjective<br/>        output = []<br/>        for sent in texts:<br/>                doc = nlp(" ".join(sent)) <br/>                output.append([token.lemma_ for token in doc if token.pos_ in tags])<br/>        return output</span></pre><p id="01eb" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">然后将该函数应用于数据集。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="a962" class="mx kg it mt b gy my mz l na nb">Lem_reviews = lemmatization(tokenized_Reviews)<br/>print(Lem_reviews[1])</span></pre><figure class="mo mp mq mr gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nl"><img src="../Images/b26e569e54845db0c7d52723dd734434.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oLTBWp1N25v7z6PgXGfK_w.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图:词汇化函数的输出</p></figure><p id="03fc" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated"><strong class="lf iu">标记化</strong></p><p id="4fa6" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">记号化是将语料库和句子分解成单独的“记号”的过程这里，我们想把句子分开，这样我们就可以单独检查语料库中的每个单词。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="d52f" class="mx kg it mt b gy my mz l na nb">#Tokenization<br/>tokenized_Reviews = pd.Series(Reviews).apply(lambda x: x.split())<br/>print(tokenized_Reviews[1])</span></pre><figure class="mo mp mq mr gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nm"><img src="../Images/d3403d3f4a06e1d92c936c9eea8f17e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SlylJrkz3fG645BVyTK5yA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图:Altomonte评论数据集的符号化输出示例</p></figure><p id="b93b" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated"><strong class="lf iu">最终清洁</strong></p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="498a" class="mx kg it mt b gy my mz l na nb">reviews_cleaned = []<br/>for i in range(len(Lem_reviews)):<br/>    reviews_cleaned.append(' '.join(Lem_reviews[i]))</span><span id="5c26" class="mx kg it mt b gy nk mz l na nb">df['Reviews'] = reviews_cleaned</span><span id="d388" class="mx kg it mt b gy nk mz l na nb">frequent_words(df['Reviews'], 20)</span></pre><p id="153f" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">对数据集进行最后一次清理，并绘制词频。</p><figure class="mo mp mq mr gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/28796a18ea79b7db5e5a579c994e239b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lwEoYphpB88RN8Ry893Nog.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图:20个最常见的单词</p></figure><p id="369c" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">此外，一个单词云是由最常用的单词组成的</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="ef3f" class="mx kg it mt b gy my mz l na nb">full_text = ' '.join(df['Review'])<br/>cloud_no_stopword = WordCloud(background_color='white', stopwords=stop_words).generate(full_text)<br/>plt.imshow(cloud_no_stopword, interpolation='bilinear')<br/>plt.axis('off')<br/>plt.show()</span></pre><figure class="mo mp mq mr gt ju gh gi paragraph-image"><div class="gh gi no"><img src="../Images/4a66297fe62453a0ca43a9b0fae5ed90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*i3rV54AqADnb6ejxUTZfVA.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图:最常用的20个单词</p></figure><p id="4eab" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">词频表中出现频率最高的五个词是<strong class="lf iu">食物、意大利菜、好、棒极了、</strong>和<strong class="lf iu">三明治。</strong>从词频中，我们可以获得一些洞察力，并得出结论:顾客认为<strong class="lf iu"> Altomonte的意大利市场是一个不错的，甚至是很棒的意大利市场，供应各种三明治</strong>(在费城，我们称之为三明治三明治！强烈推荐顺道买一个！).</p><p id="9abb" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">虽然词频可以为客户在评论企业时使用的词提供很好的洞察力，但将词频与主题建模分析相结合可以帮助创建客户对企业的真实感受和观点的具体结论。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="9367" class="kf kg it bd kh ki mj kk kl km mk ko kp kq ml ks kt ku mm kw kx ky mn la lb lc bi translated">主题建模分析</h1><p id="0706" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">对于主题建模分析，我使用了Genism Python包中的<a class="ae mb" href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" rel="noopener ugc nofollow" target="_blank">线性狄利克雷分配模型</a>。LDA模型试图揭示评论集的潜在主题，这些主题在顶级分析中可能不明显。</p><p id="2e80" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">首先，创建一个词条化评论的字典。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="cd2b" class="mx kg it mt b gy my mz l na nb">overall_dictionary = corpora.Dictionary(Lem_reviews)</span><span id="f1df" class="mx kg it mt b gy nk mz l na nb">#Converting reviews into a Document Term Matrix<br/>overall_doctermtx = [overall_dictionary.doc2bow(review) for review in Lem_reviews]</span></pre><p id="dd4a" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">决定你要代表多少个话题的语料库，取决于话题的<strong class="lf iu">连贯性评分</strong>。一个<a class="ae mb" rel="noopener" target="_blank" href="/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0#:~:text=But%20before%20that%E2%80%A6-,What%20is%20topic%20coherence%3F,are%20artifacts%20of%20statistical%20inference.">连贯性分数</a>是主题的质量以及当它们被组合在一起时的相关程度。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="f829" class="mx kg it mt b gy my mz l na nb">def compute_c_values(dictionary, corpus, texts, limit, start=2, step=1):<br/>    """<br/>    Compute c_v coherence for various number of topics</span><span id="b796" class="mx kg it mt b gy nk mz l na nb">Parameters:<br/>    ----------<br/>    dictionary : Gensim dictionary<br/>    corpus : Gensim corpus<br/>    texts : List of input texts<br/>    limit : Max num of topics</span><span id="1a59" class="mx kg it mt b gy nk mz l na nb">Returns:<br/>    -------<br/>    model_list : List of LDA topic models<br/>    coherence_values : Coherence values corresponding to the LDA model with respective number of topics<br/>    """<br/>    coherence_values = []<br/>    model_list = []<br/>    for num_topics in range(start, limit, step):<br/>        model=LDA(corpus=corpus, id2word=dictionary, num_topics=num_topics,)<br/>        model_list.append(model)<br/>        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')<br/>        coherence_values.append(coherencemodel.get_coherence())</span><span id="01fd" class="mx kg it mt b gy nk mz l na nb">return model_list, coherence_values</span></pre><figure class="mo mp mq mr gt ju gh gi paragraph-image"><div class="gh gi np"><img src="../Images/0775233db602bcb8f145cb06db0ea71d.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*e_9I02-LNMfAsbX9KS0UXA.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图:前10个一致性分数</p></figure><p id="e195" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">上面的函数将计算语料库的一致性分数。对于这个语料库，<strong class="lf iu"> 7个主题</strong>被观察到具有最高的连贯性分数. 400。然后使用7个主题进行主题模型分析，以提取数据集中的潜在主题。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="1887" class="mx kg it mt b gy my mz l na nb">LDA = gensim.models.ldamodel.LdaModel<br/>LDA_overall_Model = LDA(corpus=overall_doctermtx, id2word=overall_dictionary, num_topics=7)<br/>LDA_overall_Model.print_topics( num_topics=7,num_words=5)</span></pre><p id="6b8c" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">7个主题中的每一个都提取了5个最重要的单词。如下所示，LDA模型对单词的重要性进行了分级评分。</p><figure class="mo mp mq mr gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nq"><img src="../Images/fa272f089239c0719a527be730b09d9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mcA4Wtf8kC1jimxO_YU8mQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图:阿洛蒙特在线评论的潜在话题</p></figure><p id="2495" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">现在，我们可以将代表Altomonte在线评论数据集的7个主题归为一类。这些主题是(按以上顺序排列):</p><ol class=""><li id="ad3f" class="nr ns it lf b lg nd lk ne lo nt ls nu lw nv ma nw nx ny nz bi translated">美味的意大利披萨</li><li id="71e9" class="nr ns it lf b lg oa lk ob lo oc ls od lw oe ma nw nx ny nz bi translated">各种新鲜食物</li><li id="53ef" class="nr ns it lf b lg oa lk ob lo oc ls od lw oe ma nw nx ny nz bi translated">多种三明治选择</li><li id="7dab" class="nr ns it lf b lg oa lk ob lo oc ls od lw oe ma nw nx ny nz bi translated">各式各样的意大利食物</li><li id="e731" class="nr ns it lf b lg oa lk ob lo oc ls od lw oe ma nw nx ny nz bi translated">意大利商品/美食/等的好去处。</li><li id="0802" class="nr ns it lf b lg oa lk ob lo oc ls od lw oe ma nw nx ny nz bi translated">美味的三明治</li><li id="d86f" class="nr ns it lf b lg oa lk ob lo oc ls od lw oe ma nw nx ny nz bi translated">高品质的意大利食物</li></ol><p id="7965" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated">我们做到了！这些话题有助于解释顾客对Altomonte意大利市场的看法！阿尔托蒙特可以被称为一个独特的食品店，有各种各样的比萨饼、三明治和食物。无论您是去商店购买食材在家制作食谱，还是在室内热吧、三明治柜台或披萨柜台随便吃点东西，您都会非常享受您的Alomonte意大利市场之旅并享受美食！这个话题很有意义，因为Altomonte's除了新鲜制作的意大利食品外，还提供各种其他产品。最近，R&amp;D部门不知疲倦地在商店里扩展产品线。这些评论的潜在含义表明，客户已经注意到了这种业务扩张，因此Altomonte的领导团队应该继续扩大其产品线。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="0506" class="kf kg it bd kh ki mj kk kl km mk ko kp kq ml ks kt ku mm kw kx ky mn la lb lc bi translated"><strong class="ak">结论</strong></h1><p id="1ca5" class="pw-post-body-paragraph ld le it lf b lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma im bi translated">主题建模分析用于表明食品行业的小企业可以更深入地了解客户对他们提供的商品和服务的看法。对Altomonte's来说，顾客对该公司提供的食物、比萨饼、三明治和独特的选择有一种渴望。此外，企业主不断努力扩大商店中商品和服务的种类，这一点并没有被顾客所忽视，而且正在引起消费者的注意。这一知识有助于Altomonte's继续开发和投资用于增加商店产品和顾客体验的流程，同时继续为大费城地区的人们服务。感谢您的阅读！</p><p id="03d6" class="pw-post-body-paragraph ld le it lf b lg nd li lj lk ne lm ln lo nf lq lr ls ng lu lv lw nh ly lz ma im bi translated"><strong class="lf iu">来源</strong></p><ol class=""><li id="4816" class="nr ns it lf b lg nd lk ne lo nt ls nu lw nv ma nw nx ny nz bi translated">Gé ron，A.: <em class="of">用Scikit-Learn和TensorFlow实践机器学习:构建智能系统的概念、工具和技术</em>。加利福尼亚州塞瓦斯托波尔奥莱利媒体公司(2017年)。</li><li id="b7d4" class="nr ns it lf b lg oa lk ob lo oc ls od lw oe ma nw nx ny nz bi translated">瓦西里耶夫尤利。<em class="of">用Python和Spacy进行自然语言处理:实用介绍</em>。旧金山:不上浆，2020。打印。</li><li id="e3c6" class="nr ns it lf b lg oa lk ob lo oc ls od lw oe ma nw nx ny nz bi translated">图片的使用得到了Altomonte的意大利市场公司的批准。</li><li id="6437" class="nr ns it lf b lg oa lk ob lo oc ls od lw oe ma nw nx ny nz bi translated"><a class="ae mb" href="https://www.analyticsvidhya.com/blog/2018/10/mining-online-reviews-topic-modeling-lda/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2018/10/mining-online-reviews-topic-modeling-LDA/</a></li><li id="2bb7" class="nr ns it lf b lg oa lk ob lo oc ls od lw oe ma nw nx ny nz bi translated"><a class="ae mb" href="https://realpython.com/sentiment-analysis-python/" rel="noopener ugc nofollow" target="_blank">https://realpython.com/sentiment-analysis-python/</a></li><li id="d2f3" class="nr ns it lf b lg oa lk ob lo oc ls od lw oe ma nw nx ny nz bi translated"><a class="ae mb" href="https://neptune.ai/blog/pyldavis-topic-modelling-exploration-tool-that-every-nlp-data-scientist-should-know" rel="noopener ugc nofollow" target="_blank">https://Neptune . ai/blog/pyl Davis-topic-modeling-exploration-tool-that-every-NLP-data-scientist-should-know</a></li><li id="d3a5" class="nr ns it lf b lg oa lk ob lo oc ls od lw oe ma nw nx ny nz bi translated"><a class="ae mb" rel="noopener" target="_blank" href="/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0">https://towards data science . com/evaluate-topic-model-in-python-latent-Dirichlet-allocation-LDA-7d 57484 bb5d 0</a></li><li id="6bbc" class="nr ns it lf b lg oa lk ob lo oc ls od lw oe ma nw nx ny nz bi translated"><a class="ae mb" href="https://iq.opengenus.org/topic-modelling-techniques/#:~:text=Topic%20modeling%20can%20be%20used%20in%20graph%20based,time%20and%20helps%20students%20get%20their%20results%20quickly" rel="noopener ugc nofollow" target="_blank">https://IQ . open genus . org/Topic-modeling-techniques/#:~:text = Topic % 20 modeling % 20 can % 20 be % 20 used % 20 in % 20 graph % 20 based，time % 20 and % 20 helps % 20 students % 20 get % 20 their % 20 results % 20 fast</a>。</li></ol></div></div>    
</body>
</html>