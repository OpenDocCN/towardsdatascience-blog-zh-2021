<html>
<head>
<title>Simple 3D MRI classification with PyTorch Lightning, MONAI models, and Rising augmentation ranked bronze on the Kaggle leaderboard</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch Lightning、MONAI 模型和 Rising augmentation 的简单 3D MRI 分类在 Kaggle 排行榜上排名铜牌</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/simple-3d-mri-classification-ranked-bronze-on-kaggle-87edfdef018a?source=collection_archive---------11-----------------------#2021-10-27">https://towardsdatascience.com/simple-3d-mri-classification-ranked-bronze-on-kaggle-87edfdef018a?source=collection_archive---------11-----------------------#2021-10-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/19581fd21eb23ea0e015f8e516d74ac3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u03JSFFqg5ysrk8JxEm5eQ.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">插图照片由<a class="ae jd" href="https://www.pexels.com/@shvetsa?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">安娜·施韦茨</a>从<a class="ae jd" href="https://www.pexels.com/photo/person-holding-black-and-white-wall-decor-4226219/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">派克斯</a>拍摄</p></figure><div class=""/><div class=""><h2 id="b92a" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">使用 MONAI 模型和 MedicalNet 预训练权重在 3D MRI 扫描上解决图像分类任务(脑瘤识别)，通过 Rising augmentation 和 Pytorch Lightning 训练获得分组，在 Kaggle 排行榜上获得铜牌基线。</h2></div><p id="2fa1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这篇文章介绍了我们提交给最近的 Kaggle 竞赛:<a class="ae jd" href="https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification" rel="noopener ugc nofollow" target="_blank">RSNA-米卡脑肿瘤放射基因组分类</a>，旨在从 3D MRI 扫描中检测脑肿瘤。我简单描述一下比赛，提供数据。后来，我设计了一个简单的培训工作流程，它建立在几个成熟的框架之上，以产生一个健壮的<a class="ae jd" href="https://www.kaggle.com/jirkaborovec/brain-tumor-classif-lightning-monai-resnet3d" rel="noopener ugc nofollow" target="_blank">基线解决方案</a>。</p><blockquote class="lr ls lt"><p id="9f00" class="kv kw lu kx b ky kz kh la lb lc kk ld lv lf lg lh lw lj lk ll lx ln lo lp lq ij bi translated">尽管公共排行榜得分较低，但该基线在私人排行榜上获得了铜牌！我的观点是“简单比复杂好”,过多地关注公共排行榜是不明智的。</p></blockquote><h1 id="792e" class="ly lz jg bd ma mb mc md me mf mg mh mi km mj kn mk kp ml kq mm ks mn kt mo mp bi translated">竞争概述</h1><p id="bf85" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">RSNA-密歇根大学脑肿瘤放射基因组分类竞赛解决了一个基本的医学筛查挑战——检测大脑中的恶性肿瘤。这是一种威胁生命的疾病，中位生存期不到一年。竞赛发起人声称，肿瘤中存在一种称为 MGMT 启动子甲基化的特定遗传序列，可以用作预后因素和对化疗反应性的强预测因子。挑战在于从给定的 MRI ( <a class="ae jd" href="https://en.wikipedia.org/wiki/Magnetic_resonance_imaging" rel="noopener ugc nofollow" target="_blank">磁共振成像</a>)扫描及其结构参数化中预测每个病例的 MGMT 值。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/51e79aa01d342694dff4fd600e045fdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*hVfntCbjUuJNVbrRzjOI9Q.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">三轴切面，累积投影在完整 MRI 扫描的下方。</p></figure><p id="f364" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">MRI 是一种用于放射学的非侵入性医学成像技术，用于获取活体组织中解剖和生理过程的图片。MRI 扫描仪依靠固体磁场来测量磁场梯度和无线电波，以产生人体或选定器官的人类可解读图像。</p><p id="fa96" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">简单介绍一下竞赛的组织者和动机:北美放射学会(RSNA)与医学图像计算和计算机辅助介入学会(MICCAI)联手改进诊断。如果成功，你将帮助脑癌患者接受侵入性更小的诊断和治疗。</p><p id="12b1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的投稿 Kaggle 笔记本是下面的<a class="ae jd" href="https://www.kaggle.com/jirkaborovec/brain-tumor-classif-lightning-monai-resnet3d" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jh"> 🧠Brain 肿瘤 Classif。~ lightning⚡monai-resnet3d</strong>T3。</a></p><div class="ip iq gp gr ir na"><a href="https://www.kaggle.com/jirkaborovec/brain-tumor-classif-lightning-monai-resnet3d" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd jh gy z fp nf fr fs ng fu fw jf bi translated">🧠Brain 肿瘤分类。~ Lightning⚡MONAI-ResNet3D</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">使用 Kaggle 笔记本探索和运行机器学习代码|使用来自[私有数据源]的数据</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">www.kaggle.com</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no ix na"/></div></div></a></div><p id="39e2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> <em class="lu">随意分叉，进一步延伸！</em> </strong></p><h1 id="d9b7" class="ly lz jg bd ma mb mc md me mf mg mh mi km mj kn mk kp ml kq mm ks mn kt mo mp bi translated">探索性数据分析</h1><p id="a839" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">训练数据集包括 585 个病例(患者研究)。每个独立的病例都有一个由五位数标识的专用文件夹，其中每个病例文件夹包含四个对应于结构多参数 MRI (mpMRI)的子文件夹。特定的 MRI 扫描以<a class="ae jd" href="https://en.wikipedia.org/wiki/DICOM" rel="noopener ugc nofollow" target="_blank"> DICOM 格式</a>保存。</p><p id="f264" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">数据集中包含的<em class="lu"> mpMRI </em>扫描有:</p><ul class=""><li id="354f" class="np nq jg kx b ky kz lb lc le nr li ns lm nt lq nu nv nw nx bi translated"><strong class="kx jh"> T1w </strong> : T1 加权预对比</li><li id="a183" class="np nq jg kx b ky ny lb nz le oa li ob lm oc lq nu nv nw nx bi translated"><strong class="kx jh"> T1Gd </strong> : T1 加权后对比</li><li id="65bd" class="np nq jg kx b ky ny lb nz le oa li ob lm oc lq nu nv nw nx bi translated"><strong class="kx jh"> T2w </strong> : T2 加权</li><li id="8a93" class="np nq jg kx b ky ny lb nz le oa li ob lm oc lq nu nv nw nx bi translated"><strong class="kx jh"> FLAIR </strong>:流体衰减反转恢复</li></ul><p id="7e02" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">简而言之:T1 加权更好地描绘了解剖，T2 加权自然地显示了病理。</p><blockquote class="lr ls lt"><p id="23ec" class="kv kw lu kx b ky kz kh la lb lc kk ld lv lf lg lh lw lj lk ll lx ln lo lp lq ij bi translated"><a class="ae jd" href="https://radiopaedia.org/articles/fluid-attenuated-inversion-recovery" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jh">流体衰减反转恢复(FLAIR) </strong> </a>是一种特殊的反转恢复序列，反转时间长。这将从生成的图像中去除脑脊液信号。FLAIR 图像上的脑组织看起来类似于 T2 加权图像，灰质比白质亮，但脑脊液是暗的而不是亮的。<br/> <strong class="kx jh">物理学:</strong>为了消除来自流体的信号，调节 FLAIR 脉冲序列的反转时间，使得在平衡状态下没有流体的净横向磁化。<br/> <strong class="kx jh">临床应用:</strong>FLAIR 序列是几乎所有脑部成像协议的一部分，尤其适用于检测大脑半球外围和靠近脑脊液的脑室周围区域的细微变化。</p></blockquote><h2 id="e960" class="od lz jg bd ma oe of dn me og oh dp mi le oi oj mk li ok ol mm lm om on mo oo bi translated">浏览注释</h2><p id="48fc" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">不管 mpMRI 如何，每个病例的注释都是二元分类，MGMT 为 0 或 1。在训练数据集中，正负 MGMT 观测值分布均衡，如下图所示。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi op"><img src="../Images/5090ad556f4cec5e9a211efb9c2f2bbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:492/format:webp/1*LCsKEEA5GpMDhHWsIzrrBA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">二元事例间的标号分布。</p></figure><h2 id="a70e" class="od lz jg bd ma oe of dn me og oh dp mi le oi oj mk li ok ol mm lm om on mo oo bi translated">一维稀疏扫描</h2><p id="065c" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">与任何真实数据集一样，并非所有扫描都具有相同的质量。我们观察到输入扫描尺寸的差异，在一维上从 512 到 52 个像素不等。与相同扫描中的其他 X 和 Y 轴相比，高稀疏性通常出现在 Z 轴中。</p><p id="c8df" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于大多数深度学习模型依赖于固定大小的输入，我们有两种选择来处理扫描:<br/> 1。将所有扫描向下采样至最低分辨率或<br/> 2。将所有扫描插入(上/下采样，取决于原始尺寸和与目标尺寸的比率)到一个共同的尺寸。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/a2969669a60d9a4e9fd99a3a53196f49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*SuyVP9PiiEapW8aJ-8f4hQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">累积投影低于 MRI 扫描的三轴切面在 Z 维稀疏。</p></figure><p id="f947" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于第一个选项，我们将丢失大量有价值的信息，对训练好的模型产生负面影响。所以我们决定把所有的扫描都插值成一个标准尺寸。虽然插值可能会在降级的扫描中引入一些噪声，但它会在其他地方保留完整的信息。</p><h1 id="5c9b" class="ly lz jg bd ma mb mc md me mf mg mh mi km mj kn mk kp ml kq mm ks mn kt mo mp bi translated">结构</h1><p id="7cd5" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">我们使用 PyTorch 生态系统中的几个框架来解决深度学习过程的每个阶段:<br/> 1。将数据处理封装到由<a class="ae jd" href="https://www.pytorchlightning.ai/" rel="noopener ugc nofollow" target="_blank"> Pytorch Lightning </a> <br/> 2 提供的<code class="fe oq or os ot b"><a class="ae jd" href="https://pytorch-lightning.readthedocs.io/en/latest/extensions/datamodules.html" rel="noopener ugc nofollow" target="_blank">DataModule</a></code>中。通过<a class="ae jd" href="https://monai.io/" rel="noopener ugc nofollow" target="_blank">MONAI</a>T10】3 创建卷积模型。从<a class="ae jd" href="https://github.com/Tencent/MedicalNet" rel="noopener ugc nofollow" target="_blank">医疗网</a> <br/> 4 加载预训练的重量。应用由<a class="ae jd" href="https://rising.readthedocs.io/en/latest" rel="noopener ugc nofollow" target="_blank">上升</a> <br/> 5 提供的基本 3D 增强。利用<a class="ae jd" href="https://www.pytorchlightning.ai/" rel="noopener ugc nofollow" target="_blank"> Pytorch </a> Lightning 的最佳实践无缝培训模型</p><blockquote class="lr ls lt"><p id="f3b0" class="kv kw lu kx b ky kz kh la lb lc kk ld lv lf lg lh lw lj lk ll lx ln lo lp lq ij bi translated">所有代码快照和可视化都是这个示例库的一部分，可以作为<code class="fe oq or os ot b">pip install <a class="ae jd" href="https://borda.github.io/kaggle_vol-3D-classify" rel="noopener ugc nofollow" target="_blank">https://borda.github.io/kaggle_vol-3D-classify</a>/archive/refs/heads/main.zip</code>安装。欢迎任何好的贡献！</p></blockquote><h2 id="a9d5" class="od lz jg bd ma oe of dn me og oh dp mi le oi oj mk li ok ol mm lm om on mo oo bi translated">Pytorch 闪电</h2><figure class="mw mx my mz gt is gh gi paragraph-image"><a href="https://pytorch-lightning.readthedocs.io/en/stable/"><div class="gh gi ou"><img src="../Images/8d6ade20f3b1be90074a073bd752b45a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Niy9e22AcTnQmHC9.png"/></div></a></figure><p id="4184" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae jd" href="https://www.pytorchlightning.ai/" rel="noopener ugc nofollow" target="_blank"> PyTorch Lightning </a>是一个用于高性能人工智能研究的轻量级 PyTorch 包装器，允许你缩放你的模型，而不是样板文件。它还分离了数据、模型和训练逻辑，使研究人员能够专注于这些阶段中的每一个(此外，这种分离的代码更容易与您的同事共享)。此外，训练完全由 Lightning <code class="fe oq or os ot b"><a class="ae jd" href="https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html" rel="noopener ugc nofollow" target="_blank">Trainer</a></code>和自动监控一起处理。</p><h2 id="d560" class="od lz jg bd ma oe of dn me og oh dp mi le oi oj mk li ok ol mm lm om on mo oo bi translated">莫奈模型</h2><figure class="mw mx my mz gt is gh gi paragraph-image"><a href="https://monai.io/"><div class="gh gi ov"><img src="../Images/b534651a1e9545bb3f2e0e8826ae909b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*06E0VXAoQZW2PewE.png"/></div></a></figure><p id="b091" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae jd" href="https://monai.io/" rel="noopener ugc nofollow" target="_blank"> MONAI </a>是一个基于 PyTorch 构建的开源医疗框架，专注于医疗保健成像领域的深度学习。我们选择它作为一个丰富的模型集合，还包括这个任务所需的 3D 模型。在大多数情况下，他们还提供预先训练的重量，以改善你的训练的最初表现。</p><h2 id="85e1" class="od lz jg bd ma oe of dn me og oh dp mi le oi oj mk li ok ol mm lm om on mo oo bi translated">来自 MedicalNet 的预训练重量</h2><figure class="mw mx my mz gt is gh gi paragraph-image"><a href="https://github.com/Tencent/MedicalNet"><div class="gh gi ow"><img src="../Images/9f8f2baacde7e36996f258fda779d0ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IeqeiKFwddAowVmv.png"/></div></a></figure><p id="bfb1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">深度学习的性能受到训练数据量的显著影响。<a class="ae jd" href="https://github.com/Tencent/MedicalNet" rel="noopener ugc nofollow" target="_blank"> MedicalNet </a>项目聚合了具有不同模态、目标器官和病理的数据集，以促进知识转移。基于该数据集，提供了一系列 3D-ResNet 预训练模型。特别是，作者参考了<a class="ae jd" href="https://arxiv.org/abs/1904.00625" rel="noopener ugc nofollow" target="_blank"> Med3D:用于 3D 医学图像分析的迁移学习</a>。</p><h2 id="c597" class="od lz jg bd ma oe of dn me og oh dp mi le oi oj mk li ok ol mm lm om on mo oo bi translated">上升增强</h2><figure class="mw mx my mz gt is gh gi paragraph-image"><a href="https://rising.readthedocs.io/en/stable/"><div class="gh gi ox"><img src="../Images/53dbbb510e4f9f5dc49376a1b3ee9e6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qwaQElclCyS7FE3y_s1_Og.png"/></div></a></figure><p id="0b6d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae jd" href="https://rising.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> Rising </a>是一个高性能的数据加载和增强库，用于 PyTorch 编写的 2D 和 3D 数据。它专注于提供与 PyTorch 生态系统的无缝集成，而不牺牲可用性或特性。一个很好的部分是，增强功能集成在<code class="fe oq or os ot b">DataLoader</code>中，可以在 GPU 中应用，以显著提高训练，因为任何更高维度的变换/插值都需要计算。</p><h1 id="b75c" class="ly lz jg bd ma mb mc md me mf mg mh mi km mj kn mk kp ml kq mm ks mn kt mo mp bi translated">数据准备和扩充</h1><p id="6d0a" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">体积数据以<a class="ae jd" href="https://en.wikipedia.org/wiki/DICOM" rel="noopener ugc nofollow" target="_blank"> DICOM 格式</a>的标准 2D 图像的有序序列提供。DICOM(医学数字成像和通信)是一种典型的医学图像格式，通常用于存储和传输医学图像，实现医学成像设备的集成。为了加载这些图像，我们使用了<code class="fe oq or os ot b"><a class="ae jd" href="https://pypi.org/project/pydicom/" rel="noopener ugc nofollow" target="_blank">pydicom</a></code> Python 包:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><a href="https://github.com/Borda/kaggle_brain-tumor-3D/blob/4c5898b2ef18783eb47810084dd97941747068f3/kaggle_brain3d/utils.py#L21-L29"><div class="gh gi oy"><img src="../Images/37e94d9f657b713ec477b43c074f4570.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*90LczWRZW049As-htOfXZg.png"/></div></a><p class="iz ja gj gh gi jb jc bd b be z dk translated">用于加载 DICOM 图像的样本<a class="ae jd" href="https://github.com/Borda/kaggle_brain-tumor-3D/blob/4c5898b2ef18783eb47810084dd97941747068f3/kaggle_brain3d/utils.py#L21-L29" rel="noopener ugc nofollow" target="_blank">代码</a>。</p></figure><p id="23ce" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了加载完整的卷，我们列出了特定文件夹中的所有图像，按照文件名中编码的切片索引对它们进行排序，并将它们全部连接到一个卷中:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><a href="https://github.com/Borda/kaggle_brain-tumor-3D/blob/4c5898b2ef18783eb47810084dd97941747068f3/kaggle_brain3d/utils.py#L32-L48"><div class="gh gi oy"><img src="../Images/e9b69c1374e3723a2adc573a29275a3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eHtk6pzkirnumM5vQ4yhsA.png"/></div></a><p class="iz ja gj gh gi jb jc bd b be z dk translated">样品<a class="ae jd" href="https://github.com/Borda/kaggle_brain-tumor-3D/blob/4c5898b2ef18783eb47810084dd97941747068f3/kaggle_brain3d/utils.py#L32-L48" rel="noopener ugc nofollow" target="_blank">代码</a>用于装载完整的体积。</p></figure><p id="b012" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们使用标准的最小-最大强度归一化使所有值都在范围(0，1)内，并在体积内插入一些缺失的切片，使所有轴相等。这种标准化简化了后期的增强，因此我们可以使用全方位翻转和旋转，而不会出现任何并发症。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oy"><img src="../Images/55f9220c63663c3501a930eb514eb97a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GfTaVVR4-HLSLWMt-r2hEQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">使用 PyTorch 进行体积插值的示例代码。</p></figure><h2 id="313b" class="od lz jg bd ma oe of dn me og oh dp mi le oi oj mk li ok ol mm lm om on mo oo bi translated">数据缓存</h2><p id="50c8" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">加载过程相对较慢，并且对存储 IO 要求很高。这很快成为未来培训工作流程的瓶颈。我们引入了简单的扫描缓存来加速数据加载——每幅图像只从原始 DICOM 图像序列中加载一次，然后保存在 PyTorch 3D tensor 中。</p><p id="6075" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">DICOM 图像在内部使用 JPEG 压缩来减小它们的大小，相比之下，我们使用默认参数(张量使用<code class="fe oq or os ot b">torch.float64</code>)进行简单的保存，结果非常占用空间。所以我们将张量保存为<code class="fe oq or os ot b">torch.float16</code>，它仍然保留了所有的图像信息，但是显著减小了缓存大小(大约 4 倍),并连续改善了加载时间。</p><h2 id="7092" class="od lz jg bd ma oe of dn me og oh dp mi le oi oj mk li ok ol mm lm om on mo oo bi translated">裁剪扫描</h2><p id="ff14" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">我们观察到，所有扫描都包括覆盖每个扫描的重要部分的黑色/均匀背景，这使得模型学习能力的相当一部分被浪费，或者最终对不想要的噪声敏感。</p><p id="bb9d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">作为一项实验，我们在每个扫描轴上进行简单的裁剪，以最大化大脑占用率。我们计算一个简单 1D 投影(强度总和)；从扫描边缘开始，当总强度超过给定阈值时，我们搜索第一个点。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oz"><img src="../Images/a57ee8ca4ef3489ce8f11531698594e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_HpWTJi5tPHVehT2b4HZMQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">从各个方向裁剪体积</p></figure><p id="6812" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">原则上，它运行良好；设置适当的数据集范围的阈值是非常敏感的，结果显示每次扫描之间略有不同。它还取决于实际的轴和特定的大脑质量的存在。</p><h2 id="c1be" class="od lz jg bd ma oe of dn me og oh dp mi le oi oj mk li ok ol mm lm om on mo oo bi translated">扫描增强</h2><p id="3e80" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">有许多方法可以通过各种图像/体积扩充来提高模型的鲁棒性。主要类别是基于强度的、几何变换和结论(最后一种可能对输入样本敏感，因为我们不会移除肿瘤部分)。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><a href="https://github.com/Borda/kaggle_brain-tumor-3D/blob/4c5898b2ef18783eb47810084dd97941747068f3/kaggle_brain3d/data.py#L26-L35"><div class="gh gi oy"><img src="../Images/2e82f70045eb93e217e98b964b3b1924.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FgNXiZH73kJnZNxqLLHRoQ.png"/></div></a><p class="iz ja gj gh gi jb jc bd b be z dk translated">用于培训的<a class="ae jd" href="https://github.com/Borda/kaggle_brain-tumor-3D/blob/1c13ddde884b40b5d4a181f1b063ba3dff49b471/kaggle_brain3d/data.py#L26-L35" rel="noopener ugc nofollow" target="_blank">培训/验证增强</a>。</p></figure><p id="5873" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们已经使用了简单的镜像和<a class="ae jd" href="https://github.com/Borda/kaggle_brain-tumor-3D/blob/4c5898b2ef18783eb47810084dd97941747068f3/kaggle_brain3d/transforms.py#L95-L153" rel="noopener ugc nofollow" target="_blank">随机仿射变换</a>，对于移位和旋转具有保守的参数范围。作为最后一步，我们将强度归一化为在训练数据集上计算的零平均值。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pa"><img src="../Images/1b61da301dbcbfe078c35047fc871f43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pUuIO_o1a8pZdzHI5si2YQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">使用过的培训和验证<a class="ae jd" href="https://github.com/Borda/kaggle_brain-tumor-3D/blob/4c5898b2ef18783eb47810084dd97941747068f3/kaggle_brain3d/data.py#L26-L35" rel="noopener ugc nofollow" target="_blank">增强</a>。</p></figure><h1 id="b453" class="ly lz jg bd ma mb mc md me mf mg mh mi km mj kn mk kp ml kq mm ks mn kt mo mp bi translated">微调基线模型</h1><p id="86a7" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">我们的基线选择使用来自<a class="ae jd" href="https://monai.io/" rel="noopener ugc nofollow" target="_blank"> MONAI </a>包的 ResNet 模型，该模型加载了来自<a class="ae jd" href="https://github.com/Tencent/MedicalNet" rel="noopener ugc nofollow" target="_blank"> MedicalNet </a>的权重，并在大约 23 个不同的医学数据集上进行了预训练。</p><p id="55d4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">唯一复杂的是，MONAI 模型中的根模块名与 MedicalNet 中的预期模型名不兼容，因此在调用<code class="fe oq or os ot b">load_state_dict</code>之前必须对其进行重命名。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><a href="https://github.com/Borda/kaggle_brain-tumor-3D/blob/4c5898b2ef18783eb47810084dd97941747068f3/kaggle_brain3d/models.py#L19-L54"><div class="gh gi oy"><img src="../Images/6b4eb15be0b580cc24b5744ad29e57d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DNCvZ4TkSdsC1_m2L30_Tg.png"/></div></a><p class="iz ja gj gh gi jb jc bd b be z dk translated">简化的<a class="ae jd" href="https://github.com/Borda/kaggle_brain-tumor-3D/blob/4c5898b2ef18783eb47810084dd97941747068f3/kaggle_brain3d/models.py#L19-L54" rel="noopener ugc nofollow" target="_blank">权重加载</a>从 MedicalNet 到 MONAI ResNet 模型。</p></figure><p id="52de" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">竞赛使用<a class="ae jd" href="https://glassboxmedicine.com/2019/02/23/measuring-performance-auc-auroc/" rel="noopener ugc nofollow" target="_blank"> AUROC </a>(接收器工作特性下的面积)作为主要指标。我们用重物将 MONIA 模型包裹在<a class="ae jd" href="https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html" rel="noopener ugc nofollow" target="_blank"> PyTorch-Lightning 模块</a>中，并添加了几个<a class="ae jd" href="https://torchmetrics.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> TorchMetrics </a>来监控模型性能，包括 AUROC。</p><p id="ae7b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于培训，我们使用了<a class="ae jd" href="https://docs.grid.ai/products/sessions" rel="noopener ugc nofollow" target="_blank"> Grid.ai sessions </a>和一个基本的英伟达 T4 显卡。我们对基线模型的参数化如下:<br/> * <strong class="kx jh"> ResNet18 </strong>模型架构<br/> *体积大小设置为<strong class="kx jh"> 224px </strong>各维度<br/> *自动混合精度训练(<strong class="kx jh"> AMP </strong> ) <br/> *批量大小<strong class="kx jh"> 4 </strong></p><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/2f023aede653b8f9f787a62156c125b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*BpdJwfattRD5y0lDwKWQjw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">监控传输过程。</p></figure><p id="35c7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们对微调进行了实验(所有预先训练的权重都被冻结)，并将其与从头开始训练模型进行了比较。比较这两个选项，我们没有观察到任何显著的改进(通过所描述的参数化)。对于微调，我们显著增加了批量大小，同时仍然适合 16GB GPU。</p><h1 id="946a" class="ly lz jg bd ma mb mc md me mf mg mh mi km mj kn mk kp ml kq mm ks mn kt mo mp bi translated">推理和提交</h1><p id="b2ff" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">一个简单的模型推理迭代测试数据集中的图像，并生成预测，这些预测被汇总到竞争提交中。请注意，您需要首先将模型切换到<code class="fe oq or os ot b">eval</code>状态，对于预测，您不需要跟踪梯度，这大大加快了预测速度并降低了内存需求。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oy"><img src="../Images/c031b0cd293ddef82b4e677c4702ccbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B8twoLY5crZuFmkOcrb6Lw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">测试数据集上的简单<a class="ae jd" href="https://github.com/Borda/kaggle_brain-tumor-3D/blob/4c5898b2ef18783eb47810084dd97941747068f3/kaggle_brain3d/models.py#L157-174" rel="noopener ugc nofollow" target="_blank">模型推断</a>。</p></figure><p id="03ad" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们知道，训练数据集具有大约 52:48 的平衡标签分布比率。我们希望测试分布与训练数据集大致相似(因为模型的一部分是学习偏差)。</p><p id="9291" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面我们绘制了测试数据集预测的概率直方图，它似乎在一边形成了 0.5 左右的两个模式。</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/10df71a8f4226d61d3f6d2fdf0e898ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*jeFg_D_8WcMCHd9Nk5Cpsw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">最终预测分布。</p></figure><blockquote class="lr ls lt"><p id="daf9" class="kv kw lu kx b ky kz kh la lb lc kk ld lv lf lg lh lw lj lk ll lx ln lo lp lq ij bi translated">比赛期间，我在公开排行榜上排名第 757 位，后来在私人排行榜上跃升至第 134 位！公共测试分数基于总测试数据集的 1/3。</p></blockquote><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pd"><img src="../Images/5765fa26c20f8e08bd98ceb465ba0575.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fgjjmpXpXFMICNENf2Yqwg.png"/></div></div></figure><h1 id="28bf" class="ly lz jg bd ma mb mc md me mf mg mh mi km mj kn mk kp ml kq mm ks mn kt mo mp bi translated">结论</h1><p id="8c39" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">这篇文章为最近的 Kaggle 竞赛提供了一个基线解决方案，旨在通过 MRI 扫描进行大脑分类。我挑选了几个方便的框架来取长补短，并从社区和学术研究中受益。</p><p id="e452" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我介绍了数据集，并展示了一些如何通过缓存来增强训练的技巧。后来，我将预训练的模型权重加载到一个简单的 ResNet 模型中，并在带有 AMP 的英伟达 T4 显卡上对其进行了训练。我用这个解决方案在公共排行榜上排名居中，后来在私人排行榜上获得了铜牌。</p><p id="a63a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">通过交互式<a class="ae jd" href="https://grid.ai/" rel="noopener ugc nofollow" target="_blank"> Grid.ai </a>会议和<a class="ae jd" href="https://borda.github.io/kaggle_vol-3D-classify" rel="noopener ugc nofollow" target="_blank"> Github 项目</a>查看培训，该项目包括作为简单 python 包和 iPython 笔记本提供的所有代码…</p><div class="ip iq gp gr ir na"><a href="https://borda.github.io/kaggle_brain-tumor-3D" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd jh gy z fp nf fr fs ng fu fw jf bi translated">Kaggle:脑肿瘤放射基因组分类</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">这项挑战旨在预测对脑癌治疗重要的遗传生物标志物的状态。与……</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">borda.github.io</p></div></div></div></a></div></div><div class="ab cl pe pf hu pg" role="separator"><span class="ph bw bk pi pj pk"/><span class="ph bw bk pi pj pk"/><span class="ph bw bk pi pj"/></div><div class="ij ik il im in"><p id="6d11" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> <em class="lu">对更酷的 Pytorch 闪电集成感兴趣？<br/>关注我，加入我们牛逼的</em></strong><a class="ae jd" href="https://join.slack.com/t/pytorch-lightning/shared_invite/zt-pw5v393p-qRaDgEk24~EjiZNBpSQFgQ" rel="noopener ugc nofollow" target="_blank"><strong class="kx jh"><em class="lu">Slack</em></strong></a><strong class="kx jh"><em class="lu">社区！</em> </strong></p><div class="ip iq gp gr ir na"><a href="https://devblog.pytorchlightning.ai/best-practices-to-rank-on-kaggle-competition-with-pytorch-lightning-and-grid-ai-spot-instances-54aa5248aa8e" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd jh gy z fp nf fr fs ng fu fw jf bi translated">使用 PyTorch Lightning 和 Grid.ai Spot 实例对 Kaggle 竞争进行排名的最佳实践</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">通过交互式会话、超参数解决图像分类挑战的完整数据科学周期…</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">devblog.pytorchlightning.ai</p></div></div><div class="nj l"><div class="pl l nl nm nn nj no ix na"/></div></div></a></div></div><div class="ab cl pe pf hu pg" role="separator"><span class="ph bw bk pi pj pk"/><span class="ph bw bk pi pj pk"/><span class="ph bw bk pi pj"/></div><div class="ij ik il im in"><h1 id="d15f" class="ly lz jg bd ma mb pm md me mf pn mh mi km po kn mk kp pp kq mm ks pq kt mo mp bi translated">关于作者</h1><p id="6d1e" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">吉尔卡·博罗维克 拥有 CTU 大学的计算机视觉博士学位。他已经在几家 IT 创业公司和公司从事机器学习和数据科学工作几年了。他喜欢探索有趣的世界问题，用最先进的技术解决这些问题，并开发开源项目。</p><h2 id="afff" class="od lz jg bd ma oe of dn me og oh dp mi le oi oj mk li ok ol mm lm om on mo oo bi translated">感谢</h2><p id="07aa" class="pw-post-body-paragraph kv kw jg kx b ky mq kh la lb mr kk ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">MRI 插图是基于提供的<a class="ae jd" href="https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/data" rel="noopener ugc nofollow" target="_blank"> Kaggle 数据集</a>生成的，作为<a class="ae jd" href="https://www.med.upenn.edu/cbica/brats2021/" rel="noopener ugc nofollow" target="_blank">RSNA-ASNR-米凯布拉特挑战赛 2021 </a> <br/> U.Baid 等人的“RSNA-ASNR-米凯布拉特 2021 脑肿瘤分割和放射基因组分类基准”，<a class="ae jd" href="https://arxiv.org/abs/2107.02314" rel="noopener ugc nofollow" target="_blank"> arXiv:2107.02314 </a>，2021。</p></div></div>    
</body>
</html>