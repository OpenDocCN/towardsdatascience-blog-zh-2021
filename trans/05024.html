<html>
<head>
<title>A complete Data Analysis workflow in Python and scikit-learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python和scikit中的完整数据分析工作流程-学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-complete-data-analysis-workflow-in-python-and-scikit-learn-9a77f7c283d3?source=collection_archive---------1-----------------------#2021-05-03">https://towardsdatascience.com/a-complete-data-analysis-workflow-in-python-and-scikit-learn-9a77f7c283d3?source=collection_archive---------1-----------------------#2021-05-03</a></blockquote><div><div class="fc ik il im in io"/><div class="ip iq ir is it"><h2 id="d24f" class="iu iv iw bd b dl ix iy iz ja jb jc dk jd translated" aria-label="kicker paragraph">数据分析</h2><div class=""/><div class=""><h2 id="d30d" class="pw-subtitle-paragraph kc jf iw bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">一个现成的代码，包括预处理，参数调整和模型运行和评估。</h2></div><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ku"><img src="../Images/d950ca8b2271ca472200cd484564fa56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KLjJ53tl5Rs2HnQX3PFGOw.jpeg"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">来自<a class="ae lk" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5475660" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae lk" href="https://pixabay.com/users/buffik-17824401/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5475660" rel="noopener ugc nofollow" target="_blank"> Buffik </a>的图像</p></figure><p id="73cd" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在这个简短的教程中，我展示了一个利用<code class="fe mh mi mj mk b">scikit-learn</code> Python库的完整数据分析过程。该过程包括</p><ul class=""><li id="7fc8" class="ml mm iw ln b lo lp lr ls lu mn ly mo mc mp mg mq mr ms mt bi translated">预处理，包括特征选择、归一化和平衡化</li><li id="f5bc" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated">带参数调整的模型选择</li><li id="33a4" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated">模型评估</li></ul><p id="cfab" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">本教程的代码可以从我的<a class="ae lk" href="https://github.com/alod83/data-science/blob/master/DataAnalysis/Data%20Analysis.ipynb" rel="noopener ugc nofollow" target="_blank"> Github库</a>下载。</p><h1 id="347f" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">加载数据集</h1><p id="c502" class="pw-post-body-paragraph ll lm iw ln b lo nr kg lq lr ns kj lt lu nt lw lx ly nu ma mb mc nv me mf mg ip bi translated">首先，我通过Python <code class="fe mh mi mj mk b">pandas</code>库加载数据集。我利用了由<a class="ae lk" href="https://www.kaggle.com/rashikrahmanpritom/heart-attack-analysis-prediction-dataset" rel="noopener ugc nofollow" target="_blank"> Kaggle库</a>提供的<code class="fe mh mi mj mk b">heart.csv</code>数据集。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="8d95" class="oa na iw mk b gz ob oc l od oe">import pandas as pd</span><span id="6653" class="oa na iw mk b gz of oc l od oe">df = pd.read_csv('source/heart.csv')<br/>df.head()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj og"><img src="../Images/276f3e0c054b366a0eed31c7d50893ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_lieDhXnc5li7SAWTgiCzg.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="1aa6" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我计算数据集中的记录数和列数:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="c0c4" class="oa na iw mk b gz ob oc l od oe">df.shape</span></pre><p id="11d4" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">它给出了以下输出:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="f3a4" class="oa na iw mk b gz ob oc l od oe">(303, 14)</span></pre><h1 id="cd7f" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">功能选择</h1><p id="b2d7" class="pw-post-body-paragraph ll lm iw ln b lo nr kg lq lr ns kj lt lu nt lw lx ly nu ma mb mc nv me mf mg ip bi translated">现在，我将数据集的列分为输入(<code class="fe mh mi mj mk b">X</code>)和输出(<code class="fe mh mi mj mk b">Y</code>)。我使用除了<code class="fe mh mi mj mk b">output</code>之外的所有列作为输入特征。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="b8c7" class="oa na iw mk b gz ob oc l od oe">features = []<br/>for column in df.columns:<br/>    if column != 'output':<br/>        features.append(column)<br/>X = df[features]<br/>Y = df['output']</span></pre><p id="c799" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">为了选择输入特征的最小集合，我通过由<code class="fe mh mi mj mk b">pandas dataframe</code>提供的<code class="fe mh mi mj mk b">corr()</code>函数计算特征之间的皮尔逊相关系数。</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj oh"><img src="../Images/59bb80bb5c98aadd2be29b3641516838.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_OsaZlDEPh7A0abHb2Lf1Q.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="0122" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我注意到所有的特征都具有低相关性，因此我可以将它们都作为输入特征。</p><h1 id="b155" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">数据标准化</h1><p id="49a4" class="pw-post-body-paragraph ll lm iw ln b lo nr kg lq lr ns kj lt lu nt lw lx ly nu ma mb mc nv me mf mg ip bi translated">数据归一化会在相同的时间间隔内缩放所有要素。我利用了由<code class="fe mh mi mj mk b">scikit-learn</code>库提供的<code class="fe mh mi mj mk b">MinMaxScaler()</code>。在我的<a class="ae lk" rel="noopener" target="_blank" href="/data-normalization-with-python-scikit-learn-e9c5640fed58">上一篇文章</a>中，我在<code class="fe mh mi mj mk b">scikit-learn</code>中讨论了数据规范化，而在我的<a class="ae lk" rel="noopener" target="_blank" href="/data-preprocessing-with-python-pandas-part-3-normalisation-5b5392d27673">这篇</a>文章中，我描述了没有<code class="fe mh mi mj mk b">scikit-learn</code>的数据规范化的一般过程。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="e8b1" class="oa na iw mk b gz ob oc l od oe">X.describe()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj oi"><img src="../Images/53b269da4f2d44767a326e84cecf79bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eD4cs6wvMZKrsrxs3evJfA.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="d7a0" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">查看每个特性的最小值和最大值，我注意到有许多特性超出了范围[0，1]，因此我需要对它们进行缩放。</p><p id="2c11" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">对于每个输入特征，我计算<code class="fe mh mi mj mk b">MinMaxScaler()</code>并将结果存储在同一个<code class="fe mh mi mj mk b">X</code>列中。<code class="fe mh mi mj mk b">MinMaxScaler()</code>必须先通过<code class="fe mh mi mj mk b">fit()</code>功能进行拟合，然后才能通过<code class="fe mh mi mj mk b">transform()</code>功能申请转换。注意，我必须对格式(-1，1)中的每个特征进行整形，以便作为缩放器的输入参数传递。例如，<code class="fe mh mi mj mk b">Reshape(-1,1)</code>将数组<code class="fe mh mi mj mk b">[0,1,2,3,5]</code>转换为<code class="fe mh mi mj mk b">[[0],[1],[2],[3],[5]]</code>。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="6573" class="oa na iw mk b gz ob oc l od oe">from sklearn.preprocessing import MinMaxScaler</span><span id="4f0e" class="oa na iw mk b gz of oc l od oe">for column in X.columns:<br/>    feature = np.array(X[column]).reshape(-1,1)<br/>    scaler = MinMaxScaler()<br/>    scaler.fit(feature)<br/>    feature_scaled = scaler.transform(feature)<br/>    X[column] = feature_scaled.reshape(1,-1)[0]</span></pre><h1 id="b7a2" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">在训练和测试中拆分数据集</h1><p id="642a" class="pw-post-body-paragraph ll lm iw ln b lo nr kg lq lr ns kj lt lu nt lw lx ly nu ma mb mc nv me mf mg ip bi translated">现在我把数据集分成两部分:训练集和测试集。测试集的大小是整个数据集的20%。我利用了<code class="fe mh mi mj mk b">scikit-learn</code>函数<code class="fe mh mi mj mk b">train_test_split()</code>。我将使用训练集来训练模型，使用测试集来测试模型的性能。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="963d" class="oa na iw mk b gz ob oc l od oe">import numpy as np<br/>from sklearn.model_selection import train_test_split</span><span id="de35" class="oa na iw mk b gz of oc l od oe">X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.20, random_state=42)</span></pre><h1 id="8646" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">平衡</h1><p id="0c5e" class="pw-post-body-paragraph ll lm iw ln b lo nr kg lq lr ns kj lt lu nt lw lx ly nu ma mb mc nv me mf mg ip bi translated">我检查数据集是否平衡，即训练集中的输出类是否被同等地表示。我可以使用<code class="fe mh mi mj mk b">value_counts()</code>函数来计算每个输出类中的记录数。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="4c50" class="oa na iw mk b gz ob oc l od oe">y_train.value_counts()</span></pre><p id="8be0" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">它给出了以下输出:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="2caf" class="oa na iw mk b gz ob oc l od oe">1    133<br/>0    109</span></pre><p id="0bb3" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">输出类不平衡，因此我可以平衡它。我可以利用<code class="fe mh mi mj mk b">imblearn</code>库来执行平衡。我尝试过采样少数类和欠采样多数类。关于不平衡学习库的更多细节可以在<a class="ae lk" href="https://imbalanced-learn.org/stable/" rel="noopener ugc nofollow" target="_blank">这里</a>找到。首先，我通过<code class="fe mh mi mj mk b">RandomOverSampler()</code>执行过采样。我创建模型，然后我适应训练集。<code class="fe mh mi mj mk b">fit_resample()</code>函数返回平衡的训练集。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="d098" class="oa na iw mk b gz ob oc l od oe">from imblearn.over_sampling import RandomOverSampler<br/>over_sampler = RandomOverSampler(random_state=42)<br/>X_bal_over, y_bal_over = over_sampler.fit_resample(X_train, y_train)</span></pre><p id="103f" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我通过<code class="fe mh mi mj mk b">value_counts()</code>函数计算每个类中的记录数，我注意到现在数据集是平衡的。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="24da" class="oa na iw mk b gz ob oc l od oe">y_bal_over.value_counts()</span></pre><p id="dce4" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">它给出了以下输出:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="d22b" class="oa na iw mk b gz ob oc l od oe">1    133<br/>0    133</span></pre><p id="b7d4" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">其次，我通过<code class="fe mh mi mj mk b">RandomUnderSampler()</code>模型执行欠采样。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="71f3" class="oa na iw mk b gz ob oc l od oe">from imblearn.under_sampling import RandomUnderSampler</span><span id="92ed" class="oa na iw mk b gz of oc l od oe">under_sampler = RandomUnderSampler(random_state=42)<br/>X_bal_under, y_bal_under = under_sampler.fit_resample(X_train, y_train)</span></pre><h1 id="1e55" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">模型选择和培训</h1><p id="34b5" class="pw-post-body-paragraph ll lm iw ln b lo nr kg lq lr ns kj lt lu nt lw lx ly nu ma mb mc nv me mf mg ip bi translated">现在，我准备好训练模型了。我选择一个<code class="fe mh mi mj mk b">KNeighborsClassifier</code>，首先用不平衡数据训练它。我利用<code class="fe mh mi mj mk b">fit()</code>函数来训练模型，然后利用<code class="fe mh mi mj mk b">predict_proba()</code>函数来预测测试集的值。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="af16" class="oa na iw mk b gz ob oc l od oe">from sklearn.neighbors import KNeighborsClassifier</span><span id="13c9" class="oa na iw mk b gz of oc l od oe">model = KNeighborsClassifier(n_neighbors=3)<br/>model.fit(X_train, y_train)<br/>y_score = model.predict_proba(X_test)</span></pre><p id="4848" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我计算模型的性能。特别是，我计算了<code class="fe mh mi mj mk b">roc_curve()</code>和<code class="fe mh mi mj mk b">precision_recall()</code>，然后绘制它们。我利用<code class="fe mh mi mj mk b">scikitplot</code>库来绘制曲线。</p><p id="70b3" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">从图中我注意到每个类别都有一条roc曲线。关于精确召回曲线，类别1比类别0工作得更好，可能是因为它由更大数量的样本表示。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="85f0" class="oa na iw mk b gz ob oc l od oe">import matplotlib.pyplot as plt<br/>from sklearn.metrics import roc_curve<br/>from scikitplot.metrics import plot_roc,auc<br/>from scikitplot.metrics import plot_precision_recall</span><span id="2394" class="oa na iw mk b gz of oc l od oe">fpr0, tpr0, thresholds = roc_curve(y_test, y_score[:, 1])</span><span id="fbfd" class="oa na iw mk b gz of oc l od oe"># Plot metrics <br/>plot_roc(y_test, y_score)<br/>plt.show()<br/>    <br/>plot_precision_recall(y_test, y_score)<br/>plt.show()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj oj"><img src="../Images/b1559deb070c65291461910cc6054b33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0fe9xDt-aCxU5o2mv96mkA.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ok"><img src="../Images/edd74a0826979f0247ca0ce8c1ab0e80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aqjfoMoq6uw3Mv-QTw9ebw.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="a4d6" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在，我用过采样平衡重新计算同样的事情。我注意到类0的精确召回曲线增加，而类1的精确召回曲线减少。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="39c0" class="oa na iw mk b gz ob oc l od oe">model = KNeighborsClassifier(n_neighbors=3)<br/>model.fit(X_bal_over, y_bal_over)<br/>y_score = model.predict_proba(X_test)<br/>fpr0, tpr0, thresholds = roc_curve(y_test, y_score[:, 1])</span><span id="dc88" class="oa na iw mk b gz of oc l od oe"># Plot metrics <br/>plot_roc(y_test, y_score)<br/>plt.show()<br/>    <br/>plot_precision_recall(y_test, y_score)<br/>plt.show()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ol"><img src="../Images/e4de72eb288ecfb21a4ce63c5e3bf400.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pb81Y9jNvZzWHp64YyntXQ.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj om"><img src="../Images/3d9c61469205e7ecac1e8c8149470f90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Loygozl5hW7kyU8FMsO9BQ.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="2019" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">最后，我通过欠采样数据来训练模型，我注意到性能普遍下降。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="ff93" class="oa na iw mk b gz ob oc l od oe">model = KNeighborsClassifier(n_neighbors=3)<br/>model.fit(X_bal_under, y_bal_under)<br/>y_score = model.predict_proba(X_test)<br/>fpr0, tpr0, thresholds = roc_curve(y_test, y_score[:, 1])</span><span id="d58a" class="oa na iw mk b gz of oc l od oe"># Plot metrics <br/>plot_roc(y_test, y_score)<br/>plt.show()<br/>    <br/>plot_precision_recall(y_test, y_score)<br/>plt.show()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj on"><img src="../Images/0e32e738974c1ad9d571d13cbae98dd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LiwjuhLwx6dP96CGmzpIZA.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj oo"><img src="../Images/78e6ec020240d1e8ff79b0d17d669c8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZZvj3FVRA2eC_yJP-L5qpw.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><h1 id="8d60" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">参数调整</h1><p id="097a" class="pw-post-body-paragraph ll lm iw ln b lo nr kg lq lr ns kj lt lu nt lw lx ly nu ma mb mc nv me mf mg ip bi translated">在本教程的最后一部分，我试图通过为我的模型搜索最佳参数来提高模型的性能。我利用了由<code class="fe mh mi mj mk b">scikit-learn</code>库提供的<code class="fe mh mi mj mk b">GridSearchCV</code>机制。我为要测试的每个参数选择一系列值，并将它们放入<code class="fe mh mi mj mk b">param_grid</code>变量中。我创建了一个<code class="fe mh mi mj mk b">GridSearchCV()</code>对象，与训练集相适应，然后检索包含在<code class="fe mh mi mj mk b">best_estimator_</code>变量中的最佳估计值。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="515f" class="oa na iw mk b gz ob oc l od oe">from sklearn.model_selection import GridSearchCV</span><span id="f7f5" class="oa na iw mk b gz of oc l od oe">model = KNeighborsClassifier()</span><span id="1329" class="oa na iw mk b gz of oc l od oe">param_grid = {<br/>   'n_neighbors': np.arange(2,8),<br/>   'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],<br/>    'metric' : ['euclidean','manhattan','chebyshev','minkowski']<br/>}</span><span id="cf09" class="oa na iw mk b gz of oc l od oe">grid = GridSearchCV(model, param_grid = param_grid)<br/>grid.fit(X_train, y_train)</span><span id="8bf4" class="oa na iw mk b gz of oc l od oe">best_estimator = grid.best_estimator_</span></pre><p id="c62b" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我利用最佳估计量作为我的预测模型，并计算算法的性能。</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="94e6" class="oa na iw mk b gz ob oc l od oe">best_estimator.fit(X_train, y_train)<br/>y_score = best_estimator.predict_proba(X_test)<br/>fpr0, tpr0, thresholds = roc_curve(y_test, y_score[:, 1])</span><span id="23d8" class="oa na iw mk b gz of oc l od oe"># Plot metrics <br/>plot_roc(y_test, y_score)<br/>plt.show()<br/>    <br/>plot_precision_recall(y_test, y_score)<br/>plt.show()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj op"><img src="../Images/40116210f74b8b3577838b09098f8e1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7jAMK6y0l2YPVr1XWCJjqw.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj oq"><img src="../Images/54c55828816dfafe5c530a20a3f7e9e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hci4XJJ6owm6mJiHlhbDHQ.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="8742" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我注意到roc曲线有所改善。我现在尝试使用过采样的训练集。我省略了代码，因为它与前面的代码相同。在这种情况下，我获得了最佳性能。</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj or"><img src="../Images/0212f1c185c41c95b81e8d6826223d65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rA9FfV59sJ7cUWD7t-q5iQ.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj os"><img src="../Images/291c9c1fb51f3f2003937960ce717bdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SrA1d6QMnC-eXlgZ_2o0kg.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><h1 id="382f" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">摘要</h1><p id="eba3" class="pw-post-body-paragraph ll lm iw ln b lo nr kg lq lr ns kj lt lu nt lw lx ly nu ma mb mc nv me mf mg ip bi translated">在本教程中，我展示了为数据分析构建良好模型的完整工作流程。工作流程包括:</p><ul class=""><li id="167a" class="ml mm iw ln b lo lp lr ls lu mn ly mo mc mp mg mq mr ms mt bi translated">数据预处理，包括特征选择和平衡</li><li id="a4a6" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated">利用交叉验证的网格搜索进行模型选择和参数调整</li><li id="be36" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated">模型评估，通过ROC曲线和精确召回曲线。</li></ul><p id="e802" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在本教程中，我没有处理异常值检测。如果你想了解这方面的东西，可以看一下<a class="ae lk" rel="noopener" target="_blank" href="/how-to-detect-outliers-with-python-pyod-aa7147359e4b">我之前的文章</a>。</p><p id="2b08" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">如果你想了解我的研究和其他活动的最新情况，你可以在<a class="ae lk" href="https://twitter.com/alod83" rel="noopener ugc nofollow" target="_blank"> Twitter </a>、<a class="ae lk" href="https://www.youtube.com/channel/UC4O8-FtQqGIsgDW_ytXIWOg?view_as=subscriber" rel="noopener ugc nofollow" target="_blank"> Youtube </a>和<a class="ae lk" href="https://github.com/alod83" rel="noopener ugc nofollow" target="_blank"> Github </a>上关注我。</p><h1 id="b69c" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">相关文章</h1><div class="ot ou gq gs ov ow"><a rel="noopener follow" target="_blank" href="/a-complete-data-analysis-workflow-in-python-pycaret-9a13c0fa51d4"><div class="ox ab fp"><div class="oy ab oz cl cj pa"><h2 class="bd jg gz z fq pb fs ft pc fv fx jf bi translated">Python PyCaret中的完整数据分析工作流</h2><div class="pd l"><h3 class="bd b gz z fq pb fs ft pc fv fx dk translated">这是一个现成的教程，利用了我用过的最好的机器学习库。</h3></div><div class="pe l"><p class="bd b dl z fq pb fs ft pc fv fx dk translated">towardsdatascience.com</p></div></div><div class="pf l"><div class="pg l ph pi pj pf pk le ow"/></div></div></a></div><div class="ot ou gq gs ov ow"><a rel="noopener follow" target="_blank" href="/machine-learning-getting-started-with-the-k-neighbours-classifier-d7e6b25f2b09"><div class="ox ab fp"><div class="oy ab oz cl cj pa"><h2 class="bd jg gz z fq pb fs ft pc fv fx jf bi translated">机器学习:K近邻分类器入门</h2><div class="pd l"><h3 class="bd b gz z fq pb fs ft pc fv fx dk translated">一个Python的现成代码，实现了scikit-learn中的K-neighbors分类器，从数据预处理到…</h3></div><div class="pe l"><p class="bd b dl z fq pb fs ft pc fv fx dk translated">towardsdatascience.com</p></div></div><div class="pf l"><div class="pl l ph pi pj pf pk le ow"/></div></div></a></div><h1 id="c914" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">新到中？您可以每月订阅几美元，并解锁无限的文章— <a class="ae lk" href="https://alod83.medium.com/membership" rel="noopener">点击此处</a>。</h1></div></div>    
</body>
</html>