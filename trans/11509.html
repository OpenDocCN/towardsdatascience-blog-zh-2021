<html>
<head>
<title>5 Cute Features of CatBoost</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CatBoost 的 5 个可爱特性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-cute-features-of-catboost-61532c260f69?source=collection_archive---------8-----------------------#2021-11-13">https://towardsdatascience.com/5-cute-features-of-catboost-61532c260f69?source=collection_archive---------8-----------------------#2021-11-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f696" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">其他升压算法没有这些功能</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/85f13be681a68b4613f088d7c4b76d4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*taSuAADkW9GT_yp4NUO31A.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@yerlinmatu?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">耶尔林·马图</a>在<a class="ae ky" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="0461" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经讨论过 5 种 boosting 算法:<a class="ae ky" rel="noopener" target="_blank" href="/how-do-you-implement-adaboost-with-python-a76427b0fa7a"> <strong class="lb iu"> AdaBoost </strong> </a>，<a class="ae ky" rel="noopener" target="_blank" href="/under-the-hood-of-gradient-boosting-and-its-python-implementation-99cc63efd24d"> <strong class="lb iu">梯度 Boosting </strong> </a>，<a class="ae ky" href="https://rukshanpramoditha.medium.com/unlock-the-power-of-xgboost-738536b9f36f" rel="noopener"> <strong class="lb iu"> XGBoost </strong> </a>，<a class="ae ky" rel="noopener" target="_blank" href="/can-lightgbm-outperform-xgboost-d05a94102a55"><strong class="lb iu">light GBM</strong></a><strong class="lb iu"/>和<a class="ae ky" rel="noopener" target="_blank" href="/how-do-you-use-categorical-features-directly-with-catboost-947b211c2923"> <strong class="lb iu"> CatBoost </strong> </a>。</p><p id="4ae1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中，<strong class="lb iu"> CatBoost </strong>之所以如此特别，是因为它有其他 boosting 算法所没有的特殊之处。</p><p id="78c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通常，升压算法有两个主要缺点:</p><ul class=""><li id="7621" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">在 boosting 算法中很容易发生过拟合，因为它们是基于树的算法。</li><li id="c824" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">将 boosting 算法的训练过程并行化并不容易，因为新的树是按顺序一个接一个地创建的。</li></ul><p id="9b53" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">考虑到这些缺点，CatBoost 旨在以闪电般的速度为大型数据集构建更一般化的模型。它有内置参数，以减少过度拟合和并行学习，加上一些其他独特的功能！让我们来探索它们。</p><h1 id="a52b" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">CatBoost 同时支持 CPU 和 GPU，开箱即用</h1><p id="bb06" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">CatBoost 的<code class="fe ng nh ni nj b">pip</code>和<code class="fe ng nh ni nj b">conda</code>安装都为 CatBoost 提供 GPU 支持。</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="cbe4" class="no mk it nj b gy np nq l nr ns">pip install catboost<br/>#OR<br/>conda install -c conda-forge catboost</span></pre><p id="1fc1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> CatBoostClassifier() </strong>和<strong class="lb iu"> CatBoostRegressor() </strong>类中的以下参数设置可用于在训练时获得 GPU 支持。</p><ul class=""><li id="e9bd" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu"> task_type: </strong>可能值为“CPU”和“GPU”。值类型是字符串。默认值为“CPU”。要在培训期间获得 GPU 支持，只需使用“GPU”作为<em class="nt"> task_type </em>的值。</li><li id="2713" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">设备:</strong>该参数定义了计算机中 GPU 设备的 id。值类型是字符串。您可以使用“0”或“1”等数字来定义单个 GPU 设备。要一次定义多个 GPU 设备，您可以使用一系列数字，如“0:1:2”。</li></ul><p id="67ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要查找您有多少个 GPU 和正确的 GPU ID，请在 Windows 中转到任务管理器，然后单击性能选项卡。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/cecb3cfb37e5a6f872b3483be56cafa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*JXIg-_MmgoOtmU3AX3mYyQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="edb7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了允许 CatBoost 使用我的 NVIDIA GPU，我应该设置<strong class="lb iu"> task_type="GPU" </strong>和<strong class="lb iu"> devices='1' </strong>。下面是一个关于<strong class="lb iu"> CatBoostClassifier() </strong>类的例子。</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="b855" class="no mk it nj b gy np nq l nr ns">from catboost import CatBoostClassifier</span><span id="3c5b" class="no mk it nj b gy nv nq l nr ns">model = CatBoostClassifier(iterations=100,<br/>                           <strong class="nj iu">task_type="GPU"</strong>,<br/>                           <strong class="nj iu">devices='1'</strong>)</span></pre><p id="a56b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用 GPU 实现 CatBoost 对于包含数百万个对象和数百个要素的大型数据集来说非常有效！根据官方文档，对于这样的大型数据集，使用强大的 GPU 可以获得高达 40 倍的速度提升。如果你的数据集不够大，你不会看到 CPU 和 GPU 的训练时间有太大的差别。</p><h1 id="c4c2" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">我们可以在 CatBoost 中直接使用分类特征</h1><p id="b9e2" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">通常，在算法中使用分类特征之前，我们必须对数据集中的分类特征(如果有的话)进行编码。但是使用 CatBoost，您不需要进行编码，因为算法会使用一次性编码自动将这些分类特征编码为数值。</p><p id="0691" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，如果您的数据具有分类特征，您需要使用<a class="ae ky" href="https://catboost.ai/en/docs/concepts/python-reference_pool" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Pool() </strong> </a>类将整个数据集转换为 CatBoost 的特殊<strong class="lb iu"> <em class="nt"> Pool </em> </strong>数据类型。如果您的数据只有数字特征，我建议您不要将数据转换为<strong class="lb iu"> <em class="nt">池</em> </strong>数据类型，因为这可能会减慢训练过程。因此，只转换分类数据。</p><p id="986e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> Pool() </strong>类中的以下参数设置可用于通过 CatBoost 直接包含分类特征。</p><ul class=""><li id="67d7" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">数据:</strong>由<strong class="lb iu"> X </strong>定义的特征矩阵。可能的类型有<strong class="lb iu"> </strong>熊猫数据帧或 2D 数字阵列。</li><li id="3915" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">标签:</strong>由<strong class="lb iu"> y </strong>定义的目标或标签列。可能的型号有<strong class="lb iu"> </strong>熊猫系列或 1D Numpy 阵列。</li><li id="72fa" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu"> cat_features: </strong>数据集中分类特征名称的列表。</li></ul><p id="fd47" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有一个例子:</p><pre class="kj kk kl km gt nk nj nl nm aw nn bi"><span id="6190" class="no mk it nj b gy np nq l nr ns">from catboost import CatBoostRegressor, Pool</span><span id="5aa7" class="no mk it nj b gy nv nq l nr ns">model = CatBoostRegressor()</span><span id="4ca7" class="no mk it nj b gy nv nq l nr ns">pool_data = Pool(X_train,<br/>                 y_train,                  <br/>                 cat_features=['F1', 'F2', ...])</span><span id="172d" class="no mk it nj b gy nv nq l nr ns">model.fit(pool_data)</span></pre><p id="8782" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我写的更详细的指南可以在<a class="ae ky" rel="noopener" target="_blank" href="/how-do-you-use-categorical-features-directly-with-catboost-947b211c2923">这里</a>找到。</p><h1 id="03de" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">CatBoost 具有内置参数来减少过度拟合</h1><p id="51dc" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated"><strong class="lb iu"> CatBoostClassifier() </strong>和<strong class="lb iu"> CatBoostRegressor() </strong>类及其<strong class="lb iu"> fit() </strong>方法中的以下参数可用于减少模型的过拟合。</p><ul class=""><li id="4092" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu"> early_stopping_rounds: </strong>这在<strong class="lb iu"> CatBoostClassifier() </strong>和<strong class="lb iu"> CatBoostRegressor() </strong>类的<strong class="lb iu"> fit() </strong>方法中都有。默认值为<code class="fe ng nh ni nj b">False</code>，不激活提前停止。我们可以使用一个整数来提前停止学习过程，以减少过拟合。我写的详细指南可以在这里找到<a class="ae ky" rel="noopener" target="_blank" href="/activate-early-stopping-in-boosting-algorithms-to-mitigate-overfitting-9c1b12cc6729">。</a></li><li id="49ca" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu"> l2_leaf_reg </strong>或<strong class="lb iu"> reg_lambda: </strong>这在<strong class="lb iu"> CatBoostClassifier() </strong>和<strong class="lb iu"> CatBoostRegressor() </strong>类中都可用。这将 L2 正则化项的系数添加到成本函数中。默认值为 3。类型是 float。增加该值可以防止过度拟合。</li><li id="ab22" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">深度:</strong>该参数定义了树的深度。这类似于决策树中的<strong class="lb iu"> max_depth </strong>参数。默认值为 6。类型是整数。减小该值可以防止过度拟合。好的值是 2 和 3。</li></ul><h1 id="37f9" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">CatBoost 有一个内置参数来生成学习曲线</h1><p id="f915" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">学习曲线对于监控模型的学习过程极其重要。根据由<strong class="lb iu"> n_estimators </strong>或<strong class="lb iu">迭代</strong>定义的提升回合数绘制训练和验证分数。</p><p id="ce66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在 CatBoost 中，我们可以通过在两个<strong class="lb iu"> CatBoostClassifier() </strong>和<strong class="lb iu"> CatBoostRegressor() </strong>类的<strong class="lb iu"> fit() </strong>方法中将<strong class="lb iu"> <em class="nt"> plot </em> </strong>参数设置为<code class="fe ng nh ni nj b">True</code>来轻松生成学习曲线。下图显示了由 CatBoost 创建的学习曲线。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/58c55a6d864dbdf6537d2833c7fce910.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*zOwEV4ppAboKWxbyZVr8vw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="12e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这条学习曲线有两个用例:</p><ul class=""><li id="0d87" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">寻找是否有机会提前停止</li><li id="0a75" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">为<strong class="lb iu"> <em class="nt">早 _ 停 _ 轮</em> </strong>自变量寻找最优值</li></ul><p id="4302" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于这个的详细指南可以通过阅读我写的<a class="ae ky" rel="noopener" target="_blank" href="/activate-early-stopping-in-boosting-algorithms-to-mitigate-overfitting-9c1b12cc6729">这篇文章</a>找到。</p><h1 id="c315" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">CatBoost 通过其默认参数值提供了很好的结果</h1><p id="7351" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">这是 CatBoost 的另一大特色。您不需要在 CatBoost 中进行参数调整来获得很好的结果。所以，你可以节省时间！根据官方文档，调整后的参数值和默认参数值提供了几乎相同的性能分数！</p><h1 id="6751" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">结论</h1><p id="e934" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated"><strong class="lb iu">你最喜欢的 CatBoost 功能是什么？</strong>请在评论区提及。</p><p id="73d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">综上:</strong> CatBoost 提供了一种在决策树上实现梯度提升的特殊方法。凭借其特殊功能，很容易提高具有数百万个数据点的大型数据集的学习速度。它还提供了减少过度拟合的有用功能。最后，您可以节省参数调整的时间，因为在 CatBoost 中不需要调整。</p><p id="6b3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">你应该考虑安装 CatBoost 吗？</strong>是的，肯定！CatBoost 是一个开源库，每个人都可以使用！除此之外，在它的官方<a class="ae ky" href="https://catboost.ai/" rel="noopener ugc nofollow" target="_blank">网站</a>上有很棒的文档。看一看吧！</p><h2 id="7f73" class="no mk it bd ml nx ny dn mp nz oa dp mt li ob oc mv lm od oe mx lq of og mz oh bi translated">阅读下一条(推荐):</h2><p id="7dae" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">探索 ML 中的 boosting 算法及其 Python 实现！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://rukshanpramoditha.medium.com/list/boosting-techniques-2b61b7fab9ec"><div class="gh gi oi"><img src="../Images/398accfd8d77b49af1fdeee143275446.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*HjZK3bSjXK9QKCf9yir49Q.png"/></div></a><p class="ku kv gj gh gi kw kx bd b be z dk translated">助推技术(作者截图)</p></figure><h2 id="85d8" class="no mk it bd ml nx ny dn mp nz oa dp mt li ob oc mv lm od oe mx lq of og mz oh bi translated">阅读下一条(可选):</h2><p id="9478" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">找到大多数数据科学家面临的最糟糕问题的解决方案:过度拟合问题！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://rukshanpramoditha.medium.com/list/addressing-overfitting-868959382d1d"><div class="gh gi oj"><img src="../Images/f3e2d34256adacde772b4759b5e06cc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*HiIOZhrq0lOv4jc5S2yrBg.png"/></div></a><p class="ku kv gj gh gi kw kx bd b be z dk translated">解决过度拟合问题(作者截图)</p></figure></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><p id="d197" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">今天的帖子到此结束。我总是尽我所能以一种你能从中获得最大收益的方式来写和组织我的内容。应该有很多方法来进一步改善我的内容，你可能有很好的想法。所以，</p><p id="43cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您有任何反馈，请告诉我。</p><p id="73b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与此同时，你可以<a class="ae ky" href="https://rukshanpramoditha.medium.com/membership" rel="noopener"> <strong class="lb iu">注册成为会员</strong> </a>来获得我写的每一个故事的全部信息，我将会收到你的一部分会员费。</p><p id="4c06" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">非常感谢你一直以来的支持！下一个故事再见。祝大家学习愉快！</p><p id="aa74" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特别感谢 Unsplash 上的<strong class="lb iu"> Yerlin Matu </strong>，<strong class="lb iu"> </strong>为我提供了这篇文章的封面图片。</p><p id="0908" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="or os ep" href="https://medium.com/u/f90a3bb1d400?source=post_page-----61532c260f69--------------------------------" rel="noopener" target="_blank">鲁克山普拉莫迪塔</a><br/><strong class="lb iu">2021–11–13</strong></p></div></div>    
</body>
</html>