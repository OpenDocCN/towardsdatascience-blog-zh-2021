<html>
<head>
<title>Multidimensional Scaling (MDS) for Dimensionality Reduction and Data Visualization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于降维和数据可视化的多维标度(MDS)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multidimensional-scaling-mds-for-dimensionality-reduction-and-data-visualization-d5252c8bc4c0?source=collection_archive---------6-----------------------#2021-10-15">https://towardsdatascience.com/multidimensional-scaling-mds-for-dimensionality-reduction-and-data-visualization-d5252c8bc4c0?source=collection_archive---------6-----------------------#2021-10-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4ec3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过python实现使用不同的距离方法解释和再现多维标度(MDS)</h2></div><p id="786f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">降维方法允许根据具有许多特征的数据集中的各种参数(例如相关性、距离、方差)之间的关系，在另一个轴上检查数据集。在这个阶段之后，可以使用监督或无监督学习方法轻松地对数据集执行分类等操作。此外，如果我们考虑具有30个特征的数据集，而不是进行30维可视化，则在可视化方面，根据它们之间的各种因素从不同方面考虑30个特征并使它们二维化会更容易。可以从不同的方面考虑降维方法对数据集的处理，即通过使用傅立叶变换将时间轴中给出的信号变换到频率轴，并有效地处理信号。本文从理论层面讨论了作为降维和可视化方法之一的多维尺度变换的各种类型，并介绍了它的应用领域。python实现丰富了研究。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="2a58" class="ln lo it lj b gy lp lq l lr ls"><strong class="lj iu"><em class="lt">Table of Contents<br/></em>1. What is Multi-Dimensional Scaling?<br/>2. Goodness of fit — Stress —<br/>3. PCA vs MDS<br/>4. Different Distance Approaches on image dataset<br/>- Euclidean Distance<br/>- Manhattan Distance<br/>- Chebyshev Distance<br/>- Minkowski Distance<br/>5. Tutorials<br/>- S curve<br/>- Digits Dataset<br/>6. Metric MDS and Non-Metric MDS<br/>7. References</strong></span></pre><figure class="le lf lg lh gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lu"><img src="../Images/3e4bb69dd8407b82d6c803a5289fb898.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*20RGiEXyBob6gtPR"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">索尔·阿尔维斯在Unsplash<a class="ae mg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">上的照片</a></p></figure><h1 id="fb44" class="mh lo it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">1.什么是多维标度？</h1><p id="7616" class="pw-post-body-paragraph ki kj it kk b kl my ju kn ko mz jx kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">多维缩放是对象集之间的距离或差异的可视化表示。[1]“对象”可以是颜色、面孔、地图坐标、政治信仰，也可以是任何一种真实的或概念上的刺激[2]。除了将差异解释为图上的距离，MDS还可以作为高维数据的降维技术[3]。简而言之，MDS的主要目的是在降维后保持这些不同。</p><p id="442b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在Sklearn库中提供的MDS中，距离默认设置为<strong class="kk iu">欧几里德距离</strong>。此外，可以调整和使用其他距离，如曼哈顿(见第4节)。</p><figure class="le lf lg lh gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi nd"><img src="../Images/14f8ac5efd3fec7282c409f2829b1de3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2iT-_7EMoX-lWF1IVNEAmA.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">图一。数据集，按作者分类的图像</p></figure><p id="0efd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在下面的代码块中，使用图1和图2(左)中所示的城市之间的航空公司距离创建了一个6 x 6数据集，并应用了MDS sklearn库中的基础版本。</p><figure class="le lf lg lh gt lv"><div class="bz fp l di"><div class="ne nf l"/></div></figure><figure class="le lf lg lh gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ng"><img src="../Images/85fe7a299784d58396bd60eafbb2507f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2lRRh85Mqz5Yg3fmKlRU7A.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">图二。地图(左)，代码块的输出(右)，图片作者</p></figure><p id="d6af" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">结果如图2(右)所示。另外，应力值为<code class="fe nh ni nj lj b">0.188</code>。在进入压力的话题之前，让我们讨论一下得到的结果。最初，我们有一个6×6的矩阵，通过应用MDS将数据集的维数减少到6×2，然后将其可视化。</p><p id="32e1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果考虑坐标平面，则(x，y)点的位置由参考(0，0)原点确定。任何(x，y)点相对于(0，0)点定位。另一方面，在MDS，每个列对都是用指定的距离类型计算的。这就是为什么与MDS保持距离。当我们看图2时，可以看到埃尔祖鲁姆是离其他城市最远的。同样，在应用MDS后，彼此靠近的城市的位置也很接近，因此当我们查看MDS的结果时，会遇到类似的情况。从不同的角度查看数据集，同时保持数据之间的距离关系。</p><h1 id="761e" class="mh lo it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">2.契合度——压力——</h1><p id="52b4" class="pw-post-body-paragraph ki kj it kk b kl my ju kn ko mz jx kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">需要一个特定的表达式来确定在数据分析应用中需要降维到什么程度。在PCA中，累积方差是通过绘制一个scree图来确定的。在MDS，距离是模型化的。因此，MDS的最佳选择是基于实际距离与其估计值之间的差异。这种方法被称为压力。上面示例中绘制应力图的代码块及其输出如下:</p><figure class="le lf lg lh gt lv"><div class="bz fp l di"><div class="ne nf l"/></div></figure><figure class="le lf lg lh gt lv gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/ca941bef88f8cca47883bb59be8d6e81.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*TTxdvT2AUvIF5DhmX1n46A.png"/></div><p class="mc md gj gh gi me mf bd b be z dk translated">图3。代码块的输出-重音-，作者图像</p></figure><p id="384e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">结果如图3所示。在关于MDS的原始论文中，Kruskal (1964)根据他的经验给出了以下关于压力值的建议[4]:</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="b297" class="ln lo it lj b gy lp lq l lr ls">0.2   – poor<br/>0.1   – fair<br/>0.05  – good<br/>0.025 – excellent<br/>0     – perfect</span></pre><p id="dda5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如今，学术研究认为，根据数据集的规模和数据的质量来遵循这一表格会产生误导。</p><h1 id="5f58" class="mh lo it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">3.PCA vs MDS</h1><figure class="le lf lg lh gt lv"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="ab1b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过考虑PCA中的方差-相关值来执行通过保持MDS中的距离来执行的过程。使用欧几里德距离最小化线性距离类似于最大化线性相关性。因此，可以说PCA和MDS应用数据集的2D图形具有相似的特征。当然，这仅适用于使用欧几里得距离的MDS。此外，可以根据项目应用不同的距离方法。(例如，对于大型数据集，欧几里德距离可能很弱。)PCA已经应用于上面代码块中的数据集，结果如图4所示。</p><div class="nl nm gp gr nn no"><a rel="noopener follow" target="_blank" href="/comprehensive-guide-for-principal-component-analysis-7bf2b4a048ae"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">主成分分析综合指南</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">用python实现主成分分析的理论和实践部分</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">towardsdatascience.com</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc ma no"/></div></div></a></div><figure class="le lf lg lh gt lv gh gi paragraph-image"><div class="gh gi od"><img src="../Images/1e6a89eacaec6cd5cf5c62167d94fc5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*yvX43xAADIBQzNaNZMx_ZA.png"/></div><p class="mc md gj gh gi me mf bd b be z dk translated">图4。PCA降维，作者降维</p></figure><h1 id="3ee0" class="mh lo it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">4.不同的距离方法</h1><p id="0c17" class="pw-post-body-paragraph ki kj it kk b kl my ju kn ko mz jx kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">已经提到过，在Sklearn库中默认使用欧几里德距离。此外，通过设置<code class="fe nh ni nj lj b">dissimilarities = “precomputed”</code>可以使用各种距离。在下面的代码块中，MDS被应用于sklearn库中不同距离的<code class="fe nh ni nj lj b">fetch_olivetti_faces</code>数据集，并在2D可视化。</p><figure class="le lf lg lh gt lv"><div class="bz fp l di"><div class="ne nf l"/></div></figure><h2 id="a7ac" class="ln lo it bd mi oe of dn mm og oh dp mq kr oi oj ms kv ok ol mu kz om on mw oo bi translated"><strong class="ak">欧几里德距离</strong></h2><figure class="le lf lg lh gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi op"><img src="../Images/fc9216f854f78b3311cfb0f24c9e35be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MvpwfUlPkJLiCVGSg6KXkw.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">图5。MDS使用欧几里德距离降低了维数，作者使用图像</p></figure><h2 id="9777" class="ln lo it bd mi oe of dn mm og oh dp mq kr oi oj ms kv ok ol mu kz om on mw oo bi translated"><strong class="ak">曼哈顿</strong>距离</h2><figure class="le lf lg lh gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi oq"><img src="../Images/780fb1bf632441169fba80ce7ebac237.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3evFe_9lpmWmzwtm6nSAtg.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">图6。通过MDS和曼哈顿距离降低维度，通过作者降低图像维度</p></figure><h2 id="9330" class="ln lo it bd mi oe of dn mm og oh dp mq kr oi oj ms kv ok ol mu kz om on mw oo bi translated"><strong class="ak">切比雪夫</strong>距离</h2><figure class="le lf lg lh gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi or"><img src="../Images/00b04c5ba35dde6d6dc672dcff985f54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VlSuYESMNwt0Krtp8eymcA.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">图7。通过MDS和切比雪夫距离降低维数，图片由作者提供</p></figure><h2 id="fe8a" class="ln lo it bd mi oe of dn mm og oh dp mq kr oi oj ms kv ok ol mu kz om on mw oo bi translated"><strong class="ak">闵可夫斯基</strong>距离</h2><figure class="le lf lg lh gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi or"><img src="../Images/30a234f84272032cfb0e036fca1c90fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c_GYggzkjkxeTeBaowFqUw.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">图8。MDS使用闵可夫斯基距离降低维度，作者使用图像</p></figure><p id="31b3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">查看上面的图像，可以看到每个结果都是根据基于距离的不同特征形成的。应该根据进行选择时所使用的数据集的结构来选择。例如，研究基因的生物学家应该选择和使用对数倍数变化，因为他们对基因的对数倍数变化感兴趣。</p><h1 id="3285" class="mh lo it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">5.教程</h1><h2 id="cd2e" class="ln lo it bd mi oe of dn mm og oh dp mq kr oi oj ms kv ok ol mu kz om on mw oo bi translated"><strong class="ak"> S曲线</strong></h2><p id="9d2f" class="pw-post-body-paragraph ki kj it kk b kl my ju kn ko mz jx kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">3D S曲线导入到下面的代码块中。它被渲染成2D，并用主成分分析和MDS可视化。结果如图9所示。</p><figure class="le lf lg lh gt lv"><div class="bz fp l di"><div class="ne nf l"/></div></figure><figure class="le lf lg lh gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi os"><img src="../Images/4a9e6ac1f0a7109e1c147e2c11801fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sEpRYkKtO1768diWnM1U2A.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">图9。MDS的S曲线(左)，PCA的S曲线(右)，图片作者</p></figure><p id="96b1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果在项目中使用机器学习对数据集进行分类，那么在使用各种非监督学习方法或监督学习方法应用MDS后，分类过程可以很容易地完成。</p><h2 id="5f66" class="ln lo it bd mi oe of dn mm og oh dp mq kr oi oj ms kv ok ol mu kz om on mw oo bi translated">数字</h2><p id="0cea" class="pw-post-body-paragraph ki kj it kk b kl my ju kn ko mz jx kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">导入Digits数据集的前5个标签，即0，1，2，3，4。通过分别应用MDS和PCA过程，数据集的形状从901 x 64转换为901 x 2。然后进行可视化，结果如图10所示。</p><figure class="le lf lg lh gt lv"><div class="bz fp l di"><div class="ne nf l"/></div></figure><figure class="le lf lg lh gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi ot"><img src="../Images/04c8bc0fb75dbce14f6fa59ea0e37d31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nk5sIdKe3YSRk4UXC40OVw.png"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">图10。数字数据集的维数分别通过MDS(左)和主成分分析(右)降低，图像通过作者</p></figure><p id="6e1d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">经过MDS过程，可以看出，特别是2。第三。与PCA相比，组形成在更好的簇中。在这个阶段之后，各种机器学习过程的应用将给出有效的结果。</p><h1 id="4689" class="mh lo it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">6.公制MDS和非公制MDS</h1><p id="6fda" class="pw-post-body-paragraph ki kj it kk b kl my ju kn ko mz jx kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">到目前为止，它一直专注于度量(经典)多维标度，也称为主坐标分析(PCoA)。在这种方法中，通过考虑特征之间的距离进行降维，并进行可视化。</p><p id="908d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">非公制MDS适用于序数数据集。比如在市场调研时收集的调查数据中，比方说10以上的X牌车会给多少分。在这里，8分意味着质量比3分好。标签0–1–2–3–4被用在上面的数字数据集中，但是两者都没有优势。在另一个例子中，当精神病患者被要求评价他们的情绪时，高分和低分意味着不同的东西。</p><p id="a960" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">简而言之，虽然度量MDS显示了线性关系，但非度量MDS(也称为有序MDS)是由一组仅取决于等级值的曲线来描述的。[5]通过设置<code class="fe nh ni nj lj b">metric = False</code>，它可以用作Sklearn库中的非公制MDS。</p><h1 id="0b72" class="mh lo it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">7.参考</h1><p id="bf97" class="pw-post-body-paragraph ki kj it kk b kl my ju kn ko mz jx kq kr na kt ku kv nb kx ky kz nc lb lc ld im bi translated">[1]“多维标度:定义、概述、示例—统计方法。”<a class="ae mg" href="https://www.statisticshowto.com/multidimensional-scaling/" rel="noopener ugc nofollow" target="_blank">https://www.statisticshowto.com/multidimensional-scaling/</a>(2021年10月14日访问)。</p><p id="2c10" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2]“多维标度——约瑟夫·b·克鲁斯卡尔，米隆·威希——谷歌图书。”<a class="ae mg" href="https://books.google.de/books/about/Multidimensional_Scaling.html?id=iTydugEACAAJ&amp;redir_esc=y" rel="noopener ugc nofollow" target="_blank">https://books . Google . de/books/about/多维_Scaling.html？id = iTydugEACAAJ&amp;redir _ ESC = y</a>(2021年10月13日访问)。</p><p id="7017" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[3] A. Buja，D. F. Swayne，M. L. Littman，N. Dean，H. Hofmann和L. Chen，“多维标度下的数据可视化”，<em class="lt">计算机学报图表。统计。</em>，第17卷，第2期，第444–472页，2008年6月，doi: 10.1198/106186008X318440。</p><p id="84a5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[4] NCSS有限责任公司，“435–1多维标度”</p><p id="aaf0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[5]“多维标度:定义、概述、示例—统计方法。”<a class="ae mg" href="https://www.statisticshowto.com/multidimensional-scaling/" rel="noopener ugc nofollow" target="_blank">https://www.statisticshowto.com/multidimensional-scaling/</a>(2021年10月14日访问)。</p><div class="nl nm gp gr nn no"><a href="https://ibrahimkovan.medium.com/machine-learning-guideline-959da5c6f73d" rel="noopener follow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">机器学习指南</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">所有与机器学习相关的文章</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">ibrahimkovan.medium.com</p></div></div><div class="nx l"><div class="ou l nz oa ob nx oc ma no"/></div></div></a></div></div></div>    
</body>
</html>