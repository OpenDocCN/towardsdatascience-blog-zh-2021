<html>
<head>
<title>How to Remove Multicollinearity Using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Python移除多重共线性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-remove-multicollinearity-using-python-4da8d9d8abb2?source=collection_archive---------6-----------------------#2021-06-12">https://towardsdatascience.com/how-to-remove-multicollinearity-using-python-4da8d9d8abb2?source=collection_archive---------6-----------------------#2021-06-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ce9e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">它可能不会提高性能，但对于可解释性来说是必不可少的。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b1bd3cf37f28fce1fa492e204ad8b317.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MZ9Ea8atakI3RDnaBzkS8Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Jr Korpa 在<a class="ae ky" href="https://unsplash.com/s/photos/data?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="23be" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="ce15" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">机器学习是一种解决无法显式编码的问题的方法，例如分类问题。机器学习模型会从数据中学习一个模式，所以我们可以用它来确定数据属于哪个类。因此，我们可以以最佳性能完成分类任务。</p><p id="66d8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">但是有一个问题。模型是如何工作的？有几个人无法接受一个性能很好的模型，因为它无法被解读。这些人关心可解释性，因为他们想确保模型以合理的方式预测数据。</p><p id="fad9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在我们能够解释ML模型之前，去除多重共线性是一个必要的步骤。多重共线性是一种预测变量与另一个预测变量相关的情况。虽然多重共线性不会影响模型的性能，但它会影响可解释性。如果我们不消除多重共线性，我们将永远不会知道一个变量对结果的贡献有多大。因此，我们必须消除多重共线性。</p><p id="7af5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">本文将向您展示如何使用Python消除多重共线性。没有进一步，让我们开始吧！</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="ac76" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">履行</h1><h2 id="fb8f" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">数据源</h2><p id="639d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了进行演示，我们将使用一个名为澳大利亚雨水的数据集。它描述了不同日期和地点的天气特征。这个数据集也是一个监督学习问题，我们可以使用这些数据来预测明天是否下雨。这个数据集可以在Kaggle上找到，你可以在这里 访问它<a class="ae ky" href="https://www.kaggle.com/jsphyg/weather-dataset-rattle-package" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/fac2f4b1671fdbd482f530b0b255a148.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CXv1FvJBVsIWwI9N"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者捕捉到的。</p></figure><p id="b948" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以下是加载数据集的代码和预览:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><h2 id="5439" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">预处理数据</h2><p id="1d7c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">加载数据后，下一步是预处理数据。在这种情况下，我们将不使用分类列，并删除至少有一个缺失值的行。下面是实现这一点的代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><h2 id="f2bb" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">计算VIF值</h2><p id="3998" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">有了清晰的数据后，让我们来计算方差通胀因子(VIF)值。什么是VIF？</p><p id="3839" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">VIF是一个确定变量是否具有多重共线性的数字。这个数字也代表了一个变量由于与其他变量的线性相关性而被夸大了多少。</p><p id="826b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">VIF值从1开始，没有上限。如果数字变大，这意味着变量有很大的多重共线性。</p><p id="ec98" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了计算VIF，我们将对每个变量进行线性回归，该变量将成为目标变量。完成这个过程后，我们计算R平方。最后，我们用这个公式计算VIF值:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/fed4295f718d3ed2e67affa0a0cfed57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MfJX6LCkiJ35cbHI"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由作者创作。</p></figure><p id="6cb3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在Python中，我们可以使用statsmodels库中名为variance_inflation_factor的函数来计算VIF。下面是这样做的代码及其结果:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="0b8b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">从上面可以看出，几乎所有变量的VIF值都在5以上。甚至压力变量也有超过40万的VIF值。这是一个巨大的因素！</p><p id="2a8c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因此，我们需要清除数据中的多重共线性。</p><h2 id="19a2" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">移除多重共线性</h2><p id="d6c2" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">要消除多重共线性，我们可以做两件事。我们可以创建新要素或从数据中删除它们。</p><p id="8d9f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最初不建议删除功能。原因是因为我们移除了该功能，所以有可能丢失信息。因此，我们将首先生成新特征。</p><p id="cbac" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">从数据中，我们可以看到有一些特征是成对的。比如' Temp9am '带' Temp3pm '，' Pressure9am '带' Pressure3pm '，' Cloud9am '带' Cloud3pm '，等等。</p><p id="aa87" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">根据这些特征，我们可以生成新的。新要素将包含这些对之间的差值。创建这些要素后，我们可以安全地将它们从数据中移除。</p><p id="35e9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下面是这样做的代码及其结果:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="0dc1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在，让我们看看我们的数据的VIF值是什么样的:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="ccd1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">正如你从上面看到的，我们仍然有一个巨大的VIF值的变量。但是，我们仍然从生成新的特性中得到了很好的结果。</p><p id="8b12" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在让我们移除VIF值大于5的要素。下面是这样做的代码及其结果:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="1a3c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">不错！现在我们有了所有VIF值小于5的变量。有了这些变量，现在我们可以解释结果了。但首先，让我们建立我们的机器学习模型。</p><h2 id="077a" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">建立模型</h2><p id="94bf" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在这种情况下，我们将使用支持向量机(SVM)算法来建模我们的数据。简而言之，SVM是一个模型，它将创建一个超平面，可以最大限度地分离不同标签的数据。</p><p id="1dec" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因为我们的数据属于分类任务，所以我们将使用scikit-learn中的SVC对象来创建模型。下面是实现这一点的代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><h2 id="ff63" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">使用排列特征重要性的解释</h2><p id="b2bd" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">理论上，SVM模型是不可解释的。这是因为我们不能仅仅通过参数来解释结果。但幸运的是，我们可以用几种方法来解释这个模型。我们可以使用的方法之一是置换特征重要性。</p><p id="efcc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">置换特征重要性通过查看改变特征值后误差增加多少来测量特征的重要性。如果其值的改变增加了模型的误差，则该特征是重要的。</p><p id="e5a6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了实现这个方法，我们可以使用scikit-learn库中的一个名为permutation_importance的函数来计算特性的重要性。根据结果，我们将创建一个箱线图来可视化特性的重要性。</p><p id="eae2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下面是这样做的代码及其结果:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="2827" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">从上面可以看出，HumanityDiff特性是对最终结果有巨大贡献的最重要的特性。然后，降雨特征成为第二重要的特征。之后，分别以风速、蒸发量、风速差、气压差和云差为最重要的特征。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="2769" class="kz la it bd lb lc mz le lf lg na li lj jz nb ka ll kc nc kd ln kf nd kg lp lq bi translated">结束语</h1><p id="6116" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">干得好！现在，您已经了解了如何使用Python移除数据集中的多重共线性。我希望这篇文章能帮助你如何消除多重共线性，以及如何解释机器学习模型。</p><p id="092b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你对我的文章感兴趣，你可以关注我的媒体以获得更多类似的文章。还有，如果你有什么问题或者想打个招呼，你可以在<a class="ae ky" href="https://www.linkedin.com/in/alghaniirfan/" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> LinkedIn </strong> </a>上关注我。</p><p id="9a5c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">谢谢你看我的文章！</p><h2 id="98e7" class="ne la it bd lb nf ng dn lf nh ni dp lj ma nj nk ll me nl nm ln mi nn no lp np bi translated">参考</h2><p id="fd48" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">[1]【https://etav.github.io/python/vif_factor_python.html<br/>【2】<a class="ae ky" href="https://statisticalhorizons.com/multicollinearity" rel="noopener ugc nofollow" target="_blank">https://statisticalhorizons.com/multicollinearity</a><br/>【3】<a class="ae ky" href="https://www.analyticsvidhya.com/blog/2020/03/what-is-multicollinearity/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2020/03/what-is-multicollism/</a></p></div></div>    
</body>
</html>