<html>
<head>
<title>Building Machine Learning Pipelines using Snowflake and Dask</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用雪花和Dask构建机器学习管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-machine-learning-pipelines-using-snowflake-and-dask-10ae5e7fff0f?source=collection_archive---------9-----------------------#2021-07-22">https://towardsdatascience.com/building-machine-learning-pipelines-using-snowflake-and-dask-10ae5e7fff0f?source=collection_archive---------9-----------------------#2021-07-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/6c8b91fb49ce217362714bd88630c4eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zBznEGIuOCHIH3qTXWEMSA.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">弗雷德里克·菲利克斯在<a class="ae jg" href="https://unsplash.com/s/photos/saturn?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="c4b2" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><h1 id="75c8" class="kp kq jj bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">介绍</h1><p id="405b" class="pw-post-body-paragraph ln lo jj lp b lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">最近，作为一名数据科学家，我一直在努力寻找更好的方法来改善我的工作流程。我倾向于在工作中花费大量时间建模和构建ETL。这意味着我越来越需要依赖工具来可靠、高效地处理大型数据集。我很快意识到，用熊猫来操纵这些数据集并不总是一个好方法，这促使我寻找其他替代方法。</p><p id="5fc2" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">在这篇文章中，我想分享我最近探索的一些工具，并向你展示我如何使用它们，以及它们如何帮助我提高工作流程的效率。我将特别谈到的两个是雪花和Dask。两个非常不同的工具，但是可以很好地互补，尤其是作为ML生命周期的一部分。我希望在读完这篇文章后，你能很好地理解什么是雪花和Dask，如何有效地使用它们，并且能够使用你自己的用例。</p><p id="b195" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">更具体地说，我想向您展示如何使用雪花和Python构建ETL管道，为机器学习任务生成训练数据。然后，我想介绍Dask和<a class="ae jg" href="https://www.saturncloud.io/s/?utm_source=daniel-foley" rel="noopener ugc nofollow" target="_blank"> Saturn Cloud </a>，并向您展示如何利用云中的并行处理来真正加快ML培训过程，从而提高您作为数据科学家的工作效率。</p><h1 id="a8cc" class="kp kq jj bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">用雪花和Python构建ETL</h1><p id="75c2" class="pw-post-body-paragraph ln lo jj lp b lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">在我们开始编码之前，我最好简单解释一下雪花是什么。这是我最近在我的团队决定开始使用它时问的问题。在高层次上，它是云中的数据仓库。玩了一会儿后，我意识到它有多强大。我认为对我来说，最有用的功能之一是你可以使用的虚拟仓库。虚拟仓库让您可以访问相同的数据，但完全独立于其他虚拟仓库，因此计算资源不会在团队之间共享。事实证明这非常有用，因为它消除了其他用户全天执行查询所导致的任何潜在性能问题。这减少了等待查询运行时的挫败感和时间浪费。</p><p id="119b" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">由于我们将使用雪花，我将简要概述如何设置它，并开始自己试验。我们需要做到以下几点:</p><ul class=""><li id="a338" class="mq mr jj lp b lq ml lu mm ly ms mc mt mg mu mk mv mw mx my bi translated"><em class="mz">获得雪花账户设置</em></li><li id="8d6d" class="mq mr jj lp b lq na lu nb ly nc mc nd mg ne mk mv mw mx my bi translated"><em class="mz">把我们的数据变成雪花</em></li><li id="91a9" class="mq mr jj lp b lq na lu nb ly nc mc nd mg ne mk mv mw mx my bi translated"><em class="mz">使用SQL和雪花UI编写并测试我们的查询</em></li><li id="7bbc" class="mq mr jj lp b lq na lu nb ly nc mc nd mg ne mk mv mw mx my bi translated"><em class="mz">编写一个Python类，它可以执行我们的查询来生成我们的最终数据集用于建模</em></li></ul><p id="1d1e" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">建立一个账户就像在他们的网站上注册免费试用一样简单。一旦你完成了，你可以在这里下载snowsql CLI<a class="ae jg" href="https://docs.snowflake.com/en/user-guide/snowsql-install-config.html#installing-snowsql-on-macos-using-the-installer" rel="noopener ugc nofollow" target="_blank"/>。这将使向雪花添加数据变得简单。按照这些步骤，我们可以尝试使用我们的凭证和命令行连接到雪花。</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="2315" class="no kq jj nk b gy np nq l nr ns">snowsql -a &lt;account_name&gt; -u &lt;user_name&gt;</span></pre><p id="f777" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">登录雪花UI可以在网址中找到自己的账户名。它看起来应该是这样的:xxxxx.europe-west2.gcp。好了，让我们进入下一步，将我们的数据放入雪花中。这里我们需要遵循几个步骤，即:</p><ul class=""><li id="4fb8" class="mq mr jj lp b lq ml lu mm ly ms mc mt mg mu mk mv mw mx my bi translated"><em class="mz">创建我们的虚拟仓库</em></li><li id="b9d3" class="mq mr jj lp b lq na lu nb ly nc mc nd mg ne mk mv mw mx my bi translated"><em class="mz">创建数据库</em></li><li id="d010" class="mq mr jj lp b lq na lu nb ly nc mc nd mg ne mk mv mw mx my bi translated"><em class="mz">定义并创建我们的表格</em></li><li id="fa1b" class="mq mr jj lp b lq na lu nb ly nc mc nd mg ne mk mv mw mx my bi translated"><em class="mz">为我们的CSV文件创建暂存表</em></li><li id="158e" class="mq mr jj lp b lq na lu nb ly nc mc nd mg ne mk mv mw mx my bi translated"><em class="mz">将数据复制到我们的表格中</em></li></ul><p id="73cf" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">幸运的是，这并不太难，我们完全可以使用snowsql CLI来完成。对于这个项目，我将使用一个比我想要的更小的数据集，但不幸的是，我不能使用我公司的任何数据，而且很难在网上找到合适的大型数据集。不过，我确实从Dunnhumby找到了一些交易数据，这些数据可以在<a class="ae jg" href="https://www.kaggle.com/frtgnn/dunnhumby-the-complete-journey" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上免费获得。只是为了好玩，我使用这些数据创建了一个更大的合成数据集来测试Dask与sklearn相比处理挑战的能力。</p><p id="04ff" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">首先，我们需要在雪花UI中使用以下命令建立一个虚拟仓库和一个数据库。</p><p id="9699" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated"><strong class="lp jt">创建</strong> <strong class="lp jt">或</strong> <strong class="lp jt">用</strong><br/>warehouse _ size = " X-SMALL "<br/>auto _ suspend = 180<br/>auto _ resume = true<br/>initially _ suspended = true；</p><p id="fb3d" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated"><strong class="lp jt">创建</strong> <strong class="lp jt">或</strong> <strong class="lp jt">替换</strong> <strong class="lp jt">数据库</strong>dunhumby；</p><p id="d2f8" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">我们的数据由6个CSV组成，我们将把它们转换成6个表。我不会花太多时间浏览数据集，因为这篇文章更多的是关于使用雪花和Dask，而不是解释数据。</p><p id="11d3" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">下面是我们可以用来创建表格的命令。您需要预先知道的是您将使用什么列和数据类型。</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="3f85" class="no kq jj nk b gy np nq l nr ns"><strong class="nk jt">create</strong> <strong class="nk jt">or</strong> <strong class="nk jt">replace</strong> <strong class="nk jt">table</strong> campaign_desc ( <br/>description <strong class="nk jt">string</strong>, <br/>campaign number,<br/>start_day number,<br/>end_day number );</span><span id="fa80" class="no kq jj nk b gy nt nq l nr ns"><strong class="nk jt">create</strong> <strong class="nk jt">or</strong> <strong class="nk jt">replace</strong> <strong class="nk jt">table</strong> campaign_table ( <br/>description <strong class="nk jt">string</strong>, <br/>Household_key number, <br/>campaign number );</span><span id="d816" class="no kq jj nk b gy nt nq l nr ns"><strong class="nk jt">create</strong> <strong class="nk jt">or</strong> <strong class="nk jt">replace</strong> <strong class="nk jt">table</strong> coupon ( <br/>COUPON_UPC number, <br/>product_id number, <br/>campaign number );</span><span id="ff9c" class="no kq jj nk b gy nt nq l nr ns"><strong class="nk jt">create</strong> <strong class="nk jt">or</strong> <strong class="nk jt">replace</strong> <strong class="nk jt">table</strong> coupon_redempt ( <br/>household_key number, <br/><strong class="nk jt">day</strong> number, <br/>coupon_upc number, <br/>campaign number );</span><span id="69fa" class="no kq jj nk b gy nt nq l nr ns"><strong class="nk jt">create</strong> <strong class="nk jt">or</strong> <strong class="nk jt">replace</strong> <strong class="nk jt">table</strong> transactions ( <br/>household_key number, <br/>BASKET_ID number, <br/><strong class="nk jt">day</strong> number, <br/>product_id number, <br/>quantity number, <br/>sales_value number, <br/>store_id number, <br/>retail_disc decimal, <br/>trans_time number, <br/>week_no number, <br/>coupon_disc decimal, <br/>coupon_match_disc decimal );</span><span id="45bd" class="no kq jj nk b gy nt nq l nr ns"><strong class="nk jt">create</strong> <strong class="nk jt">or</strong> <strong class="nk jt">replace</strong> <strong class="nk jt">table</strong> demographic_data ( <br/>age_dec <strong class="nk jt">string</strong>, <br/>marital_status_code <strong class="nk jt">string</strong>, <br/>income_desc <strong class="nk jt">string</strong>, <br/>homeowner_desc <strong class="nk jt">string</strong>, <br/>hh_comp_desc <strong class="nk jt">string</strong>, <br/>household_size_desc string, <br/>kid_category_desc <strong class="nk jt">string</strong>, <br/>Household_key number);</span></pre><p id="a174" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">现在我们已经创建了表，我们可以开始考虑如何将数据放入其中。为此，我们需要存放CSV文件。这基本上只是一个中间步骤，因此雪花可以直接将文件从我们的阶段加载到我们的表中。我们可以使用<strong class="lp jt"> PUT </strong>命令将本地文件放到我们的stage中，然后使用<strong class="lp jt"> COPY INTO </strong>命令来指示雪花将这些数据放在哪里。</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="1135" class="no kq jj nk b gy np nq l nr ns">use database dunnhumby;</span><span id="3ea0" class="no kq jj nk b gy nt nq l nr ns"><strong class="nk jt">create</strong> <strong class="nk jt">or</strong> <strong class="nk jt">replace</strong> stage dunnhumby_stage;</span><span id="935b" class="no kq jj nk b gy nt nq l nr ns">PUT file://campaigns_table.csv @dunnhumby.public.dunnhumby_stage;</span><span id="cc10" class="no kq jj nk b gy nt nq l nr ns">PUT file://campaigns_desc.csv @dunnhumby.public.dunnhumby_stage;</span><span id="4866" class="no kq jj nk b gy nt nq l nr ns">PUT file://coupon.csv @dunnhumby.public.dunnhumby_stage;</span><span id="b825" class="no kq jj nk b gy nt nq l nr ns">PUT file://coupon_d=redempt.csv @dunnhumby.public.dunnhumby_stage; <br/>PUT file://transaction_data.csv @dunnhumby.public.dunnhumby_stage; <br/>PUT file://demographics.csv @dunnhumby.public.dunnhumby_stage;</span></pre><p id="1963" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">作为快速检查，您可以运行此命令来检查临时区域中有什么。</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="ce25" class="no kq jj nk b gy np nq l nr ns">ls @dunnhumby.public.dunnhumby_stage;</span></pre><p id="fb62" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">现在我们只需要使用下面的查询将数据复制到我们的表中。您可以在登录Snowflake后，在Snowflake UI或命令行中执行这些操作。</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="ba39" class="no kq jj nk b gy np nq l nr ns">copy into campaign_table <br/>from @dunnhumby.public.dunnhumby_stage/campaigns_table.csv.gz <br/>file_format = ( type = csv<br/>skip_header=1 <br/>error_on_column_count_mismatch = false <br/>field_optionally_enclosed_by=’”’);</span><span id="c879" class="no kq jj nk b gy nt nq l nr ns">copy into campaign_desc <br/>from @dunnhumby.public.dunnhumby_stage/campaign_desc.csv.gz <br/>file_format = ( type = csv<br/>skip_header=1 <br/>error_on_column_count_mismatch = false <br/>field_optionally_enclosed_by=’”’);</span><span id="2de7" class="no kq jj nk b gy nt nq l nr ns">copy into coupon <br/>from @dunnhumby.public.dunnhumby_stage/coupon.csv.gz <br/>file_format = ( type = csv<br/>skip_header=1 <br/>error_on_column_count_mismatch = false <br/>field_optionally_enclosed_by=’”’);</span><span id="178b" class="no kq jj nk b gy nt nq l nr ns">copy into coupon_redempt <br/>from @dunnhumby.public.dunnhumby_stage/coupon_redempt.csv.gz <br/>file_format = ( type = csv<br/>skip_header=1 <br/>error_on_column_count_mismatch = false <br/>field_optionally_enclosed_by=’”’);</span><span id="3821" class="no kq jj nk b gy nt nq l nr ns">copy into transactions <br/>from @dunnhumby.public.dunnhumby_stage/transaction_data.csv.gz <br/>file_format = ( type = csv<br/>skip_header=1 <br/>error_on_column_count_mismatch = false <br/>field_optionally_enclosed_by=’”’);</span><span id="6fb6" class="no kq jj nk b gy nt nq l nr ns">copy into demographic_data <br/>from @dunnhumby.public.dunnhumby_stage/demographics.csv.gz <br/>file_format = ( type = csv skip_header=1 <br/>error_on_column_count_mismatch = false <br/>field_optionally_enclosed_by=’”’);</span></pre><p id="952c" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">好极了，如果运气好的话，我们第一次尝试就有数据了。哦，要是有那么简单就好了，整个过程我试了几次才弄对(小心拼写错误)。希望你能跟上这一步，做好准备。我们离有趣的东西越来越近了，但是上面的步骤是这个过程中至关重要的一部分，所以要确保你理解了每一个步骤。</p><h1 id="3df8" class="kp kq jj bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">用SQL编写我们的管道</h1><p id="567b" class="pw-post-body-paragraph ln lo jj lp b lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">在下一步中，我们将编写查询来生成我们的目标和功能，然后最终生成一个训练数据集。创建用于建模的数据集的一种方法是将这些数据读入内存，然后使用pandas创建新要素并将所有数据框连接在一起。这是你在Kaggle和其他在线教程中看到的典型方法。这样做的问题是效率不是很高，尤其是当您处理任何合理大小的数据集时。出于这个原因，将繁重的工作外包给Snowflake是一个更好的主意，它可以非常好地处理大量数据集，并可能为您节省大量时间。在这里，我不会花太多时间深入研究我们数据集的细节，因为它对我要展示的内容并不重要。不过，一般来说，在开始建模之前，您会希望花大量的时间来探索和理解您的数据。这些查询的目标是对数据进行预处理，并创建一些简单的特征，我们稍后可以在我们的模型中使用它们。</p><h2 id="3038" class="no kq jj bd kr nu nv dn kv nw nx dp kz ly ny nz ld mc oa ob lh mg oc od ll jp bi translated">目标定义</h2><p id="8d20" class="pw-post-body-paragraph ln lo jj lp b lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">显然，监督机器学习的一个重要组成部分是定义一个合适的预测目标。对于我们的用例，我们将通过计算用户是否在截止周之后的两周内再次访问来预测流失。2周的选择是相当随意的，将取决于我们试图解决的具体问题，但让我们假设它对这个项目来说是好的。一般来说，你需要仔细分析你的客户，以了解访问间隔的分布情况，从而得出一个合适的客户流失定义。</p><p id="cceb" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">这里的主要思想是，对于每个表，我们希望每个household_key有一行包含我们的每个特性的值。</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="oe of l"/></div></figure><h2 id="73c4" class="no kq jj bd kr nu nv dn kv nw nx dp kz ly ny nz ld mc oa ob lh mg oc od ll jp bi translated">活动特征</h2><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="oe of l"/></div></figure><h2 id="5e37" class="no kq jj bd kr nu nv dn kv nw nx dp kz ly ny nz ld mc oa ob lh mg oc od ll jp bi translated">交易特征</h2><p id="a59b" class="pw-post-body-paragraph ln lo jj lp b lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">下面我们根据总体统计数据创建一些简单的指标，如平均值、最大值和标准差。</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="oe of l"/></div></figure><h2 id="0272" class="no kq jj bd kr nu nv dn kv nw nx dp kz ly ny nz ld mc oa ob lh mg oc od ll jp bi translated">人口特征</h2><p id="6106" class="pw-post-body-paragraph ln lo jj lp b lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">这个数据集有很多缺失数据，所以我决定在这里使用插补。有大量的技术可以处理缺失数据，从丢弃缺失数据到先进的插补方法。在这里，我让自己的生活变得简单，并用模式替换了缺失的值。我一般不推荐采用这种方法，因为理解为什么数据丢失对于决定如何处理它非常重要，但是对于这个例子来说，我将继续采用简单的方法。我们首先计算每个特征的模式，然后使用coalesce在数据丢失时用模式替换每一行。</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="oe of l"/></div></figure><h2 id="941e" class="no kq jj bd kr nu nv dn kv nw nx dp kz ly ny nz ld mc oa ob lh mg oc od ll jp bi translated">培训用数据</h2><p id="1fb5" class="pw-post-body-paragraph ln lo jj lp b lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">最后，我们通过将我们的主表连接在一起为我们的训练数据构建一个查询，最终得到一个包含我们的目标、我们的活动、交易和人口统计特征的表，我们可以用它来构建一个模型。</p><p id="98e4" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">作为一个简短的旁白，对于那些有兴趣了解更多关于雪花的特征和细微差别的人，我推荐以下这本书:<a class="ae jg" href="https://www.amazon.co.uk/gp/product/1800560613/ref=as_li_tl?ie=UTF8&amp;camp=1634&amp;creative=6738&amp;creativeASIN=1800560613&amp;linkCode=as2&amp;tag=mediumdanny05-21&amp;linkId=b016babb9c48e7f068b4a6bfa70c403c" rel="noopener ugc nofollow" target="_blank"> <strong class="lp jt">雪花食谱</strong> </a>。我开始读这本书，它充满了关于如何使用雪花的真正有用的信息，并且比我在这里做的更详细。</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="oe of l"/></div></figure><h1 id="41de" class="kp kq jj bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">用于ETL的Python代码</h1><p id="80c4" class="pw-post-body-paragraph ln lo jj lp b lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">我们需要这个ETL的最后一部分是编写一个脚本来执行它。现在，只有当您计划定期运行这样的ETL时，才真正需要这样做，但这是一个很好的实践，并且在需要时运行ETL会容易得多。</p><p id="ca5d" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">让我们简单讨论一下EtlTraining类的主要组件。我们班有一个输入，就是截止周。这是由于我们的数据集中定义数据的方式，但通常情况下，这将是一种日期格式，对应于我们希望选择的生成训练数据的截止日期。</p><p id="5c2f" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">我们初始化了一个查询列表，这样我们就可以轻松地遍历并执行它们。我们还创建了一个字典，其中包含我们传递给雪花连接的参数。这里我们使用我们在土星云中设置的环境变量。这里的是如何做到这一点的指南。连接到雪花并不太难，我们需要做的就是使用雪花连接器并传入我们的凭证字典。我们在雪花连接方法中实现了这一点，并将该连接作为属性返回。</p><p id="f417" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">为了使这些查询更容易运行，我将每个查询作为python字符串变量保存在ml_query_pipeline.py文件中。execute_etl方法完全按照它在tin上所说的去做。我们遍历每个查询，格式化它，执行它，最后关闭雪花连接。</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="6c1a" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">要运行这个ETL，我们只需在终端中输入下面的命令。(其中ml_pipeline是上面脚本的名称。)</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="f88b" class="no kq jj nk b gy np nq l nr ns">python -m ml_pipeline -w 102 -j ‘train’</span></pre><p id="7e40" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">简单地说，您可能希望定期运行这样的ETL。例如，如果您想要进行每日预测，那么您需要每天生成一个这样的数据集，并传递到您的模型中，这样您就可以确定哪些客户可能会流失。我不会在这里详细讨论这个，但是在我的工作中，我们使用气流来编排我们的ETL，所以如果你感兴趣，我建议你去看看。事实上，我最近买了一本名为《使用Apache Airflow的<a class="ae jg" href="https://www.amazon.co.uk/gp/product/1617296902/ref=as_li_tl?ie=UTF8&amp;camp=1634&amp;creative=6738&amp;creativeASIN=1617296902&amp;linkCode=as2&amp;tag=mediumdanny05-21&amp;linkId=1ad3a1bf79e65482860570c3a484a73c" rel="noopener ugc nofollow" target="_blank">数据管道</a>的书，我认为这本书很棒，它给出了一些关于如何使用Airflow的可靠例子和建议。</p><h1 id="02b0" class="kp kq jj bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">Dask和建模</h1><p id="8cdb" class="pw-post-body-paragraph ln lo jj lp b lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">现在我们已经建立了数据管道，我们可以开始考虑建模了。我写这篇文章的另一个主要目的是强调在ML开发过程中使用Dask的优势，并向你们展示它的易用性。</p><p id="6560" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">对于项目的这一部分，我还使用了<a class="ae jg" href="https://www.saturncloud.io/s/?utm_source=daniel-foley" rel="noopener ugc nofollow" target="_blank"> Saturn Cloud </a>，这是我最近遇到的一个非常好的工具，它允许我们在云中的计算机集群上利用Dask的能力。对我来说，使用Saturn的主要优势是，分享您的工作非常容易，在您需要时扩展您的计算非常简单，并且它有一个免费的层选项。一般来说，模型开发对于Dask来说是一个非常好的用例，因为我们通常想要训练一堆不同的模型，看看什么最有效。我们做得越快越好，因为我们有更多的时间关注模型开发的其他重要方面。与雪花类似，你只需要在这里注册<a class="ae jg" href="https://www.saturncloud.io/s/?utm_source=daniel-foley" rel="noopener ugc nofollow" target="_blank"/>，你就可以非常快速地建立一个Jupyter实验室的实例，并开始自己进行实验。</p><p id="36bc" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">现在，我意识到在这一点上我提到过几次Dask，但从未真正解释过它是什么。所以让我花一点时间给你一个非常高层次的概述Dask和为什么我认为它是可怕的。非常简单，Dask是一个python库，它利用并行计算来允许您在非常大的数据集上处理和执行操作。最好的部分是，如果你已经熟悉Python，那么Dask应该非常简单，因为语法非常相似。</p><p id="89c3" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">下图突出显示了Dask的主要组件。</p><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi og"><img src="../Images/2477fccec4ad7fe06df1c44c87c1ee51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AevKzp_YXucjB2mi"/></div></div></figure><p id="ef04" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">来源:<a class="ae jg" href="https://docs.dask.org/en/latest/" rel="noopener ugc nofollow" target="_blank"> Dask文件</a></p><p id="6131" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">集合允许我们创建一个可以在多台计算机上执行的任务图。其中一些数据结构可能听起来很熟悉，比如数组和数据框，它们与python中的数据结构相似，但有一些重要的区别。例如，您可以将Dask数据帧想象为一组pandas数据帧，它们的构建方式允许我们并行执行操作。</p><p id="2b07" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">从集合开始，我们有了调度器。一旦我们创建了任务图，调度程序就会为我们处理剩下的工作。它管理工作流，并将这些任务发送到单台机器或分布到整个集群。希望这能让你对Dask的工作原理有一个简单的了解。要了解更多信息，我建议查看一下<a class="ae jg" href="https://docs.dask.org/en/latest/" rel="noopener ugc nofollow" target="_blank">文档</a>或者这本<a class="ae jg" href="https://www.amazon.co.uk/gp/product/1617295604/ref=as_li_tl?ie=UTF8&amp;camp=1634&amp;creative=6738&amp;creativeASIN=1617295604&amp;linkCode=as2&amp;tag=mediumdanny05-21&amp;linkId=fbcbf83b35fe6ce3c909ba9ece7001af" rel="noopener ugc nofollow" target="_blank">书</a>。两者都是深入探讨这个主题的很好的资源。</p><h1 id="cb5c" class="kp kq jj bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">用于建模的Python代码</h1><p id="bd0d" class="pw-post-body-paragraph ln lo jj lp b lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">建模时，我倾向于先尝试少量的算法。这通常会给我一个好主意，什么可能适合我的具体问题。这些模型是逻辑回归、随机森林和梯度推进。根据我的经验，当处理表格数据时，这些算法通常会给你很好的结果。下面我们用这三个模型建立一个sklearn模型管道。我们在这里使用的确切模型并不重要，因为管道应该适用于任何sklearn分类模型，这只是我的偏好。</p><p id="4650" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">事不宜迟，让我们深入研究代码。幸运的是，我们将大部分预处理外包给了雪花，因此我们不必在这里过多地摆弄我们的训练数据，但我们将使用sklearn管道添加一些额外的步骤。</p><p id="b009" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">下面的第一段代码展示了使用sklearn时的管道。请注意，我们的数据集是一个普通的旧pandas数据帧，我们的预处理步骤都是使用sklearn方法执行的。这里没有什么特别不寻常的事情。我们从雪花ETL生成的表中读入数据，并将其传递给sklearn管道。通常的建模步骤在这里适用。我们将数据集分为训练和测试，并做一些预处理，即使用中位数估算缺失值，缩放数据并一次性编码我们的分类数据。我是sklearn管道的忠实粉丝，现在每当我开发模型时，基本上都使用它们，它们确实有助于代码简洁明了。</p><p id="e5c9" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">这个管道在大约有200万行的数据集上表现如何？在没有任何超参数调整的情况下运行这个模型大约需要34分钟。哎哟，有点慢。你可以想象，如果我们想要进行任何类型的超参数调整，这将需要多长时间。好吧，不太理想，但让我们看看Dask是如何应对挑战的。</p><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="oe of l"/></div></figure></div><div class="ab cl oh oi hx oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="im in io ip iq"><h1 id="970e" class="kp kq jj bd kr ks oo ku kv kw op ky kz la oq lc ld le or lg lh li os lk ll lm bi translated">Dask ML Python代码</h1><p id="0919" class="pw-post-body-paragraph ln lo jj lp b lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">我们的目标是看看我们是否能打败上面的sklearn管道，剧透一下，我们肯定能。Dask很酷的一点是，当你已经熟悉python时，入门的门槛相当低。我们可以在Dask中建立并运行这条管道，只需做一些更改。</p><p id="6237" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">你可能会注意到的第一个变化是我们有了一些不同的进口。这条管道与前一条管道的主要区别之一是，我们将使用Dask数据框架而不是pandas数据框架来训练我们的模型。你可以把Dask数据帧想象成一堆熊猫数据帧，我们可以同时对每个数据帧进行计算。这是Dask并行性的核心，也是减少该管道培训时间的原因。</p><p id="5e63" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">注意我们使用<strong class="lp jt"> <em class="mz"> @dask.delayed </em> </strong>作为我们的<strong class="lp jt"><em class="mz">load _ training _ data</em></strong>函数的装饰器。这指示Dask为我们并行这个功能。</p><p id="4036" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">我们还将从Dask导入一些预处理和管道方法，最重要的是，我们将需要导入SaturnCluster，这将允许我们创建一个用于训练模型的集群。这段代码的另一个关键区别是，在我们的训练测试分割之后，我们使用了<strong class="lp jt"> <em class="mz"> dask.persist </em> </strong>。在这之前，由于Dask的懒惰计算，我们的函数实际上没有被计算过。一旦我们使用了persist方法，我们就告诉Dask将我们的数据发送给workers，并执行到目前为止我们已经创建的任务，并将这些对象留在集群上。</p><p id="6f84" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">最后，我们使用延迟方法训练我们的模型。同样，这使我们能够以一种懒惰的方式创建我们的管道。在我们到达以下代码之前，管道不会被执行:</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="047d" class="no kq jj nk b gy np nq l nr ns">fit_pipelines = dask.compute(*pipelines_)</span></pre><figure class="nf ng nh ni gt iv"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="125a" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">这一次，我们只花了大约10分钟就在完全相同的数据集上运行了这条管道。这是3.4倍的加速，不算太差。现在，如果我们想的话，我们可以通过在土星上按一下按钮来扩大我们的计算资源，从而进一步加快速度。</p><h1 id="6bf4" class="kp kq jj bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">部署我们的管道</h1><p id="4ff0" class="pw-post-body-paragraph ln lo jj lp b lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">我之前提到过，你可能希望使用类似气流这样的东西，定期运行这样的管道。碰巧的是，如果你不想为气流设置一切的最初麻烦，土星云提供了一个简单的替代工作。作业允许我们打包代码，并定期或根据需要运行它。您只需转到一个现有项目，然后单击create a job。一旦我们这样做了，它应该看起来如下:</p><figure class="nf ng nh ni gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ot"><img src="../Images/30e8007a08efffc945d8e9d1e1b416ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oRqCk7LiC3cgXOWc"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:<a class="ae jg" href="https://saturncloud.io/docs/using-saturn-cloud/jobs_and_deployments/" rel="noopener ugc nofollow" target="_blank">土星</a></p></figure><p id="6e54" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">从这里开始，我们需要做的就是确保我们上面的python文件在图像中的目录中，并且我们可以输入上面的python命令</p><pre class="nf ng nh ni gt nj nk nl nm aw nn bi"><span id="6675" class="no kq jj nk b gy np nq l nr ns">python -m ml_pipeline -w 102 -j 'train'</span></pre><p id="99e3" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated">如果愿意，我们还可以使用cron语法设置一个时间表，每天运行ETL。对于那些感兴趣的人来说，这里有一个<a class="ae jg" href="https://saturncloud.io/docs/using-saturn-cloud/jobs_and_deployments/" rel="noopener ugc nofollow" target="_blank">教程</a>，可以深入到所有的细节。</p><h1 id="26f0" class="kp kq jj bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">结论和要点</h1><p id="ffce" class="pw-post-body-paragraph ln lo jj lp b lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk im bi translated">好了，我们现在已经到了项目的尾声。显然，我已经忽略了ML开发周期中的一些关键部分，例如超参数调整和部署我们的模型，但也许我会留待以后再说。我觉得你应该试试达斯克吗？我绝不是专家，但就我目前所见，它确实非常有用，作为一名数据科学家，我非常兴奋能够对它进行更多的实验，并找到更多的机会将其融入我的日常工作中。希望您发现这很有用，并且您也可以看到雪花和Dask的一些优点，并且您将开始自己尝试它们。</p><h1 id="ba27" class="kp kq jj bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">资源</h1><ul class=""><li id="7835" class="mq mr jj lp b lq lr lu lv ly ou mc ov mg ow mk mv mw mx my bi translated"><a class="ae jg" href="https://www.amazon.co.uk/gp/product/1617296902/ref=as_li_tl?ie=UTF8&amp;camp=1634&amp;creative=6738&amp;creativeASIN=1617296902&amp;linkCode=as2&amp;tag=mediumdanny05-21&amp;linkId=1ad3a1bf79e65482860570c3a484a73c" rel="noopener ugc nofollow" target="_blank">带有阿帕奇气流的数据管道</a></li><li id="98a4" class="mq mr jj lp b lq na lu nb ly nc mc nd mg ne mk mv mw mx my bi translated"><a class="ae jg" href="https://www.amazon.co.uk/gp/product/1800560613/ref=as_li_tl?ie=UTF8&amp;camp=1634&amp;creative=6738&amp;creativeASIN=1800560613&amp;linkCode=as2&amp;tag=mediumdanny05-21&amp;linkId=b016babb9c48e7f068b4a6bfa70c403c" rel="noopener ugc nofollow" target="_blank">雪花食谱</a></li><li id="b125" class="mq mr jj lp b lq na lu nb ly nc mc nd mg ne mk mv mw mx my bi translated"><a class="ae jg" href="https://www.amazon.co.uk/gp/product/1617295604/ref=as_li_tl?ie=UTF8&amp;camp=1634&amp;creative=6738&amp;creativeASIN=1617295604&amp;linkCode=as2&amp;tag=mediumdanny05-21&amp;linkId=fbcbf83b35fe6ce3c909ba9ece7001af" rel="noopener ugc nofollow" target="_blank">使用Python和Dask实现大规模数据科学</a></li><li id="be44" class="mq mr jj lp b lq na lu nb ly nc mc nd mg ne mk mv mw mx my bi translated"><a class="ae jg" href="https://click.linksynergy.com/deeplink?id=z2stMJEP3T4&amp;mid=40328&amp;murl=https%3A%2F%2Fwww.coursera.org%2Fspecializations%2Flearn-sql-basics-data-science%23courses" rel="noopener ugc nofollow" target="_blank"> Coursera:数据科学的SQL</a></li></ul><h1 id="2516" class="kp kq jj bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">我的其他一些帖子你可能会感兴趣</h1><div class="is it gp gr iu ox"><a rel="noopener follow" target="_blank" href="/lets-build-a-streaming-data-pipeline-e873d671fc57"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd jt gy z fp pc fr fs pd fu fw js bi translated">让我们建立一个流数据管道</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">用于实时数据管道的Apache Beam和数据流</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">towardsdatascience.com</p></div></div><div class="pg l"><div class="ph l pi pj pk pg pl ja ox"/></div></div></a></div><div class="is it gp gr iu ox"><a rel="noopener follow" target="_blank" href="/gaussian-mixture-modelling-gmm-833c88587c7f"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd jt gy z fp pc fr fs pd fu fw js bi translated">高斯混合模型(GMM)</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">使用无监督学习理解文本数据</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">towardsdatascience.com</p></div></div><div class="pg l"><div class="pm l pi pj pk pg pl ja ox"/></div></div></a></div><div class="is it gp gr iu ox"><a rel="noopener follow" target="_blank" href="/a-bayesian-approach-to-time-series-forecasting-d97dd4168cb7"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd jt gy z fp pc fr fs pd fu fw js bi translated">时间序列预测的贝叶斯方法</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">今天，我们将从头开始在R中实现贝叶斯线性回归，并使用它来预测美国的GDP增长…</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">towardsdatascience.com</p></div></div><div class="pg l"><div class="pn l pi pj pk pg pl ja ox"/></div></div></a></div><p id="09ed" class="pw-post-body-paragraph ln lo jj lp b lq ml ls lt lu mm lw lx ly mn ma mb mc mo me mf mg mp mi mj mk im bi translated"><em class="mz">注意:这篇文章中的一些链接是附属链接。</em></p></div></div>    
</body>
</html>