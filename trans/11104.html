<html>
<head>
<title>MS-DAYOLO: Multiscale Domain Adaptive YOLO for Cross-Domain Object Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MS-DAYOLO:用于跨域目标检测的多尺度域自适应YOLO</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ms-dayolo-multiscale-domain-adaptive-yolo-for-cross-domain-object-detection-d7912a9de975?source=collection_archive---------28-----------------------#2021-10-29">https://towardsdatascience.com/ms-dayolo-multiscale-domain-adaptive-yolo-for-cross-domain-object-detection-d7912a9de975?source=collection_archive---------28-----------------------#2021-10-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f8c8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">提高检测器对畴变的鲁棒性</h2></div><p id="7964" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当测试数据的分布与训练数据的分布不同时，会发生域转移问题，导致目标检测模型的性能下降。例如，对象检测器是针对在晴朗天气和有利天气下捕获的图像数据进行训练的，但它适用于测试阶段的恶劣天气场景，包括灰尘、雨或雾。虽然已经提出了许多先进的对象检测方法，包括R-CNN网络家族(R-CNN，Fast R-CNN，Faster R-CNN，Cascade R-CNN)或YOLO系列(YOLOv1-v4)，但研究人员只专注于在基准数据集上的性能，如COCO，VOC，WAYMO，Cityscapes等。其中包括干净图像数据和对象检测中的域移动。近年来，这个主题被更广泛地研究，有时它被称为术语<em class="lb">领域适应</em>。在这篇文章的剩余部分，我将回顾一个新的多尺度域自适应YOLO (MS-DAYOLO)框架，用于跨域对象检测。</p><h1 id="fa56" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">戴约洛女士</h1><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi lu"><img src="../Images/8cc699fc8afe98038095e1e5e444eaec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8aFLQJ6XrZdY8HcnteirRw.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">MS- DAYOLO的建筑(图片见诸报端[ <a class="ae mk" href="https://arxiv.org/abs/2106.01483" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="c261" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">MS-DAYOLO的架构如上图所示。一般来说，MS-DAYOLO是基于YOLOv4开发的，它几乎采用了YOLOv4的主要组件。主要区别在于，有一个域自适应网络(DAN ),它连接到主干上，以鼓励主干学习域不变特征。具体来说，如上图所示，DAN连接到主干中的特征地图F1、F2和F3。作者已经考虑利用特征图F1、F2和F3，因为这些特征被直接馈送到检测器的颈部，从而它们携带了输入图像的主要信息，这可能有利于训练DAN。</p><h1 id="9a2a" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated"><strong class="ak">域自适应网络(丹)</strong></h1><p id="3460" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">为了避免获得实时对象检测器中最重要的计算，DAN仅在训练期间被集成到主干中。DAN的任务是预测输入图像是否在<em class="lb">源域</em>(完成训练的域)或<em class="lb">目标域</em>(没有训练模型的新的域)。</p><p id="72b1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">DAN被优化以最小化域分类损失<em class="lb"> L_dc </em>，其被计算为以下二元交叉熵损失函数:</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/72871b9d99e0ff31042060db1df03d63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*4hIzreo-jcf6sVsgFFrF9w.png"/></div></figure><p id="0245" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<em class="lb"> i </em>为训练图像的索引，<em class="lb"> t_i </em>为领域标号(<em class="lb"> t_i </em> = 1:源领域，<em class="lb"> t_i </em> = 0:目标领域)，<em class="lb"> p(x，y) </em>为特征图位置<em class="lb"> (x，y) </em>处的预测领域概率。</p><p id="3187" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一方面训练骨干最大化<em class="lb"> L_dc </em>学习不变特征。也就是说，为了使对象检测器对域的变化具有鲁棒性，应该鼓励检测器学习输入图像中的显著内容(或显著对象),即使图像是在任何条件下捕获的。如果这一过程操作得当，可以提高检测机的性能和稳健性。</p><p id="492a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">丹被优化为最小化<em class="lb"> L_dc </em>，而骨干被训练为最大化<em class="lb"> L_dc </em>，这导致了联合最小值-最大值问题。</p><h1 id="a625" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">总损失</h1><p id="fadb" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">总损失函数公式如下:</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/ae35765d0bc4780e749e4fc25228078b.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*s9lFINEWeZRsLIEHH_jP8Q.png"/></div></figure><p id="a62a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<em class="lb"> L_det </em>是检测损耗，而<em class="lb"> λ </em>是用于平衡总损耗的负标量。<em class="lb"> λ </em>的负值可以解释为解决前段提到的联合最小-最大问题。换句话说，<em class="lb"> λ </em>负责控制DAN对整个网络性能的影响。关于<em class="lb"> λ </em>的进一步详细解释可以在<a class="ae mk" href="https://arxiv.org/abs/2106.01483" rel="noopener ugc nofollow" target="_blank">论文</a>中找到。</p><h1 id="5e34" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">结果</h1><p id="3cfa" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">表1显示了Cityscapes数据集上不同适应配置的定量结果。表中，<em class="lb"> P </em>、<em class="lb"> R </em>、<em class="lb"> C </em>、<em class="lb"> M </em>和<em class="lb"> B </em>是代表人、骑手、汽车、摩托车和自行车的类别名称。通过对DAN采用所有三个特征映射F1、F2和F3，已经实现了最佳性能。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/f1019a87acd167daf57b6543dfafbbe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*q27hNJCKflJomLTOqDeAmg.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">表Cityscapes数据集的定量结果(论文中的表格[ <a class="ae mk" href="https://arxiv.org/abs/2106.01483" rel="noopener ugc nofollow" target="_blank">来源</a> ])</p></figure><p id="17ae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">表2显示了在BDD100K和INIT数据集上验证YOLOv4和MS-DAYOLO时的性能比较。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/c8664bb329d289800381939b3054f45f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*ltKh1u38caDKQsWTsdmf0A.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">表BDD100K和INIT数据集的定量结果(论文中的表格[ <a class="ae mk" href="https://arxiv.org/abs/2106.01483" rel="noopener ugc nofollow" target="_blank">来源</a> ])</p></figure><p id="3d2e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用YOLOv4和MS-DAYOLO对雾状图像数据进行目视检测的结果如下图所示:</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/2fcf27ee4007852fa8c3a733492b8885.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*8AoNVwDbdOXK4UosUjohVQ.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">视觉检测结果:(a)清晰图像上的YOLOv4，(b)模糊图像上的YOLOv4，(c)模糊图像上的MS-DAYOLO。(论文中的图像[ <a class="ae mk" href="https://arxiv.org/abs/2106.01483" rel="noopener ugc nofollow" target="_blank">来源</a> ])</p></figure><h1 id="f3f8" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">结论</h1><p id="d96f" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在这篇文章中，我简要回顾了一种新的多尺度域自适应YOLO (MS-DAYOLO)框架，用于跨域对象检测。正如论文中提到的，MS-DAYOLO是第一个提出考虑改进YOLO模型来处理畴变问题的工作。在自动驾驶应用的各种测试场景下，MS-DAYOLO已被证明优于最初的YOLOv4。</p><p id="5533" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">欢迎读者访问我的脸书粉丝页面，这是一个分享关于机器学习的事情的页面:<a class="ae mk" href="https://www.facebook.com/diveintomachinelearning" rel="noopener ugc nofollow" target="_blank">深入机器学习</a>。我发布的关于物体检测的其他值得注意的帖子包括:</p><ul class=""><li id="665c" class="mv mw iq kh b ki kj kl km ko mx ks my kw mz la na nb nc nd bi translated"><a class="ae mk" rel="noopener" target="_blank" href="/yolov4-5d-an-enhancement-of-yolov4-for-autonomous-driving-2827a566be4a">约洛夫4–5D评论</a></li><li id="0df6" class="mv mw iq kh b ki ne kl nf ko ng ks nh kw ni la na nb nc nd bi translated"><a class="ae mk" rel="noopener" target="_blank" href="/darkeras-execute-yolov3-yolov4-object-detection-on-keras-with-darknet-pre-trained-weights-5e8428b959e2">达克拉斯</a></li><li id="2838" class="mv mw iq kh b ki ne kl nf ko ng ks nh kw ni la na nb nc nd bi translated"><a class="ae mk" rel="noopener" target="_blank" href="/efpn-extended-feature-pyramid-network-for-small-object-detection-980af794a093"> EFPN </a></li><li id="6476" class="mv mw iq kh b ki ne kl nf ko ng ks nh kw ni la na nb nc nd bi translated"><a class="ae mk" rel="noopener" target="_blank" href="/data-augmentation-compilation-with-python-and-opencv-b76b1cd500e0">数据增强</a></li><li id="bc77" class="mv mw iq kh b ki ne kl nf ko ng ks nh kw ni la na nb nc nd bi translated"><a class="ae mk" rel="noopener" target="_blank" href="/synthesize-hazy-foggy-image-using-monodepth-and-atmospheric-scattering-model-9850c721b74e">雾霾数据合成</a></li></ul><p id="44ba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">感谢您抽出时间！</p></div></div>    
</body>
</html>