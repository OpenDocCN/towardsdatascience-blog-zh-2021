<html>
<head>
<title>Building a Hybrid Fake News Detective App with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python构建混合假新闻侦探应用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-hybrid-fake-news-detective-app-with-python-28ba87638ade?source=collection_archive---------16-----------------------#2021-07-09">https://towardsdatascience.com/building-a-hybrid-fake-news-detective-app-with-python-28ba87638ade?source=collection_archive---------16-----------------------#2021-07-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="20c7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用无监督K均值和有监督支持向量分类器算法的组合</h2></div><p id="2b10" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当今世界，网络上到处都是新闻。我们可以在CNN、BBC News、India Today、NDTV和Times of India等各种新闻网站以及脸书、Twitter和Instagram等社交媒体网站上轻松找到它们，只需轻点鼠标。新闻的目的是让我们了解身边正在发生的事情。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/e31e0784bf65dfbd29b2eadb57601058.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dQrXnWDwWMTNLj2b"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">路易斯·科尔特斯在<a class="ae lr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="58bd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不幸的是，我们今天听到的消息的可信度值得怀疑。有人很容易在社交媒体网站上发布随机的东西，而不验证它是否真实。一些人，特别是政党成员，也可能在社交媒体网站上组建团体，歪曲新闻，恶意传播宣传，误导人们，转移对实际问题的注意力。尽管如此，许多主流新闻频道和报纸还是带着选择性的偏见进行报道，传播针对个人和社区的仇恨、阴谋论，其唯一目的是获得更多的电视收视率或简称为TRP。也就是说，民主的第四大支柱正在瓦解。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ls"><img src="../Images/f3a0d19b94eae8d5da5fe89c0cb62387.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-Cmndkowr5c2SUTf"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">照片由<a class="ae lr" href="https://unsplash.com/@pixel_talkies?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Nijwam Swargiary </a>在<a class="ae lr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="35ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">新闻来源的可信度在新冠肺炎疫情期间创下新低。这一时期出现了各种错误信息运动，特别是在美国，劝说人们不要遵循COVID适当的行为和接种疫苗。因此，在相信这个消息之前，核实事实是必要的。</p><p id="19fa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">于是出现了各种事实核查组织，如Alt News、BOOM和Factly，它们核查一篇新闻文章的可靠性。这些组织通过与目击者或有关当局核实，对新闻文章进行人工分类。但是，在许多情况下，他们可以认为反对他们意识形态的新闻文章是假的。所以，这些事实核查网站的可靠性也值得怀疑。因此，我们需要的是一种对新闻标题进行分类的AI方式。这在自然语言处理中是可能的。</p><h1 id="1d0d" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated"><strong class="ak">为什么要混合模式？</strong></h1><p id="b099" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">现在的问题是，我们应该使用哪种方法。一般情况下，我们使用监督学习算法对新闻进行分类。这种方法有两个问题:</p><ol class=""><li id="7a15" class="mq mr iq kh b ki kj kl km ko ms ks mt kw mu la mv mw mx my bi translated">首先，通常可用的数据集都有新闻标题，这些标题被一些事实核查机构手动标记为真实或虚假。我们永远不能确定这个组织是公正的。</li><li id="e429" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la mv mw mx my bi translated">第二，监督学习算法需要这些标签进行训练。因此，人们最终偏向了分类器，违背了使用人工智能的初衷。</li></ol><p id="07c4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们必须明白，在极少数情况下，消息肯定是真的或假的。大多数情况下，我们无法确定。所以，我们应该寻找的是，新闻是真是假的概率。</p><p id="c983" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用的模型是由<strong class="kh ir">非监督K均值聚类算法</strong>和<strong class="kh ir">监督支持向量分类算法</strong>混合而成的。K Means算法通过捕捉特定单词的用法将新闻标题组织成簇。支持向量算法从这些聚类中学习，并预测未知新闻标题所属的类别。</p><p id="ba2b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你想了解我的仪表盘是什么样子，请访问https://fake-news-headlines-detective.herokuapp.com/<a class="ae lr" href="https://fake-news-headlines-detective.herokuapp.com/" rel="noopener ugc nofollow" target="_blank"/>。</p><h1 id="64a5" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated"><strong class="ak">数据来源:</strong></h1><p id="35fa" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">除了我在上一节提到的原因，通常可用的数据集包含来自美国的新闻。因此，我必须自己创建一个数据集，通过收集热门新闻网站的新闻标题进行训练，如《印度时报》、《新闻18》、《印度快报》和《共和世界》。此外，我还从Op India、News Punch和Great Game India等纯数字新闻网站收集了这些信息，这些网站被国际事实核查网络(IFCN)视为假新闻网站。</p><p id="e0cc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了训练，我从印度和美国的各种来源收集了14787个标题。GitHub存储库中有这个数据集。同样的链接是<a class="ae lr" href="https://github.com/pradeepprajan/Fake-News-Detective" rel="noopener ugc nofollow" target="_blank">https://github.com/pradeepprajan/Fake-News-Detective</a>。您还可以找到包含Python代码的Jupyter笔记本。</p><h1 id="792b" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated"><strong class="ak">安装必要的软件包:</strong></h1><p id="b45d" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">除了常用的软件包之外，我们还需要安装以下特定于dashboard应用程序的软件包:</p><ol class=""><li id="3852" class="mq mr iq kh b ki kj kl km ko ms ks mt kw mu la mv mw mx my bi translated">自然语言工具包(NLTK)</li><li id="ac50" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la mv mw mx my bi translated">海生的</li><li id="1811" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la mv mw mx my bi translated">Scikit学习</li><li id="ce95" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la mv mw mx my bi translated">Plotly</li><li id="934b" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la mv mw mx my bi translated">破折号</li><li id="e7e9" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la mv mw mx my bi translated">仪表板引导组件</li></ol><h1 id="eabb" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated"><strong class="ak">第1部分:用K-Means对标题进行聚类</strong></h1><h2 id="fb23" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated">导入必要的库</h2><p id="4762" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在开始之前，我们导入必要的库。可以参考我分享过的GitHub库中的Jupyter笔记本。</p><h2 id="e34e" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated"><strong class="ak">数据的读取和预处理:</strong></h2><p id="f6a7" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">首先，我们读取收集的训练数据集。因为数据集中的行是按照新闻源排序的，所以我们对它们进行了洗牌。</p><pre class="lc ld le lf gt nq nr ns nt aw nu bi"><span id="06ee" class="ne lu iq nr b gy nv nw l nx ny">dataset = pd.read_csv('NewsArticles.csv',encoding='unicode escape')<br/>dataset = dataset.drop(columns=['Unnamed: 0'])<br/>dataset_copy = dataset.copy()<br/>dataset_copy = dataset_copy.sample(frac=1).reset_index(drop=<strong class="nr ir">True</strong>)</span></pre><h2 id="2fb9" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated"><strong class="ak">一些探索性的数据分析:</strong></h2><p id="fcb6" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">我们找到每个来源发布的新闻文章的数量，并构建一个条形图。</p><pre class="lc ld le lf gt nq nr ns nt aw nu bi"><span id="b3e2" class="ne lu iq nr b gy nv nw l nx ny">news_articles_count = dataset_copy.groupby('Source_code',as_index=<strong class="nr ir">False</strong>).count()<br/>news_articles_count = news_articles_count.rename(columns={'Headlines' : 'Article_Count'})<br/>news_articles_count = news_articles_count.drop(columns='Sources')news_articles_bar_plot = sns.barplot(x=news_articles_count['Source_code'],y=news_articles_count['Article_Count'])</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nz"><img src="../Images/a2c0a9cc6ea0cda6f0a52ae4479ec5be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Clk9KFPe4EMXkY9HMixw9g.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者图片</p></figure><h2 id="3cbc" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated">创建单词语料库:</h2><p id="ed62" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">现在，我们创建一个单词语料库。在此过程中，我们执行以下操作:</p><ol class=""><li id="ba0d" class="mq mr iq kh b ki kj kl km ko ms ks mt kw mu la mv mw mx my bi translated">删除特殊字符，因为它们对我们的模型没什么用。</li><li id="9e1c" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la mv mw mx my bi translated">将大写字母更改为小写字母，因为我们希望我们的模型将大写和小写的同一个单词识别为一个单词。比如新闻，新闻，新闻，要被算法识别为一个词。</li><li id="7d84" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la mv mw mx my bi translated">将标题符号化，即将标题拆分成单词。</li><li id="d95b" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la mv mw mx my bi translated">将单词词条化。它将单词转换成有意义的基本形式。</li></ol><p id="db86" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在创建语料库之前，我们安装了S <strong class="kh ir"> topwords </strong>、<strong class="kh ir"> Punkt、</strong>和<strong class="kh ir"> Wordnet </strong>字典。</p><pre class="lc ld le lf gt nq nr ns nt aw nu bi"><span id="50a9" class="ne lu iq nr b gy nv nw l nx ny">lemmatizer = WordNetLemmatizer()<br/>nltk.download('stopwords')<br/>nltk.download('punkt')<br/>nltk.download('wordnet')</span><span id="ed7c" class="ne lu iq nr b gy oa nw l nx ny">corpus = []<br/><strong class="nr ir">for</strong> i <strong class="nr ir">in</strong> range(0,len(dataset_copy)):<br/>message = re.sub('[^a-zA-Z0-9]', ' ', dataset_copy['Headlines'][i])<br/>message = message.lower()<br/>message = word_tokenize(message)<br/>message = [lemmatizer.lemmatize(w) <strong class="nr ir">for</strong> w <strong class="nr ir">in</strong> message <strong class="nr ir">if</strong> <strong class="nr ir">not</strong> w <strong class="nr ir">in</strong> stopwords.words('english')]<br/>message = ' '.join(message)<br/>corpus.append(message)<br/>print(corpus)</span></pre><h2 id="08be" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated"><strong class="ak">将单词库转换成向量:</strong></h2><p id="d0e0" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">我们通过<strong class="kh ir"> TF-IDF(词频-逆文档频)矢量化</strong>将词语料库中的标题转化为向量。此外，我们将每个向量的维数限制为1000。</p><pre class="lc ld le lf gt nq nr ns nt aw nu bi"><span id="e4b2" class="ne lu iq nr b gy nv nw l nx ny">tfidf_v = TfidfVectorizer(max_features=1000)<br/>X = tfidf_v.fit_transform(corpus).toarray()</span></pre><h2 id="5da8" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated"><strong class="ak">特征缩放:</strong></h2><p id="fae7" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在执行任何非监督分类之前，特征缩放是<strong class="kh ir">必须的</strong>。</p><pre class="lc ld le lf gt nq nr ns nt aw nu bi"><span id="7f2d" class="ne lu iq nr b gy nv nw l nx ny">scaler = StandardScaler()<br/>X = scaler.fit_transform(X)</span></pre><h2 id="dd99" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated"><strong class="ak">应用PCA: </strong></h2><p id="85f1" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">因为形成的每个向量的维数是1000，所以我们应用PCA。这消除了维数灾难。</p><pre class="lc ld le lf gt nq nr ns nt aw nu bi"><span id="b35f" class="ne lu iq nr b gy nv nw l nx ny">pca = PCA(n_components=2)<br/>pca_result = pca.fit_transform(X)</span></pre><h2 id="d012" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated"><strong class="ak"> K均值聚类:</strong></h2><p id="af09" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在执行聚类之前，我们需要使用肘方法找出所需的聚类数。</p><pre class="lc ld le lf gt nq nr ns nt aw nu bi"><span id="1601" class="ne lu iq nr b gy nv nw l nx ny">wcss = []<br/><strong class="nr ir">for</strong> i <strong class="nr ir">in</strong> range(1,20):<br/> kmeans = cluster.KMeans(n_clusters=i,init='k- means++',max_iter=300,n_init=10,random_state=0)<br/> kmeans.fit(pca_result)<br/> wcss.append(kmeans.inertia_)<br/> print("Cluster", i, "Intertia", kmeans.inertia_)<br/> plt.plot(range(1,20),wcss)<br/> plt.title('The Elbow Curve')<br/> plt.xlabel('Number of clusters')<br/> plt.ylabel('WCSS')<br/> plt.show()</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ob"><img src="../Images/dffcb6e718f3682bc764f460af284954.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J7665KgmvWpJfC9uCcQS-w.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者图片</p></figure><p id="0c34" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对应于图中“肘部”的聚类数为6。因此，我们需要6个集群。</p><p id="f7d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们执行聚类。我们还绘制了一个散点图来证明这一点。</p><pre class="lc ld le lf gt nq nr ns nt aw nu bi"><span id="933e" class="ne lu iq nr b gy nv nw l nx ny">Kmeans = cluster.KMeans(n_clusters=6,init='k-means++',max_iter=500,verbose=<strong class="nr ir">True</strong>,random_state=0)<br/>clustered = Kmeans.fit_predict(pca_result)<br/>PCA_df = pd.DataFrame(pca_result) <br/>PCA_df['cluster'] = clustered <br/>PCA_df.columns = ['x1','x2','cluster'] <br/>k_means_figure = sns.scatterplot(data=PCA_df,x='x1',y='x2',hue='cluster',legend="full",alpha=0.5)</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ob"><img src="../Images/1ba6656aee71df5326368ef35438277c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZZpeP-Jj8ZCYomyqxwdGOw.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者图片</p></figure><p id="cc0e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不得不承认聚类并不完美。但是我们必须明白，数据科学就是从获得的结果中推导出结论。因为我们可以从这种聚类中得出新闻的可信度，所以我们可以自信地说K-Means聚类对于可用的数据集工作得很好。结论在文末。</p><h2 id="56ed" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated"><strong class="ak">保存模型:</strong></h2><p id="1331" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在Pickle的帮助下，我们保存模型以备将来使用。</p><pre class="lc ld le lf gt nq nr ns nt aw nu bi"><span id="6729" class="ne lu iq nr b gy nv nw l nx ny">Kmeans = Kmeans.fit(pca_result)<br/>filename = 'news_classifier_KMeans2.sav'<br/>pickle.dump(Kmeans, open(filename, 'wb'))</span></pre><h1 id="3727" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">第二部分:预测那些看不见的标题群</h1><h2 id="1994" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated"><strong class="ak">监督培训</strong></h2><p id="1a70" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">我们首先创建一个pandas数据框，其中包含用于训练的标题和由K-Means算法分配的聚类(在“预测”列下)。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/765f2d684cadb6e79e61cc94a6a12582.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*mvktzFnSw2y12WxY4WseOg.png"/></div></figure><p id="acf0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们使用监督分类算法，如<strong class="kh ir">逻辑回归</strong>、<strong class="kh ir">K-最近邻、</strong>和<strong class="kh ir">支持向量分类器</strong>，对用于“预测”列聚类的相同新闻标题进行训练，然后选择具有最高准确度的算法。相同的代码可以在我的GitHub库中找到。结果总结如下:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi od"><img src="../Images/4196475bef12ccb93f77d240a02c336b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*8P-KU6EvaQS0a-0LepdN_Q.png"/></div></figure><p id="e800" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从表中我们发现<strong class="kh ir">支持向量分类器</strong>和<strong class="kh ir">朴素贝叶斯</strong>的准确率最高，为99.93 %。在这里，我们用前者来训练。</p><pre class="lc ld le lf gt nq nr ns nt aw nu bi"><span id="dd43" class="ne lu iq nr b gy nv nw l nx ny">SVC_classifier = SVC(C=300,kernel='linear',random_state=0)<br/>SVC_classifier.fit(pca_result,y_train)</span><span id="75f9" class="ne lu iq nr b gy oa nw l nx ny"># y_train is the 'Predictions' column of the Data Frame used for supervised training. </span></pre><h2 id="24d8" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated"><strong class="ak">预测未知标题的聚类:</strong></h2><p id="06ab" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">这是包含未显示标题的表格。我通过使用Newsdata.io提供的API键获得了它们，我们称之为测试数据集。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/65bec22f2125e759f403785eac7da253.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*Q4cqv5mlrFDMrTZ0TyHXhg.png"/></div></figure><p id="9ef1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了获得准确的结果，我们结合测试和训练数据集，并重复预处理步骤。然后，我们将生成的NumPy数组拆分回训练和测试数据集的数组。pca_result_test是测试数据集对应的NumPy数组。</p><p id="e33c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们预测看不见的标题所属的群集:</p><pre class="lc ld le lf gt nq nr ns nt aw nu bi"><span id="05f3" class="ne lu iq nr b gy nv nw l nx ny">clustered_test = SVC_classifier.predict(pca_result_test)</span></pre><p id="e5d4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们再次创建一个熊猫数据框，其中包含看不见的标题和预测的聚类。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi of"><img src="../Images/9264835e349400e26b83226b28897e8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*dXF6m177VY0Nxz6ZgJBj3w.png"/></div></figure><p id="10ba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们将训练和测试数据集的分类编号映射到类别编号1到6，以使分类更加直观。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi og"><img src="../Images/1627b6560ca0374fab2a6fd69995fb07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OAaQH4Lmvw-_HdJnevP-oA.png"/></div></div></figure><p id="3f2e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们最终保存两个数据帧。我们将在创建仪表板应用程序时使用它们。</p><h1 id="55fa" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated"><strong class="ak">第3部分:构建仪表板应用程序并将其部署在Heroku上</strong></h1><p id="5c07" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">最后，我们使用Python的<strong class="kh ir"> Dash </strong>和<strong class="kh ir"> Plotly </strong>包构建了一个交互式web dashboard应用程序，并将其部署在<strong class="kh ir"> Heroku </strong>上。Heroku是一个云平台即服务，开发者可以免费部署他们的应用程序。</p><h1 id="5ada" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated"><strong class="ak">推论和结论:</strong></h1><p id="7948" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">阅读完本文后，您可能想知道K-Means聚类在这种情况下是如何工作的。原因是K-Means分类器通过识别某些词的用法将标题组织成簇。TF-IDF分配给每个单词的值与该单词在标题中出现的次数成正比，与包含该单词的标题的数量成反比。可信度存疑的新闻标题数量较多，拉低了频繁词的TF-IDF值。因此，这些标题的数据点更接近K均值散点图中的原点。另一方面，可信的新闻标题数量较少，因此频繁出现的词具有较高的TF-IDF值。因此，数据点远离散点图中的原点。</p><p id="da54" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">类别描述如下:</p><h2 id="f628" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated">类别1:</h2><p id="af94" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">新闻主要是关于燃料、黄金和白银价格。新闻是假的可能性微乎其微。类别1下的标题数量是53。常用词有— <strong class="kh ir">燃油、汽油、翘尾、黄金、白银、</strong>和<strong class="kh ir">暴跌。</strong></p><h2 id="9343" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated">类别2:</h2><p id="e08a" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">新闻是假的几率稍微高一点。头条大多是关于经济、股市、铁路、航空、汽车、智能手机等。该类别下的标题数量为798个。常用的词有— <strong class="kh ir">市场、俏皮、银行、三星、铁路、Flipkart、</strong>和<strong class="kh ir">制造。</strong></p><h2 id="15fb" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated">类别3:</h2><p id="8f87" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">新闻有中等概率是假的。新闻标题大多是关于健康(大多与COVID相关)、经济、基础设施和技术的。一些政治新闻标题也出现在这个集群中。这个类别有4089个标题。常用的词有<strong class="kh ir">比特币、锁定、COVID、疫苗、限制、解锁、项目</strong>和<strong class="kh ir">销售。</strong></p><h2 id="9f65" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated">类别4:</h2><p id="b1a7" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">发现虚假和被操纵的新闻的概率很高。新闻标题大多与印度和世界的政治以及疫情有关。今天印度国内外主流媒体发表的大部分新闻文章都属于这一类。这一类别还包含说服人们不要服用COVID疫苗的宣传和谣言。但是我们也可以在这里找到一些体育和名人新闻。总共有7018条新闻标题属于这一类。常用词有— <strong class="kh ir"> COVID、疫苗、洗手液、男演员、女演员、网球、火柴、莫迪、拜登、流氓、敌对、列宁主义、愚蠢、</strong>和<strong class="kh ir">叛乱。</strong></p><h2 id="7c41" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated">类别5:</h2><p id="f752" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">找到有偏见的、被操纵的和虚假的新闻的概率非常高。这一类包含了很多宣传。这个分类下有2800个标题。常用词有— <strong class="kh ir">莫迪、拉胡尔·甘地、国会、BJP、自由派、左派、穆斯林、印度教、暴动、政府、巴基斯坦、邪教、骗局、谋杀、</strong>和<strong class="kh ir">中国。</strong></p><h2 id="7301" class="ne lu iq bd lv nf ng dn lz nh ni dp md ko nj nk mf ks nl nm mh kw nn no mj np bi translated">类别6:</h2><p id="d8b5" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">这是一个异常类别。这个类别有29个标题。所有的标题都来自Alt-Market，这是一家以发布假新闻而闻名的新闻媒体。这是他们下一期时事通讯的发布通知。因此，我们可以忽略它们。</p><p id="95fd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是显示每个类别下的文章数量的条形图。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ob"><img src="../Images/c840de5ab3dfedb7e8ebace7374ba490.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ndVmMeOjIQhn5rZItJO-4A.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者图片</p></figure><p id="23dd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">分类1到3下的训练数据集中标题的数量总共是4940，与其他分类下的9847相比要少。相应的百分比分别为33%和67%。</p><p id="705b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那么，我们能从中得出什么结论呢？只有1、2、3类下的新闻标题才值得关注。其他标题下的新闻标题，除了体育标题，一般都是有毒的和固执己见的，更有可能在WhatsApp上转发或发布在脸书和推特上。因此，我们必须半信半疑地对待它们，或者忽略它们。</p></div></div>    
</body>
</html>