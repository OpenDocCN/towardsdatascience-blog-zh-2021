<html>
<head>
<title>Plotting the Learning Curve with a Single Line of Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用一行代码绘制学习曲线</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/plotting-the-learning-curve-with-a-single-line-of-code-90a5bbb0f48a?source=collection_archive---------19-----------------------#2021-04-26">https://towardsdatascience.com/plotting-the-learning-curve-with-a-single-line-of-code-90a5bbb0f48a?source=collection_archive---------19-----------------------#2021-04-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="14d3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">查看您的模型从添加更多训练数据中获益多少</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a1a4fd8024e5acd815fc06cc334b3d05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vfkP4k6WhJzD7KY2GLnmQw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">科林·卡特在<a class="ae ky" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="830d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">学习曲线</em> </strong>是任何数据科学家工具箱中的另一个伟大工具。这是一种可视化技术，可以看到我们的模型从添加更多的训练数据中受益多少。它显示了具有不同数量的训练样本的机器学习模型的训练分数和测试分数之间的关系。通常，交叉验证程序在绘制学习曲线时生效。</p><p id="f4b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个好的ML模型非常适合训练数据，也可以推广到新的输入数据。有时，ML模型可能需要更多的训练实例，以便推广到新的输入数据。添加更多的训练数据有时会有利于模型进行概括，但并不总是如此！我们可以通过查看它的学习曲线来决定是否添加更多的训练数据，以建立一个更具普遍性的模型。</p><p id="5cee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">绘制学习曲线通常需要编写许多行代码，并且消耗更多的时间。但是，多亏了Python <strong class="lb iu"> Yellowbrick </strong>库，现在事情就简单多了！通过正确使用它，我们可以只用一行代码就绘制出学习曲线！在本文中，我们将讨论如何用Yellowbrick绘制学习曲线，并学习如何解读它。</p><h2 id="b2ab" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">先决条件</h2><p id="8949" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">为了充分利用今天的内容，建议阅读我的<a class="ae ky" rel="noopener" target="_blank" href="/k-fold-cross-validation-explained-in-plain-english-659e33c0bc0"> <strong class="lb iu"> k-fold交叉验证浅显易懂的</strong> </a> <strong class="lb iu"> <em class="lv"> </em> </strong>文章的<em class="lv">“使用k-fold交叉验证评估模型的性能”部分。</em></p><p id="6129" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除此之外，最好了解<strong class="lb iu">支持向量机</strong>和<strong class="lb iu">随机森林</strong>算法。这是因为，今天，我们根据这些算法绘制学习曲线。如果你不熟悉它们，就看看我写的以下内容。</p><ul class=""><li id="f9ad" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated"><a class="ae ky" href="https://medium.com/data-science-365/support-vector-machines-with-scikit-learn-555fa56cef25" rel="noopener"> <strong class="lb iu">支持向量机与Scikit-learn </strong> </a></li><li id="2761" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/random-forests-an-ensemble-of-decision-trees-37a003084c6c"> <strong class="lb iu">随机森林——决策树的集合</strong> </a></li></ul><h1 id="bbc8" class="ni lx it bd ly nj nk nl mb nm nn no me jz np ka mh kc nq kd mk kf nr kg mn ns bi translated">安装<strong class="ak">黄砖</strong></h1><p id="2847" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">Yellowbrick 没有默认的Anaconda安装程序。您需要手动安装它。要安装它，打开Anaconda提示符并运行下面的命令。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="754b" class="lw lx it nu b gy ny nz l oa ob">pip install yellowbrick</span></pre><p id="176a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果那对你不起作用，用<strong class="lb iu"> <em class="lv">用户</em> </strong>标签试试下面的。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="64b4" class="lw lx it nu b gy ny nz l oa ob">pip install yellowbrick --user</span></pre><p id="dbf1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者你也可以用<strong class="lb iu">康达锻造</strong>频道试试。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="2150" class="lw lx it nu b gy ny nz l oa ob">conda install -c conda-forge yellowbrick</span></pre><p id="b975" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者用<strong class="lb iu"> DistrictDataLabs </strong>频道试试。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="0a82" class="lw lx it nu b gy ny nz l oa ob">conda install -c districtdatalabs yellowbrick</span></pre><p id="366b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以上任何一种方法都会安装最新版本的Yellowbrick。</p><h1 id="42bc" class="ni lx it bd ly nj nk nl mb nm nn no me jz np ka mh kc nq kd mk kf nr kg mn ns bi translated">绘制学习曲线</h1><p id="8622" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">现在，考虑以下示例代码，其中我们使用Scikit-learn内置的<strong class="lb iu">乳腺癌数据集</strong>绘制了一个<strong class="lb iu"> SVM </strong>和一个<strong class="lb iu">随机森林分类器</strong>的学习曲线。该数据集有30个特征和569个训练样本。让我们看看添加更多数据将有利于SVM和随机森林模型推广到新的输入数据。</p><h2 id="b071" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">学习曲线— SVM</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等到加载Python代码！</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/4c149b9a4523d602d408d6a4525185d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*EFJ6Ih4N9dD11nSQXawe3g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><h2 id="fc69" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">学习曲线—随机森林分类器</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等到加载Python代码！</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/053ba149f3aaf7af4b04040dc9a5312b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*nrIxtE0pSjpb3iBjIi_-fQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><h1 id="5210" class="ni lx it bd ly nj nk nl mb nm nn no me jz np ka mh kc nq kd mk kf nr kg mn ns bi translated">解释</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/6e4dd27c5e430e3871c10ad6fe6b7f70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z7UJJHCygmEMdeBj-ndUUw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="86d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上图中，训练集的准确率标记为<strong class="lb iu">“训练分”</strong>，测试集的准确率标记为<strong class="lb iu">“交叉验证分”</strong>。直到大约175个训练实例，SVC(支持向量分类器)模型的训练分数(左图)远大于测试分数。因此，如果当前数据集的训练实例远少于175个(例如，大约100个)，则添加更多的训练实例将提高泛化能力。但是，在175水平之后，该模型可能不会从添加更多的训练数据中受益。对于随机森林分类器(右图)，我们可以看到训练和测试分数尚未收敛，因此该模型可能会受益于添加更多的训练数据(例如，大约700–1000个训练实例)。</p><h1 id="2a2d" class="ni lx it bd ly nj nk nl mb nm nn no me jz np ka mh kc nq kd mk kf nr kg mn ns bi translated">它是如何工作的！</h1><p id="132b" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">当我们执行<strong class="lb iu"> learning_curve() </strong>函数时，很多工作都是在幕后进行的。我们只需要运行一行代码来绘制学习曲线。这就是黄砖的力量！<strong class="lb iu"> learning_curve() </strong>函数的第一个参数应该是Scikit-learn估计器(这里是SVM或随机森林分类器)。第二个和第三个应该是<strong class="lb iu"> X </strong>(特征矩阵)和<strong class="lb iu"> y </strong>(目标向量)。<strong class="lb iu"> "cv" </strong>定义交叉验证的折叠数。标准值是3、5和10(这里是10)。<strong class="lb iu">评分</strong>参数包含模型的评分方法。在分类上，首选<strong class="lb iu">【准确性】</strong><strong class="lb iu">【roc _ AUC】</strong>。回归中常用<strong class="lb iu">【R2】</strong><strong class="lb iu">【负均方误差】</strong>。除此之外，还有许多评估指标。你可以通过访问<a class="ae ky" href="https://scikit-learn.org/stable/modules/model_evaluation.html" rel="noopener ugc nofollow" target="_blank">这个链接</a>找到他们。</p><p id="78ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们执行<strong class="lb iu"> learning_curve() </strong>函数时，交叉验证过程在后台发生。正因为如此，我们才输入<strong class="lb iu"> X </strong>和<strong class="lb iu"> y </strong>。我们不需要把数据集拆分为<strong class="lb iu"> X_train </strong>、<strong class="lb iu"> y_train </strong>、<strong class="lb iu"> X_test </strong>、<strong class="lb iu"> y_test </strong>。在交叉验证中，根据<strong class="lb iu"> cv </strong>中指定的折叠数在内部进行分割。在这里使用交叉验证可以保证模型的准确性分数不会受到随机数据分割过程的太大影响。如果你只是使用<strong class="lb iu"> train_test_split() </strong>函数<em class="lv">而没有</em> t交叉验证，那么根据你在<strong class="lb iu"> train_test_split() </strong>函数内提供的<strong class="lb iu"> random_state </strong>，准确率会有很大差异。在交叉验证中，使用10次(cv=10)这样迭代的平均值来计算精确度！</p><h1 id="1634" class="ni lx it bd ly nj nk nl mb nm nn no me jz np ka mh kc nq kd mk kf nr kg mn ns bi translated">关键要点</h1><p id="bbff" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">学习曲线是一个很好的工具，你应该把它放在你的机器学习工具包里。它可用于查看您的模型从添加更多训练数据中获益多少。有时，添加更多数据将有利于模型推广到新的输入数据。通常，交叉验证程序在绘制学习曲线时生效，以避免随机数据分割过程的影响。</p><p id="df26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">学习曲线</strong>不应与<strong class="lb iu">验证曲线</strong>混淆，后者用于绘制单个超参数的影响。两条曲线的功能完全不同。如果你有兴趣了解更多关于验证曲线的知识，你可以阅读我的<strong class="lb iu"/><a class="ae ky" rel="noopener" target="_blank" href="/validation-curve-explained-plot-the-influence-of-a-single-hyperparameter-1ac4864deaf8"><strong class="lb iu">验证曲线讲解——绘制单个超参数</strong></a><strong class="lb iu"/>的文章。</p><p id="2925" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读！</p><p id="7233" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本教程由<a class="ae ky" href="https://www.linkedin.com/in/rukshan-manorathna-700a3916b/" rel="noopener ugc nofollow" target="_blank"><em class="lv">Rukshan Pramoditha</em></a><em class="lv">，</em>数据科学365博客作者设计创作。</p><p id="a6a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在https://rukshanpramoditha.medium.com阅读我的其他文章</p><p id="ba4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi">2021–04–26</p></div></div>    
</body>
</html>