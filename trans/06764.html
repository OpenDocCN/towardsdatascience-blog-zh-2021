<html>
<head>
<title>Video analytics at the edge</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">边缘视频分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/video-analytics-at-the-edge-1c1e05c5fd5a?source=collection_archive---------20-----------------------#2021-06-18">https://towardsdatascience.com/video-analytics-at-the-edge-1c1e05c5fd5a?source=collection_archive---------20-----------------------#2021-06-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3dec" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用Raspberry PI和英特尔NCS从CCTV IP摄像机中检测人体</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/470a5c7040ecf6c91423bf7f4ab24777.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BBX2Tbib5IUcoKrRz9S0Rw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">尼克·洛格在<a class="ae kv" href="https://unsplash.com/s/photos/cctv-camera?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="f0fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我最近在家里安装了闭路电视系统。它由4台IP摄像机组成。我希望他们更聪明一点。不要总是看闭路电视录像，如果任何一个摄像机检测到有人，最好能得到通知。这真是一个很酷的东西。我想，如果任何一台摄像机检测到运动，我能在电报中得到一个警报，那就太好了。虽然我开始只是为了好玩，但我学到了很多。从根本上说，它无需云就能在边缘实现视频分析。我在这里分享我的学习，并渴望向你学习，如果有优化的方法。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="6e7b" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">目标</h1><p id="ca03" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">我有4个不同的IP摄像头，可以以25FPS的速度播放720P的视频。我有一个闲置的树莓派，还有一个英特尔Movidius神经计算棒(即第一代NCS)。我希望Raspberry PI和NCS执行人体检测，并在摄像头检测到人体时向我发送电报通知。在构建过程中，我认为有几件事非常重要，它们是</p><p id="74d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">1.我应该能够几乎24/7运行应用程序，这意味着代码应该是高效的。CPU利用率必须尽可能低，以便PI的温度得到控制。</p><p id="a349" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2.我应该会立刻收到通知。最优先考虑的是，一旦发生，人的检测应该尽快完成。</p><p id="92b7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">3.通知应该包含一个图像，以便我可以理解警报的上下文(是谁的人)。</p><p id="3da5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我提前告诉你，第1、2项比我想象的要难多了。</p><h1 id="2411" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">项目开始:</h1><p id="78c6" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">我认为这是一个简单的任务，假设Raspberry pi可以从每个摄像机获得视频帧，NCS可以执行人体检测。然而，这并不容易。</p><p id="93f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">像往常一样，我从普通的OpenCV代码开始，在一台摄像机上读取视频RTSP流，看看它是如何工作的。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="b8ab" class="ng ma iq nc b gy nh ni l nj nk">cap = cv2.VideoCapture(“RTSP URL of the IP Camera”)<br/><br/> <br/><br/>while(True):<br/><br/>    ret, frame = cap.read()<br/><br/>    cv2.imshow('frame',frame)<br/><br/>    if cv2.waitKey(1) &amp; 0xFF == ord('q'):<br/><br/>        break<br/><br/> <br/><br/>cap.release()<br/><br/>cv2.destroyAllWindows()</span></pre><p id="4e3f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，很少有事情不像我预期的那样。首先也是最重要的，在实时获取帧时有巨大的延迟。也就是说，即使没有处理(人工检测),也会有大约5到10秒的延迟，在某些情况下，在运行应用程序的几分钟内，延迟会达到40秒。CPU利用率立即达到100%。在这一点上，我意识到这比我想象的要复杂得多。所以，我不得不从头开始，看看解决这个问题的最好方法是什么。</p><p id="81cb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我的分析过程中，我观察到这种解决方案不需要处理来自相机的每一帧。我们绝对不需要分析一秒钟内产生的25帧。这是我在设计中使用的主要原则之一，我提出了以下设计。什么参数将帮助我们定义系统可以处理的帧数将在后面讨论。</p><h1 id="1c76" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">设计</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/b17760e76dfeabe6892bfcc96a6e221c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YAuSTn208WiwcVjry28iAg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="0314" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如你可能注意到的，这个想法是在每X秒钟内从每个摄像机捕捉N个帧。这并不是使系统有效运行的唯一原因。该解决方案利用了Raspberry pi中可用的硬件加速，因此CPU使用率非常低。这将在我描述GStreamer时详细介绍。帧数和持续时间可变的原因是，它完全基于用于处理帧的硬件的处理能力。据我所知，第一版英特尔NCS能够执行的推理数量较少。正如您所想象的，该图清楚地显示了处理引擎中的瓶颈，因为它必须处理所有的帧。由于我计划利用现有的英特尔NCS，我必须根据NCS的能力调整这些参数。</p><p id="5a7f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为一个起点，我决定在每一秒钟内从每一台摄像机中捕捉一帧。这在我看来是有道理的。因为对于一个人来说，在不到一秒的时间内通过摄像机的观察区域实际上是不可能的。然而，处理引擎有可能无法检测到对象，但这是一个单独的主题，我们将在后面讨论。</p><p id="4a73" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我意识到，当我使用OpenCV时，很难指定我想要捕捉的帧数/秒。因此，探索并发现可能有两种方法来解决这个问题。一个是GStreamer，另一个是FFMPG。所以我决定进一步探索第一个选项GStreamer。</p><p id="078c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我发现GStreamer非常强大，但由于缺乏文档/示例，它非常复杂。所以我开始在youtube上探索一些教程，我发现它们非常有用。我在参考资料部分提到了帮助我学习GStreamer的链接。我相信这对你也会有帮助。</p><h1 id="42ad" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">安装和设置</h1><p id="8971" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">这个实验的源代码可以在这里找到:</p><div class="nm nn gp gr no np"><a href="https://github.com/abypaulvarghese56/Edgevisionpi" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd ir gy z fp nu fr fs nv fu fw ip bi translated">abypaulvarghese56/Edgevisionpi</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">在Raspberry PI 4中从4个不同的IP摄像机捕获RTSP流，并使用英特尔NCS执行人体检测。它…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">github.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od kp np"/></div></div></a></div><p id="2df0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我的第一步是在Raspberry PI中安装GStreamer。这是相当直接的。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="7932" class="ng ma iq nc b gy nh ni l nj nk">sudo apt-get install gstreamer1.0-tools</span></pre><p id="2bf6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一步是为raspberry PI安装英特尔OpenVino toolkit。这是必要的，因为处理引擎是英特尔NCS。我必须安装一个支持英特尔NCS的OpenVINO版本，因为最新版本的OpenVINO只支持英特尔NCS 2。请点击下面的链接，并根据您拥有的NCS安装OpenVINO。</p><div class="nm nn gp gr no np"><a href="https://docs.openvinotoolkit.org/latest/openvino_docs_install_guides_installing_openvino_raspbian.html" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd ir gy z fp nu fr fs nv fu fw ip bi translated">为Raspbian* OS安装OpenVINO工具包- OpenVINO工具包</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">注意:这些步骤适用于32位Raspbian*操作系统，这是Raspberry Pi*主板的官方操作系统。这些步骤已经…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">docs.openvinotoolkit.org</p></div></div></div></a></div><p id="5491" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其他库包括:</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="de9e" class="ng ma iq nc b gy nh ni l nj nk">pip install telepot<br/>pip install viztracer<br/><br/>sudo apt-get install pkg-config libcairo2-dev gcc python3-dev libgirepository1.0-dev<br/>sudo apt-get install python3-gi<br/><br/>pip install gobject PyGObject</span></pre><p id="2900" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一步是创建GStreamer管道。正如我前面提到的，它是非常强大的工具。Gstreamer通过使用管道来配置，管道是一系列命令，指定从哪里获取视频，如何处理和编码视频，然后将视频发送到哪里。</p><p id="a888" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看看我创建的管道。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="7228" class="ng ma iq nc b gy nh ni l nj nk">pipelinestring = "rtspsrc location={0} name=m_rtspsrc ! rtph264depay ! h264parse ! v4l2h264dec capture-io-mode=4 ! video/x-raw ! v4l2convert output-io-mode=5 capture-io-mode=4    ! video/x-raw, format=(string)BGR, width=(int)640, height=(int)480 ! videorate ! video/x-raw,framerate=1/1 ! appsink name=m_appsink sync=false"</span></pre><p id="7ba5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看看每个元素的用途。</p><p id="c7ff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">RTSP src location = { 0 }-该位置是摄像机流的RTSP url。</p><p id="87c8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> rtph264depay </strong> —从RTP包中提取H264视频。</p><p id="f092" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">v4l 2h 264 dec</strong>——这个很有意思。这告诉Raspberry PI使用GPU解码H264。请记住，有一个替代方案是使用CPU来解码。是avdec_h264。如果我们试图只从一个摄像头解码，使用avdec_h264可能会有效。然而，因为我们的目标是从4个摄像头捕捉，所以将它卸载到GPU是非常必要的。</p><p id="4b51" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看看参数，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/eb4138c8f43dbea868a4e4be998f8768.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*TQDzgElbo7qL91eU7XAQ5Q.png"/></div></figure><blockquote class="of og oh"><p id="76f8" class="kw kx oi ky b kz la jr lb lc ld ju le oj lg lh li ok lk ll lm ol lo lp lq lr ij bi translated">将视频解码卸载到GPU是我们实现最小化CPU使用的目标的关键一步。</p></blockquote><p id="aa1d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> v4l2convert </strong> —这是让系统知道使用GPU而不是CPU来转换帧。有一个相当于视频转换CPU。这又是一个CPU密集型过程，所以我们应该使用v4l2convert来利用Raspberry PI提供的硬件加速。我们在这里做一些转换，他们是</p><p id="00b3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将源格式转换为BGR格式。帧尺寸缩小到640x480(从原来的720P)。v4l2convert的文档显示，有一个选项可以使用v4l2convert本身来控制帧速率。然而，我不能让它工作。请让我知道，如果你们中的任何人让它工作，我会很高兴听到。我不得不使用另一个videorate来控制帧速率，因为我无法让v4l2convert控制帧速率。</p><p id="e8dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这将帮助我们控制我们想要在应用程序中捕获的帧速率。在我们的例子中，我们希望从摄像机中每秒只捕捉一帧。所以会是framerate="1/1 "。假设我们只想在两秒钟内捕捉一帧，那么帧速率将是“1/2”。如果我们想在一秒钟内捕捉5帧，帧速率将是“5/1”</p><p id="c137" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在的想法是使用多重处理运行视频捕获应用程序，以利用Raspberry PI的不同内核。主程序将为每个摄像机启动一个单独的进程。</p><p id="6981" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其余的事情相当简单。一旦帧被捕获，它就被转换成OpenCV格式并被推入队列。目前这种转换是使用python代码完成的，请让我知道是否有办法在GStreamer管道中处理它。我假设会有，但我没有调查。据我所知，如果我们能够在GStreamer管道中处理它，它可以进一步减少CPU的使用。因为我们有4个不同的摄像机，所以会有4个不同的队列。队列使用TCP协议，因为如果我们希望这个系统在多个硬件上工作，这将有助于我们将来分配负载。也就是说，我们可以根据我们的需求扩展处理服务器，提高帧速率或捕捉间隔，或者添加更多的摄像头。也许我们会在下一个版本中针对分布式环境进行优化。</p><p id="fee5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在main_prgall.py(第27行)中，您需要输入您的流的RTSP URL</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="f8fa" class="ng ma iq nc b gy nh ni l nj nk">self.camlink1 = 'rtsp://&lt;username&gt;:&lt;password&gt;@192.168.1.2:554/cam/realmonitor?channel=1&amp;subtype=0&amp;unicast=true&amp;proto=Onvif' #Add your RTSP cam link</span></pre><p id="2e28" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">并根据您的环境添加其余的流URL。</p><blockquote class="of og oh"><p id="e0f4" class="kw kx oi ky b kz la jr lb lc ld ju le oj lg lh li ok lk ll lm ol lo lp lq lr ij bi translated">您可以从OpenCV使用GStreamer管道。Opencv需要在GStreamer支持下构建。</p></blockquote><p id="a5d4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">处理服务器</strong></p><p id="7f7a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个想法非常简单，从队列(4个队列)中抓取帧，并将其推送到英特尔NCS。这里的队列使用发布/订阅模型工作。摄像机是酒馆，流程服务器是SUB。如果NCS在一个帧中检测到一个人，我们将把这个帧移到另一个队列中。我使用的是英特尔型号zoom的个人检测零售013型号。该模型的详细信息可在此处找到:</p><div class="nm nn gp gr no np"><a href="https://docs.openvinotoolkit.org/2021.2/omz_models_intel_person_detection_retail_0013_description_person_detection_retail_0013.html" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd ir gy z fp nu fr fs nv fu fw ip bi translated">人员检测零售-0013 - OpenVINO工具包</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">这是一个用于零售场景的行人检测器。它基于类似MobileNetV2的主干网，包括…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">docs.openvinotoolkit.org</p></div></div><div class="ny l"><div class="om l oa ob oc ny od kp np"/></div></div></a></div><p id="3723" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您应该使用与您的设备兼容的型号，这一点非常重要。如果您有NCS2，那么您应该使用支持NCS 2的型号。这是一个可以在视频帧中检测出人的模型。它接受高度为320、宽度为544的输入帧</p><p id="5b5c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">通信引擎</strong></p><p id="6258" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是一个非常简单的组件。它从队列中获取已处理的数据，并将图像存储到本地目录中。它还与电报机器人连接，并发送附有图像的通知。</p><blockquote class="of og oh"><p id="40ab" class="kw kx oi ky b kz la jr lb lc ld ju le oj lg lh li ok lk ll lm ol lo lp lq lr ij bi translated">Bot密钥和用户ID从源代码中删除。你必须插入你自己的电报机器人密钥和用户ID</p></blockquote><h1 id="70e4" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated"><strong class="ak">结果</strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/6ce7f5debe2cf2154caef5375a130cc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_2zcJvp4T-lhrJtYqASrbw.jpeg"/></div></div></figure><blockquote class="of og oh"><p id="5860" class="kw kx oi ky b kz la jr lb lc ld ju le oj lg lh li ok lk ll lm ol lo lp lq lr ij bi translated">从图像中可以看出，这些帧几乎是实时处理的。在我的测试中，我发现所有的帧都能在不到2秒的时间内处理。(在不到2秒的时间内检测到运动)。电报机器人发送图像时可能会有轻微的延迟，但这是基于你的互联网连接。然而，我发现它在几乎所有的情况下都可以忽略不计。</p></blockquote><p id="971b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> CPU消耗</strong></p><p id="79f1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">CPU消耗大约为30–35 %,考虑到它每秒钟处理4个不同流的视频，这是可以接受的。下图显示了raspberry pi报告的CPU消耗和温度。</p><p id="4786" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我发现了另一种降低CPU占用率的方法。这不在python脚本中，而是在CCTV本身中。大多数IP摄像机支持多个流。即一个主流(具有高质量分辨率和帧速率)和一个分辨率降低的子流(在我的例子中是640x480)。以下截图显示了我的相机网络界面中的设置</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/d53ddff3d853a1475983802b2a3ac5e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kyJDIujwN3cm_DC7XOT_1A.png"/></div></div></figure><p id="480d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图显示了连接到子流时的CPU利用率和温度</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/6d96e3337444717969b4dce0e8f1816e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ISm-bZmGmXC_HXIqoJPxRw.png"/></div></div></figure><blockquote class="of og oh"><p id="7e96" class="kw kx oi ky b kz la jr lb lc ld ju le oj lg lh li ok lk ll lm ol lo lp lq lr ij bi translated">您可能会注意到，整体cpu利用率在16–22%之间，这似乎非常合理。由于繁重的工作是由GPU完成的，因此系统能够在不到2秒的时间内处理多个流，同时占用较少的CPU资源</p></blockquote><h1 id="2df4" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">结论</h1><p id="d2cf" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">树莓派是一个很棒的平台。您将能够找到大量的库和支持。相对便宜又高效。英特尔NCS 1尽职尽责。很可能英特尔NCS2将能够执行更多的推理，因为它被宣传为在性能方面更好。我没有机会在NCS 2中测试这个应用程序，因为我没有机会。我真的很想听听你们中是否有人愿意在NCS2中测试脚本并报告性能。话虽如此，只是碰巧我的实验用到了NCS1和Raspberry PI。从成本角度来看，如果你从零开始，这可能不是最好的平台。RPI将花费大约4K印度卢比，NCS花费我大约8K印度卢比。很好奇想知道Nvidia的Jetson Nano 2GB怎么样？它比NCS2有更好的性能，不需要像PI那样的另一个SBC。费用在5000印度卢比左右。也许我会在下一次更新中提到它。</p><p id="03e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">参考文献</strong></p><p id="0825" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">https://github.com/sahilparekh/GStreamer-Python<a class="ae kv" href="https://github.com/sahilparekh/GStreamer-Python" rel="noopener ugc nofollow" target="_blank">——这是一个很棒的报告，展示了如何在OpenCV中获取RTSP流。我在我的项目中扩展了这个样本，这归功于各自的所有者。</a></p><p id="a69e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">https://www.youtube.com/watch?v=HDY8pf-b1nA<a class="ae kv" href="https://www.youtube.com/watch?v=HDY8pf-b1nA" rel="noopener ugc nofollow" target="_blank">—这是开始学习GStreamer的好地方。这真的帮助我了解了GStreamer。</a></p><p id="36cb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="http://lifestyletransfer.com/how-to-use-gstreamer-appsrc-in-python/" rel="noopener ugc nofollow" target="_blank">http://life style transfer . com/how-to-use-gstreamer-app src-in-python/</a>—这是学习高级Gstreamer概念的好地方。一组很好的工作示例和很好的解释。</p></div></div>    
</body>
</html>