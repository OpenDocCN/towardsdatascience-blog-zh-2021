<html>
<head>
<title>How Do You Use Categorical Features Directly with CatBoost?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在CatBoost中直接使用分类特征？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-do-you-use-categorical-features-directly-with-catboost-947b211c2923?source=collection_archive---------5-----------------------#2021-10-31">https://towardsdatascience.com/how-do-you-use-categorical-features-directly-with-catboost-947b211c2923?source=collection_archive---------5-----------------------#2021-10-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="bbba" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">助推技术</h2><div class=""/><div class=""><h2 id="2abc" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">机器学习中的助推算法——第六部分</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/eab80d70a03d3c6ce4f0904f04b4b668.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FM59FEQGs5YLo-InmNKA5g.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">妮可·詹皮耶罗在<a class="ae lh" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="3934" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是我们在<strong class="lk jd"> <em class="me">“机器学习中的boosting算法”</em> </strong>文章系列中涉及的第四个(最后一个)Boosting算法。到目前为止，我们已经详细讨论了<a class="ae lh" rel="noopener" target="_blank" href="/how-do-you-implement-adaboost-with-python-a76427b0fa7a"> AdaBoost </a>、<a class="ae lh" rel="noopener" target="_blank" href="/under-the-hood-of-gradient-boosting-and-its-python-implementation-99cc63efd24d">梯度增强</a>、<a class="ae lh" href="https://rukshanpramoditha.medium.com/unlock-the-power-of-xgboost-738536b9f36f" rel="noopener"> XGBoost </a>和<a class="ae lh" rel="noopener" target="_blank" href="/can-lightgbm-outperform-xgboost-d05a94102a55"> LightGBM </a>算法及其Python实现。</p><p id="07a1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">CatBoost(分类增强)是XGBoost的替代方案。它具有以下特点:</p><ul class=""><li id="08fd" class="mf mg it lk b ll lm lo lp lr mh lv mi lz mj md mk ml mm mn bi translated">可以直接处理分类特征，无需编码</li><li id="deb4" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">具有更简单的超参数调谐过程</li><li id="2256" class="mf mg it lk b ll mo lo mp lr mq lv mr lz ms md mk ml mm mn bi translated">运行速度比XGBoost快</li></ul><p id="99c9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本教程中，我们将讨论如何在CatBoost中直接使用分类特征。我们还将它与LightGBM进行比较，后者也可以处理分类特征，但需要一些额外的工作！</p><p id="0c60" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们开始吧！</p><h1 id="1722" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">安装CatBoost</h1><p id="ae24" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">CatBoost的安装超级简单。在Anaconda提示符或Google Colab编辑器中运行以下命令之一。</p><pre class="ks kt ku kv gt nq nr ns nt aw nu bi"><span id="815b" class="nv mu it nr b gy nw nx l ny nz">pip install catboost<br/>#OR<br/>conda install catboost</span></pre><p id="d23d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这两个命令都可以安装既支持CPU又支持GPU的catboost包。</p><h1 id="6a75" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">在CatBoost中直接使用分类特征</h1><p id="3f24" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">与其他boosting算法相比，CatBoost的一个独特特性是我们可以通过CatBoost直接使用分类特征(如果数据集中有分类特征的话)(无需编码)。为了验证这一点，我们将使用具有一些分类特征的<a class="ae lh" href="https://drive.google.com/file/d/1iFSgksCgFNSiEN__yE_QcRoenVKsaTAS/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">“钻石”数据集</a>构建一个CatBoost回归模型。</p><h2 id="b5b0" class="nv mu it bd mv oa ob dn mz oc od dp nd lr oe of nf lv og oh nh lz oi oj nj iz bi translated">钻石数据集</h2><p id="319a" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">现在，我们来看看<a class="ae lh" href="https://drive.google.com/file/d/1iFSgksCgFNSiEN__yE_QcRoenVKsaTAS/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">“钻石”数据集</a>的一些重要细节。</p><pre class="ks kt ku kv gt nq nr ns nt aw nu bi"><span id="1a4c" class="nv mu it nr b gy nw nx l ny nz">import pandas as pd</span><span id="15a0" class="nv mu it nr b gy ok nx l ny nz">df = pd.read_csv('diamonds.csv')<br/>df.head()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/42053c68f5f83296c22a7c798774f351.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*t53J1lfIDV6OKRlKvGt0zQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="0588" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们在数据集中找出一些关于特征(变量)的信息。</p><pre class="ks kt ku kv gt nq nr ns nt aw nu bi"><span id="c381" class="nv mu it nr b gy nw nx l ny nz">df.info()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi om"><img src="../Images/3f7e8e10d2a68aa7c3b268aff9bd721d.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*NX0b7jDCNVaA3heyJMuUxg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="f872" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如你所见，变量<strong class="lk jd">切割</strong>、<strong class="lk jd">颜色</strong>和<strong class="lk jd">净度</strong>是分类变量。它们都有<strong class="lk jd">对象</strong>数据类型。这些分类变量没有数值。通常，我们需要将它们编码成数值，因为大多数算法在训练过程中只接受带有数值的数据。</p><p id="64d9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但是，CatBoost的情况并非如此。我们可以在CatBoost中直接使用分类特征，而无需对它们进行编码。为此，我们需要通过使用<a class="ae lh" href="https://catboost.ai/en/docs/concepts/python-reference_pool" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> Pool() </strong> </a>类将我们的数据转换为CatBoost的特殊<strong class="lk jd"> <em class="me"> Pool </em> </strong>数据类型。我们还需要在<strong class="lk jd"> cat_features </strong>参数中指定分类特征的名称。</p><p id="44c6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果我们的数据只有数字特征，我们也可以使用CatBoost，而无需将数据转换为Pool数据类型。如果我们的数据具有分类特征，我们必须在使用CatBoost之前将数据转换为Pool数据类型。</p><p id="0c26" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">基于钻石数据的CatBoost模型的设计过程非常简单。我们可以选择<strong class="lk jd">价格</strong>变量作为目标列(y)，其余变量作为特征矩阵(X)。我们还从数据集中删除了<em class="me">表</em>、<em class="me"> x </em>、<em class="me"> y </em>和<em class="me"> z </em>变量，因为它们对数据没有太大价值。然后，我们可以将X和y定义如下:</p><pre class="ks kt ku kv gt nq nr ns nt aw nu bi"><span id="4c65" class="nv mu it nr b gy nw nx l ny nz">X = df.drop(columns=['price', 'table', 'x', 'y', 'z'])<br/>y = df['price']</span></pre><p id="ac25" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因为<strong class="lk jd">价格</strong>是一个连续值变量，这里我们需要建立一个回归模型(实际上是一个CatBoost回归模型！).为了构建模型，我们使用了<a class="ae lh" href="https://catboost.ai/en/docs/concepts/python-reference_catboostregressor" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd">CatBoostRegressor()</strong></a><strong class="lk jd"/>类及其相关的超参数值。对于分类任务，有一个单独的类叫做<a class="ae lh" href="https://catboost.ai/en/docs/concepts/python-reference_catboostclassifier" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd">CatBoostClassifier()</strong></a>。</p><h2 id="8a1c" class="nv mu it bd mv oa ob dn mz oc od dp nd lr oe of nf lv og oh nh lz oi oj nj iz bi translated">基于钻石数据构建CatBoost回归模型</h2><p id="1a0c" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">这是代码。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">等到加载代码！</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi op"><img src="../Images/6ba7cb918fdd05ccb1bbfd97a7d294c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*74ATSfRI-sfg3tt25Nt30A.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="ade2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这个值吗？这是预测误差(残差)的标准差。值越低，模型越好。让我们仔细看看价格变量。</p><pre class="ks kt ku kv gt nq nr ns nt aw nu bi"><span id="815e" class="nv mu it nr b gy nw nx l ny nz">y.describe()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/409b76aa942de2b66532fdc3e870a26c.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*PRudo_4gA187Sc_nBtFjyw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="8011" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">范围(最大-最小)是18497。标准差是3989。因此，我们得到的RMSE值对于我们的模型来说是非常好的。另外，请注意，我们是在没有进行任何超参数调整的情况下获得这个值的！</p><h1 id="28bc" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">具有分类特征的LightGBM</h1><p id="6bb1" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">在<a class="ae lh" rel="noopener" target="_blank" href="/can-lightgbm-outperform-xgboost-d05a94102a55">第5部分</a>中，我们已经讨论了LightGBM也可以不经过编码直接用于分类特征。但是，LightGBM没有任何内部机制来处理分类特征。</p><p id="ed10" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们看看如果使用带有分类特性的LightGBM会发生什么。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">等到加载代码！</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi or"><img src="../Images/e792b0319c0c05b71c05d8bc8607ce3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*IB6PcR15hekgxxnf0dvfFg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="24e2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">您将得到一个值错误，提示您应该将分类值编码为数值。</p><p id="a039" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但是，等等！LightGBM有一个简单的方法。我们不需要对我们的分类值进行编码。相反，我们只需要在训练算法之前对<em class="me"> X </em>做一个数据类型转换(<em class="me">对象</em>数据类型→ <em class="me">类别</em>数据类型)。</p><h2 id="c92e" class="nv mu it bd mv oa ob dn mz oc od dp nd lr oe of nf lv og oh nh lz oi oj nj iz bi translated">转换前:</h2><pre class="ks kt ku kv gt nq nr ns nt aw nu bi"><span id="5b97" class="nv mu it nr b gy nw nx l ny nz">X.info()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/4ad260980e79e15044f48fb76510eb58.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*eoSh_oq0pyrUdsZyLGW-iQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><h2 id="a3e6" class="nv mu it bd mv oa ob dn mz oc od dp nd lr oe of nf lv og oh nh lz oi oj nj iz bi translated">转换过程:</h2><pre class="ks kt ku kv gt nq nr ns nt aw nu bi"><span id="7232" class="nv mu it nr b gy nw nx l ny nz">for col in X.select_dtypes(include=['object']):<br/>  X[col] = X[col].astype('category')</span></pre><h2 id="8ea7" class="nv mu it bd mv oa ob dn mz oc od dp nd lr oe of nf lv og oh nh lz oi oj nj iz bi translated">转换后:</h2><pre class="ks kt ku kv gt nq nr ns nt aw nu bi"><span id="70a5" class="nv mu it nr b gy nw nx l ny nz">X.info()</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/0f5bdc9e43dddd372fcc5c6056969160.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*GZN4hqVcMriA96EOUZyrPw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="2112" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，所有分类变量都有<em class="me">类别</em>数据类型。因此，我们可以无任何误差地重建模型。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">等到加载代码！</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/cd3952c233afd5dbc1331091937103c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:454/format:webp/1*fOgqokTaqJT-MXstR7m8bw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="a617" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这个RMSE值比之前从CatBoost得到的值稍微好一点！</p><h1 id="b2b8" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">结论</h1><p id="97c9" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">CatBoost是XGBoost的一个很好的替代品。如果您有一个包含分类变量的大型数据集，这应该是您的选择。当我们考虑性能和执行时间时，CatBoost可以优于XGBoost。但是，LightGBM比CatBoost好多了！</p><p id="a7e1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">今天的帖子到此结束。在第7部分的<a class="ae lh" rel="noopener" target="_blank" href="/performance-comparison-catboost-vs-xgboost-and-catboost-vs-lightgbm-886c1c96db64">中，我们将讨论XGBoost与CatBoost以及LightGBM与CatBoost的一些性能比较。除此之外，我们还将讨论一些指导原则，帮助您为您的任务选择正确的提升算法。</a></p><p id="be72" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下一个故事再见。祝大家学习愉快！</p></div><div class="ab cl ov ow hx ox" role="separator"><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa"/></div><div class="im in io ip iq"><p id="b645" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我的读者可以通过下面的链接注册成为会员，以获得我写的每个故事的全部信息，我将收到你的一部分会员费。</p><div class="pc pd gp gr pe pf"><a href="https://rukshanpramoditha.medium.com/membership" rel="noopener follow" target="_blank"><div class="pg ab fo"><div class="ph ab pi cl cj pj"><h2 class="bd jd gy z fp pk fr fs pl fu fw jc bi translated">通过我的推荐链接加入Medium</h2><div class="pm l"><h3 class="bd b gy z fp pk fr fs pl fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pn l"><p class="bd b dl z fp pk fr fs pl fu fw dk translated">rukshanpramoditha.medium.com</p></div></div><div class="po l"><div class="pp l pq pr ps po pt lb pf"/></div></div></a></div><p id="f045" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">非常感谢你一直以来的支持！</p><p id="affb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">特别要感谢Unsplash网站上的Nicole Giampietro，她为我的这篇文章提供了一张漂亮的封面图片。</p><p id="a198" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="pu pv ep" href="https://medium.com/u/f90a3bb1d400?source=post_page-----947b211c2923--------------------------------" rel="noopener" target="_blank">鲁克山普拉莫迪塔</a><br/><strong class="lk jd">2021–10–31</strong></p></div></div>    
</body>
</html>