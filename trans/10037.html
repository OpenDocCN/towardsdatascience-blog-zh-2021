<html>
<head>
<title>Medical Image Pre-Processing with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于Python的医学图像预处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/medical-image-pre-processing-with-python-d07694852606?source=collection_archive---------3-----------------------#2021-09-22">https://towardsdatascience.com/medical-image-pre-processing-with-python-d07694852606?source=collection_archive---------3-----------------------#2021-09-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="42f3" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用于训练模型的dicom图像预处理概述。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f095560fd62b52de701bfac36dc176b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gPJifTR9i87igxC2AiO0Dw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">CT图像- <em class="kv">作者提供的图像</em></p></figure><h2 id="0ee0" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">数据怎么样</h2><p id="6cce" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在这篇文章中，我将解释如何用简单的例子预处理美丽的医学图像来训练任何人工智能模型，以及如何通过所有预处理阶段为模型准备数据以给出最高的结果。</p><p id="8f44" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">我要用的数据是一堆2D大脑CT图像。它们是DICOM格式的。您可以简单地将这些操作应用于您自己的数据，以从您的模型中获得更有效的结果。</p><p id="bf44" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在我们开始编码之前，让我们先讨论一下医学数据。首先我来解释一下什么是CT。</p><p id="c0ab" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">计算机断层扫描是一种扫描，它拍摄从不同角度发送到身体的X射线图像，并使用计算机处理器进行组合，以访问身体各个部位的骨骼、血管和软组织的横截面图像(切片)。这些图像提供了比常规x射线图像更详细的信息。这样，患者的骨骼、静脉或组织中的异常被检测到。这就是为什么，可以对病人作出更准确的诊断，并相应地继续治疗。</p><p id="c421" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">现在我们来讨论一下，DICOM格式是什么。</p><p id="a03c" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">DICOM是医学数字成像和通信的首字母缩写。这种格式的文件很可能以“dcm”文件扩展名保存。DICOM既是一种通信协议，也是一种文件格式；这意味着患者可以在一个文件中存储医疗信息，如超声和MRI图像及其信息。而png或jpg文件只包含图片的名称、日期和像素数；dicom格式包括病人的信息，图片的开窗间隔，我们称之为元数据。简而言之，它包括更详细的患者信息。这种格式不仅可以将所有数据保存在一起，还可以确保信息在支持DICOM格式的设备之间传输。我从<a class="ae mq" href="https://www.kaggle.com/c/rsna-intracranial-hemorrhage-detection/data" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>那里拿了几张dcm图像。</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="f890" class="kw kx iq ms b gy mw mx l my mz"><strong class="ms ir">import</strong> <strong class="ms ir">pydicom<br/></strong>file_path = "/Users/esmasert/Desktop/basicsDcm/10095.dcm"<br/>medical_image = pydicom.read_file(file_path)<br/>print(medical_image)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/e5117bf36add34c741c8b47ab8c20915.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A0I-dbZOcQjervOPvuVSyQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">阅读Dicom文件— <em class="kv">作者图片</em></p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/a52559f5d6da2f97524bc304e6bb1ce8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i5MZdTMsh6r3nI3BwWTL6g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><p id="9a56" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在对CT和dicom做了基本的总结之后，让我们继续进行预处理。在图像的预处理阶段，我使用了5个步骤。</p><p id="d110" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">这些步骤是:变换到HU，去除噪声，倾斜校正，裁剪图像和填充。</p><p id="be08" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在将这些预处理步骤应用到数据之后，我们看到模型精度得到了显著提高。我正在讲解预处理方法。要以更清晰的格式查看代码，您可以访问这个<a class="ae mq" href="https://github.com/esmasert/Medical-Image/blob/main/PreprocessingDcmImages.ipynb" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="3a15" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在以DICOM格式加载我们的图像数据后，我们将把它转换成Hounsfield单位形式。</p><h2 id="e23a" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">变身胡</strong></h2><p id="5c76" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">Hounsfield单位(HU)是一种无线电波强度的相对定量测量单位，放射科医生使用它来更好地解释和理解计算机断层扫描(CT)图像。在CT重建期间使用组织内辐射的吸收/衰减系数来产生灰度图像。线性变换产生显示为灰色调的Hounsfield标度。更致密的组织，具有更大的X射线束吸收，具有正值并且看起来更亮；密度较低的组织对X射线束的吸收较少，具有负值，看起来较暗。[1]Hounsfield单位是以著名的Godfrey Hounsfield爵士命名的，他有计算机断层摄影的部分发明，并因此获得诺贝尔奖。</p><p id="ea17" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">我们可以通过使用重新调整截距和重新调整坡度标题来获得HU:</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="9ae0" class="kw kx iq ms b gy mw mx l my mz"><strong class="ms ir">def</strong> transform_to_hu(medical_image, image):<br/>    intercept = medical_image.RescaleIntercept<br/>    slope = medical_image.RescaleSlope<br/>    hu_image = image * slope + intercept<br/><br/>    <strong class="ms ir">return</strong> hu_image</span><span id="74f2" class="kw kx iq ms b gy nb mx l my mz"><strong class="ms ir">def</strong> window_image(image, window_center, window_width):<br/>    img_min = window_center - window_width // 2<br/>    img_max = window_center + window_width // 2<br/>    window_image = image.copy()<br/>    window_image[window_image &lt; img_min] = img_min<br/>    window_image[window_image &gt; img_max] = img_max<br/>    <br/>    <strong class="ms ir">return</strong> window_image</span></pre><p id="1d2d" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如果您想要图像的特定区域，您可以调整图像的窗口。</p><h2 id="cfab" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">去除噪音</strong></h2><p id="ea80" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在预处理过程中，去除噪声是一个非常重要的阶段，因为实施后数据得到改善，我们可以更清楚地看到它。因此，模型可以被更好地训练。[2]</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="7754" class="kw kx iq ms b gy mw mx l my mz"><strong class="ms ir">def</strong> remove_noise(file_path, display=<strong class="ms ir">False</strong>):<br/>    medical_image = pydicom.read_file(file_path)<br/>    image = medical_image.pixel_array<br/>    <br/>    hu_image = transform_to_hu(medical_image, image)<br/>    brain_image = window_image(hu_image, 40, 80) #bone windowing<br/>    <br/>    segmentation = morphology.dilation(brain_image, np.ones((1, 1)))<br/>    labels, label_nb = ndimage.label(segmentation)<br/>    <br/>    label_count = np.bincount(labels.ravel().astype(np.int))<br/>    label_count[0] = 0<br/><br/>    mask = labels == label_count.argmax()<br/> <br/>    mask = morphology.dilation(mask, np.ones((1, 1)))<br/>    mask = ndimage.morphology.binary_fill_holes(mask)<br/>    mask = morphology.dilation(mask, np.ones((3, 3)))<br/>    masked_image = mask * brain_image</span><span id="0e2d" class="kw kx iq ms b gy nb mx l my mz"><strong class="ms ir">    return</strong> masked_image</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/4055dbb4b363fd21ca05a129123ad333.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lWleusIrFrrbgLd3RKy2yg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/e171ba950af00ce996abeee7599476b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vR-TmijMbYyUQeICi4smcA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><h2 id="98dd" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">倾斜校正:</strong></h2><p id="c292" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">倾斜校正是大脑图像对齐的一种建议方式。当脑部CT图像经历倾斜时，它可能导致医学应用的不对准。这很重要，因为当我们训练模型时，它可以通过相同的排列看到整个数据。手动校正大规模数据的倾斜既费时又费钱。因此，需要一种在训练前的预处理中执行倾斜校正的自动方法。</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="b430" class="kw kx iq ms b gy mw mx l my mz">img=numpy.uint8 (iskemiMaskedImg)<br/>contours, hier =cv2.findContours (img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)<br/>mask=numpy.zeros (img.shape, numpy.uint8)<br/><br/><em class="ne"># find the biggest contour (c) by the area</em><br/>c = max(contours, key = cv2.contourArea)<br/><br/>(x,y),(MA,ma),angle = cv2.fitEllipse(c)<br/><br/>cv2.ellipse(img, ((x,y), (MA,ma), angle), color=(0, 255, 0), thickness=2)<br/><br/>rmajor = max(MA,ma)/2<br/><strong class="ms ir">if</strong> angle &gt; 90:<br/>    angle -= 90<br/><strong class="ms ir">else</strong>:<br/>    angle += 96<br/>xtop = x + math.cos(math.radians(angle))*rmajor<br/>ytop = y + math.sin(math.radians(angle))*rmajor<br/>xbot = x + math.cos(math.radians(angle+180))*rmajor<br/>ybot = y + math.sin(math.radians(angle+180))*rmajor<br/>cv2.line(img, (int(xtop),int(ytop)), (int(xbot),int(ybot)), (0, 255, 0), 3)<br/><br/>pylab.imshow(img)<br/>pylab.show()<br/><br/>M = cv2.getRotationMatrix2D((x, y), angle-90, 1)  <em class="ne">#transformation matrix</em><br/><br/>img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]), cv2.INTER_CUBIC)<br/><br/>pylab.imshow(img)<br/>pylab.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/8491bbe60882df1725cbd07270d2193d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OdqstCMk46RZJZSgknDhCQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><h2 id="1c87" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">裁剪图像并添加填充:</strong></h2><p id="52e9" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">需要对图像进行裁剪，以将大脑图像置于中心，并去除图像中不必要的部分。此外，一些大脑图像可能被放置在一般图像中的不同位置。通过裁剪图像和添加填充，我们将确保几乎所有的图像都在普通图像本身的相同位置。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/783e0aa755d98d28f488e53be8b6d4ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*62e95rA44TX7OnB69GPznQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="kv">作者图片</em></p></figure><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="07a7" class="kw kx iq ms b gy mw mx l my mz"><strong class="ms ir">def</strong> add_pad(image, new_height=512, new_width=512):<br/>    height, width = image.shape<br/><br/>    final_image = np.zeros((new_height, new_width))<br/><br/>    pad_left = int((new_width - width) // 2)<br/>    pad_top = int((new_height - height) // 2)<br/>    <br/>    <br/>    <em class="ne"># Replace the pixels with the image's pixels</em><br/>    final_image[pad_top:pad_top + height, pad_left:pad_left + width] = image<br/>    <br/>    <strong class="ms ir">return</strong> final_image</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/51e1bc495541bdaf1044ec8bb071349c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0x8ekwE7giZZcMSS18MSuQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="9140" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">下面是结果！一个干净的，正确的和居中的大脑图像。准备好进去训练了。</p><p id="763d" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">我在下面附上了参考资料。非常感谢https://vincentblog.xyz/！它确实帮助我更深入地理解了图像处理。</p><p id="c3e5" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如果您有任何建议或问题，请在下面评论。非常感谢！</p></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><h2 id="d698" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">参考文献</strong></h2><ol class=""><li id="a466" class="np nq iq lu b lv lw ly lz lf nr lj ns ln nt mk nu nv nw nx bi translated"><a class="ae mq" href="https://www.ncbi.nlm.nih.gov/books/NBK547721/" rel="noopener ugc nofollow" target="_blank">https://www.ncbi.nlm.nih.gov/books/NBK547721/</a></li><li id="d6e4" class="np nq iq lu b lv ny ly nz lf oa lj ob ln oc mk nu nv nw nx bi translated"><a class="ae mq" href="https://vincentblog.xyz/posts/medical-images-in-python-computed-tomography" rel="noopener ugc nofollow" target="_blank">https://Vincent blog . XYZ/posts/medical-images-in-python-computed-tomography</a></li><li id="bd16" class="np nq iq lu b lv ny ly nz lf oa lj ob ln oc mk nu nv nw nx bi translated"><a class="ae mq" href="https://link.springer.com/article/10.1007/s10278-020-00400-7" rel="noopener ugc nofollow" target="_blank">https://link . springer . com/article/10.1007/s 10278-020-00400-7</a></li><li id="0dcc" class="np nq iq lu b lv ny ly nz lf oa lj ob ln oc mk nu nv nw nx bi translated">【https://www.eyewated.com T4】</li></ol></div></div>    
</body>
</html>