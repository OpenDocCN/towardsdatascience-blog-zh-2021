<html>
<head>
<title>How to make an effective coreference resolution model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何建立有效的共指消解模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-make-an-effective-coreference-resolution-model-55875d2b5f19?source=collection_archive---------15-----------------------#2021-04-06">https://towardsdatascience.com/how-to-make-an-effective-coreference-resolution-model-55875d2b5f19?source=collection_archive---------15-----------------------#2021-04-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d818" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何改进现成的共指消解库</h2></div><p id="5799" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">作者</em> <a class="ae lc" href="https://medium.com/@m.maslankowska" rel="noopener"> <em class="lb">玛尔塔·马朗考斯卡</em> </a> <em class="lb">和</em> <a class="ae lc" href="https://medium.com/@p.mielniczuk" rel="noopener"> <em class="lb">帕韦·米耶尼克祖克</em> </a> <em class="lb">。</em></p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/8e658b2f6bcc558e7a3b96300b1ea253.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0C5xQRgOvNPT1WtfBA2BPQ.jpeg"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">Dariusz Sankowski 在<a class="ae lc" href="https://unsplash.com/s/photos/open-book?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="3148" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">介绍</h1><p id="ebd8" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在本文中，我们介绍了如何改进AllenNLP的共指消解模型，以实现更连贯的输出。我们还介绍了几个集成策略，以同时利用Huggingface和AllenNLP模型。</p><p id="34c2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">简而言之，共指消解(CR)是一个NLP任务，旨在替换句子中所有的歧义词，以便我们获得不需要任何额外上下文就可以理解的文本。如果您需要复习一些基本概念，请参考我们的介绍文章。</p><p id="e995" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我们主要关注<strong class="kh ir">改进库如何解析发现的集群</strong>。如果你对CR最常见的库的详细<a class="ae lc" href="https://neurosys.com/article/most-popular-frameworks-for-coreference-resolution/" rel="noopener ugc nofollow" target="_blank">解释感兴趣(例如什么是<em class="lb"> AllenNLP </em>或<em class="lb"> Huggingface </em>)，我们的动机可以随意查看。</a></p><h1 id="f374" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">现成可用但不完整</h1><p id="02bf" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">Huggingface和AllenNLP共指消解模型对许多项目来说都是一个很好的补充。然而，我们发现了几个缺点(在前一篇文章中有详细描述),这让我们怀疑我们是否真的想在我们的系统中实现这些库。最大的问题不是无法找到可接受的聚类，而是整个过程的最后一步——解析共指以获得明确的文本。</p><p id="45db" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这让我们想到，也许我们可以为此做些什么。我们决定对最终文本进行几处小改动，从而带来显著的改进。因为AllenNLP似乎找到了更多的集群，而这些集群往往更好，所以我们决定采用一种更侧重于这种模式的解决方案。</p><h1 id="f16d" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">拟议改进概述</h1><p id="e699" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">我们已经决定将AllenNLP作为我们的主要模型，并利用Huggingface作为更多的参考，同时主要将其用作对AllenNLP输出的改进。我们的解决方案包括:</p><ol class=""><li id="e9cd" class="mq mr iq kh b ki kj kl km ko ms ks mt kw mu la mv mw mx my bi translated">基于模型已经获得的聚类，改进AllenNLP替换共参照的方法，</li><li id="4f51" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la mv mw mx my bi translated">引入几种策略，将两种模型的输出(聚类)合并成一个增强的结果。</li></ol><p id="115e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了改进相互引用的替换，有几个有问题的区域可以稍微容易地改进:</p><ul class=""><li id="97a8" class="mq mr iq kh b ki kj kl km ko ms ks mt kw mu la ne mw mx my bi translated">在一个集群中缺少一个有意义的提及，可能成为它的头<br/>(一个跨度，我们用它替换给定集群中的所有其他提及)</li><li id="5758" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la ne mw mx my bi translated">将第一个区间视为一个簇的头(这对于下一个区间尤其成问题)，</li><li id="438e" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la ne mw mx my bi translated">各种复杂情况，以及由于嵌套提及而导致的无意义输出。</li></ul><p id="015f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所有上述问题都在下面举例说明:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nf"><img src="../Images/2f7dfcf81a9d9dd7de59e61eb03bb2d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pM7ta6Y8lrMsRR0K"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">在聚类中缺少有意义的提及(例如名词短语)的文本。</p></figure><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nf"><img src="../Images/e61a0981b6cec6396aa1fbb060ce034d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*A5qq8b3EP9jK4siO"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">有下指的文本—代词在名词短语之前。</p></figure><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nf"><img src="../Images/5ca3a790ac6883dfc9e2d218b309d3b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*H5TIzQAbc2kKfRNQ"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">具有嵌套相关提及的文本。</p></figure><p id="7b18" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们对这些问题提出以下解决办法:</p><ul class=""><li id="dec7" class="mq mr iq kh b ki kj kl km ko ms ks mt kw mu la ne mw mx my bi translated">如果一个集群不包含任何名词短语，就不要考虑它</li><li id="994e" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la ne mw mx my bi translated">将聚类中的第一个名词短语(不是第一次提到的)视为其标题</li><li id="bccf" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la ne mw mx my bi translated">仅解析嵌套的共同引用中的内部范围</li></ul><p id="57ec" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下一节中，将详细解释这些方法，包括AllenNLP改进和组合模型的策略。此外，无论你想更深入还是跳过细节，下一章的所有代码都可以在我们的<a class="ae lc" href="https://github.com/NeuroSYS-pl/coreference-resolution" rel="noopener ugc nofollow" target="_blank"> NeuroSYS GitHub </a>库中找到。</p><h1 id="32b3" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">深入改进</h1><p id="8941" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">由于Huggingface基于spaCy，使用起来毫不费力，并提供了多种附加功能。然而，修改起来要复杂得多，因为spaCy提供了许多机制，禁止您访问或更改底层实现。</p><p id="9ed5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，除了与Huggingface相比，AllenNLP获得了更多数量的有效聚类之外，我们还发现前者更容易修改。</p><p id="bee0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了修改AllenNLP的行为，我们关注于<em class="lb"> coref_resolved(text) </em>方法。它遍历所有聚类，并用第一个找到的提及替换每个聚类中的所有跨度。我们的改进只涉及这个函数和其中的嵌套方法。</p><p id="5bc8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是一个简短文本的例子，它包含了我们试图解决的上述所有三个问题，我们现在将重点关注这些问题。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nf"><img src="../Images/aff158f0e0e97e9e45c7fa60756e4136.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-nkxyADoetI-dBOL"/></div></div></figure><h1 id="cb93" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">冗余集群</h1><p id="7d3a" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">为了让我们的解决方案简单明了，我们决定将有意义的提及定义为任何名词短语。</p><p id="ed11" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于每个聚类，我们获取包含名词短语的跨度的索引(我们在下面的改进中也使用它们)。验证一个标记是否是名词的最简单的方法是使用spaCy！事实证明，AllenNLP也使用spaCy语言模型，但只是对输入文本进行标记化。</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="ad52" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里最让我们感兴趣的嵌套方法是<em class="lb"> replace_corefs(spacy_doc，clusters) </em>。它不仅利用了spaCy Doc对象，还包含了实现我们的改进所需的所有逻辑。它看起来像这样:</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="6147" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从<a class="ae lc" href="https://spacy.io/api/annotation#pos-tagging" rel="noopener ugc nofollow" target="_blank">空间文档</a>中，我们知道名词由两个词性(POS)标签表示:<em class="lb">名词</em>和<em class="lb">属性</em>。我们需要检查集群中每个span的POS标签(实际上是每个span中的每个令牌)是否是这两者之一。</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="a439" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面展示了这段代码如何改进共指替换。现在，我们主要关注第一个集群，因为它显示了当前的问题。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nf"><img src="../Images/1c9dea17865d8ade047feefe7d8a0c91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*T_c5ojBo7qaZI15S"/></div></div></figure><h1 id="cc51" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">解决下指问题</h1><p id="fba5" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">许多共指消解模型，如Huggingface，在检测下指时存在严重问题，因为这种情况很少发生。一方面，我们可能对解决这种引起更多问题的异常情况不感兴趣。另一方面，根据文本的不同，如果我们忽略了它们，我们可能会丢失或多或少的信息。</p><p id="7650" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">AllenNLP检测下指，但由于它将聚类中的第一个提及作为其头部，因此会导致进一步的错误。这是因为先行词(例如代词)在后置词(例如名词短语)之前，所以一个无意义的跨度成为一个簇的头。</p><p id="a70c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了避免这种情况，我们建议将集群中的第一个名词短语(不仅仅是任何提及)作为它的头，用它替换所有前面和后面的部分。这个解决方案是琐碎的，虽然我们可以看到其他更复杂的想法的优点，但我们的解决方案似乎对大多数情况都足够有效。</p><p id="edda" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们仔细看看AllenNLP的<em class="lb"> replace_corefs </em>方法中的几个关键行。</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="b21f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了让我们的解决方案起作用，我们需要重新定义<em class="lb">reference _ span</em>变量(集群的头),这样它就表示第一个找到的名词短语。为了实现这一点，我们使用了我们的<em class="lb">noun _ indexes</em>列表——它的第一个元素是我们想要的。</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="ed1e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看看它是如何提高输出的。这次我们关注第二个集群。现在没有信息丢失！然而，由于AllenNLP根据找到的聚类的顺序返回结果，所以在我们的版本中也有一个小错误。不过不要担心，我们将在下一节中修复它。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nf"><img src="../Images/42daef0b9e1001c04cd34e831076cc75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DGK7Ar7xWx2r0OA4"/></div></div></figure><h1 id="a4fa" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">嵌套提及</h1><p id="0c99" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">最后一个改进涉及由多个提及组成的跨度。正如我们在上一篇文章中所展示的，有几种策略可以用来解决这个问题，但没有一种是完美的:</p><ol class=""><li id="590a" class="mq mr iq kh b ki kj kl km ko ms ks mt kw mu la mv mw mx my bi translated">仅用外部跨度替换整个嵌套提及→我们会丢失信息</li><li id="749f" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la mv mw mx my bi translated">替换内部和外部span →在许多情况下不起作用，根据找到的集群顺序会导致不同的结果</li><li id="8de4" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la mv mw mx my bi translated">仅替换内部span →适用于大多数文本，但是，一些替换会导致无意义的句子</li><li id="c4e1" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la mv mw mx my bi translated">省略嵌套提及；根本不替换跨度→我们没有获得共指消解模型首先应该提供给我们的信息，但是我们100%确定文本在语法上是正确的</li></ol><p id="c305" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们认为，第三种策略——仅替换内部跨度<em class="lb"/>——是信息增益和最终文本中可能的错误数量之间的良好折衷。它还提供了一个额外的功能—现在，无论群集排序如何，输出都将始终相同。</p><p id="a342" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要实现它，我们只需要检测外部跨度并忽略它们。为此，我们只需检查特定的跨度索引是否包含任何其他提及。</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="422f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我们获得了一个包含所有改进的文本。我们意识到这个问题本来可以解决得更好，但是我们发现在解决方案的简单性和解决文本的有效性之间的权衡恰到好处。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nf"><img src="../Images/c35141316875d6d20a91369d47664216.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RTcrSaw8H7nuE2H_"/></div></div></figure><p id="4e61" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如上图所示，我们可以获得更好的结果，同时只增强找到的聚类的解析方式。</p><h1 id="572f" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">整体策略</h1><p id="9d59" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在所有的改进之后，我们现在可以转移到交集策略——关于如何结合AllenNLP和Huggingface集群的想法。正如我们之前提到的，我们认为AllenNLP产生了明显更好的集群，但它并不完美。为了在没有任何微调的情况下获得关于最终聚类的最高可能置信度，我们提出了几种合并两个模型输出的方法:</p><ul class=""><li id="82fc" class="mq mr iq kh b ki kj kl km ko ms ks mt kw mu la ne mw mx my bi translated">严格-仅保留那些在Huggingface和AllenNLP模型输出中完全相同的聚类(聚类的交集)</li><li id="c52c" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la ne mw mx my bi translated">部分-仅保留那些在Huggingface和AllenNLP(跨距的交点)中完全相同的跨距</li><li id="f946" class="mq mr iq kh b ki mz kl na ko nb ks nc kw nd la ne mw mx my bi translated">模糊-保留Huggingface和AllenNLP中部分相同(重叠)的所有跨度，但优先考虑较短的跨度</li></ul><p id="29e7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于AllenNLP通常更好，我们将其作为我们的基础，因此在可疑的情况下，我们仅根据其发现构建输出。由于代码不像讨论的改进那样短，我们给<a class="ae lc" href="https://github.com/NeuroSYS-pl/coreference-resolution" rel="noopener ugc nofollow" target="_blank">提供了一个详细的Jupyter笔记本</a>，在这里只看一下策略的输出。</p><p id="7ec5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下示例摘自GAP数据集，我们之前已经详细解释过。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nf"><img src="../Images/1334bb4183c60a9c741bcc5311585a2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rvbvqd1DTg-b-LG8"/></div></div></figure><p id="c664" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了有效地比较提议的交集策略，更容易将模型的输出视为聚类集，如下图所示。值得注意的是，AllenNLP和Huggingface不仅发现了略微不同的提及，还发现了整个集群。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nf"><img src="../Images/2560de5aed5a33febe1e85ececdfc0ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TrSKTVD7_lDVm_FG"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">两个库都找到的集群— AllenNLP和Huggingface。</p></figure><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ni"><img src="../Images/82fbf570fdaca82402cc97ed17f1c283.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KVxzLpDiwfIxI-WU"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">通过每个交集策略获得的聚类AllenNLP和Huggingface的集合。</p></figure><p id="49ec" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们大多倾向于模糊策略。它提供了比单一模型的输出更高的确定性，同时还提供了最大的信息增益。所有策略都各有利弊，因此最好进行试验，看看哪种策略最适合您的数据集。</p><p id="8753" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看看最终的结果——包含已解决的相互引用的示例，包括我们之前的改进:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nf"><img src="../Images/46503b3c246bef2c4773f1f8b1c7cd17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*a5mPxfiLuuPutOCP"/></div></div></figure><p id="7d8c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管最终的文本听起来不太自然，但我们必须记住，共指消解的目的通常是为语言模型消除歧义。因此，他们可以更好地理解输入，并能够产生更合适的嵌入。在这种情况下，我们只缺少一条信息——他死于1370年——同时获得了许多正确的替换，并去掉了过长的提及。</p><h1 id="63e7" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">摘要</h1><p id="5411" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在我们的文章中，我们解决了NLP中的一个主要问题——共指消解。我们解释了什么是CR，介绍了最常见的库以及它们带来的问题，现在向<strong class="kh ir">展示了如何改进现有的解决方案</strong>。</p><p id="0518" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们试图用多张图片和各种例子来阐明我们可能有的一切。基本用法和我们的修改都可以在<a class="ae lc" href="https://github.com/NeuroSYS-pl/coreference-resolution" rel="noopener ugc nofollow" target="_blank">我们的NeuroSYS GitHub </a>上找到。</p><p id="d486" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">希望现在您已经熟悉了共指解决方案，并且可以轻松地将我们提出的解决方案应用到您的项目中！</p></div></div>    
</body>
</html>