<html>
<head>
<title>AutoVideo: An Automated Video Action Recognition System</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AutoVideo:一个自动视频动作识别系统</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/autovideo-an-automated-video-action-recognition-system-43198beff99d?source=collection_archive---------12-----------------------#2021-08-10">https://towardsdatascience.com/autovideo-an-automated-video-action-recognition-system-43198beff99d?source=collection_archive---------12-----------------------#2021-08-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="af26" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利用神经网络和自动化机器学习识别人类行为，如刷牙、坐着和跑步</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/916c4c2efdc2667df49d7af6d3da44b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SF2dpQlTxbGbaC1q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">视频动作识别管道可以使用AutoVideo预测的一些常用动作来源:<a class="ae kv" href="https://serre-lab.clps.brown.edu/wp-content/uploads/2012/08/HMDB_snapshot2.png" rel="noopener ugc nofollow" target="_blank"> HMDB </a> (CC BY 4.0)</p></figure><p id="27ea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇文章中，我将介绍我们如何建立一个神经网络来自动识别人类的行为。虽然这对于人类来说似乎是一项简单而琐碎的任务，但对于人工系统来说却很难做到。基于视频的动作识别旨在通过从视频片段中识别不同的动作来解决这个问题。这是视频理解的一项重要任务，在各个领域都有广泛的应用，如安全<a class="ae kv" href="https://www.researchgate.net/publication/226868093_Motion_History_Histograms_for_Human_Action_Recognition" rel="noopener ugc nofollow" target="_blank">(孟、Pears和Bailey 2007) </a>、医疗<a class="ae kv" href="https://arxiv.org/pdf/1909.06423.pdf" rel="noopener ugc nofollow" target="_blank">(高等2018) </a>、行为分析<a class="ae kv" href="https://www.researchgate.net/publication/220611909_Poppe_R_A_Survey_on_Vision-based_Human_Action_Recognition_Image_and_Vision_Computing_286_976-990" rel="noopener ugc nofollow" target="_blank"> (Poppe 2010)。</a>视频动作识别的实际应用包括老年人行为监控以增强辅助生活、自动视频监控系统等等。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/2d957f272e798a6810718ede71decf08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2OtrFSirkheQx2gx.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://github.com/datamllab/autovideo" rel="noopener ugc nofollow" target="_blank">https://github.com/datamllab/autovideo</a>。图片作者。</p></figure><p id="8c6c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文的目的是为我们的开源项目AutoVideo ( <a class="ae kv" href="https://github.com/datamllab/autovideo" rel="noopener ugc nofollow" target="_blank"> GitHub </a>)提供一个教程，这是一个全面且易于使用的视频动作识别工具包。在本教程中，您将学习:</p><blockquote class="lt lu lv"><p id="a7c3" class="kw kx lw ky b kz la jr lb lc ld ju le lx lg lh li ly lk ll lm lz lo lp lq lr ij bi translated"><em class="iq"> (1)如何训练一个可以预测人类动作的神经网络；</em></p><p id="f871" class="kw kx lw ky b kz la jr lb lc ld ju le lx lg lh li ly lk ll lm lz lo lp lq lr ij bi translated"><em class="iq"> (2)如何使用自动调优工具节省你调优超参数的努力；</em></p><p id="b681" class="kw kx lw ky b kz la jr lb lc ld ju le lx lg lh li ly lk ll lm lz lo lp lq lr ij bi translated"><em class="iq"> (3)如何在你定制的数据集上训练模型。</em></p></blockquote><p id="09ec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你将能够使用你训练过的模型来识别任何新的视频剪辑，就像下面检测刷毛的演示一样。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/2edc8c3ae6de33426b5c01bd437f807b.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/0*NNKtYeCYJ8NtZM6F.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">预测演示视频上的动作(刷牙)。图片作者。</p></figure><h1 id="0bd3" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">概观</h1><p id="eee4" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">AutoVideo是一个高度模块化和可扩展的系统，它用标准管道语言包装了数据加载、数据处理和最先进的动作识别模型。因此，从业者可以很容易地添加新的动作识别模块或其他模块，如其他视频理解任务。AutoVideo还引入了数据驱动的搜索器来自动调整不同的模型和超参数，以减少人工工作量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1eb47ac5747c8e86fd0359ecc7dd5c31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NLtuo83TSqGxZ2Na.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图一。系统概述。AutoVideo中的每个模块都被包装成一个带有一些超参数的原语。流水线由从预处理到动作识别的一系列原语组成。AutoVideo配备了调谐器来搜索模型和超参数。图片作者。</p></figure><h1 id="446b" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">入门指南</h1><p id="10c1" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">让我们从教程开始吧，它将帮助您熟悉这个包，并在自定义/基准数据集上执行动作识别。</p><h1 id="c79a" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">安装:</h1><p id="f2f5" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">要安装该软件包，请确保您的Linux/MacOS系统上安装了Python 3.6和pip。首先安装以下软件包:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="d2cb" class="nd mc iq mz b gy ne nf l ng nh">pip3 install torch<br/>pip3 install torchvision</span></pre><p id="83a0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，只需使用以下命令即可安装AutoVideo软件包:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="abce" class="nd mc iq mz b gy ne nf l ng nh">pip3 install autovideo</span></pre><h1 id="e640" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">准备数据集:</h1><p id="aa6d" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">数据集必须遵循D3M格式，由一个csv文件和一个媒体文件夹组成。csv文件应包含三列，用于指定实例索引、视频文件名和标签。下面是一个示例csv文件:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="9a6a" class="nd mc iq mz b gy ne nf l ng nh"><strong class="mz ir">d3mIndex,video,label</strong><br/>0,Brushing_my_waist_lenth_hair_brush_hair_u_nm_np1_ba_goo_0.avi,0<br/>1,brushing_raychel_s_hair_brush_hair_u_cm_np2_ri_goo_2.avi,0<br/>2,Haarek_mmen_brush_hair_h_cm_np1_fr_goo_0.avi,0<br/>3,Haarek_mmen_brush_hair_h_cm_np1_fr_goo_1.avi,0<br/>4,Prelinger_HabitPat1954_brush_hair_h_nm_np1_fr_med_26.avi,0<br/>5,brushing_hair_2_brush_hair_h_nm_np1_ba_med_2.avi,0</span></pre><p id="31ec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">媒体文件夹应该包含视频文件。你可以参考我们在<a class="ae kv" href="https://drive.google.com/drive/folders/13oVPMyoBgNwEAsE_Ad3XVI1W5cNqfvrq" rel="noopener ugc nofollow" target="_blank"> Google Drive </a>中的例子hmdb6数据集。我们还在Google Drive中准备了hmdb51和ucf101进行基准测试。要试用这个教程，你可以从<a class="ae kv" href="https://drive.google.com/drive/folders/13oVPMyoBgNwEAsE_Ad3XVI1W5cNqfvrq" rel="noopener ugc nofollow" target="_blank">这里</a>下载hmdb6数据集。然后，您可以解压缩一个数据集，并将其放入<a class="ae kv" href="https://github.com/datamllab/autovideo/blob/main/datasets" rel="noopener ugc nofollow" target="_blank">数据集</a>。</p><h1 id="a26b" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">进行实验:</h1><p id="f018" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">这个界面基于Axolotl，我们对D3M的高级抽象。下面给出了使用预训练权重(在子采样hmdb6数据集上训练)在样本视频上运行动作识别任务的最小示例。我们开始吧！</p><h2 id="3d74" class="nd mc iq bd md ni nj dn mh nk nl dp ml lf nm nn mn lj no np mp ln nq nr mr ns bi translated">加载数据集:</h2><p id="6f27" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">如上所述，以D3M格式准备数据集，并将其放在数据集文件夹中。在这个例子中，我们使用了hmdb-6 ( <a class="ae kv" href="https://drive.google.com/drive/folders/13oVPMyoBgNwEAsE_Ad3XVI1W5cNqfvrq?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Google-Drive </a>)(来自HMDB-51的子样本，仅包含6个类)。我们使用实用函数<strong class="ky ir"> <em class="lw"> set_log_path() </em> </strong>为实验设置日志记录系统。<strong class="ky ir"><em class="lw">train _ table _ path</em></strong>是带有视频文件名和标签信息的训练csv文件的路径。<strong class="ky ir"><em class="lw">train _ media _ dir</em></strong>表示包含视频文件的媒体文件夹，而<strong class="ky ir"> <em class="lw"> target_index </em> </strong>指定包含输出标签信息的列的索引</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="2391" class="nd mc iq bd md ni nj dn mh nk nl dp ml lf nm nn mn lj no np mp ln nq nr mr ns bi translated">预处理:</h2><p id="7804" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">在读取火车csv文件后，接下来我们通过从<strong class="ky ir"> <em class="lw">火车_媒体_目录</em> </strong>中的视频中提取帧并将它们存储在文件夹目录<strong class="ky ir"> <em class="lw">帧中来预处理数据集。</em> </strong>为了实现这一点，我们从<strong class="ky ir"> autovideo </strong>包中使用<strong class="ky ir"><em class="lw">extract _ frames</em></strong>实用函数如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="8719" class="nd mc iq bd md ni nj dn mh nk nl dp ml lf nm nn mn lj no np mp ln nq nr mr ns bi translated">构建模型:</h2><p id="e782" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">我们的软件包支持7种动作识别模式。在这个例子中，我们使用TSN作为视频识别模型。<strong class="ky ir"><em class="lw">build _ pipeline()</em></strong>函数返回由端到端可训练模型组成的<strong class="ky ir"> <em class="lw">管道</em> </strong>。下面是一个构建管道的示例。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="ed00" class="nd mc iq bd md ni nj dn mh nk nl dp ml lf nm nn mn lj no np mp ln nq nr mr ns bi translated">调整超参数:</h2><p id="bbd0" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">在上面的函数中，用户可以在<strong class="ky ir"><em class="lw">build _ pipeline()</em></strong>函数中自定义配置字典<strong class="ky ir"> <em class="lw"> (config) </em> </strong>，用不同的超参数训练不同的算法。我们已经指定了一些超参数值(如学习率、时期数。等等)来演示用法。支持的超参数的完整列表可在<a class="ae kv" href="https://gist.github.com/zaidbhat1234/b0519ed39aaa3ee8ac0045634ce9ac06" rel="noopener ugc nofollow" target="_blank">这里</a>找到。AutoVideo中的每个模型都被包装成一个图元，其中包含一些超参数。TSN的一个例子是这里的<a class="ae kv" href="https://github.com/datamllab/autovideo/blob/main/autovideo/recognition/tsn_primitive.py#L31-78" rel="noopener ugc nofollow" target="_blank"/>。所有的超参数都可以在构建管道时指定，方法是在上面的<code class="fe nv nw nx mz b">config</code>字典中传递它们。</p><h2 id="98c0" class="nd mc iq bd md ni nj dn mh nk nl dp ml lf nm nn mn lj no np mp ln nq nr mr ns bi translated">火车:</h2><p id="4bcc" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">可以使用上面指定的配置对模型进行端到端训练。这里我们使用<strong class="ky ir"> <em class="lw">拟合</em> </strong>函数，该函数将训练模型并返回拟合的管道/模型。这可以保存下来供将来使用。下面是一个适合管道的示例:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="5090" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上述函数在训练集上进行训练，并在验证集上进行验证，以将最佳执行模型保存在验证集上用于推理阶段。fit函数的输出如下所示:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="833f" class="nd mc iq mz b gy ne nf l ng nh"><strong class="mz ir">Confidence Scores: </strong><br/>[[0.0692555  0.06158188 0.02618745 0.05211503 0.10426781 0.68659234]</span><span id="0245" class="nd mc iq mz b gy ny nf l ng nh">...</span><span id="04be" class="nd mc iq mz b gy ny nf l ng nh">[0.00917702 0.01555088 0.00744944 0.00688883 0.02226333 0.9386706 ]]</span></pre><p id="9b4d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的输出是在上面已经在训练集上训练之后的验证集中的视频的置信度分数。</p><p id="5e90" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，你可以在<a class="ae kv" href="https://github.com/datamllab/autovideo/blob/dd10cd61e2271455d335e3ac79cfebc82a8ac338/examples/fit.py#L1" rel="noopener ugc nofollow" target="_blank"> examples/fit.py </a>找到上述代码片段的完整示例代码。要使用fit()函数训练模型，只需运行:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="0222" class="nd mc iq mz b gy ne nf l ng nh">python3 examples/fit.py</span></pre><h2 id="9c47" class="nd mc iq bd md ni nj dn mh nk nl dp ml lf nm nn mn lj no np mp ln nq nr mr ns bi translated">推论:</h2><p id="1bef" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">我们可以加载使用<strong class="ky ir"> <em class="lw"> fit() </em> </strong>函数获得的训练模型权重，以检测样本视频上的动作或计算测试集上的准确度。可点击<a class="ae kv" href="https://drive.google.com/drive/folders/1j4iGUQG3m_TXbQ8mQnaR_teg1w0I2x60?usp=sharing" rel="noopener ugc nofollow" target="_blank">此处</a>下载一段演示视频和预训练的重量。在演示视频中检测动作的示例如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="0df5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是演示视频输出的GIF图:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/f0a51fbe702d9b817caadac0504f8b32.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/0*Vv6lo78pyj2tFriW.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="52d9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">或者，我们可以使用经过训练的模型来计算测试集的准确性。这里我们使用autovideo的<strong class="ky ir"> <em class="lw"> produce() </em> </strong>函数从测试集中获得<strong class="ky ir"> <em class="lw">预测</em> </strong>，然后使用<strong class="ky ir"><em class="lw">compute _ accuracy _ with _ preds()</em></strong>实用函数计算准确度。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="bfdb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里<strong class="ky ir"><em class="lw">test _ table _ path</em></strong>表示包含视频文件路径及其标签信息的测试csv文件，而<strong class="ky ir"><em class="lw">test _ media _ dir</em></strong>表示包含视频文件的媒体目录。</p><p id="1ba3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在测试集上计算精确度的完整代码可以在<a class="ae kv" href="https://github.com/datamllab/autovideo/blob/dd10cd61e2271455d335e3ac79cfebc82a8ac338/examples/produce.py#L1" rel="noopener ugc nofollow" target="_blank"> examples/produce.py </a>中找到。您可以使用以下命令运行此示例:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="83ec" class="nd mc iq mz b gy ne nf l ng nh">python3 examples/produce.py</span></pre><h1 id="c529" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">搜索器模块:</h1><p id="b09f" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">除了用指定的配置拟合模型之外，用户还可以使用调谐器以数据驱动的方式自动搜索管道(即，模型和超参数)。我们当前的系统支持两种类型的调谐器，包括随机搜索和Hyperopt。要使用自动搜索，您需要安装ray-tune和hyperopt以及:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="1050" class="nd mc iq mz b gy ne nf l ng nh">pip3 install 'ray[tune]' hyperopt</span></pre><p id="7dd1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">运行搜索器模块的示例界面如下。</p><h2 id="3ff7" class="nd mc iq bd md ni nj dn mh nk nl dp ml lf nm nn mn lj no np mp ln nq nr mr ns bi translated">加载数据:</h2><p id="e765" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">让我们通过在<strong class="ky ir"> <em class="lw"> train_table_path </em> </strong>和<strong class="ky ir"> <em class="lw"> valid_table_path中指定csv文件路径来加载训练和验证数据集。</em> </strong>搜索器使用<strong class="ky ir"> <em class="lw"> train_dataset </em> </strong>使用搜索器在每个样本中绘制的一组超参数来训练模型。搜索结束时超参数的最佳配置是在<strong class="ky ir"><em class="lw">valid _ dataset</em></strong>上具有最佳准确度的那些。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="924f" class="nd mc iq bd md ni nj dn mh nk nl dp ml lf nm nn mn lj no np mp ln nq nr mr ns bi translated">初始化搜索器模块:</h2><p id="295d" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">在这里，用户可以使用<strong class="ky ir"> RaySearcher </strong>为上面指定的数据集初始化搜索器模块。除了指定搜索算法(随机v/s超点)之外，用户还可以定义搜索空间(支持连续和离散空间)。在下面的例子中，我们使用了远视搜索。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="f03d" class="nd mc iq bd md ni nj dn mh nk nl dp ml lf nm nn mn lj no np mp ln nq nr mr ns bi translated">搜索:</h2><p id="4053" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">然后，调谐器将在搜索空间中搜索最佳超参数组合，以提高性能。下面是一个使用指定配置进行搜索并返回最佳超参数集的示例:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="8f4b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">搜索器的完整代码可以在<a class="ae kv" href="https://github.com/datamllab/autovideo/blob/dd10cd61e2271455d335e3ac79cfebc82a8ac338/examples/search.py#L1" rel="noopener ugc nofollow" target="_blank"> examples/search.py </a>中找到，可以使用以下命令运行:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="1980" class="nd mc iq mz b gy ne nf l ng nh">python3 examples/search.py</span></pre><h1 id="9e53" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">总结:</h1><p id="fb6d" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">要了解这个项目的更多信息，请点击查看。该团队正在积极开发项目的更多功能，包括带有可视化工具的图形用户界面，并添加更多的视频理解任务。我们的目标是让视频识别对每个人来说都更容易使用。我希望你喜欢阅读这篇文章。</p></div></div>    
</body>
</html>