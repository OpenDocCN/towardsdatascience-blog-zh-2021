<html>
<head>
<title>Can a Data Scientist Replace an NBA Scout? ML App Development for Best Transfer Suggestion</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一个数据科学家能代替一个NBA球探吗？最佳转会建议的ML应用程序开发</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/can-a-data-scientist-replace-a-nba-scout-ml-app-development-for-best-transfer-suggestion-f07066c2773?source=collection_archive---------16-----------------------#2021-09-03">https://towardsdatascience.com/can-a-data-scientist-replace-a-nba-scout-ml-app-development-for-best-transfer-suggestion-f07066c2773?source=collection_archive---------16-----------------------#2021-09-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="0c0c" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="9f43" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用NBA API创建自己的ML模型并预测最佳球员交易</h2></div><p id="686d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">“我有一个行动计划，但这个游戏是一个调整的游戏”</em> |迈克·沙舍夫斯基</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/0242a63ffc93d9a5a1ee2d9b3ab1c008.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8skiwEU2nUkpePnaSOyZlg.jpeg"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">照片由<a class="ae me" href="https://unsplash.com/@jcgellidon?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> JC Gellidon </a>在<a class="ae me" href="https://unsplash.com/photos/XmYSlYrupL8" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="7544" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">由于最近达到顶峰的希腊怪胎，我给了这个项目一个机会，这个项目我潜伏了几个月。那就NBA吧！</p><p id="0774" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">本文的主要内容是提出一个端到端的ML应用程序开发过程，其中包含了大量的监督和非监督算法，包括<strong class="kt jd">高斯混合模型(GMM) </strong>、<strong class="kt jd"> K-Means </strong>、<strong class="kt jd">主成分分析(PCA) </strong>、<strong class="kt jd"> XGBoost </strong>、<strong class="kt jd">随机森林和多项逻辑回归分类器</strong>。</p><h2 id="ee82" class="mf mg it bd mh mi mj dn mk ml mm dp mn la mo mp mq le mr ms mt li mu mv mw iz bi translated"><strong class="ak">概念</strong></h2><p id="aef3" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">在成功聚集威士忌品种以促进供应商的销售后，数据公司接受了一个新项目:协助密尔沃基雄鹿队在2020年交易窗口期间做出最佳下一步行动。即预先接触得分后卫(SG)位置的候选球员，并购买表现最好的球员。对篮球知识的无知让我想到了一个棘手的选择:</p><p id="ebac" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">请求NBA API，从过去赛季的比赛中获取球员数据(例如，助攻失误率、助攻百分比等)，以一种有意义的方式为总经理(GM)分类，并最终指导他应该在谁身上花费转会预算，怎么样？</p><p id="f37d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了更好地传达结果，我们做了几个假设:</p><p id="09e4" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">#1:我们在2020赛季(10月)结束。雄鹿通用为SG职位准备了3名候选人名单:<strong class="kt jd">朱·霍勒迪</strong>、<strong class="kt jd">丹尼·格伦</strong>、<strong class="kt jd">博格丹·博格达诺维奇</strong>。</p><p id="28e4" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">#2:为了完成任务，我们必须从数据中发现任何可能导致雄鹿在各自主场进攻中提高表现的见解(最大助攻数、最小失误数等)，同时<strong class="kt jd">保留</strong>其余的统计数据(即加权投篮命中率%等)。也就是说，我们不应该简单地建议总经理购买最好的传球手或得分手，因为这可能会损害其他有价值的数据。</p><h2 id="232c" class="mf mg it bd mh mi mj dn mk ml mm dp mn la mo mp mq le mr ms mt li mu mv mw iz bi translated">作案手法</h2><ol class=""><li id="0c50" class="nc nd it kt b ku mx kx my la ne le nf li ng lm nh ni nj nk bi translated">构建<strong class="kt jd">数据集</strong>；获取每个游戏的玩家统计数据(从现在开始“游戏”)。</li><li id="17b1" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">执行<strong class="kt jd">EDA；</strong>对变量的利用建立直觉，得出最早的结论。</li><li id="6172" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated"><strong class="kt jd">集群</strong>‘玩’通过<strong class="kt jd">K-Means</strong>&amp;<strong class="kt jd">GMM</strong>；揭示潜在模式并确定最适合该案例的群集。</li><li id="3ea4" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">使用现在标记的数据集(clusters = labels)，训练多个多类分类器，包括<strong class="kt jd">多项式</strong> <strong class="kt jd">逻辑回归</strong>，<strong class="kt jd">随机森林</strong> &amp; <strong class="kt jd"> XGBoost </strong>。</li><li id="0798" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">对候选球员的最新‘比赛’(2020赛季)进行<strong class="kt jd">预测</strong>，并据此对其进行基准测试。</li><li id="44de" class="nc nd it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated"><strong class="kt jd">通过构建&amp;服务API(在下一篇文章中分析<em class="ln">)，向最终用户提供</em></strong>训练好的模型。</li></ol><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi nq"><img src="../Images/bc03102d363ae1a7721588b6eb7fb467.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_xMzNQd-_s-vV65dnTuxow@2x.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">工作流程图(图片由作者提供)</p></figure><p id="94a2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">您可以运行解释过的工作流程的笔记本或脚本文件(。py)为自动的</em>。</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h1 id="604e" class="ny mg it bd mh nz oa ob mk oc od oe mn ki of kj mq kl og km mt ko oh kp mw oi bi translated">1.资料组</h1><p id="9ee1" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">该数据集分两步构建:(a)从这个Kaggle <a class="ae me" href="https://www.kaggle.com/wyattowalsh/basketball" rel="noopener ugc nofollow" target="_blank">数据集</a>开始，我们查询<code class="fe oj ok ol om b">basketball.sqlite</code>以提取2017-2020赛季的<code class="fe oj ok ol om b">GAME_IDs</code>,( b)我们向<a class="ae me" href="https://github.com/swar/nba_api" rel="noopener ugc nofollow" target="_blank"> NBA_api </a>发出请求以获取每场比赛的球员数据。</p><p id="1569" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">整个过程被打包在<code class="fe oj ok ol om b"><a class="ae me" href="https://github.com/makispl/ml-nba-transfer-suggestion-app/blob/main/src/dataset.py" rel="noopener ugc nofollow" target="_blank">dataset.py</a></code>中，你可以选择运行它，或者使用已经准备好的数据集，放在“<a class="ae me" href="https://github.com/makispl/ml-nba-transfer-suggestion-app/tree/main/data/raw" rel="noopener ugc nofollow" target="_blank"> data/raw </a>目录中。</p><p id="3220" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们使用2017-2019赛季的比赛来训练聚类和分类模型，并保留2020年的数据用于测试。以下是数据集的样本和对变量的充分的<a class="ae me" href="https://github.com/basketballrelativity/py_ball/wiki/BoxScore" rel="noopener ugc nofollow" target="_blank">解释</a>:</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated"><code class="fe oj ok ol om b">plays_df</code>数据集样本</p></figure><p id="c5ad" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">在减杂的脉络中，我不深究</em> <strong class="kt jd"> <em class="ln">数据清理</em> </strong> <em class="ln">和</em> <strong class="kt jd"> <em class="ln">预处理</em> </strong> <em class="ln">程序——大家可以分别参考</em><a class="ae me" href="https://github.com/makispl/ml-nba-transfer-suggestion-app/blob/main/notebooks/00_EDA.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="ln">00 _ EDA . ipynb</em></a><em class="ln">&amp;</em><a class="ae me" href="https://github.com/makispl/ml-nba-transfer-suggestion-app/blob/main/src/preprocess.py" rel="noopener ugc nofollow" target="_blank"><em class="ln">preprocess . py</em></a><em class="ln">。</em></p><h1 id="547e" class="ny mg it bd mh nz op ob mk oc oq oe mn ki or kj mq kl os km mt ko ot kp mw oi bi translated">2.电子设计自动化(Electronic Design Automation)</h1><p id="46ea" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">【<em class="ln"/><a class="ae me" href="https://github.com/makispl/ml-nba-transfer-suggestion-app/blob/main/notebooks/00_EDA.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="ln">00 _ EDA . ipynb</em></a>中提供了一个完整的EDA</p><p id="1c86" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">当涉及到评估SG的性能时，我们必须根据真正重要的东西来建立直觉。在这种情况下，我们根据领域知识将特性从最不重要的到最重要的进行分类。这也会让你更容易做出最终决定。</p><pre class="lp lq lr ls gt ou om ov ow aw ox bi"><span id="c279" class="mf mg it om b gy oy oz l pa pb"># classify features by domain importance<br/>group_1 = [OF_RATING,AST_PCT,AST_TOV,TM_TOV_PCT,EFG_PCT,TS_PCT,POSS]<br/>group_2 = [MIN, AST_RATIO, DREB_PCT]<br/>group_3 = [OREB_PCT, REB_PCT, USG_PCT, PACE, PACE_PER40, PIE]<br/>group_4 = [START_POSITION]<br/>group_5 = [DEF_RATING]</span></pre><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">已解释-分类特征</p></figure><p id="d610" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">简而言之，就零存在、重复样本或低方差而言，所有特征都是高质量的，而它们的边界是有意义的(没有不合理极值的可疑情况)。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pc"><img src="../Images/27eeccf436c16ebe1d270f13fc0171be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*djMaIqGd7igjeBfyGavdSA@2x.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">特征直方图</p></figure><p id="a792" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">然而，它们中的许多都包含了任一侧的异常值。这是意料之中的，因为我们处理的是真实的游戏，没有人(甚至是不同游戏中的同一玩家)能够总是在一个固定的性能“范围”内表现。</p><div class="lp lq lr ls gt ab cb"><figure class="pd lt pe pf pg ph pi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/b698b254835159ebad1e3c04188ef05e.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*0argwHnSE_OPdVaZhdfykg@2x.png"/></div></figure><figure class="pd lt pj pf pg ph pi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/79e7f37fdf28d24874cd4edcdd3dd6c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/1*gqMOqnapnBgrHn2CeJqO1g@2x.png"/></div></figure><figure class="pd lt pk pf pg ph pi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/65ecf4efa0e74d83c85af3209053e41f.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*idVIanJYMRMS2XAyr_URrQ@2x.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk pl di pm pn translated">特征的须盒图</p></figure></div><p id="3270" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">关于关键的一组<code class="fe oj ok ol om b">group_1</code>特征，它们在左右倾斜之间几乎是平衡的。然而，占主导地位的因素是超出相关上限的异常值的大量存在。有许多球员经常表现出色，超出预期，这一事实符合我们最初的结论:</p><blockquote class="po pp pq"><p id="ee54" class="kr ks ln kt b ku kv kd kw kx ky kg kz pr lb lc ld ps lf lg lh pt lj lk ll lm im bi translated"><strong class="kt jd">归纳#1 </strong>:我们必须深入研究<code class="fe oj ok ol om b">group_1</code>，不仅要保证各自特性的显著水平，而且不能损害(尽可能多的)其他特性。</p></blockquote><p id="4a20" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">考虑到这一点，我们启动了一种简单的方法，通过主特征(<code class="fe oj ok ol om b">AST_PCT</code>)对数据集进行排序，取其较高的部分(第95百分位)并“水平地”(跨所有特征)评估剧本。</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated"><code class="fe oj ok ol om b">plays_df</code>描述性统计(人口)</p></figure><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated"><code class="fe oj ok ol om b">plays_df</code>描述性统计(第95百分位)</p></figure><p id="2a28" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">结果令人失望。通过将人口与第95百分位的平均特征进行比较，我们看到随着<code class="fe oj ok ol om b">AST_PCT</code>的最大化，许多剩余的特征变得更差，违反了假设2。另外，我们也不愿意买一个助攻率很高但投篮表现很差的SG(<code class="fe oj ok ol om b">EFG_PCT</code>)！</p><p id="186a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">因此，很容易想到，我们无法基于简单的探索技术完成构建最佳SG轮廓的任务。因此:</p><blockquote class="po pp pq"><p id="d12a" class="kr ks ln kt b ku kv kd kw kx ky kg kz pr lb lc ld ps lf lg lh pt lj lk ll lm im bi translated"><strong class="kt jd">归纳#2 </strong>:我们必须在现有数据的基础上建立更好的直觉，并使用更先进的技术，有效地对其进行细分并捕捉潜在的模式，这可能会引导我们找到最佳的SG档案。</p></blockquote><p id="ea7b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">集群拿起火炬…</p><h1 id="3650" class="ny mg it bd mh nz op ob mk oc oq oe mn ki or kj mq kl os km mt ko ot kp mw oi bi translated">3.使聚集</h1><p id="d213" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">【<em class="ln">参考</em><a class="ae me" href="https://github.com/makispl/ml-nba-transfer-suggestion-app/blob/main/notebooks/01_clustering%5Bkmeans_gmm%5D.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="ln">01 _聚类【kmeans_gmm】。ipynb</em>T11】</a></p><h2 id="f65d" class="mf mg it bd mh mi mj dn mk ml mm dp mn la mo mp mq le mr ms mt li mu mv mw iz bi translated">k均值</h2><p id="9f6e" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">我们从流行的<strong class="kt jd"> K-Means </strong>算法开始，但是首先实现PCA，以便降低数据集的维数，同时保留大部分原始特征的方差[1]。</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">pca4clustering.py</p></figure><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pu"><img src="../Images/ce0c93b9dfa14ebc0297203ab79b3e27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_rspZcdUIZptjeKtaoNLYA@2x.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">PCA ~解释方差</p></figure><p id="a83a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们选择一个4部分的解决方案，因为它解释了至少80%的人口方差。接下来，我们通过使用<a class="ae me" href="https://en.wikipedia.org/wiki/Elbow_method_(clustering)" rel="noopener ugc nofollow" target="_blank">肘形法</a>并绘制WCSS线，找到最佳的簇数(k ):</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">locate _肘部. py</p></figure><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pv"><img src="../Images/dcafa7bcda091700f82002486766defb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4VbGpfDSX7rtcp3dAPrL7Q@2x.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">WCSS ~团簇图</p></figure><p id="c1cc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">最佳聚类数是4，我们准备好拟合K均值。</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">kmeans.py</p></figure><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pw"><img src="../Images/8e5fc2590e8d0a67d14d9c6c88f2baed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O5P9QyGZqApD-YulfyX_IQ@2x.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">k-均值聚类</p></figure><p id="935d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">得到的聚类还不错，但是分别有许多<code class="fe oj ok ol om b">cluster_2</code>和<code class="fe oj ok ol om b">cluster_3</code>蓝绿色&amp;蓝色的重叠点。为了寻求潜在的增强，我们将研究另一种聚类算法。这次不是基于距离，而是基于分布；<strong class="kt jd">高斯混合模型</strong>【2】。</p><h2 id="f0e9" class="mf mg it bd mh mi mj dn mk ml mm dp mn la mo mp mq le mr ms mt li mu mv mw iz bi translated">戈-梅-莫三氏:男性假两性畸形综合征</h2><p id="5f53" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">一般来说，GMM可以处理更多种类的形状，而不需要假设聚类是圆形的(像K-Means那样)。此外，作为一种概率算法，它为数据点分配概率，表示它们与特定聚类的关联有多强。然而，没有免费的午餐；GMM可能会很快收敛到局部最小值，从而恶化结果。为了解决这个问题，我们可以用K-Means初始化它们，通过调整各自的类参数[3]。</p><p id="b948" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了挑选合适的聚类数，我们可以利用Scikit中的<a class="ae me" href="https://scikit-learn.org/stable/modules/generated/sklearn.mixture.BayesianGaussianMixture.html" rel="noopener ugc nofollow" target="_blank">贝叶斯高斯混合模型</a>类——了解哪些权重聚类，将错误的聚类拉平为零或接近零。</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">贝叶斯_gm.py</p></figure><pre class="lp lq lr ls gt ou om ov ow aw ox bi"><span id="5306" class="mf mg it om b gy oy oz l pa pb"># returns<br/>array([0.07, 0.19, 0.03, 0.14, 0.19, 0.09, 0.06, 0.18, 0.05, 0.01])</span></pre><p id="aa99" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">显然，只有4个集群超过0.01阈值。</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">gmm.py</p></figure><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pw"><img src="../Images/35908412083f206f981dae8946a1ac58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IgYnUkgIKS0IZPKNn8H5nw@2x.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">GMM星团</p></figure><p id="8290" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">就是这样！<code class="fe oj ok ol om b">cluster_3</code>(蓝色)这次更好分离，而<code class="fe oj ok ol om b">cluster_2</code>(青绿色)也更好包容。</p><h2 id="aec4" class="mf mg it bd mh mi mj dn mk ml mm dp mn la mo mp mq le mr ms mt li mu mv mw iz bi translated">聚类评估</h2><p id="9e5b" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">为了增强聚类评估，我们引入了一个新的变量，它描述了被检查特征的净得分。对每组进行加权，以便更好地表达其对最终性能的影响，并计算它们的代数和。我将权重分配如下:</p><pre class="lp lq lr ls gt ou om ov ow aw ox bi"><span id="1373" class="mf mg it om b gy oy oz l pa pb">NET_SCORE = 0.5*group_1 + 0.3*group_2 + 0.2*group_3 - 0.3*group_5</span><span id="db97" class="mf mg it om b gy px oz l pa pb"># <!-- -->group_4<!-- --> (START_POSITION) shouldn't be scored (categorical feature)<br/># being a center ‘5’ doesn't mean to be ‘more’ of something a guard ‘1’ stands for!</span><span id="5526" class="mf mg it om b gy px oz l pa pb"># group_5 (DEF_RATING) is negative in nature<br/># it should be subtracted from the Net Score</span></pre><p id="b77f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">那么，让我们对集群进行评分和评估。</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">net_scoring.py</p></figure><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">通用汽车集群得分由<code class="fe oj ok ol om b">NET_SCORE</code></p></figure><p id="635a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">显然，<code class="fe oj ok ol om b">cluster_3</code>的表现优于其他产品，其<code class="fe oj ok ol om b">NET_SCORE</code>为aprox。662.49，而<code class="fe oj ok ol om b">cluster_1</code>紧随其后。但是，这里值得强调的是第95百分位和新引入的<code class="fe oj ok ol om b">cluster_3</code>之间的量化比较:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi py"><img src="../Images/6286b279f2d94382e56b850a4efd78ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mQ2gbD1b985U5QkruTS3Eg@2x.png"/></div></div></figure><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pz"><img src="../Images/baed66bb65aaee1cb8e8c7b3fd1f18e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VLNlTFKdoWIAh_9JlPMZ_A.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated"><code class="fe oj ok ol om b">NET_SCORE</code>第95百分位&amp; cluster_3的须盒图</p></figure><p id="d501" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">通过注意146.5个<code class="fe oj ok ol om b">NET_SCORE</code>单位的增加，可以清楚地看到<code class="fe oj ok ol om b">cluster_3</code>在第95百分位段中占主导地位！因此:</p><blockquote class="po pp pq"><p id="73c5" class="kr ks ln kt b ku kv kd kw kx ky kg kz pr lb lc ld ps lf lg lh pt lj lk ll lm im bi translated"><strong class="kt jd">归纳#3 </strong> : <code class="fe oj ok ol om b">Cluster_3</code>以一种真正平衡的方式概括了那些源自SG出色表现的“剧本”——<code class="fe oj ok ol om b">group_1</code>特性达到了较高水平，而其余大部分保持了不错的平均水平。该分析考虑了比最初尝试更多的特性(参考文献1)。EDA)，它利用了一个主导者(<code class="fe oj ok ol om b">AST_PCT</code>)。这证明了…</p><p id="fb2a" class="kr ks ln kt b ku kv kd kw kx ky kg kz pr lb lc ld ps lf lg lh pt lj lk ll lm im bi translated"><strong class="kt jd">归纳#4 </strong>:聚类促进了更全面的数据分离，这些数据来自更多组件的信号，沿着这些思路，我们设法揭示了顶级SG的预期性能的更清晰指示。</p></blockquote><p id="a6b3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在，我们能够操纵标记的(具有聚类)数据集，并开发一种方法来预测新样本(未标记的“播放”)所属的聚类。</p><h1 id="019c" class="ny mg it bd mh nz op ob mk oc oq oe mn ki or kj mq kl os km mt ko ot kp mw oi bi translated">4.分类器</h1><p id="1dfe" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">【<em class="ln">参考</em><a class="ae me" href="https://github.com/makispl/ml-nba-transfer-suggestion-app/blob/main/notebooks/02_classifying%5Blogres_rf_xgboost%5D.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="ln">02 _分类【logres_rf_xgboost】。ipynb </em> </a> ]</p><p id="f304" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们的问题属于多类分类的范畴，要采取的第一步是选择一个验证策略来解决潜在的过度拟合。</p><pre class="lp lq lr ls gt ou om ov ow aw ox bi"><span id="1c8a" class="mf mg it om b gy oy oz l pa pb"># check for the clusters' balance<br/>0    27508<br/>1    17886<br/>3    11770<br/>2     5729</span></pre><p id="b98e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">偏斜的数据集意味着必须选择一个<strong class="kt jd">分层K倍</strong>交叉验证，而不是随机验证。这将使标签的比率在每个折叠中保持不变，无论我们选择什么度量来评估，它都将给出相似的结果[4]。说到指标，F1分数(精确度和召回率的调和平均值)看起来比准确度更合适，因为目标是倾斜的[5]。</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">创建_折叠. py</p></figure><p id="393e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">接下来，我们<strong class="kt jd">标准化</strong>数据，以便训练我们的(基线)逻辑回归模型。请注意，这里首先要适合训练数据集，然后转换训练和测试数据。这对于避免数据泄露至关重要[6]！</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">基线_模型. py</p></figure><pre class="lp lq lr ls gt ou om ov ow aw ox bi"><span id="88cf" class="mf mg it om b gy oy oz l pa pb"># returns<br/>Mean F1 Score = 0.9959940207018171</span></pre><h2 id="9d05" class="mf mg it bd mh mi mj dn mk ml mm dp mn la mo mp mq le mr ms mt li mu mv mw iz bi translated">特征重要性</h2><p id="dd74" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">如此惊人的准确性从一开始就令人生疑。在检查特征重要性的可用方法中(例如MDI)，我选择了<strong class="kt jd">置换特征重要性</strong>，它是模型不可知的，因此我们能够对所有模型使用任何结论【7】。</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">置换_专长_重要性. py</p></figure><div class="lp lq lr ls gt ab cb"><figure class="pd lt qa pf pg ph pi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/ad307dce760afbae965f2cfe9bb8bb9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*WUeMUqLeVK0AADlAl30obA@2x.png"/></div></figure><figure class="pd lt qb pf pg ph pi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/f8df254cdb751a97e4fa8a2dddd475e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*k0pr1RmkEMG5xDDhCQOWAQ@2x.png"/></div></figure><figure class="pd lt qb pf pg ph pi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><img src="../Images/3647b839277910b3863a33fb2f75a647.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*HeCdm93PqmO3A8Vv5hxgWg@2x.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk qc di qd pn translated">排列特征重要性为:(a)所有特征，(b)所有<strong class="bd qe">≦</strong><code class="fe oj ok ol om b">START_POSITION</code>，(c)所有<strong class="bd qe">≦</strong><code class="fe oj ok ol om b">START_POSITION</code>，<code class="fe oj ok ol om b">MIN</code></p></figure></div><p id="cab0" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><code class="fe oj ok ol om b">START_POSITION</code>贡献的重要性极高(<em class="ln">单独计算，得分F1=0.865 </em>)。如果我们检查相关的描述性统计，我们看到所有的<code class="fe oj ok ol om b">group_1</code>特征在<code class="fe oj ok ol om b">START_POSITION</code>为0(即NaN)时得到最低水平。</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated"><code class="fe oj ok ol om b">START_POSITION</code>描述性统计</p></figure><p id="ada7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这<em class="ln">暴露了</em>这些玩家没有开始游戏，所以他们很有可能比其他人玩的时间少，因此他们的统计数据更差！这同样适用于<code class="fe oj ok ol om b">MIN</code>变量——它精确地表达了一名球员在球场上花费的时间。因此两者都会导致<strong class="kt jd">数据泄漏</strong>，我们忽略它们。除此之外，我们还区分了最重要的特征。</p><h2 id="dfdf" class="mf mg it bd mh mi mj dn mk ml mm dp mn la mo mp mq le mr ms mt li mu mv mw iz bi translated">特征工程</h2><p id="bcd2" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">此外，我们试图通过构建一个新的、数量更少的变量来减少特征的数量，这些变量捕获了原始信息的重要部分。我们再次将PCA置于聚光灯下，这一次尝试9和7组分。注意只使用剩余的标准化特征(≦<code class="fe oj ok ol om b">START_POSITION</code>，<code class="fe oj ok ol om b">MIN</code>)！</p><p id="a0a2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">最终，我们产生了以下特征“桶”:</p><pre class="lp lq lr ls gt ou om ov ow aw ox bi"><span id="66c4" class="mf mg it om b gy oy oz l pa pb">all_feats   = [all] - [<!-- -->START_POSITION<!-- -->,<!-- -->MIN]<br/>sgnft_feats = [all_feats] - [OFF_RATING,AST_TOV,PACE,PACE_PER40,PIE<!-- -->]<br/>pca_feats   = [pca x 9]<br/>pca_feats   = [pca x 7]</span></pre><h2 id="0123" class="mf mg it bd mh mi mj dn mk ml mm dp mn la mo mp mq le mr ms mt li mu mv mw iz bi translated">超参数优化</h2><p id="4260" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">在考虑了特征选择之后，我们开始优化每个模型的超参数。<a class="ae me" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" rel="noopener ugc nofollow" target="_blank"> GridSearch </a>非常有效，尽管很耗时。该过程与所有模型相似——为了简单起见，我只给出XGBoost案例:</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">xgboost_grid_search.py</p></figure><pre class="lp lq lr ls gt ou om ov ow aw ox bi"><span id="928c" class="mf mg it om b gy oy oz l pa pb"># returns<br/>Best score: 0.7152999106187636<br/>Best parameters set:<br/>      colsample_bytree: 1.0<br/>      lambda: 0.1,<br/>      max_depth: 3,<br/>      n_estimators: 200</span></pre><h2 id="0de3" class="mf mg it bd mh mi mj dn mk ml mm dp mn la mo mp mq le mr ms mt li mu mv mw iz bi translated">模型</h2><p id="a16c" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">现在，我们在<a class="ae me" href="https://github.com/makispl/ml-nba-transfer-suggestion-app/blob/main/src/model_dispatcher.py" rel="noopener ugc nofollow" target="_blank"> model_dipatcher.py </a>中声明每个模型的最佳超参数，它将我们选择的模型分派到train.py中。后者总结了整个训练过程，使训练具有每个特性“桶”的调整模型变得更加容易。我们得到:</p><pre class="lp lq lr ls gt ou om ov ow aw ox bi"><span id="3457" class="mf mg it om b gy oy oz l pa pb">## Logistic Regression ##</span><span id="14a9" class="mf mg it om b gy px oz l pa pb">   used               num_feats            F1_weighted<br/>=========      |      =========     |      ==========<br/>all_feats      |         16         |        0.7144<br/>sgnft_feats    |         11         |        0.7152<br/>pca_feats      |          9         |        0.7111 # sweet-spot<br/>pca_feats      |          7         |        0.7076</span><span id="3db5" class="mf mg it om b gy px oz l pa pb">## Random Forest ##</span><span id="7287" class="mf mg it om b gy px oz l pa pb">   used               num_feats             F1_weighted<br/>=========      |      =========     |       ==========<br/>all_feats      |         16         |         0.7213<br/>sgnft_feats    |         11         |         0.7145<br/>pca_feats      |          9         |         0.7100<br/>pca_feats      |          7         |         0.7049</span><span id="4981" class="mf mg it om b gy px oz l pa pb">## XGBoost ##</span><span id="adc7" class="mf mg it om b gy px oz l pa pb">   used               num_feats             F1_weighted<br/>=========      |      =========     |       ==========<br/>all_feats      |         16         |         0.7238  #best<br/>sgnft_feats    |         11         |         0.7168<br/>pca_feats      |          9         |         0.7104  <br/>pca_feats      |          7         |         0.7068</span></pre><p id="48ac" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> <em class="ln">注</em> </strong> <em class="ln">:由于模型的随机性质或数值精度，您的结果可能会有所不同。</em></p><p id="9ee5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">引入了经典的<em class="ln">性能</em>与<em class="ln">简单性</em>的权衡；我选择了具有pca_feats (x9)的逻辑回归的潜力来进一步进行。</p><h1 id="8330" class="ny mg it bd mh nz op ob mk oc oq oe mn ki or kj mq kl os km mt ko ot kp mw oi bi translated">5.预言</h1><p id="62ff" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">现在，对于测试数据集的剧本，我们通过使用所选择的模型来预测它们的聚类。</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">预测. py</p></figure><h2 id="2a9e" class="mf mg it bd mh mi mj dn mk ml mm dp mn la mo mp mq le mr ms mt li mu mv mw iz bi translated">确认</h2><p id="fbb6" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">为了进行验证，<em class="ln">基本事实</em>标签是必要的。然而，这不是我们的情况，因为测试数据集(<code class="fe oj ok ol om b">test_proc.csv</code>)没有被标记。您可能想知道为什么我们不通过聚类来标记它，但这将引导我们执行完全相同的程序，交叉验证已经完成了5次—隔离一小部分数据并进行验证。</p><p id="c594" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">相反，我们将通过进行定性检查来进一步评估分类器。我们可以手动检查一部分数据的标签，以确保它们是好的，或者将预测值与训练聚类进行比较，并检查任何主要的描述性统计数据是否仍然有效。</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="on oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">通过<code class="fe oj ok ol om b">NET_SCORE</code>预测集群得分</p></figure><p id="8642" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">事实上，<code class="fe oj ok ol om b">cluster_3</code>以109.35辆的<code class="fe oj ok ol om b">NET_SCORE</code>成绩再次领先于其他厂商，同时在大多数关键特性(<code class="fe oj ok ol om b">OFF_RATING</code>、<code class="fe oj ok ol om b">AST_PCT</code>、<code class="fe oj ok ol om b">AST_TOV</code>和<code class="fe oj ok ol om b">POSS</code>)上保持最高水平。</p><h2 id="1301" class="mf mg it bd mh mi mj dn mk ml mm dp mn la mo mp mq le mr ms mt li mu mv mw iz bi translated">交易</h2><p id="1cf3" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">最后也是最有趣的部分涉及到决策。首先，我们对候选球员(<strong class="kt jd">朱·霍勒迪</strong>、<strong class="kt jd">丹尼·格伦</strong>、<strong class="kt jd">博格丹·博格达诺维奇</strong>)在2020年上半赛季的“发挥”进行预测，并用各自的聚类对他们进行标注。</p><p id="5d40" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">然后我们检查它们在<em class="ln"/><code class="fe oj ok ol om b">cluster_3</code>中的成员资格，根据各自的<code class="fe oj ok ol om b">cluster_3_plays</code> / <code class="fe oj ok ol om b">total_plays</code>比率对它们进行排序。因此，我们运行<code class="fe oj ok ol om b">predict.py</code>脚本并得到:</p><pre class="lp lq lr ls gt ou om ov ow aw ox bi"><span id="3e11" class="mf mg it om b gy oy oz l pa pb"># Results<br/>{<br/> '<strong class="om jd">Jrue Holiday</strong>': <strong class="om jd">0.86</strong>,<br/> 'Bogdan Bogdanovic': 0.38,<br/> 'Danny Green': 0.06<br/>}</span></pre><p id="7920" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">你猜怎么着？</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="qf oo l"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">密尔沃基雄鹿队关于朱·霍勒迪转会太阳队的推特</p></figure><p id="f1bb" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">2020年11月24日，雄鹿官方宣布朱·霍勒迪交易！你这样认为；一个<strong class="kt jd">脱离现实的</strong>验证…</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><h2 id="6d38" class="mf mg it bd mh mi mj dn mk ml mm dp mn la mo mp mq le mr ms mt li mu mv mw iz bi translated"><strong class="ak">结论</strong></h2><p id="aa8a" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">到目前为止，我们已经走了很长的路……从Kaggle &amp; NBA API开始，我们建立了一个庞大的数据集，对它进行了聚类，并揭示了成为一名真正优秀的得分后卫所需要的深刻模式。然后，我们在带标签的数据集上训练各种分类模型，以相当高的精度预测新玩家条目可能注册的集群。通过这样做，我们成功地聚焦了密尔沃基雄鹿队的下一步行动。)拿着，去补SG的位置。</p><p id="4f1f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">类似于<a class="ae me" rel="noopener" target="_blank" href="/can-a-data-scientist-replace-a-dj-spotify-manipulation-with-python-fbbd4a45ffd5"> DJ vs数据科学家</a>的案例，几乎不可能武断地回答数据科学在球探领域的潜力。然而，时代的迹象再次表明了人工智能在体育产业决策领域实施的有利温床…</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi qg"><img src="../Images/d25183dd9acdbf38684c7a085b3f6594.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qfKhmv8-ff7dARlSw445TQ.jpeg"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">照片由<a class="ae me" href="https://unsplash.com/@patrickian4?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">帕特里克·福尔</a>在<a class="ae me" href="https://unsplash.com/photos/DVpn-Ot0fV4" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="57ea" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我把这个项目献给我的好朋友<a class="ae me" href="https://medium.com/@djmouzz/about" rel="noopener">帕诺斯</a>——一个狂热的篮球迷、天文爱好者和IT专家。</p><p id="ef0b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">感谢您的阅读&amp;祝您度过愉快的一周！如果有任何问题，欢迎在下面留言或通过<a class="ae me" href="https://twitter.com/MPlegas" rel="noopener ugc nofollow" target="_blank"> Twitter </a> / <a class="ae me" href="https://www.linkedin.com/in/gerasimosplegas" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系我。无论如何…</p><p id="c89c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">坐下来，克隆<a class="ae me" href="https://github.com/makispl/ml-nba-transfer-suggestion-app" rel="noopener ugc nofollow" target="_blank">回购</a>，开始下一步……行动🤝</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><p id="a06a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">参考文献</strong></p><p id="ab6d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">[1]<a class="ae me" href="https://machinelearningmastery.com/dimensionality-reduction-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/dimensionally-reduction-for-machine-learning/</a></p><p id="6105" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">[2]<a class="ae me" href="https://www.analyticsvidhya.com/blog/2019/10/gaussian-mixture-models-clustering/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2019/10/Gaussian-mixture-models-clustering/</a></p><p id="e56e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">[3]<a class="ae me" rel="noopener" target="_blank" href="/gaussian-mixture-models-vs-k-means-which-one-to-choose-62f2736025f0">https://towards data science . com/Gaussian-mixture-models-vs-k-means-one-to-choose-62f 2736025 f 0</a></p><p id="7cba" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">[4] A .塔库尔，<a class="ae me" href="https://www.amazon.com/Approaching-Almost-Machine-Learning-Problem/dp/8269211508/ref=tmm_pap_swatch_0?_encoding=UTF8&amp;qid=&amp;sr=" rel="noopener ugc nofollow" target="_blank">《接近(几乎)任何机器学习问题</a>，第一版(2020)，isbn-10‏: 9390274435</p><p id="a487" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">[5]<a class="ae me" rel="noopener" target="_blank" href="/comprehensive-guide-on-multiclass-classification-metrics-af94cfb83fbd">https://towards data science . com/comprehensive-guide-on-multi class-classification-metrics-af 94 CFB 83 FBD</a></p><p id="a5b5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">[6]<a class="ae me" href="https://machinelearningmastery.com/data-preparation-without-data-leakage/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/data-preparation-without data-leaving/</a></p><p id="c7d5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">[7]<a class="ae me" href="https://scikit-learn.org/stable/modules/permutation_importance.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/permutation _ importance . html</a></p></div></div>    
</body>
</html>