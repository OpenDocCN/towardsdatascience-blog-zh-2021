<html>
<head>
<title>Multivariate Fractional Polynomials: Why Isn’t This Used More?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多元分式多项式:为什么这个没有被更多的使用？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multivariate-fractional-polynomials-why-isnt-this-used-more-1a1fa9ead12c?source=collection_archive---------12-----------------------#2021-11-09">https://towardsdatascience.com/multivariate-fractional-polynomials-why-isnt-this-used-more-1a1fa9ead12c?source=collection_archive---------12-----------------------#2021-11-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="f7c9" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/tips-and-tricks" rel="noopener" target="_blank">提示和技巧</a></h2><div class=""/><div class=""><h2 id="5eca" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">…为什么 R 和 Stata 得到了所有的乐趣？</h2></div><p id="c22a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果你的数据有一些非常奇怪的形状，你会怎么做？像，<em class="lk">真的很诡异</em>？除了说“#@ &amp; % it”并决定使用决策树之外？一旦你学会了非参数模型，你很容易认为参数模型太笨拙了，不能认真考虑更复杂的建模项目。您可能知道也可能不知道，像决策树、K-最近邻等非参数模型提供了一个显著的优势，因为它们不像参数模型那样对基础分布或方程做出假设。顾名思义——参数模型试图找到<em class="lk">参数</em>或一些最能描述数据的方程或直线，这不是一件轻而易举的事情！事实上，在野外数据很少采用漂亮、舒适的线性形式:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/bc8c20a192befb995ce90e3e5eaeb7df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*FuTlRqx4oyA6Zrl0rYB5sg.png"/></div><p class="lt lu gj gh gi lv lw bd b be z dk translated">像这样的数据大多存在于入门课程和我的梦里。图<em class="lx"> e 作者</em></p></figure><p id="6a54" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">更常见的是，您会得到这样的噩梦数据:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/ccc25d6f12a599da0d22535510b84c09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*AugjbB1d6b8X3oD3_RJj5w.png"/></div><p class="lt lu gj gh gi lv lw bd b be z dk translated">上帝啊。被作者诅咒的形象</p></figure><p id="1b85" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">您可能认为参数估计过于局限，注定产生不充分的结果。那么你如何处理这个问题呢？正如我在上面提到的，您可以完全避免参数化建模，但是这会带来一系列的问题。有时候，你真的必须接受现实，使用参数模型。因为你有一组创造性的数据点，你需要创造性地使用你的方法来建模。这就是多元分数多项式(MFP)的用武之地。</p><p id="6cbe" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我在研究<a class="ae lz" href="https://medium.com/@nicholasindorf/messed-up-models-fiddling-with-feature-selection-two-ways-41363bbb74a0" rel="noopener">我之前的博客文章</a>时偶然发现了这种技术(以及 R 和 Stata 中的函数)，并最终阅读了太多关于它的内容，以至于我决定最好将其保存到自己的文章中。实际上，我很惊讶网络上没有更多关于它的信息——似乎大多数关于它的讨论或使用它的论文都局限于某些统计空间和医学科学社区。我认为，由于其巨大的潜力，它将被用于其他地方，或者至少作为一个 Scikit-learn 风格的实用程序。但是没有！甚至没有讨论它在 Python 中的使用，这让我感到非常困惑。</p><p id="6900" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">所以真的，所有这些的重点是把它作为一个强大的工具放在你的雷达上。MFP 算法将复杂的特征工程和选择一气呵成地结合在一起，以简洁、程序化和统计上合理的方式完成。谁还能要求更多？在这篇博文中，我将带您浏览我偶然发现的各种论文，并带您了解其总体思想，狂热地谈论它的力量，并指出您可能在哪里获得它以供使用。</p><p id="cdef" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">但是在我进入 MFP 的细节之前，一个关于参数化建模的简单入门…</p><h1 id="0aed" class="ma mb iq bd mc md me mf mg mh mi mj mk kf ml kg mm ki mn kj mo kl mp km mq mr bi translated">参数化建模</h1><p id="ddb9" class="pw-post-body-paragraph ko kp iq kq b kr ms ka kt ku mt kd kw kx mu kz la lb mv ld le lf mw lh li lj ij bi translated">这背后的整个想法是，你需要得到某种线来拟合一堆数据点。这在线性回归中可能是最好的例证，线性回归由如下等式描述:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/262fd45e86bbd44da633165cd335b3e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/0*v-w89Hz9RjxkQs1a.png"/></div><p class="lt lu gj gh gi lv lw bd b be z dk translated">奥格。作者图</p></figure><p id="c345" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在 2D，您可以像这样对上面第一幅图中的数据进行图形化建模:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/c462d1b6e02124e4fc8cf8a09ae073f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*lQfY2D0bwU-cCmCuJITFrg.png"/></div><p class="lt lu gj gh gi lv lw bd b be z dk translated">是的，这是一条线。图<em class="lx"> e </em>作者</p></figure><p id="4eb5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于许多变量来说，这条线可能存在于比我们原始的 3D 大脑所能想象的更多的维度中，但它以同样的方式工作。</p><p id="3f27" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">一个因变量是潜在的许多独立输入变量的输出。请注意，从现在开始，我将只谈论连续变量:那些可以在一个范围内取任何数值的变量。你开始的基本假设是，无党派人士(X，见上图)是一级的——也就是说，是一次幂。但是你不需要限制自己。为了使关系更加线性，独立变量有试验的余地，这就是特征工程的领域。你可以创建交互项，多项式特征，对数变换，任何原始数据的变换。sterling Scikit-learn，在其无限的效用中，有一些函数可以帮助:多项式特性，最显著的。对于门外汉来说，它使你能够在一行代码中，通过将所有的原件相乘或相乘来创建一堆新的特性。比如，如果你有特征 A，B，C，你可以得到 A*B，A*C，A，B*C，B，C 的 2 次多项式特征。</p><p id="feaf" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然而，除了前面提到的实用程序之外，以编程方式创建非线性特性并不容易，通常需要一定程度的领域专业知识来知道应该注意什么。但是这也需要一些猜测，而且不管你对这个领域了解多少，你都不太可能想到极其复杂和描述性的工程特性。从多项式特性的角度来看，仅仅制造一船的特性会导致其他问题，因为只有一小部分是真正重要的。这种散弹枪式的方法需要<a class="ae lz" href="https://medium.com/@nicholasindorf/messed-up-models-fiddling-with-feature-selection-two-ways-41363bbb74a0" rel="noopener">一些健壮的特征选择</a>,以便去除你刚刚添加的所有不必要的复杂性，留下真正重要的复杂术语。</p><p id="24d1" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果我们可以创造一些极其复杂的术语<strong class="kq ja"> <em class="lk">和</em> </strong>来去除不必要的复杂性，会怎么样？</p><h1 id="2f9b" class="ma mb iq bd mc md me mf mg mh mi mj mk kf ml kg mm ki mn kj mo kl mp km mq mr bi translated">多元分数多项式(MFP)</h1><p id="a5d8" class="pw-post-body-paragraph ko kp iq kq b kr ms ka kt ku mt kd kw kx mu kz la lb mv ld le lf mw lh li lj ij bi translated">据我所知，这项技术最早发表于 1994 年，来自《皇家统计学会杂志》，作者是帕特里克·罗伊斯顿和道格拉斯·g·奥特曼。在论文的总结中，他们描述了我在上面描述的一些相同的弱点，以及其他一些，给出了传统曲率解决方案的失败的完整描述。然后，他们提出了一个解决方案，即“扩展的曲线族……其幂项被限制在一个预定义的整数和非整数值的小集合中”。幂的选择使得传统多项式成为该族的子集这个列表包含了你可以为一个变量设计的最重要的特性。然后，他们继续说，这或多或少是在文献中出现了一段时间的东西的形式化，并断言强积金的灵活性和易用性。在论文的后面，他们提出了一种算法，用于迭代地为每个因变量选择该族中的幂。这就是我上面提到的关键特征选择组件的用武之地，因为它包括作为过程一部分的向后消除。这篇论文以医学中的几个例子作为结尾——也许这是一个有趣的预兆，预示着这种技术直到今天仍然存在于这个领域。我不会深入研究本文中的各种例子(以及下面的其他例子)，但是请看看这种技术如何处理真实世界的数据。挺有意思的。此外，如果你渴望更多的例子，简单地搜索“多元分数多项式”就会从医学数据空间中得到大量的例子。</p><h2 id="fab9" class="my mb iq bd mc mz na dn mg nb nc dp mk kx nd ne mm lb nf ng mo lf nh ni mq iw bi translated">“曲线族”:特征工程变得更容易</h2><p id="cbac" class="pw-post-body-paragraph ko kp iq kq b kr ms ka kt ku mt kd kw kx mu kz la lb mv ld le lf mw lh li lj ij bi translated">我们将首先深入研究他们的“曲线族”的基本设置，然后深入研究他们提出的迭代算法。来自<a class="ae lz" href="http://www.vjsonline.org/sites/default/files/PDF/c111402-Communication-Modelling%20continuous%20risk%20variables%20Introduction%20to%20fractional%20polynomial%20regression.pdf" rel="noopener ugc nofollow" target="_blank"> Duong 等人(2014) </a>的这篇论文提供了一个比我能想到的任何东西都好得多的总结。有一个预定义的集合 S = {-2，-1，-0.5，0，0.5，1，2，3}包含了你的自变量的所有可能的幂(0 定义为 ln(X))。您的变量可以采用 x^p(1 度)或 x^p1+x^p2(2 度)的形式来表示不同的幂值(p、p1 和 p2)，这些值取自集合 s。从技术上讲，这可以扩展到 2 度以上，但 Royston 和 Altman 认为这是不必要的。这两次分数多项式(FP)是这样构造的:</p><blockquote class="nj nk nl"><p id="de90" class="ko kp lk kq b kr ks ka kt ku kv kd kw nm ky kz la nn lc ld le no lg lh li lj ij bi translated"><strong class="kq ja"> FP 度 1 带 1 次方 p: </strong></p><p id="4c58" class="ko kp lk kq b kr ks ka kt ku kv kd kw nm ky kz la nn lc ld le no lg lh li lj ij bi translated">y = β0 +β1X^p</p><p id="054e" class="ko kp lk kq b kr ks ka kt ku kv kd kw nm ky kz la nn lc ld le no lg lh li lj ij bi translated">(当 p=0 时):y= β0 +β1ln(X)</p><p id="749c" class="ko kp lk kq b kr ks ka kt ku kv kd kw nm ky kz la nn lc ld le no lg lh li lj ij bi translated"><strong class="kq ja"> FP 度 2 带一对幂(p1，p2): </strong></p><p id="8bc8" class="ko kp lk kq b kr ks ka kt ku kv kd kw nm ky kz la nn lc ld le no lg lh li lj ij bi translated">y = β0 + β1X^p1 + β2X^p2(适用于 p=0 的相同规则)</p><p id="b8fe" class="ko kp lk kq b kr ks ka kt ku kv kd kw nm ky kz la nn lc ld le no lg lh li lj ij bi translated">(当 p1=p2 时):y = β0 + β1X^p1 + β2X^p2*ln(X)</p></blockquote><p id="f5d3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">根据这种结构，FP1 有 8 种不同功率值的 8 种模型，FP2 有 36 种不同的模型——这 8 种值的 28 种组合和 8 种重复组合。总的来说，我们有 44 种可能的模型来拟合我们的数据。重要的是，要记住这些只是起点，系数<em class="lk"> β </em>的值也会严重改变这些线的形状(见下文)。</p><p id="e0b8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">那又怎样？仅仅基于方程式，可能很难看出其中的价值；我听到了。一个直观的演示可能最能解释为什么这 44 个模型如此有效。当你看下面的图表时，思考一下线迹有多复杂，仅仅通过盯着散点图来试图独自思考这个问题是多么令人头痛。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi np"><img src="../Images/75423b3977fbab7d0ee5a1f200471d62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gSVD8mU7UGwkr0NDP-si9w.png"/></div></div><p class="lt lu gj gh gi lv lw bd b be z dk translated">FP 1 次多项式，从 X=~0 到刚好高于 X=1。所有<em class="lx">β</em>-系数= 1。作者图，灵感来自<a class="ae lz" href="http://www.vjsonline.org/sites/default/files/PDF/c111402-Communication-Modelling%20continuous%20risk%20variables%20Introduction%20to%20fractional%20polynomial%20regression.pdf" rel="noopener ugc nofollow" target="_blank"> Duong 等人</a></p></figure><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi nu"><img src="../Images/6d7855616f27e6e9f9947cee2b76f6fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mM-GgxBB0gOJ4DKqHIsJrg.png"/></div></div><p class="lt lu gj gh gi lv lw bd b be z dk translated">FP 1 次多项式，从 X=1 到 X=5。所有<em class="lx">β</em>-系数= 1。作者图，灵感来自<a class="ae lz" href="http://www.vjsonline.org/sites/default/files/PDF/c111402-Communication-Modelling%20continuous%20risk%20variables%20Introduction%20to%20fractional%20polynomial%20regression.pdf" rel="noopener ugc nofollow" target="_blank"> Duong 等人</a></p></figure><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi nv"><img src="../Images/63232f0239625494a4e454db521ace95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jfu4b2olN1GhWjASVhRntQ.png"/></div></div><p class="lt lu gj gh gi lv lw bd b be z dk translated">FP 次多项式。根据上述结构，元组表示 X 的幂。所有<em class="lx">β</em>-系数= 1。我花了很长时间做这个。作者图，灵感来自<a class="ae lz" href="https://www.jstor.org/stable/2986270" rel="noopener ugc nofollow" target="_blank">罗伊斯顿等人</a></p></figure><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi nw"><img src="../Images/a390731ee96e8297ff20a330a55eea33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qx67wSvQrxV6c5j-hnA8Vg.png"/></div></div><p class="lt lu gj gh gi lv lw bd b be z dk translated">形式为(-0.5，2)的 FP 次 2 多项式，具有不同的<em class="lx">β</em>-系数值。作者图，灵感来自<a class="ae lz" href="https://www.jstor.org/stable/2986270" rel="noopener ugc nofollow" target="_blank">罗伊斯顿等人</a></p></figure><p id="7c41" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果有希望的话，你会得出和我一样的结论，那就是在没有帮助的情况下想出这个几乎是不可能的！这就是特征工程的力量所在——这种方法为我们的独立变量提供了一组最具描述性的力量，以及将它们放在一起的结构。这就足够了，但是方法<em class="lk">还附带了一个特性选择组件。</em></p><h2 id="e957" class="my mb iq bd mc mz na dn mg nb nc dp mk kx nd ne mm lb nf ng mo lf nh ni mq iw bi translated">内置功能选择</h2><p id="a849" class="pw-post-body-paragraph ko kp iq kq b kr ms ka kt ku mt kd kw kx mu kz la lb mv ld le lf mw lh li lj ij bi translated">同样，我将使用其他人的清晰解释来涵盖这一点，这些解释来自<a class="ae lz" href="http://www.vjsonline.org/sites/default/files/PDF/c111402-Communication-Modelling%20continuous%20risk%20variables%20Introduction%20to%20fractional%20polynomial%20regression.pdf" rel="noopener ugc nofollow" target="_blank"> Duong </a>和<a class="ae lz" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4876277/" rel="noopener ugc nofollow" target="_blank">张等人(2016) </a>。张概述了一般程序，如何选择适当的程度和正确的权力，为您的自变量。它首先指出该过程有两个组成部分:</p><ol class=""><li id="8761" class="nx ny iq kq b kr ks ku kv kx nz lb oa lf ob lj oc od oe of bi translated">统计上无关紧要的变量的反向消除</li><li id="25dc" class="nx ny iq kq b kr og ku oh kx oi lb oj lf ok lj oc od oe of bi translated">变量 FP 度的迭代检验</li></ol><p id="53ce" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">相应地，对于上述两个部分，您需要两个显著性水平:<em class="lk"> α1 </em>，用于排除/包含变量，以及<em class="lk"> α2 </em>，用于确定分数变换的显著性。注意<em class="lk"> a1 </em>和<em class="lk"> a2 </em>可以是(并且经常是)相同的值，但是这是你可以随意处理的。</p><p id="0de3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因此，有了你的<em class="lk"> α </em>值和连续变量列表，你就可以开始建立一个包含所有变量的多变量线性模型。或者，您可以对目标的每个变量进行单变量分析，并且只包括那些具有<em class="lk"> p </em> &lt; 0.25 或 0.2 的变量，以帮助削减真正不重要的变量。然后，从第一个模型开始，按照 p 值递增的顺序组织所有变量。</p><p id="0dbc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">接下来，您选择最高、最低的<em class="lk"> p </em>值变量并开始封闭测试，该测试跟踪变量形式的变化如何影响整个模型的拟合(也就是它不是一个单变量模型)。这如下进行(来自 Duong 的关于统计测试的细节):</p><ol class=""><li id="7e9e" class="nx ny iq kq b kr ks ku kv kx nz lb oa lf ob lj oc od oe of bi translated">根据偏差(也称为模型误差)，找到该变量的最佳拟合二次分数多项式(FP2)。使用具有 4 个自由度的卡方差检验，将其与零模型(变量不存在)进行比较。如果测试不显著(根据<em class="lk"> α1 </em>)，则删除变量，并得出变量对目标没有影响的结论。否则，继续。</li><li id="99a1" class="nx ny iq kq b kr og ku oh kx oi lb oj lf ok lj oc od oe of bi translated">使用具有 3 个自由度的卡方差检验，将步骤 1 中的 FP2 模型与线性模型(可变功率= 1)进行比较，以确定非线性。如果测试不显著(根据<em class="lk"> α2 </em>，变量是线性的，封闭测试结束。否则，继续。</li><li id="00f3" class="nx ny iq kq b kr og ku oh kx oi lb oj lf ok lj oc od oe of bi translated">类似于步骤 1，为变量找到最佳拟合的一次分数多项式(FP1)。使用 2 个自由度的卡方差检验与 FP2 模型进行比较。如果测试不显著(根据<em class="lk"> α2 </em>，模型不会从额外的复杂性中受益，正确的模型是 FP1。</li></ol><p id="b449" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lk">(关于我们为什么使用卡方差检验来评估这些模型的更多信息，</em> <a class="ae lz" href="https://www.psychologie.uzh.ch/dam/jcr:ffffffff-b371-2797-0000-00000fda8f29/chisquare_diff_en.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lk">看这里</em> </a> <em class="lk"> ) </em></p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/383e96953fda6d04313df005853c8200.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*a3eQ3mR3pLwTThqcq6pJXA.png"/></div><p class="lt lu gj gh gi lv lw bd b be z dk translated">上述封闭测试算法的流程图。图由作者提供，灵感来自<a class="ae lz" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4876277/" rel="noopener ugc nofollow" target="_blank">张等人</a></p></figure><p id="9d3b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在，一旦您对最低的<em class="lk"> p </em>值变量执行了上述封闭测试，您就可以对先前在原始大线性模型中生成的有序列表中的下一个最高的<em class="lk"> p </em>值变量进行同样的评估。先前 X 的 FP 形式被保留，但是<em class="lk"> β </em>系数可以相应地改变。每隔一个变量继续这样，这标志着第一个周期。第二个周期是相同的过程，只是从第二低的<em class="lk"> p </em>值变量开始，并保持先前低的<em class="lk"> p </em>值变量的 FP 形式。这个循环过程迭代地继续，直到两个循环收敛，并且没有发生变化。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi om"><img src="../Images/9b0de47ca98407d160cd524b6ba69963.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-m3l2LI29DyDMFo8SlEFKQ.png"/></div></div><p class="lt lu gj gh gi lv lw bd b be z dk translated">查找模型中所有变量的 FPs 的流程图。图由作者提供，灵感来自<a class="ae lz" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4876277/" rel="noopener ugc nofollow" target="_blank">张等人</a></p></figure><h2 id="773d" class="my mb iq bd mc mz na dn mg nb nc dp mk kx nd ne mm lb nf ng mo lf nh ni mq iw bi translated">更复杂，对于顽固的复杂</h2><p id="88b6" class="pw-post-body-paragraph ko kp iq kq b kr ms ka kt ku mt kd kw kx mu kz la lb mv ld le lf mw lh li lj ij bi translated">如果你的数据不知何故是<em class="lk">特别是</em>香蕉，愿上帝保佑，你可以考虑用你漂亮的新 FPs 做其他事情。它们可能足够复杂，但是您可以考虑将 FPs 乘以一个多项式特性。类似地，您可能决定完全避开 MFP 判定算法(直接在上面)，而简单地用 FP 集合 S (= {-2，-1，-0.5，0，0.5，1，2，3}，其中 0 为 ln(X))中的幂的变量来构造多项式特征。考虑到包含负幂、ln 和平方根，与基多项式特性相比，这可能仍会为您提供相当多的额外建模能力。当然，以上任何一个决定都可能需要<a class="ae lz" href="https://medium.com/@nicholasindorf/messed-up-models-fiddling-with-feature-selection-two-ways-41363bbb74a0" rel="noopener">额外的特性选择</a>。</p><h2 id="ca7d" class="my mb iq bd mc mz na dn mg nb nc dp mk kx nd ne mm lb nf ng mo lf nh ni mq iw bi translated">缺点，因为不是一切都是完美的</h2><p id="b146" class="pw-post-body-paragraph ko kp iq kq b kr ms ka kt ku mt kd kw kx mu kz la lb mv ld le lf mw lh li lj ij bi translated">据我所知，MFP 的主要缺点在于计算量太大。但我认为这并不十分令人惊讶，因为你需要经历多少步骤才能找到每个特征的理想 FP 形式——在一个典型的场景中，选择算法需要计算 44 个模型进行比较，每个特征的<em class="lk"/>，这可能需要相当长的时间。但放在上下文中，能够捕捉相似复杂程度的模型(例如，网格搜索随机森林或神经网络)可能不会好到哪里去。此外，对于其他一些模型，运行时间会减少，但最终会牺牲可解释性。MFP 似乎取得了很好的平衡。</p><p id="1e9a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">此外，MFP 似乎忽略了交互条款，这可能会削弱其作为工具的整体实力。如果两个变量有协同效应，MFP 将在算法执行时忽略它们。解决这个问题的一个简单方法是在开始时加入交互术语，但是增加特性会增加已经很昂贵的流程的运行时间，正如我刚才提到的。或者，正如我在上一节中所述，您可以完全放弃内置的选择算法，尝试一种多项式 Features 类型的工作流，只需使用 FP set S 中的幂。这肯定是一种可以尝试的方法，可以看出什么效果最好。</p><h1 id="513e" class="ma mb iq bd mc md me mf mg mh mi mj mk kf ml kg mm ki mn kj mo kl mp km mq mr bi translated">开门见山 Python 包在哪里？</h1><p id="60fd" class="pw-post-body-paragraph ko kp iq kq b kr ms ka kt ku mt kd kw kx mu kz la lb mv ld le lf mw lh li lj ij bi translated">谢谢你读到这里，我知道这是相当多的细节。不幸的是，我在另一边没有任何好消息给你。根据大量的搜索，似乎没有简单的方法可以将它集成到基于 Python 的数据项目中。我为所有没有回报的构建道歉——在许多方面，这篇文章表达了我自己的沮丧。正如我在引言中提到的，在医学统计学的范围之外，对这种非常强大的方法没有太多的讨论(如果有的话)，尽管它的广泛用途是显而易见的。它确实作为函数存在于<a class="ae lz" href="https://cran.r-project.org/web/packages/mfp/vignettes/mfp_vignette.pdf" rel="noopener ugc nofollow" target="_blank"> R </a>和<a class="ae lz" href="https://www.stata.com/manuals13/rmfp.pdf" rel="noopener ugc nofollow" target="_blank"> Stata </a>中，但是除非我遗漏了某人晦涩的 GitHub repo，否则它不存在于任何 Python 包中，坦率地说，我觉得这很令人震惊。Python 中最接近于建模这种级别的曲线细节的是 Scikit-learn 的<a class="ae lz" href="https://scikit-learn.org/dev/auto_examples/linear_model/plot_polynomial_interpolation.html" rel="noopener ugc nofollow" target="_blank">样条函数</a>，它似乎做得很好——但它本身很难处理，而且 MFP 方法有明显的优势。</p><p id="20f5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这种技术与统计世界的其他部分隔离开来真的很糟糕，如果幸运的话，这篇文章可能会激发一些改变。也许我会改变，写一个 Scikit-learn 风格的实用程序来执行 MFP 和增压我的参数模型，当我这样做时，我会确保链接下面的 GitHub repo。但与此同时，亲爱的读者，如果你现在迫切需要这个功能，希望你能够使用我在这篇文章中列出的资源作为起点，同时构建自己的功能。</p><h1 id="23f0" class="ma mb iq bd mc md me mf mg mh mi mj mk kf ml kg mm ki mn kj mo kl mp km mq mr bi translated"><em class="lx">参考文献:</em></h1><p id="0af7" class="pw-post-body-paragraph ko kp iq kq b kr ms ka kt ku mt kd kw kx mu kz la lb mv ld le lf mw lh li lj ij bi translated">罗伊斯顿博士和奥特曼博士(1994 年)。使用连续协变量的分数多项式回归:简约参数模型。皇家统计学会杂志。系列 C(应用统计学)，<em class="lk"> 43 </em> (3)，429–467。<a class="ae lz" href="https://doi.org/10.2307/2986270" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.2307/2986270</a></p><p id="94b6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">Duong 和 d . Volding(2014 年)。模拟连续风险变量:分数多项式回归导论。<em class="lk">越南科学杂志，1 </em> (2)，1–5。</p><p id="ad18" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">张 Z. (2016)。回归模型的多元分式多项式方法。<em class="lk">转化医学年鉴</em>，<em class="lk"> 4 </em> (9)，174 页。<a class="ae lz" href="https://doi.org/10.21037/atm.2016.05.01" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.21037/atm.2016.05.01</a></p></div></div>    
</body>
</html>