<html>
<head>
<title>The Concept of Artificial Neurons (Perceptrons) in Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络中人工神经元(感知器)的概念</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-concept-of-artificial-neurons-perceptrons-in-neural-networks-fab22249cbfc?source=collection_archive---------1-----------------------#2021-12-26">https://towardsdatascience.com/the-concept-of-artificial-neurons-perceptrons-in-neural-networks-fab22249cbfc?source=collection_archive---------1-----------------------#2021-12-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3d91" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">神经网络和深度学习课程:第一部分</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4d892009b4c367e533a0925cba6f43db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hkYlTODpjJgo32DoCOWN5w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=296581" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae ky" href="https://pixabay.com/users/clker-free-vector-images-3736/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=296581" rel="noopener ugc nofollow" target="_blank"> Clker-Free-Vector-Images </a>的图片(左图)和作者用 draw.io 制作的图片(右图)</p></figure><p id="136c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">今天，我们正式开始我们的<a class="ae ky" href="https://rukshanpramoditha.medium.com/list/neural-networks-and-deep-learning-course-a2779b9c3f75" rel="noopener"> <strong class="lb iu">神经网络和深度学习课程</strong> </a> <strong class="lb iu"> </strong>正如这里介绍的<a class="ae ky" href="https://rukshanpramoditha.medium.com/introducing-my-neural-networks-and-deep-learning-course-everyone-can-understand-6335fd541c9e" rel="noopener"/>。我们将从对神经网络中人工神经元(感知器)概念的扎实介绍开始。</p><p id="38fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">人工神经元</em> </strong>(也叫<strong class="lb iu"> <em class="lv">感知器</em> </strong>，<strong class="lb iu"> <em class="lv">单元</em> </strong>或<strong class="lb iu"> <em class="lv">节点</em> </strong>)是神经网络中最简单的元素或积木。它们的灵感来自于人类大脑中的生物神经元。</p><p id="2b87" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将讨论感知器是如何受到生物神经元的启发，绘制感知器的结构，讨论感知器内部的两个数学函数，最后，我们将在感知器内部执行一些计算。</p><h1 id="b68b" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">感知机是如何受到生物神经元的启发的？</h1><p id="f89b" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">人工神经元(感知器)如何受到生物神经元的启发，值得探讨。您可以将人工神经元视为受生物神经元启发的数学模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/565514d59109ec1fe86d7c2474e238c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*SgJPlfKHwL-qis-aL19Fyg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=296581" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae ky" href="https://pixabay.com/users/clker-free-vector-images-3736/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=296581" rel="noopener ugc nofollow" target="_blank">Clker-Free-Vector-Images</a>的图像(在左边)和作者的图像(在右边)，使用 draw.io 制作</p></figure><ul class=""><li id="777e" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated">一个生物神经元通过<strong class="lb iu">树突<em class="lv"> </em> </strong>(小纤维)接收来自其他神经元的输入信号。同样，一个感知器通过<strong class="lb iu">输入神经元</strong>接收来自其他感知器的数据。</li><li id="cae5" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">树突与<strong class="lb iu"> </strong>生物神经元的连接点称为<strong class="lb iu">突触</strong>。同样，输入和感知器之间的连接被称为<strong class="lb iu">权重</strong>。他们衡量每个输入的重要性水平。</li><li id="cee8" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">在生物神经元中，<strong class="lb iu"> <em class="lv">核</em> </strong>根据树突提供的信号产生输出信号。同样，感知器中的<strong class="lb iu"> <em class="lv">核心</em> </strong>(蓝色)基于输入值执行一些计算，并产生一个输出。</li><li id="7e97" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">在一个生物神经元中，输出信号由<strong class="lb iu"> <em class="lv">轴突</em> </strong>带走。同样，感知器中的轴突是<strong class="lb iu">输出值</strong>，它将是下一个感知器的输入。</li></ul><h1 id="7dc6" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">感知器的结构</h1><p id="c3a5" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">下图显示了感知器的详细结构。在某些情况下，偏差<strong class="lb iu"> b </strong>用<strong class="lb iu"> w0 </strong>表示。输入值<strong class="lb iu"> x0 </strong>总是取值 1。所以，<strong class="lb iu"> b*1 = b </strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/2e566645abf2d84c94507426d2d900ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*_1K2AV2rTjY3EWSJSvmPDQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">感知器的结构(图片由作者提供，用 draw.io 制作)</p></figure><blockquote class="nj nk nl"><p id="7cd6" class="kz la lv lb b lc ld ju le lf lg jx lh nm lj lk ll nn ln lo lp no lr ls lt lu im bi translated">一个感知器接受输入，<strong class="lb iu"> x1 </strong>，<strong class="lb iu"> x2 </strong>，…，<strong class="lb iu"> xn </strong>，将它们乘以权重，<strong class="lb iu"> w1 </strong>，<strong class="lb iu"> w2 </strong>，…，<strong class="lb iu"> wn </strong>，并添加偏置项，<strong class="lb iu"> b，</strong>，然后<strong class="lb iu"> </strong>计算线性函数，<strong class="lb iu"> z </strong>，激活函数，<strong class="lb iu">f<strong class="lb iu"/></strong></p></blockquote><p id="14b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在画感知器时，为了方便起见，我们通常忽略偏置单元，并将图表简化如下。但是在计算中，我们仍然考虑偏差单位。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/e5eca04041457ee028097d5474c407ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*bqKYF9786q0jUg8zFBgmEA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">没有偏差单元的感知器的简化版本(图片由作者提供，使用 draw.io 制作)</p></figure><h1 id="3558" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">感知器内部</h1><p id="2cd8" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">感知器通常由两个数学函数组成。</p><h2 id="5ca1" class="nq lx it bd ly nr ns dn mc nt nu dp mg li nv nw mi lm nx ny mk lq nz oa mm ob bi translated">感知器的线性函数</h2><p id="03ad" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这也被称为感知器的线性组件。用<strong class="lb iu"> z </strong>表示。其输出是输入加上偏置单元的加权和，计算公式如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/3dcca6e9125bc6602406f4445fb0e083.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*RoJ9uRjvYqcG2L3RICMtEg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">感知器的线性函数(图片由作者提供，用 draw.io 制作)</p></figure><ul class=""><li id="8329" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated"><strong class="lb iu"> x1 </strong>、<strong class="lb iu"> x2 </strong>、…、<strong class="lb iu"> xn </strong>是取数值的输入。单个神经元可以有几个(有限的)输入。它们可以是原始输入数据或其他感知器的输出。</li><li id="408d" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated"><strong class="lb iu"> w1 </strong>、<strong class="lb iu"> w2 </strong>、…、<strong class="lb iu"> wn </strong>为<strong class="lb iu"> <em class="lv">权重</em> </strong>取数值，控制每个输入的重要程度。值越高，输入越重要。</li><li id="a2e2" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated"><strong class="lb iu"> w1.x1 + w2.x2 + … + wn.xn </strong>称为输入的加权和。</li><li id="f996" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated"><strong class="lb iu"> b </strong>称为<strong class="lb iu"> <em class="lv">偏置项</em> </strong>或<strong class="lb iu"> <em class="lv">偏置单元</em> </strong>也是取数值。它被添加到输入的加权和中。包含偏置项的目的是移动每个感知器的激活函数，以不得到零值。换句话说，如果所有的<strong class="lb iu"> x1 </strong>、<strong class="lb iu"> x2 </strong>、…、<strong class="lb iu"> xn </strong>输入都为 0，则<strong class="lb iu"> z </strong>等于 bias 的值。</li></ul><p id="c703" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在神经网络模型中，权重和偏差被称为<strong class="lb iu"> <em class="lv">参数</em> </strong>。这些参数的最佳值在神经网络的学习(训练)过程中找到。</p><p id="abaa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你也可以把上面的<strong class="lb iu"> z </strong>函数想象成一个线性回归模型，其中权重被称为<strong class="lb iu"> <em class="lv">系数</em> </strong>，偏差项被称为<strong class="lb iu"> <em class="lv">截距</em> </strong>。这只是用来在不同的上下文中标识同一事物的术语。</p><h2 id="a3e2" class="nq lx it bd ly nr ns dn mc nt nu dp mg li nv nw mi lm nx ny mk lq nz oa mm ob bi translated">感知器的非线性(激活)功能</h2><p id="087a" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这也被称为感知器的非线性部分。用<strong class="lb iu"> f </strong>表示。它应用于<strong class="lb iu"> z </strong>上，根据我们使用的激活函数类型得到输出<strong class="lb iu"> y </strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/e4270055c1568e06454af88f6e237858.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*f3HtSCQQIVl078Xzh-mi6A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供，用 draw.io 制作)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/7d0677cf89d8a4a522c3838796663f41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YURbJY9b2V3qWA94NCCyrg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供，用 draw.io 制作)</p></figure><p id="1abe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">功能<strong class="lb iu"> f </strong>可以是不同类型的激活功能。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/eede6c4d64140c6232a0bb34cdb8cbb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*4RkikPcOz3L8H-qj6Cfm1w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">激活功能的类型(图片由作者提供，使用 draw.io 制作)</p></figure><p id="f2c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于有许多不同类型的激活函数，我们将在另一篇文章中详细讨论它们。现在，记住激活函数的目的是向网络引入非线性就足够了。如果没有激活函数，神经网络只能模拟线性关系，而不能模拟数据中存在的非线性关系。在现实世界的数据中，大多数关系是非线性的。因此，如果没有激活功能，神经网络将毫无用处。</p><h1 id="914e" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">“激发一个神经元”是什么意思？</h1><p id="91bb" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为此，考虑下面的<strong class="lb iu"> <em class="lv">二进制步骤</em> </strong>激活函数，也称为<strong class="lb iu"> <em class="lv">阈值激活函数</em> </strong>。我们可以为阈值设置任何值，这里我们指定值为 0。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/ff07b4261ada8942da302fb4bafb9343.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*f2j3hw3j6PebMTluhf6RBg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">二进制步进激活函数(图片由作者提供，用 draw.io 制作)</p></figure><p id="1933" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们说，只有当<strong class="lb iu"> z </strong>的值超过阈值 0 时，神经元或感知机才会激发(或激活)。换句话说，如果<strong class="lb iu"> z </strong>的值超过阈值 0，则神经元输出 1(触发或激活)。否则，它输出 0。</p><p id="1fa1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，激活函数的类型决定了神经元如何激活或激发，而偏置项<strong class="lb iu"> <em class="lv"> b </em> </strong>控制了激发的难易程度。现在考虑线性函数，<strong class="lb iu"> z </strong>。</p><p id="f695" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">z =(w1 . x1+w2 . x2+…+wn . xn)+b<br/>z =(输入的加权和)+ bias </strong></p><p id="f1d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设偏差为-2。这里，我们也考虑二元阶跃激活函数。因此，只有当输入的加权和超过+2 时，神经元才会激活。用数学术语来说，这可以表示如下。</p><p id="af6f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了激活神经元，根据上面定义的二进制阶跃激活函数，它应该输出 1。它只发生在，</p><p id="ac49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> z &gt; 0 </strong> <br/> <strong class="lb iu">(输入加权和)+ bias &gt; 0 <br/>(输入加权和)&gt; -bias </strong></p><p id="0e33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的例子中，当偏差为-2 时，</p><p id="7db6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">(输入的加权和)&gt; -(-2) <br/>(输入的加权和)&gt; 2 </strong></p><p id="9e61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，在这种情况下，输入的加权和应该超过+2，以激发或激活神经元。</p><h1 id="076f" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">在感知器内执行计算</h1><p id="335c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">让我们在感知内部进行一个简单的计算。假设我们有 3 个输入，值如下。</p><pre class="kj kk kl km gt oh oi oj ok aw ol bi"><span id="f332" class="nq lx it oi b gy om on l oo op"><strong class="oi iu">x1=2</strong>, <strong class="oi iu">x2=3</strong> and <strong class="oi iu">x3=1</strong></span></pre><p id="0ac3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我们有 3 个输入，所以我们也有 3 个权重来控制每个输入的重要程度。假设重量值如下。</p><pre class="kj kk kl km gt oh oi oj ok aw ol bi"><span id="8ffb" class="nq lx it oi b gy om on l oo op"><strong class="oi iu">w1=0.5</strong>, <strong class="oi iu">w2=0.2 </strong>and<strong class="oi iu"> w3=10</strong></span></pre><p id="739b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">偏差单位也有以下值。</p><pre class="kj kk kl km gt oh oi oj ok aw ol bi"><span id="cfdf" class="nq lx it oi b gy om on l oo op"><strong class="oi iu">b=2</strong></span></pre><p id="2af3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们来计算一下线性函数，<strong class="lb iu"> z </strong>。</p><p id="ffce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">z =(0.5 * 2+0.2 * 3+10 * 1)+2<br/>z = 13.6</strong></p><p id="a60c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">激活函数将<strong class="lb iu"> z </strong> (13.6)的输出作为其输入，并根据我们使用的激活函数类型计算输出<strong class="lb iu"> y </strong>。现在，我们使用下面定义的<strong class="lb iu"><em class="lv"/></strong>激活函数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/df2760850bfe39567a76cc6ecbff6e2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*mKYhdEtLRZr2JPUij2Md2A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Sigmoid 激活函数(图片由作者提供，用 draw.io 制作)</p></figure><p id="0f58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">y = sigmoid(13.6)<br/>y = 0.999<br/>y ~ 1</strong></p><p id="f431" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">整个计算过程可以用下图表示。为了便于理解，我们也在单独的节点中表示偏置项。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/d73f2df46ea75569c0c74598c5605595.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*akNWLsfeLaDnwfHI_1WADQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">感知器内部的计算过程(图片由作者提供，用 draw.io 制作)</p></figure><p id="7081" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">恭喜你！你已经成功地在感知器中完成了计算。</p><h1 id="d872" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">摘要</h1><p id="d7c8" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">感知器是一种数学模型，其中线性函数和非线性激活函数一起工作来计算输出，该输出可以是下一个感知器的输入或者仅仅是最终输出。</p><p id="cf02" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们在感知器中使用激活函数用于以下目的。</p><ul class=""><li id="1fcd" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated">它给网络带来了非线性。它使神经网络能够模拟现实世界数据中常见的非线性关系。</li><li id="7fa6" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">激活函数的类型决定了神经元应该如何激发或激活。</li><li id="86c5" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">它将<strong class="lb iu"> z </strong>的输出值保持在一定的范围内。例如，sigmoid 激活功能将<strong class="lb iu"> z </strong>的值保持在 0 和 1(包括 0 和 1)的范围内。无论<strong class="lb iu"> z </strong>的值是大是小。</li></ul><p id="921d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事实上，没有激活函数的神经网络只是线性回归模型，只能对数据中的线性关系进行建模。</p><p id="b0ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感知器的参数是<strong class="lb iu">权重</strong>和<strong class="lb iu">偏差</strong>。权重控制每个输入的重要程度。偏置项具有以下功能。</p><ul class=""><li id="44ce" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated">如上所述，它决定了神经元点火或激活的难易程度。</li><li id="837b" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">它移动每个感知器的激活函数以不得到零值。有时，零值可能会影响网络的训练过程。</li></ul><p id="50b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着感知器数量的增加，神经网络中可能有数千个参数(权重和偏差)。如前所述，这些参数的最佳值在神经网络的学习(训练)过程中找到。因此，参数(权重和偏差)从我们提供的数据中学习它们的最佳值。</p></div><div class="ab cl os ot hx ou" role="separator"><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox"/></div><div class="im in io ip iq"><p id="5653" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本课程第 1 部分到此结束。第 2 部分见。</p><p id="e50f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一如既往，祝大家学习愉快！</p><p id="446f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过<a class="ae ky" href="https://rukshanpramoditha.medium.com/subscribe" rel="noopener"> <strong class="lb iu">订阅我的</strong> <strong class="lb iu">邮件列表</strong> </a>，再也不要错过精彩的故事。我一点击发布按钮，你就会在收件箱里收到每一篇文章。</p><p id="ada8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你愿意，你可以<a class="ae ky" href="https://rukshanpramoditha.medium.com/membership" rel="noopener"> <strong class="lb iu">注册成为会员</strong> </a>以获得我写的每一个故事的全部信息，我将收取你一部分会员费。</p><p id="f7f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="oz pa ep" href="https://medium.com/u/f90a3bb1d400?source=post_page-----fab22249cbfc--------------------------------" rel="noopener" target="_blank">鲁克山·普拉莫迪塔</a><br/><strong class="lb iu">2021–12–26</strong></p></div></div>    
</body>
</html>