<html>
<head>
<title>Introduction to Boosted Trees</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">助推树木简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-boosted-trees-2692b6653b53?source=collection_archive---------9-----------------------#2021-10-21">https://towardsdatascience.com/introduction-to-boosted-trees-2692b6653b53?source=collection_archive---------9-----------------------#2021-10-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="8925" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">助推技术</h2><div class=""/><div class=""><h2 id="fe25" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">机器学习中的助推算法——第一部分</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/895d66c786039dd686ae443887994e52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pRfg6CwooPPUfpXtX0W9_w.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@karsten_wuerth?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">卡斯登·沃斯(➡️@卡斯登.沃斯)</a>在<a class="ae lh" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="11b8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">欢迎来到我的新文章系列:<strong class="lk jd">机器学习中的助推算法</strong>！这是本系列的第1部分。在这里，我会给你一个简短的介绍升压，它的目标，一些关键的定义和一个升压算法列表，我们打算涵盖在未来的职位。</p><h2 id="c0e0" class="me mf it bd mg mh mi dn mj mk ml dp mm lr mn mo mp lv mq mr ms lz mt mu mv iz bi translated">先决条件</h2><p id="22d3" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">你应该熟悉初级的基于树的机器学习模型，比如<strong class="lk jd">决策树</strong>和<a class="ae lh" rel="noopener" target="_blank" href="/random-forests-an-ensemble-of-decision-trees-37a003084c6c"> <strong class="lk jd">随机森林</strong> </a>。除此之外，建议好好了解一下<strong class="lk jd"> Python </strong>及其<a class="ae lh" rel="noopener" target="_blank" href="/9-guidelines-to-master-scikit-learn-without-giving-up-in-the-middle-5102863d89d7"> <strong class="lk jd"> Scikit-learn </strong> </a>库。</p><h1 id="9a2f" class="nb mf it bd mg nc nd ne mj nf ng nh mm ki ni kj mp kl nj km ms ko nk kp mv nl bi translated">创造助推树木的目的</h1><p id="d423" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">当我们想要创建非线性模型时，我们可以尝试创建基于树的模型。首先，我们可以从决策树开始。决策树的主要缺点是过度拟合训练数据。决策树的一个很好的替代品是随机森林。我们可以通过一种叫做<em class="nm">Bagging</em>(bootstrap aggregating)的技术组合多个决策树来创建一个随机森林。随机森林比决策树有更好的性能。</p><p id="1051" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">随机森林也有一个缺点。他们不能处理由他们个人的决策树产生的错误(如果有的话)。由于并行学习，如果一个决策树出错，整个随机森林模型都会出错。随机森林的一个很好的替代方案是提升树模型。这种模型的主要目标是通过避免上述缺点来超越决策树和随机森林。</p><h1 id="db2e" class="nb mf it bd mg nc nd ne mj nf ng nh mm ki ni kj mp kl nj km ms ko nk kp mv nl bi translated">什么是助推？</h1><p id="0c64" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">像bagging一样，boosting是一种集成方法，其中用一组决策树创建boosted树。区分装袋和助推是有用的。</p><blockquote class="nn no np"><p id="9c91" class="li lj nm lk b ll lm kd ln lo lp kg lq nq ls lt lu nr lw lx ly ns ma mb mc md im bi translated"><strong class="lk jd">装袋</strong>是自举聚集的简称。当算法进行样本替换时，称为<strong class="lk jd">自举</strong>。随机森林通过聚合自举决策树样本的预测来做出最终预测。因此，随机森林是一种bagging系综方法。随机森林中的树是相互独立的。</p></blockquote><p id="2240" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">相比之下，</p><blockquote class="nn no np"><p id="2164" class="li lj nm lk b ll lm kd ln lo lp kg lq nq ls lt lu nr lw lx ly ns ma mb mc md im bi translated"><strong class="lk jd"> Boosting </strong>处理之前决策树产生的错误。在boosting中，通过考虑前几轮树的错误来形成新的树。因此，新的树一棵接一棵地被创造出来。每棵树都依赖于前一棵树。这种类型的学习被称为<strong class="lk jd">顺序学习</strong>，其中并行计算并不理想。</p></blockquote><p id="3526" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">升压的一些关键考虑因素是:</p><ul class=""><li id="4c4a" class="nt nu it lk b ll lm lo lp lr nv lv nw lz nx md ny nz oa ob bi translated">Boosting将弱决策树(称为弱学习器)转换为强学习器。</li><li id="ab87" class="nt nu it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated">每个新树的建立都考虑了先前树的错误。</li><li id="889f" class="nt nu it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated">在bagging和boosting中，算法都使用一组(总体)决策树。打包和提升被称为集成元算法。</li><li id="269f" class="nt nu it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated">升压是一个迭代过程。每棵树都依赖于前一棵树。因此，很难并行化boosting算法的训练过程。培训时间会高一些。这是boosting算法的主要缺点。</li><li id="7afd" class="nt nu it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated">从增强过程中修改的树被称为<strong class="lk jd">增强树</strong>。</li></ul><h1 id="7597" class="nb mf it bd mg nc nd ne mj nf ng nh mm ki ni kj mp kl nj km ms ko nk kp mv nl bi translated">基础学习者</h1><p id="c899" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">基础学习者是任何集成技术的基本组成部分。它是一个单独的模型，更常见的是一个决策树。在增压中，一个基本的稀薄器被称为<strong class="lk jd">弱稀薄器</strong>。当弱学习器是决策树时，专门称为<strong class="lk jd">决策树树桩</strong>、<strong class="lk jd">决策树桩</strong>、<strong class="lk jd">浅决策树</strong>或<strong class="lk jd">只有一个内部节点(根)连接两个叶节点(<strong class="lk jd"> max_depth=1 </strong>)的1-分裂决策树</strong>。</p><h1 id="e897" class="nb mf it bd mg nc nd ne mj nf ng nh mm ki ni kj mp kl nj km ms ko nk kp mv nl bi translated">助推算法</h1><p id="5571" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">这里列出了机器学习中使用的一些流行的boosting算法。我们将在接下来的文章中详细介绍每个算法及其Python实现。</p><ul class=""><li id="8315" class="nt nu it lk b ll lm lo lp lr nv lv nw lz nx md ny nz oa ob bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/how-do-you-implement-adaboost-with-python-a76427b0fa7a"> AdaBoost(自适应增强)</a></li><li id="8873" class="nt nu it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/under-the-hood-of-gradient-boosting-and-its-python-implementation-99cc63efd24d">梯度推进</a></li><li id="6b20" class="nt nu it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated"><a class="ae lh" href="https://rukshanpramoditha.medium.com/unlock-the-power-of-xgboost-738536b9f36f" rel="noopener"> XGBoost(极限梯度提升)</a></li><li id="5d5e" class="nt nu it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/can-lightgbm-outperform-xgboost-d05a94102a55"> LightGBM(光梯度推进机)</a></li><li id="d9d5" class="nt nu it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/how-do-you-use-categorical-features-directly-with-catboost-947b211c2923">催化增强(分类增强)</a></li></ul><h1 id="afe2" class="nb mf it bd mg nc nd ne mj nf ng nh mm ki ni kj mp kl nj km ms ko nk kp mv nl bi translated">摘要</h1><p id="5159" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">我们刚刚开始我们的新文章系列:<strong class="lk jd">机器学习中的助推算法</strong>。除了讨论以上算法，我还会增加一些专题。</p><p id="8a34" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Boosting算法是基于树的算法，对于在非线性数据上构建模型非常重要。因为大多数真实世界的数据是非线性的，所以学习这些算法将是有用的。在本系列文章结束时，您将对boosting算法及其Python实现有一个清晰的了解。</p></div><div class="ab cl oh oi hx oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="im in io ip iq"><p id="daef" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">今天的帖子到此结束。我的读者可以通过下面的链接注册成为会员，以获得我写的每个故事的全部信息，我将收到你的一部分会员费。</p><div class="oo op gp gr oq or"><a href="https://rukshanpramoditha.medium.com/membership" rel="noopener follow" target="_blank"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd jd gy z fp ow fr fs ox fu fw jc bi translated">通过我的推荐链接加入Medium</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">rukshanpramoditha.medium.com</p></div></div><div class="pa l"><div class="pb l pc pd pe pa pf lb or"/></div></div></a></div><p id="6cce" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">非常感谢你一直以来的支持！下一个故事再见。祝大家学习愉快！</p><p id="5ab8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">特别要感谢Unsplash网站上的<strong class="lk jd"> Karsten Würth </strong>、<strong class="lk jd">T3，他为我提供了这篇文章的封面图片。</strong></p><p id="0fde" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="pg ph ep" href="https://medium.com/u/f90a3bb1d400?source=post_page-----2692b6653b53--------------------------------" rel="noopener" target="_blank">鲁克山·普拉莫迪塔</a><br/><strong class="lk jd">2021–10–21</strong></p></div></div>    
</body>
</html>