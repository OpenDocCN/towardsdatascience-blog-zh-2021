<html>
<head>
<title>Data Pipelines with Apache Beam</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Apache Beam的数据管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-pipelines-with-apache-beam-86cd8eb55fd8?source=collection_archive---------2-----------------------#2021-10-22">https://towardsdatascience.com/data-pipelines-with-apache-beam-86cd8eb55fd8?source=collection_archive---------2-----------------------#2021-10-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="962e" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">利用Beam实施大数据</h2><div class=""/><div class=""><h2 id="0402" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">如何借助Beam实现数据管道</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/b376856a27aa6c7ce1216f15145bbe6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*itUDSD5mOyqYVlyHBbzc7Q.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://pixabay.com/photos/binary-binary-code-binary-system-2910663/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="9013" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="https://beam.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Beam </a>是Apache的最新项目之一，这是一个整合的编程模型，用于表达高效的数据处理管道，正如Beam的主网站[ <a class="ae le" href="https://beam.apache.org/" rel="noopener ugc nofollow" target="_blank"> 1 </a>所强调的那样。在本文中，我们将更深入地研究这个特定的数据处理模型，并探索它的数据管道结构以及如何处理它们。此外，我们还将举例说明。</p><h1 id="2374" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">什么是阿帕奇光束</h1><p id="488b" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">Apache Beam可以表示为分布式数据处理的编程模型[ <a class="ae le" href="https://beam.apache.org/" rel="noopener ugc nofollow" target="_blank"> 1 </a> ]。它只有一个API来处理数据集和数据帧这两种类型的数据。当您建立束管线时，您并不关心您所建立的管线类型，无论您是建立批次管线还是串流管线。</p><p id="34be" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">就其侧面而言，顾名思义，它可以调节到任何位置。在Beam上下文中，这意味着开发您的代码并在任何地方运行它。</p><h2 id="fc7f" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">装置</h2><p id="be0c" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">要在Python中使用Apache Beam，我们首先需要安装Apache Beam Python包，然后将其导入到其网页[ <a class="ae le" href="https://beam.apache.org/get-started/quickstart-py/" rel="noopener ugc nofollow" target="_blank"> 2 </a> ]上描述的<a class="ae le" href="https://research.google.com/colaboratory/faq.html" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>环境中。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="63fa" class="nc mc iq nb b gy nr ns l nt nu">! pip   install apache-beam[interactive]<br/>import   apache_beam as beam</span></pre><h2 id="df06" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">什么是管道</h2><p id="4280" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">管道通过改变输入来封装信息处理任务。</p><h2 id="97d2" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">Apache Beam的体系结构</h2><p id="5e7a" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">在本节中，将介绍Apache Beam模型的体系结构、它的各种组件以及它们的作用。主要是用于合并处理的Beam概念，这是Apache Beam的核心。Beam SDKs是用户可以用来创建管道的语言。用户可以选择自己喜欢的、舒适的SDK。随着社区的发展，新的SDK正在被整合。</p><p id="37d8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">一旦用任何支持的语言定义了管道，它将被转换成通用语言标准。这种转换由一组运行程序API在内部完成。</p><p id="0988" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我想提一下，这种通用格式并不完全是语言通用的，但我们可以说是部分通用的。这种转换只是概括了核心转换的基本内容，这些内容对于所有人来说都是通用的，如映射函数、分组和过滤。</p><p id="0baa" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于每个SDK，都有一个相应的SDK工作人员，他们的任务是理解特定于语言的东西并解决它们。这些工人提供了一个一致的环境来执行代码。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nv"><img src="../Images/125ab4f4a6841eb7efa16e373de04845.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*CNRKd5hcqHdSbfmAqNxrWA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="12d9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于每种语言的SDK，我们都有一个特定的SDK工作人员。所以现在，如果我们有这个runner或Beam API和特定于语言的SDK工作器，我们使用哪个Runner就无关紧要了。任何跑步者都可以执行其指南页[ <a class="ae le" href="https://beam.apache.org/contribute/runner-guide/" rel="noopener ugc nofollow" target="_blank"> 4 </a> ]上提到的相同代码。</p><h1 id="52cd" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">阿帕奇波束的特点</h1><p id="b408" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">阿帕奇波束包括四个基本特征:</p><ul class=""><li id="4fe6" class="nw nx iq lh b li lj ll lm lo ny ls nz lw oa ma ob oc od oe bi translated">管道</li><li id="9299" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">p集合</li><li id="aea2" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">p转换</li><li id="8f49" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">跑步者</li></ul><p id="3420" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><code class="fe my mz na nb b">Pipeline</code>负责读取、处理和保存数据。这整个循环是一个从输入开始直到输出的整个循环的管道。每个Beam程序都能够生成一条流水线。</p><p id="b945" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">光束的第二个特征是一个<code class="fe my mz na nb b">Runner</code>。它决定了这条管道将在哪里运行[ <a class="ae le" href="https://beam.apache.org/contribute/runner-guide/" rel="noopener ugc nofollow" target="_blank"> 5 </a> ]。</p><p id="f5ab" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">光束的第三个特征是<code class="fe my mz na nb b">PCollection</code>。它相当于Spark中的RDD或数据帧。管道通过从数据源读取数据来创建一个<code class="fe my mz na nb b">PCollection</code>，之后，随着PTransforms被应用于它，更多的PCollections继续发展[ <a class="ae le" href="https://beam.apache.org/documentation/programming-guide/" rel="noopener ugc nofollow" target="_blank"> 6 </a> ]。</p><p id="fa65" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">每个<code class="fe my mz na nb b">PCollection</code>上的<code class="fe my mz na nb b">PTransform</code>都会产生一个新的<code class="fe my mz na nb b">PCollection</code>，使其不可改变。构造后，您将无法配置PCollection中的单个项目。在<code class="fe my mz na nb b">PCollection</code>上的转换将产生一个新的<code class="fe my mz na nb b">PCollection</code>。<code class="fe my mz na nb b">PCollection</code>中的特征可以是任何类型，但必须是同一类型。然而，为了保持分布式处理，Beam将每个元素编码为一个字节串，以便Beam可以将项目传递给分布式工作器，如其编程页面[ <a class="ae le" href="https://beam.apache.org/documentation/programming-guide/" rel="noopener ugc nofollow" target="_blank"> 6 </a>中所述。</p><p id="b8b9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Beam SDK包还作为所用类型的编码机制，支持自定义编码。此外，PCollection不支持粒度操作。因此，我们不能对PCollection中的某些特定项目应用转换。我们使用所有的转换来应用于整个<code class="fe my mz na nb b">PCollection</code>而不是某些方面[ <a class="ae le" href="https://beam.apache.org/documentation/programming-guide/" rel="noopener ugc nofollow" target="_blank"> 6 </a> ]。</p><p id="717c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">通常，当读取或添加项目时，源通常会为每个新元素分配一个时间戳。如果<code class="fe my mz na nb b">PCollection</code>持有有界数据，我们可以强调每个特性都将被设置为相同的时间戳。您可以显式指定时间戳，或者Beam将提供自己的时间戳。在任何情况下，如果源没有为我们指定时间戳，我们可以手动为元素指定时间戳。</p><p id="443b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">光束的第四个特征是<code class="fe my mz na nb b">PTransform</code>。它将一个样本<code class="fe my mz na nb b">PCollection</code>作为数据源，并生成一个带有时间戳的相同的PCollection。它们并行操作，同时进行诸如开窗、分配水印等操作。</p><h1 id="02b8" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">梁的管道结构</h1><p id="618e" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">在本节中，我们将使用Python实现Beam的管道结构。第一步从“给管道分配一个名称”开始，这是一行强制代码。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="9438" class="nc mc iq nb b gy nr ns l nt nu">pipeline1 = beam.Pipeline()</span></pre><p id="4b2c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第二步是通过读取任何文件、流或数据库来“创建”初始的<code class="fe my mz na nb b">PCollection</code>。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="623f" class="nc mc iq nb b gy nr ns l nt nu">dept_count = ( <br/> <strong class="nb ja">pipeline1</strong><br/> |beam.io.ReadFromText(‘/content/input_data.txt’)<br/> )</span></pre><p id="ebcb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第三步是根据您的使用案例“应用”<code class="fe my mz na nb b">PTransforms</code>。我们可以在这个管道中使用几个转换，每个转换都由管道操作符应用。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="35ab" class="nc mc iq nb b gy nr ns l nt nu">dept_count = (<br/> <strong class="nb ja">pipeline1</strong><br/> |beam.io.ReadFromText(‘/content/input_data.txt’)<br/><strong class="nb ja"> |beam.Map(lambda line: line.split(‘,’))<br/> |beam.Filter(lambda line: line[3] == ‘Backend’) <br/> |beam.Map(lambda line: (line[1], 1))<br/> |beam.CombinePerKey(sum)</strong><br/> )</span></pre><p id="5995" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">要请求一个转换操作，您需要对输入<code class="fe my mz na nb b">PCollection</code>实现它。对于每个转换，都存在一个非专有的应用方法。我们可以通过`. apply '或`| '管道运算符来使用apply操作。</p><p id="a3f2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在所有转换之后，第四步是将最终的<code class="fe my mz na nb b">PCollection</code>写入外部源。它可以是文件、数据库或流。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="530c" class="nc mc iq nb b gy nr ns l nt nu">dept_count = (<br/> <strong class="nb ja">pipeline1</strong><br/> |beam.io.ReadFromText(‘/content/input_data.txt’)<br/> |beam.Map(<strong class="nb ja">lambda</strong> line: line.split(‘,’))<br/> |beam.Filter(lambda line: line[3] == ‘Backend’) <br/> |beam.Map(<strong class="nb ja">lambda</strong> line: (<strong class="nb ja">line</strong>[1], 1))<br/> |beam.CombinePerKey(sum)<br/><strong class="nb ja"> |beam.io.WriteToText(‘/content/output_data.txt’) </strong><br/> )</span></pre><p id="64be" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后一步是运行管道。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="ed97" class="nc mc iq nb b gy nr ns l nt nu">pipeline1.run()</span></pre><h1 id="21b7" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">用Python生成变换操作</h1><p id="0dce" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">转换是每个数据处理结构的基本元素。Apache Beam包含内置的转换，可以很容易地用封闭的形式应用，如Beam的主编程文档[ <a class="ae le" href="https://beam.apache.org/documentation/programming-guide/" rel="noopener ugc nofollow" target="_blank"> 6 </a>中所述。让我们在接下来的章节中介绍这些转换。</p><h2 id="d2f8" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">从文本中读取</h2><p id="2866" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">Beam支持多种文件格式的“读”和“写”操作，如文本、<a class="ae le" href="https://avro.apache.org/" rel="noopener ugc nofollow" target="_blank"> Avro </a>、<a class="ae le" href="https://parquet.apache.org/documentation/latest/" rel="noopener ugc nofollow" target="_blank"> Parquet </a>。第一个转换是“ReadFromText”。这种格式将文本文件解析为换行符分隔的元素，这意味着默认情况下，文件中的每一行都将被视为单个元素。“ReadFromText”共有六个参数可供编辑，如果您希望在读取Beam的包模块页面[ <a class="ae le" href="https://beam.apache.org/releases/pydoc/2.6.0/apache_beam.io.textio.html" rel="noopener ugc nofollow" target="_blank"> 7 </a> ]上列出的文件时有完全的控制权。让我们来看看这些参数。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="daa0" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/> reading = beam.Pipeline()<br/> <br/> content_read = (<br/> reading <br/> <strong class="nb ja">|beam.io.ReadFromText(‘/content/input_data.txt’)</strong><br/> |beam.io.WriteToText(‘/content/output_data.txt’)<br/> )<br/> <br/> reading.run()</span></pre><p id="be16" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">首先是<code class="fe my mz na nb b">file_pattern</code>。它指定输入文件的完整路径。当从一个目录中读取多个文件时，我们可以用*操作符来设置它。这个路径意味着它将读取所有以input关键字开始的文件。</p><p id="fc69" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第二个参数是<code class="fe my mz na nb b">minimum_bundle_size</code>。此参数指定将源拆分成束时应该生成的束的最小大小。一个PCollection在内部被分成许多批，称为bundle[<a class="ae le" href="https://beam.apache.org/documentation/runtime/model/" rel="noopener ugc nofollow" target="_blank">8</a>]。它们在不同的机器上并行处理。这个参数的值决定了PCollection的最小包大小，它的参数应该是一个整数值。</p><p id="a535" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第三个参数是<code class="fe my mz na nb b">compression_type</code>。它处理压缩的输入文件，以防输入文件被压缩。我们不提供，因为Beam将使用提供的文件路径的扩展名来检测输入文件的压缩类型。例如，如果我们有一个. gzip文件，那么输入路径将从这个路径检测压缩类型。但是，如果您希望自己处理压缩的输入文件，您可以显式地提供压缩类型。</p><p id="c578" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第四个参数是<code class="fe my mz na nb b">strip_trialing_newlines</code>，一个布尔字段。它指示源是否应该移除换行符。如果设置为“真”,则结束行被移除并且不被读取。如果设置为“假”,则不绘制结束线，并作为空行读取。默认情况下，其值为“True”。</p><p id="4386" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第五个参数是<code class="fe my mz na nb b">validate</code>。它还是一个布尔标志，用于确认文件在管道创建期间是否存在。如果设置为“真”,它将控制输入文件是否存在。如果没有创建管道，那么Beam将抛出一个错误。如果设置为“false ”, Beam不检查文件是否存在，而是生成管道。在这种情况下，您将看到空的输出文件。建议将该参数设置为“真”。因此，其默认值为“True”。</p><p id="b2cf" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后一个参数是<code class="fe my mz na nb b">skip_header_lines</code>。它帮助处理加载了头文件的文件。我们不希望处理标题，所以我们可以使用此参数跳过阅读它们。您可以在输入文件中提供想要忽略的行数。</p><h2 id="a045" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">从Avro读取</h2><p id="3eea" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">此操作用于读取一个或一组Avro文件。它有四个参数。<code class="fe my mz na nb b">ReadFromAvro</code>的前三个参数与ReadFromText的参数相同。它的第四个不同的参数是“use_fastavro”。该参数接受一个布尔值，以从Avro文件[ <a class="ae le" href="https://beam.apache.org/releases/pydoc/2.6.0/apache_beam.io.textio.html" rel="noopener ugc nofollow" target="_blank"> 7 </a> ]中读取数据。由于该参数是强制性的，<code class="fe my mz na nb b">ReadFromAvro</code>应将其设置为‘真’以使用该库。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="4dc0" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/>import avro.schema<br/>from avro.datafile import DataFileReader, DataFileWriter<br/>from avro.io import DatumReader, DatumWriter<br/> <br/>from apache_beam.io import ReadFromAvro<br/>from apache_beam.io import WriteToAvro<br/> <br/>schema = avro.schema.parse(open(“parquet_file.parqet”, “rb”).read())<br/> <br/>parquet_write = beam.Pipeline()<br/> content_4 = ( parquet_write<br/> |beam.Create({‘dict1’:[24,45,68],’dict2':[32,54,75]})<br/> |beam.Map(lambda <strong class="nb ja">element</strong>: element)<br/> |beam.io.WriteToAvro(‘/content/output.avro’,schema=schema))<br/> <br/>parquet_write.run()</span></pre><h1 id="b601" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">阅读拼花地板</h1><p id="5044" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">第三个输入变换是<code class="fe my mz na nb b">ReadFromParquet</code>。该操作受益于读取拼花文件。前三个参数是与<code class="fe my mz na nb b">ReadFromText</code>相同的参数，第四个是“columns”。该参数指定了<code class="fe my mz na nb b">ReadFromParquet</code>将从输入文件[ <a class="ae le" href="https://beam.apache.org/releases/pydoc/2.11.0/apache_beam.io.parquetio.html" rel="noopener ugc nofollow" target="_blank"> 8 </a> ]中读取的列列表。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="61c6" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/>import pandas as pd<br/>import pyarrow<br/>from apache_beam.options.pipeline_options import PipelineOptions<br/> <br/> <br/>parquet_data = pd.read_parquet(‘/content/parquet_data.parquet’, engine=’pyarrow’)</span><span id="54ca" class="nc mc iq nb b gy ok ns l nt nu">parquet_schema = pyarrow.schema([])<br/> <br/>schema_map = {<br/> ‘STRING’: pyarrow.string(),<br/> ‘FLOAT’: pyarrow.float64(), <br/> ‘STRING’: pyarrow.string(),<br/> ‘DATE’: pyarrow.date64()<br/>}<br/> <br/>for item in parquet_data.schema:<br/>parquet_schema = parquet_schema.append(pyarrow.field(item.name, schema_map[item.field_type]))<br/> <br/>parquet_write = beam.Pipeline()<br/>content = ( parquet_write |beam.beam.io.ReadFromParquet(‘/content/parquet_data.parquet’)<br/>|beam.io.parquetio.WriteToParquet(‘/content/output5.parquet’,schema=parquet_schema))<br/> <br/>parquet_write.run()</span></pre><h2 id="4bc6" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">从TFRecord读取</h2><p id="815a" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">拼花之后，最后一个文件I/O是<code class="fe my mz na nb b">ReadFromTFRecord</code>。该操作读取TensorFlow记录。TFRecord格式是一种用于存储二进制形式序列的简单格式。这些记录之所以出名，是因为它们被序列化，因此在网络上传输速度更快。这种格式还有助于捕捉任何数据预处理。要读取TensorFlow记录，我们有<code class="fe my mz na nb b">ReadFromTFRecord</code> [ <a class="ae le" href="https://beam.apache.org/releases/pydoc/2.11.0/apache_beam.io.tfrecordio.html" rel="noopener ugc nofollow" target="_blank"> 9 </a>。它有一个包含四个参数的列表。</p><p id="131d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">它的三个参数与以前的类型相同。其他参数包括指定用于解码每个TFRecord的“编码器”名称的“编码器”。</p><p id="9207" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这些是各种基于文件的读取转换。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="6165" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/>from apache_beam.io.tfrecordio import ReadFromTFRecord<br/>from apache_beam import coders<br/> <br/>reading_tf = beam.Pipeline()<br/>data_path = ‘/content/input_data’<br/> <br/>content_read = (<br/>reading_tf <br/>|beam.io.ReadFromTFRecord(data_path, coder=beam.coders.BytesCoder(), <br/>compression_type=’auto’, validate=True) |beam.io.WriteToText(‘/content/output_tfrecord.txt’)<br/> )</span><span id="e08b" class="nc mc iq nb b gy ok ns l nt nu">reading_tf.run()</span></pre><h2 id="d9a9" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">从PubSub读取</h2><p id="f90f" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">下一个主题是从消息队列中读取。梁整体支持<a class="ae le" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank">阿帕奇卡夫卡</a>、<a class="ae le" href="https://aws.amazon.com/kinesis/" rel="noopener ugc nofollow" target="_blank">亚马逊Kinesis </a>、<a class="ae le" href="https://www.oracle.com/technical-resources/articles/java/intro-java-message-service.html" rel="noopener ugc nofollow" target="_blank"> JMS </a>、<a class="ae le" href="https://mqtt.org/" rel="noopener ugc nofollow" target="_blank"> MQTT </a>、<a class="ae le" href="https://cloud.google.com/pubsub/docs" rel="noopener ugc nofollow" target="_blank"> Google Cloud PubSub </a>。<a class="ae le" href="https://www.java.com/download/" rel="noopener ugc nofollow" target="_blank"> Java </a>支持其中的每一种；但是，Python只支持Google Cloud PubSub。我们有一个转换操作。它有一个大约五个参数的列表，如下所示。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="0c16" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/>from apache_beam.options.pipeline_options import PipelineOptions<br/>import os<br/>from apache_beam import window</span><span id="cb97" class="nc mc iq nb b gy ok ns l nt nu">project = 'SubscribeBeam'<br/>pubsub_topic = 'projects/qwiklabs-gcp-01-7779ab5fa77e/topics/BeamTopic'</span><span id="a242" class="nc mc iq nb b gy ok ns l nt nu">path = "C:\\Users\ersoyp\qwiklabs-gcp-01-7779ab5fa77e-2d40f7ded2a8.json"</span><span id="d3af" class="nc mc iq nb b gy ok ns l nt nu">os.environ["GOOGLE_APPLICATION_CREDENTIALS"]=path  <br/>  <br/>input_file = "C:\\Users\ersoyp\data.csv"</span><span id="eaf9" class="nc mc iq nb b gy ok ns l nt nu">output_file = "C:\\Users\ersoyp\output.csv"<br/>options = PipelineOptions()</span><span id="31c6" class="nc mc iq nb b gy ok ns l nt nu">options.view_as(StandardOptions).streaming = True</span><span id="a2ed" class="nc mc iq nb b gy ok ns l nt nu">process = beam.Pipeline(options=options)</span><span id="c968" class="nc mc iq nb b gy ok ns l nt nu">output_file = '/content/outputs/'</span><span id="70f0" class="nc mc iq nb b gy ok ns l nt nu">pubsub_data = ( process<br/>                | 'Read from PubSub' &gt;&gt; beam.io.ReadFromPubSub(subscription= input_file)<br/>                | 'Write to PubSub' &gt;&gt; beam.io.WriteToPubSub(output_file)<br/>              )<br/>final_file = process.run()</span></pre><p id="9585" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第一个参数是<code class="fe my mz na nb b">topic</code>。对于这个参数，我们必须提供主题名称。然后，我们指定要发布的消息，Beam将从这些消息中读取，如数据流文档[ <a class="ae le" href="https://cloud.google.com/pubsub/docs/pubsub-dataflow" rel="noopener ugc nofollow" target="_blank"> 9 </a>中所述。</p><p id="7c99" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第二个参数是<code class="fe my mz na nb b">subscription</code>。现有的发布-订阅订阅附加到特定的主题。以上两个参数是相互矛盾的。在这种情况下，我们提供一个主题作为参数。</p><p id="1394" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第三个参数是<code class="fe my mz na nb b">id_label</code>。它指定传入PubSub消息的哪个属性应被视为Beam的模块页面[ <a class="ae le" href="https://beam.apache.org/releases/pydoc/2.8.0/_modules/apache_beam/io/gcp/pubsub.html" rel="noopener ugc nofollow" target="_blank"> 10 </a> ]中指定的记录标识符。设置后，该属性的值将用于消息的重复数据删除。否则，如果不提供，Beam将不保证数据的唯一性。</p><p id="7179" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第四个参数是<code class="fe my mz na nb b">with_attributes</code>。这是一个布尔型字段。如果设置为“True ”,则输出元素将是objects类型。如果设置为“False ”,输出元素将为字节类型。默认情况下，该参数设置为“假”[ <a class="ae le" href="https://beam.apache.org/releases/pydoc/2.8.0/_modules/apache_beam/io/gcp/pubsub.html" rel="noopener ugc nofollow" target="_blank"> 10 </a> ]。</p><p id="fffd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后一个参数是<code class="fe my mz na nb b">timestamp_attribute</code>。因为Beam中的每个元素都附有时间戳。该参数是从PubSub转换中读取的，用于从Google Cloud PubSub [ <a class="ae le" href="https://beam.apache.org/releases/pydoc/2.8.0/_modules/apache_beam/io/gcp/pubsub.html" rel="noopener ugc nofollow" target="_blank"> 10 </a> ]中提取消息。</p><h2 id="0b9a" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">创建转换</h2><p id="705d" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">为了生成我们的数据，Beam支持创建转换操作。我们可以生成各种形式的数据，如列表、集合、字典等。创建转换将在下面的示例中显示“创建转换”操作的一些状态。我们将简单地使用create生成数据，并将其写入输出文件。</p><p id="a517" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">要生成元素列表，请使用' beam.Create ',然后使用方括号，在方括号内，您可以指定用逗号分隔的项目。在下面的示例中，我们没有对生成的数据应用任何转换。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="5fc2" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam</span><span id="d0d3" class="nc mc iq nb b gy ok ns l nt nu">create_transform = beam.Pipeline()</span><span id="ee6f" class="nc mc iq nb b gy ok ns l nt nu">content = (<strong class="nb ja">create_transform</strong><br/>            |beam.Create(['Beam create transform'])<br/>            |beam.io.WriteToText('/content/outCreate1.txt')<br/>          )</span><span id="7a01" class="nc mc iq nb b gy ok ns l nt nu">create_transform.run()</span></pre><p id="3041" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">作为第二个例子，可以创建一个列表。为此，我们生成一个数字列表。管线段应该在直线的最开始，前面没有空格。当我们创建管道或预期的缩进时，情况也是如此。它是无缩进的。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="e771" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/> <br/>create_transform_2 = beam.Pipeline()<br/> <br/>content_2 = (create_transform_2<br/>            |beam.Create([10,22,38,47,51,63,78])<br/>            |beam.io.WriteToText('/content/output2.txt')<br/>           )</span><span id="e206" class="nc mc iq nb b gy ok ns l nt nu">create_transform_2.run()</span></pre><p id="8162" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果您想要两列或更多列的数据，那么传递一个元组列表。它是一个键值元组。如果在元组中进一步应用映射转换，每个元素都表现为一个单独的列。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="97f4" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/> <br/>create_transform_3 = beam.Pipeline()<br/> <br/>content_3 = (create_transform_3<br/> |beam.Create([(“DataScience”,10), (“DataEngineering”,20),(“ArtificialIntelligence”,30), (“BigData”,40)])<br/> |beam.io.WriteToText(‘/content/output3.txt’)<br/>)</span><span id="f1b2" class="nc mc iq nb b gy ok ns l nt nu">create_transform_3.run()</span></pre><p id="85dc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于字典，可以传递键值对。对于键值对，你用花括号传递它们。您可以使用圆形、方形和花括号来生成各种形式的数据。使用这些括号的不同组合，你会得到额外的数据。它在“beam.Create”操作的帮助下创建一个变换。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="fff2" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/> <br/>create_transform_4 = beam.Pipeline()</span><span id="cf86" class="nc mc iq nb b gy ok ns l nt nu">content_3 = ( create_transform_4<br/>       |beam.Create({'dict1':[24,45,68],'dict2':[32,54,75]})<br/>       |beam.Map(lambda element: element)<br/>       |beam.io.WriteToText('/content/output4.txt'))<br/> <br/>create_transform_4.run()</span></pre><h2 id="7d8f" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">写入文本</h2><p id="e9fc" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated"><code class="fe my mz na nb b">WriteToText</code>将PCollection的每个元素作为一行写入输出文件。</p><p id="0d17" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第一个参数是<code class="fe my mz na nb b">file_path_prefix</code>。它指定写入PCollection的文件路径。如果我们将其定义为一个参数，那么Beam将生成文件或者数据目录[ <a class="ae le" href="https://beam.apache.org/releases/pydoc/2.1.0/apache_beam.io.html" rel="noopener ugc nofollow" target="_blank"> 11 </a> ]中的项目。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="0949" class="nc mc iq nb b gy nr ns l nt nu">beam.io.WriteToText(‘/content/output.txt’)</span></pre><p id="7316" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><code class="fe my mz na nb b">num_shards</code>和<code class="fe my mz na nb b">file_path_suffix</code>是第二个和第三个参数。我们文件的全名如下所示。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="ec51" class="nc mc iq nb b gy nr ns l nt nu">&lt;prefix&gt;&lt;num_shards&gt;&lt;suffix&gt;</span><span id="a5bb" class="nc mc iq nb b gy ok ns l nt nu">content-0000-of-0001-departments</span></pre><p id="a7e6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第一部分，“内容”是一个前缀。第二个“0001的0000”属于“碎片数”。此参数指定作为输出写入的碎片数或文件数。如果我们将“number_of_shards”参数设置为3，那么我们得到的文件将由3部分组成。当我们不设置这个参数时，服务将决定最佳碎片。</p><p id="e5dd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在本例中,“部门”代表由名为“文件名后缀”的参数控制的后缀。</p><p id="a5ca" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第四个参数是<code class="fe my mz na nb b">append_trailing_newlines</code>。此参数接受一个布尔值，该值指示输出文件是否应该在写入每个元素后写入一个换行符。即输出文件是否应该用换行符分隔。默认情况下，它被设置为“真”[ <a class="ae le" href="https://beam.apache.org/releases/pydoc/2.16.0/apache_beam.io.textio.html" rel="noopener ugc nofollow" target="_blank"> 12 </a> ]。</p><p id="90b0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第五个参数是<code class="fe my mz na nb b">coder</code>。它指定了用于编码每一行的编码器名称。</p><p id="1e78" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第六个参数是<code class="fe my mz na nb b">compression_type</code>，一个字符串值。此参数用于处理压缩输出文件。</p><p id="9071" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第七个参数是<code class="fe my mz na nb b">header</code>。它指定一个字符串作为头写在输出文件的开头。</p><h2 id="a574" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">写信给Avro</h2><p id="d9f9" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated"><code class="fe my mz na nb b">WriteToAvro</code>的参数包括<code class="fe my mz na nb b">file_path_prefix</code>、<code class="fe my mz na nb b">file_path_suffix</code>、<code class="fe my mz na nb b">num_shards</code>、<code class="fe my mz na nb b">compression_type</code>，如刚才对<code class="fe my mz na nb b">WriteToText</code>的解释。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="2312" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/>from avro import schema<br/>import avro<br/>from apache_beam.io import ReadFromAvro<br/>from apache_beam.io import WriteToAvro<br/>   <br/>schema = avro.schema.parse(open("avro_file.avsc", "rb").read())<br/>   <br/>create_transform_5 = beam.Pipeline()</span><span id="3533" class="nc mc iq nb b gy ok ns l nt nu">content_4 = ( create_transform_5<br/>|beam.Create(['Beam create transform'])<br/>|beam.Map(lambda <strong class="nb ja">element</strong>:   element)  <strong class="nb ja">|beam.io.WriteToAvro('/content/output5.avro',schema=schema)</strong>)</span><span id="b489" class="nc mc iq nb b gy ok ns l nt nu">create_transform_5.run()</span></pre><p id="b4fd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><code class="fe my mz na nb b">WriteToAvro</code>的第五个参数是<code class="fe my mz na nb b">schema</code>。写入Avro文件需要指定模式。</p><p id="6a6e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第六个参数是<code class="fe my mz na nb b">codec</code>。它是用于块级压缩的压缩编解码器。</p><p id="e867" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第七个参数是设置为“真”的<code class="fe my mz na nb b">use_fastavro</code>。你可以使用“fastavro库”来加快写作速度。</p><p id="a3fb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后一个参数是<code class="fe my mz na nb b">mime_type</code>。如果文件系统支持指定的MIME类型，它将传递生成的输出文件的MIME类型。</p><h1 id="05b4" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">写信给拼花地板</h1><p id="50f0" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">它用于将PCollection的每个元素写入Parquet文件。<code class="fe my mz na nb b">file_path_prefix</code>、<code class="fe my mz na nb b">file_path_suffix</code>、<code class="fe my mz na nb b">num_shards</code>、<code class="fe my mz na nb b">codec</code>、<code class="fe my mz na nb b">mime_type</code>、<code class="fe my mz na nb b">schema</code>的参数与<code class="fe my mz na nb b">WriteToAvro</code>相同。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="1ea4" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/>import pandas as pd<br/>import pyarrow<br/>from apache_beam.options.pipeline_options import PipelineOptions<br/> <br/>parquet_data = pd.read_parquet(‘/content/parquet_data.parquet’, engine=’pyarrow’)</span><span id="8760" class="nc mc iq nb b gy ok ns l nt nu">parquet_schema = pyarrow.schema([])<br/> <br/>schema_map = {<br/> ‘STRING’: pyarrow.string(),<br/> ‘FLOAT’: pyarrow.float64(), <br/> ‘STRING’: pyarrow.string(),<br/> ‘DATE’: pyarrow.date64()<br/> }<br/> <br/>for item in parquet_data.schema:</span><span id="1183" class="nc mc iq nb b gy ok ns l nt nu">parquet_schema =</span><span id="f2fb" class="nc mc iq nb b gy ok ns l nt nu">parquet_schema.append(pyarrow.field(item.name, schema_map[item.field_type]))<br/> <br/>parquet_write = beam.Pipeline()<br/>content = ( parquet_write<br/>|beam.beam.io.ReadFromParquet(‘/content/parquet_data.parquet’) <strong class="nb ja">|beam.io.parquetio.WriteToParquet(‘/content/output.parquet’, <br/>schema=parquet_schema</strong>))<br/> <br/>parquet_write.run()</span></pre><p id="492a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第七个参数是<code class="fe my mz na nb b">row_group_buffer_size</code>。它指定行组缓冲区的字节大小。行组可以被接受为parquet文件的一部分，它保存列输入的序列化数组。这是一项高级功能，用于调整拼花文件的性能。</p><p id="2d5b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第八个参数是<code class="fe my mz na nb b">record_batch_size</code>。它指定了每个<code class="fe my mz na nb b">record_batch</code>的记录数。记录批次可以定义为用于在行组缓冲区中存储数据的基本单位。该参数纯粹与拼花文件相关。</p><h1 id="eba2" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">写入TFRecord</h1><p id="d570" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">它具有<code class="fe my mz na nb b">file_path_prefix</code>、<code class="fe my mz na nb b">file_path_suffix</code>、<code class="fe my mz na nb b">num_shards</code>、<code class="fe my mz na nb b">compression_type</code>参数，这些参数已经在上面的写操作中解释过了。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="12bb" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/>from apache_beam import Create<br/>from apache_beam import coders<br/>from apache_beam.io.filesystem import CompressionTypes<br/>from apache_beam.io.tfrecordio import ReadFromTFRecord<br/>from apache_beam.io.tfrecordio import WriteToTFRecord<br/> <br/>reading_tf = beam.Pipeline()<br/>data_path = ‘/content/input_data’<br/> <br/>content_read = (reading_tf <br/>|<strong class="nb ja">beam.io.ReadFromTFRecord(data_path, coder=beam.coders.BytesCoder(), compression_type=’auto’, validate=True</strong>)<br/>|<strong class="nb ja">beam.io.WriteToTFRecord(data_path, compression_type=CompressionTypes.GZIP, file_name_suffix=’.gz’</strong>)<br/>)<br/> <br/>reading_tf.run()</span></pre><h1 id="3c01" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">写入PubSub</h1><p id="b183" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">该操作将PCollection作为消息流写入Google Cloud PubSub服务。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="6bb7" class="nc mc iq nb b gy nr ns l nt nu">import os<br/>import apache_beam as beam<br/>from apache_beam import window<br/>from apache_beam.options.pipeline_options import PipelineOptions</span><span id="ea95" class="nc mc iq nb b gy ok ns l nt nu">project = ‘SubscribeBeam’</span><span id="6e89" class="nc mc iq nb b gy ok ns l nt nu">pubsub_topic = ‘projects/qwiklabs-gcp-01–7779ab5fa77e/topics/BeamTopic’</span><span id="20b2" class="nc mc iq nb b gy ok ns l nt nu">path = “C:\\Users\ersoyp\qwiklabs-gcp-01–7779ab5fa77e-2d40f7ded2a8.json”</span><span id="852f" class="nc mc iq nb b gy ok ns l nt nu">os.environ[“GOOGLE_APPLICATION_CREDENTIALS”]=path</span><span id="8439" class="nc mc iq nb b gy ok ns l nt nu">input_file = <!-- -->“<!-- -->C:\\Users\ersoyp\data.csv”</span><span id="07dc" class="nc mc iq nb b gy ok ns l nt nu">output_file = “C:\\Users\ersoyp\output.csv”</span><span id="e86f" class="nc mc iq nb b gy ok ns l nt nu">options = PipelineOptions()</span><span id="93e1" class="nc mc iq nb b gy ok ns l nt nu">options.view_as(StandardOptions).streaming = True</span><span id="dbd6" class="nc mc iq nb b gy ok ns l nt nu">process = beam.Pipeline(options=options)</span><span id="c919" class="nc mc iq nb b gy ok ns l nt nu">output_file = “/content/outputs/”</span><span id="5262" class="nc mc iq nb b gy ok ns l nt nu">pubsub_data = ( process<br/> | ‘Read from PubSub’ &gt;&gt; beam.io.ReadFromPubSub(subscription= input_file)<br/> | ‘Write to PubSub’ ‘ &gt;&gt; beam.io.WriteToPubSub(output_file)<br/> )</span><span id="3953" class="nc mc iq nb b gy ok ns l nt nu">final_file = process.run()</span></pre><p id="4032" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第一个参数是<code class="fe my mz na nb b">topic</code>。它被用作写入输出的位置。</p><p id="6af5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第二个参数是<code class="fe my mz na nb b">with_attributes</code>，决定输入元素的类型。如果它被设置为“真”,那么输入元素将是对象类型。如果为“假”,则特征的格式为字节。</p><p id="f50b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第三个参数是<code class="fe my mz na nb b">id_label</code>。它为每个具有给定名称和新颖内容的Cloud PubSub消息设置一个属性。它可以在<code class="fe my mz na nb b">ReadFromPubSub</code>和<code class="fe my mz na nb b">PTransform</code>中应用该属性，以对消息[ <a class="ae le" href="https://beam.apache.org/releases/pydoc/2.32.0/apache_beam.io.gcp.pubsub.html" rel="noopener ugc nofollow" target="_blank"> 14 </a> ]进行重复数据删除。</p><p id="5e80" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第四个参数是<code class="fe my mz na nb b">timestamp_attribute</code>。它被用作每个具有给定名称的云发布订阅消息的属性，其发布时间为Beam的模块页面[ <a class="ae le" href="https://beam.apache.org/releases/pydoc/2.18.0/apache_beam.io.external.gcp.pubsub.html" rel="noopener ugc nofollow" target="_blank"> 15 </a>中提供的值。</p><h1 id="10d0" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">地图变换</h1><p id="3e8d" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated"><code class="fe my mz na nb b">Map</code> transform将一个元素作为输入，一个元素作为输出。它对集合中的每个项目执行一对一的映射功能。该示例应该将整个字符串作为单个输入，基于逗号对其进行分割，并返回元素列表。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="dbf5" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/> <br/>map_transform = beam.Pipeline()<br/> <br/>content = ( map_transform<br/> |beam.io.ReadFromText(([‘data.txt’]))<br/> |beam.Map(lambda element: element)<br/> |beam.io.WriteToText(‘/content/output_1.txt’)<br/> )<br/> <br/>map_transform.run()</span></pre><h1 id="e153" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">平面图变换</h1><p id="5b67" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">功能方面<code class="fe my mz na nb b">FlatMap</code>与<code class="fe my mz na nb b">Map</code>几乎相同，但有一个显著的区别。虽然<code class="fe my mz na nb b">Map</code>只能为单个输入输出一个元素，但<code class="fe my mz na nb b">FlatMap</code>可以为单个组件发出多个元素。以下示例生成一个列表作为输出。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="d718" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/> <br/>flatMap_transform = beam.Pipeline()<br/> <br/> content = ( flatMap_transform<br/> |beam.io.ReadFromText(([‘data.txt’]))<br/><strong class="nb ja"> |beam.FlatMap(lambda element: element)</strong><br/> |beam.io.WriteToText(‘/content/output_1.txt’)<br/>)<br/> <br/> flatMap_transform.run()</span></pre><h2 id="f2fd" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">过滤变换</h2><p id="b6d2" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated"><code class="fe my mz na nb b">filter</code>操作将过滤指定部门的元素。这个过滤函数将前面的列表作为输入，并返回匹配条件中所有需要的特征。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="5290" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam</span><span id="44f2" class="nc mc iq nb b gy ok ns l nt nu">filtering = beam.Pipeline()<br/> <br/>dept_count = (<br/> filtering<br/> |beam.io.ReadFromText(‘/content/input_data.txt’)<br/> |beam.Map(lambda line: line.split(‘,’))<br/><strong class="nb ja"> |beam.Filter(lambda line: line[3] == ‘Backend’) </strong><br/> |beam.Map(lambda line: (line[1], 1))<br/> |beam.io.WriteToText(‘/content/output_data.txt’)<br/> |beam.CombinePerKey(sum)<br/> )<br/> filtering.run()</span></pre><h1 id="f53b" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">管道分支操作</h1><p id="193a" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">大多数管道只是用一对一的映射来表示操作的线性流程。在第一个PCollection之后，一个过滤操作产生一个新的PCollection。在PCollection上，一个映射转换在队列中创建附加PCollection，直到它被写入文件。</p><p id="da44" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然而，对于大多数用例来说，您的管道可能非常复杂和分支。这种类型的管道在Beam中称为分支管道，我们可以使用同一个PCollection作为多个转换的输入。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/024d6190cbb41bd47acd52313d2af16c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*vVyFo0EVfdL1KQEuLI3Png.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="2f43" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">以下是管道分支结构的实现示例流程。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="c28d" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam</span><span id="0748" class="nc mc iq nb b gy ok ns l nt nu">branched = beam.Pipeline()</span><span id="aad6" class="nc mc iq nb b gy ok ns l nt nu">input_collection = ( <br/>branched <br/> | “Read from text file” &gt;&gt; beam.io.ReadFromText(‘data.txt’)<br/> | “Split rows” &gt;&gt; beam.Map(lambda line: line.split(‘,’)))<br/> <br/> backend_dept = (input_collection<br/> | ‘Retrieve Backend employees’ &gt;&gt; beam.Filter(lambda record: record[3] == ‘Backend’)<br/> | ‘Pair them 1–1 for Backend’ &gt;&gt; beam.Map(lambda record: (“Backend, “ +record[1], 1))<br/> | ‘Aggregation Operations: Grouping &amp; Summing1’ &gt;&gt; beam.CombinePerKey(sum))<br/> ai_dept = ( input_collection<br/> |’Retrieve AI employees’ &gt;&gt; beam.Filter(lambda record: record[3] == ‘AI’)<br/> |’Pair them 1–1 for HR’ &gt;&gt; beam.Map(lambda record: (“AI, “ +record[1], 1))<br/> |’Aggregation Operations: Grouping &amp; Summing2' &gt;&gt; beam.CombinePerKey(sum))</span><span id="0e67" class="nc mc iq nb b gy ok ns l nt nu">output =(<br/> (backend_dept , ai_dept)<br/> | beam.Flatten()<br/> | beam.io.WriteToText(‘/content/branched.txt’)<br/> )</span><span id="da6b" class="nc mc iq nb b gy ok ns l nt nu">branched.run()</span></pre><p id="ac15" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在上面的例子中，第一个transform操作在后端部门应用了一个过滤器，Transform B过滤了AI部门的所有雇员。</p><h1 id="4c53" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">用Python生成ParDo变换运算</h1><p id="0e79" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">ParDo可以作为并行处理的转换机制[ <a class="ae le" href="https://beam.apache.org/documentation/programming-guide/#applying-transforms" rel="noopener ugc nofollow" target="_blank"> 16 </a> ]。</p><p id="2154" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第一个是<code class="fe my mz na nb b">Filtering</code>，数据集。您可以使用ParDo获取PCollection中的每个元素，或者将该元素输出到一个新的集合中，或者按照Beam [ <a class="ae le" href="https://beam.apache.org/documentation/programming-guide/#applying-transforms" rel="noopener ugc nofollow" target="_blank"> 16 </a> ]的编程指南中的规定将其丢弃。</p><p id="7385" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第二个是数据集中每个元素的<code class="fe my mz na nb b">Formatting</code>或<code class="fe my mz na nb b">Type Converting</code>。<code class="fe my mz na nb b">ParDo</code>可用于对输入PCollection [ <a class="ae le" href="https://cloud.google.com/dataflow/docs/concepts/beam-programming-model" rel="noopener ugc nofollow" target="_blank"> 17 </a> ]上的每个组件进行转换。</p><p id="c1a8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第三个是每个项目的<code class="fe my mz na nb b">Extracting Individual Parts</code>。如果存在具有多个字段的元素集合，您可以使用<code class="fe my mz na nb b">ParDo</code>或提取单个项目。</p><p id="ad75" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第四个是对PCollection的每一项执行<code class="fe my mz na nb b">Computations</code>。我们可以将这个函数应用到PCollection的各个方面。</p><p id="31c9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">此外，我们可以利用ParDo以各种方式分割PCollection。在下面的脚本中，我们使用了<code class="fe my mz na nb b">Map</code>、<code class="fe my mz na nb b">FlatMap</code>和<code class="fe my mz na nb b">Filter</code>变换。当您应用一个<code class="fe my mz na nb b">ParDo</code>转换时，您将需要以一个<code class="fe my mz na nb b">DoFn</code>对象的形式提供用户代码。</p><p id="8e69" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在内部，<code class="fe my mz na nb b">Map</code>和<code class="fe my mz na nb b">FlatMap</code>也继承了<code class="fe my mz na nb b">DoFn</code>类。为了实现代码中的<code class="fe my mz na nb b">ParDo</code>，用<code class="fe my mz na nb b">ParDo</code>替换<code class="fe my mz na nb b">Map</code>和。“DoFn”类中有许多函数，我们只需覆盖其中的一部分，即流程函数。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="ce0a" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/> class EditingRows(beam.DoFn):<br/> <br/>def process(self, element):<br/> return [element.split(‘,’)]<br/> <br/>class Filtering(beam.DoFn):<br/> <br/>def process(self, element):<br/> if element[3] == ‘Finance’:<br/> return [element] <br/> <br/>class Matching(beam.DoFn):<br/> <br/>def process(self, element):<br/> return [(element[3]+”,”+element[1], 1)] <br/> <br/>class Summing(beam.DoFn):<br/> <br/>def process(self, element):<br/> (key, values) = element <br/> return [(key, sum(values))]<br/> <br/>pardo = beam.Pipeline()<br/> department_operations= (pardo<br/> |beam.io.ReadFromText(‘data.txt’)<br/> |beam.ParDo(EditingRows())<br/> |beam.ParDo(Filtering())<br/> |beam.ParDo(Matching())<br/> |’Grouping’ &gt;&gt; beam.GroupByKey()<br/> |’Summing’ &gt;&gt; beam.ParDo(Summing()) <br/> |beam.io.WriteToText(‘data/output_pardo.txt’) )<br/> pardo.run()</span></pre><h1 id="a890" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">合成变换操作的生成</h1><p id="5404" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated"><code class="fe my mz na nb b">CompositeTransform</code>顾名思义是一个内部有一系列内置转换的转换。</p><p id="a748" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在管道中使用复合转换可以使您的代码更加模块化，更容易理解。在复合转换中，我们将多个转换组合成一个单元。为此，我们将创建一个类<code class="fe my mz na nb b">CompositeTransform</code>，和Beam中的每个其他类一样，它应该继承其对应的基类。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="f50e" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/> <br/>class CompositeTransform(beam.PTransform):<br/> <br/>def expand(self, columns):<br/> x = ( columns |’Grouping &amp; Summing’ &gt;&gt; beam.CombinePerKey(sum)<br/> |’Filtering’ &gt;&gt; beam.Filter(Filtering))<br/> return x<br/> <br/>def EditingRows(element):<br/> return element.split(‘,’)<br/> def Filtering(element):<br/> name, count = element<br/> if count &gt; 30:<br/> return element<br/> composite = beam.Pipeline()<br/> input_data = ( composite <br/> | “Reading Data” &gt;&gt; beam.io.ReadFromText(‘data.txt’)<br/> | “Editing Rows” &gt;&gt; beam.Map(EditingRows))</span><span id="71aa" class="nc mc iq nb b gy ok ns l nt nu">frontend_count = (input_data<br/> | ‘Get Frontend Employees’ &gt;&gt; beam.Filter(lambda record: record[3] == ‘Frontend’)<br/> | ‘Matching one-to-one’ &gt;&gt; beam.Map(lambda record: (“Frontend, “ +record[1], 1))<br/> | ‘Composite Frontend’ &gt;&gt; MyTransform()<br/> | ‘Write to Text’ &gt;&gt; beam.io.WriteToText(‘/content/composite_frontend.txt’))<br/> <br/> ai_count = (input_data<br/> | ‘Get AI Employees’ &gt;&gt; beam.Filter(lambda record: record[3] == ‘AI’)<br/> | ‘Pairing one-to-one’ &gt;&gt; beam.Map(lambda record: (“AI, “ +record[1], 1))<br/> | ‘Composite AI’ &gt;&gt; MyTransform()<br/> | ‘Write to Text for AI’ &gt;&gt; beam.io.WriteToText(‘/content/composite_ai.txt’))</span><span id="7ce6" class="nc mc iq nb b gy ok ns l nt nu">composite.run()</span></pre><p id="66e2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了创建复合变换，我们可以使用函数“Beam.PTransform”。这个PTransform是我们使用的每个PTransform的基类。PTransform有一个需要重写的扩展方法。此方法将一个PCollection作为输入，将对其应用几个转换。要在我们的管道中使用这个转换，只需用它的惟一标签调用它的对象。</p><h1 id="ef5f" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">侧面输入和侧面输出</h1><p id="0b59" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">顾名思义，<code class="fe my mz na nb b">side input</code>是可以贡献给<code class="fe my mz na nb b">DoFn</code>对象的额外信息。除了输入“PCollection”之外，您还可以以侧面输入[ <a class="ae le" href="https://beam.apache.org/documentation/patterns/side-inputs/" rel="noopener ugc nofollow" target="_blank"> 19 </a> ]的形式将附加信息引入到<code class="fe my mz na nb b">ParDo</code>或其子转换中，如<code class="fe my mz na nb b">Map</code>、<code class="fe my mz na nb b">FlatMap</code>。</p><p id="34c0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们为侧面输入实现一个示例脚本。我们可以将侧面输入移动到<code class="fe my mz na nb b">ParDo</code>转换。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="63c1" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/> <br/>side_inputs = list()<br/> <br/>with open (‘id_list.txt’,’r’) as my_file:<br/> for line in my_file:<br/> side_inputs.append(line.rstrip())<br/> sideInput = beam.Pipeline()<br/> <br/>class Filtering(beam.DoFn):</span><span id="d6db" class="nc mc iq nb b gy ok ns l nt nu">def process(self, element, side_inputs, lower, upper=float(‘inf’)):<br/> id = element.split(‘,’)[0]<br/> name = element.split(‘,’)[1]<br/> items = element.split(‘,’)<br/> if (lower &lt;= len(name) &lt;= upper) and id not in side_inputs:<br/> return [items]<br/> <br/>small_names =( sideInput<br/> |”Reading Data” &gt;&gt; beam.io.ReadFromText(‘data.txt’)<br/> |”Side inputs &amp; ParDo” &gt;&gt; beam.ParDo(Filtering(), side_inputs,3,10) <br/> |beam.Filter(lambda record: record[3] == ‘Frontend’)<br/> |beam.Map(lambda record: (record[0]+ “ “ + record[1], 1))<br/> |beam.CombinePerKey(sum)<br/> |’Write to Text’ &gt;&gt; beam.io.WriteToText(‘/content/side_inputs.txt’))<br/> <br/>sideInput.run()</span></pre><h1 id="8da3" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">在Apache Beam中实现windows</h1><p id="2c97" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">Beam中的窗口可以说是其数据处理理念中的一个关键元素。窗口逻辑是任何流处理环境的关键概念。没有它，处理实时数据几乎是不可能的。</p><p id="87cf" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">流式传输中有两种时间概念。这些是事件时间和处理时间。这些时间在处理过程中起着至关重要的作用，因为它们决定了窗口中要处理的数据。</p><p id="da5c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><code class="fe my mz na nb b">event time</code>可以表示为特定事件的时间。这个时间嵌入在记录中。所有生成和发送事件的源都嵌入了带有值的时间戳。</p><p id="e39c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><code class="fe my mz na nb b">processing time</code>可以描述为特定事件开始被处理时的处理时间。它是指执行相应操作的机器的系统时间。通过网络将信息发送到服务器需要一些时间，甚至是几毫秒或几秒钟。</p><h2 id="57eb" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">翻滚的窗户</h2><p id="b1c9" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated"><code class="fe my mz na nb b">tumbling window</code>的意思是一旦创建了一个窗口，窗口将继续处理数据，直到特定的时间过去。用户必须在创建窗口时分配该时间。一旦给定了指定的时间量，窗口将发出直到该时间的计算结果。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="9d38" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/> <br/>fixed_window = beam.Pipeline()<br/> <br/>content = ( fixed_window<br/> |beam.Create({‘dict1’:[24,45,68],’dict2':[32,54,75],‘dict3’:[56,78,92]})<br/> |beam.Map(lambda element: element)<br/> |beam.WindowInto(window.FixedWindows(20))<br/> |beam.io.WriteToText(‘/content/output_1’)<br/>)<br/> <br/>fixed_window.run()</span></pre><h2 id="38f6" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">推拉窗</h2><p id="e146" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">创建一个<code class="fe my mz na nb b">sliding window</code>的基本原理类似于一个<code class="fe my mz na nb b">tumbling window.</code>，一旦完成，窗口将继续执行数据，直到一段特定的时间过去；然而，这是一个不同之处，因为滑动窗口可以重叠。单个窗口可能会与另一个窗口的时间重叠。为此，多个窗口有可能重叠。最终，数据中的大多数元素将属于多个窗口。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="547e" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/> <br/>sliding_window = beam.Pipeline()<br/> <br/>content = ( sliding_window<br/> |beam.Create({‘dict1’:[24,45,68],’dict2':[32,54,75],‘dict3’:[56,78,92]})<br/> |beam.Map(lambda element: element)<br/> |beam.WindowInto(window.SlidingWindows(30,10))<br/> |beam.io.WriteToText(‘/content/output_2’)<br/> )<br/> <br/>sliding_window.run()</span></pre><h2 id="91b0" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">水印</h2><p id="0ee4" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">可以在事件时间戳上处理窗口。为了让Beam跟踪事件时间，会有一个额外的操作与之对应。如果我们用声明的时间定义一个窗口，那么应该有一些实体可以跟踪已经过去的指定数量的时间戳元素。测量事件时间进度的波束机制称为水印。水印声明流中已经过了指定的事件时间量。当前窗口不会接受时间戳小于当前水印值的任何元素。</p><h1 id="afcc" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">用编码器进行编码操作</h1><p id="0790" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">本节重点介绍Beam的数据编码机制。因此，您应该理解有两种数据模式。第一种是面向对象的，用户可以理解。另一种是机器可以理解的字节形式的序列化数据。</p><h2 id="2c18" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">Beam中的编码器类别</h2><p id="d62a" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">在每个生态系统中，对象数据在通过网络传输时被序列化为字节串。对于目标机器，它们被反序列化为对象形式。在Beam中，当运行者执行您的管道时，他们需要具体化您的PCollections的中间数据，这需要将组件从字节格式转换为字符串。</p><p id="90dc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">编码人员不一定与数据类型有一对一的关系。一种数据类型可以有多个编码器。</p><h2 id="3fdb" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">波束中的数据编码</h2><p id="b883" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">创建定制编码器的最重要的步骤在下面作为一个例子来实现。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="12f1" class="nc mc iq nb b gy nr ns l nt nu">import parquet<br/>from apache_beam.coders import Coder<br/>from apache_beam.transforms.userstate import ReadModifyWriteStateSpec<br/> <br/>class ParquetCoder(Coder):<br/>def encode(self, item):<br/> return parquet.dumps(item).encode()<br/> <br/>def decode(self, item):<br/> return parquet.loads(item.decode())<br/> <br/>def is_deterministic(self) -&gt; bool:<br/> return True</span><span id="3aa0" class="nc mc iq nb b gy ok ns l nt nu">class EncodeDecode(beam.DoFn):<br/> data_source = ReadModifyWriteStateSpec(name=’data_source’, coder=ParquetCoder())<br/> <br/>def execute(self, item, DataSource=beam.DoFn.StateParam(data_source)):</span><span id="98da" class="nc mc iq nb b gy ok ns l nt nu">return DataSource</span></pre><p id="58c3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第一种方法是<code class="fe my mz na nb b">Encode</code>。它接受输入值并将它们编码成字节串。</p><p id="2fd3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第二种方法是<code class="fe my mz na nb b">Decode</code>，它将编码后的字节串解码成相应的对象。</p><p id="1fd8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第三种方法是<code class="fe my mz na nb b">is_deterministic</code>。它决定该编码器是否按照Beam [ <a class="ae le" href="https://beam.apache.org/releases/pydoc/2.5.0/_modules/apache_beam/coders/coders.html" rel="noopener ugc nofollow" target="_blank"> 21 </a> ]文档中的规定对值进行确定性编码。</p><h1 id="bc34" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">阿帕奇光束触发器</h1><p id="5a25" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">Apache Beam触发器提示窗口发出结果。如[ <a class="ae le" href="https://beam.apache.org/releases/javadoc/2.6.0/org/apache/beam/sdk/transforms/windowing/Window.html" rel="noopener ugc nofollow" target="_blank"> 22 </a>和[ <a class="ae le" href="https://beam.apache.org/releases/javadoc/2.5.0/org/apache/beam/sdk/transforms/windowing/Trigger.html" rel="noopener ugc nofollow" target="_blank"> 23 </a>所述，在对窗口结构中的元素进行分组的情况下，Beam受益于触发器来决定何时转换每个窗口的聚合结果。即使你没有指定，每个窗口都有一个“默认触发器”。</p><p id="64a4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">您可以为您的窗口设置触发器来更改此默认行为。Beam提供了几个预置的触发器供您选择。除此之外，您还可以创建自定义触发器。根据触发类型，您的窗口可以在水印穿过您的窗口之前发出早期结果，也可以在任何后期元素到达时发出后期效果。</p><h2 id="c064" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">事件时间触发器</h2><p id="e5a6" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated"><code class="fe my mz na nb b">EventTimeTrigger</code>表现为<code class="fe my mz na nb b">AfterMarkTrigger</code>。这些是传输窗口内容的默认触发器。当缺省窗口设置和缺省触发器一起使用时，缺省触发器精确地发出一次，并且后期数据被丢弃[ <a class="ae le" href="https://beam.apache.org/releases/javadoc/2.5.0/org/apache/beam/sdk/transforms/windowing/AfterWatermark.html" rel="noopener ugc nofollow" target="_blank"> 24 </a> ]。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="1dc9" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/>from apache_beam import window<br/>from apache_beam.options.pipeline_options import PipelineOptions, StandardOptions<br/>from apache_beam.transforms.trigger import AfterWatermark, AfterProcessingTime, AccumulationMode, AfterCount<br/> <br/>after_watermark_trigger = beam.Pipeline()<br/> <br/>content = ( after_watermark_trigger<br/> |beam.Create({‘dict1’:[24,45,68],’dict2':[32,54,75], ‘dict3’:[56,78,92]})<br/> |beam.Map(lambda element: element)<br/> |beam.WindowInto(window.FixedWindows(20), <br/>trigger=AfterWatermark(<br/>early=AfterProcessingTime(5),<br/>late=AfterCount(5)),<br/>accumulation_mode=AccumulationMode.DISCARDING)<br/> |beam.io.WriteToText(‘/content/after_watermark_trigger.txt’)<br/>)<br/> <br/>after_watermark_trigger.run()</span></pre><h2 id="73ee" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">处理时间触发器</h2><p id="7ba9" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">第二个是<code class="fe my mz na nb b">ProcessingTimeTrigger</code>俗称<code class="fe my mz na nb b">AfterProcessingTime</code> [ <a class="ae le" href="https://beam.apache.org/releases/javadoc/2.1.0/org/apache/beam/sdk/transforms/windowing/AfterProcessingTime.html" rel="noopener ugc nofollow" target="_blank"> 25 </a>。顾名思义，这个触发器在处理时间上运行。经过一定的处理时间后，触发器会提示窗口发出结果。执行时间受到系统日期的限制，最好是数据项的时间戳。此触发器有助于从窗口中触发早期结果，尤其是具有重要时间范围的窗口，如单个全局窗口。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="ef90" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/>from apache_beam import window<br/>from apache_beam.options.pipeline_options import PipelineOptions, StandardOptions<br/>from apache_beam.transforms.trigger import AfterWatermark, AfterProcessingTime, AccumulationMode, AfterCount<br/> <br/>after_processing_time_trigger = beam.Pipeline()<br/> <br/>content = ( after_processing_time_trigger<br/> |beam.Create({‘dict1’:[24,45,68],’dict2':[32,54,75], ‘dict3’:[56,78,92]})<br/> |beam.Map(lambda element: element)<br/> |beam.WindowInto(window.FixedWindows(20), trigger=AfterProcessingTime(10), accumulation_mode=AccumulationMode.DISCARDING) |beam.io.WriteToText(‘/content/after_processing_time_trigger.txt’))<br/> <br/>after_processing_time_trigger.run()</span></pre><h2 id="8d34" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">数据驱动触发器</h2><p id="3d6a" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">第三个是<code class="fe my mz na nb b">DataDrivenTrigger</code>，名字叫<code class="fe my mz na nb b">AfterCount</code>。它在现有窗口收集了至少N个元素后运行。如果用“N = 5”指定计数触发器，当窗口的窗格中有五个功能时，它将提示窗口再次发出结果。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="5554" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/>from apache_beam import window<br/>from apache_beam.options.pipeline_options import PipelineOptions, StandardOptions<br/>from apache_beam.transforms.trigger import AfterWatermark, AfterProcessingTime, AccumulationMode, AfterCount<br/> <br/>after_count_trigger = beam.Pipeline()<br/> <br/>content = ( after_count_trigger<br/> |beam.Create({‘dict1’:[24,45,68],’dict2':[32,54,75], ‘dict3’:[56,78,92]})<br/> |beam.Map(lambda element: element)<br/> |beam.WindowInto(window.GlobalWindows(), trigger=AfterCount(5), accumulation_mode=AccumulationMode.DISCARDING)<br/> |beam.io.WriteToText(‘/content/after_count_trigger.txt’)<br/> )<br/> <br/>after_count_trigger.run()</span></pre><h2 id="51f5" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">复合触发器</h2><p id="d9e4" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">复合触发器是多个触发器的组合。它允许用谓词合并不同类型的触发器。它们允许同时使用多个触发器。光束包括以下类型[ <a class="ae le" href="https://beam.apache.org/releases/javadoc/2.5.0/org/apache/beam/sdk/transforms/windowing/AfterEach.html" rel="noopener ugc nofollow" target="_blank"> 26 </a> ]。</p><p id="b94a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第一个是<code class="fe my mz na nb b">Repeatedly</code>。该条件指定一个运行到无穷大的触发器。建议将<code class="fe my mz na nb b">Repeatedly</code>与其他一些可能导致该重复触发停止的条件结合使用。下面添加了一个示例代码片段。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="184a" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/>from apache_beam import window<br/>from apache_beam.options.pipeline_options import PipelineOptions, StandardOptions<br/>from apache_beam.transforms.trigger import AfterWatermark, AfterProcessingTime, AccumulationMode, AfterAny, Repeatedly<br/> <br/>composite_repeatedly = beam.Pipeline()<br/> <br/>content = ( composite_repeatedly<br/> | beam.Create({‘dict1’:[24,45,68],‘dict2’:[32,54,75], ‘dict3’:[56,78,92]})<br/> | beam.Map(lambda element: element)<br/> |beam.WindowInto(window.FixedWindows(20), trigger=Repeatedly(AfterAny(AfterCount(50), AfterProcessingTime(20))),<br/> accumulation_mode=AccumulationMode.DISCARDING)<br/> | beam.io.WriteToText(‘/content/composite_repeatedly’))<br/> <br/>composite_repeatedly.run()</span></pre><p id="b914" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第二个是<code class="fe my mz na nb b">AfterEach</code>。这种状态将多个触发器组合在一起，以特定的顺序一个接一个地触发。每当触发器发出一个窗口，过程就前进到下一个窗口。</p><p id="e427" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第三个是<code class="fe my mz na nb b">AfterFirst</code>。它使用多个触发器作为参数。当它的任何参数触发器被满足时，它处理窗口发出结果。它类似于多个触发器的“或”运算。</p><p id="f1de" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第四个是<code class="fe my mz na nb b">AfterAll</code>。它保存多个触发器作为参数，并使窗口在其所有参数触发器都满足时发出结果。对于许多触发器来说，它相当于“与”运算。</p><p id="dc36" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第五个是<code class="fe my mz na nb b">Finally</code>。它作为最终条件，使任何触发器最后一次触发，并且不再触发。</p><h1 id="dddd" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">Beam中流式数据管道的结构</h1><p id="e5a5" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">Beam的核心思想是提供整合的大数据处理管道。正如其官方文档[ <a class="ae le" href="https://beam.apache.org/documentation/programming-guide/" rel="noopener ugc nofollow" target="_blank"> 6 </a> ]中所述，其和谐的本质用单个API构建了批处理和流管道。</p><p id="47b7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当您创建您的<code class="fe my mz na nb b">Pipeline</code>时，您还可以设置一些与之相关的配置选项，比如管道运行器，它将执行您的管道，以及所选择的运行器所需的任何运行器特定的配置。</p><p id="0672" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">您可以考虑通过硬编码来分配管道的配置参数。尽管如此，通常建议从命令行读取它们，然后将其传递给<code class="fe my mz na nb b">Pipeline</code>对象。出于这个原因，如果我们可以构建一个从命令行获取运行器信息、输入输出文件路径信息的管道，那么我们的问题就解决了，我们可以说我们将获得一个通用管道。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="4c79" class="nc mc iq nb b gy nr ns l nt nu">import apache_beam as beam<br/>import argparse<br/>from apache_beam.options.pipeline_options import PipelineOptions, StandardOptions<br/> <br/>parser = argparse.ArgumentParser() <br/> <br/>parser.add_argument(‘ — input’, dest=’input’, required=True, help=’/content/data.txt/’)</span><span id="dbfb" class="nc mc iq nb b gy ok ns l nt nu">parser.add_argument(‘ — output’, dest=’input’, required=True, help=’/content/output.txt/’)<br/> <br/>path_args, pipeline_args = parser.parse_known_args() <br/> <br/>input_arguments = path_args.input <br/>output_arguments = path_args.output <br/> <br/>options = PipelineOptions(pipeline_args)<br/>pipeline_with_options = beam.Pipeline(options = options)<br/> <br/>dept_count = (pipeline_with_options<br/> |beam.io.ReadFromText(input_arguments)<br/> |beam.Map(lambda line: line.split(‘,’))<br/> |beam.Filter(lambda line: line[3] == ‘AI’) <br/> |beam.Map(lambda line: (line[1], 1))<br/> |beam.io.WriteToText(output_arguments)<br/>)<br/> <br/>pipeline_with_options.run()</span></pre><h1 id="3d8d" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">部署数据管道</h1><p id="769a" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">Beam将通过Google PubSub提供流媒体数据。为了在Google PubSub中处理流数据，我们需要创建一个项目，并获得它的“服务_账户_认证”密钥[ <a class="ae le" href="https://cloud.google.com/dataflow/docs/concepts/streaming-with-cloud-pubsub" rel="noopener ugc nofollow" target="_blank"> 27 </a> ]。</p><h2 id="dc6d" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">在Google PubSub中创建主题</h2><p id="c000" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">首先，我们需要点击<a class="ae le" href="https://cloud.google.com/" rel="noopener ugc nofollow" target="_blank">https://cloud.google.com/</a>主页右上角的按钮进入“控制台”。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/e9c0536e29f65d3f862354825cec46a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*8a7-rh749mTwKxbyO5139A.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="9700" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第二，谷歌云控制台将帮助你创建一个新项目。启动此项目可能需要几秒钟时间。创建项目后，您可以在“项目信息”部分查看“项目名称”。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi om"><img src="../Images/a9aaba3d361d3bf9ec23cb3df75091fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*SRkGbVoWF5_s9lgYISE46A.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="cc87" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">要获得其“服务身份验证密钥”,我们需要转到“IAM &amp; Admin”部分下的服务帐户。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi on"><img src="../Images/33635c7c55d1c6cc18f294b0ae675b05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*K66Y54Qz90zM5yHoLFNnrw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="7883" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">填写完必填字段后，我们可以点击“创建并继续”。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/ed81ce614a19887762fa3a097a604147.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*-8lH3SmlBHvzB4d8MvjGwg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="3382" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">或者，您可以在该身份验证密钥中授予您想要的权限。从选项中，继续“项目&gt;编辑器”。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/b13ac1dfb1ef1cbde385ea65aeb133e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*wOTPMjPT4jP54BrBciOWlg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="5a13" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">您可以通过单击“完成”按钮来完成初始化部分。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/bb54e07a741fd732b1c77d9e1b9b06c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*D-XoRxNw_oGrPgWzklj6rw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="a13c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">要创建一个`. json '格式的密钥，您可以单击“密钥”选项卡，然后选择“添加密钥”下的“创建新密钥”。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/fcdd2ab985649f026be0d4b34616f5bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*Jd3nCAIHHwFleobcTAKGSg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="8772" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这是我们希望为服务帐户生成的密钥。下载并保存在一个非常安全的地方。任何拥有此密钥的人都可以查看您的项目。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/275284166fd3835ac66cdd3dbed24941.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*yNqDf2A7Txsh0MfiUSHAWQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="42b3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">您将需要一个出版商、一个主题和一个订阅。发布者将发布关于某个主题的消息。为此，我们将使用“PubSub”。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ol"><img src="../Images/5b4259322d675c73483b375485e0664a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*gzuniKihWufh9kNgNBEfqQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="a971" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们已经创建了主题。一些统计数据是“发布消息请求计数”和“发布消息操作计数”。我们将在publisher脚本中使用这个主题路径。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/d550497e928ef7a583e78a8173063410.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*VzG9xh1zCoOMQ7eNq-ELwA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="e64a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">您需要通过将订阅名称和“交付类型”填写为“拉”来创建订阅主题。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/53a11188564e0812b1087daa4526393c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*r_65sc78Gken6HSZFmfmOQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="db4e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在创建了主题和订阅之后，我们可以查看统计图表，该图表没有显示任何内容，因为我们还没有发布任何消息。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/21eeaae7695466e8be73a74eb399265a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*nuIY2cxCQPqrzzJ87mhRcQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="d4d8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">假设您希望通过使用接口本身来发布消息。您可以点击“发布消息”并提供可选的消息属性作为键值对。这些属性用于发送有关消息的附加信息。对于“添加属性”,您可以添加“语言”作为关键字，添加“英语”作为其值。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/b32505444b59d8d8dfabc5f6abc23f56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*0YZnZanpsZzBGJDnyWbrIA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="eee7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">消息已发布，我们可以手动提取此消息，因为没有正在运行的订阅者。您可以选择您想要“拉”它的订阅。您可以选中“启用确认”按钮，在收到确认后发送确认。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/fc87c1903c160a7e477f60d8dea5356c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*gDTLmN_onUNw6_So9ai0oA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="2b90" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后，您可以点击“拉”。除了查看消息的属性之外，您还可以查看消息。我们可以观察到该消息已被确认。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/b76c92a07b9bb1c7c3f5118ce962172b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*eDpl4N4uUBIS4D1BjkKlFA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="ef3f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">整个活动中包括一些连接器，用于将客户的提供者连接到我们的发布者应用程序。这种方法在一些现实场景中使用，在这些场景中，他们希望我们逐行读取文件并进行处理，而不是对文件进行批处理。</p><p id="8d0f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">创建的PubSub主题可以像下面这样在脚本中定义来使用它。您可以用您的特定路径替换引用的字符串。应该填写这些路径，以便在Google Cloud的指南页面[ <a class="ae le" href="https://cloud.google.com/pubsub/docs/publisher" rel="noopener ugc nofollow" target="_blank"> 28 </a> ]中提到的正确主题上发布消息。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="7333" class="nc mc iq nb b gy nr ns l nt nu">import os<br/> from google.cloud import pubsub_v1<br/> <br/> project = ‘SubscribeBeam’<br/> <br/> topic_for_pubsub = ‘projects/qwiklabs-gcp-01–7779ab5fa77e/topics/BeamTopic’<br/> <br/> service_account_path = “C:\\Users\ersoyp\Documents\ApacheBeam\qwiklabs-gcp-01–7779ab5fa77e-2d40f7ded2a8.json”<br/> os.environ[“GOOGLE_APPLICATION_CREDENTIALS”] = service_account_path <br/> <br/> data_path = “C:\\Users\ersoyp\Documents\ApacheBeam\data.csv”</span></pre><h2 id="9452" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">用GCP处理数据管道</h2><p id="c31b" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">在上一节中，我们定义了PubSub主题和相关的“service_account_path”信息。在接下来的步骤中，我们将使用PubSub凭证通过Beam读写数据。我们一起来实施吧。</p><p id="c087" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">以下脚本定义了发布订阅主题路径、服务帐户路径、输入和输出文件路径。此外，我们添加了“GOOGLE_APPLICATION_CREDENTIALS”作为环境变量。在分配了这些路径之后，我们初始化了将要处理的射束管道。在输入和输出路径的帮助下，我们很容易从Google Cloud PubSub中读取数据，然后将结果写回给它。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="47ec" class="nc mc iq nb b gy nr ns l nt nu">import osimport os<br/>import apache_beam as beam<br/>from apache_beam.options.pipeline_options import PipelineOptions, StandardOptions<br/>from apache_beam import window<br/>project = ‘SubscribeBeam’<br/> <br/>pubsub_topic = ‘projects/qwiklabs-gcp-01–7779ab5fa77e/topics/BeamTopic’<br/> <br/>path_service_account = “C:\\Users\ersoyp\Documents\ApacheBeam\qwiklabs-gcp-01–7779ab5fa77e-2d40f7ded2a8.json”<br/> <br/>os.environ[“GOOGLE_APPLICATION_CREDENTIALS”] = path_service_account <br/> <br/>input_file = “C:\\Users\ersoyp\Documents\ApacheBeam\data.csv”<br/> <br/>output_file = ‘C:\\Users\ersoyp\Documents\ApacheBeam\output.csv’<br/> <br/>options = PipelineOptions()<br/> <br/>options.view_as(StandardOptions).streaming = True<br/> <br/>process = beam.Pipeline(options=options)<br/> <br/>output_file = ‘/content/outputs/’<br/> <br/>pubsub_data = ( process<br/> |’Read from Google PubSub’ &gt;&gt; beam.io.ReadFromPubSub(subscription= input_file)<br/> |’Write to Google PubSub’ &gt;&gt; beam.io.WriteToPubSub(output_file))<br/> <br/>final_file = process.run()</span></pre><h2 id="e318" class="nc mc iq bd md nd ne dn mh nf ng dp ml lo nh ni mn ls nj nk mp lw nl nm mr iw bi translated">向GCP订购数据管道</h2><p id="a290" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">作为部署数据管道的最后一步，我们需要用PubSub创建一个“SubscriberClient”对象。订阅服务器初始化后，将被分配到相应的订阅路径。您可以使用下面的脚本查看实现。</p><p id="715a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">脚本首先将“GOOGLE_APPLICATION_CREDENTIALS”指定为操作系统中的一个环境变量。分配的路径包括从GCP IAM &amp; Admin界面生成的服务帐户密钥。之后，我们在“args”的帮助下创建一个订阅路径。然后，我们用GCP公共订阅创建一个SubcriberClient。最后，我们将构建的订阅路径分配给GCP的订阅者。</p><pre class="kp kq kr ks gt nn nb no np aw nq bi"><span id="9832" class="nc mc iq nb b gy nr ns l nt nu">from google.cloud import pubsub_v1<br/>import time<br/>import os<br/> <br/>os.environ[“GOOGLE_APPLICATION_CREDENTIALS”] = ‘C:\\Users\ersoyp\Documents\ApacheBeam\qwiklabs-gcp-01–7779ab5fa77e-2d40f7ded2a8.json’<br/> <br/>path_for_subcription = args.subscription_path<br/> <br/>pubsub_subscriber = pubsub_v1.SubscriberClient()<br/> <br/>pubsub_subscriber.subscribe(path_for_subcription, callback=callback)</span></pre><h1 id="1c3c" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">监控数据管道</h1><p id="c2e5" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">在上面的章节中，我们在Google Cloud PubSub的帮助下发布、处理和订阅了带有示例脚本的数据管道。由于我们使用了GCP，我们可以使用谷歌云监控工具跟踪监控活动。</p><p id="7eaf" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为此，我们可以通过使用此窗格选择监控来查看“概述”、“仪表板”、“服务”和“指标浏览器”。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/8ce9f2110acc8bed415f2649c3512797.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*cc_5GboS2zkCsI_TEAiPSQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><p id="b071" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们创建的任何指标都将添加到“指标浏览器”选项卡下。我们可以选择“资源类型”和“指标”来过滤出正确的数据。此外，我们可以使用“Group by”和“Aggregator”的聚合操作和“Alignment period”。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/5b46f19b07648338d257a6d848afe09f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*re_3LpVaM97pDazNoJyyaA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">来源:图片由作者提供</p></figure><h1 id="755e" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">阿帕奇光束vs阿帕奇火花</h1><p id="e2ca" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">阿帕奇梁生产各种环境下的管道。它只是分布式数据的另一种编程模型。与Apache Spark一样，Apache Beam有RDD或数据帧来执行批处理，还有数据流来进行流处理。Beam用<a class="ae le" href="https://www.java.com/download/" rel="noopener ugc nofollow" target="_blank"> Java </a>、<a class="ae le" href="https://www.python.org/" rel="noopener ugc nofollow" target="_blank"> Python </a>和<a class="ae le" href="https://golang.org/" rel="noopener ugc nofollow" target="_blank"> Go </a>语言实现。</p><p id="a767" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">另一方面，Apache Spark是一个用于海量数据处理的综合引擎。它是在2012年开发的，最初只是为批处理而设计的。Spark将流分成几个小批量，并处理这些小批量。</p><p id="b9ba" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果我们保持小批量，就好像我们在执行实时流数据。这就是为什么Spark被认为接近实时流处理引擎，而不是有效的流处理引擎。Spark是用Scala语言实现的。也兼容Spark官方页面[ <a class="ae le" href="https://spark.apache.org/docs/latest/streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank"> 29 </a> ]中描述的<a class="ae le" href="https://hadoop.apache.org/" rel="noopener ugc nofollow" target="_blank"> Hadoop </a>平台。</p><h1 id="bf5c" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">最后的想法</h1><p id="91e1" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">在整篇文章中，在最初描述概念和用示例脚本实现解决方案的结构中呈现了广泛的主题。主题包括介绍Apache Beam，然后在Beam中构建管道。标题包括但不限于:</p><ul class=""><li id="4d8e" class="nw nx iq lh b li lj ll lm lo ny ls nz lw oa ma ob oc od oe bi translated">Apache Beam的体系结构</li><li id="7d2a" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">阿帕奇波束的特点</li><li id="309f" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">阿帕奇梁的管道结构</li><li id="a48a" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">帕尔多变换</li><li id="7d3a" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">复合转换</li><li id="8a9d" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">侧面输入和侧面输出</li><li id="929c" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">在Apache Beam中实现Windows</li><li id="b244" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">用编码器进行编码操作</li><li id="f1e5" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">阿帕奇光束触发器</li><li id="dd0a" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">流式数据管道的结构</li><li id="12b6" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">部署数据管道</li><li id="d319" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">监控数据管道</li><li id="194b" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">阿帕奇光束vs阿帕奇火花</li></ul></div><div class="ab cl oo op hu oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="ij ik il im in"><p id="4779" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">非常感谢您的提问和评论！</p></div><div class="ab cl oo op hu oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="ij ik il im in"><h1 id="ad79" class="mb mc iq bd md me ov mg mh mi ow mk ml kf ox kg mn ki oy kj mp kl oz km mr ms bi translated">附加参考</h1><ul class=""><li id="1a2b" class="nw nx iq lh b li mt ll mu lo pa ls pb lw pc ma ob oc od oe bi translated">阿帕奇光束:<a class="ae le" href="https://beam.apache.org/documentation/" rel="noopener ugc nofollow" target="_blank">https://beam.apache.org/documentation/</a></li><li id="5e56" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">Apache Beam Pipeline:<a class="ae le" href="https://beam.apache.org/documentation/pipelines/design-your-pipeline/" rel="noopener ugc nofollow" target="_blank">https://Beam . Apache . org/documentation/pipelines/design-your-Pipeline/</a></li><li id="a7c8" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">阿帕奇火花:【https://spark.apache.org/documentation.html】的<a class="ae le" href="https://spark.apache.org/documentation.html" rel="noopener ugc nofollow" target="_blank">，</a><a class="ae le" href="https://beam.apache.org/documentation/runners/spark/" rel="noopener ugc nofollow" target="_blank">的https://beam.apache.org/documentation/runners/spark/</a></li><li id="0eca" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">阿帕奇弗林克:<a class="ae le" href="https://ci.apache.org/projects/flink/flink-docs-master/" rel="noopener ugc nofollow" target="_blank">https://ci.apache.org/projects/flink/flink-docs-master/</a></li><li id="ba17" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">阿帕奇萨姆扎:<a class="ae le" href="http://samza.apache.org/startup/quick-start/1.6.0/beam.html" rel="noopener ugc nofollow" target="_blank">http://samza.apache.org/startup/quick-start/1.6.0/beam.html</a></li><li id="86ab" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">谷歌云数据流:<a class="ae le" href="https://cloud.google.com/dataflow/docs/concepts/beam-programming-model" rel="noopener ugc nofollow" target="_blank">https://Cloud . Google . com/data flow/docs/concepts/beam-programming-model</a></li><li id="2a24" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">大数据描述:<a class="ae le" href="https://www.sas.com/en_us/insights/big-data/what-is-big-data.html" rel="noopener ugc nofollow" target="_blank">https://www . SAS . com/en _ us/insights/big-Data/what-is-big-Data . html</a></li><li id="7f8a" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">Apache Beam |构建大数据管道的实践课程:<a class="ae le" href="https://www.udemy.com/course/apache-beam-a-hands-on-course-to-build-big-data-pipelines/" rel="noopener ugc nofollow" target="_blank">https://www . udemy . com/course/Apache-Beam-A-Hands-On-course-build-Big-data-Pipelines/</a></li><li id="8eda" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">窗口累加模式，<a class="ae le" href="https://beam.apache.org/documentation/programming-guide/#triggers" rel="noopener ugc nofollow" target="_blank">https://beam . Apache . org/documentation/programming-guide/# triggers</a></li><li id="a36a" class="nw nx iq lh b li of ll og lo oh ls oi lw oj ma ob oc od oe bi translated">谷歌云控制台，<a class="ae le" href="https://console.cloud.google.com" rel="noopener ugc nofollow" target="_blank">https://console.cloud.google.com</a></li></ul></div></div>    
</body>
</html>