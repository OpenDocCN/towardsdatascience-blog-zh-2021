<html>
<head>
<title>Clustering Made Easy with PyCaret</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyCaret简化了集群</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/clustering-made-easy-with-pycaret-656316c0b080?source=collection_archive---------3-----------------------#2021-10-15">https://towardsdatascience.com/clustering-made-easy-with-pycaret-656316c0b080?source=collection_archive---------3-----------------------#2021-10-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6694" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利用强大的Python库进行低代码机器学习</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c2f82eac0469140a2f667397aaf994c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*k7m_lgr--sBapUz9"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">卢卡斯·霍布斯在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><blockquote class="kw kx ky"><p id="a44c" class="kz la lb lc b ld le jr lf lg lh ju li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">这篇文章的内容最初发表在我的最新著作《用PyCaret简化机器学习》中。你可以<a class="ae kv" href="https://leanpub.com/pycaretbook/" rel="noopener ugc nofollow" target="_blank">点击这里</a>了解更多。</p></blockquote><p id="3f44" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi lz translated">无监督机器学习的基本任务之一是聚类。此任务的目标是根据给定数据集实例的共同特征，将它们分类到不同的群集中。聚类在各个领域有许多实际应用，包括市场研究、社会网络分析、生物信息学、医学等。在本文中，我们将通过使用<a class="ae kv" href="https://pycaret.org/" rel="noopener ugc nofollow" target="_blank"> PyCaret </a>来检查一个聚类案例研究，PyCaret是一个Python库，它支持所有基本的机器学习任务，如回归、分类、聚类和异常检测。PyCaret通过遵循低代码方法简化了机器学习工作流，从而使其成为初学者以及希望快速原型化ML模型的专家的绝佳选择。</p><h1 id="3191" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">软件要求</h1><p id="86c4" class="pw-post-body-paragraph kz la iq lc b ld na jr lf lg nb ju li lw nc ll lm lx nd lp lq ly ne lt lu lv ij bi translated">本文中的代码应该可以在所有主要的操作系统上运行，比如微软的Windows、Linux和苹果的macOS。你需要在你的电脑上安装Python 3和JupyterLab。我建议你使用Anaconda，这是一个机器学习和数据科学工具包，包括许多有用的库和软件包。Anaconda可以在这个<a class="ae kv" href="https://www.anaconda.com/products/individual" rel="noopener ugc nofollow" target="_blank">链接</a>免费下载。或者，你可以使用像<a class="ae kv" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>这样的云服务来运行Python代码，而不用担心在你的机器上安装任何东西。你可以创建一个新的Jupyter笔记本并输入代码，或者从Github库下载。</p><h1 id="3a16" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">正在安装PyCaret</h1><p id="80bd" class="pw-post-body-paragraph kz la iq lc b ld na jr lf lg nb ju li lw nc ll lm lx nd lp lq ly ne lt lu lv ij bi translated">通过在Anaconda终端上执行以下命令，可以在本地安装PyCaret库。您还可以在Google Colab或类似的服务上执行相同的命令，将库安装到远程服务器上。</p><p id="4fdf" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated"><code class="fe nf ng nh ni b">pip install pycaret[full]==2.3.4</code></p><p id="3438" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">执行该命令后，PyCaret将被安装，您将能够运行本文的所有代码示例。建议通过包含<code class="fe nf ng nh ni b">[full]</code>说明符来安装可选的依赖项。此外，安装正确的包版本确保了最大的兼容性，因为我使用的是PyCaret ver。2.3.4撰写本文时。最后，<a class="ae kv" href="https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html#managing-envs" rel="noopener ugc nofollow" target="_blank">为PyCaret创建一个conda环境</a>被认为是最佳实践，因为它将帮助您避免与其他包的冲突，并确保您总是安装了正确的依赖项。</p><h1 id="2e11" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">k均值聚类</h1><p id="3c62" class="pw-post-body-paragraph kz la iq lc b ld na jr lf lg nb ju li lw nc ll lm lx nd lp lq ly ne lt lu lv ij bi translated">K-Means聚类是最流行和最简单的聚类方法之一，易于理解并在代码中实现。它在下面的公式中定义。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/08268b1e039877fb36c3ce6b0be8ecda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8x056xyQFZjcujF_MTQYQw.png"/></div></div></figure><p id="9a1d" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated"><em class="lb"> K </em>是所有集群的数量，而<em class="lb"> C </em>代表每个单独的集群。我们的目标是最小化<em class="lb"> W </em>，这是集群内变化的度量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/5d04af052f123fe1a6bc584a0f25948a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FflGcxgGmxBUWcb_XwAmaQ.png"/></div></div></figure><p id="d8f9" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">定义类内变异有多种方法，但最常用的方法是平方欧几里德距离，如上式所示。这导致了以下形式的K均值聚类，其中<em class="lb"> W </em>被欧几里德距离公式代替。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/4ad37dde62b80032f1d38013785f730c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O8hpohcdKZ3A2MICxFF3rA.png"/></div></div></figure><h1 id="56d9" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">使用PyCaret进行聚类</h1><p id="6653" class="pw-post-body-paragraph kz la iq lc b ld na jr lf lg nb ju li lw nc ll lm lx nd lp lq ly ne lt lu lv ij bi translated">K-Means是一种广泛使用的方法，但还有许多其他可用的方法，如仿射传播、谱聚类、凝聚Clustering⁴、均值漂移Clustering⁵和基于密度的空间聚类(DBSCAN)⁶.我们现在将了解PyCaret聚类模块如何帮助我们轻松地训练模型并评估其性能。</p><pre class="kg kh ki kj gt nm ni nn no aw np bi"><span id="3e6f" class="nq mj iq ni b gy nr ns l nt nu">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import matplotlib as mpl<br/>import seaborn as sns<br/>from pycaret.clustering import *<br/>from sklearn.datasets import make_blobs<br/>mpl.rcParams['figure.dpi'] = 300</span></pre><p id="853f" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">我们首先导入一些标准的Python库，包括NumPy、pandas、Matplotlib和Seaborn。我们还导入了PyCaret聚类函数，以及可用于生成数据集的<code class="fe nf ng nh ni b">make_blobs()</code> scikit-learn函数。最后，我们将Matplotlib图形DPI设置为300，这样我们就可以获得高分辨率的图形。没有必要启用此设置，所以如果需要，可以删除最后一行。</p><h1 id="6f0f" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">生成合成数据集</h1><pre class="kg kh ki kj gt nm ni nn no aw np bi"><span id="a90d" class="nq mj iq ni b gy nr ns l nt nu">cols = ['column1', 'column2', 'column3',<br/>        'column4', 'column5']</span><span id="9019" class="nq mj iq ni b gy nv ns l nt nu">arr = make_blobs(n_samples = 1000, n_features = 5, random_state =20,<br/>                 centers = 3, cluster_std = 1)</span><span id="bad0" class="nq mj iq ni b gy nv ns l nt nu">data = pd.DataFrame(data = arr[0], columns = cols)<br/>data.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/47d28896c3d20e3c3eba8f6e3dd26d1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j4h3aMUpFifpz6zQIwwo3g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><pre class="kg kh ki kj gt nm ni nn no aw np bi"><span id="9ba0" class="nq mj iq ni b gy nr ns l nt nu">data.info()</span><span id="9c53" class="nq mj iq ni b gy nv ns l nt nu">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 1000 entries, 0 to 999<br/>Data columns (total 5 columns):<br/> #   Column   Non-Null Count  Dtype  <br/>---  ------   --------------  -----  <br/> 0   column1  1000 non-null   float64<br/> 1   column2  1000 non-null   float64<br/> 2   column3  1000 non-null   float64<br/> 3   column4  1000 non-null   float64<br/> 4   column5  1000 non-null   float64<br/>dtypes: float64(5)<br/>memory usage: 39.2 KB</span></pre><p id="3776" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">我们将使用<code class="fe nf ng nh ni b">make_blobs()</code> scikit-learn函数生成一个合成数据集，而不是加载真实世界的数据集。该函数生成适合于聚类模型的数据集，并且具有可以根据我们的需要修改的各种参数。在本例中，我们创建了一个包含1000个实例、5个特征和3个不同聚类的数据集。使用合成数据集来测试我们的聚类模型有各种好处，主要是我们已经知道了实际的聚类数，因此我们可以轻松地评估模型性能。真实世界的数据通常更加复杂，也就是说，它们并不总是具有明显分离的聚类，但是使用简单的数据集可以让您熟悉工具和工作流。</p><h1 id="0cfb" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">探索性数据分析</h1><pre class="kg kh ki kj gt nm ni nn no aw np bi"><span id="9ea7" class="nq mj iq ni b gy nr ns l nt nu">data.hist(bins = 30, figsize = (12,10), grid = False)</span><span id="eb2b" class="nq mj iq ni b gy nv ns l nt nu">plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/5ab73b85bd5fb290ea41350a3f4b6be0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MGJ72lZxVq6JJ4CukvSveg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="338a" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated"><code class="fe nf ng nh ni b">hist()</code> pandas函数让我们可以轻松地可视化每个变量的分布。我们可以看到，所有变量分布要么是双峰的，要么是多峰的，也就是说，它们有两个或更多的峰值。当数据集包含多个具有不同特征的组时，通常会发生这种情况。在这种情况下，数据集专门创建为包含3个不同的聚类，因此变量具有多峰分布是合理的。</p><pre class="kg kh ki kj gt nm ni nn no aw np bi"><span id="7e36" class="nq mj iq ni b gy nr ns l nt nu">plt.figure(figsize=(10, 8))<br/>sns.heatmap(data.corr().round(decimals=2), annot=True)</span><span id="43f2" class="nq mj iq ni b gy nv ns l nt nu">plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/2d531e48d8dc7e2078498a29edd82365.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xX__o9N6oIw57ip0j-hm5Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="a5b1" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">我们使用了<code class="fe nf ng nh ni b">corr()</code> pandas函数和<code class="fe nf ng nh ni b">heatmap()</code> Seaborn函数来创建一个热图，可视化所有变量对的相关值。我们可以看到列2和列3有很强的线性关系，相关值为0.93。第3列和第4列也是如此，相关值为0.75。另一方面，列1与所有其他列反向相关，尤其是列5，其值为-0.85。</p><pre class="kg kh ki kj gt nm ni nn no aw np bi"><span id="6720" class="nq mj iq ni b gy nr ns l nt nu">plot_kws = {'scatter_kws': {'s': 2}, 'line_kws': {'color': 'red'}}<br/>sns.pairplot(data, kind='reg', vars=data.columns[:-1], plot_kws=plot_kws)</span><span id="5783" class="nq mj iq ni b gy nv ns l nt nu">plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/abb826c5dccc9d5f8a6b73c0bb55e7b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N-OabBhWhNC-R5P4h-h-jQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="e0fd" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">我们使用<code class="fe nf ng nh ni b">pairplot()</code> Seaborn函数为合成数据集创建散点图矩阵，对角线上有每个变量的直方图。数据集聚类在散点图中是可见的，这表明它们彼此明显分开。正如之前在关联热图中观察到的，我们可以看到一些变量对具有很强的线性关系，而其他变量对则具有相反的线性关系。通过将<code class="fe nf ng nh ni b">pairplot()</code>函数的<code class="fe nf ng nh ni b">kind</code>参数设置为<code class="fe nf ng nh ni b">reg</code>，每个散点图中包含的回归线突出显示了这一点。</p><h1 id="8f1d" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">正在初始化PyCaret环境</h1><pre class="kg kh ki kj gt nm ni nn no aw np bi"><span id="70a8" class="nq mj iq ni b gy nr ns l nt nu">cluster = setup(data, session_id = 7652)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/0e4b367fe799fd62a387f4a5bbffe46e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0e1xOiGfw5vZLYK5b572yQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="df7f" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">在完成探索性数据分析(EDA)之后，我们现在将使用<code class="fe nf ng nh ni b">setup()</code>函数来初始化PyCaret环境。通过这样做，将创建一个为模型训练和部署准备数据的管道。在这种情况下，默认设置是可以接受的，所以我们不打算修改任何参数。不管怎样，这个强大的函数有许多数据预处理能力，所以你可以参考<a class="ae kv" href="https://pycaret.readthedocs.io/en/latest/api/clustering.html" rel="noopener ugc nofollow" target="_blank"> PyCaret集群模块</a>的文档页面来阅读更多关于它的细节。</p><h1 id="630d" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">创建模型</h1><pre class="kg kh ki kj gt nm ni nn no aw np bi"><span id="4b63" class="nq mj iq ni b gy nr ns l nt nu">model = create_model('kmeans')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/f5e41e8af01133819860404e0303b3c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YPfxA_XBUczKv3HKgpVnfw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="aadb" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated"><code class="fe nf ng nh ni b">create_model()</code>函数让我们可以轻松地创建和评估我们偏好的聚类模型，比如K-Means算法。这个函数默认创建4个集群，所以我们可以简单地将<code class="fe nf ng nh ni b">num_clusters</code>参数设置为3，因为这是正确的数字。相反，我们将遵循一种对真实世界数据集进行归纳的方法，其中聚类数通常是未知的。执行该功能后，将打印出许多绩效指标，包括Silhouette⁷、Calinski-Harabasz⁸和Davies-Bouldin⁹.我们将把重点放在轮廓系数上，它在下面的等式中定义。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/60204e671a69a79c05194a3b2f265a40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I1lMDXBcZ0Wrzg5YMVJG9w.png"/></div></div></figure><ul class=""><li id="ea9f" class="oc od iq lc b ld le lg lh lw oe lx of ly og lv oh oi oj ok bi translated"><em class="lb"> s(i) </em>是数据集实例<em class="lb"> i </em>的剪影系数。</li><li id="5d54" class="oc od iq lc b ld ol lg om lw on lx oo ly op lv oh oi oj ok bi translated"><em class="lb"> a(i) </em>是<em class="lb"> i </em>的平均类内距离。</li><li id="a308" class="oc od iq lc b ld ol lg om lw on lx oo ly op lv oh oi oj ok bi translated"><em class="lb"> b(i) </em>是<em class="lb"> i </em>的平均最近簇距离。</li></ul><p id="3f4e" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">产生的度量值是所有实例的平均轮廓系数，范围在-1和1之间。负值表示实例被分配到了错误的集群，而接近0的值表示集群重叠。另一方面，接近1的正值表示分配正确。在我们的示例中，该值为0.5822，这表明可以通过为数据集找到最佳聚类数来提高模型性能。接下来，我们将看看如何通过使用肘方法来实现这一点。</p><pre class="kg kh ki kj gt nm ni nn no aw np bi"><span id="7e66" class="nq mj iq ni b gy nr ns l nt nu">plot_model(model, 'elbow')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oq"><img src="../Images/15c4a065dfab1b104c929576faf22ae0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N6OHN0yMiHM8-eTg-23jYw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="6a10" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated"><code class="fe nf ng nh ni b">plot_model()</code>函数让我们为模型创建各种有用的图表。在这种情况下，我们创建了一个肘图，它将帮助我们找到K-Means模型的最佳聚类数。肘方法为一系列的<em class="lb"> K </em>值训练聚类模型，并可视化每个⁰.的失真分数曲线上的拐点——即所谓的“肘”——表明了K 的最佳值。正如所料，该图在<em class="lb"> K </em> = 3处有一个拐点，用垂直虚线突出显示。</p><pre class="kg kh ki kj gt nm ni nn no aw np bi"><span id="776e" class="nq mj iq ni b gy nr ns l nt nu">model = create_model('kmeans', num_clusters = 3)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi or"><img src="../Images/f6adb9ff9cd4f0b343b55ec1b6a93ea6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mdpIzfoQQgt5ReenaFhvbw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="1553" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">在使用肘方法找到最佳聚类数之后，我们再次训练K-Means模型。正如我们所看到的，平均轮廓系数增加到0.7972，表明模型性能提高，每个数据集实例的聚类分配更好。</p><h1 id="1b82" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">绘制模型</h1><pre class="kg kh ki kj gt nm ni nn no aw np bi"><span id="3495" class="nq mj iq ni b gy nr ns l nt nu">plot_model(model, 'cluster')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi os"><img src="../Images/2029ccfed1108f0f5c48f065345629bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t-QwyDLJV010bxWmvSWzrA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="aabd" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">如前所述，<code class="fe nf ng nh ni b">plot_model()</code>是一个有用的函数，可以用来为我们的聚类模型绘制各种图形。在这种情况下，我们为K均值模型创建了2D主成分分析(PCA)图。PCA可用于将数据投影到低维空间，同时保留大部分方差，这种技术称为降维。在将PCA应用于合成数据集之后，原始的5个特征已经减少到2个主成分。此外，我们可以看到集群被清楚地分开，并且所有数据集实例都被分配到正确的集群。</p><h1 id="997a" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">保存和分配模型</h1><pre class="kg kh ki kj gt nm ni nn no aw np bi"><span id="4986" class="nq mj iq ni b gy nr ns l nt nu">save_model(model, 'clustering_model')</span><span id="d082" class="nq mj iq ni b gy nv ns l nt nu">results = assign_model(model)<br/>results.head(10)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ot"><img src="../Images/d81444471c7fb402dc1eb976141b34c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*guU5qLo43UTEbK0qV5SOew.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="9d65" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated"><code class="fe nf ng nh ni b">save_model()</code>函数让我们将集群模型保存到本地磁盘，以备将来使用或作为应用程序部署。模型存储为pickle文件，可以使用补充的<code class="fe nf ng nh ni b">load_model()</code>功能加载。此外，<code class="fe nf ng nh ni b">assign_model()</code>函数返回合成数据集，并为分配给数据集实例的分类标签添加一列。</p><h1 id="4e85" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">结论</h1><p id="dbb1" class="pw-post-body-paragraph kz la iq lc b ld na jr lf lg nb ju li lw nc ll lm lx nd lp lq ly ne lt lu lv ij bi translated">希望我在本文中提供的案例研究能够帮助您掌握PyCaret集群模块。我还鼓励读者自己尝试其他数据集并实践上述技术。如果你想了解更多关于PyCaret的知识，你可以查看<a class="ae kv" href="https://leanpub.com/pycaretbook/" rel="noopener ugc nofollow" target="_blank">用Pycaret </a>简化机器学习，这是我最近出版的一本关于图书馆的书。欢迎在评论中分享你的想法，或者关注我的LinkedIn，我会定期在那里发布关于数据科学和其他主题的内容。</p><h1 id="12a0" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">参考</h1><p id="93db" class="pw-post-body-paragraph kz la iq lc b ld na jr lf lg nb ju li lw nc ll lm lx nd lp lq ly ne lt lu lv ij bi translated">[1]:斯坦利，道格拉斯。" K-均值聚类:半个世纪的综合."英国数学和统计心理学杂志59.1(2006):1–34。</p><p id="14d3" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">[2]:杜拉克，德尔伯特。相似性传播:通过传递消息来聚集数据。多伦多:多伦多大学，2009年。</p><p id="34d3" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">[3]:冯·卢克斯堡，乌尔里克。"关于谱聚类的教程."统计与计算17.4(2007):395–416。</p><p id="aedb" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">[4]:阿克曼，马塞尔r等，“凝聚式聚类分析”算法69.1(2014):184–215。</p><p id="b747" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">[5]:德尔潘尼斯，康斯坦丁诺斯g .“均值漂移聚类”课堂讲稿(2005): 32。</p><p id="6a93" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">[6]:汗、卡姆兰等《DBSCAN:过去、现在和未来》第五届数字信息与网络技术应用国际会议(ICADIWT 2014)。IEEE，2014年。</p><p id="e020" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">[7]: Rousseeuw，Peter J .“轮廓:聚类分析的解释和验证的图形辅助”计算与应用数学杂志20(1987):53–65。</p><p id="408b" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">[8]:卡利翁斯基、塔德乌什和耶日·哈拉巴斯。"一种用于聚类分析的枝晶方法."统计学通讯-理论与方法3.1(1974):1–27。</p><p id="83c5" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">[9]:戴维斯、戴维l和唐纳德w波尔丁。"一种聚类分离方法."IEEE模式分析和机器智能汇刊2(1979):224–227。</p><p id="6f28" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">[10]:袁、春晖、。" K-means聚类算法中K值选择方法的研究."j 2.2(2019):226–235。</p><p id="5cb9" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li lw lk ll lm lx lo lp lq ly ls lt lu lv ij bi translated">[11]:阿卜迪、埃尔韦和林恩·威廉斯。“主成分分析。”威利跨学科评论:计算统计学2.4(2010):433–459。</p></div></div>    
</body>
</html>