<html>
<head>
<title>Train MaskRCNN on custom dataset with Detectron2 in 4 steps</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Detectron2分4步在自定义数据集上训练MaskRCNN</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/train-maskrcnn-on-custom-dataset-with-detectron2-in-4-steps-5887a6aa135d?source=collection_archive---------1-----------------------#2021-07-27">https://towardsdatascience.com/train-maskrcnn-on-custom-dataset-with-detectron2-in-4-steps-5887a6aa135d?source=collection_archive---------1-----------------------#2021-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3e90" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">对自定义数据集应用对象检测的最简单方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f7ad14a479c35d53e9365b62d9608f97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xiRa-niQQqkoHOdl9Q5abQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片作者</p></figure><p id="b7d1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae lu" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank">0 detector 2</a>是AI脸书研究团队最新发布的用于物体检测的Python库。与火炬视觉相比，它的主要优势是你可以更快地训练。此外，我相信它更容易使用，因为他们已经提供了一个默认的训练器，其中包含了许多可配置的对象检测模型，如FasterRCNN，MaskRCNN，Retinatet等。在本教程中，我解释了使用Detectron2在自定义数据集上逐步训练MaskRCNN，因此您可以在一分钟内看到它有多简单。</p><h1 id="70b7" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">第一步:准备好注释</h1><p id="a33d" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">注释必须是下面的COCO格式，和这里<a class="ae lu" href="https://www.immersivelimit.com/tutorials/create-coco-annotations-from-scratch#:~:text=The%20COCO%20dataset%20is%20formatted,%E2%80%9D%20(in%20one%20case)." rel="noopener ugc nofollow" target="_blank">介绍的COCO格式</a>有点不同。对于每个图像，包括关于图像路径、宽度、高度、id和注释的信息。</p><p id="eaee" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">注意:</strong>如果已经有了<a class="ae lu" href="https://www.immersivelimit.com/tutorials/create-coco-annotations-from-scratch#:~:text=The%20COCO%20dataset%20is%20formatted,%E2%80%9D%20%28in%20one%20case%29." rel="noopener ugc nofollow" target="_blank"> COCO格式</a>的数据集，可以跳过这一步，进入下一步。唯一的区别是，你应该用<code class="fe ms mt mu mv b">register_coco_instances()</code>而不是<code class="fe ms mt mu mv b">register()</code>来注册你的数据。</p><p id="5bb2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请记住，<code class="fe ms mt mu mv b">filename</code>应该是一个图像路径，并且<code class="fe ms mt mu mv b">image_id</code>在数据集的图像中必须是唯一的。<code class="fe ms mt mu mv b">segmentation</code>是一个有<code class="fe ms mt mu mv b">n</code>个点的多边形，<code class="fe ms mt mu mv b">(x_i, y_i)</code>。对于边界框，你有多种选择<code class="fe ms mt mu mv b">[x_0, y_1, x_1, y_1]</code>、<code class="fe ms mt mu mv b">[x_0, y_0, width, height]</code>或这里呈现的<a class="ae lu" href="https://github.com/facebookresearch/detectron2/blob/master/detectron2/structures/boxes.py" rel="noopener ugc nofollow" target="_blank">的任何其他表示。然而，<code class="fe ms mt mu mv b">bbox_mode</code>应该与<code class="fe ms mt mu mv b">bbox</code>表示一致。</a></p><p id="0d30" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，我将<code class="fe ms mt mu mv b">bbox_mode</code>设置为<code class="fe ms mt mu mv b">XYWH_ABS</code>，即<code class="fe ms mt mu mv b">[x_0, y_0, width, height]</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Detectron2数据集的模板</p></figure><h1 id="11c6" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">第二步:加载数据</h1><p id="b349" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">假设您的数据集已经是上面的格式，并且在本地保存为<code class="fe ms mt mu mv b">.json</code>。为了加载数据，我们应该在Detectron2数据集目录中注册数据集，为此我们需要一个数据加载器函数:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">加载数据集</p></figure><h1 id="c608" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">第三步:定制配置</h1><p id="16e1" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">Detectron2提供了一个默认配置，包括许多超参数。要定制默认配置，首先导入<code class="fe ms mt mu mv b">get_cfg</code>，这将返回一个超参数字典。</p><p id="54a5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以从<code class="fe ms mt mu mv b">detectron2.model_zoo</code>得到配置文件。此外，我们也可以通过从<code class="fe ms mt mu mv b">model_zoo</code>加载重量来使用预训练模型。此外，我们可以设置其他配置，就像我在下面对我的desire模型所做的那样。</p><ul class=""><li id="80e6" class="my mz it la b lb lc le lf lh na ll nb lp nc lt nd ne nf ng bi translated">默认情况下，遮罩是关闭的。要训练一个MaskRCNN，打开它:<code class="fe ms mt mu mv b">MODEL.MASK_ON = True</code></li><li id="5a13" class="my mz it la b lb nh le ni lh nj ll nk lp nl lt nd ne nf ng bi translated">骨干网络默认为<code class="fe ms mt mu mv b">build_resnet_backbone</code>，但预训练模型使用ResnetFPN。我更喜欢保持默认，用<code class="fe ms mt mu mv b">resnet34</code>代替<code class="fe ms mt mu mv b">resnet101</code>，降低模型的复杂度；<code class="fe ms mt mu mv b">MODEL.BACKBONE.NAME = "build_resnet_backbone"</code>和<code class="fe ms mt mu mv b">cfg.MODEL.RESNETS.DEPTH = 34</code>。</li><li id="a0be" class="my mz it la b lb nh le ni lh nj ll nk lp nl lt nd ne nf ng bi translated">我通过设置<code class="fe ms mt mu mv b">cfg.INPUT.MIN_SIZE_TRAIN = (800,)</code>均等地缩小所有图像的尺寸</li><li id="5414" class="my mz it la b lb nh le ni lh nj ll nk lp nl lt nd ne nf ng bi translated">因为我知道每幅图像中只有很少的物体，所以我减少了区域提议网络中的预处理和后处理NMS。</li><li id="9451" class="my mz it la b lb nh le ni lh nj ll nk lp nl lt nd ne nf ng bi translated">您还可以根据您的GPU设备<code class="fe ms mt mu mv b">cfg.SOLVER.IMS_PER_BATCH = 4</code>设置每批图像的数量。</li><li id="079f" class="my mz it la b lb nh le ni lh nj ll nk lp nl lt nd ne nf ng bi translated">在本地设置数据集和输出目录。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">自定义配置</p></figure><h1 id="549f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">最后一步:训练</h1><p id="72b3" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">现在，训练很简单。只需几行代码就可以完成。创建标签列表的是<code class="fe ms mt mu mv b">thing_classes</code>。在这里，我创建了三个标签:人、狗和猫。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用检测器2训练MaskRCNN</p></figure><h1 id="a251" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">预测和可视化</h1><p id="3901" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">可视化对于呈现对象检测结果是方便的，并且它也有助于评估。</p><p id="3850" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最终的模型已经保存在输出目录中。我们可以从最终模型中加载权重，从测试集中逐个读取图像，运行预测器，并在本地保存带有遮罩和边界框的输出图像。</p><p id="8c2c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">测试集应该包含图像路径的<code class="fe ms mt mu mv b">file_name</code>和<code class="fe ms mt mu mv b">image_id</code>。举个例子，</p><pre class="kj kk kl km gt nm mv nn no aw np bi"><span id="debe" class="nq lw it mv b gy nr ns l nt nu">test_data = [{'file_name': '.../image_1.jpg',<br/>              'image_id': 10},<br/>             {'file_name': '.../image_2.jpg',<br/>              'image_id': 20}<br/>             ]</span></pre><p id="9801" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe ms mt mu mv b">visualization()</code>接受定制配置、元数据和测试集。它获取最终的模型，并将边界框和遮罩添加到图像中。最后，它在输出目录中创建一个目录，并将结果保存在那里。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">可视化步骤</p></figure><h1 id="79c1" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="d7c4" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">Detectron2使物体检测变得简单快捷。在本教程中，我解释了如何通过几个步骤运行MaskRCNN。此外，Detectron2在这里创建了一个对象检测的初学者教程<a class="ae lu" href="https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="7280" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">参考</h1><p id="055b" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">[1] <a class="ae lu" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank"> Detectron2 Github库</a></p><p id="4214" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[2] <a class="ae lu" href="https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5" rel="noopener ugc nofollow" target="_blank">探测器2教程</a></p><div class="nv nw gp gr nx ny"><a href="https://sciencenotes.medium.com/membership" rel="noopener follow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd iu gy z fp od fr fs oe fu fw is bi translated">加入媒体阅读伟大的教程和故事！</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">我写机器学习、深度学习和数据科学教程。升级阅读更多。</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">sciencenotes.medium.com</p></div></div><div class="oh l"><div class="oi l oj ok ol oh om ks ny"/></div></div></a></div></div></div>    
</body>
</html>