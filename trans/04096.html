<html>
<head>
<title>Natural Language Processing: III</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理:III</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/natural-language-processing-iii-b067c5d0e89c?source=collection_archive---------36-----------------------#2021-04-06">https://towardsdatascience.com/natural-language-processing-iii-b067c5d0e89c?source=collection_archive---------36-----------------------#2021-04-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8f15" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">HMM &amp; LDA的一瞥</h2></div><p id="0d76" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我已经在这个系列的第一部分和第二部分<a class="ae lb" rel="noopener" target="_blank" href="/natural-language-processing-a-beginners-guide-part-ii-54a1bf8c0497">中解释了NLP的基本知识。可能会让你吃惊的一件事是，没有一个文本预处理没有解释单词之间的任何隐藏关系。这个博客会让你对NLP可用的数学工具有所了解。我们来了解一下。</a></p><h2 id="b61c" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated"><strong class="ak">马尔科夫模型:</strong></h2><p id="5742" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">马尔可夫的性质告诉我们</p><blockquote class="ma mb mc"><p id="d8a1" class="kf kg md kh b ki kj jr kk kl km ju kn me kp kq kr mf kt ku kv mg kx ky kz la ij bi translated">在一组事件中，任何事件都依赖于它的前一个事件。</p></blockquote><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/6fad015038573e1651b44fb7233ea41e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tdkP91dTjTdfuSqEIx1QGA.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">版权所有somesh</p></figure><p id="e295" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以上是已经发生的一系列事件。所以根据马尔可夫的属性事件，2将依赖于事件2，事件3将依赖于事件2。这意味着明天天气的概率取决于今天，而今天天气的概率取决于昨天。</p><p id="637a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="md">一些术语:</em> </strong></p><p id="a988" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="md"> 1。有多少个状态被考虑用于概率的计算是状态空间。</em></p><p id="23d6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="md"> 2。遵循马尔可夫性质的事件集合将形成马尔可夫链。</em></p><p id="d178" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="md"> 3。事件发生概率的矩阵称为传递矩阵。</em></p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/0e1b302cc6672495b288c41eab7dbaed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*SAr5luM9TGbv4xsO6W7K7A.png"/></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">版权所有Somesh</p></figure><p id="6833" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="md"> 1。天气热的时候天气会有雾有雾的概率有多大？</em>T19】</strong></p><p id="534a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">状态空间= {多雾，炎热}</p><p id="4deb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">初始概率= {0.7，0.1}</p><p id="05b7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Q = {热，多雾，多雾}</p><p id="9352" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">P(多雾，多雾|热)= P(多雾|热)* P(多雾|多雾)</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi my"><img src="../Images/0f229bbff5b4c054185475669e418d24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*vo9FX7APMCTbwEppQbf9CQ.png"/></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">向右复制一些</p></figure><p id="6b5e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以结果是0.7*0.3=0.21</p><p id="0f7a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Q = {热，多雾，多雾，热，多雾}</p><p id="31c4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以用P(Hot)* P(F | H)* P(F | F)* P(H | F)* P(F | H)来计算</p><p id="7a66" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="md">它仅仅是事件跃迁概率的产物！</em> </strong></p><h2 id="eccb" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated"><strong class="ak">隐马尔可夫模型:一种改进的马尔可夫模型</strong></h2><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mz"><img src="../Images/c1366cdd36b46acc309b9e75883f8b87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lgK4tqXor4GLf-JvmCPAMw.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">版权所有Somesh</p></figure><p id="b78a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="md">隐马尔可夫模型</em> </strong> <em class="md">由一个普通的马科夫链&amp;的一组观察变量组成。</em></p><p id="b309" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上图代表天气和相应的心情。天气是一种隐藏状态，情绪是依赖于隐藏状态的观察变量。简单地说，当天气多云时，心情愉快的概率是0.65，概率是0.75。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi na"><img src="../Images/ce164aa329cbeab77394b5813fe7fb9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*K8et_1n-5c6WVGyUEX_caQ.png"/></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">版权所有Somesh</p></figure><p id="61a1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">隐藏状态的概率矩阵是一个转移矩阵，其中观察变量的概率是一个发射矩阵</p><p id="7152" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下情况发生的概率有多大？</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nb"><img src="../Images/3a123e9988cd22b6dee795e5fd5aaafb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k-MEmCDk_QErNzqXIPBcDQ.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">版权所有Somesh</p></figure><p id="a144" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">用数学术语来说，我们可以把它写成，</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nc"><img src="../Images/da1cba5c67c1030fd88d3f2348ce72a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F0jomPfPy2nfL7zBeeyYiw.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">版权所有Somesh</p></figure><p id="a5c9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这可以使用P(多云)、P(快乐|多云)、P(多雾|多云)、P(悲伤|多雾)、P(多云|多雾)、P(快乐|多云)的乘积来计算</p><p id="dcd7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以从跃迁和发射矩阵中找到除P(多云)以外的所有值。P(多云)的值可以使用马尔可夫链的平稳分布来计算。重复矩阵乘法和归一化左特征向量来计算分布。</p><p id="8fe0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是，与特定的情绪序列相对应的最可能的天气序列是什么呢？</p><p id="0b35" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以用每个节点的概率来计算。那么概率较大的隐藏状态将是答案。从数学上讲，我们可以计算出这个公式。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/a34015e20d51dd1bab18b4e5f471fa89.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*KqdyaYkKv7kYO6hZk8inKw.png"/></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">版权所有Somesh</p></figure><p id="0893" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">利用贝叶斯定理，arg max P(Y|X)*p(X) / P(Y)</p><p id="9c87" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">P(Y |X) = P(Y1 | X1)*P(Y2|X2)……。P(Yn|Xn)</p><p id="30ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">进一步可以写成πP(Yi | Xi)&amp;利用马尔可夫的性质，</p><p id="6119" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">P(X)=πP(Xi | Xi-1)。对于Xo，你可以使用马尔可夫链的平稳分布来计算。所以最终等式会变成—</p><p id="6546" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">arg maxπP(Y<em class="md">I</em>| X<em class="md">I</em>)* P(X<em class="md">I</em>| X<em class="md">I</em>-<em class="md">1</em>)。就这些了嗯！</p><p id="761f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以在生物信息学、自然语言处理、语音识别等领域实现它。</p><h2 id="eb60" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated"><strong class="ak"> <em class="ne"> LDA-潜在狄利克雷分配</em> </strong></h2><p id="5498" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">LDA对于在给定文档中找到相当准确的各种主题非常有用。当你处理主题建模时，这是很方便的。考虑下面的几个例子。</p><blockquote class="ma mb mc"><p id="cb63" class="kf kg md kh b ki kj jr kk kl km ju kn me kp kq kr mf kt ku kv mg kx ky kz la ij bi translated">1.我喜欢蜂蜜和浆果。</p><p id="87c4" class="kf kg md kh b ki kj jr kk kl km ju kn me kp kq kr mf kt ku kv mg kx ky kz la ij bi translated">2.熊也喜欢蜂蜜。</p><p id="4727" class="kf kg md kh b ki kj jr kk kl km ju kn me kp kq kr mf kt ku kv mg kx ky kz la ij bi translated">3.熊和熊猫很可爱。</p></blockquote><p id="9cc9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你理解了上面的句子，你会得到食物和动物的主题，第二句话将是两个句子的组合。在决定主题的时候，你必须明白一些事情。LDA有两个方面:1 .文件中的文字——这是已知的。2.你需要计算才能知道你所学单词的主题。</p><p id="b51d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每个文档都是主题的概率分布，每个主题都是单词的概率分布。换句话说，文档是主题的混合物，主题是单词的混合物。 </p><p id="42b8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">像- is，am，are，has，have等这样的词你必须去掉，因为它们不携带信息。 </p><p id="379b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="md">在你开始找题目之前，你必须决定你想要多少题目。这基本上表示为K. </em> </strong></p><p id="f266" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="md">除了你目前拥有的单词以外的所有题目都可以考虑。</em>T29】</strong></p><p id="8053" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">LDA是如何工作的？</p><ol class=""><li id="f213" class="nf ng iq kh b ki kj kl km ko nh ks ni kw nj la nk nl nm nn bi translated">选择你认为语料库中存在的主题数量。</li></ol><p id="0d9f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2.仔细阅读每个文档中的每个单词及其主题。</p><p id="8a4d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">3.查找该主题在文档中的出现情况，其次是该主题的整体出现情况。在此基础上，指定一个词作为新的主题。</p><p id="a3f7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">4.执行多次迭代，直到获得合适的主题。</p><p id="1009" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">同样，最后一步是您作为人的工作，通过改变文档术语矩阵中的参数、主题数量和迭代次数来解释主题，并在达到目标时停止！</p><p id="c308" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">还有其他的主题建模技术，比如潜在语义索引和负矩阵分解。</p><p id="945c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">希望你能理解，并请在评论区写下你的想法。我会为NLP系列带来更多有趣的话题。在<a class="ae lb" href="https://somesh-routray11.medium.com/" rel="noopener"> <strong class="kh ir">中</strong> </a>关注我，或者订阅我的博客了解他们。一如既往，我欢迎反馈和建设性的批评，可以通过Twitter @ RoutraySomesh&amp;<a class="ae lb" href="http://somesh.routray11@gmail.com" rel="noopener ugc nofollow" target="_blank">Gmail</a>联系</p></div></div>    
</body>
</html>