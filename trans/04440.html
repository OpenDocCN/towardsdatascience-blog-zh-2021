<html>
<head>
<title>Baby’s First Algorithmic Sampling from a Distribution: Methods Available and How to Use Them</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">婴儿的第一次分配算法抽样:可用的方法和如何使用它们</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/babys-first-algorithmic-sampling-from-a-distribution-methods-available-and-how-to-use-them-208678247e62?source=collection_archive---------19-----------------------#2021-04-15">https://towardsdatascience.com/babys-first-algorithmic-sampling-from-a-distribution-methods-available-and-how-to-use-them-208678247e62?source=collection_archive---------19-----------------------#2021-04-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/f875ce879e921f8af3d39ecbe5037518.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yli-cyBYr31BJED3tD2kRg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">Gabriela Morgenshtern拍摄的图片</p></figure><h2 id="2287" class="jd je jf bd b dl jg jh ji jj jk jl dk jm translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="1832" class="pw-subtitle-paragraph kl jo jf bd b km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc dk translated">从复杂分布中取样和近似的缓慢和可接近的介绍</h2></div><h1 id="549e" class="ld le jf bd lf lg lh li lj lk ll lm ln ku lo kv lp kx lq ky lr la ls lb lt lu bi translated">TL；速度三角形定位法(dead reckoning)</h1><p id="f6c7" class="pw-post-body-paragraph lv lw jf lx b ly lz kp ma mb mc ks md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">这篇文章包括了来自<a class="ae mr" href="https://arxiv.org/pdf/2011.00901.pdf" rel="noopener ugc nofollow" target="_blank">最近一篇关于算法抽样的论文</a>的描述，用更简单的术语描述了使用简单或马尔可夫链蒙特卡罗方法进行抽样的动机和方法。它将Metropolis Hastings算法作为在读者实践中实现这种思想的一个例子，并简要地列出了对所涉及的超参数的考虑和启发。</p><h1 id="a87a" class="ld le jf bd lf lg lh li lj lk ll lm ln ku lo kv lp kx lq ky lr la ls lb lt lu bi translated">抽样作为一个概念</h1><p id="430b" class="pw-post-body-paragraph lv lw jf lx b ly lz kp ma mb mc ks md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">这里，我们将来自分布p(x)的样本xᵢ称为概率分布为p(x)的<em class="ms">单个</em>实现。这与统计中的一些其他地方相反，在这些地方，样本x可能指的是实现的集合</p><h1 id="f20b" class="ld le jf bd lf lg lh li lj lk ll lm ln ku lo kv lp kx lq ky lr la ls lb lt lu bi translated">蒙特卡洛</h1><p id="ace3" class="pw-post-body-paragraph lv lw jf lx b ly lz kp ma mb mc ks md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">蒙特卡罗方法有两个目标:(1)从一个给定的分布中产生覆盖该分布的样本；(2)在给定的分布下估计函数的期望。如果我们使用蒙特卡罗方法进行采样(即解决我们的第一个问题)，我们也将能够为我们的第二个问题的解决方案提供一个无偏估计量——良好的覆盖采样将允许我们近似期望表达式中的积分<strong class="lx jp"> x~P(X) </strong>:</p><blockquote class="mt mu mv"><p id="78ec" class="lv lw ms lx b ly mw kp ma mb mx ks md my mz mg mh na nb mk ml nc nd mo mp mq ij bi translated"><strong class="lx jp"><em class="jf">e</em>ₓ=<em class="jf">e[f(x)]=∫f(x)p(x)dx</em></strong></p></blockquote><p id="c1bf" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated">因此，我们应该考虑的基本计算问题是如何最好地获取这些样本。这里，我们讨论一种根据蒙特卡罗和马尔可夫方法获取这些样本的算法方法，以及改进这种马尔可夫链蒙特卡罗方法的计算时间的一些考虑因素:Metropolis Hastings采样算法</p><h1 id="c6e8" class="ld le jf bd lf lg lh li lj lk ll lm ln ku lo kv lp kx lq ky lr la ls lb lt lu bi translated">马尔可夫性质/过程</h1><p id="5c11" class="pw-post-body-paragraph lv lw jf lx b ly lz kp ma mb mc ks md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">一个简短但重要的注意事项是，我们在这里讨论的不是马尔可夫链，它是一种<em class="ms">类型</em>的概率<em class="ms">模型</em>，它融合了马尔可夫过程的思想。马尔可夫过程排序的方法在假设下操作，即在随机变量(RVs)的时间序列中，每个RV独立于所有其他RV，除了紧接在它前面的那个<em class="ms">。</em>这转化为应用于一系列样本的联合概率分布的概率链规则，因此:</p><blockquote class="mt mu mv"><p id="0e3f" class="lv lw ms lx b ly mw kp ma mb mx ks md my mz mg mh na nb mk ml nc nd mo mp mq ij bi translated"><strong class="lx jp"> <em class="jf"> P( X </em> </strong> ₁ <strong class="lx jp"> <em class="jf">，…，x</em></strong>ₙ<strong class="lx jp"><em class="jf">)= p(x</em></strong>₁<strong class="lx jp"><em class="jf">p(x</em></strong>₂<strong class="lx jp"><em class="jf">| x</em></strong>₁<strong class="lx jp">【t21)…p(x</strong>ₙ<strong class="lx jp"><em class="jf">| x</em></strong>ₙ₋₁<strong class="lx jp"/></p></blockquote><h1 id="ee6c" class="ld le jf bd lf lg lh li lj lk ll lm ln ku lo kv lp kx lq ky lr la ls lb lt lu bi translated">蒙特卡罗方法</h1><p id="d8cc" class="pw-post-body-paragraph lv lw jf lx b ly lz kp ma mb mc ks md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">如果我们的数据分布简单(即由我们的一个分布公式很好地定义)，或者如果我们的累积密度函数(CDF)是已知的，那么采样就很容易。如果分布不简单，我们不能直接从中取样。例如，当我们处理基于能量的模型时，就存在这种情况，因为归一化常数需要对输入域中的所有值进行计算开销很大的求和计算。</p><p id="3aa8" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated">蒙特卡罗(MC)方法是探索(良好覆盖的采样)领域空间的迭代方法。这些方法有两个总体分类:<strong class="lx jp">简单</strong>和<strong class="lx jp">马尔可夫链</strong>。</p><h2 id="2047" class="ne le jf bd lf nf ng dn lj nh ni dp ln me nj nk lp mi nl nm lr mm nn no lt jl bi translated">简单抽样</h2><p id="b5f5" class="pw-post-body-paragraph lv lw jf lx b ly lz kp ma mb mc ks md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">这里，每次迭代都是独立的，因为每次迭代都是盲目执行的(不知道先前的采样结果)。简单MC使用简单样本(明确定义的)分布。虽然我们不会在这里详细讨论这些，但简单的MC采样可以进一步细分为:</p><p id="8302" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated"><em class="ms">重要性抽样:</em></p><p id="e2e6" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated">通过简单样本分布，在域上逼近复杂(非简单样本)函数的期望</p><p id="f5e6" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated"><em class="ms">拒绝采样:</em></p><p id="b9ee" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated">来自复杂(非简单到样本)函数的样本通过简单到样本上限分布。也就是说，我们通过取某个明确定义的分布<strong class="lx jp"> Q(x) </strong>来近似我们的复函数，该分布通过乘以某个正整数<strong class="lx jp"> <em class="ms"> c </em> </strong> <em class="ms">，</em>将总是位于我们在笛卡尔轴上感兴趣的分布<strong class="lx jp"> P(x) </strong>之上，并且从来自<strong class="lx jp"> Q(x) </strong>的垂直切片的轴值的均匀分布范围中取样。在此图中可以看到这种方法的示例和伪代码:</p></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><div class="nw nx ny nz gt ab cb"><figure class="oa is ob oc od oe of paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/4f336ce7f6e8fc14172df50154dc7209.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*7EU2g5MqcfGUE1rtqN0AIQ.png"/></div></figure><figure class="oa is og oc od oe of paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/4381d7064989ac3d863ab32ccde68c01.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*qA7C4nnlJV7atrACan9BuQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk oh di oi oj translated">同时计算c图和伪代码的拒绝采样是Ghojogh、Nekoei和Ghojogh等人提出的方法的改进。</p></figure></div><p id="8599" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated">然后，可以通过我们所有样本的平均值<strong class="lx jp"> {x} ∈ <em class="ms"> S </em> </strong>来计算我们对利息预期的无偏估计值(<strong class="lx jp"> E[P(x)] </strong>)。它是无偏的，因为随着样本集的大小接近域的大小，我们接近了兴趣分布期望值的真实值。此外，通过增加<strong class="lx jp"> <em class="ms"> S </em> </strong> <em class="ms"> </em>的基数(即，通过获取更多样本)，我们的估计量的方差将以与<strong class="lx jp"> 1/R </strong>成比例的速率减少。这两个性质的证明，对所有的蒙特卡罗估计器都是通用的，如下所示:</p><div class="nw nx ny nz gt ab cb"><figure class="oa is ok oc od oe of paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/9c496a87da12822a722f99990f9fc98b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/0*7byxs95dwqzESaQM"/></div></figure><figure class="oa is ol oc od oe of paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/01406225c57fc5fc58e54b22616b33c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/0*stKrLUgq1Y1uk5WQ"/></div><p class="iz ja gj gh gi jb jc bd b be z dk om di on oj translated"><a class="ae mr" href="https://probmlcourse.github.io/csc412/lectures/week_6/" rel="noopener ugc nofollow" target="_blank"> <strong class="bd oo"> <em class="op">左:</em> </strong> <em class="op">蒙特卡洛估计量无偏的证明。</em> <strong class="bd oo"> <em class="op">对:</em> </strong> <em class="op">证明蒙特卡洛估计量的方差以1/R的速率递减</em> <strong class="bd oo"> <em class="op">。</em> </strong> <em class="op">这些证明摘自CSC 412 2020年冬季第6周笔记</em> </a></p></figure></div><p id="ae3d" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated">从上面的估计器计算表达式中可以看出，这是一个非常简单的计算，可以包含在训练模型的证据下限(ELBO)函数计算中。而且，当你增加你的训练集的大小，或者用于训练的小批量的数量，你将更加接近你的概率的，难以处理的损失函数的真实期望。</p><h2 id="bec7" class="ne le jf bd lf nf ng dn lj nh ni dp ln me nj nk lp mi nl nm lr mm nn no lt jl bi translated">马尔可夫链抽样</h2><p id="8eae" class="pw-post-body-paragraph lv lw jf lx b ly lz kp ma mb mc ks md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">在马尔可夫链抽样算法中，有一个候选生成分布<strong class="lx jp"> Q </strong>是由实现者做出的选择。在<strong class="lx jp">φᵢ</strong>的候选可能或可能不直接依赖于<strong class="lx jp">φᵢ-₁</strong>，但是将总是以某种方式依赖于前一次迭代，从而允许马尔可夫属性特征(如上所述)。让<strong class="lx jp">φᵢ</strong>直接依赖于<strong class="lx jp">φᵢ-₁</strong>的一个替代方案是保持相同的<strong class="lx jp">q(φ)</strong>分布，具有相同的参数化，然后将依赖依赖与<strong class="lx jp">φᵢ-₁</strong>第一次迭代相关的一些其他属性。然后，<strong class="lx jp">q(φᵢ)</strong>必须与我们的目标分布相似，以确保它是对它的良好近似。</p><p id="073e" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated"><em class="ms"> Metropolis-Hastings采样算法</em></p><p id="3da2" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated">在Metropolis算法中，有一个简单到样本的候选(或建议)分布，取决于前一次迭代的样本值<strong class="lx jp">φᵢ-₁</strong>。我们使用这个候选提议作为从复杂的利益分布中取样的手段，<strong class="lx jp"> P*(X) </strong>。</p><p id="8740" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated">例如，如果我们选择一个候选分布为具有一个常数𝝈但依赖于迭代的𝝁的高斯族，由于这种依赖性引入的对称性，我们简化了𝞪值的计算，如<strong class="lx jp">q(φᵢ-₁|φ*)= q(φ* | φᵢ-₁).</strong>在这种情况下，𝝈的值也被称为<em class="ms">步长</em>，这是一个必须仔细考虑的超参数，因为它影响探索具有足够覆盖的样本空间所花费的时间，从而影响算法的运行时间。对建议函数的这种对称选择定义了<em class="ms"> Metropolis算法。</em>当算法的alpha值计算被推广以接受不一定对称的建议时，就会出现<em class="ms">黑斯廷斯</em>增强。<em class="ms"> Metropolis-Hastings </em>基于<em class="ms"> Metropolis </em>方法，使用重要性抽样的思想:它通过候选分布对新旧样本进行加权。</p><div class="nw nx ny nz gt ab cb"><figure class="oa is oq oc od oe of paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/c627f7488eeca30b5b14793b854df6f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*--dExeQph_LwaLXuY9m_VQ.png"/></div></figure><figure class="oa is or oc od oe of paragraph-image"><img src="../Images/3ea9b7a534a5b44e69ce71fdece14072.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*jkknva2N3kgP0KBicVY0Hw.png"/><p class="iz ja gj gh gi jb jc bd b be z dk os di ot oj translated"><strong class="bd oo">左:</strong>Metropolis算法的伪代码。<strong class="bd oo">右:</strong>黑斯廷斯扩增允许近似的非对称候选分布。改编自Ghojogh，Nekoei，和Ghojogh等人。</p></figure></div><p id="06ec" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated">请注意，在<em class="ms"> Metropolis </em>和<em class="ms">Metropolis-Hastings</em>alpha计算中，<strong class="lx jp"> P*(X) </strong>项同时出现在分子和分母中——这是一种抵消任何不依赖于<strong class="lx jp"> X </strong>但仍然难以处理的归一化因子的聪明方法，例如那些出现在基于能源的模型中的因子。</p><p id="750d" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated"><em class="ms">在大都市的随机漫步(RWM) </em></p><p id="173a" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated">在RWM，比如大都会黑斯廷斯，我们有当前候选样本对先前迭代的依赖性。通常在RWM中，候选<strong class="lx jp">φᵢ</strong>可能或可能不直接依赖于<strong class="lx jp">φᵢ-₁</strong>，但总是以某种方式依赖于前一次迭代，从而利用了马尔可夫性质。当使用这个算法系列时，我们有两个重要的选择:候选分布和步长。步长将直接影响我们接受样本的速率:太高的速率(太小的步长)将导致非常慢的域探索；过低的速率(过大的步长)将导致域的不完全覆盖。<a class="ae mr" href="http://probability.ca/jeff/ftpdir/lawlessart.pdf" rel="noopener ugc nofollow" target="_blank">有一篇论文</a>提出，在大多数情况下，为大都市实施设置的合适步长是𝝈 = 2.38。<a class="ae mr" href="https://www.youtube.com/watch?v=0lpT-yveuIA" rel="noopener ugc nofollow" target="_blank">对于适当的接受率，一个建议的启发式方法</a>是23–50%的样本，并且在任何情况下，候选分布应该具有比<br/> <strong class="lx jp"> P*(X) </strong>(用于近似的感兴趣的分布)更高的方差。</p><h1 id="bc08" class="ld le jf bd lf lg lh li lj lk ll lm ln ku lo kv lp kx lq ky lr la ls lb lt lu bi translated">来源</h1><p id="fb9a" class="pw-post-body-paragraph lv lw jf lx b ly lz kp ma mb mc ks md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">1.Ghojogh，Nekoei，Ghojogh，et。艾尔。<em class="ms"> </em>抽样算法，从调查抽样到蒙特卡罗方法:教程和文献综述。2020年11月:<a class="ae mr" href="https://arxiv.org/pdf/2011.00901.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2011.00901.pdf</a></p><p id="db62" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated">2.乔治。多伦多大学，CSC412年冬季讲座5:<a class="ae mr" href="https://probmlcourse.github.io/csc412/lectures/week_6/" rel="noopener ugc nofollow" target="_blank">https://probmlcourse.github.io/csc412/lectures/week_6/</a></p><p id="3eef" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated">3.乔治。多伦多大学CSC 412 2020年冬季讲座7:<a class="ae mr" href="https://probmlcourse.github.io/csc412/lectures/week_10/#optimizing-the-elbo" rel="noopener ugc nofollow" target="_blank">https://probml course . github . io/CSC 412/lections/week _ 10/# optimizing-the-elbo</a></p><p id="1c55" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated">4.理解Metropolis-Hastings算法。机器学习电视(加州大学圣克鲁斯分校)。2020年2月:<a class="ae mr" href="https://www.youtube.com/watch?v=0lpT-yveuIA" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=0lpT-yveuIA</a></p><p id="111a" class="pw-post-body-paragraph lv lw jf lx b ly mw kp ma mb mx ks md me mz mg mh mi nb mk ml mm nd mo mp mq ij bi translated">5.罗森塔尔。优化和调整Metropolis算法。2013年2月:【http://probability.ca/jeff/ftpdir/lawlessart.pdf T21】</p></div></div>    
</body>
</html>