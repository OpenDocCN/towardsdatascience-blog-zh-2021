<html>
<head>
<title>Encoding Data with Transformers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用转换器编码数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/encoding-data-with-transformers-d14445e96ead?source=collection_archive---------11-----------------------#2021-12-02">https://towardsdatascience.com/encoding-data-with-transformers-d14445e96ead?source=collection_archive---------11-----------------------#2021-12-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="e6ab" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">相关事件</h2><div class=""/><div class=""><h2 id="6cc0" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">如何使用基于转换器的技术来执行数据编码</h2></div><p id="a92f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">数据编码是人工智能领域最新的技术进步之一。通过使用编码器模型，我们可以将分类数据转换为数字数据，这使我们能够进行比较，了解数据之间的关系，提出建议，改进搜索…</p><p id="abff" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这篇文章中，我将解释如何通过使用安装在<a class="ae lk" href="https://relevance.ai/" rel="noopener ugc nofollow" target="_blank"> RelevanceAI </a>库中的一个模型，将一组文章(文本数据)转换成向量(数字数据)。</p><p id="9e50" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果您希望使用API，可以遵循一个快速入门指南，使用基于向量的技术对数据集执行第一次语义搜索。</p><h2 id="4d61" class="ll lm iq bd ln lo lp dn lq lr ls dp lt kx lu lv lw lb lx ly lz lf ma mb mc iw bi translated">什么是编码</h2><p id="4698" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">编码意味着我们将分类数据转换成数字数据。有非常基本的编码类型，例如，one_hot编码或基于索引的编码。然而，当我们处理文本数据时，最高级的编码形式可以使用嵌入来完成。</p><p id="a0a4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">嵌入能够扫描单词集，并将每个单词放入多维空间，本质上是将每个单词转换成一个向量。一旦模型被训练，语料库中的每个单词都被适当地放置到具有相似含义的单词附近的数学空间中。</p><p id="8b1a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">您可以使用<a class="ae lk" href="https://projector.tensorflow.org/" rel="noopener ugc nofollow" target="_blank">谷歌的嵌入投影仪</a>来体验嵌入的乐趣:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mi"><img src="../Images/a6fa3e56cada4db480cd7f1ad730557a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AVSHDDxqjKJ0xkb5Tvi2Xw.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">Tensorflow嵌入式投影仪，检索自:【https://projector.tensorflow.org/ T4】</p></figure><p id="959e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这项技术对现在搜索的工作方式产生了巨大的影响，在搜索引擎、推荐系统和计算机视觉中找到了大多数应用。</p><h2 id="25de" class="ll lm iq bd ln lo lp dn lq lr ls dp lt kx lu lv lw lb lx ly lz lf ma mb mc iw bi translated">有多少编码器？</h2><p id="fb8c" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">直到几年前，最流行的文本编码器是word2vec。由于有几种模型，你可以将每个单词转换成空间中相应的向量。然而，这被称为静态嵌入，这意味着向量永远不会改变:该模型是一个字一个字地编码，而忽略了句子的上下文:我们可以做得更好！</p><p id="e457" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这个问题的答案现在以变形金刚模型的形式出现了。这些编码器使用<a class="ae lk" href="https://www.youtube.com/watch?v=2uQ6bgemuLw&amp;t=87s" rel="noopener ugc nofollow" target="_blank">动态嵌入</a>:根据周围的单词，每个单词可以有不同的向量。</p><p id="f1cf" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">可以想象，这比使用静态嵌入要精确得多:RelevanceAI致力于使用同样的技术。</p><h2 id="b5a5" class="ll lm iq bd ln lo lp dn lq lr ls dp lt kx lu lv lw lb lx ly lz lf ma mb mc iw bi translated">用几行代码编码数据</h2><p id="20a3" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">要对文本数据进行编码，您唯一需要做的就是下载vectorhub库，该库托管相关的编码器:</p><pre class="mj mk ml mm gt my mz na nb aw nc bi"><span id="3b1b" class="ll lm iq mz b gy nd ne l nf ng">#encode on local<br/>from vectorhub.encoders.text.sentence_transformers import SentenceTransformer2Vec<br/>model = SentenceTransformer2Vec("bert-base-uncased")</span><span id="1eba" class="ll lm iq mz b gy nh ne l nf ng">df_json = model.encode_documents(documents=df_json, fields=['raw'])<br/>df_json</span></pre><h1 id="0a87" class="ni lm iq bd ln nj nk nl lq nm nn no lt kf np kg lw ki nq kj lz kl nr km mc ns bi translated">编码大数据</h1><p id="2330" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">因为尝试使用更大的数据集总是有用的，所以您可以通过relevance API使用我们的数据集。让我们尝试编码一个数据集，我们将在后面的文章中使用它来上传到您的相关工作空间，并尝试几种方法:</p><h2 id="3a2e" class="ll lm iq bd ln lo lp dn lq lr ls dp lt kx lu lv lw lb lx ly lz lf ma mb mc iw bi translated">1.安装relevanceai和vectorhub</h2><p id="ea7a" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">第一步是在你的笔记本上安装relevanceai。安装非常简单，因为它使用pip。</p><pre class="mj mk ml mm gt my mz na nb aw nc bi"><span id="122f" class="ll lm iq mz b gy nd ne l nf ng">!pip install vectorhub[encoders-text-sentence-transformers]<br/>!pip install -U relevanceai</span><span id="cd79" class="ll lm iq mz b gy nh ne l nf ng">import relevanceai<br/>print(relevanceai.__version__)<br/>#restart notebook if you are updating the API rather than just installing it for the first time</span><span id="e38d" class="ll lm iq mz b gy nh ne l nf ng">Output:<br/>0.12.17</span></pre><h2 id="b68a" class="ll lm iq bd ln lo lp dn lq lr ls dp lt kx lu lv lw lb lx ly lz lf ma mb mc iw bi translated">2.加载数据集</h2><p id="f077" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">RelevanceAI允许您下载几个可能的样本数据集。在这种情况下，我将使用约有20.000个样本的<strong class="kq ja"> flipkart数据集</strong>。要下载它，只需使用以下代码:</p><pre class="mj mk ml mm gt my mz na nb aw nc bi"><span id="e110" class="ll lm iq mz b gy nd ne l nf ng">from relevanceai import datasets</span><span id="8507" class="ll lm iq mz b gy nh ne l nf ng">json_files = datasets.get_flipkart_dataset()<br/>json_files</span></pre><h2 id="02cf" class="ll lm iq bd ln lo lp dn lq lr ls dp lt kx lu lv lw lb lx ly lz lf ma mb mc iw bi translated">3.数据集架构</h2><p id="2238" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">上传过程结束后，现在让我们检查数据集的模式:我们可以看到它的所有字段。到目前为止，还没有任何字段被编码。</p><pre class="mj mk ml mm gt my mz na nb aw nc bi"><span id="8a64" class="ll lm iq mz b gy nd ne l nf ng">{'_id': 0,<br/>  'product_name': "Alisha Solid Women's Cycling Shorts",<br/>  'description': "Key Features of Alisha Solid...",<br/>  'retail_price': 999.0},<br/> {'_id': 1,<br/>  'product_name': 'FabHomeDecor Fabric Double Sofa Bed',<br/>  'description': "FabHomeDecor Fabric Double ...",<br/>  'retail_price': 32157.0},<br/> {'_id': 2,<br/>  'product_name': 'AW Bellies',<br/>  'description': 'Key Features of AW Bellies Sandals...',<br/>  'retail_price': 999.0},<br/> {'_id': 3,<br/>  'product_name': "Alisha Solid Women's Cycling Shorts",<br/>  'description': "Key Features of Alisha Solid Women's Cycling...",<br/>  'retail_price': 699.0},</span></pre><h2 id="57b9" class="ll lm iq bd ln lo lp dn lq lr ls dp lt kx lu lv lw lb lx ly lz lf ma mb mc iw bi translated">4.执行编码</h2><p id="01ee" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">要开始在本地执行文本数据的编码，您可以通过vectorhub库轻松访问我们的一些transformers模型。执行编码非常简单，您只需要传入指定您希望编码的字段的<strong class="kq ja"> json_files </strong>数据:</p><pre class="mj mk ml mm gt my mz na nb aw nc bi"><span id="b597" class="ll lm iq mz b gy nd ne l nf ng">#encode on local<br/>from vectorhub.encoders.text.sentence_transformers import SentenceTransformer2Vec<br/>model = SentenceTransformer2Vec("bert-base-uncased")</span><span id="5eee" class="ll lm iq mz b gy nh ne l nf ng">df_json = model.encode_documents(documents=json_files[0:1000], fields=['product_name'])<br/>df_json</span></pre><p id="2ea8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我将只编码前1000个样本，否则，编码器可能会运行一段时间。大约一分钟后，输出如下:如您所见，字典中添加了一个包含向量的新字段。</p><pre class="mj mk ml mm gt my mz na nb aw nc bi"><span id="a008" class="ll lm iq mz b gy nd ne l nf ng">Output:<br/>[{'_id': 0,<br/>  'product_name': "Alisha Solid Women's Cycling Shorts",<br/>  'description': "Key Features of Alisha Solid Women's...",<br/>  'retail_price': 999.0,<br/>  'product_name_sentence_transformers_vector_': [0.29085323214530945,<br/>   -0.12144982814788818,<br/>   -0.33044129610061646,<br/>   0.07810567319393158,<br/>   0.3813101351261139,<br/>   -0.13027772307395935,</span></pre><h2 id="a34a" class="ll lm iq bd ln lo lp dn lq lr ls dp lt kx lu lv lw lb lx ly lz lf ma mb mc iw bi translated">5.为可视化准备数据</h2><p id="9d14" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">因为您还没有将数据集上传到relevanceAI中(我们将在下一篇文章中向您展示如何做到这一点)，所以您必须手动可视化您的数据。下面是一个示例代码，您可以使用它将输出字典转换成pandas数据帧。</p><pre class="mj mk ml mm gt my mz na nb aw nc bi"><span id="df00" class="ll lm iq mz b gy nd ne l nf ng">import numpy as np<br/>import pandas as pd</span><span id="13e6" class="ll lm iq mz b gy nh ne l nf ng">df = pd.DataFrame(df_json)<br/>df_vectors = pd.DataFrame(np.column_stack(list(zip(*df[['product_name_sentence_transformers_vector_']].values))))<br/>df_vectors.index = df['product_name']<br/>df_vectors</span></pre><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nt"><img src="../Images/458ae9bf22e924c9026220aef842703b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yDft0zkTtBxfY2EC4YtTJg.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">转换成熊猫数据帧的结果，图片由作者提供</p></figure><h2 id="5f5b" class="ll lm iq bd ln lo lp dn lq lr ls dp lt kx lu lv lw lb lx ly lz lf ma mb mc iw bi translated">6.可视化数据</h2><p id="9efb" class="pw-post-body-paragraph ko kp iq kq b kr md ka kt ku me kd kw kx mf kz la lb mg ld le lf mh lh li lj ij bi translated">因为数据由768列组成，为了可视化，您需要压缩它。您可以使用主成分分析轻松可视化您的数据。要知道，有很多更先进的技术来获得相同的结果，但这将足以快速浏览数据。</p><pre class="mj mk ml mm gt my mz na nb aw nc bi"><span id="e4e8" class="ll lm iq mz b gy nd ne l nf ng">from sklearn.decomposition import PCA<br/>import matplotlib.pyplot as plt</span><span id="99fc" class="ll lm iq mz b gy nh ne l nf ng">pca = PCA(n_components=2, svd_solver='auto')<br/>pca_result = pca.fit_transform(df_vectors.values)<br/>#display(df)</span><span id="9cd8" class="ll lm iq mz b gy nh ne l nf ng">fig = plt.figure(figsize=(14, 8))<br/>x = list(pca_result[:,0])<br/>y = list(pca_result[:,1])<br/># x and y given as array_like objects<br/>import plotly.express as px<br/>fig = px.scatter(df, x=x, y=y, hover_name=df_vectors.index)<br/>fig.update_traces(textfont_size=10)<br/>fig.show()</span></pre><p id="e17c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">精彩！所有这1000个样本都被放置在太空中，现在我们可以看到它们了。</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nu"><img src="../Images/2b23fa0ac2d7646d50133cf0eba61196.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B8npOoHxfiYl3SO1-6x-Sw.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">1000个产品的数据压缩，图片由作者提供</p></figure><p id="d323" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">通过放大数据，我们可以了解每个产品与另一个产品的关系:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nv"><img src="../Images/cf7da3ba56ed2c77876d4c5762d54a7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kV0jzl918Z1jSc4WlzhHIg.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">放大数据压缩，按作者显示文本和图像</p></figure></div></div>    
</body>
</html>