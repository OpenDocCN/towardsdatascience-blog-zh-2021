<html>
<head>
<title>Estimating Uncertainty with CatBoost Classifiers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用CatBoost分类器估计不确定性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/estimating-uncertainty-with-catboost-classifiers-2d0b2229ad6?source=collection_archive---------27-----------------------#2021-06-15">https://towardsdatascience.com/estimating-uncertainty-with-catboost-classifiers-2d0b2229ad6?source=collection_archive---------27-----------------------#2021-06-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8e58" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">如何利用模型集检测未知的网络入侵</em></h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/54a9be1671a70060d80fad79ea14c119.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-3KG8RV2kevlMTE2lut4FA.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">数据不确定性示例(图片由Yandex提供)</p></figure><p id="5827" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是我们关于梯度推进决策树模型(GBDT)中不确定性估计的教程的第二部分。<a class="ae ls" rel="noopener" target="_blank" href="/tutorial-uncertainty-estimation-with-catboost-255805ff217e">第一部分</a>讨论回归问题中的不确定性估计。在这篇文章中，我们将展示如何解决分类问题，以及不确定性在实际任务中的应用。包含这篇文章中描述的实验的GitHub知识库可以在<a class="ae ls" href="https://github.com/yandex-research/GBDT-uncertainty" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h2 id="aeab" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated"><strong class="ak">为什么不确定？</strong></h2><p id="8b02" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">在机器学习的高风险应用中，重要的是检测系统何时不确定并且可能出错。这些应用包括医疗诊断、金融预测等等。数据通常以表格形式表示，具有不同性质和规模的特征。对于这样的数据，最好的结果通常是用GBDT模型实现的，例如CatBoost。</p><p id="b2b3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">回想一下，不确定性有两个主要来源:数据和知识。数据的不确定性是由于数据中的噪声(目标值的高方差或重叠类别)而产生的。当模型被给予远离训练数据的输入时，知识不确定性出现。由于模型对这个地区知之甚少，它可能会出错。因此，知识不确定性可用于检测异常实例。</p><h2 id="be9f" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated"><strong class="ak"> KDD入侵检测</strong></h2><p id="f2b7" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">我们将通过一个实例演示如何使用CatBoost进行异常检测。为此，我们考虑<a class="ae ls" href="http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html" rel="noopener ugc nofollow" target="_blank"> KDD-99入侵检测数据集</a>。任务是检测网络入侵，以保护计算机网络免受未经授权的用户。模型被训练为将网络活动分类为正常或几种入侵类型之一。至关重要的是，测试集包含了几种在训练集中没有观察到的攻击类型——这与真实的实际场景非常吻合。对于ML系统来说，能够检测异常行为是很重要的——用户行为会随着时间的推移而漂移，恶意黑客总是试图找到攻击系统的新方法。</p><p id="f792" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，我们的目标是:</p><ul class=""><li id="4b6d" class="mr ms iq ky b kz la lc ld lf mt lj mu ln mv lr mw mx my mz bi translated">区分正常和恶意的网络活动</li><li id="3075" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">将恶意网络活动分为已知的攻击类型</li><li id="4279" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">检测以前未发现的攻击</li></ul><h2 id="e57a" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated">数据集和预处理描述</h2><p id="5d72" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">对于这个实验，我们按照[3]中的描述对数据进行预处理。我们将原始测试数据分成两个子集:一个称为“域内测试”的子集包含训练数据中存在的攻击类型，另一个称为“域外测试”的子集仅包含未知的攻击类型。然后，任务是基于不确定性的度量来分类输入样本是属于域内还是域外测试集。我们在训练数据上训练10个SGLB catboost模型的集合。在<a class="ae ls" href="https://github.com/yandex-research/GBDT-uncertainty" rel="noopener ugc nofollow" target="_blank"> <em class="nf"> GitHub </em> </a>上有一个完全重新创建这个设置的脚本。</p><h2 id="6579" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated">分类的不确定性估计</h2><p id="3de7" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">给定SGLB分类模型的集合，可以如下计算不确定性。每个模型产生已知类别的分布。我们可以通过将所有模型的预测分布平均在一起来组合所有模型，以获得<em class="nf">预测后验</em>:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ng"><img src="../Images/84c0870b63763b1a2fd81ee6db9e4d03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bLEcXvUmlVkLz6iipSSS2w.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated"><em class="kf">作者图片</em></p></figure><p id="c2e3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">预测后验的<em class="nf">熵</em>是<em class="nf">总不确定性的集合。总不确定度</em>是上述<em class="nf">数据</em>和<em class="nf">知识不确定度</em>的总和(详见【1，2】)。我们可以通过考虑<em class="nf">集合多样性</em>的度量，例如互信息，将总不确定性分离成其组成部分，这产生了<em class="nf">知识不确定性</em>的估计:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nh"><img src="../Images/c8b71c76ce60dcf85b43422910e49b12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*viRhLylB4rxlfF2bdguJag.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated"><em class="kf">作者图片</em></p></figure><p id="7652" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为什么<em class="nf">集合多样性</em>度量<em class="nf">知识不确定性</em>？我们假设模型集合将对熟悉的数据产生非常相似、几乎相同的预测，并且随着输入距离训练数据越来越远，将产生越来越多样化的预测。我们可以考虑多样性的其他度量方法，这些方法都会产生对知识不确定性的估计，但这超出了本文的范围。</p><h2 id="c3a5" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated">结果</h2><p id="80d0" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">现在让我们看看我们在KDD入侵检测数据集上获得了什么。首先，我们在<a class="ae ls" href="https://catboost.ai/docs/concepts/loss-functions-multiclassification.html" rel="noopener ugc nofollow" target="_blank">多类</a>机制中训练单个SGLB CatBoost模型。预测网络活动类型的误差率为4%。然后，我们评估我们检测异常(未知)攻击类型的能力。为此，我们用预测的熵来衡量不确定性。我们通过ROC曲线下的面积来评估质量[2]。获得的ROC-AUC为92.8。</p><p id="547f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们通过使用SGLB CatBoost模型的集成来改进结果[1]。为此，我们训练了10个独立的SGLB模型(用不同的种子)。首先，我们观察到平均集合预测将错误率提高到3.6%。然后，我们比较两种不确定性度量:<em class="nf">总不确定性，</em>作为预测后验熵(平均预测)度量，<em class="nf">知识不确定性，</em>作为互信息度量。正如预期的那样，使用达到94.2 ROC-AUC值的<em class="nf">知识不确定性</em>获得了最好的结果。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ni"><img src="../Images/e5eefc5033bca7100f16a11f154054e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ECBHtB6wcoEbH8PTPjC_wQ.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">10个SGLB CatBoost模型的Ensembe结果</p></figure><h2 id="4d33" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated">带回家</h2><p id="1908" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">这个小实验表明，我们可以使用梯度增强模型的集合来实现两个目标:</p><ul class=""><li id="f119" class="mr ms iq ky b kz la lc ld lf mt lj mu ln mv lr mw mx my mz bi translated">即使在不平衡的数据集中，也能提高分类精度</li><li id="767c" class="mr ms iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">改进域外/异常输入检测</li></ul><p id="b0e3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这证明了使用GBDT模型集合的好处。</p><p id="b644" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[1] A. Malinin，L. Prokhorenkova和A. Ustimenko，<a class="ae ls" href="https://arxiv.org/pdf/2006.10562.pdf" rel="noopener ugc nofollow" target="_blank">ICLR 2021会议论文集</a>中通过系综提高梯度的不确定性。</p><p id="eda2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2]一种马林宁。<a class="ae ls" href="https://www.repository.cam.ac.uk/bitstream/handle/1810/298857/PhD_Thesis-61.pdf?sequence=1" rel="noopener ugc nofollow" target="_blank">深度学习中的不确定性估计及其在口语评估中的应用</a>。博士论文，2019。</p><p id="6377" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3] Divekar等人，<a class="ae ls" href="https://arxiv.org/pdf/1811.05372.pdf" rel="noopener ugc nofollow" target="_blank">基于异常的网络入侵检测基准数据集:KDD杯99备选方案</a>ICCCS 2018论文集。</p></div></div>    
</body>
</html>