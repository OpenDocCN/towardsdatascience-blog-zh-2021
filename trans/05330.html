<html>
<head>
<title>NER With Transformers And spaCy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NER与变形金刚和太空</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ner-with-transformers-and-spacy-b3240bc65eb4?source=collection_archive---------9-----------------------#2021-05-11">https://towardsdatascience.com/ner-with-transformers-and-spacy-b3240bc65eb4?source=collection_archive---------9-----------------------#2021-05-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="29bb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用roBERTa提取过强的实体</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/db1c07c069a523366bee41cc0319f3ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ml4nzmLFh8mzzQAQYVszJA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="f9dd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated"><span class="l lv lw lx bm ly lz ma mb mc di"> N </span>命名实体识别(NER)包括从文本中提取“实体”——我们的意思在句子中给出了:</p><blockquote class="md"><p id="134a" class="me mf it bd mg mh mi mj mk ml mm lt dk translated">"今年1月，苹果公司的股价达到了143美元的历史新高。"</p></blockquote><p id="59df" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">我们可能想要提取关键的信息片段——或“实体”——并对这些实体进行分类。像这样:</p><p id="b454" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">苹果—组织</strong></p><p id="0c55" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> 143美元——货币价值</strong></p><p id="15c1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">今年1月—日期</strong></p><p id="0e53" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于我们人类来说，这很容易。但是，我们如何教会一台机器区分一个史密斯奶奶苹果和我们在纳斯达克交易的苹果呢？</p><p id="9114" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="ms">(不，我们不能指望‘A’大写……)</em></p><p id="5f75" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就是NER的用武之地——使用NER，我们可以提取像苹果这样的关键词，并确定它实际上是一个<em class="ms">组织</em>——而不是一种水果。</p><p id="9c7c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Python中NER的首选是spaCy库——这真的很神奇。例如，我在编写任何代码之前编写了上面的NER示例，spaCy完美地匹配了该示例:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/dfe6ecd4c0bc7355ef8edae269a9f75e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZmLNeogrESb6RrEMkIJ3bQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">变压器NER模型的输出。</p></figure><p id="6a9b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">很酷的东西…但是，这只是香草空间——如果我们加入变形金刚会怎么样？</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="8da0" class="nb nc it bd nd ne nf ng nh ni nj nk nl jz nm ka nn kc no kd np kf nq kg nr ns bi translated">空间变压器</h1><p id="b60c" class="pw-post-body-paragraph ky kz it la b lb nt ju ld le nu jx lg lh nv lj lk ll nw ln lo lp nx lr ls lt im bi translated">变形金刚是自NLP中的面包片以来最热门的东西。自2017-18年推出以来，它们已经主导了NLP基准，成为事实上的语言标准(抱歉，LSTM)。</p><p id="f026" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">SpaCy在2019年推出了<code class="fe ny nz oa ob b">spacy-transformers</code>库[1]。它将spaCy连接到HuggingFace的变形金刚库——允许我们像往常一样使用NER——但由尖端的变形金刚模型驱动。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">NER与变形金刚和空间的视频漫游。</p></figure><h2 id="c8e0" class="oe nc it bd nd of og dn nh oh oi dp nl lh oj ok nn ll ol om np lp on oo nr op bi translated">装置</h2><p id="6003" class="pw-post-body-paragraph ky kz it la b lb nt ju ld le nu jx lg lh nv lj lk ll nw ln lo lp nx lr ls lt im bi translated">我们首先安装<code class="fe ny nz oa ob b">spacy-transformers</code>,使用:</p><pre class="kj kk kl km gt oq ob or os aw ot bi"><span id="f88c" class="oe nc it ob b gy ou ov l ow ox">pip install spacy[transformers]</span></pre><p id="25b2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你使用CUDA，用<code class="fe ny nz oa ob b">nvcc --version</code>检查你的版本，把CUDA版本添加到安装中——我有CUDA 11.1，所以我的安装命令是:</p><pre class="kj kk kl km gt oq ob or os aw ot bi"><span id="2750" class="oe nc it ob b gy ou ov l ow ox">pip install spacy[transformers,cuda111]</span></pre><h2 id="0bcd" class="oe nc it bd nd of og dn nh oh oi dp nl lh oj ok nn ll ol om np lp on oo nr op bi translated">初始化空间转换器</h2><p id="ac7f" class="pw-post-body-paragraph ky kz it la b lb nt ju ld le nu jx lg lh nv lj lk ll nw ln lo lp nx lr ls lt im bi translated">现在我们已经安装了<code class="fe ny nz oa ob b">spacy-transformers</code>，我们可以像通常使用spaCy模型一样开始使用transformer模型。</p><p id="7aae" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里唯一的例外是我们下载并初始化一个spaCy transformer模型——而不是通常的模型。</p><p id="0a9a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们下载了<a class="ae oy" href="https://spacy.io/models/en#en_core_web_trf" rel="noopener ugc nofollow" target="_blank"> roBERTa-base模型</a>,其中包含:</p><pre class="kj kk kl km gt oq ob or os aw ot bi"><span id="2ebf" class="oe nc it ob b gy ou ov l ow ox">python -m spacy download en_core_web_trf</span></pre><p id="f9a8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后用Python初始化它:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz od l"/></div></figure><p id="31d2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于以前使用过spaCy的人来说，这应该看起来很熟悉。</p><h2 id="da47" class="oe nc it bd nd of og dn nh oh oi dp nl lh oj ok nn ll ol om np lp on oo nr op bi translated">NER</h2><p id="e126" class="pw-post-body-paragraph ky kz it la b lb nt ju ld le nu jx lg lh nv lj lk ll nw ln lo lp nx lr ls lt im bi translated">我们现在准备用我们的transformer模型处理一些文本，并开始提取实体。同样，这里与通常的空间语法没有区别:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz od l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/dfe6ecd4c0bc7355ef8edae269a9f75e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZmLNeogrESb6RrEMkIJ3bQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">变压器NER模型的输出。</p></figure><h2 id="7aeb" class="oe nc it bd nd of og dn nh oh oi dp nl lh oj ok nn ll ol om np lp on oo nr op bi translated">变形金刚v传统空间</h2><p id="2b24" class="pw-post-body-paragraph ky kz it la b lb nt ju ld le nu jx lg lh nv lj lk ll nw ln lo lp nx lr ls lt im bi translated">很好，但是与传统的空间模型相比，这种模型表现如何？我们将使用<code class="fe ny nz oa ob b">en_core_web_lg</code>模型，并比较来自<a class="ae oy" href="https://www.reddit.com/r/investing/" rel="noopener ugc nofollow" target="_blank"><em class="ms">r/投资</em> </a>子编辑的一些帖子。</p><div class="kj kk kl km gt ab cb"><figure class="pa kn pb pc pd pe pf paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/dff79bd0dac9070529e05b0f57ba054a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*AHbhWqBbN9ec9vo_HQZkOw.png"/></div></figure><figure class="pa kn pg pc pd pe pf paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/cdf8c91b1f6bbebea92a75dbc1d48ddb.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*iCVVKiH7ioQfkizFEO0E8g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk ph di pi pj translated">传统<strong class="bd pk"> en_core_web_lg </strong>型号(左)，变形金刚<strong class="bd pk"> en_core_web_trf </strong>型号(右)。</p></figure></div><p id="0c34" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这里，我们可以看到这两个模型之间没有任何差异——我们应该期待有相当数量的样本，因为传统模型<code class="fe ny nz oa ob b">en_core_web_lg</code>仍然是一个非常高性能的模型。</p><p id="9cd3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是，让我们从<a class="ae oy" href="https://www.reddit.com/r/investing/comments/n6uka6/fastly_drops_27_after_release_of_q121_results/" rel="noopener ugc nofollow" target="_blank">这里</a>尝试一个稍微长一点、更复杂的例子:</p><pre class="kj kk kl km gt oq ob or os aw ot bi"><span id="69d6" class="oe nc it ob b gy ou ov l ow ox">Fastly released its Q1-21 performance on Thursday, after which the stock price dropped a whopping 27%. The company generated revenues of $84.9 million (35% YoY) vs. $85.1 million market consensus. Net loss per share was $0.12 vs. an expected $0.11.</span><span id="6933" class="oe nc it ob b gy pl ov l ow ox">These are not big misses but make the company one of the few high-growth cloud players that underperformed market expectations.</span><span id="cd2d" class="oe nc it ob b gy pl ov l ow ox">However, the company also lowered its guidance for Q2: Fastly forecasts revenues of $84 - $87 million and a net loss of $0.16 - $0.19 per share, compared to the market consensus of $92 million in revenue and a net loss of $0.08 per share, thereby disappointing investors.</span><span id="9456" class="oe nc it ob b gy pl ov l ow ox">Lastly, Adriel Lares will step down as CFO of the company after 5 years.</span></pre><div class="kj kk kl km gt ab cb"><figure class="pa kn pm pc pd pe pf paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/96e28f50191914b899dadd31e457ff28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*fKT3pnE-kUb_3r7o0DCGdQ.png"/></div></figure><figure class="pa kn pn pc pd pe pf paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/509c556282e576f0651207a04e539db1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*Peci7h6a44256JLjPSgegQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk ph di pi pj translated">传统<strong class="bd pk"> en_core_web_lg </strong>型号(左)，变形金刚<strong class="bd pk"> en_core_web_trf </strong>型号(右)。</p></figure></div><p id="717a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们看到了不同之处:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz od l"/></div></figure><p id="f974" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">除了在百分比标签中包含<em class="ms">“巨大的”</em>——transformer模型明显优于传统模型。</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><p id="f79a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">关于在空间中使用转换器<em class="ms">进行命名实体识别的文章到此结束！你可以在这里找到完整的笔记本<a class="ae oy" href="https://github.com/jamescalam/transformers/blob/main/course/named_entity_recognition/04_spacy_and_transformers.ipynb" rel="noopener ugc nofollow" target="_blank"/>。</em></p><p id="6b80" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我希望你喜欢这篇文章！如果你有任何问题，请通过<a class="ae oy" href="https://twitter.com/jamescalam" rel="noopener ugc nofollow" target="_blank"> Twitter </a>或在下面的评论中告诉我。如果你想要更多这样的内容，我也会在YouTube上发布。</p><p id="eeba" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢阅读！</p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><h1 id="d7b4" class="nb nc it bd nd ne nf ng nh ni nj nk nl jz nm ka nn kc no kd np kf nq kg nr ns bi translated">参考</h1><p id="87d5" class="pw-post-body-paragraph ky kz it la b lb nt ju ld le nu jx lg lh nv lj lk ll nw ln lo lp nx lr ls lt im bi translated">[1] M. Honnibal &amp; I. Montani，<a class="ae oy" href="https://explosion.ai/blog/spacy-transformers" rel="noopener ugc nofollow" target="_blank"> spaCy遇上变形金刚:微调伯特、XLNet和GPT-2 </a> (2019)，爆炸AI</p><p id="66cb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae oy" href="https://bit.ly/nlp-transformers" rel="noopener ugc nofollow" target="_blank">🤖带变压器的NLP课程</a></p></div><div class="ab cl mu mv hx mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="im in io ip iq"><p id="fcc8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您有兴趣了解更多关于使用NER空间库的信息，我会在这里做更深入的介绍:</p><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/ner-for-extracting-stock-mentions-on-reddit-aa604e577be"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd iu gy z fp pw fr fs px fu fw is bi translated">NER在Reddit上提取股票提及</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">如何使用命名实体识别进行有意义的分类</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qb l qc qd qe qa qf ks pr"/></div></div></a></div><p id="a71e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="ms">*所有图片均由作者提供，除非另有说明</em></p></div></div>    
</body>
</html>