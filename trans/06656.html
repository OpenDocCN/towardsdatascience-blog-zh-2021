<html>
<head>
<title>Moving from Pandas to Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从熊猫到星火</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/moving-from-pandas-to-spark-7b0b7d956adb?source=collection_archive---------13-----------------------#2021-06-15">https://towardsdatascience.com/moving-from-pandas-to-spark-7b0b7d956adb?source=collection_archive---------13-----------------------#2021-06-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4063" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">当您的数据集开始变大时，迁移到Spark可以提高速度并节省时间。</h2></div><p id="8adf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">大多数数据科学工作流都是从熊猫开始的。Pandas是一个很棒的库，可以让你做各种各样的转换，可以处理不同种类的数据，比如CSV或JSONs等。我喜欢熊猫——我在上面制作了一个名为“为什么熊猫是新的Excel”的播客。我仍然认为熊猫是数据科学家武库中的一个令人敬畏的图书馆。然而，当你正在处理的数据集变得太大时，熊猫就会开始耗尽内存。正是在这里，火花进入画面。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/9622f01b8058586094ac9a11f1dc3f6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lDS_B0Q5cfQnSL88a7W08g.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">Spark对于大型数据集来说是很棒的❤️ [ <a class="ae le" href="https://unsplash.com/photos/hBzrr6m6-pc" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="bdf4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我以问答的形式写这篇博文，带着你可能会有的问题，我刚开始写的时候也有。</p><h2 id="1359" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated"><strong class="ak"> Q1。什么是火花？</strong></h2><p id="c3fc" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">Spark是一个处理海量数据集的框架。它允许您以分布式方式处理大数据文件。它让几个工人运转起来，这些工人处理你的大数据集，所有这些都由一个驱动节点来编排。该框架的分布式特性使您可以将其扩展到数TB的数据。你不再被任何一台机器的内存所限制。Spark生态系统现在已经发展得如此之快，以至于您不需要担心任何工作流程编排，并且可以开箱即用，性能卓越。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mt"><img src="../Images/f0b5d8fcfea2c44a3b2c6ff5ac11a12e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_r5cETGXngsjDcYos4HEzg.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">星火生态系统<a class="ae le" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank">参考</a></p></figure><h2 id="47c9" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated"><strong class="ak"> Q2。什么时候应该搬出熊猫，认真考虑用Spark？</strong></h2><p id="dd2a" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">这取决于你机器的内存。我想说大于10GB的数据集对熊猫来说太大了，Spark在这里变得非常有益。假设您的数据集中有10列，每个单元格有100个字符，因此大约有100个字节，并且大多数字符都是ASCII码，可以用1个字节进行编码，那么10M行将是您应该想到Spark的地方。</p><h2 id="1a45" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated"><strong class="ak"> Q3。Spark做什么都比熊猫好吗？</strong></h2><p id="7522" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">不要！对于初学者来说，学习熊猫肯定要容易得多。Spark可能更难，但有了最新的API，您可以使用数据帧处理大量数据，这些数据帧几乎和熊猫数据帧一样容易处理。</p><p id="cb18" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，直到最近，Spark还不太支持可视化。你只能对数据子集进行可视化。最近，当Databricks宣布他们将在Spark中对可视化提供原生支持时，情况发生了变化(我仍在等待看到这一点)。但在这种技术成熟之前，Spark至少在虚拟世界里不会完全取代熊猫。您总是可以通过<code class="fe mu mv mw mx b">df.toPandas()</code>将Spark数据帧转换成Pandas，然后运行可视化或Pandas代码。</p><h2 id="32cd" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated"><strong class="ak"> Q4。Spark设置起来很吓人。我该怎么办？</strong></h2><p id="10ba" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">Spark可以通过PySpark或Scala(或R或SQL)在Python中进行交互。我写了一篇关于在本地或定制服务器上开始使用PySpark的<a class="ae le" rel="noopener" target="_blank" href="/how-to-get-started-with-pyspark-1adc142456ec">博客</a>——人们评论说开始使用PySpark有多难。我认为在尝试运行Spark时，您可以直接使用托管云解决方案。</p><p id="9998" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我推荐两种开始使用Spark的方法:<br/> 1。Databricks  —这是一个完全托管的服务，为您管理AWS / Azure / GCP中的Spark集群。他们有可以运行的笔记本，与Jupyter笔记本非常相似。<br/> 2。<strong class="kk iu">亚马逊EMR和Zeppelin笔记本</strong> —这是由AWS提供的半托管服务。您需要托管一个Spark EMR端点，然后运行Zeppelin笔记本与之交互。其他云提供商也有类似的服务，我在这里不包括他们。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi my"><img src="../Images/f43e775d5a0dfbd816b953ede2de0646.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*VW4aYSABF37XtksnrwXRHw.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">Databricks是托管Spark集群的一种流行方式[Image<a class="ae le" href="https://commons.wikimedia.org/wiki/File:Databricks_Logo.png" rel="noopener ugc nofollow" target="_blank">Source</a>with CC<a class="ae le" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en" rel="noopener ugc nofollow" target="_blank">license</a></p></figure><h2 id="01bb" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated"><strong class="ak"> Q5。Databricks和EMR哪个好？</strong></h2><p id="c4f4" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">在花了几个小时试图了解两者的利弊之后，有一些考虑:<br/> a) EMR完全由亚马逊管理，你不需要离开AWS生态系统。<br/> b)如果您有devops专业知识或有devops人员帮助您，EMR可能是一个更便宜的选择——您需要知道如何在完成后上下旋转实例。也就是说，EMR可能不稳定，你可能需要花几个小时调试。Databricks Spark要稳定得多。<br/> c)使用Databricks很容易安排作业——您可以非常轻松地安排笔记本电脑在一天或一周的特定时间运行。它们还提供了一个到Ganglia UI中指标的接口。<br/> d)对于Spark作业而言，Databricks作业可能比EMR作业贵30–40%。但是考虑到灵活性和稳定性以及强大的客户支持，我认为他们是值得的。Databricks在Spark中以交互方式运行笔记本电脑的收费是6-7倍，所以请注意这一点。鉴于30/60/120分钟的活动后，你可以拒绝实例，从而节省成本，我仍然认为他们可以整体更便宜。</p><p id="a91d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">鉴于这几点，我想说如果这是你的第一个Spark项目，你应该选择Databricks，但是如果你有大量的DevOps专业知识，你可以尝试EMR或者在你自己的机器上运行Spark。如果你不介意公开分享你的工作，你可以免费试用Databricks社区版或者用他们的企业版做14天的<a class="ae le" href="https://databricks.com/try-databricks" rel="noopener ugc nofollow" target="_blank">试用</a>。</p><h2 id="ce67" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated"><strong class="ak"> Q6。PySpark和熊猫相比有多相似或不同？</strong></h2><p id="9406" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">我觉得这值得有自己的博客。星火计划的贡献者安德鲁·雷的这个演讲应该可以回答你的一些问题。<br/>主要相似之处有:<br/> a) Spark <strong class="kk iu">数据帧</strong>与熊猫数据帧非常相似。<br/> b) PySpark的groupby、aggregations、selection等变换都和熊猫很像。与熊猫相比，PySpark稍微难一点，有一点学习曲线——但感觉相似。</p><p id="8112" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">主要区别是:<br/> a) Spark允许你用SQL 和Python<strong class="kk iu">查询数据帧，我觉得这真的很棒。有时，用SQL编写一些逻辑可能比用Pandas/PySpark记住确切的API更容易，您可以这样做，也可以互换工作。<br/> b) <strong class="kk iu">火花数据帧是不可变的</strong>。不允许切片，覆盖数据等。<br/>c)<strong class="kk iu">Spark※懒评</strong>。它构建了一个所有转换的图表，然后当你实际提供一个动作，比如<code class="fe mu mv mw mx b">collect</code>或<code class="fe mu mv mw mx b">show</code>或<code class="fe mu mv mw mx b">take</code>时，它会懒洋洋地评估它们。转换可以是宽的(查看所有节点上的全部数据，因此<code class="fe mu mv mw mx b">orderBy</code>或<code class="fe mu mv mw mx b">groupBy</code>)或窄的(查看每个节点中的单个数据，因此<code class="fe mu mv mw mx b">contains</code>或<code class="fe mu mv mw mx b">filter</code>)。与窄转换相比，进行几个宽转换会慢一些。与熊猫相比，你需要更加注意你正在使用的广泛转换！</strong></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/22e59e00b4980ce452b2403cbebc3ce9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*pZNJZZ4iyfGt81B59AWzDA.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">Spark中的窄与宽转换。大范围转换速度较慢[图片由作者提供]</p></figure><h2 id="edcd" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated"><strong class="ak"> Q7。还有什么其他优势可以火花吗？</strong></h2><p id="85b8" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">Spark不仅提供数据帧(rdd上的高级抽象)，还通过MLLib提供优秀的流数据和分布式机器学习API。因此，如果你想对流数据进行转换，或者想在大型数据集上进行机器学习，Spark可能会对你有用。</p><h2 id="c9fb" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated"><strong class="ak"> Q8。有Spark的数据管道架构的例子吗？</strong></h2><p id="14b6" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">是的，这里有一个ETL管道，原始数据从数据湖(S3)处理，并在Spark中转换，加载回S3，然后加载到像雪花或红移这样的数据仓库，然后驱动像Tableau或Looker这样的BI工具。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi na"><img src="../Images/f4f02dbfff74a1d7fd17571ba87f9052.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TJtt-1yrCCaJ-1mNT36Cmg.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">BI工具的大型数据处理ETL管道示例[图片由作者提供]</p></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nb"><img src="../Images/167815da47bead58941e65974f5699af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r7SGfe0Mi3BRdnWoFiUGLA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">在Amazon SageMaker中执行ML的示例管道</p></figure><p id="ae14" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您也可以首先从仓库内不同的来源收集数据，然后使用Spark转换这些大型数据集，将它们加载到S3的Parquet文件中，然后从SageMaker读取它们，以防您更喜欢使用SageMaker而不是Spark的MLLib。SageMaker的一个额外优势是，它让您可以轻松部署，并通过Lambda函数触发模型，而Lambda函数又通过API Gateway中的REST端点连接到世界。我已经写了一篇关于这个架构的博文。另外<a class="ae le" href="https://www.amazon.com/dp/1492050040/?tag=omnilence-20" rel="noopener ugc nofollow" target="_blank">学习Spark</a>Jules Damji的书学习Spark真的很棒。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><p id="c0cc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就完成了从熊猫到星火的博文。我们讨论了一些相似点和不同点，开始使用Spark的最佳方式，以及一些利用Spark的常见架构。</p><p id="67ff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如有任何问题或意见，请通过LinkedIn 联系我！</p><p id="7237" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">资源:</strong> <br/> 1。Jules Damji讲述Spark如何工作的幕后故事。<br/> 2。朱尔斯·丹吉的《学习的火花》一书。<br/> 3。比较熊猫句法和安德鲁·雷的PySpark <a class="ae le" href="https://www.amazon.com/dp/1492050040/?tag=omnilence-20" rel="noopener ugc nofollow" target="_blank"> talk </a>。</p></div></div>    
</body>
</html>