<html>
<head>
<title>Effortless distributed training for PyTorch models with Azure Machine Learning and PyTorch-accelerated</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">借助Azure机器学习和PyTorch加速，轻松实现PyTorch模型的分布式培训</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/effortless-distributed-training-for-pytorch-models-with-azure-machine-learning-and-32797bd2336d?source=collection_archive---------24-----------------------#2021-12-13">https://towardsdatascience.com/effortless-distributed-training-for-pytorch-models-with-azure-machine-learning-and-32797bd2336d?source=collection_archive---------24-----------------------#2021-12-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ec69" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">帮助您开始使用AzureML CLI v2的全面指南</h2></div><p id="a879" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当训练深度学习模型时，通常会有一个点，当使用单一机器不再适合你时，通常是因为你需要更多的GPU来加速训练！即使对于有经验的从业者来说，从在本地机器上训练模型转移到云中的集群也是一个令人望而生畏的前景。通常，这个过程需要更新您的PyTorch训练脚本，以包括初始化过程组和用“分布式数据并行”包装模型等步骤，以及提供和管理基础设施；确保环境一致，并设置正确的变量等。令人欣慰的是，PyTorch加速的工具和Azure机器学习工具使得这个过程尽可能的简单，只需要对你的脚本进行最小的修改。</p><p id="6d95" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文的目的是展示使用AzureML运行分布式培训作业是多么简单，并帮助您尽快获得培训！例如，我们将探索如何在<a class="ae lb" href="https://github.com/fastai/imagenette" rel="noopener ugc nofollow" target="_blank"> Imagenette数据集</a>上训练图像分类模型；imagenette是Imagenet 中10个容易分类的类的子集。然而，虽然我们将使用此培训脚本作为示例，但我们的重点主要是整体工作流程，而不是试图最大限度地提高给定任务的性能。任务本身是本文中最不重要的部分，因为它的想法是，您将会很乐意将脚本更改为您自己的脚本！</p><p id="0776" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">免责声明</strong>:在我为微软工作期间，我没有被要求以任何方式推广Azure机器学习，也没有得到任何报酬。在Data Intelligence &amp;设计团队中，我们引以为豪的是，根据具体情况和我们正在合作的客户，使用我们认为最适合工作的工具。如果我们选择不使用微软产品，我们会向产品团队提供详细的反馈，说明原因，以及我们认为缺少或可以改进的地方；这种反馈循环通常会导致微软产品非常适合我们的需求。在这里，我选择推广Azure机器学习的特性，因为CLI v2是我个人选择的基于云的培训工具。</p><h1 id="06be" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">在本地进行培训</h1><p id="91e0" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">在我们看AzureML之前，让我们了解并验证一下，我们如何在本地运行训练脚本。</p><h2 id="6a37" class="lz ld iq bd le ma mb dn li mc md dp lm ko me mf lo ks mg mh lq kw mi mj ls mk bi translated">下载数据集</h2><p id="2942" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">首先，让我们为数据创建一个文件夹，并下载Imagenette数据集:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ml"><img src="../Images/d3bb8716a9a6fbfee4e98089a2507d6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yyAnL1Hyn6qtHuJFzWmM5w.png"/></div></div></figure><h2 id="d134" class="lz ld iq bd le ma mb dn li mc md dp lm ko me mf lo ks mg mh lq kw mi mj ls mk bi translated">定义培训脚本</h2><p id="2bbe" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">现在我们已经下载了数据，让我们为培训任务和输出创建文件夹，并编写脚本:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/e8e8fbd6f7ef408611a2c87912e05fad.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*9DdjIK-bc2kKTkt8nffxvg.png"/></div></figure><figure class="mm mn mo mp gt mq"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="7476" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我们正在训练一个来自优秀的<a class="ae lb" href="https://github.com/rwightman/pytorch-image-models" rel="noopener ugc nofollow" target="_blank"> timm库</a>的<a class="ae lb" href="https://arxiv.org/abs/2103.07579" rel="noopener ugc nofollow" target="_blank"> Resnet-RS50 </a>模型——这是标准Resnet架构的改进版本，我建议使用它来代替常规的<a class="ae lb" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">Resnet 50</a>——带有<a class="ae lb" href="https://arxiv.org/abs/1711.05101v3" rel="noopener ugc nofollow" target="_blank"> AdamW优化器</a>和<a class="ae lb" href="https://arxiv.org/abs/1506.01186" rel="noopener ugc nofollow" target="_blank">单周期</a>学习速率表；我发现这个配置对于大多数图像分类任务来说是一个很好的默认配置。</p><p id="f508" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我们不需要编写训练循环，或者管理向不同设备移动数据，我们使用P <em class="na"> yTorch-accelerated </em>的<a class="ae lb" href="https://pytorch-accelerated.readthedocs.io/en/latest/trainer.html" rel="noopener ugc nofollow" target="_blank">训练器</a>来为我们处理这些问题。这样，我们的代码将保持不变，无论我们是在单个GPU上训练，还是在分布于不同节点的多个GPU上训练。由于建议使用<a class="ae lb" href="https://huggingface.co/docs/accelerate/quicktour.html#launching-your-distributed-script" rel="noopener ugc nofollow" target="_blank"> Accelerate CLI </a>启动P <em class="na"> yTorch-accelerated </em>脚本<em class="na"> </em>，这也意味着我们使用的命令也将保持一致，不管我们的硬件如何。</p><p id="f7d6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="na">如果您对</em> <a class="ae lb" href="https://github.com/Chris-hughes10/pytorch-accelerated" rel="noopener ugc nofollow" target="_blank"> <em class="na"> PyTorch加速</em> </a> <em class="na">不熟悉，并且想在开始阅读本文之前了解更多信息，请查看</em> <a class="ae lb" href="https://medium.com/@chris.p.hughes10/introducing-pytorch-accelerated-6ba99530608c?source=friends_link&amp;sk=868c2d2ec5229fdea42877c0bf82b968" rel="noopener"> <em class="na">介绍性博客文章</em> </a> <em class="na">或</em> <a class="ae lb" href="https://pytorch-accelerated.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> <em class="na">文档</em></a><em class="na">；或者，这很简单，缺乏这方面的知识不会影响您对本文所探讨内容的理解！</em></p><h2 id="839c" class="lz ld iq bd le ma mb dn li mc md dp lm ko me mf lo ks mg mh lq kw mi mj ls mk bi translated">在本地进行培训</h2><p id="ed89" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">让我们验证一下训练脚本是否在我们的本地机器上运行。首先，让我们创建一个配置文件，使用accelerate CLI指定我们的硬件选项。我们可以通过运行以下命令并回答问题来做到这一点:</p><pre class="mm mn mo mp gt nb nc nd ne aw nf bi"><span id="9830" class="lz ld iq nc b gy ng nh l ni nj">accelerate config --config_file train_imagenette/accelerate_config.yaml</span></pre><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ml"><img src="../Images/4af9b176a1592b0ea6c3e5eea8b27e49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AbK0YKuinkmSRym8a0JOBw.png"/></div></div></figure><p id="330f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以生成以下yaml文件:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/d2299061aa9b33c7b5721a94f2d8c9dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*cPAu0TGOTweVM7nOh193Xg.png"/></div></figure><p id="d523" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在可以使用accelerate launch命令开始我们的训练跑了:</p><pre class="mm mn mo mp gt nb nc nd ne aw nf bi"><span id="f92b" class="lz ld iq nc b gy ng nh l ni nj">accelerate launch --config_file train_imagenette/accelerate_config.yaml \<br/>train_imagenette/train.py --data_dir data/imagenette2-320 --epochs 1</span></pre><p id="8273" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这将产生以下输出:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi nl"><img src="../Images/b0f9a12b391d042dc45d35f318912881.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w_PaEuYi3YX_Rxd5ZabFew.png"/></div></div></figure><p id="31ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了使用额外的GPU进行训练，我们需要修改我们的accelerate配置文件。一种方法是使用与之前相同的过程。或者，由于我们想要更改的只是进程的数量，我们可以直接从命令行覆盖该属性，如下所示。为了避免不得不在不同的运行之间运行“accelerate config”命令，我们将在稍后使用AzureML时利用这一点。</p><pre class="mm mn mo mp gt nb nc nd ne aw nf bi"><span id="9ad3" class="lz ld iq nc b gy ng nh l ni nj">accelerate launch --config_file train_imagenette/accelerate_config.yaml --num_processes 2 \<br/>train_imagenette/train.py --data_dir data/imagenette2-320 --epochs 1</span></pre><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi nm"><img src="../Images/bff660353a60231ab06dad93790fc939.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZTrYnzn84piU-b1VRI530g.png"/></div></div></figure><p id="0bf2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以从输出中看到，由于使用了两个GPU，在训练和验证期间需要的步骤减少了一半。</p><p id="9178" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们已经验证了我们可以在本地运行我们的脚本，让我们探索如何使用AzureML来扩展我们的训练。</p><p id="ada0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您更喜欢使用vanilla PyTorch编写脚本，您仍然可以遵循本文中概述的方法，但是您必须手动处理脚本中所有复杂的分布式训练，并确保您为您的硬件使用正确的启动命令！</p><h1 id="86ff" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated"><strong class="ak">azure ml上的分布式培训</strong></h1><p id="b9cc" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">AzureML为训练模型提供了两种不同的方法:</p><ul class=""><li id="4907" class="nn no iq kh b ki kj kl km ko np ks nq kw nr la ns nt nu nv bi translated">使用<a class="ae lb" href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-cli" rel="noopener ugc nofollow" target="_blank"> CLI v2 </a>(我个人偏好)</li><li id="3630" class="nn no iq kh b ki nw kl nx ko ny ks nz kw oa la ns nt nu nv bi translated">使用<a class="ae lb" href="https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py" rel="noopener ugc nofollow" target="_blank"> Python SDK </a></li></ul><p id="f288" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，我们将重点介绍CLI v2的使用。</p><p id="13cb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">AzureML CLI v2提供了一种基于命令行的模型训练方法，其中我们的配置是在yaml文件中定义的。如果你习惯于在笔记本上使用SDK，这可能会有点令人生畏，但是一旦你理解了可用的选项是什么，这就很简单了！</p><p id="fdb1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们开始培训之前，需要注意一些先决条件。要遵循本指南，您需要:</p><ul class=""><li id="3657" class="nn no iq kh b ki kj kl km ko np ks nq kw nr la ns nt nu nv bi translated">一个<strong class="kh ir"> Azure订阅</strong>——在这里很容易注册一个订阅<a class="ae lb" href="https://azure.microsoft.com/en-gb/free/" rel="noopener ugc nofollow" target="_blank">，它包括前30天的免费积分，然后在特定阈值下免费使用。</a></li><li id="24cf" class="nn no iq kh b ki nw kl nx ko ny ks nz kw oa la ns nt nu nv bi translated">安装<strong class="kh ir"> Azure CLI </strong>和</li><li id="9cf9" class="nn no iq kh b ki nw kl nx ko ny ks nz kw oa la ns nt nu nv bi translated">创建一个<strong class="kh ir"> Azure机器学习工作区— </strong>这很简单，可以使用<a class="ae lb" href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace?tabs=python" rel="noopener ugc nofollow" target="_blank">门户</a>或<a class="ae lb" href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace-cli?tabs=createnewresources%2Cvnetpleconfigurationsv1cli" rel="noopener ugc nofollow" target="_blank">CLI</a>来完成</li><li id="6295" class="nn no iq kh b ki nw kl nx ko ny ks nz kw oa la ns nt nu nv bi translated">为了<a class="ae lb" href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-cli" rel="noopener ugc nofollow" target="_blank">安装<strong class="kh ir">azure ml CLI v2</strong>T9】</a></li></ul><p id="5d10" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在撰写本文时使用的版本如下所示:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/fd07ddf986da9de5a270fa1e05820e6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*gdJ-_o0HXcUDIF0k3FGldQ.png"/></div></figure><p id="9cd4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="na">注意:</em> </strong> <em class="na">重要的是，CLI v2的扩展名显示为“ml”，如果您看到的是“azure-cli-ml”，这是CLI v1，以下步骤将不起作用！</em></p><p id="47c9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了获得Azure ML CLI v2中可用功能的概述，我们可以运行命令:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi oc"><img src="../Images/8ad0bf6d6e6f95d728877769d28195a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ujLaouLi_sOC8sIp8QZ_pA.png"/></div></div></figure><p id="c0c7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦一切都安装好了，我们就可以开始了！</p><h2 id="ec1f" class="lz ld iq bd le ma mb dn li mc md dp lm ko me mf lo ks mg mh lq kw mi mj ls mk bi translated"><strong class="ak">将日志记录添加到培训脚本(可选)</strong></h2><p id="a2a8" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">尽管我们的脚本已经准备好按原样运行，但是唯一将被捕获的输出是标准输出日志，当在AzureML上运行时，它将被写入一个文本文件。为了帮助我们跟踪和比较不同的实验运行，而不必查看日志，我们可以设置一个日志记录器来记录某些指标和工件，以显示在AzureML门户上。</p><p id="6f54" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用<em class="na"> azureml-mlflow </em>包，我们可以使用<a class="ae lb" href="https://mlflow.org/docs/latest/python_api/mlflow.html" rel="noopener ugc nofollow" target="_blank"> MLFlow fluent API </a>进行日志记录；更多关于使用MLFlow和AzureML的信息可以在<a class="ae lb" href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="0980" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过PyTorch加速，我们可以<a class="ae lb" href="https://pytorch-accelerated.readthedocs.io/en/latest/callbacks.html#creating-new-callbacks" rel="noopener ugc nofollow" target="_blank">为此创建一个回调</a>，如下图所示:</p><figure class="mm mn mo mp gt mq"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="82ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们所见，这根本不需要太多代码！这里，我们子类化了一个现有的PyTorch加速回调函数，并覆盖了日志记录方法来记录MLFlow这只能在所有节点的主流程中完成，以防止相同的指标被记录两次。通常，当使用MLFlow时，我们必须显式地开始和结束运行，但AzureML将为我们处理这一点；以及确保为我们设置了包含跟踪URI的环境。除了记录指标，我们还将记录训练者的<a class="ae lb" href="https://pytorch-accelerated.readthedocs.io/en/latest/run_config.html" rel="noopener ugc nofollow" target="_blank">跑步配置</a>，其中包含诸如训练周期数和是否使用了混合精度等信息。如果我们需要重新运行相同的实验，获取这些信息将有助于我们在将来复制训练条件。</p><p id="70d5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，正如我们前面看到的，PyTorch-accelerated默认显示一个进度条。让我们删除它，以保持日志尽可能清晰。我们可以通过移除<a class="ae lb" href="https://pytorch-accelerated.readthedocs.io/en/latest/callbacks.html#pytorch_accelerated.callbacks.ProgressBarCallback" rel="noopener ugc nofollow" target="_blank"> ProgressBarCallback </a>来做到这一点。</p><p id="9c01" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们更新我们的脚本来反映这些变化。</p><figure class="mm mn mo mp gt mq"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="3435" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里我们可以看到，我们已经更新了传递给培训师的回访列表。因为我们正在将模型保存到。outputs '文件夹，这将由AzureML为我们存储。</p><h2 id="8bba" class="lz ld iq bd le ma mb dn li mc md dp lm ko me mf lo ks mg mh lq kw mi mj ls mk bi translated"><strong class="ak">定义我们的培训环境</strong></h2><p id="0e22" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">既然我们的训练代码已经准备好了，我们需要定义代码执行的环境。AzureML提供了<a class="ae lb" href="https://docs.microsoft.com/en-us/azure/machine-learning/concept-environments" rel="noopener ugc nofollow" target="_blank">管理环境</a>——旨在按原样使用——以及通过指定conda依赖文件来<a class="ae lb" href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-environments-v2" rel="noopener ugc nofollow" target="_blank">创建环境</a>的选项，conda依赖文件定义了要安装到默认基本docker映像上的指定包。</p><p id="7c61" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然这些方法可能是一个很好的开始，因为它们是建立在“默认”docker映像之上的，并且以这种方式创建的环境通常包括许多您没有指定和不需要的包；在这些环境中安装额外的包可能会产生您没有意识到的冲突。</p><p id="6f86" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些方法的替代方法是定义我们自己的docker图像。就我个人而言，尤其是在生产环境中，我喜欢完全控制环境的所有方面，并且倾向于发现，在第一次设置实验时，我花在创建docker映像上的少量时间可以节省我以后花在调试环境问题上的更多时间！</p><p id="0e9c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于这个实验，我们可以使用<a class="ae lb" href="https://hub.docker.com/r/pytorch/pytorch/tags/" rel="noopener ugc nofollow" target="_blank"> base PyTorch image </a>来定义一个自定义Dockerfile，如下所示。由于我们的基本映像包含PyTorch和所有必要的cuda库，我们需要指定的唯一包是AzureML组件、MlFlow和运行我们的训练脚本所需的依赖项。</p><p id="0647" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面演示了这一点:</p><figure class="mm mn mo mp gt mq"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="a310" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们也可以在此时将我们的训练脚本复制到docker映像中，但是我们会让AzureML稍后为我们做这件事！为此，我们将在实验文件夹中使用一个单独的目录来存储docker文件，它将被用作docker构建上下文；AzureML只会在该文件夹中的内容发生变化时触发映像构建过程。通过使用AzureML将我们的脚本复制到环境中，我们可以避免在每次修改脚本时触发构建和推送映像的过程。</p><p id="7cbb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">关于创建Dockerfiles的更多信息可以在<a class="ae lb" href="https://kevalnagda.github.io/dockerfile" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h2 id="005b" class="lz ld iq bd le ma mb dn li mc md dp lm ko me mf lo ks mg mh lq kw mi mj ls mk bi translated"><strong class="ak">注册数据集</strong></h2><p id="3120" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">我们必须做的另一件事是将数据集上传到云中。虽然我们有多种方法可以做到这一点(取决于数据的位置)，但我们将通过从本地文件夹注册数据集来做到这一点。我们可以通过定义以下yaml文件来做到这一点:</p><figure class="mm mn mo mp gt mq"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="d66a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们可以使用CLI在工作区中注册该数据集，并使用以下命令上传文件:</p><pre class="mm mn mo mp gt nb nc nd ne aw nf bi"><span id="4a6f" class="lz ld iq nc b gy ng nh l ni nj">az ml data create -f data/register_dataset.yaml \<br/>--resource-group myResourceGroup --workspace-name myWorkspace</span></pre><p id="c32d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然在培训工作中有其他<a class="ae lb" href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-cli#data-inputs" rel="noopener ugc nofollow" target="_blank">选择</a>来访问数据，但注册和版本化数据集是一种推荐的方法，可以实现实验的跟踪和再现性。</p><h2 id="a2ed" class="lz ld iq bd le ma mb dn li mc md dp lm ko me mf lo ks mg mh lq kw mi mj ls mk bi translated"><strong class="ak">创建计算目标</strong></h2><p id="3410" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">接下来要做的是定义我们希望运行培训脚本的计算目标。我们可以通过访问<a class="ae lb" href="https://docs.microsoft.com/en-us/azure/virtual-machines/sizes-gpu" rel="noopener ugc nofollow" target="_blank"> Azure文档</a>或运行以下命令来了解可用的选项:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ml"><img src="../Images/2c4863cdc5b6033ee8457d3e2abe53bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E4hvhkCnsBxRRzDwTEXP5g.png"/></div></div></figure><p id="564f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里我们用一个<a class="ae lb" href="https://docs.microsoft.com/en-us/azure/virtual-machines/nv-series" rel="noopener ugc nofollow" target="_blank"> Standard_NV24 </a>，它有4个<a class="ae lb" href="https://images.nvidia.com/content/tesla/pdf/188417-Tesla-M60-DS-A4-fnl-Web.pdf" rel="noopener ugc nofollow" target="_blank">NVIDIA Tesla M60</a>GPU。</p><p id="cc58" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以按如下方式定义和配置我们的计算集群:</p><figure class="mm mn mo mp gt mq"><div class="bz fp l di"><div class="my mz l"/></div></figure><pre class="mm mn mo mp gt nb nc nd ne aw nf bi"><span id="f01b" class="lz ld iq nc b gy ng nh l ni nj">az ml compute create -f infra/create_compute_target.yaml \<br/>--resource-group myResourceGroup --workspace-name myWorkspace</span></pre><p id="7050" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于我们已经定义了一系列实例，AzureML将根据需求管理集群的伸缩。</p><h2 id="e4e0" class="lz ld iq bd le ma mb dn li mc md dp lm ko me mf lo ks mg mh lq kw mi mj ls mk bi translated">定义培训工作配置</h2><p id="cf75" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">现在，是时候为我们的训练运行定义配置了！这是通过使用一个<a class="ae lb" href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-cli#hello-world" rel="noopener ugc nofollow" target="_blank">任务</a>来完成的，它指定了以下内容:</p><ul class=""><li id="0185" class="nn no iq kh b ki kj kl km ko np ks nq kw nr la ns nt nu nv bi translated">跑什么</li><li id="f455" class="nn no iq kh b ki nw kl nx ko ny ks nz kw oa la ns nt nu nv bi translated">在哪里运行</li><li id="27c0" class="nn no iq kh b ki nw kl nx ko ny ks nz kw oa la ns nt nu nv bi translated">如何运行它</li></ul><p id="a64b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们定义我们的作业配置文件，然后分解它:</p><figure class="mm mn mo mp gt mq"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="31d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们已经指定了我们想要运行的内容，这非常类似于我们用来在本地运行培训的accelerate launch命令；关键的区别在于我们覆盖了accelerate配置文件的一些属性。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi od"><img src="../Images/a2a7ebf0ba018c9e8cdd0992ca002523.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*AAl3-nhcz6qR74sYuzs9og.png"/></div></figure><p id="b9bf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，我们使用了由AzureML自动设置的环境变量来指定分布式训练所需的机器等级、主进程IP地址和主进程端口的值。这将确保在每个节点上使用正确的值，这样我们就不需要为每台机器创建单独的配置文件。</p><p id="a7b8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还定义了一些输入，作为参数传递给我们的脚本。通过定义输入部分，我们可以选择从命令行覆盖这些值，这样我们就不必为不同的超参数配置修改yaml脚本。</p><p id="6c91" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要访问我们的数据集，因为它是在我们的工作区中注册的，我们可以使用' azureml '前缀来访问它，后跟它注册时的名称和数据集版本标签；AzureML将把这个数据集挂载到每个计算实例，并将正确的数据路径传递给我们的训练脚本。</p><p id="ccb9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们定义了想要运行代码的位置:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/7463bf238d47757d76afee398a92dc81.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*pU1PubbNsDfTQ_zBuXgwig.png"/></div></figure><p id="8844" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，我们指定环境——包含我们之前创建的docker文件的目录——我们代码的本地路径，以及我们提供的计算目标。提交时，AzureML将构建docker映像，然后将此映像推送到容器注册中心；这将被缓存，直到做出更改。对于每次运行,“代码”路径中的所有内容都将被复制到docker映像中，并在指定的计算目标上执行。</p><p id="b792" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我们已经定义了希望如何运行作业，在本例中，就是指定我们的分布式培训配置。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi of"><img src="../Images/5abc38925ce3e09d48b7380ca3f90122.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*5lGYRqz5zo04-MXW3hmCUQ.png"/></div></figure><p id="ec46" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为accelerate launch命令将处理为每个GPU创建进程的任务，所以我们只需要在每台机器上执行一个进程。在参考资料部分，我们已经指定了我们希望用于培训的实例数量。</p><p id="ec62" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要了解配置作业的所有可用选项，您可以查看文档或检查<a class="ae lb" href="https://azuremlschemas.azureedge.net/latest/commandJob.schema.json" rel="noopener ugc nofollow" target="_blank">命令作业模式</a>。</p><h2 id="0ab9" class="lz ld iq bd le ma mb dn li mc md dp lm ko me mf lo ks mg mh lq kw mi mj ls mk bi translated">启动AzureML培训</h2><p id="6d7f" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">现在，让我们使用下面的命令启动我们的培训作业。默认情况下，我们的配置指定在单台机器上使用单个GPU，因此我们覆盖了其中的一些值，以便在两台机器上使用八个GPU。</p><pre class="mm mn mo mp gt nb nc nd ne aw nf bi"><span id="095a" class="lz ld iq nc b gy ng nh l ni nj">az ml job create -f train_imagenette/train_config.yaml --set \<br/> inputs.num_machines=2 \<br/> inputs.num_processes=8 \<br/> resources.instance_count=2 \<br/>--resource-group myResourceGroup --workspace-name myWorkspace</span></pre><p id="28d7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，如果我们导航到AzureML工作区中的实验部分，我们应该能够看到我们的训练运行！</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ml"><img src="../Images/3bda4f347b50d47ac3504ef9797021c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BT1LpW7UnhfGxhmua_bUNQ.png"/></div></div></figure><p id="44a6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我们可以看到一些图表是基于我们在培训期间记录的值绘制的；这个视图可以根据你的喜好定制。由于我们没有在配置文件中指定显示名称，AzureML已经指定了一个随机名称；如果我们对多次运行使用相同的显示名称，将会使图表上显示的指标与正确的运行相关联变得更加困难。</p><p id="656a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还可以选择我们的跑步来查看其他信息，包括从教练的跑步配置中记录的标签。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ml"><img src="../Images/09dadc9706ad589787e6ea9d5b468ed9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t_uw0TPkrn1ux91rJh_mFA.png"/></div></div></figure><p id="65d0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">浏览选项卡，我们可以看到记录的指标的更细粒度视图，以及所用代码的快照。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ml"><img src="../Images/6c33ae535b2c8b99fb5c9acc34493c29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ITOCC94M5O_v_Pe6wYo_TA.png"/></div></div></figure><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi og"><img src="../Images/0a8d157d34e9dab02ad8b47201ac34ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZKldpazN_U7T7FcIYZq2Pg.png"/></div></div></figure><p id="5174" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在“Outputs + Logs”选项卡中，我们可以看到由我们的脚本生成的日志，以及我们保存到Outputs文件夹的模型检查点:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ml"><img src="../Images/3e9781ebbe1fa14f57032f0972c4b7fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eKFaFkq3j8_lbmSe_FQ8AQ.png"/></div></div></figure><h1 id="8eaf" class="lc ld iq bd le lf lg lh li lj lk ll lm jw ln jx lo jz lp ka lq kc lr kd ls lt bi translated">结论</h1><p id="031f" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">希望这已经展示了使用<a class="ae lb" href="https://docs.microsoft.com/en-us/azure/machine-learning/" rel="noopener ugc nofollow" target="_blank"> Azure机器学习</a>和<a class="ae lb" href="https://github.com/Chris-hughes10/pytorch-accelerated" rel="noopener ugc nofollow" target="_blank"> PyTorch加速</a>的强大组合，在Azure上开始PyTorch模型的分布式培训是多么容易！</p><p id="2313" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="na">克里斯·休斯上了</em><a class="ae lb" href="http://www.linkedin.com/in/chris-hughes1/" rel="noopener ugc nofollow" target="_blank"><em class="na">LinkedIn</em></a><em class="na">。</em></p></div></div>    
</body>
</html>