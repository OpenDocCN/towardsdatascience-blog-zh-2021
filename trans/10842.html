<html>
<head>
<title>Transfer Learning for Guitar Effects</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">吉他效果的迁移学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/transfer-learning-for-guitar-effects-4af50609dce1?source=collection_archive---------13-----------------------#2021-10-20">https://towardsdatascience.com/transfer-learning-for-guitar-effects-4af50609dce1?source=collection_archive---------13-----------------------#2021-10-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/a51a213cea0bab790f5487c59c8c379a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i3MwRByt00zyipZtDbCdzw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">挡泥板布鲁斯Jr .放大器中的真空管(图片由作者提供)</p></figure><h2 id="cd0e" class="jd je jf bd b dl jg jh ji jj jk jl dk jm translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><p id="6281" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如果每一件新事物都要从头学起，生活会有多艰难？如果你曾经学过“狗”这个词，你必须再次学习字母是有声音的符号，你可以把它们放在一起组成单词，而“c-a-t”是一种不同的有尾巴的四条腿的动物？</p><p id="2203" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">谢天谢地，我们的大脑非常擅长识别模式。如果你已经知道“狗”这个词表示一种动物，那么不难理解“猫”这个词代表一种不同的动物。使用我们已经知道的东西来解决类似的问题是人工神经网络中的<em class="lj">转移学习</em>背后的概念。</p><p id="da5c" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">迁移学习<strong class="kn jp"> </strong>是机器学习中的一种技术，其中从解决一个问题中获得的信息被应用到类似但不同的问题中。实际上，当训练神经网络时，这种技术可用于获得更快的收敛或更低的损失。当缺少特定问题的训练数据时，也可以使用它。</p><p id="6faa" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">本文介绍了使用迁移学习来模拟吉他效果和放大器的几个实验的结果。(关于使用神经网络模拟模拟吉他效果和放大器的介绍，请从这里的<a class="ae lk" href="https://medium.com/nerd-for-tech/neural-networks-for-real-time-audio-introduction-ed5d575dc341" rel="noopener">开始。)</a></p><h1 id="ac8f" class="ll lm jf bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">实验设置</h1><p id="e8a5" class="pw-post-body-paragraph kl km jf kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">这些测试有几个假设。首先，原始模型和“迁移学习增强”模型使用完全相同的层和层大小(LSTM大小为20，接着是密集层)。迁移学习的一个棘手部分是考虑模型架构的差异，并保持相关信息的完整性。使用相同的模型可以大大简化事情。</p><p id="9b05" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><em class="lj">注:有关该特定神经网络实现的更多信息，请在此处阅读</em><a class="ae lk" rel="noopener" target="_blank" href="/neural-networks-for-real-time-audio-stateful-lstm-b534babeae5d"><em class="lj"/></a><em class="lj">。</em></p><p id="a850" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">第二，每个迁移学习测试只使用相似声音(失真水平)的设备。测试了一个失真踏板对另一个失真踏板和一个放大器对另一个放大器的相似超速传动水平。每个目标设备首先从头开始训练(基线)。接下来，使用预先训练的模型作为起点(迁移学习增强)。</p><p id="e357" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">每个设备对进行两次运行:完整数据集运行(3分钟以上的音频)和有限数据集运行(30秒的音频)。对于数据不足的模型，使用大约相同长度的验证数据(~30秒)来提供与完整数据集模型的合理损失比较。每2个时期进行一次验证，并使用Matplotlib绘制验证损失。</p><p id="b065" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">选择的失真踏板是依班娜TS9电子管扬声器踏板和Boss MT-2失真踏板。TS9用作起始模型，MT-2用作迁移学习模型。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mo"><img src="../Images/959e0de1dbc4700cf40f0facc2f7fab6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JP7QXm2w4LNbG4ObHShcUA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">TS9模型用作MT2模型的起点(图片由作者提供)</p></figure><p id="87df" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">选择的放大器是Fender Blues Jr和Blackstar HT40。蓝调Jr .作为起步机型，HT40作为转移学习机型。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mt"><img src="../Images/39ac14f021c575242457f537a757f27e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CANQ45C17gyYuPn0HaIg-w.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">小布鲁斯模型被用作HT40模型的起点(图片由作者提供)</p></figure><p id="8be0" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><em class="lj">注意:开始的模型都是在完整的3-4分钟数据集上训练的(TS9和Blues Jr)。</em></p><p id="69e4" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">使用的训练代码是Github上的<a class="ae lk" href="https://github.com/Alec-Wright/Automated-GuitarAmpModelling" rel="noopener ugc nofollow" target="_blank">Automated-guitar amp modeling</a>项目，具体是同一项目的<a class="ae lk" href="https://github.com/GuitarML" rel="noopener ugc nofollow" target="_blank"> GuitarML </a> fork中包含的<a class="ae lk" href="https://github.com/GuitarML/Automated-GuitarAmpModelling/blob/main/colab_training.ipynb" rel="noopener ugc nofollow" target="_blank"> Colab脚本</a>。允许训练运行至完成，每次运行的周期数根据“验证耐心”设置25而变化，这意味着在25个周期没有改善后，训练自动停止。应当注意，在该代码中还实现了自适应学习率。</p><h1 id="0da2" class="ll lm jf bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">失真踏板测试</h1><p id="5d2c" class="pw-post-body-paragraph kl km jf kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated"><strong class="kn jp"> Boss MT-2全数据集</strong></p><p id="9357" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">进行的第一次测试是从TS9型号开始的Boss MT-2。即使这些是相似的踏板，它们的失真质量在音乐上是不同的。MT-2驱动器被拨回，以更紧密地匹配TS9的较轻失真，这是在全驱动设置。验证损失比较如下所示。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mu"><img src="../Images/93d30f791ce54583668da9c5da326d1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1FhoOubpqWybfh36egflOQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图1: Boss MT2与来自TS9的Boss MT2，完整数据集(作者提供的图)</p></figure><p id="f996" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">最显著的差异是起始损失，这是在前两个时期之后测量的。迁移学习模型能够从0.37快速下降到0.06。总体趋势显示，转移模型的损失略低，持续到运行结束。0.004的整体损失改善(对我的耳朵来说)不是听觉上的更好。在这种情况下，最佳点似乎就在第50时段之前，此时损耗差约为0.02。</p><p id="3225" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kn jp"> Boss MT-2精简数据集</strong></p><p id="eff0" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">第二个测试使用30秒的相同MT-2数据进行训练，而不是完整的150秒。30秒的音频仍然用于验证，因为较短长度的验证数据可能导致看似较低的损失值。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/1f3c53645e2124d886babfb248a45256.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X6UV706DiA0zq4CHZ2d2rw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图2:来自TS9的Boss MT2与Boss MT2，有限的训练数据集(30秒)(图由作者提供)</p></figure><p id="1951" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">由于训练数据集更小，训练时间减少了一半，如果使用更小的验证集，时间会更短。(同样，为了更准确的比较，验证集保持与完整数据训练中相同的长度，大约30秒)。</p><p id="0a0b" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">开始的损失要低得多，在迁移学习模型持续改进的60年代前后，趋势相似。迁移学习模型也继续在更多的时期有非常小的改进，直到在时期263停止。与完整数据集测试相比，从头开始模型和迁移学习模型之间的损失差异在60代左右开始更显著。0.023的总损耗差足以让受过训练的耳朵(和高质量扬声器)识别更精确的模型。</p><h1 id="0c4a" class="ll lm jf bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">放大器测试</h1><p id="c951" class="pw-post-body-paragraph kl km jf kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">接下来进行组合放大器的迁移学习测试。小布鲁斯驱动器被设置为最大与“脂肪”推进按钮接合。HT40的驱动旋钮从最大值减少到大约25%,以接近相同的嘎吱声水平。两个放大器都具有全电子管前置放大器和功率放大器电路，但HT-40也有一个带有电子管扬声器风格声音的过驱动限幅电路。两个样本都是使用位于扬声器锥体中部的SM57动圈麦克风录制的。一般来说，使用带麦克风的放大器进行训练比使用带直接输出功能的放大器更困难。扬声器和麦克风增加了信号的力度，听起来悦耳，但对于训练来说更复杂。</p><p id="ed97" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kn jp"> HT40完整数据集(带声音样本)</strong></p><p id="c5f4" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">第一个amp测试使用了全套数据，这次使用了4分钟的音频(3' 20 "用于训练，40秒用于验证)。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mw"><img src="../Images/afb93fcaf48271262267195315acf691.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uNTqK3n4F99qfmVuCsTIKQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图3:来自Blues Jr .的HT40与HT40的比较，完整数据集(图由作者提供)</p></figure><p id="4ea4" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">HT40放大器在整个训练过程中的损耗差异比MT-2失真踏板更加极端。从零开始的HT40在损失开始减少之前需要大约60个时期。然而，迁移学习增强模型的起点低得多，并在整个运行过程中不断取得小的改进。</p><p id="8a33" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><em class="lj">注意:HT40从零开始的训练在纪元340附近被中断，但是看起来它自己接近完成。</em></p><p id="b729" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">完整数据集HT40放大器测试的声音样本在此分享，以供比较。目标是听起来尽可能接近目标音频。这是目标音频，即从SM57麦克风录制的25%增益的HT40放大器(过驱动通道):</p><figure class="mp mq mr ms gt is"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="6a89" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这是从零开始训练的模型(无迁移学习，损失值0.078):</p><figure class="mp mq mr ms gt is"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="efa0" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这是以Blues Jr. amp为起点的模型(迁移学习增强，损失值为0.036):</p><figure class="mp mq mr ms gt is"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="e44b" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">即使没有录音室显示器或昂贵的耳机，迁移学习模式也明显更接近目标。使用迁移学习的损失改善约为0.04。</p><p id="ff70" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kn jp"> HT40精简数据集</strong></p><p id="51cb" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">接下来，使用有限的数据集；40秒用于培训，40秒用于验证。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mz"><img src="../Images/49a77638734afb640422400b20e297d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PIW1ZoY_oRHG5XMRlsPYcQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图4:来自Blues Jr的HT40与HT40对比，有限训练数据集(40秒)(作者图)</p></figure><p id="fa5c" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这项测试显示了使用迁移学习最显著的好处。从头开始训练HT-40的有限数据集未收敛，验证损失未低于0.74。在达到耐心极限和训练自动停止之前，跑步持续了68个时期。然而，当从小布鲁斯模型开始时，损失立即开始减少，并在整个过程中继续改善。</p><p id="d6d6" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">下表1中比较了所有测试的损失和培训时间。当在Colab上训练时，减少的训练集的每个时期的时间大约减少了一半。由于达到了Colab限制，HT40的完整数据集必须在本地GPU上进行训练，因此HT40的训练时间不应与缩减后的数据集进行比较。转移学习模型的最终损失值较小，在放大器测试与失真踏板的情况下，差异更明显。在HT-40放大器缩减数据集的情况下，需要使用转移学习来对模型进行训练。除了HT40缩减数据集之外，转移模型的最佳损失大约减半。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi na"><img src="../Images/9300947839231736e9acf76b049d43a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3qSyWJIqq7uIcEdoqw83mQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">表1:所有运行比较(作者图片)</p></figure><h1 id="db00" class="ll lm jf bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">结论和未来工作</h1><p id="2130" class="pw-post-body-paragraph kl km jf kn b ko mj kq kr ks mk ku kv kw ml ky kz la mm lc ld le mn lg lh li ij bi translated">这些初始测试表明，使用迁移学习可以减少训练时间，因为达到可接受的准确度需要更少的训练数据。当训练过驱的麦克风放大器等困难信号时，这也是有益的。在数据有限的情况下，可能需要迁移学习才能使模型收敛，就像HT40有限的数据集一样。使用转移学习来训练一个"容易的"信号，如直接输出轻度失真踏板似乎对最终模型的影响最小。需要进行更多测试，以确定这些结论是否适用于其他效应和放大器。</p><p id="6b75" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在上述测试中，确定什么构成了类似的发声装置是基于简单地听它，这是主观的。有可能使用人工智能(或其他DSP技术)来首先分析来自目标设备的音频，然后从预训练模型库中确定哪个最接近，以获得最佳结果。</p><p id="baec" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">所有测试都是在特定设置(增益水平、均衡器、音量)下对每个设备的“快照”进行的。可以使用每个设置的训练数据来调节给定参数或参数集的模型。例如，您可以训练增益或驱动旋钮全范围的单个模型。但是，使用模型调节会增加所需的数据量和训练时间。迁移学习可能是减少条件模型训练所需的训练时间和数据量的好方法。</p><p id="3bd9" class="pw-post-body-paragraph kl km jf kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我希望你喜欢阅读这篇文章！关于问题和反馈，你可以发电子邮件到smartguitarml@gmail.com给我。</p></div></div>    
</body>
</html>