<html>
<head>
<title>How to Mitigate Overfitting by Creating Ensembles</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何通过创建系综来减轻过度拟合</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-mitigate-overfitting-by-creating-ensembles-77e9299b9ad0?source=collection_archive---------24-----------------------#2021-09-30">https://towardsdatascience.com/how-to-mitigate-overfitting-by-creating-ensembles-77e9299b9ad0?source=collection_archive---------24-----------------------#2021-09-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="67b8" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">解决过度拟合问题</h2><div class=""/><div class=""><h2 id="0d3e" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">解决过度拟合问题—第4部分</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/40c62d2e3b3cf424cb49129562d9828d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qXknzqGcJ4MYgr3JKM6EhA.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@skyestudios?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">斯凯工作室</a>在<a class="ae lh" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="51ea" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果我们总结一下到目前为止在<strong class="lk jd">“解决过度拟合问题”</strong>系列文章中所做的工作，我们已经讨论了三种可以用来减轻过度拟合的不同技术。正如你已经知道的，<strong class="lk jd">交叉验证</strong>(在<a class="ae lh" rel="noopener" target="_blank" href="/how-to-mitigate-overfitting-with-k-fold-cross-validation-518947ed7428">第一部分</a>中讨论过)、<strong class="lk jd">正则化</strong>(在<a class="ae lh" rel="noopener" target="_blank" href="/how-to-mitigate-overfitting-with-regularization-befcf4e41865">第二部分</a>中讨论过)和<strong class="lk jd">降维</strong>(在<a class="ae lh" rel="noopener" target="_blank" href="/how-to-mitigate-overfitting-with-dimensionality-reduction-555b755b3d66">第三部分</a>中讨论过)可以有效地减轻过拟合。在第4部分中，今天我们讨论另一个有用的技术，叫做<strong class="lk jd">创建合集</strong>。</p><p id="1640" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，这种技术仅限于基于树的模型。有人可以尝试构建决策树模型(步骤1)而不限制树的增长(不提前停止或不做任何超参数调整)。他将得到一个明显过度合身的模型。然后，他可以通过限制树的增长(通过提前停止或超参数调整)来构建相同的模型(步骤2)。这一次，模型不会像前一次那样过度拟合数据。如果他想进一步减轻过拟合，他可以建立一个集成模型(步骤3)，例如，<strong class="lk jd"> <em class="me">随机森林</em> </strong>即不相关决策树的集合。这是我们讨论今天内容所遵循的顺序。</p><p id="d818" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">与单个决策树模型相比，如果我们通过限制每个单独决策树的增长来构建随机森林模型，则随机森林模型不太可能过度拟合数据。请记住，与其他模型相比，随机森林模型可能仍然过拟合。</p><p id="9104" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">与其他模型相比，随机森林不太可能过度拟合数据，这背后的直觉是:</p><blockquote class="mf mg mh"><p id="ed94" class="li lj me lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated">随机森林是通过组合多个不相关的决策树构建的(因此得名，<strong class="lk jd">森林</strong>)。当创建随机森林时，在选择特征和训练实例时将应用额外的随机性(因此得名，<strong class="lk jd">随机</strong>)。由于这些原因，当创建随机森林时，数据和特征被很好地表示(混合)。森林中的每棵树都生成不相关的结果，然后对这些结果进行平均，得到最终结果，这个结果足够强大，可以产生比任何单个决策树更准确和稳定的结果(更少的过拟合)——作者</p></blockquote><p id="7e62" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，我们将进入包含在3个步骤中的编码部分。</p><h1 id="2b93" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">(步骤1):在不限制树增长的情况下构建决策树模型</h1><p id="ec56" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">为此，我们在“<a class="ae lh" href="https://drive.google.com/file/d/19s5qMRjssBoohFb2NY4FFYQ3YW2eCxP4/view?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">心脏病</strong> </a>”数据集上创建决策树模型，而不限制树的增长(不提前停止或不进行任何超参数调整)。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">创建决策树模型，而不限制树的增长</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/416a7458e5ec192f53dd62d81f4fa0b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*uJ0ufF84oRap5G1CTaD6vA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="4f19" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">训练准确率100%。测试精度远低于训练精度。因此，模型明显过拟合。这并不奇怪，因为我们没有限制树木的生长。</p><h1 id="c9cf" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">(步骤2):通过限制树的增长来构建相同的决策树模型</h1><p id="5f91" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">这里，我们将通过设置<strong class="lk jd"> max_depth=3 </strong>来限制树的深度。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">通过限制树的增长来创建相同的决策树模型</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/f45fdba68ebfd7343a2495cbbfdd324d.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*FxE68wJA_95wjoU1TFIuUQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="4695" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这个型号比早期的稍好一些。让我们看看是否可以通过创建一个随机森林(系综)——多个不相关的决策树的搭配——来进一步减轻过度拟合。</p><h1 id="2984" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">(步骤3):构建随机森林</h1><p id="b7b9" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">这里，我们将应用相同的限制标准，<strong class="lk jd"> max_depth=3 </strong>来限制每棵树的深度，然后创建一个随机森林。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">创建随机森林模型</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/a11477dd77f45734dd8e91623257f308.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*9YSQlZRi9oJPtBd0kyd_YA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="be86" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这一次的模式比前两次好很多。它能够很好地概括新的看不见的数据。因此，我们能够通过创建决策树的集合来减轻过度拟合。</p><h1 id="3fbe" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">最后的想法</h1><p id="7bb8" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">到目前为止，我们已经讨论了以下可用于减轻过度拟合的技术:</p><ul class=""><li id="97d6" class="nn no it lk b ll lm lo lp lr np lv nq lz nr md ns nt nu nv bi translated"><strong class="lk jd">交叉验证</strong></li><li id="7781" class="nn no it lk b ll nw lo nx lr ny lv nz lz oa md ns nt nu nv bi translated"><strong class="lk jd">正规化</strong></li><li id="28bd" class="nn no it lk b ll nw lo nx lr ny lv nz lz oa md ns nt nu nv bi translated"><strong class="lk jd">降维</strong></li><li id="2b55" class="nn no it lk b ll nw lo nx lr ny lv nz lz oa md ns nt nu nv bi translated"><strong class="lk jd">创建合奏</strong></li></ul><p id="0034" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">要完成本系列文章，还有一项技术需要讨论。在应用任何技术之前，您应该首先意识到您的模型是过度拟合的。然后，根据您想要构建的数据和模型选择最佳技术。您可以尝试多种技术，看看模型的表现如何。在本系列的最后一部分(第5部分)，我将添加详细的指导原则，帮助您选择最佳技术。同时，你可以练习到目前为止你所学的方法。记住“你知道的不去实践”等于“你不知道”！</p><p id="7964" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">更新(2021–10–05):</strong>第5部分现已推出！<br/> [ <a class="ae lh" rel="noopener" target="_blank" href="/how-to-mitigate-overfitting-with-feature-selection-164897c0c3db">如何通过特征选择减轻过度拟合</a></p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><p id="bbe4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">今天的帖子到此结束。我的读者可以通过下面的链接注册成为会员，以获得我写的每个故事的全部信息，我将收到你的一部分会员费。</p><p id="dfc0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">报名链接:</strong><a class="ae lh" href="https://rukshanpramoditha.medium.com/membership" rel="noopener">https://rukshanpramoditha.medium.com/membership</a></p><p id="ff85" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">非常感谢你一直以来的支持！下一个故事再见。祝大家学习愉快！</p><p id="241d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">特别感谢Unsplash上的<strong class="lk jd"> Skye Studios </strong>，<strong class="lk jd"> </strong>为我提供了一张不错的封面图片(我对图片做了一些修改:添加了一些文字并删除了一些部分)。</p><p id="128c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="oi oj ep" href="https://medium.com/u/f90a3bb1d400?source=post_page-----77e9299b9ad0--------------------------------" rel="noopener" target="_blank">鲁克山普拉莫迪塔</a><br/><strong class="lk jd">2021–09–30</strong></p></div></div>    
</body>
</html>