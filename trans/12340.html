<html>
<head>
<title>How I deployed my first machine learning model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我如何部署我的第一个机器学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-i-deployed-my-first-machine-learning-model-1147c04c449b?source=collection_archive---------15-----------------------#2021-12-15">https://towardsdatascience.com/how-i-deployed-my-first-machine-learning-model-1147c04c449b?source=collection_archive---------15-----------------------#2021-12-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="72c0" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="d19d" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">我用来交付我的第一个商业机器学习模型的流程和工具</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/50301dfc200a170f3da7a737f80e5dc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z-P1ZDZSL8yWbShShdii_w.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://unsplash.com/@dtopkin1?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">戴恩·托普金</a>在<a class="ae le" href="https://unsplash.com/s/photos/start?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="fd18" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated"><strong class="ak"> 1。简介</strong></h1><p id="e5aa" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">我们在机器学习中听到最多的一个词是术语部署。机器学习模型的部署只不过是一个过程，在这个过程中，我们让其他人可以使用机器学习模型，正是在这个阶段，我们看到模型如何成为产品。</p><p id="7f85" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">向用户提供模型时，会出现几个问题，例如:</p><ul class=""><li id="09b4" class="my mz iq lz b ma mt md mu mg na mk nb mo nc ms nd ne nf ng bi translated">模型是如何生产和测试的？</li><li id="b09e" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">如何监控模型？</li><li id="2d32" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">如何更新我的模型？</li><li id="33fa" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">我使用什么框架和工具？</li></ul><p id="ba9d" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">在这篇文章中，我稍微解释了一下部署我的第一个机器学习模型的生产过程，从生产流水线、模型监控、交付给最终用户和持续/交付集成(CI/CD)。目标是直接关注生产过程，解释做出了哪些决定及其原因，以及解释在模型构建过程中使用了哪些工具。在这篇文章中，我们没有任何类型的代码，只是对生产过程的解释。</p><h1 id="ce0f" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated"><strong class="ak"> 2。TFX(张量流扩展)</strong></h1><p id="fc8d" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">这个模型是用TFX<a class="ae le" href="https://www.tensorflow.org/tfx" rel="noopener ugc nofollow" target="_blank">建造的</a>并且大部分应用内容是通过<a class="ae le" href="https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops?" rel="noopener ugc nofollow" target="_blank">面向生产的机器学习工程(MLOps)综合课程项目</a>学习的，这些课程由吴恩达、罗伯特·克劳和劳伦斯·莫罗尼等杰出的专业人士讲授。</p><blockquote class="nm nn no"><p id="b853" class="lx ly np lz b ma mt ka mc md mu kd mf nq mv mi mj nr mw mm mn ns mx mq mr ms ij bi translated">“TFX是基于TensorFlow的谷歌生产规模的机器学习(ML)平台。它提供了一个配置框架和共享库，以集成定义、启动和监控您的机器学习系统所需的通用组件。”根据TFX用户Guide⁴.的说法</p></blockquote><p id="6da0" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><em class="np">但是你为什么选择为你的第一个模型使用一个不那么简单的框架呢？</em></p></div><div class="ab cl nt nu hu nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="ij ik il im in"><p id="0274" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">在生产中处理模型时，MLOps中有三个非常重要的概念。</p><ul class=""><li id="96b8" class="my mz iq lz b ma mt md mu mg na mk nb mo nc ms nd ne nf ng bi translated">数据来源</li></ul><p id="8e6f" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">您的数据来自哪里，如何产生，提交了什么方法和流程。</p><ul class=""><li id="9df8" class="my mz iq lz b ma mt md mu mg na mk nb mo nc ms nd ne nf ng bi translated">数据谱系</li></ul><p id="cdc9" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">它指的是到达管道末端之前的一系列步骤。</p><ul class=""><li id="68a8" class="my mz iq lz b ma mt md mu mg na mk nb mo nc ms nd ne nf ng bi translated">[计]元数据</li></ul><p id="1e37" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">是数据描述数据。它们用来解释我们正在看的物品的特征。例如，如果我们正在查看一张照片，元数据可能是照片拍摄的时间、相机设置、照片拍摄者等等。</p><p id="bd1f" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja">这三个部分是生产模型</strong> <strong class="lz ja">的关键，因为它们有助于跟踪模型生命周期中发生的变化</strong>。假设我们有一个团队来收集和清理数据，另一个团队来管理接收，另一个团队来创建/测试模型，还有一个团队来部署它。有许多人在不同的环境中处理不同的文件，如果没有有效地完成，这会使变更跟踪过程变得非常复杂。</p><p id="2fa6" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">假设我们将模型投入生产，但是在几个版本之后我们发现在清理数据时出现了错误。我们如何跟踪数据版本，执行了什么转换，模型的属性是什么？我们如何再现之前提交数据的相同环境？</p><p id="ed6a" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja">这就是为什么使用对这些过程有某种支持的框架是很重要的。</strong>开发TFX是为了在生产环境中构建和管理工作流。因此，TFX的三个主要组成部分是:</p><ul class=""><li id="8758" class="my mz iq lz b ma mt md mu mg na mk nb mo nc ms nd ne nf ng bi translated">管道</li><li id="6b92" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">成分</li><li id="2020" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">图书馆</li></ul><h2 id="faf4" class="oa lg iq bd lh ob oc dn ll od oe dp lp mg of og lr mk oh oi lt mo oj ok lv iw bi translated"><strong class="ak"> 2.1管道</strong></h2><p id="c867" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">为了确保数据遵循逻辑顺序的步骤，有管道。TFX管道包含一系列组件，它是为可伸缩和高性能的机器学习任务而设计的。在管道内部，您可以转换数据、训练模型、部署、显示推论等等。TFX支持多个orchestrators，例如Apache Airflow、Apache Beam和Kubeflow管道。</p><h2 id="c025" class="oa lg iq bd lh ob oc dn ll od oe dp lp mg of og lr mk oh oi lt mo oj ok lv iw bi translated"><strong class="ak"> 2.2组件</strong></h2><p id="4ea7" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">我喜欢把组件想象成乐高积木。您可以单独或一起使用它，每个组件都是为特定的任务而设计的。有些组件依赖于另一个组件的输出，因此您必须按照逻辑顺序使用它们。</p><p id="ec9d" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">为了理解我们的管道是如何组装的，我们首先需要理解它的组件。TFX有几个教程解释如何使用这些组件。通常，TFX管道包括以下<a class="ae le" href="https://www.tensorflow.org/tfx/guide?hl=en-us#tfx_standard_components" rel="noopener ugc nofollow" target="_blank">组件</a>:</p><ul class=""><li id="aa97" class="my mz iq lz b ma mt md mu mg na mk nb mo nc ms nd ne nf ng bi translated"><a class="ae le" href="https://www.tensorflow.org/tfx/guide/examplegen?hl=en-us" rel="noopener ugc nofollow" target="_blank"> ExampleGen </a>在开始时出现，将数据分成训练和评估数据集，将其转换为“tf”。“示例”格式。它接受不同的格式，如CSV、TFRecord、Avro、Parquet和BigQuery。</li><li id="c5c7" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated"><a class="ae le" href="https://www.tensorflow.org/tfx/guide/statsgen?hl=en-us" rel="noopener ugc nofollow" target="_blank"> StatisticsGen </a>负责计算数据集的统计数据，如分布、最大值、最小值、缺失值等。</li><li id="b8ab" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated"><a class="ae le" href="https://www.tensorflow.org/tfx/guide/schemagen?hl=en-us" rel="noopener ugc nofollow" target="_blank"> SchemaGen </a>创建一个数据模式。它显示了每个功能的预期数据类型。</li><li id="a331" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated"><a class="ae le" href="https://www.tensorflow.org/tfx/guide/exampleval?hl=en-us" rel="noopener ugc nofollow" target="_blank">示例验证器</a>在训练和评估数据集中寻找异常(与预期值不同的值)和缺失值，例如检测训练服务偏差。</li><li id="ff91" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated"><a class="ae le" href="https://www.tensorflow.org/tfx/guide/transform?hl=en-us" rel="noopener ugc nofollow" target="_blank"> Transform </a>负责执行我们模型中变量的所有转换/创建。该组件的一个重要之处在于，它生成一个存储数据全局属性的图表，这些属性将用于训练和推理，从而提供可靠性。</li><li id="4e03" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated"><a class="ae le" href="https://www.tensorflow.org/tfx/guide/trainer?hl=en-us" rel="noopener ugc nofollow" target="_blank">培训师</a>培训模特。在这个组件中，除了定义模型的整个架构之外，我们还指定了模型将在哪里以及如何被训练。</li><li id="0942" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated"><a class="ae le" href="https://www.tensorflow.org/tfx/guide/tuner?hl=en-us" rel="noopener ugc nofollow" target="_blank">调谐器</a>调谐模型的超参数。调谐器可以在管道的所有执行中执行，或者如果您只想不时地执行超参数的调整，也可以导入它。</li><li id="a897" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated"><a class="ae le" href="https://www.tensorflow.org/tfx/guide/evaluator?hl=en-us" rel="noopener ugc nofollow" target="_blank">评估员</a>深度评估模型的性能。它还可以验证您的模型，允许您对数据的特定子集进行度量，确保模型足够好，可以推向生产。</li><li id="687b" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated"><a class="ae le" href="https://www.tensorflow.org/tfx/guide/pusher?hl=en-us" rel="noopener ugc nofollow" target="_blank">推送器</a>将经过验证的模型推送到<a class="ae le" href="https://www.tensorflow.org/tfx/guide#deployment_targets" rel="noopener ugc nofollow" target="_blank">部署目标</a>。这是我们指定模型将被服务的地方。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ol"><img src="../Images/19d70874406909b83b1c0e4c958b45b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9VjWKD8W97Pn9CPoga2_pw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><strong class="bd om">图一。</strong> TFX管道。这张图片是从谷歌创作和<a class="ae le" href="https://developers.google.com/readme/policies" rel="noopener ugc nofollow" target="_blank">分享的作品中复制的，并根据</a><a class="ae le" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank">知识共享4.0归属许可</a>中描述的条款使用。来源:<a class="ae le" href="https://www.tensorflow.org/tfx/guide" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tfx/guide</a></p></figure><h2 id="0639" class="oa lg iq bd lh ob oc dn ll od oe dp lp mg of og lr mk oh oi lt mo oj ok lv iw bi translated"><strong class="ak"> 2.3库</strong></h2><p id="fa57" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">库是为组件提供功能的基础。</p><blockquote class="nm nn no"><p id="3aeb" class="lx ly np lz b ma mt ka mc md mu kd mf nq mv mi mj nr mw mm mn ns mx mq mr ms ij bi translated">基本上，TFX管道是由组件组成的，而组件又是由库组成的。</p></blockquote><h1 id="c717" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated"><strong class="ak"> 3。实验跟踪和管理</strong></h1><p id="a0ab" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">在建立模型的过程中，我认为非常重要的一步是实验跟踪和管理。在构建模型时，您将运行几个实验，包括:</p><ul class=""><li id="4cef" class="my mz iq lz b ma mt md mu mg na mk nb mo nc ms nd ne nf ng bi translated">具有不同超参数的不同模型</li><li id="9161" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">不同的培训和测试数据</li><li id="cc35" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">不同的特征</li><li id="446b" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">对代码的细微更改</li></ul><p id="c123" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">这些不同的实验会产生不同的指标。<strong class="lz ja">记录所有这些信息不是一项简单的任务，而是一项非常重要的任务</strong>，主要是跟踪模型的进展，比较不同的实验以对最终结果有信心。</p><p id="92e9" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">这就是实验跟踪和管理的用武之地。在这个过程中，我们保存所有对我们进行的每个实验都很重要的信息。每个项目都有自己的一组需要保存的重要信息，包括:</p><ul class=""><li id="2520" class="my mz iq lz b ma mt md mu mg na mk nb mo nc ms nd ne nf ng bi translated">每个文件使用的代码</li><li id="20c8" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">环境设置</li><li id="1f54" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">数据集版本</li><li id="ea30" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">超参数设置</li><li id="7d55" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">性能指标</li><li id="1eb7" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">使用的模型类型</li></ul><p id="b5c4" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">有几种方法可以保存这些信息，<strong class="lz ja">但是</strong> <strong class="lz ja">对于大型项目来说，控制正在做的事情是非常重要的</strong>。为此，有几个工具可用，如<a class="ae le" href="https://www.comet.ml/site/" rel="noopener ugc nofollow" target="_blank"> CometML </a>、<a class="ae le" href="https://www.wandb.com/" rel="noopener ugc nofollow" target="_blank">权重和偏差(WandB) </a>、<a class="ae le" href="https://mlflow.org/" rel="noopener ugc nofollow" target="_blank"> MLFlow </a>。</p><p id="a1ed" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">在我们的项目中，我们选择使用海王星。</p><blockquote class="nm nn no"><p id="c1b0" class="lx ly np lz b ma mt ka mc md mu kd mf nq mv mi mj nr mw mm mn ns mx mq mr ms ij bi translated">“Neptune是任何MLOps工作流的元数据存储。它是为进行大量实验的研究和生产团队设计的。它让您可以在一个地方监控、可视化和比较数以千计的ML模型。”根据Patrycja⁸的观点</p></blockquote><p id="5d86" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">Neptune支持实验跟踪、模型注册和模型监控，其设计方式允许轻松协作。它还具有<a class="ae le" href="https://docs.neptune.ai/integrations-and-supported-tools/model-training/tensorflow-keras" rel="noopener ugc nofollow" target="_blank"> TensorFlow integration </a>，使得在一个地方监控所有实验变得非常简单。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi on"><img src="../Images/daeb101d9d3cf8b93edd743c086e3aa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IyxVcJf_zO5B6WnbHvVo5Q.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><strong class="bd om">图二。</strong>海王星运行(图片由作者提供)。</p></figure><h1 id="d207" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated"><strong class="ak"> 4。顶点AI + TFX管线</strong></h1><p id="8bea" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">当我们部署一个模型时，我们需要考虑如何将它提供给我们的最终用户。在我们的例子中，我们需要通过API使模型可用，这样我们就可以发送请求和接收响应。</p><p id="4117" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">为了建立我们的管道，我们选择与谷歌云合作。作为一名管弦乐手，我们使用Kubeflow管道，因为大多数教程都是通过它完成的。有几个教程教你如何在云中集成TFX管道，如[1]、[2]和[3]。</p><p id="3847" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja">我们决定使用</strong> <a class="ae le" href="https://cloud.google.com/vertex-ai" rel="noopener ugc nofollow" target="_blank"> <strong class="lz ja">顶点人工智能</strong> </a>，谷歌新的人工智能平台平台来建立我们的管道。我们选择Vertex AI有两个原因:</p><ul class=""><li id="685c" class="my mz iq lz b ma mt md mu mg na mk nb mo nc ms nd ne nf ng bi translated">与人工智能平台管道相比，它更便宜(在我们的情况下)。顶点流水线不需要集群一直处于活动状态，成本按每次运行收取，并且与用于训练/预测模型的计算资源的使用相关联。</li><li id="3c62" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">不像<a class="ae le" href="https://cloud.google.com/google/kubernetes" rel="noopener ugc nofollow" target="_blank"> GKE </a>(谷歌Kubernetes引擎)，我们不需要管理我们组件的基础设施/服务器/健康状况，因为它是一个自我管理的平台。</li></ul><p id="4fa3" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">根据<a class="ae le" href="https://cloud.google.com/vertex-ai/docs/pipelines/build-pipeline" rel="noopener ugc nofollow" target="_blank">文档</a>，Vertex AI管道可以运行使用Kubeflow Pipelines SDK v1.8.9或更高版本或TensorFlow Extended v0.30.0或更高版本创建的管道。</p><p id="ff81" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja">虽然我们的流水线运行在Vertex AI上，但我们选择在</strong> <a class="ae le" href="https://cloud.google.com/ai-platform/docs/" rel="noopener ugc nofollow" target="_blank"> <strong class="lz ja"> AI平台</strong> </a>上训练和服务我们的模型。Vertex AI是一个最新的平台，其局限性将随着时间的推移而改善，因此，在撰写本文时，有一些重要的特性还不存在于被服务的模型中，例如在发出<a class="ae le" href="https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/predict" rel="noopener ugc nofollow" target="_blank"> predict请求</a>时指定一个<a class="ae le" href="https://www.tensorflow.org/guide/saved_model" rel="noopener ugc nofollow" target="_blank"> SavedModel </a> TensorFlow的签名。</p><p id="31d6" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">每个组件负责TFX管道中的一项任务，并且通常一个组件依赖于另一个组件的输出。在我们的例子中，我们选择不使用InfraValidator和BulkInferrer组件。然而，我们选择在管道中增加一个节点，即<a class="ae le" href="https://www.tensorflow.org/tfx/api_docs/python/tfx/v1/dsl/Resolver?hl=th" rel="noopener ugc nofollow" target="_blank">解析器</a>。Resolver是一个特殊的TFX节点，用于处理特殊工件的求解，在我们的例子中，它用于将最新的基础模型指定到评估器组件中。</p><p id="11f3" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">所以我们的顶点管道是这样构成的:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oo"><img src="../Images/89bba36debcf78a52bad01071f186e09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qS_ziE764uF1EIz8wEIhxw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><strong class="bd om">图三。</strong> Vertex AI管道(图片由作者提供)。这张图片是基于谷歌创作和分享的<a class="ae le" href="https://developers.google.com/readme/policies" rel="noopener ugc nofollow" target="_blank">作品的修改，并根据</a><a class="ae le" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank">知识共享4.0归属许可</a>中描述的条款使用。来源:<a class="ae le" href="https://www.tensorflow.org/tfx/guide" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tfx/guide</a></p></figure><h1 id="cee8" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated"><strong class="ak"> 5。监控</strong></h1><p id="857d" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">一旦管道被执行，我们的模型将可用于预测。然而，这并不意味着我们的工作已经结束，而是刚刚开始。当您在生产中部署一个ML模型以服务于业务用例时，<strong class="lz ja">定期地、主动地验证模型性能不会衰退是至关重要的。</strong>由于模型不在静态环境中运行，ML模型的性能会随着时间的推移而降低。数据分布可能会发生变化，导致数据不对称，从而影响模型的性能。为了维护模型在生产中的性能，有必要注册服务请求并将其与定型数据进行比较，以验证模型的预测能力是否发生了变化。</p><p id="1120" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">所以，我们需要监控模型。我们已经选择从我们的模型中<a class="ae le" href="https://cloud.google.com/architecture/ml-modeling-monitoring-logging-serving-requests-using-ai-platform-prediction" rel="noopener ugc nofollow" target="_blank">记录服务请求</a>，这个过程以raw (JSON)格式记录在线预测请求和对<a class="ae le" href="https://cloud.google.com/bigquery/docs" rel="noopener ugc nofollow" target="_blank"> BigQuery </a>表的响应的示例。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi op"><img src="../Images/28131dba5f9ce07351730ddb89ff6b7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*epQZGauFpyAjuUa0kQqbpA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><strong class="bd om">图4。</strong>监控架构。这张图片是从谷歌创作和<a class="ae le" href="https://developers.google.com/readme/policies" rel="noopener ugc nofollow" target="_blank">分享的作品中复制的，并根据</a><a class="ae le" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank">知识共享4.0归属许可</a>中描述的条款使用。来源:<a class="ae le" href="https://cloud.google.com/architecture/ml-modeling-monitoring-analyzing-ai-platform-prediction-in-big-query" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/architecture/ml-建模-监控-分析-ai-平台-预测-大查询</a></p></figure><p id="06ae" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja">有了这些记录，我们就可以分析数据、计算统计数据并可视化数据的偏差。</strong>这一过程对于模型的健康发展至关重要，提供数据会改变其分布，这将导致我们的模型性能下降，表明有必要重新训练/调整模型。由于数据将被注册到BigQuery表中，因此生成关于数据分布和模型预测的可视化和报告非常容易，要使用的工具的一个例子是<a class="ae le" href="https://datastudio.google.com/c/navigation/reporting" rel="noopener ugc nofollow" target="_blank"> Data Studio </a>。</p><h1 id="8780" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated"><strong class="ak"> 6。CI/CD </strong></h1><p id="db34" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">现在，让我们进入项目的最后一步。假设我们有几十个模型，生产中有数百个文件，并且我们定期需要进行调整，例如调整数据集、创建变量、重新训练模型、调整超参数等。我们如何自动化这个过程，以便检测、测试任何设计变更，并自动部署新模型？</p><blockquote class="nm nn no"><p id="0fcd" class="lx ly np lz b ma mt ka mc md mu kd mf nq mv mi mj nr mw mm mn ns mx mq mr ms ij bi translated">“在软件工程中，持续集成(CI)和持续交付(CD)是两个非常重要的概念。CI是指集成变更(新特性、批准的代码提交等。)进入你的系统。CD是您可靠地、持续地部署这些变更的时候。CI和CD既可以单独执行，也可以耦合执行。”根据P. Chansung的说法；Sayak⁶</p></blockquote><p id="a39b" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">CI/CD管道允许我们的软件处理代码变更、测试、交付等等。我们可以自动化实施变更、测试和交付的流程，以便检测、测试项目的任何变更，并自动部署新模型。<strong class="lz ja">这使得我们的系统除了提供速度和可靠性之外，还可以扩展和适应变化</strong>，减少由于重复故障导致的错误。如果你想了解更多关于CI/CD的重要性以及为什么你的项目需要它，请查看<a class="ae le" href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。</p><p id="2d14" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">在此项目中，我们创建了以下CI/CD管道:</p><ol class=""><li id="e184" class="my mz iq lz b ma mt md mu mg na mk nb mo nc ms oq ne nf ng bi translated">我们在Github上创建了一个存储库，包含了将在Vertex AI上运行的TFX管道的所有代码。</li><li id="aa15" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms oq ne nf ng bi translated">我们已经在GitHub Actions上建立了一个工作流，它将在每次推送到主分支时触发，并将检查我们存储库中特定目录的更改。</li><li id="13d0" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms oq ne nf ng bi translated">如果包含与管道配置相关的文件的目录发生变化，流程将启动<a class="ae le" href="https://cloud.google.com/build" rel="noopener ugc nofollow" target="_blank">云构建过程</a>，该过程将克隆整个存储库，基于代码变化构建新的Docker映像，将新映像上传到<a class="ae le" href="https://cloud.google.com/container-registry" rel="noopener ugc nofollow" target="_blank"> Google容器注册表</a>，并在Vertex AI中提交TFX管道。</li></ol><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi or"><img src="../Images/41f50fbe804a21df2b67ad41dbe50c0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yx_Cx39fTBHkn5GTPeJCrQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><strong class="bd om">图5。</strong>整个管道的CI/CD。本图片转载自P. Chansung创作并分享的作品<a class="ae le" href="https://github.com/deep-diver/Model-Training-as-a-CI-CD-System" rel="noopener ugc nofollow" target="_blank">；P. Sayak </a>并根据<a class="ae le" href="https://www.apache.org/licenses/LICENSE-2.0" rel="noopener ugc nofollow" target="_blank"> Apache 2.0许可证</a>中描述的条款使用。来源:<a class="ae le" href="https://cloud.google.com/blog/topics/developers-practitioners/model-training-cicd-system-part-i" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/blog/topics/developers-从业者/模型-培训-cicd-system-part-i </a></p></figure><p id="3bbc" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">4.如果目录中存在包含对模型代码、预处理或训练数据的改变的改变，则流程将启动云构建过程，该过程将克隆整个储存库，仅将改变的模块复制到<a class="ae le" href="https://cloud.google.com/storage/docs" rel="noopener ugc nofollow" target="_blank"> GCS桶</a>中的目录模块，并在Vertex AI中提交TFX管道，而无需构建新的Docker映像。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi or"><img src="../Images/b6db65a1607e58aa3719e2a8a9e98faf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fvNF9kQ3Vdnt3fl4fQ4Oxw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><strong class="bd om">图6。</strong> CI/CD用于数据预处理和建模模块。本图片转载自P. Chansung创作并分享的作品<a class="ae le" href="https://github.com/deep-diver/Model-Training-as-a-CI-CD-System" rel="noopener ugc nofollow" target="_blank">；P. Sayak </a>并根据<a class="ae le" href="https://www.apache.org/licenses/LICENSE-2.0" rel="noopener ugc nofollow" target="_blank"> Apache 2.0许可证</a>中描述的条款使用。来源:<a class="ae le" href="https://cloud.google.com/blog/topics/developers-practitioners/model-training-cicd-system-part-i" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/blog/topics/developers-从业者/模型-培训-cicd-system-part-i </a></p></figure><p id="840a" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">配置好管道后，<strong class="lz ja">任何对存储库的推送都将激活GitHub Actions </strong>，它将检查变更并自动运行管道，自动部署我们的模型。需要强调的是，TFX管道将正常遵循流程，也就是说，例如，如果候选模型没有得到评估者的批准，那么该模型将不会被部署。</p><p id="3599" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">CI/CD管道还有其他一些可能的改进，例如:</p><ul class=""><li id="3077" class="my mz iq lz b ma mt md mu mg na mk nb mo nc ms nd ne nf ng bi translated">培训数据验证</li><li id="5c17" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">不同模块的单元测试，如可接受的数据类型、预期的数据量等。</li><li id="8ca8" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">测试模型输出是否不产生空值</li><li id="d3b9" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">通过使用测试数据调用服务API来测试预测服务，以验证模型是否正常工作</li><li id="066c" class="my mz iq lz b ma nh md ni mg nj mk nk mo nl ms nd ne nf ng bi translated">预生产环境的自动部署，例如，在审阅者批准变更后，代码合并触发的主分支的部署</li></ul><h1 id="b407" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated"><strong class="ak"> 7。结论</strong></h1><p id="03eb" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">部署机器学习模型并将其提供给用户并不是一件容易的事情，构建模型只是第一步。部署我们的第一个机器学习模型并保持我们模型的性能，我们需要监控您的预测并提供替代方案，使我们的流程可扩展并适应变化。此外，我们保留有关管道执行的数据是很重要的，这样我们的过程是可重复的，并且纠错过程是有效的。使用支持该过程的工具对于抽象项目的复杂性是必不可少的，使其更具可伸缩性和更易于维护。</p><h1 id="0f70" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated"><strong class="ak"> 8。参考文献</strong></h1><p id="c0ab" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">[1] <a class="ae le" href="https://www.tensorflow.org/tfx/tutorials/tfx/cloud-ai-platform-pipelines" rel="noopener ugc nofollow" target="_blank"> <strong class="lz ja">云上TFX AI平台管道</strong></a><strong class="lz ja"/>(2021年11月05日)，TensorFlow。</p><p id="6cd7" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">[2] O. Rising，<a class="ae le" href="https://neptune.ai/blog/deep-dive-into-ml-models-in-production-using-tfx-and-kubeflow" rel="noopener ugc nofollow" target="_blank"> <strong class="lz ja">深度潜入ML模型在生产中使用TensorFlow Extended (TFX)和kube flow</strong></a><strong class="lz ja"/>(2021年11月12日)，海王星博客。</p><p id="e298" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">[3] <a class="ae le" href="https://www.tensorflow.org/tfx/tutorials/tfx/gcp/vertex_pipelines_simple" rel="noopener ugc nofollow" target="_blank"> <strong class="lz ja">简单TFX管道为顶点管道</strong></a><strong class="lz ja"/>(2021年12月08日)，TensorFlow。</p><p id="d427" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><a class="ae le" href="https://www.tensorflow.org/tfx/guide" rel="noopener ugc nofollow" target="_blank"><strong class="lz ja">【TFX用户指南】</strong></a><strong class="lz ja"/>(2021年12月14日)，TensorFlow。</p><p id="809b" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">[5] <a class="ae le" href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning" rel="noopener ugc nofollow" target="_blank"> <strong class="lz ja"> MLOps:机器学习中的连续交付和自动化管道</strong></a><strong class="lz ja"/>(2020年01月07日)，谷歌。</p><p id="432d" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">[6]陈松；P. Sayak，<a class="ae le" href="https://cloud.google.com/blog/topics/developers-practitioners/model-training-cicd-system-part-i" rel="noopener ugc nofollow" target="_blank"> <strong class="lz ja">作为CI/CD系统的模型训练:第一部分</strong></a>(2021年10月6日)，谷歌。</p><p id="f762" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">[7] <a class="ae le" href="https://cloud.google.com/architecture/ml-modeling-monitoring-logging-serving-requests-using-ai-platform-prediction" rel="noopener ugc nofollow" target="_blank"> <strong class="lz ja"> ML模型监控:利用AI平台预测</strong></a><strong class="lz ja"/>(2021年3月12日)，Google。</p><p id="e5cd" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">[8] J. Patrycja，<a class="ae le" href="https://neptune.ai/blog/best-ml-experiment-tracking-tools" rel="noopener ugc nofollow" target="_blank"><strong class="lz ja">ML实验跟踪管理的15个最佳工具</strong></a><strong class="lz ja"/>(2021年10月25日)，海王博客。</p></div></div>    
</body>
</html>