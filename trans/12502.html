<html>
<head>
<title>Exploration of Deep Learning pipelines made easy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习管道的探索变得容易</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/exploration-of-deep-learning-pipelines-made-easy-e1cf649892bc?source=collection_archive---------31-----------------------#2021-12-21">https://towardsdatascience.com/exploration-of-deep-learning-pipelines-made-easy-e1cf649892bc?source=collection_archive---------31-----------------------#2021-12-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1a9b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">关于如何使用正确的包在 Python 中执行快速 DL 实验的简单指南</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/3feae77cdc5753205297895e5872aeb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zYA5v4v7Lk18dLdW"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">艾莉娜·格鲁布尼亚克在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="76a7" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="0bff" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在项目的探索阶段，数据科学家试图为他的特定用例找到最佳的管道。在这个故事中，我将解释如何使用<a class="ae kv" href="https://github.com/tvdboom/ATOM" rel="noopener ugc nofollow" target="_blank"> ATOM </a>包来快速帮助你在任何给定的数据集上训练和评估深度学习模型。ATOM 是一个开源的 Python 包，旨在帮助数据科学家加快机器学习管道的探索。如果你想对图书馆有一个温和的介绍，请阅读这个故事。</p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h1 id="150a" class="kw kx iq bd ky kz mr lb lc ld ms lf lg jw mt jx li jz mu ka lk kc mv kd lm ln bi translated">例子</h1><p id="b611" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">展示 ATOM 如何帮助您的最简单方法是通过一个示例。这个故事带你浏览一个笔记本，它训练并验证了一个用<a class="ae kv" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>实现的卷积神经网络。该模型使用<a class="ae kv" href="https://keras.io/api/datasets/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST </a>进行训练，这是一个众所周知的图像数据集，其目标是对手写数字进行分类。</p><p id="e9dc" class="pw-post-body-paragraph lo lp iq lq b lr mw jr lt lu mx ju lw lx my lz ma mb mz md me mf na mh mi mj ij bi translated">我们从必要的导入和定义模型开始:一个简单的神经网络，具有两个卷积层和一个输出层，由 10 个神经元组成，每个神经元对应一个数字。数据集包含 28x28 灰度图像，因此每个图像的数组都有形状(28，28，1)。之后，我们加载数据集。请注意，我们需要对数据进行整形，以与模型的输入保持一致。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="3908" class="ng kx iq nc b gy nh ni l nj nk">from atom import ATOMClassifier, ATOMModel<br/>from keras.datasets import mnist<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Flatten, Conv2D<br/>from keras.wrappers.scikit_learn import KerasClassifier</span><span id="8ffb" class="ng kx iq nc b gy nl ni l nj nk"><em class="nm"><br/># Create the convolutional neural network</em><br/>def neural_network():<br/>    model = Sequential()<br/>    model.add(<br/>        Conv2D(<br/>            filters=64,<br/>            kernel_size=3,<br/>            activation="relu",<br/>            input_shape=(28, 28, 1),<br/>        )<br/>    )<br/>    model.add(Conv2D(filters=64, kernel_size=3, activation="relu"))<br/>    model.add(Flatten())<br/>    model.add(Dense(units=10, activation="softmax"))<br/>    model.compile(<br/>        optimizer="adam",<br/>        loss="categorical_crossentropy",<br/>        metrics=["accuracy"],<br/>    )<br/><br/>    return model</span><span id="593b" class="ng kx iq nc b gy nl ni l nj nk"><em class="nm"># Download the MNIST dataset</em><br/>(X_train, y_train), (X_test, y_test) <strong class="nc ir">=</strong> mnist<strong class="nc ir">.</strong>load_data()</span><span id="afea" class="ng kx iq nc b gy nl ni l nj nk"><em class="nm"># Reshape data to fit model</em><br/>X_train <strong class="nc ir">=</strong> X_train<strong class="nc ir">.</strong>reshape(60000,28,28,1)<br/>X_test <strong class="nc ir">=</strong> X_test<strong class="nc ir">.</strong>reshape(10000,28,28,1)<br/><br/>data <strong class="nc ir">=</strong> (X_train, y_train), (X_test, y_test)</span></pre><p id="619d" class="pw-post-body-paragraph lo lp iq lq b lr mw jr lt lu mx ju lw lx my lz ma mb mz md me mf na mh mi mj ij bi translated">因为 ATOM 使用 sklearn 的 API，所以我们为我们的模型使用了<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/wrappers/scikit_learn/KerasClassifier" rel="noopener ugc nofollow" target="_blank"> KerasClassifier </a>包装器。然后，我们将模型传递给<a class="ae kv" href="https://tvdboom.github.io/ATOM/API/ATOM/atommodel/" rel="noopener ugc nofollow" target="_blank"> ATOMModel </a>函数，该函数向类添加一个名称和一个缩写词(用于从 atom 中访问模型)。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="f26e" class="ng kx iq nc b gy nh ni l nj nk"># Wrap the model to use sklearn’s API<br/>model <strong class="nc ir">=</strong> KerasClassifier(neural_network, verbose=0)<br/><br/><em class="nm"># Add useful attributes to the model</em><br/>model <strong class="nc ir">=</strong> ATOMModel(model, acronym<strong class="nc ir">=</strong>"NN", fullname<strong class="nc ir">=</strong>"Neural network")</span></pre><p id="c1dd" class="pw-post-body-paragraph lo lp iq lq b lr mw jr lt lu mx ju lw lx my lz ma mb mz md me mf na mh mi mj ij bi translated">现在我们已经准备好了模型，让我们从 atom 的管道开始。我们初始化 ATOM，以(X_train，y_train)，(X_test，y_test)的形式提供我们想要训练的数据。注意，我们只使用了 10%的数据来加速计算。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="f69f" class="ng kx iq nc b gy nh ni l nj nk">atom = ATOMClassifier(*data, n_rows=0.1, warnings=False, verbose=2)</span></pre><p id="d07f" class="pw-post-body-paragraph lo lp iq lq b lr mw jr lt lu mx ju lw lx my lz ma mb mz md me mf na mh mi mj ij bi translated">输出显示了数据集及其类别分布的概述。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="82c3" class="ng kx iq nc b gy nh ni l nj nk">&lt;&lt; ================== ATOM ================== &gt;&gt;<br/>Algorithm task: multiclass classification.<br/>Parallel processing with 10 cores.<br/><br/>Dataset stats ==================== &gt;&gt;<br/>Shape: (7000, (28, 28, 1), 2)<br/>-------------------------------------<br/>Train set size: 6000<br/>Test set size: 1000<br/>-------------------------------------<br/>|    |     dataset |       train |        test |<br/>| -- | ----------- | ----------- | ----------- |<br/>| 0  |   745 (1.2) |   614 (1.1) |   131 (1.5) |<br/>| 1  |   764 (1.2) |   668 (1.2) |    96 (1.1) |<br/>| 2  |   694 (1.1) |   584 (1.1) |   110 (1.2) |<br/>| 3  |   679 (1.1) |   589 (1.1) |    90 (1.0) |<br/>| 4  |   701 (1.1) |   612 (1.1) |    89 (1.0) |<br/>| 5  |   631 (1.0) |   542 (1.0) |    89 (1.0) |<br/>| 6  |   714 (1.1) |   604 (1.1) |   110 (1.2) |<br/>| 7  |   714 (1.1) |   616 (1.1) |    98 (1.1) |<br/>| 8  |   641 (1.0) |   548 (1.0) |    93 (1.0) |<br/>| 9  |   717 (1.1) |   623 (1.1) |    94 (1.1) |</span></pre><p id="8a97" class="pw-post-body-paragraph lo lp iq lq b lr mw jr lt lu mx ju lw lx my lz ma mb mz md me mf na mh mi mj ij bi translated">当输入数据超过 2 维时，ATOM 会将数据集转换为只有一个形状特征的数据帧(n_samples，shape_sample)。该特征被自动称为<em class="nm">多维特征</em>。这就是为什么形状被表示为(7000，(28，28，1)，2)。请注意，末尾的 2 代表数据集包含的两列:功能列和目标列。让我们快速检查一下这个看起来怎么样。</p><p id="decd" class="pw-post-body-paragraph lo lp iq lq b lr mw jr lt lu mx ju lw lx my lz ma mb mz md me mf na mh mi mj ij bi translated"><code class="fe nn no np nc b">atom.dataset.head()</code></p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="90a2" class="ng kx iq nc b gy nh ni l nj nk">Multidimensional feature                              Target<br/>0  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...       5<br/>1  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...       8<br/>2  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...       8<br/>3  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...       3<br/>4  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...       9</span></pre><p id="c488" class="pw-post-body-paragraph lo lp iq lq b lr mw jr lt lu mx ju lw lx my lz ma mb mz md me mf na mh mi mj ij bi translated">列中的每一行都包含一个 shape=(28，28，1)的数组，该数组中的数据对应于一幅图像。</p><p id="c4d1" class="pw-post-body-paragraph lo lp iq lq b lr mw jr lt lu mx ju lw lx my lz ma mb mz md me mf na mh mi mj ij bi translated">现在我们准备开始训练。为了自动执行超参数调整，我们首先定义我们想要在其中尝试参数的自定义空间。ATOM 使用<a class="ae kv" href="https://tvdboom.github.io/ATOM/user_guide/training/#hyperparameter-tuning" rel="noopener ugc nofollow" target="_blank">贝叶斯优化算法进行超参数调整</a>。确保超参数空间与<a class="ae kv" href="https://scikit-optimize.github.io/stable/" rel="noopener ugc nofollow" target="_blank"> skopt 的 API </a>一致。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="1d36" class="ng kx iq nc b gy nh ni l nj nk">from skopt.space.space import Integer, Categorical</span><span id="ac36" class="ng kx iq nc b gy nl ni l nj nk">hyperparameter_space <strong class="nc ir">=</strong> [<br/>    Integer(1, 10, name<strong class="nc ir">=</strong>"epochs"),<br/>    Categorical([32, 64, 128, 256], name<strong class="nc ir">=</strong>"batch_size"),<br/>]</span></pre><p id="59f4" class="pw-post-body-paragraph lo lp iq lq b lr mw jr lt lu mx ju lw lx my lz ma mb mz md me mf na mh mi mj ij bi translated">下一步是训练模型。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="f0e0" class="ng kx iq nc b gy nh ni l nj nk">atom<strong class="nc ir">.</strong>run(<br/>    models=model,  # Our neural network<br/>    metric<strong class="nc ir">=</strong>"f1_weighted",<br/>    n_calls<strong class="nc ir">=</strong>25,  # Number of trials of the optimizer<br/>    n_initial_points=10,  # Number of initial random trials<br/>    bo_params<strong class="nc ir">=</strong>{"dimensions": hyperparameter_space},<br/>)</span></pre><p id="36e4" class="pw-post-body-paragraph lo lp iq lq b lr mw jr lt lu mx ju lw lx my lz ma mb mz md me mf na mh mi mj ij bi translated">输出如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/b6835763c70bf6620d1d2245811bf589.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*heTnHTjPQY9-1hdKxJ1QXQ.png"/></div></div></figure><p id="f970" class="pw-post-body-paragraph lo lp iq lq b lr mw jr lt lu mx ju lw lx my lz ma mb mz md me mf na mh mi mj ij bi translated">就这样，使用优化器找到的最佳超参数来训练模型。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="259a" class="ng kx iq nc b gy nh ni l nj nk">atom.evaluate()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/c6531e5cb14418cb2161876fedc9ce50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*KyFJBv5X4rdFGG5hWSpgZQ.png"/></div></div></figure><p id="94ea" class="pw-post-body-paragraph lo lp iq lq b lr mw jr lt lu mx ju lw lx my lz ma mb mz md me mf na mh mi mj ij bi translated">可以通过我们定义的缩写词 nn 从 atom 访问该模型。</p><pre class="kg kh ki kj gt nb nc nd ne aw nf bi"><span id="7dbd" class="ng kx iq nc b gy nh ni l nj nk">atom.nn.plot_confusion_matrix()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/d83394c4e5b81fe379b33338fef67c79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*2N3a9La4G6TrA76He1U3FQ.png"/></div></figure></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h1 id="0e56" class="kw kx iq bd ky kz mr lb lc ld ms lf lg jw mt jx li jz mu ka lk kc mv kd lm ln bi translated">结论</h1><p id="18a4" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们已经学习了如何使用 ATOM 包来快速探索神经网络在给定数据集上的表现。然而，这个例子非常简单。ATOM 的能力远不止这些！其他有用的功能有:</p><ul class=""><li id="0cf0" class="nt nu iq lq b lr mw lu mx lx nv mb nw mf nx mj ny nz oa ob bi translated">多种数据清理和特征工程方法</li><li id="5f2a" class="nt nu iq lq b lr oc lu od lx oe mb of mf og mj ny nz oa ob bi translated">30 多个分类和回归模型(逻辑回归、随机森林、xgboost、lightgbm 等)</li><li id="0696" class="nt nu iq lq b lr oc lu od lx oe mb of mf og mj ny nz oa ob bi translated">轻松比较模型和管线</li><li id="5221" class="nt nu iq lq b lr oc lu od lx oe mb of mf og mj ny nz oa ob bi translated">35 个以上的图来分析数据和模型性能</li></ul><p id="ed3f" class="pw-post-body-paragraph lo lp iq lq b lr mw jr lt lu mx ju lw lx my lz ma mb mz md me mf na mh mi mj ij bi translated">要了解更多信息，请看软件包的文档<a class="ae kv" href="https://tvdboom.github.io/ATOM/" rel="noopener ugc nofollow" target="_blank">。对于 bug 或功能请求，请不要犹豫，在</a><a class="ae kv" href="https://github.com/tvdboom/ATOM" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上发表问题或给我发电子邮件。</p><p id="b092" class="pw-post-body-paragraph lo lp iq lq b lr mw jr lt lu mx ju lw lx my lz ma mb mz md me mf na mh mi mj ij bi translated">相关故事:</p><ul class=""><li id="4564" class="nt nu iq lq b lr mw lu mx lx nv mb nw mf nx mj ny nz oa ob bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/atom-a-python-package-for-fast-exploration-of-machine-learning-pipelines-653956a16e7b">https://towards data science . com/atom-a-python-package-for-fast-exploration-of-machine-learning-pipelines-653956 a16 e7b</a></li><li id="d8cd" class="nt nu iq lq b lr oc lu od lx oe mb of mf og mj ny nz oa ob bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/how-to-test-multiple-machine-learning-pipelines-with-just-a-few-lines-of-python-1a16cb4686d">https://towards data science . com/how-to-test-multiple-machine-learning-pipelines-with-just-the-less-lines-of-python-1 a16 CB 4686d</a></li><li id="950a" class="nt nu iq lq b lr oc lu od lx oe mb of mf og mj ny nz oa ob bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/from-raw-data-to-web-app-deployment-with-atom-and-streamlit-d8df381aa19f">https://towards data science . com/from-raw-data-to-we B- app-deployment-with-atom-and-streamlit-d 8df 381 aa 19 f</a></li></ul><p id="7a06" class="pw-post-body-paragraph lo lp iq lq b lr mw jr lt lu mx ju lw lx my lz ma mb mz md me mf na mh mi mj ij bi translated">引用:</p><ul class=""><li id="59c5" class="nt nu iq lq b lr mw lu mx lx nv mb nw mf nx mj ny nz oa ob bi translated">邓，2012 年。用于机器学习研究的手写数字图像 mnist 数据库。<em class="nm"> IEEE 信号处理杂志</em>，29(6)，第 141–142 页。(麻省理工学院许可证)</li></ul></div></div>    
</body>
</html>