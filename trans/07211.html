<html>
<head>
<title>An Overview of Performance Evaluation Metrics of Machine Learning(Classification) Algorithms in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中机器学习(分类)算法的性能评价指标综述</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-overview-of-performance-evaluation-metrics-of-machine-learning-classification-algorithms-7a95783a762f?source=collection_archive---------19-----------------------#2021-06-30">https://towardsdatascience.com/an-overview-of-performance-evaluation-metrics-of-machine-learning-classification-algorithms-7a95783a762f?source=collection_archive---------19-----------------------#2021-06-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/978f38927a9dc3ae8667f23f57ed5716.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TqmCSeerHZRP8tNQ"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">由<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的科坦·拉杰普特<a class="ae jg" href="https://unsplash.com/@ketan_rajput?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">拍摄的照片</a></p></figure><div class=""/><div class=""><h2 id="3680" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">使用Python函数开发分类模型并计算所有流行的性能评估指标</h2></div><p id="175e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我看来，性能评估是机器学习中最重要的部分。因为机器学习本身已经变得相当容易，因为有了所有的库和包。任何人都可以在不太了解幕后发生的事情的情况下开发机器学习。那么绩效评估可能是一个挑战。你如何评价那个机器学习模型的性能？</p><p id="253f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">像Weka这样的软件会在你建立模型的时候自动提供大量的性能评估参数。但是在sklearn或R packages等其他工具中，性能评估参数不会随模型自动提供。您必须选择评估模型性能的参数。</p><p id="fb02" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我决定撰写这篇文章，总结分类模型的所有流行的性能评估指标。所以，它为你节省了一些时间。</p><p id="346c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我将尝试使用公式、简单的解释以及使用实际示例的计算来简要解释分类模型的性能评估度量。我不会深入探究它们，因为这是一个概述或备忘单。</p><p id="586b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们需要一个机器学习模型，在这个模型上我们将尝试所有的性能评估指标。因此，首先，我们将开发一个模型，然后逐个研究绩效评估指标。</p><p id="69a8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这篇文章表现:</p><ol class=""><li id="874c" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">特征的选择</li><li id="0d17" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">模型开发</li><li id="9edc" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">绩效评估方法</li></ol><p id="0fc7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我将使用这个关于关节炎的数据集。该数据集包含其他参数，我们将使用这些参数来预测一个人是否患有关节炎。请随意从以下链接下载数据集:</p><div class="is it gp gr iu mi"><a href="https://github.com/rashida048/Machine-Learning-BU/blob/main/arthritis.csv" rel="noopener  ugc nofollow" target="_blank"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jk gy z fp mn fr fs mo fu fw ji bi translated">rashida 048/机器学习-BU</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">在GitHub上创建一个帐户，为rashida048/Machine-Learning-BU开发做贡献。</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">github.com</p></div></div><div class="mr l"><div class="ms l mt mu mv mr mw ja mi"/></div></div></a></div><p id="4328" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们把重点放在模型开发上。但在此之前，我们需要选择功能。</p><h2 id="59bc" class="mx my jj bd mz na nb dn nc nd ne dp nf lh ng nh ni ll nj nk nl lp nm nn no np bi translated">特征选择</h2><p id="39b5" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">以下是该项目的数据集:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="7111" class="mx my jj oa b gy oe of l og oh">import pandas as pd<br/>import numpy as np</span><span id="eb28" class="mx my jj oa b gy oi of l og oh">df = pd.read_csv('arthritis.csv')</span></pre><p id="f582" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个数据框太大了，我无法在这里显示截图。它总共有108列。这些是列:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="4cfb" class="mx my jj oa b gy oe of l og oh">df.columns</span></pre><p id="64d4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="7968" class="mx my jj oa b gy oe of l og oh">Index(['x.aidtst3', 'employ1', 'income2', 'weight2', 'height3', 'children', 'veteran3', 'blind', 'renthom1', 'sex1',<br/>       ...<br/>'x.denvst3', 'x.prace1', 'x.mrace1', 'x.exteth3', 'x.asthms1',<br/>'x.michd', 'x.ltasth1', 'x.casthm1', 'x.state', 'havarth3'],<br/>dtype='object', length=108)</span></pre><p id="3af9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后一列“havarth3”是我们希望使用分类器预测的目标变量。这一栏告诉我们一个人是否有关节炎。它有两个价值。值1表示该人患有关节炎，值2表示该人没有关节炎。</p><p id="64ca" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其余的特征是输入参数。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="b431" class="mx my jj oa b gy oe of l og oh">X= df.drop(columns=["havarth3"])<br/>y= df['havarth3']</span></pre><p id="91e5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用scikit-learn库中的train_test_split方法，将数据集拆分为训练集和测试集:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="4172" class="mx my jj oa b gy oe of l og oh">from sklearn.model_selection import train_test_split<br/>x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.34, random_state = 35)</span></pre><p id="0c6f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们现在有了培训和测试集。但是我们需要所有的108个训练特征吗？也许不是。</p><p id="aa9e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我使用sklearn库中可用的SelectKBest函数从中选择了9个特性。</p><blockquote class="oj"><p id="f44f" class="ok ol jj bd om on oo op oq or os lt dk translated">我没有随意选择9这个数字。我检查了不同的其他功能选择方法，并尝试了不同的数字，即使使用这种功能选择方法，最终选择了数字9。</p></blockquote><p id="55f3" class="pw-post-body-paragraph ky kz jj la b lb ot kk ld le ou kn lg lh ov lj lk ll ow ln lo lp ox lr ls lt im bi translated">请随时查看我关于特性选择的文章。我在最后提供了链接。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="7a3c" class="mx my jj oa b gy oe of l og oh">from sklearn.feature_selection import SelectKBest<br/>from sklearn.feature_selection import f_classif</span><span id="285b" class="mx my jj oa b gy oi of l og oh">uni = SelectKBest(score_func = f_classif, k = 9)<br/>fit = uni.fit(X, y)</span><span id="3f35" class="mx my jj oa b gy oi of l og oh">reduced_training = fit.transform(x_train)<br/>reduced_test = uni.transform(x_test)</span></pre><p id="de61" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些是通过上述特征选择方法选择的列:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="4b1b" class="mx my jj oa b gy oe of l og oh">x_train.columns[fit.get_support(indices=True)].tolist()</span></pre><p id="5606" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="11f4" class="mx my jj oa b gy oe of l og oh">['employ1',<br/> 'rmvteth4',<br/> 'genhlth',<br/> 'x.age.g',<br/> 'x.age80',<br/> 'x.ageg5yr',<br/> 'x.age65yr',<br/> 'x.phys14d',<br/> 'x.hcvu651']</span></pre><p id="05ed" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这9个特征将用于分类器。</p><h2 id="416f" class="mx my jj bd mz na nb dn nc nd ne dp nf lh ng nh ni ll nj nk nl lp nm nn no np bi translated">模型开发</h2><p id="20d2" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">有这么多可用的分类器。我在这里选择一个随机的森林分类器。如果您使用sklearn库，这相当简单。只需导入分类器，传递超参数并使训练数据适合它。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="74c2" class="mx my jj oa b gy oe of l og oh">from sklearn.ensemble import RandomForestClassifier</span><span id="7583" class="mx my jj oa b gy oi of l og oh">clf = RandomForestClassifier(max_depth=6, random_state=0).fit(reduced_training, y_train)</span></pre><p id="5b2e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">分类器完成了！现在我们将转向我们做这一切的主要目的。那就是学习所有的绩效评估指标。</p><h2 id="d1bf" class="mx my jj bd mz na nb dn nc nd ne dp nf lh ng nh ni ll nj nk nl lp nm nn no np bi translated">机器学习的性能评估指标</h2><blockquote class="oy oz pa"><p id="0236" class="ky kz pb la b lb lc kk ld le lf kn lg pc li lj lk pd lm ln lo pe lq lr ls lt im bi translated"><strong class="la jk">精度</strong></p></blockquote><p id="ba59" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">任何人都很容易想到的第一个是准确率。对于这个特定的项目，我们想知道准确预测了多少有关节炎和没有关节炎的人。让我们先检查一下训练集。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="3be6" class="mx my jj oa b gy oe of l og oh">clf.score(reduced_test, y_test)</span></pre><p id="d9b2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="fcff" class="mx my jj oa b gy oe of l og oh">0.7417447018235584</span></pre><p id="611f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">是74.17%。还不错！我们保留测试集来测试模型。让我们来测试一下:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="e0e9" class="mx my jj oa b gy oe of l og oh">clf.score(reduced_training, y_train)</span></pre><p id="973c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="cd53" class="mx my jj oa b gy oe of l og oh">0.7466666666666667</span></pre><p id="dfd9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">74.67%的训练集和测试集的准确率非常接近。所以这里不存在过度拟合的问题。</p><blockquote class="oy oz pa"><p id="fd0f" class="ky kz pb la b lb lc kk ld le lf kn lg pc li lj lk pd lm ln lo pe lq lr ls lt im bi translated"><strong class="la jk">困惑_矩阵</strong></p></blockquote><p id="c7e5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">很多时候我们需要处理非常敏感的数据。例如，如果我们正在处理一个诊断癌症患者的数据集。正确诊断非常重要。</p><p id="e62b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请记住，在这些情况下，准确性度量可能具有欺骗性。因为数据集可能会非常倾斜。也许98%或更多的数据是负面的。意味着98%或更多的情况下，患者没有癌症并且是阴性的。只有少量的数据是肯定的。在这种情况下，如果我们的分类器准确率是98%，这意味着什么？</p><p id="87ee" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这可能意味着它只能正确分类癌症阴性患者，而不能诊断任何癌症阳性患者。但准确率仍高达98%。但是在这种情况下分类器有效吗？一点也不。</p><p id="783e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，知道正确分类的癌症阳性患者的百分比和正确分类的癌症阴性患者的百分比是重要的。</p><p id="1900" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">混淆矩阵是一个由四个数字组成的2x2矩阵，将结果细分为真阳性、假阳性、真阴性和假阴性。定义如下:</p><p id="2a12" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">真阳性</strong>:真阳性是被正确预测为阳性的阳性数据的数量。</p><p id="f495" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">假阳性</strong>:假阳性显示实际上是阴性的数据量，但分类器将其归类为阳性。</p><p id="2b14" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">真阴性:</strong>被正确预测为阴性的阴性数据的数量。</p><p id="8db0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">假阴性:</strong>假阴性是被分类器错误地预测为阴性的阳性数据的数量。</p><p id="2f27" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以比较实际标签和预测标签来找出所有这些。但是这里我将导入并使用confuion_matrix函数。</p><p id="9059" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面是使用混淆矩阵函数的函数，并使用字典将输出标记为tp(真阳性)、“fp”(假阳性)、fn(假阴性)和“tn”(真阴性)。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="84ae" class="mx my jj oa b gy oe of l og oh">def confusion_matrix_score(clf, X, y):<br/>    y_pred = clf.predict(X)<br/>    cm = confusion_matrix(y, y_pred)<br/>    return {'tp': cm[0, 0], 'fn': cm[0, 1],<br/>            'fp': cm[1, 0], 'tn': cm[1, 1]}</span></pre><p id="f7a8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">接下来，只需导入混淆矩阵函数并使用上面的函数:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="5837" class="mx my jj oa b gy oe of l og oh">from sklearn.metrics import confusion_matrix<br/>cm = confusion_matrix_score(clf, reduced_test, y_test)<br/>cm</span></pre><p id="113a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="9e1d" class="mx my jj oa b gy oe of l og oh">{'tp': 692, 'fn': 651, 'fp': 397, 'tn': 2318}</span></pre><p id="2418" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这四个参数将用于查找其他几个绩效评估指标。</p><blockquote class="oy oz pa"><p id="7eeb" class="ky kz pb la b lb lc kk ld le lf kn lg pc li lj lk pd lm ln lo pe lq lr ls lt im bi translated"><strong class="la jk">真阳性率(TPR)和假阳性率(FPR) </strong></p></blockquote><p id="ba51" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">真阳性率是真阳性(TP)除以总阳性(P)。如果我们看混淆矩阵，真正已经在那里了。但是总的积极因素是什么呢？总阳性是真阳性和假阴性的总和。</p><p id="da7c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">真阳性率(TPR) =真阳性/(真阳性+假阴性)</p><blockquote class="oj"><p id="fa84" class="ok ol jj bd om on oo op oq or os lt dk translated">真实阳性率也称为敏感度。</p></blockquote><p id="215c" class="pw-post-body-paragraph ky kz jj la b lb ot kk ld le ou kn lg lh ov lj lk ll ow ln lo lp ox lr ls lt im bi translated">同样，假阳性率是假阳性除以假阳性和真阴性之和。</p><p id="66cb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">假阳性率(FPR) =假阳性/(假阳性+真阴性)</p><p id="9a41" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">TPR和FPR都是非常重要的指标。如果我们看这个项目，我们可以发现有多少关节炎的人被正确检测出来，有多少没有关节炎的人被错误地检测为关节炎患者。为了计算它们，让我们从上面计算的混淆矩阵‘cm’中提取tn、fp、fn和tp。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="7155" class="mx my jj oa b gy oe of l og oh">tn, fp, fn, tp = cm['tn'], cm['fp'], cm['fn'], cm['tp']</span><span id="8dc3" class="mx my jj oa b gy oi of l og oh">tpr = tn/(tn+fn)<br/>fpr = fn/(fn+tp)</span><span id="aa2d" class="mx my jj oa b gy oi of l og oh">(tpr, fpr)</span></pre><p id="bdf2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="4591" class="mx my jj oa b gy oe of l og oh">(0.7807342539575615, 0.4847356664184661)</span></pre><p id="bb35" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">真阳性率为78.07%，假阳性率为48.47%。</p><blockquote class="oy oz pa"><p id="2ec3" class="ky kz pb la b lb lc kk ld le lf kn lg pc li lj lk pd lm ln lo pe lq lr ls lt im bi translated"><strong class="la jk"> ROC曲线和曲线下面积(AUC) </strong></p></blockquote><p id="d3c7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">ROC曲线(受试者工作特征曲线)显示了真阳性率(TPR)和假阳性率(FPR)之间的权衡。针对不同的阈值计算TRP和FPR。然后将这一系列的TPR和FPR绘制成ROC曲线。如果曲线下面积(AUC)更接近1，则认为该模型是有技巧的。</p><p id="7747" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以，这里是如何找到ROC曲线和曲线下的面积</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="4cf5" class="mx my jj oa b gy oe of l og oh">from sklearn import metrics<br/>metrics.plot_roc_curve(clf, reduced_test, y_test)</span></pre><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/e0aef926a0dec44f88e413b4cbe369e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*uVNl5wkzOSSBZlMwoj4g4g.png"/></div></figure><p id="ec8a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该图显示曲线下面积(AUC)为0.8。</p><blockquote class="oy oz pa"><p id="5e32" class="ky kz pb la b lb lc kk ld le lf kn lg pc li lj lk pd lm ln lo pe lq lr ls lt im bi translated"><strong class="la jk">精度和校准</strong></p></blockquote><p id="a6ba" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们考虑这个项目，precision将计算分类器正确预测关节炎患者的比例。这个公式可以写成:</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/7a21e21fb8b6de296570f2b24249eb22.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/0*FnVMeKuN0fwh-5qK.png"/></div></figure><p id="83e5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从公式中可以看出，精度越高意味着真阳性越高，假阳性越低。</p><p id="d126" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另一方面，回忆代表所有关节炎患者中被检测为关节炎患者的比例。如果你是第一次看到这个，这个定义可能看起来很混乱。公式如下:</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/5178838c6958957be96a89675f7fb739.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/0*Q9G1CICbfOc7a4Aj.png"/></div></figure><p id="e168" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以，更高的回忆意味着更高的真阳性和更低的假阴性。回忆也叫敏感。</p><p id="1bd0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们计算一下精度和回忆:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="4713" class="mx my jj oa b gy oe of l og oh">precision = tn/(tn+fn)<br/>recall = tn/(tn+fp)</span><span id="4abe" class="mx my jj oa b gy oi of l og oh">(precision, recall)</span></pre><p id="9f1d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="04d4" class="mx my jj oa b gy oe of l og oh">(0.7807342539575615, 0.8537753222836095)</span></pre><blockquote class="oy oz pa"><p id="df15" class="ky kz pb la b lb lc kk ld le lf kn lg pc li lj lk pd lm ln lo pe lq lr ls lt im bi translated">f分数</p></blockquote><p id="ae07" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如您所见，精确度意味着更低的误报率，召回意味着更低的误报率。当你将要优化一个机器学习模型的时候，你需要选择你想往哪个方向走:更低的误报率还是更低的漏报率？这取决于项目要求。</p><p id="7c9b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">F1分数是精确度和召回率的调和平均值。该公式如下所示:</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/9da18810f9e6f03d13419d00d4587493.png" data-original-src="https://miro.medium.com/v2/resize:fit:364/format:webp/0*Q3e1JCePkHfQfO4x.png"/></div></figure><p id="b29d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">注意公式。当精确度和召回率都达到完美时，f值为1。</p><p id="7f7c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">f分数的一个更通用的公式是:</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/e53d562312199e2c97d503138f8d1891.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*-RDbdl7tc6mh90Be3FdZ3w.png"/></div></figure><p id="d27b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当精确度或召回率需要比另一个更重要时，使用这个公式。β的三个常用值是1、2或0.5。当精度和召回权重相同时使用1，当召回权重高于精度时使用2，当召回权重低于精度时使用0.5。</p><p id="77a8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本次演示中，我将使用1和2的β值，并计算f 1和f2值:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="e3b8" class="mx my jj oa b gy oe of l og oh">f1_score = 2*precision*recall/(precision + recall)<br/>f2_score = 5*precision*recall/(4*precision + recall)<br/>(f1_score, f2_score)</span></pre><p id="9def" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="e05d" class="mx my jj oa b gy oe of l og oh">(0.8156228008444757, 0.8380938607274568)</span></pre><blockquote class="oy oz pa"><p id="5a74" class="ky kz pb la b lb lc kk ld le lf kn lg pc li lj lk pd lm ln lo pe lq lr ls lt im bi translated"><strong class="la jk">精确召回曲线</strong></p></blockquote><p id="f425" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">精确-召回曲线显示了精确和召回之间的权衡。精确度-召回率曲线下的高区域意味着高精确度和高召回率。为此，使用不同的阈值来计算精确度和召回率。</p><p id="5a9f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是没问题。我们不必手动计算不同阈值的精度和召回率。我们可以简单地使用sklearn库中可用的函数，该函数将为我们提供曲线以及曲线下的面积。</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="1553" class="mx my jj oa b gy oe of l og oh">from sklearn.metrics import auc, plot_precision_recall_curve<br/>plot_precision_recall_curve(clf, reduced_test, y_test)</span></pre><p id="f28e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/6304129c718c129b72804c6a3a18324a.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*udvcuKP_8vAyNsrh0J72Rg.png"/></div></figure><p id="a503" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">曲线显示平均精度(AP)为0.89。</p><p id="3132" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是中国曲线下的面积:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="fbc1" class="mx my jj oa b gy oe of l og oh">auc(recall, precision)</span></pre><p id="5a4d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="b917" class="mx my jj oa b gy oe of l og oh">0.6555667752074759</span></pre><blockquote class="oy oz pa"><p id="a9a0" class="ky kz pb la b lb lc kk ld le lf kn lg pc li lj lk pd lm ln lo pe lq lr ls lt im bi translated"><strong class="la jk">马修斯相关系数</strong></p></blockquote><p id="aa96" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">MCC是二进制分类的另一个很好的性能评估指标。它考虑了真阳性、假阳性和假阴性。它返回一个介于-1和1之间的值。值1表示完美的分类器，0表示不比随机猜测好，而-1表示原始标签和预测标签之间完全不一致。公式如下:</p><figure class="nv nw nx ny gt iv gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/61ba95ebfa8aa101da81d04eeac53940.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*dvME7t6eDmEXpVPJQgAXHA.png"/></div></figure><p id="0198" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用python对本项目进行计算:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="b151" class="mx my jj oa b gy oe of l og oh">mcc = (tn*tp - fn*fp)/np.sqrt((tn+fn)*(tn+fp)*(tp+fn)*(tp+fp))<br/>mcc</span></pre><p id="3b51" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="bcbd" class="mx my jj oa b gy oe of l og oh">0.3919014959349731</span></pre><p id="7bde" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">也可以使用以下函数进行计算，该函数将预测y和原始y作为参数:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="2104" class="mx my jj oa b gy oe of l og oh"><strong class="oa jk">from </strong> <strong class="oa jk">sklearn.metrics </strong> <strong class="oa jk">import</strong> matthews_corrcoef <br/>matthews_corrcoef (y_test, y_pred)</span></pre><p id="2ecd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="nv nw nx ny gt nz oa ob oc aw od bi"><span id="14e7" class="mx my jj oa b gy oe of l og oh">0.3919014959349731</span></pre><h2 id="857a" class="mx my jj bd mz na nb dn nc nd ne dp nf lh ng nh ni ll nj nk nl lp nm nn no np bi translated">结论</h2><p id="662f" class="pw-post-body-paragraph ky kz jj la b lb nq kk ld le nr kn lg lh ns lj lk ll nt ln lo lp nu lr ls lt im bi translated">所有指标都显示为二进制分类设置。但是相同的度量也可以用于多类分类问题。这种方法被称为一对一。说，你在计算精度。您将其中一个类设置为正类，将其余的类设置为负类。这样问题就变成二元的了。</p><p id="537c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">希望这个关于绩效评估的讨论有所帮助。请随时在Twitter上关注我。</p><h2 id="71b6" class="mx my jj bd mz na nb dn nc nd ne dp nf lh ng nh ni ll nj nk nl lp nm nn no np bi translated">更多阅读</h2><div class="is it gp gr iu mi"><a rel="noopener follow" target="_blank" href="/four-popular-feature-selection-methods-for-efficient-machine-learning-in-python-fdd34762efdb"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jk gy z fp mn fr fs mo fu fw ji bi translated">Python中高效机器学习的四种流行特征选择方法</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">使用真实数据集执行特征选择方法，并在每个方法后检索所选特征</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="pm l mt mu mv mr mw ja mi"/></div></div></a></div><div class="is it gp gr iu mi"><a rel="noopener follow" target="_blank" href="/stochastic-gradient-descent-explanation-and-complete-implementation-from-scratch-a2c6a02f28bd"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jk gy z fp mn fr fs mo fu fw ji bi translated">随机梯度下降:从头开始的解释和完整实现</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">使用单个感知器</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="pn l mt mu mv mr mw ja mi"/></div></div></a></div><div class="is it gp gr iu mi"><a rel="noopener follow" target="_blank" href="/exploratory-data-analysis-of-text-data-including-visualization-and-sentiment-analysis-e46dda3dd260"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jk gy z fp mn fr fs mo fu fw ji bi translated">文本数据的探索性数据分析，包括可视化和情感分析</h2><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="po l mt mu mv mr mw ja mi"/></div></div></a></div><div class="is it gp gr iu mi"><a rel="noopener follow" target="_blank" href="/an-ultimate-cheatsheet-of-data-visualization-in-seaborn-be8ed13a3697"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jk gy z fp mn fr fs mo fu fw ji bi translated">用Python的Seaborn库实现数据可视化的终极指南</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">对学习者来说也是一个很好的资源</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="pp l mt mu mv mr mw ja mi"/></div></div></a></div><div class="is it gp gr iu mi"><a href="https://pub.towardsai.net/dissecting-1-way-anova-and-ancova-with-examples-in-r-a3a7da83d742" rel="noopener  ugc nofollow" target="_blank"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jk gy z fp mn fr fs mo fu fw ji bi translated">用R中的例子剖析单向方差分析和协方差分析</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">通过分析方差得出的均值差异</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">pub.towardsai.net</p></div></div><div class="mr l"><div class="pq l mt mu mv mr mw ja mi"/></div></div></a></div><div class="is it gp gr iu mi"><a rel="noopener follow" target="_blank" href="/detailed-guide-to-multiple-linear-regression-model-assessment-and-inference-in-r-146845067aa3"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jk gy z fp mn fr fs mo fu fw ji bi translated">多元线性回归模型、评估和推理的详细指南</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">模型开发、解释、方差计算、f检验和t检验</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="pr l mt mu mv mr mw ja mi"/></div></div></a></div></div></div>    
</body>
</html>