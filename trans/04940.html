<html>
<head>
<title>Image Captions with Attention in Tensorflow, Step-by-step</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Tensorflow中带注意的图像标题，逐步</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-captions-with-attention-in-tensorflow-step-by-step-927dad3569fa?source=collection_archive---------1-----------------------#2021-04-30">https://towardsdatascience.com/image-captions-with-attention-in-tensorflow-step-by-step-927dad3569fa?source=collection_archive---------1-----------------------#2021-04-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="e61b" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">直观的图像字幕系列</h2><div class=""/><div class=""><h2 id="e3e2" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">Keras和Tensorflow 2.0中使用编码器-解码器的端到端示例，用简单的英语讲述</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/a9386ad3e6a00f0537544728099615d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*w-f5UYU0aIoXlk3G"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">马克斯·克莱恩在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="9606" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">近年来，使用深度学习生成图像字幕已经产生了显著的结果。最广泛使用的架构之一出现在<a class="ae le" href="https://arxiv.org/abs/1502.03044" rel="noopener ugc nofollow" target="_blank">展示、出席和讲述</a>论文中。</p><p id="40c2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">它引入的创新是将注意力应用于图像标题问题，这在NLP领域已经取得了很大的成功。注意力帮助模型专注于图像中最相关的部分，因为它生成了标题的每个单词。</p><p id="621d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在本文中，我们将通过一个简单的演示应用程序来详细了解这个体系结构是如何工作的。</p><p id="fa8f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我还有另一篇文章，概述了许多流行的图像标题架构。它提供了这些体系结构所使用的主要组件的背景，解释了每个体系结构的独特特征以及它们为什么有趣。如果你感兴趣，我鼓励你去看一看。</p><div class="mb mc gp gr md me"><a rel="noopener follow" target="_blank" href="/image-captions-with-deep-learning-state-of-the-art-architectures-3290573712db"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ja gy z fp mj fr fs mk fu fw iz bi translated">具有深度学习的图像标题:最先进的架构</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">图像特征编码器、序列解码器、注意和多模态架构的简明指南，用简单的英语编写</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">towardsdatascience.com</p></div></div><div class="mn l"><div class="mo l mp mq mr mn ms ky me"/></div></div></a></div><h1 id="107b" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated">图像字幕应用程序</h1><p id="153d" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">图像字幕应用程序将图像作为输入，并生成描述照片内容的简短文本摘要。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/60725d24a34de171e72d202c9a02bc37.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/0*NqFHtmCuSWz-KXr1.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="46f4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于我们的应用程序，我们从图像文件作为输入开始，并以紧凑的编码表示提取它们的基本特征。我们将这些输入到一个序列解码器，由几个LSTM层组成，它将解码编码图像并预测描述照片的单词序列。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/a35a6f12fb9f39b18e54cc6d5ffa3c46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/0*NdAie2w9MS8CrZDf.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="d2e3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">至于大多数深度学习问题，我们会按照以下步骤:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ns"><img src="../Images/c344d716ffb2f4040685404acb2f1da2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pxeoTS_6Bu7hGZmq.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><h1 id="3095" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated">图像标题数据集</h1><p id="839e" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">有一些众所周知的数据集常用于这类问题。这些数据集包含一组图像文件和一个文本文件，该文本文件将每个图像文件映射到一个或多个标题。每个标题都是一种语言中的一句话。</p><p id="e813" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于我们的演示，我们将使用Flickr8K数据集(<a class="ae le" href="https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip" rel="noopener ugc nofollow" target="_blank">图像</a>，<a class="ae le" href="https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip" rel="noopener ugc nofollow" target="_blank">文本</a>)。这是一个合理大小的数据集，包含大约8000张图像，足以训练我们的模型，而不需要大量的RAM和磁盘空间。</p><p id="c4dd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">将它下载到“<em class="nt">数据集</em>文件夹后，我们看到它由三部分组成:</p><ul class=""><li id="f63b" class="nu nv iq lh b li lj ll lm lo nw ls nx lw ny ma nz oa ob oc bi translated">“<em class="nt"> Flicker8k_Dataset </em>”文件夹中的<strong class="lh ja">图像文件</strong>:该文件夹包含大约8000个。jpg文件如'<em class="nt">1000268201 _ 693 b 08 cb0e . jpg</em>'</li><li id="2275" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">主文件夹中'<em class="nt"> Flickr8k.token.txt </em>'文件中的<strong class="lh ja">字幕</strong>:包含所有图片的字幕。因为同一幅图像可以用许多不同的方式描述，所以每幅图像有5个标题。</li><li id="7027" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated"><strong class="lh ja">一组中的训练、验证和测试图像的列表</strong>。主文件夹中的txt文件:'<em class="nt">Flickr _ 8k . train images . txt</em>'包含用于训练的图像文件名列表。同样，也有用于验证和测试的文件。</li></ul><h1 id="3183" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated">探索数据</h1><p id="1ebe" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">标题文件中的每一行代表一个标题。它包含由制表符分隔的两列。每行的格式是:</p><p id="7517" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">“<image file=""> #i <caption>”，其中0≤i≤4为5个字幕中的每一个。</caption></image></p><p id="f0ef" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">eg ."<em class="nt">1000268201 _ 693 b 08 cb0e . jpg # 1一个女孩走进一栋木屋里。</em></p><p id="0697" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下面是一张带有五个标题的图片:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oi"><img src="../Images/28d000b72257a2f2206e0facc0ca2916.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WS1t-_S5LDrmzh_J.png"/></div></div></figure><h1 id="6ad5" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated">训练数据管道</h1><p id="118f" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">我们将分两个阶段为我们的深度学习架构构建管道。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oj"><img src="../Images/353e7b945ee345ff91841286c098f076.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*YDXg0m7kT5f1FfQL.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><ul class=""><li id="cdb3" class="nu nv iq lh b li lj ll lm lo nw ls nx lw ny ma nz oa ob oc bi translated">在第一阶段，我们使用迁移学习，通过预先训练的基于CNN的网络对原始图像进行预处理。这将图像作为输入，并产生捕获图像基本特征的编码图像向量。我们不需要进一步训练这个网络。</li><li id="4832" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">然后，我们将这些编码图像特征，而不是原始图像本身，输入到我们的图像标题模型中。我们还传入对应于每个编码图像的目标标题。该模型解码图像特征并学习预测与目标字幕匹配的字幕。</li></ul><p id="a12c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于图像字幕模型，训练数据包括:</p><ul class=""><li id="b505" class="nu nv iq lh b li lj ll lm lo nw ls nx lw ny ma nz oa ob oc bi translated"><strong class="lh ja">特征(X) </strong>是编码的特征向量</li><li id="f2ff" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated"><strong class="lh ja">目标标签(y) </strong>是标题</li></ul><p id="77ef" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了准备这种格式的培训数据，我们将使用以下步骤:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/524184ba85a4361c0d6405b02fd19a0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/0*X8EF7M0gLhWgdz-_.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><ul class=""><li id="84cf" class="nu nv iq lh b li lj ll lm lo nw ls nx lw ny ma nz oa ob oc bi translated">加载图像和标题数据</li><li id="445c" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">预处理图像</li><li id="e584" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">预处理标题</li><li id="062b" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">使用预处理的图像和字幕准备训练数据</li></ul><p id="4849" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，让我们更详细地看一下这些步骤。</p><h1 id="804d" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated">加载图像和标题</h1><p id="656d" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">让我们将完整的数据集加载到Python字典中:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ol om l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi on"><img src="../Images/fd9db6f17063d0e7ab06835542beba83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZDpvjpkv4mHAiZ-H.png"/></div></div></figure><p id="f256" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后使用训练列表文本文件从我们的完整数据集中选择用于训练的图像子集。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ol om l"/></div></figure><h1 id="1cdb" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated">预处理图像</h1><p id="9534" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">我们将使用预训练的初始模型，这是一个众所周知的具有优异性能的图像分类模型。该模型由两部分组成:</p><ul class=""><li id="2f38" class="nu nv iq lh b li lj ll lm lo nw ls nx lw ny ma nz oa ob oc bi translated">第一部分由一系列CNN图层组成，这些图层从图像中逐步提取相关特征，以生成紧凑的特征地图表示。</li><li id="50ff" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">第二部分是由一系列线性层组成的分类器。它获取图像特征图，并预测该特征所属的类别(例如，狗、汽车、房子等)。</li></ul><p id="eafb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于我们的图像字幕模型，我们只需要图像特征图，而不需要分类器。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oo"><img src="../Images/e8a64fa3fc3a2a234d84db916c7e9cbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*W2YZdbkCt7uQNbyE.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="fcb4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们下载这个预训练的模型，截断分类器部分并编码训练图像。每个编码图像的特征使用图像名称和另一个扩展名保存在一个单独的文件中，例如“<em class="nt">1000268201 _ 693 b 08 cb0e . npy</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi op"><img src="../Images/bcf2229fbf7569284540d5061884ad73.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/0*2Vjcief1IQSfLENi.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="451c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">既然图像已经为训练做好了准备，接下来我们必须准备字幕数据。</p><h1 id="5b24" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated">准备标题</h1><p id="82ac" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">每个标题由一个英语句子组成。为了准备培训，我们对每个句子执行以下步骤:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oq"><img src="../Images/d989e73de701561d69ea43cc2179158e.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/0*i5uIvFuganAyr2KV.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><ul class=""><li id="3862" class="nu nv iq lh b li lj ll lm lo nw ls nx lw ny ma nz oa ob oc bi translated">通过将所有单词转换成小写字母并删除标点符号、带数字的单词和带单个字符的短单词来清理它。</li><li id="c425" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">在句首和句尾添加“<startseq>”和“<endseq>”标记。</endseq></startseq></li><li id="adba" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">通过将每个单词映射到一个数字单词ID来标记句子。它通过构建标题集中出现的所有单词的词汇表来做到这一点。</li><li id="d961" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">通过追加填充标记将每个句子扩展到相同的长度。这是必要的，因为模型期望每个数据样本具有相同的固定长度。</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ol om l"/></div></figure><h1 id="d2b5" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated">使用张量流数据集准备训练数据</h1><p id="698c" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">我们现在有预处理的图像和标题。我们检查每个训练图像及其匹配的标题来准备训练数据。这包括:</p><ul class=""><li id="7ac4" class="nu nv iq lh b li lj ll lm lo nw ls nx lw ny ma nz oa ob oc bi translated"><strong class="lh ja">特征(X) </strong>由图像文件路径组成</li><li id="53d4" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated"><strong class="lh ja">目标(y) </strong>由经过清理和标记的字幕组成</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="5a04" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们将训练数据包装在Tensorflow Dataset对象中，以便可以在训练过程中高效地获取数据并一次一批地将其提供给模型。数据被缓慢提取，因此不必同时存在于内存中。这使我们能够支持非常大的数据集。</p><p id="f9a1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">数据集加载先前保存的预处理编码图像矢量。它使用图像文件名来标识保存的文件路径。</p><p id="75a7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这个例子的大部分代码取自Tensorflow图片说明教程<a class="ae le" href="https://www.tensorflow.org/tutorials/text/image_captioning" rel="noopener ugc nofollow" target="_blank"/>。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ol om l"/></div></figure><h1 id="87a5" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated">带注意力的图像字幕模型</h1><p id="bdf2" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">该模型由四个逻辑组件组成:</p><ul class=""><li id="0716" class="nu nv iq lh b li lj ll lm lo nw ls nx lw ny ma nz oa ob oc bi translated"><strong class="lh ja">编码器</strong>:由于图像编码已经由预先训练好的Inception模型完成，这里的编码器非常简单。它由一个线性层组成，该层获取预编码图像特征并将其传递给解码器。</li><li id="e677" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated"><strong class="lh ja">序列解码器</strong>:这是用GRUs搭建的递归网络。字幕首先通过嵌入层，然后作为输入传入。</li><li id="6cf4" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated"><strong class="lh ja">注意力</strong>:当解码器生成输出序列的每个单词时，注意力模块帮助它聚焦于图像中与生成该单词最相关的部分。</li><li id="d722" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">句子生成器:这个模块由几个线性层组成。它从解码器获得输出，并为词汇表中的每个单词以及预测序列中的每个位置产生一个概率。</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ol om l"/></div></figure><h1 id="1b5a" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated">注意力如何增强图像字幕的表现</h1><p id="7b19" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">最早的图像字幕架构包括其他三个组件，但没有引起注意。让我们先回顾一下这个模型是如何工作的，然后看看注意力有什么不同。</p><p id="2449" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在每个时间步长，解码器从先前时间步长和当前输入字中提取隐藏状态，以产生该时间步长的输出字。隐藏状态携带编码图像特征的一些表示。</p><p id="23c3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在没有注意的情况下，解码器在生成输出字时平等地对待图像的所有部分。</p><p id="8a42" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">那么注意力的表现有什么不同呢？</p><p id="6f7d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在每个时间步，注意力模块将编码图像以及解码器在前一时间步的隐藏状态作为输入。</p><p id="686e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">它产生一个注意力分数，该分数为编码图像的每个像素分配一个权重。像素的权重越高，在下一时间步输出的单词就越相关。</p><p id="0a3b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">例如，如果目标输出序列是“一个女孩正在吃苹果”，则在生成单词“女孩”时，照片中女孩的像素被高亮显示，而对于单词“苹果”，苹果的像素被高亮显示。</p><p id="af1b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后，该分数与该时间步长的输入字连接，并馈入解码器。这有助于解码器关注图像中最相关的部分，并生成适当的输出字。</p><h1 id="b768" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated">培养</h1><p id="e67d" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">我们现在准备创建训练循环来训练模型。</p><p id="7167" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们为优化器和损失定义函数。我们为几个时期训练模型，在每次迭代中处理一批数据。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="7478" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">训练期间会发生很多事情，计算流程可能会有点混乱。所以让我们一步一步地来看。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi or"><img src="../Images/4849b75f2d82d5535e7e4b2bc38baeb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Bnn4FEjOV0hX0XXz.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="2ac2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在每个时期，训练循环执行几个操作:</p><h2 id="c7cb" class="os mu iq bd mv ot ou dn mz ov ow dp nd lo ox oy nf ls oz pa nh lw pb pc nj iw bi translated">设置</h2><p id="6166" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">首先，我们设置我们需要的数据元素。</p><ul class=""><li id="fc0a" class="nu nv iq lh b li lj ll lm lo nw ls nx lw ny ma nz oa ob oc bi translated">通过TF数据集获取一批数据。这将从保存的预处理文件和准备好的字幕中加载图像特征向量。</li><li id="a1e9" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">编码器对图像特征向量进行编码。</li><li id="928f" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">序列解码器初始化其隐藏状态。注意，也可以对编码图像应用一些变换来初始化隐藏状态。</li><li id="7fb6" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">通过仅用一个“Start”标记播种输入序列来开始输入序列。</li></ul><h2 id="3606" class="os mu iq bd mv ot ou dn mz ov ow dp nd lo ox oy nf ls oz pa nh lw pb pc nj iw bi translated">多个时间步长上的流程序列</h2><p id="ac80" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">接下来，我们在多个时间步长上迭代输入序列的每个元素。让我们来看看批次中一个序列的流程:</p><ul class=""><li id="b81e" class="nu nv iq lh b li lj ll lm lo nw ls nx lw ny ma nz oa ob oc bi translated">注意力模块从编码器获取编码图像，从序列解码器获取隐藏状态，并计算加权注意力分数。</li><li id="5fdc" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">输入序列通过嵌入层，然后与关注度结合。</li><li id="29d2" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">组合的输入序列被馈送到序列解码器，该解码器产生输出序列以及新的隐藏状态。</li><li id="eb23" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">句子生成器处理输出序列并生成其预测单词概率。</li><li id="e904" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">我们现在为下一个时间步重复这个循环。来自该时间步长的解码器的新隐藏状态被用于下一个时间步长。我们继续这样做，直到预测到“结束”标记，或者达到序列的最大长度。</li><li id="d6c3" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">然而，有一点值得注意，即。老师逼的，下面解释。</li></ul><h2 id="9f26" class="os mu iq bd mv ot ou dn mz ov ow dp nd lo ox oy nf ls oz pa nh lw pb pc nj iw bi translated">教师强迫</h2><ul class=""><li id="5e32" class="nu nv iq lh b li nl ll nm lo pd ls pe lw pf ma nz oa ob oc bi translated">通常，在推理期间，当模型被完全训练时，来自这个时间步长的输出序列被用作下一个时间步长的输入序列。这允许模型基于迄今为止预测的前一个单词来预测下一个单词。</li><li id="7395" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">然而，如果我们在模型仍在训练期间学习时这样做，则模型在这个时间步中预测输出字时所犯的任何错误都将被结转到下一个时间步。该模型将基于错误的前一个单词来预测下一个单词。</li><li id="a466" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">相反，因为我们在训练中有地面实况字幕可用，所以我们使用一种叫做教师强迫的技术。来自目标字幕的正确的预期单词被添加到下一个时间步长的输入序列，而不是模型的预测单词。</li><li id="1760" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">这样，我们就像老师一样，通过给模型一个提示来帮助它。</li></ul><h2 id="ff52" class="os mu iq bd mv ot ou dn mz ov ow dp nd lo ox oy nf ls oz pa nh lw pb pc nj iw bi translated">失败</h2><ul class=""><li id="4bda" class="nu nv iq lh b li nl ll nm lo pd ls pe lw pf ma nz oa ob oc bi translated">在每个时间步，预测的概率与地面实况字幕进行比较，以计算损失。损失将用于通过反向传播训练网络。</li></ul><p id="9cf0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">通常，作为训练循环的一部分，我们还会评估验证数据的度量。然而，为了这个演示的目的，在模型被完全训练之后，我们将继续对测试数据进行推断。</p><h1 id="94a1" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated">推理</h1><p id="eb7f" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">我们使用预先训练的模型从测试图像中提取图像特征。生成标题的后续步骤与我们在培训中所做的非常相似，但有以下变化:</p><ul class=""><li id="f37d" class="nu nv iq lh b li lj ll lm lo nw ls nx lw ny ma nz oa ob oc bi translated">贪婪搜索通过在每个时间步长选择概率最高的单词来预测输出。</li><li id="762a" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">由于我们没有地面真相标题，我们不使用教师强迫。在每个时间步长，预测字被附加到输入序列，并反馈到解码器，用于下一个时间步长。</li><li id="73a3" class="nu nv iq lh b li od ll oe lo of ls og lw oh ma nz oa ob oc bi translated">显然，我们不计算损失和梯度，也不做反向传播。</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ol om l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/10835b231d4b9f0c315909b27023c5b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*J6LYgU6up5DBmaG0ddkPEw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">预测说明:“人爬上岩石到大岩石”。真实描述:“一个人正在两个大岩壁之间攀岩”</p></figure><h1 id="41c3" class="mt mu iq bd mv mw mx my mz na nb nc nd kf ne kg nf ki ng kj nh kl ni km nj nk bi translated">结论</h1><p id="2c53" class="pw-post-body-paragraph lf lg iq lh b li nl ka lk ll nm kd ln lo nn lq lr ls no lu lv lw np ly lz ma ij bi translated">图像字幕是一个有趣的应用，因为它结合了计算机视觉和自然语言处理的技术，并且需要处理图像和文本。</p><p id="07e3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们仔细浏览了一个使用编码器-解码器架构的端到端图像字幕示例。我们看到注意力是如何被用来提高网络预测更好字幕的能力的。这是近年来性能较好的架构之一。</p><p id="e33d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后，如果你喜欢这篇文章，你可能也会喜欢我关于变形金刚、音频深度学习和地理定位机器学习的其他系列。</p><div class="mb mc gp gr md me"><a rel="noopener follow" target="_blank" href="/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ja gy z fp mj fr fs mk fu fw iz bi translated">直观解释的变压器(第1部分):功能概述</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">NLP变形金刚的简明指南，以及为什么它们比rnn更好，用简单的英语。注意力如何帮助…</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">towardsdatascience.com</p></div></div><div class="mn l"><div class="ph l mp mq mr mn ms ky me"/></div></div></a></div><div class="mb mc gp gr md me"><a rel="noopener follow" target="_blank" href="/audio-deep-learning-made-simple-part-1-state-of-the-art-techniques-da1d3dff2504"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ja gy z fp mj fr fs mk fu fw iz bi translated">音频深度学习变得简单(第一部分):最新技术</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">颠覆性深度学习音频应用和架构世界的温和指南。以及为什么我们都需要…</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">towardsdatascience.com</p></div></div><div class="mn l"><div class="pi l mp mq mr mn ms ky me"/></div></div></a></div><div class="mb mc gp gr md me"><a rel="noopener follow" target="_blank" href="/leveraging-geolocation-data-for-machine-learning-essential-techniques-192ce3a969bc"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ja gy z fp mj fr fs mk fu fw iz bi translated">利用地理位置数据进行机器学习:基本技术</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">简明的地理空间数据特征工程和可视化指南</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">towardsdatascience.com</p></div></div><div class="mn l"><div class="pj l mp mq mr mn ms ky me"/></div></div></a></div><p id="3acc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们继续学习吧！</p></div></div>    
</body>
</html>