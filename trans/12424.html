<html>
<head>
<title>Introduction to SHAP with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python SHAP 简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-shap-with-python-d27edc23c454?source=collection_archive---------0-----------------------#2021-12-19">https://towardsdatascience.com/introduction-to-shap-with-python-d27edc23c454?source=collection_archive---------0-----------------------#2021-12-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1bfb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何创造和解读 SHAP 情节:瀑布、力量、卑鄙的 SHAP、蜂群和依赖</h2></div><p id="f3ce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">更新日期:2023 年 3 月 12 日</em></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/35a1553fa06ca1baedaf85391a6b6407.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fi77jD4p5krQzRRtH7HhKA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">(来源:作者)</p></figure><p id="97b5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">SHAP 是理解和调试模型的最强大的 Python 包。它可以告诉我们每个模型特征是如何对单个预测做出贡献的。通过聚合 SHAP 值，我们还可以了解多个预测的趋势。通过几行代码，我们能够识别和可视化模型中的重要关系。</p><p id="7f0e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们遍历用于计算和显示 SHAP 值的代码。这包括对以下 SHAP 图的解释:</p><ul class=""><li id="fc68" class="lv lw it kk b kl km ko kp kr lx kv ly kz lz ld ma mb mc md bi translated">瀑布图</li><li id="88e2" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">力图</li><li id="3276" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">平均 SHAP 图</li><li id="6c34" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">蜂群图</li><li id="70a8" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">依赖图</li></ul><p id="9f04" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们为预测一个<strong class="kk iu">连续</strong>目标变量的模型做这个。最后，我们解释了对于<strong class="kk iu">二元</strong>目标变量的解释是如何相似的。你可以在 GitHub 上找到完整的项目。</p><p id="a047" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">还有一个<strong class="kk iu">视频</strong>过一遍这篇文章的内容。如果你想要更多，请查看我的<a class="ae mj" href="https://adataodyssey.com/courses/shap-with-python/" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu"> SHAP 课程</strong> </a> <strong class="kk iu">。</strong>注册我的<a class="ae mj" href="https://mailchi.mp/aa82a5ce1dc0/signup" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu">简讯</strong> </a>:)即可免费获取</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="mk ml l"/></div></figure><h1 id="dc2f" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">资料组</h1><p id="4b81" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">为了演示 SHAP 包，我们将使用一个有 4177 个观察值的<a class="ae mj" href="https://archive.ics.uci.edu/ml/datasets/abalone" rel="noopener ugc nofollow" target="_blank">鲍鱼数据集</a>。下面，你可以看到我们的数据集的快照。鲍鱼是一种美味的贝类。我们想用数据集来预测他们的年龄。更具体地说，我们的目标变量是鲍鱼壳中<strong class="kk iu">环</strong>的数量。我们将使用鲍鱼的<strong class="kk iu">壳长</strong>、<strong class="kk iu">壳径</strong>和<strong class="kk iu">总重</strong>等特征。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nj"><img src="../Images/e5a4072dc2823ac4d8f61eaca3fcad96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*FHLG0i7AKGeauDVmuk8mBA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">(来源:<a class="ae mj" href="https://archive.ics.uci.edu/ml/datasets/abalone" rel="noopener ugc nofollow" target="_blank"> UCI 机器学习库</a>)(许可证:CC0:公共领域)</p></figure><p id="9c77" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在下面的图表中，我们展示了一些特征和目标变量之间的关系。<strong class="kk iu">剥壳重量</strong>是鲍鱼肉的重量(即鲍鱼肉从壳中取出后的重量)。我们可以看到，环的数量随着<strong class="kk iu">去皮重量</strong>的增加而增加。这是有道理的，因为我们预计老鲍鱼会更大，有更多的肉。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nk"><img src="../Images/785f296c7d3612b7375c6ee76713b64a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oo6l5s3w6WIc6wQh2OYGXA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图 1:体重和性别特征的数据探索(来源:作者)</p></figure><p id="3292" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还可视化了鲍鱼的性别，这是一个分类特征。在我们可以在模型中使用这个特性之前，我们需要使用一键编码来转换它。如您所见，这将为每个生成的二进制要素生成一个单独的 SHAP 值。这使得很难理解原始分类特征的总体贡献。我们在下面的文章中探索了一个解决方案。</p><div class="nl nm gp gr nn no"><a rel="noopener follow" target="_blank" href="/shap-for-categorical-features-7c63e6a554ea"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">分类特征的 SHAP</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">将已经用一键编码转换的分类特征的 SHAP 值相加</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">towardsdatascience.com</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc lp no"/></div></div></a></div><p id="ee33" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于数据探索的最后一点，我们为连续特征创建一个相关矩阵。你可以看到我们正在处理高度相关的特征。长度和直径完全相关。同样，<strong class="kk iu">整体重量</strong>与其他重量测量值高度相关。例如肉的重量(<strong class="kk iu">去壳重量</strong>)和除去肉的壳的重量(<strong class="kk iu">壳重</strong>)。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/0512e3de55659dcab5054bf7de26c61e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*S_cxRlYYgeXQQh4EVoqfNQ.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图 2:关联热图(来源:作者)</p></figure><h1 id="f262" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">包装</h1><p id="f779" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">我们在下面导入必要的 Python 包。我们有一些用于管理和可视化数据的标准库(第 2-5 行)。XGBoost 用于建模目标变量(第 7 行)，我们导入一些包来评估我们的模型(第 8 行)。最后，我们导入 SHAP 包(第 10 行)。我们初始化包(第 11 行)。这是为了让我们可以在笔记本上显示一些 SHAP 的情节。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oe ml l"/></div></figure><h1 id="ccd5" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">系统模型化</h1><p id="3d50" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">我们利用数据探索为特征工程提供信息。首先，我们从 X 特征矩阵中去掉长度和整体重量(第 10-11 行)。我们看到这些与其他特征完全相关。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oe ml l"/></div></figure><p id="9852" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们看到<strong class="kk iu">性</strong>是一个分类特征。在模型中使用它之前，我们需要将其转换成 3 个虚拟变量(第 2-4 行)。然后，我们从特征矩阵中删除原始特征(第 5 行)。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oe ml l"/></div></figure><p id="b194" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在有 8 个模型特征。你可以在下面看到这些的快照。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/38ab678dca2c322716c9abd28db36538.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*aJdBHXItHERAnxiQZp5_VA.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">(来源:作者)</p></figure><p id="7ce8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在可以训练一个模型来预测鲍鱼壳上的年轮数量。因为我们的目标变量是连续的，所以我们使用<strong class="kk iu"> XGBRegressor </strong>(第 2 行)。我们在整个特征集上训练模型(第 3 行)。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oe ml l"/></div></figure><p id="d30f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个模型应该足以证明 SHAP 一揽子计划。我们可以通过使用图 3 中的散点图对其进行评估来了解这一点。我们将模型的预测(第 2 行)与实际的环数进行比较。红线给出了我们完美预测的值。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi og"><img src="../Images/cf2c9fcb1044592d232e6d68259cd247.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CRZrOChrazqqNQno0jV1kA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图 3:实际与预测环的散点图(来源:作者)</p></figure><p id="833a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">注意:</strong>我们没有在模型上投入太多精力。除非您使用 SHAP 进行数据探索，否则您应该始终使用最佳实践。你的模型越好，你的 SHAP 分析就越可靠。</p><h1 id="74d0" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">SHAP 地块</h1><p id="4de8" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">最后，我们可以用 SHAP 值来解释这个模型。为此，我们将模型传递给 SHAP <strong class="kk iu">解释器</strong>函数(第 2 行)。这将创建一个解释器对象。我们用它来计算特征矩阵中每个观察值的 SHAP 值(第 3 行)。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oe ml l"/></div></figure><h2 id="682e" class="oh mn it bd mo oi oj dn ms ok ol dp mw kr om on my kv oo op na kz oq or nc os bi translated">情节 1:瀑布</h2><p id="57fe" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">对于特征矩阵中的 4，177 个观察值中的每一个，都有 8 个 SHAP 值。这是我们模型中每个特征的一个 SHAP 值。我们可以使用<strong class="kk iu">瀑布</strong>函数来可视化第一次观察的 SHAP 值(第 2 行)。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oe ml l"/></div></figure><p id="b5f6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> E[f(x)] = 9.933 </strong>给出了所有 4177 只鲍鱼的平均预测年轮数。f(x) = 12.668 是这种特殊鲍鱼的预测年轮数。SHAP 值是介于两者之间的所有值。例如，去皮重量增加了预测环数<strong class="kk iu"> 1.68 </strong></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ot"><img src="../Images/3a21025f814ca1920986bc8430c75f9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N0bblRIhStTgcOywM2uJmw.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图 4:第一次观察的瀑布图(来源:作者)</p></figure><p id="fe56" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我们的数据集中，每个观察/鲍鱼都有一个独特的瀑布图。都可以用和上面一样的方式来解读。在每种情况下，SHAP 值告诉我们与平均预测相比，特征对预测的贡献如何。较大的正值/负值表示该特征对模型的预测有重大影响。</p><h2 id="a946" class="oh mn it bd mo oi oj dn ms ok ol dp mw kr om on my kv oo op na kz oq or nc os bi translated">剧情 2:武力剧情</h2><p id="9534" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">另一种可视化的方法是使用力场图。你可以认为这是一个浓缩的瀑布图。我们从相同的基值<strong class="kk iu"> 9.933 </strong>开始，您可以<strong class="kk iu"> </strong>看到每个特征如何影响<strong class="kk iu"> 13.04 </strong>的最终预测。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oe ml l"/></div></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ou"><img src="../Images/67d4aca5d0f47b451b6e603f645bb834.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G-6hPIwTxFRkUx6IM3HASQ.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图 5:第一次观察的力图(来源:作者)</p></figure><h2 id="1393" class="oh mn it bd mo oi oj dn ms ok ol dp mw kr om on my kv oo op na kz oq or nc os bi translated">图 3:堆叠力图</h2><p id="1be2" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">瀑布图和力量图非常适合解释个人预测。为了了解我们的模型是如何进行预测的，我们需要汇总 SHAP 值。一种方法是使用堆积力图</p><p id="0400" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以将多个力图组合在一起，创建一个堆叠力图。这里，我们在力图函数中传递前 100 次观察的 SHAP 值。每个单独的力图现在是垂直的，并并排堆叠。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oe ml l"/></div></figure><p id="1e56" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以在下面看到这个情节是互动的。我们还可以更改绘图的顺序，并选择要显示的特征贡献。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/b3bda5dd63c145bbf34a0dbcfb0f6532.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*Vdt1l1rhvZ51MEhSsvOvJQ.gif"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图 6:交互式堆叠力图(来源:作者)</p></figure><p id="2372" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，在下图中，我们有:</p><ul class=""><li id="ec49" class="lv lw it kk b kl km ko kp kr lx kv ly kz lz ld ma mb mc md bi translated">仅显示壳重量的 SHAP 值(<strong class="kk iu"> y 轴</strong> <strong class="kk iu"> =壳重量影响</strong>)</li><li id="1394" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">通过壳重量特征值(<strong class="kk iu"> x 轴</strong> <strong class="kk iu"> =壳重量</strong>)命令力图</li></ul><p id="128a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从该图中，我们可以看出，随着壳体重量的增加，SHAP 值也增加。换句话说，老鲍鱼的壳更重。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ow"><img src="../Images/96299cb71c275afe773a57fd718936d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AoaUkqCN7GpZMEeeV9KFow.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图 7:外壳重量的叠加力图(来源:作者)</p></figure><p id="d2fd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是理解我们的模型所捕捉的关系的本质的一种方式。我们将看到蜂群图和依赖图也可以这样使用。</p><h2 id="be60" class="oh mn it bd mo oi oj dn ms ok ol dp mw kr om on my kv oo op na kz oq or nc os bi translated">情节 4:卑鄙的 SHAP</h2><p id="a9e0" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">下一张图将告诉我们哪些特征是最重要的。对于每个特征，我们计算所有观测的平均 SHAP 值。具体来说，我们取绝对值的平均值，因为我们不希望正值和负值相互抵消。最后，我们有下面的条形图。每个功能都有一个栏。例如，我们可以看到<strong class="kk iu">壳重</strong>具有最大的平均 SHAP 值。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oe ml l"/></div></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ox"><img src="../Images/cb463ca275f90f1168216f51195e2372.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QjHmNRXRTkkZ43DXycJzOA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图 8:绝对均值图(来源:作者)</p></figure><p id="3ea1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">具有较大正/负贡献的要素将具有较大的平均 SHAP 值。换句话说，这些特征对模型的预测产生了重大影响。在这种意义上，该图可以以与特征重要性图相同的方式使用。</p><h2 id="3f25" class="oh mn it bd mo oi oj dn ms ok ol dp mw kr om on my kv oo op na kz oq or nc os bi translated">情节 5:蜂群</h2><p id="ffa8" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">接下来，我们有一个最有用的情节。蜂群将所有的 SHAP 值可视化。在 y 轴上，值按要素分组。对于每个组，点的颜色由特征值决定(即特征值越高越红)。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oe ml l"/></div></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi oy"><img src="../Images/130e6fd7a5a5042f98e498274acf8e6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E9qjNl324bRR2KxnyeSJMQ.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图 7:蜂群图(来源:作者)</p></figure><p id="6e3f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">像卑鄙的 SHAP 一样，蜂群可以用来突出重要的关系。事实上，上图中的特征是由平均 SHAP 排序的。</p><p id="98cc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们也可以开始理解这些关系的本质。对于<strong class="kk iu">壳重</strong>，注意当特征值增加时，SHAP 值如何增加。我们在叠加力图中看到了类似的关系。它告诉我们，壳重量的值越大，预测的环数就越多。</p><p id="1677" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可能已经注意到<strong class="kk iu">去皮重量</strong>有相反的关系。查看蜂群图，我们可以看到该特性的较大值与较小的 SHAP 值相关联。我们可以使用依赖图来仔细观察这些关系。</p><h2 id="fdfe" class="oh mn it bd mo oi oj dn ms ok ol dp mw kr om on my kv oo op na kz oq or nc os bi translated">图 6:依赖图</h2><p id="7303" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">相关性图是单个特征的 SHAP 值与特征值的散点图。如果特征与目标变量具有非线性关系，它们特别有用。</p><p id="cf5d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，以壳重量的相关图为例。查看蜂群图，我们可能假设 SHAP 值随着特征值线性增加。依赖图告诉我们，这种关系并不是完全线性的。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oe ml l"/></div></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/ac981ab655cd205d1fad5506cf1d85e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*YUcj_KOJEVSHnPeFjt7s-w.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图 8:弹壳重量的相关图(来源:作者)</p></figure><p id="7bf2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还可以使用第二个特征的值来给散点图着色。我们现在有相同的图，去皮重量越大，点越红。我们可以看到，当壳重和去壳重都很大时，SHAP 值也很大。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oe ml l"/></div></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/ba54172457f56434457f4d269ba58eab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*1lvpN39y8aJCTxdBmBXvWA.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图 9:用去壳重量着色的壳重相关图(来源:作者)</p></figure><p id="7a8a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些图可以用来可视化功能之间的相互作用，但要小心！在我们的例子中，情节是两个特征之间相互关联的结果。</p><p id="bb97" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们也有<strong class="kk iu">剥壳重量</strong>(即鲍鱼肉的重量)的依赖图。使用这个图，我们可以确认我们在蜂群图中看到的关系。SHAP 值随着<strong class="kk iu">去皮重量</strong>的增加而降低。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oe ml l"/></div></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/ec9007ef1fbe1d9a166a2825bf34d328.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*a1cRX8pjNh0D734_mpDEHg.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图 10:去皮重量的相关图(来源:作者)</p></figure><p id="e2f9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">直觉上，这种关系似乎很奇怪。难道我们不会期待老鲍鱼更大，肉更多吗？事实上，这是壳重和去壳重之间的<strong class="kk iu">相互作用</strong>的结果。由于相关性，我们在相关性图中看不到它。在下面的文章中，我们将探讨如何使用 SHAP 互动值来识别这样的互动。</p><div class="nl nm gp gr nn no"><a rel="noopener follow" target="_blank" href="/analysing-interactions-with-shap-8c4a2bc11c2a"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">分析与 SHAP 的互动</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">使用 SHAP Python 包来识别和可视化数据中的交互</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">towardsdatascience.com</p></div></div><div class="nx l"><div class="pc l nz oa ob nx oc lp no"/></div></div></a></div><h1 id="ec6c" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">二元目标变量</h1><p id="aa86" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">二元目标变量的 SHAP 值的解释与上述类似。SHAP 值仍然会告诉我们每个因素对模型预测的贡献大小。不同的是，我们现在用对数概率进行预测。这是一个正面预测的<strong class="kk iu">对数几率</strong>。在图 11 中，您可以看到 SHAP 值给出了预测对数优势和平均预测对数优势之间的差异。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi pd"><img src="../Images/8cc6344b32c42bac83c2c5a556ebe67a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xYY8jluIhx8eoGPUypAmOQ.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图 10:用对数优势解释 SHAP 值(来源:作者)</p></figure><p id="7e57" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了更好地理解这一点，让我们深入 SHAP 的情节。我们首先创建一个二进制目标变量(第 2 行)。这具有以下值:</p><ul class=""><li id="f36b" class="lv lw it kk b kl km ko kp kr lx kv ly kz lz ld ma mb mc md bi translated"><strong class="kk iu"> 1 </strong>如果鲍鱼的年轮数高于平均值</li><li id="c9e3" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated"><strong class="kk iu"> 0 </strong>否则</li></ul><p id="b416" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们使用目标变量和之前相同的特征来训练一个<strong class="kk iu"> XGBoost 分类器</strong>(第 5–6 行)。该模型的准确率为 96.6%</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oe ml l"/></div></figure><p id="92a2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在计算 SHAP 值(第 2-3 行)并显示瀑布图(第 6 行)。注意，代码与连续变量的代码相同。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="oe ml l"/></div></figure><p id="834b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如图 11 所示，即使是瀑布图也是相似的。不同的是基值现在是<strong class="kk iu"> E[f(x)] = -0.789 </strong>。这是所有鲍鱼的平均预测对数概率。对于这种特定的鲍鱼，模型预测其年轮数高于平均水平的概率为<strong class="kk iu"> 0.3958 </strong>(即<strong class="kk iu"> P = 0.3958 </strong>)。这给了我们一个预测的对数几率为<strong class="kk iu">f(x)= ln(0.3958/(1–0.3958))=-0.423。</strong></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi pe"><img src="../Images/850c03e51e9e6d55d7c71c8a73966070.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8lRrJ0OKd5EVaL-BaY-S-w.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图 11:带有二元目标变量的瀑布图(来源:作者)</p></figure><p id="9a0c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正 SHAP 值被解释为增加对数几率。例如，脱壳重量增加了对数几率<strong class="kk iu"> 1.32 </strong>。此功能增加了模型预测高于平均年轮数的可能性。同样，负值会降低对数几率。</p><p id="acea" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们也可以像以前一样聚合这些值。好消息是，对《蜜蜂群》或《SHAP 均值》的解读将是一样的。你只需要记住，我们现在处理的是对数概率。</p><p id="0700" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如我们所见，SHAP 值是用来理解我们的模型如何进行预测的有用工具。然而，我们只是触及了该方案所能提供的皮毛。如果你想了解更多，我写了很多关于 SHAP 的文章。下面的文章深入探讨了 SHAP 和沙普利价值观的某些方面。</p><div class="nl nm gp gr nn no"><a rel="noopener follow" target="_blank" href="/from-shapley-to-shap-understanding-the-math-e7155414213b"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">从沙普利到 Shapley 理解数学</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">如何计算 SHAP 要素贡献的概述</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">towardsdatascience.com</p></div></div><div class="nx l"><div class="pf l nz oa ob nx oc lp no"/></div></div></a></div><div class="nl nm gp gr nn no"><a rel="noopener follow" target="_blank" href="/kernelshap-vs-treeshap-e00f3b3a27db"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">KernelSHAP vs TreeSHAP</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">基于速度、复杂性和其他考虑因素比较 SHAP 近似方法</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">towardsdatascience.com</p></div></div><div class="nx l"><div class="pg l nz oa ob nx oc lp no"/></div></div></a></div><div class="nl nm gp gr nn no"><a rel="noopener follow" target="_blank" href="/using-shap-to-debug-a-pytorch-image-regression-model-4b562ddef30d"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">使用 SHAP 调试 PyTorch 图像回归模型</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">使用 DeepShap 来理解和改进驱动自动驾驶汽车的模型</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">towardsdatascience.com</p></div></div><div class="nx l"><div class="ph l nz oa ob nx oc lp no"/></div></div></a></div></div><div class="ab cl pi pj hx pk" role="separator"><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn"/></div><div class="im in io ip iq"><p id="5e8c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我希望这篇文章对你有帮助！如果你想看更多，你可以成为我的<a class="ae mj" href="https://conorosullyds.medium.com/membership" rel="noopener"><strong class="kk iu"/></a><strong class="kk iu">推荐会员来支持我。你可以访问 medium 上的所有文章，我可以得到你的部分费用。</strong></p><div class="nl nm gp gr nn no"><a href="https://conorosullyds.medium.com/membership" rel="noopener follow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iu gy z fp nt fr fs nu fu fw is bi translated">通过我的推荐链接加入 Medium 康纳·奥沙利文</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">conorosullyds.medium.com</p></div></div><div class="nx l"><div class="pp l nz oa ob nx oc lp no"/></div></div></a></div><p id="7356" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以在|<a class="ae mj" href="https://twitter.com/conorosullyDS" rel="noopener ugc nofollow" target="_blank">Twitter</a>|<a class="ae mj" href="https://www.youtube.com/channel/UChsoWqJbEjBwrn00Zvghi4w" rel="noopener ugc nofollow" target="_blank">YouTube</a>|<a class="ae mj" href="https://mailchi.mp/aa82a5ce1dc0/signup" rel="noopener ugc nofollow" target="_blank">时事通讯</a>上找到我——注册免费参加<a class="ae mj" href="https://adataodyssey.com/courses/shap-with-python/" rel="noopener ugc nofollow" target="_blank"> Python SHAP 课程</a></p><h2 id="34a0" class="oh mn it bd mo oi oj dn ms ok ol dp mw kr om on my kv oo op na kz oq or nc os bi translated">图像来源</h2><p id="63f1" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">所有图片都是我自己的或从<a class="ae mj" href="http://www.flaticon.com/" rel="noopener ugc nofollow" target="_blank">www.flaticon.com</a>获得。在后者的情况下，我拥有他们的<a class="ae mj" href="https://support.flaticon.com/hc/en-us/articles/202798201-What-are-Flaticon-Premium-licenses-" rel="noopener ugc nofollow" target="_blank">保费计划</a>中定义的“完全许可”。</p><h2 id="9d91" class="oh mn it bd mo oi oj dn ms ok ol dp mw kr om on my kv oo op na kz oq or nc os bi translated">参考</h2><p id="02a2" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr ng kt ku kv nh kx ky kz ni lb lc ld im bi translated">南伦德伯格，<em class="le"> SHAP 蟒包</em> (2021) 【T2，<a class="ae mj" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"/></p><p id="aa69" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">南伦德伯格和 s .李，<em class="le">解释模型预测的统一方法</em> (2017 年)，<a class="ae mj" href="https://arxiv.org/pdf/1705.07874.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1705.07874.pdf</a></p><p id="9e02" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">C.Molnar，<em class="le">可解释机器学习</em>(2021)<a class="ae mj" href="https://christophm.github.io/interpretable-ml-book/shap.html" rel="noopener ugc nofollow" target="_blank">https://christophm . github . io/Interpretable-ml-book/shap . html</a></p></div></div>    
</body>
</html>