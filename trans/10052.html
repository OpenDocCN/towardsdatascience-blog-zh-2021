<html>
<head>
<title>A Reply to “TensorFlow Sad Story”</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对“张量流悲伤故事”的回复</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-reply-to-tensorflow-sad-story-b4b52ea59bc3?source=collection_archive---------18-----------------------#2021-09-22">https://towardsdatascience.com/a-reply-to-tensorflow-sad-story-b4b52ea59bc3?source=collection_archive---------18-----------------------#2021-09-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/55abd387f6e10fdba765d15fa9784c6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*o33LethG194AzGA4"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">马库斯·斯皮斯克在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="3812" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated"><span class="l lf lg lh bm li lj lk ll lm di"> T </span>今天我读了Zahar Chikishev 的《TensorFlow Sad Story 》,虽然我同意他的大部分观点，但我觉得这对TensorFlow本身有点不公平，因为它没有试图掩盖或理解TensorFlow为什么是现在这个样子，或者谷歌究竟为什么要做某些事情。自从2019年9月TensorFlow问世以来，我一直是TensorFlow的用户，并且感受到了Zahar在他的文章中描述的许多相同的痛苦，我开始起草一份回复。然而，正如你从这篇文章中看到的，我的评论失去了控制，所以我决定把它变成一个独立的部分。</p><p id="a0d4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">需要澄清的是，我并不为Google或TensorFlow工作，但是，作为一名用户和系统工程师，我也许能够解释为什么TF是现在这个样子(我并不同意它的大部分内容，但是我猜它提供了一些视角)。</p><p id="93cf" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，我或多或少地按照最初帖子的顺序讨论了每个主题，你可以在这里阅读:</p><div class="lp lq gp gr lr ls"><a href="https://medium.com/geekculture/tensorflow-sad-story-cf8e062d84ba" rel="noopener follow" target="_blank"><div class="lt ab fo"><div class="lu ab lv cl cj lw"><h2 class="bd iu gy z fp lx fr fs ly fu fw is bi translated">张量流悲伤故事</h2><div class="lz l"><h3 class="bd b gy z fp lx fr fs ly fu fw dk translated">我已经使用Pytorch好几年了，并且一直很喜欢它。它清晰、直观、灵活、快速。还有…</h3></div><div class="ma l"><p class="bd b dl z fp lx fr fs ly fu fw dk translated">medium.com</p></div></div><div class="mb l"><div class="mc l md me mf mb mg jz ls"/></div></div></a></div><h1 id="ac1d" class="mh mi it bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">易于安装</h1><p id="abc1" class="pw-post-body-paragraph kg kh it ki b kj nf kl km kn ng kp kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">事实上，安装TensorFlow，特别是对于Python生态系统的新手来说，可能是一件痛苦的事情。我想谷歌不介意这一点有几个原因:</p><ol class=""><li id="bd8f" class="nk nl it ki b kj kk kn ko kr nm kv nn kz no ld np nq nr ns bi translated">它免费提供实验室，这样你就可以从那里开始</li><li id="50e1" class="nk nl it ki b kj nt kn nu kr nv kv nw kz nx ld np nq nr ns bi translated">Anaconda已经<a class="ae kf" href="https://anaconda.org/anaconda/tensorflow-gpu" rel="noopener ugc nofollow" target="_blank">为您预打包了TensorFlow </a>及其依赖项，如果您愿意自己安装的话</li><li id="6715" class="nk nl it ki b kj nt kn nu kr nv kv nw kz nx ld np nq nr ns bi translated">大多数(如果不是全部的话)云提供商<a class="ae kf" href="https://aws.amazon.com/machine-learning/amis/" rel="noopener ugc nofollow" target="_blank">将它与他们的GPU实例一起预打包</a></li><li id="42bf" class="nk nl it ki b kj nt kn nu kr nv kv nw kz nx ld np nq nr ns bi translated">坦率地说，到目前为止，这种方法很有效。</li></ol><p id="6eed" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，很大一部分痛苦来自于Nvidia无法发布一个能够跨不同<em class="ny">小</em>版本远程兼容的CUDA SDK。当试图手动安装TensorFlow时，大多数人会犯的错误是找到编译TensorFlow二进制文件所依据的CUDA和cuDNN的确切版本。</p><h1 id="5d6f" class="mh mi it bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">插件包:</h1><p id="aaad" class="pw-post-body-paragraph kg kh it ki b kj nf kl km kn ng kp kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">对于那些不知道的人来说，TensorFlow项目有几个兄弟姐妹，即<a class="ae kf" href="https://www.tensorflow.org/addons" rel="noopener ugc nofollow" target="_blank">插件</a>、<a class="ae kf" href="https://www.tensorflow.org/probability" rel="noopener ugc nofollow" target="_blank">概率</a>、<a class="ae kf" href="https://www.tensorflow.org/graphics" rel="noopener ugc nofollow" target="_blank">图形</a>和<a class="ae kf" href="https://github.com/tensorflow/gan" rel="noopener ugc nofollow" target="_blank">甘</a>，以及一些不太为人知的，如<a class="ae kf" href="https://github.com/tensorflow/similarity" rel="noopener ugc nofollow" target="_blank">相似性</a>、<a class="ae kf" href="https://github.com/tensorflow/agents" rel="noopener ugc nofollow" target="_blank">代理、</a>和其他。您可以通过浏览TensorFlow 的<a class="ae kf" href="https://github.com/orgs/tensorflow/repositories" rel="noopener ugc nofollow" target="_blank"> GitHub页面获得完整列表。</a></p><p id="9e67" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在最初的帖子中，作者抱怨插件包与主包是分开的，这似乎是不必要的，因为他总是两个都安装。虽然我发现了一个微小的麻烦——仅仅是requirements.txt文件中让pip吞食的另一行，但这是用户不总是理解公司基本原理的一个很好的例子。</p><p id="c934" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">TensorFlow是一个庞然大物软件。它是巨大的，跨越数百万行代码、几种语言、几种设备等。此外，使用TensorFlow的所有产品的总和可能接近(或接近)数十亿美元。如果谷歌搞砸了，反弹将是巨大的。因此，将一个项目分割成更易管理的部分是有意义的，比如一个包含所有基本内容的核心包和几个更集中的项目。</p><p id="9b9f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在较小的子项目的一般好处中，我强调:(1)您可以按照自己的步调推进每个子项目，(2)它限制了糟糕的发布的影响，以及(3)它简化了对人们正在使用什么的跟踪。</p><p id="4897" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，最重要的是能够包含你不确定是否会被主流采用的东西。例如，考虑优化器。我猜90%的人只知道亚当或者从来懒得去尝试别人。我在Addons包上数了超过<a class="ae kf" href="https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers" rel="noopener ugc nofollow" target="_blank">十个小说优化器</a>。这些应该添加到核心包中吗？这些年来测试和维护的成本是多少？</p><p id="2d5e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作为深度学习，一个由上个月的研究推动的领域，我们永远无法知道什么将经得起时间的考验。</p><h1 id="6f5c" class="mh mi it bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">渴望是一场骗局:</h1><p id="bc0f" class="pw-post-body-paragraph kg kh it ki b kj nf kl km kn ng kp kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">急切执行是TensorFlow 2最令人期待的特性之一。它将为TensorFlow带来PyTorch式的开发体验，摆脱该死的“会话”基本原理是，eager可以调试，但速度较慢，而deferred(图形模式)更快，因为它编译代码，但不能直接调试。谷歌解释说，当训练他们的模型时，人们会使用渴望调试和切换图形模式。</p><p id="bf53" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">《张量流悲伤的故事》的作者引用了:</p><blockquote class="nz oa ob"><p id="c40d" class="kg kh ny ki b kj kk kl km kn ko kp kq oc ks kt ku od kw kx ky oe la lb lc ld im bi translated">TensorFlow 2.0急切地执行(就像Python通常做的那样)，在2.0中，图形和会话应该感觉像实现细节。</p><p id="0831" class="kg kh ny ki b kj kk kl km kn ko kp kq oc ks kt ku od kw kx ky oe la lb lc ld im bi translated"><em class="it">对于计算密集型模型，比如在GPU上进行ResNet50训练，急切执行性能堪比</em> <code class="fe of og oh oi b"><a class="ae kf" href="https://www.tensorflow.org/api_docs/python/tf/function" rel="noopener ugc nofollow" target="_blank"><em class="it">tf.function</em></a></code> <em class="it">执行。但是对于计算量较少的模型来说，这种差距会变得更大，对于有大量小操作的模型来说，优化热代码路径还有很多工作要做。</em></p></blockquote><p id="c86f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一个引用中提出的要点是<em class="ny">大多数时候，您可以在两个</em>之间无缝切换。第二段引文指出<em class="ny">图模式受益于许多低成本操作和优化路径</em>。这里的问题是，“多低的成本才算足够低？”。作者提到使用ResNet-50模型，并使用图形模式获得超过五倍的执行速度。如果我是猜测，批量太小，或者GPU是相当强大的。在这两种情况下，即使是ResNet-50操作也可以被称为低成本。</p><p id="c3c2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">后来作者提到文档不鼓励使用渴望模式。的确，它本可以措辞得更好。默认情况下，急切模式是关闭的，因为这样更快。然而，如果你正在调试，你可以打开它，随心所欲地调试，然后关闭它。</p><p id="90ec" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">具有讽刺意味的是，PyTorch渴望模式默认情况下很快，而TensorFlow很慢。事实上，PyTorch提供了一个混合解决方案，将Torch代码JIT化为图形模式，以提高性能。我猜如果PyTorch团队认为有必要实现一个JIT编译器…</p><h1 id="f012" class="mh mi it bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">数据API:</h1><p id="7b35" class="pw-post-body-paragraph kg kh it ki b kj nf kl km kn ng kp kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">我完全同意tf.data.Dataset很乱，我不会说我大部分时间都喜欢它。</p><p id="6ebb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个API之所以这么烂，是因为它伪装的非常TF1化(而且所有TF1的东西都很烂)。data API被设计成跟踪你的代码到C++调用中，所以当你用Python写代码时，它被跟踪到一个图形模式表示，并在CPU C++后端运行。</p><p id="ecb3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">基本原理是性能:虽然Python苦于不可并行化(参见<a class="ae kf" href="https://realpython.com/python-gil/" rel="noopener ugc nofollow" target="_blank">全局解释器锁</a> (GIL))，但C++代码可以在所有可用的CPU线程上自由运行，因此可以更快地处理数据集，从而让GPU保持忙碌。缺点是生成的代码无法调试(毕竟是图形模式)，运行任何外部Python代码都有极其痛苦的语法和性能。</p><p id="a66b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">只有图形模式是TF1的事情，希望它将成为整个图书馆的过去。与此同时，<a class="ae kf" href="https://github.com/tensorflow/tensorflow/releases/tag/v2.5.0" rel="noopener ugc nofollow" target="_blank"> TensorFlow 2.5增加了对tf.data.Dataset </a>的实验性热切支持，这是一个开始。</p><h1 id="7c0f" class="mh mi it bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">API复制:</h1><p id="e982" class="pw-post-body-paragraph kg kh it ki b kj nf kl km kn ng kp kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">TensorFlow确实具有大量重复的功能。起初这很可怕，但实际上并不是问题。这些大部分都是帮助人们从TF1移植代码的遗留操作。如果谷歌放弃所有1.x的东西，他们永远不会让人们更新。</p><p id="0507" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一个例子是TF 1.x如何拥有自己的操作(比如卷积)，然后公开一个更高级的API (slim)。在此之后，他们开始整合类似Keras的语法(tf.layers)，这导致采用Keras本身作为其主要后端(tf.keras)。所以，现在，他们不得不处理所有这些遗留代码。希望他们会在TensorFlow 3.0版本中剥离大部分内容，或者更好的是，<a class="ae kf" href="https://github.com/google/jax" rel="noopener ugc nofollow" target="_blank"> JAX </a>会取代生态系统。</p><p id="67bc" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在实践中，您只需关心tf.nn模块(类似于PyTorch)和tf.keras包(高级API ),它隐藏了许多样板文件和形状/尺寸计算。这两个tf.keras是主要的API，而tf.nn用于实现定制的东西。</p><h1 id="d731" class="mh mi it bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">草率开发:</h1><p id="4d50" class="pw-post-body-paragraph kg kh it ki b kj nf kl km kn ng kp kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">都是真的。句号。</p><p id="bfaa" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">特别是ImageDataGenerator，它是Keras中最流行的数据扩充方法，在我看来，它一直是一个失去控制的样本代码，并开始在生产中使用。</p></div><div class="ab cl oj ok hx ol" role="separator"><span class="om bw bk on oo op"/><span class="om bw bk on oo op"/><span class="om bw bk on oo"/></div><div class="im in io ip iq"><p id="5d3b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated"><span class="l lf lg lh bm li lj lk ll lm di">最后一点，虽然我确实认为谷歌可以做得更好，但我知道TensorFlow是第一个为大规模模型设计的开源深度学习包之一，因此完全关注速度。在这方面，承认当时的情况是值得注意的。首先，神经网络几十年来一直是个笑话；它们速度慢，难以训练，并且不能提供有意义的好处。人工智能社区对决策树和支持向量机更感兴趣。</span></p><p id="0854" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着CUDA或在GPU上编程非图形的东西，事情开始发生变化。Nvidia在2007年发布了第一个公开版本的CUDA。当时，它主要是实验性的技术，有一些有趣的用例，但是使用它太痛苦了，而且工具很糟糕(现在仍然是，IMHO)。因此，它的大部分采用来自不同的来源和图形社区本身。直到2012年9月30日，CUDA(和神经网络)才有了改变人生的突破:AlexNet。</p><p id="c165" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用CUDA训练的卷积神经网络赢得ImageNet比赛并不是AlexNet的唯一壮举；它也成功做到了这一点，准确率提高了10个百分点以上。它引起了人们的注意。问题是:所有可用的神经网络工具充其量都是实验性和学术性的。此外，使用CUDA虽然并不完全新颖，但绝对不是主流。比赛开始了。</p><p id="d6cb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从AlexNet到TensorFlow首次公开发布，整整用了3年1个月11天。换句话说，对于谷歌大脑团队来说，要将他们在神经网络上的一切重新规划成某种东西，他们可以复制突破性的结果，做进一步的最先进的研究，并向公众开放。</p><p id="b2f2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在谷歌大脑团队的论文标题中快速搜索“深度”一词，我们从2000年到2011年总共有3篇论文。在那个时候，人们对“深度学习”或“深度神经网络”没有那么多兴趣。2012年发布次数变为3次，2013年变为9次，2014年变为10次，2015年TensorFlow发布时(准确的说是2015年11月11日)变为20次。</p><p id="87db" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从那时起，没有一年没有一些突破性的变化或新奇。试图暴露深度学习的最新水平是一场猫捉老鼠的游戏。PyTorch是在TensorFlow之后一年左右发布的，而变形金刚是在那之后一年提出的。在2018年，2019年和2020年，我们分别有GPT-1，-2和-3，嘿，我们在2021年，GPT-4的谣言正在流传！</p><p id="54a7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我在这里的观点是，深度学习是一种不断发展的技术，因此，工具总是滞后的。因此，下一个将总是更闪亮，或者至少不会过时。</p><p id="3652" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每个计算机架构师都是赌徒。谷歌工程师打赌性能将主导市场，并为此设计了TensorFlow，赢得了最大的市场份额。脸书工程师赌上了灵活性，这在学术界获得了回报，但在行业采用方面却落后了。Keras的创造者Franç ois Chollet将赌注押在了易用性上。</p><p id="a84b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">谁是对的？可能没有，因为世界正在转向大规模分布式的基于注意力的模型。谁会想到呢？上述工具都不适合这种情况。难怪会看到新的竞争者在函数式编程上下赌注。</p><p id="5b14" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尽管如此，我们看到PyTorch增加了图形模式，TensorFlow拥有渴望的功能，并且两者今天都有类似Keras的API。而且，都是互相学习。</p><p id="5c20" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">长话短说，TensorFlow有它自己的问题，但是，就像任何其他库一样，其他一些库将会出现并成为它应该成为的样子，其他一些库也会取代它。变化是软件的美妙之处。</p><p id="212a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有人知道Java Servlets吗？</p></div><div class="ab cl oj ok hx ol" role="separator"><span class="om bw bk on oo op"/><span class="om bw bk on oo op"/><span class="om bw bk on oo"/></div><div class="im in io ip iq"><p id="131d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">暂时就这些了。如果您对本文有任何问题，请随时发表评论或与我联系。</p><p id="5fe4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你刚接触媒体，我强烈推荐<a class="ae kf" href="https://ygorserpa.medium.com/membership" rel="noopener">订阅</a>。对于数据和IT专业人士来说，中型文章是<a class="ae kf" href="https://stackoverflow.com/" rel="noopener ugc nofollow" target="_blank"> StackOverflow </a>的完美搭档，对于新手来说更是如此。注册时请考虑使用<a class="ae kf" href="https://ygorserpa.medium.com/membership" rel="noopener">我的会员链接。</a></p><p id="1db4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢阅读:)</p></div></div>    
</body>
</html>