<html>
<head>
<title>Using Transfer Learning for Breast Cancer Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用迁移学习进行乳腺癌检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-transfer-learning-for-breast-cancer-detection-2fb3785e2aa?source=collection_archive---------46-----------------------#2021-05-31">https://towardsdatascience.com/using-transfer-learning-for-breast-cancer-detection-2fb3785e2aa?source=collection_archive---------46-----------------------#2021-05-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="971c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">具有高效微调的多尺度Inception V3方法</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/94d0b2938897e6d06730c4567e974e6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PBWiAvHBCg2Y79KK.jpg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://camelyon16.grand-challenge.org/Data" rel="noopener ugc nofollow" target="_blank">注有癌性肿瘤细胞的组织切片</a></p></figure><h1 id="063c" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><blockquote class="lo lp lq"><p id="37aa" class="lr ls lt lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">每年，美国有超过230，000名乳腺癌患者取决于癌症是否转移。转移检测由病理学家检查大量的生物组织来进行。这个过程是劳动密集型的并且容易出错。<a class="ae kv" href="https://arxiv.org/abs/1703.02442" rel="noopener ugc nofollow" target="_blank">来源</a></p></blockquote><p id="c8af" class="pw-post-body-paragraph lr ls iq lu b lv lw jr lx ly lz ju ma mo mc md me mp mg mh mi mq mk ml mm mn ij bi translated">在这个项目中，我们旨在实现论文<a class="ae kv" href="https://arxiv.org/abs/1703.02442" rel="noopener ugc nofollow" target="_blank"> <strong class="lu ir">中提出的多尺度转移分类模型，在千兆像素病理图像上检测癌症转移</strong> </a>。</p><h1 id="1d9d" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">资料组</h1><p id="68d1" class="pw-post-body-paragraph lr ls iq lu b lv mr jr lx ly ms ju ma mo mt md me mp mu mh mi mq mv ml mm mn ij bi translated">我们使用<a class="ae kv" href="https://camelyon16.grand-challenge.org/Data/" rel="noopener ugc nofollow" target="_blank">camelion-16</a>多千兆像素的幻灯片数据。从主数据集中采样一组22个具有显著肿瘤的载玻片。每张载玻片都有一个相应的标记肿瘤区域的遮罩。我们可以访问大约9个放大级别。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/7eca87d001647b9a1250baf0bd79ad49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/0*NadKCpN7UJVQmcBw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">多倍放大肿瘤图像(。tif文件)<a class="ae kv" href="https://camelyon16.grand-challenge.org/Data/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="1976" class="pw-post-body-paragraph lr ls iq lu b lv lw jr lx ly lz ju ma mo mc md me mp mg mh mi mq mk ml mm mn ij bi translated">每个多尺度图像以一致的坐标系一个接一个地存储，以允许用户访问任何放大倍数的任何图像片段。</p><p id="b195" class="pw-post-body-paragraph lr ls iq lu b lv lw jr lx ly lz ju ma mo mc md me mp mg mh mi mq mk ml mm mn ij bi translated">我们利用<a class="ae kv" href="https://openslide.org/" rel="noopener ugc nofollow" target="_blank"> OpenSlide </a> C库及其Python绑定来高效地访问千兆像素大小的压缩文件。</p><h1 id="b21c" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">数据准备</h1><p id="2dfe" class="pw-post-body-paragraph lr ls iq lu b lv mr jr lx ly ms ju ma mo mt md me mp mu mh mi mq mv ml mm mn ij bi translated">作为生成标记的训练数据的第一步，我们使用滑动窗口方法在较高的缩放级别上滑动，并创建幻灯片片段的标记图像，稍后我们将使用这些图像进行训练和测试。</p><p id="da01" class="pw-post-body-paragraph lr ls iq lu b lv lw jr lx ly lz ju ma mo mc md me mp mg mh mi mq mk ml mm mn ij bi translated">我们使用论文中的方法，定义一个中心窗口，如果中心包含至少1个标记为肿瘤的像素，我们将图像标记为包含肿瘤细胞。</p><p id="375f" class="pw-post-body-paragraph lr ls iq lu b lv lw jr lx ly lz ju ma mo mc md me mp mg mh mi mq mk ml mm mn ij bi translated">窗口大小和中心大小分别被选择为80和50。最后，为了使我们的训练数据具有多尺度，我们创建了原始图像片段的类似大小的缩小版本。缩小版本用于向分类模型提供宏观级别的上下文。我们使用<strong class="lu ir">多尺度</strong>方法生成数据，并使用两种不同的放大倍数来准备数据集。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/7aae09ba9127c047b1263a40c7f267e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*wLbQikyXqYMdgoViZ1YZxQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://camelyon16.grand-challenge.org/Data" rel="noopener ugc nofollow" target="_blank">多尺度图像对</a></p></figure><h1 id="1ce0" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">数据扩充</h1><p id="21c3" class="pw-post-body-paragraph lr ls iq lu b lv mr jr lx ly ms ju ma mo mt md me mp mu mh mi mq mv ml mm mn ij bi translated">我们使用了各种数据扩充技术来补充我们的训练数据，使我们的模型更加稳健。</p><h2 id="2c40" class="my kx iq bd ky mz na dn lc nb nc dp lg mo nd ne li mp nf ng lk mq nh ni lm nj bi translated">正交旋转和翻转</h2><p id="4604" class="pw-post-body-paragraph lr ls iq lu b lv mr jr lx ly ms ju ma mo mt md me mp mu mh mi mq mv ml mm mn ij bi translated">我们引入了正交扩充来引入旋转不变性，因为载玻片可以在这些方向中的任何方向上被检查</p><ul class=""><li id="4754" class="nk nl iq lu b lv lw ly lz mo nm mp nn mq no mn np nq nr ns bi translated">随机正交旋转</li><li id="3da8" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn np nq nr ns bi translated">随机水平和垂直翻转</li></ul><h2 id="4fa7" class="my kx iq bd ky mz na dn lc nb nc dp lg mo nd ne li mp nf ng lk mq nh ni lm nj bi translated">颜色扰动</h2><p id="dfd2" class="pw-post-body-paragraph lr ls iq lu b lv mr jr lx ly ms ju ma mo mt md me mp mu mh mi mq mv ml mm mn ij bi translated">为了使我们的模型对光照和染料强度有鲁棒性，我们对颜色做了如下改动。</p><ul class=""><li id="ccc4" class="nk nl iq lu b lv lw ly lz mo nm mp nn mq no mn np nq nr ns bi translated">最大差值为64/255的亮度</li><li id="05f2" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn np nq nr ns bi translated">最大增量为0.25的饱和度</li><li id="74c4" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn np nq nr ns bi translated">最大差值为0.04的色调</li><li id="e038" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn np nq nr ns bi translated">与最大增量0.75形成对比</li></ul><h1 id="bc28" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">方法学</h1><p id="cd91" class="pw-post-body-paragraph lr ls iq lu b lv mr jr lx ly ms ju ma mo mt md me mp mu mh mi mq mv ml mm mn ij bi translated">我们利用多塔Inception V3模型来利用多尺度图像进行分类。我们只对顶层进行了微调，因为这些层学习更高级的功能，并且可以通过基于我们的数据集对这些层进行微调来大大改善结果。阅读谷歌人工智能的这篇博文了解更多细节</p><ul class=""><li id="5f72" class="nk nl iq lu b lv lw ly lz mo nm mp nn mq no mn np nq nr ns bi translated"><strong class="lu ir">使用的架构:</strong> Inceptionv3(多尺度)<em class="lt">微调图层&gt; 150 </em></li><li id="678b" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn np nq nr ns bi translated"><strong class="lu ir">初始权重:</strong>图像净</li><li id="89bf" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn np nq nr ns bi translated"><strong class="lu ir">损失使用:</strong>二元交叉熵损失</li><li id="2313" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn np nq nr ns bi translated"><strong class="lu ir">放大倍率:</strong>2级和3级</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/87a2863c800812952cb8d1cbdee08d6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*K-Sv5wqk7IT2flIQR5pRhw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">多尺度模型结构</p></figure><h1 id="b833" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结果</h1><p id="846a" class="pw-post-body-paragraph lr ls iq lu b lv mr jr lx ly ms ju ma mo mt md me mp mu mh mi mq mv ml mm mn ij bi translated">我们最后基于一个新的肿瘤切片测试了我们的模型。在对肿瘤切片进行预处理并进行预测后，我们使用模型输出创建了一个热图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/b272d7b1f5579ac2be3f9a9e0a0e7652.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EiViKtslX5DRNBQi"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">真实肿瘤掩模与预测肿瘤掩模</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/1d47738c691648c3b71503d001e72220.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/0*_cM58pkeb81KrgJo"/></div></figure><ol class=""><li id="110e" class="nk nl iq lu b lv lw ly lz mo nm mp nn mq no mn ob nq nr ns bi translated"><strong class="lu ir"> AUC </strong> : 0.97659</li><li id="5fd2" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn ob nq nr ns bi translated"><strong class="lu ir">阈值</strong> : 0.48429</li><li id="aadf" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn ob nq nr ns bi translated"><strong class="lu ir">灵敏度</strong> : 0.97478</li><li id="e38e" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn ob nq nr ns bi translated"><strong class="lu ir">特异性</strong> : 0.95004</li><li id="c7d0" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn ob nq nr ns bi translated">召回 : 0.97277</li><li id="39fd" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn ob nq nr ns bi translated"><strong class="lu ir">精度</strong> : 0.22275</li></ol><ul class=""><li id="d8f6" class="nk nl iq lu b lv lw ly lz mo nm mp nn mq no mn np nq nr ns bi translated">我们看到所有的肿瘤区域都被正确识别。</li><li id="8e3a" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn np nq nr ns bi translated">我们可以产生非常高的召回率(这在医学预后的背景下是很重要的)</li><li id="5e52" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn np nq nr ns bi translated">带有微调的迁移学习在通过计算强度较低的训练产生良好结果方面是有效的</li><li id="5f19" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn np nq nr ns bi translated">该模型对边界的预测似乎不太准确。</li></ul><h1 id="7863" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">未来的改进</h1><ul class=""><li id="d40c" class="nk nl iq lu b lv mr ly ms mo oc mp od mq oe mn np nq nr ns bi translated">通过访问更好的GPU和高RAM机器，使用更高放大倍数的图像。</li><li id="18dd" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn np nq nr ns bi translated">通过计算每个可能的幻灯片方向上的预测来使用预测平均，以提高准确性并引入旋转不变性。</li><li id="7147" class="nk nl iq lu b lv nt ly nu mo nv mp nw mq nx mn np nq nr ns bi translated">使用更好的前景和背景分离技术来提高边界的性能。</li></ul></div><div class="ab cl of og hu oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="ij ik il im in"><p id="bfc9" class="pw-post-body-paragraph lr ls iq lu b lv lw jr lx ly lz ju ma mo mc md me mp mg mh mi mq mk ml mm mn ij bi translated">如果你有任何问题，你可以通过<a class="ae kv" href="http://smarth.g@columbia.edu/" rel="noopener ugc nofollow" target="_blank">smarth.g@columbia.edu</a>联系我。在<a class="ae kv" href="https://www.linkedin.com/in/smarth-gupta/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae kv" href="https://twitter.com/smurphyxg" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注我。</p><p id="698d" class="pw-post-body-paragraph lr ls iq lu b lv lw jr lx ly lz ju ma mo mc md me mp mg mh mi mq mk ml mm mn ij bi translated"><strong class="lu ir">谢谢！</strong></p></div><div class="ab cl of og hu oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="ij ik il im in"><h1 id="c20a" class="kw kx iq bd ky kz om lb lc ld on lf lg jw oo jx li jz op ka lk kc oq kd lm ln bi translated">参考</h1><p id="ecc2" class="pw-post-body-paragraph lr ls iq lu b lv mr jr lx ly ms ju ma mo mt md me mp mu mh mi mq mv ml mm mn ij bi translated">[1] <a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y" rel="noopener ugc nofollow" target="_blank"> Y .刘</a>，<a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gadepalli%2C+K" rel="noopener ugc nofollow" target="_blank"> K .加德帕利</a>，<a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Norouzi%2C+M" rel="noopener ugc nofollow" target="_blank">m .</a>，<a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dahl%2C+G+E" rel="noopener ugc nofollow" target="_blank"> G. E .达尔</a>，<a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kohlberger%2C+T" rel="noopener ugc nofollow" target="_blank"> T .科尔伯格</a>，<a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boyko%2C+A" rel="noopener ugc nofollow" target="_blank">a .</a>，<a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Venugopalan%2C+S" rel="noopener ugc nofollow" target="_blank"> S .韦努戈帕兰</a>，<a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Timofeev%2C+A" rel="noopener ugc nofollow" target="_blank">a .</a>，<a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Nelson%2C+P+Q" rel="noopener ugc nofollow" target="_blank"> P. Q .纳尔逊</a>，<a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Corrado%2C+G+S" rel="noopener ugc nofollow" target="_blank"> G</a></p><p id="739f" class="pw-post-body-paragraph lr ls iq lu b lv lw jr lx ly lz ju ma mo mc md me mp mg mh mi mq mk ml mm mn ij bi translated">[2]骆驼数据集</p></div></div>    
</body>
</html>