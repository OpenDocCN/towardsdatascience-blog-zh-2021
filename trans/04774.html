<html>
<head>
<title>The importance of systems adaptability for meaningful Responsible AI deployment</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">系统适应性对有意义的负责任的人工智能部署的重要性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-importance-of-systems-adaptability-for-meaningful-responsible-ai-deployment-a14e6ccd0f35?source=collection_archive---------42-----------------------#2021-04-25">https://towardsdatascience.com/the-importance-of-systems-adaptability-for-meaningful-responsible-ai-deployment-a14e6ccd0f35?source=collection_archive---------42-----------------------#2021-04-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/8a946a6fea5c8b6202e70cce559697a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eupvDljfEdReX7IJjXJenw.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">照片由Petr Ruzicka在Unsplash上拍摄</p></figure><p id="5703" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">到目前为止，我们已经讨论了一些关于如何部署负责任的人工智能的想法，包括“<a class="ae ld" rel="noopener" target="_blank" href="/the-importance-of-goal-setting-in-product-development-to-achieve-responsible-ai-eda040809292">在产品开发中设定目标以实现负责任的人工智能的重要性</a>”、“<a class="ae ld" rel="noopener" target="_blank" href="/tradeoff-determination-for-ethics-safety-and-inclusivity-in-ai-systems-60f20a3d0d0c">在人工智能系统中权衡道德、安全和包容性的决定</a>”和“<a class="ae ld" rel="noopener" target="_blank" href="/systems-design-thinking-for-responsible-ai-a0e51a9a2f97">负责任的人工智能的系统设计思维</a>”，这些想法向我们表明，从相邻和相关领域借鉴想法可以帮助将负责任的人工智能变为现实，而不是空想。</p><p id="8f99" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">让我们利用这篇文章来探索系统适应性的想法，这是另一个可以帮助我们在实践中实现负责任的人工智能的原则。</p><h1 id="034a" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">活力</h1><p id="8d1f" class="pw-post-body-paragraph kf kg it kh b ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky mg la lb lc im bi translated">人类是动态的！(毫无意外！)</p><p id="ef3e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们的经营环境也是如此。</p><blockquote class="mh mi mj"><p id="d30c" class="kf kg mk kh b ki kj kk kl km kn ko kp ml kr ks kt mm kv kw kx mn kz la lb lc im bi translated">所有的模型都是错的，但有些是有用的。—乔治·博克斯</p></blockquote><p id="b4c7" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">必要的是，当我们有一个人工智能系统时，我们必须对它将要部署的世界做出一些简化的假设。这样的假设将高保真的真实世界转化为低分辨率的数字世界，我们在那里进行优化，我们<em class="mk">希望</em>它们能推广到真实世界。</p><p id="1431" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">但是，希望不是策略！(我的意思是技术上我们当然不希望；在发布之前，我们会进行测试、评估、验证和确认。如果你没有这样做，请这样做！)</p><p id="7dcf" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">牢记这一点，我们需要确保我们能够以审慎的方式适应这种动态。我们需要这样做的原因是，在一个动态的世界中，人工智能系统的僵化会导致伦理挑战。</p><p id="2489" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们举个例子。</p><p id="cb10" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">考虑一下每季度更新一次的内容审核系统，因为培训和部署成本很高。这可能是因为巨大的成本、不成熟的基础设施，或者团队认为他们不需要更频繁地进行这些更新。或者任何数量的其他原因。那么什么会出错呢？</p><p id="7707" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在一个数字化和互联的世界里，语言(如果我们以单峰内容调节为例)迅速呈现出新的语义。想一想政治运动可以采用一个词成为呼号，或者单词如何在网上变成仇恨言论。这可能在几周内发生。系统的季度更新可能会滞后于现实世界中发生的变化，从而限制其效力，并让仇恨言论在平台上不受限制地蔓延。</p><p id="11fa" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">非自适应系统或缓慢自适应系统有可能偏离目标，并导致比其在实践中旨在减轻的危害更大的危害。</p><p id="ecda" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">那么，我们能做些什么来应对这些挑战呢？</p><h1 id="2239" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">如何做到这一点的建议</h1><p id="de56" class="pw-post-body-paragraph kf kg it kh b ki mc kk kl km md ko kp kq me ks kt ku mf kw kx ky mg la lb lc im bi translated">鉴于我在本文顶部链接的一些文章，这可能看起来很老套，但它值得重复，因为它非常重要:将正确的利益相关者带到桌面上来！在这种情况下，它特别包括社区利益相关者，他们将是系统的主体，以及他们周围可能在管理系统中发挥作用的人。这一点之所以重要，是因为我们永远不知道一个系统将如何在现场准确使用，以及它可能如何被滥用(有意或无意)。将这些利益攸关方聚集在一起的做法将有助于阐明这些关切，并将它们置于中心位置。</p><p id="98e4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">内部红队的工作是破坏系统，这也有助于找到系统被滥用的方法。这是安全测试中的常见做法，也应该成为人工智能系统中更常见的事情。机器学习安全领域就是关注这一点的领域。这样的红队也可以帮助对系统进行压力测试，发现系统开始表现不稳定的新方式。这对于运输和医疗等关键任务系统尤为重要。</p><p id="2a31" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">适应性还来自于快速替换不工作或行为不当的模型的能力。这需要一个成熟的MLOps基础架构才能成功。我在“<a class="ae ld" href="https://actionableaiethics.substack.com/p/actionable-ai-ethics-1-adopting-an" rel="noopener ugc nofollow" target="_blank">采用人工智能伦理的MLOps思维模式</a>”中更多地谈到了这个想法。</p><p id="3061" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">期待听到你的意见，谈谈你认为我们可以实现更具系统适应性的其他方式，以进行有意义的负责任的人工智能部署。</p><blockquote class="mh mi mj"><p id="bec0" class="kf kg mk kh b ki kj kk kl km kn ko kp ml kr ks kt mm kv kw kx mn kz la lb lc im bi translated"><strong class="kh iu">了解更多关于我的作品</strong> <a class="ae ld" href="https://atg-abhishek.github.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh iu">这里</strong> </a> <strong class="kh iu">！</strong></p><p id="a698" class="kf kg mk kh b ki kj kk kl km kn ko kp ml kr ks kt mm kv kw kx mn kz la lb lc im bi translated"><strong class="kh iu">还有，看看我作为</strong> <a class="ae ld" href="https://montrealethics.ai/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh iu">蒙特利尔人工智能伦理研究所</strong> </a> <strong class="kh iu">的一部分发布的</strong> <a class="ae ld" href="https://brief.montrealethics.ai/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh iu">人工智能伦理简报</strong> </a> <strong class="kh iu">！</strong></p></blockquote></div></div>    
</body>
</html>