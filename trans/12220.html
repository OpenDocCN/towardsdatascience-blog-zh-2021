<html>
<head>
<title>Hierarchical Classification of Expected Answer Type in Knowledge Graph Question Answering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">知识图问答中期望答案类型的层次分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hierarchical-classification-of-expected-answer-type-in-knowledge-graph-question-answering-6c7b72d65923?source=collection_archive---------10-----------------------#2021-12-11">https://towardsdatascience.com/hierarchical-classification-of-expected-answer-type-in-knowledge-graph-question-answering-6c7b72d65923?source=collection_archive---------10-----------------------#2021-12-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="569d" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><div class=""><h2 id="aeaf" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">机器如何理解用户在问什么？</h2></div><h1 id="23fb" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">TLDR</h1><p id="8691" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">人们在寻找一个问题的答案时使用的一个重要步骤是了解哪种类型的答案最适合[1]。例如，对于“现在几点了？”我们希望听到“时间”类型的回答，以及“伊万·彼得罗夫出生在哪里？”—类型为“城市”或“国家”的答案。</p><p id="e2d8" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">基于知识图的问答系统也是如此，其目的是找到仿真问题的答案。本文介绍了一个用于确定预期答案类型(EAT)的模块，该模块不仅能够预测单个类，还能够构建类的层次结构作为预测值。该模块既作为<a class="ae mh" href="https://webengineering.ins.hs-anhalt.de:41009/eat-classification" rel="noopener ugc nofollow" target="_blank">网络界面(UI) </a>提供，也作为<a class="ae mh" href="https://webengineering.ins.hs-anhalt.de:41020/docs" rel="noopener ugc nofollow" target="_blank"> RESTful API </a>提供。该功能允许最终用户获得<a class="ae mh" href="https://github.com/google-research/bert/blob/master/multilingual.md#list-of-languages" rel="noopener ugc nofollow" target="_blank"> 104种语言</a>的答案类型预测，查看预测的可信度并留下反馈。此外，API允许研究人员和开发人员将EAT分类模块集成到他们的系统中。</p><blockquote class="mi"><p id="716f" class="mj mk iq bd ml mm mn mo mp mq mr mb dk translated"><em class="ms">通过问题理解一个人在问什么是人类用来找到相应答案的第一步。</em></p></blockquote><figure class="mu mv mw mx my mz gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mt"><img src="../Images/9f14f0cda0d52789ab46b9a5b3106e28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rtaiKrazxWVrVcIN_2DU8Q.png"/></div></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">预期答案类型分类器的Web用户界面(图片由作者提供)</p></figure><h1 id="3a9f" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">知识图问答系统</h1><p id="5ef5" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><em class="nk">开发问答系统</em>有两种范式:(1)基于非结构化数据(基于IR)，其目标是在一组文本文档中找到最相关的段落，(2)基于结构化数据和知识(KBQA)，这类系统将自然语言问题翻译成形式化的查询(SQL、SPARQL等)。) [2].另外，我们应该提到知识图问答系统(KGQA)，它是KBQA的一个子集，最近变得越来越流行。</p><figure class="nm nn no np gt mz gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/bd86628ce729d81293f7fcc0ffdda4ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*HXeDz_tJ9hnp4LO7H3IfUQ.jpeg"/></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">开发问答系统的范例(图片由作者提供)</p></figure><p id="7b1d" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">顾名思义，<em class="nk"> KGQA系统由知识图</em>驱动，通常使用<a class="ae mh" href="https://www.w3.org/TR/rdf-primer/" rel="noopener ugc nofollow" target="_blank">资源描述框架(RDF) </a>存储，这又允许通过<a class="ae mh" href="https://www.w3.org/TR/rdf-sparql-query/" rel="noopener ugc nofollow" target="_blank"> SPARQL </a>查询访问数据。换句话说，KGQA系统的目标是将自然语言问题转换成SPARQL查询，以便简化最终用户的数据访问。</p><p id="fb9a" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">向KGQA系统提出的问题是基于事实的。例如，当我们问“安格拉·默克尔出生在哪个城市？”我们希望看到“城市”类型的答案，在这个例子中是汉堡。在这种情况下，“城市”是预期的答案类型。根据KGQA系统中使用的特定知识图，这些类型通常被组织成层次分类法或本体(例如<a class="ae mh" href="https://www.dbpedia.org/resources/ontology/" rel="noopener ugc nofollow" target="_blank"> DBpedia本体</a>)。考虑“安格拉·默克尔出生在哪个城市？”预期的答案类型层次结构(基于DBpedia本体中的类)如下所示。</p><figure class="nm nn no np gt mz gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nq"><img src="../Images/41b17c4d2caaca40b60fa0b4ccfdd3b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*584zRDyrkP2Gf2tf-ipmaA.jpeg"/></div></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">问题“安格拉·默克尔出生在哪个城市？”的预期答案类型层次结构给出DBpedia本体(图片由作者提供)</p></figure><p id="cdc1" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">在这个层次中，第一种类型是最具体的，而最后一种类型是最普遍的。</p><p id="80df" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated"><em class="nk">为什么KGQA系统需要知道预期的答案类型？</em>非常简单——它将答案的搜索空间缩小了数倍。这可以通过一个简单的例子(参见下面的代码片段)来说明，这个例子使用了我们熟悉的安格拉·默克尔问题。</p><pre class="nm nn no np gt nr ns nt nu aw nv bi"><span id="f3f1" class="nw kp iq ns b gy nx ny l nz oa"># without EAT prediction<br/>PREFIX dbr: &lt;<a class="ae mh" href="http://dbpedia.org/resource/" rel="noopener ugc nofollow" target="_blank">http://dbpedia.org/resource/</a>&gt;<br/>SELECT (COUNT(DISTINCT ?obj) as ?count)<br/>WHERE {<br/>  dbr:Angela_Merkel ?p ?obj .<br/>}<br/># ?count = 861</span></pre><p id="9985" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">如代码片段所示，这个SPARQL查询根据DBpedia中的安格拉·默克尔资源计算可能的候选答案。结果是巨大的——861。让我们试着用预测的EAT缩小搜索空间。</p><pre class="nm nn no np gt nr ns nt nu aw nv bi"><span id="e699" class="nw kp iq ns b gy nx ny l nz oa"># with EAT prediction<br/>PREFIX dbr: &lt;<a class="ae mh" href="http://dbpedia.org/resource/" rel="noopener ugc nofollow" target="_blank">http://dbpedia.org/resource/</a>&gt;<br/>PREFIX rdf: &lt;<a class="ae mh" href="http://www.w3.org/1999/02/22-rdf-syntax-ns#" rel="noopener ugc nofollow" target="_blank">http://www.w3.org/1999/02/22-rdf-syntax-ns#</a>&gt;<br/>SELECT (COUNT(DISTINCT ?obj) as ?count)<br/>WHERE {<br/>  dbr:Angela_Merkel ?p ?obj .<br/>  ?obj rdf:type ?type .<br/>  FILTER(?type = dbo:City)<br/>}<br/># ?count = 6</span></pre><p id="e6ce" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">现在，由于我们使用类型“城市”限制了候选答案集，因此只有6个可能的候选答案。这确实令人印象深刻，因为从6个候选人中找出正确答案比从861个候选人中找出正确答案要容易得多。在下一节中，将介绍特定的EAT分类器架构。</p><h1 id="df72" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">预期答案类型分类器的体系结构</h1><p id="9f28" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><em class="nk">层次分类有三种方法</em>【3】:扁平化、局部化、全局化。扁平方法忽略了层次结构，甚至可以说是扁平的，在这种情况下，我们处理的是多标签分类。局部方法为层次结构的每个级别(节点)使用几个分类器，而全局方法在一次调用中预测整个层次结构。</p><p id="2621" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated"><em class="nk">在本文中，我们使用局部方法</em>(见架构图)对EAT进行分层分类。该解决方案基于多语言BERT模型[4]，其中一个由<em class="nk"> n </em>个神经元组成的全连接层被附加到【CLS】令牌输出中，其中<em class="nk"> n </em>是在特定层次级别(节点)预测的类的数量。</p><figure class="nm nn no np gt mz gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/880787fa9dc032edd72f40c04755b21d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*ClVEd2XdLiZ7HNbMu5HkZA.jpeg"/></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">分层EAT分类器的架构(图片由作者提供)</p></figure><p id="3d2d" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">该图示出了3种模型——类别分类器、文字分类器和资源分类器。总共有三个类别:布尔、文字和资源。还有三种文字:数字、数据和字符串。对于资源，事情要复杂得多，因为有一个完整的层次分类(参见简介中的例子)。在我们的解决方案中，资源分类器预测最具体的响应类型(例如<a class="ae mh" href="https://dbpedia.org/ontology/city" rel="noopener ugc nofollow" target="_blank"> dbo:City </a>)，然后我们简单地使用SPARQL query从DBpedia获取层次结构的其余部分到顶层，如下所示。</p><figure class="nm nn no np gt mz"><div class="bz fp l di"><div class="oc od l"/></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">给定最具体的本体类型，获取DBpedia本体层次结构的源代码</p></figure><p id="7514" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">下面的代码用于创建基于BERT的EAT分类器。完整的源代码可以在我们的<a class="ae mh" href="https://github.com/Perevalov/iswc-classification" rel="noopener ugc nofollow" target="_blank"> Github资源库</a>中找到。</p><figure class="nm nn no np gt mz"><div class="bz fp l di"><div class="oc od l"/></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">使用变压器库创建多类分类器的源代码</p></figure><p id="7226" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">分类器输出的例子如下所示。</p><pre class="nm nn no np gt nr ns nt nu aw nv bi"><span id="91b1" class="nw kp iq ns b gy nx ny l nz oa">[<br/> {<br/>   "id": "dbpedia_1",<br/>   "question": "Who are the gymnasts coached by Amanda Reddin?",<br/>   "category": "resource",<br/>   "type": ["dbo:Gymnast", "dbo:Athlete", "dbo:Person", "dbo:Agent"]<br/> },<br/> {<br/> "id": "dbpedia_2",<br/> "question": "How many superpowers does wonder woman have?",<br/> "category": "literal",<br/> "type": ["number"]<br/> }<br/> {<br/>   "id": "dbpedia_3",<br/>   "question": "When did Margaret Mead marry Gregory Bateson?",<br/>   "category": "literal",<br/>   "type": ["date"]<br/> },<br/> {<br/>   "id": "dbpedia_4",<br/>   "question": "Is Azerbaijan a member of European Go Federation?",<br/>   "category": "boolean",<br/>   "type": ["boolean"]<br/> }<br/>]</span></pre><p id="9902" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">类别分类器的质量由准确度度量来测量，而其他分类器使用NDCG 5和NDCG 10度量来评估，这些度量被设计来评估排名列表。运行评估脚本后，我们获得了以下结果:准确率:98%，NDCG@5: 76%，NDCG@10: 73%。这些结果也可以在语义答案类型预测任务2020的公共排行榜上找到:<a class="ae mh" href="https://smart-task.github.io/2020" rel="noopener ugc nofollow" target="_blank">https://smart-task.github.io/2020</a>。</p><h1 id="de19" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">结论</h1><p id="2a64" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">这篇短文介绍了一个用于分类预期答案类型的组件，它可以用于基于知识图的问答系统。<em class="nk">分类器支持多语言输入，在预测质量方面表现相当好</em>。重要链接如下:</p><ul class=""><li id="4b7d" class="oe of iq li b lj mc lm md lp og lt oh lx oi mb oj ok ol om bi translated">Out原文PDF:<a class="ae mh" href="http://ceur-ws.org/Vol-2980/paper349.pdf" rel="noopener ugc nofollow" target="_blank">http://ceur-ws.org/Vol-2980/paper349.pdf</a></li><li id="0d1f" class="oe of iq li b lj on lm oo lp op lt oq lx or mb oj ok ol om bi translated">GitHub:<a class="ae mh" href="https://github.com/Perevalov/iswc-classification" rel="noopener ugc nofollow" target="_blank">https://github.com/Perevalov/iswc-classification</a></li><li id="017e" class="oe of iq li b lj on lm oo lp op lt oq lx or mb oj ok ol om bi translated">web UI:<a class="ae mh" href="https://webengineering.ins.hs-anhalt.de:41009/eat-classification" rel="noopener ugc nofollow" target="_blank">https://web engineering . ins . hs-an halt . de:41009/eat-class ification</a></li><li id="2329" class="oe of iq li b lj on lm oo lp op lt oq lx or mb oj ok ol om bi translated">API:【https://webengineering.ins.hs-anhalt.de:41020/docs T2】</li></ul><h1 id="1927" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">参考</h1><ol class=""><li id="c70e" class="oe of iq li b lj lk lm ln lp os lt ot lx ou mb ov ok ol om bi translated">郝，，等。“利用问题目标词特征通过语义关系扩展进行答案类型分类。”<em class="nk">基于知识的系统</em>133(2017):43–52。</li><li id="6259" class="oe of iq li b lj on lm oo lp op lt oq lx or mb ov ok ol om bi translated">朱拉夫斯基、丹尼尔和詹姆斯·马丁。"语音和语言处理(草案)."<em class="nk">可从:</em> <a class="ae mh" href="https://web.stanford.edu/~jurafsky/slp3/" rel="noopener ugc nofollow" target="_blank"> <em class="nk"> https://web。斯坦福。edu/~茹拉夫斯基/slp3 </em> </a> (2021)。</li><li id="cc2a" class="oe of iq li b lj on lm oo lp op lt oq lx or mb ov ok ol om bi translated">卡洛斯·新罗和亚历克斯·弗雷塔斯。"不同应用领域的层次分类综述."<em class="nk">数据挖掘和知识发现</em>22.1(2011):31–72。</li><li id="1d3b" class="oe of iq li b lj on lm oo lp op lt oq lx or mb ov ok ol om bi translated">伯特:用于语言理解的深度双向转换器的预训练。<em class="nk"> arXiv预印本arXiv:1810.04805 </em> (2018)。</li></ol><h1 id="8fce" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">感谢</h1><p id="f855" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我要感谢我的导师Andreas Both教授，他给了我写博士论文的机会。我还要感谢安哈特应用科技大学的支持。最后，我要感谢T21的Axel-Cyrille Ngonga Ngomo博士教授，他同意共同指导我的博士论文。</p></div></div>    
</body>
</html>