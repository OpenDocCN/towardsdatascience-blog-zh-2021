<html>
<head>
<title>Preventing Drowsy-Driving Accidents Using Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用卷积神经网络预防疲劳驾驶事故</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/drowsiness-detection-using-convolutional-neural-networks-face-recognition-and-tensorflow-56cdfc8315ad?source=collection_archive---------7-----------------------#2021-04-13">https://towardsdatascience.com/drowsiness-detection-using-convolutional-neural-networks-face-recognition-and-tensorflow-56cdfc8315ad?source=collection_archive---------7-----------------------#2021-04-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ece3" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用Keras、人脸识别、OpenCV和PIL进行全面演练</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/7fa692279b3ec80b8edd56364a85a302.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*9z8zDRxispxxtl36Jop7dg.gif"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="4a35" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">疲劳驾驶:一个严重的问题</h1><p id="8654" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">国家公路交通安全管理局估计，每年有91，000起涉及昏昏欲睡的司机的撞车事故，导致估计<strong class="lp ir"> 50，000人受伤，近800人死亡</strong>。此外，每24名成年司机中就有1人报告在过去的30天里开车时睡着了。研究甚至发现，超过20小时不睡觉相当于<strong class="lp ir">的血液酒精浓度为0.08%——美国法定上限</strong>。</p><p id="633f" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">由于这个严重的问题，我和一群其他数据科学家着手<strong class="lp ir">开发一个可以检测眼睛是否闭合的神经网络</strong>，当与计算机视觉结合使用时，<strong class="lp ir">检测一个活生生的人是否闭眼超过一秒钟</strong>。这种技术对任何对提高驾驶安全性感兴趣的人都很有用，包括商业司机、汽车公司和汽车保险公司。</p><p id="342c" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir">目录:</strong></p><p id="dfb1" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><a class="ae mo" href="https://medium.com/p/56cdfc8315ad/#2249" rel="noopener">构建卷积神经网络</a></p><p id="62cd" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><a class="ae mo" href="https://medium.com/p/56cdfc8315ad/#30af" rel="noopener">网络摄像头应用</a></p><h1 id="7386" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated"><strong class="ak">数据收集</strong></h1><p id="e48a" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我们使用了许多来源的完整面部数据，即来自<a class="ae mo" href="http://vis-www.cs.umass.edu/lfw/" rel="noopener ugc nofollow" target="_blank">马萨诸塞大学</a>的睁眼面部数据和来自<a class="ae mo" href="http://parnec.nuaa.edu.cn/_upload/tpl/02/db/731/template731/pages/xtan/ClosedEyeDatabases.html" rel="noopener ugc nofollow" target="_blank">南大</a>的闭眼面部数据。</p><p id="9ae5" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">然后，我们使用一个简单的python函数从这个数据集中裁剪出眼睛，给我们留下了30，000多张裁剪后的眼睛图像。我们给每个图像添加了一个缓冲区，这样不仅可以得到眼睛，还可以得到眼睛周围的区域。这个裁剪功能将在稍后的网络摄像头部分重新使用。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="5dbc" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir">一个警告:</strong>手动擦洗这个数据集，除非你想要人们眨眼或者200张比尔·克林顿的照片来训练你的模型。以下是我们用来训练模型的数据示例:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/ea4187d12f443a360d4274c7eff5f40e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PsbEE_xCb0zyVY8bJdHJ6g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="2249" class="kv kw iq bd kx ky mz la lb lc na le lf jw nb jx lh jz nc ka lj kc nd kd ll lm bi translated"><strong class="ak">创建卷积神经网络</strong></h1><p id="719b" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><strong class="lp ir">决定一个指标</strong></p><p id="f05c" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">因为对我们来说，预测正面类别(一个睡着的司机)比预测负面类别(一个醒着的司机)更重要，所以我们最重要的衡量标准将是回忆(灵敏度)。召回率越高，模型错误预测的睡着的司机醒着的数量就越少(假阴性)。</p><p id="c64e" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">这里唯一的问题是，我们的积极阶层在数量上远远超过了我们的消极阶层。正因为如此，最好使用<strong class="lp ir"> F1得分或精确回忆AUC得分</strong>，因为它们也考虑了我们猜测司机睡着但实际上醒着的次数(精确)。否则，我们的模型将总是预测我们睡着了，无法使用。另一个我们没有用来处理不平衡图像数据的方法是使用<a class="ae mo" href="https://machinelearningmastery.com/image-augmentation-deep-learning-keras/" rel="noopener ugc nofollow" target="_blank">图像增强</a>。我在这里没有利用这一点，但是Jason Brownlee做了很好的工作来解释你如何能在这里<a class="ae mo" href="https://machinelearningmastery.com/image-augmentation-deep-learning-keras/" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="ffac" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir">准备图像数据</strong></p><p id="8f51" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">下一步是导入图像并为模型进行预处理。</p><p id="0dfb" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">此部分所需的导入:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="b16c" class="nj kw iq nf b gy nk nl l nm nn"><strong class="nf ir">import cv2<br/>import</strong> <strong class="nf ir">tensorflow</strong> <strong class="nf ir">as</strong> <strong class="nf ir">tf</strong><br/><strong class="nf ir">from</strong> <strong class="nf ir">tensorflow</strong> <strong class="nf ir">import</strong> keras<br/><strong class="nf ir">from</strong> <strong class="nf ir">sklearn.model_selection</strong> <strong class="nf ir">import</strong> train_test_split<br/><strong class="nf ir">from</strong> <strong class="nf ir">tensorflow.keras.wrappers.scikit_learn</strong> <strong class="nf ir">import</strong> KerasClassifier<br/><strong class="nf ir">from</strong> <strong class="nf ir">keras.models</strong> <strong class="nf ir">import</strong> Sequential<br/><strong class="nf ir">from</strong> <strong class="nf ir">keras.layers</strong> <strong class="nf ir">import</strong> Dense,Flatten,Conv2D,MaxPooling2D,Dropout</span></pre><p id="c89a" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">导入我们之前创建的图像，调整图像大小，使它们完全匹配。对于这个项目，我们调整到80x80像素。这是一个使用操作系统库的简单导入函数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="2b80" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">设置变量，自变量X为图像，因变量y为相应的标签(1表示闭眼，0表示睁眼):</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="0a62" class="nj kw iq nf b gy nk nl l nm nn">X = [] <br/>y = [] <br/><strong class="nf ir">for</strong> features, label <strong class="nf ir">in</strong> eyes: <br/>     X.append(features)<br/>     y.append(label)</span></pre><p id="b379" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">将图像转换为数组，以便它可以进入模型。此外，通过除以255来缩放数据。</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="901e" class="nj kw iq nf b gy nk nl l nm nn">X = np.array(X).reshape(-1, 80, 80, 3)<br/>y = np.array(y)<br/>X = X/255.0</span></pre><p id="f1c1" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">使用scikit learn的<code class="fe no np nq nf b">train_test_split</code>将数据分为训练集和验证集。<strong class="lp ir">重要:</strong>使<strong class="lp ir"> </strong>确定对y进行分层，因为我们有不平衡的类。</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="8397" class="nj kw iq nf b gy nk nl l nm nn">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)</span></pre></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="dc46" class="kv kw iq bd kx ky mz la lb lc na le lf jw nb jx lh jz nc ka lj kc nd kd ll lm bi translated">创建模型架构</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/94bae332497724deaf137cee797a6a9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*moqDUbHEkoXJdSmBzkgdkQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="1d36" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir">卷积层:</strong></p><p id="786a" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">这一层创建像素的子集而不是完整的图像，并允许更快的模型。根据您设置的过滤器数量，这可能比原始图像更密集或更不密集，但它们将使模型能够使用更少的资源来学习更复杂的关系。我用了32个滤镜。至少使用一个卷积层，通常需要两个或更多。对我来说，最佳设置是<strong class="lp ir">两个<em class="ns"> 3x3的</em>放在一起，然后是三个<em class="ns"> 3x3的</em>放在一起</strong>。CNN的总体趋势是使用更小的过滤器。事实上，<strong class="lp ir">双<em class="ns"> 3x3 </em>层与<em class="ns"> 5x5 </em>层</strong>本质上是一样的，但是<strong class="lp ir">更快并且常常会得到更好的分数，正如Arnault Chazareix 在这篇精彩的<a class="ae mo" href="https://www.sicara.ai/blog/en/2019-10-31-convolutional-layer-convolution-kernel" rel="noopener ugc nofollow" target="_blank">文章中所解释的那样。之后汇集并不总是必要的或更好的。如果可能的话，试试你的模型。</a></strong></p><p id="658e" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir">展平</strong></p><p id="f07a" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">确保展平图像阵列，以便它可以进入密集层。</p><p id="9663" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir">密集层</strong></p><p id="6c42" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">层数越多，模型的训练时间就越长。随着这些层中神经元数量的增加，网络所学习的关系的<strong class="lp ir">复杂性将增加</strong>。一般来说，卷积层的想法是<strong class="lp ir">避免不得不制定过深的密集层方案</strong>。在我们的模型中，我们使用了三层神经元(256，128，64)以递减的速率激活。我们还在每一层之后使用了30% <strong class="lp ir">的压差</strong>。</p><p id="3b13" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir">输出层</strong></p><p id="44b1" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">最后，因为这是一个二进制分类问题，请确保为外层使用sigmoid激活。</p><p id="2e2e" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir">编译模型</strong></p><p id="826f" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">在<code class="fe no np nq nf b">model.compile()</code>中，您将需要将指标设置为PR AUC(tensor flow中的<code class="fe no np nq nf b">tf.keras.metrics.AUC (curve = 'PR')</code>)或recall(tensor flow中的<code class="fe no np nq nf b">tf.keras.metrics.recall</code>)。设置损失等于<code class="fe no np nq nf b">binary_crossentropy</code>，因为这是一个二元分类模型，一个好的优化器通常是<code class="fe no np nq nf b">adam</code>。</p><p id="e47a" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir">拟合模型</strong></p><p id="2343" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">将您的<strong class="lp ir">批量</strong>设置得尽可能高，但不要在此过程中炸掉您的机器！我在Google Colab的32 GB TPU上运行了一个gridsearch，它轻松地运行了1000多个批次。当有疑问时，尝试32批，如果不超负荷你的记忆，增加。就<strong class="lp ir">时代</strong>而言，20个时代后收益递减，所以我不会比CNN的收益高太多。</p><p id="0777" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">以下是Tensorflow Keras的完整设置:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="6903" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir">最终精确-召回曲线下面积分数:</strong></p><p id="f0e0" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">0.981033 </p><p id="e953" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">让我知道你是否能做得更好！</p></div><div class="ab cl ms mt hu mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="ij ik il im in"><h1 id="30af" class="kv kw iq bd kx ky mz la lb lc na le lf jw nb jx lh jz nc ka lj kc nd kd ll lm bi translated"><strong class="ak">创建网络摄像头应用</strong></h1><p id="1120" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">一旦你有了满意的模型，使用<code class="fe no np nq nf b">model.save('yourmodelname.h5')</code>保存它。确保在保存时运行没有验证数据的生产模型<strong class="lp ir">。这将导致在导入时出现问题。</strong></p><p id="ef8f" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir">安装和进口:</strong></p><p id="80c5" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">这些都是Mac优化的，虽然也可以在Windows上使用相同的脚本。查看此链接<a class="ae mo" href="https://stackoverflow.com/questions/41912372/dlib-installation-on-windows-10" rel="noopener ugc nofollow" target="_blank">此处</a>用于诊断windows dlib。</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="3dff" class="nj kw iq nf b gy nk nl l nm nn"># installations needed for webcam application<br/># pip install opencv-python # <br/># if you want to play a sound for the alert:<br/># pip install -U PyObjC<br/># pip install playsound</span><span id="4bc2" class="nj kw iq nf b gy nt nl l nm nn"># imports for webcam application<br/>import cv2<br/>from playsound import playsound<br/># import model saved above<br/>eye_model = keras.models.load_model(‘best_model.h5’)</span></pre><p id="645a" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir">使用OpenCV访问网络摄像头</strong></p><p id="667e" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">使用<code class="fe no np nq nf b">cv2.VideoCapture(0)</code>开始网络摄像头捕捉。如果你想基于相对帧尺寸而不是绝对坐标来确定文本位置，请确保使用<code class="fe no np nq nf b">cap.get(cv2.CAP_PROP_FRAME_WIDTH)</code>保存网络摄像头的宽度和高度。您还可以查看每秒帧数。OpenCV捕获属性的完整列表可以在<a class="ae mo" href="https://docs.opencv.org/3.4/d4/d15/group__videoio__flags__base.html#gaeb8dd9c89c10a5c63c139bf7c4f5704d" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="6680" class="nj kw iq nf b gy nk nl l nm nn">cap = cv2.VideoCapture(0)<br/>w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)<br/>h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)<br/>print(cap.get(cv2.CAP_PROP_FPS))</span><span id="d1ef" class="nj kw iq nf b gy nt nl l nm nn">if not cap.isOpened():<br/> raise IOError(‘Cannot open webcam’)</span></pre><p id="f42c" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir">用OpenCV捕捉帧并裁剪它们</strong></p><p id="5ec5" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">如果你打算按帧计算闭上的眼睛，一定要设置一个计数器。一个<code class="fe no np nq nf b">while True:</code>循环会让摄像机一直开着，直到你完成剧本。在while循环中，使用<code class="fe no np nq nf b">ret, frame = cap.read()</code>格式捕获网络摄像机视频帧。最后，调用框架上的函数。它应该从帧中返回一个裁剪过的眼睛，如果它在帧中找不到眼睛，该函数将返回不能被255整除的<code class="fe no np nq nf b">None</code>，并将跳到下一帧。</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="3b91" class="nj kw iq nf b gy nk nl l nm nn">counter = 0</span><span id="1ba4" class="nj kw iq nf b gy nt nl l nm nn"># create a while loop that runs while webcam is in use<br/>while True:</span><span id="5a64" class="nj kw iq nf b gy nt nl l nm nn">  # capture frames being outputted by webcam</span><span id="f538" class="nj kw iq nf b gy nt nl l nm nn">  ret, frame = cap.read()</span><span id="dfb4" class="nj kw iq nf b gy nt nl l nm nn">  # function called on the frame<br/>  image_for_prediction = eye_cropper(frame)<br/>  try:<br/>     image_for_prediction = image_for_prediction/255.0<br/>  except:<br/>     continue</span></pre><p id="5119" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir">通过模型运行框架</strong></p><p id="811c" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">然后我们可以通过模型运行图像，并得到一个预测。如果预测更接近0，那么我们在屏幕上显示“打开”。否则(即更接近1)，我们显示“关闭”。注意，如果模型检测到睁开的眼睛，计数器重置为0，如果眼睛闭上，计数器增加1。我们可以使用<code class="fe no np nq nf b">cv2.putText()</code>显示一些基本文本来指示眼睛是闭着还是睁着。</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="18e2" class="nj kw iq nf b gy nk nl l nm nn">prediction = eye_model.predict(image_for_prediction)</span><span id="fe20" class="nj kw iq nf b gy nt nl l nm nn">if prediction &lt; 0.5:<br/>  counter = 0<br/>  status = ‘Open’</span><span id="6453" class="nj kw iq nf b gy nt nl l nm nn">  cv2.putText(frame, status, (round(w/2)-80,70),<br/>cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255,0), 2, cv2.LINE_4)<br/>  </span><span id="1642" class="nj kw iq nf b gy nt nl l nm nn">else:<br/>  counter = counter + 1<br/>  status = ‘Closed’</span><span id="556d" class="nj kw iq nf b gy nt nl l nm nn">  cv2.putText(frame, status, (round(w/2)-104,70), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,255), 2, cv2.LINE_4)</span></pre><p id="7b52" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">我们还希望<strong class="lp ir">显示一个警告，如果连续有6帧闭着眼睛</strong>(“睡觉”)。这可以使用一个简单的if语句来完成:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="ea2b" class="nj kw iq nf b gy nk nl l nm nn">if counter &gt; 5:<br/>  cv2.putText(frame, ‘DRIVER SLEEPING’, (round(w/2)-136,round(h) — 146), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2, cv2.LINE_4)<br/>  counter = 5</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/12e3516eb04dc27e08e89d45e69426f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MDd20KGAcpm571hFvKx1Lg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="7264" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">最后，我们需要显示框架，并为while循环提供一个退出键。<code class="fe no np nq nf b">cv2.waitKey(1)</code>决定画面将显示多长时间。括号中的数字是该帧将显示的毫秒数，除非按下“k”键，在本例中为27，或者按下escape键:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="ea58" class="nj kw iq nf b gy nk nl l nm nn">cv2.imshow(‘Drowsiness Detection’, frame)<br/>k = cv2.waitKey(1)<br/>if k == 27:<br/>  break</span></pre><p id="c704" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">在循环之外，释放网络摄像头并关闭应用程序:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="aa18" class="nj kw iq nf b gy nk nl l nm nn">cap.release()<br/>cv2.destroyAllWindows()</span></pre><h1 id="9f2a" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated"><strong class="ak">最终产品</strong></h1><p id="9e99" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">加上一些风格上的补充，这就是最终产品。你也可以包括声音，我已经在下面的完整脚本中包括了。我用的是a Down的《杂碎》(如果你知道，你就知道)的System中的《醒来》歌词。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/7fa692279b3ec80b8edd56364a85a302.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*9z8zDRxispxxtl36Jop7dg.gif"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="106f" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">如您所见，该模型非常有效，尽管训练时间很长，但在几毫秒内就能返回预测结果。随着一些进一步的改进和输出到外部机器，这个程序可以很容易地应用于实际情况，也许可以挽救生命。</p><p id="0df5" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">感谢阅读。如果您有任何问题或改进，请随时通过<a class="ae mo" href="https://www.linkedin.com/in/stewart-dustin/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系我。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure></div></div>    
</body>
</html>