<html>
<head>
<title>Build a Transformer in JAX from scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从零开始在JAX建造一个变压器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/build-a-transformer-in-jax-from-scratch-how-to-write-and-train-your-own-models-9aa02b5b28fd?source=collection_archive---------16-----------------------#2021-03-19">https://towardsdatascience.com/build-a-transformer-in-jax-from-scratch-how-to-write-and-train-your-own-models-9aa02b5b28fd?source=collection_archive---------16-----------------------#2021-03-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bdef" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何编写和训练自己的模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/829835c8f2c7d6704974d8768d91234d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PS6z2GYsrSQ7rk-Z9hrWgQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="b47e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本教程中，我们将探讨如何开发一个神经网络(神经网络)与JAX。还有什么比<a class="ae lu" href="https://theaisummer.com/transformer/" rel="noopener ugc nofollow" target="_blank">变压器</a>更好的型号可以选择。随着JAX越来越受欢迎，越来越多的开发团队开始尝试使用它，并将其整合到他们的项目中。尽管它缺乏Tensorflow或Pytorch的成熟度，但它为构建和训练深度学习模型提供了一些很好的功能。</p><p id="e186" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你还没有对JAX的基础知识有一个坚实的理解，看看我以前的文章。你也可以在我们的<a class="ae lu" href="https://github.com/The-AI-Summer/JAX-examples" rel="noopener ugc nofollow" target="_blank"> Github库</a>中找到完整的代码。</p><p id="009b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">俳句和Flax似乎是Google/Deepmind内部最多的框架，拥有最活跃的Github社区。对于本文，我将从第一个开始，看看以后是否还需要另一个。</p><p id="e300" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以你准备好用JAX和俳句做一个变形金刚了吗？对了，我假设你对变形金刚有扎实的了解。如果你还没有，请指点我们关于<a class="ae lu" href="https://theaisummer.com/attention/" rel="noopener ugc nofollow" target="_blank">注意</a>和<a class="ae lu" href="https://theaisummer.com/transformer/" rel="noopener ugc nofollow" target="_blank">变形金刚</a>的文章。</p><p id="475d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们从自我关注块开始。</p><h1 id="449f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">自我关注障碍</h1><p id="4560" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">首先，我们需要引进JAX和俳句</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="8342" class="mx lw it mt b gy my mz l na nb"><em class="nc">import</em> jax<br/><em class="nc">import</em> jax.numpy <em class="nc">as</em> jnp<br/><em class="nc">import</em> haiku <em class="nc">as</em> hk<br/>import numpy <em class="nc">as</em> np</span></pre><p id="3e6e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">幸运的是，俳句有一个内置的<code class="fe nd ne nf mt b">MultiHeadAttention</code>模块，可以扩展来构建一个屏蔽的自我关注模块。我们的块接受查询、键、值以及掩码，并将输出作为JAX数组返回。可以看到代码非常熟悉标准Pytorch或者Tensorflow代码。我们所要做的就是构建因果掩码，使用<code class="fe nd ne nf mt b">np.trill()</code>使第k个以上数组的所有元素无效，乘以我们的掩码，并将所有内容传递给<code class="fe nd ne nf mt b">hk.MultiHeadAttention</code>模块</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="59a0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个片段允许我介绍俳句的第一个关键原则。所有模块都应该是<code class="fe nd ne nf mt b">hk.Module</code>的子类。这意味着他们应该实现<code class="fe nd ne nf mt b">__init__</code>和<code class="fe nd ne nf mt b">__call__</code>，以及其他方法。在某种意义上，这与Pytorch模块的架构相同，我们实现了一个<code class="fe nd ne nf mt b">__init__</code>和一个<code class="fe nd ne nf mt b">forward</code>。</p><p id="146b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了清楚起见，让我们构建一个简单的2层多层感知器作为<code class="fe nd ne nf mt b">hk.Module</code>，它将方便地用在下面的变压器中。</p><h1 id="ee38" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">线性层</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="4279" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一个简单的两层MLP看起来像这样。你可以再次注意到它看起来多么熟悉。</p><p id="9423" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里需要注意一些事情:</p><ul class=""><li id="dbde" class="ni nj it la b lb lc le lf lh nk ll nl lp nm lt nn no np nq bi translated">俳句为我们提供了一组<code class="fe nd ne nf mt b">hk.initializers</code>下的权重初始化器，在这里我们可以找到最<a class="ae lu" href="https://dm-haiku.readthedocs.io/en/latest/api.html#module-haiku.initializers" rel="noopener ugc nofollow" target="_blank">常见的方法</a>。</li><li id="8991" class="ni nj it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">它还内置了许多流行的层和模块，如<code class="fe nd ne nf mt b">hk.Linear</code>。如需完整列表，请查看官方文档<a class="ae lu" href="https://dm-haiku.readthedocs.io/en/latest/api.html#common-modules" rel="noopener ugc nofollow" target="_blank"/>。</li><li id="970b" class="ni nj it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">没有提供激活函数，因为JAX已经有一个名为<code class="fe nd ne nf mt b">jax.nn</code>的子包，在那里我们可以找到<a class="ae lu" href="https://jax.readthedocs.io/en/latest/jax.nn.html" rel="noopener ugc nofollow" target="_blank">激活函数</a>，比如<code class="fe nd ne nf mt b">relu</code>或者<code class="fe nd ne nf mt b">softmax</code>。</li></ul><h1 id="2652" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">标准化层</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="d94a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">层规范化是transformer架构的另一个组成部分，我们也可以在Haiku的公共模块中找到它。</p><h1 id="846f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">变形金刚</h1><p id="9b13" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">现在说说好东西。下面你可以找到一个非常简单的转换器，它利用了我们预先定义的模块。在<code class="fe nd ne nf mt b">__init__</code>中，我们定义了基本变量，如层数、注意力头和辍学率。在<code class="fe nd ne nf mt b">__call__</code>中，我们使用一个<code class="fe nd ne nf mt b">for</code>循环组成一个块列表。</p><p id="1113" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如您所见，每个模块包括:</p><ul class=""><li id="d094" class="ni nj it la b lb lc le lf lh nk ll nl lp nm lt nn no np nq bi translated">标准化层</li><li id="2b1c" class="ni nj it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">自我关注障碍</li><li id="78f4" class="ni nj it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">两个脱落层</li><li id="0d10" class="ni nj it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">两个标准化层</li><li id="226c" class="ni nj it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">两个跳跃连接(<code class="fe nd ne nf mt b">h = h + h_attn</code>和<code class="fe nd ne nf mt b">h = h + h_dense</code>)</li><li id="93ba" class="ni nj it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">两层致密块体</li></ul><p id="04cd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们还添加了一个最终的规范化层。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="5b35" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我想现在你已经意识到用JAX建立一个神经网络非常简单。</p><h1 id="894d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">嵌入层</h1><p id="5db5" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">最后，让我们也包括嵌入层。很高兴知道俳句还提供了一个嵌入层，它将从我们输入的句子中创建标记。令牌然后被添加到<a class="ae lu" href="https://theaisummer.com/positional-embeddings/" rel="noopener ugc nofollow" target="_blank">位置嵌入</a>，产生最终输入。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="7acc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nd ne nf mt b">hk.get_parameter(param_name, ...)</code>用于访问模块的可训练参数。但是你可能会问，为什么不像我们在Pytorch中那样使用对象属性呢？这就是俳句的第二个关键原则发挥作用的地方。<strong class="la iu">我们使用这个API，这样我们就可以使用</strong> <code class="fe nd ne nf mt b">hk.transform</code>将代码转换成一个纯函数。这不是很容易理解，但我会尽可能地把它说清楚。</p><h1 id="6d92" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">为什么是纯函数？</h1><p id="f7a9" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">JAX的力量体现在它的函数转换中:用T2向量化函数的能力，用T3自动并行化，用T4实时编译。这里需要注意的是，为了转换一个函数，它需要是纯的。</p><p id="c173" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">纯函数</strong>是具有以下特性的函数:</p><ul class=""><li id="a088" class="ni nj it la b lb lc le lf lh nk ll nl lp nm lt nn no np nq bi translated">对于相同的参数，函数返回值是相同的(没有局部静态变量、非局部变量、可变引用参数或输入流的变化)</li><li id="596e" class="ni nj it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">函数应用程序没有副作用(没有局部静态变量、非局部变量、可变引用参数或输入/输出流的变异)。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/b9cc5876937c556325edeb27ebca8a22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UzYckL2bQsIfbmeu.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="nx">来源:</em> <a class="ae lu" href="https://www.oreilly.com/library/view/scala-reactive-programming/9781787288645/d41d894b-d1a6-4ae3-acec-8c97720d80d0.xhtml" rel="noopener ugc nofollow" target="_blank"> <em class="nx"> Scala纯函数by O'Reily </em> </a></p></figure><p id="3dcd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这实际上意味着一个纯函数将总是:</p><ul class=""><li id="e34c" class="ni nj it la b lb lc le lf lh nk ll nl lp nm lt nn no np nq bi translated"><strong class="la iu">如果用相同的输入调用，返回相同的结果</strong></li><li id="68ab" class="ni nj it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated"><strong class="la iu">所有的输入数据都通过函数参数传递，所有的结果都通过函数结果</strong>输出</li></ul><p id="4e8e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Haiku提供了一个名为<code class="fe nd ne nf mt b">hk.transform</code>的函数转换，它将具有面向对象的、功能上“不纯”的模块的函数转换成可以与JAX一起使用的纯函数。为了在实践中看到这一点，让我们继续训练我们的Transformer模型。</p><h1 id="ba9e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">向前传球</h1><p id="cfa6" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">典型的向前传球包括:</p><ol class=""><li id="5452" class="ni nj it la b lb lc le lf lh nk ll nl lp nm lt ny no np nq bi translated">获取输入并计算输入嵌入</li><li id="e3bf" class="ni nj it la b lb nr le ns lh nt ll nu lp nv lt ny no np nq bi translated">运行通过变压器的块</li><li id="6d9d" class="ni nj it la b lb nr le ns lh nt ll nu lp nv lt ny no np nq bi translated">返回输出</li></ol><p id="f89a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上述步骤可以很容易地用JAX组成如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="e10e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">虽然代码很简单，但它的结构可能看起来有点奇怪。实际的正向传递通过<code class="fe nd ne nf mt b">forward_fn</code>功能执行。然而，我们用返回<code class="fe nd ne nf mt b">forward_fn</code>的<code class="fe nd ne nf mt b">build_forward_fn</code>函数包装它。什么鬼东西？</p><p id="68eb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">接下来，我们需要使用<code class="fe nd ne nf mt b">hk.transform</code>将<code class="fe nd ne nf mt b">forward_fn</code>函数转换成一个纯函数，这样我们就可以利用自动微分、并行化等功能。</p><p id="e274" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这将通过以下方式实现:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="bf58" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就是为什么我们不是简单地定义一个函数，而是包装并返回函数本身，或者更准确地说是一个<a class="ae lu" href="https://www.geeksforgeeks.org/callable-in-python/" rel="noopener ugc nofollow" target="_blank">可调用的</a>。然后，这个可调用函数可以被传递到<code class="fe nd ne nf mt b">hk.transform</code>中，成为一个纯函数。如果这是清楚的，让我们继续我们的损失函数。</p><h1 id="282d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">损失函数</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="4375" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">损失函数是我们熟知的交叉熵函数，不同之处在于我们还考虑了掩模。JAX再次提供了<code class="fe nd ne nf mt b">one_hot</code>和<code class="fe nd ne nf mt b">log_softmax</code>功能。</p><p id="04c4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你还和我在一起，喝一口咖啡，因为从现在开始事情会变得严重。是时候建立我们的训练循环了。</p><h1 id="195c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">训练循环</h1><p id="c2c9" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">因为Jax和Haiku都没有内置的优化功能，我们将使用另一个框架，名为<a class="ae lu" href="https://github.com/deepmind/optax" rel="noopener ugc nofollow" target="_blank"> Optax </a>。如开头所述，Optax是渐变处理的goto包。</p><p id="141b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，您需要了解一些关于Optax的事情:</p><p id="6a95" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Optax的关键改造是<code class="fe nd ne nf mt b">GradientTransformation</code>。转换由两个函数定义，即<code class="fe nd ne nf mt b">__init__</code>和<code class="fe nd ne nf mt b">__update__</code>。<code class="fe nd ne nf mt b">__init__</code>初始化状态，<code class="fe nd ne nf mt b">__update__</code>根据状态和参数的当前值转换梯度</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="9b7e" class="mx lw it mt b gy my mz l na nb">state = init(params)<br/>grads, state = update(grads, state, params=None)</span></pre><p id="7d5a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了减少我们的<code class="fe nd ne nf mt b">main</code>函数，我们将把渐变更新提取到它自己的类中。</p><p id="1eea" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，<code class="fe nd ne nf mt b">GradientUpdater</code>接受模型、损失函数和优化器。</p><ol class=""><li id="3598" class="ni nj it la b lb lc le lf lh nk ll nl lp nm lt ny no np nq bi translated">该模型将是由<code class="fe nd ne nf mt b">hk.transform</code>转换的纯<code class="fe nd ne nf mt b">forward_fn</code>函数</li></ol><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="80d0" class="mx lw it mt b gy my mz l na nb">forward_fn = build_forward_fn(vocab_size, d_model, num_heads, num_layers, dropout_rate)</span><span id="0b79" class="mx lw it mt b gy nz mz l na nb">forward_fn = hk.transform(forward_fn)</span></pre><p id="7a25" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.损失函数将是具有固定<code class="fe nd ne nf mt b">forward_fn</code>和“vocab_size”的部分的结果</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="62f4" class="mx lw it mt b gy my mz l na nb">loss_fn = functools.partial(lm_loss_fn, forward_fn.apply, vocab_size)</span></pre><p id="2def" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">3.优化器是一组按顺序运行的优化转换(可以使用<code class="fe nd ne nf mt b">optax.chain</code>组合操作)</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="9b9d" class="mx lw it mt b gy my mz l na nb">optimizer = optax.chain(<br/>    optax.clip_by_global_norm(grad_clip_value),<br/>    optax.adam(learning_rate, b1=0.9, b2=0.99)<br/>)</span></pre><p id="cf24" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">梯度更新器将被初始化如下:</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="e4b7" class="mx lw it mt b gy my mz l na nb">updater = GradientUpdater(forward_fn.init, loss_fn, optimizer)</span></pre><p id="d9b5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">看起来会像这样:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="90d8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在<code class="fe nd ne nf mt b">__init__</code>中，我们用<code class="fe nd ne nf mt b">self._opt.init(params)</code>初始化优化器，并声明优化的状态。状态将是具有以下内容的字典:</p><ul class=""><li id="021f" class="ni nj it la b lb lc le lf lh nk ll nl lp nm lt nn no np nq bi translated">当前步骤</li><li id="466b" class="ni nj it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">优化程序状态</li><li id="e7f7" class="ni nj it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">可训练参数</li><li id="4adc" class="ni nj it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">(一个随机生成的密钥传入<code class="fe nd ne nf mt b">jax.random.split</code>)</li></ul><p id="694b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nd ne nf mt b">update</code>功能将更新优化器的状态以及可训练参数。最终，它将返回新的状态。</p><pre class="kj kk kl km gt ms mt mu mv aw mw bi"><span id="d8fc" class="mx lw it mt b gy my mz l na nb">updates, opt_state = self._opt.update(g, state['opt_state'])</span><span id="e3e7" class="mx lw it mt b gy nz mz l na nb">params = optax.apply_updates(params, updates)</span></pre><p id="3491" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里还有两件事需要注意:</p><ul class=""><li id="cf4a" class="ni nj it la b lb lc le lf lh nk ll nl lp nm lt nn no np nq bi translated"><code class="fe nd ne nf mt b">jax.value_and_grad()</code>是一个<a class="ae lu" href="https://jax.readthedocs.io/en/latest/jax.html#jax.value_and_grad" rel="noopener ugc nofollow" target="_blank">特殊函数</a>，它返回一个带梯度的可微函数。</li><li id="32e1" class="ni nj it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated"><code class="fe nd ne nf mt b">__init__</code>和<code class="fe nd ne nf mt b">__update__</code>都用<code class="fe nd ne nf mt b">functools.partial(jax.jit, static_argnums=0</code>标注，这将触发即时编译器，并在运行时将它们编译成XLA。注意，如果我们没有将<code class="fe nd ne nf mt b">forward_fn </code>转换成一个纯函数，这是不可能的。</li></ul><p id="81f1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们准备构建整个训练循环，它结合了迄今为止提到的所有思想和代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="9a59" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">注意我们是如何合并<code class="fe nd ne nf mt b">GradientUpdate</code>的。这只是两行代码:</p><ul class=""><li id="61ec" class="ni nj it la b lb lc le lf lh nk ll nl lp nm lt nn no np nq bi translated"><code class="fe nd ne nf mt b">state = updater.init(rng, data)</code></li><li id="f8c0" class="ni nj it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated"><code class="fe nd ne nf mt b">state, metrics = updater.update(state, data)</code></li></ul><p id="820a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">仅此而已。我希望你们现在对JAX及其能力有了更清楚的了解。</p><h1 id="8901" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">感谢</h1><p id="b310" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">所展示的代码在很大程度上受到了俳句框架的官方例子的启发。已经对其进行了修改，以适应本文的需要。有关完整的示例列表，请查看<a class="ae lu" href="https://github.com/deepmind/dm-haiku/tree/master/examples" rel="noopener ugc nofollow" target="_blank">官方知识库</a>。</p><h1 id="aa1b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="6595" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">在本文中，我们看到了如何使用俳句在JAX开发和训练一个普通的变压器。尽管代码并不难理解，但它仍然缺乏Pytorch或Tensorflow的可读性。我强烈建议尝试一下，发现JAX的优点和缺点，看看它是否适合你的下一个项目。根据我的经验，JAX非常适合需要高性能的研究应用，但对于现实项目来说还不够成熟。在我们的<a class="ae lu" href="https://discord.com/invite/k6NXwe7PXh" rel="noopener ugc nofollow" target="_blank">不和谐频道</a>让我们知道你的想法。别忘了访问我们的博客<a class="ae lu" href="https://theaisummer.com/" rel="noopener ugc nofollow" target="_blank">艾夏</a>获取类似文章。</p></div><div class="ab cl oa ob hx oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="im in io ip iq"><p id="74f1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="nc">原载于2021年3月19日</em><a class="ae lu" href="https://theaisummer.com/jax-transformer/" rel="noopener ugc nofollow" target="_blank"><em class="nc">【https://theaisummer.com】</em></a><em class="nc">。</em></p></div></div>    
</body>
</html>