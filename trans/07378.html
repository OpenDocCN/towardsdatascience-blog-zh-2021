<html>
<head>
<title>Why is Delta Lake becoming increasingly popular?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么三角洲湖越来越受欢迎？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-is-delta-lake-becoming-increasingly-popular-1e45c29cc7d2?source=collection_archive---------14-----------------------#2021-07-05">https://towardsdatascience.com/why-is-delta-lake-becoming-increasingly-popular-1e45c29cc7d2?source=collection_archive---------14-----------------------#2021-07-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="2716" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/notes-from-industry" rel="noopener" target="_blank">行业笔记</a></h2><div class=""/><div class=""><h2 id="8c50" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">讨论数据湖- <em class="kr">带来的益处超过传统挑战，ACID合规性、版本化拼花文件等。</em></h2></div><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ks"><img src="../Images/af2d36cd24730caf2f3e195ddb7096a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iRa-q6wEgZubpiGJ"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">📷由<a class="ae li" href="https://unsplash.com/@ikapics?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">加斯顿</a>在<a class="ae li" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="6f5b" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">对于初学者来说，理解三角洲湖和数据湖之间的区别可能会令人困惑。与以前的存储层一起工作了一年多，现在我分享了delta lake的特殊优势，以及它如何通过一些示例克服传统数据湖体系结构的挑战。</p><p id="3f45" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这些例子是为了使它更加直观和非技术性。我相信这将作为一个很好的策展，从不同的来源，三角洲湖可以带来什么。</p><p id="22d2" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">根据定义，delta lake不是一个独立的存储容器，而是一个运行在现有数据湖和对象存储之上的开源存储层。让我们把它看作是现有数据湖之上的附加功能，如下所示。</p><p id="07d2" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">它由一个delta引擎驱动，而delta引擎又由一个名为<strong class="ll jd"> Photon </strong>的本地执行引擎驱动。这是一个用C++从头开始编写的矢量化查询引擎。在撰写本文时，它正在公开预览中。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi mf"><img src="../Images/1f08341846b4dade187767671f77ee31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OsMXTUXa7TNC7SBTLemxuQ.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">三角洲湖建筑(图片由作者根据[ <a class="ae li" href="https://databricks.com/wp-content/uploads/2019/08/Delta-Lake-Multi-Hop-Architecture-Overview.png" rel="noopener ugc nofollow" target="_blank">原文</a> ]创作)</p></figure><h1 id="b80d" class="mg mh it bd mi mj mk ml mm mn mo mp mq ki mr kj ms kl mt km mu ko mv kp mw mx bi translated">数据湖——是什么让它充满挑战？</h1><p id="5eaa" class="pw-post-body-paragraph lj lk it ll b lm my kd lo lp mz kg lr ls na lu lv lw nb ly lz ma nc mc md me im bi translated">它是一个存储原始数据的容器。把它看作是一个尚待处理的纯原始数据的垃圾场。</p><p id="31eb" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">数据湖的一些重要特性包括——它的扁平架构，只有当你做读操作时，模式才被执行(读模式)。因此，它可以以低延迟轻松存储非结构化数据。</p><p id="1d1a" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">然而，原始数据给🧱带来了严峻挑战</p><h1 id="94d0" class="mg mh it bd mi mj mk ml mm mn mo mp mq ki mr kj ms kl mt km mu ko mv kp mw mx bi translated">挑战1:可靠性和质量——原子性</h1><p id="9fc5" class="pw-post-body-paragraph lj lk it ll b lm my kd lo lp mz kg lr ls na lu lv lw nb ly lz ma nc mc md me im bi translated">数据湖不能很好地处理损坏的数据。当我们在数据加载过程中发现故障时，将需要完全重新处理。</p><p id="103a" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">delta lake在这个场景中提供的解决方案是通过引入<strong class="ll jd">原子性。</strong>这意味着要么有一个完整的写/提交(或)没有写(又名<strong class="ll jd">原子可见性</strong>)。</p><p id="30cc" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在执行提交操作时，它是二进制的。因此，在作业完成之前，我们会知道数据中何时出现问题。</p><p id="5421" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">有一个单一的真理来源被用来服务于这个目的。它被称为<strong class="ll jd">事务日志(增量日志文件)，</strong>，它跟踪所有被写入增量表的原子事务。<strong class="ll jd"> </strong> Spark然后在每次交易后更新用户端的表格。</p><p id="2952" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">增量日志文件是JSON文件(<code class="fe nd ne nf ng b">00000000000000000000.json, 00000000000000000001.json</code>等)。)与临时的<em class="nh">检查点文件</em>一起放在<code class="fe nd ne nf ng b">_delta_log</code>子目录中。</p><p id="082c" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在增量日志文件中，还有<strong class="ll jd"> commitInfo、partitionValues和stats </strong>信息，它们是不同的元数据属性，用于跟踪数据更改，有助于提高查询效率。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ni"><img src="../Images/d10f0b69365a569a978ec94cd169d556.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wzt56DgA0o0CGrSj4PRiYg.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">三角洲湖中的原子性(图片由作者提供)</p></figure><p id="55fc" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">考虑以下简单的信用交易，一旦数据被写入，在服务启动并运行后，它应该用正确的值110更新(或者)保持为100，而交易日志不捕获提交信息。这就是原子提交的样子。</p><blockquote class="nj"><p id="66e5" class="nk nl it bd nm nn no np nq nr ns me dk translated"><strong class="ak"> <em class="kr">只有一个客户端可以通过一次原子提交来实现对象的创建。</em>T13】</strong></p></blockquote><p id="a20c" class="pw-post-body-paragraph lj lk it ll b lm nt kd lo lp nu kg lr ls nv lu lv lw nw ly lz ma nx mc md me im bi translated">部分执行可能导致非原子提交，这在服务器故障(或)其他问题期间发生在数据湖中。</p><h1 id="e495" class="mg mh it bd mi mj mk ml mm mn mo mp mq ki mr kj ms kl mt km mu ko mv kp mw mx bi translated">挑战#2:缺少数据一致性</h1><p id="3a1c" class="pw-post-body-paragraph lj lk it ll b lm my kd lo lp mz kg lr ls na lu lv lw nb ly lz ma nc mc md me im bi translated">当涉及到丢失数据时，有两种情况会产生问题:</p><ul class=""><li id="0d4b" class="ny nz it ll b lm ln lp lq ls oa lw ob ma oc me od oe of og bi translated">批处理和流处理数据需要使用lambda架构风格，将数据写入两个不同的容器。在数据湖中，这两种工作负载类型的统一是不可能的。</li><li id="e8ac" class="ny nz it ll b lm oh lp oi ls oj lw ok ma ol me od oe of og bi translated">在<strong class="ll jd">覆盖</strong>操作期间(<em class="nh">基本上是删除和写入</em>)，有一个时间点表中没有数据，如果在此瞬间发生任何故障，我们在查询时将看不到任何数据。</li></ul><p id="4249" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在Delta lake中，这种数据不一致性是使用称为<strong class="ll jd">乐观并发控制</strong>的概念来处理的，通过这个概念，由多个用户同时(或)由不同类型(<em class="nh">批处理/流</em>)写入的数据是以<strong class="ll jd">序列化</strong>的方式完成的。我们可以将源用作批处理表，将流表用作接收器。</p><p id="3c94" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在一些特殊的场景中，并发操作无法乐观地执行，在此期间，增量引擎会抛出一个错误。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi om"><img src="../Images/34368b3e41e45bcd038eac5fe0a428b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w5Ub1-NJpJ7AIbbLivzA7A.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">三角洲湖的一致性(图片由作者提供)</p></figure><p id="a2c3" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">当出现连接丢失(或)某种形式的失败(或)多次写入时，要提交的数据不应丢失，而是在事务日志中捕获，并以序列化方式执行提交。</p><h1 id="19b0" class="mg mh it bd mi mj mk ml mm mn mo mp mq ki mr kj ms kl mt km mu ko mv kp mw mx bi translated">挑战#3:并发操作-隔离</h1><p id="0fec" class="pw-post-body-paragraph lj lk it ll b lm my kd lo lp mz kg lr ls na lu lv lw nb ly lz ma nc mc md me im bi translated">如一致性一节所述，并行发生的操作需要串行隔离，以避免冲突。这允许数据模型(<em class="nh">批处理和流</em>)的统一，这在数据湖的情况下是不可能的。</p><p id="ede9" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这就是<strong class="ll jd">隔离</strong>机制应对挑战的方式:尚未完成的提交被<strong class="ll jd">互斥</strong>规则隔离。只有当提交成功时，它才允许对delta lake进行写/合并/删除操作。</p><p id="d550" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这还带来了对delta lake数据使用标准(删除、更新、合并)命令的功能，这有助于使您的数据符合CCPA/GDPR法案。</p><p id="d2c2" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">有一些特殊的场景，其中两个操作会导致增量表中的冲突，这里的<a class="ae li" href="https://docs.delta.io/latest/concurrency-control.html#avoid-conflicts-using-partitioning-and-disjoint-command-conditions" rel="noopener ugc nofollow" target="_blank"><em class="nh"/></a>捕获这些冲突以供进一步参考。简而言之，通过对filter命令中使用的列进行分区，可以避免这些冲突。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi on"><img src="../Images/b3a2f8199741b03761df45e63c671efb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mmC82gEUJFIn2OUNw_jLng.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">三角洲湖中的隔离(图片由作者提供)</p></figure><p id="d07f" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这里，事务<strong class="ll jd"> T1 </strong>和<strong class="ll jd"> T2 </strong>被隔离，并使用事务日志信息顺序执行。因此，在任何给定的时刻，它们都不会与数据相矛盾。</p><h1 id="e3d4" class="mg mh it bd mi mj mk ml mm mn mo mp mq ki mr kj ms kl mt km mu ko mv kp mw mx bi translated">挑战#4:消失的数据-持久性</h1><p id="9d44" class="pw-post-body-paragraph lj lk it ll b lm my kd lo lp mz kg lr ls na lu lv lw nb ly lz ma nc mc md me im bi translated">考虑在操作过程中出现故障和服务器端的情况。这又会导致数据丢失(或)大量损坏的记录。这在典型的数据湖中是无法避免的。</p><p id="fd21" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">然而，由于<strong class="ll jd">事务日志</strong>和<strong class="ll jd">磁盘存储持久性</strong>，即使在系统(或)服务器端出现故障时，数据也将持续存在。因此，非易失性存储器在三角洲湖中起着至关重要的作用。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi oo"><img src="../Images/abf1319b673f2a11a34b97453652375e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ud7duvb3HNOKBCTo9985nA.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">三角洲湖的耐久性(图片由作者提供)</p></figure><p id="f8b7" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这里，当服务器停机时，更新操作可能失败和/或读取可能失败。因为事务存储在磁盘上，所以可以从增量表中读取最新值，直到最后一次提交。</p><h1 id="4bc7" class="mg mh it bd mi mj mk ml mm mn mo mp mq ki mr kj ms kl mt km mu ko mv kp mw mx bi translated">挑战#5:真实性-模式检查</h1><p id="8b17" class="pw-post-body-paragraph lj lk it ll b lm my kd lo lp mz kg lr ls na lu lv lw nb ly lz ma nc mc md me im bi translated">就真实性而言，当我们试图改变写入数据湖的数据类型时，会导致损坏和丢失记录。因此，需要对模式的有效性进行检查。</p><p id="0758" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在delta lake中，在任何提交之前都会执行<strong class="ll jd">模式验证</strong>。默认情况下，不同的模式无法执行覆盖。这样，写入数据的模式格式应该总是与最初定义的模式相匹配(也称为<em class="nh">写模式</em>)。</p><p id="32ce" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">如果需要重写，<strong class="ll jd">模式进化</strong>可以拯救。这可以通过在执行写操作时设置配置选项来实现。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi op"><img src="../Images/beab189fa1bc66412e9cf1bfd5b36338.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qNMtR_LNaT-jGHh6NkO4iQ.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">三角洲湖的模式实施(图片由作者提供)</p></figure><p id="b24c" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这里，对于简单的插入操作:当<code class="fe nd ne nf ng b">mergeSchema</code>被设置为<code class="fe nd ne nf ng b">true</code>时，有一个从Float类型到Long类型的类型转换。还有一个名为<code class="fe nd ne nf ng b">overwriteSchema</code>的选项，将其设置为<code class="fe nd ne nf ng b">true</code>将完全忽略旧数据，并在其位置创建一个新表。</p><h1 id="da3b" class="mg mh it bd mi mj mk ml mm mn mo mp mq ki mr kj ms kl mt km mu ko mv kp mw mx bi translated">挑战#6:数据时间旅行的版本化</h1><p id="8d79" class="pw-post-body-paragraph lj lk it ll b lm my kd lo lp mz kg lr ls na lu lv lw nb ly lz ma nc mc md me im bi translated">现代大数据系统在进行频繁的大容量数据更改方面是一致的。需要有一个审计系统(或)回滚机制来监控正在发生的变化。数据湖中没有这种支持。</p><p id="1b5f" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">但是，在增量表中，数据的当前状态是表内事务日志(<code class="fe nd ne nf ng b">_delta_log/</code>)子目录中记录的所有提交的总和。</p><p id="723b" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">它充当了从零开始构建数据到其当前形式的方法。这种通过遍历事务日志来创建数据的能力称为<strong class="ll jd">时间旅行</strong>(或)<strong class="ll jd">数据版本控制。</strong></p><p id="7644" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">增量表中数据的先前版本可以通过时间戳(或)版本号来访问。增量表中的数据最终存储为<strong class="ll jd">版本化拼花文件</strong>。</p><p id="b3c7" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这允许用户执行更简单的回滚操作，返回到数据正确的时刻，并撤销错误的提交。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi oq"><img src="../Images/abddf3088c50f60a15e74db4a1ca3595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dgVZaytoaUS9W3bSzFF-jA.png"/></div></div><p class="le lf gj gh gi lg lh bd b be z dk translated">增量表中的时间旅行(图片由作者提供)</p></figure><p id="7874" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">每个表都有一个版本号(或)时间戳，可以从一个<code class="fe nd ne nf ng b">DESCRIBE HISTORY &lt;table_name&gt;</code>命令中获取。无论是使用子句<code class="fe nd ne nf ng b">VERSION AS OF</code> (or) <code class="fe nd ne nf ng b">TIMESTAMP AS OF</code>，我们都可以获得该时刻的表的快照。</p><h1 id="3484" class="mg mh it bd mi mj mk ml mm mn mo mp mq ki mr kj ms kl mt km mu ko mv kp mw mx bi translated">挑战#7:数据的数据-元数据管理</h1><p id="6713" class="pw-post-body-paragraph lj lk it ll b lm my kd lo lp mz kg lr ls na lu lv lw nb ly lz ma nc mc md me im bi translated">元数据是数据的数据。它由表的模式、列名、类型和事务信息组成。</p><p id="73f5" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">随着原子提交被记录在增量日志中，元数据被连续生成。这可用于跟踪由于所有来源而发生的所有变化。</p><p id="9365" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这种元数据管理在Spark中是可伸缩的，它的处理就像数据一样分布在各个节点上。这将捕获模式、原子提交的创建时间、GUID ( <em class="nh">全局唯一标识符</em>)、文件格式和其他配置选项。</p><p id="a30d" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在本机对象存储中，读取/列表操作的开销很大，而在增量湖的情况下，元数据读取是从集群上的日志并行进行的。</p><p id="d9ac" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">这可以使用<code class="fe nd ne nf ng b">DESCRIBE HISTORY</code>、<code class="fe nd ne nf ng b">DESCRIBE DETAIL</code> SQL命令来完成。它运行在并行处理引擎上，并提供底层元数据信息。进一步参考，你可以在这里看到文档<a class="ae li" href="https://docs.delta.io/latest/delta-utility.html#-delta-detail" rel="noopener ugc nofollow" target="_blank">。</a></p><pre class="kt ku kv kw gt or ng os ot aw ou bi"><span id="88e3" class="ov mh it ng b gy ow ox l oy oz">-- get the full history<br/><strong class="ng jd">DESCRIBE</strong> HISTORY '/data/balanceTable/'        <br/><strong class="ng jd">DESCRIBE</strong> HISTORY delta.'/data/balanceTable/'</span><span id="13ba" class="ov mh it ng b gy pa ox l oy oz">-- get the metadata of delta table<br/><strong class="ng jd">DESCRIBE</strong> DETAIL '/data/balanceTable/'<br/><strong class="ng jd">DESCRIBE </strong>DETAIL delta.'/data/balanceTable/'</span></pre></div><div class="ab cl pb pc hx pd" role="separator"><span class="pe bw bk pf pg ph"/><span class="pe bw bk pf pg ph"/><span class="pe bw bk pf pg"/></div><div class="im in io ip iq"><h1 id="fbac" class="mg mh it bd mi mj pi ml mm mn pj mp mq ki pk kj ms kl pl km mu ko pm kp mw mx bi translated">结束语</h1><p id="26ec" class="pw-post-body-paragraph lj lk it ll b lm my kd lo lp mz kg lr ls na lu lv lw nb ly lz ma nc mc md me im bi translated">总之，数据湖带来的所有这些挑战都通过使用delta湖得到了解决。它通过保持数据流的一致性和持久性，大大降低了原始数据处理的复杂性。</p><p id="8f8e" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">关键要点是，当有大量原始数据时，使用Delta lake，重点是提高查询性能、数据一致性和持久性。</p><p id="2d40" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated"><em class="nh">请提供您的建设性想法、意见(或)建议。</em></p><p id="da8d" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">另外，请随时在<a class="ae li" href="https://www.linkedin.com/in/lingeshwaran-kanniappan-157455117/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上与我联系。下次见！</p></div></div>    
</body>
</html>