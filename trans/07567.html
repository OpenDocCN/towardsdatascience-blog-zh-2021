<html>
<head>
<title>SHAP: Shapley Additive Explanations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SHAP:沙普利加法解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/shap-shapley-additive-explanations-5a2a271ed9c3?source=collection_archive---------2-----------------------#2021-07-11">https://towardsdatascience.com/shap-shapley-additive-explanations-5a2a271ed9c3?source=collection_archive---------2-----------------------#2021-07-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0fd6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一步一步的指导理解SHAP如何工作，以及如何通过使用SHAP图书馆解释ML模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/26dda4e020ad75bb1d030f0bea79fdfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mVlPM8efiH1ZpHnmMPB_Lg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图一。SHAP |作者图片|自由选择的图标</p></figure><p id="ee84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在过去的十年里，我们见证了人工智能时代的爆发，由学术界推动，并被业界接受。人工智能已经融入日常生活，甚至商业模式也围绕着人工智能模式。</p><p id="cbfe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">人工智能在自然语言处理、计算机视觉等领域已经显示出令人印象深刻的成果。今天，只需要几行代码就可以实现最先进的人工智能模型，这太令人着迷了。然而，作为人类，我们该如何解读AI模型做出的预测呢？我们如何衡量模型赋予待推断数据的重要性？嗯，在这个博客中我们将谈论这个有争议的话题:<em class="lv">人工智能模型的可解释性</em>。</p><p id="36bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">人工智能模型的可解释性是一个活跃的研究领域。近年来已经提出了几种替代方案，在这篇博客中，我们将特别关注其中一个:SHAP(<em class="lv">Shapley Additive explaints</em>)。</p><p id="46df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个博客中，我们将看到SHAP方法的ML模型的可解释性，我们将看到SHAP是如何工作的，以及它的主要组成部分:Shapley值。因此，本博客将分为以下几个部分:</p><ul class=""><li id="6bce" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated"><strong class="lb iu">什么是沙普利值？</strong></li><li id="f0e0" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><strong class="lb iu">什么是SHAP？</strong></li><li id="c8dc" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><strong class="lb iu"> SHAP在行动:一个分类问题</strong></li><li id="3c6a" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><strong class="lb iu">结论</strong></li></ul><p id="4e0e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我建议你去喝杯咖啡，放松一下，☕️！</p><h1 id="3fc2" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">什么是匀称的价值观？</h1><p id="4018" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">Shapley值是合作博弈论领域的一个概念，其目的是衡量每个玩家对游戏的贡献。获得Shapley值的方法是由Lloyd Shapley [ <a class="ae ky" href="https://www.degruyter.com/document/doi/10.1515/9781400881970-018/html" rel="noopener ugc nofollow" target="_blank"> 1 </a> ]在1953年提出的。Shapley值产生于这样的背景，其中"<em class="lv"> n </em>"玩家集体参与并获得奖励"<em class="lv"> p </em>"，该奖励旨在根据个人贡献公平地分配给每个"<em class="lv"> n </em>"玩家，这样的贡献是Shapley值。</p><p id="a741" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简而言之，Shapley值是一个特性实例在所有可能组合中的平均边际贡献。平均边际贡献？所有可能的联盟？我们来详细看看这一切指的是什么。</p><p id="cb85" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">比方说，一群朋友(<code class="fe nh ni nj nk b">A</code>、<code class="fe nh ni nj nk b">B</code>、<code class="fe nh ni nj nk b">C</code>、<code class="fe nh ni nj nk b">D</code>)正在一起合作获取利润<code class="fe nh ni nj nk b">P</code>。公平分配利润，意在衡量每个成员的贡献，即每个朋友的沙普利值。为了计算给定成员的Shapley值，计算当该成员存在时产生的利润与当该成员不存在时产生的利润之间的差(这种差是给定成员对当前联盟的<em class="lv">边际贡献</em>),这是针对当你期望为其计算贡献的成员存在时可以产生的所有子组(或联盟)进行的。获得的差值的平均值(平均边际贡献)是Shapley值。</p><p id="a184" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下图中，我们看到了朋友<code class="fe nh ni nj nk b">A</code>对由朋友<code class="fe nh ni nj nk b">B</code>、<code class="fe nh ni nj nk b">C</code>和<code class="fe nh ni nj nk b">D</code>组成的校对的边际贡献的计算表示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/56c71323e7463956ed7b78ac3c32565b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m-4iY6YmKI5KCdVt4xF6sw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图二。成员“A”对成员B、C、d联盟的边际贡献|作者图片|自由选择的图标<a class="ae ky" href="https://www.flaticon.es/autores/freepik" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="e41c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，为了计算朋友<code class="fe nh ni nj nk b">A</code>的Shapley值，我们将需要构建朋友<code class="fe nh ni nj nk b">A</code>出现的所有排序，对于每个排序，将计算边际贡献(成员在场时获得的利润与成员不在场时获得的利润之间的差异),并且给定所有边际贡献，将计算平均边际贡献，即Shapley值。简单吧？</p><p id="f051" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图3显示了朋友<code class="fe nh ni nj nk b">A</code>的Shapley值的计算。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/12085b306e29d7bf4df65dd4d1784a89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vwWijeEx898uoUyWOtAMaw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3。成员“A”的Shapely值计算|作者的图像|自由选择的图标<a class="ae ky" href="https://www.flaticon.es/autores/freepik" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="1dc0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">到目前为止，我们已经知道什么是Shapley值，它是如何计算的，以及它的解释是什么。然而，Shapley值与ML模型的可解释性有什么关系？让我们看看这是如何发生的。</p><p id="153a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在一个ML模型的背景下，我们假设我们例子中的每个朋友都是一个特性，游戏是生成预测的函数，利润就是预测。</p><p id="7719" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，ML模型通常具有大量的特征，其中每个特征是离散或连续的变量，这导致计算每个特征的每个实例的Shapley值在计算上非常复杂，事实上，这是一个NP-hard问题。</p><p id="27f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正是在这一点上，SHAP成了主角。在下一节中，我们将看到什么是SHAP以及它对ML模型的可解释性的方法。</p><p id="abe0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">也许是时候重新装满咖啡杯了，☕️！</p><h1 id="9cc9" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">什么是SHAP？</h1><p id="9072" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">Shapley Additive Explanations(SHAP)，是Lundberg和Lee在2017年[ <a class="ae ky" href="https://arxiv.org/pdf/1705.07874.pdf" rel="noopener ugc nofollow" target="_blank"> 2 </a>推出的一种通过Shapely值解释ML模型预测的方法。SHAP的主要思想是为要解释的样本的每个特征计算Shapley值，其中每个Shapley值代表与其关联的特征在预测中产生的影响。</p><p id="eaf3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SHAP背后的直觉很容易理解，每个特征都有一个相关的沙普利值。然而，SHAP是如何工作的呢？在上一节中，我们看到Shapley值的计算对于许多特征来说可能变得难以处理。为了避免这种情况，作者引入了Kernel Shap，这是一种从线性时间[ <a class="ae ky" href="https://arxiv.org/pdf/1602.04938.pdf" rel="noopener ugc nofollow" target="_blank"> 3 </a> ]扩展和改编的方法，用于计算Shapley值。</p><p id="799b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">核Shap是一种允许用少得多的联合样本计算Shapley值的方法。内核Shap基于加权线性回归，其中解的系数是Shapley值。为了建立加权线性模型，采用样本联盟，对于每个联盟，获得预测，并使用核形状计算权重。最后，拟合加权线性模型，得到的系数是Shapley值。</p><p id="caf5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有点复杂，对吧？我们来详细看看。</p><p id="b77f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设我们想要解释实例<code class="fe nh ni nj nk b">x</code>，它由特征<code class="fe nh ni nj nk b">f1</code>、<code class="fe nh ni nj nk b">f2</code>、<code class="fe nh ni nj nk b">f3</code>和<code class="fe nh ni nj nk b">f4</code>组成。该过程从获取一组联合样本开始。例如，联合<code class="fe nh ni nj nk b">(1,0,1,0)</code>指的是特征<code class="fe nh ni nj nk b">f1</code>和<code class="fe nh ni nj nk b">f3</code>的存在，以及特征<code class="fe nh ni nj nk b">f2</code>和<code class="fe nh ni nj nk b">f4</code>的不存在。由于ML模型不能省略特征来进行推断，所以特征<code class="fe nh ni nj nk b">f2</code>和<code class="fe nh ni nj nk b">f4</code>的值被取自训练集的值所替换。然后，对于联合<code class="fe nh ni nj nk b">(1,0,1,0)</code>，特征<code class="fe nh ni nj nk b">f1</code>和<code class="fe nh ni nj nk b">f3</code>的值取自实例<code class="fe nh ni nj nk b">x</code>，特征<code class="fe nh ni nj nk b">f2</code>和<code class="fe nh ni nj nk b">f4</code>的值来自训练集，这样可以正确地进行预测。因此，对于每个联合样本，利用等式1中描述的核形状来获得预测并计算权重。求解线性模型，得到的系数就是Shapley值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/c09bd25a812b8a239c342025ab8804a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2hZqNC0kHEyVRjxz9YgqSQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式1。内核形状</p></figure><p id="9f44" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一切都清楚了吧？没有什么比一张图片更能说明整个过程了。在图4中，我们看到了给定实例<code class="fe nh ni nj nk b">X</code>的Shapley值计算的描述过程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/c032970ac94253246103ddc42c2814d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xKuwrh3JGZolIa0FV_hAaw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4。SHAP从ML模型中获取Shapley值的描述过程|图片由作者提供</p></figure><p id="5ba8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上图可以看出，通过核Shap从ML模型中获取Shapley值的过程并不复杂，但却很费力。主要成分是联盟、预测和权重。</p><p id="d4bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">值得注意的是，试图计算所有的联盟会使问题变得棘手。这就是采取联盟样本的原因，样本越大，不确定性越低。</p><p id="9c29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，很重要的一点是，对于Shapley值的计算，Kernel Shap是唯一与模型无关的方法，也就是说，Kernel Shap可以解释任何ML模型，而不管其性质如何。另一方面，作者还提出了基于不同类型的模型(如树SHAP、深SHAP、低阶SHAP、线性SHAP和最大SHAP)来获得沙普利值的其他变型。</p><p id="3886" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好了，是时候看看SHAP的行动了。在下一节中，我们将看到如何使用<code class="fe nh ni nj nk b">shap</code>库从ML模型中获取Shapley值。我想是时候重新装满咖啡杯了，☕️！</p><h1 id="d29d" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">SHAP在行动:一个分类问题</h1><p id="8200" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">SHAP及其变体被集成到python库<code class="fe nh ni nj nk b">shap</code>中，该库除了提供计算Shapely值的不同方法外，还集成了多种结果可视化和解释方法。</p><p id="70d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本节的目标是展示如何使用<code class="fe nh ni nj nk b">shap</code>库来计算、绘制和解释分类问题中的Shapley值。所以，让我们努力吧！</p><blockquote class="no np nq"><p id="324d" class="kz la lv lb b lc ld ju le lf lg jx lh nr lj lk ll ns ln lo lp nt lr ls lt lu im bi translated">完整的项目，以及本文中显示的例子，可以在下面找到:<a class="ae ky" href="https://github.com/FernandoLpz/SHAP-Classification-Regression" rel="noopener ugc nofollow" target="_blank">https://github . com/FernandoLpz/SHAP-分类-回归</a></p></blockquote><h2 id="8c11" class="nu ml it bd mm nv nw dn mq nx ny dp mu li nz oa mw lm ob oc my lq od oe na of bi translated">数据集</h2><p id="991d" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">对于这个例子，我们将使用乳腺癌威斯康星(诊断)数据集[ <a class="ae ky" href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29" rel="noopener ugc nofollow" target="_blank"> 4 </a> ]，其特征描述了肿瘤的特征，并且目标是预测肿瘤是良性还是恶性。数据集包含100个样本，8个独立特征(<code class="fe nh ni nj nk b">radius</code>、<code class="fe nh ni nj nk b">texture</code>、<code class="fe nh ni nj nk b">perimeter</code>、<code class="fe nh ni nj nk b">area</code>、<code class="fe nh ni nj nk b">smoothness</code>、<code class="fe nh ni nj nk b">compactness</code>、<code class="fe nh ni nj nk b">symmetry</code>和<code class="fe nh ni nj nk b">fractal_dimension</code>)和一个从属特征(<code class="fe nh ni nj nk b">diagnosis_result</code>，目标特征)。</p><p id="66e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">目标特征包含两个类别<code class="fe nh ni nj nk b">M = Malign</code>和<code class="fe nh ni nj nk b">B = Benign</code>。出于实用目的，我们将类别编码如下:<code class="fe nh ni nj nk b">0 = Malign</code>和<code class="fe nh ni nj nk b">1 = Benign</code>。</p><h2 id="f0f6" class="nu ml it bd mm nv nw dn mq nx ny dp mu li nz oa mw lm ob oc my lq od oe na of bi translated">模型</h2><p id="a3c2" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">针对这个问题，我们实现并优化了一个基于随机森林的模型，在测试集中获得了<code class="fe nh ni nj nk b">92%</code>的准确率。下面的代码片段显示了分类器的实现。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码片段1。随机森林分类器的训练和优化</p></figure><p id="df1e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的代码片段中，我们实现了一个基于随机森林的分类器，它已经使用<code class="fe nh ni nj nk b">Optuna</code>库进行了优化。从这一点上来说，我们已经有了一个能做出预测的模型，我们打算用SHAP来解释它，所以让我们来看看我们是怎么做的吧！</p><h2 id="4ab5" class="nu ml it bd mm nv nw dn mq nx ny dp mu li nz oa mw lm ob oc my lq od oe na of bi translated">释义:沙普利价值观</h2><p id="c079" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">假设我们有两个想要解释的样本，一个样本属于类别<code class="fe nh ni nj nk b">1</code> ( <code class="fe nh ni nj nk b">Benign</code>)，另一个样本属于类别<code class="fe nh ni nj nk b">0</code> ( <code class="fe nh ni nj nk b">Malign</code>)，分别如图5和图6所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/80a53f01b8d6aed0a683a516b0854f72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DlVasFP1VVbw9bd7ZCGCqw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图5。阳性样本|类别=良性</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/4341505451a5f19fdfa917dcf47f01bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5XDYNfftmVrpIPsHdLrvqg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图6。负样本| Class = Malign</p></figure><p id="671e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于我们的ML模型是基于决策树的，为了获得Shapley值，我们将使用TreeShap。因此，我们首先需要导入库，并通过将我们的分类器作为参数传递来初始化解释器，如下面的代码片段所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码片段2。TreeExplainer初始化</p></figure><p id="f0c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们需要计算Shapley值的样本。在这种情况下，我从训练数据集中提取分别对应于图5和图6中所示的样本(重要的是要提到，出于解释的目的，我一次使用一个样本，但是也可以使用整个数据集)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码片段3。阳性和阴性样本</p></figure><p id="7964" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">只是为了检查，每个样本的预测是:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码片段4。阳性和阴性样本的预测</p></figure><p id="31f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了计算Shapley值，我们使用从explainer扩展而来的<code class="fe nh ni nj nk b">shap_values</code>方法。它接收到的参数就是我们想要解释的样本:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码片段5。获取阳性和阴性样本的Shapley值</p></figure><p id="99e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是我们的沙普利值！但是等一下，我们如何解读这些价值观呢？为什么从索引<code class="fe nh ni nj nk b">[1]</code>打印出来？好吧，我们来详细看看这个。</p><p id="64d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，变量<code class="fe nh ni nj nk b">shap_values_positive</code>和<code class="fe nh ni nj nk b">shap_values_negative</code>包含对应于正类和负类的每个特征的Shapley值，因此，<code class="fe nh ni nj nk b">shap_values_positive[0]</code>包含每个特征相对于类<code class="fe nh ni nj nk b">0</code>(或<code class="fe nh ni nj nk b">Malign</code>)的Shapley值，<code class="fe nh ni nj nk b">shap_values_positive[1]</code>包含每个特征相对于类<code class="fe nh ni nj nk b">1</code>(或<code class="fe nh ni nj nk b">Benign</code>)的Shapley值，这同样适用于<code class="fe nh ni nj nk b">shap_values_negative</code>。为了实用，我们使用关于类<code class="fe nh ni nj nk b">1</code>的结果。</p><p id="99b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，对于<code class="fe nh ni nj nk b">positive</code>和<code class="fe nh ni nj nk b">negative</code>样本，我们获得8个值的列表，它们对应于每个特征的Shapley值。在下图中，我们可以更清楚地看到每个样本及其各自的Shapley值:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/5837e593eff4c17bfc6a21a540bb0b79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mhx_Cv30k_8kAfdWbRX8ow.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图7。每个阳性和阴性样本的每个特征的Shapley值</p></figure><p id="f7e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你还记得第一部分中解释的Shapley值的本质吗？这里发生了完全相同的事情，具有高Shapley值的要素影响较大，具有低Shapley值的要素对预测的影响较小。我们也可以将Shapley值解释为，具有高shap值的特征<em class="lv">将</em>推向一个类，而具有低shap值的特征<em class="lv">将</em>推向另一个类。</p><p id="2833" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从正面样本中，我们看到Shapley值最高的特征是<code class="fe nh ni nj nk b">perimeter</code>、<code class="fe nh ni nj nk b">compactness</code>和<code class="fe nh ni nj nk b">area</code>。从负样本来看，Shapley值最低的特征是<code class="fe nh ni nj nk b">perimeter</code>、<code class="fe nh ni nj nk b">area</code>和<code class="fe nh ni nj nk b">compactness</code>。</p><p id="4664" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们提到的，<code class="fe nh ni nj nk b">shap</code>库也提供了生成图的工具。让我们看看如何为阳性和阴性样本绘制一个名为<code class="fe nh ni nj nk b">force_plot</code>的图:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码片段6。绘制阳性和阴性样本</p></figure><p id="a9af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个样品的结果图如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/b0652d6548176df0e55419e86faf3919.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4yaO2k0C5x7kKV-uNgNBVw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图8。阳性样本的强制绘图| Class =良性|作者提供的图像</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/d8de8a84717a20332b88c77e33866d43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ghECTTEiozSKFaGqIRUgRg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图9。负样本的强制绘图| Class = Malign |作者的图像</p></figure><p id="ccd0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们从两个图中看到的，每个特性的影响对应于图7中描述的Shapely值。在红色中我们看到高Shapley值，即它们向类<code class="fe nh ni nj nk b">1</code>(或<code class="fe nh ni nj nk b">Benign</code>)推进，在蓝色中我们看到低Shapley值，即它们向类<code class="fe nh ni nj nk b">0</code>(或<code class="fe nh ni nj nk b">Malign</code>)推进。<code class="fe nh ni nj nk b">force_plot</code>是一个很好的可视化工具，可以用来理解每个特性对给定预测的特定样本的影响。</p><p id="0f2b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nh ni nj nk b">force_plot()</code>是理解每个特性对特定样本的影响的一个很好的可视化工具，同样<code class="fe nh ni nj nk b">shap</code>库提供了各种类型的可视化工具来帮助解释Shapley值。例如，<code class="fe nh ni nj nk b">summary_plot()</code>方法通过改变每个特性的值来提供关于特性重要性以及Shapley值影响的信息。</p><p id="5a9b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于本例，<code class="fe nh ni nj nk b">summary_plot()</code>由下式给出:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码片段7。汇总图</p></figure><p id="1a61" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">生成以下图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/dfd156bc6c868e800b90f2ba6303f811.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2j8995tZXmf_egnmuodaqw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图10。汇总图</p></figure><p id="5104" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在左侧，我们观察根据重要性排序的每个特性。<code class="fe nh ni nj nk b">perimeter</code>特征最重要，而<code class="fe nh ni nj nk b">texture</code>特征最不重要。颜色代表每个要素可以采用的值，红色代表高值，蓝色代表低值。因此，对于特性<code class="fe nh ni nj nk b">perimeter</code>，如果值较高(红色)，则Shapley值将较低，因此将推向等级<code class="fe nh ni nj nk b">0</code>(或<code class="fe nh ni nj nk b">Malign</code>)，否则，当值较低(蓝色)时，Shapley值将较高，因此将推向等级<code class="fe nh ni nj nk b">1</code>(或<code class="fe nh ni nj nk b">Benign</code>)。这可以分别用图8和图9所示的结果来验证。</p><p id="f5fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个重要的观察结果是，<code class="fe nh ni nj nk b">perimeter</code>、<code class="fe nh ni nj nk b">compactness</code>和<code class="fe nh ni nj nk b">area</code>特征是在给定其相关Shapely值的情况下对预测产生最大影响的特征，也就是说，它们的Shapley值非常高或非常低。另一方面，其余的特征不会产生太大的影响，因为它们的相关Shapley值更接近于零。</p><p id="75c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图<code class="fe nh ni nj nk b">summary_plot()</code>的一个变体，以条形图的形式显示了每个特性的影响，这样的图可以通过以下方式获得:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码片段8。汇总图，条形图</p></figure><p id="f697" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">生成以下图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/5b18236314b336a3c009f65dbbcc081a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_RcueLdNe0M0XfkQJ-BG4Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图11。汇总图，条形图</p></figure><p id="6abb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如图10所示，在图11中，我们可以看到每个特性根据其相关Shapley值的影响进行排序。同样，我们观察到特征<code class="fe nh ni nj nk b">perimeter</code>、<code class="fe nh ni nj nk b">compactness</code>和<code class="fe nh ni nj nk b">area</code>是对模型影响最大的特征。</p><blockquote class="no np nq"><p id="fb8b" class="kz la lv lb b lc ld ju le lf lg jx lh nr lj lk ll ns ln lo lp nt lr ls lt lu im bi translated">完整的项目，以及本文中显示的例子，可以在下面找到:<a class="ae ky" href="https://github.com/FernandoLpz/SHAP-Classification-Regression" rel="noopener ugc nofollow" target="_blank">https://github . com/FernandoLpz/SHAP-分类-回归</a></p></blockquote><p id="165b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">喝了几杯咖啡后，现在我们已经到了终点！</p><h1 id="3deb" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">结论</h1><p id="6eaa" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">在这篇博客中，我们看到了什么是SHAP。</p><p id="068d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在第一节中，我们谈到了从Shapely价值观的起源和解释。在第二部分中，我们学习了什么是SHAP，它是如何工作的，以及它对ML模型可解释性的基于石灰和Shapely值的支持。最后，在第三部分中，我们看到了如何使用<code class="fe nh ni nj nk b">shap</code>库，并展示了一个示例来解释shap库返回的结果。</p><p id="50c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nh ni nj nk b">shap</code>库提供了大量可视化和解释ML模型的工具。在这篇博客中，我们只看到了几个例子。建议看一下文档，以便从这个伟大的库获得最大的好处。</p><blockquote class="no np nq"><p id="e09a" class="kz la lv lb b lc ld ju le lf lg jx lh nr lj lk ll ns ln lo lp nt lr ls lt lu im bi translated">“阅读、学习、写作、分享。重复“T1”——费尔南多·洛佩斯·维拉斯科。</p></blockquote><h1 id="77f1" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">参考</h1><p id="0d90" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">[1]<a class="ae ky" href="https://www.degruyter.com/document/doi/10.1515/9781400881970-018/html" rel="noopener ugc nofollow" target="_blank">n人游戏的一个数值。L.S .沙普利。1953年</a></p><p id="59a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2] <a class="ae ky" href="https://arxiv.org/pdf/1705.07874.pdf" rel="noopener ugc nofollow" target="_blank">解释模型预测的统一方法</a></p><p id="db80" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">【3】<a class="ae ky" href="https://arxiv.org/pdf/1602.04938.pdf" rel="noopener ugc nofollow" target="_blank">“我为什么要相信你？”解释任何分类器的预测</a></p><p id="171b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[4] <a class="ae ky" href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29" rel="noopener ugc nofollow" target="_blank">乳腺癌威斯康星(诊断)</a></p></div></div>    
</body>
</html>