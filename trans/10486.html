<html>
<head>
<title>AI Isn’t ‘Scary Smart’ but Mindlessly Dangerous</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能不是“可怕的聪明”，而是盲目的危险</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ai-isnt-scary-smart-but-mindlessly-dangerous-e2642fa2aec6?source=collection_archive---------9-----------------------#2021-10-06">https://towardsdatascience.com/ai-isnt-scary-smart-but-mindlessly-dangerous-e2642fa2aec6?source=collection_archive---------9-----------------------#2021-10-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="daef" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">人工智能|新闻|观点</h2><div class=""/><div class=""><h2 id="344d" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">前谷歌高管说我们在“创造上帝”——但他错了。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/efd19081d19d88c15fbf20f3a5c4e0a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZWtz7t2PX2fbp1xQ3l1B0Q.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">何塞·安德烈斯在<a class="ae lh" href="https://pixabay.com/es/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上拍摄的照片</p></figure><p id="3e7f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">人工智能中有很多分裂的事情。有可能用当前的范式创造智能机器吗，或者我们应该根据认知科学的发现更新指导人工智能研究的原则吗？我们应该继续利用深度学习的前景，还是应该使用混合方法向机器灌输知识和数据？我们应该期待更大的模型产生越来越好的结果，还是需要算法突破来引领人工智能的下一阶段？</p><p id="53c3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些问题描绘了人工智能的现在和未来，但只有少数人关心寻找答案。然而，人工智能的另一个方面应该会困扰我们所有人。包括你。它将以这样或那样的方式影响尚未被书写的历史。我说的是AI的风险和危险。奇怪的是，尽管这个问题很紧迫，甚至在这方面专家们也没有就什么是最紧迫的问题达成一致。</p><p id="6d45" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">人工智能在我们的日常生活中根深蒂固，以至于任何不熟悉这个话题的人肯定会低估它的程度。<a class="ae lh" href="https://techresearchonline.com/blog/best-ai-assistant-of-2021/#What_is_an_AI_assistant?" rel="noopener ugc nofollow" target="_blank">智能手机中的个人助理</a>；<a class="ae lh" href="https://carnegieendowment.org/2019/09/17/global-expansion-of-ai-surveillance-pub-79847" rel="noopener ugc nofollow" target="_blank">机场和街道上的监视和控制装置</a>；<a class="ae lh" href="https://www.intercom.com/blog/customer-service-chatbots/" rel="noopener ugc nofollow" target="_blank">客服中的友好聊天机器人</a>；<a class="ae lh" href="https://www.vox.com/recode/2019/12/12/20993665/artificial-intelligence-ai-job-screen" rel="noopener ugc nofollow" target="_blank">影响你职业前途的招聘算法</a>；推荐系统，决定你看的电影和购买的产品；<a class="ae lh" href="https://www.nytimes.com/wirecutter/blog/how-facial-recognition-works/" rel="noopener ugc nofollow" target="_blank">知道你是谁，你长什么样的检测识别软件</a>；在不久的将来，准智能汽车将使驾驶变得过时。</p><p id="20b7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">人工智能的无处不在加深了任何潜在的错位，这可能会对我们生活的许多方面产生影响。已经发生了。人工智能专家正在努力提高这些系统的安全性、可靠性和可解释性。他们押注于不伤害少数群体、不传播错误信息的道德人工智能。他们试图为蓝领和白领行业的劳动力面临的迫在眉睫的损失寻找解决方案。但即使在这个极其关键的问题上，也不是每个人都在同一条船上。有些人认为我们应该更关心控制超级智能的潜在出现。谷歌X的前CBO莫·格达特就是其中之一。这就是为什么我们应该对他的恐惧和警告半信半疑。</p><h1 id="2d2d" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">我们在建造上帝吗？</h1><p id="e27f" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">莫·格达害怕艾。他最近出版了一本名为《可怕的聪明》的书，在书中，他警告我们，即将到来的世界末日只有我们能够阻止。在《泰晤士报》的采访中，他回忆起他意识到人工智能将会是我们的败笔的那一刻。在Google X的一个项目中，开发人员试图教会机械臂捡球。经过数周的缓慢进展，其中一只手臂伸到了球上，举起手向镜头展示，好像在“炫耀”——在任何了解AI工作原理的人看来，这只是拟人化的又一个例子。那一刻让他意识到“真的很可怕”</p><p id="2023" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Gawdat想知道为什么几乎没有人谈论这个。在<a class="ae lh" href="https://youtu.be/cc6KgUifWRw" rel="noopener ugc nofollow" target="_blank">与作家兼技术从业者肯·雅莫什的对话</a>中，Gawdat总结了他对人工智能生命周期所处阶段的看法:“人工智能不再是一台机器，”他说。“我们正在建造一个……数字生物，它……拥有构成有意识生物的所有特征。所以它是自主的，进化的，它有智能，它发展智能…它自我复制…而且它有代理。”</p><p id="73d0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">“我们在建造上帝。”</p><p id="3ef5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这样一个大胆的主张需要同样强有力的证据，但Gawdat只提供了轶事般的例子，这些例子可以很好地解释，而不必求助于深奥的概念，如“有知觉的数字生物”、“T4”、“奇点”或“上帝”。他认为，我们没有意识到我们在人工智能发展方面已经走了多远，并提到了一些在我们通往他描绘的未来的道路上“不可避免”会发生的事情。(他的辩论围绕着未来是乌托邦还是反乌托邦展开。他相信这一天终将到来。)</p><p id="e96c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第一个不可避免的是，人工智能将会发生，事实上“[它]已经发生了，”他说。他认为深度学习已经是人工智能了，因为它比我们更好地完成了分配给它的每一项任务——这不是真的，我将在下一节中展示。第二个必然是，AI会比人类更聪明。他提到了未来学家雷·库兹韦尔(Ray Kurzweil)，这位“预测我们未来的先知”，以及奇点(Singularity)，这是他最受欢迎的概念:“到2029年，机器将比人更聪明。”这个精确的日期来自于指数增长的论点，这仍然是一个无力的辩护，因为“<a class="ae lh" href="https://web.archive.org/web/20121030072409/http://www.growth-dynamics.com/articles/Kurzweil.htm#:~:text=Nothing%20in%20nature%20follows%20a%20pure%20exponential" rel="noopener ugc nofollow" target="_blank">自然界中没有任何事物遵循纯粹的指数增长</a></p><p id="7367" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">总的来说，他的论点有两大缺陷。首先，他从未给人工智能下过定义。当讨论的术语没有明确定义时，不可能同意或不同意任何人。在那次谈话中，他承认了定义人工智能的重要性——但他没有遵循自己的前提。第二，他将今天有效的论点延伸到我们知之甚少的未来。他谈到的人工智能失调的场景已经在今天的狭义人工智能系统中发生了。然而，他用它们来证明超级智能机器才是真正的威胁。为什么不关注眼前的事情，而不是展望不可预见的未来呢？</p><h1 id="44db" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">为什么人工智能不“聪明得吓人”</h1><p id="e279" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">我们应该小心人工智能，但不是出于Gawdat描述的原因。人工智能可能很可怕，但不是因为它太聪明。几乎没有人工智能专家会同意Gawdat的观点，即当今的主要威胁是这些系统已经或“即将”变得超级智能。这可能最终会发生，但最有可能的是不会在八年后，在我们面对今天出现的其他危险情景之后。</p><h2 id="9c7d" class="nb mf it bd mg nc nd dn mk ne nf dp mo lr ng nh mq lv ni nj ms lz nk nl mu iz bi translated">艾已经来了吗？</h2><p id="535d" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">AI(最广义的定义，包含所有机器学习/深度学习系统)已经在许多狭义的任务中超过了我们，但在许多其他方面却无法达到我们的水平——更不用说在一般意义上显示智能了。</p><p id="7d9c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">算法擅长对象识别，这是研究得最多的任务之一，但只在非常特定的条件下。最佳视觉人工智能模型在ImageNet挑战赛上取得了惊人的<a class="ae lh" href="https://paperswithcode.com/sota/image-classification-on-imagenet" rel="noopener ugc nofollow" target="_blank"> +90%的前1名准确率</a>(这远比人类好<a class="ae lh" href="https://arxiv.org/abs/1502.01852" rel="noopener ugc nofollow" target="_blank">)。然而，当面对真实世界的对象数据集ObjectNet时，这个模型经历了</a><a class="ae lh" href="https://objectnet.dev/objectnet-a-large-scale-bias-controlled-dataset-for-pushing-the-limits-of-object-recognition-models.pdf" rel="noopener ugc nofollow" target="_blank">40–45%的性能下降</a>。ImageNet描绘了一个理想化的世界，因此挑战的结果扭曲了人工智能在物体识别方面的真实能力。</p><p id="4ab5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Gawdat回忆说，早在1989年，机器就已经是最好的国际象棋选手(人类不再有任何可能击败最好的人工智能选手)。两年前横扫Stockfish 8的DeepMind的AlphaZero ，是最好的棋手之一。在普通的游戏中，你无法战胜它，但只要把棋盘的大小从8×8改为9×9，你就成了主人。这项任务极其相似，但是当面临与它所学知识的最小偏差时，AlphaZero将无法概括它的知识。</p><p id="4ef2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Gawdat还提到，自动驾驶汽车是世界上最好的司机。但是相对而言，它们不仅比人类更容易撞车，我们也更善于处理意外情况。自动驾驶汽车的关键弱点是现实有尽可能多的自由度。任何事情都可能发生，人工智能系统不太擅长从训练集推断出新的情况。因为他们缺乏对世界如何运作的更深层次的模型，所以他们经验之外的任何东西都成为不可逾越的障碍。</p><p id="3b60" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://arxiv.org/abs/2005.14165" rel="noopener ugc nofollow" target="_blank"> OpenAI的GPT-3 </a>，虽然被认为是最强大的公共大语言模型，但是不能<a class="ae lh" href="https://medium.com/@melaniemitchell.me/follow-up-to-can-gpt-3-make-analogies-b202204bd292" rel="noopener">生成类比</a>，<a class="ae lh" href="https://venturebeat.com/2021/03/09/researchers-find-that-large-language-models-struggle-with-math/" rel="noopener ugc nofollow" target="_blank">解决数学问题</a>，理解上下文信息，<a class="ae lh" href="https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-intelligence-ai-opinion/#:~:text=many%20major%20issues%20with%20GPT-3%20were%20immediately%20evident%2C%20in%20every%20domain%20of%20reasoning%20and%20comprehension%20that%20we%20tested." rel="noopener ugc nofollow" target="_blank">推理</a>关于世界的底层原理，甚至链接因果。它可以生成各种形式的文本，但它还没有掌握人类意义上的语言。</p><p id="5003" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">人工智能缺乏思维理论、常识和因果推理、推断能力以及身体，因此它在几乎任何稍微复杂或一般的事情上都远远没有“比我们好”。</p><h2 id="d2c1" class="nb mf it bd mg nc nd dn mk ne nf dp mo lr ng nh mq lv ni nj ms lz nk nl mu iz bi translated">AI会比人类聪明吗？</h2><p id="d1d6" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">如果我们继续以目前的速度前进，没有任何事情会让我们慢下来(从社会政治体系的剧烈变化到全球现象——比如气候灾难——都可能阻碍技术进步)，那么“没有办法阻止它”的想法是合乎逻辑的。然而，对于AI来说，八年时间对于达到这样一个里程碑来说似乎是很短的时间。</p><p id="9bf1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">雷·库兹韦尔，加速回报定律的创造者，在他的书《精神机器的时代》中提出，技术趋向于指数增长。然而，正如物理学家西奥多·莫迪斯(Theodore Modis)在反驳库兹韦尔的预测时解释的那样，“他的错误行为依赖于数学函数，而不是自然法则……所有的自然增长都遵循逻辑函数。”</p><p id="8c26" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">事实上，我们喜欢谈论指数变化率，比如摩尔定律，但是这些“定律”只有在不成立时才成立。指数增长有自然的极限，因此合乎逻辑的假设是现实中“没有什么遵循纯粹的指数增长”，正如莫迪斯所辩护的那样。</p><p id="3ec0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">2029年是库兹韦尔认为地球上最聪明的生物将是人工智能的日子。但他用数学如何与自然世界相关的简单观点来计算它——更不用说所有其他不断干扰技术进步速度甚至可能完全改变其方向的因素，如社会运动、道德辩论或政府监管。</p><p id="a11e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，即使我们假设人工智能最终会变得比我们更聪明，也没有理由认为它会决定“与我们作对”，Gawdat显然就是这样做的。他把智力和动机混淆了。正如史蒂芬·平克所解释的(引用自加里·马库斯的书<em class="nm">重新启动人工智能</em>)，“智能是运用新方法来达到目标的能力。但目标与智力无关:聪明并不等同于想要某样东西。”</p><p id="03d8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们不知道如何给人工智能注入动机——这是一种进化特征，只因为我们进化的方式而存在。但是即使我们知道怎么做，我们为什么要这么做？仅仅因为人类既有知道如何实现目标的智慧，又有采取行动的动机，并不意味着他们一起进化，或者他们本质上是交织在一起的。</p><h1 id="7a64" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">真正的问题——无脑人工智能</h1><p id="69a0" class="pw-post-body-paragraph li lj it lk b ll mw kd ln lo mx kg lq lr my lt lu lv mz lx ly lz na mb mc md im bi translated">加里·马库斯(Gary Marcus)在推特上回应了Gawdat对《纽约时报》的采访，强调了我们今天在人工智能领域面临的“真正挑战”:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="e5de" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">AI没那么聪明，但确实很恐怖。Gawdat对生存威胁的关注掩盖了我们对当前社会结构各个层面每天都在发生的问题的看法。对尚未理解的假设风险给予更多的重视——这些风险距离未来如此之远，甚至没有一种有用的方法来讨论它们——阻碍了我们面对人工智能的真正危险的努力。</p><p id="0505" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">正如马库斯所说，没有大脑的人工智能是真正的问题。我们用它来制定决策，并在许多行业的决策过程中采取行动。当这些系统不了解世界如何运作或其行为的后果时，我们如何做到这一点呢？这正是近年来人工智能研究的新分支开始出现的原因，这些分支专注于包含这些问题，其中人工智能安全和人工智能伦理脱颖而出。</p><p id="a3ce" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们如何确保一项技术像一个“黑匣子”一样有效地运行，其决策通常是不可预测的，而这些决策背后的原因是不可理解的，我们希望它做什么？Gawdat承认，对齐的问题现在非常现实。如果人工智能最终做了我们没有预料到的事情，我们不需要等待超级智能遭受人工智能可能带来的麻烦。偏见是人工智能系统的一个非常有害的普遍特征，它最终变成了种族主义者、性别歧视者和主要针对代表性不足的少数民族。</p><p id="e84d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">没有大脑的人工智能也非常有能力取代工人，同时产生大量的污染，增加其碳足迹。它也是假新闻的首要引擎，它对几乎每个决定我们在休闲和信息方面消费的系统都有不可避免的影响。人工智能的真正危险是那些看不见的，并通过我们的生活方式缓慢而无声地传播其分支，同时牢固地巩固其在我们世界基础上的根基。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><p id="adf6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="nm">如果你喜欢这篇文章，可以考虑订阅我的免费周报</em><a class="ae lh" href="https://mindsoftomorrow.ck.page" rel="noopener ugc nofollow" target="_blank"><em class="nm"/></a><em class="nm">！每周都有关于人工智能的新闻、研究和见解！</em></p><p id="334c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="nm">您也可以直接支持我的工作，使用我的推荐链接</em> <a class="ae lh" href="https://albertoromgar.medium.com/membership" rel="noopener"> <em class="nm">这里</em> </a> <em class="nm">成为媒介会员，获得无限权限！:)</em></p></div></div>    
</body>
</html>