<html>
<head>
<title>V measure: an homogeneous and complete clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">v测度:同质的完全聚类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/v-measure-an-homogeneous-and-complete-clustering-ab5b1823d0ad?source=collection_archive---------6-----------------------#2021-04-08">https://towardsdatascience.com/v-measure-an-homogeneous-and-complete-clustering-ab5b1823d0ad?source=collection_archive---------6-----------------------#2021-04-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/d76fba45d67eca4c49c2081a802d62bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WR-pe2TLLMMk6MA8"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">萨姆·穆卡达姆在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="29f2" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">有意义的分数</h2></div><p id="b5d8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">聚类</strong>是一种机器学习技术，涉及数据点的分组。给定一组数据点，我们可以使用聚类算法将每个数据样本分类到特定的组(簇)中。</p><p id="9e72" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">聚类是<strong class="kx jh">无监督学习</strong>的一种方法，是许多领域使用的统计数据分析的常用技术。数据科学家希望同一聚类中的样本具有相似的属性、特征或行为。例如，可以对癌症样本进行聚类，希望同一组中的样本属于同一癌症亚型[2]。</p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><p id="001d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一旦聚类运行，人们必须定性地评估输出的<strong class="kx jh">优度。首先，验证分组是否真的<strong class="kx jh">有意义</strong>，而且有分数可以作为<strong class="kx jh">评估不同模型</strong>并选择<strong class="kx jh">最佳模型</strong>的代理。</strong></p><p id="af85" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有许多不同的分数，每一个都有它的优点和缺点。</p><div class="ip iq gp gr ir ly"><a href="https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd jh gy z fp md fr fs me fu fw jf bi translated">2.3.集群-sci kit-了解0.24.1文档</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">未标记数据的聚类可以使用该模块来执行。每种聚类算法都有两种变体:a…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">scikit-learn.org</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ix ly"/></div></div></a></div><p id="d906" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其中一个度量是所谓的<strong class="kx jh"> V-measure(或归一化互信息)得分</strong>。这种方法的一个优点是它可以分解成两个容易可视化的指标。</p><h1 id="ac9a" class="mn mo jg bd mp mq mr ms mt mu mv mw mx km my kn mz kp na kq nb ks nc kt nd ne bi translated">标准化互信息</h1><p id="f9e0" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">这个分数可以解释为另外两个测量值的平均值:<strong class="kx jh">同质性</strong>和<strong class="kx jh">完整性</strong>。</p><h2 id="286d" class="nk mo jg bd mp nl nm dn mt nn no dp mx le np nq mz li nr ns nb lm nt nu nd nv bi translated">同种</h2><p id="6d94" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">同质性衡量一个聚类中样本的相似程度。它是用<a class="ae jd" href="https://en.wikipedia.org/wiki/Entropy_(information_theory)" rel="noopener ugc nofollow" target="_blank">香农熵</a>定义的。</p><figure class="nx ny nz oa gt is gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/138b15714d443e45077765f9374b927d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*R8__2vr80zZq1ZyJ8pwu2A.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">同质性。图片作者。</p></figure><p id="c449" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">给定H(C|K)公式。</p><figure class="nx ny nz oa gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ob"><img src="../Images/7d4ce06d0c878ab6ff8e73146436938f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WC82dikNROiDQmB4M0UPAQ.png"/></div></div></figure><p id="daad" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">很容易理解为什么会这样。如果观察项H(C|K ),它包含n𝒸ₖ / nₖ，其代表在聚类<em class="oc">k</em>t31】中标记为<em class="oc"> c </em>的样本数量<strong class="kx jh">与聚类<em class="oc">k</em>t35】中样本总数<strong class="kx jh">之间的<strong class="kx jh">比率</strong>。</strong></strong></p><p id="6b04" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当聚类<em class="oc">k</em>T3】中的所有<strong class="kx jh">样本都具有<strong class="kx jh">相同标号<em class="oc">c</em>T7】时，<strong class="kx jh">同质性</strong>等于<strong class="kx jh"> 1 </strong>。</strong></strong></p><p id="c7ce" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">注意，在<strong class="kx jh"> c </strong>和<strong class="kx jh"> k </strong>，<strong class="kx jh">上有一个和，哪个是包含特定标签的聚类</strong>并不重要，至少有一个就足够了。这在运行输出与标注无关的无监督方法时非常有用。</p><p id="72cb" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这是一个同构集群的例子。所有三个聚类只包含一种颜色(特征)，换句话说，同一聚类中的所有样本共享它们的标签。</p><figure class="nx ny nz oa gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi od"><img src="../Images/4236eef93a6ea15bd80cf0df76b95c25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jD5KUKJQtNSaGZqpH-ShWw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">同构集群的示例。图片作者。</p></figure><p id="799b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">无论如何，这种情况不是最佳的，因为橙色样本被分成不同的群。在本例中，特征是不完整的。</p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h2 id="ab13" class="nk mo jg bd mp nl nm dn mt nn no dp mx le np nq mz li nr ns nb lm nt nu nd nv bi translated">完全</h2><p id="6fb4" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">尽管完整性度量了聚类算法将多少相似的样本放在一起。</p><figure class="nx ny nz oa gt is gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/90db4523cfd6066fa2cb3cf9adbd9b18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*4FW2mpQuL-3Sk6NAE-heAQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片作者。</p></figure><p id="22a9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">很容易理解为什么会这样。如果观察术语H(K|C ),它包含n𝒸ₖ / n𝒸，其代表在聚类<em class="oc">k</em>T25】中标记为<em class="oc"> c </em>的样本数量<strong class="kx jh">与标记为<em class="oc">c</em>t29】的样本总数<strong class="kx jh">之间的<strong class="kx jh">比率</strong>。</strong></strong></p><p id="3c1c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当所有种类为<em class="oc">c</em>T33】的<strong class="kx jh">样本都被分配到<strong class="kx jh">同一个聚类<em class="oc">k</em>T37】时，<strong class="kx jh">完整性</strong>等于<strong class="kx jh"> 1。</strong></strong></strong></p><p id="3f82" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这是一个完整聚类的例子。每种颜色只存在于一组中。在这种情况下，具有相同属性的所有<strong class="kx jh">点被分类在一起</strong>。请注意，完整并不意味着同质，事实上在每个集群中有多种颜色。</p><figure class="nx ny nz oa gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi od"><img src="../Images/99ec429a9de544a63d405134cdea13fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zTgxaUg2szfkmSFPoofSuQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">完整聚类示例。图片作者。</p></figure></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><p id="ed86" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在我们已经了解了这两个指标，很明显，一个最佳算法将能够获得一个既<strong class="kx jh">同质</strong>又<strong class="kx jh">完全</strong>的分区。在这种情况下，具有特定颜色的所有样本被放在一个聚类中，并且该聚类仅包含它们。如果算法是无监督的，那么很明显，利用这个输出，它已经正确地学习了特征。</p><figure class="nx ny nz oa gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi of"><img src="../Images/2c47789dbc5edfcf9639bcdf4721d25f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7m0cc_DrCeZBDrcuyDwxqg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">最佳聚类的示例。图片作者。</p></figure><p id="2f36" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">否则，最差的聚类可能是<strong class="kx jh">既不是同质的</strong>也不是<strong class="kx jh">完全的</strong>。在这种情况下，每个聚类包含多个标签，并且每个标签被分配给多个聚类。在这种情况下，两个测量值都是<strong class="kx jh">零</strong>。</p><figure class="nx ny nz oa gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi od"><img src="../Images/e3be0393585bb8385708d92081b501a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SyQh7gaG1qwbnrNpllUB4A.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">不良聚类的示例。图片作者。</p></figure><h2 id="b9cb" class="nk mo jg bd mp nl nm dn mt nn no dp mx le np nq mz li nr ns nb lm nt nu nd nv bi translated">标准化互信息</h2><p id="3265" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">最后，为了获得我们的聚类算法的良好性的度量，我们可以考虑在<strong class="kx jh">同质性</strong>和<strong class="kx jh">完备性</strong>之间的<strong class="kx jh">调和平均值</strong>，并且获得<strong class="kx jh"> V度量</strong>或<strong class="kx jh">归一化互信息</strong>(NMI)【1】。</p><figure class="nx ny nz oa gt is gh gi paragraph-image"><div class="gh gi og"><img src="../Images/fc0882021dbc9d2eb49bf23d6aec8edd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*O1Wo5lixbYcAz_QHLVIJXA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">标准化互信息。图片作者。</p></figure><p id="92f5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这个分数是一个介于0-1之间的度量值，它实际上量化了聚类分区的好坏。实际上，它要求<strong class="kx jh">同时最大化</strong>同质性<strong class="kx jh"> h </strong>和完备性<strong class="kx jh"> c </strong>(当h和c都为1时，NMI为1)。此外，如果聚类<strong class="kx jh">不满足两个条件</strong>中的任何一个，NMI将为<strong class="kx jh">零</strong>。</p><p id="c9c1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这种度量有很多，但是由于它在同质性和完备性两个度量中的分解，它的<strong class="kx jh">可解释性</strong>是<strong class="kx jh">清晰</strong>和<strong class="kx jh">直观</strong>。</p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h1 id="5d40" class="mn mo jg bd mp mq oh ms mt mu oi mw mx km oj kn mz kp ok kq nb ks ol kt nd ne bi translated">sklearn</h1><p id="dd57" class="pw-post-body-paragraph kv kw jg kx b ky nf kh la lb ng kk ld le nh lg lh li ni lk ll lm nj lo lp lq ij bi translated">现在，您已经执行了聚类，并希望估计NMI。Sci-kit learn已经实现了<strong class="kx jh"/>,所以估计它真的很容易。</p><div class="ip iq gp gr ir ly"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.v_measure_score.html" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd jh gy z fp md fr fs me fu fw jf bi translated">sk learn . metrics . v _ measure _ score-sci kit-learn 0 . 24 . 1文档</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">给定基本事实的v-测度簇标记。此分数等同于标准化的相互信息分数，带有…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">scikit-learn.org</p></div></div><div class="mh l"><div class="om l mj mk ml mh mm ix ly"/></div></div></a></div><p id="0a94" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里有一个简单的例子。从这个例子中还可以清楚地看出，分数不依赖于标签的名称，正如前面所讨论的，对于每个标签排列都是一样的。</p><pre class="nx ny nz oa gt on oo op oq aw or bi"><span id="0bf3" class="nk mo jg oo b gy os ot l ou ov"><strong class="oo jh">from</strong> <strong class="oo jh">sklearn.metrics.cluster</strong> <strong class="oo jh">import</strong> v_measure_score<br/>&gt;&gt;&gt; v_measure_score([0, 0, 1, 1], [0, 0, 1, 1])<br/>1.0<br/><strong class="oo jh">&gt;&gt;&gt; </strong>v_measure_score([0, 0, 1, 1], [1, 1, 0, 0])<br/>1.0</span></pre></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h1 id="d5fe" class="mn mo jg bd mp mq oh ms mt mu oi mw mx km oj kn mz kp ok kq nb ks ol kt nd ne bi translated">参考</h1><ol class=""><li id="ce86" class="ow ox jg kx b ky nf lb ng le oy li oz lm pa lq pb pc pd pe bi translated">赫希伯格；V-Measure:一种基于条件熵的外部聚类评估。 (2007年)，《欧洲自然语言文学会议录》。</li><li id="778a" class="ow ox jg kx b ky pf lb pg le ph li pi lm pj lq pb pc pd pe bi translated">瓦莱，f；奥塞拉，m；Caselle，m .<a class="ae jd" href="https://www.mdpi.com/2072-6694/12/12/3799" rel="noopener ugc nofollow" target="_blank">TCGA乳腺癌和肺癌转录组数据的主题建模分析</a>。(2020)癌症</li></ol></div></div>    
</body>
</html>