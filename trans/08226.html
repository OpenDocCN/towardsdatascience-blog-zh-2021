<html>
<head>
<title>How to Label Text Classification Training Data — With AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用人工智能标注文本分类训练数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-label-text-classification-training-data-with-ai-11ed11a5e893?source=collection_archive---------23-----------------------#2021-07-28">https://towardsdatascience.com/how-to-label-text-classification-training-data-with-ai-11ed11a5e893?source=collection_archive---------23-----------------------#2021-07-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="131c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><em class="ki">用零射击变压器模型标注你的训练数据。然后，使用标记的数据微调一个小的监督模型</em></h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/b3ab1193d9acb8b0684af9d610493c1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ffD6p32oYcH-bPbBku52Sg.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">作者图片</p></figure><p id="3c55" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">没错！使用我上个月提出的方法，在没有人工标注器的情况下标注文本分类训练数据是可能的。然后，您可以使用标记的数据来训练监督模型。那么，先有什么——“先有鸡还是先有蛋”，或者类似地，“带人工智能标签的训练数据还是监督模型”？但是这个谜题有一个解决方案——那就是零射击模型。</p><p id="03d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">零镜头文本分类模型需要两个输入:文本和一组标签。然后，他们输出每个标签的分数。因此，他们可以将文本分类为任意类别，而无需任何微调。目前，在Hugging Face的模型分发网络上有<a class="ae lv" href="https://huggingface.co/models" rel="noopener ugc nofollow" target="_blank">可用的</a>大型零镜头文本分类转换器模型，只需几行代码就可以实现。</p><p id="4291" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我将首先从较高的层面简要概述该系统，以及我为展示其功能而进行的实验的结果。我已经发表了一篇完整的文章，更深入地涵盖了这两个方面，你可以在我的<a class="ae lv" href="https://www.vennify.ai/generating-training-data-zero-shot/" rel="noopener ugc nofollow" target="_blank">网站</a>上找到，或者发表在<a class="ae lv" rel="noopener" target="_blank" href="/generating-text-classification-training-data-with-zero-shot-transformer-models-e16d390eea3e">走向数据科学</a>上。然后，我将继续讨论如何通过重现我上一篇文章中描述的主要实验来用Python代码实现这个系统。</p><h1 id="5cdc" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">过程</h1><p id="ecbf" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">整个系统非常简单。系统的输入是未标记的文本数据和标签列表。然后，输出是一个小的监督模型，将文本分类到给定的标签中。该过程中的关键组件是一个大型零镜头文本分类模型。该模型从未标记的数据集中获取文本片段，并输出每个标记的分数。具有最高分数的标签被分配给该段。最后，新标记的案例用于微调小型监督模型。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/d70091ae325ef52bcfe2d2c6fa79a630.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/0*A3uYK-TCp-Ov19m1.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">作者图片</p></figure><h1 id="d17b" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">实验总结</h1><p id="67fa" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我做的主要实验显示了有希望的结果。首先，我使用了一个名为<a class="ae lv" href="https://nlp.stanford.edu/sentiment/index.html" rel="noopener ugc nofollow" target="_blank">斯坦福情感树库V2 (SST2*) </a>的二进制文本分类数据集。然后，使用名为“<a class="ae lv" href="https://huggingface.co/facebook/bart-large-mnli" rel="noopener ugc nofollow" target="_blank"> facebook/bart-large-mnli </a>的零镜头文本分类模型对各种数量的训练案例进行标注，对评测案例的准确率为88.19%。接下来，新标记的训练案例用于微调朴素贝叶斯文本分类模型。下面是朴素贝叶斯模型在SST2评估数据集上的精度。经过8000个训练样本，取得了76.03%的准确率。</p><p id="d259" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">【The SST2数据集是 <a class="ae lv" href="https://huggingface.co/datasets/glue" rel="noopener ugc nofollow" target="_blank"> <em class="mu">胶水</em> </a> <em class="mu">数据集的一部分，该数据集属于</em><a class="ae lv" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank"><em class="mu">cc-by-4.0</em></a><em class="mu">许可证</em></p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi mv"><img src="../Images/557563864791277da6c7418af19250d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*--Nib7h-GzE88py9.png"/></div></div></figure><p id="7c95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最终，朴素贝叶斯模型实现了与最流行的零镜头文本分类转换器模型大致相同的准确性，该模型可在Hugging Face的模型分发网络上获得，名为“<a class="ae lv" href="https://huggingface.co/typeform/distilbert-base-uncased-mnli" rel="noopener ugc nofollow" target="_blank">typeform/distilbert-base-un cased-mnli</a>”但是当然，与Transformer模型相比，朴素贝叶斯模型只需要运行所需资源的一小部分。</p><h1 id="0940" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">意义</h1><p id="8a3d" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">实验表明，在没有标记数据的情况下，训练一个小的监督文本分类模型是可能的。因此，通过使用这种方法，可以在没有人工标注器的情况下对训练数据进行标注。然后，带标签的训练数据可以用来微调一个更小的模型，更容易在生产中使用。这为使用监督模型打开了大门，这些模型在过去由于缺乏标记的训练数据而无法训练。</p><h1 id="4eca" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">履行</h1><h2 id="aa2e" class="mw lx it bd ly mx my dn mc mz na dp mg li nb nc mi lm nd ne mk lq nf ng mm nh bi translated">下载零射击模型</h2><p id="bb81" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">首先，我们将使用Hugging Face的Transformers库来加载一个零镜头文本分类Transformer模型。让我们开始安装吧。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="109e" class="mw lx it nj b gy nn no l np nq">pip install transformers</span></pre><p id="3100" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们将为我们想要的模型导入并创建一个管道对象。在这种情况下，我们将执行一个名为“零任务分类”的任务，我们将使用一个名为“facebook/bart-large-mnl”的模型我还包含了自动检测和使用可用GPU的代码。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="e8be" class="mw lx it nj b gy nn no l np nq">from transformers import pipeline <br/>import torch <br/> <br/># Check to see if a GPU is available <br/>device = -1<br/>if torch.cuda.is_available():<br/>    device = torch.cuda.current_device() </span><span id="728c" class="mw lx it nj b gy nr no l np nq">task = "zero-shot-classification" <br/>zero_shot_model = "facebook/bart-large-mnli" <br/>zero_shot_classifier = pipeline(task, zero_shot_model, device=device)</span></pre><h2 id="5bce" class="mw lx it bd ly mx my dn mc mz na dp mg li nb nc mi lm nd ne mk lq nf ng mm nh bi translated">做预测</h2><p id="73ad" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我将简要讨论如何使用零炮模型进行预测。对于这些例子，我们将预测我自己创建的电影评论的情绪。首先，我们需要定义我们将使用什么标签。因此，我们将标签设置为“阳性”和“阴性”记住，在我们的模型开始预测之前，不需要微调。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="0f81" class="mw lx it nj b gy nn no l np nq">labels = ["positive", "negative"] <br/>positive_text = "Wow I loved that movie so much!"</span></pre><p id="f0d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以向分类器提供标签和文本来产生预测。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="819f" class="mw lx it nj b gy nn no l np nq">positive_prediction = zero_shot_classifier(positive_text, labels) print(positive_prediction)</span></pre><p id="e4c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果:{'sequence ':'哇，我太喜欢那部电影了！'，'标签':['正'，'负']，'分数':[0.9640112519264221，0.03598877415060997]} </p><p id="b3a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出是一个有三个键的字典:序列、标签和分数。序列键包含输入的文本。标签键包含按分数顺序排列的标签。最后，scores键包含从最高到最低的分数，其中所有分数的总和等于1。</p><p id="8e62" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以隔离顶部标签，如下所示。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="aa7e" class="mw lx it nj b gy nn no l np nq">positive_result = positive_prediction["labels"][0] print(positive_result)</span></pre><p id="5f64" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mu">结果:阳性</em></p><h2 id="96be" class="mw lx it bd ly mx my dn mc mz na dp mg li nb nc mi lm nd ne mk lq nf ng mm nh bi translated">数据</h2><p id="1438" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">让我们讨论如何收集数据，然后我们可以标记并用于训练一个小的监督模型。为了简单起见，我们将使用ss T2——我在<a class="ae lv" href="https://www.vennify.ai/generating-training-data-zero-shot/" rel="noopener ugc nofollow" target="_blank">过去的文章</a>中描述的实验所用的相同数据集。该数据集可在Hugging Face的数据集分发网络上获得，包含被标记为“正面”或“负面”的电影评论。</p><p id="720c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将从安装拥抱脸的数据集库开始。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="a2a9" class="mw lx it nj b gy nn no l np nq">pip install datasets</span></pre><p id="b15c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们将导入一个名为“load_dataset”的函数顾名思义，它允许我们从拥抱脸的网络中获取数据集。它需要三个输入，数据集的名称、数据实例和分割。在这里，数据集是一个更大的数据集“glue”的子集因此，load_dataset函数的第一个和第二个参数分别是“glue”和“sst2”。然后，对于split参数，我们将指明是否希望下载训练或验证数据以及实例的数量。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="8620" class="mw lx it nj b gy nn no l np nq">from datasets import load_dataset </span><span id="a616" class="mw lx it nj b gy nr no l np nq"># Loading 8000 training cases <br/>train_data = load_dataset('glue', 'sst2', split="train[:8000]")<br/> <br/># Loading all 872 validation cases<br/>eval_data = load_dataset('glue', 'sst2', split="validation[:]")</span></pre><p id="86a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们来探究一下数据。train_data和eval_data对象都属于“Dataset”类型，这是一个可迭代的对象，其中每个事例都包含一个字典。字典包含三个关键字:句子、标签和idx。句子关键字包含特定案例的文本。然后，标签键指示格是“正”还是“负”，其中整数“1”指示格是正的，而“0”指示格是负的。最后，在idx键下，每个都包含自己唯一的整数值。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="4b4e" class="mw lx it nj b gy nn no l np nq">for i in range(0, 2):<br/>    print(eval_data[i]) <br/>    print(eval_data[i]["label"]) <br/>    print("-------------")</span></pre><p id="4303" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">{ '句子':“这是一次迷人的、常常令人感动的旅程。"，' label': 1，' idx': 0}</p><p id="77b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi">1</p><p id="5467" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi">— — — — — — -</p><p id="0872" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">{ '句子':'不屈不挠的凄凉和绝望'，'标签':0，' idx': 1}</p><p id="abb4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi">0</p><p id="65dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi">— — — — — — -</p><h1 id="4d56" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">标记和格式化数据</h1><p id="53b4" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们可以为训练数据生成自己的标签，而不需要使用零镜头模型的人工注释器。下面的代码迭代训练案例，对于每一个案例，它都使用零命中率模型来生成预测。结果保存在元组列表中，其中每个元组的第一个索引包含案例的文本数据，第二个索引包含字符串形式的标签。这种格式与我们即将训练的TextBlob朴素贝叶斯分类器所需的格式相匹配。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="d6b3" class="mw lx it nj b gy nn no l np nq">train_cases =[] <br/>labels = ["positive", "negative"] <br/>for case in train_data: <br/>    result = zero_shot_classifier(case['sentence'], labels) <br/>    label = result["labels"][0] <br/>    result = (case['sentence'], label) <br/>    train_cases.append(result)</span></pre><p id="41d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我建议你用一个叫tqdm的Python包给循环添加一个进度条。只需对上面的代码做一些小的修改，就可以实现这一点。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="637e" class="mw lx it nj b gy nn no l np nq"># In terminal<br/>pip install tqdm</span><span id="a3c5" class="mw lx it nj b gy nr no l np nq"># Python code start<br/>from tqdm import tqdm</span><span id="f619" class="mw lx it nj b gy nr no l np nq">train_cases =[] <br/>labels = ["positive", "negative"] <br/>for case in tqdm(train_data): <br/>    result = zero_shot_classifier(case['sentence'], labels) <br/>    label = result["labels"][0] <br/>    result = (case['sentence'], label) <br/>    train_cases.append(result)</span></pre><p id="8d07" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">仅此而已，我们只是用了一个AI模型来标注我们的数据！我们使用的零炮模型对同一数据集的评估数据的准确率为88.19%，因此尽管不完美，但该训练仍可用于训练监督模型。</p><p id="647f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们将评估数据转换成适当的格式。我们将使用实际的标签，因为这样可以更好地表明最终模型的准确性。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="d06a" class="mw lx it nj b gy nn no l np nq">eval_cases = [] <br/>for case in tqdm(eval_data): <br/>    label = "positive" if case["label"] else "negative" <br/>    result = (case['sentence'], label) <br/>    eval_cases.append(result)</span></pre><h1 id="abc8" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">训练朴素贝叶斯分类器</h1><p id="d2e9" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">现在让我们使用TextBlob创建一个朴素贝叶斯分类器。这种分类器使用“传统的”NLP技术，并依靠概率进行预测。它比变压器模型等深度学习方法需要的资源少得多。我们可以使用名为TextBlob的Python包轻松创建一个朴素贝叶斯分类器。TextBlob构建在著名的Python包NLTK之上，使其更易于使用，在GitHub上获得了7000多颗星的好评，下载量超过1000万次。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="69de" class="mw lx it nj b gy nn no l np nq">pip install textblob</span></pre><p id="87b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以从textblob包中导入一个名为NaiveBayesClassifier的类，如下所示。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="4d6a" class="mw lx it nj b gy nn no l np nq">from textblob.classifiers import NaiveBayesClassifier</span></pre><p id="adf1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，在我们开始训练分类器之前，我们需要从NLTK下载一个名为“punkt”的标记器。记住，TextBlob是建立在NLTK之上的，所以有时候，我们在使用TextBlob的时候，必须从NLTK下载特定的资源。另外，当安装TextBlob时，NLTK也会被安装，所以不需要pip安装NLTK。让我们导入NLTK，下载punkt。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="c2c9" class="mw lx it nj b gy nn no l np nq">import nltk <br/>nltk.download('punkt')</span></pre><p id="2925" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从这里开始，我们可以用一行代码创建和训练一个分类器，如下所示。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="2b31" class="mw lx it nj b gy nn no l np nq">classifier = NaiveBayesClassifier(training_cases)</span></pre><p id="eafc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就是这样！我们现在已经成功地训练了一个朴素贝叶斯分类器，而没有任何先前的标记数据！</p><h2 id="8d4e" class="mw lx it bd ly mx my dn mc mz na dp mg li nb nc mi lm nd ne mk lq nf ng mm nh bi translated">评价</h2><p id="e9d4" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们现在可以用如下所示的一行代码来评估模型，以确定它在评估集上的准确性。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="0753" class="mw lx it nj b gy nn no l np nq">accuracy = classifier.accuracy(eval_cases) <br/>print(accuracy)</span></pre><p id="b433" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mu">结果:0.7603211009174312 </em></p><p id="a35c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就这样，我们的模型有76%的准确率！</p><h2 id="bf68" class="mw lx it bd ly mx my dn mc mz na dp mg li nb nc mi lm nd ne mk lq nf ng mm nh bi translated">分类</h2><p id="73bc" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">让我们讨论如何使用朴素贝叶斯分类器进行预测。下面的代码检索任意文本的顶部标签。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="5e65" class="mw lx it nj b gy nn no l np nq">prob_dist = classifier.prob_classify("I loved this movie") print(prob_dist.max())</span></pre><p id="5038" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mu">结果:阳性</em></p><p id="152a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们也可以得到任何标签的分数。分数介于0和1之间，其中1具有高确定性，0具有低确定性。所有分数的总和为1。</p><pre class="kk kl km kn gt ni nj nk nl aw nm bi"><span id="b71e" class="mw lx it nj b gy nn no l np nq">print(prob_dist.prob("positive"))</span></pre><p id="cd12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mu">结果:0.907443066804341</em></p><h1 id="eafa" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结论</h1><p id="1ffc" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我希望你在将来的应用中继续使用这个建议的方法。通过使用这种建议的方法，您可以绕过使用人工注释器来标记数据——这将节省您的时间和潜在的金钱。</p><h1 id="8825" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">有用的链接</h1><p id="fc55" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><a class="ae lv" href="https://www.vennify.ai/generating-training-data-zero-shot/" rel="noopener ugc nofollow" target="_blank">上一篇文章</a>更侧重于过程、实验和后续步骤。</p><p id="7411" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae lv" href="https://www.youtube.com/channel/UC7-EWrr8YdcQgPPk76OiUVw?sub_confirmation=1" rel="noopener ugc nofollow" target="_blank">订阅</a>我的YouTube频道，了解关于本文所述过程的最新内容。</p><p id="7aeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae lv" href="https://colab.research.google.com/drive/1zJnd9iu8KlVplRj1utZs90K7OM5NhakY?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab: </a>包含了本文中使用的代码。</p><p id="4092" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mu">原载于2021年7月28日</em><a class="ae lv" href="https://www.vennify.ai/label-training-data-with-ai/" rel="noopener ugc nofollow" target="_blank"><em class="mu">https://www . vennify . ai</em></a><em class="mu">。</em></p></div></div>    
</body>
</html>