<html>
<head>
<title>Predicting Fake News using NLP and Machine Learning | Scikit-Learn | GloVe | Keras | LSTM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用自然语言处理和机器学习预测假新闻| Scikit-Learn | GloVe | Keras | LSTM</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-fake-news-using-nlp-and-machine-learning-scikit-learn-glove-keras-lstm-7bbd557c3443?source=collection_archive---------5-----------------------#2021-05-02">https://towardsdatascience.com/predicting-fake-news-using-nlp-and-machine-learning-scikit-learn-glove-keras-lstm-7bbd557c3443?source=collection_archive---------5-----------------------#2021-05-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="905f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在Kaggle的假新闻数据集上使用Python应用传统机器学习和深度学习技术的简单指南。它也简要地包括文章的正文和文体分析。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/fbb9cdfc389d7dc308019a44e9cedc25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iaM3-vZSDozVRGhN"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">马库斯·温克勒在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="00b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假新闻数据集是<a class="ae ky" href="https://www.kaggle.com/c/fake-news/data" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上可用的经典文本分析数据集之一。它由不同作者的真假文章标题和正文组成。在这篇文章中，我使用传统的机器学习方法和深度学习走过了整个文本分类过程。</p><h1 id="0d04" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">入门</strong></h1><p id="b165" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我开始在Google Colab上从Kaggle下载数据集。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="3c01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我读取数据帧并检查其中的空值。在总共20800行中，text articles有7个空值，title有122个空值，author有503个空值，我决定删除这些行。对于测试数据，我用空白填充。</p><div class="kj kk kl km gt ab cb"><figure class="mu kn mv mw mx my mz paragraph-image"><img src="../Images/a3542eedba06f1c157a6b05faf8b134f.png" data-original-src="https://miro.medium.com/v2/resize:fit:372/format:webp/1*J72J5vakwiunUCdxpCRDGw.png"/></figure><figure class="mu kn na mw mx my mz paragraph-image"><img src="../Images/dbeb7f9d9ebea7da8b9eefe958023fb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:394/format:webp/1*XR4GelWIFCrWdM8RPiv9mQ.png"/><p class="ku kv gj gh gi kw kx bd b be z dk nb di nc nd translated">训练数据和测试数据中的空值数量</p></figure></div><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="54a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，我还检查“假”和“真”新闻在数据集中的分布。通常，我在导入matplotlib时为笔记本上的所有绘图设置rcParams。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><div class="kj kk kl km gt ab cb"><figure class="mu kn ne mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/0ff5f3897bad090f00f95d73d265517b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*yrf1YeSB0GoMgtCpTZEIQA.png"/></div></figure><figure class="mu kn nf mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/173f3779ad826d4c6c96aee09af8fcdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*r4E3zKxx-ZfViC7VltoaeQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk ng di nh nd translated">0是真正的新闻，而1是假新闻</p></figure></div><p id="a0ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">真假新闻的比例从1:1到4:5。</p><p id="63f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我决定看看下面的文章长度—</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/c391a0f8e2347723bd32e6244eeaf4ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ULy93Vyny_fUWA0eQMPBHQ.png"/></div></div></figure><p id="8d9c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以看出，假文章的中值长度较低，但也有大量异常值。两者的长度都为零。</p><p id="c8ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以看出，它们从0开始，这是令人关注的。我用的时候其实是从1开始的。描述()以查看数字。于是我看了一下这些文字，发现都是空白的。对此，显而易见的答案是条带和液滴长度为零。我检查了零长度文本的总数是74。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="0625" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我决定重新开始。因此，我会用一个空格填充所有的nan，然后去掉它们，然后删除零长度的文本，这样就可以开始预处理了。下面是处理缺失值的新代码。数据的最终形状是(20684，6)，即包含20684行，只比20800少116行。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/123d5ffa52fc00bc3b9c3c08ccde80fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oFJBkhXY6AfJlzgsGWfTHw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">目标变量的分布形状是均匀的，这有利于模型训练。</p></figure><p id="a756" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此后，出现了更多个位数长度或低至10的文本。它们看起来更像评论，而不是正式的文本。我会暂时保留它们，然后进入下一步。</p><h1 id="2a4d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">文本预处理</h1><p id="6cc7" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">因此，在我开始进行文本预处理之前，我实际上查看了拥有假冒和正版文章的作者的重叠数量。换句话说，拥有作者的信息会有任何帮助吗？我发现有3838个作者，其中2225个是真实的，1618个是假新闻的作者。其中有5位作者是真假新闻的作者。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="ae11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了开始预处理，我最初选择了通过空白和扩展收缩直接分割。然而，由于一些(我想是斯拉夫语)其他语言的文本，这已经产生了错误。因此，在第一步中，我使用regex只保留拉丁字符、数字和空格。然后，展开缩写，然后转换成小写。这是因为缩写如<strong class="lb iu">I have</strong>转化为<strong class="lb iu"> I have </strong>。因此，向小写字母的转换发生在扩张收缩之后。完整代码如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="1c5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦完成，常规单词标记化就完成了，随后是停用词移除。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><h1 id="e73c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">文本分析</h1><p id="3c35" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">既然数据已经准备好了，我打算使用wordcloud查看常用词。为了做到这一点，我首先将所有标记化的文本连接到单独列中的字符串中，因为它们将在稍后的模型训练中使用。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="a315" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，为每个标签创建一个包含所有文本的字符串，并创建如下的单词云:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><div class="kj kk kl km gt ab cb"><figure class="mu kn nk mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/63f55e07a6c48e99453340e537288de4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*s_qOcpsvAlzXg9MrxJOWVA.png"/></div></figure><figure class="mu kn nk mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/15867678b87c266af7dd90536f838a84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Nruq4B__ZtVPoIHwHVQ-lg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk nl di nm nd translated">第一个wordcloud是真新闻，第二个是假新闻。</p></figure></div><p id="3482" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在假新闻词云中，一些词的出现频率明显高于其他词。在“真实新闻”的文字云上，有不同字体大小的混合。相反，在假新闻数据集中，较小的文本在背景中，一些词使用得更频繁。假新闻词云中的中等大小的词越来越少，或者换句话说，出现频率逐渐减少，这是一种脱节。频率不是高就是低。</p><h1 id="d2d4" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">风格分析</h1><p id="80a0" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">风格计量分析通常被称为对作者风格的分析。我将研究一些风格学特性，比如每篇文章的句子数量、文章中每句话的平均字数、每篇文章的平均字数以及词性标签数。</p><h2 id="9e57" class="nn lw it bd lx no np dn mb nq nr dp mf li ns nt mh lm nu nv mj lq nw nx ml ny bi translated"><strong class="ak">每篇文章的句子数量</strong></h2><p id="be23" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">为了得到这个，我需要原始数据集，因为我在train_df中丢失了句子信息。因此，我在orginal _ train _ df中保存了一份实际数据的副本，用于将句子转换为序列。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="5120" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我查看了每个目标类别的句子数量，如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/1cf442bce14f405fc4554457da31a426.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*AzjCvMADZmt2joUjJjTksQ.png"/></div></figure><p id="557e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显然，虚假文章有很多异常值，但75%的虚假文章的句子数量低于50%的真实新闻文章。</p><h1 id="256c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">文章中每句话的平均字数</h1><p id="c39f" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在这里，我统计了每篇文章每句话的总字数，并返回平均值。然后我在箱线图上画出了这些数字，使它们可视化。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/ef3e0ce6251e81878c4344b72fb75139.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*CWohrune77kOElWILpz_-Q.png"/></div></figure><p id="a65e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以看到，平均来说，假文章比真文章更罗嗦。</p><h2 id="84c0" class="nn lw it bd lx no np dn mb nq nr dp mf li ns nt mh lm nu nv mj lq nw nx ml ny bi translated">每篇文章的平均字数</h2><p id="eb14" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这是一篇文章的平均字数。在方框图中，很明显，假文章中的平均单词长度更高。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/c324d21e7fb18a766c33df05eaf6fd05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*OKXaX9yohJulnUiv0WPJwg.png"/></div></figure><h2 id="5abd" class="nn lw it bd lx no np dn mb nq nr dp mf li ns nt mh lm nu nv mj lq nw nx ml ny bi translated">POS标签计数</h2><p id="5f56" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">接下来，我试着看了伪作vs正版文章中的词性(POS)组合。在遍历每篇文章时，我只将单词的词性存储到一个列表中，将相应的词性计数放在一个数据帧中，并使用一个条形图来显示假货和新闻文章中词性标签的百分比组合。两篇文章中的名词都高得多。总的来说，除了假新闻中动词过去式的比例是真实新闻的一半之外，没有明显的规律。除此之外，所有其他POS类型在假货和真品方面几乎相等。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/0532b323bd8020705a7a829bdaca0a5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*TcBjmUIaMOmG6d7vPCP0IQ.png"/></div></figure><h1 id="54e8" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">使用机器学习的文本分类</h1><h2 id="25e8" class="nn lw it bd lx no np dn mb nq nr dp mf li ns nt mh lm nu nv mj lq nw nx ml ny bi translated">Tf-idf和计数矢量器</h2><p id="594f" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">一旦分析完成，我首先采用传统的方法使用计数矢量器和术语频率-逆文档频率或Tf-idf。代码中配置的计数矢量器也生成二元模型。使用<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html" rel="noopener ugc nofollow" target="_blank"> CountVectorizer </a>()以矩阵的形式获得它们出现的次数，然后将这个字数矩阵转换成归一化的词频(tf-idf)表示。这里，我使用了smooth=False，以避免零除法误差。通过提供smooth=False，我基本上是在文档频率上加1，因为它是idf计算公式中的分母，如下所示</p><pre class="kj kk kl km gt od oe of og aw oh bi"><span id="fb90" class="nn lw it oe b gy oi oj l ok ol"><strong class="oe iu">idf(t) = log [ n / (df(t) + 1) ]</strong></span></pre><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><h2 id="6e6a" class="nn lw it bd lx no np dn mb nq nr dp mf li ns nt mh lm nu nv mj lq nw nx ml ny bi translated">使用默认配置进行基准测试</h2><p id="7433" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">接下来，我打算用默认配置来训练模型，并挑选出性能最好的模型稍后进行调优。为此，我遍历了一个列表，并将所有性能指标保存到另一个数据帧中，并将模型保存到一个列表中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="bf02" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我使用了逻辑回归、多项式朴素贝叶斯、决策树、随机森林、梯度增强和Ada增强分类器。多项式b的精确度是所有方法中最好的，但是f1的分数由于召回分数低而不稳定。事实上，召回率最差，为68%。结果中最好的模型是Logistic回归和AdaBoost，它们的结果是相似的。我选择用逻辑回归来节省训练时间。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/75223581fda0dc8c15e83c4e3d679a57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zkrdcVCs0X28yk-2nmQ24A.png"/></div></div></figure><h2 id="4f6a" class="nn lw it bd lx no np dn mb nq nr dp mf li ns nt mh lm nu nv mj lq nw nx ml ny bi translated">用于调整逻辑回归分类器的GridSearchCV</h2><p id="ff78" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">所以，是时候调整我选择的分类器了。我开始使用更大范围的max_iter和c。然后使用cv=r的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" rel="noopener ugc nofollow" target="_blank">gridsearchcv</a>，即交叉验证的5倍，因为标签分布是公平分布的。我已经使用f1-score进行评分，并使用refit返回f1-score最好的训练模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="07d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">得到的最佳模型的准确率为97.62%，f1值为97.60%。对于这两者，我们都实现了4%的改进。现在，我注意到max_iter的最佳值是100，这是范围的下限，对于C，它也是100，但这是范围的上限。因此，为了适应参数搜索，我使用了max_iter = 50，70，100和C = 75，100，125。在max_iter=100和C=125的情况下有微小的改进。因此，我决定保持不变，并将C的参数搜索从120扩大到150，步长为10。本次运行的所有性能指标与起始网格的结果相同。然而，这次运行的C=140的值。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="882a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后一次，我在max_iter=100和C = [100，125，140]上运行网格搜索，其中C具有所有运行中的最佳参数。最好的一个是max_iter=100，C=140，我最终保存为最佳模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/2ee1e00999fe93827ce5efb7e2da6e1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*onKGbjtlKHQ1vmEQlaDpAA.png"/></div></div></figure><p id="739b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于GradientBoost和AdaBoost分类器的性能也很好，因此未来可能的工作之一是用它们进行测试。在某些情况下，调优后的性能可能会好得多，但考虑到时间，我会在这里得出结论，因为逻辑回归是max_iter=100和C=140的最佳性能模型。</p><p id="aaf9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我终于把结果上传到Kaggle上了。这个挑战已经进行了3年，但是我对测试这个模型的测试数据的分数很感兴趣。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/46a7fe4270fcbf0331798a055777b9c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8MlxPrsSmiszPmqGKCp0Sw.png"/></div></div></figure><h1 id="6427" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">使用手套和LSTM的文本分类</h1><h2 id="250b" class="nn lw it bd lx no np dn mb nq nr dp mf li ns nt mh lm nu nv mj lq nw nx ml ny bi translated">数据准备</h2><p id="fc49" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">为了使用深度学习技术，文本数据必须以原始格式重新加载，因为嵌入会略有不同。在下面的代码中，我处理了缺少的值，并将文章的标题和作者附加到文章的正文中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="c80e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我使用Keras API的<a class="ae ky" href="https://keras.io/api/preprocessing/text/#tokenizer" rel="noopener ugc nofollow" target="_blank">标记器</a>类对文本进行标记，并使用oov_token = " &lt; OOV &gt;"替换词汇外标记，这实际上创建了一个基于词频的词汇索引。然后，我在文本上安装标记器，并使用通过安装标记器创建的词汇索引将它们转换成整数序列。最后，由于序列可能有不同的长度，我使用padding _ sequences在末尾使用padding=post填充零。因此，根据代码，每个序列的长度预计为40。最后，我将它们分成了训练集和测试集。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><h2 id="8cc6" class="nn lw it bd lx no np dn mb nq nr dp mf li ns nt mh lm nu nv mj lq nw nx ml ny bi translated">二元分类模型</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/c8480ad3d4e0f826e07142fc70ae4c6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6u3Yy0d7-nf12I4UQqdsyw.png"/></div></div></figure><p id="b9dc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了创建用于文本分类的模型，我从最简单形式的二进制分类模型结构开始，其中第一层是<a class="ae ky" href="https://keras.io/api/layers/core_layers/embedding/" rel="noopener ugc nofollow" target="_blank">嵌入</a>层，期望嵌入6000个vocab大小的文本(在vocab_size中指定)，每个长度为40的序列(因此，input_length=max_length ),并为每个输入序列给出10维的40个向量的输出。接下来，我使用<a class="ae ky" href="https://keras.io/api/layers/reshaping_layers/flatten/" rel="noopener ugc nofollow" target="_blank">展平</a>图层将形状(40，10)的矩阵展平成一个形状(400)的数组。然后，这个数组通过一个<a class="ae ky" href="https://keras.io/api/layers/core_layers/dense/" rel="noopener ugc nofollow" target="_blank">密集</a>层产生一维输出，并使用sigmoid激活函数产生二进制分类。我最初想用这个模型做更多的实验，所以为它创建了一个函数，我也喜欢把层组合成一个函数作为练习。这项工作并不真正需要它。最后，我使用precision和recall来编译模型，以便在训练和验证时进行监控。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="ae76" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我还使用了早期停止来节省时间，patience=15表示如果在过去的15个时期中模型没有改进就停止，使用模型检查点来存储最好的模型，save_best_only=True。增加了模式=分钟，因为我在这里监测损失。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="2698" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在是适合模型的时候了！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="b84a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我使用了精度和召回率以及损失，所以我也可以在这里跟踪精度和召回率值。如下图所示，验证损失在第6个时期最低，然后损失停滞或增加。因此，最佳模型在训练的第6个时期后被保存。很明显，随着训练损失的改善，模型是如何过度拟合的，而验证损失在第6代之后增加。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/6c17037a523a74951d669b61b6ca9c50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*-wyUZCZoyInEUVjHlYyNFw.png"/></div></figure><div class="kj kk kl km gt ab cb"><figure class="mu kn nk mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/61ef0f24d828da1abcaad099b664c50a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*QbbZuXzau4YAmLBLbCBAlw.png"/></div></figure><figure class="mu kn nk mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/47593b6a23590124eeac23a18a87fe7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*G7Ead0TF8qoVK9d6UoMp_A.png"/></div></figure></div><p id="ae7d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是我用来绘制训练和验证损失、精度和召回的代码。我在range函数中用了max(history.epoch) + 2，因为history.epoch从0开始。因此，对于20个时期，最大值将是19，范围将为max(history.epoch)生成从1到18的列表。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="822c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型的准确度值为96.6%，f1值为96.6%。我还在Kaggle测试数据上测试了这个模型的性能，它还不错，但不比我之前训练的逻辑回归好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/fd1a4ce839544917e78bafb6ad6a6090.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n2Hsv_qRYfpjfuyb-BcmNA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk">.</p></figure><h2 id="9f18" class="nn lw it bd lx no np dn mb nq nr dp mf li ns nt mh lm nu nv mj lq nw nx ml ny bi translated">LSTM</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/5938b59d18f10c37bcf50e9b47dfa834.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DRrFUThtCXVlB_cs-MxJ-A.png"/></div></div></figure><p id="422b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">唷！现在让我们用LSTM模型来拟合文本数据。第一层和最后一层是相同的，因为输入和输出是相同的。在这两者之间，我使用了一个<a class="ae ky" href="https://keras.io/api/layers/regularization_layers/dropout/" rel="noopener ugc nofollow" target="_blank">辍学</a>层过滤掉30%的单位，然后去<a class="ae ky" href="https://keras.io/api/layers/recurrent_layers/lstm/" rel="noopener ugc nofollow" target="_blank"> LSTM </a>层的100个单位。长短期记忆(LSTM)，是一种特殊的RNN，能够学习长期依赖。他们的特长在于记忆信息的时间更长。在使用LSTM后，我使用了另一个脱落层，然后是一个具有64个隐藏单元的全连接层，然后是另一个脱落层，最后是另一个具有“Sigmoid”激活函数的一个单元的全连接层，用于二进制分类。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="70f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完成后，我按照上一节中概述的相同过程编译、使用回调并拟合模型。我提供的纪元数量是20。但是在这种情况下，模型只训练了16个时期，因为在第一个时期之后的15次连续迭代中，验证损失没有改善。从下面的图中也可以清楚地看到。由于过度拟合，验证损失一直在增加，而训练损失却在下降。回想一下回调设置，我对模型进行了编码，以在停止之前连续15个时期等待验证损失的改善。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/ce7eb105c733d940d805713e97e0527d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*1K9qJKD4xhA8_e2oiwImoA.png"/></div></figure><p id="0882" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型没有显著的改进，尽管该模型有可能改进。其准确率为96.1%，f1评分为96.14%。</p><h2 id="e826" class="nn lw it bd lx no np dn mb nq nr dp mf li ns nt mh lm nu nv mj lq nw nx ml ny bi translated">使用预先训练的单词嵌入—手套</h2><p id="b762" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在，我们也可以使用预先训练的单词嵌入，比如GloVe。GloVe是一种无监督学习算法，用于获取单词的矢量表示。在来自语料库的聚集的全局单词-单词共现统计上执行训练，并且所得的表示展示了单词向量空间的有趣的线性子结构。[ <a class="ae ky" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank"> 4 </a></p><p id="53d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我使用的是一个在60亿个词汇上训练过的，词汇有40万个，用300维向量格式表示。</p><p id="edb4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下面的代码中，我有一个在Google Colab上加载GloVe的代码，因为我在Colab上做了部分工作。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="3a66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我概述了如何从本地加载文件。从<a class="ae ky" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank">这里</a>下载嵌入这个词。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="f62a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们的目标是在手套嵌入中找到假新闻数据中的标记，并获得相应的权重。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><h2 id="9541" class="nn lw it bd lx no np dn mb nq nr dp mf li ns nt mh lm nu nv mj lq nw nx ml ny bi translated">带手套的简单模型</h2><p id="d900" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在，我已经为我们的训练数据嵌入了手套，我使用了output_dim=300的<a class="ae ky" href="https://keras.io/api/layers/core_layers/embedding/" rel="noopener ugc nofollow" target="_blank">嵌入</a>层，这是手套向量表示形状。此外，我使用了trainable = False，因为我使用的是预训练的权重，所以我不应该在训练时更新它们。它们与其他单词有关系，所以最好不要打扰它们。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="3681" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，使用与我之前使用的相同的过程，我用50个纪元来训练模型。然而，由于在第3个时期之后没有改善，该模型在第18个时期之后停止训练。得分低于前两款。准确率和f1值都在93%左右。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/76a530817fee2abe2312b293fb33e090.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*kMpB_DtncWSiRa4T52Rk_g.png"/></div></figure><h2 id="5c11" class="nn lw it bd lx no np dn mb nq nr dp mf li ns nt mh lm nu nv mj lq nw nx ml ny bi translated">LSTM手套</h2><p id="eaa4" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">和..最后，我使用手套嵌入来训练我之前使用的LSTM模型，以获得更好的结果。完整的代码如下-</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="18dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，我使用了50个历元，模型在第三个历元后没有改进。因此，训练过程在第18个纪元后停止。准确率和f1值都提高到96.5%，接近第一个Keras模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/a681eedcd92a25fe85c72bada6253d6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*StJHb1KJjyF9iR1iGYwXNA.png"/></div></figure><p id="3d0f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，我试着用Kaggle的测试数据来预测这个模型，这是我的结果</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/02ceca1df9370af3c38f82abfd3ab05d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZTQQLZ3g3d10iwlNdKPOnQ.png"/></div></div></figure><h1 id="eadf" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="8a12" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在本练习中，最佳模型是优化的逻辑回归模型。这个用例还有很多需要进一步改进的地方，特别是设计更好的深度学习模型。此外，出于时间的考虑，我没有调整随机森林和AdaBoost分类器，这可能会导致比逻辑回归更好的性能。</p><h1 id="6bec" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">参考</h1><ol class=""><li id="7e45" class="ou ov it lb b lc mn lf mo li ow lm ox lq oy lu oz pa pb pc bi translated"><a class="ae ky" href="https://faroit.com/keras-docs/1.0.1/getting-started/sequential-model-guide/" rel="noopener ugc nofollow" target="_blank">https://faroit . com/keras-docs/1 . 0 . 1/入门/sequential-model-guide/ </a></li><li id="c6f7" class="ou ov it lb b lc pd lf pe li pf lm pg lq ph lu oz pa pb pc bi translated">【https://colah.github.io/posts/2015-08-Understanding-LSTMs/ T4】</li><li id="1098" class="ou ov it lb b lc pd lf pe li pf lm pg lq ph lu oz pa pb pc bi translated"><a class="ae ky" href="https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/use-word-embedding-layers-deep-learning-keras/</a></li><li id="60d4" class="ou ov it lb b lc pd lf pe li pf lm pg lq ph lu oz pa pb pc bi translated"><a class="ae ky" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank">https://nlp.stanford.edu/projects/glove/</a></li></ol></div><div class="ab cl pi pj hx pk" role="separator"><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn"/></div><div class="im in io ip iq"><h2 id="6dca" class="nn lw it bd lx no np dn mb nq nr dp mf li ns nt mh lm nu nv mj lq nw nx ml ny bi translated"><a class="ae ky" href="https://github.com/royn5618/Medium_Blog_Codes/tree/master/Fake_News" rel="noopener ugc nofollow" target="_blank">完整代码在这里。</a></h2></div><div class="ab cl pi pj hx pk" role="separator"><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn"/></div><div class="im in io ip iq"><p id="a6f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="pp">感谢光临！</em></p><p id="7aba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">我的链接:</strong> <a class="ae ky" href="https://medium.com/@nroy0110" rel="noopener">中</a>|<a class="ae ky" href="https://www.linkedin.com/in/nabanita-roy/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>|<a class="ae ky" href="https://github.com/royn5618" rel="noopener ugc nofollow" target="_blank">GitHub</a></p></div></div>    
</body>
</html>