<html>
<head>
<title>Introduction to Regression in Python with PyCaret</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 PyCaret 介绍 Python 中的回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-regression-in-python-with-pycaret-d6150b540fc4?source=collection_archive---------0-----------------------#2021-12-12">https://towardsdatascience.com/introduction-to-regression-in-python-with-pycaret-d6150b540fc4?source=collection_archive---------0-----------------------#2021-12-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/f067f70a95a066c42a58806149593b08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*R6GgsWB2wB2d78Rr"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">卢克·切瑟在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="a2ba" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">1.介绍</h1><p id="76d3" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><a class="ae kc" href="https://www.pycaret.org/" rel="noopener ugc nofollow" target="_blank"> PyCaret </a>是一个用 Python 编写的开源、低代码的机器学习库，可以自动化机器学习工作流。这是一个端到端的机器学习和模型管理工具，可以成倍地加快实验周期，提高您的工作效率。</p><p id="8260" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">与其他开源机器学习库相比，PyCaret 是一个替代的低代码库，可以用来用几行代码替换数百行代码。这使得实验快速有效。PyCaret 本质上是几个机器学习库和框架的 Python 包装器，比如 scikit-learn、XGBoost、LightGBM、CatBoost、spaCy、Optuna、Hyperopt、Ray 等等。</p><p id="44ef" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">PyCaret 的设计和简单性受到了公民数据科学家这一新兴角色的启发，这是 Gartner 首先使用的术语。公民数据科学家是超级用户，他们可以执行简单和中等复杂的分析任务，这些任务在以前需要更多的技术专业知识。</p><p id="d067" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">想了解更多关于 PyCaret 的信息，可以查看官方<a class="ae kc" href="https://www.pycaret.org/" rel="noopener ugc nofollow" target="_blank">网站</a>或者<a class="ae kc" href="https://www.github.com/pycaret/pycaret" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。</p><h1 id="a878" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">2.教程目标</h1><p id="f239" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在本教程中，我们将学习:</p><ul class=""><li id="6f3d" class="me mf iq ld b le lz li ma lm mg lq mh lu mi ly mj mk ml mm bi translated"><strong class="ld ir">获取数据:</strong>如何从 PyCaret 资源库导入数据。</li><li id="4198" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">设置环境:</strong>如何在 PyCaret 中设置回归实验，开始构建回归模型。</li><li id="1c18" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">创建模型:</strong>如何创建模型、执行交叉验证和评估回归指标。</li><li id="0e33" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">调整模型:</strong>如何自动调整回归模型的超参数。</li><li id="d27c" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">图模型:</strong>如何使用各种图分析模型性能。</li><li id="f8e2" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">预测模型:</strong>如何对新的/看不见的数据进行预测。</li><li id="ebb1" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">保存/加载模型:</strong>如何保存/加载模型以备将来使用。</li></ul><h1 id="e64d" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">3.正在安装 PyCaret</h1><p id="39b3" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">安装很容易，只需几分钟。PyCaret 从 pip 的默认安装只安装在<a class="ae kc" href="https://github.com/pycaret/pycaret/blob/master/requirements.txt" rel="noopener ugc nofollow" target="_blank"> requirements.txt </a>文件中列出的硬依赖项。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="dfd6" class="nb ke iq mx b gy nc nd l ne nf">pip install pycaret</span></pre><p id="a7d5" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">要安装完整版:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="63b2" class="nb ke iq mx b gy nc nd l ne nf">pip install pycaret[full]</span></pre><h1 id="034f" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">4.什么是回归？</h1><p id="63e2" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">回归分析是一组统计过程，用于估计因变量(通常称为“结果变量”或“目标变量”)与一个或多个自变量(通常称为“特征变量”、“预测变量”或“协变量”)之间的关系。机器学习中回归的目标是预测连续值，如销售额、数量、温度等。</p><p id="a4d5" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><a class="ae kc" href="https://hbr.org/2015/11/a-refresher-on-regression-analysis" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir">了解更多回归</strong> </a></p><h1 id="3d36" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">5.PyCaret 中的回归模块概述</h1><p id="9c57" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><a class="ae kc" href="https://pycaret.readthedocs.io/en/latest/api/regression.html" rel="noopener ugc nofollow" target="_blank"> PyCaret 的回归模块</a> ( <code class="fe ng nh ni mx b">pycaret.regression</code>)是一个受监督的机器学习模块，用于使用各种技术和算法预测连续值/结果。回归可用于预测值/结果，如销售额、售出单位、温度或任何连续的数字。</p><p id="4506" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">PyCaret 的回归模块有超过 25 个算法和 10 个图来分析模型的性能。无论是超参数调整、集成，还是堆叠等高级技术，PyCaret 的回归模块都具备。</p><h1 id="6a05" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">6.教程的数据集</h1><p id="86b5" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在本教程中，我们将使用 PyCaret 的数据集存储库中的数据集。该数据包含 6000 条用于训练的记录。每列的简短描述如下:</p><ul class=""><li id="1a27" class="me mf iq ld b le lz li ma lm mg lq mh lu mi ly mj mk ml mm bi translated"><strong class="ld ir"> ID: </strong>唯一标识每个观察(菱形)</li><li id="8946" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">克拉重量:</strong>钻石的重量，单位为公制克拉。一克拉等于 0.2 克，大致相当于一枚回形针的重量</li><li id="8ba4" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">切工:</strong>五个数值之一，按以下合意性顺序指示钻石的切工(签名-理想、理想、非常好、良好、一般)</li><li id="8df3" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">颜色:</strong>六个数值中的一个，表示钻石的颜色，顺序如下(D、E、F——无色，G、H、I——接近无色)</li><li id="707b" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">净度:</strong>表示钻石净度的七个值之一，按以下顺序排列(F——无瑕疵，IF——内部无瑕疵，VVS1 或 vvs 2——非常、非常轻微，或 VS1 或 VS2——非常轻微，SI1——轻微)</li><li id="8465" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">抛光度:</strong>表示钻石抛光度的四个数值之一(ID —理想、EX —优秀、VG —非常好、G —良好)</li><li id="48e7" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">对称性:</strong>表示钻石对称性的四个数值之一(ID —理想，EX —优秀，VG —非常好，G —良好)</li><li id="6414" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">报告:</strong>两个值之一“AGSL”或“GIA”表示哪个分级机构报告了钻石质量</li><li id="0eb1" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">价格:</strong>钻石估价的美元金额<code class="fe ng nh ni mx b">Target Column</code></li></ul><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="82f7" class="nb ke iq mx b gy nc nd l ne nf">from pycaret.datasets import get_data<br/>dataset = get_data('diamond')</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/47ef3fb508703eb19401c9d3f5a884b1.png" data-original-src="https://miro.medium.com/v2/format:webp/1*09u5Q8uO5Xq4v9mpWiW6WA.png"/></div></figure><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="c17d" class="nb ke iq mx b gy nc nd l ne nf">#check the shape of data<br/>dataset.shape</span><span id="ed7c" class="nb ke iq mx b gy nk nd l ne nf">(6000, 8)</span></pre><p id="1f85" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">为了演示对看不见的数据使用<code class="fe ng nh ni mx b">predict_model</code>函数，从原始数据集中保留了 600 条记录的样本用于预测。这不应与训练/测试分割相混淆，因为这种特定的分割是为了模拟真实场景而执行的。另一种思考方式是，在进行这个机器学习实验的时候，这 600 条记录是不可用的。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="3a63" class="nb ke iq mx b gy nc nd l ne nf">data = dataset.sample(frac=0.9, random_state=786)<br/>data_unseen = dataset.drop(data.index)<br/><br/>data.reset_index(drop=True, inplace=True)<br/>data_unseen.reset_index(drop=True, inplace=True)<br/><br/>print('Data for Modeling: ' + str(data.shape))<br/>print('Unseen Data For Predictions: ' + str(data_unseen.shape))</span><span id="c592" class="nb ke iq mx b gy nk nd l ne nf"><strong class="mx ir">&gt;&gt;&gt; Data for Modeling: (5400, 8)<br/>&gt;&gt;&gt; Unseen Data For Predictions: (600, 8)</strong></span></pre><h1 id="c86c" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">7.在 PyCaret 中设置环境</h1><p id="bf7e" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><code class="fe ng nh ni mx b">setup</code>函数在 pycaret 中初始化环境，并创建转换管道，为建模和部署准备数据。在 pycaret 中执行任何其他函数之前，必须调用<code class="fe ng nh ni mx b">setup</code>。它有两个强制参数:一个 pandas dataframe 和目标列的名称。所有其他参数都是可选的，用于定制预处理管道(我们将在后面的教程中看到)。</p><p id="37e6" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">当执行<code class="fe ng nh ni mx b">setup</code>时，PyCaret 的推理算法将根据某些属性自动推断所有特征的数据类型。应该可以正确推断出数据类型，但情况并非总是如此。考虑到这一点，PyCaret 在执行<code class="fe ng nh ni mx b">setup</code>函数后显示一个包含特征及其推断数据类型的表格。如果所有数据类型都被正确识别，可按下<code class="fe ng nh ni mx b">enter</code>继续，或按下<code class="fe ng nh ni mx b">quit</code>结束实验。</p><p id="2891" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">确保数据类型正确在 PyCaret 中非常重要，因为它会自动执行多个特定于类型的预处理任务，这些任务对于机器学习模型来说是必不可少的。</p><p id="c443" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">或者，您也可以使用<code class="fe ng nh ni mx b">setup</code>中的<code class="fe ng nh ni mx b">numeric_features</code>和<code class="fe ng nh ni mx b">categorical_features</code>参数来预定义数据类型。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="b494" class="nb ke iq mx b gy nc nd l ne nf">from pycaret.regression import *<br/>s = setup(data = data, target = 'Price', session_id=123)</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/cbee26cec9bae86a621b825bd6c09bc7.png" data-original-src="https://miro.medium.com/v2/format:webp/1*65YmL9g3KGW_aStvBl14bA.png"/></div></figure><p id="bfe9" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">成功执行设置后，它会显示包含几条重要信息的信息网格。大部分信息与执行<code class="fe ng nh ni mx b">setup</code>时构建的预处理流水线有关。这些特性的大部分超出了本教程的范围。但是，在此阶段需要注意的一些重要事项包括:</p><ul class=""><li id="ebeb" class="me mf iq ld b le lz li ma lm mg lq mh lu mi ly mj mk ml mm bi translated"><strong class="ld ir"> session_id: </strong>一个伪随机数，作为种子分布在所有函数中，以便以后再现。如果没有通过<code class="fe ng nh ni mx b">session_id</code>，则自动生成一个随机数，分配给所有功能。在本实验中，为了以后的再现性，将<code class="fe ng nh ni mx b">session_id</code>设置为<code class="fe ng nh ni mx b">123</code>。</li><li id="86af" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">原始数据:</strong>显示数据集的原始形状。对于这个实验，(5400，8)意味着包括目标列在内的 5400 个样本和 8 个特征。</li><li id="215f" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">缺失值:</strong>当原始数据中存在缺失值时，显示为真。对于这个实验，数据集中没有缺失值。</li><li id="6360" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">数字特征:</strong>推断为数字的特征数量。在该数据集中，8 个要素中有 1 个被推断为数值型。</li><li id="1004" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">分类特征:</strong>推断为分类的特征数量。在该数据集中，8 个特征中有 6 个被推断为分类特征。</li><li id="e558" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">转换后的训练集:</strong>显示转换后的训练集的形状。注意，对于转换后的训练集,( 5400，8)的原始形状被转换为(3779，28)。由于分类编码，特征的数量从 8 个增加到 28 个</li><li id="9ff6" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated"><strong class="ld ir">转换后的测试集:</strong>显示转换后的测试/保持集的形状。在测试/保留组中有 1621 个样本。该分割基于默认值 70/30，可使用<code class="fe ng nh ni mx b">setup</code>中的<code class="fe ng nh ni mx b">train_size </code>参数进行更改。</li></ul><p id="b5cd" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">请注意，执行建模所必需的一些任务是如何自动处理的，例如缺失值插补(在这种情况下，训练数据中没有缺失值，但我们仍然需要用于未知数据的插补器)、分类编码等。<code class="fe ng nh ni mx b">setup</code>中的大多数参数是可选的，用于定制预处理流水线。这些参数超出了本教程的范围，但是当您进入中级和专家级别时，我们将更加详细地介绍它们。</p><h1 id="39aa" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">8.比较所有模型</h1><p id="2e2e" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">一旦设置完成，比较所有模型以评估性能是建模的推荐起点(除非您确切地知道您需要哪种模型，而事实往往并非如此)。该函数训练模型库中的所有模型，并使用 k-fold 交叉验证对它们进行评分以进行度量评估。输出打印一个评分网格，显示平均平均平均误差、平均均方误差、RMSE、R2、均方根误差和 MAPE(默认为 10)以及每个模型花费的训练时间。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="3e1b" class="nb ke iq mx b gy nc nd l ne nf">best = compare_models()</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/d7d9c5e54e192aa8a977ab2390899828.png" data-original-src="https://miro.medium.com/v2/format:webp/1*cGT0XNgSBCl8k3bPGlQYWw.png"/></div></figure><p id="2163" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">一行代码，我们已经使用交叉验证训练和评估了 20 多个模型。上面打印的评分网格突出显示了最高绩效指标，仅供比较之用。默认情况下，网格使用<code class="fe ng nh ni mx b">R2</code>(从高到低)排序，这可以通过传递<code class="fe ng nh ni mx b">sort</code>参数来改变。例如，<code class="fe ng nh ni mx b">compare_models(sort = 'RMSLE')</code>将按照 RMSLE 对网格进行排序(从低到高，因为越低越好)。</p><p id="635f" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">如果您想将折叠参数从默认值<code class="fe ng nh ni mx b">10</code>更改为不同的值，那么您可以使用<code class="fe ng nh ni mx b">fold</code>参数。例如<code class="fe ng nh ni mx b">compare_models(fold = 5)</code>将对所有模型进行五重交叉验证比较。减少折叠次数将改善训练时间。</p><p id="9f98" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">默认情况下，<code class="fe ng nh ni mx b">compare_models</code>根据默认的排序顺序返回性能最好的模型，但是也可以通过使用<code class="fe ng nh ni mx b">n_select</code>参数返回前 N 个模型的列表。</p><h1 id="93da" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">9.创建模型</h1><p id="6827" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><code class="fe ng nh ni mx b">create_model</code>是 PyCaret 中粒度最细的函数，通常是大多数 PyCaret 功能的基础。顾名思义，该函数使用交叉验证来训练和评估模型，交叉验证可以用<code class="fe ng nh ni mx b">fold</code>参数来设置。输出打印出一个得分网格，按折叠显示 MAE、MSE、RMSE、R2、RMSLE 和 MAPE。</p><p id="f9a3" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">对于本教程的剩余部分，我们将使用下面的模型作为我们的候选模型。这些选择仅用于说明目的，并不意味着它们是此类数据的最佳选择或理想选择。</p><ul class=""><li id="90b2" class="me mf iq ld b le lz li ma lm mg lq mh lu mi ly mj mk ml mm bi translated">AdaBoost 回归器(“ada”)</li><li id="4258" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated">光梯度推进机</li><li id="5fce" class="me mf iq ld b le mn li mo lm mp lq mq lu mr ly mj mk ml mm bi translated">决策树(“dt”)</li></ul><p id="788d" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">PyCaret 的模型库中有 25 个可用的回归变量。要查看所有回归变量的完整列表，请检查 docstring 或使用<code class="fe ng nh ni mx b">models</code>函数查看库。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="1e76" class="nb ke iq mx b gy nc nd l ne nf">models()</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/97278b095e087ce7aa2f9719d8b9fe7e.png" data-original-src="https://miro.medium.com/v2/format:webp/1*vrbmiwHNiv-idKHDmxPAmQ.png"/></div></figure><h2 id="3b66" class="nb ke iq bd kf nl nm dn kj nn no dp kn lm np nq kr lq nr ns kv lu nt nu kz nv bi translated">9.1 AdaBoost 回归器</h2><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="02c6" class="nb ke iq mx b gy nc nd l ne nf">ada = create_model('ada')</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/7e9fcc82c76df12f81e01f83f32e6588.png" data-original-src="https://miro.medium.com/v2/format:webp/1*bY5vothU5Rc-OrQT7VNT3Q.png"/></div></figure><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="4238" class="nb ke iq mx b gy nc nd l ne nf">print(ada)</span><span id="adb6" class="nb ke iq mx b gy nk nd l ne nf"><strong class="mx ir">&gt;&gt;&gt; OUTPUT<br/></strong>AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear', n_estimators=50, random_state=123)</span></pre><h2 id="2b95" class="nb ke iq bd kf nl nm dn kj nn no dp kn lm np nq kr lq nr ns kv lu nt nu kz nv bi translated">9.2 光梯度推进机</h2><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="e436" class="nb ke iq mx b gy nc nd l ne nf">lightgbm = create_model('lightgbm')</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/41674e0cb00c0f239fa350b149e426de.png" data-original-src="https://miro.medium.com/v2/format:webp/1*laxfH0pGSQvyEvXuSU1SKQ.png"/></div></figure><h2 id="bc76" class="nb ke iq bd kf nl nm dn kj nn no dp kn lm np nq kr lq nr ns kv lu nt nu kz nv bi translated">9.3 决策树</h2><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="129d" class="nb ke iq mx b gy nc nd l ne nf">dt = create_model('dt')</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/880569e1a19fd5475aa7035cbb2004f2.png" data-original-src="https://miro.medium.com/v2/format:webp/1*DNhsgTy1Bbz-5Co4F_n3FQ.png"/></div></figure><p id="e860" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">请注意，所有型号的平均分数与<code class="fe ng nh ni mx b">compare_models</code>中打印的分数相匹配。这是因为打印在<code class="fe ng nh ni mx b">compare_models</code>分数网格中的指标是所有 CV 折叠的平均分数。与<code class="fe ng nh ni mx b">compare_models</code>类似，如果您想将折叠参数从默认值 10 更改为不同的值，那么您可以使用<code class="fe ng nh ni mx b">create_model</code>功能中的<code class="fe ng nh ni mx b">fold</code>参数。例如:<code class="fe ng nh ni mx b">create_model('dt', fold = 5)</code>使用五重交叉验证创建决策树。</p><h1 id="fddf" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">10.调整模型</h1><p id="6c63" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">当使用<code class="fe ng nh ni mx b">create_model</code>功能创建模型时，它使用默认的超参数来训练模型。为了调整超参数，使用了<code class="fe ng nh ni mx b">tune_model</code>功能。该功能在预定义的搜索空间中使用<code class="fe ng nh ni mx b">RandomGridSearch</code>自动调整模型的超参数。输出打印出一个得分网格，按折叠显示 MAE、MSE、RMSE、R2、RMSLE 和 MAPE。要使用自定义搜索网格，您可以在<code class="fe ng nh ni mx b">tune_model</code>函数中传递<code class="fe ng nh ni mx b">custom_grid</code>参数。</p><h2 id="83c8" class="nb ke iq bd kf nl nm dn kj nn no dp kn lm np nq kr lq nr ns kv lu nt nu kz nv bi translated">10.1 AdaBoost 回归器</h2><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="06ec" class="nb ke iq mx b gy nc nd l ne nf">tuned_ada = tune_model(ada)</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/c7f49255ee6d0cb5ebe957f75f8d00a2.png" data-original-src="https://miro.medium.com/v2/format:webp/1*jRaNiXhqwA8knbPqJZURFA.png"/></div></figure><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="40d4" class="nb ke iq mx b gy nc nd l ne nf">print(tuned_ada)</span><span id="a43d" class="nb ke iq mx b gy nk nd l ne nf"><strong class="mx ir">&gt;&gt;&gt; OUTPUT<br/></strong>AdaBoostRegressor(base_estimator=None, learning_rate=0.05, loss='linear',n_estimators=90, random_state=123)</span></pre><h2 id="4a10" class="nb ke iq bd kf nl nm dn kj nn no dp kn lm np nq kr lq nr ns kv lu nt nu kz nv bi translated">10.2 光梯度推进机</h2><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="7cea" class="nb ke iq mx b gy nc nd l ne nf">import numpy as np<br/>lgbm_params = {'num_leaves': np.arange(10,200,10),<br/>                        'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],<br/>                        'learning_rate': np.arange(0.1,1,0.1)<br/>                        }</span><span id="f6cd" class="nb ke iq mx b gy nk nd l ne nf">tuned_lightgbm = tune_model(lightgbm, custom_grid = lgbm_params)</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/e5cd35cfc52ea98aead852f4b9d415d9.png" data-original-src="https://miro.medium.com/v2/format:webp/1*qJH-EbblNDR8KxoY9iuQNw.png"/></div></figure><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="6dbc" class="nb ke iq mx b gy nc nd l ne nf">print(tuned_lightgbm)</span><span id="a51f" class="nb ke iq mx b gy nk nd l ne nf"><strong class="mx ir">&gt;&gt;&gt; OUTPUT</strong></span><span id="3233" class="nb ke iq mx b gy nk nd l ne nf">LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,<br/>              importance_type='split', learning_rate=0.1, max_depth=60,<br/>              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,<br/>              n_estimators=100, n_jobs=-1, num_leaves=120, objective=None,<br/>              random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent=True,<br/>              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)</span></pre><h2 id="dbf3" class="nb ke iq bd kf nl nm dn kj nn no dp kn lm np nq kr lq nr ns kv lu nt nu kz nv bi translated">10.3 决策树</h2><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="bf0a" class="nb ke iq mx b gy nc nd l ne nf">tuned_dt = tune_model(dt)</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/79b4fb5bad63d86fc8c95dbfb13173de.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Lt0PzaIx9UWLDN4iendXog.png"/></div></figure><p id="862d" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">默认情况下，<code class="fe ng nh ni mx b">tune_model</code>会优化<code class="fe ng nh ni mx b">R2</code>，但这可以使用<code class="fe ng nh ni mx b">optimize</code>参数进行更改。例如，<code class="fe ng nh ni mx b">tune_model(dt, optimize = 'MAE')</code>将搜索导致最低<code class="fe ng nh ni mx b">MAE</code>而不是最高<code class="fe ng nh ni mx b">R2</code>的决策树回归的超参数。在本例中，我们使用默认指标<code class="fe ng nh ni mx b">R2</code>只是为了简单起见。选择正确的度量来评估回归变量的方法超出了本教程的范围，但是如果您想了解更多，您可以<a class="ae kc" href="https://www.dataquest.io/blog/understanding-regression-error-metrics/" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir">单击此处</strong> </a>了解回归误差度量。</p><p id="a1f1" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">在最终确定生产的最佳模型时，度量并不是您应该考虑的唯一标准。要考虑的其他因素包括训练时间、k 倍的标准偏差等。现在，让我们向前看，把存储在<code class="fe ng nh ni mx b">tuned_lightgbm</code>变量中的调整后的光梯度增强机器作为本教程剩余部分的最佳模型。</p><h1 id="d2fe" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">11.绘制模型</h1><p id="7da1" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在模型最终确定之前，<code class="fe ng nh ni mx b">plot_model</code>函数可用于分析不同方面的性能，如残差图、预测误差、特征重要性等。此函数接受一个经过训练的模型对象，并基于测试/保留集返回一个图。</p><p id="22bf" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">有超过 10 个地块可用，请参见<code class="fe ng nh ni mx b">plot_model</code>文档中的可用地块列表。</p><h2 id="b468" class="nb ke iq bd kf nl nm dn kj nn no dp kn lm np nq kr lq nr ns kv lu nt nu kz nv bi translated">11.1 残差图</h2><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="2857" class="nb ke iq mx b gy nc nd l ne nf">plot_model(tuned_lightgbm)</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/b2ba56cfe32bb117d4945a19d79a452a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*b0Q8Fpr9KQgUzNJsE0uyAA.png"/></div></figure><h2 id="e7f8" class="nb ke iq bd kf nl nm dn kj nn no dp kn lm np nq kr lq nr ns kv lu nt nu kz nv bi translated">11.2 预测误差图</h2><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="61f6" class="nb ke iq mx b gy nc nd l ne nf">plot_model(tuned_lightgbm, plot = 'error')</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/b2e289fe895bffbe98668e37eb4272d3.png" data-original-src="https://miro.medium.com/v2/format:webp/1*bsRkOaeIy-gBGUEdZ5ZPQQ.png"/></div></figure><h2 id="f2a6" class="nb ke iq bd kf nl nm dn kj nn no dp kn lm np nq kr lq nr ns kv lu nt nu kz nv bi translated">11.3 特征重要性图</h2><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="e9d0" class="nb ke iq mx b gy nc nd l ne nf">plot_model(tuned_lightgbm, plot='feature')</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/127962b024cbdce0660a1b71eb3a7418.png" data-original-src="https://miro.medium.com/v2/format:webp/1*uYZCcZ2XXRaTxwQqXhMpQQ.png"/></div></figure><p id="f3f4" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><em class="nw">分析模型性能的另一种</em>方法是使用<code class="fe ng nh ni mx b">evaluate_model</code>功能，该功能显示给定模型所有可用图的用户界面。它在内部使用<code class="fe ng nh ni mx b">plot_model</code>功能。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="a6a9" class="nb ke iq mx b gy nc nd l ne nf">evaluate_model(tuned_lightgbm)</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nx"><img src="../Images/f65e96ddf91372ff31352b8b18d61af0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4HbjRjAW0I6-i6fY"/></div></div></figure><h1 id="0ea8" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">12.根据测试/保留样本进行预测</h1><p id="3d97" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在最终确定模型之前，建议通过预测测试/坚持集和审查评估指标来执行最后的检查。如果您查看上面第 6 节中的信息网格，您将看到 30% (1621 个样本)的数据被分离出来作为测试/保留样本。我们上面看到的所有评估指标都是仅基于训练集(70%)的交叉验证结果。现在，使用我们存储在<code class="fe ng nh ni mx b">tuned_lightgbm</code>中的最终训练模型，我们将预测拒不接受的样本并评估指标，以查看它们是否与 CV 结果有实质性的不同。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="b4ec" class="nb ke iq mx b gy nc nd l ne nf">predict_model(tuned_lightgbm);</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/c6b678185cbcce6d6791ccb9d0e7e575.png" data-original-src="https://miro.medium.com/v2/format:webp/1*e1T4pHDPVF98hmROSY3ugw.png"/></div></figure><p id="f1b8" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">与在<code class="fe ng nh ni mx b">tuned_lightgbm</code> CV 结果(见上文第 10.2 节)上获得的<code class="fe ng nh ni mx b"><strong class="ld ir">0.9708</strong></code>相比，测试/保持装置上的 R2 为<code class="fe ng nh ni mx b"><strong class="ld ir">0.9652</strong></code>。这不是一个显著的差异。如果测试/保持和 CV 结果之间存在较大差异，则这通常表明过度拟合，但也可能是由于其他几个因素，需要进一步调查。在这种情况下，我们将继续最终确定模型，并对看不见的数据进行预测(我们在开始时已经分离出来的 10%的数据，从未向 PyCaret 公开)。</p><h1 id="ccdb" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">13.最终确定用于部署的模型</h1><p id="9853" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">模型定型是实验的最后一步。PyCaret 中的机器学习工作流从<code class="fe ng nh ni mx b">setup</code>开始，然后使用<code class="fe ng nh ni mx b">compare_models</code>比较所有模型，并列出几个候选模型(基于感兴趣的度量)，以执行几种建模技术，如超参数调整、集成、堆叠等。这一工作流程最终将引导您找到用于对新的和未知的数据进行预测的最佳模型。</p><p id="5956" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><code class="fe ng nh ni mx b">finalize_model</code>函数将模型拟合到完整的数据集上，包括测试/保留样本(本例中为 30%)。此函数的目的是在将模型部署到生产中之前，在完整的数据集上训练模型。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="ae67" class="nb ke iq mx b gy nc nd l ne nf">final_lightgbm = finalize_model(tuned_lightgbm)</span><span id="963c" class="nb ke iq mx b gy nk nd l ne nf">print(final_lightgbm)</span><span id="703f" class="nb ke iq mx b gy nk nd l ne nf"><strong class="mx ir">&gt;&gt;&gt; OUTPUT</strong></span><span id="6c84" class="nb ke iq mx b gy nk nd l ne nf">LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,<br/>              importance_type='split', learning_rate=0.1, max_depth=60,<br/>              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,<br/>              n_estimators=100, n_jobs=-1, num_leaves=120, objective=None,<br/>              random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent=True,<br/>              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)</span></pre><p id="beb7" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">警告:最后一个警告。使用<code class="fe ng nh ni mx b">finalize_model</code>最终确定模型后，包括测试/拒绝集在内的整个数据集将用于训练。因此，如果在使用<code class="fe ng nh ni mx b">finalize_model</code>后，该模型用于对拒绝集进行预测，则打印的信息网格将会产生误导，因为您试图对用于建模的相同数据进行预测。</p><p id="0b82" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">为了证明这一点，我们将使用<code class="fe ng nh ni mx b">predict_model</code>下的<code class="fe ng nh ni mx b">final_lightgbm</code>来比较信息网格和上面第 12 节中的信息网格。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="1535" class="nb ke iq mx b gy nc nd l ne nf">predict_model(final_lightgbm);</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/413f402ff6cf9c8102954e2a97f3d771.png" data-original-src="https://miro.medium.com/v2/format:webp/1*43Mnwbk-PuMnll6f3fEo0w.png"/></div></figure><p id="d8ce" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">请注意，<code class="fe ng nh ni mx b">final_lightgbm</code>中的 R2 是如何从<code class="fe ng nh ni mx b"><strong class="ld ir">0.9652</strong></code>增加到<code class="fe ng nh ni mx b"><strong class="ld ir">0.9891</strong></code>的，尽管型号是相同的。这是因为<code class="fe ng nh ni mx b">final_lightgbm</code>变量是在包括测试/拒绝集的完整数据集上训练的。</p><h1 id="4b86" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">14.根据看不见的数据预测</h1><p id="e15f" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><code class="fe ng nh ni mx b">predict_model</code>函数用于预测未知/新数据集。与上一节唯一不同的是，这一次我们将传递<code class="fe ng nh ni mx b">data_unseen</code>参数。<code class="fe ng nh ni mx b">data_unseen</code>是在本教程开始时创建的变量，包含原始数据集的 10% (600 个样本)，该数据集从未暴露给 PyCaret。(参见第 5 节的解释)</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="4175" class="nb ke iq mx b gy nc nd l ne nf">unseen_predictions = predict_model(final_lightgbm, data=data_unseen)<br/>unseen_predictions.head()</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/fd3be5692680cb5828b69b996d8da4ce.png" data-original-src="https://miro.medium.com/v2/format:webp/1*lHbt6_iUgbbAOm64JnzcNA.png"/></div></figure><p id="91be" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><code class="fe ng nh ni mx b">Label</code>列被添加到<code class="fe ng nh ni mx b">data_unseen</code>集合中。标签是使用<code class="fe ng nh ni mx b">final_lightgbm</code>模型的预测值。如果您想要对预测进行舍入，您可以使用<code class="fe ng nh ni mx b">predict_model</code>中的<code class="fe ng nh ni mx b">round</code>参数。您还可以检查这方面的指标，因为您有一个实际的目标列<code class="fe ng nh ni mx b">Price</code>可用。为此，我们将使用<code class="fe ng nh ni mx b">pycaret.utils</code>模块。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="fd99" class="nb ke iq mx b gy nc nd l ne nf">from pycaret.utils import check_metric<br/>check_metric(unseen_predictions.Price, unseen_predictions.Label, 'R2')</span><span id="1911" class="nb ke iq mx b gy nk nd l ne nf"><strong class="mx ir">&gt;&gt;&gt; OUTPUT<br/></strong>0.9779</span></pre><h1 id="6d74" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">15.保存模型</h1><p id="941d" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们现在已经完成了实验，最终确定了现在存储在<code class="fe ng nh ni mx b">final_lightgbm</code>变量中的<code class="fe ng nh ni mx b">tuned_lightgbm</code>模型。我们还使用了存储在<code class="fe ng nh ni mx b">final_lightgbm</code>的模型来预测<code class="fe ng nh ni mx b">data_unseen</code>。这使我们的实验接近尾声，但仍有一个问题要问:当你有更多的新数据要预测时，会发生什么？你必须再次经历整个实验吗？答案是否定的，PyCaret 的内置函数<code class="fe ng nh ni mx b">save_model</code>允许您保存模型和整个转换管道以备后用。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="0de0" class="nb ke iq mx b gy nc nd l ne nf">save_model(final_lightgbm,'Final LightGBM Model 25Nov2020')</span><span id="6387" class="nb ke iq mx b gy nk nd l ne nf">Transformation Pipeline and Model Successfully Saved<br/><br/><strong class="mx ir">&gt;&gt;&gt; OUTPUT</strong><br/>(Pipeline(memory=None,<br/>          steps=[('dtypes',<br/>                  DataTypes_Auto_infer(categorical_features=[],<br/>                                       display_types=True, features_todrop=[],<br/>                                       id_columns=[], ml_usecase='regression',<br/>                                       numerical_features=[], target='Price',<br/>                                       time_features=[])),<br/>                 ('imputer',<br/>                  Simple_Imputer(categorical_strategy='not_available',<br/>                                 fill_value_categorical=None,<br/>                                 fill_value_numerical=None,<br/>                                 numeric_strategy='...<br/>                  LGBMRegressor(boosting_type='gbdt', class_weight=None,<br/>                                colsample_bytree=1.0, importance_type='split',<br/>                                learning_rate=0.1, max_depth=60,<br/>                                min_child_samples=20, min_child_weight=0.001,<br/>                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,<br/>                                num_leaves=120, objective=None, random_state=123,<br/>                                reg_alpha=0.0, reg_lambda=0.0, silent=True,<br/>                                subsample=1.0, subsample_for_bin=200000,<br/>                                subsample_freq=0)]],<br/>          verbose=False),<br/> 'Final LightGBM Model 25Nov2020.pkl')</span></pre><h1 id="748a" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">16.加载保存的模型</h1><p id="1611" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">为了将来在相同或不同的环境中加载已保存的模型，我们将使用 PyCaret 的<code class="fe ng nh ni mx b">load_model</code>函数，然后轻松地将已保存的模型应用于新的未知数据进行预测。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="375f" class="nb ke iq mx b gy nc nd l ne nf">saved_final_lightgbm = load_model('Final LightGBM Model 25Nov2020')</span><span id="4cb8" class="nb ke iq mx b gy nk nd l ne nf">Transformation Pipeline and Model Successfully Loaded</span></pre><p id="def4" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">一旦模型被加载到环境中，您可以使用相同的<code class="fe ng nh ni mx b">predict_model</code>函数简单地使用它来预测任何新数据。下面我们应用了加载模型来预测我们在上面第 13 节中使用的相同的<code class="fe ng nh ni mx b">data_unseen</code>。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="74e0" class="nb ke iq mx b gy nc nd l ne nf">new_prediction = predict_model(saved_final_lightgbm, data=data_unseen)</span><span id="d780" class="nb ke iq mx b gy nk nd l ne nf">new_prediction.head()</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/fd3be5692680cb5828b69b996d8da4ce.png" data-original-src="https://miro.medium.com/v2/format:webp/1*lHbt6_iUgbbAOm64JnzcNA.png"/></div></figure><p id="eba7" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">注意<code class="fe ng nh ni mx b">unseen_predictions</code>和<code class="fe ng nh ni mx b">new_prediction</code>的结果是相同的。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="941f" class="nb ke iq mx b gy nc nd l ne nf">from pycaret.utils import check_metric<br/>check_metric(new_prediction.Price, new_prediction.Label, 'R2')</span><span id="8e2b" class="nb ke iq mx b gy nk nd l ne nf">0.9779</span></pre><h1 id="fa09" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">17.总结/后续步骤？</h1><p id="8e4d" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">本教程涵盖了从数据摄取、预处理、训练模型、超参数调整、预测和保存模型以备后用的整个机器学习管道。我们已经在不到 10 个命令中完成了所有这些步骤，这些命令是自然构建的，记忆起来非常直观，例如<code class="fe ng nh ni mx b">create_model()</code>、<code class="fe ng nh ni mx b">tune_model()</code>、<code class="fe ng nh ni mx b">compare_models()</code>。在没有 PyCaret 的情况下，重新创建整个实验在大多数库中需要 100 多行代码。</p><p id="977d" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">我们只讲述了<code class="fe ng nh ni mx b">pycaret.regression</code>的基础知识。在未来的教程中，我们将更深入地研究高级预处理、集成、广义堆叠和其他技术，这些技术允许您完全定制您的机器学习管道，并且是任何数据科学家都必须知道的。</p><p id="b1d6" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">感谢您阅读<a class="ae kc" href="https://emojipedia.org/folded-hands/" rel="noopener ugc nofollow" target="_blank">🙏</a></p></div><div class="ab cl ny nz hu oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="ij ik il im in"><h1 id="3b6f" class="kd ke iq bd kf kg of ki kj kk og km kn ko oh kq kr ks oi ku kv kw oj ky kz la bi translated">重要链接</h1><p id="85f8" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">⭐ <a class="ae kc" href="https://github.com/pycaret/pycaret/tree/master/tutorials" rel="noopener ugc nofollow" target="_blank">教程</a>py caret 新手？查看我们的官方笔记本！<br/>📋<a class="ae kc" href="https://github.com/pycaret/pycaret/tree/master/examples" rel="noopener ugc nofollow" target="_blank">社区创建的示例笔记本</a>。<br/>📙<a class="ae kc" href="https://github.com/pycaret/pycaret/tree/master/resources" rel="noopener ugc nofollow" target="_blank">博客</a>投稿人的教程和文章。<br/>📚<a class="ae kc" href="https://pycaret.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">文档</a>py caret 的详细 API 文档<br/>📺<a class="ae kc" href="https://www.youtube.com/channel/UCxA1YTYJ9BEeo50lxyI_B3g" rel="noopener ugc nofollow" target="_blank">视频教程</a>我们的视频教程来自各种赛事。<br/>📢<a class="ae kc" href="https://github.com/pycaret/pycaret/discussions" rel="noopener ugc nofollow" target="_blank">讨论</a>有疑问？与社区和贡献者互动。<br/> 🛠️ <a class="ae kc" href="https://github.com/pycaret/pycaret/blob/master/CHANGELOG.md" rel="noopener ugc nofollow" target="_blank">变更日志</a>变更和版本历史。<br/>🌳<a class="ae kc" href="https://github.com/pycaret/pycaret/issues/1756" rel="noopener ugc nofollow" target="_blank">路线图</a> PyCaret 的软件和社区发展计划。</p><h1 id="01c1" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">作者:</h1><p id="7806" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我写的是 PyCaret 及其在现实世界中的用例，如果你想自动得到通知，你可以在<a class="ae kc" href="https://medium.com/@moez-62905" rel="noopener">媒体</a>、<a class="ae kc" href="https://www.linkedin.com/in/profile-moez/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae kc" href="https://twitter.com/moezpycaretorg1" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注我。</p></div></div>    
</body>
</html>