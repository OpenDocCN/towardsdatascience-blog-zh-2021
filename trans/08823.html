<html>
<head>
<title>The Unavoidable Reason Why AI Should Be More Human</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能应该更像人类的不可避免的原因</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-unavoidable-reason-why-ai-should-be-more-human-50e06ae21ee0?source=collection_archive---------20-----------------------#2021-08-14">https://towardsdatascience.com/the-unavoidable-reason-why-ai-should-be-more-human-50e06ae21ee0?source=collection_archive---------20-----------------------#2021-08-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="82e5" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">人工智能|观点</h2><div class=""/><div class=""><h2 id="d62d" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">即使这迫使我们面对可怕的未来。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/ae38bcd58c8bbf5bb31be29992c144d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eZSY90i4SpthLGBh"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">马修·费雷罗在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="e483" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">人工智能已经是一种先进的技术，但它可能会进化，直到它成为一个新的物种。我们称它为<em class="me">智人机器</em>。</p><p id="c1ee" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在40年代和50年代，科学家们对计算机和大脑产生了兴趣。认知科学和计算机科学是充满希望的新生领域，它们开启了有趣的研究可能性:控制论、人工神经网络、神经科学、人工智能……略微不同的领域来自同一个地方，但走向截然不同的未来。</p><p id="15b5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一些科学家选择了认知科学，将人类作为他们研究的核心。他们认为首要任务是理解我们的大脑以及生物智能和意识的基础。</p><p id="525d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其他人认为有可能用人类的认知能力建造一个电子大脑。对他们来说，理解大脑排在第二位，不再需要遵循生物学的足迹。为什么我们会认为我们只能通过自然的途径获得智慧？生物智能被印在碳生命形式中，但用硅创造人工智能没有明显的限制。</p><p id="b8d2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，他们忽略了一个关键问题:如果我们实现了这个目标，我们的社会会发生什么？如果我们智人试图与我们的硅基同行machina sapiens共存，我们的文明会发生什么？</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="f678" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">AI应该模仿人类生物吗？永恒的争论</h1><p id="2f34" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">大多数人工智能专家同意，人工智能既不能复制人脑，也不能完全抛弃我们的进化遗传。但是在这个协议中有分歧。没有人知道如何继续构建越来越智能的人工智能，或者如何克服深度学习的瓶颈。AI可以很好地完成狭窄的任务，但不能概括大部分内容。它不能像我们一样推理、计划或与世界互动。这是一个很容易被攻击的目标，没有人会上当。</p><p id="d954" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因为我们不知道哪条路径是正确的，所以有很多<em class="me">可能的</em>路径。</p><p id="1354" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一方面，深度学习的倡导者辩护说，我们不需要盲目地遵循生物学。他们认为基于神经网络的人工智能是获得普通人工智能的唯一途径。在去年接受《麻省理工科技评论》采访时，杰弗里·辛顿说:“我确实相信深度学习将能够做任何事情。”事实是，十年的深度学习成功支持了这些说法。从AlexNet到AlphaZero，再到GPT-3，深度学习一次又一次地重申了它在人工智能领域的统治地位。</p><p id="5c66" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">他们相信深度学习是通往AGI的道路，即使它需要一些突破。自我监督学习和transformer架构是支持这一观点的最新论据，但还有其他不太令人信服的方面。在<a class="ae lh" href="https://science.sciencemag.org/content/367/6473/83" rel="noopener ugc nofollow" target="_blank">发表在去年<em class="me">科学</em>杂志上的一项研究</a>中，Yiota Poirazi和她的团队发现生物神经元甚至比我们之前认为的更复杂，而人造神经元是在假设生物神经元是“基础数学的哑计算器<a class="ae lh" href="https://bdtechtalks.com/2020/01/20/neuroscience-artificial-intelligence-synergies/" rel="noopener ugc nofollow" target="_blank">的情况下构建的</a></p><p id="d076" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">另一方面，这也是为什么有人说AI是<em class="me">与众不同的</em>。它不同于其他技术，因为它试图解决最复杂的挑战。人脑<a class="ae lh" href="https://www.bbc.com/news/uk-scotland-18233409" rel="noopener ugc nofollow" target="_blank">被认为</a>是“宇宙中最复杂的东西”，这并非空穴来风我们的大脑是我们想要构建的唯一实例，记住这一点似乎是合理的。</p><p id="65ca" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">更成问题的是，我们不了解大脑，正如教授罗宾·默里爵士所预言的，“我们将无法了解。”对于其他技术，我们可以提取我们试图建模的事件背后的潜在规律和原则。飞机不会像鸟一样飞，但它们确实遵循空气动力学和流体动力学的物理定律。我们还不能为大脑做这些，因为神经科学还不够成熟。</p><p id="a9f1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">出于这些原因，像加里·马库斯这样的人认为我们应该研究人类的大脑。“我们需要从自然中获取灵感”以在人工智能领域走得更远。加里·马库斯为人工智能的混合模型方法辩护。他声称，我们应该将深度学习的力量与更古老的范式整合起来，如符号人工智能。数据驱动和知识驱动的人工智能系统结合起来可能比其各部分的总和更有能力。</p><p id="da95" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">深度学习系统不像我们的大脑那样学习、观察或处理。进化给了我们各种各样的先天结构，使我们更容易与我们的世界互动。为什么不给人工智能灌输这些？否则，深度学习系统可能无法开发像常识推理、自我学习或建立世界心理模型这样的能力。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="05a4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">辩论的双方都持有强有力的论点，但似乎没有人注意到更大的画面。从生物学角度思考不足以解决社会困境。让我们回到我之前提到的那个缺失的问题:如果我们假装最终生活在一个跨物种的社会中，难道不是很明显我们应该让AI更像人，即使这是次优的解决方案吗？</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="f4cf" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">一个社会兼容的人工智能应该是我们的首要任务</h1><p id="c42f" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">从严格的技术角度来看，上述争论是有意义的。创造新技术的最佳途径是什么？在哪个点上——或者在哪些方面——我们应该停止/开始复制生物学？这些问题的问题在于它们是一维的，而世界是多维的。科学和技术关心的是理解现实，创造有用的解决方案来改善我们的福祉，但它们仅限于此。</p><p id="e6cc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">社会层面呢？如果我们考虑到这一挑战的心理学和社会学方面，很明显我们至少必须遵循生物学。也许对今天的“人工智能”系统来说不是。但如果我们试图构建类似人类的人工智能，这将是一个必要条件。</p><p id="e388" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们思考一下这个问题。我们的目标是创造人类水平的智能实体。这不同于建造我们可以在一天结束后关掉的机器。人类级别的AI会发展意识吗？我们将如何与这些实体互动？AGI会更像我们的智能手机还是我们的兄弟姐妹？我们是希望人工智能拥有人形形态，还是应该冒着疏远它们的风险最大化效用？</p><p id="4629" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">流行文化已经在许多场合探讨了这些问题。从最近的电影《T2》、《T3》或《T4》、《玛奇纳》、《T5 》,到旧书《我》、《机器人》、《T7》或《2001:太空漫游》。如果我们最终进入一个我们希望AI成为我们生活中有意识的一部分的时期，照顾这些方面是至关重要的。</p><p id="9583" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，这并不容易。当今社会，当一个人感到与另一个人疏远时，会发生什么？意识形态、种族、宗教或性别的差异是一些最常见的人类冲突的原因。看似无害的失调会助长人性最野蛮的一面。</p><p id="8793" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">非人类的人工智能会离我们很远，任何其他人类都会感觉像家人一样。相比之下，任何人为的错位都可以忽略不计。作为个人和社会，我们如何适应一个新的、同样有能力的物种？</p><p id="6efd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">“我们应该遵循生物学吗？”现在感觉很肤浅。在这个层次的对话中，它忽略了要点。这场辩论应该围绕如果我们创造了一个最终与我们在社会上不兼容的人工智能，我们将面临的后果。在这个讨论中的任何一点上，我们都应该把人们的福祉放在功利之上。</p><p id="2173" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们应该在人工智能中注入生物学——以及心理学和社会学——的特征，只要我们的目标是让它们变得普遍智能。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="4ae5" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">情绪化人工智能的危险</h1><p id="5b46" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">但是我们不能忽视其中的风险。复制生物学意味着向人工智能灌输情感和动机，这被认为是最危险的途径之一。情绪和驱动力是我们对自己和他人造成伤害的主要原因。然而，如果我们希望人工智能像我们一样，情感就不能被排除在外。那么我们应该回答的问题是，“一个有情感的人工智能真的能超越并伤害我们吗？”</p><blockquote class="nj nk nl"><p id="147f" class="li lj me lk b ll lm kd ln lo lp kg lq nm ls lt lu nn lw lx ly no ma mb mc md im bi translated">“要接管世界，机器人就得想办法；他们必须有侵略性，有野心，并且不满足于暴力牛排。目前，根本没有理由制造具有情感状态的机器人。”— <em class="it">加里·马库斯</em></p></blockquote><p id="bf83" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在他的书<a class="ae lh" href="https://www.goodreads.com/en/book/show/43999120-rebooting-ai" rel="noopener ugc nofollow" target="_blank"> <em class="me">重启人工智能</em> </a>中，加里·马库斯观察到智能并不能让人工智能逃脱我们的控制。这不是能力的问题，而是动力的问题。正如史蒂芬·平克所解释的，“智力是运用新方法来达到目标的能力。但目标与智力无关:聪明并不等同于想要某样东西。”</p><p id="4a3c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">想要东西的人工智能是潜在地想要我们不希望它想要的东西的人工智能。如果一个人工智能决定它的主要目标与它当前的情况不一致，并突然产生一种未经我们同意改变某些东西的动机，会发生什么？</p><p id="0a0b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">鉴于我们也在做同样的事情，这并非不可能。进化造就了我们这个物种。但是我们作为个体想要的往往与生存不一致。我们是愿意永远被束缚着生存，还是愿意一半时间快乐地生活？生存不是我们的首要目标，最大幸福才是。原因是我们能感觉到。快乐和痛苦是我们行为背后最强大的力量。因此，我们很乐意改变我们的遗传禀赋，以更好地实现我们有意识地定义的目标。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="de0b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一个没有情感或动机的人类水平的人工智能对我们来说太陌生了，以至于不能允许毫无问题的共存。但有情感的人工智能是最可怕的人工智能类型:它可以逃脱我们的控制，并重新调整其目标，使之与我们的目标不符。似乎情感AI是我们首先想要的，也是最后想要的。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="342b" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">结论</h1><ul class=""><li id="7979" class="np nq it lk b ll ne lo nf lr nr lv ns lz nt md nu nv nw nx bi translated">先说清楚一点:不是所有的AI都需要复制大脑。机器学习和深度学习包括大量的工具、模型和技术，其中大部分距离人类大脑如此之远，以至于它们可以更好地归类为统计系统。关于基于生物学的人工智能的辩论是关于人工智能的未来，而不是现在。正是在这个意义上，人工智能需要类似于我们。</li><li id="e179" class="np nq it lk b ll ny lo nz lr oa lv ob lz oc md nu nv nw nx bi translated">人工智能在大多数方面都像其他技术，但有一个方面是不同的。这是唯一可能成为我们必须共存的新物种的技术。从这个角度来看，社会争论应该比技术争论更有分量。</li><li id="0781" class="np nq it lk b ll ny lo nz lr oa lv ob lz oc md nu nv nw nx bi translated">如果我们想制造类似人类的人工智能，我们需要给它注入情感和动机。然而，这是在该领域工作的大多数科学家长期担忧的第一个来源。情感是让我们想要和需要东西的东西。如果我们无法将人工智能的情感与我们的目标结合起来，它最终可能会脱离我们的控制，带来不可预见的后果。</li></ul><p id="e96b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">那我来问你这个:非人类AI和情感AI哪个更危险？</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h2 id="dd1d" class="od mn it bd mo oe of dn ms og oh dp mw lr oi oj my lv ok ol na lz om on nc iz bi translated">如果你喜欢这篇文章，可以考虑订阅我的免费周报<a class="ae lh" href="https://mindsoftomorrow.ck.page/" rel="noopener ugc nofollow" target="_blank"><strong class="ak"/></a>！<strong class="ak">每周一关于人工智能的新闻、观点和见解！</strong></h2><h2 id="1c0a" class="od mn it bd mo oe of dn ms og oh dp mw lr oi oj my lv ok ol na lz om on nc iz bi translated"><strong class="ak">在这里</strong>  <strong class="ak">你也可以直接支持我的工作，成为中等会员</strong> <a class="ae lh" href="https://albertoromgar.medium.com/membership" rel="noopener"> <strong class="ak">获得无限权限！:)</strong></a></h2></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="2e9e" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">推荐阅读</h1><div class="oo op gp gr oq or"><a rel="noopener follow" target="_blank" href="/unpopular-opinion-well-abandon-machine-learning-as-main-ai-paradigm-7d11e6773d46"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd jd gy z fp ow fr fs ox fu fw jc bi translated">不受欢迎的观点:我们将放弃机器学习作为主要的人工智能范式</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">这一时刻将会到来，就像它发生在象征性人工智能身上一样。</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">towardsdatascience.com</p></div></div><div class="pa l"><div class="pb l pc pd pe pa pf lb or"/></div></div></a></div><div class="oo op gp gr oq or"><a rel="noopener follow" target="_blank" href="/heres-how-openai-codex-will-revolutionize-programming-and-the-world-e8432aafc5f7"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd jd gy z fp ow fr fs ox fu fw jc bi translated">以下是OpenAI Codex将如何革新编程(和世界)</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">“Codex接近于我们大多数人真正希望从计算机中获得的东西——我们说我们想要什么，他们就做什么。”—山姆·奥特曼</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">towardsdatascience.com</p></div></div><div class="pa l"><div class="pg l pc pd pe pa pf lb or"/></div></div></a></div><div class="oo op gp gr oq or"><a rel="noopener follow" target="_blank" href="/5-must-know-ai-concepts-in-2021-75d8c1ff938"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd jd gy z fp ow fr fs ox fu fw jc bi translated">2021年必须知道的5个人工智能概念</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">这是你不想错过的。</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">towardsdatascience.com</p></div></div><div class="pa l"><div class="ph l pc pd pe pa pf lb or"/></div></div></a></div></div></div>    
</body>
</html>