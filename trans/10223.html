<html>
<head>
<title>Semi-supervised learning made simple</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">半监督学习变得简单</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/semi-supervised-learning-made-simple-141be294880c?source=collection_archive---------9-----------------------#2021-09-28">https://towardsdatascience.com/semi-supervised-learning-made-simple-141be294880c?source=collection_archive---------9-----------------------#2021-09-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="650e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解如何在PyTorch中从头开始构建自己的半监督模型</h2></div><p id="9f35" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">半监督学习是一种从标记和未标记数据中获取有用信息的机器学习技术。</p><p id="f4ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本教程中:</p><ul class=""><li id="604b" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">你将学习什么是监督、无监督、半监督和自我监督学习。</li><li id="86fa" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">一步一步地完成BYOL的PyTorch代码，这是一种半监督学习方法，你可以在Google Colab中自己实现和运行，不需要云或GPU！</li><li id="d2f5" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">你将学习BYOL背后的一个基本理论——半监督学习方法。</li></ul><p id="84f8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在学习本教程之前，您应该对使用PyTorch对图像进行监督学习有基本的了解。</p><h1 id="2e80" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">什么是半监督学习，我们为什么需要它？</h1><p id="3c29" class="pw-post-body-paragraph kf kg iq kh b ki mh jr kk kl mi ju kn ko mj kq kr ks mk ku kv kw ml ky kz la ij bi translated">一般来说，机器学习方法可以分为三类:</p><ul class=""><li id="c53a" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">监督学习</li><li id="d6e8" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">无监督学习</li><li id="5c47" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">强化学习</li></ul><p id="f793" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里我们将省略强化学习，集中讨论前两种类型。</p><p id="28ba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在<strong class="kh ir">监督</strong>学习中，我们的数据由带标签的对象组成。机器学习模型的任务是学习如何给对象分配标签(或值)。</p><blockquote class="mm mn mo"><p id="88ed" class="kf kg mp kh b ki kj jr kk kl km ju kn mq kp kq kr mr kt ku kv ms kx ky kz la ij bi translated">例如:<br/> 1)医院有标有<a class="ae mt" href="https://en.wikipedia.org/wiki/ICD-10" rel="noopener ugc nofollow" target="_blank"> ICD-10 </a>代码的心电图读数。根据心电图读数，我们希望自动对患者进行预诊断。银行有关于债权人的数据——他们的财务状况、他们拥有多少资产、他们是否按时还款等等。银行想评估他们还能借给某人多少钱。</p></blockquote><p id="bea4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">相反,<strong class="kh ir">无监督的</strong>学习只处理未标记的对象。</p><blockquote class="mm mn mo"><p id="9fed" class="kf kg mp kh b ki kj jr kk kl km ju kn mq kp kq kr mr kt ku kv ms kx ky kz la ij bi translated">示例:我们可以让计算机将图像聚类成10个类别，而无需指定这些类别的含义(<a class="ae mt" href="https://en.wikipedia.org/wiki/K-means_clustering" rel="noopener ugc nofollow" target="_blank"> k-means聚类</a>)。</p></blockquote><p id="d44f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">半监督</strong>学习介于这两者之间:一些对象被标记，但大多数没有。未标记数据的优势来自于标记数据通常是资源密集型的事实。</p><blockquote class="mm mn mo"><p id="bf77" class="kf kg mp kh b ki kj jr kk kl km ju kn mq kp kq kr mr kt ku kv ms kx ky kz la ij bi translated">例如:我们有一个包含推文的数据集。其中一些被标注了积极、消极或中性的<a class="ae mt" href="https://en.wikipedia.org/wiki/Sentiment_analysis" rel="noopener ugc nofollow" target="_blank">情绪</a>。不幸的是，注释是时间和成本密集型的——我们需要支付注释者这样做的费用，还要交叉检查他们的答案是否正确。因此，大多数推文都没有被贴上标签，因为下载它们相对便宜且容易，但给它们加注释并不便宜。</p></blockquote><p id="8ee3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">还有另外一种学习:<strong class="kh ir">自我监督</strong>。当我们想出一些我们不一定想要解决但可能成为模型学习的借口的监督任务时，我们可以谈论自我监督学习。自监督学习通常属于无监督学习的范畴，用于增强监督学习。</p><blockquote class="mm mn mo"><p id="8052" class="kf kg mp kh b ki kj jr kk kl km ju kn mq kp kq kr mr kt ku kv ms kx ky kz la ij bi translated">示例:假设我们有一个包含未分类图像的大型数据集。我们希望学习一个模型，从这些图像中提取一些有用的特征，这些特征可以帮助我们完成其他任务(如猫/狗识别)。我们在图像上随机应用9种不同的变形(或者不变形，所以有10种可能性)。然后，我们让一个模型去识别应用了哪种失真(如果有的话)。这样，我们希望模型将学会提取特征，然后可以在其他地方重用(如猫/狗识别)。</p></blockquote><h1 id="7bc0" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">STL-10——半监督学习的基准数据集</h1><p id="84be" class="pw-post-body-paragraph kf kg iq kh b ki mh jr kk kl mi ju kn ko mj kq kr ks mk ku kv kw ml ky kz la ij bi translated">在我们进入方法之前，让我们看一下我们将使用的数据集。<a class="ae mt" href="https://cs.stanford.edu/~acoates/stl10/" rel="noopener ugc nofollow" target="_blank"> STL-10数据集</a>由斯坦福大学的研究人员创建，灵感来自CIFAR-10，你可能听说过。STL-10由100，000个未标记图像和5，000个用于训练的标记图像以及8，000个用于测试的图像组成。图像平均分布在十个类中。</p><p id="4cc2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">打开<a class="ae mt" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>并创建一个具有GPU环境的新笔记本。首先，为了方便起见，安装一个Google Drive。STL-10很重，每次运行环境时重新下载可能不方便。在单元格中运行下面的代码，并按照说明操作。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">在Google Colab中安装Google Drive</p></figure><p id="93cd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，为STL-10数据集创建一个文件夹。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">为迷你项目和STL-10数据集创建一个文件夹/目录</p></figure><p id="9f0d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下载STL-10数据集。如您所见，我们也在这里定义了转型。我们这样做是因为，默认情况下，所有图像都是<a class="ae mt" href="https://pillow.readthedocs.io/en/stable/reference/Image.html" rel="noopener ugc nofollow" target="_blank"> PIL图像对象</a>，这对神经网络来说不是很方便。因此我们把它们转换成张量。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">下载数据集并将其加载到变量中</p></figure><p id="9da9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还应该为这些数据集定义数据加载器。试着自己去做！填写缺失的代码部分。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">为STL-10数据集创建数据加载器</p></figure><p id="5d0f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">太好了！正如您所看到的，批量大小被设置为128—这个值是我通过实验获得的，作为一个不会使Google Colab环境崩溃的值，但是您可以随意进行实验。</p><h1 id="3570" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">获得受监督的基线</h1><p id="5b74" class="pw-post-body-paragraph kf kg iq kh b ki mh jr kk kl mi ju kn ko mj kq kr ks mk ku kv kw ml ky kz la ij bi translated">首先，我们需要获得一个只有监督学习的基线，以便与半监督学习进行比较。使用下面的代码。如果你需要这段代码的解释，请在评论中告诉我。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">监督学习基线</p></figure><h1 id="eeca" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">引导你自己的潜能</h1><p id="c54b" class="pw-post-body-paragraph kf kg iq kh b ki mh jr kk kl mi ju kn ko mj kq kr ks mk ku kv kw ml ky kz la ij bi translated">BYOL(bootstrap your own latent)是一种自我监督的表征学习方法，于2020年1月首次发表，随后在顶级科学会议上发表。我们将实现这个方法。</p><h2 id="5ec5" class="nf lq iq bd lr ng nh dn lv ni nj dp lz ko nk nl mb ks nm nn md kw no np mf nq bi translated">粗略的概述</h2><p id="28d9" class="pw-post-body-paragraph kf kg iq kh b ki mh jr kk kl mi ju kn ko mj kq kr ks mk ku kv kw ml ky kz la ij bi translated">BYOL有两个网络——在线网络和目标网络。他们互相学习。我们拍摄一幅图像，并对其执行两种不同的放大操作(<em class="mp"> t </em>和<em class="mp">t’</em>)。一个增强图像(<em class="mp"> v </em>)被放到在线网络，并且第二个增强图像(<em class="mp">v’</em>)被馈送到目标网络。</p><figure class="mu mv mw mx gt my gh gi paragraph-image"><div role="button" tabindex="0" class="ns nt di nu bf nv"><div class="gh gi nr"><img src="../Images/0d6aaa2d181e670d2cbd2a3d9cba98c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TrJFAxcztYxLi9Ae7OJt6Q.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">图1 —架构概述(基于BYOL论文的图2；作者在Lucidchart中创建的图像)</p></figure><p id="7512" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在线网络将返回一些伪预测(它是<em class="mp">伪</em>，因为我们在这里没有实际的标签要预测)和目标网络—投影。两个输出都需要精确的尺寸。目标网络的输出将作为我们的地面实况。我们计算这些网络输出之间的均方误差。</p><p id="ee02" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们通过在线网络执行反向传播，但暂时离开目标网络。通过这样做，在线网络学会预测目标网络的输出。</p><p id="ab4e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">反向传播后，用在线网络参数的移动指数平均值更新目标网络。稍后我们会详细说明它的含义。</p><p id="e252" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在线网络从目标网络“快速”学习，目标网络从在线网络“缓慢”学习。在线网络试图尽可能接近目标网络的输出。</p><p id="53a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这种机制背后的直觉是，这两个网络的输出应该是相似的——它们都获得相同的图像，但具有不同的增强。如果我们有一张猫的图像，不管我们如何预处理它(在某种合理的程度上)，它仍然是一张猫的照片。在线网络学习目标网络对于图像中相同对象但具有不同“展示”的投影。</p><p id="19d5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在最后，在线网络的部分(编码器，<em class="mp"> fθ </em>)将被取出并用于监督学习。</p><p id="891b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你没有完全理解这个解释，不要担心——我们将一步一步地进行，所以你将有机会学习这个。</p><h2 id="c40f" class="nf lq iq bd lr ng nh dn lv ni nj dp lz ko nk nl mb ks nm nn md kw no np mf nq bi translated">对比学习</h2><p id="cf09" class="pw-post-body-paragraph kf kg iq kh b ki mh jr kk kl mi ju kn ko mj kq kr ks mk ku kv kw ml ky kz la ij bi translated">同样值得注意的是，这个架构是<strong class="kh ir">对比学习</strong>的一个例子。对比学习是一种技术，在这种技术中，我们试图获得尽可能相似的相似物体的表征(嵌入),但尽可能不同的不同图像的表征。你可以在<a class="ae mt" rel="noopener" target="_blank" href="/understanding-contrastive-learning-d5b19fd96607">这个中帖</a>里了解更多。BYOL最重要的区别是这种方法没有负对。有了这样的改进，它的计算变得更加简单，因此可以在免费的Google Colab环境中演示。</p><div class="ny nz gp gr oa ob"><a rel="noopener follow" target="_blank" href="/understanding-contrastive-learning-d5b19fd96607"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd ir gy z fp og fr fs oh fu fw ip bi translated">理解对比学习</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">学会无标签学习。</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">towardsdatascience.com</p></div></div><div class="ok l"><div class="ol l om on oo ok op nw ob"/></div></div></a></div><h2 id="437a" class="nf lq iq bd lr ng nh dn lv ni nj dp lz ko nk nl mb ks nm nn md kw no np mf nq bi translated">增加</h2><p id="0d48" class="pw-post-body-paragraph kf kg iq kh b ki mh jr kk kl mi ju kn ko mj kq kr ks mk ku kv kw ml ky kz la ij bi translated">如前所述，对图像执行了两种不同的放大。更具体地说，我们从两个不同的分布t ~τ和t′~τ′中抽取两个变换。发表在NIPS proceedings上的论文没有详细说明这些增强，但是发表在arXiv <a class="ae mt" href="https://arxiv.org/abs/2006.07733" rel="noopener ugc nofollow" target="_blank">上的预印本说明了这些增强。</a></p><p id="6b37" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你想了解最新的方法，你应该能够阅读科学论文。因此，我建议您阅读预印本的B部分(第16–17页),并实现函数中缺失的代码。由于缺少信息，文章中的一些值未被采用。<code class="fe oq or os ot b"><a class="ae mt" href="https://pytorch.org/vision/stable/transforms.html" rel="noopener ugc nofollow" target="_blank">torchvision.transforms</a></code>的文档应该会有帮助。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">图像增强代码</p></figure><h2 id="3df1" class="nf lq iq bd lr ng nh dn lv ni nj dp lz ko nk nl mb ks nm nn md kw no np mf nq bi translated">BYOL建筑的骨架</h2><p id="742b" class="pw-post-body-paragraph kf kg iq kh b ki mh jr kk kl mi ju kn ko mj kq kr ks mk ku kv kw ml ky kz la ij bi translated">让我们再看一下图1。</p><figure class="mu mv mw mx gt my gh gi paragraph-image"><div role="button" tabindex="0" class="ns nt di nu bf nv"><div class="gh gi nr"><img src="../Images/0d6aaa2d181e670d2cbd2a3d9cba98c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TrJFAxcztYxLi9Ae7OJt6Q.png"/></div></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">图1 —架构概述(基于BYOL论文的图2；作者在Lucidchart中创建的图像)</p></figure><p id="f9d0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以我们有图像(STL-10数据集)和增强。其余的呢？编码器(<em class="mp"> f </em>)可以是将给定图像转换成特征(表示)的任何网络，例如resnet18。投影(<em class="mp"> g </em>)负责从表示网络(编码器)的输出中创建更小的表示。预测层根据投影进行伪预测。</p><p id="140c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，这种架构是不对称的。作者假设它防止崩溃的解决方案(例如，为每个图像输出相同的向量，将给出MSE =0)。因此，预测图层需要具有相同的输入和输出维度，以便计算目标投影网络的输出和在线预测网络的输出之间的MSE。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">BYOL类的初始化方法</p></figure><h2 id="1933" class="nf lq iq bd lr ng nh dn lv ni nj dp lz ko nk nl mb ks nm nn md kw no np mf nq bi translated">实现投影仪</h2><p id="8f3f" class="pw-post-body-paragraph kf kg iq kh b ki mh jr kk kl mi ju kn ko mj kq kr ks mk ku kv kw ml ky kz la ij bi translated">正如你在上面看到的，<code class="fe oq or os ot b">BYOL.mlp</code>应该返回投影仪和预测器。那我们就这么做吧。第3.3节<em class="mp">实施细则</em>中的预印本规定:</p><blockquote class="mm mn mo"><p id="afa1" class="kf kg mp kh b ki kj jr kk kl km ju kn mq kp kq kr mr kt ku kv ms kx ky kz la ij bi translated">[……]表示y被多层感知器(MLP) gθ投影到更小的空间，对于目标投影gξ也是如此。此MLP包含一个输出大小为4096的线性图层，随后是批量归一化、校正线性单位(ReLU)，以及一个输出大小为256的最终线性图层。</p></blockquote><p id="9f7b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这意味着:</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">投影仪和预测器用MLP</p></figure><h2 id="b781" class="nf lq iq bd lr ng nh dn lv ni nj dp lz ko nk nl mb ks nm nn md kw no np mf nq bi translated">拟合模型</h2><p id="b6d2" class="pw-post-body-paragraph kf kg iq kh b ki mh jr kk kl mi ju kn ko mj kq kr ks mk ku kv kw ml ky kz la ij bi translated">我们将拟合模型到未标记数据分为四个步骤:</p><ul class=""><li id="2841" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">在未标记数据上训练(拟合)模型</li><li id="e15e" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">验证未标记的训练数据</li><li id="e45f" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">对验证数据进行验证(标签将被省略)</li><li id="b256" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">打印结果</li></ul><p id="1529" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以上所有步骤将重复<code class="fe oq or os ot b">epochs</code>次。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">训练和验证循环</p></figure><h2 id="b3ea" class="nf lq iq bd lr ng nh dn lv ni nj dp lz ko nk nl mb ks nm nn md kw no np mf nq bi translated">向前和向后传播</h2><p id="ef69" class="pw-post-body-paragraph kf kg iq kh b ki mh jr kk kl mi ju kn ko mj kq kr ks mk ku kv kw ml ky kz la ij bi translated">现在我们将关注代码中最关键的部分——在<code class="fe oq or os ot b">train_one_epoch</code>中的自我监督学习。请记住，您可以查看图1，并将其与代码进行比较。首先，我们必须将两个网络都设置为训练模式。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">将网络设置为训练模式</p></figure><p id="4e67" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后我们需要迭代<code class="fe oq or os ot b">DataLoader</code>返回的批次，放入GPU。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">将张量放入GPU</p></figure><p id="727d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正向传递将在一个单独的函数中实现，因为我们将在验证过程中重用它(<a class="ae mt" href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself" rel="noopener ugc nofollow" target="_blank">干规则</a>)。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">执行向前传球</p></figure><p id="8998" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们对损失张量进行反向传播…</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">添加了反向传播</p></figure><p id="ea1f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">…并更新目标网络的参数。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">在正向传递中更新目标网络</p></figure><p id="9454" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们来看一下<code class="fe oq or os ot b">forward</code>的方法。首先，我们需要用两种不同的增强函数来增强图像。我们使用<code class="fe oq or os ot b">torch.no_grad()</code>,因为我们不想通过这些转换执行反向传播。两个不同的增强图像被保存到<code class="fe oq or os ot b">v</code>和<code class="fe oq or os ot b">v_prime</code>变量中。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">批量数据上的图像增强</p></figure><p id="e187" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图像<code class="fe oq or os ot b">v</code>被送入在线网络，该网络返回伪预测。请注意，我们在这里不使用<code class="fe oq or os ot b">torch.no_grad()</code>，因为我们将在这个网络上进行反向传递。图像<code class="fe oq or os ot b">v_prime</code>通过<code class="fe oq or os ot b">torch.no_grad()</code>输入目标网络。两个输出都是<code class="fe oq or os ot b"><a class="ae mt" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.normalize.html" rel="noopener ugc nofollow" target="_blank">normalize</a></code> d和…</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">带有输出标准化的目标和在线网络的前向传递</p></figure><p id="bb94" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">…并计算这些输出的均方误差(或者更确切地说，是我们在<code class="fe oq or os ot b">__init__</code>中设置<code class="fe oq or os ot b">sum</code>减少时的<em class="mp">总和</em>均方误差)。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">损失的计算</p></figure><p id="5032" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该文件还指出:</p><blockquote class="mm mn mo"><p id="a8d6" class="kf kg mp kh b ki kj jr kk kl km ju kn mq kp kq kr mr kt ku kv ms kx ky kz la ij bi translated">我们通过分别向在线网络提供v’和向目标网络提供v来计算[loss]，从而对称化损失[…]。</p></blockquote><p id="a7a1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面的代码引入了这种对称损失。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">对称损失函数</p></figure><p id="9560" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们只剩下更新目标网络了。还记得<code class="fe oq or os ot b">__init__</code>中定义的<code class="fe oq or os ot b">self.tau</code>吗？这是一个衰减参数。目标网络的参数<em class="mp"> ξ </em>在第<em class="mp"> i </em>步用在线网络的参数<em class="mp"> θ </em>更新:</p><figure class="mu mv mw mx gt my gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/fb4b7f3df8d21f7d9ec892aebd1bbfb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/format:webp/1*NnQdQr0dU23lAIYv_DkRfg.png"/></div></figure><p id="cea2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个等式你可能已经很熟悉了。它定义了在每个步骤(批次)中更新的一系列参数<em class="mp"> θ </em>的<strong class="kh ir">指数移动平均值</strong>。它用于<a class="ae mt" href="https://en.wikipedia.org/wiki/Exponential_smoothing" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">指数平滑</strong></a><strong class="kh ir"/>——我们平滑时间序列的过程。在这种情况下，目标网络的参数“消除”在线网络中参数的“快速”变化。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">用在线网络的指数移动平均值更新目标网络</p></figure><p id="7645" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是<code class="fe oq or os ot b">BYOL</code>类的最终代码，也包括验证过程和运行训练的代码。我们将只运行一个时期的自我监督学习，因为在Google Colab上这样做通常需要一个小时。你可以把<code class="fe oq or os ot b">train_loss = self.validate(train_dl)</code>改成<code class="fe oq or os ot b">train_loss = 0</code>来节省一些时间。</p><p id="bcc2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">resnet18的最后一层被替换为<code class="fe oq or os ot b">Identity</code>层——这样，我们将获得该网络提取的特征，而不是对1000个类别的预测。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">完整的BYOL等级代码及其用法</p></figure><h1 id="f060" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">半监督学习</h1><p id="546a" class="pw-post-body-paragraph kf kg iq kh b ki mh jr kk kl mi ju kn ko mj kq kr ks mk ku kv kw ml ky kz la ij bi translated">现在，让我们把自我监督学习和监督学习结合起来。首先，我们从BYOL类中取出在线编码器(<em class="mp"> fθ </em>)并创建一个副本。因为我们想要预测十个类，我们将用<code class="fe oq or os ot b">Linear</code>替换最后的<code class="fe oq or os ot b">Identity</code>层。如果要冻结网络的编码部分，可以通过取消代码注释来实现。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">使用在未标记数据上训练的resnet18的半监督学习</p></figure><h1 id="fd01" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">结果</h1><p id="3567" class="pw-post-body-paragraph kf kg iq kh b ki mh jr kk kl mi ju kn ko mj kq kr ks mk ku kv kw ml ky kz la ij bi translated">现在，我们用<a class="ae mt" href="https://davidmathlogic.com/colorblind/#%23FFC20A-%230C7BDC" rel="noopener ugc nofollow" target="_blank">色盲友好型托盘</a>绘制图表，比较监督和半监督学习的性能。</p><figure class="mu mv mw mx gt my"><div class="bz fp l di"><div class="mz na l"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">代码生成学习曲线</p></figure><p id="ec08" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如你在下面看到的，与监督学习相比，半监督学习获得了稍微好一点的结果。</p><div class="mu mv mw mx gt ab cb"><figure class="ov my ow ox oy oz pa paragraph-image"><img src="../Images/9971e4cd6c5da5a5125d0129a16b952c.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*tnjQd2SHgF09DrScewVPXQ.png"/></figure><figure class="ov my ow ox oy oz pa paragraph-image"><img src="../Images/9bd42bf371a233ef12bae4f74543b449.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*6Ov_HJ7-ZwcWUA8ORQCh6A.png"/><p class="nb nc gj gh gi nd ne bd b be z dk pb di pc pd translated">图2——监督学习和半监督学习的性能比较。由于DataLoader中参数初始化和批次洗牌的随机性，您的结果可能会有所不同。作者创造的形象。</p></figure></div><h1 id="e4fa" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">结论</h1><p id="d37b" class="pw-post-body-paragraph kf kg iq kh b ki mh jr kk kl mi ju kn ko mj kq kr ks mk ku kv kw ml ky kz la ij bi translated">我们从只使用有标签的数据进行监督训练转变为利用无标签的数据进行自我监督和半监督学习。正如你所看到的，我们在结果上没有得到显著的差异，但我们仍然表明，在某些情况下，使用半监督学习可以改善结果。</p><p id="33e4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我鼓励你尝试这段代码——也许改变优化器，τ(<em class="mp">τ</em>)，编码器架构？如果你有一些令人兴奋的发现或者这篇文章对你的用例有帮助，请留下评论。我想听听这件事。</p><p id="32ae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">感谢您阅读本教程。如果你喜欢它，请在Medium上关注我——它将帮助我发展我的博客并继续我的工作。非常感谢您的评论、反馈和新想法！</p></div></div>    
</body>
</html>