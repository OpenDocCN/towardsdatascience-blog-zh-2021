<html>
<head>
<title>How do Decision Trees and Random Forests Work? 1b</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">决策树和随机森林是如何工作的？1b</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-do-decision-trees-and-random-forests-work-15cc2a925788?source=collection_archive---------27-----------------------#2021-11-15">https://towardsdatascience.com/how-do-decision-trees-and-random-forests-work-15cc2a925788?source=collection_archive---------27-----------------------#2021-11-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9c0f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">回归树</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8ae2d310d7115e8b051c8daa0424dd9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PwrTjqM1mjT17Z7TAdjQ0w.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">杰里米·毕晓普在<a class="ae kv" href="https://unsplash.com/s/photos/tree?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="4bd5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本系列的<a class="ae kv" rel="noopener" target="_blank" href="/how-do-decision-trees-and-random-forests-work-66a1094e6c5d">第1部分</a>中，我谈到了决策树是如何工作的。(如果你还没看过那篇文章，我建议你回去读一读再继续。去吧。我会等的。)那篇文章主要集中在分类上，例如是/否、活/死等。好吧，决策树也可以用于回归——例如，预测一个连续变量。决策树的许多方面都是相同的，但是预测答案的方式略有不同。</p><p id="d878" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于这篇文章，我将使用来自<a class="ae kv" href="https://dockship.io/challenges/5fa1f40ac2a4984b34ef0a66/power-plant-energy-prediction-ai-challenge/overview" rel="noopener ugc nofollow" target="_blank"> Dockship.io挑战赛</a>的数据集:发电厂能源预测人工智能挑战赛。这项挑战使用四个输入变量来预测发电厂的能量输出(PE)。以下是数据集中的前六条记录:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/19b99a31cc48d5afe0fc89d6a2128f4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*nAXb3v9txHRZgbz2JvCYDA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者截图</p></figure><p id="76e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在哪里，</p><ul class=""><li id="2052" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr ly lz ma mb bi translated">AT =环境温度</li><li id="e624" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">AP =环境压力</li><li id="6292" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">V =排气速度</li><li id="4216" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">RH =相对湿度</li></ul></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><p id="9281" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">回归树所做的是对某一组条件取平均值，并将其用作预测。整个数据集的PE平均值是454.31，所以这是对根节点的预测。</p><p id="12a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您还记得第1部分，在分类树中，熵用于决定如何将数据分成不同的分支。熵本质上是无序或不确定性的度量。对于连续变量，我们可以使用标准差(SD)来达到同样的目的。然后我们想尽可能地降低整体标准差。我们数据集的标准偏差是17.06。计算总体标准差的方式与我们之前计算总体熵的方式非常相似——它只是一个加权平均值。将分数百分比和每个分数的标准偏差的乘积相加。</p><p id="08f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以，让我们从温度开始，从平均温度19.68开始。如果我们观察功率输出的平均值和标准差，我们得到:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/861c49765e65eebc9dcd904a91ed8d1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*Js7TfsB6Kity6KIN3TwIxw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者截图</p></figure><p id="02e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，我们看到标准偏差通过这种简单的分割大大降低了(从17.06到9.12)。如果AT小于19.68，这个极其简单的模型将预测469.42的功率输出，如果AT为19.68或更大，将预测440.71的功率输出。</p><p id="dde2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们用其他三个输入变量的平均值做同样的事情，我们得到:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/69209319fa83de7096f1808e0d01ca76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kUyVHcL2sUoLSRYyO8F-Nw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者截图</p></figure><p id="cd61" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由此，我们看到平均温度为我们提供了最佳的SD降低。当然，正如我们在第1部分中看到的，我们不必(也不应该)满足于此。例如，如果我们以中位数(20.32)而不是平均值分割温度，我们得到的总标准差为9.22，减少了7.84。所以平均温度是一个比中位数更好的分割值。该算法将为每个变量尝试不同的分割值，以获得可能的最佳SD减少。</p></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><p id="13c8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦我们有了第一次拆分，我们可以尝试进一步拆分前两个组。然后这些可以被分割，等等。这是从R的rpart()函数得到的树，带有标准参数。(注意:只有整个数据集的70%被用作创建此决策树的训练集。)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/89c59240ac72a51d6660fe20d5890250.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QH2Ccq0XIBHoF7Z05DGNUQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者截图</p></figure><p id="c353" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如您所见，在这个决策树中，只有两个变量是有用的。如果我用这个作为预测模型，你会发现它非常粗糙。毕竟只有五个叶节点，你的预测只能得到五种可能的答案。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/5251d67732e030aa970437f6523b4241.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tdmhXPp6jZB3s5MefvC2Qg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者截图</p></figure><p id="0bac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是回归树模型的一个局限性。它处理平均值。一个相关的限制是<strong class="ky ir"> <em class="ms">它不能外推训练数据之外的</em> </strong>。毕竟你不可能得到一个小于最低值或者大于最大值的平均值。</p><p id="e167" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然我们对后者的限制无能为力，但我们<em class="ms">可以</em>避开前者。如果我们可以创建许多略有不同的决策树，我们可以得到许多不同的可能叶节点，以及许多不同的可能答案。如果我们可以将所有不同树的结果平均，我们可以得到更好的预测能力。这就是随机森林的用武之地，这将是本系列下一部分的主题。</p></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><h1 id="a79f" class="mt mu iq bd mv mw mx my mz na nb nc nd jw ne jx nf jz ng ka nh kc ni kd nj nk bi translated">进一步阅读</h1><div class="nl nm gp gr nn no"><a rel="noopener follow" target="_blank" href="/how-do-decision-trees-and-random-forests-work-66a1094e6c5d"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd ir gy z fp nt fr fs nu fu fw ip bi translated">决策树和随机森林是如何工作的？</h2><div class="nv l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">towardsdatascience.com</p></div></div><div class="nw l"><div class="nx l ny nz oa nw ob kp no"/></div></div></a></div><div class="nl nm gp gr nn no"><a href="https://www.saedsayad.com/decision_tree_reg.htm" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd ir gy z fp nt fr fs nu fu fw ip bi translated">决策树回归</h2><div class="oc l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">地图&gt;数据科学&gt;预测未来&gt;建模&gt;回归&gt;决策树决策树构建回归或…</h3></div><div class="nv l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">www.saedsayad.com</p></div></div></div></a></div><div class="nl nm gp gr nn no"><a rel="noopener follow" target="_blank" href="/use-rattle-to-help-you-learn-r-d495c0cc517f"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd ir gy z fp nt fr fs nu fu fw ip bi translated">用拨浪鼓来帮助你学习R</h2><div class="oc l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">初学者指南</h3></div><div class="nv l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">towardsdatascience.com</p></div></div><div class="nw l"><div class="od l ny nz oa nw ob kp no"/></div></div></a></div><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oe of l"/></div></figure></div></div>    
</body>
</html>