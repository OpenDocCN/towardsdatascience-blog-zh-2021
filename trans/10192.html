<html>
<head>
<title>How to get high score using MMBT and CLIP in Hateful Memes Competition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在仇恨模因比赛中使用MMBT和剪辑获得高分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-get-high-score-using-mmbt-and-clip-in-hateful-memes-competition-90bfa65cb117?source=collection_archive---------20-----------------------#2021-09-27">https://towardsdatascience.com/how-to-get-high-score-using-mmbt-and-clip-in-hateful-memes-competition-90bfa65cb117?source=collection_archive---------20-----------------------#2021-09-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bf93" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用剪辑作为一个多模态双变压器的特征编码器，使MMBT真正与拥抱脸变压器工作，以获得惊人的高精度</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/059f151808964d79265094a7b0568f6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uN62waNvz7jjOdR6Ptr8MQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://pixabay.com/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>上的<a class="ae ky" href="https://pixabay.com/ru/illustrations/%d0%bf%d0%be%d0%bb%d0%b8-%d0%bd%d0%b8%d0%b7%d0%ba%d0%b8%d0%b9-%d0%b6%d0%b8%d0%b2%d0%be%d1%82%d0%bd%d0%be%d0%b5-%d0%b2%d0%b5%d0%ba%d1%82%d0%be%d1%80-3295856/" rel="noopener ugc nofollow" target="_blank"> Manuchi </a>拍摄</p></figure><p id="ece4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">来自脸书的<a class="ae ky" href="https://www.drivendata.org/competitions/64/hateful-memes/" rel="noopener ugc nofollow" target="_blank">仇恨迷因竞赛</a>的附加阶段几个月前就结束了。我的团队很幸运地参加了这次比赛，甚至取得了相当不错的成绩(我们获得了第十名)。我们是怎么做的，用了什么方法——我会在这篇文章里告诉你。</p><h1 id="5e99" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">问题描述</h1><p id="fe09" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">乍一看，比赛中必须解决的问题非常简单——使用文本和图像数据来确定一个模因是否可恶。事实上，由于我们讲话中固有的许多模糊性，以及讽刺和讽刺的存在，问题变得复杂了，因为神经网络的定义有问题。你可以在相应的<a class="ae ky" href="https://arxiv.org/pdf/2005.04790v2.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中读到更多关于竞争和它所带来的任务的信息。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/98617e8b3e402d9cb8c2384a09ce43e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7xFnnnz_rqN7uybg4IxE4w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://unsplash.com" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><h1 id="e970" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据概述</h1><p id="7e19" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">比赛期间，提供了一个可下载的zip文件。现在比赛数据可以在这个<a class="ae ky" href="https://hatefulmemeschallenge.com/" rel="noopener ugc nofollow" target="_blank">链接</a>找到。</p><p id="456f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">zip文件包括一个包含图像的文件夹和几个包含图像注释的json文件。</p><p id="3b79" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> img/ </strong>文件夹包含挑战数据集的所有图像，包括训练、开发和测试分割。这些图像被命名为&lt; id &gt;。png，其中&lt; id &gt;是一个唯一的5位数。</p><p id="1799" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> train.jsonl，dev_seen.jsonl，dev_unseen.jsonl </strong> — json文件，其中每一行都有一个关于图像的数据的键值对的字典。该词典包括</p><ul class=""><li id="448e" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">id</strong>img目录和。jsonl文件，例如，“id”:13894。</li><li id="72ef" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu"> img </strong>实际的meme文件名，例如“img”:img/13894 . png，注意文件名包含上面描述的img目录，文件名词干是id。</li><li id="7845" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">文本</strong>嵌入在meme图像中的原始文本串，例如，img/13894.png具有“文本”:“给你的宠物戴上蝴蝶结”</li><li id="c7e2" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">标注</strong>其中1 - &gt;“可恨”和0 - &gt;“非可恨”</li></ul><p id="71fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如:</p><p id="9ba3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">{"id":23058，" img":"img/23058.png "，" label":0，" text ":"不要害怕再爱一次每个人都不像你的前任" }</p><p id="a4b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> test_seen.jsnol </strong>包括所提到的按键，除了<strong class="lb iu">标签</strong>。</p><h1 id="fc2a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">绩效指标</h1><p id="3254" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">使用<a class="ae ky" href="https://medium.com/greyatom/lets-learn-about-auc-roc-curve-4a94b4d88152" rel="noopener"> <strong class="lb iu"> AUC ROC </strong> </a>或受试者工作特征曲线下的面积来确定模型性能和排行榜排名。该指标用于衡量二元分类器在不同决策阈值下区分不同类别的能力。</p><p id="2182" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个衡量标准是预测的准确性，由正确预测与预测总数的比率给出。</p><h1 id="61a1" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">我们的方法</h1><p id="fb80" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">有许多处理多模态数据的模型和框架，其中最突出的是来自脸书的MMF。<a class="ae ky" href="https://mmf.sh/" rel="noopener ugc nofollow" target="_blank"> MMF </a>为访问许多强大的多模态模型提供了一个简单的接口。但是，作为《拥抱脸变形金刚》的超级粉丝，我们决定不走捷径。我们决定找出<a class="ae ky" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank">变形金刚</a>中有哪些多模态模型，以及如何最大限度地利用它们。原来这种型号目前在《变形金刚》里只有一款——<a class="ae ky" href="https://huggingface.co/transformers/summary.html#multimodal-models" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">【多模态双变压器(MMBT) </strong> </a>。让这个模型工作起来并不容易，但是这让这个任务变得更加有趣。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/65a13126133002aadbfaebba6fb9077d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wVs2yKRewYHr-3f5CwVL9A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">MMBT建筑，来自<a class="ae ky" href="https://arxiv.org/abs/1909.02950" rel="noopener ugc nofollow" target="_blank">监督的多模式双转换器，用于对图像和文本纸张进行分类</a></p></figure><p id="7a8c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">MMBT融合来自文本和图像编码器的信息。<a class="ae ky" href="https://huggingface.co/transformers/model_doc/bert.html" rel="noopener ugc nofollow" target="_blank"> BERT </a>用作文本编码器，<a class="ae ky" href="https://pytorch.org/hub/pytorch_vision_resnet/" rel="noopener ugc nofollow" target="_blank"> ResNet </a>用作图像编码器。我们利用MMBT架构的灵活性，用<a class="ae ky" href="https://github.com/openai/CLIP" rel="noopener ugc nofollow" target="_blank">剪辑</a>替换ResNet进行图像编码。<strong class="lb iu"> CLIP </strong>预训练图像编码器和文本编码器，以预测数据集中哪些图像与哪些文本配对。我们的假设是CLIP的特性更加通用，更适合多模态领域。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/c5611c6f16459ec2dc537be100946454.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HCqEtbXiWze0t9Sd.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">摘要剪辑模型的方法，来自<a class="ae ky" href="https://arxiv.org/abs/2103.00020" rel="noopener ugc nofollow" target="_blank">从自然语言监督论文</a>中学习可转移的视觉模型</p></figure><p id="0514" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于文本编码，我们使用了<a class="ae ky" href="https://huggingface.co/Hate-speech-CNERG/bert-base-uncased-hatexplain" rel="noopener ugc nofollow" target="_blank">Bert-base-un cased-hat explain</a>模型，该模型在Huggingface Hub中可用。该模型是为英语中的hatespeech检测而创建的，因此在我们的情况下，它的特征比最初在MMBT使用的<a class="ae ky" href="https://huggingface.co/bert-base-uncased" rel="noopener ugc nofollow" target="_blank"> bert-base-uncased </a>要好。</p><p id="f30b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最终的MMBT模型在训练数据集上进行了微调，并在dev_seen数据集上进行了验证。</p><p id="ebc5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还使用受控的<a class="ae ky" href="https://huggingface.co/transformers/model_doc/gpt2.html" rel="noopener ugc nofollow" target="_blank"> GPT-2 </a>和<a class="ae ky" href="https://github.com/dsfsi/textaugment#eda-easy-data-augmentation-techniques-for-boosting-performance-on-text-classification-tasks" rel="noopener ugc nofollow" target="_blank">简易数据扩充</a>方法扩充了训练数据集中的文本。这使我们的模型的准确性增加了几个百分点。增强超出了本文的范围，如果您对本文和我们的方法感兴趣，我可能会单独写一篇。</p><h1 id="89da" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">履行</h1><p id="cde8" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在文章的这一部分会有很多代码，但是为了更好的理解，我会尝试详细解释所有重要的部分。</p><p id="ca1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们导入所需的库。我们需要</p><ul class=""><li id="d98f" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">变压器版本&gt; =4.8.2</li><li id="0d79" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">Pytorch版本1.8.1</li><li id="c0ad" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">火炬视觉0.9.1</li><li id="0df9" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">sci kit-学习0.23.2</li><li id="ff76" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">枕头&gt; =8.2.0</li><li id="a9e5" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">tqdm &gt;= 4.60.0</li><li id="b58a" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">matplotlib &gt;= 3.3.4</li><li id="1992" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">数字&gt; =1.19.5</li><li id="2aa7" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" href="https://github.com/openai/CLIP" rel="noopener ugc nofollow" target="_blank">夹子</a>(可以从仓库安装)。</li></ul><p id="05ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">CLIP现在<a class="ae ky" href="https://huggingface.co/transformers/model_doc/clip.html" rel="noopener ugc nofollow" target="_blank">可以直接在Huggingface Transformers中</a>访问，但在实现我们的方法时，它还不存在。为了充分利用我们的模型，我们还使用了<a class="ae ky" href="https://github.com/facebookresearch/madgrad" rel="noopener ugc nofollow" target="_blank"> MADGRAD </a>优化器。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="0ac1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用可用的设备创建一个变量，它将完成所有需要的计算。我们将需要一个GPU，所以我们的设备是CUDA。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="4e84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">加载剪辑模型和所需的预处理。初始化需要的变量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="131a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">创建一个以特殊方式为剪辑编码器准备图像的函数。该功能将图像分割成三个图块(根据图像的长宽比，按高度或宽度)。最后，我们将在编码后得到四个矢量(每个图块一个矢量，填充为正方形的整个图像一个矢量)。使用这种方法，我们将从图像中获得更多的信息，因为我们将创建嵌入，不仅描述图像的整体，还描述图像的各个部分</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="7b07" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">定义一个函数，它将从剪辑中获取图像特征。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="38b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">创建将加载文本和预处理图像的JsonlDataset类。创建<strong class="lb iu"> collate_fn </strong>，以pytorch模型所需的格式对数据集中的数据进行分组。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="82b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">定义<strong class="lb iu"> load_examples </strong>函数，将json数据集中描述的数据加载到json dataset对象中。创建函数来加载和保存模型权重。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="be87" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">创建了所需的函数和类，因此我们可以加载我们的模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="1bb1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">加载训练和评估数据集，并为这些数据集创建数据加载器。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="4434" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">定义模型训练参数、优化器和损失。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="5927" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">定义评估函数，该函数将获取评估数据加载器并计算预测AUC、<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html" rel="noopener ugc nofollow" target="_blank"> F1得分</a>和准确性。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="cede" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们可以训练我们的模型。我们在<strong class="lb iu"> best_valid_auc </strong>变量中指定了所需的最小auc值，因此，如果模型在验证数据上获得了比指定值更高的AUC，我们将保存该模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="a533" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练完成后，我们可以看到结果:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/e5778141ad2e9dcc17a446aee1f9a265.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*hp7swfkYCWPFzzcpFlXuCA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图像由Rostyslav Neskorozhenyi使用<a class="ae ky" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank"> Matplotib </a>创建</p></figure><h1 id="2204" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">为提交做预测</h1><p id="3051" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在我们可以对测试数据进行预测。首先，我们将通过模拟训练阶段来创建数据加载和处理所需的类和函数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="b663" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们做一个预测，并以指定的格式保存它。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="93df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就是这样。如果比赛重新开始，这个预测文件可以立即发送到那里。</p><h1 id="e12e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="0964" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在这篇文章中，我试图详细描述我们在脸书的仇恨迷因竞赛中使用的方法的概念和实现。比赛给我们设置的任务变得非常有趣，我们在开发解决这些任务的方法时获得了很多乐趣。我希望你也喜欢阅读这篇文章。</p><p id="b3ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我还想提一下，为了获得最大AUC，我们结合了用不同损失参数和不同增强选项训练的该模型的几个变体的预测。但是这是另一篇完全不同的文章的主题。</p><p id="7703" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文章中描述的所有代码都可以通过这个<a class="ae ky" href="https://github.com/slanj/ml-notebooks/blob/main/multimodal-article.ipynb" rel="noopener ugc nofollow" target="_blank">链接</a>作为jupyter笔记本获得。</p></div></div>    
</body>
</html>