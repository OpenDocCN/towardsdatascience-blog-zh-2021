<html>
<head>
<title>Feature Selection and EDA in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的特征选择和EDA</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/feature-selection-and-eda-in-python-c6c4eb1058a3?source=collection_archive---------5-----------------------#2021-05-24">https://towardsdatascience.com/feature-selection-and-eda-in-python-c6c4eb1058a3?source=collection_archive---------5-----------------------#2021-05-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0ba0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><strong class="ak"> <em class="ki">如何利用数据可视化来指导特征选择</em> </strong></h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/40799f7af0f3a9bdf1670241123cc1de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o2T5RMUA-oXrjUN8h5rfcQ.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">功能选择和EDA备忘单(图片由作者提供，来自<a class="ae kz" href="https://www.visual-design.net/post/feature-selection-and-eda-in-machine-learning" rel="noopener ugc nofollow" target="_blank">网站</a></p></figure><p id="b043" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在机器学习生命周期中，特征选择是选择与预测相关的输入特征子集的关键过程。包含不相关的变量，尤其是那些数据质量差的变量，通常会污染模型输出。</p><p id="666c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">此外，特征选择具有以下优点:</p><p id="0c3e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">1) <strong class="lc iu">避免维数灾难</strong>，因为一些算法在高维时表现不佳，例如一般线性模型、决策树</p><p id="d747" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">2) <strong class="lc iu">降低计算成本</strong>以及大量数据带来的复杂性</p><p id="0e79" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">3) <strong class="lc iu">减少过拟合</strong>，模型更有可能推广到新数据</p><p id="e218" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">4) <strong class="lc iu">增加模型的可解释性</strong></p><p id="967c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在本文中，我们将讨论两种主要的特征选择技术:<strong class="lc iu">过滤方法</strong>和<strong class="lc iu">包装方法</strong>，以及如何利用数据可视化来指导决策制定。</p><h1 id="8f0b" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">数据预处理</h1><p id="3e53" class="pw-post-body-paragraph la lb it lc b ld mo ju lf lg mp jx li lj mq ll lm ln mr lp lq lr ms lt lu lv im bi translated">在进入特征选择之前，我们应该加载数据集，执行数据预处理和数据转换:</p><p id="825c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu"> 1。加载数据集和导入库</strong></p><p id="cc61" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我正在使用来自Kaggle的信用卡客户数据集来预测谁更有可能被炒鱿鱼。</p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="3d3a" class="my lx it mu b gy mz na l nb nc">import pandas as pd  <br/>import numpy as np  <br/>import seaborn as sns  <br/>import matplotlib.pyplot as plt  <br/>from pandas.api.types import is_string_dtype, is_numeric_dtype    </span><span id="eaab" class="my lx it mu b gy nd na l nb nc">df = pd.read_csv("../input/credit-card-customers/BankChurners.csv")</span></pre><p id="690f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">现在让我们看一下原始数据。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ne"><img src="../Images/f8693c12513bc3d81c35de3fe2e1335a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FDkCD0rh0eZQxyzSn8CjDw.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">信用卡客户数据集(图片由作者提供)</p></figure><p id="32bf" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu"> 2。定义预测:</strong>这个练习是一个分类问题，从中我们预测二元变量“Attrition _ Flag”，它可以是现有客户，也可以是流失的客户。</p><p id="434d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu"> 3。检查缺失数据:</strong></p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/4cea3b173cec44027f6b0aceedd496dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*MX6MNBEkjKS6OSMCAgymAg.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">缺失数据(图片由作者提供)</p></figure><p id="94b5" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">幸运的是，该数据集不包含任何缺失值，但情况并非总是如此。如果您想了解更多关于如何处理丢失数据的信息，这篇文章可能会对您有所帮助。</p><div class="ng nh gp gr ni nj"><a href="https://medium.com/analytics-vidhya/how-to-address-missing-data-531ed964e68" rel="noopener follow" target="_blank"><div class="nk ab fo"><div class="nl ab nm cl cj nn"><h2 class="bd iu gy z fp no fr fs np fu fw is bi translated">如何处理丢失的数据</h2><div class="nq l"><h3 class="bd b gy z fp no fr fs np fu fw dk translated">三种缺失数据的解决方法</h3></div><div class="nr l"><p class="bd b dl z fp no fr fs np fu fw dk translated">medium.com</p></div></div><div class="ns l"><div class="nt l nu nv nw ns nx kt nj"/></div></div></a></div><p id="2cb1" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu"> 4。变量转换:</strong>这个过程包括对分类变量进行编码，并将所有变量转换成相同的尺度。我分别选择了标签编码器和最小-最大缩放。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/9c1647feca510b702c8e6907ce4a2836.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*PeWdNvDTQWqMutoQYFueIQ.png"/></div></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/16e921cb6c8551c0b1ca28102a203904.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*WHQDFi98NqwZXlZArwxjBQ.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">变量转换(图片由作者提供)</p></figure><p id="e5e6" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果您想了解更多数据转换技术，请查阅这篇文章:</p><div class="ng nh gp gr ni nj"><a rel="noopener follow" target="_blank" href="/data-transformation-and-feature-engineering-e5181ef274b5"><div class="nk ab fo"><div class="nl ab nm cl cj nn"><h2 class="bd iu gy z fp no fr fs np fu fw is bi translated">数据转换和特征工程</h2><div class="nq l"><h3 class="bd b gy z fp no fr fs np fu fw dk translated">如何为您的数据选择合适的技术</h3></div><div class="nr l"><p class="bd b dl z fp no fr fs np fu fw dk translated">towardsdatascience.com</p></div></div><div class="ns l"><div class="oa l nu nv nw ns nx kt nj"/></div></div></a></div><h1 id="5ae2" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">探索性数据分析</h1><p id="29f8" class="pw-post-body-paragraph la lb it lc b ld mo ju lf lg mp jx li lj mq ll lm ln mr lp lq lr ms lt lu lv im bi translated">数据可视化和EDA是特性选择过程的重要补充工具，可以通过以下方式应用:</p><ol class=""><li id="fdea" class="ob oc it lc b ld le lg lh lj od ln oe lr of lv og oh oi oj bi translated"><strong class="lc iu">单变量分析:直方图</strong>和<strong class="lc iu">条形图</strong>有助于可视化每个变量的分布和方差</li><li id="d9bd" class="ob oc it lc b ld ok lg ol lj om ln on lr oo lv og oh oi oj bi translated"><strong class="lc iu">相关性分析:热图</strong>便于识别高度相关的解释变量，减少共线性</li><li id="a782" class="ob oc it lc b ld ok lg ol lj om ln on lr oo lv og oh oi oj bi translated"><strong class="lc iu">双变量分析:箱线图</strong>和<strong class="lc iu">分组条形图</strong>有助于发现解释变量和响应变量之间的相关性和关系</li></ol><p id="95cf" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><em class="op">(为了更好的理解数据，可以在数据转换前进行探索性的数据分析)</em></p><p id="e69b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">单变量分析—直方图和条形图</strong></p><p id="762e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">为了获得分布的概观，首先让我们将特征分类为分类变量和数值变量，然后使用条形图可视化分类特征，使用直方图可视化数值特征。可视化分布给出了关于数据点是更密集还是更分散的建议，从而给出了方差是低还是高的建议。低方差特征往往对结果变量的预测贡献较小。</p><div class="kk kl km kn gt ab cb"><figure class="oq ko or os ot ou ov paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/78bfd00ad0088a9df953502e9988e355.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*9q1sQDnHFbpukhrFpp_bHw.png"/></div></figure><figure class="oq ko ow os ot ou ov paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/3b676b6ea470abb9382c2604ed8bf65b.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*2dxI0VsvNQd31PWqIvfIQA.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk ox di oy oz translated">单变量分析(图片由作者提供)</p></figure></div><p id="61d7" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">关联分析—热图</strong></p><p id="2bff" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">一些算法要求解释变量中没有共线性，包括将用于本练习的逻辑回归。因此，消除高度相关的特征是避免这种潜在缺陷的必要步骤。使用热图可视化的相关性分析突出显示相关系数高的要素对。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi pa"><img src="../Images/ae023fe943708b754af956a2ec1128bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o4Q5nyEoC5bvfOr0VH2t9A.png"/></div></div></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi pb"><img src="../Images/33028bd1f69960d91b775435e8af1d81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wI9n5Cw9KsXHSJ4pmGO8TQ.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">相关性分析和热图(图片由作者提供)</p></figure><p id="7e95" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如图所示，不难发现以下几对高度相关的特征:</p><ul class=""><li id="0cbb" class="ob oc it lc b ld le lg lh lj od ln oe lr of lv pc oh oi oj bi translated"><em class="op">Customer _ Age&amp;Month _ on _ Book(0.79)</em></li><li id="f80f" class="ob oc it lc b ld ok lg ol lj om ln on lr oo lv pc oh oi oj bi translated"><em class="op">合计_交易_金额&amp;合计_交易_金额(0.82) </em></li><li id="8e72" class="ob oc it lc b ld ok lg ol lj om ln on lr oo lv pc oh oi oj bi translated"><em class="op">Avg _ Open _ To _ Buy&amp;Credit _ Limit(1)</em></li></ul><p id="f00b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">基于这个结果，我放弃了以下变量:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/99f3263c5dcf84bbf59df08f46125c41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*UnGhpG4AHP2OYxjGSSTShQ.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">丢弃高度相关的要素</p></figure><p id="7037" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">双变量分析—箱线图和分组条形图</strong></p><p id="a2b9" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">双变量EDA研究每个解释变量和目标变量之间的关系。分类特征和数值变量分别使用<strong class="lc iu">分组条形图</strong>和<strong class="lc iu">箱线图</strong>进行处理，这种探索可以进一步促进过滤方法中使用的统计检验，例如卡方检验和ANOVA检验。</p><blockquote class="pe pf pg"><p id="114c" class="la lb op lc b ld le ju lf lg lh jx li ph lk ll lm pi lo lp lq pj ls lt lu lv im bi translated">G <strong class="lc iu"> <em class="it">圆形条形图作为卡方分析</em> </strong>的直观表示</p></blockquote><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/144dbee2bdd3e2522fbb44b3c74824b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*s6JsimWPGv_bHKiE.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">分组条形图代码</p></figure><p id="7588" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">每个自变量被设置为主要类别。使用hue = " attachment _ Flag "将目标变量设置为二级类别。结果，它描述了“损耗_标志”是否会在主要类别的不同级别的分布中变化。如果两个变量是独立的，那么我们期望所有水平的分布是相同的。</p><p id="b23c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这与卡方检验的逻辑相同，卡方检验基于独立性假设计算观察值和期望值之间的差异。如果不存在或存在很少的相关性，我们希望每组条形的比率与流失客户与现有客户的比率成比例。如果比率显著不同，则表明观察值和期望值之间的差异较大，这意味着卡方值较高，因此拒绝了两个变量独立的假设。</p><p id="b902" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">根据目标标签绘制所有类别变量后，我发现<em class="op">“Card _ Category”</em>似乎显示了<em class="op">蓝色、金色、银色和铂金</em>的比例变化。在接下来的部分，我们将根据基于过滤方法的定量评分来了解这是否属实。</p><div class="kk kl km kn gt ab cb"><figure class="oq ko pl os ot ou ov paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/85b02b1dcd8f52fa428c7a3c83da43ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*27CfRLwGk6FNzT3KJdLQLg.png"/></div></figure><figure class="oq ko pm os ot ou ov paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><img src="../Images/2fb920aa77e3462ed5f3312eb8350376.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*P1qHYNpdAiCTKgoJM1rgaQ.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk pn di po oz translated">分组条形图结果(作者图片)</p></figure></div><blockquote class="pe pf pg"><p id="3d28" class="la lb op lc b ld le ju lf lg lh jx li ph lk ll lm pi lo lp lq pj ls lt lu lv im bi translated"><strong class="lc iu"> <em class="it">方框图用作方差分析的直观表示</em> </strong></p></blockquote><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/da80a26d12ece493059460b487d2a8e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*tpqQy4HK86MqyXwE7JVQxw.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">箱线图代码</p></figure><p id="ffac" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">箱形图显示数字数据组通过其分位数的分布。每个方框显示数据在组内的分布情况，并排放置方框表示各组之间的差异。它与ANOVA测试一致，ANOVA测试也分析组间与组内相比的差异程度。如果相对可变性较大，例如下面所示的<em class="op"> "Total_Revolving_Bal" </em>和<em class="op"> "Total_Cnt_Chng_Q4_Q1" </em>，则可能表明这些特征可能有助于预测标签。让我们看看这是否可以通过过滤方法中的ANOVA测试来量化。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi pq"><img src="../Images/667914d467f28c28ebade081a64713a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9QKXCgIyMMdrjiKYFSBcLw.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">箱线图结果(图片由作者提供)</p></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi pr"><img src="../Images/7061ffd377997c67f56d58f45e561ab7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*glkvoEyT5YjngB699hAqUw.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">箱线图结果(图片由作者提供)</p></figure><p id="a336" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><em class="op">如果你想对EDA有更透彻的了解，可以随意阅读我的文章《</em><a class="ae kz" rel="noopener" target="_blank" href="/semi-automated-exploratory-data-analysis-eda-in-python-7f96042c9809?source=your_stories_page-------------------------------------"><em class="op">Python中的半自动探索性数据分析(EDA)</em></a><em class="op">》。</em></p><h1 id="229a" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">特征选择</h1><p id="9634" class="pw-post-body-paragraph la lb it lc b ld mo ju lf lg mp jx li lj mq ll lm ln mr lp lq lr ms lt lu lv im bi translated">如果你想更深入地了解特征选择的重要性和实现特征选择的不同技术，下面来自<a class="ae kz" href="https://neptune.ai/home" rel="noopener ugc nofollow" target="_blank"> <em class="op"> neptune.ai </em> </a>的博客提供了全面的指导。</p><div class="ng nh gp gr ni nj"><a href="https://neptune.ai/blog/feature-selection-methods" rel="noopener  ugc nofollow" target="_blank"><div class="nk ab fo"><div class="nl ab nm cl cj nn"><h2 class="bd iu gy z fp no fr fs np fu fw is bi translated">特征选择方法及如何选择- neptune.ai</h2><div class="nq l"><h3 class="bd b gy z fp no fr fs np fu fw dk translated">你有没有发现自己坐在屏幕前想知道什么样的功能会帮助你的机器…</h3></div><div class="nr l"><p class="bd b dl z fp no fr fs np fu fw dk translated">海王星. ai</p></div></div><div class="ns l"><div class="ps l nu nv nw ns nx kt nj"/></div></div></a></div><p id="49bb" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在本文中，我们将主要介绍两类特征选择方法:<strong class="lc iu">过滤方法和包装方法。</strong>根本区别在于，过滤方法基于卡方、方差分析等统计测试评估特征重要性，而包装方法基于这些特征生成的模型的性能迭代评估特征子集的性能。</p><h2 id="193c" class="my lx it bd ly pt pu dn mc pv pw dp mg lj px py mi ln pz qa mk lr qb qc mm qd bi translated">过滤方法</h2><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi qe"><img src="../Images/4c451c48b7b7cf762aaa9273f0eb5e8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dJ3W2b4IIcPblJXykaESyw.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">过滤方法图解(图片由作者提供)</p></figure><p id="eb97" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">过滤方法通过评估每个特征与因变量的关系来给每个特征打分。对于具有分类响应变量的分类问题，我使用这三个主要的评分函数:<strong class="lc iu">卡方(score_func = chi2)、ANOVA (score_func = f_classif)和互信息(score_func = mutual_info_classif)。</strong>要创建一个特征选择模型，我们需要<em class="op"> SelectKBest() </em>函数，然后指定要使用的评分函数以及要选择的变量数量。</p><pre class="kk kl km kn gt mt mu mv mw aw mx bi"><span id="c625" class="my lx it mu b gy mz na l nb nc">selection_model = SelectKBest(score_func=score_function, k=variable_counts)</span></pre><p id="0cb1" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我想知道这两个参数，评分函数和变量的数量，将如何影响在所选特征上训练的模型的准确性。</p><p id="c783" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">首先，为了创建并执行特征选择，并检查在此基础上构建的模型的性能，我定义了一个<em class="op"> feature_selection </em>函数，步骤如下:</p><ul class=""><li id="a63d" class="ob oc it lc b ld le lg lh lj od ln oe lr of lv pc oh oi oj bi translated">导入所需的库</li><li id="bafe" class="ob oc it lc b ld ok lg ol lj om ln on lr oo lv pc oh oi oj bi translated">基于两个参数创建特征选择模型:score_function(例如，卡方)和变量计数(例如，范围从1到所有特征)</li><li id="d72b" class="ob oc it lc b ld ok lg ol lj om ln on lr oo lv pc oh oi oj bi translated">仅基于所选特征训练逻辑回归模型</li><li id="0eb8" class="ob oc it lc b ld ok lg ol lj om ln on lr oo lv pc oh oi oj bi translated">计算准确性分数</li></ul><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi qf"><img src="../Images/0afc5cac84c8d0d354d4163073f9719e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*lq-PlYCnEl1bpPtVILql6w.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">导入库</p></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi qg"><img src="../Images/00d0a24a08a43e16435d19808107eb48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pZMD1ZgnnsELtOk3frBJmA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">定义特征选择函数</p></figure><p id="6242" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">其次，为了测试得分函数和变量计数如何影响模型性能，我使用下面的代码迭代地传递两个参数的不同组合，<em class="op"> "variable_counts" </em>和<em class="op"> "score_function "，</em>。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi qh"><img src="../Images/f7e243f3f17214ce4a43273e5f173115.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lnawDsuJeQSAwaRJpQffdw.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">过滤方法准确度图表代码</p></figure><p id="7b56" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">数据可视化过滤方法</strong></p><p id="5f02" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">结果以数据框格式生成，然后使用折线图展示精度如何随着所选要素数量的增加而提高。如图所示，除了互信息方法，准确率评分在达到8个特征后稳定在0.88左右。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi qi"><img src="../Images/61c9242324e1e674db47c065f27e9c9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*hUOkylvY-AUtZJckpX5vog.png"/></div></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi qj"><img src="../Images/f227242b027520147576d4a55a80ffb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*LgkoL_ZebPfu6HjSC6lk5g.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">过滤方法准确性(图片由作者提供)</p></figure><p id="179e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">之后，让我们调查基于各种方法的每个特征的得分是多少。这一次，我们将使用条形图来直观显示根据卡方、方差分析或互信息分配给特征的分数。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi qk"><img src="../Images/7823b9411301882698e30172fcb991e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PovZQsc3LRvIQ-5leWJPWA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">特征分数代码</p></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ql"><img src="../Images/870d6739b35bc3ef0d2e66910233b8a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SqRqluBrnJrR38KfMA_iag.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">不同统计的特征分数(按作者的图像)</p></figure><p id="a906" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">正如你所看到的，不同的方法对相同的特性有不同的评分，但是有些特性总是出现在列表的较高位置。例如，<em class="op"> "Total_Revolving_Bal" </em>总是位于前3位，这与二元EDA中的箱线图的结果一致。与其他分类变量相比,“Card_Category”确实具有较高的特征重要性，这可以通过分组条形图来解释。</p><h2 id="687b" class="my lx it bd ly pt pu dn mc pv pw dp mg lj px py mi ln pz qa mk lr qb qc mm qd bi translated">包装方法</h2><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi qm"><img src="../Images/e5d3e0ba5b9681c3a43a9f5b8d115545.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tPBwQxtsCWpnORrwXXFeEA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">包装方法说明(图片由作者提供)</p></figure><p id="808a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">包装器方法通过评估基于这些特征训练的机器学习模型的性能来寻找最优的特征子集。因为它将模型结合到特征选择过程中，所以它需要更多的计算能力。本文介绍了两种主要的包装器方法，<strong class="lc iu">向前选择和向后消除。</strong>为了执行向前选择和向后排除，我们需要<em class="op">SequentialFeatureSelector()</em>函数，该函数主要需要四个参数:</p><ol class=""><li id="47cb" class="ob oc it lc b ld le lg lh lj od ln oe lr of lv og oh oi oj bi translated">模型:对于分类问题，我们可以使用逻辑回归、KNN等，对于回归问题，我们可以使用线性回归等</li><li id="234d" class="ob oc it lc b ld ok lg ol lj om ln on lr oo lv og oh oi oj bi translated">k_features:要选择的特征的数量</li><li id="bc4c" class="ob oc it lc b ld ok lg ol lj om ln on lr oo lv og oh oi oj bi translated">向前:确定是向前选择还是向后排除</li><li id="3269" class="ob oc it lc b ld ok lg ol lj om ln on lr oo lv og oh oi oj bi translated">评分:确定模型性能的评估指标，例如分类问题——准确度、精确度、召回率等；回归问题— p值、R平方等</li></ol><p id="c9b5" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">正向选择</strong></p><p id="63a4" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">正向选择从模型中没有特征开始，一次向特征子集中增加一个特征。在每次迭代期间，基于由特征子集训练的模型的评估来选择新特征。</p><p id="92b8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">由于机器学习模型包含在特征选择算法中，我们需要指定一个模型作为输入参数之一。对于这个分类问题，我选择了逻辑回归，并以准确率作为评价指标。与筛选方法相比，包装方法在计算精确度方面略有不同。由于我们只使训练集适合包装器模型，所以包装器方法本身返回的准确度分数完全基于训练数据集。因此，有必要在所选特征上训练附加模型，并基于测试集进一步评估。</p><p id="82ad" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">为此，我使用下面的代码来导入所需的库，并创建和评估基于包装方法构建的逻辑回归模型。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi qn"><img src="../Images/b27b7b15e84c73418e214417809eb015.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*e48ehp67cQfDsARYx_wnZQ.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">导入库</p></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi qo"><img src="../Images/693638135ab2bef96a2e1bb7371815ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*Ei1mHxlym8ufd8mvxbjQsw.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">正向选择代码</p></figure><p id="2426" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">落后淘汰</strong></p><p id="febd" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">简单来说，就是和正向选择正好相反，从包含所有特征开始训练模型。然后，基于特征是否对模型性能有贡献，从特征子集中迭代地移除特征。类似地，逻辑回归和准确度被相应地用作模型和评估度量。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi qp"><img src="../Images/ecba4f0d0b9aaff438ee574b8f0dc714.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*Pv4PCeigJvELO1uQzBH8FA.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">反向选择码</p></figure><p id="7bba" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">包装方法和数据可视化</strong></p><p id="57fe" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">与filter方法类似，我将向前选择和向后排除都封装到一个“for循环”中，以便检查变量计数是否会影响准确性分数。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi qh"><img src="../Images/2a68e43243dfe41441580cc6af9c89f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T01JaTW9GYfvghYTPIdLLQ.png"/></div></div></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi qq"><img src="../Images/195016386e59759fb8d9d751d076ccb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_FAwnPCcS46T81tE3DmQdA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">包装方法准确性代码</p></figure><p id="536e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如折线图所示，当特征计数小于4时，准确度快速增长，然后在0.88左右保持稳定。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi qr"><img src="../Images/e7683f41d9f414ae0f7067d698fca06b.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*vDLSeoCr8uAy9n3SN5b5lQ.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">包装方法准确性图表(图片由作者提供)</p></figure><p id="2804" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在该数据集中，由于总共只有大约20个要素，因此要素选择可能很难对模型性能产生任何重大影响。然而，不可否认的是，数据可视化可以帮助我们决定哪些特征和多少特征适合数据集或目标。这一原则肯定可以扩展到具有更多变量的其他数据集。</p><h1 id="a0ed" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">带回家的信息</h1><p id="c98e" class="pw-post-body-paragraph la lb it lc b ld mo ju lf lg mp jx li lj mq ll lm ln mr lp lq lr ms lt lu lv im bi translated">本文涵盖了两种基本的特性选择技术:</p><ul class=""><li id="1840" class="ob oc it lc b ld le lg lh lj od ln oe lr of lv pc oh oi oj bi translated"><strong class="lc iu">过滤方法:</strong>基于卡方、ANVOA和互信息</li><li id="4ffd" class="ob oc it lc b ld ok lg ol lj om ln on lr oo lv pc oh oi oj bi translated"><strong class="lc iu">包装方法:</strong>基于正向选择和反向淘汰</li></ul><p id="8eee" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们还将了解如何使用数据可视化来更好地理解要素属性，以及如何选择适当数量的要素。</p><h1 id="3a9e" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">更多这样的文章</h1><div class="ng nh gp gr ni nj"><a rel="noopener follow" target="_blank" href="/semi-automated-exploratory-data-analysis-eda-in-python-7f96042c9809"><div class="nk ab fo"><div class="nl ab nm cl cj nn"><h2 class="bd iu gy z fp no fr fs np fu fw is bi translated">Python中的半自动探索性数据分析(EDA)</h2><div class="nq l"><h3 class="bd b gy z fp no fr fs np fu fw dk translated">一键式全面数据探索流程</h3></div><div class="nr l"><p class="bd b dl z fp no fr fs np fu fw dk translated">towardsdatascience.com</p></div></div><div class="ns l"><div class="qs l nu nv nw ns nx kt nj"/></div></div></a></div><div class="ng nh gp gr ni nj"><a href="https://neptune.ai/blog/feature-selection-methods" rel="noopener  ugc nofollow" target="_blank"><div class="nk ab fo"><div class="nl ab nm cl cj nn"><h2 class="bd iu gy z fp no fr fs np fu fw is bi translated">特征选择方法及如何选择- neptune.ai</h2><div class="nq l"><h3 class="bd b gy z fp no fr fs np fu fw dk translated">你有没有发现自己坐在屏幕前想知道什么样的功能会帮助你的机器…</h3></div><div class="nr l"><p class="bd b dl z fp no fr fs np fu fw dk translated">海王星. ai</p></div></div><div class="ns l"><div class="ps l nu nv nw ns nx kt nj"/></div></div></a></div><div class="ng nh gp gr ni nj"><a rel="noopener follow" target="_blank" href="/simple-logistic-regression-using-python-scikit-learn-86bf984f61f1"><div class="nk ab fo"><div class="nl ab nm cl cj nn"><h2 class="bd iu gy z fp no fr fs np fu fw is bi translated">Python中的简单逻辑回归</h2><div class="nq l"><h3 class="bd b gy z fp no fr fs np fu fw dk translated">从数据预处理到模型评估的逐步指南</h3></div><div class="nr l"><p class="bd b dl z fp no fr fs np fu fw dk translated">towardsdatascience.com</p></div></div><div class="ns l"><div class="qt l nu nv nw ns nx kt nj"/></div></div></a></div><div class="ng nh gp gr ni nj"><a rel="noopener follow" target="_blank" href="/level-up-7-data-science-skills-with-youtube-ef3778f34229"><div class="nk ab fo"><div class="nl ab nm cl cj nn"><h2 class="bd iu gy z fp no fr fs np fu fw is bi translated">通过YouTube提升7项数据科学技能</h2><div class="nq l"><h3 class="bd b gy z fp no fr fs np fu fw dk translated">如果学习数据科学是一个游戏呢</h3></div><div class="nr l"><p class="bd b dl z fp no fr fs np fu fw dk translated">towardsdatascience.com</p></div></div><div class="ns l"><div class="qu l nu nv nw ns nx kt nj"/></div></div></a></div></div><div class="ab cl qv qw hx qx" role="separator"><span class="qy bw bk qz ra rb"/><span class="qy bw bk qz ra rb"/><span class="qy bw bk qz ra"/></div><div class="im in io ip iq"><p id="389e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><em class="op">原载于2021年5月24日https://www.visual-design.net</em><em class="op"/><a class="ae kz" href="https://www.visual-design.net/post/feature-selection-and-eda-in-machine-learning" rel="noopener ugc nofollow" target="_blank"><em class="op">。</em></a></p></div></div>    
</body>
</html>