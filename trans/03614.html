<html>
<head>
<title>A hands-on guide to TFRecords</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TFRecords实践指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-practical-guide-to-tfrecords-584536bc786c?source=collection_archive---------2-----------------------#2021-03-24">https://towardsdatascience.com/a-practical-guide-to-tfrecords-584536bc786c?source=collection_archive---------2-----------------------#2021-03-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="828c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">关于处理图像、音频和文本数据的介绍</h2></div><p id="cfa0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">TensorFlow的自定义数据格式TFRecord真的很有用。这些文件由速度极快的tf.data API提供本机支持，支持分布式数据集，并利用并行I/O。但它们起初有些令人难以招架。这篇文章是一个实践性的介绍。</p><h1 id="5195" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">概观</h1><p id="c1aa" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">在下文中，我们将使用人工数据来回顾TFRecord文件背后的概念。记住这一点，我们就可以继续研究图像；我们将使用小型和大型数据集。扩展我们的知识，然后我们处理音频数据。最后一个大的领域是文本领域，我们也会涉及到。为了将所有这些结合起来，我们创建了一个人工的多数据类型数据集，并且，您可能已经猜到了，也将它写入TFRecords。</p><h1 id="ca3e" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">TFRecord的布局</h1><p id="9611" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">当我开始我的深度学习研究时，我天真地将我分散在磁盘上的数据存储起来。更糟糕的是，我用数千个小文件污染了我的目录，大约只有几KB。我当时工作的集群并不觉得有趣。加载所有这些文件花了相当长的时间。</p><p id="5d8f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是TFRecords(或大型NumPy数组，就此而言)派上用场的地方:我们不是存储分散的数据，而是迫使磁盘在块之间跳转，而是简单地将数据存储在一个顺序布局中。我们可以用以下方式来形象化这个概念:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mb"><img src="../Images/c0b293e118979bf45c93d6d58559b17d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JHXOoMnNB1YqtSQjJxF0BQ.png"/></div></div><p class="mn mo gj gh gi mp mq bd b be z dk translated">作者创建的可视化</p></figure><p id="1931" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">TFRecord文件可以看作是所有单个数据样本的包装器。每一个数据样本都被称为一个<em class="mr">示例</em>，本质上是一个字典，存储着一个键和我们实际数据之间的映射。</p><p id="f8d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，看似复杂的部分是这样的:当你想把数据写到TFRecords时，你首先必须把你的数据转换成一个<em class="mr">特性</em>。这些特征是一个示例的内部组件:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi ms"><img src="../Images/bbcdd535a0e848b01ba0fb0390a3b006.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2xN2KGlvEQhCsSvkIZib0Q.png"/></div></div><p class="mn mo gj gh gi mp mq bd b be z dk translated">作者创建的可视化</p></figure><p id="fab2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">到目前为止，一切顺利。但是现在将数据存储在压缩的NumPy数组或pickle文件中有什么区别呢？两件事:TFRecord文件是顺序存储的，由于访问时间短，可以实现快速流式传输。其次，TFRecord文件原生集成到TensorFlows tf.data API中，可以轻松实现批处理、混排、缓存等功能。</p><p id="c66b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另外，如果您有机会和计算资源进行多工人培训，您可以将数据集分布在您的机器上。</p><p id="9848" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在代码级别，特性创建是通过这些方便的方法进行的，我们将在后面讨论这些方法:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="4e0d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要将数据写入TFRecord文件，首先要创建一个字典，该字典表示</p><blockquote class="mv mw mx"><p id="399c" class="ki kj mr kk b kl km ju kn ko kp jx kq my ks kt ku mz kw kx ky na la lb lc ld im bi translated">我想把这个数据点存储在这个键下</p></blockquote><p id="9df7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当从TFRecord文件中读取时，您可以通过创建一个字典来反转这个过程，该字典说</p><blockquote class="mv mw mx"><p id="2f58" class="ki kj mr kk b kl km ju kn ko kp jx kq my ks kt ku mz kw kx ky na la lb lc ld im bi translated">我有这个键，用存储在这个键上的值填充这个占位符</p></blockquote><p id="a5ac" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看看这是如何运作的。</p><h1 id="48dd" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">图像数据，小</h1><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi nb"><img src="../Images/3f7dc261a7273c827639638aabf575b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SeHk2rB4XC8Q4f2l"/></div></div><p class="mn mo gj gh gi mp mq bd b be z dk translated">一只小猫。在<a class="ae nc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae nc" href="https://unsplash.com/@kotecinho?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Kote Puerto </a>拍摄的照片</p></figure><p id="d522" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">图像是深度学习中的一个常见领域，MNIST [1]和ImageNet [2]是两个众所周知的数据集。将您的图像从磁盘放入模型的方法有很多:<a class="ae nc" href="https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly" rel="noopener ugc nofollow" target="_blank">编写一个定制的生成器</a>，使用Keras的<a class="ae nc" href="https://keras.io/api/preprocessing/image/#imagedatagenerator-class" rel="noopener ugc nofollow" target="_blank">内置工具</a>，或者从NumPy数组加载它。为了高效地加载和解析图像数据，我们可以求助于TFRecords作为底层文件格式。</p><p id="7840" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">过程如下:我们首先创建一些随机图像——也就是说，使用NumPy随机填充给定图像形状的矩阵:宽度、高度和颜色通道:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="19b1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出符合预期；我们有100个形状为250x250的图像，每个图像有三个通道:</p><pre class="mc md me mf gt nd ne nf ng aw nh bi"><span id="a11f" class="ni lf it ne b gy nj nk l nl nm">(100, 250, 250, 3)</span></pre><p id="f6dd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们也创造一些人为的标签:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="adc5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，我们有一个形状为(100，1)的标签数组，每个图像存储一个标签。打印出前十个标签:</p><pre class="mc md me mf gt nd ne nf ng aw nh bi"><span id="6248" class="ni lf it ne b gy nj nk l nl nm">(100, 1)<br/>[[2] [4] [3] [3] [2] [4] [2] [3] [3] [0]]</span></pre><p id="6d3d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了将这些{image，label}对放入TFRecord文件，我们编写了一个简短的方法，获取一个图像及其标签。使用上面定义的助手函数，我们创建一个字典，在键<em class="mr"> height </em>、<em class="mr"> width </em>和<em class="mr">depth——w</em>中存储我们图像的形状，我们需要这些信息在以后重建我们的图像。接下来，我们还将实际图像存储为<em class="mr"> raw_image </em>。为此，我们首先序列化数组(考虑构建一个长列表)，然后将其转换为一个<em class="mr"> bytes_feature </em>。最后，我们存储图像的标签。</p><p id="1964" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所有这些键:值映射构成了一个<em class="mr">示例</em>的特性，如上所述:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="b6fd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">既然我们已经定义了如何从一对{image，label}创建一个<em class="mr">示例</em>，我们需要一个函数将我们的完整数据集写入TFRecord文件。</p><p id="a943" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们首先创建一个<em class="mr"> TFRecordWriter </em>，随后使用它将<em class="mr">示例</em>写入磁盘。对于每个图像和相应的标签，我们使用上面的函数来创建这样一个对象。在写入磁盘之前，我们必须对其进行序列化。在我们使用完数据后，我们关闭我们的writer并打印我们刚刚解析的文件数:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="1cce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是将图像写入TFRecord文件所需的全部内容:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="3eb5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出与预期的一样，因为我们刚刚解析了100个{image，label}对:</p><pre class="mc md me mf gt nd ne nf ng aw nh bi"><span id="79ab" class="ni lf it ne b gy nj nk l nl nm">Wrote 100 elements to TFRecord</span></pre><p id="9fd9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有了这个文件在我们的磁盘上，我们以后可能也会有兴趣阅读它。这也是可能的，并且是相反的:</p><p id="b931" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">前面，我们定义了一个用于将内容写入磁盘的字典。我们现在使用类似的结构，但这次是为了读取数据。之前，我们说过键<em class="mr">宽度</em>包含int类型的数据。因此，当我们创建字典时，我们也分配一个int类型的占位符。因为我们正在处理固定长度的特性(我们大部分时间都在处理这些特性；稀疏张量很少使用)，我们说:</p><blockquote class="mv mw mx"><p id="8e76" class="ki kj mr kk b kl km ju kn ko kp jx kq my ks kt ku mz kw kx ky na la lb lc ld im bi translated">给我我们存储在键“width”中的数据，并用它填充这个占位符</p></blockquote><p id="eb58" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">类似地，我们为其他存储的特性定义了key:placeholder映射。然后，我们通过用<em class="mr"> parse_single_example </em>解析元素来填充占位符。假设我们处理的是一个字典，我们通常可以通过访问相应的键来提取所有的值。</p><p id="0ab9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在最后一步中，我们必须将图像从序列化形式解析回(高度、宽度、通道)布局。注意，我们希望out_type为int16，这是必需的，因为我们也是用int16创建映像的:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="2a9b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了从解析元素中创建数据集，我们只需利用tf.data API。我们通过将TFRecord文件指向磁盘上的TF record文件来创建一个<em class="mr"> TFRecordDataset </em>，然后将我们之前的解析函数应用于每个提取的<em class="mr">示例</em>。这会返回一个数据集:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="aece" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以通过获取单个数据点来探索数据集的内容:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="781f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出是</p><pre class="mc md me mf gt nd ne nf ng aw nh bi"><span id="c505" class="ni lf it ne b gy nj nk l nl nm">(250, 250, 3)<br/>()</span></pre><p id="183a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一行是一个图像的形状；第二条线是标量元素的形状，它没有维度。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="b96b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这标志着小型数据集解析的结束。在下一节中，我们将研究如何解析一个更大的数据集，在解析过程中创建多个TFRecord文件。</p><h1 id="e194" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">图像数据，大</h1><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi nu"><img src="../Images/fe2529f829526d235a263eb56897f5db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OtZn0yK-PMmuFDtq"/></div></div><p class="mn mo gj gh gi mp mq bd b be z dk translated">一只大猫。照片由<a class="ae nc" href="https://unsplash.com/@timothymeinberg?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">蒂莫西·梅恩伯格</a>在<a class="ae nc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="2319" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在上一节中，我们向单个TFRecord文件中写入了一个相当小的数据集。对于更大的数据集，我们可以考虑将数据分割到多个这样的文件中。</p><p id="845d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，让我们创建一个随机图像数据集:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="1e2c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下一步将创建相应的标签:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="6524" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于我们现在正在处理一个更大的数据集，我们首先必须确定我们甚至需要多少个碎片。为了计算这一点，我们需要文件总数和希望存储在单个碎片中的元素数量。我们还必须考虑这样的情况，例如，每个分片有64个图像和10个文件。这将导致6个碎片(6x10 ),但会丢失最后4个样本。我们只是通过预先添加一个额外的碎片来避免这种情况，如果我们有60个文件，就删除它，因为60//10不会留下任何余数:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="5634" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下一步，我们迭代分割/碎片。我们为每个分割创建一个新的文件和writer，相应地更新文件名。命名遵循{输出目录} {当前碎片数} _ {碎片总数} {文件名}。</p><p id="a12f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于每一个碎片，我们创建一个临时计数来跟踪我们存储在其中的所有元素。通过计算<em class="mr">split _ number</em>x<em class="mr">max _ files</em>+<em class="mr">current _ shard _ count</em>来确定下一个{image，label}对。对于我们的第一个碎片，索引将从0到9；对于第二个碎片，索引将从10到19，依此类推。如果索引等于元素的数量，我们只需打破循环:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="9dc1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">准备好索引后，我们可以从相应的数组中获取图像和标签。我们重用了之前编写的<em class="mr"> parse_single_image </em>函数，因为我们只改变了数据集的维度，而没有改变布局。下一步，我们将返回的<em class="mr">示例</em>对象写入TFRecord文件。最后，我们增加当前和全局计数器；最后，关闭我们的writer:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="a2ab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">和前面一样，我们可以通过一个函数调用来创建TFRecord文件:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="5755" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">打印语句的输出是</p><pre class="mc md me mf gt nd ne nf ng aw nh bi"><span id="2e2d" class="ni lf it ne b gy nj nk l nl nm">Using 17 shard(s) for 500 files, with up to 30 samples per shard<br/>100%|██████████| 17/17 [00:03&lt;00:00,  5.07it/s]<br/>Wrote 500 elements to TFRecord</span></pre><p id="bdc3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">类似于我们的小数据集，我们可以从磁盘中提取较大的文件。因为我们没有改变存储的键，所以我们重用了我们的<em class="mr"> parse_tfr_element() </em>方法。唯一的区别是我们有多个TFRecord文件，而不是只有一个。我们可以通过获取符合某个模式的所有文件的列表来处理这个问题；我们简单地搜索所有包含字符串<em class="mr"> large_images </em>的TFRecord文件:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="37e6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以用下面的代码获取一个数据集并查询一个元素:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="7547" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出是预期的，一个图像的形状是(400，750，3)，标签是一个标量，没有形状:</p><pre class="mc md me mf gt nd ne nf ng aw nh bi"><span id="2cb4" class="ni lf it ne b gy nj nk l nl nm">(400, 750, 3)<br/>()</span></pre></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="bd13" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这标志着将较大的图像数据集解析为多个TFRecord文件并获取数据的工作已经结束。在下一节中，我们将讨论存储音频数据。</p><h1 id="de07" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">音频数据</h1><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi nu"><img src="../Images/9df1d5cf177e5d1eef63e28866f59892.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jq33URG5lwAY3R4N"/></div></div><p class="mn mo gj gh gi mp mq bd b be z dk translated">照片由<a class="ae nc" href="https://unsplash.com/@intelligenciya?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Alexey Ruban </a>在<a class="ae nc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="8b9c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">音频是第二种常用的数据类型；有各种各样的大型数据集可用。Christopher Dossman列出了超过1 TB的音频数据——这只是更大的公开数据中的一部分:</p><div class="nv nw gp gr nx ny"><a rel="noopener follow" target="_blank" href="/a-data-lakes-worth-of-audio-datasets-b45b88cd4ad"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd iu gy z fp od fr fs oe fu fw is bi translated">一个数据湖的音频数据集</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">我在音频研究中使用的25个大型音频数据集列表</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">towardsdatascience.com</p></div></div><div class="oh l"><div class="oi l oj ok ol oh om ml ny"/></div></div></a></div><p id="56f0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于本节，我们不会从一开始就处理TBs。相反，我们将关注一个更小的数据集。</p><p id="7f52" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们从创建它开始，我们需要librosa包来完成它。我们使用librosa提供的示例文件，并分配一些人工标签。对于每个样本，我们存储原始音频和采样速率:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="d50c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如我们之前所做的，我们编写了一个简短的方法来帮助我们将数据放入TFRecord文件。因为我们将音频数据和采样率打包到一个公共数组中，所以我们必须简单地查询条目:第一个条目是音频数据，第二个条目保存采样率。</p><p id="13d7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有了这些，我们就可以创建并返回一个<em class="mr">示例</em>对象。这里没有什么完全新的东西；方法与之前类似:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="2807" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">前面的函数返回一个样本，准备写入TFRecord。下一个函数遍历所有样本，并将它们写入磁盘:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="e03e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后我们简单地调用</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="5fe1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将我们完整的音频数据集写入磁盘。</p><p id="2831" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将它存储在一个文件中，我们可以像以前一样继续:我们编写一个函数，它与向TFRecord编写示例的过程相反，而是读取它。这与我们用来解析图像的函数非常相似；只有键有不同的名称:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="304a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">和前面一样，要创建数据集，我们只需将这个解析函数应用于TFRecord文件中的每个元素:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="5a0b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了查询我们的数据集，我们调用这个函数并检查第一个元素:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="977d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出是</p><pre class="mc md me mf gt nd ne nf ng aw nh bi"><span id="e9cd" class="ni lf it ne b gy nj nk l nl nm">(117601,)<br/>tf.Tensor(0, shape=(), dtype=int64)</span></pre><p id="bab7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一个条目是音频文件的形状；第二个条目是相应的标签。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="ac01" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这标志着音频数据和TFRecord文件工作的结束。在下一节中，我们来看看如何处理文本数据。</p><h1 id="54c0" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">文本数据</h1><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi on"><img src="../Images/222a3a154c03f8c22753ae8287d140b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DeQl0xZGZodCs1bd"/></div></div><p class="mn mo gj gh gi mp mq bd b be z dk translated">由<a class="ae nc" href="https://unsplash.com/@micahboswell?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">米卡·博斯韦尔</a>在<a class="ae nc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="9917" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作为最后一个大域，我们有文本数据。考虑到NLP研究在过去三、四年中的成功——变形金刚[3]、GPT [4]、…这就不足为奇了。</p><p id="71cb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们首先创建一个虚拟数据集:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="f4e9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，我们创建数据集并查询前五个元素:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="635a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这给了我们</p><pre class="mc md me mf gt nd ne nf ng aw nh bi"><span id="b8e1" class="ni lf it ne b gy nj nk l nl nm">['Hey, this is a sample text. We can use many different symbols.',<br/> 'A point is exactly what the folks think of it; after Gauss.',<br/> 'Hey, this is a sample text. We can use many different symbols.',<br/> 'A point is exactly what the folks think of it; after Gauss.',<br/> 'Hey, this is a sample text. We can use many different symbols.']</span></pre><p id="5f26" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们编写一个函数，从文本数据中创建一个示例对象。过程和前面一样:我们将非标量数据存储为字节特征，将标签存储为标量。</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="ed5e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用下一个函数，我们迭代文本数据集和标签，并将它们写入单个TFRecord文件:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="7677" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将我们的人工文本数据集放到磁盘上只需一个简单的调用:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="a207" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在下一个函数中，我们反转这个过程，从TFRecord文件中获取数据。一个显著的区别是，我们希望我们的特征——文本数据——是字符串类型；因此，我们将<em class="mr"> out_type </em>参数设置为<em class="mr"> tf.string </em>:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="2caa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">和以前一样，我们将每个元素都映射到这个函数:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="1756" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后我们得到一个数据集，并期待前两个元素:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="4393" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出是</p><pre class="mc md me mf gt nd ne nf ng aw nh bi"><span id="d972" class="ni lf it ne b gy nj nk l nl nm">b'Hey, this is a sample text. We can use many different symbols.'<br/>tf.Tensor(0, shape=(), dtype=int64)<br/>b'A point is exactly what the folks think of it; after Gauss.'<br/>tf.Tensor(1, shape=(), dtype=int64)</span></pre></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="970b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这标志着在TFRecord文件的上下文中写入和读取音频数据的结束。在下一节中，我们将合并所有以前的域。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h1 id="2e8c" class="le lf it bd lg lh oo lj lk ll op ln lo jz oq ka lq kc or kd ls kf os kg lu lv bi translated">多种数据类型</h1><p id="7ab6" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">到目前为止，我们已经检查了单个域。当然，没有什么反对合并多个域！对于以下内容，请考虑以下大纲:</p><p id="4384" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们有多个图像:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="2cb1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其次，我们对每幅图像都有一个简短的描述，描述图像显示的风景:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="4ff0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，我们还有对风景的听觉描述。我们重用上面的虚拟音频数据:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="be10" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们将它们合并到TFRecord文件中。我们编写一个函数，接受这些数据类型并返回一个示例对象。这是TFRecord格式的另一个好处:即使我们处理多种数据类型，我们也可以将所有内容一起存储在一个对象中:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="a3f5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如前所述，我们迭代所有数据样本并将它们写入磁盘:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="6334" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">创建TFRecord文件只是一个函数调用:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="2c98" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">既然我们已经将这样一个<em class="mr">例子</em>写到磁盘上，我们通过提取<em class="mr">特征</em>来读回它。与上一节的主要区别在于，我们有多个特征—文本、图像和音频数据—因此我们必须分别解析它们:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="c371" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">获得组合数据集的代码非常简单:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="60c8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看看数据集中的第一个元素:</p><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="e75e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出是</p><pre class="mc md me mf gt nd ne nf ng aw nh bi"><span id="6df9" class="ni lf it ne b gy nj nk l nl nm">(&lt;tf.Tensor: shape=(256, 256, 3), dtype=int16, numpy=<br/> array([[[160, 224, 213],<br/>         ...<br/>         [189, 253,  65]]], dtype=int16)&gt;,<br/> <br/>&lt;tf.Tensor: shape=(), dtype=string, numpy=b'This image shows a house on a cliff. The house is painted in red and brown tones.'&gt;,</span><span id="1f00" class="ni lf it ne b gy ot nk l nl nm">&lt;tf.Tensor: shape=(), dtype=int64, numpy=3&gt;,</span><span id="9eff" class="ni lf it ne b gy ot nk l nl nm">&lt;tf.Tensor: shape=(117601,), dtype=float32, numpy=<br/> array([-1.4068224e-03, -4.4607223e-04, -4.1098078e-04, ...,<br/>         7.9623060e-06, -3.0417003e-05,  1.2765067e-05], dtype=float32)&gt;,</span><span id="5468" class="ni lf it ne b gy ot nk l nl nm">&lt;tf.Tensor: shape=(), dtype=int64, numpy=0&gt;)</span></pre><p id="af9e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一个元素是图像，第二个元素是图像的文本描述，第三个元素是文本的标签。最后两个元素是音频数据和音频数据的标签。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="48bb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这标志着关于将多种数据类型写入TFRecord文件的部分到此结束。</p><h1 id="1f75" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">摘要</h1><p id="b050" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">我们讨论了将图像、音频和文本数据写入TFRecord文件。我们还讨论了读回这些数据。</p><p id="cb70" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不管实际内容如何，程序总是如下:</p><ul class=""><li id="15d8" class="ou ov it kk b kl km ko kp kr ow kv ox kz oy ld oz pa pb pc bi translated">为存储在TFRecord文件中的数据定义字典</li><li id="81cf" class="ou ov it kk b kl pd ko pe kr pf kv pg kz ph ld oz pa pb pc bi translated">解析数据时，通过复制该字典来重建数据</li><li id="0a2e" class="ou ov it kk b kl pd ko pe kr pf kv pg kz ph ld oz pa pb pc bi translated">将每个元素映射到解析函数</li></ul><p id="5c6b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">只有在处理大型数据集时，才需要稍加修改。在这种情况下，您必须将您的数据写入多个TFRecord文件，这一点我们在处理大型图像数据一节中已经介绍过。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="17ac" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里有一个包含所有代码的Colab笔记本<a class="ae nc" href="https://colab.research.google.com/drive/1xU_MJ3R8oj8YYYi-VI_WJTU3hD1OpAB7?usp=sharing" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="e146" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您有兴趣了解这种文件格式，您可以阅读我关于自定义音频数据分类的帖子。在那里，我使用TFRecord文件来存储我的数据集，并直接在其上训练神经网络:</p><div class="nv nw gp gr nx ny"><a rel="noopener follow" target="_blank" href="/custom-audio-classification-with-tensorflow-af8c16c38689"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd iu gy z fp od fr fs oe fu fw is bi translated">使用TensorFlow进行自定义音频分类</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">包含代码的端到端示例项目。</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">towardsdatascience.com</p></div></div><div class="oh l"><div class="pi l oj ok ol oh om ml ny"/></div></div></a></div><h1 id="b1b7" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">文学</h1><p id="54dc" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">[1] Y. LeCun <em class="mr">等</em>。，<a class="ae nc" href="https://ieeexplore.ieee.org/document/726791" rel="noopener ugc nofollow" target="_blank">基于梯度的学习应用于文档识别</a> (1994)，IEEE会议录</p><p id="9247" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2] J. Deng <em class="mr">等</em>，Imagenet: <a class="ae nc" href="https://ieeexplore.ieee.org/document/5206848" rel="noopener ugc nofollow" target="_blank">大规模分层图像数据库</a> (2009)，IEEE计算机视觉与模式识别会议</p><p id="9ea9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[3] A .瓦斯瓦尼<em class="mr">等</em>，<a class="ae nc" href="https://arxiv.org/pdf/1706.03762.pdf）描述了这样做的原因%E3%80%82" rel="noopener ugc nofollow" target="_blank">注意力是你所需要的全部</a> (2017)，NIPS</p><p id="dd24" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[4] A .拉德福德<em class="mr">等</em>，<a class="ae nc" href="https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf" rel="noopener ugc nofollow" target="_blank">通过生成性预训练提高语言理解</a> (2018)，OpenAI</p></div></div>    
</body>
</html>