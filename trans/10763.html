<html>
<head>
<title>Running Spark on Kubernetes: Approaches and Workflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Kubernetes上运行Spark:方法和工作流程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/running-spark-on-kubernetes-approaches-and-workflow-75f0485a4333?source=collection_archive---------10-----------------------#2021-10-18">https://towardsdatascience.com/running-spark-on-kubernetes-approaches-and-workflow-75f0485a4333?source=collection_archive---------10-----------------------#2021-10-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4df2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在Kubernetes上为开发、数据探索和生产运行Spark作业的最佳方式</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b4c1b9c344e5ade335d2f6991c6502db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vuy5OD_DKRKUY1sS"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">拉扎勒斯库·亚历山德拉在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="a824" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在从事Apache Spark应用程序工作的这些年里，我一直在开发和生产环境之间切换。我会使用Visual Studio代码之类的IDE来编写Scala或PySpark代码，针对一小部分数据进行本地测试，将Spark作业提交给Hadoop YARN以在生产中运行，希望它只适用于真正的大数据。我会花大量时间处理本地和生产环境的Spark依赖关系，并确保它们同步。对于机器学习应用程序来说，这个工作流变得更加痛苦，因为需要PySpark、Python库和Jupyter notebook环境的组合。即使对于拥有许多工程师的企业来说，为Spark应用程序开发、数据探索和生产运行建立和维护环境仍然是一项挑战。</p><p id="595a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在Kubernetes上输入Spark。有了Kubernetes上的Spark，以及理想情况下像FlashBlade S3这样的快速对象存储，我们可以使用单一环境轻松运行所有这些不同的Spark任务。</p><ul class=""><li id="b27b" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">由多个Spark pods支持的Jupyter笔记本电脑，可用于小型和大型数据的快速原型制作和数据探索。</li><li id="7d4c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">在yaml文件中声明一个Spark应用程序，并提交它以在生产中运行。</li><li id="6c66" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">Apache Airflow来协调和调度具有多个作业的管道。</li></ul><p id="a6a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与以前的工作流程相比，这个新的工作流程更令人愉快。我的所有任务都利用相同的Kubernetes环境。在容器映像中管理依赖关系，以便它们在开发和生产中保持一致。性能问题可以在开发阶段检测出来，因为大规模测试变得更加容易。最重要的是，不再需要管理Hadoop集群。</p><p id="1b9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在之前的<a class="ae ky" rel="noopener" target="_blank" href="/apache-spark-with-kubernetes-and-fast-s3-access-27e64eb14e0f">博客</a>中解释了如何设置Spark在Kubernetes上运行并访问S3。这一次，我将描述我在Kubernetes上运行Spark进行开发、数据探索和生产的新工作流。</p><h1 id="ec6c" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">超级充电Jupyter笔记本，带Kubernetes上的PySpark</h1><p id="dc38" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">Jupyter Notebook对于快速原型开发和数据探索非常方便，因为开发人员和数据科学家可以在其基于web的交互式开发环境中直接开始编码。然而，由于它运行在单个Python内核中，处理大数据可能会很慢。另一方面，PySpark允许我们用Python编写Spark代码并在Spark集群中运行，但它与Jupyter的集成并不存在，直到最近的Spark 3.1版本，它允许Spark作业在Kubernetes集群中本地运行。这使得从Jupyter笔记本电脑处理大数据成为可能。</p><p id="93ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过几行代码配置，我们现在可以在Jupyter笔记本中编写PySpark代码，提交代码在Kubernetes集群中作为Spark作业运行。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/867db430f85d31334eb0460cc6b16c68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UZ0M5tDm2fe2T-0sk-l0dA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在Jupyter的Kubernetes会议上发起火花</p></figure><p id="394c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在示例笔记本blow中，我的PySpark代码从存储在FlashBlade S3的CSV文件中读取了112M条记录，然后执行了一些功能工程任务。由于记录数量巨大，如果在单个进程上运行，这可能会非常慢。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/6e867c8ff72c525de05c999ce9418449.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hzd-65U6E6mpOiOP8-8KQg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">将1.12亿张S3唱片读入PySpark</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/37eea8fc0cf8f0ee727154379b5087d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*naYoE0SS-3yL2fGHDUBokw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PySpark中的特征工程</p></figure><p id="1164" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，在这种情况下，在后端，繁重的处理由Kubernetes中运行的Spark作业来处理。下面是笔记本推出的Kubernetes中的Spark pods。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/097e13d11867a5d764a444cb030a5f33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JzR-Ba4pT1opwA3bXtw1rg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Jupyter笔记本推出的Kubernetes中的Spark pods</p></figure><p id="2c1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为后端是完全分布式的Spark作业，所以速度很快。我们现在可以从浏览器处理和浏览Juypyter笔记本中的大量记录。</p><h1 id="bd6a" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">简化生产中的Spark提交</h1><p id="13fe" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">工作流程的下一步是将Spark代码提交给生产部门。曾经讨论过是否应该将笔记本视为生产代码。一些公司如网飞已经在做这个T2，但是我认为大多数公司还没有做到。在我的工作流程中，我会将笔记本代码复制并提炼为一个Python文件，将其放在S3，在yaml文件中声明一个PySpark作业，并使用Spark on k8s操作符将其提交给Kubernetes。你可以在我的<a class="ae ky" rel="noopener" target="_blank" href="/apache-spark-with-kubernetes-and-fast-s3-access-27e64eb14e0f">以前的博客</a>中找到细节。</p><p id="0e51" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在Spark 3.x中，向Kubernetes提交Spark作业有两种方法:</p><ul class=""><li id="4e56" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">使用传统的spark提交脚本</li><li id="0cee" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">在k8s操作器上使用Spark</li></ul><p id="b694" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我选择在k8s上使用Spark操作符，因为它是Kubernetes的原生操作符，因此可以从任何有Kubernetes客户端的地方提交。使用这种方法，提交Spark作业是一个标准的Kubernetes命令:<code class="fe nk nl nm nn b">kubectl apply -f nyc-taxi.yaml</code>。这有助于简化Spark提交。它也更加灵活，因为在节点上不需要Spark客户机。</p><p id="bb0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可能已经注意到了，这与我在上面部分中从Jupyter在Kubernetes会话上启动Spark的方式不同，在那里使用了传统的spark-submit。这是真的，因为我想让Spark驱动程序运行在Jupyter内核中进行交互式开发。而在生产中，我们需要再现性、灵活性和便携性。</p><h1 id="086f" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">协调和安排管道</h1><p id="977b" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">虽然在k8s上的Spark operator很适合提交一个Spark作业在Kubernetes上运行，但我们经常希望将多个Spark和其他类型的作业链接到一个管道中，并安排管道定期运行。对此，Apache Airflow是一个流行的解决方案。</p><p id="f2ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Apache Airflow是一个以编程方式创作、调度和监控工作流的开源平台。它可以在Kubernetes上运行。它还可以与Kubernetes很好地集成。我将跳过如何在Kubernetes上运行Airflow的细节，以及从Airflow如何编排Spark作业在Kubernetes上运行。现在，让我们关注它带来的行为和价值。</p><p id="3d81" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在示例blow中，我定义了一个简单的管道(在Airflow中称为DAG ),其中包含两个顺序执行的任务。第一个任务使用Spark on k8s操作符向Kubernetes提交一个名为nyc-taxi的Spark作业，第二个任务检查在第一个状态中提交的Spark作业的最终状态。我还将DAG设置为每天运行。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/85139b911511f4c43d22658277c4c7ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X8fkaS3LyCQMYJgLNN6sHA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">气流中定义的简单管道</p></figure><p id="defb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在Airflow UI上，DAG看起来是这样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/029fe8c5e68d6edbb30c36135c900616.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cGVbf3UO0BrDJ0a0IFur_g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">气流界面上的纽约市出租车分析DAG</p></figure><p id="18ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行时，DAG中的第一个任务将在Kubernetes上通过Spark on k8s操作符启动多个Spark pods，如<code class="fe nk nl nm nn b">nyc-taxi.yaml</code>文件中所定义的，就像<code class="fe nk nl nm nn b">kubectl apply</code>命令一样。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/2d2c9e64eeea9c6b8a246be5380047b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nOlUWmpDE8mt0hLcoWj--Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">火花舱被气流旋转起来</p></figure><p id="2f8b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Airflow有助于管理多任务工作流的依赖性和计划。因为它重用作业并在相同的Kubernetes环境中运行，所以引入气流的开销是最小的。</p><h1 id="73dc" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">结论</h1><p id="d097" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">有了Kubernetes上的Spark和用于数据的外部S3对象存储，我的数据工程过程大大简化了。我会打开浏览器，开始快速原型制作和数据探索。感谢Kubernetes上Spark的强大功能，我不必将我的原型开发和探索局限于一小组样本数据。一旦我熟悉了原型，我就把代码放到Python文件中，用一个Kubenetes命令修改并提交它，以便在生产中运行。对于复杂的管道，我会用气流来编排作业，以帮助管理依赖性和调度。</p><p id="d18d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是我的数据工程工作流程。我喜欢我只需要一个单一的环境来实现所有这些。</p></div></div>    
</body>
</html>