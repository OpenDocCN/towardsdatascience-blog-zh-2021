<html>
<head>
<title>Data Leakage</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据泄露</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-leakage-5dfc2e0127d4?source=collection_archive---------22-----------------------#2021-12-15">https://towardsdatascience.com/data-leakage-5dfc2e0127d4?source=collection_archive---------22-----------------------#2021-12-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="77ef" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">你会在训练数据中加入偏见吗？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/3a25c8c51be09b9b2f17a768ba6df174.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UERlrio-s-W8qsnAv3GAiw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来源:(<a class="ae kv" href="https://pixabay.com/photos/water-water-pipes-drinking-water-4803866/" rel="noopener ugc nofollow" target="_blank">https://pix abay . com/photos/water-water-pipes-饮用水-4803866/ </a>)</p></figure><blockquote class="kw kx ky"><p id="54ce" class="kz la lb lc b ld le jr lf lg lh ju li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">如果编码器适合整个数据集，则训练数据的编码会受到验证和测试数据的分布的影响。</p></blockquote></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><p id="1cb3" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li md lk ll lm me lo lp lq mf ls lt lu lv ij bi translated">你有没有想过为什么像scikit-learn这样的数据处理库把编码过程分成两个步骤:<em class="lb">()</em>和<em class="lb">变换()</em>？在这篇文章中，我们将探究这种模式背后的原因。</p></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h1 id="991b" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">泄漏定义</h1><p id="37da" class="pw-post-body-paragraph kz la iq lc b ld my jr lf lg mz ju li md na ll lm me nb lp lq mf nc lt lu lv ij bi translated">监督算法的目的是对该算法以前未见过的数据进行预测。因此，当训练算法来预测验证和测试拆分时，从业者需要确保算法不会无意中获得关于这些拆分的信息。当这种弊端发生时，它被称为“数据泄漏”</p></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h1 id="d580" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">泄漏是如何发生的</h1><p id="9ff2" class="pw-post-body-paragraph kz la iq lc b ld my jr lf lg mz ju li md na ll lm me nb lp lq mf nc lt lu lv ij bi translated">数据泄漏可能起作用的一个特定领域是数字(连续或非有序整数)数据的预处理(也称为编码)。</p><p id="bbf9" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li md lk ll lm me lo lp lq mf ls lt lu lv ij bi translated">scikit-learn中处理数字数据的实际编码器是<em class="lb"> StandardScaler </em>。它以平均值0为中心在-1和1之间调整数值。</p><p id="7d75" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li md lk ll lm me lo lp lq mf ls lt lu lv ij bi translated">例如，假设我们正在对波士顿市一年中的每日温度进行标准化:</p><ul class=""><li id="580c" class="nd ne iq lc b ld le lg lh md nf me ng mf nh lv ni nj nk nl bi translated">平均温度(例如52华氏度)将被编码为零</li><li id="5b09" class="nd ne iq lc b ld nm lg nn md no me np mf nq lv ni nj nk nl bi translated">高温(例如华氏98度)接近1</li><li id="f017" class="nd ne iq lc b ld nm lg nn md no me np mf nq lv ni nj nk nl bi translated">和接近-1的低温(例如-5华氏度)</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/2af4422a659368b5f3f8438acf548d33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2lyrARr3gvJ964nAgW11FQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来源:(<a class="ae kv" href="https://unsplash.com/photos/0aqJNZ5tVBc" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/0aqJNZ5tVBc</a>)</p></figure><p id="00c6" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li md lk ll lm me lo lp lq mf ls lt lu lv ij bi translated">现在，我们可以在一个步骤中对整个数据集进行编码，如下所示:</p><pre class="kg kh ki kj gt ns nt nu nv aw nw bi"><span id="6d6d" class="nx mh iq nt b gy ny nz l oa ob">from sklearn.preprocessing import StandardScaler</span><span id="38d4" class="nx mh iq nt b gy oc nz l oa ob">scaler = StandardScaler()<br/>encoded_dataset = scaler.fit_transform(dataset)</span></pre><p id="9755" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li md lk ll lm me lo lp lq mf ls lt lu lv ij bi od translated"><span class="l oe of og bm oh oi oj ok ol di"> H </span>然而，你能想出为什么我们不想在这个标准化过程中包括我们所有的拆分(培训、验证、测试)的原因吗？如果我们的测试包含了一些来自寒流的极端温度会怎么样？</p><p id="1de2" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li md lk ll lm me lo lp lq mf ls lt lu lv ij bi translated">如果我们在编码中包括这些寒冷的日子，那么它会使我们的平均值(0中点)降低，从而使我们的训练样本的编码比正常情况高一点。然后，算法的权重将被这些较高的训练输入值所偏置。本质上，算法的性能被夸大了，因为它暴露于训练样本中不存在的信息。</p></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h1 id="7cd3" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">那么为什么要编码呢？</h1><p id="9501" class="pw-post-body-paragraph kz la iq lc b ld my jr lf lg mz ju li md na ll lm me nb lp lq mf nc lt lu lv ij bi translated">如果对数值型数据进行标准化的过程容易出现泄漏，那么为什么不能跳过呢？编码提供了两个主要好处:</p><p id="f67f" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li md lk ll lm me lo lp lq mf ls lt lu lv ij bi translated"><strong class="lc ir"> <em class="lb">同等特征重要性</em> </strong> —假设我们有两个特征:<em class="lb"> exam_score </em>和<em class="lb"> SAT_score </em>【美国大学预科考试】。一方面，考试的最高分是100分，但另一方面，SAT的最高分是1600分。如果我们不根据这两个特征的可能值范围对其进行归一化，那么算法最初会倾向于优先考虑<em class="lb"> SAT_score </em>特征，因为它的值更大。然而，如果我们在0和1之间标准化这两个特征，那么它们在训练开始时将被同等对待。</p><p id="3bc1" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li md lk ll lm me lo lp lq mf ls lt lu lv ij bi translated"><strong class="lc ir"> <em class="lb">帮助防止梯度爆炸</em> </strong> —当输入值接近零时，神经网络学习得更好。如果你不相信我，先试着训练一个CNN，不管有没有缩放图像数据。原因是许多激活函数(例如，如下图所示的sigmoid曲线)在1和-1处是渐近的(即饱和的)。由于渐近线，更高和更低的值不会对输出值产生有意义的影响。方便的是，大多数标准化函数输出接近0的值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/796a821ef23b46cdf9ead49eec74d54a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*cunAmhOwXGMc2Om-aLlnZg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Sigmoid曲线—图片来源:(<a class="ae kv" href="https://en.wikipedia.org/wiki/Sigmoid_function#/media/File:Logistic-curve.svg" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Sigmoid _ function #/media/File:Logistic-Curve . SVG</a>)</p></figure></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h1 id="b78e" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">编码前分割</h1><p id="1a5c" class="pw-post-body-paragraph kz la iq lc b ld my jr lf lg mz ju li md na ll lm me nb lp lq mf nc lt lu lv ij bi translated">那么我们如何在编码过程中防止数据泄露呢？</p><p id="5118" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li md lk ll lm me lo lp lq mf ls lt lu lv ij bi translated">关键是在执行标准化之前，将数据集分为训练、验证和测试部分。但是，我们不<em class="lb"> fit_transform() </em>各自单独拆分。首先，我们<em class="lb">拟合()</em>我们的训练分割，然后我们<em class="lb">转换()</em>其他分割，如下所示:</p><pre class="kg kh ki kj gt ns nt nu nv aw nw bi"><span id="56d3" class="nx mh iq nt b gy ny nz l oa ob">scaler = StandardScaler()<br/>scaler.fit(split_training)</span><span id="5f52" class="nx mh iq nt b gy oc nz l oa ob">encoded_training   = scaler.transform(split_training)<br/>encoded_validation = scaler.transform(split_validation)<br/>encoded_test       = scaler.transform(split_test)</span></pre><p id="8292" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li md lk ll lm me lo lp lq mf ls lt lu lv ij bi translated">这种模式在交叉验证期间尤其难以应用，因为在重新采样期间，训练样本和验证样本会发生旋转。手动跟踪褶皱的预处理变得不切实际。</p></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h1 id="f37e" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">进入AIQC</h1><p id="382f" class="pw-post-body-paragraph kz la iq lc b ld my jr lf lg mz ju li md na ll lm me nb lp lq mf nc lt lu lv ij bi translated">幸运的是，<a class="ae kv" href="https://github.com/aiqc/aiqc" rel="noopener ugc nofollow" target="_blank"> AIQC </a>的自动化<em class="lb"> Pipelines() </em>，一个由这篇博文的作者创建的开源库，通过以下方式解决了这些挑战:</p><ul class=""><li id="fb4c" class="nd ne iq lc b ld le lg lh md nf me ng mf nh lv ni nj nk nl bi translated">检测数字sklearn预处理器的使用</li><li id="b557" class="nd ne iq lc b ld nm lg nn md no me np mf nq lv ni nj nk nl bi translated">在分别对每个拆分和/或折叠进行<em class="lb">变换()</em>之前，对训练样本进行<em class="lb">拟合()</em></li><li id="4631" class="nd ne iq lc b ld nm lg nn md no me np mf nq lv ni nj nk nl bi translated">保存每个<em class="lb"> fit() </em>用于预测的下游解码</li></ul><pre class="kg kh ki kj gt ns nt nu nv aw nw bi"><span id="dda0" class="nx mh iq nt b gy ny nz l oa ob">splitset = aiqc.Pipeline.Tabular.make(<br/>    <em class="lb"># --- Data source ---</em><br/>    df_or_path = df</span><span id="3aff" class="nx mh iq nt b gy oc nz l oa ob"><br/>    <em class="lb"># --- Label preprocessing ---</em><br/>    , label_column = 'SurfaceTempK'<br/>    , label_encoder = dict(sklearn_preprocess =   StandardScaler(copy=<strong class="nt ir">False</strong>))</span><span id="cd77" class="nx mh iq nt b gy oc nz l oa ob"><br/>    <em class="lb"># --- Feature preprocessing ---</em><br/>    , feature_cols_excluded = 'SurfaceTempK'<br/>    , feature_encoders = [<br/>        dict(dtypes=['float64'], sklearn_preprocess=RobustScaler(copy=<strong class="nt ir">False</strong>)),<br/>        dict(dtypes=['int64'], sklearn_preprocess=OneHotEncoder(sparse=<strong class="nt ir">False</strong>))<br/>    ]<br/>    , feature_reshape_indices = <strong class="nt ir">None</strong></span><span id="2b58" class="nx mh iq nt b gy oc nz l oa ob"><br/>    <em class="lb"># --- Stratification ---</em><br/>    , size_test = 0.12<br/>    , size_validation = 0.22<br/>    , fold_count = <strong class="nt ir">None</strong><br/>    , bin_count = 4<br/>)</span></pre><p id="7fd4" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li md lk ll lm me lo lp lq mf ls lt lu lv ij bi translated">如上所述，所有从业者需要做的是:</p><ul class=""><li id="9e76" class="nd ne iq lc b ld le lg lh md nf me ng mf nh lv ni nj nk nl bi translated">定义用于标签和功能的编码器</li><li id="7dd0" class="nd ne iq lc b ld nm lg nn md no me np mf nq lv ni nj nk nl bi translated">指定其验证和测试子集的大小</li><li id="c590" class="nd ne iq lc b ld nm lg nn md no me np mf nq lv ni nj nk nl bi translated">指定要使用的折叠数(如果有)</li></ul><p id="f180" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li md lk ll lm me lo lp lq mf ls lt lu lv ij bi translated">这使得从业者能够将更多的时间花在实际的分析上，而不是处理各种分割的编码。</p><blockquote class="kw kx ky"><p id="ade1" class="kz la lb lc b ld le jr lf lg lh ju li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><a class="ae kv" href="https://github.com/aiqc/aiqc" rel="noopener ugc nofollow" target="_blank"><strong class="lc ir">【https://github.com/aiqc/aiqc】</strong></a></p></blockquote></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><p id="7663" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li md lk ll lm me lo lp lq mf ls lt lu lv ij bi od translated"><span class="l oe of og bm oh oi oj ok ol di">在</span>总结中，我们已经了解到，当编码器适用于非训练数据时，会发生数据泄漏。这个问题可以通过分别编码每个分割/折叠来解决，但是手动这样做引入了另一个维度的数据争论，需要从业者跟踪。谢天谢地，<em class="lb"> aiqc。Pipelines() </em>可以用来自动化这个和其他预处理/后处理挑战。</p></div></div>    
</body>
</html>