<html>
<head>
<title>Connecting the dots AI, IoT, Cloud, and Web Dev</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">连接人工智能、物联网、云和网络开发</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/connecting-the-dots-ai-iot-cloud-and-web-dev-848447e1ca66?source=collection_archive---------34-----------------------#2021-09-24">https://towardsdatascience.com/connecting-the-dots-ai-iot-cloud-and-web-dev-848447e1ca66?source=collection_archive---------34-----------------------#2021-09-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7410" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用趋势技术进行端到端解决方案开发的小旅程</h2></div><h1 id="d817" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">最终目标和步骤:</h1><p id="314b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这个项目背后的想法是确定我在家工作的性能，并了解如何使用物联网设备、AWS云以及简单的Web应用程序在edge上使用计算机视觉来改善我的工作站设置。</p><p id="6798" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">此外，我想分享在开发过程中发现的挫折，以及我为解决这些挫折而采取的措施。</p><p id="07a7" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">所以，根据需求，我的第一个想法是这样的:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/11b4d62ae44048a11b5f9324a097b9d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*3-dvnY3w1_ahWDX4i-snmQ.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">我工作站上方的摄像机，为了确定脸部位置，我<em class="mk">拍摄作者</em></p></figure><p id="9ed0" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">一旦定义了初始设置，我就开始确定获取数据所需的最少工具，在本例中是相机；由于在<a class="ae ml" href="https://rafael-a-rodriguez-m.medium.com/train-and-deploy-an-alpr-for-colombian-license-plate-with-tiny-yolov4-and-jetson-nano-without-5da6f975ea14" rel="noopener"> <strong class="kz ir"> LPR识别文章</strong> </a>中我使用了<a class="ae ml" href="https://www.amazon.com/-/es/gp/product/B077889YRN/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&amp;psc=1" rel="noopener ugc nofollow" target="_blank"> SV3C </a>低成本摄像头，我决定使用相同的摄像头，因为集成已经使用HTTP完成。</p><p id="5dde" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">这些是最初的图像:</p><div class="lz ma mb mc gt ab cb"><figure class="mm md mn mo mp mq mr paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><img src="../Images/3e4136527d506a79d12237c275d131a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*s24jPIJ8exCuHiv0vhey7g.jpeg"/></div></figure><figure class="mm md mn mo mp mq mr paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><img src="../Images/051f3f12472104a3f1f29dddb34aa083.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Y-0Pk-NI0ZLRTjbKGZhzJQ.jpeg"/></div><p class="mg mh gj gh gi mi mj bd b be z dk mw di mx my translated">右中我<em class="mk">作者</em>法师</p></figure></div><div class="ab cb"><figure class="mm md mn mo mp mq mr paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><img src="../Images/c1131ad8bf8b65bdce0feae3065b501d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*mu2SHaKL8uYcpyIyKHS9uw.jpeg"/></div></figure><figure class="mm md mn mo mp mq mr paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><img src="../Images/5242e56d6ebbedaa17f8db20175b9a48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*9idhuokahnYUb2WQV82hqQ.jpeg"/></div><p class="mg mh gj gh gi mi mj bd b be z dk mw di mx my translated">空，左，我作者<em class="mk">法师</em></p></figure></div><p id="f358" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">我使用了两个脚本来获取这些图像，一个用Python，一个用Bash(注意:关于这个项目的所有信息都可以在下面的<a class="ae ml" href="https://github.com/RrodriguezM/Face-position-app" rel="noopener ugc nofollow" target="_blank"> Github </a> repo中获得)。第一个用于创建名为<a class="ae ml" href="https://github.com/RrodriguezM/Face-position-app/blob/main/create-folder-structure.sh" rel="noopener ugc nofollow" target="_blank">create-folder-structure . sh</a>的文件夹结构，第二个用于收集名为<a class="ae ml" href="https://github.com/RrodriguezM/Face-position-app/blob/main/collect_images.py" rel="noopener ugc nofollow" target="_blank"> collect_images.py </a>的数据。</p><h1 id="ef30" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">获取输入数据:</h1><p id="b526" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">此时，我有了每个位置的设置和200张图像，我开始考虑如何使用这些图像，所以我最终使用带有<a class="ae ml" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet/EfficientNetB0" rel="noopener ugc nofollow" target="_blank"> EfficientNetB0 </a>的迁移学习作为特征提取器，只训练最后一层。这里是<a class="ae ml" href="https://colab.research.google.com/drive/1bjI2YLTwkMcrwIjK6Fo92C-IKzKHJSAJ?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab链接</a></p><p id="78a8" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">仅仅过了几个纪元，我就能达到80%以上的准确率。然而，我在实时测试中发现了一些挫折，因为我的想法是基于我的头部位置进行训练。然而，网络实际上学习了我的肩膀和手臂的位置，所以我有了更多的选择，如获得更多的数据，获得不同的图像，数据增强和更复杂的网络。不过，我想保持简单，所以我做了更多的研究，找到了一种新的方法。</p><p id="12f1" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">基于我最初的想法，我想跟踪我的脸，经过一些研究，我发现了一个名为<a class="ae ml" href="https://blog.tensorflow.org/2021/05/next-generation-pose-detection-with-movenet-and-tensorflowjs.html" rel="noopener ugc nofollow" target="_blank"> MoveNet </a>的神经网络，它由谷歌在2021年发布，能够检测身体中的17个关键点(<em class="mz">鼻子，左眼，右眼，左耳，右耳，左肩，右肩，左肘，右肘，左手腕，右手腕，左臀部，右臀部，左膝盖，右膝盖，左脚踝，右脚踝)</em>，通过前五个关键点，我有了一些关于我的脸的信息，或者任何信息</p><p id="89c5" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">另外，我改变了摄像机的位置。这就是做一个真正的项目而不是用数据集测试和学习的区别。对于真实的项目，您可以更改输入数据，并验证新数据是否比以前的数据提供了更多信息，我可以这样做，因为这是一个端到端的项目。</p><div class="lz ma mb mc gt ab cb"><figure class="mm md na mo mp mq mr paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><img src="../Images/386c8cad5a98dd2b825e60e24422ea43.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*nqDyiAAWrBqpOh72pt9Q1A.png"/></div></figure><figure class="mm md na mo mp mq mr paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><img src="../Images/ad64a922f801d8f7b0da8499c2394b62.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*ETHEgkvM_YhI-gUSYt7zUA.png"/></div></figure><figure class="mm md na mo mp mq mr paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><img src="../Images/3ebbb478f07aa4657b35bc39526a3e1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*68_EADQY3iQLy_WU9PWGRA.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk nb di nc my translated">我是作者的<em class="mk">法师</em></p></figure></div><p id="930d" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">有了这个信息，现在的方法是检测这5个关键点，并选择ML分类器来确定头部的位置。</p><h1 id="0457" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">选择分类器:</h1><p id="2f3d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">作为面向ML初学者的趋势技术的一部分，有几个<strong class="kz ir"> AutoML </strong>解决方案(<a class="ae ml" href="https://github.com/microsoft/FLAML" rel="noopener ugc nofollow" target="_blank"> FLAML </a>和<a class="ae ml" href="https://github.com/mljar/mljar-supervised" rel="noopener ugc nofollow" target="_blank"> MLJAR </a>)，所以我决定测试FLAML并获得使用哪个分类器的初始方向</p><p id="b087" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">只用几行代码:</p><pre class="lz ma mb mc gt nd ne nf ng aw nh bi"><span id="561c" class="ni kg iq ne b gy nj nk l nl nm">from flaml import AutoML<br/>automl = AutoML()<br/>automl.fit(X_train, y_train, task=”classification”, time_budget=120)</span></pre><p id="8bd1" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">我在验证集里得了84分</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi nn"><img src="../Images/fa9cf7549cd8b65b237cf14f4171a8d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*czPC8aWutQizDaNsPnG4ng.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">最佳ML解决方案*，作者本人<em class="mk">作者</em></p></figure><p id="d421" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">但是在测试集中有93%。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi no"><img src="../Images/5416cea5e19aaeb086f30caae598a2bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LWwJFh1HwvW2V2io3UmKMQ.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">我<em class="mk">作者法师</em></p></figure><p id="823c" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">这里是用于MoveNet未来提取和AutoML分类器的<a class="ae ml" href="https://colab.research.google.com/drive/1RD-a-c9Gs0oDoA39rkQAnCvvkxVB3qGo?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab </a>。</p><h1 id="4781" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">与AWS物联网的集成:</h1><p id="bfa5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">一旦我设置好获取图像，使用MoveNet获取关键点，并使用FLAML对图像进行分类，我想将信息发送给AWS。一个有趣的服务是AWS的物联网核心，所以这是我最后要介绍的基本架构:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi np"><img src="../Images/61b664f6aaddaff76411c7b6efd2bfc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ljybG4Hkn4vGJn_eeUpT9w.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">建筑，我<em class="mk">作者法师</em></p></figure><h1 id="cc6d" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">基本架构描述:</h1><p id="bcda" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">SV3C摄像头符合OVNIF标准。OVNIF有一些使用HTTP协议获取图像快照的标准方法，允许您随时获取图像，而不必处理视频流。你可以在<a class="ae ml" href="https://github.com/RrodriguezM/Face-position-app/blob/main/GetImagesCameraSv3c/getImage.py" rel="noopener ugc nofollow" target="_blank"> Github </a>中看到这个请求。</p><p id="5c09" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">对于终端设备和AWS物联网核心之间的通信，我使用了MQTT，这是一种帮助我轻松通过远程设备进行通信和操作的通信协议，允许我在未来添加任何智能开关，以便在我离开办公室时关灯。</p><p id="28f4" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">这部分是基于下面的AWS <a class="ae ml" href="https://aws.amazon.com/premiumsupport/knowledge-center/iot-core-publish-mqtt-messages-python/" rel="noopener ugc nofollow" target="_blank">博客</a>来使用Python <strong class="kz ir"> awsiotsdk </strong></p><p id="be77" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">关于我正在使用的AWS服务，两者都是无服务器的，可以扩展到数十亿台设备，我只为我使用的服务付费(按需付费)。对于DynamoDB，集成基于以下<a class="ae ml" href="https://docs.aws.amazon.com/iot/latest/developerguide/iot-ddb-rule.html" rel="noopener ugc nofollow" target="_blank">文档</a>。我还将图片上传到一个S3桶中，并存储在一个名为predictions的文件夹中，这将帮助我验证模型的行为。</p><p id="ba43" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">然后我们有Streamlit，我现在在本地使用它只是为了得到一个概述。</p><h1 id="d843" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">在JetsonNano中运行它:</h1><p id="f76f" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">当我准备好模型并在我的电脑上工作后，我决定将它转移到Jetson Nano上时，真正的挑战就开始了。主要原因是Jetson耗尽了内存，AutoML库(Flaml)有一些问题需要安装。</p><p id="1025" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">经过进一步的研究，我发现使用<strong class="kz ir"> Tflite </strong>的MoveNet模型解决了内存问题，但我仍然有Flaml库的问题。然而，这个博客中提到了解决方案；我建议AutoML获得一个初始方向，并且基于从Flaml库获得的输出，我找到了AutoML建议的模型的特定库，在这种情况下，<a class="ae ml" href="https://lightgbm.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> LGBM </a>如(最佳ML解决方案*)图所示。</p><p id="e727" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">参见<code class="fe nq nr ns ne b">realtimepredictionmovenetflaml.py</code>中的Tflite实现和本<a class="ae ml" href="https://colab.research.google.com/drive/1JA-fomqWhzD570D4QlmX623bzc6Fk7kR?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab </a>中的初始测试</p><p id="5211" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated">参见本<a class="ae ml" href="https://colab.research.google.com/drive/1RD-a-c9Gs0oDoA39rkQAnCvvkxVB3qGo#scrollTo=--pI-RmRrNEI" rel="noopener ugc nofollow" target="_blank"> Colab </a>中的LGBM培训</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi nt"><img src="../Images/a891ee85c831f3ba1e1917edd44cd902.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eQRUW1MLWhU90OG6o_1i2A.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">我<em class="mk">作者法师</em></p></figure><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi nu"><img src="../Images/b47bdddced242c51857a15fee3a07188.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AzjTC6_D-ei2ErzX5eI-WQ.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">杰特森留言，我<em class="mk">法师作者</em></p></figure><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi nv"><img src="../Images/d37fc360411042e9e6469622ede1e2d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VO5AzezCeC4GjDdiQL49Eg.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">AWS物联网控制台记录消息</p></figure><h1 id="b889" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">运行项目的脚本:</h1><ul class=""><li id="3970" class="nw nx iq kz b la lb ld le lg ny lk nz lo oa ls ob oc od oe bi translated">要进行实时推断并将数据发送给AWS:</li></ul><p id="d97f" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated"><code class="fe nq nr ns ne b">python realtimepredictionmovenetflaml.py</code></p><ul class=""><li id="2389" class="nw nx iq kz b la lt ld lu lg of lk og lo oh ls ob oc od oe bi translated">要在本地运行Streamlit服务器:</li></ul><p id="7918" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated"><code class="fe nq nr ns ne b">streamlit run app.py</code></p><ul class=""><li id="23de" class="nw nx iq kz b la lt ld lu lg of lk og lo oh ls ob oc od oe bi translated">要从相机收集图像:</li></ul><p id="958b" class="pw-post-body-paragraph kx ky iq kz b la lt jr lc ld lu ju lf lg lv li lj lk lw lm ln lo lx lq lr ls ij bi translated"><code class="fe nq nr ns ne b">python collect_images.py</code></p><ul class=""><li id="92d5" class="nw nx iq kz b la lt ld lu lg of lk og lo oh ls ob oc od oe bi translated">要训练NN，去<a class="ae ml" href="https://colab.research.google.com/drive/1RD-a-c9Gs0oDoA39rkQAnCvvkxVB3qGo?usp=sharing" rel="noopener ugc nofollow" target="_blank">实验室</a></li></ul><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi oi"><img src="../Images/b8f6be64bb75e46d99c7699ab0f9deba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fUm-DN6ZVsMW6k6lTv5VmQ.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">网页原型，作者本人<em class="mk">图片</em></p></figure><h1 id="dd0c" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">从原型到产品的改进和评论:</h1><p id="662f" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">本项目有许多需要改进的地方，例如:</p><ul class=""><li id="0acb" class="nw nx iq kz b la lt ld lu lg of lk og lo oh ls ob oc od oe bi translated">从Streamlit到SPA的变化可能类似于React.js</li><li id="314f" class="nw nx iq kz b la oj ld ok lg ol lk om lo on ls ob oc od oe bi translated">使用更多图像进行训练，以提高准确性</li><li id="6176" class="nw nx iq kz b la oj ld ok lg ol lk om lo on ls ob oc od oe bi translated">添加数据扩充</li><li id="7336" class="nw nx iq kz b la oj ld ok lg ol lk om lo on ls ob oc od oe bi translated">添加基础设施作为配置所有AWS服务的代码</li><li id="d861" class="nw nx iq kz b la oj ld ok lg ol lk om lo on ls ob oc od oe bi translated">获取更多指标</li><li id="7af1" class="nw nx iq kz b la oj ld ok lg ol lk om lo on ls ob oc od oe bi translated">添加可见性(日志)</li></ul></div></div>    
</body>
</html>