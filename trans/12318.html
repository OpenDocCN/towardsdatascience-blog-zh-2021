<html>
<head>
<title>4 Up-to-Date Techniques for Image Data Augmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">4最新的图像数据增强技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/4-up-to-date-techniques-for-image-data-augmentation-5bdf34ace063?source=collection_archive---------41-----------------------#2021-12-14">https://towardsdatascience.com/4-up-to-date-techniques-for-image-data-augmentation-5bdf34ace063?source=collection_archive---------41-----------------------#2021-12-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="62a5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">想把你的精确度再提高一点吗？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/be3e3302684fd60fc805fa3fa0ddb52c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dpV3qIIT8pP315Kue-5EDA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图一。演示不同的图像增强技术。从<a class="ae ky" href="https://arxiv.org/abs/1905.04899" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1905.04899</a>检索的图像。</p></figure><p id="d3b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据扩充是几乎每个机器学习工程师用来提高结果的技巧。翻转图像等简单技巧可以轻松获得图像分类模型的百分之几的准确度，而无需进行太多的微调。</p><p id="3f6b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，这些简单的技术，如翻转、旋转和抖动图像，并不是我们今天要讨论的内容。相反，我们将讨论在深度学习时代引入的4种非正统技术，这些技术在改善图像相关任务(如分类、检测和分割)方面表现出了巨大的潜力。请做好准备，因为这些增强技术中的一些可能看起来太过奇怪而不真实！</p><h1 id="b46d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">1.断流器</h1><p id="1dab" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><a class="ae ky" href="https://arxiv.org/abs/1708.04552" rel="noopener ugc nofollow" target="_blank">剪切</a>可能是本文介绍的四种技术中最直观的一种。目标是“切掉”图像的一部分，并将剩余部分用作具有相同标签的新图像数据(见图1)。由于增强技术，如抖动和添加颜色，使图像更具挑战性，已被证明是有益的，它应该没有什么不同的方法剪切工作。</p><h1 id="88eb" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">2.混合</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/fcccb847bc7c9275b64474033423978c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*QA3myTJbfw3Ddh3cTgLTeg.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图二。图像混合的简单可视化。图片作者。</p></figure><p id="0cc7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2017年推出的这种数据增强策略非常简单，乍一看常常会怀疑它的能力。张等人在他们的<a class="ae ky" href="https://arxiv.org/abs/1710.09412" rel="noopener ugc nofollow" target="_blank">论文</a>中首先提出了这种技术:我们对两幅图像进行插值，然后我们插值相应的标签作为新的标签。</p><p id="4ef0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过在不同数据集上的大量测试，我们实际上可以看到这种简单的技术提高了各种模型主干的性能。结果被推测是由于在数据集上创建的软标签混合，使得在训练期间可以看到更广泛的数据分布。</p><p id="cf45" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mt">边注:这里</em>  <em class="mt">我还有一篇关于实现Mixup </em> <a class="ae ky" rel="noopener" target="_blank" href="/enhancing-neural-networks-with-mixup-in-pytorch-5129d261bc4a"> <em class="mt">的文章。</em></a></p><h1 id="04ee" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">3.剪切混合</h1><p id="617a" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在，如果你对mixup的工作感到惊讶，你会惊叹于<a class="ae ky" href="https://arxiv.org/abs/1905.04899" rel="noopener ugc nofollow" target="_blank"> CutMix </a>工作得更好！Yun等人决定将一幅图像的一部分剪切并粘贴到另一幅图像上，而不是将每个像素混合在一起，剪切-粘贴比率用作生成图像的新标签(见图1)。同样，这种技术非常简单，易于实现，但在处理图像分类任务时却非常强大。</p><p id="8333" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另外，最近的论文<a class="ae ky" href="https://arxiv.org/pdf/2003.13048v2.pdf" rel="noopener ugc nofollow" target="_blank">attention cut mix</a>引入了attentive feature map来决定在哪里剪切和粘贴，这显示了更好的效果。</p><h1 id="c707" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">4.复制并粘贴</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/27f64cd41bdaf2f1ce5884ea103a8116.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4maCA_DaWoQTE5JwoGs5WQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3。复制粘贴演示。图片来自https://arxiv.org/abs/2012.07177的<a class="ae ky" href="https://arxiv.org/abs/2012.07177" rel="noopener ugc nofollow" target="_blank">。</a></p></figure><p id="8c83" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://arxiv.org/abs/2012.07177" rel="noopener ugc nofollow" target="_blank"> Ghiasi等人</a>决定将CutMix的成功转移到实例分割中，方法是将一个实例从一个图像随机复制到另一个图像，以允许图像将其正确分割出来。同样，研究结果表明，这种增强技术在提高性能方面非常有效。</p><h1 id="225d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">自己测试</h1><p id="aba3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">使用PyTorch之类的框架测试所有这些数据扩充技术非常简单。人们可以容易地改变数据加载器内的图像和相应的标签，以实现所有上述数据扩充技术。</p><p id="40cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，由于我们必须深入研究数据加载器，所以我们不能直接使用PyTorch提供的数据加载器。我发现一个有用的平台是<a class="ae ky" href="https://gas.graviti.com/open-datasets" rel="noopener ugc nofollow" target="_blank"> Graviti Open Dataset </a>平台，它连接到许多学术上著名的数据集(例如，CIFAR10、ImageNet)，这样就不需要查看哪些数据集经常用于特定任务。我还会推荐PyTorch 的<a class="ae ky" href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html" rel="noopener ugc nofollow" target="_blank">教程，当你添加你的扩充时。</a></p><h1 id="5a36" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="48c4" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">所以你有它！希望这些增加了一些你可以玩的技巧来提升你的图像模型到一个新的水平！</p><p id="325e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mt">感谢您坚持到现在</em>🙏<em class="mt">！</em> <em class="mt">我会在计算机视觉/深度学习的不同领域发布更多内容，所以</em> <a class="ae ky" href="https://taying-cheng.medium.com/membership" rel="noopener"> <em class="mt">加入并订阅</em> </a> <em class="mt">如果你有兴趣了解更多！</em></p></div></div>    
</body>
</html>