<html>
<head>
<title>Texture vs Shape: The Bias in CNNs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">纹理与形状:CNN中的偏见</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/texture-vs-shape-the-bias-in-cnns-5ee423edf8db?source=collection_archive---------18-----------------------#2021-05-30">https://towardsdatascience.com/texture-vs-shape-the-bias-in-cnns-5ee423edf8db?source=collection_archive---------18-----------------------#2021-05-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ea16" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">论文“图像网络训练的细胞神经网络偏向于纹理”概述</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/89ea6aa61c3c9652da8e4aa3dfac971f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*Bzp6bNLZtTDODeGAj9Qmig.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">来自<a class="ae kr" href="https://modelzoo.co/model/neural-style" rel="noopener ugc nofollow" target="_blank">博客</a></p></figure><p id="e40e" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">十多年前，随着CNN在当时可用的少数数据集上用于分类任务的引入，深度学习和计算机视觉领域已经走过了漫长的道路。我们已经看到了许多令人兴奋的应用，从自动驾驶汽车中用于了解其环境的检测和分割到<a class="ae kr" href="https://medium.com/analytics-vidhya/top-5-gan-generative-adversarial-networks-projects-for-final-year-computer-science-students-ff35eab94e4f" rel="noopener"> <em class="lo">基于GAN的图像修复、着色和风格转移</em> </a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lp"><img src="../Images/db0b8754998c95ed30bb48ced28a8517.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S7C7K1kPVwNCL1m0Yo-JbA.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">甘使用案例:从报纸上，<a class="ae kr" href="https://github.com/switchablenorms/DeepFashion_Try_On" rel="noopener ugc nofollow" target="_blank">深度试衣</a></p></figure><p id="714f" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">尽管我们看到了这么多激动人心的关于CNN架构及其应用的研究论文，但我们仍然不知道为什么这些系统会做出这样的决定。这就是为什么我们认为这些系统是“黑匣子”，我们不知道特定决策背后的“推理”。不能因为这些行为在预定义的指标上得分高就忽视它们。例如，<a class="ae kr" href="http://gendershades.org/overview.html" rel="noopener ugc nofollow" target="_blank"> <em class="lo">性别形状项目</em> </a> <em class="lo"> </em>显示，各种人脸识别系统在少数族裔类上的表现更差(肤色较浅的男性和肤色较深的女性之间的准确率差异高达34%)。现在，如果这种系统用于执法、机场或就业筛查，<a class="ae kr" href="https://sitn.hms.harvard.edu/flash/2020/racial-discrimination-in-face-recognition-technology/" rel="noopener ugc nofollow" target="_blank"> <em class="lo">这种偏差可能会产生重大影响</em> </a>。这突出了“可解释性”在计算机视觉系统中的重要性。</p><p id="ca18" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">“对抗性攻击”展示了CNN的一种违反直觉的行为。这些例子是专门设计来欺骗CNN预测错误的标签，只是通过用人眼无法分辨的噪声改变图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lu"><img src="../Images/b2d860fb882993c7808d2f32ea285371.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ERzboYp-C4uq0epwoPNDbA.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">FSGM攻击对抗示例来自<a class="ae kr" href="https://arxiv.org/pdf/1412.6572.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p></figure><p id="227c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这被称为“白盒”对抗性攻击，因为我们可以访问CNN的权重。为了训练CNN，我们最小化对给出输入数据的标签的损失。这里，我们使用梯度计算输入，以优化最大损耗。结果，我们得到了人眼无法识别的失真，而CNN预测了错误的标签。</p><p id="8c3c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">论文<a class="ae kr" href="https://arxiv.org/pdf/1811.12231.pdf" rel="noopener ugc nofollow" target="_blank">’<em class="lo">捕捉到了一个这样的行为，ImageNet训练的CNN偏向纹理’</em></a>。让我们开始吧…</p><p id="e450" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir"> <em class="lo">以前纹理偏向的迹象:</em> </strong></p><p id="048c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">对于CNN是如何运作的，有一种被广泛接受的直觉。CNN结合底层特征(线条、边缘)，分层学习更复杂的特征(车轮、人脸、树干)。换句话说，最后一层的预测将更多地取决于对象的全局形状，而不是局部纹理。但是有一些矛盾的发现，我把它们列在下面。</p><pre class="kg kh ki kj gt lv lw lx ly aw lz bi"><span id="e10b" class="ma mb iq lw b gy mc md l me mf">1. “CNNs can still classify texturized images perfectly well, even if the global shape structure is completely destroyed” (Gatys et al., 2017; Brendel &amp; Bethge, 2019).<br/>2. “Standard CNNs are bad at recognizing object sketches where object shapes are preserved yet all texture cues are missing” (Ballester &amp; de Araujo, 2016).<br/>3. “Gatys et al. (2015) discovered that a linear classifier on top of a CNN’s texture representation (Gram matrix) achieves hardly any classification performance loss compared to original network performance”.<br/>4. “Brendel &amp; Bethge (2019) demonstrated that CNNs with explicitly constrained receptive field sizes throughout all layers are able to reach surprisingly high accuracies on ImageNet, even though this effectively limits a model to recognizing small local patches rather than integrating object parts for shape recognition.”</span></pre><p id="1950" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">因此，这篇论文确定了CNN的这种特殊行为，这将解释上述观察结果。下图总结了这种行为。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mg"><img src="../Images/9a62380ac690292189dbfe7d38acfacf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*__GbM4pigqp0KJ8__z6SNQ.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">摘自<a class="ae kr" href="https://arxiv.org/pdf/1811.12231.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p></figure><p id="6f5d" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在这里，我们可以清楚地看到，即使猫的全局结构在那里，所有的顶部预测都是基于纹理，即象皮。</p><p id="9e00" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir"> <em class="lo">心理物理实验:</em> </strong></p><p id="8292" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">为了深入研究这种行为，作者提出了心理物理学实验来测试人类中枢神经系统。为了理解这种偏见，我们首先要理清形状和纹理信息，看看受试者倾向于哪里。这是通过各种方式交换原始纹理信息来完成的，即心理物理学实验的数据集。</p><p id="11ca" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir"> <em class="lo">数据集:</em> </strong></p><ul class=""><li id="3569" class="mh mi iq ku b kv kw ky kz lb mj lf mk lj ml ln mm mn mo mp bi translated"><strong class="ku ir">原稿:</strong> 160张自然彩色图像，白色背景(避免任何来自背景的信息)</li><li id="d52a" class="mh mi iq ku b kv mq ky mr lb ms lf mt lj mu ln mm mn mo mp bi translated"><strong class="ku ir">灰度:</strong>图像转换为灰度，用于堆叠在3个通道上的CNN</li><li id="ce03" class="mh mi iq ku b kv mq ky mr lb ms lf mt lj mu ln mm mn mo mp bi translated"><strong class="ku ir">剪影:</strong>白色背景上的黑色图像，类似语义分割图</li><li id="346b" class="mh mi iq ku b kv mq ky mr lb ms lf mt lj mu ln mm mn mo mp bi translated"><strong class="ku ir">边缘:</strong>通过Canny边缘检测器进行基于边缘的表示</li><li id="f37d" class="mh mi iq ku b kv mq ky mr lb ms lf mt lj mu ln mm mn mo mp bi translated"><strong class="ku ir">纹理:</strong> 48幅自然纹理图像或同一物体的重复</li><li id="7bf5" class="mh mi iq ku b kv mq ky mr lb ms lf mt lj mu ln mm mn mo mp bi translated"><strong class="ku ir">提示冲突:</strong>使用<a class="ae kr" href="https://www.tensorflow.org/tutorials/generative/style_transfer" rel="noopener ugc nofollow" target="_blank"> <em class="lo">样式转移算法</em> </a>生成的图像，使用原始(内容)和纹理(样式)</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mv"><img src="../Images/5cd4bb6d26be99106f4b7ee80959c42c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q51fSq95hwFm-oVKDOGlUg.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">来自<a class="ae kr" href="https://arxiv.org/pdf/1811.12231.pdf" rel="noopener ugc nofollow" target="_blank">的论文</a></p></figure><p id="7502" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这里，灰度、轮廓、边缘和线索冲突形成了实验设置。对这些图像的预测可以是基于形状的，也可以是基于纹理的。使用多种方式交换出纹理，我们可以确定结果不是由于特定的源纹理。</p><p id="ddf0" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">现在，关于标签，作者通过wordnet层次结构使用16个imagenet类作为标签。作者选择了在imagenet上训练的4个CNN网络，即VGG16、GoogleLeNet、AlexNet和ResNet50。现在，关于标签，作者通过WordNet层次结构使用16个imagenet类作为标签。对于试验的参与者来说，他们必须从16个标签中为每张显示的图片选择一个。</p><p id="a626" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir"> <em class="lo">结果:</em> </strong></p><p id="afa1" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">作者分三步解释了论文的结果。</p><ul class=""><li id="b52d" class="mh mi iq ku b kv kw ky kz lb mj lf mk lj ml ln mm mn mo mp bi translated">CNN和人类的形状与纹理偏见。</li><li id="3740" class="mh mi iq ku b kv mq ky mr lb ms lf mt lj mu ln mm mn mo mp bi translated">使用风格化的Imagenet克服纹理偏见(下面讨论)</li><li id="38c1" class="mh mi iq ku b kv mq ky mr lb ms lf mt lj mu ln mm mn mo mp bi translated">以及在风格化Imagenet上训练的模型的鲁棒性</li></ul><p id="519a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><a class="ae kr" rel="noopener" target="_blank" href="/food-for-thought-paper-tuesday-3c0a9b3e432f"> <em class="lo">这里</em> </a>，这些实验的结果解释得非常透彻。</p><p id="e0c4" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir"> <em class="lo">解决方案:风格化Imagenet </em> </strong></p><p id="de2a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">现在，纹理偏见被证实了，下一步将是试着把CNN推向形状偏见，就像人类对应物所展示的那样。作者解释说，imagenet任务本身并不需要CNN学习基于形状的表示，局部特征的集成对于最大化准确性非常有用。基于这一假设，作者提出了一种新的数据集作为解决方案:风格化的Imagenet。目标是去除原始图像的纹理，并用随机化的样式替换它。这既作为稳健模型的训练数据，又作为稳健性的测试，这对于具有形状偏差的模型来说是难以解决的。</p><p id="a3c7" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">上面还讨论了这些SIN训练模型的好处和传统模型的稳健性测试。</p><p id="a8e3" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir">T13】结论:T15】</strong></p><p id="9c6b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">本文假设纹理偏见是一种解释零散发现的方式，这些发现无法用我们之前对CNN工作方式的直觉来解释。对于本文的范围，作者检查了ImageNet训练模型的纹理偏差，发现这种行为在模型之间是一致的。为了推动模型学习形状偏差，作者提出了一个新的风格化imagenet数据集，通过各种失真图像来检验其纹理偏差结果。</p><p id="85ea" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir"> <em class="lo">进一步讨论:</em> </strong></p><p id="9e6c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">现在，这留给我们两个问题…</p><ul class=""><li id="399d" class="mh mi iq ku b kv kw ky kz lb mj lf mk lj ml ln mm mn mo mp bi translated">这种行为是否仅发生在Imagenet训练图像上，即它是数据集属性吗？</li></ul><p id="4793" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如上所述，解决imagenet不需要模型学习基于形状的表示。另一篇论文讨论了类似的思路，深入解释了对立的例子，在许多事情中回答了这个问题。</p><ul class=""><li id="921d" class="mh mi iq ku b kv kw ky kz lb mj lf mk lj ml ln mm mn mo mp bi translated">如果我们之前的理解是错误的，是什么原因导致CNN出现这样的行为？</li></ul><p id="290a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这属于CNN的可解释性研究范式，是一个活跃的研究领域。要了解更多关于这个话题，你可以试试<a class="ae kr" href="https://distill.pub/2017/feature-visualization/" rel="noopener ugc nofollow" target="_blank">这个</a>和<a class="ae kr" href="https://distill.pub/2018/building-blocks/" rel="noopener ugc nofollow" target="_blank">这个</a>博客。</p><p id="548e" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这篇论文由<a class="ae kr" href="http://bethgelab.org/" rel="noopener ugc nofollow" target="_blank"> Bethge实验室</a>的惊人团队发表，他们也发表了<a class="ae kr" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank">神经类型转移</a>算法。你可以在他们的网站上查看一些其他有趣的项目。</p><p id="1021" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">希望你喜欢我对这篇研究论文的看法，如果有任何问题或建议，请告诉我。快乐学习！！！</p></div></div>    
</body>
</html>