<html>
<head>
<title>Scikit-learn Pipeline Tutorial with Parameter Tuning and Cross-Validation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">sci kit-学习管道教程，包括参数调整和交叉验证</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scikit-learn-pipeline-tutorial-with-parameter-tuning-and-cross-validation-e5b8280c01fb?source=collection_archive---------11-----------------------#2021-08-16">https://towardsdatascience.com/scikit-learn-pipeline-tutorial-with-parameter-tuning-and-cross-validation-e5b8280c01fb?source=collection_archive---------11-----------------------#2021-08-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b22b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在机器学习项目中，对用于训练和验证目的的不同数据集应用预处理步骤通常是一个问题——sci kit-learn管道功能有助于解决这个问题</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c95343d4fdea6ce6d394d19a8ce948e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ro_8haXpk80DQZQi"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@jjying?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> JJ英</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="cfa3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">什么是机器学习工作流？—它包括所有的预处理步骤，如一键编码、标签编码、缺失值插补，然后是任何特征选择步骤，如选择最佳或递归特征消除(RFE)，然后是模型开发和验证步骤—所有这些都构成了一个机器学习工作流。</p><p id="6d5e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个工作流程面临哪些挑战？—一个主要挑战是将相同的变换函数应用于训练、测试和验证数据集。在干净的代码中，优化的方式是使用用户定义的函数，不是每个数据科学家都愿意编写有效的函数。</p><p id="9018" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于这个问题，scikit-learn Pipeline特性是一个开箱即用的解决方案，它可以在没有任何用户定义函数的情况下实现干净的代码。</p><p id="f3bf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我用一个示例数据集来演示管道是如何工作的。我采用了一个关于信贷审批的UCI机器学习数据集，其中混合了分类列和数字列。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="1fb3" class="lx ly iq lt b gy lz ma l mb mc">data = pd.read_csv('bank-full.csv', sep=';')<br/>target = data.pop('y')<br/>target = target.map({'yes': 1, 'no':0})<br/>X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=1234)</span></pre><p id="4a6b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我的真实项目中，我有40多个分类特征，有些有超过50个类别，为此我必须使用OrdinalEncoder。为此类功能创建一次性编码将导致内存错误。对于演示数据集，我有两列想要应用ordinal encoder——月份和教育资格——这两列都有意义，因为它们是有序值。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="d454" class="lx ly iq lt b gy lz ma l mb mc">categorical_mask = (data.dtypes=='object')<br/>categorical_columns = data.columns[categorical_mask].tolist()<br/>num_cols = data.select_dtypes(include=['int64','float64']).columns.tolist()</span><span id="40df" class="lx ly iq lt b gy md ma l mb mc">oe_cols = [c for c in categorical_columns if data[c].nunique()&gt;5]<br/>ohe_cols = [c for c in categorical_columns if data[c].nunique()&lt;=5]<br/>len(oe_cols), len(ohe_cols), len(num_cols)</span></pre><p id="2e8e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在分离列之后，我们现在从每个分类列的初始数据集中获得一个唯一值列表，以便可以在定型、测试和验证数据集之间使用相同的值。这也将给出所有值的详尽列表。人们经常发现，有些值存在于训练中，而不存在于验证中(反之亦然)。为了避免这个问题，我们从初始数据集中取唯一值。有些人可能会质疑建模时可能会有数据泄漏，但是我们是单独应用转换的。</p><p id="21e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们现在定义要使用的转换器类型——OneHotEncoder、OrdinalEncoder、simple imputr——我们也可以在此步骤中使用某种缩放函数，如MinMaxScaler / StandardScaler。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="cdc8" class="lx ly iq lt b gy lz ma l mb mc">ohe_unique_list = [data[c].unique().tolist() for c in ohe_cols]<br/>oe_unique_list = [data[c].unique().tolist() for c in oe_cols]</span><span id="5bea" class="lx ly iq lt b gy md ma l mb mc">ohe = OneHotEncoder(categories=ohe_unique_list)<br/>oe = OrdinalEncoder(categories=oe_unique_list)<br/>imp = SimpleImputer(strategy='constant', fill_value=0)</span></pre><p id="b5fa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们使用<code class="fe me mf mg lt b">scikit-learn</code>的<code class="fe me mf mg lt b">make_column_transformer</code>函数来创建预处理列转换器。此外，我们定义了一个参数<code class="fe me mf mg lt b">remainder='passthrough'</code>，让没有任何转换器标准的所有其他列通过。我们可以使用像<code class="fe me mf mg lt b">drop</code>这样的其他值来删除任何没有预处理步骤的列。</p><p id="af06" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如我最初所说的，我有如此多的预测变量，我必须进行特征选择，为此，我尝试了2个函数——select kbest和recursivefeaturelimination(RFE)。SelectKBest简单快捷。并且它需要像<code class="fe me mf mg lt b">f_classif</code>、<code class="fe me mf mg lt b">chi2</code>这样的函数来找到最佳特性。而RecursiveFeatureElimination是一个缓慢的过程，它试图一个接一个地移除特征以找到最佳特征。</p><p id="a577" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在特性选择步骤的顶部，我使用XGBoost作为估计器来预测概率。</p><p id="2848" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在所有这些都被定义为流水线的步骤。因此，如果我们调用管道，它将对数据集进行预处理、特征选择和模型拟合。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="974d" class="lx ly iq lt b gy lz ma l mb mc">preprocess = make_column_transformer(<br/>    (oe, oe_cols),<br/>    (ohe, ohe_cols),<br/>    (imp, num_cols),<br/>    remainder='passthrough'<br/>)<br/>estimator = XGBClassifier(learning_rate=0.05, max_depth=3, n_estimators=2500, random_state=1234)<br/>fs = SelectKBest(score_func=f_classif, k=5)<br/>selector = RFE(estimator, n_features_to_select=5, step=1)</span><span id="68fa" class="lx ly iq lt b gy md ma l mb mc">steps = [<br/>    ('preprocess', preprocess),<br/>    ('select', fs),<br/>    ('clf', estimator)<br/>]<br/>pipeline = Pipeline(steps)</span></pre><p id="2865" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，它就像任何其他机器学习算法一样简单，我们首先拟合，然后使用预测。预测函数执行所有其他预处理，然后应用定型模型。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="5a14" class="lx ly iq lt b gy lz ma l mb mc">pipeline.fit(X_train, y_train)<br/>y_pred = pipeline.predict(X_test)<br/>pred_df = pd.DataFrame({'y': y_test,'y_pred': y_pred})<br/>gini = 2*roc_auc_score(y_test, y_pred)-1</span></pre><p id="aad6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于我的用例，我需要评估基尼指数，为此我使用了<code class="fe me mf mg lt b">43.33</code>。</p><p id="aa77" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们进行随机搜索交叉验证，以找到最佳AUC (Gini ),为此，我将一些搜索参数传递给XGBoostRegressor。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="27c3" class="lx ly iq lt b gy lz ma l mb mc">param_grid = {<br/>    'clf__learning_rate': np.arange(0.05, 1, 0.05),<br/>    'clf__max_depth': np.arange(3,10,1),<br/>    'clf__n_estimators': np.arange(50,250,50)<br/>}</span><span id="0287" class="lx ly iq lt b gy md ma l mb mc">rand_auc = RandomizedSearchCV(estimator=pipeline, param_distributions=param_grid, n_iter=5, scoring='roc_auc', cv=5, verbose=False)<br/>rand_auc.fit(X_train, y_train)<br/>rand_auc.best_score_</span><span id="7b0e" class="lx ly iq lt b gy md ma l mb mc">y_pred = rand_auc.predict(X_test)<br/>pred_df = pd.DataFrame({'y': y_test,'y_pred': y_pred})<br/>gini = 2*roc_auc_score(y_test, y_pred)-1</span></pre><p id="8401" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我有了Gini或<code class="fe me mf mg lt b">46.48</code>，比之前的方法稍微好一点——可能需要对模型进行更多的微调。但这不是本教程的重点。</p><p id="be57" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们可以在for循环中的各种分类器上测试相同的管道，比较分数并选择最佳模型。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="236c" class="lx ly iq lt b gy lz ma l mb mc">classifiers = [<br/>    KNeighborsClassifier(3),<br/>    SVC(kernel="rbf", C=0.025, probability=True),<br/>    NuSVC(probability=True),<br/>    DecisionTreeClassifier(),<br/>    RandomForestClassifier(),<br/>    AdaBoostClassifier(),<br/>    GradientBoostingClassifier()<br/>    ]</span><span id="cdda" class="lx ly iq lt b gy md ma l mb mc">for classifier in classifiers:<br/>    steps = [<br/>        ('preprocess', preprocess),<br/>        ('select', fs),<br/>        ('clf', classifier)<br/>    ]<br/>    pipeline = Pipeline(steps)<br/>    pipeline.fit(X_train, y_train)   <br/>    print(classifier)<br/>    print("model score: %.3f" % pipeline.score(X_test, y_test))</span></pre><p id="65af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如您所见，使用scikit-learn的管道功能有助于简化机器学习工作流程，并使数据科学家的工作更加轻松，可以将时间集中在微调模型上，而不是重复进行数据预处理步骤。</p></div></div>    
</body>
</html>