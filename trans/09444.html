<html>
<head>
<title>Self-supervised Learning Algorithm: Vector Difference and Vector Sum with IOUs (VDVS)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自监督学习算法:带IOUs的矢量差和矢量和(VDVS)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/self-supervised-learning-algorithm-vector-difference-and-vector-sum-with-ious-vdvs-d8d4ecbdecfb?source=collection_archive---------42-----------------------#2021-09-01">https://towardsdatascience.com/self-supervised-learning-algorithm-vector-difference-and-vector-sum-with-ious-vdvs-d8d4ecbdecfb?source=collection_archive---------42-----------------------#2021-09-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="749a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一种使用嵌入向量的和与差的自监督学习算法</h2></div><p id="94d8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="le">链接到GitHub中的资源库:</em></strong><a class="ae lf" href="https://github.com/evrimozmermer/vectorsum_vectordifference" rel="noopener ugc nofollow" target="_blank"><strong class="kk iu"><em class="le">【https://github.com/evrimozmermer/vectorsum_vectordifference】</em></strong></a></p><h1 id="6231" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">介绍</h1><p id="b6d7" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">自我监督学习是深度学习模型的学习方法，它试图在没有人类监督的情况下捕捉有意义的特征，从而迫使模型将输入数据映射到特定的标签。<a class="ae lf" href="https://www.youtube.com/watch?v=8L10w1KoOU8&amp;list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI&amp;index=21" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu"> 10L —计算机视觉中的自监督学习</strong> </a> <strong class="kk iu">中提到了几种自监督学习方法。</strong></p><p id="a3dc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章里，我分享一个我做的方法(据我所知)。</p><h1 id="32f2" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">提议的方法</h1><p id="e512" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">所提出的方法使用在<a class="ae lf" href="https://arxiv.org/ftp/arxiv/papers/2104/2104.11231.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu"> VeriMedi:使用基于代理的深度度量学习和精确解的药丸识别</strong> </a> <strong class="kk iu">的未来研究部分中所述的向量和逻辑。</strong></p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi md"><img src="../Images/fb01fff05df42c60088484d63043b5e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gJC_TzsrFi9s9-eSJuc1OA.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">作者提供的图片-建议方法的图表</p></figure><p id="9a93" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">步骤:</p><ol class=""><li id="1024" class="mt mu it kk b kl km ko kp kr mv kv mw kz mx ld my mz na nb bi translated">在图像的左上角定义随机坐标。</li><li id="48f3" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">用定义的随机坐标和输入图像的一半大小裁剪随机片段。将裁剪的图像调整到输入图像大小。计算裁剪图像组合的并集交集(IOU)。</li><li id="a2cf" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">将裁剪后的图像提供给模型，并生成嵌入向量。(Ic:裁剪图像，Ec:裁剪图像的嵌入向量)</li><li id="85e9" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">计算嵌入向量(Ec)组合的余弦相似度。(C:组合如[(0，1)，(0，2)，(1，2)])。</li><li id="00a2" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">计算loss 1，其中as-is参数为Ec，to-be参数为IOUs。</li><li id="0224" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">将输入图像提供给模型，并生成嵌入向量。(Ei:输入图像的嵌入向量)</li><li id="c24c" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">对裁剪图像的嵌入向量求和，并计算Ei和Sum(Ec)之间的余弦相似度。</li><li id="3c8f" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">根据输入图像上裁剪图像的遮罩总和计算IOU。</li><li id="18e5" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">计算损耗2，其中现状参数是上一步中的IOU，目标参数是Ei与Sum(Ec)之间的余弦相似性。</li><li id="22e0" class="mt mu it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">合计损失并反向传播损失。</li></ol><h1 id="e969" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">损失函数</h1><p id="f529" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">为了计算损失，我使用了欧拉数，因为它的图形。计算损耗时，我从现有参数(D)中减去未来值。然后，我把D的欧拉数的幂加上一个系数。然后，我从总函数中减去1，将图形下移。红线表示正损失，蓝线表示负损失。</p><h2 id="6c0d" class="nh lh it bd li ni nj dn lm nk nl dp lq kr nm nn ls kv no np lu kz nq nr lw ns bi translated">Python中的损失</h2><pre class="me mf mg mh gt nt nu nv nw aw nx bi"><span id="c854" class="nh lh it nu b gy ny nz l oa ob">def criterion(to_be, as_is):<br/>    diff = as_is-to_be<br/>    res = torch.where(diff&gt;0,<br/>                torch.abs((torch.exp(4*(diff))-1)).sum(),<br/>                torch.abs((torch.exp(4*(-diff))-1)).sum())<br/>    return res.sum()</span></pre><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi oc"><img src="../Images/ddf7616872030f38bff846d578dbdd09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pKxkATtYm8WAW4lYK6XPAg.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">作者图片-损失函数的图表(x轴上方的区域)</p></figure><h1 id="ebeb" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">实验和结果</h1><p id="bdba" class="pw-post-body-paragraph ki kj it kk b kl ly ju kn ko lz jx kq kr ma kt ku kv mb kx ky kz mc lb lc ld im bi translated">我使用了在<a class="ae lf" href="https://arxiv.org/ftp/arxiv/papers/2104/2104.11231.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu"> VeriMedi:使用基于代理的深度度量学习和精确解的药丸识别</strong> </a> <strong class="kk iu">中提到的ShakeNet数据集。</strong>对于模型，我使用了预训练的(使用ImageNet数据集)ResNet-34。我在模型的末尾添加了一个嵌入层。</p><p id="b9e2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我在没有任何培训的情况下测试了这个模型。我有74.96%的准确率。然后，我对模型进行了15个纪元的训练。准确率上升到90.69%。这说明该方法有助于模型提取更好、更有意义的特征。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi od"><img src="../Images/e71ae1fffa108cc746ae4bdc509181f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5kgup73lDUCuvHC3b7sBtg.png"/></div></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">作者图片</p></figure></div></div>    
</body>
</html>