<html>
<head>
<title>How to Cover Up in Multiple Languages</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用多种语言掩饰</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-cover-up-in-multiple-languages-fe9cb4e9e39a?source=collection_archive---------25-----------------------#2021-10-22">https://towardsdatascience.com/how-to-cover-up-in-multiple-languages-fe9cb4e9e39a?source=collection_archive---------25-----------------------#2021-10-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="fa14" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><div class=""><h2 id="ed33" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated"><strong class="ak">应用多语言命名实体识别模型进行匿名化</strong></h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/9f2deb47afbaea6815d70e68027c8059.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3q6mVbh36nLEn_Wes5mhkg.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">照片由来自<a class="ae le" href="https://www.pexels.com/photo/globes-arranged-in-a-shelf-8926539/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">像素</a>的<a class="ae le" href="https://www.pexels.com/@thirdman?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">第三人</a>拍摄</p></figure><p id="9232" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在我之前的<a class="ae le" rel="noopener" target="_blank" href="/unlocking-inclusivity-possibilities-with-polyglot-ner-9990baf03561">帖子</a>“用Polyglot-NER开启包容性的可能性”中，我介绍了Polyglot命名实体识别(NER)及其在文档匿名化中的应用。在本系列的第二部分中，我将:</p><ul class=""><li id="1e07" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">概述匿名化问题</li><li id="99c3" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">讨论我在上一篇文章中介绍的两个模型</li><li id="d3c0" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">展示NER评估的不同方法及其缺点</li><li id="7a38" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">介绍应用多语言NER模型对巴西葡萄牙语法律文本进行匿名化的实验结果</li></ul><p id="ea42" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在线提供的预先训练的多语言模型的进步是令人兴奋的。这可能会让人认为，对于任何任务和任何语言，都很容易找到适合您需求的模型。但事实并非总是如此！我们将在这篇博文中检验这一点:我们将采用一个预先训练的多语言模型，并将其与法律领域中预先训练的单语模型进行比较。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="a2e0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">问题</strong></p><p id="9767" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">像大多数NLP应用程序一样，NER模型主要是在英语语言上训练的。另一方面，多语言模型是适用于多种语言的模型。这些模型有时被称为<em class="mw">跨域</em>模型，其中<em class="mw">域指的是</em>语言域。但是单词“域”在NLP中也可以有不同的含义，它可以指一种类型的文本。在NLP中，我们不仅有许多语言，而且还有许多领域。</p><p id="97ff" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这篇博文中的实验测量了一个多语言模型切换到这些其他类型的域的能力。我们采用一种在一般领域训练的多语言模型，并将其应用于法律领域。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="d338" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">型号:单语和多语言</strong></p><p id="7967" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在我之前的文章中，我介绍了两个模型:</p><ul class=""><li id="7d8d" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">单语模型:LENER-BR [1]</li><li id="6957" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">一个多语言模型:XLM-R-NER40 [2]</li></ul><p id="f4f6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">选择单语模型是因为它带有巴西葡萄牙语数据集，这是NLP研究中不常见的语言。正是我们要找的！选择这种多语言模式是因为:</p><ul class=""><li id="86fa" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">它可以处理葡萄牙语(和39种其他语言)</li><li id="cc8c" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">实现在Huggingface [3]上</li><li id="4661" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">就性能而言，它是最好的多语言机型之一</li></ul><p id="c05b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因为这个模型是贴在Huggingface上的，所以很容易应用。原则上，这很简单:</p><pre class="kp kq kr ks gt mx my mz na aw nb bi"><span id="561c" class="nc nd iq my b gy ne nf l ng nh">from transformers import pipeline<br/><br/>nlp_ner = pipeline(<br/>    "ner",<br/>    model="jplu/tf-xlm-r-ner-40-lang",<br/>    tokenizer=(<br/>        'jplu/tf-xlm-r-ner-40-lang',  <br/>        {"use_fast": True}),<br/>    framework="tf"<br/>)</span></pre><p id="6c3d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在你已经准备好用40种语言表演NER了！</p><p id="2203" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">XLM-R-NER-40已经在葡萄牙语的通用领域进行了测试。所以，我们不想再这样做了！相反，我们正在法律领域进行测试。Plu报告了以下分数[3]:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/344e119aa9c741584e1654faaa260017.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*k6z5x9esZmNnopUNiQHDKg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">Plu报告的葡萄牙语分数[3]</p></figure><p id="a9d7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们将多语言模型应用到单语模型的数据集。这是一个不同的数据集，而不是计算Plu提供的分数的数据集。[3]</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="f542" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">评估</strong></p><p id="7f20" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">NER模型用于预测文本中的实体，实体可能是隐私敏感的。如果我们想编辑这些敏感的实体，我们可以使用NER模型。</p><p id="0d3e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">匿名化文档时，不管实体类型如何，都有三种可能的结果:</p><ul class=""><li id="8421" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">模型编辑过度，意味着我们编辑了太多的令牌</li><li id="34dd" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">模型编辑不足，意味着我们编辑的令牌太少</li><li id="b434" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">这个模型编辑得很完美😊</li></ul><p id="7ed6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">一个好的评估方法可以量化一个模型在这三种结果中的表现。在我们进一步讨论之前，我们需要谈谈IOB (Inside-Outside-Beginning)格式，这是注释命名实体最常用的格式。</p><p id="4c0f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">通常，实体分布在多个令牌上。记号表示一个单词，或者在标点符号的情况下表示一个字符。让我们看看数据集中的一个实体:“高级军事法庭”。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/db409694bf5f9a56ef625f0a36833a34.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*xb2Tj_UwhRcxWVHsgqbTiw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">IOB格式的示例，图片由作者提供</p></figure><p id="c24f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在上图中，我们看到了第一个示例实体的原始标签和转换标签。顶部标签是原始标签，对于第二个实体，除了起始标签不同之外，转换是相同的。</p><p id="636a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这个例子中有两种不同的实体类型:一个组织和一个人。然而，在我们的实验中，我们使用的是二元方法，我们对实体类型不感兴趣，只对实体是否存在感兴趣。我们决定采用这种方法，因为原始数据集的类比XLM-R-NER40模型的训练类多。</p><p id="53ef" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当我们想要分类单个NE时，有三种可能的结果:</p><ul class=""><li id="9261" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">该模型没有预测任何令牌是实体</li><li id="16e1" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">该模型正确地预测了实体的开始和结束</li><li id="cd0c" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">模型正确预测了部分标记，但开头和/或结尾不匹配</li></ul><p id="7161" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们看一个虚构的句子，这样我们可以考虑使用NER匿名的一些复杂性。</p><p id="c872" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">考虑一下这个虚构的句子:</p><p id="e0d8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">"联邦调查局发现比尔·克林顿在芝加哥的万豪酒店偷了一个公文包。"</p><p id="77f0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当我们使用我们的模型来匿名化这个句子时，结果可能看起来像:</p><p id="86cd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">“在<strong class="lh ja"> X </strong>的<strong class="lh ja"> X </strong>处，<strong class="lh ja"> X </strong>发现<strong class="lh ja"> X </strong>克林顿偷了一个公文包。”</p><p id="8c98" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">好吧，我们正确地预测了5个实体标记中的4个，但是我们的系统有多大用处呢？我们完全匿名了这个文档吗？我们的模型有80%的效率吗？这是一个很难回答的问题。</p><p id="aaa0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">并非每个实体都具有相同的权重，这在上面的例子中显而易见。如果单词“芝加哥”而不是“克林顿”被错误归类，我认为这个句子最好匿名。某些实体比其他实体更敏感的事实在任何当前的NER评估中都没有得到体现。可以考虑的是一个模型完全预测的实体数量，我们将在本文后面看到。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="ef8f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们实验使用的数据来自LENER-BR数据集，可以在他们的<a class="ae le" href="https://github.com/peluz/lener-br" rel="noopener ugc nofollow" target="_blank">报告</a>中找到。我使用了他们测试集中的三个文档。</p><p id="0fb7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">首先让我们看看不考虑IOB的模型的准确性。</p><p id="029c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">假设我们的文档包含1000个令牌。每个令牌都有自己的标签，这样我们总共有1000个标签。可能的标签是“ENT”和“O”。我们通过将每个预测与其对应的标签进行比较来评估模型，以查看它们是否相同。这叫精准。</p><p id="2613" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当在其中一个测试文档(ACORDAOTCU11602016)上评估两个NER模型时，我们得到以下准确度分数:</p><ul class=""><li id="b2fd" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">LENER-BR: 0.991</li><li id="4a4b" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">XLM-NER比率:0.866</li></ul><p id="2fcd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">乍一看，我们发现LENER-BR的表现比XLM-R好得多。但这是否意味着LENER-BR在匿名化文档方面有99%的成功率，而XLM-R只有87%的成功率？</p><p id="379b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了回答这个问题，我们首先来看一个基线模型。假设我们有一个总是预测“O”作为标签的模型。承认这是一个愚蠢的模型，我强烈建议不要使用它。然而，它确实让我们洞察到训练模型的附加值是什么。对于这个模型和测试文档，准确性分数是:</p><ul class=""><li id="995d" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">多数基线:0.857</li></ul><p id="0227" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这些结果并不令人惊讶，因为文本中的大多数单词都不是新词。在一些文档中，只有1%的标记是ne，所以在这样的文档中获得99%的准确率是非常容易的，但是没有用。在我们的实验中，准确性不是评价NER的有用指标。我们需要看看通常的嫌疑人，精度，召回，和F1。因为这些指标提供了更多关于我们绩效的信息。例如，可能有很高的准确率，但在召回率和精确度上得分很低。</p><p id="05d2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们可以使用Sklearn[4]中的分类报告函数来获得精确度、召回率和F1分数。我们来看文档ACORDAOTCU11602016的报告:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/e649fbe7acfdcac514a83da46943c9f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*PWD_pXqTsKfi9UrN32Dd5Q.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">两个模型的分类报告，按作者分类的图像</p></figure><p id="ca2b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">精度告诉我们当模型说它是X时，它实际上是X的频率。召回告诉我们系统“捕获”了多少X。虽然这份报告对于评估NER来说并不完美，但它比使用准确度得分提供了更多信息。例如，XLM-R-NER40在B-ENT和I-ENT上的性能差异告诉我们，与属于一个实体的其他令牌相比，该模型在识别一个实体的开头时有更多的困难。它告诉我们，XLM-R-NER40只在34%的时间里捕捉到实体的开始。</p><p id="da9f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">到目前为止讨论的所有指标都适用于单个令牌，而不是多令牌实体。对于正确的匿名化，识别完整的多令牌实体(例如“Bill Clinton”)的能力是最重要的，幸运的是，seqeval [5]包可以为我们测量这一点。它产生一个分类报告，就像sklearn一样，但是要严格得多。这也有它的缺点。让我们看看下面这个由两个短句组成的例子:</p><pre class="kp kq kr ks gt mx my mz na aw nb bi"><span id="5cbc" class="nc nd iq my b gy ne nf l ng nh">gold_label = [<br/>[‘B-ENT’, ‘O’, ‘O’, ‘O’, ‘O’], <br/>[‘O’, ‘O’, ‘B-ENT’, ‘I-ENT’, ‘I-ENT’, ‘O’, ‘O’]<br/>]</span><span id="c374" class="nc nd iq my b gy nl nf l ng nh">predictions = [<br/>[‘B-ENT’, ‘I-ENT’, ‘O’, ‘O’, ‘O’],<br/>[‘O’, ‘O’, ‘B-ENT’, ‘I-ENT’, ‘O’, ‘O’, ‘O’]<br/>]</span></pre><p id="c45f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们有两个句子，两个句子中都有一个实体。在示例(1)中，第一个实体是“预测过度”，而在示例(2)中，该实体是“预测不足”。当我们将seqeval应用于这些示例时，我们得到:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/5f1aa1851b1a80ad7bc43309cbdb053f.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*WhMEMNWuZXz97nhwdnr8vg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">两个示例的seqeval评分，图片由作者提供</p></figure><p id="cd68" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">哎唷，根据报告，我们做的和只预测‘O’一样糟糕。如前所述，seqeval测量我们正确预测整个多令牌实体的次数。我们已经可以看到在我们的实验中使用它的一些缺点，因为说只预测“O”和上面的预测一样好是不完全公平的。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="7787" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">结果</strong></p><p id="9718" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">鉴于每种方法的缺点，我将展示seqeval和sklearn报告。为了得到要点，你可以直接跳到<em class="mw">结果表4 </em>。在表2中，我们不需要显示宏观/加权平均值，因为它相当于单个类的精度、召回率和f1值。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nn"><img src="../Images/d912a48046e5b75299dcc29215cae4ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VyOo1sVmNN9Lmi3wkfgAcw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">结果表1:XLM-R-ner 40的sklearn报告，图片由作者提供</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi no"><img src="../Images/847062ca8b5f8c83ac0d01b27ba14f3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KEvAQHuyI0aYnEmwSPJBqw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">结果表2:LENER-BR的sklearn报告，图片由作者提供</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi np"><img src="../Images/68886e9517053af01395774a5b51e189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RP1IBAx58gp4AvCwwx3gNQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">结果表3:两种模型的seqeval报告，图片由作者提供</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nq"><img src="../Images/2e7cb3dea6e9f78328aa4dde3c2f1599.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n4IDU-oGqkHYLYrJ76FKiA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">结果表4:两种模型的平均f1分数，按作者分类的图像</p></figure><p id="758e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">两种类型的分类报告都清楚地表明，单语模型表现得更好。这并不奇怪，因为它是专门为此任务开发的。如果我们查看<em class="mw">结果表4 </em>，我们会发现使用sklearn评估方法，单语模型的性能是多语言模型的两倍。但是，使用seqeval方法，单语模型的性能是seqeval方法的4.5倍。结果显示了XLM-R-NER40模型在法律文本上的局限性。这并不意味着这是一个糟糕的模型，但重要的是要认识到我们可以用开箱即用的模型做的事情是有限的。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="0fb5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">总结&amp;结论</strong></p><p id="a3d4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">总而言之，在这篇文章中，我们看到了:</p><ul class=""><li id="d8a6" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">域切换的影响</li><li id="8e64" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">我们如何相对容易地在网上找到多语言和单语模型</li><li id="8393" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">如何通过二值化将通用模型应用于具有更多类别的更具体的领域</li><li id="114c" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">评估NER的困难，尤其是在匿名化的背景下</li></ul><p id="2d07" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们已经看到了域名转换的影响，因为原始域名的原始分数远远高于合法域名的分数。这个实验中使用的两个模型很容易应用并在网上找到，因为其中一个在Huggingface上，另一个可以在GitHub上找到。我们必须得出结论，把一个多语言模型从盒子里拿出来并应用于任何任务都是有限制的。这说明了两件事，我们仍然需要ML工程专业知识，我们需要做更多的工作来创建可以在任何领域、任何语言上工作的模型。这样，任何人都可以用最少的ML工程知识来利用这些模型。</p><p id="8719" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于未来的工作，以特定于匿名化的方式重写评估方法将是有趣的。这将不得不考虑召回比精确更重要，同时仍然考虑过度匿名仍然是不可取的。如果有人真的对将XLM-R-NER40用于法律领域感兴趣，那么看看如果该模型针对法律领域进行微调，结果会如何将是很有趣的。</p><p id="8328" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果你想从我们的人工智能创新团队伙伴关系中了解更多关于更苗条的人工智能和最新研究，请访问我们的<a class="ae le" href="https://www.slimmer.ai/innovation" rel="noopener ugc nofollow" target="_blank">网站</a>或我们在Medium 上的<a class="ae le" href="https://medium.com/slimmerai/innovation/home" rel="noopener">人工智能创新页面。</a></p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="f435" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">参考文献</strong></p><p id="9d53" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[1] Luz de Araujo，P. H .，de Campos，T. E .，de Oliveira，R. R. R .，Stauffer，m .，Couto，s .，&amp; Bermejo，P. (2018)。LeNER-Br:巴西法律文本中命名实体识别的数据集。葡萄牙语的计算处理。斯普林格。doi:10.1007/978–3–319–99722–3 _ 32</p><p id="06e0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[2] Conneau，a .，Khandelwal，k .，Goyal，n .，Chaudhary，v .，Wenzek，g .，Guzmán，f .，…Stoyanov，V. (2019)。大规模无监督跨语言表征学习。arXiv，1911.02116。从https://arxiv.org/abs/1911.02116v2<a class="ae le" href="https://arxiv.org/abs/1911.02116v2" rel="noopener ugc nofollow" target="_blank">取回</a></p><p id="967e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[3]jplu/TF-xlm-r-ner-40-郎抱脸。(2021年6月22日)。从https://huggingface.co/jplu/tf-xlm-r-ner-40-lang<a class="ae le" href="https://huggingface.co/jplu/tf-xlm-r-ner-40-lang" rel="noopener ugc nofollow" target="_blank">取回</a></p><p id="74ee" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[4]中山博树。(2018).seqeval:一个用于序列标记评估的Python框架。</p><p id="1c74" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[5]sk learn . metrics . classification _ report。(2021年10月21日)。检索自<a class="ae le" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . metrics . classification _ report . html</a></p></div></div>    
</body>
</html>