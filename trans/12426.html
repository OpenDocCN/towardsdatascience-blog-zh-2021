<html>
<head>
<title>Gaussian Process Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">高斯过程模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gaussian-process-models-7ebce1feb83d?source=collection_archive---------2-----------------------#2021-12-19">https://towardsdatascience.com/gaussian-process-models-7ebce1feb83d?source=collection_archive---------2-----------------------#2021-12-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d00c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">能够模拟复杂行为的简单机器学习模型</h2></div><p id="c937" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://en.wikipedia.org/wiki/Gaussian_process" rel="noopener ugc nofollow" target="_blank">高斯过程</a>模型与更受欢迎的机器学习算法如<a class="ae lb" href="https://en.wikipedia.org/wiki/Linear_regression" rel="noopener ugc nofollow" target="_blank">线性回归模型</a>、<a class="ae lb" href="https://en.wikipedia.org/wiki/Decision_tree" rel="noopener ugc nofollow" target="_blank">基于树的模型</a>或<a class="ae lb" href="https://en.wikipedia.org/wiki/Perceptron" rel="noopener ugc nofollow" target="_blank">基于感知器的模型</a>相比，可能是不太为人所知的机器学习算法之一。这是不幸的，因为高斯过程模型是少数几个可以解析求解同时仍然能够对相对复杂的系统建模的机器学习模型之一。</p><p id="644c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管目前在更广泛的机器学习和数据科学社区中相对缺乏人气，但高斯过程模型已经在一些领域中找到了各种用途，例如<a class="ae lb" href="https://en.wikipedia.org/wiki/Kriging" rel="noopener ugc nofollow" target="_blank">地质统计学</a>和<a class="ae lb" href="https://en.wikipedia.org/wiki/Bayesian_optimization" rel="noopener ugc nofollow" target="_blank">昂贵评估函数的优化</a>，例如深度学习神经网络的超参数搜索，或<a class="ae lb" href="https://arxiv.org/pdf/1909.05963.pdf" rel="noopener ugc nofollow" target="_blank">激光优化</a>。今天，我将向您展示高斯过程模型是如何工作的，并教您如何使用 Python 创建自己的高斯过程回归模型！</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/64a486c12088c55cb49b42acd3d1748e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MNH2OA7Niht2fZOrCaoH7A.jpeg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">亚利桑那国家公园。Andrew Coelho 在<a class="ae lb" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片。</p></figure><h1 id="1417" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">高斯过程</h1><p id="7f01" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">高斯过程模型假设观察目标<em class="mp"> yₙ </em>的值具有以下形式:</p><p id="dc05" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mp">yₙ</em>=<em class="mp">f</em>(<strong class="kh ir">x</strong>t26】ₙ)+<em class="mp">eₙ</em>，</p><p id="32d3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<em class="mp">f</em>(<strong class="kh ir">x</strong>T4】ₙ)是产生被观察目标的某个函数，<strong class="kh ir">x</strong>t8】ₙ是一组<em class="mp"> φ </em>输入中的第<em class="mp"> n </em>行<strong class="kh ir">x</strong>=<strong class="kh ir">x</strong>₁、<strong class="kh ir"> x </strong> ₂、<strong class="kh ir">x</strong>ᵩ观察到<em class="mp"> yₙ </em>给定<em class="mp">f</em>(<strong class="kh ir">x</strong>t32】ₙ)的条件概率为正态分布:</p><p id="af35" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mp">p</em>(<em class="mp">yₙ</em>|<em class="mp">f</em>(<strong class="kh ir">x</strong>ₙ)=<em class="mp">n</em>(<em class="mp">yₙ</em>|<em class="mp">f</em>(<strong class="kh ir">x</strong><em class="mp">ₙ</em>)，<em class="mp"> σ </em>)，</p><p id="baf9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<em class="mp"> σ </em>为<em class="mp"> eₙ </em>的标准差。由于假设噪声对于每个样本都是独立的，因此以<em class="mp"><strong class="kh ir"><em class="mp"/></strong>(<strong class="kh ir">x【75】)的φ </strong></em>值为条件，<em class="mp"> φ </em>观测目标值<strong class="kh ir">y</strong>=【<em class="mp">y</em>₁、<em class="mp"> y </em> ₂、……y<em class="mp">ᵩ</em>]ᵀ的联合概率分布</p><p id="b162" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mp">p</em>(<strong class="kh ir">y</strong>|<strong class="kh ir">|<em class="mp">f</em></strong>(<strong class="kh ir">x</strong>)=<em class="mp">N</em>(<strong class="kh ir">y</strong>|<strong class="kh ir">|<em class="mp">f</em></strong>(<strong class="kh ir">x</strong>)，<strong class="kh ir"> σ </strong>)，</p><p id="3ca0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<strong class="kh ir">σ=</strong><em class="mp">σ</em><strong class="kh ir">I</strong>是大小为<em class="mp"> φ </em> × <em class="mp"> φ的对角矩阵。</em></p><p id="2218" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了对<strong class="kh ir"> y </strong>做出预测，我们需要确定边际概率分布<strong class="kh ir"/><em class="mp">p</em>(<strong class="kh ir">y</strong>)。这个概率分布可以通过使用积分将条件分布<em class="mp">p</em>(<strong class="kh ir">y</strong>|<strong class="kh ir">|<em class="mp">f</em></strong>(<strong class="kh ir">x</strong>))边缘化于分布<em class="mp">p</em>(<strong class="kh ir"><em class="mp">f</em></strong>(<strong class="kh ir">x</strong>)来获得:</p><p id="a76f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mp">p</em>(<strong class="kh ir">y</strong>)=∫<em class="mp">p</em>(<strong class="kh ir">y</strong>|<strong class="kh ir"><em class="mp">f</em></strong>(<strong class="kh ir">x</strong>)<em class="mp">p</em>(<strong class="kh ir"><em class="mp">f</em></strong>(<strong class="kh ir">x</strong>)d<strong class="kh ir"><em class="mp">f</em></strong>(<strong class="kh ir">x</strong>)。</p><p id="1928" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">分布<em class="mp">p</em>(<strong class="kh ir"><em class="mp">f</em></strong>(<strong class="kh ir">x</strong>))定义为均值为<strong class="kh ir"> 0 </strong>且协方差核矩阵<strong class="kh ir"> K </strong>大小为<em class="mp"> φ </em> × <em class="mp"> φ </em>的高斯分布:</p><p id="c55e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mp">p</em>(<strong class="kh ir"><em class="mp">f</em></strong>(<strong class="kh ir">x</strong>)=<em class="mp">N</em>(<strong class="kh ir"><em class="mp">f</em></strong>(<strong class="kh ir">x</strong>)|<strong class="kh ir"/>，<strong class="kh ir"> K </strong>)。</p><p id="8441" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">协方差矩阵<strong class="kh ir"> K </strong>由<strong class="kh ir"> x </strong>中两行之间的距离组成，并假设相似的输入应在<strong class="kh ir"> y </strong>中产生相似的目标值。矩阵<strong class="kh ir"> K </strong>中的每个元素计算如下:</p><p id="e725" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> K </strong> [ <em class="mp"> n </em>，<em class="mp">m</em>=<em class="mp">k</em>(<strong class="kh ir">x</strong>t82】ₙ，<strong class="kh ir">x</strong>t86】ₘ)，</p><p id="e65a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<em class="mp"> k </em>是稍后定义的函数。使用上面的<em class="mp">p</em>(<strong class="kh ir"><em class="mp">f</em></strong>(<strong class="kh ir">x</strong>))的等式，我们可以执行<em class="mp"> p </em> ( <strong class="kh ir"> y </strong>)中涉及的积分来获得解:</p><p id="8790" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mp">p</em>(<strong class="kh ir">y</strong>)=∫<em class="mp">p</em>(<strong class="kh ir">y</strong>|<strong class="kh ir"><em class="mp">f</em></strong>(<strong class="kh ir">x</strong>)<em class="mp">p</em>(<strong class="kh ir"><em class="mp">f</em></strong>(<strong class="kh ir">x</strong>)d <strong class="kh ir">σ</strong>)<em class="mp">N</em>(<strong class="kh ir"><em class="mp">f</em></strong>(<strong class="kh ir">x</strong>)|<strong class="kh ir">0</strong>，<strong class="kh ir">K</strong>d<strong class="kh ir"><em class="mp">f</em></strong>(<strong class="kh ir">x</strong>)<strong class="kh ir"><br/></strong></p><p id="d989" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中得到的协方差矩阵具有以下形式:<strong class="kh ir">C</strong>=<strong class="kh ir">K</strong>+<strong class="kh ir">σ</strong>=<strong class="kh ir">K</strong>+<em class="mp">σ</em><strong class="kh ir">I</strong>。<strong class="kh ir"> </strong>因此，<strong class="kh ir"> C </strong>中的各个元素可以写成:<strong class="kh ir"> C </strong> [ <em class="mp"> n </em>，<em class="mp">m</em>=<em class="mp">k</em>(<strong class="kh ir">x</strong><em class="mp">ₙ</em>，<strong class="kh ir">x</strong><em class="mp">ₘ</em>+<em class="mp">σδₙₘ</em>。</p><h1 id="3499" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">二次指数核</h1><p id="0270" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">可以使用用于<em class="mp">k</em>(<strong class="kh ir">x</strong>t38】ₙ，<strong class="kh ir">x</strong>t42】ₘ)的各种协方差核函数，例如顾名思义基本上是常数的<a class="ae lb" href="https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.ConstantKernel.html#sklearn.gaussian_process.kernels.ConstantKernel" rel="noopener ugc nofollow" target="_blank">常数核</a>，广泛使用的二次指数核(也称为<a class="ae lb" href="https://en.wikipedia.org/wiki/Radial_basis_function" rel="noopener ugc nofollow" target="_blank">径向基函数(RBF) </a>，或者通常用于对周期性数据建模的<a class="ae lb" href="https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.ExpSineSquared.html" rel="noopener ugc nofollow" target="_blank">周期性核</a>。</p><p id="9ec8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本文的其余部分，我们将使用二次指数核。这个内核是由成对的样本(<strong class="kh ir">x</strong>t52】ₙ，<strong class="kh ir">x</strong>ₘ)在<strong class="kh ir"> x </strong>中计算出来的:</p><p id="3938" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mp">k</em>(<strong class="kh ir">x</strong><em class="mp">ₙ</em>，<strong class="kh ir">x</strong><em class="mp">ₘ</em>)= exp(-| |<strong class="kh ir">x</strong><em class="mp">ₙ</em>-<strong class="kh ir">x</strong><em class="mp">ₘ</em>| |/2<em class="mp">l【t79)、</em></p><p id="8d72" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<em class="mp"> L </em>是一个内核超参数，为了方便起见，我们将其设置为 1。</p><h1 id="3302" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">新观测值的概率分布</h1><p id="8da0" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">对于目标的<em class="mp"> φ </em>观测值<strong class="kh ir">y</strong>=【<em class="mp">y</em>₁、<em class="mp"> y </em> ₂、……y<em class="mp">ᵩ</em>]ᵀ对应<em class="mp"> </em>一组<em class="mp"> φ </em>输入值<strong class="kh ir">x</strong>=【<strong class="kh ir">x</strong>₁、<strong class="kh ir"> x </strong> ₂、… <strong class="kh ir"> x </strong> <em class="mp"> ᵩ </em> ]ᵀ这一步需要我们确定概率分布<em class="mp">p</em>(<em class="mp">yᵩ</em>₊₁|<strong class="kh ir">y</strong>)的参数(即均值和协方差)。</p><p id="a16c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了确定<em class="mp">p</em>(<em class="mp">yᵩ</em>₊₁|<strong class="kh ir">y</strong>)的参数，我们从分布<em class="mp"> p </em> ( <strong class="kh ir"> y </strong>')，其中<strong class="kh ir"> y </strong> ' = [ <em class="mp"> y </em> ₁，<em class="mp"> y </em> ₂，… y <em class="mp"> ᵩ </em>，<em class="mp"> yᵩ </em> ₊₁]ᵀ是一个长度为的向量从上面的<em class="mp"> p </em> ( <strong class="kh ir"> y </strong>)的解，我们得到<em class="mp">p</em>(<strong class="kh ir">y</strong>’)的相应解:</p><p id="f05d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mp">p</em>(<strong class="kh ir">y</strong>')=<em class="mp">N</em>(<strong class="kh ir">y '</strong>|<strong class="kh ir">0</strong>，<strong class="kh ir"> C' </strong>)，</p><p id="c85c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中大小为<em class="mp"> φ </em> +1× <em class="mp"> φ </em> +1 的新协方差矩阵<strong class="kh ir">C’</strong>具有以下结构:</p><p id="51f2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> C' </strong> = [[ <strong class="kh ir"> C </strong>，<strong class="kh ir"> k </strong>，<br/>..…….[ <strong class="kh ir"> k </strong> ᵀ，<em class="mp"> c </em> ]] <strong class="kh ir">，</strong></p><p id="3219" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<strong class="kh ir">c</strong>=<strong class="kh ir">k</strong>+<em class="mp">σ</em><strong class="kh ir">I</strong>是来自上面的原始<em class="mp"> φ </em> × <em class="mp"> φ </em>协方差矩阵，<strong class="kh ir"> k </strong>是长度为<em class="mp"> φ </em>的向量，其元素由:<strong class="kh ir">k</strong><em class="mp">n</em>给出 而<em class="mp"> c </em>是包含<strong class="kh ir"> x </strong> <em class="mp"> ᵩ </em> ₊₁与自身的协方差的标量:<em class="mp">c</em>=<em class="mp">k</em>(<strong class="kh ir">x</strong><em class="mp">ᵩ</em>₊₁，<strong class="kh ir">x</strong><em class="mp">ᵩ</em>₊₁)+<em class="mp">σ</em>。</p><h1 id="d048" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">高斯过程预测</h1><p id="ba24" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">如前所述，高斯过程是少数几个具有从<a class="ae lb" href="https://en.wikipedia.org/wiki/Conditional_probability" rel="noopener ugc nofollow" target="_blank">条件概率</a>获得的解析解的机器学习模型之一，如下所示。</p><p id="cd26" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们有一些正态分布的<em class="mp">n</em>(<strong class="kh ir">r</strong>|<strong class="kh ir"><em class="mp">μ</em></strong>，<strong class="kh ir">σ</strong>)随机变量的向量<strong class="kh ir"> r </strong>，分割成两个任意长度的子向量:<strong class="kh ir">r</strong>=【<strong class="kh ir">r</strong><em class="mp">ᵤ</em>，<strong class="kh ir"> r </strong> <em class="mp"> ᵥ </em>， 然后对于条件分布<strong class="kh ir"><em class="mp"/></strong><em class="mp">p</em>(<strong class="kh ir">r</strong><em class="mp">ᵤ</em>|<strong class="kh ir">r</strong>|<em class="mp">ᵥ</em>)均值<strong class="kh ir"><em class="mp">μ</em></strong>(<strong class="kh ir">r</strong><em class="mp">ᵤ</em>|<strong class="kh ir">r<em class="mp">ᵥ</em>和协方差<strong class="kh ir">σ</strong></strong></p><p id="bd91" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"><em class="mp">μ</em></strong>(<strong class="kh ir">r</strong><em class="mp">ᵤ</em>|<strong class="kh ir">r</strong><em class="mp">ᵥ</em>)=<strong class="kh ir"><em class="mp">μ</em></strong><em class="mp">ᵤ</em>+<strong class="kh ir">σ</strong><em class="mp">ᵤᵥ</em><strong class="kh ir">σ</strong></p><p id="ca11" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">σ</strong>(<strong class="kh ir">r</strong>t100】ᵤ|<strong class="kh ir">r</strong>t104】ᵥ)=<strong class="kh ir">σ</strong><em class="mp">ᵤᵤ</em>-<strong class="kh ir">σ</strong><em class="mp">ᵤᵥ</em><strong class="kh ir">σ</strong><em class="mp">ᵥᵥ</em>⁻<strong class="kh ir">σ【t119</strong></p><p id="18a0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<strong class="kh ir"><em class="mp">μ</em></strong><em class="mp">ᵤ</em>/<strong class="kh ir"><em class="mp">μ</em></strong><em class="mp">ᵥ</em>是包含<strong class="kh ir">r</strong><em class="mp">ᵤ</em>/<strong class="kh ir">r</strong><em class="mp">ᵥ</em>和<strong class="kh ir">σ</strong>元素均值的向量</p><p id="a54c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于我们的情况，<strong class="kh ir">r</strong>T2】ᵤ对应于新的观测值，而<strong class="kh ir">r</strong>T6】ᵥ对应于旧的一组<em class="mp"> φ </em>观测值。因此新旧观测值之间的协方差<strong class="kh ir">σ</strong>ᵥᵤ是带有元素的向量<strong class="kh ir">k</strong>k<em class="mp">n</em><em class="mp">= k</em>(<strong class="kh ir">x</strong>t24】ₙ、<strong class="kh ir">x</strong>ᵩ₊₁)，旧观测值的协方差<strong class="kh ir">σ</strong> <em class="mp">m</em>=<em class="mp">k</em>(<strong class="kh ir">x</strong><em class="mp">ₙ</em>，<strong class="kh ir">x</strong><em class="mp">ₘ</em>)+<em class="mp">σδₙₘ</em>新观测值的协方差<strong class="kh ir"/><em class="mp">ᵤᵤ</em>是标量<strong class="kh ir"/><em class="mp">c</em>=<em class="mp">k</em>( 根据我们上面的定义<strong class="kh ir"><em class="mp">μ</em></strong><em class="mp">ᵤ=</em><strong class="kh ir"><em class="mp">μ</em></strong><em class="mp">ᵥ=</em><strong class="kh ir">0</strong>。</p><p id="8c70" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">把一切放在一起，条件概率分布<em class="mp">p</em>(<em class="mp">yᵩ</em>₊₁|<strong class="kh ir">y</strong>)是一个均值为的高斯分布:</p><p id="998d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mp">μ</em>=<strong class="kh ir">k</strong>ᵀ<strong class="kh ir">c</strong>⁻<strong class="kh ir">y</strong>，</p><p id="c343" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">和方差:</p><p id="f57f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mp">s</em>=<em class="mp">c</em>-<strong class="kh ir">k</strong>ᵀ<strong class="kh ir">c</strong>⁻<strong class="kh ir">k</strong>。</p><h1 id="6b13" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">在 Python 中实现高斯模型</h1><p id="4b18" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">上面的分析解决方案可以很容易地用 Python 实现！首先，我们创建一个函数来计算输入特征<em class="mp">φ</em>x=【<strong class="kh ir">x</strong>₁、<strong class="kh ir"> x </strong> ₂、… <strong class="kh ir"> x </strong> <em class="mp"> ᵩ </em> ]ᵀ:的二次指数核矩阵</p><p id="6827" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> K </strong> [ <em class="mp"> n </em>，<em class="mp">m</em>]=<em class="mp">k</em>(<strong class="kh ir">x</strong><em class="mp">ₙ</em>，<strong class="kh ir">x</strong><em class="mp">ₘ</em>)= exp(-|<strong class="kh ir">x</strong><em class="mp">ₙ</em>-<strong class="kh ir"/></p><p id="7532" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，为了简化起见，我们假设<em class="mp"> σ </em> = 0，使得<strong class="kh ir"> C </strong> = <strong class="kh ir"> K. </strong></p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="f6f3" class="mv lt iq mr b gy mw mx l my mz">import numpy as np</span><span id="8298" class="mv lt iq mr b gy na mx l my mz">def RBF_kernel(xn, xm, l = 1):<br/>    """<br/>    Inputs:<br/>        xn: row n of x<br/>        xm: row m of x<br/>        l:  kernel hyperparameter, set to 1 by default<br/>    Outputs:<br/>        K:  kernel matrix element: K[n, m] = k(xn, xm)<br/>    """<br/>    K = np.exp(-np.linalg.norm(xn - xm)**2 / (2 * l**2))<br/>    return K</span><span id="0cf5" class="mv lt iq mr b gy na mx l my mz">def make_RBF_kernel(X, l = 1, sigma = 0):<br/>    """<br/>    Inputs:<br/>        X: set of φ rows of inputs<br/>        l: kernel hyperparameter, set to 1 by default<br/>        sigma: Gaussian noise std dev, set to 0 by default<br/>    Outputs:<br/>        K:  Covariance matrix <br/>    """<br/>    K = np.zeros([len(X), len(X)])<br/>    for i in range(len(X)):<br/>        for j in range(len(X)):<br/>            K[i, j] = RBF_kernel(X[i], X[j], l)<br/>    return K + sigma * np.eye(len(K))</span></pre><p id="97e8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">新的预测平均值<em class="mp">μ</em>=<strong class="kh ir">k</strong>ᵀ<strong class="kh ir">c</strong>⁻<strong class="kh ir">y</strong>和协方差<em class="mp">s</em>=<em class="mp">c</em>-<strong class="kh ir">k</strong>ᵀ<strong class="kh ir">c</strong>⁻<strong class="kh ir">k</strong>可使用以下函数计算得出。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="95c8" class="mv lt iq mr b gy mw mx l my mz">def gaussian_process_predict_mean(X, y, X_new):<br/>    """<br/>    Inputs:<br/>        X: set of φ rows of inputs<br/>        y: set of φ observations <br/>        X_new: new input <br/>    Outputs:<br/>        y_new: predicted target corresponding to X_new<br/>    """<br/>    rbf_kernel = make_RBF_kernel(np.vstack([X, X_new]))<br/>    K = rbf_kernel[:len(X), :len(X)]<br/>    k = rbf_kernel[:len(X), -1]<br/>    return  np.dot(np.dot(k, np.linalg.inv(K)), y)</span><span id="9969" class="mv lt iq mr b gy na mx l my mz">def gaussian_process_predict_std(X, X_new):<br/>    """<br/>    Inputs:<br/>        X: set of φ rows of inputs<br/>        X_new: new input<br/>    Outputs:<br/>        y_std: std dev. corresponding to X_new<br/>    """<br/>    rbf_kernel = make_RBF_kernel(np.vstack([X, X_new]))<br/>    K = rbf_kernel[:len(X), :len(X)]<br/>    k = rbf_kernel[:len(X), -1]<br/>    return rbf_kernel[-1,-1] - np.dot(np.dot(k,np.linalg.inv(K)),k)</span></pre><h1 id="df7e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">用高斯过程模型进行预测</h1><p id="8532" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">现在我们需要做的就是用一些数据来测试这个算法！我们使用一个简单的公式<em class="mp">y =</em>(<em class="mp">x</em>-5)<em class="mp"/>得到 5 个数据点:<code class="fe nb nc nd mr b">[1, 3, 5, 7, 9]</code>。对于<code class="fe nb nc nd mr b">5.5</code>的新输入值，我们预测<em class="mp"> y </em>的值。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="eab5" class="mv lt iq mr b gy mw mx l my mz">def f(x):<br/>    return (x-5) ** 2</span><span id="032a" class="mv lt iq mr b gy na mx l my mz"># Training data x and y:<br/>X = np.array([1.0, 3.0, 5.0, 7.0, 9.0])<br/>y = f(X)<br/>X = X.reshape(-1, 1)</span><span id="df09" class="mv lt iq mr b gy na mx l my mz"># New input to predict:<br/>X_new = np.array([5.5])</span><span id="ba5e" class="mv lt iq mr b gy na mx l my mz"># Calculate and print the new predicted value of y:<br/>mean_pred = gaussian_process_predict_mean(X, y, X_new)<br/>print("mean predict :{}".format(mean_pred))</span><span id="573c" class="mv lt iq mr b gy na mx l my mz"># Calculate and print the corresponding standard deviation:<br/>sigma_pred = np.sqrt(gaussian_process_predict_std(X, X_new))<br/>print("std predict :{}".format(sigma_pred))</span><span id="6de7" class="mv lt iq mr b gy na mx l my mz">mean predict :0.277673949912025<br/>std predict :0.4150417380004999</span></pre><p id="41d3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们也可以检查高斯过程模型中使用的<strong class="kh ir"> K </strong>的值。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="b3ca" class="mv lt iq mr b gy mw mx l my mz">for i in make_RBF_kernel(X):<br/>    for j in i:<br/>        print("{:.3f}".format(j), end = ", ")<br/>    print()</span><span id="0aa6" class="mv lt iq mr b gy na mx l my mz">1.000, 0.135, 0.000, 0.000, 0.000, <br/>0.135, 1.000, 0.135, 0.000, 0.000, <br/>0.000, 0.135, 1.000, 0.135, 0.000, <br/>0.000, 0.000, 0.135, 1.000, 0.135, <br/>0.000, 0.000, 0.000, 0.135, 1.000,</span></pre><p id="7726" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作为明智的检查，我们可以使用<code class="fe nb nc nd mr b">sklearn</code>中的<code class="fe nb nc nd mr b">GaussianProcessRegressor</code>来检查我们的算法是否有效！</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="4433" class="mv lt iq mr b gy mw mx l my mz">from sklearn.gaussian_process import GaussianProcessRegressor</span><span id="6670" class="mv lt iq mr b gy na mx l my mz">gpr = GaussianProcessRegressor()<br/>gpr.fit(X, y)</span><span id="b559" class="mv lt iq mr b gy na mx l my mz">gpr_mean, gpr_std = gpr.predict(X_new.reshape(-1, 1), <br/>                                return_std = True)</span><span id="7a6a" class="mv lt iq mr b gy na mx l my mz">print("sklearn pred: {}".format(gpr_mean))<br/>print("sklearn std: {}".format(gpr_std))</span><span id="a074" class="mv lt iq mr b gy na mx l my mz">sklearn pred: [0.27767395]<br/>sklearn std: [0.41504174]</span></pre><p id="4963" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">同样，我们也可以检查<code class="fe nb nc nd mr b">sklearn</code>使用的核矩阵的值。注意<code class="fe nb nc nd mr b">sklearn</code>使用原始核矩阵的<a class="ae lb" href="https://en.wikipedia.org/wiki/Cholesky_decomposition" rel="noopener ugc nofollow" target="_blank"> Cholesky 分解</a>，以便使用以下公式优化计算:<strong class="kh ir"> K </strong> = <strong class="kh ir"> LL </strong> ᵀ.</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="c5af" class="mv lt iq mr b gy mw mx l my mz">for i in np.dot(gpr.L_, gpr.L_.T):<br/>    for j in i:<br/>        print("{:.3f}".format(j), end = ", ")<br/>    print()</span><span id="0382" class="mv lt iq mr b gy na mx l my mz">1.000, 0.135, 0.000, 0.000, 0.000, <br/>0.135, 1.000, 0.135, 0.000, 0.000, <br/>0.000, 0.135, 1.000, 0.135, 0.000, <br/>0.000, 0.000, 0.135, 1.000, 0.135, <br/>0.000, 0.000, 0.000, 0.135, 1.000,</span></pre><p id="911c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的模型和<code class="fe nb nc nd mr b">sklearn</code>的模型对于新输入<code class="fe nb nc nd mr b">x = 5.5</code>都有相同的<code class="fe nb nc nd mr b">0.278 </code>预测和<code class="fe nb nc nd mr b">0.415</code>标准差！核矩阵也是一样的！</p><h1 id="3ee6" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">在训练数据之外进行预测</h1><p id="3c68" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">现在让我们看看如果我们在训练数据范围外使用<code class="fe nb nc nd mr b">x</code>的值会发生什么。例如:如果<code class="fe nb nc nd mr b">x = 15</code>发生了什么？</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="a41a" class="mv lt iq mr b gy mw mx l my mz">X_new = np.array([15])</span><span id="e66d" class="mv lt iq mr b gy na mx l my mz">mean_pred = gaussian_process_predict_mean(X, y, X_new)<br/>print("mean predict :{}".format(mean_pred))</span><span id="a43d" class="mv lt iq mr b gy na mx l my mz">sigma_pred = np.sqrt(gaussian_process_predict_std(X, X_new))<br/>print("std predict :{}".format(sigma_pred))</span><span id="f258" class="mv lt iq mr b gy na mx l my mz">mean predict :2.396794716305008e-07<br/>std predict :0.9999999999999999</span></pre><p id="a5bf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们发现现在预测的标准差要大得多，预测值几乎是 0。虽然高斯过程模型非常擅长在训练集的范围内插值数据，但是它们不擅长在该范围外外推。</p><h1 id="11b5" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">绘制模型的 95%置信区间</h1><p id="f5fe" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">使用预测平均值和相应的标准差，我们可以为整个输入值范围<em class="mp"> x </em>创建并绘制模型的 95%置信区间。</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="fe4a" class="mv lt iq mr b gy mw mx l my mz">import matplotlib.pyplot as plt</span><span id="f875" class="mv lt iq mr b gy na mx l my mz"># Range of x to obtain the confidence intervals.<br/>x = np.linspace(0, 10, 1000)</span><span id="b1e2" class="mv lt iq mr b gy na mx l my mz"># Obtain the corresponding mean and standard deviations.<br/>y_pred = []<br/>y_std = []</span><span id="856c" class="mv lt iq mr b gy na mx l my mz">for i in range(len(x)):<br/>    X_new = np.array([x[i]])<br/>    y_pred.append(gaussian_process_predict_mean(X, y, X_new))<br/>    y_std.append(np.sqrt(gaussian_process_predict_std(X, X_new)))<br/>    <br/>y_pred = np.array(y_pred)<br/>y_std = np.array(y_std)</span><span id="cea7" class="mv lt iq mr b gy na mx l my mz">plt.figure(figsize = (15, 5))<br/>plt.plot(x, f(x), "r")<br/>plt.plot(X, y, "ro")<br/>plt.plot(x, y_pred, "b-")<br/>plt.fill(np.hstack([x, x[::-1]]),<br/>         np.hstack([y_pred - 1.9600 * y_std, <br/>                   (y_pred + 1.9600 * y_std)[::-1]]),<br/>         alpha = 0.5, fc = "b")<br/>plt.xlabel("$x$", fontsize = 14)<br/>plt.ylabel("$f(x)$", fontsize = 14)<br/>plt.legend(["$y = x^2$", "Observations", "Predictions", "95% Confidence Interval"], fontsize = 14)<br/>plt.grid(True)<br/>plt.xticks(fontsize = 14)<br/>plt.yticks(fontsize = 14)<br/>plt.show()</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ne"><img src="../Images/24744d930d87c8c9d9fa338f91c1e62c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VD6Eunoprf24Ist8zy3mDA.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">高斯过程模型的 95%置信区间。</p></figure><p id="bea9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不用单独检查每个新输入的标准偏差，使用这样的图形可以让我们很容易地查看模型对其预测最有信心和最没有信心的地方！</p><h1 id="f9a7" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">更高级的协方差核</h1><p id="df49" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">在本文中，我们使用二次指数核来计算我们的协方差核矩阵<strong class="kh ir"> K </strong>。然而，还有许多其他的内核函数，它们可能会为某些类型的数据带来更好的性能。例如，存在一个周期内核，它对于周期数据表现得非常好！如果你想了解更多关于这些更先进的内核，请阅读我关于<a class="ae lb" rel="noopener" target="_blank" href="/gaussian-process-kernels-96bafb4dd63e">高斯过程内核</a>的文章！</p><h1 id="8456" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">闭幕词</strong></h1><p id="7416" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">今天在这篇文章中，我们探索了高斯过程是如何工作的，并使用 Python 创建了我们自己的高斯过程回归模型！高斯过程模型非常强大，在学术界和工业界都被广泛使用。作为一个工业应用的例子，在以后的文章中，我将向您展示如何使用基于高斯过程的优化器来确定最佳激光参数，以获得特定的激光功率输出！</p><h1 id="1fae" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><p id="2d36" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">[1] C. M. Bishop (2006)，<a class="ae lb" href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="mp">模式识别与机器学习</em> </a>，Springer。<br/>【2】<a class="ae lb" href="https://scikit-learn.org/stable/modules/gaussian_process.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/Gaussian _ process . html</a><br/>【3】<a class="ae lb" href="https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . Gaussian _ process。GaussianProcessRegressor.html</a></p></div></div>    
</body>
</html>