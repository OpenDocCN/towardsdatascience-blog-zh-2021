<html>
<head>
<title>Deploying Serverless spaCy Transformer Model with AWS Lambda</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用AWS Lambda部署无服务器空间转换器模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deploying-serverless-spacy-transformer-model-with-aws-lambda-364b51c42999?source=collection_archive---------13-----------------------#2021-10-12">https://towardsdatascience.com/deploying-serverless-spacy-transformer-model-with-aws-lambda-364b51c42999?source=collection_archive---------13-----------------------#2021-10-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f5e0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">关于如何部署NER变压器模型无服务器的分步指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9fd66b41f4ef2eff9d45b6935cb7160e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SABnYfT-DtAuwGOgkqs79g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">约书亚·索蒂诺在<a class="ae ky" href="https://unsplash.com/s/photos/server?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="5a58" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="619b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">由于transformer无与伦比的性能，它已成为许多NLP任务的基本工具，每天都有各种有用且有影响力的NLP模型被创建出来。然而，许多NLP实践者发现将模型部署到生产中是一个挑战。<a class="ae ky" href="https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/" rel="noopener ugc nofollow" target="_blank">根据这份报告</a>，90%的机器学习模型从未投入生产。</p><p id="e9a5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">模型部署使您能够在服务器环境中托管您的模型，例如，当被API调用时，它可以用于输出预测。</p><p id="1318" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在本教程中，我将向你展示如何将NER空间转换器模型推送到Huggingface，并在AWS Lambda上部署该模型来运行预测。</p><p id="ca0d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">根据AWS网站:</p><blockquote class="ms mt mu"><p id="c7bf" class="lr ls mv lt b lu mn ju lw lx mo jx lz mw mp mc md mx mq mg mh my mr mk ml mm im bi translated"><em class="it">“AWS Lambda是一种无服务器计算服务，让您无需配置或管理服务器、创建工作负载感知集群扩展逻辑、维护事件集成或管理运行时即可运行代码。有了Lambda，您几乎可以为任何类型的应用程序或后端服务运行代码——所有这些都无需管理。”</em></p></blockquote><p id="2173" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">部署模型而无需管理后端服务器是一个游戏规则改变者</strong>。它将使没有devops资源的开发人员和小型初创公司能够开始部署准备用于生产的模型。</p><p id="72f0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以下是我们将要遵循的步骤:</p><ul class=""><li id="fc4a" class="mz na it lt b lu mn lx mo ma nb me nc mi nd mm ne nf ng nh bi translated">在Huggingface中部署一个经过训练的空间变形器模型</li><li id="abdc" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm ne nf ng nh bi translated">将模型存储在S3</li><li id="0a76" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm ne nf ng nh bi translated">在AWS Lambda中部署模型</li><li id="c24e" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm ne nf ng nh bi translated">运行AWS Lambda函数，根据用户输入输出预测</li></ul><h1 id="d468" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">在Huggingface中部署空间变压器模型</h1><p id="182c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本教程中，我们对变压器NER模型SciBert进行了微调，以从科学摘要中提取材料、流程和任务。使用<a class="ae ky" href="https://ubiai.tools" rel="noopener ugc nofollow" target="_blank"> UBIAI文本注释工具</a>完成注释。我们遵循了在<a class="ae ky" rel="noopener" target="_blank" href="/how-to-fine-tune-bert-transformer-with-spacy-3-6a90bfe57647">我之前的文章</a>中介绍的相同方法，我们利用google colab来训练模型。训练模型后的下一步是在huggingface上托管它，这样它就可以被API访问。更多关于如何将空间模型推送到huggingface的信息，请查看这个<a class="ae ky" href="https://huggingface.co/spacy" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="f2d6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">首先，从pip安装spacy-huggingface-hub:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="23ae" class="ns la it no b gy nt nu l nv nw">pip install spacy-huggingface-hub</span></pre><p id="7754" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">从经过训练的空间管道构建一个. whl文件(确保事先创建输出目录):</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="3bea" class="ns la it no b gy nt nu l nv nw">huggingface-cli login<br/>python -m spacy package ./model_science_scibert/model-last ./output --build wheel</span></pre><p id="0f22" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">将砂轮锉推入轮毂:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="9344" class="ns la it no b gy nt nu l nv nw">cd ./output/en_scibert_ScienceIE-0.0.0/dist<br/>python -m spacy huggingface-hub push en_scibert_ScienceIE-0.0.0-py3-none-any.whl</span></pre><p id="42e6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">让我们检查一下模型是否已经成功上传到Huggingface:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/9ae3c03d30a9a8d0d4c7f08596793f5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RCjtBcZPxtynoU2-A0jQww.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="be32" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">既然这个模型已经被推送到huggingface库中，我们可以在一个科学摘要上测试它了:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/d2f7e240e65b8e8a23aaf4ea4841ecb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SfcWSOLIyZO4-a5givY77g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="09ec" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">太棒了—它像预期的那样工作！我们现在可以直接用API查询模型:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="c43f" class="ns la it no b gy nt nu l nv nw">import requests<br/><br/>API_URL = "https://api-inference.huggingface.co/models/UBIAI/en_scibert_ScienceIE"<br/>headers = {"Authorization": "[API Token]"}<br/><br/>def query(payload):<br/>	response = requests.post(API_URL, headers=headers, json=payload)<br/>	return response.json()<br/><br/>output = query({"inputs": "<em class="mv">We report exptl. and theor. evidence for the formation of chiral bobbers-an interfacial topol. spin texture-in</em>"})</span></pre><p id="5a90" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下一步是将模型与AWS Lambda集成，这样我们就不会受到Huggingface的API使用的限制。</p><h1 id="712e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">在AWS Lambda上部署:</h1><p id="cfa7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本节中，我们将在S3上存储训练好的模型，并将其导入lambda函数进行预测。以下是步骤:</p><ol class=""><li id="c673" class="mz na it lt b lu mn lx mo ma nb me nc mi nd mm nz nf ng nh bi translated">将训练好的模型存储在S3上(或者，我们可以直接从huggingface库下载模型)</li><li id="5e69" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm nz nf ng nh bi translated">基于容器图像设置推理Lambda函数</li><li id="6f88" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm nz nf ng nh bi translated">将容器图像存储在您帐户内的<a class="ae ky" href="https://aws.amazon.com/ecr/" rel="noopener ugc nofollow" target="_blank"> Amazon弹性容器注册库</a> (ECR)中</li><li id="1335" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm nz nf ng nh bi translated">在Amazon弹性文件系统存储上导入并缓存训练好的模型，以改善推理延迟</li><li id="22c7" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm nz nf ng nh bi translated">对AWS Lambda运行预测</li></ol><p id="0448" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了加快这个过程，我们按照AWS的教程<a class="ae ky" href="https://aws.amazon.com/blogs/compute/hosting-hugging-face-models-on-aws-lambda/" rel="noopener ugc nofollow" target="_blank">自动提供基于容器图像的Lambda函数。首先，让我们按照教程中所示克隆回购:</a></p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="bb66" class="ns la it no b gy nt nu l nv nw">git clone https://github.com/aws-samples/zero-administration-inference-with-aws-lambda-for-hugging-face.git</span></pre><p id="85f6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">安装所有要求:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="c839" class="ns la it no b gy nt nu l nv nw">pip install -r requirements.txt</span></pre><p id="cb8b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">安装自动气象站CDK:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="1d21" class="ns la it no b gy nt nu l nv nw">npm install -g aws-cdk</span></pre><p id="01b9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">接下来，我们将添加推理文件以从我们的模型中获得预测。</p><p id="c880" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">将目录更改为推理文件夹，并添加一个新的python文件来运行模型，对于本教程，我添加了science_ie.py文件:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/68da40887f659b118b2dd5f7247827e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*PxRw64j7VwsUqEzNHsbc8g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="caea" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在，我们将在science_ie.py中创建两个函数:</p><ol class=""><li id="328f" class="mz na it lt b lu mn lx mo ma nb me nc mi nd mm nz nf ng nh bi translated">一个从S3下载模型的函数，将其解压缩并存储在缓存文件夹/mnt/hf_models_cache中。</li><li id="dafc" class="mz na it lt b lu ni lx nj ma nk me nl mi nm mm nz nf ng nh bi translated">第二个函数查询我们的模型并返回提取的实体。</li></ol><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="5a8b" class="ns la it no b gy nt nu l nv nw">import os<br/>import urllib.request<br/>import spacy<br/>import spacy_transformers<br/>from zipfile import ZipFile<br/>from pathlib import Path<br/><br/>#Download the model from S3<br/>def download(model, dest):<br/>    save_path = Path(dest) / model<br/>    if not os.path.exists(save_path):<br/>        print(<strong class="no iu">'Downloading...'</strong>)</span><span id="a7bf" class="ns la it no b gy ob nu l nv nw"># Enter url path to the model on S3<br/>        url = <strong class="no iu">f'https://[bucket name].s3.us-west-2.amazonaws.com/</strong>{model}<strong class="no iu">.zip'<br/>        </strong>filename = Path(dest) / <strong class="no iu">f'</strong>{model}<strong class="no iu">.zip'<br/>        </strong>res = urllib.request.urlretrieve(url, filename)<br/>        with ZipFile(filename, <strong class="no iu">'r'</strong>) as f:<br/>            print(dest)<br/>            f.extractall(path=dest)<br/>            print(<strong class="no iu">'finished extracting'</strong>)<br/>    dirname = model.split(<strong class="no iu">'-'</strong>)[0]<br/>    return save_path<br/><br/>#Handler function for predictions<br/>def handler(event, context):<br/>    doc = nlp(event[<strong class="no iu">'text'</strong>])<br/>    response = [<br/>        {<br/>            <strong class="no iu">'text'</strong>: ent.text,<br/>            <strong class="no iu">'label'</strong>: ent.label_,<br/>            <strong class="no iu">'start'</strong>: ent.start_char,<br/>            <strong class="no iu">'end'</strong>: ent.end_char<br/>        }<br/>        for ent in doc.ents<br/><br/>    ]<br/>    return response<br/><br/>model = <strong class="no iu">'model-last'<br/></strong>mnt_path = <strong class="no iu">'/mnt/hf_models_cache'<br/></strong>model_path = download(model, mnt_path)<br/>nlp = spacy.load(mnt_path)</span></pre><p id="4e57" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们现在准备部署。只需运行下面的命令来部署CDK应用程序(注意:我在运行下面的命令时发现了一个错误，如果发生这种情况，只需在cdk.json文件的“app”行中用python替换python 3:“python app . py”):</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="10a5" class="ns la it no b gy nt nu l nv nw">cdk bootstrap<br/>cdk deploy</span></pre><p id="264a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">一旦部署开始，我们将开始看到进展，这将需要一些时间来完成全面部署。完成后，转到AWS控制台中的AWS Lambda并选择test选项卡:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/5ba5f3aaf40ec12e5a179663890e7ca6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yp_IrRUXc0jUs3H7kh9aGg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="a9f9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">按如下方式输入测试文本，然后按下测试按钮:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="9749" class="ns la it no b gy nt nu l nv nw">{<br/>"text": "<em class="mv">We report exptl. and theor. evidence for the formation of chiral bobbers-an interfacial topol. spin texture-in FeGe films grown by mol. beam epitaxy.  After establishing the presence of skyrmions in FeGe/Si(111) thin-film samples through Lorentz transmission electron microscopy and the topol. Hall effect, we perform magnetization measurements that reveal an inverse relationship between the film thickness and the slope of the susceptibility (d?/dH).  We present evidence for the evolution as a function of film thickness L from a skyrmion phase for L&lt;LD/2 to a cone phase with chiral bobbers at the interface for L&gt;LD/2, where LD?70nm is the FeGe pitch length.  We show using micromagnetic simulations that chiral bobbers, earlier predicted to be metastable, are in fact the stable ground state in the presence of an addnl. interfacial Rashba Dzyaloshinskii-Moriya interaction.</em>"<br/>}</span></pre><p id="4b7d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">以下是预测:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="7ea9" class="ns la it no b gy nt nu l nv nw">[<br/>  {<br/>    "text": "exptl. and theor. evidence for the formation of chiral bobbers",<br/>    "label": "TASK",<br/>    "start": 10,<br/>    "end": 72<br/>  },<br/>  {<br/>    "text": "FeGe films",<br/>    "label": "MATERIAL",<br/>    "start": 111,<br/>    "end": 121<br/>  },<br/>  {<br/>    "text": "skyrmions",<br/>    "label": "MATERIAL",<br/>    "start": 186,<br/>    "end": 195<br/>  },<br/>  {<br/>    "text": "FeGe/Si(111) thin-film samples",<br/>    "label": "MATERIAL",<br/>    "start": 199,<br/>    "end": 229<br/>  },<br/>  {<br/>    "text": "transmission electron microscopy",<br/>    "label": "PROCESS",<br/>    "start": 246,<br/>    "end": 278<br/>  },<br/>  {<br/>    "text": "topol. Hall effect",<br/>    "label": "PROCESS",<br/>    "start": 287,<br/>    "end": 305<br/>  },<br/>  {<br/>    "text": "magnetization measurements",<br/>    "label": "PROCESS",<br/>    "start": 318,<br/>    "end": 344<br/>  },<br/>  {<br/>    "text": "film",<br/>    "label": "MATERIAL",<br/>    "start": 393,<br/>    "end": 397<br/>  },<br/>  {<br/>    "text": "evolution as a function of film thickness",<br/>    "label": "TASK",<br/>    "start": 482,<br/>    "end": 523<br/>  },<br/>  {<br/>    "text": "skyrmion phase",<br/>    "label": "PROCESS",<br/>    "start": 533,<br/>    "end": 547<br/>  },<br/>  {<br/>    "text": "chiral bobbers",<br/>    "label": "MATERIAL",<br/>    "start": 580,<br/>    "end": 594<br/>  },<br/>  {<br/>    "text": "FeGe pitch length",<br/>    "label": "MATERIAL",<br/>    "start": 645,<br/>    "end": 662<br/>  },<br/>  {<br/>    "text": "micromagnetic simulations",<br/>    "label": "PROCESS",<br/>    "start": 679,<br/>    "end": 704<br/>  },<br/>  {<br/>    "text": "chiral bobbers",<br/>    "label": "MATERIAL",<br/>    "start": 710,<br/>    "end": 724<br/>  }<br/>]</span></pre><p id="e722" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">瞧，我们从AWS Lambda上的模型中得到了预测，而无需担心设置服务器基础设施。</p><h1 id="9d15" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论:</h1><p id="31cf" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本教程中，我们演示了如何在Huggingface上部署一个经过训练的transformer模型，将其存储在S3上，并使用AWS lambda函数获得预测，而无需设置服务器基础架构。</p><p id="626a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果您有任何问题，请不要犹豫，在下面提问或发送电子邮件至admin@ubiai.tools。</p><p id="3e81" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你喜欢这篇文章，请喜欢并分享！</p><p id="dba5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在Twitter上关注我们<a class="ae ky" href="https://twitter.com/UBIAI5" rel="noopener ugc nofollow" target="_blank"> @UBIAI5 </a>或<a class="ae ky" href="https://walidamamou.medium.com/subscribe" rel="noopener">订阅这里</a>！</p></div></div>    
</body>
</html>