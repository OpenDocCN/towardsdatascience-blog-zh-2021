<html>
<head>
<title>Problems with Existing Abstractive Text Summarization Models— Even SOTA</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">现有抽象文本摘要模型的问题——甚至是SOTA</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/entity-level-factual-consistency-in-abstractive-text-summarization-cb19e8a48397?source=collection_archive---------22-----------------------#2021-06-02">https://towardsdatascience.com/entity-level-factual-consistency-in-abstractive-text-summarization-cb19e8a48397?source=collection_archive---------22-----------------------#2021-06-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6413" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">NLP研究论文摘要</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b88bc3b0f88ea7440d18660d2e8f616d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-U5EUbUKt4uNQZbvyqZwxQ.png"/></div></div></figure><p id="c7ca" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">在这篇博客中，我尝试根据我的理解总结了论文</em> <a class="ae lr" href="https://arxiv.org/pdf/2102.09130.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lq">抽象文本摘要的实体级事实一致性</em> </a> <em class="lq">。请随时评论你的想法！</em></p><h1 id="3328" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">问题陈述</h1><p id="4651" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">众所周知，现有的<a class="ae lr" href="https://www.youtube.com/watch?v=QY8oZxS0txs" rel="noopener ugc nofollow" target="_blank">抽象文本摘要模型</a>倾向于<strong class="kw iu">产生虚假信息</strong>。现在，这可能发生在<strong class="kw iu">实体</strong>级别<em class="lq">(生成额外的实体)</em>或实体<strong class="kw iu">关系</strong>级别<em class="lq">(实体出现的上下文被错误地生成)</em>。本文<strong class="kw iu">仅在实体级</strong>量化事实一致性，而将关系级一致性留给未来的工作。他们提出了一种度量标准来量化模型产生的这种幻觉，并提出了一系列措施和训练方案，这些措施和方案可以帮助模型更好地执行并生成实体级别的事实上正确的摘要。</p><h1 id="9178" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">提议的方法</h1><p id="600d" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">首先，本文引入了3个度量标准来量化生成的摘要中实体级的一致性。<em class="lq">其细节在下面讨论— </em></p><h2 id="48d2" class="mp lt it bd lu mq mr dn ly ms mt dp mc ld mu mv me lh mw mx mg ll my mz mi na bi translated">韵律学</h2><ol class=""><li id="bd46" class="nb nc it kw b kx mk la ml ld nd lh ne ll nf lp ng nh ni nj bi translated"><em class="lq">Precision-source—</em><strong class="kw iu">prec(s))</strong>量化幻觉程度模型有w.r.t <strong class="kw iu">源文件</strong>。<em class="lq">数学上定义为</em> —</li></ol><blockquote class="nk"><p id="b955" class="nl nm it bd nn no np nq nr ns nt lp dk translated">prec(s) = N (h ∩ s)/N (h)</p></blockquote><p id="0d0a" class="pw-post-body-paragraph ku kv it kw b kx nu ju kz la nv jx lc ld nw lf lg lh nx lj lk ll ny ln lo lp im bi translated">这里，N(h)和N(s)分别指生成的摘要和源文档中的命名实体集合。他们使用<a class="ae lr" href="https://spacy.io/universe/project/video-spacys-ner-model/" rel="noopener ugc nofollow" target="_blank"> SpaCy的NER模型</a>来提取这些实体。prec(s)的低值意味着幻觉严重，因为在这种情况下N(h)会很高，因为生成的概要中的唯一实体的计数会很高。</p><ul class=""><li id="be55" class="nb nc it kw b kx ky la lb ld nz lh oa ll ob lp oc nh ni nj bi translated"><em class="lq">精确目标— </em> <strong class="kw iu">精确目标(prec(t)) </strong>与prec(s)做相同的事情，但w.r.t .为<strong class="kw iu">实际汇总。</strong>这个想法是计算模型在假设汇总中生成多少个实体也是实际汇总的一部分。<em class="lq">数学上，它被给定为— </em></li></ul><blockquote class="nk"><p id="04a8" class="nl nm it bd nn no np nq nr ns nt lp dk translated">prec(t) = N (h ∩ t)/N (h)</p></blockquote><p id="3918" class="pw-post-body-paragraph ku kv it kw b kx nu ju kz la nv jx lc ld nw lf lg lh nx lj lk ll ny ln lo lp im bi translated">这里，N(h)和N(t)分别指生成/假设和实际摘要中的命名实体集合。</p><ul class=""><li id="a99a" class="nb nc it kw b kx ky la lb ld nz lh oa ll ob lp oc nh ni nj bi translated"><em class="lq">Recall-target—<strong class="kw iu">下的</strong></em>Recall-target(Recall(t))其思路是计算实际摘要中有多少实体没有出现在模型生成的假设摘要中。<em class="lq">数学上，它被给定为— </em></li></ul><blockquote class="nk"><p id="6d19" class="nl nm it bd nn no np nq nr ns nt lp dk translated">回忆(t) = N (h∩t)/N (t)</p></blockquote><p id="631e" class="pw-post-body-paragraph ku kv it kw b kx nu ju kz la nv jx lc ld nw lf lg lh nx lj lk ll ny ln lo lp im bi translated">这里，N(h)和N(t)分别指生成/假设和实际摘要中的命名实体集合。为了得到一个可量化的数字，他们<strong class="kw iu">将prec(t)和prec(s)合并，并表示为F1分数</strong>。<em class="lq">数学上，它被给定为— </em></p><blockquote class="nk"><p id="a5c0" class="nl nm it bd nn no od oe of og oh lp dk translated">F1 = 2预测召回次数(t)/(预测召回次数+召回次数)</p></blockquote><h2 id="3d19" class="mp lt it bd lu mq oi dn ly ms oj dp mc ld ok mv me lh ol mx mg ll om mz mi na bi translated">基于实体的数据过滤</h2><p id="24d4" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">作者假设<strong class="kw iu">幻觉问题很大程度上嵌入了训练数据本身</strong>。因此，为了验证这一点，他们计算了3个流行数据集(即Newsroom、CNN/DM和XSUM)的prec(s)分数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/748e26a0c680d83b209c808a6d2409ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*8WOOMvBiSjYdD1sX0LtRaw.png"/></div><p class="oo op gj gh gi oq or bd b be z dk translated">来自<a class="ae lr" href="https://arxiv.org/pdf/2102.09130.pdf" rel="noopener ugc nofollow" target="_blank">源</a>的实际摘要|图像中命名实体和prec的平均数量(%)</p></figure><p id="1697" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如我们在上表中看到的，新闻编辑室和CNN/DM数据集的幻觉率接近10%，XSUM 的幻觉率接近20%。因此，如果看到这些都是非常重要的数字，那么模型也会学习这些模式，并且注定会在生成摘要时产生幻觉。</p><p id="bfbb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，作者提出了一种<strong class="kw iu">数据过滤方法</strong>，其中，如果摘要中的任何实体在源文档中不存在，则从摘要中删除该特定句子。万一，如果基本事实摘要只包含一个句子，并且它需要被丢弃，我们从数据集中移除文档-摘要对。因此，从所有3个黄金标准数据集中删除句子后，大量数据被删除。例如，下表显示了XSUM数据集的相同情况。第一行是实际计数，第二行是数据过滤步骤后的计数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/8f5dcabff73fb67c078e294dbaa81d01.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*Q7NX49KFJoJlfzdPRAE5pQ.png"/></div><p class="oo op gj gh gi oq or bd b be z dk translated">对来自<a class="ae lr" href="https://arxiv.org/pdf/2102.09130.pdf" rel="noopener ugc nofollow" target="_blank">源</a>的XSUM |图像进行数据过滤</p></figure><p id="3e45" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">根据实际数据和过滤数据训练的模型的评估分数在结果部分提及。</em></p><h1 id="8e02" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">多任务学习</h1><p id="84dd" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">在这种情况下，他们提出了一个额外的任务<strong class="kw iu">对源文件<em class="lq">(编码器端)</em>中值得摘要的命名实体</strong>进行分类。有摘要价值的实体被定义为来自源文档的命名实体，其也存在于基本事实摘要中。为了实现这一点，他们用一个<strong class="kw iu">生物方案</strong> <em class="lq"> (B-Begin，I-Inside，O-outside) </em>来标记源文档中的每个标记，这是一种非常标准的技术，用于标记文本片段中的单个/多个单词实体。<em class="lq">下图以图形方式显示了流程— </em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/cc9642af608c6b5423e8b9de92e4da01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*ekB3bcYIjtVJIWq72ifiKw.png"/></div><p class="oo op gj gh gi oq or bd b be z dk translated">多任务学习|作者图片</p></figure><p id="cfc3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">数学上可以表示为— </em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/ff387a4436c5acb009bed77e893c24ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*Fo0HfAIE7mdQ_ZLZZUkzjA.png"/></div></figure><p id="d2c5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这种损失背后的直觉是，这种损失将迫使编码器对其表示进行建模，以便捕获关于值得汇总的实体的相关信息。现在，当<strong class="kw iu">解码器获得这种实体丰富的表示时，它可以产生相当好的有思想的一代</strong> <em class="lq">(希望导致较少的幻觉)？</em></p><p id="f99c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">除了BIO损失，他们还将典型的MLE损失用于训练序列生成模型，该模型将从解码器端传播损失。<em class="lq">数学上可以表示为— </em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/9d1cf7c624fcc35fda1d1244e43aa911.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*1TzUPSgupiIJUth4PvYtuA.png"/></div></figure><p id="74fe" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这里，θ，x，y，I分别是模型参数，输入记号，输出记号和第I个记号。最后，他们最小化联合损失<strong class="kw iu"><em class="lq">L(I)= L(I)_ MLE+αL(I)_ BIO</em></strong>，其中α为超参数。他们根据验证集在0.1到0.5之间选择α。</p><h2 id="325f" class="mp lt it bd lu mq mr dn ly ms mt dp mc ld mu mv me lh mw mx mg ll my mz mi na bi translated">加入显著实体和摘要生成(JAENS)</h2><p id="db18" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">除了前两种方法之外，他们还探索了另一种生成方法，其中，他们不是仅仅生成摘要，而是训练序列模型来生成值得摘要的命名实体的序列，随后是特殊标记，然后是摘要标记。</p><p id="2d8c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这种方法背后的直觉是，在生成摘要令牌的同时，解码器可以通过自我关注机制关注值得摘要的实体。因为它将在学习生成摘要的同时共同学习识别值得摘要的命名实体。<em class="lq">下图以图形方式显示了流程— </em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/d3c46e9baae5dbdc50e9cef3392b9625.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*cwO-We3Wr7kAiXHq2GkeFg.png"/></div><p class="oo op gj gh gi oq or bd b be z dk translated">JAENS建筑|作者图片</p></figure><h1 id="1de1" class="ls lt it bd lu lv lw lx ly lz ma mb mc jz md ka me kc mf kd mg kf mh kg mi mj bi translated">结果</h1><p id="43d8" class="pw-post-body-paragraph ku kv it kw b kx mk ju kz la ml jx lc ld mm lf lg lh mn lj lk ll mo ln lo lp im bi translated">正如我们在下表中看到的，使用所提出的方法，幻觉率有了相当好的降低。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/58e7d6cdb1dee6b2b82dcd59e12217d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6pQis8lCwmKWKMzl6R-Uug.png"/></div></div><p class="oo op gj gh gi oq or bd b be z dk translated">各种训练方案对比|图片来自<a class="ae lr" href="https://arxiv.org/pdf/2102.09130.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><blockquote class="nk"><p id="30fa" class="nl nm it bd nn no np nq nr ns nt lp dk translated">如果你愿意，你也可以查看我写的其他研究论文摘要。</p></blockquote><p id="39a7" class="pw-post-body-paragraph ku kv it kw b kx nu ju kz la nv jx lc ld nw lf lg lh nx lj lk ll ny ln lo lp im bi translated">所以，是的，这就是我的博客。我也有同样的多语言字幕视频漫游，如果你喜欢看视频而不是文字(就像我:D一样)，一定要看看</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oy oz l"/></div><p class="oo op gj gh gi oq or bd b be z dk translated"><a class="ae lr" href="https://www.youtube.com/channel/UCoz8NrwgL7U9535VNc0mRPA/" rel="noopener ugc nofollow" target="_blank">多看看这样的视频</a></p></figure><p id="9bad" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">请随意阅读整篇论文，并向作者说“<strong class="kw iu">嗨</strong>”，感谢他们的贡献。</p><blockquote class="pa pb pc"><p id="d3da" class="ku kv lq kw b kx ky ju kz la lb jx lc pd le lf lg pe li lj lk pf lm ln lo lp im bi translated"><strong class="kw iu"> <em class="it">论文标题:</em> </strong> <em class="it">抽象文本摘要的实体级事实一致性</em></p><p id="b2a1" class="ku kv lq kw b kx ky ju kz la lb jx lc pd le lf lg pe li lj lk pf lm ln lo lp im bi translated"><strong class="kw iu"> <em class="it">论文链接:</em></strong><a class="ae lr" href="https://arxiv.org/pdf/2102.09130.pdf" rel="noopener ugc nofollow" target="_blank"><em class="it">https://arxiv.org/pdf/2102.09130.pdf</em></a></p><p id="1ef6" class="ku kv lq kw b kx ky ju kz la lb jx lc pd le lf lg pe li lj lk pf lm ln lo lp im bi translated"><strong class="kw iu"> <em class="it">作者:</em> </strong> <em class="it">冯楠、拉梅什·纳拉帕蒂、、西塞罗·诺盖拉·多斯桑托斯、朱恒辉、张德娇、凯思琳·麦克科恩、冰翔</em></p></blockquote><p id="a157" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">另外，如果你喜欢读这篇文章，你可以选择在<a class="ae lr" href="https://www.buymeacoffee.com/TechvizCoffee" rel="noopener ugc nofollow" target="_blank"><em class="lq">【https://www.buymeacoffee.com/TechvizCoffee】</em></a><em class="lq">——因为我实际上不喝咖啡:)非常感谢！完全是可选的，自愿的:)</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/c8131c8f55990f5ddf0dadc91a525112.png" data-original-src="https://miro.medium.com/v2/resize:fit:264/format:webp/1*oBZwTW3aPRQsEERMuioV5g.png"/></div></figure></div></div>    
</body>
</html>