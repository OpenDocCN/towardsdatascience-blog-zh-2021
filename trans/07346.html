<html>
<head>
<title>Cats VS Dogs Convolutional Classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">猫狗卷积分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cats-vs-dogs-convolutional-classifier-44ec04c8eb7a?source=collection_archive---------21-----------------------#2021-07-04">https://towardsdatascience.com/cats-vs-dogs-convolutional-classifier-44ec04c8eb7a?source=collection_archive---------21-----------------------#2021-07-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9d62" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Python代码、Tensorflow和Google Colab从头开始创建和测试一个简单的模型</h2></div><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="kn ko l"/></div></figure><h2 id="f52f" class="kp kq it bd kr ks kt dn ku kv kw dp kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">3分钟机器学习</h2><p id="5043" class="pw-post-body-paragraph ll lm it ln b lo lp ju lq lr ls jx lt ky lu lv lw lc lx ly lz lg ma mb mc md im bi translated">3分钟机器学习是一系列与机器学习世界相关的教程和内容丰富的视频。你可以在YouTube上找到完整的视频。<a class="ae me" href="https://github.com/GitMarco27/TMML" rel="noopener ugc nofollow" target="_blank">库</a>包含视频中显示的所有文件。这个系列是在实验阶段，完全免费开发，为了娱乐和文化！欢迎任何反馈。</p><p id="12a5" class="pw-post-body-paragraph ll lm it ln b lo mf ju lq lr mg jx lt ky mh lv lw lc mi ly lz lg mj mb mc md im bi translated">其他剧集:</p><ul class=""><li id="e869" class="mk ml it ln b lo mf lr mg ky mm lc mn lg mo md mp mq mr ms bi translated"><a class="ae me" rel="noopener" target="_blank" href="/images-generation-with-neural-style-transfer-and-tensorflow-a823b0353b06">用神经风格转移和张量流生成图像</a></li></ul><h2 id="2280" class="kp kq it bd kr ks kt dn ku kv kw dp kx ky kz la lb lc ld le lf lg lh li lj lk bi translated"><strong class="ak">为什么要读这篇文章？</strong></h2><p id="5905" class="pw-post-body-paragraph ll lm it ln b lo lp ju lq lr ls jx lt ky lu lv lw lc lx ly lz lg ma mb mc md im bi translated">本文将会看到如何使用<strong class="ln iu"> Google Colab </strong>来实现我们自己的<strong class="ln iu">深度学习</strong>模型的实用性和功能性。然后，我们将看到如何将一个预先存在的数据集导入到我们的工作空间中。我们将实现一个<strong class="ln iu"> 2D卷积神经网络模型</strong>，用于我们图像的<strong class="ln iu">二进制分类</strong>。一旦模型被建立和训练，我们将用新的图像测试我们的模型。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi mt"><img src="../Images/ce63094014a22b81e171b8cef765a239.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MVN9kJDHaKaWuiEYbtlBrA.jpeg"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">正确分类的图像——来自<a class="ae me" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=323262" rel="noopener ugc nofollow" target="_blank">像素库</a>的<a class="ae me" href="https://pixabay.com/users/teamk-222368/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=323262" rel="noopener ugc nofollow" target="_blank"> K L </a>图像</p></figure><h2 id="f455" class="kp kq it bd kr ks kt dn ku kv kw dp kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">Google Colab:为什么？</h2><p id="0692" class="pw-post-body-paragraph ll lm it ln b lo lp ju lq lr ls jx lt ky lu lv lw lc lx ly lz lg ma mb mc md im bi translated">Colaboratory，简称“<strong class="ln iu"> Colab </strong>”，是谷歌研究院的产品。Colab允许任何人通过浏览器编写和执行任意的<strong class="ln iu"> python代码</strong>，特别适合机器学习、数据分析和教育。从技术上来说，Colab是一种托管的Jupyter笔记本服务，无需设置即可使用，同时提供对计算资源的免费访问，包括<strong class="ln iu">GPU</strong>。点击此<a class="ae me" href="https://research.google.com/colaboratory/faq.html" rel="noopener ugc nofollow" target="_blank">链接</a>了解更多信息。</p><h2 id="2a7e" class="kp kq it bd kr ks kt dn ku kv kw dp kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">在Google Colab中选择运行时</h2><p id="81e5" class="pw-post-body-paragraph ll lm it ln b lo lp ju lq lr ls jx lt ky lu lv lw lc lx ly lz lg ma mb mc md im bi translated">当开发您自己的代码或使用共享代码时，请记住从运行时下的工具栏中选择所需的硬件加速器。对于这个案例研究，由于它是基于卷积网络的模型，所以最好使用平台上免费提供的<strong class="ln iu"> GPU的</strong>的能力。总之，我们的<strong class="ln iu">神经网络模型</strong>有大量参数，必须使用<strong class="ln iu">优化</strong>算法来确定这些参数，以最小化期望的损失函数。这个过程包括<strong class="ln iu">前向传播</strong>和<strong class="ln iu">后向传播</strong>，对每个训练时期的每个<strong class="ln iu">批</strong>数据重复这个过程。因此，这个过程涉及到一个<strong class="ln iu"> <em class="ne">大数</em> </strong>的简单数学运算。GPU，带有:</p><ul class=""><li id="1c7a" class="mk ml it ln b lo mf lr mg ky mm lc mn lg mo md mp mq mr ms bi translated">核心数量多</li><li id="957f" class="mk ml it ln b lo nf lr ng ky nh lc ni lg nj md mp mq mr ms bi translated">数千个并发硬件线程</li></ul><p id="fdef" class="pw-post-body-paragraph ll lm it ln b lo mf ju lq lr mg jx lt ky mh lv lw lc mi ly lz lg mj mb mc md im bi translated">允许我们更快地执行模型的训练和推理。</p><h2 id="c76f" class="kp kq it bd kr ks kt dn ku kv kw dp kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">卷积分类器</h2><p id="6058" class="pw-post-body-paragraph ll lm it ln b lo lp ju lq lr ls jx lt ky lu lv lw lc lx ly lz lg ma mb mc md im bi translated">图像分析可以通过各种深度学习和神经网络模型来执行，但是，C<strong class="ln iu">on voluntive Networks</strong>由于其有效性，几乎成为这种类型分析的强制工具。总而言之，一系列大小可变的<strong class="ln iu">过滤器</strong>的应用允许从图像本身提取信息和<strong class="ln iu">特征</strong>。第一层会提取出<strong class="ln iu">最一般的特征</strong>，越深的层越有<strong class="ln iu">具体的特征</strong>。同时，这种方法允许在模型的几个可训练参数下工作，这些参数远低于用专门基于<strong class="ln iu">致密层</strong>的神经网络分析图像所需的参数。更多信息，请参考<a class="ae me" rel="noopener" target="_blank" href="/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1">这篇文章</a>。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nk"><img src="../Images/af9b7b01172087428ad0205fe770c292.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7-lqUVzdHS5KDuQCOCJK3Q.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">猫和狗的分类器结构-作者图片</p></figure><h2 id="ffe8" class="kp kq it bd kr ks kt dn ku kv kw dp kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">代码</h2><p id="8d0b" class="pw-post-body-paragraph ll lm it ln b lo lp ju lq lr ls jx lt ky lu lv lw lc lx ly lz lg ma mb mc md im bi translated">让我们从导入数据集开始:</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="nl ko l"/></div></figure><p id="bc58" class="pw-post-body-paragraph ll lm it ln b lo mf ju lq lr mg jx lt ky mh lv lw lc mi ly lz lg mj mb mc md im bi translated">让我们导入我们的<strong class="ln iu">数据集</strong>。它包含<strong class="ln iu">狗</strong>和<strong class="ln iu">猫</strong>的图像，这将允许我们训练我们的分类器。我们直接从Google API下载数据集，然后将其解压缩到所需的路径。我们通过定义路径来定义<strong class="ln iu">目录</strong>的结构。我们为<strong class="ln iu">训练</strong>和<strong class="ln iu">验证</strong>数据定义了两个独立的目录，每个目录又分为两个文件夹:狗和猫。这种结构可能看起来很复杂，但它变得特别复杂，因为它很容易与Tensorflow语法接口。所以让我们看看我们有多少数据。</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="nl ko l"/></div></figure><p id="c3bb" class="pw-post-body-paragraph ll lm it ln b lo mf ju lq lr mg jx lt ky mh lv lw lc mi ly lz lg mj mb mc md im bi translated">让我们的神经网络模型，类似于前一个图像中描述的。在这种情况下，考虑到模型的简单性，我们使用Keras 的<strong class="ln iu">顺序API。这允许我们通过简单地定义不同层的列表来创建神经网络，正如我们可以从名称本身猜测的那样。使用的层是在Tensorflow/Keras中实现的标准层的一部分。</strong></p><ul class=""><li id="4e8a" class="mk ml it ln b lo mf lr mg ky mm lc mn lg mo md mp mq mr ms bi translated"><a class="ae me" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D" rel="noopener ugc nofollow" target="_blank"> Conv2D </a> : 2D卷积层</li><li id="374d" class="mk ml it ln b lo nf lr ng ky nh lc ni lg nj md mp mq mr ms bi translated"><a class="ae me" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D" rel="noopener ugc nofollow" target="_blank">MaxPooling2D</a>:2D空间数据的最大池操作</li><li id="ab66" class="mk ml it ln b lo nf lr ng ky nh lc ni lg nj md mp mq mr ms bi translated"><a class="ae me" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten" rel="noopener ugc nofollow" target="_blank">展平</a>:展平输入</li><li id="0e0a" class="mk ml it ln b lo nf lr ng ky nh lc ni lg nj md mp mq mr ms bi translated"><a class="ae me" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense" rel="noopener ugc nofollow" target="_blank">密集</a>:规则密集连接NN层</li></ul><p id="922a" class="pw-post-body-paragraph ll lm it ln b lo mf ju lq lr mg jx lt ky mh lv lw lc mi ly lz lg mj mb mc md im bi translated"><em class="ne"> model.summary() </em>显示我们模型的概要，显示每层的<strong class="ln iu">名称</strong>、<strong class="ln iu">类型</strong>、<strong class="ln iu">输出形状</strong>和<strong class="ln iu">可训练参数</strong>数量。</p><p id="b671" class="pw-post-body-paragraph ll lm it ln b lo mf ju lq lr mg jx lt ky mh lv lw lc mi ly lz lg mj mb mc md im bi translated">该型号必须<strong class="ln iu">编制</strong>，方可训练。对于本教程，我选择了<strong class="ln iu"> Adam </strong>作为优化器，学习率固定。然而，通过优化结构和调整所有的<em class="ne">初级</em>和<em class="ne">次级</em> <strong class="ln iu">超参数</strong>，该模型可以得到很大的改进。我们将评估仅仅<strong class="ln iu"> <em class="ne">准确度</em> </strong>作为评估模型性能的主要指标。然而，准确性可能会与其他指标相结合，例如<strong class="ln iu"> <em class="ne"> f-Beta得分</em> </strong>，以便更可靠地评估模型的质量。</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="nl ko l"/></div></figure><p id="5b8e" class="pw-post-body-paragraph ll lm it ln b lo mf ju lq lr mg jx lt ky mh lv lw lc mi ly lz lg mj mb mc md im bi translated">所使用的目录结构允许使用<strong class="ln iu">图像数据生成器</strong>和<strong class="ln iu"> flow_from_directory </strong>方法。第一个允许对源图像应用缩放和<strong class="ln iu">数据扩充</strong>。为了进行这种分析，我们对<strong class="ln iu">训练图像</strong>应用了缩放、旋转、移动、剪切、缩放和翻转。您可能会注意到，没有对测试数据应用数据扩充。<strong class="ln iu"> flow_from_directory </strong>方法自动加载指定路径中包含的子目录中的所有图像，并在文件夹名称后标记图像。我们只需指定图像的主路径、批量大小、分类模型和<strong class="ln iu">目标大小</strong>。</p><p id="49cb" class="pw-post-body-paragraph ll lm it ln b lo mf ju lq lr mg jx lt ky mh lv lw lc mi ly lz lg mj mb mc md im bi translated">最后，我们可以训练模型，将训练数据存储在历史对象中。请注意，我们有2000个训练图像和1000个测试图像，批量大小为20:对于<strong class="ln iu"> <em class="ne">训练集</em> </strong>，每个时期有100个步骤，对于<strong class="ln iu"> <em class="ne">验证集</em> </strong>，每个时期有50个步骤。让我们对网络进行少量纪元(50)的训练，看看结果。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nm"><img src="../Images/3f93fe405acc3ad34b96b092174c0927.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-r2XkuPoN05FcG_DL1baRw.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">培训历史-作者图片</p></figure><p id="b8e3" class="pw-post-body-paragraph ll lm it ln b lo mf ju lq lr mg jx lt ky mh lv lw lc mi ly lz lg mj mb mc md im bi translated">在训练过程的最后，我们用我们的基本分类器在两个集合上实现了大约80 %  的准确率<strong class="ln iu"> <em class="ne">。这是一个好结果，但我们绝没有优化我们的模型，正如更长的训练似乎可能导致更高的表现。在接下来的一篇文章中，我们将看到如何使用各种超参数优化和迁移学习技术来尝试<strong class="ln iu">改进我们的分类器。</strong></em></strong></p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="nl ko l"/></div></figure><p id="d087" class="pw-post-body-paragraph ll lm it ln b lo mf ju lq lr mg jx lt ky mh lv lw lc mi ly lz lg mj mb mc md im bi translated">您可以使用直接从本地存储空间上传的新图像来测试代码，并且<strong class="ln iu">立即</strong>获得一个<strong class="ln iu">预测</strong>。该模型虽然没有优化，但能够正确预测以下两幅图像的类别，这两幅图像是该模型在训练或验证阶段从未见过的。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi mt"><img src="../Images/d8ed1e302860ed879e3d3b75fc2ad93b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7RLX_E68ukQBLrBzBICPkA.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">测试图像—作者提供的图像</p></figure><h1 id="5fd9" class="nn kq it bd kr no np nq ku nr ns nt kx jz nu ka lb kc nv kd lf kf nw kg lj nx bi translated">结论</h1><p id="47ba" class="pw-post-body-paragraph ll lm it ln b lo lp ju lq lr ls jx lt ky lu lv lw lc lx ly lz lg ma mb mc md im bi translated">我希望你喜欢这篇文章的内容。我提醒你，你可以在这里找到<a class="ae me" href="https://github.com/GitMarco27/TMML/blob/main/Notebooks/003_Cat_vs_Dog.ipynb" rel="noopener ugc nofollow" target="_blank">源代码</a>，在GitHub和<a class="ae me" href="https://www.youtube.com/channel/UCExkeDZ9WC0tg9aoFMsNF0w" rel="noopener ugc nofollow" target="_blank"> YouTube </a>上可以找到完整的<a class="ae me" href="https://github.com/GitMarco27/TMML" rel="noopener ugc nofollow" target="_blank">资源库</a>。<br/>下次见，<br/>马尔科</p></div></div>    
</body>
</html>