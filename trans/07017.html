<html>
<head>
<title>Text Classification: Predicting ‘Good’ or ‘Bad’ Statements using Natural Language Processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本分类:使用自然语言处理预测“好”或“坏”的陈述</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/text-classification-predicting-good-or-bad-statements-using-natural-language-processing-e3a4edb07118?source=collection_archive---------21-----------------------#2021-06-25">https://towardsdatascience.com/text-classification-predicting-good-or-bad-statements-using-natural-language-processing-e3a4edb07118?source=collection_archive---------21-----------------------#2021-06-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e410" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用空间库创建和训练NLP模型，以预测和分类输入线</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/663c4d89132f77dc4b9d66bc475c5b7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PkU81_ZirqycgH5S.jpg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由<a class="ae kv" href="https://pixabay.com/users/ramdlon-710044/" rel="noopener ugc nofollow" target="_blank">拉姆德隆</a>从<a class="ae kv" href="https://pixabay.com/photos/good-bad-opposite-choice-choose-1123013/" rel="noopener ugc nofollow" target="_blank"> Pixbay </a>拍摄</p></figure><p id="45a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇博客将介绍一种非常基本的方法，预测给定的输入语句应该被分类为“好”还是“坏”。为此，我们将首先利用过去的数据集训练自然语言处理(NLP)模型。这样，我们开始怎么样！</p><h2 id="6fdf" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">先决条件:</h2><p id="4890" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">你应该知道BOW(单词袋)方法。你可以查看[1]了解更多细节。BOW方法本质上是将文本转换成数字，使得NLP模型更容易学习。</p><p id="8194" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本教程中，<a class="ae kv" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>用于运行脚本。你可以选择任何你喜欢的平台。另外，使用的脚本语言是Python。</p><h2 id="8890" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">数据集</h2><p id="5f62" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">由于这是一个非常入门的博客，我自己写的数据集总共只有7行，如表1所示。一旦你熟悉了基本要素，我强烈建议你选择一个更大的数据集，并尝试应用类似的处理来获得经验。Kaggle是追踪无数数据集的好地方。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">表1:带有标记为“好”或“坏”的简单语句的自定义数据集</p></figure><h2 id="2f74" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">Python脚本</h2><p id="9523" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">你可以在<a class="ae kv" href="https://github.com/semicolon123/ML-DL-projects/blob/main/Predict_good_bad_lines_in_dataset.ipynb" rel="noopener ugc nofollow" target="_blank">这个</a> Github仓库中找到完整的代码库。在这篇博客中，我将只解释重要的代码片段。如果仍然需要代码的其他部分的助手，做评论，我很乐意帮助。</p><p id="0ddf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用<a class="ae kv" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank"> spaCy </a>包。这是一个免费的开源库，用于Python中的自然语言处理。我强烈推荐你访问这个软件包的网站，快速浏览一下它提供了什么。</p><p id="af9a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">导入数据集后，我们将创建一个空白模型。我们使用spaCy提供的文本分类器。请注意，文本分类程序有许多版本。但是我们将使用textcat，如下面的代码所示。使用<code class="fe ms mt mu mv b">textcat</code>是因为我们只想预测一个真正的标签，它要么是<em class="mw">好的</em>要么是<em class="mw">坏的。</em></p><pre class="kg kh ki kj gt mx mv my mz aw na bi"><span id="39f3" class="ls lt iq mv b gy nb nc l nd ne">nlp = spacy.blank("en")  <em class="mw">#model is named as nlp</em><br/><br/><em class="mw"># text categroizer wit standard settings</em><br/>textcat = nlp.create_pipe("textcat", config={<br/>                "exclusive_classes": <strong class="mv ir">True</strong>,<br/>                "architecture": "bow"}) <em class="mw">#bow = bag of words</em><br/><br/>nlp.add_pipe(textcat) <em class="mw">#add textcat to nlp</em></span></pre><h2 id="83cc" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">训练模型</h2><p id="61de" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">为了训练一个模型，你需要一个优化器，为此，spaCy包来拯救你。优化器将在训练阶段使用<code class="fe ms mt mu mv b">minibatch</code>函数不断更新模型。请注意下面的代码，它完成了我们刚刚讨论过的任务。</p><pre class="kg kh ki kj gt mx mv my mz aw na bi"><span id="fe86" class="ls lt iq mv b gy nb nc l nd ne">from <strong class="mv ir">spacy</strong>.util import <strong class="mv ir">minibatch</strong><br/>optimizer = nlp.begin_training() <em class="mw">#create optmizer to be used by spacy to update the model</em><br/><br/>batches = minibatch(train_data, size=8) <em class="mw">#spacy provides minibatch fn</em><br/><br/>for batch in batches:<br/>    texts, labels = zip(*batch)<br/>    nlp.update(texts, labels, sgd=optimizer)</span></pre><h2 id="3012" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">做预测</h2><p id="23f6" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在上一步中，我们使用输入数据集对模型进行了定型。完成后，您可以使用如下所示的predict()方法，使用训练好的模型对输入语句或行进行预测:</p><pre class="kg kh ki kj gt mx mv my mz aw na bi"><span id="a877" class="ls lt iq mv b gy nb nc l nd ne"><em class="mw"># i mentioned all lines to be predicted in a 'texts' array</em> </span><span id="0f6e" class="ls lt iq mv b gy nf nc l nd ne">Lines = ["<strong class="mv ir">I look awesome</strong>"] <br/>docs = [nlp.tokenizer(text)<strong class="mv ir">for</strong> text <strong class="mv ir">in</strong> Lines]      <br/>textcat = nlp.get_pipe('textcat') <br/>scores, _ = textcat.predict(docs)  </span><span id="4038" class="ls lt iq mv b gy nf nc l nd ne"><em class="mw">#Prob score for both classes (Good/bad)</em> <br/>print(scores)</span></pre><p id="c413" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另外，请注意一件事。当上述代码运行时，输出将类似于:</p><pre class="kg kh ki kj gt mx mv my mz aw na bi"><span id="5eed" class="ls lt iq mv b gy nb nc l nd ne">[[0.50299996 0.49700007]]</span></pre><p id="d0b1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的输出是两个类标签的概率分数。在当前的场景中，可能的标签是- <em class="mw">好的</em>或<em class="mw">坏的。</em>根据上述输出，给定输入线为<em class="mw">好</em>的概率更大(0.50299996)，因此模型将该线分类为<em class="mw">好</em>。</p><p id="850c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了使预测更直接，让我们打印给定输入行的类标签，而不是概率分数。</p><pre class="kg kh ki kj gt mx mv my mz aw na bi"><span id="ce14" class="ls lt iq mv b gy nb nc l nd ne">predicted_labels = scores.argmax(axis=1)<br/>print([textcat.labels[label] <strong class="mv ir">for</strong> label <strong class="mv ir">in</strong> predicted_labels])</span></pre><p id="9a94" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您将看到如下输出:</p><pre class="kg kh ki kj gt mx mv my mz aw na bi"><span id="2540" class="ls lt iq mv b gy nb nc l nd ne">['Good']</span></pre><h2 id="526c" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">后续步骤</h2><p id="a030" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">首先，祝贺你！您刚刚学习了如何使用spaCy库构建文本分类器。绝对有许多替代方法可以做到这一点，我以后会提供更多的指导性博客。在进一步通知之前，我想请求我的读者从这个指导性练习中吸取经验，并将其应用到一些相对更大的数据集上。</p><p id="90df" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">还有，你可以在<a class="ae kv" href="https://twitter.com/SwatiRajwal" rel="noopener ugc nofollow" target="_blank"> Twitter </a>和<a class="ae kv" href="https://www.linkedin.com/in/swati-r-84682b12b/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上问我一个问题！</p><h2 id="1822" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">参考</h2><p id="b71d" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">[1] Ismayil，M. (2021年2月10日)。<em class="mw">从文字到向量——走向数据科学</em>。中等。<a class="ae kv" rel="noopener" target="_blank" href="/from-words-to-vectors-e24f0977193e">https://towards data science . com/from-words-to-vectors-e24f 0977193 e</a></p></div></div>    
</body>
</html>