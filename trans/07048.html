<html>
<head>
<title>TextGenie - Augmenting your text dataset with just 2 lines of code!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">text genie——仅用两行代码扩充您的文本数据集！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/textgenie-augmenting-your-text-dataset-with-just-2-lines-of-code-23ce883a0715?source=collection_archive---------10-----------------------#2021-06-26">https://towardsdatascience.com/textgenie-augmenting-your-text-dataset-with-just-2-lines-of-code-23ce883a0715?source=collection_archive---------10-----------------------#2021-06-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/63518f43d847f58a4ce4a0e425af1c54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Qozu9DvGYJfASyn0KPTTA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">TextGenie徽标-作者图片</p></figure><p id="6419" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">通常在开发自然语言处理模型时，我们发现很难找到相关数据。更重要的是，找到大量的数据。</p><p id="616d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">之前，在开发我们的<a class="ae la" href="https://medium.com/analytics-vidhya/creating-your-own-intent-classifier-b86e000a4926" rel="noopener">意图分类器</a>时，我们使用了<a class="ae la" href="https://github.com/clinc/oos-eval" rel="noopener ugc nofollow" target="_blank"> CLINC150数据集</a>，该数据集包含150个不同类别的100个样本。但是，如果我们需要更多的样本呢？另一个类似的场景是我在用<a class="ae la" href="https://github.com/RasaHQ/rasa" rel="noopener ugc nofollow" target="_blank"> Rasa </a>开发上下文助手的时候。当从头开始创建训练数据时，我必须为每个意图设想不同的样本，或者向我的朋友寻求一些帮助。根据领域的不同，每个类可能需要一定数量的样本。</p><p id="8785" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这是我产生创建<a class="ae la" href="https://github.com/hetpandya/textgenie" rel="noopener ugc nofollow" target="_blank"> TextGenie </a>的想法的时候，这是一个增加文本数据的库。python包在我的<a class="ae la" href="https://github.com/hetpandya/textgenie" rel="noopener ugc nofollow" target="_blank"> Github repo </a>是开源的。让我们看看图书馆的运作。</p><h1 id="f870" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">图书馆是如何工作的</h1><p id="f6a9" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">到目前为止，该库使用以下方法来扩充文本数据:</p><h2 id="efb2" class="me lc iq bd ld mf mg dn lh mh mi dp ll kn mj mk lp kr ml mm lt kv mn mo lx mp bi translated">使用T5解释</h2><p id="68e9" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">通过使用深度学习进行解释，可以生成大量不同的样本。我们将使用来自huggingface的这个<a class="ae la" href="https://huggingface.co/ramsrigouthamg/t5_paraphraser" rel="noopener ugc nofollow" target="_blank"> T5模型</a>来生成释义。</p><h2 id="cba9" class="me lc iq bd ld mf mg dn lh mh mi dp ll kn mj mk lp kr ml mm lt kv mn mo lx mp bi translated">伯特遮罩填充</h2><p id="b4c1" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">为了使用掩码填充来扩充文本，找到可以被掩码的第一个单词。为此，我们将使用spacy从一个句子中提取关键字。一旦找到关键词，它们就被替换为掩码，并被馈送到BERT模型，以预测一个单词来代替被屏蔽的单词。</p><h2 id="0c09" class="me lc iq bd ld mf mg dn lh mh mi dp ll kn mj mk lp kr ml mm lt kv mn mo lx mp bi translated">将句子转换成主动语态</h2><p id="8050" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">此外，我们还检查一个句子是否是被动语态。如果是，则转换为主动语态。</p><h1 id="3436" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">装置</h1><p id="205b" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">使用以下命令安装库:</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="48e0" class="me lc iq mv b gy mz na l nb nc">pip install textgenie</span></pre><h1 id="d4c2" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">使用</h1><p id="1b50" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">让我们使用下面的代码初始化来自<code class="fe nd ne nf mv b">TextGenie</code>类的增强器:</p><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="6550" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在这里，除了解释模型，我还提到了BERT模型的名称，它默认设置为<code class="fe nd ne nf mv b">None</code>。但是可以通过提到模型的名称来启用它。<strong class="ke ir">建议也使用掩码填充方法，因为这将有助于生成更多数据。</strong></p><p id="1d7b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">您可以在下面找到<code class="fe nd ne nf mv b">TextGenie</code>对象的完整参数列表:</p><ul class=""><li id="9e13" class="ni nj iq ke b kf kg kj kk kn nk kr nl kv nm kz nn no np nq bi translated"><code class="fe nd ne nf mv b">paraphrase_model_name</code>:T5改述模型的名称。<strong class="ke ir">编辑:</strong>在这里可以找到用于释义生成的预训练模型列表<a class="ae la" href="https://github.com/hetpandya/paraphrase-datasets-pretrained-models#pretrained-models" rel="noopener ugc nofollow" target="_blank">。</a></li><li id="b866" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">mask_model_name</code>:该参数是可选的BERT模型，将用于填充遮罩。<code class="fe nd ne nf mv b">mask_model_name</code>的默认值设置为<code class="fe nd ne nf mv b">None</code>，默认禁用。但是可以通过提及要使用的BERT模型的名称来启用它。面具填充模型列表可以在找到<a class="ae la" href="https://huggingface.co/models?filter=en&amp;pipeline_tag=fill-mask" rel="noopener ugc nofollow" target="_blank">。</a></li><li id="d6a2" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">spacy_model_name</code>:空间模型名称。可用型号可在这里找到<a class="ae la" href="https://spacy.io/models" rel="noopener ugc nofollow" target="_blank">。默认值设置为<code class="fe nd ne nf mv b">en</code>。虽然已经设置了空间模型名称，但是如果<code class="fe nd ne nf mv b">mask_model_name</code>设置为<code class="fe nd ne nf mv b">None</code>，则不会使用该名称。</a></li><li id="e003" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">device</code>:模型加载的设备。默认值设置为<code class="fe nd ne nf mv b">cpu</code>。</li></ul><h2 id="f269" class="me lc iq bd ld mf mg dn lh mh mi dp ll kn mj mk lp kr ml mm lt kv mn mo lx mp bi translated">使用T5的释义进行文本扩充:</h2><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="b913" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><code class="fe nd ne nf mv b">augment_sent_t5()</code>方法的参数列表如下:</p><ul class=""><li id="7086" class="ni nj iq ke b kf kg kj kk kn nk kr nl kv nm kz nn no np nq bi translated"><code class="fe nd ne nf mv b">sent</code>:必须应用增强的句子。</li><li id="dd79" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">prefix</code>:T5型号输入的前缀。</li><li id="24ae" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">n_predictions</code>:增加的次数，函数应该返回。默认值设置为<code class="fe nd ne nf mv b">5</code>。</li><li id="972f" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">top_k</code>:T5模型应该生成的预测数。默认值设置为<code class="fe nd ne nf mv b">120</code>。</li><li id="9f0a" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">max_length</code>:输入模型的句子的最大长度。默认值设置为<code class="fe nd ne nf mv b">256</code>。</li></ul><h2 id="253e" class="me lc iq bd ld mf mg dn lh mh mi dp ll kn mj mk lp kr ml mm lt kv mn mo lx mp bi translated">使用BERT遮罩填充的文本增强；</h2><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="a304" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">注意:</strong>使用这种方法时，请注意标点符号。</p><p id="26bf" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">请在下面找到<code class="fe nd ne nf mv b">augment_sent_mask_filling()</code>方法的参数表:</p><ul class=""><li id="a683" class="ni nj iq ke b kf kg kj kk kn nk kr nl kv nm kz nn no np nq bi translated"><code class="fe nd ne nf mv b">sent</code>:必须应用增强的句子。</li><li id="efd8" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">n_mask_predictions</code>:伯特遮罩填充模型应生成的预测数量。默认值设置为<code class="fe nd ne nf mv b">5</code>。</li></ul><h2 id="ff8c" class="me lc iq bd ld mf mg dn lh mh mi dp ll kn mj mk lp kr ml mm lt kv mn mo lx mp bi translated">将句子转换成主动语态</h2><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="35f4" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在第一个例子中，这个句子是主动语态。因此，它被原样归还。而在另一个例子中，句子从被动语态转换成了主动语态。</p><p id="4482" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">以下是<code class="fe nd ne nf mv b">convert_to_active()</code>方法所需的参数:</p><ul class=""><li id="2aa7" class="ni nj iq ke b kf kg kj kk kn nk kr nl kv nm kz nn no np nq bi translated"><code class="fe nd ne nf mv b">sent</code>:要转换的句子。</li></ul><h2 id="b37e" class="me lc iq bd ld mf mg dn lh mh mi dp ll kn mj mk lp kr ml mm lt kv mn mo lx mp bi translated">神奇的一次:将所有方法包装在一个方法中</h2><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="e478" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">受输出所占空间的限制，我将预测值放在一个较小的数字上。请随意和他们玩！😉</p><p id="df44" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">看起来，<code class="fe nd ne nf mv b">textgenie.magic_once()</code>方法融合了上述所有技术的功能。</p><p id="644d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">由于该方法对单个文本数据进行操作，因此可以很容易地与需要数据扩充的其他框架合并。</strong></p><p id="785c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><code class="fe nd ne nf mv b">magic_once()</code>的完整参数列表如下:</p><ul class=""><li id="27b9" class="ni nj iq ke b kf kg kj kk kn nk kr nl kv nm kz nn no np nq bi translated"><code class="fe nd ne nf mv b">sent</code>:必须扩充的句子。</li><li id="be59" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">paraphrase_prefix</code>:T5型号输入的前缀。</li><li id="ebde" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">n_paraphrase_predictions</code>:扩增次数，T5型号应该返回。默认值设置为<code class="fe nd ne nf mv b">5</code>。</li><li id="1e54" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">paraphrase_top_k</code>:T5模型应该生成的预测总数。默认值设置为<code class="fe nd ne nf mv b">120</code>。</li><li id="09c8" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">paraphrase_max_length</code>:输入模型的句子的最大长度。默认值设置为<code class="fe nd ne nf mv b">256</code>。</li><li id="90b0" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">n_mask_predictions</code>:伯特遮罩填充模型应生成的预测数。默认值设置为<code class="fe nd ne nf mv b">None</code>。</li><li id="5634" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">convert_to_active</code>:句子是否要转换成主动语态。默认值设置为<code class="fe nd ne nf mv b">True</code>。</li></ul><h1 id="1ce1" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">神灯时间到了！</h1><p id="020a" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">既然已经讨论了单个数据，让我们对整个数据集施展一下魔法吧！😋</p><p id="8727" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><code class="fe nd ne nf mv b">magic_lamp()</code>方法获取整个数据集，并根据输入生成一个包含扩充数据的<code class="fe nd ne nf mv b">txt</code>或<code class="fe nd ne nf mv b">tsv</code>文件。如果输入是一个<code class="fe nd ne nf mv b">Python List</code>或<code class="fe nd ne nf mv b">.txt</code>文件，扩充后的输出将存储在一个名为<code class="fe nd ne nf mv b">sentences_aug.txt</code>的<code class="fe nd ne nf mv b">txt</code>文件中，同时，包含扩充数据的<code class="fe nd ne nf mv b">Python List</code>将被返回。如果数据在<code class="fe nd ne nf mv b">csv</code>或<code class="fe nd ne nf mv b">tsv</code>文件中，将保存一个名为<code class="fe nd ne nf mv b">original_file_name_aug.tsv</code>的包含扩充数据的<code class="fe nd ne nf mv b">tsv</code>文件，并返回一个熊猫<code class="fe nd ne nf mv b">DataFrame</code>。如果这些文件包含带标签的数据，将返回增加的数据以及相应的标签。</p><p id="dec5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">首先，我们需要一个数据集来处理。我从<a class="ae la" href="https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection" rel="noopener ugc nofollow" target="_blank">垃圾短信收集数据集</a>中提取了300个样本进行测试，你可以从<a class="ae la" href="https://gist.github.com/hetpandya/0bfbf07d587d84c37d40e54199428547" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><h2 id="cf4d" class="me lc iq bd ld mf mg dn lh mh mi dp ll kn mj mk lp kr ml mm lt kv mn mo lx mp bi translated">扩充数据集</h2><p id="46e7" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">下载当前工作目录中的<code class="fe nd ne nf mv b">hamspam.tsv</code>并运行以下代码:</p><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="855f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><code class="fe nd ne nf mv b">magic_lamp()</code>方法的完整列表如下:</p><ul class=""><li id="fcbc" class="ni nj iq ke b kf kg kj kk kn nk kr nl kv nm kz nn no np nq bi translated"><code class="fe nd ne nf mv b">sentences</code>:需要扩充的数据集。这可以是一个<code class="fe nd ne nf mv b">Python List</code>、<code class="fe nd ne nf mv b">txt</code>、<code class="fe nd ne nf mv b">csv</code>或<code class="fe nd ne nf mv b">tsv</code>文件。</li><li id="1576" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">paraphrase_prefix</code>:T5型号输入的前缀。</li><li id="4dd0" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">n_paraphrase_predictions</code>:扩增数，T5型号应该回归。默认值设置为<code class="fe nd ne nf mv b">5</code>。</li><li id="60df" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">paraphrase_top_k</code>:T5模型应该生成的预测总数。默认值设置为<code class="fe nd ne nf mv b">120</code>。</li><li id="dbed" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">paraphrase_max_length</code>:输入模型的句子的最大长度。默认值设置为<code class="fe nd ne nf mv b">256</code>。</li><li id="ce68" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">n_mask_predictions</code>:伯特遮罩填充模型应生成的预测数。默认值设置为<code class="fe nd ne nf mv b">None</code>。</li><li id="0965" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">convert_to_active</code>:句子是否要转换成主动语态。默认值设置为<code class="fe nd ne nf mv b">True</code>。</li><li id="5483" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">label_column</code>:包含带标签数据的列的名称。默认值设置为<code class="fe nd ne nf mv b">None</code>。如果数据集在<code class="fe nd ne nf mv b">Python List</code>或<code class="fe nd ne nf mv b">txt</code>文件中，则不需要设置该参数。</li><li id="d9ed" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">data_column</code>:包含数据的列的名称。默认值设置为<code class="fe nd ne nf mv b">None</code>。如果数据集是一个<code class="fe nd ne nf mv b">Python List</code>或<code class="fe nd ne nf mv b">txt</code>文件，也不需要这个参数。</li><li id="3c5c" class="ni nj iq ke b kf nr kj ns kn nt kr nu kv nv kz nn no np nq bi translated"><code class="fe nd ne nf mv b">column_names</code>:如果<code class="fe nd ne nf mv b">csv</code>或<code class="fe nd ne nf mv b">tsv</code>没有列名，必须传递一个Python列表来给列命名。由于该功能也接受<code class="fe nd ne nf mv b">Python List</code>和一个<code class="fe nd ne nf mv b">txt</code>文件，默认值被设置为<code class="fe nd ne nf mv b">None</code>。但是，如果使用<code class="fe nd ne nf mv b">csv</code>或<code class="fe nd ne nf mv b">tsv</code>文件，则必须设置该参数。</li></ul><p id="98d3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">代码需要一些时间来扩充数据。拿起你的咖啡，看精灵表演他的魔术！</p><p id="bfad" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">一旦增强完成，输出将如下所示:</p><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="74e5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">你可以在这里找到整个扩充数据集<a class="ae la" href="https://gist.github.com/hetpandya/ad86da386cc98e8da195baaf319160fa" rel="noopener ugc nofollow" target="_blank">。从300排到43600排！</a></p><h1 id="99e4" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">包扎</h1><p id="30d7" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">目前就这些。图书馆随时欢迎各种建议和想法。</p><p id="c71d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">感谢阅读😃！</p></div></div>    
</body>
</html>