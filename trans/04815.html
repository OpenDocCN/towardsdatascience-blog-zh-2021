<html>
<head>
<title>The power of democracy in Feature Selection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">民主在特征选择中的力量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-power-of-democracy-in-feature-selection-dfb75f970b6e?source=collection_archive---------40-----------------------#2021-04-26">https://towardsdatascience.com/the-power-of-democracy-in-feature-selection-dfb75f970b6e?source=collection_archive---------40-----------------------#2021-04-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="33d5" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="7757" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">使用孔多塞方法来聚集特征选择排名</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/beb925fe70794357c4fb69ddcab12165.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KVcj9xZfEkIIOzw8"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@mikepetrucci?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">迈克·彼得鲁奇</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="14d4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">根据维基百科，<strong class="lh ja">特征选择</strong>，也称为<strong class="lh ja">变量选择</strong>、<strong class="lh ja">属性选择、</strong>或<strong class="lh ja">变量子集选择</strong>，是选择相关<a class="ae le" href="https://en.wikipedia.org/wiki/Feature_(machine_learning)" rel="noopener ugc nofollow" target="_blank">特征</a>(变量、预测器)的子集用于模型构建的过程。</p><p id="e7ad" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">使用特征选择技术有几个原因:</p><ul class=""><li id="475d" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">简化模型，使其更容易被研究人员/用户解释。</li><li id="a92e" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">更短的训练时间，</li><li id="6276" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">为了避免<a class="ae le" href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" rel="noopener ugc nofollow" target="_blank">维数灾难</a>，</li><li id="031b" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">通过减少<a class="ae le" href="https://en.wikipedia.org/wiki/Overfitting" rel="noopener ugc nofollow" target="_blank">过拟合</a> g来增强通用性</li></ul><p id="c344" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们研究了先例<a class="ae le" rel="noopener" target="_blank" href="/towards-building-a-unified-framework-for-feature-selection-with-ranking-functions-5605ef665f26">故事</a>中的一类特征选择方法:排序方法。</p><p id="916d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">分级方法是根据质量度量对数据集的要素进行分级并选择第一个要素的方法。</p><p id="3506" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">它们是五种度量:距离、信息、一致性、依赖性和分类准确性，我们看到，根据我们采取的度量类型，我们可以获得非常不同的排名，这导致各种排名对于一些数据集是有效的，而对于其他数据集则完全无效，因此需要使用许多度量。</p><p id="5013" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">假设我们把每个度量看作一个选择者，把每个属性看作一个候选者。在这种情况下，排名可以被视为偏好的顺序，因此，我们可以应用选举方法来计算汇总排名。</p><p id="001a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这篇文章将首先给出计算社会选择的背景；之后，我们将看到如何用Kemeny方法从多种特征选择方法中汇总排名。最后，我们将评估排名汇总相对于每个排名的性能。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="805b" class="mw mx iq bd my mz na nb nc nd ne nf ng kf nh kg ni ki nj kj nk kl nl km nm nn bi translated">计算社会选择背景</h1><h2 id="af19" class="no mx iq bd my np nq dn nc nr ns dp ng lo nt nu ni ls nv nw nk lw nx ny nm iw bi translated">偏好配置文件</h2><p id="bea9" class="pw-post-body-paragraph lf lg iq lh b li nz ka lk ll oa kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">假设你有n个候选人，m个选举人。每个选举人以这种形式给我们一个对候选人的偏好顺序a ≥ b ≥ … ≥ z，我们称之为“偏好简档”</p><p id="217c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果你想选举一个候选人，你应该使用哪种协议？你想拥有什么财产？就复杂程度而言，代价是什么？</p><h2 id="afff" class="no mx iq bd my np nq dn nc nr ns dp ng lo nt nu ni ls nv nw nk lw nx ny nm iw bi translated">多数图</h2><p id="804f" class="pw-post-body-paragraph lf lg iq lh b li nz ka lk ll oa kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">多数图是其中每个候选者是顶点的图；</p><p id="d8f7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果多数人严格地偏好x而不是y，即，如果偏好x而不是y的选举人数量:k(x)严格地大于偏好y而不是x: k(y)的选举人数量，我们就画出从候选人x到候选人y的有向边。</p><p id="f3d4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们通过加权多数图中的差值k <em class="oe"> (x)-k(y)来加权候选x和候选y之间的每个有向边。</em></p><h2 id="8a66" class="no mx iq bd my np nq dn nc nr ns dp ng lo nt nu ni ls nv nw nk lw nx ny nm iw bi translated">孔多塞奖获得者</h2><p id="bead" class="pw-post-body-paragraph lf lg iq lh b li nz ka lk ll oa kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">孔多塞方法是一种总是选出孔多塞获胜者的选举方法；如果一个候选人在一场势均力敌的投票中击败了所有其他候选人，他就是孔多塞奖得主；例如，两轮选举不是孔多塞方法，让我们举一个例子来说明:</p><p id="fb96" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">假设你有8个选民有这样的偏好</p><ul class=""><li id="a7e8" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">3选举人:a ≥ c ≥ b</li><li id="504f" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">3选举人:b ≥ c ≥ a</li><li id="419c" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">2选举人:c ≥ b ≥ a</li></ul><p id="5da6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">两轮选举是选民为他们喜欢的候选人投一票的选举。只有在没有候选人在第一轮投票中获得简单多数票(超过50%)的情况下，选举才会进入第二轮。</p><p id="5bbb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这个例子中，a和b进入第二轮，b获胜；让我们来看看多数图。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi of"><img src="../Images/b419f55214ad8ca7adb2ecb5e0b64d77.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*qWZml9PkVuefgFFZQSczzw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="8a82" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们可以看到，c在任何一场对决中获胜，但仍然是，他在第一轮就被淘汰；这就是众所周知的孔多塞悖论。</p><h1 id="d0d2" class="mw mx iq bd my mz og nb nc nd oh nf ng kf oi kg ni ki oj kj nk kl ok km nm nn bi translated">孔多塞方法</h1><p id="9a25" class="pw-post-body-paragraph lf lg iq lh b li nz ka lk ll oa kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">孔多塞方法是一种总是选出孔多塞奖获得者(如果有的话)的方法。</p><p id="0d13" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">许多孔多塞方法可能需要不同层次的多数图知识。</p><h2 id="0315" class="no mx iq bd my np nq dn nc nr ns dp ng lo nt nu ni ls nv nw nk lw nx ny nm iw bi translated">博尔达法</h2><p id="ae60" class="pw-post-body-paragraph lf lg iq lh b li nz ka lk ll oa kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">一些方法不需要任何关于多数图的知识，比如Borda计数，它可以在线性时间(O(n*m))内计算</p><blockquote class="ol om on"><p id="623d" class="lf lg oe lh b li lj ka lk ll lm kd ln oo lp lq lr op lt lu lv oq lx ly lz ma ij bi translated">假设我们有n个选举人，为了用<strong class="lh ja"> Borda </strong>计数计算总排名，我们给每个候选人n分，每次他在一个选举人偏好的第一个位置，n-1，每次他在第二个位置，等等。</p></blockquote><p id="e926" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在上面的例子中，“a”将有14分，“b”将有16分，而“c”，孔多塞奖得主，有18分。</p><h2 id="8008" class="no mx iq bd my np nq dn nc nr ns dp ng lo nt nu ni ls nv nw nk lw nx ny nm iw bi translated">科普兰方法</h2><p id="761f" class="pw-post-body-paragraph lf lg iq lh b li nz ka lk ll oa kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">其他一些方法也是基于计数，但需要未加权多数图，我们可以在二次时间O(m*n)内计算，因为我们必须比较每对候选。每次比较都涉及所有的选举人。</p><p id="347d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果我们有未加权多数图，那么转换Copeland排名就很简单了。</p><blockquote class="ol om on"><p id="af24" class="lf lg oe lh b li lj ka lk ll lm kd ln oo lp lq lr op lt lu lv oq lx ly lz ma ij bi translated">为了计算科普兰总数的综合排名，我们给每位候选人2分，如果他以多数票击败另一位候选人，给1分，如果他与他持平。</p></blockquote><p id="da13" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在前面的例子中，“a”得0分，“b”得2分，“c”当然以4分获胜。</p><h2 id="627f" class="no mx iq bd my np nq dn nc nr ns dp ng lo nt nu ni ls nv nw nk lw nx ny nm iw bi translated">斯莱特方法</h2><p id="392d" class="pw-post-body-paragraph lf lg iq lh b li nz ka lk ll oa kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">斯莱特方法也需要未加权多数图，但是用斯莱特方法计算聚合排名是一个<strong class="lh ja"> NP-Hard </strong>问题，更准确地说是一个<a class="ae le" href="https://en.wikipedia.org/wiki/NP-completeness" rel="noopener ugc nofollow" target="_blank">T5】NP-Complete</a>问题。</p><p id="4f5f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这意味着我们无法找到一个在多项式时间内运行的算法来用Slater方法计算聚合排名，除非<a class="ae le" href="https://en.wikipedia.org/wiki/P_versus_NP_problem" rel="noopener ugc nofollow" target="_blank"> P=NP </a>，这是极不可能的。</p><blockquote class="ol om on"><p id="b035" class="lf lg oe lh b li lj ka lk ll lm kd ln oo lp lq lr op lt lu lv oq lx ly lz ma ij bi translated">使用Slater方法的综合排名是最小化<strong class="lh ja">不一致数量的排名；</strong>在排名R中，每当一名候选人以多数击败另一名候选人，但在R中排名在他之后时，我们就计算1次异议。</p></blockquote><p id="ff0b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于上面的例子，c ≥ b≥ a不一致的次数最少；我们很容易找到它，因为多数图是非循环的，所以任何拓扑排序都是最小化不一致数量的排序。</p><blockquote class="ol om on"><p id="ad78" class="lf lg oe lh b li lj ka lk ll lm kd ln oo lp lq lr op lt lu lv oq lx ly lz ma ij bi translated">根据维基百科的定义，<a class="ae le" href="https://en.wikipedia.org/wiki/Directed_graph" rel="noopener ugc nofollow" target="_blank">有向图</a>的<strong class="lh ja">拓扑排序</strong>或<strong class="lh ja">拓扑排序</strong>是其<a class="ae le" href="https://en.wikipedia.org/wiki/Vertex_(graph_theory)" rel="noopener ugc nofollow" target="_blank">顶点</a>的<a class="ae le" href="https://en.wikipedia.org/wiki/Total_order" rel="noopener ugc nofollow" target="_blank">线性排序</a>，使得对于从顶点<em class="iq"> u </em>到顶点<em class="iq"> v </em>的每条有向边<em class="iq"> uv </em>，在排序中<em class="iq"> u </em>在<em class="iq"> v </em>之前。</p></blockquote><p id="cc39" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们假设事实并非如此，假设我们有一个偏好配置文件，给出了下面的图表:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi or"><img src="../Images/f3402845b4e96edfa74602b71f21f732.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*RAWl3IpD5NOUdf_AmW7nTQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="b2ee" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">首先，因为我们有一个循环(A，B，C)，我们将不得不至少反转一个弧，这意味着我们能找到的最佳排名将至少有一个分歧，这取决于哪一个将是三个A，B，C中的最后一个。</p><p id="3d1e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">例如，我们可以颠倒(B，C)和(C，A ),从而得到这个图。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi os"><img src="../Images/7559cae10a26946a1dbdfab3b04db425.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D7l-77o5Fotk1N3i2T-DqQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="9220" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">并且有这个排序A ≥ D ≥ C ≥ B有2个不一致，因为B多数打败C，A多数打败C。</p><p id="f391" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这不是Slater排名，因为我们可以通过不反转(B，C)做得更好，我们将有:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ot"><img src="../Images/9e6a43cb6897f2dfe8aa2708d9ef03dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f7iQWF99R6lB3WfrM3quDw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="5664" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">并由此，推导出这个排序:A ≥ D ≥ B ≥ C有1个不同意，是一个斯莱特的排序(因为我们不能少做)。</p><h2 id="c25c" class="no mx iq bd my np nq dn nc nr ns dp ng lo nt nu ni ls nv nw nk lw nx ny nm iw bi translated">克梅尼方法</h2><p id="516a" class="pw-post-body-paragraph lf lg iq lh b li nz ka lk ll oa kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">这种方法与斯莱特排名非常相似:</p><blockquote class="ol om on"><p id="6612" class="lf lg oe lh b li lj ka lk ll lm kd ln oo lp lq lr op lt lu lv oq lx ly lz ma ij bi translated">使用Kemeny方法的综合排名是最小化<strong class="lh ja">不一致数量的排名；</strong>在排名R中，每当一名候选人被选举人优先考虑，但在R中排名在他之后时，我们计算1次异议。</p></blockquote><p id="bf38" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，Kemeny的排名是一种使称为Kendall Tau距离的距离最小化的排名，因此，直观地说，如果选举人的初始排名彼此接近，则获得汇总排名是容易的。</p><p id="14fb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">谈到复杂性，计算Kemeny的排名也是一个NP-完全问题，这意味着我们无法找到一个算法，它的运行时间是实例大小(n*m)的多项式函数。</p><p id="98c4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">事实上，动态编程方法将采用O(m n2ᵐ)运算(查看<a class="ae le" href="https://fpt.akt.tu-berlin.de/publications/kemeny-jaamas.pdf" rel="noopener ugc nofollow" target="_blank">这篇</a>文章了解更多细节)。</p><p id="d4dd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然而，我们仍然有一个有趣的属性，为我们提供了一个有效的预处理，大大减少了计算时间。</p><p id="1ae2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了引入这一性质，我们必须引入适当候选者的概念。</p><blockquote class="ol om on"><p id="f603" class="lf lg oe lh b li lj ka lk ll lm kd ln oo lp lq lr op lt lu lv oq lx ly lz ma ij bi translated">如果一个候选人对另一个候选人b来说，至少有3/4的选举人认为b比他好，或者至少有3/4的选举人认为b比他差，那么这个候选人就被认为是合适的。</p></blockquote><p id="9e9d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们用一个应用案例来说明这一点。</p><p id="8487" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">假设四个老师在一个科研团队，他们正在寻求实习生，但他们事先不知道他们将被允许带多少实习生；每个老师可以根据学生在课程中获得的分数，为申请实习的学生提供一个优先顺序，因此我们将为每个老师提供一个优先顺序。</p><p id="8410" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们考虑四个候选人和以下简介:</p><ul class=""><li id="559e" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">a ≥ c ≥ b ≥ d</li><li id="4cd2" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">a ≥ c ≥ b≥ d</li><li id="a01a" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">d ≥ b ≥ a ≥ c</li><li id="f417" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">c ≥ a ≥ b≥ d</li></ul><p id="2e11" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">一个合适的候选人的例子是a，因为他在四门课程中的三门中击败了所有其他候选人，所以他将是综合排名中的第一名。因此，无论选择多少实习生，他都会被录取。</p><p id="a063" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">基于这种直觉，<a class="ae le" href="https://link.springer.com/chapter/10.1007/978-3-642-17493-3_5" rel="noopener ugc nofollow" target="_blank">这篇</a>文章指出，我们可以将候选人的数量减少到11δ，其中δ是排名之间的平均距离。</p><p id="8153" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这个过程被称为内核化。</p><p id="06ff" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">内核化是一种预处理分析，它允许我们将问题简化为一个更小的问题，称为内核；这里，核的大小是排名之间的平均距离的多项式函数。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="3aa2" class="mw mx iq bd my mz na nb nc nd ne nf ng kf nh kg ni ki nj kj nk kl nl km nm nn bi translated">方法的实施</h1><h2 id="0dd2" class="no mx iq bd my np nq dn nc nr ns dp ng lo nt nu ni ls nv nw nk lw nx ny nm iw bi translated">全球框架</h2><p id="0d18" class="pw-post-body-paragraph lf lg iq lh b li nz ka lk ll oa kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">在<a class="ae le" rel="noopener" target="_blank" href="/towards-building-a-unified-framework-for-feature-selection-with-ranking-functions-5605ef665f26">的前一篇文章</a>中，我解释了我们如何设计一个可扩展的框架来分组许多特征选择排序方法；现在，这是一个极好的机会来看看我们如何扩展它。</p><p id="8a1c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">其思想是，每种特征选择方法在用评价函数对特征进行排序后选择要保留的特征；现在，我们必须向框架添加一类特征选择方法，这些方法基于来自多个评估函数的许多排名的<strong class="lh ja">聚合</strong>来设置特征。</p><p id="e720" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们还必须记住，我们可以用任何评估函数的子集来聚合它们，并用任何前面的方法来聚合它们。</p><p id="a8e7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">一个快速的模型化给了我们这个图表，我们将使用它作为接下来的地图。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ou"><img src="../Images/d1670da0f258d238d34f87f9483ae319.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aQAO7-74mxQV6uuKuGlRwA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">类图(作者)</p></figure><p id="dcf9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在本教程中，我将解释Kemeny聚合器的实现，但是我们可以用同样的方式快速实现其他的。</p><h2 id="36c3" class="no mx iq bd my np nq dn nc nr ns dp ng lo nt nu ni ls nv nw nk lw nx ny nm iw bi translated">加权多数图</h2><p id="4a12" class="pw-post-body-paragraph lf lg iq lh b li nz ka lk ll oa kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">首先，我们必须实现一个加权多数图生成器；为此，我们将考虑邻接矩阵表示并使用NumPy。</p><pre class="kp kq kr ks gt ov ow ox oy aw oz bi"><span id="0c08" class="no mx iq ow b gy pa pb l pc pd">def build_weighted_majority_graph(self, rankings, n_candidates):<br/>    graph = np.zeros((n_candidates, n_candidates))<br/>    rankings = np.array(rankings)<br/>    candidates = list(np.unique(rankings))<br/>    for i in range(len(candidates)):<br/>        for k in range(i+1,len(candidates)):<br/>            r = 0<br/>            for ranking in rankings:<br/>                p1 = np.where(ranking == candidates[i])[0][0]<br/>                p2 = np.where(ranking == candidates[k])[0][0]<br/>                if (p1 &lt; p2):<br/>                    r += 1<br/>                else:<br/>                    r -= 1<br/>            if(r &gt; 0):<br/>                graph[i,k] = r<br/>            elif(r &lt; 0):<br/>                graph[k,i] = -r<br/>    return graph</span></pre><p id="55e2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">之后，我们必须考虑如何从多数图中获得Kemeny排序。为此，我们将使用线性编程范式。</p><p id="5654" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果你不熟悉这个范例，我建议你看看我在Julia上写的关于它的文章，但是，你会注意到，它非常相似。</p><h2 id="91e8" class="no mx iq bd my np nq dn nc nr ns dp ng lo nt nu ni ls nv nw nk lw nx ny nm iw bi translated">线性规划的Kemeny排序</h2><p id="6f3e" class="pw-post-body-paragraph lf lg iq lh b li nz ka lk ll oa kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">要构建Kemeny排序问题的线性程序，我们必须首先使用变量和一组相关约束来描述解空间。</p><p id="3189" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">排名是候选人的偏好顺序，因此要用一组变量来表示它，我们必须使用m个布尔变量，每对候选人一个。</p><p id="bc06" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果在最终排名中候选人j优于候选人I，则每个变量xᵢⱼ被设置为1。</p><p id="9525" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果一个排名是一个偏好顺序，不是任何偏好顺序都是一个排名。首先，排名是一个<strong class="lh ja">总数</strong>的顺序，这意味着对于任何一对候选人，我们要么选择一个，要么选择另一个。此外，排序是一种优先顺序<strong class="lh ja">传递</strong>的顺序，因为如果我们将x排在y之前，y排在z之前，我们必然将x排在z之前。</p><p id="5979" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这可以用以下约束来表示:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/79ecb1e7855a6b19421aa055c29c7945.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*M0SVqJqE9PbwHDRPRX4OnA.png"/></div></figure><p id="45f3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第一个不等式的意思是:“我们在排名中有<strong class="lh ja"> <em class="oe"> i </em> </strong>在<strong class="lh ja"> <em class="oe"> j </em> </strong>或<em class="oe"> </em> <strong class="lh ja"> <em class="oe"> j </em> </strong>在<strong class="lh ja"> <em class="oe"> i </em> </strong>之后”，而第二个就是违反了如果“我们在<strong class="lh ja"><em class="oe">j</em></strong><strong class="lh ja"><em class="oe">j</em></strong></p><p id="a8c1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，我们必须确定要优化的目标函数。</p><p id="997a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">正如我们之前所说的，我们必须最小化不一致的数量，因此，为了得到排序的不一致的数量，我们建立变量的加权和，其中每个变量xᵢⱼ由弧(I，j)的权重加权。</p><p id="1439" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们可以用下面的代码做到这一点:</p><pre class="kp kq kr ks gt ov ow ox oy aw oz bi"><span id="a7e0" class="no mx iq ow b gy pa pb l pc pd">import numpy as np<br/>import pulp as pl</span><span id="7b4d" class="no mx iq ow b gy pf pb l pc pd">def aggregate_kemeny(graph):<br/>    prob = pl.LpProblem("Kemeny Ranking Problem", pl.LpMinimize)<br/>    nodes = range(graph.shape[0])<br/>    x = pl.LpVariable.dicts("X", (nodes, nodes), cat='Binary')<br/>    e = 0<br/>    for i in range(graph.shape[0]):<br/>        for j in range(graph.shape[0]):<br/>            if (i == j):<br/>                continue<br/>            prob += (x[i][j] + x[j][i] == 1)<br/>            for k in range(graph.shape[0]):<br/>                if(k == j):<br/>                    continue<br/>                prob += (x[i][j] + x[j][k] + x[k][i] &gt;= 1)<br/>            e += graph[i,j] * x[i][j]<br/>    prob += e<br/>    prob.solve()<br/>    rates = np.zeros(graph.shape[0])<br/>    for i in nodes:<br/>        for j in nodes:<br/>            if(i == j):<br/>                continue<br/>            if(pl.value(x[i][j]) == 1):<br/>                rates[j] += 1<br/>    return rates.argsort()[::-1]</span></pre></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="bd72" class="mw mx iq bd my mz na nb nc nd ne nf ng kf nh kg ni ki nj kj nk kl nl km nm nn bi translated">实验结果</h1><p id="4072" class="pw-post-body-paragraph lf lg iq lh b li nz ka lk ll oa kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">在这个实验中，我首先调查了不同特征选择方法的排序之间的差异。</p><p id="2097" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了做到这一点，我绘制了一张肯德尔-陶距离的热图，这些距离是来自不同特征选择度量的排名以及它们与Kemeny方法的聚合。</p><p id="89b9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">肯德尔τ距离是两个等级之间对应性的度量。接近1的值表示强烈同意，接近-1的值表示强烈不同意。</p><p id="309b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">考虑的措施是我在这篇文章中实施的:</p><ul class=""><li id="02e1" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">两个相关性度量(C1、C2)。</li><li id="5955" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">两种分类方法(CL1，CL2)。</li><li id="6dcb" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">通过CHI2测试测量的依赖性。</li><li id="3831" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">互信息。</li></ul><p id="730b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">所使用的数据集是增加了不相关特征的虹膜数据集。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/2364d58500a50555fc37bd41120df933.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*gPbtCoKNOkI8Rk1T4irLqg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="f5f6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">正如我们可以注意到的，度量的集合为我们提供了一个尽可能接近每个等级的等级。</p><p id="492c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我想研究的第二件事是聚合排名的性能。</p><p id="d692" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为此，我使用了随机采样的数据集，并比较了每个度量的最佳特征子集和不同度量的多个聚合所达到的精度。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/9cc987ddbb1ab0f7a92cf26c8dc65d68.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*5OIScBzVo8LteFcb3Nh7SA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="6739" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们可以注意到许多事情:</p><ul class=""><li id="a4af" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">一些特征选择方法对于一些数据集非常有效，而对于其他数据集非常无效，但是聚集总是具有良好的整体性能。</li><li id="12e4" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">第一个聚合向我们展示了，有时将许多度量结合起来会得到一个聚合排名，它比用于聚合的每个度量都更有效。</li><li id="0e79" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">第二个聚合向我们展示了向聚合添加一个弱度量可以提高性能，但情况并非总是如此，如第三个聚合所示。</li></ul></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="fe36" class="mw mx iq bd my mz na nb nc nd ne nf ng kf nh kg ni ki nj kj nk kl nl km nm nn bi translated">结论</h1><p id="0676" class="pw-post-body-paragraph lf lg iq lh b li nz ka lk ll oa kd ln lo ob lq lr ls oc lu lv lw od ly lz ma ij bi translated">使用来自不同特征选择方法的排序的集合是非常有用的，因为它为我们提供了一个通用协议来获得更健壮并且通常更有效的集合器。</p><p id="5a10" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这项研究向我们展示了建立一个集合的组合方面，因为一些措施似乎协同积极和其他没有。此外，一些度量选择对一些分类器有用而对其他分类器无用的特征。</p><p id="1794" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">所以，最后，把分类器想象成一个决策者，他会选择一组特权措施，不是更好吗？可以积极或消极互动的措施。但是我们如何建立这样一个模型并训练它，同时限制对分类器非常昂贵的调用呢？</p><p id="09f4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">敬请关注，了解更多相关信息:)</p></div></div>    
</body>
</html>