<html>
<head>
<title>Advanced K-Means: Controlling Groups Sizes and Selecting Features</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">高级K-Means:控制组大小和选择特征</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/advanced-k-means-controlling-groups-sizes-and-selecting-features-a998df7e6745?source=collection_archive---------3-----------------------#2021-07-28">https://towardsdatascience.com/advanced-k-means-controlling-groups-sizes-and-selecting-features-a998df7e6745?source=collection_archive---------3-----------------------#2021-07-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2f5a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">K-Means的一些有用的调整</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1ca1506814f8a673546907ee1a3d0526.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LfoHQusJlF2_wwwv"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Patrick Schneider 在<a class="ae kv" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="1a43" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当使用K-means时，我们会面临两个问题:</p><ul class=""><li id="b095" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">我们最终得到大小非常不同的<strong class="ky ir">星团</strong>，一些包含数千个观测值，而另一些只有几个</li><li id="9af3" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">我们的数据集有太多的变量，K-Means算法很难找到一个最佳的聚类集</li></ul><h1 id="8ec7" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">受约束的K-Means:控制组大小</h1><p id="6652" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">该算法基于Bradley等人的一篇论文，并由Joshua Levy-Kramer:<a class="ae kv" href="https://github.com/joshlk/k-means-constrained" rel="noopener ugc nofollow" target="_blank">https://github.com/joshlk/k-means-constrained</a>使用优秀的Google OR-Tools库(<a class="ae kv" href="https://developers.google.com/optimization/flow/mincostflow" rel="noopener ugc nofollow" target="_blank">https://developers.google.com/optimization/flow/mincostflow</a>)实现</p><p id="2acd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该算法使用线性规划的思想，特别是<a class="ae kv" href="http://web.mit.edu/15.053/www/AMP-Chapter-08.pdf" rel="noopener ugc nofollow" target="_blank">网络模型</a>。在物流中，网络模型被用于优化道路网络上的货物流动。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/9659f2a03c61a68116c503c49b3fef56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*89w1PX49DIh4ciNUikcDQA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">网络流模型示例(图片由作者提供)，示例取自<a class="ae kv" href="http://web.mit.edu/15.053/www/AMP-Chapter-08.pdf" rel="noopener ugc nofollow" target="_blank">麻省理工学院的AML </a>。</p></figure><p id="93b0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以在上面的简单图形中看到，我们有5个节点，它们之间有有向弧(箭头)。每个结点都有一个需求(负)或供应(正)值，弧线有流量和成本值。例如，arc 2–4的流量为4，成本为2美元。类似地，节点1供应20个单位，节点4需要5个单位。</p><p id="a12a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些问题可以通过使用优化算法来解决，例如<a class="ae kv" href="https://en.wikipedia.org/wiki/Simplex_algorithm" rel="noopener ugc nofollow" target="_blank">单纯形算法</a>。</p><p id="1cc0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在一个非常高的层次上，我们可以用一个网络来表示这个受约束的K-means问题，其中我们希望最小化每个点与其聚类的质心之间的距离之和，并且对聚类大小有一些约束。</p><p id="c724" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以在下图中看到它的样子。每个点x(i)都是一个值等于1的供应节点，并且是一条指向每个单个聚类c的有向弧。这些弧的成本是该点与相应聚类的质心之间的距离。C1、C2等集群。值等于所需最小大小的需求群。最后，我们添加一个人工需求节点，以确保供应的总和等于需求的总和。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/390a048461fc564e714656d37679b20f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IuniFCvWyfhfMFTNKfFuhA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">优化问题被视为一个网络(图片由作者提供)，例子取自<a class="ae kv" href="http://web.mit.edu/15.053/www/AMP-Chapter-08.pdf" rel="noopener ugc nofollow" target="_blank">原始论文</a>。</p></figure><p id="9613" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">更详细的解释可以在<a class="ae kv" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2000-65.pdf" rel="noopener ugc nofollow" target="_blank">的原文中找到。</a></p><h2 id="fccc" class="nf mh iq bd mi ng nh dn mm ni nj dp mq lf nk nl ms lj nm nn mu ln no np mw nq bi translated">Python实现</h2><p id="960a" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">Joshua Levy-Kramer和其他人开发了一个包，可以在<a class="ae kv" href="https://pypi.org/project/k-means-constrained/" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p><p id="5c19" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它可以与pip一起安装</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="10de" class="nf mh iq ns b gy nw nx l ny nz">pip install k-means-constrained</span></pre><p id="2d82" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后很容易地应用于数据集，我们将重用以前文章中的那个，但是我们需要将我们的pandas数据帧转换成一个数组。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="0cbe" class="nf mh iq ns b gy nw nx l ny nz">X=np.array(X).transpose()</span></pre><p id="e252" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们可以用我们想要的集群数量(n_clusters)、集群的最小和最大大小(size_min和size_max)来拟合KMeansConstrained方法</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="0dad" class="nf mh iq ns b gy nw nx l ny nz">from k_means_constrained import KMeansConstrained</span><span id="44ee" class="nf mh iq ns b gy oa nx l ny nz">clf = KMeansConstrained(<br/>     n_clusters=4,<br/>     size_min=8,<br/>     size_max=12,<br/>     random_state=0<br/>)<br/>clf.fit_predict(X)print(clf.cluster_centers_)<br/>print(clf.labels_)</span></pre><p id="2c2b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后我们可以用<em class="ob"> clf.cluster_centers_ </em>访问质心，用<em class="ob"> clf.labels_ </em>访问聚类</p><p id="067d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如我们在下面看到的，我们获得了4个集群，每个集群有8个元素。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/158160286a458c02532cc900878e891a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Q1B6jXlJdzNBOhSS.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">最小大小为8的4个聚类的结果(图片由作者提供)</p></figure><p id="5cf9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个例子中，我们使用了一个具有两个特征的数据集，因此它可以很好地在2D散点图中可视化。在大多数情况下，我们将处理包含大量要素的数据集。下一节将讨论如何在集群环境中处理这些问题。</p><h1 id="0173" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">K-均值的特征选择</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/555ebebcffa38e02561e4907998cf1d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jn4-ngJLn9KTqehK"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@edgr?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">edu·格兰德</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="cb28" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这一节中，我们将看到在处理包含大量变量的数据集时如何选择变量。降维通常有助于找到更好的聚类。</p><p id="c505" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我们处理高维数据集时，我们可能会遇到聚类方法的问题。特征选择对于监督学习是一种众所周知的技术，但是对于非监督学习(如聚类)方法来说却很少。这里我们将开发一个相对简单的贪婪算法来对Kaggle上的<a class="ae kv" href="https://www.kaggle.com/roshansharma/europe-datasets" rel="noopener ugc nofollow" target="_blank">欧洲数据集</a>执行变量选择。</p><p id="9f5d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该算法将具有以下步骤:</p><p id="0fa1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">0.确保变量是数值型的且经过缩放，例如使用StandardScaler()及其fit_transform()方法</p><ol class=""><li id="ad87" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr oe ly lz ma bi translated">选择你要保留的变量的最大值(<em class="ob"> maxvars </em>)，最小和最大的聚类数(<em class="ob"> kmin </em>和<em class="ob"> kmax </em>)，创建一个空列表:<em class="ob"> selected_variables </em>。</li><li id="6b80" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr oe ly lz ma bi translated">从kmin到kmax循环。然后，依次使用每个变量，使用K-Means记录变量和聚类数的每个组合的轮廓值(从kmin到kmax)。</li><li id="6428" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr oe ly lz ma bi translated">选择给出最大轮廓值的变量，将其添加到<em class="ob"> selected_variables </em>中，并将其从测试变量列表中移除。</li><li id="9289" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr oe ly lz ma bi translated">通过使用<em class="ob"> selected_variables </em>列表并依次添加每个剩余变量，重复2和3中的过程，直到达到某个停止标准(在这种情况下是要保留的变量数量，<em class="ob"> maxvars </em>)。</li></ol><p id="4572" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，对于第一步，我们定义和初始化一些变量。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="59af" class="nf mh iq ns b gy nw nx l ny nz">maxvars=3<br/>kmin=2<br/>kmax=8kmeans_kwargs = {"init": "random","n_init": 20,"max_iter": 1000,"random_state": 1984}<br/>cut_off=0.5</span><span id="f545" class="nf mh iq ns b gy oa nx l ny nz"># We define a cols variables containing a list of all features:</span><span id="ad0e" class="nf mh iq ns b gy oa nx l ny nz">cols=list(df.columns)</span><span id="8e25" class="nf mh iq ns b gy oa nx l ny nz">'''We set a list and a dictionary to store the silhouette values<br/>for each number of clusters tested so we can choose the k value<br/>maximising the silhouette score, with its corresponding features'''</span><span id="e05e" class="nf mh iq ns b gy oa nx l ny nz">results_for_each_k=[]<br/>vars_for_each_k={}</span></pre><p id="d539" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后我们创建三个嵌套循环，外部的一个循环遍历集群数量<em class="ob"> k </em>的值。然后我们有一个while循环来检查保留变量的数量是否低于由<em class="ob"> maxvars </em>设置的阈值。<em class="ob"> selected_variables </em>列表将保存保留的特征名称。<em class="ob">结果</em>列表将保存每个变量的轮廓值。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="20d0" class="nf mh iq ns b gy nw nx l ny nz">for k in range(kmin,kmax+1):<br/>    selected_variables=[]<br/>    while(len(selected_variables)&lt;maxvars):<br/>        results=[]    <br/>        selected_variables=[]<br/>    print(k)<br/>    while(len(selected_variables)&lt;maxvars):<br/>        results=[]</span></pre><p id="32a4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">内部循环逐一检查所有特征，将它们添加到已选择的变量中(如果有)，并评估轮廓值。然后选择获得最高值的变量，并将其添加到<em class="ob"> selected_variables </em>列表中。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="4521" class="nf mh iq ns b gy nw nx l ny nz">for col in cols:<br/>    scols=[]<br/>    scols.extend(selected_variables)<br/>    scols.append(col) <br/>    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)<br/>    kmeans.fit(df[scols])<br/>    results.append(silhouette_score(df[scols],   kmeans.predict(s)))</span><span id="6207" class="nf mh iq ns b gy oa nx l ny nz">''' We identify the best variable, add it to our list and remove it <br/>from the list of variables to be tested on the next iteration '''</span><span id="4114" class="nf mh iq ns b gy oa nx l ny nz">selected_var=cols[np.argmax(results)]<br/>selected_variables.append(selected_var)<br/>cols.remove(selected_var)</span></pre><p id="559e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们可以在我们的循环中更新这个特定k值的变量列表和分数。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="bef0" class="nf mh iq ns b gy nw nx l ny nz">results_for_each_k.append(max(results))<br/>vars_for_each_k[k]=selected_variables</span></pre><p id="f513" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，在三个循环运行之后，我们可以确定k和变量的最佳组合，拟合模型并绘制它。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="77c7" class="nf mh iq ns b gy nw nx l ny nz">best_k=np.argmax(results_for_each_k)+kmin<br/>selected_variables=vars_for_each_k[best_k]<br/>kmeans = KMeans(n_clusters=best_k, **kmeans_kwargs)<br/>kmeans.fit(df_[selected_variables])<br/>clusters=kmeans.predict(df[selected_variables])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/2bf050a66e55716519db992d13396185.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*U97CvNK-4GX7QBvq.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">基于人口、财富和犯罪率的2组国家的最终结果(图片由作者提供)</p></figure><p id="5182" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们选择3个集群，我们会得到不同的选择</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/d5fb321cb704b4ce6b2e515ab3c815e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*y5-DVgmKtzcC-WPc.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">对于3个集群，我们有不同的变量选择(图片由作者提供)</p></figure><p id="f5bb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每组国家的一些例子:</p><p id="9582" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">冰岛、瑞士、比利时、德国、卢森堡、荷兰、奥地利和英国</p><p id="c786" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第二组:希腊、西班牙、法国、克罗地亚、意大利、塞浦路斯、拉脱维亚、立陶宛、匈牙利、马耳他、波兰、葡萄牙</p><p id="1de5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第3组:挪威、丹麦、芬兰和瑞典</p><p id="0b06" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是完整的代码，包括3d绘图。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="df45" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们当然可以将变量选择与受约束的K-Means算法相结合，以强制均匀聚类。</p><p id="068d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我希望这个教程是有帮助的，如果你有问题，请随意评论。</p><h2 id="9cba" class="nf mh iq bd mi ng nh dn mm ni nj dp mq lf nk nl ms lj nm nn mu ln no np mw nq bi translated"><strong class="ak">参考文献</strong></h2><p id="9e8c" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">页（page的缩写）S. Bradley，K. P. Bennett和A. Demiriz，<a class="ae kv" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2000-65.pdf" rel="noopener ugc nofollow" target="_blank">约束K均值聚类</a> (2000年)</p><p id="265e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">布拉德利、哈克斯和马格南蒂，<a class="ae kv" href="http://web.mit.edu/15.053/www/AMP.htm" rel="noopener ugc nofollow" target="_blank">应用数学编程</a>，艾迪森-韦斯利(1977)</p></div></div>    
</body>
</html>