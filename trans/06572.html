<html>
<head>
<title>Chefboost — an alternative Python library for tree-based models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">chef boost——基于树的模型的替代Python库</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/chefboost-an-alternative-python-library-for-tree-based-models-f46af028a348?source=collection_archive---------14-----------------------#2021-06-13">https://towardsdatascience.com/chefboost-an-alternative-python-library-for-tree-based-models-f46af028a348?source=collection_archive---------14-----------------------#2021-06-13</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><figure class="iu iv gp gr iw ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi it"><img src="../Images/5919104e0c0bb49057fc16ce5fcde696.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tzAod2DzLo0nAOmakvaulQ.jpeg"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated">照片由<a class="ae ji" href="https://unsplash.com/@johnathanmphoto?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">张克帆·马塞多</a>在<a class="ae ji" href="https://unsplash.com/s/photos/chef?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><div class=""/><div class=""><h2 id="1946" class="pw-subtitle-paragraph ki jk jl bd b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dk translated">与scikit-learn的主要区别概述</h2></div><p id="7bad" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我在我的Twitter feed中随机遇到了<code class="fe lw lx ly lz b">chefboost</code>,鉴于我以前从未听说过它，我决定快速浏览一下并测试一下。在本文中，我将简要介绍这个库，提到它与首选库<code class="fe lw lx ly lz b">scikit-learn</code>的主要区别，并展示一个实践中的<code class="fe lw lx ly lz b">chefboost</code>的快速示例。</p><h1 id="0e4c" class="ma mb jl bd mc md me mf mg mh mi mj mk kr ml ks mm ku mn kv mo kx mp ky mq mr bi translated">chefboost简介</h1><p id="ebe4" class="pw-post-body-paragraph la lb jl lc b ld ms km lf lg mt kp li lj mu ll lm ln mv lp lq lr mw lt lu lv io bi translated">我认为最好的描述是在库的<a class="ae ji" href="https://github.com/serengil/chefboost" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>中提供的:“chefboost是Python的一个轻量级决策树框架，支持分类特性”。</p><p id="1645" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">与<code class="fe lw lx ly lz b">scikit-learn</code>相比，<code class="fe lw lx ly lz b">chefboost</code>有三个突出的特点:</p><ul class=""><li id="c9bb" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated">支持分类特征，这意味着我们不需要使用例如一键编码对它们进行预处理。</li><li id="9d68" class="mx my jl lc b ld ng lg nh lj ni ln nj lr nk lv nc nd ne nf bi translated">使用<code class="fe lw lx ly lz b">chefboost</code>训练的决策树被存储为专用Python文件中的<em class="nl"> if-else </em>语句。通过这种方式，我们可以很容易地看到树做出了什么决定来达到一个给定的预测。</li><li id="1bbc" class="mx my jl lc b ld ng lg nh lj ni ln nj lr nk lv nc nd ne nf bi translated">我们可以选择多种算法中的一种来训练决策树。</li></ul><p id="167d" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">遵循最后一点，<code class="fe lw lx ly lz b">chefboost</code>为分类树(ID3、C4.5和CART)提供了三种算法，为回归树提供了一种算法。老实说，我并不完全确定哪一个是当前在<code class="fe lw lx ly lz b">scikit-learn</code>中实现的，所以我查看了<a class="ae ji" href="https://scikit-learn.org/stable/modules/tree.html#tree-algorithms-id3-c4-5-c5-0-and-cart" rel="noopener ugc nofollow" target="_blank">文档</a>(它也提供了算法的简明摘要)。原来<code class="fe lw lx ly lz b">scikit-learn</code>用的是优化版的CART算法，没有分类特征的支持。</p><p id="c4ef" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">在我们已经介绍的基础上，<code class="fe lw lx ly lz b">chefboost</code>还提供了一些更高级的基于树的方法，比如随机森林、梯度增强和Adaboost。</p><h1 id="2e43" class="ma mb jl bd mc md me mf mg mh mi mj mk kr ml ks mm ku mn kv mo kx mp ky mq mr bi translated">Python中的一个例子</h1><p id="06ac" class="pw-post-body-paragraph la lb jl lc b ld ms km lf lg mt kp li lj mu ll lm ln mv lp lq lr mw lt lu lv io bi translated">和往常一样，我们从导入库开始。</p><figure class="nm nn no np gt ix"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="b162" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">对于这个例子，我们将使用<em class="nl">成人</em>数据集。你可能已经遇到过，但简单来说，目标是预测一个成年人的年收入是高于还是低于5万美元。为此，我们从1994年人口普查数据库中选择了一些数字和分类特征。你可以在这里找到原始数据集<a class="ae ji" href="https://archive.ics.uci.edu/ml/datasets/adult" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="nm nn no np gt ix"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="a4bf" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><code class="fe lw lx ly lz b">chefboost</code>中的一个怪癖是对目标变量的处理——它必须存储在与特征相同的数据帧中，它必须被称为<code class="fe lw lx ly lz b">Decision</code>,并且必须是数据帧的最后一列。很奇怪，但这可能是有原因的。</p><p id="03a7" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我们还将把数据分成训练集和测试集。然而，数据的非标准结构要求<code class="fe lw lx ly lz b">scikit-learn</code>的<code class="fe lw lx ly lz b">train_test_split</code>函数有一点不同的用法。即使数据集不是高度不平衡的，我们也使用了目标列的分层分割。</p><figure class="nm nn no np gt ix"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="953b" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">通常，我们也会将分类特征编码为布尔虚拟对象，但是<code class="fe lw lx ly lz b">chefboost</code>可以直接处理它们。这就是我们开始训练模型的原因。</p><p id="e878" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">为了训练模型，我们使用了<code class="fe lw lx ly lz b">fit</code>函数，并传递dataframe(包含正确格式的数据)和<code class="fe lw lx ly lz b">config</code>字典作为参数。这一次，我们只表明我们想要使用CART算法。</p><p id="b70e" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">假设我们的数据包含分类和数字特征，我们也可以使用C4.5算法，但不能使用ID3，因为它不能处理数字特征。</p><figure class="nm nn no np gt ix"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="dd43" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">培训完成后，我们得到了以下总结。</p><figure class="nm nn no np gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi ns"><img src="../Images/4c8c2c729d461397eba05793bace6bd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g4psT6vKwmAbZJnMc5LLNg.png"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated">作者图片</p></figure><p id="df80" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">很高兴看到这么多现成的指标，但最突出的是培训时间。这一棵树花了10多分钟来训练！可以通过在<code class="fe lw lx ly lz b">config</code>字典中设置<code class="fe lw lx ly lz b">enableParallelism</code>到<code class="fe lw lx ly lz b">True</code>来并行化训练。这样，树的分支被平行地训练。然而，这样做并没有带来实际的训练速度的提高，至少在我的机器上没有。</p><p id="371d" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">另外，与<code class="fe lw lx ly lz b">scikit-learn</code>的另一个区别是<code class="fe lw lx ly lz b">chefboost</code>主要使用函数而不是类。</p><p id="8c89" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">训练模型导致创建一个新文件-&gt; <code class="fe lw lx ly lz b">rules.py</code>。如简介中所述，它以嵌套的<em class="nl"> if-elif-else </em>语句的形式包含了决策树的整个结构。</p><p id="db9a" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">下面你可以看到脚本的一部分，整个脚本有20.5千行长。一方面，使用这样的嵌套结构，决策的逻辑非常清晰。但是另一方面，如果不限制树的最大深度(我认为这对于<code class="fe lw lx ly lz b">chefboost</code>中的决策树是不可能的)，遵循决策路径根本不容易。</p><figure class="nm nn no np gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi nt"><img src="../Images/83b99c63a62cbc08b9637ac841889264.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ols8DFo1C0d3mEHoGC2O1g.png"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated">作者图片</p></figure><p id="9601" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">训练好一个模型后，我们可以将它存储在pickle文件中，或者使用<code class="fe lw lx ly lz b">restoreTree</code>函数直接从<code class="fe lw lx ly lz b">rules.py</code>文件中加载它。</p><p id="6606" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">为了获得预测，我们使用了<code class="fe lw lx ly lz b">predict</code>函数。</p><figure class="nm nn no np gt ix"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="27df" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">您可能已经注意到，我们只向函数传递了一行数据。不幸的是，这是<code class="fe lw lx ly lz b">chefboost</code>做预测的唯一方法。我们可以自然地循环整个数据帧，但这不如<code class="fe lw lx ly lz b">scikit-learn</code>的predict方法方便。</p><p id="9e7d" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我们可以做的是使用<code class="fe lw lx ly lz b">evaluate</code>函数运行评估。</p><figure class="nm nn no np gt ix"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="0397" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我们得到了一个类似于我们从训练中得到的输出。但是我们不会花太多时间来分析树的性能，因为这不是本文的目的。</p><figure class="nm nn no np gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi nu"><img src="../Images/15977f7cff8ef14a2fa3ea47854a00a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oX7ZeDEQeZ4SUTJXoxU8Pw.png"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated">作者图片</p></figure><p id="0c37" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">该库提供的另一个特性是特性重要性分析。我就不赘述它是如何计算的了(你可以在这里找到它们<a class="ae ji" href="https://sefiks.com/2020/04/06/feature-importance-in-decision-trees/" rel="noopener ugc nofollow" target="_blank">)。为了获得重要性，我们需要使用<code class="fe lw lx ly lz b">feature_importance</code>函数并提供<code class="fe lw lx ly lz b">rules.py</code>文件的路径作为参数。</a></p><figure class="nm nn no np gt ix"><div class="bz fp l di"><div class="nq nr l"/></div></figure><figure class="nm nn no np gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi nv"><img src="../Images/4f30e64ddc1243f95dbddcb346c2887d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sjoCNjH3Id5ZHuJ8ax_MUg.png"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated">作者图片</p></figure><p id="cd30" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">结果表明，年龄是预测一个人年收入是否超过5万美元的最重要的特征。</p><p id="2204" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">作为最后一件事，我想比较一下<code class="fe lw lx ly lz b">chefboost</code>和<code class="fe lw lx ly lz b">scikit-learn</code>的速度。自然，后一个库中的决策树需要不同格式的数据，所以我们相应地准备了数据。</p><figure class="nm nn no np gt ix"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="1aa3" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我们使用与之前相同的分割设置，以确保公平的比较。然后，我们使用<code class="fe lw lx ly lz b">%time</code>魔法来看看训练模型需要多长时间。</p><figure class="nm nn no np gt ix"><div class="bz fp l di"><div class="nq nr l"/></div></figure><pre class="nm nn no np gt nw lz nx ny aw nz bi"><span id="7233" class="oa mb jl lz b gy ob oc l od oe">CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns <br/>Wall time: 3.1 µs</span></pre><p id="19ea" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">这是一个相当大的差异…我不确定是什么原因，我打赌会创建树的<em class="nl"> if-else </em>表示。</p><h1 id="02b0" class="ma mb jl bd mc md me mf mg mh mi mj mk kr ml ks mm ku mn kv mo kx mp ky mq mr bi translated">外卖食品</h1><ul class=""><li id="4f5b" class="mx my jl lc b ld ms lg mt lj of ln og lr oh lv nc nd ne nf bi translated"><code class="fe lw lx ly lz b">chefboost</code>是用于训练基于树的模型的备选库，</li><li id="b41d" class="mx my jl lc b ld ng lg nh lj ni ln nj lr nk lv nc nd ne nf bi translated">突出的主要特性是对分类特性的支持和以嵌套<em class="nl"> if-else </em>语句形式的模型输出，</li><li id="048d" class="mx my jl lc b ld ng lg nh lj ni ln nj lr nk lv nc nd ne nf bi translated">与<code class="fe lw lx ly lz b">scikit-learn</code>相比，训练要慢得多，并且要调整的超参数的选择非常有限。</li></ul><p id="b291" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">你可以在我的<a class="ae ji" href="https://github.com/erykml/medium_articles/blob/master/Machine%20Learning/chefboost.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到本文使用的代码。此外，欢迎任何建设性的反馈。你可以在推特或评论中联系我。</p><p id="0b42" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">如果您喜欢这篇文章，您可能还会对以下内容感兴趣:</p><div class="iu iv gp gr iw oi"><a rel="noopener follow" target="_blank" href="/explaining-feature-importance-by-example-of-a-random-forest-d9166011959e"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd jm gy z fp on fr fs oo fu fw jk bi translated">以随机森林为例解释特征的重要性</h2><div class="op l"><h3 class="bd b gy z fp on fr fs oo fu fw dk translated">了解Python中最流行的确定要素重要性的方法</h3></div><div class="oq l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">towardsdatascience.com</p></div></div><div class="or l"><div class="os l ot ou ov or ow jc oi"/></div></div></a></div><div class="iu iv gp gr iw oi"><a rel="noopener follow" target="_blank" href="/beautiful-decision-tree-visualizations-with-dtreeviz-af1a66c1c180"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd jm gy z fp on fr fs oo fu fw jk bi translated">用dtreeviz实现漂亮的决策树可视化</h2><div class="op l"><h3 class="bd b gy z fp on fr fs oo fu fw dk translated">改进绘制决策树的旧方法，永不回头！</h3></div><div class="oq l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">towardsdatascience.com</p></div></div><div class="or l"><div class="ox l ot ou ov or ow jc oi"/></div></div></a></div><div class="iu iv gp gr iw oi"><a rel="noopener follow" target="_blank" href="/linkedins-response-to-prophet-silverkite-and-greykite-4fd0131f64cb"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd jm gy z fp on fr fs oo fu fw jk bi translated">LinkedIn对Prophet-silver kite和Greykite的回应</h2><div class="op l"><h3 class="bd b gy z fp on fr fs oo fu fw dk translated">时间序列预测新算法综述</h3></div><div class="oq l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">towardsdatascience.com</p></div></div><div class="or l"><div class="oy l ot ou ov or ow jc oi"/></div></div></a></div></div></div>    
</body>
</html>