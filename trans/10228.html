<html>
<head>
<title>Can Bayesian Statistics Give Predictions of the Same Quality as ML?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯统计能给出和ML一样质量的预测吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/can-bayesian-statistics-give-predictions-of-the-same-quality-as-ml-bc0f9c886819?source=collection_archive---------14-----------------------#2021-09-28">https://towardsdatascience.com/can-bayesian-statistics-give-predictions-of-the-same-quality-as-ml-bc0f9c886819?source=collection_archive---------14-----------------------#2021-09-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a201" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在某些情况下是的。这就是方法。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/fd252edd97374817479bb139d5f79b47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sCr1u6jJiE4o3cOJzXFy4A.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">巴勃罗·加西亚·萨尔达尼亚在<a class="ae kv" href="https://unsplash.com/s/photos/direction?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="58c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最大似然算法是当今解决预测问题的主要方法。这种算法可能易于使用，并且通常提供更准确的预测。另一方面，统计方法提供了关于过程的更多信息，另外，由于算法更加透明，结果对最终用户来说似乎更加可靠。但是精度上的差距是不是太大了？</p><h2 id="4168" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">介绍</h2><p id="a213" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">任务如下:给我们一个数据集，代表400家商店。对于每个商店，都有其3年的收入，以及一组反映内部因素的特征，如商店的外观、可达性等。以及外部因素，如行人流量、该地区的房地产价格等。目标是根据商店的特征预测商店的日收入。</p><p id="7318" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在一次头脑风暴会议期间，我们的团队决定开发两种方法:基于ML树的方法和使用贝叶斯统计并比较结果的方法。</p><p id="b3d2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">统计方法包括3个步骤:</p><ol class=""><li id="8928" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">线性回归并通过将收入除以相关特征来构成新的目标。</li><li id="20ba" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">从与新目标不相关的特征中，我们根据它们提供的信息增益挑选出最有用的特征。</li><li id="fa64" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">基于所选特征的值，用贝叶斯分析对新目标进行预测。以及使用先前计算的线性回归系数来计算收入预测。</li></ol><p id="c70b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们更深入。</p><h2 id="2279" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">1.线性回归</h2><p id="a532" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">首先，我们需要找出哪些特征与目标相关，从而适合线性回归。不出所料，他们人数很少。基本上，我最后只得到一个——商店的工作时间，但它的相关系数为0.7。</p><p id="0f33" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我认为这里可能会出现一个正反馈循环:不仅商店营业时间越长，产生的收入越多，而且管理层也倾向于减少不太成功的商店的工作时间，以削减开支。所以工作时间短可能说明店铺业绩不好。</p><p id="5585" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">无论如何，在计算线性回归系数后，我可以通过将收入除以工作时间来生成一个新的目标。实际上，我最终得到的是商店的每小时收入，这反映了它的核心业绩。这个目标似乎与任何特征都没有很强的相关性，</p><p id="ea7c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在进入下一步之前，我们要做的一切就是从数据集中删除所有相关的要素，只留下独立的要素。</p><h2 id="88d1" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">2.复杂依赖关系，差分熵</h2><p id="ca75" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">现在是最有趣的部分。我们有一组独立的特征，它们既不与目标相关也不彼此相关。</p><p id="2028" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果特征与目标不相关，并不一定意味着它没有给出关于它的信息。让我用下面的例子来说明:</p><p id="0eab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们生成一个数据集:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="ec2e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是它看起来的样子</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/72b14af167b33dd6fd8681a4ae56c9b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/0*s3kOVZUBpohiJsze"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">这个特征告诉我们很多关于目标的信息，但并不与目标相关(图片由作者提供)</p></figure><p id="af89" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里的相关指数是-0.18，这意味着基本上没有依赖性，但很明显，该特征具有很高的信息量。</p><p id="01a7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有一种度量随机变量不确定性的方法叫做熵。对于连续变量，它可以计算为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/a03a64552a080d2446841f33ffa8be2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*6fE0HRYr61QUqnhN65rFdg.png"/></div></figure><p id="eaf2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中ρ(x) —概率密度函数</p><p id="edf1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了挑选最有信息的特征，我们可以简单地根据它们提供的信息增益对它们进行分类</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/7d4cd08153c4719fd547db95f967a7c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*baNMsV_i0fLsQhoUQ2rp7w.png"/></div></figure><p id="1de9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中<br/>y-要素<br/>nᵢ-数据集中具有要素Y = yᵢ值的条目数</p><p id="eb0b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">基本上，信息增益是数据集的初始熵和由特征值选取的子集的熵的加权平均值之间的差。</p><p id="75a2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这一点上，可能不清楚为什么不使用标准差？事实上，在上面的图片中，每个子集的标准偏差比整个数据集的标准偏差小5倍，这也同样有效。</p><p id="e413" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是让我们考虑下面的例子:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/5e7401b34cd12e27ff283c66865c0ac1.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/0*5vuuB8Ouq1-TEOzQ"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">信息越丰富的要素标准偏差越大(图片由作者提供)</p></figure><p id="17b4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上图中你可以看到两个分布，一个是宽高斯分布，另一个是两个窄峰。第一个分布的标准差是0.5，而另一个分布的标准差是3。但是让我们计算熵，我们得到1.04和-0.27(是的，熵可以是负的)。第二个分布提供了更多关于变量的信息，尽管有更大的标准差。</p><h2 id="62bf" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">3.贝叶斯分析介绍，部分分布→可能性</h2><p id="e484" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">现在让我们试着做一些预测。首先，快速提醒一下贝叶斯推理是如何工作的。主要的想法是你用基于你的观察的可能性因子来更新你先前的信念。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/b8c36993e3d9b8c6376fd7a191f68577.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*-ZPaENhmjj6eh2udAAj3YA.png"/></div></figure><p id="72b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可能性是假设你先前的信念，观察给定证据的概率。现在，用概率分布来改写它:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/929f67e0c87496a0ca5fa48f6a5f9624.png" data-original-src="https://miro.medium.com/v2/resize:fit:368/format:webp/1*GA7VDej2tdaUjUZSdSfjDA.png"/></div></figure><p id="9b55" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">α—归一化常数</p><p id="7a6a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了获得观察到具有特定收入的商店的特定特征的概率，我们需要计算在显示该收入的所有商店中拥有该特征的商店的分数。</p><p id="0024" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了让这个技巧发挥作用，我们需要把一个连续的特征变成一个分类的特征。我用pd.qcut()把所有的连续特征分类成8个八分位数。常规线性宁滨似乎不适用于此目的，因为大多数要素的分布并不均匀。这意味着，虽然2-3个箱将包含几乎所有的商店，但其他箱将包含很少的商店，并且很难评估此类箱的部分收入分布。</p><p id="cfc0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为先验分布，使用数据集中收入的总体分布是合理的。</p><p id="8ed9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们要做的就是用所有特征的似然因子更新先验分布，并计算结果的平均值。当然，在计算部分分布之前，有必要将商店本身从数据集中排除。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/2d9393644917888cc7646ad8669d630c.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/0*BlvW7D46LdU2ORzi"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">贝叶斯推理后得到的收益分布(图片由作者提供)</p></figure><p id="7f42" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了获得对初始目标的预测，我们需要将从步骤1中获得的预测乘以车间的工作时间。</p><h2 id="11d8" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">预测和结果分析</h2><p id="674b" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在下图中，你可以看到预测与事实的散点图。为保密起见，预测和实际收入均以常规单位表示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/e46a0798318d926bdfff7549d45c6689.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/0*wr5pjvtFbCDua9jk"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="39f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">实现了以下性能指标:</p><p id="fc9e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">MAPE — 23.1 <br/> MdAPE — 20.0</p><p id="84da" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">出现错误的店铺数量:<br/>错误&lt; 10% — 14 <br/>错误&lt; 20% — 29 <br/>错误&lt; 30% — 43 <br/>错误&gt; 50% — 5</p><p id="3e86" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">同时，基于树的ML模型已经在具有以下性能指标的相同数据集上被训练:</p><p id="1775" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">MAPE — 22.5 <br/> MdAPE — 19.2</p><p id="5601" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">误差店铺数:<br/>误差&lt; 10% — 17 <br/>误差&lt; 20% — 30 <br/>误差&lt; 30% — 43 <br/>误差&gt; 50% — 5</p><p id="7561" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从误差分布可以看出，ML在小误差领域表现更好。ML模型预测了17家商店的收入，误差小于10%，而Bayesian只对14家商店达到了这一分数。不管怎么说，ML只比MAPE好0.6，比MdAPE好0.8。</p><p id="facb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总的来说，ML模型提供了更好的准确性。但是该实验表明，对于0.6 MAPE的价格，人们可以获得概率分布以及获得该结果的更透明的算法，这在某些情况下对于最终用户是至关重要的。</p><p id="c196" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢阅读！</p><div class="nn no gp gr np nq"><a href="https://vityazevdanil.medium.com/" rel="noopener follow" target="_blank"><div class="nr ab fo"><div class="ns ab nt cl cj nu"><h2 class="bd ir gy z fp nv fr fs nw fu fw ip bi translated">丹尼尔·维蒂亚泽夫培养基</h2><div class="nx l"><h3 class="bd b gy z fp nv fr fs nw fu fw dk translated">数据和业务分析师。我制作业务流程的数学模型，并帮助人们做出决策。</h3></div><div class="ny l"><p class="bd b dl z fp nv fr fs nw fu fw dk translated">vityazevdanil.medium.com</p></div></div><div class="nz l"><div class="oa l ob oc od nz oe kp nq"/></div></div></a></div></div></div>    
</body>
</html>