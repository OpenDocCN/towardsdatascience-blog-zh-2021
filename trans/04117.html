<html>
<head>
<title>Extract Keywords from Audio files with Natural Language processing(NLP)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用自然语言处理(NLP)从音频文件中提取关键词</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-extract-keywords-from-audio-files-with-natural-language-processing-nlp-3084ceb951c9?source=collection_archive---------13-----------------------#2021-04-07">https://towardsdatascience.com/how-to-extract-keywords-from-audio-files-with-natural-language-processing-nlp-3084ceb951c9?source=collection_archive---------13-----------------------#2021-04-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a595" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">HuggingFace Transformers将语音转换为文本，Spacy提取关键字</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/71026cd268e32b4f95baefa9928e214a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jhs4DgRHYWE0gfwXFdMS8g.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@olegixanovpht?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">奥列格·伊万诺夫</a>在<a class="ae kv" href="https://unsplash.com/s/photos/singing?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="6b25" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最新版本的HuggingFace transformers引入了一个模型Wav2Vec 2.0，该模型有可能解决与音频相关的自然语言处理(NLP)任务。而现在，你可以解决的任务之一就是如何从音频中提取关键词。</p><p id="963f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Wav2Vec 2.0模型是由脸书人工智能团队发布的自动语音识别模型。当该模型在10分钟的转录语音和53k小时的未标记语音上训练时，它在有噪语音上的单词错误率(WER)为8.6%，在干净语音上为5.2%。Wav2Vec 2.0的性能在标准LibriSpeech基准上进行检验。</p><p id="d5e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">点击  <strong class="ky ir">了解更多关于<a class="ae kv" href="https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/" rel="noopener ugc nofollow" target="_blank">wav2 vec 2.0的信息。</a></strong></p><p id="9cb2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以解决的其他NLP任务有自动摘要、翻译、命名实体识别、关系提取、情感分析、语音识别、主题分割等。</p><p id="1255" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文中，我们将解决的NLP任务是从音频中提取文本，然后提取文本的关键字。</p><p id="88d0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们将这些任务分成3部分。</p><p id="6216" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">1.音频预处理</p><p id="219b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2.从音频预测文本</p><p id="0f99" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">3.从文本中提取关键词</p><h1 id="56ed" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">第一步:音频预处理</h1><p id="3b54" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">最常用的音频格式是mp3、mp4和m4a。但是，Wav2Vec 2.0模型是在Wav格式音频上训练的。因此，它接受wav格式作为输入。我使用Pydub库来转换不是wav格式的格式。</p><p id="0be3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">按照下面的代码将音频文件转换成Wav格式。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="35d6" class="mu lt iq mq b gy mv mw l mx my">from pydub import AudioSegment</span><span id="ce16" class="mu lt iq mq b gy mz mw l mx my">m4a_audio = AudioSegment.from_file(r”dnc-2004-speech.mp3", format=”mp3")</span><span id="8630" class="mu lt iq mq b gy mz mw l mx my">m4a_audio.export(“dnc-2004-speech_converted.wav”, format=”wav”)</span></pre><p id="122d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我的笔记本电脑一次只能处理3-4分钟的音频。任何超过3-4分钟的音频在处理时都会引发内存不足的错误。</p><p id="1836" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我引用了美国前总统奥巴马先生的讲话。音频长度为12分钟。所以，我把12分钟的音频分成4部分来避免这个错误，每个音频有3分钟的长度。之后，我使用该模型从每个音频元素中提取文本。最后，我将所有音频的文本合并成一个段落。</p><p id="0608" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">按照下面的代码将大的音频文件分解成较小的文件。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="4743" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">至此，音频预处理部分完成。我们现在将这些文件输入到模型中来预测文本。</p><p id="725d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那么，让我们执行第二步。</p><h1 id="8fa0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">第二步:从音频预测文本</h1><p id="31ec" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在这一步中，您将使用Wav2vec 2.0模型从音频中获取文本。您可以通过循环播放我们之前转换成较小音频文件的音频文件来实现这一点。</p><p id="16ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在每个循环中，从音频中预测文本，并将其存储到collection_of_text变量中。最后，添加collection_of_text变量中的所有文本，并将其存储在final_complete_speech变量中。</p><p id="077e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可以使用transformers库导入预先训练好的模型facebook/wav2vec2-base-960h。这个模型在960小时的Librispeech语音音频上进行了微调。其他型号也可以进行微调或不进行微调，或者提供不同的培训时间。</p><p id="dd31" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">访问<a class="ae kv" href="https://github.com/pytorch/fairseq/tree/master/examples/wav2vec#wav2vec-20" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">这里下载</strong> </a>其他型号。</p><p id="142b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，这些模型是在16Khz频率音频上训练的。因此，输入音频也应该具有16 Khz的频率。</p><p id="9a55" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">按照这段代码完成第二步。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="bf32" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这样，第二部分就完成了。在最后一部分，你可以从final_complete_speech变量中提取关键字。</p><h1 id="1ae0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">第三步:从文本中提取关键词</h1><p id="ba0f" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">您可以使用各种python库来完成这一步。但是最常用的python库是Spacy、Rake、Bert和Yake。我更喜欢spacy的关键字提取，因为它非常简单易用。使用Spacy，您只需4行代码就可以完成第三步。</p><p id="2036" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">还有，你可以参考<a class="ae kv" rel="noopener" target="_blank" href="/keyword-extraction-process-in-python-with-natural-language-processing-nlp-d769a9069d5c?source=friends_link&amp;sk=63f531986bf4be7be7ff7a2225c1c061"> <strong class="ky ir">这篇文章</strong> </a>来使用其他的关键词提取方法。</p><p id="4dbe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">按照这段代码从文本中提取关键字。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="8f80" class="mu lt iq mq b gy mv mw l mx my"># use this code to install Spacy, Scispacy and en_core_sci_scibert model<br/># pip install -U pip setuptools wheel<br/># pip install -U spacy<br/># pip install scispacy<br/># pip install <a class="ae kv" href="https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_core_sci_scibert-0.4.0.tar.gz" rel="noopener ugc nofollow" target="_blank">https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_core_sci_scibert-0.4.0.tar.gz</a></span><span id="cc41" class="mu lt iq mq b gy mz mw l mx my">import spacy<br/>nlp = spacy.load(“en_core_sci_scibert”)<br/>doc = nlp(final_complete_speech.lower())<br/>print(doc.ents)</span></pre><h1 id="39cb" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="4093" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">随着变形金刚库的完善，NLP领域也在不断发展。Wav2Vec 2.0模型是脸书人工智能团队和HuggingFace团队的重大成功之一。现在，你可以用很低的WER成功地从音频中提取抄本。</p><p id="1349" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可以解决自动文摘、翻译、命名实体识别、关系抽取、情感分析、语音识别、话题分割等。，与音频相关的NLP任务。</p><p id="d1fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">希望这篇文章能帮助你解决与音频相关的关键词提取任务。</p></div></div>    
</body>
</html>