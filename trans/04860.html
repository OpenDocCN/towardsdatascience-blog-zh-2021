<html>
<head>
<title>How to Build Better Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何建立更好的机器学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-better-machine-learning-models-537a4486d056?source=collection_archive---------30-----------------------#2021-04-27">https://towardsdatascience.com/how-to-build-better-machine-learning-models-537a4486d056?source=collection_archive---------30-----------------------#2021-04-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="45e1" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">开发良好深度神经网络的提示、技巧和指南</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/caf4d61526800b467196c31d2868af0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*W5E_OWL3AGy-5QVE"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">伊万·阿列克西奇在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="adbc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">开发者们好👋。如果你以前建立过深度神经网络，你可能知道这需要大量的实验。</p><p id="0649" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文中，我将与您分享一些有用的技巧和指南，您可以使用它们来更好地建立更好的深度学习模型。这些技巧会让你更容易发展一个好的人际网络。</p><p id="042c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以选择使用哪些技巧，因为有些对你正在做的项目更有帮助。并不是本文中提到的所有东西都能直接提高模型的性能。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="5fc7" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">超参数tuning🕹️的高级方法</h1><p id="ffcc" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">训练深度神经网络的一个更痛苦的事情是，你必须处理大量的超参数。</p><p id="9a06" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些可能是你的学习率<strong class="ky ir"> α </strong>，折现因子<strong class="ky ir"> ρ </strong>和ε<strong class="ky ir">ε</strong>，如果你使用的是RMSprop优化器(<a class="ae kv" href="https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf" rel="noopener ugc nofollow" target="_blank">辛顿等人</a>)，或者是指数衰减率<strong class="ky ir"> β₁ </strong>和<strong class="ky ir"> β₂ </strong>，如果你使用的是亚当优化器(<a class="ae kv" href="https://arxiv.org/abs/1412.6980" rel="noopener ugc nofollow" target="_blank">金玛等人</a>)。</p><p id="d7f4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您还需要选择网络中的层数或层的隐藏单元数。您可能正在使用学习率调度程序，并且想要配置这些功能以及更多功能😩！我们确实需要更好地组织超参数调整过程的方法。</p><p id="a3b1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我倾向于使用随机搜索算法来组织我的超参数搜索过程。尽管有其他可能更好的算法，但我通常最终还是会使用它。</p><p id="6939" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设在本例中，您想要调整两个超参数，并且您怀疑这两个参数的最佳值都在1到5之间。</p><p id="d56f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里的想法是，与其选择25个值像(1，1) (1，2)等系统地尝试，随机选择25个点会更有效。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/f542ad71d235eebfcf71a3b3149514cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TPDNGfzc-jP0ZeIF"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">基于<a class="ae kv" href="https://www.andrewng.org/" rel="noopener ugc nofollow" target="_blank">吴恩达</a>的课堂笔记</p></figure><p id="bb87" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是一个关于TensorFlow的简单示例，我尝试在时尚MNIST数据集上使用随机搜索来获得学习率和第一密集层中的单元数量:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mx my l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">张量流随机搜索</p></figure><p id="815d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，我怀疑第一密集层中单元的最佳数量将在32和512之间，并且我的学习率将是1e-2、1e-3或1e-4之一。</p><p id="d550" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，如本例所示，我将单位数的最小值设为32，最大值设为512，步长为32。然后，我指定了一个可以尝试的范围，而不是硬编码一个单位数的值。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="6f61" class="ne ma iq na b gy nf ng l nh ni">hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)<br/>model.add(tf.keras.layers.Dense(units = hp_units, activation = 'relu'))</span></pre><p id="cfc3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们对我们的学习率做同样的事情，但是我们的学习率只是1e-2、1e-3或1e-4中的一个，而不是一个范围。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="fd87" class="ne ma iq na b gy nf ng l nh ni">hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4])<br/>optimizer = tf.keras.optimizers.Adam(learning_rate = hp_learning_rate)</span></pre><p id="9dde" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们执行随机搜索，并指定在我们构建的所有模型中，具有最高验证准确性的模型将被称为最佳模型。或者简单地说，获得良好的验证准确性是目标。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="f01c" class="ne ma iq na b gy nf ng l nh ni">tuner = kt.RandomSearch(model_builder,<br/>                        objective = 'val_accuracy', <br/>                        max_trials = 10,<br/>                        directory = 'random_search_starter',<br/>                        project_name = 'intro_to_kt') <br/>                     <br/>tuner.search(img_train, label_train, epochs = 10, validation_data = (img_test, label_test))</span></pre><p id="38fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这样做之后，我还想检索最佳模型和最佳超参数选择。尽管我想指出使用<code class="fe nj nk nl na b">get_best_models</code>通常被认为是一种捷径。</p><p id="5538" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了获得最佳性能，您应该使用在整个数据集上获得的最佳超参数来重新训练您的模型。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="1d94" class="ne ma iq na b gy nf ng l nh ni"># Which was the best model?<br/>best_model = tuner.get_best_models(1)[0]</span><span id="7e04" class="ne ma iq na b gy nm ng l nh ni"># What were the best hyperparameters?<br/>best_hyperparameters = tuner.get_best_hyperparameters(1)[0]</span></pre><p id="2159" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我不会在这篇文章中详细讨论这些代码，但是如果你愿意，你可以在<a class="ae kv" rel="noopener" target="_blank" href="/the-art-of-hyperparameter-tuning-in-deep-neural-nets-by-example-685cb5429a38">这篇文章</a>中读到。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="581e" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">对大型网络使用混合精度训练🎨</h1><p id="7769" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">你的神经网络越大，你的结果就越准确(一般来说)。随着模型规模的增长，用于训练这些模型的内存和计算需求也会增加。</p><p id="a0d8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用混合精度训练的想法(NVIDIA，<a class="ae kv" href="https://arxiv.org/abs/1710.03740" rel="noopener ugc nofollow" target="_blank"> Micikevicius等人</a>)是使用半精度浮点数来训练深度神经网络，这让您可以更快地训练大型神经网络，而不会降低或可以忽略网络的性能。</p><p id="ee84" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，我想指出的是，这种技术应该只用于参数超过1亿左右的大型模型。</p><p id="627d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然混合精度可以在大多数硬件上运行，但它只会提高最近的NVIDIA GPUs(例如特斯拉V100和特斯拉T4)和云TPU上的模型的速度。</p><p id="c5af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我想让您了解一下使用混合精度时的性能提升。当我在我的GCP笔记本实例(由Tesla V100组成)上训练ResNet模型时，它在训练时间上几乎好了三倍，在云TPU实例上几乎好了1.5倍，准确性几乎没有差异。测量上述加速的代码取自<a class="ae kv" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank">本例</a>。</p><p id="a586" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了进一步增加你的训练量，你也可以考虑使用更大的批量——因为我们使用的是float16 tensors，你应该不会耗尽内存。</p><p id="5edc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">用TensorFlow实现混合精度也相当容易。使用TensorFlow，您可以轻松使用<a class="ae kv" href="https://www.freecodecamp.org/news/p/d63b23cb-c1f8-4997-87c1-6c5c44ea9e14/tf.keras.mixed_precision" rel="noopener ugc nofollow" target="_blank"> tf.keras.mixed_precision </a>模块，该模块允许您设置数据类型策略(使用float16)并应用损失缩放以防止下溢。</p><p id="2d13" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是一个在网络上使用混合精度训练的简单示例:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="946b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个例子中，我们首先将<code class="fe nj nk nl na b">dtype</code>策略设置为float16，这意味着我们所有的模型层都将自动使用float16。</p><p id="2ee4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这样做之后，我们构建一个模型，但是我们覆盖了最后一个或输出层的数据类型为float32，以防止任何数字问题。理想情况下，你的输出层应该是float32。</p><p id="9675" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意:我已经建立了一个有这么多单位的模型，所以我们可以看到混合精度训练在训练时间上的一些差异，因为它对大型模型很有效。</p><p id="2d39" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您正在寻找使用混合精度训练的更多灵感，这里有一张图片，展示了Google Cloud在TPU上对多个模型进行加速:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/91d58e9e26d869be4f30be5cb032107f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hZ6puLtKcjTtrakE"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">云TPU上的加速</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="3827" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">对backpropagation✔️使用毕业支票</h1><p id="0238" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">在多种情况下，我不得不定制实现一个神经网络。实现反向传播通常是容易出错的方面，也很难调试。</p><p id="d5bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过不正确的反向传播，你的模型可能会学到一些看起来合理的东西，这使得调试更加困难。那么，如果我们能够实现一些东西，让我们能够轻松地调试我们的神经网络，那该有多酷呢？</p><p id="6a2d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我经常在实现反向传播时使用梯度检查来帮助我调试它。这里的想法是使用数值方法来近似梯度。如果它接近反向传播算法计算的梯度，那么您可以更加确信反向传播是正确实现的。</p><p id="b0f6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">到目前为止，你可以用这个表达式得到一个向量，我们称之为<code class="fe nj nk nl na b">dθ[approx]</code>:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/51fe95c0cc62b0f67f30d378deee5e7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/0*IVXY7Ky7jxsjHFY5"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">计算近似梯度(图片由作者提供)</p></figure><p id="de2b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你正在寻找这背后的原因，你可以在我写的这篇文章中找到更多。</p><p id="a0b4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以，现在我们有两个向量<code class="fe nj nk nl na b">dθ[approx]</code>和<code class="fe nj nk nl na b">dθ</code>(通过反向投影计算)。而这些应该是彼此几乎相等的。您可以简单地计算这两个向量之间的欧几里德距离，并使用该参考表来帮助您调试网络:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/518d54b19ba808a822dcf133cdf0a1e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Q2p_SO1yTh2NiEuN"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">参考表格(图片由作者提供)</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="7df9" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">缓存数据集💾</h1><p id="f3d8" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">缓存数据集是一个简单的想法，但我没见过用得多的。这里的想法是检查整个数据集，并将其缓存在文件或内存中(如果它是一个小数据集)。</p><p id="c13f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这将使你不必在每个时期执行一些昂贵的CPU操作，如文件打开和数据读取。</p><p id="96db" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这也意味着你的第一个纪元会花费更多的时间📉因为理想情况下，您会执行所有操作，如在第一个时期打开文件和读取数据，然后缓存它们。但是随后的时期应该快得多，因为您将使用缓存的数据。</p><p id="6227" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这看起来绝对是一个非常容易实现的想法，对吗？这里有一个TensorFlow示例，展示了如何轻松缓存数据集。它还显示了加速🚀实现这个想法。在我的要点中找到下面例子的完整代码。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/a44346345db4324aed34d07d1550eb77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*t_hS-Bcpap2Y5gqF"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">一个简单的数据集缓存和加速的例子</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="f0c4" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">如何解决⭐过度拟合的问题</h1><p id="c685" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">当您使用神经网络时，过度拟合和欠拟合可能是您面临的两个最常见的问题。这一部分讲述了我在处理这些问题时常用的一些方法。</p><p id="4e72" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可能知道这一点，但高偏差会导致您错过要素和标注之间的关系(拟合不足)，而高方差会导致模型捕捉噪声并过度拟合训练数据。</p><p id="78e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我认为解决过度拟合的最有效方法是获取更多的数据——尽管你也可以扩充你的数据。深度神经网络的一个好处是，随着数据越来越多，它们的性能会提高。</p><p id="93d9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但在很多情况下，获取更多数据可能成本太高，或者根本不可能。在这种情况下，让我们谈谈你可以用来解决过度拟合的其他方法。</p><p id="677a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除了获取更多数据或扩充数据，您还可以通过改变网络的架构或对网络的权重进行一些修改来解决过度拟合问题。我们来看看这两种方法。</p><h2 id="e834" class="ne ma iq bd mb nr ns dn mf nt nu dp mj lf nv nw ml lj nx ny mn ln nz oa mp ob bi translated">改变模型架构</h2><p id="efd1" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">改变架构的一个简单方法是使用随机搜索偶然发现一个好的架构。或者您可以尝试从模型中删除节点，从本质上降低模型的容量。</p><p id="dac2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们已经讨论了随机搜索，但是如果你想看修剪的例子，你可以看看<a class="ae kv" href="https://www.tensorflow.org/model_optimization/guide/pruning" rel="noopener ugc nofollow" target="_blank"> TensorFlow模型优化修剪指南</a>。</p><h2 id="baa7" class="ne ma iq bd mb nr ns dn mf nt nu dp mj lf nv nw ml lj nx ny mn ln nz oa mp ob bi translated">修改网络权重</h2><p id="a5ee" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">在这一节中，我们将看到一些我常用的方法，通过修改网络的权重来防止过度拟合。</p><h2 id="fb88" class="ne ma iq bd mb nr ns dn mf nt nu dp mj lf nv nw ml lj nx ny mn ln nz oa mp ob bi translated">权重正则化</h2><p id="632c" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">重复我们所讨论的，“简单的模型比复杂的模型更不容易过度拟合”。我们试图通过强制网络权重取小值来限制网络的复杂性。</p><p id="b3cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为此，我们将在损失函数中添加一项，如果模型的权重较大，则该项会对模型不利。通常使用L₁和L₂正则化，区别在于:</p><ul class=""><li id="4940" class="oc od iq ky b kz la lc ld lf oe lj of ln og lr oh oi oj ok bi translated">L1——增加的惩罚是∝对|权重系数|</li><li id="c45c" class="oc od iq ky b kz ol lc om lf on lj oo ln op lr oh oi oj ok bi translated">L2——增加的惩罚是∝到|权重系数|<strong class="ky ir">|</strong></li></ul><p id="b213" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中|x|代表绝对值。</p><p id="df11" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你注意到L1和L2的区别了吗，平方项？由于这个原因，L1可能会推动权重等于零，而L2会有权重趋于零，但不是零。</p><p id="f651" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你对进一步探索这个问题感兴趣，<a class="ae kv" rel="noopener" target="_blank" href="/solving-overfitting-in-neural-nets-with-regularization-301c31a7735f">这篇文章</a>深入探讨了规范化，可能会有所帮助。</p><p id="c628" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这也是我倾向于使用L2多于L1正则化的确切原因。让我们看一个TensorFlow的例子。</p><p id="302a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，我展示了一些代码来创建一个简单的3个单位和L2正则密集层:</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="608b" class="ne ma iq na b gy nf ng l nh ni">import tensorflow as tf<br/>tf.keras.layers.Dense(3, kernel_regularizer = tf.keras.regularizers.L2(0.1))</span></pre><p id="a960" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了更清楚地说明这是干什么的，正如我们上面讨论的，这将向损失函数添加一项(0.1 ×权重系数值)，作为对非常大的权重的惩罚。此外，在上面的代码中，将L2替换为L1来为您的层实现L1非常简单。</p><h2 id="f5b8" class="ne ma iq bd mb nr ns dn mf nt nu dp mj lf nv nw ml lj nx ny mn ln nz oa mp ob bi translated">辍学者</h2><p id="a9f4" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">当我在构建一个模型并且面临过度拟合时，我做的第一件事就是尝试使用droppets(<a class="ae kv" href="https://jmlr.org/papers/v15/srivastava14a.html" rel="noopener ugc nofollow" target="_blank">Srivastava等人</a>)。这里的想法是在训练过程中随机丢弃或设置为零(忽略)x%的图层输出要素。</p><p id="af25" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们这样做是为了阻止单个节点依赖于其他节点的输出，并防止它们过多地从其他节点进行共同适应。</p><p id="cf46" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用TensorFlow很容易实现辍学，因为他们可以作为层使用。下面是一个例子，我试图建立一个模型来区分辍学的狗和猫的图像，以减少过度拟合:</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="fcc9" class="ne ma iq na b gy nf ng l nh ni">model = tf.keras.models.Sequential([<br/>    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu',input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),<br/>    tf.keras.layers.MaxPooling2D(2,2),<br/>    tf.keras.layers.Dropout(0.2),<br/>    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),<br/>    tf.keras.layers.MaxPooling2D(2,2),<br/>    tf.keras.layers.Dropout(0.2),<br/>    tf.keras.layers.Flatten(),<br/>    tf.keras.layers.Dense(512, activation='relu'),<br/>    tf.keras.layers.Dense(1, activation='sigmoid')<br/>])</span></pre><p id="9f57" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如您在上面的代码中看到的，您可以直接使用<code class="fe nj nk nl na b">tf.keras.layers.dropout</code>来实现dropout，向它传递要忽略的输出特征的一部分(这里是20%的输出特征)。</p><h2 id="ceb7" class="ne ma iq bd mb nr ns dn mf nt nu dp mj lf nv nw ml lj nx ny mn ln nz oa mp ob bi translated">提前停止</h2><p id="4776" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">早期停止是我经常使用的另一种正则化方法。这里的想法是在验证集上的每个时期监控模型的性能，并在满足验证性能的某些指定条件时终止训练(如当丢失时停止训练&lt; 0.5)</p><p id="567e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">It turns out that the basic condition like we talked about above works like a charm if your training error and validation error look something like in this image. In this case, Early Stopping would just stop training when it reaches the red box (for demonstration) and would straight up prevent overfitting.</p><blockquote class="oq or os"><p id="f982" class="kw kx ot ky b kz la jr lb lc ld ju le ou lg lh li ov lk ll lm ow lo lp lq lr ij bi translated"><em class="iq">)它(早期停止)是一种如此简单有效的正则化技术，以至于Geoffrey Hinton称之为“美丽的免费午餐”。</em></p><p id="c604" class="kw kx ot ky b kz la jr lb lc ld ju le ou lg lh li ov lk ll lm ow lo lp lq lr ij bi translated"><em class="iq"> —使用Aurelien Geron的Scikit-Learn和TensorFlow进行机器实践学习</em></p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/14589b4d7e28cf92d986ae9fe610e29b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KEMyzD1GSMPVzltG.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">改编自<a class="ae kv" href="https://link.springer.com/chapter/10.1007/978-3-642-35289-8_5" rel="noopener ugc nofollow" target="_blank">Lutz pre helt</a></p></figure><p id="9e80" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，在某些情况下，您可能无法直接选择识别标准或知道何时停止训练模型。</p><p id="a0b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">就本文的范围而言，我们不会在这里讨论更多的标准，但我建议您查看“<a class="ae kv" href="https://link.springer.com/chapter/10.1007/978-3-642-35289-8_5" rel="noopener ugc nofollow" target="_blank">早期停止—但何时，Lutz pre helt</a>”，我经常使用它来帮助确定标准。</p><p id="91f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看一个使用TensorFlow提前停止操作的示例:</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="ddf3" class="ne ma iq na b gy nf ng l nh ni">import tensorflow as tf</span><span id="ae0c" class="ne ma iq na b gy nm ng l nh ni">callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)<br/>model = tf.keras.models.Sequential([...])<br/>model.compile(...)<br/>model.fit(..., callbacks = [callback])</span></pre><p id="a345" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的例子中，我们创建了一个提前停止的回调，并指定我们想要监控我们的损失值。我们还规定，如果在3个时期内损失值没有明显的改善，就应该停止训练。最后，在训练模型时，我们指定它应该使用这个回调。</p><p id="771a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，为了这个例子的目的，我展示了一个顺序模型——但是这也可以以完全相同的方式与用功能API或子类模型创建的模型一起工作。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="40dc" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">感谢您的阅读！</h1><p id="1f23" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">谢谢你坚持到最后。我希望你能从这篇文章中受益，并将这些技巧应用到你自己的实验中。</p><p id="f6e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我很高兴看到它们是否也能帮助你提高神经网络的性能。如果您对我有任何反馈或建议，请随时通过Twitter 联系我<a class="ae kv" href="https://twitter.com/rishit_dagli" rel="noopener ugc nofollow" target="_blank">。</a></p></div></div>    
</body>
</html>