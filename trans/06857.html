<html>
<head>
<title>Scalable and Reliable Kubernetes Logging</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可扩展且可靠的Kubernetes日志记录</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scalable-and-reliable-kubernetes-logging-d47a27b8b04d?source=collection_archive---------22-----------------------#2021-06-21">https://towardsdatascience.com/scalable-and-reliable-kubernetes-logging-d47a27b8b04d?source=collection_archive---------22-----------------------#2021-06-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="f8e2" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><div class=""><h2 id="04f6" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用可伸缩工具和快速对象存储为大型Kubernetes集群构建可伸缩的可靠日志记录解决方案。</h2></div><p id="9cb9" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为Kubernetes构建一个基本的日志解决方案可能就像运行几个命令一样简单。然而，为了支持大规模的Kubernetes集群，日志解决方案本身需要具有可伸缩性和可靠性。</p><p id="bd95" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在我之前的<a class="ae ln" rel="noopener" target="_blank" href="/kubernetes-monitoring-and-logging-an-apache-spark-example-62e3c8b1224b">博客</a>中，我描述了我的Kubernetes监控和日志记录解决方案的概况。当时，我使用了一个日志记录的基本设置:Fluentd在Kubernetes节点上收集的日志被直接发送到Elasticsearch和Kibana集群进行搜索和可视化，Fluentd和Elasticsearch都在Kubernetes集群上运行。这是一个适用于小型集群的简单设置。一旦我们迁移到大型生产集群，它将面临以下挑战:1) Fluentd可能会丢失日志(数据丢失！)如果Elasticsearch停机或无法跟上对传入日志的索引。2)日志输入和输出紧密耦合，因此难以管理。3)日志仅存储在Elasticsearch中，因此很难扩展到其他工具，例如用于一般日志处理和分析的Apache Spark。</p><p id="822b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在这篇博客中，我将描述我是如何通过使用Fluentd、Kafka、Elasticsearch、Spark和Trino等可扩展工具构建一个可扩展且可靠的Kubernetes日志解决方案来应对这些挑战的。我还将强调像FlashBlade S3这样的快速对象存储在此解决方案中的作用。最终的架构如下图所示。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/4b930242dacaab0776734da412c603b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P7uyNwTzlW9l__kL6YIRZw.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">可伸缩的Kubernetes日志记录</p></figure><h1 id="bade" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">Apache Kafka作为管道缓冲器和代理</h1><p id="60b1" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">我们首先需要解耦日志输入(Fluentd)和输出(Elasticsearch)。这增加了日志管道的灵活性和可伸缩性。阿帕奇卡夫卡是最受欢迎的解决方案。该设置需要运行Kafka集群。请参考<a class="ae ln" href="https://medium.com/swlh/apache-kafka-with-kubernetes-provision-and-performance-81c61d26211c" rel="noopener">我的博客这里</a>关于如何在Kubernetes上建立一个开源的Kafka集群。另一个选择是用<a class="ae ln" href="https://docs.confluent.io/operator/current/overview.html" rel="noopener ugc nofollow" target="_blank">汇合的卡夫卡来代替Kubernetes </a>。融合Kafka的一个很好的特性是它对分层存储的支持，这允许Kafka将冷数据卸载到远程对象存储，如FlashBlade S3。稍后将详细介绍。现在，让我们把重点放在Fluentd和Kafka的整合上。</p><p id="f2b5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">最简单的入门方法是使用来自<a class="ae ln" href="https://github.com/fluent/fluentd-kubernetes-daemonset" rel="noopener ugc nofollow" target="_blank">Fluentd Kubernetes Daemonset repo</a>的Kafka2插件，其中包括预构建的Docker图像和Kubernetes规范示例。Fluentd-Kafka2 Docker镜像使用环境变量支持<a class="ae ln" href="https://github.com/fluent/fluentd-kubernetes-daemonset/blob/master/docker-image/v1.12/debian-kafka2/conf/fluent.conf" rel="noopener ugc nofollow" target="_blank">基本配置</a>。例如，Kafka经纪人和主题可以在Kubernetes规范文件中设置如下:</p><pre class="lp lq lr ls gt nb nc nd ne aw nf bi"><span id="c21d" class="ng mf it nc b gy nh ni l nj nk">containers:<br/>- name: fluentd<br/>  image: fluent/fluentd-kubernetes-daemonset:v1.12-debian-kafka2-1<br/>  env:<br/>    - name:  FLUENT_KAFKA2_BROKERS<br/>      value: "kafka-headless.kafka:29092"<br/>    - name:  FLUENT_KAFKA2_DEFAULT_TOPIC<br/>      value: "k8s-logs"</span></pre><p id="d59e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">因为我需要对Kafka生产者确认、时间戳格式和日志源分离进行更多的控制，所以我使用Kubernetes ConfigMap扩展了配置文件。之后，日志会根据它们的来源被发送到多个Kafka主题中。Fluentd还附加了其他元数据，如摄取时间戳和源标签。当我们用Elasticsearch和Apache Spark处理日志时，这些将会很有帮助。</p><h2 id="172a" class="ng mf it bd mg nl nm dn mk nn no dp mo la np nq mq le nr ns ms li nt nu mu iz bi translated">将日志从Kafka发送到多个输出</h2><p id="00f6" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">为了将日志从Kafka发送到其最终输出，在本例中是Elasticsearch和S3对象存储，我使用了<a class="ae ln" href="https://www.googleadservices.com/pagead/aclk?sa=L&amp;ai=DChcSEwiA1PSfrp7xAhXHIysKHbNxAAUYABAAGgJzZg&amp;ae=2&amp;ohost=www.google.com&amp;cid=CAESQeD2EZ7-HkNPdNAe9ONXD005um2FY0cMrE0POJSTPOqrP4NFcLKHaX9f_HjSQRrNrbs4bcPw_UAMQU_Bz-nGKSvt&amp;sig=AOD64_3YzYgWYFFUxMyDyswEqzEx3X1_dA&amp;q&amp;adurl&amp;ved=2ahUKEwiB9Oqfrp7xAhWjgUsFHQpDCpwQ0Qx6BAgEEAE&amp;dct=1" rel="noopener ugc nofollow" target="_blank">Kafka Connect</a>elastic search sink和S3 sink。Kafka Connect是一个工具，用于在Apache Kafka和其他数据系统之间可扩展和可靠地传输数据。每个连接器都以分布式模式作为自己的Kafka消费群运行，这意味着内置了可伸缩性和可靠性。因为日志的输入和输出被Kafka解耦了，所以扩展系统并不容易。例如，生态系统中有超过100个连接器将数据从Kafka传输到不同的输出。</p><p id="3efd" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">通过将connector pods作为Kubernetes部署来运行，我们可以轻松地扩展日志记录管道，以适应Kubernetes集群的增长。下面是在Kubernetes集群中运行的Fluentd和Kafka Connect的示例。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi nv"><img src="../Images/d8339923c29f837062142009c48b1aab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XuVSpstCZr9dCp5KarVvYQ.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">Fluentd和Kafka连接运行在Kubernetes</p></figure><h2 id="3189" class="ng mf it bd mg nl nm dn mk nn no dp mo la np nq mq le nr ns ms li nt nu mu iz bi translated">融合卡夫卡与S3的分层存储</h2><p id="3611" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">如果使用融合的Kafka，其分层存储功能，尤其是与FlashBlade S3一起，使Kafka在Kubernetes环境中更加可扩展、可靠和易于操作。基本思想是将冷数据从Kafka代理卸载到远程对象存储，这样Kafka只需要在代理中管理最少的本地数据(热数据)。这使得Kafka broker pods非常轻便，因此更易于扩展和操作。特别是，数据重新平衡可以快几倍。这也降低了存储成本，因为Kafka无需在S3维护多个数据副本。</p><p id="5127" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">以下是使用Kubernetes的<a class="ae ln" href="https://docs.confluent.io/operator/current/overview.html" rel="noopener ugc nofollow" target="_blank">汇合</a>操作符为汇合Kafka分层存储设置FlashBlade S3的示例:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi nw"><img src="../Images/f922928b9c69ecb4ee18671dcabe9b85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0JcTxriQL9qxFg6qckxR0g.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">融合式Kafka分层存储，采用FlashBlade S3配置</p></figure><p id="0c8d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">部署后，我们可以确认FlashBlade S3已在融合用户界面上配置为分层存储后端。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi nx"><img src="../Images/dfdfc116ed75b3c7cbe92d31fcb55777.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2bS89lVSDtE0RgfSo19Usg.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">融合式卡夫卡分层存储，带闪光灯S3</p></figure><p id="5f50" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">Kafka客户端仍然通过Kafka访问所有数据。如果一个请求命中冷数据，Kafka将从远程对象存储器下载它，缓存它并提供给客户机。FlashBlade S3是受支持的分层存储目标。与亚马逊S3和其他对象存储不同，FlashBlade S3的设计速度非常快，因此即使数据是远程存储的，提供冷数据的速度也可以接近热数据。</p><h1 id="9c73" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">使用Elasticsearch、Spark和Trino进行日志分析</h1><p id="777c" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">大型Kubernetes集群每小时或更快地生成数百万个日志条目。分析这些日志本身就是一个大数据问题。Elasticsearch、Apache Spark和Trino是一些最流行的日志分析可扩展工具。</p><p id="1864" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我使用Elasticsearch进行流日志分析、搜索和仪表板。使用Kubernetes上的<a class="ae ln" href="https://www.elastic.co/elastic-cloud-kubernetes" rel="noopener ugc nofollow" target="_blank">弹性云</a>，在Kubernetes上部署弹性搜索就像几个命令一样简单。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ny"><img src="../Images/fd3bc00b697586f671b41b0faf4627d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E7uelDmlcGDoJzAHfnX_kg.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">在Elasticsearch中搜索Kubernetes日志</p></figure><h2 id="37df" class="ng mf it bd mg nl nm dn mk nn no dp mo la np nq mq le nr ns ms li nt nu mu iz bi translated">使用S3搜索可搜索的快照</h2><p id="b7e0" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">与融合的Kafka一样，Elasticsearch也支持将冷数据和冻结数据卸载到远程对象存储。最初，S3的快照仅支持备份目的，随着最新的7.13版本，<a class="ae ln" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/searchable-snapshots.html" rel="noopener ugc nofollow" target="_blank">快照变得可搜索</a>！</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi nz"><img src="../Images/c6c9a40a0bfaad2ccae32ad73b752460.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gH-89gN5o0uXxoIIrQGvaQ.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">使用FlashBlade S3搜索可搜索的快照</p></figure><p id="cf74" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">通过在本地保留最少的数据，可搜索的快照使弹性搜索更容易操作和扩展，降低存储成本，同时使用FlashBlade S3提高冷数据和冻结数据的搜索速度。</p><p id="0f12" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">可搜索快照最重要的配置是在Elasticsearch冻结节点中设置共享缓存存储和大小。在下面的示例中，我将100GB闪存阵列支持的持久卷中的90GB设置为缓存。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi oa"><img src="../Images/f87dffbb5e1bc154d4931c88a2403748.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yta0g3IDhNTXFox0VR8tKg.png"/></div></div></figure><p id="60f1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">然后，我们可以创建一个可搜索的快照，并将其存储在FlashBlade S3存储库中。</p><pre class="lp lq lr ls gt nb nc nd ne aw nf bi"><span id="8ed9" class="ng mf it nc b gy nh ni l nj nk">POST /_snapshot/reddot-s3-repo/demo/_mount?storage=shared_cache<br/>{<br/>  "index": "logstash-2021.05.20",<br/>  "renamed_index": "logstash-2021.05.20-mounted"<br/>}</span></pre><p id="f201" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">搜索可搜索的快照索引与搜索任何其他索引相同。如果数据在本地不可用，Elasticsearch将从S3下载索引，在本地缓存并从那里提供服务器以备将来请求。</p><p id="e7a7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">正如您在下面看到的，我已经创建了三个索引:原始的，一个从常规快照完全恢复，另一个从可搜索的快照恢复。可搜索快照的索引使用磁盘上的零字节，表明数据是由S3存储库提供的。</p><pre class="lp lq lr ls gt nb nc nd ne aw nf bi"><span id="d8d8" class="ng mf it nc b gy nh ni l nj nk">GET /_cat/shards/logstash-2021.05.20*/?v&amp;h=index,shard,prirep,state,docs,store,node</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ob"><img src="../Images/008053debf769c229e52a5e815044cd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6rcSTQa815dNp6Yxc1Jyfg.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">使用磁盘上的零字节对可搜索快照进行索引</p></figure><h2 id="c482" class="ng mf it bd mg nl nm dn mk nn no dp mo la np nq mq le nr ns ms li nt nu mu iz bi translated">ETL和SQL分析</h2><p id="b28d" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">虽然Elasticsearch非常擅长流日志分析，但它并不能满足所有的日志分析需求。例如，我们使用Apache Spark和Trino进行ETL和SQL分析。为此，我们首先需要将原始日志存储在S3。如上所述，我们使用Kafka Connect S3接收器将原始json格式的日志发送到S3。我们还按照来源和摄取时间对数据进行分离/分区，以便于处理。日志存储在S3，如下所示。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi oc"><img src="../Images/0cf9949c2b679fba9873baccab378ba3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oSGK7S7wXY5Hds5XfBVO2Q.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">存储在S3 flash blade的Kubernetes日志</p></figure><p id="c031" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">一旦日志被存储在S3桶中，我就可以使用Spark来研究JupyterLab笔记本中的数据。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi od"><img src="../Images/da140d9d1e5d83bd070e882d62bb45da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qN5VjYpfWxxdJt1LWWKWMg.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">在JupyterLab中用Spark记录ETL</p></figure><p id="bae2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我还可以使用Trino直接对json数据运行SQL查询。</p><pre class="lp lq lr ls gt nb nc nd ne aw nf bi"><span id="e4db" class="ng mf it nc b gy nh ni l nj nk">CREATE TABLE IF NOT EXISTS k8s_logs(<br/>    ingest_ts varchar, <br/>    log varchar,<br/>    kubernetes ROW(<br/>      container_image_id varchar,<br/>      container_name varchar,<br/>      ...<br/>    ),<br/>    dt varchar,<br/>    hour varchar<br/>)<br/>WITH (<br/>    format='json',<br/>    partitioned_by = ARRAY['dt', 'hour'],<br/>    external_location='s3a://deephub/logs/k8s-logs'<br/> );</span></pre><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi oe"><img src="../Images/83a16e7470b625415b981fa2985be791.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QHo6POEEBg-YUAJXJjG0fA.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">使用Trino的SQL分析</p></figure><p id="e631" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">因为所有的工具，包括JupyterLab、Spark和Trino，都运行在Kubernetes集群中，所以我可以立即开始这些分析，并轻松扩展。我之前的博客<a class="ae ln" rel="noopener" target="_blank" href="/apache-spark-with-kubernetes-and-fast-s3-access-27e64eb14e0f">这里</a>和<a class="ae ln" href="https://medium.com/swlh/presto-with-kubernetes-and-s3-deployment-4e262849244a" rel="noopener">这里</a>描述了如何与Kubernetes和S3一起运行Spark和Trino(前PrestoSQL)。</p><h1 id="0d3b" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">摘要</h1><p id="38a4" class="pw-post-body-paragraph kr ks it kt b ku mw kd kw kx mx kg kz la my lc ld le mz lg lh li na lk ll lm im bi translated">在这篇博客中，我描述了如何扩展我的日志解决方案来收集、存储和处理Kubernetes集群中生成的大量日志。虽然它是为Kubernetes日志记录而构建的，但该解决方案非常灵活，也适用于其他大数据用例。</p><p id="e120" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了使解决方案具有可伸缩性和可靠性，我们使用的核心工具需要具有可伸缩性和可靠性。云原生趋势(公共云或本地Kubernetes)鼓励Kafka和Elasticsearch等传统大数据系统从本地数据复制转向远程对象存储。正因为如此，像FlashBlade S3这样的快速对象存储在解决方案中起着重要作用。</p><p id="c871" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">扩展日志解决方案变得更加容易。</p></div></div>    
</body>
</html>