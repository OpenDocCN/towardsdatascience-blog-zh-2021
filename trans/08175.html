<html>
<head>
<title>Class Imbalance</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">阶级不平衡</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/class-imbalance-d90f985c681e?source=collection_archive---------19-----------------------#2021-07-27">https://towardsdatascience.com/class-imbalance-d90f985c681e?source=collection_archive---------19-----------------------#2021-07-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9b05" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在这篇文章中，我们讨论了类不平衡的问题以及可能有助于提高模型性能的技术</h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/71876078c335132161ec6b7cec95bac2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TGXsDRw-WeHQ9r2L2z2hxQ.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">(<a class="ae kz" href="https://unsplash.com/photos/v0_MCllHY9M" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h1 id="24d6" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">介绍</h1><p id="9c09" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">当我开始学习机器学习及其各种子领域时，我参加了各种MOOCs，阅读了各种文章、书籍等。我使用了各种免费的数据集并建立了模型，这些模型表现非常好。我当时的心态是，一切都依赖于我们使用的模型，数据只起次要作用。这种心态主要是因为数据是以干净、平衡的形式提供的，只需要很少的预处理。当我在一个研究所加入我的第一个机器学习角色时，这个信念遭受了重大挫折。该研究所专门从事医学研究，我的工作重点是超声图像。可用的数据不像公开可用的数据集那样清晰和结构化。以前我花大部分时间选择模型，现在我花大部分时间清理、构建和整理数据。此外，在公开可用的数据集中，类的分布几乎相似，如果不相似，每个类都有足够的代表性样本。但在现实世界中，尤其是在医疗领域，存在固有的阶级不平衡，因为患有特定疾病/病症的人与健康人相比要少得多。</p><p id="242f" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">当一个分类问题中一个或多个类别的可用示例数量远远少于其他类别时，类别不平衡就是问题所在。<br/>样本数量多的类称为多数类，样本数量少的类称为少数类。在加入这个角色之前，我读到过关于类不平衡的问题，但从来没有机会处理不平衡的数据集，因为大多数在线可用的数据集都非常平衡，所有类都有几乎相同数量的样本。然而，我开始研究的第一批问题中有一个分布非常不均衡。这是一个二元分类问题，我应该检测给定的妇女是足月还是早产。早产是指妇女在怀孕不到37周时分娩，而足月是指妇女在怀孕超过37周时分娩。早产婴儿患有各种健康并发症，因为他们的器官没有正常发育，需要特殊护理才能存活。</p><p id="5535" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">据世卫组织称，每年有1500万婴儿早产，约100万婴儿死于早产引起的并发症。因此，检测早产是非常必要的，以便可以向婴儿提供足够的护理，并且可以挽救他/她的生命。</p><p id="3eb5" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">现有数据极不平衡，只有300名参与者分娩早产，而分娩足月分娩的妇女人数约为3000人。</p><p id="2831" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">这个问题很有挑战性，我开始研究阶级不平衡的话题和减轻它的技术。我发现网上大多数关于阶级不平衡的材料只提到了两种技术，即过采样和欠采样。在深入挖掘和阅读一些研究论文之后，我发现了一些其他不太为人所知的技术，我想在本文中与已知技术一起讨论这些技术。</p><p id="d8b5" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated"><strong class="lu iu">注意</strong>:这篇文章中讨论的技术是从计算机视觉的角度来看的，但是由于核心概念保持不变，因此也可以应用到其他领域。</p><h1 id="b360" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">处理类别不平衡问题的技巧</h1><p id="4ad6" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">处理类别不平衡的技术可以进一步分为两大类:</p><ol class=""><li id="b069" class="mt mu it lu b lv mo ly mp mb mv mf mw mj mx mn my mz na nb bi translated">数据级方法</li><li id="0b34" class="mt mu it lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">分类器级方法</li></ol><h1 id="efd5" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">数据级方法:</h1><p id="7a16" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">数据级方法是指我们在保持算法及其子部分(如损失函数、优化器)不变的同时，对训练集的分布进行更改。数据级方法旨在以某种方式改变数据集，使标准算法发挥作用。</p><p id="8121" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">有两种著名的数据级方法很容易应用于机器学习领域。</p><h2 id="9c3b" class="nh lb it bd lc ni nj dn lg nk nl dp lk mb nm nn lm mf no np lo mj nq nr lq ns bi translated">1.过采样:</h2><p id="10be" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">过采样或者更准确地说，少数类过采样是一种非常简单且广为人知的技术，用于解决类不平衡的问题。在这种技术中，我们试图通过从所有类中采样相同数量的样本，从而从少数类中采样比多数类中更多的样本，来使小批量中所有类的分布相等。实际上，这是通过增加属于少数类的样本的采样概率，从而降低属于多数类的样本的采样概率来实现的。确定所有类别的抽样概率的最简单方法是取每个类别中样本数的倒数。这将增加样本属于少数类的概率，同时将降低样本属于多数类的概率。有些论文还用样本数平方根的倒数来衡量样本。</p><p id="5365" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">过采样的性能取决于原始数据集中代表性样本的数量，因为在过采样中，我们批量增加样本，但唯一样本的数量保持不变。</p><p id="e28e" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated"><strong class="lu iu">py torch中实现少数类过采样的代码</strong></p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nt"><img src="../Images/0705cd225bf6a952438a2226c5c96d1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zVswPUqmo633oNmds6LSgw.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><strong class="bd nu">图1 </strong>:使用Pytorch加权采样器进行过采样的代码</p></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/2ee063e64ae499707086130042194dda.png" data-original-src="https://miro.medium.com/v2/resize:fit:344/format:webp/1*B_jiUVMtLJZU1WlkFMO7vw.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><strong class="bd nu">图2: </strong>使用加权采样器进行过采样后的批量分配</p></figure><h2 id="8dad" class="nh lb it bd lc ni nj dn lg nk nl dp lk mb nm nn lm mf no np lo mj nq nr lq ns bi translated">2.欠采样:</h2><p id="ead9" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">用于解决类不平衡问题的另一种流行技术是欠采样，它与过采样相反。在这种情况下，我们从多数类中随机移除样本，直到所有类都具有相同数量的样本。这种技术有一个明显的缺点，因为它丢弃了可能导致数据集中代表性样本数量减少的数据。为了解决这个缺点，使用了各种方法，这些方法小心地去除冗余样本，从而保持数据集的可变性。</p><p id="718c" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">实现欠采样的一种简单方法是从多数类中随机抽取与少数类中样本数量相等的样本，同时保持少数类的分布不变。<br/>为了在Pytorch中实现欠采样，可以使用Pytorch的WeightedRandomSampler，其中多数类的权重应该减小，以便从多数类和少数类中采样几乎相同数量的样本。</p><p id="68be" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">例如:假设您有一个二元分类任务，其中多数类中的样本数为2000，而少数类中的样本数为1000。为了使用加权采样器进行欠采样，我们可以将属于少数类的所有示例的权重设为1，即每个示例都有100%的机会被采样，而对于属于多数类的示例，我们可以将权重设为0.5(num _ samples _ minority/num _ samples _ majority)，这意味着属于多数类的每个示例都有50/50的机会被采样。</p><p id="add9" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated"><strong class="lu iu">py torch中实现欠采样的代码:</strong></p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nt"><img src="../Images/bb07d7db661d0237d1b55b10ba389e4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LrYfxQKGw08c-LwGMyypAw.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><strong class="bd nu">图3 </strong>:使用Pytorch加权取样器的欠采样代码</p></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/19e82a88be5e284fb32ce4a7e0eee19c.png" data-original-src="https://miro.medium.com/v2/resize:fit:316/format:webp/1*0zhzrOoDB2uHzJm6rYnLgw.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><strong class="bd nu">图4。</strong>使用加权取样器进行欠采样后的批量分配</p></figure><h1 id="891c" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">算法级方法:</h1><p id="eeb4" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">算法级方法是处理类不平衡的一类方法，其目的是保持数据集不变，但改变训练或推理算法。</p><p id="ba10" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">在这篇文章中，我将讨论我在处理不平衡数据集时常用的两种方法。</p><h2 id="28c7" class="nh lb it bd lc ni nj dn lg nk nl dp lk mb nm nn lm mf no np lo mj nq nr lq ns bi translated">1.对成本敏感的学习:</h2><p id="6707" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">在代价敏感学习中，基本思想是根据类的分布给类分配不同的代价。有各种实现成本敏感学习的方式，例如对属于多数类的例子使用比属于少数类的例子更高的学习率，或者使用类加权损失函数，该函数通过考虑类分布来计算损失，从而对来自少数类的例子的误分类比来自多数类的例子更加惩罚分类器。有各种类别的加权损失函数，但最广泛使用的两个是加权交叉熵和焦点损失。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nx"><img src="../Images/f85be09bd11b6843fdbfa2edf98d6f48.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*GZnUd1hlftAq3U7C3zdCsA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><strong class="bd nu">图五。</strong>加权交叉熵损失方程</p></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/272498001f614e05e1f4c15666a1f563.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*RdiwD353oKsAmm3L5YUeuQ.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><strong class="bd nu">图6。</strong>焦损失方程</p></figure><p id="2409" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">WeightedCrossEntropy使用经典的交叉熵损失，并加入了一个权重项，用于给特定类别(在类别不平衡问题中是少数类别)更多的权重。因此，当分类器错误分类属于少数类的例子时，交叉熵损失惩罚更多。</p><p id="cf1d" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">聚焦损失是由FAIR在他们的论文<a class="ae kz" href="https://arxiv.org/abs/1708.02002?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">中首次介绍的，用于密集物体检测的聚焦损失</a>被设计为以这样的方式执行两个任务来解决类别不平衡。<br/>首先，与简单例子相比，它对困难例子的惩罚更多，并有助于算法更好地执行。难的例子是那些模型不自信并且以低概率预测事实真相的例子，而容易的例子是那些模型高度自信并且以高概率预测事实真相的例子。<br/>例如，假设模型以0.8的概率错误地预测了某个类别，为简单起见，保持γ = 2，α = 1，log = log10，代入图6中给出的焦损方程中的值，我们得到<br/>-(1–0.8)log(0.8)= 0.00387。<br/>现在假设，模型以0.2的概率预测某个类别，保持上面我们得到的相同条件，<br/>-(1–0.2)log(0.2)= 0.4473<br/>如您所见，与模型过度自信的示例相比，模型不太自信的示例的焦点损失对模型的惩罚更大。</p><p id="9441" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">在类不平衡的情况下，由于少数类很少，模型很少看到它的例子，与拥有大量样本的多数类相比，模型在预测它时不太有信心(硬例子)，而多数类反过来给模型更多的学习机会，因此模型在预测它时更有信心(简单例子)。</p><p id="8719" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">因此，焦点损失为少数类的实例提供了更大的权重，而为多数类提供了更小的权重，这反过来使得模型更加关注少数类，并提高了整体分类器的性能。</p><p id="e269" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">第二，类似于加权交叉熵，它在损失函数中有一个加权项。适当地设置权重项可以在错误分类少数类而不是多数类时对模型进行更多的惩罚。<br/>焦点损失广泛用于对由于其上述两个属性而遭受类别不平衡问题的任务进行建模。</p><p id="1397" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">通过使用Pytorch中可用的交叉熵损失函数并指定权重项，可以在Pytorch中轻松实现WeightedCrossEntropy，如下图7所示。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nz"><img src="../Images/2b56d67aeddb3999d53bd8f9136e664b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xybpexBbe5iS9q_1icMu4g.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><strong class="bd nu">图7。</strong>py torch中的加权交叉熵损失码</p></figure><p id="5850" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">要实现焦点损失，你可以参考文章从头开始实现，或者许多软件包为你实现，例如<a class="ae kz" href="https://catalyst-team.github.io/catalyst/_modules/catalyst/contrib/nn/criterion/focal.html." rel="noopener ugc nofollow" target="_blank"> Catalyst </a>、<a class="ae kz" href="https://kornia.readthedocs.io/en/latest/losses.html" rel="noopener ugc nofollow" target="_blank"> Kornia </a>等。</p><h2 id="69d8" class="nh lb it bd lc ni nj dn lg nk nl dp lk mb nm nn lm mf no np lo mj nq nr lq ns bi translated">2.一级分类:</h2><p id="b725" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">顾名思义，一种类别分类是通过仅对少数类别的分布建模并将所有其他类别视为分布外/异常类别来处理类别不平衡的技术。使用这种技术，我们的目标是创建一个分类器，它可以检测属于少数类的例子，而不是区分少数类和多数类。这在实践中通过仅在属于少数类的实例上训练模型来完成，并且在测试时间期间使用属于所有类的实例来测试分类器正确识别属于少数类的实例的能力，同时标记属于其他类的实例。</p><p id="cc1c" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">一种类别分类技术以多种方式实现。计算机视觉应用中广泛使用的一种方法是使用自动编码器，我们在属于少数类的例子上训练自动编码器，并使其重新生成输入。现在，在测试时，我们传递属于所有类别的图像，并使用诸如RMSE、MSE等损失函数来测量模型的重建误差。如果图像属于少数类，则重建误差将会很低，因为模型已经熟悉其分布，并且对于属于除少数类之外的类的例子，重建误差将会很高。</p><p id="b2c2" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">现在你可能会想“但是我们怎么知道哪个误差低，哪个误差高呢？我们将使用什么阈值来决定给定图像是属于少数类还是异常？”。<br/>在实践中，我们通过绘制差错率来确定阈值，差错率是通过传递属于所有类别的图像，然后选择能够清楚地区分少数和其他类别的值来获得的。<br/>人们还取通过传递属于少数类的图像而获得的重建误差的均值std。任何重建误差超过平均标准偏差的例子都被归类为异常。</p><p id="5281" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">经常使用使用神经网络和专门的单类分类器的混合方法。该方法包括两个阶段。在第一阶段，图像通过诸如Resnet的特征提取器，并且从模型的最后一层中提取特征。一旦要素被提取出来，它们就会被展平并传递给专门的OCC算法，例如一类SVM或隔离森林。分类器从特征中学习，并使用学习到的知识来分类一个例子是属于训练分布还是异常。</p><p id="22c8" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">Sklearn支持一些单类分类器，如<a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html" rel="noopener ugc nofollow" target="_blank"> OneClassSVM </a>、<a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html" rel="noopener ugc nofollow" target="_blank"> IsolationForest </a>等。应该使用交叉验证来调整这些模型的各种超参数，以获得更好的性能。</p><h1 id="f16c" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">结论:</h1><p id="008b" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">类别不平衡虽然在机器学习及其子领域中普遍存在，但却没有得到应有的重视，而且众所周知的技术是古老的，可能没有帮助。</p><p id="1fb7" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">因此，在这篇文章中，我试图解释一些我用来处理固有的职业不平衡的技巧。<br/>然而，许多技巧在这篇文章中并未涉及，但对缓解班级失衡可能很重要。</p><p id="1ede" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">如果你发现任何你认为有用的东西，并认为可能有助于改善这篇文章，我请求你在这里留言或通过我的<a class="ae kz" href="https://www.linkedin.com/in/divyanshu-mishra-ai/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>、<a class="ae kz" href="https://twitter.com/Perceptron97" rel="noopener ugc nofollow" target="_blank"> Twitter </a>与我联系。<br/>我希望你喜欢这篇文章，并祝你有美好的一天:)</p><h1 id="c8f1" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">激励人心的名言:</h1><blockquote class="oa ob oc"><p id="2eb0" class="ls lt od lu b lv mo ju lx ly mp jx ma oe mq md me of mr mh mi og ms ml mm mn im bi translated">“相信你能，你已经成功了一半”。</p></blockquote></div></div>    
</body>
</html>