<html>
<head>
<title>How to Train StyleGAN2-ADA with Custom Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用自定义数据集训练StyleGAN2-ADA</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-train-stylegan2-ada-with-custom-dataset-dc268ff70544?source=collection_archive---------6-----------------------#2021-06-07">https://towardsdatascience.com/how-to-train-stylegan2-ada-with-custom-dataset-dc268ff70544?source=collection_archive---------6-----------------------#2021-06-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2cfb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何训练人工智能生成任何你想要的图像</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ba05e9c4f27988623ee4e4372339f825.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*-pTAmI0zn6caTy2P941niw.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">生成的自行车插值[图片由作者提供]</p></figure><p id="1c6f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你一直想知道如何训练自己的生成模型吗？第一次发现像这个<a class="ae lu" href="https://thispersondoesnotexist.com/" rel="noopener ugc nofollow" target="_blank">人脸生成网站</a>这样的GAN应用，一直在想怎么在其他东西上训练GAN。幸运的是，作为我研究的一部分，我最近有机会训练一个自行车发电模型。在本文中，我将记录我在如何根据自己的图像训练StyleGAN2-ADA方面的经验。</p><p id="108d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">StyleGAN是NVIDIA最受欢迎的生成模型之一。StlyeGAN的多个版本已经发布，我们将使用最新版本StyleGAN2-ADA。为了避免重复，我不会解释StyleGAN，因为有很多文章已经很好地解释了它。</p><div class="lv lw gp gr lx ly"><a href="https://jonathan-hui.medium.com/gan-stylegan-stylegan2-479bdf256299" rel="noopener follow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">GAN — StyleGAN和StyleGAN2</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">你知道你的风格吗？大部分GAN型号没有。在普通GAN中，我们从潜在因素z生成图像。</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">jonathan-hui.medium.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/generating-anime-characters-with-stylegan2-6f8ae59e237b"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">使用StyleGAN2生成动画角色</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">了解如何生成这个很酷的动画人脸插值</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="mn l mj mk ml mh mm ks ly"/></div></div></a></div><p id="38a8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">训练StyleGAN的计算量很大。因此，如果你没有一个像样的GPU，你可能想在云上训练。如果你决定在Google Colab上训练(这是免费的)，有人为此制作了一个不错的<a class="ae lu" href="https://colab.research.google.com/github/ArthurFDLR/GANightSky/blob/main/GANightSky.ipynb#scrollTo=qQqYjeRsfYD2" rel="noopener ugc nofollow" target="_blank">笔记本</a>。</p><p id="5c06" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在教程中，我将使用自行车数据集<a class="ae lu" href="https://decode.mit.edu/projects/biked/" rel="noopener ugc nofollow" target="_blank"> BIKED </a>。请随意使用您自己的数据集。只要确保所有的训练图像都是正方形的，并将它们放在同一个文件夹中。</p><p id="abb8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我将使用StyleGAN2-ADA的Tensorflow实现。确保使用Tensorflow版本1，因为代码与Tensorflow版本2不兼容。或者，如果你喜欢PyTorch，你可以使用最近发布的PyTorch版本。PyTorch代码在性能上似乎稍快一些。如果您使用PyTorch，您仍然可以遵循本教程，只是在数据集准备方面稍有不同。</p><h1 id="2105" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">要求</h1><ul class=""><li id="b68f" class="ng nh it la b lb ni le nj lh nk ll nl lp nm lt nn no np nq bi translated">64位Python 3.6或3.7。建议使用带有numpy 1.14.3或更新版本的Anaconda3。</li><li id="3ef4" class="ng nh it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">建议使用TensorFlow 1.14，但Linux上也支持TensorFlow 1.15。不支持TensorFlow 2.x。</li><li id="3d37" class="ng nh it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">在Windows上，您需要使用TensorFlow 1.14，因为标准的1.15安装不包括必要的C++头文件。</li><li id="af8e" class="ng nh it la b lb nr le ns lh nt ll nu lp nv lt nn no np nq bi translated">1-8个高端NVIDIA GPUs，至少12 GB GPU内存，NVIDIA驱动程序，CUDA 10.0工具包和cuDNN 7.5</li></ul><h1 id="25b1" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">步伐</h1><ol class=""><li id="ca50" class="ng nh it la b lb ni le nj lh nk ll nl lp nm lt nw no np nq bi translated">克隆StyleGAN2-ADA存储库并进入目录</li></ol><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="e5a8" class="oc mp it ny b gy od oe l of og">git clone <a class="ae lu" href="https://github.com/NVlabs/stylegan2-ada.git" rel="noopener ugc nofollow" target="_blank">https://github.com/NVlabs/stylegan2-ada.git</a><br/>cd styelgan2-ada</span></pre><p id="f954" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.下载或创建自己的数据集。我将使用我已经预处理过的<a class="ae lu" href="https://decode.mit.edu/projects/biked/" rel="noopener ugc nofollow" target="_blank"> BIKED </a>数据集。你可以从<a class="ae lu" href="https://www.dropbox.com/s/0ybsudabqscstf7/biked_dataset.tar.gz" rel="noopener ugc nofollow" target="_blank"> dropbox </a>下载我的预处理版本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/959a5240e829eb3b1406132cfff58885.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j03F9g5yslGoTGLxijEuow.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae lu" href="https://decode.mit.edu/projects/biked/" rel="noopener ugc nofollow" target="_blank"> BIKED数据集</a> [ <a class="ae lu" href="https://arxiv.org/abs/2103.06242" rel="noopener ugc nofollow" target="_blank"> CreativeGAN </a>的样本图像</p></figure><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="d044" class="oc mp it ny b gy od oe l of og"># Dowload dataset<br/>wget "https://www.dropbox.com/s/0ybsudabqscstf7/biked_dataset.tar.gz" -q -O biked_dataset.tar.gz</span><span id="ffb7" class="oc mp it ny b gy oi oe l of og"># extract dataset<br/>tar -zxvf biked_dataset.tar.gz</span><span id="744d" class="oc mp it ny b gy oi oe l of og"># Delete the tar.gz file<br/>rm biked_dataset.tar.gz</span></pre><p id="1cd6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">提取内容后，您将拥有一个名为BIKED的文件夹，其中包含4510个自行车设计的正方形图像。</p><p id="799f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="oj">注意</em> </strong> <em class="oj">:如果使用自己的数据集，创建一个文件夹，将所有训练图像放入文件夹中。确保所有的图像都是正方形的，大小相同。</em></p><p id="c57a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">3.正在准备数据集</p><p id="2193" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为代码需要数据集。tfrecords格式。我们首先需要将数据集转换成这种格式。StyleGAN2-ADA已经编写了一个脚本来简化这种转换。</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="71cf" class="oc mp it ny b gy od oe l of og"># first argument is output and second arg is path to dataset<br/>python dataset_tool.py create_from_images ./datasets/biked biked</span></pre><p id="2775" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这将创建一个多分辨率。/datasets/biked/文件夹中的tfrecord文件。</p><p id="689f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">4.培训风格GAN2-ADA</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="2ca7" class="oc mp it ny b gy od oe l of og"># snap is how often you want to save the model and sample results<br/># res is what image resolution you want to train on<br/># augpipe is augmentation pipes, such as 'blit', 'geom', 'color', 'filter', 'noise', 'cutout' or combination of these</span><span id="5f6a" class="oc mp it ny b gy oi oe l of og">python train.py --outdir ./results --snap=10 --data=./datasets/biked --augpipe=bgcfnc --res=512</span></pre><p id="f8af" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您还可以修改许多其他参数，请随意查看train.py代码以了解关于这些参数的更多信息。</p><p id="545c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一旦您运行该命令，它将开始训练并定期保存结果和模型文件(。pkl)，基于您提供的快照参数(在本例中，每10kimg)。一旦你认为结果足够好或者FID开始平台期，你可以停止训练，使用最后保存的。pkl文件。</p><p id="e30b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一旦你有了模型文件，你就可以使用这个命令生成图像。</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="07d9" class="oc mp it ny b gy od oe l of og">python generate.py --outdir=out --trunc=0.5 --seeds=600-605 --network={path_to_pkl_model_file}</span></pre><p id="28f1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以为种子提供一个范围或逗号分隔值。trunc是截断技巧的值。截断值越高，输出越多样化或极端，但可能会降低图像质量。该值越低，图像质量越高，但多样性可能会降低。最大值为1。</p><p id="662d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是，如果你想生成插值视频或图像网格。可以参考我之前的文章。</p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/generating-anime-characters-with-stylegan2-6f8ae59e237b"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">使用StyleGAN2生成动画角色</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">了解如何生成这个很酷的动画人脸插值</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="mn l mj mk ml mh mm ks ly"/></div></div></a></div><p id="c651" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">5.转移学习或恢复培训</p><p id="9fea" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你的训练因为某种原因停止或崩溃。您仍然可以从上次保存的进度继续训练。您只需要添加— resume参数和模型的路径(。pkl)文件。</p><p id="491a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此外，你也可以把这个论点用于迁移学习。与其从头开始训练，通常最好从一个预先训练好的模型开始，即使数据集本身并不相似。只需更换。由<a class="ae lu" href="https://github.com/NVlabs/stylegan2-ada" rel="noopener ugc nofollow" target="_blank"> StyleGAN-ADA </a>提供的预训练模型之一的pkl路径。</p><p id="8723" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个例子中，我将在biked数据集上从我的<a class="ae lu" href="https://www.dropbox.com/s/p51bd1muw11c06m/full-bike-network-snapshot-004096.pkl" rel="noopener ugc nofollow" target="_blank">预训练模型</a>恢复训练。</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="5397" class="oc mp it ny b gy od oe l of og">python train.py --outdir ./results --snap=10 --data=./datasets/biked --augpipe=bgcfnc --res=512 --resume=full-bike-network-snapshot-004096.pkl</span></pre><h1 id="8899" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">培训结果</h1><p id="fbef" class="pw-post-body-paragraph ky kz it la b lb ni ju ld le nj jx lg lh ok lj lk ll ol ln lo lp om lr ls lt im bi translated">这是一个经过一天的训练后，在特斯拉P100 GPU上256x256分辨率的训练结果的动画。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/081ead8d87832092ccd165631fd1fa23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*29EwkAXoISwXMh_jszt8xg.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">1天的StyleGAN2-ADA训练进度。[图片由作者提供]</p></figure></div><div class="ab cl oo op hx oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="im in io ip iq"><p id="9ee2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你喜欢我的作品，看看我的其他文章！</p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/animating-yourself-as-a-disney-character-with-ai-78af337d4081"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">用人工智能让你自己成为一个迪斯尼角色</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">先睹为快数字艺术的未来</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="ov l mj mk ml mh mm ks ly"/></div></div></a></div><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/generating-novel-content-without-dataset-544107da4cc8"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">在没有数据集的情况下生成新内容</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">重写GAN中的规则:上下文相关的复制和粘贴特性</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="ow l mj mk ml mh mm ks ly"/></div></div></a></div><h1 id="34c5" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">参考</h1><p id="0514" class="pw-post-body-paragraph ky kz it la b lb ni ju ld le nj jx lg lh ok lj lk ll ol ln lo lp om lr ls lt im bi translated">[1] Regenwetter，l .，Curry，b .，和Ahmed，F. (2021年)。BIKED:数据驱动自行车设计的数据集和机器学习基准。</p><p id="1b0a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[2]诺巴里，A. H .，拉沙德，M. F .，，艾哈迈德，F. (2021)。CreativeGAN:编辑用于创造性设计综合的生成性对抗网络</p><p id="5d41" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[3]t . Karras，m . Aittala，j . hells ten，Laine，s .，Lehtinen，j .，&amp; Aila，T. (2020年)。用有限数据训练生成性对抗网络</p></div></div>    
</body>
</html>