<html>
<head>
<title>Neural Network Inference on FPGAs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于FPGAs的神经网络推理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-network-inference-on-fpgas-d1c20c479e84?source=collection_archive---------12-----------------------#2021-05-31">https://towardsdatascience.com/neural-network-inference-on-fpgas-d1c20c479e84?source=collection_archive---------12-----------------------#2021-05-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="876c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何在AWS上从头开始构建和实现FPGA应用</h2></div><p id="ff33" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">作者:</strong> <a class="ae le" href="https://www.linkedin.com/in/daniel-suess/" rel="noopener ugc nofollow" target="_blank">丹尼尔·苏斯</a><a class="ae le" href="https://maxkelsen.com" rel="noopener ugc nofollow" target="_blank">高级机器学习工程师马克斯·凯尔森</a></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/989d55082b51e3a8461061aad60612b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D4SNWNkiVgwKoVM_hysivg.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">劳拉·奥克尔在<a class="ae le" href="https://unsplash.com/s/photos/chip-neon?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="81a7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与传统的云部署相比，将深度学习模型直接部署到边缘设备具有许多优势:消除通信可以减少延迟和对网络连接的依赖；由于数据从不离开设备，边缘推断有助于维护用户隐私；由于云资源的数量急剧减少，边缘推理也可以降低持续成本。</p><p id="2f9f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">运行在边缘设备上的ML的激增既推动了专用硬件加速器(如GPU、ASICs或FPGAs)的发展，也受其推动。对于每种硬件类型的优缺点的概述，请参见<a class="ae le" href="https://blog.inten.to/hardware-for-deep-learning-current-state-and-trends-51c01ebbb6dc" rel="noopener ugc nofollow" target="_blank">本系列文章</a>或<a class="ae le" rel="noopener" target="_blank" href="/deep-learning-hardware-know-your-options-9e95026b5d5e">本文</a>。</p><p id="3ba5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，我们将讨论如何在FPGA器件上运行简单神经网络的推理。主要重点将是更好地了解FPGA编程，并略微降低其传统的高准入门槛。</p><p id="1b8d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章将通过一个在2层全连接网络上运行推理的<a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/tree/part-1-v1" rel="noopener ugc nofollow" target="_blank">简单示例应用</a>来回顾基本开发。通过使用AWS的F1实例及其提供的AMI和所有必要的软件，您需要做的就是创建一个AWS帐户。稍加修改，该示例也可以在大多数Xilinx FPGAs上运行。</p><h1 id="394b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">FPGAs编程</h1><p id="e741" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">使用FPGA的主要挑战之一是，它们的编程模型与大多数其他“编程”有着根本的不同:对FPGA编程意味着对实际硬件编程，而不是生成由处理单元运行的指令。要理解这一点，我们首先需要了解什么是FPGA。</p><p id="9666" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">高度简化后，FPGA由许多可编程逻辑模块组成，例如查找表(LUT)、存储器以及这些构建模块之间的可重新配置连接。重新配置逻辑块的行为和它们之间的连接允许我们实现不同的数字电路。因此，最终的“程序”可以看作是由FPGA实现的原理图。</p><p id="28ca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">传统上，FPGAs使用硬件描述语言(如Verilog或VHDL)编程。这些与流行的编程语言有很大不同，这是FPGA编程门槛高的一个主要原因。</p><p id="b3cd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着高级综合(HLS)工具的引入，这一障碍已经大大降低，这些工具允许用C/C++等更主流的语言编写FPGAs代码。</p><p id="6463" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通常情况下，这种抽象性和简洁性的提高往往是以电路效率的降低为代价的。因此，对于性能关键的实现，对底层硬件层的良好理解是必不可少的。</p><p id="13ba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于我们的第一个实现，我们将使用Xilinx的基于OpenCL的Vitis平台:OpenCL设备(如FPGA)执行称为“内核”的小程序。这些内核由主机设备(CPU)管理和启动。通过使用HLS实现这些内核，FPGA的实现看起来非常接近CPU的类似实现。</p><blockquote class="ms mt mu"><p id="0b3d" class="ki kj mv kk b kl km ju kn ko kp jx kq mw ks kt ku mx kw kx ky my la lb lc ld im bi translated">主要区别在于，FPGA内核不仅仅是像在CPU上一样处理的指令，而是作为设备上的数字电路来实现。</p></blockquote><p id="a7a0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以举个例子，如果我们想并行运行部分代码，不能只在多核上并行运行；相反，我们需要在FPGA上复制物理电路。</p><p id="6f32" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，Xilinx' <a class="ae le" href="https://github.com/Xilinx/Vitis-AI" rel="noopener ugc nofollow" target="_blank"> Vitis AI </a>平台为常见的网络架构(如用于图像分类的Resnets)和单级对象检测器(如SSD和Yolo)提供了现成的运行时。然而，在写这篇文章的时候，AWS F1实例<a class="ae le" href="https://github.com/Xilinx/Vitis-AI/issues/2" rel="noopener ugc nofollow" target="_blank">还不被支持</a>。</p><p id="a871" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将来，我想看看必要层的简单实现在效率上能有多接近这样的参考实现。</p><h1 id="efa2" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">设置开发环境</h1><p id="f8ec" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">这篇文章附带的代码可以在<a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/tree/part-1-v1" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。在第一个技术部分，我们将讨论如何运行它。由于必要的软件似乎不是免费提供的，我们将在AWS上使用<a class="ae le" href="https://aws.amazon.com/marketplace/pp/Amazon-Web-Services-FPGA-Developer-AMI/B06VVYBLZZ" rel="noopener ugc nofollow" target="_blank"> FPGA开发者AMI </a>。</p><p id="7479" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你将需要一个AWS帐户支付设置，因为自由层的机器是不够强大的。</p><p id="f691" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本例中的构建脚本基于<a class="ae le" href="https://github.com/Xilinx/Vitis-Tutorials" rel="noopener ugc nofollow" target="_blank">官方Vitis教程</a>。然而，这些在AWS的FPGA环境中不能开箱即用，需要进行两项更改:</p><ul class=""><li id="604b" class="mz na it kk b kl km ko kp kr nb kv nc kz nd ld ne nf ng nh bi translated">需要将<code class="fe ni nj nk nl b"><a class="ae le" href="https://github.com/Xilinx/Vitis-Tutorials/blob/master/Hardware_Accelerators/Introduction/03-Algorithm_Acceleration/docs/module1_baseline/Makefile#L36" rel="noopener ugc nofollow" target="_blank">PLATFORM</a></code>变量设置为<code class="fe ni nj nk nl b"><a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/blob/master/CMakeLists.txt#L14" rel="noopener ugc nofollow" target="_blank">$AWS_PLATFORM</a></code>——由FPGA AMI设置的环境变量，以及</li><li id="5dbf" class="mz na it kk b kl nm ko nn kr no kv np kz nq ld ne nf ng nh bi translated">使用的FPGA内存条需要在硬件仿真模式下<a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/blob/master/src/matrix.hpp#L22" rel="noopener ugc nofollow" target="_blank">更改</a>。</li></ul><p id="6e9c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后一句话已经让我们看到了使用FPGAs的一个要点:为实际硬件设备合成程序可能需要很长时间，甚至几个小时，即使是简单的设计也是如此。这就是为什么我们将广泛使用两种不同类型的仿真。</p><p id="41f7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，在软件仿真模式下，内核被编译成本机代码，直接在CPU上运行。一方面，这使得编译速度非常快，并且在特性开发期间实现快速开发周期是理想的。另一方面，由于这个步骤不需要实际的原理图合成，某些错误不会在软件仿真中出现。</p><p id="b25f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第二种是硬件仿真模式，在仿真设备上运行实际的合成原理图。由于这种模拟非常详细，硬件模拟运行起来比软件模拟慢得多。它也增加了开发周期的额外编译时间，但仍然比实际FPGA的编译快得多。</p><p id="cbb7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从好的方面来看，硬件仿真不仅允许功能测试，还允许探测在物理设备上运行的性能特征和资源需求。</p><p id="4912" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于这两种仿真模式都不需要FPGA，大多数开发工作可以(也应该)在一台强大的纯CPU机器上完成，从而节省了大量资金。我们只需要一个FPGA实例进行最后的测试。</p><h1 id="d7da" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">设置EC2实例</h1><p id="c9c9" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">如前所述，大多数开发工作不需要FPGA实例，可以在通用实例类型上完成。按照本教程，您将需要一个S3桶(在这里命名为<code class="fe ni nj nk nl b">fpga-storage</code>)和一个EC2实例，它具有:</p><ul class=""><li id="f505" class="mz na it kk b kl km ko kp kr nb kv nc kz nd ld ne nf ng nh bi translated">AWS FPGA开发人员AMI加载，</li><li id="d067" class="mz na it kk b kl nm ko nn kr no kv np kz nq ld ne nf ng nh bi translated">至少16GB的RAM(例如，<code class="fe ni nj nk nl b">m5.xlarge</code>实例类型或更大以加速仿真)，以及</li><li id="7d66" class="mz na it kk b kl nm ko nn kr no kv np kz nq ld ne nf ng nh bi translated">对S3存储桶具有读/写访问权限的IAM角色，并具有以下权限:</li></ul><p id="496d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe ni nj nk nl b">DescribeFpgaImageAttribute</code></p><p id="545a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe ni nj nk nl b">DescribeFpgaImages</code></p><p id="2f47" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe ni nj nk nl b">CopyFpgaImage</code></p><p id="1246" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe ni nj nk nl b">CreateFpgaImage</code></p><p id="4256" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe ni nj nk nl b">DeleteFpgaImage</code></p><p id="f173" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe ni nj nk nl b">ModifyFpgaImageAttribute</code></p><p id="c7cf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本节的剩余部分，我们将提供如何启动所需实例的分步说明。有经验的AWS用户可以跳到下面的<strong class="kk iu">设置环境</strong>部分。</p><p id="91ed" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">1.从<a class="ae le" href="https://s3.console.aws.amazon.com/s3/home" rel="noopener ugc nofollow" target="_blank"> S3管理控制台</a>创建一个新的S3桶。将名称设置为<code class="fe ni nj nk nl b">fpga-storage</code>，并保留其余选项的默认值。</p><p id="d72e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.从<a class="ae le" href="https://console.aws.amazon.com/iam/home#/policies" rel="noopener ugc nofollow" target="_blank"> IAM策略创建</a>创建新策略。</p><p id="d290" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3.对于服务，选择“S3”；对于操作，选择“ListBucket”、“GetObject”、“PutObject”和“DeleteObject”，对于资源，为除“Bucket”之外的所有字段选择“Any”，对于“bucket”，您将bucket-name设置为“fpga-storage”:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nr"><img src="../Images/ec014941f0fcab8704e21bc27273d030.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KRXM7BygNROUZPLH8E7E1A.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated"><em class="ns">S3服务的策略设置</em></p></figure><p id="a2d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">4.单击“添加附加权限”并为“EC2”服务添加以下权限(也在上面列出):</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nt"><img src="../Images/29d669af2a3880283e3bbf9690656e88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L-kiU_B0FfPbGXm5LSCeug.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated"><em class="ns">EC2服务的策略设置</em></p></figure><p id="67ef" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">5.继续浏览各个屏幕，直到您到达“审查政策”屏幕。输入“FpgaDevPolicy”作为名称，并完成角色创建。</p><p id="e43d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">6.您现在可以使用<a class="ae le" href="https://console.aws.amazon.com/iam/home#/roles" rel="noopener ugc nofollow" target="_blank"> IAM角色创建</a>来创建一个新角色。</p><p id="4dd1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">7.从下一个屏幕中选择“AWS服务”→“EC2”作为可信实体。</p><p id="2c47" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">8.从列表中选择新创建的“FpgaDevPolicy ”,并继续操作，直到到达“查看角色”屏幕。输入名称“FpgaDevRole”并完成角色创建。</p><p id="af99" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">9.从<a class="ae le" href="https://console.aws.amazon.com/ec2/v2/home#Instances:" rel="noopener ugc nofollow" target="_blank"> EC2控制台</a>中，点击“启动实例”。</p><p id="bf1e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">10、在AMI搜索栏中，输入“FPGA”，从左侧菜单中选择AWS Marketplace。从列表中选择AWS的“FPGA Developer AMI”。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nu"><img src="../Images/ca9e0b6328ddf328fc730ad8eaebfe9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z0LFp4dErfqSr4Nmw-CZRA.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated"><em class="ns">选择FPGA AMI </em></p></figure><p id="a863" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">11.继续执行实例选择步骤。选择<code class="fe ni nj nk nl b">m5.xlarge</code>实例类型并点击“下一步:配置实例细节”按钮。</p><p id="40f2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">12.为IAM角色条目选择创建的“FpgaDevRole”。单击“添加存储”。</p><p id="5f3f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">13.删除额外的EBS卷，并将根分区的大小增加到200GB。</p><p id="19bd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">14.单击“查看并启动”和“启动实例”。</p><p id="88a8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">15.如有必要，<a class="ae le" href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html" rel="noopener ugc nofollow" target="_blank">使用AWS中显示的公共IP将ssh认证</a>和ssh设置到新实例中:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="07cc" class="nz lw it nl b gy oa ob l oc od"><em class="mv">$ </em>ssh -i ~/.ssh/PATH_TO_PRIVATE_KEY centos@xxx.xxx.xxx.xxx</span></pre><h1 id="30b1" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">设置环境</h1><p id="9ad9" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">现在我们已经使用FPGA开发工具连接到EC2实例，我们需要安装一些额外的要求:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="a622" class="nz lw it nl b gy oa ob l oc od"><em class="mv">$ sudo </em>yum <em class="mv">install </em>cmake3 jq<br/><em class="mv">$ </em>git clone https://github.com/aws/aws-fpga ~/src/project_data/aws-fpga</span></pre><p id="8db1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第二行从AWS的官方Github repo中克隆了一个repo和一些额外的助手脚本。我们主要需要它通过运行以下命令在机器上设置开发环境:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="5331" class="nz lw it nl b gy oa ob l oc od"><em class="mv">$ source</em> ~/src/project_data/aws-fpga/vitis_setup.sh</span></pre><blockquote class="ms mt mu"><p id="b571" class="ki kj mv kk b kl km ju kn ko kp jx kq mw ks kt ku mx kw kx ky my la lb lc ld im bi translated">注意，上述命令需要在每次登录机器时运行<strong class="kk iu">，因为它修改了shell环境。</strong></p></blockquote><h1 id="a33a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">运行示例</h1><p id="d75f" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">我们现在准备在这台机器上运行<a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/tree/part-1-v1" rel="noopener ugc nofollow" target="_blank">示例</a>。为此，我们将遵循正常的开发周期:软件仿真、硬件仿真，最后为硬件设备编译。要遵循以下示例，您需要克隆示例repo:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="ae4b" class="nz lw it nl b gy oa ob l oc od">$ git clone https://github.com/dsuess/nn-on-fpgas -b part-1-v1 --recursive &amp;&amp; cd nn-on-fpgas</span></pre><h1 id="371f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">软件仿真</h1><p id="0626" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">运行这些示例的最快方法是使用软件仿真。这将内核编译成本机代码，完全避开了电路合成。</p><p id="f688" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在构建脚本中，编译模式是通过<code class="fe ni nj nk nl b">TARGET</code>变量控制的，该变量有三个可能的值<code class="fe ni nj nk nl b">sw_emu</code>、<code class="fe ni nj nk nl b">hw_emu</code>和<code class="fe ni nj nk nl b">hw</code>。要在软件仿真中编译示例，我们可以简单地运行:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="7526" class="nz lw it nl b gy oa ob l oc od"><em class="mv">$ mkdir </em>build_sw <strong class="nl iu">&amp;&amp;</strong> <em class="mv">cd </em>build_sw <strong class="nl iu">&amp;&amp;</strong> cmake3 -DTARGET<strong class="nl iu">=</strong>sw_emu .. <strong class="nl iu">&amp;&amp;</strong> make main kernels tests emconfig.json</span></pre><p id="1c1a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果该命令引发错误，请确保您遵循了上面<strong class="kk iu">设置环境</strong>部分的说明。这将在<code class="fe ni nj nk nl b">build_sw</code>子目录中构建所有必需的目标:</p><ul class=""><li id="4035" class="mz na it kk b kl km ko kp kr nb kv nc kz nd ld ne nf ng nh bi translated"><code class="fe ni nj nk nl b">main</code>构建示例程序，</li><li id="20d0" class="mz na it kk b kl nm ko nn kr no kv np kz nq ld ne nf ng nh bi translated"><code class="fe ni nj nk nl b">tests</code>为内核构建测试套件，</li><li id="78ba" class="mz na it kk b kl nm ko nn kr no kv np kz nq ld ne nf ng nh bi translated"><code class="fe ni nj nk nl b">kernels</code>构建内核二进制文件<code class="fe ni nj nk nl b">xclbin/kernels.xclbin</code>，并且</li><li id="5265" class="mz na it kk b kl nm ko nn kr no kv np kz nq ld ne nf ng nh bi translated"><code class="fe ni nj nk nl b">emconfig.json</code>包含目标硬件平台的信息。</li></ul><p id="9d2c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">内核(即应该在FPGA上运行的基本数学运算)由应用在运行时加载。</p><p id="c2ee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在可以运行测试或示例应用程序了:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="2e87" class="nz lw it nl b gy oa ob l oc od"><em class="mv">$ XCL_EMULATION_MODE</em><strong class="nl iu">=</strong>sw_emu ./tests<br/><em class="mv">$ XCL_EMULATION_MODE</em><strong class="nl iu">=</strong>sw_emu ./main</span></pre><p id="d0db" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">后者应该在最后一行打印<code class="fe ni nj nk nl b">0 1 2 2 4 5 6 7 8 9</code>。这些是模型在对类别0到9的图像运行时的类别预测。该模型的精确度约为94%,这是我们看到标签3错误的原因。</p><h1 id="9a3b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">硬件仿真</h1><p id="bc00" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">为硬件仿真构建内核只需要改变<code class="fe ni nj nk nl b">TARGET</code>变量:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="7092" class="nz lw it nl b gy oa ob l oc od"><em class="mv">$ mkdir </em>build_hw <strong class="nl iu">&amp;&amp;</strong> <em class="mv">cd </em>build_hw <strong class="nl iu">&amp;&amp;</strong> cmake3 -DTARGET<strong class="nl iu">=</strong>hw_emu .. <strong class="nl iu">&amp;&amp;</strong> make kernels tests emconfig.json</span></pre><p id="f395" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该命令应该从git repo的根目录运行。请注意，与软件仿真模式相比，编译需要更长的时间。运行示例也是如此，这就是为什么我们只在硬件仿真中运行测试:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="ed50" class="nz lw it nl b gy oa ob l oc od"><em class="mv">XCL_EMULATION_MODE</em><strong class="nl iu">=</strong>hw_emu ./tests</span></pre><p id="be99" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除了二进制文件之外，硬件仿真还会生成关于资源利用的详细报告，并建议在<code class="fe ni nj nk nl b">_x/reports</code>中进行更改。我们将在本系列的后面部分回到这些诊断。</p><h1 id="48af" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">在FPGA上运行</h1><p id="7e81" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">最后，我们现在可以在实际的FPGA硬件设备上运行示例了:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="1bed" class="nz lw it nl b gy oa ob l oc od"><em class="mv">$ mkdir </em>build <strong class="nl iu">&amp;&amp;</strong> <em class="mv">cd </em>build <strong class="nl iu">&amp;&amp;</strong> cmake3 -DTARGET<strong class="nl iu">=</strong>hw .. <strong class="nl iu">&amp;&amp;</strong> make kernels</span></pre><p id="8de5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这一步只会在<code class="fe ni nj nk nl b">xclbin/kernels.xclbin</code>中构建内核二进制文件，可能需要一个多小时才能完成。如果你不想等那么久，我们提供一个二进制文件的完成版本作为Github版本。</p><p id="151b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在标准的Xilinx系统上，我们可以直接从xclbin文件运行内核。然而，AWS需要一个额外的步骤，即把xclbin转换成亚马逊FGPA图像(AFI)。构建步骤在<a class="ae le" href="https://github.com/aws/aws-fpga/blob/master/Vitis/README.md#build-the-host-application-and-xilinx-fpga-binary" rel="noopener ugc nofollow" target="_blank">官方AWS FPGA报告</a>中概述。</p><p id="1e58" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我们需要将用于以下命令的默认区域设置为支持FPGA实例的区域(这里是<code class="fe ni nj nk nl b">us-east-1</code>)</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="439a" class="nz lw it nl b gy oa ob l oc od"><em class="mv">$ </em>aws configure <em class="mv">set </em>default.region us-east-1</span></pre><p id="f9e0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们可以创建AFI映像，并将其保存到我们在初始环境设置中创建的S3存储桶<code class="fe ni nj nk nl b">fpga-storage</code>:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="9d0d" class="nz lw it nl b gy oa ob l oc od"><em class="mv">$ $VITIS_DIR</em>/tools/create_vitis_afi.sh -xclbin<strong class="nl iu">=</strong>xclbin/kernels.xclbin \<br/>		-o<strong class="nl iu">=</strong>xclbin/kernels \<br/>		-s3_bucket<strong class="nl iu">=</strong>fpga-storage -s3_dcp_key<strong class="nl iu">=</strong>kernels -s3_logs_key<strong class="nl iu">=</strong>logs</span></pre><p id="938f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这将创建一个xclbin文件<code class="fe ni nj nk nl b">xclbin/kernels.awsxclbin</code>，在F1实例上运行时，它应该由运行时加载，而不是由<code class="fe ni nj nk nl b">xclbin/kernels.xclbin</code>加载。在我们的标准运行时中，这是基于编译时标志自动完成的。我们将该文件复制到S3存储桶中以备后用。</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="485f" class="nz lw it nl b gy oa ob l oc od"><em class="mv">$ </em>aws s3 <em class="mv">cp </em>xclbin/kernels.awsxclbin s3://fpga-storage/</span></pre><p id="d85d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，应该创建一个包含AFI ID的<code class="fe ni nj nk nl b">*_afi_id.txt</code>文件。使用AFI ID，我们可以检查在后台运行的转换过程的状态:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="5503" class="nz lw it nl b gy oa ob l oc od"><em class="mv">$ export AFI_ID</em><strong class="nl iu">=</strong>$(<em class="mv">cat</em> <strong class="nl iu">*</strong>_afi_id.txt | jq -r ".FpgaImageId")<br/><em class="mv">$ </em>aws ec2 describe-fpga-images --fpga-image-ids <em class="mv">$AFI_ID</em></span></pre><p id="54f2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意，当多次运行<code class="fe ni nj nk nl b">create_vitis_afi.sh</code>脚本时，目录中将会有多个符合第一个命令的glob-pattern的文件。要么手动选择正确的选项，要么删除所有选项并重新运行脚本。</p><p id="579f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦describe-fpga-images命令输出的状态代码从“pending”变为“available”，我们就可以在fpga硬件设备上运行这个示例了。</p><p id="2371" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为此，遵循上面的<strong class="kk iu">设置EC2实例</strong>一节中概述的设置步骤，但是选择F1实例类型。在克隆了示例repo之后，我们需要构建除内核之外的所有东西:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="3a02" class="nz lw it nl b gy oa ob l oc od"><em class="mv">$ mkdir </em>build <strong class="nl iu">&amp;&amp;</strong> <em class="mv">cd </em>build <strong class="nl iu">&amp;&amp;</strong> cmake3 -DTARGET<strong class="nl iu">=</strong>hw .. <strong class="nl iu">&amp;&amp;</strong> make emconfig.json main tests</span></pre><p id="3e85" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以简单地从S3复制AFI内核二进制文件:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="eab8" class="nz lw it nl b gy oa ob l oc od"><em class="mv">$ mkdir </em>xclbin <strong class="nl iu">&amp;&amp;</strong> aws s3 <em class="mv">cp </em>s3://fpga-storage/kernels.awsxclbin xclbin/</span></pre><p id="81f3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">并在FPGA上运行测试和示例应用程序:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="b8c9" class="nz lw it nl b gy oa ob l oc od"><em class="mv">$ </em>./tests<br/><em class="mv">$ </em>./main</span></pre><h1 id="508c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">履行</h1><p id="4d82" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">既然我们已经介绍了如何构建用于仿真和硬件部署的<a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/tree/part-1-v1" rel="noopener ugc nofollow" target="_blank">示例</a>，我们将回顾一下在FPGAs上运行推理的2层全连接网络的简单基线实现。</p><h1 id="fe17" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">代码走查</h1><p id="8c69" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">我们试图运行的<a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/blob/4811b23d4fd4300c53a2f7638d5b9deee93a051d/train.py" rel="noopener ugc nofollow" target="_blank">模型</a>非常简单。两个完全连接的层；第一层重新激活，第二层(也是最后一层)激活softmax。</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="56ed" class="nz lw it nl b gy oa ob l oc od"><strong class="nl iu">class</strong> <strong class="nl iu">FCNN:</strong><br/>    <strong class="nl iu">def</strong> <strong class="nl iu">__init__(</strong><em class="mv">self</em><strong class="nl iu">,</strong> input_size<strong class="nl iu">:</strong> <em class="mv">int</em><strong class="nl iu">,</strong> num_classes<strong class="nl iu">:</strong> <em class="mv">int</em><strong class="nl iu">):</strong><br/>        <em class="mv">self</em><strong class="nl iu">.</strong>layer1 <strong class="nl iu">=</strong> Dense<strong class="nl iu">(</strong>input_size<strong class="nl iu">,</strong> 64<strong class="nl iu">)</strong><br/>        <em class="mv">self</em><strong class="nl iu">.</strong>layer2 <strong class="nl iu">=</strong> Dense<strong class="nl iu">(</strong>64<strong class="nl iu">,</strong> num_classes<strong class="nl iu">)</strong></span><span id="b082" class="nz lw it nl b gy oe ob l oc od"><strong class="nl iu">def</strong> <strong class="nl iu">__call__(</strong><em class="mv">self</em><strong class="nl iu">,</strong> x<strong class="nl iu">:</strong> Tensor<strong class="nl iu">)</strong> <strong class="nl iu">-&gt;</strong> Tensor<strong class="nl iu">:</strong><br/>        y <strong class="nl iu">=</strong> x<br/>        y <strong class="nl iu">=</strong> <em class="mv">self</em><strong class="nl iu">.</strong>layer1<strong class="nl iu">(</strong>y<strong class="nl iu">).</strong>relu6<strong class="nl iu">()</strong><br/>        <strong class="nl iu">return</strong> <em class="mv">self</em><strong class="nl iu">.</strong>layer2<strong class="nl iu">(</strong>y<strong class="nl iu">).</strong>logsoftmax<strong class="nl iu">()</strong></span></pre><p id="4039" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这意味着我们需要实现以下三个内核:</p><ul class=""><li id="351f" class="mz na it kk b kl km ko kp kr nb kv nc kz nd ld ne nf ng nh bi translated">矩阵-矩阵乘法</li><li id="7789" class="mz na it kk b kl nm ko nn kr no kv np kz nq ld ne nf ng nh bi translated">偏置相加+ ReLu非线性</li><li id="0eba" class="mz na it kk b kl nm ko nn kr no kv np kz nq ld ne nf ng nh bi translated">偏置相加+ softmax非线性</li></ul><blockquote class="ms mt mu"><p id="8106" class="ki kj mv kk b kl km ju kn ko kp jx kq mw ks kt ku mx kw kx ky my la lb lc ld im bi translated">将矩阵乘法和偏置加法操作分成两个内核的原因是，前者可能会成为最大的性能瓶颈。</p></blockquote><p id="bf43" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，将它们分开会使以后用不同的矩阵乘法实现进行实验更容易。</p><p id="6d46" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此外，将偏置相加和非线性函数融合到单个内核中可能有利于性能。这两种操作都相对较快，因此启动内核的额外开销会更明显。</p><p id="1523" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这两种操作还具有低的计算-存储器-传输比，因此，通过在一次通过中执行偏置相加和非线性，受益于减少存储器访问。</p><p id="64f9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在<code class="fe ni nj nk nl b"><a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/blob/f301d3053bbc0ab7baea4ea92b440add63734369/src/net.hpp" rel="noopener ugc nofollow" target="_blank">net.hpp</a></code>文件中的C++实现也复制了模型的结构，我们将在后面介绍。</p><h1 id="4f80" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">内核实现</h1><p id="fba1" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">我们将编写的第一个也是最简单的内核是bias + ReLu6内核。由于HLS使用C++并且不包括任何可选的FPGA特定代码，第一个<a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/blob/4811b23d4fd4300c53a2f7638d5b9deee93a051d/src/bias_relu6_kernel.cpp" rel="noopener ugc nofollow" target="_blank">基线实现</a>看起来像标准C++代码:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="dab8" class="nz lw it nl b gy oa ob l oc od"><strong class="nl iu">extern</strong> "C" <strong class="nl iu">void</strong> <strong class="nl iu">bias_relu6_kernel(float</strong> <strong class="nl iu">*const</strong> activation<strong class="nl iu">,</strong> <strong class="nl iu">const</strong> <strong class="nl iu">float</strong> <strong class="nl iu">*const</strong> bias<strong class="nl iu">,</strong> <strong class="nl iu">const</strong> uint batch_size<strong class="nl iu">,</strong> <strong class="nl iu">const</strong> uint dim<strong class="nl iu">)</strong><br/><strong class="nl iu">{</strong><br/>   <strong class="nl iu">for</strong> <strong class="nl iu">(</strong>uint b <strong class="nl iu">=</strong> 0<strong class="nl iu">;</strong> b <strong class="nl iu">&lt;</strong> batch_size<strong class="nl iu">;</strong> b<strong class="nl iu">++)</strong><br/>   <strong class="nl iu">{</strong><br/>      <strong class="nl iu">for</strong> <strong class="nl iu">(</strong>uint d <strong class="nl iu">=</strong> 0<strong class="nl iu">;</strong> d <strong class="nl iu">&lt;</strong> dim<strong class="nl iu">;</strong> d<strong class="nl iu">++)</strong><br/>      <strong class="nl iu">{</strong><br/>         <strong class="nl iu">const</strong> uint ia <strong class="nl iu">=</strong> dim <strong class="nl iu">*</strong> b <strong class="nl iu">+</strong> d<strong class="nl iu">;</strong><br/>         activation<strong class="nl iu">[</strong>ia<strong class="nl iu">]</strong> <strong class="nl iu">=</strong> relu6<strong class="nl iu">(</strong>activation<strong class="nl iu">[</strong>ia<strong class="nl iu">]</strong> <strong class="nl iu">+</strong> bias<strong class="nl iu">[</strong>d<strong class="nl iu">]);</strong><br/>      <strong class="nl iu">}</strong><br/>   <strong class="nl iu">}</strong><br/><strong class="nl iu">}</strong></span></pre><p id="ba53" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">bias + softmax <a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/blob/4811b23d4fd4300c53a2f7638d5b9deee93a051d/src/bias_softmax_kernel.cpp" rel="noopener ugc nofollow" target="_blank">内核</a>的实现非常相似。注意，结果是使用<code class="fe ni nj nk nl b">activation</code>作为输入和输出就地计算的。这对于矩阵乘法核来说是不可能的，因为输入和输出的形状可能不同。</p><p id="5a8b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，我们需要在内核之外分配足够的内存，并使用额外的<code class="fe ni nj nk nl b">out</code>参数传入一个指针。使用三个for循环的简单实现当然不是最佳的，稍后需要重新考虑:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="6983" class="nz lw it nl b gy oa ob l oc od"><strong class="nl iu">extern</strong> "C" <strong class="nl iu">void</strong> <strong class="nl iu">matmul_kernel(const</strong> <strong class="nl iu">float</strong> <strong class="nl iu">*const</strong> matrixA<strong class="nl iu">,</strong> <strong class="nl iu">const</strong> <strong class="nl iu">float</strong> <strong class="nl iu">*const</strong> matrixB<strong class="nl iu">,</strong> <strong class="nl iu">const</strong> uint rowsA<strong class="nl iu">,</strong> <strong class="nl iu">const</strong> uint colsA<strong class="nl iu">,</strong> <strong class="nl iu">const</strong> uint colsB<strong class="nl iu">,</strong> <strong class="nl iu">float</strong> <strong class="nl iu">*const</strong> out<strong class="nl iu">)</strong><br/><strong class="nl iu">{</strong><br/>   <strong class="nl iu">for</strong> <strong class="nl iu">(</strong>uint i <strong class="nl iu">=</strong> 0<strong class="nl iu">;</strong> i <strong class="nl iu">&lt;</strong> rowsA<strong class="nl iu">;</strong> <strong class="nl iu">++</strong>i<strong class="nl iu">)</strong><br/>   <strong class="nl iu">{</strong><br/>      <strong class="nl iu">for</strong> <strong class="nl iu">(</strong>uint j <strong class="nl iu">=</strong> 0<strong class="nl iu">;</strong> j <strong class="nl iu">&lt;</strong> colsB<strong class="nl iu">;</strong> <strong class="nl iu">++</strong>j<strong class="nl iu">)</strong><br/>      <strong class="nl iu">{</strong><br/>         <em class="mv">// Nulling result here causes issues when running in hw-emu mode.</em><br/>         <em class="mv">// Looks like io isn't updated "in time"</em><br/>         <strong class="nl iu">const</strong> uint io <strong class="nl iu">=</strong> colsB <strong class="nl iu">*</strong> i <strong class="nl iu">+</strong> j<strong class="nl iu">;</strong><br/>         <strong class="nl iu">for</strong> <strong class="nl iu">(</strong>uint k <strong class="nl iu">=</strong> 0<strong class="nl iu">;</strong> k <strong class="nl iu">&lt;</strong> colsA<strong class="nl iu">;</strong> <strong class="nl iu">++</strong>k<strong class="nl iu">)</strong><br/>         <strong class="nl iu">{</strong><br/>            <strong class="nl iu">const</strong> uint ia <strong class="nl iu">=</strong> colsA <strong class="nl iu">*</strong> i <strong class="nl iu">+</strong> k<strong class="nl iu">;</strong><br/>            <strong class="nl iu">const</strong> uint ib <strong class="nl iu">=</strong> colsB <strong class="nl iu">*</strong> k <strong class="nl iu">+</strong> j<strong class="nl iu">;</strong><br/>            out<strong class="nl iu">[</strong>io<strong class="nl iu">]</strong> <strong class="nl iu">+=</strong> matrixA<strong class="nl iu">[</strong>ia<strong class="nl iu">]</strong> <strong class="nl iu">*</strong> matrixB<strong class="nl iu">[</strong>ib<strong class="nl iu">];</strong><br/>         <strong class="nl iu">}</strong><br/>      <strong class="nl iu">}</strong><br/>   <strong class="nl iu">}</strong><br/><strong class="nl iu">}</strong></span></pre><p id="487a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出数组<code class="fe ni nj nk nl b">out</code>应该在内核之外初始化为零，并且所有的数组都假定以行优先的顺序存储它们的元素。</p><h1 id="050e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">主机应用程序</h1><p id="916b" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">到目前为止，我们已经实现了将在FPGA器件上“运行”的所有代码。剩下的部分构成了代码的大部分，用于主机设备(CPU)和内存管理以及内核调度。</p><p id="b8fc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe ni nj nk nl b"><a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/blob/4811b23d4fd4300c53a2f7638d5b9deee93a051d/src/matrix.hpp#L37" rel="noopener ugc nofollow" target="_blank">Matrix</a></code> <a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/blob/4811b23d4fd4300c53a2f7638d5b9deee93a051d/src/matrix.hpp#L37" rel="noopener ugc nofollow" target="_blank">类</a>抽象出内存管理以及主机设备内存传输。使用Vitis的一个主要限制是，复制到FPGA器件或从FPGA器件复制的所有存储器都需要在主机器件上按页对齐，即起始地址和存储器大小都必须能被页大小整除。为此，我们使用一个<a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/blob/4811b23d4fd4300c53a2f7638d5b9deee93a051d/src/matrix.hpp#L27" rel="noopener ugc nofollow" target="_blank">定制分配器</a>，其中<code class="fe ni nj nk nl b">DEFAULT_ALIGNMENT</code>被硬编码为页面大小<code class="fe ni nj nk nl b">4096</code>:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="182c" class="nz lw it nl b gy oa ob l oc od"><strong class="nl iu">template</strong> <strong class="nl iu">&lt;typename</strong> <strong class="nl iu">T&gt;</strong><br/>T <strong class="nl iu">*aligned_alloc(</strong>std<strong class="nl iu">::size_t</strong> num<strong class="nl iu">,</strong> std<strong class="nl iu">::size_t</strong> alignment <strong class="nl iu">=</strong> DEFAULT_ALIGNMENT<strong class="nl iu">)</strong><br/><strong class="nl iu">{</strong><br/>    <strong class="nl iu">void</strong> <strong class="nl iu">*</strong>ptr <strong class="nl iu">=</strong> <em class="mv">nullptr</em><strong class="nl iu">;</strong><br/>    <strong class="nl iu">if</strong> <strong class="nl iu">(</strong>posix_memalign<strong class="nl iu">(&amp;</strong>ptr<strong class="nl iu">,</strong> alignment<strong class="nl iu">,</strong> num <strong class="nl iu">*</strong> <strong class="nl iu">sizeof(</strong>T<strong class="nl iu">)))</strong><br/>    <strong class="nl iu">{</strong><br/>        <strong class="nl iu">throw</strong> std<strong class="nl iu">::</strong>bad_alloc<strong class="nl iu">();</strong><br/>    <strong class="nl iu">}</strong><br/>    <strong class="nl iu">return</strong> <strong class="nl iu">reinterpret_cast&lt;</strong>T <strong class="nl iu">*&gt;(</strong>ptr<strong class="nl iu">);</strong><br/><strong class="nl iu">}</strong></span></pre><p id="69ef" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">函数<code class="fe ni nj nk nl b"><a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/blob/4811b23d4fd4300c53a2f7638d5b9deee93a051d/src/matrix.hpp#L178" rel="noopener ugc nofollow" target="_blank">to_device</a></code>和<code class="fe ni nj nk nl b"><a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/blob/4811b23d4fd4300c53a2f7638d5b9deee93a051d/src/matrix.hpp#L196" rel="noopener ugc nofollow" target="_blank">to_cpu</a></code>处理主机和设备之间的内存传输。我们通过实现特殊的构造函数和<code class="fe ni nj nk nl b">=</code>-操作符来实现<code class="fe ni nj nk nl b">Matrix</code>类的移动语义，以允许从函数中自由复制返回值。</p><p id="6edf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，<code class="fe ni nj nk nl b"><a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/blob/4811b23d4fd4300c53a2f7638d5b9deee93a051d/src/matrix.hpp#L210" rel="noopener ugc nofollow" target="_blank">matrix.hpp</a></code>底部的两个助手函数为我们抽象了OpenCL内核调度开销。例如，<code class="fe ni nj nk nl b">apply_matmul</code>函数将<code class="fe ni nj nk nl b">matmul_kernel</code>应用于两个<code class="fe ni nj nk nl b">Matrix</code>实例:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="c854" class="nz lw it nl b gy oa ob l oc od">std<strong class="nl iu">::</strong>pair<strong class="nl iu">&lt;</strong>Matrix<strong class="nl iu">,</strong> cl<strong class="nl iu">::</strong>Event<strong class="nl iu">&gt;</strong> apply_matmul<strong class="nl iu">(</strong>Matrix <strong class="nl iu">&amp;</strong>matrixA<strong class="nl iu">,</strong> Matrix <strong class="nl iu">&amp;</strong>matrixB<strong class="nl iu">,</strong> cl<strong class="nl iu">::</strong>Kernel <strong class="nl iu">&amp;</strong>kernel<strong class="nl iu">,</strong> std<strong class="nl iu">::</strong>vector<strong class="nl iu">&lt;</strong>cl<strong class="nl iu">::</strong>Event<strong class="nl iu">&gt;</strong> <strong class="nl iu">*</strong>wait_on <strong class="nl iu">=</strong> <em class="mv">NULL</em><strong class="nl iu">,</strong> DeviceHandle <strong class="nl iu">&amp;</strong>handle <strong class="nl iu">=</strong> HANDLE<strong class="nl iu">)</strong><br/><strong class="nl iu">{</strong><br/>    Matrix result <strong class="nl iu">=</strong> Matrix<strong class="nl iu">::</strong>constant<strong class="nl iu">(</strong>matrixA<strong class="nl iu">.</strong>rows<strong class="nl iu">,</strong> matrixB<strong class="nl iu">.</strong>cols<strong class="nl iu">,</strong> 0.0<strong class="nl iu">,</strong> 4096<strong class="nl iu">);</strong><br/>    result<strong class="nl iu">.</strong>to_device<strong class="nl iu">(</strong>handle<strong class="nl iu">);</strong><br/>    kernel<strong class="nl iu">.</strong>setArg<strong class="nl iu">(</strong>0<strong class="nl iu">,</strong> matrixA<strong class="nl iu">.</strong>get_buffer<strong class="nl iu">());</strong><br/>    kernel<strong class="nl iu">.</strong>setArg<strong class="nl iu">(</strong>1<strong class="nl iu">,</strong> matrixB<strong class="nl iu">.</strong>get_buffer<strong class="nl iu">());</strong><br/>    kernel<strong class="nl iu">.</strong>setArg<strong class="nl iu">(</strong>2<strong class="nl iu">,</strong> matrixA<strong class="nl iu">.</strong>rows<strong class="nl iu">);</strong><br/>    kernel<strong class="nl iu">.</strong>setArg<strong class="nl iu">(</strong>3<strong class="nl iu">,</strong> matrixA<strong class="nl iu">.</strong>cols<strong class="nl iu">);</strong><br/>    kernel<strong class="nl iu">.</strong>setArg<strong class="nl iu">(</strong>4<strong class="nl iu">,</strong> matrixB<strong class="nl iu">.</strong>cols<strong class="nl iu">);</strong><br/>    kernel<strong class="nl iu">.</strong>setArg<strong class="nl iu">(</strong>5<strong class="nl iu">,</strong> result<strong class="nl iu">.</strong>get_buffer<strong class="nl iu">());</strong></span><span id="814e" class="nz lw it nl b gy oe ob l oc od">cl<strong class="nl iu">::</strong>Event event<strong class="nl iu">;</strong><br/>    handle<strong class="nl iu">.</strong>q<strong class="nl iu">.</strong>enqueueTask<strong class="nl iu">(</strong>kernel<strong class="nl iu">,</strong> wait_on<strong class="nl iu">,</strong> <strong class="nl iu">&amp;</strong>event<strong class="nl iu">);</strong><br/>    <strong class="nl iu">return</strong> std<strong class="nl iu">::</strong>make_pair<strong class="nl iu">(</strong>std<strong class="nl iu">::</strong>move<strong class="nl iu">(</strong>result<strong class="nl iu">),</strong> event<strong class="nl iu">);</strong><br/><strong class="nl iu">}</strong></span></pre><p id="71ed" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于OpenCL提供了一个异步API，我们不只是简单地调用内核，而是将运行内核的任务放入一个<a class="ae le" href="https://livebook.manning.com/book/opencl-in-action/chapter-7/" rel="noopener ugc nofollow" target="_blank">命令队列</a>。该任务可能依赖于其他先前排队的任务，这可以使用(可选)<code class="fe ni nj nk nl b">wait_on</code>参数来表示。</p><p id="df0d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对新调用的任务的引用作为类型<code class="fe ni nj nk nl b">cl::Event</code>的第二个返回值返回。只有在这个任务被处理之后，返回值<code class="fe ni nj nk nl b">result</code>才包含计算值。</p><p id="c1f0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要了解这是如何使用的，请看一下网络的<a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/blob/f301d3053bbc0ab7baea4ea92b440add63734369/src/net.hpp#L40" rel="noopener ugc nofollow" target="_blank">正向传递</a>:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="2d85" class="nz lw it nl b gy oa ob l oc od">Matrix <strong class="nl iu">operator()(</strong>Matrix <strong class="nl iu">&amp;</strong>input<strong class="nl iu">)</strong><br/>    <strong class="nl iu">{</strong><br/>        std<strong class="nl iu">::</strong>vector<strong class="nl iu">&lt;</strong>cl<strong class="nl iu">::</strong>Event<strong class="nl iu">&gt;</strong> events<strong class="nl iu">;</strong><br/>        events<strong class="nl iu">.</strong>resize<strong class="nl iu">(</strong>3<strong class="nl iu">);</strong><br/>        Matrix y<strong class="nl iu">;</strong><br/>        std<strong class="nl iu">::</strong>tie<strong class="nl iu">(</strong>y<strong class="nl iu">,</strong> events<strong class="nl iu">[</strong>0<strong class="nl iu">])</strong> <strong class="nl iu">=</strong> apply_matmul<strong class="nl iu">(</strong>input<strong class="nl iu">,</strong> weight1<strong class="nl iu">,</strong> MATMUL_KERNEL<strong class="nl iu">);</strong></span></pre><p id="8783" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一层中的矩阵乘法独立于任何运算。因此，我们不传递该行中的<code class="fe ni nj nk nl b">wait_on</code>参数。然后将event-result分配给<code class="fe ni nj nk nl b">events</code>向量的第一个条目，并复制到下面的行中，以确保<code class="fe ni nj nk nl b">events</code>的每个条目都是有效的<code class="fe ni nj nk nl b">cl::Event</code>实例:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="468a" class="nz lw it nl b gy oa ob l oc od">events<strong class="nl iu">[</strong>1<strong class="nl iu">]</strong> <strong class="nl iu">=</strong> events<strong class="nl iu">[</strong>0<strong class="nl iu">];</strong><br/>        events<strong class="nl iu">[</strong>2<strong class="nl iu">]</strong> <strong class="nl iu">=</strong> events<strong class="nl iu">[</strong>0<strong class="nl iu">];</strong><br/>        events<strong class="nl iu">[</strong>1<strong class="nl iu">]</strong> <strong class="nl iu">=</strong> apply_bias<strong class="nl iu">(</strong>y<strong class="nl iu">,</strong> bias1<strong class="nl iu">,</strong> BIAS_RELU6_KERNEL<strong class="nl iu">,</strong> <strong class="nl iu">&amp;</strong>events<strong class="nl iu">);</strong></span></pre><p id="0706" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">指向这个向量的指针然后被传递到第一层的偏置激活部分，因为它依赖于先前的矩阵乘法来完成。此时只分配一个大小为1的向量也可以达到类似的效果，但是在每次额外的操作之后，我们必须调整向量的大小。接下来的几行相应地应用了网络的第二层。</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="fbab" class="nz lw it nl b gy oa ob l oc od">std<strong class="nl iu">::</strong>tie<strong class="nl iu">(</strong>y<strong class="nl iu">,</strong> events<strong class="nl iu">[</strong>2<strong class="nl iu">])</strong> <strong class="nl iu">=</strong> apply_matmul<strong class="nl iu">(</strong>y<strong class="nl iu">,</strong> weight2<strong class="nl iu">,</strong> MATMUL_KERNEL<strong class="nl iu">,</strong> <strong class="nl iu">&amp;</strong>events<strong class="nl iu">);</strong><br/>        apply_bias<strong class="nl iu">(</strong>y<strong class="nl iu">,</strong> bias2<strong class="nl iu">,</strong> BIAS_SOFTMAX_KERNEL<strong class="nl iu">,</strong> <strong class="nl iu">&amp;</strong>events<strong class="nl iu">);</strong><br/>        <strong class="nl iu">return</strong> y<strong class="nl iu">;</strong><br/>    }</span></pre><p id="c810" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们准备看看<a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/blob/f301d3053bbc0ab7baea4ea92b440add63734369/src/main.cpp" rel="noopener ugc nofollow" target="_blank"> main.cpp </a>中的高级实现:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="5a3f" class="nz lw it nl b gy oa ob l oc od"><strong class="nl iu">int</strong> <strong class="nl iu">main(int</strong> argc<strong class="nl iu">,</strong> <strong class="nl iu">const</strong> <strong class="nl iu">char</strong> <strong class="nl iu">*</strong>argv<strong class="nl iu">[])</strong><br/><strong class="nl iu">{</strong><br/>    init_kernels<strong class="nl iu">();</strong></span><span id="d6b8" class="nz lw it nl b gy oe ob l oc od"><strong class="nl iu">auto</strong> model <strong class="nl iu">=</strong> FCNN<strong class="nl iu">(</strong>"weights/"<strong class="nl iu">);</strong><br/>    <strong class="nl iu">auto</strong> input <strong class="nl iu">=</strong> Matrix<strong class="nl iu">::</strong>from_npy<strong class="nl iu">(</strong>"weights/samples.npy"<strong class="nl iu">);</strong><br/>    input<strong class="nl iu">.</strong>to_device<strong class="nl iu">();</strong></span></pre><p id="c4d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对<code class="fe ni nj nk nl b"><a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/blob/f301d3053bbc0ab7baea4ea92b440add63734369/src/utils.hpp#L40" rel="noopener ugc nofollow" target="_blank">init_kernels</a></code>的第一次调用从一个单独的二进制文件加载OpenCL内核，并将对它们的引用存储在全局变量中。接下来，我们从单独的<code class="fe ni nj nk nl b">.npy</code>文件中加载模型权重，每个张量一个。最后，我们还加载将输入到模型中的输入样本。这些<code class="fe ni nj nk nl b">.npy</code>文件由<a class="ae le" href="https://github.com/dsuess/nn-on-fpgas/blob/f301d3053bbc0ab7baea4ea92b440add63734369/train.py#L97" rel="noopener ugc nofollow" target="_blank">训练脚本</a>准备，并存储为float32数组。</p><p id="378f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，我们运行模型，等待所有OpenCL事件完成，并将结果从设备复制回主机:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="2257" class="nz lw it nl b gy oa ob l oc od"><strong class="nl iu">auto</strong> result <strong class="nl iu">=</strong> model<strong class="nl iu">(</strong>input<strong class="nl iu">);</strong></span><span id="240b" class="nz lw it nl b gy oe ob l oc od">finish_cl_queue<strong class="nl iu">();</strong><br/>    result<strong class="nl iu">.</strong>to_cpu<strong class="nl iu">();</strong><br/>    finish_cl_queue<strong class="nl iu">();</strong></span></pre><p id="e8c3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，对于批处理中的每个元素，我们计算置信度得分的argmax，以获得最终的预测，并将其打印到stdout:</p><pre class="lg lh li lj gt nv nl nw nx aw ny bi"><span id="0b1e" class="nz lw it nl b gy oa ob l oc od"><em class="mv">// print argmax result</em><br/>    <strong class="nl iu">for</strong> <strong class="nl iu">(int</strong> i <strong class="nl iu">=</strong> 0<strong class="nl iu">;</strong> i <strong class="nl iu">&lt;</strong> result<strong class="nl iu">.</strong>rows<strong class="nl iu">;</strong> i<strong class="nl iu">++)</strong><br/>    <strong class="nl iu">{</strong><br/>        <strong class="nl iu">float</strong> minval <strong class="nl iu">=</strong> <strong class="nl iu">-</strong>1<strong class="nl iu">;</strong><br/>        <strong class="nl iu">int</strong> idx <strong class="nl iu">=</strong> <strong class="nl iu">-</strong>1<strong class="nl iu">;</strong></span><span id="2514" class="nz lw it nl b gy oe ob l oc od"><strong class="nl iu">for</strong> <strong class="nl iu">(int</strong> j <strong class="nl iu">=</strong> 0<strong class="nl iu">;</strong> j <strong class="nl iu">&lt;</strong> result<strong class="nl iu">.</strong>cols<strong class="nl iu">;</strong> j<strong class="nl iu">++)</strong><br/>        <strong class="nl iu">{</strong><br/>            <strong class="nl iu">auto</strong> val <strong class="nl iu">=</strong> result<strong class="nl iu">(</strong>i<strong class="nl iu">,</strong> j<strong class="nl iu">);</strong><br/>            <strong class="nl iu">if</strong> <strong class="nl iu">(</strong>minval <strong class="nl iu">&lt;</strong> val<strong class="nl iu">)</strong><br/>            <strong class="nl iu">{</strong><br/>                idx <strong class="nl iu">=</strong> j<strong class="nl iu">;</strong><br/>                minval <strong class="nl iu">=</strong> val<strong class="nl iu">;</strong><br/>            <strong class="nl iu">}</strong><br/>        <strong class="nl iu">}</strong></span><span id="4d02" class="nz lw it nl b gy oe ob l oc od">std<strong class="nl iu">::</strong>cout <strong class="nl iu">&lt;&lt;</strong> idx <strong class="nl iu">&lt;&lt;</strong> " "<strong class="nl iu">;</strong><br/>    <strong class="nl iu">}</strong><br/>    std<strong class="nl iu">::</strong>cout <strong class="nl iu">&lt;&lt;</strong> std<strong class="nl iu">::</strong>endl<strong class="nl iu">;</strong><br/>}</span></pre><p id="b3e3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们希望你喜欢这篇文章。在随后的帖子中，我们将研究这种基线实现的性能特征，以及如何改善延迟和减少资源需求。</p></div></div>    
</body>
</html>