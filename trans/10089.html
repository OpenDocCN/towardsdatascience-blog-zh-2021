<html>
<head>
<title>Mathematical Statistics: Mathematical Justifications for Maximum Likelihood Estimation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数理统计:最大似然估计的数学证明</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/mathematical-statistics-mathematical-justifications-of-maximum-likelihood-estimation-e489dd013557?source=collection_archive---------15-----------------------#2021-09-23">https://towardsdatascience.com/mathematical-statistics-mathematical-justifications-of-maximum-likelihood-estimation-e489dd013557?source=collection_archive---------15-----------------------#2021-09-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ba51" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">全变差、KL散度和最大似然估计之间关系的说明和推导</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/13228f88df3cfaae2084041178dec165.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*b1p_S_iftpHQUTP9"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ky" href="https://unsplash.com/@pietrozj?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Pietro Jeng </a>拍摄</p></figure><h1 id="c9e9" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">1:介绍和动机</h1><p id="1213" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在这篇文章中，我试图涵盖最大似然估计(MLE)的数学基础；构造分布参数的抽样估计量的一种常用方法。虽然MLE非常常用，但从教学的角度来看，它并不总是被很好地理解或很好地数学化。</p><p id="0c0b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这篇文章试图涵盖分布的总变差(TV)、分布的Kullbac-Leibler (KL)散度和最大似然估计(MLE)之间的联系。</p><p id="597f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这篇文章的目录如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/3cc1b0dd1dd6ec43dd88586a7e09ad69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AdUk6mjnmEQUIzIgaBzn4g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h1 id="59e3" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">2:玩具问题的说明</h1><p id="ad52" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">让我们暂时假设:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/0aa8b624ac28d30f764628da96c886a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WS8mfF1_1mdj3D4veBzzog.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="69be" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最大似然估计(MLE)是构造抽样估计量的一种非常常用的估计方法。MLE估计量是“插入式”估计量，从这个意义上说，它们是以样本构造的经验分布作为输入的泛函。</p><p id="3633" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最大似然估计顾名思义；它们是关于感兴趣参数的似然函数的<strong class="lt iu"> <em class="mu"> arg-max </em> </strong>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/0555f871a3b0f1626a70615f33ae25fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*94wMi-EZTlIxNmottDcoLA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="be32" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">尽管这个问题回避了，最大似然估计的数学依据是什么？为什么关于感兴趣参数的似然函数的<strong class="lt iu"> <em class="mu"> arg-max </em> </strong>是该参数的“好”抽样估计量？</p><p id="e9c9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们现在开始介绍分布之间的总变差(TV)。</p><h1 id="b563" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">3.总变分(TV)、Kullbac-Leibler (KL)散度和最大似然估计(MLE)</h1><h2 id="c534" class="mw la it bd lb mx my dn lf mz na dp lj ma nb nc ll me nd ne ln mi nf ng lp nh bi translated">总变差(电视):</h2><p id="9966" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">让我们再次提出我们的玩具问题:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/0aa8b624ac28d30f764628da96c886a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WS8mfF1_1mdj3D4veBzzog.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/380447200edc9a0228085dc9b43583cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HgiKJgsrazwWE2AHN1BPfQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/16056bcbf4826ccd7479b5cf6deb7b61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8N_foASfNNfwRUf8oIQriA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h2 id="1992" class="mw la it bd lb mx my dn lf mz na dp lj ma nb nc ll me nd ne ln mi nf ng lp nh bi translated">库尔巴克-莱布勒(KL)散度:</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/963c238827e88fae40e882d233d8d84e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*inOKuOWS2PX640_mhpM9AA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/23bccedf309f7a101eeb2e3cd3ef2eb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bdv-_ZwNaB6oOiQK1BLbRg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/6264d3a0f479f31fc41faef180734aa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WZVo8EDBR6SfxGIeb_jJsA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="4c7c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">还有维奥拉。我们证明了KL散度相对于我们的抽样估计量的<strong class="lt iu"> <em class="mu"> arg-min </em> </strong>等价于似然函数的<strong class="lt iu"> <em class="mu"> arg-max </em> </strong>(即最大似然估计)。</p><p id="0a0b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">完整的推导过程如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/053e00f89ab9bb9f65185411f6897066.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Caja6CvWcJMU69tr7GO30g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h1 id="906f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">4:总结和结论</h1><p id="6c2a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">总之，最大似然估计(MLE)的数学依据如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/63cb69a29bec8a00e73f71f7cf4dc95c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bP09uSWlmfsd0QPIEUyUdA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="f2e8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">希望以上有见地。正如我在以前的一些文章中提到的，我认为没有足够的人花时间去做这些类型的练习。对我来说，这种基于理论的洞察力让我在实践中更容易使用方法。我个人的目标是鼓励该领域的其他人采取类似的方法。以后我会继续写类似的作品。请<a class="ae ky" href="https://anr248.medium.com/" rel="noopener"> <strong class="lt iu">订阅并关注我在</strong> </a>和<a class="ae ky" href="http://www.linkedin.com/in/andrew-rothman-49739630" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> LinkedIn </strong> </a>上的更新！</p></div></div>    
</body>
</html>