<html>
<head>
<title>Challenges in Sentiment Classification with NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理在情感分类中的挑战</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/challenges-in-sentiment-classification-with-nlp-a20314600c3d?source=collection_archive---------41-----------------------#2021-05-25">https://towardsdatascience.com/challenges-in-sentiment-classification-with-nlp-a20314600c3d?source=collection_archive---------41-----------------------#2021-05-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="534f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">高等级不平衡的影响</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0c227e983502628280c2460971162f8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8_ErVIkMCtLVXvoLcCZrSQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">克里斯·j·戴维斯在<a class="ae kv" href="https://unsplash.com/s/photos/twitter?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="f4f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di"> It </span>毫无疑问，对于任何数据科学和/或机器学习相关的任务来说，文本数据可能是我们可用的最大数据源。因此，许多复杂的和高性能的算法已经被发明来分析文本数据和预测它的情感。但是应用更先进的算法并不一定意味着我们的预测是高精度的。我们仍然需要回到基础，了解数据的本质，这对任何进一步的处理都是挑战。</p><p id="8514" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我最近在自然语言处理领域进行了一项案例研究(这可能是我有史以来的第一个NLP项目)，以分析推文及其对两大品牌的情绪:苹果和谷歌。这个项目的主要目的是将推文分为正面和负面或中性。这些数据集是由Crowdflower通过“data.world”提供的。数据集由大约9000条推文组成，分为四类:“正面”、“负面”、“中性”和“无法辨别”，我将它们重新组织成三类，如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mb"><img src="../Images/ad419e985d3bf5e8fae5dedd4a8b02b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ESgejjD2-RJjho0C9_G5sQ.png"/></div></div></figure><p id="c9c8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从这里，人们可以很容易地看到，这是高度不平衡的阶级状况。尽管如此，我还是决定继续为快速脏分类任务准备数据。当然，我们必须至少做一些分类器可以接受的基本文本预处理。我应用的一些基本预处理包括:</p><ul class=""><li id="6f80" class="mc md iq ky b kz la lc ld lf me lj mf ln mg lr mh mi mj mk bi translated">扩展缩略词，如“不是”:“不是”、“不会”、“不会”、“不会”等。</li><li id="2a1b" class="mc md iq ky b kz ml lc mm lf mn lj mo ln mp lr mh mi mj mk bi translated">小写所有文本，删除非字母字符串，@，超链接，停用词，少于3个字母的单词等。</li></ul><p id="165c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是文本预处理代码片段的一个示例:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/4f0facfd646a2dcf58a1170fd68e8b8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eRJ-cbDbKu1eO0x1uAiENw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">一些研究建议保留' # '，在这种情况下没有任何区别</p></figure><p id="af32" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">干净的推文示例:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/f911a6d4a199b9cef711241d8e8a4b2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Up01gUhDgzG90rpoeZ0_OQ.png"/></div></div></figure><p id="cc4b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在对预处理感觉良好之后，我开始使用简单的分类器，比如传统的朴素贝叶斯和随机森林。出于矢量化的目的，我使用了TFIDF矢量器。下面是分类的快速结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/9b62020bfe85481f4fed37e9eea3e834.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*wbXyhrFJLOBmjPWflPwdLg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">朴素贝叶斯分类报告</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/34626f74f24344e3b5020289448336b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*GeXbSiUA5Huda7pfXFYxNg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">随机森林分类报告</p></figure><p id="87c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">很明显，如果我们研究“回忆”值，我们可以看到两个模型都存在不平衡数据。此外，随机森林高度过度适合训练数据。所以，在这一点上，我满怀希望地转向了神经网络。显然，首先想到的是LSTM和GRU. <em class="mu">但是在实现这些模型之前，我改变了文本预处理策略，以避免删除一些上下文中的停用词。</em>像LSTM和GRU这样的网络需要令牌形式的文本dat，可按如下示例创建:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mv"><img src="../Images/b521a27708c1977c0080c9152e4e580c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*eV85t5L4NMwZqUEh84eV6Q.png"/></div></div></figure><p id="c81d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用新的预处理文本，我执行了三种类型的LSTM:简单的单向LSTM、双向LSTM和带有手套嵌入的双向LSTM。此外，我还在类似配置的GRU网络上进行了培训。在我几乎所有的测试中，LSTM和GRU都产生了相同的结果。因此，为了简洁起见，我将只显示LSTM的结果。对于预训练的手套模型，在模型中引入了一个<em class="mu">‘手套. 6b . 100d’</em>嵌入。包含GLOVE的代码随处可见，不过我还是提供下面的代码片段:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/543781fb9d429211886514b9780bfade.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*UI0I49fdD-bPow-pNRwOPg.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/f06e21a4e4515a26f348e5ecebf9105d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*Sw5Gq3BRVZ52aw6YM0E9GA.png"/></div></figure><p id="929d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图显示了上述三种LSTMs架构的培训结果。请注意，启用了提前停止，因此不同的模型在不同的时间停止。还要注意，我训练的最大历元是20，这是因为在早期历元的验证数据中出现了大量训练过度。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/de0f90e2ed8bb428b1f05679df67eac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gJWNh0I7gVvn_rSw6a64zA.png"/></div></div></figure><p id="5294" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那么我们在这里得到了什么？从一开始，更先进的模型就不能推广这个模型。戴着预训练手套模型的LSTM似乎表现稍好，但仍然差得很远！</p><p id="8a8c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">还要记住，一开始的班级失衡，是不是影响了我们的模型表现？模型拟合参数中还包括类别权重字典。这对于提高模型性能没有任何帮助。还尝试了其他方法，如SMOTE、随机过采样器/欠采样器。然而，这些方法对这个数据集都没有帮助。最后，我决定通过增加物理数据来解决班级不平衡的问题。</p><h2 id="015a" class="mz na iq bd nb nc nd dn ne nf ng dp nh lf ni nj nk lj nl nm nn ln no np nq nr bi translated">数据扩充</h2><p id="592c" class="pw-post-body-paragraph kw kx iq ky b kz ns jr lb lc nt ju le lf nu lh li lj nv ll lm ln nw lp lq lr ij bi translated">在这种情况下，我找到了推文文本，但是推文与苹果相关产品相关。然而，文本的情感可以与任何特定品牌无关，只要它有与情感相关的关键词。怀着这个希望，我将<strong class="ky ir"> <em class="mu">只添加了负面分类的</em> </strong>到我当前的数据集中，并重新运行上述算法。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/9a4b3d787c5859df464b47d775e90e21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7e-Z_XPjSLGCFut7-XRypA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">扩充后的类别分布</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/04e0c92542eb70358fd9a71e875d22ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*ohF2QNpljzYlFp_9scbRKQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">朴素贝叶斯分类报告</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/821699fdec44380d9b91c973fef0e1f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*j85bLnE0_5-0091yHk_NBw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">随机森林分类报告</p></figure><p id="8813" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然整体准确率只是略有提高，但我很高兴负面类的<em class="mu">【回忆】</em>有所增加。因为，在任何市场情绪分析中，尽可能准确地预测人们的负面观点是很重要的。那么，神经网络在新的扩充数据集中表现如何。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/6423c59f25a87a4a0d4244dcc84930b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fyZvfe5aSxr61E6Dw1VuSw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">增强前后嵌入手套的双向LSTMs</p></figure><p id="fb69" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到模型性能有一些轻微的改进。训练过度仍然是一个大问题。在这一点上，我应该把更多的注意力放在优化模型架构上。在测试不同模型架构组合时，先测试多个LSTMs层，然后测试密集层，最大的影响来自于dropout参数的调整。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/58f43617e99fb5c3662fef07f3b93071.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1rsGwvBkjVSEYhNRCcafOw.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/88233ff0f8389c6b59f00dd83861a03b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*mhHJq2hewB37y2c9OY1ozA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">注意:最大纪元被设置为20，但是模型停止得更早</p></figure><p id="7705" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到，在LSTM层之前包含漏失参数似乎表现得更好。我通常对一次下降超过20%持谨慎态度，但在这个特定的案例中，高达30-40%的下降似乎没问题。我的最终模型(LSTM和GRU)只能以大约70%的准确率预测一条给定的推文。对于NLP任务来说，这并不是一个很好的结果，然而，考虑到具有挑战性的数据集，预处理a模型优化显示了有希望的结果。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/f0e51459774547abe46c106b79af7c86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o08JpKJlN9fZz3_ldf2sPw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">最终模型对比:LSTM vs GRU</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/5cb0fa4c07c39d4e3435b2e86d1e4d28.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*sRX_3vRVitZvNh6ui-_c4g.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/bef5f615e28f1e8f172962199f259355.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u23YVcXUfaerAIv5PFJX_Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">推文预测示例</p></figure><h1 id="f248" class="of na iq bd nb og oh oi ne oj ok ol nh jw om jx nk jz on ka nn kc oo kd nq op bi translated">最后的想法</h1><p id="8239" class="pw-post-body-paragraph kw kx iq ky b kz ns jr lb lc nt ju le lf nu lh li lj nv ll lm ln nw lp lq lr ij bi translated">该数据集需要做大量工作，尤其是数据扩充结果所支持的平衡类标签的收集。然而我的问题是:<em class="mu">一个大约9000条推文的文本数据集，对于像LSTM和GRU这样的建筑来说足够好吗？</em></p><p id="dffb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在下一步中，我将尝试对这个数据集使用transformer模型。</p><p id="6a37" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">完整的笔记本和必要的文档可以在我的github网站上找到:<a class="ae kv" href="https://github.com/sgautam666/Brand_Sentiment_Analysis_with_NLP" rel="noopener ugc nofollow" target="_blank">https://github . com/sgautam 666/Brand _情操_分析_with_NLP </a></p><h2 id="472a" class="mz na iq bd nb nc nd dn ne nf ng dp nh lf ni nj nk lj nl nm nn ln no np nq nr bi translated">参考</h2><p id="c1fa" class="pw-post-body-paragraph kw kx iq ky b kz ns jr lb lc nt ju le lf nu lh li lj nv ll lm ln nw lp lq lr ij bi translated"><a class="ae kv" href="https://data.world/crowdflower/brands-and-product-emotions" rel="noopener ugc nofollow" target="_blank">https://data.world/crowdflower/brands-and-product-emotions</a></p><p id="34c4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://data.world/crowdflower/apple-twitter-sentiment" rel="noopener ugc nofollow" target="_blank">https://data.world/crowdflower/apple-twitter-sentiment</a></p></div></div>    
</body>
</html>