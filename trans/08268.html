<html>
<head>
<title>A Template for Custom and Distributed Training</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">定制和分布式培训的模板</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-template-for-custom-and-distributed-training-c24e17bd5d8d?source=collection_archive---------32-----------------------#2021-07-29">https://towardsdatascience.com/a-template-for-custom-and-distributed-training-c24e17bd5d8d?source=collection_archive---------32-----------------------#2021-07-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ddcc" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用此模板快速编写自定义张量流算法</h2></div><p id="4ac9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">定制训练循环提供了极大的灵活性。您可以快速添加新功能，并深入了解算法的工作原理。然而，一遍又一遍地设置自定义算法是乏味的。总体布局通常是相同的；只有很小的部分会改变。</p><p id="efc4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是跟随模板的<a class="ae le" href="https://github.com/phrasenmaeher/distributed_template" rel="noopener ugc nofollow" target="_blank">发挥作用的地方:它概述了一个定制的分布式训练循环。所有需要修改以适应任务的地方都用待办事项突出显示。</a></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/d68a404ab67184397fdfb8616d8b60a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2yRqSJ4RjotGDmV8"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@cdr6934?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">克里斯里德</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="593e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">自定义分布式循环的一般布局</h1><p id="e2e5" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated"><a class="ae le" href="https://www.tensorflow.org/tutorials/distribute/custom_training" rel="noopener ugc nofollow" target="_blank">定制训练循环</a>——与调用model.fit()相反——是一种迭代数据集、更新模型权重和计算任何指标的机制。</p><p id="cfa7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在迭代任何数据集之前，无论是训练、验证还是测试分割，数据集都必须准备好分发。这是借助TensorFlow的分发策略对象完成的。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="3da0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们首先创建策略对象，它负责所有的分布式计算。通过选择不同的分发策略，我们可以在各种计算环境中使用我们的算法。这一事实使得定制循环高度灵活。</p><p id="e49b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在第2行，在创建了我们的策略之后，我们准备好了我们的数据集分布；TensorFlow处理所有内部细节。</p><p id="3b93" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于我们的分布式数据集，我们可以使用“<em class="mu"> for i in x </em>”方法对其进行迭代:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="0a90" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该循环对于所有子集(训练、验证、测试)都是相同的。主要区别是被调用的<em class="mu">步骤</em>。上面，我示例性地调用了<em class="mu"> distributed_train_step </em>，它处理我们的数据到所有加速器的分发。但是不要担心，TensorFlow处理大部分内部设备到设备的通信。我们只有它知道我们想做什么。方法已经为我们做好了。</p><p id="0640" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作为培训、测试或验证步骤的一部分，我们还会更新我们希望在培训期间跟踪的任何指标。我们必须手动执行此操作，如下所示:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="1d18" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这里，我编写了一个训练步骤，该步骤采用单个数据批次，将其解包为要素和标注，计算梯度，更新模型，并计算任何训练度量。这种方法类似于验证和测试步骤；我们只跳过模型更新。</p><p id="c1e6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">概括总体布局:</p><ul class=""><li id="10af" class="mv mw it kk b kl km ko kp kr mx kv my kz mz ld na nb nc nd bi translated">准备好分发所需的对象(模型、数据集、优化器、指标)</li><li id="388a" class="mv mw it kk b kl ne ko nf kr ng kv nh kz ni ld na nb nc nd bi translated">迭代数据集</li><li id="2947" class="mv mw it kk b kl ne ko nf kr ng kv nh kz ni ld na nb nc nd bi translated">调用分布式训练/测试/验证步骤来更新模型并计算指标</li></ul><p id="81f5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">总体布局到此为止。在接下来的内容中，我们将检查模板，看看您需要为手头的任务修改什么。</p><h1 id="69fc" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">分布式定制培训模板</h1><p id="701b" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">我们从必要的导入和一些全局定义开始:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="de34" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于这个模板，我决定将训练、测试和验证步骤中使用的所有对象和变量设为全局。这样，我们就不必一直传递它们，这使得代码更干净。然而，这只是一种方法，我相信还有更好的方法。</p><p id="d027" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所有模型及其优化器都是全局可用的，任何度量和损失也是如此。我没有在模板中包括测试和验证损失，但是我强烈建议您这样做。除此之外，我们还全局注册<em class="mu">全局</em>批量大小和分配策略(如前所述)。</p><p id="13c3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的训练脚本是用几个示例命令调用的，所以我们还导入了<em class="mu"> argparse </em>库。完整脚本的代码是</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="c086" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">并引出了主要的方法:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><h1 id="16f5" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">主要方法</h1><p id="08c9" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated"><em class="mu"> main </em>方法从使用我们之前介绍过的大部分全局对象开始。到目前为止，它们只是占位符，这就是我们现在实例化它们的原因。我们从分布策略(第13行)开始，然后是损失(第16行)、指标(第19行)和模型(第22行)。我们将很快详细介绍所有被调用的方法。</p><p id="2e6c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个模板中，我跳过了数据集创建部分。有太多的方法可以做到这一点，你知道什么最适合你的问题。从第26行开始，我只使用了<em class="mu"> None </em>作为初始值；将这一部分替换为创建和分发数据集(使用前面代码片段中显示的策略)</p><p id="f557" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从第31行开始，我们首先使用分布式训练和验证数据集训练模型，然后在保留测试数据集上评估它。</p><h2 id="620e" class="nj lw it bd lx nk nl dn mb nm nn dp mf kr no np mh kv nq nr mj kz ns nt ml nu bi translated">损耗</h2><p id="5f87" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">第一种方法<em class="mu"> create_loss_objects </em>，负责创建我们使用的任何损失。如下所示:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="d1c6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在分配策略的范围内，我们创造任何我们需要的损失。在示例代码中，这只是一个虚拟损失——修改它以满足您的需要。无论选择哪个损耗，不要忘记设置如图所示的<em class="mu">减少</em>参数:我们在后面的方法中手动减少损耗。无论您使用单个损失还是多个损失，都在这里创建并返回对象。您应该全局注册所有返回的亏损对象。我已经对样本<em class="mu"> train_loss_object1 </em>执行了此操作。对所有损失重复此步骤。</p><h2 id="4832" class="nj lw it bd lx nk nl dn mb nm nn dp mf kr no np mh kv nq nr mj kz ns nt ml nu bi translated">韵律学</h2><p id="7d32" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">创建用于跟踪模型进展的指标的代码遵循相同的方案:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="90ae" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在分布策略的范围下，我们实例化所有的度量。在模板中，这只是训练精度。缺少的是任何验证(在培训期间)和测试(在培训之后)的度量。我建议在打印时使用有意义的名称来标识指标。像以前一样，全局注册所有返回的指标。在<em class="mu">主</em>方法中，我已经用第9行中的<em class="mu"> train_metric1 </em>实现了这一点。</p><p id="1705" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在实例化指标之后，我们现在关注模型和优化器。这种模板方法遵循前两种方法:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="0034" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">和以前一样，我们在选择的策略范围内创建任何东西。这一步是强制性的，以使模型的内部变量和优化器分布准备就绪。在示例代码中，我没有选择任何特定的模型或优化器；修改第8行中的任何内容以适合您的任务。此外，不要忘记全局注册返回的对象，正如我在<em class="mu"> main </em>函数的第9行中对<em class="mu">模型</em>和<em class="mu">优化器</em>所做的那样。</p><h2 id="90b2" class="nj lw it bd lx nk nl dn mb nm nn dp mf kr no np mh kv nq nr mj kz ns nt ml nu bi translated">数据集</h2><p id="cf3a" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">在所有必需的对象都被实例化并准备好发布后，就该创建数据集了。我有意将此留作空白，因为创建数据集有多种方法:从<em class="mu"> tf.data.Dataset </em>对象到定制生成器或混合方法。你可以在这里找到概述<a class="ae le" href="https://www.tensorflow.org/guide/data?hl=en#basic_mechanics" rel="noopener ugc nofollow" target="_blank"/>，但是因为这个模板是面向更有经验的程序员的，我怀疑它对你是否有必要。无论如何，在创建数据集之后，您必须使用</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="6e39" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦数据集准备好，我们就可以继续训练循环(主中的第31行)。对于我们使用的模板，我们需要训练和验证数据集，但是您可以随意放弃后者。</p><h1 id="0492" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">训练和验证循环</h1><p id="63fc" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">训练循环是我们分布式算法的核心:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="0ffc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在第12行，我们开始在数据集上迭代<em class="mu">个时期</em>次。然后，从第15行到第20行，我们对训练数据进行循环，并将每一批数据提供给<em class="mu"> distributed_train_step </em>方法。在我们完成一次迭代之后，我们计算训练损失，并对验证数据重复这个过程。</p><p id="06ee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">完成之后，我们查询所有(全局)度量和丢失对象的当前值，我们打印并为下一个时期重置这些值(第34到39行)。正如评论所指出的，修改这段代码以考虑任何度量或损失对象。此外，如果您不在每个时期后重置度量(第37行)，它们将跟踪所有时期的进度，导致错误的每个时期值。</p><h2 id="d4ff" class="nj lw it bd lx nk nl dn mb nm nn dp mf kr no np mh kv nq nr mj kz ns nt ml nu bi translated">分布式训练步骤</h2><p id="8958" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">训练循环(从第17行开始)在内部调用分布式训练步骤。这个的代码是</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="60ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们在这里没有太多事情要做:我们得到一个数据批次(<em class="mu"> dataset_inputs </em>)，告诉策略运行一个单独的训练步骤，并减少返回的损失。现在，我们为什么不直接调用<em class="mu"> train_step </em>？因为我们处理分布式数据。第5行中的<em class="mu"> strategy.run </em>调用说明了这一点；为每个计算设备调用它。例如，如果我们连接了5个GPU，TensorFlow将自动调用train步骤五次。</p><p id="cafd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，我们必须合计(考虑“合并”或“合并”)从每个副本到当前设备(我们运行脚本的地方)的火车损失，并减少它以考虑加速器的数量。查看<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/distribute/Strategy#reduce" rel="noopener ugc nofollow" target="_blank">文档</a>了解更多信息。</p><h2 id="39ea" class="nj lw it bd lx nk nl dn mb nm nn dp mf kr no np mh kv nq nr mj kz ns nt ml nu bi translated">训练步骤</h2><p id="576a" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">如果我们没有分配我们的工作负载，我们可以直接调用实际的train步骤。然而，由于我们使用的是分布式设置，我们必须让TensorFlow知道。我们使用前面的方法做到了这一点，该方法使用<em class="mu"> strategy.run </em>来处理分发。在这个调用中，我们说实际的训练方法是<em class="mu"> train_step </em>方法，如下所示:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="90d3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于TensorFlow负责拆分批处理，因此我们接收的是单个批处理。在第9行，我们将它分解成特性和标签——这只是一个例子，根据您的需要修改代码。接下来的几行遵循一个标准的定制循环:我们计算损失(第15行)，计算并应用梯度(第18行和第19行)，并更新任何训练指标(第22行)。正如我在TODO注释中所做的标记，您必须对此进行调整，以考虑您所使用的所有模型、损失和指标。</p><h2 id="9a46" class="nj lw it bd lx nk nl dn mb nm nn dp mf kr no np mh kv nq nr mj kz ns nt ml nu bi translated">计算(培训)损失</h2><p id="9c97" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">为了计算培训损失，我们使用以下简短模板:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="3201" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们在第10行查询我们的loss对象，它给出了每个副本的损失。让我解释一下:我们的定制算法运行在多个计算设备或副本上。在每个设备上，独立调用训练步骤，导致总共<em class="mu"> n </em>个损失。每个损失现在用于计算梯度，通过求和在复制品之间同步。如果我们不衡量损失，结果会被夸大。</p><p id="a382" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">还不服气？<a class="ae le" href="https://www.tensorflow.org/tutorials/distribute/custom_training#define_the_loss_function" rel="noopener ugc nofollow" target="_blank">在单台机器上，损耗除以小批量样品的数量</a>。在多GPU设置中，我们不必将损失除以本地批量大小，而是除以全局批量大小。例如，本地批处理大小可能是8，而全局批处理大小可能是32 (=4*8代表4个GPU)。如果除以8，我们会假设我们在正向传递中看到的样本总数是8，这是不正确的。因此，在第14行中，我们对损失进行平均，以考虑全局批量大小。</p><p id="e919" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">那是为了训练程序。总结一下:我们首先调用<em class="mu"> distributed_train_step </em>，它负责将计算分发给每个工人。然后，在每个工人身上，调用<em class="mu"> train_step </em>，它接受一个批处理并更新模型的权重。</p><h2 id="f709" class="nj lw it bd lx nk nl dn mb nm nn dp mf kr no np mh kv nq nr mj kz ns nt ml nu bi translated">验证步骤</h2><p id="fca0" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">验证程序与培训程序非常相似:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="eaba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">只有微小的区别:我们不更新模型的权重(第11行)，我们更新我们的验证指标(第13行)。修改这些部分以适应你的需要。<em class="mu">distributed _ validation _ step</em>遵循与<em class="mu"> distributed_train_step </em>相同的布局:获取按比例缩放的每个副本的损失并将其合计(第25至28行)。</p><h1 id="8fa0" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">测试回路</h1><p id="c6e9" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">测试循环与前两个相似:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="d31b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们迭代分布式测试数据集(第11行)，对损失求和(第12行)，并对其求平均值(第14行)。之后，我们收集所有指标的结果。我没有包括任何单独的测试指标；根据您的需要修改这一部分(第16行和第17行)。</p><p id="6bda" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦我们查看了<em class="mu"> distributed_test_step </em>(第12行)，我们会注意到它再次高度相似:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="518f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在第32行中，我们收集了缩放后的损失，并在第36行中对其进行平均。实际的<em class="mu"> test_step </em>(第2行)取一个批次，打开它(第9行)，并计算损耗(第16行)和任何测试指标(第18行)。在这个片段中，我没有包括任何单独的测试指标。你必须调整它以适应你的问题。通常，您可以在<em class="mu"> create_metrics </em>方法中创建所有指标。记住要全局注册它们，以便能够轻松访问它们。</p><h1 id="d743" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">摘要</h1><p id="c986" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">我们已经讨论了定制和分布式算法的基本部分。通过选择适当的分布策略，我们可以将它用于各种计算环境，也可以用于单GPU设置。一般来说，所有需要修改的地方都标有TODO注释。虽然模板应该涵盖大多数用例，但它只是作为一个起点。像你我这样的从业者应该调整关键部分以满足他们的需求。完整的代码可以在<a class="ae le" href="https://github.com/phrasenmaeher/distributed_template" rel="noopener ugc nofollow" target="_blank"> GitHub </a>获得。</p></div></div>    
</body>
</html>