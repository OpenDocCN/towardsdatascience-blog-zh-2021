<html>
<head>
<title>Real-time anomaly detection with Apache Kafka and Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于Apache Kafka和Python的实时异常检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/real-time-anomaly-detection-with-apache-kafka-and-python-3a40281c01c9?source=collection_archive---------8-----------------------#2021-06-18">https://towardsdatascience.com/real-time-anomaly-detection-with-apache-kafka-and-python-3a40281c01c9?source=collection_archive---------8-----------------------#2021-06-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b2eb" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">了解如何使用Python对来自Kafka的流数据进行预测。</em></h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/06c85780eff7953b52be09396ad52b27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xem1rbG0Fa8DAhtez7mvsA.jpeg"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">照片由<a class="ae kw" href="https://unsplash.com/@aronvisuals" rel="noopener ugc nofollow" target="_blank">阿隆在<a class="ae kw" href="https://unsplash.com/photos/BXOXnQ26B7o" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的视觉效果</a>拍摄。</p></figure><p id="8120" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在这篇文章中，我将讨论如何使用Apache Kafka的传入流数据进行实时预测；我们将要实现的解决方案如下所示:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi lt"><img src="../Images/ae6426dfaf42e813fd999fa236a3c1a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JDJNjUSajl1DFbmqZ8jgRg.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">解决方案图。图片由作者提供。来自<a class="ae kw" href="https://flaticon.com/" rel="noopener ugc nofollow" target="_blank">平面图标</a>的图标。</p></figure><p id="3c97" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这个想法是:</p><ul class=""><li id="78d4" class="lu lv iq kz b la lb ld le lg lw lk lx lo ly ls lz ma mb mc bi translated">使用无监督机器学习训练异常检测算法。</li><li id="c847" class="lu lv iq kz b la md ld me lg mf lk mg lo mh ls lz ma mb mc bi translated">创建一个新的数据生成器，将事务发送到Kafka主题。</li><li id="81b1" class="lu lv iq kz b la md ld me lg mf lk mg lo mh ls lz ma mb mc bi translated">阅读Kafka主题中的数据，使用训练好的ml模型进行预测。</li><li id="3ec9" class="lu lv iq kz b la md ld me lg mf lk mg lo mh ls lz ma mb mc bi translated">如果模型检测到事务不是内联者，就把它发送到另一个Kafka主题。</li><li id="73e6" class="lu lv iq kz b la md ld me lg mf lk mg lo mh ls lz ma mb mc bi translated">创建最后一个读取异常并向松弛通道发送警报的消费者。</li></ul><p id="1943" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">本文假设您了解Apache Kafka、机器学习和Python的基础知识。</p><p id="6751" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">交易可以表示任何相关信息，以便实时分析并预测是否有异常情况，如信用卡交易、GPS日志、系统消耗指标等。</p><h1 id="6794" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated"><strong class="ak"> 1。项目结构:</strong></h1><p id="14c8" class="pw-post-body-paragraph kx ky iq kz b la na jr lc ld nb ju lf lg nc li lj lk nd lm ln lo ne lq lr ls ij bi translated">我们的项目结构将是这样的，你可以在这里得到完整的代码:</p><pre class="kh ki kj kk gt nf ng nh ni aw nj bi"><span id="1e6d" class="nk mj iq ng b gy nl nm l nn no">git clone <a class="ae kw" href="https://github.com/rodrigo-arenas/kafkaml-anomaly-detection.git" rel="noopener ugc nofollow" target="_blank">https://github.com/rodrigo-arenas/kafkaml-anomaly-detection.git</a></span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi np"><img src="../Images/5457fe5e9768c71656ad6b93c4fae5b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*Y4Ij2gWLuI6FDzAnFZOaQg.png"/></div></figure><p id="1793" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">首先查看settings.py它有一些我们需要设置的变量，比如Kafka broker主机和端口；您可以保留默认设置(监听本地主机以及Kafka和zookeeper的默认端口)。</p><p id="6464" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">streaming/utils.py文件包含创建Kafka消费者和生产者的配置；它有一些默认选项，如果需要，您也可以更改。</p><p id="503f" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">现在安装要求:</p><pre class="kh ki kj kk gt nf ng nh ni aw nj bi"><span id="39a7" class="nk mj iq ng b gy nl nm l nn no">pip install -r requirements.txt</span></pre><h1 id="5f8f" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated"><strong class="ak"> 2。训练模型</strong></h1><p id="e60e" class="pw-post-body-paragraph kx ky iq kz b la na jr lc ld nb ju lf lg nc li lj lk nd lm ln lo ne lq lr ls ij bi translated">为了说明如何设置这个解决方案，我们将生成随机数据；它会有两个变量，它们看起来像这样:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/b78ef7fe3a04a4db552d2446b6499444.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*_Jh3YaMYXqHBeIp9kE7tBQ.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">异常检测数据。图片由作者提供。</p></figure><p id="40c7" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">接下来，我们将使用一个<a class="ae kw" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html#sklearn.ensemble.IsolationForest" rel="noopener ugc nofollow" target="_blank">隔离森林</a>模型来检测离群值；简而言之，该模型将通过跟踪(采样)变量轴上的随机线来尝试隔离数据点，并在几次迭代后，测量隔离每个观察值的“难度”,因此在train.py文件中我们有:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="c8ef" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">运行这个之后，应该会创建isolation_forest.joblib文件；这是经过训练的模型。</p><h1 id="7456" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">3.创建主题</h1><p id="c35f" class="pw-post-body-paragraph kx ky iq kz b la na jr lc ld nb ju lf lg nc li lj lk nd lm ln lo ne lq lr ls ij bi translated">我们将使用两个主题；第一个称为“事务”，生产者将发送新的事务记录。让我们使用以下命令从终端创建它:</p><pre class="kh ki kj kk gt nf ng nh ni aw nj bi"><span id="0e51" class="nk mj iq ng b gy nl nm l nn no">kafka-topics.sh --zookeeper localhost:2181 --topic transactions --create --partitions 3 --replication-factor 1</span></pre><p id="8bd7" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">第二个主题将被称为“异常”，检测到异常的模块将在这里发送数据，最后一个消费者将读取数据以发送一个松弛通知:</p><pre class="kh ki kj kk gt nf ng nh ni aw nj bi"><span id="2985" class="nk mj iq ng b gy nl nm l nn no">kafka-topics.sh --zookeeper localhost:2181 --topic anomalies --create --partitions 3 --replication-factor 1</span></pre><h1 id="96bf" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">4.交易生成者:</h1><p id="0dc0" class="pw-post-body-paragraph kx ky iq kz b la na jr lc ld nb ju lf lg nc li lj lk nd lm ln lo ne lq lr ls ij bi translated">现在，我们将生成第一个向Kafka主题“transactions”发送新数据的生成器；我们将使用合流-卡夫卡包；在文件streaming/producer.py中，我们有:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="879b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">有了这段代码，一个生产者会向一个卡夫卡主题发送数据，概率为OUTLIERS _ GENERATION _ PROBABILITY；数据将来自“异常值生成器”，将发送自动增量id、机器学习模型所需的数据和UTC中的当前时间。</p><p id="14f4" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">让我们检查到目前为止一切都是正确的，运行producer.py文件，并作为消费者从终端登录到主题:</p><pre class="kh ki kj kk gt nf ng nh ni aw nj bi"><span id="bc6a" class="nk mj iq ng b gy nl nm l nn no">kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 --topic transactions</span></pre><p id="336d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">您应该会看到这样的传入消息:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt ns l"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">交易生成者。作者Gif。</p></figure><h1 id="2ee4" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">5.异常值检测器消费者:</h1><p id="93dc" class="pw-post-body-paragraph kx ky iq kz b la na jr lc ld nb ju lf lg nc li lj lk nd lm ln lo ne lq lr ls ij bi translated">数据来了！现在，我们必须从消费者那里读取它，将其传递给机器学习模型以进行预测，并过滤离群值。这是在如下所示的streaming/anomalies _ detector . py文件中完成的:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="8902" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">消费者阅读来自“交易”主题的消息，并且消费者向“异常”主题发送离群值；除了我们已经拥有的数据之外，它还将通过模型给出的分数来丰富记录，这是一种衡量数据“有多少”被视为异常值的方法。</p><p id="3c71" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">请注意，只有那些预测输出为-1的消息才会转到新主题；这就是这个模型将数据归类为内联者的方式。</p><p id="14bd" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">另外，注意这个主题有三个分区，所以在最后，我使用多重处理来模拟三个独立的消费者，并加快这个过程；它们都属于同一个group_id。在生产中，这些消费者可能会在不同的服务器上运行。</p><p id="0ac1" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">让我们检查这一步，确保生成器正在运行并运行anomalies_detector.py文件，现在在终端中，让我们打开异常主题，我们应该看到模型预测为异常值的传入事务，它应该如下所示:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nu ns l"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">异常检测。作者Gif。</p></figure><p id="6282" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这里有一个事务生产者和异常值检测如何同时运行的可视化；顶部窗口是事务生产者主题，底部窗口是发送到异常主题的离群值。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nv ns l"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">实时异常检测。作者Gif。</p></figure><h1 id="925b" class="mi mj iq bd mk ml mm mn mo mp mq mr ms jw mt jx mu jz mv ka mw kc mx kd my mz bi translated">5.时差通知:</h1><p id="f69b" class="pw-post-body-paragraph kx ky iq kz b la na jr lc ld nb ju lf lg nc li lj lk nd lm ln lo ne lq lr ls ij bi translated">最后一步，我们希望对这些检测到的异常值采取一些措施；在现实生活中，它可以阻止交易、扩展服务器、生成建议、向管理用户发送警报等。</p><p id="77bb" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这里，我们将向一个松弛通道发送一个警报；为此，请确保创建一个slack应用程序，将该应用程序添加到slack通道，并注册一个名为SLACK_API_TOKEN的环境变量来验证SLACK。这里是<a class="ae kw" href="https://api.slack.com/start" rel="noopener ugc nofollow" target="_blank">相关文档。</a></p><p id="d089" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">现在我们使用文件streaming/bot _ alerts . py；代码如下:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="9181" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">所以在这里，脚本创建了一个新的消费者，但是它订阅了“异常”主题；一旦消息到达，它将使用Slack API发送消息；对于这个演示，我发送了相同的原始消息(尽量使它更漂亮！).传入的消息如下所示:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nw ns l"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">宽限通知。作者Gif。</p></figure><p id="23ce" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">原来如此；解决方案已经启动并运行！我希望这对你有用。请记住，完整的代码在这里:</p><div class="nx ny gp gr nz oa"><a href="https://github.com/rodrigo-arenas/kafkaml-anomaly-detection" rel="noopener  ugc nofollow" target="_blank"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd ir gy z fp of fr fs og fu fw ip bi translated">Rodrigo-arenas/kaf kaml-异常检测</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">使用Kafka和python的实时异常检测项目</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">github.com</p></div></div><div class="oj l"><div class="ok l ol om on oj oo kq oa"/></div></div></a></div><p id="e524" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我想留下一些关于这个特定实现的最后考虑:</p><ul class=""><li id="9e31" class="lu lv iq kz b la lb ld le lg lw lk lx lo ly ls lz ma mb mc bi translated">我在本地机器上进行所有的设置和运行，选择多少分区、消费者、代理、zookeeper服务器和要设置的副本(以及其他配置)是您必须根据您的业务特征、数据生成速率、可用资源等进行分析的事情。我在演示中使用了足够小的数字。</li><li id="5ae1" class="lu lv iq kz b la md ld me lg mf lk mg lo mh ls lz ma mb mc bi translated">我使用scikit-learn和“纯”Python来处理数据流，但根据消息量/生产率，可能有必要使用流处理功能，如<a class="ae kw" href="https://spark.apache.org/docs/latest/streaming-kafka-0-10-integration.html" rel="noopener ugc nofollow" target="_blank"> spark streaming </a>。</li><li id="e56c" class="lu lv iq kz b la md ld me lg mf lk mg lo mh ls lz ma mb mc bi translated">你必须知道的还有对<a class="ae kw" href="https://api.slack.com/docs/rate-limits" rel="noopener ugc nofollow" target="_blank">松弛API </a>的限制。</li></ul></div></div>    
</body>
</html>