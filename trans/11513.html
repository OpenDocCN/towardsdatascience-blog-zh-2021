<html>
<head>
<title>How to build an MLOps pipeline for hyperparameter tuning in Vertex AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在Vertex AI中构建用于超参数调整的MLOps管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-an-mlops-pipeline-for-hyperparameter-tuning-in-vertex-ai-45cc2faf4ff5?source=collection_archive---------12-----------------------#2021-11-13">https://towardsdatascience.com/how-to-build-an-mlops-pipeline-for-hyperparameter-tuning-in-vertex-ai-45cc2faf4ff5?source=collection_archive---------12-----------------------#2021-11-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4334" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">为超参数调整设置模型和orchestrator的最佳实践</h2></div><p id="6752" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当你设计一个机器学习模型时，有许多超参数——学习速率、批量大小、神经网络的层数/节点数、桶数、嵌入维数等。你基本上是猜的。通过找到这些超参数的最佳值，通常会比最初的猜测有2-10%的改进。(当然，这取决于您最初的猜测有多糟糕，但我会假设您做出了一些有根据的猜测)。</p><p id="82c5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在之前的一篇文章中，我建议你使用Jupyter笔记本进行实验，但是一旦事情稳定下来，就使用普通的Python文件。这样做可以区分ML开发和MLOps之间的职责。因此，假设您已经这样做了，并且您的模型训练文件以<a class="ae lb" href="https://github.com/GoogleCloudPlatform/data-science-on-gcp/blob/edition2/09_vertexai/model.py" rel="noopener ugc nofollow" target="_blank"> model.py </a>的形式存在，您的管道编排器以<a class="ae lb" href="https://github.com/GoogleCloudPlatform/data-science-on-gcp/blob/edition2/09_vertexai/train_on_vertexai.py" rel="noopener ugc nofollow" target="_blank"> train_on_vertexai.py </a>的形式存在。在阅读本文时，您可能会发现使用这两个链接中的代码很有帮助。</p><h2 id="29d9" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">1.在model.py中参数化您的模型</h2><p id="10f3" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">第一步是为您的模型创建超参数命令行参数。例如，在model.py中，我们可能会这样做:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="6978" class="lc ld iq mf b gy mj mk l ml mm">parser.add_argument(<br/>        '--nembeds',<br/>        help='Embedding dimension for categorical variables',<br/>        type=int,<br/>        default=3<br/>    )</span></pre><p id="1a73" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，变量的初始猜测值是默认值。这允许您的训练脚本像以前一样继续工作。然后，通过命令行参数设置该变量，供训练脚本使用:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="d87f" class="lc ld iq mf b gy mj mk l ml mm">args = parser.parse_args()<br/>...<br/>NEMBEDS = args['nembeds']</span></pre><p id="2a69" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对您现在或将来可能想要调优的所有超参数都这样做。一个好的做法是在model.py中不要有任何硬编码的值——那里的所有东西都需要一个输入参数。</p><h2 id="c032" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">2.实施更短的训练运行</h2><p id="7077" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">通常，您的训练运行将涉及在整个数据集上进行训练，然后在整个测试数据集上进行评估。为超参数调整进行完整的训练运行是昂贵的、浪费的和错误的。为什么？</p><p id="a5d2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">贵:</strong>超参数调优的重点是获得最佳的一组参数，而不是获得可能的最佳模型。一旦你找到了最好的参数，你就可以用这些参数来训练一个模型。因此，没有必要进行完整的试验。你只需要训练它，直到你知道哪个试验可能会更好。</p><figure class="ma mb mc md gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mn"><img src="../Images/cfb128ac2dd8387ada4011705d594514.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*emQW9oQg2gENJ2v5Nnp9FQ.png"/></div></div><p class="mv mw gj gh gi mx my bd b be z dk translated">为超参数调整进行完整的训练运行是昂贵的、浪费的和错误的。作者图解。</p></figure><p id="287d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">浪费:</strong>在假设你的训练曲线表现良好的情况下，在整个训练过程中，一组更好的参数会更好，你可以在它开始收敛之前很好地停止训练。用你的训练预算做更多的试验，而不是延长试验时间。</p><p id="facd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">错误:</strong>您不想评估测试数据集上的超参数调优。您希望比较验证数据集的性能。只需确保验证数据集足够大，让您能够在试验模型之间进行有意义的比较。</p><p id="85c6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我做这些修改的方法是在我的model.py中添加两个选项:一个用于较短时间的训练，另一个用于跳过完整的评估:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="6b4b" class="lc ld iq mf b gy mj mk l ml mm">NUM_EXAMPLES = args['num_examples']<br/>SKIP_FULL_EVAL = args['skip_full_eval']<br/>...</span><span id="691d" class="lc ld iq mf b gy mz mk l ml mm">steps_per_epoch = NUM_EXAMPLES // train_batch_size<br/>epochs = NUM_EPOCHS<br/>eval_dataset = read_dataset(eval_data_pattern, eval_batch_size,<br/>                    tf.estimator.ModeKeys.EVAL, <strong class="mf ir">num_eval_examples</strong>)<br/>model.fit(train_dataset,<br/>                        validation_data=eval_dataset,<br/>                        epochs=NUM_EPOCHS,<br/>                        <strong class="mf ir">steps_per_epoch=steps_per_epoch,</strong><br/>                        callbacks=[cp_callback, HpCallback()])<br/>...</span><span id="55e1" class="lc ld iq mf b gy mz mk l ml mm">if not SKIP_FULL_EVAL:<br/>        test_dataset = read_dataset(test_data_pattern, eval_batch_size, tf.estimator.ModeKeys.TEST, None)<br/>        final_metrics = model.evaluate(test_dataset)<br/>        ...<br/>else:<br/>        logging.info("Skipping evaluation on full test dataset")</span></pre><p id="8a18" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">steps_per_epoch和NUM_EXAMPLES是怎么回事？注意上图中的x轴。这不是时代，而是例子的数量。虽然在完整数据集上进行训练是非常浪费的，但获得与完整训练相同数量的中间指标是有帮助的(我将在下一步解释原因)。因为您还将超参数调整批量大小，所以最好的方法是使用<em class="na">虚拟时期</em>(参见<a class="ae lb" href="https://amzn.to/31T9RRL" rel="noopener ugc nofollow" target="_blank">机器学习设计模式书</a>:检查点了解详情)。每历元步数是我们在大型数据集上获取虚拟历元的方法。</p><h2 id="0284" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">3.在培训期间写出衡量标准</h2><p id="e736" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">在培训过程中写出衡量标准。不要只是等到最后。如果你这样做了，那么Vertex AI也将通过缩短非生产性试验来帮助你节省成本。</p><p id="4ff9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在Keras中，要在培训期间写出指标，可以使用回调。看起来是这样的:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="8f35" class="lc ld iq mf b gy mj mk l ml mm">METRIC = 'val_rmse'<br/>hpt = hypertune.HyperTune()</span><span id="ec2b" class="lc ld iq mf b gy mz mk l ml mm"><strong class="mf ir">class HpCallback</strong>(tf.keras.callbacks.Callback):<br/>        def on_epoch_end(self, epoch, logs=None):<br/>            if logs and METRIC in logs:<br/>                logging.info("Epoch {}: {} = {}".format(epoch, METRIC, logs[METRIC]))<br/>                hpt.report_hyperparameter_tuning_metric(<br/>hyperparameter_metric_tag=METRIC, metric_value=logs[METRIC], global_step=epoch)</span><span id="79e4" class="lc ld iq mf b gy mz mk l ml mm">...</span><span id="9fcb" class="lc ld iq mf b gy mz mk l ml mm">history = model.fit(train_dataset,<br/>                    ...<br/>                    callbacks=[cp_callback, <strong class="mf ir">HpCallback()</strong>])</span></pre><p id="d6a4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我正在使用cloudml-hypertune包来简化以TensorFlow生态系统(TensorBoard、Vizier等)的形式编写指标。)可以理解。</p><h2 id="94e0" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">4.实现超参数调整管道</h2><p id="5ad8" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">现在您已经修改了model.py，使其易于进行超参数调整，MLOps人员可以随时调整您的模型，只要他们注意到它在漂移。</p><p id="4d90" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">编排代码中有两个步骤(在train_on_vertexai.py中):</p><p id="d52e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> (4a) </strong>创建一个顶点AI CustomJob，用正确的参数调用你的model.py:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="3495" class="lc ld iq mf b gy mj mk l ml mm">    tf_version = '2-' + tf.__version__[2:3]<br/>    train_image = "us-docker.pkg.dev/vertex-ai/training/tf-gpu.{}:latest".format(tf_version)</span><span id="65c9" class="lc ld iq mf b gy mz mk l ml mm">    model_display_name = '{}-{}'.format(ENDPOINT_NAME, timestamp)<br/>    trial_job = aiplatform.CustomJob.from_local_script(<br/>        display_name='train-{}'.format(model_display_name),<br/>        <strong class="mf ir">script_path="model.py",</strong><br/>        container_uri=train_image,<br/>        <strong class="mf ir">args=[<br/>            '--bucket', BUCKET,<br/>            '--skip_full_eval', # no need to evaluate on test data<br/>            '--num_epochs', '10',<br/>            '--num_examples', '500000' # 1/10 actual size<br/>        ],</strong><br/>        requirements=['cloudml-hypertune'],  <strong class="mf ir"># hpt</strong><br/>        replica_count=1,<br/>        machine_type='n1-standard-4',<br/>        # See <a class="ae lb" href="https://cloud.google.com/vertex-ai/docs/general/locations#accelerators" rel="noopener ugc nofollow" target="_blank">https://cloud.google.com/vertex-ai/docs/general/locations#accelerators</a><br/>        accelerator_type=aip.AcceleratorType.NVIDIA_TESLA_T4.name,<br/>        accelerator_count=1,<br/>    )</span></pre><p id="ef2b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> (4b) </strong>创建并运行一个超参数调整作业，该作业将使用上述作业作为单独试验:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="35d9" class="lc ld iq mf b gy mj mk l ml mm">   hparam_job = aiplatform.HyperparameterTuningJob(<br/>        # See <a class="ae lb" href="https://googleapis.dev/python/aiplatform/latest/aiplatform.html#" rel="noopener ugc nofollow" target="_blank">https://googleapis.dev/python/aiplatform/latest/aiplatform.html#</a><br/>        display_name='hparam-{}'.format(model_display_name),<br/>        custom_job=trial_job,<br/>        <strong class="mf ir">metric_spec={'val_rmse': 'minimize'},</strong><br/>        parameter_spec={<br/>            <strong class="mf ir">"train_batch_size": hpt.IntegerParameterSpec(min=16, max=256, scale='log'),<br/>            "nbuckets": hpt.IntegerParameterSpec(min=5, max=10, scale='linear'),<br/>            "dnn_hidden_units": hpt.CategoricalParameterSpec(values=["64,16", "64,16,4", "64,64,64,8", "256,64,16"])</strong><br/>        },<br/>        max_trial_count=4 if develop_mode else 10,<br/>        parallel_trial_count=2,<br/>        search_algorithm=None,  # Bayesian<br/>    )<br/></span></pre><p id="8aed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，我在这里指定的指标与我的model.py中的指标相匹配，并且我指定了参数的范围。</p><p id="73dd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">默认情况下，Vertex AI中的超参数调优服务(称为Vizier)将使用贝叶斯优化，但如果你愿意，可以将算法更改为GridSearch。</p><h2 id="4bbc" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">5.监控GCP web控制台</h2><p id="1b5f" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">一旦你启动超参数调优工作，你可以在GCP控制台的顶点人工智能部分看到参数进来。</p><p id="13b9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您会看到类似这样的内容:</p><figure class="ma mb mc md gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nb"><img src="../Images/51d6c9bf43e97b3736d28261b59ca02c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oHi86Gd51VysMJWH"/></div></div></figure><h2 id="e981" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">6.运行最佳试验直至完成</h2><p id="882f" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">确定最佳参数集后，采用最佳参数集，然后运行训练作业直到完成。这将为您提供部署模型。</p><p id="7e4d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当然，我们也可以实现自动化:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="054c" class="lc ld iq mf b gy mj mk l ml mm">    best = sorted(hparam_job.trials, <br/>              key=lambda x: x.final_measurement.metrics[0].value)[0]<br/>    logging.info('Best trial: {}'.format(best))<br/>    best_params = []<br/>    for param in best.parameters:<br/>        best_params.append('--{}'.format(param.parameter_id))<br/>        best_params.append(param.value)</span><span id="4ec8" class="lc ld iq mf b gy mz mk l ml mm">    # run the best trial to completion<br/>    model = train_custom_model(data_set, timestamp, develop_mode, extra_args=best_params)</span></pre><p id="330b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">同样，通过Vertex AI，数据科学家(决定哪些参数可以优化)和MLOps工程师(决定何时重新调整模型)之间的职责分离变得更加容易。</p><p id="6278" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽情享受吧！</p><h1 id="7ab9" class="nc ld iq bd le nd ne nf lh ng nh ni lk jw nj jx ln jz nk ka lq kc nl kd lt nm bi translated">更多关于Vertex AI的阅读:</h1><ol class=""><li id="1cb6" class="nn no iq kh b ki lv kl lw ko np ks nq kw nr la ns nt nu nv bi translated"><a class="ae lb" rel="noopener" target="_blank" href="/giving-vertex-ai-the-new-unified-ml-platform-on-google-cloud-a-spin-35e0f3852f25">给谷歌云上的新统一ML平台Vertex AI一个旋转</a> : <br/>我们为什么需要它，无代码ML培训到底有多好，所有这些对数据科学工作意味着什么？</li><li id="4b1b" class="nn no iq kh b ki nw kl nx ko ny ks nz kw oa la ns nt nu nv bi translated"><a class="ae lb" rel="noopener" target="_blank" href="/how-to-deploy-a-tensorflow-model-to-vertex-ai-87d9ae1df56">如何将TensorFlow模型部署到Vertex AI </a>:在Vertex AI中使用保存的模型和端点</li><li id="3c5b" class="nn no iq kh b ki nw kl nx ko ny ks nz kw oa la ns nt nu nv bi translated"><a class="ae lb" href="https://medium.com/@lakshmanok/developing-and-deploying-a-machine-learning-model-on-vertex-ai-using-python-865b535814f8" rel="noopener">使用Python在Vertex AI上开发和部署机器学习模型</a>:编写让你的MLOps团队满意的训练管道</li><li id="6451" class="nn no iq kh b ki nw kl nx ko ny ks nz kw oa la ns nt nu nv bi translated"><a class="ae lb" href="https://lakshmanok.medium.com/how-to-build-an-mlops-pipeline-for-hyperparameter-tuning-in-vertex-ai-45cc2faf4ff5" rel="noopener">如何在Vertex AI中为超参数调整构建MLOps管道</a> : <br/>为超参数调整设置模型和协调器的最佳实践</li></ol></div></div>    
</body>
</html>