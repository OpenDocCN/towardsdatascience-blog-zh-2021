<html>
<head>
<title>Pytorch Model Visual Interpretation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pytorch模型视觉解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pytorch-model-visual-interpretation-7133383bb6ae?source=collection_archive---------23-----------------------#2021-06-16">https://towardsdatascience.com/pytorch-model-visual-interpretation-7133383bb6ae?source=collection_archive---------23-----------------------#2021-06-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="23cf" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用Captum解释Pytorch模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7b97f4d61454a7c2249c12992c56465b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pKK4C1XQll-JA71pC382zw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:作者</p></figure><p id="ae23" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Pytorch是一个开源的python库，用于创建深度学习/机器学习模型，是继TensorFlow之后使用最多的库之一。它基于Torch库，主要用于计算机视觉和NLP应用。</p><p id="f333" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">根据我们正在开发的应用程序，我们可以使用不同的预训练PyTorch模型。但问题是，我们真的了解这个黑匣子里到底有什么吗？模型解释很重要，因为我们需要了解模型是如何工作的，以及我们如何改进模型。</p><p id="d38b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Captum是一个开源python库，用于解释PyTorch模型。它在模型理解和可解释性方面创造了透明性。它有助于理解数据所具有的最重要的特征，以及它如何影响模型的输出。</p><p id="a1b7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们将为PyTorch模型解释创建一个Captum insights仪表板。</p><p id="e86b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们开始吧…</p><h1 id="bafc" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">安装所需的库</h1><p id="1f7d" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">我们将从使用pip安装flask_compress和Captum开始。下面给出的命令可以做到这一点。</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="8bdd" class="mw lv it ms b gy mx my l mz na">!pip install flask_compress <br/>!pip install captum</span></pre><h1 id="177f" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">导入所需的库</h1><p id="c0c7" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">在这一步中，我们将导入创建PyTorch模型所需的库和用于模型解释的Captum仪表板。在这篇文章中，我不会讨论如何创建一个模型。</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="22d4" class="mw lv it ms b gy mx my l mz na">import os</span><span id="7476" class="mw lv it ms b gy nb my l mz na">import torch<br/>import torch.nn as nn<br/>import torchvision<br/>import torchvision.transforms as transforms</span><span id="e69e" class="mw lv it ms b gy nb my l mz na">from captum.insights import AttributionVisualizer, Batch<br/>from captum.insights.attr_vis.features import ImageFeature</span></pre><h1 id="8a53" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">创建模型</h1><p id="9aa5" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">对于本文，我将使用一个预先训练好的模型来创建我们的模型。</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="3e09" class="mw lv it ms b gy mx my l mz na">def get_classes():<br/>    classes = [<br/>        "Plane",<br/>        "Car",<br/>        "Bird",<br/>        "Cat",<br/>        "Deer",<br/>        "Dog",<br/>        "Frog",<br/>        "Horse",<br/>        "Ship",<br/>        "Truck",<br/>    ]<br/>    return classes</span><span id="e5b7" class="mw lv it ms b gy nb my l mz na">def get_pretrained_model():<br/>    class Net(nn.Module):<br/>        def __init__(self):<br/>            super(Net, self).__init__()<br/>            self.conv1 = nn.Conv2d(3, 6, 5)<br/>            self.pool1 = nn.MaxPool2d(2, 2)<br/>            self.pool2 = nn.MaxPool2d(2, 2)<br/>            self.conv2 = nn.Conv2d(6, 16, 5)<br/>            self.fc1 = nn.Linear(16 * 5 * 5, 120)<br/>            self.fc2 = nn.Linear(120, 84)<br/>            self.fc3 = nn.Linear(84, 10)<br/>            self.relu1 = nn.ReLU()<br/>            self.relu2 = nn.ReLU()<br/>            self.relu3 = nn.ReLU()<br/>            self.relu4 = nn.ReLU()</span><span id="4c00" class="mw lv it ms b gy nb my l mz na">def forward(self, x):<br/>            x = self.pool1(self.relu1(self.conv1(x)))<br/>            x = self.pool2(self.relu2(self.conv2(x)))<br/>            x = x.view(-1, 16 * 5 * 5)<br/>            x = self.relu3(self.fc1(x))<br/>            x = self.relu4(self.fc2(x))<br/>            x = self.fc3(x)<br/>            return x</span><span id="5774" class="mw lv it ms b gy nb my l mz na">net = Net()<br/>    net.load_state_dict(torch.load("cifar_torchvision.pt"))<br/>    return net</span><span id="90a1" class="mw lv it ms b gy nb my l mz na">def baseline_func(input):<br/>    return input * 0</span><span id="cce3" class="mw lv it ms b gy nb my l mz na">def formatted_data_iter():<br/>    dataset = torchvision.datasets.CIFAR10(<br/>        root="data/test", train=False, download=True, transform=transforms.ToTensor()<br/>    )<br/>    dataloader = iter(<br/>        torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=False, num_workers=2)<br/>    )<br/>    while True:<br/>        images, labels = next(dataloader)<br/>        yield Batch(inputs=images, labels=labels)</span></pre><h1 id="ebdc" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">创建模型解释仪表板</h1><p id="f3d5" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">这是最后一步，将创建用于模型理解和解释的仪表板。</p><pre class="kj kk kl km gt mr ms mt mu aw mv bi"><span id="2bb8" class="mw lv it ms b gy mx my l mz na">normalize = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))<br/>model = get_pretrained_model()<br/>visualizer = AttributionVisualizer(<br/>    models=[model],<br/>    score_func=lambda o: torch.nn.functional.softmax(o, 1),<br/>    classes=get_classes(),<br/>    features=[<br/>        ImageFeature(<br/>            "Photo",<br/>            baseline_transforms=[baseline_func],<br/>            input_transforms=[normalize],<br/>        )<br/>    ],<br/>    dataset=formatted_data_iter(),<br/>)</span><span id="f3a5" class="mw lv it ms b gy nb my l mz na">#Visualize Model<br/>visualizer.render()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/1a22b92536467da57013c4047058cd2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-2xeUdqXD83nYVWjYvQGrg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">仪表板(来源:作者)</p></figure><p id="3306" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这里，您可以清楚地看到模型是如何工作的，您可以选择您想要解释的类，类似地选择归因方法和参数。它清楚地显示了归属量级、标签和预测。</p><p id="ecd8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">继续尝试使用不同的数据集，并创建漂亮的Captum仪表板来解释模型。如果您发现任何困难，请在回复部分告诉我。</p><p id="da5f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本文是与<a class="nd ne ep" href="https://medium.com/u/40808d551f5a?source=post_page-----7133383bb6ae--------------------------------" rel="noopener" target="_blank"> Piyush Ingale </a>合作完成的。</p><h1 id="b410" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">在你走之前</h1><p id="273e" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated"><strong class="la iu"> <em class="nf">感谢</em> </strong> <em class="nf">的阅读！如果你想与我取得联系，请随时通过hmix13@gmail.com联系我或我的</em> <a class="ae ng" href="http://www.linkedin.com/in/himanshusharmads" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> <em class="nf"> LinkedIn个人资料</em> </strong> </a> <em class="nf">。可以查看我的</em><a class="ae ng" href="https://github.com/hmix13" rel="noopener ugc nofollow" target="_blank"><strong class="la iu"><em class="nf">Github</em></strong><em class="nf"/></a><em class="nf">简介针对不同的数据科学项目和包教程。还有，随意探索</em> <a class="ae ng" href="https://medium.com/@hmix13" rel="noopener"> <strong class="la iu"> <em class="nf">我的简介</em> </strong> </a> <em class="nf">，阅读我写过的与数据科学相关的不同文章。</em></p></div></div>    
</body>
</html>