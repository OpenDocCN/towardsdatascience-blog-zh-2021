<html>
<head>
<title>K-Means Clustering: Concepts and Implementation in R for Data Science</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">K-Means聚类:数据科学R中的概念和实现</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/k-means-clustering-concepts-and-implementation-in-r-for-data-science-32cae6a3ceba?source=collection_archive---------3-----------------------#2021-06-10">https://towardsdatascience.com/k-means-clustering-concepts-and-implementation-in-r-for-data-science-32cae6a3ceba?source=collection_archive---------3-----------------------#2021-06-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1213" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">介绍如何理解用R实现的kmeans并选择最佳的K</h2></div><p id="18c6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">机器学习中的聚类算法是无监督的技术(那些有输入数据但没有标记响应的技术)。他们的目标是绘制数据模式，并根据相似性将数据观察结果分成不同的组。K-Means聚类是实现成功汇总高维数据的聚类算法的一种方式。</p><blockquote class="lb lc ld"><p id="e21c" class="kf kg le kh b ki kj jr kk kl km ju kn lf kp kq kr lg kt ku kv lh kx ky kz la ij bi translated">K-means聚类将一组观察值划分为固定数量的聚类，这些聚类最初是基于它们的相似特征指定的。</p></blockquote><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi li"><img src="../Images/1dd1fe2a027b677c8819812b6e8c0ab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qHAqssu5zDlrs3YvMJcEQA.jpeg"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated"><a class="ae ly" href="https://unsplash.com/@vinomamba24?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Vino Li </a>在<a class="ae ly" href="https://unsplash.com/collections/1218220/animal-references?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="7d08" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，问题出现了，对群体的观察:</p><p id="6387" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">1)事物彼此相似是什么意思？</p><p id="e8ca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2)我们如何确定事物之间的距离是否足够近，可以归为一组？</p><p id="83d5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">回答这两个问题，决定最佳K，理解K-means概念并在R中的数据集上实现它是这篇博客的范围。</p><p id="9df5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦我们定义了<strong class="kh ir"> a)我们需要的聚类数量，b)定位我们的聚类(质心)的初始猜测，以及c)距离度量</strong>，我们就可以应用K-means来获得聚类质心的最终估计和质心的每个观察的分配。</p><h2 id="64eb" class="lz ma iq bd mb mc md dn me mf mg dp mh ko mi mj mk ks ml mm mn kw mo mp mq mr bi translated"><strong class="ak">理解算法:</strong></h2><p id="1cf0" class="pw-post-body-paragraph kf kg iq kh b ki ms jr kk kl mt ju kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">为了便于理解，让我们假设我们有一个总共有10个观察值的数据集。查看数据，我们可以得出结论，数据可以很容易地分为3个不同的集群，所以我们用这个。</p><p id="6f27" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们选择我们想要对数据进行分类的聚类数(这是K-means中的K)。这里，让我们决定K = 3，因为这是可以直观推断的；一会儿我们将讨论确定K的技术方法。</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/3e360d5cc15f924571f2e463e047ad4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*edsqmxBq7qbN1eV1vIDwIg.png"/></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">样本数据集(图片由作者提供)</p></figure><p id="10c3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下一步是随机决定三个不同的初始数据点，作为我们的聚类或图表上的“质心”，如下图中的彩色三角形所示。然后，我们测量“1”数据点和三个质心之间的距离，并为其指定最接近的质心的颜色。这将被重复，直到所有的数据点都被分配给任何一个质心。</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi my"><img src="../Images/db47309905e4711274e9017ac0471bfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lmg5WIzOtww6do9dFW3Edw.png"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">选择随机的K形心(图片由作者提供)</p></figure><p id="058c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们计算每个聚类的平均值，它对应于每个质心的数据点。这个平均值现在是每个质心的新位置，我们在图上重新定位它们，如下所示。我们计算每个点与所有质心的距离并相应地给它们着色的部分将再次重复，直到质心的位置不再改变。下面的图表是我们期望得到的，一旦没有更多的变化。</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi mz"><img src="../Images/30af89ce5bba3c207e552ea2ec42ad81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0v0DKPxc-czjShFeBJoHUw.png"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">将质心重新定位到它们的聚类点(图片由作者提供)</p></figure><p id="8a52" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是K-means如何基于距离度量将我们的数据集分割成指定数量的聚类。我们在二维图中使用的距离度量是欧几里德距离(x + y的平方根)。</p><h2 id="519e" class="lz ma iq bd mb mc md dn me mf mg dp mh ko mi mj mk ks ml mm mn kw mo mp mq mr bi translated">在R中实现K-means:</h2><p id="c04c" class="pw-post-body-paragraph kf kg iq kh b ki ms jr kk kl mt ju kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated"><strong class="kh ir">第一步:安装相关的包并调用它们的库</strong></p><pre class="lj lk ll lm gt na nb nc nd aw ne bi"><span id="e285" class="lz ma iq nb b gy nf ng l nh ni">install.packages("dplyr")<br/>install.packages("ggplot2")<br/>install.packages("ggfortify")</span><span id="db94" class="lz ma iq nb b gy nj ng l nh ni">library("ggplot2")<br/>library("dplyr")<br/>library("ggfortify")</span></pre><p id="0bb9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">第二步:加载并理解数据集</strong></p><p id="280c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Iris是一个内置的数据集，它包含来自3种不同类型的鸢尾物种(<em class="le">鸢尾</em>、<em class="le">杂色</em>和<em class="le">海滨鸢尾</em>)的150个花朵观察结果。我们将用它来进行算法测试。</p><pre class="lj lk ll lm gt na nb nc nd aw ne bi"><span id="2a39" class="lz ma iq nb b gy nf ng l nh ni">summary(iris)<br/>head(iris)</span></pre><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/bea169facd844d384544296bac8877f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*pkV0cHEk6AjR3m7M7ANptA.png"/></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">(图片由作者提供)</p></figure><p id="ebad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">步骤3:消除目标变量</strong></p><p id="1ba9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于观察值的分类已经在这个数据集中完成，我们需要从代码中删除目标变量，因为我们希望我们的算法能够自己完成这项工作。为此，我将把iris的前四列加载到我的数据框‘data’中。</p><pre class="lj lk ll lm gt na nb nc nd aw ne bi"><span id="5366" class="lz ma iq nb b gy nf ng l nh ni">data &lt;- select(iris, c(1:4))</span></pre><blockquote class="lb lc ld"><p id="cc93" class="kf kg le kh b ki kj jr kk kl km ju kn lf kp kq kr lg kt ku kv lh kx ky kz la ij bi translated"><strong class="kh ir">如何确定K用什么值？</strong></p></blockquote><p id="6bdc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">第四步:肘穴手法</strong></p><p id="bee3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然有许多方法来决定要选择的聚类数，但广泛使用的是<strong class="kh ir"> <em class="le">肘点法</em> </strong>(虽然不是很准确，我们将看到为什么)。其思想是通过将每个聚类内的变化相加来评估聚类的质量(跟踪这一点并以不同的起点重新开始)，具有最小变化的参数获胜。肘点法绘制了变异减少与聚类数(K)的关系，肘点是K的一个数值，在此之后变异不是很陡，是我们的最佳K。</p><p id="6cf1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们没有一个内置的函数来衡量我们观察结果的变化程度。但是，有一个Rpubs文档为我们创建了一个wssplot函数(在组平方和图内)来实现我们的肘点方法。</p><pre class="lj lk ll lm gt na nb nc nd aw ne bi"><span id="425d" class="lz ma iq nb b gy nf ng l nh ni">wssplot &lt;- function(data, nc=15, seed=1234){<br/>  wss &lt;- (nrow(data)-1)*sum(apply(data,2,var))<br/>  for (i in 2:nc){<br/>    set.seed(seed)<br/>    wss[i] &lt;- sum(kmeans(data, centers=i)$withinss)}<br/>  plot(1:nc, wss, type="b", xlab="Number of Clusters",<br/>       ylab="Within groups sum of squares")<br/>  wss<br/>}</span></pre><p id="466a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该图显示了K = 2时的锐边，表明数据集的最佳聚类数为2。</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi nl"><img src="../Images/1e3997bc3aea5c9063f62fbcd8ca7306.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_7rI0Iui3y1sjbcxPv4jow.png"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">WSS情节(作者图片)</p></figure><p id="deb1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">第五步:实施K-means </strong></p><p id="2e1e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如它看起来那样简单，kmeans()只需要我们输入数据帧，并指定K来运行。</p><pre class="lj lk ll lm gt na nb nc nd aw ne bi"><span id="5cd9" class="lz ma iq nb b gy nf ng l nh ni">kmean &lt;- kmeans(data, 2)<br/>kmean$centers</span></pre><p id="b15f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">kmean$clusters将返回一个范围从1到2的数字向量，描述哪些观察值属于分类1和分类2。kmean$centers返回每个质心的位置。例如，聚类1具有萼片的平均值。长度= 5.00，萼片宽度= 3.36，花瓣。长度= 1.56，花瓣宽度= 0.29。</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi nm"><img src="../Images/f81cfeaec7817c9616bd1cc5356e1dfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*thMXsdo93X4RnmWdTl2jjg.png"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">(图片由作者提供)</p></figure><p id="7f84" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">步骤6:绘制聚类中的数据点</strong></p><p id="c3b4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管这个图看起来很棒，并且已经清楚地将我们的观察结果分成了2个组，但是我们已经知道我们的数据集总共有3个组。我们的肘点技术在给出正确的K值时并不完全准确。因此，根据经验，最好是在肘点周围的K值之间迭代，并自己决定最佳的行动方案。</p><pre class="lj lk ll lm gt na nb nc nd aw ne bi"><span id="03e6" class="lz ma iq nb b gy nf ng l nh ni">autoplot(kmean, data, frame = TRUE)</span></pre><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi nn"><img src="../Images/e05ea3867586fa7d2cec691105d7315c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8gxXZ8wduBjYnbWu4bbA-A.png"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">聚类后的数据图表，K = 2(图片由作者提供)</p></figure><p id="f205" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">第七步:K表示K = 3 </strong></p><p id="a835" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">既然我们已经决定改变K并查看数据模式，那么让我们看看结果是如何变化的。</p><pre class="lj lk ll lm gt na nb nc nd aw ne bi"><span id="bed7" class="lz ma iq nb b gy nf ng l nh ni">kmean &lt;- kmeans(data, 3)<br/>kmean$centers</span></pre><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi no"><img src="../Images/615e2235f57bb36e2b01eaf6125b6079.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P-03WedD6qhnfIr0bYgVvA.png"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">(图片由作者提供)</p></figure><p id="53b1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">步骤8:绘制新的聚类图</strong></p><p id="9f8e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们看到kmean$clusters现在如何将观察结果分成三个类，kmean$centers也更新了质心值。下图显示了基于3个集群的分组。同样，K规格取决于我们；确定K值的技术可以给我们一个很好的估计。</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi np"><img src="../Images/d208dcc2a6a1974b6926e43a5ab37d58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NYMl4CONWTwihYVGLMyt8Q.png"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">聚类后的数据图表，K = 3(图片由作者提供)</p></figure><p id="1e90" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">K-means是一种有效的机器学习技术，它:</p><ul class=""><li id="67a8" class="nq nr iq kh b ki kj kl km ko ns ks nt kw nu la nv nw nx ny bi translated">易于实施和应用</li><li id="64e8" class="nq nr iq kh b ki nz kl oa ko ob ks oc kw od la nv nw nx ny bi translated">具有很强的可解释性</li><li id="daa7" class="nq nr iq kh b ki nz kl oa ko ob ks oc kw od la nv nw nx ny bi translated">产生比分层聚类更紧密的聚类</li><li id="6acc" class="nq nr iq kh b ki nz kl oa ko ob ks oc kw od la nv nw nx ny bi translated">计算速度很快</li></ul><p id="4796" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，通过迭代方法手动选择<em class="le"> K、依赖于初始聚类以及由于离群值</em>导致的质心位置不准确是kmeans的一些缺点。这篇博文重点解释了kmeans的主要概念，讨论了一种确定K值的技术，用R实现了kmeans，并强调了它的一些优点和缺点。</p></div></div>    
</body>
</html>