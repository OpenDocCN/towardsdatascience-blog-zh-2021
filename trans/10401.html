<html>
<head>
<title>Machine Translation Evaluation with sacreBLEU and BERTScore</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于sacreBLEU和BERTScore的机器翻译评估</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-translation-evaluation-with-sacrebleu-and-bertscore-d7fdb0c47eb3?source=collection_archive---------14-----------------------#2021-10-04">https://towardsdatascience.com/machine-translation-evaluation-with-sacrebleu-and-bertscore-d7fdb0c47eb3?source=collection_archive---------14-----------------------#2021-10-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="29f5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">评估MT模型性能的两个有用的软件包</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/86c0bfdca912a8d2df5e0036a5c88953.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rumbfw6oca_lblNuRH3xng.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">汉娜·赖特在<a class="ae ky" href="https://unsplash.com/s/photos/language?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="df1a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过阅读本文，您将学会使用以下软件包评估您的机器翻译模型:</p><ul class=""><li id="9926" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">萨克勒布鲁</li><li id="eb2d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">贝特斯科尔</li></ul><p id="ac41" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">供您参考，BLEU(双语评估替角)是评估机器翻译文本最流行的指标之一。它可以用来评估任何语言的翻译，只要文本中存在某种形式的单词边界。</p><p id="35f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">BLEU的输出通常是0到100之间的分数，表示参考文本和假设文本之间的相似度值。值越高，翻译越好。</p><p id="05c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">话虽如此，BLEU的一个主要缺点是需要适当地标记文本。例如，您可以使用空格作为分隔符轻松标记任何英语句子。然而，对于缅甸语、汉语和泰语等语言来说，标记化可能具有挑战性。</p><p id="fb73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，也有人批评BLEU分数的提高并不能保证更好的翻译。当翻译的文本包含传达相同信息的相似单词或同义词时，这是相当明显的。例如，下面的句子从人类的角度来看实际上是相同的，但是当用BLEU评估它们时不会得到100分。</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="2eaa" class="mo mp it mk b gy mq mr l ms mt"># Reference text<br/>Hi, how are you?</span><span id="cd06" class="mo mp it mk b gy mu mr l ms mt"># Hypothesis text<br/>Hello, how are you?</span></pre></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="1851" class="nc mp it bd nd ne nf ng nh ni nj nk nl jz nm ka nn kc no kd np kf nq kg nr ns bi translated">萨克勒布鲁</h1><p id="6526" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">然而，让我们来探索如何使用<a class="ae ky" href="https://github.com/mjpost/sacrebleu" rel="noopener ugc nofollow" target="_blank"> sacreBLEU </a>轻松评估BLEU分数，它:</p><blockquote class="ny nz oa"><p id="7aec" class="kz la ob lb b lc ld ju le lf lg jx lh oc lj lk ll od ln lo lp oe lr ls lt lu im bi translated">…轻松计算可共享、可比较和可复制的<strong class="lb iu"> BLEU </strong>分数。</p></blockquote><h2 id="ad33" class="mo mp it bd nd of og dn nh oh oi dp nl li oj ok nn lm ol om np lq on oo nr op bi translated">装置</h2><p id="413c" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">强烈建议您在继续之前创建一个新的虚拟环境。激活它并运行以下命令来安装<code class="fe oq or os mk b">sacrebleu</code>:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="9fcf" class="mo mp it mk b gy mq mr l ms mt">pip install sacrebleu</span></pre><h2 id="56aa" class="mo mp it bd nd of og dn nh oh oi dp nl li oj ok nn lm ol om np lq on oo nr op bi translated">导入</h2><p id="b294" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">创建一个名为<code class="fe oq or os mk b">bleu_scorer.py</code>的新文件，并在文件顶部附加以下导入语句:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="2c4d" class="mo mp it mk b gy mq mr l ms mt">from sacrebleu.metrics import BLEU</span></pre><h2 id="10cc" class="mo mp it bd nd of og dn nh oh oi dp nl li oj ok nn lm ol om np lq on oo nr op bi translated">参考和假设文本</h2><p id="e205" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">如下定义假设文本和参考文本:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="820a" class="mo mp it mk b gy mq mr l ms mt">refs = [['The dog bit the guy.', 'It was not unexpected.', 'The man bit him first.']]</span><span id="f543" class="mo mp it mk b gy mu mr l ms mt">hyps = ['The dog bit the man.', "It wasn't surprising.", 'The man had just bitten him.']</span></pre><p id="8696" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe oq or os mk b">hyps</code>由一个文本列表组成，而<code class="fe oq or os mk b">refs</code>必须是一个文本列表列表。在实际的用例中，您应该从文件中读取它，如下所示(去掉结尾的换行符):</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="5bd6" class="mo mp it mk b gy mq mr l ms mt">with open('hyps.txt', 'r', encoding='utf8') as f:<br/>    lines = [x.strip() for x in f]</span></pre><p id="4445" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于多重引用，您应该将其定义如下:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="c6dc" class="mo mp it mk b gy mq mr l ms mt">refs = [['The dog bit the guy.', 'It was not unexpected.', 'The man bit him first.'],<br/>        ['The dog had bit the man.', 'No one was surprised.', 'The man had bitten the dog.']]</span><span id="9b1a" class="mo mp it mk b gy mu mr l ms mt">hyps = ['The dog bit the man.', "It wasn't surprising.", 'The man had just bitten him.']</span></pre><p id="cb88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下代码强调了多重引用的基本结构:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="369b" class="mo mp it mk b gy mq mr l ms mt">refs <!-- -->= [[ref1_for_sent1, ref1_for_sent2 ...,], [ref2_for_sent1, ref2_for_sent2, ...], ...]</span></pre><h2 id="8b59" class="mo mp it bd nd of og dn nh oh oi dp nl li oj ok nn lm ol om np lq on oo nr op bi translated">应用程序接口</h2><p id="e607" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">然后，使用<code class="fe oq or os mk b">metrics.BLEU</code>面向对象的API创建一个新实例:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="362a" class="mo mp it mk b gy mq mr l ms mt">bleu = BLEU()</span></pre><p id="57ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它接受以下输入参数:</p><ul class=""><li id="b5a3" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><code class="fe oq or os mk b">lowercase</code> —如果为真，则计算小写BLEU。</li><li id="c6bf" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">tokenize</code> —要使用的标记器。如果没有，则默认为特定于语言的标记化器，并将“13a”作为后备默认值。</li><li id="a752" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">smooth_method</code> —要使用的平滑方法(“floor”、“add-k”、“exp”或“none”)。</li><li id="4a15" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">smooth_value</code>—“floor”和“add-k”方法的平滑值。`无'返回默认值。</li><li id="405b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">max_ngram_order</code> —如果给定，它将在计算精度时覆盖最大n元语法顺序(默认值:4)。</li></ul><p id="bcd4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最大ngram默认为4，因为根据以下<a class="ae ky" href="http://aclweb.org/anthology/P/P02/P02-1040.pdf" rel="noopener ugc nofollow" target="_blank">研究论文</a>发现它与单语人类判断的相关性最高。</p><h2 id="0dbc" class="mo mp it bd nd of og dn nh oh oi dp nl li oj ok nn lm ol om np lq on oo nr op bi translated">语料库得分</h2><p id="20b3" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">调用<code class="fe oq or os mk b">corpus_score</code>函数计算整个语料库的蓝分:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="e8d0" class="mo mp it mk b gy mq mr l ms mt">result = bleu.corpus_score(hyps, refs)</span></pre><p id="80dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以在以下<a class="ae ky" href="https://gist.github.com/wfng92/91e596f294c488ce67359e70f945b429" rel="noopener ugc nofollow" target="_blank">要点</a>中找到完整的代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div></figure><h2 id="876d" class="mo mp it bd nd of og dn nh oh oi dp nl li oj ok nn lm ol om np lq on oo nr op bi translated">输出</h2><p id="758e" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">输出如下所示:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="bbd5" class="mo mp it mk b gy mq mr l ms mt">29.44 82.4/42.9/27.3/12.5 (BP = 0.889 ratio = 0.895 hyp_len = 17 ref_len = 19)</span></pre><ul class=""><li id="c43d" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><code class="fe oq or os mk b">29.44</code>指最终的BLEU分数</li><li id="bcea" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">82.4/42.9/27.3/12.5</code>表示1–4 ngram顺序的精度值</li><li id="7d40" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">BP</code>是简洁的惩罚</li><li id="16f7" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">ratio</code>表示假设长度与参考长度之比</li><li id="511c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">hyp_len</code>指假设文本的总字符数</li><li id="e1c4" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">ref_len</code>是参考文本的总字符数</li></ul><p id="7cfc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以在下面的<a class="ae ky" href="https://github.com/mjpost/sacrebleu/blob/master/sacrebleu/metrics/bleu.py" rel="noopener ugc nofollow" target="_blank">库</a>找到关于每个指标的更多信息。</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="638a" class="nc mp it bd nd ne nf ng nh ni nj nk nl jz nm ka nn kc no kd np kf nq kg nr ns bi translated">贝特斯科尔</h1><p id="a2fc" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">另一方面，<code class="fe oq or os mk b">BERTScore</code>有一些与BLEU不同的突出之处。它</p><blockquote class="ny nz oa"><p id="be9e" class="kz la ob lb b lc ld ju le lf lg jx lh oc lj lk ll od ln lo lp oe lr ls lt lu im bi translated">…利用来自BERT的预训练上下文嵌入，并通过余弦相似度匹配候选句子和参考句子中的单词。</p><p id="b2cb" class="kz la ob lb b lc ld ju le lf lg jx lh oc lj lk ll od ln lo lp oe lr ls lt lu im bi translated">它已被证明与人类对句子级和系统级评估的判断相关。此外，BERTScore还计算精确度、召回率和F1值，这对于评估不同的语言生成任务非常有用。</p></blockquote><p id="56a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这为使用同义词或相似词的句子提供了更好的评估。例如:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="34f4" class="mo mp it mk b gy mq mr l ms mt"># reference text<br/>The weather is cold today.</span><span id="066f" class="mo mp it mk b gy mu mr l ms mt"># hypothesis text<br/>It is freezing today.</span></pre><h2 id="5f73" class="mo mp it bd nd of og dn nh oh oi dp nl li oj ok nn lm ol om np lq on oo nr op bi translated">装置</h2><p id="b474" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">运行以下命令通过<code class="fe oq or os mk b">pip install</code>安装<code class="fe oq or os mk b">BERTScore</code>:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="a3d5" class="mo mp it mk b gy mq mr l ms mt">pip install bert-score</span></pre><h2 id="5fcb" class="mo mp it bd nd of og dn nh oh oi dp nl li oj ok nn lm ol om np lq on oo nr op bi translated">导入</h2><p id="faef" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">创建一个名为<code class="fe oq or os mk b">bert_scorer.py</code>的新文件，并在其中添加以下代码:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="743a" class="mo mp it mk b gy mq mr l ms mt">from bert_score import BERTScorer</span></pre><h2 id="9394" class="mo mp it bd nd of og dn nh oh oi dp nl li oj ok nn lm ol om np lq on oo nr op bi translated">参考和假设文本</h2><p id="9dc5" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">接下来，您需要定义引用和假设文本。BERTScore接受文本列表(单个引用)或文本列表列表(多个引用):</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="4ce7" class="mo mp it mk b gy mq mr l ms mt">refs = [['The dog bit the guy.', 'The dog had bit the man.'],                               ['It was not unexpected.', 'No one was surprised.'],                               ['The man bit him first.', 'The man had bitten the dog.']]</span><span id="a9ce" class="mo mp it mk b gy mu mr l ms mt">hyps = ['The dog bit the man.', "It wasn't surprising.", 'The man had just bitten him.']</span></pre><p id="0da1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与sacreBLEU相比，多引用的结构略有不同。它基于以下语法:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="2956" class="mo mp it mk b gy mq mr l ms mt">refs <!-- -->= [[ref1_for_sent1, ref2_for_sent1 ...,], [ref1_for_sent2, ref2_for_sent2, ...], ...]</span></pre><h2 id="7c62" class="mo mp it bd nd of og dn nh oh oi dp nl li oj ok nn lm ol om np lq on oo nr op bi translated">应用程序接口</h2><p id="76ec" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">实例化BERTScorer面向对象API的新实例，如下所示:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="6c64" class="mo mp it mk b gy mq mr l ms mt">scorer = BERTScorer(lang="en", rescale_with_baseline=True)</span></pre><p id="f8e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它接受:</p><ul class=""><li id="4984" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><code class="fe oq or os mk b">model_type</code> —上下文嵌入模型规范，默认使用目标语言的建议模型；必须指定<code class="fe oq or os mk b">model_type</code>或<code class="fe oq or os mk b">lang</code>中的至少一个</li><li id="bf8d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">verbose </code> —打开中间状态更新</li><li id="9d44" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">device</code> —如果没有，则模型存在于cuda上:如果cuda可用，则为0</li><li id="cdb6" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">batch_size</code> —加工批量</li><li id="5898" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">nthreads</code> —螺纹数量</li><li id="2d24" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">lang</code> —句子的语言。当<code class="fe oq or os mk b">rescale_with_baseline</code>为真时需要指定</li><li id="2320" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">rescale_with_baseline</code> —使用预先计算的基线重新调整伯特得分</li><li id="8a91" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">baseline_path</code> —定制的基线文件</li><li id="d9c7" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">use_fast_tokenizer</code> —使用HuggingFace的快速标记器</li></ul><p id="da0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">默认情况下，它基于指定的<code class="fe oq or os mk b">lang</code>使用以下模型:</p><ul class=""><li id="34d8" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><code class="fe oq or os mk b">en</code> —罗伯塔-大号</li><li id="0ea7" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">en-sci</code>—allenai/scibert _ scivocab _ uncased</li><li id="ec6d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">zh</code>—Bert-base-中文</li><li id="717d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">tr </code>—dbmdz/Bert-base-Turkish-cased</li></ul><p id="47aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">语言的其余部分将基于Bert-base-多语言环境。如果您打算定制该型号，请查看以下<a class="ae ky" href="https://docs.google.com/spreadsheets/d/1RKOVpselB98Nnh_EOC4A2BYn8_201tmPODpNWu4w7xI/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank">谷歌表单</a>了解更多信息。</p><p id="adc6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">重新调整基线有助于调整输出分数，使其更具可读性。这仅仅是因为一些上下文嵌入模型倾向于在非常窄的范围内产生分数。你可以在下面的<a class="ae ky" href="https://github.com/Tiiiger/bert_score/blob/master/journal/rescale_baseline.md" rel="noopener ugc nofollow" target="_blank">博客文章</a>中找到更多信息。</p><p id="7b63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个存储库还包含一些预先计算好基线文件。只需前往下面的<a class="ae ky" href="https://github.com/Tiiiger/bert_score/tree/master/bert_score/rescale_baseline" rel="noopener ugc nofollow" target="_blank">库</a>并根据您打算使用的模式下载所需的文件。</p><p id="456c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它将在初始运行时从HuggingFace下载模型和依赖项。随后，它将重用相同的下载模型。在Linux操作系统上，该模型位于以下目录中:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="91c3" class="mo mp it mk b gy mq mr l ms mt">~/.cache/huggingface/transformers/</span></pre><h2 id="5320" class="mo mp it bd nd of og dn nh oh oi dp nl li oj ok nn lm ol om np lq on oo nr op bi translated">语料库得分</h2><p id="b978" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">如下调用<code class="fe oq or os mk b">score</code>函数:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="2928" class="mo mp it mk b gy mq mr l ms mt">P, R, F1 = scorer.score(hyps, refs)</span></pre><p id="f2ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它将返回以下项的张量:</p><ul class=""><li id="ff7d" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><code class="fe oq or os mk b">P</code> —精度</li><li id="9643" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">R</code> —回忆</li><li id="43a8" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><code class="fe oq or os mk b">F1</code>—F1-得分</li></ul><p id="01df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是F1分数的输出示例:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="b068" class="mo mp it mk b gy mq mr l ms mt">tensor([0.9014, 0.8710, 0.5036, 0.7563, 0.8073, 0.8103, 0.7644, 0.8002, 0.6673, 0.7086])</span></pre><p id="7330" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，基础值的范围是从-1到1。</p><p id="a5bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过调用如下的<code class="fe oq or os mk b">mean</code>函数，可以很容易地计算出语料库的分数:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="4157" class="mo mp it mk b gy mq mr l ms mt">print(F1.mean())<br/># 0.6798698902130217</span></pre><p id="c666" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完整代码位于以下<a class="ae ky" href="https://gist.github.com/wfng92/c25848d7e22b5b7d86e20469a0d38783" rel="noopener ugc nofollow" target="_blank">要点</a>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="75b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，与sacreBLEU相比，运行BERTScore要慢很多。请确保您在评估期间有足够的GPU内存。</p><p id="1eb4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要了解更多关于BERTScore的信息，请查看官方资料库中的<a class="ae ky" href="https://github.com/Tiiiger/bert_score/blob/master/example/Demo.ipynb" rel="noopener ugc nofollow" target="_blank">示例笔记本</a>。</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="f4b5" class="nc mp it bd nd ne nf ng nh ni nj nk nl jz nm ka nn kc no kd np kf nq kg nr ns bi translated">结论</h1><p id="592d" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">让我们回顾一下你今天所学的内容。</p><p id="60c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文首先简要介绍了BLEU，以及用它来评估译文的优缺点。</p><p id="69bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，它讲述了如何使用sacreBLEU来计算语料库级别的BLEU分数。输出还包括1–4n gram的精度值。</p><p id="bca7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随后，在BERTScore上探讨了用余弦相似度评价译文的方法。<code class="fe oq or os mk b">score</code>函数分别返回精度、召回率和F1分数的张量。</p><p id="9226" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢你阅读这篇文章。祝你有美好的一天！</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="1c2c" class="nc mp it bd nd ne nf ng nh ni nj nk nl jz nm ka nn kc no kd np kf nq kg nr ns bi translated">参考</h1><ol class=""><li id="da72" class="lv lw it lb b lc nt lf nu li ov lm ow lq ox lu oy mb mc md bi translated"><a class="ae ky" href="https://github.com/mjpost/sacrebleu" rel="noopener ugc nofollow" target="_blank"> Github — sacreBLEU </a></li><li id="f09b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oy mb mc md bi translated"><a class="ae ky" href="https://github.com/Tiiiger/bert_score" rel="noopener ugc nofollow" target="_blank"> Github — BERTScore </a></li></ol></div></div>    
</body>
</html>