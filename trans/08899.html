<html>
<head>
<title>How to Make Your Modeling Process More Efficient</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何让你的建模过程更有效率</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-make-your-modeling-process-more-efficient-89e70259839d?source=collection_archive---------43-----------------------#2021-08-16">https://towardsdatascience.com/how-to-make-your-modeling-process-more-efficient-89e70259839d?source=collection_archive---------43-----------------------#2021-08-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0879" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">介绍一种用于数据集初始建模的省时方法</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/2eed346bf0738bfc6b710656895fd3fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PDneFcx1qwURIGTm"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@jay_zhang?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">张杰</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="abc5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇文章中，我将分享一些关于如何有效地开始初始建模的技巧。在花了很多时间测试哪些模型在我的特定数据集上表现最好之后，我想出了一个节省时间的方法，我用它来对我的所有数据集进行初始建模。一旦我能够找出在我的数据集上表现最好的模型，我就专注于这些模型，并开始调整它们的超参数，使它们在我优化的指标方面更好。</p><p id="6911" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我下面描述的过程将有助于找到你的模型的一个好的起点。在这个例子中，我正在进行一个项目，该项目使用CTG信息将胎儿健康分为3类(1为健康，2为可疑，3为病理)。请注意，在开始项目的建模阶段之前，我彻底清理了数据并执行了EDA。</p><p id="8e6f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了开始分类建模过程，我定义了X和y变量，并创建了训练、测试分割和缩放数据，如下图所示。一旦训练和测试数据被缩放，就该开始初始建模了。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="f6b3" class="lx ly iq lt b gy lz ma l mb mc">X = df.drop(columns = ['fetal_health'])<br/>y = df['fetal_health']</span><span id="5de6" class="lx ly iq lt b gy md ma l mb mc">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y )</span><span id="6aa3" class="lx ly iq lt b gy md ma l mb mc">ss = StandardScaler()<br/>X_train_sc = ss.fit_transform(X_train)<br/>X_test_sc = ss.transform(X_test)</span></pre><p id="8adb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我创建了一个函数来实例化并拟合训练数据上的指定模型，对测试数据进行预测，然后打印出训练和测试的准确度分数。下图显示了我如何设置这个简单而有效的函数。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="1fe8" class="lx ly iq lt b gy lz ma l mb mc">def pipe(model):</span><span id="a6d2" class="lx ly iq lt b gy md ma l mb mc">    #instantiate model<br/>    model = model()</span><span id="4f70" class="lx ly iq lt b gy md ma l mb mc">    #fit to scaled data<br/>    model.fit(X_train_sc, y_train)<br/>    <br/>    #make predictions<br/>    predictions = model.predict(X_test_sc)</span><span id="2a0d" class="lx ly iq lt b gy md ma l mb mc">    #print accuracy scores for training and testing groups<br/>    print(f'{model} training score: {model.score(X_train_sc, y_train)}')<br/>    print(f'{model} testing score: {model.score(X_test_sc, y_test)}')</span><span id="18fb" class="lx ly iq lt b gy md ma l mb mc">return</span></pre><p id="c8d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来的部分是最有趣的部分！我能够通过我在笔记本中导入的函数传递任何模型。我能够很快地在8个不同的分类模型上重复这个函数，并打印出训练组和测试组的准确度分数。然后，我可以查看如下所示的8个模型的得分，并挑选出前两个模型来微调超参数，以进一步提高准确性。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="c59d" class="lx ly iq lt b gy lz ma l mb mc">pipe(LogisticRegression)<br/>&gt; LogisticRegression() training score: 0.8977415307402761<br/>&gt; LogisticRegression() testing score: 0.9078947368421053</span><span id="bc54" class="lx ly iq lt b gy md ma l mb mc">pipe(DecisionTreeClassifier)<br/>&gt; DecisionTreeClassifier() training score: 0.998745294855709<br/>&gt; DecisionTreeClassifier() testing score: 0.9116541353383458</span><span id="b8c1" class="lx ly iq lt b gy md ma l mb mc">pipe(KNeighborsClassifier)<br/>&gt; KNeighborsClassifier() training score: 0.9316185696361355<br/>&gt; KNeighborsClassifier() testing score: 0.8984962406015038</span><span id="d7b0" class="lx ly iq lt b gy md ma l mb mc">pipe(RandomForestClassifier)<br/>&gt; RandomForestClassifier() training score: 0.998745294855709<br/>&gt; RandomForestClassifier() testing score: 0.9454887218045113</span><span id="e19d" class="lx ly iq lt b gy md ma l mb mc">pipe(AdaBoostClassifier)<br/>&gt; AdaBoostClassifier() training score: 0.9084065244667503<br/>&gt; AdaBoostClassifier() testing score: 0.8853383458646616</span><span id="081d" class="lx ly iq lt b gy md ma l mb mc">pipe(SVC)<br/>&gt; SVC() training score: 0.9240903387703889<br/>&gt; SVC() testing score: 0.9191729323308271</span><span id="ff4a" class="lx ly iq lt b gy md ma l mb mc">pipe(GradientBoostingClassifier)<br/>&gt; GradientBoostingClassifier() training score: 0.9949811794228356<br/>&gt; GradientBoostingClassifier() testing score: 0.9492481203007519</span><span id="f457" class="lx ly iq lt b gy md ma l mb mc">pipe(ExtraTreesClassifier)<br/>&gt; ExtraTreesClassifier() training score: 0.998745294855709<br/>&gt; ExtraTreesClassifier() testing score: 0.9342105263157895</span></pre><p id="c46e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种情况下，我选择继续研究梯度提升分类器和随机福里斯特分类器，因为它们在训练组和测试组之间具有最高和最一致的分数。在那里，我设置了网格搜索来测试每个模型中不同的超参数选项。网格搜索需要更多的时间来迭代，这就是为什么我只想在最高性能的模型上尝试。梯度增强分类器网格搜索如下所示。然而，我对这两个模型都做了这个过程，并确定了每个模型的最佳参数。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="f39c" class="lx ly iq lt b gy lz ma l mb mc">X = df.drop(columns = ['fetal_health'])<br/>y = df['fetal_health']</span><span id="88e3" class="lx ly iq lt b gy md ma l mb mc">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y )</span><span id="d77c" class="lx ly iq lt b gy md ma l mb mc">#pipeline to scale data and then grid search<br/>pipe = Pipeline([<br/>    ('ss', StandardScaler()),<br/>    ('gbc' , GradientBoostingClassifier()) <br/>])</span><span id="3bd4" class="lx ly iq lt b gy md ma l mb mc">#gbc parameters to grid search through<br/>pipe_params = {<br/>    'gbc__max_depth':[1, 2, 3, 4],<br/>    'gbc__learning_rate'  :[0.1, 0.001, 1],<br/>    'gbc__n_estimators' :[100, 300, 500],<br/>    'gbc__min_samples_leaf' :[1, 2]<br/>}</span><span id="3b44" class="lx ly iq lt b gy md ma l mb mc">#instantiate and fit grid search<br/>gs = GridSearchCV(pipe, param_grid = pipe_params, cv = 5)<br/>gs.fit(X_train, y_train)</span><span id="deee" class="lx ly iq lt b gy md ma l mb mc">#print accuracy scores for training and testing groups<br/>print(f'training score:  {gs.score(X_train, y_train)}')<br/>print(f'testing score: {gs.score(X_test, y_test)}')</span><span id="f5cf" class="lx ly iq lt b gy md ma l mb mc">&gt; training score: 0.9887076537013801<br/>&gt; testing score: 0.9473684210526315</span><span id="95b9" class="lx ly iq lt b gy md ma l mb mc">#get best parameters from grid search<br/>gs.best_params_</span><span id="8b87" class="lx ly iq lt b gy md ma l mb mc">&gt; {'gbc__learning_rate': 0.1,<br/> 'gbc__max_depth': 2,<br/> 'gbc__min_samples_leaf': 2,<br/> 'gbc__n_estimators': 500}</span></pre><p id="a5a7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，为了评估用于生产的最佳模型，我对测试数据进行了预测，并查看了每个模型的准确性分数和召回分数。我希望优化召回分数，因为在处理胎儿健康数据时，假阴性的风险很高。我选择梯度提升分类器作为最佳模型，因为与随机森林分类器相比，它在准确性和召回率方面得分最高。参见下面的分类报告和混淆矩阵，其中第3组(病理组)的假阴性已降至最低。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="ad34" class="lx ly iq lt b gy lz ma l mb mc">#make predictions on testing data<br/>preds = gs.predict(X_test)</span><span id="172d" class="lx ly iq lt b gy md ma l mb mc">#print out classification report<br/>print(classification_report(y_test,preds))</span><span id="dcdb" class="lx ly iq lt b gy md ma l mb mc">&gt; <br/>fetal health  precision    recall  f1-score   support<br/><br/>           1       0.96      0.97      0.97       414<br/>           2       0.91      0.78      0.84        74<br/>           3       0.86      0.98      0.91        44<br/><br/>    accuracy                           0.95       532<br/>   macro avg       0.91      0.91      0.91       532<br/>weighted avg       0.95      0.95      0.95       532</span><span id="edd6" class="lx ly iq lt b gy md ma l mb mc">#plot confusion matrix<br/>cm = confusion_matrix(y_test, preds)<br/>ConfusionMatrixDisplay(cm, display_labels = gs.classes_).plot(cmap = 'Blues');</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi me"><img src="../Images/fd8f4e772026b5a9e63fb2427a1c965c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*bq1F84HWqLgEuUAkkpLMbQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者照片</p></figure><p id="ff54" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这整个过程可以在一天的工作中完成。我希望模型功能和网格搜索的结合也能帮助你的分类建模更有效！</p></div></div>    
</body>
</html>