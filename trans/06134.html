<html>
<head>
<title>Best of ML Code and Software— June 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最佳ML代码和软件—2021年6月</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/best-of-ml-code-and-software-june-2021-486dcf6f461b?source=collection_archive---------35-----------------------#2021-06-01">https://towardsdatascience.com/best-of-ml-code-and-software-june-2021-486dcf6f461b?source=collection_archive---------35-----------------------#2021-06-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b468" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">每月精选的最近实现、工具和软件正在ML领域获得牵引力:Google的Vertex AI、PyTorch Vision、HuggingFace Accelerate等等。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/07a2b3617a4852564df8bcbc09633aa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WCXyjvV6HIfGgGLgZapxcg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="4c36" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">构建ML软件并从研究跳到生产并不是一件容易的事，即使当资源的海洋是巨大的:很难跟上。确切地说，当我们努力将最新的模型投入生产并找到最佳的纸面实现时，我们经常在<a class="ae lr" href="https://search.zeta-alpha.com/" rel="noopener ugc nofollow" target="_blank"> Zeta Alpha </a>遇到这个问题，因此我们希望通过分享我们每月在最新的存储库、工具、库和软件新闻中的发现来做出贡献。尽情享受吧！</p><h1 id="99ec" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">⚙️ MLOps亮点</h1><p id="f302" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">ML Operations (MLOps)的空间正在以令人眼花缭乱的速度移动，这可能会使它变得混乱:在过去的几年里，数百家公司和产品已经出现，以更可靠和更强大的方式帮助ML投入生产，但结果是一个非常拥挤，尚未确定的市场，仍然很难导航。当我们自己试图理解它的时候，我们密切关注着最新的新闻和发展。这里有一个选择:</p><ul class=""><li id="bb6c" class="mp mq iq kx b ky kz lb lc le mr li ms lm mt lq mu mv mw mx bi translated"><a class="ae lr" href="https://cloud.google.com/blog/products/ai-machine-learning/google-cloud-launches-vertex-ai-unified-platform-for-mlops" rel="noopener ugc nofollow" target="_blank">谷歌发布VertexAI </a>:一个“MLOps的统一平台”。大型云提供商(<a class="ae lr" href="https://azure.microsoft.com/en-us/services/machine-learning/mlops/" rel="noopener ugc nofollow" target="_blank">微软的Azure </a>，<a class="ae lr" href="https://aws.amazon.com/solutions/implementations/aws-mlops-framework/" rel="noopener ugc nofollow" target="_blank">亚马逊的AWS </a>)正在快速构建与他们的技术集成的ML工具——可能是为了锁定更多的客户——而像DataBricks这样的公司，凭借新的<a class="ae lr" href="https://databricks.com/blog/2021/05/27/introducing-databricks-machine-learning-a-data-native-collaborative-full-ml-lifecycle-solution.html" rel="noopener ugc nofollow" target="_blank"> DataBricks ML </a>，或者像MLFlow或Kubeflow这样的框架，继续推动一个不可知的未来，即你在哪里运行你的ML项目。我们将看到内置或第三方解决方案是否会在未来几年内得到更广泛的采用，以及端到端MLOps产品是否会赢得特定功能工具的海洋，如带有<a class="ae lr" href="https://snorkel.ai" rel="noopener ugc nofollow" target="_blank">通气管</a>的标签、带有<a class="ae lr" href="https://neptune.ai" rel="noopener ugc nofollow" target="_blank">海王星</a>的跟踪实验以及带有<a class="ae lr" href="https://airflow.apache.org" rel="noopener ugc nofollow" target="_blank">气流</a>的协调。</li><li id="8041" class="mp mq iq kx b ky my lb mz le na li nb lm nc lq mu mv mw mx bi translated">Huggingface 将变压器推向大众，加速了这些架构在生产中的应用。随着变形金刚几个月前在解决计算机视觉任务的研究方面取得进展，<a class="ae lr" href="https://github.com/huggingface/transformers/releases/tag/v4.6.0" rel="noopener ugc nofollow" target="_blank"> Huggingface最近发布了第一个完整的“视觉版本”</a>，其中包括CLIP、ViT和Deit。工业中使用的模型总是比研究中使用的模型落后几个月，因为性能/ <em class="nd">简单性</em>的权衡适用于不同的情况。因此，尽管ViTs最近取得了成功，我们仍然想知道:变形金刚会在不久的将来取代CNN吗？</li><li id="dc91" class="mp mq iq kx b ky my lb mz le na li nb lm nc lq mu mv mw mx bi translated"><a class="ae lr" href="https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops" rel="noopener ugc nofollow" target="_blank">吴恩达的新coursera“生产中的人工智能”</a>:Andrew的原创<a class="ae lr" href="https://www.coursera.org/learn/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习课程</a>通过将人工智能介绍给数百万从业者，成为人工智能迅速崛起的催化剂。如果这是一个指标的话，这个新课程有可能通过教育成千上万的工程师和研究人员来缩小研究和生产之间的差距。</li></ul><h1 id="2125" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">同时，在GitHub上</h1><p id="8767" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">一系列最近发布的库、框架和实现。</p><h2 id="c6fd" class="ne lt iq bd lu nf ng dn ly nh ni dp mc le nj nk me li nl nm mg lm nn no mi np bi translated">👾<a class="ae lr" href="https://github.com/facebookresearch/pytorchvideo" rel="noopener ugc nofollow" target="_blank">Facebook research/pytorchvideo</a>⭐️1.4k |📄<a class="ae lr" href="https://pytorchvideo.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">文档</a> |🌐<a class="ae lr" href="https://pytorchvideo.org" rel="noopener ugc nofollow" target="_blank">网站</a></h2><p id="d464" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">👉<em class="nd"> Pytorch Video提供了加速视频理解研究所需的可重用、模块化和高效的组件。PyTorchVideo是使用</em><a class="ae lr" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"><em class="nd">PyTorch</em></a><em class="nd">开发的，支持不同的深度学习视频组件，如视频模型、视频数据集和视频特定变换。</em></p><p id="f006" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">🚀非常适合构建定制视频处理研究模型并进行基准测试。功能和特点:</p><ul class=""><li id="a4ff" class="mp mq iq kx b ky kz lb lc le mr li ms lm mt lq mu mv mw mx bi translated">一个“模型动物园”,包含现有模型的几个实现，以及最常见数据集的数据加载器。</li><li id="2743" class="mp mq iq kx b ky my lb mz le na li nb lm nc lq mu mv mw mx bi translated">高效的视频组件:组件针对视频进行了优化，并支持硬件上的加速推理。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/672f824a91c9b7b87ec13903ce4d9b44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5z-fnXn8PkQGsTOZi79LKw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae lr" href="https://github.com/facebookresearch/pytorchvideo" rel="noopener ugc nofollow" target="_blank">https://github.com/facebookresearch/pytorchvideo</a></p></figure><h2 id="4ba3" class="ne lt iq bd lu nf ng dn ly nh ni dp mc le nj nk me li nl nm mg lm nn no mi np bi translated">👾微软/swin-transformer  ⭐️ 3.4k |📄<a class="ae lr" href="https://arxiv.org/abs/2103.14030" rel="noopener ugc nofollow" target="_blank">论文</a></h2><p id="897c" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated"><em class="nd">👉如果你想玩视觉变形金刚，这里有你现在可能需要的支柱。</em></p><p id="6a6d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">❓此报告是<a class="ae lr" href="https://arxiv.org/pdf/2103.14030.pdf" rel="noopener ugc nofollow" target="_blank">“swin transformer:使用移位窗口的分层视觉转换器”</a>的正式实现，它还包括以下论文和任务的代码:</p><ul class=""><li id="2aff" class="mp mq iq kx b ky kz lb lc le mr li ms lm mt lq mu mv mw mx bi translated"><em class="nd">对象检测和实例分割:参见</em><a class="ae lr" href="https://github.com/SwinTransformer/Swin-Transformer-Object-Detection" rel="noopener ugc nofollow" target="_blank"><em class="nd">Swin Transformer for Object Detection</em></a><em class="nd">。</em></li><li id="31ac" class="mp mq iq kx b ky my lb mz le na li nb lm nc lq mu mv mw mx bi translated"><em class="nd">语义分割:参见</em> <a class="ae lr" href="https://github.com/SwinTransformer/Swin-Transformer-Semantic-Segmentation" rel="noopener ugc nofollow" target="_blank"> <em class="nd"> Swin Transformer进行语义分割</em> </a> <em class="nd">。</em></li><li id="47f3" class="mp mq iq kx b ky my lb mz le na li nb lm nc lq mu mv mw mx bi translated"><em class="nd">自监督学习:参见</em><a class="ae lr" href="https://github.com/SwinTransformer/Transformer-SSL" rel="noopener ugc nofollow" target="_blank"><em class="nd">Transformer-SSL</em></a><em class="nd">。</em></li></ul><p id="672d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你想玩一个立体的视觉变形器迭代，这个实现将是有用的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/cc4e4a1142c6cf0463e9f78eaeff45a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ftg7uUUrLw2JRzcLbreFog.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae lr" href="https://github.com/microsoft/Swin-Transformer" rel="noopener ugc nofollow" target="_blank">https://github.com/microsoft/Swin-Transformer</a></p></figure><h2 id="7f2b" class="ne lt iq bd lu nf ng dn ly nh ni dp mc le nj nk me li nl nm mg lm nn no mi np bi translated">👾<a class="ae lr" href="https://github.com/huggingface/accelerate" rel="noopener ugc nofollow" target="_blank">拥抱脸/加速</a> ⭐️1.4k |📄<a class="ae lr" href="https://huggingface.co/docs/accelerate/" rel="noopener ugc nofollow" target="_blank">文档</a></h2><p id="d3cc" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated"><em class="nd">👉在不同的硬件加速配置(单个/多个GPU和单个/多个节点上的TPU)上运行PyTorch的非常简单的方法，无需特定于硬件的样板代码。</em></p><p id="e6b5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">🚀一次定义，随处训练。很快。accelerate的用途和用途:</p><ul class=""><li id="a7c9" class="mp mq iq kx b ky kz lb lc le mr li ms lm mt lq mu mv mw mx bi translated">Accelerate让您可以在分布式环境(即跨计算节点或许多其他配置)中运行训练脚本，而不会放弃对训练循环的控制。</li><li id="d7db" class="mp mq iq kx b ky my lb mz le na li nb lm nc lq mu mv mw mx bi translated">Accelerate不会让你从训练循环本身中抽象出来，不像PyTorch之上的其他高级框架，比如<a class="ae lr" href="https://github.com/pytorch/ignite" rel="noopener ugc nofollow" target="_blank"> pytorch/ignite </a>。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/ad8b0eda68da58567aea88ef57c3ae84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1BzXFuZpCSB85bpNu_aMJQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:https://github.com/huggingface/accelerate<a class="ae lr" href="https://github.com/huggingface/accelerate" rel="noopener ugc nofollow" target="_blank"/></p></figure><h2 id="bef2" class="ne lt iq bd lu nf ng dn ly nh ni dp mc le nj nk me li nl nm mg lm nn no mi np bi translated">👾<a class="ae lr" href="https://github.com/open-mmlab/mmocr" rel="noopener ugc nofollow" target="_blank"> open-mmlab/mmocr </a> ⭐️ 1.2k |📄<a class="ae lr" href="https://mmocr.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">文档</a></h2><p id="8c73" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">👉<em class="nd">一个基于</em> <a class="ae lr" href="https://github.com/pytorch/pytorch" rel="noopener ugc nofollow" target="_blank"> <em class="nd"> PyTorch </em> </a> <em class="nd">和</em><a class="ae lr" href="https://github.com/open-mmlab/mmdetection" rel="noopener ugc nofollow" target="_blank"><em class="nd">mm detection</em></a><em class="nd">的开源工具箱，用于文本检测、文本识别，以及包括关键信息提取在内的相应下游任务。</em></p><p id="1651" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">🚀非常适合构建图像或视频处理管道。主要特性和组件:</p><ul class=""><li id="5cba" class="mp mq iq kx b ky kz lb lc le mr li ms lm mt lq mu mv mw mx bi translated">一个<strong class="kx ir">综合管道</strong>，包括下游信息提取任务。</li><li id="12e5" class="mp mq iq kx b ky my lb mz le na li nb lm nc lq mu mv mw mx bi translated">用于文本检测和识别的各种最先进的模型</li><li id="882b" class="mp mq iq kx b ky my lb mz le na li nb lm nc lq mu mv mw mx bi translated">一个模块化的设计来定义你自己的优化器，数据预处理，模型骨干或损失函数。</li><li id="8d2b" class="mp mq iq kx b ky my lb mz le na li nb lm nc lq mu mv mw mx bi translated">几个可视化工具，地面纹理和预测边界框等等。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/e69d92110ed298c65038ef00fbf93cd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4yW1DBG28xTfsLO_obfsYA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae lr" href="https://mmocr.readthedocs.io/en/latest/demo.html" rel="noopener ugc nofollow" target="_blank">https://mmocr.readthedocs.io/en/latest/demo.html</a></p></figure><h2 id="1b2e" class="ne lt iq bd lu nf ng dn ly nh ni dp mc le nj nk me li nl nm mg lm nn no mi np bi translated">👾<a class="ae lr" href="https://github.com/linkedin/greykite" rel="noopener ugc nofollow" target="_blank">LinkedIn/grey kite</a>⭐️939 |📄<a class="ae lr" href="https://linkedin.github.io/greykite/docs" rel="noopener ugc nofollow" target="_blank">文档</a></h2><p id="b747" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">👉Greykite库通过其旗舰算法Silverkite提供灵活、直观和快速的预测。Silverkite算法适用于大多数时间序列，尤其适用于趋势或季节性变化点、事件/假日效应以及时间相关性。它的预测是可解释的，因此有助于可信的决策和洞察力。</p><p id="ca9f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">🚀非常适合快速现成的时序应用。主要特性和特征:</p><ul class=""><li id="e1e2" class="mp mq iq kx b ky kz lb lc le mr li ms lm mt lq mu mv mw mx bi translated">灵活的设计:提供基本的回归检测趋势和季节性，假期和变化点；以及最先进的ML型号可供选择。同一管道支持所有模型的预处理、交叉验证、回溯测试、预测和评估。</li><li id="0b13" class="mp mq iq kx b ky my lb mz le na li nb lm nc lq mu mv mw mx bi translated">直观的可视化界面、适用于特定数据特征的模板，以及可生成可解释输出以检查每个回归变量贡献的it。</li><li id="de6e" class="mp mq iq kx b ky my lb mz le na li nb lm nc lq mu mv mw mx bi translated">使用网格搜索进行模型选择的快速培训、基准测试和原型制作。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/de690f27baa79cf89f5ad9ae94ec9606.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MlSC7baaBr28SfPiuiDhlg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae lr" href="https://github.com/linkedin/greykite" rel="noopener ugc nofollow" target="_blank">https://github.com/linkedin/greykite</a></p></figure><h2 id="18d1" class="ne lt iq bd lu nf ng dn ly nh ni dp mc le nj nk me li nl nm mg lm nn no mi np bi translated">👾<a class="ae lr" href="https://github.com/google/lyra" rel="noopener ugc nofollow" target="_blank">谷歌/天琴座</a> ⭐️ 2.6k | <a class="ae lr" href="https://ai.googleblog.com/2021/02/lyra-new-very-low-bitrate-codec-for.html" rel="noopener ugc nofollow" target="_blank">博文</a> |📄<a class="ae lr" href="https://arxiv.org/abs/2102.09660" rel="noopener ugc nofollow" target="_blank">论文</a></h2><p id="ddda" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated"><em class="nd">👉一种高质量、低比特率的语音编解码器，即使在最慢的网络上也能进行语音通信。为此，它应用传统的编解码器技术，同时利用机器学习(ML)的进步，通过数千小时的数据训练模型，创建一种压缩和传输语音信号的新方法。</em></p><p id="e7f0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">🚀这项工作在精神上类似于<a class="ae lr" href="https://blogs.nvidia.com/blog/2020/10/05/gan-video-conferencing-maxine/" rel="noopener ugc nofollow" target="_blank"> Nvidia基于GAN的极低比特率视频压缩</a>。该方法的工作原理是每40毫秒提取语音特征，基于心理声学特性进行量化(即去除人耳对其敏感度低的方面)，并通过信道传输该信号。解码器是一个生成模型，它接收语音特征作为输入，并输出音频波形。这对于构建带宽受限的移动应用程序非常有用。主要功能和特点包括:</p><ul class=""><li id="ff83" class="mp mq iq kx b ky kz lb lc le mr li ms lm mt lq mu mv mw mx bi translated">极低比特率语音编解码(3kbps)。</li><li id="7319" class="mp mq iq kx b ky my lb mz le na li nb lm nc lq mu mv mw mx bi translated">易于集成基于Android和Linux的应用程序。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/c2d99745cf08bcae64c9f05361b33c1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oQFda_s_A9bgXHFiqAoQwA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae lr" href="https://ai.googleblog.com/2021/02/lyra-new-very-low-bitrate-codec-for.html" rel="noopener ugc nofollow" target="_blank">https://ai . Google blog . com/2021/02/lyra-new-very-low-bitrate-codec-for . html</a></p></figure></div><div class="ab cl nw nx hu ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="ij ik il im in"><p id="16f8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你对MLOps的广阔世界更感兴趣，我怎么推荐都不为过，你可以看看迟虎燕在她的博客上的<a class="ae lr" href="https://huyenchip.com/2020/12/30/mlops-v2.html" rel="noopener ugc nofollow" target="_blank">工具诊断摘要，以及</a><a class="ae lr" href="https://ml-ops.org" rel="noopener ugc nofollow" target="_blank">ml-ops.org</a>网站和他们在GitHub 上的<a class="ae lr" href="https://github.com/visenger/awesome-mlops" rel="noopener ugc nofollow" target="_blank">资源列表。</a></p><p id="9e0b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这就是这个月的内容，如果你想跟上ML世界的最新发展，请在Twitter上关注我们。要了解更多有趣的近期研究，请查看其他月度博客系列<a class="ae lr" rel="noopener" target="_blank" href="/best-of-arxiv-june-2021-dcd3aa48a66d"> <em class="nd">和arXiv </em> </a>精选，它们主要关注学术文献。下个月见！</p></div><div class="ab cl nw nx hu ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="ij ik il im in"><p id="dcab" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="nd">【所有GitHub回购星级统计截至2021年6月1日】。</em></p><p id="1c85" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="nd">参考文献</em></p><p id="731b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[1] <a class="ae lr" href="https://arxiv.org/abs/2103.00020" rel="noopener ugc nofollow" target="_blank"> <em class="nd">从自然语言监督中学习可转移的视觉模型</em></a>——亚历克·拉德福德、琼·金旭等2021。</p><p id="334e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[2] <a class="ae lr" href="https://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank"> <em class="nd">一幅图像抵得上16x16个字:大规模图像识别的变形金刚</em></a>——作者阿列克谢·多索维茨基、卢卡斯·拜尔、亚历山大·科列斯尼科夫、德克·韦森博恩、翟晓华等2021</p><p id="654c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[3] <a class="ae lr" href="https://arxiv.org/abs/2012.12877?fbclid=IwAR0g4j0LEcHzO67FGGNMLTg1ksFymSOmuCAAkIbemlU2r5XhIuJyargTbpc" rel="noopener ugc nofollow" target="_blank"> <em class="nd">训练数据高效的图像转换器&amp;通过注意力的升华</em></a>——Hugo Touvron等人2020</p></div></div>    
</body>
</html>