<html>
<head>
<title>Spotify Genre Classification Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spotify流派分类算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/spotify-genre-classification-algorithm-88051db23d42?source=collection_archive---------10-----------------------#2021-04-22">https://towardsdatascience.com/spotify-genre-classification-algorithm-88051db23d42?source=collection_archive---------10-----------------------#2021-04-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="73a1" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">监督机器学习— SVM、随机森林、逻辑回归</h2></div><p id="b6ec" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文假设对机器学习算法和数据科学技术有基本的了解。</p><p id="cc73" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">文章大纲:</p><ul class=""><li id="4b0b" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">监督机器学习</li><li id="3fef" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">分类—多类</li><li id="6123" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">数据集-初步分析和特征选择</li><li id="35a8" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">算法选择— SVM、逻辑回归、随机森林</li><li id="e78f" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">模型性能—准确性得分</li><li id="dade" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">改进—超参数调整和集成学习</li><li id="5652" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">结论—更多数据！</li></ul><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/38cf84b773f0dbf612c4635dfebaed7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oogkcJdURZstGVOq"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">亚历山大·沙托夫在<a class="ae mf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="cf61" class="mg mh iq bd mi mj mk dn ml mm mn dp mo ko mp mq mr ks ms mt mu kw mv mw mx my bi translated">什么是有监督的机器学习？</h2><p id="cf35" class="pw-post-body-paragraph kf kg iq kh b ki mz jr kk kl na ju kn ko nb kq kr ks nc ku kv kw nd ky kz la ij bi translated">正如所有技术都有术语一样，监督学习是一个总括术语，用来描述机器学习的一个领域(在实践中使用最频繁)，其中使用的数据是标记为的<strong class="kh ir">。监督学习算法的目标是利用数据集来产生一个模型，该模型以特征向量(x)作为输入，以变量(Y)作为输出。使用一种算法来学习从输入到输出的映射函数，然后使用新的未知输入数据来预测该数据的输出变量。</strong></p><h2 id="a169" class="mg mh iq bd mi mj mk dn ml mm mn dp mo ko mp mq mr ks ms mt mu kw mv mw mx my bi translated">什么是分类？</h2><p id="b924" class="pw-post-body-paragraph kf kg iq kh b ki mz jr kk kl na ju kn ko nb kq kr ks nc ku kv kw nd ky kz la ij bi translated">分类算法将已标记示例的数据集作为输入来产生模型，该模型可以获取未标记的新数据并自动将标签分配给未标记的示例。</p><p id="0a09" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果分类问题有一组两个标签(例如“垃圾邮件”或“非垃圾邮件”)，那么它就是一个二元分类问题。当集合中的标签数量为三个或更多时，多类分类是一个问题。我们正在寻找的问题是一个多类，因为在这个集合中有许多类型。</p><h2 id="bc73" class="mg mh iq bd mi mj mk dn ml mm mn dp mo ko mp mq mr ks ms mt mu kw mv mw mx my bi translated">给我看看数据</h2><p id="800f" class="pw-post-body-paragraph kf kg iq kh b ki mz jr kk kl na ju kn ko nb kq kr ks nc ku kv kw nd ky kz la ij bi translated">被检查的数据集是歌曲信息的集合。它可以在我的python代码旁边的<a class="ae mf" href="https://www.kaggle.com/c/cs9856-spotify-classification-problem-2021/overview/description" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>和<a class="ae mf" href="https://github.com/rorybain96/spotifyclass" rel="noopener ugc nofollow" target="_blank"> Github </a>上获得。</p><p id="b7d2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据已经被分成标记的训练数据和未标记的测试数据。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ne"><img src="../Images/92d264f267f98f9ce46a24535a23dff1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S_Wc54fqDqT67WxVxPQZOA.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">按作者分类的图像(标记为训练数据)</p></figure><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nf"><img src="../Images/26b69fc8b2e56d5826a71e92e7d890a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b21NPTc6nx8T8_2SjQfd-Q.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">作者提供的图片(未标记的测试数据)</p></figure><ul class=""><li id="7654" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">Id —任意唯一的轨道标识符</li><li id="1a95" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">标题—音轨标题</li><li id="0924" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">艺术家——歌手或乐队</li><li id="d7ab" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">年份—发布(或重新发布)的年份</li><li id="3ec1" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">bpm —每分钟节拍数(节奏)</li><li id="16bf" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">nrgy —能量:数值越高，能量越大</li><li id="4127" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">dnce — danceability:值越高，越容易随着这首歌跳舞</li><li id="990b" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">dB —响度(dB):值越高，歌曲的音量越大</li><li id="b52a" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">live-liveness:该值越高，歌曲越有可能是现场录制的</li><li id="e8e6" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">val-valence:值越高，歌曲的情绪越积极</li><li id="c917" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">dur —持续时间:歌曲的长度</li><li id="d028" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">acous-acoustic:值越高，歌曲的声音越大</li><li id="e4a4" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">spch-speechiness:值越高，歌曲包含的口语单词越多</li><li id="b3d4" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">流行度:值越高，歌曲越流行</li><li id="fb28" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">热门流派—曲目的流派(以及此问题的目标变量)</li></ul><p id="a3be" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在top_genre列的训练集中识别出15个空值。missingo库为缺失值提供了很好的可视化效果，使得识别具有空值的列变得很容易。15个空值被删除。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="76a6" class="mg mh iq nh b gy nl nm l nn no">import missingno as msno<br/>msno.bar(class_train, color="dodgerblue", sort="ascending", figsize=(10,5), fontsize=12)<br/>class_train["top genre"].isnull().value_counts()<br/># dropping NULL values<br/>class_train = class_train.dropna(axis=0)</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi np"><img src="../Images/6de6829b8ccf6ce7cd408c835e80933e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ixjpGMIqU-K3KizKkD3tgQ.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">作者图片</p></figure><p id="a85c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在创建任何模型之前，最好检查<a class="ae mf" href="https://statisticsbyjim.com/regression/multicollinearity-in-regression-analysis/" rel="noopener ugc nofollow" target="_blank">多重共线性</a>，多重共线性是数据集中独立要素之间的相关性。检查这一点最简单的方法是使用关联热图。显然不存在多重共线性。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="8875" class="mg mh iq nh b gy nl nm l nn no"># Plot linear correlation matrix<br/>fig, ax = plt.subplots(figsize=(15,10))<br/>sns.heatmap(class_train.corr(), annot=True, cmap='YlGnBu', vmin=-1, vmax=1, center=0, ax=ax)<br/>plt.title('LINEAR CORRELATION MATRIX - CLASS_TRAIN')<br/>plt.show()</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nq"><img src="../Images/140fc6ac7a9cc22240c34dd04bfad376.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mst2bOM-eZ-B9CUHPMUK5g.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">作者图片</p></figure><p id="9806" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">pop(流行度)列可用于创建另一个列，表示一首歌曲是否受欢迎(1)或不受欢迎(2)。直方图可用于显示数据集中每个要素的“相似”分布。这是特征工程的一个例子。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="3cc5" class="mg mh iq nh b gy nl nm l nn no">conditions = [<br/>    (class_train['pop'] &gt;= 55),<br/>    (class_train['pop'] &lt; 55) ]<br/>values = [1, 2]<br/>class_train['like'] = np.select(conditions, values)</span><span id="7387" class="mg mh iq nh b gy nr nm l nn no"># for all features<br/>pos_bpm = class_train[class_train['like'] == 1]['bpm']<br/>neg_bpm = class_train[class_train['like'] == 2]['bpm']<br/>pos_nrgy = class_train[class_train['like'] == 1]['nrgy']<br/>neg_nrgy = class_train[class_train['like'] == 2]['nrgy']<br/>pos_db = class_train[class_train['like'] == 1]['dB']<br/>neg_db = class_train[class_train['like'] == 2]['dB']<br/>pos_live = class_train[class_train['like'] == 1]['live']<br/>neg_live = class_train[class_train['like'] == 2]['live']<br/>pos_dur = class_train[class_train['like'] == 1]['dur']<br/>neg_dur = class_train[class_train['like'] == 2]['dur']<br/>pos_acous = class_train[class_train['like'] == 1]['acous']<br/>neg_acous = class_train[class_train['like'] == 2]['acous']<br/>pos_spch = class_train[class_train['like'] == 1]['spch']<br/>neg_spch = class_train[class_train['like'] == 2]['spch']<br/>pos_val = class_train[class_train['like'] == 1]['val']<br/>neg_val = class_train[class_train['like'] == 2]['val']<br/>pos_dnce = class_train[class_train['like'] == 1]['dnce']<br/>neg_dnce = class_train[class_train['like'] == 2]['dnce']</span><span id="9632" class="mg mh iq nh b gy nr nm l nn no">fig2 = plt.figure(figsize=(20,20))<br/>#dnce<br/>ax3 = fig2.add_subplot(331)<br/>ax3.set_xlabel('Danceability')<br/>ax3.set_ylabel('Count')<br/>ax3.set_title('Song Danceability Like Distribution')</span><span id="864f" class="mg mh iq nh b gy nr nm l nn no">pos_dnce.hist(alpha=0.5, bins=30)<br/>ax4 = fig2.add_subplot(331)</span><span id="cb38" class="mg mh iq nh b gy nr nm l nn no">neg_dnce.hist(alpha=0.5, bins=30)<br/>plt.legend(['Like', 'Dislike'])</span><span id="74fc" class="mg mh iq nh b gy nr nm l nn no">#duration<br/>ax5 = fig2.add_subplot(332)<br/>ax5.set_xlabel('Duration')<br/>ax5.set_ylabel('Count')<br/>ax5.set_title('Song Duration Like Distribution')</span><span id="8b5c" class="mg mh iq nh b gy nr nm l nn no">pos_dur.hist(alpha=0.5, bins=30)<br/>ax6 = fig2.add_subplot(332)</span><span id="948c" class="mg mh iq nh b gy nr nm l nn no">neg_dur.hist(alpha=0.5, bins=30)<br/>plt.legend(['Like', 'Dislike'])</span><span id="c91f" class="mg mh iq nh b gy nr nm l nn no"># loudness (dB)<br/>ax7 = fig2.add_subplot(333)<br/>ax7.set_xlabel('Loudness -dB')<br/>ax7.set_ylabel('Count')<br/>ax7.set_title('Song Loudness Like Distribution')<br/>plt.legend(['Like', 'Dislike'])</span><span id="a218" class="mg mh iq nh b gy nr nm l nn no">pos_db.hist(alpha=0.5, bins=30)<br/>ax8 = fig2.add_subplot(333)</span><span id="f803" class="mg mh iq nh b gy nr nm l nn no">neg_db.hist(alpha=0.5, bins=30)<br/>plt.legend(['Like', 'Dislike'])</span><span id="2d77" class="mg mh iq nh b gy nr nm l nn no"># energy<br/>ax9 = fig2.add_subplot(334)<br/>ax9.set_xlabel('Energy')<br/>ax9.set_ylabel('Count')<br/>ax9.set_title('Song Energy Like Distribution')</span><span id="67ee" class="mg mh iq nh b gy nr nm l nn no">pos_nrgy.hist(alpha=0.5, bins=30)<br/>ax9 = fig2.add_subplot(334)</span><span id="61d1" class="mg mh iq nh b gy nr nm l nn no">neg_nrgy.hist(alpha=0.5, bins=30)<br/>plt.legend(['Like', 'Dislike'])</span><span id="15f1" class="mg mh iq nh b gy nr nm l nn no"># live<br/>ax10 = fig2.add_subplot(335)<br/>ax10.set_xlabel('Liveness')<br/>ax10.set_ylabel('Count')<br/>ax10.set_title('Liveness - Like Distribution')</span><span id="3550" class="mg mh iq nh b gy nr nm l nn no">pos_live.hist(alpha=0.5, bins=30)<br/>ax11 = fig2.add_subplot(335)</span><span id="9e79" class="mg mh iq nh b gy nr nm l nn no">neg_live.hist(alpha=0.5, bins=30)<br/>plt.legend(['Like', 'Dislike'])</span><span id="5fca" class="mg mh iq nh b gy nr nm l nn no"># val<br/>ax12 = fig2.add_subplot(336)<br/>ax12.set_xlabel('Valence')<br/>ax12.set_ylabel('Count')<br/>ax12.set_title('Valence (Mood?) - Like Distribution')</span><span id="2a74" class="mg mh iq nh b gy nr nm l nn no">pos_val.hist(alpha=0.5, bins=30)<br/>ax13 = fig2.add_subplot(336)</span><span id="a336" class="mg mh iq nh b gy nr nm l nn no">neg_val.hist(alpha=0.5, bins=30)<br/>plt.legend(['Like', 'Dislike'])</span><span id="55ca" class="mg mh iq nh b gy nr nm l nn no"># acous<br/>ax14 = fig2.add_subplot(337)<br/>ax14.set_xlabel('Acousticness')<br/>ax14.set_ylabel('Count')<br/>ax14.set_title('Acousticness - Like Distribution')</span><span id="f5f4" class="mg mh iq nh b gy nr nm l nn no">pos_acous.hist(alpha=0.5, bins=30)<br/>ax15 = fig2.add_subplot(337)</span><span id="edb6" class="mg mh iq nh b gy nr nm l nn no">neg_acous.hist(alpha=0.5, bins=30)<br/>plt.legend(['Like', 'Dislike'])</span><span id="383a" class="mg mh iq nh b gy nr nm l nn no"># speech<br/>ax16 = fig2.add_subplot(338)<br/>ax16.set_xlabel('Speech')<br/>ax16.set_ylabel('Count')<br/>ax16.set_title('Speech - Like Distribution')</span><span id="301c" class="mg mh iq nh b gy nr nm l nn no">pos_spch.hist(alpha=0.5, bins=30)<br/>ax17 = fig2.add_subplot(338)</span><span id="9eca" class="mg mh iq nh b gy nr nm l nn no">neg_spch.hist(alpha=0.5, bins=30)<br/>plt.legend(['Like', 'Dislike'])</span><span id="9394" class="mg mh iq nh b gy nr nm l nn no"># bpm<br/>ax18 = fig2.add_subplot(339)<br/>ax18.set_xlabel('Beats Per Minute')<br/>ax18.set_ylabel('Count')<br/>ax18.set_title('Song BPM - Like Distribution')</span><span id="eb35" class="mg mh iq nh b gy nr nm l nn no">pos_bpm.hist(alpha=0.5, bins=30)<br/>ax19 = fig2.add_subplot(339)</span><span id="fd13" class="mg mh iq nh b gy nr nm l nn no">neg_bpm.hist(alpha=0.5, bins=30)<br/>plt.legend(['Like', 'Dislike'])</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ns"><img src="../Images/25c61433f6e75ff04a3db8f62d84e7e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QtZgv1_zc3aLkXJbPPNlKg.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">作者图片</p></figure><p id="ce3d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后调查歌曲在训练集中的流派分布。在训练集中，有86个独特的流派名称，这实在是太多了。经过进一步调查，这些流派名称中有许多只是地理上的差异，例如，“英国摇滚”和“专辑摇滚”——它们可以归入“摇滚”类别。因此，流派被进一步概括，将流派的数量从86个减少到20个。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="f976" class="mg mh iq nh b gy nl nm l nn no">class_train = class_train.replace({'top genre': {"album rock": "rock", "glam rock": "rock", "dance rock":"rock", "art rock":"rock",<br/>                                  "soft rock":"rock", "country rock": "rock", "classic rock":"rock", "blues rock":"rock", "celtic rock":"rock",<br/>                                  "australian rock":"rock", "german alternative rock":"rock", "alternative rock":"rock", "dance pop":"pop",<br/>                                "brill building pop": "pop", "europop": "pop", "barbadian pop": "pop", "classic uk pop":"pop", <br/>                                "new wave pop":"pop", "canadian pop":"pop", "art pop":"pop", "belgian pop": "pop", "britpop": "pop", <br/>                                "italian pop":"pop", "classic danish pop": "pop", "bow pop": "pop", "baroque pop": "pop", "bubblegum pop": "pop",<br/>                                "afropop":"pop", "hip pop":"pop", "atl hip hop": "hip hop", "east coast hip hop": "hip hop", "detroit hip hop":"hip hop", <br/>                                "bronx hip hop": "hip hop", "bubblegum dance": "dance", "eurodance":"dance", "belgian dance":"dance", "german dance": "dance",<br/>                                "classic soul": "soul", "british soul": "soul", "chicago soul": "soul", "british folk": "folk", "american folk revival":"folk",<br/>                                "drone folk":"folk","canadian folk":"folk", "deep adult standards":"adult standards", "glam metal": "metal", "alternative metal": "metal",<br/>                                "acoustic blues":"blues", "british blues":"blues", "louisiana blues":"blues", "g funk":"funk", "brit funk":"funk",<br/>                                "afrobeat":"dance", "british invasion":"rock", "doo-wop":"blues", "boy band":"pop", "merseybeat":"rock-and-roll", "blue":"blues",<br/>                                                "bebop":"jazz", "avant-garde jazz":"jazz", "boogaloo": "latin", "big room": "trance", "bubble trance":"trance", "glam punk":"rock",<br/>                                                "australian talent show":"pop", "mellow gold":"rock", "hi-nrg": "dance", "neo mellow": "pop", "yodeling":"folk", "classic girl group":"pop",<br/>                                                "british dance band":"jazz", "deep house":"dance", "uk garage": "dance", "chicago rap":"hip hop"}})</span></pre><p id="c15c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面的饼状图显示了前10个流派，只是为了保持可读性。很明显，训练数据集中的大多数歌曲属于摇滚和流行音乐类别——这种情况的影响将在结论中讨论。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="0915" class="mg mh iq nh b gy nl nm l nn no"># Find percent of each genre<br/>df_genre = class_train['top genre'].value_counts()[:10].sort_values(ascending=False) / len(class_train)<br/>sizes = df_genre.values.tolist()<br/>labels = df_genre.index.values.tolist()</span><span id="2ce1" class="mg mh iq nh b gy nr nm l nn no"># Pie chart for genre<br/>fig1, ax1 = plt.subplots(figsize=(10,10))<br/>ax1.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=False, textprops={'fontsize': 14})<br/>ax1.axis('equal')<br/>plt.title("Most Popular Genres\n" + "(limited to top 10 genres)", bbox={'facecolor':'0.8', 'pad':5})<br/>plt.show()</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nt"><img src="../Images/b82023f05e9c4a938229c59b1624cb88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FBPuN8uYaOoLYv6G3-oeRA.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">作者图片</p></figure><p id="bddd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后观察特征的分布。这是因为我们希望每个特征的直方图显示正态分布。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="2d1a" class="mg mh iq nh b gy nl nm l nn no">import matplotlib.pyplot as plt<br/>%matplotlib inline<br/>class_train.hist(bins=20, figsize=(15,15))<br/>plt.show()</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nu"><img src="../Images/98de087b826406121f65d5a70c7b22a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zfrR_GSuIedpPYA_m7lJUQ.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">作者图片</p></figure><p id="9ea0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面的直方图显示一些变量是偏斜的(acous，live，spch)，这种偏斜可能是异常值的原因。因此，可以通过移除潜在的异常值来纠正这种偏差。可以使用箱线图和<a class="ae mf" href="https://www.geeksforgeeks.org/z-score-for-outlier-detection-python/" rel="noopener ugc nofollow" target="_blank"> z值</a>来识别异常值。z值大于3的数据点将被移除。移除异常值以减少噪声可以提高模型的性能并防止过度拟合。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="c0da" class="mg mh iq nh b gy nl nm l nn no">import seaborn as sns<br/># acoustic<br/>sns.boxplot(x=class_train['acous']) # no visible outliers<br/># dur<br/>sns.boxplot(x=class_train['dur']) # OUTLIERS !!<br/># live<br/>sns.boxplot(x=class_train['live']) #OUTLIERS !!<br/># spch<br/>sns.boxplot(x=class_train['spch']) #OUTLIERS !!</span><span id="5ed4" class="mg mh iq nh b gy nr nm l nn no">class_train = class_train[np.abs(class_train.dur-class_train.dur.mean()) &lt;= (3*class_train.dur.std())]<br/># keep only the ones that are within +3 to -3 standard deviations in the column 'live'.</span><span id="5a93" class="mg mh iq nh b gy nr nm l nn no">class_train = class_train[np.abs(class_train.live-class_train.live.mean()) &lt;= (3*class_train.live.std())]<br/># keep only the ones that are within +3 to -3 standard deviations in the column 'live'.</span><span id="e700" class="mg mh iq nh b gy nr nm l nn no">class_train= df[np.abs(class_train.spch-class_train.spch.mean()) &lt;= (3*class_train.spch.std())]<br/># keep only the ones that are within +3 to -3 standard deviations in the column 'spch'.</span></pre><p id="d8af" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将在模型创建过程中使用的特征是第3列到第13列。被删除的功能有标题、艺术家和Id。为模型训练选择的特征是:“年份”、“bpm”、“nrgy”、“dnce”、“dB”、“spch”、“pop”、“live”、“acous”。</p><p id="f7ca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后使用train_test_split函数对训练集进行分离，以进一步将数据划分为75% / 25%的分割。通过进一步分割训练数据集，我们创建了一个<a class="ae mf" href="https://machinelearningmastery.com/difference-test-validation-datasets/#:~:text=The%20%E2%80%9Ctraining%E2%80%9D%20data%20set%20is,is%20used%20to%20qualify%20performance.&amp;text=Perhaps%20traditionally%20the%20dataset%20used,called%20the%20%E2%80%9Ctest%20set%E2%80%9D." rel="noopener ugc nofollow" target="_blank">验证集</a>。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="c289" class="mg mh iq nh b gy nl nm l nn no">y = class_train.values[:,14]<br/>X = class_train.values[:,3:13]</span><span id="489f" class="mg mh iq nh b gy nr nm l nn no">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)</span></pre><h2 id="b31a" class="mg mh iq bd mi mj mk dn ml mm mn dp mo ko mp mq mr ks ms mt mu kw mv mw mx my bi translated">算法选择+模型性能+改进</h2><p id="6e3d" class="pw-post-body-paragraph kf kg iq kh b ki mz jr kk kl na ju kn ko nb kq kr ks nc ku kv kw nd ky kz la ij bi translated">这三个部分紧密交织在一起。因为所选择的算法在很大程度上取决于它与其他算法相比的表现，反过来，改进在很大程度上是一个迭代过程。</p><p id="e68e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">支持向量机(SVM)算法是分析的好选择，因为训练集具有少量实例和大量特征。这是<a class="ae mf" href="https://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">合适的</a>，因为SVM算法可以处理高偏差/低方差。<a class="ae mf" href="https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/#:~:text=One%2Dvs%2Drest%20(OvR%20for%20short%2C%20also%20referred,into%20multiple%20binary%20classification%20problems." rel="noopener ugc nofollow" target="_blank"> OneVersusRest </a>是一种启发式方法，涉及将训练数据拆分为多个二元分类问题。如前所述，这个问题被认为是多重标签。然而，SVM算法要求正标签的数值为+1，负标签的数值为-1。因此，使用OneVersusRest技术，它对每个二元分类问题训练二元分类器，并根据最有把握的模型进行预测。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="91ab" class="mg mh iq nh b gy nl nm l nn no">from sklearn import datasets<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.svm import LinearSVC<br/>from sklearn.multiclass import OneVsRestClassifier<br/><br/>std_scaler = StandardScaler()<br/>X_scaled_train = std_scaler.fit_transform(X_train)<br/>X_scaled_train <strong class="nh ir">=</strong> std_scaler.fit_transform(X_train)</span><span id="a553" class="mg mh iq nh b gy nr nm l nn no">X_scaled_train <strong class="nh ir">=</strong> std_scaler.fit_transform(X_train)</span><span id="6916" class="mg mh iq nh b gy nr nm l nn no">svm_clf <strong class="nh ir">=</strong> OneVsRestClassifier(LinearSVC(C<strong class="nh ir">=</strong>1, loss <strong class="nh ir">=</strong> "hinge", random_state <strong class="nh ir">=</strong> 1))</span><span id="c82d" class="mg mh iq nh b gy nr nm l nn no">svm_clf.fit(X_scaled_train, y_train)</span></pre><p id="761b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在构建我们的SVM之前进行缩放，因为它们对要素比例很敏感。这是为了防止模型中<a class="ae mf" href="https://zhuanlan.zhihu.com/p/349758659#:~:text=The%20fundamental%20idea%20behind%20Support%20Vector%20Machines%20is%20to%20fit,classes%20and%20the%20training%20instances." rel="noopener ugc nofollow" target="_blank">最宽的可能街道</a>过于靠近决策边界。</p><p id="d9f4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">超参数不是由学习算法优化的，必须由我们这些数据分析师来完成。网格搜索是最简单的超参数调整方法，可以在scikit-learn Python机器学习库中找到。在使用C=1的超参数的模型的第一次运行中，精确度非常低，为26%。使用网格搜索将C(算法的超参数之一)减少到0.01。这将防止过度拟合。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="f787" class="mg mh iq nh b gy nl nm l nn no">SVCpipe = Pipeline([('scale', StandardScaler()),<br/>                   ('SVC',LinearSVC())])</span><span id="be75" class="mg mh iq nh b gy nr nm l nn no"># Gridsearch to determine the value of C<br/>param_grid = {'SVC__C':np.arange(0.01,100,10)}<br/>linearSVC = GridSearchCV(SVCpipe,param_grid,cv=5,return_train_score=True)<br/>linearSVC.fit(X_train,y_train)<br/>print(linearSVC.best_params_)</span><span id="6c7c" class="mg mh iq nh b gy nr nm l nn no">svm_clf = OneVsRestClassifier(LinearSVC(C=0.01, loss = "hinge", random_state=1))<br/><br/>preds = svm_clf.predict(X_scaled_train)<br/>from sklearn.metrics import classification_report<br/>print(classification_report(y_train,preds))</span></pre><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/a59d1226b9c13d95af6ade149869f2b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*fHUnpv0TeEHHDBMrDe2dkA.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">作者图片</p></figure><p id="5306" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最终达到的模型精度为46%。其中准确度是正确分类的例子的数量除以分类的例子的总数。</p><p id="7030" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">逻辑回归算法是一种分类算法，而不是回归算法，可用于二元和多类问题。获得的准确度分数为50%。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="c105" class="mg mh iq nh b gy nl nm l nn no">from sklearn.linear_model import LogisticRegression<br/>ovr_clf = OneVsRestClassifier(LogisticRegression(max_iter=1000, random_state=1))<br/>ovr_clf.fit(X_train, y_train)<br/>y_test_pred = ovr_clf.predict(X_test)</span><span id="3598" class="mg mh iq nh b gy nr nm l nn no">from sklearn.metrics import accuracy_score<br/>confusion_matrix(y_test, y_test_pred)<br/>print(accuracy_score(y_test, y_test_pred))</span></pre><p id="530c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae mf" rel="noopener" target="_blank" href="/understanding-random-forest-58381e0602d2">随机森林算法</a>使用一种改进的树学习算法来检查“学习”过程中每个分裂处的随机特征子集。这样就避免了树的相关性。随机森林减少了最终模型的方差，从而减少了过度拟合。Random Forest取得了46%的准确率。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="72f4" class="mg mh iq nh b gy nl nm l nn no">from sklearn.ensemble import RandomForestClassifier<br/>rnd_clf = RandomForestClassifier(n_estimators=25, max_leaf_nodes=16, n_jobs=-1, random_state=1)<br/>rnd_clf.fit(X_train, y_train)<br/>ypred = rnd_clf.predict(X_test)<br/>print(accuracy_score(y_test, ypred))</span></pre><p id="79a6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">选择最好的3个模型用于集成学习:SVM、逻辑回归和随机森林。使用硬投票分类器，因为它实现了高精度。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="0549" class="mg mh iq nh b gy nl nm l nn no">from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.ensemble import VotingClassifier<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.svm import SVC</span><span id="4ca2" class="mg mh iq nh b gy nr nm l nn no">log_clf = OneVsRestClassifier(LogisticRegression(max_iter=1000, penalty = "l2", C=1, random_state=1))<br/>rnd_clf = RandomForestClassifier(random_state=1)<br/>svm_clf = OneVsRestClassifier(LinearSVC(C=0.01, loss = "hinge", random_state = 1))<br/>voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],voting='hard')<br/>voting_clf.fit(X_train, y_train)</span><span id="04db" class="mg mh iq nh b gy nr nm l nn no">from sklearn.metrics import accuracy_score<br/>for clf in (log_clf, rnd_clf, svm_clf, voting_clf):<br/>    clf.fit(X_train, y_train)<br/>    ypred = clf.predict(X_test)<br/>    print(clf.__class__.__name__, accuracy_score(y_test, ypred))</span></pre><p id="2ee6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">逻辑回归和投票分类器得分相同。选择投票分类器是因为它更稳健，因为它减少了预测和模型性能的传播。</p><h2 id="77dc" class="mg mh iq bd mi mj mk dn ml mm mn dp mo ko mp mq mr ks ms mt mu kw mv mw mx my bi translated">结论</h2><p id="1118" class="pw-post-body-paragraph kf kg iq kh b ki mz jr kk kl na ju kn ko nb kq kr ks nc ku kv kw nd ky kz la ij bi translated">当提交给Kaggle竞赛时…一个可接受的第17名(50支队伍中)。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nw"><img src="../Images/f63399a5b92cac0ea9807ed908c83f79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aXrYUSnjcu5bE2snTieQqw.png"/></div></div></figure><p id="4504" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当选定的模型应用于测试数据时(一旦提交给Kaggle竞赛)，准确性得分明显较低。这被称为过度拟合，即模型可以很好地预测训练数据的标签，但在应用于新数据时会经常出错。这意味着模型有很高的方差。</p><p id="5683" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尝试过的过度拟合的可能解决方案:</p><ul class=""><li id="2809" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">添加更多数据</li><li id="b773" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">移除异常值</li><li id="5f76" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">降维(通过主成分分析)</li></ul><p id="4b30" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过识别15个空值并在训练集中手动添加流派标签，试图增加总体样本大小。然而，使用z分数移除异常值会产生很大的反作用。总体而言，可用于训练模型的数据量非常有限，这可能是导致过度拟合的原因。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="f452" class="mg mh iq nh b gy nl nm l nn no"># reload the data<br/>class_train = pd.read_csv("CS98XClassificationTrain.csv")<br/>class_test = pd.read_csv("CS98XClassificationTest.csv")</span><span id="a9ec" class="mg mh iq nh b gy nr nm l nn no"># update the genres for the missing values<br/>class_train.loc[class_train['title'] == 'Unchained Melody', 'top genre'] = 'pop'<br/>class_train.loc[class_train['title'] == 'Someone Elses Roses', 'top genre'] = 'adult standards'<br/>class_train.loc[class_train['title'] == 'Drinks On The House', 'top genre'] = 'pop'<br/>class_train.loc[class_train['title'] == 'Pachuko Hop', 'top genre'] = 'blues'<br/>class_train.loc[class_train['title'] == 'Little Things Means A Lot', 'top genre'] = 'blues'<br/>class_train.loc[class_train['title'] == 'The Lady Is A Tramp', 'top genre'] = 'pop'<br/>class_train.loc[class_train['title'] == 'If I Give My Heart To You', 'top genre'] = 'pop'<br/>class_train.loc[class_train['title'] == 'Happy Days And Lonely Nights','top genre'] = 'rock'<br/>class_train.loc[class_train['title'] == 'Stairway Of Love','top genre'] = 'rock'<br/>class_train.loc[class_train['title'] == 'You', 'top genre'] = 'pop'<br/>class_train.loc[class_train['title'] == 'No Other Love' , 'top genre'] = 'adult standards'  <br/>class_train.loc[class_train['title'] == "Hot Diggity" , 'top genre'] = 'folk'<br/>class_train.loc[class_train['title'] == "Ain't That Just the Way" , 'top genre'] = 'r&amp;b'<br/>class_train.loc[class_train['title'] == "I Promised Myself" , 'top genre'] = 'pop'</span><span id="be9f" class="mg mh iq nh b gy nr nm l nn no"># dropping NULL values  (I've Waited So Long Anthony Newley = ? (Dance/ Electronic))<br/>class_train = class_train.dropna(axis=0)</span><span id="f532" class="mg mh iq nh b gy nr nm l nn no"># check again for null values<br/>class_train.info()</span></pre><p id="d72d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">PCA(主成分分析)是一种降维方法。降维移除数据集中冗余和高度相关的特征。它还有助于减少数据中的总体噪声。</p><pre class="lq lr ls lt gt ng nh ni nj aw nk bi"><span id="707d" class="mg mh iq nh b gy nl nm l nn no">from sklearn.decomposition import PCA</span><span id="5dcd" class="mg mh iq nh b gy nr nm l nn no">pca = PCA()<br/>X_train = pca.fit_transform(X_train)<br/>X_test = pca.transform(X_test)</span><span id="7a14" class="mg mh iq nh b gy nr nm l nn no">explained_variance = pca.explained_variance_ratio_<br/>pca = PCA(n_components=0.95)<br/>X_reduced = pca.fit_transform(X_train)<br/>print(pca.explained_variance_ratio_)</span><span id="b8be" class="mg mh iq nh b gy nr nm l nn no">pca = PCA(n_components=6)<br/>X_train = pca.fit_transform(X_train)<br/>X_test = pca.transform(X_test)</span></pre><p id="7cb3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用主成分分析来降低维数没有显示出对Kaggle分数的改善。当特征之间有很强的相关性时，PCA是最有效的。正如之前在关联热图中所强调的，训练数据集中的要素之间没有强关联。</p><p id="235a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然该模型在测试数据上表现不佳，但希望有一些有用的经验教训和可视化，可以为您未来的项目重铸！</p><p id="5513" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">安德烈·布尔科夫的百页机器学习书是一个很好的免费资源来学习更多关于ML的知识。</p></div></div>    
</body>
</html>