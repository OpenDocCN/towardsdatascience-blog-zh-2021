<html>
<head>
<title>A Guide to Regularization in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python正则化指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-guide-to-regularization-in-python-8abf91ebca9a?source=collection_archive---------14-----------------------#2021-12-07">https://towardsdatascience.com/a-guide-to-regularization-in-python-8abf91ebca9a?source=collection_archive---------14-----------------------#2021-12-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b9ab" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用正则化来防止深度学习模型中的过拟合</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4542fb461d3960a8885c11fca0f632f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kp4XYg7obqvn4VVjOXi7-g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">安娜·涅克拉舍维奇在<a class="ae ky" href="https://www.pexels.com/photo/magnifying-glass-on-top-of-document-6801648/" rel="noopener ugc nofollow" target="_blank">的图片</a></p></figure><p id="285a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">过度拟合是数据科学家在构建高度复杂的模型时面临的一个常见问题。当模型非常适合训练数据，但随后在新数据上进行测试时表现不佳时，就会出现这种情况。</p><p id="ed09" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个问题在构建深度神经网络模型时最常出现，深度神经网络模型是一种统计模型，松散地表示大脑中的连通性。这些模型往往很复杂，因为它们可能包含数百到数千个参数。由于高度的复杂性，这些模型可以拾取随机噪声作为真正的趋势，这导致在对新数据进行推断时性能不佳。</p><p id="15ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于任何使用深度学习模型进行预测的企业来说，过度拟合都是一个很大的问题。例如，如果一家公司想要预测客户保持率，过度拟合模型可能会将数据中的随机噪声和异常值表示为重要的统计趋势。因此，当用于预测客户未来是否会重复购买时，该模型的表现将会很差，从而导致公司的收入损失巨大。</p><p id="e7a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">几种方法通常用于防止深度学习模型中的过度拟合。套索回归，也称为L1正则化，是一种在复杂模型(如神经网络)中防止过度拟合的流行方法。L1正则化通过向模型添加惩罚项来工作。这种损失会导致模型中的一些系数变为零，您可以将其解释为丢弃分配了随机噪声、异常值或在数据中发现的任何其他统计上无关紧要的关系的模型权重。</p><p id="460e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通常，L1正则化对于模型构建过程的特征选择步骤是有用的。具体来说，您可以使用它来移除预测能力不强的要素。例如，在预测客户保持率时，我们可能会访问一些对做出准确预测不太有用的功能，如客户的姓名和电子邮件。</p><p id="8d59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一种正则化方法是岭回归，也称为L2正则化。岭回归的工作原理是均匀收缩分配给模型中要素的权重。当模型中的要素高度相关时，此方法非常有用。在客户保持示例中，高度相关的特征可能是上次购买花费的美元或购买的商品数量。这两个特征高度相关，因为顾客购买的商品越多，他们花的钱就越多。共线要素的存在也会对模型性能产生负面影响。</p><p id="43ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Python库<a class="ae ky" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>使得构建深度学习模型变得容易。深度学习库可用于建立分类、回归和无监督聚类任务的模型。此外，Keras还使得将L1和L2正则化方法应用于这些统计模型变得很容易。通过在单行代码中指定参数值，L1和L2正则化都可以应用于深度学习模型。</p><p id="c91b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我们将使用<a class="ae ky" href="https://www.kaggle.com/blastchar/telco-customer-churn" rel="noopener ugc nofollow" target="_blank">电信公司流失数据</a>来建立一个预测客户保留率的深度神经网络模型。该数据包含一个虚构的电信公司的信息。</p><p id="9884" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">数据准备</strong></p><p id="172f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们导入Pandas库并将电信客户流失数据读入Pandas数据框:</p><p id="14d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">进口熊猫作为pd</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="2536" class="ma mb it lw b gy mc md l me mf">df = pd.read_csv('telco_churn.csv')</span></pre><p id="4938" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们显示前五行数据:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="62c1" class="ma mb it lw b gy mc md l me mf">print(df.head())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mg"><img src="../Images/ff9051d91fa30f216164cd3524450716.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Xxinwd6ercA7tepA"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="551d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了构建客户流失模型，我们需要将数据中的客户流失列转换为机器可读的值。在churn的值为“否”的情况下，我们将分配标签“零”，在churn的值为“是”的情况下，我们将分配标签“一”</p><p id="9a05" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们导入Numpy包并使用where()方法来标记我们的数据:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="08da" class="ma mb it lw b gy mc md l me mf">import numpy as np</span><span id="6be4" class="ma mb it lw b gy mh md l me mf">df['Churn'] = np.where(df['Churn'] == 'Yes', 1, 0)</span></pre><p id="631a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据中的许多字段都是分类的。我们需要将这些字段转换成机器可读的分类代码，以便训练我们的模型。让我们编写一个函数，它接受分类列名的列表，并修改我们的数据框以包含每列的分类代码:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="6815" class="ma mb it lw b gy mc md l me mf">def convert_categories(cat_list):<br/>    for col in cat_list:<br/>        df[col] = df[col].astype('category')<br/>        df[f'{col}_cat'] = df[col].cat.codes<br/>        df[f'{col}_cat'] = df[f'{col}_cat'].astype(float)</span></pre><p id="ed00" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们定义分类列的列表:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="08ea" class="ma mb it lw b gy mc md l me mf">category_list = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService',<br/>                  'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',<br/>                  'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']<br/>convert_categories(category_list)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mi"><img src="../Images/e76059235ab09d61d82a83b75a62b153.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qc1m51nC4L1lMnoD"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="a9b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，我们的数据框现在包含每个分类列的分类代码。</p><p id="30dc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们定义我们的输入和输出:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="51a9" class="ma mb it lw b gy mc md l me mf">df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')<br/>df['TotalCharges'].fillna(0, inplace=True)<br/>cols = ['gender_cat', 'Partner_cat', 'Dependents_cat', 'PhoneService_cat', 'MultipleLines_cat', 'InternetService_cat',<br/>                  'OnlineSecurity_cat', 'OnlineBackup_cat', 'DeviceProtection_cat', 'TechSupport_cat', 'StreamingTV_cat',<br/>                  'StreamingMovies_cat', 'Contract_cat', 'PaperlessBilling_cat', 'PaymentMethod_cat','MonthlyCharges',<br/>                  'TotalCharges', 'SeniorCitizen', 'tenure']</span><span id="75e2" class="ma mb it lw b gy mh md l me mf">X = df[cols]<br/>print(X.head())<br/>df['Churn'] = df['Churn'].astype(int)<br/>y = df['Churn']</span></pre><p id="2757" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们为Scikit-learn中的模型选择模块导入训练/测试分割方法。让我们为训练和测试拆分我们的数据</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="8967" class="ma mb it lw b gy mc md l me mf">from sklearn.model_selection import train_test_split</span><span id="ef3f" class="ma mb it lw b gy mh md l me mf">X_train, X_test_hold_out, y_train, y_test_hold_out = train_test_split(X, y, test_size=0.33)</span></pre><p id="9c7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">用于分类的神经网络</strong></p><p id="5de5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了开始构建我们的分类神经网络模型，让我们从Keras中的layers模块导入dense layer类。让我们从Keras的models模块中导入sequential类，从Scikit-learn的metric模块中导入accuracy方法:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="f348" class="ma mb it lw b gy mc md l me mf">from tensorflow.keras.layers import Dense</span><span id="7b83" class="ma mb it lw b gy mh md l me mf">from tensorflow.keras.models import Sequential</span><span id="993b" class="ma mb it lw b gy mh md l me mf">from sklearn.metrics import accuracy_score</span></pre><p id="dad5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们定义并拟合我们的模型，并使模型符合我们的训练数据。我们将建立一个具有两个隐藏层和32个神经元的神经网络。我们还将使用20个时期，这对应于通过训练数据的次数。</p><p id="64fe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们定义我们的模型对象。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="7e25" class="ma mb it lw b gy mc md l me mf">model = Sequential()</span></pre><p id="556a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们使用add方法添加一个密集层。我们需要传入特性的数量，即列列表的长度，以及输入，即包含列列表长度的元组。我们还将根据正态分布并使用校正线性单位(ReLu)激活函数来初始化权重值。激活函数是模拟神经元放电的函数:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="dc80" class="ma mb it lw b gy mc md l me mf">model.add(Dense(len(cols),input_shape=(len(cols),), kernel_initializer='normal', activation='relu'))</span></pre><p id="76bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将使用add方法添加两个隐藏层。这些层将具有32个神经元，并且还使用ReLu激活功能:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="bd95" class="ma mb it lw b gy mc md l me mf">model.add(Dense(32, activation='relu'))</span><span id="5cc5" class="ma mb it lw b gy mh md l me mf">model.add(Dense(32, activation='relu'))</span></pre><p id="2e66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们需要添加输出层，它将有一个神经元和一个softmax激活函数。这将允许我们的模型输出类别概率，以预测客户是否会流失:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="8ef6" class="ma mb it lw b gy mc md l me mf">model.add(Dense(1, activation='softmax'))</span><span id="ba27" class="ma mb it lw b gy mh md l me mf">model.compile(optimizer = 'adam',loss='binary_crossentropy', metrics =['accuracy'])</span><span id="0658" class="ma mb it lw b gy mh md l me mf">model.fit(X_train, y_train,epochs =20)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mj"><img src="../Images/eb78ea08e31de36cea595a42621d26c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-mzl6gxnARSWW9JG"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="4657" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，随着每个历元的增加，损耗一般会减少，而精度会增加。</p><p id="8ad1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们进行预测。预测输出是对应于测试数据中每个输入的流失概率的列表。我们可以将预测转换为二进制分数，其中大于50 %( 0.5)的概率值将被分类为流失，标签为1。否则，它将被归类为标签为0的客户，对应于留在公司的客户:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="f4b7" class="ma mb it lw b gy mc md l me mf">y_pred = model.predict(X_test)</span><span id="7e48" class="ma mb it lw b gy mh md l me mf">y_pred = np.where(y_pred &gt; 0.5, 1, 0)</span><span id="892d" class="ma mb it lw b gy mh md l me mf">Let’s also calculate the accuracy of our model:</span><span id="410b" class="ma mb it lw b gy mh md l me mf">print(“Accuracy: “, accuracy_score(y_pred, y_test))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/77a526799052311b37d9d7c96be72e5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/0*Ly8IcEtdO-7p8KMx"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="bf31" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们看到我们的模型准确率为77.9%，这是相当不错的。让我们看看是否可以通过lasso回归来提高性能。</p><p id="a815" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">拉索回归(L1正则化)</strong></p><p id="dca9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Keras使得用神经网络模型实现lasso回归变得简单明了。Keras中的正则化器包有一个我们可以调用的方法，在我们的神经网络层中命名为l1。这将对层中的权重应用惩罚项，这将有助于防止过度拟合。</p><p id="01f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通常，lasso回归将无关紧要的要素权重设置为零，从而允许模型包含最重要的要素以进行准确预测。让我们从Keras导入正则化包:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="aa01" class="ma mb it lw b gy mc md l me mf">from tensorflow.keras import regularizers</span></pre><p id="2b93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们定义一个新的模型对象，我们称之为model_lasso。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="5d4f" class="ma mb it lw b gy mc md l me mf">model_lasso = Sequential()</span></pre><p id="8dfd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在输入层中，我们将使用正则化程序包中的l1方法为kernel _ regularizer传入一个值:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="ba70" class="ma mb it lw b gy mc md l me mf">model_lasso.add(Dense(len(cols),input_shape=(len(cols),), kernel_initializer='normal', activation='relu', kernel_regularizer = regularizers.l1(1e-6)))</span></pre><p id="f78c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来的几行代码与我们最初的神经网络模型相同。唯一的区别是我们正在使用模型对象model_lasso，而不是模型:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="4734" class="ma mb it lw b gy mc md l me mf">model_lasso.add(Dense(32, activation='relu'))<br/>model_lasso.add(Dense(32, activation='relu'))<br/>model_lasso.add(Dense(1, activation='sigmoid'))<br/>model_lasso.compile(optimizer = 'adam',loss='binary_crossentropy', metrics =['accuracy'])<br/>model_lasso.fit(X_train, y_train,epochs =20)</span><span id="308e" class="ma mb it lw b gy mh md l me mf">y_pred = model_lasso.predict(X_test)<br/>y_pred = np.where(y_pred &gt; 0.5, 1, 0)<br/>print("Accuracy With Lasso: ", accuracy_score(y_pred, y_test))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/e12ab5cf5cea0f02890d8d00b60c8545.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/0*po46Rb0k7rVwQMje"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="69fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果模型中有许多对性能没有积极贡献的要素，套索回归是一个很好的选择。因此，它作为一个功能选择工具非常有用。</p><p id="459d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">岭回归(L2) </strong></p><p id="82aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在Keras中，将岭回归应用于神经网络模型也很容易。类似于套索方法，我们只需要在神经网络的层中调用一个方法名l2。lasso和ridge之间的区别在于，前者倾向于完全丢弃无关紧要的值，而ridge只是减少我们的神经网络中所有特征的权重大小。让我们定义一个名为model_ridge的新模型对象:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="2116" class="ma mb it lw b gy mc md l me mf">model_ridge = Sequential()</span></pre><p id="b8d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在输入层，我们将使用l2方法:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="a231" class="ma mb it lw b gy mc md l me mf">model_ridge.add(Dense(len(cols),input_shape=(len(cols),), kernel_initializer='normal', activation='relu', kernel_regularizer = regularizers.l2(1e-6)))</span></pre><p id="713a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">剩下的和我们上面做的类似:</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="2b6c" class="ma mb it lw b gy mc md l me mf">model_ridge.add(Dense(32, activation='relu'))<br/>model_ridge.add(Dense(32, activation='relu'))<br/>model_ridge.add(Dense(1, activation='sigmoid'))<br/>model_ridge.compile(optimizer = 'adam',loss='binary_crossentropy', metrics =['accuracy'])<br/>model_ridge.fit(X_train, y_train,epochs =20)</span><span id="6f54" class="ma mb it lw b gy mh md l me mf">y_pred = model_ridge.predict(X_test)<br/>y_pred = np.where(y_pred &gt; 0.5, 1, 0)<br/>print("Accuracy With Ridge: ", accuracy_score(y_pred, y_test))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/8f70f0f7c41da9ab0c783ab4add0ce0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/0*3Rzf55P7clGWAtcB"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="66a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用ridge，精度比我们构建的第一个神经网络以及使用lasso的神经网络稍好。选择最佳的正则化方法取决于用例。如果使用模型中的所有输入要素很重要，那么岭回归可能是正则化的更好选择。这可能是为了训练我们的模型而需要保留某些特征的情况。</p><p id="e8f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，一个薄弱的特征可能仍然是一家公司的杠杆。他们可能希望了解模型预测如何随着弱特征的值的变化而变化，即使它对性能的贡献不是很大。</p><p id="3e2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章的代码可以在GitHub 上找到。</p><p id="cca0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">结论</strong></p><p id="1e0b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于使用神经网络等复杂模型的数据科学团队来说，防止模型过度拟合非常重要。如果不加以考虑，过度拟合会对公司的收入产生重大影响。具有许多参数的模型，如神经网络，特别容易过度拟合，并可能给研究人员一种模型性能良好的错觉。</p><p id="5ec7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通常，过拟合模型在对当前数据进行测试时表现出很强的性能，而一旦向模型提供新数据，其性能就会非常差。例如，在客户流失的情况下，如果客户不会重复购买，overfit模型可能能够以很高的准确度进行预测。然而，当出现新的客户数据时，overfit模型将表现不佳，并且不再能够预测客户流失。这种不准确会导致公司浪费大量的金钱和资源，通过广告和促销瞄准错误的客户，而忽略了实际上可能流失的客户。出于这个原因，对于每个数据科学家来说，很好地理解如何使用lasso和ridge回归来防止复杂模型的过度拟合是一项重要的技能。</p><p id="a49a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你有兴趣学习python编程的基础知识、Pandas的数据操作和python中的机器学习，请查看<a class="ae ky" href="https://www.amazon.com/dp/B08N38XW2Q/ref=sr_1_1?dchild=1&amp;keywords=sadrach+python&amp;qid=1604966500&amp;s=books&amp;sr=1-1" rel="noopener ugc nofollow" target="_blank"><em class="mm">Python for Data Science and Machine Learning:Python编程、Pandas和sci kit-初学者学习教程</em> </a> <em class="mm">。我希望你觉得这篇文章有用/有趣。</em></p><p id="6d70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="mm">本帖原载于</em> </strong> <a class="ae ky" href="https://builtin.com/data-science" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="mm">内置博客</em> </strong> </a> <strong class="lb iu"> <em class="mm">。原片可以在这里找到</em></strong><a class="ae ky" href="https://builtin.com/data-science/overfitting-regularization-python" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="mm"/></strong></a><strong class="lb iu"><em class="mm">。</em> </strong></p></div></div>    
</body>
</html>