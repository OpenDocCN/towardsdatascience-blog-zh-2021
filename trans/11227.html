<html>
<head>
<title>Performance Comparison: CatBoost vs XGBoost and CatBoost vs LightGBM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">性能比较:CatBoost与XGBoost以及CatBoost与LightGBM</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/performance-comparison-catboost-vs-xgboost-and-catboost-vs-lightgbm-886c1c96db64?source=collection_archive---------11-----------------------#2021-11-03">https://towardsdatascience.com/performance-comparison-catboost-vs-xgboost-and-catboost-vs-lightgbm-886c1c96db64?source=collection_archive---------11-----------------------#2021-11-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="8d66" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">助推技术</h2><div class=""/><div class=""><h2 id="6a8f" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">机器学习中的助推算法——第七部分</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/7148b70a7d7cf1affe7258b99c159cff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i-lf2dNE5KDFSHyexVcDHQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">Arnaud Mesureur 在<a class="ae lh" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="42f2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">到目前为止，我们已经讨论了5种不同的boosting算法:<a class="ae lh" rel="noopener" target="_blank" href="/how-do-you-implement-adaboost-with-python-a76427b0fa7a"> <strong class="lk jd"> AdaBoost </strong> </a>，<a class="ae lh" rel="noopener" target="_blank" href="/under-the-hood-of-gradient-boosting-and-its-python-implementation-99cc63efd24d"> <strong class="lk jd">梯度Boosting </strong> </a>，<a class="ae lh" href="https://rukshanpramoditha.medium.com/unlock-the-power-of-xgboost-738536b9f36f" rel="noopener"> <strong class="lk jd"> XGBoost </strong> </a>，<a class="ae lh" rel="noopener" target="_blank" href="/can-lightgbm-outperform-xgboost-d05a94102a55"><strong class="lk jd">light GBM</strong></a><strong class="lk jd"/>和<a class="ae lh" rel="noopener" target="_blank" href="/how-do-you-use-categorical-features-directly-with-catboost-947b211c2923"> <strong class="lk jd"> CatBoost </strong> </a>。</p><p id="70c2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其中，<a class="ae lh" href="https://rukshanpramoditha.medium.com/unlock-the-power-of-xgboost-738536b9f36f" rel="noopener"> <strong class="lk jd"> XGBoost </strong> </a>，<a class="ae lh" rel="noopener" target="_blank" href="/can-lightgbm-outperform-xgboost-d05a94102a55"><strong class="lk jd">light GBM</strong></a><strong class="lk jd"/>和<a class="ae lh" rel="noopener" target="_blank" href="/how-do-you-use-categorical-features-directly-with-catboost-947b211c2923"><strong class="lk jd">CatBoost</strong></a><strong class="lk jd"/>是更重要的算法，因为它们产生更准确的结果，执行时间更快。</p><p id="c78c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在<a class="ae lh" rel="noopener" target="_blank" href="/can-lightgbm-outperform-xgboost-d05a94102a55">第5部分</a>中，我们已经比较了XGBoost和LightGBM的性能和执行时间。在那里，我们发现:</p><blockquote class="me mf mg"><p id="7e9d" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated">LightGBM有时会优于XGBoost，但并不总是如此。但是，LightGBM比XGBoost快7倍左右！</p></blockquote><p id="52bb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">是时候对CatBoost和XGBoost以及CatBoost和LightGBM进行一些性能比较了。在本内容的最后，我还将提到一些指导原则，帮助您为您的任务选择正确的升压算法。</p><h1 id="f2e7" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">CatBoost与XGBoost</h1><p id="c3b5" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">这里我们考虑2个因素:<strong class="lk jd"> <em class="mh">性能</em> </strong>和<strong class="lk jd"> <em class="mh">执行时间</em> </strong>。我们在<a class="ae lh" href="https://drive.google.com/file/d/1Kees3lk-Zo7AsrYz7svcj8Hnbr6gHok6/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">加州房价数据集</a>上构建CatBoost和XGBoost回归模型。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">CatBoost与XGBoost</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/139231ed33593b18219e238b2f24d5dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*RlCeB5ek52svULApnk4oPw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><blockquote class="me mf mg"><p id="cc38" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated"><strong class="lk jd"> XGBoost的表现略胜于CatBoost。但是，CatBoost比XGBoost快3.5倍左右！</strong></p></blockquote><h1 id="9cbd" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">CatBoost与LightGBM</h1><p id="bcdb" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">这里，我们也考虑同样的两个因素。这一次，我们在<a class="ae lh" href="https://drive.google.com/file/d/1Kees3lk-Zo7AsrYz7svcj8Hnbr6gHok6/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">加州房价数据集</a>上构建CatBoost和LightGBM回归模型。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ni nj l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">CatBoost与LightGBM</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/24bbbab5a24a4de4ba645065f556b976.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*0ZZy2WR2ngV8WwC-5jOsBw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><blockquote class="me mf mg"><p id="7923" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated"><strong class="lk jd"> LightGBM略胜CatBoost，比CatBoost快2倍左右！</strong></p></blockquote><h1 id="e367" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">结论</h1><p id="d6f8" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">当我们考虑执行时间时，LightGBM轻而易举地胜出！比XGBoost快7倍，比CatBoost快2倍！</p><p id="5cbd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当我们考虑性能的时候，XGBoost比另外两个稍微好一点。然而，选择正确的升压技术取决于许多因素。这里有一些指导方针，可以帮助您为您的任务选择正确的升压算法。</p><h2 id="a560" class="nm mm it bd mn nn no dn mr np nq dp mv lr nr ns mx lv nt nu mz lz nv nw nb iz bi translated">选择正确增压技术的指南</h2><ol class=""><li id="9627" class="nx ny it lk b ll nd lo ne lr nz lv oa lz ob md oc od oe of bi translated">除了并行化训练过程之外，任何提升技术都比决策树和随机森林好得多。</li><li id="893a" class="nx ny it lk b ll og lo oh lr oi lv oj lz ok md oc od oe of bi translated">您可以从基本的增强技术开始，如<a class="ae lh" rel="noopener" target="_blank" href="/how-do-you-implement-adaboost-with-python-a76427b0fa7a"> <strong class="lk jd"> AdaBoost </strong> </a>或<a class="ae lh" rel="noopener" target="_blank" href="/under-the-hood-of-gradient-boosting-and-its-python-implementation-99cc63efd24d"> <strong class="lk jd">渐变增强</strong> </a> <strong class="lk jd"> </strong>，然后您可以转向增强技术，如<a class="ae lh" href="https://rukshanpramoditha.medium.com/unlock-the-power-of-xgboost-738536b9f36f" rel="noopener"> <strong class="lk jd"> XGBoost </strong> </a>。</li><li id="56fd" class="nx ny it lk b ll og lo oh lr oi lv oj lz ok md oc od oe of bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/can-lightgbm-outperform-xgboost-d05a94102a55"><strong class="lk jd">light GBM</strong></a><strong class="lk jd"/>和<a class="ae lh" rel="noopener" target="_blank" href="/how-do-you-use-categorical-features-directly-with-catboost-947b211c2923"> <strong class="lk jd"> CatBoost </strong> </a>是<a class="ae lh" href="https://rukshanpramoditha.medium.com/unlock-the-power-of-xgboost-738536b9f36f" rel="noopener"> <strong class="lk jd"> XGBoost </strong> </a>的绝佳替代品。</li><li id="f9f1" class="nx ny it lk b ll og lo oh lr oi lv oj lz ok md oc od oe of bi translated">如果你有更大的数据集，可以考虑使用<a class="ae lh" rel="noopener" target="_blank" href="/can-lightgbm-outperform-xgboost-d05a94102a55"> <strong class="lk jd"> LightGBM </strong> </a> <strong class="lk jd"> </strong>或者<strong class="lk jd"/><a class="ae lh" rel="noopener" target="_blank" href="/how-do-you-use-categorical-features-directly-with-catboost-947b211c2923"><strong class="lk jd">CatBoost</strong></a>。LightGBM是最好的选择。</li><li id="f574" class="nx ny it lk b ll og lo oh lr oi lv oj lz ok md oc od oe of bi translated">如果你的数据集有分类特征，可以考虑使用<a class="ae lh" rel="noopener" target="_blank" href="/can-lightgbm-outperform-xgboost-d05a94102a55"><strong class="lk jd">light GBM</strong></a><strong class="lk jd"/>或者<strong class="lk jd"/><a class="ae lh" rel="noopener" target="_blank" href="/how-do-you-use-categorical-features-directly-with-catboost-947b211c2923"><strong class="lk jd">CatBoost</strong></a>。两者都可以处理尚未编码的分类特征。CatBoost是处理分类特征的最佳选择。</li><li id="60f7" class="nx ny it lk b ll og lo oh lr oi lv oj lz ok md oc od oe of bi translated"><a class="ae lh" href="https://rukshanpramoditha.medium.com/unlock-the-power-of-xgboost-738536b9f36f" rel="noopener"><strong class="lk jd">XGBoost</strong></a><strong class="lk jd"/>比其他boosting技术有更多的泛化能力。就性能而言，这很好。</li><li id="1799" class="nx ny it lk b ll og lo oh lr oi lv oj lz ok md oc od oe of bi translated"><a class="ae lh" rel="noopener" target="_blank" href="/can-lightgbm-outperform-xgboost-d05a94102a55"><strong class="lk jd">light GBM</strong></a><strong class="lk jd"/>执行时间最快。</li><li id="cd3d" class="nx ny it lk b ll og lo oh lr oi lv oj lz ok md oc od oe of bi translated">当我们同时考虑<strong class="lk jd"> <em class="mh">性能</em> </strong>和<strong class="lk jd"> <em class="mh">执行时间</em> </strong> <em class="mh"> </em>时，<a class="ae lh" rel="noopener" target="_blank" href="/can-lightgbm-outperform-xgboost-d05a94102a55"><strong class="lk jd">light GBM</strong></a><strong class="lk jd"/>是最佳选择。</li></ol><p id="8f5f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">boosting技术的一个主要缺点是，由于boosting算法是基于树的算法，因此很容易发生过拟合。我们已经讨论了一些解决过度拟合问题的技术:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://rukshanpramoditha.medium.com/list/addressing-overfitting-868959382d1d"><div class="gh gi ol"><img src="../Images/747771b979c59ccd183309360ec134cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*QJEXVS4T7r54erq5K52jAg.png"/></div></a><p class="ld le gj gh gi lf lg bd b be z dk translated">解决文章系列过多的问题(作者截图)</p></figure><p id="30fe" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">可以用来解决boosting算法中过拟合问题的最佳技术之一是<strong class="lk jd"> <em class="mh">提前停止</em> </strong>。这是我们在本文中讨论过的一种正规化。我还将发表一篇单独的文章，描述我们如何使用早期停止，尤其是在boosting算法中。</p></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><p id="f4af" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">今天的帖子到此结束。我的读者可以通过下面的链接注册成为会员，以获得我写的每个故事的全部信息，我将收到你的一部分会员费。</p><div class="ot ou gp gr ov ow"><a href="https://rukshanpramoditha.medium.com/membership" rel="noopener follow" target="_blank"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd jd gy z fp pb fr fs pc fu fw jc bi translated">通过我的推荐链接加入Medium</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">rukshanpramoditha.medium.com</p></div></div><div class="pf l"><div class="pg l ph pi pj pf pk lb ow"/></div></div></a></div><p id="f928" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">非常感谢你一直以来的支持！下一个故事再见。祝大家学习愉快！</p><p id="d7b7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">特别要感谢Unsplash网站上的<strong class="lk jd"> Arnaud Mesureur </strong>、<strong class="lk jd">、T3，他为我提供了这篇文章的精美封面图片。</strong></p><p id="9f6e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="pl pm ep" href="https://medium.com/u/f90a3bb1d400?source=post_page-----886c1c96db64--------------------------------" rel="noopener" target="_blank">鲁克山·普拉莫迪塔</a><br/><strong class="lk jd">2021–11–03</strong></p></div></div>    
</body>
</html>