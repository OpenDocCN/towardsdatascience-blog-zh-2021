<html>
<head>
<title>Generalized Linear Mixed Effects Models in R and Python with GPBoost</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用GPBoost实现R和Python中的广义线性混合效果模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generalized-linear-mixed-effects-models-in-r-and-python-with-gpboost-89297622820c?source=collection_archive---------5-----------------------#2021-06-22">https://towardsdatascience.com/generalized-linear-mixed-effects-models-in-r-and-python-with-gpboost-89297622820c?source=collection_archive---------5-----------------------#2021-06-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="b8e1" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><div class=""><h2 id="d5a2" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">“lme4”和“statsmodels”的介绍和比较</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/43b7d84bfa787b318550085bb3554180.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hi7huSeqSgc58d1_u22pag.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图gpboost、lme4和stats模型的比较:<strong class="bd lh">估计时间和单水平随机效应模型的系数和方差参数的均方误差(MSE) </strong>对于<strong class="bd lh">变化的样本数</strong></p></figure><p id="6734" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae me" href="https://github.com/fabsig/GPBoost" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> GPBoost </strong> </a> <strong class="lk jd">是一个最近发布的C++软件库，它允许在R和Python中拟合广义线性混合效果模型</strong>。本文展示了如何使用相应的<a class="ae me" href="https://github.com/fabsig/GPBoost/tree/master/R-package" rel="noopener ugc nofollow" target="_blank"> R </a>和<a class="ae me" href="https://github.com/fabsig/GPBoost/tree/master/python-package" rel="noopener ugc nofollow" target="_blank"> Python </a> <code class="fe mf mg mh mi b"><strong class="lk jd">gpboost</strong></code>包来实现这一点。此外，我们对<code class="fe mf mg mh mi b">lme4</code> R包和<code class="fe mf mg mh mi b">statsmodels</code> Python包进行了比较。<strong class="lk jd">在模拟实验中，我们发现</strong> <code class="fe mf mg mh mi b"><strong class="lk jd">gpboost</strong></code> <strong class="lk jd">比</strong> <code class="fe mf mg mh mi b"><strong class="lk jd">lme4</strong></code> <strong class="lk jd"> R包</strong><strong class="lk jd">快很多(有些情况下快100倍以上)。令人不安的是，</strong> <code class="fe mf mg mh mi b"><strong class="lk jd">statsmodels</strong></code> <strong class="lk jd"> Python包经常错误地估计模型。</strong></p><h1 id="21a2" class="mj mk it bd ml mm mn mo mp mq mr ms mt ki mu kj mv kl mw km mx ko my kp mz na bi translated">简介:广义线性混合效应模型</h1><p id="a339" class="pw-post-body-paragraph li lj it lk b ll nb kd ln lo nc kg lq lr nd lt lu lv ne lx ly lz nf mb mc md im bi translated"><a class="ae me" href="https://en.wikipedia.org/wiki/Generalized_linear_mixed_model" rel="noopener ugc nofollow" target="_blank">广义线性混合效应模型(GLMMs) </a>假设响应变量<em class="ng"> y </em>遵循已知的参数分布<em class="ng"> p(y|mu) </em>，并且该分布的参数<em class="ng"> mu </em>(通常是平均值)与所谓的固定效应<em class="ng"> Xb </em>和随机效应<em class="ng"> Zu </em>的总和相关:</p><blockquote class="nh"><p id="a408" class="ni nj it bd nk nl nm nn no np nq md dk translated">y ~ p(y |μ)</p><p id="b1b3" class="ni nj it bd nk nl nm nn no np nq md dk translated">mu = f( Xb + Zu)</p></blockquote><ul class=""><li id="9151" class="nr ns it lk b ll nt lo nu lr nv lv nw lz nx md ny nz oa ob bi translated"><em class="ng"> y </em>是响应变量(又名标签，因变量)</li><li id="97fe" class="nr ns it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated"><em class="ng"> Xb </em>是固定效应，<em class="ng"> X </em>是具有预测变量(又名特征、协变量)的矩阵，<em class="ng"> b </em>是系数</li><li id="6f06" class="nr ns it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated"><em class="ng"> Zu </em>是随机效应，其中<em class="ng"> u </em>假设遵循多元正态分布，而<em class="ng"> Z </em>是将<em class="ng"> u </em>与样本相关联的矩阵</li><li id="b62b" class="nr ns it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated"><em class="ng"> f() </em>是一个链接函数，确保<em class="ng"> mu = f( Xb + Zu ) </em>在适当的范围内(例如，对于二进制数据，平均值必须在0和1之间)</li></ul><p id="860e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">GLMM与广义线性模型(GLM)的区别在于随机效应的存在。例如，随机效果可以由具有潜在嵌套或交叉分组结构的分组(又名群集)随机效果组成。因此，<a class="ae me" href="https://arxiv.org/abs/2105.08966" rel="noopener ugc nofollow" target="_blank">随机效应也可以被看作是一种建模高基数分类变量</a>的方法。此外，随机效应可以包括例如用于对空间数据建模的高斯过程。与仅使用固定效应相比，随机效应的优势在于，当例如组或类别的数量相对于样本大小较大时，可以更有效地估计模型。<a class="ae me" href="https://en.wikipedia.org/wiki/Mixed_model" rel="noopener ugc nofollow" target="_blank">线性混合效应模型(LMEs </a>)是GLMMs的一个特例，其中<em class="ng"> p(y|mu) </em>是高斯的，<em class="ng"> f() </em>仅仅是恒等式。</p><h1 id="c30d" class="mj mk it bd ml mm mn mo mp mq mr ms mt ki mu kj mv kl mw km mx ko my kp mz na bi translated"><strong class="ak">使用GPBoost在R和Python中建模glm ms</strong></h1><p id="d96c" class="pw-post-body-paragraph li lj it lk b ll nb kd ln lo nc kg lq lr nd lt lu lv ne lx ly lz nf mb mc md im bi translated">我们简要地展示了R和Python <code class="fe mf mg mh mi b">gpboost</code>包如何通过GLMMs用于推断和预测。更多细节，我们参考<a class="ae me" href="https://github.com/fabsig/GPBoost" rel="noopener ugc nofollow" target="_blank"> GitHub页面</a>，特别是<a class="ae me" href="https://github.com/fabsig/GPBoost/blob/master/R-package/demo/generalized_linear_Gaussian_process_mixed_effects_models.R" rel="noopener ugc nofollow" target="_blank"> R </a>和<a class="ae me" href="https://github.com/fabsig/GPBoost/blob/master/examples/python-guide/generalized_linear_Gaussian_process_mixed_effects_models.py" rel="noopener ugc nofollow" target="_blank"> Python </a> GLMM的例子。</p><h2 id="3904" class="oh mk it bd ml oi oj dn mp ok ol dp mt lr om on mv lv oo op mx lz oq or mz iz bi translated">装置</h2><p id="67d1" class="pw-post-body-paragraph li lj it lk b ll nb kd ln lo nc kg lq lr nd lt lu lv ne lx ly lz nf mb mc md im bi translated">CRAN和PyPI上有<code class="fe mf mg mh mi b">gpboost</code> R和Python包，可以按如下方式安装<strong class="lk jd">:</strong></p><p id="f58a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">Python:</strong>T2】</p><p id="f21c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">R:</strong>T3】</p><h2 id="d679" class="oh mk it bd ml oi oj dn mp ok ol dp mt lr om on mv lv oo op mx lz oq or mz iz bi translated">模型估计</h2><p id="c25c" class="pw-post-body-paragraph li lj it lk b ll nb kd ln lo nc kg lq lr nd lt lu lv ne lx ly lz nf mb mc md im bi translated">由于可能性(应该最大化的数量)不能以封闭的形式写下来，因此GLMMs的估计是一项重要的任务。GPBoost(版本0.6.3)的当前实现基于拉普拉斯近似。Python和R中的模型估计可以如下进行:</p><p id="a392" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> Python </strong></p><pre class="ks kt ku kv gt os mi ot ou aw ov bi"><span id="3e3c" class="oh mk it mi b gy ow ox l oy oz">gp_model = gpb.GPModel(group_data=group_data, likelihood="binary")<br/>gp_model.fit(y=y, X=X)<br/>gp_model.summary()</span></pre><p id="86b4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> R </strong></p><pre class="ks kt ku kv gt os mi ot ou aw ov bi"><span id="9f2f" class="oh mk it mi b gy ow ox l oy oz">gp_model &lt;- fitGPModel(group_data=group_data, likelihood="binary",                               <br/>                        y=y, X=X)<br/>summary(gp_model)</span></pre><p id="72b1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在哪里</p><ul class=""><li id="f4eb" class="nr ns it lk b ll lm lo lp lr pa lv pb lz pc md ny nz oa ob bi translated"><code class="fe mf mg mh mi b">group_data</code>是具有分类分组变量的矩阵或向量，指定随机效应结构。如果有多个(交叉或嵌套)随机效应，相应的分组变量应该在<code class="fe mf mg mh mi b">group_data</code>的列中</li><li id="924d" class="nr ns it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated"><code class="fe mf mg mh mi b">y</code>是一个带有响应变量数据的向量</li><li id="c0bb" class="nr ns it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated"><code class="fe mf mg mh mi b">X</code>是一个具有固定效应的矩阵协变量数据</li><li id="3417" class="nr ns it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated"><code class="fe mf mg mh mi b">likelihood</code>表示响应变量的分布(例如，似然性=“二元”表示具有概率单位链接函数的伯努利分布)</li></ul><p id="3700" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">估计后，<code class="fe mf mg mh mi b">summary()</code>函数显示随机效应和固定效应系数<em class="ng"> b </em>的估计方差和协方差参数。</p><h2 id="3084" class="oh mk it bd ml oi oj dn mp ok ol dp mt lr om on mv lv oo op mx lz oq or mz iz bi translated">固定效应系数的近似p值</h2><p id="319e" class="pw-post-body-paragraph li lj it lk b ll nb kd ln lo nc kg lq lr nd lt lu lv ne lx ly lz nf mb mc md im bi translated">获取GLMMs中固定效应系数的p值是一项有些模糊的工作。由于不可能首先精确地计算出可能性，人们不得不依赖于多重渐近论证。即，p值可以是(非常)近似的，应持保留态度。然而，由于<code class="fe mf mg mh mi b">lme4</code>和<code class="fe mf mg mh mi b">statsmodels</code>包允许计算近似标准偏差和p值，我们还展示了如何使用<code class="fe mf mg mh mi b">gpboost</code>依靠与<code class="fe mf mg mh mi b">lme4</code>相同的方法来实现这一点。简而言之，必须启用<code class="fe mf mg mh mi b">"std_dev": True</code> / <code class="fe mf mg mh mi b">std_dev=TRUE</code>，以在拟合模型时计算近似标准差，然后使用如下所示的近似Wald测试。</p><p id="e202" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> Python </strong></p><pre class="ks kt ku kv gt os mi ot ou aw ov bi"><span id="749a" class="oh mk it mi b gy ow ox l oy oz">gp_model = gpb.GPModel(group_data=group, likelihood="binary")<br/>gp_model.fit(y=y, X=X, params={“std_dev”: True})<br/>coefs = gp_model.get_coef()<br/>z_values = coefs[0] / coefs[1]<br/>p_values = 2 * stats.norm.cdf(-np.abs(z_values))<br/>print(p_values) # show p-values</span></pre><p id="0724" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> R </strong></p><pre class="ks kt ku kv gt os mi ot ou aw ov bi"><span id="0403" class="oh mk it mi b gy ow ox l oy oz">gp_model &lt;- fitGPModel(group_data=group_data, likelihood="binary",                               <br/>                        y=y, X=X, params=list(std_dev=TRUE))<br/>coefs &lt;- gp_model$get_coef()<br/>z_values &lt;- coefs[1,] / coefs[2,]<br/>p_values &lt;- 2 * exp(pnorm(-abs(z_values), log.p=TRUE))<br/>coefs_summary &lt;- rbind(coefs, z_values, p_values)<br/>print(signif(coefs_summary, digits=4)) # show p-values</span></pre><h2 id="738c" class="oh mk it bd ml oi oj dn mp ok ol dp mt lr om on mv lv oo op mx lz oq or mz iz bi translated">预言；预测；预告</h2><p id="70be" class="pw-post-body-paragraph li lj it lk b ll nb kd ln lo nc kg lq lr nd lt lu lv ne lx ly lz nf mb mc md im bi translated">可以通过调用如下所示的<code class="fe mf mg mh mi b">predict()</code>函数来获得预测。</p><p id="f21a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> Python </strong></p><pre class="ks kt ku kv gt os mi ot ou aw ov bi"><span id="0625" class="oh mk it mi b gy ow ox l oy oz">pred = gp_model.predict(X_pred=X_test, group_data_pred=group_test,<br/>                        predict_var=True, predict_response=False)<br/>print(pred['mu'])  # predicted latent mean<br/>print(pred['var']) # predicted latent variance</span></pre><p id="6b8f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> R </strong></p><pre class="ks kt ku kv gt os mi ot ou aw ov bi"><span id="9f5e" class="oh mk it mi b gy ow ox l oy oz">pred &lt;- predict(gp_model, X_pred=X_test,<br/>                 group_data_pred=group_test,<br/>                 predict_var=TRUE, predict_response=FALSE)<br/>pred$mu # predicted latent mean<br/>pred$var # predicted latent variance</span></pre><p id="e21b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在哪里</p><ul class=""><li id="02f9" class="nr ns it lk b ll lm lo lp lr pa lv pb lz pc md ny nz oa ob bi translated"><code class="fe mf mg mh mi b">group_data_pred</code>是带有分类分组变量的矩阵或向量，用于进行预测</li><li id="05d0" class="nr ns it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated"><code class="fe mf mg mh mi b">X_pred</code>是对其进行预测的具有固定效应协变量数据的矩阵</li><li id="18a5" class="nr ns it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated"><code class="fe mf mg mh mi b">predict_var</code>(布尔型)表示除平均值外，是否还应计算预测方差</li><li id="ff1b" class="nr ns it lk b ll oc lo od lr oe lv of lz og md ny nz oa ob bi translated"><code class="fe mf mg mh mi b">predict_response</code>(布尔型)表示是否应预测响应<em class="ng"> y </em>或潜在<em class="ng"> Xb + Zu </em>。即随机效应部分也被预测。如果<code class="fe mf mg mh mi b">group_data_pred</code>包含新的、未观察到的类别，相应的随机效应预测将为0。</li></ul><h1 id="c0b2" class="mj mk it bd ml mm mn mo mp mq mr ms mt ki mu kj mv kl mw km mx ko my kp mz na bi translated">与<code class="fe mf mg mh mi b">lme4</code>和<code class="fe mf mg mh mi b">statsmodels</code>的对比</h1><p id="4bb1" class="pw-post-body-paragraph li lj it lk b ll nb kd ln lo nc kg lq lr nd lt lu lv ne lx ly lz nf mb mc md im bi translated">下面，我们做一个模拟研究来比较<code class="fe mf mg mh mi b">gpboost</code>(版本0.6.3)与<code class="fe mf mg mh mi b">lme4</code>(版本1.1–27)和<code class="fe mf mg mh mi b">statsmodels</code>(版本0.12.2)。重现完整模拟研究的代码可在<a class="ae me" href="https://github.com/fabsig/Comparison_GLMM_Packages" rel="noopener ugc nofollow" target="_blank">这里</a>找到。我们对所有包都使用默认选项。特别是，所有软件包都使用拉普拉斯近似来近似(边际)似然性。<strong class="lk jd">我们评估了计算时间和方差参数的准确性，以及根据均方根误差(RMSE)测量的固定效应系数估计值。</strong>关于后者，我们预计只会看到微小的差异，因为理论上，所有软件包都依赖于相同的统计方法，只是在具体的软件实现上有所不同。</p><h2 id="fadb" class="oh mk it bd ml oi oj dn mp ok ol dp mt lr om on mv lv oo op mx lz oq or mz iz bi translated">模拟设置</h2><p id="e6ea" class="pw-post-body-paragraph li lj it lk b ll nb kd ln lo nc kg lq lr nd lt lu lv ne lx ly lz nf mb mc md im bi translated">作为基线设置，我们使用以下模型来模拟数据:</p><ol class=""><li id="64d9" class="nr ns it lk b ll lm lo lp lr pa lv pb lz pc md pd nz oa ob bi translated">n=1000个样本</li><li id="a390" class="nr ns it lk b ll oc lo od lr oe lv of lz og md pd nz oa ob bi translated">每组10个样本(即100个不同的组)</li><li id="ff65" class="nr ns it lk b ll oc lo od lr oe lv of lz og md pd nz oa ob bi translated">10个固定效应协变量加上一个截距项</li><li id="b095" class="nr ns it lk b ll oc lo od lr oe lv of lz og md pd nz oa ob bi translated">单水平分组随机效应模型</li><li id="ecb6" class="nr ns it lk b ll oc lo od lr oe lv of lz og md pd nz oa ob bi translated">具有概率单位连接函数的二元伯努利似然</li></ol><p id="a4f3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当改变这些选择中的每一个而保持所有其他选择不变时，我们煽动结果如何变化。具体来说，我们如下改变这些选择:(1 .)样本数:100，200，500，1000，2000，(2。)组数:2，5，10，20，50，100，200，500，(3。)协变量个数:1，2，5，10，20，(4。)嵌套和交叉随机效应模型，以及(5。)泊松概率而不是二进制概率。方差1用于随机效应。协变量<em class="ng"> X </em>从均值为0的正态分布中取样，选择方差，使固定效应和随机效应之间的信噪比为1，除截距为0外，真实回归系数均为1。对于上述模型选择的每个组合，我们模拟100次数据，并使用三个不同的软件包估计相应的模型。参见<a class="ae me" href="https://github.com/fabsig/Comparison_GLMM_Packages" rel="noopener ugc nofollow" target="_blank">此处</a>了解模拟研究的更多细节。所有计算都在一台配备2.9 GHz四核处理器的笔记本电脑上运行。</p><h2 id="9514" class="oh mk it bd ml oi oj dn mp ok ol dp mt lr om on mv lv oo op mx lz oq or mz iz bi translated">结果</h2><p id="0767" class="pw-post-body-paragraph li lj it lk b ll nb kd ln lo nc kg lq lr nd lt lu lv ne lx ly lz nf mb mc md im bi translated">结果用下面的五个数字表示。注意，我们在对数标度上绘制结果，因为例如<code class="fe mf mg mh mi b">lme4</code>和<code class="fe mf mg mh mi b">gpboost</code>之间的计算时间差异非常大。我们观察到以下发现。首先，<code class="fe mf mg mh mi b">statsmodels</code>给出了RMSEs非常大的参数估计，即非常不准确的估计。这是令人不安的，因为从理论上讲，所有三个软件包应该做“同样的事情”。此外，<code class="fe mf mg mh mi b">gpboost</code>比<code class="fe mf mg mh mi b">lme4</code>快得多，随机效应的维度越高，固定效应协变量的数量越多，差异就越大。例如，对于具有100组、1000个样本和20个协变量的二元单级随机效应模型，<code class="fe mf mg mh mi b">gpboost</code>平均比<code class="fe mf mg mh mi b">lme4</code>快大约600倍。正如所料，<code class="fe mf mg mh mi b">gpboost</code>和<code class="fe mf mg mh mi b">lme4</code>具有几乎相同的RMSEs，因为两个包使用相同的方法。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/43b7d84bfa787b318550085bb3554180.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hi7huSeqSgc58d1_u22pag.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lh">不同数量的样本n </strong></p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/bb9dc154b0edf499e9f33f7dfe104304.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uUPiA2aLcbjM7W-ha8JNww.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lh">改变组数</strong></p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/03f952679ef3bcafd5c9eeb5bd456a4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E-pOV-9sCHMaB5FRRVdi-A.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lh">改变协变量的数量</strong></p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pe"><img src="../Images/d79cb315b24c2bd73ecd8513f9ca0c60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7oS_jiqKRQTw-z1fJYAS5Q.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lh">不同的随机效果模型</strong></p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/85863318ee320f6354dd286e4b5708b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5RIu9RUDtRADwdbaCVTs_A.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd lh">泊松可能性和样本数量的变化</strong></p></figure><p id="c833" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="ng">注意:</em> <code class="fe mf mg mh mi b"><em class="ng">gpboost</em></code> <em class="ng">对于可以并行化的操作，使用C++中的OpenMP并行化。但是主要的计算瓶颈是Cholesky分解的计算，并且该操作不能并行化。即</em> <code class="fe mf mg mh mi b"><em class="ng">lme4</em></code> <em class="ng">和</em> <code class="fe mf mg mh mi b"><em class="ng">gpboost</em></code> <em class="ng">计算时间的巨大差异不是并行化</em>的结果。</p><h1 id="ac40" class="mj mk it bd ml mm mn mo mp mq mr ms mt ki mu kj mv kl mw km mx ko my kp mz na bi translated"><strong class="ak">结论</strong></h1><p id="288e" class="pw-post-body-paragraph li lj it lk b ll nb kd ln lo nc kg lq lr nd lt lu lv ne lx ly lz nf mb mc md im bi translated"><a class="ae me" href="https://github.com/fabsig/GPBoost" rel="noopener ugc nofollow" target="_blank"> GPBoost </a>是一个最近发布的C++软件库，它允许在R和Python中拟合广义线性混合效果模型。如上图所示，<code class="fe mf mg mh mi b">gpboost</code>比<code class="fe mf mg mh mi b">lme4</code> R包快很多。令人不安的是，<code class="fe mf mg mh mi b">statsmodels</code> Python包经常导致非常不准确的估计。除了本文中考虑的分组随机效应，GPBoost还允许对高斯过程建模，例如空间或时间随机效应，以及组合的分组随机效应和高斯过程模型。此外，GPBoost支持随机系数，例如随机斜率或空间变化系数。最后，除了LMMs和GLMMs，GPBoost还允许学习非线性模型，而无需使用<a class="ae me" href="https://en.wikipedia.org/wiki/Gradient_boosting" rel="noopener ugc nofollow" target="_blank">树提升</a>对固定效果采取任何函数形式；详见这两篇关于将树提升与<a class="ae me" rel="noopener" target="_blank" href="/tree-boosted-mixed-effects-models-4df610b624cb">分组随机效果</a>和<a class="ae me" rel="noopener" target="_blank" href="/tree-boosting-for-spatial-data-789145d6d97d">高斯过程</a>或<a class="ae me" href="https://arxiv.org/abs/2004.02653" rel="noopener ugc nofollow" target="_blank"> Sigrist (2020) </a>和<a class="ae me" href="https://arxiv.org/abs/2105.08966" rel="noopener ugc nofollow" target="_blank"> Sigrist (2021) </a>结合的博文。</p></div></div>    
</body>
</html>