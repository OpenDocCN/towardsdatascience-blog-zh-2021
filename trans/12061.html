<html>
<head>
<title>Road Signs “Driving” You Crazy?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">路标让你疯狂？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/road-signs-driving-you-crazy-e686d97f2480?source=collection_archive---------16-----------------------#2021-12-05">https://towardsdatascience.com/road-signs-driving-you-crazy-e686d97f2480?source=collection_archive---------16-----------------------#2021-12-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5eb5" class="pw-subtitle-paragraph jr is it bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">以下是我如何建立一个程序来为你阅读它们</h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/ae8d1d04880f4364deb44a6d22402b78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mkYI9nbLDj2_tkKrX-qBgQ.jpeg"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">罗西·斯蒂格尔斯在<a class="ae kz" href="https://unsplash.com/s/photos/road-signs?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="20b2" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">路标。一大堆不同颜色的符号，它们的形状你应该能够推断出它们的意思。奇怪的符号，你必须谷歌甚至模糊地认识。路标令人困惑，很难记住它们的意思。这就是为什么我建立了<a class="ae kz" href="https://www.kaggle.com/taraprole/roadsignclassifier" rel="noopener ugc nofollow" target="_blank">这个程序</a>来为你阅读它们！给定一张足够清晰、裁剪得当的图像，我的CNN可以读取路标中的图案，并使用数字分类系统对它们进行分类。我将向你展示它是如何工作的！</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="fa0b" class="md me it bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">目录</h1><p id="a742" class="pw-post-body-paragraph la lb it lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv im bi translated">因为这是一篇有点长的文章，我想我应该给你一个简短的目录，以便能够快速导航到我的文章的特定部分。</p><ol class=""><li id="fde1" class="na nb it lc b ld le lg lh lj nc ln nd lr ne lv nf ng nh ni bi translated"><a class="ae kz" href="#e7b3" rel="noopener ugc nofollow"> <strong class="lc iu"> <em class="nj">为什么这个其实有用？</em> </strong> </a></li><li id="55b8" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv nf ng nh ni bi translated"><a class="ae kz" href="#4930" rel="noopener ugc nofollow"><strong class="lc iu"><em class="nj">CNN</em></strong></a></li><li id="c670" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv nf ng nh ni bi translated"><a class="ae kz" href="#9795" rel="noopener ugc nofollow"> <strong class="lc iu"> <em class="nj">入门</em> </strong> </a></li><li id="9d64" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv nf ng nh ni bi translated"><a class="ae kz" href="#f088" rel="noopener ugc nofollow"> <strong class="lc iu"> <em class="nj">准备数据</em> </strong> </a></li><li id="f3ad" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv nf ng nh ni bi translated"><a class="ae kz" href="#c631" rel="noopener ugc nofollow"> <strong class="lc iu"> <em class="nj">创建神经网络</em> </strong> </a></li><li id="0dc0" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv nf ng nh ni bi translated"><a class="ae kz" href="#088e" rel="noopener ugc nofollow"> <strong class="lc iu"> <em class="nj">定义功能</em> </strong> </a></li><li id="b725" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv nf ng nh ni bi translated"><a class="ae kz" href="#af7b" rel="noopener ugc nofollow"> <strong class="lc iu"> <em class="nj">训练神经网络</em> </strong> </a></li><li id="8230" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv nf ng nh ni bi translated"><a class="ae kz" href="#48c1" rel="noopener ugc nofollow"> <strong class="lc iu"> <em class="nj">测试型号</em> </strong> </a></li></ol></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="e7b3" class="md me it bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">为什么这实际上是有用的？</h1><p id="3bd7" class="pw-post-body-paragraph la lb it lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv im bi translated">你可能想知道这一切有什么意义。当我们可以自己看路标时，为什么我们需要一台计算机来对它们进行分类？</p><p id="ebdd" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">答案:<strong class="lc iu">自动驾驶汽车。</strong></p><p id="c0dc" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">无人驾驶汽车每天都变得越来越真实。谷歌的姐妹公司Waymo已经在亚利桑那州的凤凰城建立了完整的系统。城市特定区域的市民可以像订购优步一样订购无人驾驶汽车！但是，为了让自动驾驶汽车与你今天可能驾驶的汽车无缝集成，它们需要能够像人类一样遵守道路规则。这包括阅读路标！</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="4930" class="md me it bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">CNN</h1><p id="7986" class="pw-post-body-paragraph la lb it lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv im bi translated">你可能也想知道这些CNN的东西是什么。别担心，我可以解释😉</p><p id="370a" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">CNN是一种特别擅长图像分类的神经网络(阅读我的其他文章来了解基础知识)。CNN用于计算机视觉，因为它们擅长检测图像中的图案，如线条、圆形和其他形状和图案。CNN使用卷积层，它本质上学习可以检测图像模式的过滤器。例如，过滤器可以检测垂直线，也可以检测水平线。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi np"><img src="../Images/bb5a85c5982e4181cca273a1f897f373.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/0*VgBcuIK7pzIcYMuh.jpg"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">信用:塔拉普罗尔</p></figure><p id="304e" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这些滤波器在图像上“卷积”,以小的3x3(或任何大小的滤波器)块来获得所述3x3块的点积。过滤器首先检查输入图像的第一个3x3区域，并找到该块的点积。它记录下来，并成为下一层输入的一部分。对于整个图片中的每一个3×3的块，都会发生这种情况，并且创建一个用点积和过滤器简化的新图片。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/7469231bd2b1a8a80288784f649e46f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/0*SqmAY40aMN0ClMvL"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">图片由Kjell Magne Fauske在<a class="ae kz" href="https://commons.wikimedia.org/wiki/File:2D_Convolution_Animation.gif" rel="noopener ugc nofollow" target="_blank">公共领域</a>发布</p></figure><p id="8752" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">正如你所看到的，这个过滤器把一个更大的图像变成更容易管理和计算机可读的东西。过滤器通常检测图像中最相关和最突出的特征——它们可以非常简单，如检测线条和形状，也可以非常复杂，如面部识别——或者就我而言，是路标。</p><p id="5e5f" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果你想看看这些卷积层是如何工作的，请查看瑞尔森大学的资源:</p><div class="nr ns gp gr nt nu"><a href="https://www.cs.ryerson.ca/~aharley/vis/conv/" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd iu gy z fp nz fr fs oa fu fw is bi translated">卷积神经网络的三维可视化</h2><div class="ob l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">www.cs.ryerson.ca</p></div></div></div></a></div><p id="de48" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这里有一段来自DeepLizard的视频，让你了解更多关于CNN的信息:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oc od l"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">CNN上的深蜥蜴</p></figure><h1 id="9795" class="md me it bd mf mg oe mi mj mk of mm mn ka og kb mp kd oh ke mr kg oi kh mt mu bi translated">入门指南</h1><p id="3767" class="pw-post-body-paragraph la lb it lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv im bi translated">为了创建我自己的CNN，我使用了一个叫做<a class="ae kz" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>的Python库。PyTorch是一个开源的机器学习框架，允许你从头到尾创建神经网络。首先，我通过<a class="ae kz" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>创建了一个Jupyter笔记本，这是一个非常有用的网站，允许你使用免费的GPU来运行你的机器学习模型。我强烈建议将您的代码移到那里——一旦您掌握了窍门，它非常直观且易于使用。</p><p id="3379" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">神经网络在大型数据集上训练。在我的神经网络中，我使用德国交通标志识别基准(GTSRB)数据集来训练和测试神经网络。我的神经网络对一组39，209个带标签的图像进行了训练，以学习用于确定路标模式的过滤器。然后，它在一组12，630张带标签的测试图像上进行测试，以了解它在真实世界数据上的准确性。</p><p id="540f" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">为了将数据加载到我的程序中，我前往GTSRB数据集的<a class="ae kz" href="https://www.kaggle.com/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign" rel="noopener ugc nofollow" target="_blank"> Kaggle页面，并创建了一个新的笔记本。</a></p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="249f" class="oo me it ok b gy op oq l or os">import torch as t <br/>import torchvision <br/>from torchvision import transforms <br/>import torch.utils.data as data <br/>import torch.optim as optim<br/>import torch.nn as nn <br/>import time <br/>import numpy as np<br/>import os <br/>import matplotlib.pyplot as plt</span></pre><p id="81ff" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">下面是我导入的库的列表，它们是什么，以及它们各自文档的链接。</p><ul class=""><li id="da53" class="na nb it lc b ld le lg lh lj nc ln nd lr ne lv ot ng nh ni bi translated"><a class="ae kz" href="https://pytorch.org/docs/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a></li><li id="0cea" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv ot ng nh ni bi translated"><a class="ae kz" href="https://pytorch.org/vision/stable/index.html" rel="noopener ugc nofollow" target="_blank">火炬视觉【PyTorch内部的计算机视觉库</a></li><li id="7dbf" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv ot ng nh ni bi translated"><a class="ae kz" href="https://pytorch.org/vision/stable/transforms.html" rel="noopener ugc nofollow" target="_blank"> Transforms </a> -允许转换输入数据，在这种情况下是从图像到张量。还能够对输入数据进行大小调整、裁剪和其他转换。</li><li id="1dd0" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv ot ng nh ni bi translated"><a class="ae kz" href="https://pytorch.org/docs/stable/data.html" rel="noopener ugc nofollow" target="_blank"> torch.utils.data </a> -处理数据的工具</li><li id="4bb6" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv ot ng nh ni bi translated"><a class="ae kz" href="https://pytorch.org/docs/stable/optim.html" rel="noopener ugc nofollow" target="_blank"> torch.optim </a> -优化算法，使网络达到最佳状态</li><li id="0578" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv ot ng nh ni bi translated"><a class="ae kz" href="https://pytorch.org/docs/stable/nn.html" rel="noopener ugc nofollow" target="_blank"> torch.nn </a> -神经网络工具，专门为训练神经网络而制作</li><li id="e5af" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv ot ng nh ni bi translated"><a class="ae kz" href="https://docs.python.org/3/library/time.html" rel="noopener ugc nofollow" target="_blank">时间</a> -用于计时测试和培训所需的时间</li><li id="1635" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv ot ng nh ni bi translated"><a class="ae kz" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank">NumPy</a>——用于制作和使用数据数组</li><li id="cb71" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv ot ng nh ni bi translated"><a class="ae kz" href="https://docs.python.org/3/library/os.html" rel="noopener ugc nofollow" target="_blank"> os </a> -用于管理我们程序中的文件</li><li id="2403" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv ot ng nh ni bi translated">matplotlib.pyplot  -用于显示整个程序的图形和图像</li></ul><h1 id="f088" class="md me it bd mf mg oe mi mj mk of mm mn ka og kb mp kd oh ke mr kg oi kh mt mu bi translated">准备数据</h1><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="25a5" class="oo me it ok b gy op oq l or os"><em class="nj">#Defining the transformation</em><br/>data_transforms = transforms.Compose([transforms.Resize([112, 112]), transforms.ToTensor()])</span></pre><p id="7a16" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">接下来，我为数据定义了转换。该转换将输入图像的大小调整为112x112，并将这些图像转换为张量。</p><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="0f9c" class="oo me it ok b gy op oq l or os"><em class="nj">#Defining hyperparameters</em><br/><br/>BATCH_SIZE = 256<br/>learning_rate = 0.001<br/>EPOCHS = 7<br/>numClasses = 43</span></pre><p id="74d6" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">然后我定义了模型的超参数，比如批量大小、学习速率和时期数。批量大小是指一次处理的图像数量。学习率是神经网络每次出错时调整的程度。历元是计算机检查整个训练集的次数(它查看每个图像7次)。</p><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="15b9" class="oo me it ok b gy op oq l or os"><em class="nj">#path of training data</em><br/><br/>train_data_path = '../input/gtsrb-german-traffic-sign/Train'<br/>train_data = torchvision.datasets.ImageFolder(root = train_data_path, transform = data_transforms)<br/><br/><em class="nj">#Divide data into training and validation (0.8 and 0.2)</em><br/>ratio = 0.8<br/>n_train_examples = int(len(train_data) * ratio)<br/>n_val_examples = len(train_data) - n_train_examples<br/><br/>train_data, val_data = data.random_split(train_data, [n_train_examples, n_val_examples])<br/><br/>print(f"Number of training samples = <strong class="ok iu">{</strong>len(train_data)<strong class="ok iu">}</strong>")<br/>print(f"Number of validation samples = <strong class="ok iu">{</strong>len(val_data)<strong class="ok iu">}</strong>")</span></pre><p id="02cd" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">接下来，我开始创建我的数据集！首先，我定义了训练数据的文件路径。Kaggle使复制和粘贴数据路径在您的程序中使用变得很容易——只需前往界面的右侧，将鼠标悬停在包含您的列车数据的文件夹上，然后单击复制按钮。然后，我使用torchvision的<a class="ae kz" href="https://pytorch.org/vision/stable/datasets.html#torchvision.datasets.VisionDataset" rel="noopener ugc nofollow" target="_blank"> ImageFolder </a>数据集类型，使用Kaggle文件路径和我之前定义的转换，创建了我的训练集。</p><p id="6dc3" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">然后，我将训练集分为训练集和验证集。训练是程序实际训练的内容——这些是它将学习识别的图像。验证集基本上是为了在训练时进行测试——它让您实时看到您的模型在没有训练的数据上的表现。</p><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="f000" class="oo me it ok b gy op oq l or os"><em class="nj">#create data loader for training and validation</em><br/>trainloader = data.DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)<br/>valloader = data.DataLoader(val_data, shuffle=True, batch_size=BATCH_SIZE)</span></pre><p id="b215" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">准备训练数据的最后一步是创建数据加载器。这基本上是一种让程序轻松访问和遍历你定义的数据集的方法。我已经将这些加载器的批处理大小设置为256(我之前设置的变量),它们每次都会洗牌。</p><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="855c" class="oo me it ok b gy op oq l or os"><em class="nj"># Plot histogram for training and validation data</em><br/><br/>train_hist = [0]*numClasses<br/>for i <strong class="ok iu">in</strong> train_data.indices:<br/>    tar = train_data.dataset.targets[i]<br/>    train_hist[tar] += 1<br/>    <br/>val_hist = [0]*numClasses<br/>for i <strong class="ok iu">in</strong> val_data.indices:<br/>    tar = val_data.dataset.targets[i]<br/>    val_hist[tar] += 1<br/><br/>plt.bar(range(numClasses), train_hist, label="train")<br/>plt.bar(range(numClasses), val_hist, label="val")<br/>legend = plt.legend(loc='upper right', shadow=True)<br/>plt.title("Distribution Plot")<br/>plt.xlabel("Class ID")<br/>plt.ylabel("# of examples")<br/><br/>plt.savefig("train_val_split.png", bbox_inches = 'tight', pad_inches=0.5)</span></pre><p id="7295" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">不过，在开始实际训练网络之前，我画了一个数据分布图。我设置它来显示总共有多少个例子，以及训练和验证之间的差异。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/c003703b0a8b6d24616698e6a63726d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/0*24k1IdZJUrBoJjgm.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">信用:塔拉普罗尔</p></figure><h1 id="c631" class="md me it bd mf mg oe mi mj mk of mm mn ka og kb mp kd oh ke mr kg oi kh mt mu bi translated">创建神经网络</h1><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="c674" class="oo me it ok b gy op oq l or os">class <strong class="ok iu">NeuralNet</strong>(nn.Module):<br/>    def __init__(self, output_dim):<br/>        super().__init__()<br/>        <br/>        self.features = nn.Sequential(<br/>            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1),<br/>            nn.MaxPool2d(kernel_size=2),<br/>            nn.ReLU(inplace=True),<br/>            <br/>            nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, padding=1),<br/>            nn.MaxPool2d(kernel_size=2),<br/>            nn.ReLU(inplace=True),<br/>            <br/>            nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, padding=1),<br/>            nn.ReLU(inplace=True),<br/>            <br/>            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),<br/>            nn.ReLU(inplace=True),<br/>            <br/>            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),<br/>            nn.BatchNorm2d(256),<br/>            nn.MaxPool2d(kernel_size=2),<br/>            nn.ReLU(inplace=True),<br/>            )<br/>        <br/>        self.classifier = nn.Sequential(<br/>            nn.Dropout(0.5),<br/>            nn.Linear(256*7*7, 1000),<br/>            nn.ReLU(inplace=True),<br/>            <br/>            nn.Dropout(0.5),<br/>            nn.Linear(in_features=1000, out_features=256),<br/>            nn.ReLU(inplace=True),<br/>            <br/>            nn.Linear(256, output_dim)<br/>            )<br/>        <br/>    def forward(self, x):<br/>        x = self.features(x)<br/>        h = x.view(x.shape[0], -1)<br/>        x = self.classifier(h)<br/>        return x, h</span></pre><p id="3f2d" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">有趣的事情从这里开始！这是我定义我的神经网络的代码块。这个网络非常类似于AlexNet框架，使用5个卷积层，然后是3个全连接(线性)层。每个卷积层使用最大池。这里有一个来自DeepLizard的关于max pooling layers的视频，我觉得它很好地解释了这个主题。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oc od l"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">最大池层数上的深蜥蜴</p></figure><p id="6b65" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我还使用了<a class="ae kz" href="https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/" rel="noopener ugc nofollow" target="_blank">退出方法</a>来减少我的模型中的过度拟合(网络学习特定的图像而不是模式)——这是使用nn定义的。辍学(0.5)。</p><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="c581" class="oo me it ok b gy op oq l or os"><em class="nj"># define optimiser and criterion functions</em><br/>optimiser = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.01)<br/>criterion = nn.CrossEntropyLoss()</span></pre><p id="f82a" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这里我定义了优化器和损失函数。优化器是在每个训练时期之后返回并固定模型的参数。我还在优化器中设置了权重衰减，这意味着权重每次都会减少一点。这也有助于减少过度拟合。</p><h1 id="088e" class="md me it bd mf mg oe mi mj mk of mm mn ka og kb mp kd oh ke mr kg oi kh mt mu bi translated">定义函数</h1><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="c316" class="oo me it ok b gy op oq l or os"><em class="nj"># Function to perform training of the model</em><br/><br/>def train(model, loader, opt, criterion):<br/>    epoch_loss = 0<br/>    epoch_acc = 0<br/>    <br/>    <em class="nj"># Train the model</em><br/>    model.train()<br/>    <br/>    for (images, labels) <strong class="ok iu">in</strong> loader:<br/>        images = images.cuda()<br/>        labels = labels.cuda()<br/>        <br/>        output, _ = model(images)<br/>        loss = criterion(output, labels)<br/>        <br/>        <em class="nj"># Training pass</em><br/>        opt.zero_grad()<br/>        <br/>        <br/>        <em class="nj"># Backpropagation</em><br/>        loss.backward()<br/>        <br/>        <em class="nj"># Calculate accuracy</em><br/>        acc = calculate_accuracy(output, labels)<br/>        <br/>        <em class="nj"># Optimizing weights</em><br/>        opt.step()<br/>        <br/>        epoch_loss += loss.item()<br/>        epoch_acc += acc.item()<br/>        <br/>    return epoch_loss / len(loader), epoch_acc / len(loader)</span></pre><p id="2cf1" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">接下来，定义一个函数来训练模型。基本上，该函数迭代通过训练/验证加载器并训练网络。需要注意的几件重要事情是优化和反向传播。该函数还返回它所使用的每个历元的损失和精度(一个历元是程序循环通过所有训练数据的次数)。</p><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="8c84" class="oo me it ok b gy op oq l or os">def evaluate(model, loader, opt, criterion):<br/>    epoch_loss = 0<br/>    epoch_acc = 0<br/><br/>    <em class="nj">#evaluate the model</em><br/>    model.eval()<br/><br/>    with t.no_grad():<br/>        for (images, labels) <strong class="ok iu">in</strong> loader:<br/>            <br/>            images = images.cuda()<br/>            labels = labels.cuda()<br/>            <br/>            <br/>            output, _ = model(images)<br/>            loss = criterion(output, labels)<br/><br/>            acc = calculate_accuracy(output, labels)<br/><br/>            epoch_loss += loss.item()<br/>            epoch_acc += acc.item()<br/>    <br/>    return epoch_loss / len(loader), epoch_acc / len(loader)</span></pre><p id="f322" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我还定义了一个函数来评估模型。不使用梯度下降，它测试网络的表现如何。像训练函数一样，它评估网络的损耗和准确性。</p><h1 id="af7b" class="md me it bd mf mg oe mi mj mk of mm mn ka og kb mp kd oh ke mr kg oi kh mt mu bi translated">训练神经网络</h1><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="bd98" class="oo me it ok b gy op oq l or os"><em class="nj">#TRAINING</em><br/><br/>train_loss_list = [0]*EPOCHS<br/>train_acc_list = [0]*EPOCHS<br/>val_loss_list = [0]*EPOCHS<br/>val_acc_list = [0]*EPOCHS<br/><br/>for epoch <strong class="ok iu">in</strong> range(EPOCHS):<br/>    print("Epoch <strong class="ok iu">{}</strong>: ".format(epoch))<br/>    train_start_time=time.monotonic()<br/>    train_loss, train_acc= train(model, trainloader, optimiser, criterion)<br/>    train_end_time = time.monotonic()<br/><br/>    val_start_time = time.monotonic()<br/>    val_loss, val_acc = evaluate(model, valloader, optimiser, criterion)<br/>    val_end_time = time.monotonic()<br/><br/>    train_loss_list[epoch] = train_loss<br/>    train_acc_list[epoch] = train_acc<br/>    val_loss_list[epoch] = val_loss<br/>    val_acc_list[epoch] = val_acc<br/><br/>    print("Training: Loss = <strong class="ok iu">%.4f</strong>, Accuracy = <strong class="ok iu">%.4f</strong>, Time = <strong class="ok iu">%.2f</strong> seconds" %(train_loss, train_acc, train_end_time-train_start_time))<br/>    print("Validation: Loss = <strong class="ok iu">{}</strong>, Accuracy = <strong class="ok iu">{}</strong>, Time = <strong class="ok iu">{}</strong> seconds".format(val_loss, val_acc, val_end_time - val_start_time))<br/>    print("")</span></pre><p id="5544" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这就是:我的代码中最重要的部分！这个模块是所有神经网络训练发生的地方。它首先打印出纪元编号，然后使用训练集加载器训练模型。它还使用time.monotonic()函数计算训练模型所需的时间。然后它对验证集做同样的事情，除了它使用evaluate函数(这里没有训练)。</p><p id="3411" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在这一切结束时，它打印出损耗、精度和训练网络所用的时间。我看到了损失的减少和精确度的提高——这非常令人满意😁</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ov"><img src="../Images/658beb2169e91f7be501d88036dd95e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cbjynLNN-h3jlWf13ETpOQ.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">前一个块的输出——看着损耗减少，精度增加！</p></figure><p id="1c8f" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">顺便说一下，你可以访问项目的Kaggle页面来查看这些块的所有输出。</p><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="1161" class="oo me it ok b gy op oq l or os"><em class="nj"># Saving the model</em><br/><br/><em class="nj"># Create folder to save model</em><br/>MODEL_FOLDER = "../Model"<br/>if <strong class="ok iu">not</strong> os.path.isdir(MODEL_FOLDER):<br/>    os.mkdir(MODEL_FOLDER)<br/>    <br/>PATH_TO_MODEL = MODEL_FOLDER + "/pytorch_classification_alexnetTS.pth"<br/>if os.path.exists(PATH_TO_MODEL):<br/>    os.remove(PATH_TO_MODEL)<br/>t.save(model.state_dict(), PATH_TO_MODEL)<br/><br/>print("Model saved at <strong class="ok iu">%s</strong>" %(PATH_TO_MODEL))</span></pre><p id="d4da" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">当训练完成时，程序保存模型，以便我可以在以后加载和使用它。</p><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="38b8" class="oo me it ok b gy op oq l or os"><em class="nj"># Plot loss and accuracies for training and validation data</em><br/><br/>_, axs = plt.subplots(1, 2, figsize=(15, 5))<br/><br/><em class="nj"># Loss plot</em><br/>axs[0].plot(train_loss_list, label="train")<br/>axs[0].plot(val_loss_list, label="val")<br/>axs[0].set_title("Plot - Loss")<br/>axs[0].set_xlabel("Epochs")<br/>axs[0].set_ylabel("Loss")<br/>legend = axs[0].legend(loc='upper right', shadow=False)<br/><br/><em class="nj"># Accuracy plot</em><br/>axs[1].plot(train_acc_list, label="train")<br/>axs[1].plot(val_acc_list, label="val")<br/>axs[1].set_title("Plot - Accuracy")<br/>axs[1].set_xlabel("Epochs")<br/>axs[1].set_ylabel("Accuracy")<br/>legend = axs[1].legend(loc='center right', shadow=True)</span></pre><p id="7941" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">测试过程之前的最后一点代码是绘制网络的损耗和准确性。这使用matplotlib库来创建两个简单的线图，显示每个时期的损耗和每个时期的精度。每个图表将这些元素中的一个与训练集和验证集进行比较。训练集的线条是蓝色的，验证集的线条是橙色的。看到网络如何随着时代的发展而进步真的很有趣。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ow"><img src="../Images/9c137b5a0d619bbdd29fb3685525b7b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Lz0PASgPGzcW60yS.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">信用:塔拉普罗尔</p></figure><h1 id="48c1" class="md me it bd mf mg oe mi mj mk of mm mn ka og kb mp kd oh ke mr kg oi kh mt mu bi translated">测试模型</h1><p id="f44e" class="pw-post-body-paragraph la lb it lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv im bi translated">现在我已经训练了神经网络，是时候看看它在一些它从未见过的测试数据上的表现了。这是因为在现实世界中，并非所有的路标都处于相同的角度，相同的旋转，相同的背景-计算机通过训练集学习了许多变化，我们需要看看它是否可以应用于一些新的例子。</p><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="ee97" class="oo me it ok b gy op oq l or os"><em class="nj">#Define transformations</em><br/><br/>test_transforms = transforms.Compose([<br/>    transforms.Resize([112, 112]),<br/>    transforms.ToTensor()<br/>    ])</span></pre><p id="e9b8" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">首先，我为测试数据定义了转换。这种转换将测试图像转换为112 x 112的图片，然后转换为PyTorch可以读取的张量。</p><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="dc15" class="oo me it ok b gy op oq l or os"><em class="nj"># Define path of test data</em><br/><br/>test_data_path = "../input/gtsrb-test-images/GTSRB/Final_Test"<br/>test_data = torchvision.datasets.ImageFolder(root = test_data_path, transform = test_transforms)<br/>test_loader = data.DataLoader(test_data, batch_size=1, shuffle=False)<br/><br/>numClasses = 43</span></pre><p id="a448" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">然后我定义了测试数据的路径，再次使用Kaggle数据集中的复制粘贴函数。对于测试数据，我在数据输入方面有一些问题。我使用的CSV文件中的png格式，图像是。ppm文件。我选择从<a class="ae kz" href="https://benchmark.ini.rub.de/gtsrb_dataset.html#Downloads" rel="noopener ugc nofollow" target="_blank"> GTSRB网站</a>单独下载测试图片，并上传到Kaggle作为自定义数据集。</p><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="43fb" class="oo me it ok b gy op oq l or os">import pandas as pd<br/><em class="nj"># Read the image labels from the csv file</em><br/><em class="nj"># Note: The labels provided are all numbers, whereas the labels assigned by PyTorch dataloader are strings</em><br/><br/>df = pd.read_csv("../input/gtsrb-german-traffic-sign/Test.csv")<br/>numExamples = len(df)<br/>labels_list = list(df.iloc[:,6])<br/><br/>print(numExamples)</span></pre><p id="2222" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">为了让计算机读取每个图像，使用CSV文件来获取文件路径和它们各自的类。为了实现这一点，我导入了Pandas库。我用它来读取CSV文件，获取示例数量，并使用iloc函数创建标签列表。这得到了整个列(列7，按照Python语法索引为6 ),并将它转换成一个列表，我可以用它来标记测试图像。</p><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="234f" class="oo me it ok b gy op oq l or os"><em class="nj">#Perform classification</em><br/><br/>y_pred_list = []<br/>corr_classified = 0<br/><br/>with t.no_grad():<br/>    model.eval()<br/>    <br/>    i = 0<br/>    <br/>    for image, _ <strong class="ok iu">in</strong> test_loader:<br/>        image = image.cuda()<br/>        <br/>        y_test_pred = model(image)<br/>        <br/>        y_pred_softmax = t.log_softmax(y_test_pred[0], dim=1)<br/>        _, y_pred_tags = t.max(y_pred_softmax, dim=1)<br/>        y_pred_tags = y_pred_tags.cpu().numpy()<br/>        <br/>        y_pred = y_pred_tags[0]<br/>        y_pred = labels[y_pred]<br/>        <br/>        y_pred_list.append(y_pred)<br/>        <br/>        if labels_list[i] == y_pred:<br/>            corr_classified += 1<br/>        <br/>        i += 1<br/>    <br/>print("Correctly classified: <strong class="ok iu">{}</strong>".format(corr_classified))<br/>print("Incorrectly classified: <strong class="ok iu">{}</strong>".format(numExamples - corr_classified))<br/>print("Final accuracy: <strong class="ok iu">{}</strong>".format(corr_classified / numExamples))</span></pre><p id="5359" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这是一大段代码🤣总的来说，这个模块为模型对测试数据的预测创建了一个空列表。在没有梯度下降(没有训练)的情况下，代码循环通过测试加载器中的每个图像，并在模型中运行它。它使用softmax和max函数来预测给定图像将具有哪个标签，然后将该标签添加到之前创建的列表中。</p><p id="6eef" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">最后，它打印出正确分类的数量，错误分类的数量，然后将两者相除得到最终的准确度。</p><pre class="kk kl km kn gt oj ok ol om aw on bi"><span id="f9f6" class="oo me it ok b gy op oq l or os"><em class="nj"># Display first 30 images, along with the actual and predicted classes</em><br/>from PIL import Image<br/>fig, axs = plt.subplots(6,5,figsize=(50,75))<br/><em class="nj">#fig.tight_layout(h_pad = 50)</em><br/>for i <strong class="ok iu">in</strong> range(30):<br/>    row = i // 5<br/>    col = i % 5<br/>    <br/>    imgName = '../input/gtsrb-test-images/GTSRB/Final_Test/' + df.iloc[i,7]<br/>    wrongFolder = str(imgName).replace('/Test', '/Images')<br/>    wrongExtension = wrongFolder.replace('.png', '.ppm')<br/>    img = Image.open(wrongExtension)<br/>    axs[row, col].imshow(img)<br/>    title = "Pred: <strong class="ok iu">%d</strong>, Actual: <strong class="ok iu">%d</strong>" % (y_pred_list[i], labels_list[i])<br/>    axs[row, col].set_title(title, fontsize=50)<br/><br/>plt.savefig("predictions.png", bbox_inches = 'tight', pad_inches=0.5)</span></pre><p id="0b65" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">最后，是时候看看一些真实的数据和随之而来的预测了！这段代码显示了30个测试图像，预测和实际标签显示在每个图像的上方。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ox"><img src="../Images/363282b45cf689f2443f345b8fac9984.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mG7P0Db9r7pR0odq.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">信用:塔拉普罗尔</p></figure><p id="571b" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">正如你所看到的，该模型只预测了一些错误的图像，并且在对一些硬路标进行分类方面做了非常出色的工作。</p><blockquote class="oy oz pa"><p id="c29c" class="la lb nj lc b ld le jv lf lg lh jy li pb lk ll lm pc lo lp lq pd ls lt lu lv im bi translated">这个项目来自Suraj Krishnamurthy的GTSRB分类程序。这里看Github项目原文:【https://github.com/surajmurthy/TSR_PyTorch T2】</p></blockquote><div class="nr ns gp gr nt nu"><a href="https://www.linkedin.com/in/taraprole/" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd iu gy z fp nz fr fs oa fu fw is bi translated">塔拉·普罗尔- TKS创新者-知识社会(TKS) | LinkedIn</h2><div class="pe l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">我是一名15岁的企业家，已经创建了许多项目，包括一个在线课程和一个NFT作品集。我是…</h3></div><div class="ob l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">www.linkedin.com</p></div></div><div class="pf l"><div class="pg l ph pi pj pf pk kt nu"/></div></div></a></div><p id="e77e" class="pw-post-body-paragraph la lb it lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果你有兴趣看更多我的作品，我有一份每周时事通讯，请在下面订阅！</p><div class="nr ns gp gr nt nu"><a href="https://taraprole.substack.com/subscribe" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab fo"><div class="nw ab nx cl cj ny"><h2 class="bd iu gy z fp nz fr fs oa fu fw is bi translated">塔拉的时事通讯</h2><div class="pe l"><h3 class="bd b gy z fp nz fr fs oa fu fw dk translated">每周想法、目标和建议</h3></div><div class="ob l"><p class="bd b dl z fp nz fr fs oa fu fw dk translated">taraprole.substack.com</p></div></div><div class="pf l"><div class="pl l ph pi pj pf pk kt nu"/></div></div></a></div><h1 id="251a" class="md me it bd mf mg oe mi mj mk of mm mn ka og kb mp kd oh ke mr kg oi kh mt mu bi translated">参考</h1><p id="8c73" class="pw-post-body-paragraph la lb it lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv im bi translated"><strong class="lc iu"> GTSRB数据集</strong></p><ul class=""><li id="74cb" class="na nb it lc b ld le lg lh lj nc ln nd lr ne lv ot ng nh ni bi translated">Johannes Stallkamp、Marc Schlipsing、Jan Salmen和Christian Igel <br/> <a class="ae kz" href="https://www.sciencedirect.com/science/article/abs/pii/S0893608012000457" rel="noopener ugc nofollow" target="_blank">人与计算机:交通标志识别的基准机器学习算法</a>。神经网络32，第323–332页，2012年</li><li id="2aa7" class="na nb it lc b ld nk lg nl lj nm ln nn lr no lv ot ng nh ni bi translated">Johannes Stallkamp、Marc Schlipsing、Jan Salmen和Christian Igel <br/> <a class="ae kz" href="https://ieeexplore.ieee.org/document/6033395" rel="noopener ugc nofollow" target="_blank">德国交通标志识别基准:多类别分类竞赛</a>。神经网络国际联合会议(IJCNN 2011)，第1453–1460页，IEEE出版社</li></ul></div></div>    
</body>
</html>