<html>
<head>
<title>Rockin‘ Rolling Regression in Python via PyMC3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过 PyMC3 在 Python 中实现滚动回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/rockin-rolling-regression-in-python-via-pymc3-e4722b6118cd?source=collection_archive---------4-----------------------#2021-12-03">https://towardsdatascience.com/rockin-rolling-regression-in-python-via-pymc3-e4722b6118cd?source=collection_archive---------4-----------------------#2021-12-03</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><h2 id="c598" class="is it iu bd b dl iv iw ix iy iz ja dk jb translated" aria-label="kicker paragraph"><a class="ae ep" href="https://medium.com/tag/bayesian-statistics" rel="noopener">贝叶斯统计</a></h2><div class=""/><div class=""><h2 id="0f50" class="pw-subtitle-paragraph ka jd iu bd b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr dk translated">学习如何处理变化的参数</h2></div><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ks"><img src="../Images/5ad73a9d9f588c6488184cf1b74cd37e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qCWCrfqnLlR5SvXm"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">由<a class="ae li" href="https://unsplash.com/@vorosbenisop?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">本杰明·沃罗斯</a>在<a class="ae li" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="04cd" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi mf translated"><span class="l mg mh mi bm mj mk ml mm mn di">答</span>假设您想要训练一个参数模型，如线性模型或神经网络。在线性回归的情况下，首先，你指定模型的形状，我们说<em class="mo"> y = ax + b. </em>其次，你估计参数<em class="mo"> a </em>和<em class="mo"> b </em>。对你这样的专家来说没什么难的。</p><p id="de78" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我想指出的是你在这样做的时候所做的一个隐含的假设:</p><blockquote class="mp"><p id="5335" class="mq mr iu bd ms mt mu mv mw mx my me dk translated">来自数据集的所有观测值都服从具有相同固定参数的相同模型。</p></blockquote><p id="c700" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nb lu lv lw nc ly lz ma nd mc md me in bi translated">在线性模型的情况下，这意味着<em class="mo"> a </em>和<em class="mo"> b </em>  <strong class="ll je">的<strong class="ll je">相同固定值适用于所有观测值</strong>。这个假设是否合理，取决于你手头的数据集。虽然它经常成立，但在这篇文章中，我想给你看一个简单的例子，它是完全错误的。在你读完之后，你将能够自己发现这些有问题的例子，并且知道如何以一种好的方式对待它们。我们将考虑一个天真的以及不错的贝叶斯治疗。</strong></p><h1 id="ee6d" class="ne nf iu bd ng nh ni nj nk nl nm nn no kj np kk nq km nr kn ns kp nt kq nu nv bi translated">随时间变化的参数</h1><p id="a685" class="pw-post-body-paragraph lj lk iu ll b lm nw ke lo lp nx kh lr ls ny lu lv lw nz ly lz ma oa mc md me in bi translated">一个参数可能变化的明显场景是在处理时间序列时。随着时间的推移，数据的输入和输出之间的依赖关系可能会改变，这意味着模型及其参数也必须随着时间的推移而改变。</p><p id="81c4" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">作为一个假设的例子，让我们假设我们有一个数据集<em class="mo"> D </em> = ( <em class="mo"> t </em>，<em class="mo"> x </em>，<em class="mo"> y </em>)，其中<em class="mo"> t </em>是某个时间戳。<em class="mo"> D </em>的时间上的第一个条目可能表现得像<em class="mo">y</em><strong class="ll je">≈</strong><em class="mo"/>3<em class="mo">x+</em>2，而最近的条目表现得更像<em class="mo">y</em><strong class="ll je">≈</strong><em class="mo">-x+</em>1，这只是因为事情随着时间而改变。如果我们能够检测并量化这样的变化，那就太好了，例如通过找到一些满足<em class="mo">y</em><strong class="ll je">≈</strong><em class="mo">a</em><em class="mo">t</em><em class="mo">x+b</em>的时间相关函数<em class="mo"> a </em> ( <em class="mo"> t </em>)和<em class="mo"> b </em> ( <em class="mo"> t </em>)</p><p id="ef8d" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">为了了解我们如何做到这一点，让我们看一个具体的例子。</p><h2 id="88df" class="ob nf iu bd ng oc od dn nk oe of dp no ls og oh nq lw oi oj ns ma ok ol nu ja bi translated">抽样资料</h2><p id="c30d" class="pw-post-body-paragraph lj lk iu ll b lm nw ke lo lp nx kh lr ls ny lu lv lw nz ly lz ma oa mc md me in bi translated">首先，让我们加载数据集:</p><pre class="kt ku kv kw gu om on oo bn op oq bi"><span id="62ce" class="or nf iu on b be os ot l ou ov">import pandas as pd<br/>data = pd.read_csv(<br/>  'https://raw.githubusercontent.com/Garve/datasets/3b6b1e6fadc04e2444905db0a0b2ed222daeaa28/rolling_data.csv',<br/>   index_col='t'<br/>)</span></pre><p id="9fe1" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">然后，我们可以看一看它:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ow"><img src="../Images/648c7df32394a376e021496a1fe2e6c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JbSNi9qq97mDs5_iINhLmA.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="428c" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们的目标是找到一个线性模型，在给定<em class="mo"> x，</em>即<em class="mo"> y = ax + b </em>的情况下预测<em class="mo"> y </em>。然而，仅从图中我们可以看出，由于以下观察结果，固定值对于<em class="mo"> a </em>和<em class="mo"> b </em>是不够的:</p><ol class=""><li id="9ca5" class="ox oy iu ll b lm ln lp lq ls oz lw pa ma pb me pc pd pe pf bi translated">在 300 和 670 左右的时间内，蓝色和红色时间序列都增加，然后又同步下降。这表明它们是正相关的，这暗示着<em class="mo">a</em>T54】0。</li><li id="9490" class="ox oy iu ll b lm pg lp ph ls pi lw pj ma pk me pc pd pe pf bi translated">在时间 720 和 950 期间，蓝色时间序列先增加然后下降，而红色时间序列正好相反。这暗示着这些时间序列是负相关的，意味着<em class="mo">a</em>T55】0。</li></ol><p id="b62a" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">这两点都表明斜率<em class="mo"> a </em>必须随时间变化，这意味着我们更愿意处理一个依赖于时间的函数<em class="mo"> a </em> ( <em class="mo"> t </em>)，而不仅仅是一个固定的<em class="mo"> a </em>。</p><p id="a16c" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们也可以在散点图中以不同的方式显示上面的图片，这样我们可以更好地理解实际数据集的样子:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pl"><img src="../Images/b133ee7735b127cad9e1de1fd18568ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oDhDZaCn0gjipBZ8r7Ps2g.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="5b1d" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">在这个表示中，您还可以看到回归线做了次优的工作。做线性回归</p><pre class="kt ku kv kw gu om on oo bn op oq bi"><span id="161b" class="or nf iu on b be os ot l ou ov">from sklearn.linear_model import LinearRegression<br/><br/>X = data[['x']]<br/>y = data['y']<br/><br/>lr = LinearRegression().fit(X, y)<br/><br/>print(f'intercept = {lr.intercept_:.5f}, slope = {lr.coef_[0]:.3f}')<br/><br/># Output: intercept = 18.45587, slope = 0.593</span></pre><p id="cc67" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">生产</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pl"><img src="../Images/b371be9f16d09c45fd663a2bab5d2b61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QVO0B5M4UACvvGVkpAkwgw.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="d39c" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">不是很合适。那么，怎样做才能更精确地描述<em class="mo"> x </em>和<em class="mo"> y </em>之间的联系呢？</p><h1 id="04c8" class="ne nf iu bd ng nh ni nj nk nl nm nn no kj np kk nq km nr kn ns kp nt kq nu nv bi translated">可怜人的滚动回归</h1><p id="5411" class="pw-post-body-paragraph lj lk iu ll b lm nw ke lo lp nx kh lr ls ny lu lv lw nz ly lz ma oa mc md me in bi translated">一个简单的解决方法是在一个连续的滑动窗口上进行几次较小的回归。听起来不错吧？它的意思如下:</p><ol class=""><li id="4a2b" class="ox oy iu ll b lm ln lp lq ls oz lw pa ma pb me pc pd pe pf bi translated">您创建了第一个<em class="mo"> w </em>观察值的较小子集，即从时间<strong class="ll je"> 0 到<em class="mo"> w </em> -1 </strong>。<em class="mo">即第一次迭代中的滑动窗口</em>。你在这个子数据集上做普通的最小二乘法，写下直线的斜率和截距。</li><li id="271e" class="ox oy iu ll b lm pg lp ph ls pi lw pj ma pk me pc pd pe pf bi translated">你移动窗口一步，意味着它现在从时间<strong class="ll je"> 1 到达<em class="mo">w</em>T37】。在这个子数据集上使用普通最小二乘法。</strong></li><li id="033f" class="ox oy iu ll b lm pg lp ph ls pi lw pj ma pk me pc pd pe pf bi translated">您将窗口移动一步，这意味着它现在从时间<strong class="ll je"> 2 到达 w+1 </strong>。在这个子数据集上使用普通最小二乘法。</li><li id="ec95" class="ox oy iu ll b lm pg lp ph ls pi lw pj ma pk me pc pd pe pf bi translated">你移动窗口一步，意味着它现在从时间<strong class="ll je"> 3 到达 w+2 </strong>。在这个子数据集上使用普通最小二乘法。</li><li id="3664" class="ox oy iu ll b lm pg lp ph ls pi lw pj ma pk me pc pd pe pf bi">…</li></ol><p id="9f3f" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">你明白了:每个小数据集由<em class="mo"> w </em>个连续元素组成，其中<em class="mo"> w </em>也被称为(<em class="mo">窗口</em> ) <em class="mo">长度。这是一个你可以随意摆弄的超参数。从图形上看是这样的(<em class="mo"> w </em> = 3):</em></p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj pm"><img src="../Images/65f53e9fd600040bcb76064f91523463.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/1*lKKEWER7lGg8sweujSSBzg.gif"/></div><p class="le lf gk gi gj lg lh bd b be z dk translated">数据集上长度为 3 的滑动窗口(蓝色),有 9 个时间步长，图片由作者提供。</p></figure><p id="e9e6" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">编写这种<strong class="ll je">滚动回归方法</strong>的简单方法如下:</p><pre class="kt ku kv kw gu om on oo bn op oq bi"><span id="7a49" class="or nf iu on b be os ot l ou ov">w = 30 # sliding window of length 30<br/><br/>slopes = []<br/>intercepts = []<br/><br/>for i in range(len(data) - w):<br/>    X = data.loc[i:i+w, ['x']]<br/>    y = data.loc[i:i+w, 'y']<br/>    lr = LinearRegression()<br/>    lr.fit(X, y)<br/>    intercepts.append(lr.intercept_)<br/>    slopes.append(lr.coef_[0])</span></pre><p id="3a91" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">绘制我们得到的斜率和截距</p><div class="kt ku kv kw gu ab cb"><figure class="pn kx po pp pq pr ps paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><img src="../Images/f1d17196561c1ffb8db13b3aef270d9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*XwnCNS1YVUVbg8C3UxBDPw.png"/></div></figure><figure class="pn kx pt pp pq pr ps paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><img src="../Images/3dd4ac7aabd1c19fc8838c7dbecc5ee0.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*9XNTxEFIXjSZoxOJWSAQ3w.png"/></div><p class="le lf gk gi gj lg lh bd b be z dk pu di pv pw translated">作者图片。</p></figure></div><p id="2202" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们可以看到，斜率从正变到负再变回来是非常不规则的。截距似乎随着时间增加了一点。这很有趣，但是它可能取决于窗口长度吗？我们将它设置为 30 是相当武断的，那么为什么不尝试其他值，比如 200，看看故事是否会发生变化？</p><p id="80b9" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">一般来说，以下情况成立:</p><blockquote class="mp"><p id="da26" class="mq mr iu bd ms mt mu mv mw mx my me dk translated">窗口长度越大，图形越平滑。</p></blockquote><p id="d000" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nb lu lv lw nc ly lz ma nd mc md me in bi translated">这是因为窗口长度越大，每两个相邻的子数据集就越相似。如果窗口长度是 200，那么每两个相邻子数据集(至少)有 199 行是相同的。几乎相同的数据集意味着训练后几乎相同的模型，至少对于线性回归这样的确定性方法来说是如此。如果窗口长度仅为 2，那么每两个相邻的子数据集只有至少 50%是相同的，因此在这些数据集上训练的模型可以显著不同。让我们看看长度为 200 的滑动窗口的结果是什么样的。</p><div class="kt ku kv kw gu ab cb"><figure class="pn kx px pp pq pr ps paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><img src="../Images/9568bf7abb6f37130eca083398238b28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*9fTYqmLNQiX-WVsDGVy1xw.png"/></div></figure><figure class="pn kx py pp pq pr ps paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><img src="../Images/808a3388adb2b53efd6ee3642001ceb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*F1w8MagSpwdZrHxk0k2jJQ.png"/></div><p class="le lf gk gi gj lg lh bd b be z dk pz di qa pw translated">作者图片。</p></figure></div><p id="484c" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们可以看到，图形更加平滑，故事大致保持不变:斜率在零附近波动，截距随着时间的推移而增加。然而，曲线图差别很大，所以很难说斜率和截距<strong class="ll je">实际上</strong>如何随时间演变。</p><p id="1fd3" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">总之，这种滚动回归方法在很大程度上取决于窗口长度，我不知道有什么好的方法来正确选择这个超参数，以获得<em class="mo">真相</em><strong class="ll je"/>。</p><p id="460b" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">因此，让我们研究一种更好的方法来处理变化的参数。像往常一样，贝叶斯挽救了局面。</p><h1 id="af42" class="ne nf iu bd ng nh ni nj nk nl nm nn no kj np kk nq km nr kn ns kp nt kq nu nv bi translated">贝叶斯滚动回归</h1><p id="ecd7" class="pw-post-body-paragraph lj lk iu ll b lm nw ke lo lp nx kh lr ls ny lu lv lw nz ly lz ma oa mc md me in bi translated">首先，让我们回顾一下简单的贝叶斯线性回归是什么样子的。您可以在此了解更多信息:</p><div class="qb qc gq gs qd qe"><a rel="noopener follow" target="_blank" href="/bayesian-linear-regression-in-python-via-pymc3-ab8c2c498211"><div class="qf ab fp"><div class="qg ab qh cl cj qi"><h2 class="bd je gz z fq qj fs ft qk fv fx jd bi translated">通过 PyMC3 在 Python 中实现贝叶斯线性回归</h2><div class="ql l"><h3 class="bd b gz z fq qj fs ft qk fv fx dk translated">了解如何推断模型参数并对新数据进行预测，包括不确定性估计！</h3></div><div class="qm l"><p class="bd b dl z fq qj fs ft qk fv fx dk translated">towardsdatascience.com</p></div></div><div class="qn l"><div class="qo l qp qq qr qn qs lc qe"/></div></div></a></div><h2 id="4c96" class="ob nf iu bd ng oc od dn nk oe of dp no ls og oh nq lw oi oj ns ma ok ol nu ja bi translated">第一次尝试</h2><p id="e0bd" class="pw-post-body-paragraph lj lk iu ll b lm nw ke lo lp nx kh lr ls ny lu lv lw nz ly lz ma oa mc md me in bi translated">假设您知道该练习，请检查代码:</p><pre class="kt ku kv kw gu om on oo bn op oq bi"><span id="a877" class="or nf iu on b be os ot l ou ov">import pymc3 as pm<br/><br/>with pm.Model() as linear_model:<br/>    slope = pm.Normal('slope', sigma=1) # a<br/>    intercept = pm.Normal('intercept', sigma=1) # b<br/>    noise = pm.Exponential('noise', lam=1)<br/>    <br/>    y = pm.Normal(<br/>        'y',<br/>        mu=slope*data['x'] + intercept, # the linear model equation<br/>        sigma=noise,<br/>        observed=data['y']<br/>    )<br/>    <br/>    linear_trace = pm.sample(return_inferencedata=True)</span></pre><p id="2f12" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">这里应该没有什么惊喜。我们定义了一个斜率、截距和一个具有先验知识的噪声参数，并通过均值为<em class="mo"> ax + b </em>的正态分布直接对输出<em class="mo"> y </em>进行建模。</p><p id="cc92" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">不幸的是，这个模型就像简单的线性回归一样糟糕，只是带有不确定性界限。那么，我们如何对随时间变化的事物建模呢？引入变化斜率的简单方法如下:</p><pre class="kt ku kv kw gu om on oo bn op oq bi"><span id="a85d" class="or nf iu on b be os ot l ou ov">import pymc3 as pm<br/><br/>with pm.Model() as linear_model_2:<br/>    slopes = pm.Normal('slopes', sigma=1, shape=len(data))<br/>    intercepts = pm.Normal('intercepts', sigma=1, shape=len(data))<br/>    noise = pm.Exponential('noise', lam=1)<br/>    <br/>    y = pm.Normal(<br/>        'y',<br/>        mu=slopes*data['x'] + intercepts,<br/>        sigma=noise,<br/>        observed=data['y']<br/>    )<br/>    <br/>    linear_trace_2 = pm.sample(return_inferencedata=True)</span></pre><p id="019d" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">使用这段代码，我们给<strong class="ll je">每个时间步长赋予它自己的斜率和截距</strong>，因为我们定义的斜率和截距与数据集中的观测值一样多。</p><blockquote class="mp"><p id="a5ae" class="mq mr iu bd ms mt mu mv mw mx my me dk translated">我希望你明白这是个糟糕的主意。</p></blockquote><p id="4051" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nb lu lv lw nc ly lz ma nd mc md me in bi translated">该模型定义，即使用<code class="fe qt qu qv on b">shape=len(data)</code>，意味着所有参数相互独立。所有的斜率都是相同且独立的<em class="mo"> N </em> (0，1)分布(正态)，这意味着两个相邻的斜率可能相距很远。例如，假设在一个时间步长中斜率为 2.41，而在下一个时间步长中斜率急剧变化为-2.8。由于随着时间的推移变化通常更平稳，这不是我们从现实世界的时间序列中所期望的。当然，拦截也是如此。</p><p id="da0e" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">查看当前行为的另一种方式是，它相当于使用一个长度为<strong class="ll je">1 的滑动窗口。</strong>每个斜率和截距都必须用<strong class="ll je">单个数据点</strong>来估计，而且没有合理的方法来做到这一点。</p><h2 id="0a42" class="ob nf iu bd ng oc od dn nk oe of dp no ls og oh nq lw oi oj ns ma ok ol nu ja bi translated">高斯随机游动</h2><p id="5a4b" class="pw-post-body-paragraph lj lk iu ll b lm nw ke lo lp nx kh lr ls ny lu lv lw nz ly lz ma oa mc md me in bi translated">解决方案是使两个相邻滚动窗口的参数以某种方式相关。如果某一时刻<em class="mo"> t </em>的斜率为<em class="mo"> a </em> ( <em class="mo"> t </em>)，那么下一时间步<em class="mo"> t </em> + 1 的斜率也不应远离<em class="mo"> a </em> ( <em class="mo"> t </em>)。表达这一点的一种方式是通过对所有时间的标准偏差<em class="mo">σ</em>进行建模<em class="mo">a</em>(<em class="mo">t+1</em>)~<em class="mo">N</em>(<em class="mo">a</em>(<em class="mo">t</em>)<em class="mo">，σ</em><em class="mo">)</em>，对第一个斜率使用一些初始值，如<em class="mo">a</em>(0 用语言来说:</p><blockquote class="mp"><p id="0bba" class="mq mr iu bd ms mt mu mv mw mx my me dk translated">下一个斜率是旧斜率加上一些误差。</p></blockquote><p id="a60e" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nb lu lv lw nc ly lz ma nd mc md me in bi translated">这就是所谓的<a class="ae li" href="https://en.wikipedia.org/wiki/Random_walk#Gaussian_random_walk" rel="noopener ugc nofollow" target="_blank">高斯随机游走</a>。您可以通过 NumPy 自己模拟一个</p><pre class="kt ku kv kw gu om on oo bn op oq bi"><span id="fc92" class="or nf iu on b be os ot l ou ov">np.random.seed(0)<br/><br/>steps = 20 # length of the random walk<br/>a = [0] # the initial slope, can be anything<br/>sigma = 1 # the error<br/>for t in range(steps):<br/>    a.append(np.random.normal(a[-1], sigma))</span></pre><p id="2646" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">绘图<code class="fe qt qu qv on b">a</code>导致</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj qw"><img src="../Images/e994381e99ba0f2416e7aa02b0427fd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p11SAYLTk5cAI3lGfStvEQ.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="3da9" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">如果你稍微摆弄一下<code class="fe qt qu qv on b">sigma</code>，你会发现值越大，<code class="fe qt qu qv on b">a</code>内的跳跃越大，这是有道理的。你还可以看到的是，对于所有的<em class="mo"> t </em>来说，<em class="mo"> a </em> ( <em class="mo"> t+1 </em>)总是接近<em class="mo"> a </em> ( <em class="mo"> t </em>)。</p><h2 id="bbb2" class="ob nf iu bd ng oc od dn nk oe of dp no ls og oh nq lw oi oj ns ma ok ol nu ja bi translated">PyMC3 模型</h2><p id="bbd8" class="pw-post-body-paragraph lj lk iu ll b lm nw ke lo lp nx kh lr ls ny lu lv lw nz ly lz ma oa mc md me in bi translated">虽然在 PyMC3 中实现同样的逻辑并不太难，但是开发人员通过实现一个<code class="fe qt qu qv on b">GaussianRandomWalk</code>发行版让我们变得很容易。有了它，我们现在可以用 PyMC3 写下最终的模型了。整体造型和之前挺像的。我们只需要</p><ol class=""><li id="3706" class="ox oy iu ll b lm ln lp lq ls oz lw pa ma pb me pc pd pe pf bi translated">引入两个高斯随机游走，一个用于斜率，一个用于截距，以及</li><li id="7beb" class="ox oy iu ll b lm pg lp ph ls pi lw pj ma pk me pc pd pe pf bi translated">这些高斯随机游走的两个噪声参数</li></ol><p id="b451" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">以下是建议书范本:</p><pre class="kt ku kv kw gu om on oo bn op oq bi"><span id="21f6" class="or nf iu on b be os ot l ou ov">with pm.Model() as rolling_linear_model:<br/>    # noise parameters<br/>    sigma_slope = pm.Exponential('sigma_slope', lam=1)<br/>    sigma_intercept = pm.Exponential('sigma_intercept', lam=1)<br/>    sigma = pm.Exponential('sigma', lam=1)<br/>    <br/>    # Gaussian random walks<br/>    slopes = pm.GaussianRandomWalk(<br/>        'slopes',<br/>        sigma=sigma_slope,<br/>        shape=len(data)<br/>    )<br/>    intercepts = pm.GaussianRandomWalk(<br/>        'intercepts',<br/>        sigma=sigma_intercept,<br/>        shape=len(data)<br/>    )<br/>    <br/>    # putting it together<br/>    y = pm.Normal(<br/>        'y',<br/>        slopes*data['x'] + intercepts,<br/>        sigma,<br/>        observed=data['y']<br/>    )<br/>    <br/>    rolling_linear_trace = pm.sample(return_inferencedata=True)</span></pre><p id="2ecd" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">与之前的简单线性回归相比，运行该模型需要一些时间，因为有许多参数也随机地相互依赖。不过，在你的机器上，这应该不到 15 分钟。</p><p id="ab11" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们可以运行一个后验预测检查，看看这个模型是否通过</p><pre class="kt ku kv kw gu om on oo bn op oq bi"><span id="ff03" class="or nf iu on b be os ot l ou ov">import arviz as az<br/><br/>with rolling_linear_model:<br/>    posterior = pm.sample_posterior_predictive(rolling_linear_trace)<br/>    az.plot_ppc(az.from_pymc3(posterior_predictive=posterior))</span></pre><p id="e93d" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">这输出</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj qx"><img src="../Images/74424d00723f2342c02f9d929f89f558.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*ErvXa3uxFzyQ4tVerwWz8A.png"/></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="00df" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">这意味着该模型非常好地捕捉了观察到的数据，因为黑色的<em class="mo">观察到的</em>线正好在蓝色的<em class="mo">后验预测</em>管内。这辆<em class="mo"> r </em>也表现不错:</p><pre class="kt ku kv kw gu om on oo bn op oq bi"><span id="28f8" class="or nf iu on b be os ot l ou ov">az.r2_score(data['y'].values, rolling_posterior['y'])<br/><br/># Output:<br/># r2        0.981449<br/># r2_std    0.000920</span></pre><blockquote class="qy qz ra"><p id="c47b" class="lj lk mo ll b lm ln ke lo lp lq kh lr rb lt lu lv rc lx ly lz rd mb mc md me in bi translated">但是，请注意，这是培训绩效。该模型可能会也可能不会过拟合，但这不是我们在这里要讨论的内容。</p></blockquote><p id="6e4c" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">总的来说，挺好看的。是时候提取模型对斜率和截距的了解了。</p><h1 id="cc19" class="ne nf iu bd ng nh ni nj nk nl nm nn no kj np kk nq km nr kn ns kp nt kq nu nv bi translated">结果</h1><p id="8103" class="pw-post-body-paragraph lj lk iu ll b lm nw ke lo lp nx kh lr ls ny lu lv lw nz ly lz ma oa mc md me in bi translated">由于这个提取过程不是完全显而易见的，所以让我向您展示一下我是如何做到的。</p><pre class="kt ku kv kw gu om on oo bn op oq bi"><span id="a98b" class="or nf iu on b be os ot l ou ov">import matplotlib.pyplot as plt<br/><br/># extract the means and standard deviations of the slopes<br/>posteriors = rolling_linear_trace.posterior.slopes.values<br/>slopes_means = posteriors.reshape(4000, len(data)).mean(0)<br/>slopes_stds = posteriors.reshape(4000, len(data)).std(0)<br/><br/># plot<br/>plt.figure(figsize=(16, 8))<br/>plt.fill_between(<br/>    range(len(data)),<br/>    slopes_means - 2*slopes_stds,<br/>    slopes_means + 2*slopes_stds,<br/>    alpha=0.33,<br/>    label='$\mu \pm 2\sigma$'<br/>)<br/>plt.plot(slopes_means, linewidth=1, label='$\mu$')<br/>plt.title('Slope over time')<br/>plt.xlabel('Time')<br/>plt.legend()</span></pre><p id="fd5f" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">您会收到以下内容:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj re"><img src="../Images/689a2167142aae2e2b8d32d3d1eefe57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cC_u31301BzBYRYEkRHPew.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="f934" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">这看起来比以前好多了，对吧？它非常平滑，并且有很好的图案，当然这并不表示结果是正确的。但在这种情况下，我可以告诉你，结果是相当准确的，因为我自己创建了地面真相和数据集。让我把随时间变化的真实斜率也放入图中:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj re"><img src="../Images/e6bc7896302b5694fb879d2be939df16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EALaiRm3dapnvZAFWeVy0A.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="3d51" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">这是拦截的结果。正如您在这里看到的，它们也是正确的:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj rf"><img src="../Images/43f7291db1aec90e61baff96328f31bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7qSWkTW5NvPMBhzsFefZvg.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="5c4f" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">因此，使用高斯随机游走的<em class="mo">贝叶斯滚动回归方法</em>(多么好的一个词，嗯)在这种情况下工作得很好，在您的情况下也可能如此。每当您觉得参数可能会随时间或跨任何其他维度发生变化时，您都可以尝试一下！</p><h1 id="75ff" class="ne nf iu bd ng nh ni nj nk nl nm nn no kj np kk nq km nr kn ns kp nt kq nu nv bi translated">结论</h1><p id="3779" class="pw-post-body-paragraph lj lk iu ll b lm nw ke lo lp nx kh lr ls ny lu lv lw nz ly lz ma oa mc md me in bi translated">在本文中，我们已经看到，将参数模型中的参数视为固定参数有时是没有目的的。由于输入和输出数据之间的关系会随着时间的推移而变化，因此模型也必须能够调整其参数。否则，它可能会惨败。</p><p id="29b3" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们已经讨论了一种简单的滚动窗口方法，这种方法易于理解和实现，但是非常不稳定，因为它取决于超参数<em class="mo">窗口长度</em>，而我们不知道如何正确设置。</p><p id="e87f" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">作为补救措施，我们定义了一个贝叶斯滚动回归模型使用高斯随机游走。它运行良好，非常灵活。您可以扩展这个模型来包含更多的特性，但是您也可以固定一些参数，只让其中的一些发生变化。无论何时，当您想要可视化随时间的变化时，在您的清单中有这个模型是非常好的。</p><p id="1367" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">但是，请注意，该模型仅用于<strong class="ll je">推理</strong>，即确定参数。预测未来是很困难的，因为随机行走的随机性会给你未来更大的不确定性。要创建预测，您可以尝试找到斜率、截距和所有其他参数随时间变化的公式，并在您的模型中使用该公式。在示例中，我们有<em class="mo">a</em>(<em class="mo">t</em>)= sin(<em class="mo">t</em>/20)/3 和<em class="mo"> b </em> ( <em class="mo"> t </em> ) = √ <em class="mo"> t，</em>，因此最终的模型方程为<em class="mo">y</em>= sin(<em class="mo">t</em>/20)/3 *<em class="mo">x</em>+√<em class="mo">t .</em></p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pl"><img src="../Images/faee6bd3493448675e7a9729e5d1d8e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hi4u7BEkqTtwo586Ac6Yfw.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure></div><div class="ab cl rg rh hy ri" role="separator"><span class="rj bw bk rk rl rm"/><span class="rj bw bk rk rl rm"/><span class="rj bw bk rk rl"/></div><div class="in io ip iq ir"><p id="a934" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我希望你今天学到了新的、有趣的、有用的东西。感谢阅读！</p><p id="6375" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated"><strong class="ll je">作为最后一点，如果你</strong></p><ol class=""><li id="b3dc" class="ox oy iu ll b lm ln lp lq ls oz lw pa ma pb me pc pd pe pf bi translated"><strong class="ll je">想支持我多写点机器学习和</strong></li><li id="dd9b" class="ox oy iu ll b lm pg lp ph ls pi lw pj ma pk me pc pd pe pf bi translated"><strong class="ll je">无论如何，计划获得一个中等订阅量，</strong></li></ol><p id="444f" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated"><strong class="ll je">为什么不做</strong> <a class="ae li" href="https://dr-robert-kuebler.medium.com/membership" rel="noopener"> <strong class="ll je">通过这个环节</strong> </a> <strong class="ll je">？这将对我帮助很大！😊</strong></p><p id="69ec" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">透明地说，给你的价格不变，但大约一半的订阅费直接归我。</p><p id="8c98" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">非常感谢，如果你考虑支持我的话！</p><blockquote class="mp"><p id="d2df" class="mq mr iu bd ms mt mu mv mw mx my me dk translated"><em class="rn">如有问题，在</em><a class="ae li" href="https://www.linkedin.com/in/dr-robert-k%C3%BCbler-983859150/" rel="noopener ugc nofollow" target="_blank"><em class="rn">LinkedIn</em></a><em class="rn">上写我！</em></p></blockquote></div></div>    
</body>
</html>