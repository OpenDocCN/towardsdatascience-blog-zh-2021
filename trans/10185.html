<html>
<head>
<title>The Future of Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习的未来</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-future-of-deep-learning-7e8574ad6ae3?source=collection_archive---------13-----------------------#2021-09-27">https://towardsdatascience.com/the-future-of-deep-learning-7e8574ad6ae3?source=collection_archive---------13-----------------------#2021-09-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="240d" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">意见</h2><div class=""/><div class=""><h2 id="64a3" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">来自IEEE频谱的关键预测</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/60a7191b84d7df17a289a20dcd8a9602.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9-kVqzohZsdpo0uHoUdXhA.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">信用:Pixabay</p></figure><p id="97c1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">IEEE Spectrum 发布了可能是关于深度学习的最重要的论文，对其长期可行性提出了批评——结论对深度学习教会来说是严峻的。</p><p id="b0cf" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">作者尼尔·C·汤普森是麻省理工学院的人工智能研究员，所以可以肯定地说，这些不是一个不合格记者的想法；相反，这是对深度学习走向的公平评估，而不是受到公司股价的支撑。</p><p id="97c0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">早期，汤普森描述了对100%准确性的追求。假设一个任意的模型在一些分类任务上执行90%的准确率。从计算角度来说，精度每增加一次，向100%迈进，都要比前一次昂贵得多。摩尔定律表明，随着时间的推移，处理能力呈指数级增长。但是，尽管未来有更高效的芯片，我们对深度学习模型的渴望将远远超过硬件的发展。这可能看起来很抽象，但当考虑到货币和环境成本时，趋势变得很明显:深度学习永远不会是财政或环境友好的。无论硬件的发展如何，我们对深度学习的期望都将超过硬件所能提供的一切——而成本只会增加。</p><p id="b256" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了将这种现象置于背景中，考虑一下训练Alpha Go(基于RL的机器人，培养了世界上最好的围棋选手)的成本。)Deepmind支付的价码:3500万美元。与此相关，在图像分类上达到1%的错误率对环境来说可能比T2一个月的碳排放量还要糟糕！深度学习已经因算法偏见而受到负面关注，因此它作为人工智能金童的地位已经岌岌可危。环境影响进入一个同样响亮的阶段，深度学习被视为完全不人道，这只是时间问题。</p><p id="8e05" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">深度学习的成本变得如此昂贵，以至于元学习和迁移学习已经成为当前的权宜之计:一个财大气粗的组织训练一个模型，不是检测猫或狗、人或脸、建筑物或桥梁——或任何其他事物本身——而是检测一切。元学习就是这样；随后，数据科学家、软件工程师和机器学习工程师针对他们的需求，在一些下游任务中重新训练这些模型，这就是迁移学习。这种元迁移学习设计的问题是，下游任务的准确性通常被认为是不可行的，肯定达不到所宣传的最先进的阈值。解决办法？更大的元学习模型以更高的成本——在金钱和环境方面。然而，成本将超过进展，因此这种解决方案的创可贴性质。</p><p id="73ae" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">考虑到上述事实，深度学习社区的严峻未来摆在面前:成本呈指数级上升，而性能回报却在下降。这是另一个所谓的人工智能冬天的配方。</p><p id="264b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">那么，在深度学习复活之前，社区将走向何方？主要基于专家的系统，领域专家利用他们的知识来开发本体和基于规则的系统。这在计算上更有效，然而，它不允许经验学习。一个潜在的前进方向？神经符号方法——领域知识和自主学习之间的一种联系。</p><p id="b47f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">有趣的是，我从未热衷于深度学习模型本质上是黑箱；有数以亿计的参数，很难抓住一个给定的参数值，并使用它来增加我们人类对周围世界的了解。然而，神经符号方法可能是人类理解和自主学习之间缺失的一环。现在下结论还为时过早。我们现在唯一可以确定的是——深度学习社区正在面临清算。也许不是今天或明天，但冬天即将来临。</p></div></div>    
</body>
</html>