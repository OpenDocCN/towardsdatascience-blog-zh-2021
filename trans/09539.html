<html>
<head>
<title>Build Your Own Discord Moderation Bot Using Python and Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python和深度学习构建自己的不和谐调节机器人</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/build-your-own-discord-moderation-bot-using-python-and-deep-learning-4386fc43e45e?source=collection_archive---------22-----------------------#2021-09-04">https://towardsdatascience.com/build-your-own-discord-moderation-bot-using-python-and-deep-learning-4386fc43e45e?source=collection_archive---------22-----------------------#2021-09-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="dc58" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">建立一个自主机器人，删除所有有毒信息。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0be10daaef400421f74ddba2ed85fa41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fWr0suqcrNAi3mC3vHttyg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在<a class="ae kv" href="https://unsplash.com/s/photos/chat?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae kv" href="https://unsplash.com/@centelm?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Clément Falize </a>拍摄的照片</p></figure><h1 id="745b" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="6ba6" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">鉴于互联网用户生成的文本规模，内容审核可能很困难。简化这一过程的一个解决方案是使用机器学习来自动化它。一个ML模型训练了版主不想看到的例子，如有毒内容、侮辱或种族主义评论，然后可以用来自动过滤掉这些消息。</p><p id="e1e5" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在这个项目中，我们将使用Jigsaw毒性评论数据集训练这样的模型:<a class="ae kv" href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/Jigsaw-Toxic-Comment-class ification-challenge/Data</a></p><p id="80f8" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">然后，我们将使这个模型可以从一个<a class="ae kv" href="https://discord.com/developers/docs/intro" rel="noopener ugc nofollow" target="_blank"> Discord bot </a>中调用，该bot将删除该模型标记为有毒的所有消息。</p><h1 id="0f80" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">数据</h1><p id="cdba" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">Jigsaw毒性数据包括159，000个样本，每个样本都可以贴上多个类别的标签，如“有毒”、“侮辱”…</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/7dc4a727128f0251f918b6fb587af1f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ek-3vfHzNtfb1S5BA-bBw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据集格式-按作者分类的图像</p></figure><p id="d54c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">为简单起见，我们使用所有这些类别来创建一个二进制目标，如下所示:</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="0f70" class="mv kx iq mr b gy mw mx l my mz">data["label"] = (<br/>    data[<br/>        ["toxic", "severe_toxic", "obscene", "threat", "insult", "identity_hate"]<br/>    ].sum(axis=1, skipna=True)<br/>    &gt; 0.5<br/>).astype(int)</span></pre><h1 id="d279" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">机器学习步骤</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/08802490359e9a1619286e73469b1ab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*cDb11CVFNraftKnD6yQ3Mg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">机器学习步骤-作者图片</p></figure><h2 id="1ec9" class="mv kx iq bd ky nb nc dn lc nd ne dp lg lx nf ng li mb nh ni lk mf nj nk lm nl bi translated">标记器</h2><p id="6f84" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我用huggingface的库训练了我自己的BPE分词器，你可以用我的Github库中的脚本做同样的事情:</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="60eb" class="mv kx iq mr b gy mw mx l my mz">python bleach_bot/ml/train_tokenizer.py --files YOUR_TEXT_FILES</span></pre><p id="f389" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这个记号赋予器将句子分解成小记号，然后将每个记号映射成整数:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/b8b8d05affccfbd2ede71ed4a61044eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c4ROlohhaWMhp62tvXslBQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">标记器—按作者分类的图像</p></figure><h2 id="972e" class="mv kx iq bd ky nb nc dn lc nd ne dp lg lx nf ng li mb nh ni lk mf nj nk lm nl bi translated">分类者</h2><p id="37ad" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们使用变压器网络作为分类器:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/9b3e8726f4fc5381548bc78d47a45f78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7ExydVQu24lNxkGr5On_9g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">变压器网络—图片由作者提供</p></figure><p id="07c7" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">通过使用torch.nn.TransformerEncoderlayer和torch . nn . transformer encoder类，实现变得很容易。</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="e226" class="mv kx iq mr b gy mw mx l my mz"><br/>class TextBinaryClassifier(pl.LightningModule):<br/>    def __init__(<br/>        self,<br/>        vocab_size,<br/>        channels=256,<br/>        dropout=0.4,<br/>        lr=1e-4,<br/>    ):<br/>        super().__init__()<br/><br/>        self.lr = lr<br/>        self.dropout = dropout<br/>        self.vocab_size = vocab_size<br/><br/>        self.embeddings = torch.nn.Embedding(self.vocab_size, embedding_dim=channels)<br/><br/>        self.pos_embedding = torch.nn.Embedding(1024, embedding_dim=channels)<br/><br/>        encoder_layer = nn.TransformerEncoderLayer(<br/>            d_model=channels, nhead=4, dropout=self.dropout, dim_feedforward=1024<br/>        )<br/><br/>        self.encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers=8)<br/><br/>        self.linear = Linear(channels, 1)<br/><br/>        self.do = nn.Dropout(p=self.dropout)<br/><br/>        self.loss = torch.nn.BCEWithLogitsLoss()<br/><br/>    def forward(self, x):<br/>        batch_size, sequence_len = x.size(0), x.size(1)<br/><br/>        embedded = self.embeddings(x)<br/><br/>        pos_x = (<br/>            torch.arange(0, sequence_len, device=x.device)<br/>            .unsqueeze(0)<br/>            .repeat(batch_size, 1)<br/>        )<br/><br/>        pos_x = self.pos_embedding(pos_x)<br/><br/>        embedded += pos_x<br/><br/>        embedded = self.do(embedded)<br/><br/>        embedded = embedded.permute(1, 0, 2)<br/><br/>        transformed = self.encoder(embedded)<br/><br/>        transformed = transformed.permute(1, 0, 2)<br/><br/>        out = self.linear(transformed[:, 0])<br/><br/>        return out</span></pre><h1 id="7dbd" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">预言者</h1><h2 id="3209" class="mv kx iq bd ky nb nc dn lc nd ne dp lg lx nf ng li mb nh ni lk mf nj nk lm nl bi translated"><strong class="ak">火炬至onnx </strong></h2><p id="f29b" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">出于实际原因，我们将模型从torch转换。ckpt格式到. onnx. <br/>我们还使用onnxruntime库在我们的预测中使用这个模型。</p><p id="40d9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">为此，我们运行:</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="8736" class="mv kx iq mr b gy mw mx l my mz">torch.onnx.export(<br/>    model,  # model being run<br/>    ids,  # model input (or a tuple for multiple inputs)<br/>    filepath,  # where to save the model (can be a file or file-like object)<br/>    export_params=True,  # store the trained parameter weights inside the model file<br/>    opset_version=10,  # the ONNX version to export the model to<br/>    do_constant_folding=True,  # whether to execute constant folding for optimization<br/>    input_names=["input"],  # the model's input names<br/>    output_names=["output"],  # the model's output names<br/>    dynamic_axes={<br/>        "input": {0: "batch_size", 1: "sequence_len"},  # variable length axes<br/>        "output": {0: "batch_size"},<br/>    },<br/>)</span></pre><p id="2d2b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">执行此过程可以将模型的大小减少66%，并将CPU上的预测速度提高68%(从2.63毫秒到0.85毫秒，以生成一个小句的预测)。</p><h2 id="4d80" class="mv kx iq bd ky nb nc dn lc nd ne dp lg lx nf ng li mb nh ni lk mf nj nk lm nl bi translated">预测服务器</h2><p id="0c53" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们使用一个带有RabbitMQ和pika的排队系统来处理来自机器人的预测查询。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/9fe751a649a5173e0cb00f256adce2aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A9j6OC7XiFY9pazp2i3yVw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">预测架构—作者图片</p></figure><p id="7f07" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这种架构允许将机器人逻辑与机器学习/NLP逻辑隔离开来，并且如果需要的话，可以更容易地横向扩展到多个预测器。</p><p id="35c8" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">您可以使用我的存储库中的docker-compose文件来运行整个架构:</p><p id="f892" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">首先，按照本教程获取您的bot令牌:</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="685d" class="mv kx iq mr b gy mw mx l my mz"><a class="ae kv" href="https://www.freecodecamp.org/news/create-a-discord-bot-with-python/" rel="noopener ugc nofollow" target="_blank">https://www.freecodecamp.org/news/create-a-discord-bot-with-python/</a></span></pre><p id="3beb" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">然后，下载模型和标记器:</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="58db" class="mv kx iq mr b gy mw mx l my mz">wget https://github.com/CVxTz/bleach_bot/releases/download/v1/toxicity_model.onnx -P ./data/</span><span id="f6f1" class="mv kx iq mr b gy np mx l my mz">wget https://github.com/CVxTz/bleach_bot/releases/download/v1/tokenizer.json -P ./data/</span></pre><p id="72cc" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">最后，运行docker-compose</p><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="d81e" class="mv kx iq mr b gy mw mx l my mz">docker-compose up --build</span></pre><h1 id="ddc8" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">机器人演示</h1><p id="04a4" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">该机器人删除分类模型给出的分数大于0.8的所有邮件。</p><p id="3634" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">接下来是演示。我使用docker-compose在我的机器上运行这个机器人。我们可以看到，机器人删除了所有令人讨厌的负面消息，保留了常规消息。不要眨眼，因为它真的很快😉</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/8261f5296c652624acb008f1978e4b25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*niVCXXY9C7OUG5KvDATKYA.gif"/></div></div></figure><h1 id="bbf9" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><p id="a3e4" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">这个项目详细介绍了使用深度学习构建一个仲裁机器人所需的第一步。该机器人经过训练，可以检测有毒或侮辱性信息，并自动删除它们。下一步将是进一步改进机器人的机器学习部分，以减少误报的数量，并致力于其部署。</p><h2 id="6d76" class="mv kx iq bd ky nb nc dn lc nd ne dp lg lx nf ng li mb nh ni lk mf nj nk lm nl bi translated">来源</h2><pre class="kg kh ki kj gt mq mr ms mt aw mu bi"><span id="5c94" class="mv kx iq mr b gy mw mx l my mz">[1] <a class="ae kv" href="https://www.freecodecamp.org/news/create-a-discord-bot-with-python/" rel="noopener ugc nofollow" target="_blank">https://www.freecodecamp.org/news/create-a-discord-bot-with-python/</a></span></pre><p id="8766" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">密码</p><p id="c0ee" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><a class="ae kv" href="https://github.com/CVxTz/bleach_bot" rel="noopener ugc nofollow" target="_blank">https://github.com/CVxTz/bleach_bot</a></p></div></div>    
</body>
</html>