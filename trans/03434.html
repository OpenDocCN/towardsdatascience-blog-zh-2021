<html>
<head>
<title>Universal Adversarial Perturbations Could be a Threat to Autonomous Vehicles</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">普遍的对抗性扰动可能会对自动驾驶汽车构成威胁</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/universal-adversarial-perturbations-could-be-a-threat-to-autonomous-vehicles-742e3e52f9a?source=collection_archive---------36-----------------------#2021-03-18">https://towardsdatascience.com/universal-adversarial-perturbations-could-be-a-threat-to-autonomous-vehicles-742e3e52f9a?source=collection_archive---------36-----------------------#2021-03-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="32da" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/ai-alignment-and-safety" rel="noopener" target="_blank">人工智能校准和安全</a></h2><div class=""/><div class=""><h2 id="23fc" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">论文综述:<em class="ko">自主车辆物体类别检测对普遍敌对干扰的弹性</em></h2></div><p id="f96f" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">在这篇文章中，我将讨论我作为合著者撰写我的第一篇同行评审出版物的旅程:<em class="ll">自主车辆物体类别检测对普遍敌对扰动的弹性</em> <strong class="kr ja"> <em class="ll">，</em> </strong>最近被授予<em class="ll"/>2021<strong class="kr ja">IEEE iem tronics(国际IOT，电子和机电一体化会议)最佳口头陈述。</strong></p><p id="0188" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">自动驾驶汽车这些天越来越受关注。为了让自动驾驶车辆识别人、交通灯和其他车辆以做出关键任务决策，<strong class="kr ja">物体检测</strong>是自动驾驶系统中的关键任务之一。然而，众所周知，基于深度学习的算法容易受到被称为<strong class="kr ja">对抗性干扰</strong>的精心制作的噪音的影响。</p><p id="9a6c" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">因此，我们必须评估我们在自动驾驶汽车中使用的物体检测算法是否对这些扰动具有鲁棒性，以确保它可以安全地部署在现实世界中。如果不这样做，可能会发生严重的后果，例如，检测到街道上的停车标志，因为不同的物体会使汽车忽略该标志，并撞上另一辆汽车或人。</p><p id="7212" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">当我意识到这个问题的动机时，我搜索了关于对抗目标检测攻击的著作，一篇关于<em class="ll">“对抗目标检测的普遍对抗扰动”</em><em class="ll">【1】</em>的论文引起了我的注意。这是第一个从经验上证明物体探测任务中普遍对抗性干扰存在的工作。我想到，对手也可以利用这种针对自动驾驶汽车的对抗性攻击。</p><blockquote class="lm"><p id="9c76" class="ln lo iq bd lp lq lr ls lt lu lv lk dk translated">为什么目前对对抗性鲁棒性的研究相当普遍，而不涉及自动驾驶汽车等任务关键型应用？难道我们不应该在应用程序级别研究对抗性攻击和防御吗？</p></blockquote><p id="b81e" class="pw-post-body-paragraph kp kq iq kr b ks lw ka ku kv lx kd kx ky ly la lb lc lz le lf lg ma li lj lk ij bi translated">这个问题让我和我的顾问专注于一个流行的数据集COCO2017中与自动驾驶汽车相关的最重要的类别。在研究领域，理解敌对扰动对与自动驾驶汽车相关的特定类别的影响似乎探索得较少。虽然[1]已经探索了针对对象检测的对抗性攻击，但不是在自动驾驶汽车的背景下。</p><p id="7f79" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">这种差异导致我制定了三个研究问题<strong class="kr ja"> <em class="ll"> : </em> </strong></p><ul class=""><li id="6d4d" class="mb mc iq kr b ks kt kv kw ky md lc me lg mf lk mg mh mi mj bi translated">与[1]中使用的PASCAL VOC相比，这种普遍扰动的存在会扩展到更大的真实世界背景数据集COCO吗？</li><li id="b908" class="mb mc iq kr b ks mk kv ml ky mm lc mn lg mo lk mg mh mi mj bi translated">我们是否完全将普遍扰动的影响从其他因素中分离出来，例如包括没有扰动就已经被错误分类的图像？</li><li id="5789" class="mb mc iq kr b ks mk kv ml ky mm lc mn lg mo lk mg mh mi mj bi translated">通用扰动对COCO子集(仅包括与自动驾驶相关的类别)的影响有多大？</li></ul><h1 id="1da7" class="mp mq iq bd mr ms mt mu mv mw mx my mz kf na kg nb ki nc kj nd kl ne km nf ng bi translated">介绍</h1><p id="54d0" class="pw-post-body-paragraph kp kq iq kr b ks nh ka ku kv ni kd kx ky nj la lb lc nk le lf lg nl li lj lk ij bi translated">本文介绍了与<strong class="kr ja">自主车辆相关的五个类别中普遍扰动对物体检测的影响:人、停车标志、汽车、卡车和交通灯</strong>。我们从经验上证明，对包含这些类别的图像训练集计算普遍扰动并将那些发现的扰动添加到那些图像中会使对象检测器在大多数图像上检测不到那些类别。</p><p id="5637" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">论文的主要贡献包括:</p><ul class=""><li id="4a15" class="mb mc iq kr b ks kt kv kw ky md lc me lg mf lk mg mh mi mj bi translated">在目标探测中建立类别级的脆弱性等级以对抗普遍的敌对扰动</li><li id="e43b" class="mb mc iq kr b ks mk kv ml ky mm lc mn lg mo lk mg mh mi mj bi translated">通过管理数据集以仅包括其中检测器正确预测了至少一个指定类别的那些图像，完全隔离对抗扰动对检测结果的影响</li></ul><h1 id="34cb" class="mp mq iq bd mr ms mt mu mv mw mx my mz kf na kg nb ki nc kj nd kl ne km nf ng bi translated">数据集管理</h1><p id="ae8a" class="pw-post-body-paragraph kp kq iq kr b ks nh ka ku kv ni kd kx ky nj la lb lc nk le lf lg nl li lj lk ij bi translated">[1]使用PASCAL VOC作为他们实验的主要数据集，这是一个规模相对较小的对象检测数据集，更重要的是，它没有捕捉到真实视觉世界的复杂性。我们在这个实验中使用了<strong class="kr ja"> COCO2017 </strong>训练集，因为它是用于具有更真实上下文环境的对象检测的事实上的标准大规模数据集。</p><p id="a5fe" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">此外，我们声称，我们需要对目前用于对抗性攻击实验的数据集进行更精细的管理。策展分两个方向进行:<strong class="kr ja"> (1)班级</strong><strong class="kr ja">(2)影像。</strong></p><h2 id="40b0" class="nm mq iq bd mr nn no dn mv np nq dp mz ky nr ns nb lc nt nu nd lg nv nw nf iw bi translated">班级</h2><p id="f1f1" class="pw-post-body-paragraph kp kq iq kr b ks nh ka ku kv ni kd kx ky nj la lb lc nk le lf lg nl li lj lk ij bi translated">从自动驾驶的背景来看，我们不需要数据集中的所有80个类。这可能会妨碍评估普遍扰动的影响，特别是在自动驾驶汽车最常遇到的街道环境中。因此，我们只使用我们的数据集的一个子集，只策展我们感兴趣的图像类别。</p><blockquote class="nx ny nz"><p id="df34" class="kp kq ll kr b ks kt ka ku kv kw kd kx oa kz la lb ob ld le lf oc lh li lj lk ij bi translated">为了对自动驾驶汽车最相关的类进行实验，我们选择了<strong class="kr ja"> 5个类(人、汽车、卡车、交通灯、停车标志)。</strong>我们可以使用<strong class="kr ja"> COCO API轻松搜索我们感兴趣的特定类别的图像。</strong></p></blockquote><h2 id="655c" class="nm mq iq bd mr nn no dn mv np nq dp mz ky nr ns nb lc nt nu nd lg nv nw nf iw bi translated">形象</h2><p id="d23c" class="pw-post-body-paragraph kp kq iq kr b ks nh ka ku kv ni kd kx ky nj la lb lc nk le lf lg nl li lj lk ij bi translated">为了完全隔离敌对扰动对检测性能的影响，我们过滤了特定于类的数据集，以仅包括其中检测器正确预测了至少一个目标类的图像。我们这次实验的主要对象检测模型是来自<a class="ae od" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank"> <strong class="kr ja"> Detectron2 </strong> </a>库的<strong class="kr ja">更快RCNN /特征金字塔网络(FPN) / Resnet50基网络</strong>(在COCO2017训练集上预训练)。</p><p id="c2ca" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">为了滤除图像，我们使用了更快的RCNN对阈值为0.5 IoU的图像进行检测。只要对象检测器能够检测到我们的对象类别的至少一个实例，我们就会将该图像保留在我们的数据集中。如果检测器错过了图像中的所有对象实例，则该图像将不再被使用，因为该图像不需要被攻击，因为它已经发生故障。</p><p id="663c" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">由于时间和资源有限，我们精选了特定于类别的数据集，包括500幅人物、汽车和卡车图像、344个交通灯和313个停车标志。特定于类的数据集意味着所有图像至少有一个该目标类的实例，因此这些数据集之间可能有重叠，因为许多图像可能有多个我们选择的类。现在，我们准备计算每个特定于类的数据集的通用扰动。</p><h1 id="97fc" class="mp mq iq bd mr ms mt mu mv mw mx my mz kf na kg nb ki nc kj nd kl ne km nf ng bi translated">针对目标检测的通用对抗性扰动</h1><p id="4fb6" class="pw-post-body-paragraph kp kq iq kr b ks nh ka ku kv ni kd kx ky nj la lb lc nk le lf lg nl li lj lk ij bi translated"><strong class="kr ja">通用对抗性扰动</strong> [2]的想法很有趣，因为与需要为每个图像创建的图像特定扰动相反，图像不可知扰动在某种意义上更危险，因为一旦你发现了一个可以很好地推广到不同数据集、图像和模型的扰动，它就可以广泛地用于攻击各种对象检测系统。</p><p id="09b4" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">我们建立在由[1]提出的方法上，因为他们第一次证明了在物体探测任务中普遍扰动的存在。[1]引入了<strong class="kr ja"> <em class="ll">通用密集对象抑制(U-DOS) </em> </strong>算法来计算通用扰动，该算法将使对象检测器看不见，以在图像集I的大多数图像中找到对象，同时保持人眼不可察觉。如果你看完这个帖子还不清楚这个算法，请阅读[1]。</p><figure class="of og oh oi gt oj gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi oe"><img src="../Images/a088c46c6d54d73a0997ea97c2f2feef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q9yxKKzFu8pjdsWqFpA7jQ.png"/></div></div><p class="oq or gj gh gi os ot bd b be z dk translated">图一。U-DOS算法[1]。</p></figure><p id="544c" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">给定对象检测器D、图像集I、扰动的最大inf_norm约束和历元数，UDOS计算并返回通用扰动<em class="ll"> v </em>。</p><p id="959b" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">对于每个时期，它在图像集I中的每个图像上迭代，以首先检查将当前通用扰动添加到该特定图像是否导致遮蔽检测器。如果是，跳到下一张图片。否则，通过优化目标函数(2)来计算v_i(与我们修改的原始算法1略有不同)。v_i是攻击第I个图像并将其添加到我们的通用扰动v的扰动。在更新之后，它总是验证更新的扰动的inf范数被约束在Xi内，该超参数是我们设置的以确保人类的准感知性。</p><figure class="of og oh oi gt oj gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi ou"><img src="../Images/677d624ea2b18ff3ca3d40f8834a305f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cs4BgYMDCqMrtB8jWZ8BrA.png"/></div></div><p class="oq or gj gh gi os ot bd b be z dk translated">图二。U-DOS算法的原始目标函数[1]。</p></figure><p id="1e00" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">我们对[1]提出的算法1中的目标函数(第6行)进行了如下修改:</p><p id="5144" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">1.目标函数中的第一项:取决于对象检测器及其实现，从检测器的输出中访问背景类概率可能是棘手的，因此我们移除了背景类项，并且仅关心对象类的输出的总和。修正后的F(I_i，v，v_i)如下:</p><figure class="of og oh oi gt oj gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi ov"><img src="../Images/6b2c720609573bccd9b35845c90c3c7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5wPCZvbS3BUdDLAo5Cni4Q.png"/></div></div><p class="oq or gj gh gi os ot bd b be z dk translated">图3。U-DOS算法目标函数中第一项的修正。[1]</p></figure><p id="2f35" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">2.等式中的第二项:曾经是||的L-inf范数。||，所以在运行一些时期后，它停留在最大约束(Xi)，因此比较超过某个时期的扰动幅度是没有意义的。因此，我们使用<strong class="kr ja">平均L1范数</strong>——L1范数除以像素数来比较扰动范数如何平均增加。</p><p id="ef5b" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">基于这些变化，我们希望最小化第I个扰动图像上的扰动范数和目标检测概率:I_i + v + v_i (I_i:原始图像，v:通用扰动，v_i:第I个图像的附加扰动)。需要最小化的函数如下:</p><figure class="of og oh oi gt oj gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi ow"><img src="../Images/f02d859d02c22373eeb0a4a403b661d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ctkWff2-hLYXb4hhJLct1Q.png"/></div></div><p class="oq or gj gh gi os ot bd b be z dk translated">图4。U-DOS算法的改进目标函数。</p></figure><p id="758f" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">为了优化(2)，我们使用<strong class="kr ja">梯度下降</strong>来为每个第I个图像找到v_i。α是我们乘以目标函数相对于v_i的梯度的步长，v _ I是我们为了更新普适扰动而添加的扰动。</p><figure class="of og oh oi gt oj gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi ox"><img src="../Images/763b32339f92761d2833130dc8744d2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pXNXkLv0sAwIrjgCRTehTg.png"/></div></div><p class="oq or gj gh gi os ot bd b be z dk translated">图5。梯度下降以更新增加的扰动。[1]</p></figure><p id="4935" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">这种攻击非常简单，因为我们使用其输出相对于输入扰动的梯度，这意味着我们可以攻击图像中任意数量的类。</p><h1 id="13a0" class="mp mq iq bd mr ms mt mu mv mw mx my mz kf na kg nb ki nc kj nd kl ne km nf ng bi translated">实验和结果</h1><h2 id="a5cb" class="nm mq iq bd mr nn no dn mv np nq dp mz ky nr ns nb lc nt nu nd lg nv nw nf iw bi translated">超参数</h2><p id="bd2d" class="pw-post-body-paragraph kp kq iq kr b ks nh ka ku kv ni kd kx ky nj la lb lc nk le lf lg nl li lj lk ij bi translated">对于这个实验，我们需要调整四个主要的超参数:</p><ul class=""><li id="3d98" class="mb mc iq kr b ks kt kv kw ky md lc me lg mf lk mg mh mi mj bi translated">n_epochs:时期的数量</li><li id="27a6" class="mb mc iq kr b ks mk kv ml ky mm lc mn lg mo lk mg mh mi mj bi translated">阿尔法:学习率</li><li id="1932" class="mb mc iq kr b ks mk kv ml ky mm lc mn lg mo lk mg mh mi mj bi translated">xi:扰动的最大范数约束</li><li id="4712" class="mb mc iq kr b ks mk kv ml ky mm lc mn lg mo lk mg mh mi mj bi translated">score_threshold:对象检测器将其视为最终预测</li></ul><p id="e23f" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">在一系列试点实验之后，我们确定了以下参数值:n_epoch=250，Xi=10，α= 20，score_threshold=0.7。</p><h2 id="9d11" class="nm mq iq bd mr nn no dn mv np nq dp mz ky nr ns nb lc nt nu nd lg nv nw nf iw bi translated">韵律学</h2><p id="2c7b" class="pw-post-body-paragraph kp kq iq kr b ks nh ka ku kv ni kd kx ky nj la lb lc nk le lf lg nl li lj lk ij bi translated">在我们的实验中，我们评估了通用扰动对数据集的影响，因为我们通过迭代使用两个指标找到了更强的扰动:<strong class="kr ja">实例级</strong>和<strong class="kr ja">图像级</strong>盲度。我们为每个类别运行实验，以在类别级别比较易受干扰的程度。</p><p id="17df" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated"><strong class="kr ja">图像级盲度:</strong>物体检测器D能够以高于阈值的置信度找到至少一个物体的图像与图像总数N. (4)的比率</p><blockquote class="lm"><p id="322a" class="ln lo iq bd lp lq lr ls lt lu lv lk dk translated">这里要提到的重要一点是，在策展过程中，我们需要确保在添加通用扰动之前，数据集的图像级盲度始终为1.0。这是因为我们应该只包括至少有一个物体的置信度高于阈值的图像。</p></blockquote><figure class="oz pa pb pc pd oj gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi oy"><img src="../Images/7697e31557ca9a00e400dc9af2054747.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0hAO7yJWuLZQcOboBUmwEA.png"/></div></div><p class="oq or gj gh gi os ot bd b be z dk translated">图6。图像级盲度度量[1]。</p></figure><p id="2680" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated"><strong class="kr ja">实例级盲度:</strong>检测器D在每幅图像中找到的置信度超过给定阈值的平均实例数。此度量显示在实例级别有把握地检测到多少目标类的对象。(5)</p><figure class="of og oh oi gt oj gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi pe"><img src="../Images/f9832098fdd3aa717f4be29423092798.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wQT320MwMG4CZrZQikHP0g.png"/></div></div><p class="oq or gj gh gi os ot bd b be z dk translated">图7。实例级盲度度量[1]。</p></figure><h2 id="2fef" class="nm mq iq bd mr nn no dn mv np nq dp mz ky nr ns nb lc nt nu nd lg nv nw nf iw bi translated">结果</h2><p id="dfc7" class="pw-post-body-paragraph kp kq iq kr b ks nh ka ku kv ni kd kx ky nj la lb lc nk le lf lg nl li lj lk ij bi translated">下面的第一张图显示了随着标准的增加，扰动对每个类别的影响。为了绘制这个图，我们跟踪实例级和图像级的盲度，因为我们为五个类别中的每一个改变扰动范数。在进行了一系列的实验后，我们发现所有5个类别的图像和实例级盲度随着我们发现具有更强范数的普遍扰动而降低。很明显<strong class="kr ja">人</strong>在图像级和实例级失明程度中是最有弹性的类别，其次是<strong class="kr ja">汽车、交通灯、卡车</strong>和<strong class="kr ja">停车标志</strong>增加了干扰标准。进一步调查和分析为什么某些类别更能抵御这种攻击将是一个有趣的方向。</p><figure class="of og oh oi gt oj gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi pf"><img src="../Images/7ca580109d2c1d8491ed8776ef319709.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NjcA55l1njk19Gm_sRgQxg.png"/></div></div><p class="oq or gj gh gi os ot bd b be z dk translated">图8。图像级盲度与5个类别上的扰动范数[3]。</p></figure><figure class="of og oh oi gt oj gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi pf"><img src="../Images/6c4585cf0067b172f1215ce018f14183.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gxhZtaysyKEgc_D7zVavOQ.png"/></div></div><p class="oq or gj gh gi os ot bd b be z dk translated">图9。实例级盲度与5个类别上的扰动范数[3]。</p></figure><p id="0fa7" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">基于我们上面的实验结果，我们已经在图像和实例级盲度中建立了一个<strong class="kr ja">类别排名</strong>，随着时期和规范的增加，对每个类别对普遍扰动的弹性进行排名。随着扰动范数和迭代次数(历元)的增加，我们通过比较图像和实例级盲度的下降率来设置排序。因为这两个指标密切相关，所以这两个指标的排名遵循相似的模式是有意义的。</p><figure class="of og oh oi gt oj gh gi paragraph-image"><div role="button" tabindex="0" class="ok ol di om bf on"><div class="gh gi pg"><img src="../Images/49f5e8d7c0c99c60b1b1a98441172d4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G3C-lV5BUqqajf30R1pElA.png"/></div></div><p class="oq or gj gh gi os ot bd b be z dk translated">表1。对普遍扰动的复原力的分类等级。从最高到最低[3]。</p></figure><p id="b37a" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">为了形象化，我挑选了一些样本图像，它们清楚地表明，添加在数据集上计算的发现的通用扰动成功地使Faster-RCNN在检测我们指定攻击的目标类时失败。前两幅图像显示，在将计算出的攻击停车标志的扰动添加到图像后，原始图像中的<em class="ll"> 2个停车标志检测</em>消失。接下来的两幅图像显示，在添加计算出的扰动以攻击交通灯后，原始图像中的<em class="ll"> 4个交通灯检测</em>被移除。除此之外，有趣的是，添加扰动也会影响对非目标类别的检测，例如汽车。</p><figure class="of og oh oi gt oj gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/ce1b6a93d3b6047add175a875829081a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*Z50HKGkvOtNV06fQb10HBg.png"/></div><p class="oq or gj gh gi os ot bd b be z dk translated">图10。停止对原始图像[3]的标志检测。</p></figure><figure class="of og oh oi gt oj gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/436d7244754283eb445ec87255131390.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*6_3ibXWc9IZT8M0RqWNSyA.png"/></div><p class="oq or gj gh gi os ot bd b be z dk translated">图11。在受干扰的图像[3]上检测停车标志失败。</p></figure><figure class="of og oh oi gt oj gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/6e58781ecd16ed882b7f769c448b48f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*mjT382j6bBH7oR7LcSOS-A.png"/></div><p class="oq or gj gh gi os ot bd b be z dk translated">图12。对原始图像进行交通灯检测[3]。</p></figure><figure class="of og oh oi gt oj gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/60dd584c34c30917360c877d8f977ca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*JZvd0GVfVyLw2LUZ-p3How.png"/></div><p class="oq or gj gh gi os ot bd b be z dk translated">图13。扰动图像上的交通灯检测失败[3]。</p></figure><h1 id="ac4c" class="mp mq iq bd mr ms mt mu mv mw mx my mz kf na kg nb ki nc kj nd kl ne km nf ng bi translated">结论</h1><p id="27e8" class="pw-post-body-paragraph kp kq iq kr b ks nh ka ku kv ni kd kx ky nj la lb lc nk le lf lg nl li lj lk ij bi translated">从使用不同的精选数据集评估原始工作的有效性开始，我了解到准可感知的普遍扰动会对与自动驾驶相关的数据集安全的核心造成真正的伤害。此外，发现哪一类特别容易受到普遍扰动的影响，将对我们应该如何设计自动驾驶系统产生重要影响，以优先考虑我们应该重点防御的类别，而不仅仅是建立一个防御系统来抵御整体的敌对攻击。</p><p id="3e33" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">完成这个实验后，我意识到我可以直接在大规模的驾驶特定数据集上进行实验，例如，Waymo或Berkeley DeepDrive，以研究自动驾驶汽车领域的对抗性攻击的影响。</p><p id="bf3b" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">我们未来的工作将是对这些数据集进行不同的对抗性攻击实验，以研究更多攻击状态的影响，或开发针对自动驾驶汽车的新型攻击，并提出可以提高自动驾驶系统鲁棒性的防御措施。</p><p id="d532" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">如果有人想使用这个，请引用我们的论文并指出引用，我已经分享了我的<a class="ae od" href="https://github.com/seungwonoh5/Universal_Autonomous_Detection" rel="noopener ugc nofollow" target="_blank">代码库</a>。如有任何问题，请随时联系nayeem@umd.edu或aspiringtechsavvy@gmail.com。任何建设性的批评或反馈都会受到欢迎。感谢阅读。</p><h1 id="2829" class="mp mq iq bd mr ms mt mu mv mw mx my mz kf na kg nb ki nc kj nd kl ne km nf ng bi translated">参考</h1><p id="d8da" class="pw-post-body-paragraph kp kq iq kr b ks nh ka ku kv ni kd kx ky nj la lb lc nk le lf lg nl li lj lk ij bi translated">[1]李，张俊杰，黄，王(2020).针对目标探测的通用对抗性扰动。<em class="ll">模式识别</em>，<em class="ll"> 110 </em>，107584。</p><p id="03be" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">[2] Moosavi-Dezfooli，S. M .，Fawzi，a .，Fawzi，o .，&amp; Frossard，P. (2017年)。普遍的对抗性干扰。IEEE计算机视觉和模式识别会议论文集(第1765-1773页)。</p><p id="b9fe" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">[3] Mohammad Nayeem Teli和Seungwon Oh。“自主车辆物体类别检测对普遍扰动的弹性”，被认可出现在IEEE国际IOT、电子学和机械电子学(IEMTRONICS '21)中。</p></div></div>    
</body>
</html>