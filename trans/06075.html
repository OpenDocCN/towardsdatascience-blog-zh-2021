<html>
<head>
<title>A Quick Guide to AUC-ROC in Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习模型中AUC-ROC的快速指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-quick-guide-to-auc-roc-in-machine-learning-models-f0aedb78fbad?source=collection_archive---------27-----------------------#2021-05-31">https://towardsdatascience.com/a-quick-guide-to-auc-roc-in-machine-learning-models-f0aedb78fbad?source=collection_archive---------27-----------------------#2021-05-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="929a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">比较分类模型有效性的简单且健壮的方法不应该由于太多不同的定义而变得复杂。</h2></div><p id="38e6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">机器学习最常见的应用之一是将实体分为两个不同的、不重叠的类别。这些年来，人们已经设计出了几种方法，从非常简单的<a class="ae le" href="https://en.wikipedia.org/wiki/Linear_classifier" rel="noopener ugc nofollow" target="_blank">到更加复杂的</a><a class="ae le" href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html" rel="noopener ugc nofollow" target="_blank">到近乎于</a><a class="ae le" href="http://scikit-learn.org/stable/modules/neural_networks_supervised.html" rel="noopener ugc nofollow" target="_blank">的黑箱</a>。在处理几乎任何类型的模型时，一个常见的问题是如何比较不同方法的性能，或者不同的参数调整。幸运的是，在二元分类器的情况下，有一个简单的度量抓住了问题的本质:它是<a class="ae le" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener ugc nofollow" target="_blank">接收器操作特性</a>的曲线(<em class="lf">即</em>积分)下的面积，因此缩写为AUC-ROC或简称为ROC。</p><h2 id="1abf" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">处理你的错误</h2><p id="48a5" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">为了便于讨论，假设一个<em class="lf"> tiger vs cat </em>二元分类器将实体识别为属于<strong class="kk iu">真阳性</strong> ( <em class="lf"> tiger </em>，<em class="lf">接受</em>)或<strong class="kk iu">真阴性</strong> ( <em class="lf"> cat </em>，<em class="lf">拒绝</em>)情况。分类器给每个实体分配一个0到1之间的数字，如果该数字大于给定的阈值(比如0.5)，则该实体被接受，否则被拒绝。没有一个分类器是完美的，这意味着不到100%的情况会被正确识别。大多数情况下，它会因为许多原因而误识别事物，特别是小的训练数据集大小和模型的内在限制。很多情况下，我们也在努力拒绝某种形式的“背景噪音”(这里:<em class="lf">猫</em>)。</p><p id="8d52" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">传统上，分类错误分为两类，我在下文中将其称为<strong class="kk iu">假阴性</strong> ( <em class="lf">即</em>老虎被分类为<em class="lf">猫</em>)和<strong class="kk iu">假阳性</strong> ( <em class="lf">即</em>猫被识别为<em class="lf">老虎</em>)。不言而喻，将猫识别为老虎远没有将老虎识别为猫危险:这两种类型的错误通常不会被同等对待，并且根据问题的不同，分类器的参数被优化以最小化任何一种类型。</p><h2 id="5415" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">ROC曲线</h2><p id="c681" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">说了这么多，我们想找到一种简洁的方法来总结分类器的性能。直观地，人们很容易认识到，给定的模型位于参数空间中的一个折衷点，平衡了真阳性(TP)、假阳性(FP)、假阴性(FN)和真阴性(TN)的数量。一旦模型被训练，我们被允许改变的唯一参数是输出概率的阈值。因此，我们从0到1扫描这个数字，看看性能如何相应地变化。然而，4D参数空间几乎是直观的！然而，事实证明这些数字中只有四分之二实际上是独立的，所以更容易将它们组合成其他东西来使用。长话短说，这是一个可能的组合:</p><p id="630e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">真阳性率(TPR) </strong> = TP / (TP + FN) =识别信号的效率(εₛ)(也称<strong class="kk iu">回忆</strong>或<strong class="kk iu">灵敏度</strong> ) <br/> <strong class="kk iu">假阳性率(FPR) </strong> = FP / (FP + TN) =低效率(ε_B)拒绝背景</p><p id="b386" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ROC曲线无非是TPR对FPR，作为产出概率的函数来扫描。通常，它看起来有点像这样:</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi me"><img src="../Images/e772f96aed897be4b7e34c944bceae20.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*KknhpKOdxtVFYugHt5obig.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">典型的<a class="ae le" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener ugc nofollow" target="_blank">接收器工作特性</a> (ROC)曲线示例。图片作者。</p></figure><p id="6a95" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另类组合怎么样？当然，如果你看一看<a class="ae le" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener ugc nofollow" target="_blank">维基百科页面</a>，你会发现关于<a class="ae le" href="https://en.wikipedia.org/wiki/Sensitivity_(test)" rel="noopener ugc nofollow" target="_blank">敏感度</a>、<a class="ae le" href="https://en.wikipedia.org/wiki/Precision_and_recall#Recall" rel="noopener ugc nofollow" target="_blank">召回率</a>、<a class="ae le" href="https://en.wikipedia.org/wiki/Hit_rate" rel="noopener ugc nofollow" target="_blank">命中率</a>，或<a class="ae le" href="https://en.wikipedia.org/wiki/Sensitivity_(test)" rel="noopener ugc nofollow" target="_blank">真阳性率</a>、<a class="ae le" href="https://en.wikipedia.org/wiki/Specificity_(tests)" rel="noopener ugc nofollow" target="_blank">特异性</a>、<a class="ae le" href="https://en.wikipedia.org/wiki/Specificity_(tests)" rel="noopener ugc nofollow" target="_blank">选择性</a>或<a class="ae le" href="https://en.wikipedia.org/wiki/Specificity_(tests)" rel="noopener ugc nofollow" target="_blank">真阴性率</a>、<a class="ae le" href="https://en.wikipedia.org/wiki/Information_retrieval#Precision" rel="noopener ugc nofollow" target="_blank">精确度</a>或<a class="ae le" href="https://en.wikipedia.org/wiki/Positive_predictive_value" rel="noopener ugc nofollow" target="_blank">阳性预测值</a>、<a class="ae le" href="https://en.wikipedia.org/wiki/Negative_predictive_value" rel="noopener ugc nofollow" target="_blank">阴性预测值</a> <a class="ae le" href="https://en.wikipedia.org/wiki/False_positive_rate" rel="noopener ugc nofollow" target="_blank">脱落</a>或<a class="ae le" href="https://en.wikipedia.org/wiki/False_positive_rate" rel="noopener ugc nofollow" target="_blank">假阳性率</a>、<a class="ae le" href="https://en.wikipedia.org/wiki/False_discovery_rate" rel="noopener ugc nofollow" target="_blank">假发现率</a>、<a class="ae le" href="https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values" rel="noopener ugc nofollow" target="_blank">假遗漏率</a>、<a class="ae le" href="https://en.wikipedia.org/wiki/Prevalence_threshold" rel="noopener ugc nofollow" target="_blank">流行阈值</a>、威胁分值(TS)或关键成功指数(CSI)、<a class="ae le" href="https://en.wikipedia.org/wiki/Accuracy" rel="noopener ugc nofollow" target="_blank">准确度</a>、平衡准确度、<a class="ae le" href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient" rel="noopener ugc nofollow" target="_blank">马修斯相关系数</a>、<a class="ae le" href="https://en.wikipedia.org/wiki/Fowlkes%E2%80%93Mallows_index" rel="noopener ugc nofollow" target="_blank">福尔克斯-马洛指数</a>、<a class="ae le" href="https://en.wikipedia.org/wiki/Informedness" rel="noopener ugc nofollow" target="_blank">信息量</a>或庄家 所有这些都是为了说明不同的背景可能需要不同的定义，但这些不一定像TPR vs FPR那样直观。</p><h2 id="8f3d" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">解释ROC曲线下的面积</h2><p id="45e9" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">假设我们有两个分类器<em class="lf"> A </em>和<em class="lf"> B </em>。他们的ROC曲线如下图所示。哪个性能更好？</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi me"><img src="../Images/4c06528a37803f1ec715200f8314bbd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*lpOGYe_gYgnv4hrdqMbxDg.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">两种不同模型的比较。图片作者。</p></figure><p id="cd82" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在回答这个之前，我们想做一些考虑。两个分类器都具有在0和1之间的输出，但是通常两个分类器对于相同的TFP或FPR值将具有不同的阈值。因此，我们可能想要一个不依赖于阈值的度量，除非我们设计分类器来最小化FP或FN类型的误差。此外，我们想要一个归一化的数字，<em class="lf">即</em>可以直接在两者之间进行比较。如果我说分类器<em class="lf"> A </em>的分数是122，分类器<em class="lf"> B </em>的分数是72，那就不好说了……但是如果我们知道分数是在0和1之间归一化的，那么直接比较就很容易了。</p><p id="b7d8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">具有这种特性的一个简单函数是——猜猜看？——曲线下的面积，<em class="lf">，即</em>积分。因为FPR和TPR都在0和1之间，所以面积不能小于0，也不能大于1。</p><p id="075a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于一张图片胜过千言万语，下面这张图片展示了如何通过查看AUC-ROC来发现不同分类器的性能:</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/bb5e9f9d34dcb424b055001b853a8c54.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*EPmzi0GCgdLstsJb6Q8e-w.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">如何一眼看出哪个是最好的分类器的总结？图片作者。</p></figure><p id="b537" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在实践中，您可能最终会使用某个预定义库中的函数，比如来自<a class="ae le" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>的函数。该函数需要真实标签，以便将阈值扫描的结果与真实情况进行比较。</p><pre class="mf mg mh mi gt mr ms mt mu aw mv bi"><span id="5734" class="lg lh it ms b gy mw mx l my mz">from sklearn.datasets import load_breast_cancer<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.metrics import roc_auc_score<br/>X, y = load_breast_cancer(return_X_y=True)<br/>clf = LogisticRegression(solver="liblinear", random_state=0).fit(X, y)<br/>roc_auc_score(y, clf.predict_proba(X)[:, 1])<br/>0.99</span></pre><p id="5af9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这也适用于多类吗？的确是这样:只要画出一个类与其他类的对比图。</p><h2 id="bf88" class="lg lh it bd li lj lk dn ll lm ln dp lo kr lp lq lr kv ls lt lu kz lv lw lx ly bi translated">结论</h2><p id="4f9d" class="pw-post-body-paragraph ki kj it kk b kl lz ju kn ko ma jx kq kr mb kt ku kv mc kx ky kz md lb lc ld im bi translated">计算<a class="ae le" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener ugc nofollow" target="_blank">接收器工作特性</a>曲线下的面积是比较不同分类器有效性的最直观的工具。虽然有一些已知的限制，例如，当你想最小化某些类型的错误时，这可能是说服任何人分类器比随机选择答案做得更好的最有效的方法。需要注意的是，比较不同的分类器，特别是属于不同类别的分类器，通常需要更加仔细的思考，例如，训练决策树所需的数据集可能比训练深度神经网络所需的数据集小，但它们在某些特定边缘情况下的效率可能很微妙，仅通过查看单个数字(如AUC-ROC)很难发现。</p></div></div>    
</body>
</html>