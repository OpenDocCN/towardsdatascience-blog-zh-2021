<html>
<head>
<title>A Practical Guide to Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归实用指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-practical-guide-to-linear-regression-3b1cb9e501a6?source=collection_archive---------4-----------------------#2021-09-18">https://towardsdatascience.com/a-practical-guide-to-linear-regression-3b1cb9e501a6?source=collection_archive---------4-----------------------#2021-09-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="572c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">从EDA到特征工程再到模型评估</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/763b34d6b306b6c775ea75f6f31a96e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_xszvgfP2xIQz7krzbJMOA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">线性回归备忘单(作者图片来自<a class="ae ky" href="https://www.visual-design.net/post/a-simple-practical-guide-to-linear-regression" rel="noopener ugc nofollow" target="_blank">原始博客</a></p></figure><p id="f23b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">线性回归是负责数值预测的典型回归算法。它不同于分类模型，如决策树、支持向量机或神经网络。简而言之，线性回归找到自变量和因变量之间的最佳线性关系，然后做出相应的预测。</p><p id="863f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我估计大多数人在数学课上都频繁遇到过函数<strong class="lb iu"> <em class="lv"> y = b0 + b1x </em> </strong>。基本上是简单线性回归的形式，其中<em class="lv"> b0 </em>定义截距<em class="lv"> b1 </em>定义直线的斜率。我将在“模型实现”一节中解释算法背后的更多理论，本文的目的是走向实用！如果您想访问代码，请访问<a class="ae ky" href="https://www.visual-design.net/code" rel="noopener ugc nofollow" target="_blank">我的网站</a>。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="bf58" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">定义目标</h1><p id="4672" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">我在这个练习中使用Kaggle公共数据集“<a class="ae ky" href="https://www.kaggle.com/noordeen/insurance-premium-prediction" rel="noopener ugc nofollow" target="_blank">保险费预测</a>”。数据包括自变量:<em class="lv">年龄、性别、bmi、孩子、吸烟者、</em>地区、目标变量——<em class="lv">费用</em>。首先，让我们加载数据，并使用<em class="lv"> df.info() </em>对数据进行初步检查</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="3238" class="nf me it nb b gy ng nh l ni nj">import pandas as pd<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>from pandas.api.types import is_string_dtype, is_numeric_dtype</span><span id="e387" class="nf me it nb b gy nk nh l ni nj">df = pd.read_csv('../input/insurance-premium-prediction/insurance.csv')<br/>df.info()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/65bf681a7bc2c2064c8ffeba8bed0001.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/0*aQJMHI_FtPdLSRc8.png"/></div></figure><p id="84c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关键要点:</p><ol class=""><li id="8ec3" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu nr ns nt nu bi translated">分类变量:性别、吸烟者、地区</li><li id="27d2" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">数字变量:年龄、体重指数、孩子、费用</li><li id="52fc" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated"><strong class="lb iu">1338条记录中没有缺失数据</strong></li></ol><h1 id="1d09" class="md me it bd mf mg oa mi mj mk ob mm mn jz oc ka mp kc od kd mr kf oe kg mt mu bi translated">探索性数据分析</h1><p id="6ebd" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">EDA对于调查数据质量和揭示变量之间隐藏的相关性是必不可少的。在本练习中，我将介绍与线性回归相关的三种技术。要全面了解EDA，请查看:</p><div class="of og gp gr oh oi"><a rel="noopener follow" target="_blank" href="/semi-automated-exploratory-data-analysis-eda-in-python-7f96042c9809"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd iu gy z fp on fr fs oo fu fw is bi translated">Python中的半自动探索性数据分析(EDA)</h2><div class="op l"><h3 class="bd b gy z fp on fr fs oo fu fw dk translated">一键式全面数据探索流程</h3></div><div class="oq l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">towardsdatascience.com</p></div></div><div class="or l"><div class="os l ot ou ov or ow ks oi"/></div></div></a></div><h2 id="0955" class="nf me it bd mf ox oy dn mj oz pa dp mn li pb pc mp lm pd pe mr lq pf pg mt ph bi translated">1.单变量分析</h2><p id="e218" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">使用直方图显示数值变量，使用条形图显示分类变量的数据分布。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/8518e8349cfeb27fee634e831fab9097.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*tumA7scmZ50mXh4pmQL8rg.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/b99c2e310712b9506b9b54b4b82645a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*f2tJyC9O-Q6P8G_-BSjFRg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">单变量分析(图片由作者提供)</p></figure><p id="ba37" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为什么我们需要单变量分析？</p><ul class=""><li id="1d86" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu pk ns nt nu bi translated">确定数据集是否包含异常值</li><li id="c9a9" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu pk ns nt nu bi translated">确定是否需要数据转换或特征工程</li></ul><p id="eb49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，我们发现“费用”遵循幂律分布，这意味着作为特征工程步骤的一个步骤，需要进行对数变换，以将其转换为正态分布。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/9d66ebf2718b9d9dfa6c4806d431b95b.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/0*LdfGbW-JgvoFlEFe.png"/></div></figure><h2 id="2e41" class="nf me it bd mf ox oy dn mj oz pa dp mn li pb pc mp lm pd pe mr lq pf pg mt ph bi translated">2.多变量分析</h2><p id="92a6" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">当想到线性回归时，我们能想到的第一个可视化技术是散点图。通过使用单行代码<em class="lv"> sns.pairplot(df) </em>绘制目标变量与自变量的关系，潜在的线性关系变得更加明显。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/7dfe5bdd9c3dfc7fea5c19df9b97134c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*wP1Mb1DGj9SWHEQ6nw0g8g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">配对图(图片由作者提供)</p></figure><p id="8780" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，添加分类变量作为图例怎么样？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pn"><img src="../Images/e70d0c8fd61fd76e7146359d958d9651.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*BJNpOeGW2lgP7GtQ.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/42fb5f5f6e3ec37f9776c72479605057.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*yoL27IIax5baaw3p.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">色调=性</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/b9ba810c066f8271a4a7914afe197eb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*6HTCh_XHvxsOr-68.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">色调=区域</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/3324ceb7327eaf3e7ae4226e9b2a99ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*puNX-hJ9atGNMajZ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">色调=吸烟者</p></figure><p id="f328" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从吸烟者与非吸烟者分割的散点图中，我们可以观察到吸烟者(蓝色)的医疗费用明显较高。这表明“吸烟者”这一特征可能是费用的一个强有力的预测因素。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi po"><img src="../Images/de2a3e5252059247f7d62091baafb286.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*00MK-yNGt5CDIfnriH-i-g.png"/></div></figure><h2 id="158b" class="nf me it bd mf ox oy dn mj oz pa dp mn li pb pc mp lm pd pe mr lq pf pg mt ph bi translated">3.相关分析</h2><p id="ffad" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">相关性分析检查变量对之间的线性相关性。这可以通过结合corr()函数和sns.heatmap()来实现。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/13d2d90d9b9375a2653ab8b0e791dc3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*oe_sHwXA8INFF58yZ0i9KQ.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pq"><img src="../Images/e5023ebbe5d549c317d18129ec38db38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2_oK2H7fg4ZAxI-43sik_Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">相关性分析(图片由作者提供)</p></figure><p id="c9a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">注意，这是在分类变量编码之后(如“特征工程”一节)，因此热图中不仅显示数字变量。</em></p><p id="9d30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">为什么我们需要相关性分析？</strong></p><ul class=""><li id="f3d9" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu pk ns nt nu bi translated">识别独立变量之间的共线性-线性回归假设独立要素之间没有共线性，因此如果存在共线性，则必须删除一些要素。在这个例子中，没有一个独立变量与另一个高度相关，因此不需要删除任何变量。</li><li id="e0f0" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu pk ns nt nu bi translated">识别与目标密切相关的独立变量——它们是强有力的预测因素。再一次，我们可以看到“吸烟者”与费用相关。</li></ul><h1 id="a25c" class="md me it bd mf mg oa mi mj mk ob mm mn jz oc ka mp kc od kd mr kf oe kg mt mu bi translated">特征工程</h1><p id="676c" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">EDA带来了一些关于什么类型的特征工程技术适合数据集的见解。</p><h2 id="beda" class="nf me it bd mf ox oy dn mj oz pa dp mn li pb pc mp lm pd pe mr lq pf pg mt ph bi translated">1.对数变换</h2><p id="bfdd" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">我们发现目标变量“费用”是右偏的，服从幂律分布。由于线性回归假设输入和输出变量之间存在线性关系，因此有必要对“费用”变量进行对数变换。如下图，应用<em class="lv"> np.log2() </em>后数据趋于正态分布。除此之外，剧透一下，这个转换确实把线性回归模型得分从0.76提高到了0.78。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/95e4f404ec613cf3def038b3d9378466.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*5u4rXwXV9LuAUvH3Z2hyDA.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/ac808064b1863453b2d743eb1a0de053.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*fhtRu21tmNd036XW5WG73g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">转型前的“费用”</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/ad51326fd5f6b7d177333de57c094276.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*nEtHb3kz1fS0ptMqY-6Vqw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">转型后的“费用”</p></figure><h2 id="fd6c" class="nf me it bd mf ox oy dn mj oz pa dp mn li pb pc mp lm pd pe mr lq pf pg mt ph bi translated">2.编码分类变量</h2><p id="4d7c" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">机器学习算法的另一个要求是将分类变量编码成数字。两种常见的方法是一热编码和标签编码。如果你想了解更多的区别，请查看:“<a class="ae ky" rel="noopener" target="_blank" href="/feature-selection-and-eda-in-python-c6c4eb1058a3?source=your_stories_page-------------------------------------">特征选择和机器学习中的EDA</a>”。</p><p id="e272" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里我比较一下这两者的实现和结果。</p><ul class=""><li id="d551" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu pk ns nt nu bi translated"><strong class="lb iu">一个热编码</strong></li></ul><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="013b" class="nf me it nb b gy ng nh l ni nj">df = pd.get_dummies(df, columns = cat_list)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pu"><img src="../Images/a6ecba0115f121749f6615bcf2c64467.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5OT_AxrwIUxzQ6mgSvL40A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一个热编码结果</p></figure><ul class=""><li id="e020" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu pk ns nt nu bi translated"><strong class="lb iu">标签编码</strong></li></ul><div class="kj kk kl km gt ab cb"><figure class="pv kn pw px py pz qa paragraph-image"><img src="../Images/e91b98100eeb077a0c44ca312e3d5959.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*o6GYUDZKRKzV59Iii3qvxw.png"/></figure><figure class="pv kn qb px py pz qa paragraph-image"><img src="../Images/10f8ac2786fa76a60a4117252263bac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*uGlfUcp_ARUhRQL92I6M-A.png"/><p class="ku kv gj gh gi kw kx bd b be z dk qc di qd qe translated">标签编码</p></figure></div><p id="37ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，这两种方法都导致模型得分为0.78，这表明选择任何一种都不会在这个意义上产生显著差异。</p><h1 id="c339" class="md me it bd mf mg oa mi mj mk ob mm mn jz oc ka mp kc od kd mr kf oe kg mt mu bi translated">模型实现</h1><p id="6fb3" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">简单的线性回归，<em class="lv"> y = b0 + b1x，</em>预测一个自变量x和一个因变量y之间的关系，例如，经典的身高-体重相关性。随着更多特征/独立变量的引入，它演变成多元线性回归y = b0 + b1x1 + b2x2 + … + bnxn，这不能容易地使用二维空间中的线来绘制。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/9e570ff202d4fbb6af0bed84b6381298.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*aPSJLLqM6M418x1-.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">简单线性回归(图片由作者提供)</p></figure><p id="d856" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我从scikit-learn应用了<em class="lv"> LinearRegression() </em>来实现线性回归。我指定了<em class="lv"> normalize = True </em>，这样独立变量将被规范化并转换成相同的标度。scikit-learn线性回归利用<strong class="lb iu">普通最小二乘法</strong>找到拟合数据的最佳直线。因此，由系数b0，b1，b2 … bn定义的线使观测目标和预测值之间的残差平方和最小(图中的蓝线)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qf"><img src="../Images/c9bb3c2e550121d176763eb708b5bda4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uHW6dsi3ZhgirmvF0OFU3g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">线性回归模型(图片作者提供)</p></figure><p id="499e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实现非常简单，并返回一些属性:</p><ul class=""><li id="bea0" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu pk ns nt nu bi translated">model.coef_:系数值— <em class="lv"> b1，b2，b3 … bn </em></li><li id="9dd5" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu pk ns nt nu bi translated">model.intercept_:常量值— <em class="lv"> b0 </em></li><li id="6bca" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu pk ns nt nu bi translated">model.score:有助于评估模型性能的预测的确定性R平方(在模型评估部分有更详细的描述)</li></ul><p id="6fe7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们先用系数值粗略估计一下特征重要性，并可视化。不出所料，吸烟者是医疗费用的主要预测因素。</p><pre class="kj kk kl km gt na nb nc nd aw ne bi"><span id="dc90" class="nf me it nb b gy ng nh l ni nj">sns.barplot(x = X_train.columns, y = coef, palette = "GnBu")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qg"><img src="../Images/644f48f4203a9d917dbddc51e25ac430.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jfY9op4OIZRaen8JHWKkfA.png"/></div></div></figure><p id="9060" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">回想一下，我们已经对目标变量进行了对数转换，因此不要忘记使用<em class="lv"> 2**y_pred </em>来恢复到实际预测费用。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qh"><img src="../Images/356ec126572138999a3d4daa8d2e6c90.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*50xpMGfeUEOsWn9JSj3ylQ.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/3604ee91c2b53a166af593d2cf9fc322.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*GGtzJMEdckEB1O1j.png"/></div></figure><h1 id="b773" class="md me it bd mf mg oa mi mj mk ob mm mn jz oc ka mp kc od kd mr kf oe kg mt mu bi translated">模型评估</h1><p id="e98c" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">线性回归模型可以通过可视化误差分布进行定性评估。也有定量的措施，如平均误差，均方误差，RMSE和R平方。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qi"><img src="../Images/dee59a8e9befdd2ad29862d002627f8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*IW_D0v7erdBFvPDqsfJZQg.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qj"><img src="../Images/5f10f9dd113de181368f1b08ffd08cc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*dbXE6nk0tSzQXpmBQr_6pg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型评估(图片由作者提供)</p></figure><h2 id="f0c5" class="nf me it bd mf ox oy dn mj oz pa dp mn li pb pc mp lm pd pe mr lq pf pg mt ph bi translated">1.误差分布</h2><p id="1eca" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">首先，我使用直方图来可视化误差的分布。理想情况下，它应该多少符合正态分布。非正态误差分布可能表明存在模型未能提取的非线性关系，或者需要更多的数据转换。</p><h2 id="85f9" class="nf me it bd mf ox oy dn mj oz pa dp mn li pb pc mp lm pd pe mr lq pf pg mt ph bi translated">2.RMSE的梅、姆塞</h2><p id="8c4c" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">平均绝对误差(MAE):误差绝对值的平均值</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/3272a7daff6d5b6752b41b060a4df1a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*MZgJ2kC5eQN3iCF2.png"/></div></figure><p id="e022" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">均方误差(MSE):均方误差的平均值</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/b8e1512be295306113faf4b6e2d1bf1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*87n6v8yPcZWDEZpP.png"/></div></figure><p id="ec2a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">均方根误差(RMSE):平方误差平均值的平方根</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/0d64fd3a83a2385ec7a2c68001bc420e.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*hAVPHHVESbaMAWN3.png"/></div></figure><p id="65f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这三种方法都是通过计算预测值ŷ和实际值y之间的差值来测量误差的，因此差值越小越好。主要区别是MSE/RMSE惩罚大的误差并且是可微的，而MAE是不可微的，这使得它很难应用于梯度下降。与MSE相比，RMSE取平方根，从而保持原始数据比例。</p><h2 id="1921" class="nf me it bd mf ox oy dn mj oz pa dp mn li pb pc mp lm pd pe mr lq pf pg mt ph bi translated">3.r平方——决定系数</h2><p id="c138" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">r的平方或决定系数是一个介于0和1之间的值，表示模型所解释的实际目标变量的变化量。r平方定义为1 — RSS/TSS，1减去残差平方和(RSS)与总平方和(TSS)之比。更高的R平方意味着更好的模型性能。</p><p id="7901" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">残差平方和(RSS) </strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/ff0b5c0cbe4a19979804e9cb4f470154.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*aXf3HeFRblyCiQk7.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/bb21bdb930ff8f9f68785bc92f4b6dbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*Pe9GZ6PpHvgaJk__.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">RSS(图片由作者提供)</p></figure><p id="9c13" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">总平方和(TSS) </strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/4913ae33ed34e2d3cf364953d23783f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*kaJ1GZ83uaufPP-I.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/d0bf8f09385984a317ce0cb6e2dfa6cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*zFCQkZtKF7UAG-hX.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">TSS(图片由作者提供)</p></figure><p id="93ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，R的平方值为0.78，表明模型解释了目标变量中78%的变化，这通常被认为是一个好的比率，没有达到过度拟合的水平。</p><p id="dda5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">希望你喜欢我的文章:)。如果你想阅读我更多关于媒体的文章，我将非常感谢你的支持，注册<a class="ae ky" href="https://destingong.medium.com/membership" rel="noopener">媒体会员</a>。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="af54" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">带回家的信息</h1><p id="a40e" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">本文提供了实现线性回归的实用指南，介绍了模型构建的整个生命周期:</p><ol class=""><li id="11a5" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu nr ns nt nu bi translated">EDA:单变量分析，散点图，相关分析</li><li id="91eb" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">特征工程:对数变换，分类变量编码</li><li id="ef3d" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">模型实现:scikit learn LinearRegression()</li><li id="3613" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">模型评估:平均误差、均方误差、RMSE、R平方</li></ol><p id="6dd5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您对视频指南感兴趣:)</p><p id="a7f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://www.youtube.com/watch?v=tMcbmyK6QiM" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=tMcbmyK6QiM</a></p><h2 id="7f38" class="nf me it bd mf ox oy dn mj oz pa dp mn li pb pc mp lm pd pe mr lq pf pg mt ph bi translated">更多这样的文章</h2><div class="of og gp gr oh oi"><a rel="noopener follow" target="_blank" href="/simple-logistic-regression-using-python-scikit-learn-86bf984f61f1"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd iu gy z fp on fr fs oo fu fw is bi translated">Python中的简单逻辑回归</h2><div class="op l"><h3 class="bd b gy z fp on fr fs oo fu fw dk translated">从数据预处理到模型评估的逐步指南</h3></div><div class="oq l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">towardsdatascience.com</p></div></div><div class="or l"><div class="qk l ot ou ov or ow ks oi"/></div></div></a></div><div class="of og gp gr oh oi"><a rel="noopener follow" target="_blank" href="/semi-automated-exploratory-data-analysis-eda-in-python-7f96042c9809"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd iu gy z fp on fr fs oo fu fw is bi translated">Python中的半自动探索性数据分析(EDA)</h2><div class="op l"><h3 class="bd b gy z fp on fr fs oo fu fw dk translated">一键式全面数据探索流程</h3></div><div class="oq l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">towardsdatascience.com</p></div></div><div class="or l"><div class="os l ot ou ov or ow ks oi"/></div></div></a></div><div class="of og gp gr oh oi"><a rel="noopener follow" target="_blank" href="/clustering-algorithm-for-customer-segmentation-e2d79e28cbc3"><div class="oj ab fo"><div class="ok ab ol cl cj om"><h2 class="bd iu gy z fp on fr fs oo fu fw is bi translated">客户细分的聚类算法</h2><div class="op l"><h3 class="bd b gy z fp on fr fs oo fu fw dk translated">K-均值聚类的逐步指南</h3></div><div class="oq l"><p class="bd b dl z fp on fr fs oo fu fw dk translated">towardsdatascience.com</p></div></div><div class="or l"><div class="ql l ot ou ov or ow ks oi"/></div></div></a></div></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="9bce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">原载于2021年9月18日https://www.visual-design.net</em><em class="lv">的</em> <a class="ae ky" href="https://www.visual-design.net/post/semi-automated-exploratory-data-analysis-process-in-python" rel="noopener ugc nofollow" target="_blank"> <em class="lv">。</em></a></p></div></div>    
</body>
</html>