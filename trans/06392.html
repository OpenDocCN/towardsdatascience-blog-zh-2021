<html>
<head>
<title>Random Forest Classifier Project — Predicting Online News Popularity</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">随机森林分类器项目——预测在线新闻流行度</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/random-forest-classifier-project-predicting-online-news-popularity-e99c79daa33?source=collection_archive---------22-----------------------#2021-06-08">https://towardsdatascience.com/random-forest-classifier-project-predicting-online-news-popularity-e99c79daa33?source=collection_archive---------22-----------------------#2021-06-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c2d0" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用scikit-learn构建一个随机森林分类器并预测在线新闻文章的份额数量</h2></div><p id="f7a6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假想场景:我是一名数据科学家，在一家网络新闻公司工作。营销经理想花一笔预算来推广具有高潜力的商品。因此，她要求我建立一个预测模型来预测一篇文章是否会获得大量的份额。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/065e8176dee75c30c6bfd0d43f08d030.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DEsQ2BHXvO-g88Xk"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">谢尔盖·阿库利奇在<a class="ae lr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="c1dd" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">数据集概述:</h2><p id="df38" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">该数据集中的文章由Mashable(【www.mashable.com】)发布，其内容的版权归其所有。因此，该数据集不共享原始内容，而是共享一些与之相关的统计数据。使用数据集中提供的URL公开访问和检索原始内容。(<a class="ae lr" href="https://www.kaggle.com/srikaranelakurthy/online-news-popularity" rel="noopener ugc nofollow" target="_blank">随意从Kaggle </a>下载数据集)</p><p id="d78d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它包含<strong class="kh ir">大约40k行</strong>和<strong class="kh ir"> 61列(58个预测属性，2个非预测属性，1个目标字段)。</strong></p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mq"><img src="../Images/99123b00ce0dc8d1d93e702353ca87d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pmLPInqpP2UvqLSRwhaJkQ.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">属性信息。作者照片</p></figure></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><p id="a41a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们开始吧！(<a class="ae lr" href="https://github.com/YuehHanChen/Random_Forest_Project_Predicting_Popularity_of_Online_News_Articles/blob/main/Predicting_Popularity_of_Online_News_Articles.ipynb" rel="noopener ugc nofollow" target="_blank">参见此处的代码</a>)</p><h2 id="94e1" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated"><em class="my">第一步:数据评估</em></h2><p id="7ad5" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在评估数据之后，我发现这个数据集非常干净、整洁，并且没有缺失值。然而，它唯一的问题是，除了“url”之外，每个列的名称开头都有空格。(请参见下面的列名。)</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mz"><img src="../Images/a5ff68d55a75dde64271df83308f2edd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oH00jFGWRTkg22tDoa_UOQ.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者照片</p></figure><h2 id="8156" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated"><strong class="ak"> <em class="my">第二步:数据清理</em> </strong></h2><p id="4e1c" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">因此，我使用下面的代码来解决上述问题。</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="5a1c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">lambda函数用于遍历每一列的名称，如果其中有一个""，则使用" "替换它。</p><h2 id="e137" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated"><strong class="ak"> <em class="my">第三步:探索性数据分析</em> </strong></h2><p id="1d6b" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在EDA阶段，我发现大部分份额都在15000以下，所以我把15000以上的文章筛选出来看大部分。我计划绘制经验累积分布函数(ECDF)和股票数量的分布，以了解如何将股票数量分为不同的组，以便我可以建立一个分类模型来预测它属于哪个组。</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="na nb l"/></div></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nc"><img src="../Images/9fc513b0d6c4fed541143c33063cc0f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VUgqk5sihwhji1yJBkPVKA.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者照片</p></figure><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="na nb l"/></div></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nd"><img src="../Images/d09e09e81a90fcb2f44d7643aa9b85cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qjzxT4pK6-9woIMS8dYhag.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者照片</p></figure><p id="dc55" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在看了ECDF和分布之后，似乎大多数文章都在500到3000股之间。所以，我决定把股数分成3个等级。(<a class="ae lr" href="https://github.com/YuehHanChen/Random_Forest_Project_Predicting_Popularity_of_Online_News_Articles/blob/main/Predicting_Popularity_of_Online_News_Articles.ipynb" rel="noopener ugc nofollow" target="_blank">见此处代码</a>)</p><ol class=""><li id="cb40" class="ne nf iq kh b ki kj kl km ko ng ks nh kw ni la nj nk nl nm bi translated"><strong class="kh ir">极差</strong>:股数低于500股。</li><li id="9d18" class="ne nf iq kh b ki nn kl no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kh ir">多数</strong>:股数在500-3000股之间。</li><li id="a2b1" class="ne nf iq kh b ki nn kl no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kh ir">极好</strong>:股数高于3000。</li></ol><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nc"><img src="../Images/7285a01b27027d126ecf4ec0bb3d7925.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*At_r50SvwHbRP1SYGYDkIA.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者照片</p></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/d6a119f0beee785cde51cab0ac4301fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*3tvoOBozmRH0_IRLCzIr7A.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">这显示了数据集中每个级别的百分比。作者照片</p></figure><p id="e1bf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其次，我发现原始数据集包含两个特性，weekday和data_channel，这两个特性已经被一次性编码。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nt"><img src="../Images/b98cb1cf4cec15a6805454acd887a8c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XMct5w_EZ9x4Y7QxUNZpNA.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">data_channel已经是一键编码。作者照片。</p></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nu"><img src="../Images/2f56c860aa72705b26c95cece9f45dac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fQ49fwd3ms6DHdoDx9h8NQ.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">工作日已被一次性编码。作者照片。</p></figure><p id="e29d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为具有高基数的独热编码分类变量会导致基于树的集成的低效率。算法将给予连续变量比虚拟变量更大的重要性，这将模糊特征重要性的顺序，导致较差的性能(Ravi。"<a class="ae lr" rel="noopener" target="_blank" href="/one-hot-encoding-is-making-your-tree-based-ensembles-worse-heres-why-d64b282b5769">一键编码使基于树的集成变得更糟，这是为什么？</a>》。</p><p id="b991" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，在这个项目的最后一步，优化精度，我将测试是否不使用一热编码真的执行得更好。因此，在这里，为了准备测试，我将所有一次性编码的变量、与工作日相关的变量和与data_channel相关的变量恢复为单列。</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="4ba7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">weekday和data_channel变量的转换版本如下所示:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/df480110a81783b1b8b79a059a2229c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*LlqUFLdwgR7i6Ge8xJF8QQ.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者照片</p></figure><h2 id="be0d" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated"><strong class="ak"> <em class="my">第四步:</em>随机森林模型构建</strong></h2><p id="4e51" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">我们到了最重要的部分，建立模型。在模型构建过程中，我们需要遵循一些小步骤来正确地执行它。</p><blockquote class="nw nx ny"><p id="23c1" class="kf kg nz kh b ki kj jr kk kl km ju kn oa kp kq kr ob kt ku kv oc kx ky kz la ij bi translated">1.将分类列转换为数字列。</p></blockquote><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="na nb l"/></div></figure><blockquote class="nw nx ny"><p id="ce10" class="kf kg nz kh b ki kj jr kk kl km ju kn oa kp kq kr ob kt ku kv oc kx ky kz la ij bi translated">2.将数据集分为训练集(70%)和测试集(30%)</p></blockquote><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="na nb l"/></div></figure><blockquote class="nw nx ny"><p id="f127" class="kf kg nz kh b ki kj jr kk kl km ju kn oa kp kq kr ob kt ku kv oc kx ky kz la ij bi translated">3.构建并测试模型</p></blockquote><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="na nb l"/></div></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi od"><img src="../Images/c53485c95b3c22beda7dec9cd8f12b82.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*2S-EIeiUBfpJotolFvEINg.png"/></div></figure><p id="40d3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">漂亮！其实比我预想的要高！</p><blockquote class="nw nx ny"><p id="13fe" class="kf kg nz kh b ki kj jr kk kl km ju kn oa kp kq kr ob kt ku kv oc kx ky kz la ij bi translated">4.尝试不同数量的n估计量，看看我们应该使用多少棵树</p></blockquote><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="na nb l"/></div></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi oe"><img src="../Images/3038168798c2d9e55cab7647c8c1d548.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xSRjd8rcT5hdZuEKUIzYJw.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者照片</p></figure><p id="9188" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该图显示，在使用超过60棵树(n_estimatpr = 60)后，我们将获得大约76%的准确率。</p><h2 id="3261" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated"><strong class="ak"> <em class="my">第五步:</em>优化准确率</strong></h2><p id="7e84" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">为了优化准确率，我有三个方向可以探索:</p><ol class=""><li id="7482" class="ne nf iq kh b ki kj kl km ko ng ks nh kw ni la nj nk nl nm bi translated">搞清楚用一键编码和不用哪个准确率更高？</li><li id="cbe4" class="ne nf iq kh b ki nn kl no ko np ks nq kw nr la nj nk nl nm bi translated">找出哪个变量对因变量不太重要？放下它们，看看准确率有没有提高。</li><li id="eef3" class="ne nf iq kh b ki nn kl no ko np ks nq kw nr la nj nk nl nm bi translated">随机森林分类器、线性支持向量分类器和RBF支持向量分类器哪个模型效果更好？</li></ol><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi of"><img src="../Images/2f84211a4a1fdd72c57f75879ca4ff61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3KQ0TXOEhGUptYWji99GYQ.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者照片</p></figure><p id="68fc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于第一种情况，在计算了每种情况下不同n _ estimaters的精确度后，我们可以看到，没有使用独热编码的情况比另一种情况高出近1%。因此，我决定继续不使用一键编码。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi oe"><img src="../Images/bece339aaf7d849f7bf29e2bcf19a871.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ImIPM7-X0yAWeTS-hYy4rg.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">该图显示了10个最不重要的变量，并且“n_non_stop_words”具有最低的特征重要性分数。作者照片</p></figure><p id="80f3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于方向2，在得到特征重要性得分后，只有一个变量得分明显偏低，“n_non_stop_words”。而下图是去掉“n_non_stop_words”之后和去掉之前的对比。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi oe"><img src="../Images/e80717a29c5f3a5e3c5cc5e6ef3e77a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BMpME6MxbkNE6RWv2l7BnA.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者照片</p></figure><p id="079b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">奇怪的是，去掉“n_non_stop_words”后，并没有增加准确率。反而下降了近1.5%。因此，我决定不移除它。</p><p id="cf6f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于最后一个，随机森林分类器，线性支持向量分类器，还是RBF支持向量分类器，哪个模型更好？</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi og"><img src="../Images/356fc3c4b6806823e418e2bbda4fb76a.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*P9yVshBC3la0nXOh6Gtaig.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者照片</p></figure><blockquote class="oh"><p id="fd42" class="oi oj iq bd ok ol om on oo op oq la dk translated">经过5分钟计算其中三个的准确率，随机森林分类器以76%的准确率胜出！</p></blockquote><p id="bf86" class="pw-post-body-paragraph kf kg iq kh b ki or jr kk kl os ju kn ko ot kq kr ks ou ku kv kw ov ky kz la ij bi translated">谢谢你看完！如果你对这个项目的完整代码感兴趣，请查看<a class="ae lr" href="https://github.com/YuehHanChen/Random_Forest_Project_Predicting_Popularity_of_Online_News_Articles/blob/main/Predicting_Popularity_of_Online_News_Articles.ipynb" rel="noopener ugc nofollow" target="_blank"> my Github </a>。此外，我喜欢反馈，如果有任何不清楚或应该做得更好的地方，请联系我。这是我的<a class="ae lr" href="https://www.linkedin.com/in/yueh-han-chen/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或者通过我的电子邮件联系我(【johneeeeeeeeee3@gmail.com】T4</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><p id="babb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">引用作品:</p><p id="b15a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">拉维拉克什。"<a class="ae lr" rel="noopener" target="_blank" href="/one-hot-encoding-is-making-your-tree-based-ensembles-worse-heres-why-d64b282b5769">一键编码让你的基于树的整体变得更糟，这是为什么？</a><em class="nz">走向数据科学。</em>2019年1月11日。<a class="ae lr" rel="noopener" target="_blank" href="/one-hot-encoding-is-making-your-tree-based-ensembles-worse-heres-why-d64b282b5769">https://towards data science . com/one-hot-encoding-is-making-your-tree-based-ensembles-worse-heres-why-d64b 282 b 5769</a></p></div></div>    
</body>
</html>