<html>
<head>
<title>Text-to-Speech: One Small Step by Mankind to Create Lifelike Robots</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本到语音:人类创造逼真机器人的一小步</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/text-to-speech-one-small-step-by-mankind-to-create-lifelike-robots-54e19f843b21?source=collection_archive---------13-----------------------#2021-03-27">https://towardsdatascience.com/text-to-speech-one-small-step-by-mankind-to-create-lifelike-robots-54e19f843b21?source=collection_archive---------13-----------------------#2021-03-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ecfd" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">虽然机器人不会很快完全复制一个人，但语音合成确实已经走了很长的路</h2></div><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="kn ko l"/></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">作者提供的视频</p></figure><p id="b576" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="lp">注意:如果你更喜欢看视频，请随意播放相同内容的上述视频。</em></p><p id="80ea" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">虽然自Kratzenstein的元音器官能够发出五个元音以来，语音合成已经取得了很大进展，但将文本转换为听起来自然的语音却是另一个层次的挑战。</p><p id="6b9a" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">深度学习的最新发展为我们提供了应对挑战的新方法，在本文中，我们将简要介绍深度学习时代之前的主流文本到语音方法，然后探索WaveNet等模型，Google的文本到语音API服务现在正在使用这些模型进行逼真的语音合成。</p><h1 id="6f08" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">拼接文本到语音转换</h1><p id="5531" class="pw-post-body-paragraph kt ku it kv b kw mj ju ky kz mk jx lb lc ml le lf lg mm li lj lk mn lm ln lo im bi translated">如果你停下来想一想如何实现文本到语音的转换，你可能会想出一种与拼接方法非常相似的方法。</p><p id="fe74" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在拼接的文本到语音转换中，文本被分解成更小的单元，例如音素，然后这些单元的相应记录被组合以形成完整的语音。</p><p id="9524" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在英语中，大约有44个音素，如下表所示。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mo"><img src="../Images/7d8313e543667befc83d140fa81cda0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2zF1S7Jn65DRrR7EmsytZQ.png"/></div></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">作者图片</p></figure><p id="12f5" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">举个例子，单词“hello”有拼音文字<code class="fe mv mw mx my b">həˈloʊ</code>，表示由四个音组成:<code class="fe mv mw mx my b">h</code>、<code class="fe mv mw mx my b">ə</code>、<code class="fe mv mw mx my b">l</code>、<code class="fe mv mw mx my b">oʊ</code>。我们使用音频编辑器将四种独立的声音组合在一起，您可以播放下面的录音来聆听输出。这当然是我们连接声音的原始尝试，只是为了说明这个想法，专业制作的连接语音听起来肯定更好。</p><h2 id="b6d3" class="mz ls it bd lt na nb dn lx nc nd dp mb lc ne nf md lg ng nh mf lk ni nj mh nk bi translated"><em class="nl">单个音素录音</em></h2><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="nm ko l"/></div></figure><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="nm ko l"/></div></figure><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="nm ko l"/></div></figure><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="nm ko l"/></div></figure><h2 id="5391" class="mz ls it bd lt na nb dn lx nc nd dp mb lc ne nf md lg ng nh mf lk ni nj mh nk bi translated">“你好”的连接音素</h2><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="nm ko l"/></div></figure><p id="19bb" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">因此，不难想象，如果我们可以保存一个单词及其相应语音脚本的字典，我们就可以只用44个音素记录来执行文本到语音的转换。事实上，有<a class="ae lq" href="https://ieeexplore.ieee.org/document/1162873?reload=true&amp;arnumber=1162873" rel="noopener ugc nofollow" target="_blank">字母到声音的规则</a>可以高度准确地将任何单词翻译成它的音素，而不需要保存一个大的字典数据库。因此，即使你从未见过单词“<a class="ae lq" href="https://www.bbc.com/news/world-us-canada-40104063" rel="noopener ugc nofollow" target="_blank"> covfefe </a>”，你还是会设法把它读出来。</p><p id="b2cb" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">然而，虽然我们在技术上解决了文本到语音的转换，但语音输出远非自然。使用我们前面描述的方法，单词“right”在句子“你还好吗？”中听起来是一样的和“你是对的。”。也许，我们可以通过添加语调转录和相应的录音来改进，这样就有了一个“正确”，根据上下文以更高或更低的音高结束。但是你可以很容易地想象出很多其他的场景，在这些场景中“正确”听起来会有所不同。因此，大量的变化使得拼接方法难以操作。</p><h1 id="f553" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">WaveNet</h1><p id="3aa3" class="pw-post-body-paragraph kt ku it kv b kw mj ju ky kz mk jx lb lc ml le lf lg mm li lj lk mn lm ln lo im bi translated">2016年9月，DeepMind推出了WaveNet，这是一种可以生成音频波形的深度学习模型。这种开创性的方法产生了听起来更自然的语音，用美国英语和普通话进行的盲测显示WaveNet <a class="ae lq" href="https://deepmind.com/blog/article/wavenet-generative-model-raw-audio" rel="noopener ugc nofollow" target="_blank">优于谷歌最好的文本到语音转换系统</a>。</p><p id="c591" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们来听一个WaveNet的样本。</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="nm ko l"/></div></figure><p id="9e4b" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">目前，谷歌的文本到语音转换API由WaveNet提供支持，你可以在<a class="ae lq" href="https://cloud.google.com/text-to-speech#section-2" rel="noopener ugc nofollow" target="_blank">谷歌云的网站</a>上亲自体验。</p><p id="40f6" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">为了理解WaveNet是如何实现突破的，让我们看看该模型的三个主要特征。有关WaveNet的架构等完整细节，请参考<a class="ae lq" href="https://arxiv.org/abs/1609.03499" rel="noopener ugc nofollow" target="_blank">的原始论文</a>。</p><h2 id="416b" class="mz ls it bd lt na nb dn lx nc nd dp mb lc ne nf md lg ng nh mf lk ni nj mh nk bi translated">扩张的因果回旋</h2><p id="a546" class="pw-post-body-paragraph kt ku it kv b kw mj ju ky kz mk jx lb lc ml le lf lg mm li lj lk mn lm ln lo im bi translated">在数字音频中，声波表示为时间序列，y轴表示振幅(或音频音量)，每秒钟的语音记录通常包含至少16，000个样本点。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nn"><img src="../Images/66312d96fa4ba76958e956a99e658eb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e3j0iKEMzMF_HjSCKw9WOA.png"/></div></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">作者图片</p></figure><p id="9097" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">声波作为时间序列的性质也意味着每个样本都依赖于过去的样本。因此，挑战之一是模型必须考虑大量以前的样本。</p><p id="d7e4" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">为了克服这一挑战，DeepMind提出了使用扩张因果卷积，这也是其主要的独特特征。本质上，原始音频样本点以如下所示的模式通过模型，只有过去的样本用于预测当前输出。对于那些了解卷积的人来说，这种模式类似于步长为2的卷积。并且通过将扩展的卷积堆叠成若干层，网络可以在保持计算效率的同时具有大的感受野。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi no"><img src="../Images/cb44b42e68d3f94729515c35aa32dd02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X_cvYDp7pOI5pAFqn3y_PQ.png"/></div></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">作者图片</p></figure><h2 id="8ced" class="mz ls it bd lt na nb dn lx nc nd dp mb lc ne nf md lg ng nh mf lk ni nj mh nk bi translated">目标输出的非线性量化</h2><p id="dd72" class="pw-post-body-paragraph kt ku it kv b kw mj ju ky kz mk jx lb lc ml le lf lg mm li lj lk mn lm ln lo im bi translated">原始音频通常存储为一系列16位整数值。这意味着有2⁸ = 65，536个可能值，幅度范围从-32，768到32，767。因此，语音模型必须输出这65，536个值中的一个值。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi np"><img src="../Images/bfc45f2eec1f3574e407145e7c944c54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q2OkSaA1KR6pjCx2-51jTg.png"/></div></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">作者图片</p></figure><p id="bb68" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">也许你会想，30，000的振幅听起来和29，999有什么不同？事实上，对于正常人的耳朵来说，这两个值听起来没有什么不同。因此，65，536个可能值只会对模型训练造成不必要的负担。</p><p id="1bf6" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">因此，WaveNet对目标输出进行非线性量化。换句话说，根据一个公式(如下所示)，65，536个值被分组到更少数量的箱中。这将把唯一值的数量减少到256个量化值，使模型更易于管理。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nq"><img src="../Images/edfe312844481e5e187628b817bbd610.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Z1AMzI5nxXpqyNQPdxYdA.png"/></div></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">作者图片</p></figure><h2 id="c14b" class="mz ls it bd lt na nb dn lx nc nd dp mb lc ne nf md lg ng nh mf lk ni nj mh nk bi translated">语言特征制约</h2><p id="fd90" class="pw-post-body-paragraph kt ku it kv b kw mj ju ky kz mk jx lb lc ml le lf lg mm li lj lk mn lm ln lo im bi translated">在模型训练期间，语言特征嵌入也被馈送到每一层，以便模型可以学习如何从文本产生语音。这些嵌入本质上是语言特征的数字表示，如音素或重音符号。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nr"><img src="../Images/262419d128b1a8d3670a6d30f97c7273.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pfaFDGQ6F440Gw96einyCA.png"/></div></div><p class="kp kq gj gh gi kr ks bd b be z dk translated">作者图片</p></figure><p id="8370" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="lp">注:上图是模型的简化表示。有关全部细节(例如，具有门控激活单元和跳过连接的剩余块)，请参考</em> <a class="ae lq" href="https://arxiv.org/abs/1609.03499" rel="noopener ugc nofollow" target="_blank"> <em class="lp">原文</em> </a> <em class="lp">。</em></p><h1 id="7a62" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">其他深度学习模型</h1><p id="5271" class="pw-post-body-paragraph kt ku it kv b kw mj ju ky kz mk jx lb lc ml le lf lg mm li lj lk mn lm ln lo im bi translated">自从WaveNet发布以来，在WaveNet研究的基础上又有了其他改进的模型。其中包括Tacotron2和Glow-TTS，我们希望在以后的文章中介绍它们。</p><p id="4fab" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">通过使用Mozilla的GitHub repositor y，我们可以很容易地实现这些模型。首先，请随意使用用户友好的Colab笔记本。</p></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><p id="6e48" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">通过上面的插图，我们希望你现在能够有一种感觉，类似人类的语言是如何从文本中产生的。虽然机器人不会很快完全复制一个人，但语音合成确实已经走了很长的路。</p><p id="c609" class="pw-post-body-paragraph kt ku it kv b kw kx ju ky kz la jx lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">感谢阅读，我希望这篇文章是有用的:)也请随时评论您可能有的任何问题或建议。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nz"><img src="../Images/ec7c445dbcf62a12b4232d332d5beb05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0YblD7F9C6HewCBjlbV0dQ.png"/></div></div></figure><h1 id="c9de" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">参考</h1><div class="oa ob gp gr oc od"><a href="https://arxiv.org/abs/1609.03499" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">WaveNet:原始音频的生成模型</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">本文介绍了WaveNet，一种用于生成原始音频波形的深度神经网络。该模型完全…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">arxiv.org</p></div></div></div></a></div><div class="oa ob gp gr oc od"><a href="https://archive.org/details/Text-to-speechtts-AQuickOverview" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">文本到语音(TTS) -快速概述:Kishore Prahallad:免费下载，借用，和流…</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">remove-circle Internet Archive的浏览器内视频播放器需要启用JavaScript。您的浏览器似乎…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">archive.org</p></div></div><div class="om l"><div class="on l oo op oq om or mt od"/></div></div></a></div><div class="oa ob gp gr oc od"><a href="http://cambridgeenglishonline.com/interactive_phonemic_chart/" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">互动音位图:英语的44种声音和符号</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">欢迎来到我们的互动音位图表区。我们制作了两个版本，这样每个人都可以练习和学习44…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">cambridgeenglishonline.com</p></div></div><div class="om l"><div class="os l oo op oq om or mt od"/></div></div></a></div></div></div>    
</body>
</html>