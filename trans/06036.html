<html>
<head>
<title>Smartphone for Activity Recognition (Part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于活动识别的智能手机(第一部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/smartphone-for-activity-recognition-228b9e75c306?source=collection_archive---------20-----------------------#2021-05-30">https://towardsdatascience.com/smartphone-for-activity-recognition-228b9e75c306?source=collection_archive---------20-----------------------#2021-05-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="5e8d" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">R中的数据科学</h2><div class=""/><div class=""><h2 id="c685" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">你的手机知道你在做什么，即使没有麦克风或摄像头</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/1848671e773304c3f1c5ed173def6cde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ekmX89TW6N8Bi8bL"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">塞尔温·范·哈伦在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="8db4" class="ln lo it lj b gy lp lq l lr ls"><strong class="lj jd">Table of Contents</strong></span><span id="d294" class="ln lo it lj b gy lt lq l lr ls">· <a class="ae lh" href="#24eb" rel="noopener ugc nofollow">Library</a><br/>· <a class="ae lh" href="#ef5d" rel="noopener ugc nofollow">Dataset</a><br/>· <a class="ae lh" href="#15aa" rel="noopener ugc nofollow">Data Cleaning</a><br/>· <a class="ae lh" href="#097c" rel="noopener ugc nofollow">Exploratory Data Analysis</a><br/>· <a class="ae lh" href="#265a" rel="noopener ugc nofollow">Cross-validation</a><br/>· <a class="ae lh" href="#2b5b" rel="noopener ugc nofollow">Metrics</a><br/>· <a class="ae lh" href="#6ca2" rel="noopener ugc nofollow">Modeling</a><br/>  ∘ <a class="ae lh" href="#8b68" rel="noopener ugc nofollow">Naive Bayes</a><br/>  ∘ <a class="ae lh" href="#b02b" rel="noopener ugc nofollow">Decision Tree</a><br/>  ∘ <a class="ae lh" href="#f14a" rel="noopener ugc nofollow">k-Nearest Neighbors</a><br/>  ∘ <a class="ae lh" href="#ebbe" rel="noopener ugc nofollow">Random Forest</a><br/>· <a class="ae lh" href="#3122" rel="noopener ugc nofollow">Conclusion</a></span></pre><p id="aef5" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi mq translated"><span class="l mr ms mt bm mu mv mw mx my di">现代智能手机配备了加速度计和陀螺仪等传感器，以提供高级功能和更好的用户体验。智能手机中的加速度计用于检测手机的方向。陀螺仪通过跟踪旋转或扭曲，为加速度计提供的信息增加了一个额外的维度。</span></p><p id="1463" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">已经进行了利用这些传感器的研究，例如在<a class="ae lh" href="https://ieeexplore.ieee.org/document/7049855" rel="noopener ugc nofollow" target="_blank">估计路面不平度条件</a>中。然而，我们正在做的将更类似于哈佛大学的这项研究。具体来说，这个项目是建立一个模型，根据智能手机的测量准确预测人类的活动，如行走、上楼、下楼、坐着、站着或躺着。</p><h1 id="24eb" class="mz lo it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">图书馆</h1><p id="6a55" class="pw-post-body-paragraph lu lv it lw b lx nq kd lz ma nr kg mc md ns mf mg mh nt mj mk ml nu mn mo mp im bi translated">我们将使用R语言。这是一些要导入的库。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="1d21" class="ln lo it lj b gy lp lq l lr ls">library(dplyr)          # data wrangling<br/>library(ggplot2)        # visualization<br/>library(Rtsne)          # EDA<br/>library(caret)          # machine learning functions<br/>library(MLmetrics)      # machine learning metrics<br/>library(e1071)          # naive bayes<br/>library(rpart)          # decision tree<br/>library(rattle)         # tree visualization<br/>library(class)          # k-NN<br/>library(randomForest)   # random forest</span></pre><h1 id="ef5d" class="mz lo it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">资料组</h1><p id="5957" class="pw-post-body-paragraph lu lv it lw b lx nq kd lz ma nr kg mc md ns mf mg mh nt mj mk ml nu mn mo mp im bi translated">用于训练该模型的数据集是从30名在腰部佩戴智能手机进行不同活动的人那里收集的，并在智能手机传感器的帮助下进行记录。该实验被录像以手动标记数据。要查看更多详情，请参考此<a class="ae lh" href="https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="66a5" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">我们来读一下数据集。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="057e" class="ln lo it lj b gy lp lq l lr ls">uci_har &lt;- read.csv("UCI HAR.csv")<br/>dim(uci_har)</span><span id="1491" class="ln lo it lj b gy lt lq l lr ls">#&gt; [1] 10299   563</span></pre><p id="8298" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">如上所示，该数据集包含563个要素和10299个观测值。太多了！目前，我们不需要完全理解测量的含义。简而言之，我们有这些:</p><ol class=""><li id="5a82" class="nv nw it lw b lx ly ma mb md nx mh ny ml nz mp oa ob oc od bi translated"><code class="fe oe of og lj b">subject</code>特征表示进行实验的受试者的标识符。有30个唯一的id，每个id对应30个人中的一个。</li><li id="0b64" class="nv nw it lw b lx oh ma oi md oj mh ok ml ol mp oa ob oc od bi translated"><code class="fe oe of og lj b">Activity</code>特征表示受试者正在进行的活动，包括:行走、上楼、下楼、坐、站、躺</li><li id="4b50" class="nv nw it lw b lx oh ma oi md oj mh ok ml ol mp oa ob oc od bi translated">具有时域和频域变量的561特征向量。</li></ol><p id="5505" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">根据问题陈述，<code class="fe oe of og lj b">Activity</code>将是我们的目标特性。</p><h1 id="15aa" class="mz lo it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">数据清理</h1><p id="3ada" class="pw-post-body-paragraph lu lv it lw b lx nq kd lz ma nr kg mc md ns mf mg mh nt mj mk ml nu mn mo mp im bi translated">首先，将<code class="fe oe of og lj b">subject</code>和<code class="fe oe of og lj b">Activity</code>特征转换成因子，其他的转换成数值。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="3db4" class="ln lo it lj b gy lp lq l lr ls">uci_har &lt;- uci_har %&gt;% <br/>  mutate_at(c('subject', 'Activity'), as.factor) %&gt;% <br/>  mutate_at(vars(-subject, -Activity), as.numeric)</span><span id="95b1" class="ln lo it lj b gy lt lq l lr ls">lvl &lt;- levels(uci_har$Activity)<br/>lvl</span><span id="32bf" class="ln lo it lj b gy lt lq l lr ls">#&gt; [1] "LAYING"             "SITTING"            "STANDING"           "WALKING"            "WALKING_DOWNSTAIRS" "WALKING_UPSTAIRS"</span></pre><p id="44c4" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">让我们检查是否有任何重复的观察值或丢失的值。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="4cf1" class="ln lo it lj b gy lp lq l lr ls">cat("Number of duplicated rows:", sum(duplicated(uci_har)))</span><span id="5334" class="ln lo it lj b gy lt lq l lr ls">#&gt; Number of duplicated rows: 0</span><span id="a388" class="ln lo it lj b gy lt lq l lr ls">cat("Number of missing values:", sum(is.na(uci_har)))</span><span id="32d7" class="ln lo it lj b gy lt lq l lr ls">#&gt; Number of missing values: 0</span></pre><p id="be74" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">太好了！它们都不存在。现在让我们检查数据不平衡。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="9e86" class="ln lo it lj b gy lp lq l lr ls">ggplot(uci_har %&gt;% <br/>         group_by(subject, Activity) %&gt;% <br/>         count(name = 'activity_count'), <br/>       aes(x = subject, y = activity_count, fill = Activity)) + <br/>  geom_bar(stat = 'identity')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl om"><img src="../Images/f878ec2d5afa0617c7e68b25acd91589.png" data-original-src="https://miro.medium.com/v2/format:webp/1*S9qGaaqymXyK5MLNJIWbag.png"/></div></figure><p id="d172" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">就每个受试者的活动计数而言，没有显著差异。因此，所有目标类都是平衡的。</p><h1 id="097c" class="mz lo it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">探索性数据分析</h1><p id="4b2c" class="pw-post-body-paragraph lu lv it lw b lx nq kd lz ma nr kg mc md ns mf mg mh nt mj mk ml nu mn mo mp im bi translated">我们可以把<code class="fe oe of og lj b">Activity</code>分为两类:静止活动(如躺、坐或站)和运动活动(如走路、下楼或上楼)。我们来看看物体加速度信号三轴震级均值的分布(phew，真拗口！我真正的意思是<code class="fe oe of og lj b">tBodyAccMagmean</code>。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="9897" class="ln lo it lj b gy lp lq l lr ls">ggplot(uci_har,<br/>       aes(x = tBodyAccMagmean, group = Activity, fill = Activity)) +<br/>  geom_density(alpha = .5) + <br/>  annotate('text', x = -.8, y = 25, label = "Stationary activities") + <br/>  annotate('text', x = -.0, y = 5, label = "Moving activities")</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl om"><img src="../Images/94ae87c4b1d7414982ba09cfeb9e042f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*5T-ZIR8JOroaWWi-QZ4nSA.png"/></div></figure><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="fcdb" class="ln lo it lj b gy lp lq l lr ls">ggplot(uci_har,<br/>       aes(y = Activity, x = tBodyAccMagmean, group = Activity, fill = Activity)) +<br/>  geom_boxplot(show.legend = FALSE)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl om"><img src="../Images/d332f7d15c1c165744486653ffbe4c10.png" data-original-src="https://miro.medium.com/v2/format:webp/1*grnImSOoG-dDnv_XfHYdKQ.png"/></div></figure><p id="5c4c" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">我们可以看到两组之间的明显区别:</p><ol class=""><li id="c8ed" class="nv nw it lw b lx ly ma mb md nx mh ny ml nz mp oa ob oc od bi translated">与移动活动相比，静止活动具有非常小的身体运动。</li><li id="8d9d" class="nv nw it lw b lx oh ma oi md oj mh ok ml ol mp oa ob oc od bi translated">如果<code class="fe oe of og lj b">tBodyAccMagmean</code> &gt; -0.5，那么活动大概会是要么走路，要么上楼，要么下楼。</li><li id="5fe8" class="nv nw it lw b lx oh ma oi md oj mh ok ml ol mp oa ob oc od bi translated">如果<code class="fe oe of og lj b">tBodyAccMagmean</code> &lt; -0.5，那么活动最有可能是躺、站、坐。</li></ol><p id="b2ef" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">现在，在手机定位方面，做爱和其他活动也应该有所区别。与其他活动不同，躺着时，人们倾向于将手机水平放在腰间。那么，让我们通过比较X、Y、Z轴之间的角度与每个轴上重力加速度信号的平均值(<code class="fe oe of og lj b">angleXgravityMean</code>、<code class="fe oe of og lj b">angleYgravityMean</code>和<code class="fe oe of og lj b">angleZgravityMean</code>)来看看这个假设是否成立。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="6c3a" class="ln lo it lj b gy lp lq l lr ls">for (coor in c('angleXgravityMean', 'angleYgravityMean', 'angleZgravityMean')) {<br/>  print(<br/>    ggplot(uci_har,<br/>           aes_string(y = 'Activity', x = coor, group = 'Activity', fill = 'Activity')) + <br/>      geom_boxplot(show.legend = FALSE)<br/>  )<br/>}</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl om"><img src="../Images/975e513d0736141d828037fcf064557b.png" data-original-src="https://miro.medium.com/v2/format:webp/1*W2P-K9SP94sWNmcUJDwhUA.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl om"><img src="../Images/2bed21c2eaf794cb87d4469b76da269c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*STEmRK3X5pTNhbkd-GG80g.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl om"><img src="../Images/b2c90cb9540e8184105452e1d762e985.png" data-original-src="https://miro.medium.com/v2/format:webp/1*MfSJba4R24e0KR2oWPsj6A.png"/></div></figure><p id="cf41" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">很明显:</p><ol class=""><li id="98a4" class="nv nw it lw b lx ly ma mb md nx mh ny ml nz mp oa ob oc od bi translated">躺着时的手机方向明显不同于做其他活动时的手机方向。</li><li id="67ba" class="nv nw it lw b lx oh ma oi md oj mh ok ml ol mp oa ob oc od bi translated">如果<code class="fe oe of og lj b">angleXgravityMean</code> &gt;为0，则该活动极有可能是铺设，否则为其他活动。</li><li id="8157" class="nv nw it lw b lx oh ma oi md oj mh ok ml ol mp oa ob oc od bi translated">如果<code class="fe oe of og lj b">angleYgravityMean</code> &lt; -0.25或者<code class="fe oe of og lj b">angleZgravityMean</code> &lt; -0.25，那么该活动将可能是铺设，其他活动则不然。</li><li id="12d9" class="nv nw it lw b lx oh ma oi md oj mh ok ml ol mp oa ob oc od bi translated">我们可以仅通过使用<code class="fe oe of og lj b">angleXgravityMean</code>，或者可能通过X轴的其他重力相关特征，以最小的误差预测铺设活动。</li></ol><p id="7ffe" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">最后，我们可以对数据集执行<a class="ae lh" href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" rel="noopener ugc nofollow" target="_blank"> t-SNE </a>来减少它的维度，以便可视化，希望每个<code class="fe oe of og lj b">Activity</code>将被分组到不同的区域。t-SNE是一种无监督的非线性技术，主要用于数据探索和可视化高维数据。基本上，t-SNE所做的是给我们一种感觉或直觉，让我们知道数据是如何在高维空间中排列的。在本文中，我们不会深入研究SNE霸王龙。我们将通过在5、10和20的困惑中做灵敏度来执行t-SNE，以确保降维后获得的值确实被分组到不同的<code class="fe oe of og lj b">Activity</code>中。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="0b5e" class="ln lo it lj b gy lp lq l lr ls">for (perp in c(5, 10, 20)) {<br/>  tsne &lt;- Rtsne(uci_har %&gt;% select(-c(subject, Activity)), perplexity = perp)<br/>  tsne_plot &lt;- data.frame(x = tsne$Y[,1], y = tsne$Y[,2], Activity = uci_har$Activity)<br/>  print(<br/>    ggplot(tsne_plot) + <br/>      geom_point(aes(x = x, y = y, color = Activity))<br/>  )<br/>}</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl om"><img src="../Images/956d50e9a776e40b3bbbfdbaf832f2f3.png" data-original-src="https://miro.medium.com/v2/format:webp/1*1zr2C4Mf9vuVOTAUr9gqDA.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl om"><img src="../Images/0248b51eaf63ccb8abee675eae20304f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*yXxPa0gQS-3BMHP_tkT8hg.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl om"><img src="../Images/c2b835346cbda27f1d8d320880348272.png" data-original-src="https://miro.medium.com/v2/format:webp/1*N-ZMwHLUzBYe7pm_K0K_Tw.png"/></div></figure><p id="515b" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">可以看出，除了站和坐，所有的活动都可以很容易地分开。这是有道理的，因为站着和坐着在手机方向上没有太大的区别。</p><h1 id="265a" class="mz lo it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">交叉验证</h1><p id="e3d8" class="pw-post-body-paragraph lu lv it lw b lx nq kd lz ma nr kg mc md ns mf mg mh nt mj mk ml nu mn mo mp im bi translated">对于这个问题，我们不能应用正常的k倍交叉验证。回想一下，我们的目标是基于手机传感器预测人类活动。这意味着当一个新的看不见的<code class="fe oe of og lj b">subject</code>进来时，我们不知道他们用手机的行为。如果我们通过随机选择观察值来使用k-fold交叉验证，那么相同的<code class="fe oe of og lj b">subject</code>有可能同时出现在训练和测试数据集中，这表明存在数据泄漏。为了避免这种情况，在交叉验证期间，我们分割数据集，使得训练和测试数据集中的<code class="fe oe of og lj b">subject</code>不相交。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="066f" class="ln lo it lj b gy lp lq l lr ls">set.seed(2072) # for reproducibility<br/>subject_id &lt;- unique(uci_har$subject)<br/>folds &lt;- sample(1:5, 30, replace = TRUE)<br/>d &lt;- data.frame(col1 = c(subject_id), col2 = c(folds))<br/>uci_har$folds &lt;- d$col2[match(uci_har$subject, d$col1)]<br/>uci_har &lt;- uci_har %&gt;% <br/>  mutate(folds = as.factor(folds)) %&gt;% <br/>  select(-subject)</span></pre><p id="bf58" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">请注意，在为每个观察结果创建折叠后，我们丢弃了<code class="fe oe of og lj b">subject</code>特征，因为在分析中不再需要它。最后，我们还可以在下面看到，数据在褶皱之间均匀分布，因此没有出现不平衡数据。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="15b6" class="ln lo it lj b gy lp lq l lr ls">ggplot(uci_har %&gt;%<br/>         group_by(folds, Activity) %&gt;%<br/>         count(name = 'activity_count'),<br/>       aes(x = folds, y = activity_count, fill = Activity)) +<br/>  geom_bar(stat = 'identity')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl om"><img src="../Images/ef4e3b869fa825a8f117fc6165a5fa97.png" data-original-src="https://miro.medium.com/v2/format:webp/1*9ij-2ac9SvWX_mne-h98hQ.png"/></div></figure><h1 id="2b5b" class="mz lo it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">韵律学</h1><p id="1305" class="pw-post-body-paragraph lu lv it lw b lx nq kd lz ma nr kg mc md ns mf mg mh nt mj mk ml nu mn mo mp im bi translated">在考虑以下原因后，我们使用精确度来量化模型的性能:</p><ol class=""><li id="b41b" class="nv nw it lw b lx ly ma mb md nx mh ny ml nz mp oa ob oc od bi translated">根据问题陈述，我们只对同等准确地预测每个类感兴趣，而不是偏爱其中一个，因此怀疑召回和精度度量的目的。</li><li id="0ab2" class="nv nw it lw b lx oh ma oi md oj mh ok ml ol mp oa ob oc od bi translated">这个问题是一个多类分类，其准确性比ROC-AUC度量更容易解释。</li></ol><h1 id="6ca2" class="mz lo it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">建模</h1><p id="5b6e" class="pw-post-body-paragraph lu lv it lw b lx nq kd lz ma nr kg mc md ns mf mg mh nt mj mk ml nu mn mo mp im bi translated">首先，作为健全性检查，让我们看看数据集的维度，以及每个要素中的最大值和最小值。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="fbd4" class="ln lo it lj b gy lp lq l lr ls">dim(uci_har)</span><span id="c3c1" class="ln lo it lj b gy lt lq l lr ls">#&gt; [1] 10299   563</span><span id="241f" class="ln lo it lj b gy lt lq l lr ls">max(apply(uci_har %&gt;% select(-c(Activity, folds)), 1, max))</span><span id="84a3" class="ln lo it lj b gy lt lq l lr ls">#&gt; [1] 1</span><span id="0dcb" class="ln lo it lj b gy lt lq l lr ls">min(apply(uci_har %&gt;% select(-c(Activity, folds)), 1, max))</span><span id="8416" class="ln lo it lj b gy lt lq l lr ls">#&gt; [1] 0.795525</span><span id="433c" class="ln lo it lj b gy lt lq l lr ls">min(apply(uci_har %&gt;% select(-c(Activity, folds)), 1, min))</span><span id="5932" class="ln lo it lj b gy lt lq l lr ls">#&gt; [1] -1</span><span id="da14" class="ln lo it lj b gy lt lq l lr ls">max(apply(uci_har %&gt;% select(-c(Activity, folds)), 1, min))</span><span id="0bc3" class="ln lo it lj b gy lt lq l lr ls">#&gt; [1] -0.9960928</span></pre><p id="d527" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">所有特征的最小值都接近-1，而最大值的范围在0.8到1之间。我们不会进行任何标准化，因为前面提到的范围被认为很小，更重要的是，我们不想丢失太多关于特征之间相关性的信息。</p><p id="f0aa" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">数据集有563个要素，其中两个将在建模时被丢弃。它们是<code class="fe oe of og lj b">Activity</code>(因为这是目标变量)和<code class="fe oe of og lj b">folds</code>(因为这不会向数据集添加任何信息)。</p><p id="6d1f" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">我们将提出四个模型来实现问题陈述的最佳解决方案:朴素贝叶斯、决策树、k-最近邻和随机森林。为了简化，下面是一个交叉验证所有模型的函数。在此函数中，我们迭代之前已构建的交叉验证的每个折叠，并在每次迭代中执行以下操作:</p><ol class=""><li id="ecd8" class="nv nw it lw b lx ly ma mb md nx mh ny ml nz mp oa ob oc od bi translated">创建<code class="fe oe of og lj b">X_train</code>、<code class="fe oe of og lj b">y_train</code>、<code class="fe oe of og lj b">X_test</code>、<code class="fe oe of og lj b">y_test</code>，分别为训练的预测变量、训练的目标变量、测试的预测变量、测试的目标变量。</li><li id="2a77" class="nv nw it lw b lx oh ma oi md oj mh ok ml ol mp oa ob oc od bi translated">建立模型，预测输出为<code class="fe oe of og lj b">y_pred</code>。</li><li id="c80d" class="nv nw it lw b lx oh ma oi md oj mh ok ml ol mp oa ob oc od bi translated">通过比较<code class="fe oe of og lj b">y_pred</code>和<code class="fe oe of og lj b">y_test</code>计算模型精度。</li><li id="b1bc" class="nv nw it lw b lx oh ma oi md oj mh ok ml ol mp oa ob oc od bi translated">然后对所有折叠的精度结果进行平均，产生一个数字来比较所有模型。</li></ol><p id="b83c" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">注意，对于随机森林模型，我们也使用交叉验证精度而不是OOB误差，这样与其他模型的比较就是苹果对苹果。但是，稍后我们会单独处理随机森林模型，以强调超参数调整的重要性。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="6daa" class="ln lo it lj b gy lp lq l lr ls">crossvalidate &lt;- function(data, k, model_name,<br/>                          tuning = FALSE, mtry = NULL, nodesize = NULL) {<br/>  # 'data' is the training set with the 'folds' column<br/>  # 'k' is the number of folds we have<br/>  # 'model_name' is a string describing the model being used<br/>  # 'tuning' is a mode in which this function will operate, tuning = TRUE means we are doing hyperparameter tuning<br/>  # 'mtry' and 'nodesize' are used only in Random Forest hyperparameter tuning<br/>  <br/>  # initialize empty lists for recording performances<br/>  acc_train &lt;- c()<br/>  acc_test &lt;- c()<br/>  y_preds &lt;- c()<br/>  y_tests &lt;- c()<br/>  models &lt;- c()<br/>  <br/>  # one iteration per fold<br/>  for (fold in 1:k) {<br/>    <br/>    # create training set for this iteration<br/>    # subset all the datapoints where folds does not match the current fold<br/>    training_set &lt;- data %&gt;% filter(folds != fold)<br/>    X_train &lt;- training_set %&gt;% select(-c(Activity, folds))<br/>    y_train &lt;- training_set$Activity<br/>    <br/>    # create test set for this iteration<br/>    # subset all the datapoints where folds matches the current fold<br/>    testing_set &lt;- data %&gt;% filter(folds == fold)<br/>    X_test &lt;- testing_set %&gt;% select(-c(Activity, folds))<br/>    y_test &lt;- testing_set$Activity<br/>    <br/>    # train &amp; predict<br/>    switch(model_name,<br/>      nb = {<br/>        model &lt;- naiveBayes(x = X_train, y = y_train, laplace = 1)<br/>        y_pred &lt;- predict(model, X_test, type = 'class')<br/>        y_pred_train &lt;- predict(model, X_train, type = 'class')<br/>      },<br/>      dt = {<br/>        model &lt;- rpart(formula = Activity ~ ., data = training_set %&gt;% select(-folds), method = 'class')<br/>        y_pred &lt;- predict(model, X_test, type = 'class')<br/>        y_pred_train &lt;- predict(model, X_train, type = 'class')<br/>      },<br/>      knn = {<br/>        k &lt;- round(sqrt(nrow(training_set)))<br/>        y_pred &lt;- knn(train = X_train, test = X_test, cl = y_train, k = k)<br/>        y_pred_train &lt;- knn(train = X_train, test = X_train, cl = y_train, k = k)<br/>      },<br/>      rf = {<br/>        if (tuning == FALSE) {<br/>          model &lt;- randomForest(x = X_train, y = y_train, xtest = X_test, ytest = y_test)<br/>        } else {<br/>          model &lt;- randomForest(x = X_train, y = y_train, xtest = X_test, ytest = y_test,<br/>                                mtry = mtry, nodesize = nodesize)<br/>        }<br/>        y_pred &lt;- model$test$predicted<br/>        y_pred_train &lt;- model$predicted<br/>      },<br/>      {<br/>        print("Model is not recognized. Try to input 'nb', 'dt', 'knn', or 'rf'.")<br/>        return()<br/>      }<br/>    )<br/>    <br/>    # populate corresponding lists<br/>    acc_train[fold] &lt;- Accuracy(y_pred_train, y_train)<br/>    acc_test[fold] &lt;- Accuracy(y_pred, y_test)<br/>    y_preds &lt;- append(y_preds, y_pred)<br/>    y_tests &lt;- append(y_tests, y_test)<br/>    models &lt;- c(models, list(model))<br/>  }<br/>  <br/>  # convert back to factor<br/>  y_preds &lt;- factor(y_preds, labels = lvl)<br/>  y_tests &lt;- factor(y_tests, labels = lvl)<br/>  <br/>  # get the accuracy between the predicted and the observed<br/>  cm &lt;- confusionMatrix(y_preds, y_tests)<br/>  cm_table &lt;- cm$table<br/>  acc &lt;- cm$overall['Accuracy']<br/>  <br/>  # return the results<br/>  if (model_name == 'knn') {<br/>    return(list('cm' = cm_table, 'acc' = acc, 'acc_train' = acc_train, 'acc_test' = acc_test))<br/>  } else {<br/>    return(list('cm' = cm_table, 'acc' = acc, 'acc_train' = acc_train, 'acc_test' = acc_test, 'models' = models))<br/>  }<br/>}</span></pre><p id="ff55" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">现在我们准备好了。</p><h2 id="8b68" class="ln lo it bd na on oo dn ne op oq dp ni md or os nk mh ot ou nm ml ov ow no iz bi translated">朴素贝叶斯</h2><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="e370" class="ln lo it lj b gy lp lq l lr ls">nb &lt;- crossvalidate(uci_har, 5, 'nb')<br/>cat("Naive Bayes Accuracy:", nb$acc)</span><span id="776c" class="ln lo it lj b gy lt lq l lr ls">#&gt; Naive Bayes Accuracy: 0.7258957</span></pre><p id="8164" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">朴素贝叶斯模型给出的结果很差，准确率为73%。这主要是由于模型的基本假设，即每个预测因子都是相互独立的，而在我们的数据集中并非如此。例如，我们有以下模型没有捕捉到的一些预测值之间的高度相关性。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="5064" class="ln lo it lj b gy lp lq l lr ls">set.seed(3)<br/>col &lt;- c(sample(names(uci_har), 6))<br/>GGally::ggcorr(uci_har[, col], hjust = 1, layout.exp = 3, label = T)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl om"><img src="../Images/bda2c63ef434017b59525ec3c02ce49d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Aw01MRuyoTA3NvY_xVphUg.png"/></div></figure><p id="8d86" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">让我们看看下面的混淆矩阵。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="e766" class="ln lo it lj b gy lp lq l lr ls">nb$cm</span><span id="1bc4" class="ln lo it lj b gy lt lq l lr ls">#&gt;                     Reference<br/>#&gt; Prediction           LAYING SITTING STANDING WALKING WALKING_DOWNSTAIRS WALKING_UPSTAIRS<br/>#&gt;   LAYING               1623      14        4       0                  0                0<br/>#&gt;   SITTING               286    1550     1188       0                  0                0<br/>#&gt;   STANDING                0     187      677       0                  0                0<br/>#&gt;   WALKING                 2       0        1    1181                 93               40<br/>#&gt;   WALKING_DOWNSTAIRS      4       0        0     234               1065              124<br/>#&gt;   WALKING_UPSTAIRS       29      26       36     307                248             1380</span></pre><p id="7330" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">朴素贝叶斯模型仍然在几个微不足道的不同活动之间混淆，比如躺下和坐着(大约300个错误的预测)。这个模型也很难区分上楼和静止的活动(大约90个错误的预测)。</p><p id="c791" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">最后，正如下面可以看到的，基于预测训练和测试数据集所得到的准确性，我们可以看到该模型已经相当不错，没有对训练数据集欠拟合或过拟合(除了第四个折叠)。因此，我们不能过多地依靠权衡偏差和方差来提高模型性能。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="5705" class="ln lo it lj b gy lp lq l lr ls">print(nb$acc_train)</span><span id="78cd" class="ln lo it lj b gy lt lq l lr ls">#&gt; [1] 0.7349193 0.7647131 0.7280039 0.7635290 0.7612536</span><span id="3830" class="ln lo it lj b gy lt lq l lr ls">print(nb$acc_test)</span><span id="2d52" class="ln lo it lj b gy lt lq l lr ls">#&gt; [1] 0.7475728 0.7491702 0.7276636 0.6863137 0.7169533</span></pre><h2 id="b02b" class="ln lo it bd na on oo dn ne op oq dp ni md or os nk mh ot ou nm ml ov ow no iz bi translated">决策图表</h2><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="ee28" class="ln lo it lj b gy lp lq l lr ls">dt &lt;- crossvalidate(uci_har, 5, 'dt')<br/>cat("Decision Tree Accuracy:", dt$acc)</span><span id="4a12" class="ln lo it lj b gy lt lq l lr ls">#&gt; Decision Tree Accuracy: 0.8599864</span></pre><p id="4d91" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">决策树模型给出了更好的结果，准确率为86%。通过注意t-SNE结果，我们可以看出为什么我们的数据集是高度可分的(除了坐着和站着的活动)。基于树的模型可以利用这一特性。为了让大家了解决策树是如何工作的，请观察下面的5个树形图，每个图代表一个交叉验证文件夹。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="48cd" class="ln lo it lj b gy lp lq l lr ls">for (model in dt$models) {<br/>  fancyRpartPlot(model, sub = NULL)<br/>}</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl om"><img src="../Images/562f048d6bbcc56ac9014f40531e7d05.png" data-original-src="https://miro.medium.com/v2/format:webp/1*AQPOsIKvydkbP7akP7bqJQ.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl om"><img src="../Images/6f6c27213417ea660da7e9043c56bf88.png" data-original-src="https://miro.medium.com/v2/format:webp/1*aq86x1gZI3-W3s1BVNOC7A.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl om"><img src="../Images/0e0a0c01f73bc16cbcc8d8ec8c3d98cb.png" data-original-src="https://miro.medium.com/v2/format:webp/1*EdMUaqJH6jVSlJuMTG04qw.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl om"><img src="../Images/bee742cdd250b29599814350423cbddf.png" data-original-src="https://miro.medium.com/v2/format:webp/1*NDusMk9sLKEFWkSQzNsOmA.png"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="ab gu cl om"><img src="../Images/fb3d4167a1dc69cd212ad580523bf4a6.png" data-original-src="https://miro.medium.com/v2/format:webp/1*g5vj2mBi9H17CVIZ3RPyrA.png"/></div></figure><p id="f833" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">人们可以很容易地看到，<code class="fe oe of og lj b">tGravityAccminX</code>或<code class="fe oe of og lj b">tGravityAccmeanX</code>在根之后的第一次分割中成为一个关键特征。如果该特征小于某个阈值，则模型可以完美地预测相应的活动正在进行，这占所有训练数据集观察的19%。这与我们的EDA结果是一致的，即仅通过观察X轴的一个重力相关特征就可以区分铺设活动。</p><p id="1781" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">在第二次分割中，基于身体加速度信号，模型可以将坐着和站着与移动活动完全分开(坐着和站着占36%，而所有移动活动占训练数据集观察的45%)。这一发现证实了我们先前的分析，即静止和运动活动可以相当容易地分开。</p><p id="e338" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">然后，在第三次分解到树叶时，模特们分开了坐着和站着，同样都是移动的活动，有一些误差。这意味着坐着和站着，同样都是移动的活动，对于模特来说很难区分。为了看清楚这一点，这里有一个混淆矩阵。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="534e" class="ln lo it lj b gy lp lq l lr ls">dt$cm</span><span id="e46e" class="ln lo it lj b gy lt lq l lr ls">#&gt;                     Reference<br/>#&gt; Prediction           LAYING SITTING STANDING WALKING WALKING_DOWNSTAIRS WALKING_UPSTAIRS<br/>#&gt;   LAYING               1942      15        0       0                  0                0<br/>#&gt;   SITTING                 2    1564      334       0                  0                0<br/>#&gt;   STANDING                0     196     1571       8                  0                0<br/>#&gt;   WALKING                 0       0        1    1549                151              296<br/>#&gt;   WALKING_DOWNSTAIRS      0       1        0      39               1149              166<br/>#&gt;   WALKING_UPSTAIRS        0       1        0     126                106             1082</span></pre><p id="a121" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">此表中的一个小注意事项:与朴素贝叶斯模型不同，决策树模型不会错误地预测上楼时的平稳活动。事实上，与朴素贝叶斯模型中的91个预测相比，在这种情况下只有一个预测是错误的。</p><p id="399c" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">接下来，我们来看看哪些变量是最重要的。下表再次证实了X轴的重力相关特征(<code class="fe oe of og lj b">tGravityAccminX</code>和<code class="fe oe of og lj b">angleXgravityMean</code>)对我们模型的重要性。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="5694" class="ln lo it lj b gy lp lq l lr ls">for (model in dt$models) {<br/>  var_imp &lt;- varImp(model)<br/>  var_imp &lt;- var_imp %&gt;% slice_max(Overall, n = 10)<br/>  print(var_imp)<br/>}</span><span id="3e20" class="ln lo it lj b gy lt lq l lr ls">#&gt;                             Overall<br/>#&gt; tGravityAccminX            1647.338<br/>#&gt; tGravityAccmeanX           1522.782<br/>#&gt; tGravityAccenergyX         1521.581<br/>#&gt; angleXgravityMean          1521.581<br/>#&gt; tGravityAccmaxX            1505.993<br/>#&gt; fBodyAccJerkbandsEnergy116 1374.982<br/>#&gt; fBodyAccJerkbandsEnergy124 1374.982<br/>#&gt; fBodyAccmadX               1374.982<br/>#&gt; fBodyAccmeanX              1374.982<br/>#&gt; tBodyAccJerkmadX           1374.178<br/>#&gt;                        Overall<br/>#&gt; angleXgravityMean     1494.691<br/>#&gt; tGravityAccenergyX    1494.691<br/>#&gt; tGravityAccmeanX      1494.691<br/>#&gt; tGravityAccminX       1494.691<br/>#&gt; tGravityAccmaxX       1483.883<br/>#&gt; fBodyAccJerkentropyX  1376.017<br/>#&gt; fBodyAccmadX          1376.017<br/>#&gt; fBodyAccmeanX         1376.017<br/>#&gt; tBodyAccJerkmadX      1376.017<br/>#&gt; tBodyAccJerkMagenergy 1376.017<br/>#&gt;                      Overall<br/>#&gt; angleXgravityMean   1504.419<br/>#&gt; tGravityAccenergyX  1504.419<br/>#&gt; tGravityAccmeanX    1504.419<br/>#&gt; tGravityAccminX     1504.419<br/>#&gt; tGravityAccmaxX     1488.823<br/>#&gt; fBodyAccJerkenergyX 1370.566<br/>#&gt; fBodyAccmadX        1370.566<br/>#&gt; fBodyAccmeanX       1370.566<br/>#&gt; tBodyAccJerkenergyX 1370.566<br/>#&gt; tBodyAccJerkstdX    1370.566<br/>#&gt;                      Overall<br/>#&gt; tGravityAccminX     1528.936<br/>#&gt; tGravityAccmeanX    1527.734<br/>#&gt; angleXgravityMean   1526.532<br/>#&gt; tGravityAccenergyX  1526.532<br/>#&gt; tGravityAccmaxX     1508.549<br/>#&gt; tBodyAccJerkenergyX 1387.769<br/>#&gt; tBodyAccJerkmadX    1387.769<br/>#&gt; tBodyAccJerkstdX    1387.769<br/>#&gt; tBodyAccmaxX        1387.769<br/>#&gt; tBodyAccstdX        1387.769<br/>#&gt;                             Overall<br/>#&gt; tGravityAccminX            1531.881<br/>#&gt; tGravityAccmeanX           1530.679<br/>#&gt; angleXgravityMean          1529.478<br/>#&gt; tGravityAccenergyX         1529.478<br/>#&gt; tGravityAccmaxX            1512.692<br/>#&gt; fBodyAccJerkbandsEnergy116 1379.583<br/>#&gt; fBodyAccJerkbandsEnergy124 1379.583<br/>#&gt; fBodyAccmadX               1379.583<br/>#&gt; fBodyAccmeanX              1379.583<br/>#&gt; tBodyAccJerkmadX           1378.776</span></pre><p id="40c7" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">通常情况下，决策树模型倾向于过度适应训练数据集，因为它们可以很容易地适应数据中的噪声。幸运的是，这不是我们的情况，因为正如下面可以看到的，除了第四次折叠，训练和测试数据集的精度都很接近。因此，树木修剪是不必要的。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="03b3" class="ln lo it lj b gy lp lq l lr ls">print(dt$acc_train)</span><span id="5d2c" class="ln lo it lj b gy lt lq l lr ls">#&gt; [1] 0.8897925 0.8959707 0.8811845 0.8897192 0.8691917</span><span id="05b5" class="ln lo it lj b gy lt lq l lr ls">print(dt$acc_test)</span><span id="2454" class="ln lo it lj b gy lt lq l lr ls">#&gt; [1] 0.8660194 0.8914177 0.8643096 0.7902098 0.8855037</span></pre><h2 id="f14a" class="ln lo it bd na on oo dn ne op oq dp ni md or os nk mh ot ou nm ml ov ow no iz bi translated">k-最近邻</h2><p id="6d19" class="pw-post-body-paragraph lu lv it lw b lx nq kd lz ma nr kg mc md ns mf mg mh nt mj mk ml nu mn mo mp im bi translated">由于k-NN是一种基于距离的模型，因此数据集必须在建模之前进行归一化，以便模型可以平等地对待每个要素。换句话说，如果某个特征与其他特征相比具有相对较大的值，那么它将在选择数据点的邻居时对模型产生主要影响。但是在我们的例子中，我们没有对数据集进行任何规范化，原因已经在建模部分的开头解释过了。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="f98e" class="ln lo it lj b gy lp lq l lr ls">knn &lt;- crossvalidate(uci_har, 5, 'knn')<br/>cat("k-Nearest Neighbors Accuracy:", knn$acc)</span><span id="fd26" class="ln lo it lj b gy lt lq l lr ls">#&gt; k-Nearest Neighbors Accuracy: 0.8925138</span></pre><p id="4645" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">k-NN模型给出了比决策树模型更好的结果，准确率为89%。同样，这是由于我们的数据集是高度可分离的，因此k-NN算法可以很容易地对每个活动进行分组。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="9d50" class="ln lo it lj b gy lp lq l lr ls">knn$cm</span><span id="6fad" class="ln lo it lj b gy lt lq l lr ls">#&gt;                     Reference<br/>#&gt; Prediction           LAYING SITTING STANDING WALKING WALKING_DOWNSTAIRS WALKING_UPSTAIRS<br/>#&gt;   LAYING               1926      13        0       0                  0                0<br/>#&gt;   SITTING                 5    1369      245       0                  0                0<br/>#&gt;   STANDING                5     390     1659       0                  0                0<br/>#&gt;   WALKING                 1       0        1    1658                 98               90<br/>#&gt;   WALKING_DOWNSTAIRS      0       0        0      35               1178               52<br/>#&gt;   WALKING_UPSTAIRS        7       5        1      29                130             1402</span></pre><p id="398f" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">然而，k-NN模型在区分坐着和站着活动方面不如决策树模型。此外，一些静止的活动被预测为上楼。另一方面，与决策树模型相比，更多的移动活动被正确预测。</p><p id="d714" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">通过在训练和测试数据集上比较准确性，可以看出该模型恰到好处，具有低偏差和方差。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="24b3" class="ln lo it lj b gy lp lq l lr ls">print(knn$acc_train)</span><span id="44d8" class="ln lo it lj b gy lt lq l lr ls">#&gt; [1] 0.9299672 0.9269841 0.9332196 0.9308184 0.9335673</span><span id="18d6" class="ln lo it lj b gy lt lq l lr ls">print(knn$acc_test)</span><span id="bf3b" class="ln lo it lj b gy lt lq l lr ls">#&gt; [1] 0.9169903 0.9184448 0.8781653 0.8516484 0.8958231</span></pre><h2 id="ebbe" class="ln lo it bd na on oo dn ne op oq dp ni md or os nk mh ot ou nm ml ov ow no iz bi translated">随机森林</h2><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="116f" class="ln lo it lj b gy lp lq l lr ls">rf &lt;- crossvalidate(uci_har, 5, 'rf')<br/>cat("Random Forest Accuracy:", rf$acc)</span><span id="1bc0" class="ln lo it lj b gy lt lq l lr ls">#&gt; Random Forest Accuracy: 0.9336829</span></pre><p id="7e92" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">与其他模型相比，随机森林模型给出了迄今为止最好的结果，准确率高达93%。特别是，随机森林几乎总是比决策树好，原因如下:</p><ol class=""><li id="f1af" class="nv nw it lw b lx ly ma mb md nx mh ny ml nz mp oa ob oc od bi translated">随机森林是许多决策树模型的集合。它基于许多决策树的多数投票，因此倾向于减少单个决策树预测的错误。</li><li id="fb02" class="nv nw it lw b lx oh ma oi md oj mh ok ml ol mp oa ob oc od bi translated">随机森林执行bootstrap聚合，生成一系列模型，将弱学习者转换为强学习者，从而克服一个决策树的过拟合问题。</li></ol><p id="c9bc" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">然而，这些优点并非没有缺点:随机森林模型比决策树训练更慢，更难解释。</p><p id="9c83" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">现在让我们看看混淆矩阵。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="d8a6" class="ln lo it lj b gy lp lq l lr ls">rf$cm</span><span id="47a0" class="ln lo it lj b gy lt lq l lr ls">#&gt;                     Reference<br/>#&gt; Prediction           LAYING SITTING STANDING WALKING WALKING_DOWNSTAIRS WALKING_UPSTAIRS<br/>#&gt;   LAYING               1942      15        0       0                  0                0<br/>#&gt;   SITTING                 0    1626      189       0                  0                0<br/>#&gt;   STANDING                0     135     1717       0                  0                0<br/>#&gt;   WALKING                 0       0        0    1585                 18               37<br/>#&gt;   WALKING_DOWNSTAIRS      0       0        0      27               1293               54<br/>#&gt;   WALKING_UPSTAIRS        2       1        0     110                 95             1453</span></pre><p id="07ab" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">随机森林模型仍然很难弄清楚哪个是坐着的，哪个是站着的，哪个是从移动活动中来的。然而，除了这些错误之外，这个模型只错分了18个其他的观察值，这是所有观察值的一小部分。</p><p id="0513" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">根据下面的变量重要性表，我们看到随机森林模型更喜欢重力相关的特征，而不是身体相关的特征。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="60b6" class="ln lo it lj b gy lp lq l lr ls">for (model in rf$models) {<br/>  var_imp &lt;- varImp(model)<br/>  var_imp &lt;- var_imp %&gt;% slice_max(Overall, n = 10)<br/>  print(var_imp)<br/>}</span><span id="424a" class="ln lo it lj b gy lt lq l lr ls">#&gt;                     Overall<br/>#&gt; tGravityAccmeanX   233.5234<br/>#&gt; tGravityAccminX    212.9809<br/>#&gt; angleXgravityMean  190.1192<br/>#&gt; tGravityAccmaxX    185.7354<br/>#&gt; angleYgravityMean  168.6782<br/>#&gt; tGravityAccenergyX 158.2211<br/>#&gt; tGravityAccminY    152.9756<br/>#&gt; tGravityAccmaxY    149.8530<br/>#&gt; tGravityAccmeanY   128.6168<br/>#&gt; tGravityAccenergyY 115.0822<br/>#&gt;                      Overall<br/>#&gt; tGravityAccmeanX   215.90652<br/>#&gt; tGravityAccminX    199.06699<br/>#&gt; tGravityAccenergyX 187.14571<br/>#&gt; tGravityAccmaxX    174.64894<br/>#&gt; angleXgravityMean  170.14726<br/>#&gt; tGravityAccmaxY    148.36554<br/>#&gt; angleYgravityMean  147.43523<br/>#&gt; tGravityAccmeanY   136.34275<br/>#&gt; tGravityAccminY    132.14115<br/>#&gt; tGravityAccenergyY  83.03708<br/>#&gt;                     Overall<br/>#&gt; angleXgravityMean  211.0124<br/>#&gt; tGravityAccminX    193.4731<br/>#&gt; tGravityAccmaxX    183.6834<br/>#&gt; tGravityAccenergyX 178.2531<br/>#&gt; tGravityAccmaxY    175.3123<br/>#&gt; tGravityAccmeanX   170.4459<br/>#&gt; tGravityAccmeanY   166.4416<br/>#&gt; tGravityAccminY    164.2081<br/>#&gt; angleYgravityMean  159.2264<br/>#&gt; tGravityAccenergyY 113.4814<br/>#&gt;                     Overall<br/>#&gt; tGravityAccmaxX    214.2470<br/>#&gt; tGravityAccminX    201.6110<br/>#&gt; tGravityAccenergyX 198.3143<br/>#&gt; angleXgravityMean  191.6710<br/>#&gt; tGravityAccmeanY   185.8804<br/>#&gt; tGravityAccmeanX   182.7646<br/>#&gt; tGravityAccmaxY    179.4252<br/>#&gt; angleYgravityMean  172.8559<br/>#&gt; tGravityAccminY    171.5347<br/>#&gt; tGravityAccenergyY 102.5362<br/>#&gt;                      Overall<br/>#&gt; tGravityAccmeanX   208.67569<br/>#&gt; angleXgravityMean  202.43801<br/>#&gt; tGravityAccminX    192.91251<br/>#&gt; tGravityAccenergyX 185.74270<br/>#&gt; tGravityAccmaxX    158.31243<br/>#&gt; tGravityAccmaxY    148.26482<br/>#&gt; angleYgravityMean  145.74691<br/>#&gt; tGravityAccmeanY   142.97585<br/>#&gt; tGravityAccminY    126.27075<br/>#&gt; tGravityAccenergyY  95.61133</span></pre><p id="edd1" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">最后，从下面的训练和测试精度来看，很明显，该模型在训练和测试数据集上表现得非常好，尽管在第三次和第四次折叠中，测试精度仍然略低于91%。我们已经知道，如果我们从决策树模型切换到随机森林(由于装袋和随机特征选择)，过度拟合的趋势应该会减少。然而，泛化误差不会变为零。随着添加更多的树，泛化误差的方差将趋近于零，但偏差不会！</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="b0d5" class="ln lo it lj b gy lp lq l lr ls">print(rf$acc_train)</span><span id="55b3" class="ln lo it lj b gy lt lq l lr ls">#&gt; [1] 0.9815512 0.9805861 0.9837923 0.9865011 0.9842691</span><span id="9f88" class="ln lo it lj b gy lt lq l lr ls">print(rf$acc_test)</span><span id="e184" class="ln lo it lj b gy lt lq l lr ls">#&gt; [1] 0.9631068 0.9720247 0.9096990 0.8971029 0.9248157</span></pre><p id="7e7e" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">我们可以通过超参数调整来进一步改进模型。预计通过修剪树木，我们可以交易一些偏差，降低两个值。这是通过增加随机森林模型中的<code class="fe oe of og lj b">nodesize</code>参数来实现的。参考R文档，<code class="fe oe of og lj b">nodesize</code>是终端节点的最小尺寸。将该数值设置得越大，生成的树就越小(因此花费的时间也就越少)。对于分类问题，默认值为1，这往往会使模型过度适应数据中的噪声。</p><p id="e549" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">除了<code class="fe oe of og lj b">nodesize</code>，我们还将调优<code class="fe oe of og lj b">mtry</code>(在每次分割时随机抽样作为候选变量的变量数量，在我们的例子中默认为sqrt(561) = 23)。我们将通过改变<code class="fe oe of og lj b">nodesize</code>到<code class="fe oe of og lj b">c(3,5,7)</code>和<code class="fe oe of og lj b">mtry</code>到<code class="fe oe of og lj b">c(11,16)</code>来进行网格搜索。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="ff66" class="ln lo it lj b gy lp lq l lr ls"># establish a list of possible values for nodesize and mtry<br/>nodesize &lt;- c(3, 5, 7)<br/>mtry &lt;- c(11, 16)</span><span id="6968" class="ln lo it lj b gy lt lq l lr ls"># create a data frame containing all combinations <br/>hyper_grid &lt;- expand.grid(mtry = mtry, nodesize = nodesize)</span><span id="51d0" class="ln lo it lj b gy lt lq l lr ls"># initialize empty vectors to store the results<br/>rf_acc &lt;- c()<br/>rf_acc_train &lt;- c()<br/>rf_acc_test &lt;- c()</span><span id="ecac" class="ln lo it lj b gy lt lq l lr ls"># loop over the rows of hyper_grid<br/>for (i in 1:nrow(hyper_grid)) {<br/>  # cross validate<br/>  rf_tuning &lt;- crossvalidate(uci_har, 5, 'rf', <br/>                             tuning = TRUE, mtry = hyper_grid$mtry[i], nodesize = hyper_grid$nodesize[i])<br/>  # store the results<br/>  rf_acc[i] &lt;- rf_tuning$acc<br/>  rf_acc_train &lt;- c(rf_acc_train, list(rf_tuning$acc_train))<br/>  rf_acc_test &lt;- c(rf_acc_test, list(rf_tuning$acc_test))<br/>}</span><span id="5d2a" class="ln lo it lj b gy lt lq l lr ls"># identify optimal set of hyperparameters based on accuracy<br/>opt_i &lt;- which.max(rf_acc)<br/>print(hyper_grid[opt_i,])</span><span id="8b47" class="ln lo it lj b gy lt lq l lr ls">#&gt;   mtry nodesize<br/>#&gt; 5   11        7</span></pre><p id="9e8c" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">找到的最佳超参数是<code class="fe oe of og lj b">nodesize</code>的7和<code class="fe oe of og lj b">mtry</code>的11。有了这些，准确率稍微提高了一点，接近94%，如下图所示。此外，所有的测试精度在褶皱之间更加一致，并且具有91%以上的值。</p><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="dd77" class="ln lo it lj b gy lp lq l lr ls">print(rf_acc[opt_i])</span><span id="9ecb" class="ln lo it lj b gy lt lq l lr ls">#&gt; [1] 0.9370813</span><span id="195b" class="ln lo it lj b gy lt lq l lr ls">print(rf_acc_train[opt_i])</span><span id="15a5" class="ln lo it lj b gy lt lq l lr ls">#&gt; [[1]]<br/>#&gt; [1] 0.9815512 0.9788767 0.9820863 0.9849343 0.9831801</span><span id="8ab4" class="ln lo it lj b gy lt lq l lr ls">print(rf_acc_test[opt_i])</span><span id="1d9a" class="ln lo it lj b gy lt lq l lr ls">#&gt; [[1]]<br/>#&gt; [1] 0.9684466 0.9687055 0.9182991 0.9130869 0.9154791</span></pre><h1 id="3122" class="mz lo it bd na nb nc nd ne nf ng nh ni ki nj kj nk kl nl km nm ko nn kp no np bi translated">结论</h1><pre class="ks kt ku kv gt li lj lk ll aw lm bi"><span id="6954" class="ln lo it lj b gy lp lq l lr ls">rbind("Naive Bayes" = nb$acc, "Decision Tree" = dt$acc, "k-Nearest Neighbors" = knn$acc, "Random Forest" = max(rf_acc))</span><span id="1765" class="ln lo it lj b gy lt lq l lr ls">#&gt;                      Accuracy<br/>#&gt; Naive Bayes         0.7258957<br/>#&gt; Decision Tree       0.8599864<br/>#&gt; k-Nearest Neighbors 0.8925138<br/>#&gt; Random Forest       0.9370813</span></pre><p id="8d4d" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">根据上面的准确度表，Random Forest显然是最佳模型。Random Forest能够根据人们的手机行为识别人类活动，准确率高达94%。另一方面，随机森林运行缓慢，因为默认情况下它是500个决策树的集合。当然，我们也可以尝试更简单的模型，如One-vs-Rest逻辑回归，或目前业界非常标准的boosting模型，如XGBoost或LightGBM，然后比较结果。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oy"><img src="../Images/e1a6e3674ab93bcb99796285f9d0175c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*6HsoGpmIb1oibJc_JWbqJA.gif"/></div></div></figure></div><div class="ab cl oz pa hx pb" role="separator"><span class="pc bw bk pd pe pf"/><span class="pc bw bk pd pe pf"/><span class="pc bw bk pd pe"/></div><div class="im in io ip iq"><p id="4859" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">🔥<em class="ox">你好！如果你喜欢这个故事，想支持我这个作家，可以考虑</em> <a class="ae lh" href="https://dwiuzila.medium.com/membership" rel="noopener"> <strong class="lw jd"> <em class="ox">成为会员</em> </strong> </a> <em class="ox">。每月只需5美元，你就可以无限制地阅读媒体上的所有报道。如果你注册使用我的链接，我会赚一小笔佣金。</em></p><p id="bd58" class="pw-post-body-paragraph lu lv it lw b lx ly kd lz ma mb kg mc md me mf mg mh mi mj mk ml mm mn mo mp im bi translated">🔖<em class="ox">想了解更多关于经典机器学习模型如何工作以及如何优化其参数的信息？或者MLOps大型项目的例子？有史以来最优秀的文章呢？继续阅读:</em></p><div class="pg ph gp gr pi"><div role="button" tabindex="0" class="ab bv gv cb fp pj pk bn pl lb ex"><div class="pm l"><div class="ab q"><div class="l di"><img alt="Albers Uzila" class="l de bw pn po fe" src="../Images/b4f51438d99b29f789091dd239d7cfa6.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*WVCVz-tM5PW1TaWqnVXRLQ.jpeg"/><div class="fb bw l pn po fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://dwiuzila.medium.com/?source=post_page-----228b9e75c306--------------------------------" rel="noopener follow" target="_top">艾伯斯·乌兹拉</a></p></div></div><div class="pr ps gw l"><h2 class="bd jd uw nv fp ux fr fs uy fu fw jc bi translated">从零开始的机器学习</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi uz au va vb vc rm vd an eh ei ve vf vg el em eo de bk ep" href="https://dwiuzila.medium.com/list/machine-learning-from-scratch-b35db8650093?source=post_page-----228b9e75c306--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="vh l fo"><span class="bd b dl z dk">8 stories</span></div></div></div><div class="qe dh qf fp ab qg fo di"><div class="di pw bv px py"><div class="dh l"><img alt="" class="dh" src="../Images/4b97f3062e4883b24589972b2dc45d7e.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*CWNoicci28F2TUQc-vKijw.png"/></div></div><div class="di pw bv pz qa qb"><div class="dh l"><img alt="" class="dh" src="../Images/b1f7021514ba57a443fe0db4b7001b26.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*wSRsSHYnIiGJFAqC"/></div></div><div class="di bv qc qd qb"><div class="dh l"><img alt="" class="dh" src="../Images/deb73e42c79667024a46c2c8902b81fa.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*HVEz7KwzO0tv1Q4d"/></div></div></div></div></div><div class="pg ph gp gr pi"><div role="button" tabindex="0" class="ab bv gv cb fp pj pk bn pl lb ex"><div class="pm l"><div class="ab q"><div class="l di"><img alt="Albers Uzila" class="l de bw pn po fe" src="../Images/b4f51438d99b29f789091dd239d7cfa6.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*WVCVz-tM5PW1TaWqnVXRLQ.jpeg"/><div class="fb bw l pn po fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://dwiuzila.medium.com/?source=post_page-----228b9e75c306--------------------------------" rel="noopener follow" target="_top">艾伯斯·乌兹拉</a></p></div></div><div class="pr ps gw l"><h2 class="bd jd uw nv fp ux fr fs uy fu fw jc bi translated">高级优化方法</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi uz au va vb vc rm vd an eh ei ve vf vg el em eo de bk ep" href="https://dwiuzila.medium.com/list/advanced-optimization-methods-26e264a361e4?source=post_page-----228b9e75c306--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="vh l fo"><span class="bd b dl z dk">7 stories</span></div></div></div><div class="qe dh qf fp ab qg fo di"><div class="di pw bv px py"><div class="dh l"><img alt="" class="dh" src="../Images/15b3188b0f29894c2bcf3d0965515f44.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*BVMamoNudzn9UlAE"/></div></div><div class="di pw bv pz qa qb"><div class="dh l"><img alt="" class="dh" src="../Images/3249ba2cf680952e2ccdff36d8ebf4a7.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*C1fv3HJdh1RBspwN"/></div></div><div class="di bv qc qd qb"><div class="dh l"><img alt="" class="dh" src="../Images/a73f0494533d8a08b01c2b899373d2b9.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*QZvzgiM2VnhYyx8M"/></div></div></div></div></div><div class="pg ph gp gr pi"><div role="button" tabindex="0" class="ab bv gv cb fp pj pk bn pl lb ex"><div class="pm l"><div class="ab q"><div class="l di"><img alt="Albers Uzila" class="l de bw pn po fe" src="../Images/b4f51438d99b29f789091dd239d7cfa6.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*WVCVz-tM5PW1TaWqnVXRLQ.jpeg"/><div class="fb bw l pn po fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://dwiuzila.medium.com/?source=post_page-----228b9e75c306--------------------------------" rel="noopener follow" target="_top">艾伯斯·乌兹拉</a></p></div></div><div class="pr ps gw l"><h2 class="bd jd uw nv fp ux fr fs uy fu fw jc bi translated">MLOps大型项目</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi uz au va vb vc rm vd an eh ei ve vf vg el em eo de bk ep" href="https://dwiuzila.medium.com/list/mlops-megaproject-6a3bf86e45e4?source=post_page-----228b9e75c306--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="vh l fo"><span class="bd b dl z dk">6 stories</span></div></div></div><div class="qe dh qf fp ab qg fo di"><div class="di pw bv px py"><div class="dh l"><img alt="" class="dh" src="../Images/41b5d7dd3997969f3680648ada22fd7f.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*EBS8CP_UnStLesXoAvjeAQ.png"/></div></div><div class="di pw bv pz qa qb"><div class="dh l"><img alt="" class="dh" src="../Images/41befac52d90334c64eef7fc5c4b4bde.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*XLpRKnIMcJzBzCwvXrLvsw.png"/></div></div><div class="di bv qc qd qb"><div class="dh l"><img alt="" class="dh" src="../Images/80908ef475e97fbc42efe3fae0dfcff5.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*K_gzBmjv-ZHlU0Q6HeXclQ.jpeg"/></div></div></div></div></div><div class="pg ph gp gr pi"><div role="button" tabindex="0" class="ab bv gv cb fp pj pk bn pl lb ex"><div class="pm l"><div class="ab q"><div class="l di"><img alt="Albers Uzila" class="l de bw pn po fe" src="../Images/b4f51438d99b29f789091dd239d7cfa6.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*WVCVz-tM5PW1TaWqnVXRLQ.jpeg"/><div class="fb bw l pn po fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated">艾伯斯·乌兹拉</p></div></div><div class="pr ps gw l"><h2 class="bd jd uw nv fp ux fr fs uy fu fw jc bi translated">我最好的故事</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi uz au va vb vc rm vd an eh ei ve vf vg el em eo de bk ep" href="https://dwiuzila.medium.com/list/my-best-stories-d8243ae80aa0?source=post_page-----228b9e75c306--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="vh l fo"><span class="bd b dl z dk">24 stories</span></div></div></div><div class="qe dh qf fp ab qg fo di"><div class="di pw bv px py"><div class="dh l"><img alt="" class="dh" src="../Images/0c862c3dee2d867d6996a970dd38360d.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*K1SQZ1rzr4cb-lSi"/></div></div><div class="di pw bv pz qa qb"><div class="dh l"><img alt="" class="dh" src="../Images/392d63d181090365a63dc9060573bcff.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*hSKy6kKorAfHjHOK"/></div></div><div class="di bv qc qd qb"><div class="dh l"><img alt="" class="dh" src="../Images/f51725806220b60eccf5d4c385c700e9.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*HiyGwoGOMI5Ao_fd"/></div></div></div></div></div><div class="pg ph gp gr pi"><div role="button" tabindex="0" class="ab bv gv cb fp pj pk bn pl lb ex"><div class="pm l"><div class="ab q"><div class="l di"><img alt="Albers Uzila" class="l de bw pn po fe" src="../Images/b4f51438d99b29f789091dd239d7cfa6.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*WVCVz-tM5PW1TaWqnVXRLQ.jpeg"/><div class="fb bw l pn po fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://dwiuzila.medium.com/?source=post_page-----228b9e75c306--------------------------------" rel="noopener follow" target="_top">艾伯斯·乌兹拉</a></p></div></div><div class="pr ps gw l"><h2 class="bd jd uw nv fp ux fr fs uy fu fw jc bi translated">R中的数据科学</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi uz au va vb vc rm vd an eh ei ve vf vg el em eo de bk ep" href="https://dwiuzila.medium.com/list/data-science-in-r-0a8179814b50?source=post_page-----228b9e75c306--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="vh l fo"><span class="bd b dl z dk">7 stories</span></div></div></div><div class="qe dh qf fp ab qg fo di"><div class="di pw bv px py"><div class="dh l"><img alt="" class="dh" src="../Images/e52e43bf7f22bfc0889cc794dcf734dd.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*10B3radiyQGAp-QA"/></div></div><div class="di pw bv pz qa qb"><div class="dh l"><img alt="" class="dh" src="../Images/945fa9100c2a00b46f8aca3d3975f288.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*o6A863Vdwq7ThlmW"/></div></div><div class="di bv qc qd qb"><div class="dh l"><img alt="" class="dh" src="../Images/3ca9e4b148297dbc4e7da0a180cf9c99.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*ekmX89TW6N8Bi8bL"/></div></div></div></div></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://dwiuzila.medium.com/membership"><div class="gh gi qk"><img src="../Images/f767019309a71e9b3b70d2f9b1016aad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q_dzEmnimgItuotIZ-y73A.png"/></div></a></figure></div></div>    
</body>
</html>