<html>
<head>
<title>Sex and Drugs and Organic Topic Modeling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">性、毒品和有机主题建模</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sex-and-drugs-and-organic-topic-modeling-91a9776d32e6?source=collection_archive---------18-----------------------#2021-12-01">https://towardsdatascience.com/sex-and-drugs-and-organic-topic-modeling-91a9776d32e6?source=collection_archive---------18-----------------------#2021-12-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1b89" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用GPT J分析摇滚歌曲的歌词</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/075e7b9531db3f182943bd6c06692cd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UJMhJsRXWxulRuseNTLU8Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">性、毒品和有机主题建模</strong>，作者提供的图表</p></figure><p id="74a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">问题</strong>:摇滚歌词中最常见的话题是哪个？</p><p id="7004" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">回答</strong>:甲壳虫乐队在他们的歌中总结道，“你所需要的只是爱。”</p><p id="9eb0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为主题建模的实验，我使用最新的人工智能系统分析了50个摇滚乐队的12，000首歌曲。本文将介绍我使用的过程，并解释所有的组件，包括运行在Google Colab的TPU GPT j上的GPT 3的免费版本。请注意，您可以使用这些技术来查找和分析任何文本数据集中的主题。</p><h1 id="8edd" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">RockTopics概述</h1><p id="a361" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这是这个实验的高级图表，我称之为RockTopics。在简要讨论了主要组件之后，我将在下面的小节中更详细地解释处理步骤。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/7fef14bcabb7fa31b592a1de11b90e6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m6QWtq5aNqJi3os40KUGqw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky"> RockTopics组件</strong>，作者图解</p></figure><p id="849f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我从我在Kaggle上找到的128K歌词数据库开始，我通过找到它与滚石杂志上100个最伟大的摇滚乐队列表的交集来过滤歌曲的数量。这产生了来自50个乐队的13K首歌曲。</p><p id="58f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该系统的核心是开源的GPT-J转换器，它是使用Pile上的网格转换器JAX训练的，Pile是一个大型英语文本语料库。我把每首歌的歌词一行一行输入GPT J，用几个简短的提示找到每一行的主题。</p><p id="cd82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我使用谷歌通用句子编码器将每个发现的主题转换成一个512个数字的数组。然后，我结合使用TSNE降维和k-means聚类来分析主题，并使用matplotlib生成图表。</p><p id="6664" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据分析，以下是最常见的话题。注意，相似的主题聚集在一起，圆圈的大小代表歌词中出现的次数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/025a101e472050a0d3b5c54d8e2bca26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YGDRyFHda4kuhFUMadyKNA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">摇滚话题</strong>，作者图片</p></figure><h1 id="1181" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">系统组件</h1><p id="ee38" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">以下部分详细描述了我使用的组件和过程。</p><h2 id="b37e" class="mu lw it bd lx mv mw dn mb mx my dp mf li mz na mh lm nb nc mj lq nd ne ml nf bi translated">歌词数据库</h2><p id="c975" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">对于歌词，我找到了一个不错的数据集<a class="ae ng" href="https://www.kaggle.com/neisse/scrapped-lyrics-from-6-genres" rel="noopener ugc nofollow" target="_blank">，作者是巴西的人工智能研究员安德森·尼斯(Anderson Neisse)。该数据集包含来自6个流派的2940个乐队的128083首歌曲。他在</a><a class="ae ng" href="https://opendatacommons.org/licenses/dbcl/1-0/" rel="noopener ugc nofollow" target="_blank">数据库内容许可</a>下发布了数据集。</p><p id="a203" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我上面提到的，我用《滚石》杂志的<a class="ae ng" href="https://www.rollingstone.com/music/music-lists/100-greatest-artists-147446/" rel="noopener ugc nofollow" target="_blank"> 100位最伟大的录音艺术家</a>名单过滤了歌曲列表。结果列表有来自50个乐队的11，959首歌曲，包括披头士、鲍勃·迪伦、猫王、滚石、查克·贝里和吉米·亨德里克斯。总共有185003行歌词。</p><h2 id="eb09" class="mu lw it bd lx mv mw dn mb mx my dp mf li mz na mh lm nb nc mj lq nd ne ml nf bi translated">GPT J</h2><p id="a6c3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">GPT-J是一个人工智能模型，用于分析和生成使用<a class="ae ng" href="https://github.com/kingoflolz/mesh-transformer-jax/" rel="noopener ugc nofollow" target="_blank">网格转换器JAX </a>训练的文本，这是一个使用并行处理训练大型模型的可扩展系统。该模型在一个名为Pile的大型文本语料库上进行训练，这是一个825千兆字节的英语文本数据集，旨在训练大规模的语言模型[1]。</p><p id="4137" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GPT-J是由<a class="ae ng" href="https://www.eleuther.ai/" rel="noopener ugc nofollow" target="_blank"> EleutherAI </a>创建的，这是一个致力于开源人工智能研究的草根研究人员集体。该系统模仿OpenAI的GPT-3，但GTP-J在Apache 2.0开源许可下可以免费使用。</p><p id="3130" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在这里免费试用GPT J，<a class="ae ng" href="https://6b.eleuther.ai/" rel="noopener ugc nofollow" target="_blank">https://6b.eleuther.ai/</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/43e455ae49295b017b85e262aa506144.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gfIcQlvE1nGWIGRC8szLaw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">EleutherAI的GPT J，作者图片</p></figure><p id="97b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如你所见，它已经知道了摇滚歌曲中的头号话题。接下来，我会告诉你如何找到歌词中每一行的主题。</p><h2 id="76c9" class="mu lw it bd lx mv mw dn mb mx my dp mf li mz na mh lm nb nc mj lq nd ne ml nf bi translated">在歌词中寻找主题</h2><p id="6721" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">与其他大型transformer模型类似，GPG-J的工作方式是传入一个提示，结果系统会生成连续的文本。我使用下面的提示从歌曲的每一行获取主题。请注意，这被称为“少量”推理，因为给出了几个例子。</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="9c12" class="mu lw it nj b gy nn no l np nq"><strong class="nj iu">Determine the topic for these lyrics.</strong></span><span id="b1d0" class="mu lw it nj b gy nr no l np nq"><strong class="nj iu">Line</strong>: Ah, look at all the lonely people!<br/><strong class="nj iu">Topic</strong>: Loneliness</span><span id="b678" class="mu lw it nj b gy nr no l np nq"><strong class="nj iu">Line</strong>: Wiping the dirt from his hands as he walks from the grave.<br/><strong class="nj iu">Topic</strong>: Death</span><span id="3238" class="mu lw it nj b gy nr no l np nq"><strong class="nj iu">Line</strong>: Little darling, the smiles returning to the faces.<br/><strong class="nj iu">Topic</strong>: Happiness</span><span id="5ef7" class="mu lw it nj b gy nr no l np nq"><strong class="nj iu">Line</strong>: Every breath you take.<br/><strong class="nj iu">Topic</strong>:</span></pre><p id="a197" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一行是对查询的一般描述，后面是三个示例行和主题。该系统将使用这些信息来获取所提问题的要点，并为最后一行“你的每一次呼吸”指定主题多次运行该查询将得到主题“呼吸”、“健康”、“生命”等。</p><p id="d81b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是警察的《你的每一次呼吸》前五行的题目。</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="b45f" class="mu lw it nj b gy nn no l np nq"><strong class="nj iu">Line                     Topic</strong><br/>Every breath you take    Breathing<br/>Every move you make      Movement<br/>Every bond you break     Leaving<br/>Every step you take      Walking<br/>I'll be watching you     Watching</span></pre><p id="6f29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个系统似乎做得很好，为台词找到了主题。注意，不仅仅是拉关键词。它总是以名词的形式陈述主题，有时会概括该行的意思来找到主题，就像它对离开和行走所做的那样。</p><p id="68a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，我发现对每个查询使用相同的示例有时会将示例主题“孤独”、“死亡”和“幸福”泄漏到结果中，从而增加它们的数量。为了最大限度地减少泄漏，我从中间结果中挑选了一个包含300个示例的列表，并编写了一些代码来为每个查询从大量的列表中随机选择三个示例。这似乎已经将渗漏减少(或分散)到统计上不显著的水平。</p><p id="2bbf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我发现，使用OpenAI的GPT-3 <a class="ae ng" href="https://beta.openai.com/docs/engines/instruct-series-beta" rel="noopener ugc nofollow" target="_blank">达芬奇-指导-贝塔</a>模型，使用“零射击”查询，意味着没有提供示例，可以完全避免泄漏问题。下面是提示。</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="9f73" class="mu lw it nj b gy nn no l np nq"><strong class="nj iu">Determine the topic for this line of lyrics.<br/>Line</strong>: Every breath you take.<br/><strong class="nj iu">Topic</strong>:</span></pre><p id="8d6e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果类似于GPT J，没有任何泄漏，因为没有例子。这种方法是首选的，但它是有代价的。虽然使用GPT-3的付费版本运行这个查询只需要0.0017美元，但在185，000条线路上运行它需要300多美元。</p><h2 id="bc61" class="mu lw it bd lx mv mw dn mb mx my dp mf li mz na mh lm nb nc mj lq nd ne ml nf bi translated"><strong class="ak">张量处理单元</strong></h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/ec843e753ade12db862c798b4e30b9ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/0*lFI4p2-dQ41WjqHm"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">张量处理单元</strong>，图片来源:<a class="ae ng" href="https://cloud.google.com/blog/products/ai-machine-learning/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu" rel="noopener ugc nofollow" target="_blank">谷歌博客</a></p></figure><p id="a7c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在过去的18个月里，我一直在使用Google Colab来运行我的人工智能实验。我一直在使用两种类型的处理器，中央处理器(CPU)和图形处理器(GPU)。CPU是自20世纪60年代以来就存在的通用计算机。GPU是在20世纪80年代为图形密集型操作开发的，并从2010年开始用于人工智能和ML。</p><p id="70e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2016年，谷歌推出了他们的<a class="ae ng" href="https://cloud.google.com/blog/products/ai-machine-learning/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu" rel="noopener ugc nofollow" target="_blank">张量处理单元</a> (TPU)，专门为训练和运行人工智能模型的实例而设计。自2020年以来，它们已经可以在谷歌Colab上使用。王禹带领一个来自哈佛的团队在GPU和TPU上测试人工智能模型的速度。他们发现，在运行大型模型时，TPU的性能比GPU高出3到7倍[2]。</p><p id="b516" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我用于运行GPT-J主题建模的RockTopics Colab是基于来自王贲EleutherAI的TPU <a class="ae ng" href="https://colab.research.google.com/github/kingoflolz/mesh-transformer-jax/blob/master/colab_demo.ipynb" rel="noopener ugc nofollow" target="_blank"> Colab </a>。每一行花了大约1.4秒，运行了大约三天来获得所有185，000行歌词的主题。</p><h2 id="468a" class="mu lw it bd lx mv mw dn mb mx my dp mf li mz na mh lm nb nc mj lq nd ne ml nf bi translated">通用句子编码器</h2><p id="d8f7" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在我收集了主题之后，我使用Google的通用句子编码器将每个主题短语转换成嵌入的512个浮点数的数组。这里有一些示例代码来展示它是如何工作的。</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="beb7" class="mu lw it nj b gy nn no l np nq">import tensorflow_hub as hub<br/>embed = hub.Module("https://tfhub.dev/google/universal-sentence-encoder-large/5")<br/>embedding = embed(["love loss"])<br/>print(embedding)</span></pre><p id="068f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果在这里。</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="84c5" class="mu lw it nj b gy nn no l np nq">tf.Tensor( [[-2.79744454e-02 -6.52119750e-03 1.32698761e-02<br/>4.50092048e-04 9.81796882e-04 3.18628997e-02 2.73146853e-02<br/>-1.10505158e-02 -2.71893758e-02 -5.06720766e-02 -3.20894904e-02<br/>...<br/>-1.08678043e-02 7.85474479e-03 -6.44846493e-03 -3.88006195e-02]], shape=(1, 512), dtype=float32)</span></pre><p id="6519" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然这些数字对人类来说没有任何意义，但它们代表了编码器多维空间中“失恋”的概念。在接下来的部分中，我将向您展示我是如何使用统计学来理解这些主题的。</p><h2 id="a7a8" class="mu lw it bd lx mv mw dn mb mx my dp mf li mz na mh lm nb nc mj lq nd ne ml nf bi translated">降维</h2><p id="22bf" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在每个嵌入中都有大量的信息。然而，我使用的第一步是降维(DR)来图形化地显示主题嵌入。这将通过将每个主题的维度数量从512个减少到两个来创建二维图表，从而帮助可视化数据。</p><p id="2ca9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">DR的两种标准方法是主成分分析(PCA)和T分布随机邻居嵌入(TSNE)。每种方法都试图保留数据的要点，同时减少维数。</p><p id="29f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PCA获取数据，将其转换为矩阵，使用一些复杂的数学运算来找出最显著的方差，然后将其转换回数据集。TSNE的工作原理是，在将输入数据点和表示相同数据点的数据点转换成低维表示后，迭代地最小化它们之间的差异。你可以在Luuk Derksen的文章<a class="ae ng" rel="noopener" target="_blank" href="/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b">中阅读更多关于PCA和TSNE方法的内容。</a></p><p id="bcd6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当使用主成分分析和TSNE从512个维度减少到两个维度时，前100个主题看起来像这样。每个圆圈的大小代表该主题在一行歌词中被发现的次数。你可以点击图片查看大图。</p><div class="kj kk kl km gt ab cb"><figure class="nt kn nu nv nw nx ny paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/e39c52c89740986c254a458a138fdc2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*-89kYP1RE6Cha8KgddwtnQ.png"/></div></figure><figure class="nt kn nz nv nw nx ny paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/28db4fc7ab002cb8f4a6862a9cbfb290.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*K-tBxqmGQ1v3JVo5Ovnp3g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk oa di ob oc translated"><strong class="bd ky">PCA和TSNE降维后的摇滚话题</strong>，作者图片</p></figure></div><p id="453a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以看到主成分分析减少了更紧密的集群，而TSNE减少了更多的主题。虽然PCA简化有一个更有趣的整体分组，但它使阅读主题标签变得困难，因为它们经常堆叠在另一个之上。总的来说，我觉得TSNE的简化更容易阅读。</p><h2 id="fef6" class="mu lw it bd lx mv mw dn mb mx my dp mf li mz na mh lm nb nc mj lq nd ne ml nf bi translated">确定图表的方向</h2><p id="73b3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在看图表时，你可能会问为什么主题在它们的空间位置上？虽然相对位置有意义，但整体空间方向是任意的。通用句子编码器在512维空间中指定短语含义的位置。尽管DR算法试图保持空间的一致性，但并不能保证任何特定的主题会落在任何特定的地方。</p><p id="c1ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了使图形的方向更加可预测，我任意选择主题<strong class="lb iu">时间</strong>来确定X轴的方向，主题<strong class="lb iu">音乐</strong>来确定Y轴的方向。下面是运行方向代码前后的图形。</p><div class="kj kk kl km gt ab cb"><figure class="nt kn od nv nw nx ny paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/ba504d9bbe8a2e1d97844112020c8f32.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*Zo04BY93y6TPWQ_PKrEnHQ.png"/></div></figure><figure class="nt kn oe nv nw nx ny paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/eb8741fa353a3c2a53b837bfe9ee0e1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*-c4lL3m621gXhjjAzTUOBA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk of di og oc translated"><strong class="bd ky">摇滚主题定位</strong>，作者图解</p></figure></div><p id="486d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图形定向后，<strong class="lb iu">时间</strong>话题现在在三点钟位置，<strong class="lb iu">音乐</strong>话题大致在12点钟位置。图定向的源代码是这里的<a class="ae ng" href="https://gist.github.com/robgon-art/ec5983cff11b0032854f2ff38029d7da" rel="noopener ugc nofollow" target="_blank"/>。</p><h2 id="c9bf" class="mu lw it bd lx mv mw dn mb mx my dp mf li mz na mh lm nb nc mj lq nd ne ml nf bi translated">k均值聚类</h2><p id="5422" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">你可能已经注意到有些主题是同义词。比如可以看到<strong class="lb iu">梦</strong>和<strong class="lb iu">梦</strong>，<strong class="lb iu">舞</strong>和<strong class="lb iu">舞</strong>等。，作为单独的主题。</p><p id="39d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了组合相似的主题，我使用了一种叫做k-means聚类的算法。该算法旨在将n个样本分成k个聚类，其中每个样本属于具有最近均值的聚类。</p><p id="e9fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是使用k-means将数据减少到50个聚类后主题的样子。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/14ac656dd0de12747375261870106c6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zHEcf3IYqXbJpBAadD7LuA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">摇滚话题群</strong>，作者图片</p></figure><p id="7e25" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以看到相似的主题被有效地分组在一起，像主题<strong class="lb iu">梦</strong>如何合并成<strong class="lb iu">梦</strong>和<strong class="lb iu">舞</strong>合并成<strong class="lb iu">舞</strong>等等。</p><p id="a586" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有一张图表，显示了按歌词主题平均值排列的乐队。圆圈的大小代表他们的歌曲目录中的行数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/572267ce9031070a4893f7f0d5fa10d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uYu64d-AHIRLTd3y6DbxLw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">按乐队分类的主题</strong>，按作者分类的图片</p></figure><p id="9a51" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看到你最喜欢的乐队登陆是相当有趣的。有些分组是有道理的，比如看到布鲁斯·斯普林斯汀挨着埃尔维斯·考斯特罗。但不知何故，沙滩男孩夹在电台司令和涅磐之间。我没想到会这样。</p><h1 id="9c58" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">讨论和后续步骤</h1><p id="6a47" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">使用大型transformer模型进行有机主题建模似乎可以很好地处理大型数据集。在Google Colab上运行GPT-J是一种经济高效的分析方法。我可以尝试的下一件事是微调GPT-J，在不指定例子的情况下找到主题，消除例子泄漏的问题。</p><p id="65df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个项目是观察这种主题建模技术与其他方法相比有多好。例如，我可以在20个新闻组数据集上运行它，看看它与最先进的系统双向对抗训练(BAT)[4]相比如何。虽然BAT方法使用一个较小的模型来执行主题建模的特定任务，但是我使用大型transformer模型的方法可以利用一般知识来产生更好的结果。</p><h1 id="8bc8" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">源代码和Colabs</h1><p id="c846" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这个项目的所有源代码都可以在GitHub上找到。我在<a class="ae ng" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank"> CC BY-SA许可</a>下发布了源代码。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/5852c0c55c55a1b8fc69f92d570e878a.png" data-original-src="https://miro.medium.com/v2/resize:fit:176/format:webp/0*3rJYV5PI1gE9D6-n.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">归属共享</strong></p></figure><h1 id="8e63" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">感谢</h1><p id="e424" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我要感谢詹尼弗·林和奥利弗·斯特瑞普对这个项目的帮助。</p><h1 id="ecc5" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">参考</h1><p id="0c2e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">[1] L. Gao等，<a class="ae ng" href="https://arxiv.org/pdf/2101.00027.pdf" rel="noopener ugc nofollow" target="_blank"> The Pile:一个用于语言建模的800GB多样化文本数据集</a> (2020)</p><p id="404e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2] Y. Wang等人，<a class="ae ng" href="https://arxiv.org/pdf/1907.10701.pdf" rel="noopener ugc nofollow" target="_blank">深度学习的、GPU和CPU平台的基准测试</a> (2019)</p><p id="d584" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[3] D. Cer等人，<a class="ae ng" href="https://arxiv.org/pdf/1803.11175.pdf" rel="noopener ugc nofollow" target="_blank">通用语句编码器</a> (2018)</p><p id="76f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[4] R.Wang等，<a class="ae ng" href="https://arxiv.org/pdf/2004.12331v1.pdf" rel="noopener ugc nofollow" target="_blank">双向对抗训练的神经主题建模</a> (2020)</p></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><p id="08ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了无限制地访问Medium上的所有文章，<a class="ae ng" href="https://robgon.medium.com/membership" rel="noopener">成为会员</a>，每月支付5美元。非会员每月只能看三个锁定的故事。</p></div></div>    
</body>
</html>