<html>
<head>
<title>Text analysis in the social sciences</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">社会科学中的文本分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/text-analysis-in-the-social-sciences-a-new-spectrum-of-possibilities-33adc44e8a0e?source=collection_archive---------29-----------------------#2021-06-28">https://towardsdatascience.com/text-analysis-in-the-social-sciences-a-new-spectrum-of-possibilities-33adc44e8a0e?source=collection_archive---------29-----------------------#2021-06-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="bce7" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><div class=""><h2 id="c859" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">一系列新的可能性</h2></div><p id="091f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">计算机科学家长期受益于允许他们从各种文本文档中提取信息的方法。他们的方法不仅统计文本中的术语和短语，而且还揭示了文本的结构并提供了对文本内容的洞察。另一方面，大多数社会科学家——他们在调查的评论栏、采访记录等中有大量的文本数据。—似乎不依赖这些方法*(那些学习语言或与计算机科学家合作的人是极少数的例外)。</p><p id="18e3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这篇文章中，我鼓励社会科学家探索文本分析所能提供的各种可能性。为此，我简要介绍了两种文本分析技术:潜在语义分析(LSA)和主题分析(TA)。显而易见，具有多元统计学背景的社会科学家将能够毫不费力地使用、应用和解释LSA和助教(可能只需要这篇文章就能让你开始工作！)我的解释依赖于社会科学中众所周知的两种统计技术:主成分分析(PCA)和因子分析(FA)。</p><h1 id="dc8a" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">主成分分析综述</h1><p id="e573" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">PCA是一种允许我们从数据中识别和提取最大可变性的不相关维度的方法。这是通过数据的相关矩阵的特征值分解来完成的。图1描述了特征值分解中涉及的步骤，以及帮助解释PCA的后续步骤(注意，为了便于回顾，该图过于简化)。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/3907af0e40ce1d5cee2d025c953a9091.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HJv2T-8VYyv4lh8Q"/></div></div></figure><p id="052f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="mt">图一。主成分分析步骤的描述。图片作者。</em></p><p id="643b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">相关矩阵表示多维空间中的“数据云”。特征值分解有助于识别该云中相互垂直的主要维度，并产生两条关键信息:表示主要维度方向的<strong class="kq ja">特征向量</strong>，以及表示每个维度大小和维度方差的<strong class="kq ja">特征值</strong>。如果只有几个维度捕获了数据中的大部分可变性(即，前两个特征值相对于所有其他特征值都很大)，那么分析师可能会选择保留前两个特征向量和特征值，以减少他们必须分析的变量的数量。所有的特征向量都是单位长度的，但是可以使用特征值提供的信息来“调整大小”。这些重新调整的特征向量被称为载荷。</p><p id="5c27" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">载荷向量的可变性等于它们相应的特征值。此外，加载系数是描述维度(主成分)和相应变量之间的关联的相关系数。因此，载荷对于理解主分量代表什么是至关重要的。然而，载荷矩阵可能具有难以辨别的模式，例如跨越几个维度的中等大小的载荷(参见图1中的载荷矩阵)。因此，分析师可能会选择旋转加载矩阵，以努力改善组件的解释。最常见的是，采用正交旋转(例如，Varimax)，这往往导致一种简单的载荷模式(Thurstone，1947年称之为“简单结构”)。也就是说，对于给定的部件，载荷非常高，而对于所有其它部件，载荷几乎为零。旋转载荷矩阵的简单结构(见图1)有助于清楚地识别每个主分量代表什么。</p><h1 id="9d73" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">主成分分析==潜在语义分析</h1><p id="b046" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">既然主成分分析在你的脑海中是新鲜的，好消息是潜在语义分析(LSA)只是对文本术语的相关矩阵进行的主成分分析(但不涉及任何旋转)。换句话说，分析中的变量是表示某个术语在文本文档中的出现频率的列。这组变量被称为文档术语矩阵(DTM；参见图2)，它的列数与文档中的术语数一样多，行数与文档数一样多。如果我们想要一个二进制DTM，每个单元格条目可以是0或1，这取决于给定的术语是否在给定的文档中。频率DTM要求每个条目是该术语在给定文档中出现的次数的计数。还有其他方法来建造DTM；文献(Ramos，2003)中推荐的方法被称为TF-IDF(术语频率-逆文档频率)，您可以在<a class="ae mu" href="https://www.jmp.com/en_us/software/data-analysis-software.html?utm_campaign=aw&amp;utm_source=bl&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> JMP </a>中通过点击一个按钮来实现它！</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mv"><img src="../Images/7c023e351dc4ab78f1529cb3b03a2398.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CcHWq-hB-IVnIE3o"/></div></div></figure><p id="98b5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="mt">图二。三个文档的样本文档术语矩阵(DTM)。图像是使用JMP Pro软件生成的，版权2021 SAS Institute Inc .，经作者许可使用。</em></p><p id="e6ef" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">注意，图2中的第一个文档有单词“from ”,但是这个词没有出现在DTM中。这是因为创建DTM需要一些重要的初步步骤。接下来让我们看看那些！</p><h1 id="6d81" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">设置用于分析的文本数据</h1><p id="ca0b" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">文本分析从确定测量单位开始。具体来说，您必须确定什么将构成“文档”文档可以是一个句子、段落、文章或一本书，还有许多其他选择。下一步涉及识别文档中的相关术语。你可以通过过滤掉“停用词”(那些在文本语料库中不太可能有助于揭示结构的极其常见的词，如“the”、“and”、“from”、“is”、“of”等)来做到这一点。).此外，您可以选择将相似的术语浓缩成一个。例如，图2中的“分析”和“分析”列是多余的，可以合并成一列“分析”这就是所谓的词干。最后，不是文本中的所有单词都应该分开。图2第一行的“社会科学家”就是一个例子。在创建DTM之前，您可以将这些单词组合成一个术语(您可以对类似“从前”这样的短语执行相同的操作)。</p><p id="08df" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">以上所有步骤对于固体分析都至关重要。幸运的是，JMP的文本浏览器平台让这些任务变得轻而易举！在Analyze &gt;文本浏览器菜单下，将包含文档的数据表中的列指定为文本列(参见图3)。您还可以在启动窗口中自定义词干选项。启动文本浏览器后，您可以进一步选择短语作为术语。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/e194f626d40e234ae7ba48c956151148.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_GLNktOdytcYSirX"/></div></div></figure><p id="9361" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="mt">图三。文本资源管理器启动窗口(左)和启动文本资源管理器的初始报告(右)。图像是使用JMP Pro软件生成的，版权2021 SAS Institute Inc .，经作者许可使用。</em></p><p id="d7b0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">完成所有预备步骤后，您可以创建DTM并使用它进行PCA。然而，取决于你的DTM有多大(它们往往很大)，我上面描述的PCA可能需要很长时间来运行，并且需要大量的内存。幸运的是，JMP使用奇异值分解代替特征值分解，使这种分析非常有效！在以后的文章中，我将解释特征值分解和奇异值分解之间的等价性，但是现在，你必须相信我，这两种方法会导致相同的结果。</p><h1 id="593c" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">话题分析</h1><p id="9391" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">另一种有价值的文本分析技术是主题分析(TA)。这种技术也可以很容易地转化为社会科学家通过澄清TA是简单的PCA与Varimax旋转的负荷矩阵。与LSA类似，TA是用奇异值分解而不是特征值分解来进行的，以使其更有效。由于载荷的旋转，从TA得到的结果可能比从LSA得到的结果更容易解释。主题将是文本数据可变性的主要方面。加载允许你解释这个主题代表了什么。此外，主题(或组件)分数可以计算并用于辅助分析。</p><p id="160e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了让大家了解TA能做些什么，我在231，657个笑话的数据集**上执行了TA。为了避免冒犯任何读者，我只展示了分析中出现的三个主题的结果(图4)。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/81b8face6bb01d94d551742e127c1e94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/0*gSMNRr_4yPhubo9C"/></div></figure><p id="eb9e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="mt">图4。从对231，657个笑话的数据表执行的主题分析(TA)中选择主题。图像是使用JMP Pro软件生成的，版权2021 SAS Institute Inc .，经作者许可使用。</em></p><p id="fe4c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">读者可能会同意，图4中每个主题所代表的笑话类型之间有明显的区别。要获得更多令人信服的文本分析示例，请参见<a class="ae mu" href="https://community.jmp.com/t5/JMP-Blog/Exploring-text-to-see-what-might-happen-in-the-stock-market/ba-p/33121" rel="noopener ugc nofollow" target="_blank">这篇关于预测未来股票价格的文章</a>，或者阅读最近使用社交媒体数据的出版物(Kern et al .，2016)。或者看<a class="ae mu" href="https://youtu.be/JnigzY7gl_o" rel="noopener ugc nofollow" target="_blank">这个视频</a>。</p><h1 id="e585" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">关于因子分析的注记</h1><p id="6149" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">在开始部分，我说我会依靠社会科学家的PCA和FA的知识。但到目前为止我只讨论了PCA。如果你的训练和我的相似，你就会知道PCA和FA之间有很大的不同。在<a class="ae mu" href="https://community.jmp.com/t5/JMP-Blog/Principal-components-or-factor-analysis/ba-p/38347" rel="noopener ugc nofollow" target="_blank">的前一篇文章</a>中，我描述了这些差异，但我也提到了一个关键的相似之处:随着所考虑的数据矩阵规模的增长，PCA和FA的结果变得越来越相似(如果你想重温FA，我推荐你<a class="ae mu" href="https://community.jmp.com/t5/JMP-Blog/Principal-components-or-factor-analysis/ba-p/38347" rel="noopener ugc nofollow" target="_blank">阅读文章</a>)。事实上，在文本分析中，数据矩阵往往非常大。在上面的样本文档术语矩阵中，DTM已经有10个变量了！笑话示例中的DTM有4316个变量！).因此，来自LSA和助教的主题或组成部分可以被认为是潜在变量的近似值，可以有效地用于解决无数的研究问题！</p><h1 id="10fa" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">关闭…</h1><p id="977c" class="pw-post-body-paragraph ko kp iq kq b kr mc ka kt ku md kd kw kx me kz la lb mf ld le lf mg lh li lj ij bi translated">太多时候，我们让我们的统计工具包来决定我们研究的设计和分析(有时是无意的！).因此，我希望这篇文章打开了社会科学(和其他领域)中新的研究问题的大门，这些问题可以用文本分析独特地解决。</p><h1 id="bc8f" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">要点</h1><ul class=""><li id="9710" class="mx my iq kq b kr mc ku md kx mz lb na lf nb lj nc nd ne nf bi translated">尽管文本分析依赖于社会科学家熟知的统计技术，但它在社会科学中并未得到充分利用。</li><li id="1a13" class="mx my iq kq b kr ng ku nh kx ni lb nj lf nk lj nc nd ne nf bi translated">潜在语义分析相当于对文档术语矩阵进行的主成分分析。</li><li id="82e4" class="mx my iq kq b kr ng ku nh kx ni lb nj lf nk lj nc nd ne nf bi translated">文档术语矩阵具有与文档一样多的行和与文档中的术语一样多的列。单元格包含给定文档中出现的术语。</li><li id="529f" class="mx my iq kq b kr ng ku nh kx ni lb nj lf nk lj nc nd ne nf bi translated">主题分析相当于主成分分析，通过旋转成分载荷来帮助解释主题。但是请注意，一些聚类方法有时也被称为主题分析。</li><li id="77b5" class="mx my iq kq b kr ng ku nh kx ni lb nj lf nk lj nc nd ne nf bi translated">因为文档术语矩阵往往很大，社会科学家可以将主成分视为潜在变量或潜在主题的很好的近似。</li></ul><p id="3886" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">关于文本分析还有很多要说的！我建议从这个点播网络广播开始，它在描述更多细节方面做得很好。你还可以看到<a class="ae mu" href="https://community.jmp.com/t5/JMPer-Cable/The-new-look-of-Text-Explorer/ba-p/43506" rel="noopener ugc nofollow" target="_blank">我的帖子</a>关于JMP的文本浏览器平台，尤其是<a class="ae mu" href="https://community.jmp.com/t5/JMPer-Cable/The-new-look-of-Text-Explorer/ba-p/43506#Rosetta-Stone" rel="noopener ugc nofollow" target="_blank">罗塞塔石碑部分</a>，阐明了PCA和LSA/TA更多的联系。</p><h1 id="7aad" class="lk ll iq bd lm ln lo lp lq lr ls lt lu kf lv kg lw ki lx kj ly kl lz km ma mb bi translated">参考</h1><ul class=""><li id="9d23" class="mx my iq kq b kr mc ku md kx mz lb na lf nb lj nc nd ne nf bi translated">Kern，M. L .，Park，g .，Eichstaedt，J. C .，Schwartz，H. A .，Sap，m .，Smith，L. K .，&amp; Ungar，L. H. (2016)。从社交媒体语言中获得洞察力:方法和挑战。<em class="mt">心理方法。</em>提前在线发布。<a class="ae mu" href="http://dx.doi.org/10.1037/met0000091" rel="noopener ugc nofollow" target="_blank">http://dx.doi.org/10.1037/met0000091</a></li><li id="34c6" class="mx my iq kq b kr ng ku nh kx ni lb nj lf nk lj nc nd ne nf bi translated">j .拉莫斯(2003年12月)。使用tf-idf确定文档查询中的单词相关性。在<em class="mt">第一届机器学习教学会议论文集</em>(第242卷，第133–142页)。</li><li id="6df3" class="mx my iq kq b kr ng ku nh kx ni lb nj lf nk lj nc nd ne nf bi translated">瑟斯通法律杂志(1947年)。<em class="mt">多因素分析</em>。芝加哥:芝加哥大学出版社，1947年。</li></ul><p id="3304" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">*现在的文字分析比2017年我第一次写这个帖子的时候更普遍。</p><p id="b96a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">**感谢在此免费提供此文件的amoudgl:<a class="ae mu" href="https://github.com/amoudgl/short-jokes-dataset" rel="noopener ugc nofollow" target="_blank">https://github.com/amoudgl/short-jokes-dataset</a></p><p id="af0f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="mt">本文原载于2017年9月26日</em> <a class="ae mu" href="https://community.jmp.com/t5/JMP-Blog/Principal-components-or-factor-analysis/ba-p/38347" rel="noopener ugc nofollow" target="_blank"> <em class="mt"> JMP用户社区</em> </a> <em class="mt">。</em></p></div></div>    
</body>
</html>