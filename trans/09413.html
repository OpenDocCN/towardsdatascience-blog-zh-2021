<html>
<head>
<title>Building MobileNet from Scratch Using TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用TensorFlow从头构建MobileNet</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-mobilenet-from-scratch-using-tensorflow-ad009c5dd42c?source=collection_archive---------11-----------------------#2021-09-01">https://towardsdatascience.com/building-mobilenet-from-scratch-using-tensorflow-ad009c5dd42c?source=collection_archive---------11-----------------------#2021-09-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0f2e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在TensorFlow中从头开始创建MobileNet架构</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/409623376097c6be50137aef5dee936c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xqHfl2xbDAZSwRh5LpRJ7Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图一。(来源:安德里亚·德·森蒂斯峰在<a class="ae ky" href="https://unsplash.com/s/photos/ai?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片)</p></figure><p id="1431" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之前我已经讨论了MobileNet的架构和它最重要的层“<strong class="lb iu"> <em class="lv">深度方向可分离卷积</em> </strong>”,在故事中— <a class="ae ky" rel="noopener" target="_blank" href="/understanding-depthwise-separable-convolutions-and-the-efficiency-of-mobilenets-6de3d6b62503">理解深度方向可分离卷积和MobileNet的效率</a>。</p><p id="5153" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将看到如何使用TensorFlow从头开始实现这个架构。</p><h2 id="9867" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">实施:</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/f5ebc3a3d236c77a5bf38ac235fc1681.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*l31pZKpoQmkiKHmQs4OZlA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图二。MobileNet架构(来源:图片来自原论文)</p></figure><p id="1877" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图2显示了我们将用代码实现的MobileNet架构。网络从Vonv、BatchNorm、ReLU块开始，然后是多个MobileNet块。它最终以一个平均池和一个完全连接的层结束，具有一个Softmax激活。</p><p id="3ab5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们看到这个架构有这样的模式——conv dw/S1，然后是Conv/s1，等等。这里的dw是深度层的步数，后面是Conv层的步数。这两行是MobileNet块。</p><p id="009a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">“过滤器形状”列给出了内核大小和要使用的过滤器数量的详细信息。该列的最后一个数字给出了过滤器的数量。我们看到过滤器数量逐渐从32增加到64，从64增加到128，从128增加到256，等等。</p><p id="3dfc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后一列显示了随着我们深入网络，图像的大小是如何变化的。输入尺寸选择为224*224像素，具有3个通道，输出层分类1000个类。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/7720b999f70a9e1ddb9f757e4a9415eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*nUhElqFbTXK9h7NMfVQesQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3。普通CNN架构(左)与MobileNet架构(右)之间的差异(来源:图片来自原始论文)</p></figure><p id="5a02" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">构建网络时需要记住的几件事:</p><ol class=""><li id="21de" class="mr ms it lb b lc ld lf lg li mt lm mu lq mv lu mw mx my mz bi translated">所有层之后是批量归一化和ReLU非线性。</li><li id="7a9e" class="mr ms it lb b lc na lf nb li nc lm nd lq ne lu mw mx my mz bi translated">与具有Conv2D层的普通CNN模型不同，MobileNet具有深度方向的Conv层，如图3所示。要更好地理解这一层，请参考— <a class="ae ky" rel="noopener" target="_blank" href="/understanding-depthwise-separable-convolutions-and-the-efficiency-of-mobilenets-6de3d6b62503">深度方向卷积块</a>。</li></ol><h2 id="20d4" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">工作流程:</h2><ol class=""><li id="92e9" class="mr ms it lb b lc nf lf ng li nh lm ni lq nj lu mw mx my mz bi translated">从TensorFlow库中导入所有必需的图层</li><li id="445a" class="mr ms it lb b lc na lf nb li nc lm nd lq ne lu mw mx my mz bi translated">为MobileNet块编写一个助手函数</li><li id="b754" class="mr ms it lb b lc na lf nb li nc lm nd lq ne lu mw mx my mz bi translated">构建模型的主干</li><li id="b49c" class="mr ms it lb b lc na lf nb li nc lm nd lq ne lu mw mx my mz bi translated">使用辅助函数来构建模型的主要部分</li></ol><p id="6033" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">导入图层</strong></p><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="5ccc" class="lw lx it nl b gy np nq l nr ns"><strong class="nl iu">import tensorflow as tf</strong></span><span id="4281" class="lw lx it nl b gy nt nq l nr ns">#import all necessary layers</span><span id="3054" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">from tensorflow.keras.layers import Input, DepthwiseConv2D<br/>from tensorflow.keras.layers import Conv2D, BatchNormalization<br/>from tensorflow.keras.layers import ReLU, AvgPool2D, Flatten, Dense</strong></span><span id="9aaa" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">from tensorflow.keras import Model</strong></span></pre><p id="c527" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Keras已经内置了一个DepthwiseConv层，所以我们不需要从头开始创建它。</p><p id="66c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> MobileNet模块</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/7ee3a34469d106dbbdf28425f6dc4599.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*8iIkESaVcKv1atWdSQRQlg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4。MobileNet块的表示(来源:图片来自原始论文)</p></figure><p id="6d7b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了创建MobileNet块的函数，我们需要以下步骤:</p><ol class=""><li id="4e3e" class="mr ms it lb b lc ld lf lg li mt lm mu lq mv lu mw mx my mz bi translated">函数的输入:</li></ol><p id="e518" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv"> a .一个张量(x) </em></p><p id="dad3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv"> b .卷积层的滤波器数量(滤波器)</em></p><p id="802e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv"> c .深度方向卷积层的步距(步距)</em></p><p id="da2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.运行(图3 —右侧图像):</p><p id="bfb6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv"> a .应用具有步长的3×3去hwise卷积层，之后是批量归一化层和ReLU激活</em></p><p id="2c87" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv"> b .应用带有滤波器的1x1卷积层，之后是批量归一化层和ReLU激活</em></p><p id="6e7c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.返回张量(输出)</p><p id="2b2b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这3个步骤在下面的代码块中实现。</p><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="b5a5" class="lw lx it nl b gy np nq l nr ns"># MobileNet block</span><span id="e553" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">def mobilnet_block (x, filters, strides):<br/>    <br/>    x = DepthwiseConv2D(kernel_size = 3, strides = strides, padding = 'same')(x)<br/>    x = BatchNormalization()(x)<br/>    x = ReLU()(x)<br/>    <br/>    x = Conv2D(filters = filters, kernel_size = 1, strides = 1)(x)<br/>    x = BatchNormalization()(x)<br/>    x = ReLU()(x)<br/>    <br/>    return x</strong></span></pre><p id="bb1e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">建立模型的主干</strong></p><p id="4b35" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如图2所示，第一层是Conv/s2，过滤器形状为3x3x3x32。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/46952f8936b0e69d23f55b8a702eb512.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*CEIl_bUOPVt1r-0I664H2w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图5。模型的主干(来源:图片来自原论文)</p></figure><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="9e75" class="lw lx it nl b gy np nq l nr ns">#stem of the model</span><span id="fa8f" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">input = Input(shape = (224,224,3))</strong></span><span id="526c" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">x = Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = 'same')(input)<br/>x = BatchNormalization()(x)<br/>x = ReLU()(x)</strong></span></pre><p id="eb36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">模型的主要部分</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/282bcfb64964401790004d0c5021757a.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*kF7RB7usEjM4l5ZpNw8A0g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图6。模型的主体部分(来源:图片来自原论文)</p></figure><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="5ab1" class="lw lx it nl b gy np nq l nr ns"># main part of the model</span><span id="613d" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">x = mobilnet_block(x, filters = 64, strides = 1)<br/>x = mobilnet_block(x, filters = 128, strides = 2)<br/>x = mobilnet_block(x, filters = 128, strides = 1)<br/>x = mobilnet_block(x, filters = 256, strides = 2)<br/>x = mobilnet_block(x, filters = 256, strides = 1)<br/>x = mobilnet_block(x, filters = 512, strides = 2)</strong></span><span id="bfdb" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">for _ in range (5):<br/>     x = mobilnet_block(x, filters = 512, strides = 1)</strong></span><span id="e766" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">x = mobilnet_block(x, filters = 1024, strides = 2)<br/>x = mobilnet_block(x, filters = 1024, strides = 1)</strong></span><span id="90a2" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">x = AvgPool2D (pool_size = 7, strides = 1, data_format='channels_first')(x)<br/>output = Dense (units = 1000, activation = 'softmax')(x)</strong></span><span id="8664" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">model = Model(inputs=input, outputs=output)<br/>model.summary()</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/ed71e57fc81ba8afa900a4cc67743482.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*5yeRAyyJ-7MhDp8CQuHgAg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图7。模型摘要的片段</p></figure><p id="cbdd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">绘制模型</strong></p><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="b898" class="lw lx it nl b gy np nq l nr ns">#plot the model</span><span id="c756" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_dtype=False,show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96)</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/75b032bc244ee1ed18b535c24b462f02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*CVMsj-28f67xeyFhQHGpMA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图8:模型图的一个片段</p></figure><h2 id="11c3" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">使用TensorFlow的整个MobileNet模型实现:</h2><pre class="kj kk kl km gt nk nl nm nn aw no bi"><span id="fa41" class="lw lx it nl b gy np nq l nr ns"><strong class="nl iu">import tensorflow as tf</strong></span><span id="a91b" class="lw lx it nl b gy nt nq l nr ns">#import all necessary layers</span><span id="8d89" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">from tensorflow.keras.layers import Input, DepthwiseConv2D<br/>from tensorflow.keras.layers import Conv2D, BatchNormalization<br/>from tensorflow.keras.layers import ReLU, AvgPool2D, Flatten, Dense</strong></span><span id="599f" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">from tensorflow.keras import Model</strong></span><span id="cf0a" class="lw lx it nl b gy nt nq l nr ns"># MobileNet block</span><span id="a746" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">def mobilnet_block (x, filters, strides):<br/>    <br/>    x = DepthwiseConv2D(kernel_size = 3, strides = strides, padding = 'same')(x)<br/>    x = BatchNormalization()(x)<br/>    x = ReLU()(x)<br/>    <br/>    x = Conv2D(filters = filters, kernel_size = 1, strides = 1)(x)<br/>    x = BatchNormalization()(x)<br/>    x = ReLU()(x)<br/>    <br/>    return x</strong></span><span id="55c4" class="lw lx it nl b gy nt nq l nr ns">#stem of the model</span><span id="57c7" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">input = Input(shape = (224,224,3))</strong></span><span id="a313" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">x = Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = 'same')(input)<br/>x = BatchNormalization()(x)<br/>x = ReLU()(x)</strong></span><span id="9ce7" class="lw lx it nl b gy nt nq l nr ns"># main part of the model</span><span id="677d" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">x = mobilnet_block(x, filters = 64, strides = 1)<br/>x = mobilnet_block(x, filters = 128, strides = 2)<br/>x = mobilnet_block(x, filters = 128, strides = 1)<br/>x = mobilnet_block(x, filters = 256, strides = 2)<br/>x = mobilnet_block(x, filters = 256, strides = 1)<br/>x = mobilnet_block(x, filters = 512, strides = 2)</strong></span><span id="2de1" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">for _ in range (5):<br/>     x = mobilnet_block(x, filters = 512, strides = 1)</strong></span><span id="fa12" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">x = mobilnet_block(x, filters = 1024, strides = 2)<br/>x = mobilnet_block(x, filters = 1024, strides = 1)</strong></span><span id="a3c4" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">x = AvgPool2D (pool_size = 7, strides = 1, data_format='channels_first')(x)<br/>output = Dense (units = 1000, activation = 'softmax')(x)</strong></span><span id="d078" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">model = Model(inputs=input, outputs=output)<br/>model.summary()</strong></span><span id="6efa" class="lw lx it nl b gy nt nq l nr ns">#plot the model</span><span id="a680" class="lw lx it nl b gy nt nq l nr ns"><strong class="nl iu">tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_dtype=False,show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96)<br/></strong></span></pre><h2 id="01d1" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">结论</h2><p id="5a41" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nz lk ll lm oa lo lp lq ob ls lt lu im bi translated">MobileNet是最小的深度神经网络之一，快速高效，可以在没有高端GPU的设备上运行。当使用Keras(tensor flow上)这样的框架时，这些网络的实现非常简单。</p><h2 id="de6e" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">相关文章</h2><p id="9b2a" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nz lk ll lm oa lo lp lq ob ls lt lu im bi translated">要了解如何使用TensorFlow实现其他著名的CNN架构，请访问以下链接-</p><ol class=""><li id="1a63" class="mr ms it lb b lc ld lf lg li mt lm mu lq mv lu mw mx my mz bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/xception-from-scratch-using-tensorflow-even-better-than-inception-940fb231ced9">异常</a></li><li id="50fc" class="mr ms it lb b lc na lf nb li nc lm nd lq ne lu mw mx my mz bi translated">ResNet </li><li id="fa4a" class="mr ms it lb b lc na lf nb li nc lm nd lq ne lu mw mx my mz bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/creating-vgg-from-scratch-using-tensorflow-a998a5640155"> VGG </a></li><li id="b246" class="mr ms it lb b lc na lf nb li nc lm nd lq ne lu mw mx my mz bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/creating-densenet-121-with-tensorflow-edbc08a956d8"> DenseNet </a></li></ol></div><div class="ab cl oc od hx oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="im in io ip iq"><h1 id="2c7a" class="oj lx it bd ly ok ol om mb on oo op me jz oq ka mh kc or kd mk kf os kg mn ot bi translated">参考资料:</h1><p id="b819" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nz lk ll lm oa lo lp lq ob ls lt lu im bi translated">Howard，A.G .，Zhu，m .，Chen，b .，Kalenichenko，d .，Wang，w .，Weyand，t .，Andreetto，m .，&amp; Adam，H. (2017)。MobileNets:用于移动视觉应用的高效卷积神经网络。<em class="lv"> ArXiv，abs/1704.04861 </em>。</p></div></div>    
</body>
</html>