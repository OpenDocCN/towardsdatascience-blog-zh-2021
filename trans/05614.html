<html>
<head>
<title>Structured natural language processing with Pandas and spaCy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">熊猫与空间的结构化自然语言处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/structured-natural-language-processing-with-pandas-and-spacy-7089e66d2b10?source=collection_archive---------6-----------------------#2021-05-19">https://towardsdatascience.com/structured-natural-language-processing-with-pandas-and-spacy-7089e66d2b10?source=collection_archive---------6-----------------------#2021-05-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3f19" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过将非结构化数据结构化来加速分析</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/9a300cad7230fd6872c41b6b0c137349.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*LAy_6CwZKbJs5-sqKMyxJw.png"/></div></figure><p id="b944" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">由于自然语言数据缺乏结构性，处理自然语言数据通常具有挑战性。大多数数据科学家、分析师和产品经理都熟悉由<strong class="ks iu">行和</strong>列组成的<strong class="ks iu">结构化</strong> <strong class="ks iu">表格</strong>，但不太熟悉由<strong class="ks iu">句子和</strong>单词组成的<strong class="ks iu">非结构化</strong> <strong class="ks iu">文档</strong>。出于这个原因，知道如何处理自然语言数据集可能是相当具有挑战性的。在这篇文章中，我想展示如何使用令人敬畏的Python包<code class="fe lm ln lo lp b"><strong class="ks iu">spaCy</strong></code>和<code class="fe lm ln lo lp b"><strong class="ks iu">Pandas</strong></code>，来构建自然语言并快速提取有趣的见解。</p><h2 id="9c5f" class="lq lr it bd ls lt lu dn lv lw lx dp ly kz lz ma mb ld mc md me lh mf mg mh mi bi translated">空间介绍</h2><p id="1dbd" class="pw-post-body-paragraph kq kr it ks b kt mj ju kv kw mk jx ky kz ml lb lc ld mm lf lg lh mn lj lk ll im bi translated">spaCy 是一个非常流行的用于高级自然语言处理的Python包——我这里有一个关于spaCy的<a class="ae mo" rel="noopener" target="_blank" href="/a-short-introduction-to-nlp-in-python-with-spacy-d0aa819af3ad">初学者友好介绍。spaCy是应用数据科学家在从事NLP项目时的完美工具包。<strong class="ks iu">API非常直观，软件包运行速度极快，并且有很好的文档记录</strong>。可以说它是目前最好的NLP通用软件包。在开始构建NLP数据之前，熟悉spaCy库和api的基础知识是很有用的。</a></p><p id="d31b" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">安装软件包后，您可以加载模型(在这种情况下，我加载的是简单的Engilsh模型，它针对效率而非准确性进行了优化)，即底层神经网络的参数较少。</p><pre class="kj kk kl km gt mq lp mr ms aw mt bi"><span id="4560" class="lq lr it lp b gy mu mv l mw mx">import spacy<br/>nlp = spacy.load("en_core_web_sm")</span></pre><p id="363c" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">按照惯例，我们将这个模型实例化为<code class="fe lm ln lo lp b"><strong class="ks iu">nlp</strong></code>。在整篇文章中，我将使用这个著名的激励语录数据集。让我们将<code class="fe lm ln lo lp b"><strong class="ks iu">nlp</strong></code>模型应用于数据中的单个报价，并将其存储在一个变量中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi my"><img src="../Images/9503eb23807098696b131f798cdbe658.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E5UJqgBxN87BCGbYnF4Jaw.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">数据集标题-按作者分类的图像。</p></figure><pre class="kj kk kl km gt mq lp mr ms aw mt bi"><span id="0495" class="lq lr it lp b gy mu mv l mw mx">doc = nlp(df.quote[819]) <br/>print(doc)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nh"><img src="../Images/c4991ccffa9a70478b557cd261cb574c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wtc1qgs9bukHHc9G1T9h2w.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图片作者。</p></figure><p id="940e" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">如果我们打印这个文档，你可以看到它只是返回了原来的引用，<strong class="ks iu">但是在这个引擎盖下，发生了很多NLP的魔法——我们创建了一个spaCy <code class="fe lm ln lo lp b"><strong class="ks iu">doc</strong></code>对象。那么我们能用它做什么呢？</strong></p><p id="c8e1" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">首先，我们可以做两个非常酷和有趣的可视化。下面的可视化显示了文档的<strong class="ks iu">依赖结构</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi ni"><img src="../Images/cbf56a90b42d6f04e6ac388fa7620a13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ePaTmEiBOAwUhuycIVhA6w.png"/></div></div></figure><p id="9fa4" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">这些依存关系通过显示文档中每个单词如何与其他单词相关来描述句子的<strong class="ks iu">语言结构。值得停下来惊叹一下。在引擎盖下，spaCy已经将一个大型神经语言模型应用于文档，解析了依赖结构，并使我们能够轻松地查看它— <strong class="ks iu">所有这一切都只需要一行代码。</strong>如果你想更好地理解如何解释这个依赖结构，你可以使用<code class="fe lm ln lo lp b"><strong class="ks iu">spacy.explain</strong></code>函数来获得每个依赖类型的定义。</strong></p><p id="b50d" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">下一个可视化显示了已经被语言模型识别的实体。在这种情况下，语言模型已经识别出几个属于<strong class="ks iu">日期</strong>类型的单词。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nj"><img src="../Images/990c0c09c27198fe27650517a7f3e2e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u1b8W6yb0WEeoi6TXAJxSQ.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图片作者。</p></figure><p id="abdb" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们可以通过编程来访问文档的这些属性，如下所示。</p><pre class="kj kk kl km gt mq lp mr ms aw mt bi"><span id="8a95" class="lq lr it lp b gy mu mv l mw mx">[(i, i.label_) for i in doc.ents]</span></pre><p id="2684" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><code class="fe lm ln lo lp b"><strong class="ks iu">doc.ents</strong></code>方法允许访问spaCy语言模型预测的实体。和依赖标签一样，你可以使用<code class="fe lm ln lo lp b"><strong class="ks iu">spacy.explain</strong></code>来理解每个实体标签的意思。</p><p id="6caf" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated"><code class="fe lm ln lo lp b"><strong class="ks iu">doc</strong></code>对象的其他有用属性是<code class="fe lm ln lo lp b"><strong class="ks iu">sents</strong></code>和<code class="fe lm ln lo lp b"><strong class="ks iu">noun_chunks</strong></code>方法，它们使您能够将文档分割成句子或名词块(即名词加上它们的描述符)。</p><pre class="kj kk kl km gt mq lp mr ms aw mt bi"><span id="695b" class="lq lr it lp b gy mu mv l mw mx">doc = nlp(df.quote[0])<br/>spacy.displacy.render(doc, style="ent")<br/>doc_nouns = list(doc.noun_chunks)<br/>print(doc_nouns)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nk"><img src="../Images/a85b06c9ba705ded6bcc732470b9e12b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hJS4GOmjmlJEhn_tJr3LvQ.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图片作者。</p></figure><p id="8946" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">如果我们从文档中访问一个单词，我们实际上是在访问一个空间 <code class="fe lm ln lo lp b"><strong class="ks iu">token</strong></code> <strong class="ks iu">对象</strong>。像<code class="fe lm ln lo lp b"><strong class="ks iu">doc</strong></code>对象一样，<code class="fe lm ln lo lp b"><strong class="ks iu">token</strong></code>对象包含许多有用的属性。例如，我们可以遍历文档来提取每个令牌及其各种属性。</p><pre class="kj kk kl km gt mq lp mr ms aw mt bi"><span id="8f90" class="lq lr it lp b gy mu mv l mw mx">[(i, i.ent_type_, i.is_stop) for i in doc]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/9a300cad7230fd6872c41b6b0c137349.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*LAy_6CwZKbJs5-sqKMyxJw.png"/></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图片作者。</p></figure><p id="42ff" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">既然我们已经介绍了spaCy和api的一些基础知识，让我们对数据采取一种更结构化的方法。</p><h2 id="1124" class="lq lr it bd ls lt lu dn lv lw lx dp ly kz lz ma mb ld mc md me lh mf mg mh mi bi translated">结构化自然语言数据</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nl"><img src="../Images/27c2913b3da6b78e2a27ad2847ecde8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*FA1XPG4kEC-mIuTu"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">由<a class="ae mo" href="https://unsplash.com/@xavi_cabrera?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">哈维·卡夫雷拉</a>在<a class="ae mo" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="0ffc" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">这里的目标是将非结构化文档转换成结构化的数据表。本质上，我们希望从文档、令牌及其元数据的非结构化语料库转移到行和列的结构化数据集。</p><ul class=""><li id="e6e1" class="nm nn it ks b kt ku kw kx kz no ld np lh nq ll nr ns nt nu bi translated"><strong class="ks iu">步骤1: </strong>我们首先需要将<code class="fe lm ln lo lp b"><strong class="ks iu">spaCy</strong></code>语言模型应用于整个报价集合。最简单和计算效率最高的方法是使用<code class="fe lm ln lo lp b"><strong class="ks iu">nlp.pipe</strong></code>函数。这将迭代每个文档并应用语言模型。</li></ul><pre class="kj kk kl km gt mq lp mr ms aw mt bi"><span id="ab02" class="lq lr it lp b gy mu mv l mw mx">docs = list(nlp.pipe(df.quote))</span></pre><ul class=""><li id="a839" class="nm nn it ks b kt ku kw kx kz no ld np lh nq ll nr ns nt nu bi translated"><strong class="ks iu">第二步:</strong>定义一个函数，提取你想要包含在表格中的每个单词的所有属性。该函数将在单个<code class="fe lm ln lo lp b"><strong class="ks iu">doc</strong></code>中迭代令牌，并将提取各种属性，如词条、位置、实体和标签。使用该函数定义您想要从<code class="fe lm ln lo lp b">token</code>对象中提取的所有属性。在这种情况下，我提取我经常使用的公共属性，这将有助于分析数据。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><ul class=""><li id="620a" class="nm nn it ks b kt ku kw kx kz no ld np lh nq ll nr ns nt nu bi translated"><strong class="ks iu">步骤3: </strong>定义一个函数，将上面的函数应用于所有文档，并将输出存储在一个Pandas <code class="fe lm ln lo lp b"><strong class="ks iu">dataframe</strong></code>中。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="06c7" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">如果我们运行这些步骤，我们最终会得到如下所示的数据集:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nx"><img src="../Images/bc99773b9f6fd27f490820880e05afc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ozQEUw7YSyXrFJXhVdxAPg.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图片作者。</p></figure><p id="a96c" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">每行代表一个令牌，各列捕获该令牌上的各种元数据。重要的是，我们还可以使用<code class="fe lm ln lo lp b">doc_id</code>列将每个单词链接回它的文档。</p><h2 id="07e6" class="lq lr it bd ls lt lu dn lv lw lx dp ly kz lz ma mb ld mc md me lh mf mg mh mi bi translated">分析结构化自然语言数据</h2><p id="2f0c" class="pw-post-body-paragraph kq kr it ks b kt mj ju kv kw mk jx ky kz ml lb lc ld mm lf lg lh mn lj lk ll im bi translated">现在我们有了这种格式的数据，我们可以像分析任何其他结构化数据集一样分析它。例如，我们可以计算每篇文档的字数，并用直方图显示出来。</p><pre class="kj kk kl km gt mq lp mr ms aw mt bi"><span id="4eba" class="lq lr it lp b gy mu mv l mw mx">tidy_docs.groupby("doc_id").size().hist(figsize=(14, 7), color="red", alpha=.4, bins=50);</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi ny"><img src="../Images/c33426608e89b7345f149966a275e2e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wN3yYiaym3L7QMpaDVOugg.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图片作者。</p></figure><p id="85eb" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">或者，我们可能有兴趣了解在语料库中识别的最常见的实体:</p><pre class="kj kk kl km gt mq lp mr ms aw mt bi"><span id="65ae" class="lq lr it lp b gy mu mv l mw mx">tidy_docs.query("ent_type != ''").ent_type.value_counts()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/ef01bb6ba1c59ef24cccb4ab4a767f8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*HbuNXk05j1mH479NEBPmGA.png"/></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图片作者。</p></figure><p id="8f4c" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在过滤掉停用词和切分后，我们可以对单词做同样的事情:</p><pre class="kj kk kl km gt mq lp mr ms aw mt bi"><span id="1489" class="lq lr it lp b gy mu mv l mw mx">tidy_docs.query("is_stop == False &amp; is_punct == False").lemma.value_counts().head(10).plot(kind="barh", figsize=(24, 14), alpha=.7)<br/>plt.yticks(fontsize=20)<br/>plt.xticks(fontsize=20);</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi oa"><img src="../Images/63542b05eb78e236180d705078b0e2ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*21Li2xmEdQxX8j3wYG_ujw.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图片作者。</p></figure><p id="5b37" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">我们可以对结构化数据进行的另一个有趣的分析是查看所有格，以了解corpu 中的所有权。下面的代码按每个文档分组，然后提取前面和后面的标记，然后过滤带有<code class="fe lm ln lo lp b"><strong class="ks iu">POS</strong></code>标记的标记，该标记指示所有格关系，即<strong class="ks iu"> <em class="mp">前一个标记的对象拥有后一个标记的主题。</em> </strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi ob"><img src="../Images/299b1298ced8727a38c0f04bfc4f783e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4I3KatxHYVjCMyK0Rb9vTw.png"/></div></div><p class="nd ne gj gh gi nf ng bd b be z dk translated">图片作者。</p></figure><p id="fb99" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">这使我们能够理解语料库中的所有格关系。例如，你可以看到这样的短语:<em class="mp">【一个人的勇气】</em><em class="mp">【某人的祈祷】</em><em class="mp">【今日运动会】</em>。深！</p><p id="42f8" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">正如您所看到的，由于数据是结构化的，处理数据变得非常简单。</p><h2 id="2f78" class="lq lr it bd ls lt lu dn lv lw lx dp ly kz lz ma mb ld mc md me lh mf mg mh mi bi translated">把一切都包起来</h2><p id="7c89" class="pw-post-body-paragraph kq kr it ks b kt mj ju kv kw mk jx ky kz ml lb lc ld mm lf lg lh mn lj lk ll im bi translated">这篇文章展示了如何将非结构化的文本数据转化为易于分析的结构化数据集。我经常发现这是对NLP项目的数据有感觉时有用的第一步，并且经常可以揭示有趣和有用的见解。</p><p id="54c6" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">感谢阅读！</p><p id="c057" class="pw-post-body-paragraph kq kr it ks b kt ku ju kv kw kx jx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">附:这篇文章的所有代码可以在这里找到<a class="ae mo" href="https://conormm.github.io/blog/2021/05/18/structured-nlp.html" rel="noopener ugc nofollow" target="_blank"/>。</p></div></div>    
</body>
</html>