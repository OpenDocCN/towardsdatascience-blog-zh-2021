<html>
<head>
<title>Topic Modelling on NYT articles using Gensim, LDA</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Gensim，LDA对NYT文章进行主题建模</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/topic-modelling-on-nyt-articles-using-gensim-lda-37caa2796cd9?source=collection_archive---------33-----------------------#2021-06-08">https://towardsdatascience.com/topic-modelling-on-nyt-articles-using-gensim-lda-37caa2796cd9?source=collection_archive---------33-----------------------#2021-06-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/4d3b42fdd0c31a192fb9cecb21bd1011.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6LqRJqfgGafAYgGA"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://unsplash.com/@pineapple?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">菠萝供应公司</a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="548c" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">NYT文章主题建模指南，了解趋势</h2></div><p id="7a73" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">假设给你一个文本数据，要求你找出这个文本数据是关于什么的。快速浏览一下数据就可以了。现在想象一下，必须浏览大量的文本文档才能理解它的内容。乏味，对吗？在这种情况下，主题建模可以派上用场。</p><p id="dc8d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">主题建模的其他有趣应用是索引研究论文，帮助研究人员跟踪研究趋势和识别要阅读的论文；推荐系统通过对产品评论的聚类和情感分析来匹配用户和新闻文章。</p><p id="7294" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本文中，我们将了解主题建模的本质，并使用名为Gensim的python库对2020年的《纽约时报》文章进行主题建模。</p><p id="4a2f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">文章的流程如下:</p><ol class=""><li id="9631" class="lr ls jg kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">主题建模简介</li><li id="6c90" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">实现主题建模的要素<br/> a. Gensim，一个执行各种NLP任务的python库<br/> b. LDA，最流行的主题建模算法之一</li><li id="eeb2" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">实现LDA <br/> a .预处理数据<br/> b .创建字典和语料库<br/> c .执行LDA <br/> d .可视化结果</li><li id="13f9" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">进一步增强</li></ol></div><div class="ab cl mf mg hu mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="ij ik il im in"><h1 id="592f" class="mm mn jg bd mo mp mq mr ms mt mu mv mw km mx kn my kp mz kq na ks nb kt nc nd bi translated">1.主题建模简介</h1><p id="67a1" class="pw-post-body-paragraph kv kw jg kx b ky ne kh la lb nf kk ld le ng lg lh li nh lk ll lm ni lo lp lq ij bi translated">主题建模允许我们理解高维文本数据，并通过给出每个主题的关键词来识别我们的文本数据的主要主题。这样提取的主题可以用于从文本数据中获得有意义的见解。主题也可以用于给下一个模型(可以是监督学习)额外的分析提升。</p><p id="0d10" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在深入研究这个过程之前，有几个术语需要了解。</p><ul class=""><li id="a6cb" class="lr ls jg kx b ky kz lb lc le lt li lu lm lv lq nj lx ly lz bi translated"><strong class="kx jh">文档:</strong>每个文本文件(我们案例研究中的文章)</li><li id="29bd" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq nj lx ly lz bi translated"><strong class="kx jh">语料库:</strong>所有文档的集合</li><li id="c101" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq nj lx ly lz bi translated"><strong class="kx jh">字典:</strong>每个唯一单词到唯一索引的映射集合</li></ul><blockquote class="nk nl nm"><p id="8db6" class="kv kw nn kx b ky kz kh la lb lc kk ld no lf lg lh np lj lk ll nq ln lo lp lq ij bi translated"><strong class="kx jh">假设</strong>:每个文档都与语料库相关，没有文档是从语料库中孤立出来的</p></blockquote><p id="dd37" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在执行任何自然语言处理任务时，我们必须在将数据提供给模型之前对文本数据进行预处理，因为预测和数据一样好。同样，在这里，我们首先预处理文本数据，然后对预处理的数据进行主题建模。在这个案例研究中，我们从模型中看到的两个结果是，</p><ol class=""><li id="662a" class="lr ls jg kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">每篇文章映射到一个独特的主题</li><li id="7773" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">每个主题都有一组构成特定主题的关键字</li></ol><p id="d3c7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">实现最佳效果的重点领域</strong>如下:</p><ol class=""><li id="b5d7" class="lr ls jg kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">处理数据的<strong class="kx jh">技术，以确保<strong class="kx jh"> </strong>只有重要的信息进入模型，因为模型预测只与我们训练它的数据一样好。</strong></li><li id="1bd4" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><strong class="kx jh">根据我们为每个模型获得的一组关键词来解释主题</strong>的能力。</li></ol><p id="86a3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，选择正确的预处理方法和拥有领域知识来理解主题建模的结果是至关重要的。</p></div><div class="ab cl mf mg hu mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="ij ik il im in"><h1 id="78b6" class="mm mn jg bd mo mp mq mr ms mt mu mv mw km mx kn my kp mz kq na ks nb kt nc nd bi translated">2.实现主题建模的要素</h1><h2 id="30d4" class="nr mn jg bd mo ns nt dn ms nu nv dp mw le nw nx my li ny nz na lm oa ob nc oc bi translated">a.根西姆</h2><p id="f1f0" class="pw-post-body-paragraph kv kw jg kx b ky ne kh la lb nf kk ld le ng lg lh li nh lk ll lm ni lo lp lq ij bi translated">Gensim是一个令人惊叹的开源python库，用于无监督主题建模和自然语言处理。Gensim设计用于处理大型文本集合。</p><h2 id="c9c0" class="nr mn jg bd mo ns nt dn ms nu nv dp mw le nw nx my li ny nz na lm oa ob nc oc bi translated">b.皱胃向左移</h2><p id="43ff" class="pw-post-body-paragraph kv kw jg kx b ky ne kh la lb nf kk ld le ng lg lh li nh lk ll lm ni lo lp lq ij bi translated">主题建模算法，例如我们在本文中将要使用的潜在狄利克雷分配(LDA ),是一组基于自然语言处理的模型，用于在巨大的文本语料库中检测潜在的主题。LDA中的<em class="nn">潜伏</em>是指发现<strong class="kx jh"> <em class="nn">隐藏的</em> </strong> <em class="nn"> </em>主题，<em class="nn">狄利克雷</em>是<strong class="kx jh"> <em class="nn">概率分布</em> </strong>用来理解一个关键字和主题是如何关联的。</p><p id="0582" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">LDA使用每个文档中的主题概率和每个主题中的单词概率，将每个文档(在我们的例子中是新闻文章)分配给一个唯一的主题，并将每个主题分配给一组关键字。</p><h2 id="2b5d" class="nr mn jg bd mo ns nt dn ms nu nv dp mw le nw nx my li ny nz na lm oa ob nc oc bi translated">LDA的内部</h2><ol class=""><li id="940d" class="lr ls jg kx b ky ne lb nf le od li oe lm of lq lw lx ly lz bi translated">选择主题数量(输入参数)</li><li id="3a92" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">LDA将每个单词随机分配给一个主题号</li><li id="0075" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">遍历每个文档计算以下两个概率:<br/> <strong class="kx jh"> <em class="nn"> a .文档中的主题:</em> </strong>文档属于每个主题的概率<br/> <strong class="kx jh"> <em class="nn"> b .主题中的单词:</em> </strong>对每个主题有贡献的单词的概率</li><li id="7f60" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">基于来自步骤3的概率分数，'<em class="nn">通过次数</em>'，一个输入参数，times，重新分配单词以产生主题号和具有主题号的文档。</li></ol><p id="f229" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Gensim提供了一个函数<em class="nn"> LDAModel </em>，该函数在很少或没有指令的情况下完成上述所有步骤。然而，我们可以调整各种参数来获得所需的输出。</p></div><div class="ab cl mf mg hu mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="ij ik il im in"><h1 id="f09d" class="mm mn jg bd mo mp mq mr ms mt mu mv mw km mx kn my kp mz kq na ks nb kt nc nd bi translated">3.实施LDA</h1><p id="7dad" class="pw-post-body-paragraph kv kw jg kx b ky ne kh la lb nf kk ld le ng lg lh li nh lk ll lm ni lo lp lq ij bi translated">本案例研究中使用的数据集是2020年的<a class="ae jd" href="https://www.kaggle.com/tumanovalexander/nyt-articles-data?select=df_2020.csvhttps://www.kaggle.com/tumanovalexander/nyt-articles-data?select=df_2020.csv" rel="noopener ugc nofollow" target="_blank">纽约时报文章数据</a>。该数据集包含大约<em class="nn"> 69k </em>个数据点。</p><p id="991b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下图显示了数据的快照。</p><figure class="oh oi oj ok gt is gh gi paragraph-image"><div class="gh gi og"><img src="../Images/e4d027d29e8b2cfdc5e4744911b43735.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*mH5F5tMtYysXDAkba3lVbg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">文章数据快照(图片由作者提供)</p></figure><p id="5c25" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">列'<em class="nn"> year' </em>可以忽略，因为我们只使用2020年的数据。列'<em class="nn">句子</em>'具有句子级别的文章数据。</p><p id="bd97" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将首先预处理<em class="nn">句子</em>列，然后将Gensim中的LDA模型应用于预处理后的数据。</p><h2 id="9c34" class="nr mn jg bd mo ns nt dn ms nu nv dp mw le nw nx my li ny nz na lm oa ob nc oc bi translated">a.预处理数据</h2><p id="e2c1" class="pw-post-body-paragraph kv kw jg kx b ky ne kh la lb nf kk ld le ng lg lh li nh lk ll lm ni lo lp lq ij bi translated">预处理文本数据不是一步到位的过程，因为它包含冗余和/或重复的单词，必须经过大量的清理。此外，这个过程有时取决于我们寻求的目标。</p><p id="de97" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这个阶段包括删除对文本意义没有附加值的单词或字符<strong class="kx jh">、</strong>。让我们在下面逐一讨论:</p><ul class=""><li id="e3b7" class="lr ls jg kx b ky kz lb lc le lt li lu lm lv lq nj lx ly lz bi translated"><strong class="kx jh">降低文本</strong>的大小写是必要的，原因如下:<br/>单词“选举”、“选举”和“选举”都给句子增加了相同的值。降低所有单词的大小写有助于通过减少词汇的大小来减少维度。</li><li id="fc63" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq nj lx ly lz bi translated">删除任何标点符号将有助于处理像“万岁”和“万岁！”这样的词同理。</li><li id="0f37" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq nj lx ly lz bi translated">停用词是语言中经常出现的词，如“the”、“a”、“an”、“is”。我们可以在这里删除它们，因为它们不会为我们的分析提供任何有价值的信息。另外<strong class="kx jh">删除停止字</strong>减少了数据的维度。</li><li id="82fb" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq nj lx ly lz bi translated">在本案例研究中，当我们寻找构成主题的关键词时，数字不会增加任何价值。因此，我们正在从数据中删除数字。</li></ul><p id="4f96" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以使用Gensim执行上述所有操作。Gensim提供了一个函数，<strong class="kx jh"> <em class="nn"> preprocess_string，</em> </strong>提供了最广泛使用的文本数据预处理技术。该函数提供的默认技术(过滤器)如下:</p><ol class=""><li id="1fc2" class="lr ls jg kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">strip_tags()，</li><li id="ef0e" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">strip _标点符号()，</li><li id="ee33" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">strip_multiple_whitespaces()，</li><li id="c889" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">strip_numeric()，</li><li id="8f13" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">remove_stopwords()，</li><li id="b58a" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">strip_short()，</li><li id="1618" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">stem_text()</li></ol><p id="5d7c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用下面的单行代码，我们可以使用默认过滤器对整个文本数据进行预处理。</p><figure class="oh oi oj ok gt is"><div class="bz fp l di"><div class="ol om l"/></div></figure><h2 id="f59c" class="nr mn jg bd mo ns nt dn ms nu nv dp mw le nw nx my li ny nz na lm oa ob nc oc bi translated">b.词典和语料库的创建</h2><p id="adfc" class="pw-post-body-paragraph kv kw jg kx b ky ne kh la lb nf kk ld le ng lg lh li nh lk ll lm ni lo lp lq ij bi translated">让我们创建一个字典和一个单词语料库包，作为输入传递给模型。</p><ul class=""><li id="6ba1" class="lr ls jg kx b ky kz lb lc le lt li lu lm lv lq nj lx ly lz bi translated"><strong class="kx jh"> <em class="nn">字典</em> </strong>:收集所有独特的单词</li><li id="7f37" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq nj lx ly lz bi translated"><strong class="kx jh"> <em class="nn"> bow_corpus </em> </strong>:将整个语料库中的每个单词转换成单词包。单词包是通过使用唯一单词的字典将文档简单转换为向量，在字典中我们可以获得每个单词的频率。</li></ul><figure class="oh oi oj ok gt is"><div class="bz fp l di"><div class="ol om l"/></div></figure><figure class="oh oi oj ok gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi on"><img src="../Images/c8e341643bb44cb161c5ebf976b417f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nVWU4zX0bz7xFpTbr1ZQRA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">字典和bow_corpus的快照(图片由作者提供)</p></figure><h2 id="6cf3" class="nr mn jg bd mo ns nt dn ms nu nv dp mw le nw nx my li ny nz na lm oa ob nc oc bi translated">c.LDA模型</h2><p id="35b0" class="pw-post-body-paragraph kv kw jg kx b ky ne kh la lb nf kk ld le ng lg lh li nh lk ll lm ni lo lp lq ij bi translated">我们把<strong class="kx jh"> <em class="nn">字典</em> </strong>和<strong class="kx jh"> <em class="nn"> bow_corpus </em> </strong>传递给Gensim提供的LDA模型，由它做每个句子的主题建模。</p><p id="f20a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面是使用LDA执行主题建模的代码行。</p><figure class="oh oi oj ok gt is"><div class="bz fp l di"><div class="ol om l"/></div></figure><h2 id="81e0" class="nr mn jg bd mo ns nt dn ms nu nv dp mw le nw nx my li ny nz na lm oa ob nc oc bi translated">d.可视化结果</h2><p id="1ffd" class="pw-post-body-paragraph kv kw jg kx b ky ne kh la lb nf kk ld le ng lg lh li nh lk ll lm ni lo lp lq ij bi translated">有许多方法可以用来可视化的结果，如tSNE，文字云，条形图。我们将使用<strong class="kx jh"> <em class="nn"> pyLDAvis </em> </strong>来可视化我们的LDA模型，因为它是查看结果的最具交互性的工具之一。</p><p id="630f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面是用于显示LDA模型结果的代码。</p><figure class="oh oi oj ok gt is"><div class="bz fp l di"><div class="ol om l"/></div></figure><figure class="oh oi oj ok gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oo"><img src="../Images/b93d70d654ea2e50913c474b33bdf4ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4SwfOuE5tfNgiJuzGLkwwQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">pyLDAvis可视化主题，每个主题有前30个相关术语(图片由作者提供)</p></figure><p id="167a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">每个气泡代表一个主题。每个主题的大小显示了主题的受欢迎程度，各个主题的接近程度显示了主题之间的相似性。</p><p id="01b1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">正如我们所看到的，最常见的话题是电晕、病毒、疫情，我们知道这是2020年全球讨论最多的话题。</p><p id="0ea5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">看到结果，我们可以断言，我们创建了一个非常好的模型，能够将主要新闻识别为最受欢迎的话题。</p></div><div class="ab cl mf mg hu mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="ij ik il im in"><h1 id="6dd3" class="mm mn jg bd mo mp mq mr ms mt mu mv mw km mx kn my kp mz kq na ks nb kt nc nd bi translated">4.进一步增强</h1><p id="59d6" class="pw-post-body-paragraph kv kw jg kx b ky ne kh la lb nf kk ld le ng lg lh li nh lk ll lm ni lo lp lq ij bi translated">如前所述，模型性能高度依赖于预处理。我们可以使用领域知识和各种文本处理技术来改进预处理——比如词性标注，生成单词的二元/三元模型。</p><p id="026c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们也可以从观想中看到，有几个主题彼此非常接近。当我们减少主题的数量时，这样相似的主题就会聚集到同一个主题中，这使得主题更具排他性。这可以根据我们的目标进行调整。</p></div><div class="ab cl mf mg hu mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="ij ik il im in"><h1 id="16db" class="mm mn jg bd mo mp mq mr ms mt mu mv mw km mx kn my kp mz kq na ks nb kt nc nd bi translated">摘要</h1><p id="bf55" class="pw-post-body-paragraph kv kw jg kx b ky ne kh la lb nf kk ld le ng lg lh li nh lk ll lm ni lo lp lq ij bi translated">在这篇文章中，我们了解了主题建模是什么，为什么和如何。使用python库、Gensim和Gensim的LDA对2020年的《纽约时报》文章进行预处理和主题建模。使用pyLDAvis生成结果的交互式可视化。该模型的性能与预先定义的参数是令人满意的。</p></div><div class="ab cl mf mg hu mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="ij ik il im in"><p id="f3ff" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">感谢阅读！我也将在未来写更多初学者友好的帖子。请在<a class="ae jd" href="https://medium.com/@ramyavidiyala" rel="noopener">媒体</a>上关注我，以便了解他们。我欢迎反馈，可以通过Twitter <a class="ae jd" href="https://twitter.com/ramya_vidiyala" rel="noopener ugc nofollow" target="_blank"> ramya_vidiyala </a>和LinkedIn <a class="ae jd" href="https://www.linkedin.com/in/ramya-vidiyala-308ba6139/" rel="noopener ugc nofollow" target="_blank"> RamyaVidiyala </a>联系我。快乐学习！</p></div></div>    
</body>
</html>