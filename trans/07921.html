<html>
<head>
<title>The Next Step in Machine Learning’s Evolution: Graph Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习进化的下一步:图形神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-next-step-in-machine-learnings-evolution-graph-neural-networks-fdf16b8df85a?source=collection_archive---------27-----------------------#2021-07-20">https://towardsdatascience.com/the-next-step-in-machine-learnings-evolution-graph-neural-networks-fdf16b8df85a?source=collection_archive---------27-----------------------#2021-07-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/da535385904d7f95c8a0342122f353f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TgIEBGS1BCMtP4ug"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">鲍勃·奥西阿斯在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="8580" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated"><strong class="ak"> <em class="kv">如果你有多维网络数据集，考虑一个图形神经网络</em> </strong></h2></div><p id="780f" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从任务关键型机器学习部署中持续获得企业价值的能力取决于以下三种应用中的至少一种:分类实体、预测事件和理解事件发生的原因。</p><p id="8b53" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">无论使用哪种技术，无论是包括监督、非监督还是强化学习，或者如果涉及深度学习的规模和计算，传统的机器学习在解决这些业务问题方面都有局限性。</p><p id="d5c6" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它适用于许多类型的数据，但在应用于高维网络数据集时会遇到困难和彻底失败。这些限制要求社交网络研究、推荐引擎、生物学、化学、计算机视觉和自然语言处理部署采用一种新的方法，其中上下文至关重要。</p><p id="29b1" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae jd" href="https://arxiv.org/ftp/arxiv/papers/1812/1812.08434.pdf" rel="noopener ugc nofollow" target="_blank">图形神经网络</a>擅长预测事件，解释事件，并对实体进行大规模分类，从而为这些和其他实用部署提供惊人的准确性。将他们的推理与语义推理相结合，创建了额外的知识，用于基于高维度数据中的多方面、情境化的关系来预测事件。</p><p id="e7d1" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">无论是用于反洗钱、疾病预测还是电子商务产品推荐，它都大大提高了机器学习执行前面提到的任务的能力，因此企业用户可以利用这项技术。</p><p id="25c9" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky jh">机器学习的问题</strong></p><p id="3c29" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">典型的机器学习部署的问题是，它们只能在欧几里德数据集或容易转换为数字的低维数据上工作良好。这些数字(称为向量)描述了一系列情况的特征，从消费者行为到用于面部识别的眼睛和鼻子之间的距离。例如，特征向量通知完成准确检测对象的预测，而不管它们在屏幕上的什么位置，使用什么类型的照明，或者它们的大小。</p><p id="fdc3" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，这种方法的有效性在具有两个以上维度的非欧几里德数据集上迅速下降，在这些数据集上，底层上下文对于表示用于计算的真实世界的实体是至关重要的。例如，对于金融中的“了解你的客户”<a class="ae jd" href="https://www.gartner.com/smarterwithgartner/financial-forecasters-should-beware-3-machine-learning-myths/" rel="noopener ugc nofollow" target="_blank">用例，很难根据客户在网络中的朋友和敌人(以及这些人的朋友和敌人)对客户进行分类，因为这些数据不容易矢量化。向量中的每个数字都依赖于图形的其他部分，这使得这种方法过于复杂——但对于图形神经网络来说并非如此。</a></p><p id="cc24" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky jh">图形神经网络</strong></p><p id="eb6a" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在前面的例子或任何其他情况下，情况的背景——如开发药物时化学品之间的关系——影响机器学习模型中表示的<a class="ae jd" href="https://blogs.gartner.com/leinar-ramos/2020/10/24/machine-learning-projects/?_ga=2.218061014.1796993379.1622167190-340082403.1618942319" rel="noopener ugc nofollow" target="_blank">数据，图形神经网络完成三项任务。它们通过确定一个实体是否应该与另一个实体(人、业务对象等)有另一个链接来预测关系。)，他们迅速对节点的类型进行分类，并在复杂的图形中精确定位形状或聚类以检测子图。</a></p><p id="2f50" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些神经网络的大多数应用都结合了所有这三种能力，尽管它们的预测能力很容易在推荐产品、服务甚至回答客户服务问题等用例中给人留下最深刻的印象。他们还擅长预测与反洗钱和其他金融服务法规相关的行动，或预测人们对社交网络中不同事件或行动的反应。</p><p id="7d3a" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky jh">可扩展的上下文化</strong></p><p id="4015" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些用例中的最后一个最令人印象深刻，不仅因为图形神经网络的预测准确性，还因为它们实现这些结果的环境规模。这里描述了<a class="ae jd" href="https://arxiv.org/pdf/1904.05530.pdf" rel="noopener ugc nofollow" target="_blank">的一个有趣的应用领域</a>:根据报纸上记录的一年内的所有世界事件来训练这些模型。这一特定任务包括关于23，000个不同实体(包括国家、政府、机构等)的400，000个事实和超过250种事件类型，如发表声明、发起攻击、威胁或杀人等。</p><p id="19cf" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图形神经网络可以分析大规模新闻数据的背景，识别实体及其相互之间的多方面关系，例如，根据过去10个月发生的一切，发布关于总统将威胁谁以及他将向谁寻求帮助的准确预测。预测基于以前的事件和所需的时间戳。</p><p id="57e8" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky jh">令人印象深刻的含义</strong></p><p id="721e" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种方法的含义可以为关键任务流程的机器学习的企业应用带来革命性的变化。几乎任何事情都是可能的，从通过分析患者的医疗过去(和现在)来快速评估他或她的医疗未来，到为一批资产预测工业互联网中设备故障的准确时间和地点。例如，在市场营销中，图形神经网络可以准确地揭示哪些策略可能在特定的客户群中产生最多的转换，同时为销售和电子商务应用程序带来同样的优势。</p><p id="3330" class="pw-post-body-paragraph kw kx jg ky b kz la kh lb lc ld kk le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图形神经网络对事件之间的上下文的无与伦比的理解是揭示未来将发生什么的蓝图，其上下文化和准确性超越了传统的机器学习。</p></div></div>    
</body>
</html>