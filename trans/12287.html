<html>
<head>
<title>eXplainable AI (XAI): LIME &amp; SHAP, Two Great Candidates to Help You Explain Your Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可解释的人工智能(XAI):莱姆和 SHAP，两个伟大的候选人来帮助你解释你的机器学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/explainable-ai-xai-lime-shap-two-great-candidates-to-help-you-explain-your-machine-learning-a95536a46c4e?source=collection_archive---------10-----------------------#2021-12-14">https://towardsdatascience.com/explainable-ai-xai-lime-shap-two-great-candidates-to-help-you-explain-your-machine-learning-a95536a46c4e?source=collection_archive---------10-----------------------#2021-12-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b238" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用两个代理工具来更好地理解模型的预测。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9421a189717f4b20fbe1b2f5084dbf39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cXXoagWy2hJE_w_6"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@medienstuermer" rel="noopener ugc nofollow" target="_blank">医学家</a>在<a class="ae ky" href="https://unsplash.com/photos/aWf7mjwwJJo" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="cba0" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="2e44" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">作为数据科学家或机器学习实践者，将可解释层集成到您的机器学习模型中可以使它们值得信赖。它可以帮助决策者和其他利益相关者获得更多的可见性，并理解导致模型输出的决策的解释。</p><p id="6cfc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在本文中，我将带您了解两个代理模型，<strong class="lt iu">莱姆</strong>和<strong class="lt iu"> SHAP </strong>，帮助您了解您的模型的决策过程。</p><h1 id="6b80" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">模型结构</h1><p id="8e83" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们将使用来自 Kaggle 的<a class="ae ky" href="https://www.kaggle.com/cjboat/diabetes2" rel="noopener ugc nofollow" target="_blank">糖尿病数据集</a>。主要的焦点是可解释性，所以我们不会花太多时间去尝试花哨的模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><h1 id="c2dc" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">模型可解释性</h1><h2 id="e9a3" class="mu la it bd lb mv mw dn lf mx my dp lj ma mz na ll me nb nc ln mi nd ne lp nf bi translated"><strong class="ak"> <em class="ng"> SHAP </em> </strong></h2><p id="389d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">它代表沙普利加法解释。该方法旨在通过计算每个特征对预测的贡献来解释实例/观察的预测。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="bf2a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">SHAP 有许多模型解释的可视化工具，但是我们将讨论其中几个，每一个都有其特殊性。</p><ol class=""><li id="240d" class="nh ni it lt b lu mn lx mo ma nj me nk mi nl mm nm nn no np bi translated"><strong class="lt iu">带汇总图的变量重要性</strong></li></ol><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/9d29ea878eeacb83f671c39d48ea122f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*BZ8HftJTaRNkD4-vPTWgUA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 1:显示重要变量的汇总图</p></figure><p id="14f5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">观察:</strong>以下是我们从之前的剧情中可以推断出来的:</p><ul class=""><li id="54d2" class="nh ni it lt b lu mn lx mo ma nj me nk mi nl mm nr nn no np bi translated">它显示了重要特性的列表，从最重要到最不重要(从上到下)。</li><li id="b009" class="nh ni it lt b lu ns lx nt ma nu me nv mi nw mm nr nn no np bi translated">特征分析</li><li id="b7de" class="nh ni it lt b lu ns lx nt ma nu me nv mi nw mm nr nn no np bi translated">所有的特征似乎对被诊断为糖尿病(标签=1)或未被诊断为糖尿病(标签= 0)的两个类别都有同等的贡献，因为颜色占据了矩形的 50%。</li><li id="6390" class="nh ni it lt b lu ns lx nt ma nu me nv mi nw mm nr nn no np bi translated">根据该模型，葡萄糖是最具有预测能力的一种。</li><li id="b8ac" class="nh ni it lt b lu ns lx nt ma nu me nv mi nw mm nr nn no np bi translated">年龄是第二个最有预测力的特征。</li><li id="1a6a" class="nh ni it lt b lu ns lx nt ma nu me nv mi nw mm nr nn no np bi translated">怀孕是最有预测力的第五个特征。</li></ul><p id="7cdd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> 2。特定标签上的汇总图</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/011cee07b2dc8fc86a752eff6db4c9ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*icVYmjFlzY0L7u9BvApYqQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 2:标签= 1 上的深度摘要图</p></figure><p id="602d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">观察:</strong>对于分类问题，每个可能的标签都存在 SHAP 值。在我们的例子中，我们决定得到预测值 1(真)。以下是从图中可以推断出的主要特征:</p><ul class=""><li id="a821" class="nh ni it lt b lu mn lx mo ma nj me nk mi nl mm nr nn no np bi translated">对于<strong class="lt iu"><em class="ny"/></strong><strong class="lt iu"><em class="ny">重要特性</em> </strong>，同样从变量重要性情节进行分析。</li><li id="48a6" class="nh ni it lt b lu ns lx nt ma nu me nv mi nw mm nr nn no np bi translated">每个点代表单个数据实例的特征值。</li><li id="2409" class="nh ni it lt b lu ns lx nt ma nu me nv mi nw mm nr nn no np bi translated">颜色表明该特征是高值(红色)还是低值(蓝色)。</li><li id="e46d" class="nh ni it lt b lu ns lx nt ma nu me nv mi nw mm nr nn no np bi translated">X 轴显示对预测输出的积极或消极贡献</li></ul><p id="71e0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">当我们将这些分析应用于特征时，我们得到以下解释:</p><ul class=""><li id="7319" class="nh ni it lt b lu mn lx mo ma nj me nk mi nl mm nr nn no np bi translated"><strong class="lt iu">对于葡萄糖:</strong>我们看到大多数高值(红点)对预测输出有正贡献(在 X 轴上为正)。换句话说，如果单个数据实例的葡萄糖量很高，其具有阳性结果(被诊断为糖尿病)的可能性会大大增加，而低量(蓝点)会降低(负 X 轴值)被诊断为糖尿病的可能性。</li><li id="b399" class="nh ni it lt b lu ns lx nt ma nu me nv mi nw mm nr nn no np bi translated"><strong class="lt iu">对于年龄</strong>:对年龄进行同样的分析。年龄越高，数据实例(患者)最有可能被诊断为糖尿病。另一方面，当涉及到未成年时，该模型似乎很混乱，因为我们可以在垂直线(X 轴=0)的每一侧观察到几乎相同数量的数据点。由于年龄特征对于分析来说似乎是令人困惑的，我们可以使用<strong class="lt iu"> <em class="ny">依赖关系</em> </strong> <strong class="lt iu"> <em class="ny">情节</em> </strong>来获得更细粒度的信息。</li></ul><p id="f55f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> 3。依赖图</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/557246d51e2ffd0630ddeccdfb809401.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*M48mXeqW4WoC43uX2eFtfg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 3:年龄特征的<strong class="bd oa">依赖</strong> <strong class="bd oa">图</strong></p></figure><p id="12d9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">观察:</strong>从依赖关系图中，我们可以清楚地看到，30 岁以下的患者被诊断为糖尿病的风险较低，而 30 岁以上的患者被诊断为糖尿病的风险较高。</p><h2 id="cbef" class="mu la it bd lb mv mw dn lf mx my dp lj ma mz na ll me nb nc ln mi nd ne lp nf bi translated">石灰</h2><p id="d50c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">它代表局部可解释模型不可知解释。<strong class="lt iu"> <em class="ny">局部</em> </strong>方面意味着它用于解释机器学习模型的个体预测。</p><p id="76d8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">设置讲解人</strong></p><p id="0319" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">使用两个非常简单的步骤来构建解释器:(1)导入模块，(2)使用训练值、特征和目标来适应解释器。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="58ca" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> <em class="ny">第 5 行</em> </strong>:我用最容易理解的方式创建了两个标签，而不是 1 和 0。</p><p id="4d01" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">单实例解释</strong></p><p id="dc1d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这里，对来自测试数据的单个实例进行解释</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/7ba5a64219b81dc6d65fcda8c8af49fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KTBIswPulIWproPGgfoEuQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 3:单个实例的时间解释能力</p></figure><p id="c1c5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">观察:t </strong>该模型以 73%的置信度预测该特定患者患有糖尿病，并且解释了该预测，因为葡萄糖水平高于 99，血压高于 70。在右边，我们可以观察到真实特征对患者的价值。</p><h1 id="ae45" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">文章结尾</h1><p id="1370" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">恭喜你！你刚刚学会了如何用 SHAP 和莱姆来解释你的机器学习模型。现在，您可以构建可信的模型，帮助决策者和其他利益相关者获得更多的可见性，并理解导致模型输出的决策的解释。本文只介绍了这些工具的一小部分，您可以在下面的附加资源中进一步分析。</p><p id="bdb6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在 YouTube 上关注我，了解更多互动会话！</p><h1 id="c76c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">额外资源</h1><p id="e6e3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><a class="ae ky" href="https://shap.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">欢迎来到 SHAP 文档</a></p><p id="3f91" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="https://lime-ml.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">本地可解释的模型不可知解释(lime) </a></p><p id="81bc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">再见🏃🏾</p></div></div>    
</body>
</html>