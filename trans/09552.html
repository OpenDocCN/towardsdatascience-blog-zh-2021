<html>
<head>
<title>Explaining how I reached the top ranks of the new Data-Centric competition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解释我如何在以数据为中心的新竞争中名列前茅</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/explaining-how-i-reached-the-top-ranks-of-the-new-data-centric-competition-888fc8e86547?source=collection_archive---------8-----------------------#2021-09-05">https://towardsdatascience.com/explaining-how-i-reached-the-top-ranks-of-the-new-data-centric-competition-888fc8e86547?source=collection_archive---------8-----------------------#2021-09-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="0992" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="6173" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">继吴君如本人代言(！)关于我的上一篇文章，很自然地分享了所有的技巧(带代码！)关于我如何应对DeepLearning.ai的新挑战。</h2></div><p id="6bac" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><em class="ln">10月21日编辑:我以优秀奖的身份被选为8名获奖者之一(见下文)。</em></p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/7a8fdbce510a4444603ed53b13871b2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iAafM-CytcmMocQV"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated"><a class="ae me" href="https://unsplash.com/@universaleye?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">万用眼</a>在<a class="ae me" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><h1 id="780c" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">比赛解释…又来了！</h1><p id="c2ad" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">如果你还不熟悉DeepLearning.ai几周前推出的以数据为中心的新挑战，你可以看看我几周前写的描述这一挑战的文章。</p><p id="f3ef" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">不确定这是否值得？只是听从吴恩达的建议😉：</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/56bffb13578457d5550bdda7508b55be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*4DJKx1DQ5_yCId25ruDnhQ.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">截图自Andrew NG对我上一篇文章的背书—2021年8月<br/><a class="ae me" href="https://www.linkedin.com/feed/update/urn:li:activity:6830591493435224064/" rel="noopener ugc nofollow" target="_blank">https://www . LinkedIn . com/feed/update/urn:李:活动:6830591493435224064/ </a></p></figure><div class="nf ng gp gr nh ni"><a href="https://medium.com/geekculture/a-deep-dive-into-andrew-ng-data-centric-competition-eb2bc0886005" rel="noopener follow" target="_blank"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd jd gy z fp nn fr fs no fu fw jc bi translated">深入探讨Andrew NG以数据为中心的竞争</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">关于这种新型挑战，您需要了解的一切，关注数据质量而不是模型…</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">medium.com</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw ly ni"/></div></div></a></div><p id="2703" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果你赶时间，<strong class="kt jd">长话短说</strong>:比赛的目标是产生尽可能好的一组图片来训练预定义的模型(ResNet50)识别罗马数字。该竞赛提供了一个大约。3000张图片，包括嘈杂和贴错标签的数字，如下图所示:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/83afadef6bd539cdee80b110af4272e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7QXgFrXLJsCsV53o"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">从训练数据集中提取-由作者在DeepLearning.ai的授权下编译</p></figure></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h1 id="f2d7" class="mf mg it bd mh mi of mk ml mm og mo mp ki oh kj mr kl oi km mt ko oj kp mv mw bi translated">让游戏开始吧！</h1><p id="0a35" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">我将介绍不同的步骤，以平稳的方式达到良好的性能，但这显然是我为了找到最佳组合而进行的多次测试和试验的结果！</p><p id="d613" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果您想进一步探索我的解决方案，我还在GitHub上创建了一个专门的资源库(本文末尾有链接)。</p><h2 id="413b" class="ok mg it bd mh ol om dn ml on oo dp mp la op oq mr le or os mt li ot ou mv iz bi translated">1.图片评论</h2><p id="d6a2" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">第一项任务可能是要求最高的:查看每张照片，检查一些标准。以下是我用过的一些:</p><ul class=""><li id="c55a" class="ov ow it kt b ku kv kx ky la ox le oy li oz lm pa pb pc pd bi translated">这看起来像罗马数字吗？(如果没有，我们就应该去掉！)</li><li id="26f7" class="ov ow it kt b ku pe kx pf la pg le ph li pi lm pa pb pc pd bi translated"><strong class="kt jd">图片标注正确吗？</strong>(例如。“II”在“III”文件夹中，反之亦然)</li><li id="7a44" class="ov ow it kt b ku pe kx pf la pg le ph li pi lm pa pb pc pd bi translated"><strong class="kt jd">什么是数质？</strong>(评分从1:好到4:差)</li><li id="3add" class="ov ow it kt b ku pe kx pf la pg le ph li pi lm pa pb pc pd bi translated"><strong class="kt jd">背景质量如何？</strong>(等级同上)</li><li id="cacc" class="ov ow it kt b ku pe kx pf la pg le ph li pi lm pa pb pc pd bi translated"><strong class="kt jd">什么是字体风格？</strong>(“Arial”或“Roman”)</li><li id="dd4a" class="ov ow it kt b ku pe kx pf la pg le ph li pi lm pa pb pc pd bi translated"><strong class="kt jd">数字的确切格式是什么？</strong>(“viii”或“VIII”)</li><li id="3976" class="ov ow it kt b ku pe kx pf la pg le ph li pi lm pa pb pc pd bi translated">我们能应用对称吗？(水平或垂直对称通常适用于“I、II、III或X”数字，但不适用于“I”、“II”或“VII”)</li></ul><p id="9940" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">以下是我评估的三个例子(以表格形式存储):</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pj"><img src="../Images/2fd05156569eebc50146f5e286f35d99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LNJ-JSNOt8XpN4cXAd1PLg.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">图片分类示例—按作者分类的图片</p></figure><p id="cba9" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在查看3000张照片时(这花了我大约2到3个小时😅)，我有时会有“似曾相识”的感觉，我开始怀疑数据集中是否隐藏了一些重复项？这并不奇怪，所以我也必须考虑到这一点。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pk"><img src="../Images/7c2d94361ddbbf3d97b4e5426599deac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*w3H6iVfVDzTwaeoH"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">照片由<a class="ae me" href="https://unsplash.com/@jhaland?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">约尔根·哈兰</a>在<a class="ae me" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><p id="5ba2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我还设计了一个简单的函数来自动检查文件夹的内容，以评估我将执行的不同操作的结果。像我后来在笔记本中使用的所有其他函数一样，我将它存储在一个专用的“dcc_functions.py”中(可以在GitHub存储库中找到)。</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="pl pm l"/></div></figure><p id="603e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">以下是初始数据集的输出:</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="pl pm l"/></div></figure><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pn"><img src="../Images/1e78696b556016186ffbec1a2c486a97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3SO3NjxhCQlbfjUJVPPjWg.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated"><strong class="bd po"> folders_sumary </strong>由<strong class="bd po"> Pierre-Louis Bescond </strong>输出</p></figure><h2 id="1298" class="ok mg it bd mh ol om dn ml on oo dp mp la op oq mr le or os mt li ot ou mv iz bi translated">2.数据集清理</h2><p id="edda" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated"><strong class="kt jd"> 2.1噪声消除</strong></p><p id="5d8d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我首先删除所有我认为纯粹是噪音或者至少是噪音太大而无法正确训练模型的图片。这显然是个人的选择，每个参与者可能都有不同的选择。我确定大约。要删除的260张图片(相应的列表存储在GitHub repo上的Excel文件中)。</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="pl pm l"/></div></figure></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><p id="02b8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> 2.2去重</strong></p><p id="1251" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如前所述，我感觉有些照片完全一样，但手动识别它们是不可能的。我知道有一些技术可以解决这个问题:</p><ul class=""><li id="84c2" class="ov ow it kt b ku kv kx ky la ox le oy li oz lm pa pb pc pd bi translated">将大小相同的文件配对 …但是会出现很多误报</li><li id="c0dd" class="ov ow it kt b ku pe kx pf la pg le ph li pi lm pa pb pc pd bi translated"><strong class="kt jd">配对大小相同的文件&amp;配置</strong>(如两个“II”或“viii”)</li><li id="220b" class="ov ow it kt b ku pe kx pf la pg le ph li pi lm pa pb pc pd bi translated"><strong class="kt jd">按文件统计配对文件</strong>(使用，例如。，<a class="ae me" href="https://pillow.readthedocs.io/en/stable/reference/ImageStat.html" rel="noopener ugc nofollow" target="_blank"> PIL的ImageStat </a></li><li id="8881" class="ov ow it kt b ku pe kx pf la pg le ph li pi lm pa pb pc pd bi translated"><strong class="kt jd">利用结构相似度指标对文件进行配对</strong>(此处<a class="ae me" rel="noopener" target="_blank" href="/how-pictures-structural-similarity-can-boost-your-computer-vision-projects-3dbb721a0fa">有说明</a>)</li><li id="71a8" class="ov ow it kt b ku pe kx pf la pg le ph li pi lm pa pb pc pd bi translated"><strong class="kt jd">根据文件的“哈希”号将文件配对</strong></li></ul><p id="32c5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">由于这不是一个“生死攸关”的问题，我决定使用第二种解决方案，这种方案既简单又容易实现。剧本(<a class="ae me" href="https://github.com/pierrelouisbescond/data-centric-challenge-public/blob/main/dcc_find_duplicates.ipynb" rel="noopener ugc nofollow" target="_blank">此处</a>)确定了大约200对双胞胎照片，其中53张实际上是真正的复制品(下面是一些例子):</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pp"><img src="../Images/ba47fc2c48952656fa2efab8ddd7e823.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8rszfx3DvctbqabKifDEzw.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">由<strong class="bd po">DCC _ find _ duplicates . ipynb</strong>通过<strong class="bd po"> Pierre-Louis Bescond </strong>识别的双胞胎对的例子</p></figure></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><p id="1b2e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> 2.3移动右侧文件夹中的一些图片</strong></p><p id="3f17" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">没必要在这上面花太多时间:当一张照片被贴错标签时，我只是把它移回到它所属的文件夹。</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><p id="b4c5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> 2.4前卫还是不前卫？</strong></p><p id="b897" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在我们继续之前，我想分享一个有趣的发现:我看了两次照片:一次是在我参加比赛的时候，另一次是在我对照片有了更好的想法的时候。</p><p id="bd76" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">当我第一次查看原始图片时，我已经排除了许多看起来太模糊而无法训练模型的“边缘案例”。</p><p id="16e3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">但比赛开始几周后，我开始习惯这些尖锐的案例，并以不同的方式考虑它们，比如:“嗯，包括这个案例可能是好的，以教导模型这个案例可能会发生。”我最后添加了大约。80张图片到数据集。</p><p id="3eba" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">与直觉相反的是，这一新选择的性能正在下降，包括更尖锐的图片。怎么会这样</p><p id="bc02" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">参与者之一<a class="nc nd ep" href="https://medium.com/u/6a49733f05dd?source=post_page-----888fc8e86547--------------------------------" rel="noopener" target="_blank"> Mohamed Mohey </a>在专门的对话主题中强调，32x32变换(在训练前应用于数据集)有时会完全改变图片的本质，如下例所示:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/7b78eefe3f3978b4047602dadc151a08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*dfIBVGLVmVvnNXE6tz3dug.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">32x32转换前后的相同图片-图片由作者提供-归功于<a class="nc nd ep" href="https://medium.com/u/6a49733f05dd?source=post_page-----888fc8e86547--------------------------------" rel="noopener" target="_blank"> Mohamed Mohey </a></p></figure><p id="f0af" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们可以观察到，由于这种32x32的转换，一个明显的“III”正在变成一个似是而非的“II”，解释了为什么一些尖锐的案例不一定会给模型带来有价值的信息。</p><p id="b111" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在32x32的转换后再看一遍照片可能是件好事，但我没有！</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><p id="1f08" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> 2.5使用“标签簿”图片训练模型</strong></p><p id="f0a5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">DeepLearning.ai的组织者提供了一组52张图片，这些图片不在“train”或“validation”文件夹中，以评估我们的模型在ResNet50训练结束时的表现。</p><p id="e45a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这是一个很好的方式来了解模型在最终和隐藏数据集上将如何表现，但由于排行榜上显示的分数，我也“猜测”到<strong class="kt jd">对隐藏数据集的最终评估包括2420张图片</strong> ( <a class="ae me" href="https://github.com/pierrelouisbescond/data-centric-challenge-public/blob/main/dcc_final_dataset_estimate.ipynb" rel="noopener ugc nofollow" target="_blank">请参见这里的相应笔记本</a>)。所以52张图片无论如何都不是很有代表性！</p><p id="9a9c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">所以我干脆把这些图片放在了我的训练文件夹里！越开心，越有趣😁</p><p id="d4c2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> 2.6评估增强技术的影响</strong></p><p id="5124" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">正如你可能知道的，在由图片组成的数据集上使用增强技术来帮助深度学习模型识别允许正确推断类别的特征是非常常见的。</p><p id="a58d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我决定考虑其中的几个:</p><ul class=""><li id="5f9d" class="ov ow it kt b ku kv kx ky la ox le oy li oz lm pa pb pc pd bi translated"><strong class="kt jd">水平和垂直对称</strong></li><li id="d340" class="ov ow it kt b ku pe kx pf la pg le ph li pi lm pa pb pc pd bi translated"><strong class="kt jd">顺时针和逆时针旋转(10°和20°)</strong></li><li id="befd" class="ov ow it kt b ku pe kx pf la pg le ph li pi lm pa pb pc pd bi translated"><strong class="kt jd">水平和垂直平移</strong></li><li id="f4f3" class="ov ow it kt b ku pe kx pf la pg le ph li pi lm pa pb pc pd bi translated"><strong class="kt jd">裁剪图片中的白色区域</strong></li><li id="9264" class="ov ow it kt b ku pe kx pf la pg le ph li pi lm pa pb pc pd bi translated"><strong class="kt jd">添加合成“盐和胡椒”噪声</strong></li><li id="2549" class="ov ow it kt b ku pe kx pf la pg le ph li pi lm pa pb pc pd bi translated"><strong class="kt jd">将一些图片的噪声转移到另一些图片上</strong></li></ul><p id="210f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> 2.7实现海关功能</strong></p><p id="19f9" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">第一个功能非常简单，很容易用PIL、OpenCV，甚至像ImgAug这样的“打包解决方案”来实现。我认为分享一些关于我设计的自定义函数的技巧会更有趣😀</p><p id="a856" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> <em class="ln"> 2.7.1平方裁剪功能</em> </strong></p><p id="1eb3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">裁剪操作是一个有趣的操作！由于图片最终将被转换为32x32的图片，放大数字所在的区域可能会更好。</p><p id="6add" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">但是，如果数字不是“平方”形状，则在转换为32x32时，结果可能会失真(如下所示)。我重新设计了该函数，以便裁剪后的输出将始终为方形，并避免这种失真效果:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pr"><img src="../Images/652ff45831c37312fa89fd3276c82217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oWhZriWTCDNpAX3KiD6CiQ.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">原始和裁剪的可能输出—作者提供的图像</p></figure><p id="908c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> <em class="ln"> 2.7.2【盐和胡椒】功能</em> </strong></p><p id="83fc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">由于最终评估数据集上的背景可能不总是纯白的，我试图通过添加合成背景来增加图片。</p><p id="dc4a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我使用了“salt &amp; pepper”函数，它基本上是将“0”和“1”随机添加到描述图片的NumPy数组中:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi ps"><img src="../Images/81d862af5ad8211e1b3df076eaa33767.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yz4cUmWunM2GaNF1u2QwIA.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">原创和“经验丰富”的图片——作者提供的图片</p></figure><p id="c1cb" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> <em class="ln"> 2.7.3背景噪声传递函数</em> </strong></p><p id="381b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我对“盐和胡椒”函数的结果不太满意，因为噪声总是均匀的，所以我想了另一种方法给图片添加噪声。</p><p id="bf40" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我回收了一些我原本认为不可读的图片，让它们成为一些“嘈杂的背景”的基础。还有一些“背景很重”的图片，我去掉了编号(如下所示)以获得更多的样本。</p><p id="e0b0" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">它为我提供了一个“嘈杂背景库”，里面有10张图片，我在应用水平或垂直对称后随机添加到一些图片中:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pt"><img src="../Images/205cf3d873de7f0c7ed78df76f65305c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3poWRUh2ttbL9paSZ4RKyw.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">嘈杂的背景银行-作者图片</p></figure><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pu"><img src="../Images/e12470e5900ded8c6138dbc2ba79cab6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oyGy3J9Z3UCw-h6bJ970hg.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">背景噪声转移示例—作者提供的图片</p></figure><p id="c2a4" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd"> 2.8选择最佳增量</strong></p><p id="4f78" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">由于允许的图片数量不能超过10.000个元素，我必须知道哪些转换提供了最高的效果。</p><p id="24af" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我决定通过比较基线(没有转换的干净数据集)和每种增强技术的单独性能来对它们进行基准测试(总结如下):</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi pv"><img src="../Images/6cfa0b24633404b78e8ad3f5eed34ba7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*2HyI4Y6TT-BLl7RL2ZDj4w.png"/></div><p class="ma mb gj gh gi mc md bd b be z dk translated">增强的影响，基于损失或准确性-图片由作者提供</p></figure><p id="12a7" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们可以观察到旋转、平移和裁剪带来了比其他方式更大的影响，所以我决定把重点放在这些方面。</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h1 id="00b4" class="mf mg it bd mh mi of mk ml mm og mo mp ki oh kj mr kl oi km mt ko oj kp mv mw bi translated"><strong class="ak">和“瞧”！</strong></h1><p id="b174" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">由于该过程是随机的(以50%的概率和一些随机参数应用变换)，脚本的每次迭代将产生图片的唯一组合。</p><p id="d910" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我的许多测试产生了大约84%的性能，而最高的竞争对手达到了86%(基线为64%)。我猜是光荣的😅</p><p id="5d1c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">将有一些额外的调整要考虑(如创建我自己的图片，并将其添加到数据集，但我选择只依赖于提供的初始图片)。其他人可能也尝试过！</p><h1 id="903a" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">竞争对手表现的全球概览</h1><p id="7862" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">可能还值得一提的是，我分析了竞争对手在挑战的前几周(直到2008年6月)的表现，我们可以看到大多数参与者很快达到了可接受的表现，很快就达到了75%及以上:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pw"><img src="../Images/c29b062107949107f32bdb830765d5f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ba5RsRpZNHKf9ECsxNatIg.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">参赛作品的性能分析—作者提供的图片</p></figure><h1 id="7450" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">最后的话</h1><p id="26e1" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">如前所述，<strong class="kt jd">在对数据进行适当的审查/清理，并在不到30秒的时间内执行一个脚本之后，您可以轻松地胜过最先进的模型在有噪声的数据下所能产生的结果！</strong></p><p id="b6a2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我真的很喜欢参加这个挑战，根据我的说法，<strong class="kt jd">比“GPU能力”更需要“新鲜的想法”</strong>，我真的很期待下一次挑战！</p><p id="e1e8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们与其他参赛者和Lynn(来自DeepLearning.ai)进行了<strong class="kt jd">许多有趣而丰富的互动</strong>，分享我们对这场“同类第一”竞赛的看法。许多参与者更希望分享他们的观点和发现，而不是在排行榜上名列前茅。</p><p id="78d3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我也知道生成“平均和嘈杂的数据”有多困难…所以祝贺组织者提供了这么好的材料来研究！</p><p id="4319" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">当然，我希望你喜欢DeepLearning.ai关于以数据为中心的挑战的第二部分！</p><h1 id="0dda" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">等级</h1><p id="da1a" class="pw-post-body-paragraph kr ks it kt b ku mx kd kw kx my kg kz la mz lc ld le na lg lh li nb lk ll lm im bi translated">我的解决方案被Andrew和他的团队从2000多份提交的作品中选中，并获得了荣誉奖(共有8名获奖者/团队):</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi pt"><img src="../Images/7b0165141f68d7c832292a9f2ee51c1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PvdI0GpHdeCQdAfUZpgjrQ.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated"><a class="ae me" href="https://www.linkedin.com/posts/andrewyng_thank-you-to-everyone-who-participated-in-activity-6851239083843444736-zuKc" rel="noopener ugc nofollow" target="_blank">源链接dIn </a></p></figure><p id="71fb" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">正如我所承诺的，这里是GitHub知识库的链接，欢迎在评论中分享你的经验和/或发现:</p><div class="nf ng gp gr nh ni"><a href="https://github.com/pierrelouisbescond/data-centric-challenge-public" rel="noopener  ugc nofollow" target="_blank"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd jd gy z fp nn fr fs no fu fw jc bi translated">pierrellouisscond/以数据为中心-挑战-公共</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">github.com</p></div></div><div class="nr l"><div class="px l nt nu nv nr nw ly ni"/></div></div></a></div><div class="nf ng gp gr nh ni"><a href="https://pl-bescond.medium.com/pierre-louis-besconds-articles-on-medium-f6632a6895ad" rel="noopener follow" target="_blank"><div class="nj ab fo"><div class="nk ab nl cl cj nm"><h2 class="bd jd gy z fp nn fr fs no fu fw jc bi translated">皮埃尔-路易·贝斯康德关于媒介的文章</h2><div class="np l"><h3 class="bd b gy z fp nn fr fs no fu fw dk translated">数据科学、机器学习和创新</h3></div><div class="nq l"><p class="bd b dl z fp nn fr fs no fu fw dk translated">pl-bescond.medium.com</p></div></div><div class="nr l"><div class="py l nt nu nv nr nw ly ni"/></div></div></a></div></div></div>    
</body>
</html>