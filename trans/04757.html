<html>
<head>
<title>Data Science Quick Tips #012: Creating a Machine Learning Inference API with FastAPI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学快速提示#012:用FastAPI创建机器学习推理API</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-science-quick-tips-012-creating-a-machine-learning-inference-api-with-fastapi-bb6bcd0e6b01?source=collection_archive---------25-----------------------#2021-04-25">https://towardsdatascience.com/data-science-quick-tips-012-creating-a-machine-learning-inference-api-with-fastapi-bb6bcd0e6b01?source=collection_archive---------25-----------------------#2021-04-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/a5e4021d284500ec8141392608d72510.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1tBl3ZoA3kYcUln1snQ_eQ@2x.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="9300" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">与你分享如何使用FastAPI构建一个机器学习推理API</h2></div><p id="5fcd" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">你好，朋友们！我们又回来了，带来了另一篇关于用Docker和FastAPI创建机器学习推理API的半快速文章。说实话，我写这篇文章是为了我自己。虽然我已经非常熟悉Docker，但我个人过去一直使用Flask来构建我的ML推理API。这并不是说Flask一定有什么问题，但是看起来FastAPI正在迅速成为行业标准。FastAPI的一些优势包括…</p><ul class=""><li id="5d64" class="lp lq je kv b kw kx kz la lc lr lg ls lk lt lo lu lv lw lx bi translated"><strong class="kv jf">比Flask </strong>更快:说实话，我试图使用蝗虫工具演示Flask和FastAPI之间的速度测试，我发现它们的性能相当。当然，我测试的模型是一个非常基本的泰坦尼克号分类模型，所以也许我的测试一开始就不是一个好的测试。无论如何，我只是相信人们的话，FastAPI比Flask快</li><li id="78b0" class="lp lq je kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><strong class="kv jf">内置的Swagger文档</strong>:如果你不熟悉Swagger是什么，它是人们记录如何正确使用他们的API的主要行业标准方法之一。这在Flask中根本不存在，所以这绝对是一个受欢迎的好处。</li><li id="ad73" class="lp lq je kv b kw ly kz lz lc ma lg mb lk mc lo lu lv lw lx bi translated"><strong class="kv jf">内置数据验证</strong> : FastAPI允许一个非常简单的方法来实现对你的传入API调用的数据验证，这非常好。我们肯定会在稍后的帖子中对此进行报道。</li></ul><p id="7bdf" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">如果您以前使用过Flask，您会发现这种向FastAPI的转移非常容易。这两个框架在Python代码中的实际实现非常相似。在本帖中，我们将创建一个API，为经典的Iris数据集提供逻辑回归模型。这个模型一点也不花哨，但它将演示如何使用FastAPI轻松地服务于您自己的机器学习模型。</p><p id="79ef" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">和往常一样，如果你想了解这篇文章中显示的代码，你可以在我的个人GitHub 中找到这个<a class="ae md" href="https://github.com/dkhundley/ds-quick-tips/tree/master/012_dockerizing_fastapi" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="af19" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">让我们开始吧！</p><h1 id="303f" class="me mf je bd mg mh mi mj mk ml mm mn mo kk mp kl mq kn mr ko ms kq mt kr mu mv bi translated">训练虹膜模型</h1><p id="23da" class="pw-post-body-paragraph kt ku je kv b kw mw kf ky kz mx ki lb lc my le lf lg mz li lj lk na lm ln lo im bi translated">在我的GitHub repo中，我实际上已经创建并导出了Iris逻辑回归模型，您可以随意使用，但是如果您想训练自己的模型，下面是我为此创建的脚本:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="83ae" class="nk mf je ng b gy nl nm l nn no"># Importing the required Python libraries<br/>import numpy as np<br/>import pandas as pd<br/>import pickle<br/>from sklearn import datasets<br/>from sklearn.linear_model import LogisticRegression</span><span id="3452" class="nk mf je ng b gy np nm l nn no"># Loading the iris dataset from Scikit-Learn<br/>iris = datasets.load_iris()</span><span id="43d4" class="nk mf je ng b gy np nm l nn no"># Converting the iris dataset into a Pandas DataFrame<br/>df_iris = pd.DataFrame(data = np.c_[iris['data'], iris['target']],<br/>            columns = iris['feature_names'] + ['target'])</span><span id="a383" class="nk mf je ng b gy np nm l nn no"># Separating the training dataset (X) from the predictor value (y)<br/>X = df_iris.drop(columns = ['target'])<br/>y = df_iris[['target']]</span><span id="a939" class="nk mf je ng b gy np nm l nn no"># Instantiating a Logistic Regression (LR) model<br/>lr_model = LogisticRegression()</span><span id="beec" class="nk mf je ng b gy np nm l nn no"># Fitting the dataset to the LR model<br/>lr_model.fit(X, y)</span><span id="cba3" class="nk mf je ng b gy np nm l nn no"># Saving the model to a serialized .pkl file<br/>pkl_filename = "../model/iris_model.pkl"<br/>with open(pkl_filename, 'wb') as file:<br/> pickle.dump(lr_model, file)</span></pre><p id="8f66" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">再说一次，我们在这里没有做任何花哨的事情。因为Iris数据集本身是一个非常干净的数据集，所以我所做的唯一一件事就是加载原始形式的数据集，并立即将其输入到Scikit-Learn的逻辑回归模型中。一旦模型被训练，我们就把它作为一个序列化的<code class="fe nq nr ns ng b">.pkl</code>文件转储出来，这就是我们将用于模型推理的精确文件。</p><p id="11dd" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这一节到此为止！让我们开始使用FastAPI来构建我们的API。</p><h1 id="ebf1" class="me mf je bd mg mh mi mj mk ml mm mn mo kk mp kl mq kn mr ko ms kq mt kr mu mv bi translated">用基本GET端点实例化FastAPI</h1><p id="a844" class="pw-post-body-paragraph kt ku je kv b kw mw kf ky kz mx ki lb lc my le lf lg mz li lj lk na lm ln lo im bi translated">好的，在我们开始之前，我们需要从PyPi快速安装我们将要使用的Python库。幸运的是，这非常简单:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="be9a" class="nk mf je ng b gy nl nm l nn no">pip3 install fastapi uvicorn</span></pre><p id="e3bb" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">安装<code class="fe nq nr ns ng b">fastapi</code>对你来说可能是显而易见的，但是你可能对<code class="fe nq nr ns ng b">uvicorn</code>很好奇。Flask和FastAPI都需要一种网关接口。Flask需要一个类似于<code class="fe nq nr ns ng b">gunicorn</code>的WSGI服务器，而<code class="fe nq nr ns ng b">uvicorn</code>本质上是WSGI的“精神”继承者，也就是所谓的ASGI服务器。如果这有点令人困惑，请不要担心。你需要知道的主要事情是，当我们在终端中启动FastAPI时，我们实际上将使用<code class="fe nq nr ns ng b">uvicorn</code>来执行它。</p><p id="07e2" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">正如你在<a class="ae md" href="https://github.com/dkhundley/ds-quick-tips/blob/master/012_dockerizing_fastapi/container/api.py" rel="noopener ugc nofollow" target="_blank">我的GitHub脚本</a>中注意到的，整个API非常容易上手。让我们从一个非常基本的GET端点开始。与Flask一样，FastAPI利用位于函数之上的Python装饰器来提供不同的端点。这里的语法将用这个单一的GET端点创建一个超级简单的API。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="c0f7" class="nk mf je ng b gy nl nm l nn no">from fastapi import FastAPI, Request</span><span id="a7a7" class="nk mf je ng b gy np nm l nn no"># Instantiating FastAPI<br/>api = FastAPI()</span><span id="1c9f" class="nk mf je ng b gy np nm l nn no"># Defining a test root path and message<br/>@api.get('/')<br/>def root():<br/>  return {'message': 'Hello friends!'}</span></pre><p id="4035" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">信不信由你，这实际上是一个全功能的API。它显然什么都不做，但是如果您想看看它目前的运行情况，让我们启动FastAPI来看看这个小东西的运行情况。为此，我们将执行以下命令:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="466f" class="nk mf je ng b gy nl nm l nn no">uvicorn api:api --host 0.0.0.0 --port 5001 --reload</span></pre><p id="6fbd" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这是在寻找一个名为<code class="fe nq nr ns ng b">api.py</code>的Python文件，然后寻找一个名为<code class="fe nq nr ns ng b">api</code>的FastAPI实例。然后我们将它绑定到端口<code class="fe nq nr ns ng b">5001</code>上的主机<code class="fe nq nr ns ng b">0.0.0.0</code>，最后一个<code class="fe nq nr ns ng b">--reload</code>标志只是在您更改<code class="fe nq nr ns ng b">api.py</code>脚本时重新加载您的API。这对于测试来说很好，但是我建议您在生产环境中去掉最后一个标志。</p><p id="46c6" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">现在您的API在一个终端窗口中运行，打开另一个终端窗口并执行下面的<code class="fe nq nr ns ng b">curl</code>命令:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="287c" class="nk mf je ng b gy nl nm l nn no">curl 0.0.0.0:5001</span></pre><p id="251d" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">因为我们没有指定任何路径，它将默认为主要的<code class="fe nq nr ns ng b">'/'</code>路径，因此应该返回我们的小“Hello friends！”给你回信息。整洁！现在，打开浏览器，前往<a class="ae md" href="http://localhost:5001/docs." rel="noopener ugc nofollow" target="_blank"> http://localhost:5001/docs。</a>这是你应该看到的:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nt"><img src="../Images/6934c6307f8f62bed8b690c2f7f7b2be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5E3c6nIm9e7yBmDavjIZVw@2x.jpeg"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">作者截图</p></figure><p id="391e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">正如您所看到的，Swagger已经在这里编目了我们的基本GET端点，甚至允许您做一点测试触发器来测试这个端点。现在这里没有太多内容，但是随着我们在这篇文章中的继续，您将看到这是如何成为一个非常强大的工具，用于快速记录您的机器学习推理API。不错！</p><p id="9865" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">好了，现在我们的API已经有了一个很好的开始，让我们继续用Iris模型创建一个基本的推理端点。</p><h1 id="2728" class="me mf je bd mg mh mi mj mk ml mm mn mo kk mp kl mq kn mr ko ms kq mt kr mu mv bi translated">基本推理终点</h1><p id="fd77" class="pw-post-body-paragraph kt ku je kv b kw mw kf ky kz mx ki lb lc my le lf lg mz li lj lk na lm ln lo im bi translated">好了，我们现在准备开始围绕我们在前面部分中训练的Iris模型构建一个端点！首先，让我们首先导入我们需要的其他Python库，并加载模型本身:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="f9ac" class="nk mf je ng b gy nl nm l nn no">import pandas as pd<br/>import pickle</span><span id="d12e" class="nk mf je ng b gy np nm l nn no"># Loading in model from serialized .pkl file<br/>pkl_filename = "../model/iris_model.pkl"<br/>with open(pkl_filename, 'rb') as file:<br/> lr_model = pickle.load(file)</span></pre><p id="e5fb" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">好了，这里的<code class="fe nq nr ns ng b">lr_model</code>对象与我们之前针对Iris数据集训练的逻辑回归模型相同。就像我们处理任何其他Python脚本一样，我们将通过调用模型的<code class="fe nq nr ns ng b">.predict()</code>函数将数据传递给该模型进行推理。</p><p id="9e8c" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">对于Flask用户来说，这是我觉得有点奇怪的地方。我不想解释Flask是如何工作的，但它就是…与众不同。在Flask中，我习惯于直接从请求体获取JSON，这就是我们在这个基本端点中要做的。(剧透:有一个比这更好的选择，我们将在下一节演示，但如果您想尽可能地与Flask保持一致，这就是您要寻找的模式。</p><p id="a6ca" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这里是我们的<code class="fe nq nr ns ng b">/basic_predict</code>端点的完整代码:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="3b09" class="nk mf je ng b gy nl nm l nn no">from fastapi import Request</span><span id="87d4" class="nk mf je ng b gy np nm l nn no"># Defining the prediction endpoint without data validation<br/><a class="ae md" href="http://twitter.com/api" rel="noopener ugc nofollow" target="_blank">@api</a>.post('/basic_predict')<br/>async def basic_predict(request: Request):<br/> <br/> # Getting the JSON from the body of the request<br/> input_data = await request.json()<br/> <br/> # Converting JSON to Pandas DataFrame<br/> input_df = pd.DataFrame([input_data])<br/> <br/> # Getting the prediction from the Logistic Regression model<br/> pred = lr_model.predict(input_df)[0]<br/> <br/> return pred</span></pre><p id="b8d2" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">FastAPI是围绕Python新的异步特性构建的，因此我们在这里看到了<code class="fe nq nr ns ng b">async</code>和<code class="fe nq nr ns ng b">await</code>关键字。为了实际使用请求体中的JSON，我们必须首先从FastAPI导入<code class="fe nq nr ns ng b">Request</code>类对象，然后将它作为参数传递给这里的<code class="fe nq nr ns ng b">basic_predict</code>函数。(再说一次，这可能不是你在Flask中所习惯的。)幸运的是，从这里可以很快地从我们的虹膜模型中得到预测的推论。我们从请求体中取出JSON，将其转换成Pandas数据帧，将数据帧传递给逻辑回归模型以产生一个推断，最后将该推断返回给用户。</p><p id="9814" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">好吧！现在我们来试试这个。为了方便起见，我创建了一些shell脚本来快速测试我们的端点。它们可以在这个GitHub repo目录中找到<a class="ae md" href="https://github.com/dkhundley/ds-quick-tips/tree/master/012_dockerizing_fastapi/tests" rel="noopener ugc nofollow" target="_blank">。您可以简单地通过运行<code class="fe nq nr ns ng b">bash script_name.sh</code>来执行这些。例如，运行<code class="fe nq nr ns ng b">bash basic_predict.sh</code>脚本实际上是在做以下事情:</a></p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="eb4b" class="nk mf je ng b gy nl nm l nn no">curl --request POST \<br/>--header 'Content-Type: application/json' \<br/>--data <a class="ae md" href="http://twitter.com/test_json/test_data" rel="noopener ugc nofollow" target="_blank">@test_json/test_data</a>.json \<br/>--url <a class="ae md" href="http://0.0.0.0:5001/basic_predict" rel="noopener ugc nofollow" target="_blank">http://0.0.0.0:5001/basic_predict</a></span></pre><p id="4fcd" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">通过我们的模型运行这个脚本应该会返回一个“0.0”值。不错！现在让我们回过头来检查一下我们的Swagger UI，看看事情发生了怎样的变化。下面是您现在应该看到的:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/a1c1a57d2c5e182750f74908d29485a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O5PMjBzElyL52rhJe58yNg@2x.jpeg"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">作者截图</p></figure><p id="a187" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">除了我们原来的GET端点颜色为蓝色之外，我们现在看到我们的基本predict POST端点颜色为绿色。因为这是一个非常基本的端点，所以您会注意到这里没有多少文档。这是可以增强的，我们不仅要用我们的最终端点来增强它，还要添加最后一个非常酷的功能:数据验证。</p><h1 id="4ea5" class="me mf je bd mg mh mi mj mk ml mm mn mo kk mp kl mq kn mr ko ms kq mt kr mu mv bi translated">带数据验证的推理端点</h1><p id="adb6" class="pw-post-body-paragraph kt ku je kv b kw mw kf ky kz mx ki lb lc my le lf lg mz li lj lk na lm ln lo im bi translated">好了，虽然我们的基本预测端点如预期的那样工作，但我们现在将通过向传入请求添加数据验证来提高性能。数据验证确保我们的模型被正确地传递期望值。如果调用者传递了不正确的内容，则向用户返回一个响应，告诉他们由于数据验证错误，请求无法处理，并且还向用户具体描述了哪里出错了。</p><p id="1b7c" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">FastAPI通过与一个名为Pydantic的框架合作，在他们的<code class="fe nq nr ns ng b">BaseModel</code>类的基础上构建Python类来实现这一点。对于我们的Iris数据集，下面是我们将为验证构建的数据模型:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="e3be" class="nk mf je ng b gy nl nm l nn no">from pydantic import BaseModel </span><span id="04bc" class="nk mf je ng b gy np nm l nn no"># Creating the data model for data validation<br/>class Iris(BaseModel):<br/> sepal_length: float<br/> sepal_width: float<br/> petal_length: float<br/> petal_width: float</span></pre><p id="f4ac" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">(注意:默认的Iris数据集以不同的方式命名其特征，并包含空白。我一辈子也想不出如何用包含空格的特性名称创建这个Pydantic数据模型，所以我适当地更改了特性的名称。这也反映在我们的测试JSON文件中。)</p><p id="2f22" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我在这里描述的验证非常简单。使用这个<code class="fe nq nr ns ng b">Iris</code>数据模型的端点期待一个具有这四个特性的请求，并且所有这些特性都应该是<code class="fe nq nr ns ng b">float</code>数据类型。这是非常基本的，但是您可以通过数据验证进行深入研究。您甚至可以具体定义每个特性的期望值范围。例如，如果您定义了一个期望值范围在0到366之间的<code class="fe nq nr ns ng b">days</code>特性，那么当用户试图传递一个值为367的<code class="fe nq nr ns ng b">days</code>时，FastAPI将返回一个验证错误。</p><p id="e12e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">为了在端点中实际使用这个<code class="fe nq nr ns ng b">Iris</code>数据模型，下面是它的语法:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="9013" class="nk mf je ng b gy nl nm l nn no"># Defining the prediction endpoint with data validation<br/><a class="ae md" href="http://twitter.com/api" rel="noopener ugc nofollow" target="_blank">@api</a>.post('/predict')<br/>async def predict(iris: Iris):<br/> <br/> # Converting input data into Pandas DataFrame<br/> input_df = pd.DataFrame([iris.dict()])<br/> <br/> # Getting the prediction from the Logistic Regression model<br/> pred = lr_model.predict(input_df)[0]<br/> <br/> return pred</span></pre><p id="6055" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这与我们的<code class="fe nq nr ns ng b">/basic_predict</code>端点非常相似，但是现在，FastAPI将自动传递传入的请求，并在我们的模型处理它之前对它执行数据验证。</p><p id="5b69" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">让我们付诸实践吧！为了方便起见，我提供了两个测试JSON文件:一个包含正确的信息，另一个包含错误的信息。好的那个看起来是这样的:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="7470" class="nk mf je ng b gy nl nm l nn no">{"sepal_length":5.1,"sepal_width":3.5,"petal_length":1.4,"petal_width":0.2}</span></pre><p id="b3e3" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这是坏的那个的样子:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="9f72" class="nk mf je ng b gy nl nm l nn no">{"sepal_length":"dkhundley","sepal_width":3.5,"petal_length":1.4,"petal_width":0.2}</span></pre><p id="6411" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">正如你所看到的，我把<code class="fe nq nr ns ng b">sepal_length</code>改成了我名字的<code class="fe nq nr ns ng b">string</code>值，这应该无法通过我们设置的数据验证，因为我们期望的是<code class="fe nq nr ns ng b">float</code>值。通过用这些坏数据发出curl命令(可以用我的<code class="fe nq nr ns ng b">test_bad_predict.sh</code>脚本完成)，FastAPI告诉我们:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nz"><img src="../Images/2716d741d29a83b44ca31c33410dceae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j6lhRaVxgBBpJs9YSH7ISQ@2x.jpeg"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">作者截图</p></figure><p id="01b0" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我的截图被剪掉了一点，但是你可以看到FastAPI指出<code class="fe nq nr ns ng b">sepal_length</code>应该是一个浮点数。如果您正在调用API，而您自己不是开发人员，那么这非常清楚地描述了您出错的地方。不错！</p><p id="52b1" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">传入正确的数据(可以用我的<code class="fe nq nr ns ng b">test_predict.sh</code>脚本来完成)会产生我们期望的推断值。</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nz"><img src="../Images/2bfa3b40b7a31bcdfa7df2bd5a06724c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YxLLDxlFTlc8noNBNNA_Aw@2x.jpeg"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">作者截图</p></figure><p id="e64a" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">好吧，让我们最后看一眼我们的招摇文件来结束这篇文章。你现在应该看到一些新的东西了！首先，看一下“模式”部分:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oa"><img src="../Images/c977bf3656aae3f9ff374bb2d9dd3fa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MIK-WMiUQGXANTuNZC4Uog@2x.jpeg"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">作者截图</p></figure><p id="9ec3" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在这里，您可以看到我们的<code class="fe nq nr ns ng b">Iris</code>数据模型，包括所有预期的特性和预期的数据类型。现在，让我们来看看我们的<code class="fe nq nr ns ng b">/predict</code>端点文档:</p><figure class="nb nc nd ne gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ob"><img src="../Images/24890543a28fe8df7591a12e19d3be8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZrNvcwzsf0zk9G-141LbEA@2x.jpeg"/></div></div><p class="nu nv gj gh gi nw nx bd b be z dk translated">作者截图</p></figure><p id="f094" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">与我们的<code class="fe nq nr ns ng b">/basic_predict</code>端点相比，我们现在可以看到一些额外的东西。也就是说，我们现在看到了一个端点所期望的样本，此外，FastAPI提供了一个虚拟数据集，您可以从Swagger UI随时随地对其进行测试。非常好！</p><p id="e790" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">朋友们，今天的帖子到此结束！尽管我很喜欢Flask，但我个人将来会将FastAPI用于我所有的机器学习模型。我很清楚为什么数据科学社区很快采用FastAPI而不是Flask。这是一个非常简洁、功能丰富的工具！感谢你查看这篇文章。请继续关注机器学习和数据科学的最新进展。</p></div></div>    
</body>
</html>