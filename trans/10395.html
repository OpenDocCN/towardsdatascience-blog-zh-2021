<html>
<head>
<title>Stop using Spark for ML!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">停止用火花做ML！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/stop-using-spark-for-ml-59496927ef93?source=collection_archive---------8-----------------------#2021-10-04">https://towardsdatascience.com/stop-using-spark-for-ml-59496927ef93?source=collection_archive---------8-----------------------#2021-10-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8153" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">让你的机器学习管道尽可能简单的指导方针。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/49df94791e6bceabb3fc268000bd9f95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i8Oe27kxMD11jeNHkbDI2A.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">以赛亚·鲁斯塔德在Unsplash<a class="ae ky" href="https://unsplash.com/s/photos/stop-pretty?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">上的照片</a></p></figure><p id="263d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您有大量的数据需要处理，Spark是很好的选择。spark和Pyspark(用于与Spark交互的Python API)是数据工程师工具箱中的关键工具。有一个很好的理由:</p><blockquote class="lv"><p id="e08d" class="lw lx it bd ly lz ma mb mc md me lu dk translated"><em class="mf">“无论您的数据增长到多大，您仍然能够处理它。”</em></p></blockquote><p id="cef8" class="pw-post-body-paragraph kz la it lb b lc mg ju le lf mh jx lh li mi lk ll lm mj lo lp lq mk ls lt lu im bi translated">是一个常见的论点。尽管现代公司使用Spark端到端构建“经典”数据管道来组合、清理、转换和聚合他们的数据以输出数据集<em class="ml">是有效的。</em></p><h1 id="60d4" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">ML的火花成本</h1><p id="5128" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">对于构建数据管道的数据科学家和ML工程师来说，上述论点并不总是成立的，这些管道<em class="ml">输出机器学习模型</em>。对于机器学习管道来说，涉及到成本:</p><ul class=""><li id="020b" class="nj nk it lb b lc ld lf lg li nl lm nm lq nn lu no np nq nr bi translated">👭<strong class="lb iu">熟悉度— </strong>从我的经验数据来看，科学家对(Py)Spark的熟悉程度不如对熊猫。两者都使用数据帧的概念，但是用于操作数据帧中的数据的API是完全不同的。这里有一个熊猫对Pyspark的例子，我们创建了一个新的列:<br/> <code class="fe ns nt nu nv b">df['Age_times_Fare'] = df['Age'] * df['Fare']<br/>df = df.withColumn("AgeTimesFare", $"Age" * $"Fare")</code></li><li id="3144" class="nj nk it lb b lc nw lf nx li ny lm nz lq oa lu no np nq nr bi translated">🔧<strong class="lb iu">维护—</strong>Pandas、Scikit-learn、Pytorch、Tensorflow等Python包是数据科学家和ML工程师的主要工具。通过引入Spark，您在您需要维护的管道中引入了第二个额外的数据处理工具。</li><li id="3ebc" class="nj nk it lb b lc nw lf nx li ny lm nz lq oa lu no np nq nr bi translated">🏋🏽<strong class="lb iu">训练复杂性— </strong> Spark在Python进程之外的集群上运行，这增加了测试和运行定制代码的复杂性。对于<em class="ml">测试</em>，您必须在您的系统上配置一个Spark环境。当使用PySpark时，<em class="ml">第三方Python库</em>需要被运送到Spark执行器以避免“导入错误”。</li><li id="7e48" class="nj nk it lb b lc nw lf nx li ny lm nz lq oa lu no np nq nr bi translated">🔄<strong class="lb iu">推理复杂度</strong>—根据我的经验，Spark/SparkML很少用于建模，虽然我看到Spark用于特征工程。使用特征工程，您最好在推理时从训练时复制相同的步骤。为此，您可以在训练时将特征工程步骤打包为模型，并在推理时使用该模型。因为ML模型通常基于不同的技术(Scikit-learn、PyTorch、Tensorflow等)，所以您需要在推理时管理基于Spark的特征工程模型和ML模型之间的编排。这增加了运行模型的复杂性。</li></ul><blockquote class="lv"><p id="8d67" class="lw lx it bd ly lz ob oc od oe of lu dk translated">我不是说你应该把火花扔进垃圾桶。<strong class="ak"> </strong>在选择它的时候反而显得挑剔。</p></blockquote><h1 id="b078" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz og ka my kc oh kd na kf oi kg nc nd bi translated">简单性准则</h1><p id="b2ac" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">在编写一行Spark代码之前，下面的指南提出了一些替代方法和更简单的方法。</p><h2 id="a5b3" class="oj mn it bd mo ok ol dn ms om on dp mw li oo op my lm oq or na lq os ot nc ou bi translated">1.垂直缩放🐣</h2><p id="f3f2" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">尝试垂直扩展您的计算实例，以便您可以将所有数据保存在内存中。尝试使用Pandas处理您的数据，看看处理时间是否仍然合理。</p><h2 id="2d71" class="oj mn it bd mo ok ol dn ms om on dp mw li oo op my lm oq or na lq os ot nc ou bi translated">2.你需要所有的数据吗？📈</h2><p id="9bba" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">您是否需要所有数据来实现业务价值？多一年数据的附加值是什么？</p><p id="fd4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你的模型性能的收益是否超过涉及Spark的成本？在获取更多数据之前，请查看您的ML评估曲线。如果你已经有了好的结果，并且你没有过度拟合，也许你不需要更多的数据。</p><h2 id="1479" class="oj mn it bd mo ok ol dn ms om on dp mw li oo op my lm oq or na lq os ot nc ou bi translated">3.结构化查询语言📇</h2><p id="f1c7" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">在编写一行(Py)Spark代码之前，检查一下您是否无法通过使用SQL达到您的目标。一般来说，SQL更容易编写和维护。如果您已经有了一个Spark集群，请尝试SparkSQL。你也可以尝试通过一个无服务器的SQL引擎来公开你的数据，比如<a class="ae ky" href="https://cloud.google.com/bigquery" rel="noopener ugc nofollow" target="_blank">谷歌大查询</a>或者<a class="ae ky" href="https://aws.amazon.com/athena/" rel="noopener ugc nofollow" target="_blank"> AWS Athena。</a>您甚至可以通过<a class="ae ky" href="https://github.com/dbt-labs/dbt" rel="noopener ugc nofollow" target="_blank"> dbt </a>使用SQL进行更高级的转换，看看吧！</p><h2 id="26ea" class="oj mn it bd mo ok ol dn ms om on dp mw li oo op my lm oq or na lq os ot nc ou bi translated">4.云服务☁️</h2><p id="40b4" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">如果你需要建立一个Spark集群，首先检查一下<em class="ml">无服务器云服务</em>比如<a class="ae ky" href="https://aws.amazon.com/glue/" rel="noopener ugc nofollow" target="_blank"> AWS Glue </a>。它允许您在几秒钟内启动多达100个执行器的spark集群，其中每个执行器有4个CPU和16GB RAM。<br/>如果你需要一个更具可配置性的集群，并且你已经对你正在做的事情有所了解，你可以尝试一个<em class="ml">托管服务</em>，比如<a class="ae ky" href="https://aws.amazon.com/emr/" rel="noopener ugc nofollow" target="_blank"> AWS EMR </a>。</p><h1 id="500e" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">火花的替代品</h1><p id="6dbe" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">一些替代方案可以帮助您处理大量数据:</p><h2 id="7fcb" class="oj mn it bd mo ok ol dn ms om on dp mw li oo op my lm oq or na lq os ot nc ou bi translated">Vaex</h2><p id="73c5" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated"><a class="ae ky" href="https://github.com/vaexio/vaex" rel="noopener ugc nofollow" target="_blank"> Vaex </a>是一个Python数据处理库，API与Pandas类似。这是一个<em class="ml">核外</em>解决方案，每秒可以处理多达10亿行。数据集的大小限制等于硬盘的大小。⁴</p><h2 id="645b" class="oj mn it bd mo ok ol dn ms om on dp mw li oo op my lm oq or na lq os ot nc ou bi translated">达斯克</h2><p id="0c49" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated"><a class="ae ky" href="https://github.com/dask/dask" rel="noopener ugc nofollow" target="_blank"> Dask </a>在某种意义上类似于Spark，你可以水平扩展来处理大量数据。但这是不同的，因为Dask是用Python编写的，并且支持Pandas和Scikit这样的库——开箱即用。</p></div><div class="ab cl ov ow hx ox" role="separator"><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa"/></div><div class="im in io ip iq"><p id="5431" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你有任何建议，让我知道在回应！</p><h1 id="8e33" class="mm mn it bd mo mp mq mr ms mt mu mv mw jz mx ka my kc mz kd na kf nb kg nc nd bi translated">文森特·克拉斯</h1><p id="17d4" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">👋如果您想了解更多关于ML工程和ML管道的信息，请关注我的<a class="ae ky" href="https://medium.com/@vincentclaes_43752" rel="noopener"> Medium </a>、<a class="ae ky" href="https://www.linkedin.com/in/vincent-claes-0b346337/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>和<a class="ae ky" href="https://twitter.com/VincentClaes1" rel="noopener ugc nofollow" target="_blank"> Twitter </a>。</p><p id="9988" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">脚注</strong></p><p id="3d0e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[1]:<a class="ae ky" href="https://www.signifytechnology.com/blog/2019/04/pandas-vs-spark-how-to-handle-dataframes-part-ii-by-emma-grimaldi" rel="noopener ugc nofollow" target="_blank">https://www . signify technology . com/blog/2019/04/pandas-vs-spark-how-to-handle-data frames-part-ii-by-Emma-grima ldi</a><br/>【2】:在AWS上，您可以以大约8.5美元/小时的价格访问ml . r 5.24 xlage等具有96个CPU和768个GiB内存的实例。更多信息可在<a class="ae ky" href="https://aws.amazon.com/sagemaker/pricing/" rel="noopener ugc nofollow" target="_blank">此处</a>。<br/>【3】:<a class="ae ky" rel="noopener" target="_blank" href="/vaex-out-of-core-dataframes-for-python-and-fast-visualization-12c102db044a">https://towards data science . com/vaex-out-of-core-data frames-for-python-and-fast-visualization-12c 102 db 044 a</a><br/>【4】:<a class="ae ky" href="https://www.kdnuggets.com/2021/05/vaex-pandas-1000x-faster.html" rel="noopener ugc nofollow" target="_blank">https://www . kdnugges . com/2021/05/vaex-pandas-1000 x-faster . html</a></p></div></div>    
</body>
</html>