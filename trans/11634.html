<html>
<head>
<title>Predicting Hospitalized Time of Covid-19 Patients</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">新冠肺炎患者住院时间的预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-hospitalized-time-of-covid-19-patients-f4e70456db9b?source=collection_archive---------19-----------------------#2021-11-17">https://towardsdatascience.com/predicting-hospitalized-time-of-covid-19-patients-f4e70456db9b?source=collection_archive---------19-----------------------#2021-11-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5c67" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">医疗保健中的监督机器学习</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/4c4099484103a5c7f0c8c45f65dc058a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UgE3_kiU8ZFIKJCFL6CKSA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者照片</p></figure><p id="68b3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">2020 年新冠肺炎疫情的爆发导致美国医疗保健系统出现巨大的设备、材料短缺和床位短缺问题[1]。医院不仅需要照顾常规病人，还需要照顾突然增加的新冠肺炎病人。医院系统的良好规划和管理变得非常重要。</p><p id="909f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本文介绍了如何使用机器学习来预测新冠肺炎患者在入院时需要住院多长时间(以天为单位)的新方法。这可以帮助医院专业人员对患者治疗和资源(例如，房间、床位等)进行优化规划。)分配。这也可以减少医院访客的数量，从而减少工作人员和访客感染的机会。</p><p id="a3b7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本文其余部分安排如下:</p><ul class=""><li id="4664" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">数据理解</li><li id="2c5d" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">数据准备</li><li id="40c5" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">建模</li><li id="2c55" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">模型评估</li><li id="484a" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">部署考虑</li></ul><h1 id="abec" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated">1.数据理解</h1><p id="2c4e" class="pw-post-body-paragraph kv kw iq kx b ky mx jr la lb my ju ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">数据集从<a class="ae nc" href="https://www.kaggle.com/nehaprabhavalkar/av-healthcare-analytics-ii" rel="noopener ugc nofollow" target="_blank"> Kaggle 的网站</a>【1】获得。本文中使用了三个文件:</p><ul class=""><li id="08ec" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated"><em class="nd"> train_data.csv </em>:包含与患者、医院和住院时间相关的特征(标签)</li><li id="9b25" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><em class="nd"> test_data.csv </em>:包含与患者、医院相关的特征。需要预测每个病例 id 的“住院时间”</li><li id="b646" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><em class="nd">train _ data _ dictionary . CSV</em>:包含训练和测试文件中的特征信息。</li></ul><p id="499e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如图 1 所示，该数据集中有 318，438 个数据样本，总共 17 个特征和 1 个标签列(<em class="nd"> Stay </em>)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/2429d744f9ff6cfc5b247b745da4f9dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A-p8Ws7pUhJJd53bEaZDGQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd nf">图 1: </strong>训练数据集的转置视图。</p></figure><p id="db73" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">图 2a 显示了数据集中以下数字特征的统计摘要:</p><ul class=""><li id="e20b" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">案例 id</li><li id="5eaf" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">医院代码</li><li id="6371" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">城市代码医院</li><li id="8912" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">医院提供额外房间</li><li id="d10a" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">河床坡度</li><li id="74bd" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">patientid</li><li id="92ed" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">城市代码患者</li><li id="493b" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">有病人的来访者</li><li id="5bee" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">入场 _ 存款</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/0eb1089b9b35da2e7b064be471458379.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uP9eytaOkRIlVkAKKbHuhw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd nf">图 2a: </strong>数据集中数值特征的统计汇总。</p></figure><p id="f5b1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">上述数字特征分布的可视化如图 2b 所示。</p><p id="e83a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">可以看出，<em class="nd"> case_id </em>特征值均匀分布在仓上，因为它们是唯一的序列号。由于缺乏预测能力，此功能可能会被删除。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/9e083c5257e5c3cd619fc7bda385ae67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zBGI8Tdzs8VCYQEf59cclw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd nf">图 2b: </strong>数字特征分布。</p></figure><p id="880d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">图 3 显示了患者就诊分布。我们可以看到许多患者多次(从 10 次到 50 次)重访医院。所以病人身份在预测中很重要。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/a2321ec34a354bc21ca3a3aa2e37c731.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6iq94zR8nAsOb5xPuRKcAw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd nf">图 3: </strong>患者就诊分布。</p></figure><p id="42ee" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">图 4a 显示了分类特征和标签列的分布:</p><ul class=""><li id="b7e7" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">医院类型代码</li><li id="0121" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">医院区域代码</li><li id="f3a0" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">部门</li><li id="6b52" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">病房类型</li><li id="8d6e" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">病房设施代码</li><li id="808e" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">录取类型</li><li id="132f" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">疾病的严重程度</li><li id="b534" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">年龄</li><li id="0f2b" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">停留(标签)</li></ul><p id="3754" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以看到标签的分布明显向右倾斜。换句话说，数据是不平衡的。从“41–50”到“61–70”的数据样本非常少。这将对预测能力产生显著的负面影响。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/9a5f16c1d90dcddab5a52d8b9ba8d067.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MsnOlLfDCp1ETEX-qqMOPg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd nf">图 4a: </strong>分类特征分布。</p></figure><p id="a954" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">图 4b 显示了每个标签类中的数据样本数量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/785695a0b74deeda42fd7226505734f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:480/format:webp/1*UMN3-ofi31q6lx8WeMcdNw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd nf">图 4b: </strong>标签类计数。</p></figure><h1 id="b4c8" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated">2.数据准备</h1><p id="8204" class="pw-post-body-paragraph kv kw iq kx b ky mx jr la lb my ju ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">有了数据理解，下一步是探索、清理收集的原始数据集并将其转换为适当的格式，以便转换后的数据可以被目标机器学习模型有效地使用。</p><h2 id="6a85" class="nl mg iq bd mh nm nn dn ml no np dp mp le nq nr mr li ns nt mt lm nu nv mv nw bi translated">2.1.处理缺失数据</h2><p id="98fb" class="pw-post-body-paragraph kv kw iq kx b ky mx jr la lb my ju ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">如图 5 所示，<em class="nd">床级</em>特征列有 113 个缺失数据，<em class="nd">城市 _ 代码 _ 患者</em>特征列有 4532 个缺失数据。与 318，438 行的数据集相比，缺失数据的总数相对较少(总共 4，645 行)。在这种情况下，我们可以删除缺少数据的行，或者用 0 替换缺少的数据。我选择用 0 替换丢失的数据，以便能够预测部署中带有丢失特征值的<em class="nd"> test_data </em>数据集的结果。详见<code class="fe nx ny nz oa b">data_preprocessing.py</code>中的<code class="fe nx ny nz oa b">DataCleaning</code>类【6】。</p><pre class="kg kh ki kj gt ob oa oc od aw oe bi"><span id="7a08" class="nl mg iq oa b gy of og l oh oi">train_data.isnull().sum()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/0468bd75bc5fc8ba23008daf5b0a659d.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*i8A6UPqVWgCg9R0vr2iWvg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd nf">图 5: </strong>缺失数据计数。</p></figure><h2 id="234f" class="nl mg iq bd mh nm nn dn ml no np dp mp le nq nr mr li ns nt mt lm nu nv mv nw bi translated">2.2 删除没有预测能力的要素(列)</h2><p id="e965" class="pw-post-body-paragraph kv kw iq kx b ky mx jr la lb my ju ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">如前所述，<em class="nd"> case_id </em>特性不具备预测能力，因此在本项目中被丢弃(参见<code class="fe nx ny nz oa b">data_preprocessing.py</code> [6]中的<code class="fe nx ny nz oa b">DataCleaning</code>类)。</p><h2 id="c6de" class="nl mg iq bd mh nm nn dn ml no np dp mp le nq nr mr li ns nt mt lm nu nv mv nw bi translated">2.3 分类编码</h2><p id="d3be" class="pw-post-body-paragraph kv kw iq kx b ky mx jr la lb my ju ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated"><strong class="kx ir"> 2.3.1。分类标签编码</strong></p><p id="b3c8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">标签列<em class="nd">在这个数据集中停留</em>是分类的。必须转化为数字，用于分类特征目标编码[7]和深度学习模型。LabelEncoder 算法[8]用于转换(参见<code class="fe nx ny nz oa b">data_preprocessing.py</code> [6]中的<code class="fe nx ny nz oa b">TargetEncoding</code>和<code class="fe nx ny nz oa b">OneHotEncoding</code>类)。</p><p id="1a5f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> 2.3.2 分类特征目标编码</strong></p><p id="a220" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">目标编码[7]的优势在于它不会增加数据集的维度。它已经在这个项目中用于将分类特征转换为集成机器学习模型<code class="fe nx ny nz oa b">XGBoost</code>【2】和<code class="fe nx ny nz oa b">Random Forest</code>【3】的数字，因为这些模型由于高维度而不能很好地与一键编码一起工作。参见<code class="fe nx ny nz oa b">data_preprocessing.py</code>【6】中的<code class="fe nx ny nz oa b">TargetEncoding</code>类。</p><p id="bc18" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> 2.3.3。分类特征一键编码</strong></p><p id="cd64" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">作为比较，流行的 one-hot 编码方法用于转换分类特征，也用于深度学习模型(参见<code class="fe nx ny nz oa b">data_preprocessing.py</code> [6]中的<code class="fe nx ny nz oa b">OneHotEncoding</code>类)。</p><p id="60f6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> 2.3.4。其他分类特征转换</strong></p><p id="3c35" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我注意到分类年龄特征(例如“21–30”)一旦转换成数字就有了更强的预测能力，因为年龄的顺序有所不同。在这个项目中，每个年龄范围(例如，“21-30”)都被转换成一个平均数，比如(21+30)/2 = 25.5(参见<code class="fe nx ny nz oa b">data_preprocessing.py</code> [6]中的<code class="fe nx ny nz oa b">OneHotEncoding</code>类)。</p><h2 id="8cf6" class="nl mg iq bd mh nm nn dn ml no np dp mp le nq nr mr li ns nt mt lm nu nv mv nw bi translated">2.4.特征标准化</h2><p id="555f" class="pw-post-body-paragraph kv kw iq kx b ky mx jr la lb my ju ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">数字特征归一化到深度学习的<code class="fe nx ny nz oa b">[-1, 1]</code>范围内(见<code class="fe nx ny nz oa b">data_preprocessing.py</code>【6】中的<code class="fe nx ny nz oa b">FeatureNormorlization</code>类)。</p><h2 id="4d44" class="nl mg iq bd mh nm nn dn ml no np dp mp le nq nr mr li ns nt mt lm nu nv mv nw bi translated">2.5.数据分割</h2><p id="1e0d" class="pw-post-body-paragraph kv kw iq kx b ky mx jr la lb my ju ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">最后，预处理后的数据集被分成两个子集:一个用于模型训练，另一个用于模型评估。</p><h2 id="bac5" class="nl mg iq bd mh nm nn dn ml no np dp mp le nq nr mr li ns nt mt lm nu nv mv nw bi translated">2.6.数据预处理管道</h2><p id="f2cd" class="pw-post-body-paragraph kv kw iq kx b ky mx jr la lb my ju ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">为方便起见，数据准备步骤 2.1–2.5 已合并到数据预处理管道中:</p><ul class=""><li id="f521" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">目标 _ 编码 _ 预处理</li><li id="5f9f" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">预测的目标编码预处理</li><li id="ec5a" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">onehot _ encoding _ 预处理</li><li id="b596" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">one hot _ encoding _ preprocessing _ for _ prediction</li></ul><p id="732f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">详见<code class="fe nx ny nz oa b">data_preprocessing.py</code>【6】。</p><h1 id="1414" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated">3.建模</h1><p id="0c21" class="pw-post-body-paragraph kv kw iq kx b ky mx jr la lb my ju ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">数据准备好后，我们就可以开始建模了。建模的主要目标包括:</p><ul class=""><li id="5585" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">识别潜在的机器学习模型</li><li id="435d" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">训练模型并调整模型的超参数</li></ul><h2 id="75c9" class="nl mg iq bd mh nm nn dn ml no np dp mp le nq nr mr li ns nt mt lm nu nv mv nw bi translated">3.1.型号选择</h2><p id="4abd" class="pw-post-body-paragraph kv kw iq kx b ky mx jr la lb my ju ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">这个项目解决了一个分类问题，因为标签是分类的。这适用于<em class="nd">XGBoost</em>【2】、<em class="nd">随机森林</em>【3】、深度学习多层感知器(<a class="ae nc" href="https://en.wikipedia.org/wiki/Multilayer_perceptron" rel="noopener ugc nofollow" target="_blank"><em class="nd"/></a><em class="nd">)</em>分类器等有监督的机器学习分类模型【4】。</p><p id="0f44" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于数据是表格形式，特征数量相对较少，所以相比深度学习模型，一般首选<em class="nd"> XGBoost </em>和<em class="nd">随机森林</em>。</p><p id="9d10" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本项目选择<em class="nd"> XGBoost </em>、<em class="nd">随机森林、</em>、<em class="nd"> MLP </em>、分类器进行实验。</p><h2 id="f3e6" class="nl mg iq bd mh nm nn dn ml no np dp mp le nq nr mr li ns nt mt lm nu nv mv nw bi translated">3.2.模型训练和超参数调整</h2><p id="4b1a" class="pw-post-body-paragraph kv kw iq kx b ky mx jr la lb my ju ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated"><em class="nd"> XGBoost </em>和<em class="nd">随机森林</em>模型训练均采用 10 文件夹交叉验证。<em class="nd">网格搜索</em>用于选择超参数的最佳组合。交叉验证也用于训练深度学习模型。参见<code class="fe nx ny nz oa b">train_test_classifier.py</code>中的以下功能:</p><ul class=""><li id="3515" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated"><em class="nd"> build_xgboost_model </em></li><li id="aef6" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><em class="nd">构建 _ 射频 _ 模型</em></li><li id="34db" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><em class="nd">构建 _ 深度学习 _ 模型</em></li></ul><h1 id="3460" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated">4.模型评估</h1><p id="3a3b" class="pw-post-body-paragraph kv kw iq kx b ky mx jr la lb my ju ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">一旦训练了不同的机器学习模型，就需要评估这些模型的性能，以便我们可以选择最佳的模型进行部署。</p><p id="85bb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">分类准确度、F1 分数和混淆矩阵被用作该项目的主要评估指标。详见<code class="fe nx ny nz oa b">train_test_classifier.py</code>中的以下功能:</p><ul class=""><li id="4a5d" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated"><em class="nd"> evaluate_xgboost_model </em></li><li id="0aa4" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><em class="nd"> evaluate_rf_model </em></li><li id="5c0f" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><em class="nd"> evaluate_dl_model </em></li></ul><p id="ec57" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">通常，在具有不平衡数据的二进制分类的情况下，准确度不是一个好的度量，因为它可以通过简单地预测多数类来容易地实现高百分比的准确度。然而，在多类分类中这不是必须的。例如，在这个项目的数据集中，大多数类别 21-30 只有 87，491 个数据样本。数据样本的总数是 318，438。如果一个模型总是预测多数类，精度将是大约 27.5%。因此，在多类分类的情况下，精度仍然可以是良好的模型性能测量，因为它表示不同标签类的分类的平均精度。</p><p id="a8dd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">除了准确性之外，F1 分数还用于测量 XGBoost 和随机森林模型性能，因为它可以测量准确性和召回率的平衡，这适用于不平衡的数据。</p><p id="061c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用混淆矩阵是因为它可以清楚地告诉我们模型犯了什么预测错误。</p><h2 id="c321" class="nl mg iq bd mh nm nn dn ml no np dp mp le nq nr mr li ns nt mt lm nu nv mv nw bi translated">4.1.MLflow</h2><p id="6c2f" class="pw-post-body-paragraph kv kw iq kx b ky mx jr la lb my ju ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">为了有效地跟踪模型超参数和性能指标，使用了<em class="nd"> MLflow </em>工具【5】。特别是，我开发了<code class="fe nx ny nz oa b">train_test_classifier.py</code>中的<code class="fe nx ny nz oa b">mlFlow()</code>功能，将以下活动合并到一个过程中:</p><ul class=""><li id="321c" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">加载训练数据</li><li id="fcf4" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">预处理数据</li><li id="e41d" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">培训模式</li><li id="e769" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">评估模型</li></ul><p id="cbe1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">例如，下面的<em class="nd"> mlFlow </em>()函数调用为 XGBoost 模型产生结果(例如，图 6 中的混淆矩阵)。</p><pre class="kg kh ki kj gt ob oa oc od aw oe bi"><span id="7580" class="nl mg iq oa b gy of og l oh oi">target_encoders, label_encoder = mlFlow()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/6f7e1a8033b75653ec31fbb401194c32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hk8QDrAQ9YEiGhAurbxuUA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd nf">图 6: </strong> XGBoost 混淆矩阵。</p></figure><p id="05a5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">图 6 中的混淆矩阵表明，数据越多，预测结果越好。例如，真阳性的最大数量 14，429 在 21–30 的类别中。</p><p id="efb9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">图 7 显示了四个模型评估的结果:</p><ul class=""><li id="aa14" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated"><em class="nd"> XGBoost </em>带目标编码</li><li id="931a" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><em class="nd">随机森林</em>带目标编码</li><li id="ffb9" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><em class="nd"> MLP </em>用目标编码</li><li id="4a6a" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><em class="nd"> MLP </em>采用一键编码</li></ul><p id="5312" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以看到<em class="nd"> XGBoost </em>在给定数据集的准确性和 F1 分数方面都具有最佳性能，因此如果其性能满足业务需求，我们可以选择它进行部署。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/5413ecaf5d92f67472f115da6992008a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NNOxo8LEx5f2T7ZOGzD65Q.png"/></div></div></figure><p id="6c2b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如图 7 所示，最好的准确率分数只有 42.4%左右。这是因为在大多数标记的类别中数据太少，例如以下范围:<code class="fe nx ny nz oa b">41-50</code>，从<code class="fe nx ny nz oa b">61-70</code>一直到<code class="fe nx ny nz oa b">more than 100</code>。</p><p id="d8b0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果可以收集更多的数据来平衡数据集，准确性得分将会增加。作为实验，我只选择了类别为<code class="fe nx ny nz oa b">11-20</code>和<code class="fe nx ny nz oa b">21-30</code>的数据样本，并注意到准确率提高到了大约 63%。图 8 显示了来自经过训练的随机森林模型的相应混淆矩阵。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/2fff0ed74c5620c0c80ccb6568cf393b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3U0UFcZNWq8qiidq0isZXQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd nf">图 8: </strong>带有两个标签类别的随机森林模型的混淆矩阵。</p></figure><p id="e805" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了理解不同的特征如何影响预测，图 9 显示了由训练的随机森林模型产生的特征重要性。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/0dbbfd51830c57849d3a2513d6b3d72b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ETVc2L3eHf1zET_Zx725JA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd nf">图 9: </strong>随机森林模型产生的特征重要性。</p></figure><p id="fc96" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我还研究了特性和目标标签之间的相关性，如图 10 所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/6192cf5c43b045df7386ea9617c8fa46.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*iQ2EclQWYYUq2Cx9rCkbUQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd nf">图 10: </strong>特征和目标标签(Stay)相关系数。</p></figure><p id="38f0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用相关系数来确定特征和目标之间的关系的强度是棘手的，因为相关系数仅指示线性关系。具有非常低的相关系数的特征(例如<em class="nd"> patientid </em>)不一定表示该特征和目标之间没有关系。例如，<code class="fe nx ny nz oa b">patient id</code>具有非常小的相关系数，但是其特征重要性很高。</p><p id="c066" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我尝试删除一些功能重要性较低的功能(例如，医院 _ 地区 _ 代码、城市 _ 代码 _ 医院等)。)和具有非常小的相关系数的特征(例如，City_Code_Hospital ),并且观察到这无助于提高准确度分数。</p><h1 id="6aa7" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated">5.部署</h1><p id="3b08" class="pw-post-body-paragraph kv kw iq kx b ky mx jr la lb my ju ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">一旦在模型评估中确定了部署的最佳模型，我们就可以进入最后一步，将确定的模型部署到生产环境中。一种常见的部署方法是将模型作为 Web 服务部署在服务器上，目标生产系统中的其他组件可以调用它来预测结果。</p><p id="635b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了支持部署，在模型训练后，所选择的训练模型(如<em class="nd"> XGBoost </em>和相关的编码对象(如<em class="nd"> LabelEncoder </em>对象、<em class="nd"> TargetEncoder </em>对象)都被保存到 Python pickle 文件中。这些保存的编码对象和模型将被加载回来，以便在部署中进行预测。</p><p id="0432" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">例如，以下代码加载到<code class="fe nx ny nz oa b">test_data.csv</code>中，用于部署中的预测。图 11 显示了加载的测试数据集的转置视图。注意，这个数据集没有标签列<em class="nd"> Stay </em>。</p><pre class="kg kh ki kj gt ob oa oc od aw oe bi"><span id="35dd" class="nl mg iq oa b gy of og l oh oi">test_data = load_data('test_data.csv')<br/>print(test_data.shape)<br/>test_data.transpose().head(100)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/a4915b0ef8020c91a001fb873d81a6cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qtIZiR86tJcvbvPJvUSs3A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd nf">图 11: </strong>预测前的测试数据。</p></figure><p id="297a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面的代码执行以下操作:</p><ul class=""><li id="37ed" class="lr ls iq kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">加载保存的模型并编码对象</li><li id="28a2" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">使用它们来预测测试数据集中每个患者的住院天数</li><li id="1a67" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">显示结果数据帧中的前 100 条记录，带有特性和预测标签(<em class="nd">保持</em>列)(参见图 12)</li><li id="e678" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">显示预测标签的分布。</li></ul><p id="d453" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以从图 4 和图 13 中看到，图 13 中预测标签的分布模式与图 4 中标签的分布模式非常相似。</p><pre class="kg kh ki kj gt ob oa oc od aw oe bi"><span id="3512" class="nl mg iq oa b gy of og l oh oi">label_encoder, target_encoders = load_encoders()<br/>result_df = predict(label_encoder, target_encoders, test_data_file='test_data.csv')<br/>result_df['Stay'].value_counts().plot(kind='bar')<br/>result_df.transpose().head(100)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oq"><img src="../Images/c47f04c3a84eb255017f335b052d54c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mPI_IjMYPyI0jUb9fcKrYw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd nf">图 12: </strong>带预测标签的测试数据。</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/8f7917b850d810f68f35bac754973bcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*2DTLV9o71c2HDB1tkUDupQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd nf">图 13: </strong>预测标签分布。</p></figure><h1 id="fe48" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated">改进</h1><p id="7649" class="pw-post-body-paragraph kv kw iq kx b ky mx jr la lb my ju ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">如第 4.1 节所示，所选的最佳模型 XGBoost 仅实现了约 42.4%的准确性和 0.39 的 F1 分数。一个主要问题是数据严重失真，如图 4a 和 4b 所示。一个可能的改进是尽可能收集更多数据和/或使用<a class="ae nc" href="https://en.wikipedia.org/wiki/Data_augmentation" rel="noopener ugc nofollow" target="_blank">数据论证</a>技术生成更多数据样本以平衡数据集。</p><h1 id="2af3" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated">结论</h1><p id="6dea" class="pw-post-body-paragraph kv kw iq kx b ky mx jr la lb my ju ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">本文介绍了如何使用不同的机器学习模型来预测新冠肺炎患者的住院时间，使用的数据集来自 Kaggle [1]。这个数据集是困难的，因为它是一个多类单标签的情况，并且数据集是显著偏斜的。</p><p id="6181" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">实验结果表明，使用具有目标编码和特征工程(例如，年龄特征的转换)的<em class="nd"> XGBoost </em>在预测准确度(42.4%)和 F1 分数 0.39 方面实现了最佳性能。这一结果与 Kaggle [1]中描述的结果具有竞争性。</p><h1 id="3490" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated">参考</h1><ol class=""><li id="47db" class="lr ls iq kx b ky mx lb my le os li ot lm ou lq ov lx ly lz bi translated"><a class="ae nc" href="https://www.kaggle.com/nehaprabhavalkar/av-healthcare-analytics-ii" rel="noopener ugc nofollow" target="_blank">ka ggle 中的新冠肺炎数据集</a></li><li id="96d5" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq ov lx ly lz bi translated"><a class="ae nc" href="https://xgboost.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> XGBoost </a></li><li id="bf06" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq ov lx ly lz bi translated"><a class="ae nc" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">随机森林分类器</a></li><li id="9afc" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq ov lx ly lz bi translated"><a class="ae nc" href="https://keras.io/guides/sequential_model/" rel="noopener ugc nofollow" target="_blank"> Keras 顺序模型</a></li><li id="45a8" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq ov lx ly lz bi translated"><a class="ae nc" href="https://mlflow.org/docs/latest/index.html" rel="noopener ugc nofollow" target="_blank"> MLflow </a></li><li id="629f" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq ov lx ly lz bi translated"><a class="ae nc" href="https://github.com/yuhuang3/machine-learning/tree/master/Udacity/capstone_project" rel="noopener ugc nofollow" target="_blank">Github 中的源代码</a></li><li id="dc1c" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq ov lx ly lz bi translated"><a class="ae nc" href="https://contrib.scikit-learn.org/category_encoders/targetencoder.html" rel="noopener ugc nofollow" target="_blank">目标编码器</a></li><li id="deba" class="lr ls iq kx b ky ma lb mb le mc li md lm me lq ov lx ly lz bi translated"><a class="ae nc" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html" rel="noopener ugc nofollow" target="_blank">标签编码器</a></li></ol></div><div class="ab cl ow ox hu oy" role="separator"><span class="oz bw bk pa pb pc"/><span class="oz bw bk pa pb pc"/><span class="oz bw bk pa pb"/></div><div class="ij ik il im in"><p id="b6ef" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">鸣谢:我要感谢 Udacity reviewer 的指导性评论和 Kaggle 的数据集。</p></div></div>    
</body>
</html>