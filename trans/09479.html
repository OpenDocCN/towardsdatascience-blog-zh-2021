<html>
<head>
<title>AI Ethics in Engineering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">工程中的人工智能伦理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ai-ethics-in-engineering-65ab23af3f76?source=collection_archive---------31-----------------------#2021-09-02">https://towardsdatascience.com/ai-ethics-in-engineering-65ab23af3f76?source=collection_archive---------31-----------------------#2021-09-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3c47" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">传统工程师在基于人工智能的物理建模中的偏见——第一部分</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/4a26a602d1c986514e1e91371eb24912.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*33lCtt2EVJBvOjQLxAVc7w.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="74d4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">概要</strong></p><p id="6e9a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">摘要</p><p id="cead" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">导言</p><p id="d9e2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">数据:基于人工智能建模的基础</p><p id="f390" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">人工智能伦理解决了基于人工智能的建模中的偏见</p><h1 id="5aed" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">摘要</h1><p id="56ad" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">人工智能和机器学习算法开发的预测模型是基于“数据”的，这是众所周知的事实。由于已知数据如何用于构建基于人工智能的模型，人工智能伦理的主要特征是基于模型开发期间使用的数据的质量和数量来解决人工智能模型如何变得有偏差。</p><p id="713a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当谈到人工智能和机器学习的非工程应用时，已经证明，通过在机器学习算法的训练过程中包含有偏见的数据，人工智能模型中可以包含种族主义和性别歧视等人类偏见。由于人工智能和机器学习的工程应用用于建模物理现象，人工智能伦理学可以确定和澄清传统工程师的人类偏见，包括假设、解释、简化和先入为主的概念，如何用于人工智能和机器学习的工程应用。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mo"><img src="../Images/b855c95598b7093f6610da81ee27d980.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*koF6fTy1_OTSxG8aYZLnkA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者——<strong class="bd mp">W</strong>est<strong class="bd mp">V</strong>irginia<strong class="bd mp">U</strong>大学<strong class="bd mp"> L </strong>实验室为<strong class="bd mp"> E </strong>工程<strong class="bd mp"> A </strong>应用<strong class="bd mp">D</strong>A<strong class="bd mp">S</strong>科学</p></figure><h1 id="656c" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">介绍</h1><p id="6237" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">核武器最终没有毁灭我们的星球(至少到目前为止)的主要原因与如何处理核弹的全球条约和协议有关。重要的是，世界各地的政治家最终要就人工智能达成一套类似的全球性条约和协议。让许多人担心人工智能在未来几十年将如何影响我们的世界的主要原因之一与几个国家的政府有关。一些国家的政府正在根据他们自己的目标使用这项技术，这些目标是他们对民主的观点、信仰和理解的函数，以及他们成为世界领导者的意图，这些意图基于人工智能如何为他们服务。人工智能的伦理最近已经成为一个重要的话题，必须被已经或正在对人工智能和机器学习算法感兴趣的个人很好地理解。</p><p id="01ca" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">自2000年代中期，基于人工智能的图像识别、语音识别、面部识别、物体识别和自动驾驶汽车接触到世界上大多数人以来，人们对人工智能和机器学习的兴趣显著增加。作为新的科学技术，人工智能和机器学习将在21世纪改变很多事情。人工智能已经成为人们、公司和学术界经常涉足的最有趣的技术之一。</p><p id="40ed" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">例如，最近，银行已经开始使用人工智能和机器学习模型来做出关于向申请人提供贷款的决策的第一步，而大公司的人力资源则使用人工智能和机器学习模型来做出关于雇用谁的决定。从工程角度来看，一些运营中的石油公司对使用人工智能开发基于事实的油藏模拟模型很感兴趣。</p><p id="80bc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">银行使用人工智能模型来最大限度地减少他们必须详细评估其特征的申请人数量，而公司使用基于人工智能的模型来评估根据公司的招聘广告申请就业的大量申请人，然后大幅减少实际人力资源专业人员必须集中精力的申请人数量。石油公司使用基于人工智能的油藏模拟的目的是提高他们的石油和天然气产量。人工智能和机器学习被银行和公司用来贷款或雇用个人的方式，使得人工智能的伦理成为一个令人难以置信的重要话题。石油公司关于人工智能和机器学习的工程应用也是如此。</p><p id="aa6d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">人工智能的伦理对工程师和科学家来说很重要，他们已经热衷于使用这项技术来解决工程相关的问题。虽然在过去几年中，人工智能伦理已经成为人工智能和机器学习的非工程应用中的一个重要话题，但本文将阐述人工智能伦理在该技术的工程应用中的重要性。本文给出了人工智能和机器学习的工程应用中人工智能伦理的具体例子。虽然工程中的人工智能伦理可能与政治没有太大关系(至少在本文中)，但它在很大程度上受到以下因素的影响:(a)缺乏对人工智能的科学理解，(b)在通过人工智能的工程应用解决现实问题方面缺乏成功，或者将传统的工程偏见(包括假设、解释、简化和先入为主的概念)纳入基于人工智能的物理现象模型。</p><p id="eef5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">目前，一些声称他们使用这项技术的工程应用的个人和公司正在包括大量的人类偏见，以便他们在建立一个不包括人类偏见的基于人工智能的模型失败后，可以使用机器学习算法解决问题。工程中的人类偏见与如何建立数学方程来解决基于物理的问题有很大关系。</p><p id="faf1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">数据:人工智能建模的基础</strong></p><p id="6dcd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">人工智能使用机器学习算法来开发工具和模型，以实现其目标。基于AI的模型的发展与“数据”有很大关系。数据的质量和数量是基于人工智能的模型将如何表现的主要影响。正如上一节提到的，银行已经开始使用人工智能和机器学习模型来做出关于向申请人提供贷款的决策的第一步。人工智能模型通常使用贷款申请人提供的历史数据以及以前的贷款支付结果来开发。正贷款额和负贷款额，以及贷款申请人的输入数据，如性别、种族、信用、居住地点、收入等。将决定为银行贷款开发的基于人工智能的模型的质量。这种模型还可以包括由银行管理层确定的某些特征。</p><p id="b76c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">同样的一般方法也适用于大公司人力资源的人工智能模型，以决定雇用谁。这种模型也是利用来自多家公司的现有数据开发的，这些数据涉及申请人以及过去聘用的员工的素质。使人工智能伦理变得非常重要的人工智能的其他应用包括人脸识别、人脸检测、人脸聚类、人脸捕捉、人脸匹配等。这种技术被移动电话、安全、警察、机场等使用。</p><p id="0fa8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在人工智能的工程应用中，用于模型开发的数据的特征，包括其质量和数量，会影响基于人工智能的模型的质量。人工智能和机器学习的工程应用是使用实际测量和基于实际物理的数据来模拟物理，而不是使用数学方程来建立物理现象的模型。传统上，在过去的几个世纪中，在任何给定的时间模拟物理都与工程师和科学家对被模拟的物理现象的理解有关。随着科学家对物理现象理解的加深，用来模拟物理现象的数学方程的特征也在增强。</p><p id="0a32" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">人工智能伦理解决了基于人工智能建模中的偏见</strong></p><p id="171e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">用于构建基于人工智能的模型的数据的质量和数量的特征决定了基于人工智能的模型中是否包含任何偏差。人工智能伦理学的目标是确定用于建立基于人工智能的模型的数据的质量和数量，并通过用于建立模型的数据确定是否有任何偏见(有意或无意)被纳入模型。</p><p id="454a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">人工智能和机器学习被银行和公司用来贷款或雇用个人的方式，使得人工智能的伦理成为一个令人难以置信的重要话题。人工智能和机器学习的工程应用也是如此。只要结合了现实的和非传统的基于统计的机器学习算法，基于人工智能的模型的质量就完全取决于用于建立模型的数据的质量和数量。因此，用于开发基于人工智能的模型的数据完全控制了被开发并用于决策的模型的本质。</p><p id="2144" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">随着这项技术向前发展并开始解决更多问题，科学家们开始有兴趣了解更多关于人工智能和机器学习如何工作的细节。很明显，人工智能和机器学习的主要特征是使用数据来提出所需的解决方案并做出决策。由于数据是基于人工智能的模型开发的主要来源，因此了解(a)数据来自哪里以及它的主要来源是什么，以及(b)数据在多大程度上包括人工智能和机器学习可以从中提取模式、趋势和信息的所有所需信息(即使不是显式的)变得很重要。</p><p id="fe7b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">经过近十年的研究和学习，直到通过检查这项技术的实际应用变得非常清楚，人工智能和机器学习具有政治(Crawford 2019，Lim 2020)、种族主义(Doshi 2018，Dave 2021)和性别歧视(Dastin 2018，Dave 2021)的潜力。这与用于构建人工智能和机器学习模型的数据类型有关。换句话说，创建一个有偏见的AI和机器学习模型是很有可能的，它可以做你希望它做的事情。它完全与用于训练和构建模型的数据有关。这就是当传统工程师有意或无意地修改基于人工智能的模型的质量时，人工智能伦理如何解决人工智能的工程应用，以便它将生成他们认为是正确的东西，而不是基于现实、事实和实际测量来建模物理现象。</p><p id="4e8e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">麻省理工学院的人工智能伦理学发表了一些关于使用人工智能和机器学习时可能发生的偏见的文章。在其中的一些文章中，明确提到“三项新的研究提出了让算法更好地识别不同人口统计群体中的人的方法。但如果没有监管，这将不会遏制该技术被滥用的可能性，”(郝2019-1)，以及“这就是人工智能偏见真正发生的方式——以及为什么它如此难以修复。偏见可能会在深度学习过程的许多阶段出现，而计算机科学的标准实践并不是为了检测它而设计的。”(郝2019–2)。</p><p id="5ca5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在另一篇有趣的文章中，提到了“收集数据；偏见主要以两种方式出现在训练数据中:要么你收集的数据不代表现实，要么它反映了现有的偏见。例如，第一种情况可能会发生，如果深度学习算法被输入更多浅肤色人脸的照片，而不是深肤色人脸的照片。由此产生的人脸识别系统不可避免地会在识别深色皮肤的人脸方面表现不佳。第二个案例正是亚马逊发现其内部招聘工具正在解雇女性候选人时发生的情况。因为它接受了历史雇佣决策的训练，而历史雇佣决策更倾向于男性而非女性，所以它学会了做同样的事情。本文中提到的是研究结果，这些研究是为了了解如何将偏见纳入模型中。这对人工智能和机器学习的工程和非工程应用来说都是如此真实和非常重要。在本文中，我们将展示在人工智能的工程应用中类似的活动是如何发生的，我们将在下一节解释当人工智能被用来模拟物理现象时什么是偏差。</p><p id="ac3a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">通过对人工智能和机器学习算法的基础进行一些认真的研究，很明显这项技术在发现用于训练和开发模型、进行预测和帮助决策的数据模式方面有着令人难以置信的强大能力。由于人工智能和机器学习算法所做的一切都与数据有关，因此很明显，只要提供给人工智能和机器学习算法的数据是基于偏见、解释和假设生成的，那么这项技术开发的模型和工作流就成为这种偏见、解释和假设的代表。</p><p id="0a8c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">pare 2:-&gt;<a class="ae mq" href="https://shahab-mohaghegh.medium.com/ai-ethics-in-engineering-437ec07046a6?postPublishedType=initial" rel="noopener">https://shahab-mohaghegh . medium . com/ai-ethics-in-engineering-437 EC 07046 a6？postPublishedType=initial </a></p></div></div>    
</body>
</html>