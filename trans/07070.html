<html>
<head>
<title>k-Nearest Neighbors (kNN) — How To Make Quality Predictions With Supervised Learning?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k-最近邻(kNN)-如何使用监督学习进行质量预测？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/k-nearest-neighbors-knn-how-to-make-quality-predictions-with-supervised-learning-d5d2f326c3c2?source=collection_archive---------6-----------------------#2021-06-27">https://towardsdatascience.com/k-nearest-neighbors-knn-how-to-make-quality-predictions-with-supervised-learning-d5d2f326c3c2?source=collection_archive---------6-----------------------#2021-06-27</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><h2 id="643f" class="is it iu bd b dl iv iw ix iy iz ja dk jb translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><div class=""><h2 id="a43d" class="pw-subtitle-paragraph ka jd iu bd b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr dk translated">使用kNN解决回归和分类问题的综合指南</h2></div><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ks"><img src="../Images/2a902a6eee3fdfb947346463bbeb37d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FA_w9fcXccK69R7ozk8Vzw.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">k近邻(kNN)机器学习算法。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><h1 id="23e4" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated"><strong class="ak">简介</strong></h1><p id="0c3f" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">本文是深入研究不同机器学习算法的系列文章的继续。如果您对数据科学感兴趣，并且希望更好地理解kNN算法，或者如果您需要用Python构建自己的ML模型的指南，请继续阅读。</p><h1 id="3422" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated"><strong class="ak">内容</strong></h1><ul class=""><li id="ab08" class="mx my iu md b me mf mh mi mk mz mo na ms nb mw nc nd ne nf bi translated">kNN所属的算法类别</li><li id="4316" class="mx my iu md b me ng mh nh mk ni mo nj ms nk mw nc nd ne nf bi translated">kNN工作原理的直观解释</li><li id="bc30" class="mx my iu md b me ng mh nh mk ni mo nj ms nk mw nc nd ne nf bi translated">一个完整的Python示例，展示了kNN在真实数据中的使用</li></ul><h1 id="c4b8" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated"><strong class="ak">kNN属于哪一类算法？</strong></h1><p id="4e69" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">有这么多的机器学习算法，可能永远不可能将它们全部收集和分类。然而，我已经尝试对一些最常用的进行了测试，你可以在下面的<strong class="md je">交互式</strong>旭日图中找到。确保点击👇在不同的类别上对<strong class="md je">进行放大并揭示更多的</strong>。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="nl nm l"/></div><p class="le lf gk gi gj lg lh bd b be z dk translated">机器学习算法分类。由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>创建的互动图表。</p></figure><p id="1363" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated"><strong class="md je"> <em class="ns">如果你喜欢数据科学和机器学习</em> </strong> <em class="ns">，请</em> <a class="ae li" href="https://solclover.com/subscribe" rel="noopener ugc nofollow" target="_blank"> <em class="ns">订阅</em> </a> <em class="ns">每当我发布一个新故事时，你都会收到一封电子邮件。</em></p><p id="13d8" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">从上图可以看出，k-Nearest Neighbors属于机器学习算法的<strong class="md je">监督</strong>分支，这意味着它需要有标签的数据进行训练。</p><p id="c951" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">但是，假设你只想找到相似的数据点(即找到邻居)，而不是进行预测。那样的话，就有可能以无监督的方式使用kNN<em class="ns">(参见sklearn的</em><a class="ae li" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors" rel="noopener ugc nofollow" target="_blank"><em class="ns">nearest neighbors</em></a><em class="ns">实现这种无监督的学习器)</em>。</p><p id="3a5c" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">值得注意的是，kNN是一种非常灵活的算法，可以用来解决不同类型的问题。因此，在本文中，我将带您了解它在<strong class="md je">分类</strong>和<strong class="md je">回归</strong>中的用法。</p><h1 id="1d8f" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated"><strong class="ak">kNN是如何工作的？</strong></h1><p id="03a6" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">让我们从kNN中的“k”开始。由于算法是基于最近的邻居进行预测的，所以我们需要告诉算法我们想要考虑的邻居的确切数量。因此，“k”代表邻居的数量，只是一个我们可以调整的超参数。</p><p id="babd" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">现在让我们假设我们选择了k=5，并且我们有一个包含房屋大小(平方英尺)、房屋建造年份和房价的数据集。我们希望在这些数据上训练kNN，然后用它来预测我们感兴趣的另一所房子的价格。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj nt"><img src="../Images/fbc155ed370f8268292f1c5bc9753322.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NIhra6i-ag7J56p5KYc11A.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">运行中的kNN算法。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="3eca" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">在上图中，黑色圆圈代表一个新的数据点(我们感兴趣的房子)。因为我们已经设置k=5，所以该算法找到这个新点的五个最近的邻居。</p><blockquote class="nu nv nw"><p id="1afc" class="mb mc ns md b me nn ke mg mh no kh mj nx np mm mn ny nq mq mr nz nr mu mv mw in bi translated">注意，通常使用欧几里德距离，但是一些实现允许替代的距离度量(例如，曼哈顿)。</p></blockquote><p id="f8db" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">找到邻域后，根据您是执行分类分析还是回归分析，将会发生以下两种情况之一。</p><ul class=""><li id="a30b" class="mx my iu md b me nn mh no mk oa mo ob ms oc mw nc nd ne nf bi translated"><strong class="md je">分类:</strong>该算法使用简单多数投票将标签分配给新的数据点。在我们的例子中，大多数由3个价格为100万美元的邻居组成。因此，新数据点的预测标签是&lt; $1M。</li><li id="99b2" class="mx my iu md b me ng mh nh mk ni mo nj ms nk mw nc nd ne nf bi translated"><strong class="md je">回归:</strong>算法计算所有邻居的平均值。在我们的示例中，这将是:($90万+ $95万+ $98万+$ 100万+$ 110万)/5 = $ 98.6万。所以，房子的预测价格(新数据点)是986K美元。</li></ul><p id="e7b7" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">从这个例子中可以看出，kNN是一个非常直观的算法，很容易解释预测是如何进行的。因此，它与RandomForest或XGBoost等其他分类和回归算法形成对比。</p><p id="51eb" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">最后要补充的是，上面的解释说明了使用统一砝码时会发生什么。即，每个邻居在计算中携带相同的权重。但是，在某些情况下(例如，当您有稀疏数据时)，使用基于距离的权重可能是有益的。</p><p id="3dec" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">距离权重分配的权重与距查询点的距离成反比，这意味着距离数据点较近的相邻要素比距离较远的相邻要素具有更大的权重。</p><div class="kt ku kv kw gu ab cb"><figure class="od kx oe of og oh oi paragraph-image"><a href="https://solclover.com/membership"><img src="../Images/63320331b74bd98eea6402472b4209ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*qkXay39OnVc2IosW6rkxtw.png"/></a></figure><figure class="od kx oe of og oh oi paragraph-image"><a href="https://www.linkedin.com/in/saulius-dobilas/"><img src="../Images/60fb21d1cb2701bfb6b71f61c99403e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*vabxOXtQ4T034N_mscHSmQ.png"/></a></figure></div><h1 id="f166" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">kNN在现实生活数据中使用的Python示例</h1><p id="16a0" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">现在让我们看一个Python例子，这样您就可以看到如何在实践中使用kNN。</p><h2 id="6b3b" class="oj lk iu bd ll ok ol dn lp om on dp lt mk oo op lv mo oq or lx ms os ot lz ja bi translated">设置</h2><p id="0fb1" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">我们将使用以下数据和库:</p><ul class=""><li id="ba81" class="mx my iu md b me nn mh no mk oa mo ob ms oc mw nc nd ne nf bi translated"><a class="ae li" href="https://www.kaggle.com/quantbruce/real-estate-price-prediction?select=Real+estate.csv" rel="noopener ugc nofollow" target="_blank">Kaggle的房价数据</a></li><li id="2463" class="mx my iu md b me ng mh nh mk ni mo nj ms nk mw nc nd ne nf bi translated"><a class="ae li" href="https://scikit-learn.org/stable/index.html" rel="noopener ugc nofollow" target="_blank">Scikit-learn library</a>for<br/>1)特征缩放(<a class="ae li" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler" rel="noopener ugc nofollow" target="_blank">minmax scaler</a>)；<br/> 2)分类变量的编码(<a class="ae li" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html" rel="noopener ugc nofollow" target="_blank">OrdinalEncoder</a>)；<br/> 3)执行kNN分类(<a class="ae li" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.kneighbors" rel="noopener ugc nofollow" target="_blank">KNeighborsClassifier</a>)；<br/> 4)进行kNN回归(<a class="ae li" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor" rel="noopener ugc nofollow" target="_blank">KNeighborsRegressor</a>)；<br/> 5)模型评估(<a class="ae li" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html" rel="noopener ugc nofollow" target="_blank">分类_报告</a>)</li><li id="7672" class="mx my iu md b me ng mh nh mk ni mo nj ms nk mw nc nd ne nf bi translated">用于数据可视化的<a class="ae li" href="https://plotly.com/python/" rel="noopener ugc nofollow" target="_blank"> Plotly </a>和<a class="ae li" href="https://matplotlib.org/" rel="noopener ugc nofollow" target="_blank"> Matplotlib </a></li><li id="f206" class="mx my iu md b me ng mh nh mk ni mo nj ms nk mw nc nd ne nf bi translated"><a class="ae li" href="https://pandas.pydata.org/docs/" rel="noopener ugc nofollow" target="_blank">熊猫</a>和<a class="ae li" href="https://numpy.org/doc/stable/" rel="noopener ugc nofollow" target="_blank"> NumPy </a>进行数据操作</li></ul><p id="e8b3" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">让我们导入所有的库:</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="ou nm l"/></div></figure><p id="8d3b" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">接下来，我们下载并接收将在kNN模型中使用的数据。<br/> <em class="ns">(来源:</em><a class="ae li" href="https://www.kaggle.com/quantbruce/real-estate-price-prediction?select=Real+estate.csv" rel="noopener ugc nofollow" target="_blank"><em class="ns">https://www . ka ggle . com/quant Bruce/real-estate-price-prediction？select = Real+estate . CSV</em></a><em class="ns">)</em></p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="ou nm l"/></div></figure><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ov"><img src="../Images/972d5746e6eaeadffd4d8a55e1443b0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hy7IpfIGnWgFRyDB_0Hxrg.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated"><a class="ae li" href="https://www.kaggle.com/quantbruce/real-estate-price-prediction?select=Real+estate.csv" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>的房价数据。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="7f74" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">我们将在模型中使用以下数据字段:</p><ul class=""><li id="bea9" class="mx my iu md b me nn mh no mk oa mo ob ms oc mw nc nd ne nf bi translated"><strong class="md je">特征(自变量):</strong>‘X5纬度’，‘X6经度’，‘X2宅龄’</li><li id="7625" class="mx my iu md b me ng mh nh mk ni mo nj ms nk mw nc nd ne nf bi translated"><strong class="md je">目标(因变量):</strong> 'Y单位面积房价'<em class="ns">注意，我们将使用原始字段进行回归，并创建一个带状版本用于分类。</em></li></ul><p id="59f7" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">我们的目标是预测给定坐标和年龄的房屋的单位面积价格。但是，首先，让我们创建一个新的变量作为分类模型的目标。下面是‘Y单位面积房价’的分布:</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="ou nm l"/></div></figure><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ow"><img src="../Images/7b1165de601d658d84a5819364dc65c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8BvQ3KQ8txnru7L_OyVNMw.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">显示“单位面积Y房价”字段分布的直方图。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="9228" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">我们可以任意选择对我们有意义的波段，例如0–20、20–40、40–60、60–80和80+。但是，这将创建包含不同数量观测值的波段。例如，我们在(40–60)范围内有171个观察值，而在(60–80)范围内只有18个观察值。</p><p id="a6c7" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">由于kNN分类依赖于多数投票，拥有不平衡的数据将使算法很难选择除多数类之外的任何其他类。由于这个原因，我们将创建三个<strong class="md je">平衡</strong>波段，而不是将观察值分组为单位面积价格最低的33%、中间的33%和最高的33%。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="ou nm l"/></div></figure><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ox"><img src="../Images/fa1e905f5f197d072dafed2332d1dd01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pGIxgyb7_-t0pzEkh659oQ.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">带有新的“价格范围”字段的房价数据将用于分类。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="ed6d" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">最后，在开始训练模型之前，让我们在3D图上绘制观察结果以可视化数据。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="ou nm l"/></div></figure><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="nl nm l"/></div><p class="le lf gk gi gj lg lh bd b be z dk translated">房屋数据的交互式3D散点图。图表作者<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>。</p></figure><p id="5441" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">像这样的可视化效果非常好，因为它们让我们可以立即看到数据中的模式。</p><p id="3e4a" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">绿点(价格区间底部33%的房屋)分布在更广的区域(经度-纬度方向)，表明它们离中心位置更远，导致价格更低。</p><p id="6493" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">同时，蓝色(中间33%)和红色(顶部33%)点可以在同一位置找到，但在年龄上有显著差异。蓝色往往更老(因此更便宜)，而红色往往更新(更贵)。</p><h2 id="e818" class="oj lk iu bd ll ok ol dn lp om on dp lt mk oo op lv mo oq or lx ms os ot lz ja bi translated">kNN分类和回归</h2><p id="b43a" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">下面我提供了一大块代码，它完成了从特征缩放到模型训练和结果生成的所有工作。让我详细说明一下每一步:</p><p id="4e17" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated"><strong class="md je">步骤1——特征缩放</strong>。因为kNN依赖于计算点之间的距离，所以确保我们的特征使用一致的比例是很重要的。否则，规模较小的将占主导地位，规模较大的将几乎没有影响。这里我们使用<strong class="md je"> MinMaxScaler() </strong>，它保持底层分布不变，但将比例范围更改为0到1。</p><p id="4492" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">此外，我们的分类模型的目标值为['底部33 '，'中间33 '，和'顶部33']。由于sklearn的实现要求目标标签为数字，因此我们使用<strong class="md je"> OrdinalEncoder() </strong>将其转换为[0，1，2]。</p><p id="13ca" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated"><strong class="md je">步骤2——训练/测试样本</strong>。我们现在需要将数据分成训练和测试样本，这是在<strong class="md je"> train_test_split </strong>函数的帮助下完成的。</p><p id="678a" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">我们还准备了两个独立的目标阵列。“yC”包含基于编码价格带的分类模型的目标，而“yR”包含基于原始房屋单位面积价格的回归模型的目标。</p><p id="08af" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated"><strong class="md je">第三步——模型设置</strong>。在这里，我们建立模型并调整超参数。请注意，我们有两个独立的模型，一个用于分类，另一个用于回归。</p><p id="dd53" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">正如我们之前所了解到的，它们本质上是相同的，只是在基于之前确定的最近邻计算预测时，在最后部分有所不同。在这种情况下，我们选择<strong class="md je"> n_neighbors ("k") </strong>等于5，并将权重设置为“统一”，给每个邻居一个相等的权重。</p><p id="4e77" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated"><strong class="md je">步骤4——培训</strong>。我们使用训练数据和它们独特的训练目标阵列来训练这两个模型。</p><p id="f83d" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated"><strong class="md je">步骤5—预测</strong>。模型训练完成后，我们使用它们来预测训练和测试数据的分类标签和回归值。</p><p id="715a" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated"><strong class="md je">第六步</strong> <strong class="md je"> —绩效总结</strong>。我们生成并打印性能指标来评估我们的模型。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="ou nm l"/></div></figure><p id="ceb8" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">以上代码打印了以下模型结果:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj oy"><img src="../Images/592b39ee4d50ebba7af8051b93b87b6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nEM0pFVV6MG3pzHvzXNRIA.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">具有统一权重的kNN模型结果。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="311d" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">如您所见，分类模型的性能相当好，测试和训练数据的准确率分别为0.84和0.82。同时，回归模型在两个数据集上都产生了0.75的准确度分数(R)。</p><p id="2bb1" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">现在，让我们看看当我们将权重从“统一”改为“距离”时会发生什么，即，给予更近的邻居更高的权重。</p><blockquote class="nu nv nw"><p id="1d4c" class="mb mc ns md b me nn ke mg mh no kh mj nx np mm mn ny nq mq mr nz nr mu mv mw in bi translated">注意，我们使用完全相同的Python代码，除了在两个模型中将weights='uniform '改为<strong class="md je"> weights='distance' </strong>。</p></blockquote><p id="6d53" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">结果如下:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj oz"><img src="../Images/52c4fef682776e1b1c4d389be1ac0e5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5c_l7hRUzQb3HGAMtBLjHw.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">具有距离调整权重的kNN模型结果。图片来自<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>。</p></figure><p id="ea5a" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">我们可以在分类(0.98)和回归(0.99)的<strong class="md je">训练</strong>数据上看到模型性能的显著提高。然而，使用基于距离的加权对模型的泛化能力产生了负面影响，在<strong class="md je">测试</strong>数据上，分类性能下降到0.81，回归性能下降到0.73。</p><h2 id="01bd" class="oj lk iu bd ll ok ol dn lp om on dp lt mk oo op lv mo oq or lx ms os ot lz ja bi translated">奖金代码</h2><p id="7218" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">有时，我们还想知道训练集中的哪些数据点是我们通过测试集传入的数据点的邻居。您可以使用<strong class="md je"> kneighbors() </strong>方法找出答案，该方法返回到每个“k”邻居的距离和索引。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pa"><img src="../Images/13e7b0f7eae05d2029614ee49b235b9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AiqfGbSs2EoO0Qw7RSXYGw.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">测试记录的邻居指数(k=5)。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="70ff" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">然而，需要注意的是，<strong class="md je"> kneighbors() </strong>方法返回的索引引用了训练数据集中观察值的<strong class="md je">索引号。因此，如果您想找到测试数据中第一个观察值的邻居，您需要在<strong class="md je">训练数据集</strong>中查找索引为330、122、40、44和140的记录。不要将该索引与原始数据框中的索引混淆。</strong></p><p id="5490" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">作为存储模型预测和邻居索引的一种方式，我编写了以下代码，将训练和测试数据合并到一个数据框中，同时保留training_index编号，以便您可以快速识别每个测试记录的邻居。它还保留预测标签和预测值。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="ou nm l"/></div></figure><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pb"><img src="../Images/2965168df272b5798e3c2119e5b52a6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ItfjoboxFy6rI5NhfMzTzA.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">包含模型预测和邻域索引的最终数据框。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="7e6e" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">此外，我们现在可以使用上述数据框在3D图上绘制我们的模型预测，并直观地将其与原始数据进行比较。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="ou nm l"/></div></figure><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="nl nm l"/></div><p class="le lf gk gi gj lg lh bd b be z dk translated">带有模型预测的交互式3D散点图。图表作者<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>。</p></figure><p id="eb58" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">3D图直观地证实了我们在模型评估总结中看到的良好结果。</p><h1 id="109c" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">结论</h1><p id="99ac" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">当谈到机器学习时，可解释性通常与模型的预测能力一样重要。因此，如果你正在寻找一个易于解释的算法，你可以向你的利益相关者解释，那么kNN可能是一个不错的选择。</p><p id="dafa" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">但是，不要忘记缩放您的要素并尝试不同的超参数组合，因为k=5和weight =“uniform”的默认值可能不适合您的数据。</p><p id="9c1f" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">我希望这篇文章对您有所帮助，并成为您在自己的数据科学之旅中使用的宝贵资源。请不要犹豫，分享你的想法，意见和问题。你的反馈对帮助我写出更好的故事至关重要。</p><p id="6d0d" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated">干杯！👏<br/> <strong class="md je">索尔·多比拉斯</strong></p></div><div class="ab cl pc pd hy pe" role="separator"><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph"/></div><div class="in io ip iq ir"><p id="5cd4" class="pw-post-body-paragraph mb mc iu md b me nn ke mg mh no kh mj mk np mm mn mo nq mq mr ms nr mu mv mw in bi translated"><strong class="md je"> <em class="ns">如果你已经花光了这个月的学习预算，下次请记得我。</em> </strong> <em class="ns">我的个性化链接加入媒介是:</em></p><div class="pj pk gq gs pl pm"><a href="https://solclover.com/membership" rel="noopener  ugc nofollow" target="_blank"><div class="pn ab fp"><div class="po ab pp cl cj pq"><h2 class="bd je gz z fq pr fs ft ps fv fx jd bi translated">通过我的推荐链接加入Medium索尔·多比拉斯</h2><div class="pt l"><h3 class="bd b gz z fq pr fs ft ps fv fx dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pu l"><p class="bd b dl z fq pr fs ft ps fv fx dk translated">solclover.com</p></div></div><div class="pv l"><div class="pw l px py pz pv qa lc pm"/></div></div></a></div></div><div class="ab cl pc pd hy pe" role="separator"><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph pi"/><span class="pf bw bk pg ph"/></div><div class="in io ip iq ir"><div class="kt ku kv kw gu pm"><a rel="noopener follow" target="_blank" href="/cart-classification-and-regression-trees-for-clean-but-powerful-models-cc89e60b7a85"><div class="pn ab fp"><div class="po ab pp cl cj pq"><h2 class="bd je gz z fq pr fs ft ps fv fx jd bi translated">CART:清晰而强大的模型的分类和回归树</h2><div class="pt l"><h3 class="bd b gz z fq pr fs ft ps fv fx dk translated">CART算法是如何工作的，如何在Python中成功使用？</h3></div><div class="pu l"><p class="bd b dl z fq pr fs ft ps fv fx dk translated">towardsdatascience.com</p></div></div><div class="pv l"><div class="qb l px py pz pv qa lc pm"/></div></div></a></div><div class="pj pk gq gs pl pm"><a rel="noopener follow" target="_blank" href="/k-means-clustering-a-comprehensive-guide-to-its-successful-use-in-python-c3893957667d"><div class="pn ab fp"><div class="po ab pp cl cj pq"><h2 class="bd je gz z fq pr fs ft ps fv fx jd bi translated">K-Means聚类——在Python中成功使用的综合指南</h2><div class="pt l"><h3 class="bd b gz z fq pr fs ft ps fv fx dk translated">用真实数据的Python演示解释K-Means算法</h3></div><div class="pu l"><p class="bd b dl z fq pr fs ft ps fv fx dk translated">towardsdatascience.com</p></div></div><div class="pv l"><div class="qc l px py pz pv qa lc pm"/></div></div></a></div><div class="pj pk gq gs pl pm"><a rel="noopener follow" target="_blank" href="/random-forest-models-why-are-they-better-than-single-decision-trees-70494c29ccd1"><div class="pn ab fp"><div class="po ab pp cl cj pq"><h2 class="bd je gz z fq pr fs ft ps fv fx jd bi translated">随机森林模型:为什么它们比单一决策树更好？</h2><div class="pt l"><h3 class="bd b gz z fq pr fs ft ps fv fx dk translated">详细解释了随机森林机器学习算法如何工作，是什么使它优于决策树…</h3></div><div class="pu l"><p class="bd b dl z fq pr fs ft ps fv fx dk translated">towardsdatascience.com</p></div></div><div class="pv l"><div class="qd l px py pz pv qa lc pm"/></div></div></a></div></div></div>    
</body>
</html>