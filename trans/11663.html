<html>
<head>
<title>Spin up your models in GCP AI-platform with MLflow Deployment plugin</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 MLflow 部署插件在 GCP 人工智能平台上旋转您的模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/spin-up-your-models-in-gcp-ai-platform-with-mlflow-deployment-plugin-c0198077dca1?source=collection_archive---------20-----------------------#2021-11-18">https://towardsdatascience.com/spin-up-your-models-in-gcp-ai-platform-with-mlflow-deployment-plugin-c0198077dca1?source=collection_archive---------20-----------------------#2021-11-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="2436" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">MLflow 插件允许集成到任何定制平台。这是一个从实验跟踪到模型生产的绝佳机会。今天让我们看看如何在 MLflow 中实现一个部署插件</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/3b0a7ef299d15fea9f1fa1746cffc00b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AYEZ3uD1vsJFzvTp3Loiqg.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">Vishnu Mohanan 在<a class="ae le" href="https://unsplash.com/photos/_hAZlayJFoA" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的图片</p></figure><div class="lf lg gp gr lh li"><a href="https://medium.com/@stefanobosisio1/membership" rel="noopener follow" target="_blank"><div class="lj ab fo"><div class="lk ab ll cl cj lm"><h2 class="bd iu gy z fp ln fr fs lo fu fw is bi translated">通过我的推荐链接加入 Medium-Stefano Bosisio</h2><div class="lp l"><h3 class="bd b gy z fp ln fr fs lo fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="lq l"><p class="bd b dl z fp ln fr fs lo fu fw dk translated">medium.com</p></div></div><div class="lr l"><div class="ls l lt lu lv lr lw ky li"/></div></div></a></div><p id="0294" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">之前关于 MLflow 的文章:</p><ul class=""><li id="1b1b" class="lx ly it js b jt ju jx jy kb lz kf ma kj mb kn mc md me mf bi translated"><a class="ae le" rel="noopener" target="_blank" href="/scale-up-your-models-development-with-mlflow-4b78a5f22cb7"> <strong class="js iu">使用 MLflow </strong> </a>扩展您的模型开发</li><li id="0d59" class="lx ly it js b jt mg jx mh kb mi kf mj kj mk kn mc md me mf bi translated"><a class="ae le" rel="noopener" target="_blank" href="/improve-your-mlflow-experiment-keeping-track-of-historical-metrics-6e70a6c7b201?source=your_stories_page----------------------------------------"> <strong class="js iu">改进您的 MLflow 实验，跟踪历史指标</strong> </a></li></ul><h1 id="2f81" class="ml mm it bd mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni bi translated">目录</h1><p id="c7f0" class="pw-post-body-paragraph jq jr it js b jt nj jv jw jx nk jz ka kb nl kd ke kf nm kh ki kj nn kl km kn im bi translated">— <a class="ae le" href="#ca15" rel="noopener ugc nofollow">什么是 MLflow 插件？</a><br/>——<a class="ae le" href="#be30" rel="noopener ugc nofollow">MLflow AI-platform 插件</a> <br/> — — <a class="ae le" href="#fd82" rel="noopener ugc nofollow">我们需要什么来创建一个新的 ml flow 插件？</a><br/>—<a class="ae le" href="#d8c9" rel="noopener ugc nofollow">插件文件夹和模型模板文件的结构</a><br/>—<a class="ae le" href="#4673" rel="noopener ugc nofollow">部署跟踪界面</a><br/>—<a class="ae le" href="#92d1" rel="noopener ugc nofollow">创建捆绑方法</a><br/>—<a class="ae le" href="#c3b9" rel="noopener ugc nofollow">上传捆绑方法</a><br/>—<a class="ae le" href="#79d2" rel="noopener ugc nofollow">创建模型方法</a><br/>—<a class="ae le" href="#d3ba" rel="noopener ugc nofollow">更新部署方法</a><br/>—<a class="ae le" href="#5531" rel="noopener ugc nofollow">删除部署方法<br/></a></p><h1 id="ca15" class="ml mm it bd mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni bi translated">什么是 MLflow 插件？</h1><p id="9fbe" class="pw-post-body-paragraph jq jr it js b jt nj jv jw jx nk jz ka kb nl kd ke kf nm kh ki kj nn kl km kn im bi translated">MLflow 是一个与框架无关的机器学习工具，可以覆盖整个 ML 过程，从数据探索到模型开发、调整和部署。MLflow Python API 非常通用，允许开发人员为不同 ML 框架和后端完全集成 MLflow。插件是 MLflow 提供的集成之一。插件允许用户拥有额外的 MLflow 兼容组件，例如，可以保存特定服务的人工制品(例如，在专用数据库上)。此外，可以开发插件来接受第三方认证，或者将任何模型部署到定制平台。</p><p id="8f1f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这里你可以找到 MLflow 插件优秀文档:<a class="ae le" href="https://www.mlflow.org/docs/latest/plugins.html" rel="noopener ugc nofollow" target="_blank">https://www.mlflow.org/docs/latest/plugins.html</a>而在这里:<a class="ae le" href="https://www.mlflow.org/docs/latest/plugins.html#deployment-plugins" rel="noopener ugc nofollow" target="_blank">https://www . mlflow . org/docs/latest/plugins . html # deployment-plugins</a>你可以找到 ml flow 部署插件的列表。</p><p id="c363" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这篇文章中，我们将看到如何实现一个插件，这个插件可以将一个模型从开发带到 GCP 人工智能平台上。特别是，我们将理解创建一个新插件需要什么元素，以及我们需要什么功能来部署一个定制模型到 AI 平台。这将是一个可以进一步开发的框架，以在我们的 ML Ops 框架中获得一个更加自动化和自治的组件。</p><h1 id="be30" class="ml mm it bd mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni bi translated">MLflow 人工智能平台插件</h1><h2 id="fd82" class="no mm it bd mn np nq dn mr nr ns dp mv kb nt nu mz kf nv nw nd kj nx ny nh nz bi translated">我们需要什么来创建一个新的 MLflow 插件？</h2><p id="4974" class="pw-post-body-paragraph jq jr it js b jt nj jv jw jx nk jz ka kb nl kd ke kf nm kh ki kj nn kl km kn im bi translated">最终，MLflow 插件是一个定制的 Python 包，它必须满足主部署对象的以下约束:</p><ul class=""><li id="e8e5" class="lx ly it js b jt ju jx jy kb lz kf ma kj mb kn mc md me mf bi translated">必须是<code class="fe oa ob oc od b">mlflow.deployments.BaseDeploymentClient</code>的子类；</li><li id="df21" class="lx ly it js b jt mg jx mh kb mi kf mj kj mk kn mc md me mf bi translated">它必须具有<code class="fe oa ob oc od b">run_local</code>和<code class="fe oa ob oc od b">target_help</code>功能。前者允许本地测试——我们不会在本教程中实现这个功能——而后者可以返回有用的信息；</li><li id="09d3" class="lx ly it js b jt mg jx mh kb mi kf mj kj mk kn mc md me mf bi translated">它必须具有以下方法(由<code class="fe oa ob oc od b">BaseDeploymentClient</code>继承):1) <code class="fe oa ob oc od b">create_deployment</code>，用于定义部署过程的主要方法，2) <code class="fe oa ob oc od b">update_deployment</code>，用于更新部署信息，3) <code class="fe oa ob oc od b">delete_deployment</code>，用于删除已部署的模型，4) <code class="fe oa ob oc od b">list_deployments</code>，用于列出所有已部署的模型，5) <code class="fe oa ob oc od b">get_deplyoment</code>，用于检索特定已部署模型的信息，6) <code class="fe oa ob oc od b">predict</code>，用于直接从 MLflow 返回预测的主要方法。</li></ul><p id="df67" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">特别是，我们的目标是 GCP 人工智能平台。在 AI 平台上，将模型部署为端点有一条路径可循:<a class="ae le" href="https://cloud.google.com/ai-platform/prediction/docs/deploying-models" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/AI-platform/prediction/docs/deploying-models</a>。因此，我们可以构建这个路径，以便在我们的部署方法<code class="fe oa ob oc od b">create_deployment</code>中轻松实现，如图 1 所示:</p><ul class=""><li id="4df6" class="lx ly it js b jt ju jx jy kb lz kf ma kj mb kn mc md me mf bi translated">首先，代码检索所有需要的配置设置(例如<code class="fe oa ob oc od b">production_bucket</code>、<code class="fe oa ob oc od b">run_id</code>、工件等等)</li><li id="be71" class="lx ly it js b jt mg jx mh kb mi kf mj kj mk kn mc md me mf bi translated">然后创建一个“部署包”。代码寻找模型工件的位置、生产 uri，它为我们的模型创建安装包以及模型的端点 API Python 代码— <code class="fe oa ob oc od b">create_bundle()</code></li><li id="609b" class="lx ly it js b jt mg jx mh kb mi kf mj kj mk kn mc md me mf bi translated">此时，可以将捆绑包推到特定的生产桶— <code class="fe oa ob oc od b">upload_bundle()</code></li><li id="ee84" class="lx ly it js b jt mg jx mh kb mi kf mj kj mk kn mc md me mf bi translated">AI 平台 Python API 开始在平台上创建模型容器— <code class="fe oa ob oc od b">create_model()</code></li><li id="5ee5" class="lx ly it js b jt mg jx mh kb mi kf mj kj mk kn mc md me mf bi translated">一个 json 请求被发送到 AI 平台以继续模型部署— <code class="fe oa ob oc od b">update_deployment()</code></li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oe"><img src="../Images/9c253f565a112f784b4221189f4d8140.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L1oBB3HTUeMic7agcor3Dg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 1:主部署类方法 create_deployment()遵循 AI 平台路径将新模型部署到端点</p></figure><p id="2767" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">此外，我们必须创建<code class="fe oa ob oc od b">delete_deployment</code>、<code class="fe oa ob oc od b">get_deployment</code>和<code class="fe oa ob oc od b">list_deployments</code>方法，始终使用 AI 平台 API，以满足 MLflow 部署插件的需求。</p><h2 id="d8c9" class="no mm it bd mn np nq dn mr nr ns dp mv kb nt nu mz kf nv nw nd kj nx ny nh nz bi translated">插件文件夹和模型模板文件的结构</h2><p id="e7f8" class="pw-post-body-paragraph jq jr it js b jt nj jv jw jx nk jz ka kb nl kd ke kf nm kh ki kj nn kl km kn im bi translated">首先，插件包文件和文件夹的结构可以定义如下:</p><pre class="kp kq kr ks gt of od og oh aw oi bi"><span id="76d9" class="no mm it od b gy oj ok l ol om">mlflow_ai_plugin/ <br/>                mlflow_ai_plugin/<br/>                                __init__.py<br/>                                DeploymentTrackingInterface.py<br/>                                model_setup.py<br/>                                predictor_template.py<br/>                requirements.txt<br/>                setup.py</span></pre><p id="7b57" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">主部署类包含在入口点<code class="fe oa ob oc od b">DeploymentTrackingInterface.py</code>中。<code class="fe oa ob oc od b">predictor_template.py</code>是模型端点 API 的模板版本:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="on oo l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 2:给定模型的模板化 API。在这个例子中，我们正在处理 load_iris，注释指出可以使用一个预处理器</p></figure><p id="67f2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">API 满足了 AI 平台的需求。首先，类构造函数<code class="fe oa ob oc od b">__init__</code>读取输入模型和预处理器——为了简单起见，我们在这里注释掉了预处理器的位。方法<code class="fe oa ob oc od b">predict</code>返回模型的预测。一个输入数据集被转换成一个 NumPy 数组作为<code class="fe oa ob oc od b">np.array(instances)</code>，并通过<code class="fe oa ob oc od b">self._model.predict(inputs).</code>计算概率。最后，方法<code class="fe oa ob oc od b">from_path</code>允许使用 MLflow 在 AI 平台中旋转模型。任何模型的 artefact 文件(如<code class="fe oa ob oc od b">pickle, joblib, h5</code>)都可以作为<code class="fe oa ob oc od b">mlflow.pyfun.load_model()</code>通过 MLflow 读取。这里的<code class="fe oa ob oc od b">MODEL_ARTIFACT_URI</code>是一个模板化的关键字，当部署脚本运行时，可以通过 main 方法<code class="fe oa ob oc od b">create_bundle()</code>用模型工件 uri 替换它，我们将在后面看到。</p><p id="8a5b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了让模型的 API <code class="fe oa ob oc od b">predictor_template.py</code>工作，需要一个<code class="fe oa ob oc od b">setup.py</code>文件，这样 AI-platform 就知道需要哪些包来安装模型。<code class="fe oa ob oc od b">model_setup.py</code>是模型设置文件的模板版本。在本例中，设置文件相当简单，但是可以进行调整，例如，由数据科学家在部署时进行调整:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="on oo l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 3:模型的 setup.py 文件的模板版本</p></figure><p id="f29a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">同样，在方法<code class="fe oa ob oc od b">create_bundle</code>中，模板关键字<code class="fe oa ob oc od b">MODEL_VERSION</code>被当前模型版本所替代。该文件将创建一个名为<code class="fe oa ob oc od b">deploy_from_script</code>的包，它的脚本是<code class="fe oa ob oc od b">predictor.py</code>——它是从<code class="fe oa ob oc od b">predictor_template.py</code>创建的——它的依赖项是通过<code class="fe oa ob oc od b">install_requires</code>安装的。</p><h2 id="4673" class="no mm it bd mn np nq dn mr nr ns dp mv kb nt nu mz kf nv nw nd kj nx ny nh nz bi translated">部署跟踪界面</h2><p id="35f2" class="pw-post-body-paragraph jq jr it js b jt nj jv jw jx nk jz ka kb nl kd ke kf nm kh ki kj nn kl km kn im bi translated">是我们插件的核心，所有人工智能平台的步骤都在这里被触发和控制。</p><p id="8612" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">配置和构造器</strong></p><p id="b469" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">第一步是定义作业常量变量、配置和对象构造函数。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="on oo l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 4:定义插件常量变量，如 AI_PLATFORM、GS_BUCKET、TODAY 和 MLFLOW_AIPLATFORM_PATH。</p></figure><p id="432d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">图 4 显示了导入语句和常量变量。在这些导入中，值得记住的是我们需要导入<code class="fe oa ob oc od b">from mlflow.deployments import BaseDeploymentClient</code>和<code class="fe oa ob oc od b">import mlflow_ai_plugin</code>，这是包本身，因此将有可能检索模板化文件<code class="fe oa ob oc od b">predictor_template.py</code>和<code class="fe oa ob oc od b">model_setup.py</code>的路径。最后，我们可以在这里定义 MLflow 插件需要的两个功能，分别是<code class="fe oa ob oc od b">run_local</code>和<code class="fe oa ob oc od b">target_help</code>——这里就不实现了。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="on oo l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 Config 类定义了我们使用 AI 平台所需的所有配置设置</p></figure><p id="6bf9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于人工智能平台和流程配置，我们可以定义一个类<code class="fe oa ob oc od b">Config</code>,它读取包含以下所有变量的字典的输入:</p><ul class=""><li id="afc9" class="lx ly it js b jt ju jx jy kb lz kf ma kj mb kn mc md me mf bi translated">这是我们正在进行的 GCP 项目</li><li id="9e61" class="lx ly it js b jt mg jx mh kb mi kf mj kj mk kn mc md me mf bi translated"><code class="fe oa ob oc od b">production_bucket</code>生产用桶的名称</li><li id="375c" class="lx ly it js b jt mg jx mh kb mi kf mj kj mk kn mc md me mf bi translated"><code class="fe oa ob oc od b">production_route</code>我们希望在<code class="fe oa ob oc od b">production_bucket</code>中存储所有模型工件的路径</li><li id="30a5" class="lx ly it js b jt mg jx mh kb mi kf mj kj mk kn mc md me mf bi translated"><code class="fe oa ob oc od b">run_id</code>ml flow 模型的运行 id，因此我们可以选择特定的模型</li><li id="f993" class="lx ly it js b jt mg jx mh kb mi kf mj kj mk kn mc md me mf bi translated"><code class="fe oa ob oc od b">tracking_uri</code>是 MLflow UI uri，例如<code class="fe oa ob oc od b">http://localhost:5000</code></li><li id="9c58" class="lx ly it js b jt mg jx mh kb mi kf mj kj mk kn mc md me mf bi translated"><code class="fe oa ob oc od b">prediction_script</code>定义了<code class="fe oa ob oc od b">predictor_template.py</code>的路径，该路径将被<code class="fe oa ob oc od b">create_bundle()</code>读取以容纳模型的端点信息</li><li id="a600" class="lx ly it js b jt mg jx mh kb mi kf mj kj mk kn mc md me mf bi translated"><code class="fe oa ob oc od b">tmp_dir</code>定义一个临时路径，插件可以在这里创建文件</li><li id="a300" class="lx ly it js b jt mg jx mh kb mi kf mj kj mk kn mc md me mf bi translated"><code class="fe oa ob oc od b">setup_file</code>是<code class="fe oa ob oc od b">model_setup.py</code>文件路径，将由<code class="fe oa ob oc od b">create_bundle()</code>读取</li><li id="13de" class="lx ly it js b jt mg jx mh kb mi kf mj kj mk kn mc md me mf bi translated"><code class="fe oa ob oc od b">model_name</code>生产中的型号名称</li><li id="95c3" class="lx ly it js b jt mg jx mh kb mi kf mj kj mk kn mc md me mf bi translated"><code class="fe oa ob oc od b">version_name</code>型号的版本</li></ul><p id="31b0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">部署协议</strong></p><p id="6596" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">图 6 显示了部署协议，它定义了在 MLflow 中实现插件所需的所有方法，以及将模型部署到 AI 平台的所有方法。构造函数<code class="fe oa ob oc od b">__init__</code>定义了来自<code class="fe oa ob oc od b">Config</code>类的配置设置——如上所述。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="on oo l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 6:部署协议定义。这个类是 AI 平台 MLflow 插件的核心，定义 MLflow 所需的方法和 AI 平台方法来部署模型</p></figure><h2 id="92d1" class="no mm it bd mn np nq dn mr nr ns dp mv kb nt nu mz kf nv nw nd kj nx ny nh nz bi translated">创建捆绑方法</h2><p id="30fa" class="pw-post-body-paragraph jq jr it js b jt nj jv jw jx nk jz ka kb nl kd ke kf nm kh ki kj nn kl km kn im bi translated">图 7 显示了创建模型“包”，即模型文件的代码步骤。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="on oo l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 7:该方法检索模型信息，创建 setup.py 和模型的 API 脚本，并将所有内容打包到一个 tar 文件中</p></figure><p id="56ba" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">首先调用<code class="fe oa ob oc od b">retrieve_model_info()</code>(图 8)。在这里，通过<code class="fe oa ob oc od b">MlflowClient</code>从其<code class="fe oa ob oc od b">run_id</code>中检索模型文件，并将其转换为字典<code class="fe oa ob oc od b">run_info['info']['artifact_uri']</code>。</p><p id="ea9c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">随后，模型的端点 Python <code class="fe oa ob oc od b">predictor.py</code>被相应调整，这样<code class="fe oa ob oc od b">MODEL_ARTIFACT_URI</code>将是<code class="fe oa ob oc od b">self.model_uri_production</code>路径(例如<code class="fe oa ob oc od b">gs://bucket/model/model.joblib</code>)<code class="fe oa ob oc od b">template_predictor.py</code>文件将被保存为<code class="fe oa ob oc od b">self.predictor_path</code>(例如<code class="fe oa ob oc od b">predictor.py</code>)。这个替换是使用 Ubuntu 的<code class="fe oa ob oc od b">sed</code>命令完成的</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="on oo l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 8:检索模型信息并创建设置和端点文件</p></figure><p id="0fa9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后，创建模型的<code class="fe oa ob oc od b">setup.py</code>,再次通过<code class="fe oa ob oc od b">sed</code>替换<code class="fe oa ob oc od b">MODEL_VERSION</code>,并将文件保存在本地，这样 AI 平台可以读取它。一旦模型文件可用，<code class="fe oa ob oc od b">create_bundle</code>通过命令<code class="fe oa ob oc od b">python self.setup_path sdist --formats=gztar</code>将安装<code class="fe oa ob oc od b">sdist</code>打包到<code class="fe oa ob oc od b">gztar </code>中，并将<code class="fe oa ob oc od b">gztar</code>文件路径返回给<code class="fe oa ob oc od b">create_deployment</code></p><h2 id="c3b9" class="no mm it bd mn np nq dn mr nr ns dp mv kb nt nu mz kf nv nw nd kj nx ny nh nz bi translated">上传捆绑方法</h2><p id="ce6e" class="pw-post-body-paragraph jq jr it js b jt nj jv jw jx nk jz ka kb nl kd ke kf nm kh ki kj nn kl km kn im bi translated">此时，安装<code class="fe oa ob oc od b">gztar</code>文件，以及模型工件(如模型二进制文件<code class="fe oa ob oc od b">model.joblib</code>)被上传到生产路径。如图 9 所示</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="on oo l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 9:上传包方法负责将包文件和模型的工件上传到生产桶。在模型工件中，我们将有模型的二进制文件(例如 joblib 扩展)，它允许预测 API 读取模型</p></figure><h2 id="79d2" class="no mm it bd mn np nq dn mr nr ns dp mv kb nt nu mz kf nv nw nd kj nx ny nh nz bi translated">创建模型方法</h2><p id="ad9a" class="pw-post-body-paragraph jq jr it js b jt nj jv jw jx nk jz ka kb nl kd ke kf nm kh ki kj nn kl km kn im bi translated">接下来，一旦所有文件对 AI 平台可用，我们需要通过<code class="fe oa ob oc od b">create_model</code>创建一个 AI 平台模型。最初，一个 json 请求被发送到 AI 平台，指定模型名称<code class="fe oa ob oc od b">self.settings['model_name']</code>，我们是否想要一个终点预测<code class="fe oa ob oc od b">onlinePredictionLogging</code>和工作区域(例如<code class="fe oa ob oc od b">europe-west1</code>)。然后，列出 AI 平台中的所有模型<code class="fe oa ob oc od b">AI_PLATFORM.projects().models().list</code>，一个 for 循环检查给定的模型名称是否已经存在。如果模型不存在，<code class="fe oa ob oc od b">AI_PLATFORM</code>创建这个新模型作为<code class="fe oa ob oc od b">AI_PLATFORM.projects().models().create().execute()</code></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="on oo l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 10:创建模型方法向 AI 平台发送请求，以检查模型是否存在，否则 AI 平台创建新模型</p></figure><h2 id="d3ba" class="no mm it bd mn np nq dn mr nr ns dp mv kb nt nu mz kf nv nw nd kj nx ny nh nz bi translated">更新部署方法</h2><p id="be45" class="pw-post-body-paragraph jq jr it js b jt nj jv jw jx nk jz ka kb nl kd ke kf nm kh ki kj nn kl km kn im bi translated"><code class="fe oa ob oc od b">update_deployment</code>方法是部署的真正触发器，也是 MLflow 插件的要求。该方法调用<code class="fe oa ob oc od b">update_source</code>方法，如图 11 所示</p><p id="427a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">向人工智能平台发送 json 请求。json 请求包含模型的名称，<code class="fe oa ob oc od b">deploymentUri</code>是模型工件的位置，<code class="fe oa ob oc od b">createTime</code>，<code class="fe oa ob oc od b">machineType</code>，<code class="fe oa ob oc od b">packageUris</code>是<code class="fe oa ob oc od b">gztar</code>模型安装文件的位置，<code class="fe oa ob oc od b">pythonVersion</code>，<code class="fe oa ob oc od b">runtimeVersion</code>是 AI 平台的位置，<code class="fe oa ob oc od b">predictorClass</code>是模型端点文件<code class="fe oa ob oc od b">predictor.py</code>的预测类</p><p id="5b87" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过<code class="fe oa ob oc od b">AI_PLATFORM.projects().models().versions().create</code>创建新的端点</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="on oo l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 11:上传部署和更新源是 MLflow 部署插件的关键元素。update_source 向 AI 平台发送一个 json 请求，带有 model_uri_production，即模型的 artefacts 路径，以及 package uri，即模型的 gztar 路径和 endpoint 类，以便创建模型的端点</p></figure><h2 id="5531" class="no mm it bd mn np nq dn mr nr ns dp mv kb nt nu mz kf nv nw nd kj nx ny nh nz bi translated">删除部署方法</h2><p id="ac60" class="pw-post-body-paragraph jq jr it js b jt nj jv jw jx nk jz ka kb nl kd ke kf nm kh ki kj nn kl km kn im bi translated">现在，让我们看看附件插件方法。<code class="fe oa ob oc od b">delete_deployment</code>删除一个现有的模型，给出它的 GCP uri(图 12)。</p><p id="33dd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">模型的版本被重构，以与 AI 平台一致，并且模型的 AI 平台路径被创建<code class="fe oa ob oc od b">parent = self.settings['project_id'] + f"/models/{self.settings['model_name']}"</code>。然后通过<code class="fe oa ob oc od b">AI_PLATFORM.projects().models().versions().delete(name=body)</code>删除该模型</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="on oo l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 12:删除部署方法。json 请求被发送到 AI 平台，以便从 AI 平台中删除给定的模型</p></figure><h2 id="1efa" class="no mm it bd mn np nq dn mr nr ns dp mv kb nt nu mz kf nv nw nd kj nx ny nh nz bi translated">获取和列出部署方法</h2><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="on oo l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 13:获取并列出部署方法。从 get 可以从模型的名称中检索到关于特定模型的信息，而 list deployments 返回所有已部署的模型</p></figure><p id="ff57" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">图 13 显示了<code class="fe oa ob oc od b">get_deployment</code>和<code class="fe oa ob oc od b">list_deployment</code>方法。前者通过<code class="fe oa ob oc od b">AI_PLATFORM.projects().models().version().get(name=body)</code>从一个模特的名字中返回模特的信息。后者，通过<code class="fe oa ob oc od b">AI_PLATFORM.projects().models().version().list(parent=parent)</code>登记所有部署的模型，其中<code class="fe oa ob oc od b">parent</code>是模型在 AI-platform 中的 uri。</p><h1 id="a7af" class="ml mm it bd mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni bi translated">安装 MLflow 部署插件</h1><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="on oo l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 14:安装 MLflow 部署插件 g mlflow_ai_plugin 的 setup.py 文件</p></figure><p id="1cbf" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在让我们将注意力转向 MLflow 部署插件<code class="fe oa ob oc od b">setup.py</code>文件。此安装程序将在您的 MLflow 安装中安装插件。值得注意的是，我们需要指定插件入口点:<code class="fe oa ob oc od b">entry_points={"mlflow.deployments":"aiplatform=mlflow_ai_plugin.DeploymentTrackingInterface"}</code>，它调用<code class="fe oa ob oc od b">DeploymentTrackingInterface</code>代码。<code class="fe oa ob oc od b">aiplatform</code>是从 MLflow 中读取的目标，因此我们可以通过类似<code class="fe oa ob oc od b">mlflow deployments create -t aiplatform ...</code>的命令调用我们的 MLflow AI-platform 插件</p><h1 id="2e66" class="ml mm it bd mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni bi translated">例子</h1><p id="90a4" class="pw-post-body-paragraph jq jr it js b jt nj jv jw jx nk jz ka kb nl kd ke kf nm kh ki kj nn kl km kn im bi translated">最后，让我们看一些如何使用部署插件的例子。首先，我们将通过 Python 运行部署插件。首先，<a class="ae le" rel="noopener" target="_blank" href="/improve-your-mlflow-experiment-keeping-track-of-historical-metrics-6e70a6c7b201#8668">正如我们在 MLflow 系列的第 2 部分中看到的，让我们运行一个 MLflow 实验</a>，在这里我们训练一个简单的神经网络模型，如图 15 所示</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="on oo l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 15:要在 MLflow 上训练的玩具模型</p></figure><p id="3e4b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦模型的训练被保存在 MLflow 中，我们就可以通过 Python 脚本部署该模型，如下所示:</p><pre class="kp kq kr ks gt of od og oh aw oi bi"><span id="53eb" class="no mm it od b gy oj ok l ol om">from mlflow.deployments import get_deploy_client</span><span id="d222" class="no mm it od b gy op ok l ol om">target_uri = 'aiplatform'<br/>aiplatform = get_deploy_client(target_uri)<br/>aiplatform.create_deployment()</span></pre><p id="bf28" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe oa ob oc od b">target_uri='aiplatform'</code>将目标传达给 MLflow。从那里我们可以使用<code class="fe oa ob oc od b">mlflow.deployments</code>方法来获得我们的 AI 平台插件并调用部署核心<code class="fe oa ob oc od b">aiplatform.create_deploment()</code></p><p id="1171" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，我们可以通过 bash 脚本完成部署，指定输入 env 变量:</p><pre class="kp kq kr ks gt of od og oh aw oi bi"><span id="9baf" class="no mm it od b gy oj ok l ol om">#!/bin/bash <br/>export project_id='YOUR GCP PROJECT'<br/>export production_bucket='YOUR PRODUCTION BUCKET'<br/>export production_route='YOUR PATH WITHIN PROD BUCKET'<br/>export run_id='2c6d5f4bc3bc4bf3b6df3ca80212a28d'<br/>export tracking_uri='http://localhost:5000'<br/>export model_name='YOUR MODEL NAME'<br/>export version_name='VERSION NUMBER'<br/>python deploy.py</span></pre><p id="c944" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过命令行界面可以获得相同的结果。在这种情况下，我们不会调用 python 脚本，而是:</p><pre class="kp kq kr ks gt of od og oh aw oi bi"><span id="e698" class="no mm it od b gy oj ok l ol om"># export statements as above <br/>export model_uri="YOUR MODEL PRODUCTION URI"</span><span id="bb1f" class="no mm it od b gy op ok l ol om">mlflow deployments create -t aiplatform --name tester -m $model-uri</span></pre><p id="132e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后，我们可以发送请求来获得对数据的预测，如图 16 所示。这里我们将使用<code class="fe oa ob oc od b">googleapiclient.discovery</code> API，用输入数据创建一个 json 请求来返回模型的预测。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="on oo l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 16:通过 googleapiclient.discovery 发送预测数据</p></figure></div><div class="ab cl oq or hx os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="im in io ip iq"><p id="deb5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">MLflow 这边到此为止！我希望你喜欢这些关于 MLflow 及其 SDK 开发和插件的文章。</p><p id="f76e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你有任何问题或好奇，请给我发电子邮件到 stefanobosisio1@gmail.com</p></div></div>    
</body>
</html>