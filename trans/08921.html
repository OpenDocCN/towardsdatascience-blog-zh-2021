<html>
<head>
<title>Creating an Innovative Custom Loss Function in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Python中创建创新的自定义损失函数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/creating-a-innovative-custom-loss-function-in-python-using-tensorflow-and-fitting-a-lstm-model-ded222efbc89?source=collection_archive---------20-----------------------#2021-08-17">https://towardsdatascience.com/creating-a-innovative-custom-loss-function-in-python-using-tensorflow-and-fitting-a-lstm-model-ded222efbc89?source=collection_archive---------20-----------------------#2021-08-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="03cb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在python中使用Tensorflow包并使用LSTM模型进行测试</h2></div><p id="c2cc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里我想介绍一个创新的新损失函数。我将这个新的损失函数定义为MSE-MAD。使用指数加权移动平均框架并结合使用MSE和MAD来构建损失函数。MSE-MAD的结果将使用适合太阳黑子数据的LSTM模型进行比较。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi le"><img src="../Images/046a885c225f3387d360f9f519a70fca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*IFjkyiwdUO6m-VDf8avWtg.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">图片来源【https://algorithm ia . com/blog/introduction-to-loss-functions】经作者允许编辑。</p></figure><h1 id="09f1" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">介绍</h1><p id="dcd0" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">在我们进入新的损失函数之前，让我先介绍一下什么是损失函数，以及它如何应用于机器学习。损失函数的目的是衡量模型对输入数据的解释程度。换句话说，损失函数是我们的预测与响应变量之间距离的度量。在几乎所有的应用中，我们都有一个固定的模型，目标是在给定一些数据的情况下估计模型的参数。</p><p id="2d0a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我介绍这个新的损失函数之前，我将首先介绍一些基本的损失函数以及它们在模型拟合期间的表现。</p><h1 id="7fe3" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">均方误差</h1><p id="1d65" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">均方差是我要介绍的第一个损失函数。均方误差(MSE)的计算公式如下</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/04a3653ba76ca280f3a28f92007f6e46.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*2rwChZBoGggEAgd6vInLOA.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">均方误差</p></figure><p id="415e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">根据MSE公式，hat表示变量y的预测值或估计值。在数学中，变量上方的hat表示给定随机变量的估计值。n代表我们估计的总数据点的数量。从某种意义上说，MSE公式所做的只是测量每个预测与响应变量之间的距离，并对距离求平方，然后对所有测量值求平均值。下图用虚线显示了模型，每个数据点用绿色显示。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/100d7cb6718f5168ffabd25f35aef499.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*GuEm3LG0YxPG3PRaafE1nA.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">误差测量</p></figure><p id="11d9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">python中MSE的实现如下。</p><pre class="lf lg lh li gt mp mq mr bn ms mt bi"><span id="1044" class="mu lr it mq b be mv mw l mx my">def MSE(y_predicted, y):<br/>  squared_error = (y_predicted - y) ** 2<br/>  sum_squared_error = np.sum(squared_error)<br/>  mse = sum_squared_error / y.size<br/>  return(mse)</span></pre><h1 id="3d37" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">平均绝对偏差</h1><p id="c40e" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">下一个损失函数是平均绝对偏差(MAD)。MAD的公式如下所示</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/ceb4aff6ef621217ad7836ed69e467b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*qKid6VKLvdr4Cu-hfO3gjw.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">平均绝对偏差</p></figure><p id="dcf5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在MAD函数的实现中，我使用TensorFlow包来计算平均值。</p><pre class="lf lg lh li gt mp mq mr bn ms mt bi"><span id="8ace" class="mu lr it mq b be mv mw l mx my">def MAD(y_true, y_pred):   <br/>   mean =  tf.reduce_mean((y_true - y_pred))<br/>   mad = tf.reduce_mean((y_true - mean)<br/>   return(mad)</span></pre><h1 id="2712" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">MSE-MAD损失函数</h1><p id="d4ea" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">这里我介绍一下自定义损失函数。这个损失函数的背景使用EWMA框架，其中我们的阿尔法项固定在0.5。简单地说，损失函数是MSE和MAD公式的组合。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi na"><img src="../Images/ca7e75488037cc2540fa12083ee52f1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*DCq7YTdrjZtEOpO1kRFThw.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">MSE-MAD损失函数</p></figure><pre class="lf lg lh li gt mp mq mr bn ms mt bi"><span id="8524" class="mu lr it mq b be mv mw l mx my">def custom_loss_function(y_true, y_pred):<br/>   squared_difference = tf.square((y_true - y_pred))<br/>   mse = tf.reduce_mean(squared_difference, axis=-1)<br/>   mean =  tf.reduce_mean((y_true - y_pred))<br/>   mad = tf.reduce_mean((y_true - y_pred) - mean)<br/>   return 0.5*mse + (1-0.5)*mad</span></pre><h1 id="4781" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">使用LSTM模型的损失函数比较</h1><p id="5173" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">首先，我介绍用于比较的数据集和机器学习模型。正在使用的数据集太阳黑子数据集和LSTM模型将用于预测太阳黑子时间序列。</p><h1 id="4ca4" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">LSTM模式介绍</h1><p id="d6c3" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">递归神经网络是用于建模时间序列数据的人工神经网络家族的一部分。递归神经网络结合先前的信息来预测当前的时间步长。给定一个输入向量x = (x1，.。。，xn)，我们假设每个xi独立于x中的每个其他观察值。但是，对于资产数据，这可能不成立，需要创建一个模型来说明某些给定时间序列数据的动态行为。对于给定数量的先前时间步骤，使用人工神经网络来构建递归神经网络的结构。在这篇论文中，我们探讨了RNN在预测未来股票价格中的应用。使用RNN的主要缺点是在尝试将模型参数拟合到数据时渐变会消失和爆炸</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/613230caaeb2c0665845f87678e75e66.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*fWwYqwAX5DuzNnX14ymviQ.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">LSTM门</p></figure><p id="b4fb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每个块A代表具有输入xt和输出ht的神经网络。LSTM背后的主要思想是遗忘之门，信息可以通过它传递给下一个神经网络。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi nc"><img src="../Images/2f50c1eca9063d3827ba044515cd8e9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*TFo4osa2YMAGWdk9mvJARg.png"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">LSTM建筑</p></figure><p id="649d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">LSTM模型成为时间序列预测的有力工具。</p><h1 id="a065" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">黑子数据集游戏攻略</h1><p id="ee25" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">该数据集包含太阳黑子数量的月度数据(从1749年到2013年)。有3000多个数据点。我们演示数据集的前几行。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/119f8e9c8dbf064622fe7f5c1b071964.png" data-original-src="https://miro.medium.com/v2/resize:fit:226/format:webp/1*CPmDLpLHL_ZYjeLrLYfCXA.png"/></div></figure><p id="cf74" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从上表中我们可以看到，我们得到了包含太阳黑子数量的每月数据。当拟合LSTM模型来预测时间序列数据时，我们将要求值限制在0和1之间。</p><p id="b30e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于LSTM模型，模型结构由输入数据的结构和预测特征决定。取决于在拟合时有多少个月用于回顾，特征的数量将决定需要权重和偏差的神经元的数量。</p></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><p id="8def" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了在比较每个损失函数时保持一致，将使用相同的LSTM模型结构，如下所示。</p><pre class="lf lg lh li gt mp mq mr bn ms mt bi"><span id="8440" class="mu lr it mq b be mv mw l mx my"># Initializing the LSTM<br/>regressor = Sequential()<br/># Adding the first LSTM layer and some Dropout regularisation<br/>regressor.add(LSTM(units = nodes, return_sequences = True, input_shape = (new.shape[1], new.shape[2])))<br/>regressor.add(Dropout(0.2))<br/># Adding a second LSTM layer and some Dropout regularisation<br/>regressor.add(LSTM(units = nodes, return_sequences = True))<br/>regressor.add(Dropout(0.2))<br/># Adding a third LSTM layer and some Dropout regularisation<br/>regressor.add(LSTM(units = nodes, return_sequences = True))<br/>regressor.add(Dropout(0.2))<br/>regressor.add(LSTM(units = nodes))<br/>regressor.add(Dropout(0.2))<br/># Adding the output layer<br/>regressor.add(Dense(units = t)) # this is the output layer so this represents a single node with our output value</span></pre><p id="af20" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">既然我们已经编译了模型。我首先测试MSE损失函数作为基线。</p><pre class="lf lg lh li gt mp mq mr bn ms mt bi"><span id="75ab" class="mu lr it mq b be mv mw l mx my"># Compiling the RNN<br/>regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')<br/># Fitting the RNN to the Training set<br/>model = regressor.fit(new, y_train, epochs = 50, batch_size = 22)</span></pre><p id="9d06" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">损失函数在编译步骤中设置。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi np"><img src="../Images/718823bf605a1dbf14f5c0c4a9d6afe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*7g7tn_opXENq5Cq7lgdEQA.png"/></div></figure><p id="e2bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来我研究了Huber损失函数。我测试Huber损失函数的原因是它遵循与MSE-MAD相似的结构，其中Huber函数充当组合函数或分段函数。</p><pre class="lf lg lh li gt mp mq mr bn ms mt bi"><span id="c63a" class="mu lr it mq b be mv mw l mx my"># Compiling the RNN<br/>regressor.compile(optimizer = 'adam', loss = "huber_loss")<br/># Fitting the RNN to the Training set<br/>model = regressor.fit(new, y_train, epochs = 50, batch_size = 22)</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/b3530562c2075475cbccce3fd6fb4dd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*jKafYlkld7T_M5_YpYfBow.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">胡伯损失函数</p></figure><p id="02d7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后我给出了MSE-MAD损失函数的结果。实现是简单地将损失函数定义为python函数，然后在编译模型时以下面的方式调用它。</p><pre class="lf lg lh li gt mp mq mr bn ms mt bi"><span id="73da" class="mu lr it mq b be mv mw l mx my"># Compiling the RNN<br/>regressor.compile(optimizer='adam', loss=custom_loss_function)<br/># Fitting the RNN to the Training set<br/>model = regressor.fit(new, y_train, epochs = 50, batch_size = 22)</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/9f017b863da46660f60d17a0b544242b.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*uCkOujOD7jDJgWtpsSiT_A.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">MSE-MAD损失函数</p></figure><p id="0cd5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当比较MSE-MAD和MSE时，我们发现收敛大约是一半快，然而当我们比较MSE-MAD和huber损失函数时，我发现非常相似的结果。</p><h1 id="d016" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">LSTM预言</h1><p id="7aec" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">下面使用自定义损失函数给出了LSTM的最终预测。使用覆盖速度更快的损失函数的主要好处是运行时间更短，并且可以更快地求解模型的最佳参数。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/7bfa9a14de095c4bc30541cfcbee4fb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*MQu0eMU2i7MmZ0hI7mQKvg.png"/></div></figure></div><div class="ab cl ni nj hx nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="im in io ip iq"><h1 id="6b55" class="lq lr it bd ls lt ns lv lw lx nt lz ma jz nu ka mc kc nv kd me kf nw kg mg mh bi translated">关于我自己的一点点</h1><p id="09cb" class="pw-post-body-paragraph ki kj it kk b kl mi ju kn ko mj jx kq kr mk kt ku kv ml kx ky kz mm lb lc ld im bi translated">我最近在加拿大多伦多的瑞尔森大学获得了应用数学硕士学位。我是金融数学组的一员，专业是统计学。我深入研究了波动建模和算法交易。</p><p id="17dd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我之前在庞巴迪宇航公司担任工程专业人员，负责与飞机维护相关的生命周期成本建模。</p><p id="2c42" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本人积极训练铁人三项，热爱健身。</p><div class="nx ny gp gr nz oa"><a href="https://www.linkedin.com/in/ethanjohnsonskinner/" rel="noopener  ugc nofollow" target="_blank"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd iu gy z fp of fr fs og fu fw is bi translated">伊森·约翰逊-斯金纳-数学导师-夏普Minds学院| LinkedIn</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">我最近在瑞尔森大学获得了应用数学硕士学位。我是财务的一部分…</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">www.linkedin.com</p></div></div></div></a></div><p id="bbb1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">推特:@Ethan_JS94</p></div></div>    
</body>
</html>