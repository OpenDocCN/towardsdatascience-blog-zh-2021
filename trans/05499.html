<html>
<head>
<title>Strategies and Tactics for Regression on Imbalanced Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不平衡数据回归的策略和方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/strategies-and-tactics-for-regression-on-imbalanced-data-61eeb0921fca?source=collection_archive---------2-----------------------#2021-05-16">https://towardsdatascience.com/strategies-and-tactics-for-regression-on-imbalanced-data-61eeb0921fca?source=collection_archive---------2-----------------------#2021-05-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/185f76eef469751e3072bcb2479f1ede.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lv3stjRTR86LUKli3druUA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">(图片由作者提供)</p></figure><h2 id="7d4f" class="jd je jf bd b dl jg jh ji jj jk jl dk jm translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><div class=""><h2 id="b602" class="pw-subtitle-paragraph kl jo jf bd b km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc dk translated">深入探究深度不平衡回归(ICML 2021，龙口述)</h2></div><p id="0431" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">给大家介绍一下我们的最新作品，已经被ICML 2021接受为<strong class="lf jp"> <em class="lz">长篇口述</em> </strong>展示:<a class="ae ma" href="https://arxiv.org/abs/2102.09554" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jp">深度挖掘不平衡回归</strong> </a>。在经典的数据不平衡问题下，本工作探索了一个非常实用但很少研究的问题:<strong class="lf jp">不平衡回归</strong>。现有的处理不平衡数据的方法大多只针对分类问题——即目标值是不同类别的离散指标；然而，许多实际任务涉及<strong class="lf jp">连续</strong>，有时甚至<strong class="lf jp">无限</strong>目标值。这项工作提升了传统不平衡分类问题的范式，将数据不平衡问题从<strong class="lf jp">离散</strong>目标扩展到<strong class="lf jp">连续</strong>目标。</p><p id="3b02" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们不仅提出了两种简单而有效的方法来提高不平衡回归问题的模型性能，而且还为计算机视觉、自然语言处理和医疗保健领域的常见现实任务建立了五个新的基准不平衡回归数据集。代码、数据和模型已经在GitHub上开源:<a class="ae ma" href="https://github.com/YyzHarry/imbalanced-regression" rel="noopener ugc nofollow" target="_blank">https://github.com/YyzHarry/imbalanced-regression</a>。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><p id="b127" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">首先，我想先总结一下本文的主要贡献:</p><ul class=""><li id="2716" class="mi mj jf lf b lg lh lj lk lm mk lq ml lu mm ly mn mo mp mq bi translated"><strong class="lf jp">新任务</strong>:我们正式定义了现实环境中出现的<em class="lz">深度不平衡回归(DIR) </em>任务。DIR旨在从具有连续目标的不平衡数据中学习，处理某些区域的潜在缺失数据，并推广到整个目标范围。</li><li id="4a41" class="mi mj jf lf b lg mr lj ms lm mt lq mu lu mv ly mn mo mp mq bi translated"><strong class="lf jp">新技术</strong>:我们开发了两种简单、有效、可解释的DIR寻址算法:<em class="lz">标签分布平滑(LDS) </em>和<em class="lz">特征分布平滑(FDS) </em>，它们利用了标签和特征空间中邻近目标之间的相似性。</li><li id="06ee" class="mi mj jf lf b lg mr lj ms lm mt lq mu lu mv ly mn mo mp mq bi translated"><strong class="lf jp">新基准</strong>:我们为<em class="lz">计算机视觉</em>、<em class="lz">自然语言处理</em>和<em class="lz">医疗保健</em>中常见的现实世界任务策划和基准测试大规模DIR数据集。它们的范围从<em class="lz">单值</em>预测，如年龄、文本相似性得分、健康状况得分，到<em class="lz">密集值</em>预测，如深度。新的数据集可以支持实际评估，并有助于不平衡回归的未来研究。</li></ul><p id="f285" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">接下来，我们将进入正文。我将首先介绍非平衡回归问题的背景(与非平衡分类相比)，以及目前的一些研究现状。那我就介绍一下我们的思路和方法，省略不必要的细节。</p><h1 id="97f5" class="mw mx jf bd my mz na nb nc nd ne nf ng ku nh kv ni kx nj ky nk la nl lb nm nn bi translated">背景和动机</h1><p id="3866" class="pw-post-body-paragraph ld le jf lf b lg no kp li lj np ks ll lm nq lo lp lq nr ls lt lu ns lw lx ly ij bi translated">数据不平衡在现实世界中是普遍存在和固有的。数据不是在每个类别上保持理想的均匀分布，而是经常呈现带有长尾的偏斜分布，其中某些目标值的观察值明显较少。这种现象给深度识别模型带来了巨大的挑战，并激发了许多解决数据不平衡的现有技术。</p><p id="24cc" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">特别是过去的解决方案大致可以分为<em class="lz">基于数据的</em>和<em class="lz">基于模型的</em>解决方案。基于数据的解决方案要么对少数类进行过采样，要么对多数类进行欠采样，例如SMOTE算法，该算法通过对同一类中的样本进行线性插值来为少数类生成合成样本。基于模型的解决方案包括重新加权、调整损失函数和利用相关的学习范式，如迁移学习、元学习和两阶段训练。更详细的回顾可以在我的<a class="ae ma" rel="noopener" target="_blank" href="/struggling-with-data-imbalance-semi-supervised-self-supervised-learning-help-4de8b8f23490">上一篇文章</a>中找到。</p><p id="d432" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">然而，现有的从不平衡数据中学习的解决方案集中在具有<strong class="lf jp">分类指数</strong>的目标上，基本上目标是<strong class="lf jp">不同的类别</strong>。例如，下图显示了一个用于地点分类的典型真实数据集，该数据集是不平衡的，具有长尾标注分布，并且标注是不同的类，例如住宅、森林和博物馆。类似地，一个用于物种分类的现实世界不平衡数据集，称为iNaturalist，目标也是分类的，并且具有硬边界，不同类别之间没有重叠。</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nt"><img src="../Images/58a2175eb2d6d146a0b7d278f9f361f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NinyOsvDZwEWDoAS5lSSTA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">现有的不平衡学习方案主要针对具有类别索引的目标。目标具有硬边界，不同类别之间没有重叠。(图片由作者提供)</p></figure><p id="d1c1" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">然而，许多现实世界的任务可能涉及<strong class="lf jp">连续</strong>，有时甚至<strong class="lf jp">无限</strong>的目标值。例如，在视觉应用中，人们经常需要根据不同人的视觉外观来推断他们的年龄。在这里，年龄是一个连续的目标，在整个目标范围内可能是高度不平衡的。例如，这里有一个真实世界的年龄估计数据集，它在不同年龄之间有一个倾斜的标签分布。在这种情况下，将不同的年龄视为不同的阶层不太可能产生最好的结果，因为它没有利用年龄相近的人之间的相似性<em class="lz">。</em></p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ny"><img src="../Images/55451ddf898773884d789e1038223dc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9men4xRJcBAihk_74cQ3gA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">左图:一个计算机视觉应用程序，我们根据不同人的视觉外观来推断他们的年龄。右图:大规模年龄估计数据集IMDB-WIKI在不同年龄之间存在偏态标签分布。(图片由作者提供)</p></figure><p id="626f" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">类似的问题也发生在医疗应用中，我们希望推断患者人群中不同的健康指标，如心率、血压和氧饱和度。这些指标也是连续的，并且通常在患者人群中有偏斜的分布。</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nz"><img src="../Images/200eff148c1545dc0d29eb3e184ca10b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KKJbJxjTGN3E2qJ7KrovHQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">不平衡回归问题在医疗保健领域也很常见。左图:大多数健康指标，如心率、血压和氧饱和度，都是连续的目标，通常在患者群体中高度不平衡。右图:真实世界数据集SHHS的健康状况评分的偏态标签分布。(图片由作者提供)</p></figure><p id="7500" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">此外，许多重要的现实世界应用(如经济学、危机管理、故障诊断或气象学等。)也有类似的要求。在这些应用中需要预测的连续目标变量往往有许多罕见的极值。这种连续域中的不平衡问题在线性和深度模型中都存在。在深度模式下更为严重。这是为什么呢？因为神经网络预测往往过于自信，而这种数据失衡问题被严重放大。</p><p id="06c7" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">因此，在这项工作中，我们定义并研究了<em class="lz">深度不平衡回归(DIR) </em>，从这种具有连续目标的不平衡数据中学习。具体而言，给定具有连续目标值的数据集，DIR旨在从这种具有不平衡和偏斜分布的数据中学习，处理某些目标区域的潜在缺失数据，并推广到整个支持的目标范围。特别是，我们感兴趣的是推广到在连续目标值的整个范围内平衡的测试集，这为DIR提供了全面和无偏见的评估。这也符合不平衡分类的设置。</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oa"><img src="../Images/039e59cd1d72b379510176d07d992bfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*mpAXXQGtkxDfNG76X_tF-w.gif"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">深度不平衡回归(DIR)旨在从具有连续目标的不平衡数据中学习，处理某些区域的潜在缺失数据，并推广到整个目标范围。(图片由作者提供)</p></figure><h1 id="d93f" class="mw mx jf bd my mz na nb nc nd ne nf ng ku nh kv ni kx nj ky nk la nl lb nm nn bi translated">不平衡回归的挑战</h1><p id="e582" class="pw-post-body-paragraph ld le jf lf b lg no kp li lj np ks ll lm nq lo lp lq nr ls lt lu ns lw lx ly ij bi translated">然而，我们注意到，DIR带来了不同于其分类对应物的新挑战。</p><p id="afa6" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf jp"> (I) </strong>首先，给定连续且潜在无限的目标值，<strong class="lf jp">类之间的硬边界不再存在</strong>。当直接应用诸如重新采样和重新加权的传统不平衡分类方法时，这可能导致模糊。</p><p id="152c" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf jp"> (II) </strong>此外，<strong class="lf jp">连续标签固有地拥有目标之间有意义的距离</strong>，这暗示了我们应该如何解释连续设置中的数据不平衡。例如，假设有两个目标标签<em class="lz"> t1 </em>和<em class="lz"> t2 </em>，它们在训练数据中都有同样少量的观察值。然而，<em class="lz"> t1 </em>处于高代表邻域，如图所示其邻域范围内样本较多，而<em class="lz"> t2 </em>处于弱代表邻域。在这种情况下，<em class="lz"> t1 </em>不会遭受与<em class="lz"> t2 </em>相同水平的不平衡。</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ob"><img src="../Images/eeb47020f7f20207ddd818672607799b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iRwZFy2UkgC5pVzOarsRxw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">连续标记固有地拥有目标之间有意义的距离，这暗示了我们应该如何解释连续设置中的数据不平衡。例如，即使t1和t2具有相同数量的观察值，t1也不会遭受与t2相同程度的不平衡。(图片由作者提供)</p></figure><p id="4a57" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf jp"> (III) </strong>最后，与分类问题不同，在DIR中，<strong class="lf jp">某些目标值可能根本没有数据</strong>，这也激发了对目标<strong class="lf jp">外推</strong>和<strong class="lf jp">插值</strong>的需求。</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oc"><img src="../Images/794a33c0bb96d1d00301216ba1ad7882.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FV1QWFlBz6kz2sPpYCgtaw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">在不平衡回归中，某些目标值可能根本没有数据，这也激发了对目标外推和内插的需求。(图片由作者提供)</p></figure><p id="caa1" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">综上所述，与传统的不平衡分类相比，DIR有着新的困难和挑战。那么，应该如何进行深度不平衡回归呢？在接下来的两个部分中，我们提出了两种简单有效的方法，分别是标签分布平滑(LDS)和特征分布平滑(FDS ),通过利用在<strong class="lf jp">标签空间</strong>和<strong class="lf jp">特征空间</strong>中附近目标之间的相似性。</p><h1 id="f892" class="mw mx jf bd my mz na nb nc nd ne nf ng ku nh kv ni kx nj ky nk la nl lb nm nn bi translated">标签分布平滑(LDS)</h1><p id="9aab" class="pw-post-body-paragraph ld le jf lf b lg no kp li lj np ks ll lm nq lo lp lq nr ls lt lu ns lw lx ly ij bi translated">我们首先展示一个例子来说明当不平衡出现时分类和回归之间的区别。</p><p id="0f9b" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf jp">激励示例</strong>:我们采用了两个不同的数据集，(1) CIFAR100，这是一个100类分类数据集，以及(2)IMD b-WIKI数据集，这是一个大规模图像数据集，用于根据视觉外观进行年龄估计。这两个数据集具有本质上不同的标签空间:CIFAR-100展示了<strong class="lf jp">分类标签空间</strong>，其中目标是类别索引，而IMDB-WIKI具有<strong class="lf jp">连续标签空间</strong>，其中目标是年龄。我们将年龄范围限制为0~99，以便两个数据集具有相同的标签范围。此外，我们对两个数据集进行二次抽样，以模拟数据不平衡，同时确保它们具有完全相同的标签密度分布。我们使两个测试集平衡。</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi od"><img src="../Images/5415decacfc0cd24d1ff32bf2ec95ed0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n3kOUlFBipwe0swuWIMSDw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">(图片由作者提供)</p></figure><p id="99bb" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">然后，我们在两个数据集上训练一个简单的ResNet-50模型，并绘制它们的测试误差分布。如第一幅图所示，在CIFAR-100上，我们观察到<strong class="lf jp">误差分布实际上与标签密度分布</strong>相关。具体而言，作为类别索引函数的测试误差与分类标签空间中的标签密度分布(即0.76)具有高度负皮尔逊相关性。这种现象是意料之中的，因为拥有更多样本的多数班比少数班学得更好。</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oe"><img src="../Images/afc95d1abdb4b5820cd5128e8353b354.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5JKAFzI_yHkmVqjy0jsnCw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">(图片由作者提供)</p></figure><p id="ef4f" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">然而有趣的是，IMDB-WIKI的误差分布非常不同，它具有<strong class="lf jp">连续的</strong>标签空间，即使标签密度分布与CIFAR-100相同。特别是，误差分布更加平滑，并且<strong class="lf jp">不再与</strong>和标签密度分布(0.47)相关。</p><p id="da4a" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">这种现象表明，对于连续标签，经验标签密度不能准确反映模型或神经网络所看到的不平衡。因此，在连续的情况下，经验标签分布不能反映真实的标签密度分布。这是因为邻近标签处的数据样本之间的相关性(例如，接近年龄的图像)。</p><p id="3d6a" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf jp">标签分布平滑(LDS) </strong>:事实上，在统计学中有一个重要的文献是关于在这种情况下如何估计期望密度的。因此，标签分布平滑(LDS)提倡使用核密度估计来学习对应于连续目标的数据集中的有效不平衡。给定连续的经验标签密度分布，LDS将对称核<em class="lz"> k </em>与经验密度分布卷积，以提取核平滑版本，该版本考虑了附近标签的数据样本的信息重叠。由LDS计算得到的有效标签密度分布与现在的误差分布有很好的相关性，Pearson相关系数为0.83。这表明LDS抓住了影响回归问题的真正不平衡。</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oa"><img src="../Images/9099aff85b9bb33449d36083af055976.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*D2lR6XiPEfmes-2qNWydZQ.gif"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">(图片由作者提供)</p></figure><p id="b08b" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">既然有效标签密度是可用的，用于解决类不平衡问题的技术可以直接适用于DIR上下文。例如，一种直接的适应可以是成本敏感的重新加权方法，其中我们通过将损失函数乘以每个目标的LDS估计标签密度的倒数来重新加权损失函数。</p><h1 id="2454" class="mw mx jf bd my mz na nb nc nd ne nf ng ku nh kv ni kx nj ky nk la nl lb nm nn bi translated">特征分布平滑(FDS)</h1><p id="bf38" class="pw-post-body-paragraph ld le jf lf b lg no kp li lj np ks ll lm nq lo lp lq nr ls lt lu ns lw lx ly ij bi translated">我们已经证明了可以有效地利用标签空间中的连续性来寻址DIR。我们进一步受到直觉的激励，即目标空间中的<strong class="lf jp">连续性应该在特征空间</strong>中产生相应的连续性。也就是说，如果模型工作正常并且数据平衡，人们期望对应于附近目标的<strong class="lf jp">特征统计</strong>彼此接近。同样，我们用一个说明性的例子来强调数据不平衡对DIR中特征统计的影响。</p><p id="54fd" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf jp">激励示例</strong>:同样，我们使用在IMDB-WIKI数据集中的图像上训练的简单模型来从视觉外观推断一个人的年龄。我们关注已学习的特征空间，即图中的<em class="lz"> z </em>。我们为标签空间引入了一个额外的结构来进行分析，其中我们将它分成具有相等间隔的仓。我们使用<em class="lz"> b </em>来表示目标值的组索引。这里，在年龄估计中，箱的长度被定义为1，表示感兴趣的最小年龄差为1。现在，使用这种结构，我们将具有相同目标值的要素分组到相同的条柱中。然后，我们针对每个箱中的数据计算特征统计量(即，<strong class="lf jp">均值</strong>和<strong class="lf jp">方差</strong>)。</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi of"><img src="../Images/67ef50af59891ada0aee508d514f9cb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mkOarFIWfU0WOTGaVSALig.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">(图片由作者提供)</p></figure><p id="fffa" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">现在我们准备好可视化特征统计之间的相似性。首先，我们选择一个锚仓，表示为<em class="lz"> b0 </em>，并且我们有这个锚仓的特征统计。此外，我们还计算了其他面元的统计量，最后，我们计算了<em class="lz"> b0 </em>和所有其他面元之间的特征统计量的<strong class="lf jp">余弦相似度</strong>，并汇总了锚年龄的结果，如下图所示为30。该图还使用紫色、黄色和粉红色显示了具有不同数据密度的区域。</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oa"><img src="../Images/0ec996f2efb6af0f9512468419fc5878.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*fCpLbndIVrr1cUZmgL3d7Q.gif"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">(图片由作者提供)</p></figure><p id="c9de" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">有趣的是，我们发现锚仓周围的特征统计与它们在锚仓的值高度相似。具体来说，25至35岁之间的所有箱的<em class="lz">特征均值</em>和<em class="lz">特征方差</em>的余弦相似性与它们在30岁(锚年龄)时的值相差几个百分点。我们注意到仓30处的锚年龄落在多次拍摄区域中。因此，该图证实了当有足够数据时<strong class="lf jp">的直觉，并且对于连续目标，特征统计类似于附近的面元</strong>。</p><p id="0d7c" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">然而，有趣的是，该图还显示了数据样本非常少的地区的问题，如年龄范围为0至6岁的地区。请注意，这个范围内的平均值和方差显示出与30岁时出乎意料的高相似性。<strong class="lf jp">这种不合理的相似性是由于数据不平衡</strong>。具体来说，由于没有足够的0到6岁的图像，因此该范围从具有最大数据量的范围(大约30岁的范围)继承其先验。</p><p id="0bd7" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf jp">特征分布平滑(FDS) </strong>:受这些观察的启发，我们提出了特征分布平滑(FDS)，它在特征空间上执行分布平滑，基本上在附近的目标箱之间转移特征统计。该程序旨在校准特征分布<em class="lz">的潜在有偏估计，尤其是针对代表性不足的目标</em>。因此，我们有了一个将输入数据映射到连续预测的模型。现在，通过首先估计每个箱的统计来执行FDS。不失一般性，我们用协方差代替方差来反映<em class="lz"> z </em>内特征元素之间的关系。给定特征统计，我们再次采用对称核<em class="lz"> k </em>来平滑特征<strong class="lf jp">均值</strong>和<strong class="lf jp">协方差</strong>在目标仓上的分布。这导致统计数据的平滑版本。现在，有了估计和平滑的统计数据，我们就可以按照标准的<strong class="lf jp">白化和重着色</strong>过程来校准每个输入样本的特征表示。通过在最终特征地图后插入一个<strong class="lf jp">特征校准层</strong>，FDS的整个管道被集成到深度网络中。最后，为了在训练期间获得特征统计的更稳定和准确的估计，我们采用跨每个时期的运行统计的动量更新。</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi og"><img src="../Images/de8597a016b591d0e20c7fd909876497.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*EBhGDrOZUyHblJ3djV9qYg.gif"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">(图片由作者提供)</p></figure><p id="e589" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们注意到，FDS可以与任何神经网络模型相结合，以及任何过去在改善标签不平衡方面的工作。</p><h1 id="226b" class="mw mx jf bd my mz na nb nc nd ne nf ng ku nh kv ni kx nj ky nk la nl lb nm nn bi translated">基准DIR数据集和实验</h1><p id="8a25" class="pw-post-body-paragraph ld le jf lf b lg no kp li lj np ks ll lm nq lo lp lq nr ls lt lu ns lw lx ly ij bi translated">为了支持不平衡回归方法的实际评估，并促进未来的研究，我们策划了五个DIR基准，涵盖<strong class="lf jp">计算机视觉</strong>、<strong class="lf jp">自然语言处理</strong>和<strong class="lf jp">医疗保健</strong>。它们从单值预测(如年龄、文本相似性得分、健康状况得分)到密集值预测(如深度)不等。</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oh"><img src="../Images/7e44267aba022fe7d585a67da82874ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*67EvgwarPJghnaSkrwSrVw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">策划了五个基准DIR数据集。(图片由作者提供)</p></figure><ul class=""><li id="e8f1" class="mi mj jf lf b lg lh lj lk lm mk lq ml lu mm ly mn mo mp mq bi translated"><strong class="lf jp"> IMDB-WIKI-DIR (vision，age) </strong>:第一个叫做IMDB-WIKI-DIR，包含人脸图像和对应的年龄，用于年龄估计。我们使验证和测试集达到平衡。</li><li id="a70d" class="mi mj jf lf b lg mr lj ms lm mt lq mu lu mv ly mn mo mp mq bi translated"><strong class="lf jp"> AgeDB-DIR(视力，年龄)</strong>:类似地，第二个数据集，称为AgeDB-DIR，也是根据单个输入图像的年龄估计。请注意，AgeDB-DIR的标签分布不同于IMDB-WIKI-DIR，即使它们展示了相同的任务。</li><li id="2006" class="mi mj jf lf b lg mr lj ms lm mt lq mu lu mv ly mn mo mp mq bi translated"><strong class="lf jp"> NYUD2-DIR (vision，depth) </strong>:此外，尽管是单个目标值预测，我们也采用NYU2数据集进行深度估计，这是一个密集值预测任务，并为不平衡回归评估建立NYUD2-DIR数据集。</li><li id="6735" class="mi mj jf lf b lg mr lj ms lm mt lq mu lu mv ly mn mo mp mq bi translated"><strong class="lf jp"> STS-B-DIR (NLP，文本相似度得分)</strong>:我们还构造了一个NLP领域的DIR基准，叫做STS-B-DIR。任务是推断两个输入句子之间的语义文本相似度得分。分数在0到5的范围内是连续的，并且具有不平衡的分布。</li><li id="627a" class="mi mj jf lf b lg mr lj ms lm mt lq mu lu mv ly mn mo mp mq bi translated"><strong class="lf jp"> SHHS-DIR(医疗保健，健康状况评分)</strong>:最后，我们在医疗保健领域创建了一个DIR基准，称为SHHS-DIR。任务是推断一个总的健康分数，该分数在0到100之间连续分布，分数越高，健康状况越好。输入是每个患者在整个晚上睡眠期间的高维多导睡眠图信号，包括ECG信号、EEG信号和呼吸信号。如图所示，分数分布也不均衡。</li></ul><p id="9c58" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">所有的数据和模型都在<a class="ae ma" href="https://github.com/YyzHarry/imbalanced-regression" rel="noopener ugc nofollow" target="_blank"> <strong class="lf jp">我们的GitHub repo </strong> </a>开源。在评估过程中，我们在平衡的测试集上评估每种方法的性能。我们进一步将目标空间分成几个不相交的子集:多镜头、中镜头和少镜头区域，反映训练数据中不同数量的样本。对于基线，由于文献中只有一些关于DIR的建议，除了过去使用合成样本的非平衡回归工作，我们采用了一些非平衡回归分类方法，并提出了<em class="lz">一组强基线</em>(有关更多详细信息，请参考<a class="ae ma" href="https://arxiv.org/abs/2102.09554" rel="noopener ugc nofollow" target="_blank">我们的论文</a>)。</p><p id="d231" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf jp">实验</strong>:由于实验较多，这里只展示IMDB-WIKI-DIR上有代表性的结果(所有结果请参考<a class="ae ma" href="https://arxiv.org/abs/2102.09554" rel="noopener ugc nofollow" target="_blank">论文</a>)。我们首先根据使用的基本策略将不同的方法分为4个部分。在每个组中，我们进一步将LDS、FDS以及LDS和FDS的组合应用于基线方法。最后，我们报告了LDS+FDS相对于普通模型的绝对改进。如表所示，无论使用哪种基础训练技术，LDS和FDS都取得了显著的成绩。特别是，对于少炮区域，我们可以通过<strong class="lf jp">获得比基线模型</strong>多40%的相对改进。</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oi"><img src="../Images/68e44932e45e1aea709186578fc8f00e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6q3TZ3szsf-ac0ZjZwggNg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">(图片由作者提供)</p></figure><p id="f337" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf jp">理解FDS </strong>的分析:我们仔细看看FDS，分析它是如何影响网络训练的。类似于之前的设置，我们绘制锚年龄为0的特征统计相似性。如图所示，由于目标箱0中的样本非常少，特征统计可能具有较大的偏差，即年龄0与区域40≁80具有较大的相似性。相比之下，当添加FDS时，统计数据得到更好的校准，导致仅在其邻域中具有高相似性，并且随着目标值变大，相似性得分逐渐降低。我们在训练期间进一步可视化运行统计和平滑统计之间的L1距离。有趣的是，随着训练的进行，平均L1距离<strong class="lf jp">变得越来越小，并逐渐减少</strong>。这表明模型学习生成即使没有平滑也更准确的特征，并且最终可以在推断期间移除平滑模块。</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ob"><img src="../Images/d2bea387aa99a386b917bdb0db5b76ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lKMRsmHyF0PJ2h0DR9sqZw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">(图片由作者提供)</p></figure><p id="764a" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf jp">外推分析&amp;插值</strong>:最后，在现实世界的DIR任务中，某些目标值<strong class="lf jp">可以根本没有数据</strong>。例如，回想一下SHHS-DIR和STS-B-DIR基准测试中的标签分布。这激发了对目标外推和内插的需求。我们从IMDB-WIKI-DIR的训练集中筛选出几个子集，这些子集在某个区域没有训练数据，但是在原始测试集上进行评估，用于零镜头泛化分析。这里，我们将我们的方法相对于普通模型的绝对MAE增益可视化。如上所述，我们的方法提供了对多、中、少以及零触发区域的综合处理，在整个频谱上实现了显著的性能增益，并且对不同的不平衡标签分布是鲁棒的。</p><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oj"><img src="../Images/f04a8152175d5ac1ab6626c97b59648f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QN5k-727ngR-6l6Cze6KHA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">(图片由作者提供)</p></figure><h1 id="4b16" class="mw mx jf bd my mz na nb nc nd ne nf ng ku nh kv ni kx nj ky nk la nl lb nm nn bi translated">结束语</h1><p id="cbee" class="pw-post-body-paragraph ld le jf lf b lg no kp li lj np ks ll lm nq lo lp lq nr ls lt lu ns lw lx ly ij bi translated">在这篇文章的结尾，我们提出了(1)一个称为深度不平衡回归的<strong class="lf jp">新任务</strong>，和(2) <strong class="lf jp">新技术</strong>，标签分布平滑和特征分布平滑，以解决具有连续目标的学习不平衡数据，和(3)五个<strong class="lf jp">新基准</strong>以促进未来的研究。也请查看我们的代码、数据和论文。感谢您的聆听。我们的工作填补了实际不平衡回归问题的基准和技术的空白。这些结果可能会引起更广泛的不同应用领域的兴趣。最后，我附上了几个与本文相关的链接；感谢阅读！</p><p id="c8b9" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf jp">代码</strong>:<a class="ae ma" href="https://github.com/YyzHarry/imbalanced-regression" rel="noopener ugc nofollow" target="_blank">https://github.com/YyzHarry/imbalanced-regression</a></p><p id="85d5" class="pw-post-body-paragraph ld le jf lf b lg lh kp li lj lk ks ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf jp">项目页面</strong>:http://dir.csail.mit.edu/<a class="ae ma" href="http://dir.csail.mit.edu/" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>