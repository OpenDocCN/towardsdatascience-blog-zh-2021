<html>
<head>
<title>Identifying Outliers in Linear Regression — Cook’s Distance</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">识别线性回归中的异常值——库克距离</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/identifying-outliers-in-linear-regression-cooks-distance-9e212e9136a?source=collection_archive---------1-----------------------#2021-05-15">https://towardsdatascience.com/identifying-outliers-in-linear-regression-cooks-distance-9e212e9136a?source=collection_archive---------1-----------------------#2021-05-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1b1b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">库克距离是什么，它如何帮助您识别和移除数据集中的异常值？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/2b7b42463b27d1adf66b17844e9f395a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rL6f_nj2tegNp8rM"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">尼克·吉奥在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="3862" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有许多技术可以从数据集中移除异常值。回归设置中经常使用的一种方法是库克距离。库克距离是对一个数据点影响力的估计。它考虑了每个观察值的杠杆作用和残差。库克距离是当第一个<em class="ls">观察值被移除时，回归模型变化程度的总结。</em></p><p id="72ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当查看哪些观察值可能是异常值时，一般的经验法则是调查所有距离的平均值大于3 <em class="ls"> x </em>的任何点(<em class="ls">注意:还有其他几个常用的标准</em>)。我将展示一个例子，说明这是如何与来自<em class="ls"> ISLR </em>库的一个著名数据集Hitters一起工作的。Hitters数据集包含250多名棒球运动员及其职业统计数据和薪水的信息。</p><p id="f788" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我们将导入数据集:</p><pre class="kg kh ki kj gt lt lu lv lw aw lx bi"><span id="4555" class="ly lz iq lu b gy ma mb l mc md">library(ISLR)</span><span id="828c" class="ly lz iq lu b gy me mb l mc md">Hitters &lt;- na.omit(Hitters)<br/>glimpse(Hitters)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mf"><img src="../Images/5788ba896412d8aa318905441b4107e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cTMz9c1UqiqHDkzWrQey7w.png"/></div></div></figure><p id="f81f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们将使用所有可用的功能初始化一个多元线性回归模型，目标是预测球员的工资。</p><pre class="kg kh ki kj gt lt lu lv lw aw lx bi"><span id="9037" class="ly lz iq lu b gy ma mb l mc md">model &lt;- lm(Salary ~ ., data = Hitters)<br/>summary(model)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mg"><img src="../Images/6ee3a659fb064eb4a4c5b73a4fedc9b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*PzlrppPF8R_QG1Xp0-qjag.png"/></div></div></figure><p id="5f3b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们看到基线模型的调整后R平方为0.5106。现在，让我们看看诊断图:</p><pre class="kg kh ki kj gt lt lu lv lw aw lx bi"><span id="49c3" class="ly lz iq lu b gy ma mb l mc md">par(mfrow = c(2, 2))<br/>plot(model)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mh"><img src="../Images/8aa603dba3a7134d495bda984381c337.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4pYo-_-1S8yRK24i74RLrw.jpeg"/></div></div></figure><p id="b16d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在查看诊断图时，我们看到确实有一些异常值(在其他问题中，如异方差)。如果你看看右下角的图，<em class="ls">残差对杠杆</em>，你会发现一些异常值也有一些重要的杠杆。举例来说，我们希望从数据集中移除这些异常值，以便我们可以拟合更好的模型。我们如何做到这一点？我们可以在刚刚运行的模型上使用<em class="ls"> cooks.distance </em>函数，然后过滤掉任何大于平均值3 <em class="ls"> x </em>的值。让我们先来看看有多少观察符合这个标准:</p><pre class="kg kh ki kj gt lt lu lv lw aw lx bi"><span id="8544" class="ly lz iq lu b gy ma mb l mc md">cooksD &lt;- cooks.distance(model)<br/>influential &lt;- cooksD[(cooksD &gt; (3 * mean(cooksD, na.rm = TRUE)))]<br/>influential</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mi"><img src="../Images/732d29103987e6c8e309a9cf108a9293.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-KvxO6oiC_QdNjkehdHGww.png"/></div></div></figure><p id="1598" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们看到18个玩家的库克距离大于平均值的3倍。让我们排除这些玩家，重新运行模型，看看我们是否有更好的拟合。</p><pre class="kg kh ki kj gt lt lu lv lw aw lx bi"><span id="abb0" class="ly lz iq lu b gy ma mb l mc md">names_of_influential &lt;- names(influential)<br/>outliers &lt;- Hitters[names_of_influential,]<br/>hitters_without_outliers &lt;- Hitters %&gt;% anti_join(outliers)</span><span id="fe05" class="ly lz iq lu b gy me mb l mc md">model2 &lt;- lm(Salary ~ ., data = hitters_without_outliers)<br/>summary(model2)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mg"><img src="../Images/21fc5aab06255fb4c80e6bb0abb6365c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*zHzz-js77q2pPE3FqtCjSg.png"/></div></div></figure><p id="2654" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的模型拟合度大幅提高。我们已经从0.5106的调整后R平方提高到0.6445，仅去除了18个观察值。这证明了异常值在回归模型中的影响有多大。让我们来看看新模型的诊断图:</p><pre class="kg kh ki kj gt lt lu lv lw aw lx bi"><span id="100f" class="ly lz iq lu b gy ma mb l mc md">par(mfrow = c(2, 2))<br/>plot(model2)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mj"><img src="../Images/224bd38c0276eb9ad2f2130fbcc363de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sILTiibKu_Op570Cs_2S1Q.jpeg"/></div></div></figure><p id="8c3a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与我们以前的诊断图相比，这些图有了很大的改进。再次查看<em class="ls">残差与杠杆率</em>图，我们看到没有任何剩余的点具有显著的杠杆率，从而更适合我们的模型。</p><p id="5ad9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的例子只是为了演示。在没有对有问题的点进行深入彻底的分析的情况下，永远不要仅仅删除离群值。此外，这样做可能会导致对训练数据的良好拟合，但对看不见的数据的预测较差。</p><p id="2c1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">库克的距离是一个很好的工具，添加到您的回归分析工具箱！您现在有了一个有意义的方法来调查模型中的异常值。快乐造型！</p><h1 id="5ce0" class="mk lz iq bd ml mm mn mo mp mq mr ms mt jw mu jx mv jz mw ka mx kc my kd mz na bi translated">谢谢大家的支持！</h1><p id="e672" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">感谢您阅读本文！如果你觉得有帮助，请给我一两下掌声:)</p></div></div>    
</body>
</html>