<html>
<head>
<title>Statistical Tests for Comparing Classification Algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于比较分类算法的统计测试</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/statistical-tests-for-comparing-classification-algorithms-ac1804e79bb7?source=collection_archive---------6-----------------------#2021-11-23">https://towardsdatascience.com/statistical-tests-for-comparing-classification-algorithms-ac1804e79bb7?source=collection_archive---------6-----------------------#2021-11-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ec94" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">回顾开创性的论文和实施，为您的数据找到最佳选择</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/992d77e799e0522e899670e31f1f9b44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*I-SLE9ea8huwnVwC"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@lxrcbsv?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">алексарцибашев</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="11d9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对大多数数据科学家来说，比较预测方法以确定哪种方法应该用于手头的任务是一项日常活动。通常，人们会有一个分类模型池，并使用交叉验证来验证它们，以确定哪一个是最好的。</p><p id="e01d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，另一个目标不是比较分类器，而是学习算法本身。这个想法是:给定这个任务(数据)，哪种学习算法(KNN，SVM，随机森林等)将在大小为D的数据集上生成更准确的分类器？</p><p id="58c8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如我们将看到的，这里介绍的每种方法都有一些优点和缺点。然而，使用两个比例测试的第一直觉会导致一些非常糟糕的结果。</p><p id="f392" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了更多地了解我们如何比较这些算法，并提高我们的统计知识，今天我将解释和实现来自用于比较监督分类学习算法的<a class="ae kv" href="https://direct.mit.edu/neco/article-abstract/10/7/1895/6224/Approximate-Statistical-Tests-for-Comparing" rel="noopener ugc nofollow" target="_blank">近似统计测试</a> [1]的方法，这是一篇关于该领域的开创性论文。</p><p id="f670" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在接下来的部分中，我将描述每个测试，讨论它的优点和缺点，实现它们，然后将结果与可用的实现进行比较。</p><p id="085d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章的笔记本可以在<a class="ae kv" href="https://www.kaggle.com/tiagotoledojr/statistical-tests-for-comparing-classfiers" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>和我的<a class="ae kv" href="https://github.com/TNanukem/paper_implementations/blob/main/Approximate%20Statistical%20Tests%20for%20Comparing%20Supervised%20Classification%20Learning%20Algorithms.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。</p><h1 id="bdb2" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">初始代码设置</h1><p id="03b5" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">对于本文中的代码，我们将使用两种分类算法:KNN和随机森林来预测葡萄酒数据集[2]上的葡萄酒质量，该数据集来自UCI机器学习库，可在sklearn包中免费获得。为此，我们将导入一些必需的库，并将实例化算法:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="e7a8" class="mu lt iq mq b gy mv mw l mx my"># Importing the required libs<br/>import numpy as np<br/>import pandas as pd<br/><br/>from tqdm import tqdm<br/>from scipy.stats import norm, chi2<br/>from scipy.stats import t as t_dist<br/>from sklearn.datasets import load_wine<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.model_selection import train_test_split, KFold<br/><br/><em class="mz"># Libs implementations</em><br/>from mlxtend.evaluate import mcnemar<br/>from mlxtend.evaluate import mcnemar_table<br/>from mlxtend.evaluate import paired_ttest_5x2cv<br/>from mlxtend.evaluate import proportion_difference<br/>from mlxtend.evaluate import paired_ttest_kfold_cv<br/>from mlxtend.evaluate import paired_ttest_resampled</span><span id="60ef" class="mu lt iq mq b gy na mw l mx my"># Getting the wine data from sklearn<br/>X, y = load_wine(return_X_y = True)</span><span id="51e2" class="mu lt iq mq b gy na mw l mx my"># Instantiating the classification algorithms<br/>rf = RandomForestClassifier(random_state=42)<br/>knn = KNeighborsClassifier(n_neighbors=1)</span><span id="e775" class="mu lt iq mq b gy na mw l mx my"><em class="mz"># </em>For holdout cases<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)</span></pre><h1 id="5205" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">两比例检验</h1><p id="9bd6" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">比较两个比例是一个非常古老的问题，统计学有一个经典的假设检验来解决这个问题:给定两个人口的两个比例，零假设是两个比例之差的均值等于零。</p><p id="66f1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以用下面的统计数据来计算:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/7d5af2ebd8f18b990b29d8492dd375f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/format:webp/1*NCskR-PAbbjj5yRqEihijQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">两比例检验统计量</p></figure><p id="9113" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">看起来很简单，对吧？我们只是得到我们算法的命中比例(准确率)并进行比较。然而，这个测试有一个重要的假设:样本的独立性。</p><p id="bb41" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可以很快猜到，这里的样本不是独立的，因为两种算法的测试集和训练集是相同的。所以这个假设是错误的。</p><p id="844f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种方法还有另外两个问题:</p><ul class=""><li id="8b24" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nh ni nj nk bi translated">它没有考虑测试集的方差。如果我们改变它，我们可能会有非常不同的结果</li><li id="3b07" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">它不考虑整个数据集，而是考虑被选择用于训练的一个较小的数据集</li></ul><p id="65be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要使用该测试，可以使用以下代码:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="c50f" class="mu lt iq mq b gy mv mw l mx my"># First we fit the classification algorithms<br/>rf.fit(X_train, y_train)<br/>knn.fit(X_train, y_train)</span><span id="c797" class="mu lt iq mq b gy na mw l mx my"># Generate the predictions<br/>rf_y = rf.predict(X_test)<br/>knn_y = knn.predict(X_test)</span><span id="7f71" class="mu lt iq mq b gy na mw l mx my"># Calculate the accuracy<br/>acc1 = accuracy_score(y_test, rf_y)<br/>acc2 = accuracy_score(y_test, knn_y)</span><span id="cb95" class="mu lt iq mq b gy na mw l mx my"># Run the test<br/>print("Proportions Z-Test")<br/>z, p = proportion_difference(acc1, acc2, n_1=len(y_test))<br/>print(f"z statistic: <strong class="mq ir">{</strong>z<strong class="mq ir">}</strong>, p-value: <strong class="mq ir">{</strong>p<strong class="mq ir">}\n</strong>")</span></pre><p id="16ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，我们只是在拒不接受的测试集上拟合算法，并对结果精度进行测试。</p><h1 id="74d0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">重采样配对t检验</h1><p id="a02c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">为了说明测试集的方差，可以使用重采样的配对t检验。在这个测试中，我们将设置一些试验(例如30次),并使用维持测试集在每次试验中测量每个算法的准确性。</p><p id="76be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，如果我们假设p_i = pA_i - pB_i，对于每个试验<em class="mz"> i </em>是正态分布的，我们可以应用配对学生的t-检验:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/620eac984c5f462beaa948771a422e97.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*Xo6nO3R9Whpo0LLea7v2tQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">配对t检验统计量</p></figure><p id="79c3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为在每一次试验中，我们都要改变我们的测试集，它的方差被考虑在内，改进了前一次试验中的一个问题。然而，我们手中仍有一些问题:</p><ul class=""><li id="b537" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nh ni nj nk bi translated">p_i的正态分布不成立，因为这些比例不是独立的，因为它们是在同一测试集上计算的</li><li id="e87e" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">每次试验的训练集和测试集之间都有重叠，所以p_i不是独立的</li><li id="baa4" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">它要求我们的算法被拟合多次，如果拟合时间太长，这可能是禁止的</li></ul><p id="dd73" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于这个实现，我们将定义创建一个函数，它将接收p_is作为参数:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="2a9d" class="mu lt iq mq b gy mv mw l mx my">def paired_t_test(p):<br/>    p_hat = np.mean(p)<br/>    n = len(p)<br/>    den = np.sqrt(sum([(diff - p_hat)**2 for diff <strong class="mq ir">in</strong> p]) / (n - 1))<br/>    t = (p_hat * (n**(1/2))) / den<br/>    <br/>    p_value = t_dist.sf(t, n-1)*2<br/>    <br/>    return t, p_value</span></pre><p id="39f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个函数中，我们只是根据等式从测试中创建t统计量。然后，我们使用scipy中学生的t分布来找出测试的p值，然后返回统计数据和p值。</p><p id="8587" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">运行重采样t-test的代码如下:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="9303" class="mu lt iq mq b gy mv mw l mx my">n_tests = 30<br/><br/>p_ = []<br/>rng = np.random.RandomState(42)<br/>for i <strong class="mq ir">in</strong> range(n_tests):<br/>    randint = rng.randint(low=0, high=32767)<br/>    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=randint)<br/>    rf.fit(X_train, y_train)<br/>    knn.fit(X_train, y_train)<br/><br/>    acc1 = accuracy_score(y_test, rf.predict(X_test))<br/>    acc2 = accuracy_score(y_test, knn.predict(X_test))<br/>    p_.append(acc1 - acc2)<br/>    <br/>print("Paired t-test Resampled")<br/>t, p = paired_t_test(p_)<br/>print(f"t statistic: <strong class="mq ir">{</strong>t<strong class="mq ir">}</strong>, p-value: <strong class="mq ir">{</strong>p<strong class="mq ir">}\n</strong>")</span></pre><p id="393f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，我们将迭代次数定义为30次，对于每一次迭代，我们分割数据，拟合分类器，然后计算精确度之间的差异。我们将这个值保存在一个列表中，然后用这个列表调用上面定义的函数。</p><p id="e466" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Mlxtend库已经实现了这个测试，因此也可以使用:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="ecf5" class="mu lt iq mq b gy mv mw l mx my">print("Paired t-test Resampled")<br/>t, p = paired_ttest_resampled(estimator1=rf, estimator2=knn, X=X,y=y, random_seed=42, num_rounds=30, test_size=0.2)<br/>print(f"t statistic: <strong class="mq ir">{</strong>t<strong class="mq ir">}</strong>, p-value: <strong class="mq ir">{</strong>p<strong class="mq ir">}\n</strong>")</span></pre><p id="b028" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，我们必须传递该函数的整个训练集，因为它将在自身内部创建拆分。您可以验证给定相同种子的结果是否相同。</p><h1 id="9e25" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">交叉验证配对t检验</h1><p id="31cf" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">这个方法的结构与上面的方法相同。然而，我们将使用<em class="mz"> K </em>折叠进行交叉验证，而不是在每次试验中使用坚持测试集。</p><p id="b836" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这将消除重叠测试集的问题，因为现在每个样本都将针对不同的数据进行测试。</p><p id="1607" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，我们仍然有重叠的训练数据问题。在10重交叉验证中，每轮训练与其他轮训练共享80%的训练数据。</p><p id="1065" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，我们仍然有一个时间问题，因为我们必须适应我们的分类器几次。然而，通常少于重采样配对t检验，因为通常运行10倍或5倍交叉验证，这比我们以前做的30次检验要小得多。</p><p id="d83f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于这个测试，我们将使用我们在之前的测试中定义的相同函数，因为它无论如何都将是一个t测试，我们只需要改变我们在循环的每次迭代中划分数据的方式(当然，还有循环的迭代次数)。使用sklearn库中的KFold，我们可以:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="7603" class="mu lt iq mq b gy mv mw l mx my">p_ = []<br/><br/>kf = KFold(n_splits=10, shuffle=True, random_state=42)<br/>for train_index, test_index <strong class="mq ir">in</strong> kf.split(X):<br/>    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]<br/>    rf.fit(X_train, y_train)<br/>    knn.fit(X_train, y_train)<br/><br/>    acc1 = accuracy_score(y_test, rf.predict(X_test))<br/>    acc2 = accuracy_score(y_test, knn.predict(X_test))<br/>    p_.append(acc1 - acc2)<br/><br/>print("Cross Validated Paired t-test")<br/>t, p = paired_t_test(p_)<br/>print(f"t statistic: <strong class="mq ir">{</strong>t<strong class="mq ir">}</strong>, p-value: <strong class="mq ir">{</strong>p<strong class="mq ir">}\n</strong>")</span></pre><p id="36fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Mlxtend也有针对此测试的实现:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="e79e" class="mu lt iq mq b gy mv mw l mx my">t, p = paired_ttest_kfold_cv(estimator1=rf, estimator2=knn, X=X, y=y, random_seed=42, shuffle=True, cv=10)<br/>print(f"t statistic: <strong class="mq ir">{</strong>t<strong class="mq ir">}</strong>, p-value: <strong class="mq ir">{</strong>p<strong class="mq ir">}\n</strong>"</span></pre><h1 id="bb79" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">麦克内马试验</h1><p id="32f3" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">这种测试的优点是，我们的每种算法只需要一次拟合。我们使用一个维持集来拟合它们，然后创建一个列联表:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/d80355df05bcf3882bc04a427878f923.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3klAhxUYFnnMidZNQ4sb_Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">麦克纳玛的应急表。由作者开发。</p></figure><p id="69cb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们陈述两种算法应具有相同错误率的零假设，并用以下统计量进行卡方检验:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/cd015f8bb3038aea89daa491da2163ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:486/format:webp/1*EdkIhNFofuRXHHtUbXReXg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">麦克内马检验统计量</p></figure><p id="25ab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在paper benchmarks测试中，与其他测试相比，该测试在错误率方面排名第二，仅次于我们将在下面看到的5x2交叉验证测试。正因为如此，作者说，如果你负担不起交叉验证，就应该使用这种方法。</p><p id="61d9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，这仍然存在问题:</p><ul class=""><li id="2228" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nh ni nj nk bi translated">该测试没有考虑训练集的变化，因为我们只适合一次</li><li id="651e" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">因为我们只适合一次，所以我们不考虑内部算法的变化</li><li id="909b" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">我们使用比原来更小的一套。但是，请注意，这里的每个测试都会受到影响</li></ul><p id="385d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了实现测试，我们将创建一个专用函数:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="62fc" class="mu lt iq mq b gy mv mw l mx my">def mcnemar_test(y_true, y_1, y_2):<br/>    b = sum(np.logical_and((knn_y != y_test),(rf_y == y_test)))<br/>    c = sum(np.logical_and((knn_y == y_test),(rf_y != y_test)))<br/>    <br/>    c_ = (np.abs(b - c) - 1)**2 / (b + c)<br/>    <br/>    p_value = chi2.sf(c_, 1)<br/>    return c_, p_value</span></pre><p id="dbbe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，我们只是计算列联表中的值，看看模型在哪里有正确或不正确的答案。然后，我们查看卡方分布，找出我们计算的统计数据的p值。</p><p id="bc6c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于这使用了维持集，因此以下步骤很简单:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="8496" class="mu lt iq mq b gy mv mw l mx my">print("McNemar's test")<br/>chi2_, p = mcnemar_test(y_test, rf_y, knn_y)<br/>print(f"chi² statistic: <strong class="mq ir">{</strong>chi2_<strong class="mq ir">}</strong>, p-value: <strong class="mq ir">{</strong>p<strong class="mq ir">}\n</strong>")</span></pre><p id="b15d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，还可以使用Mlxtend库中的实现:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="2141" class="mu lt iq mq b gy mv mw l mx my">print("McNemar's test")<br/>table = mcnemar_table(y_target=y_test, y_model1=rf_y, y_model2=knn_y)<br/>chi2_, p = mcnemar(ary=table, corrected=True)<br/>print(f"chi² statistic: <strong class="mq ir">{</strong>chi2_<strong class="mq ir">}</strong>, p-value: <strong class="mq ir">{</strong>p<strong class="mq ir">}\n</strong>")</span></pre><h1 id="3da0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">5x2交叉验证测试</h1><p id="3ce7" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">根据作者的基准测试，这个测试被认为是这5个测试中最好的一个。</p><p id="2ca5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个想法是运行2重交叉验证5次，产生10个不同的估计。然后，我们定义以下比例:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/daef78f8695cce95a76976a88df5d4fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*bTCSDTTMok3E4YCRfTQ1BQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">5x2交叉验证测试参数</p></figure><p id="e9e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后是统计数据:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/9e2948d61302b3dde9189acaabae97cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:410/format:webp/1*F3EZuZJdphINf0P_yfxOuw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">5x2交叉验证测试统计</p></figure><p id="16eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里最大的缺点是我们必须多次调整算法。</p><p id="fada" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该论文对该方法有更全面的描述和推导，所以我建议阅读它以获得全面的理解。</p><p id="cdcd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，为了实现它，我们将创建一个函数:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="127a" class="mu lt iq mq b gy mv mw l mx my">def five_two_statistic(p1, p2):<br/>    p1 = np.array(p1)<br/>    p2 = np.array(p2)<br/>    p_hat = (p1 + p2) / 2<br/>    s = (p1 - p_hat)**2 + (p2 - p_hat)**2<br/>    t = p1[0] / np.sqrt(1/5. * sum(s))<br/>    <br/>    p_value = t_dist.sf(t, 5)*2<br/>    <br/>    return t, p_value</span></pre><p id="316e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，我们只是创建所需的值来计算统计数据，然后像往常一样，查看分布来查找p值。</p><p id="132a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们继续运行双重交叉验证五次:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="ca0b" class="mu lt iq mq b gy mv mw l mx my">p_1 = []<br/>p_2 = []<br/><br/>rng = np.random.RandomState(42)<br/>for i <strong class="mq ir">in</strong> range(5):<br/>    randint = rng.randint(low=0, high=32767)<br/>    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=randint)<br/><br/>    rf.fit(X_train, y_train)<br/>    knn.fit(X_train, y_train)<br/>    acc1 = accuracy_score(y_test, rf.predict(X_test))<br/>    acc2 = accuracy_score(y_test, knn.predict(X_test))<br/>    p_1.append(acc1 - acc2)<br/><br/>    rf.fit(X_test, y_test)<br/>    knn.fit(X_test, y_test)<br/>    acc1 = accuracy_score(y_train, rf.predict(X_train))<br/>    acc2 = accuracy_score(y_train, knn.predict(X_train))<br/>    p_2.append(acc1 - acc2)</span><span id="604e" class="mu lt iq mq b gy na mw l mx my"># Running the test<br/>print("5x2 CV Paired t-test")     <br/>t, p = five_two_statistic(p_1, p_2)<br/>print(f"t statistic: <strong class="mq ir">{</strong>t<strong class="mq ir">}</strong>, p-value: <strong class="mq ir">{</strong>p<strong class="mq ir">}\n</strong>")</span></pre><p id="77c0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还有Mlxtend实现:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="fd16" class="mu lt iq mq b gy mv mw l mx my">print("5x2 CV Paired t-test")<br/>t, p = paired_ttest_5x2cv(estimator1=rf, estimator2=knn, X=X, y=y, random_seed=42)<br/>print(f"t statistic: <strong class="mq ir">{</strong>t<strong class="mq ir">}</strong>, p-value: <strong class="mq ir">{</strong>p<strong class="mq ir">}\n</strong>")</span></pre><p id="5c48" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们在两个实现上都得到了与预期相同的结果。</p><h1 id="4170" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="8d3c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">重要的是要注意，在这种情况下没有银弹。这里提出的每个测试都有一些优点和缺点，它们都是近似值。但是，请注意，在任何情况下都不应该使用两个比例检验。</p><p id="ec7c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">给定所需的时间预算，可以应用所有这些测试并比较它们的结果，以尝试对是否应该使用一类算法或另一类算法做出更好的评估。</p><p id="c4e8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一方面，如果感兴趣的算法可以计算它们的粉碎系数(如SVM、MLP或决策树)，这些测试可以与统计学习理论的结果一起使用，以确定应该使用哪种算法。但这是一个单独的帖子的讨论。</p><p id="aaf2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我强烈建议阅读这篇论文，看看这些基准是如何构建的，它很容易阅读，而且信息量很大。</p><p id="95b2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[1] Thomas G. Dietterich，比较监督分类学习算法的近似统计检验(1998)，<em class="mz">神经计算</em>1998；10 (7): 1895–1923</p><p id="72a5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2]利奇曼(2013年)。https://archive.ics.uci.edu/ml UCI机器学习库<a class="ae kv" href="https://archive.ics.uci.edu/ml" rel="noopener ugc nofollow" target="_blank"/>。加州欧文:加州大学信息与计算机科学学院。</p></div></div>    
</body>
</html>