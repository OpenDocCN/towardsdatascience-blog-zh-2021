<html>
<head>
<title>Shop Order Analysis in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的商店订单分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/shop-order-analysis-in-python-ff13615404e0?source=collection_archive---------15-----------------------#2021-06-15">https://towardsdatascience.com/shop-order-analysis-in-python-ff13615404e0?source=collection_archive---------15-----------------------#2021-06-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0e22" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用Apriori算法进行产品分析</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f089ac8c90e464c97b9405fb46e3b1d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3b4e_depRxgTDnvv"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@_gemmajade?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">杰玛</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="ea2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Apriori算法用于数据挖掘，以识别数据集中的频繁项和关联规则学习。本文将关注一个实用且常见的用例，商店订单分析。例如，订购哪些产品比其他产品更频繁，以及订购哪些不相关的产品是订购另一种产品的结果。换句话说，也许购物者在买牙刷的时候会买牙膏，或者买面包的时候会买黄油。他们没有直接的联系，但是在两者之间找到联系并不是没有道理的。Apriori算法有助于识别这些关联规则。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="7302" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文将提供一个非数学的演练，演示它如何使用Python mlxtend库工作。对于进一步的阅读，我推荐彼得·哈灵顿<strong class="lb iu">的《机器学习在行动</strong> 》中的<strong class="lb iu">第11章</strong>。</p><div class="mc md gp gr me mf"><a href="https://www.manning.com/books/machine-learning-in-action" rel="noopener  ugc nofollow" target="_blank"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">机器学习在行动</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">行动中的机器学习是独特的书，融合了机器学习的基础理论与实践…</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">www.manning.com</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt ks mf"/></div></div></a></div></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="c4ea" class="mu mv it bd mw mx my dn mz na nb dp nc li nd ne nf lm ng nh ni lq nj nk nl nm bi translated">准备</h2><p id="38d0" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">我将使用一个<a class="ae ky" href="https://jupyter.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Jupyter笔记本</strong> </a>来演示这一点。如果你的本地系统上没有安装<a class="ae ky" href="https://jupyter.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Jupyter笔记本</strong> </a>你也可以使用<a class="ae ky" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Google Colab </strong> </a>，它有免费的云版本。</p><p id="f02a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将使用用于Python的"<a class="ae ky" href="http://rasbt.github.io/mlxtend/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">mlx tend</strong></a>" Apriori库。如果你没有安装它，你可以通过命令行或通过Jupiter笔记本直接安装。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="2d55" class="mu mv it nt b gy nx ny l nz oa"># from the command line<br/>$ <strong class="nt iu">python3 -m pip install pandas mlxtend ploty matplotlib networkx</strong></span><span id="5e60" class="mu mv it nt b gy ob ny l nz oa"># or, from Jupyter notebooks<br/><strong class="nt iu">!python3 -m pip install pandas mlxtend ploty matplotlib networkx</strong></span></pre><p id="7416" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像往常一样，Jupyter笔记本的第一步是加载所需的库。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="a97b" class="mu mv it nt b gy nx ny l nz oa">import pandas as pd</span><span id="4af9" class="mu mv it nt b gy ob ny l nz oa">import networkx as nx<br/>import plotly.express as px<br/>import matplotlib.pyplot as plt<br/>plt.style.use('default')</span><span id="503f" class="mu mv it nt b gy ob ny l nz oa">from mlxtend.frequent_patterns import apriori<br/>from mlxtend.frequent_patterns import association_rules</span></pre><h2 id="13a8" class="mu mv it bd mw mx my dn mz na nb dp nc li nd ne nf lm ng nh ni lq nj nk nl nm bi translated">数据收集</h2><p id="cf73" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">出于本演练的目的，我将使用我在<a class="ae ky" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上找到的一个数据集，名为“<a class="ae ky" href="https://www.kaggle.com/roshansharma/market-basket-optimization" rel="noopener ugc nofollow" target="_blank">购物篮优化</a>”。该数据集在订单中有一个很好的产品组合，但不是以一种清晰的方式呈现的。我不得不进行一些预处理以使其可行。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="ffa8" class="mu mv it nt b gy nx ny l nz oa">df_orders = pd.read_csv('Market_Basket_Optimisation.csv')<br/>df_orders.shape<br/><strong class="nt iu">(7500, 20)</strong></span></pre><p id="18ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的数据集有7500行和20个特征。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/04d86aa2784966b3a46eaeaf0a8ba343.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q7RwAaSmootL3VHTZur14g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="5a2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我不太确定为什么数据集的作者会这样展示数据。</p><p id="346d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一步是创建一个求反的正则表达式。用下划线替换所有非字母数字字符和换行符。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="5ede" class="mu mv it nt b gy nx ny l nz oa">df_orders = df_orders.replace(r'[^A-z0-9\n]+','_', regex=True)</span></pre><p id="0b2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们需要创建一个名为“<strong class="lb iu"> combined </strong>的新特性，它的每一行都有一个CSV格式的列。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="475b" class="mu mv it nt b gy nx ny l nz oa">x = df_orders.to_string(header=False, index=False, index_names=False).split('\n')<br/>vals = [','.join(e.split()) for e in x]<br/>df_orders['combined'] = [','.join(e.split()) for e in x]</span></pre><p id="3d02" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在的问题是NaN词条也是这样收录的:<br/>汉堡，肉丸，鸡蛋，NaN，NaN，NaN等。</p><p id="a821" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们删除这些条目的方法是使用正则表达式。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="de7a" class="mu mv it nt b gy nx ny l nz oa">df_orders_tmp = df_orders[['combined']].replace(to_replace=r',NaN.*$', value='', regex=True)</span></pre><p id="a522" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，第一行的“<strong class="lb iu">组合</strong>功能现在看起来像:<br/>汉堡、肉丸、鸡蛋</p><p id="eb0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我还想包括一个订单号功能，它只是复制索引号。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="96a7" class="mu mv it nt b gy nx ny l nz oa">df_orders_tmp['orderId'] = df_orders_tmp.index</span></pre><p id="6b15" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在用逗号将每个订单分成单独的行。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="bf0c" class="mu mv it nt b gy nx ny l nz oa">df_orders_tmp = df_orders_tmp.assign(combined=df_orders_tmp.combined.str.split(',')).explode('combined').reset_index(drop=True)</span></pre><p id="66b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在想用空格替换上面的临时下划线。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="94ea" class="mu mv it nt b gy nx ny l nz oa">df_orders_tmp = df_orders_tmp.replace(r'_',' ', regex=True)</span></pre><p id="7d13" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您想知道为什么要这样做，数据集中的一些意外字符会导致“<strong class="lb iu">内爆</strong>过程出现问题。解决方案是将它们全部替换为下划线，执行拆分，并将空格放回原处。</p><p id="b201" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们需要订单中购买的每个项目的数量。这看起来很简单，因为每一列都是购买的一件商品，所以我将对每一行反映1。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="6a71" class="mu mv it nt b gy nx ny l nz oa">df_orders_tmp['itemQuantity'] = 1</span></pre><p id="cf48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用我们需要的有意义的名称的列来完成我们的新数据框架。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="49b6" class="mu mv it nt b gy nx ny l nz oa">df = df_orders_tmp[['orderId','combined','itemQuantity']]<br/>df.columns = ['orderId','itemDescription','itemQuantity']</span></pre><p id="81bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们来看看…</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="396e" class="mu mv it nt b gy nx ny l nz oa">df</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/238161856705e526a8f969473a0d121c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*DBnwUaoBgyPO_1c4wQEByQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h2 id="9792" class="mu mv it bd mw mx my dn mz na nb dp nc li nd ne nf lm ng nh ni lq nj nk nl nm bi translated">(英)可视化(= visualization)</h2><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="0417" class="mu mv it nt b gy nx ny l nz oa">df_table = df.copy()<br/>df_table['all'] = 'all'</span><span id="fbd1" class="mu mv it nt b gy ob ny l nz oa">fig = px.treemap(df_table.head(30), path=['all', "itemDescription"], values='itemQuantity', color=df_table["itemQuantity"].head(30), hover_data=['itemDescription'], color_continuous_scale='Blues')</span><span id="be03" class="mu mv it nt b gy ob ny l nz oa">fig.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/4740f7c27a243593f4fc8eed9398aa2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7lU2fAPw9BfWRXMdbTHu1w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="e3f7" class="mu mv it nt b gy nx ny l nz oa">df.value_counts()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/5af1b8016b5db46b37af92ff7c819093.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TAxUbzhLZIrAczVzxWcV-Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="0a51" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个非常好的可视化是一个网络图，显示订单中的前15个产品。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="8065" class="mu mv it nt b gy nx ny l nz oa">df_network = df.copy()<br/>df_network_first = df_network.groupby("itemDescription").sum().sort_values("itemQuantity", ascending=False).reset_index()<br/>df_network_first["itemType"] = "groceries"<br/>df_network_first = df_network_first.truncate(before=-1, after=15) # top 15</span><span id="6836" class="mu mv it nt b gy ob ny l nz oa">plt.rcParams['figure.figsize']=(20,20)<br/>first_choice = nx.from_pandas_edgelist(df_network_first, source='itemType', target="itemDescription", edge_attr=True)<br/>pos = nx.spring_layout(first_choice)<br/>nx.draw_networkx_nodes(first_choice, pos, node_size=12500, node_color="lavender")<br/>nx.draw_networkx_edges(first_choice, pos, width=3, alpha=0.6, edge_color='black')<br/>nx.draw_networkx_labels(first_choice, pos, font_size=18, font_family='sans-serif')<br/>plt.axis('off')<br/>plt.grid()<br/>plt.title('Top 15 Products', fontsize=25)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/db9ecd34a098fdb64a10f76b122023c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oFa8jlZLao4Ku2yQuoYLbw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="85a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了继续，我们需要汇总同一订单中的多个产品。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="b5f2" class="mu mv it nt b gy nx ny l nz oa">df_grouped = df.groupby(['orderId','itemDescription']).sum()['itemQuantity']</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/a215c8ddab52f4449bb9212f2c1473c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nvaywwflBLlOvozv-dYLGA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="4a41" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们需要拆分已分组的数据帧。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="0d6d" class="mu mv it nt b gy nx ny l nz oa">df_basket = df_grouped.unstack().reset_index().fillna(0).set_index('orderId')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/769b947bb68800699922b6de4f945508.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MqcY7tACcv9aQV3VJjGa8g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="bfa6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在需要将矩阵中的值编码为1和0。我们的方法是，如果值小于或等于0，则将值设置为0，如果值大于或等于1，则将值设置为1。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="e17d" class="mu mv it nt b gy nx ny l nz oa">def encode_units(x):<br/>    if x &lt;= 0:<br/>        return 0<br/>    if x &gt;= 1:<br/>        return 1</span><span id="c631" class="mu mv it nt b gy ob ny l nz oa">basket_sets = df_basket.applymap(encode_units)<br/>basket_sets.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/f8fa93dc66f1443490d9b2ac0fca88a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*83qeeCYc4Cmqx-X6OxFhgQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h2 id="9a9d" class="mu mv it bd mw mx my dn mz na nb dp nc li nd ne nf lm ng nh ni lq nj nk nl nm bi translated">Apriori算法</h2><p id="eafa" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">我们将使用函数"<strong class="lb iu"> apriori </strong>"，从"<strong class="lb iu"> mlxtend </strong>"库打开，"<strong class="lb iu"> basket_sets </strong>"创建一个数据框架，"<strong class="lb iu">frequency _ items sets</strong>"，并支持每一项。我们将把参数设置为“<strong class="lb iu">先验</strong>”到“<strong class="lb iu">最小支持= 0.05 </strong>”和“<strong class="lb iu">使用列名=真</strong>”。</p><p id="c1b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">重要术语</strong></p><ul class=""><li id="e864" class="ok ol it lb b lc ld lf lg li om lm on lq oo lu op oq or os bi translated"><strong class="lb iu">前件</strong> ( <strong class="lb iu"> if </strong>)是Apriori算法的第一部分。将在数据集中找到该商品或产品。我们说“<strong class="lb iu">如果</strong>”是因为“<strong class="lb iu">如果</strong>”存在，那么很可能“<strong class="lb iu">的结果</strong>也将存在，“<strong class="lb iu">然后</strong>”。</li><li id="5656" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated"><strong class="lb iu">后件</strong> ( <strong class="lb iu"> then </strong>)是Apriori算法的第二部分。结合“<strong class="lb iu">先行词</strong>”找到的商品或产品。</li><li id="ebd5" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated">关联规则是从由两个或更多项目组成的数据集(例如商店订单)中计算出来的。</li><li id="e551" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated"><strong class="lb iu">支持度</strong>表示该商品在数据集中出现的频率，例如某产品在商店中的受欢迎程度</li><li id="f705" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated">置信度表示该规则被发现为正确的频率。它表明该规则有多可靠。有人在购买牙刷时会购买牙膏的可能性有多大</li><li id="c519" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated"><strong class="lb iu"> Lift </strong>是一种度量标准，用于测量产品在统计上独立的情况下同时出现的置信比率。例如，当购买一个产品时购买另一个产品的可能性有多大，同时控制另一个产品有多受欢迎。提升分数接近1表示前提和结果是独立的，前提的出现对结果的出现没有影响。提升分数大于1表明前因和后果相互依赖，且前因的出现对后果的出现有积极影响。提升分数小于1表明前因和后果是相互替代的，这意味着前因的存在对后果有负面影响，反之亦然。</li><li id="695c" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated"><strong class="lb iu">信念</strong>从统计独立性来衡量规则的隐含强度。信念得分是一个比率，它是一种产品在没有另一种产品的情况下出现的概率与一种产品在没有另一种产品的情况下存在的实际概率之间的比率。例如，如果(橙子)→(苹果)关联的信念得分为1.5；如果两者之间的关联是完全独立的，则该规则错误的几率会增加1.5倍(增加50%)。</li></ul><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="4f29" class="mu mv it nt b gy nx ny l nz oa">frequent_itemsets = apriori(basket_sets, min_support=0.05, use_colnames=True).sort_values(by=['support'], ascending=False)<br/>frequent_itemsets.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/03479a978ada182a81001ad57ee7265a.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*pm-cIIdPwEEpz4vucpFbgA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="c0ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是在告诉我们“<strong class="lb iu">矿泉水</strong>”、“<strong class="lb iu">鸡蛋</strong>”、“<strong class="lb iu">意大利面</strong>”是这家店最受欢迎的商品。“<strong class="lb iu"> min_support </strong>”参数需要根据数据集进行微调。0.05在这里工作得很好，但如果你尝试其他数据集，你可能需要在某些情况下将其降低到0.01。</p><p id="416b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用函数，"<strong class="lb iu"> association_rules </strong> " from，"<strong class="lb iu"> mlxtend </strong>"创建dataframe from，"<strong class="lb iu">frequency _ items ets</strong>"使用参数度量，"<strong class="lb iu"> lift </strong>"。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="b542" class="mu mv it nt b gy nx ny l nz oa">rules = association_rules(frequent_itemsets, metric="lift")<br/>rules.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/50e7aa89626da2a4ddab08001dc9da89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O254JrT1PxaDKAB5C4RPCg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="0059" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">重申一下，“<strong class="lb iu">前因</strong>是正在购买的产品，“<strong class="lb iu">后果</strong>是经常购买的产品，以及它们相关的可能性。</p><p id="773d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">理想情况下，我们寻找提升和信心都很高的参赛作品。类似于"<strong class="lb iu"> lift </strong>"大于等于6，以及"<strong class="lb iu"> confidence </strong>"大于等于0.8。简单重述一下，“<strong class="lb iu"> lift </strong>”是“<strong class="lb iu">实际置信度</strong>”和“<strong class="lb iu">预测置信度</strong>”之间的比值。大于1.0的升力比意味着两个产品之间的关系比如果两个集合是独立的所预期的更重要。升力比越大，关联越显著。“置信度”是规则被发现为正确的频率。换句话说，这个规则作为百分比有多可靠。</p><p id="da45" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们寻找的是“<strong class="lb iu">提升</strong>”和“<strong class="lb iu">信心</strong>”最高的规则。这在熊猫身上很容易过滤。至少我们希望"<strong class="lb iu">升力</strong>"大于1，但尽可能高。对于“<strong class="lb iu">置信度</strong>”我将规则设置为等于或高于25%。</p><pre class="kj kk kl km gt ns nt nu nv aw nw bi"><span id="c9ef" class="mu mv it nt b gy nx ny l nz oa">rules[ (rules['lift'] &gt; 1) &amp; (rules['confidence'] &gt;= 0.25) ]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/6bb9389057ab4be98d13a159aceab00b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZY4zwB9rwmQQZgVv_imF2w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="85a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这告诉我们，在这家商店，如果有人买了“<strong class="lb iu">意大利面</strong>”，他们也有34%的可能会买“<strong class="lb iu">矿泉水</strong>”。</p><h2 id="d0f8" class="mu mv it bd mw mx my dn mz na nb dp nc li nd ne nf lm ng nh ni lq nj nk nl nm bi translated">最后</h2><p id="ddda" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">Apriori算法在数据挖掘中非常有用。最常见的使用案例是零售市场、推荐系统、营销活动、用户行为分析等。</p><h1 id="7833" class="pb mv it bd mw pc pd pe mz pf pg ph nc jz pi ka nf kc pj kd ni kf pk kg nl pl bi translated">迈克尔·惠特尔</h1><ul class=""><li id="6fde" class="ok ol it lb b lc nn lf no li pm lm pn lq po lu op oq or os bi translated"><strong class="lb iu"> <em class="pp">如果你喜欢这个，请</em> </strong> <a class="ae ky" href="https://whittle.medium.com/" rel="noopener"> <strong class="lb iu"> <em class="pp">跟我上媒</em> </strong> </a></li><li id="ad37" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated"><strong class="lb iu"> <em class="pp">更多有趣的文章，请</em> </strong> <a class="ae ky" href="https://medium.com/trading-data-analysis" rel="noopener"> <strong class="lb iu"> <em class="pp">关注我的刊物</em> </strong> </a></li><li id="b3c7" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated"><strong class="lb iu"> <em class="pp">有兴趣合作吗？</em> </strong> <a class="ae ky" href="https://www.linkedin.com/in/miwhittle/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="pp">我们上LinkedIn </em> </strong> </a>连线吧</li><li id="2811" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated"><strong class="lb iu"> <em class="pp">支持我和其他媒体作者</em> </strong> <a class="ae ky" href="https://whittle.medium.com/membership" rel="noopener"> <strong class="lb iu"> <em class="pp">在此报名</em> </strong> </a></li><li id="85f7" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated"><strong class="lb iu"> <em class="pp">请别忘了为文章鼓掌:)←谢谢！</em>T13】</strong></li></ul></div></div>    
</body>
</html>