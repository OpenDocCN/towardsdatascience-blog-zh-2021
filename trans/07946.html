<html>
<head>
<title>Implementing Customer Segmentation using K-Means clustering with PySpark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用PySpark的K-Means聚类实现客户细分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-customer-segmentation-using-k-means-clustering-with-pyspark-2e597a1456a6?source=collection_archive---------18-----------------------#2021-07-21">https://towardsdatascience.com/implementing-customer-segmentation-using-k-means-clustering-with-pyspark-2e597a1456a6?source=collection_archive---------18-----------------------#2021-07-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a889" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过Python和Apache Spark (PySpark)使用K-Means集群实现客户细分的分步指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/dec08d580bdf04fbef1f2e53221bf5c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QBh0FqQtAsh9sHzLGewo7w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://www.pexels.com/@sarah-chai?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">莎拉·柴</a>从<a class="ae ky" href="https://www.pexels.com/photo/jars-with-various-raw-pasta-and-nuts-7262772/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">派克斯</a>拍摄</p></figure><p id="b5cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在之前的<a class="ae ky" rel="noopener" target="_blank" href="/implementing-customer-segmentation-using-rfm-analysis-with-pyspark-3aed363f1d53">文章</a>中，我们看到了如何根据消费者最近的购买、交易频率和其他购买习惯对他们进行分类。在那里，我们利用了RFM分析，一种管理细分方法。在本帖中，我们将了解如何使用机器学习算法k-means clustering对相同的客户数据集进行细分，使我们能够更好地为客户服务，同时提高盈利能力。</p><p id="8dfe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">和以前一样，本文中使用的完整代码和数据集可以在<a class="ae ky" href="https://github.com/asish012/dataanalytics" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上获得。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="292a" class="ma mb it lw b gy mc md l me mf">· <a class="ae ky" href="#495c" rel="noopener ugc nofollow">Introduction</a><br/>· <a class="ae ky" href="#b1d3" rel="noopener ugc nofollow">Dataset</a><br/>· <a class="ae ky" href="#bf94" rel="noopener ugc nofollow">Feature Engineering</a><br/>· <a class="ae ky" href="#c533" rel="noopener ugc nofollow">Find the optimal number of clusters</a><br/>· <a class="ae ky" href="#9145" rel="noopener ugc nofollow">Implementing K-Means Clustering</a><br/>· <a class="ae ky" href="#a758" rel="noopener ugc nofollow">Observation</a><br/>· <a class="ae ky" href="#e0b4" rel="noopener ugc nofollow">Conclusion</a></span></pre><h1 id="495c" class="mg mb it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">介绍</h1><p id="0992" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">K-Means是最流行的无监督聚类算法之一。它可以通过简单地利用输入向量进行推断，而不参考已知或标记的结果。输入参数“k”代表我们希望在给定数据集中形成的聚类或组的数量。</p><p id="2ff8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们不会讨论k-means算法的数学细节，因为这超出了本文的范围。相反，我们将专注于业务需求:使用算法识别不同的客户群，看看我们如何更好地为客户服务。</p><blockquote class="nc nd ne"><p id="e274" class="kz la nf lb b lc ld ju le lf lg jx lh ng lj lk ll nh ln lo lp ni lr ls lt lu im bi translated">我推荐以下站点来了解更多关于k-means算法、其应用、优点和缺点的信息:</p></blockquote><div class="nj nk gp gr nl nm"><a rel="noopener follow" target="_blank" href="/k-means-clustering-algorithm-applications-evaluation-methods-and-drawbacks-aa03e644b48a"><div class="nn ab fo"><div class="no ab np cl cj nq"><h2 class="bd iu gy z fp nr fr fs ns fu fw is bi translated">k-均值聚类:算法、应用、评价方法和缺点</h2><div class="nt l"><h3 class="bd b gy z fp nr fr fs ns fu fw dk translated">使聚集</h3></div><div class="nu l"><p class="bd b dl z fp nr fr fs ns fu fw dk translated">:算法、应用、评估方法和缺点Clusteringtowardsdatascience.com</p></div></div><div class="nv l"><div class="nw l nx ny nz nv oa ks nm"/></div></div></a></div><p id="ed49" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要应用k-means聚类，我们所要做的就是告诉算法我们想要多少个聚类，它就会把数据集划分成所请求数量的聚类。有几种方法可以确定最佳的集群数量。我们将在本文中使用的<em class="nf">肘</em>方法就是其中之一。</p><p id="cf33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本质上，我们将使用不同的k值(例如2-10)运行聚类算法几次，然后计算并绘制每次迭代产生的成本函数。随着聚类数量的增加，平均失真将减少，每个数据点将更接近其聚类质心。然而，平均失真的改善将随着k的增加而下降。最后，我们将得到一个图表(其中我们绘制了每个k的平均失真),它类似于一只胳膊有一个弯曲的肘部。失真的改善在臂弯曲最严重的k值处下降最多。这个点被称为肘部，这将是最佳的集群大小。</p><h1 id="b1d3" class="mg mb it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">资料组</h1><p id="ad10" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">我们将从上一篇文章中的一个半准备好的数据集开始，其中已经计算了每个唯一客户的最近值、频率和货币值。如果你想从原始数据集开始，你可以参考我以前的<a class="ae ky" rel="noopener" target="_blank" href="/implementing-customer-segmentation-using-rfm-analysis-with-pyspark-3aed363f1d53">文章</a>以及<a class="ae ky" href="https://github.com/asish012/dataanalytics" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上的代码。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="b304" class="ma mb it lw b gy mc md l me mf">rfm_numbers = spark.read.csv("retail_rfm_numbers.csv", <br/>                             inferSchema=True, <br/>                             header=True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/069c7b1183819c08a04af6ca08fd7cb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/0*1sW7vlFtnoVKhMLl"/></div></figure><p id="8f8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们有三个显著的特点:</p><ul class=""><li id="984c" class="oc od it lb b lc ld lf lg li oe lm of lq og lu oh oi oj ok bi translated"><strong class="lb iu">最近度:</strong>顾客购买的时间。</li><li id="5861" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated"><strong class="lb iu">频率:</strong>为了简单起见，我们将统计每位顾客购物的次数。</li><li id="61ba" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated">他们花掉的钱的总数。</li></ul><h2 id="1b9d" class="ma mb it bd mh oq or dn ml os ot dp mp li ou ov mr lm ow ox mt lq oy oz mv pa bi translated">使用Pandas+Seaborn探索数据集</h2><p id="f65d" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">为了更好地理解数据集，让我们使用分布图来看看数据集的特性。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="4b25" class="ma mb it lw b gy mc md l me mf">import seaborn as sns</span><span id="5e9e" class="ma mb it lw b gy pb md l me mf">rfm_scores_df = rfm_scores.toPandas()<br/><br/>fig, ax = plt.subplots(1, 3, figsize=(16, 8))<br/><br/><em class="nf"># Recency distribution plot</em><br/>sns.histplot(rfm_scores_df['Recency'], kde=True, ax=ax[0])<br/><br/><em class="nf"># Frequency distribution plot</em><br/>sns.histplot(rfm_scores_df.query('Frequency &lt; 1000')['Frequency'], kde=True, ax=ax[1])<br/><br/><em class="nf"># Monetary distribution plot</em><br/>sns.histplot(rfm_scores_df.query('Monetary &lt; 10000')['Monetary'], kde=True, ax=ax[2])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/e07acd871a8dea8e871fc8623b0938ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*K4WHBhCMxH8lwJb2"/></div></div></figure><h1 id="bf94" class="mg mb it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">特征工程</h1><p id="a501" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">正如我们可以看到的，所有三个特征(最近、频率和货币)都是右偏的<a class="ae ky" href="https://en.wikipedia.org/wiki/Skewness" rel="noopener ugc nofollow" target="_blank">并且处于不同的尺度和范围，因此我们需要标准化数据，以便ML算法可以评估特征之间的相对距离并识别特征之间的趋势。令人欣慰的是，Spark ML为我们提供了一个类"<em class="nf"> StandardScaler </em>"，它允许我们轻松地缩放和标准化这些特性。</a></p><p id="287b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在以下代码中，我们执行这些特征工程步骤:</p><ol class=""><li id="2783" class="oc od it lb b lc ld lf lg li oe lm of lq og lu pd oi oj ok bi translated">从<em class="nf">货币</em>列中删除零和负值</li><li id="0c3e" class="oc od it lb b lc ol lf om li on lm oo lq op lu pd oi oj ok bi translated">向量化所有的特征(从Spark ML到工作的K-Means是强制性的)</li><li id="d8a5" class="oc od it lb b lc ol lf om li on lm oo lq op lu pd oi oj ok bi translated">标准化特征向量</li></ol><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="1b43" class="ma mb it lw b gy mc md l me mf"><em class="nf"># Remove zero and negative numbers</em></span><span id="565d" class="ma mb it lw b gy pb md l me mf">rfm_data = (<br/>    rfm_numbers.withColumn("Monetary", <br/>        F.when(F.col("Monetary") &lt;= 0, 1)<br/>         .otherwise(F.col("Monetary")))<br/>)</span><span id="b71f" class="ma mb it lw b gy pb md l me mf"><em class="nf"># Identifying feature columns</em><br/>features = rfm_data.columns[1:]</span><span id="50c2" class="ma mb it lw b gy pb md l me mf"><em class="nf"># vectorize all the features</em><br/>assembler = VectorAssembler(<br/>    inputCols=features, <br/>    outputCol="rfm_features")<br/>assembled_data = assembler.transform(rfm_data)<br/>assembled_data = assembled_data.select(<br/>    'CustomerID', 'rfm_features')</span><span id="6afc" class="ma mb it lw b gy pb md l me mf"><em class="nf"># Standardization</em><br/>scaler = StandardScaler(</span><span id="f6bd" class="ma mb it lw b gy pb md l me mf">inputCol='rfm_features',</span><span id="cc4b" class="ma mb it lw b gy pb md l me mf">outputCol='rfm_standardized')<br/>data_scale = scaler.fit(assembled_data)<br/>scaled_data = data_scale.transform(assembled_data)</span></pre><h1 id="c533" class="mg mb it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">找到最佳的聚类数</h1><p id="0333" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">正如我们在开始时所讨论的，我们将使用肘方法来确定数据集的最佳聚类数。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="32fa" class="ma mb it lw b gy mc md l me mf">costs = {}</span><span id="c789" class="ma mb it lw b gy pb md l me mf"><em class="nf"># Apply k-means with different value of k</em><br/>for k in range(2, 10):<br/>    k_means = KMeans(featuresCol='rfm_standardized', k=k)<br/>    model = k_means.fit(scaled_data)<br/>    costs[k] = model.computeCost(scaled_data)<br/><br/><em class="nf"># Plot the cost function</em><br/>fig, ax = plt.subplots(1, 1, figsize =(16, 8))<br/><br/>ax.plot(costs.keys(), costs.values())<br/>ax.set_xlabel('k')<br/>ax.set_ylabel('cost')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/1282365d3f3981adf32144e434c9cff9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OMFzY5jW6Sx8Cgz2"/></div></div></figure><p id="c7af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在k=4的值处，线看起来像肘部一样弯曲(失真的改善下降最多)。所以我们可以假设k=4是最佳的聚类数。</p><h1 id="9145" class="mg mb it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">实现K均值聚类</h1><p id="19f3" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">在这一步中，我们将使用聚类数“k”等于4，并对整个数据集最后一次运行k-means算法，我们将在名为“prediction”的列中获得每个客户的预测聚类数。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="cf16" class="ma mb it lw b gy mc md l me mf">k_means = KMeans(featuresCol='rfm_standardized', k=4)<br/>model = k_means.fit(scaled_data)<br/>predictions = model.transform(scaled_data)<br/><br/>result = predictions.select('CustomerID', 'prediction')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/c9c5bb08ffc187ccd92c611f28a9618c.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/0*A3v5xcz49d_vo2oS"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/9021eede9d4f340a9f1ef506b899705b.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/0*EBYmSU6mfSL6COxJ"/></div></figure><h1 id="a758" class="mg mb it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">观察</h1><p id="72a4" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">让我们将预测与起始数据集连接起来，这样我们就可以用一些图表来检查结果。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="7ca9" class="ma mb it lw b gy mc md l me mf"><em class="nf"># Join other information with the prediction result-set</em><br/><br/>rfm_score = spark.read.csv(retail_rfm_numbers.csv', <br/>                           inferSchema=True, <br/>                           header=True)<br/>rfm_score = rfm_score.select("CustomerID", "Recency", "Frequency", "Monetary", "RFM_Score", "RFM_ScoreGroup", "Loyalty")</span><span id="c6e6" class="ma mb it lw b gy pb md l me mf">combined_result = result.join(rfm_score, on='CustomerID', how='inner')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/5d7e33d3fb0a93ee3ed6b2bb38b76d66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*av_hGcIfEyj8-8HE"/></div></div></figure><p id="0fe4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，为了更好地理解预测结果，我们在箱线图中绘制了每个聚类的最近值、频率和货币值。生成的图表揭示了这些关键点:</p><ul class=""><li id="ce43" class="oc od it lb b lc ld lf lg li oe lm of lq og lu oh oi oj ok bi translated">c<em class="nf">cluster 2</em>与其他聚类相比明显具有更高的频率和货币数字，并且与其他聚类相比具有最低的新近值。</li><li id="c997" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated">另一方面,<em class="nf">群1 </em>具有最高的新近数字，但是最低的频率和货币数字。</li><li id="f76e" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated">其他集群(1和3)位于中间。</li></ul><p id="df1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这一观察表明，我们的顾客被分成不同的群体，其中某些群体表现出最佳表现顾客的特征(聚类2)，而其他群体对与我们一起购物失去了兴趣(聚类1，他们已经很久没有光顾我们了)。其他顾客(第0类和第3类)可能需要更多的关注/激励，以便更频繁地与我们一起购物。基于这种分析，企业可以对不同的客户群体做出不同的反应，以增加利润。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="648e" class="ma mb it lw b gy mc md l me mf">analysis_df = combined_result.toPandas()<br/><br/>fig, ax = plt.subplots(1, 3, figsize=(20, 12))<br/>sns.boxplot(x='prediction', y='Recency', data=analysis_df, ax=ax[0])<br/>sns.boxplot(x='prediction', y='Frequency', data=analysis_df, ax=ax[1])<br/>sns.boxplot(x='prediction', y='Monetary', data=analysis_df, ax=ax[2])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/b8deb670acdca8fdecc7c5a50887a426.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PbgLCpuDIuMhLseb"/></div></div></figure><p id="154b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还可以查看成对特征比较，以了解这些特征如何影响每个分段。</p><pre class="kj kk kl km gt lv lw lx ly aw lz bi"><span id="4243" class="ma mb it lw b gy mc md l me mf"><em class="nf"># Monetary vs Frequency (combined)</em><br/>fig, ax = plt.subplots(1, 1, figsize=(8, 8))<br/>sns.scatterplot(x='Recency', y='Monetary', <br/>                data=selected_result_df, <br/>                hue='prediction', <br/>                palette="deep")<br/><br/><em class="nf"># Monetary vs Frequency (combined)</em><br/>fig, ax = plt.subplots(1, 1, figsize=(8, 8))<br/>sns.scatterplot(x='Recency', y='Frequency', <br/>                data=selected_result_df, <br/>                hue='prediction', <br/>                palette="deep")<br/><br/><em class="nf"># Monetary vs Frequency (combined)</em><br/>fig, ax = plt.subplots(1, 1, figsize=(8, 8))<br/>sns.scatterplot(x='Monetary', y='Frequency', <br/>                data=selected_result_df, <br/>                hue='prediction', <br/>                palette="deep")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/6b857c588a29fcc1f87d87730e7f0064.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/0*ce4lrEnxpYKpeXkz"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/409f108a8fb513ecb30c832d5867f45b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/0*4TIqVWk-3hlm4EXG"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/68f225020c8acce698efd099f506a8fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/0*7J8xRJ4c63CHPJG2"/></div></figure></div><div class="ab cl pl pm hx pn" role="separator"><span class="po bw bk pp pq pr"/><span class="po bw bk pp pq pr"/><span class="po bw bk pp pq"/></div><div class="im in io ip iq"><h1 id="c255" class="mg mb it bd mh mi ps mk ml mm pt mo mp jz pu ka mr kc pv kd mt kf pw kg mv mw bi translated">结论</h1><p id="e0b4" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">K-means聚类是最流行和广泛使用的数据聚类分析技术之一。但是，它的性能通常不如其他复杂的聚类技术。但它仍然可以为我们提供很好的见解，帮助我们理解数据。你对K-means聚类有什么想法？</p></div></div>    
</body>
</html>