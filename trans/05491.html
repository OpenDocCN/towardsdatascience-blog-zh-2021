<html>
<head>
<title>Interactive guide to Attention Mechanism</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">注意机制互动指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-attention-mechanism-8d044442a29?source=collection_archive---------13-----------------------#2021-05-15">https://towardsdatascience.com/introduction-to-attention-mechanism-8d044442a29?source=collection_archive---------13-----------------------#2021-05-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="7824" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">理解ML</h2><div class=""/><div class=""><h2 id="06e4" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">注意力是如何产生的？为什么它会起作用，为什么它现在是ML中最重要的事情之一？</h2></div><h1 id="16b8" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">介绍</h1><p id="5ef2" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">注意机制是机器学习中最重要的发明之一，目前(2021年)它被用于在几乎每个领域取得令人印象深刻的成果，今天我想解释它的来源和工作原理。</p><p id="7a51" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">在开始解释注意力之前，我们必须回过头来看看注意力应该解决的问题。在2015年之前，当输入序列非常长时，RNN会出现问题。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/7d4635ae565c0ecf3163eb83b09f4041.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pd1apf8n9MkdF_5jsB5wqA.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">图1:基于<a class="ae mx" href="https://arxiv.org/abs/1409.3215" rel="noopener ugc nofollow" target="_blank"> <em class="my">“序列对序列神经网络学习”</em>、NeurIPS 2014 </a>论文、<a class="ae mx" href="https://web.eecs.umich.edu/~justincj/teaching/eecs498/FA2019/" rel="noopener ugc nofollow" target="_blank"> UMich </a>设计的RNN序列对序列</p></figure><blockquote class="mz na nb"><p id="f2d7" class="lg lh nc li b lj mc ka ll lm md kd lo nd me lr ls ne mf lv lw nf mg lz ma mb ij bi translated"><strong class="li ja">注意</strong> <br/>这只是原图的截图，不幸的是我不能在介质上包含应用程序的一部分。如果你想玩它请直接去<a class="ae mx" href="https://erdem.pl/2021/05/introduction-to-attention-mechanism#pure-rnn-sts-diagram" rel="noopener ugc nofollow" target="_blank">这个链接</a></p></blockquote><p id="10ba" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">只要句子很短，这种解决方案就很好。在解码器完成其工作后，我们剩下了<strong class="li ja">上下文向量<em class="nc">c</em>T14】和<strong class="li ja">初始解码器状态</strong>T17】s0。这两个向量必须<em class="nc"/>“汇总”整个输入序列，因为我们要将它们送入模型的解码器部分。你可以把上下文向量看作是在编码序列和解码序列之间传递信息的东西。</strong></p><h2 id="5ba6" class="ng kp iq bd kq nh ni dn ku nj nk dp ky lp nl nm la lt nn no lc lx np nq le iw bi translated">长句问题</h2><p id="8215" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">对于长句，像<strong class="li ja"> T=100 </strong>，很可能我们的上下文向量<strong class="li ja"> <em class="nc"> c </em> </strong>不能够保存来自编码序列的所有有意义的信息。想想这句话:</p><blockquote class="mz na nb"><p id="82cc" class="lg lh nc li b lj mc ka ll lm md kd lo nd me lr ls ne mf lv lw nf mg lz ma mb ij bi translated">“在某种程度上，人工智能比我们想象的更近也更远。AI更接近于能够做比大多数人预期的更强大的事情——驾驶汽车、治疗疾病、发现行星、理解媒体。这些都将对世界产生重大影响，但我们仍在研究什么是真正的智能。”——<strong class="li ja"><em class="iq">马克·扎克伯格</em></strong><em class="iq"/><strong class="li ja">【建筑贾维斯】</strong></p></blockquote><p id="b1bd" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">将第一句话压缩成上下文向量要比对整个引用做同样的事情容易得多。我们可以创建越来越长的上下文向量，但因为rnn是连续的，不会按比例增加。这就是注意力机制发挥作用的地方。</p><p id="f58a" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">想法是在解码器的每个时间步长创建一个新的上下文向量<strong class="li ja">，其不同地关注编码序列。</strong></p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nr"><img src="../Images/69f7e0eb066b14947d7f511c84ca2120.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*moACsqnXeJsfuxIxY7UL_w.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">图2:与RNN的序列对序列(注意)，基于<a class="ae mx" href="https://arxiv.org/abs/1409.0473" rel="noopener ugc nofollow" target="_blank"> <em class="my">【神经机器transla$on通过联合学习对齐和翻译】</em>，NeurIPS 2015 </a>论文，<a class="ae mx" href="https://web.eecs.umich.edu/~justincj/teaching/eecs498/FA2019/" rel="noopener ugc nofollow" target="_blank"> UMich </a>设计</p></figure><p id="9a34" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">这次我们在解码器的每一步都计算一个额外的上下文向量。让我们通过一个完整的步骤来解释正在发生的事情。</p><h1 id="e215" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">1.计算比对分数</h1><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/c5137401fc680569152cc308747b8016.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/0*n4C4stbin-atMZHN.png"/></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><em class="my">图3:t = 1，</em> <a class="ae mx" href="https://erdem.pl/2021/04/introduction-to-attention-mechanism" rel="noopener ugc nofollow" target="_blank"> <em class="my">的比对分数来源:erdem.pl </em> </a></p></figure><p id="2f30" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">在<strong class="li ja"> <em class="nc"> t </em> =1 </strong>时，我们将使用解码器状态<strong class="li ja"><em class="nc">s _ t</em>-1</strong>来计算比对分数。为了计算每个编码器状态的校准分数，我们使用了一个名为<em class="nc">校准函数</em>的函数，但它只是一个MLP(多层感知器)。每个校准分数可以被视为“在状态<em class="nc"> s </em> 0下，有多少<em class="nc"> h </em> 1对预测输出有用”。alignment函数输出一个标量值，它是一个实数，我们不能就这样使用它，我们必须使用softmax函数来规范化这些值。</p><h1 id="f448" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">2.计算注意力权重</h1><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nt"><img src="../Images/cd6a53b1ae31f811e5c4c354950be936.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OZAH_Z3Jj3gbfqx-.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><em class="my">图4:t = 1，</em> <a class="ae mx" href="https://erdem.pl/2021/04/introduction-to-attention-mechanism" rel="noopener ugc nofollow" target="_blank"> <em class="my">的注意力权重来源:erdem.pl </em> </a></p></figure><p id="d966" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">softmax函数的输出被归一化，因此所有数字的总和为1。这些输出被称为<strong class="li ja">注意力权重</strong>，顾名思义，它们向模型显示“它应该关注相应的隐藏状态多少”。</p><h1 id="109d" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">3.计算上下文向量</h1><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nu"><img src="../Images/4e31635c72477a1aa11862e694d296ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FWzmdda_XIrvpfAW.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><em class="my">图5:t = 1的上下文向量计算，</em> <a class="ae mx" href="https://erdem.pl/2021/04/introduction-to-attention-mechanism" rel="noopener ugc nofollow" target="_blank"> <em class="my">来源:erdem.pl </em> </a></p></figure><p id="cbc9" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">现在发生了很多事情(上图中的3个步骤)。首先，我们将每个注意力权重乘以相应的隐藏状态(<em class="nc"> a </em> 1，1 × <em class="nc"> h </em> 1，1，<em class="nc"> a </em> 1，2 × <em class="nc"> h </em> 1，2……)。然后，将所有结果相加以用作<strong class="li ja">上下文向量<em class="nc"> c </em> 1 </strong>。</p><blockquote class="mz na nb"><p id="ba2e" class="lg lh nc li b lj mc ka ll lm md kd lo nd me lr ls ne mf lv lw nf mg lz ma mb ij bi translated"><strong class="li ja"> <em class="iq">注意:</em> </strong> <em class="iq"> <br/>你可能已经注意到，在这一点上“上下文向量”实际上是一个“上下文标量”但这只是因为我们决定只输出1D(现在更容易展示和理解)。当我们开始将注意力抽象到它自己的层面时，我将切换到向量。</em></p></blockquote><h1 id="e54a" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">4.计算第一个输出</h1><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nv"><img src="../Images/2cf77e233607208392d561b298918ad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*abjHgrU0S852W6iq.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><em class="my">图6:t = 1时解码器的输出，</em> <a class="ae mx" href="https://erdem.pl/2021/04/introduction-to-attention-mechanism" rel="noopener ugc nofollow" target="_blank"> <em class="my">来源:erdem.pl </em> </a></p></figure><p id="e489" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">在第一个时间步长结束时，我们最终可以计算解码器的第一个输出。使用上下文向量<em class="nc"> c </em> 1、先前解码器的状态<em class="nc"> s </em> 0和开始标记<em class="nc"> y </em> 0来计算该输出。有趣的是，在整个过程中，我们不必将<em class="nc"> f_att </em>作为一个单独的模型来训练。<strong class="li ja">整个过程是可微的</strong>，所以我们可以通过计算图反向传播。</p><h1 id="5099" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">5.并重复…</h1><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nw"><img src="../Images/780765844b18477f5b45e7adfcfdad3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8XDq04QUUudzS3MW.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><em class="my">图7:t = 2的新上下文向量，</em> <a class="ae mx" href="https://erdem.pl/2021/04/introduction-to-attention-mechanism" rel="noopener ugc nofollow" target="_blank"> <em class="my">来源:erdem.pl </em> </a></p></figure><p id="5b18" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">在时间步长t=2时，我们唯一要做的事情是<strong class="li ja">改变输入以计算从<em class="nc"> s </em> 0到<em class="nc"> s </em> 1 </strong>的比对分数。使用相同的过程，我们计算新的分数(<em class="nc"> e2，1，e2，1</em>……)和注意力权重(<em class="nc"> a2，1，a2，1</em>……)。然后将新的注意力权重和编码器的隐藏状态相乘，以计算新的上下文向量<em class="nc"> c </em> 2。此时，整个过程只是在循环中运行，直到解码器产生<em class="nc">【停止】</em> token(有时也叫<em class="nc">【EOS】</em>token，eng。句尾)。</p><h1 id="addd" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">注意力权重可视化</h1><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nx"><img src="../Images/e8b52a2eb544471bc8096df4280d0eb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Zxi7-StjTuHDIg9I.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><em class="my">图8:英语到法语翻译的注意力权重，来源:</em> <a class="ae mx" href="https://arxiv.org/abs/1409.0473" rel="noopener ugc nofollow" target="_blank"> <em class="my">通过联合学习对齐和翻译的神经机器翻译</em> </a></p></figure><p id="d122" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">在原论文中，有一个简单的可视化的注意力权重<strong class="li ja"> <em class="nc"> ai，j </em> </strong> <em class="nc"> </em>是在翻译英文句子<em class="nc">“关于欧洲经济区的协议于1992年8月签署”时生成的</em>译成法语<em class="nc">“1992年8月签署的欧洲经济区协议”</em>。这个可视化向我们展示了一些有趣的事情。</p><p id="7d2a" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">第一件事是一个对角线模式，它告诉我们，模型把更多的注意力放在来自相同位置的相应法语单词上。第二件事更有趣，它是短语<em class="nc">“欧洲经济区”</em>，在法语中有相反的顺序<em class="nc">“欧洲经济区”</em>。我们可以看到，当生成<code class="fe ny nz oa ob b">la</code>令牌时，模型更关注<code class="fe ny nz oa ob b">the</code>和<code class="fe ny nz oa ob b">Area</code>，那么当生成<code class="fe ny nz oa ob b">zone</code>令牌时，它关注<code class="fe ny nz oa ob b">Area</code>和<code class="fe ny nz oa ob b">Economic</code>(忽略<code class="fe ny nz oa ob b">European</code>)。另一个有趣的观察是<em class="nc"> "a été signé" </em>，其中当生成<code class="fe ny nz oa ob b">a</code>和<code class="fe ny nz oa ob b">été</code>令牌时，模型同时考虑<code class="fe ny nz oa ob b">was</code>和<code class="fe ny nz oa ob b">signed</code>(这在法语中是有意义的，因为我们需要知道单词<code class="fe ny nz oa ob b">étre</code>的确切变体)。</p><p id="c754" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">这个热图很重要，因为我们没有告诉模型它应该注意哪些单词，它是自己学习的。此外，我们还得到了模型决策的某种可解释性。</p><h1 id="4954" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">注意力不知道输入是一个序列</h1><p id="ebc7" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">您可能已经开始担心上一步我的信息发生了什么:</p><p id="f910" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated"><em class="nc">“我们没有利用h向量是有序序列的事实。它被用作无序集。为了解决这个问题，我们必须给每个元素添加一个位置编码</em></p><p id="2bec" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">我已经单独写了一篇关于位置编码的文章，因为这篇文章包含了太多的信息。如果你感兴趣，请查看<a class="ae mx" href="https://erdem.pl/2021/05/understanding-positional-encoding-in-transformers" rel="noopener ugc nofollow" target="_blank">了解变形金刚</a>中的位置编码。</p><p id="5c9d" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">这仍然是一个东西，但不是解决这个问题，而是利用它来抽象注意力机制，并将其用于不同于文本序列的东西。用注意力描述图像呢？同年有一篇名为<a class="ae mx" href="https://arxiv.org/abs/1502.03044" rel="noopener ugc nofollow" target="_blank"> <em class="nc">“展示、参与、讲述:具有视觉注意力的神经图像字幕生成”</em> </a>的论文，该论文在RNN解码器的帮助下，利用对CNN嵌入的注意力来生成图像字幕。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oc"><img src="../Images/2ed43064090b8ed623f141651739a3f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D6qPOwDqrbq9n-NXgcxuZQ.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated">图9:带注意的图像字幕(仍为RNN)，基于<a class="ae mx" href="https://arxiv.org/abs/1502.03044" rel="noopener ugc nofollow" target="_blank"> <em class="my">【展示、出席、讲述:带视觉注意的神经图像字幕生成】</em>，</a>论文，<a class="ae mx" href="https://web.eecs.umich.edu/~justincj/teaching/eecs498/FA2019/" rel="noopener ugc nofollow" target="_blank"> UMich </a>设计</p></figure><blockquote class="mz na nb"><p id="470e" class="lg lh nc li b lj mc ka ll lm md kd lo nd me lr ls ne mf lv lw nf mg lz ma mb ij bi translated"><strong class="li ja">注意</strong> <br/>这只是原图的截图，不幸的是我不能在介质上包含应用程序的一部分。如果你想玩它请直接去<a class="ae mx" href="https://erdem.pl/2021/05/introduction-to-attention-mechanism#rnn-imtos-with-attention-diagram" rel="noopener ugc nofollow" target="_blank">这个链接</a></p></blockquote><p id="da83" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">在本文中，作者提出了一种基于卷积特征提取的解决方案，而不是标准的RNN编码器网络。我们使用CNN的这些功能来计算状态，然后计算RNN解码器每个时间步长的对齐分数。和前面的例子一样，我将带你经历整个过程，但是你可能会根据上面的交互图理解它:)</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi od"><img src="../Images/44da808e1bdab8327f811d7b8479cd93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/0*6DUcb6nznVKc2BRq.png"/></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><em class="my">图10:提取特征的比对分数计算，</em> <a class="ae mx" href="https://erdem.pl/2021/04/introduction-to-attention-mechanism" rel="noopener ugc nofollow" target="_blank"> <em class="my">来源:erdem.pl </em> </a></p></figure><p id="96ea" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">我们假设CNN已经被训练并产生了我们的3x3网格。我们将使用初始网格来预测初始隐藏状态(有时它可以随机生成，甚至设置为0)。现在，我们必须将相同的网格和<em class="nc"> s </em> 0传递给对齐函数，以计算网格的每个值的相应对齐分数</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/be8318100e32f44013ab169b4349996d.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*s3T1CFlRAk8wmzDMypdOnA.png"/></div></figure><p id="e6e7" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">这给了我们<strong class="li ja"> t=1 </strong>时间步长的对齐分数。和前面的例子一样，每个比对分数都是一个标量，它告诉我们“给定特征在当前时间步长中有多重要”。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi of"><img src="../Images/ccde4293ef0dc7a2e235faa6a038363a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lELhlfAKRoj2xO64.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><em class="my">图11:注意力权重，</em> <a class="ae mx" href="https://erdem.pl/2021/04/introduction-to-attention-mechanism" rel="noopener ugc nofollow" target="_blank"> <em class="my">来源:erdem.pl </em> </a></p></figure><p id="e5f5" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">计算出比对分数后，我们需要应用softmax将分数归一化为某个概率分布，其总和为1。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi og"><img src="../Images/bdf6003010ca5d9cc66ae327cfbdded5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WL5z4ailD7EiJ--1.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><em class="my">图12:计算上下文向量并生成第一个输出，</em> <a class="ae mx" href="https://erdem.pl/2021/04/introduction-to-attention-mechanism" rel="noopener ugc nofollow" target="_blank"> <em class="my">来源:erdem.pl </em> </a></p></figure><p id="b5eb" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">现在，我们所要做的就是计算<a class="ae mx" href="https://en.wikipedia.org/wiki/Hadamard_product_(matrices)" rel="noopener ugc nofollow" target="_blank">哈达玛乘积</a>(逐元素乘法，…)并对所有内容求和以获得上下文向量<em class="nc"> c </em> 1。其余部分的工作方式与前面的示例完全相同，因此我们使用上下文向量<em class="nc"> c </em> 1、起始令牌<em class="nc"> y </em> 0和初始解码器状态<em class="nc"> s </em> 0，并通过<em class="nc"> gU </em>函数来计算<em class="nc"> s </em> 1状态，并获得一些输出令牌<em class="nc"> y </em> 1。</p><blockquote class="mz na nb"><p id="0620" class="lg lh nc li b lj mc ka ll lm md kd lo nd me lr ls ne mf lv lw nf mg lz ma mb ij bi translated"><strong class="li ja"> <em class="iq">注意</em> </strong> <em class="iq"> <br/>此时不需要求和，我这样做只是为了让上下文向量的形状和上一个例子一样。我们可以很容易地使用一个3x3的矩阵作为函数的输入。</em></p></blockquote><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi of"><img src="../Images/debcba9072f01e4fec094e6cf35b4434.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DHG4sAwh90NjonCe.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><em class="my">图14:第二个时间步长(t=2)，</em> <a class="ae mx" href="https://erdem.pl/2021/04/introduction-to-attention-mechanism" rel="noopener ugc nofollow" target="_blank"> <em class="my">来源:erdem.pl </em> </a></p></figure><p id="05c6" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">与之前相同，我们使用新生成的<em class="nc"> s </em> 1状态来计算新的对齐分数<em class="nc"> e_ </em> 2、<em class="nc"> i </em>、<em class="nc"> j </em>，然后使用softmax对其进行归一化，并将其计算到上下文向量<em class="nc"> c </em> 2中。当解码器产生<em class="nc">【停止】</em>令牌作为输出时，该过程停止。</p><h1 id="7b3e" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">注意力权重的可视化</h1><p id="d991" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">与序列到序列的翻译一样，在这种情况下，我们能够可视化注意力权重。我将使用作者提供的一个例子。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oh"><img src="../Images/a9cd343034734009a5c43e7d8ae878fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*C-kyzy3I-621PKSH.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><em class="my">图15:图像注意力可视化，白色区域具有较高的注意力权重值，来源:</em> <a class="ae mx" href="https://arxiv.org/abs/1502.03044" rel="noopener ugc nofollow" target="_blank"> <em class="my">显示、出席、讲述:具有视觉注意力的神经图像字幕生成</em> </a></p></figure><p id="ae8c" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">正如你所看到的，这不是一个解释模型的理想解决方案，但是仍然可以给你一种关于正在发生的事情的直觉。尤其是当我们看到像<code class="fe ny nz oa ob b">frisbee</code>或<code class="fe ny nz oa ob b">park</code>这样的记号时，当模型关注那些确切的对象时。在令牌<code class="fe ny nz oa ob b">woman</code>的情况下，图像上的两个人节省了相似的注意力权重，但这仍然没问题，因为模型可以决定哪个是主题以及如何命名那个人。</p><p id="d536" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">还有一种类型的注意力叫做<strong class="li ja">硬注意力</strong>，我们不使用softmax函数，而是选择一个具有最高对齐分数的特征，并使用该特征的值作为上下文。这需要在训练过程中进行一些改变，我现在不打算讨论这些。这里有一个努力关注的例子。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oi"><img src="../Images/f0573f1a62c99ed45e9f960a8148bf1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aVtkndy_X8r5FVg1.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><em class="my">图16:硬注意可视化，白色区域为模型注意的区域，来源:</em> <a class="ae mx" href="https://arxiv.org/abs/1502.03044" rel="noopener ugc nofollow" target="_blank"> <em class="my">展示、注意、讲述:视觉注意的神经图像字幕生成</em> </a></p></figure><p id="d2d7" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">如您所见，标题已经更改。现在它在说<em class="nc">“一个男人和一个女人在田野里玩飞盘。”取而代之的是“一个女人在公园里扔飞盘。”</em>。当生成标记<code class="fe ny nz oa ob b">frisbee</code>模型关注孩子时，注意区域不完全与生成的标记相关(如在软注意中)。</p><h1 id="6ea6" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">让我们抽象一下注意力</h1><p id="7f49" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">现在，当你知道注意力是什么的时候，我们可以开始抽象这个想法来创建所谓的<em class="nc">“注意力层】</em>。首先，让我们总结一下我们现在所拥有的:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oj"><img src="../Images/953bdf48c80db9f763f645071b107a93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eT0TmED7snb6jFqUQzCcAg.png"/></div></div></figure><p id="15c5" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">目前，我们的相似性函数是<em class="nc"> f_att，</em>，这是基于早期关注论文的正确结果，但是为了推广，我们可以将其改为<strong class="li ja"> q </strong>和<strong class="li ja"> X </strong>向量之间的<strong class="li ja">点积</strong>。这只是更有效地计算点积，但它创建了一个具有最终结果的乘积。正如你们所记得的，当计算两个向量的点积时，结果是这样的</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/2638e664e4c934b3592bc48e4dca3d44.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*QBPMoYpj4NHzJRKEfnwzFw.png"/></div></figure><p id="75a3" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">当向量的维数很大时，这可能会导致问题。为什么会有问题？看下一步和<em class="nc"> softmax </em>功能。这是一个很好的函数，但是当一个元素的值非常大，并且我们的值大小随着输入维度的增加而增加时，它会导致渐变消失的问题。这就是为什么你不仅仅使用点积，而是使用<strong class="li ja">比例点积</strong>，这样我们的新公式看起来就像</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/57a77db30664951207f36dd1834f7a64.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*5RgnUVkXWp9lubD6MT-r7w.png"/></div></figure><blockquote class="mz na nb"><p id="8d95" class="lg lh nc li b lj mc ka ll lm md kd lo nd me lr ls ne mf lv lw nf mg lz ma mb ij bi translated"><em class="iq">如果你不理解为什么点积会产生一个高维向量的大数，请查看</em> 3Blue1Brown的<em class="iq"> </em> <a class="ae mx" href="https://www.youtube.com/watch?v=LyGKycYT2v0" rel="noopener ugc nofollow" target="_blank"> <em class="iq"> Youtube上关于这个主题的视频</em> </a></p></blockquote><p id="f33d" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">此外，我们希望能够使用不止一个查询向量<strong class="li ja"> q </strong>。对于解码器的每个时间戳有一个单独的查询向量是很好的，但是当我们同时使用它们时会简单得多，所以我们将向量改为向量<strong class="li ja"> Q </strong>(形状<em class="nc"> NQ </em> × <em class="nc"> DQ </em>)。这也影响相似性得分和注意力的输出形状:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi om"><img src="../Images/668660f5fdc667fb759bcd60b8034eaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RoQZlGo9tyFrS3XArAehJA.png"/></div></div></figure><p id="5858" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">你可能想知道为什么<em class="nc"> softmax </em>要计算在<em class="nc"> dim=1 </em>之上？这是因为我们希望获得每个查询向量在输入向量上的概率分布。您应该注意的另一件事是，相似性得分的计算简化为矩阵乘法。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi on"><img src="../Images/d56c026b8f92d0bc3c456617c683284f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YV2VtphWGCQ5OV-ssngxWg.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><em class="my">图17:注意力和自我注意力层层叠加，演职员表:</em> <a class="ae mx" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank"> <em class="my">《注意力就是你所需要的一切》</em> </a> <em class="my">，</em> <a class="ae mx" href="https://web.eecs.umich.edu/~justincj/teaching/eecs498/FA2019/" rel="noopener ugc nofollow" target="_blank"> <em class="my">乌米奇</em> </a> <em class="my">，</em> <a class="ae mx" href="http://jalammar.github.io/illustrated-transformer/" rel="noopener ugc nofollow" target="_blank"> <em class="my">插图变压器</em> </a></p></figure><blockquote class="mz na nb"><p id="300d" class="lg lh nc li b lj mc ka ll lm md kd lo nd me lr ls ne mf lv lw nf mg lz ma mb ij bi translated"><strong class="li ja">注意</strong> <br/>这只是原图的截图，不幸的是我不能在介质上包含部分应用程序。如果你想玩它请直接去<a class="ae mx" href="https://erdem.pl/2021/05/introduction-to-attention-mechanism#the-layer" rel="noopener ugc nofollow" target="_blank">这个链接</a></p></blockquote><p id="d722" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">现在我们进入有趣的话题。图表的第一步是注意力的标准方法。我们只有我们的<strong class="li ja">查询向量</strong>和<strong class="li ja">输入向量</strong>。我们使用输入两次，一次是在计算<strong class="li ja">相似度</strong>时，第二次是在计算<strong class="li ja">输出向量</strong>时。我们可能想以稍微不同的方式使用这些向量，这就是<strong class="li ja">键</strong>和<strong class="li ja">值</strong>的想法的来源。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oo"><img src="../Images/456faf84d411ccb7b67bd24b118205d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NJr_-JN2a6WUARFJcKTGXQ.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><em class="my">图18:键和值分离，来源:</em> <a class="ae mx" href="http://localhost:8000/2021/05/introduction-to-attention-mechanism#the-layer" rel="noopener ugc nofollow" target="_blank"> <em class="my">关注层图</em> </a></p></figure><p id="b64e" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">你可能想知道这些向量是什么，为什么它们很重要？我在<a class="ae mx" href="https://stats.stackexchange.com/a/424127" rel="noopener ugc nofollow" target="_blank"> stackexchange </a>上发现了查询/值/键的一般概念背后的一个直觉:</p><blockquote class="mz na nb"><p id="583f" class="lg lh nc li b lj mc ka ll lm md kd lo nd me lr ls ne mf lv lw nf mg lz ma mb ij bi translated"><em class="iq">键/值/查询概念来自检索系统。比如你在Youtube上键入一个查询搜索某个视频，搜索引擎会将你的</em> <strong class="li ja"> <em class="iq">查询</em> </strong> <em class="iq">映射到一组</em> <strong class="li ja"> <em class="iq">键</em> </strong> <em class="iq">(视频标题、描述等)。)与数据库中的候选视频相关联，然后呈现给你最匹配的视频(</em> <strong class="li ja"> <em class="iq">值</em> </strong> <em class="iq">)。</em></p></blockquote><p id="9b82" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">如果我们从可用性的角度来看，它们允许模型决定如何使用输入数据。通过创建可训练权重(WK和WV ),我们可以调整输入以适应不同的任务。</p><blockquote class="mz na nb"><p id="ee98" class="lg lh nc li b lj mc ka ll lm md kd lo nd me lr ls ne mf lv lw nf mg lz ma mb ij bi translated"><strong class="li ja"> <em class="iq">注意</em> </strong> <em class="iq">刚好我所有的向量都有相同的长度，确切的形状要匹配(看描述中显示的形状)，但不一定要一样。</em></p></blockquote><p id="dfba" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">这时我们的<strong class="li ja">注意层</strong>准备好了！我们能做得更好吗？是啊！！！</p><h2 id="9af4" class="ng kp iq bd kq nh ni dn ku nj nk dp ky lp nl nm la lt nn no lc lx np nq le iw bi translated">自我关注层</h2><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi op"><img src="../Images/660885d7fa412c048e0437570bd0a34a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fa1s6-oxLnTEHc00wOqjGQ.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><em class="my">图19:自我关注层结构，来源:</em> <a class="ae mx" href="http://localhost:8000/2021/05/introduction-to-attention-mechanism#the-layer" rel="noopener ugc nofollow" target="_blank"> <em class="my">关注层图</em> </a></p></figure><p id="c6cf" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">一直以来，当使用关注层时，我们创建单独的<strong class="li ja">查询向量</strong>，这在自我关注方法中已经改变。这次我们添加了另一个权重矩阵(WQ ),它将用于计算新的<strong class="li ja">查询向量</strong>。这样，我们就能让我们的模型自己学习<strong class="li ja">输入向量</strong>的转换。</p><p id="f6cd" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">我们这里有所谓的<strong class="li ja">自我关注层</strong>，这是一个通用层，你可以在你的模型中使用。它接受<strong class="li ja">输入向量</strong>并输出<strong class="li ja">输出向量</strong>。整个层是<strong class="li ja">排列等变</strong></p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/1c5fc5c014a61782d6ec676dcf4e73c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*za7PXpZYL8OLrgnGhxSJqg.png"/></div></figure><p id="35ae" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">这意味着当你置换<strong class="li ja">输入向量</strong>时，输出将是相同的，但被置换。</p><p id="d6c1" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">最后，我需要解释为什么我改变了颜色。原因是为了匹配<a class="ae mx" href="http://jalammar.github.io/illustrated-transformer/" rel="noopener ugc nofollow" target="_blank">图文并茂的变形金刚</a>博文中使用的颜色。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi or"><img src="../Images/16731ab93fad042f087e45d457169467.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3rux5_TgYQXmgmU1.png"/></div></div><p class="mt mu gj gh gi mv mw bd b be z dk translated"><em class="my">图19:自关注层矩阵计算，设计来自:</em> <a class="ae mx" href="http://jalammar.github.io/illustrated-transformer/" rel="noopener ugc nofollow" target="_blank"> <em class="my">图示变压器</em> </a></p></figure><h1 id="d9e0" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">结论</h1><p id="b127" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">从这一点开始，我们可以使用<strong class="li ja">自我关注层</strong>来创建一个<strong class="li ja">变压器</strong>，但是这篇文章已经太长了。你应该对注意力机制如何工作以及为什么工作有一个直觉。我将写另一篇关于设计<strong class="li ja">变形金刚</strong>和<strong class="li ja">多头注意力</strong>的文章，但现在请参考<a class="ae mx" href="http://jalammar.github.io/illustrated-transformer/" rel="noopener ugc nofollow" target="_blank">图解变形金刚</a>。</p><p id="622c" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">Jay Alammar 很好地解释了变压器的工作原理，还有一个矢量计算的例子。我的文章试图解释关注和自我关注的概念是如何产生的，因为你们中的很多人是在阅读了那篇博客文章后来到这里的，所以我希望你们对色彩模式感到熟悉。</p><p id="3da9" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated">我希望你喜欢这些图表，如果你有任何问题，请随时提问。</p><h1 id="4484" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">参考资料:</h1><ul class=""><li id="b9d1" class="os ot iq li b lj lk lm ln lp ou lt ov lx ow mb ox oy oz pa bi translated">Sutskever等人，“神经网络的序列对序列学习”，NeurIPS 2014年【https://arxiv.org/abs/1409.3215 T2】</li><li id="5dbf" class="os ot iq li b lj pb lm pc lp pd lt pe lx pf mb ox oy oz pa bi translated">Bahdanau等人，“通过联合学习对齐和翻译的神经机器翻译”，https://arxiv.org/abs/1409.0473 ICLR 2015年<a class="ae mx" href="https://arxiv.org/abs/1409.0473" rel="noopener ugc nofollow" target="_blank"/></li><li id="ef01" class="os ot iq li b lj pb lm pc lp pd lt pe lx pf mb ox oy oz pa bi translated">徐等，“展示、参与、讲述:视觉注意下的神经图像字幕生成”，2015<a class="ae mx" href="https://arxiv.org/abs/1502.03044" rel="noopener ugc nofollow" target="_blank">2015</a></li><li id="fcc4" class="os ot iq li b lj pb lm pc lp pd lt pe lx pf mb ox oy oz pa bi translated">阿希什·瓦斯瓦尼等人，《注意力是你所需要的一切》，neur IPS 2017<a class="ae mx" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1706.03762</a></li><li id="d922" class="os ot iq li b lj pb lm pc lp pd lt pe lx pf mb ox oy oz pa bi translated">杰伊·阿拉玛，《图解变形金刚》，2018年<a class="ae mx" href="http://jalammar.github.io/illustrated-transformer/" rel="noopener ugc nofollow" target="_blank">http://jalammar.github.io/illustrated-transformer/</a></li><li id="1cfa" class="os ot iq li b lj pb lm pc lp pd lt pe lx pf mb ox oy oz pa bi translated">3Blue1Brown，“点积与二元性| EoLA #9”，2016<a class="ae mx" href="https://www.youtube.com/watch?v=LyGKycYT2v0" rel="noopener ugc nofollow" target="_blank">Youtube lygkycyt 2v 0</a></li><li id="9d4d" class="os ot iq li b lj pb lm pc lp pd lt pe lx pf mb ox oy oz pa bi translated">密歇根大学，“计算机视觉的深度学习”，2019 <a class="ae mx" href="https://web.eecs.umich.edu/~justincj/teaching/eecs498/FA2019/" rel="noopener ugc nofollow" target="_blank">讲座</a></li></ul></div><div class="ab cl pg ph hu pi" role="separator"><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl"/></div><div class="ij ik il im in"><p id="01ef" class="pw-post-body-paragraph lg lh iq li b lj mc ka ll lm md kd lo lp me lr ls lt mf lv lw lx mg lz ma mb ij bi translated"><em class="nc">最初发布于</em><a class="ae mx" href="https://erdem.pl/2021/05/introduction-to-attention-mechanism" rel="noopener ugc nofollow" target="_blank"><em class="nc">https://erdem . pl</em></a><em class="nc">。</em></p></div></div>    
</body>
</html>