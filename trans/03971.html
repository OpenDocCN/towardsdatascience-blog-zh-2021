<html>
<head>
<title>Google releases EfficientNetV2 — a smaller, faster, and better EfficientNet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">谷歌发布efficient net v2——一个更小、更快、更高效的网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/google-releases-efficientnetv2-a-smaller-faster-and-better-efficientnet-673a77bdd43c?source=collection_archive---------4-----------------------#2021-04-03">https://towardsdatascience.com/google-releases-efficientnetv2-a-smaller-faster-and-better-efficientnet-673a77bdd43c?source=collection_archive---------4-----------------------#2021-04-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4592" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">与最先进的技术相比，性能更高，同时训练速度提高5-10倍</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2b32f357ba4e8bfda6f11cf8e888fbce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*44kaH6LuxNReMLzG"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@fossy?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Fab Lentz </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><blockquote class="kz la lb"><p id="3380" class="lc ld le lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">通过渐进式学习，我们的EfficientNetV2在ImageNet和CIFAR/Cars/Flowers数据集上明显优于以前的模型。通过在相同的ImageNet21k上进行预训练，我们的EfficientNetV2在ImageNet ILSVRC2012上实现了87.3%的顶级准确率，比最近的ViT高2.0%，同时使用相同的计算资源训练速度快5-11倍。代码将在https://github.com/的<a class="ae ky" href="https://github.com/" rel="noopener ugc nofollow" target="_blank">发布</a>Google/automl/efficient net v2。</p></blockquote><p id="56d9" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">来源:<a class="ae ky" href="https://arxiv.org/pdf/2104.00298.pdf" rel="noopener ugc nofollow" target="_blank"> Arxiv </a></p><p id="253d" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">高效网络已经成为高质量和快速图像分类的SOTA。他们大约在2年前发布，因为他们的扩展方式而非常受欢迎，这使得他们的训练比其他网络快得多。几天前，谷歌发布了EfficientNetV2，它在训练速度和准确性方面都比EfficientNet有了很大的提高。在这篇文章中，我们将探讨这个新的高效网络是如何优于以前的。</p><p id="6659" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">DenseNets和EfficientNets等性能更好的网络的主要基础是以更少的参数获得更好的性能。当您减少参数的数量时，您通常会获得很多好处，例如更小的模型大小，使它们更容易适应内存。然而，这通常会降低性能。因此，主要的挑战是在不降低性能的情况下减少参数的数量。</p><p id="4879" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">这一挑战现在主要属于神经网络架构搜索(NAS)领域，该领域日益成为热门话题。在最佳情况下，我们将对某个神经网络给出一个问题描述，它将为该问题提供一个最佳的网络架构。</p><p id="a24f" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我不想在这篇文章中讨论效率网。但是，我想提醒大家效率网络的概念，以便我们能够找出架构中的主要差异，这些差异实际上会带来更好的性能。高效网络使用NAS来构建基线网络(B0)，然后使用“<strong class="lf iu">复合扩展”</strong>来增加网络容量，而不大幅增加参数数量。在这种情况下，最重要的度量标准是FLOPS(每秒浮点运算次数)和参数数量。</p><h2 id="bd42" class="mc md it bd me mf mg dn mh mi mj dp mk lz ml mm mn ma mo mp mq mb mr ms mt mu bi translated">1.渐进式训练</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/0b23d47188e7e3077c9b58a2f444e8f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JYFnEAodirdni_yB"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">乔纳森·博尔巴在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="cf4e" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">EfficientNetV2使用渐进式学习的概念，这意味着尽管训练开始时图像尺寸最初很小，但它们的尺寸会逐渐增大。这种解决方案源于这样一个事实，即EfficientNets的训练速度在高图像大小时开始受到影响。</p><p id="0112" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">渐进式学习并不是一个新概念，以前就有人用过。问题是，当它以前使用时，相同的正则化效果用于不同的图像大小。EfficientNetV2的作者认为这降低了网络容量和性能。这就是为什么他们动态地增加正则化和图像大小来解决这个问题。</p><p id="7d9c" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">仔细想想，很有道理。对小图像的大的正则化效果会导致欠拟合，而对大图像的小的正则化效果会导致过拟合。</p><blockquote class="kz la lb"><p id="2b96" class="lc ld le lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">借助改进的渐进式学习，我们的EfficientNetV2在ImageNet、CIFAR-10、CIFAR- 100、Cars和Flowers数据集上取得了出色的结果。在ImageNet上，我们实现了85.7%的顶级准确率，同时训练速度比以前的模型快3-9倍，体积小6.8倍</p></blockquote><p id="7306" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">来源:<a class="ae ky" href="https://arxiv.org/pdf/2104.00298.pdf" rel="noopener ugc nofollow" target="_blank"> Arxiv </a></p><p id="8fc0" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><strong class="lf iu"> 2。MB Conv层上的熔融MB Conv层</strong></p><p id="a372" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">EfficientNets使用一个称为"<strong class="lf iu">深度方向卷积层"</strong>的卷积层，这些层的参数和FLOPS数量较少，但它们无法充分利用现代加速器(GPU/CPU) [1]。为了解决这个问题，最近一篇名为“<strong class="lf iu"> MobileDets:搜索移动加速器的对象检测架构”</strong>的论文用一种新的层解决了这个问题，他们称之为“<strong class="lf iu">融合MB Conv层”。</strong>这一新层正在EfficientNetV2中使用。然而，他们不能简单地用融合层替换所有旧的MB Conv层，因为它有更多的参数。</p><p id="eb41" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">这就是为什么他们使用训练感知NAS来动态搜索融合和常规MB Conv层的最佳组合[1]。NAS的结果显示，在早期阶段用融合的层替换一些MB Conv层提供了更小模型的更好性能。它还示出了MB Conv层(沿着网络)的较小扩展比是更优的。最后，它表明内核越小，层数越多越好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/faf9a33d1cca042968bafca6c750f2da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qX3VVcRkKQogEfI4OxEETQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://arxiv.org/pdf/2104.00298.pdf" rel="noopener ugc nofollow" target="_blank"> Arxiv </a>。EfficientNetV2在ImageNet上拥有几乎最高的精确度，而参数数量却只有一半</p></figure><p id="e8b6" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><strong class="lf iu"> 3。更加动态的扩展方法</strong></p><p id="1a04" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我认为这里要学习的一个主要的有价值的想法是他们用来改进网络的方法。我认为总结这种方法的最佳方式是首先调查EfficientNet的问题，这是显而易见的，但下一步是<strong class="lf iu">开始使一些规则和概念更加动态，以更好地适应目标和目的。</strong>我们首先在渐进式学习中看到这一点，当时他们使正则化更加动态，以更好地适应图像大小，从而提高了性能。</p><p id="673e" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们现在看到这种方法再次被用于扩大网络规模。EfficientNet使用一个简单的复合缩放规则[1]平均放大所有阶段。EfficientNetV2的作者指出，这是不必要的，因为并非所有这些阶段都需要扩展来提高性能。这就是为什么他们使用非统一的缩放策略，在后期阶段逐渐添加更多的层。他们还添加了一个缩放规则来限制最大图像大小，因为EfficientNets往往会过度放大图像大小[1](导致内存问题)。</p><p id="37c4" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我认为这背后的要点是，早期的层并不真正需要扩展，因为在这个早期阶段，网络只关注高级功能。然而，当我们进入网络的更深部分并开始查看底层功能时，我们将需要更大的层来完全消化这些细节。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mx"><img src="../Images/eb5ebe4e07045e960328944b9630bf87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RCpnF6xOLJVRuGU3FQHPvQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://arxiv.org/pdf/2104.00298.pdf" rel="noopener ugc nofollow" target="_blank"> Arxiv </a></p></figure><p id="ba20" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><strong class="lf iu">参考文献:</strong></p><p id="3e8f" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">[1]Arxiv中的EfficientNetsV2</p></div></div>    
</body>
</html>