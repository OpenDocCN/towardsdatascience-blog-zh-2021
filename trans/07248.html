<html>
<head>
<title>Unit 3 Application) Evolving Neural Network for Time Series Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">单元3应用)用于时间序列分析的进化神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unit-3-application-evolving-neural-network-for-time-series-analysis-63c057cb1595?source=collection_archive---------23-----------------------#2021-07-01">https://towardsdatascience.com/unit-3-application-evolving-neural-network-for-time-series-analysis-63c057cb1595?source=collection_archive---------23-----------------------#2021-07-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="f303" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">进化计算课程</h2><div class=""/><div class=""><h2 id="53af" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">第三单元的高潮是应用我们的概念来发展一个预测时间序列问题的神经网络</h2></div><p id="4d25" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">大家好，欢迎回到进化计算的完整课程！在这篇文章中，我们将总结第3单元，这是一个非常令人期待的应用，为时间序列分析进化神经网络的权重！</p><p id="eb45" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为了更好地理解本材料，你需要知道的概念和材料是神经网络如何工作的基础，进化计算的全面概述，以及遗传算法如何工作。如果这是您第一次看到这个系列，请阅读我以前写的这两篇文章，以便您能够最好地理解我是如何开发我将很快详述的算法的:</p><div class="ln lo gp gr lp lq"><a rel="noopener follow" target="_blank" href="/unit-2-introduction-to-evolutionary-computation-85764137c05a"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">单元2)进化计算简介</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">进化计算和遗传算法概述！</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">towardsdatascience.com</p></div></div><div class="lz l"><div class="ma l mb mc md lz me mf lq"/></div></div></a></div><div class="ln lo gp gr lp lq"><a rel="noopener follow" target="_blank" href="/unit-3-genetic-algorithms-part-1-986e3b4666d7"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">单元3)遗传算法(第一部分)</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">遗传算法概述—主要是交叉和变异算子</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">towardsdatascience.com</p></div></div><div class="lz l"><div class="mg l mb mc md lz me mf lq"/></div></div></a></div><h1 id="1fdd" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">目录</h1><ul class=""><li id="9eec" class="mz na it kt b ku nb kx nc la nd le ne li nf lm ng nh ni nj bi translated">时间序列问题</li><li id="a764" class="mz na it kt b ku nk kx nl la nm le nn li no lm ng nh ni nj bi translated">神经网络综述</li><li id="a659" class="mz na it kt b ku nk kx nl la nm le nn li no lm ng nh ni nj bi translated">实现我们的神经网络</li><li id="c2c9" class="mz na it kt b ku nk kx nl la nm le nn li no lm ng nh ni nj bi translated">神经网络的设计</li><li id="120a" class="mz na it kt b ku nk kx nl la nm le nn li no lm ng nh ni nj bi translated">培训、验证和测试数据集</li><li id="e2ba" class="mz na it kt b ku nk kx nl la nm le nn li no lm ng nh ni nj bi translated">遗传算法</li><li id="1085" class="mz na it kt b ku nk kx nl la nm le nn li no lm ng nh ni nj bi translated">评估我们的算法</li><li id="a4db" class="mz na it kt b ku nk kx nl la nm le nn li no lm ng nh ni nj bi translated">通过反向传播训练的神经网络进行比较</li><li id="d8d7" class="mz na it kt b ku nk kx nl la nm le nn li no lm ng nh ni nj bi translated">最终代码和视频实现</li><li id="1c44" class="mz na it kt b ku nk kx nl la nm le nn li no lm ng nh ni nj bi translated">结论</li></ul><h1 id="a009" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">时间序列问题</h1><p id="87af" class="pw-post-body-paragraph kr ks it kt b ku nb kd kw kx nc kg kz la np lc ld le nq lg lh li nr lk ll lm im bi translated">时间序列分析是指任何一系列的数据，其中的数据是按时间顺序排列的。时间序列分析非常适用于许多场合，从经济到天气预测和预报。我们将要分析的问题是太阳黑子时间序列数据集。太阳黑子周期是发生在太阳上的太阳磁场活动。自1749年以来，太阳黑子的月平均数就有记录。我们的问题是要看看我们能多好地模拟这个时间序列问题，并预测未来的月平均数。这里我们看到了时间序列数据集在其整个生命周期中的样子:</p><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi ns"><img src="../Images/0d73808fdf445b2449a71f35f891c950.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n6OZnLpf7ZSYfu5clijU7Q.png"/></div></div><p class="od oe gj gh gi of og bd b be z dk translated">作者图片</p></figure><p id="1c05" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">你可以在Kaggle网站上找到这些数据:</p><div class="ln lo gp gr lp lq"><a href="https://www.kaggle.com/robervalt/sunspots" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">雀斑</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">月平均太阳黑子总数-1749年至2018年7月</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">www.kaggle.com</p></div></div><div class="lz l"><div class="oh l mb mc md lz me mf lq"/></div></div></a></div><h1 id="5e9f" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated"><strong class="ak">神经网络综述</strong></h1><p id="50b1" class="pw-post-body-paragraph kr ks it kt b ku nb kd kw kx nc kg kz la np lc ld le nq lg lh li nr lk ll lm im bi translated">我们将尝试通过前馈神经网络来解决这个问题。人工神经网络是受生物神经网络(大脑的基本单元)的启发而产生的。这些模型能够执行分类、回归和其他技术。神经网络在机器学习和人工智能中已经变得非常普遍，因为它们在许多问题类型中取得了意想不到的成功。因为我们将大量涉及神经网络，我将简要概述它们是如何工作的。如果你有任何使用神经网络的经验，请随意跳过这一部分，因为它主要是回顾。</p><p id="c464" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">神经网络的体系结构分为三个部分，即隐藏层数、每层的节点数和每层的激活函数。每层之间的权重由矩阵表示。我们可以在下面的基本示例中看到，我们有三个输入节点(意味着三个变量)，第一个隐藏层中有四个节点，第二个隐藏层中有五个节点，还有一个输出。</p><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/fc7ed0e2c672ef6cab2fb23645cf5c38.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*sb-374iPoEArtxq3BYDgZQ.png"/></div><p class="od oe gj gh gi of og bd b be z dk translated">作者图片</p></figure><p id="5756" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们用一个权重来表示两个神经元之间的每一个连接，这个权重可以组合起来形成一个矩阵。因此，我们的输入是一个[N，3]矩阵，N代表我们想要传递的观察值的数量，3是变量的数量。通过我们的网络向前传递就是简单地将矩阵相乘，在每一层应用我们的转移函数，然后得到我们的结果。图中没有列出的一个关键因素是各层的偏置矢量。偏差是在激活函数之后添加到每个观测值的[1，M]向量，其中M是该层的节点数。</p><p id="382e" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">神经网络通常通过某种形式的反向传播来训练；其中当前误差(MSE或交叉熵)从输出层传播回整个隐藏层，以调整权重，使得它们最小化误差。然而，在我们的应用中，我们将使用遗传算法来训练权重，而不是使用反向传播。</p><h1 id="7222" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">神经网络的设计</h1><p id="c133" class="pw-post-body-paragraph kr ks it kt b ku nb kd kw kx nc kg kz la np lc ld le nq lg lh li nr lk ll lm im bi translated">对于我们的问题，如何用一个神经网络来预测一个时间序列问题？对于一维时间序列问题，你只有一个单一的变量和一个时间指数，你怎么能预测基于时间的变量呢？在神经网络中解决时间序列问题的最常见实现是使用所谓的<strong class="kt jd">递归神经网络。</strong><strong class="kt jd"/>递归神经网络是一个<strong class="kt jd"> </strong>的网络，其中有一个来自输出的递归层，它被反馈到输入层，用于在随后的时间索引处的下一个值。然而，绕过这个实现的一个简单方法是简单地使输入层成为一个“窗口”,它跨越当前值之前的一些索引值。</p><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/26790f5a839a412c139da8a02ac9a8bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*gqGrn-1FWFiIRJ7dmN3TiA.png"/></div><p class="od oe gj gh gi of og bd b be z dk translated">作者图片</p></figure><p id="79ea" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">以上图为例，这里我们有一个时间序列问题的子集。我们的目标是预测黑盒中的值。对于第一行，我们希望预测值110.5，这可以通过将141.7、139.2和158作为神经网络的输入来实现。注意，在上面的例子中，我们的“窗口”大小是三。我们将使用之前的值(不包括当前值)作为预测的输入变量。窗口的确切大小取决于问题，通常需要测试。对于我们的问题，我们将测试不同的窗口大小。为了简单起见，我们的神经网络将有三个隐藏层，每个层有5个隐藏节点和ReLU激活函数。然而，输入的数量将根据“窗口”的大小而变化。</p><h1 id="f7af" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated"><strong class="ak">实现我们的神经网络</strong></h1><p id="863c" class="pw-post-body-paragraph kr ks it kt b ku nb kd kw kx nc kg kz la np lc ld le nq lg lh li nr lk ll lm im bi translated">因为我们将进化神经网络的权重，所以我们需要从头实现一个，因为在常见的Python实现中，这需要大量的操作。我们将实现我们的网络，以适应任意数量的层和每层的节点，但将只有每层的ReLU激活功能。我会试着解释下面的代码，但它处理神经网络矩阵乘法的细节，这可能会变得非常快；所以现在，如果你不明白它到底是如何工作的，不要担心，因为这不是本文的重点。</p><figure class="nt nu nv nw gt nx"><div class="bz fp l di"><div class="ok ol l"/></div></figure><h1 id="da6c" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">培训、验证和测试数据集</h1><p id="697c" class="pw-post-body-paragraph kr ks it kt b ku nb kd kw kx nc kg kz la np lc ld le nq lg lh li nr lk ll lm im bi translated">所有机器学习模型最常见的失败被称为<strong class="kt jd">过度拟合</strong>。当我们的模型有如此多的可调参数，以至于它开始记忆输入时，就会发生这种情况。因此，当预测一个它从未见过的值时，它的表现比它被训练的值差。下面是一个过拟合的例子，我们可以通过简单地增加多项式的次数来人为地最小化残差的误差；然而，这种预测对于数据来说是极度超参数化的，并且不能准确地代表实际趋势，因此对于以前没有见过的数据来说是极其错误的。</p><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div class="gh gi om"><img src="../Images/fde96139f8dc1a068f5d4ad83cc99252.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*zIiq8q9eqqlNDdqUgbf7xg.png"/></div><p class="od oe gj gh gi of og bd b be z dk translated">作者图片</p></figure><p id="1a99" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">所有机器学习和数据科学的目标都是创建简单但强大的模型，这些模型可以适应并准确地插入新值。有许多不同的方法来防止神经网络中的过拟合，从<strong class="kt jd">丢弃层</strong>到<strong class="kt jd">交叉验证</strong>；然而，最常见的仅仅是<strong class="kt jd">提前停止</strong>。为此，我们可以将数据集分为两个主要部分，训练数据集和测试数据集。我们使用我们的<strong class="kt jd">训练数据集</strong>来训练我们的模型，然后使用<strong class="kt jd">测试数据集</strong>来测试它的性能。这样，我们在我们的训练集上训练，一旦我们开始看到过度拟合，这意味着我们的测试集中的误差开始增加，我们就停止我们的算法。这就是所谓的<strong class="kt jd">提前停止。</strong>如下所示，我们的模型开始过度拟合训练数据，因为训练误差仍在减少，但测试数据停滞不前，并开始略有增加。在几次迭代之后，当我们的测试数据误差增加了某个值时，我们需要执行早期停止，以确保我们防止过度拟合。</p><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div class="gh gi on"><img src="../Images/01881ca57a039d6d648d49f6a606292c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*Qqd8bJ0LdmDqZnK0NL06aw.png"/></div><p class="od oe gj gh gi of og bd b be z dk translated">作者图片</p></figure><p id="5680" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">然而，这有一个关键问题，当我们的模型开始在我们的测试数据集上产生更坏的错误值时，我们就停止训练；这样，我们实际上已经在测试和训练数据集上训练了我们的模型，因为当我们的模型在测试集上表现更差时，我们已经停止了。这正是我们一开始想要摆脱的…为了解决这个问题，我们可以引入<strong class="kt jd">验证数据集</strong>，它取代了早期停止中的测试数据集。我们现在将数据集分成三部分，训练集、验证集和测试集。我们在训练集上训练我们的模型，然后我们使用验证集执行早期停止、参数调整和模型比较。在我们选择了最终模型及其最终架构之后，我们才评估测试数据集。通过这样做，我们可以确保我们的模型从未见过测试数据集中的值，以便获得我们模型的准确评估。</p><p id="2347" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这些是重要的概念，当我们为我们的神经网络实现遗传算法以防止过度拟合时，我们将回头来看。</p><h1 id="f6be" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">遗传算法</h1><p id="80cb" class="pw-post-body-paragraph kr ks it kt b ku nb kd kw kx nc kg kz la np lc ld le nq lg lh li nr lk ll lm im bi translated">现在是时候讨论我们进化算法的具体实现细节了。正如在以前的帖子中所讨论的，每个个体都是由其<strong class="kt jd">基因型</strong>和<strong class="kt jd">表现型</strong>组成的。<strong class="kt jd">基因型</strong>代表个体的实际遗传密码，<strong class="kt jd">表现型</strong>代表环境中的个体。在我们的问题中，基因型由权重矩阵和偏差矩阵组成，其中每个矩阵都是基因组中的一个基因。对于表型，一起编译的权重和偏差矩阵在环境中形成神经网络。既然我们知道了我们将如何编码我们的染色体，是时候讨论繁殖算子了。对于选择，我们将使用<strong class="kt jd">轮盘赌轮选择</strong>，它的工作原理是根据个体的适应度值从被选择的个体比例中创建一个累积分布:</p><figure class="nt nu nv nw gt nx"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="3591" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">对于交叉，我们将实现<strong class="kt jd">平均技术</strong>，它采用父值的线性组合。对于我们的问题，子代权重和偏差矩阵将只是父代矩阵的线性组合。为此，我们首先实例化一个新的EvolvableNetwork，但这次initialize等于False，因为我们不希望权重和偏差矩阵被初始化为随机值，因为我们将从父级创建它们:</p><figure class="nt nu nv nw gt nx"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="2dfd" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">对于突变，我们将简单地为所有矩阵的权重和偏差矩阵的每个条目添加一些小的随机值:</p><figure class="nt nu nv nw gt nx"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="9870" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">与我们以前的遗传算法实现不同，这个特定的实现将不具有用于变异、交叉或精英化概率的超参数。相反，我们可以通过去掉这些参数来降低调整算法的复杂性。为了做到这一点，我们的父母将创建一组四个孩子，这些孩子将与他们的父母一起被集中起来，最适合的个体将被选择存活下来。对于子代，四个都将通过不同系数值的交叉产生，然后最后两个交叉子代将通过不同的随机值进行变异。通过这样做，我们保证我们的算法将收敛，因为后代和父母中的最佳个体将被选择存活，并且我们减少了调整算法的需要，因为后代集将包含交叉和变异的个体。这是我们对双亲的复制函数的样子:</p><figure class="nt nu nv nw gt nx"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="4995" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在是我们的适应度函数的时间了，它将取我们的时间序列问题的预测值和实际值之间的均方误差:</p><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/23a383c9603f7b4783d556271857e230.png" data-original-src="https://miro.medium.com/v2/resize:fit:526/format:webp/1*-GM7AFX89lxF13gvWQbCyg.png"/></div><p class="od oe gj gh gi of og bd b be z dk translated">作者图片</p></figure><figure class="nt nu nv nw gt nx"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="6344" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">因为我们想要最小化MSE误差函数，所以我们需要缩放我们的适应值，使得较小的值产生较大的值，较大的值产生较小的值，然后最大化缩放的适应值。我们可以通过下面的函数做到这一点:</p><figure class="nt nu nv nw gt nx"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="3735" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">有关其工作原理的直观表示，请参见下图，其中x轴是原始适应值，y轴是缩放后的适应值。缩放后，接近0的值将趋向于1，然后对其执行标准的最大化。</p><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div class="gh gi op"><img src="../Images/f0b7ef3eb36085b14025911be542726c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*DmIppjPa1AeCNoJTdONZ-A.png"/></div><p class="od oe gj gh gi of og bd b be z dk translated">作者图片</p></figure><p id="be20" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">接下来，我们需要将数据分成训练集、验证集和测试集。我们将使用训练数据集来训练我们的算法，并使用验证集来比较我们的模型，并通过提前停止来防止过度拟合。最后，在我们选择了最终的模型之后，我们将通过测试数据集来评估它的准确性。我们将把我们的训练和验证数据传递给我们的进化算法。如前所述，我们将测试不同的窗口大小，因此我们将循环所有可能的窗口大小，创建数据，并测试我们的算法:</p><figure class="nt nu nv nw gt nx"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="f654" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">既然我们已经定义了所有的辅助函数，是时候定义我们进化算法的主体了。我们的算法将通过对训练数据进行训练来工作，并且如果当前代的验证数据的平均误差连续三代增加，则提前停止。在收敛或提前停止后，验证数据将再次用于从当前代中选择最佳模型。</p><figure class="nt nu nv nw gt nx"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="9e26" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">对于评估，我们将从每个窗口大小中找到具有最佳验证分数的模型，然后基于该窗口大小重新创建数据来评估我们的测试MSE分数。</p><figure class="nt nu nv nw gt nx"><div class="bz fp l di"><div class="ok ol l"/></div></figure><h1 id="b28c" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">评估我们的算法</h1><p id="bc90" class="pw-post-body-paragraph kr ks it kt b ku nb kd kw kx nc kg kz la np lc ld le nq lg lh li nr lk ll lm im bi translated">最后，是时候测试我们的遗传神经网络了。在编译了到目前为止给出的脚本之后，在种群大小为100个个体、最大突变值为0.1、网络架构为[5，5，5]的情况下，在从3到10的每个窗口大小下运行200代之后，结果如下:</p><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi oq"><img src="../Images/1622dcbbb2fbe633155ab5f333638f2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3-0rQq7PDNjMHIHncqPhSQ.png"/></div></div><p class="od oe gj gh gi of og bd b be z dk translated">作者图片</p></figure><p id="1dc6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">从每个窗口大小的最佳模型的结果来看，窗口大小为5的模型对于验证数据集具有最小的MSE，因此我们选择它作为最终模型。在测试数据集上对最终模型进行评估后，我们得到的误差为616.378。平均验证误差徘徊在618左右，标准偏差为36。对于视觉效果，以下是使用窗口大小为5:</p><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi or"><img src="../Images/2224eac35fb1a8c9c67b0bb808ec6757.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*POEkIP5gkLu1pDc_u-3Ztw.png"/></div></div><p class="od oe gj gh gi of og bd b be z dk translated">作者图片</p></figure><h1 id="ba22" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">测试通过反向传播训练的神经网络</h1><p id="a4ef" class="pw-post-body-paragraph kr ks it kt b ku nb kd kw kx nc kg kz la np lc ld le nq lg lh li nr lk ll lm im bi translated">现在我们已经评估了我们的算法，是时候用通过反向传播训练的神经网络来测试它，看看所有这些麻烦是否值得。因为在一天结束时，如果通过反向传播训练的神经网络能够胜过我们的遗传算法，那么为什么要浪费时间这样做呢？因为大多数人都安装了<strong class="kt jd"> scikit-learn </strong>，所以我将使用scikit-learn中的神经网络实现，称为<strong class="kt jd"> MLPRegressor </strong>。与我们的遗传算法一样，我将在不同的窗口大小下测试每个神经网络，并根据最佳验证数据集误差为每次运行选择最佳模型作为最终模型。为了确保公平的比较，通过反向传播训练的神经网络将使用相同的训练、验证和测试数据集。不幸的是，MLPRegressor中的提前停止机制从给定的训练数据创建验证数据集，而不是传入特定的数据。在scikit中培训MLPRegressor的效果如何-了解:</p><figure class="nt nu nv nw gt nx"><div class="bz fp l di"><div class="ok ol l"/></div></figure><p id="6661" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">因此，验证数据仅用于比较模型。结果如下:</p><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi os"><img src="../Images/8005d6df307e57eebe13c60c4994c1f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tQJPQCUMdWul6mN137YEkg.png"/></div></div><p class="od oe gj gh gi of og bd b be z dk translated">作者图片</p></figure><p id="0aec" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">从结果中我们可以看出，窗口大小为3产生最小的验证误差，这与遗传算法有很大的不同；然而，窗口大小为3的验证分数与大小为5的遗传算法的验证分数相当。为了比较这两个框架，我们可以通过使用验证误差的平均值和标准偏差来并列。遗传算法具有较好的平均验证误差4.65%和较小的标准偏差25%。此外，其测试均方误差优于4.18%。因此，有理由得出结论，对于这个特定的问题，我们的遗传算法在训练神经网络方面优于反向传播算法。下面是我们对通过反向传播训练的神经网络的整个时间序列数据集的预测。</p><figure class="nt nu nv nw gt nx gh gi paragraph-image"><div role="button" tabindex="0" class="ny nz di oa bf ob"><div class="gh gi ot"><img src="../Images/f799206ca3c7d453873fa189788b5172.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YfBBJXFxZLEWfxEoPMXznQ.png"/></div></div><p class="od oe gj gh gi of og bd b be z dk translated">作者图片</p></figure><h1 id="907d" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">最终代码和视频实现</h1><p id="4788" class="pw-post-body-paragraph kr ks it kt b ku nb kd kw kx nc kg kz la np lc ld le nq lg lh li nr lk ll lm im bi translated">这篇文章中有很多代码，这里有一个到我的GitHub的链接，整个脚本是完整的，实际上和我在这里使用的一样。运行它，看看奇迹发生吧！</p><div class="ln lo gp gr lp lq"><a href="https://github.com/OUStudent/EvolutionaryComputationCourse/blob/main/Unit3/time_series_problem.py" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">学生/进化计算课程</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">通过在GitHub上创建一个帐户，为ou student/evolutionary computationcourse开发做出贡献。</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">github.com</p></div></div><div class="lz l"><div class="ou l mb mc md lz me mf lq"/></div></div></a></div><p id="0258" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">对于任何想要更深入了解代码的人，我将在这里制作一个视频实现视频，并放在这里。(也就是说，如果你看到这条消息，但网址没有发布，请等待一周左右)</p><h1 id="e7c6" class="mh mi it bd mj mk ml mm mn mo mp mq mr ki ms kj mt kl mu km mv ko mw kp mx my bi translated">结论</h1><p id="7119" class="pw-post-body-paragraph kr ks it kt b ku nb kd kw kx nc kg kz la np lc ld le nq lg lh li nr lk ll lm im bi translated">在这篇文章中，我们应用了我们在过去两篇文章中学到的知识来进化用于时间序列分析的神经网络的权重。通过将我们的数据分成训练、验证和测试集，它允许我们精确地训练、比较和评估我们的模型。结果表明，对于给定的时间序列问题，遗传算法在训练神经网络方面优于反向传播算法。这些结果非常有希望。</p><p id="84da" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在计算智能领域，将遗传算法应用于神经网络实际上是一个被称为<strong class="kt jd">神经进化</strong>的子领域。神经进化可以有许多不同的形状和大小。在这个范例中，不仅权重被进化，而且层数、节点数、激活函数和神经元连接方向也被进化。当适应度函数不可微时，神经进化<strong class="kt jd"> </strong>通常应用于强化型问题，因此不能应用反向传播；或者当神经网络规模较小时，如本例所示。不幸的是，<strong class="kt jd"> </strong>神经进化<strong class="kt jd"> </strong>并不是训练<strong class="kt jd">深度神经网络</strong>的竞争领域，因为这些网络具有成千上万个用于权重连接的参数，这使得标准遗传算法中的交叉和变异极其耗时，因为评估每个权重矩阵需要O(n*m)。然而，神经进化是一个越来越感兴趣的领域，不是为了进化深度神经网络的权重，而是为了进化结构和超参数，然后使用标准的数值方法(例如反向传播)来训练这些结构和超参数。这种情况的一个例子可以是发展每层的节点数、层激活函数、包含退出或卷积层、以及用于反向传播的算法超参数，例如动量和学习速率。这被称为<strong class="kt jd">自动机器学习</strong>，不再需要数据科学家来“调整”算法；相反，利用遗传算法来为给定的神经网络找到最佳的超参数集和结构。</p><p id="6990" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">总之，这篇文章总结了单元3)遗传算法。尽管这个单元已经写了四篇文章，时间有点长，但我希望它对你理解遗传算法的工作原理以及它们在实践中的应用非常有帮助。在下一篇文章中，我们将开始<strong class="kt jd">单元4)遗传编程</strong>，这将是非常短的，并在这里处理相同的时间序列问题！</p></div></div>    
</body>
</html>