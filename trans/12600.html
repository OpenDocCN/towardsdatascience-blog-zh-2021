<html>
<head>
<title>Introduction to Geometric Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">几何深度学习简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/geometric-deep-learning-da09e7c17aa3?source=collection_archive---------12-----------------------#2021-12-27">https://towardsdatascience.com/geometric-deep-learning-da09e7c17aa3?source=collection_archive---------12-----------------------#2021-12-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="5a84" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/geometric-deep-learning" rel="noopener" target="_blank">几何深度学习</a></h2><div class=""/><div class=""><h2 id="1e2d" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated"><strong class="ak">机器学习的埃尔兰根计划</strong></h2></div><p id="0da8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lk">的一系列博文，关于</em> <a class="ae ll" href="https://geometricdeeplearning.com/lectures/" rel="noopener ugc nofollow" target="_blank"> <em class="lk">几何深度学习(GDL)课程</em> </a> <em class="lk">，在 AMMI 计划；</em> <a class="ae ll" href="https://aimsammi.org/" rel="noopener ugc nofollow" target="_blank"> <em class="lk">非洲机器智能硕士</em> </a> <em class="lk">，所教</em> <a class="ae ll" href="https://www.imperial.ac.uk/people/m.bronstein" rel="noopener ugc nofollow" target="_blank"> <em class="lk">迈克尔·布朗斯坦</em> </a> <em class="lk">，</em> <a class="ae ll" href="https://cims.nyu.edu/~bruna/" rel="noopener ugc nofollow" target="_blank"> <em class="lk">琼·布鲁纳</em> </a> <em class="lk">，</em> <a class="ae ll" href="https://tacocohen.wordpress.com/" rel="noopener ugc nofollow" target="_blank"> <em class="lk">塔科·科恩</em> </a> <em class="lk">，以及</em> <a class="ae ll" href="https://petar-v.com/" rel="noopener ugc nofollow" target="_blank"> <em class="lk">佩塔尔·韦利奇科维奇</em></a></p><p id="994b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">深度学习的快速发展创造了不同的神经网络架构，这些架构在各个数据科学领域都取得了成功。同时，我们在这些架构之间没有一个明确的统一原则，所以很难理解它们之间的关系。在这篇文章中，我们回顾了各种数学家对<em class="lk">对称性</em>的定义，以及<em class="lk">埃尔兰根程序</em>的出现，以及它是如何以<em class="lk">几何深度学习</em>的名义进入深度学习的。我们将看到深度学习的当前状态如何让我们想起 19 世纪的许多几何。</p><p id="4404" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们主要参考的是四位导师的<a class="ae ll" href="https://arxiv.org/abs/2104.13478" rel="noopener ugc nofollow" target="_blank"> <em class="lk"> GDL 原书</em> </a>，以及<a class="ae ll" href="https://geometricdeeplearning.com/lectures/" rel="noopener ugc nofollow" target="_blank"> <em class="lk"> GDL 课程</em></a>at<a class="ae ll" href="https://aimsammi.org/" rel="noopener ugc nofollow" target="_blank"><em class="lk">AMMI</em></a><em class="lk">。</em></p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lm"><img src="../Images/b5f412812bda78dc5cc679e0e2bceec0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RdgL6chbQ3TYEUCy"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">来自 GDL 的图片课程:第一讲</p></figure><p id="1a36" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lk">这篇博文与</em><a class="ae ll" href="https://www.linkedin.com/in/mohammedelfatih-salah-0b29b4169/?originalSubdomain=sd" rel="noopener ugc nofollow" target="_blank"><em class="lk">MohammedElfatih Salah</em></a>合著</p><p id="1540" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi md translated"><span class="l me mf mg bm mh mi mj mk ml di">如果</span>你想要一个简单的词来描述我们将要谈论的内容，并对几何深度学习(GDL)的思想有一个直觉，那将是<em class="lk">对称性</em>。让我们回顾历史，看看数学家们是如何定义这个词的。20 世纪最优秀的数学家之一 H. Weyl 给出了关于 T4 对称性的第一个定义。Weyl 在他关于<em class="lk">对称性</em>的话里说:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mm"><img src="../Images/c907765dd9bb2f5ea71e501730c935b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bg69dn2nCePdGzKV3iWMeA.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated"><em class="mc">图片</em>来自 GDL 课程:第一讲</p></figure><p id="1431" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">追溯到古希腊人，他们也用这个术语来模糊地表达比例、和谐和音乐之美。</p><p id="ce2a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">第一个例子是<em class="lk">五个正多面体</em>，或者是雅典哲学家柏拉图提出的柏拉图立体。柏拉图立体是三维空间中的凸正多面体。在正多面体中，面在形状和大小上是相同的，所有的角和所有的边也是相同的。并且同样数量的面在每个顶点相遇。</p><p id="4452" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">类似的例子来自古希腊，对称形状的水结晶是由数学家 j .开普勒提出的。他写了一本名为<a class="ae ll" href="https://books.google.sn/books/about/The_Six_Cornered_Snowflake.html?id=yE8yTUFWLXgC&amp;source=kp_book_description&amp;redir_esc=y" rel="noopener ugc nofollow" target="_blank"> <em class="lk">的关于六角雪花的书</em> </a>，在书中他解释了雪花的六面对称。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lm"><img src="../Images/c8e69db75151a7fc2422cd934975ee0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*55u7cy7RwnVpgFmT"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated"><em class="mc">图片</em>来自 GDL 课程:第一讲</p></figure><p id="e6ce" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lk">欧几里得几何</em>也是可以追溯到古希腊。另一位希腊数学家欧几里得对欧几里得几何定义如下:</p><blockquote class="mn mo mp"><p id="71d2" class="ko kp lk kq b kr ks ka kt ku kv kd kw mq ky kz la mr lc ld le ms lg lh li lj ij bi translated">在一个平面上，给定一条直线和一个不在该直线上的点，至多可以通过该点画出一条与给定直线平行的直线。</p></blockquote><p id="87bf" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">随着 19 世纪的到来，又经过了<a class="ae ll" href="https://en.wikipedia.org/wiki/Projective_geometry" rel="noopener ugc nofollow" target="_blank"> <em class="lk">射影几何</em> </a>的发展；到了法国人庞斯列，这种<em class="lk">欧几里得几何学</em>告一段落。<em class="lk">射影几何</em>中，点和线是可以互换的；没有任何两条直线恰好在一点上是平行的。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mt"><img src="../Images/4877ea03108d9d343fb2f1ebb98d971d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yw0564fWN80AS3J41gKgNg.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated"><em class="mc">图片</em>来自 GDL 课程——作者编辑</p></figure><p id="e210" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">有人会问非欧几何的第一次出现是什么？我们会说它来自俄罗斯数学家罗巴切夫斯基。他指出，在任何一点都有不止一条线可以延伸通过该点，并与该点不属于的另一条线平行。类似的想法也有，但我们在这里就不解释了，就是德国数学家 b .黎曼的曲面的<a class="ae ll" href="https://en.wikipedia.org/wiki/Differential_geometry#:~:text=Differential%20geometry%20is%20a%20mathematical,linear%20algebra%20and%20multilinear%20algebra." rel="noopener ugc nofollow" target="_blank"><em class="lk"/></a>(<em class="lk">黎曼几何</em>)。</p><p id="0ded" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi md translated">在所有这些发展之后，接近 19 世纪末，数学家们争论哪种几何是正确的，以及应该如何定义它。直到德国数学家 f·克莱因发表了<em class="lk">埃尔兰根纲领</em>，他在其中给出了所有这些问题的答案。</p><blockquote class="mn mo mp"><p id="4f84" class="ko kp lk kq b kr ks ka kt ku kv kd kw mq ky kz la mr lc ld le ms lg lh li lj ij bi translated">当 F. Klein 提出 Erlangen 计划时，他只有 23 岁，在这个年龄，他被任命为巴伐利亚大学的教授。在这个埃尔兰根计划中，克莱恩将几何描述为对不变量和对称性的研究；这意味着在某一类变换下不变的性质。</p></blockquote><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mu"><img src="../Images/ec665f3ccec1db99364ab196cff650b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lUjxX2ojbb928GaY1OHNFQ.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated"><em class="mc">图片</em>来自 GDL 课程:第一讲</p></figure><p id="a608" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">所以我们可以从克莱因的话中清楚地看到，适当选择对称性可以定义不同的几何形状。例如，定义<em class="lk">欧几里德几何</em>的对称性是刚性运动。这些是平移、反射和旋转，它们保留了角度、距离、面积、线的平行度和交点等属性。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mv"><img src="../Images/d2cf0e98b944fadcbd40f6a8ee9f4b45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BxRLLJyuZQA7xpDcFLynZQ.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated"><em class="mc">图片</em>来自 GDL 课程:第一讲</p></figure><p id="03d9" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi md translated">另一件重要的事情是，这个埃尔兰根计划(T21)扩展到了其他领域，尤其是在物理学领域。这里一个明显的例子是<em class="lk"> Noether 定理</em>，它指出一个物理系统运行的每一个明显的对称性都有一个相应的保护定律。在这个定理之前，如果你想发现能量守恒，你必须做非常详细的材料实验观察和测量，以确保能量保持不变，即使有一些微小的误差。但是<em class="lk"> Noether 定理</em>说能量守恒源于时间的平移对称性。所以相对清楚的是，你的实验结果，无论是昨天做的，今天做的，还是明天做的，都是一样的。</p><blockquote class="mn mo mp"><p id="fc36" class="ko kp lk kq b kr ks ka kt ku kv kd kw mq ky kz la mr lc ld le ms lg lh li lj ij bi translated">我们还可以提到诺贝尔物理学家之一 p .安德森的话:"说物理学是对对称性的研究只是稍微夸大了一点。"</p></blockquote><p id="590b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi md translated">在经历了关于几何和对称性的漫长历史背景之后，你可能会问这与深度学习有什么关系。简单的答案是，深度学习的现状让我们想起了 19 世纪的许多几何。由于我们对于不同类型的数据有不同的神经网络架构(比如对于特殊数据有 CNN，对于顺序数据有 transformers，对于时态数据有 RNNs)，但是这些方法之间没有明确的统一原则。因此，很难理解它们之间的关系，这导致了相同概念的重新发明。<em class="lk">几何深度学习</em>揭示了统一在所有这些架构背后的基本原理。我们希望在<em class="lk">埃尔兰根计划</em>的本质上实现这种统一，这将在后面的帖子中澄清。</p><p id="aa9f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi md translated"><span class="l me mf mg bm mh mi mj mk ml di"> B </span>另外，正常的问题会是为什么要研究<em class="lk">几何深度学习，</em>或者<em class="lk"> GDL </em>的目标是什么。我们可以说 GDL 有两个目的。首先，它解释了为什么当前最先进的架构是成功的(因为它们尊重数据的不变性，我们将在后面的帖子中解释)。第二，它提出了主要原则，如果我们遵循这些原则，我们可以为未来的任务构建更好的架构(我们还将有另一篇关于<em class="lk"> GDL 蓝图</em>的帖子)。</p><blockquote class="mn mo mp"><p id="ac08" class="ko kp lk kq b kr ks ka kt ku kv kd kw mq ky kz la mr lc ld le ms lg lh li lj ij bi translated">“几何深度学习”一词在 2017 年的一篇论文中流行起来:<a class="ae ll" href="https://arxiv.org/abs/1611.08097" rel="noopener ugc nofollow" target="_blank">几何深度学习:超越欧几里德数据</a>发表在布朗斯坦等人撰写的 IEEE 信号处理杂志上。最近，布朗斯坦、布鲁纳、科恩和韦利奇科维奇写了一篇长文，这是一本名为<a class="ae ll" href="https://arxiv.org/abs/2104.13478" rel="noopener ugc nofollow" target="_blank">几何深度学习:网格、组、图、测地线和量规的书的预览。</a></p></blockquote><p id="c804" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi md translated"><span class="l me mf mg bm mh mi mj mk ml di">在</span>这一系列的帖子中，我们将详细解释如何通过两个属性<em class="lk">对称性</em>和<em class="lk">比例分离</em>我们可以开发一个<em class="lk"> GDL 蓝图</em>作为当前最先进架构的框架。我们将在<em class="lk"> GDL 蓝图</em>的管道中讨论所谓的<em class="lk">几何域</em>或<em class="lk"> 5 Gs </em>，包括<em class="lk">网格、组、图、测地线和量规、</em>及其适当的结构。</p><p id="fc56" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">参考文献</strong>:</p><ul class=""><li id="4fb4" class="mw mx iq kq b kr ks ku kv kx my lb mz lf na lj nb nc nd ne bi translated"><a class="ae ll" href="https://geometricdeeplearning.com/lectures/" rel="noopener ugc nofollow" target="_blank"> GDL 课程</a>，(<a class="ae ll" href="https://aimsammi.org/" rel="noopener ugc nofollow" target="_blank"> AMMI </a>，2021 年夏季)。</li><li id="c725" class="mw mx iq kq b kr nf ku ng kx nh lb ni lf nj lj nb nc nd ne bi translated">M. M .布朗斯坦第一讲[ <a class="ae ll" href="https://youtu.be/PtA0lg_e5nA" rel="noopener ugc nofollow" target="_blank">视频</a> | <a class="ae ll" href="https://bit.ly/3iw6AO9" rel="noopener ugc nofollow" target="_blank">幻灯片</a>。</li><li id="f63c" class="mw mx iq kq b kr nf ku ng kx nh lb ni lf nj lj nb nc nd ne bi translated">米（meter 的缩写））m .布朗斯坦、j .布鲁纳、t .科恩和 p .韦利奇科维奇，<a class="ae ll" href="https://arxiv.org/abs/2104.13478" rel="noopener ugc nofollow" target="_blank">几何深度学习:网格、组、图形、测地线和量规</a> (2021)。</li></ul><p id="c948" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们感谢 Rami Ahmed 对草案提出的宝贵意见。</p></div></div>    
</body>
</html>