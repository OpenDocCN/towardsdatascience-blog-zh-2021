<html>
<head>
<title>Delight: The New &amp; Improved Spark UI &amp; Spark History Server is now Generally Available</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">令人高兴的是:新的和改进的Spark用户界面和Spark历史服务器现在已经上市</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/delight-the-new-improved-spark-ui-spark-history-server-is-now-generally-available-79e72adc3d65?source=collection_archive---------35-----------------------#2021-05-05">https://towardsdatascience.com/delight-the-new-improved-spark-ui-spark-history-server-is-now-generally-available-79e72adc3d65?source=collection_archive---------35-----------------------#2021-05-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="61e6" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Delight是一个免费的、托管的、跨平台的Apache Spark监控仪表板，带有内存和CPU指标，希望能让您满意！</h2></div><p id="1b4a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一年前，我们在TowardsDataScience上发布了一篇被广泛分享的博文:<a class="ae lb" rel="noopener" target="_blank" href="/spark-delight-were-building-a-better-spark-ui-1b463840e243">我们正在构建一个更好的Spark UI </a>！</p><p id="ef0e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">今天，经过大量的工程工作，我们很自豪地最终发布了<a class="ae lb" href="https://www.datamechanics.co/delight" rel="noopener ugc nofollow" target="_blank"> Delight </a>，这是我们为<a class="ae lb" href="https://www.datamechanics.co/apache-spark" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>提供的免费托管跨平台监控仪表板。</p><p id="9291" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它也可以在Databricks、EMR、Dataproc、HDInsight、HDP/CDP和开源平台上工作(任何spark-submit，或者使用spark-on-kubernetes操作符，或者使用Apache Livy)。</p><p id="6677" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Delight帮助您理解和提高Spark应用程序的性能。它提供:</p><ul class=""><li id="1699" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">以Spark为中心的CPU和内存指标，我们希望会让你高兴！</li><li id="d281" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">Spark UI——因此您不需要自己运行Spark历史服务器。</li></ul><p id="4462" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将在本文中讨论的内容:</p><ol class=""><li id="ec12" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lq li lj lk bi translated">项目的动机和时间表</li><li id="74b4" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lq li lj lk bi translated">它的高层架构</li><li id="61e2" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lq li lj lk bi translated">浏览主屏幕以及它们如何帮助您的日常工作</li></ol><h1 id="a4ec" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">我们对快乐的愿景和动机</h1><p id="2f7c" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">很难对Spark UI的应用程序的性能进行故障诊断。UI中有一些有用的信息，但是它们被淹没在大量的噪音中，理解这些信息需要大量的部落知识。此外，Spark UI不会显示关键的系统指标，如CPU使用率、内存使用率和I/O。</p><p id="1c51" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为此，您必须使用一个通用的可观察性工具(如Ganglia)。这些工具的问题是，它们不是为Spark设计的。您需要在每个节点的指标之间跳转，尝试在头脑中得到一个粗略的估计，然后查看时间戳，在它们和Spark UI之间来回跳转。</p><p id="9988" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们在<a class="ae lb" href="https://www.datamechanics.co" rel="noopener ugc nofollow" target="_blank"> Data Mechanics </a>的任务是让Apache Spark对开发人员更友好，更具成本效益。这就是为什么我们建立了我们的托管<a class="ae lb" href="https://www.datamechanics.co/apache-spark-on-kubernetes" rel="noopener ugc nofollow" target="_blank"> Spark-on-Kubernetes </a>平台(在AWS、GCP和Azure上可用)，该平台自动化基础设施参数和Spark配置，以使我们的客户管道稳定和高性能。</p><p id="c4d0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还希望简化数据科学家和工程师的开发体验，而可观察层是这个难题的关键部分。我们想让任何人都容易理解他们的Spark代码的性能。</p><p id="39b6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是我们着手为Spark构建一个开源监控仪表板Delight的原因。2020年6月，我们在一篇被广泛分享的博文中分享了<a class="ae lb" href="https://www.datamechanics.co/blog-post/building-a-better-spark-ui-data-mechanics-delight" rel="noopener ugc nofollow" target="_blank">我们对快乐的愿景，该博文以下面的GIF为特色:</a></p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi mo"><img src="../Images/f732aa16d2380b6bfc1acb47ab6f43fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Qs2SXH0uhNaQIwmv.gif"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">我们的喜悦设计原型，2020年6月出版。图片作者。</p></figure><p id="d6b5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">受到数百名注册者和我们公告上的评论的鼓励，我们开始构建Delight，这是一项大规模的工程工作。</p><ul class=""><li id="03cb" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">2020年11月，我们发布了一个MVP，其中包含一个托管仪表板，让您可以访问已终止应用程序的Spark UI(避免您运行和维护自己的Spark历史服务器的麻烦)。</li><li id="b663" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">在Q1 2021中，我们在内部向客户发布了Delight，并重复了他们给出的反馈，修复了我们发现的许多漏洞和稳定性问题。</li><li id="d686" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">今天，要实现我们的最终愿景，还有很多工作要做。但是，快乐已经被证明对许多人有价值，所以我们很高兴向Spark社区开放它！</li></ul><h1 id="875b" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">架构:开源代理+托管后端</h1><p id="6de4" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">Delight可以在任何Spark平台上免费工作，包括Databricks、Amazon EMR、Google Dataproc或开源的Spark-on-Kubernetes或Spark-on-YARN设置。它与使用spark-submit、Apache Livy或Spark-on-Kubernetes操作符运行Spark应用程序兼容。</p><p id="7c9a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">愉悦包括:</p><ul class=""><li id="0ec9" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">一个<a class="ae lb" href="https://github.com/datamechanics/delight" rel="noopener ugc nofollow" target="_blank">开源代理</a>运行在您的Spark应用程序中，将Spark事件度量流式传输到Delight后端。</li><li id="d3b2" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">一个托管的后端负责收集这些指标，解析它们，并在https://delight.datamechanics.co的<a class="ae lb" href="https://delight.datamechanics.co/" rel="noopener ugc nofollow" target="_blank">托管仪表板</a></li></ul><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ne"><img src="../Images/506471f29ff2e8352fc752de6b0706ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Zhf6ZndZUeNEo8I5.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">高层架构:一个开源代理&amp;一个托管后端。图片作者。</p></figure><p id="3789" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Delight收集的指标包含关于Spark应用程序执行的底层元数据，比如每个任务读取/写入了多少数据，使用了多少内存和cpu。这些指标被称为Spark事件日志(<a class="ae lb" href="https://github.com/datamechanics/delight/blob/main/documentation/resources/example_spark_event_log.txt" rel="noopener ugc nofollow" target="_blank">查看示例</a>)，它们是让Spark历史服务器回放已完成应用程序的Spark UI的相同信息。</p><p id="de4b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些指标使用您可以在我们的控制面板中生成的秘密访问令牌进行保护，该令牌可以唯一地标识您。它们不会与任何第三方共享，并且会在30天后自动从我们的服务器中删除。每个组织最多可存储1，000个应用程序(如果您在30天内运行超过1，000个应用程序，我们将开始删除最旧的应用程序)。</p><h1 id="40d5" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">浏览主屏幕</h1><h1 id="9079" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">1.主仪表板</h1><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ne"><img src="../Images/2d230453342acd83a666b248545b4315.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JV-CkRDKsR_mlHL-.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">Delight的主仪表板列出了您最近完成的所有Spark应用程序。图片作者。</p></figure><p id="8477" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">‍When:你登录到Delight，你会看到这个表格，是你最近运行的Spark应用程序。请注意，实时应用程序还不可见，它们只在完成几分钟后才会出现。该屏幕中的大部分信息应该是不言自明的，除了3列:Spark任务、CPU和效率。在解释它们之前，先快速回顾一下Spark分布式执行是如何工作的。</p><blockquote class="nf ng nh"><p id="4416" class="kf kg ni kh b ki kj jr kk kl km ju kn nj kp kq kr nk kt ku kv nl kx ky kz la ij bi translated"><em class="iq">在一个火花</em> <strong class="kh ir"> <em class="iq">应用</em> </strong> <em class="iq">中，你有一个单独的</em> <strong class="kh ir"> <em class="iq">驱动</em> </strong> <em class="iq">进程(你的应用的“大脑”)，和许多</em> <strong class="kh ir"> <em class="iq">执行</em> </strong> <em class="iq">进程。驱动负责理解你的代码，把它拆分成</em> <strong class="kh ir"> <em class="iq">作业</em></strong><em class="iq"/><strong class="kh ir"><em class="iq">阶段</em> </strong> <em class="iq">和</em> <strong class="kh ir"> <em class="iq">任务</em> </strong> <em class="iq">。阶段是一组可以在执行器上并行执行的任务。一个执行器内核一次可以运行(最多)一个Spark任务；换句话说，具有4个CPU的Spark执行器可以并行运行多达4个任务。</em></p></blockquote><p id="56cc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在让我们定义三列:</p><ul class=""><li id="463d" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated"><strong class="kh ir">星火任务</strong>。这是应用程序中所有任务持续时间的总和。<em class="ni">旁注:这是数据力学平台</em> <a class="ae lb" href="https://www.datamechanics.co/pricing" rel="noopener ugc nofollow" target="_blank"> <em class="ni">定价</em> </a> <em class="ni">所依据的度量。</em></li><li id="72f1" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated"><strong class="kh ir"> CPU </strong>。这是你的Spark执行器生命周期的总和，乘以分配给每个执行器的核心数。换句话说，这是您的“执行者核心正常运行时间”。这一指标通常与您的基础设施成本成比例。</li><li id="b116" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated"><strong class="kh ir">效率</strong>。这是Spark任务除以CPU的比率，用百分比表示。这表示CPU资源有效用于运行Spark任务的时间比例。100%是理想的(完美的并行)，0%意味着您的计算资源被浪费了(您有运行的容器，但它们是空闲的)。</li></ul><p id="fd35" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是我们关注数据机制的关键指标之一，因为我们的平台具有自动化功能(自动扩展、自动调整等)来提高我们客户的效率，从而降低他们的云成本(查看这个从 EMR迁移过来的客户的<a class="ae lb" href="https://www.datamechanics.co/blog-post/migrating-from-emr-to-spark-on-kubernetes-with-data-mechanics" rel="noopener ugc nofollow" target="_blank">故事以了解更多信息)。</a></p><h1 id="1af1" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">2.执行器核心使用情况</h1><p id="c4b7" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated"><strong class="kh ir"> ‍ </strong>一旦你点击一个特定的应用程序，你就会进入一个应用程序概述页面，上面有高级统计数据和一个指向顶部Spark UI的链接。下一个信息是executor核心使用图。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ne"><img src="../Images/a68e6d69bc8a7d1200e14b3b58cf4628.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yQRCXpWAJlzJec6A.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">executor核心使用情况图提供了应用程序性能的高级视图。图片作者。</p></figure><p id="ba6e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">executor cores usage graph将Spark在应用程序执行期间测量的低级CPU指标汇总到一个简单的可视化概览中。首先，您会看到一份executor内核使用情况的摘要，按主要类别进行了分类(单击ℹ️图标阅读它们的定义):</p><ul class=""><li id="cd54" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated"><strong class="kh ir"> CPU </strong> —实际计算Spark任务所花费的时间。</li><li id="680c" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated"><strong class="kh ir"> I/O </strong> —等待读取或写入数据(通常来自网络)所花费的时间。<em class="ni">注意:Spark目前将python进程中完成的工作视为I/O(从JVM的角度来看，这是等待Python提供数据的I/O)。例如，当您执行python用户定义的函数时，就会发生这种情况。查看这篇</em> <a class="ae lb" href="https://stackoverflow.com/questions/61816236/does-pyspark-code-run-in-jvm-or-python-subprocess" rel="noopener ugc nofollow" target="_blank"> <em class="ni"> StackOverflow帖子</em> </a> <em class="ni">可以更好地理解JVM和Python如何在PySpark中协同工作。</em> <strong class="kh ir"> ‍ </strong></li><li id="1081" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated"><strong class="kh ir"> Shuffle </strong> —在Shuffle(Spark执行器之间的数据交换阶段)期间等待数据块被写入或提取所花费的时间。<strong class="kh ir"> ‍ </strong></li><li id="b6e0" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated"><strong class="kh ir">垃圾收集</strong>—JVM进行垃圾收集所花费的时间。对于大多数(健康的)应用程序，这不应该超过几个百分点。<strong class="kh ir"> ‍ </strong></li><li id="4b7f" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated"><strong class="kh ir">Spark Internals</strong>—Spark花费在调度程序延迟、任务序列化和反序列化等开销操作上的时间。同样，这对于大多数应用程序来说应该很小。<strong class="kh ir"> ‍ </strong></li><li id="c789" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated"><strong class="kh ir">一些内核空闲</strong> —任务被执行的时间，但是只在一部分执行程序内核上。高值是不完全平行的标志。</li><li id="9f6d" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated"><strong class="kh ir">所有内核空闲</strong> —无火花任务运行的时间。这可能是完全闲置，这种情况经常发生，例如当你以交互方式使用Spark时，然后休息一下。或者这可能意味着一些非Spark工作正在发生，例如你可能在驱动上执行纯Python或Scala代码，所以所有的执行器都是空闲的。</li></ul><p id="89bb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些信息会显示在一个图表上，其中X轴是应用程序的时间轴，Y轴是您拥有的执行器核心数(如果您启用了动态分配，它可能会随时间而变化)。在这个图表下，你可以看到你的Spark工作和阶段的时间表。</p><p id="2760" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此图的主要好处是，您可以非常快速地将注意力集中在应用程序的主要性能瓶颈上。在本例中，很明显<strong class="kh ir"> job-1/stage-1 </strong>占用了大部分应用时间。大的灰色区域表示大多数内核在此期间处于空闲状态。如果您单击“stage-1”，您将被带到Spark UI，因此您可以进一步对此进行故障诊断(在本例中，问题是该阶段只有2个任务)。</p><h1 id="c00f" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">3.执行者峰值内存使用</h1><p id="c797" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">此图仅在您使用Spark 3.0或更高版本时可见，因为它依赖于Spark 3.0中引入的新功能(<a class="ae lb" href="https://issues.apache.org/jira/browse/SPARK-23429" rel="noopener ugc nofollow" target="_blank"> SPARK-23429 </a>和<a class="ae lb" href="https://issues.apache.org/jira/browse/SPARK-27189" rel="noopener ugc nofollow" target="_blank"> SPARK-27189 </a>)。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ne"><img src="../Images/4d8c18ffdf1ba92d20530c45410e97d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6xXkHhdE7mFom5y1.png"/></div></div><p class="na nb gj gh gi nc nd bd b be z dk translated">executors峰值内存使用图表显示了Spark executors达到最大内存使用量时的内存使用量明细。图片作者。</p></figure><p id="f501" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">‍While你的应用程序正在运行，火花测量每个执行者的内存使用。此图报告了针对前5名执行者观察到的内存使用峰值，按不同类别细分:</p><ul class=""><li id="7b66" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">JVM使用的内存(这是你的最大堆大小)</li><li id="4901" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">由<strong class="kh ir"> Python </strong>进程使用的内存(如果您使用PySpark)</li><li id="a093" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated"><strong class="kh ir">其他</strong>进程使用的内存(如果您正在使用R，那么R当前被列为“其他”)</li></ul><p id="ef52" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个图表对PySpark用户应该特别有用，他们目前没有简单的方法知道他们的python进程消耗了多少内存。这个图表可以帮助你决定使用不同类型的容器是否安全。它还可能警告您，您正在与允许的最大内存使用量调情。提醒一下，如果您的Python进程使用了太多的内存，那么您的资源管理器将会终止您的Spark执行器(例如在Kubernetes上，您将会得到docker退出代码137)。</p><h1 id="65d9" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">结论:尝试一下，并让我们知道您的反馈！</h1><p id="23d7" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">我们希望Delight能够实现它的承诺，并帮助您获得愉快的Spark开发体验。</p><p id="b78e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们鼓励您尝试一下！<a class="ae lb" href="https://www.datamechanics.co/delight" rel="noopener ugc nofollow" target="_blank">注册</a>，按照我们的github页面上的安装说明<a class="ae lb" href="https://github.com/datamechanics/delight" rel="noopener ugc nofollow" target="_blank">，并通过电子邮件(回复欢迎邮件)或使用产品中的实时聊天窗口让我们知道您的反馈。</a></p><p id="01a1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们对快乐有雄心勃勃的计划。我们的未来路线图包括:</p><ul class=""><li id="2549" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">每个执行器和驱动程序都有一个页面，用于跟踪它们的内存使用情况，并提供更详细的细分(堆外内存使用情况)</li><li id="e04c" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">自动化性能调整建议(例如，关于数据不对称/低效数据分区的警报等)</li><li id="1b10" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">在应用程序运行的同时，让快乐实时可及</li><li id="5f87" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">更多基于您的反馈:让我们知道您的优先事项！</li></ul><p id="45de" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将很快发布后续文章，介绍具体的故障排除步骤，并使用Delight启动性能调优会议。我们还将举办关于它的聚会和会议，包括即将举行的<a class="ae lb" href="https://databricks.com/session_na21/delight-a-free-and-cross-platform-apache-spark-ui-complement" rel="noopener ugc nofollow" target="_blank">数据+人工智能峰会</a>。敬请关注，感谢您的支持！</p></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><p id="724c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ni">最初发表于</em><a class="ae lb" href="https://www.datamechanics.co/blog-post/delight-the-new-improved-spark-ui-spark-history-server-is-now-ga" rel="noopener ugc nofollow" target="_blank">T5【https://www.datamechanics.co】</a><em class="ni">。</em></p></div></div>    
</body>
</html>