<html>
<head>
<title>Poisson Regression and Generalised Linear Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">泊松回归和广义线性模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/poisson-regression-and-generalised-linear-models-606fe5f7c1fd?source=collection_archive---------7-----------------------#2021-11-15">https://towardsdatascience.com/poisson-regression-and-generalised-linear-models-606fe5f7c1fd?source=collection_archive---------7-----------------------#2021-11-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="af3a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">泊松回归和广义线性模型的理论介绍</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4cb54f797e148daeffaa36280699268c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Au5zvO7BTKL3BLv4"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">杰斯温·托马斯在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><blockquote class="kz la lb"><p id="2807" class="lc ld le lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">注意:在整篇文章中，我错误地将E[Y]称为目标输出。当我提到E[Y]时，我隐含的意思是E[Y|X],因为这是正确的符号！<a class="ae ky" href="https://stats.stackexchange.com/questions/439463/in-glm-do-we-make-an-assumption-on-the-distribution-of-y-or-the-distribution-of" rel="noopener ugc nofollow" target="_blank">这里链接的是一个解释这种差异的统计交换线程。</a></p></blockquote><p id="b330" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Linear_regression" rel="noopener ugc nofollow" target="_blank"> <strong class="lf iu">线性回归</strong> </a>是大多数数据科学家开始其旅程的第一个算法。对于连续数据，这是一个简单、易于实现和可视化的模型。初学数据的科学家第二常学的算法是<a class="ae ky" href="https://en.wikipedia.org/wiki/Logistic_regression" rel="noopener ugc nofollow" target="_blank"> <strong class="lf iu">逻辑回归</strong> </a>，其中模型有二进制输出。大多数人认为这两种算法是完全独立的，但实际上它们是名为<a class="ae ky" href="https://en.wikipedia.org/wiki/Generalized_linear_model" rel="noopener ugc nofollow" target="_blank"> <strong class="lf iu">广义线性模型(GLMs) </strong> </a>的同一模型家族的一部分。在本文中，我们将通过一个使用<a class="ae ky" href="https://en.wikipedia.org/wiki/Poisson_distribution" rel="noopener ugc nofollow" target="_blank"> <strong class="lf iu">泊松分布</strong> </a> <strong class="lf iu">的示例场景来获得关于GLMs的直觉。</strong></p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="148e" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">线性回归基础和局限性</h1><p id="009e" class="pw-post-body-paragraph lc ld it lf b lg nb ju li lj nc jx ll lz nd lo lp ma ne ls lt mb nf lw lx ly im bi translated">线性回归是一种用于将<strong class="lf iu">线</strong>或<strong class="lf iu">超平面</strong>拟合到数据集的模型，其中输出为<strong class="lf iu">连续</strong>并具有正态分布的<strong class="lf iu">残差。这是数学上的写法:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/78302ccb7f0640a01ec8324fc2a99799.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*Ynv0qkJBzUJbuLy_oDjEfg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LaTeX作者的方程式</p></figure><p id="8155" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">其中<strong class="lf iu"><em class="le">E(Y)</em></strong><em class="le"/>是目标变量的<strong class="lf iu">均值响应</strong>，<strong class="lf iu"> <em class="le"> X </em> </strong>是预测变量的<strong class="lf iu">矩阵</strong>，<strong class="lf iu"> <em class="le"> β </em> </strong>是被调整和训练以产生最佳模型的<strong class="lf iu">未知线性系数</strong>。</p><p id="87f8" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">线性回归在<strong class="lf iu">流行病学、金融和经济学</strong>等很多行业都有应用。然而，尽管被用于所有这些领域，它确实有一些缺陷，使得它的预测在某些应用中是多余的。假设你是一名电话接线员，想要<strong class="lf iu">预测你一天会接到多少个电话</strong>。你认为线性回归是一个合适的模型吗？答案是<strong class="lf iu">否</strong>，原因如下:</p><ul class=""><li id="4888" class="nh ni it lf b lg lh lj lk lz nj ma nk mb nl ly nm nn no np bi translated">调用次数必须大于或等于0，而在线性回归中，输出可以是负的，也可以是正的。</li><li id="1456" class="nh ni it lf b lg nq lj nr lz ns ma nt mb nu ly nm nn no np bi translated">调用次数只取整数值<strong class="lf iu">而线性回归可以输出小数值</strong>。</li></ul><p id="fc7d" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">这些缺陷以及许多其他缺陷要求我们使用另一种回归算法来模拟预期的调用次数。</p><h1 id="3421" class="mj mk it bd ml mm nv mo mp mq nw ms mt jz nx ka mv kc ny kd mx kf nz kg mz na bi translated">泊松分布</h1><p id="e3de" class="pw-post-body-paragraph lc ld it lf b lg nb ju li lj nc jx ll lz nd lo lp ma ne ls lt mb nf lw lx ly im bi translated">泊松分布是一种概率分布，用于测量在指定的时间段内<strong class="lf iu">发生多少次以及<em class="le"> x(调用)</em>发生的可能性有多大。分布的公式是:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/333e66f1aac4fc365678daf86dc2065e.png" data-original-src="https://miro.medium.com/v2/resize:fit:248/format:webp/1*lMNoV-FSodZ99dWCJSWVbg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LaTeX作者的方程式</p></figure><p id="b48d" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">其中<strong class="lf iu"> <em class="le"> λ </em> </strong>是<strong class="lf iu">预期出现的次数，</strong>在我们的例子中是调用。</p><p id="928e" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">这是将呼叫数量建模为其<strong class="lf iu">离散</strong>并且<strong class="lf iu"> <em class="le"> x </em> </strong>和<strong class="lf iu"><em class="le">λ</em></strong><strong class="lf iu">只能取大于或等于0的值的完美分布。</strong>现在的问题是<strong class="lf iu">如何把</strong>上面的线性回归方程变成泊松回归方程？这可以通过使用<strong class="lf iu">广义线性模型</strong>来实现。</p><h1 id="c1c9" class="mj mk it bd ml mm nv mo mp mq nw ms mt jz nx ka mv kc ny kd mx kf nz kg mz na bi translated">广义线性模型</h1><p id="cf35" class="pw-post-body-paragraph lc ld it lf b lg nb ju li lj nc jx ll lz nd lo lp ma ne ls lt mb nf lw lx ly im bi translated">GLM，就像他们的名字一样，是线性回归的概括，其中响应变量采用非正态分布，如泊松或二项式分布。GLM包含三个核心内容:</p><ul class=""><li id="bbff" class="nh ni it lf b lg lh lj lk lz nj ma nk mb nl ly nm nn no np bi translated"><em class="le">指数分布族的一部分</em></li><li id="017d" class="nh ni it lf b lg nq lj nr lz ns ma nt mb nu ly nm nn no np bi translated"><em class="le">线性预测器</em></li><li id="8d1d" class="nh ni it lf b lg nq lj nr lz ns ma nt mb nu ly nm nn no np bi translated"><em class="le">链接功能</em></li></ul><p id="5fd0" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们现在将浏览这些内容，并简要推导和解释它们所指的内容。</p><h2 id="48c0" class="ob mk it bd ml oc od dn mp oe of dp mt lz og oh mv ma oi oj mx mb ok ol mz om bi translated">指数族</h2><p id="17f5" class="pw-post-body-paragraph lc ld it lf b lg nb ju li lj nc jx ll lz nd lo lp ma ne ls lt mb nf lw lx ly im bi translated">如果满足以下函数，概率分布被视为<a class="ae ky" href="https://en.wikipedia.org/wiki/Exponential_family" rel="noopener ugc nofollow" target="_blank"> <strong class="lf iu">指数族</strong> </a> <strong class="lf iu"> </strong>的一部分:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/7ca81cf5788bc6e8178e5f3a8254a68d.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*wezCahdS3QJHC_pJsMXQFg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LaTeX作者的方程式</p></figure><p id="0215" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">这里，θ指的是<strong class="lf iu">自然参数，</strong>是与均值关联的<strong class="lf iu">，</strong>，φ是与方差关联的<strong class="lf iu">标度参数</strong>。此外，a(φ)，b(θ)和c(y，φ)是待定的函数，但我们不会在本文中详细讨论。</p><p id="2328" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">通过一些数学操作可以看出，指数族的<strong class="lf iu">均值、<em class="le"> E(Y)、</em>和方差、<em class="le"> VAR(Y) </em>、</strong>由下式给出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/e10c3927a2458edae54e32e079879b48.png" data-original-src="https://miro.medium.com/v2/resize:fit:242/format:webp/1*Fr763FOB-sp4J74NnpGRQg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LaTeX作者的方程式</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/867c54c84b31c2a66ad20d28409ce06f.png" data-original-src="https://miro.medium.com/v2/resize:fit:380/format:webp/1*bipIQk7XS2YLaPOz65OZwA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LaTeX作者的方程式</p></figure><p id="c619" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">根据上面的泊松概率分布公式，我们可以将其改写为指数族形式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/26323546ed75b630e420c7c5e55ebc26.png" data-original-src="https://miro.medium.com/v2/resize:fit:374/format:webp/1*kR-hZYn2nqxUiz5Fn40HdA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LaTeX作者的方程式</p></figure><p id="3d2a" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">通过<strong class="lf iu">将系数</strong>与泊松公式和指数公式相匹配，我们得出结论:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/52d948eef454a64ced94a580b04e1a84.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*T4X8uSGNiOHpSOfsJleM7g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LaTeX作者的方程式</p></figure><p id="96eb" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">这些是泊松分布的一般已知结果。在文章的后面，我们将解释为什么我们会得到上述值以及它们的重要性。</p><h2 id="ae03" class="ob mk it bd ml oc od dn mp oe of dp mt lz og oh mv ma oi oj mx mb ok ol mz om bi translated">线性预测器</h2><p id="0f96" class="pw-post-body-paragraph lc ld it lf b lg nb ju li lj nc jx ll lz nd lo lp ma ne ls lt mb nf lw lx ly im bi translated">这是解释变量<strong class="lf iu"><em class="le"/></strong>及其对应的未知系数<strong class="lf iu"><em class="le"/></strong>的<strong class="lf iu">线性组合</strong>(本质上是求和)，等于目标数据的期望输出<strong class="lf iu"><em class="le">【E(Y)</em></strong>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/8c593b926f226b85ae71cfcf596e62dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:216/format:webp/1*LcIl2Or2nV4QpfsLcsRtOQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LaTeX作者的方程式</p></figure><p id="ac8d" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">其中上述系数和解释变量在<strong class="lf iu">矩阵形式</strong>中。</p><h2 id="b980" class="ob mk it bd ml oc od dn mp oe of dp mt lz og oh mv ma oi oj mx mb ok ol mz om bi translated">链接功能</h2><p id="e14b" class="pw-post-body-paragraph lc ld it lf b lg nb ju li lj nc jx ll lz nd lo lp ma ne ls lt mb nf lw lx ly im bi translated">这是GLM最重要的部分。<strong class="lf iu">链接函数，<em class="le"> g()，</em>'链接'输入变量到输出目标的分配</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/ec931ed4b8f07246ccbf22cf57cf4b46.png" data-original-src="https://miro.medium.com/v2/resize:fit:314/format:webp/1*oj_zso05V9N0Cw32lM2nEw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LaTeX作者的方程式</p></figure><p id="f48d" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我个人认为这是<strong class="lf iu">“缩放”我们的输入到我们预期的输出范围</strong>。例如，在逻辑回归中，<strong class="lf iu"> Sigmoid函数</strong>将输出缩放到0和1之间。事实上，逻辑回归是基于<strong class="lf iu">二项式分布</strong>，它也是指数家族的一部分，因此是GLM。对于线性回归，链接函数是<strong class="lf iu">恒等函数</strong>，因此它不会转换线性预测值。</p><p id="ac12" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">人们可以通过简单地<strong class="lf iu">猜测允许特定范围输出的函数</strong>来确定链接函数。然而，它们也可以数学推导为t <strong class="lf iu">，它们与自然参数θ </strong>的值“关联”。因此，泊松分布的链接函数是<strong class="lf iu">自然对数<em class="le"> ln() </em> </strong>。此外，由于链接函数等于自然参数，这意味着它被称为<strong class="lf iu">规范链接函数</strong>。</p><h1 id="00fe" class="mj mk it bd ml mm nv mo mp mq nw ms mt jz nx ka mv kc ny kd mx kf nz kg mz na bi translated">把所有的放在一起</h1><p id="1a23" class="pw-post-body-paragraph lc ld it lf b lg nb ju li lj nc jx ll lz nd lo lp ma ne ls lt mb nf lw lx ly im bi translated">啊！我们已经到了文章的结尾，现在我们可以把所有这些数学知识放在一起产生我们的<strong class="lf iu">泊松回归公式</strong>。现在我们知道链接函数是<strong class="lf iu">自然对数</strong>，线性回归方程转换为泊松回归方程:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/23a97aef99fa1d8d709919c48ca08e5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/1*HacwvGBkbHEMFewZqVoVzA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LaTeX作者的方程式</p></figure><p id="e71c" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们可以看到，将自然对数应用于输出意味着<strong class="lf iu">将总是取正值</strong>，即使线性预测器输出负结果！</p><h1 id="9718" class="mj mk it bd ml mm nv mo mp mq nw ms mt jz nx ka mv kc ny kd mx kf nz kg mz na bi translated">结论</h1><p id="b9f6" class="pw-post-body-paragraph lc ld it lf b lg nb ju li lj nc jx ll lz nd lo lp ma ne ls lt mb nf lw lx ly im bi translated">在这篇文章中，我们探讨了GLM的需要和一点他们的数学背景。本文并不全面，因此感兴趣的读者应该更详细地探讨这个主题，以便更好地理解。但是，我希望您会对这篇文章感兴趣，并从中获得一些关于高级统计建模的知识！</p><h1 id="777f" class="mj mk it bd ml mm nv mo mp mq nw ms mt jz nx ka mv kc ny kd mx kf nz kg mz na bi translated">和我联系！</h1><ul class=""><li id="ca40" class="nh ni it lf b lg nb lj nc lz ov ma ow mb ox ly nm nn no np bi translated">要在媒体上阅读无限的故事，请务必在此注册！  <em class="le"> </em>💜</li><li id="9786" class="nh ni it lf b lg nq lj nr lz ns ma nt mb nu ly nm nn no np bi translated"><a class="ae ky" href="/subscribe/@egorhowell" rel="noopener ugc nofollow" target="_blank"> </a> <em class="le"> </em>😀</li><li id="b8dc" class="nh ni it lf b lg nq lj nr lz ns ma nt mb nu ly nm nn no np bi translated"><a class="ae ky" href="https://www.linkedin.com/in/egor-howell-092a721b3/" rel="noopener ugc nofollow" target="_blank"><em class="le">LinkedIn</em></a><em class="le"/>👔</li><li id="a7a0" class="nh ni it lf b lg nq lj nr lz ns ma nt mb nu ly nm nn no np bi translated"><a class="ae ky" href="https://twitter.com/EgorHowell" rel="noopener ugc nofollow" target="_blank"> <em class="le">推特</em> </a> <em class="le"> </em> 🖊</li><li id="fb18" class="nh ni it lf b lg nq lj nr lz ns ma nt mb nu ly nm nn no np bi translated"><a class="ae ky" href="https://github.com/egorhowell" rel="noopener ugc nofollow" target="_blank"><em class="le">github</em></a><em class="le"/>🖥</li><li id="87b0" class="nh ni it lf b lg nq lj nr lz ns ma nt mb nu ly nm nn no np bi translated"><a class="ae ky" href="https://www.kaggle.com/egorphysics" rel="noopener ugc nofollow" target="_blank"><em class="le"/></a><em class="le"/>🏅</li></ul><blockquote class="kz la lb"><p id="52b4" class="lc ld le lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">(所有表情符号都是由<a class="ae ky" href="https://openmoji.org/" rel="noopener ugc nofollow" target="_blank"> OpenMoji </a>设计的——开源的表情符号和图标项目。许可证:<a class="ae ky" href="https://creativecommons.org/licenses/by-sa/4.0/#" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0 </a></p></blockquote></div></div>    
</body>
</html>