<html>
<head>
<title>Unit 8) Co-Evolution —Reinforcement Learning for Game AI Design</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">单元8)协同进化——游戏人工智能设计的强化学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unit-8-co-evolution-reinforcement-learning-for-game-ai-design-97453ed946ec?source=collection_archive---------21-----------------------#2021-08-21">https://towardsdatascience.com/unit-8-co-evolution-reinforcement-learning-for-game-ai-design-97453ed946ec?source=collection_archive---------21-----------------------#2021-08-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="dffe" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">进化计算课程</h2><div class=""/><div class=""><h2 id="ecbd" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用Python Gym环境和进化计算库，共同进化用于玩月球着陆器的竞争游戏AI！</h2></div><p id="2674" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">大家好，欢迎回到进化计算的完整课程！在这篇文章中，我们将开始并完成第八单元，共同进化。不幸的是，这将是本课程的最后一个单元，但希望你在这个过程中学到了很多！在前一单元中，我们应用差分进化来进化Keras中的卷积神经网络的模型架构，您可以在此处找到该文章:</p><div class="ln lo gp gr lp lq"><a rel="noopener follow" target="_blank" href="/unit-7-differential-evolution-automated-machine-learning-eb22014e592e"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">第7单元)差异进化—自动机器学习</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">应用差分进化的概念在进化一个深度卷积神经网络的结构上…</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">towardsdatascience.com</p></div></div><div class="lz l"><div class="ma l mb mc md lz me mf lq"/></div></div></a></div><p id="130a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果您是本系列的新手，请查看下面的两篇文章，我在其中介绍了理解进化计算所必需的背景信息:</p><div class="ln lo gp gr lp lq"><a rel="noopener follow" target="_blank" href="/unit-2-introduction-to-evolutionary-computation-85764137c05a"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">单元2)进化计算简介</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">进化计算和遗传算法概述！</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">towardsdatascience.com</p></div></div><div class="lz l"><div class="mg l mb mc md lz me mf lq"/></div></div></a></div><div class="ln lo gp gr lp lq"><a rel="noopener follow" target="_blank" href="/unit-3-genetic-algorithms-part-1-986e3b4666d7"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">单元3)遗传算法(第一部分)</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">遗传算法概述—主要是交叉和变异算子</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">towardsdatascience.com</p></div></div><div class="lz l"><div class="mh l mb mc md lz me mf lq"/></div></div></a></div><p id="11e1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在这篇文章中，我们将简要概述共同进化、竞争适应度、不同类型的共同进化，然后以进化合作/竞争游戏AI来玩<strong class="kt jd">月球着陆器</strong>来结束。</p><h1 id="4416" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">目录</h1><ul class=""><li id="5ce3" class="na nb it kt b ku nc kx nd la ne le nf li ng lm nh ni nj nk bi translated"><strong class="kt jd">协同进化和标准遗传算法的区别</strong></li><li id="c686" class="na nb it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated"><strong class="kt jd">竞技健身</strong></li><li id="cdfe" class="na nb it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated"><strong class="kt jd">竞争与合作的协同进化伪算法</strong></li><li id="fae2" class="na nb it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated"><strong class="kt jd">用于强化学习的Python健身房环境</strong></li><li id="9c50" class="na nb it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated"><strong class="kt jd">月球着陆器的竞争/合作协同进化</strong></li><li id="fecc" class="na nb it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated"><strong class="kt jd">代码</strong></li><li id="35e1" class="na nb it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated"><strong class="kt jd">结论</strong></li></ul><h1 id="656e" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">协同进化和标准遗传算法的区别</h1><p id="e28d" class="pw-post-body-paragraph kr ks it kt b ku nc kd kw kx nd kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">协同进化和标准遗传算法的主要区别在于，协同进化不是一种进化算法，而是一种同时进化不同物种和种群的方法论。共同进化背后的思想是为了解决同一个问题而进化两个或更多独特的个体物种。例如，假设我们回到单元3和单元4，在那里我们试图预测时间序列问题。单元3中采用的方法是进化固定神经网络的权重，而单元4中采用的方法是进化决策树。当我们将这两种独特的算法结合起来，创建两个不同的种群、算法种类，并让它们针对同一问题同时进化时，就会出现协同进化。通过这种方式，我们可以创造一个竞争的环境，在这个环境中，每个物种的进化都是基于它们比其他物种好多少，而不一定是基于它们在自己物种中的适应程度。</p><p id="ca10" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">有两种主要类型的共同进化:</p><ul class=""><li id="b957" class="na nb it kt b ku kv kx ky la nt le nu li nv lm nh ni nj nk bi translated">捕食者与猎物(竞争)</li><li id="5a36" class="na nb it kt b ku nl kx nm la nn le no li np lm nh ni nj nk bi translated">共生(合作)</li></ul><p id="36ec" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">竞争协同进化通常用于从可能的种群中确定最佳物种，或者为游戏人工智能设计进化不同的策略。另一方面，<strong class="kt jd">合作共同进化</strong>被执行，其中目标是所有物种一起合作来解决特定问题。</p><h1 id="f494" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">竞技体能</h1><p id="538f" class="pw-post-body-paragraph kr ks it kt b ku nc kd kw kx nd kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">如前所述，在共同进化中，个体的适应度是通过它比其他物种/种群中的个体好多少来计算的，而不是在它自己的物种中。存在不同的方式来计算先前描述的两种类型的协同进化方法的适合度。</p><p id="25c5" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">对于<strong class="kt jd">捕食者与猎物(竞争)，</strong>我们想要比较物种之间的适应度得分。我们可以通过竞争适应度抽样进行比较，我们随机抽取另一个群体的适应度值与当前值进行比较。有四种主要的采样技术:</p><ol class=""><li id="2530" class="na nb it kt b ku kv kx ky la nt le nu li nv lm nw ni nj nk bi translated"><strong class="kt jd">所有采样</strong> —将每个物种的每个个体与其他物种的所有个体进行比较。</li><li id="0880" class="na nb it kt b ku nl kx nm la nn le no li np lm nw ni nj nk bi translated"><strong class="kt jd">随机抽样</strong> —将每个物种的每个个体与每个物种整个种群的随机样本进行比较。</li><li id="dc84" class="na nb it kt b ku nl kx nm la nn le no li np lm nw ni nj nk bi translated"><strong class="kt jd">锦标赛抽样</strong> —将每个物种的每个个体与每个物种的小型锦标赛进行比较。</li><li id="3641" class="na nb it kt b ku nl kx nm la nn le no li np lm nw ni nj nk bi translated"><strong class="kt jd">最佳取样</strong> —将每个物种的每个个体与每个物种的最佳个体进行比较。</li></ol><p id="6b2a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">对于<strong class="kt jd">共生(合作)</strong>，因为我们希望的一般种群共同进化，所以我们会执行相对适应度，而不是竞争适应度。相对适应度关注的是个体相对于他们周围的人，包括他们自己的物种，表现得有多好。有三种主要的采样技术:</p><ol class=""><li id="7dc2" class="na nb it kt b ku kv kx ky la nt le nu li nv lm nw ni nj nk bi translated"><strong class="kt jd">所有取样</strong> —将每个个体与所有个体进行比较</li><li id="0ead" class="na nb it kt b ku nl kx nm la nn le no li np lm nw ni nj nk bi translated"><strong class="kt jd">随机抽样</strong> —将每个人与随机样本进行比较</li><li id="938d" class="na nb it kt b ku nl kx nm la nn le no li np lm nw ni nj nk bi translated"><strong class="kt jd">锦标赛抽样</strong> —每个人都与一个小型锦标赛进行比较</li></ol><p id="3f39" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">正如我们所看到的，竞争和合作共同进化的采样技术极其相似；竞争的主要区别在于每个物种相对于其他物种的表现如何，而共同进化则在于整个物种群体的表现如何。</p><h1 id="5ca0" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">竞争与合作协同进化伪算法</h1><p id="e3b7" class="pw-post-body-paragraph kr ks it kt b ku nc kd kw kx nd kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">既然我们已经讨论了共同进化的主要区别，让我们来看两个用于设计游戏AI代理的伪代码算法。第一次竞争协同进化:</p><figure class="ny nz oa ob gt oc gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/e97de25747013c49be5b090608e26ac8.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*Ls6D_tH684s0geVG47dxrw.png"/></div><p class="oe of gj gh gi og oh bd b be z dk translated">作者图片</p></figure><p id="6f1c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">上面我们有一个两个种群物种之间的竞争性共同进化的例子，其中它们的适应度是基于来自另一个物种的适应度值的一些样本。</p><p id="9cb8" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">对于合作式共同进化:</p><figure class="ny nz oa ob gt oc gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/ed8f6c1a10a3fb9a1c4e18e9bc5e5456.png" data-original-src="https://miro.medium.com/v2/resize:fit:386/format:webp/1*F757Ky_JioxSTd-Mz7zZ-Q.png"/></div><p class="oe of gj gh gi og oh bd b be z dk translated">作者图片</p></figure><p id="4760" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">上面我们有一个所有种群物种之间合作共同进化的例子。我们简单地计算原始适合度，然后通过上面讨论的某种采样技术计算相对适合度。在合作协同进化中，允许相对适应值差的物种灭绝是很常见的。</p><h1 id="c9be" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated"><strong class="ak">用于强化学习的Python健身房环境</strong></h1><p id="59d1" class="pw-post-body-paragraph kr ks it kt b ku nc kd kw kx nd kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">开发游戏AI代理是一个包含许多不同学科领域的广阔领域。在这个领域中，有太多不同的方法来创造游戏人工智能代理；然而，培训这些代理的主要领域被称为<strong class="kt jd">强化学习:</strong>代理在不同情况下应该如何行动。</p><figure class="ny nz oa ob gt oc gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/24da31e37d7c3592cb95836ed8e9b228.png" data-original-src="https://miro.medium.com/v2/resize:fit:372/format:webp/0*mea6GsujfNcx0DhM.png"/></div><p class="oe of gj gh gi og oh bd b be z dk translated"><a class="ae ok" href="https://commons.wikimedia.org/wiki/File:Reinforcement_learning_diagram.svg" rel="noopener ugc nofollow" target="_blank">https://commons . wikimedia . org/wiki/File:Reinforcement _ learning _ diagram . SVG</a></p></figure><p id="eaff" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在强化学习场景中，我们奖励我们的代理在环境中采取的行动。如果代理采取了不好的行动，我们惩罚它，否则我们奖励它的好行动。通过这种方式，代理人学会在环境中导航，以最大化回报。在这类问题中创建人工智能代理的最常见方式是通过神经网络。我不打算在这里详述神经网络，所以如果你不熟悉，我建议你仔细阅读。神经网络的强化算法有很多，比如<strong class="kt jd">演员评判法</strong>、<strong class="kt jd"> Q学习</strong>、<strong class="kt jd"> DDPG </strong>等等。然而，在这篇文章中，我们的目标不是使用上述方法，而是使用<strong class="kt jd">遗传算法</strong>。</p><p id="2531" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">一些人在尝试测试他们的强化学习算法时可能遇到的主要问题是如何创建环境本身。嗯，幸运的是，在Python中存在一个名为<strong class="kt jd"> Gym </strong>的库，这是一个用于开发和比较强化学习算法的工具包，包含大量旧的Atari游戏、复杂的物理问题和其他简单的小游戏。您可以在下面找到他们的网站:</p><div class="ln lo gp gr lp lq"><a href="https://gym.openai.com/" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">Gym:开发和比较强化学习算法的工具包</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">健身房图书馆提供了一套易于使用的强化学习任务。import gym env = gym . make(" cart pole-v1 ")…</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">gym.openai.com</p></div></div><div class="lz l"><div class="ol l mb mc md lz me mf lq"/></div></div></a></div><p id="502c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们将使用体育馆的环境来测试我们的遗传算法。</p><h1 id="78d3" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated"><strong class="ak">月球着陆器的竞争/合作协同进化</strong></h1><p id="d048" class="pw-post-body-paragraph kr ks it kt b ku nc kd kw kx nd kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">我们的应用问题是处理<strong class="kt jd">月球Landar-v2 </strong>环境。这种环境是健身房特有的。这个问题的目标是让月球着陆器在着陆台上着陆。输入是八个不同的数值，代表着陆器的距离和方向，而输出是四个离散的选项，向左、向右、向上移动，或者什么都不做。当获得200的适应值时，认为问题已经解决。</p><p id="47a6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">为此我们将使用<strong class="kt jd">进化计算</strong>库中的<strong class="kt jd">神经增强器</strong>类，附:我写的。这将是库的一小段，目前还没有完全完成，但是我已经等不及要展示这个例子了。您可以在我的GitHub资源库页面上找到更多关于该库及其更新的信息:</p><div class="ln lo gp gr lp lq"><a href="https://github.com/OUStudent/EvolutionaryComputation" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">GitHub -学生/进化计算</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">进化计算是一个Python模块，包含进化计算领域的高级算法…</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">github.com</p></div></div><div class="lz l"><div class="om l mb mc md lz me mf lq"/></div></div></a></div><p id="4f7a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">你也可以在PyPi上找到它</p><div class="ln lo gp gr lp lq"><a href="https://pypi.org/project/EvolutionaryComputation/" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab fo"><div class="ls ab lt cl cj lu"><h2 class="bd jd gy z fp lv fr fs lw fu fw jc bi translated">进化计算</h2><div class="lx l"><h3 class="bd b gy z fp lv fr fs lw fu fw dk translated">进化计算是一个Python模块，包含进化计算领域的高级算法…</h3></div><div class="ly l"><p class="bd b dl z fp lv fr fs lw fu fw dk translated">pypi.org</p></div></div><div class="lz l"><div class="on l mb mc md lz me mf lq"/></div></div></a></div><p id="6020" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated"><strong class="kt jd">神经强化器</strong>类是专门解决输入为数字的强化型学习问题的类，而<strong class="kt jd">神经强化器</strong>类解决输入为图像的强化型学习问题。<strong class="kt jd">神经强化器</strong>类通过先进的自适应对数正态遗传算法来进化前馈神经网络的权重和激活函数。神经强化器展示了将竞争和合作机制结合成一种进化机制。它展示了合作的方面，因为目标是让所有物种进化出解决问题的最佳模式；此外，它展示了竞争的品质，因为进化中的每个物种都必须为生存而战，否则就会灭绝……<strong class="kt jd">神经强化剂</strong>中的物种由其激活功能来指定，这些激活功能可以是所有层的静态激活功能，也可以是混合激活功能。</p><p id="2e39" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">要建立这个问题，我们首先需要创建我们的适应度函数，它将接受群体并返回每个个体的“适应度”。“健康”只是玩一个游戏后的奖励:</p><figure class="ny nz oa ob gt oc"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="04a3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在我们需要创建神经网络架构。对于这个例子，我们将选择一个具有三个隐藏层和50、100、50个节点的网络架构。对于激活功能选择，我们将考虑<strong class="kt jd"> relu、leaky relu、卢瑟、elu、高斯、sigmoid、</strong>和<strong class="kt jd"> tanh </strong>。为了允许进化过程中的一些变化，如果一个个体的当前物种多于一个，它将有5%的机会转换物种。最后，对于物种形成，我们将把个体各层的激活函数视为静态的。</p><figure class="ny nz oa ob gt oc"><div class="bz fp l di"><div class="oo op l"/></div></figure><h1 id="481b" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">原始群体</h1><p id="76c8" class="pw-post-body-paragraph kr ks it kt b ku nc kd kw kx nd kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">这里我们有来自人群的初始因子。注意他们在登陆月球着陆器时做得很差。然而，他们将很快学会如何在环境中的良好行为得到奖励。</p><div class="ny nz oa ob gt ab cb"><figure class="oq oc or os ot ou ov paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><img src="../Images/791e70df624af7c7b72ee34521f93814.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/1*vsN-g0lnFaqGXf2XLfQgxg.gif"/></div></figure><figure class="oq oc or os ot ou ov paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><img src="../Images/aa8c3f83c8b69d09e9b5d619ad9f1a78.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/1*sVmru-JNeKz6Xn79MhLpFg.gif"/></div></figure><figure class="oq oc or os ot ou ov paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><img src="../Images/08c60fc424870fc25f3a4158bffdbbc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/1*5-1Aung8pgk7LPun2TT81A.gif"/></div></figure></div><div class="ab cb"><figure class="oq oc or os ot ou ov paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><img src="../Images/eec9fe0ce434da5198dc0bc60c3ddd8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/1*4SMn8LYA3aOViOJ1AWPHlA.gif"/></div></figure><figure class="oq oc or os ot ou ov paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><img src="../Images/08e957a4fc6dd1dde33a59fa9b4f4882.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/1*hD7UrYmCGlPOKb4k8Od0_Q.gif"/></div></figure><figure class="oq oc or os ot ou ov paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><img src="../Images/e969694491deedd3465f32c08f9225a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/1*t0O1JyYLr1J-OnT-qTrQ9Q.gif"/></div></figure></div><h1 id="36ed" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">绘图结果-完成层激活</h1><p id="1c1f" class="pw-post-body-paragraph kr ks it kt b ku nc kd kw kx nd kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">达到最大代数后，就该可视化结果了:</p><figure class="ny nz oa ob gt oc"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="9430" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">首先，我们有了最佳和平均奖励分数的总体图:</p><div class="ny nz oa ob gt ab cb"><figure class="oq oc pa os ot ou ov paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><img src="../Images/3011d9d7753da8f1175382853688ffd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*cfdkcv7lQKQDDvm0Z9115Q.png"/></div></figure><figure class="oq oc pb os ot ou ov paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><img src="../Images/75c73aa77c3e4e31c7b49b4286e1e9ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*psv-Q2sluan8Fb3rVRN_BA.png"/></div></figure></div><p id="ebd3" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">正如我们在上面看到的，最佳奖励在第0代和第100代之间波动很大，这表明高奖励仅仅是随机获得的。然而，请注意，在第225代，平均奖励急剧增加，然后在第260代左右停止。给定一代人的最佳回报可以简单地从随机机会中获得，因此建议查看平均回报，因为它展示了人口的行为。在第240代，平均奖励增加到200多一点，表明该算法成功地进化出一群模型来解决<strong class="kt jd">月球着陆器-v2 </strong>问题。</p><p id="c28a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">下面我们可以看看进化后的物种大小。图例展示了物种，其中激活函数表示特定层的激活。例如，物种“elu，elu，elu”展示了三个隐藏层都具有“elu”作为激活功能。</p><figure class="ny nz oa ob gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><div class="gh gi pc"><img src="../Images/0e01724c8f7dcd102476353a85aed505.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YdPTT-6ZJkutww75CSGgKA.png"/></div></div><p class="oe of gj gh gi og oh bd b be z dk translated">作者图片</p></figure><p id="3981" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">正如我们在上面看到的，<strong class="kt jd"> leaky relu </strong>(绿色)开始规模很大，但很快在60代左右消亡，而<strong class="kt jd"> elu </strong>(蓝色)<strong class="kt jd"> tanh </strong>(粉色)<strong class="kt jd">卢瑟</strong>(紫色)开始掌权。然而，除了卢瑟之外，其他的都很快开始减少。最上面的两个激活功能可能是<strong class="kt jd">卢瑟</strong>和<strong class="kt jd">坦恩</strong>。</p><p id="412a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在，因为我们已经确定了顶部的两个激活函数，我们可以重做的演变，除了这一次允许激活函数混合每层之间的顶部两个，卢瑟和坦。这样，我们就能进化出最好的激活功能架构。</p><h1 id="6594" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">绘图结果-混合层激活</h1><div class="ny nz oa ob gt ab cb"><figure class="oq oc pd os ot ou ov paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><img src="../Images/8769085f5b6d696e38fdccf070f87c04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*nzuLy-tVsgj_EdDD_B-G3g.png"/></div></figure><figure class="oq oc pe os ot ou ov paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><img src="../Images/68ca209b75ea64647ee91ad0ef42d632.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*6oYEjA6ByAd10gUKAPZNZw.png"/></div></figure></div><p id="81f1" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">正如我们从上面看到的，改进我们的层激活搜索实际上改善了群体收敛。当获得200的奖励时，问题被认为解决了，这是在种群中通过第170代实现的，比保持层激活静态快55代。然而，收敛末期的最佳模型与之前的进化有着相似的最终回报。如果问题更复杂，那么第二次改进的架构搜索也可能获得更好的最佳模型。</p><p id="0285" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">下面我们可以看看进化后的物种大小。图例展示了物种，其中激活函数表示特定层的激活。例如，物种“卢瑟，卢瑟，坦”展示了前两个隐藏层都有“卢瑟”作为激活函数，而第三层有“坦”。</p><figure class="ny nz oa ob gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><div class="gh gi pf"><img src="../Images/9e1452089c301adc243853eb760ddb1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mj5bNddjfkpkMgT0rrU9-Q.png"/></div></div></figure><p id="bfdb" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">正如我们所见，物种大小在进化过程中变化很大。<strong class="kt jd">卢瑟，谭，卢瑟</strong>’(绿色)是在整个进化过程中体型最大的物种，在大约190代时，50个种群中有45个个体；然而，该物种在10年左右因趋同而慢慢消亡。在50个种群中，大约有15个个体的最大最终物种是“<strong class="kt jd">谭，谭，卢瑟”</strong>。</p><h1 id="6c86" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated">最终生成后的最佳模型</h1><p id="a782" class="pw-post-body-paragraph kr ks it kt b ku nc kd kw kx nd kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">进化之后，最好的模型被保存下来，下面是连续六场比赛的视觉效果:</p><div class="ny nz oa ob gt ab cb"><figure class="oq oc or os ot ou ov paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><img src="../Images/3c0f5f80c297b96c5baad86e899fe6f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/1*fCRKW3u5DhMoYhbHEF9nOw.gif"/></div></figure><figure class="oq oc or os ot ou ov paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><img src="../Images/cb88003d0f5384786b965ae3ddd40f73.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/1*Y5hID_rxj3SVuPcQHDv9Aw.gif"/></div></figure><figure class="oq oc or os ot ou ov paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><img src="../Images/6db72353531c12a0ded235145c9d6d72.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/1*PZueWtjQ5oZ7zA7mi_W_bg.gif"/></div></figure></div><div class="ab cb"><figure class="oq oc or os ot ou ov paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><img src="../Images/1eb8a5ab58ff281b7e5cbb28a9117d0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/1*afINe_EM1jnirCdRMS_aKg.gif"/></div></figure><figure class="oq oc or os ot ou ov paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><img src="../Images/9ced8801f14070b0ab7c9f8cef6de407.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/1*46cEVJd7uc6Asam0MFRC-g.gif"/></div></figure><figure class="oq oc or os ot ou ov paragraph-image"><div role="button" tabindex="0" class="ow ox di oy bf oz"><img src="../Images/4b04f7ade4ae5c1f02770070fa7a740d.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/1*f6lNkS2Ya-itQsAlZxuVwg.gif"/></div></figure></div><h1 id="325c" class="mi mj it bd mk ml mm mn mo mp mq mr ms ki mt kj mu kl mv km mw ko mx kp my mz bi translated"><strong class="ak">结论</strong></h1><p id="fa19" class="pw-post-body-paragraph kr ks it kt b ku nc kd kw kx nd kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">共同进化可以是竞争的，合作的，或者两者兼有。协同进化的目标是协同进化不同的物种或算法来解决给定的问题。它最常用于钢筋类型的情况。</p><p id="2c91" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在这篇文章中，我们讨论了竞争和合作环境中的两个基本伪算法，而我们的例子结合了这两个算法来解决Gym的<strong class="kt jd">月球着陆器</strong>环境。我们为此使用的API是来自<strong class="kt jd">进化计算</strong>库的<strong class="kt jd">神经强化器</strong>类。</p><p id="98d2" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这篇文章将是进化计算课程的最后一部分。我希望你们都学到了很多关于进化算法的知识，并渴望在自己的问题中使用它们！在下一篇文章中，我将介绍<strong class="kt jd">进化计算</strong>库，它是我用本课程涵盖的所有材料创建的！</p></div></div>    
</body>
</html>