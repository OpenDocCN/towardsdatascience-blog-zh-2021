<html>
<head>
<title>Image Captions with Deep Learning: State-of-the-Art Architectures</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有深度学习的图像标题:最先进的架构</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-captions-with-deep-learning-state-of-the-art-architectures-3290573712db?source=collection_archive---------7-----------------------#2021-04-23">https://towardsdatascience.com/image-captions-with-deep-learning-state-of-the-art-architectures-3290573712db?source=collection_archive---------7-----------------------#2021-04-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="c145" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a>，直观的图像字幕系列</h2><div class=""/><div class=""><h2 id="3537" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated"><strong class="ak">用简单的英语介绍图像特征编码器、序列解码器、注意力和多模态架构的简明指南</strong></h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/be672ac0cc95bb834b44ff73194c46e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WK-6otMgoJjoE-jM"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@brett_jordan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">布雷特·乔丹</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="6e89" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">图像字幕是深度学习的一个迷人应用，近年来取得了巨大的进展。更有趣的是，它将计算机视觉和NLP结合在一起。</p><h1 id="5d83" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">什么是图像字幕？</h1><p id="235e" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">它接受一个图像作为输入，并产生一个描述照片内容的简短文本摘要。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi my"><img src="../Images/2d594d7319c1ac867b933b57ef81ce9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*ulEFoMZzj96C9Mx3.jpg"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">描述—“站在草丛中的狗”(<a class="ae le" href="https://en.wikipedia.org/wiki/Labrador_Retriever#/media/File:Labrador_on_Quantock_(2175262184).jpg. By IDS.photos from Tiverton, UK - Labrador on Quantock, CC BY-SA 2.0, https://commons.wikimedia.org/w/index.php?curid=25739129 )" rel="noopener ugc nofollow" target="_blank">来源</a>)</p></figure><p id="1398" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这张图片的相关说明可能是“站在草地上的狗”或“站在草地上的拉布拉多犬”。</p><p id="078a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在本文中，我的目标是介绍这个主题，并概述常用于解决这个问题的技术和架构。</p><p id="2dd7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">此外，如果您感兴趣，我还有一篇文章介绍了使用Keras和Tensorflow的端到端图像标题示例。</p><div class="mz na gp gr nb nc"><a rel="noopener follow" target="_blank" href="/image-captions-with-attention-in-tensorflow-step-by-step-927dad3569fa"><div class="nd ab fo"><div class="ne ab nf cl cj ng"><h2 class="bd ja gy z fp nh fr fs ni fu fw iz bi translated">Tensorflow中带注意的图像标题，逐步</h2><div class="nj l"><h3 class="bd b gy z fp nh fr fs ni fu fw dk translated">Keras和Tensorflow 2.0中使用编码器-解码器的端到端示例，用简单的英语讲述</h3></div><div class="nk l"><p class="bd b dl z fp nh fr fs ni fu fw dk translated">towardsdatascience.com</p></div></div><div class="nl l"><div class="nm l nn no np nl nq ky nc"/></div></div></a></div><h1 id="b017" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">它是如何工作的？</h1><p id="7887" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">概括地说，图像字幕利用了三个主要部分。顺便说一下，这些组件没有标准的名称，这些名称是我为了解释它们的用途而想出来的。</p><h2 id="227e" class="nr mc iq bd md ns nt dn mh nu nv dp ml lo nw nx mn ls ny nz mp lw oa ob mr iw bi translated">1.图像特征编码器</h2><p id="2520" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">这将源照片作为输入，并产生一个捕捉其基本特征的编码表示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/07c767ad2c811dc3841f836676461e02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/0*8eGngRyY2vWtLHXN.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="5300" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这使用CNN架构，并且通常使用迁移学习来完成。我们采用为图像分类而预先训练的CNN模型，并移除最后的部分，即“分类器”。有几个这样的模型，如VGGNet、ResNet和Inception。</p><p id="dae9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这个模型的“主干”由几个CNN模块组成，这些模块从照片中逐步提取各种特征，并生成一个紧凑的特征图，以捕捉照片中最重要的元素。</p><p id="be86" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">它首先在初始层中提取简单的几何形状，如曲线和半圆，然后发展到更高层次的结构，如鼻子、眼睛和手，最后识别出面部和车轮等元素。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi od"><img src="../Images/86ad3b613d3dcfafe68f77efa874ef6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/0*9xdwtgtpBmt6tX3j.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(经Vigneashwara Solairaja Pandiyan许可，改编自<a class="ae le" href="https://www.researchgate.net/figure/The-architecture-of-a-VGG-16-network_fig2_330467052" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="2179" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在图像分类模型中，该特征图然后被馈送到最后一级，该最后一级是生成图像中主要对象的类别(例如猫或车)的最终输出预测的分类器。</p><p id="7c9b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当将该模型应用于图像字幕时，我们感兴趣的是图像的特征映射表示，而不需要分类预测。因此，我们保留主干并删除分类器层。</p><h2 id="a1f8" class="nr mc iq bd md ns nt dn mh nu nv dp ml lo nw nx mn ls ny nz mp lw oa ob mr iw bi translated">2.序列解码器</h2><p id="b2cd" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">它获取照片的编码表示，并输出描述照片的标记序列。</p><p id="39ac" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">典型地，这是一个递归网络模型，包括由嵌入层馈送的一堆LSTM层。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/e919f7d2604b4427aa6b981fb4664746.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/0*s5MLu6-_ObTibYKm.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="f09e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">它将图像编码向量作为其初始状态，并以仅包含“开始”标记的最小输入序列作为种子。它“解码”输入图像向量并输出一系列标记。</p><p id="df83" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">它在一个循环中生成这个预测，一次输出一个令牌，然后将其反馈给网络作为下一次迭代的输入。因此，在每一步，它都采用迄今为止预测的记号序列，并生成序列中的下一个记号。最后，它输出一个“结束”标记来完成序列。</p><h2 id="eb9f" class="nr mc iq bd md ns nt dn mh nu nv dp ml lo nw nx mn ls ny nz mp lw oa ob mr iw bi translated">3.句子生成器</h2><p id="e416" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">句子生成器的工作是获取标记序列并输出标题，标题是描述照片的所需语言的单词句子。</p><p id="220f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">它由一个线性层和一个Softmax组成。这为目标语言的词汇表中的每个单词，为序列中的每个位置产生一个概率。</p><p id="22a3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这个概率是这个单词出现在句子中那个位置的可能性。然后，我们可以使用贪婪搜索，通过在每个位置选择概率最高的单词来生成最终的句子。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi of"><img src="../Images/69482f8bc7215c5c655bf276b84dfab7.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*gdMtwRI7SyLn7oqtfazQRQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="9726" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后，该句子将作为预测字幕输出。</p><p id="3f22" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">几乎所有的图像字幕架构都使用这种方法，包括我们刚刚看到的三个组件。然而，随着时间的推移，这个框架已经有了很多变化。</p><h1 id="d574" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">架构:编码器-解码器</h1><p id="96eb" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">也许最常见的用于图像字幕的深度学习架构有时被称为“注入”架构，并直接将图像特征编码器连接到序列解码器，随后是句子生成器，如上所述。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi og"><img src="../Images/17d3916683d28d7732a3486f5ca211ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/0*3RdBJmJ5qCtoUhgt.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><h1 id="8314" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">建筑:多模态</h1><p id="93aa" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">注入架构是图像字幕的原始架构，现在仍然非常流行。然而，一种被称为“合并”架构的替代方案被发现可以产生更好的结果。</p><p id="234c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这两个组件彼此独立工作，而不是将图像编码器作为序列解码器的输入依次连接。换句话说，我们不混合这两种模式。带文本的图像。</p><ul class=""><li id="212e" class="oh oi iq lh b li lj ll lm lo oj ls ok lw ol ma om on oo op bi translated">CNN网络只处理图像</li><li id="3062" class="oh oi iq lh b li oq ll or lo os ls ot lw ou ma om on oo op bi translated">LSTM网络只对目前产生的序列进行操作。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ov"><img src="../Images/3145a7ab91485040326651975f2d887e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wlg8d7WPzONYPLj-.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="30ba" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这两个网络的输出然后与多模态层(可以是线性和Softmax层)结合在一起。它负责解释两种输出，然后是句子生成器，生成最终的预测字幕。</p><p id="2c73" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这种方法的另一个优点是，它允许我们不仅对图像编码器，而且对序列解码器使用迁移学习。我们可以为序列解码器使用预先训练的语言模型。</p><p id="8a3a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">已经尝试了许多不同的组合输出的方法，例如级联、乘法等等。通常最有效的方法是使用加法。</p><h1 id="a8e0" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">架构:对象检测主干</h1><p id="4bc1" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">前面我们讨论了使用来自图像编码器的预训练图像分类模型的主干。这种类型的模型通常被训练来识别整个画面的单个类别。</p><p id="3f7a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然而，在大多数照片中，你可能会有多个感兴趣的对象。不使用图像分类主干，为什么不使用预先训练的对象检测主干从图像中提取特征？</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ow"><img src="../Images/b5e7a28fc5d281644393d2c2e0741a07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4C3sSdnCLnhfSfKA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="3ad4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对象检测模型在场景中所有突出的对象周围生成边界框。它不仅能标记多个对象，还能识别它们在图片中的相对位置。因此，它能够提供图像的更丰富的编码表示，然后序列解码器可以使用该编码表示在其标题中包括所有那些对象的提及。</p><h1 id="c155" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">架构:专注的编码器-解码器</h1><p id="f001" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">在过去的几年里，注意力在NLP模型中的应用已经获得了很大的关注。已经发现它显著提高了NLP应用的性能。当模型生成输出中的每个单词时，注意力有助于它关注输入序列中与该输出单词最相关的单词。</p><p id="fac5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，毫不奇怪地发现，注意力也已经被应用于图像字幕，从而产生了最先进的结果。</p><p id="9d10" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当序列解码器产生字幕的每个单词时，注意力被用来帮助它集中在图像中与它所产生的单词最相关的部分。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/fd566f4ef879bc5b75c47858bf960dc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*VIbSCTQkAVR_jLxaZxMqMA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="6efe" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">注意模块从LSTM获取编码图像向量以及当前输出令牌。它会产生一个加权注意力分数。当该分数与图像结合时，它增加了LSTM在预测下一个令牌时应该关注的那些像素的权重。</p><p id="cac4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">例如，对于标题“狗在窗帘后面”，当它生成单词“狗”时，模型聚焦于照片中的狗，然后当它到达单词“窗帘”时，将焦点转移到窗帘，如您所料。</p><h1 id="071b" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">架构:带变压器的编码器-解码器</h1><p id="c2be" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">谈到关注度，目前的巨头无疑是变形金刚。它以注意力为核心，不使用多年来一直是NLP支柱的循环网络。该架构与编码器-解码器非常相似，只是用变压器代替了LSTM。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/499945e3f48aebbf3a7c2b0f0392e405.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/0*uDWEMjBqfX4JI8JK.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="5e0c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">已经提出了变压器架构的几种不同变体来解决图像字幕问题。一种方法试图不仅编码照片中的单个对象，还编码它们的空间关系，因为这对理解场景很重要。例如，知道一个对象是在另一个对象的下面、后面还是旁边，为生成标题提供了有用的上下文。</p><h1 id="fb67" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">建筑:密集字幕</h1><p id="61a9" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">对象检测方法的另一种变体被称为密集字幕。这个想法是，照片通常是图片中不同位置的物体和活动的丰富集合。</p><p id="58ab" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，它不仅可以表示单个字幕，还可以表示图像不同区域的多个字幕。这个模型帮助它捕捉图像中的所有细节。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/e20416f80df0457cf7c094a72816b58e.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*59YMVTQqyxSF9EclsnK9Vg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">密密麻麻的字幕(<a class="ae le" href="https://arxiv.org/pdf/1511.07571.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>，经费教授、许可)</p></figure><h1 id="1098" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">具有波束搜索的句子生成器</h1><p id="b295" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">当句子生成器生成最终标题时，它可以使用波束搜索，而不是我们上面提到的贪婪搜索。Beam Search不是在每个位置只选择概率最高的单个单词，而是在每一步选择几个单词，基于到该点为止句子中所有单词的组合概率。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pa"><img src="../Images/ec9f13533ea79a06a94c023bbd145a1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*m94l0ywLEgsSHtmz.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">波束搜索(图片由作者提供)</p></figure><p id="a77b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">波束搜索非常有效，在许多NLP应用中被广泛使用。我有几篇文章以直观的方式详细解释了这些。如果你感兴趣，我鼓励你去看一看。</p><div class="mz na gp gr nb nc"><a rel="noopener follow" target="_blank" href="/foundations-of-nlp-explained-visually-beam-search-how-it-works-1586b9849a24"><div class="nd ab fo"><div class="ne ab nf cl cj ng"><h2 class="bd ja gy z fp nh fr fs ni fu fw iz bi translated">自然语言处理的基础直观解释:波束搜索，它是如何工作的</h2><div class="nj l"><h3 class="bd b gy z fp nh fr fs ni fu fw dk translated">波束搜索如何增强预测的简明指南</h3></div><div class="nk l"><p class="bd b dl z fp nh fr fs ni fu fw dk translated">towardsdatascience.com</p></div></div><div class="nl l"><div class="pb l nn no np nl nq ky nc"/></div></div></a></div><div class="mz na gp gr nb nc"><a rel="noopener follow" target="_blank" href="/foundations-of-nlp-explained-bleu-score-and-wer-metrics-1a5ba06d812b"><div class="nd ab fo"><div class="ne ab nf cl cj ng"><h2 class="bd ja gy z fp nh fr fs ni fu fw iz bi translated">解释自然语言处理的基础——Bleu评分和WER指标</h2><div class="nj l"><h3 class="bd b gy z fp nh fr fs ni fu fw dk translated">NLP模型的两个基本指标(Bleu分数和单词错误率)的简明指南，用简单的英语编写</h3></div><div class="nk l"><p class="bd b dl z fp nh fr fs ni fu fw dk translated">towardsdatascience.com</p></div></div><div class="nl l"><div class="pc l nn no np nl nq ky nc"/></div></div></a></div><h1 id="af30" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">Bleu分数度量</h1><p id="ceaf" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">在训练期间，一旦字幕生成，我们如何决定它有多好？用于评估图像字幕模型的常见度量是Bleu分数。对于其他NLP应用程序，如翻译和语言模型，这也是一个流行的指标。</p><p id="11ec" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这是一个简单的指标，衡量预测标题和真实标题之间匹配的连续单词的数量。为此，它比较了从1到4的各种长度的n元文法。</p><p id="341b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">预测说明:“一只狗站在绿色的草地上”地面真实说明:“狗站在草地上”</p><p id="de1c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="pd">1-gram的Bleu分数=正确预测的单词数/总预测单词数</em></p><p id="36f5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">有三个预测单词也出现在真实字幕ie中。“狗”、“上”、“草”，一共出了六个预言词。</p><p id="68c6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="pd"> Bleu评分为1克(即。单字)= 3/6 = 0.5 </em></p><h1 id="9efd" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">结论</h1><p id="7daf" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">随着计算机视觉和NLP的进步，今天的图像字幕模型能够产生几乎与人类表现相匹配的结果。当你输入一张照片，并得到一个完美的人类可读的说明，它几乎感觉就像有一些魔术在进行！</p><p id="2cbd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们刚刚探讨了实现这一目标的常用方法。我们现在处于一个很好的位置，可以看到幕后的细节。在我的下一篇文章中，我将一步一步地介绍一个示例演示应用程序，这样我们就可以确切地看到它是如何工作的。</p><p id="44d6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后，如果你喜欢这篇文章，你可能也会喜欢我关于变形金刚、音频深度学习和地理定位机器学习的其他系列。</p><div class="mz na gp gr nb nc"><a rel="noopener follow" target="_blank" href="/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452"><div class="nd ab fo"><div class="ne ab nf cl cj ng"><h2 class="bd ja gy z fp nh fr fs ni fu fw iz bi translated">直观解释的变压器(第1部分):功能概述</h2><div class="nj l"><h3 class="bd b gy z fp nh fr fs ni fu fw dk translated">NLP变形金刚的简明指南，以及为什么它们比rnn更好，用简单的英语。注意力如何帮助…</h3></div><div class="nk l"><p class="bd b dl z fp nh fr fs ni fu fw dk translated">towardsdatascience.com</p></div></div><div class="nl l"><div class="pe l nn no np nl nq ky nc"/></div></div></a></div><div class="mz na gp gr nb nc"><a rel="noopener follow" target="_blank" href="/audio-deep-learning-made-simple-part-1-state-of-the-art-techniques-da1d3dff2504"><div class="nd ab fo"><div class="ne ab nf cl cj ng"><h2 class="bd ja gy z fp nh fr fs ni fu fw iz bi translated">音频深度学习变得简单(第一部分):最新技术</h2><div class="nj l"><h3 class="bd b gy z fp nh fr fs ni fu fw dk translated">颠覆性深度学习音频应用和架构世界的温和指南。以及为什么我们都需要…</h3></div><div class="nk l"><p class="bd b dl z fp nh fr fs ni fu fw dk translated">towardsdatascience.com</p></div></div><div class="nl l"><div class="pf l nn no np nl nq ky nc"/></div></div></a></div><div class="mz na gp gr nb nc"><a rel="noopener follow" target="_blank" href="/leveraging-geolocation-data-for-machine-learning-essential-techniques-192ce3a969bc"><div class="nd ab fo"><div class="ne ab nf cl cj ng"><h2 class="bd ja gy z fp nh fr fs ni fu fw iz bi translated">利用地理位置数据进行机器学习:基本技术</h2><div class="nj l"><h3 class="bd b gy z fp nh fr fs ni fu fw dk translated">简明的地理空间数据特征工程和可视化指南</h3></div><div class="nk l"><p class="bd b dl z fp nh fr fs ni fu fw dk translated">towardsdatascience.com</p></div></div><div class="nl l"><div class="pg l nn no np nl nq ky nc"/></div></div></a></div><p id="f2f3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们继续学习吧！</p></div></div>    
</body>
</html>