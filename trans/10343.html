<html>
<head>
<title>How I built an AI Text-to-Art Generator</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我如何建立一个人工智能文本到艺术的生成器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-i-built-an-ai-text-to-art-generator-a0c0f6d6f59f?source=collection_archive---------0-----------------------#2021-10-02">https://towardsdatascience.com/how-i-built-an-ai-text-to-art-generator-a0c0f6d6f59f?source=collection_archive---------0-----------------------#2021-10-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3419" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一篇关于我如何建设Text2Art.com的详细、循序渐进的文章</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/08f5b02499e9996e452a7221f7fa31bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/1*ukOiybiWShMNiKRJhkJkFA.gif"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">text 2生成艺术画廊[图片由作者提供]</p></figure><h1 id="fb11" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">概观</h1><p id="63d8" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">这篇文章是关于我如何在一周内建造了Text2Art.com的。Text2Art是一个基于VQGAN+CLIP的AI驱动的艺术生成器，可以仅从文本输入生成各种艺术，如像素艺术、绘图和绘画。文章跟随我的思维过程，从尝试VQGAN+CLIP，用Gradio构建简单的UI，切换到FastAPI为模型服务，最后使用Firebase作为队列系统。请随意跳到您感兴趣的部分。</p><blockquote class="mj"><p id="46fc" class="mk ml it bd mm mn mo mp mq mr ms mh dk translated">你可以在text2art.com<a class="ae mi" href="http://text2art.com" rel="noopener ugc nofollow" target="_blank">的</a>尝试一下，这里是<a class="ae mi" href="https://github.com/mfrashad/text2art" rel="noopener ugc nofollow" target="_blank">的源代码</a>(随意启动回购)</p></blockquote><figure class="mt mu mv mw mx kn"><div class="bz fp l di"><div class="my mz l"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">Text2Art演示(更新:我们现在有15k+用户)</p></figure><h1 id="1e40" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">概述</h1><ul class=""><li id="b16b" class="na nb it lo b lp lq ls lt lv nc lz nd md ne mh nf ng nh ni bi translated">介绍</li><li id="8903" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">它是如何工作的</li><li id="7a92" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">用VQGAN+带代码的剪辑生成艺术</li><li id="b626" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">用Gradio制作用户界面</li><li id="aac5" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">用FastAPI供应ML</li><li id="92d7" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated">基于Firebase的排队系统</li></ul><h1 id="f464" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated"><strong class="ak">简介</strong></h1><p id="0808" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">不久前，生成艺术和NFT风靡全球。这是在OpenAI在文本到图像生成方面取得重大进展后才成为可能的。今年早些时候，OpenAI发布了一款功能强大的文本到图像生成器，效果非常好。为了说明DALL-E工作得有多好，这些是DALL-E生成的图像，带有文本提示“一个专业的高质量长颈鹿龙奇美拉插图”。模仿龙的长颈鹿。龙做的长颈鹿”。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi no"><img src="../Images/ee8474267a33bc85c3cc40b9734adaf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DafIRlTrsgGkC0y7.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">DALL-E制作的法师在得到文字提示“一个专业高质量的长颈鹿龙奇美拉插图”时。模仿龙的长颈鹿。龙做的长颈鹿。”[图片由拥有麻省理工学院许可证的<a class="ae mi" href="https://en.wikipedia.org/wiki/DALL-E#/media/File:DALL-E_sample.png" rel="noopener ugc nofollow" target="_blank"> OpenAI </a>提供]</p></figure><p id="8a17" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">不幸的是，DALL-E没有向公众发布。但幸运的是，DALL-E魔术背后的模型<a class="ae mi" href="https://openai.com/blog/clip/" rel="noopener ugc nofollow" target="_blank"> CLIP </a>反而出版了。剪辑或对比图像语言预训练是一个结合文本和图像的多模态网络。简而言之，CLIP能够评估图片与标题的匹配程度，反之亦然。这对于引导生成器生成与文本输入完全匹配的图像非常有用。在DALL-E中，CLIP用于对生成的图像进行排序，输出得分最高的图像(最类似于文本提示)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/4dae2b1baeb812bc3639cd2982af185a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*YUfLMCLNsRfGKW_O7EHCbQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">片段评分图像和说明的示例[按作者分类的图像]</p></figure><p id="c1d7" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">在DALL-E公布后的几个月，一个名为<a class="ae mi" href="https://compvis.github.io/taming-transformers/" rel="noopener ugc nofollow" target="_blank"> VQGAN </a>(矢量量化GAN)的新变形金刚图像生成器发表了。将VQGAN与CLIP相结合，可获得与DALL-E相似的质量。自预先训练的VQGAN模型公开以来，社区已经创造了许多令人惊叹的艺术。</p><div class="kj kk kl km gt ab cb"><figure class="nz kn oa ob oc od oe paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><img src="../Images/d5fb8691766bb9a1c14b385031d75628.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*4MXzMxBaH_s_25a0.png"/></div></figure><figure class="nz kn of ob oc od oe paragraph-image"><img src="../Images/8349e4889917cefdd36d700b21fb4ee3.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/0*do9DpWUFqgjw9u-X.png"/><p class="kq kr gj gh gi ks kt bd b be z dk og di oh oi translated">多船城市港口夜景画，战争中的难民画。[图片由作者生成]</p></figure></div><p id="d5bb" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">我真的对结果感到惊讶，并想与我的朋友分享这一点。但由于没有多少人愿意钻研代码来生成艺术，我决定创建Text2Art.com，一个任何人都可以简单地输入提示并快速生成他们想要的图像而不用看任何代码的网站。</p><h1 id="2d93" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">它是如何工作的</h1><p id="0da2" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">那么VQGAN+CLIP是如何工作的呢？简而言之，生成器将生成图像，剪辑将测量图像与图像的匹配程度。然后，生成器使用来自剪辑模型的反馈来生成更“准确”的图像。这种迭代将进行多次，直到剪辑分数变得足够高，并且生成的图像与文本匹配。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi oj"><img src="../Images/c1823a0fcb399903976250eeccbf45d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WeVqITaPf0a-mlIY.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated"><em class="ok">VQGAN模型生成图像，而CLIP指导这个过程。这是通过多次迭代完成的，直到生成器学会产生更“精确”的图像。【来源:</em> <a class="ae mi" href="https://ljvmiranda921.github.io/notebook/2021/08/08/clip-vqgan/" rel="noopener ugc nofollow" target="_blank"> <em class="ok"> T </em>何插图VQGAN作者:LJ Miranda</a><em class="ok">】</em></p></figure><p id="0d48" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">我不会在这里讨论VQGAN或CLIP的内部工作原理，因为这不是本文的重点。但是如果你想深入了解VQGAN、CLIP或DALL-E，你可以参考我找到的这些令人惊叹的资源。</p><ul class=""><li id="7d7a" class="na nb it lo b lp nt ls nu lv ol lz om md on mh nf ng nh ni bi translated"><a class="ae mi" href="https://ljvmiranda921.github.io/notebook/2021/08/08/clip-vqgan/" rel="noopener ugc nofollow" target="_blank">LJ Miranda的插图VQGAN</a>:用很棒的插图解释VQGAN。</li><li id="8a69" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated"><a class="ae mi" href="https://ml.berkeley.edu/blog/posts/vq-vae/" rel="noopener ugc nofollow" target="_blank">Charlie Snell解释的DALL-E</a>:从基础开始的伟大DALL-E解释</li><li id="2226" class="na nb it lo b lp nj ls nk lv nl lz nm md nn mh nf ng nh ni bi translated"><a class="ae mi" href="https://youtu.be/T9XSU0pKX2E" rel="noopener ugc nofollow" target="_blank">Yannic kil cher的回形针讲解视频</a>:回形针讲解</li></ul><h2 id="b331" class="oo kv it bd kw op oq dn la or os dp le lv ot ou lg lz ov ow li md ox oy lk oz bi translated">X +剪辑</h2><p id="5aa0" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">VQGAN+CLIP是一个简单的例子，说明了将图像生成器与CLIP相结合可以实现的功能。然而，你可以用任何类型的生成器替换VQGAN，它仍然可以很好地工作，这取决于生成器。X + CLIP的许多变体已经出现，如<a class="ae mi" href="https://github.com/orpatashnik/StyleCLIP" rel="noopener ugc nofollow" target="_blank"> StyleCLIP </a> (StyleGAN + CLIP)、<a class="ae mi" href="https://arxiv.org/abs/2106.14843" rel="noopener ugc nofollow" target="_blank"> CLIPDraw </a>(使用矢量艺术生成器)、BigGAN + CLIP等等。甚至有<a class="ae mi" href="https://github.com/AndreyGuzhov/AudioCLIP" rel="noopener ugc nofollow" target="_blank">音频剪辑</a>使用音频而不是图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi pa"><img src="../Images/7a5b93ac630bdb02b3b8994c4128d70f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NL6r1DKhDgZhCwdc.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">使用StyleCLIP编辑图像[Source: <a class="ae mi" href="https://github.com/orpatashnik/StyleCLIP" rel="noopener ugc nofollow" target="_blank"> StyleCLIP Paper </a></p></figure><h1 id="f052" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">用VQGAN+带代码的剪辑生成艺术</h1><p id="d8c3" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我一直在使用dribnet的<a class="ae mi" href="https://github.com/dribnet/clipit" rel="noopener ugc nofollow" target="_blank"> clipit </a>资源库中的代码，这使得使用VQGAN+CLIP生成艺术变成了简单的几行代码(更新:<a class="ae mi" href="https://github.com/dribnet/clipit" rel="noopener ugc nofollow" target="_blank"> clipit </a>已经迁移到了<a class="ae mi" href="https://github.com/dribnet/pixray" rel="noopener ugc nofollow" target="_blank"> pixray </a>)。</p><p id="b858" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">建议在Google Colab上运行，因为VQGAN+CLIP需要相当多的GPU内存。这里有一本<a class="ae mi" href="https://colab.research.google.com/github/mfrashad/text2art/blob/main/text2art.ipynb" rel="noopener ugc nofollow" target="_blank"> Colab笔记本</a>你可以跟着看。</p><p id="2c71" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">首先，如果你在Colab上运行，确保你把运行时类型改成使用GPU。</p><div class="kj kk kl km gt ab cb"><figure class="nz kn pb ob oc od oe paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><img src="../Images/ec3ca41187ec3ac288acce0277625f72.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*iAHXIsRGdeK_Tb_0OmWrBg.png"/></div></figure><figure class="nz kn pc ob oc od oe paragraph-image"><img src="../Images/93a202256a660c0e05cbd9d584c8db88.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*v15OK9hyh_JYjnLOoj1_wQ.png"/><p class="kq kr gj gh gi ks kt bd b be z dk pd di pe oi translated">将Colab运行时类型更改为GPU的步骤。[图片由作者提供]</p></figure></div><p id="c36b" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">接下来，我们需要首先设置代码库和依赖项。</p><pre class="kj kk kl km gt pf pg ph pi aw pj bi"><span id="e1ab" class="oo kv it pg b gy pk pl l pm pn"><strong class="pg iu">from</strong> <strong class="pg iu">IPython.utils</strong> <strong class="pg iu">import</strong> io<br/><strong class="pg iu">with</strong> io.capture_output() <strong class="pg iu">as</strong> captured:<br/>  !git clone https://github.com/openai/CLIP<br/>  <em class="po"># !pip install taming-transformers</em><br/>  !git clone https://github.com/CompVis/taming-transformers.git<br/>  !rm -Rf clipit<br/>  !git clone https://github.com/mfrashad/clipit.git<br/>  !pip install ftfy regex tqdm omegaconf pytorch-lightning<br/>  !pip install kornia<br/>  !pip install imageio-ffmpeg   <br/>  !pip install einops<br/>  !pip install torch-optimizer<br/>  !pip install easydict<br/>  !pip install braceexpand<br/>  !pip install git+https://github.com/pvigier/perlin-numpy<br/><br/>  <em class="po"># ClipDraw deps</em><br/>  !pip install svgwrite<br/>  !pip install svgpathtools<br/>  !pip install cssutils<br/>  !pip install numba<br/>  !pip install torch-tools<br/>  !pip install visdom<br/><br/>  !pip install gradio<br/><br/>  !git clone https://github.com/BachiLi/diffvg<br/>  %cd diffvg<br/>  <em class="po"># !ls</em><br/>  !git submodule update --init --recursive<br/>  !python setup.py install<br/>  %cd ..<br/>  <br/>  !mkdir -p steps<br/>  !mkdir -p models</span></pre><p id="67f4" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">(注:“！”是google Colab中的一个特殊命令，这意味着它将在bash而不是python中运行该命令”)</p><p id="81fe" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">一旦我们安装了库，我们就可以导入<code class="fe pp pq pr pg b">clipit</code>并运行这几行代码来用VQGAN+CLIP生成你的艺术作品。只需随意更改文本提示。此外，您还可以给<code class="fe pp pq pr pg b">clipit</code>一些选项，如迭代次数、宽度、高度、生成器模型、是否要生成视频等等。您可以阅读<a class="ae mi" href="https://github.com/mfrashad/clipit/blob/master/clipit.py" rel="noopener ugc nofollow" target="_blank">源代码</a>以获得更多关于可用选项的信息。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ps mz l"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">使用VQGAN+CLIP生成艺术作品的代码</p></figure><p id="994e" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">一旦你运行代码，它将生成一个图像。对于每次迭代，生成的图像将更接近文本提示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi pt"><img src="../Images/7758440877894bcc603d296a52b2c218.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*af0aFZegZOJ73imceppK9A.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">基于“水下城市”较长迭代的结果改进。[图片由作者提供]</p></figure><h2 id="d6e0" class="oo kv it bd kw op oq dn la or os dp le lv ot ou lg lz ov ow li md ox oy lk oz bi translated">更长的迭代</h2><p id="8ac7" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">如果您想生成一个更长的迭代，只需使用<code class="fe pp pq pr pg b">iterations</code>选项，并将其设置为您想要的长度。例如，如果您希望它运行500次迭代。</p><pre class="kj kk kl km gt pf pg ph pi aw pj bi"><span id="fb49" class="oo kv it pg b gy pk pl l pm pn">clipit.add_settings(iterations=500)</span></pre><h2 id="bdaf" class="oo kv it bd kw op oq dn la or os dp le lv ot ou lg lz ov ow li md ox oy lk oz bi translated">生成视频</h2><p id="d964" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">因为我们无论如何都需要为每次迭代生成图像，所以我们可以保存这些图像，并创建一个关于人工智能如何生成图像的动画。为此，您可以在应用设置之前简单地添加<code class="fe pp pq pr pg b">make_video=True</code>。</p><pre class="kj kk kl km gt pf pg ph pi aw pj bi"><span id="7850" class="oo kv it pg b gy pk pl l pm pn">clipit.add_settings(make_video=True)</span></pre><p id="8b8c" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">它将生成以下视频。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi pu"><img src="../Images/6f904a918e4c760b9998363c5a0ea7d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*tASkZrx_poGKZL4nl6PN1Q.gif"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">生成的“水下城市”GIF[图片由作者提供]</p></figure><h2 id="c415" class="oo kv it bd kw op oq dn la or os dp le lv ot ou lg lz ov ow li md ox oy lk oz bi translated">自定义图像大小</h2><p id="d578" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">您也可以通过添加<code class="fe pp pq pr pg b">size=(width, height)</code>选项来修改图像。例如，我们将生成一个分辨率为800x200的横幅图像。请注意，更高的分辨率将需要更高的GPU内存。</p><pre class="kj kk kl km gt pf pg ph pi aw pj bi"><span id="e329" class="oo kv it pg b gy pk pl l pm pn">clipit.add_settings(size=(800, 200))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi pv"><img src="../Images/ffb515f54c216838d167ab0c855921e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MbsxDOoF23m2yGdgNLa_WQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">生成800x200图片，提示“幻想王国# art station”[图片由作者提供]</p></figure><h2 id="adc1" class="oo kv it bd kw op oq dn la or os dp le lv ot ou lg lz ov ow li md ox oy lk oz bi translated">生成像素艺术</h2><p id="52f5" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">还有一个在clipit中生成像素艺术的选项。它在场景后面使用CLIPDraw渲染器，通过一些工程来强制像素艺术风格，例如限制调色板颜色、像素化等。要使用像素艺术选项，只需启用<code class="fe pp pq pr pg b">use_pixeldraw=True</code>选项。</p><pre class="kj kk kl km gt pf pg ph pi aw pj bi"><span id="4f8e" class="oo kv it pg b gy pk pl l pm pn">clipit.add_settings(use_pixeldraw=True)</span></pre><div class="kj kk kl km gt ab cb"><figure class="nz kn pw ob oc od oe paragraph-image"><img src="../Images/5edf918b5cfbe5e308136377dd62d318.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*qeAm5xD0krzDzGA0.png"/></figure><figure class="nz kn px ob oc od oe paragraph-image"><img src="../Images/509f2a79c759899cf6174d0f16da2c42.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*MV61P5WAYCz2cZe5.png"/><p class="kq kr gj gh gi ks kt bd b be z dk py di pz oi translated">生成的图像带有提示“盔甲骑士#pixelart”(左)和“中国奇幻电子游戏世界#pixelart”(右)[图片由作者提供]</p></figure></div><h2 id="fd08" class="oo kv it bd kw op oq dn la or os dp le lv ot ou lg lz ov ow li md ox oy lk oz bi translated">VQGAN+剪辑关键字修改器</h2><p id="5cd0" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">由于CLIP中的偏差，在提示中添加某些关键字可能会对生成的图像产生一定的效果。例如，在文本提示中添加“虚幻引擎”往往会生成逼真或高清的样式。添加某些网站名称，如“deviantart”、“artstation”或“flickr”，通常会使结果更加美观。我最喜欢的是使用“艺术站”关键字，因为我发现它产生最好的艺术。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi qa"><img src="../Images/8671bb30c089f7b19de53f2c63110aa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yVHBKcdoGDs7SNZ21r94Bw.jpeg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">关键词对比[ <a class="ae mi" href="https://imgur.com/a/SALxbQm" rel="noopener ugc nofollow" target="_blank">图片由kingdomakrillic </a></p></figure><p id="5129" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">此外，您还可以使用关键字来调节艺术风格。例如，关键字“铅笔素描”，“低聚”，甚至艺术家的名字，如“托马思·金凯德”或“詹姆斯格尼”。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi qb"><img src="../Images/f6444cafe1218e69c267b56db99251a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_vwNbasrHuw5ScVIugi4aw.jpeg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">Artstyle关键字比较。[ <a class="ae mi" href="https://imgur.com/a/SALxbQm" rel="noopener ugc nofollow" target="_blank">图片由kingdomakrillic </a>提供</p></figure><p id="6607" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">要了解更多关于各种关键词的效果，您可以查看kingdomakrillic 的<a class="ae mi" href="https://imgur.com/a/SALxbQm" rel="noopener ugc nofollow" target="_blank">完整实验结果，它显示了使用相同4个主题的200多个关键词的结果。</a></p><h1 id="64da" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">用Gradio构建UI</h1><p id="2ea2" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我部署ML模型的第一个计划是使用<a class="ae mi" href="https://gradio.app/" rel="noopener ugc nofollow" target="_blank"> Gradio </a>。Gradio是一个python库，它将ML演示的构建简化为几行代码。使用Gradio，您可以在不到10分钟的时间内构建一个演示。此外，您可以在Colab中运行Gradio，它将使用Gradio域生成一个可共享的链接。您可以立即与您的朋友或公众分享此链接，让他们试用您的演示。Gradio仍然有一些限制，但我发现当你只想演示一个函数时，它是最合适的库。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi qc"><img src="../Images/52c2b752e451efd321830e9b4d8ab4b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*L_PqJ6neCcCPmOkn-XOxVQ.gif"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">gradio UI[图片由作者提供]</p></figure><p id="5a20" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">这是我为Text2Art应用程序编写的简单UI代码。我认为代码是不言自明的，但是如果你需要更多的解释，你可以阅读<a class="ae mi" href="https://gradio.app/docs" rel="noopener ugc nofollow" target="_blank"> Gradio文档</a>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ps mz l"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">构建Gradio UI的代码</p></figure><p id="c664" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">一旦你在Google Colab或local中运行它，它将生成一个可共享的链接，使你的演示可以公开。我发现这非常有用，因为我自己不需要像Ngrok一样使用SSH隧道来分享我的演示。此外，Gradio还提供托管服务，您可以永久托管您的演示，每月仅需7美元。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi qd"><img src="../Images/c1b53ae754c39c42acad78eeb33a1906.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x_u47xwrEN6J9jKAlAvu8w.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">Gradio演示的可共享链接。[图片由作者提供]</p></figure><p id="37ad" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">然而，Gradio仅适用于演示单一功能。创建一个带有额外功能的自定义站点，比如图库、登录，甚至只是自定义CSS，都是相当有限的，或者根本不可能。</p><p id="b71f" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">我能想到的一个快速解决方案是创建一个独立于Gradio UI的演示站点。然后，我可以使用iframe元素在站点上嵌入Gradio UI。我最初尝试了这种方法，但后来意识到一个重要的缺点，我不能个性化任何需要与ML应用程序本身交互的部分。例如，输入验证、自定义进度条等功能在iframe中是不可能实现的。这是我决定建立一个API的时候。</p><h1 id="f87d" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">用FastAPI服务ML模型</h1><p id="582d" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我一直使用FastAPI而不是Flask来快速构建我的API。主要原因是我发现FastAPI写起来更快(代码更少),而且它还自动生成文档(使用Swagger UI ),允许我用基本UI测试API。另外，FastAPI支持异步函数，据说比Flask 更快<a class="ae mi" href="https://fastapi.tiangolo.com/benchmarks/" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi qe"><img src="../Images/76838cda0599c6fddff65aeecf8358c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HUSz7taTaiCgO63czf6icw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">通过在URL中添加/docs/来访问Swagger UI</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qf"><img src="../Images/d93541ab841a4752cb1b2da75cb9edaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*Zyl9xH9Tlne-V1A-V89mcw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">在Swagger UI中测试API图片由作者提供]</p></figure><p id="3254" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">下面是我编写的代码，它将我的ML函数作为FastAPI服务器。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ps mz l"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">API服务器的代码</p></figure><p id="3214" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">一旦我们定义了服务器，我们就可以使用uvicorn运行它。此外，因为Google Colab只允许通过Colab接口访问他们的服务器，所以我们必须使用Ngrok向公众公开FastAPI服务器。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ps mz l"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">运行和公开服务器的代码</p></figure><p id="471d" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">一旦我们运行了服务器，我们就可以进入Swagger UI(通过在生成的ngrok URL上添加<code class="fe pp pq pr pg b">/docs</code>)并测试API。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qg"><img src="../Images/34d9290ec8fc22aeab045471b2c965a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*Ql3BPECZ8yuKas6Vpq7VMA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">使用FastAPI Swagger UI生成“水下城堡”</p></figure><p id="2d59" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">在测试API时，我意识到根据质量和迭代次数的不同，推断可能需要大约3-20分钟。对于HTTP请求来说，3分钟本身已经被认为很长了，用户可能不想在站点上等待那么长时间。由于推理时间较长，我认为将推理设置为后台任务并在结果出来后给用户发电子邮件可能更适合这个任务。</p><p id="9e9c" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">既然我们决定了计划，我们首先将编写发送电子邮件的函数。我最初使用SendGrid电子邮件API来完成这项工作，但在用完免费使用配额(100封电子邮件/天)后，我改用Mailgun API，因为它们是GitHub学生开发包的一部分，允许学生每月发送20，000封电子邮件。</p><p id="e472" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">下面是使用Mailgun API发送带有图像附件的电子邮件的代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ps mz l"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">使用Mailgun API发送电子邮件的代码</p></figure><p id="2953" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">接下来，我们将修改我们的服务器代码以使用FastAPI中的后台任务，并在后台通过电子邮件发送结果。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ps mz l"/></div></figure><p id="ef95" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">有了上面的代码，服务器将很快用“任务在后台处理”消息来回复请求，而不是等待生成过程完成，然后用图像来回复。</p><p id="627c" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">一旦该过程完成，服务器将通过电子邮件向用户发送结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qh"><img src="../Images/f0302582917ccc6e80cced3763d5ae5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*PFsSfcp0k2cgQsmlF_R7xQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图像和视频结果通过电子邮件发送给用户。[图片由作者提供]</p></figure><p id="fdb8" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">现在一切似乎都正常了，我建立了<a class="ae mi" href="http://text2art.com" rel="noopener ugc nofollow" target="_blank">前端</a>，并与我的朋友们分享了这个网站。然而，我发现在对多个用户进行测试时存在并发问题。</p><p id="4000" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">当第二个用户在第一个任务仍在处理时向服务器发出请求，第二个任务会以某种方式终止当前进程，而不是创建一个并行进程或队列。我不确定这是什么原因造成的，可能是在clipit代码中使用了全局变量，也可能不是。我没有花太多时间调试它，因为我意识到我需要实现一个消息队列系统。</p><p id="04a0" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">在消息队列系统上谷歌搜索了几下后，大多数都推荐RabbitMQ或者Redis。然而，我不确定RabbitMQ或Redis是否可以安装在Google Colab上，因为它似乎需要<code class="fe pp pq pr pg b">sudo</code>的许可。最后，我决定使用Google Firebase作为队列系统，因为我想尽快完成这个项目，而Firebase是我最熟悉的一个。</p><p id="ded6" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">基本上，当用户试图在前端生成一个艺术时，它会在一个名为<code class="fe pp pq pr pg b">queue</code>的集合中添加一个条目来描述任务(提示、图像类型、大小等)。另一方面，我们将在Google Colab上运行一个脚本，该脚本持续监听<code class="fe pp pq pr pg b">queue</code>集合中的新条目，并逐个处理任务。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ps mz l"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">处理任务并持续监听队列的后端代码</p></figure><p id="dbec" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">在前端，我们只需在队列中添加一个新任务。但是确保你已经在你的前端做了一个合适的<a class="ae mi" href="https://firebase.google.com/docs/web/setup" rel="noopener ugc nofollow" target="_blank"> Firebase设置</a>。</p><pre class="kj kk kl km gt pf pg ph pi aw pj bi"><span id="f776" class="oo kv it pg b gy pk pl l pm pn">db.collection("queue").add({<br/>        prompt: prompt,<br/>        email: email,<br/>        quality: quality,<br/>        type: type,<br/>        aspect: aspect,<br/>        created_at: firebase.firestore.FieldValue.serverTimestamp(),<br/>})</span></pre><p id="e7ef" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">完成了！现在，当用户试图在前端生成art时，它会在队列中添加一个新任务。Colab服务器中的worker脚本将逐个处理队列中的任务。</p><blockquote class="mj"><p id="3cc4" class="mk ml it bd mm mn mo mp mq mr ms mh dk translated">你可以查看<a class="ae mi" href="https://github.com/mfrashad/text2art" rel="noopener ugc nofollow" target="_blank"> GitHub回购</a>来查看完整的代码(随意开始回购)。</p></blockquote><figure class="mt mu mv mw mx kn gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi qi"><img src="../Images/2141bf10d489fe6458a4113170d40b53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Gdpcj0tCfAFiI7pyb-lcw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">在前端队列中添加新任务[图片由作者提供]</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi qj"><img src="../Images/302f7641841cd52d16ad20a1145967f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NMvUBobCW7UzmYxd8QgojA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">Firebase中的队列内容[图片由作者提供]</p></figure></div><div class="ab cl qk ql hx qm" role="separator"><span class="qn bw bk qo qp qq"/><span class="qn bw bk qo qp qq"/><span class="qn bw bk qo qp"/></div><div class="im in io ip iq"><p id="5b04" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">如果你喜欢我的文章，看看我的其他文章！</p><div class="qr qs gp gr qt qu"><a rel="noopener follow" target="_blank" href="/animating-yourself-as-a-disney-character-with-ai-78af337d4081"><div class="qv ab fo"><div class="qw ab qx cl cj qy"><h2 class="bd iu gy z fp qz fr fs ra fu fw is bi translated">用人工智能让你自己成为一个迪斯尼角色</h2><div class="rb l"><h3 class="bd b gy z fp qz fr fs ra fu fw dk translated">先睹为快数字艺术的未来</h3></div><div class="rc l"><p class="bd b dl z fp qz fr fs ra fu fw dk translated">towardsdatascience.com</p></div></div><div class="rd l"><div class="re l rf rg rh rd ri ko qu"/></div></div></a></div><div class="qr qs gp gr qt qu"><a rel="noopener follow" target="_blank" href="/generating-anime-characters-with-stylegan2-6f8ae59e237b"><div class="qv ab fo"><div class="qw ab qx cl cj qy"><h2 class="bd iu gy z fp qz fr fs ra fu fw is bi translated">使用StyleGAN2生成动画角色</h2><div class="rb l"><h3 class="bd b gy z fp qz fr fs ra fu fw dk translated">了解如何生成这个很酷的动画人脸插值</h3></div><div class="rc l"><p class="bd b dl z fp qz fr fs ra fu fw dk translated">towardsdatascience.com</p></div></div><div class="rd l"><div class="rj l rf rg rh rd ri ko qu"/></div></div></a></div><p id="b5db" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">也可以在Linkedin上和我联系。</p><div class="qr qs gp gr qt qu"><a href="https://www.linkedin.com/in/mfathyrashad/" rel="noopener  ugc nofollow" target="_blank"><div class="qv ab fo"><div class="qw ab qx cl cj qy"><h2 class="bd iu gy z fp qz fr fs ra fu fw is bi translated">Muhammad Fathy Rashad -技术作家-中型| LinkedIn</h2><div class="rb l"><h3 class="bd b gy z fp qz fr fs ra fu fw dk translated">16岁时，我作为大学最年轻的学生开始了我的学位，并出版了2款2K+…</h3></div><div class="rc l"><p class="bd b dl z fp qz fr fs ra fu fw dk translated">www.linkedin.com</p></div></div><div class="rd l"><div class="rk l rf rg rh rd ri ko qu"/></div></div></a></div><h1 id="f40d" class="ku kv it bd kw kx ky kz la lb lc ld le jz lf ka lg kc lh kd li kf lj kg lk ll bi translated">参考</h1><p id="a35b" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">[1]<a class="ae mi" href="https://openai.com/blog/dall-e/" rel="noopener ugc nofollow" target="_blank">https://openai.com/blog/dall-e/</a></p><p id="3621" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated"><a class="ae mi" href="https://openai.com/blog/clip/" rel="noopener ugc nofollow" target="_blank">https://openai.com/blog/clip/</a></p><p id="c571" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">[3]<a class="ae mi" href="https://ljvmiranda921.github.io/notebook/2021/08/08/clip-vqgan/" rel="noopener ugc nofollow" target="_blank">https://ljvmiranda 921 . github . io/notebook/2021/08/08/clip-vqgan/</a></p><p id="7e2d" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated"><a class="ae mi" href="https://github.com/orpatashnik/StyleCLIP" rel="noopener ugc nofollow" target="_blank">https://github.com/orpatashnik/StyleCLIP</a></p><p id="0684" class="pw-post-body-paragraph lm ln it lo b lp nt ju lr ls nu jx lu lv nv lx ly lz nw mb mc md nx mf mg mh im bi translated">[5]<a class="ae mi" rel="noopener" target="_blank" href="/understanding-flask-vs-fastapi-web-framework-fe12bb58ee75">https://towards data science . com/understanding-flask-vs-fastapi-we b-framework-Fe 12 bb 58 ee 75</a></p></div></div>    
</body>
</html>