<html>
<head>
<title>A step-by-step guide for clustering images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图像聚类的分步指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-step-by-step-guide-for-clustering-images-4b45f9906128?source=collection_archive---------0-----------------------#2021-12-10">https://towardsdatascience.com/a-step-by-step-guide-for-clustering-images-4b45f9906128?source=collection_archive---------0-----------------------#2021-12-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e177" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用于图像簇的检测和探索。了解如何仔细预处理图像，利用众所周知的特征提取方法，并评估聚类的良好性。理论背景，然后是实践教程。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e6b44da2c6bbd94ccd3ccd76ed0cf15a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4RSmrTrHpBWiHO-gRz9wTw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@universaleye?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">万用眼</a>在<a class="ae ky" href="https://unsplash.com/s/photos/clusters?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="358a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">许多计算机视觉任务依赖于(深度)神经网络，旨在预测“<em class="lv">图像</em>上有什么”。然而，并不是所有的任务都需要监督方法或神经网络。通过无监督的方法，我们可以确定图像的自然组或簇，而不局限于固定数量的(学习的)类别。在这篇博客中，我将总结<em class="lv">无监督聚类</em>的概念，然后是一个关于如何预处理图像、提取特征(PCA、HOG)以及考虑到聚类的良好性对具有高相似性的图像进行分组的实践教程。我将演示对<strong class="lb iu"><em class="lv">【MNIST】</em><em class="lv"/><strong class="lb iu"><em class="lv">数据集</em> </strong>、<strong class="lb iu"> <em class="lv"> 101 对象数据集</em> </strong>、<strong class="lb iu"> <em class="lv">花数据集</em> </strong>的聚类，最后使用<strong class="lb iu"><em class="lv">【Olivetti】数据集</em> </strong>对<strong class="lb iu"> <em class="lv">面孔</em> </strong>的聚类。所有结果都是使用 Python <a class="ae ky" href="https://erdogant.github.io/clustimage" rel="noopener ugc nofollow" target="_blank">库<em class="lv">clustimage</em>T37】导出的。</a></strong></p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="5612" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">如果你觉得这篇文章很有帮助，可以使用我的</em> <a class="ae ky" href="https://medium.com/@erdogant/membership" rel="noopener"> <em class="lv">推荐链接</em> </a> <em class="lv">继续无限制学习，并注册成为中级会员。另外，</em> <a class="ae ky" href="http://erdogant.medium.com" rel="noopener"> <em class="lv">关注我</em> </a> <em class="lv">关注我的最新内容！</em></p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="2bd3" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">重要的事情先来。</h1><p id="2cf8" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">图像识别是一项计算机视觉任务，其识别部分可以分为有监督的和无监督的方法。在监督任务的情况下，<em class="lv">目标可以是对图像或图像上的对象进行分类</em>。现在有各种各样的预学习模型用于分类任务。共同的主题是，所有监督模型都需要一个学习步骤，其中使用基础事实标签来学习模型的对象。一些模型可以容易地识别数百个对象，并且这个数字在稳步增加，但是大多数特定领域的对象在预先学习的模型中可能仍然是未知的。在这种情况下，向无监督聚类方法的过渡似乎是不可避免的。构建高质量的标注数据集是一项艰巨的任务，因此倾向于使用聚类方法。</p><blockquote class="na"><p id="0900" class="nb nc it bd nd ne nf ng nh ni nj lu dk translated"><em class="nk">一般来说，无监督机器学习的任务是从“未标记”的数据中推断出一个描述隐藏结构的函数</em>。</p></blockquote><p id="6a6f" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">非监督任务不仅仅是聚类，还可以用于各种其他任务，如数据探索、离群点检测和特征提取。在这篇博客中，我将关注<strong class="lb iu"> <em class="lv">无监督聚类方法及其在图像识别中的应用</em> </strong>。然而，图像的聚类需要多个步骤，每个步骤都会影响最终的聚类结果。让我们从一个示意图开始，然后进入兔子洞。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="45a0" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">图像聚类的示意图。</h1><p id="6d29" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">图像的聚类是一个多步骤的过程，其步骤是<strong class="lb iu"> <em class="lv">预处理图像</em></strong><strong class="lb iu"><em class="lv">提取特征</em></strong><strong class="lb iu"><em class="lv">根据相似性对图像</em> </strong>进行聚类，<strong class="lb iu"> <em class="lv">使用优度来评估聚类的最佳数目</em> </strong> <em class="lv"> </em>。另请参见图 1 中的示意图。所有这些步骤都很容易在 python 包<a class="ae ky" href="https://erdogant.github.io/clustimage" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="lv">clustimage</em></strong></a>中实现，该包只需要<strong class="lb iu"> <em class="lv">路径位置</em> </strong>或<strong class="lb iu"> <em class="lv">原始像素值</em> </strong>作为输入。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/7780994aebcc71c336fa5832ee219376.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p5AEA72wGVlNG8c892MTdw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图一。图像无监督聚类的 clustimage 中所采取步骤的示意图。图片来自作者。</p></figure><p id="ddc2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将在接下来的章节中描述这些步骤，但是让我们先简单介绍一下无监督聚类的背景和一些术语。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="bc05" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">无监督聚类。</h1><p id="6f15" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">对于无监督聚类，我们的目标是在不使用关于标签或类别的先验知识的情况下，确定数据中的“<em class="lv">自然的</em>或“<em class="lv">数据驱动的</em>”组。使用不同的无监督聚类方法的挑战在于，它将导致样本的不同划分，从而导致不同的分组，因为每种方法都隐含地对数据施加了结构。因此问题出现了；<em class="lv">什么是“好的”集群？</em>图 2A 描绘了二维空间中的一串样本。直观上，我们可以将它描述为一组杂乱的样本(也称为图像)。我会声明有两个不使用任何标签信息的聚类。<em class="lv">为什么？</em>因为点与点之间的距离，以及杂乱样本之间相对较大的“间隙”。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/28ca9f238c9cc50fe7c5d578a67c238d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rXE-_93t79ZCIRJ2fEcTzg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图二。聚类示例。图片来自作者。</p></figure><p id="8579" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">考虑到这一点，我们可以将我们对“<em class="lv">簇</em>”的直觉转换成一个数学陈述，例如；所谓的类内样本的方差应该较小(<strong class="lb iu"> <em class="lv">内方差</em></strong>【σW】<strong class="lb iu"><em class="lv">，红蓝</em> </strong>)，同时类间方差应该较大(<strong class="lb iu"> <em class="lv">间方差，</em></strong>【σB】)，如图 2B 所示。样本之间的距离(或内在关系)可以用<strong class="lb iu"> <em class="lv">一个距离度量</em> </strong>(例如<em class="lv">欧几里德</em>距离)来测量，并存储在所谓的<em class="lv">相异度矩阵</em>中。然后可以使用<strong class="lb iu"> <em class="lv">链接类型</em> </strong>计算样本组之间的距离(用于层次聚类)。</p><h2 id="0899" class="ns me it bd mf nt nu dn mj nv nw dp mn li nx ny mp lm nz oa mr lq ob oc mt od bi translated">距离度量</h2><p id="e5b9" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">最广为人知的距离度量是<em class="lv">欧几里德距离</em>。尽管在许多方法中它被设置为默认度量，但它并不总是最佳选择。</p><blockquote class="na"><p id="fb9b" class="nb nc it bd nd ne nf ng nh ni nj lu dk translated"><strong class="ak"> <em class="nk">理解指标的数学属性，使其符合数据的统计属性，并与研究问题保持一致。</em> </strong></p></blockquote><p id="a6c7" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">各种距离度量的示意图如图 3 所示[1]。在图像相似的情况下，当使用<em class="lv">主成分分析(PCA)</em>【2】或<em class="lv">梯度方向直方图(HOG) </em>提取特征时，推荐使用<em class="lv">欧几里德</em>距离。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/f9c0875d20942453bd4e983c047ebd50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p3IBF63oMY4iQfPum0oERQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 3:最流行的距离度量的示意图。图片作者:马腾·格鲁特·奥斯特[1]。由作者编辑。</p></figure><h2 id="4170" class="ns me it bd mf nt nu dn mj nv nw dp mn li nx ny mp lm nz oa mr lq ob oc mt od bi translated">链接类型</h2><p id="9bcc" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated"><em class="lv">分级</em>聚类的过程包括将样本分组到更大的聚类中的方法。在此过程中，需要计算两个子集群之间的距离，不同类型的链接描述了集群之间的连接方式(图 4)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/2e6191f3cefe5b85ab68575857ca18c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*av2rbVLXncBdjz3sszhxmQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 4:链接类型。图片由作者提供。</p></figure><p id="8c13" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简单来说，两个聚类之间的<strong class="lb iu"> <em class="lv">单连锁</em> </strong>就是它们最接近的两个样本之间的接近程度。它产生一个长链，因此非常适合聚类球形数据，也适合异常值检测。<strong class="lb iu"> <em class="lv">完全连锁</em> </strong>两个星团之间的距离就是它们两个最远样本之间的接近度。直观上，两个相距最远的样本不可能比其他完全不同的样本对更不相似。它迫使星系团呈球形，其边界通常具有“紧凑的”轮廓，但内部不一定是紧凑的。<strong class="lb iu"> <em class="lv">两个集群之间的平均链接</em> </strong>是一侧的一个对象与另一侧的另一个对象之间的所有邻近度的算术平均值。<strong class="lb iu"> <em class="lv">形心</em>连锁</strong>是簇的几何形心之间的接近度。谨慎选择<em class="lv">度量</em>和<em class="lv">链接类型</em>，因为它直接影响最终的聚类结果。考虑到这一点，我们可以开始预处理图像。</p><h1 id="7fe5" class="md me it bd mf mg og mi mj mk oh mm mn jz oi ka mp kc oj kd mr kf ok kg mt mu bi translated">图像预处理。</h1><p id="ca94" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">在我们从图像中提取特征之前，我们需要执行一些预处理步骤，以确保图像在<strong class="lb iu"><em class="lv"/></strong><strong class="lb iu"><em class="lv"/></strong><strong class="lb iu"><em class="lv">图像大小</em> </strong>中与 相当。预处理步骤利用了<a class="ae ky" href="https://github.com/opencv/opencv-python" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="lv">open-cv</em></strong></a>和<strong class="lb iu"> <em class="lv"> </em> </strong>流水线中的<a class="ae ky" href="https://erdogant.github.io/clustimage" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="lv">clustimage</em></strong></a><strong class="lb iu"><em class="lv">。</em>T57】</strong></p><ol class=""><li id="a052" class="ol om it lb b lc ld lf lg li on lm oo lq op lu oq or os ot bi translated"><strong class="lb iu"> <em class="lv">色阶:</em> </strong>将图像转换成例如灰度(二维)或彩色(三维)。</li><li id="307d" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated"><strong class="lb iu"> <em class="lv"> scale: </em> </strong>归一化最小和最大范围[0，255]之间的所有像素值。</li><li id="9797" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated"><strong class="lb iu"> <em class="lv"> dim: </em> </strong>调整每个图像的大小，确保特征的数量相同。</li></ol><pre class="kj kk kl km gt oz pa pb pc aw pd bi"><span id="eb24" class="ns me it pa b gy pe pf l pg ph">pip install clustimage</span></pre><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pi pj l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图像预处理示例，包括颜色缩放、数值缩放、大小调整和矢量化。</p></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="c085" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">图像特征提取。</h1><p id="13f5" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">在对图像进行预处理之后，我们可以开始使用像素值信息从图像中提取特征。有许多方法来提取特征，但我将集中于 PCA 和 HOG 特征，因为这些是公认的技术，可以很好地概括不同类型的对象。我将简要回顾 PCA 和 HOG，但更多细节我建议阅读其他文章和博客。</p><h2 id="0f50" class="ns me it bd mf nt nu dn mj nv nw dp mn li nx ny mp lm nz oa mr lq ob oc mt od bi translated">主成分分析</h2><p id="35da" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">使用主成分分析，我们可以降低维数，并提取主要成分(PC ),其中大部分方差可见。非常重要的是，所有图像必须具有相同的宽度和高度，并且进行类似的预处理，因为像素值将形成特征空间。假设我们有 100 张 128×128 像素的灰度 2D 图像。每个图像将被展平并形成大小为 16384 的向量。现在可以将向量堆叠起来，形成一个新的 NxM 阵列，其中 N 是 100 个样本，M 是 16384 个特征。特征提取将在 NxM 阵列上进行。在<a class="ae ky" href="https://erdogant.github.io/clustimage" rel="noopener ugc nofollow" target="_blank">在后一种情况下，将自动确定电脑的数量。</a></p><h2 id="3f2b" class="ns me it bd mf nt nu dn mj nv nw dp mn li nx ny mp lm nz oa mr lq ob oc mt od bi translated">方向梯度直方图(HOG)</h2><p id="3998" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">HOG 是一个特征<em class="lv">描述符</em>，用于从图像数据中提取与边缘的方向和方位相关的特征。一般来说，它是图像的简化表示，仅包含最重要的信息，例如图像的局部部分中梯度方向的出现次数。总结如下:</p><ol class=""><li id="d57b" class="ol om it lb b lc ld lf lg li on lm oo lq op lu oq or os ot bi translated">HOG 描述符侧重于对象的结构或形状。HOG 特征包含边缘和方向信息。</li><li id="47f6" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated">完整的图像被分解成更小的区域(局部部分),并且对于每个区域，计算梯度方向。</li><li id="868c" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated">最后，HOG 会为这些区域分别生成一个直方图。直方图是使用像素值的梯度方向创建的，因此称为梯度方向直方图。</li></ol><p id="c8e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用 HOG 功能时，并非所有应用程序都有用，因为它“仅”提供图像的轮廓。例如，如果用例是对不同的通用对象进行分组，HOG 特征可以做得很好，但是对象内更深层次的相似性可能很困难，因为细节可能会丢失。然而，如果需要增加 HOG 特征，可以减少每个像元的像素(例如 4，4)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pi pj l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">从花中提取 HOG 特征的例子。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/131c2cddc0794bf2296cee2f77cb7fa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EkmVskwv5ljFWCOR7UmDOw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 5。HOG 特征描述符。左:输入图像。右图:猪的特征。图片由作者提供。</p></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="594a" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">集群评价。</h1><p id="3d54" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">在这一点上，我们<em class="lv">预处理</em>图像，<em class="lv">提取特征，</em>并且在我们心中有了目标，我们选择<em class="lv">链接类型</em>并且能够<em class="lv">开始聚类</em>图像以基于<em class="lv">距离度量</em>找到相似的组。然而，聚类方法不<strong class="lb iu"> <em class="lv">而不</em> </strong>提供关于聚类的可分性、良好性或最佳数量的信息。为了评估聚类，有各种方法，其中最著名的方法是<strong class="lb iu">Si<em class="lv">lhouette score</em></strong>和<strong class="lb iu"><em class="lv">Davies–Bouldin(DB)</em></strong>。每种都有其属性，其摘要如下:</p><ul class=""><li id="1ab7" class="ol om it lb b lc ld lf lg li on lm oo lq op lu pl or os ot bi translated"><strong class="lb iu"> <em class="lv">戴维斯–波尔丁指数(dbindex) </em> </strong>:直观上可以描述为<em class="lv">簇内</em>距离和<em class="lv">簇间</em>距离的度量。分数有界在[0，1]之间，<strong class="lb iu"> <em class="lv">越低越好</em> </strong>。请注意，由于它测量聚类质心之间的距离，因此仅限于使用欧几里德距离。</li><li id="2bbd" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu pl or os ot bi translated"><strong class="lb iu"> <em class="lv">剪影得分</em> </strong>:剪影值是一个样本与其聚类(内聚)相比与其他聚类(分离)相似程度的度量。分数限制在[-1，1]之间，其中高值指示对象与其聚类匹配良好，而与相邻聚类匹配较差。因而<strong class="lb iu"> <em class="lv">分数越高越好</em> </strong>。与<em class="lv"> DBindex </em>相反，<em class="lv">剪影得分</em>是一种样本方式的测量，即测量一个聚类内的样本的平均相似性以及它们与其他聚类中的其他对象的距离。轮廓分数可以与任何距离度量结合使用。</li></ul><p id="c89d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于聚类的评价，<a class="ae ky" href="https://erdogant.github.io/classeval" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="lv">clusteval</em></strong></a><strong class="lb iu"><em class="lv"/></strong>库在<a class="ae ky" href="https://erdogant.github.io/clustimage" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="lv">clustimage</em></strong></a>中使用，包含三种评价方法:<strong class="lb iu"> <em class="lv">剪影</em> </strong>、<strong class="lb iu"> <em class="lv"> DBindex </em> </strong>，以及<strong class="lb iu"> <em class="lv">衍生</em> </strong>方法。评估方法应与聚类方法结合使用，如<em class="lv">agglomerate、k-means 或 dbscan </em>，这些方法也包含在<em class="lv"> clustimage 中。</em>同样，理解这些方法的数学属性很重要，这样它才能与(预期的)聚类的统计属性相匹配。例如，<em class="lv"> DBscan </em>结合<em class="lv">剪影</em>评估可以检测具有不同密度和形状的聚类，而 k-means 假设聚类是凸形的。</p><blockquote class="na"><p id="5bc8" class="nb nc it bd nd ne nf ng nh ni nj lu dk translated"><em class="nk">请注意，聚类评估方法很容易被欺骗，因为分数会随着聚类数量的增加而逐渐提高。</em></p></blockquote><p id="bff6" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">明智的做法是设置聚类数量的搜索范围，以找到局部最小值/最大值。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="79cc" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">MNIST 数据集。</h1><p id="15ea" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">MNIST 是一个著名的手写数字数据集，它非常适合于检查和展示方法的性能。让我们加载数据集并运行<a class="ae ky" href="https://erdogant.github.io/clustimage" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="lv">clustimage</em></strong></a>来检测集群。在这种情况下，我将使用 PCA 提取特征，并将所有其他参数保留为默认值。默认设置如下:对于<strong class="lb iu"> <em class="lv">预处理</em> </strong>，将<em class="lv">灰度</em>设置为<em class="lv">假</em>(将其设置为真不会改变结果，因为图像很容易被灰度化)，如果需要，图像<em class="lv">尺寸</em>减少到<em class="lv"> 128，128 </em>。PCA 用于<strong class="lb iu"> <em class="lv">特征提取</em> </strong>，其中选择覆盖 95%方差的主成分数。使用具有欧几里德距离度量和沃德链接的凝聚方法来检测聚类。使用<em class="lv">剪影得分评估聚类和最佳聚类数。</em>聚类数的搜索范围在[3，25]之间。为了可视化的目的，执行 tSNE 以减少高维空间并分散相对于彼此的样本。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pi pj l"/></div></figure><p id="6068" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如您可能注意到的，在<a class="ae ky" href="https://erdogant.github.io/clustimage" rel="noopener ugc nofollow" target="_blank"><em class="lv">clustimage</em></a><em class="lv"/>中，有许多参数的所有功能都很容易流水线化，以对图像进行聚类并确定最佳聚类数。输出存储在<strong class="lb iu"> <em class="lv">结果</em> </strong>和对象本身中。让我们看看结果。维数减少到 29 个特征(图 6)并存储在<strong class="lb iu"> <em class="lv"> feat </em> </strong>键中。可用<code class="fe pm pn po pa b">cl.pca.plot()</code>绘制解释的差异。嵌入的坐标存储在<strong class="lb iu"> <em class="lv"> xycoord、</em> </strong>中，聚类标签可以在<strong class="lb iu"> <em class="lv">标签</em> </strong>中找到。为了更直观地了解性能，我们可以绘制各种图表，例如聚类的良好程度、每个聚类中相似检测样本的一致性，以及散点图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/2fddb7c7f058f1c26a6c1bc31ed111e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*tCcPh1KSKkTE8Tym69qc3Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 6。解释差异。图片作者。</p></figure><h2 id="5771" class="ns me it bd mf nt nu dn mj nv nw dp mn li nx ny mp lm nz oa mr lq ob oc mt od bi translated">集群评价。</h2><p id="f352" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">我们使用检测到 10 个最佳聚类的轮廓分数(图 7A 中的最高相对分数)来评估分级聚类。数据集也包含 10 个数字[0 到 9]，但我们需要检查聚类是否也表示这些数字。在图 7B 中，我们可以看到每个样本的系数值。许多样本具有较高的值，这意味着聚类配置是适当的。如果有许多点具有低值或负值，则聚类配置可能具有太多或太少的聚类。因此，总的来说，两个图都表明样本的良好聚类。</p><p id="097e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe pm pn po pa b">cl.clusteval.plot()</code> <code class="fe pm pn po pa b">cl.clusteval.scatter()</code></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pq"><img src="../Images/c886a2b8ff0ca22ac6baf5087ac2034b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AjQqbW98W_VxaEtrRXXl7w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 7。基于轮廓得分的聚类评价结果。a .聚类数与轮廓分数的关系。b .每个样本的轮廓系数值。图片由作者提供。</p></figure><p id="b9f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了研究样本在聚类中的分布，我们可以用<code class="fe pm pn po pa b">cl.plot_dendrogram()</code>绘制树状图。树状图提供了样本在 10 个聚类中的分布情况，聚类之间的距离似乎或多或少是均匀分布的，没有强烈的异常值或其他可能干扰聚类结果的影响。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pr"><img src="../Images/f4d2b884e03894a6e2b4dce7cd493a00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I6M2Hoceb8Uc1GfH42iLmw.png"/></div></div></figure><p id="2015" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用功能<code class="fe pm pn po pa b">cl.plot_unique()</code>,我们可以绘制每个聚类的质心图像。此外，还可以通过设置以下参数对每个聚类的所有图像进行平均:<code class="fe pm pn po pa b">cl.plot_unique(img_mean=True)</code>。后一个选项有助于更直观地了解每个聚类的图像是否相似。例如，如果我们看图 9 中的聚类 7，聚类的质心似乎是数字 3，而平均图像似乎更像 9？这表明群集可能看到不完全相同的图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ps"><img src="../Images/1eb5fd7d0d0b552333875c46f9f24b72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DTgpRuRBMSuEfsDCcPL1zA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 9。绘制每个集群的独特图像。a .每个聚类的最质心图像。b .每个聚类的平均图像。图片由作者提供。</p></figure><h2 id="96af" class="ns me it bd mf nt nu dn mj nv nw dp mn li nx ny mp lm nz oa mr lq ob oc mt od bi translated">基于 t 分布随机邻居嵌入的散点图</h2><p id="15c6" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">使用散点图功能<code class="fe pm pn po pa b">cl.scatter(zoom=5)</code>,我们可以将样本分散在嵌入的 2D tSNE 空间中，并直观了解样本相对于彼此的分布情况。注意，样本(数字图像)在高维空间中确定的聚类标签上是有颜色的。在这种情况下，2D tSNE 嵌入仅用于可视化目的。对于每个聚类，在 2D 空间中确定质心，并绘制最接近质心的图像。总的来说，我们看到一些数字可能需要进一步检查的聚类的清晰分离，例如聚类 4 和 5。为了查看集群标签，我们可以将<code class="fe pm pn po pa b">zoom</code>参数设置为 None，<code class="fe pm pn po pa b">cl.scatter(zoom=None)</code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pt"><img src="../Images/b235b5203f1d4bd517ade2fa899ffc03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xRRURTBEzCt2kzQC4e50Kg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 10。tSNE 嵌入的散点图。图片作者。</p></figure><p id="e5df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了更深入地检查集群中的图像，我们可以使用绘图功能<code class="fe pm pn po pa b">cl.plot(cmap=’binary’, labels=[4,5])</code>。这里我们只画出感兴趣的聚类，比如聚类 4 和 5。簇 4 似乎包含数字 1 和 9，簇 5 包含数字 1、4 和 9。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pu"><img src="../Images/b7864d8315b8b7e726af02313755e1f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7iUx77KLN05ppw5FpnEHKg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 11。为指定的集群绘制图像。a .群组 4 中的图像。b .第 5 组中的图像。图片作者。</p></figure><h2 id="929f" class="ns me it bd mf nt nu dn mj nv nw dp mn li nx ny mp lm nz oa mr lq ob oc mt od bi translated">猪的特征。</h2><p id="7bb4" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">使用<a class="ae ky" href="https://erdogant.github.io/clustimage" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="lv">clustimage</em></strong></a>，也可以通过将方法设置为<strong class="lb iu"> <em class="lv"> hog，使用<strong class="lb iu">方向梯度直方图</strong>提取特征。</em> </strong>因为 MNIST 的图像尺寸很小，所以也需要减少每个像元的像素数来计算 hog 特征。让我们再次聚类 MNIST 数据集，但现在使用 HOG 特征。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pi pj l"/></div></figure><p id="49f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用<code class="fe pm pn po pa b">pixels_per_cell:(2,2)</code>可以获得以下结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pv"><img src="../Images/cd504ed377026a37e0e93fe421c06aa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zfMjZOjjUIChYqovE3BsAw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 12。使用 HOG 特征检测聚类。a .聚类数与轮廓分数的关系。使用 HOG 特征的 tSNE 嵌入的散点图。图片作者。</p></figure><p id="5e0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基于最大<em class="lv">剪影</em> <em class="lv">分数</em>检测十四个聚类。注意，第二个局部最优值是 10 个集群。当我们将聚类结果(图 12B)与使用 PCA 的聚类结果(图 10)进行比较时，基于视觉检查，使用 HOG 特征的聚类显得不太明显。当使用最接近质心的图像和每个聚类的平均图像绘制每个聚类的独特图像时，我们可以更深入地检查聚类。尽管如此，结果似乎是合理的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pw"><img src="../Images/57114dc0dd3a26e5095225598127a05d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UjxQ3B4Kn5DtnBzN5gtwyQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 13。绘制每个集群的独特图像。a .每个聚类的最质心图像。b .每个聚类的平均图像。图片由作者提供。</p></figure><h1 id="4079" class="md me it bd mf mg og mi mj mk oh mm mn jz oi ka mp kc oj kd mr kf ok kg mt mu bi translated">聚类 101 对象和花数据集的示例。</h1><p id="4ceb" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">对 MNIST 数据集进行聚类很有趣，但现在我们将对两个真实世界的数据集进行聚类。第一个数据集包含大量不同的对象，第二个数据集相对较小，但包含不同的花的子类型。</p><h2 id="d136" class="ns me it bd mf nt nu dn mj nv nw dp mn li nx ny mp lm nz oa mr lq ob oc mt od bi translated"><strong class="ak">加州理工</strong> 101 对象数据集。</h2><p id="b818" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">包含 101 个对象的大型数据集是<strong class="lb iu"> Caltech101 数据集。</strong>该数据集包含属于 101 个类别的 9144 幅真实世界图像。大约 40 至 800 每类图像。每张图片的大小大约为 300 x 200 像素，可以在加州理工学院的网站上下载。作为对<a class="ae ky" href="https://erdogant.github.io/clustimage" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="lv">clustimage</em></strong></a><strong class="lb iu"><em class="lv"/></strong>的输入，我们可以简单地提供存储所有图像的<em class="lv">路径位置</em>。子目录中的所有图像将被递归收集。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pi pj l"/></div></figure><p id="d50c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">检测到最佳的 63 个聚类(图 14A ),其中聚类的质心图像在图 14C 中示出，这少于 101 个已知输入对象。尽管如此，一些聚类还是很好地从整体中分离出来(图 14B)，并且包含具有高相似性的图像(图 14D)。由于 tSNE 算法的性质，在 2-D 空间中更居中的聚类可能不像图 14D 所示的那样纯。总的来说，一些对象倾向于很好地聚类，而其他对象可能需要进一步微调模型参数，或者甚至可能需要不同的特征提取方法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi px"><img src="../Images/e724c4b65702f6cf3d522baaef885bc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*exc-qkkwuxLvukat7E_Xvw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 14。Caltech101 数据集。a .轮廓分数在 63 个聚类处检测到最佳值。b .使用检测到的聚类标签对样本进行着色的 tSNE 嵌入。c .每个聚类的质心图像。d .在群集 13 中检测到的图像。图片由作者提供。</p></figure><h2 id="ea9f" class="ns me it bd mf nt nu dn mj nv nw dp mn li nx ny mp lm nz oa mr lq ob oc mt od bi translated">花卉数据集</h2><p id="6ae3" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">花卉数据集包含 210 幅图像，并使用 HOG 方法进行聚类。在花数据集的情况下，与使用基于视觉检查的 PCA 特征相比，HOG 特征似乎产生更好的结果(结果未示出),即使颜色在特征提取方法期间丢失。如果图像数量变大，也可以将方法设置为<code class="fe pm pn po pa b">pca-hog</code>，对 HOG 特征执行 PCA，从而显著减少特征数量，节省内存并保留结果。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pi pj l"/></div></figure><p id="0dcc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">检测到最佳的 6 个聚类(图 15A ),这些聚类的质心图像在图 15B 和 c 中示出。质心图像的 HOG 特征在图 15D 中示出。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi py"><img src="../Images/245e4a6efdf4a40e71f4961a0aff171b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HNUh5fiqlTEEWduYwfZQcg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 15。花卉数据集。a .轮廓分数在 6 个集群处检测到最佳值。b .使用检测到的聚类标签对样本进行着色的 tSNE 嵌入。c .每个聚类的质心图像。提取的猪特征。图片由作者提供。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pz"><img src="../Images/4a41b68eb41905073c285c8194ac140d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gETsTAzcfvPh-ThAE4vRAg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图。检测到的聚类 1 和聚类 4 中的样本。图片由作者提供。</p></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="429b" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">聚类人脸。</h1><p id="9ed5" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">使用<a class="ae ky" href="https://erdogant.github.io/clustimage" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="lv"> clustimage </em> </strong>库</a>也可以进行人脸聚类。然而，这可能需要额外的步骤，即从图像中提取脸部的<strong class="lb iu"><em class="lv"/></strong>。可以使用 cl.extract_faces()功能从图像中提取人脸，该功能反过来使用 openCV 的 haar 级联，更具体地说，是 Haar cascade _ frontal face _ default . XML。在本例中，我们将加载具有 400 张人脸图像的著名的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html" rel="noopener ugc nofollow" target="_blank"> Olivetti faces </a>数据集。对于这个数据集，不需要提取人脸，因为人脸很容易被裁剪。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pi pj l"/></div></figure><p id="9b1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们运行<em class="lv"> clustimage </em>时，检测到 18 个簇的最优值(图 16A)，嵌入了簇标签的 tSNE 如图 16B 所示。我们确实看到了一些集群的分离，现在可以使用<code class="fe pm pn po pa b">cl.plot()</code>功能检查每个集群。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/3713a3e7aca8d532c9d100e6255ad671.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4zDMY-jmW_wRzyW7pS3SAw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 16。人脸数据集。a .轮廓分数在 18 个聚类处检测到最佳值。b .使用检测到的聚类标签对样本进行着色的 tSNE 嵌入。c .每个聚类的质心图像。d .聚类 15 中的图像示例。图片由作者提供。</p></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="ce59" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">找到相似的图像。</h1><p id="4e31" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">除了<em class="lv">聚类</em>功能外，<a class="ae ky" href="https://erdogant.github.io/clustimage" rel="noopener ugc nofollow" target="_blank"><em class="lv">clustimage</em><strong class="lb iu"><em class="lv"/></strong>库</a>也包含了搜索图片的功能。使用<code class="fe pm pn po pa b">find</code>功能，可以提供输入图像，并将返回类似的图像。实现了两种方法:</p><ul class=""><li id="4cec" class="ol om it lb b lc ld lf lg li on lm oo lq op lu pl or os ot bi translated">基于 k 近邻。</li><li id="b7a8" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu pl or os ot bi translated">基于概率密度拟合后的显著性。</li></ul><p id="cc8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于这两种方法，使用指定的距离度量(<em class="lv">默认欧几里德</em>)跨所有图像计算邻接矩阵。在 k-最近邻方法的情况下，选择 k-最近邻，并且逻辑上它将总是导致命中。在<em class="lv">密度拟合</em>的情况下，邻接矩阵用于估计测试分布<em class="lv"> ['norm '，' expon '，' uniform '，' gamma '，' t'] </em>中 loc/scale/arg 参数的最佳拟合。拟合的分布形成样本的<em class="lv">相似性分布</em>。对于每个新的看不见的输入图像，跨所有图像计算相似性的概率，并且返回在分布的下限中为<em class="lv">P&lt;α</em>的图像。这种方法只会返回重要的命中结果。在指定了<em class="lv"> k </em>和<em class="lv">α</em>两个参数的情况下，取检测样本的并集。让我们使用 flower-dataset，使用来自路径位置的输入图像来查找相似的图像。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pi pj l"/></div></figure><p id="798f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的例子中，我们的目标是检测两幅输入图像的相似图像。出于演示目的，这些图像也在<em class="lv"> fit_transform </em>功能本身中。或者换句话说，我们至少应该能够检测到相同的图像。图 17 展示了相似性显著且<em class="lv"> P &lt; 0.05 </em>的图像。请注意，由于拟合分布中的随机成分，结果可能会略有变化。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qa"><img src="../Images/c9e536ae85014c0fadb439904a9ca5d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GwvJcnShQKfeIu9g-WdufQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 17。输入图像用红色矩形表示。a .检测到一幅输入图像。b .检测到 34 个相似性显著的图像。图片由作者提供。</p></figure></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="216e" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">最后的话。</h1><p id="e13a" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">我提到了无监督聚类的概念，以及如何从原始输入图像到高度相似图像的聚类。图像的聚类需要多个步骤和各种方法。采取不同的步骤和/或方法将产生不同的分组，因为它隐含地对数据施加了结构，从而对样本进行了划分。<a class="ae ky" href="https://erdogant.github.io/clustimage" rel="noopener ugc nofollow" target="_blank"> clustimage <strong class="lb iu"> <em class="lv"> </em> </strong>包</a>可以帮助使用众所周知的特征提取、评估和聚类方法。通过各种绘图功能可以很容易地研究结果。此外，它还可以用于检测新的看不见的图像的非常相似的图像。如果你的目标是找到(几乎)相同的图像(照片)，我推荐阅读这个<a class="ae ky" rel="noopener" target="_blank" href="/detection-of-duplicate-images-using-image-hash-functions-4d9c53f04a75">博客</a>，它是关于使用 <a class="ae ky" href="https://erdogant.github.io/undouble" rel="noopener ugc nofollow" target="_blank"> <em class="lv">可撤销库</em> </a> <em class="lv">使用图像哈希函数检测重复图像的<em class="lv">。</em>这已经成为一篇冗长的文章，但是底线是<em class="lv"> </em>总是<em class="lv"> </em>确保方法的数学属性与数据的统计属性相匹配。</em></p><p id="b022" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意安全。保持冷静。</p><p id="73ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">干杯 E. </em> </strong></p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="91f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">如果你觉得这篇文章很有帮助，可以使用我的</em> <a class="ae ky" href="https://medium.com/@erdogant/membership" rel="noopener"> <em class="lv">推荐链接</em> </a> <em class="lv">继续无限制学习，并注册成为中级会员。另外，</em> <a class="ae ky" href="http://erdogant.medium.com" rel="noopener"> <em class="lv">关注我</em> </a> <em class="lv">保持我的最新内容！</em></p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h2 id="6980" class="ns me it bd mf nt nu dn mj nv nw dp mn li nx ny mp lm nz oa mr lq ob oc mt od bi translated">软件</h2><ul class=""><li id="941c" class="ol om it lb b lc mv lf mw li qb lm qc lq qd lu pl or os ot bi translated"><a class="ae ky" href="https://erdogant.github.io/clustimage/pages/html/Documentation.html#colab-notebook" rel="noopener ugc nofollow" target="_blank"> clustimage Colab 笔记本</a></li><li id="c1c3" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu pl or os ot bi translated"><a class="ae ky" href="https://erdogant.github.io/clustimage" rel="noopener ugc nofollow" target="_blank">clustimage Github/文档</a></li><li id="7b7a" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu pl or os ot bi translated"><a class="ae ky" href="https://erdogant.github.io/clusteval" rel="noopener ugc nofollow" target="_blank">clusteval Github/文档</a></li><li id="1bae" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu pl or os ot bi translated"><a class="ae ky" href="https://erdogant.github.io/undouble" rel="noopener ugc nofollow" target="_blank">无疑问 Github/文档</a></li></ul><h2 id="62e8" class="ns me it bd mf nt nu dn mj nv nw dp mn li nx ny mp lm nz oa mr lq ob oc mt od bi translated">我们连线吧！</h2><ul class=""><li id="ff1c" class="ol om it lb b lc mv lf mw li qb lm qc lq qd lu pl or os ot bi translated"><a class="ae ky" href="https://www.linkedin.com/in/erdogant/" rel="noopener ugc nofollow" target="_blank">我们在 LinkedIn 上连线</a></li><li id="73b8" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu pl or os ot bi translated"><a class="ae ky" href="https://github.com/erdogant" rel="noopener ugc nofollow" target="_blank">在 Github 上关注我</a></li><li id="22f4" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu pl or os ot bi translated"><a class="ae ky" href="https://erdogant.medium.com/" rel="noopener">在媒体上跟随我</a></li></ul></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="77fb" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">参考</h1><ol class=""><li id="fd25" class="ol om it lb b lc mv lf mw li qb lm qc lq qd lu oq or os ot bi translated"><em class="lv"> Maarten Grootendorst </em>、<a class="ae ky" rel="noopener" target="_blank" href="/9-distance-measures-in-data-science-918109d069fa">、<strong class="lb iu">数据科学中的 9 个距离测度</strong>、<em class="lv">走向数据科学，2021 年 2 月</em>。</a></li><li id="be86" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated"><em class="lv"> Kimberly L. Elmore 等人</em>、<a class="ae ky" href="https://journals.ametsoc.org/view/journals/mwre/129/3/1520-0493_2001_129_0540_edaasm_2.0.co_2.xml?tab_body=fulltext-display" rel="noopener ugc nofollow" target="_blank">、<strong class="lb iu">欧氏距离作为主成分分析的相似性度量</strong>、</a>、<em class="lv"> AMS，2001 年 3 月 1 日</em></li><li id="aeaa" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated">Sergei Evgenievich Ivanov <em class="lv">等</em>，<strong class="lb iu">基于修正距离度量的物体识别与分类</strong>，<em class="lv">Procedia Computer Science 136(2018)</em></li></ol></div></div>    
</body>
</html>