<html>
<head>
<title>Batch sampler for sequential data using PyTorch deep learning framework</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用PyTorch深度学习框架的序列数据批量采样器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/batch-sampler-for-sequential-data-using-pytorch-deep-learning-framework-part-3-df19f449f24e?source=collection_archive---------13-----------------------#2021-05-09">https://towardsdatascience.com/batch-sampler-for-sequential-data-using-pytorch-deep-learning-framework-part-3-df19f449f24e?source=collection_archive---------13-----------------------#2021-05-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e2e3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在PyTorch框架的dataloader中使用零填充顺序数据集时，优化GPU利用率</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0bd9d1fe33971fe712355367760fdcdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oYsq0-LKJ8rASDTb"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">杰西卡·约翰斯顿在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="34a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意——要了解如何为自定义数据集编写数据加载器，无论是顺序的还是图像的，<a class="ae ky" href="https://medium.com/@AnveeNaik/dataloader-for-sequential-data-using-pytorch-deep-learning-framework-part-2-ed3ad5f6ad82" rel="noopener">请参考这里的</a>。</p><p id="a3ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于数据点大小可能不同的顺序数据集，我们使用零填充使所有数据点大小相同。因此，批处理可以转换为张量，并传递到图形卡(GPU)进行并行处理。</p><p id="14e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是这种方法不是最佳的。考虑两批8个数据点，每个数据点的大小如下:</p><ul class=""><li id="6d13" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">批次1— [2，5，5，4，6，7，8，2]，批次的最终大小= 8*8</li><li id="78a9" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">批次2— [2，32，5，36，6，34，8，2]，批次的最终大小= 36*8</li></ul><p id="7d2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在批次1中，所有数据点需要使用零填充转换为大小8，而在批次2中，所有数据点需要转换为大小36。在这两种情况下，最小大小都是2，但是在批次1中，我们只给大小为2的元素添加了6个零，而在批次2中，我们需要添加34个零。因此，我们可以看到，批处理2在处理无用的零时浪费了大量GPU内存，而批处理1是一种高效的打包方式，浪费的GPU很少。这个例子显示了问题所在，也给出了我们的解决方案。如果我们能以某种方式手工制作批次，那么我们就能确保每个包装都是有效的。</p><p id="86d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是我们怎么做呢？？</p><p id="c85d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还记得内部提供的<em class="mj"> __getitem__ </em>函数中的<em class="mj"> index </em>变量吗，如果我们可以手动为每个批次提供索引，那么我们的工作就完成了。为此，我们可以使用数据加载器中的<em class="mj"> batch_sampler </em>参数，如下所示。</p><pre class="kj kk kl km gt mk ml mm mn aw mo bi"><span id="b4cb" class="mp mq it ml b gy mr ms l mt mu">train_dataset = Dataset_seq(word2id, train_path)<br/>sampler = Sampler(tokens, data, bin_size) #data is list of sentences<br/>                                           present in whole corpus<br/>train_batch_sampler_loader = DataLoader(<br/>        train_dataset, <br/>        batch_sampler = sampler,<br/>        collate_fn = collate_fn)</span></pre><p id="47c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，将使用我们将在下面定义的sampler函数来提供一个批次的索引。</p><p id="95ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意——对于不同的时期，最好在一批中有不同的数据点集，即如果在第一个时期一批通过(<em class="mj">数据1、数据2、数据3、数据4 </em>)，在其他时期，我们应确保不一起提供相同的数据集(<em class="mj">数据1、数据2、数据3、数据4 </em>)。这是为了确保我们的模型不会学习提供数据点的模式/顺序。</p><p id="edd6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们来理解如何为我们的采样器函数编写算法:</p><ul class=""><li id="5caa" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">我们将创建一个包含每个数据点长度的列表<em class="mj"> text_len </em>。</li><li id="7e06" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">然后，我们将创建箱(或桶数据),使得每个箱存储大小小于或等于对应于该箱的大小的数据点的索引。这里，对应于每个库的大小取决于<em class="mj"> bin_size。例如，如果<em class="mj"> bin_size </em> = 2，那么bin的大小将是3，5，7…直到最大尺寸出现在<em class="mj"> text_len </em>中。</em></li><li id="99e5" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如果说<em class="mj"> text_len = </em> [2，3，4，5，6，7，8]，那么我们将得到{3: [0，1]，5: [2，3]，7: [4，5]，8: [6]}即索引0，1处的值大小≤ 3，索引2，3处的值大小≤ 5，依此类推。最后一个bin的大小为8，因为这是<em class="mj"> text_len中的最大大小。</em></li><li id="da4d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">现在，我们已经根据大小分离了所有数据，我们将创建我们的批次。为此，我们将使用一个参数<em class="mj"> n_tokens </em>，该参数指示GPU中可以加载的最大总大小(包括零填充)。因此，如果<em class="mj"> n_tokens=500 </em>，那么我们可以使每一批在补零之后，一批中每个数据点的大小之和小于或等于500。</li><li id="99fc" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">现在，为了形成批，我们从最大的桶开始，继续按顺序挑选索引，直到该批的总大小刚好小于或等于<em class="mj"> n_tokens。</em>一旦形成一个批次，我们将其附加到<em class="mj"> final_indicies </em>中，这是一个列表列表。这个过程一直持续到所有的数据点(存在于所有的箱中)被拾取并被分配给一批。</li><li id="9c08" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">为了确保不在不同时期发送相同的一组批，在每个时期之后，我们随机打乱为每个箱存储的列表。因此，当我们按顺序开始从箱子中挑选时，我们每次都会得到不同的数据。</li></ul><p id="a54b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请参考下面的算法代码</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="de15" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望这个博客能帮助你理解和探索新的应用。请分享你的反馈和其他方法，让这个博客变得更好。</p><p id="5d67" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mj">成为</em> <a class="ae ky" href="https://medium.com/@AnveeNaik/membership" rel="noopener"> <em class="mj">介质会员</em> </a> <em class="mj">解锁并阅读介质上的许多其他故事。关注我们的</em> <a class="ae ky" href="https://medium.com/@AnveeNaik" rel="noopener"> <em class="mj">中的</em> </a> <em class="mj">，阅读更多此类博文</em>。</p></div></div>    
</body>
</html>