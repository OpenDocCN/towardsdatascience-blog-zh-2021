<html>
<head>
<title>TensorFlow on Arduino</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Arduino上的张量流</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tensorflow-on-arduino-b336f08fa0e9?source=collection_archive---------20-----------------------#2021-04-09">https://towardsdatascience.com/tensorflow-on-arduino-b336f08fa0e9?source=collection_archive---------20-----------------------#2021-04-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="fa91" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">训练TensorFlow模型并将其部署到Arduino</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f686c2d8006a83dd8d4e2653262f4bee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dINpSbLq7F85Z_eVL9QDUg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">(图片由作者提供)</p></figure><p id="e891" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我将训练一个玩具算法，并将其部署在一台<a class="ae lr" href="https://store.arduino.cc/usa/nano-33-ble-sense" rel="noopener ugc nofollow" target="_blank"> Arduino Nano 33 BLE Sense </a>上进行推理。我正在寻求使用最少的组件构建和测试一个shell，并在以后进行增强。</p><p id="57fb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我将使用<a class="ae lr" href="http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/" rel="noopener ugc nofollow" target="_blank">auto pgg数据集</a>，训练一个模型，该模型将使用一个特征，马力，来预测车辆的每加仑英里数。我们将使用Arduino串行监视器与模型进行交互。</p><h1 id="595e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">训练模型</h1><p id="437b" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated"><a class="ae lr" href="https://github.com/paulbruffett/ArduinoMPGModel/blob/master/train_mpg_quant.ipynb" rel="noopener ugc nofollow" target="_blank">训练笔记本</a>跟着一起走。</p><p id="981e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我不会在数据准备上花太多时间，这是一个相当简单的数据集，需要注意的是，因为我想调用它并从串行监视器获得预测，我们将只使用一个特性，马力。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="08b4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，我们在这里丢弃了空值，分割了数据，得到了我们的标签(MPG)和我们的一个特征(马力)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="80ab" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，我建立我的模型。我只需要一个输入(马力)，我正在建立一个非常简单的模型，只有一个隐藏层。我也只有一个输出神经元来预测MPG。</p><p id="f845" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，我将保存模型，以便以后进行转换。</p><h1 id="8fe9" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">模型转换</h1><p id="963c" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">现在我们将转换模型。在我们的GPU上，该模型使用float32数字来捕获重量和偏差，在我们的微控制器上运行非常慢，如果有的话。我们将在训练后量化模型，在训练时可以使用较小的权重和激活，这是一个单独的主题。</p><p id="4f83" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了在有限的微控制器硬件上运行，我们需要转换成整数。这通常对准确性影响很小。有几个转换模型的选项；</p><ul class=""><li id="4c47" class="mr ms iq kx b ky kz lb lc le mt li mu lm mv lq mw mx my mz bi translated">float32到float16，这可以将模型的大小减少一半，并显著加快某些硬件上的推理速度，这意味着参数是float16，推理是在float32下执行的</li><li id="3079" class="mr ms iq kx b ky na lb nb le nc li nd lm ne lq mw mx my mz bi translated">int8参数，模型在可用时使用混合计算</li><li id="1ec9" class="mr ms iq kx b ky na lb nb le nc li nd lm ne lq mw mx my mz bi translated">int8参数和激活，仅执行整数运算</li></ul><p id="2af5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一个方便的决策树和更多细节<a class="ae lr" href="https://www.tensorflow.org/lite/performance/post_training_quantization" rel="noopener ugc nofollow" target="_blank">在这里</a>。</p><p id="7cf5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们想量化到后者，int8一切与强制整数只运算。为此，我们必须生成一个有代表性的数据集。这是必需的，因为为了有效地转换8位值，需要线性转换为实数。对于权重，这可以自动完成，因为TensorFlow可以根据训练值计算每层的范围。对于激活来说，这更加困难，因为从参数来看，每一层的输出范围并不明显。如果任意选择的范围过小，值将被最小值或最大值截断，如果范围过大，精度将会损失。</p><p id="4d11" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TensorFlow使用代表性数据集来执行激活的计算并转换它们。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="eb52" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这里，我们将测试数据集转换成张量，并在我们的representative_dataset函数中使用它，调用时会产生一条记录。</p><p id="cf58" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们实际上在这里保存了两个模型，一个只是转换为TFLite格式，但保持权重和激活为float32，因此我们可以看到它如何影响准确性。然后，该模型与量化一起保存，只强制int(因为如果没有指定，它可以退回到float32进行不支持的操作)。提供代表性数据集，转换并保存模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/0b4506eb2ec2ee998761d18094cb329b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-jMGuTkm1vuNuoWI_0jVgQ.png"/></div></div></figure><p id="00e2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">加载并显示输入和输出细节显示量化标度和零点。当调用模型时，我们将使用这些来适当地准备输入和输出。这可以在我们评估量子化模型时看到。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="1e69" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这里，我们捕获上面显示的输入和输出细节，然后在将测试数据转换为整数之前，使用刻度和零点来调整测试数据。在执行推理之后，我们对模型的输出进行同样的操作。</p><h1 id="531f" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">尺寸和精度</h1><p id="f422" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">现在我们已经得到了模型的训练、转换和一些样本的精度，那么模型的大小和对精度的影响会有多大的不同呢？</p><p id="644e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">就精确度而言，我们可以看到它是最小的，TFLite和未转换的模型是相同的，这是我们所期望的，因为没有发生量子化。对于未量化的模型，量化的模型精度最低，MSE为23.871至24.809。因为这是一个非常小且不复杂的模型，量化也没有减少模型的大小，只节省了228字节。对于具有更多层和神经元的模型，将节省更多空间。</p><p id="7461" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在我将使用<a class="ae lr" href="https://ss64.com/osx/xxd.html" rel="noopener ugc nofollow" target="_blank"> xxd </a>将模型从TFLite转换为文件的十六进制转储，允许我们将模型直接复制并粘贴到Arduino程序中。</p><p id="35bf" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这个十六进制转储的输出可以直接复制到Arduino程序的model.ccp文件中。内容和g_model_len都必须相加匹配，如下图；</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng mq l"/></div></figure><h1 id="7af9" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">Arduino程序</h1><p id="ea67" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">包含<a class="ae lr" href="https://github.com/paulbruffett/ArduinoMPGModel/blob/master/mpgModel.ino" rel="noopener ugc nofollow" target="_blank"> mpgModel.ino </a>的<a class="ae lr" href="https://github.com/paulbruffett/ArduinoMPGModel" rel="noopener ugc nofollow" target="_blank">回购</a>。</p><p id="c7a5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在我们有了模型，让我们一步一步地在控制器上调用它。</p><p id="5e6a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">所有有趣的事情都发生在autoTest.ino中。这建立了我们的环境，并通过捕获输入和调用模型进行循环。首先，我们需要导入我们需要的操作。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="63ae" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这个模型不需要太多的操作，其他模型会有嵌套的名称空间，并调用特定的架构，如max pooling和conv层。kTensorArenaSize是分配给模型的内存量。到目前为止，除了试错法之外，还没有一种非常好的方法来估计这一点；减少数量，直到模型崩溃。</p><h2 id="beec" class="nh lt iq bd lu ni nj dn ly nk nl dp mc le nm nn me li no np mg lm nq nr mi ns bi translated">模型设置</h2><p id="0c0e" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">现在我们需要分配模型的内存，配置指针并检查模式版本。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="3b3c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TensorFlow lite提供了报告和日志挂钩，我们将设置它，在检查中使用它来确保模式版本与模型匹配。我们分配内存并获取指针。</p><h2 id="ca90" class="nh lt iq bd lu ni nj dn ly nk nl dp mc le nm nn me li no np mg lm nq nr mi ns bi translated">调用模型</h2><p id="64c3" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">更有趣的是在我们的循环中调用模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="d2c9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们获取输入，并将其解析为浮点数。就像我们评估模型时一样，我们必须缩放和更新零点，同时将浮点输入转换为整数。然后将此作为输入提供给模型。模型(解释器)在输入时被调用，我们确保一切正常。</p><p id="a802" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">输出从其输出张量中捕获并存储，但在转换回浮点数之前，必须用更新的零点进行缩放。</p><p id="d680" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然后，我们打印预测以及一系列可选信息，显示我们的输入是如何修改的，以及量化前后的输出是什么样子。</p></div></div>    
</body>
</html>