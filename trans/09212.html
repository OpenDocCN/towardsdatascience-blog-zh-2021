<html>
<head>
<title>How to Annotate and Improve Computer Vision Datasets with CVAT and FiftyOne</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用CVAT和五十一注释和改进计算机视觉数据集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tools-to-annotate-and-improve-computer-vision-datasets-f9b99cdb0e04?source=collection_archive---------7-----------------------#2021-08-26">https://towardsdatascience.com/tools-to-annotate-and-improve-computer-vision-datasets-f9b99cdb0e04?source=collection_archive---------7-----------------------#2021-08-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a6a7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用开源工具551和CVAT构建高效标注工作流和训练更好模型的技巧</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><a href="https://voxel51.com/docs/fiftyone/integrations/cvat.html"><div class="gh gi kf"><img src="../Images/bd3d48ff4d9881fa5cc7ac677a79c240.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GHxmgxJIbwSVX68N-RovFg.png"/></div></a><p class="kn ko gj gh gi kp kq bd b be z dk translated">图像505f00d8762c07fc来自在<a class="ae kr" href="https://fiftyone.ai" rel="noopener ugc nofollow" target="_blank">五十一</a>中可视化的开放图像数据集(图像由作者提供)</p></figure><p id="6544" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">每个人都想培养伟大的模特。机器学习社区已经有一段时间以模型为中心，每个人都试图创建下一个最好的模型。最近，通过像<a class="ae kr" href="https://karpathy.medium.com/software-2-0-a64152b37c35" rel="noopener">软件2.0 </a>这样的想法，向以数据为中心的工作流转变的重要性变得越来越突出。在为你的任务训练模型时，<a class="ae kr" href="http://googleresearch.blogspot.com/2009/03/unreasonable-effectiveness-of-data.html" rel="noopener ugc nofollow" target="_blank">你可能会发现，对你的模型最大的改进</a>将来自仔细管理和改进你用来训练模型的数据集，而不是担心你正在使用的特定模型架构。</p><p id="17d3" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir">在数据集监管和注释领域，</strong> <a class="ae kr" href="https://fiftyone.ai" rel="noopener ugc nofollow" target="_blank"> <strong class="ku ir">五十一</strong> </a> <strong class="ku ir">和</strong><a class="ae kr" href="https://github.com/openvinotoolkit/cvat" rel="noopener ugc nofollow" target="_blank"><strong class="ku ir">CVAT</strong></a><strong class="ku ir">是两种领先的开源工具，分别处理数据集监管和改进工作流的不同部分，每个部分都有数万名用户</strong>。此外，这些工具<a class="ae kr" href="https://voxel51.com/docs/fiftyone/integrations/cvat.html" rel="noopener ugc nofollow" target="_blank">现在与</a>紧密集成，允许更快、更高效的工作流程。<a class="ae kr" href="https://fiftyone.ai" rel="noopener ugc nofollow" target="_blank"> FiftyOne </a>是一个数据集管理和模型分析工具，提供灵活的API和直观的应用程序，作为开源的“数据集IDE”<a class="ae kr" href="https://github.com/openvinotoolkit/cvat" rel="noopener ugc nofollow" target="_blank"> CVAT </a>是领先的开源图像和视频注释工具之一，由于其广泛的功能集和易于使用的界面而被广泛采用。51和CVAT之间的集成允许您在51中管理和探索数据集，然后只需一行代码就可以将样本或现有标签发送到CVAT进行注释。</p><p id="6365" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这篇文章涵盖了两个工作流程的例子，展示了如何使用51和CVAT之间的集成。第一个工作流智能地选择未标记数据的子集，并将其发送到CVAT进行注释。第二个工作流评估现有数据集以查找注记错误，并使用CVAT来提高数据集的质量。这两个例子都显示了与551和CVAT合作进行注释工作流是多么容易，从而更快地开发更好的模型所需的微调的计算机视觉数据集。</p><p id="fa83" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir"> <em class="lo">免责声明</em> </strong> <em class="lo">:我是Voxel51的工程师，在做五十一！</em></p><h1 id="be0e" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">跟随在科拉布</h1><p id="cdfb" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated">文章中展示的例子可以通过Google Colab直接在你的浏览器中运行。<a class="ae kr" href="https://voxel51.com/docs/fiftyone/tutorials/cvat_annotation.html" rel="noopener ugc nofollow" target="_blank">点击此链接查看</a>！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mm"><img src="../Images/54e557fc153c0390bc85c549b96ac103.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iTi1Eos6gQi7u5uoVytY5A.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">Colab笔记本随这篇文章一起出现(图片由作者提供)</p></figure><h1 id="f647" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">设置</h1><p id="32e3" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated">为了跟随这篇文章中的例子，你需要设置51和CVAT。</p><p id="0d99" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">对于FiftyOne，你只需要<a class="ae kr" href="https://voxel51.com/docs/fiftyone/getting_started/install.html" rel="noopener ugc nofollow" target="_blank">安装开源Python包</a>:</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="649a" class="mw lq iq ms b gy mx my l mz na">pip install fiftyone</span></pre><p id="154b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">对于CVAT，您需要在<a class="ae kr" href="https://cvat.org/" rel="noopener ugc nofollow" target="_blank">cvat.org</a>(<a class="ae kr" href="https://openvinotoolkit.github.io/cvat/docs/administration/basics/installation/" rel="noopener ugc nofollow" target="_blank">或本地设置CVAT</a>)上进行记账。在本地设置CVAT的主要好处是避免cvat.org的10个任务和500 Mb限制。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/c5ae533d16be33c73bdbea23d6388ea3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*eIQ2CDhukgAufI8nqjQ-MA.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><a class="ae kr" href="https://cvat.org/auth/register" rel="noopener ugc nofollow" target="_blank"> CVAT登录界面</a>(图片由作者提供)</p></figure><p id="79ce" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">运行本文中的例子时，511需要连接到你的CVAT账户。将您的CVAT用户名和密码传递给FfityOne的最简单方法是将它们存储在环境变量中。</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="cbcf" class="mw lq iq ms b gy mx my l mz na">export FIFTYONE_CVAT_USERNAME=&lt;YOUR_USERNAME&gt;<br/>export FIFTYONE_CVAT_PASSWORD=&lt;YOUR_PASSWORD&gt;</span></pre><p id="416b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如果您不想使用这些环境变量，<a class="ae kr" href="https://voxel51.com/docs/fiftyone/integrations/cvat.html#setup" rel="noopener ugc nofollow" target="_blank">查看向fiftone</a>提供您的CVAT用户名和密码的替代方法。</p><p id="94c4" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">本帖还运行了一些需要TensorFlow的深度模型:</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="898e" class="mw lq iq ms b gy mx my l mz na">pip install tensorflow</span></pre><p id="2136" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如果你有一个GPU和/或想用Conda设置Tensorflow或PyTorch，请查看这篇文章。</p><h1 id="1ffc" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">概观</h1><p id="54e8" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated">在您自己的数据上使用51和CVAT之间的这种集成的基本工作流程包括:<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/index.html" rel="noopener ugc nofollow" target="_blank">将您的数据</a>(可能还有现有标签)加载到51中，<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/using_views.html" rel="noopener ugc nofollow" target="_blank">浏览您的数据集</a>以找到需要检查或注释的子集，<a class="ae kr" href="https://voxel51.com/docs/fiftyone/integrations/cvat.html" rel="noopener ugc nofollow" target="_blank">将这些子集上传到CVAT </a>，在CVAT对它们进行注释，以及<a class="ae kr" href="https://voxel51.com/docs/fiftyone/integrations/cvat.html" rel="noopener ugc nofollow" target="_blank">将更新后的标签</a>加载回51中。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><h1 id="2b08" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">未标记的数据集标注</h1><p id="2751" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated">对于大多数机器学习项目来说，第一步是收集特定任务所需的数据集。特别是对于计算机视觉项目来说，这通常会产生数以千计的图像或视频，这些图像或视频是从像<a class="ae kr" href="https://www.flickr.com/" rel="noopener ugc nofollow" target="_blank"> Flickr </a>这样的互联网来源收集的，或者是由数据采集团队的新镜头捕捉的。</p><p id="b735" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">对于包含数千或数百万样本的集合，注释每个样本的成本可能是天文数字。因此，确保只将最有用和最相关的数据发送给注释是有意义的。衡量数据在训练模型中有多“有用”的一个标准是该示例相对于数据集的其余部分有多独特。多个相似的例子不会像视觉上独特的例子那样给模型提供那么多新的信息来学习。</p><p id="4d74" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/brain.html" rel="noopener ugc nofollow" target="_blank"> FiftyOne提供了</a>一套方法来计算数据集属性，如样本硬度、标签错误率，以及对该工作流程最重要的<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/brain.html#visual-similarity" rel="noopener ugc nofollow" target="_blank">视觉相似性/唯一性</a>。</p><h2 id="eee4" class="mw lq iq bd lr ne nf dn lv ng nh dp lz lb ni nj mb lf nk nl md lj nm nn mf no bi translated">加载数据</h2><p id="5df2" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated">我们从<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/index.html" rel="noopener ugc nofollow" target="_blank">加载一组未标记的图像到51个</a>开始。这只用一行代码就可以完成。例如，如果您正在<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_creation/index.html" rel="noopener ugc nofollow" target="_blank">使用您自己的数据</a>，您可以运行以下内容:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="309a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">然而，在这篇博客中，我们将使用内置的<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_zoo/index.html" rel="noopener ugc nofollow" target="_blank">51数据集Zoo </a>从<a class="ae kr" href="https://voxel51.com/docs/fiftyone/integrations/open_images.html" rel="noopener ugc nofollow" target="_blank"> Open Images V6数据集</a>下载一些图像。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="913d" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">不管怎样，让我们创建数据集<code class="fe np nq nr ms b"><a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/using_datasets.html#dataset-persistence" rel="noopener ugc nofollow" target="_blank">persistent</a></code>,这样我们就可以关闭Python会话，并在需要时重新加载数据集。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="8ce9" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">既然数据已经加载，让我们在<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/app.html" rel="noopener ugc nofollow" target="_blank"> FiftyOne应用</a>中可视化它。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ns"><img src="../Images/aa71e9be4e8030de57a410df9911f171.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KmCRS6ikssy0yr81IjJ2VQ.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">打开在<a class="ae kr" href="https://fiftyone.ai" rel="noopener ugc nofollow" target="_blank">第五十一</a>中可视化的图像(图片由作者提供)</p></figure><h2 id="5b7d" class="mw lq iq bd lr ne nf dn lv ng nh dp lz lb ni nj mb lf nk nl md lj nm nn mf no bi translated">寻找独特的样本</h2><p id="6fab" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated">让我们对数据集运行<code class="fe np nq nr ms b"><a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/brain.html#visual-similarity" rel="noopener ugc nofollow" target="_blank">compute_similarity()</a></code>方法，以便根据数据集中所有其他样本的视觉相似性来索引数据集中的所有样本。一旦完成，我们就可以使用索引来根据视觉相似性找到最独特的样本。还有其他衡量独特性的方法，但在这篇博客中，我们主要关注这种基于相似性的方法。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="5a27" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们还可以<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/plots.html" rel="noopener ugc nofollow" target="_blank">可视化</a>选择的确切样本。默认情况下，这种可视化是用降维包<code class="fe np nq nr ms b">umap-learn</code>计算的:</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="d8e6" class="mw lq iq ms b gy mx my l mz na">pip install umap-learn</span></pre><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nt"><img src="../Images/9eb6ba1be57c899dedcfd3f1ee19d0d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_TuZpH2AjnNl2_XQ8PaGCg.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">由<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/brain.html" rel="noopener ugc nofollow" target="_blank">第51个大脑</a>选择的独特样本图(图片由作者提供)</p></figure><p id="7ad6" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">现在让我们在数据集内创建一个<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/using_views.html" rel="noopener ugc nofollow" target="_blank">视图</a>，该数据集只包含所选的独特样本，并对它们进行可视化。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="c3bc" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">减少了需要注释的样本数量后，注释该数据集的时间和成本也减少了。</p><h2 id="b4dd" class="mw lq iq bd lr ne nf dn lv ng nh dp lz lb ni nj mb lf nk nl md lj nm nn mf no bi translated">注释样本</h2><p id="7d32" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated">无论您是自己注释数据还是有一个注释团队，从FiftyOne向CVAT上传数据的工作流程几乎是相同的。样本集合上的<code class="fe np nq nr ms b"><a class="ae kr" href="https://voxel51.com/docs/fiftyone/api/fiftyone.core.collections.html#fiftyone.core.collections.SampleCollection.annotate" rel="noopener ugc nofollow" target="_blank">annotate()</a></code>方法允许您为正在注释的标签指定名称、类型和类别。</p><p id="c55f" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">例如，如果我们为类“person”、“vehicle”和“animal”注释分段掩码，我们可以运行下面的代码。假设您想自己注释这些样本，那么一旦加载了数据，您可以使用CVAT编辑器自动启动一个浏览器窗口。对于这个示例帖子，让我们只加载视图中的几个示例。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="b1f7" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><code class="fe np nq nr ms b">results</code>对象可用于获取已创建任务的当前状态。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="587a" class="mw lq iq ms b gy mx my l mz na">Status for label field 'segmentations':<br/><br/>	Task 386 (FiftyOne_example_dataset_segmentations):<br/>		Status: annotation<br/>		Assignee: None<br/>		Last updated: 2021-08-20T21:22:37.928988Z<br/>		URL: <a class="ae kr" href="http://localhost:8080/tasks/386" rel="noopener ugc nofollow" target="_blank">http://cvat.org/tasks/386</a><br/><br/>		Job 441:<br/>			Status: annotation<br/>			Assignee: None<br/>			Reviewer: None</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nu"><img src="../Images/09625d369761fd1689559771d7ee7de7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5YNVOh8oVJuDeUS_DPR99Q.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">在<a class="ae kr" href="https://github.com/openvinotoolkit/cvat" rel="noopener ugc nofollow" target="_blank"> CVAT </a>给一张图片做注解(图片由作者提供)</p></figure><p id="c87f" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">一旦注释完成并保存在CVAT，我们就可以下载注释并自动更新我们的数据集。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nv"><img src="../Images/fae0280455f1fd0218a177162f081fd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*arI6ZZcvAAqkswIrGDEqFQ.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">在<a class="ae kr" href="https://github.com/openvinotoolkit/cvat" rel="noopener ugc nofollow" target="_blank"> CVAT </a>标注的图片在<a class="ae kr" href="https://fiftyone.ai" rel="noopener ugc nofollow" target="_blank">第五十一</a>可视化(图片由作者提供)</p></figure><p id="a478" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如果您想要将数据集上传到一个注释者团队，那么您可以提供注释者和审阅者的CVAT用户名，这些用户名将被分配循环方式。<code class="fe np nq nr ms b">segment_size</code>参数用于定义CVAT任务中每个任务的最大图像数量。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nw"><img src="../Images/83b9868233861b3dece788744e994d89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*COqo5s1hg-jhM_Xl67f8Vw.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">在<a class="ae kr" href="https://github.com/openvinotoolkit/cvat" rel="noopener ugc nofollow" target="_blank"> CVAT </a>分配给用户的工作(图片由作者提供)</p></figure><p id="74e1" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">对于较大的数据集，注记过程可能需要一些时间。我们提供的<code class="fe np nq nr ms b">anno_key</code>存储了关于在数据集上运行的注释的相关信息。当注释准备好导入回FiftyOne时，我们可以很容易地这样做:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><h1 id="a4a3" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">数据集改进</h1><p id="6e7f" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated">在许多项目中，数据集已经存在，并用于训练模型。在这种情况下，时间的最佳利用可能会提高数据集的质量，这通常比优化模型体系结构的类似努力提供更大的性能增益。</p><p id="98c6" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">FiftyOne提供了强大的API和应用程序工作流来识别需要更新的样本/注释，并且与CVAT的紧密集成允许您采取必要的措施来提高数据集的质量。</p><p id="749f" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">对于这个示例工作流，让我们从<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/dataset_zoo/index.html" rel="noopener ugc nofollow" target="_blank">第五十一数据集Zoo </a>加载<a class="ae kr" href="https://voxel51.com/docs/fiftyone/integrations/coco.html" rel="noopener ugc nofollow" target="_blank"> COCO对象检测数据集</a>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="cb5c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在这种情况下，我们将使用来自<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/model_zoo/index.html" rel="noopener ugc nofollow" target="_blank"> FiftyOne Model Zoo </a>的模型，但是您也可以轻松地<a class="ae kr" href="https://voxel51.com/docs/fiftyone/tutorials/evaluate_detections.html" rel="noopener ugc nofollow" target="_blank">将您自己的模型预测</a>添加到您的数据集中。为了运行这个特定的模型，我们还需要安装<a class="ae kr" href="https://github.com/voxel51/models" rel="noopener ugc nofollow" target="_blank"> TensorFlow模型花园</a>,其中包含:</p><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="ddd5" class="mw lq iq ms b gy mx my l mz na">eta install models</span></pre><p id="a258" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir">注意</strong>:建议在有GPU的机器上运行！</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="b8b3" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">让我们想象一下这些模型预测。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nx"><img src="../Images/ee070c850f488b68e87ff21cf734a301.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*onVQjzKivsK1gbAky_cm0A.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">可可数据集在<a class="ae kr" href="https://fiftyone.ai" rel="noopener ugc nofollow" target="_blank">五十一</a>中可视化(图片由作者提供)</p></figure><p id="86f8" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">为了找到该模型表现如何的具体案例，<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/evaluation.html" rel="noopener ugc nofollow" target="_blank">让我们来评估该模型</a>:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="3d5c" class="mw lq iq ms b gy mx my l mz na">0.3957238101325776</span></pre><p id="7c04" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">使用FiftyOne复杂的查询语言，我们可以<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/using_views.html" rel="noopener ugc nofollow" target="_blank">在数据集</a>中构建不同的视图。具体来说，让我们找到模型对其预测有信心但预测被标记为不正确(假阳性)的样本。这表明模型可能是正确的，但是地面实况注释是不正确的。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="58d5" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">浏览这些结果，我们可以看到一个模式出现。COCO数据集在标签上包含一个<code class="fe np nq nr ms b">iscrowd</code>布尔属性，指示边界框是包含一群多个对象还是仅包含一个对象实例。在许多模型不正确的情况下，<code class="fe np nq nr ms b">iscrowd</code>属性被错误地注释或者完全丢失。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ny"><img src="../Images/2e509f4c1b93a14dd977dd060de20237.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fCNMTgEOk5qdxzrkRJPHjw.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">不正确的<code class="fe np nq nr ms b">iscrowd</code>标签出现在<a class="ae kr" href="https://fiftyone.ai" rel="noopener ugc nofollow" target="_blank">第五十一</a>(图片由作者提供)</p></figure><p id="07e7" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们可以通过点击选择相关样本并点击<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/app.html#tags-and-tagging" rel="noopener ugc nofollow" target="_blank">标签按钮</a>来标记这些样本中的一些样本。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nz"><img src="../Images/20500911aa513e5158f8554d7748cb8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0KY4ZVpUfLBb65URlGyGIA.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">在<a class="ae kr" href="https://fiftyone.ai" rel="noopener ugc nofollow" target="_blank">五十一</a>中标记样本(图片由作者提供)</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="66f9" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们现在可以使用<code class="fe np nq nr ms b">annotate()</code>方法将这些样本和标签上传到CVAT进行重新标注。以下代码在您的帐户中的<a class="ae kr" href="https://cvat.org" rel="noopener ugc nofollow" target="_blank">cvat.org</a>上创建一个新任务，其中仅包含带有<code class="fe np nq nr ms b">requires_annotation</code>标签的样本:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oa"><img src="../Images/f916e96d41c4d9afe1afbf0e61429055.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AB-yWCwVhtVUIkZ5FH9WNw.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">更正<a class="ae kr" href="https://github.com/openvinotoolkit/cvat" rel="noopener ugc nofollow" target="_blank"> CVAT </a>中的<code class="fe np nq nr ms b">iscrowd</code>标注(图片由作者提供)</p></figure><p id="a0c0" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在更新了所有示例中的相关注释之后，确保点击CVAT中的save按钮。现在重记已经完成，让我们将更新的标签加载回51，并清理在CVAT创建的任务。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nx"><img src="../Images/6b6887f083ee0e99b7a439fc07624793.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kInRaYiuNDClN_d8lMjZHg.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">更新了<a class="ae kr" href="https://fiftyone.ai" rel="noopener ugc nofollow" target="_blank">第五十一</a>中的<code class="fe np nq nr ms b">iscrowd</code>注释(图片由作者提供)</p></figure><p id="ddfd" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">正如我们所见，数据集上的<code class="fe np nq nr ms b">ground_truth</code>标签已经更新。让我们<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/evaluation.html" rel="noopener ugc nofollow" target="_blank">在这些更新的标签上再次评估同一个型号</a>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><pre class="kg kh ki kj gt mr ms mt mu aw mv bi"><span id="42bb" class="mw lq iq ms b gy mx my l mz na">0.3984999388520894</span></pre><p id="99e3" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir">模型的<a class="ae kr" href="https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#map-and-pr-curves" rel="noopener ugc nofollow" target="_blank">图</a>仅仅通过更新一个样本中的单个标签，就从39.57%提升到了39.85%！</strong>下一步是花更多的时间探索51年的数据集，找出更多的注释错误，并将它们发送给CVAT的注释者团队进行审查和重新注释。可以指派特定的用户来注释或审阅通过该API创建的任务。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="2c91" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">此工作流展示了如何改进数据集的验证拆分以及该拆分下模型的后续性能。在这一点上，我们实际上从未重新训练过模型！下一步是在整个数据集上迭代这个工作流，一次一个分割，直到它被完整地细化。然后，当需要训练模型时，演示与<a class="ae kr" rel="noopener" target="_blank" href="/stop-wasting-time-with-pytorch-datasets-17cac2c22fa8"> PyTorch数据加载器</a>或<a class="ae kr" href="https://voxel51.com/docs/fiftyone/integrations/lightning_flash.html" rel="noopener ugc nofollow" target="_blank"> PyTorch Lightning Flash </a>集成的其他工作流是一个很好的起点。</p><h1 id="a9cc" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">摘要</h1><p id="61e8" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated">构建高质量的数据集是产生高性能模型的最可靠的方法。用于构建和改进数据集的开源工具允许计算机视觉社区作为一个整体来开发更好的模型。<a class="ae kr" href="https://fiftyone.ai" rel="noopener ugc nofollow" target="_blank">五十一</a>和<a class="ae kr" href="https://github.com/openvinotoolkit/cvat" rel="noopener ugc nofollow" target="_blank"> CVAT </a>是两个开源工具，现在紧密集成在一起，你可以用来从头管理和注释数据集，以及探索和重新注释现有的数据集以改进它们。</p><h1 id="491c" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">关于体素51</h1><p id="7beb" class="pw-post-body-paragraph ks kt iq ku b kv mh jr kx ky mi ju la lb mj ld le lf mk lh li lj ml ll lm ln ij bi translated"><a class="ae kr" href="https://voxel51.com/" rel="noopener ugc nofollow" target="_blank"> Voxel51 </a>总部位于密歇根州安阿伯，由密歇根大学教授Jason Corso博士和Brian Moore博士于2016年创立，是一家人工智能软件公司，通过提供开放核心软件构建模块，使计算机视觉和机器学习工程师能够快速设计数据驱动的工作流，从而实现软件2.0的民主化。</p><p id="333c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在<a class="ae kr" href="http://fiftyone.ai/" rel="noopener ugc nofollow" target="_blank"> fiftyone.ai </a>了解更多！</p></div></div>    
</body>
</html>