<html>
<head>
<title>Spatial Transformer Networks — Backpropagation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">空间变压器网络—反向传播</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/spatial-transformer-networks-backpropagation-15023fe41c88?source=collection_archive---------11-----------------------#2021-10-12">https://towardsdatascience.com/spatial-transformer-networks-backpropagation-15023fe41c88?source=collection_archive---------11-----------------------#2021-10-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6e48" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">独立的介绍</h2></div><p id="f2e4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由Max Jaderberg等人引入的空间变换器模块是一种流行的方法，用于增加模型对空间变换(如平移、缩放、旋转、裁剪以及非刚性变形)的空间不变性。它们通过自适应地将其输入变换为规范的、预期的姿态来实现空间不变性，从而导致更好的分类性能。</p><p id="fd37" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个由四部分组成的教程中，我们涵盖了深入理解空间转换器所需的所有先决条件。在前两篇文章中，我们已经介绍了正向和反向映射的<a class="ae lc" rel="noopener" target="_blank" href="/spatial-transformer-tutorial-part-1-forward-and-reverse-mapping-8d3f66375bf5">概念</a>，并深入研究了双线性插值的<a class="ae lc" rel="noopener" target="_blank" href="/spatial-transformer-networks-tutorial-part-2-bilinear-interpolation-371e1d5f164f">细节</a>。在上一篇文章中，我们已经介绍了构成空间转换器模块的所有构件。最后，在这篇文章中，我们将从头开始推导所有必要的反向传播方程。</p><h1 id="5c73" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">梯度流动</h1><p id="e388" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">在我们开始推导公式之前，让我们快速了解一下梯度是如何通过空间转换器模块流回的:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi ma"><img src="../Images/49b54ce3d3f84d4fbb71470e120b8dd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*KgNiiggMZcsTfl8M1PFTLw.gif"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">梯度流，𝓛表示损失函数(图片由作者提供)</p></figure><p id="e441" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面的动画清楚地说明了为什么空间转换器网络可以使用标准反向传播进行端到端训练。我们从模块输出端的梯度开始，该梯度已经在较高层计算过了。我们要做的第一件事，是导出显式公式，通过<strong class="kh ir">采样器</strong>将该梯度传播(或流动)回输入特征图和<strong class="kh ir">采样网格</strong>。然后，我们必须通过<strong class="kh ir">网格生成器</strong>推导出控制反向传播的公式。记住<strong class="kh ir">采样器</strong>和<strong class="kh ir">网格生成器</strong>都是无参数操作，即没有任何可训练参数。最后，我们必须通过<strong class="kh ir">定位网络</strong>反向传播梯度，这是一个标准的神经网络，因此这里不需要推导新的公式。参数更新发生在<strong class="kh ir">本地化网络</strong>中。</p><p id="9cd4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你从未遇到过反向传播，对梯度流概念的理解有问题，<a class="ae lc" rel="noopener" target="_blank" href="/deriving-the-backpropagation-equations-from-scratch-part-1-343b300c585a">请看看我的介绍帖</a>。</p><h1 id="84b0" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">梯度w.r.t采样网格坐标</h1><p id="6ae0" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">在所有以前的帖子中，我们将假设<strong class="kh ir">采样器</strong>使用双线性插值来转换输入特征图。让我们快速回忆一下在第二篇文章中<a class="ae lc" rel="noopener" target="_blank" href="/spatial-transformer-networks-tutorial-part-2-bilinear-interpolation-371e1d5f164f">推导出的相应公式。对于<strong class="kh ir">采样网格</strong>的每个条目:</a></p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/9dfe792475a24002cf5d7323db4b67a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:234/format:webp/1*qVeb44qY1diJgWx3l8A84Q.png"/></div></figure><p id="80eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">采样器</strong>首先通过取下限和上限运算找到四个相邻值:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/b8cfb39e9e9bce4bec24d3d3cf3b3969.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*73DzzeTMYFZ-IC46XHxMCw.png"/></div></figure><p id="8920" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了清楚起见，我们去掉了上标“𝑠”。接下来，<strong class="kh ir">采样器</strong>计算从采样点到其单元格右边界的<em class="lb">水平距离</em>和到单元格上边界的<em class="lb">垂直距离</em>:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/e1b604aed88ba04f5b9158c47bf367d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*7ENIOQD6Ovgq6jmMiZy79A.png"/></div></figure><p id="4193" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，需要一个加权平均值来产生输出:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mt"><img src="../Images/c06956e5fa4d20f3864e672c85044054.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iiorhaZUGqMQxMRevZqwWw.png"/></div></div></figure><p id="b203" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了得到想要的导数的直觉，让我们摆动单个(！)进入<strong class="kh ir">采样网格</strong>:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mu"><img src="../Images/6d7653ccea460218894ef037e98fc8f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Gn5jesLJIvoPHeqEiw4MEg.gif"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">单个条目对输出地图的影响(图片由作者提供)</p></figure><p id="275b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们看到，摆动仅影响输出特征地图中的单个像素。这是意料之中的，因为<strong class="kh ir">采样器</strong>在<strong class="kh ir">采样网格</strong>的每个入口上独立运行(这是采样器非常适合并行化的原因)。为了将损失误差从输出特征图反向传播到<strong class="kh ir">采样网格</strong>，我们所要做的就是应用链式法则:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/24e6b6425fbb035609d079fa7294cf0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*MwaSVURJiSrcK1nX_R2lIQ.png"/></div></figure><p id="e864" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中𝓛是损失函数。接下来，我们必须把𝑉·w·r·t的导数带到𝑥:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mw"><img src="../Images/88acaa1075e66797a41c3dcded471e2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*83F3IAXeUVXj4Wac8OUVxw.png"/></div></div></figure><p id="ddfb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这需要我们对水平距离求导:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/6506db1978b6b5652ab5c09022165391.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/1*KBrATCOM1jp0CP_n5N0CGA.png"/></div></figure><p id="2645" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了更进一步，我们必须看看天花板运算的导数:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi my"><img src="../Images/4e2b131794379ed423487dd7a5ae0687.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1xGabgpMRrIUwYhWY5r_BQ.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">天花板操作及其衍生工具(图片由作者提供)</p></figure><p id="21a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到，上限运算是分段常数，常数的导数为零。上限运算在𝑥的整数值处是不连续的，并且在那里是不可微的。</p><p id="e812" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从技术上讲，我们不能对一个不可微的函数应用梯度下降。我们的补救办法是所谓的次导数，它是导数的延伸，见<em class="lb">参考文献</em>。实际上，这可以归结为在𝑥:的整数值处将导数设置为零</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/7ab98304ab75b29757f2fe4257504cec.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*XZoUkKlQtqPeDMNA4vz_aA.png"/></div></figure><p id="21d0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">类似地:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi na"><img src="../Images/d2f8504bb802dfbdab815c1f4cccc23a.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*fhFoN4YIL2ctGkgWPGuDcQ.png"/></div></figure><p id="8a51" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">形式上，我们现在计算子梯度而不是梯度。我们最后的公式是:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nb"><img src="../Images/74f099822ed9bf21de901f73965e0204.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kz3YgG8CpTSPRl2HBC4UOA.png"/></div></div></figure><p id="d543" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">重新排列后:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nc"><img src="../Images/cc010e4465b6ec4d454df1e0b263aa4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nua4iLryOUd0mpQsCThFPA.png"/></div></div></figure><p id="377f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于𝑦分量，我们相应地得到:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi my"><img src="../Images/6a3affa6f87a2efd8b1c785301a90d4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EtorjDUGtS1MARGXPmgWoQ.png"/></div></div></figure><h1 id="9f05" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">梯度w.r.t输入要素地图</h1><p id="bcff" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">在我们深入研究数学公式之前，让我们再次首先发展一种直觉。这一次，我们必须摆动输入要素地图中的像素值，比如坐标(2，1):</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nd"><img src="../Images/111fb0c1ff283bcb45dbe9ac698d1aa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*PsRvvpCON_-E2S1eqNuE0Q.gif"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">单个输入像素对输出地图的影响(图片由作者提供)</p></figure><p id="9f56" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们看到，摆动输入特征图中的单个像素会导致输出特征图中的多个像素发生变化。为了理解原因，让我们仔细看看受影响的输出像素的采样点:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/822f4197f959aca8f8b35054e4eecc6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/1*0PuvNyIQjRCMvAl3vI_BUw.gif"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">受影响的样本点共享一个公共输入像素(图片由作者提供)</p></figure><p id="bc94" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们注意到，所有提到的样本点都有一些共同点:坐标(2，1)处的输入像素总是属于双线性插值中使用的四个相邻点之一。还请注意输入像素(2，1)有时是右上邻居，有时是左下邻居，依此类推。</p><p id="e6ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">用于反向传播误差的链式法则现在变成:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/e3c363c52adbd1911b426e7340a04256.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*4htGQmvS7Y18U3veffiITA.png"/></div></figure><p id="3a44" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中两个和考虑了输入特征图中的每个像素可能(潜在地)影响输出特征图中的多个像素的事实。在下一步中，我们必须评估表达式∂𝑉/ ∂𝑈，它强烈依赖于𝑈相对于𝑉's样本点的相对位置(左上邻居、右上邻居等)。).为此，我们以如下方式重写双线性插值公式:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/282a01b3bd30df65fe40ac287195cf72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*6enQ8mBc3exMv8KF-uZC0Q.png"/></div></figure><p id="18bb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">相应的衍生工具有:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/1bf476a3f29339c09944d6c2f7d96e03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*tyRwgsXXSRlQtgmMrv6wfw.png"/></div></figure><p id="a0d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在有了计算梯度的所有必要公式。为了对整个过程有一个更好的直觉，让我们把它应用到上面动画的例子中。这里，输入像素(2，1)影响以下五个输出像素(0，0)、(0，1)、(1，0)、(1，1)和(2，1):</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi ni"><img src="../Images/02cfe3d99a6df9e952180834feea726a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lYGirab618KsJFYze94s_g.png"/></div></div></figure><p id="8ff7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该过程的主要挑战似乎在于找到所有受影响的输出像素。幸运的是，在实际实现中，我们可以通过利用线性来完全省略显式搜索:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/9883963621a6b657fba9ba8b7b123980.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/1*ZW3roW0Pq2CAeJVfQ8uSDw.gif"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">高效实施(图片由作者提供)</p></figure><p id="e1bc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为此，我们首先为梯度∂𝓛 / ∂𝑈初始化一个空数组，然后迭代<strong class="kh ir">采样网格</strong>的条目。对于每个条目，我们使用倒数第二个公式来计算∂𝑉/ ∂𝑈的所有四个导数，随后乘以梯度<br/> ∂𝓛 / ∂𝑉.的相应条目剩下的最后一步是将四个计算值添加到梯度数组中。请注意，每个值都添加在不同的位置，由四个相邻点的位置定义。在整个过程结束时，梯度阵列的每个条目将包含所有受影响的输出像素的完整总和。</p><h1 id="ce7f" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">通过网格生成器反向传播</h1><p id="abf3" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">我们已经看到损失函数如何依赖于<strong class="kh ir">采样网格</strong>的所有坐标:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nk"><img src="../Images/208525a0e44bddb1f1a6a1b5aee3f9c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*eLwuvj7kmGaH0hu6cdLf4A.png"/></div></div></figure><p id="482f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，每个样本坐标是由<strong class="kh ir">定位网络</strong>提供的参数的函数:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/f8c8cfb97dc420d0f5fd19ec957fb672.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*XHEKYggz1dI19FeCzFUo9g.png"/></div></figure><p id="92df" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，将链式法则应用于多元函数，我们得到:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/9dd0bb175954921e9a3dcdad1383c095.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*HdGLfVAyt6QCZC9ncZLgSw.png"/></div></figure><p id="a8c4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下文中，我们将假设<strong class="kh ir">网格生成器</strong>正在使用仿射变换:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/de680bc5d37fd3538d47114b4bbb6799.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*bEWT2QOL-5SFjF1qyFT9rw.png"/></div></figure><p id="6aa6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于目标坐标位于规则的采样网格上，因此我们有:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi no"><img src="../Images/d69a6eda3658406efb3dc3637628d10b.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*Apv1gV4u_BH8CpIzfKQYHg.png"/></div></figure><p id="e59a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使得上述等式简化为:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi np"><img src="../Images/bcac4ae7c7e8e634d91353c22a830863.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/1*RkLKMZ6uJn41pM00EVGNVQ.png"/></div></figure><p id="6cec" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">相应的衍生工具有:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/891bc9ce208efd3d2de7caf1ef305769.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*uZx-JUHpk0b-GPv2h0e4Aw.png"/></div></figure><p id="4b9e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其余情况为零。为了获得最终的公式，我们将这些导数代入上述链式法则:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nr"><img src="../Images/c4d1619ec81fe92f5a9a40bbd70c5cc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_lY24_KkYY-iLJnN_N_WPg.png"/></div></div></figure><p id="87b2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">类似地:</p><figure class="mb mc md me gt mf gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nr"><img src="../Images/2c843c31d7d64ba8f511ef915154b464.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ERiS_QdvjkAxvOzc7rSupQ.png"/></div></div></figure><p id="1c57" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如第一节所述，<strong class="kh ir">网格生成器</strong>通常被实现为标准的神经网络，例如全连接网络或卷积网络。为此，我们不需要推导任何新的反向传播公式。</p></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><p id="e106" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们已经到了第四个也是最后一个帖子的末尾。在这篇文章中，我们讨论了空间转换模块中很少被提及的反向传播的话题。虽然很复杂，但它将极大地帮助您调试在使用空间转换器模块时可能会遇到的问题。如果你想进一步磨练你的理解，请看看通过采样器反向传播的实际<a class="ae lc" href="https://github.com/tensorflow/addons/blob/v0.13.0/tensorflow_addons/custom_ops/image/cc/kernels/resampler_ops.cc" rel="noopener ugc nofollow" target="_blank"> Tensorflow C++实现</a>。</p><h1 id="b5f3" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">参考</h1><p id="fab0" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated"><a class="ae lc" href="https://arxiv.org/pdf/1506.02025.pdf" rel="noopener ugc nofollow" target="_blank">原文</a> <br/> <a class="ae lc" rel="noopener" target="_blank" href="/beyond-the-derivative-subderivatives-1c4e5bf20679">超越导数—次导数</a> <br/> <a class="ae lc" href="https://medium.com/@kanchansarkar/relu-not-a-differentiable-function-why-used-in-gradient-based-optimization-7fef3a4cecec" rel="noopener"> ReLU:不是可微函数</a> <br/> <a class="ae lc" href="https://en.m.wikipedia.org/wiki/Subderivative?wprov=sfla1" rel="noopener ugc nofollow" target="_blank">次导数</a></p></div></div>    
</body>
</html>