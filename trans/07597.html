<html>
<head>
<title>TabNet — Deep Neural Network for Structured, Tabular Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TabNet —用于结构化表格数据的深度神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tabnet-deep-neural-network-for-structured-tabular-data-39eb4b27a9e4?source=collection_archive---------6-----------------------#2021-07-12">https://towardsdatascience.com/tabnet-deep-neural-network-for-structured-tabular-data-39eb4b27a9e4?source=collection_archive---------6-----------------------#2021-07-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/2ad2d5e47f77da9a7b0a384c9a5a1886.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SoDAKG_qZxhtW9c988z7Wg.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">里卡多·戈麦斯·安吉尔在<a class="ae kf" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="5d58" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，我将带你看一个使用Google的TabNet解决分类问题的例子。</p><p id="557f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尽管最近图像、音频和文本的深度神经网络(DNNs)激增，但似乎使用良好的结构化表格数据的任务在某种程度上被忽略了。</p><p id="0b4a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然今天的大部分数据确实是非结构化的(<a class="ae kf" href="https://www.altexsoft.com/blog/structured-unstructured-data/" rel="noopener ugc nofollow" target="_blank">大约80% </a>，但重要的是要正确看待绑定到行和列的<em class="le">少得可怜的</em> 20%的数据仍然代表着巨大的数量。事实上，在2020年，<a class="ae kf" href="https://www.ibm.com/blogs/journey-to-ai/2020/11/addressing-data-growth-with-scalable-immediate-and-live-data-migration/" rel="noopener ugc nofollow" target="_blank"> IBM </a>估计全世界的数据收集总量将达到350亿兆字节(或350亿兆兆字节)。</p><p id="a26e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这使得<strong class="ki iu"> 7，000，000，000，000，000，000字节的结构化数据需要一些深层的神经关注！</strong></p><p id="6a4f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">平心而论，正如TabNet最初的<a class="ae kf" href="https://arxiv.org/pdf/1908.07442.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中指出的，这是由于当前的集合决策树(DT)变体(XGBoost、LightGBM、CatBoost等)的事实。，)在表格数据方面比DNNs有一些优势。</p><p id="4a78" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，这一切都消失了，因为TabNet的发布在多个基准数据集上超过了基于DT的模型。</p></div><div class="ab cl lf lg hx lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="im in io ip iq"><h1 id="0235" class="lm ln it bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">弗雷明汉心脏研究</h1><p id="4447" class="pw-post-body-paragraph kg kh it ki b kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">今天，我将通过一个例子来说明如何使用TabNet来完成分类任务。该数据集包含来自弗雷明汉心脏研究的结果，该研究始于1948年，已经提供(并且仍在提供)对心血管疾病风险因素的重要见解。对于那些有兴趣了解更多关于这项研究的人，请查看此<a class="ae kf" href="https://framinghamheartstudy.org/fhs-about/" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="8551" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你有兴趣了解更多关于TabNet架构的知识，我鼓励你看看我上面链接的原始论文。额外的资源包括这个<a class="ae kf" href="https://github.com/google-research/google-research/blob/master/tabnet/tabnet_model.py" rel="noopener ugc nofollow" target="_blank"> repo </a>，在这里你可以看到原始的TabNet代码。</p><p id="2a3c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，在我们深入讨论之前，你可以使用我在这个<a class="ae kf" href="https://github.com/ryancburke/framingham" rel="noopener ugc nofollow" target="_blank">回购</a>找到的笔记本。</p><h2 id="6a91" class="mp ln it bd lo mq mr dn ls ms mt dp lw kr mu mv ma kv mw mx me kz my mz mi na bi translated">数据</h2><p id="a4f8" class="pw-post-body-paragraph kg kh it ki b kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">用于该分析的数据由16个变量组成，包括目标变量ANYCHD。每一个的描述可以在下面找到。</p><figure class="nb nc nd ne gt ju"><div class="bz fp l di"><div class="nf ng l"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">表1-数据集中变量的描述。</p></figure><p id="13cb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是我们的数据帧的样子。</p><figure class="nb nc nd ne gt ju"><div class="bz fp l di"><div class="nf ng l"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">表2 —表格形式的数据视图</p></figure><h2 id="6069" class="mp ln it bd lo mq mr dn ls ms mt dp lw kr mu mv ma kv mw mx me kz my mz mi na bi translated">调查缺失值</h2><p id="029a" class="pw-post-body-paragraph kg kh it ki b kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">接下来，我想看看丢失了多少数据。使用df.isnull()很容易做到这一点。sum()，它将告诉我们每个变量丢失了多少数据。另一种方法是使用一个软件包<a class="ae kf" href="https://github.com/ResidentMario/missingno" rel="noopener ugc nofollow" target="_blank"> missingno </a>，它允许我们非常快速地可视化缺失数据之间的关系。</p><p id="78d9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在图1中，变量的缺失值(白色)的矩阵表示。这是按行垂直组织的，这允许我们查看丢失的值之间是否有任何关系。例如，HDLC和LDLC的缺失值是相同的，这表明这些值不是为该数据集中的部分患者收集的。</p><figure class="nb nc nd ne gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nh"><img src="../Images/68d9b431baaadc561f299cc2272e2a87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A2pIjPXJ2zGtdYKPdXvn9A.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图1 —按变量排列的缺失数据矩阵。作者图片</p></figure><p id="bc79" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还可以从另一个角度得到缺失值之间关系的热图，如图2所示。在这里，我们可以更容易地看到HDLC和LDLC之间的关系。值&lt;1 means that it is slightly less than 1. Since al 3 of these variables are measure of cholesterol, it suggests that cholesterol data was not collected for certain patients in the dataset.</p><figure class="nb nc nd ne gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ni"><img src="../Images/026eadd13393e2ae09bced54a98cd4fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tUZWUOQjC_f2lL_5zhZqMQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">Figure 2 — A heatmap demonstrating the relationship between missing values. Image by author</p></figure><h2 id="f324" class="mp ln it bd lo mq mr dn ls ms mt dp lw kr mu mv ma kv mw mx me kz my mz mi na bi translated">Imputing missing values</h2><p id="83ba" class="pw-post-body-paragraph kg kh it ki b kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">Now that we have gathered information about our missing values, we need to decide what to do about them. There are many options depending on your data, and you can read more about the various imputation algorithms available on <a class="ae kf" href="https://scikit-learn.org/stable/modules/impute.html" rel="noopener ugc nofollow" target="_blank"> sklearn </a>的网页。</p><p id="2aba" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我选择了KNN估算器，您可以使用下面的代码实现它。总而言之，在第一个模块中，我简单地将数据分为特征和目标。</p><p id="f478" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第二个模块使用KNN估算器变换特征。正如您在打印报表中看到的，最初有1812个缺失值被估算。</p><figure class="nb nc nd ne gt ju"><div class="bz fp l di"><div class="nf ng l"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图3-使用KNN估算器处理数据集中的缺失值。</p></figure><p id="1049" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后一步是分割我们的数据。使用下面的代码，我最初将数据分成70%用于训练集，30%用于验证集。然后，我将验证集分为验证集和测试集两部分。打印声明为我们提供了关于裂缝形状的信息。</p><figure class="nb nc nd ne gt ju"><div class="bz fp l di"><div class="nf ng l"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图4 —将数据分为训练集、验证集和测试集</p></figure><h2 id="5bd4" class="mp ln it bd lo mq mr dn ls ms mt dp lw kr mu mv ma kv mw mx me kz my mz mi na bi translated">TabNet</h2><p id="8942" class="pw-post-body-paragraph kg kh it ki b kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">您可以用几行简单的代码来运行TabNet，如下所示。这是TabNet的pytorch实现，所以您必须导入(或者安装，如果您还没有导入的话)torch、pythorch_tabnet和您希望使用的模型(二进制分类器、多分类器、回归器)。</p><p id="2556" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您还需要某种度量来评估您的模型。以下是从<a class="ae kf" href="https://scikit-learn.org/stable/modules/model_evaluation.html" rel="noopener ugc nofollow" target="_blank"> sklearn </a>获得的列表。我还包含了一个标签编码，以防您的数据与我的略有不同。我的分类变量都是二进制整数，但是如果你有存储为字符串的类别，你会首先使用这个(或者一个替代的，比如一个热编码)。</p><figure class="nb nc nd ne gt ju"><div class="bz fp l di"><div class="nf ng l"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图5 —导入必要的库</p></figure><p id="7fff" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，我们必须定义我们的模型，这可以在下面的第一个代码块中看到。在第一行，我们定义了我们的优化器，<a class="ae kf" href="https://arxiv.org/abs/1412.6980" rel="noopener ugc nofollow" target="_blank">亚当</a>。接下来的几行安排了我们学习速度的逐步衰减。让我们打开它的内容:</p><ul class=""><li id="b778" class="nj nk it ki b kj kk kn ko kr nl kv nm kz nn ld no np nq nr bi translated">学习率最初设置为lr = 0.020</li><li id="cfb0" class="nj nk it ki b kj ns kn nt kr nu kv nv kz nw ld no np nq nr bi translated">10个时期后，我们将应用0.9的衰减率</li><li id="5a97" class="nj nk it ki b kj ns kn nt kr nu kv nv kz nw ld no np nq nr bi translated">结果仅仅是我们的学习率和衰减率的乘积0.02*0.9，这意味着在第10个时期它将减少到0.018</li></ul><p id="1353" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在下一个代码块中，我们使模型适合我们的数据。基本上，它说训练和验证集将使用<em class="le"> auc </em>(曲线下面积)和<em class="le">准确性</em>作为总共1000次迭代(<em class="le">时期</em>)的度量来评估。</p><p id="f98a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">耐心</em>参数表示，如果在连续50个时期后没有观察到度量的改善，则模型将停止运行，并将加载来自最佳时期的最佳权重。</p><p id="efac" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">256的<em class="le">批量</em>是根据TabNet论文的建议选择的，他们建议批量不超过总数据的10%。他们还建议<em class="le">虚拟批量</em>小于批量，可以均分为批量。</p><p id="bd9a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">工人<em class="le">的数量</em>保持为零，这意味着将根据需要装载批量。据我所知，增加这个数字是一个非常消耗内存的过程。</p><p id="4cec" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="le">权重</em>可以是0(无采样)或1(自动采样)。最后，<em class="le"> drop_last </em>是指在训练过程中，如果没有完成，则丢弃最后一批。</p><p id="7fe3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">值得注意的是，其中许多都是默认参数。你可以在这里查看参数<a class="ae kf" href="https://github.com/dreamquark-ai/tabnet" rel="noopener ugc nofollow" target="_blank">的完整列表</a>。</p><figure class="nb nc nd ne gt ju"><div class="bz fp l di"><div class="nf ng l"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图6——定义和拟合我们的TabNet分类器</p></figure><p id="178d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个分析的结果可以在图8中看到，并且可以使用下面的代码重现。前三个代码块绘制了损失分数、准确性(对于训练集和验证集)和特征重要性(对于测试集)。</p><p id="26e8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后的块简单地计算验证和测试集达到的最佳精度，分别是68%和63%。</p><figure class="nb nc nd ne gt ju"><div class="bz fp l di"><div class="nf ng l"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图7 —绘制损失分数、准确性和特征重要性</p></figure><figure class="nb nc nd ne gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nx"><img src="../Images/1ee1b6c726fdc624685de4cb29e5a946.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ghb9DNFZtKK1J0pXXuntoQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图8 —(左)损失分数；(中间)训练(蓝色)和验证(橙色)集的准确性；(右)相对特征重要性</p></figure><h2 id="79f7" class="mp ln it bd lo mq mr dn ls ms mt dp lw kr mu mv ma kv mw mx me kz my mz mi na bi translated">无监督预训练</h2><p id="5e9d" class="pw-post-body-paragraph kg kh it ki b kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">TabNet也可以作为无监督模型进行预训练。预训练包括有意屏蔽某些单元格，并通过预测屏蔽值来学习这些单元格和相邻列之间的关系。然后，可以保存学习到的权重，并将其用于监督任务。</p><p id="6fd1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看看使用无监督的预训练如何影响我们的模型精度！</p><p id="463d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然类似，但代码有一些差异，所以我在下面列出了这些差异。具体来说，您必须导入TabNetPretrainer。您可以在第一个代码块中看到，TabNetClassifier被替换为TabNetPretrainer。</p><p id="9fc6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当您拟合模型时，请注意最后一行<em class="le"> pretraining_ratio </em>，它是在预训练期间被屏蔽的特征的百分比。值为0.8表示80%的要素被遮罩。</p><p id="a231" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下一个代码块引用从TabNet的编码表示中生成的重构特征。这些被保存，然后可以在单独的监督任务中使用。</p><figure class="nb nc nd ne gt ju"><div class="bz fp l di"><div class="nf ng l"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图9 —使用TabNet的无监督表示学习</p></figure><p id="0b96" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当对该数据集使用预训练时，验证集和测试集的结果分别为76%和71%的准确度。这是一个显著的进步！下面，您可以看到损失分数、训练集(蓝色)和验证集(橙色)的准确性，以及为测试集确定的特性重要性。</p><figure class="nb nc nd ne gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ny"><img src="../Images/a30447c131d7ce7ad1c406ed93922680.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CerlPaLMDUDjB1yEyWM9aA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图10 —(左)损失分数；(中间)训练(蓝色)和验证(橙色)集的准确性；(右)相对特征重要性。图片作者。</p></figure><h2 id="26f6" class="mp ln it bd lo mq mr dn ls ms mt dp lw kr mu mv ma kv mw mx me kz my mz mi na bi translated">摘要</h2><p id="d2e7" class="pw-post-body-paragraph kg kh it ki b kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz mo lb lc ld im bi translated">在本文中，我们通过一个例子演示了如何为分类任务实现TabNet。我们发现使用TabNet的无监督预训练显著提高了模型的准确性。</p><p id="432e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在下面的图11中，我绘制了有监督(左)和无监督(右)模型的特征重要性。有趣的是，无监督的预训练能够提高模型的准确性，同时减少特征的数量。</p><p id="ddc0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们考虑特性之间的关系时，这是有意义的。例如，使用TabNet进行预训练可以了解到血压药物(BPMEDS)、收缩压(SYSBP)和舒张压(DIABP)是相关的。因此，无监督表示学习作为监督学习任务的高级编码器模型，具有更清晰和更可解释的结果。</p><figure class="nb nc nd ne gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nz"><img src="../Images/dda6598626ec3152cde8217e0562fa59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qdde5MMeT2Y6CM94xTRrmQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图11-有监督(左)和无监督(右)TabNet模型的特征重要性值。图片作者。</p></figure><p id="396f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我希望你喜欢这篇文章！试试看，让我知道它对你有什么效果。</p></div></div>    
</body>
</html>