<html>
<head>
<title>Pyspark Installation Guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pyspark安装指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pyspark-installation-guide-140aee9aab87?source=collection_archive---------47-----------------------#2021-06-07">https://towardsdatascience.com/pyspark-installation-guide-140aee9aab87?source=collection_archive---------47-----------------------#2021-06-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="aada" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">设置Pyspark的全面指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/165675248aa5c3cbad6d5c721a2c1d82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*koo5Tv_lCeXT83sNdqzkdg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@selimarda?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">seli̇m·阿尔达·埃里希马兹</a>在<a class="ae ky" href="https://unsplash.com/s/photos/pipeline?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="be4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您需要为数据科学应用程序设置PySpark环境的完整指南，请留下来；PySpark功能，以及有待探索的最佳平台。</p><h1 id="2d05" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">Pyspark是什么？</h1><p id="981c" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">Pyspark是一种健壮的语言，如果您想创建更具可伸缩性的管道和分析，就必须考虑学习这种语言。据数据工程师Chris Min称，Pyspark基本上支持用Python编写spark应用程序，并以分布式方式高效处理数据。Python不仅是一门伟大的语言，还是一个一体化的生态系统，可以执行探索性的数据分析，为数据平台创建ETL，并构建ML管道。你也可以说PySpark不亚于一个完整的库，可以在单个/集群机器上用于大量的大型数据处理，此外，它甚至不需要Python中的线程或多处理模块就可以处理所有这些并行处理。</p><h1 id="c3fc" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">Spark是数据工程的真正交易</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/9ccae10feae7ca74a8ab6db912416adf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MvbGZYLDd0qAzJkFF9Jw8w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@smudgern6?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">丹尼尔·史密斯</a>在<a class="ae ky" href="https://unsplash.com/s/photos/engineering?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="3f2b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据<a class="ae ky" href="https://rdcu.be/clqD9" rel="noopener ugc nofollow" target="_blank">国际数据科学与分析杂志</a>的报道，Spark作为一个通用集群计算框架的出现是真实的，它拥有Python、Scala和Java语言集成的API。它令人印象深刻的高级内存编程模型和用于结构化数据处理的库、可伸缩ML和图形分析增加了它在数据科学行业中的功能。事实上，不可否认的是，在数据处理的某一点上，用Pandas进行扩展是很困难的。成为一名数据工程师需要处理大量的大型数据，如果你精通Spark，这并不是什么大不了的事情。</p><h1 id="62f4" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据科学家为什么要学spark？</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/9580ec2b1ef806326b174a56b8a43c40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MPF6ggKLonN7wXfq"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@sigmund?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">西格蒙德</a>在<a class="ae ky" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="da4f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为一名数据科学家，学习Spark可以改变游戏规则。对于大型数据处理，Spark比Pandas好得多，但在使用上没有太大的不同，所以改用它不是什么大问题，当您在数据工程操作中获得真正的好处时也是如此。Spark有各种问题的解决方案，它是一个完整的库集合，可以非常有效地执行逻辑。Spark确保您获得非常干净和高效的操作体验，在某种程度上甚至比Pandas更好，尤其是在处理大型数据集时。Spark以其高效的高性能分析和用户友好的结构为您所用。</p><h1 id="1ea4" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">探索Pyspark设置的所有选项</h1><p id="bc5e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我也有这篇文章的视频版本，如果你感兴趣的话，可以在我的youtube频道上看这个视频</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mu mv l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://youtu.be/Ql_jfk3UnHE" rel="noopener ugc nofollow" target="_blank"> Pyspark安装指南</a>作者<a class="ae ky" href="https://www.youtube.com/channel/UCO8XsgcjqArk_mAd1VGBMfg?sub_confirmation=1" rel="noopener ugc nofollow" target="_blank"> Anuj Syal </a></p></figure><p id="360a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是一组您可以考虑用来建立PySpark生态系统的各种选项。下面列出了您可以考虑的所有最佳平台:</p><h1 id="cc99" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">在Ubuntu上本地设置Spark和Python</h1><ul class=""><li id="df61" class="mw mx it lb b lc mn lf mo li my lm mz lq na lu nb nc nd ne bi translated">安装Java</li></ul><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="32cc" class="nk lw it ng b gy nl nm l nn no">sudo apt install openjdk-8-jdk</span></pre><ul class=""><li id="539c" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">从<code class="fe ns nt nu ng b"><a class="ae ky" href="https://spark.apache.org/downloads.html" rel="noopener ugc nofollow" target="_blank">https://spark.apache.org/downloads.html</a></code> linux版本下载spark</li><li id="4c56" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">设置环境变量<code class="fe ns nt nu ng b">sudo nano /etc/environment</code></li></ul><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="1d1b" class="nk lw it ng b gy nl nm l nn no">JAVA_HOME="/usr/lib/jvm/java-8-openjdk-amd64"<br/>#Save and exit</span></pre><ul class=""><li id="53f3" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">测试<code class="fe ns nt nu ng b">echo $JAVA_HOME</code>并查看路径以确认安装</li><li id="6351" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">打开bashrc <code class="fe ns nt nu ng b">sudo nano ~/.bashrc</code>，在文件末尾添加<code class="fe ns nt nu ng b">source /etc/environment</code></li><li id="8503" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">这应该可以在ubuntu上建立Java环境</li><li id="473f" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">安装spark，在步骤2中下载spark后，用以下命令安装</li></ul><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="f594" class="nk lw it ng b gy nl nm l nn no">cd Downloads<br/>sudo tar -zxvf spark-3.1.2-bin-hadoop3.2.tgz</span></pre><ul class=""><li id="3c48" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">为spark <code class="fe ns nt nu ng b">sudo nano ~/.bashrc</code>配置环境，并添加以下内容</li></ul><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="1ebd" class="nk lw it ng b gy nl nm l nn no">export SPARK_HOME=~/Downloads/spark-3.1 .2-bin-hadoop3.2 export PATH=$PATH:$SPARK_HOME/bin export PATH=$PATH:~/anaconda3/bin export PYTHONPATH=$SPARK_HOME/python:$PYTHONPATH export PYSPARK_DRIVER_PYTHON="jupyter" export PYSPARK_DRIVER_PYTHON_OPTS="notebook" export PYSPARK_PYTHON=python3 export PATH=$PATH:$JAVA_HOME/jre/bin</span></pre><ul class=""><li id="ef59" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">保存并退出</li><li id="183d" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">测试端子中的类型<code class="fe ns nt nu ng b">pyspark</code></li></ul><p id="11df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">没有ubuntu？使用VirtualBox </strong></p><p id="243b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用VirtualBox在本地安装Ubuntu。VirtualBox基本上可以让你在自己的物理计算机上构建一台虚拟计算机。您可以探索VirtualBox来设置Spark和Python:(大约20-30分钟)</p><ul class=""><li id="fcd1" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">从下载<a class="ae ky" href="https://www.virtualbox.org/wiki/Downloads" rel="noopener ugc nofollow" target="_blank"> Virtualbox </a>开始。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/afb2cd98b845c982fc25f85d501168f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-1QzX0UEm7-DCVvH"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="ob">来自Virtualbox下载的截图</em></p></figure><ul class=""><li id="4387" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">下载Ubuntu ISO <a class="ae ky" href="https://ubuntu.com/download/desktop/thank-you?version=20.04.2.0&amp;architecture=amd64" rel="noopener ugc nofollow" target="_blank">图片</a></li><li id="a577" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">在VirtualBox中，点击新建并设置ubuntu 64位环境</li><li id="d217" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">传入所需的CPU内核、内存和存储</li><li id="5a17" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">指向下载的ubuntu映像</li></ul><h1 id="896c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">在Mac上本地设置Spark和Python</h1><ul class=""><li id="0ca1" class="mw mx it lb b lc mn lf mo li my lm mz lq na lu nb nc nd ne bi translated">确保安装并更新了家酿软件，如果没有，请点击此<a class="ae ky" href="https://brew.sh/" rel="noopener ugc nofollow" target="_blank">链接</a>或键入终端</li></ul><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="7a57" class="nk lw it ng b gy nl nm l nn no">/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"</span></pre><ul class=""><li id="fc72" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">打开终端并安装Java</li></ul><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="8912" class="nk lw it ng b gy nl nm l nn no">brew install java<br/>#to check if java installed?<br/>brew info java</span></pre><ul class=""><li id="78b8" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">安装scala</li></ul><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="09c5" class="nk lw it ng b gy nl nm l nn no">brew install scala</span></pre><ul class=""><li id="0c36" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">安装Spark</li></ul><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="23e7" class="nk lw it ng b gy nl nm l nn no">brew install apache-spark</span></pre><ul class=""><li id="d618" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">安装python</li></ul><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="d08b" class="nk lw it ng b gy nl nm l nn no">brew install python3</span></pre><ul class=""><li id="b823" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">设置环境bashrc打开文件<code class="fe ns nt nu ng b">sudo nano .bashrc</code></li><li id="160f" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">添加以下环境变量</li></ul><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="924e" class="nk lw it ng b gy nl nm l nn no">#java<br/>export JAVA_HOME=/Library/java/JavaVirtualMachines/adoptopenjdk-8.jdk/contents/Home/<br/>export JRE_HOME=/Library/java/JavaVirtualMachines/openjdk-13.jdk/contents/Home/jre/<br/>#spark<br/>export SPARK_HOME=/usr/local/Cellar/apache-spark/2.4.4/libexec<br/>export PATH=/usr/local/Cellar/apache-spark/2.4.4/bin:$PATH<br/>#pyspark<br/>export PYSPARK_PYTHON=/usr/local/bin/python3 <br/>export PYSPARK_DRIVER_PYTHON=jupyter<br/>export PYSPARK_DRIVER_PYTHON_OPTS='notebook'</span></pre><ul class=""><li id="237f" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">这将配置pyspark设置，以测试终端中的类型<code class="fe ns nt nu ng b">pyspark</code></li></ul><h1 id="0c0d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">用docker和jupyter笔记本在本地设置(我的首选方法)</h1><p id="5a81" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><strong class="lb iu">docker是什么？</strong></p><p id="179c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Docker是一个开发、发布和运行应用程序的开放平台。想了解更多关于docker的知识，可以查看这个<a class="ae ky" href="https://docs.docker.com/get-started/overview/" rel="noopener ugc nofollow" target="_blank">链接</a></p><p id="1231" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用docker和jupyter notebook设置Spark是一项非常简单的任务，只需要几个步骤就可以帮助PySpark在Jupyter Notebook上运行。遵循下面提到的步骤:</p><ul class=""><li id="db13" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">安装<a class="ae ky" href="https://docs.docker.com/get-docker/" rel="noopener ugc nofollow" target="_blank">对接器</a></li><li id="27b8" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">通过<a class="ae ky" href="https://hub.docker.com/u/jupyter" rel="noopener ugc nofollow" target="_blank"> jupyter </a>使用预先存在的docker映像“<a class="ae ky" href="https://hub.docker.com/r/jupyter/pyspark-notebook" rel="noopener ugc nofollow" target="_blank">jupyter/pyspark-notebook</a></li><li id="4c8f" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">拉图像</li></ul><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="139e" class="nk lw it ng b gy nl nm l nn no">docker pull jupyter/pyspark-notebook</span></pre><ul class=""><li id="3c4c" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">码头运行</li></ul><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="ddc7" class="nk lw it ng b gy nl nm l nn no">docker run -d -p 8888:8888 jupyter/pyspark-notebook:latest</span></pre><ul class=""><li id="08ff" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">到<a class="ae ky" href="http://localhost:8888/" rel="noopener ugc nofollow" target="_blank"> localhost:8888 </a>新建一个笔记本，用<code class="fe ns nt nu ng b">import pyspark</code>运行cell</li></ul><h1 id="b348" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据块设置</h1><p id="f73e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">Databricks是一个统一的分析平台，基本上在云中有Spark集群，管理得非常好。这是一个易于使用的环境，鼓励用户在完全集成的工作空间中学习、协作和工作。任何spark代码都可以轻松调度，没有任何麻烦，因为数据块本身就支持pyspark</p><ul class=""><li id="b1ec" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">开始<a class="ae ky" href="https://databricks.com/try-databricks" rel="noopener ugc nofollow" target="_blank">创建一个databricks帐户</a>(这通常由databricks管理员完成)。并将其链接到您首选的云提供商。欲了解更多信息，请查看此<a class="ae ky" href="https://www.youtube.com/watch?v=3fqfWYBXj2A" rel="noopener ugc nofollow" target="_blank">视频</a></li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mu mv l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://youtu.be/3fqfWYBXj2A" rel="noopener ugc nofollow" target="_blank">数据砖块教程</a>作者<a class="ae ky" href="https://www.youtube.com/channel/UCO8XsgcjqArk_mAd1VGBMfg?sub_confirmation=1" rel="noopener ugc nofollow" target="_blank">阿努杰·塞亚尔</a></p></figure><ul class=""><li id="6cda" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">您必须从创建Databricks集群开始。</li><li id="c86f" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">通过<code class="fe ns nt nu ng b">import pyspark</code>创建一个数据块笔记本并进行测试</li></ul><h1 id="b9ad" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">AWS EC2上的Spark和Python</h1><p id="9141" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">Amazon EC2是AWS提供的虚拟机，这些虚拟机预装了操作系统软件ami，但其余的依赖项需要单独安装。</p><ul class=""><li id="1793" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">转到AWS控制台和EC2</li><li id="a855" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">选择Ubuntu AMI</li><li id="c215" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">遵循选项1中的步骤</li></ul><p id="b9a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">避免这样做，使用其他选项</strong></p><h1 id="290d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">AWS Sagemaker笔记本电脑上的Pyspark</h1><p id="4d54" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">Amazon SageMaker于2017年推出，是一个基于云的机器学习平台，它是完全管理的，并将您的环境从开发、培训和部署中分离出来，让您可以单独扩展它们，同时帮助您优化您的支出和时间。点击几个按钮就可以轻松旋转Sagemaker笔记本。Amazon sage maker Notebook instance是一个运行Jupyter Notebook环境的机器学习(ML)计算实例。它带有预配置的Conda环境，如python2、python3、PyTorch、TensorFlow等</p><ul class=""><li id="e9b1" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">登录到您的aws控制台并转到Sagemaker</li><li id="3823" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">点击笔记本，左侧为笔记本实例</li><li id="77b2" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">点击创建笔记本实例，给它一个名字，并选择所需的配置</li><li id="b863" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">选择实例类型，也许从小型的ml.t2.medium开始，也许以后可以构建一个强大的实例</li><li id="9476" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">单击“创建”并等待几分钟，然后单击“打开jupyterlab”转到笔记本</li><li id="8b65" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">创建一个新笔记本，并编写以下代码片段来运行pyspark</li></ul><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="0c99" class="nk lw it ng b gy nl nm l nn no">import sagemaker_pyspark <br/>from pyspark.sql import SparkSession, DataFrame <br/>classpath = ":".join(sagemaker_pyspark.classpath_jars()) </span><span id="9caa" class="nk lw it ng b gy oc nm l nn no">spark = SparkSession.builder.config( "spark.driver.extraClassPath", classpath ).getOrCreate()</span></pre><ul class=""><li id="f55b" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">如果你有兴趣了解更多关于Sagemaker的信息，一定要看看我之前的<a class="ae ky" href="https://youtu.be/95332cm5ROo" rel="noopener ugc nofollow" target="_blank">视频</a>，<a class="ae ky" href="https://youtu.be/95332cm5ROo" rel="noopener ugc nofollow" target="_blank">11分钟内Sagemaker</a></li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mu mv l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://youtu.be/95332cm5ROo" rel="noopener ugc nofollow" target="_blank"> AWS Sagemaker在11分钟内</a>由<a class="ae ky" href="https://www.youtube.com/channel/UCO8XsgcjqArk_mAd1VGBMfg?sub_confirmation=1" rel="noopener ugc nofollow" target="_blank"> Anuj Syal </a></p></figure><h1 id="889c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">AWS EMR集群设置</h1><p id="eb2a" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">亚马逊EMR可能是运行Spark的最佳地点之一，它可以帮助你非常容易地创建Spark集群，因为它配备了各种功能，如亚马逊S3连接，这使它变得非常快和超级方便。此外，与EC2现货市场和EMR的集成操作管理了扩展。</p><p id="69a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">准确地说，EMR是一个管理良好的大数据服务，使数据科学家能够在使用Python、Scala和Pyspark编写的数据科学应用程序的工作中获得帮助。它为Spark确保了一个方便的集群设置，让数据科学家有一个开发和可视化的平台。</p><ul class=""><li id="87ab" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">转到AWS控制台并搜索EMR</li><li id="8759" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">点击创建一个集群</li><li id="9048" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">在常规配置中为其命名，在软件配置中选择Spark应用程序</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/b267509b3cbc4b3847883957de79f427.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*o7l7w8eGPGSD9jxG"/></div></div></figure><ul class=""><li id="64ab" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">在硬件配置中，选择实例类型，可以从m1.medium开始，并选择集群中的实例数量</li><li id="d5f2" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">在Security中，选择EC2密钥对，通常由管理员创建，如果没有，您可以按照右边的步骤创建编程访问密钥供集群使用</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/c7cf319c6c8cbb6e57b301b1041d9799.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6RREQFuxlvS2qbD7"/></div></div></figure><ul class=""><li id="ac10" class="mw mx it lb b lc ld lf lg li np lm nq lq nr lu nb nc nd ne bi translated">保留rest选项的默认值，并创建集群</li><li id="731d" class="mw mx it lb b lc nv lf nw li nx lm ny lq nz lu nb nc nd ne bi translated">之后，创建一个EMR笔记本，并选择新创建的集群来执行您的工作</li></ul><h1 id="b093" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论:</h1><p id="dbf5" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">Spark是一个完整的分析引擎，可以帮助数据科学家进行冗长的数据处理操作，这些操作在熊猫身上是相当困难的。因此，学习PySpark这个健壮的库可以在数据工程师的工作过程中给予他们很大的帮助。现在您已经了解了各种平台，这些平台使您能够使用管理良好的云来建立Spark集群，您可以自己探索它们。</p><h1 id="7034" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">在Linkedin和Twitter上关注我</h1><p id="ae7e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">如果你对类似的内容感兴趣，点击Medium上的“关注”按钮，或者在Twitter和Linkedin上关注我</p></div><div class="ab cl oe of hx og" role="separator"><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj"/></div><div class="im in io ip iq"><p id="2351" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">【https://anujsyal.com】最初发表于<a class="ae ky" href="https://anujsyal.com/pyspark-installation-guide" rel="noopener ugc nofollow" target="_blank"><em class="ol"/></a><em class="ol">。</em></p></div></div>    
</body>
</html>