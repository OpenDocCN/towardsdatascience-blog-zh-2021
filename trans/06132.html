<html>
<head>
<title>Best of arXiv — Readings for June 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">arXiv精选—2021年6月阅读</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/best-of-arxiv-june-2021-dcd3aa48a66d?source=collection_archive---------33-----------------------#2021-06-01">https://towardsdatascience.com/best-of-arxiv-june-2021-dcd3aa48a66d?source=collection_archive---------33-----------------------#2021-06-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f712" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">最近的ML论文每月精选:MLPs回归，无令牌语言模型，视觉变形金刚上的SSL等等。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8e289f7b5220a72cf7791b89e55b67a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YlSCMH4FJ-7TYblLJrm_uQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="9e12" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在过去的一个月里，ML研究文献带来了令人惊讶的结果，例如MLPs作为计算机视觉的竞争性架构的复兴，或者对批处理规范化作为一种完全无害的层的质疑。变形金刚也(当然)在盘子上:用于视觉上的自我监督学习，以及句子表示技术和字符级语言建模。</p><p id="f041" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这是每月一次的最新ML研究文献精选，由<a class="ae lr" href="https://search.zeta-alpha.com/" rel="noopener ugc nofollow" target="_blank"> Zeta Alpha </a>支持，我们总是密切关注最新的论文。尽情享受吧！</p><h2 id="cd13" class="ls lt iq bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated"><a class="ae lr" href="https://arxiv.org/abs/2105.01601" rel="noopener ugc nofollow" target="_blank"> MLP混合器:一个全MLP架构的愿景</a>👾<a class="ae lr" href="https://github.com/google-research/vision_transformer" rel="noopener ugc nofollow" target="_blank">代号</a></h2><p id="d201" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated"><em class="mq">作者:伊利亚·托尔斯泰欣、尼尔·霍尔斯比、亚历山大·科列斯尼科夫、卢卡斯·拜尔等人</em></p><p id="6bf4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> ❓Why → </strong>非常简单的基于MLP的架构突然比它们应该的工作得更好，这具有有趣的含义，并推进了我们关于深度学习工作原理的知识。</p><p id="4e10" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">💡关键见解→ </strong>你或许可以通过扩大规模来解决<em class="mq"> ML </em>问题。好吧，好吧，这是一个过于简化和夸张的说法，但是里奇·萨顿的惨痛教训似乎比好酒更容易陈酿。</p><p id="ab5e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本文构建了一个既不使用注意力也不使用CNN的架构，其工作方式如下:</p><ul class=""><li id="a62e" class="mr ms iq kx b ky kz lb lc le mt li mu lm mv lq mw mx my mz bi translated">将图像分割成小块，展平成矢量并叠加。</li><li id="6cc5" class="mr ms iq kx b ky na lb nb le nc li nd lm ne lq mw mx my mz bi translated">转置堆栈，并对所有面片的每个要素应用2层MLP。</li><li id="7f48" class="mr ms iq kx b ky na lb nb le nc li nd lm ne lq mw mx my mz bi translated">转置回原始形状，并在每个面片的所有要素上应用2层MLP。</li><li id="d22a" class="mr ms iq kx b ky na lb nb le nc li nd lm ne lq mw mx my mz bi translated">重复前面的块N次。</li></ul><p id="adca" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">结果并不十分SOTA，但足以引起一些眉毛和引发讨论。虽然CNN目前还没有走向任何地方，但这加强了一个想法，即架构选择不是引入所需归纳偏差(如平移不变性/等方差)的必要条件，这些可以通过增强等技术仅从数据中学习，尽管效率较低。</p><p id="25d0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">非常有趣的是，就在这篇论文被上传到arXiv之后，其他几篇显示非常相似结果的文章也被上传，如注意MLPs，<a class="ae lr" href="https://arxiv.org/abs/2105.01883" rel="noopener ugc nofollow" target="_blank"> RepMLP:将卷积重新参数化为完全连接的图像识别层</a>，<a class="ae lr" href="https://arxiv.org/abs/2105.03404" rel="noopener ugc nofollow" target="_blank"> ResMLP:具有数据高效训练的图像分类前馈网络</a>和<a class="ae lr" href="https://arxiv.org/abs/2105.02723" rel="noopener ugc nofollow" target="_blank">你甚至需要注意吗？一堆前馈层在ImageNet </a> ⁴.上表现惊人的好</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/44ecf391813a8af4291ff73fca8ce89c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xQcVGW1KXE3jmQmYFT_MSA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae lr" href="https://arxiv.org/pdf/2105.01601.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2105.01601.pdf</a></p></figure><h2 id="d5d5" class="ls lt iq bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated"><a class="ae lr" href="https://arxiv.org/abs/2105.13626" rel="noopener ugc nofollow" target="_blank">字节5:通过预先训练的字节到字节模型走向无令牌的未来</a>👾<a class="ae lr" href="https://github.com/google-research/byt5" rel="noopener ugc nofollow" target="_blank">代码</a></h2><p id="1bb3" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated"><em class="mq">作者薛阿迪蒂亚·巴鲁阿、诺亚·恒、拉米·阿尔-Rfou等人</em></p><p id="f8b5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> ❓Why → </strong>大多数NLP语言模型(LM)都是在几万个标记的固定词汇或子词单元上操作的。虽然这种方法在大多数时候都很有效，但它仍然会遇到诸如打字错误、大写变化或形态变化等问题。无令牌LMs是解决这些问题的一个很有前途的方向。</p><p id="1b1a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">💡关键见解→ </strong>本文的主要目标是展示如何在不牺牲性能的情况下，通过最少的修改，使现有的基于令牌的语言模型(mT5⁹)适用于字符或字节级操作。事实上，作者几乎没有改变主干T5架构:他们只是简单地去掉了原来的句子片段标记器，并把文本作为UTF 8字符的原始序列，这相当于256的“词汇表”大小。训练前的目标-最初屏蔽大约3个标记的范围并预测它们-被调整为大约20个字符的平均屏蔽范围长度。最后，作者还发现，byT5受益于编码器和解码器之间的不均匀参数分布:与常规T5不同，以较轻的解码器为代价获得“沉重”的编码器是有益的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/2afe22b45e011ee8f0f22318117617f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FmX0OJ6wh054HZVmiLRA-Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae lr" href="https://arxiv.org/pdf/2105.13626.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2105.13626.pdf</a></p></figure><p id="899f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这篇文章最令人惊讶的方面是，byT5几乎不需要任何调整就可以达到与其原始版本相当的性能。此外，byT5具有几个优点，例如对噪声的鲁棒性更强，并且在拼写和发音很重要的任务中表现更好。这为现有的转换器适应字节级序列输入描绘了一个充满希望的未来，尽管有许多警告适用:训练和推理效率仍然明显较差。</p><h2 id="098f" class="ls lt iq bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated"><a class="ae lr" href="https://arxiv.org/abs/2104.14294" rel="noopener ugc nofollow" target="_blank">自监督视觉变压器的新兴特性</a> (DINO)👾<a class="ae lr" href="https://github.com/facebookresearch/dino" rel="noopener ugc nofollow" target="_blank">代号</a></h2><p id="d770" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated"><em class="mq">作者玛蒂尔德·卡隆等人</em></p><p id="f2a9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> ❓Why → </strong>成熟的自我监督视觉变形金刚是迟早的事，现在它们来了。虽然这只是vision transformers和SSL的第一步，但这项技术将在接下来的几个月里变得更加实用。</p><p id="13f8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">💡关键洞察力→ </strong>视觉变形器可以使用Bootstrap Your Own Latent方法训练，其中图像的不同视图由<em class="mq">教师</em>和<em class="mq">学生</em>编码，输出的相似性最大化。该方法通过使一个网络是另一个网络的指数平均值来避免崩溃(即，对所有图像输出相同的嵌入)。</p><p id="c1ac" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，与BYOL不同的是，他们在模拟分类器上使用交叉熵作为输出之间的相似性度量，而不是内积相似性，这允许他们在softmax中设置“温度”正则化，这有助于训练稳定性。</p><p id="3f0e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这种方法最引人注目的结果是，在没有任何监督的情况下，transformer中深层的注意力图形成了令人惊讶的高性能对象分割，并且对学习表示的k-NN检索也显示了将该技术应用于图像检索的有希望的结果。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/96bee936a00500297df69c79a9517f2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hAK77WcGjWbW4Vzj7y6Brw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">资料来源:https://arxiv.org/pdf/2104.14294.pdf</p></figure><p id="6ef3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="mq">你可能也会喜欢</em> : <a class="ae lr" href="https://arxiv.org/abs/2105.04553" rel="noopener ugc nofollow" target="_blank">用Swin变形金刚进行自我监督学习</a></p><h2 id="e1ad" class="ls lt iq bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">简单的句子嵌入对比学习👾<a class="ae lr" href="https://github.com/princeton-nlp/SimCSE" rel="noopener ugc nofollow" target="_blank">代码</a></h2><p id="1222" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">由王彤宙和菲利普·伊索拉创作</p><p id="2505" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> ❓Why → </strong>在无监督的句子表征学习上取得了令人印象深刻的进步，这是一种非常简单的方法，有可能用于其他领域。</p><p id="8c6a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">💡关键见解→ </strong>在计算机视觉中，生成输入的<em class="mq">两个视图</em>就像获取图像的两种不同作物一样简单，但由于语言的离散性，这种简单的增强不能直接应用于语言，这使得对比学习有点棘手。</p><p id="394c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这项工作中，作者建议简单地将同一个句子输入到transformer encode两次，但在前馈层和注意力层中绘制不同的随机丢失。令人惊讶的是——至少对我来说——添加任何其他以前使用过的增强功能，如“删除一个单词”或“裁剪句子的一部分”,都会降低性能。类似地，添加以前研究过的目标，如“下一句预测”，也会降低性能。</p><p id="0ddf" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">虽然最令人印象深刻的结果是针对仅无监督的训练，但作者也扩展了他们的方法，通过使用正面和负面句子对分别作为正面和硬负面样本来利用标记的数据。</p><p id="01a6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">结果不仅包括标准的句子级基准，如STS⁵，还包括对表征的<em class="mq">对齐</em>和<em class="mq">一致性</em>的分析，最近被提议作为表征quality⁵.的预测代理</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/a9646ec66fa89c6d067142bd9b9da3d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6H8oxuOwI4yRCQ-KgpRQQQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae lr" href="https://arxiv.org/pdf/2104.08821.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2104.08821.pdf</a></p></figure><h2 id="b9a8" class="ls lt iq bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated"><a class="ae lr" href="https://arxiv.org/abs/2105.07407" rel="noopener ugc nofollow" target="_blank">蛋白质序列到结构的学习:这是终点(-端到端的革命)</a>？</h2><p id="c051" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated"><em class="mq">作者:埃洛蒂·莱恩、斯蒂芬·艾斯曼、阿恩·埃洛夫松和谢尔盖·格鲁丁宁</em></p><p id="3c27" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> ❓Why → </strong>几个月前，DeepMind的AlphaFold进行了一轮展示，展示了变形金刚和SSL如何跳过被称为蛋白质折叠的任务，蛋白质的3D结构仅由它们的线性氨基酸结构构建而成。我没有必要的背景来理解这到底有多有影响力，但这篇论文帮助奠定了事态的发展，并提供了关于蛋白质结构领域深度学习未来的知情意见。</p><p id="f065" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">💡关键见解→ </strong> AlphaFold 2确实走在了时代的前面，这是it计算资源的一个重要原因，它越来越成为研究的一个区分因素。这再一次将学术研究团体置于一个困难的位置，与资金雄厚的公司支持的实验室竞争。</p><p id="ece2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">结构生物学精确预测的影响在很大程度上仍然是未知的。虽然蛋白质结构的确在很大程度上决定了它的性质，但还有更多变量在起作用。从乐观的方面来看，<em class="mq">计算机模拟</em>结构蛋白预测将会以比以前更快的数量级实现一致、深刻和新颖的生物学见解；但在悲观的一端，这些不足以成功地模拟更现实的蛋白质行为，如复杂的动力学，灵活性和相互作用，这种方法只会在少数情况下有用。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/f47c52a39068fa38d65cb121afd1a462.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nICieoFIB1xUsgXMFf8x1g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:https://arxiv.org/pdf/2105.07407.pdf<a class="ae lr" href="https://arxiv.org/pdf/2105.07407.pdf" rel="noopener ugc nofollow" target="_blank"/></p></figure><h2 id="be9c" class="ls lt iq bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated"><a class="ae lr" href="https://arxiv.org/abs/2105.05233" rel="noopener ugc nofollow" target="_blank">扩散模型在图像合成上击败甘斯</a>👾<a class="ae lr" href="https://github.com/openai/guided-diffusion" rel="noopener ugc nofollow" target="_blank">代码</a></h2><p id="cc34" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">Prafulla Dhariwal和Alex Nichol </p><p id="8c92" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> ❓Why → </strong> GANs⁶自从引入以来，多年来一直是无可争议的图像生成方法。然而，在过去的几年里，越来越多的基于可能性的替代方法正在出现，以取代它们。他们会变得一样受欢迎吗？</p><p id="20fc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">💡关键见解→ </strong>一个月前，我们在ICLR强调了一篇扩散模型论文，这篇论文的主旨大部分是相似的，尽管需要额外8个月的工作来完善。扩散模型的要点如下:你可以将图像转换成“噪声”作为“扩散过程”。想想单个水分子是如何在流动的水中运动的:有一些确定性的水流遵循一个梯度，并伴随着一些额外的随机抖动。你可以对像素图像做同样的事情，<em class="mq">扩散它们</em>，这样它们最终就像一个易于处理的概率分布中的噪声。现在，这个过程实际上是可逆的，所以同样的“反向”扩散过程可以用来从噪声中生成图像。</p><p id="11e9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">作者展示了一个良好调整的模型如何在许多图像生成基准上达到SOTA，超越甘斯。然而，仍然有警告。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/76faf0501d0573ff7ef5ffc651469d5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2lmVatAfPuk2KyC3ls6Lkw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae lr" href="https://arxiv.org/pdf/2105.05233.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2105.05233.pdf</a></p></figure><p id="bd8d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有一些权衡仍然是不可避免的:<strong class="kx ir"> </strong> GANs仍然是图像生成任务中最受欢迎的技术，并且速度很快，但它们通常缺乏多样性，并且没有覆盖图像的整个领域，这使得它们更难扩展和应用到新的领域。另一方面，基于可能性的模型——如VQ-VAE、扩散模型或自回归生成——以速度和图像保真度为代价提供了更好的覆盖范围，由人类(或其他代理指标)来判断。</p><h2 id="59c3" class="ls lt iq bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated"><a class="ae lr" href="https://arxiv.org/abs/2105.07576" rel="noopener ugc nofollow" target="_blank">重新思考BatchNorm </a>中的“批处理”</h2><p id="05a0" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated"><em class="mq">吴雨欣和贾斯廷·约翰逊</em></p><p id="f399" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> ❓Why → </strong>自从batchnorm⁷被提出以来，它已经成为DL工具箱中无处不在的工具。然而，它具有不可忽视的含义，而这些含义往往被经验驱动的研究所忽视。</p><p id="c4b0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">💡关键见解→ </strong>这里有很多东西需要解开，但我要强调的是，BatchNorm并不像乍看上去那样无害。</p><p id="0931" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，BatchNorm是唯一一个对组而不是对单个输入进行操作的层，这意味着它在训练和推理过程中必然会有不同的行为。而且，BatchNorm会导致批内信息泄露。该论文给出了以下有见地的例子:设想通过具有16个不同类别的32个图像，每个类别2个图像，一致地构造训练批；该模型将通过至少“成对地”而不是单独地为每个样本生成标签来学习利用这种批量模式。在对比learning⁸.中可以观察到类似的“欺骗”现象</p><p id="7330" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">训练-测试的不一致性也无意中损害了用BatchNorm训练的模型的性能:指数移动平均(EMA)技术——最常用于估计用于推断的总体统计数据——导致有偏差的估计，损害了测试集中的性能。</p><p id="e2b8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">那么我们能从这一切中得到什么呢？您可能应该继续使用BatchNorm，并受益于它在最常见的设置下的良好工作(从训练集中提取固定大小的批处理i.i.d ),并使用从同一数据分布中提取的测试集)；但在其他情况下使用时要格外小心。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/7af8e55451b0409365c55e8067c38cef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QiKrdjlKIJcoE3GMRWOU3g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:<a class="ae lr" href="https://arxiv.org/pdf/2105.07576.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2105.07576.pdf</a></p></figure></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><p id="aa5d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的月度评选到此结束；如果你想了解最新的研究，请在Twitter上关注我们。如果你想了解更多关于ML代码、实现和库的最新进展，请查看我们的其他博客系列<a class="ae lr" rel="noopener" target="_blank" href="/best-of-ml-code-and-software-june-2021-486dcf6f461b"> <em class="mq">最佳ML工具和软件</em> </a> <em class="mq">。</em>下集再见！</p></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><p id="aa27" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="mq">参考文献:</em></p><p id="3e57" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[1] <a class="ae lr" href="https://arxiv.org/abs/2105.08050" rel="noopener ugc nofollow" target="_blank"> <em class="mq">关注MLPs</em></a><em class="mq">——</em>作者，戴子航，David R. So，Quoc V. Le，2021。</p><p id="3878" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[2] <a class="ae lr" href="https://arxiv.org/abs/2105.01883" rel="noopener ugc nofollow" target="_blank"> <em class="mq"> RepMLP:将卷积重新参数化为全连通层，用于图像识别</em></a><em class="mq"/>——丁小寒，，韩，丁桂光，2021 .</p><p id="dff2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[3] <a class="ae lr" href="https://arxiv.org/abs/2105.03404" rel="noopener ugc nofollow" target="_blank"> <em class="mq"> ResMLP:数据高效训练的图像分类前馈网络</em> </a> <em class="mq"> </em> — Hugo Touvron等2021。</p><p id="a043" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">【4】<a class="ae lr" href="https://arxiv.org/abs/2105.02723" rel="noopener ugc nofollow" target="_blank"><em class="mq">你甚至需要关注吗？一堆前馈层在ImageNet</em></a>——Luke Melas-Kyriazi，2021。</p><p id="f0e9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[5] <a class="ae lr" href="https://arxiv.org/abs/2005.10242" rel="noopener ugc nofollow" target="_blank"> <em class="mq">通过超球面上的对齐和一致理解对比表征学习</em></a><em class="mq">——</em>王彤宙和菲利普·伊索拉，2020。</p><p id="6bdd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[6] <a class="ae lr" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank"> <em class="mq">生成对抗网络</em></a>——作者Ian J. Goodfellow等人2014。</p><p id="cc5f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[7] <a class="ae lr" href="https://arxiv.org/abs/1502.03167" rel="noopener ugc nofollow" target="_blank"> <em class="mq">批量归一化:通过减少内部协变量移位加速深度网络训练</em></a><em class="mq">——</em>作者<a class="ae lr" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ioffe%2C+S" rel="noopener ugc nofollow" target="_blank">谢尔盖·约夫</a>，<a class="ae lr" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Szegedy%2C+C" rel="noopener ugc nofollow" target="_blank">克里斯蒂安·塞格迪</a></p><p id="29c5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[8] <a class="ae lr" href="https://arxiv.org/abs/1905.09272" rel="noopener ugc nofollow" target="_blank"> <em class="mq">采用对比预测编码的数据高效图像识别</em> </a> <em class="mq"> — </em>作者Oliver Henaff，2020。</p><p id="6c87" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[9]<a class="ae lr" href="https://arxiv.org/abs/2010.11934" rel="noopener ugc nofollow" target="_blank"><em class="mq">【mT5:一个大规模的多语种预训练文本到文本转换器</em></a>——由薛、诺亚康斯坦、等人2020。</p></div></div>    
</body>
</html>