<html>
<head>
<title>🥈Two-layered Recommender System Methodology: A Prize-Winning Solution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">🥈双层推荐系统方法论:一个获奖的解决方案</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/two-layered-recommender-system-methodology-a-prize-winning-solution-c4bdb815b156?source=collection_archive---------26-----------------------#2021-03-20">https://towardsdatascience.com/two-layered-recommender-system-methodology-a-prize-winning-solution-c4bdb815b156?source=collection_archive---------26-----------------------#2021-03-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="cb46" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解如何将简单的算法结合到强大的推荐引擎中</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/cbecdec875cd2e1ef52051a19ff6689d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GGEZ1YzHTUVzEXw4"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">丹尼斯·简斯在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="3020" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2020年11月14日至22日举行了一场<a class="ae kv" href="https://cinema.wechallenge.it/ru" rel="noopener ugc nofollow" target="_blank">电影挑战赛</a>黑客马拉松。它致力于为在线剧院<a class="ae kv" href="https://sweet.tv/ru" rel="noopener ugc nofollow" target="_blank"> sweet.tv </a>创造解决方案。参与者可以从三个项目中选择一个:</p><ol class=""><li id="108a" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">挑战1——电影推荐系统；</li><li id="1805" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">挑战2——电视节目推荐系统；</li><li id="d675" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">项目竞赛。</li></ol><p id="0ee5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我设法为挑战2创造了一个获奖的解决方案，并决定分享我的方法。</p><p id="b1dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">📃任务</strong></p><p id="4c12" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">任务是根据每个用户的观看历史来预测他最喜欢的5个电视节目。如果用户观看了电视节目的80%以上并且没有更换频道，则认为该电视节目被观看了。</p><p id="7d7a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用<a class="ae kv" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>确定解决方案的准确性。<a class="ae kv" href="https://www.kaggle.com/c/sweettv-tv-program-recommender/overview" rel="noopener ugc nofollow" target="_blank">在这里</a>你可以查看更详细的任务描述、数据和最终排行榜。</p><p id="827a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">给了20周的用户日志来训练我们的模型(从3月初到7月底)和一些关于电视节目的附加信息。Kaggle用了12周的时间进行公共/私人测试，用户各占一半。还有测试日期的电视节目时间表。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mg"><img src="../Images/665cf89839f91d6fa52dfae4c9ca07ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kBIwiGZ7vM9d4jHBh7ly7w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">浏览日志(<em class="mh">作者图片)</em></p></figure><p id="936e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">组织者使用<a class="ae kv" href="https://habr.com/ru/company/econtenta/blog/303458/" rel="noopener ugc nofollow" target="_blank"> MAP@5 </a> metric检查了模型的准确性，我也将其用于本地维持验证:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mi"><img src="../Images/ef26ff72876093aa299d57197e3926eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AprpvNr556HkuLZEuDZBEg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用平均精度@K绘制@ k度量图(<em class="mh">图片由作者提供)</em></p></figure><p id="5b14" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> ⚒方案</strong></p><p id="77f4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第1部分—基本算法</p><p id="dc96" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">算法1。假设——用户将继续观看相同的电视节目。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mj"><img src="../Images/532d1ee677f9fedb2818a3c068cdc3b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ElKFkWlw3Ckc5PlDwZ2chQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">算法1示例(<em class="mh">作者图片)</em></p></figure><p id="f1d0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个基线解决方案非常简单:我们需要根据观看次数计算前5名的节目:</p><ul class=""><li id="19e0" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr mk ly lz ma bi translated">如果用户一次观看了电视节目总长度的50%以上，则电视节目被视为已观看；</li><li id="c71a" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mk ly lz ma bi translated">通过将来不在电视节目中的节目过滤结果；</li><li id="15a9" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mk ly lz ma bi translated">如果用户一生中总共观看的电视节目少于5个，请在他的预测中填入最受欢迎的电视节目。</li></ul><p id="a0b7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该解决方案在保持数据上进行本地验证，Kaggle <strong class="ky ir"> MAP@5的精度= 0.41296 </strong>。</p><p id="427c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">➕简单快速的解决方案，良好的基线精度。</p><p id="aa2c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">➖算法没有考虑用户可能的偏好，也不能预测用户没有看过的电视节目。</p><p id="1c72" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">算法二。</strong>假设——用户会观看与他喜欢的电视节目相似的电视节目。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ml"><img src="../Images/e3ec833b9363a25463cc9496bdca5ad1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qEUwsz-W_TM2gCNgjsFnSg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">算法2示例(<em class="mh">图片作者)</em></p></figure><p id="a217" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">推荐任务的一个经典例子。为了解决这个问题，我创建了一个用户和电视节目的矩阵，并训练了一个协作过滤模型。然后我们只对每个用户进行前5个预测。我使用了<a class="ae kv" href="https://github.com/lyst/lightfm" rel="noopener ugc nofollow" target="_blank"> LightFM </a>来创建带有WARP metric的模型，并对维持数据进行了轻微的超参数调整。</p><p id="d172" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">➕算法基于相似用户考虑可能的用户偏好，这保证了预测不限于先前观看的节目。</p><p id="e525" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">➖精度比第一种方法稍低一些(可能有一种方法可以提高它，但是调整的时间有限)。另一个缺点是很难使用电视节目和用户参数，尽管LightFM库为其提供了功能。</p><p id="1a69" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第2部分—第二层模型</p><p id="03e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">方法论。到目前为止，我们只使用了观看电视节目的事实，所以我们需要一种使用更多参数和一些机器学习的方法。</strong></p><p id="ab25" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了解决这个问题并提高解决方案准确性，经常使用第二层模型，该模型根据查看概率对相关项目进行优先级排序。在这项任务中，我采用了以下方式:</p><ul class=""><li id="4f4e" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr mk ly lz ma bi translated">使用基本算法(来自本教程的第1部分)为每个用户生成相关的电视节目(大约200个就可以了)。前N项我们从算法1得到，因为它的准确率更高。其余M项(200 — N = M)从LigthFM的算法2中得到；</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mm"><img src="../Images/9bd206d0a413a6d2de6ce76affe7e8e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b5eVx5Iwk-fYWTmjYI-WXg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">为一个用户生成相关程序(N = 200)(<em class="mh">作者的图像)</em></p></figure><ul class=""><li id="b138" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr mk ly lz ma bi translated">收集特征来训练助推模型，更多信息在下面；</li><li id="bb41" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mk ly lz ma bi translated">训练二进制分类<a class="ae kv" href="https://lightgbm.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> LightGBM </a>模型——哪些相关的电视节目用户观看了维持数据；</li><li id="dc57" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mk ly lz ma bi translated">对于测试数据，还收集特征并使用训练模型来为每个用户区分电视节目的优先级；</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mn"><img src="../Images/61f93c61460b112198df8d985dbd5019.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5QNc9K_HgtdEf7CpuSjjjw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">基于相关节目的观看概率对其进行排序(<em class="mh">图片由作者提供)</em></p></figure><ul class=""><li id="42e6" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr mk ly lz ma bi translated">为每个用户获取前5个相关的和可能观看的项目；</li></ul><p id="ae43" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">增加二层模型精度的日志。</strong></p><p id="be0f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为基本特征，我用不同的参数记录了用户观看电视节目的次数:节目时间的30%，50%，80%。我还添加了基于观看次数的电视节目排名。导致了<strong class="ky ir"> MAP@5 = 0.43128 </strong>。</p><p id="dd67" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用频道号和节目类别(分类特征)<strong class="ky ir"> MAP@5 = 0.43302。</strong></p><p id="6c40" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">加上用户观看电视节目的频率、自用户被创建以来的时间、自最后一次观看以来的时间，得到<strong class="ky ir"> MAP@5 =0.43565。</strong></p><p id="244b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用LightFM库中的电视节目排名和user _ bias/item _ bias特征给出了<strong class="ky ir"> MAP@5 =0.43823。</strong></p><p id="4ea0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">描述电视节目时间表将如何改变(时间减少/增加)的特征给出了<strong class="ky ir"> MAP@5 =0.44075。</strong></p><p id="c0af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用<a class="ae kv" href="https://github.com/hyperopt/hyperopt" rel="noopener ugc nofollow" target="_blank"> hyperopt </a>对LightGBM模型进行超参数搜索，将精度提高到<strong class="ky ir"> MAP@5 =0.44173。</strong></p><p id="bdeb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">过滤节目，只保留那些被观看10次以上的节目，减少了数据量，去除了不相关的项目，精度提高到<strong class="ky ir"> MAP@5 =0.44203。</strong></p><p id="2beb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">就是这样！在最终的公共排行榜上，这个解决方案在决赛前一直名列第一，但在最后一天，一个团队最终战胜了我的解决方案。经过私人测试，我的解决方案停留在第二位，与第一位相差很小，与第三位相差很大，精确度<strong class="ky ir"> MAP@5 =0.42905。</strong></p><p id="df06" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">热门功能—用户观看时间、LightFM的用户功能、日程更改。</p><p id="820d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你感兴趣，这里的代码是<a class="ae kv" href="https://github.com/ndmel/2nd_place_recsys_cinema_challenge_2020" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir"/></a>。</p><p id="a8fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">🔮改进方法</strong></p><ul class=""><li id="a5c9" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr mk ly lz ma bi translated">根据观看的时间和日期对用户档案进行细分。将其与电视节目时间表相结合，进一步个性化推荐。</li><li id="f72b" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mk ly lz ma bi translated">使用更复杂的第二层模型，比如LambdaRank而不是二进制分类(LightGBM中也有)。</li><li id="ae0e" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mk ly lz ma bi translated">当新用户没有观看历史时，解决冷启动问题。我们可以找到相似的用户，并结合他们的口味来预测相关的电视节目(改进LightFM方法)。</li></ul><p id="8918" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> ⭐有趣的事实</strong></p><ul class=""><li id="9858" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr mk ly lz ma bi translated">比赛只持续了4天，所以我只能尝试基本的假设和易于实现的特性；</li><li id="512c" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mk ly lz ma bi translated">本地抵制验证与Kaggle排行榜高度相关，因此在私下测试后几乎没有任何变动。</li></ul></div></div>    
</body>
</html>