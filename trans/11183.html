<html>
<head>
<title>Overfitting and Underfitting Principles</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">过拟合和欠拟合原则</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/overfitting-and-underfitting-principles-ea8964d9c45c?source=collection_archive---------0-----------------------#2021-11-02">https://towardsdatascience.com/overfitting-and-underfitting-principles-ea8964d9c45c?source=collection_archive---------0-----------------------#2021-11-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2245" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><strong class="ak">理解欠拟合和过拟合的基本原理，以及为什么你应该使用特殊的技巧来处理它们</strong></h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/759488a7993845742014d24d5c28f2ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XObtOu0QzwYQLiU81IlBsQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">欠拟合和过拟合原则。作者图片</p></figure><p id="5d1e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">已经有很多关于过度拟合的文章，但是几乎所有的<em class="lu">都只是简单的工具列表</em>。“如何处理过度拟合——十大工具”或“防止过度拟合的最佳技术”。<em class="lu">这就像给别人看钉子却不解释怎么钉一样</em>。对于试图弄清楚过度拟合是如何工作的人来说，这可能非常令人困惑。还有，这些文章往往不考虑欠适，好像根本不存在。</p><p id="fe22" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这篇文章中，我想列出提高模型质量的<strong class="la iu">基本原则</strong>(确切地说是<em class="lu">原则</em>),并相应地防止特定示例的欠拟合和过拟合。这是一个非常普遍的问题，可以适用于所有的算法和模型，所以很难完全描述它。但是我想试着给你一个<em class="lu">理解</em>为什么会出现欠拟合和过拟合，以及为什么要使用一种或另一种特定的技术。</p><h1 id="14b3" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">欠拟合和过拟合以及偏差/方差权衡</h1><p id="33b4" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">虽然我没有在这里描述你需要知道的所有概念(例如，<em class="lu">质量度量</em>或者<em class="lu">交叉验证</em>，但是我认为向你解释(或者只是提醒你)什么是欠拟合/过拟合是很重要的。</p><p id="bd33" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了弄清楚这一点，让我们创建一些数据集，将其分为训练集和测试集，然后在其上训练三个模型——简单、良好和复杂(我不会在这个示例中使用验证集来简化它，但我将在稍后讲述它)。所有代码都可以在这个<a class="ae ms" href="https://gitlab.com/Winston-90/underfitting_vs_overfitting" rel="noopener ugc nofollow" target="_blank"> GitLab repo </a>中找到。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/7eda546ed01620eded3af3032fe9e8e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*H1WaXRPgMN_huEg4rY8H6A.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">生成的数据集。作者图片</p></figure><p id="9e29" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">欠拟合</strong>是指你的模型对于你的数据来说<strong class="la iu">过于简单</strong>的情况。更正式地说，你关于数据分布的假设是错误的，过于简单——比如你的数据是二次的，你的模型是线性的。这种情况也叫<strong class="la iu">高偏</strong>。这意味着您的算法可以进行准确的预测，但最初对数据的假设是不正确的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/653113594370f6ebfd80931a81b14f02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*2lH2YCBteTcsNfb2M7wU-A.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">不合身。基于立方数据训练的线性模型。作者图片</p></figure><p id="adb0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">相反，<strong class="la iu">过度拟合</strong>是当你的模型对于你的数据来说<strong class="la iu">太复杂</strong>的情况。更正式地说，你关于数据分布的假设是错误的，太复杂了——比如你的数据是线性的，你的模型是高次多项式。这种情况也被称为<strong class="la iu">高方差</strong>。这意味着您的算法无法进行准确的预测——输入数据变化很小，模型输出变化很大。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/66cc1f3f064b670984b6b8d4162be941.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*4c9jedXxoc6Y-urqh4k-SQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">过度拟合。基于立方数据训练的13次多项式模型。作者图片</p></figure><p id="0ee0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是同一个问题的两个极端，最优解总是在中间的某个地方。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/a536985ca495d921d85a606126b9fe65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*RgzD6hDLY2esO5EGV4ZpyQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">好模式。基于立方数据训练的立方模型。作者图片</p></figure><p id="0375" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我不会过多谈论偏差/方差权衡(您可以阅读本文中的基础知识<a class="ae ms" rel="noopener" target="_blank" href="/understanding-the-bias-variance-tradeoff-165e6942b229">，但让我简单地提一下可能的选项:</a></p><ul class=""><li id="b0bc" class="mu mv it la b lb lc le lf lh mw ll mx lp my lt mz na nb nc bi translated">低偏差、低方差——这是一个很好的结果，恰到好处。</li><li id="d0b6" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">低偏差、<strong class="la iu">高方差</strong> — <strong class="la iu">过度拟合</strong> —算法对相似数据输出非常不同的预测。</li><li id="467c" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><strong class="la iu">高偏差</strong>，低方差— <strong class="la iu">欠拟合</strong> —算法对相似数据输出相似预测，但预测是错误的(算法“未命中”)。</li><li id="3b26" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">高偏差、高方差——非常糟糕的算法。你很可能永远看不到这个。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/5127fe8b0398480cc62f99bf5f15a2c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*idzNMBgNIPLF_njyOg4VUw.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">四幅图上的偏差和方差选项。作者图片</p></figure><p id="cd4f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所有这些情况都可以放在同一个地块上。这是一个有点不如前一个清晰，但更紧凑。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/c59af4ecd938d923df15baaf078c92bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*Rvbk-AyHq0YCfWzeawgatQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一个图上的偏差和方差选项。作者图片</p></figure><h2 id="84aa" class="nk lw it bd lx nl nm dn mb nn no dp mf lh np nq mh ll nr ns mj lp nt nu ml nv bi translated">如何检测欠拟合和过拟合</h2><p id="c6ec" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">在我们进入工具之前，让我们了解如何“诊断”欠拟合和过拟合。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/a3549b946594e7a3e597da3e6ac80f07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4f2R4EpXYUUY8rfKH888RQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">训练/测试错误和欠拟合/过拟合。作者图片</p></figure><p id="7328" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">拟合不足</strong>意味着你的模型做出了准确但最初不正确的预测。在这种情况下，<strong class="la iu">训练误差大</strong>和<strong class="la iu"> val/test误差也大</strong>。</p><p id="2c0d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">过度拟合意味着你的模型预测不准确。在这种情况下，<strong class="la iu">训练误差很小</strong>而<strong class="la iu"> val/test误差很大</strong>。</p><p id="ff01" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当你找到一个<strong class="la iu">好的模型</strong>，<strong class="la iu">训练误差小</strong>(但比过拟合的情况下大)，并且<strong class="la iu"> val/test误差也小</strong>。</p><p id="9730" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在上述情况下，测试误差和验证误差大致相同。当一切正常，并且您的<em class="lu">训练、验证和测试数据具有相同的分布</em>时，就会发生这种情况。如果验证和测试误差非常不同，那么您需要获得更多类似于测试数据的数据，并确保您正确地分割数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/33043304c45304db4232aef1efe6bbd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EqjPJebq38w9pBdXH54KGw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">如何检测欠拟合和过拟合？作者图片</p></figure><h1 id="f9a1" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">工具和技术</h1><p id="870b" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">现在让我们看看防止欠拟合和过拟合的技术，确切地考虑一下<em class="lu">为什么我们应该使用它们</em>。</p><h2 id="31ec" class="nk lw it bd lx nl nm dn mb nn no dp mf lh np nq mh ll nr ns mj lp nt nu ml nv bi translated">你应该记住一般直觉</h2><p id="44e4" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">我们记得:</p><ul class=""><li id="4735" class="mu mv it la b lb lc le lf lh mw ll mx lp my lt mz na nb nc bi translated"><strong class="la iu">当你的模型对你的数据来说<strong class="la iu">太简单</strong>时，就会出现</strong>欠拟合。</li><li id="3546" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><strong class="la iu">过度拟合</strong>发生在你的模型<strong class="la iu">对你的数据</strong>太复杂的时候。</li></ul><p id="c438" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">基于此，你应该记住的简单直觉是:</p><ul class=""><li id="c0ec" class="mu mv it la b lb lc le lf lh mw ll mx lp my lt mz na nb nc bi translated">要修复<strong class="la iu">欠拟合</strong>，你应该<strong class="la iu">将</strong>模型复杂化。</li><li id="e836" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">为了修正<strong class="la iu">过拟合</strong>，你应该<strong class="la iu">简化</strong>模型。</li></ul><p id="4011" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">事实上，下面将要列出的一切只是这个简单规则的结果。我将试图说明为什么某些行为会使模型变得复杂或简化。</p><h2 id="3990" class="nk lw it bd lx nl nm dn mb nn no dp mf lh np nq mh ll nr ns mj lp nt nu ml nv bi translated">更简单/复杂的模型</h2><p id="7a28" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">基于上述直觉想到的最简单的方法是尝试更简单或更复杂的算法(模型)。</p><p id="ee52" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了使模型变得复杂，你需要添加更多的参数(<em class="lu">自由度</em>)。有时这意味着直接尝试更强大的模型——一种先验地能够恢复更复杂的依赖性的模型(具有不同内核的<em class="lu"> SVM，而不是逻辑回归</em>)。<strong class="la iu">如果算法已经相当复杂</strong>(神经网络或者某种集成模型)<strong class="la iu">你需要给它增加更多的参数</strong>，比如增加boosting中的模型数量。在神经网络的上下文中，这意味着添加更多的层/每层中更多的神经元/层之间更多的连接CNN更多的过滤器，等等。</p><p id="6f05" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了简化模型，你需要反过来减少参数的数量。要么彻底改变算法(<em class="lu">尝试随机森林代替深度神经网络</em>)，要么减少自由度。更少的层，更少的神经元，等等。</p><h2 id="e493" class="nk lw it bd lx nl nm dn mb nn no dp mf lh np nq mh ll nr ns mj lp nt nu ml nv bi translated">更多正规化/更少正规化</h2><p id="b097" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">这一点与前一点非常相关。实际上，<strong class="la iu">正则化是对模型</strong>的间接强制简化。正则项要求模型保持参数值尽可能小，因此要求模型尽可能简单。具有强正则化的复杂模型通常比最初的简单模型表现得更好，因此这是一个非常强大的工具。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/48bfe354a73d8fa6bafeac800ab0d42c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RGfqm4-v-2YCduRsQqNV8w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">正则化的好模型和复杂模型。作者图片</p></figure><p id="ca76" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">更多的正则化(简化模型)意味着增加正则化项的影响。这一过程是严格的个体化过程——取决于算法，正则化参数是不同的(例如，<strong class="la iu">为了减少正则化，岭回归的α应该减少，而SVM的C——增加</strong>)。所以你要研究算法的参数，注意在特定情况下是应该增加还是减少。有很多这样的参数——线性回归的L1/L2系数，SVM的C和gamma，决策树的最大树深度，等等。在神经网络中，主要的正则化方法有:</p><ul class=""><li id="e4d8" class="mu mv it la b lb lc le lf lh mw ll mx lp my lt mz na nb nc bi translated">提前停车，</li><li id="d5e8" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">辍学，</li><li id="f847" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">L1和L2正规化。</li></ul><p id="9f92" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以在这篇文章中读到它们<a class="ae ms" href="https://medium.com/@ODSC/classic-regularization-techniques-in-neural-networks-68bccee03764" rel="noopener">。</a></p><p id="5bd5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">相反，在模型需要复杂的情况下，你应该减少正则项的影响或者完全放弃正则化，看看会发生什么。</p><h2 id="ccf7" class="nk lw it bd lx nl nm dn mb nn no dp mf lh np nq mh ll nr ns mj lp nt nu ml nv bi translated">更多功能/更少功能</h2><p id="def6" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">这可能不那么明显，但是添加新功能也会使模型变得复杂。在<em class="lu">多项式回归</em>的背景下考虑这个问题-向数据集添加二次要素允许线性模型恢复二次数据。</p><p id="bb70" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">添加新的“自然”特性</em>(如果你可以这样称呼的话)——获取现有数据的新特性很少使用，主要是因为它非常昂贵且耗时较长。但是你要记住，有时候这是有帮助的。</p><p id="2aa7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是从现有特征中人工获得附加特征(所谓的<em class="lu">特征工程</em>)经常用于经典的机器学习模型。这种转变的例子数不胜数，但以下是主要的几个:</p><ul class=""><li id="ac75" class="mu mv it la b lb lc le lf lh mw ll mx lp my lt mz na nb nc bi translated">多项式特征—从<em class="lu"> x </em> ₁ <em class="lu">，x </em> ₂到<em class="lu"> x </em> ₁ <em class="lu">，x </em> ₂ <em class="lu">，x </em> ₁ <em class="lu"> x </em> ₂ <em class="lu">，x </em> ₁ <em class="lu">，x </em> ₂ <em class="lu">，… </em> ( <code class="fe nz oa ob oc b">sklearn.preprocessing.PolynomialFeatures</code>类)</li><li id="c864" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">log(x)，用于非正态分布的数据</li><li id="5202" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">ln(|x| + 1)用于右尾粗的数据</li><li id="7c61" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">范畴特征的转换</li><li id="18bc" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">其他非线性数据转换(从长度和宽度到面积(长度*宽度))等等。</li></ul><p id="6697" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您需要简化模型，那么您应该使用较少数量的特征。首先，删除您之前添加的所有附加功能。但结果可能是，在原始数据集中，有些要素不包含有用的信息，有时还会引发问题。如果一些特征是相关的，线性模型通常工作得更差。在这种情况下，你需要使用<em class="lu">特征选择</em>方法来选择那些携带最大量有用信息的特征。</p><p id="ef0d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">值得一提的是，在神经网络的背景下，<em class="lu">特征工程</em>和<em class="lu">特征选择</em>几乎毫无意义，因为<strong class="la iu">网络在数据本身</strong>中找到依赖性。这其实也是为什么深度神经网络可以还原如此复杂的依赖关系。</p><h2 id="03d7" class="nk lw it bd lx nl nm dn mb nn no dp mf lh np nq mh ll nr ns mj lp nt nu ml nv bi translated">为什么获取更多数据有时没有帮助</h2><p id="eb31" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">对抗过度拟合的技术之一是获取更多的数据。然而，令人惊讶的是，这并不总是有用的。让我们生成一个类似的10倍大的数据集，并在其上训练相同的模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/12ba7a1d1f8e31b23a2dad5d6e566576.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l3v0Tv9hxFvLyDqERgWIEQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">为什么获取更多的数据有时没有帮助。作者图片</p></figure><p id="7306" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一个非常简单的模型(1级)一直保持简单，几乎没有什么变化。因此<strong class="la iu">获得更多的数据在</strong>不足的情况下没有帮助。</p><p id="7802" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是复杂模型(13度)已经变好了。它仍然比最初的好模型(3级)差，但比原来的好得多。为什么会这样？</p><p id="dd9f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上次(对于初始数据集)，在14个数据点上训练模型(<em class="lu"> 20(初始数据集大小)* 0.7(训练比)= 14 </em>)。一个13次多项式可以完美匹配这些数据(以此类推，我们可以通过2个点画一条理想直线(次数=1)，通过3个点画一条理想抛物线(次数=2)，以此类推)。通过获得10倍多的数据，我们的训练集的大小现在是140个数据点。为了完美匹配这些数据，我们需要一个139次多项式！</p><p id="8362" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">注意，如果我们最初训练了一个<em class="lu">非常复杂的模型</em>(例如，150次多项式)，这样的数据增加不会有帮助。所以获取更多的数据是提高模型质量的好方法，但是如果模型非常非常复杂的话可能就没什么帮助了。</p><p id="2078" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，结论是——<strong class="la iu">获得更多的数据只能有助于过度拟合(而不是欠拟合)，并且如果你的模型不是太复杂</strong>。</p><p id="f755" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在计算机视觉的背景下，获得更多数据也可以意味着<a class="ae ms" href="https://en.wikipedia.org/wiki/Data_augmentation" rel="noopener ugc nofollow" target="_blank"> <em class="lu">数据扩充</em> </a>。</p><h1 id="211e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">摘要</h1><p id="beba" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">让我们用一个表来总结所有的事情。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/05a8a48aac3bffccf40ad7c986e09605.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D_BYes9MMdkxyVFSnG2fAw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">对抗欠适和过适的技巧。作者图片</p></figure><p id="13f7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">好吧，两个更好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/1c36626c35ff0938e92a2f914d241b5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9DtauyXaQFAOi31Pp1XQUg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">应对欠适和过适的技巧(扩展版)。作者图片</p></figure><p id="675d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一些工具和技术在本文中没有涉及。例如，我认为<strong class="la iu">数据清理</strong>和<strong class="la iu">交叉验证</strong>或<strong class="la iu">保持验证</strong>是任何机器学习项目中的常见做法，但它们也可以被视为对抗过度拟合的工具。</p><p id="686a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可能会注意到，为了消除欠拟合或过拟合，你需要应用<strong class="la iu">完全相反的动作</strong>。因此，如果您最初“误诊”了您的模型，您可能会花费大量的时间和金钱在无意义的工作上(例如，当实际上您需要将模型复杂化时，获取新的数据)。这就是它如此重要的原因——数小时的分析可以节省您数天甚至数周的工作时间。</p><p id="1b0f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">除了通常的模型质量分析(训练/测试错误)，还有许多技术可以准确理解需要做什么来改进模型(<a class="ae ms" href="https://www.analyticsvidhya.com/blog/2021/08/a-quick-guide-to-error-analysis-for-machine-learning-classification-models/" rel="noopener ugc nofollow" target="_blank">错误分析</a>、<a class="ae ms" href="https://www.coursera.org/lecture/machine-learning/ceiling-analysis-what-part-of-the-pipeline-to-work-on-next-LrJbq" rel="noopener ugc nofollow" target="_blank">上限分析</a>等)。).不幸的是，这些主题超出了本文的范围。</p><p id="4e2f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是，所有这些程序都有一个目的，就是了解往哪里搬，需要注意什么。我希望这篇文章能帮助你理解欠适和过适的基本原则，并激励你去了解更多。</p></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><p id="a9ea" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我之前所说，本教程中使用的所有代码都可以在<a class="ae ms" href="https://gitlab.com/Winston-90/underfitting_vs_overfitting" rel="noopener ugc nofollow" target="_blank"> GitLab </a>上获得。</p><div class="om on gp gr oo op"><a href="https://gitlab.com/Winston-90/underfitting_vs_overfitting" rel="noopener  ugc nofollow" target="_blank"><div class="oq ab fo"><div class="or ab os cl cj ot"><h2 class="bd iu gy z fp ou fr fs ov fu fw is bi translated">Dmytro Nikolaiev /欠拟合_ vs _过拟合</h2><div class="ow l"><h3 class="bd b gy z fp ou fr fs ov fu fw dk translated">过拟合和欠拟合原则。理解适配不足和适配过度的基本原则，以及为什么你应该…</h3></div><div class="ox l"><p class="bd b dl z fp ou fr fs ov fu fw dk translated">gitlab.com</p></div></div><div class="oy l"><div class="oz l pa pb pc oy pd ks op"/></div></div></a></div></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><h1 id="d1bf" class="lv lw it bd lx ly pe ma mb mc pf me mf jz pg ka mh kc ph kd mj kf pi kg ml mm bi translated">感谢您的阅读！</h1><ul class=""><li id="cdcc" class="mu mv it la b lb mn le mo lh pj ll pk lp pl lt mz na nb nc bi translated">我希望这些材料对你有用。<a class="ae ms" href="https://medium.com/@andimid" rel="noopener">在Medium </a>上关注我，获取更多这样的文章。</li><li id="a5a4" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">如果您有任何问题或意见，我将很高兴得到任何反馈。在评论里问我，或者通过<a class="ae ms" href="https://www.linkedin.com/in/andimid/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或者<a class="ae ms" href="https://twitter.com/dimid_ml" rel="noopener ugc nofollow" target="_blank"> Twitter </a>联系。</li><li id="31ce" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">为了支持我作为一个作家，并获得数以千计的其他媒体文章，使用<a class="ae ms" href="https://medium.com/@andimid/membership" rel="noopener">我的推荐链接</a>获得媒体会员资格(不收取额外费用)。</li></ul></div></div>    
</body>
</html>