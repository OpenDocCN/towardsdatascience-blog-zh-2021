<html>
<head>
<title>Imbalanced Data — Oversampling Using Gaussian Mixture Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不平衡数据—使用高斯混合模型进行过采样</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/imbalanced-data-oversampling-using-gaussian-mixture-models-dfb5b8dd5825?source=collection_archive---------23-----------------------#2021-06-06">https://towardsdatascience.com/imbalanced-data-oversampling-using-gaussian-mixture-models-dfb5b8dd5825?source=collection_archive---------23-----------------------#2021-06-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="de8d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">其他创成式模型也可以类似地用于过采样</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/54d4c93b2d176e45ee0f1b555e78d8d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SP5yLCORKXtjB0fPdYzbHA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5029714" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a></p></figure><p id="4cda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">TL；DR </strong> —从高斯混合模型(GMM)或其他生成模型中提取样本，是另一种创造性的过采样技术，可能优于SMOTE变体。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="866a" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">目录</h2><ul class=""><li id="5add" class="mv mw it lb b lc mx lf my li mz lm na lq nb lu nc nd ne nf bi translated">介绍</li><li id="1565" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">数据集准备</li><li id="e262" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">GMM介绍</li><li id="a217" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">使用GMM作为过采样技术</li><li id="3cea" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">绩效指标的评估</li><li id="54d9" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">结论</li></ul></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="9e01" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">介绍</h2><p id="73a9" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">在<a class="ae ky" rel="noopener" target="_blank" href="/imbalanced-data-oversampling-using-genetic-crossover-operators-bb581150a9a8">之前的文章</a>中，我讨论了一个人如何想出许多能够胜过SMOTE变体的创造性过采样技术。我们看到了使用“交叉”的过采样如何优于SMOTE变体。</p><p id="a0ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将展示如何使用<strong class="lb iu">高斯混合模型(GMM) </strong>或生成模型对<strong class="lb iu">不平衡数据集</strong>中的少数类实例进行过采样。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="fecb" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">数据集准备</h2><p id="d8c2" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">我们首先使用scikit-learn的make_classification函数生成一个包含两个类的5000个数据点的图像分类数据集(二元分类)。有95%的可能性目标是0，有5%的可能性目标是1。我们准备了一个类似于<a class="ae ky" rel="noopener" target="_blank" href="/imbalanced-data-oversampling-using-genetic-crossover-operators-bb581150a9a8">上一篇文章</a>的数据集。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="58b0" class="mc md it np b gy nt nu l nv nw">from sklearn.datasets import make_classification<br/>import seaborn as sns</span><span id="6dce" class="mc md it np b gy nx nu l nv nw">X, y = make_classification(<br/>    n_samples=5000, n_classes=2, <br/>    weights=[0.95, 0.05], flip_y=0<br/>)</span><span id="eb07" class="mc md it np b gy nx nu l nv nw">sns.countplot(y)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/4582ce1a8b115be554e5b4577ab6b5af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Lj5ncl62nt5j_a5C.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">为练习生成的不平衡数据集(图片由作者提供)</p></figure><p id="1fbe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">默认情况下会创建20个特征，下面是我们的X数组中的一个示例条目。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/d6cb33f60e5ad5a149cc93897cf25662.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SHdNBJnkhokr1w6c.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用scikit-learn的make_classification创建的包含20个特征的示例条目(图片由作者提供)</p></figure><p id="b186" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们将数据分成训练和测试数据集。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="64da" class="mc md it np b gy nt nu l nv nw">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y)</span></pre></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="8121" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">高斯混合模型介绍(GMM)</h2><p id="1e73" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">高斯混合模型(GMM)假设数据来自多个正态分布的子群体。</p><p id="2e9c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">示例:</strong>假设我们有一万个人的身高数据。下面是一个样本分布。看起来不像钟形正态分布。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/883ff69e14578421857a352b6c1fe428.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*4qkC32vziiAAe2qTBf9seg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">万人身高的概率分布(图片由作者提供)</p></figure><p id="df2a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，它实际上来自正态分布的平均身高不同的4个不同人群。一组的平均身高为150厘米，其他组的平均身高分别为160、170和180厘米。</p><p id="9360" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是用于生成图表的代码。您可以看到4个不同的组，我们分别从中生成4000、1000、1000和4000个样本数据，总共10，000个样本个体。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="8623" class="mc md it np b gy nt nu l nv nw">samples_150 = ss.norm(150, 10).rvs(4000)<br/>samples_160 = ss.norm(160, 10).rvs(1000)<br/>samples_170 = ss.norm(170, 10).rvs(1000)<br/>samples_180 = ss.norm(180, 10).rvs(4000)</span><span id="6543" class="mc md it np b gy nx nu l nv nw">samples_total = np.hstack([samples_150, samples_160,<br/>                          samples_170, samples_180])</span><span id="6b81" class="mc md it np b gy nx nu l nv nw">plt.figure(figsize=(10, 5))<br/>ax = sns.distplot(samples_total)<br/>ax.set_xlabel("Height (in cm)")<br/>plt.show()</span></pre><p id="4174" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">各组身高呈正态分布。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="d8f3" class="mc md it np b gy nt nu l nv nw">plt.figure(figsize=(10, 5))<br/>ax = sns.distplot(samples_150)<br/>ax.set_xlabel("Height (in cm)")<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/a4dabdb0b80ef7577ac232b89ed33a5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*IZ1ulnowGFVY63QX3wwoIQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">显示平均身高150 cm的群体如何正态分布的示例(图片由作者提供)</p></figure><p id="bc70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GMM背后的想法是，一个数据集可能有来自不同子群体的观察值，这些子群体有自己的特征。GMM帮助从数据中提取子群体，这样每个子群体就形成了一个我们可以使用的集群。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="dff8" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">使用GMM作为过采样技术</h2><p id="a88b" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">如果我们回到在“数据集准备”一节中生成的分类数据集，我们可以尝试从数据中提取子群体/聚类。让我们以提取5个集群为例。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="40c9" class="mc md it np b gy nt nu l nv nw">gmm = GaussianMixture(5)<br/>gmm.fit(X_train)</span></pre><p id="0f58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就是这样！</p><p id="c176" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在引擎盖下，我们的GMM模型现在已经创建了5个不同的聚类，它们具有不同的正态分布，反映了每个聚类可以采用的特征值。</p><p id="5a82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面的示例显示了20个特征中每个特征的聚类平均值。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="c35c" class="mc md it np b gy nt nu l nv nw">pd.DataFrame(gmm.means_.T)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/7147b13534fa579728b9a5352212d456.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*G8k0U63pgecSpbgnWxAUhQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">例如，我们可以看到，对于特征1，聚类0的平均值为-0.159613(图片由作者提供)</p></figure><p id="6e14" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更重要的是，GMM模型可以帮助我们实现两个功能:</p><p id="0774" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">1-它可以查看特定样本的特征值，并将该样本分配给一个聚类。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="90cc" class="mc md it np b gy nt nu l nv nw">gmm.predict(X_test)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/f2c334cd9f1f210d2b609404491c0087.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*qdDdz8j3WdXdvls8YVF6Zw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">示例预测显示X_test中的前3个样本分别属于聚类0、2和4(图片由作者提供)</p></figure><p id="500a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2-它可以使用拟合的正态分布来<strong class="lb iu">生成新的样本</strong>，我们可以将其用于<strong class="lb iu">过采样</strong>。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="6cb4" class="mc md it np b gy nt nu l nv nw">gmm.sample(5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/a524af1d9f6f3632adf9309665b6e14e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g4YYqDL5gumkqFPUdE_jAA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">生成了具有特征值的5个样本，即X，它们分别属于聚类0、1、2、2和2(图片由作者提供)</p></figure><p id="ba95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，在本例中，我们将数据聚类到5个不同的桶中，但我们的问题是一个二元分类问题，其中我们的目标变量可以是0或1。</p><p id="01d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个想法是检查每个聚类和目标(y)变量之间的关系。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="efcf" class="mc md it np b gy nt nu l nv nw">cluster_mean = pd.DataFrame(data={<br/>    "Cluster": gmm.predict(X_train), <br/>    "Mean Target Variable (y)": y_train<br/>}).groupby("Cluster").mean().reset_index(drop=False)</span><span id="d148" class="mc md it np b gy nx nu l nv nw">plt.figure(figsize=(10, 5))<br/>sns.barplot(data=cluster_mean, x="Cluster", <br/>     y="Mean Target Variable (y)")<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/22c7e42fdee9c45c69ddb71dfa25535d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*As_QimDiP8ZOjyH7Y99jBw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">聚类4与一个积极的目标变量有最强的关联(图片由作者提供)</p></figure><p id="a2c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到<strong class="lb iu">集群4 </strong>的目标值平均值最高，略高于40%。</p><blockquote class="og oh oi"><p id="1849" class="kz la oj lb b lc ld ju le lf lg jx lh ok lj lk ll ol ln lo lp om lr ls lt lu im bi translated">请记住，这是一个不平衡的数据集，其中只有5%的样本的目标变量(y)值= 1，因此40%是一个很大的数字。</p></blockquote><p id="096a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后一步是从GMM模型中生成随机样本，并且只保留属于聚类4的样本。我们可以用一个正的目标变量(y=1)来标记它们。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="4b32" class="mc md it np b gy nt nu l nv nw">samples, clusters = gmm.sample(100)<br/>samples_to_keep = samples[clusters==4]</span></pre><p id="875f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们终于可以将它们添加到我们的训练数据中了！</p><p id="16fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们同样可以从与y=1关联最强的前2–3个集群中抽取样本。或者我们可以从y的平均值高于预定义阈值的任何集群中抽取样本。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="1f11" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">绩效指标的评估</h2><p id="2687" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">测试这种过采样技术的性能时，我们将使用下面的函数，该函数总结了我们讨论的所有步骤。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="6a82" class="mc md it np b gy nt nu l nv nw">def oversample_gmm(X, y, rows_1, no_clusters=2, <br/>                   no_sampling_clusters=1, rs=1):<br/>    # Instantiate GMM model<br/>    gmm = GaussianMixture(<br/>        no_clusters,<br/>        covariance_type='tied', <br/>        max_iter=10000,<br/>        random_state=rs<br/>    )<br/>    gmm.fit(X)<br/>    <br/>    # Finding cluster with y=1 most likely<br/>    cluster_mean = pd.DataFrame(data={<br/>        "Cluster": gmm.predict(X_train), <br/>        "Mean Target Variable (y)": y_train<br/>        }).groupby("Cluster").mean().sort_values(<br/>        by='Mean Target Variable (y)', ascending=False)</span><span id="6b1c" class="mc md it np b gy nx nu l nv nw">top_clusters = cluster_mean.sort_values(<br/>        by='Mean Target Variable (y)', ascending=False).index[<br/>        :no_sampling_clusters]<br/>    <br/>    # Number of rows we will generate before<br/>    # filtering by required cluster.<br/>    # Multiply by 5 to ensure we have sufficient samples<br/>    rows_initial = rows_1 * no_clusters * 5<br/>    <br/>    # Generate samples<br/>    samples, clusters = gmm.sample(rows_initial)</span><span id="cab1" class="mc md it np b gy nx nu l nv nw"># Keep samples coming from clusters where y=1 is likely<br/>    top_clusters_filter = [np.any([<br/>        cluster == x for x in top_clusters]<br/>        ) for cluster in clusters]<br/>    samples_to_keep = samples[top_clusters_filter]<br/>    <br/>    # Keep only required number of additional samples<br/>    rows_required = rows_1 - np.sum(y)<br/>    np.random.shuffle(samples_to_keep)<br/>    samples_to_keep = samples_to_keep[:rows_required]<br/>    <br/>    # Add samples to training dataset<br/>    X_gmm = np.vstack([X, samples_to_keep])<br/>    y_gmm = np.hstack([y, np.ones(samples_to_keep.shape[0])])<br/>    <br/>    return X_gmm, y_gmm</span></pre><p id="66a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与我们的<a class="ae ky" rel="noopener" target="_blank" href="/imbalanced-data-oversampling-using-genetic-crossover-operators-bb581150a9a8">上一篇文章</a>类似，我们遍历了30个随机状态，并比较了随机森林分类器在原始数据集和过采样方法上的性能，确保我们有2000个具有正目标值(target = 1)的训练样本:</p><ul class=""><li id="f426" class="mv mw it lb b lc ld lf lg li on lm oo lq op lu nc nd ne nf bi translated">随机过采样</li><li id="c5f5" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">SMOTE — 1个邻居</li><li id="64c9" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">SMOTE — 3个邻居</li><li id="1ee3" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">SMOTE — 5个邻居</li><li id="93f4" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">SMOTE — 10个邻居</li><li id="fe6c" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">GMM — 2</li><li id="f41b" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">GMM — 3</li><li id="ccfb" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">GMM — 5</li><li id="e4d9" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">GMM — 10</li><li id="2cab" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">GMM——15人</li></ul><p id="5391" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还研究了7个<strong class="lb iu">分类指标</strong>:</p><ul class=""><li id="a05b" class="mv mw it lb b lc ld lf lg li on lm oo lq op lu nc nd ne nf bi translated">ROC AUC—ROC曲线下的面积</li><li id="51ca" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">PR AUC——精确召回曲线下的面积</li><li id="bd2b" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">平衡的准确性—这也相当于两个标签的宏观平均召回率</li><li id="7bd8" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">最大F1 —不同概率临界值的最大F1分数(即，如果我们在预测概率&gt; 0.2或0.3时预测1，等等。而不是默认的0.5)</li><li id="bd16" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">回忆</li><li id="7d31" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">精确</li><li id="9a55" class="mv mw it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">F1分数</li></ul><p id="2a7e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是结果…</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/affbb0bf2bb14ceccedb75cd38ee71df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eOO5K_nvI0h5EYWOLmcdyQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">SMOTE在ROC AUC上领先(查看中位数)，但PR AUC更适合不平衡数据集(图片由作者提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/e9432ace907159f707006ed7d50e1632.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QXEFXB3DAGFoxIDbpETQgg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">GMM在PR AUC上领先10或15，这是不平衡数据集的良好指标(图片由作者提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/003f5d7d7ce60d7768646a74a6734d13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cKTZS_t5STXYCCwPswuOcg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">具有10个和15个簇的GMM在Max F1上也表现非常好，但是随机过采样稍有优势(图片由作者提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/53451d89f232e136e9388e090a1ac3b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lUW8GjaWfNpplhMsMsrwPA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">拥有两个集群的GMM在平衡准确性方面领先(图片由作者提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/72a235fbcb289fe727303ebd4107e875.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QyIlc_SAmlv3fzP2bv1_5Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">GMM在回忆方面领先2或3个集群(图片由作者提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/9e572208388d650d0e243db9faefe7f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JIXc7h2MovLBWgr6VlCk1g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">原始数据集和具有10个聚类的GMM在精度指标上领先(图片由作者提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/938ef5965f9b2914dfb4b86c9490475d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DsfDnwPF3kx7vExk5Qff3g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">具有5个以上聚类的GMM具有最高的F1分数(图片由作者提供)</p></figure><p id="5593" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当然，结果有好有坏。</p><p id="653f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当查看与不平衡数据集最相关的指标时，具有10个聚类的GMM是最佳选择:精度-召回曲线、F1得分和最大F1(F1的替代方案，其中我们考虑所有概率阈值)。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="8753" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">结论</h2><p id="f53d" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">我们已经展示了另一种用于不平衡数据集的创新而简单的过采样技术如何在几个指标上优于SMOTE和随机过采样等默认技术。</p><p id="b613" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样基于GMM的方法也可用于生成合成数据样本，以调整您的预测模型。这在预期会有大量模型/数据漂移并且交叉验证结果会产生误导的用例中尤其有用。</p><p id="1cc1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一个在后续文章中讨论的话题…</p></div></div>    
</body>
</html>