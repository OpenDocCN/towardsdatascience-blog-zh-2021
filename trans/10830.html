<html>
<head>
<title>Tuning the Hyperparameters of your Machine Learning Model using GridSearchCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用GridSearchCV调整机器学习模型的超参数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tuning-the-hyperparameters-of-your-machine-learning-model-using-gridsearchcv-7fc2bb76ff27?source=collection_archive---------1-----------------------#2021-10-20">https://towardsdatascience.com/tuning-the-hyperparameters-of-your-machine-learning-model-using-gridsearchcv-7fc2bb76ff27?source=collection_archive---------1-----------------------#2021-10-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c993" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何使用sklearn中的GridSearchCV函数来优化您的机器学习模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2ef5c7343b32c60f3678053693fe4db2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6M4bP8J4Fsychqkr"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">罗伯塔·索奇在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="4790" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">机器学习的两个关键挑战是找到正确的算法和优化你的模型。如果你熟悉机器学习，你可能用过线性回归、逻辑回归、决策树、支持向量机等算法。一旦您决定为您的机器学习模型使用特定的算法，下一个挑战就是如何微调您的模型的超参数，以便您的模型与您拥有的数据集很好地配合。在本文中，我想把重点放在后一部分——微调模型的超参数。尽管这个术语听起来可能很复杂，但是使用<strong class="lb iu"> sklearn </strong>模块中的<strong class="lb iu"> GridSearchCV </strong>函数可以非常容易地微调您的超参数。</p><h1 id="3552" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">使用逻辑回归进行分类</h1><p id="6f4b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在你学习如何微调你的机器学习模型的超参数之前，让我们尝试使用sklearn附带的经典<strong class="lb iu">乳腺癌</strong>数据集来建立一个模型。由于这是一个分类问题，我们将使用逻辑回归作为例子。</p><blockquote class="ms mt mu"><p id="fe1c" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated">对于分类问题，您还可以使用其他算法，如支持向量机(SVM)、K近邻(KNN)、朴素贝叶斯等。但是对于本文，我将使用逻辑回归。</p></blockquote><p id="e7e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们加载数据集，并将其加载到Pandas数据框架中:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="3a63" class="ne lw it na b gy nf ng l nh ni">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>from sklearn.datasets import load_breast_cancer</span><span id="77aa" class="ne lw it na b gy nj ng l nh ni">bc = load_breast_cancer()</span><span id="708f" class="ne lw it na b gy nj ng l nh ni">df = pd.DataFrame(bc.data, columns = bc.feature_names)<br/>df['diagnosis'] = bc.target<br/>df</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/f21d9cd52cf6f691d0ee15efa1b5ed35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iGFVOOWQgC9p53io0bS03Q.png"/></div></div></figure><p id="43d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">前30列是各种特征，最后一列是诊断(0表示恶性，1表示良性)。为了简单起见，我将使用30列进行训练，最后一列作为目标。</p><blockquote class="ms mt mu"><p id="7d83" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated">理想情况下，您应该执行要素选择来筛选出那些显示共线性的列以及与目标没有强相关性的列。</p></blockquote><p id="16f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们提取特性和标签的值，并将它们保存为数组:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="4290" class="ne lw it na b gy nf ng l nh ni">dfX = df.iloc[:,:-1]   # Features - 30 columns<br/>dfy = df['diagnosis']  # Label - last column</span><span id="b4a2" class="ne lw it na b gy nj ng l nh ni">X = dfX.values<br/>y = dfy.values</span><span id="a036" class="ne lw it na b gy nj ng l nh ni">print(X.shape)   # (569, 30); 2D array<br/>print(y.shape)   # (569,);    1D array</span></pre><p id="657c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将数据集分为训练集和测试集:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="10be" class="ne lw it na b gy nf ng l nh ni">from sklearn.model_selection import train_test_split</span><span id="9a02" class="ne lw it na b gy nj ng l nh ni">X_train, X_test, y_train, y_test = train_test_split(X, y,<br/>                                       test_size=0.25, <br/>                                       random_state=2)</span></pre><p id="4b1e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图显示了训练和测试数据集的用法:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/13b091fb9836a9625d98df9afa10a4b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*qKjPJi4lJM6eNlOhBRGtDQ.png"/></div></figure><p id="3ee9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，标准化训练和测试数据集:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="9ec8" class="ne lw it na b gy nf ng l nh ni">from sklearn import preprocessing</span><span id="4823" class="ne lw it na b gy nj ng l nh ni">scaler = preprocessing.StandardScaler()<br/>X_train = scaler.fit_transform(X_train)<br/>X_test = scaler.fit_transform(X_test)</span></pre><p id="396e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> StandardScaler </strong>类重新调整数据，使平均值为0，标准差为1(单位方差)。</p><blockquote class="ms mt mu"><p id="7e59" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated">数据集的标准化是许多机器学习估计器的常见要求:如果单个特征或多或少看起来不像标准的正态分布数据(例如，均值和单位方差为0的高斯数据)，它们可能表现不佳。来源:<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . preprocessing . standard scaler . html</a></p></blockquote><p id="bbb6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，使用sklearn的<strong class="lb iu"> LogisticRegression </strong>类，使用训练集建立一个模型，然后使用测试集获得测试集中所有项目的预测:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="57a6" class="ne lw it na b gy nf ng l nh ni">from sklearn.linear_model import LogisticRegression</span><span id="3e81" class="ne lw it na b gy nj ng l nh ni">logreg = LogisticRegression()<br/>logreg.fit(X_train,y_train)</span><span id="63b6" class="ne lw it na b gy nj ng l nh ni">y_pred = logreg.predict(X_test)</span></pre><p id="4b44" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要查看模型的执行情况，请获取其精确度:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="59ff" class="ne lw it na b gy nf ng l nh ni">from sklearn import metrics</span><span id="f1f9" class="ne lw it na b gy nj ng l nh ni">print("Accuracy:",metrics.accuracy_score(y_test, y_pred))<br/># OR<br/>print("Accuracy:",logreg.score(X_test, y_test))</span></pre><blockquote class="ms mt mu"><p id="a0f9" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated">您可以使用您刚刚构建的模型的<strong class="lb iu"> score() </strong>函数，或者使用来自<strong class="lb iu"> metrics </strong>模块的<strong class="lb iu"> accuracy_score() </strong>函数来获得精确度。</p></blockquote><p id="e870" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上述代码片段的准确性为:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="3821" class="ne lw it na b gy nf ng l nh ni">Accuracy: 0.9790209790209791</span></pre><h1 id="7c36" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">了解交叉验证</h1><p id="f6ee" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">为了理解如何使用GridSearchCV优化您的模型，您需要理解什么是<em class="mv">交叉验证</em>。还记得在上一节中我们将数据集分为训练集和测试集吗？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/17296d0c81de45edff7857b3740b2008.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*h2aPBBsEPvbUMvLYEjtLNQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="e150" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">测试集用于评估您使用定型集定型的模型的性能。虽然这是评估模型的一个好方法，但它可能不会给出模型性能的真实指示。众所周知，测试集中的数据可能是有偏差的，使用它来评估模型可能会给出非常有偏差的结果。一个好得多的方法是将整个数据集分成<em class="mv"> k倍</em>(或k份，即k倍意味着将数据集分成10等份)。在k折中，使用<em class="mv"> 1 </em>折进行测试，使用<em class="mv"> k-1 </em>折进行训练:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/f6b2efb5ed90266e7c779cb915e9ce9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*8Keoub8_NLNUaw1B3ak4Mg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="a068" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在每次迭代中，记录度量标准(比如准确度、精确度等)，并在所有迭代结束时，计算这些度量标准的平均值。这为您的模型提供了训练和测试数据的良好组合，并为您的模型提供了更好的性能基准。这个将你的数据分成k个折叠并使用1个折叠进行测试和k-1个折叠进行测试的过程被称为<strong class="lb iu"> k折叠交叉验证</strong>。</p><h1 id="9e53" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">使用GridSearchCV进行超参数调整</h1><p id="ae1e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在我们之前的<strong class="lb iu"> LogisticRegression </strong>类的例子中，我们创建了一个<strong class="lb iu"> LogisticRegression </strong>类的实例，没有传递任何初始化器。相反，我们依赖各种参数的默认值，例如:</p><ul class=""><li id="2560" class="no np it lb b lc ld lf lg li nq lm nr lq ns lu nt nu nv nw bi translated"><strong class="lb iu">惩罚</strong> —指定惩罚的标准。</li><li id="54ac" class="no np it lb b lc nx lf ny li nz lm oa lq ob lu nt nu nv nw bi translated"><strong class="lb iu"> C </strong> —正则化强度的逆；较小的值指定较强的正则化。</li><li id="89ec" class="no np it lb b lc nx lf ny li nz lm oa lq ob lu nt nu nv nw bi translated"><strong class="lb iu">求解器</strong> —在优化问题中使用的算法。</li><li id="8ccf" class="no np it lb b lc nx lf ny li nz lm oa lq ob lu nt nu nv nw bi translated"><strong class="lb iu"> max_iter </strong> —求解器收敛所需的最大迭代次数。</li></ul><p id="eedb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然在某些情况下依赖这些参数的默认值是可以的(在机器学习中称为<em class="mv">超参数</em>)，但能够微调它们的值总是好的，以便算法最适合您所拥有的数据类型。不幸的是，找到能够完美拟合您的数据的超参数的完美组合并不是一项简单的任务。这就是GridSearchCV的用武之地。</p><p id="0c8d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> GridSearchCV </strong>是<strong class="lb iu"> sklearn </strong>的<strong class="lb iu"> model_selection </strong>包中的一个函数。它允许您为每个超参数指定不同的值，并在拟合模型时尝试所有可能的组合。它使用数据集的交叉验证进行训练和测试——因此GridSearchCV中缩写为“<strong class="lb iu"> CV </strong>”。GridSearchCV的最终结果是一组超参数，根据您希望优化模型的评分标准，这些超参数最适合您的数据。</p><p id="a3f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们首先创建<em class="mv">参数网格</em>，它是一个字典，包含拟合模型时想要尝试的所有各种超参数:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="04e4" class="ne lw it na b gy nf ng l nh ni">from sklearn.model_selection import GridSearchCV</span><span id="ef7f" class="ne lw it na b gy nj ng l nh ni">import warnings<br/>warnings.filterwarnings('ignore')</span><span id="9d4a" class="ne lw it na b gy nj ng l nh ni"><strong class="na iu"># parameter grid<br/>parameters = {<br/>    'penalty' : ['l1','l2'], <br/>    'C'       : np.logspace(-3,3,7),<br/>    'solver'  : ['newton-cg', 'lbfgs', 'liblinear'],<br/>}</strong></span></pre><blockquote class="ms mt mu"><p id="f1ef" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated">注意，我已经关闭了警告，因为GridSearchCV()函数倾向于生成相当多的警告。</p></blockquote><p id="5720" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，您可以使用正在使用的算法以及如下所示的各种参数来调用GridSearchCV()函数:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="758b" class="ne lw it na b gy nf ng l nh ni">logreg = LogisticRegression()<br/>clf = GridSearchCV(logreg,                    # model<br/>                   param_grid = parameters,   # hyperparameters<br/>                   scoring='accuracy',        # metric for scoring<br/>                   cv=10)                     # number of folds</span></pre><p id="185d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> GridSearchCV() </strong>函数返回一个<strong class="lb iu"> LogisticRegression </strong>实例(在本例中，基于您正在使用的算法)，然后您可以使用您的训练集对其进行训练:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="c3fa" class="ne lw it na b gy nf ng l nh ni">clf.fit(X_train,y_train)</span></pre><p id="91ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完成训练后，您现在可以打印出调整后的超参数以及训练精度:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="efd5" class="ne lw it na b gy nf ng l nh ni">print("Tuned Hyperparameters :", clf.best_params_)<br/>print("Accuracy :",clf.best_score_)</span></pre><p id="ae39" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是我运行上述代码片段获得的结果:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="aa4e" class="ne lw it na b gy nf ng l nh ni">Tuned Hyperparameters : {'C': 0.1, <br/>                         'penalty': 'l2', <br/>                         'solver': 'liblinear'}<br/>Accuracy : 0.983499446290144</span></pre><p id="d681" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 0.9835 </strong>的精度现在比早期的0.9790精度好得多。</p><p id="6734" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用GridSearchCV()函数返回的超参数值，您现在可以使用这些值通过训练数据集构建模型:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="1214" class="ne lw it na b gy nf ng l nh ni">logreg = LogisticRegression(<strong class="na iu">C = 0.1</strong>, <br/>                            <strong class="na iu">penalty = 'l2'</strong>, <br/>                            <strong class="na iu">solver = 'liblinear'</strong>)<br/>logreg.fit(X_train,y_train)</span><span id="17ad" class="ne lw it na b gy nj ng l nh ni">y_pred = logreg.predict(X_test)<br/>print("Accuracy:",logreg.score(X_test, y_test))</span></pre><p id="60e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图总结了我们所做的工作:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/d0233c35a59e95821db7bc5733e1b324.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*a4ENJEahtQsSKS3pWoaKLg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="66f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">观察到:</p><ul class=""><li id="d11e" class="no np it lb b lc ld lf lg li nq lm nr lq ns lu nt nu nv nw bi translated">GridSearchCV使用<strong class="lb iu">训练集</strong>和<strong class="lb iu">验证集</strong>进行交叉验证。</li><li id="20ec" class="no np it lb b lc nx lf ny li nz lm oa lq ob lu nt nu nv nw bi translated">一旦GridSearchCV找到了超参数的值，我们就使用调整后的参数值通过训练集建立一个新的模型。</li><li id="d724" class="no np it lb b lc nx lf ny li nz lm oa lq ob lu nt nu nv nw bi translated">有了<strong class="lb iu">测试设备</strong>，我们现在可以评估我们的新模型了。</li></ul><blockquote class="ms mt mu"><p id="5d8e" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated">这里采用的方法让我们有了一个衡量新模型性能的指标。</p></blockquote><p id="e6f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用GridSearchCV的另一种方法是使用整个数据集来拟合它，如下所示:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="bf3a" class="ne lw it na b gy nf ng l nh ni">parameters = {<br/>    'penalty' : ['l1','l2'], <br/>    'C'       : np.logspace(-3,3,7),<br/>    'solver'  : ['newton-cg', 'lbfgs', 'liblinear'],<br/>}</span><span id="11f9" class="ne lw it na b gy nj ng l nh ni">logreg = LogisticRegression()<br/>clf = GridSearchCV(logreg, <br/>                   param_grid = parameters,<br/>                   scoring = 'accuracy', <br/>                   cv = 10)<br/><strong class="na iu">clf.fit(X,y)</strong></span></pre><p id="3c76" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上述代码片段返回以下结果:</p><pre class="kj kk kl km gt mz na nb nc aw nd bi"><span id="b308" class="ne lw it na b gy nf ng l nh ni">Tuned Hyperparameters : {'C': 1000.0, <br/>                         'penalty': 'l1', <br/>                         'solver': 'liblinear'}<br/>Accuracy : 0.9701754385964911</span></pre><p id="c980" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图总结了我们刚刚完成的工作:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/02c7d69cc6a375fc3251fcbaae6e87f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*RzKju8rT8mla_dizyTGbDg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="c545" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，您让GridSearchCV使用整个数据集来导出调优的参数，然后使用新获得的值来构建新的模型。</p><blockquote class="ms mt mu"><p id="63b9" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated">这里采用的方法允许我们为我们的数据集找出最佳的超参数，但是不允许你精确地评估你的模型。</p></blockquote><p id="f5bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用这种方法无法真正评估该模型，因为您不想传递任何用于预测训练的数据。为什么？因为模型已经在训练期间看到了数据，因此不会给你模型性能的准确度量。</p><div class="oe of gp gr og oh"><a href="https://weimenglee.medium.com/membership" rel="noopener follow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd iu gy z fp om fr fs on fu fw is bi translated">加入媒介与我的介绍链接-李伟孟</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">weimenglee.medium.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov ks oh"/></div></div></a></div><h1 id="89af" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">摘要</h1><p id="a0cd" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">使用GridSearchCV可以节省您在优化机器学习模型方面的大量精力。但是请注意，GridSearchCV只会根据您在参数网格中提供的内容来评估您的超参数。当然，您可能希望为每个超参数指定所有可能的值，但是这样做的计算代价很高，因为所有的组合都将被评估。最后，不要把GridSearchCV作为优化模型的灵丹妙药——在考虑训练模型之前，一定要花时间进行适当的特征选择。</p><p id="c046" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是我之前关于<em class="mv">功能选择</em>的文章链接:</p><div class="oe of gp gr og oh"><a rel="noopener follow" target="_blank" href="/statistics-in-python-using-anova-for-feature-selection-b4dc876ef4f0"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd iu gy z fp om fr fs on fu fw is bi translated">Python中的统计数据-使用方差分析进行要素选择</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">了解如何使用ANOVA比较分类变量和数值变量</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">towardsdatascience.com</p></div></div><div class="oq l"><div class="ow l os ot ou oq ov ks oh"/></div></div></a></div><div class="oe of gp gr og oh"><a rel="noopener follow" target="_blank" href="/statistics-in-python-using-chi-square-for-feature-selection-d44f467ca745"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd iu gy z fp om fr fs on fu fw is bi translated">Python中的统计数据-使用卡方进行要素选择</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">在我之前的两篇文章中，我谈到了如何度量数据集中各列之间的相关性，以及…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">towardsdatascience.com</p></div></div><div class="oq l"><div class="ox l os ot ou oq ov ks oh"/></div></div></a></div><div class="oe of gp gr og oh"><a rel="noopener follow" target="_blank" href="/statistics-in-python-collinearity-and-multicollinearity-4cc4dcd82b3f"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd iu gy z fp om fr fs on fu fw is bi translated">Python中的统计数据-共线性和多重共线性</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">了解如何发现数据集中的多重共线性</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">towardsdatascience.com</p></div></div><div class="oq l"><div class="oy l os ot ou oq ov ks oh"/></div></div></a></div><div class="oe of gp gr og oh"><a rel="noopener follow" target="_blank" href="/statistics-in-python-understanding-variance-covariance-and-correlation-4729b528db01"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd iu gy z fp om fr fs on fu fw is bi translated">Python中的统计学-了解方差、协方差和相关性</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">理解你的数据之间的关系，知道皮尔逊相关系数和…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">towardsdatascience.com</p></div></div><div class="oq l"><div class="oz l os ot ou oq ov ks oh"/></div></div></a></div></div></div>    
</body>
</html>