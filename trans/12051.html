<html>
<head>
<title>Visual Servoing for Robotics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器人视觉伺服</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/visual-servoing-part-1-of-3-cad49595564d?source=collection_archive---------6-----------------------#2021-12-05">https://towardsdatascience.com/visual-servoing-part-1-of-3-cad49595564d?source=collection_archive---------6-----------------------#2021-12-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="6f29" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">计算机视觉与机器人</h2><div class=""/><div class=""><h2 id="3fb3" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">使用摄像机传感器的路径规划</h2></div><h1 id="334b" class="ko kp iq bd kq kr ks kt ku kv kw kx ky kf kz kg la ki lb kj lc kl ld km le lf bi translated">介绍</h1><p id="8e79" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">这个项目的目的是使用一个鱼眼镜头和一个带ROS的Turtlubot3实现一个端到端的视觉伺服项目。视觉伺服意味着，机器人将只使用一个传感器，即摄像头，实现自动驾驶！</p><ol class=""><li id="6bb2" class="mc md iq li b lj me lm mf lp mg lt mh lx mi mb mj mk ml mm bi translated">第一个目标是将机器人从当前位置移动到目标位置。为了指定这些位置和它们的姿态，我们使用两个Aruco标记。</li><li id="7d47" class="mc md iq li b lj mn lm mo lp mp lt mq lx mr mb mj mk ml mm bi translated">机器人的第二个任务是避开用红色指定的障碍物，我们用A-star路径搜索算法实现了这个任务。</li><li id="be1a" class="mc md iq li b lj mn lm mo lp mp lt mq lx mr mb mj mk ml mm bi translated">最后，当机器人在目标位置时，我们必须“停车”，这意味着目标的位置姿态应该与机器人的姿态相同。</li></ol><figure class="ms mt mu mv gt mw"><div class="bz fp l di"><div class="mx my l"/></div></figure></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><p id="2335" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">在这个报告之后，我们将分析数学理论背景和我们实现的代码实现。</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi nj"><img src="../Images/c5fe3a95776c9a927ad10e507fa47eae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EZTNrlQ2EyTNaR7pTsVXoA.png"/></div></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">位置之间的角度，作者的图像</p></figure></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h2 id="95ab" class="nu kp iq bd kq nv nw dn ku nx ny dp ky lp nz oa la lt ob oc lc lx od oe le iw bi translated">ROS是什么？</h2><p id="0df3" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">机器人操作系统(ROS)是一个开源中间件，它包含一组用于促进机器人应用程序开发的库、软件和工具。有太多的功能，从传感器驱动器到最先进的算法。作为中间件，它包含软件和硬件的特性，因此，它能够执行各种动作，如硬件抽象和低级控制。到目前为止，不同版本的ROS存在一些重要的差异，所以出于兼容性的原因，我们使用Melodic release。</p><h2 id="969c" class="nu kp iq bd kq nv nw dn ku nx ny dp ky lp nz oa la lt ob oc lc lx od oe le iw bi translated">用于此场景的机器人——turtle bot 3</h2><p id="24fd" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在这个项目中，使用的移动机器人是一个Turtlebot3汉堡。Turtlebot3是一个紧凑、模块化和可编程的移动机器人。它使用ROS，并且能够为培训研究和开发创建多个应用程序。</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi of"><img src="../Images/7fd32ac517b85b7da8768418cb63c8f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oI5cOmhtZslGB7c1.png"/></div></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">工作流程，按作者分类的图像</p></figure></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="ca7f" class="ko kp iq bd kq kr og kt ku kv oh kx ky kf oi kg la ki oj kj lc kl ok km le lf bi translated">第一个目标—从当前位置移动到目标位置</h1><h2 id="fbdf" class="nu kp iq bd kq nv nw dn ku nx ny dp ky lp nz oa la lt ob oc lc lx od oe le iw bi translated"><strong class="ak"> 1。摄像机校准</strong></h2><p id="9ab3" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">摄像机校准是这个项目不可或缺的一部分。在这一阶段，该项目使用<a class="ae ol" href="http://wiki.ros.org/camera_calibration" rel="noopener ugc nofollow" target="_blank"> camera_calibration </a>包，它允许使用棋盘校准目标轻松校准单目摄像机。这些包使用OpenCV库，其中包含摄像机校准方法。</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi om"><img src="../Images/ea4ea6f11e90266914359f5223d8e3e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G4sqbV21V3eq3rRilw39eg.jpeg"/></div></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">棋盘，作者图片</p></figure><p id="076b" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated"><strong class="li ja">内在校准</strong> <br/>正如我们前面提到的，它使用<a class="ae ol" href="http://wiki.ros.org/camera_calibration" rel="noopener ugc nofollow" target="_blank"> camera_calibration </a>包。该套件可轻松校准单目或立体摄像机。棋盘是为了修复采集图像的<strong class="li ja"> <em class="on">径向畸变</em> </strong>的工具。<strong class="li ja"> <em class="on">径向或桶形失真</em> </strong>可以表示为:</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/9060fe752a62a74b8b61014f7165948a.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*DygybdB64s-kNnCDg888cA.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">x失真，图片由作者提供</p></figure><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi op"><img src="../Images/0c3513d05a8126593a902d1f36cd9e6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*ljJkntgvq2tqT_jObndJGg.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">y变形，图片作者</p></figure><p id="5abd" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">以同样的方式，因为成像镜头没有完全平行于成像平面对准，所以出现切向失真。因此，一些图像看起来比预期的要近。切向变形量可表示如下:</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/f358433cb1b5f9e0e03f729f8f253e4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*aTcH7DKtlRv9Onv3ZIUmgg.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">x失真，图片由作者提供</p></figure><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi or"><img src="../Images/d3e5a8b38ec74c67deb02c2f0b0ed48d.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*I4PXyG2gAQogu-1qTzZlMQ.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">y变形，图片作者</p></figure><p id="f351" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">根据上面的等式，我们可以找到五个参数，称为失真系数</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi os"><img src="../Images/cfdcd1ad3054e46ce3efd00d639e307b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*BLdh9M5JfsAv8deGUNWh2A.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">失真系数，图片由作者提供</p></figure><p id="8004" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">此外，<em class="on">内在参数</em>允许相机坐标和图像帧中的像素坐标之间的映射。它们包括像局部长度(fx，fy)和光学中心(Cx，Cy)这样的信息。</p><p id="e287" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">这些参数可以用摄像机矩阵表示:</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/1cdbd6e240cfd20c35ede6c9ca84e09c.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*u2R6ZQoelq3sK5VOqIDxHw.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">相机矩阵，图片由作者提供</p></figure><h2 id="9374" class="nu kp iq bd kq nv nw dn ku nx ny dp ky lp nz oa la lt ob oc lc lx od oe le iw bi translated"><strong class="ak"> 2。接收图像</strong></h2><p id="6de9" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">下一步是通过订阅ROS主题“/camera/image_raw”接收图像帧，并将其转换为NumPy数组。然后我们需要根据我们的需要裁剪图像，通过指定我们需要工作的窗口。然后，我们使用摄像机矩阵和上一步接收到的失真系数对接收到的图像进行去失真处理。</p><h2 id="2842" class="nu kp iq bd kq nv nw dn ku nx ny dp ky lp nz oa la lt ob oc lc lx od oe le iw bi translated"><strong class="ak"> 3。检测标记</strong></h2><p id="318d" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">使用OpenCV库，我们可以检测放置在机器人顶部的两个Aruco标记，一个标记用于当前位置，一个标记用于目标位置。我们只需调用函数“cv2.detectMarkers ”,从该函数中我们可以接收每个标记的角，然后我们可以继续进行姿态估计。</p><h2 id="d818" class="nu kp iq bd kq nv nw dn ku nx ny dp ky lp nz oa la lt ob oc lc lx od oe le iw bi translated"><strong class="ak"> 4。姿态估计</strong></h2><p id="342f" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">下一步是估计当前和目标姿态，简单地调用<a class="ae ol" href="https://github.com/manoskout/visual_servoing/blob/master/scripts/pose_estimation.py" rel="noopener ugc nofollow" target="_blank">姿态估计模块</a>中的函数<em class="on">cv2 . estimateposesinglemarkers</em>。从中我们接收每个标记的两个向量，一个平移向量[x，y，z]和一个旋转向量`[x，y，z]`。使用ROS publisher，我们将这些向量发送给机器人控制器，后者负责以机器人应该能够移动的方式翻译这些矩阵。这是通过ROS publisher实现的</p><figure class="ms mt mu mv gt mw"><div class="bz fp l di"><div class="ou my l"/></div></figure><p id="9814" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">其中<em class="on"> current_position </em>是控制器将订阅的ROS主题，以获取我们创建的自定义消息<em class="on">Pose _ estimation _ vectors</em>，以便发送这些向量。</p><p id="f450" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">该消息的结构如下:<br/> <em class="on">几何_msgs/Vector3旋转<br/>几何_msgs/Vector3平移</em></p><p id="9a2e" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">这是两种姿势的图像:</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/868c64e8c26ac1ab800864d7c544959f.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*8Mv54LVlhF62yEMjBj0Emg.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">初始姿势，图片作者</p></figure><h2 id="0636" class="nu kp iq bd kq nv nw dn ku nx ny dp ky lp nz oa la lt ob oc lc lx od oe le iw bi translated"><strong class="ak"> 5。控制器——将旋转和平移矩阵转换成齐次矩阵</strong></h2><p id="9c6e" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">齐次变换由外部参数<em class="on"> R </em>和<em class="on"> t </em>编码，并表示从世界坐标系<em class="on"> w </em>到摄像机坐标系<em class="on"> c </em>的基的变化。因此，给定点<em class="on"> P </em>在世界坐标<em class="on"> Pw </em>中的表示，我们通过下式获得<em class="on"> P </em>在摄像机坐标系<em class="on"> Pc </em>中的表示:</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/f473c54906ff902c53b417437e88983c.png" data-original-src="https://miro.medium.com/v2/resize:fit:422/format:webp/1*PGQfmOr08DW09DRJgLxpEQ.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">积分矩阵，作者图片</p></figure><p id="8d84" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">这种齐次变换由3乘3旋转矩阵<em class="on"> R </em>和3乘1平移向量<em class="on"> t </em>组成:</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/34fccc40e2e0851797ad84fd0a205a73.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*dGidvlBjKsqigBU8d5UBJA.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">同质矩阵，作者图片</p></figure><p id="c83f" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">结合射影变换和齐次变换，我们获得了将世界坐标中的3D点映射到图像平面和归一化相机坐标中的2D点的射影变换:</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/ae3b514f6c8e5848a4a6672bbdfcf8f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*yfIZW6sBtYHisdIVOBHfQQ.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">同质矩阵，作者图片</p></figure><p id="3bfc" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated"><a class="ae ol" href="https://github.com/manoskout/visual_servoing/blob/master/scripts/controller.py" rel="noopener ugc nofollow" target="_blank">控制器模块</a>必须通过OpenCV函数使用Rodrigues变换将旋转矢量转换成旋转矩阵:</p><pre class="ms mt mu mv gt oz pa pb pc aw pd bi"><span id="ba2c" class="nu kp iq pa b gy pe pf l pg ph">rotational_matrix, _ = cv2.Rodrigues(np.array([data.rotational.x, data.rotational.y, data.rotational.z], dtype=np.float32))</span></pre><p id="8054" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">然后，我们将旋转矩阵与变换向量水平堆叠，并在末尾添加行[0，0，0，1]以获得齐次矩阵。</p><h2 id="9d97" class="nu kp iq bd kq nv nw dn ku nx ny dp ky lp nz oa la lt ob oc lc lx od oe le iw bi translated">6。计算当前位置和目标位置之间的α角和距离ρ</h2><p id="a9db" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们从上一步获得的齐次矩阵描述了每个位置相对于摄像机框架的位置。我们需要将它们组合起来，以便从一个位置接收相对于另一个位置的位置。为此，我们将当前齐次矩阵的逆矩阵与目标齐次矩阵相乘，以获得组合的齐次矩阵(t):</p><pre class="ms mt mu mv gt oz pa pb pc aw pd bi"><span id="904e" class="nu kp iq pa b gy pe pf l pg ph">t = np.matmul(np.linalg.inv(self.curr_homogeneous_matrix), self.target_homogeneous_matrix)</span></pre><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/7507e3cd24913ce166868696ac73791e.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*FjGokDh_4W_1p6iXtl5drw.jpeg"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">组合齐次矩阵，作者图片</p></figure><p id="5280" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">接下来，我们需要计算机器人应该移动的角度(α)和距离(ρ):</p><p id="edce" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">我们从上面的矩阵中得到<em class="on"> dx </em>，<em class="on"> dy </em>:</p><pre class="ms mt mu mv gt oz pa pb pc aw pd bi"><span id="9b09" class="nu kp iq pa b gy pe pf l pg ph">dx = t[0][3]<br/>dy = t[1][3]</span></pre><p id="08bd" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">然后我们用<em class="on"> dx </em>，<em class="on"> dy </em>计算反正切:</p><pre class="ms mt mu mv gt oz pa pb pc aw pd bi"><span id="9d67" class="nu kp iq pa b gy pe pf l pg ph">self.alpha = math.atan2(dy, dx)</span></pre><p id="bccc" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">最后，我们通过应用欧几里德距离得到到目标的距离(rho ):</p><pre class="ms mt mu mv gt oz pa pb pc aw pd bi"><span id="4425" class="nu kp iq pa b gy pe pf l pg ph">self.rho = math.sqrt(math.pow(dy, 2) + math.pow(dx, 2))</span></pre><h2 id="0769" class="nu kp iq bd kq nv nw dn ku nx ny dp ky lp nz oa la lt ob oc lc lx od oe le iw bi translated"><strong class="ak"> 7。固定角度并将机器人移动到目标</strong></h2><p id="a31a" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">现在，我们通过向ROS主题“cmd_vel”发布仅角速度来确定β角，并且当根据目标角度角度角度正确时，我们再次向同一主题发布仅线速度，直到到目标的距离接近于零。我们使用比例控制器，所以给机器人的速度乘以两个常数，一个是角速度，一个是线速度。</p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="4e2a" class="ko kp iq bd kq kr og kt ku kv oh kx ky kf oi kg la ki oj kj lc kl ok km le lf bi translated">第二个目标——避开障碍</h1><h2 id="c3b2" class="nu kp iq bd kq nv nw dn ku nx ny dp ky lp nz oa la lt ob oc lc lx od oe le iw bi translated">1.障碍物检测</h2><p id="5170" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><a class="ae ol" href="https://github.com/manoskout/visual_servoing/blob/master/scripts/obstacle_detection.py" rel="noopener ugc nofollow" target="_blank">障碍检测模块</a>正在使用输入图像，并将其切割成与机器人大小相同的方块。这样，我们就有了一个数组，里面有机器人能完成的所有可能的动作。为了区分障碍物，这意味着如果图像中有一个障碍物——一个红色的盒子——机器人就不能移动到那里。</p><p id="10a5" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">然后，我们对图像的每个框进行迭代，并将该框转换为HSV。接下来，如果该框包含红色范围内的任何像素，我们将对图像进行遮罩，并对输出应用按位遮罩。如果盒子包含红色像素，我们假设它是一个障碍。</p><p id="880f" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">这一步的输出是一个长度等于盒子数量的单向数组，它包含0(没有障碍物时)和1(有障碍物时)。</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/2dbff89ab116bf07c6e7263b7040ba16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*k0X9C4AnqNm0oM-w.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">障碍地图，作者提供的图像</p></figure><h2 id="e6a7" class="nu kp iq bd kq nv nw dn ku nx ny dp ky lp nz oa la lt ob oc lc lx od oe le iw bi translated">2.使用A-star算法寻找最短路径</h2><p id="24ed" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">使用上一步的障碍地图阵列，我们实现了<a class="ae ol" href="https://github.com/manoskout/visual_servoing/blob/master/scripts/path_planning.py" rel="noopener ugc nofollow" target="_blank">路径规划模块</a>，以获得机器人应该移动的最短路径，从而更快地进入目标。</p><p id="a374" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">这是一个基于图的算法，使用启发式方法来获得更好的性能。其核心是f = g + h，其中:</p><ul class=""><li id="2c1c" class="mc md iq li b lj me lm mf lp mg lt mh lx mi mb pk mk ml mm bi translated">f是总成本</li><li id="2074" class="mc md iq li b lj mn lm mo lp mp lt mq lx mr mb pk mk ml mm bi translated">g是当前节点和起始节点之间的距离。</li><li id="9dbf" class="mc md iq li b lj mn lm mo lp mp lt mq lx mr mb pk mk ml mm bi translated">h是启发式的，即从当前节点到结束节点的估计距离。</li></ul><p id="7030" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">阅读下面的<a class="ae ol" href="https://medium.com/@nicholas.w.swift/easy-a-star-pathfinding-7e6689c7f7b2" rel="noopener">文章</a>了解更多信息。</p><h2 id="619a" class="nu kp iq bd kq nv nw dn ku nx ny dp ky lp nz oa la lt ob oc lc lx od oe le iw bi translated">3.估计中点姿态</h2><p id="bca3" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">最短路径包含一些中间点，机器人应该在不与障碍物发生任何碰撞的情况下更快地找到目标位置。</p><p id="02be" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">这里，我们面临一个问题，因为我们只有这些中间点的索引。因此，我们决定根据我们的框式框架将这些索引转换成像素。使用它们的角，我们计算它们的姿态，就像我们使用函数<code class="fe pl pm pn pa b">cv2.aruco.estimatePoseSingleMarkers</code>计算aruco标记的姿态一样。</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/85f19d3de44766dda9aba62d56de3458.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/0*SANLzVBXCibJfk8v.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">中点姿势，作者图片</p></figure><h2 id="6c8a" class="nu kp iq bd kq nv nw dn ku nx ny dp ky lp nz oa la lt ob oc lc lx od oe le iw bi translated">4.绘制最短路径</h2><p id="7292" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">然后，我们查看障碍地图，并在图像上画出我们在前面步骤中计算的最短路径的每个中点。</p><p id="3f29" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">这是最终的地图，其中蓝色的零表示机器人有有效的移动，浅蓝色的X表示有障碍，橙色的圆圈表示最短的路径，粗体白色的S和G分别表示路径的起点和目标点。</p><figure class="ms mt mu mv gt mw gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/bb5f0ab84a73d6e17f5d5bd2909332ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/0*_ojPpRAvVzKxeZc1.png"/></div><p class="nq nr gj gh gi ns nt bd b be z dk translated">最终地图，图片由作者提供</p></figure><h2 id="3bfd" class="nu kp iq bd kq nv nw dn ku nx ny dp ky lp nz oa la lt ob oc lc lx od oe le iw bi translated">5.在每个中间点上移动</h2><p id="a580" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">每次执行<code class="fe pl pm pn pa b">on_receive_image</code>回调时，我们的控制器都会接收当前的姿态向量。如前所述，它计算齐次矩阵，并将其保存为类变量<code class="fe pl pm pn pa b">self.current_homogeneous_matrix</code>。</p><p id="e4b1" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">对于每个中间点，控制器接收相同的向量并更新列表<code class="fe pl pm pn pa b">target_position_path</code>类变量。当这个列表没有值时，机器人不会移动，因为它不知道去哪里。当接收到一些值时，它计算这个特定中点的齐次矩阵，并将其保存为类变量<code class="fe pl pm pn pa b">self.target_homogeneous_matrix</code>。</p><p id="25ea" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">通过固定角度，然后移动到中点，机器人现在可以在<code class="fe pl pm pn pa b">target_position_path</code>列表中指定的每个中点上移动。当机器人接近中点并且距离误差很小时，我们得到列表的下一个元素(中点),并继续移动直到列表为空！</p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="9020" class="ko kp iq bd kq kr og kt ku kv oh kx ky kf oi kg la ki oj kj lc kl ok km le lf bi translated">第三个目标——停车</h1><h2 id="2ce2" class="nu kp iq bd kq nv nw dn ku nx ny dp ky lp nz oa la lt ob oc lc lx od oe le iw bi translated">1.计算β欧拉角</h2><p id="db91" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在控制器<code class="fe pl pm pn pa b">move_robot</code>上，有两个循环用于执行前面的步骤(固定角度，向前移动)。出于停车的目的，我们需要添加另一个循环，该循环仅在机器人位于目标位置时执行，该循环的目的是固定相对于指定目标姿态的最终角度。</p><p id="3db3" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">我们需要额外代码很简单:</p><pre class="ms mt mu mv gt oz pa pb pc aw pd bi"><span id="4a61" class="nu kp iq pa b gy pe pf l pg ph">rotational_matrix = np.array([<br/>            [t[0][0], t[0][1], t[0][2]],<br/>            [t[1][0], t[1][1], t[1][2]],<br/>            [t[2][0], t[2][1], t[2][2]],<br/>        ])<br/>                <br/>r = R.from_matrix(rotational_matrix)<br/>self.beta = r.as_euler('XYZ', degrees=False)[2]</span></pre><p id="4722" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">我们将旋转矩阵转换为欧拉角，我们接收一个向量<code class="fe pl pm pn pa b">[x,y,z]</code>并得到第三个值，因为我们只需要z角，我们将它保存为类变量beta。</p><h2 id="a778" class="nu kp iq bd kq nv nw dn ku nx ny dp ky lp nz oa la lt ob oc lc lx od oe le iw bi translated">2.移动机器人以修正角度误差</h2><p id="2839" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">最后，我们公布所需的角速度，机器人确定β角！</p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><h1 id="2ab4" class="ko kp iq bd kq kr og kt ku kv oh kx ky kf oi kg la ki oj kj lc kl ok km le lf bi translated">演示</h1><p id="96ac" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">执行Roscore:</p><pre class="ms mt mu mv gt oz pa pb pc aw pd bi"><span id="8af2" class="nu kp iq pa b gy pe pf l pg ph">roscore</span></pre><p id="2519" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">启动摄像机</p><pre class="ms mt mu mv gt oz pa pb pc aw pd bi"><span id="c255" class="nu kp iq pa b gy pe pf l pg ph">roslaunch ueye_cam rgb8.launch</span></pre><p id="a4de" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">远程监控，了解更多详情<a class="ae ol" href="http://wiki.ros.org/robotican/Tutorials/Remote%20monitoring%20and%20control" rel="noopener ugc nofollow" target="_blank">点击此处</a>:</p><pre class="ms mt mu mv gt oz pa pb pc aw pd bi"><span id="7b45" class="nu kp iq pa b gy pe pf l pg ph">ssh ubuntu@192.168.0.200</span></pre><p id="db24" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">关于turtlebot运行，更多详情<a class="ae ol" href="https://emanual.robotis.com/docs/en/platform/turtlebot3/bringup/" rel="noopener ugc nofollow" target="_blank">请点击此处</a>:</p><pre class="ms mt mu mv gt oz pa pb pc aw pd bi"><span id="006a" class="nu kp iq pa b gy pe pf l pg ph">roslaunch turtlebot3_bringup turtlebot3_robot.launch</span></pre><p id="7354" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated">在远程计算机上启动我们的实现:</p><pre class="ms mt mu mv gt oz pa pb pc aw pd bi"><span id="ce60" class="nu kp iq pa b gy pe pf l pg ph">roslaunch visual_servoing visual_servoing.launch</span></pre></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><p id="eea9" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated"><a class="ae ol" href="https://github.com/manoskout/visual_servoing/" rel="noopener ugc nofollow" target="_blank">项目的GitHub链接</a></p><p id="19fd" class="pw-post-body-paragraph lg lh iq li b lj me ka ll lm mf kd lo lp ng lr ls lt nh lv lw lx ni lz ma mb ij bi translated"><a class="ae ol" href="https://www.linkedin.com/in/manos-mark/" rel="noopener ugc nofollow" target="_blank">我的LinkedIn账户</a></p></div></div>    
</body>
</html>