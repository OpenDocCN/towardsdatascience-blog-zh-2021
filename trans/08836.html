<html>
<head>
<title>Grad-CAM: A Camera For Your Model’s Decision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Grad-CAM:为你的模特做决定的相机</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/grad-cam-camera-for-your-models-decision-1ef69aae8fe7?source=collection_archive---------8-----------------------#2021-08-15">https://towardsdatascience.com/grad-cam-camera-for-your-models-decision-1ef69aae8fe7?source=collection_archive---------8-----------------------#2021-08-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="518d" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">🤖<a class="ae ep" href="https://equipintelligence.medium.com/list/deep-learning-techniques-methods-and-how-tos-01015cf5f917" rel="noopener">深度学习</a></h2><div class=""/><div class=""><h2 id="24e0" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">灯光，凸轮，渐变！</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><a href="https://linktr.ee/shubham0204"><div class="gh gi ko"><img src="../Images/5491c50fbf26de06b9ab84e0a348a6db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HuiYnh0iRLogVNl2AAKJtA.png"/></div></a><p class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd la">来源:</strong> <a class="ae lb" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank"> <strong class="bd la"> Grad-CAM:基于梯度定位的深度网络视觉解释</strong> </a></p></figure><p id="08fd" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">模型可解释性是ML中的热门话题之一，因为它对于理解<em class="ly">黑盒</em>神经网络和一般ML系统非常重要。它们有助于识别ML系统中的潜在偏差，这些偏差会导致失败或不满意的用户体验。</p><div class="lz ma gp gr mb mc"><a href="https://www.weforum.org/agenda/2021/07/ai-machine-learning-bias-discrimination/" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ja gy z fp mh fr fs mi fu fw iz bi translated">研究显示人工智能经常有偏见。以下是如何让算法为我们所有人服务的方法</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">现有的人类偏见过于频繁地转移到人工智能上。这里有五种类型的偏见以及如何解决…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">www.weforum.org</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq ku mc"/></div></div></a></div><div class="lz ma gp gr mb mc"><a href="https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ja gy z fp mh fr fs mi fu fw iz bi translated">研究发现商业人工智能系统中的性别和皮肤类型偏见</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">主要技术公司的三个商业发布的面部分析程序展示了皮肤类型和…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">news.mit.edu</p></div></div><div class="ml l"><div class="mr l mn mo mp ml mq ku mc"/></div></div></a></div><p id="1367" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">你会不时地看到这些头条新闻，因为无偏见ML模型的重要性在现代世界一直在上升。模型可解释性技术实际上允许我们检查我们的ML系统的低效率，并且寻找潜在的偏见。</p><p id="d77d" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">在这个故事中，我们将研究一种新的方法，Grad-CAM技术来生成CAM(类激活图)，这有助于我们可视化我们的CNN(或任何其他模型)在给定数据中的外观。</p><p id="743f" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">另外，您可以在官方的Keras examples repo中找到Grad-CAM实现(使用TF)的源代码，</p><div class="lz ma gp gr mb mc"><a href="https://keras.io/examples/vision/grad_cam/" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ja gy z fp mh fr fs mi fu fw iz bi translated">Keras文档:Grad-CAM类激活可视化</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">作者:fchollet创建日期:2020/04/26最近修改时间:2021/03/07描述:如何获得类激活…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">keras.io</p></div></div><div class="ml l"><div class="ms l mn mo mp ml mq ku mc"/></div></div></a></div><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mt mu l"/></div></figure><h1 id="e55d" class="mv mw iq bd mx my mz na nb nc nd ne nf kf ng kg nh ki ni kj nj kl nk km nl nm bi translated">🧾目录</h1><p id="2a3b" class="pw-post-body-paragraph lc ld iq le b lf nn ka lh li no kd lk ll np ln lo lp nq lr ls lt nr lv lw lx ij bi translated"><a class="ae lb" href="#03b1" rel="noopener ugc nofollow"> <strong class="le ja"> 1。模型可解释性介绍</strong> </a></p><p id="0552" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><a class="ae lb" href="#276f" rel="noopener ugc nofollow">②<strong class="le ja">。我们可以用什么来解释模型的决定？</strong> </a></p><p id="1138" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><a class="ae lb" href="#cc6c" rel="noopener ugc nofollow"> <strong class="le ja"> 3。输入Grad-CAM </strong> </a></p><p id="1219" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><a class="ae lb" href="#d351" rel="noopener ugc nofollow"> <strong class="le ja"> 4。通过实验学习- Grad-CAM </strong> </a></p><p id="0e1f" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><a class="ae lb" href="#7e0c" rel="noopener ugc nofollow"> <em class="ly"> — 4.1。了解设置</em>和</a></p><p id="cc5b" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><a class="ae lb" href="#d63f" rel="noopener ugc nofollow"> <em class="ly"> — 4.2。为每个特征图生成分数</em> </a></p><p id="b895" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><a class="ae lb" href="#f3bb" rel="noopener ugc nofollow"> <em class="ly"> — 4.3。生成Grad-CAM热图</em> </a></p><p id="119f" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><a class="ae lb" href="#e71d" rel="noopener ugc nofollow"> <strong class="le ja"> 5。用Grad-CAM </strong> </a>进行反事实解释</p><p id="d87b" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><a class="ae lb" href="#978a" rel="noopener ugc nofollow"> <strong class="le ja"> 6。模型决策中的检验偏差</strong> </a></p><p id="ffba" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><a class="ae lb" href="#c079" rel="noopener ugc nofollow">第七期<strong class="le ja">。作者的下一步/更多故事</strong> </a></p><p id="dd0b" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated"><a class="ae lb" href="#32cf" rel="noopener ugc nofollow"> <strong class="le ja"> 8。参考文献</strong> </a></p></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><h1 id="03b1" class="mv mw iq bd mx my nz na nb nc oa ne nf kf ob kg nh ki oc kj nj kl od km nl nm bi translated">1.⚖模型可解释性简介</h1><blockquote class="oe of og"><p id="1458" class="lc ld ly le b lf lg ka lh li lj kd lk oh lm ln lo oi lq lr ls oj lu lv lw lx ij bi translated">对黑盒进行逆向工程</p></blockquote><figure class="kp kq kr ks gt kt gh gi paragraph-image"><a href="https://linktr.ee/shubham0204"><div class="gh gi ok"><img src="../Images/3f69f8a04e3d76e3a731b242a6ccfcab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R1LEvJuphPvyEwsCSsPJKQ.jpeg"/></div></a><p class="kw kx gj gh gi ky kz bd b be z dk translated">图1 -&gt;由图像分类CNN做出的推断。<strong class="bd la">来源:作者图片</strong></p></figure><p id="4ad8" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">在阅读深度学习的入门书籍时，你可能已经注意到一件事，那就是他们将神经网络称为* <strong class="le ja"> <em class="ly">【黑盒】</em> </strong>。我们知道神经网络确实有一个定义良好的数学结构，那么为什么它们被称为“黑盒”呢？</p><p id="d3e8" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">原因是我们无法解码神经网络做出的决策。例如，让我们考虑一个简单的CNN的狗与猫分类器(见<em class="ly">图1 </em>)。对于给定的图像，由模型做出的决定是由模型预测的类别。对于给定的图像，该模型决定该图像包含“狗”还是“猫”。</p><p id="a6b8" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">在我们的案例中，解码一个决定将有助于我们研究输入图像的特性或特征，这些特性或特征在产生那个决定中起了主要作用。如果我们的模型预测了“狗”这个类别，那么可能产生这个决定的一个重要特征可能是它的鼻子、耳朵或任何其他使它区别于“猫”这个类别的特征。我们想知道我们的模型基于什么来预测某个标签，比如“猫”或“狗”。</p><blockquote class="ol"><p id="0fbd" class="om on iq bd oo op oq or os ot ou lx dk translated">“为了建立对智能系统的信任，并让它们有意义地融入我们的日常生活，很明显，我们必须建立‘透明’的模型，能够解释它们为什么会预测它们预测的东西。”—来自[ 1 ]</p></blockquote><p id="7c89" class="pw-post-body-paragraph lc ld iq le b lf ov ka lh li ow kd lk ll ox ln lo lp oy lr ls lt oz lv lw lx ij bi translated">考虑到橙子和苹果的图像分类问题，这些水果的形状不是一个<em class="ly">好的</em>特征，因为它们可能有相似的形状。这可能会给我们<strong class="le ja"><em class="ly">*不正确的结果</em> </strong>，当模型已经在现实世界中部署时。</p><p id="0a38" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">为了更好地理解ML中模型可解释性的概念，请参考，</p><div class="lz ma gp gr mb mc"><a href="https://christophm.github.io/interpretable-ml-book/" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ja gy z fp mh fr fs mi fu fw iz bi translated">可解释的机器学习</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">机器学习在改进产品、流程和研究方面潜力巨大。但是电脑通常不会…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">christophm.github.io</p></div></div><div class="ml l"><div class="pa l mn mo mp ml mq ku mc"/></div></div></a></div><p id="5923" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">为了识别这样的特征，也为了发现我们的NN模型对于特定决策的<em class="ly">焦点</em>，我们引入了<strong class="le ja">模型可解释性</strong>的概念(参见<strong class="le ja">【2】</strong>)<strong class="le ja"/>)。它包括所有那些为我们的模型决策带来可解释性和透明性的技术。</p><blockquote class="oe of og"><p id="73d7" class="lc ld ly le b lf lg ka lh li lj kd lk oh lm ln lo oi lq lr ls oj lu lv lw lx ij bi translated"><strong class="le ja"> *“黑盒”<em class="iq"> : </em> </strong>在我们的上下文中，“黑盒”指的是决策无法被解码的模型。通俗地说，我们无法满意地回答这个问题，“为什么这个决定是由我们的模型做出的？。</p><p id="4759" class="lc ld ly le b lf lg ka lh li lj kd lk oh lm ln lo oi lq lr ls oj lu lv lw lx ij bi translated"><strong class="le ja">*不正确的结果:</strong>我们可能想要识别这样的特征，以便我们可以知道我们的模型的弱点</p></blockquote></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><h1 id="276f" class="mv mw iq bd mx my nz na nb nc oa ne nf kf ob kg nh ki oc kj nj kl od km nl nm bi translated">2.🎓我们如何解释模型的决定？</h1><blockquote class="oe of og"><p id="fb96" class="lc ld ly le b lf lg ka lh li lj kd lk oh lm ln lo oi lq lr ls oj lu lv lw lx ij bi translated">渐变是你所需要的，尤其是在DL中</p></blockquote><p id="45d0" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">为了更好地解释模型的决策，我们需要确定输入中的哪个要素对决策的贡献最大。在我们的狗与猫分类器中，如果预测一幅图像包含一只“猫”,那么模型会考虑哪些特征，如眼睛、身体颜色、耳朵，来产生这种预测？</p><p id="21ea" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">嗯，我们可以分析梯度，以检查我们的模型侧重于生成某个预测。梯度有助于我们测量输入(<strong class="le ja"> <em class="ly"> x </em> </strong>)对输出的影响(如<strong class="le ja"> <em class="ly"> x </em> </strong>上的某些函数<strong class="le ja"> <em class="ly"> f </em> </strong>)。这就是我们所需要的，图像中对神经网络输出影响最大的部分或区域。</p><div class="lz ma gp gr mb mc"><a href="https://medium.com/analytics-vidhya/understanding-gradients-in-machine-learning-60fff04c6400" rel="noopener follow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ja gy z fp mh fr fs mi fu fw iz bi translated">理解机器学习中的梯度</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">以张量值函数的导数为例。</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">medium.com</p></div></div><div class="ml l"><div class="pb l mn mo mp ml mq ku mc"/></div></div></a></div><p id="66b1" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">我们将确保梯度调查区域的形象，这是重要的决策模型。这就是Grad-CAM方法中“Grad-”的含义，我们将在下一节探讨。</p></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><h1 id="cc6c" class="mv mw iq bd mx my nz na nb nc oa ne nf kf ob kg nh ki oc kj nj kl od km nl nm bi translated">3.进入Grad CAM</h1><blockquote class="oe of og"><p id="8a92" class="lc ld ly le b lf lg ka lh li lj kd lk oh lm ln lo oi lq lr ls oj lu lv lw lx ij bi translated">嗯，这就是故事的全部！</p></blockquote><figure class="kp kq kr ks gt kt gh gi paragraph-image"><a href="https://linktr.ee/shubham0204"><div class="gh gi pc"><img src="../Images/fb7ec931e334acd8e66d625e4c414e2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:414/format:webp/1*y2KreqyRRTDYkYvnwV3ASg.png"/></div></a><p class="kw kx gj gh gi ky kz bd b be z dk translated"><strong class="bd la">来源:</strong> <a class="ae lb" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank"> <strong class="bd la"> Grad-CAM:通过基于梯度的定位来自深度网络的视觉解释</strong> </a></p></figure><p id="587a" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">Grad-CAM是由研究人员于2017年在论文<strong class="le ja"><em class="ly">【Grad-CAM:通过基于梯度的定位来自深度网络的视觉解释】</em> </strong>(参见<strong class="le ja">【1】</strong>)中引入的，以便为模型的某些输出生成类激活图(CAM)。他们的方法Grad-CAM也概括了<strong class="le ja">【7】</strong>的方法，也可用于其他类型的模型。在他们的论文中，人们可以观察到图像字幕模型以及VQA(视觉问答)模型的可视化。</p><div class="lz ma gp gr mb mc"><a rel="noopener follow" target="_blank" href="/visual-question-answering-with-deep-learning-2e5e7cbfdcd4"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ja gy z fp mh fr fs mi fu fw iz bi translated">具有深度学习的视觉问答</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">本博客包含“面向视觉问答的分层问题-图像共同关注”论文的实现…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ml l"><div class="pd l mn mo mp ml mq ku mc"/></div></div></a></div><p id="4a83" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">首先，我们将从神经网络的基础上理解Grad-CAM的基本实现。因此，这个故事期望读者有一些关于神经网络，反向传播和卷积层的知识。</p><div class="lz ma gp gr mb mc"><a rel="noopener follow" target="_blank" href="/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ja gy z fp mh fr fs mi fu fw iz bi translated">轻轻潜入卷积神经网络背后的数学</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">神经网络之谜第五部分</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ml l"><div class="pe l mn mo mp ml mq ku mc"/></div></div></a></div><p id="81d4" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">然后，我们将强调Grad-CAM的一些特性，这些特性有助于更好地理解我们的模型。所以，我们开始吧！</p></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><h1 id="d351" class="mv mw iq bd mx my nz na nb nc oa ne nf kf ob kg nh ki oc kj nj kl od km nl nm bi translated">4.🧪通过实验学习——grad-cam</h1><h2 id="7e0c" class="pf mw iq bd mx pg ph dn nb pi pj dp nf ll pk pl nh lp pm pn nj lt po pp nl iw bi translated">4.1.了解设置</h2><blockquote class="oe of og"><p id="ccd2" class="lc ld ly le b lf lg ka lh li lj kd lk oh lm ln lo oi lq lr ls oj lu lv lw lx ij bi translated">理解包含模型决策信息的参数</p></blockquote><figure class="kp kq kr ks gt kt gh gi paragraph-image"><a href="https://linktr.ee/shubham0204"><div class="gh gi pq"><img src="../Images/e0412bac2aeb135e06bd27e32315df8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pSbs3j__dNy3BpSus_xrCg.jpeg"/></div></a><p class="kw kx gj gh gi ky kz bd b be z dk translated">图2-&gt; CNN的底层。<strong class="bd la">来源:作者图片</strong></p></figure><p id="f05e" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">假设我们对猫和狗的图像分类问题做了一个简单的CNN。我们的CNN将预测标签<em class="ly">‘猫’</em>和<em class="ly">‘狗’</em>的分布，为此我们需要在最后一个密集层上激活<strong class="le ja"> <em class="ly"> *softmax </em> </strong>(参见<em class="ly">图2 </em>)。我们的CNN由一些卷积层组成，后面是一个<em class="ly">展平</em>层，然后是一些FC ( <em class="ly">全连通或密集</em>)层。我们没有考虑所有卷积层，而是只分析最后一个卷积层的* <strong class="le ja"> <em class="ly">输出。</em> </strong>最后一个卷积层的输出被展平并传递给FC层。如<em class="ly">图2 </em>所示，最后一个卷积层的输出是<strong class="le ja"><em class="ly"/></strong>特征图，宽度<strong class="le ja"> <em class="ly"> W </em> </strong>和高度<strong class="le ja"> <em class="ly"> H </em> </strong>各一张。我们将它们统称为张量<strong class="le ja"> <em class="ly"> A </em> </strong>，其中<strong class="le ja"> <em class="ly"> A_k </em> </strong>将是<strong class="le ja"><em class="ly">k个</em> </strong>内核。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/8e510c9ded51e8c98040871194c399b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*bMsLWfPCUX84c4sqePN9OA.png"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">图3-&gt;<strong class="bd la">A</strong>和<strong class="bd la"> A_k的形状来源:作者图片</strong></p></figure><p id="c94a" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">要知道内核和过滤器的区别，你可以参考我的这个故事，</p><div class="lz ma gp gr mb mc"><a href="https://pub.towardsai.net/kernels-vs-filters-demystified-1fd594e1c38d" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ja gy z fp mh fr fs mi fu fw iz bi translated">内核与过滤器:去神秘化</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">一劳永逸地理解差异。</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">pub.towardsai.net</p></div></div><div class="ml l"><div class="ps l mn mo mp ml mq ku mc"/></div></div></a></div><p id="fb97" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">在softmax之前，我们的CNN的输出是<strong class="le ja"> <em class="ly"> y_c </em> </strong>，在猫与狗分类器的情况下，<strong class="le ja"> <em class="ly"> y_c </em> </strong>是一个形状为<code class="fe pt pu pv pw b">( 2 , 1 )</code>的数组。这个数组的第一个和第二个元素分别是类“cat”和“dog”的输出。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi px"><img src="../Images/381aa6e50e4709c46800509349b5fdd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*ifj00u0BE8s_wAjFNSITyQ.png"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">图4-&gt;<strong class="bd la">y _ c的构成来源:作者图片</strong></p></figure><p id="59a2" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">正如我们之前讨论的，我们将利用渐变来解码模型的决策。为了计算梯度，我们需要一个函数和变量来计算它。我们的目的是研究特征图、<strong class="le ja"><em class="ly"/></strong>和我们的CNN、<strong class="le ja"> <em class="ly"> y </em> </strong>的输出之间的关系。</p><p id="e6af" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">每个特征图捕获输入图像的一些高级特征，并在做出最终决定<strong class="le ja"> <em class="ly"> y </em> </strong>中有其贡献。让我们假设，我们需要解码预测类“cat”的决策，所以我们将只关注输入<strong class="le ja"> <em class="ly"> y_cat </em> </strong>中的一个。<strong class="le ja"><em class="ly"/></strong>中任何特征映射的任何变化都会导致<strong class="le ja"> <em class="ly"> y_cat </em> </strong>值的变化。那么，为什么不计算<strong class="le ja"> <em class="ly"> y_cat </em> </strong>相对于特征图<strong class="le ja"> <em class="ly"> A_k </em> </strong>之一的梯度呢？</p><p id="f736" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">首先，让我们从下图中了解这个渐变的形状，</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi py"><img src="../Images/d5b70ba7f4f46596a0b43734d42a0459.png" data-original-src="https://miro.medium.com/v2/resize:fit:442/format:webp/1*qWZUw3r6QzBn_dY1ayAhsg.png"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">图5-&gt;<strong class="bd la">y _ cat</strong>w . r . t .到<strong class="bd la"> A_k .的渐变形状来源:作者图片</strong></p></figure><p id="40ae" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">因此，我们感兴趣的梯度具有形状<strong class="le ja"> <em class="ly"> W * H </em> </strong>，这与<strong class="le ja"> <em class="ly"> A </em> </strong>中的特征图相同。我们还会用<strong class="le ja"> <em class="ly"> i </em> </strong>和<strong class="le ja"> <em class="ly"> j </em> </strong>来索引这个矩阵的元素。我们可以构造这个矩阵的另一种方法是通过计算<strong class="le ja"><em class="ly">y _ cat</em></strong>w . r . t .<strong class="le ja"><em class="ly">A _ k</em></strong>的元素之一的梯度，索引为<strong class="le ja"> <em class="ly"> i </em> </strong>和<strong class="le ja"> <em class="ly"> j </em> </strong>。这个梯度是实数(标量)，</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pz"><img src="../Images/07e79510265e5a1f60f5c9a54062d7ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*H86cxezzu3E4mrKkSk-Maw.png"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">图6-&gt;<strong class="bd la">y _ cat</strong>w . r . t .到由<strong class="bd la"> A_k的<strong class="bd la"> i </strong>和<strong class="bd la"> j </strong>索引的元素的渐变形状来源:图片由作者</strong>提供</p></figure><p id="f849" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">如果我们计算所有这些可能的梯度，对于所有的值<strong class="le ja"> <em class="ly"> i </em> </strong>和<strong class="le ja"> <em class="ly"> j </em> </strong>并将它们放置在一个<strong class="le ja"> <em class="ly"> W * H </em> </strong>网格中，我们得到与图5 中描述的相同的梯度。我们中的许多人可能已经知道这一点，但在这里提到它是很重要的，因为我们将在执行梯度的全局平均池中使用这一观察。</p><blockquote class="oe of og"><p id="1b51" class="lc ld ly le b lf lg ka lh li lj kd lk oh lm ln lo oi lq lr ls oj lu lv lw lx ij bi translated"><strong class="le ja"> *softmax </strong>:准确地说，我们将其称为soft argmax，但大多数ML文献都求助于softmax。参见<strong class="le ja">【3】。</strong></p><p id="cabb" class="lc ld ly le b lf lg ka lh li lj kd lk oh lm ln lo oi lq lr ls oj lu lv lw lx ij bi translated"><strong class="le ja">*最后一个卷积层的输出</strong>:我们选择最后一个卷积层的输出是有原因的。最后一个卷积层捕获高级特征，从而保存关于输入图像(馈送给CNN的图像)的重要区域的信息。Grad-CAM研究论文<strong class="le ja"><em class="iq">【1】</em></strong>的一个注解，</p><p id="67a8" class="lc ld ly le b lf lg ka lh li lj kd lk oh lm ln lo oi lq lr ls oj lu lv lw lx ij bi translated"><strong class="le ja"> <em class="iq">“我们发现Grad-CAM图随着我们移至更早的卷积层而变得越来越差，因为它们具有更小的感受域，并且只关注语义更少的局部特征。”</em>T3】</strong></p><p id="8429" class="lc ld ly le b lf lg ka lh li lj kd lk oh lm ln lo oi lq lr ls oj lu lv lw lx ij bi translated">注意，我们总是可以使用CNN的其他层。当CNN的初始层捕获局部特征时，它们的梯度不会解释任何关于构成最终预测(或决策)的全局或高级特征的事情</p></blockquote><h2 id="d63f" class="pf mw iq bd mx pg ph dn nb pi pj dp nf ll pk pl nh lp pm pn nj lt po pp nl iw bi translated">4.2.为每个特征地图生成分数</h2><blockquote class="oe of og"><p id="b95b" class="lc ld ly le b lf lg ka lh li lj kd lk oh lm ln lo oi lq lr ls oj lu lv lw lx ij bi translated">根据每个特征图在最终输出中的影响对其进行加权</p></blockquote><p id="2309" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">在上一节中，我们已经获得了一个渐变来研究<strong class="le ja"> <em class="ly"> y_cat </em> </strong>(甚至<strong class="le ja"> <em class="ly"> y_dog </em> </strong> ) w.r.t到单个特征图<strong class="le ja"> <em class="ly"> A_k </em> </strong>的变化。但我们的目标是研究从<strong class="le ja"> <em class="ly"> y_cat </em> </strong> w.r.t到<strong class="le ja"> <em class="ly"> A </em> </strong>，一个由所有<strong class="le ja"> <em class="ly"> K </em> </strong>组成的张量特征图。<strong class="le ja"><em class="ly"/></strong>中的一些特征映射可能对最终输出<strong class="le ja"> <em class="ly"> y_cat </em> </strong>产生比其他更大的影响。如果我们能根据它们在<strong class="le ja"> <em class="ly"> y_cat </em> </strong>中的影响，给这些特征图中的每一个分配一个分数就好了。如文中所述，我们可以计算<em class="ly">图6 </em>中描述的梯度的所有元素的平均值，并将其用作该特征图的得分。</p><div class="lz ma gp gr mb mc"><a href="https://www.guidetomlandai.com/Global-Average-Pooling/" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ja gy z fp mh fr fs mi fu fw iz bi translated">全球平均池</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">本教程将展示YOLO如何使用张量流工作的基本解释。本教程的代码旨在…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">www.guidetomlandai.com</p></div></div><div class="ml l"><div class="qa l mn mo mp ml mq ku mc"/></div></div></a></div><p id="f678" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">换句话说，我们正在执行特征映射的全局平均池化(GAP ),</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><a href="https://linktr.ee/shubham0204"><div class="gh gi qb"><img src="../Images/4baa7282af6e1393c41d91535fa0d0aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*wT2VLLwQWJgLsvrCp-r2vg.png"/></div></a></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi qc"><img src="../Images/8b422cfa1cd5dd34b9cf8b4b3cc908cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/1*eDcVm6lBjlaygwuNdWj2Dg.png"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">图7 -&gt;每个特征图的得分。<strong class="bd la">来源:作者图片</strong></p></figure><p id="bf6a" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">特征图的分数越大，对<strong class="le ja"> <em class="ly"> y_c </em> </strong>的影响越大。由于我们想要分析增加<strong class="le ja"> <em class="ly"> y_c </em> </strong>值的特征，我们期望具有更高分数的特征图具有更多正梯度，总结了<em class="ly">图7 </em>中的表达式。如<em class="ly">图6 </em>所示，渐变的正值意味着增加像素(元素)<strong class="le ja"> <em class="ly"> A_i，j，</em></strong><strong class="le ja">y _ c</strong>的值也会增加<strong class="le ja"> <em class="ly">。</em> </strong></p><h2 id="f3bb" class="pf mw iq bd mx pg ph dn nb pi pj dp nf ll pk pl nh lp pm pn nj lt po pp nl iw bi translated">4.3.生成Grad-CAM热图</h2><blockquote class="oe of og"><p id="00bb" class="lc ld ly le b lf lg ka lh li lj kd lk oh lm ln lo oi lq lr ls oj lu lv lw lx ij bi translated">将我们所有的知识整合起来制作热图</p></blockquote><p id="e2f2" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">由于我们已经为<strong class="le ja"><em class="ly"/></strong>中的每个特征图计算了分数，我们现在可以继续制作Grad-CAM热图，我们在故事的前面部分已经看到了。稍后，我们将把这张热图叠加到输入图像上，看看我们的模型<em class="ly">看到了什么</em>来生成某种预测。</p><p id="6bef" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">使用这些分数，我们计算<strong class="le ja"><em class="ly"/></strong>中所有<strong class="le ja"> <em class="ly"> K </em> </strong>特征图的加权和，</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi qd"><img src="../Images/7d94aea444740ec08fd66e0e02b34ae4.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*eAJYoneDa3UQe6KG3w5xIg.png"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/925341e17dc88ac7da8c3b27cf299351.png" data-original-src="https://miro.medium.com/v2/resize:fit:380/format:webp/1*yl9AkGP-AQLbDxkwlFBsmA.png"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">图8 -&gt;计算特征图的加权和。<strong class="bd la">来源:作者图片</strong></p></figure><p id="8930" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">最后，我们应用逐元素的ReLU操作(参见<strong class="le ja">【4】</strong>)来获得最终的热图。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi qf"><img src="../Images/1a13fae2f4fdad32bbe041458a98ad5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*lOjIYc-OC-8BI2_kqRMZ6A.png"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">图9-&gt; Grad-CAM热图。<strong class="bd la">来源:作者图片</strong></p></figure><p id="1360" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">使用ReLU操作的原因在文章中有清楚的描述，</p><blockquote class="ol"><p id="afa1" class="om on iq bd oo op oq or os ot ou lx dk translated">我们将ReLU应用于地图的线性组合，因为我们只对对感兴趣的类别有积极影响的特征感兴趣，即，为了增加y_c，应该增加其强度的像素。</p></blockquote><p id="b418" class="pw-post-body-paragraph lc ld iq le b lf ov ka lh li ow kd lk ll ox ln lo lp oy lr ls lt oz lv lw lx ij bi translated">您可以从Grad-CAM上的官方Keras示例中找到将热图叠加到输入图像上的代码。</p></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><h1 id="e71d" class="mv mw iq bd mx my nz na nb nc oa ne nf kf ob kg nh ki oc kj nj kl od km nl nm bi translated">5.🎎Grad-CAM的反事实解释</h1><blockquote class="oe of og"><p id="e649" class="lc ld ly le b lf lg ka lh li lj kd lk oh lm ln lo oi lq lr ls oj lu lv lw lx ij bi translated">思考你的模型没有想到的东西！</p></blockquote><p id="ea0e" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">正如Christoph Molnar在“可解释的机器学习”中提到的(参见<strong class="le ja">【5】</strong>)，</p><blockquote class="ol"><p id="face" class="om on iq bd oo op oq or os ot ou lx dk translated">一个反事实的解释以这样的形式描述了一个因果关系:“如果X没有发生，Y也不会发生”</p></blockquote><figure class="qh qi qj qk ql kt gh gi paragraph-image"><div role="button" tabindex="0" class="qm qn di qo bf qp"><div class="gh gi qg"><img src="../Images/557389b15d873670e6bfc990b59763b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5-4FXC9SnLSqMBIF-j695Q.png"/></div></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">图10 -&gt;如论文[ 1 ]所示的反事实解释。<strong class="bd la">来源:</strong> <a class="ae lb" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank"> <strong class="bd la"> Grad-CAM:通过基于梯度的定位来自深度网络的视觉解释</strong> </a></p></figure><p id="866e" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">一个反事实的解释描述了当一个特定的决定被采取的时候什么不会发生。考虑到我们的猫与狗分类器的例子，我们想检查在给定输入图像的情况下，当模型的决定是“猫”或“狗”时，什么不会发生。</p><p id="b7a5" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">为了计算给定类别和模型的反事实解释，我们重复第4节中描述的相同过程。</p><div class="lz ma gp gr mb mc"><a href="https://christophm.github.io/interpretable-ml-book/counterfactual.html" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ja gy z fp mh fr fs mi fu fw iz bi translated">6.1反事实解释|可解释的机器学习</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">作者:Susanne Dandl &amp; Christoph Molnar一个反事实的解释以“如果X…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">christophm.github.io</p></div></div><div class="ml l"><div class="qq l mn mo mp ml mq ku mc"/></div></div></a></div><p id="ab86" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">但是这一次，在对特征图<strong class="le ja"> <em class="ly"> A_k </em> </strong>进行全局平均池化的同时，我们对梯度取反，比如，</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi qr"><img src="../Images/1cd1e38b31190e7695b4d75c3dff7443.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*RRYevBeuBiLNsFkbvJqcRg.png"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">图11 -&gt;计算热图作为反事实解释的<strong class="bd la"> alpha_c </strong>表达式。<strong class="bd la">来源:</strong> <a class="ae lb" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank"> <strong class="bd la"> Grad-CAM:基于梯度定位的深度网络视觉解释</strong> </a></p></figure><p id="b693" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">通过否定梯度，如图11所示，我们现在看到的是当像素值(或强度)增加时导致<strong class="le ja"> <em class="ly"> y_c </em> </strong>减少的像素。生成的热图捕捉了模型在生成预测时没有关注的要素。</p></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><h1 id="978a" class="mv mw iq bd mx my nz na nb nc oa ne nf kf ob kg nh ki oc kj nj kl od km nl nm bi translated">6.👩模型决策中的🧑检验偏差</h1><blockquote class="oe of og"><p id="4e8b" class="lc ld ly le b lf lg ka lh li lj kd lk oh lm ln lo oi lq lr ls oj lu lv lw lx ij bi translated">改进数据集和ML系统</p></blockquote><figure class="kp kq kr ks gt kt gh gi paragraph-image"><a href="https://linktr.ee/shubham0204"><div class="gh gi qs"><img src="../Images/3200a32103861d6ec777bf5077ed248d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OeQd60rCMDRnZNDMIj-LbA.png"/></div></a><p class="kw kx gj gh gi ky kz bd b be z dk translated">图12 -&gt;模型预测的偏差。<strong class="bd la">来源:</strong> <a class="ae lb" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank"> <strong class="bd la"> Grad-CAM:通过基于梯度的定位来自深度网络的视觉解释</strong> </a></p></figure><p id="978c" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">我们可以使用Grad-CAM来识别训练数据集传递的模型预测中的偏差。考虑到本文中的示例，假设我们已经根据从ImageNet数据集获取的图像训练了一个护士和医生图像分类器。该分类器在测试数据集上表现很好，但不能很好地泛化。我们是怎么知道的？查看<em class="ly">图12 </em>中的Grad-CAM热图，我们的有偏模型，我们可以观察到该模型专注于预测“护士”和“医生”标签时看似无关紧要的不需要的特征(部分面部、头发)。该模型似乎学习基于性别的特征，这在我们的用例中是不合适的。</p><div class="lz ma gp gr mb mc"><a href="https://www.foreseemed.com/blog/bias-in-machine-learning" rel="noopener  ugc nofollow" target="_blank"><div class="md ab fo"><div class="me ab mf cl cj mg"><h2 class="bd ja gy z fp mh fr fs mi fu fw iz bi translated">机器学习和深度学习中的偏见是什么？</h2><div class="mj l"><h3 class="bd b gy z fp mh fr fs mi fu fw dk translated">随着医疗行业收集数字数据的能力增强，新一轮的基于机器的学习(ML)和…</h3></div><div class="mk l"><p class="bd b dl z fp mh fr fs mi fu fw dk translated">www.foreseemed.com</p></div></div><div class="ml l"><div class="qt l mn mo mp ml mq ku mc"/></div></div></a></div><p id="90c8" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">正如论文中提到的，数据集是有偏差的。78%标为“医生”的图像包含男性，而93%标为“护士”的图像包含女性。显然，数据集中存在的性别偏见被传递到了模型中。请注意，该模型在测试数据集上表现良好，准确率为82%。</p><p id="eb98" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">一旦我们知道我们的数据集中存在特定的偏差，我们就重新收集数据并重新训练模型。无偏模型，如图<em class="ly">图12 </em>所示，捕捉准确的特征以识别包含“护士”和“医生”的图像。请注意，该模型侧重于识别“医生”形象的听诊器。</p></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><h1 id="c079" class="mv mw iq bd mx my nz na nb nc oa ne nf kf ob kg nh ki oc kj nj kl od km nl nm bi translated">7.👨‍🦱下一步/作者的更多故事</h1><p id="fe31" class="pw-post-body-paragraph lc ld iq le b lf nn ka lh li no kd lk ll np ln lo lp nq lr ls lt nr lv lw lx ij bi translated">Grad-CAM之后，许多研究小组提出了他们的方法，以获得更好的模型可解释性。</p><p id="0b01" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">Grad-CAM++<strong class="le ja">【8】</strong>和Score-CAM<strong class="le ja">【9】</strong>都是基于Grad-CAM的思想构建的。此外，我们还平滑了分数凸轮<strong class="le ja">【10】</strong>。</p><p id="f3bc" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">正如您将观察到的，模型可解释性一直是一个活跃的研究领域。因此，我们制作了一些新的“CAM ”,请在下面的评论中告诉我！</p><p id="5dc6" class="pw-post-body-paragraph lc ld iq le b lf lg ka lh li lj kd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">感谢您阅读这个故事！欢迎在下面的评论区发表你的评论/疑问/建议。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mt mu l"/></div></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="mt mu l"/></div></figure><h1 id="32cf" class="mv mw iq bd mx my mz na nb nc nd ne nf kf ng kg nh ki ni kj nj kl nk km nl nm bi translated">8.参考</h1><ol class=""><li id="75b9" class="qu qv iq le b lf nn li no ll qw lp qx lt qy lx qz ra rb rc bi translated"><a class="ae lb" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank"> <strong class="le ja"> Grad-CAM:基于梯度定位的深度网络视觉解释</strong> </a></li><li id="256e" class="qu qv iq le b lf rd li re ll rf lp rg lt rh lx qz ra rb rc bi translated">博客:<a class="ae lb" rel="noopener" target="_blank" href="/fair-and-explainable-machine-learning-25b802b00bec"> <strong class="le ja">公平可解释的机器学习</strong> </a>，<a class="ae lb" rel="noopener" target="_blank" href="/addressing-the-issue-of-black-boxes-in-machine-learning-f86429acbb2a"> <strong class="le ja">解决机器学习中的“黑箱”问题</strong> </a></li><li id="a2be" class="qu qv iq le b lf rd li re ll rf lp rg lt rh lx qz ra rb rc bi translated">维基百科:<a class="ae lb" href="https://en.wikipedia.org/wiki/Softmax_function" rel="noopener ugc nofollow" target="_blank"> <strong class="le ja"> Softmax函数</strong> </a></li><li id="ff7f" class="qu qv iq le b lf rd li re ll rf lp rg lt rh lx qz ra rb rc bi translated"><a class="ae lb" href="https://arxiv.org/abs/1611.01491" rel="noopener ugc nofollow" target="_blank"> <strong class="le ja">理解具有整流线性单元的深度神经网络</strong> </a></li><li id="88d8" class="qu qv iq le b lf rd li re ll rf lp rg lt rh lx qz ra rb rc bi translated"><a class="ae lb" href="https://christophm.github.io/interpretable-ml-book/" rel="noopener ugc nofollow" target="_blank"> <strong class="le ja">可解释的机器学习——让黑盒模型变得可解释的指南。，作者克里斯托夫·莫尔纳尔</strong> </a></li><li id="a01a" class="qu qv iq le b lf rd li re ll rf lp rg lt rh lx qz ra rb rc bi translated"><a class="ae lb" rel="noopener" target="_blank" href="/bias-in-your-datasets-covid-19-case-study-d065aa698b74"> <strong class="le ja">数据集中的偏差:深度学习用于新冠肺炎检测|走向数据科学</strong> </a></li><li id="c18b" class="qu qv iq le b lf rd li re ll rf lp rg lt rh lx qz ra rb rc bi translated"><a class="ae lb" href="https://arxiv.org/abs/1512.04150v1" rel="noopener ugc nofollow" target="_blank"> <strong class="le ja">学习深度特征进行判别定位</strong> </a></li><li id="d483" class="qu qv iq le b lf rd li re ll rf lp rg lt rh lx qz ra rb rc bi translated"><a class="ae lb" href="https://arxiv.org/abs/1710.11063" rel="noopener ugc nofollow" target="_blank"> <strong class="le ja"> Grad-CAM++:改进了对深度卷积网络的可视化解释</strong> </a></li><li id="920a" class="qu qv iq le b lf rd li re ll rf lp rg lt rh lx qz ra rb rc bi translated"><a class="ae lb" href="https://paperswithcode.com/paper/score-camimproved-visual-explanations-via" rel="noopener ugc nofollow" target="_blank"> <strong class="le ja"> Score-CAM:卷积神经网络的分数加权可视化解释</strong> </a></li><li id="7798" class="qu qv iq le b lf rd li re ll rf lp rg lt rh lx qz ra rb rc bi translated"><a class="ae lb" href="https://arxiv.org/abs/2006.14255" rel="noopener ugc nofollow" target="_blank"> <strong class="le ja"> SS-CAM:平滑的分数-CAM，用于更清晰的视觉特征定位</strong> </a></li></ol></div></div>    
</body>
</html>