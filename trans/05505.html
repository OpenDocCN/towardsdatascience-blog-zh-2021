<html>
<head>
<title>How to train your deep learning models in a distributed fashion.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何以分布式方式训练你的深度学习模型？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-train-your-deep-learning-models-in-a-distributed-fashion-43a6f53f0484?source=collection_archive---------8-----------------------#2021-05-16">https://towardsdatascience.com/how-to-train-your-deep-learning-models-in-a-distributed-fashion-43a6f53f0484?source=collection_archive---------8-----------------------#2021-05-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a2b1" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">基于Horovod的Azure ML分布式训练实用方法</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a6e69bc58a6c4b69da85cecf2ef09d37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*j84a6wWEd19z_DBq"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">凯文·Ku在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="556f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">深度学习算法非常适合大数据集，并且训练深度学习网络需要大的计算能力。由于GPU/TPU很容易按使用付费或免费获得(如Google collab)，今天有可能在类似云的ImageNet数据库上训练大型神经网络，例如Resnet 152 (152层)，ImageNet数据库有大约1400万张图像。但是一台支持多核GPU的机器是否足以训练庞大的模型呢？从技术上来说是的，但是训练这个模型可能需要几个星期。那么我们如何减少训练时间呢？任何可扩展性问题都可以使用两种方法来解决—纵向扩展或横向扩展。我们都知道，如果我们选择纵向扩展，容量会在某个时候达到极限，因此更好的替代方案是横向扩展。但是，你如何进行分布式训练，如果我使用Jupyter笔记本进行模型训练，我从哪里开始，我可以对任何深度学习模型进行分布式训练吗？这个博客旨在用一种实用的方法来回答这些问题。</p><p id="f963" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇博客中，我们将学习如何在云上应用横向扩展或者说分布式机器学习技术。我们将了解如何从Jupyter笔记本阶段(构建ML模型的最敏捷方式)过渡到可以在使用Azure ML和Horovod的GPU集群上运行的生产就绪型培训脚本。</p><p id="1521" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你是分布式机器学习的新手，这里有一些概念/术语是你在继续学习之前应该知道的。</p><h1 id="1901" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">数据并行和模型并行</h1><p id="4ade" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在数据并行方法中，整个模型被部署到一个集群的多个节点上，数据被分片(水平分割)。模型的每个实例都处理一部分数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/9c707d332c245c9af2c8d0c790fe03b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*rSis24NWXpCAy_NJ9jgg1g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据并行训练。</p></figure><p id="f847" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在模型并行方法中，模型的一个层(或一组层)被部署在集群的一个节点上，并且整个数据被复制到该节点，每个节点在完整的数据集上训练。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/bee3ce86a7c60000d4b5f3462bb779cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*G_bUmWPk48mQ_M6BbTmbBQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">模型平行训练。</p></figure><p id="0224" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最常见也最容易实现的是数据并行，我们将在接下来的章节中看到一种实用的方法。直观理解数据并行如何工作的一种方式是，在每个GPU节点中为一小批数据(比如一次30个图像)计算梯度，并且在网络的一轮前后传递结束时，更新的权重被发送回发起节点。来自每个节点的权重的加权平均值被应用于模型参数。更新的模型参数被发送回节点用于下一轮迭代。</p><p id="fd08" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这几乎类似于你以非分布式方式分批训练时发生的情况。然而，这里的关键问题是如何在数据并行方法中存储和更新模型参数。这就把我们带到了下一个话题，集中和去中心化的培训。</p><h1 id="3acb" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">集中和分散培训。</h1><p id="8942" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在模型并行或数据并行训练中，关键是节点之间的通信，定义参数如何初始化、权重/偏差如何更新很重要。</p><p id="2e85" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有两种类型的沟通方式。这适用于数据并行和模型并行方法。在集中式通信模式中，存在负责同步模型参数的节点或节点组，该节点被称为参数服务器。这种方法的优点是很容易同步模型参数，另一方面，参数服务器本身可能成为大型集群的瓶颈。这也是一个单点故障。当然，通过引入多个并行服务器并确保应用适当的存储冗余，可以在一定程度上减少瓶颈问题。</p><p id="711e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在去中心化的通信模式中，每个节点与每个其他节点通信以更新参数。这种方法的优点是对等更新更快，稀疏更新可以通过仅交换已更改的内容来进行，并且没有单点故障。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/8a2c153ceee7414990b6e0e060200908.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*iEXhP6XGYZgLnLXZD6bVfw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">集中培训与分散培训。</p></figure><h1 id="57b2" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">同步和异步更新。</h1><p id="acf4" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">如果你熟悉深度学习并知道如何训练权重(如果不是，你可以在这里阅读我的文章<a class="ae kv" href="https://www.linkedin.com/pulse/understanding-backpropagation-neural-network-1-srikanth-machiraju/" rel="noopener ugc nofollow" target="_blank"/>)，一旦损失函数的梯度可用，就计算更新的权重。在使用数据并行方法的分布式训练中，可以用两种方式更新模型参数，即权重和偏差。</p><p id="a951" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">1.同步地:假设我们正在处理10k图像和10个节点，每个节点被给予1k图像的子集，一旦它们完成第一次迭代，更新的模型参数被发送到参数服务器。这种方法大大提高了模型的准确性，但这种方法的缺点当然是服务器必须等待所有节点完成迭代，如果有一个非常慢的服务器，它可能会降低整个训练的速度。</p><p id="4fec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2.异步:在这种情况下，不是等待所有节点发送权重更新，而是一旦它们可用就发送，这增加了集群利用率并提高了训练速度，但是当然导致了陈旧梯度问题。大多数实现异步更新的框架都应用了一些策略来降低影响，以利于更高的集群利用率。</p><p id="480b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请记住，同步或异步更新适用于集中式和分散式培训方法。类似地，同步和异步更新可以应用于权重和对权重的更新，即，根据等式权重(新)=权重(旧)LR *梯度损失，在每次迭代之后，仅可以发送关于权重的梯度损失。为了更好地理解这一点，让我们想象一下，我们建立了一个具有同步更新和集中训练的集群，这意味着还有一个单独的参数服务，每个节点发送更新，一旦参数服务器上接收到所有更新，就计算新的权重，然后在所有节点上复制该权重，用于下一次迭代。</p><p id="1111" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在讨论了如何存储和更新模型参数的优点和缺点之后，选择最佳参数总是取决于问题、数据集、聚类大小和各种因素。没有一个解决所有问题的正确方法。</p><h1 id="c1e5" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">实现分布式机器学习的框架</h1><p id="ad66" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">Map/Reduce、Apache Spark、百度All Reduce、Horovod、Caffe2、微软认知工具包(CNTK)、dist faith、Tensorflow、DIANNE、MXNet、Petumm是分布式机器学习可用的顶级框架。在这里<a class="ae kv" href="https://analyticsindiamag.com/top-tools-distributed-machine-learning-tensorflow/" rel="noopener ugc nofollow" target="_blank">可以找到每一项的简要介绍。</a></p><p id="8946" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中，以下是Azure today在工作区(PaaS)模型中支持的——Apache Spark、Horovod(它在Databricks和Azure ML上都可用)、TensorFlow分布式培训，当然还有CNTK。</p><h1 id="7a89" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">Horovod和天蓝色ML。</h1><p id="85e1" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">分布式训练可以在Azure ML上使用PyTorch、TensorFlow这样的框架来完成。Tensorflow的分布式训练支持集中式和分散式训练方法(更多信息<a class="ae kv" href="https://www.tensorflow.org/guide/distributed_training" rel="noopener ugc nofollow" target="_blank">这里</a>)，如果你已经有一个使用分布式TF的笔记本，你可以很容易地将其导入Azure ML。在这篇文章中，我们将了解霍洛佛德。</p><p id="79ad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Horovod是一个开源的分布式深度学习框架，适用于TF、Keras、PyTorch和Apache MXNet，它通过减少对并行运行在多个GPU节点上的训练脚本所做的更改数量，简化了分布式训练。你可以在这里了解更多关于霍洛佛德<a class="ae kv" href="https://horovod.readthedocs.io/en/latest/summary_include.html" rel="noopener ugc nofollow" target="_blank">的信息。</a></p><p id="3767" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用Horovod设置环境时，您不必担心太多，Azure ML提供了精选的培训环境，可以使用各种框架轻松设置培训，其中一个框架预装了TensorFlow和Horovod。如果需要，这些策划的框架还允许定制。</p><p id="70d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">注意</strong>:你也可以在Azure ML上使用上面解释的集中式或分散式训练方法运行原生分布式TensorFlow。</p><h1 id="fd0f" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">从笔记本阶段到分布式ML的训练过程。</h1><p id="cb4d" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在这个例子中，我试图使用CNN对两类图像进行分类。这些图像属于胸部X射线，一类图像包含检测到积液的图像，另一类不包含。有关学习过程、预处理、消融实验等的更多信息。我推荐你参观这里的代码<a class="ae kv" href="https://github.com/sriksmachi/octopus" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="bfad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图解释了从笔记本阶段到以分布式方式在集群上运行训练实验的过程。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/c9c166731bf51bce639782191a952981.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yyoqa6U05baZ_6LgD5pojg.png"/></div></div></figure><p id="e355" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是我在一个支持Horovod的4节点分布式训练集群上运行单个GPU训练脚本的代码片段。</p><pre class="kg kh ki kj gt mt mu mv mw aw mx bi"><span id="44e5" class="my lt iq mu b gy mz na l nb nc">import os</span><span id="1bfb" class="my lt iq mu b gy nd na l nb nc">from azureml.core import ScriptRunConfig</span><span id="e6b2" class="my lt iq mu b gy nd na l nb nc">import shutil</span><span id="15b9" class="my lt iq mu b gy nd na l nb nc">from azureml.core import Experiment</span><span id="ec16" class="my lt iq mu b gy nd na l nb nc">from azureml.core import Environment</span><span id="8b1f" class="my lt iq mu b gy nd na l nb nc">from azureml.core.conda_dependencies import CondaDependencies</span><span id="3a56" class="my lt iq mu b gy nd na l nb nc">from azureml.widgets import RunDetails</span><span id="00e6" class="my lt iq mu b gy nd na l nb nc">from azureml.core.runconfig import MpiConfiguration</span><span id="9224" class="my lt iq mu b gy nd na l nb nc">## The training script capable of running in distributed environment is extracted to effusion_detector_distributed.py</span><span id="dbe5" class="my lt iq mu b gy nd na l nb nc">project_folder = './effusion_detector-distributed'</span><span id="897a" class="my lt iq mu b gy nd na l nb nc">os.makedirs(project_folder, exist_ok=True)</span><span id="702d" class="my lt iq mu b gy nd na l nb nc">shutil.copy('effusion_detector_distributed.py', project_folder)</span><span id="7eb0" class="my lt iq mu b gy nd na l nb nc">## choosing an experiment name</span><span id="0556" class="my lt iq mu b gy nd na l nb nc">experiment_name = 'tf-distributed-effusion-detector'</span><span id="3fee" class="my lt iq mu b gy nd na l nb nc">experiment = Experiment(ws, name=experiment_name)</span><span id="4e45" class="my lt iq mu b gy nd na l nb nc"># loading the env dependencies from conda configuration</span><span id="4105" class="my lt iq mu b gy nd na l nb nc">os.makedirs('./envs', exist_ok=True)</span><span id="91b7" class="my lt iq mu b gy nd na l nb nc">tf_env = Environment.from_conda_specification(name="imageclassification", file_path="envs/distributed-tensorflow-with-horovod/conda_dependencies.yml")</span><span id="0db3" class="my lt iq mu b gy nd na l nb nc"># Specify a GPU base image</span><span id="fd86" class="my lt iq mu b gy nd na l nb nc">tf_env.docker.enabled = True</span><span id="262f" class="my lt iq mu b gy nd na l nb nc">tf_env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'</span><span id="2c1b" class="my lt iq mu b gy nd na l nb nc"># using a cluster which can autoscale uptp 4 nodes.</span><span id="5164" class="my lt iq mu b gy nd na l nb nc">cluster_name = "gpus"</span><span id="7bd4" class="my lt iq mu b gy nd na l nb nc">compute_target = ComputeTarget(workspace=ws, name=cluster_name)</span><span id="ba74" class="my lt iq mu b gy nd na l nb nc"># running the script</span><span id="09be" class="my lt iq mu b gy nd na l nb nc">args = ['--data-folder', dataset.as_mount(), '--epochs', 20]</span><span id="6b28" class="my lt iq mu b gy nd na l nb nc">src = ScriptRunConfig(source_directory=project_folder,</span><span id="babf" class="my lt iq mu b gy nd na l nb nc">script='effusion_detector_distributed.py',</span><span id="4dd0" class="my lt iq mu b gy nd na l nb nc">arguments=args,</span><span id="0d71" class="my lt iq mu b gy nd na l nb nc">compute_target=compute_target,</span><span id="3024" class="my lt iq mu b gy nd na l nb nc">environment=tf_env, distributed_job_config=MpiConfiguration(node_count=4))</span><span id="d620" class="my lt iq mu b gy nd na l nb nc">run = experiment.submit(src)</span><span id="5524" class="my lt iq mu b gy nd na l nb nc">print(run)</span><span id="6bf1" class="my lt iq mu b gy nd na l nb nc">run.get_details()</span></pre><p id="48f7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里有一个图像显示了培训的结果，第一个实验是使用分布式培训(4个节点，每个节点6个GPU核心)完成的，第二个实验是使用一台具有6个GPU核心的机器完成的。用于单机和集群的处理单元<a class="ae kv" href="https://www.nvidia.com/en-gb/data-center/tesla-k80" rel="noopener ugc nofollow" target="_blank"> GPU — 1个NVIDIA Tesla K80 </a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/681642ca0a853e9e6f884212ba8b6690.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gprEafj1FuOtugPNrSAoWw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">分布式训练和单机训练的实验结果。</p></figure><p id="6ca9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我在分布式培训中没有发现什么明显的不同。</p><ol class=""><li id="89ac" class="nf ng iq ky b kz la lc ld lf nh lj ni ln nj lr nk nl nm nn bi translated">训练时间从7.5分钟减少到5分钟。</li><li id="ed92" class="nf ng iq ky b kz no lc np lf nq lj nr ln ns lr nk nl nm nn bi translated">为运行配置了20个时期，每个节点运行5个时期。(注意:这也意味着不能应用最小容差设置为5个时期的提前停止，在单机训练中，由于提前停止规则，训练最终停止)</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/dd79b9c13a806e58a0a3fead2e379b82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L-y-0wCqBwe20V12Lc17Mw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">该图显示了运行5个时期的工作进程0。</p></figure><p id="6520" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">3.每个工作进程都有一个私有IP，日志显示它们都是相互连接的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/3acaba85f98528af689985a93e665d73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FuUbCvD0sZ_725cpp08ceA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">该图显示了给定私有IP的每个进程。</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/466dc2962fb8c90c129d3fba00d034f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l0f-HFalQ5MxheeOVuHl4g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">显示工作进程0连接到工作进程3的图像。</p></figure></div><div class="ab cl nw nx hu ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="ij ik il im in"><div class="kg kh ki kj gt od"><a href="https://github.com/sriksmachi/octopus" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd ir gy z fp oi fr fs oj fu fw ip bi translated">八爪鱼</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">使用Azure ML、Horovod和TF - sriksmachi/octopus的分布式机器学习样本</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">github.com</p></div></div><div class="om l"><div class="on l oo op oq om or kp od"/></div></div></a></div><h1 id="e1ae" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">附加阅读</h1><p id="e88d" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">-<a class="ae kv" href="https://stackoverflow.com/questions/53498952/tensorflow-horovod-nccl-and-mpi#:~:text=MPI%20is%20used%20for%20CPU,used%20for%20GPU%2DGPU%20communication" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/53498952/tensor flow-horo VOD-nccl-and-MPI #:~:text = MPI % 20 is % 20 used % 20 for % 20 CPU，used % 20 for % 20g pu % 2d GPU % 20 communication</a>。</p><ul class=""><li id="21ec" class="nf ng iq ky b kz la lc ld lf nh lj ni ln nj lr os nl nm nn bi translated"><a class="ae kv" href="https://leimao.github.io/blog/Data-Parallelism-vs-Model-Paralelism/" rel="noopener ugc nofollow" target="_blank">https://lei Mao . github . io/blog/Data-Parallelism-vs-Model-parale lism/</a></li><li id="ece3" class="nf ng iq ky b kz no lc np lf nq lj nr ln ns lr os nl nm nn bi translated"><a class="ae kv" href="https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-tensorflow#distributed-training" rel="noopener ugc nofollow" target="_blank">https://docs . Microsoft . com/en-us/azure/machine-learning/how-to-training-tensor flow #分布式培训</a></li></ul></div></div>    
</body>
</html>