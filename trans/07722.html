<html>
<head>
<title>Let’s Start a Music Production House</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">让我们开一家音乐制作公司</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lets-start-a-music-production-house-ccd2655984f9?source=collection_archive---------46-----------------------#2021-07-14">https://towardsdatascience.com/lets-start-a-music-production-house-ccd2655984f9?source=collection_archive---------46-----------------------#2021-07-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6575" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">wave net by<a class="ae kf" href="https://google.com/" rel="noopener ugc nofollow" target="_blank">Google</a><a class="ae kf" href="https://deepmind.com/" rel="noopener ugc nofollow" target="_blank">deep mind</a>，时间就是现在。使用WaveNet生成音频</h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/20e4a1ea60b19aec6aa509dafb883b0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OQK-I53nW_wgX88gFLQvDQ.jpeg"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">照片由<a class="ae kf" href="https://unsplash.com/@cvanbebber?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">克里斯蒂安·范·贝伯</a>在<a class="ae kf" href="https://unsplash.com/s/photos/waves?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><blockquote class="kw"><p id="5d83" class="kx ky iq bd kz la lb lc ld le lf lg dk translated">音乐是精神的语言。它揭示了生活的秘密，带来和平，消除冲突。——卡里·纪伯伦</p></blockquote><p id="3f9c" class="pw-post-body-paragraph li lj iq lk b ll lm jr ln lo lp ju lq lr ls lt lu lv lw lx ly lz ma mb mc lg ij bi translated">最令人期待和期待的功能之一是以自然的形式与机器进行交互，类似于人类进行对话的方式。深度学习在许多方面都是人类的一个有效领域。具体来说，生成方法已经成为深度学习趋势的转折点，这种趋势开启了<a class="ae kf" href="https://en.wikipedia.org/wiki/Robotics#:~:text=Robotics%20is%20an%20interdisciplinary%20field,can%20help%20and%20assist%20humans." rel="noopener ugc nofollow" target="_blank">机器人</a>、<a class="ae kf" href="https://en.wikipedia.org/wiki/Internet_of_things" rel="noopener ugc nofollow" target="_blank">物联网</a>、互联网、电信以及几乎整个软件行业的几个应用。应用涉及<a class="ae kf" href="https://www.ibm.com/cloud/learn/natural-language-processing#:~:text=Natural%20language%20processing%20%28NLP%29%20refers,same%20way%20human%20beings%20can." rel="noopener ugc nofollow" target="_blank">自然语言处理</a>、<a class="ae kf" href="https://www.ibm.com/topics/computer-vision#:~:text=Computer%20vision%20is%20a%20field,recommendations%20based%20on%20that%20information." rel="noopener ugc nofollow" target="_blank">计算机视觉</a>、语音转文本和文本转语音、生成音频等。今天，我们将了解音频生成的<a class="ae kf" href="https://developers.google.com/machine-learning/gan/generative#:~:text=A%20generative%20model%20includes%20the,to%20a%20sequence%20of%20words." rel="noopener ugc nofollow" target="_blank">生成模型</a>之一。</p><h2 id="38ec" class="md me iq bd mf mg mh dn mi mj mk dp ml lr mm mn mo lv mp mq mr lz ms mt mu mv bi translated">介绍</h2><p id="f2e8" class="pw-post-body-paragraph li lj iq lk b ll mw jr ln lo mx ju lq lr my lt lu lv mz lx ly lz na mb mc lg ij bi translated"><strong class="lk ir"> WaveNet: </strong>深度学习模型，一种生成原始音频<a class="ae kf" href="https://whatis.techtarget.com/definition/waveform#:~:text=A%20waveform%20is%20a%20representation,sine%20of%20the%20elapsed%20time." rel="noopener ugc nofollow" target="_blank">波形</a>的神经网络。这是一个自回归以及<a class="ae kf" href="https://www.statisticshowto.com/probabilistic/#:~:text=A%20probabilistic%20method%20or%20model,the%20added%20complication%20of%20randomness." rel="noopener ugc nofollow" target="_blank">概率模型</a>。它可以在大量的音频样本上进行训练。它提供了音频一代中最先进的性能，具有显著的自然感觉。它可以用来创作音乐。如果用大量的音频数据进行训练，可以获得非常逼真的音乐效果。实际上，开发类似人类声音背后的秘密是用神经网络直接模拟波形。Wavenet模型提供了从多个代理中准确提取不同特征的灵活性。它还可以通过对声音身份进行调节来在这些声音之间切换，也称为条件WaveNet变体。</p><p id="4181" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated">拼接TTS(文本到语音)涉及从单个说话者收集音频片段形式的数据，然后将它们拼接起来以产生完整的话语。但是<a class="ae kf" href="https://en.wikipedia.org/wiki/Speech_synthesis" rel="noopener ugc nofollow" target="_blank">串联的TTS </a>听起来不自然，甚至不能修饰声音。</p><p id="bc47" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated">在<a class="ae kf" href="https://en.wikipedia.org/wiki/Speech_synthesis" rel="noopener ugc nofollow" target="_blank">参数化TTS </a>中，使用被称为声码器的语音合成器(一种音频处理算法)来创建语音。数据存储在模型的参数中。语音的特征可以通过模型的输入来控制。</p><h2 id="e994" class="md me iq bd mf mg mh dn mi mj mk dp ml lr mm mn mo lv mp mq mr lz ms mt mu mv bi translated">典型卷积</h2><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ng"><img src="../Images/e5783e72b3dad0aaaeefc102da866444.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UECUJB9jV0JY-boQTEIQKQ.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">2D卷积</p></figure><p id="9047" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated"><a class="ae kf" rel="noopener" target="_blank" href="/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">卷积神经网络</a>是一种深度学习模型，它接受图像作为输入，并进一步为其各个方面分配必要的可学习参数，这使得区分成为一项简单的任务。卷积采用以下参数:</p><ol class=""><li id="3a1e" class="nh ni iq lk b ll nb lo nc lr nj lv nk lz nl lg nm nn no np bi translated">内核大小:在图中具有阴影状外观的图像上悬停和移动的过滤器的大小为3×3，称为内核过滤器。3x3是2D卷积常用的大小</li><li id="bf80" class="nh ni iq lk b ll nq lo nr lr ns lv nt lz nu lg nm nn no np bi translated">通道:通道是保存像素值的维度；对于彩色图像，它可以由三个通道RGB表示，即红色、绿色和蓝色。而在黑白图像的情况下，我们只有两个通道，黑色和白色</li><li id="c2d4" class="nh ni iq lk b ll nq lo nr lr ns lv nt lz nu lg nm nn no np bi translated">填充:如图所示，边框被填充了一个单独的框，该框可以通过保持输入和输出维度的平衡和相等来处理它们。而无填充的卷积从边界裁剪开。</li><li id="718d" class="nh ni iq lk b ll nq lo nr lr ns lv nt lz nu lg nm nn no np bi translated">步幅:滤镜覆盖整个图像所要走的步数，包括逐步填充，如图所示</li></ol><p id="6e7d" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated">上图显示了使用3填充=1和步幅=1的内核大小的2D卷积。</p><h2 id="1d40" class="md me iq bd mf mg mh dn mi mj mk dp ml lr mm mn mo lv mp mq mr lz ms mt mu mv bi translated">扩张的回旋</h2><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/160d65f0d3fcf9ae68a118b8cd48b118.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*GpLyq1FRTyBvz8UuyUkqhg.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">扩张卷积</p></figure><p id="1c6c" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated"><a class="ae kf" href="https://paperswithcode.com/method/dilated-convolution#:~:text=Dilated%20Convolutions%20are%20a%20type,spaces%20inserted%20between%20kernel%20elements." rel="noopener ugc nofollow" target="_blank">膨胀卷积</a>是对自然卷积的一个微小修改，只增加了一个膨胀率参数。膨胀率只不过是在内核值之间消失的值的数量，即内核应该间隔多少步。它在内核的每个值之间定义了相等的空间。</p><p id="67f3" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated">在上图中，内核的大小是3x3，但是，它仍然广泛存在；这是由于它们之间产生了空间，膨胀率为2，因此行和列中的每一秒钟的值都消失了。膨胀率为2的3×3内核将具有与5×5内核相同的视野，而仅使用9个参数。扩张的卷积允许感受野的指数扩张，具有相同的计算能力并且没有任何损失。</p><h2 id="864c" class="md me iq bd mf mg mh dn mi mj mk dp ml lr mm mn mo lv mp mq mr lz ms mt mu mv bi translated">扩张的因果回旋</h2><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nw"><img src="../Images/6c897a1fc2593c1fbf62777713efa610.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AQT5CZYNWovnnTc7w7Nqlg.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">扩展因果卷积工作</p></figure><p id="a971" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated"><a class="ae kf" href="https://paperswithcode.com/method/dilated-causal-convolution" rel="noopener ugc nofollow" target="_blank">膨胀因果卷积</a>是WaveNet模型的主要组成部分之一。特定时间步长t的模型输出不依赖于未来的时间步长。因果卷积可以模拟具有长期依赖性的序列。与RNN相比，它们速度更快，因为它们没有循环连接。它们遵循数据建模方式中的数据排序。输出按顺序得到，反馈给模型得到下一个。因果卷积需要一个很宽的感受野，这个障碍被我们之前看到的膨胀技术克服了，它的工作效率很高，降低了计算成本。堆叠的扩张卷积使得网络在保持输入分辨率的同时，仅用几层就具有广泛的感受野。</p><h2 id="c300" class="md me iq bd mf mg mh dn mi mj mk dp ml lr mm mn mo lv mp mq mr lz ms mt mu mv bi translated">Wavenet架构</h2><p id="c359" class="pw-post-body-paragraph li lj iq lk b ll mw jr ln lo mx ju lq lr my lt lu lv mz lx ly lz na mb mc lg ij bi translated">使用WaveNet可以以自然的方式生成文本到语音的音频波形。该模型是来自计算机视觉、音频处理和时间序列的各种策略的组合。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nx"><img src="../Images/f42ae825c8ae3fdbb68654713527bbd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L5si_sjAVK7DbqpgKZ-fdQ.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">WaveNet架构</p></figure><p id="b453" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated">输入是从因果卷积层传递到残差块的音频样本。对于每个残差块，前一个块的输出将被馈入下一个块。<a class="ae kf" href="https://en.wikipedia.org/wiki/Gated_recurrent_unit#:~:text=Gated%20recurrent%20units%20%28GRUs%29%20are,it%20lacks%20an%20output%20gate." rel="noopener ugc nofollow" target="_blank">门控激活单元</a>的想法是从<a class="ae kf" href="https://keras.io/examples/generative/pixelcnn" rel="noopener ugc nofollow" target="_blank"> PixelCNN </a>实现的。残差块产生两个输出，一个是将被用作输入的特征图，第二个是用于计算损失的跳过连接。输入进一步通过扩展卷积层、门和滤波器，并彼此相遇，以逐元素相乘。其中⊙表示基于元素的乘法运算符，∵表示卷积运算符，σ是sigmoid函数，f和g表示滤波器和门。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/a36d82ebf8efcf31c78365f049adf887.png" data-original-src="https://miro.medium.com/v2/resize:fit:474/format:webp/1*-ThvxPCoFQCLhbNNnk3IYg.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">【<a class="ae kf" href="https://arxiv.org/pdf/1609.03499.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="49a3" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated">在整个网络中使用残差连接和参数化跳过连接的组合来加速收敛并实现更深层次的模型训练。该输入进一步与原始信息相加，并被下一个剩余黑色重新使用以产生输出。跳过连接通过整流线性单元被累加和激活，<a class="ae kf" href="https://en.wikipedia.org/wiki/Softmax_function" rel="noopener ugc nofollow" target="_blank"> Softmax </a>的最终结果不是一个连续值，但是我们应用了-law压扩变换，然后将其量化为256种可能性。<strong class="lk ir">根据论文，经过</strong> <a class="ae kf" href="https://en.wikipedia.org/wiki/Quantization#:~:text=Quantization%20is%20the%20process%20of,%28such%20as%20the%20integers%29." rel="noopener ugc nofollow" target="_blank"> <strong class="lk ir">量化</strong> </a> <strong class="lk ir">后的重构信号听起来与原始信号非常相似。</strong></p><p id="b57d" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated">Conditional Wavenet带来了更多的修改，具有所需的特性，如馈送多个实体的声音；我们还将向模型提供他们的身份。</p><h2 id="8c0e" class="md me iq bd mf mg mh dn mi mj mk dp ml lr mm mn mo lv mp mq mr lz ms mt mu mv bi translated">履行</h2><p id="e981" class="pw-post-body-paragraph li lj iq lk b ll mw jr ln lo mx ju lq lr my lt lu lv mz lx ly lz na mb mc lg ij bi translated">需要Python版本3.6或更高版本。克隆我的WaveNet存储库，并按照说明运行文件。</p><pre class="kh ki kj kk gt nz oa ob oc aw od bi"><span id="c446" class="md me iq oa b gy oe of l og oh">!git clone <a class="ae kf" href="https://github.com/AmitNikhade/WaveNet.git" rel="noopener ugc nofollow" target="_blank">https://github.com/AmitNikhade/WaveNet.git</a></span></pre><p id="ae25" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated">首先，我们将从安装需求开始。</p><pre class="kh ki kj kk gt nz oa ob oc aw od bi"><span id="3d9a" class="md me iq oa b gy oe of l og oh"> pip install -r requirements.txt</span></pre><p id="c7b7" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated">接下来，我们将使用自定义数据训练模型；在我的例子中，我使用了来自Kaggle的<strong class="lk ir">钢琴三和弦wavset </strong>数据集。我刚刚把它训练了20个纪元来充分地与你交流。您还必须定义数据路径。</p><pre class="kh ki kj kk gt nz oa ob oc aw od bi"><span id="14da" class="md me iq oa b gy oe of l og oh">!python3 ./WaveNet/src/train.py --dp piano-triads-wavset --epochs 20</span></pre><p id="3545" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated">训练开始了。</p><p id="e631" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated">现在是做音乐总监的时候了。生成定义保存路径和模型路径的音乐。</p><pre class="kh ki kj kk gt nz oa ob oc aw od bi"><span id="15e6" class="md me iq oa b gy oe of l og oh">!python ./WaveNet/src/generate.py --mp src/trained_model/modelWN.h5 --fs ./</span></pre><p id="b000" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated">你完了。</p><p id="9dc3" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated">尝试在至少1000个历元的足够数据上进行训练；你会看到杰出的成果。</p><p id="4ba9" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated">完整代码请访问<a class="ae kf" href="https://github.com/AmitNikhade/WaveNet" rel="noopener ugc nofollow" target="_blank"> Github </a>。</p><h2 id="e178" class="md me iq bd mf mg mh dn mi mj mk dp ml lr mm mn mo lv mp mq mr lz ms mt mu mv bi translated">要尝试的事情</h2><p id="8892" class="pw-post-body-paragraph li lj iq lk b ll mw jr ln lo mx ju lq lr my lt lu lv mz lx ly lz na mb mc lg ij bi translated">尝试实现股票价格预测模型等等，因为我们知道它也可以处理时间序列数据。此外，尝试通过手动调整参数来演奏一首好音乐。我希望你会。</p><h2 id="8d8e" class="md me iq bd mf mg mh dn mi mj mk dp ml lr mm mn mo lv mp mq mr lz ms mt mu mv bi translated">结论</h2><p id="0ebf" class="pw-post-body-paragraph li lj iq lk b ll mw jr ln lo mx ju lq lr my lt lu lv mz lx ly lz na mb mc lg ij bi translated">早期的TTS产生了有点机器人化的噪音，但是逐渐地，直到今天，音频处理的进步带来了更好的声音质量。Wavenet是一个更高级的模型，它将TTS提升到了一个新的水平，听起来非常清晰、不可重构、有规律，这使它成为许多TTS引擎背后的一个秘密。WaveNet需要太多的计算处理能力来用于现实世界的应用。</p><blockquote class="oi oj ok"><p id="7e27" class="li lj ol lk b ll nb jr ln lo nc ju lq om nd lt lu on ne lx ly oo nf mb mc lg ij bi translated">WaveNet随后被用于在所有谷歌平台上为美国英语和日语生成<a class="ae kf" href="https://en.wikipedia.org/wiki/Google_Assistant" rel="noopener ugc nofollow" target="_blank">谷歌助手</a>语音。-深度思维</p></blockquote><p id="fee5" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated">希望你发现这个主题和解释很有见地；试着在循环中读两遍来熟悉它。</p><h2 id="1189" class="md me iq bd mf mg mh dn mi mj mk dp ml lr mm mn mo lv mp mq mr lz ms mt mu mv bi translated">关于我</h2><p id="e9b0" class="pw-post-body-paragraph li lj iq lk b ll mw jr ln lo mx ju lq lr my lt lu lv mz lx ly lz na mb mc lg ij bi translated">最初发表于amitnikhade.com的<a class="ae kf" href="https://amitnikhade.com/" rel="noopener ugc nofollow" target="_blank"/></p><p id="9a04" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated">LinkedIn <a class="ae kf" href="https://www.linkedin.com/in/theamitnikhade/" rel="noopener ugc nofollow" target="_blank"> amitnikhade </a></p><p id="d832" class="pw-post-body-paragraph li lj iq lk b ll nb jr ln lo nc ju lq lr nd lt lu lv ne lx ly lz nf mb mc lg ij bi translated"><strong class="lk ir"> Github </strong></p><div class="op oq gp gr or os"><a href="https://github.com/AmitNikhade" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd ir gy z fp ox fr fs oy fu fw ip bi translated">AmitNikhade -概述</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">🂮 |人工智能和机器人爱好者|机器学习、深度学习、NLP、物联网、机器人| LinkedIn…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">github.com</p></div></div><div class="pb l"><div class="pc l pd pe pf pb pg kq os"/></div></div></a></div><h2 id="1fd4" class="md me iq bd mf mg mh dn mi mj mk dp ml lr mm mn mo lv mp mq mr lz ms mt mu mv bi translated">参考</h2><div class="op oq gp gr or os"><a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd ir gy z fp ox fr fs oy fu fw ip bi translated">WaveNet:原始音频的生成模型</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">这篇文章介绍了WaveNet，一个原始音频波形的深度生成模型。我们证明了波网能够产生…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">deepmind.com</p></div></div><div class="pb l"><div class="ph l pd pe pf pb pg kq os"/></div></div></a></div><div class="op oq gp gr or os"><a href="https://en.wikipedia.org/wiki/WaveNet" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd ir gy z fp ox fr fs oy fu fw ip bi translated">WaveNet -维基百科</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">WaveNet是一个用于生成原始音频的深度神经网络。它是由总部位于伦敦的人工…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">en.wikipedia.org</p></div></div><div class="pb l"><div class="pi l pd pe pf pb pg kq os"/></div></div></a></div><div class="op oq gp gr or os"><a href="https://arxiv.org/abs/1609.03499" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd ir gy z fp ox fr fs oy fu fw ip bi translated">WaveNet:原始音频的生成模型</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">本文介绍了WaveNet，一种用于生成原始音频波形的深度神经网络。该模型完全…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">arxiv.org</p></div></div><div class="pb l"><div class="pj l pd pe pf pb pg kq os"/></div></div></a></div><div class="op oq gp gr or os"><a href="https://paperswithcode.com/method/dilated-causal-convolution" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd ir gy z fp ox fr fs oy fu fw ip bi translated">论文与代码扩展因果卷积解释</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">扩展因果卷积是一种因果卷积，其中滤波器应用于比其长度大的区域…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">paperswithcode.com</p></div></div></div></a></div></div></div>    
</body>
</html>