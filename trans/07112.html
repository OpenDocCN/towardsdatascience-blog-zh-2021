<html>
<head>
<title>Stacked Autoencoders.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">堆叠式自动编码器。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/stacked-autoencoders-f0a4391ae282?source=collection_archive---------4-----------------------#2021-06-28">https://towardsdatascience.com/stacked-autoencoders-f0a4391ae282?source=collection_archive---------4-----------------------#2021-06-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="46df" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用深度学习从数据中提取重要特征。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c7f4cd999c551e32f4168e1a8e8da18a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IMJzSuq7Le49kZbd"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">米卡·鲍梅斯特在<a class="ae kv" href="https://www.google.com/url?q=https://unsplash.com?utm_source%3Dmedium%26utm_medium%3Dreferral&amp;sa=D&amp;source=editors&amp;ust=1624895991419000&amp;usg=AOvVaw1j4VZKsVAgpSRfjdpWMGWx" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="9a49" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">降维</h2><p id="3fbe" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在解决数据科学问题时，您是否遇到过包含数百个要素的数据集？或者一千个特征？如果没有，那么你就不知道开发一个高效的模型会有多大的挑战性。对于那些不知道的人来说，降维是一种从数据中过滤出本质特征的方法。</p><p id="1b2f" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">数据中的输入要素越多，预测从属要素的任务就越困难。大量的元素有时会导致模型性能不佳。这背后的原因可能是模型可能试图找到特征向量和输出向量之间的关系，这种关系非常弱或不存在。有各种方法可以用来降低数据的维度，在下面的链接中可以找到关于这方面的综合指南。</p><p id="080e" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><a class="ae kv" href="https://www.google.com/url?q=https://www.analyticsvidhya.com/blog/2018/08/dimensionality-reduction-techniques-python/&amp;sa=D&amp;source=editors&amp;ust=1624895991421000&amp;usg=AOvVaw0xNWIY2krKFIOEiNke7AgA" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2018/08/dimensionally-reduction-techniques-python/</a></p><h2 id="08ee" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">主成分分析</h2><p id="ee95" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">主成分分析是一种常用的降维方法。主成分分析可以帮助你找到最相关的特征向量。这组新的特征称为主成分。提取第一个主成分，以便它解释数据集中的最大变化。第二个中心成分与第一个无关，试图解释数据集中的其余变化。第三个主成分试图解释前两个主成分解释不了的解释，以此类推。尽管这种方法有助于我们降低维数，但是PCA仅在从属特征和独立特征之间的关系是线性时才有效。要更深入地了解PCA，请访问下面的链接。</p><p id="e25e" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><a class="ae kv" href="https://www.google.com/url?q=https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c&amp;sa=D&amp;source=editors&amp;ust=1624895991422000&amp;usg=AOvVaw2cKybkuO17TV0RofbdLpY9" rel="noopener ugc nofollow" target="_blank">https://towards data science . com/a-一站式主成分分析-5582fb7e0a9c </a></p><h2 id="cac4" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">自动编码器</h2><p id="453d" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">当非线性函数描述从属和独立特征之间的关系时，自动编码器用于减少数据的维数。自动编码器是一种无监督的人工神经网络。自动编码器用于从数据中自动提取特征。它是最有前途的特征提取工具之一，用于各种应用，如语音识别、自动驾驶汽车、人脸对齐/人体手势检测。下图显示了自动编码器的架构</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/a4a52dcc807d7bee7459c9ec95b8151f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ETohyQVhOoLiZxdc"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">自动编码器来源:<a class="ae kv" href="https://www.google.com/url?q=https://www.jeremyjordan.me/autoencoders/&amp;sa=D&amp;source=editors&amp;ust=1624895991423000&amp;usg=AOvVaw3KPd8tI-FjSSVK90ZJiRrW" rel="noopener ugc nofollow" target="_blank">自动编码器介绍。</a></p></figure><p id="be98" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如上图所示，自动编码器架构分为三个部分:编码器、瓶颈和解码器。编码器从数据中挑选关键特征，而解码器试图使用关键成分来重建原始数据。通过仅保留重建数据所需的特征，自动编码器降低了数据维度。自动编码器是一种前馈网络，可以使用与前馈网络相同的过程来训练。自动编码器的输出与输入相同，但有一些损耗。因此，自动编码器也被称为有损压缩技术。此外，如果我们在每个编码器和解码器中有一个具有线性激活函数的密集层，则自动编码器可以像PCA一样执行。</p><h2 id="e78f" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">堆叠自动编码器</h2><p id="2917" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">一些数据集的要素之间存在复杂的关系。因此，仅使用一个自动编码器是不够的。单个自动编码器可能无法降低输入特征的维数。因此，对于这样的用例，我们使用堆栈式自动编码器。顾名思义，堆叠式自动编码器是多个编码器堆叠在一起。下图显示了一个堆叠式自动编码器，其中三个编码器堆叠在一起。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/aa504f0d3aba93c1af5e9e1115ed4e83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9etlfhalsPFJ8Eh_Cmlobg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="66a8" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">根据上图所示的架构，输入数据首先提供给自动编码器1。然后，自动编码器1的输出和自动编码器1的输入作为自动编码器2的输入。类似地，自动编码器2的输出和自动编码器2的输入作为自动编码器3的输入给出。因此，自动编码器3的输入向量的长度是自动编码器2的输入的两倍。这种技术在一定程度上也有助于解决数据不足的问题。</p><h2 id="b5f1" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">使用python实现堆栈式自动编码器</h2><p id="beaa" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">为了演示堆叠式自动编码器，我们使用振动信号的快速傅立叶变换(FFT)。FFT振动信号用于故障诊断和许多其他应用。数据具有非常复杂的模式，因此单个自动编码器无法降低数据的维数。下图是FFT波形图。FFT的幅度被变换到0和1之间。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/c9baa6f344f35a4e902ab8befcb0bbc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CSmEE8uhHWliq53L"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="6bbf" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">为了更好的直观理解，我们将信号重塑成63*63的矩阵，并绘制出来(由于是振动信号转换成图像，所以要半信半疑)。下图是振动信号的图像表示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/53cf55dfac9acdf5db88d8e91a8bf1a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/0*UXosx_39-D6-XLzz"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="e1b1" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">我知道在这幅图像中很难看到很多东西。不过，我们还是能在图中看到几个特征。大约在(0，15)处拍摄的亮白色是振动信号FFT中的峰值。</p><p id="459d" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">现在我们开始创建我们的自动编码器。</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="a46d" class="kw kx iq mv b gy mz na l nb nc">batch_size = 32<br/>input_dim = x_train[0].shape[0] #num of predictor variables learning_rate = 1e-5<br/>input_layer = Input(shape=(input_dim, ), name=”input”)</span><span id="8d62" class="kw kx iq mv b gy nd na l nb nc">#Input Layer<br/>encoder = Dense (2000, activation=”relu”, activity_regularizer=regularizers.l1(learning_rate))(input_layer)</span><span id="92fb" class="kw kx iq mv b gy nd na l nb nc">#Encoder’s first dense layer<br/>encoder = Dense (1000, activation=”relu”,<br/>activity_regularizer=regularizers.l1(learning_rate))(encoder)</span><span id="4f2f" class="kw kx iq mv b gy nd na l nb nc">#Encoder’s second dense layer<br/>encoder = Dense (500, activation=”relu”, activity_regularizer=regularizers.l1(learning_rate))(encoder)</span><span id="fc67" class="kw kx iq mv b gy nd na l nb nc"># Code layer<br/>encoder = Dense (200, activation=”relu”, activity_regularizer=regularizers.l1(learning_rate))(encoder)</span><span id="3e30" class="kw kx iq mv b gy nd na l nb nc"># Decoder’s first dense layer<br/>decoder = Dense(500, activation=”relu”, activity_regularizer=regularizers.l1(learning_rate))(encoder)</span><span id="ac0e" class="kw kx iq mv b gy nd na l nb nc"># Decoder’s second dense layer<br/>decoder = Dense(1000, activation=”relu”, activity_regularizer=regularizers.l1(learning_rate))(decoder)</span><span id="8699" class="kw kx iq mv b gy nd na l nb nc"># Decoder’s Third dense layer<br/>decoder = Dense(2000, activation=”relu”, activity_regularizer=regularizers.l1(learning_rate))(decoder)</span><span id="a02d" class="kw kx iq mv b gy nd na l nb nc"># Output Layer<br/>decoder = Dense(input_dim, activation=”sigmoid”, activity_regularizer=regularizers.l1(learning_rate))(decoder)</span></pre><p id="2ae0" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">上面设计的自动编码器在两侧有两个密集层:编码器和解码器。请注意，每个解码器和编码器中的神经元数量是相同的。此外，解码器是编码器的镜像。</p><p id="0f15" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">正如我们所见，FFT信号有4000个数据点；因此，我们的输入和输出层有4000个神经元。当我们深入网络时，神经元的数量随之减少。最后，在代码层，我们只有200个神经元。因此，这个自动编码器试图将特征的数量从4000减少到200。</p><p id="d492" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">现在，我们构建模型，编译它，并根据我们的训练数据进行拟合。由于自动编码器的目标输出与输入相同，我们将x_train作为输入和输出传递。</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="e9e0" class="kw kx iq mv b gy mz na l nb nc">autoencoder_1 = Model(inputs=input_layer, outputs=decoder)</span><span id="9a2d" class="kw kx iq mv b gy nd na l nb nc">autoencoder_1.compile(metrics=[‘accuracy’],loss=’mean_squared_error’,optimizer=’adam’)</span><span id="7711" class="kw kx iq mv b gy nd na l nb nc">satck_1 = autoencoder_1.fit(x_train, x_train,epochs=200,batch_size=batch_size)</span></pre><p id="006e" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">一旦我们训练了我们的第一个自动编码器，我们连接第一个自动编码器的输出和输入。</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="0b42" class="kw kx iq mv b gy mz na l nb nc">autoencoder_2_input = autoencoder_1.predict(x_train)</span><span id="4559" class="kw kx iq mv b gy nd na l nb nc">autoencoder_2_input = np.concatenate((autoencoder_2_input , x_train))</span></pre><p id="7dd2" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">现在，自动编码器2的输入准备就绪。因此，我们在新的数据集上构建、编译和训练autoencoder 2。</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="39f3" class="kw kx iq mv b gy mz na l nb nc">autoencoder_2 = Model(inputs=input_layer, outputs=decoder)</span><span id="7bd8" class="kw kx iq mv b gy nd na l nb nc">autoencoder_2.compile(metrics=[‘accuracy’],loss=’mean_squared_error’,optimizer=’adam’)</span><span id="a863" class="kw kx iq mv b gy nd na l nb nc">satck_2 = autoencoder_2.fit(autoencoder_2_input, autoencoder_2_input,epochs=100,batch_size=batch_size)</span></pre><p id="f0c1" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">一旦我们训练了我们的自动编码器2，我们就开始训练我们的第三个自动编码器。正如我们对第二个自动编码器所做的那样，第三个自动编码器的输入是第二个自动编码器的输出和输入的串联。</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="36d6" class="kw kx iq mv b gy mz na l nb nc">autoencoder_3_input = autoencoder_2.predict(autoencoder_2_input)</span><span id="0324" class="kw kx iq mv b gy nd na l nb nc">autoencoder_3_input = np.concatenate((autoencoder_3_input, autoencoder_2_input))</span></pre><p id="3c6b" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">现在，最后，我们训练第三个自动编码器。正如我们对上两个编码器所做的那样，我们对新数据进行构建、编译和训练。</p><pre class="kg kh ki kj gt mu mv mw mx aw my bi"><span id="9671" class="kw kx iq mv b gy mz na l nb nc">autoencoder_2 = Model(inputs=input_layer, outputs=decoder)</span><span id="45ea" class="kw kx iq mv b gy nd na l nb nc">autoencoder_3.compile(metrics=[‘accuracy’], loss=’mean_squared_error’, optimizer=’adam’)</span><span id="839f" class="kw kx iq mv b gy nd na l nb nc">satck_3 = autoencoder_3.fit(autoencoder_3_input, autoencoder_3_input, epochs=50, batch_size=16)</span></pre><p id="af5d" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在训练我们的堆叠式自动编码器之后，我们达到了大约90%的准确率。这意味着我们的堆叠式自动编码器可以以大约90%的准确度重建我们的原始输入信号。</p><p id="d060" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">原始信号和重建信号的图像如下所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/958d89cf1c233351fbae37aeb1b83b6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*UrY_1nZ7ky5Fr5guq2GBDQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure></div></div>    
</body>
</html>