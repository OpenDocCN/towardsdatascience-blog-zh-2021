<html>
<head>
<title>Train Your Own Variational Auto-Encoder for Sound Generation with AWS SageMaker</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用AWS SageMaker训练您自己的声音生成可变自动编码器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/train-your-own-variational-auto-encoder-for-sound-generation-with-aws-sagemaker-1ecb82918695?source=collection_archive---------34-----------------------#2021-07-22">https://towardsdatascience.com/train-your-own-variational-auto-encoder-for-sound-generation-with-aws-sagemaker-1ecb82918695?source=collection_archive---------34-----------------------#2021-07-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9868" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在脚本模式下使用AWS SageMaker训练您的定制TensorFlow模型的简单方法。</h2></div><p id="7ad7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">经过10个小时的训练，我进入了150个纪元中的第22个，我意识到3000 wav文件数据集对于我5岁的MacBook Pro来说有点难以接受。<a class="ae lb" href="https://github.com/Jakobovski/free-spoken-digit-dataset" rel="noopener ugc nofollow" target="_blank">自由口述数字数据集</a>包含来自6个说话者的录音，每个说话者50个8kHz <em class="lc">的数字。wav </em>格式。当我在跟踪Valerio Velardo的关于神经网络  <em class="lc"> </em>声音生成的优秀视频系列时，我发现自己陷入了一个无休止的训练阶段。目标是训练一个定制的可变自动编码器来生成声音数字。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/41c2f3538b8d3a275e8d8a267ba59a03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2OafwP-J2GwbK7jC"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">Pawel Czerwinski 在<a class="ae lb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="3c52" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">FSDD wav文件的预处理在本地进行，并在<em class="lc">中生成3000个光谱图的训练数据集。npy </em>格式(我的TensorFlow模型的预期输入格式)。虽然SageMaker现在支持各种数据源，如<em class="lc">亚马逊FSx </em>和<em class="lc">亚马逊EFS </em>，但我将训练数据集上传到了位于美国东一区(N. Virginia)的<em class="lc"> S3 </em>的一个桶中。请注意这一点，因为SageMaker需要与您的铲斗在同一区域。</p><p id="0d79" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我的源代码由两个文件组成:</p><ul class=""><li id="6b81" class="lt lu iq kh b ki kj kl km ko lv ks lw kw lx la ly lz ma mb bi translated"><em class="lc"> autoencoder.py </em> —自动编码器“<em class="lc"> VAE </em>”类定义:具有镜像编码器/解码器和潜在空间的深度卷积自动编码器。包含所有TensorFlow库导入。</li><li id="bcb4" class="lt lu iq kh b ki mc kl md ko me ks mf kw mg la ly lz ma mb bi translated"><em class="lc"> train.py </em> —训练初始化:访问训练数据，实例化模型，定义所有参数(输入形状、滤波器、核、步幅、潜在空间维度和各种超参数)。包含从<em class="lc"> autoencoder.py </em>导入的<em class="lc"> VAE </em>类</li></ul><p id="2b8c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这两个文件在本地培训时在我的本地硬盘上协同工作，但是如何转移到云中呢？</p><h1 id="ba9a" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">与SageMaker一起训练</h1><p id="3356" class="pw-post-body-paragraph kf kg iq kh b ki mz jr kk kl na ju kn ko nb kq kr ks nc ku kv kw nd ky kz la ij bi translated">SageMaker主要提供了5种训练模型的方法:</p><ul class=""><li id="ab55" class="lt lu iq kh b ki kj kl km ko lv ks lw kw lx la ly lz ma mb bi translated">内置算法</li><li id="d8d0" class="lt lu iq kh b ki mc kl md ko me ks mf kw mg la ly lz ma mb bi translated">脚本模式</li><li id="f0e1" class="lt lu iq kh b ki mc kl md ko me ks mf kw mg la ly lz ma mb bi translated">码头集装箱</li><li id="d986" class="lt lu iq kh b ki mc kl md ko me ks mf kw mg la ly lz ma mb bi translated">市场</li><li id="6a00" class="lt lu iq kh b ki mc kl md ko me ks mf kw mg la ly lz ma mb bi translated">笔记本实例</li></ul><p id="253d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们的特殊情况下，脚本模式是可行的，因为我们提供了在TensorFlow兼容的容器(由AWS管理)中执行的源代码。</p><p id="ff9f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">选择一个基本的SageMaker笔记本配置(一个<em class="lc"> ml.t2.medium </em>就可以了)，确保附加的<em class="lc"> IAM-execution-role </em>允许访问您的S3 bucket，并从管理控制台启动实例(与bucket在同一区域)。在脚本模式下，注意这个SageMaker笔记本实例只用于脚本启动，不用于培训。</p><p id="4502" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我将我的源代码上传到SageMaker笔记本实例存储的工作目录中，在那里我还创建了自己的<em class="lc"> script.ipynb </em>来编排培训过程。在这个脚本中，我包含了以下导入:</p><pre class="le lf lg lh gt ne nf ng nh aw ni bi"><span id="bb23" class="nj mi iq nf b gy nk nl l nm nn">import sagemaker<br/>from sagemaker.tensorflow import TensorFlow<br/>import boto3</span></pre><p id="6b75" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我将所有有用的SageMaker变量定义如下:</p><pre class="le lf lg lh gt ne nf ng nh aw ni bi"><span id="3af6" class="nj mi iq nf b gy nk nl l nm nn">bucket = 'mytrainingdatabucket'<br/>role = sagemaker.get_execution_role()</span><span id="9953" class="nj mi iq nf b gy no nl l nm nn">numpy_train_s3_prefix = f"<strong class="nf ir">{</strong>bucket<strong class="nf ir">}</strong>/spectrograms"<br/>numpy_train_s3_uri = f"s3://<strong class="nf ir">{</strong>numpy_train_s3_prefix<strong class="nf ir">}</strong>"</span><span id="c3dc" class="nj mi iq nf b gy no nl l nm nn">inputs = {'data' : numpy_train_s3_uri}</span></pre><p id="8085" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最重要的是，<em class="lc">估算器</em>处理所有端到端的SageMaker训练任务。以下是需要特别注意的参数:</p><ul class=""><li id="31e4" class="lt lu iq kh b ki kj kl km ko lv ks lw kw lx la ly lz ma mb bi translated"><em class="lc">入口点</em>:你的训练代码的路径(在我的例子中是<em class="lc"> train.py </em>)</li><li id="e8a8" class="lt lu iq kh b ki mc kl md ko me ks mf kw mg la ly lz ma mb bi translated"><em class="lc"> source_dir </em>:剩余源代码的路径(依赖、库等)。</li><li id="ba01" class="lt lu iq kh b ki mc kl md ko me ks mf kw mg la ly lz ma mb bi translated"><em class="lc"> model_dir </em>:指定你的代码将你的算法生成的模型写入容器的预期位置，通常为'<em class="lc"> opt/ml/model </em>'。在训练结束时，SageMaker获取它在'<em class="lc"> opt/ml/model </em>'中找到的任何东西，并将其输出给S3。</li><li id="001f" class="lt lu iq kh b ki mc kl md ko me ks mf kw mg la ly lz ma mb bi translated">去找一个强大的，因为它只会用于训练。</li><li id="f251" class="lt lu iq kh b ki mc kl md ko me ks mf kw mg la ly lz ma mb bi translated"><em class="lc"> output_path </em>:保存模型工件和输出文件的S3路径。</li><li id="b363" class="lt lu iq kh b ki mc kl md ko me ks mf kw mg la ly lz ma mb bi translated"><em class="lc"> script_mode </em> : boolean，在这种情况下选择<em class="lc"> True </em>。</li></ul><p id="9b6a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是我如何为AWS管理的TensorFlow兼容容器初始化我的<em class="lc"> estimator </em>实例:</p><pre class="le lf lg lh gt ne nf ng nh aw ni bi"><span id="509e" class="nj mi iq nf b gy nk nl l nm nn">estimator = TensorFlow(entry_point='train.py',<br/>                       source_dir='.',<br/>                       model_dir = "/opt/ml/model",<br/>                       train_instance_type='ml.p2.xlarge',<br/>                       output_path=f"s3://<strong class="nf ir">{</strong>bucket<strong class="nf ir">}</strong>/output",<br/>                       train_instance_count=1,<br/>                       role=sagemaker.get_execution_role(), <br/>                       framework_version='2.0',<br/>                       py_version='py3',<br/>                       script_mode=<strong class="nf ir">True</strong>)</span></pre><p id="1a34" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，将通过调用估计器上的<em class="lc"> fit() </em>来启动训练，如下所示，但在此之前，我们需要定义下一段中描述的所有环境变量。</p><pre class="le lf lg lh gt ne nf ng nh aw ni bi"><span id="85d7" class="nj mi iq nf b gy nk nl l nm nn">estimator.fit(inputs)</span></pre><h1 id="a5de" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">环境变量</h1><p id="ce2f" class="pw-post-body-paragraph kf kg iq kh b ki mz jr kk kl na ju kn ko nb kq kr ks nc ku kv kw nd ky kz la ij bi translated">我在我的<em class="lc"> train.py </em>文件中实现了<em class="lc"> parse_args() </em>函数来收集所有必要的SageMaker环境变量，比如路径和超参数:</p><pre class="le lf lg lh gt ne nf ng nh aw ni bi"><span id="374b" class="nj mi iq nf b gy nk nl l nm nn">def parse_args():</span><span id="ba5b" class="nj mi iq nf b gy no nl l nm nn"> parser = argparse.ArgumentParser()        </span><span id="0413" class="nj mi iq nf b gy no nl l nm nn"> parser.add_argument('--epochs', type=int, default=150)<br/> parser.add_argument('--batch_size', type=int, default=64)<br/> parser.add_argument('--learning_rate', type=float, default=0.0005)      </span><span id="7b59" class="nj mi iq nf b gy no nl l nm nn"> # data directories    <br/> parser.add_argument('--data', type=str,<br/> default=os.environ.get('SM_CHANNEL_DATA'))    </span><span id="1908" class="nj mi iq nf b gy no nl l nm nn"> parser.add_argument('--output', type=str,<br/> default=os.environ.get('SM_CHANNEL_OUTPUT'))    </span><span id="eba6" class="nj mi iq nf b gy no nl l nm nn"> parser.add_argument('--train', type=str,<br/> default=os.environ.get('SM_CHANNEL_TRAIN'))       </span><span id="a7f7" class="nj mi iq nf b gy no nl l nm nn"> parser.add_argument('--model_dir', type=str,<br/> default=os.environ.get('SM_MODEL_DIR'))</span><span id="20fe" class="nj mi iq nf b gy no nl l nm nn"> return parser.parse_known_args()</span></pre><p id="2264" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我可以加载训练数据:</p><pre class="le lf lg lh gt ne nf ng nh aw ni bi"><span id="0964" class="nj mi iq nf b gy nk nl l nm nn">x_train = get_train_data(args.data)</span></pre><p id="895a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后我可以实例化<em class="lc"> VAE </em>类，并相应地调用训练方法:</p><pre class="le lf lg lh gt ne nf ng nh aw ni bi"><span id="3bed" class="nj mi iq nf b gy nk nl l nm nn">autoencoder = train(x_train, args.learning_rate, args.batch_size, args.epochs)</span></pre><p id="f098" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，一旦模型训练完毕，我就可以从<em class="lc"> VAE </em>类中调用<em class="lc"> save() </em>方法<em class="lc"> </em>来将我的模型工件(<em class="lc"> parameters.pkl </em>和<em class="lc"> weights.h5 </em>)存储在'<em class="lc"> opt/ml/model </em>'中。这一步是必不可少的，因为SageMaker不会自动保存你的模型，而是简单地获取容器文件夹中的内容。因此，请明确执行此操作:</p><pre class="le lf lg lh gt ne nf ng nh aw ni bi"><span id="3bd0" class="nj mi iq nf b gy nk nl l nm nn">autoencoder.save(args.model_dir)</span></pre><p id="c0db" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就是这样！下面是我的<em class="lc"> script.ipynb </em>的执行快照:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi np"><img src="../Images/ffe513e1bfe03e95d15af90a1ed79ee9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WOJpyc8uvGTpllZTz-apvA.png"/></div></div></figure><h1 id="ce81" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">结论</h1><p id="5b7c" class="pw-post-body-paragraph kf kg iq kh b ki mz jr kk kl na ju kn ko nb kq kr ks nc ku kv kw nd ky kz la ij bi translated">如上所述，培训工作需要大约2个小时才能完成，费用大约为。根据我在自由层帐户上的<em class="lc"> AWS计费仪表板</em>，3.20美元(计算+存储)。</p><p id="adf9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">新生成的模型存储在我的“<em class="lc">输出/ </em>文件夹的<em class="lc"> S3 </em>桶中，并以8.4 MB<em class="lc">model.tar.gz</em>档案的形式出现。下载并解压后，我能够使用<em class="lc"> VAE </em>类的<em class="lc"> load() </em>方法，并成功地做出推理来生成声音。以下是我的模型生成的“<em class="lc">零</em>”声音数字的示例:</p><div class="nq nr gp gr ns nt"><a href="https://soundcloud.com/msaintfelix/zero" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd ir gy z fp ny fr fs nz fu fw ip bi translated">零</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">流零由msaintfelix在桌面和移动。在SoundCloud上免费播放超过2.65亿首歌曲。</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">soundcloud.com</p></div></div></div></a></div><p id="4fa7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">查看我的<a class="ae lb" href="https://github.com/msaintfelix/Training_Custom_VAE_Model_in_AWS_SageMaker" rel="noopener ugc nofollow" target="_blank"> GitHub资源库</a>这个项目，感谢阅读！</p></div></div>    
</body>
</html>