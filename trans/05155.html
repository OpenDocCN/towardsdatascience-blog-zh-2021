<html>
<head>
<title>Online Learning: Recursive Least Squares and Online PCA</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在线学习:递归最小二乘法和在线PCA</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/online-learning-recursive-least-squares-and-online-pca-c05bd23106c9?source=collection_archive---------11-----------------------#2021-05-06">https://towardsdatascience.com/online-learning-recursive-least-squares-and-online-pca-c05bd23106c9?source=collection_archive---------11-----------------------#2021-05-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4676" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">关于如何创建能够在处理流数据时训练一个数据点的在线机器学习模型的实用介绍</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7f28ac76e17c1d3a4db32255e2c8d9a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*34AxmKyhZ904m28o"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@o12?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> O12 </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><h1 id="843d" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">在线学习</h1><p id="35fe" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在线学习是机器学习的一个子集，它强调从环境中生成的数据会随着时间而变化。</p><p id="dd5e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">事实上，传统的机器学习模型被认为是静态的:一旦模型根据一组数据进行训练，它的参数就不再改变。尽管环境及其生成的数据可能会随着时间的推移而改变，因此，我们预先训练的模型不再可靠。</p><p id="1a68" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了解决这些问题，公司通常使用的一种简单解决方案是，一旦性能开始下降，自动重新训练和部署机器学习模型的更新版本。</p><p id="1a3c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">但是，使用这种方法会导致模型周期性地表现得比预期的标准更差[1]。然后可以使用在线学习来为这个问题提供一个明确的答案。</p><p id="1c05" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你对用Python实现在线学习算法感兴趣，<a class="ae ky" href="https://github.com/online-ml/river" rel="noopener ugc nofollow" target="_blank"> Creme库</a>是一个很好的起点。</p><p id="60ce" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">本文中使用的所有代码都是可用的(甚至更多！)在我的GitHub个人资料上有<a class="ae ky" href="https://github.com/pierpaolo28/Artificial-Intelligence-Projects/tree/master/Online%20Learning" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="851e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">递归最小二乘法</h1><h2 id="6049" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">介绍</h2><p id="3abe" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">递归最小二乘法(RLS)是一种用于研究实时数据的常用技术。因此，RLS可以被认为是标准最小二乘算法的递归等价物。</p><p id="9556" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在递归最小二乘法中，在每次算法迭代中分析单个新数据点，以便改进我们的模型参数的估计(在这种情况下，目标不是像最小均方误差那样最小化总均方误差)。</p><p id="3d2b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">与其他回归技术相比，RLS通常收敛速度更快，但计算成本更高。</p><p id="0c7d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">关于该算法的两个重要观察结果是:</p><ul class=""><li id="bec6" class="ne nf it lt b lu mn lx mo ma ng me nh mi ni mm nj nk nl nm bi translated">使用一个名为Lambda ( <strong class="lt iu"> <em class="nn"> λ </em> </strong>)的用户定义参数来定义给予过去输入数据的权重(旧输入的预测权重低于新输入)。<strong class="lt iu"> <em class="nn"> λ </em> </strong>的值越小，过去输入值的重要性越低。</li><li id="4569" class="ne nf it lt b lu no lx np ma nq me nr mi ns mm nj nk nl nm bi translated">为了避免在每个迭代步骤中计算矩阵求逆(这在计算上可能是昂贵的)，我们可以改为应用<a class="ae ky" href="https://en.wikipedia.org/wiki/Woodbury_matrix_identity" rel="noopener ugc nofollow" target="_blank">矩阵求逆引理</a>。</li></ul><p id="d532" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你对这个算法的实现细节感兴趣，数学推导可以在麻省理工学院开放课件[2]的“动态系统与控制讲座”中找到。</p><h2 id="e3a0" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">示范</h2><p id="5e84" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了测试这个算法，我们将在本文中使用来自UCI机器学习库的<br/> <a class="ae ky" href="https://archive.ics.uci.edu/ml/datasets/Daily+Demand+Forecasting+Orders" rel="noopener ugc nofollow" target="_blank">每日需求预测订单数据集。</a></p><p id="4c5d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">首先，我们需要导入所需的依赖项，并将数据集划分为要素和标签。在本练习中，我们的目标是在给定输入特征的情况下预测订单总数(图1)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/e923c48ebd50ba499b455e30d9907691.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jwoqQ1CcnP7lFC1X2piyPQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1:每日需求预测订单数据集</p></figure><p id="82a5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在，我们可以创建自己的递归最小二乘算法实现，并检查我们的残差。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="e668" class="ms la it nx b gy ob oc l od oe">Residual Error:  0.851</span></pre><p id="0fb1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如低残差所示，我们的算法似乎已经成功地收敛到相对可靠的解决方案。这可以通过比较我们在相同任务中使用小批量梯度下降算法的结果来进一步证实(图2)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/9d2b5457cc18359d748c5167d8063415.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h0xRQUkwenTRpGqkhVOdYw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图2:递归最小二乘法与小批量梯度下降</p></figure><p id="8e7e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">绘制实际时间序列值与递归最小二乘估计值，我们可以进一步确认这个简单问题模型的可靠性(图3)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/5cd4fe35832088c61e4ad3021482ca38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xMpVnorMmASwhx0PbepMnQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3:总订单估算比较</p></figure><p id="8e2b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最后，通过创建一个简单的函数，我们可以将我们的模型的总体残差与一些常见的Scikit-Learn模型进行比较，以比较性能。如下面的结果所示，高斯过程回归器似乎比递归最小二乘法表现得更好。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="6c61" class="ms la it nx b gy ob oc l od oe">SGDRegressor Residual Error:  83.905<br/>DecisionTreeRegressor Residual Error:  84.853<br/>GaussianProcessRegressor Residual Error:  0.0<br/>KNeighborsRegressor Residual Error:  2.296<br/>BayesianRidge Residual Error:  84.853<br/>MLPRegressor Residual Error:  84.661</span></pre><h1 id="440b" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">在线主成分分析</h1><p id="e368" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">当处理具有大量特征的数据集时，在线PCA当然可以被认为是一种很好的实现技术，以便尝试降低我们问题的维数，同时加快执行速度并将我们的误差限制在用户定义的限度内。在线主成分分析试图将主成分分析的相同基本概念应用于在线环境中，通过每次将一个数据点作为输入来创建其估计值。</p><p id="c119" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">该算法的一个主要参数是ε(<strong class="lt iu"><em class="nn">)ε</em></strong>)。ε是我们可以容忍的给定数据(误差)。然后，该算法将返回一个<strong class="lt iu"> <em class="nn"> l </em> </strong>维度表示(O(<strong class="lt iu"><em class="nn">k</em></strong>×poly(1/<strong class="lt iu"><em class="nn">ε</em></strong>))略高于所需的<strong class="lt iu"> <em class="nn"> k </em> </strong>维度表示(但仍低于原始的<strong class="lt iu"> <em class="nn"> d </em> </strong>维度表示)。</p><p id="167a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">使用小的<strong class="lt iu"> <em class="nn"> ε </em> </strong>，我们迫使我们的算法不能容忍太多的误差，因此这将导致<strong class="lt iu"> <em class="nn"> l </em> </strong>的高值。使用高<strong class="lt iu"> <em class="nn"> ε </em> </strong>来代替，我们允许我们的算法容忍高误差，并且允许使用低值用于<strong class="lt iu"> <em class="nn"> l </em> </strong>。按照Boutsidis等人[3]的实现，<strong class="lt iu"> <em class="nn"> ε </em> </strong>可以用0到1/15之间的任意值来表示。通过这种方式，在线PCA允许我们在期望的维度和最大允许误差之间进行权衡。</p><p id="99a6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">使用该算法的一些额外优点是:</p><ol class=""><li id="d378" class="ne nf it lt b lu mn lx mo ma ng me nh mi ni mm og nk nl nm bi translated">在线PCA可以使我们在更低的维度上进行推理，对输入数据进行降噪，并实现重要的计算节省(特别是在处理属于大数据机制的数据集时)。</li><li id="36f8" class="ne nf it lt b lu no lx np ma nq me nr mi ns mm og nk nl nm bi translated">使用在线PCA的优化版本，可以避免计算整个协方差矩阵(可能相当大)的所有特征值和特征向量，而是只计算我们感兴趣的第一个<strong class="lt iu"> <em class="nn"> N个</em> </strong>特征值和特征向量。</li></ol><p id="30dd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果您对实现在线PCA感兴趣，<a class="ae ky" href="https://www.cs.yale.edu/homes/el327/papers/opca.pdf" rel="noopener ugc nofollow" target="_blank"> Boutsidis等人[3]的出版物</a>是一个很好的起点。</p></div><div class="ab cl oh oi hx oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="im in io ip iq"><p id="0365" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">希望你喜欢这篇文章，谢谢你的阅读！</p><h1 id="cee7" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">联系人</h1><p id="d84d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如果你想了解我最新的文章和项目<a class="ae ky" href="https://pierpaoloippolito28.medium.com/subscribe" rel="noopener">，请通过媒体</a>关注我，并订阅我的<a class="ae ky" href="http://eepurl.com/gwO-Dr?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">邮件列表</a>。以下是我的一些联系人详细信息:</p><ul class=""><li id="aa98" class="ne nf it lt b lu mn lx mo ma ng me nh mi ni mm nj nk nl nm bi translated"><a class="ae ky" href="https://uk.linkedin.com/in/pier-paolo-ippolito-202917146?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">领英</a></li><li id="b3c3" class="ne nf it lt b lu no lx np ma nq me nr mi ns mm nj nk nl nm bi translated"><a class="ae ky" href="https://pierpaolo28.github.io/blog/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">个人博客</a></li><li id="6b85" class="ne nf it lt b lu no lx np ma nq me nr mi ns mm nj nk nl nm bi translated"><a class="ae ky" href="https://pierpaolo28.github.io/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">个人网站</a></li><li id="26ed" class="ne nf it lt b lu no lx np ma nq me nr mi ns mm nj nk nl nm bi translated"><a class="ae ky" href="https://towardsdatascience.com/@pierpaoloippolito28?source=post_page---------------------------" rel="noopener" target="_blank">中型简介</a></li><li id="b1c4" class="ne nf it lt b lu no lx np ma nq me nr mi ns mm nj nk nl nm bi translated"><a class="ae ky" href="https://github.com/pierpaolo28?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> GitHub </a></li><li id="e81e" class="ne nf it lt b lu no lx np ma nq me nr mi ns mm nj nk nl nm bi translated"><a class="ae ky" href="https://www.kaggle.com/pierpaolo28?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">卡格尔</a></li></ul><h1 id="0086" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">文献学</h1><p id="3b79" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">[1]什么是在线机器学习？马克斯·佩格尔斯，四种。访问:<a class="ae ky" href="https://medium.com/value-stream-design/online-machine-learning-515556ff72c5" rel="noopener">https://medium . com/value-stream-design/online-machine-learning-515556 ff 72 C5</a></p><p id="b8bf" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">[2]动力系统和控制讲座。Mohammed Dahleh等人，麻省理工学院开放课件。访问:<a class="ae ky" href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-241j-dynamic-systems-and-control-spring-2011/readings/MIT6_241JS11_chap02.pdf" rel="noopener ugc nofollow" target="_blank">https://OCW . MIT . edu/courses/electrical-engineering-and-computer-science/6-241j-dynamic-systems-and-control-spring-2011/readings/MIT 6 _ 241 js11 _ chap 02 . pdf</a></p><p id="dfdf" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">[3] Boutsidis，C，Garber D，Karnin ZS和Liberty，e .在线主成分分析，第26届ACM-SIAM离散算法研讨会会议录，SODA-15:887–901，2015。</p></div></div>    
</body>
</html>