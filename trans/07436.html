<html>
<head>
<title>How Can You Tell if Your Recommender System Is Any Good?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你怎么知道你的推荐系统好不好？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-can-you-tell-if-your-recommender-system-is-any-good-e4a6be02d9c2?source=collection_archive---------3-----------------------#2021-07-07">https://towardsdatascience.com/how-can-you-tell-if-your-recommender-system-is-any-good-e4a6be02d9c2?source=collection_archive---------3-----------------------#2021-07-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="f21f" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/notes-from-industry" rel="noopener" target="_blank">行业笔记</a></h2><div class=""/><div class=""><h2 id="a49f" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">离线评估的12个技巧，带航海弯</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/5308e6b480b2e8dd6b900899209ceed0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6GZL6QZGy-m9uaIKEWOrvw.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">Charles Frodsham的航海天文钟，可能是通过“离线”(或陆地)评估开发的。用户照片:Ktr101 — Ladd天文台，CC BY-SA 4.0，【https://commons.wikimedia.org/w/index.php?curid=45968685 T2】</p></figure><p id="0898" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">研究推荐系统是一个激动人心的时刻。它们不仅比以往任何时候都更相关，脸书最近<a class="ae le" href="https://arxiv.org/abs/2104.05158" rel="noopener ugc nofollow" target="_blank">投资了12万亿参数模型</a>，亚马逊估计<a class="ae le" href="https://www.mckinsey.com/industries/retail/our-insights/how-retailers-can-keep-up-with-consumers#" rel="noopener ugc nofollow" target="_blank">他们35%的购买来自推荐</a>，而且有大量强大的、尖端的技术和代码可供任何人尝试。</p><p id="b34d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，工具就在手边，可以用来为用户提供个性化的推荐。问题是，知道它有没有用。</p><p id="7722" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当<a class="ae le" href="https://en.wikipedia.org/wiki/John_Harrison" rel="noopener ugc nofollow" target="_blank">约翰·哈里森</a>正在开发<a class="ae le" href="https://en.wikipedia.org/wiki/Marine_chronometer" rel="noopener ugc nofollow" target="_blank">海洋天文钟</a>时，它通过允许船只精确确定其经度而彻底改变了长途海上旅行，他有一个评估问题:在实践中测量该设备的精度需要长途海上航行。同样，评估推荐系统的黄金标准也是昂贵且耗时的:一个<a class="ae le" href="https://en.wikipedia.org/wiki/A/B_testing" rel="noopener ugc nofollow" target="_blank"> A/B测试</a>，在这个测试中，随机选择的真实用户会看到新模型，他们的行为会与看到旧模型的用户进行比较。在这两种情况下，如果这是唯一的评估方式，就不可能敏捷地尝试新的想法，或者快速地消除缺陷。</p><p id="3a5e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">相反，有必要找到一种快速、廉价的方法来评估一个模型。在哈里森的例子中，他总是建造两个时钟，并在他的工作台上测量它们偏离的程度。这给了他一个精确的衡量标准，这反过来又让他能够快速迭代他的设计，并在一艘船出海之前达到非常高的性能水平——事实上，1736年从伦敦到里斯本的第一次测试旅程表明他的发明是成功的。对于推荐系统，解决方案是<em class="mb">离线评估</em>，其中历史数据用于估计用户在某个时间点对摆在他们面前的一组不同的推荐可能会有什么反应，方法是使用他们后来真正做出反应的知识。</p><blockquote class="mc"><p id="d1c9" class="md me iq bd mf mg mh mi mj mk ml ma dk translated">有了好的线下评估，当我们做出好的东西时，我们会知道的。相反，如果没有良好的离线评估，整个团队可能会在几周或几个月内完全不知所措。</p></blockquote><p id="56b9" class="pw-post-body-paragraph lf lg iq lh b li mm ka lk ll mn kd ln lo mo lq lr ls mp lu lv lw mq ly lz ma ij bi translated">出于娱乐和学习的目的，我正在为维基百科编辑(又名维基人)建立一个推荐系统，建议他们下一步应该编辑什么文章，这个系统叫做<strong class="lh ja">维基百科</strong>。我对时间和行动顺序的相互作用特别感兴趣，以预测某人在应用程序或网站上的下一步行动。我正在探索几种尖端的人工智能技术，以充分利用所有这些信息来源，但从我的科学背景来看，我知道首要任务是值得信赖的测量，在这种情况下是通过离线评估。</p><p id="5ec3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">离线评估需要弄清楚如何建立一个有效的测试集，计算什么度量，以及与什么基线模型进行比较。我将在下面给出我的建议，侧重于对行业实用的东西，而不是学术出版物的更高标准，但首先是关于我的数据集。维基百科没有星级评定，也没有竖拇指/竖拇指，所以这本质上是一个<a class="ae le" href="https://jessesw.com/Rec-System/" rel="noopener ugc nofollow" target="_blank">隐含推荐问题</a>，我感兴趣的信号是选择编辑一篇文章。基于用户的编辑历史，以及我可以获取的任何其他信息，我想建立一个他们兴趣的图片，特别是他们最近的兴趣，并学习对个性化的文章列表进行排序。</p><p id="966e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这是我的维基百科数据的一个例子，给我的瑞士朋友，他叫<a class="ae le" href="https://en.wikipedia.org/wiki/User:Rama" rel="noopener ugc nofollow" target="_blank"> Rama </a>。自2004年以来，他对维基百科进行了超过45000次编辑，并有非常具体的兴趣，主要是法国海军史和计算机技术。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/555bee008342680a0b6b5ae9ca5c327f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*6Y_ZRAUndGVcYnh1f0O1sQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">一个用户编辑的原始数据样本，来自维基百科API</p></figure><p id="360c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">利用维基百科的公开API，我对英文维基百科所有用户的100万条最新编辑进行了采样，结果发现这些数据只有几天的价值。然后，对于样本中的每个编辑，我提取了他们最近一年的编辑，总共2100万个数据点。像这样的抽样只捕获在这一时期活跃的用户——首先，这多少会过多地代表最活跃的编辑，但这是我最感兴趣服务的人群。我做了一些基本的清理，例如删除编辑过多或过少的机器人和用户，然后建立我的训练集、测试集和基线推荐器。最终的训练集覆盖了300万个维基百科页面(总共约630万个页面)和32，000个用户。</p><p id="5a1a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" href="https://github.com/drsaunders/wikirecs" rel="noopener ugc nofollow" target="_blank">(回购和笔记本全部代码</a>)</p><h2 id="a8a9" class="ms mt iq bd mu mv mw dn mx my mz dp na lo nb nc nd ls ne nf ng lw nh ni nj iw bi translated">提示1:为了精心制作你的评估，首先要考虑推荐系统的目的</h2><p id="9f46" class="pw-post-body-paragraph lf lg iq lh b li nk ka lk ll nl kd ln lo nm lq lr ls nn lu lv lw no ly lz ma ij bi translated">没有通用的度量或评估程序适用于所有用例。关于离线评估的每一个决定都取决于你使用推荐系统的目的。</p><p id="47f8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">你想为一个人做3小时的音乐DJ吗？你是想让人们注意并点击广告中的产品吗？当搜索者输入“绿色银行”时，你是否试图猜测他们想要什么？你想给订户安排一个合适的约会对象吗？</p><p id="ea90" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这将成为回答如下问题的基础:<em class="mb">成功的衡量标准是什么？你到底是如何分离出测试集的？在不再有用之前，相关的东西可以放在列表的什么位置？重新展示他们已经感兴趣的物品有多重要？</em></p><p id="1101" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">就我而言，我把维基百科想象成编辑维基百科的副驾驶。一个个性化的列表，你可以浏览一下，为你可能想要编辑的下一篇文章提供思路。我还希望它能够灵活、持续地适应用户不断变化的兴趣。因此，我选择将我的评估集中在学习排序算法预测用户真正编辑的下一个页面的能力上。从短期预测的角度来阐述这个问题，使其成为<a class="ae le" href="https://arxiv.org/pdf/1905.01997" rel="noopener ugc nofollow" target="_blank">顺序推荐系统</a>的绝佳候选，在该系统中，用户行动的顺序和时间被明确建模。</p><p id="22fe" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">与其预测下一个项目，我可以用一整周或一个月的后续活动来预测在那个时期编辑了什么，这将是一个多标签问题(并考虑到Precision@K等其他指标)，但这将需要更多的数据，增加复杂性，并将重点转移到更长期的预测上。如果我的目标是捕捉用户更深、更持久的偏好，我会再次采用另一种方法，这种偏好预计会在他们与应用程序或工具的关系中持续存在。</p><p id="10fe" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">要编辑的文章的快速菜单可能不应该超过20个项目，所以我选择了奖励将相关项目放在前20位的指标。首先，要看的基本指标是<a class="ae le" href="https://en.wikipedia.org/wiki/Precision_and_recall#Recall" rel="noopener ugc nofollow" target="_blank"> Recall </a> @20(也称为点击率，在这种只有一个相关条目的情况下):这个算法将下一篇文章排在前20名的频率有多高？</p><h2 id="055a" class="ms mt iq bd mu mv mw dn mx my mz dp na lo nb nc nd ls ne nf ng lw nh ni nj iw bi translated">技巧#2:注意模型和位置偏差</h2><p id="feca" class="pw-post-body-paragraph lf lg iq lh b li nk ka lk ll nl kd ln lo nm lq lr ls nn lu lv lw no ly lz ma ij bi translated">当你构建一个推荐系统来替换现有的解决方案时，会有一个<a class="ae le" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.112.1288&amp;rep=rep1&amp;type=pdf" rel="noopener ugc nofollow" target="_blank">位置偏差</a>(也称为呈现偏差)的问题:当前系统推荐的项目通常会被放在列表的顶部，或者在用户面前更加突出。这使得这些项目在离线评估中具有优势，因为无论客户在实践中如何反应，都有倾向于将它们放在顶部的模型。因此，简单的评估指标对现有系统来说是保守的，改进必须很大才能击败“历史推荐者”(真正向客户展示的排名列表)。</p><p id="7a8d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">有许多技术可以对抗这种偏见，特别是<a class="ae le" href="http://www.cs.cornell.edu/people/tj/publications/joachims_etal_17a.pdf" rel="noopener ugc nofollow" target="_blank">反向倾向评分</a>，它试图对不公平的优势项目进行建模，然后按比例降低它们的权重。另一种方法，虽然成本较高，但在生产中有一个“拒绝通道”，在那里不提供个性化推荐，并使用它来至少提供评估数据——它可能不会提供足够的数据来进行训练。最终的评估数据可能是呈现给部分用户的真正随机的项目列表，但即使一家公司能够承受可能的性能大幅下降，它也可能不想要那种<em class="mb">信任破坏</em>(见下文)体验！</p><p id="aa1c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">幸运的是，就我而言，我不必太担心位置偏差。编辑维基百科页面是一个相当高强度的行为，所以人们只是因为文章就在他们面前而随意编辑文章是没有问题的。这些编辑与我的推荐系统无关(因为它还不存在)，所以我不必担心<a class="ae le" href="https://labs.pinterest.com/user/themes/pin_labs/assets/paper/p2p-www17.pdf" rel="noopener ugc nofollow" target="_blank">先前模型偏差</a>(一种呈现偏差)。可能存在受欢迎程度的偏见，人们争相编辑当天的热门话题，但正如我们将在下面看到的那样，这种偏见并不强烈。</p><h2 id="f419" class="ms mt iq bd mu mv mw dn mx my mz dp na lo nb nc nd ls ne nf ng lw nh ni nj iw bi translated">技巧3:小心挑选测试集</h2><p id="da86" class="pw-post-body-paragraph lf lg iq lh b li nk ka lk ll nl kd ln lo nm lq lr ls nn lu lv lw no ly lz ma ij bi translated">对于大多数推荐算法，可靠的评估需要留出一部分数据，并且仅用于该目的。我把我的推荐问题框定为一个预测问题，所以我把我的数据分为最近的行为和之前的所有行为。本帖中的基线算法(比如“最近编辑的”)，都是无监督的，所以把历史数据看做“训练数据”，把下一个动作看做测试数据。然而，当将来我评估由<a class="ae le" href="https://en.wikipedia.org/wiki/Supervised_learning" rel="noopener ugc nofollow" target="_blank">监督的</a>算法时，我还需要留出一个随机的用户样本，他们的历史和最近的编辑，来自相同的时间范围。</p><p id="f8be" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">要点:确保你的训练集不与测试集重叠，并制作两个测试集，一个是<em class="mb">开发集</em>，可用于调整你的hyper参数，而不是用于最终评估。</p><h2 id="dbb9" class="ms mt iq bd mu mv mw dn mx my mz dp na lo nb nc nd ls ne nf ng lw nh ni nj iw bi translated">技巧4:使用考虑位置的指标</h2><p id="02af" class="pw-post-body-paragraph lf lg iq lh b li nk ka lk ll nl kd ln lo nm lq lr ls nn lu lv lw no ly lz ma ij bi translated">回想一下@20，前20个rec包含下一个被编辑的页面的频率，这是比较我的任务模型的一个合理、直接的指标。然而，通过考虑学习排序算法是否将相关项目放在排序的顶部，可以在更细粒度的级别上对其进行比较。这可以通过简单地绘制Recall @ 1到N来直观地检查，这可以揭示位置差异。</p><p id="f6d9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">例如，对于数据的子集(“发现集”，稍后将详细介绍)，BM25模型具有较高的召回率@20，但是对于召回率@1，交替最小二乘法得分更高。BM25的累积优势仅排在榜单的第12位。这可能表明BM25更擅长标记相关项目，但ALS更擅长确保最相关的项目出现在顶部。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi np"><img src="../Images/bd975e1d40fd12f5b37dab46a03eaf34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*uuxuQM-VBGJXRkjhuxMoGQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">在“discovery”测试案例上回忆ALS和BM25算法的@N性能曲线</p></figure><p id="9813" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这种位置表现可以归结为一个数字，使用像<a class="ae le" href="https://en.wikipedia.org/wiki/Mean_reciprocal_rank" rel="noopener ugc nofollow" target="_blank"> MRR </a>或<a class="ae le" href="https://en.wikipedia.org/wiki/Discounted_cumulative_gain#Normalized_DCG" rel="noopener ugc nofollow" target="_blank"> nDCG </a>这样的衡量标准来衡量最高位置的表现。如果有多个相关的项目需要检索，并且这些项目可能具有不同的相关性级别，那么nDCG是更好的选择。但在我的例子中，在我的测试集中有一个相关项目，它们在数学上是相似的，相当于随着算法将相关项目放在页面的更下方,“得分”急剧下降。报告两者都不会增加什么，所以我武断地决定关注nDCG@20，如果相关项目总是出现在第一个位置，那么它的得分为1，如果它从未出现在前20位，那么它的得分为0，在这两者之间有一个按位置加权的反对数下降。果不其然，未过滤的ALS在@20时的召回率比BM25低，但在@20时的nDCG较高。</p><p id="eda6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">Precision@K或MAP之类的指标对我来说没有帮助，因为只有一个相关的条目。还有一些我没有计算出来的指标，可能对区分算法很有帮助，比如多样性、覆盖率和受欢迎程度偏差。</p><h2 id="6ede" class="ms mt iq bd mu mv mw dn mx my mz dp na lo nb nc nd ls ne nf ng lw nh ni nj iw bi translated">提示5:决定你是否关心发现，重新露面，或者两者都关心</h2><p id="1db8" class="pw-post-body-paragraph lf lg iq lh b li nk ka lk ll nl kd ln lo nm lq lr ls nn lu lv lw no ly lz ma ij bi translated">许多依赖推荐的公司，如网飞或亚马逊，在他们的界面上为特殊菜单或最近访问过的商品开辟了空间。然后，他们的推荐算法可以专注于向用户提供他们从未互动过，但可能喜欢的项目:<em class="mb">发现</em>。另一方面，许多推荐系统只是想向用户显示一个包含有吸引力的个性化项目的列表，包括他们已经参与的重新露面项目:<em class="mb">发现加重新露面</em>。这种“单流”推荐的例子包括Spotify和YouTube播放序列、一些电子商务和广告。</p><p id="cd40" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">决定<em class="mb">重新显示</em>项目的顺序是一个有价值的挑战，其中有许多细微差别，例如时间的作用以及如何决定用户是否考虑了某个项目并拒绝了它。它与电子商务应用程序非常相关，例如<a class="ae le" href="https://about.ads.microsoft.com/en-us/blog/post/may-2021/what-is-ad-retargeting-and-how-to-use-it-to-capture-customers" rel="noopener ugc nofollow" target="_blank">重定向</a>。但是有简单明了的基线:简单地按照交互的新近性或者交互的数量来排序。</p><p id="0c09" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">相比之下，在<em class="mb"> discovery </em>中获得良好表现是一个更加开放的问题，需要努力找到一个合理的基线。首先，即使用户已经购买了数百件商品，也可能有数百万件商品没有购买。</p><p id="8c40" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">但我真正感兴趣的一个挑战是如何在一个列表中最佳地结合发现和重现。虽然过去与某个项目的接触应该很有分量，但如果它是很久以前的事情或者非常不合时宜(我曾经在Wayfair上点击一张俗气的雕花木床，只是为了弄乱我妻子的推荐)，一个全新的、有很高信心的推荐有时应该会击败它。</p><p id="446f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于我的维基百科推荐任务，我既关心发现，也关心重现，所以我的评估需要反映这一点。许多维基人一遍又一遍地回到相同的文章，我的工具也应该使这变得方便，同时混合新的rec，它有很高的信心那个人会喜欢。</p><p id="2179" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，我将我的测试集划分为发现集和表面重现集，这取决于该用户之前是否编辑过目标最近的项目，并计算了我的所有指标，包括分别在这两个集上的Recall@20和nDCG，以及组合的测试集。</p><p id="75b1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">通过查看原始编辑历史，我注意到一些影响我的训练和测试集的东西，那就是人们经常连续编辑两次或更多次文章。通常这些只是为了纠正他们刚刚编辑的一个错别字。在我最初的数据集中，我发现35%的编辑是针对前一页的，所以推荐最后编辑的文章太容易了。这也不是很有用，因为该页面可能仍然在用户的某个选项卡中打开。因此，我更改了我的训练集和测试集，以删除块中的重复编辑。我重新定义了我的任务和评估，那就是:预测下一篇被编辑的<em class="mb">不同的</em>文章。这是一个更困难的任务，我的指标也相应下降。但是，当我考虑推荐质量时，这个任务更能反映我的意思。</p><p id="c7cf" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在删除运行的编辑后，我的训练集是30%的重新出现案例和70%的发现案例。这种混合可能会影响模型的预测，因此通过下采样或上采样来强调其中一个可能是有意义的(也可能值得尝试为每组案例训练单独的模型)。但重要的是分别评估它们，了解整体性能来自哪里，以及是否以牺牲另一个为代价来强调一个。</p><h2 id="b5fd" class="ms mt iq bd mu mv mw dn mx my mz dp na lo nb nc nd ls ne nf ng lw nh ni nj iw bi translated">技巧6:为比较实现强大、简单的基线</h2><p id="02d7" class="pw-post-body-paragraph lf lg iq lh b li nk ka lk ll nl kd ln lo nm lq lr ls nn lu lv lw no ly lz ma ij bi translated">“我建立了一个深度学习推荐器，它有27层，5亿个可训练参数，它很宽，很深，它有inception，autoencoder和transformer组件。”</p><p id="3d90" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">“那它做得怎么样？”</p><p id="1df5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">“嗯，它有0.4 nDCG。”</p><p id="373e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">…这样好吗？即使在学术机器学习的细致世界中，也有几个创新模型无法与常识基线相比较的高调案例，当它们与常识基线相比较时，也无法击败它们——这被称为“<a class="ae le" href="https://arxiv.org/pdf/1907.06902" rel="noopener ugc nofollow" target="_blank">幻影进展</a>问题。即使这不是一个新的、实验性的模型类型，未能超越简单的基线也是一个很好的迹象，表明实现出现了问题。</p><p id="7218" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">确定您是否取得了进展，并理解您的度量标准的唯一方法是实现一些基本的推荐器——选择哪一个也取决于问题。</p><p id="f797" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我想出了三个非常基本的方法来预测下一篇编辑过的文章:</p><ul class=""><li id="4326" class="nq nr iq lh b li lj ll lm lo ns ls nt lw nu ma nv nw nx ny bi translated"><strong class="lh ja">人气:</strong>过去一年最受欢迎</li><li id="ac22" class="nq nr iq lh b li nz ll oa lo ob ls oc lw od ma nv nw nx ny bi translated"><strong class="lh ja">最近:</strong>该用户最近编辑的</li><li id="fffd" class="nq nr iq lh b li nz ll oa lo ob ls oc lw od ma nv nw nx ny bi translated"><strong class="lh ja">频繁:</strong>该用户在去年最频繁编辑的内容</li></ul><p id="33e0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后我实现了一些稍微聪明一点，但仍然很好理解的<a class="ae le" href="https://en.wikipedia.org/wiki/Collaborative_filtering" rel="noopener ugc nofollow" target="_blank">协同过滤</a>算法，它有成熟的、易于使用的Python包(特别是<a class="ae le" href="https://implicit.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">隐式</a>包):</p><ul class=""><li id="2994" class="nq nr iq lh b li lj ll lm lo ns ls nt lw nu ma nv nw nx ny bi translated"><strong class="lh ja"> BM25: </strong> <a class="ae le" href="https://en.wikipedia.org/wiki/Okapi_BM25" rel="noopener ugc nofollow" target="_blank"> Okapi BM25，</a>JAC card与TF-IDF相似性的一个简单变化，即<a class="ae le" href="http://www.benfrederickson.com/distance-metrics/" rel="noopener ugc nofollow" target="_blank">通常会有更好的结果</a></li><li id="bd5e" class="nq nr iq lh b li nz ll oa lo ob ls oc lw od ma nv nw nx ny bi translated"><strong class="lh ja"> ALS: </strong> <a class="ae le" href="http://yifanhu.net/PUB/cf.pdf" rel="noopener ugc nofollow" target="_blank">隐式训练数据的交替最小二乘矩阵分解</a>，带BM25预缩放</li></ul><p id="717c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于这两个项目，我还计算了“过滤”推荐，删除了用户之前编辑的所有页面，因此推荐了20个有价值的纯发现项目。后两者使用了相同的精简训练数据:用户-项目交互计数矩阵(300万乘32，000个条目，由于<a class="ae le" href="https://docs.scipy.org/doc/scipy/reference/sparse.html" rel="noopener ugc nofollow" target="_blank"> SciPy稀疏矩阵</a>，加载到我笔记本电脑的RAM中仍然非常实用！)</p><p id="bfe6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">实现简单基线的另一个主要好处是，它可以让您在数据准备和模型评估管道的每一步都踢轮胎，本质上是评估评估。如果度量标准，比如说，最近与流行度没有意义，最好在这个阶段找到它，而不是在试图解释一个更复杂的模型的结果时。我发现我的评估中至少有一个大的bug！</p><h2 id="d3c3" class="ms mt iq bd mu mv mw dn mx my mz dp na lo nb nc nd ls ne nf ng lw nh ni nj iw bi translated">技巧7:检查“反托拉斯者”</h2><p id="4c15" class="pw-post-body-paragraph lf lg iq lh b li nk ka lk ll nl kd ln lo nm lq lr ls nn lu lv lw no ly lz ma ij bi translated">一旦我有了我的第一套推荐算法，我会特意留出时间<em class="mb">查看</em>这些推荐——仔细阅读结果，看看它们直观上看起来有多好，并对算法如何因人而异有一个定性的了解。</p><p id="1eb9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我特别寻找的是网飞团队称之为“<a class="ae le" href="https://www.slideshare.net/justinbasilico/recent-trends-in-personalization-at-netflix" rel="noopener ugc nofollow" target="_blank">反托拉斯者</a>，或者另一个团队称之为<a class="ae le" href="https://thenoisychannel.com/2012/08/20/wtf-k-measuring-ineffectiveness/" rel="noopener ugc nofollow" target="_blank">“WTF @ K”</a>的东西:给用户的建议，这些建议来自如此遥远的领域，看起来就像是一个小故障。</p><p id="4813" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">对于Rama来说，只有人气推荐者有明显的信任破坏推荐，我碰巧知道他对一些话题不感兴趣，比如Zach Snyder的正义联盟。ALS和BM25算法严重依赖于表面重建，这对一个17年的网站老手来说是有意义的。当新的页面被强制时(“过滤”的推荐)，他们通常给出看起来安全的海战和法国船只的选择。在下表中，重新显示的页面以粗体显示，数据集中正确的下一页为红色。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oe"><img src="../Images/80b986be2af2a1016c675ac122766ae8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PUTKJ9II-C0ETvQGLo-QQg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">七个基线推荐者对Rama的10大维基百科页面推荐。粗体条目是之前编辑过的，红色是下一次编辑的目标</p></figure><p id="e2e1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">有趣的是，只有最近的推荐者进入了前10名。</p><p id="840a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">除了Rama，我还滚动了大量其他随机选择的用户的推荐，他们有超过50次的编辑。事实证明，就像我的朋友Rama一样，许多维基百科编辑都有相对较小的“节拍”,我们至少应该能够为他们提供推荐。例如，编辑金加蒂最关心的是漫威的电影和电视剧，大多数算法都注意到了这一点，尽管方式不同。有几个人还正确预测了金加蒂接下来会编辑《漫威女士》(电视剧)。然而，ALS的最高推荐是一部相当晦涩的2003年西部连续剧《和平缔造者》，它可能会构成一部信任破坏者。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi of"><img src="../Images/b4703dfc429b2c3a9fe1d833dca58982.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-2wXStHiFWSnoJSkAnSFJQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">7个基线推荐者对KingArti的10大维基百科页面推荐。粗体条目是之前编辑过的，红色是下一次编辑的目标</p></figure><p id="d63d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在我的观察中，BM25，当没有被过滤时，比ALS更倾向于表面重建，这后来被定量地证实了。</p><h2 id="e819" class="ms mt iq bd mu mv mw dn mx my mz dp na lo nb nc nd ls ne nf ng lw nh ni nj iw bi translated">技巧8:花时间优化你的评估代码是值得的</h2><p id="ecf3" class="pw-post-body-paragraph lf lg iq lh b li nk ka lk ll nl kd ln lo nm lq lr ls nn lu lv lw no ly lz ma ij bi translated">在这一点上，我会注意到，你将会一遍又一遍地运行评估代码，比你所能想到的还要多，而且你能使这个循环越紧密，找到你的最佳模型的过程将会越快越有趣。现在是时候通过使用Spark、多处理或joblib等并行计算工具来利用所有可用的并行计算了，无论是在云中还是笔记本电脑上的多核。有一些包，比如<a class="ae le" href="https://modin.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">摩丁</a>，试图让简单的熊猫并行化，所以这些包可能值得一试。</p><p id="cbca" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我选择隐式库是幸运的，但也是有目的的，因为它是高度优化的，本质上是并行的。尽管如此，我还是令人尴尬地花了很长时间才意识到有一个<code class="fe og oh oi oj b">recommend_all </code>函数比在每个例子中运行<code class="fe og oh oi oj b">recommend</code>要快得多。如果您使用Scikit-learn，许多操作都有一个<code class="fe og oh oi oj b">n_jobs </code>参数——确保将其设置为-1，它将在您的所有内核上并行化。</p><p id="7b6f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">除了并行化，这是一个很好的机会来更好地理解事情是如何在幕后计算的，并投资于<a class="ae le" href="https://www.askpython.com/python-modules/numpy/vectorization-numpy" rel="noopener ugc nofollow" target="_blank">矢量化</a>和重构依赖于Pandas的繁重工作负载，这通常非常慢。当我重新编写我的回忆曲线函数来使用列表理解而不是<code class="fe og oh oi oj b">DataFrame.iterrows()</code>时，每次评估从2.5分钟变成了4秒钟，这产生了巨大的差异。</p><h2 id="3b9f" class="ms mt iq bd mu mv mw dn mx my mz dp na lo nb nc nd ls ne nf ng lw nh ni nj iw bi translated">提示9:确保你的评估是可重复的</h2><p id="2045" class="pw-post-body-paragraph lf lg iq lh b li nk ka lk ll nl kd ln lo nm lq lr ls nn lu lv lw no ly lz ma ij bi translated">一种可怕的感觉是回去重新计算指标，发现在相同的测试集上相同的模型产生了完全不同的分数。我防止这种情况的两个建议(我并不总是遵循)是:</p><ul class=""><li id="5605" class="nq nr iq lh b li lj ll lm lo ns ls nt lw nu ma nv nw nx ny bi translated">同时检入您的模型代码、评估代码和评估结果，以便它们匹配</li><li id="c6ee" class="nq nr iq lh b li nz ll oa lo ob ls oc lw od ma nv nw nx ny bi translated"><a class="ae le" href="https://locallyoptimistic.com/post/git-for-data-not-a-silver-bullet/" rel="noopener ugc nofollow" target="_blank">遵循这种模式</a>，而不是投资于数据版本化工具，将数据集视为一次写入，然后对管道的每一步进行版本控制，以清理和转换数据，从而生成您的训练集和测试集。</li></ul><h2 id="b113" class="ms mt iq bd mu mv mw dn mx my mz dp na lo nb nc nd ls ne nf ng lw nh ni nj iw bi translated">技巧10:调整你的基线，但仅限于某一点</h2><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/09506bbd50d519852bbf92e57d2849bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I_GkxDuGQkHE4HP0mOHEXA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">对测试集计算的所有基线算法的度量，按Recall@20排序。因为不是所有的用户在他们的历史中都有20次编辑，所以他们的rec被填充了流行的页面，所以最近和频繁的重铺并不是100%</p></figure><p id="c760" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">毫不奇怪，当谈到整体指标时，最近很难被击败——人们确实倾向于一次又一次地返回来编辑相同的页面。但是发现测试子集，其中最近的没有用，更有趣，这些回忆和nDCG分数帮助我区分协同过滤技术。</p><p id="a66b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">提出改进这些基线的想法是很容易的。例如，我可以采用频繁算法，并尝试将它限制为过去30天内最频繁的算法，引入时间元素。对于最近，我只能包括最近编辑的项目，这些项目至少被编辑了5次，或者编辑超过了一定的大小，例如20个字符。但是这些都是手工调整的试探法，这正是我们在ML项目中试图摆脱的。如果你不是在一个试图展示渐进改进的学术环境中，就停留在一些简单易懂的东西上。</p><p id="baf2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然后是稍微不那么愚蠢的基线，它有可调的超参数，但很少——BM25和ALS有两个，尽管我为隐式因子分解添加了BM25缩放，增加了两个超参数。但是四个仍然比最简单的神经网络的超参数数量少得多！我运行了几个长网格搜索来挑选最终设置(对于BM25，K1 = 100，B = 0.25)，但并不太担心绝对完美的磨练。</p><p id="1a27" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">令人惊讶的是，我最看好的算法，使用ALS的隐式矩阵分解，在discovery中的表现并不是最好的。相反，更简单和更快的BM25方法击败了它，无论是在发现集上过滤到新项目时(在nDCG上通过<em class="mb"> 240% </em>)还是在未过滤时的整体集上。我仍然有可能找到超参数的正确组合，甚至是一个不同的包，这将突然提供一个突破，但这只是一个基线，还有更强大的算法我渴望尝试。</p><p id="594c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">受欢迎程度确实非常糟糕——几乎在所有指标上都垫底，这与我通过查看具体例子对这个特定数据集的直觉相符。在维基百科上，人们通常会编辑他们自己的特殊兴趣，而不是插话讨论当天的问题。</p><h2 id="99cc" class="ms mt iq bd mu mv mw dn mx my mz dp na lo nb nc nd ls ne nf ng lw nh ni nj iw bi translated">技巧11:有了好的评估指标，你可以尝试简单的解决方案——这可能正是你想要的</h2><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ol"><img src="../Images/4672921d7b6b812e7ebf47557e50b2dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iQDio-RUo6v5Z1PPPlI_7w.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">测试所有算法在discovery和resume示例集上的性能。虚线展示了交织算法优于许多其他算法的帕累托最优</p></figure><p id="0813" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这听起来可能与技巧10关于不要过多修改基线相矛盾，但事实并非如此！</p><p id="27f0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果我不得不在本周发布一个维基百科推荐算法<em class="mb">，并且它必须擅长发现和重新浮现，我可能会尝试简单地将最佳重新浮现(最近)和最佳发现算法(BM25过滤)交错，在我进行的过程中删除重复的。对于我的数据集，我发现我得到的离线召回@20比所有其他模型都好，除了BM25在discovery中过滤，在表面重建时只比最好的模型差11%。此外，它显然<a class="ae le" href="https://hinnefe2.github.io/python/tools/2015/09/21/mario-kart.html" rel="noopener ugc nofollow" target="_blank">帕累托优于</a>任何其他试图平衡重新露面和发现的解决方案。</em></p><p id="8e19" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">从Rama和KingArti的交叉推荐中，我也很清楚它是如何有用的。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi om"><img src="../Images/160950e1b2e0ca58cfd9e4faa067b6bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:598/format:webp/1*qs8tTU2aIob0BUURlKq5_g.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">交叉推荐的Rama的10大维基百科页面推荐。粗体条目是之前编辑过的，红色是下一次编辑的目标</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi on"><img src="../Images/87d0286b9533e3c9695b7089bf1fbea6.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*HPkgjY4WQsS0P_Z9hiNn6g.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">KingArti对交叉推荐器的10大维基百科页面推荐。粗体条目是之前编辑过的，红色是下一次编辑的目标</p></figure><p id="1f1d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当然，这是一个黑客，但这个交错输出是一个单流推荐器，很容易得到正确的，产生高度可解释的rec，并在生产中运行非常快。对于之前没有个性化的第一个系统来说，类似这样的东西可能是一个很好的选择——除非你经历过，否则你不会相信在生产哪怕是最简单的ML模型时会有多少意想不到的挑战，特别是如果它需要实时服务rec的话。</p><h2 id="afd9" class="ms mt iq bd mu mv mw dn mx my mz dp na lo nb nc nd ls ne nf ng lw nh ni nj iw bi translated">提示#12:如果可能的话，从用户那里获得定性的反馈</h2><p id="22cc" class="pw-post-body-paragraph lf lg iq lh b li nk ka lk ll nl kd ln lo nm lq lr ls nn lu lv lw no ly lz ma ij bi translated">你有没有跟你的Spotify Discover Weekly或者你的网飞流派旋转木马顶嘴过？我有！我注意到我和我的朋友在生活中与推荐系统有着亲密的、固执己见的关系。当rec好的时候，尤其是当它们不好的时候。我们判断rec，我们试图找出它们，我们甚至试图有意识地塑造它们，使它们更接近他们想要的和期望的。理想情况下，你可以将这种定性反馈作为你离线评估的一部分。</p><p id="7907" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">许多组织没有一个<a class="ae le" href="https://en.wikipedia.org/wiki/User_experience_evaluation" rel="noopener ugc nofollow" target="_blank">用户体验</a>部门，作为建模者，你可以进入这个部门——尽管这值得一查！但即使如此，从已经是用户的朋友和亲戚那里获得非正式的反馈也是一个好主意，尤其是如果你可以向他们并排展示不同的推荐输出。我给Rama发送了这7个基线的输出，他写道“BM25_filtered(流行和他熟悉的文章之间)在这些极端之间取得了良好的平衡”，还说“系统显然正在找到与我的兴趣和能力相关的主题。”有趣的是，他还记得编辑过过滤列表中的许多页面，这意味着要么他是在一年多前编辑的，要么就是这么好。</p></div><div class="ab cl oo op hu oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="ij ik il im in"><p id="9379" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最后一个长期想法是:离线评估可能无法完美预测A/B测试结果的原因有很多，但如果你小心谨慎并补偿一些偏差，希望它至少可以预测结果的方向:离线看起来像赢家的模型在线上也是赢家。然而，如果您在多个A/B测试的过程中保持认真的记录，您最终可以估计您的离线指标预测测试结果的程度，甚至可以猜测nDCG改进的成功程度。最重要的是，它会显示你的离线评估中是否有系统性的偏差。</p><p id="76d7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，我的WikiRecs基线已经就绪，当我用更强大的机器学习算法击败它们时，我将确切知道我为了这些收益在增加的复杂性和性能方面牺牲了多少。而且，就像海洋计时器的创造者一样，我很清楚更昂贵的验证测试将会如何进行——远在帆展开之前。</p></div></div>    
</body>
</html>