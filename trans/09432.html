<html>
<head>
<title>Train, Visualize and Inspect Computer Vision Models with no code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无需代码即可训练、可视化和检查计算机视觉模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/train-visualize-and-inspect-computer-vision-models-on-a-no-code-mlops-platform-6e26ea9c6fef?source=collection_archive---------30-----------------------#2021-09-01">https://towardsdatascience.com/train-visualize-and-inspect-computer-vision-models-on-a-no-code-mlops-platform-6e26ea9c6fef?source=collection_archive---------30-----------------------#2021-09-01</a></blockquote><div><div class="fc if ig ih ii ij"/><div class="ik il im in io"><h2 id="8923" class="ip iq ir bd b dl is it iu iv iw ix dk iy translated" aria-label="kicker paragraph">计算机视觉</h2><div class=""/><div class=""><h2 id="09e9" class="pw-subtitle-paragraph jx ja ir bd b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko dk translated">看看Nexus和Portal，这是一个无代码的MLOps平台，允许您训练、测试和部署最先进的cv模型</h2></div><figure class="kq kr ks kt gu ku gi gj paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gi gj kp"><img src="../Images/85b38862f0d02c1b72b478bd0c26b766.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lYXiiJ2DVbJ34APC"/></div></div><p class="lb lc gk gi gj ld le bd b be z dk translated">法尔汉·阿扎姆在<a class="ae lf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="aa65" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi mc translated"><span class="l md me mf bm mg mh mi mj mk di"> A </span>你是一个对训练计算机视觉模型感兴趣的计算机视觉爱好者，但是本地机器的局限性或花费数小时编写大量代码阻止了你吗？</p><p id="9e77" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">或者你是一个ML从业者，希望简化你的ML堆栈，而不是仅仅为了可视化和验证你的模型而与cv2或matplotlib代码争论？</p><p id="561b" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">这篇文章是给你的。</p><p id="c459" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">介绍由初创公司<a class="ae lf" href="https://datature.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="li jb"> Datature </strong> </a>打造的开源无代码app<a class="ae lf" href="https://datature.io/" rel="noopener ugc nofollow" target="_blank"><strong class="li jb">Nexus</strong></a>和<a class="ae lf" href="https://datature.io/portal" rel="noopener ugc nofollow" target="_blank"> <strong class="li jb"> Portal </strong> </a>，一个无代码的MLOps平台。</p><h2 id="60a6" class="ml mm ir bd mn mo mp dn mq mr ms dp mt lp mu mv mw lt mx my mz lx na nb nc ix bi translated">什么是Nexus和Portal？</h2><ul class=""><li id="9bc1" class="nd ne ir li b lj nf lm ng lp nh lt ni lx nj mb nk nl nm nn bi translated">Nexus是构建计算机视觉应用的最快方法，无需代码(也不会牺牲准确性)</li><li id="3cd0" class="nd ne ir li b lj no lm np lp nq lt nr lx ns mb nk nl nm nn bi translated"><strong class="li jb">门户</strong> ( <a class="ae lf" href="https://www.producthunt.com/posts/datature-portal" rel="noopener ugc nofollow" target="_blank">最近发布</a>！)是一款针对视觉模型的开源视觉检测工具。</li></ul><p id="76b0" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">为了测试这两个应用程序，我决定使用Kaggle的<a class="ae lf" href="https://www.kaggle.com/andrewmvd/face-mask-detection" rel="noopener ugc nofollow" target="_blank">人脸面具检测</a>数据集，包含属于三个类别的853张图像——无面具、面具和面具佩戴不当，并训练一个简单的面具检测模型。</p></div><div class="ab cl nt nu hv nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="ik il im in io"><h1 id="f2af" class="oa mm ir bd mn ob oc od mq oe of og mt kg oh kh mw kj oi kk mz km oj kn nc ok bi translated">用Nexus训练掩模检测模型</h1><h2 id="4d76" class="ml mm ir bd mn mo mp dn mq mr ms dp mt lp mu mv mw lt mx my mz lx na nb nc ix bi translated">上传图像</h2><p id="b349" class="pw-post-body-paragraph lg lh ir li b lj nf kb ll lm ng ke lo lp ol lr ls lt om lv lw lx on lz ma mb ik bi translated">首先，我把图片上传到图片区；这一部分是不言自明的。</p><p id="cf1a" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">我取出了10%的图像，并保存下来，以便在Portal中进行检查，从而验证我的模型。</p><h2 id="64ab" class="ml mm ir bd mn mo mp dn mq mr ms dp mt lp mu mv mw lt mx my mz lx na nb nc ix bi translated">上传注释</h2><p id="ab8b" class="pw-post-body-paragraph lg lh ir li b lj nf kb ll lm ng ke lo lp ol lr ls lt om lv lw lx on lz ma mb ik bi translated">数据集带有PASCAL VOC格式的注释，因此将它们上传到Nexus只需要选择正确的格式。</p><figure class="kq kr ks kt gu ku gi gj paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gi gj oo"><img src="../Images/9f09705dee28b4f1f7540c9a558d301c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kn7ZA6BlkxlFeZSaMeEllg.png"/></div></div><p class="lb lc gk gi gj ld le bd b be z dk translated">上传注释</p></figure><h2 id="5864" class="ml mm ir bd mn mo mp dn mq mr ms dp mt lp mu mv mw lt mx my mz lx na nb nc ix bi translated">注释图像</h2><p id="7768" class="pw-post-body-paragraph lg lh ir li b lj nf kb ll lm ng ke lo lp ol lr ls lt om lv lw lx on lz ma mb ik bi translated">如果你没有注释或者想要编辑和添加更多注释，Nexus有一个圆滑而丰富的界面可供你使用。一个很酷的功能是，你可以实时地给它们贴标签。</p><figure class="kq kr ks kt gu ku gi gj paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gi gj op"><img src="../Images/ca6dbdb7a958cdec1b1e6fb7eeea0037.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vGIJ82cwK5x3ixaA1ctqYQ.png"/></div></div></figure><p id="40b5" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">完成图像和注释后，您会在主页上看到一个漂亮的小摘要。</p><figure class="kq kr ks kt gu ku gi gj paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gi gj oq"><img src="../Images/04ce9a3e36c1893a3b8ca6191614e0ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BgnhPMh3_QUz2OtjtwmFqA.png"/></div></div><p class="lb lc gk gi gj ld le bd b be z dk translated">标签的分布，图像和注释的良好统计。</p></figure><h2 id="78b1" class="ml mm ir bd mn mo mp dn mq mr ms dp mt lp mu mv mw lt mx my mz lx na nb nc ix bi translated">创建工作流</h2><p id="c070" class="pw-post-body-paragraph lg lh ir li b lj nf kb ll lm ng ke lo lp ol lr ls lt om lv lw lx on lz ma mb ik bi translated">构建工作流的可视化方式非常直观。基本的想法是:</p><blockquote class="or"><p id="5483" class="os ot ir bd ou ov ow ox oy oz pa mb dk translated">数据集→扩充→选择模型架构</p></blockquote><figure class="pc pd pe pf pg ku gi gj paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gi gj pb"><img src="../Images/d22450f54bbfa939734347b59668f8fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZTJKjFFSlxOvUrDYxxDLUw.png"/></div></div><p class="lb lc gk gi gj ld le bd b be z dk translated">我的遮罩检测模型的简单工作流程</p></figure><p id="5a75" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">对于数据集，我使用默认值<code class="fe ph pi pj pk b">0.3</code>作为训练-测试分割比，您也可以选择一个特定的随机种子来实现可重复性。</p><p id="6c5a" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">我选择了一些基本的随机位置增强——中心裁剪、水平和垂直翻转。在色彩空间增强中还有许多其他选项，切换到高级模式可以让你选择这些增强的概率。</p><p id="0bbc" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">对于该模型，我选择了FasterRCNN ResNet50 640x640，并使用每批2个图像和1000个训练时期的默认值，因此训练不会花费太多时间，因为这只是一个有趣的小项目。</p><p id="6f22" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">还有一个预览增强功能，这是有用的测试选定的增强。</p><h2 id="f0e6" class="ml mm ir bd mn mo mp dn mq mr ms dp mt lp mu mv mw lt mx my mz lx na nb nc ix bi translated"><strong class="ak">超参数调谐</strong></h2><p id="c387" class="pw-post-body-paragraph lg lh ir li b lj nf kb ll lm ng ke lo lp ol lr ls lt om lv lw lx on lz ma mb ik bi translated">在工作流启动之前，您将能够看到您选择的所有参数的预览，我发现这很有用，因为它可以作为神经网络初始化之前的最后一分钟检查。</p><figure class="kq kr ks kt gu ku gi gj paragraph-image"><div class="gi gj pl"><img src="../Images/a9d68af818e5b15892e395884e48aa4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*3CAZpQQ5JnnAsXdEceHZkA.png"/></div><p class="lb lc gk gi gj ld le bd b be z dk translated">训练前调整超参数</p></figure><h2 id="147d" class="ml mm ir bd mn mo mp dn mq mr ms dp mt lp mu mv mw lt mx my mz lx na nb nc ix bi translated">培训的实时监控</h2><p id="d194" class="pw-post-body-paragraph lg lh ir li b lj nf kb ll lm ng ke lo lp ol lr ls lt om lv lw lx on lz ma mb ik bi translated">在Nexus上训练一个模型最酷的事情是，你可以看到<strong class="li jb">你的模型在图表上的实时进度</strong>，如果你决定停止，你可以点击一个按钮。</p><p id="3efb" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">NVIDIA k80引擎上的模型训练只花了大约30分钟，但根据你训练的模型的大小和类型，有不同的GPU设置供你选择。</p><p id="913c" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">完成后，您会得到一个关于您的模型的所有重要指标的很好的摘要。</p><figure class="kq kr ks kt gu ku gi gj paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gi gj pm"><img src="../Images/8cc3820c975a5f8845c72843c67359c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m5-vTM4gPkbJrFPnl2NKRw.png"/></div></div></figure><p id="69a8" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">完成后，我前往工件部分生成我的TensorFlow模型并下载它。</p><p id="0047" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">准备好模型后，我前往门户网站开始可视化和检查它。</p></div><div class="ab cl nt nu hv nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="ik il im in io"><h1 id="0720" class="oa mm ir bd mn ob oc od mq oe of og mt kg oh kh mw kj oi kk mz km oj kn nc ok bi translated">使用门户网站检查</h1><h2 id="62d8" class="ml mm ir bd mn mo mp dn mq mr ms dp mt lp mu mv mw lt mx my mz lx na nb nc ix bi translated">加载训练好的模型和图像</h2><p id="5e30" class="pw-post-body-paragraph lg lh ir li b lj nf kb ll lm ng ke lo lp ol lr ls lt om lv lw lx on lz ma mb ik bi translated">加载模型非常容易。我所要做的就是选择TensorFlow选项，然后提供我下载的模型的路径。</p><p id="1d17" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">然后，我将我的验证图像上传到门户网站。</p><p id="7780" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">准备好图像后，我可以开始测试我的模型了！</p><h2 id="0f1a" class="ml mm ir bd mn mo mp dn mq mr ms dp mt lp mu mv mw lt mx my mz lx na nb nc ix bi translated">分析图像</h2><p id="74c0" class="pw-post-body-paragraph lg lh ir li b lj nf kb ll lm ng ke lo lp ol lr ls lt om lv lw lx on lz ma mb ik bi translated">分析图像只需点击一个按钮，如果您想一次性分析所有图像，只需点击<code class="fe ph pi pj pk b">Bulk Analysis</code></p><p id="31a4" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">您可以为每个分析设置您想要的置信度阈值，甚至可以过滤您想要查看的标签。</p><p id="123a" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">在对我的验证图像进行批量分析时，我发现我的掩模检测模型出现了一些小问题。</p><p id="3006" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">以下是我的模型在相当高的置信阈值下的预测，这产生了错误的预测。</p><div class="kq kr ks kt gu ab cb"><figure class="pn ku po pp pq pr ps paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><img src="../Images/c3931ec8a925713cfca95455399b3327.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*8R7z3BIOiP_VTjPfPCUpDQ.png"/></div></figure><figure class="pn ku pt pp pq pr ps paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><img src="../Images/24c6c1cc7be63392ed67d3003a8fa6f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*EOAlV8zC0zXDsYJDSLs6qw.png"/></div></figure><figure class="pn ku pu pp pq pr ps paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><img src="../Images/be316d1363863432a4a767fa706315b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*mJPzdJ-mVr2mqB3L4chFhA.png"/></div><p class="lb lc gk gi gj ld le bd b be z dk pv di pw px translated">(右)模型应预测带面罩，(中)模型应预测不带面罩，(左)模型应预测面罩佩戴不正确</p></figure></div><p id="40c2" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">检查表明，该模型将一片单一颜色(帽子、太阳镜、衬衫)混淆为一个面罩，导致错误预测。</p><p id="e25c" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">此外，检查显示该模型在头部转向左侧或右侧时表现不佳。</p><figure class="kq kr ks kt gu ku gi gj paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gi gj py"><img src="../Images/da410139b647c3b670d66ae9d802e251.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WlYuo_Nx8WuxRkX6UJQlWA.png"/></div></div><p class="lb lc gk gi gj ld le bd b be z dk translated">头部朝左或朝右时，模型表现不佳</p></figure><p id="7b5c" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">该模型的另一个问题是，该模型没有像它应该的那样预测<code class="fe ph pi pj pk b">mask_worn_incorrectly</code>。下面的图片正好说明了这一点。</p><div class="kq kr ks kt gu ab cb"><figure class="pn ku pz pp pq pr ps paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><img src="../Images/e5782775247b43f5b029b4f68a63e178.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*sZYmp7O9LtcLbu4bXweftw.png"/></div></figure><figure class="pn ku qa pp pq pr ps paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><img src="../Images/08eb6228df699bd50fb064edd4a7d01f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*8388agRi-6We2O1UBMpIvA.png"/></div><p class="lb lc gk gi gj ld le bd b be z dk qb di qc px translated">图像清楚地显示了没有正确佩戴的面具，因为鼻子暴露在外，但我们的模型只能在5%的置信水平下预测正确的标签。</p></figure></div><p id="8257" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">发生这种情况有两个可能的原因。首先，与其他两个标签相比，<code class="fe ph pi pj pk b">mask_weared_incorrectly</code>标签的样本量很小，另一个原因是该模型需要更多的训练或调整。</p><p id="6c24" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">检查完成后，我现在可以继续调整我的注释，添加更多的数据，添加更多的扩充以捕获更多的信息，甚至使用不同的模型来改进我的掩码检测模型。</p><p id="12d0" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">所以你走吧！我训练了一个更快的R-CNN模型，并使用Nexus和Portal在没有代码的情况下对其进行了检查。</p></div><div class="ab cl nt nu hv nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="ik il im in io"><h1 id="4430" class="oa mm ir bd mn ob oc od mq oe of og mt kg oh kh mw kj oi kk mz km oj kn nc ok bi translated">关于连接和门户的思考</h1><ul class=""><li id="7b37" class="nd ne ir li b lj nf lm ng lp nh lt ni lx nj mb nk nl nm nn bi translated"><strong class="li jb">设计</strong> —令人敬畏的设计和圆滑的界面。很明显他们在设计上下了很多功夫。</li><li id="523e" class="nd ne ir li b lj no lm np lp nq lt nr lx ns mb nk nl nm nn bi translated"><strong class="li jb">性能</strong>——对我来说，Nexus和Portal都运行得很流畅，尽管Nexus有时在工作流部分滞后，我不得不刷新web应用程序。</li><li id="9b6d" class="nd ne ir li b lj no lm np lp nq lt nr lx ns mb nk nl nm nn bi translated">易用性 —我惊讶于这些平台的易用性。我没有发现应用程序令人困惑的任何部分，每一步都很直观。</li></ul><p id="d51c" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">Portal的最终目标是简化可视化和检查模型的过程，我认为它肯定实现了这一点，尤其是对于那些没有技术背景的人。</p><p id="7464" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">作为一个狂热的计算机视觉爱好者，我发现Nexus和Portal是两个非常直观的应用程序，可以旋转cv模型并测试模型。</p><p id="e9fd" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">我认为这两个无代码应用的革命性之处在于，它简化了整个计算机视觉管道，消除了对多个工具或平台的需求，更不用说无需编写任何代码，这肯定会占用大量时间。</p><p id="383b" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">Datature的平台正在推动无代码人工智能革命，并无疑是计算机视觉行业的游戏规则改变者。</p></div><div class="ab cl nt nu hv nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="ik il im in io"><p id="b991" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">还有很多我没有在本文中介绍的特性，您可以使用Portal来完成，比如进行视频推理和通过API部署模型的能力(即将推出)。推荐你去他们网站自己试试！</p><p id="c1b8" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">构建您自己的模型@ <a class="ae lf" href="http://nexus.datature.io" rel="noopener ugc nofollow" target="_blank"> Nexus </a> →使用<a class="ae lf" href="https://github.com/datature/portal" rel="noopener ugc nofollow" target="_blank">门户</a>检查您的模型！</p><h2 id="470d" class="ml mm ir bd mn mo mp dn mq mr ms dp mt lp mu mv mw lt mx my mz lx na nb nc ix bi translated">Datature的Nexus和Portal视频教程</h2><ul class=""><li id="d3ab" class="nd ne ir li b lj nf lm ng lp nh lt ni lx nj mb nk nl nm nn bi translated"><a class="ae lf" href="https://www.youtube.com/watch?v=dTaqVkr8re0" rel="noopener ugc nofollow" target="_blank">使用Portal检查计算机视觉模型</a></li><li id="d17b" class="nd ne ir li b lj no lm np lp nq lt nr lx ns mb nk nl nm nn bi translated"><a class="ae lf" href="https://www.youtube.com/watch?v=KA4RGtnabDk" rel="noopener ugc nofollow" target="_blank">用#NoCode </a>训练一个自定义对象检测模型</li><li id="24f0" class="nd ne ir li b lj no lm np lp nq lt nr lx ns mb nk nl nm nn bi translated"><a class="ae lf" href="https://youtu.be/uLVWanPjGp0" rel="noopener ugc nofollow" target="_blank">用自定义数据集训练实例分割模型</a></li></ul><p id="0561" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">欲了解更多关于数据的信息，请访问👉<a class="ae lf" href="https://datature.io/" rel="noopener ugc nofollow" target="_blank">网站</a>或<a class="ae lf" href="https://datature.io/contact" rel="noopener ugc nofollow" target="_blank">联系他们</a>！</p></div><div class="ab cl nt nu hv nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="ik il im in io"><p id="1c5e" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">我尽可能地撰写与数据科学和机器学习相关的文章，并经常在<a class="ae lf" href="https://medium.com/bitgrit-data-science-publication" rel="noopener"> bitgrit数据科学出版物</a>上发表文章。</p><p id="01d3" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated"><a class="ae lf" href="https://benedictxneo.medium.com/subscribe" rel="noopener">订阅我的时事通讯</a>以便在我发布时获得更新。</p><p id="aa85" class="pw-post-body-paragraph lg lh ir li b lj lk kb ll lm ln ke lo lp lq lr ls lt lu lv lw lx ly lz ma mb ik bi translated">感谢阅读👋！</p></div></div>    
</body>
</html>