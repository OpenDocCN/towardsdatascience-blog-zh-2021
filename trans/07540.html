<html>
<head>
<title>Building a GAN with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用PyTorch构建GAN</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-gan-with-pytorch-237b4b07ca9a?source=collection_archive---------5-----------------------#2021-07-10">https://towardsdatascience.com/building-a-gan-with-pytorch-237b4b07ca9a?source=collection_archive---------5-----------------------#2021-07-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8f59" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">凭空产生逼真的图像？</h2></div><p id="8726" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Goodfellow等人在2014年提出的生成对抗网络(GANs)彻底改变了计算机视觉中图像生成的一个领域——没有人能相信这些令人惊叹和生动的图像实际上是纯粹由机器生成的。事实上，人们过去认为生成的任务是不可能的，并对甘的力量感到惊讶，因为传统上，根本没有我们可以比较我们生成的图像的地面真相。</p><p id="757d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本文介绍了创建GAN背后的简单直觉，然后通过PyTorch实现了一个卷积GAN及其训练过程。</p><h1 id="a522" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">甘背后的直觉</h1><p id="cb00" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">与传统分类不同，在传统分类中，我们的网络预测可以直接与真实的正确答案进行比较，生成图像的“正确性”很难定义和测量。Goodfellow等人在他们的原始论文<em class="mb">生成对抗网络</em>，<em class="mb"> </em>中提出了一个有趣的想法:使用一个训练非常好的分类器来区分生成的图像和实际图像。如果存在这样的分类器，我们可以创建并训练一个生成器网络，直到它能够输出可以完全欺骗分类器的图像。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi mc"><img src="../Images/779f7cbf1d1cf46d2f1f3cd57d37b736.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dX0PnDVobp1bZcPk0r54Wg.jpeg"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图一。甘的管道。作者创建的图像。</p></figure><p id="aa28" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">GAN是这一过程的产物:它包含一个基于给定数据集生成图像的生成器，以及一个用于区分图像是真实图像还是生成图像的鉴别器(分类器)。GAN的详细流水线如图1所示。</p><h2 id="0939" class="ms lf it bd lg mt mu dn lk mv mw dp lo kr mx my lq kv mz na ls kz nb nc lu nd bi translated">损失函数</h2><p id="0c1a" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">优化发生器和鉴别器都很困难，因为正如你可能想象的那样，这两个网络有着完全相反的目标:发生器希望创造尽可能真实的东西，但鉴别器希望区分产生的材料。</p><p id="4f4d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了说明这一点，我们让<em class="mb"> D(x) </em>是来自鉴别器的输出，这是<em class="mb"> x </em>是真实图像的概率，<em class="mb"> G(z) </em>是我们的生成器的输出。鉴别器类似于二元分类器，因此鉴别器的目标是最大化功能:</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/7ce32e98de22fa1dd04a803537298114.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*oqgQtjaig7m83l1xrKwT4A.png"/></div></figure><p id="a8e0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本质上是没有负号的二元交叉熵损失。另一方面，生成器的目标是最小化鉴别器做出正确决定的机会，因此它的目标是最小化函数。因此，最终的损失函数将是两个分类器之间的极小最大博弈，可以如下所示:</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/d74b1a67357c49361a8503142df6db18.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*Ujk3suoGag0npSjdPusTUA.png"/></div></figure><p id="f04d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这将在理论上收敛到以0.5的概率预测一切的鉴别器。</p><p id="1ed0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，在实践中，极大极小游戏通常会导致网络不收敛，因此仔细调整训练过程是很重要的。学习率等超参数在训练GAN时更为重要——微小的变化都可能导致GAN产生单一输出，而不管输入噪声如何。</p><h1 id="3b8d" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">计算环境</h1><h2 id="952e" class="ms lf it bd lg mt mu dn lk mv mw dp lo kr mx my lq kv mz na ls kz nb nc lu nd bi translated">图书馆</h2><p id="5f14" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">整个程序是通过PyTorch库(包括torchvision)构建的。GAN生成结果的可视化使用Matplotlib库绘制。以下代码导入所有库:</p><figure class="md me mf mg gt mh"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h2 id="17b9" class="ms lf it bd lg mt mu dn lk mv mw dp lo kr mx my lq kv mz na ls kz nb nc lu nd bi translated">资料组</h2><p id="66c1" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">数据集是训练gan时的一个重要方面。图像的非结构化本质意味着任何给定的类别(即，狗、猫或手写数字)可以具有可能数据的分布，并且这种分布最终是GAN生成的内容的基础。</p><p id="359e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了进行演示，本文将使用最简单的<a class="ae ni" href="https://gas.graviti.com/dataset/hellodataset/MNIST?utm_medium=0708Taying_2" rel="noopener ugc nofollow" target="_blank"> MNIST数据集</a>，它包含了60000个从0到9的手写数字图像。像MNIST这样的非结构化数据集实际上可以在<a class="ae ni" href="https://graviti.com/?utm_medium=0708Taying_2" rel="noopener ugc nofollow" target="_blank"> Graviti </a>上找到。这是一家年轻的初创公司，希望用非结构化数据集帮助社区，他们在自己的<a class="ae ni" href="https://gas.graviti.com/open-datasets/?utm_medium=0708Taying_2" rel="noopener ugc nofollow" target="_blank">平台</a>上有一些最好的公共非结构化数据集，包括MNIST。</p><h2 id="0a27" class="ms lf it bd lg mt mu dn lk mv mw dp lo kr mx my lq kv mz na ls kz nb nc lu nd bi translated">硬件要求</h2><p id="0b48" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">最好在GPU上训练神经网络，因为它们可以显著提高训练速度。但是，如果只有CPU可用，您仍然可以测试程序。要让您的程序自己决定硬件，只需使用以下代码:</p><figure class="md me mf mg gt mh"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h1 id="2ed6" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">履行</h1><h2 id="80ad" class="ms lf it bd lg mt mu dn lk mv mw dp lo kr mx my lq kv mz na ls kz nb nc lu nd bi translated">网络体系结构</h2><p id="b7a7" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">由于数字的简单性，两种架构——鉴别器和发生器——由完全连接的层构成。请注意，有时全连接GAN比DCGAN更容易收敛。</p><p id="4e1b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是两种架构的PyTorch实现:</p><figure class="md me mf mg gt mh"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h2 id="1f59" class="ms lf it bd lg mt mu dn lk mv mw dp lo kr mx my lq kv mz na ls kz nb nc lu nd bi translated">培养</h2><p id="390d" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">在训练GAN时，我们优化了鉴别器的结果，同时改进了我们的生成器。因此，在每次迭代过程中会有两个相互矛盾的损失来同时优化它们。我们输入到生成器中的是随机噪声，生成器应该根据给定噪声的细微差异来创建图像:</p><figure class="md me mf mg gt mh"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h1 id="646e" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">结果</h1><p id="0d9a" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">经过100个时期后，我们可以绘制数据集，并查看从随机噪声中生成的数字的结果:</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nj"><img src="../Images/d2fcb31594a2ce6098bdee53337f2b1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7STetN3jFjS4fC7k_GHMaA.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图二。GAN生成的结果。作者创建的图像。</p></figure><p id="524b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如上所示，生成的结果看起来确实很像真实的结果。考虑到网络相当简单，结果确实看起来很有希望！</p><h1 id="1089" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">不仅仅是内容创作</h1><p id="d01a" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">甘的创作与之前在计算机视觉领域的工作大相径庭。随后出现的大量应用让学术界惊讶于深度网络的能力。一些惊人的工作描述如下。</p><h2 id="6a0d" class="ms lf it bd lg mt mu dn lk mv mw dp lo kr mx my lq kv mz na ls kz nb nc lu nd bi translated">CycleGAN</h2><p id="86da" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">Zhu等人的CycleGAN引入了一个概念，该概念将图像从域<em class="mb"> X </em>转换到域<em class="mb"> Y </em>而不需要成对样本。马变成了斑马，夏天的阳光变成了暴风雪，CycleGAN的结果令人惊讶而准确。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nk"><img src="../Images/5a71b7c127c335ff6f533e424cc3bf17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jrv08i4X24kOn1kUlQ7dLA.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图3。朱等人展示的CycleGAN结果图片来自其<a class="ae ni" href="https://junyanz.github.io/CycleGAN/" rel="noopener ugc nofollow" target="_blank"> Github页面。</a></p></figure><h2 id="db85" class="ms lf it bd lg mt mu dn lk mv mw dp lo kr mx my lq kv mz na ls kz nb nc lu nd bi translated">高根</h2><p id="0cd6" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">Nvidia利用GAN的力量，根据画笔的语义，将简单的绘画转换为优雅而逼真的照片。尽管训练资源在计算上很昂贵，但它创造了一个全新的研究和应用领域。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi nl"><img src="../Images/3b1987a85298fe9ef6523917a810a93a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B9Keu2tlDpGEDV3GdQl_5A.jpeg"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">图3。高干的生成结果。左为原图，右为生成结果。作者创建的图像。</p></figure><h2 id="200b" class="ms lf it bd lg mt mu dn lk mv mw dp lo kr mx my lq kv mz na ls kz nb nc lu nd bi translated">AdvGAN</h2><p id="04ff" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">GANs还被扩展到清理对立的图像，并将它们转换成不会欺骗分类的干净的例子。更多关于对抗性攻击和防御的信息可以在<a class="ae ni" rel="noopener" target="_blank" href="/adversarial-attack-and-defense-on-neural-networks-in-pytorch-82b5bcd9171">这里</a>找到。</p><h1 id="7e79" class="le lf it bd lg lh li lj lk ll lm ln lo jz lp ka lq kc lr kd ls kf lt kg lu lv bi translated">结论</h1><p id="38b8" class="pw-post-body-paragraph ki kj it kk b kl lw ju kn ko lx jx kq kr ly kt ku kv lz kx ky kz ma lb lc ld im bi translated">所以你有它！希望这篇文章提供了如何自己构建GAN的概述。完整的实现可以在下面的Github资源库中找到:</p><div class="nm nn gp gr no np"><a href="https://github.com/ttchengab/MnistGAN" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd iu gy z fp nu fr fs nv fu fw is bi translated">ttchengab/MnistGAN</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">使用PyTorch实现GAN并在MNIST数据集上进行测试。没有执行保存/加载的保存检查点…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">github.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od mm np"/></div></div></a></div><p id="5dca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mb">感谢您坚持到现在</em>🙏！<em class="mb">我会在计算机视觉/深度学习的不同领域发布更多内容。一定要看看我关于计算机视觉方法的其他文章！</em></p></div></div>    
</body>
</html>