<html>
<head>
<title>Finding Word Similarity using TF-IDF and Cosine in a Term-Context Matrix from Scratch in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Python 中使用 TF-IDF 和余弦在术语上下文矩阵中从头开始查找单词相似度</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/finding-word-similarity-using-tf-idf-in-a-term-context-matrix-from-scratch-in-python-e423533a407?source=collection_archive---------1-----------------------#2021-11-07">https://towardsdatascience.com/finding-word-similarity-using-tf-idf-in-a-term-context-matrix-from-scratch-in-python-e423533a407?source=collection_archive---------1-----------------------#2021-11-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f874" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">嵌入是直接从单词在文本中的分布来表征单词的意思。这些表示被用在每一个利用意义的 NLP 应用中。</h2></div><p id="1407" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇文章的完整代码可以在<a class="ae lb" href="https://github.com/cleopatra27/Document-Similarity" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="da1f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">词义的一个重要组成部分是词义之间的关系。例如，当一个单词的意思与另一个单词的意思相同或几乎相似时，我们说这两个单词的两个意思是<strong class="kh ir">同义词</strong>。如<em class="lc">的关键</em> / <em class="lc">的命令式。</em></p><p id="72c0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然单词没有很多同义词，但大多数单词都有很多相似的术语。<em class="lc">饭</em>不是<em class="lc">豆</em>的同义词，但是<em class="lc">饭</em>和<em class="lc">豆</em>无疑是相近的词(都是食物)。在谈论词义之间的关系时，相似性是从同义词的一个有价值的转变；这将简化我们的任务。</p><p id="f3b9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将分析一系列莎士比亚的文本，并在我们的戏剧中寻找戏剧和文字之间的相似之处。我们的数据有一些来自不同莎士比亚戏剧的句子和戏剧的名字。</p><h1 id="f134" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">术语-文档矩阵</h1><p id="c0e8" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">意义的向量或分布模型通常基于共现矩阵，这是一种表示单词共现频率的方法。我们将实现两个流行的矩阵；术语-文档矩阵和术语-上下文矩阵。</p><p id="9008" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在术语-文档矩阵中，每行代表词汇表中的一个单词，每列代表文档集合中的一个文档。请看下面我们的实现:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="1288" class="mj le iq mf b gy mk ml l mm mn">def term_document(self, word_list):<br/>    for play, word in word_list:<br/>        if (play, word) in self.term_document_matrix:<br/>            self.term_document_matrix[(play, word)] += 1<br/>        else:<br/>            self.term_document_matrix[(play, word)] = 1<br/>    return self.term_document_matrix</span></pre><p id="fdcc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们矩阵中的数据示例如下:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="4e19" class="mj le iq mf b gy mk ml l mm mn">('Twelfth Night', 'love'): 77<br/>('Julius Caesar', 'come'): 75<br/>('Romeo and Juliet', 'enter'): 74</span></pre><p id="4ae8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面的意思是单词 enter 在戏剧《罗密欧与朱丽叶》的句子中出现了 74 次，以此类推。</p><p id="9c04" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以从上面的矩阵中计算出这些剧本之间的相似性，这可以使用<strong class="kh ir">余弦</strong>来完成。这基于线性代数中的点积运算符，可计算如下:</p><figure class="ma mb mc md gt mp gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/e8218d9ee4661526a4717b78b19b241d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*dI2U0weROtSw1me1ub0u4w.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">图片来自作者</p></figure><p id="2a29" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">余弦</strong>值的范围从指向相同方向的向量的 1 到正交向量的 0。</p><p id="3d5e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将利用 scipy 的空间库来实现这一点，如下所示:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="bf8e" class="mj le iq mf b gy mk ml l mm mn">def cos_sim(self, vector1, vector2):<br/>    cosine_similarity = 1 - spatial.distance.cosine(vector1, vector2)<br/>    print(cosine_similarity)</span></pre><p id="a91a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以通过一个小样本轻松验证这一点:</p><figure class="ma mb mc md gt mp gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/0ede3313b01bd15c77eceb03eb87caf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*dkajHKVk5rkTb92mZYgbzQ.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">图片来自作者</p></figure><figure class="ma mb mc md gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><div class="gh gi mx"><img src="../Images/d3b562768fdaac4bac72cd2147976579.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2EV5wHFrJuNQW1K_1fKLbw.png"/></div></div></figure><p id="0b6c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">实现此功能以进行测试:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="745e" class="mj le iq mf b gy mk ml l mm mn"><strong class="mf ir">apricot</strong> = [1, 0, 0]<br/><strong class="mf ir">digital</strong> = [0, 1, 2]<br/><strong class="mf ir">information</strong> = [1, 6, 1]<br/>print(self.cos_sim(apricot, digital))</span><span id="28bb" class="mj le iq mf b gy nc ml l mm mn">0.0</span></pre><p id="4141" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">测试其他样本也返回有效结果，太好了，现在让我们测试我们的数据，我们将相互比较我们的每个文档:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="f8fd" class="mj le iq mf b gy mk ml l mm mn">def cal_cosine(self, docs):<br/>    tf = self.read_csv()<br/>    play_dict = {}<br/>    for play in self.play_names:<br/>        play_vec = []<br/>        for word in self.vocab:<br/>            play_vec.append(tf[(play, word)])<br/>        play_dict[play] = play_vec<br/><br/>    scores = []<br/>    for k1, v1 in play_dict.items():<br/>        for k2, v2 in play_dict.items():<br/>            if k1 &lt;= k2: continue<br/>            scores.append((self.cos_sim(v1, v2), (k1 ,k2)))<br/>    scores.sort(reverse=True)<br/>    print(scores[:25])</span></pre><p id="5a3a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的顶级<strong class="kh ir">余弦相似点</strong>是:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="db25" class="mj le iq mf b gy mk ml l mm mn">(0.9885556994486011, ('Cymbeline', 'A Winters Tale')),(0.9817079988849085, ('Henry VI Part 2', 'Henry VI Part 1')),(0.9811981513422073, ('Alls well that ends well', 'A Winters Tale'))</span></pre><h1 id="1cdd" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">术语上下文矩阵</h1><p id="8a14" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">对于我们上面的计算，我们使用了频率，但原始频率可能会非常倾斜，要知道我们的单词或文档共享哪些上下文，停用词在这里或任何其他频繁出现的单词形式都没有用，不知何故，在你关注的单词附近出现的单词的频率更重要。</p><p id="2c4f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个问题的解决方案是使用<em class="lc"> tf-idf </em>加权，这是两项的乘积:</p><p id="6e3f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"><em class="lc">TF</em></strong>——这是词频，即单词<em class="lc"> t </em>在文档<em class="lc"> d、</em>中的出现频率，这是在日志空间中计算的:</p><figure class="ma mb mc md gt mp gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/81c86be0a6d3701d9123ad274e69c2b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*ORGcKSJ3YlgPKCE7eOXAtw.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">图片来自作者</p></figure><p id="538b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lc"> IDF </em> </strong> -本逆文档频率<strong class="kh ir"><em class="lc">N/df</em></strong>；其中 N 是集合中的文档总数，df 是一个术语出现在其中的文档数。这使得只在少数文档中出现的单词具有更高的权重。仅限于几个文档的术语有助于将这些文档与集合中的其他文档区分开来。术语出现的文档越少，权重越高，这也是在日志空间中计算的:</p><figure class="ma mb mc md gt mp gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/ee0cb12ed4f9372075c3565c7c7d220f.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*pWZVkdK_-9Jok7txHENYRQ.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">图片来自作者</p></figure><p id="3ed7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lc"> TF-IDF </em> </strong>是<strong class="kh ir"> <em class="lc"> TF </em> </strong>和<strong class="kh ir"> <em class="lc"> IDF </em> </strong>的点积，因此计算为:</p><figure class="ma mb mc md gt mp gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/4bd27297c47f5b5bdc85f2f99d7656d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*H5zuHVIz9K3NSmSy-l1Gag.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">图片来自作者</p></figure><p id="1a44" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们在当前的语料库上尝试一下，我们将从实现一个术语上下文矩阵开始，我们将查看每个单词和前后的 4 个单词，然后统计它在同一个单词周围出现的频率。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="b291" class="mj le iq mf b gy mk ml l mm mn">def term_context(self):<br/>    term_context = defaultdict(lambda: defaultdict(lambda: 0))<br/>    with open("ShakespearePlays_text.csv", "r") as f:<br/>        # load csv<br/>        reader = csv.reader(f, delimiter=";")<br/>        # loop through line in csv<br/>        for line in reader:<br/>            play_name = line[1]<br/>            if play_name not in self.play_names:<br/>                continue<br/>            tokens = line[5].split()<br/>            sentence = []<br/>            for term in tokens:<br/>                token = self.clean(term)<br/>                if token in self.vocab:<br/>                    sentence.append(token)<br/>            for i in range(len(sentence)):<br/>                word = sentence[i]<br/>                for j in range(max(0, i - 4), min(len(sentence), i + 5)):<br/>                    if i == j: continue<br/>                    term_context[word][sentence[j]] += 1<br/>    return term_context</span></pre><p id="dcbd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的术语上下文矩阵看起来像这样:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="44d0" class="mj le iq mf b gy mk ml l mm mn">'<strong class="mf ir">befortune</strong>': ({'i': 1, 'wish': 1, 'all': 1, 'good': 1, 'you': 1})</span><span id="469f" class="mj le iq mf b gy nc ml l mm mn">'<strong class="mf ir">bohemia</strong>': ({'chance': 1, 'camillo': 1, 'to': 4, 'visit': 1,'on': 1, 'difference': 1, 'betwixt': 1, 'our': 1, 'and': 5, 'your': 1, 'sicilia': 1, 'means': 1, 'pay': 1, 'the': 5, 'visitation': 1}</span></pre><p id="e4b1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们将构建我们的文档频率矩阵，我们将使用上面的术语上下文来完成这个任务，(以减少计算时间并使用更小的子集)，</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="7608" class="mj le iq mf b gy mk ml l mm mn">def cal_doc_freq(self, term_frequency):<br/>    values_per_key = {}<br/>    for k, v in term_frequency:<br/>        values_per_key.setdefault(k, set()).add(v)<br/>    counts = {k: len(v) for k, v in values_per_key.items()}<br/>    return counts</span></pre><p id="a3be" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用下面的公式计算术语上下文中所有单元格的文档频率:</p><figure class="ma mb mc md gt mp gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/60959ddba5c7a3e9f721f79730bb6e13.png" data-original-src="https://miro.medium.com/v2/resize:fit:472/format:webp/1*rd7xoceceCwVpnEvg9A7Gw.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">图片来自作者</p></figure><p id="6904" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将计算<strong class="kh ir"> <em class="lc"> TF-IDF </em></strong></p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="f15e" class="mj le iq mf b gy mk ml l mm mn">    t = self.read_csv()<br/>    counts = self.cal_doc_freq(t)<br/>    tc = self.term_context()<br/>    for i in tc:<br/>        for j in tc[i].keys():<br/>            tc[i][j] = tc[i][j] * (1 / counts[j])<br/>    return tc</span></pre><p id="df6e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将在我们的 vocab 的一个小子集上进行测试，并找到单词罗密欧、朱丽叶、贵族、凯撒和朋友与其他单词的相似性。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="e0a1" class="mj le iq mf b gy mk ml l mm mn">def compute_word_similarity(self, words):<br/>    tc = self.idf()<br/><br/>    def to_vec(w):<br/>        vec = []<br/>        for x in self.vocab:<br/>            vec.append(tc[w][x])<br/>        return vec<br/><br/>    for word in words:<br/>        word_vec = to_vec(word)<br/>        scores = []<br/>        c = 0<br/>        for k in tc.keys():<br/>            if k == word: continue<br/>            k_vec = to_vec(k)<br/>            scores.append((self.cos_sim(word_vec, k_vec), k))<br/>            c += 1<br/>            # if  c &gt; 10: break<br/>        scores.sort(reverse=True)<br/>        print("Top-5 matches for " + word + ": ", scores[:5])</span></pre><p id="bf2e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的前 5 个相似词是:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="6dab" class="mj le iq mf b gy mk ml l mm mn"><strong class="mf ir">Top-5 matches for romeo</strong>:  [(0.7349592582145151, 'dead'), (0.7291389527324256, 'he'), (0.7256033280986567, 'then'), (0.7237096963536124, 'it'), (0.719416236702853, 'where')]</span><span id="5ffb" class="mj le iq mf b gy nc ml l mm mn"><strong class="mf ir">Top-5 matches for juliet</strong>:  [(0.7840722487008701, 'lucius'), (0.7700540752904482, 'servants'), (0.7692483251584336, 'soldiers'), (0.7682255792237922, 'warwick'), (0.7672900349518263, 'others')]</span><span id="ffd7" class="mj le iq mf b gy nc ml l mm mn"><strong class="mf ir">Top-5 matches for nobleman</strong>:  [(0.8139265551526883, 'woman'), (0.813455008644156, 'soldier'), (0.808373550553078, 'little'), (0.8053083580334184, 'gentleman'), (0.8046068607590102, 'stranger')]</span><span id="0af7" class="mj le iq mf b gy nc ml l mm mn"><strong class="mf ir">Top-5 matches for caesar</strong>:  [(0.8897940437391335, 'him'), (0.8825311102107262, 'them'), (0.8718307075270313, 'that'), (0.8707738937545483, 'his'), (0.8674185090147457, 'me')]</span><span id="7cf7" class="mj le iq mf b gy nc ml l mm mn"><strong class="mf ir">Top-5 matches for friend</strong>:  [(0.9280138220686541, 'wife'), (0.9239327316145367, 'daughter'), (0.9111186066627961, 'father'), (0.9091224168395339, 'brother'), (0.9086148854991047, 'mother')]</span></pre><p id="13b5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这看起来很合理，因为朋友——妻子、女儿、兄弟、父亲和母亲确实有一些相似之处。贵族和绅士或许还有士兵有一些相似之处，等等。</p><p id="1b16" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我确信有办法让我们的预测更准确，但这是一个好的开始。</p><p id="826a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">期待问题、评论和反馈。谢了。</p></div></div>    
</body>
</html>