<html>
<head>
<title>Learn with me: Image captioning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">跟我学:图像字幕</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learn-with-me-image-captioning-48f22c168912?source=collection_archive---------32-----------------------#2021-04-25">https://towardsdatascience.com/learn-with-me-image-captioning-48f22c168912?source=collection_archive---------32-----------------------#2021-04-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c55a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">让我们一起学习并创建一个神经网络模型，它以一幅图像作为输入，并返回一个描述性文本作为输出。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d64972ea61ad4a0a74f164a57054b0a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sBITUJ2ng6JqaMcE"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">k .米奇·霍奇在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="66c6" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">介绍</h2><p id="1262" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">不久前，我开始尝试“图像字幕”的问题。这里，目的是为给定的图像生成文本描述。类似于一个人如何向他的同伴描述一幅画。正如在实验中经常发生的那样，你不会直接得到最佳解决方案——你会尝试、犯错、改进自己，然后最终得到一个不错的解决方案。这正是我对这个项目的探索。在本文中，我想介绍我是如何开始解决这个问题的，偶然发现一个不太好的解决方案，但最终达到了“足够好”的状态。所以，让我们开始吧！</p><h2 id="6b21" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">问题定义</h2><p id="cfd7" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">如前所述，任务是为图像生成自然语言描述或标题。这个问题非常有趣，因为它是两个领域的结合——计算机视觉(CV)和自然语言处理(NLP)。因此，要想出一个手写的高级解决方案，我们需要这样做——将图像作为输入，用CV做一些魔术，用一个做一些NLP魔术的块修补它，并期望文本描述作为输出。听起来很简单，对吗？让我们试试这个。😃</p><h2 id="6605" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">资料组</h2><p id="5dde" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在深入研究技术细节之前，让我们花一些时间来理解我们的数据集——“Flickr 8k”。它由8091个图像(大小不同)组成，每个图像有5个不同的标题，因此标题总数为8091*5=40455。我们有一个图像文件夹(包含所有的图像)，和一个标题文本文件(CSV格式)，将每张图像映射到它的5个标题。首先，让我们看看字幕文件是什么样子的，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ml"><img src="../Images/e80a6d51e5504a686ea03c99047c2cc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7ZEywnG5VilolBDkEIhGIQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">标题CSV(按作者)</p></figure><p id="81a5" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">让我们也来看一些图片和它们各自的标题，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/1f795eaee974a6885cafb34c368a9605.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*2SccYWqWS-9PkZ0mjNUh-g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">带标题的示例图像(由作者提供)</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/5757e5c77ca7f5f032974d492adf6e02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*AG0bknYSM2Nf1F55Vdsapw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">带标题的示例图像(由作者提供)</p></figure><h2 id="5bb2" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">模型架构——第一次尝试</h2><p id="cdbd" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">拐弯抹角说够了，让我们来形式化我们将用来解决这个问题的神经网络模型的架构。正如我们已经讨论过的，整个流程看起来会像这样，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/7f3535ede6728c42579eb2f1fd8eb1a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KkI9X5vuRp-I_jQiaP_rJg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">我们将在本文中创建的解决方案的高级流程(按作者)</p></figure><p id="a008" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">现在选择第一部分，也就是说，首先，我们要用计算机视觉来处理图像。这种“处理”通俗的解释就是把一个图像作为输入，转换成矢量表示。在这样做的同时，希望网络将学习到字幕所需的重要信息，而忘记不相关的信息。所以我们希望图像作为输入，向量作为输出。在CV中最常见的方法是使用卷积神经网络。详细讨论CNN超出了本文的范围，但是为了简单的细节，我将建议<a class="ae kv" href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank">这个</a>。首先，为了测试waters，我们可以创建简单的CNN图层。代码如下所示，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/28d9cbc1b7e04a626cff87ee7c6e9d12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*0578XJR6CQ1rgw2RX4iFVA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">CNN部分的代码(按作者)</p></figure><p id="980d" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">理解代码，</p><ul class=""><li id="1232" class="mu mv iq lu b lv mm ly mn lf mw lj mx ln my mk mz na nb nc bi translated"><strong class="lu ir">第6行:</strong>初始化顺序Keras模型</li><li id="7a7e" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir">第9–21行:</strong>你可以看到一对多次使用的<code class="fe ni nj nk nl b">Conv2D</code>和<code class="fe ni nj nk nl b">MaxPooling2D</code>层。这是定义CNN模型最常见的方式之一。</li><li id="27c8" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated">第23行:我们展平最后一层，创建一个矢量作为图像表示。</li><li id="c5cd" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir">第24行:</strong>这是最终的CNN图层，我们已经将图像表示缩减为256D大小的矢量。</li></ul><p id="92de" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">接下来，我们希望将这个向量表示输入到NLP模块中，该模块将生成输出文本描述。为此，我们可以使用LSTM，这是一个递归层类型的神经网络。它可以很好地处理任何序列数据，其中它处理序列的每个元素并生成各自的向量表示。更多细节，我会建议<a class="ae kv" href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks#architecture" rel="noopener ugc nofollow" target="_blank">这篇</a>和<a class="ae kv" rel="noopener" target="_blank" href="/a-practical-guide-to-rnn-and-lstm-in-keras-980f176271bc">这篇</a>文章。所以如果你看到，我们的描述，也就是文本，遵循连续的顺序，因此非常适合递归型NN。所以我们需要文本作为输出，因此LSTM将图像向量作为输入，并给出向量表示，我们将使用softmax函数将其转换为单词。这将使字幕写作模型成为一个分类模型，在每一步中，我们将预测每个单词的概率，并选择具有最高值的一个。这将在所有步骤中重复(LSTM模型的大小，通常是固定文本描述的大小)。NLP解码器模块可以被编码为，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/d485eb655e5ee23241c2ca182f7e10f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wRo_vQjSHKXCuMB0SYAz4g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">NLP部分的代码(按作者)</p></figure><p id="416e" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">理解代码，</p><ul class=""><li id="0c66" class="mu mv iq lu b lv mm ly mn lf mw lj mx ln my mk mz na nb nc bi translated"><strong class="lu ir">第2行:</strong>由于LSTM层需要输入到它的所有步骤，我们将重复图像向量并将其传递到LSTM的所有步骤作为输入。这里的步长是<code class="fe ni nj nk nl b">config['max_len']</code> (=39)。</li><li id="189d" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir">第三行:</strong>LSTM层。<code class="fe ni nj nk nl b">return_sequence</code>为真，因为我们希望返回所有步骤的输出。</li><li id="c818" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir">第4–5行:</strong>对于每一步，我们将把向量表示传递给一个密集层，该层充当分类器部分，并挑选一个<code class="fe ni nj nk nl b">config['max_vocab']</code> (=10k)单词。在所有的步骤中这样做，我们将得到我们的标题！</li></ul><p id="32ec" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">如果你对<code class="fe ni nj nk nl b">max_vocab</code>和<code class="fe ni nj nk nl b">max_len</code>感到困惑，不要担心，在下一节中它会变得清晰。</p><h2 id="b686" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">数据准备和数据生成器</h2><p id="56d5" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">现在我们已经修复了我们的架构，让我们看看如何处理数据加载并使用它来训练模型。首先要做的是转换文本数据。代码如下所示，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/48120f3391d78d82063216d1cdf1c12b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0V7G5YZMCsNJJ59QGe5xLA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">清理、标记和填充标题文本(按作者)</p></figure><p id="9816" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">理解代码，</p><ul class=""><li id="70bc" class="mu mv iq lu b lv mm ly mn lf mw lj mx ln my mk mz na nb nc bi translated"><strong class="lu ir">第6行:</strong>为我们的每个标题添加前缀&lt;开始&gt;和后缀&lt;结束&gt;。这将使我们的递归模块更容易了解标题的边界。</li><li id="4177" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir">第8–12行:</strong>我们在这里做了很多事情。总的来说，我们希望将文本从单词序列转换为数字序列，因为数字是神经网络所能理解的。在此之前，我们还(1)删除非字母字符，(2)仅考虑<code class="fe ni nj nk nl b">config['max_vocab']</code> (=10k)唯一的单词，以及(3)将任何其他单词表示为0。</li><li id="6271" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir">第14–15行:</strong>我们想让每个序列(标题用数字符号表示)长度相同，为此我们填充较小的序列来匹配最大的序列<code class="fe ni nj nk nl b">config['max_len']</code> (=39)。这会用0填充较小序列的右侧。</li></ul><p id="0944" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">预处理完成后，我们就可以创建数据生成器了，它将加载数据并将其传递给模型进行训练。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/1b6196d6e259bd0b73bf3b0b7bba761a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RAZvoO8bJ-_QLfTy0VNk1Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据生成器(按作者)</p></figure><p id="4d05" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">理解代码，</p><ul class=""><li id="f027" class="mu mv iq lu b lv mm ly mn lf mw lj mx ln my mk mz na nb nc bi translated"><strong class="lu ir">第1行:</strong>我们的函数接受以下输入，(1) <code class="fe ni nj nk nl b">pick_from_caption_indices</code>:我们可以从中随机采样的标题的索引，(2) <code class="fe ni nj nk nl b">batch_size</code>:一次返回的(图像，标题)对的数量，以及(3) <code class="fe ni nj nk nl b">reproduce</code>:设置随机种子的标志，以便我们返回相同顺序的(图像，标题)对。</li><li id="e47d" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir">第2行:</strong>因为这是一个数据生成器，所以函数会不断迭代。因此这里出现了无限循环。另外，请注意第25行的<code class="fe ni nj nk nl b">yield</code>使这成为可能。</li><li id="14cb" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir">第8–10行:</strong>从字幕CSV中随机抽取字幕及其相应图像的路径。</li><li id="8806" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir">第12行:</strong>我们重复下面的过程，直到(图像，标题)对等于<code class="fe ni nj nk nl b">batch_size</code> (=32)。</li><li id="be9d" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir">第14–16行:</strong>从驱动器加载图像，并将其调整为(229，229，3)形状。这将确保每个图像的大小相同。此外，我们通过保留所有3个通道来保留颜色信息。接下来，我们还将图像像素值归一化到0和1之间。</li><li id="c605" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir">第18–19行:</strong>将序列数据(来自预处理)转换为一键编码，以便进行分类。它接受一个长度为39的数字序列，并返回一个大小为(39，10000)的矩阵。这是因为我们的最大词汇大小是10k，所以对于序列的每一步，我们创建一个10k大小的向量，除了该步的数字之外，其他地方都是0。</li><li id="911f" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir">第28–29行:</strong>创建两个数据生成器，一个用于训练，另一个用于测试。注:对于测试，我们有<code class="fe ni nj nk nl b">reproduce=True</code>,因为无论是模型还是试验，我们都希望测试相同的数据。此外，<code class="fe ni nj nk nl b">train_indices</code>和<code class="fe ni nj nk nl b">test_indices</code>可以通过从标题CSV中抽取80%的索引来轻松创建(更多细节见<a class="ae kv" href="https://www.kaggle.com/evilmage93/image-captioning-on-flickr8k" rel="noopener ugc nofollow" target="_blank">代码</a></li></ul><h2 id="98d1" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">培训和结果— v1</h2><p id="5094" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">现在我们已经准备好了模型和数据生成器，让我们来训练模型。在这里，我们所要做的就是定义一些回调函数并编写训练程序。代码如下所示，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/741e25772787ee81273bb3d2b1d8d4af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N0mbOCgY7EjuVxnHGvgG2Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">培训脚本(作者)</p></figure><p id="9fae" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">理解代码，</p><ul class=""><li id="f0a3" class="mu mv iq lu b lv mm ly mn lf mw lj mx ln my mk mz na nb nc bi translated"><strong class="lu ir">第2–4行:</strong>检查点回调，保存过去10个时期的最佳模型。</li><li id="502b" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir">第5行:</strong>提前停止回调，如果我们在10个时期内没有看到任何显著的进步，则停止训练。</li><li id="8c0c" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir">第8行:</strong>通过定义优化器和损失函数来编译模型。</li><li id="4d10" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir">第11–16行:</strong>使用<code class="fe ni nj nk nl b">fit</code>功能训练模型。它接受以下输入，(1)训练数据生成器，(2)要训练的最大时期(这里是100)，(3)每个时期的步骤(这里是1000)，(4)进度详细级别，以及(5)定义的回调。</li></ul><p id="269d" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">训练会花一些时间，但是对于支持GPU的系统来说，会快很多。对我来说，训练过程在25个纪元后停止，损失约为1.65。这个完整的过程大约需要2小时30分钟。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/7463f7fba4375ba6cc17ece6bc948b03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*lfeiI0AstbddK8OtqFnw0w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">v2(按作者)的历元(x轴)上的训练损失(y轴)</p></figure><p id="a58b" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">现在我的期望很低，但我仍然很好奇，想看看结果。退一步说，结果并不太好😅。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/c6ea55aabd2bbd9502338c969673ddcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jEJ21Kbalh7oi22nkyYpIQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">v1的样本测试图像结果(由作者提供)</p></figure><p id="57a3" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">似乎我们的模型学习的只是一个单一的模式，所有的图像都预测到了同样的模式。这很糟糕，但是你注意到描述总是以一个<start>标记开始吗！至少模型那东西没错。😃</start></p><h2 id="7389" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">丰富</h2><p id="29fb" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">现在的问题是——为了改善结果，我们接下来应该修改什么，CV部分还是NLP部分？经过一番阅读，我得出了这个结论——为什么不两者都要呢？这是我接下来做的，</p><ul class=""><li id="2462" class="mu mv iq lu b lv mm ly mn lf mw lj mx ln my mk mz na nb nc bi translated"><strong class="lu ir">计算机视觉</strong> — <strong class="lu ir">使用已经在大型图像数据集上训练过的预训练模型</strong>。这种将在一项任务中训练的模型用于另一项任务的过程被称为“迁移学习”。这里的主要思想是，预先训练的模型为新任务提供了推动力，因为它已经学会了从图像中提取重要的特征。把这想象成创建一个网络，而不是用随机数初始化权重，我们使用以前工作过的预训练权重。Keras包在其应用部分提供了几个这样的预训练模型。我们使用“<strong class="lu ir">exception</strong>”预训练模型，它很小，但具有相当好的准确性。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/3a2f2ca4ae0fd0df9335a83d23e8cb61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*977GahjhjSdNRSTrvb2yQA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自<a class="ae kv" href="https://keras.io/api/applications/" rel="noopener ugc nofollow" target="_blank"> Keras应用网站</a>的前5个预培训应用。(作者)</p></figure><ul class=""><li id="5df3" class="mu mv iq lu b lv mm ly mn lf mw lj mx ln my mk mz na nb nc bi translated"><strong class="lu ir">自然语言处理</strong> — <strong class="lu ir">使用双向LSTM </strong>被证明可以改善序列数据编码。双向LSTM(或biLSTM)基本上是一个堆叠在另一个之上的LSTM，但有一个扭曲。一个LSTM从左到右处理序列，而另一个以相反的方向处理。因此，我们得到了一个方向不可知的嵌入。我会建议<a class="ae kv" rel="noopener" target="_blank" href="/guide-to-custom-recurrent-modeling-in-keras-29027e3f8465">这篇</a>文章(自私的自我推销😃)，它比较了一个简单分类任务的不同重现图层。</li></ul><p id="93f4" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">在Keras中执行这些修改非常容易，新的模型定义脚本如下所示(适用于CV和NLP)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/02ec30c736439e69a254efbd7d4ed21e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g4KnHNU7OcRzYMaybCmh6Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">修改后的型号代码(作者)</p></figure><p id="3489" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">理解代码，</p><ul class=""><li id="5f18" class="mu mv iq lu b lv mm ly mn lf mw lj mx ln my mk mz na nb nc bi translated"><strong class="lu ir">第8–16行:</strong>我们加载<strong class="lu ir">异常</strong>应用程序，并将其附加到模型上。我也使这一层不可训练。最后，我添加了一个256D的密集层，以获得最终的翻译图像。</li><li id="a05d" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir">第19–21行:</strong>一切都和以前一样，除了第20行，我在那里添加了双向LSTM。</li></ul><h2 id="57a5" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">培训和结果— v2</h2><p id="c807" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">训练代码和以前一样。这次模型训练了超过75个纪元，用了~7个小时！损失值也突破了1大关。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/82e13b889ff58e9d1ba17521be0cb3ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*OmDaXHxPohzMJuvLH35fzA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">v2(按作者)的历元(x轴)上的训练损失(y轴)</p></figure><p id="674f" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">这一次我真的支持这个模型，让我们看看同样的测试图片的标题是什么样子的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/15dfcc26b8c281d854fd01f9ef71a01c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MA7OeRBvZ4-rziHuv8XHeg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">v2的样本测试图像结果(由作者提供)</p></figure><p id="a7bd" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">这个比上一个好多了！想想我们的模型只有15行代码！我认为我们可以在这里停止，至少现在。</p><h2 id="c5e9" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">下一步是什么？</h2><p id="bfe7" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">即使结果很好，也不是完美的。如果你仔细观察，标题不是以<end>符号结束的。此外，虽然字幕的开头很好，但在字幕的过程中，它变得有点没有意义。因此，有很大的改进空间。我有以下想法，我想接下来尝试一下，</end></p><ul class=""><li id="7657" class="mu mv iq lu b lv mm ly mn lf mw lj mx ln my mk mz na nb nc bi translated"><strong class="lu ir"> CV: </strong> (1)从Keras应用列表中尝试更好的预训练模型。(2)使预训练的模型可训练(将增加参数和时间，但是也应该增加精度)，(3)在应用层之后添加更多可训练的FC层，等等。</li><li id="1341" class="mu mv iq lu b lv nd ly ne lf nf lj ng ln nh mk mz na nb nc bi translated"><strong class="lu ir"> NLP: </strong> (1)使用多个biLSTM栈，(2)使用attention或transformers或BERT</li></ul><h2 id="0815" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">结论</h2><p id="014b" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">学习是一个持续的过程，只有当你真的生病了，或者像我一样，周末即将结束时，你才应该停下来😅。这篇文章背后的想法不是展示最好的图像字幕解决方案，而是通过人工智能/人工智能解决问题的过程。目的是向读者介绍实验的想法，并推动他们不只是复制解决方案，而是尝试创造自己的解决方案。对我来说也是如此，因为我认为试图在一个系统的流程中处理问题确实有助于人们将问题内在化。</p><p id="9e29" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">无论如何，我选择了这个问题，因为它是两个不同领域的结合——CV和NLP。因此，它有可能帮助我同时应用这两个领域的知识。这就像是一石二鸟。希望这有所帮助！</p></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><p id="2318" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">本文中使用的代码可从<a class="ae kv" href="https://www.kaggle.com/evilmage93/image-captioning-on-flickr8k" rel="noopener ugc nofollow" target="_blank">这里</a>获得。随意发挥，随意修改。</p><p id="3cfc" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">你可以在<a class="ae kv" href="https://www.linkedin.com/in/imohitmayank/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上和我联系。</p><p id="0ad2" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">干杯。</p></div></div>    
</body>
</html>