<html>
<head>
<title>Open-sourcing Tipoca Stream</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">开源的Tipoca流</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/open-sourcing-tipoca-stream-f261cdcc3a13?source=collection_archive---------25-----------------------#2021-06-18">https://towardsdatascience.com/open-sourcing-tipoca-stream-f261cdcc3a13?source=collection_archive---------25-----------------------#2021-06-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="94a4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">以近乎实时的方式将数据从Kafka转换到Redshift</h2></div><p id="77ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi lb translated">在AWS中使用Kafka、KafkaConnect和RedshiftSink创建云原生近实时数据管道的故事。CDC + Sink。RedshiftSink是Practo新推出的开源项目。它配备了一个高性能低开销的数据加载器，用于在Redshift中加载数据，并提供丰富的<a class="ae lk" href="https://github.com/practo/tipoca-stream/blob/master/MASKING.md" rel="noopener ugc nofollow" target="_blank">屏蔽支持</a>，以确保您能够以保护隐私的方式在您的组织中创建通用数据访问。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/a216cd7b41ff399eb8b2ee7f931c1986.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*omYOg7ceJzciV6nbaZZ_5A.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">蒂波卡河2021:作者图片，<a class="ae lk" href="https://github.com/practo/tipoca-stream/blob/master/build/arch.png" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="58b0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">直接进入我们在GitHub上的<a class="ae lk" href="https://github.com/practo/tipoca-stream" rel="noopener ugc nofollow" target="_blank">回购</a>开始吧。🏊</p><h1 id="2039" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">背景</h1><p id="04a7" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">2015年，我们编写了内部事务数据复制器<a class="ae lk" href="https://starwars.fandom.com/wiki/Tipoca_City" rel="noopener ugc nofollow" target="_blank"> Tipoca </a>，用于bootstrap Practo的仓库。它曾经在PII屏蔽支持下将数据从我们的事务数据库复制到Redshift。它每天晚上刷新数据，应用最新的掩码配置进行完整的重新创建。Practo的每个人第一次能够访问所有数据，并能够在保护客户隐私的同时连接不同系统的数据。</p><p id="33d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当时，构建分布式系统需要大量的工作。我们构建了一个具有不同流程的系统，跨多个工作人员运行，并通过重试来管理他们的协调。在开源技术和工具的帮助下，构建分布式系统已经变得越来越容易。这是蒂波卡的样子:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi my"><img src="../Images/fbe9877975741627e3d356b774e2771b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BGCGZdhUHULn1h88FuQ-mQ.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">2015年蒂波卡:作者图片</p></figure><h1 id="747f" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">超越蒂波卡的动力</h1><ol class=""><li id="78b8" class="mz na iq kh b ki mt kl mu ko nb ks nc kw nd la ne nf ng nh bi translated">实时数据分析。</li><li id="90de" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ne nf ng nh bi translated">更快的红移查询。大批量负载占用红移资源。同步数据的需要不同。</li><li id="4779" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ne nf ng nh bi translated">数据驱动的产品。</li><li id="ed9d" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ne nf ng nh bi translated">每天重新创建数据是不可扩展的，而且成本高昂。</li><li id="3257" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ne nf ng nh bi translated">移除对RDS读取副本的分析依赖。</li></ol><p id="92d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这导致了蒂波卡流的诞生，结束了蒂波卡5年的运行。</p><h1 id="dcfc" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">引入蒂波卡流</h1><p id="354e" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">2020年7月，我们开始讨论迁移到<a class="ae lk" href="https://en.wikipedia.org/wiki/Change_data_capture" rel="noopener ugc nofollow" target="_blank"> CDC </a>平台的计划。这个想法是将运行在RDS上的事务数据库中的数据以近乎实时的方式传输到Redshift。我们选择卡夫卡主要有两个原因——第一，卡夫卡是开放的；第二，它周围有很好的数据生态系统。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/a216cd7b41ff399eb8b2ee7f931c1986.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*omYOg7ceJzciV6nbaZZ_5A.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">蒂波卡流2021:作者图片，<a class="ae lk" href="https://github.com/practo/tipoca-stream/blob/master/build/arch.png" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="d76a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一部分(CDC)是开源的。我们使用<a class="ae lk" href="http://debezium.io" rel="noopener ugc nofollow" target="_blank"> Debezium </a>将RDS流写入Kafka。<a class="ae lk" href="https://strimzi.io" rel="noopener ugc nofollow" target="_blank"> Strimzi </a>有开源的<strong class="kh ir"> KafkaConnect </strong>和<strong class="kh ir"> Kafka </strong>作为<strong class="kh ir"> Kubernetes CRDs。</strong></p><pre class="lm ln lo lp gt nn no np nq aw nr bi"><span id="8748" class="ns mc iq no b gy nt nu l nv nw">kubectl get kafka<br/>kubectl get kafkaconnect<br/>kubectl get kafkaconnector</span></pre><p id="9097" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在卡夫卡中，我们使用AVRO以紧凑的二进制格式存储数据。AVRO很快，使用AVRO，您可以在模式注册中心定义和存储数据模式。<a class="ae lk" href="https://github.com/practo/tipoca-stream/blob/22ba8370550891e8b64c667785136e51b603fb38/redshiftsink/pkg/schemaregistry/schemaregistry.go#L12-L19" rel="noopener ugc nofollow" target="_blank">这是我们使用的模式注册中心的接口</a>。</p><p id="3c04" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">RedshiftSink解决了第二部分。它将数据从卡夫卡主题下沉到红移。它有丰富的<a class="ae lk" href="https://github.com/practo/tipoca-stream/blob/master/MASKING.md" rel="noopener ugc nofollow" target="_blank">屏蔽</a>支持，并支持所有模式迁移。</p><p id="8ce4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">眼睛多了软件更好！我们对开源红移链接感到兴奋。它可作为Kubernetes红移链运营商。🎉</p><pre class="lm ln lo lp gt nn no np nq aw nr bi"><span id="4fad" class="ns mc iq no b gy nt nu l nv nw">kubectl get redshiftsink</span></pre><p id="63d3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你<strong class="kh ir">可以直接跳转到GitHub 上的</strong> <a class="ae lk" href="https://github.com/practo/tipoca-stream" rel="noopener ugc nofollow" target="_blank"> repo来自己尝试一下。请继续阅读，理解下面实现的核心概念。</a></p><h1 id="3ce8" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">核心组件</h1><h1 id="1aff" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated"><strong class="ak">红移追踪器</strong></h1><p id="6e21" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">RedshiftBatcher从Kafka读取数据，对其进行屏蔽，然后以微批处理的形式上传到S3。然后，它向红移加载器发送信号，将这些批次加载到红移。</p><p id="79a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">为什么要在流媒体平台上批量？</strong></p><p id="c320" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Redshift擅长使用<a class="ae lk" href="https://docs.aws.amazon.com/redshift/latest/dg/r_COPY.html" rel="noopener ugc nofollow" target="_blank"> COPY </a>命令快速摄取数百万条记录。每个文件副本都有开销，因此需要在文件数量和每个文件中的记录数量之间取得平衡。这就是为什么我们要小批量复制。您可以使用maxSizePerBatch和maxWaitSeconds来控制这些。</p><pre class="lm ln lo lp gt nn no np nq aw nr bi"><span id="977c" class="ns mc iq no b gy nt nu l nv nw">spec:<br/>  kafkaTopicRegexes: "db.inventory.*"<br/>  batcher:<br/>    sinkGroup:<br/>      reload:<br/>        maxReloadingUnits: 2<br/>        maxSizePerBatch: 10Mi<br/>        maxWaitSeconds: 30</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nx"><img src="../Images/1606a200daa1b040d3fe757724a6a976.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*G_QTi1vfaiaMMXOM"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">图片作者，<a class="ae lk" href="https://github.com/practo/tipoca-stream/blob/master/build/arch-batcher.png" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="68a0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每一个话题都是一张桌子，都有自己的卡夫卡消费群体。批处理程序中的每个主题都会发生以下情况:</p><ul class=""><li id="38b5" class="mz na iq kh b ki kj kl km ko ny ks nz kw oa la ob nf ng nh bi translated">管理器例程创建并优雅地关闭使用者组。</li><li id="0fa0" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ob nf ng nh bi translated">萨拉马消费者团体关注卡夫卡主题，并用新信息填充阅读频道。</li><li id="93ce" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ob nf ng nh bi translated">读取器将收到的消息写入读取缓冲区。</li><li id="4c88" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ob nf ng nh bi translated">当达到批处理大小或时间过去时，读取器将批处理刷新到进程通道。缓冲通道用于分离消息的接收和处理。</li><li id="7afc" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ob nf ng nh bi translated">Orchestrator例程使多个批处理并发进行。当处理完成时，它向Kafka发送这些批次的加载信号。</li><li id="5d34" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ob nf ng nh bi translated">提交给Kafka，将偏移标记为已处理。</li></ul><p id="44c6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">配料员的职责:</strong></p><ul class=""><li id="d3ff" class="mz na iq kh b ki kj kl km ko ny ks nz kw oa la ob nf ng nh bi translated"><strong class="kh ir">转换:</strong>将批处理中的每个Debezium消息转换为Redshift可加载格式。我们分叉并改变了开源的<a class="ae lk" href="https://github.com/practo/tipoca-stream/tree/master/redshiftsink/pkg/redshift" rel="noopener ugc nofollow" target="_blank">红移</a>库，将所有与红移的通信作为这个库的一部分。我们用两个附加字段注释每个消息:operation和kafka-offset。在加载到Redshift之前，RedshiftLoader使用这些字段执行合并操作。</li><li id="c516" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ob nf ng nh bi translated"><strong class="kh ir">面膜:</strong>面膜一直是我们最重要的需求。默认情况下，从RDS到红移的数据被完全屏蔽，除非开发人员指定不屏蔽它。未屏蔽的配置作为文件保存在GitHub中。按照GitHub Pull的要求，开发人员和分析师指定不要屏蔽什么。一旦安全工程师审查并批准了更改，RedshiftSink操作人员就会负责将这些掩码更改应用到红移。第一次接收中的RedshiftBatcher CPU要求也很高，因为它必须进行屏蔽处理。这里有<a class="ae lk" href="https://github.com/practo/tipoca-stream/issues/173" rel="noopener ugc nofollow" target="_blank">改进</a>的空间。以下是屏蔽功能，详情请查看<a class="ae lk" href="https://github.com/practo/tipoca-stream/blob/master/MASKING.md" rel="noopener ugc nofollow" target="_blank">和</a>。</li><li id="56b8" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ob nf ng nh bi translated"><strong class="kh ir">上传批处理到S3 </strong>:一旦转换完成，我们在S3上传批处理。批量写入是一个幂等操作，因此批量的重新处理不成问题。但是我们会优雅地关闭，重新处理的机会非常少。很少见，因为Kafka的提交是异步的，以保持批处理的速度。</li><li id="d089" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ob nf ng nh bi translated"><strong class="kh ir">信号:</strong>对于主题db.inventory.customers，批处理器读取来自该主题的消息，处理数据并上传到S3。然后，它在主题loader-db.inventory.customers中添加一个作业，由RedshiftLoader读取该作业以在Redshift中加载批处理。下面是作业模式:</li></ul><pre class="lm ln lo lp gt nn no np nq aw nr bi"><span id="d462" class="ns mc iq no b gy nt nu l nv nw">var JobAvroSchema string = `{<br/>    "type": "record",<br/>    "name": "redshiftloader",<br/>    "fields": [<br/>        {"name": "upstreamTopic", "type": "string"},<br/>        {"name": "startOffset", "type": "long"},<br/>        {"name": "endOffset", "type": "long"},<br/>        {"name": "csvDialect", "type": "string"},<br/>        {"name": "s3Path", "type": "string"},<br/>        {"name": "schemaId", "type": "int"},<br/>        {"name": "maskSchema", "type": "string"},<br/>        {"name": "skipMerge", "type": "string", "default": ""}<br/>    ]<br/>}`</span></pre><h1 id="7f18" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">红移装载机</h1><p id="a9bd" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">RedshiftLoader将已处理的批处理从S3加载到红移。</p><p id="5c45" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">RedshiftLoader监视批处理程序编写的主题。由于红移连接有限，因此使用尽可能少的加载程序执行加载非常重要。在单个加载器pod中，我们在所有加载器例程之间共享红移连接。</p><pre class="lm ln lo lp gt nn no np nq aw nr bi"><span id="a048" class="ns mc iq no b gy nt nu l nv nw">spec:<br/>  loader:<br/>    redshiftGroup: non_pii<br/>    redshiftSchema: inventory<br/>    sinkGroup:<br/>      all:<br/>        maxSizePerBatch: 1Gi</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nx"><img src="../Images/132609b0bddfd95a08e2421846511e9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yoZQWfTLQdeJ3QeG"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">图片作者，<a class="ae lk" href="https://github.com/practo/tipoca-stream/blob/master/build/arch-loader.png" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="37e2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你通过<code class="fe oc od oe no b">maxSizePerBatch</code>指定加载多少！</p><p id="9265" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">加载程序希望批中的每个消息都具有相同的模式。如果批处理程序为消息找到了新的模式，它将负责刷新现有的批处理。</p><p id="55a6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Debezium和RedshiftBatcher都将模式存储在模式注册表中。当需要获取模式相关信息时，批处理程序和加载程序都会与模式注册中心进行对话。</p><p id="b721" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">装载机的职责</strong></p><ul class=""><li id="142d" class="mz na iq kh b ki kj kl km ko ny ks nz kw oa la ob nf ng nh bi translated"><strong class="kh ir">模式迁移:</strong>开发团队随着他们的代码发布不断地改变RDS模式。我们需要使红移模式与RDS中发生的模式变化保持同步。因此，我们编写了一个模式迁移器。通过读取批处理中的第一条消息，加载程序判断是否需要执行模式迁移。它通过从作业负载中提取schema-id来实现这一点。然后，它从模式注册表中获取模式信息，并使用该信息构建一个输入红移表。然后将输入红移表与红移中的实际表进行比较，并决定模式迁移策略。Redshift并不支持所有的SQL迁移命令，例如，它们只支持很少的ALTER命令。第一个策略是尝试就地迁移，如果第一个策略不可行，我们重新创建完整的表并替换它。第二个策略对于大牌桌来说非常耗时。我们计划将大模式迁移从RedshiftLoader中移除，并让操作者执行大模式操作。</li><li id="9ba6" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ob nf ng nh bi translated"><strong class="kh ir">合并加载:</strong>如前所述，复制是向红移添加数据的最有效方式。但是单独复制只能做插入。因此，我们需要使用阶段表的合并技术来执行红移中的更新。YELP红移连接器<a class="ae lk" href="https://engineeringblog.yelp.com/2016/10/redshift-connector.html" rel="noopener ugc nofollow" target="_blank">文章</a>和<a class="ae lk" href="https://docs.aws.amazon.com/redshift/latest/dg/merge-examples.html" rel="noopener ugc nofollow" target="_blank"> AWS文档</a>对使用这种技术有很好的解释。虽然YELP的文章很有帮助。</li></ul><h1 id="99bb" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated"><strong class="ak">红移链操作符</strong></h1><p id="267b" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">Kubernetes操作员帮助将编排和操作交由操作员完成。谢谢Kubernetes！</p><pre class="lm ln lo lp gt nn no np nq aw nr bi"><span id="feb1" class="ns mc iq no b gy nt nu l nv nw">kubectl get deploy redshiftsink-operator</span></pre><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nx"><img src="../Images/b54bd924c5aedc965eeaf3e7af883102.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GGmP-AibXglaIEVS"/></div></div></figure><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nx"><img src="../Images/5aa77804b78fe481422684d334340bcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vVecgq4TftDapHiE"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">图像<a class="ae lk" href="https://twitter.com/kelseyhightower/status/1298343780307755008?s=20" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="ad5b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们使用Kubernetes <a class="ae lk" href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/resource-management.md#the-kubernetes-resource-model-krm" rel="noopener ugc nofollow" target="_blank">声明式API</a>解决了以下问题:</p><ol class=""><li id="8773" class="mz na iq kh b ki kj kl km ko ny ks nz kw oa la ne nf ng nh bi translated">真人面具重装。</li><li id="445b" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ne nf ng nh bi translated">用户得到一个简单干净的API。</li></ol><p id="15ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该操作符帮助我们管理表的第一时间槽，并在更新掩码配置时帮助我们在Redshift中重新加载表。</p><p id="d3aa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">操作员帮助我们解决上述用例，但不是强制性的。您可以安装批处理程序和加载程序，并以任何可能的方式运行它们。Kubernetes不是强制的！</p><h1 id="fe59" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">实时蒙版重装</h1><p id="e9bf" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">掩码更改需要用新的掩码配置重新创建表。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nx"><img src="../Images/aefe2d9601d2a4846e108d59506a5126.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZWmMrBkazPndlCXd"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">图片作者，<a class="ae lk" href="https://github.com/practo/tipoca-stream/blob/master/build/arch-operator.png" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="f879" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面我们用一个例子来了解一下真人蒙版重装。在本例中，我们正在接收与regex: db.inventory.*匹配的主题</p><pre class="lm ln lo lp gt nn no np nq aw nr bi"><span id="a445" class="ns mc iq no b gy nt nu l nv nw">apiVersion: tipoca.k8s.practo.dev/v1<br/>kind: RedshiftSink<br/>metadata:<br/>  name: inventory<br/>spec:<br/>  kafkaTopicRegexes: "^db.inventory*"<br/>  batcher:<br/>    mask: true<br/>    maskFile: <a class="ae lk" href="https://github.com/practo/tipoca-stream/blob/master/redshiftsink/pkg/transformer/masker/database.yaml" rel="noopener ugc nofollow" target="_blank">"</a><a class="ae lk" href="https://github.com/practo/tipoca-stream/blob/master/pkg/transformer/masker/database.yaml" rel="noopener ugc nofollow" target="_blank">database.yaml</a>"<br/>  loader:<br/>    redshiftSchema: "datawarehouse"<br/>    redshiftGroup:  "nonpii"</span></pre><p id="bd41" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Batcher屏蔽了它从Kafka读取的所有数据。用户在GitHub中指定不要屏蔽什么(非PII)，在本例中是<a class="ae lk" href="https://github.com/practo/tipoca-stream/blob/master/redshiftsink/pkg/transformer/masker/database.yaml" rel="noopener ugc nofollow" target="_blank"> db.yaml </a>。为了简单起见，让我们假设db.yaml的掩码版本在每次更改时都以v1、v2、v3…递增。</p><p id="caa0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">什么是SinkGroup？</strong></p><p id="383c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该运算符通过创建SinkGroup来执行sink到红移。SinkGroup是一组RedshiftBatcher和RedshiftLoader吊舱。</p><p id="6263" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">构成接收器组的三个参数是1)由该组处理的主题，2)使用的掩码版本，以及3)目标红移表。例如，customers是主题db.inventory.customers的目标表，customers_ts_reload是临时表。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi of"><img src="../Images/f98198768604038226495c07e34d30d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jpUDmPO455e0GXtV"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">图片作者，<a class="ae lk" href="https://github.com/practo/tipoca-stream/blob/master/build/sinkgroup.png" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><pre class="lm ln lo lp gt nn no np nq aw nr bi"><span id="da85" class="ns mc iq no b gy nt nu l nv nw">I0218 10:24:21.226806 status.go:229] rsk/inventory allTopics:   126<br/>I0218 10:24:21.226827 status.go:230] rsk/inventory diffTopics:  6<br/>I0218 10:24:21.226832 status.go:231] rsk/inventory released:    120<br/>I0218 10:24:21.226837 status.go:232] rsk/inventory reloading:   6<br/>I0218 10:24:21.226838 status.go:233] rsk/inventory reload-dupe: 6<br/>I0218 10:24:21.226848 status.go:234] rsk/inventory realtime:    0</span></pre><p id="1660" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在第一次创建RedshiftSink资源时，操作符将所有主题分配给Reload SinkGroup，后者开始将掩码版本为<strong class="kh ir"> v1 </strong>的数据加载到红移临时表中。</p><p id="bfb7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与此同时，操作员持续监控正在重新加载的主题的消费者群滞后。当lag满足规范中指定的发布条件时，它将重载主题标记为实时。</p><p id="c037" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当操作员发现主题已经到达实时时，它重新配置所有的SinkGroups以停止接收实时主题并尝试释放它们。</p><p id="c69a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">什么是发布？</strong></p><p id="fb05" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Release是Redshift中的操作符在激活实时表时执行的一组操作。</p><ol class=""><li id="7bda" class="mz na iq kh b ki kj kl km ko ny ks nz kw oa la ne nf ng nh bi translated">用实时临时表替换当前的实时表。</li><li id="0274" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ne nf ng nh bi translated">对指定的红移组运行模式授权。</li><li id="91be" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ne nf ng nh bi translated">将发布的主题移动到主SinkGroup。</li></ol><p id="7fa2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">当一个新列需要在表格中取消屏蔽时会发生什么？</strong></p><p id="7c67" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这需要使用新的掩码配置重新创建该表。</p><p id="8a5a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如上所述，所有事情都发生在第一次接收时，唯一的区别是:我们用旧的掩码配置提供对当前活动表的更新，直到用新的掩码配置完成表的完全重新加载。是用<code class="fe oc od oe no b">ReloadDupeSink</code>组完成的。我们这样做是因为重新加载一个大表需要时间，在此期间，我们仍然希望当前活动的表得到实时更新。一旦表被释放，操作员就通知用户松弛状态的释放。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi og"><img src="../Images/8362875024833ff7fe4b17acf7640cb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AgJkjNSued4YM42nB4VDNw.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">slack bot通知用户发布:作者图片</p></figure><p id="da13" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">什么是部署单位？</strong></p><pre class="lm ln lo lp gt nn no np nq aw nr bi"><span id="d51f" class="ns mc iq no b gy nt nu l nv nw">batcher:<br/>  sinkGroup:<br/>    reload:<br/>      maxReloadingUnit: 20<br/>      deploymentUnit:<br/>        podTemplate:<br/>          resources:<br/>            requests:<br/>              cpu: 3<br/>              memory: 3Gi<br/>            limits:<br/>              cpu: 3<br/>              memory: 3Gi</span></pre><p id="2c09" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">批处理单元需要更多的CPU来快速处理大表。要以每秒80k条消息的速度处理消息，需要将近3个CPU内核。在第一个水槽完成后，表已经达到实时，所需的资源非常少，对我们来说是500万。这就是我们有<code class="fe oc od oe no b">sinkGroup</code>规格的原因。使用它，您可以为所有三个sinkGroups指定不同的pod资源。</p><pre class="lm ln lo lp gt nn no np nq aw nr bi"><span id="2187" class="ns mc iq no b gy nt nu l nv nw">maxReloadingUnit 20</span></pre><p id="3df9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">reload sinkGroup为每个主题运行一个单元(pod)。但是main和reloadDupe sinkGroups将所有主题作为一个单元(pod)一起运行。假设一个数据库有1000个主题，我们不会一起重新加载所有的主题，但是我们会首先处理最大maxReloadingUnit个具有最短延迟的主题。</p><h1 id="861e" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">挑战</h1><p id="ada5" class="pw-post-body-paragraph kf kg iq kh b ki mt jr kk kl mu ju kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">Redshift是一个强大的分析工具，但是要很好地使用它，很多事情都需要正确处理才能达到最佳性能。</p><ul class=""><li id="7b56" class="mz na iq kh b ki kj kl km ko ny ks nz kw oa la ob nf ng nh bi translated">设置正确的排序和DIST键。</li><li id="d0c0" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ob nf ng nh bi translated">清空表以保持排序，并回收未使用的磁盘块。</li><li id="7caa" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ob nf ng nh bi translated">最佳利用节点片实现高效拷贝。决定文件的大小和文件的数量，以便进行有效的复制。</li><li id="638d" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ob nf ng nh bi translated">在复制期间最小化s3对文件的查找。</li><li id="8315" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ob nf ng nh bi translated">使用正确的压缩。</li></ul><p id="1da0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们将大约50%的数据库转移到实时数据库之后，表延迟开始超过阈值。</p><p id="49a0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">🤖:您有一个传呼机值班警报！📟 🔥</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nx"><img src="../Images/1d9058e118ba56dbe40900962607820c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-Mi8dhQSPahLnkGU"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">普罗米修斯对提波卡流的警告:作者图片</p></figure><p id="5cdf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以我们开始测量。我们添加了加载持续时间、加载频率(时间线)、加载速度等指标。<a class="ae lk" href="https://github.com/practo/tipoca-stream/blob/master/REDSHIFTSINK.md#metrics-1" rel="noopener ugc nofollow" target="_blank">这些</a>可作为普罗米修斯指标。</p><p id="ddf3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">致力于压缩、节点片利用率、保持s3查找率较低，我们已经解决了许多负载瓶颈。我们现在<strong class="kh ir">以&gt;2mb/秒</strong>的速度加载，从大约100 kb/秒开始跳跃，并设置了正确的默认值，让每个人都从中受益。</p><p id="15c1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">AWS继续在每个版本中改进红移。像自动分拣键，自动DIST键，自动真空释放是伟大的！但我们期待更多:)</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi oh"><img src="../Images/68e10d3248deddf1cb5468ae0d8d672c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nlYfTIKM52oAvsv0ENAFoA.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">加载时间轴:按作者排序的图像</p></figure><p id="db46" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> </strong> <a class="ae lk" href="https://stackoverflow.com/questions/67278497/stream-many-tables-in-realtime-to-redshift-bottleneck-parallel-concurrent-load" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">最大的挑战是保持</strong></a><strong class="kh ir"/>1000个表的滞后红移&lt;10分钟，同时发生许多并发负载。我们有1000多个红移表，但我们一天使用的不超过400个。这就是我们现在在需要时为未使用的表调节负载的原因。<strong class="kh ir"> </strong>这个特性确保了正在使用的<strong class="kh ir">表总是接近实时</strong>并且保持红移负担较小。这非常有用。</p><p id="5abd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">期待<a class="ae lk" href="https://www.youtube.com/watch?v=EOwg8NwZKkI" rel="noopener ugc nofollow" target="_blank">红移AQUA </a>在孟买发布。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi oi"><img src="../Images/bd214baac66b6f1004d1377422c827be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Zl8I3eEIKx24ucc88pULQ.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">count(redshift _ scan _ query _ total)&gt; 0，给出正在使用的表的总数！:作者图片</p></figure><p id="4f77" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">节流是如何工作的？</strong></p><p id="0d3c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">按照<a class="ae lk" href="https://github.com/practo/tipoca-stream/blob/master/REDSHIFTSINK.md#enable-redshiftsink-exporter-optional-recommended" rel="noopener ugc nofollow" target="_blank">此</a>启用节流。它是这样工作的:</p><ul class=""><li id="d978" class="mz na iq kh b ki kj kl km ko ny ks nz kw oa la ob nf ng nh bi translated"><strong class="kh ir">首先，确定正在使用的表:</strong>我们导出红移STL_SCAN为普罗米修斯度量<code class="fe oc od oe no b">redhshift_scan_query_total</code> <strong class="kh ir">。如果扫描查询总数大于零，我们认为表正在使用中。扫描查询表对最近X天的视图的查询，以确定该表是否在使用中。</strong></li><li id="287c" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ob nf ng nh bi translated"><strong class="kh ir">然后，根据表的用法节流:</strong>接下来，我们在红移中只允许10个并发加载。如果表在使用中，我们从不节流，总是加载它。否则，如果需要的话，我们会将表负载限制到最大1小时。如果表在这1小时的限制窗口内被访问，我们就直接让它实时访问。</li></ul><p id="b371" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们已经成功地将大部分数据库转移到实时数据库，一切都很顺利！</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/95784c1480d798acd664f5d632f9344f.png" data-original-src="https://miro.medium.com/v2/resize:fit:456/format:webp/1*XNdKY4-lcZLem8qcPilMaQ.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">从我们的仓库滞后仪表板:作者图片</p></figure><p id="cfbe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过开源这个项目，我们希望回馈社会。期待向大家学习，并与大家合作，继续做得更好。</p></div></div>    
</body>
</html>