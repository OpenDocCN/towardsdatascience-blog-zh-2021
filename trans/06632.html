<html>
<head>
<title>Five Open-Source Machine learning libraries worth checking out</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">五个值得一试的开源机器学习库</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/five-open-source-machine-learning-libraries-worth-checking-out-c47f95d2d014?source=collection_archive---------37-----------------------#2021-06-14">https://towardsdatascience.com/five-open-source-machine-learning-libraries-worth-checking-out-c47f95d2d014?source=collection_archive---------37-----------------------#2021-06-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5d48" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">五个库的旋风之旅，这可能是对您的数据科学堆栈的一个很好的补充</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/aa4998580716c13eebad313aa9ac8284.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3OQ6Yys1O28il8Tt"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@setbydaniel?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">丹尼尔</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="c0e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">开源是机器学习的支柱。它们携手并进。没有开源兄弟会的贡献，这个领域的快速发展是不可能的。机器学习社区中许多广泛使用的工具都是开源的。每年都有越来越多的图书馆加入这个生态系统。在本文中，我快速浏览了我最近遇到的一些库，它们可能是对您的机器学习堆栈的一个很好的补充。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="b106" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">1️⃣.蜂鸟</h1><p id="5bce" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">Humminbird是一个用于将训练好的传统机器学习模型编译成张量计算的库。这意味着你可以利用GPU和TPU等硬件加速，即使是传统的机器学习模型。这在几个层面上都是有益的。</p><ul class=""><li id="6f60" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu ne nf ng nh bi translated">用户可以受益于在神经网络框架中实现的当前和未来的优化；</li><li id="c301" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">用户可以从本机硬件加速中受益；</li><li id="5f90" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">用户可以从拥有支持传统和神经网络模型的独特平台中受益；</li><li id="3641" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">用户不必重新设计他们的模型。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/cedf2bdeff6c77f88005ccd93bad6bbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qOyFrQtqbmNCJ6ikXVTZCA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">蜂鸟库高层架构|来源:<a class="ae ky" href="http://Compiling Classical ML Pipelines into Tensor Computations for One-size-fits-all Prediction Serving" rel="noopener ugc nofollow" target="_blank">官方论文</a></p></figure><p id="2822" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，Hummingbird还在Sklearn API之后提供了一个方便的统一“推理”API。这允许用Hummingbird生成的模型交换Sklearn模型，而不必更改推理代码。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/651e6d216324e7cfa064346acb94fa8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JRTgBndMsT80FPag0xoUSw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="np"> Hummingbird </em>根据作者转换您训练过的传统ML |图像</p></figure><h2 id="aa5e" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">🛠 Github</h2><ul class=""><li id="c0fe" class="mz na it lb b lc mu lf mv li oc lm od lq oe lu ne nf ng nh bi translated"><a class="ae ky" href="https://github.com/microsoft/hummingbird" rel="noopener ugc nofollow" target="_blank">https://github.com/microsoft/hummingbird</a></li></ul><h2 id="8af1" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">🔬论文:</h2><ul class=""><li id="1193" class="mz na it lb b lc mu lf mv li oc lm od lq oe lu ne nf ng nh bi translated"><a class="ae ky" href="https://arxiv.org/abs/2010.04804" rel="noopener ugc nofollow" target="_blank">为</a>服务的统一机器学习预测的张量编译器。</li><li id="b080" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated"><a class="ae ky" href="http://learningsys.org/neurips19/assets/papers/27_CameraReadySubmission_Hummingbird%20(5).pdf" rel="noopener ugc nofollow" target="_blank">将经典的ML管线编译成张量计算，以实现“一刀切”的预测服务</a>。</li></ul><h2 id="a6f4" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">📋博客</h2><p id="f5aa" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/standardizing-traditional-machine-learning-pipelines-to-tensor-computation-using-hummingbird-7a0b3168670">使用Hummingbird将传统机器学习管道标准化为张量计算</a></p><h2 id="4fda" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">💻演示</h2><p id="9004" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">蜂鸟的语法非常直观和简洁。要在DNN框架上运行您的传统ML模型，您只需要<code class="fe of og oh oi b">import hummingbird.ml</code>并将<code class="fe of og oh oi b">convert(model, 'dnn_framework')</code>添加到您的代码中。下面是一个使用<a class="ae ky" href="https://scikit-learn.org/stable/modules/ensemble.html#forest" rel="noopener ugc nofollow" target="_blank"> scikit-learn随机森林</a>模型和<a class="ae ky" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>作为目标框架的例子。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/9c99ed57c89375c972115184f5578bcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*LjRApbCp_4KYyaCEBFth5Q.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用一个<a class="ae ky" href="https://scikit-learn.org/stable/modules/ensemble.html#forest" rel="noopener ugc nofollow" target="_blank"> scikit-learn随机森林</a>模型和<a class="ae ky" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>作为目标框架使用Hummingbird |图片由作者提供</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="178f" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">2️⃣.Top2Vec</h1><p id="892f" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">文本文档包含大量信息。手动筛选很难。主题建模是工业中广泛使用的一种技术，用于在大量文档中自动发现主题。一些传统的和最常用的方法是<a class="ae ky" href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" rel="noopener ugc nofollow" target="_blank">潜在狄利克雷分配</a> (LDA)和<a class="ae ky" href="https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis" rel="noopener ugc nofollow" target="_blank">概率潜在语义分析(PLSA)。</a>然而，这些方法都有缺点，比如没有考虑单词的语义或顺序。Top2vec是一种利用联合文档和单词语义嵌入来寻找主题向量的算法。以下是作者要说的话:</p><blockquote class="ok ol om"><p id="cfad" class="kz la on lb b lc ld ju le lf lg jx lh oo lj lk ll op ln lo lp oq lr ls lt lu im bi translated">这种模型不需要停用词表、词干或词汇化，它可以自动找到主题的数量。得到的主题向量与文档和单词向量一起嵌入，它们之间的距离表示语义相似度。我们的实验表明，top2vec找到的主题比概率生成模型更具信息量和代表性。甚至，预先训练的通用语句编码器和BERT语句转换器也可以用于编码。</p></blockquote><p id="db2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦训练了Top2Vec模型，我们可以执行以下操作:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/6f75cdf2768972c5adfd56c581d6a5f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k9oPom6IULKmz0fDfk0SrQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Top2Vec |作者图片的功能</p></figure><h2 id="e645" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">🛠 Github</h2><p id="9bab" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated"><a class="ae ky" href="https://github.com/ddangelov/Top2Vec" rel="noopener ugc nofollow" target="_blank">https://github.com/ddangelov/Top2Vec</a></p><h2 id="134b" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">🔬纸</h2><p id="a6bf" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated"><a class="ae ky" href="https://arxiv.org/abs/2008.09470" rel="noopener ugc nofollow" target="_blank"> Top2Vec:主题的分布式表示</a></p><h2 id="ffc1" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">📜文档:</h2><p id="2eb0" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated"><a class="ae ky" href="https://top2vec.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">https://top2vec.readthedocs.io/en/latest/index.html</a></p><h2 id="d347" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">💻演示</h2><p id="b06b" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">这里有一个在<a class="ae ky" href="https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html" rel="noopener ugc nofollow" target="_blank">20个新闻组数据集</a>上训练Top2Vec模型的演示。这个例子取自他们的官方Github回购。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/dcd523d07ab4c9f7ddee4b2ff07a35a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*uQuxyjaZGy9Ok1vHpq9Pwg.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html" rel="noopener ugc nofollow" target="_blank">20个新闻组数据集</a> |作者图片上训练Top2Vec模型的演示</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="79e4" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">3️⃣.贝尔托皮奇</h1><p id="e047" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated"><a class="ae ky" href="https://github.com/MaartenGr/BERTopic" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">BERTopic</strong></a><strong class="lb iu"/>是另一种主题建模技术，它利用BERT嵌入和基于类的TF-IDF来创建密集的集群，允许轻松解释主题，同时保留主题描述中的重要单词。它还支持类似于<a class="ae ky" href="https://cran.r-project.org/web/packages/LDAvis/index.html" rel="noopener ugc nofollow" target="_blank"> LDAvis </a>的可视化。这里是对BERTopic功能的一个快速总结。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/56bfad092bcec8f3bbae4efddd6fa834.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q4G6x1YpdyYkrKUy0DYl_w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">BERTopic |作者图片的功能</p></figure><h2 id="5625" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">🛠 Github</h2><p id="3512" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated"><a class="ae ky" href="https://github.com/MaartenGr/BERTopic" rel="noopener ugc nofollow" target="_blank">https://github.com/MaartenGr/BERTopic</a></p><h2 id="c4f3" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">🔬证明文件</h2><p id="de14" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated"><a class="ae ky" href="https://maartengr.github.io/BERTopic/" rel="noopener ugc nofollow" target="_blank">https://maartengr.github.io/BERTopic/</a></p><h2 id="4e0f" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">📋博客</h2><ul class=""><li id="32a1" class="mz na it lb b lc mu lf mv li oc lm od lq oe lu ne nf ng nh bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/topic-modeling-with-bert-779f7db187e6?source=friends_link&amp;sk=0b5a470c006d1842ad4c8a3057063a99">使用BERT进行主题建模</a></li><li id="57a3" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/interactive-topic-modeling-with-bertopic-1ea55e7d73d8?sk=03c2168e9e74b6bda2a1f3ed953427e4">与BERTopic的互动主题建模</a></li></ul><h2 id="a18d" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">💻演示</h2><p id="8be1" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">在<a class="ae ky" href="https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html" rel="noopener ugc nofollow" target="_blank">20个新闻组数据集</a>上训练<code class="fe of og oh oi b">BERTopic</code>模型后生成的主题的<a class="ae ky" href="https://maartengr.github.io/BERTopic/tutorial/visualization/visualization.html" rel="noopener ugc nofollow" target="_blank">可视化</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/6ba4a627e8a8b1e16c5f177a0c4dfa76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*smP4EVtdO8uAwlIi7IitnQ.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用BERTopic |作者图片可视化主题</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="95a4" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">4️⃣.Captum</h1><p id="cf85" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">Captum 是为<a class="ae ky" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>设计的模型可解释性和理解库。Captum在拉丁语中的意思是<em class="on">理解</em>，它包含了PyTorch模型的集成渐变、显著图、smoothgrad、vargrad和其他的通用实现。此外，它可以快速集成用特定领域库构建的模型，如torchvision、torch text等。Captum还提供了一个名为Insights的网络界面，便于可视化和访问我们的许多可解释性算法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/81043f919585047f39ddeffe8ab03bc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_WYyY9QnXfqEvsIduLsa_g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">解释文本模型:使用Captum的IMDB情感分析| <a class="ae ky" href="https://captum.ai/tutorials/IMDB_TorchText_Interpret" rel="noopener ugc nofollow" target="_blank">图片来自文档</a></p></figure><blockquote class="ok ol om"><p id="3b91" class="kz la on lb b lc ld ju le lf lg jx lh oo lj lk ll op ln lo lp oq lr ls lt lu im bi translated">Captum目前处于测试阶段，正在积极开发中！</p></blockquote><h2 id="e802" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">🛠 Github</h2><p id="1b3c" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated"><a class="ae ky" href="https://github.com/pytorch/captum" rel="noopener ugc nofollow" target="_blank">https://github.com/pytorch/captum</a></p><h2 id="37fe" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">🔬证明文件</h2><p id="5fc0" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated"><a class="ae ky" href="https://captum.ai/" rel="noopener ugc nofollow" target="_blank">https://captum.ai/</a></p><h2 id="0e82" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">🎤幻灯片</h2><ul class=""><li id="a979" class="mz na it lb b lc mu lf mv li oc lm od lq oe lu ne nf ng nh bi translated">他们来自NeurIPS 2019的幻灯片可以在<a class="ae ky" href="https://github.com/pytorch/captum/blob/master/docs/presentations/Captum_NeurIPS_2019_final.key" rel="noopener ugc nofollow" target="_blank">这里</a>找到</li><li id="2086" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">他们来自KDD 2020指南的幻灯片可以在这里找到。</li></ul><h2 id="05bb" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">💻演示</h2><p id="9da7" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">以下是我们如何通过Captum Insights在CIFAR10上分析样本模型:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/5c110f36c37b57159ba7d9d4c5b55a9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*UC_UUJRn8gy6645qczpr6g.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">通过Captum Insights分析CIFAR10上的样本模型|作者图片</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="9521" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">5️⃣.烦恼</h1><p id="d5f3" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">骚扰代表<a class="ae ky" href="http://en.wikipedia.org/wiki/Nearest_neighbor_search#Approximate_nearest_neighbor" rel="noopener ugc nofollow" target="_blank">近似最近邻居</a>。它是用C++构建的，但是附带了Python、Java、Scala、R和Ruby的绑定。Annoy用于在高维空间中进行(近似)最近邻查询。尽管许多其他库也执行同样的操作，但airy附带了一些很棒的插件。它创建基于文件的大型只读数据结构，这些数据结构被映射到内存中，这样许多进程可以共享相同的数据。由埃里克·伯恩哈德森开发的Annoy被用于Spotify 的音乐推荐，并被用于搜索相似的用户/商品。</p><blockquote class="ox"><p id="4e19" class="oy oz it bd pa pb pc pd pe pf pg lu dk translated">我们在高维空间中有数百万首歌曲，所以内存使用是首要考虑的问题</p></blockquote><h2 id="80a3" class="nq md it bd me nr ph dn mi nt pi dp mm li pj nw mo lm pk ny mq lq pl oa ms ob bi translated">🛠 Github</h2><p id="ae3f" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">https://github.com/spotify/annoy<a class="ae ky" href="https://github.com/spotify/annoy" rel="noopener ugc nofollow" target="_blank"/></p><h2 id="61e6" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">🎤幻灯片</h2><ul class=""><li id="9ec8" class="mz na it lb b lc mu lf mv li oc lm od lq oe lu ne nf ng nh bi translated"><a class="ae ky" href="http://www.slideshare.net/erikbern/approximate-nearest-neighbor-methods-and-vector-models-nyc-ml-meetup" rel="noopener ugc nofollow" target="_blank">来自纽约机器学习会议的演讲</a>关于骚扰</li></ul><h2 id="ac67" class="nq md it bd me nr ns dn mi nt nu dp mm li nv nw mo lm nx ny mq lq nz oa ms ob bi translated">💻演示</h2><p id="18b2" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">下面是我们如何使用Annoy来查找100个最近的邻居。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/b8ac5d58b79467d84377c7946fbeb64d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*zPPUft8B4zGXs14qAd46og.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用作者的图片寻找100个最近的邻居</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="9bc7" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">包裹</h1><p id="fabc" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">这些是我觉得有趣、有用、值得分享的库。我相信您会想探索它们，看看如何在您的工作领域中使用它们。尽管我们已经有数不清的库需要修补，探索新的库总是有趣和有见识的。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="7ac6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="on">👉有兴趣看我写的其他文章。这个</em> <a class="ae ky" href="https://github.com/parulnith/Data-Science-Articles/blob/main/README.md" rel="noopener ugc nofollow" target="_blank"> <em class="on">回购</em> </a> <em class="on">包含了我分类写的所有文章。</em></p></div></div>    
</body>
</html>