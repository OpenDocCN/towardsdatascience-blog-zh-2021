<html>
<head>
<title>How to calculate confidence intervals for performance metrics in Machine Learning using an automatic bootstrap method</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用自动引导方法计算机器学习中性能指标的置信区间</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/get-confidence-intervals-for-any-model-performance-metrics-in-machine-learning-f9e72a3becb2?source=collection_archive---------6-----------------------#2021-09-08">https://towardsdatascience.com/get-confidence-intervals-for-any-model-performance-metrics-in-machine-learning-f9e72a3becb2?source=collection_archive---------6-----------------------#2021-09-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="7625" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="7677" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">您的模型性能度量是因为“大”测试集而非常精确，还是因为“小”或不平衡的测试集而非常不确定？</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/12107798c618a59f28ef2316ae41f9d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fN1nrz_mkdqkwP2RvHUY4w.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">橙色线显示89.7%为平衡准确度置信区间的下限，绿色线表示原始观察到的平衡准确度=92.4%(点估计)，红色线表示上限为94.7%。(此图及所有图片均由作者所有，除非另有说明。)</p></figure><h1 id="6415" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">介绍</h1><p id="ce20" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">如果您报告您的分类器在测试集上的性能为准确率=94.8%，F1=92.3%，在不了解测试集的大小和组成的情况下，这没有多大意义。这些性能测量的误差幅度将根据测试集的大小而变化很大，或者，对于不平衡的数据集，主要取决于它包含多少个<em class="mv"> minority </em>类的独立实例(来自过采样的相同实例的更多副本对此没有帮助)。</p><p id="6b8a" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">如果您能够收集另一个类似来源的独立测试集，您的模型在该数据集上的准确性和F1不太可能相同，但它们可能有多大的差异呢？与此类似的问题在统计学中被回答为测量的<strong class="mb jd">置信区间</strong>。</p><p id="435b" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">如果我们要从基础人群中抽取许多独立的样本数据集，那么对于这些数据集的95%，该指标的真实基础人群值将在我们为该特定样本数据集计算的95%置信区间内。</p><p id="aaef" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">在本文中，我们将向您展示如何一次计算任意数量的机器学习性能指标的置信区间，使用bootstrap方法，<em class="mv">自动</em>确定默认情况下要生成多少引导样本数据集。</p><p id="de70" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">如果您只想了解如何调用此代码来计算置信区间，请跳到“<strong class="mb jd">计算结果一节！</strong>“下面下来。</p><h1 id="29ea" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">自助方法</h1><p id="0f9e" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">如果我们能够从数据的真实分布中提取额外的测试数据集，我们将能够看到跨这些数据集的感兴趣的性能指标的分布。(在绘制这些数据集时，我们不会做任何事情来防止多次绘制相同或相似的实例，尽管这种情况可能很少发生。)</p><p id="1eba" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">既然我们不能这样做，那么下一个最好的办法就是从这个测试数据集的<em class="mv">经验分布</em>中提取额外的数据集，这意味着从它的实例中取样，替换，以生成新的引导样本数据集。替换采样意味着一旦我们绘制了一个特定的实例，我们就把它放回去，这样我们就可以为同一个样本数据集再次绘制它。因此，每个这样的数据集通常具有一些实例的多个副本，并且不包括基本测试集中的所有实例。</p><p id="9119" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">如果我们在没有替换的情况下对<em class="mv">进行采样，那么我们每次都会简单地得到原始数据集的相同副本，以不同的随机顺序进行洗牌，这将没有任何用处。</em></p><p id="6f49" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">用于估计置信区间的<em class="mv">百分点</em> bootstrap方法如下:</p><ol class=""><li id="eb92" class="nb nc it mb b mc mw mf mx mi nd mm ne mq nf mu ng nh ni nj bi translated">生成<code class="fe nk nl nm nn b"><em class="mv">nboots</em></code> <em class="mv"> </em>“引导样本”数据集，每个数据集的大小与原始测试集相同。每个样本数据集都是通过从测试集中随机抽取实例并替换而获得的。</li><li id="6e67" class="nb nc it mb b mc no mf np mi nq mm nr mq ns mu ng nh ni nj bi translated">在每个样本数据集上，计算指标并保存。</li><li id="5ffe" class="nb nc it mb b mc no mf np mi nq mm nr mq ns mu ng nh ni nj bi translated">95%的置信区间由指标的<code class="fe nk nl nm nn b"><em class="mv">nboots</em></code> <em class="mv"> </em>计算值中的第2.5个<em class="mv">至第97.5个<em class="mv">百分位给出。如果<code class="fe nk nl nm nn b"><em class="mv">nboots</em></code> =1001，并且您对长度为1001的序列/数组/列表<em class="mv"> X </em>中的值进行排序，则第0 <em class="mv">个</em>百分位是<em class="mv"> X </em> [0】，第100个<em class="mv">个</em>百分位是<em class="mv"> X </em> [1000】，因此置信区间将由<em class="mv"> X </em> [25】到<em class="mv">X</em>[970]给出</em></em></li></ol><p id="8448" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">当然，您可以在步骤2中为每个样本数据集计算尽可能多的指标，但是在步骤3中，您将分别找到每个指标的百分位数。</p><h1 id="ff95" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">数据集和置信区间结果示例</h1><p id="1553" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">我们将使用上一篇文章中的结果作为例子:<a class="ae nt" href="https://www.kdnuggets.com/2021/09/imbalanced-classification-without-re-balancing-data.html" rel="noopener ugc nofollow" target="_blank"> <strong class="mb jd">如何处理不平衡的分类，而不重新平衡数据</strong> : <em class="mv">在考虑对倾斜的数据进行过采样之前，尝试调整分类决策阈值</em> </a> <em class="mv">。</em></p><p id="a661" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">在那篇文章中，我们使用了<em class="mv">高度</em>-不平衡两类Kaggle <a class="ae nt" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank">信用卡欺诈识别数据集</a>。我们选择使用一个与默认的0.5阈值完全不同的分类阈值，默认的0.5阈值隐含在使用predict()方法中，使得没有必要平衡数据。这种方法有时被称为<em class="mv">阈值移动</em>，其中我们的分类器通过将选择的阈值应用于由predict <strong class="mb jd"> _proba </strong>()方法提供的预测类概率来分配类。</p><p id="3a8b" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">我们将把本文(和代码)的范围限制在二进制分类:类0和1，按照惯例，类1是“正”类，特别是不平衡数据的少数类，尽管代码也应该适用于回归(单个连续目标)。</p><h1 id="e36c" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">生成一个引导样本数据集</h1><p id="68be" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">虽然我们的置信区间代码可以处理传递给度量函数的各种数量的数据参数，但我们将专注于sklearn风格的度量，它总是接受两个数据参数y_true和y_pred，其中y_pred将是二进制类预测(0或1)，或者是连续的类概率或决策函数预测，如果y_true也是连续的，甚至是连续的回归预测。以下函数生成单个引导示例数据集。它接受任何data_args，但是在我们的例子中，这些参数将是<code class="fe nk nl nm nn b">ytest</code>(我们在之前的文章中的<a class="ae nt" href="https://www.kdnuggets.com/2021/09/imbalanced-classification-without-re-balancing-data.html" rel="noopener ugc nofollow" target="_blank">实际/真实测试集目标值)和<code class="fe nk nl nm nn b">hardpredtst_tuned_thresh</code>(预测类)。两者都包含0和1，以指示每个实例的真实或预测类。</a></p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h1 id="73a2" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">自定义指标specificity_score()和效用函数</h1><p id="cca8" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">我们将为特异性定义一个定制的度量函数，这只是召回<em class="mv">负</em>类(类0)的另一个名称。还有一个calc_metrics函数，它将一系列感兴趣的指标应用于我们的数据，还有几个实用函数:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="cf27" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">在这里，我们列出了度量标准，并将它们应用于数据。我们不认为准确性是一个相关指标，因为假阴性(将真实的欺诈错误分类为合法)比假阳性(将真实的合法错误分类为欺诈)对业务的成本高得多，而准确性认为两种类型的错误分类都是不好的，因此有利于正确分类那些真实类别为多数类别的人，因为这些发生得更频繁，因此对整体准确性的贡献更大。</p><pre class="ks kt ku kv gt nw nn nx ny aw nz bi"><span id="443f" class="oa li it nn b gy ob oc l od oe">met=[ metrics.recall_score, specificity_score, <br/>      metrics.balanced_accuracy_score<br/>    ]<br/>calc_metrics(met, ytest, hardpredtst_tuned_thresh)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi of"><img src="../Images/681c5c37e7f265e6aeabb68eb7d5a648.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*0-OSArLZ2JSGHIVqcAAVjw.png"/></div></div></figure><h1 id="7324" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">制作每个启动样本数据集并计算其指标</h1><p id="74fd" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">在raw_metric_samples()中，我们实际上将逐个生成多个样本数据集，并保存每个数据集的指标:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="3a7b" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">您给raw_metric_samples()一个感兴趣的指标(或仅一个指标)列表以及真实和预测的类数据，它获取nboots样本数据集并返回一个dataframe，其中仅包含从每个数据集计算的指标值。通过_boot_generator()，它在生成器表达式中一次调用一个_boot()，而不是一次将所有数据集存储为一个潜在的巨大的列表。</p><h1 id="470d" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">查看7个启动示例数据集的指标</h1><p id="c552" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">我们列出度量函数并调用raw_metric_samples()来获得7个样本数据集的结果。为了便于理解，我们在这里调用raw_metric_samples()，这对于使用下面的ci_auto()获得置信区间是不必要的，尽管为ci_auto() <em class="mv">指定一个度量列表(或仅仅一个度量)是必要的</em>。</p><pre class="ks kt ku kv gt nw nn nx ny aw nz bi"><span id="7a9a" class="oa li it nn b gy ob oc l od oe">np.random.seed(13)<br/>raw_metric_samples(met, ytest, hardpredtst_tuned_thresh, <br/>          nboots=7).style.format('{:.2%}')  #optional #style</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi og"><img src="../Images/d38f00cc518195431c95662dc2b3ff7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uHNWCn_-60nVfrq-P2c8aA.png"/></div></div></figure><p id="f0c9" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">上面的每一列都包含从一个引导样本数据集(编号为0到6)计算的指标，因此计算出的指标值会因随机采样而有所不同。</p><h1 id="0f9b" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">启动数据集的数量，带有计算的默认值</h1><p id="49eb" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">在我们的实现中，默认情况下，引导数据集的数量<code class="fe nk nl nm nn b">nboots</code>将从期望的置信水平(例如95%)自动计算，以便满足由<a class="ae nt" href="http://www.google.com/search?q=Am+J+Hum+Genet.+2002+Aug%3B+71%282%29%3A+439%E2%80%93441.+doi%3A+10.1086%2F341527+A+Note+on+the+Calculation+of+Empirical+P+Values+from+Monte+Carlo+Procedures+B.+V.+North+D.+Curtis+P.+C.+Sham&amp;btnI" rel="noopener ugc nofollow" target="_blank"> North、Curtis和Sham </a>提出的在分布的每个尾部具有最小数量的引导结果的建议。(实际上，该建议适用于<em class="mv">p</em>-值，因此假设检验<em class="mv">接受区域</em>，但是<em class="mv">置信区间</em>与那些将此作为经验法则的区间足够相似。)虽然那些作者推荐尾部最少10个引导结果，<a class="ae nt" href="http://hdl.handle.net/10419/67820" rel="noopener ugc nofollow" target="_blank"><em class="mv">Davidson&amp;MacKinnon</em></a>推荐95%置信度下最少399个引导，这需要尾部11个引导，所以我们用这个更保守的推荐。</p><p id="9411" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">我们指定α为1<strong class="mb jd"/>置信水平。例如95%的置信度变成0.95，α= 0.05。如果您指定了一个明确的启动次数(也许是一个较小的<code class="fe nk nl nm nn b">nboots</code>,因为您想要更快的结果),但这对于您所请求的alpha来说是不够的，那么将会自动选择一个更高的alpha，以便获得该启动次数的准确置信区间。将使用最少51个boots，因为任何更少的boots都只能精确地计算非常小的置信水平(例如40%的置信度，给出了从第30个<em class="mv">百分点到第70个<em class="mv">百分点的区间，其中40%在区间内，60%在区间外)，并且不清楚最小boots建议是否考虑了这种情况。</em></em></p><p id="84c7" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">函数get_alpha_nboots()设置缺省的nboots，或者根据上述内容修改所请求的alpha和nboots:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="295a" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">让我们展示不同alpha值的默认nboots:</p><pre class="ks kt ku kv gt nw nn nx ny aw nz bi"><span id="ba0b" class="oa li it nn b gy ob oc l od oe">g = get_alpha_nboots <br/>pd.DataFrame( [ g(0.40), g(0.20, None), g(0.10), g(), g(alpha=0.02), <br/>                g(alpha=0.01, nboots=None), g(0.005, nboots=None)<br/>              ], columns=['alpha', 'default nboots']<br/>            ).set_index('alpha')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/12a76a440d688d324ebdb64aa48d067e.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*yjmz-4jU4eccMbrTbLgy6A.png"/></div></figure><p id="4ef7" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">如果我们请求显式nboots，会发生以下情况:</p><pre class="ks kt ku kv gt nw nn nx ny aw nz bi"><span id="5756" class="oa li it nn b gy ob oc l od oe">req=[(0.01,3000), (0.01,401), (0.01,2)]<br/>out=[get_alpha_nboots(*args) for args in req]<br/>mydf = lambda x: pd.DataFrame(x, columns=['alpha', 'nboots'])<br/>pd.concat([mydf(req),mydf(out)],axis=1, keys=('Requested','Using'))</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/24d7b01073c48327bf72e7d06e96f8ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*QYaNtPu3ch_Th3b62rryyQ.png"/></div></figure><p id="99d3" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">较小的nboots值将alpha增加到0.05和0.40，nboots=2被更改为最小值51。</p><h1 id="424c" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">bootstrap样本数据集的直方图显示了平衡精度的置信区间</h1><p id="4d15" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">同样，我们不需要通过调用ci_auto()来获得下面的置信区间。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nu nv l"/></div></figure><pre class="ks kt ku kv gt nw nn nx ny aw nz bi"><span id="f0c2" class="oa li it nn b gy ob oc l od oe">np.random.seed(13)<br/>metric_boot_histogram\<br/>  (metrics.balanced_accuracy_score, ytest, hardpredtst_tuned_thresh)</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/12107798c618a59f28ef2316ae41f9d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fN1nrz_mkdqkwP2RvHUY4w.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">橙色线显示89.7%为平衡准确度置信区间的下限，绿色线表示原始观察到的平衡准确度=92.4%(点估计)，红色线表示上限为94.7%。(同样的图片出现在本文的顶部。)</p></figure><h1 id="011e" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">如何计算度量列表的所有置信区间</h1><p id="f944" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">下面是调用上述内容的主函数，它根据度量结果的百分位数计算置信区间，并将点估计值作为结果输出数据帧的第一列插入。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h1 id="288e" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">计算结果！</h1><p id="e46d" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">这就是我们真正需要做的:调用ci_auto()，如下所示，使用一个度量列表(<code class="fe nk nl nm nn b">met</code>在上面赋值)来获得它们的置信区间。百分比格式是可选的:</p><pre class="ks kt ku kv gt nw nn nx ny aw nz bi"><span id="0f74" class="oa li it nn b gy ob oc l od oe">np.random.seed(13)<br/>ci_auto( met, ytest, hardpredtst_tuned_thresh<br/>       ).style.format('{:.2%}')</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oj"><img src="../Images/86035b401dd99b0ddb6059996679fb8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ARg4UGx6ZMKalqp0ttLpPQ.png"/></div></div></figure><h1 id="309a" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">对结果置信区间的讨论</h1><p id="ad37" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">下面是来自<a class="ae nt" href="https://www.kdnuggets.com/2021/09/imbalanced-classification-without-re-balancing-data.html" rel="noopener ugc nofollow" target="_blank">原文</a>的混淆矩阵。类别0是阴性(多数类别),类别1是阳性(极少数类别)</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/8d8ccada86ba563cb7d04ab04e632491.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/0*Sd0WM17orx85PyGP.png"/></div></figure><p id="f46f" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">134/(134+14)的召回率(真阳性率)具有最宽的置信区间，因为这是涉及少量计数的二项式比例。</p><p id="c851" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">特异性(真阴性率)为80，388/(80，388+4，907)，涉及<em class="mv">多</em>大的计数，因此其置信区间极窄，仅为【94.11%至94.40%】。</p><p id="edda" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">由于平衡的准确性是简单地计算召回率和特异性的平均值，其置信区间的宽度介于两者之间。</p><h1 id="0e50" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">由于测试数据的变化和训练数据的变化导致的度量测量不精确</h1><p id="bfce" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">这里，我们没有考虑基于我们的<em class="mv">训练</em>数据的随机性的<em class="mv">模型</em>中的可变性(尽管这对于某些目的也是有意义的，例如，如果你已经自动重复重新训练，并且想要知道未来模型的性能可能变化多少)，而是仅仅考虑由于我们的<em class="mv">测试</em>数据的随机性而导致的这个<em class="mv">特定</em>模型(从一些特定训练数据创建)的性能测量中的可变性。</p><p id="efec" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">如果我们有足够的独立测试数据，我们可以非常精确地测量这个特定模型在底层人群中的性能，并且我们将知道如果部署这个模型，它将如何执行，而不管我们如何构建该模型，以及我们是否可以通过不同的训练样本数据集获得更好或更差的模型。</p><h1 id="7680" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">单个实例的独立性</h1><p id="84f3" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">bootstrap方法假设您的每个实例(案例、观察结果)都是从基础总体中独立抽取的。如果您的测试集包含多组彼此不独立的行，例如，对同一实体的重复观察可能彼此相关，或者从测试集中的其他实例中过度采样/复制/生成实例，则结果可能无效。您可能需要使用<em class="mv">分组</em>采样，在这种情况下，您随机地将整个组集合在一起，而不是单独的行，同时避免分解任何组或只使用其中的一部分。</p><p id="652c" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">此外，您还希望确保没有跨训练集和测试集拆分的组，因为这样测试集不一定是独立的，您可能会发现未被发现的过度拟合。例如，如果您使用过采样，您通常应该只在从测试集中分离出来之后进行<strong class="mb jd">，而不是之前。通常情况下，您会对训练集而不是测试集进行过采样，因为测试集必须能够代表模型在未来部署时将看到的实例。对于交叉验证，您可能希望使用scikit-learn的<code class="fe nk nl nm nn b">model_selection.GroupKFold()</code>。</strong></p><h1 id="51ac" class="lh li it bd lj lk ll lm ln lo lp lq lr ki ls kj lt kl lu km lv ko lw kp lx ly bi translated">结论</h1><p id="df4a" class="pw-post-body-paragraph lz ma it mb b mc md kd me mf mg kg mh mi mj mk ml mm mn mo mp mq mr ms mt mu im bi translated">您总是可以为您的评估度量计算置信区间，以查看您的测试数据使您能够多精确地测量您的模型的性能。我计划撰写另一篇文章来展示评估概率预测(或置信度得分——与统计置信度无关)的指标的置信区间，即软分类，如Log Loss或ROC AUC，而不是我们在此使用的评估模型对类别的离散选择的指标(硬分类)。同样的代码适用于这两种情况，也适用于回归(预测一个连续的目标变量)——您只需要传递给它一个不同类型的预测(在回归的情况下，传递给它不同类型的真实目标)。</p><p id="3cf2" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated"><em class="mv">这款jupyter笔记本在github有:</em><a class="ae nt" href="https://github.com/DavidRosen/conf-intervals-auto/blob/main/bootConfIntAutoV1o_standalone.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="mv">bootconfintautov 1 o _ standalone . ipynb</em></a></p><p id="255a" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">这篇文章信息丰富和/或有用吗？请张贴回复(语音气泡图标在左下方，黑/白旁边👏如果您对本文或置信区间、引导、引导数、实施、数据集、模型、阈值移动或结果有任何意见或问题。</p><p id="ee83" class="pw-post-body-paragraph lz ma it mb b mc mw kd me mf mx kg mh mi my mk ml mm mz mo mp mq na ms mt mu im bi translated">除了前面提到的<a class="ae nt" rel="noopener" target="_blank" href="/how-to-deal-with-imbalanced-classification-without-re-balancing-the-data-8a3c02353fe3">前一篇文章</a>之外，您可能还对我的<a class="ae nt" rel="noopener" target="_blank" href="/auto-detect-and-set-the-date-datetime-datatypes-when-reading-csv-into-pandas-261746095361"> <strong class="mb jd">感兴趣，如何在Pandas </strong> </a>中读取CSV文件时自动检测日期/日期时间列并设置它们的数据类型，尽管它与本文没有直接关系。</p></div></div>    
</body>
</html>