<html>
<head>
<title>PixelCNN’s Blind Spot</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PixelCNN的盲点</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pixelcnns-blind-spot-84e19a3797b9?source=collection_archive---------12-----------------------#2021-09-08">https://towardsdatascience.com/pixelcnns-blind-spot-84e19a3797b9?source=collection_archive---------12-----------------------#2021-09-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="bb48" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><div class=""><h2 id="d346" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">PixelCNN的局限性以及如何修复它！</h2></div><p id="ef52" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">由<a class="ae lk" href="https://twitter.com/Warvito" rel="noopener ugc nofollow" target="_blank">沃尔特·雨果·洛佩兹·皮纳亚</a>、<a class="ae lk" href="https://twitter.com/thepfcosta" rel="noopener ugc nofollow" target="_blank">佩德罗·f·达·科斯塔</a>和<a class="ae lk" href="https://twitter.com/jessdafflon" rel="noopener ugc nofollow" target="_blank">杰西卡·达弗伦</a>编剧</p><p id="a990" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">大家好！今天，我们将继续关于自回归模型的系列，我们将重点关注PixelCNNs的最大限制之一(即盲点)以及如何改进以解决它。</p><p id="186b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">总结</strong></p><ol class=""><li id="24ec" class="ll lm iq kq b kr ks ku kv kx ln lb lo lf lp lj lq lr ls lt bi translated"><a class="ae lk" rel="noopener" target="_blank" href="/autoregressive-models-pixelcnn-e30734ede0c1">自回归模型— PixelCNN </a></li><li id="549d" class="ll lm iq kq b kr lu ku lv kx lw lb lx lf ly lj lq lr ls lt bi translated"><a class="ae lk" href="https://medium.com/@pedro.hpf.costa/modelling-coloured-images-acd0ebde0102" rel="noopener">多通道建模数据</a></li><li id="dbe8" class="ll lm iq kq b kr lu ku lv kx lw lb lx lf ly lj lq lr ls lt bi translated">PixelCNN的盲点及其修复方法—门控PixelCNN</li><li id="76a5" class="ll lm iq kq b kr lu ku lv kx lw lb lx lf ly lj lq lr ls lt bi translated">使用门控像素CNN的条件生成</li><li id="896f" class="ll lm iq kq b kr lu ku lv kx lw lb lx lf ly lj lq lr ls lt bi translated">带裁剪卷积的门控像素CNN</li><li id="3ea8" class="ll lm iq kq b kr lu ku lv kx lw lb lx lf ly lj lq lr ls lt bi translated">提高性能— PixelCNN++</li><li id="cc1c" class="ll lm iq kq b kr lu ku lv kx lw lb lx lf ly lj lq lr ls lt bi translated">缩短采样时间—快速PixelCNN++</li><li id="d837" class="ll lm iq kq b kr lu ku lv kx lw lb lx lf ly lj lq lr ls lt bi translated">使用注意机制——pixels nail</li><li id="9df1" class="ll lm iq kq b kr lu ku lv kx lw lb lx lf ly lj lq lr ls lt bi translated">生成多样化的高保真图像——VQ-VAE 2</li></ol><p id="340c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于每个主题，代码都可以在这个<a class="ae lk" href="https://github.com/Mind-the-Pineapple/Autoregressive-models" rel="noopener ugc nofollow" target="_blank">库</a>中找到。</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="eb31" class="mg mh iq bd mi mj mk ml mm mn mo mp mq kf mr kg ms ki mt kj mu kl mv km mw mx bi translated">介绍</h1><p id="db30" class="pw-post-body-paragraph ko kp iq kq b kr my ka kt ku mz kd kw kx na kz la lb nb ld le lf nc lh li lj ij bi translated">在前两篇文章中，我们介绍了生成模型，PixelCNN背后的概念，并研究了彩色pixel CNN的工作原理。回想一下，PixelCNNs是一种生成模型，它学习像素的概率分布，这意味着未来像素的强度将由先前的像素决定。在这个blogpost系列中，我们实现了两个PixelCNNs，并注意到性能并不出色。在之前的帖子中，我们提到了改善模型性能的方法之一是修复盲点问题。因此，在本帖中，我们将介绍盲点的概念，讨论像素CNN是如何受到影响的，并提出一种解决方案——门控像素CNN <strong class="kq ja">。</strong>我们开始吧！</p><h1 id="27f5" class="mg mh iq bd mi mj nd ml mm mn ne mp mq kf nf kg ms ki ng kj mu kl nh km mw mx bi translated">盲点</h1><p id="d66d" class="pw-post-body-paragraph ko kp iq kq b kr my ka kt ku mz kd kw kx na kz la lb nb ld le lf nc lh li lj ij bi translated">正如你从以前的帖子中回忆的那样，PixelCNN学习图像中所有像素的条件分布，并使用这些信息进行预测。还记得PixelCNNs将从左到右和从上到下学习像素的分布。因此，为了确保“未来”像素(即预测像素右侧或下方的像素)不能用于给定像素的预测，通常使用掩码(图1A)。如图1A所示，掩码将当前预测像素“之后”的像素清零，这对应于掩码中心的像素。然而，由于这种选择，不是所有的“过去的”像素将被用于计算新点，并且信息的丢失将导致盲点的产生。</p><p id="1553" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了理解盲点问题，让我们看看图1B。在图1B中，暗粉色的点(<em class="ni"> m </em>)是我们想要预测的像素，因为它位于过滤器的中心。因为我们用的是3x3的蒙版(1A。)，像素<em class="ni"> m </em>依赖于<em class="ni"> l，g，h，i. </em>另一方面，那些像素依赖于之前的像素。例如，像素g依赖于<em class="ni"> f，a，b，c，</em>而像素i <em class="ni"> </em>依赖于<em class="ni"> h，c，d，e. </em>从图1B中，我们还可以看到，尽管出现在<em class="ni"> </em>像素<em class="ni"> m之前，</em>像素<em class="ni"> j </em>在计算<em class="ni"> m </em>的预测时从未被考虑。类似地，如果我们想要对<em class="ni"> q、</em> j、n、o进行预测，则从不考虑(图1C。).并非所有先前的像素都会影响预测的事实被称为盲点问题。</p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi nj"><img src="../Images/dd44550d732d95475783d56554c6335a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8Z3v9e3CSSps0ADWtJH89Q.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">图1: A .举例说明了一个3×3掩码的例子，该掩码可用于确保只有“过去的”像素用于计算预测。只有绿色的像素将用于计算蒙版中心的像素。b .如何在5x 5图像上使用掩模来预测像素m的示例。只有像素l、g、h、I将用于计算暗粉色(m)的像素。但是，我们需要记住，l，g，h，I也依赖于之前的像素(a，b，c，d，e，f，k；显示为淡紫色)。从B中的第三张图可以看出，j(橙色)将不会被使用，从而形成一个盲点。c .如果我们将遮罩的中心下移，现在预测像素q，我们可以看到橙色的像素永远不会被考虑在内(图片由作者提供)。</p></figure><p id="c438" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们将首先从PixelCNNs的实现以及盲点如何影响结果开始。下面的代码片段显示了使用Tensorflow 2.0框架从PixelCNN实现遮罩。</p><figure class="nk nl nm nn gt no"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="c5f3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">查看原始PixelCNN的感受野(在图2中用黄色标记),我们可以看到盲点以及它如何在不同层上传播。在这篇博文的第二部分，我们将描述PixelCNN的下一个版本，门控PixelCNN，它引入了一种新的机制来避免盲点的产生。</p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi ob"><img src="../Images/1b2d41de947adbbcbee3a3446a736768.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V0V1blD6mdGkPmYDede3dw.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">图PixelCNN上盲点的演变(图片由作者提供)。</p></figure></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="ca8b" class="mg mh iq bd mi mj mk ml mm mn mo mp mq kf mr kg ms ki mt kj mu kl mv km mw mx bi translated">门控像素CNN</h1><p id="f5da" class="pw-post-body-paragraph ko kp iq kq b kr my ka kt ku mz kd kw kx na kz la lb nb ld le lf nc lh li lj ij bi translated">在前两篇博文中，我们介绍了PixelCNN然而，这种模型性能较低，并且存在我们上面介绍的盲点问题。</p><p id="6981" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了解决这些问题，<a class="ae lk" href="https://arxiv.org/abs/1606.05328" rel="noopener ugc nofollow" target="_blank"> van den Oord等人(2016) </a>引入了门控PixelCNN。门控像素CNN在两个主要方面不同于像素CNN:</p><ol class=""><li id="43ec" class="ll lm iq kq b kr ks ku kv kx ln lb lo lf lp lj lq lr ls lt bi translated">它解决了盲点问题</li><li id="14a4" class="ll lm iq kq b kr lu ku lv kx lw lb lx lf ly lj lq lr ls lt bi translated">它使用门控卷积图层提高了模型的性能</li></ol><h1 id="4f1a" class="mg mh iq bd mi mj nd ml mm mn ne mp mq kf nf kg ms ki ng kj mu kl nh km mw mx bi translated">1.门控像素CNN如何解决盲点问题</h1><p id="2343" class="pw-post-body-paragraph ko kp iq kq b kr my ka kt ku mz kd kw kx na kz la lb nb ld le lf nc lh li lj ij bi translated">这个新模型通过将卷积分成两部分:垂直和水平叠加，解决了盲点问题。让我们看看垂直和水平堆栈是如何工作的。</p><p id="91a2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">纵横书库</strong></p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/701705abcfe91c17b1856c6d98066fb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*k-VkBWRSAjRQ5Tc4kP9M5w.png"/></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">图3:垂直堆栈(绿色)和水平堆栈(蓝色-作者提供的图片)。</p></figure><p id="0b79" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在垂直堆栈中，目标是处理当前行之前所有行的上下文信息。用于确保使用所有先前的信息并且保持因果关系(即，当前预测的像素不应该知道它右边的信息)的技巧是将掩模的中心分别向上移动一行到被预测的像素。如图3所示，虽然垂直掩码的中心是浅绿色像素(<em class="ni"> m </em>，但是由垂直堆栈收集的信息将不会用于预测它，而是用于预测它下面的行中的像素(<em class="ni"> r </em>)。</p><p id="c81a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然而，单独使用垂直堆栈会在黑色预测像素(<em class="ni"> m </em>)的左侧产生盲点。为了避免这种情况，由垂直堆栈收集的信息与来自水平堆栈的信息相结合(<em class="ni"> p-q </em>在图3中用蓝色表示)，水平堆栈预测预测像素左侧的所有像素(<em class="ni"> m </em>)。水平和垂直堆栈之间的组合解决了两个问题:(1)不使用预测像素右边的信息，(2)因为我们作为一个块来考虑，所以我们不再有盲点。</p><p id="3665" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在<a class="ae lk" href="https://arxiv.org/abs/1606.05328" rel="noopener ugc nofollow" target="_blank"> van den Oord et al. (2016) </a>中，实现了垂直叠加，使得每个卷积的感受野具有2×3格式。我们通过使用一个3×3卷积来实现这一点，最后一行被屏蔽掉。在水平堆栈中，卷积层将预测值与来自被分析像素的当前行的数据相关联。这可以使用1×3卷积来实现，其中我们屏蔽未来像素以保证自回归模型的因果条件。与PixelCNN类似，我们实现了一个A型遮罩(用于第一层)和一个B型遮罩(用于后续层)。</p><p id="8d92" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们修改了以前的掩蔽卷积层，以便能够实现这些新配置。下面的代码片段显示了使用Tensorflow 2.0框架实现的掩码。</p><figure class="nk nl nm nn gt no"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="d6f7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">通过在网络上添加这两个堆栈的特征图，我们获得了一个具有一致感受野的自回归模型，并且不会产生盲点(图4)。</p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi od"><img src="../Images/f02daf3f401f46759d8e6d2d3fb66ef2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o4T2iVy6-YcXoxOF51-FEw.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">图4:门控PixelCNN感受野概述。我们注意到，使用垂直和水平堆栈的组合，我们能够避免在PixelCNNs的初始版本中观察到的盲点问题(图3 —作者提供的图片)。</p></figure><h1 id="0fd6" class="mg mh iq bd mi mj nd ml mm mn ne mp mq kf nf kg ms ki ng kj mu kl nh km mw mx bi translated">2.门控激活单元(或门控块)</h1><p id="4989" class="pw-post-body-paragraph ko kp iq kq b kr my ka kt ku mz kd kw kx na kz la lb nb ld le lf nc lh li lj ij bi translated">从普通像素CNN到门控CNN的第二个主要改进是引入了门控块和乘法单元(以LSTM门的形式)。因此，不像原始的pixelCNN那样在屏蔽卷积之间使用校正线性单元(ReLUs );门控像素CNN使用门控激活单元来模拟特征之间更复杂的相互作用。这种门控激活单元使用sigmoid(作为遗忘门)和tanh(作为实际激活)。在<a class="ae lk" href="https://arxiv.org/pdf/1606.05328.pdf" rel="noopener ugc nofollow" target="_blank">的原始论文</a>中，作者提出这可能是PixelRNN(使用LSTM的)优于PixelCNN的一个原因，因为他们能够通过递归的方式更好地捕捉过去的像素——他们可以记住过去的信息。因此，门控PixelCNN使用了以下内容:</p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi oe"><img src="../Images/f8fc2f53320c9b24d2e137374bdf8c2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C159K48wLsrLZ6g70HryfA.png"/></div></div></figure><p id="567c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">σ是sigmoid非线性度，<em class="ni"> k </em>是层数，⊙是逐元素乘积，∵是卷积算子，<em class="ni"> W </em>是来自前一层的权重。让我们更详细地看一下PixelCNN中的一个层。</p><h1 id="42c9" class="mg mh iq bd mi mj nd ml mm mn ne mp mq kf nf kg ms ki ng kj mu kl nh km mw mx bi translated">门控像素CNN中的单层块</h1><p id="6c64" class="pw-post-body-paragraph ko kp iq kq b kr my ka kt ku mz kd kw kx na kz la lb nb ld le lf nc lh li lj ij bi translated">堆栈和门是门控PixelCNN的基本模块(图5)。但是它们是如何连接的，信息将如何处理？我们将把它分成4个处理步骤，我们将在下面的会议中讨论。</p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi of"><img src="../Images/3774bcfb6900af9be30b00f41a8448c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xsEZZT_tpQn35kgQN6FLMQ.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">图5:门控PixelCNN架构概述(图片来自<a class="ae lk" href="https://arxiv.org/pdf/1606.05328.pdf" rel="noopener ugc nofollow" target="_blank">原始论文</a>)。颜色代表不同的操作(即，绿色:卷积；红色:元素间的乘法和加法；蓝色:与权重卷积</p></figure><p id="ed7c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> <em class="ni"> 1。计算垂直叠加特征图</em> </strong></p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi og"><img src="../Images/c6094de78cefa337f3751ee83e1074de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-uwYebXZ_i4d7wI3dXU-oA.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">(图片改编自<a class="ae lk" href="https://arxiv.org/pdf/1606.05328.pdf" rel="noopener ugc nofollow" target="_blank">原纸</a>)</p></figure><p id="f738" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">作为第一步，来自垂直叠加的输入由我们的3×3卷积层和垂直掩模处理。然后，得到的特征图通过门控激活单元，并被输入到下一个块的垂直堆栈中。</p><p id="f720" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> <em class="ni"> 2。将垂直地图送入水平堆栈</em> </strong></p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi og"><img src="../Images/c9347bd348e190849e8331e9683c0222.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QF2Tk07fnyusyDo43uxxSQ.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">(图片改编自<a class="ae lk" href="https://arxiv.org/pdf/1606.05328.pdf" rel="noopener ugc nofollow" target="_blank">原图</a>)</p></figure><p id="3702" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于我们的自回归模型，需要结合纵向和横向堆栈的信息。为此，在每个块中，垂直堆栈也被用作水平层的输入之一。由于垂直堆栈的每个卷积步长的中心对应于被分析的像素，所以我们不能仅仅添加垂直信息。这将打破自回归模型的因果关系条件，因为它将允许未来像素的信息用于预测水平堆栈中的值。这是图8A中第二幅图的情况，其中黑色像素右侧(或未来)的像素用于预测它。因此，在将垂直信息输入水平堆栈之前，我们使用填充和裁剪将其下移(图8B)。).通过对图像进行零填充并裁剪图像的底部，我们可以确保垂直和水平堆栈之间的因果关系得以保持。我们将在以后的文章中深入探讨关于裁剪如何工作的更多细节，所以如果细节不完全清楚，请不要担心。</p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi oh"><img src="../Images/f3fac660f433ce650b109ed09b51321d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EsJFheSPP1fbOeYjHjqtzg.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">图8:如何确保像素之间的因果关系得以保留(图片由作者提供)</p></figure><p id="124c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> <em class="ni"> 3。计算水平特征图</em> </strong></p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi og"><img src="../Images/9bf533c97c838854ed3459ddfa974d16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*em0dM96i3VwqRHAzGPHDtg.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">(图片改编自<a class="ae lk" href="https://arxiv.org/pdf/1606.05328.pdf" rel="noopener ugc nofollow" target="_blank">原文</a>)</p></figure><p id="d225" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这一步中，我们处理水平卷积层的特征图。事实上，第一步包括对从垂直到水平卷积层输出的特征图求和。该组合的输出具有理想的接收格式，其考虑了所有先前像素的信息。最后，特征图通过门控激活单元。</p><p id="08c2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja"> <em class="ni"> 4。计算水平堆栈上的剩余连接</em>T3</strong></p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi og"><img src="../Images/bc73a2abf84c1871f56d083217aa7f0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FjBCnF9H61jm-EQEioyDeQ.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">(图片改编自<a class="ae lk" href="https://arxiv.org/pdf/1606.05328.pdf" rel="noopener ugc nofollow" target="_blank">原创论文</a>)</p></figure><p id="76cd" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这最后一步中，如果块不是网络的第一个，剩余连接将组合前一步的输出(通过1x1卷积处理)，然后馈入下一个块的水平堆栈。如果是网络的第一块，那么就没有剩余连接，跳过这一步。</p><p id="e646" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">使用Tensorflow 2。我们实现了上述方案，如下所示:</p><figure class="nk nl nm nn gt no"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="6969" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">总之，使用门控块，我们解决了感受野上的盲点并改善了模型性能。</p><h1 id="ab55" class="mg mh iq bd mi mj nd ml mm mn ne mp mq kf nf kg ms ki ng kj mu kl nh km mw mx bi translated">体系结构</h1><p id="9d49" class="pw-post-body-paragraph ko kp iq kq b kr my ka kt ku mz kd kw kx na kz la lb nb ld le lf nc lh li lj ij bi translated">在Oord et al. 2016中，PixelCNN使用了以下架构:第一层是带有7x7滤波器的掩蔽卷积(A型)。然后，使用15个残差块。每个模块使用3×3层卷积层和标准1×1卷积层的组合来处理数据。在每个卷积层之间，有一个非线性ReLU。最后，剩余块还包括剩余连接。</p><p id="2cbf" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在下一篇文章中，我们将看看如何进一步改善门控像素CNN的性能。我们还将介绍有条件的PixelCNN，敬请期待！</p><h1 id="9cfc" class="mg mh iq bd mi mj nd ml mm mn ne mp mq kf nf kg ms ki ng kj mu kl nh km mw mx bi translated">结果</h1><p id="faac" class="pw-post-body-paragraph ko kp iq kq b kr my ka kt ku mz kd kw kx na kz la lb nb ld le lf nc lh li lj ij bi translated">我们训练了PixelCNN和门控PixelCNN，并比较了下面的结果。</p><figure class="nk nl nm nn gt no gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi oi"><img src="../Images/5ac17e7b9fb1657dcb946fcd75216540.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ryep9ONnW35WUxGweEw_GQ.png"/></div></div><p class="nv nw gj gh gi nx ny bd b be z dk translated">图11:PixelCNN和门控pixel CNN的比较(图片由作者提供)</p></figure><p id="87c3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">当比较PixelCNN和门控PixelCNN的MNIST预测(图11)时，我们没有观察到MNIST数据集有很大的改善。一些以前被正确预测的数字现在被错误地预测了。但是，这并不意味着不应考虑PixelCNNs。在下一篇博文中，我们将讨论门控PixelCNNs和PixelCNN++以及它们将如何提高模型的性能。敬请关注！</p><h1 id="f8bc" class="mg mh iq bd mi mj nd ml mm mn ne mp mq kf nf kg ms ki ng kj mu kl nh km mw mx bi translated">参考</h1><p id="61a0" class="pw-post-body-paragraph ko kp iq kq b kr my ka kt ku mz kd kw kx na kz la lb nb ld le lf nc lh li lj ij bi translated"><a class="ae lk" href="https://youtu.be/1BURwCCYNEI" rel="noopener ugc nofollow" target="_blank">https://youtu.be/1BURwCCYNEI</a></p><p id="5ce1" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lk" href="https://openreview.net/pdf?id=Hyvw0L9el" rel="noopener ugc nofollow" target="_blank">https://openreview.net/pdf?id=Hyvw0L9el</a></p><p id="cd98" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lk" href="https://www.slideshare.net/suga93/conditional-image-generation-with-pixelcnn-decoders" rel="noopener ugc nofollow" target="_blank">https://www . slide share . net/suga 93/conditional-image-generation-with-pixel CNN-decoders</a></p><p id="f139" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><a class="ae lk" href="https://sergeiturukin.com/2017/02/24/gated-pixelcnn.html" rel="noopener ugc nofollow" target="_blank">https://sergeiturukin.com/2017/02/24/gated-pixelcnn.html</a></p></div></div>    
</body>
</html>