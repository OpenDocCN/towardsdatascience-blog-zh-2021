<html>
<head>
<title>My experience with uploading a dataset on HuggingFace’s dataset-hub</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我在HuggingFace的dataset-hub上上传数据集的经验</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/my-experience-with-uploading-a-dataset-on-huggingfaces-dataset-hub-803051942c2d?source=collection_archive---------18-----------------------#2021-06-23">https://towardsdatascience.com/my-experience-with-uploading-a-dataset-on-huggingfaces-dataset-hub-803051942c2d?source=collection_archive---------18-----------------------#2021-06-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="fbe3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">HuggingFace的<a class="ae kl" href="https://github.com/huggingface/datasets" rel="noopener ugc nofollow" target="_blank">数据集</a>库是一个单行python库，用于从<a class="ae kl" href="https://huggingface.co/datasets" rel="noopener ugc nofollow" target="_blank"> HuggingFace数据集中心</a>下载和预处理数据集。截至目前，该图书馆包含约1000个公开可用的数据集。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/0db34c90771840aba91281f5127f8b15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/0*ICZCwKWw7qffZggn.jpg"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">(来源:self)</p></figure><p id="1ee0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这篇文章中，我将分享我在dataset-hub上上传和维护数据集的经验。以下meme总结了使用数据集库背后的意图:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lc"><img src="../Images/39477e9c3c51481718dd14f0c8e5ab5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*S6lwkCamRR67weGb"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">上传数据集的灵感(作者:self)</p></figure><h2 id="e297" class="ld le iq bd lf lg lh dn li lj lk dp ll jy lm ln lo kc lp lq lr kg ls lt lu lv bi translated">获取数据:</h2><p id="d78d" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">在HuggingFace人员的帮助和指导下，我能够将<a class="ae kl" href="https://huggingface.co/models" rel="noopener ugc nofollow" target="_blank">模型中心</a>(类似于数据集，HuggingFace托管10，000多个公开可用的模型)上可用信息的元数据下载到一个csv文件中。然后，我开始将它作为数据集上传到dataset-hub。</p><h2 id="caf9" class="ld le iq bd lf lg lh dn li lj lk dp ll jy lm ln lo kc lp lq lr kg ls lt lu lv bi translated">安装数据集库:</h2><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="85a4" class="ld le iq mc b gy mg mh l mi mj">$pip install datasets</span></pre></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h2 id="ea95" class="ld le iq bd lf lg lh dn li lj lk dp ll jy lm ln lo kc lp lq lr kg ls lt lu lv bi translated">添加数据集:</h2><p id="d4d9" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">添加<a class="ae kl" href="https://huggingface.co/docs/datasets/share_dataset.html#sharing-your-dataset" rel="noopener ugc nofollow" target="_blank">公共数据集</a>有两种方式:</p><ul class=""><li id="d2bb" class="mr ms iq jp b jq jr ju jv jy mt kc mu kg mv kk mw mx my mz bi translated"><strong class="jp ir"> <em class="na">社区提供的</em> </strong>:数据集托管在数据集中心。它<strong class="jp ir">未经验证</strong>并在名称空间或组织下被识别，就像GitHub repo一样。</li><li id="2efa" class="mr ms iq jp b jq nb ju nc jy nd kc ne kg nf kk mw mx my mz bi translated"><strong class="jp ir"> <em class="na">规范</em> </strong>:通过打开<strong class="jp ir"> PR(Pull Request) </strong>到回购，数据集直接添加到<strong class="jp ir"> <em class="na">数据集</em>回购</strong>。通常，数据是不托管的，必须经过PR合并过程。</li></ul><p id="19f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为我想托管数据，以及预处理脚本(被库称为“数据集加载脚本”)，所以我选择上传数据集作为<em class="na">社区提供的数据集</em>。</p><p id="992f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将csv、json、xml或任何其他格式的现有数据集转换为数据集有两个主要要求:</p><ul class=""><li id="6725" class="mr ms iq jp b jq jr ju jv jy mt kc mu kg mv kk mw mx my mz bi translated">数据集加载脚本</li><li id="060b" class="mr ms iq jp b jq nb ju nc jy nd kc ne kg nf kk mw mx my mz bi translated">数据集元数据</li></ul><h2 id="1733" class="ld le iq bd lf lg lh dn li lj lk dp ll jy lm ln lo kc lp lq lr kg ls lt lu lv bi translated">数据集加载脚本:</h2><p id="75d1" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">创建这样一个脚本有很好的文档可用。然而，我更喜欢通过使用与我相似的预先存在的数据集的脚本进行复制粘贴，这些脚本存在于数据集库中<a class="ae kl" href="https://github.com/huggingface/datasets/tree/master/datasets" rel="noopener ugc nofollow" target="_blank">。例如:如果我的数据集是csv类型，我将从一个类似的csv类型脚本开始，并根据我的需要修改它。</a></p><p id="97c1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该脚本主要需要定义三个组件:</p><ul class=""><li id="b275" class="mr ms iq jp b jq jr ju jv jy mt kc mu kg mv kk mw mx my mz bi translated">关于列和数据类型的信息(称为<a class="ae kl" href="https://huggingface.co/docs/datasets/features.html" rel="noopener ugc nofollow" target="_blank">特性</a></li><li id="45b7" class="mr ms iq jp b jq nb ju nc jy nd kc ne kg nf kk mw mx my mz bi translated">从(或本地文件)下载数据并指定培训/测试/验证分割的URL</li><li id="7c0b" class="mr ms iq jp b jq nb ju nc jy nd kc ne kg nf kk mw mx my mz bi translated">利用分割和特征产生1行数据</li></ul><p id="6b78" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 1。_ info:</strong>CSV字段的标题需要用它们的数据类型来定义。我最后用了<code class="fe ng nh ni mc b">string</code>、<code class="fe ng nh ni mc b">int32</code>和<code class="fe ng nh ni mc b">large_string</code>。f <a class="ae kl" href="https://huggingface.co/docs/datasets/features.html" rel="noopener ugc nofollow" target="_blank">特性</a>中提供了受支持数据类型的描述。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/a1795e42d9ed5eb66ace453be1433a2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*V0z-mwCcLToSbmpWN1FE5A.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">数据类型很重要！(来源:self)</p></figure><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="533b" class="ld le iq mc b gy mg mh l mi mj">def _info(self):<br/>        return datasets.DatasetInfo(<br/>            description=_DESCRIPTION,<br/>            features=datasets.Features(<br/>                {<br/>                    "modelId": datasets.Value("string"),<br/>                    "lastModified": datasets.Value("string"),<br/>                    "tags": datasets.features.Sequence(datasets.Value("string")),<br/>                    "pipeline_tag": datasets.Value("string"),<br/>                    "files": datasets.features.Sequence(datasets.Value("string")),<br/>                    "publishedBy": datasets.Value("string"),<br/>                    "downloads_last_month": datasets.Value("int32"),<br/>                    "library": datasets.Value("string"),<br/>                    "modelCard": datasets.Value("large_string"),<br/>                }<br/>            ),<br/>            homepage=_HOMEPAGE,<br/>            license=_LICENSE,<br/>            citation=_CITATION,<br/>        )</span></pre><p id="9025" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">列“标签”和“文件”是数组，因为它们可以是多个，由库通过<code class="fe ng nh ni mc b">dataset.features.Sequence.</code>支持</p><p id="0f48" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 2。URLs本地文件:</strong></p><p id="63c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下一步是定义一个URL，在我的例子中是一个本地文件。因为数据只是探索性的，没有任何目标标签(不是专门用于训练的)，所以不需要测试分割。因此，只有训练数据集分割会起作用。</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="a0e0" class="ld le iq mc b gy mg mh l mi mj">_URL = "huggingface-modelhub.csv"<br/>...<br/>def _split_generators(self, dl_manager):<br/>    """Returns SplitGenerators."""<br/>    data_file = dl_manager.download_and_extract(_URL)<br/>    return [<br/>        datasets.SplitGenerator(<br/>            name=datasets.Split.TRAIN,<br/>            gen_kwargs={<br/>                "filepath": data_file,<br/>            },),]</span></pre><p id="0881" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 3。生成一行:</strong></p><p id="d62f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下一步是生成单行数据。在运行时，适当的生成器(如上定义)将从URL或本地文件中选取数据源，并使用它来生成一行。这里，由于数据格式是<code class="fe ng nh ni mc b">csv</code>，我们可以使用python内置的csv模块及其函数<code class="fe ng nh ni mc b">csv.reader</code>从文件中读取数据。</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="873f" class="ld le iq mc b gy mg mh l mi mj">def _generate_examples(self, filepath):<br/>    """Yields examples."""<br/>    with open(filepath, encoding="utf-8") as f:<br/>        reader = csv.reader(f)<br/>        for id_, row in enumerate(reader):<br/>            if id_ == 0:<br/>                continue<br/>            yield id_, {<br/>                "modelId": row[0],<br/>                "lastModified": row[1],<br/>                "tags": ast.literal_eval(row[2]),<br/>                "pipeline_tag": row[3],<br/>                "files": ast.literal_eval(row[4]),<br/>                "publishedBy": row[5],<br/>                "downloads_last_month": float(row[6]) if row[6] else 0,<br/>                "library": row[7],<br/>                "modelCard": row[8]<br/>            }</span></pre><p id="662b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe ng nh ni mc b">ast.literal_eval</code>是一个将字符串中的数组解析成实际数组(list)的便捷函数。</p><p id="6eb1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该脚本可以这样测试:</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="4077" class="ld le iq mc b gy mg mh l mi mj"><strong class="mc ir">&gt;&gt;&gt; </strong>from datasets import load_dataset<br/><strong class="mc ir">&gt;&gt;&gt; </strong>dataset = load_dataset('PATH/TO/MY/SCRIPT.py')<br/>&gt;&gt;&gt; dataset["train"] # To access train generator<br/>&gt;&gt;&gt; dataset["train"][0] #Access elements in dataset</span></pre><p id="d8bd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">脚本就绪后，我们继续添加数据集元数据，并准备好发布数据集。</p><h2 id="c846" class="ld le iq bd lf lg lh dn li lj lk dp ll jy lm ln lo kc lp lq lr kg ls lt lu lv bi translated">数据集元数据:</h2><p id="339f" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">文档详细解释了如何为共享准备数据集。为了添加元数据，可以通过<code class="fe ng nh ni mc b">datasets-cli</code>使用一个helper命令，它是在我们安装<code class="fe ng nh ni mc b">datasets</code>库时安装的。</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="8625" class="ld le iq mc b gy mg mh l mi mj">datasets-cli test datasets/&lt;your-dataset-folder&gt; --save_infos --all_configs</span></pre><p id="acd6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">运行上面的命令会生成一个文件<code class="fe ng nh ni mc b">dataset_infos.json</code>，其中包含数据集大小、校验和等元数据。</p><h2 id="87d2" class="ld le iq bd lf lg lh dn li lj lk dp ll jy lm ln lo kc lp lq lr kg ls lt lu lv bi translated">上传数据集:</h2><p id="1a27" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">Huggingface在幕后使用git和git-lfs将数据集作为存储库进行管理。首先，我们需要创建一个<a class="ae kl" href="https://huggingface.co/new-dataset" rel="noopener ugc nofollow" target="_blank">新存储库</a>。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nk"><img src="../Images/474fd36cca194564223cefe8da37df9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dihej2xDGh-dw-DQhUv7iw.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">创建新的数据集repo ( <a class="ae kl" href="https://huggingface.co/new-dataset" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="a4e2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦存储库准备就绪，就可以应用标准的git实践了。即从您的项目目录运行:</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="853d" class="ld le iq mc b gy mg mh l mi mj">$ git init .<br/>$ git remote add origin https://huggingface.co/datasets/&lt;user&gt;/&lt;repo&gt;<br/>$ git pull origin main</span></pre><p id="4367" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们已经将本地机器与存储库同步。下一步是添加以下文件并提交:</p><ul class=""><li id="cf08" class="mr ms iq jp b jq jr ju jv jy mt kc mu kg mv kk mw mx my mz bi translated">数据集文件(csv): <strong class="jp ir">数据本身</strong></li><li id="66be" class="mr ms iq jp b jq nb ju nc jy nd kc ne kg nf kk mw mx my mz bi translated">数据集加载脚本:<strong class="jp ir">数据</strong>的加载器</li><li id="8cd1" class="mr ms iq jp b jq nb ju nc jy nd kc ne kg nf kk mw mx my mz bi translated">数据集元数据:<strong class="jp ir">元数据，如大小、引用等</strong></li></ul><p id="5a14" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">但是有一个条件！传统的git系统不适合处理大文件。这是通过<a class="ae kl" href="https://git-lfs.github.com/" rel="noopener ugc nofollow" target="_blank"> git-lfs </a>(大文件存储)来管理的。我们不需要深入了解它是如何工作的，我们只需运行以下命令就可以将大文件推送到repo:</strong></p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="ed4f" class="ld le iq mc b gy mg mh l mi mj">$ git lfs install<br/>$ git lfs track huggingface-modelhub.csv<br/>$ git add dataset_infos.json huggingface-modelhub.csv huggingface-modelhub.py<br/>$ git commit -m "Commit message"<br/>$ git push origin main</span></pre><p id="eff2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://huggingface.co/docs/datasets/share_dataset.html#uploading-your-files" rel="noopener ugc nofollow" target="_blank">文档</a>也详细介绍了lfs。因为这只是一个git repo，所以也可以提交像README这样的任何其他文件。Dataset-hub UI还提供了一种快速更新自述文件(称为datasetCard)的方法</p><p id="6075" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">仅此而已。数据集应上传到数据集中心。要访问它，请运行:</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="bcb6" class="ld le iq mc b gy mg mh l mi mj">&gt;&gt;&gt; dataset = load_dataset("&lt;user&gt;/&lt;repo&gt;")</span></pre><h2 id="147a" class="ld le iq bd lf lg lh dn li lj lk dp ll jy lm ln lo kc lp lq lr kg ls lt lu lv bi translated">将更改推送到已发布的数据集:</h2><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/288d6743d2008f4d4c3f008fc57a0d7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*JerlaSb6UwUl7Tgb1ypSHg.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">维护数据集版本(来源:self)</p></figure><p id="dc77" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于数据集的repo可以使用git进行控制，我认为首先提交到一个<code class="fe ng nh ni mc b">dev</code>分支，完整地测试它，然后执行到<code class="fe ng nh ni mc b">main</code>的合并可能是一个好的实践。这将大大有助于“意外地”破坏一个已经存在且稳定的工作数据集。这非常类似于标准的基于git的软件发布哲学。</p><p id="5649" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">另一个优势是数据集版本也不一定需要连续(1、1.1、1.2等)。不同的分支可以保存不同版本的数据集。</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="a1a7" class="ld le iq mc b gy mg mh l mi mj"><strong class="mc ir">&gt;&gt;&gt; </strong>dataset = load_dataset("&lt;user&gt;/&lt;repo&gt;",<br/><strong class="mc ir">&gt;&gt;&gt; </strong>  script_version="dev")  <em class="na"># tag name, branch name, or commit hash</em></span></pre><h2 id="d4b4" class="ld le iq bd lf lg lh dn li lj lk dp ll jy lm ln lo kc lp lq lr kg ls lt lu lv bi translated">卡住时该怎么办:</h2><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/6d6e6044634447ba703dfc88abd86ecf.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*amhzOm-BwOt0MjTJ_SG2zw.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk translated">HuggingFace有一个自主持的讨论平台(来源:self)</p></figure><p id="7bdd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">拥抱脸论坛非常活跃，团队+社区非常有帮助和支持。我个人觉得比stackoverflow更主动，反应更快。你也可以直接在github上打开<a class="ae kl" href="https://github.com/huggingface/datasets/issues" rel="noopener ugc nofollow" target="_blank">问题</a>，但是我更喜欢论坛，因为它们有点不正式。</p><blockquote class="nm nn no"><p id="4802" class="jn jo na jp b jq jr js jt ju jv jw jx np jz ka kb nq kd ke kf nr kh ki kj kk ij bi translated">没有问题是愚蠢的问题！永远不要害怕问。</p></blockquote></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><p id="8ccd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">那都是乡亲们！</p><p id="68d8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我希望你喜欢这篇文章，并发现数据集库是有用的。我用加载脚本<a class="ae kl" href="https://huggingface.co/datasets/dk-crazydiv/huggingface-modelhub" rel="noopener ugc nofollow" target="_blank">上传的数据集可以在这里</a>查看，并用作csv格式的参考。</p><p id="2d84" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请在评论中分享你的观点。我也准备在推特上进行讨论。</p><p id="a71b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">祝你愉快。:)</p></div></div>    
</body>
</html>