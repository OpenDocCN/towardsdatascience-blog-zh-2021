<html>
<head>
<title>5 Lesser-Known Python Libraries for Your Next NLP Project</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为您的下一个 NLP 项目准备的 5 个鲜为人知的 Python 库</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-lesser-known-python-libraries-for-your-next-nlp-project-ff13fc652553?source=collection_archive---------2-----------------------#2021-12-24">https://towardsdatascience.com/5-lesser-known-python-libraries-for-your-next-nlp-project-ff13fc652553?source=collection_archive---------2-----------------------#2021-12-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="34cd" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">带有代码示例和解释。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/03001a561ee3ebe311ed92857a8272bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1POhlVeQy2wFKspp"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由<a class="ae kv" href="https://unsplash.com/@conscious_design" rel="noopener ugc nofollow" target="_blank">有意识设计</a>来自<a class="ae kv" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="5af0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我第一次开始阅读 Medium 时，我最喜欢的文章类型是那些向我介绍新的 Python 库的文章。我了解的几个库现在是我日常项目的一部分。</p><p id="4785" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了传播它，我想分享我在过去几年做各种自然语言处理(NLP)工作中发现的 5 个很棒的 Python 库。</p><h1 id="474a" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak"> 1)宫缩</strong></h1><p id="676b" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">当然，你可以写一长串正则表达式来扩展文本数据中的缩写<em class="mp">(即不要</em> → <em class="mp">不要；不能</em> → <em class="mp">不能；还没有</em> → <em class="mp">还没有)。</em>但是为什么不省点力气，利用 Python 库来帮你完成繁重的工作呢？</p><p id="7c54" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">缩写是一个易于使用的库，它将扩展常见的英语缩写和俚语。它速度快，效率高，并且可以处理大多数边缘情况，比如丢失撇号。</p><h2 id="e562" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">安装</strong></h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="498a" class="mq lt iq nd b gy nh ni l nj nk">pip install contractions</span></pre><h2 id="0523" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">示例</strong></h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="17e2" class="mq lt iq nd b gy nh ni l nj nk">import contractions</span><span id="1abc" class="mq lt iq nd b gy nl ni l nj nk">s = "ive gotta go! i'll see yall later."<br/>text = contractions.fix(s, slang=True)<br/>print(text)</span></pre><h2 id="ac98" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">结果</strong></h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="b11a" class="mq lt iq nd b gy nh ni l nj nk">ORIGINAL: ive gotta go! i’ll see yall later.</span><span id="1934" class="mq lt iq nd b gy nl ni l nj nk">OUTPUT: I have got to go! I will see you all later.</span></pre><h2 id="1948" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">用例</h2><p id="5bdc" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">文本预处理的一个重要部分是创建一致性，并在不丢失太多含义的情况下削减唯一单词的列表。例如，词袋模型和 TF-IDF 创建了大型稀疏矩阵，其中每个变量都是语料库中不同的词汇。扩展缩写可以进一步降低维数，甚至有助于过滤掉停用词。</p><p id="4fd1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://github.com/kootenpv/contractions" rel="noopener ugc nofollow" target="_blank">文献</a></p></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><h1 id="f4ed" class="ls lt iq bd lu lv nt lx ly lz nu mb mc jw nv jx me jz nw ka mg kc nx kd mi mj bi translated"><strong class="ak"> 2)蒸馏标点符号</strong></h1><p id="e8e4" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">恢复丢失的标点符号到纯英语文本…听起来很简单，对吗？对计算机来说，要做到这一点肯定要复杂得多。</p><p id="2a32" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Distilbert-punctuator 是我能找到的唯一一个执行这项任务的 Python 库。而且超级准确！这是因为它使用了一个精简版本的 BERT，这是一个由谷歌提供的最先进的预训练语言模型。它进一步微调了超过 20，000 篇新闻文章和 4，000 篇 TED 演讲的文字记录，以检测句子的边界。当插入句尾标点符号时，例如句号，模型还会适当地大写下一个起始字母。</p><h2 id="f4cb" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">安装</strong></h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="07c1" class="mq lt iq nd b gy nh ni l nj nk">pip install distilbert-punctuator</span></pre><blockquote class="ny nz oa"><p id="af61" class="kw kx mp ky b kz la jr lb lc ld ju le ob lg lh li oc lk ll lm od lo lp lq lr ij bi translated">专业提示:这个库需要相当多的依赖项。如果你在安装上有问题，那么在 Google Colab 上试试，在这种情况下，你需要运行！皮普安装蒸馏标点符号代替。</p></blockquote><h2 id="4ca7" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">例子</strong></h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="51a0" class="mq lt iq nd b gy nh ni l nj nk">from dbpunctuator.inference import Inference, InferenceArguments<br/>from dbpunctuator.utils import DEFAULT_ENGLISH_TAG_PUNCTUATOR_MAP</span><span id="9eee" class="mq lt iq nd b gy nl ni l nj nk">args = InferenceArguments(<br/>        model_name_or_path="Qishuai/distilbert_punctuator_en",<br/>        tokenizer_name="Qishuai/distilbert_punctuator_en",<br/>        tag2punctuator=DEFAULT_ENGLISH_TAG_PUNCTUATOR_MAP<br/>    )</span><span id="90b3" class="mq lt iq nd b gy nl ni l nj nk">punctuator_model = Inference(inference_args=args, <br/>                             verbose=False)</span><span id="b334" class="mq lt iq nd b gy nl ni l nj nk">text = [<br/>    """<br/>however when I am elected I vow to protect our American workforce<br/>unlike my opponent I have faith in our perseverance our sense of trust and our democratic principles will you support me<br/>    """<br/>]</span><span id="1733" class="mq lt iq nd b gy nl ni l nj nk">print(punctuator_model.punctuation(text)[0])</span></pre><h2 id="66f3" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">结果</h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="1b1d" class="mq lt iq nd b gy nh ni l nj nk">ORIGINAL: <br/>however when I am elected I vow to protect our American workforce<br/>unlike my opponent I have faith in our perseverance our sense of trust and our democratic principles will you support me</span><span id="f02a" class="mq lt iq nd b gy nl ni l nj nk">OUTPUT:<br/>However, when I am elected, I vow to protect our American workforce. Unlike my opponent, I have faith in our perseverance, our sense of trust and our democratic principles. Will you support me?</span></pre><h2 id="7867" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">用例</strong></h2><p id="9fd8" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">有时，您只是希望您的文本数据在语法上更加正确和更具可读性。无论任务是修复混乱的 Twitter 帖子还是聊天机器人消息，这个库都是为你准备的。</p><p id="a061" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://pypi.org/project/distilbert-punctuator/" rel="noopener ugc nofollow" target="_blank">文档</a></p></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><h1 id="2df2" class="ls lt iq bd lu lv nt lx ly lz nu mb mc jw nv jx me jz nw ka mg kc nx kd mi mj bi translated"><strong class="ak"> 3)文本统计</strong></h1><p id="fff4" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">Textstat 是一个易于使用的轻量级库，它提供了关于文本数据的各种指标，如阅读水平、阅读时间和字数。</p><h2 id="4eef" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">安装</strong></h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="d38f" class="mq lt iq nd b gy nh ni l nj nk">pip install textstat</span></pre><h2 id="3406" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">例子</strong></h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="e7c0" class="mq lt iq nd b gy nh ni l nj nk">import textstat</span><span id="8c96" class="mq lt iq nd b gy nl ni l nj nk">text = """<br/>Love this dress! it's sooo pretty. i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite. <br/>"""</span><span id="463f" class="mq lt iq nd b gy nl ni l nj nk"># Flesch reading ease score<br/>print(textstat.flesch_reading_ease(text))<br/>  # 90-100 | Very Easy<br/>  # 80-89  | Easy<br/>  # 70-79  | Fairly Easy<br/>  # 60-69  | Standard<br/>  # 50-59  | Fairly Difficult<br/>  # 30-49  | Difficult<br/>  # &lt;30    | Very Confusing</span><span id="06ea" class="mq lt iq nd b gy nl ni l nj nk"># Reading time (output in seconds)<br/># Assuming 70 milliseconds/character<br/>print(textstat.reading_time(text, ms_per_char=70))</span><span id="2533" class="mq lt iq nd b gy nl ni l nj nk"># Word count <br/>print(textstat.lexicon_count(text, removepunct=True))</span></pre><h2 id="01e0" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">结果</h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="8594" class="mq lt iq nd b gy nh ni l nj nk">ORIGINAL:<br/>Love this dress! it's sooo pretty. i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.</span><span id="999e" class="mq lt iq nd b gy nl ni l nj nk">OUTPUTS:<br/>74.87 # reading score is considered 'Fairly Easy'<br/>7.98  # 7.98 seconds to read<br/>30    # 30 words</span></pre><h2 id="7b5c" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">用例</strong></h2><p id="24dc" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">这些指标增加了一层额外的分析。比方说，你正在从一本八卦杂志中寻找一组名人新闻文章。使用 textstat，你可能会发现更快更容易阅读的文章更受欢迎，保留率也更高。</p><p id="2831" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://pypi.org/project/textstat/" rel="noopener ugc nofollow" target="_blank">文档</a></p></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><h1 id="034d" class="ls lt iq bd lu lv nt lx ly lz nu mb mc jw nv jx me jz nw ka mg kc nx kd mi mj bi translated"><strong class="ak"> 4)胡言乱语检测器</strong></h1><p id="b959" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">这个低代码库的主要目的是检测乱码(或难以理解的单词)。它使用一个在大型英语单词语料库上训练的模型。</p><h2 id="9567" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">安装+ </strong>培训</h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="126c" class="mq lt iq nd b gy nh ni l nj nk">pip install gibberish-detector</span></pre><p id="190f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，您还需要在您的终端上训练模型，但这非常简单，只需要一分钟。只需遵循以下步骤:</p><ol class=""><li id="5cc3" class="oe of iq ky b kz la lc ld lf og lj oh ln oi lr oj ok ol om bi translated">从<a class="ae kv" href="https://github.com/rrenaud/Gibberish-Detector/blob/master/big.txt" rel="noopener ugc nofollow" target="_blank">这里</a>下载名为 big.txt 的训练语料库</li><li id="2386" class="oe of iq ky b kz on lc oo lf op lj oq ln or lr oj ok ol om bi translated">打开您的 CLI 和<em class="mp"> cd </em>到 big.txt 所在的目录</li><li id="82f5" class="oe of iq ky b kz on lc oo lf op lj oq ln or lr oj ok ol om bi translated">运行下面的:<em class="mp">胡言乱语-检测器训练。\big.txt &gt;胡言乱语-detector.model </em></li></ol><p id="88e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一个名为<em class="mp">的文件将会在你当前的目录下创建。</em></p><h2 id="5283" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">示例</strong></h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="504d" class="mq lt iq nd b gy nh ni l nj nk">from gibberish_detector import detector</span><span id="ca7b" class="mq lt iq nd b gy nl ni l nj nk"># load the gibberish detection model<br/>Detector = detector.create_from_model('.\gibberish-detector.model')</span><span id="7496" class="mq lt iq nd b gy nl ni l nj nk">text1 = "xdnfklskasqd"<br/>print(Detector.is_gibberish(text1))</span><span id="6a82" class="mq lt iq nd b gy nl ni l nj nk">text2 = "apples"<br/>print(Detector.is_gibberish(text2))</span></pre><h2 id="71ca" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">结果</h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="80f8" class="mq lt iq nd b gy nh ni l nj nk">True  # xdnfklskasqd (this is gibberish)</span><span id="2387" class="mq lt iq nd b gy nl ni l nj nk">False # apples (this is not)</span></pre><h2 id="1f0f" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">用例</strong></h2><p id="0def" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我过去曾使用过 gibbish-detector 来帮助我从数据集中删除不良的观察结果。</p><p id="e41f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它也可以被实现用于用户输入的错误处理。例如，如果用户在你的 web 应用程序上输入了无意义、无意义的文本，你可能想要返回一个错误消息。</p><p id="0065" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://pypi.org/project/gibberish-detector/" rel="noopener ugc nofollow" target="_blank">文档</a></p></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><h1 id="ff31" class="ls lt iq bd lu lv nt lx ly lz nu mb mc jw nv jx me jz nw ka mg kc nx kd mi mj bi translated"><strong class="ak"> 5) NLPAug </strong></h1><p id="6232" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我把最好的留到了最后。这个多用途的图书馆确实是一个隐藏的宝石。</p><p id="de99" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，什么是数据增强？它是通过添加现有数据的稍微修改的副本来扩展训练集大小的任何技术。当现有数据多样性有限或不平衡时，通常使用数据扩充。对于计算机视觉问题，增强用于通过裁剪、旋转和改变图像的亮度来创建新的样本。对于数字数据，可以使用聚类技术创建合成实例。</p><p id="b88f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是如果我们处理的是文本数据呢？</p><p id="1ac6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这就是 NLPAug 的用武之地。该库可以通过替换或插入语义相关的单词来扩充文本。</p><p id="bdab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它通过采用像 BERT 这样的预训练语言模型来实现这一点，这是一种强大的方法，因为它考虑了单词的上下文。根据您设置的参数，前<em class="mp"> n </em>个相似单词将用于修改文本。</p><p id="07fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">预训练的单词嵌入，如 Word2Vec 和 GloVe，也可以用于用同义词替换单词。点击<a class="ae kv" href="https://www.analyticsvidhya.com/blog/2021/08/nlpaug-a-python-library-to-augment-your-text-data/" rel="noopener ugc nofollow" target="_blank">此处</a>阅读一篇展示该库全部功能的精彩文章。</p><h2 id="8e8d" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">安装</strong></h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="f6dc" class="mq lt iq nd b gy nh ni l nj nk">pip install nlpaug</span></pre><h2 id="428f" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">例子</strong></h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="b080" class="mq lt iq nd b gy nh ni l nj nk">import nlpaug.augmenter.word as naw</span><span id="4be9" class="mq lt iq nd b gy nl ni l nj nk"># main parameters to adjust<br/>ACTION = 'substitute' # or use 'insert'<br/>TOP_K = 15 # randomly draw from top 15 suggested words<br/>AUG_P = 0.40 # augment 40% of words within text</span><span id="743b" class="mq lt iq nd b gy nl ni l nj nk">aug_bert = naw.ContextualWordEmbsAug(<br/>    model_path='bert-base-uncased', <br/>    action=ACTION, <br/>    top_k=TOP_K,<br/>    aug_p=AUG_P<br/>    )</span><span id="1714" class="mq lt iq nd b gy nl ni l nj nk">text = """<br/>Come into town with me today to buy food!<br/>"""</span><span id="fbda" class="mq lt iq nd b gy nl ni l nj nk">augmented_text = aug_bert.augment(text, n=3) # n: num. of outputs</span><span id="c0cc" class="mq lt iq nd b gy nl ni l nj nk">print(augmented_text)</span></pre><h2 id="53a9" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">结果</h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="49d7" class="mq lt iq nd b gy nh ni l nj nk">ORIGINAL:<br/>Come into town with me today to buy food!</span><span id="3558" class="mq lt iq nd b gy nl ni l nj nk">OUTPUTS:<br/>• drove into denver with me today to purchase groceries!<br/>• head off town with dad today to buy coffee!<br/>• come up shop with mom today to buy lunch!</span></pre><h2 id="62a8" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated"><strong class="ak">用例</strong></h2><p id="03d3" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">假设您正在一个数据集上训练一个监督分类模型，该数据集有 15k 个正面评论，只有 4k 个负面评论。像这样严重不平衡的数据集将在训练期间产生对多数类(正面评论)的模型偏差。</p><p id="3af9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">简单地复制少数类的例子(负面评论)不会给模型增加任何新的信息。相反，利用 NLPAug 的高级文本增强功能来增加少数民族类别的多样性。该技术已被<a class="ae kv" rel="noopener" target="_blank" href="/powerful-text-augmentation-using-nlpaug-5851099b4e97">证明</a>可改善 AUC 和 F1 评分。</p><p id="3292" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://github.com/makcedward/nlpaug" rel="noopener ugc nofollow" target="_blank">文档</a></p><h1 id="ef3b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak">结论</strong></h1><p id="877b" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">作为数据科学家，Kaggle 的竞争对手，或者一般的程序员，我们在口袋里放尽可能多的工具是很重要的。我们可以利用这些库来解决问题，增强我们的数据集，并花更多的时间来思考解决方案，而不是编写代码。</p><p id="3fbc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你对 NLP 感兴趣，可以看看我最近写的关于命名实体识别(NER)的文章。我将展示如何使用 spaCy——另一个强大的 NLP 库——来构建一个模型，自动识别非结构化文本中与家庭装修服务相关的单词。</p><div class="os ot gp gr ou ov"><a href="https://levelup.gitconnected.com/auto-detect-anything-with-custom-named-entity-recognition-ner-c89d6562e8e9" rel="noopener  ugc nofollow" target="_blank"><div class="ow ab fo"><div class="ox ab oy cl cj oz"><h2 class="bd ir gy z fp pa fr fs pb fu fw ip bi translated">通过自定义命名实体识别自动检测任何内容(NER)</h2><div class="pc l"><h3 class="bd b gy z fp pa fr fs pb fu fw dk translated">使用 spaCy v3 从头至尾的代码演练</h3></div><div class="pd l"><p class="bd b dl z fp pa fr fs pb fu fw dk translated">levelup.gitconnected.com</p></div></div><div class="pe l"><div class="pf l pg ph pi pe pj kp ov"/></div></div></a></div><p id="db63" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢阅读！</p></div></div>    
</body>
</html>