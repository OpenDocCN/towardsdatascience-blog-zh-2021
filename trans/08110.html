<html>
<head>
<title>The Ultimate Guide to Emotion Recognition from Facial Expressions using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python从面部表情识别情感的终极指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-ultimate-guide-to-emotion-recognition-from-facial-expressions-using-python-64e58d4324ff?source=collection_archive---------0-----------------------#2021-07-26">https://towardsdatascience.com/the-ultimate-guide-to-emotion-recognition-from-facial-expressions-using-python-64e58d4324ff?source=collection_archive---------0-----------------------#2021-07-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="dec5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">建立一个对图像和视频都有效的人脸情感识别(FER)算法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8dc6c0a4fe83b7958a284e7e536a1cce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ytK5LpVzuj8AdZF2iIX9CA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">人类情感的浪潮|图片来自<a class="ae ky" href="https://www.pexels.com/photo/collage-of-portraits-of-cheerful-woman-3807758/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的Andrea Piacquadio </p></figure><p id="b1bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">情感是英语中极少数没有具体定义的词之一，这是可以理解的。它是抽象的。然而，我们一生中所做的几乎每一个决定都是由情感驱动的。市场研究已经证明，正确预测情绪可以成为企业增长的巨大源泉，这就是我们今天要做的——解读情绪。在数据和机器学习的世界中，这个概念属于认知系统的范畴。让我们尝试解码情感识别算法背后的科学，并为我们自己建立一个。</p><p id="45e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个认知情感检测算法到底想完成什么？这个想法是基于训练数据(以人类的图像和视频的形式)复制人类的思维过程，并尝试分割这些数据中存在的情绪。为了执行本章的分析，我们将专注于展示情绪的预先录制的图像和视频，但同样也可以在实时视频流中实现实时分析。</p><h2 id="00b5" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">对世界的视觉理解</strong></h2><p id="fa95" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">计算机视觉是处理视觉数据的人工智能的一部分。随着机器学习和深度学习模型的使用，今天的计算机系统可以处理数字图像和视频，以理解和情感识别视频内容的特征。</p><blockquote class="mt"><p id="3bda" class="mu mv it bd mw mx my mz na nb nc lu dk translated">计算机视觉作为一个计算概念最初出现在20世纪50年代，当时一些神经网络用于检测对象的边缘，后来发展到手写文本、语音和语言。</p></blockquote><p id="10f2" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">几个复杂的用例证明了计算机视觉在当今工业中的应用。一些非常基本的用途是，在网上进行的考试。网络摄像头可以读取用户的表情来解释他们的精神状态。这也有助于在飞行员和赛车手进入驾驶舱进行最后一次驾驶前测试他们的情绪强度。今天的许多机器人，包括像Alexa和Siri这样的语音助手，都能够成功地模仿人类的行为，并动情地说话。这也可以追溯到认知疗法，这种疗法治疗退伍军人和股票交易者的压力和焦虑障碍，他们经常处于情绪紧张状态。</p><h1 id="d44c" class="ni lw it bd lx nj nk nl ma nm nn no md jz np ka mg kc nq kd mj kf nr kg mm ns bi translated">认知科学和情感分析</h1><p id="03c6" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">今天的人工智能已经达到了几年前无法想象的高度和长度。程序和计算机系统现在可以高度精确地模仿人类的行为、反应和反应。</p><h2 id="68e2" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">情感分析</strong></h2><p id="3368" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">对人类情感的分析，也称为在环境中对观点或情感的挖掘，是对人类大脑不同状态的研究。使情感分析成为可能的因素是自然语言处理、计算语言学、文本挖掘和生物统计学分析。</p><blockquote class="nt nu nv"><p id="2225" class="kz la nw lb b lc ld ju le lf lg jx lh nx lj lk ll ny ln lo lp nz lr ls lt lu im bi translated">任何情感分析程序的基本任务都是分离输入的极性(文本、语音、面部表情等)。)来理解所呈现的主要情绪是积极的、消极的还是中性的。基于这种初步分析，程序通常会更深入地挖掘，以识别快乐、幸福、厌恶、愤怒、恐惧和惊讶等情绪。</p></blockquote><blockquote class="mt"><p id="b454" class="mu mv it bd mw mx oa ob oc od oe lu dk translated">这一分析有两个前提。一是量化输入数据，以便算法读取和处理，其次，心理学研究有助于识别哪种表情代表哪种情绪。</p></blockquote><figure class="og oh oi oj ok kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/9a1adc05bf5208cebbea119eb6b30288.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I1KMA8VcXz00hPSBIB0icw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">情感的程序化分析|作者图片</p></figure><h2 id="dcfa" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">认知科学</strong></h2><p id="d8df" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">就计算系统而言，认知科学是对发生在人脑中的科学过程的研究。它负责检查认知的功能，即思想的感知、语言、大脑的记忆、推理和处理接收到的信息。在更广泛的层面上，它是对智力和行为的研究。</p><blockquote class="nt nu nv"><p id="14b8" class="kz la nw lb b lc ld ju le lf lg jx lh nx lj lk ll ny ln lo lp nz lr ls lt lu im bi translated">认知科学的目标是研究人脑并理解其智能原理。这样做是希望通过从人类智能的知识中构建计算机系统，机器将能够模仿学习并像人类一样发展智能行为模式。</p></blockquote><p id="5383" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">认知科学在三个不同层次的分析中运作:</p><ol class=""><li id="ba34" class="ol om it lb b lc ld lf lg li on lm oo lq op lu oq or os ot bi translated">计算理论:在这一层，分析的目标被指定并输入到计算机系统。这可能是对语言的模仿，也可能是对情感的理解。</li><li id="6640" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated">表示和算法:用一般的机器学习术语来说，这是训练阶段。在这里，理想的输入和输出场景被呈现给机器，算法被放置在适当的位置，最终负责将输入转换为输出。</li><li id="cedf" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated">硬件实现:这是最终的认知阶段。它是在现实世界中制定算法，并对照人脑分析其工作轨迹。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/6648bfa3bbf03d68f24a03826a4bfba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CRTVkGWnAZ1XSOhAkOn35w@2x.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">人类认知及其在人工智能图像中的潜在应用</p></figure><h1 id="b131" class="ni lw it bd lx nj nk nl ma nm nn no md jz np ka mg kc nq kd mj kf nr kg mm ns bi translated">图像中的人脸情感识别</h1><blockquote class="mt"><p id="518b" class="mu mv it bd mw mx my mz na nb nc lu dk translated">人们常说，我们内心的感受反映在脸上。</p></blockquote><p id="fe2e" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">面部表情是人类和动物交流的重要方式。人类的行为，心理特征，都很容易通过面部表情来研究。它也广泛用于医学治疗和疗法。在这一部分，我们将研究面部表情和面部肖像的图像，以解码图像中呈现的情感。在后面的部分中，我们将对基于视频的输入执行相同的步骤。</p><h2 id="2490" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">人脸情感识别器</strong></h2><p id="4589" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">人脸情感识别器(通常称为FER)是由<a class="ae ky" href="https://www.linkedin.com/in/justinshenk/?originalSubdomain=de" rel="noopener ugc nofollow" target="_blank">贾斯汀·申克</a>构建和维护的开源Python库，用于图像和视频的情感分析。该项目建立在一个版本上，该版本使用卷积神经网络，其权重在该系统创建模型的<a class="ae ky" href="https://github.com/justinshenk/fer/tree/master/src/fer/data" rel="noopener ugc nofollow" target="_blank">源代码</a>(FER的执行可以在此找到)中的HDF5数据文件中提到。当模型被调用和初始化时，这可以通过使用FER构造函数来重写。</p><ol class=""><li id="16ac" class="ol om it lb b lc ld lf lg li on lm oo lq op lu oq or os ot bi translated">MTCNN(多级联卷积网络)是构造函数的一个参数。这是一种检测人脸的技术。当设置为“真”时，MTCNN模型用于检测人脸，当设置为“假”时，该函数使用默认的OpenCV Haarcascade分类器。</li><li id="e95c" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated">detect_emotions():这个函数用于对情绪的检测进行分类，它将输出注册为六个类别，即“恐惧”、“中性”、“快乐”、“悲伤”、“愤怒”和“厌恶”。每一种情绪都经过计算，输出放在0到1的范围内。</li></ol><p id="c5bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">逻辑流程:</strong>程序首先输入需要分析的图像或视频。FER()构造函数通过给它一个人脸检测分类器(Open CV Haarcascade或MTCNN)来初始化。然后，我们调用这个构造函数的detect emotions函数，将输入对象(图像或视频)传递给它。得到的结果是一系列情绪，每种情绪都有一个值。最后，<em class="nw">‘top _ emotion’</em>函数可以将对象的最高值情感屏蔽掉并返回。</p><p id="0b99" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nw">安装FER依赖于OpenCV版或更高版本、TensorFlow版或更高版本以及Python 3.6。现在让我们看看这个算法对图像的实现。</em></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pa pb l"/></div></figure><h2 id="f31b" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">输出</h2><p id="138a" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">该代码单独以图像作为输入，并在输出中详细描述各种情绪及其单独的强度水平。然后，我们使用top_emotion()提取图像中最主要的情感。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/a0a85c83a397c9dec6f3e2adec1fc58e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Duf6qanNHjA2k7gFHehYLA@2x.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片分析代码的输出|图片作者</p></figure><p id="1d01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在已经观察了如何分析图像来检索那些图像中出现的人的表情和情绪状态。在下一部分中，我们将使用视频执行相同的分析。</p><h2 id="e731" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">完整的代码库(图像输入)</h2><div class="pd pe gp gr pf pg"><a href="https://github.com/rjrahul24/ai-with-python-series/tree/main/06.%20Emotion%20Recognition%20using%20Facial%20Images" rel="noopener  ugc nofollow" target="_blank"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd iu gy z fp pl fr fs pm fu fw is bi translated">人工智能与python系列/06。使用面部图像的情感识别</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">人工智能的Python。教程-使用图像中的面部表情进行情感识别。</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">github.com</p></div></div><div class="pp l"><div class="pq l pr ps pt pp pu ks pg"/></div></div></a></div><p id="d41a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管上面的代码片段实现了程序的核心逻辑，但我还是建议仔细阅读上面链接的资源库中的完整Colab笔记本，以获得对整个工作代码的详细理解。</p><h1 id="072d" class="ni lw it bd lx nj nk nl ma nm nn no md jz np ka mg kc nq kd mj kf nr kg mm ns bi translated">从实时视频中识别面部情绪</h1><p id="5524" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">与我们处理图像以提取情感相似，在这一部分，我们将处理视频。</p><blockquote class="mt"><p id="f66d" class="mu mv it bd mw mx my mz na nb nc lu dk translated">理论上，视频是运动中连续图像帧的组合。</p></blockquote><p id="04bf" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">所以本质上，任何算法对视频和图像的作用都是一样的。处理视频的唯一附加步骤是将视频分割成所有单独的帧，然后对其应用图像处理算法。</p><p id="972c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">逻辑流程:</strong>虽然图像和视频的底层算法是相似的，但对于视频，我们将遵循一些关键的变化。</p><ol class=""><li id="feab" class="ol om it lb b lc ld lf lg li on lm oo lq op lu oq or os ot bi translated">Video_analyze():这个函数负责从视频中提取单个图像帧，然后独立地分析它们。</li><li id="d7f2" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated">该函数分析的每一帧都由算法作为单独的图像存储在代码运行的根目录文件夹中。此外，该功能稍后会通过在脸部周围放置一个框来创建原始视频的副本，并显示视频中的实时情绪。</li><li id="4d3c" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated">然后，我们根据这些分析值创建一个Pandas数据帧，并使用matplotlib绘制该数据帧。在这个情节中，我们可以看到每一种情绪对时间的策划。</li><li id="76b8" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated">我们可以进一步分析这个数据帧，方法是获取模型识别的个人情绪值，并找出在整个视频中占主导地位的情绪。</li></ol><p id="2539" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这样，我们可以通过提取单个图像帧并分析它们来处理视频。下图显示了这个过程，显示了如何添加一个额外的步骤来处理视频。我们将在下一节看到这个实现。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pv"><img src="../Images/1838006df90e38af8dc3dc420284a15b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sw5HvtLvXQJyGs8Ukh0iTQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">将一个额外的步骤集成到图像处理算法中，并将其扩展到视频|作者图片</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pa pb l"/></div></figure><h2 id="698c" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">输出</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pw"><img src="../Images/be1feae9fa02ea1f34da74d6d7485191.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u3kUR-2TM_Ip5T6uJq0J7g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">整个视频长度中的情绪序列被绘制在图形上|代码输出的一部分，图片由作者提供</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi px"><img src="../Images/62eb63bab584b8178beb82894b01e868.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*hz5G8w4-Aj3rDyxB24rEXg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">最终情感强度|作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi py"><img src="../Images/83d07c3e0bd51816eaabf5551461ab41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XRWqSPTBqOdelUC9PblPMg@2x.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">视频处理代码生成的实时输出|图片由作者提供</p></figure><p id="a0a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由此，我们总结了图像和视频的分析以执行情感识别。我们能够成功地处理人脸，并理解面部表情所表达的情感。</p><h2 id="b0e9" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">完整的代码库(视频输入)</h2><div class="pd pe gp gr pf pg"><a href="https://github.com/rjrahul24/ai-with-python-series/tree/main/07.%20Emotion%20Recognition%20using%20Live%20Video" rel="noopener  ugc nofollow" target="_blank"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd iu gy z fp pl fr fs pm fu fw is bi translated">人工智能与python系列/07。使用实时视频的情感识别</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">Python for AI —教程—实时视频输入中的情感识别</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">github.com</p></div></div><div class="pp l"><div class="pz l pr ps pt pp pu ks pg"/></div></div></a></div><p id="13a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与处理图像的示例类似，上面的代码片段显示了一个工作逻辑。然而，我鼓励你仔细阅读Colab笔记本中的完整工作代码以及上面链接的库。</p><h1 id="7faf" class="ni lw it bd lx nj nk nl ma nm nn no md jz np ka mg kc nq kd mj kf nr kg mm ns bi translated">结论</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qa"><img src="../Images/1c87f16dea75b91876a3125383097ddf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*w1yVANegnX7ROq6Z"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">面部表情|图片由<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ky" href="https://unsplash.com/@tengyart?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Tengyart </a>拍摄</p></figure><p id="cc98" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在当今世界，情感分析和人脸检测各自都有大量的使用案例。我们在公共停车场、交通监控系统、等地方看到<strong class="lb iu">物体检测算法。拍摄人们驾驶车辆的图像来保存记录。此外，在治疗师和他们的病人不可能进行身体接触的治疗中，还使用情感分析。对人类认知的研究也促进了医学的发展。</strong>在技术前沿，虚拟助理、档案评估助理和自动化机器人被构建来模仿人类的行为，并以增加准确性和减少错误的希望取代它们。因此，它是我们今天生活的人工智能启发的世界中非常重要的一部分。一种更引人入胜、更复杂的计算机视觉方法是使用基于云的算法，如Azure认知服务或深度学习机制，我们在本文中没有涉及，但在复杂的场景中可能会派上用场。通过这个故事，我们了解了以下情况:</p><ul class=""><li id="9b55" class="ol om it lb b lc ld lf lg li on lm oo lq op lu qb or os ot bi translated">认知科学是对人类思维过程的研究，旨在通过算法将人类的反应和情绪传递给机器。</li><li id="528e" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu qb or os ot bi translated">计算机视觉是人工智能的一个分支，专注于通过处理图像形式的人类数据，在现实世界中实现认知科学。</li><li id="90fd" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu qb or os ot bi translated">图像处理是所有计算机视觉算法的一部分，它帮助算法理解图像，处理图像，将图像作为数字向量进行处理，并执行必要的操作。</li></ul><p id="7cd4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们使用人工智能的力量来研究认知科学和处理人脸，这个空间通常被称为<strong class="lb iu"> <em class="nw">计算机视觉。</em> </strong>我们能够从人脸的照片和视频中提取情感。</p></div><div class="ab cl qc qd hx qe" role="separator"><span class="qf bw bk qg qh qi"/><span class="qf bw bk qg qh qi"/><span class="qf bw bk qg qh"/></div><div class="im in io ip iq"><h2 id="44a5" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">阅读大量关于机器学习的循序渐进教程</h2><div class="pd pe gp gr pf pg"><a rel="noopener follow" target="_blank" href="/implementing-an-end-to-end-machine-learning-workflow-with-azure-data-factory-f16cbeeffd94"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd iu gy z fp pl fr fs pm fu fw is bi translated">使用Azure Data Factory实现端到端的机器学习工作流</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">使用微软的Azure数据工厂(ADF)在一个屏幕上构建完整的MLOps生命周期</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">towardsdatascience.com</p></div></div><div class="pp l"><div class="qj l pr ps pt pp pu ks pg"/></div></div></a></div><div class="pd pe gp gr pf pg"><a rel="noopener follow" target="_blank" href="/a-step-by-step-guide-to-speech-recognition-and-audio-signal-processing-in-python-136e37236c24"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd iu gy z fp pl fr fs pm fu fw is bi translated">Python中语音识别和音频信号处理的分步指南</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">向机器教授人类词汇的科学</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">towardsdatascience.com</p></div></div><div class="pp l"><div class="qk l pr ps pt pp pu ks pg"/></div></div></a></div><div class="pd pe gp gr pf pg"><a rel="noopener follow" target="_blank" href="/logic-programming-and-the-design-of-humanistic-ai-using-python-6ddb7019caa2"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd iu gy z fp pl fr fs pm fu fw is bi translated">逻辑程序设计和基于Python的人性化人工智能设计</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">建立逻辑，促进机器中的人工智能</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">towardsdatascience.com</p></div></div><div class="pp l"><div class="ql l pr ps pt pp pu ks pg"/></div></div></a></div></div><div class="ab cl qc qd hx qe" role="separator"><span class="qf bw bk qg qh qi"/><span class="qf bw bk qg qh qi"/><span class="qf bw bk qg qh"/></div><div class="im in io ip iq"><h2 id="7cdb" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">关于我</h2><p id="0165" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我是Rahul，目前在研究人工智能，在Xbox游戏上实现大数据分析。我在微软工作。除了专业工作之外，我还试图制定一个程序，来理解如何通过使用人工智能来改善世界上发展中国家的经济状况。</p><p id="0942" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在纽约的哥伦比亚大学，你可以在<a class="ae ky" href="https://www.linkedin.com/in/rjrahul24/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和<a class="ae ky" href="https://twitter.com/rjrahul24" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上与我联系。</p></div><div class="ab cl qc qd hx qe" role="separator"><span class="qf bw bk qg qh qi"/><span class="qf bw bk qg qh qi"/><span class="qf bw bk qg qh"/></div><div class="im in io ip iq"><h2 id="df10" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">参考</h2><ol class=""><li id="b1c2" class="ol om it lb b lc mo lf mp li qm lm qn lq qo lu oq or os ot bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Digital_image_processing" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Digital_image_processing</a></li><li id="9f9c" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated"><a class="ae ky" href="https://sisu.ut.ee/imageprocessing/book/1" rel="noopener ugc nofollow" target="_blank">https://sisu.ut.ee/imageprocessing/book/1</a></li><li id="765a" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Video_processing" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Video_processing</a></li><li id="a21b" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated"><a class="ae ky" href="https://www.sciencedirect.com/topics/computer-science/video-processing" rel="noopener ugc nofollow" target="_blank">https://www . science direct . com/topics/computer-science/video-processing</a></li><li id="7e82" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated"><a class="ae ky" href="https://cognitiveclass.ai/courses/python-for-data-science" rel="noopener ugc nofollow" target="_blank">https://cognitiveclass.ai/courses/python-for-data-science</a></li><li id="cd6c" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated"><a class="ae ky" href="https://www.geeksforgeeks.org/python-process-images-of-a-video-using-opencv/" rel="noopener ugc nofollow" target="_blank">https://www . geeks forgeeks . org/python-process-images-of-a-video-using-opencv/</a></li><li id="ba82" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated">https://towards data science . com/face-detection-recognition-and-emotion-detection-in-8-line of-code-b2ce 32d 4d de</li><li id="0f9d" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated"><a class="ae ky" href="https://www.frontiersin.org/articles/10.3389/fnhum.2021.621493/full" rel="noopener ugc nofollow" target="_blank">https://www . frontier sin . org/articles/10.3389/fnhum . 2021.621493/full</a></li><li id="26e2" class="ol om it lb b lc ou lf ov li ow lm ox lq oy lu oq or os ot bi translated"><a class="ae ky" href="https://analyticsindiamag.com/face-emotion-recognizer-in-6-lines-of-code/" rel="noopener ugc nofollow" target="_blank">https://analyticsindiamag . com/face-emotion-recognizer-in-6-line-of-code/</a></li></ol></div></div>    
</body>
</html>