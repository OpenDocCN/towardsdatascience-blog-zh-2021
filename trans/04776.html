<html>
<head>
<title>5 Deep Learning Trends Leading Artificial Intelligence to the Next Stage</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">引领人工智能进入下一阶段的5个深度学习趋势</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-deep-learning-trends-leading-artificial-intelligence-to-the-next-stage-11f2ef60f97e?source=collection_archive---------1-----------------------#2021-04-26">https://towardsdatascience.com/5-deep-learning-trends-leading-artificial-intelligence-to-the-next-stage-11f2ef60f97e?source=collection_archive---------1-----------------------#2021-04-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="9b15" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">人工智能|深度学习|未来</h2><div class=""/><div class=""><h2 id="b80b" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">深度学习主导了人工智能，但它需要更新以保持其霸权，并推动该领域向前发展。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/6c9b20007ce9137e1a3bb8f6cdb669b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JS7GSMaxQmrbZtF5hGIoCA.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">来源:<a class="ae lh" href="https://unsplash.com/photos/-HSvETdLVbk" rel="noopener ugc nofollow" target="_blank">顾</a>在Unsplash</p></figure><p id="fd56" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">人类是发明家的一种。世界提供给我们原材料，我们用熟练的工艺将它们转化。技术创造了无数的工具和设备:轮子、印刷机、蒸汽机、汽车、电力、互联网……这些发明已经并仍在塑造着我们的文明和文化。</p><p id="599b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们最新的技术孩子之一是人工智能，这是一种近年来与我们的生活交织在一起的工具。它对我们社会的影响是显著的，预计在未来的几十年里<a class="ae lh" href="https://news.usc.edu/trojan-family/five-ways-ai-will-change-the-world-by-2050/" rel="noopener ugc nofollow" target="_blank">会继续增长。人工智能的领军人物之一吴恩达甚至说“</a><a class="ae lh" href="https://www.wipo.int/wipo_magazine/en/2019/03/article_0001.html" rel="noopener ugc nofollow" target="_blank">人工智能是新的电力</a>”在斯坦福商业的采访中，他说“就像100年前电力改变了几乎一切一样，今天我实际上很难想象一个我认为人工智能在未来几年内不会改变的行业。”</p><p id="8e90" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但人工智能并不新鲜。它存在于1956年，当时约翰·麦卡锡创造了术语，并提出人工智能是一个独立的研究领域。从那以后，它经历了<a class="ae lh" href="https://en.wikipedia.org/wiki/AI_winter" rel="noopener ugc nofollow" target="_blank">完全漠不关心</a>和<a class="ae lh" href="https://www.privateequitywire.co.uk/2020/11/19/292458/ai-startups-raised-usd734bn-total-funding-2020" rel="noopener ugc nofollow" target="_blank">源源不断的资金和利息</a>的交替时期。今天，机器学习和深度学习(DL)垄断了AI。2012年开始的DL革命还没有结束。DL戴上了人工智能的桂冠，但专家们认为它需要一些改变来保持它。让我们看看DL的未来。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="36cf" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">摆脱卷积神经网络</h1><p id="17ca" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">在“人工智能教父”杰弗里·辛顿(Geoffrey Hinton)和他的团队凭借<a class="ae lh" href="https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf" rel="noopener ugc nofollow" target="_blank">一个基于卷积神经网络(CNN)</a>的模型赢得2012年ImageNet挑战赛之后，DL的人气飙升。他们以+10%的误差率击败了他们的(非DL)对手，达到了63.30%的最高准确率。我们可以说，在过去的十年中，数字图书馆引起了CNN的成功和兴趣，这是我们的功劳。</p><p id="5bf2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">基于CNN的模型在计算机视觉任务中非常受欢迎，如<a class="ae lh" href="https://arxiv.org/abs/2003.10580v4" rel="noopener ugc nofollow" target="_blank">分类图像</a>、<a class="ae lh" href="https://viso.ai/deep-learning/object-detection/" rel="noopener ugc nofollow" target="_blank">检测物体</a>，或<a class="ae lh" href="https://www.thalesgroup.com/en/markets/digital-identity-and-security/government/biometrics/facial-recognition" rel="noopener ugc nofollow" target="_blank">识别人脸</a>。然而，尽管它们很有用，但辛顿在他的<a class="ae lh" href="https://www.youtube.com/watch?v=UX8OubxsY8w" rel="noopener ugc nofollow" target="_blank"> AAAI 2020主题演讲</a>中强调了一个重要的缺点:“【CNN】不太擅长处理旋转和缩放等视角变化的[…]影响。”</p><p id="6389" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">CNN可以处理翻译，但人类的视觉系统也可以识别不同视角、背景或光照条件下的物体，这是CNN做不到的。当今天的顶级CNN系统——在ImageNet基准测试中获得了+90%的顶级准确性(——尝试在真实世界的对象数据集中对图像进行分类时，它们会经历40 %- 45%的性能下降(<a class="ae lh" href="https://objectnet.dev/objectnet-a-large-scale-bias-controlled-dataset-for-pushing-the-limits-of-object-recognition-models.pdf" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="def0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">另一个问题是所谓的<a class="ae lh" href="https://arxiv.org/abs/1312.6199" rel="noopener ugc nofollow" target="_blank">反面例子</a>。辛顿再次强调了人类视觉系统和CNN之间的差异:“我可以拍摄一张图像和一点点噪声，CNN会将其识别为完全不同的东西，我几乎看不出它发生了变化。[……]我认为这证明CNN实际上在使用与我们非常不同的信息来识别图像。”CNN从根本上不同于人类的视觉系统。由于它们的不可预测性，我们根本不能依赖它们。</p><p id="5101" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Hinton更进一步解释说，CNN系统不能解释他们在图像中看到的物体。我们知道物体存在于世界中，我们对它们有经验。从很小的时候起，我们就知道了坚固性、形状恒常性或物体的持久性。我们可以利用这些知识来理解奇怪的物体，但CNN只能看到一堆像素。我们可能需要从根本上改变计算机视觉的统治模式，也许是朝着<a class="ae lh" href="https://arxiv.org/abs/1710.09829" rel="noopener ugc nofollow" target="_blank">胶囊网络</a>的方向。套用量子力学之父马克斯·普朗克的话:</p><blockquote class="nj"><p id="dcc4" class="nk nl it bd nm nn no np nq nr ns md dk translated">“科学一次进步一个葬礼。”</p></blockquote></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="805c" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">自我监督的深度学习</h1><blockquote class="nj"><p id="6e46" class="nk nl it bd nm nn no np nq nr ns md dk translated">"人工智能的下一场革命将不会受到监督，也不会得到纯粹的强化."</p><p id="3fe4" class="nk nl it bd nm nn no np nq nr ns md dk translated">——脸书大学首席人工智能科学家Yann LeCun</p></blockquote><p id="5ca5" class="pw-post-body-paragraph li lj it lk b ll nt kd ln lo nu kg lq lr nv lt lu lv nw lx ly lz nx mb mc md im bi translated">今天的DL的一个明显的限制是它对大量标记数据和计算能力的依赖。另一位人工智能先驱Yann LeCun说，我们需要用他所谓的<a class="ae lh" href="https://bdtechtalks.com/2020/03/23/yann-lecun-self-supervised-learning/" rel="noopener ugc nofollow" target="_blank">自我监督学习</a>来取代监督学习——这是大多数人工智能系统的训练方法:</p><blockquote class="ny nz oa"><p id="5a46" class="li lj me lk b ll lm kd ln lo lp kg lq ob ls lt lu oc lw lx ly od ma mb mc md im bi translated">"<em class="it">【自我监督学习】</em>是在学习一个任务之前，先学习代表世界的思想。这是婴儿和动物的行为。一旦我们对世界有了好的描述，学习一项任务就需要很少的试验和样本。”</p></blockquote><p id="951a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">系统将从原始数据中学习来标记它，而不是用标记的数据来训练系统。我们人类学习的速度比监督(或强化)系统快几个数量级。孩子们不会通过看成百上千张树的照片来学会辨认一棵树。他们看到一个，然后把“树”这个标签放在他们直觉上知道属于这个类别的所有东西上。我们部分是通过观察来学习的，这是计算机目前还做不到的。</p><p id="0bf7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Yann LeCun在2019年12月就该话题对<a class="ae lh" href="https://www.youtube.com/watch?v=A7AnCvYDQrU&amp;t=45s" rel="noopener ugc nofollow" target="_blank">进行了深度访谈</a>。他认为，自我监督系统将能够“从任何其他部分预测输入的任何部分。”例如，它可以从过去预测未来，或者从可见的事物中预测不可见的事物。然而，尽管这种类型的学习对离散输入很有效，如文本(<a class="ae lh" href="https://venturebeat.com/2018/11/02/google-open-sources-bert-a-state-of-the-art-training-technique-for-natural-language-processing/" rel="noopener ugc nofollow" target="_blank">谷歌的BERT </a>或<a class="ae lh" href="https://arxiv.org/abs/2005.14165" rel="noopener ugc nofollow" target="_blank"> OpenAI的GPT-3 </a>)，但对连续数据如图像、音频或视频则不太有效。为此，他解释说，我们将需要<a class="ae lh" href="https://openai.com/blog/energy-based-models/" rel="noopener ugc nofollow" target="_blank">潜在的基于可变能源的模型</a>，这种模型更适合处理世界固有的不确定性。</p><p id="75cc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">自我监督学习将取代监督学习。未来仍有一些挑战，但我们已经在搭建弥合差距的桥梁。可以肯定的是，一旦到了彼岸，就不会回头。</p><blockquote class="nj"><p id="1b46" class="nk nl it bd nm nn no np nq nr ns md dk translated">"标签是机器学习研究者的鸦片."</p><p id="bd28" class="nk nl it bd nm nn no np nq nr ns md dk translated">—吉坦德拉·马利克，加州大学伯克利分校EECS教授</p></blockquote></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="db39" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">混合模型:符号AI +深度学习</h1><p id="d081" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">自从人工智能的概念提出以来，有两种范式在人工智能中受到了空前的欢迎:符号人工智能(也称为基于规则的人工智能)和DL。从50年代到80年代，象征性人工智能主导了这个领域，但今天大多数专家反对这个框架。约翰·豪格兰德在他的书《人工智能:非常理念》中称之为GOFAI(优秀的老式人工智能)。</p><blockquote class="ny nz oa"><p id="85ab" class="li lj me lk b ll lm kd ln lo lp kg lq ob ls lt lu oc lw lx ly od ma mb mc md im bi translated"><em class="it">【符号人工智能】</em>处理现实世界的抽象表现，这些表现是用主要基于数理逻辑的表现性语言建模的</p></blockquote><p id="e8a8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是一种自上而下的人工智能方法。它旨在通过使用“问题的高级符号表示”来赋予机器智能，遵循由艾伦·纽厄尔和司马贺提出的物理符号系统假设。例如，<a class="ae lh" href="https://www.osti.gov/biblio/5675197" rel="noopener ugc nofollow" target="_blank">专家系统</a>——最受欢迎的符号人工智能形式——被设计成通过遵循一套如果-那么规则来模拟人类决策。</p><p id="16fc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">混合模型是结合符号AI和DL优点的一种尝试。马丁·福特在他的《智能建筑师<a class="ae lh" href="https://bookshop.org/books/architects-of-intelligence-the-truth-about-ai-from-the-people-building-it/9781789131512?aid=11092" rel="noopener ugc nofollow" target="_blank"><em class="me"/></a>一书中，就这种方法采访了人工智能专家。吴恩达强调了它在解决我们只有小数据集的问题时的有用性。麻省理工学院计算认知科学教授乔希·特南鲍姆(Josh Tenenbaum)和他的团队开发了一种混合模型<a class="ae lh" href="https://openreview.net/forum?id=rJgMlhRctm" rel="noopener ugc nofollow" target="_blank">“在没有任何明确监督的情况下，学习视觉概念、单词和句子的语义解析。”</a></p><p id="cc66" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">纽约大学心理学教授加里·马库斯认为，混合模型可以更好地处理常识推理。<a class="ae lh" href="https://arxiv.org/ftp/arxiv/papers/2002/2002.06177.pdf" rel="noopener ugc nofollow" target="_blank">在最近的一篇论文</a>中，马库斯通过提及人类智力来强调他的观点:</p><blockquote class="ny nz oa"><p id="9b63" class="li lj me lk b ll lm kd ln lo lp kg lq ob ls lt lu oc lw lx ly od ma mb mc md im bi translated">“某种形式的符号操作似乎对人类的认知至关重要，比如当一个孩子知道“姐妹”这个词的含义时，这个词可以应用在无数个家庭中。”</p></blockquote><p id="66cd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">尽管前景看好，混合方法也有重要的批评者。杰弗里·辛顿(Geoffrey Hinton)批评了那些打算用象征性人工智能宠坏DL的人。“他们不得不承认深度学习正在做令人惊讶的事情，他们希望将深度学习作为一种低级仆人，为他们提供让他们的符号推理工作所需的东西，”他说。不管它是否奏效，混合动力车型都是未来几年需要关注的事情。</p><blockquote class="nj"><p id="5153" class="nk nl it bd nm nn no np nq nr ns md dk translated">“我预测，几年之内，许多人会想知道，为什么深度学习这么长时间以来一直试图在没有符号操纵工具的情况下做到这一点。”</p><p id="2a7e" class="nk nl it bd nm nn no np nq nr ns md dk translated">—加里·马库斯</p></blockquote></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="a8a3" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">系统2深度学习</h1><p id="d638" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">完成<a class="ae lh" href="https://awards.acm.org/about/2018-turing" rel="noopener ugc nofollow" target="_blank"> 2018图灵奖获奖者三重奏</a>的Yoshua Bengio(与Hinton和LeCun一起)在2019年发表了题为<a class="ae lh" href="https://www.youtube.com/watch?v=T3sxeTgT4qc" rel="noopener ugc nofollow" target="_blank"> <em class="me">的演讲，从系统1深度学习到系统2深度学习</em> </a>。他谈到了DL的现状，其中的趋势是让一切变得更大:更大的数据集、更大的计算机和更大的神经网络。他认为，我们不会在这个方向上进入人工智能的下一个阶段。</p><blockquote class="ny nz oa"><p id="e6fa" class="li lj me lk b ll lm kd ln lo lp kg lq ob ls lt lu oc lw lx ly od ma mb mc md im bi translated">“我们有以非常狭窄的方式学习的机器。他们需要比人类智能例子多得多的数据来学习任务<em class="it"/>仍然会犯愚蠢的错误。”</p></blockquote><p id="6ad0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">本吉奥从丹尼尔·卡内曼在其里程碑式的著作<a class="ae lh" href="https://bookshop.org/books/thinking-fast-and-slow/9780374533557" rel="noopener ugc nofollow" target="_blank"> <em class="me">《思考，快与慢</em> </a>》中的洞见中汲取了双系统框架。卡尼曼将系统1描述为“自动且快速地运行，很少或没有努力，也没有自愿控制的感觉”，而系统2“将注意力分配给需要它的费力的精神活动[……]通常与代理、选择和集中的主观体验有关。”</p><p id="d253" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://www.forbes.com/sites/robtoews/2020/10/29/the-next-generation-of-artificial-intelligence-part-2/?sh=687177627a30" rel="noopener ugc nofollow" target="_blank"> Rob Toews </a>总结了DL的现状:“今天的尖端人工智能系统擅长系统1的任务，但与系统2的任务斗争激烈。”本吉奥同意。“我们(人类)想出算法、配方，我们可以计划、推理、使用逻辑，”他说，“通常，如果你与计算机解决这些问题相比，这些事情非常慢。这些也是我们希望未来深度学习做的事情。”</p><p id="c24a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Bengio <a class="ae lh" href="https://bdtechtalks.com/2019/12/23/yoshua-bengio-neurips-2019-deep-learning/" rel="noopener ugc nofollow" target="_blank">认为</a>系统2 DL将能够归纳为“不同的数据分布”，这被称为<a class="ae lh" href="https://ai.googleblog.com/2019/12/improving-out-of-distribution-detection.html" rel="noopener ugc nofollow" target="_blank">无序分布</a>。目前，DL系统需要在具有相同分布的数据集中进行训练和测试，这响应了<a class="ae lh" href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables" rel="noopener ugc nofollow" target="_blank">独立同分布数据</a>的假设。“我们需要能够应对这些变化并不断学习的系统。”使用非统一的真实世界数据，系统2 DL将会成功。</p><p id="2cb3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为此，我们需要具备更好的迁移学习能力的系统。本吉奥<a class="ae lh" href="http://www.iro.umontreal.ca/~bengioy/AAAI-9feb2020.pdf" rel="noopener ugc nofollow" target="_blank">认为</a>注意力机制和元学习——学会学习——是系统2认知的基本组成部分。这里有一段引言，<a class="ae lh" href="https://quoteinvestigator.com/2014/05/04/adapt/" rel="noopener ugc nofollow" target="_blank">经常被误认为是达尔文的作品，</a>概括了达尔文关于物种起源的名著<em class="me">的中心思想，并强调了在不断变化的世界中学会适应的重要性:</em></p><blockquote class="nj"><p id="d58d" class="nk nl it bd nm nn no np nq nr ns md dk translated">“幸存下来的不是最强壮的物种，也不是最聪明的物种，而是最能适应变化的物种。”</p></blockquote></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="a9f2" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">基于神经科学的深度学习</h1><blockquote class="nj"><p id="8830" class="nk nl it bd nm nn no np nq nr ns md dk translated">"人工神经网络只是大脑工作方式的粗略类比."</p><p id="5634" class="nk nl it bd nm nn no np nq nr ns md dk translated">—大卫·苏西洛，谷歌大脑小组</p></blockquote><p id="5b04" class="pw-post-body-paragraph li lj it lk b ll nt kd ln lo nu kg lq lr nv lt lu lv nw lx ly lz nx mb mc md im bi translated">在1950年的十年里，几项重要的科学突破为人工智能的诞生奠定了基础。神经学研究发现，大脑是由“要么全有要么全无脉冲”的神经网络组成的。这一发现，连同来自<a class="ae lh" href="https://mitpress.mit.edu/books/cybernetics-second-edition" rel="noopener ugc nofollow" target="_blank">控制论</a>、<a class="ae lh" href="https://pure.mpg.de/rest/items/item_2383162_7/component/file_2456978/content" rel="noopener ugc nofollow" target="_blank">信息论</a>和<a class="ae lh" href="https://londmathsoc.onlinelibrary.wiley.com/doi/abs/10.1112/plms/s2-42.1.230" rel="noopener ugc nofollow" target="_blank">艾伦·图灵的计算理论</a>的理论描述，暗示了创造人工大脑的可能性。</p><p id="85e4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">人工智能起源于人脑，但今天的DL <a class="ae lh" href="https://verzeo.com/blog-artificial-neural-network-vs-human-brain" rel="noopener ugc nofollow" target="_blank">并不像它那样工作</a>。我已经巧妙地提到了DL系统和人脑之间的一些差异。CNN不像我们的视觉系统那样工作。我们观察这个世界，而不是从标记的数据中学习。我们将自底向上的处理与自顶向下的符号操作结合起来。我们进行系统2认知。人工智能的最终目的是建立一个可以模拟我们的电子大脑，一个人工通用智能(有人称之为<a class="ae lh" href="https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/minds-brains-and-programs/DC644B47A4299C637C89772FACC2706A" rel="noopener ugc nofollow" target="_blank">强人工智能</a>)。神经科学可以帮助DL向这个目标迈进。</p><p id="2530" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一个重要的方法是神经形态计算，这是指模拟大脑结构的硬件。正如我在上一篇文章中写的<a class="ae lh" rel="noopener" target="_blank" href="/5-reasons-why-i-left-the-ai-industry-2c88ea183cdd">，“生物和人工神经网络之间有很大的区别:大脑中的神经元以尖峰脉冲的时间和频率携带信息，而信号的强度(电压)是恒定的。人工神经元则完全相反。它们携带的信息只是输入的强度，而不是时间或频率。”神经形态计算正试图减少这些差异。</a></p><p id="2914" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">人工神经元的另一个缺点是简单。它们是假设生物神经元是“<a class="ae lh" href="https://bdtechtalks.com/2020/01/20/neuroscience-artificial-intelligence-synergies/" rel="noopener ugc nofollow" target="_blank">基础数学</a>的哑计算器”而构建的然而，这与事实相去甚远。在<a class="ae lh" href="https://science.sciencemag.org/content/367/6473/83" rel="noopener ugc nofollow" target="_blank">发表在<em class="me">科学</em>上的一项研究</a>中，一组德国研究人员表明“单个神经元可能能够计算真正复杂的功能。例如，它本身可能能够识别一个物体。”</p><blockquote class="nj"><p id="1b9c" class="nk nl it bd nm nn no np nq nr ns md dk translated">"也许你在单个神经元(大脑)中有一个很深的网络."</p><p id="80e3" class="nk nl it bd nm nn no np nq nr ns md dk translated">IMBB的约塔·波伊拉齐</p></blockquote><p id="9356" class="pw-post-body-paragraph li lj it lk b ll nt kd ln lo nu kg lq lr nv lt lu lv nw lx ly lz nx mb mc md im bi translated">DeepMind首席执行官兼联合创始人戴密斯·哈萨比斯在发表于<em class="me"> Neuron </em> 的论文中表达了<a class="ae lh" href="https://www.cell.com/neuron/fulltext/S0896-6273(17)30509-3?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0896627317305093%3Fshowall%3Dtrue" rel="noopener ugc nofollow" target="_blank">利用神经科学推动AI前进的重要性。除了我已经讨论过的一些想法之外，有两个关键方面很突出:直觉物理学和规划。</a></p><p id="6e9d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(17)30126-2" rel="noopener ugc nofollow" target="_blank"> James R. Kubricht和他的同事</a>将直觉物理学定义为“人类理解物理环境并与经历动态变化的物体和物质相互作用的能力的基础知识，至少对观察到的事件将如何展开做出近似预测。”DL系统做不到这一点。他们不在这个世界上，他们没有具体化，他们缺乏进化的包袱，这让我们有优势在周围导航。乔希·特南鲍姆正致力于将这种能力灌输给机器。</p><p id="c4b8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://thegradient.pub/when-ai-plans-ahead/" rel="noopener ugc nofollow" target="_blank">规划</a>可以理解为“决定需要采取什么行动来实现既定目标的探索。”我们每天都在这样做，然而，对于机器来说，现实世界太复杂了。<a class="ae lh" href="https://deepmind.com/blog/article/muzero-mastering-go-chess-shogi-and-atari-without-rules" rel="noopener ugc nofollow" target="_blank"> DeepMind的MuZero </a>可以通过规划玩几款世界级水平的游戏，但这些游戏都有完美定义的规则和边界。</p><p id="c4a4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://web.archive.org/web/20190717071152/https://www.talkyblog.com/artificial_general_intelligence_agi/#The_Coffee_Test" rel="noopener ugc nofollow" target="_blank">著名的咖啡测试</a>提出，一个具有规划能力的AI应该能够进入一个普通的房子，进入厨房，获取配料并制作咖啡。计划要求我们将复杂的任务分解成子任务，但是这种能力超出了今天DL系统所能做到的。Yann LeCun承认“我们不知道该怎么做。”</p><p id="92f1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">DL可以从神经科学中汲取很多理念。如果我们想更接近智慧，为什么不看看我们唯一的例子呢？正如戴密斯·哈萨比斯所说，</p><blockquote class="nj"><p id="6b61" class="nk nl it bd nm nn no np nq nr ns md dk translated">“有这么多的利害关系，神经科学和人工智能领域走到一起的需求现在比以往任何时候都更加迫切。”</p></blockquote></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h1 id="5551" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">结论</h1><p id="2217" class="pw-post-body-paragraph li lj it lk b ll ne kd ln lo nf kg lq lr ng lt lu lv nh lx ly lz ni mb mc md im bi translated">DL系统非常有用。在过去的几年里，他们单枪匹马地改变了技术领域。然而，如果我们想要创造真正智能的机器，DL将需要一个质的更新——拒绝越大越好的观念。</p><p id="76b4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">今天有几种方法可以实现这一里程碑:摆脱CNN及其局限性，摆脱带标签的数据，将自下而上与自上而下的处理结合起来，向机器灌输系统2认知，并从神经科学和人类大脑中汲取思想和进步。</p><p id="8754" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们不知道实现真正智能系统的最佳途径是什么。用Yann LeCun的话说，“没有人有一个完全好的答案”然而，我希望我们最终会到达那里。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="ea90" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">推荐阅读</strong></p><div class="oe of gp gr og oh"><a rel="noopener follow" target="_blank" href="/5-reasons-why-i-left-the-ai-industry-2c88ea183cdd"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd jd gy z fp om fr fs on fu fw jc bi translated">我离开人工智能行业的5个原因</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">我在一家人工智能公司工作了3年。现在我决定无限期地离开这个行业。</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">towardsdatascience.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov lb oh"/></div></div></a></div></div></div>    
</body>
</html>