<html>
<head>
<title>SMAC: AutoML for fast Hyperparameters tuning in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SMAC:Python中快速超参数调优的AutoML</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automl-for-fast-hyperparameters-tuning-with-smac-4d70b1399ce6?source=collection_archive---------19-----------------------#2021-05-16">https://towardsdatascience.com/automl-for-fast-hyperparameters-tuning-with-smac-4d70b1399ce6?source=collection_archive---------19-----------------------#2021-05-16</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><div class=""/><div class=""><h2 id="3fe0" class="pw-subtitle-paragraph js iu iv bd b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj dk translated">在高维空间中寻找出路</h2></div><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi kk"><img src="../Images/0b933747e9074fd65b86183a4c3b0177.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fscVA5uQNkV-95Cl"/></div></div><p class="kw kx gj gh gi ky kz bd b be z dk translated"><a class="ae la" href="https://unsplash.com/@yukkien?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">蓝莓制作</a>在<a class="ae la" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="0b06" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">为给定的数据科学问题生成第一个模型可能非常简单。建立一个高效的模型，提供高水平的精确度，要困难得多。数据科学家必须清理数据，提炼特征，找到正确的指标，找到正确的验证策略，正确地构建测试和训练集，并微调所选模型的参数。</p><p id="8b95" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">这些步骤大多受益于数据科学家的经验，很难自动化。幸运的是，超参数调优不是这样的，可以使用自动机器学习:AutoML。</p><p id="5bcb" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">在本帖中，我们将从数学上解释为什么超参数调整是一项复杂的任务，并展示SMAC如何帮助建立更好的模型。</p><h1 id="20e0" class="lx ly iv bd lz ma mb mc md me mf mg mh kb mi kc mj ke mk kf ml kh mm ki mn mo bi translated">超参数？你在说什么？</h1><p id="e78c" class="pw-post-body-paragraph lb lc iv ld b le mp jw lg lh mq jz lj lk mr lm ln lo ms lq lr ls mt lu lv lw io bi translated">当尝试为给定数据集拟合模型时，必须定义两种参数:</p><ul class=""><li id="1630" class="mu mv iv ld b le lf lh li lk mw lo mx ls my lw mz na nb nc bi translated">用于配置模型的参数:决策树的深度、SVM模型的内核、多项式的次数、神经网络的层数等等</li><li id="aa85" class="mu mv iv ld b le nd lh ne lk nf lo ng ls nh lw mz na nb nc bi translated">模型本身的参数:决策树叶子的权重，SVM核的参数，多项式的系数，每个神经元的权重，…</li></ul><p id="be75" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">第一类参数被称为模型超参数，因为它们定义了模型的结构，而后者被附加到模型本身。</p><h1 id="bac4" class="lx ly iv bd lz ma mb mc md me mf mg mh kb mi kc mj ke mk kf ml kh mm ki mn mo bi translated">为什么需要AutoML进行超参数调整？</h1><p id="7764" class="pw-post-body-paragraph lb lc iv ld b le mp jw lg lh mq jz lj lk mr lm ln lo ms lq lr ls mt lu lv lw io bi translated">请记住，超参数调整，有时也称为超参数优化(HPO)，是一个通过根据您选择的指标确定模型的最佳配置来尝试充分利用模型的过程。</p><p id="9504" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">使用AutoML主要有两个原因:</p><ol class=""><li id="0baa" class="mu mv iv ld b le lf lh li lk mw lo mx ls my lw ni na nb nc bi translated">手动寻找最佳参数是一项非常繁琐的任务。配置空间的组合学可能相当大。对于随机森林，需要考虑的参数不少于10个。每个参数可以有10个不同的值。因此，探索配置空间需要评估10种⁰配置！</li><li id="ce34" class="mu mv iv ld b le nd lh ne lk nf lo ng ls nh lw ni na nb nc bi translated">绝对不能保证针对给定数据集优化的配置在另一个数据集上也同样有效。每次将模型应用到新的数据集时，优化超参数至关重要。</li></ol><p id="bdcd" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">使用AutoML技术允许通过自动化配置空间探索来解决这两个限制。</p><h1 id="8148" class="lx ly iv bd lz ma mb mc md me mf mg mh kb mi kc mj ke mk kf ml kh mm ki mn mo bi translated">用AutoML调整超参数:一项艰巨的任务</h1><p id="cfcf" class="pw-post-body-paragraph lb lc iv ld b le mp jw lg lh mq jz lj lk mr lm ln lo ms lq lr ls mt lu lv lw io bi translated">在进一步向您展示如何高效地自动调优超参数之前，让我们解释一下为什么这是一项复杂的任务。</p><p id="38b5" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">让我们用一些数学来形式化什么是超参数优化。</p><p id="cc79" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">从数学上来说，HPO试图最小化一个或多个测试集上的评估指标，通常使用交叉验证来生成。这可以形式化为:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/dac9ccb1c4caa12a5cea9cdae36293b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*uHAc951w4sfk0Q22b0LH9g.png"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">HPO的数学公式。作者的公式。</p></figure><p id="936b" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">其中M是我们希望使用给定的训练和测试集来优化模型f_hat的度量的评估。<strong class="ld iw">θ</strong>是用于配置模型的一组参数。数值取自配置空间<strong class="ld iw">θ</strong>。</p><p id="1445" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">通常，当面对这样的优化问题时，使用基于数值微分的方法。基本上，要优化的函数，即M与f_hat的组合，相对于参数<strong class="ld iw">θ</strong>是微分的。然后，使用牛顿-拉夫森法、梯度下降法或任何类似的方法迭代收敛到最优值。</p><p id="cbe3" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">然而，在超参数调谐的情况下，通常不可能计算这些梯度:</p><ul class=""><li id="36df" class="mu mv iv ld b le lf lh li lk mw lo mx ls my lw mz na nb nc bi translated">度量可以是非平滑的，例如MAE。参见我关于这个主题的另一篇论文。因此，微分是不可能的。</li><li id="f270" class="mu mv iv ld b le nd lh ne lk nf lo ng ls nh lw mz na nb nc bi translated">模型本身可能很难区分，不仅在符号上，在数字上也是如此。想想所有基于树的方法，它们是分段常数的。</li><li id="cf57" class="mu mv iv ld b le nd lh ne lk nf lo ng ls nh lw mz na nb nc bi translated">梯度可以消失。这是神经网络的情况，也是基于树的方法:随机森林，XGBoost，CatBoost，LightGBM，…</li><li id="1bd3" class="mu mv iv ld b le nd lh ne lk nf lo ng ls nh lw mz na nb nc bi translated">数值评估梯度是非常耗时的，因为对于每个参数方向上的每个变化，我们需要训练一个完整的模型。</li><li id="43dd" class="mu mv iv ld b le nd lh ne lk nf lo ng ls nh lw mz na nb nc bi translated">模型超参数可能不连续。想想XGBoost的<em class="nk"> nb_estimators </em>参数:它是一个整数值。分类参数也是如此。</li></ul><p id="4284" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">请注意，自动微分在某些情况下会有所帮助，但在大多数情况下，您无法使用梯度导向方法进行优化。</p><p id="5884" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">正如您所看到的，在超参数调优的情况下，许多原因禁止使用标准优化方法。我们被迫仅仅依靠我们作为数据科学家的经验来选择最佳参数吗？</p><h1 id="d180" class="lx ly iv bd lz ma mb mc md me mf mg mh kb mi kc mj ke mk kf ml kh mm ki mn mo bi translated">为什么不用网格搜索？</h1><p id="b72e" class="pw-post-body-paragraph lb lc iv ld b le mp jw lg lh mq jz lj lk mr lm ln lo ms lq lr ls mt lu lv lw io bi translated">一种选择是使用暴力。毕竟，为XGBoost、Random Forest或任何其他模型寻找最佳超参数只需要评估每个可能配置的指标。</p><p id="20ba" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">但是如上所述，配置空间可能是巨大的，即使计算机越来越强大，探索10 ⁰配置仍然(远远)超出他们的能力范围。</p><p id="b9e5" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">所以这只能是你配置空间非常有限的时候的一个选项。</p><h1 id="ba23" class="lx ly iv bd lz ma mb mc md me mf mg mh kb mi kc mj ke mk kf ml kh mm ki mn mo bi translated">那么随机搜索呢</h1><p id="66f6" class="pw-post-body-paragraph lb lc iv ld b le mp jw lg lh mq jz lj lk mr lm ln lo ms lq lr ls mt lu lv lw io bi translated">这是一种选择。但是有随机性在里面；)我们将在下面看到它是可行的，但是不能保证收敛到最佳配置，至少在给定的时间内。</p><h1 id="ee23" class="lx ly iv bd lz ma mb mc md me mf mg mh kb mi kc mj ke mk kf ml kh mm ki mn mo bi translated">使用SMAC</h1><p id="17c0" class="pw-post-body-paragraph lb lc iv ld b le mp jw lg lh mq jz lj lk mr lm ln lo ms lq lr ls mt lu lv lw io bi translated">库<a class="ae la" href="https://www.automl.org/automated-algorithm-design/algorithm-configuration/smac/" rel="noopener ugc nofollow" target="_blank"> SMAC </a>提出了蛮力和随机探索的替代方案:基于序列模型的算法配置。</p><p id="fd02" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">这个库背后的想法是建立一个模型(因此SMAC的缩写是基于模型的),试图为一组给定的超参数估计度量值。使用这个内部模型，您可以随机生成配置，并使用这个估计器来猜测什么是最好的配置。</p><p id="8b79" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">参见这篇非常好的开创性的<a class="ae la" href="https://ml.informatik.uni-freiburg.de/papers/11-LION5-SMAC.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>了解更多关于这个主题的细节。我还写了一篇关于如何使用模型创建自己的HPO引擎的完整文章:</p><div class="nl nm gp gr nn no"><a rel="noopener follow" target="_blank" href="/tuning-xgboost-with-xgboost-writing-your-own-hyper-parameters-optimization-engine-a593498b5fba"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd iw gy z fp nt fr fs nu fu fw iu bi translated">用XGBoost调优XGBoost:编写自己的Hyper Parameters优化引擎</h2><div class="nv l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">towardsdatascience.com</p></div></div><div class="nw l"><div class="nx l ny nz oa nw ob ku no"/></div></div></a></div><p id="3bc1" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">SMAC使用随机森林模型来捕捉算法/模型的行为，以根据指标进行优化。</p><p id="945e" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">整个算法非常简单。运行第一次训练并计算指标。用这个第一输出训练随机森林模型。</p><p id="3ef6" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">然后生成随机配置，具有最佳估计分数的配置用于下一次训练。然后用这个新的结果重新训练模型，这个过程再次开始。</p><p id="6793" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">内部性能模型指导配置空间探索。如代码所示，受SMAC <a class="ae la" href="https://github.com/automl/SMAC3/blob/master/examples/SMAC4HPO_rf.py" rel="noopener ugc nofollow" target="_blank">示例</a>的启发，SMAC从之前的运行中学习，并在每一步中提高自己的知识:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="oc od l"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">使用随机搜索和SMAC调整随机森林模型。</p></figure><p id="dc82" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">上面的代码使用SMAC和RandomizedSearchCV来调整Hyper参数。请注意，SMAC支持连续实参数以及分类参数。支持分类参数是使用随机森林作为指导探索的内部模型的一个原因。</p><p id="f0e6" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">这段代码演示了如何使用SMAC和Random Forest作为模型进行微调，但是我一直将它用于XGBoost以及SVM或萨里玛模型，它非常有效。</p><p id="c437" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">下图比较了两种情况下的配置空间探索，即使用SMAC和随机搜索。他们根据超参数调整迭代次数绘制分数:</p><div class="kl km kn ko gt ab cb"><figure class="oe kp of og oh oi oj paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><img src="../Images/43f98c9dc843ba386d1eb938aa3e919a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*7t7_fSQz8QYB_qO1ZG729w.png"/></div></figure><figure class="oe kp ok og oh oi oj paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><img src="../Images/9b988557ea87225688bb097ba807ecd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*uCVqx5cVbt91fTN7udoOmA.png"/></div><p class="kw kx gj gh gi ky kz bd b be z dk ol di om on translated">随机搜索(左)与SMAC(右)超级参数探索。作者的图表。</p></figure></div><p id="a21c" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">在左侧，我们看到随机搜索不规则地探索配置空间。优化没有受益于以前的培训。另一方面，在右边的图中，可以清楚地看到SMAC从以前的试验中吸取了经验，并尝试了一些适合改进的构型。</p><p id="2328" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">结果是SMAC更快地收敛到更好的解。</p><h1 id="80a4" class="lx ly iv bd lz ma mb mc md me mf mg mh kb mi kc mj ke mk kf ml kh mm ki mn mo bi translated">结论</h1><p id="b8d4" class="pw-post-body-paragraph lb lc iv ld b le mp jw lg lh mq jz lj lk mr lm ln lo ms lq lr ls mt lu lv lw io bi translated">为一个模型寻找最佳的超参数是一项乏味但至关重要的任务。SMAC是一个非常有效的库，它带来了自动ML并真正加速了精确模型的构建。任何类型的模型都可以从这种微调中受益:XGBoost，Random Forest，SVM，SARIMA，…</p><p id="64bc" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">非常有趣的是，基于ML的方法可以用来帮助更好地训练ML模型。然而，这提出了一个问题:SMAC内部随机森林模型的超参数是如何优化的？</p><p id="8395" class="pw-post-body-paragraph lb lc iv ld b le lf jw lg lh li jz lj lk ll lm ln lo lp lq lr ls lt lu lv lw io bi translated">你会在<a class="ae la" href="https://github.com/automl/SMAC3" rel="noopener ugc nofollow" target="_blank"> SMAC </a>代码或者学术<a class="ae la" href="https://ml.informatik.uni-freiburg.de/papers/11-LION5-SMAC.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中找到答案:它们是硬编码的；)</p></div></div>    
</body>
</html>