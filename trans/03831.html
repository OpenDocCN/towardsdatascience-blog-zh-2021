<html>
<head>
<title>4 Useful clustering methods you should know in 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2021年你应该知道的4种有用的聚类方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/4-useful-clustering-methods-you-should-know-in-2021-ac61301e968e?source=collection_archive---------17-----------------------#2021-03-30">https://towardsdatascience.com/4-useful-clustering-methods-you-should-know-in-2021-ac61301e968e?source=collection_archive---------17-----------------------#2021-03-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4f7a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">根据距离形成相似的观察组</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/65ba4fb3a09958c730c6a9c6c78f5da2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n9GFompLyuI6jJlUjEAUQQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">凯利·西克玛在<a class="ae ky" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="3d11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">聚类分析的主要目的是通常基于<strong class="lb iu"> <em class="lv">欧几里德</em> </strong>距离形成相似观察值的组(称为<strong class="lb iu">簇 </strong>)。在机器学习术语中，聚类是一个<strong class="lb iu"> <em class="lv">无监督的</em> </strong>任务。今天，我们讨论4种有用的聚类方法，它们属于两个主要类别——<strong class="lb iu">层次聚类</strong>和<strong class="lb iu">非层次聚类</strong>。</p><p id="9fce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在层次聚类下，我们将讨论3种<em class="lv">聚集</em>层次方法——<strong class="lb iu">单连锁</strong>、<strong class="lb iu">完全连锁</strong>和<strong class="lb iu">平均连锁</strong>。在非层次聚类方法下，我们将讨论<strong class="lb iu"> K-Means聚类</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lw"><img src="../Images/899c67a74d13724924bf564792ce0043.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*S7RZzqbTA-mQAc4vU2i0jQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="a4a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们在这里讨论的每种方法都是使用Scikit-learn机器学习库实现的。我还将为分层方法创建<strong class="lb iu"> <em class="lv">树状图</em> </strong>，以显示观察值之间的分层关系。阅读本文后，您将能够区分每种聚类方法，并使用真实数据集实现每种方法。</p><h1 id="b125" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated"><strong class="ak">分层和非分层聚类</strong></h1><p id="fd4d" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">层次聚类</em> </strong>由一系列连续的合并组成。这里，我们不需要知道要查找的簇的数量。与K-Means聚类相比，这是层次聚类的一大优势。这种聚类方法可以应用于更小的数据集。使用层次聚类，我们不仅可以对观察值进行分组，还可以对变量进行分组。凝聚法如单连锁、完全连锁和平均连锁都是层次聚类的例子。</p><p id="8ce5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">非层次聚类</em> </strong>不是由一系列连续的合并组成的。这里，应该在聚类之前指定聚类的数量。这种方法适用于大得多的数据集。使用非层次聚类，我们可以只对观察值进行分组。K-means聚类是非层次聚类的一个例子。在Scikit-learn中，可以通过使用<strong class="lb iu"> KMeans() </strong>类来实现。</p><h1 id="2f7d" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">凝聚方法</h1><p id="c260" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">开始时，单个观察值被认为是凝聚方法中的主要聚类。然后，我们将最相似的对象组合成簇。通过考虑观察值之间的最小距离或最大相关性来找到最相似的对象。单个连接、完全连接和平均连接是聚集方法的例子。在Scikit-learn中，凝聚方法可以通过使用<strong class="lb iu">college veclustering()</strong>类来实现。通过在该类内部定义<strong class="lb iu">联动:<em class="lv">{‘完全’，‘平均’，‘单一’}</em></strong>超参数，可以建立基于单一联动、完全联动、平均联动的不同集聚模型。</p><h1 id="ccbb" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">分层方法</h1><h2 id="d9fb" class="mu ly it bd lz mv mw dn md mx my dp mh li mz na mj lm nb nc ml lq nd ne mn nf bi translated">凝聚-单键</h2><p id="0b8a" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">在<strong class="lb iu"> <em class="lv">单</em> </strong>联动法中，我们结合观测值考虑了两个集合的所有观测值之间距离的最小<strong class="lb iu"><em class="lv"/></strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/55a4a0a2eeb41b610ac4868c3081d687.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*FFFFCJ6Fw2B5PkGeiVZMPA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">单一链接(图片由作者提供)</p></figure><h2 id="2c0e" class="mu ly it bd lz mv mw dn md mx my dp mh li mz na mj lm nb nc ml lq nd ne mn nf bi translated">凝聚—完全连锁</h2><p id="2ada" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">在<strong class="lb iu"> <em class="lv">完成</em> </strong>联动的方法中，我们结合观测值考虑了<strong class="lb iu"> <em class="lv">最大</em> </strong>的两组所有观测值之间的距离。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/0c6612b0c1004aafd61ba6577ee36769.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*KvVcsBxNYvT_UxzkyUjKTg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">完整链接(图片由作者提供)</p></figure><h2 id="d840" class="mu ly it bd lz mv mw dn md mx my dp mh li mz na mj lm nb nc ml lq nd ne mn nf bi translated">凝聚平均连锁</h2><p id="324b" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">在<strong class="lb iu"> <em class="lv">平均</em> </strong>联动法中，我们结合观测值考虑了<strong class="lb iu"> <em class="lv">平均</em> </strong>两组各观测值的距离。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/f0597ff30935ca1ffeb0412eb37e6f8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*BK-vcxCNjxJd8frnK9AKNQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">平均链接(作者图片)</p></figure><h1 id="6480" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">履行</h1><p id="2dd4" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">以下Python代码块解释了如何将<em class="lv">完全链接方法</em>实现到“鸢尾数据集”中，以找到鸢尾花的不同物种(簇)。为了可视化的目的，我们还应用主成分分析将4维虹膜数据减少为可以用2D图绘制的2维数据，同时保留原始数据中95.8%的变化！</p><h2 id="7427" class="mu ly it bd lz mv mw dn md mx my dp mh li mz na mj lm nb nc ml lq nd ne mn nf bi translated">第一步:绘制<strong class="ak">树状图</strong></h2><p id="8483" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">在这里，我们绘制了完全连锁方法的树状图，以显示观察值之间的层次关系，并猜测聚类的数量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等到加载Python代码！</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/0d6fcd7016311a699dd3c242944d9bc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Y6C-YZFIFEdb0UHxSrRyg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">层次聚类树状图(图片由作者提供)</p></figure><p id="c9eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过查看树状图，可以更好地获得“Iris”数据的3簇解决方案。</p><h2 id="1abd" class="mu ly it bd lz mv mw dn md mx my dp mh li mz na mj lm nb nc ml lq nd ne mn nf bi translated">步骤2:获取分类标签</h2><p id="6022" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">对于“Iris”数据中的每个观察，我们得到3个聚类标签(0、1或2)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等到加载Python代码！</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/2d0d243143550b6c3de3426d744523c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*MamicXfsfcMxhkcU41kI3g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用完全链接方法对“Iris”数据进行分类标签(图片由作者提供)</p></figure><h2 id="d480" class="mu ly it bd lz mv mw dn md mx my dp mh li mz na mj lm nb nc ml lq nd ne mn nf bi translated">步骤3:绘制聚类图</h2><p id="53aa" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">在主成分分析的帮助下，我们可以绘制“Iris”数据的3个聚类。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等到加载Python代码！</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/75e262822ad32809487f65efa3ec2461.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*p2VqNfKqAEVsSEySyr1wEg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="13eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在散点图中，我们可以清楚地看到3个集群。事实上，鸢尾花实际上有3个品种，分别叫做<strong class="lb iu"> Setosa </strong>、<strong class="lb iu"> Versicolour </strong>和<strong class="lb iu"> Virginica </strong>，我们发现的3个簇代表了它们！</p><h1 id="c569" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">非等级方法</h1><h2 id="e434" class="mu ly it bd lz mv mw dn md mx my dp mh li mz na mj lm nb nc ml lq nd ne mn nf bi translated"><strong class="ak"> K均值聚类</strong></h2><p id="3d66" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">在<strong class="lb iu"> <em class="lv"> k-means聚类</em> </strong>中，算法试图将观察值分组到<strong class="lb iu"> <em class="lv"> k </em> </strong>组(簇)中，观察值数量大致相同。组数<strong class="lb iu"> <em class="lv"> k </em> </strong>应由用户指定为<strong class="lb iu"> <em class="lv">超参数</em> </strong>。</p><p id="0541" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要了解更多关于K-means聚类的工作原理、分步实现、目标和假设以及如何找到最优的聚类数(针对<strong class="lb iu"> <em class="lv"> k </em> </strong>的超参数调优)，请阅读我的<strong class="lb iu"/><a class="ae ky" href="https://medium.com/mlearning-ai/k-means-clustering-with-scikit-learn-e2af706450e4" rel="noopener"><strong class="lb iu">动手K-means聚类</strong></a><strong class="lb iu"/>帖子。</p><h1 id="7d67" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">履行</h1><p id="b04a" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">以下Python代码解释了如何对“鸢尾数据集”实施K-means聚类，以找到鸢尾花的不同种类(聚类)。为了可视化的目的，我们还应用主成分分析将4维虹膜数据减少为可以用2D图绘制的2维数据，同时保留原始数据中95.8%的变化！</p><h2 id="b63b" class="mu ly it bd lz mv mw dn md mx my dp mh li mz na mj lm nb nc ml lq nd ne mn nf bi translated">步骤1:获取分类标签</h2><p id="abf6" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">使用K-Means方法，我们为“Iris”数据中的每个观察值获得3个聚类标签(0、1或2)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等到加载Python代码！</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/05f45ba8cfdb7f5ce8e1c4882ad2d048.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*bU5yuHy8Q-AVT-W61EIlEQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用K-Means方法对“Iris”数据进行聚类标签(图片由作者提供)</p></figure><h2 id="041d" class="mu ly it bd lz mv mw dn md mx my dp mh li mz na mj lm nb nc ml lq nd ne mn nf bi translated">步骤2:绘制聚类图</h2><p id="8044" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">在主成分分析的帮助下，我们可以绘制“Iris”数据的3个聚类。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/301d9be4e3fd116f61b9fc632e94dfd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*fxp1DJ84d2Fkp9rwlFuJUQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><h2 id="a96c" class="mu ly it bd lz mv mw dn md mx my dp mh li mz na mj lm nb nc ml lq nd ne mn nf bi translated">第三步:创建<strong class="ak">剪影图</strong></h2><p id="df9d" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">让我们看看我们发现的集群是平衡的(即，每个集群具有大致相同的观察数量)并且分离良好。为此，我们可以创建一个剪影图。想了解更多，请阅读我的<strong class="lb iu"/><a class="ae ky" href="https://medium.com/mlearning-ai/k-means-clustering-with-scikit-learn-e2af706450e4" rel="noopener"><strong class="lb iu">动手K-Means聚类</strong></a><strong class="lb iu"/>帖子。</p><pre class="kj kk kl km gt nq nr ns nt aw nu bi"><span id="5516" class="mu ly it nr b gy nv nw l nx ny">from yellowbrick.cluster import silhouette_visualizer<br/>silhouette_visualizer(K_Means, X_pca, colors='yellowbrick')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/928a7eeea1c01b30564108ba66384ff2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*I_DdEKoqk2_SHaRh9XIAEA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">剪影图— K-Means方法(图片由作者提供)</p></figure><p id="f750" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该图包含每个簇的一个刀形。刀形的宽度表示集群中实例的数量。条形长度表示每个实例的轮廓系数。虚线表示平均轮廓分数。</p><p id="cc57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到我们发现的星团是<strong class="lb iu"><em class="lv"/></strong>。这是因为刀具形状的宽度大致相同。</p><p id="725a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3个集群中的大多数点具有大的轮廓值，并且向右延伸超过虚线，指示我们发现的集群是<strong class="lb iu"> <em class="lv">良好分离的</em> </strong>。</p><h1 id="1831" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">摘要</h1><p id="6b73" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated"><strong class="lb iu">聚类</strong>是一种有用的技术，可用于根据距离形成相似观察值的组。在机器学习术语中，聚类是一个<strong class="lb iu"> <em class="lv">无监督的</em> </strong>任务。如果数据中的变量不是在相似的比例上测量的，则执行要素缩放是非常重要的。今天，我们讨论了4种不同的聚类方法，并用“Iris”数据实现了它们。Scikit-learn提供了易于使用的函数来实现这些方法。</p><p id="bcad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">聚类分析有三个目标:</p><ol class=""><li id="023d" class="oa ob it lb b lc ld lf lg li oc lm od lq oe lu of og oh oi bi translated"><strong class="lb iu">形成相似观察的组</strong></li><li id="9b02" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated"><strong class="lb iu">为每个观察值分配聚类标签</strong></li><li id="d8e3" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated"><strong class="lb iu">找到每个集群的中心</strong></li></ol><p id="963a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一个目标对于发现数据中的一些重要模式(如果有的话)非常有用。出于可视化的目的，我们可以使用主成分分析来降低数据的维度。</p><p id="adb0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果数据中没有指示标签的目标列，那么第二个目标对于获取每个观察的分类标签非常有用。这就是为什么聚类是一个<strong class="lb iu"> <em class="lv">无监督</em> </strong>任务，其中数据中没有目标列。</p><p id="96d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第三个目标对于获得特定集群中观察值的平均度量非常有用。例如，一家服装厂计划设计一个新系列的衬衫。但是他们不知道适合大多数人的衬衫尺寸。他们有关于人体测量的数据。他们可以应用聚类技术，根据对这些人身体部位的具体测量，将他们分组。一旦找到聚类，他们可以使用聚类中心的值作为衬衫的尺寸。</p><p id="e0f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">聚类的主要挑战之一是找到最佳的聚类数。聚类算法本身并不学习最佳聚类数。我们必须在训练模型之前将其指定为超参数。用机器学习的术语来说，也叫<strong class="lb iu"> <em class="lv">超参数调谐</em> </strong>。为此，我们可以尝试不同的可视化技术。有时，问题的领域知识将帮助您推断出正确的聚类数。要了解更多关于聚类中超参数调优的知识，我邀请您阅读我的<strong class="lb iu"/><a class="ae ky" href="https://medium.com/mlearning-ai/k-means-clustering-with-scikit-learn-e2af706450e4" rel="noopener"><strong class="lb iu">动手K-Means聚类</strong></a><strong class="lb iu"/>帖子。它将为你提供一步一步的指导。</p><p id="4b91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读！</p><p id="2611" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本教程由<a class="ae ky" href="https://www.linkedin.com/in/rukshan-manorathna-700a3916b/" rel="noopener ugc nofollow" target="_blank"><em class="lv">Rukshan Pramoditha</em></a><em class="lv">，</em>数据科学365博客作者设计创作。</p><p id="b09a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在https://rukshanpramoditha.medium.com阅读我的其他文章</p><p id="e3be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi">2021–03–30</p></div></div>    
</body>
</html>