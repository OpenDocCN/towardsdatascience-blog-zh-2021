<html>
<head>
<title>AI-Assisted Automated Machine-Driven Data Labeling Approach</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能辅助的自动化机器驱动数据标注方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ai-assisted-automated-machine-driven-data-labeling-approach-afde67e32c52?source=collection_archive---------13-----------------------#2021-08-08">https://towardsdatascience.com/ai-assisted-automated-machine-driven-data-labeling-approach-afde67e32c52?source=collection_archive---------13-----------------------#2021-08-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4321" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><strong class="ak">用于对象检测、对象识别和分割任务的自动注释解决方案</strong></h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/69e947b4868df811785d409a397c425e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R1Ds3qtRZ9uaZf2fYdv2eA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者提供的图片:我们的数据模型无关的自动注释工具的示例表示</p></figure><p id="c807" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">作者:</strong><strong class="kx ir">Ajay Arunachalam——高级数据科学家&amp;研究员(AI) </strong></p><p id="cf6d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你好，朋友们。在这篇博文中，我想分享我们在使用人工智能技术自动生成数据标签方面所做的工作。</p><p id="a896" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的完整文章可以在这里找到——<a class="ae lr" href="https://lnkd.in/gJDKQCY" rel="noopener ugc nofollow" target="_blank">https://lnkd.in/gJDKQCY</a></p><p id="a8b0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我们探讨我们的方法之前，首先让我们通俗地理解什么是数据标记。在机器学习中，<strong class="kx ir">数据标注</strong>简单来说就是识别原始数据(图像、视频、音频文件、文本文件等)的<strong class="kx ir">过程。)，而<strong class="kx ir">向<strong class="kx ir">添加一个或多个有意义和有信息的标签</strong>提供了上下文</strong>，以便<strong class="kx ir">一个机器学习模型可以学习&amp;从中推断</strong>。大多数最先进的机器学习模型高度依赖于大量标记数据的可用性，这是监督任务中必不可少的一步。各种用例都需要数据标记，包括<strong class="kx ir">计算机视觉、自然语言处理和语音识别</strong>。传统上，这种乏味的标记数据的平凡过程迄今为止主要由人类完成。为了帮助人类从零开始最大限度地减少疯狂的数据标注工作和努力，我们建议一种自动化的算法解决方案，旨在减少大量的人工工作。让我们看一下哪里真正需要这种带标签的数据。在这里，我将谈谈计算机视觉的任务。计算机视觉</strong>简单来说就是复制人类视觉(人眼视觉)的复杂性，以及对周围环境的理解。计算机视觉任务包括<strong class="kx ir">获取、处理、分析和理解数字图像的方法，以及</strong>从真实世界中提取高维数据，以便产生数字或符号信息，例如以决策的形式。在计算机视觉领域，有许多不同的任务。例如<strong class="kx ir">分类</strong>、<strong class="kx ir">检测</strong>、<strong class="kx ir">分割</strong>等，我就不赘述了。但是，下图提供了这些任务的清晰概述&amp;目标，并提供了一个上下文中的对象示例—“<strong class="kx ir">Banana</strong>”。</p><p id="8a2a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一个上下文示例——需要标记数据</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/ff1ab96bbac65d1a615834851d5105f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ONE_rzuHuoGnHnbZRsRsPg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">分类vs .检测vs .语义分割vs .实例分割，【版权&amp;图片改编自<a class="ae lr" href="https://www.cloudfactory.com/image-annotation-guide" rel="noopener ugc nofollow" target="_blank">https://www.cloudfactory.com/image-annotation-guide</a>。经允许重新发布]</p></figure><p id="6cb7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于检测目标的监督模型——“<strong class="kx ir">香蕉</strong>”，标注的标签被馈送给模型，以便它可以学习香蕉像素的表示，并在上下文中定位它们，然后可以使用上下文来推断看不见的/新的数据。实例分割任务旨在检测对象，定位这些对象，并提供它们的数量、大小和形状信息。我们使用一个这样的最先进的实例分割模型—“<strong class="kx ir">Mask R-CNN</strong>”作为我们框架的核心骨干，但是这里可以根据他们的需求使用任何其他网络架构&amp;目标。我们坚持使用mask R-CNN，因为它可以有效地检测图像中的对象，同时为每个对象生成高质量的分段掩模。对于COVID感染检测的特定测试用例，感染区域的精确位置至关重要，因此像素级检测在这种情况下更合适。</p><h1 id="f639" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">我们的方法</h1><p id="6333" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">我们工具的流水线如下所示，主要包括检测器和跟踪器、自动标记模块和用于将机器标注的标签输出和保存到磁盘的I/O模块。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/be2d7aa686a3fa3c6fb1a30c3d26f582.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/1*_BBYR2opwKqtYvqsfsTZxA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片:自动化数据标注管道</p></figure><p id="2069" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">步骤1:-对象检测和跟踪以进行像素级分类</p><p id="957d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">定制的弱训练mask-RCNN模型用于COVID感染检测，具有非常少的标记实例(&lt; 10个样本)。为了标记感染区域，我们使用VGG图像注释器(VIA)图像注释工具。这是一个简单和独立的手动注释软件，用于图像、音频和视频。VIA在web浏览器中运行，不需要任何安装或设置。完整的VIA软件可以放在一个小于400千字节的独立HTML页面中，在大多数现代web浏览器中作为离线应用程序运行。VIA是一个完全基于HTML、Javascript和CSS的开源项目(不依赖外部库)。VIA由视觉几何小组(VGG)开发，并在BSD-2条款许可下发布，这使得它对学术项目和商业应用都很有用。检测器用于获得被定位的遮罩、包围盒和类。接下来，为了沿着输入视频数据流一致地跟踪和标记多个感染区域，我们使用了centriod跟踪算法。下面是我们的mask-RCNN covid检测器的一个片段。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="509e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">步骤2:-逐帧数据标记</p><p id="8387" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">来自预训练的检测器模型的推断用于获得边界框的位置，并创建json元数据。一旦使用Mask-RCNN对帧进行分割，就会生成相应的感兴趣区域(ROI)。此外，生成每个ROI的掩模，然后在整个图像帧上进行轮廓检测。然后，从轮廓中提取(x，y)坐标。最后，将这些形状、区域和坐标属性逐帧保存到磁盘中。下面给出了我们的自动标记算法的片段。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="8674" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">示例—新冠肺炎感染检测和自动标记</p><p id="73b3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们测试了我们的方法，目标是为Covid感染区域生成自动计算机标签。机器生成标签和人工标注标签的结果如下所示。可以看出，自动注释引擎生成相当好质量的合成标签，这些合成标签可以用于重新训练对象检测模型，或者生成可以用于不同任务的更多注释数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/c70db916cf55b9a5fef16f1b3da666f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*dwceVJd9yjU3blbPGVQF-g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">肺部CT扫描中Covid感染区域的机器生成标记与人工注释标记的比较，[图片改编自&amp; Copyright:doi:10.1109/tem . 2021.3094544 .经许可转贴]</p></figure><h1 id="0aeb" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">摘要</h1><p id="472f" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">数据标注是一项重要的任务，也是监督学习管道的关键组成部分之一。这是一项需要大量手工劳动的任务。那么，我们能不能让大量这种平凡的、劳动密集型和耗时的工作由旨在最大限度减少人类任务的机器来自主驱动。我们专注于这个通用的问题，用我们直观的方法来极大地缓解标签有限的瓶颈，或者自己从头开始标记大量实例的需要。</p><p id="e031" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">注意:-我们的工具目前处于alpha测试阶段。目前，我们设计的框架是基于掩模R-CNN和VIA注释格式。我们还旨在将我们的原型一般化，以包括不同的最先进的检测器，例如YOLO和相应的YOLO兼容注释格式。此外，我们还计划集成COCO注释格式。值得将所有不同的图像注释集成为我们框架的一部分，同时为该设施提供不同的库，即Torch、TensorFlow、Caffe等。</p><h1 id="58c1" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">联系我</h1><p id="ce58" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">你可以打<strong class="kx ir"><em class="mu"/></strong>联系我，或者通过<a class="ae lr" href="https://www.linkedin.com/in/ajay-arunachalam-4744581a/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>联系我</p><p id="291c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">感谢阅读。</p><p id="0721" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">继续学习！！！点击这里查看我的github页面<a class="ae lr" href="https://github.com/ajayarunachalam" rel="noopener ugc nofollow" target="_blank"/></p><h1 id="ae58" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">参考资料:-</h1><div class="mv mw gp gr mx my"><a href="https://en.wikipedia.org/wiki/Labeled_data" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd ir gy z fp nd fr fs ne fu fw ip bi translated">标签数据-维基百科</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">标记数据是用一个或多个标签标记的一组样本。标签通常需要一组…</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">en.wikipedia.org</p></div></div><div class="nh l"><div class="ni l nj nk nl nh nm kp my"/></div></div></a></div><p id="32f2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae lr" href="https://whatis.techtarget.com/definition/data-labeling" rel="noopener ugc nofollow" target="_blank">https://whatis.techtarget.com/definition/data-labeling</a></p><p id="657c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae lr" href="https://aws.amazon.com/sagemaker/groundtruth/what-is-data-labeling/" rel="noopener ugc nofollow" target="_blank">https://AWS . Amazon . com/sagemaker/ground truth/what-is-data-labeling/</a></p><p id="3772" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae lr" href="https://www.geeksforgeeks.org/object-detection-vs-object-recognition-vs-image-segmentation/" rel="noopener ugc nofollow" target="_blank">https://www . geeks forgeeks . org/object-detection-vs-object-recognition-vs-image-segmentation/</a></p><p id="21db" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae lr" href="https://www.robots.ox.ac.uk/~vgg/software/via/" rel="noopener ugc nofollow" target="_blank">https://www.robots.ox.ac.uk/~vgg/software/via/</a></p><p id="25e3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae lr" href="https://github.com/matterport/Mask_RCNN" rel="noopener ugc nofollow" target="_blank">https://github.com/matterport/Mask_RCNN</a></p><p id="d4a1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae lr" href="https://www.telusinternational.com/articles/5-approaches-to-data-labeling-for-machine-learning-projects" rel="noopener ugc nofollow" target="_blank">https://www . telus international . com/articles/5-面向机器学习项目的数据标注方法</a></p><p id="0fb7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae lr" href="https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46" rel="noopener ugc nofollow" target="_blank">https://engineering . matter port . com/splash-of-color-instance-segmentation-with mask-r-CNN-and-tensor flow-7c 761 e 238 b 46</a></p><div class="mv mw gp gr mx my"><a href="https://www.cloudfactory.com/image-annotation-guide" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd ir gy z fp nd fr fs ne fu fw ip bi translated">计算机视觉中的图像标注</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">有四种主要类型的图像注释可以用来训练计算机视觉人工智能模型。图像…</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">www.cloudfactory.com</p></div></div></div></a></div><div class="mv mw gp gr mx my"><a href="https://en.wikipedia.org/wiki/Computer_vision" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd ir gy z fp nd fr fs ne fu fw ip bi translated">计算机视觉-维基百科</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">计算机视觉是一个跨学科的科学领域，处理计算机如何获得高层次的…</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">en.wikipedia.org</p></div></div><div class="nh l"><div class="nn l nj nk nl nh nm kp my"/></div></div></a></div><div class="mv mw gp gr mx my"><a href="https://arxiv.org/abs/1703.06870" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd ir gy z fp nd fr fs ne fu fw ip bi translated">屏蔽R-CNN</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">我们提出了一个概念上简单、灵活、通用的对象实例分割框架。我们的方法…</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">arxiv.org</p></div></div><div class="nh l"><div class="no l nj nk nl nh nm kp my"/></div></div></a></div><div class="mv mw gp gr mx my"><a href="https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=17" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd ir gy z fp nd fr fs ne fu fw ip bi translated">IEEE工程管理汇刊|关于期刊| IEEE Xplore</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">了解IEEE工程管理汇刊。IEEE工程管理汇刊关注…</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">ieeexplore.ieee.org</p></div></div></div></a></div></div></div>    
</body>
</html>