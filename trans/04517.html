<html>
<head>
<title>Imbalanced Classification in Python: SMOTE-Tomek Links Method</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的不平衡分类:SMOTE-Tomek链接方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/imbalanced-classification-in-python-smote-tomek-links-method-6e48dfe69bbc?source=collection_archive---------9-----------------------#2021-04-18">https://towardsdatascience.com/imbalanced-classification-in-python-smote-tomek-links-method-6e48dfe69bbc?source=collection_archive---------9-----------------------#2021-04-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/451a4fdeb7e1eed410d1656d7ce4cdcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mYb_yxz4tdVAM2dU"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://unsplash.com/@matthewhenry?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马太·亨利</a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><div class=""/><div class=""><h2 id="add8" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">结合SMOTE和Tomek链接的Python不平衡分类</h2></div><h2 id="3e2c" class="kv kw jg bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">动机</h2><p id="4525" class="pw-post-body-paragraph lr ls jg lt b lu lv kh lw lx ly kk lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">在实际应用中，分类建模经常会遇到不平衡数据集问题，多数类的数量远大于少数类，从而使模型无法很好地从少数类中学习。当来自少数类的数据集中的信息更重要时，例如疾病检测数据集、客户流失数据集和欺诈检测数据集，这就成为一个严重的问题。</p><p id="e536" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">解决这种不平衡数据集问题的一种流行方法是对少数类进行过采样或对多数类进行欠采样。然而，这些方法都有自己的弱点。在普通的过采样方法中，想法是从少数类中复制一些随机样本，因此这种技术不会从数据中添加任何新信息。相反，欠采样方法是通过从多数类中移除一些随机样本来进行的，代价是原始数据中的一些信息也被移除。</p><p id="fb91" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">克服这一弱点的解决方案之一是从现有的少数类中生成新的综合示例。这种方法就是众所周知的<strong class="lt jh">合成少数过采样技术</strong>或<strong class="lt jh"> SMOTE </strong>。SMOTE有许多变体，但在本文中，我将解释SMOTE-Tomek链接方法及其使用Python的实现，其中该方法结合了SMOTE的过采样方法和Tomek链接的欠采样方法。</p><h2 id="e286" class="kv kw jg bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">概念:SMOTE</h2><p id="e003" class="pw-post-body-paragraph lr ls jg lt b lu lv kh lw lx ly kk lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">SMOTE是最流行的过采样技术之一，由Chawla <em class="mp">等人</em>开发。(2002).与仅从少数类中复制一些随机样本的随机过采样不同，SMOTE基于每个数据的距离(通常使用欧氏距离)和少数类最近邻来生成样本，因此生成的样本与原始少数类不同。</p><p id="5000" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">简而言之，生成合成样本的过程如下。</p><ol class=""><li id="32c6" class="mq mr jg lt b lu mk lx ml le ms li mt lm mu mj mv mw mx my bi translated">从少数类中选择随机数据。</li><li id="40b6" class="mq mr jg lt b lu mz lx na le nb li nc lm nd mj mv mw mx my bi translated">计算随机数据与其k个最近邻之间的欧几里德距离。</li><li id="20fb" class="mq mr jg lt b lu mz lx na le nb li nc lm nd mj mv mw mx my bi translated">将差值乘以0到1之间的随机数，然后将结果添加到少数类作为合成样本。</li><li id="0686" class="mq mr jg lt b lu mz lx na le nb li nc lm nd mj mv mw mx my bi translated">重复该过程，直到达到所需的少数族裔比例。</li></ol><p id="682e" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">这种方法是有效的，因为生成的合成数据与少数类上的特征空间相对接近，从而在数据上添加了新的“信息”，这与原始过采样方法不同。</p><h2 id="1c51" class="kv kw jg bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">概念:托梅克链接</h2><p id="cb96" class="pw-post-body-paragraph lr ls jg lt b lu lv kh lw lx ly kk lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">Tomek链接是由Tomek (1976)开发的压缩最近邻(CNN，不要与卷积神经网络混淆)欠采样技术的修改之一。与CNN方法不同，其仅从想要移除的多数类中随机选择具有k个最近邻的样本，Tomek Links方法使用规则来选择满足这些属性的观测值对(例如，<strong class="lt jh"> a </strong>和<strong class="lt jh"> b </strong>):</p><ol class=""><li id="4606" class="mq mr jg lt b lu mk lx ml le ms li mt lm mu mj mv mw mx my bi translated">观测值<strong class="lt jh"> a </strong>的最近邻居是<strong class="lt jh"> b </strong>。</li><li id="c27d" class="mq mr jg lt b lu mz lx na le nb li nc lm nd mj mv mw mx my bi translated">观测值<strong class="lt jh"> b </strong>的最近邻居是<strong class="lt jh"> a </strong>。</li><li id="833e" class="mq mr jg lt b lu mz lx na le nb li nc lm nd mj mv mw mx my bi translated">观察值<strong class="lt jh"> a </strong>和<strong class="lt jh"> b </strong>属于不同的类别。即<strong class="lt jh"> a </strong>和<strong class="lt jh"> b </strong>分别属于少数派和多数派阶级(或者<em class="mp">反之</em>)。</li></ol><p id="12b6" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">数学上可以表述如下。</p><blockquote class="ne nf ng"><p id="da8a" class="lr ls mp lt b lu mk kh lw lx ml kk lz nh mm mb mc ni mn me mf nj mo mh mi mj ij bi translated">设d(x_i，x_j)表示x_i和x_j之间的欧几里德距离，其中x_i表示属于少数类的样本，x_j表示属于多数类的样本。如果没有样本，x_k满足以下条件:</p><p id="d644" class="lr ls mp lt b lu mk kh lw lx ml kk lz nh mm mb mc ni mn me mf nj mo mh mi mj ij bi translated">1.d(x_i，x_k) &lt; d(x_i, x_j), or<br/> 2。d(x j，x k)&lt;d(x I，x j)</p><p id="197e" class="lr ls mp lt b lu mk kh lw lx ml kk lz nh mm mb mc ni mn me mf nj mo mh mi mj ij bi translated">那么(x_i，x_j)对就是一个<strong class="lt jh">托梅克链</strong>。</p></blockquote><p id="52e0" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">该方法可用于从与少数类数据具有最低欧几里德距离的多数类中找到所需的数据样本(即，来自与少数类数据最接近的多数类的数据，从而使其模糊不清)，然后将其移除。</p><h2 id="d435" class="kv kw jg bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated"><strong class="ak"> SMOTE-Tomek链接</strong></h2><p id="623d" class="pw-post-body-paragraph lr ls jg lt b lu lv kh lw lx ly kk lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">首先由巴蒂斯塔<em class="mp">等人</em>介绍。(2003)，该方法结合了SMOTE为少数类生成合成数据的能力和Tomek链接从多数类中移除被识别为Tomek链接的数据的能力(即，来自与少数类数据最接近的多数类的数据样本)。SMOTE-Tomek链接的过程如下。</p><ol class=""><li id="462f" class="mq mr jg lt b lu mk lx ml le ms li mt lm mu mj mv mw mx my bi translated">(<strong class="lt jh">SMOTE的开始</strong>)从少数类中选择随机数据。</li><li id="47b0" class="mq mr jg lt b lu mz lx na le nb li nc lm nd mj mv mw mx my bi translated">计算随机数据与其k个最近邻之间的距离。</li><li id="06d0" class="mq mr jg lt b lu mz lx na le nb li nc lm nd mj mv mw mx my bi translated">将差值乘以0到1之间的随机数，然后将结果添加到少数类作为合成样本。</li><li id="e111" class="mq mr jg lt b lu mz lx na le nb li nc lm nd mj mv mw mx my bi translated">重复步骤2-3，直到达到所需的少数族裔比例。(<strong class="lt jh">击打结束</strong>)</li><li id="1c11" class="mq mr jg lt b lu mz lx na le nb li nc lm nd mj mv mw mx my bi translated">(<strong class="lt jh">Tomek链接的开始</strong>)从多数类中选择随机数据。</li><li id="26c6" class="mq mr jg lt b lu mz lx na le nb li nc lm nd mj mv mw mx my bi translated">如果随机数据的最近邻是来自少数类的数据(即创建Tomek链接)，则移除Tomek链接。</li></ol><p id="f52c" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">为了在实践中更好地理解这种方法，这里我将给出一些如何使用<code class="fe nk nl nm nn b">imbalanced-learn</code>库(或简称为<code class="fe nk nl nm nn b">imblearn</code>)在Python中实现SMOTE-Tomek链接的例子。我们将使用的模型是通过使用<code class="fe nk nl nm nn b">RandomForestClassifier</code>随机森林。<strong class="lt jh">对于评估程序，这里我将使用重复分层K-fold交叉验证方法</strong>，以确保我们在每次重复中以不同的随机化保留每个fold中每个类别的样本百分比(即每个fold在每个类别中必须有一些样本)。</p><h2 id="98b6" class="kv kw jg bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated"><strong class="ak">实现:合成数据集</strong></h2><p id="7b92" class="pw-post-body-paragraph lr ls jg lt b lu lv kh lw lx ly kk lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">对于第一个例子，我将使用来自<code class="fe nk nl nm nn b">sklearn.datasets</code>库的<code class="fe nk nl nm nn b">make_classification</code>生成的合成数据集。首先，我们需要导入库(第二个例子中也会用到这些库)。</p><pre class="no np nq nr gt ns nn nt nu aw nv bi"><span id="02a5" class="kv kw jg nn b gy nw nx l ny nz">import pandas as pd<br/>import numpy as np<br/>from imblearn.pipeline import Pipeline<br/>import matplotlib.pyplot as plt<br/>from sklearn.datasets import make_classification<br/>from sklearn.model_selection import cross_validate<br/>from sklearn.model_selection import RepeatedStratifiedKFold<br/>from sklearn.ensemble import RandomForestClassifier<br/>from imblearn.combine import SMOTETomek<br/>from imblearn.under_sampling import TomekLinks</span></pre><p id="41ba" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">接下来，我们通过编写这些代码行来生成我们想要使用的合成数据。</p><pre class="no np nq nr gt ns nn nt nu aw nv bi"><span id="4f9a" class="kv kw jg nn b gy nw nx l ny nz">#Dummy dataset study case<br/>X, Y = make_classification(n_samples=10000, n_features=4, n_redundant=0,<br/>                           n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)</span></pre><p id="cefe" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">我们可以从<code class="fe nk nl nm nn b">weights</code>参数中看到，数据集将包含99%属于多数类的数据，而其余的属于少数类。</p><p id="bc07" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">在这里，我创建了两个模型— <strong class="lt jh">,第一个模型不使用任何不平衡数据处理，而另一个模型使用SMOTE-Tomek链接方法</strong>,为您提供使用和不使用SMOTE-Tomek链接不平衡处理方法的一些性能比较。</p><pre class="no np nq nr gt ns nn nt nu aw nv bi"><span id="eff6" class="kv kw jg nn b gy nw nx l ny nz">## No Imbalance Handling<br/># Define model<br/>model_ori=RandomForestClassifier(criterion='entropy')<br/># Define evaluation procedure (here we use Repeated Stratified K-Fold CV)<br/>cv_ori=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)<br/># Evaluate model<br/>scoring=['accuracy','precision_macro','recall_macro']<br/>scores_ori = cross_validate(model_ori, X, Y, scoring=scoring, cv=cv_ori, n_jobs=-1)</span><span id="967f" class="kv kw jg nn b gy oa nx l ny nz"># summarize performance<br/>print('Mean Accuracy: %.4f' % np.mean(scores_ori['test_accuracy']))<br/>print('Mean Precision: %.4f' % np.mean(scores_ori['test_precision_macro']))<br/>print('Mean Recall: %.4f' % np.mean(scores_ori['test_recall_macro']))</span></pre><p id="c3e2" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">如果没有SMOTE-Tomek链接，产生的模型性能如下。</p><pre class="no np nq nr gt ns nn nt nu aw nv bi"><span id="85d2" class="kv kw jg nn b gy nw nx l ny nz">Mean Accuracy: 0.9943<br/>Mean Precision: 0.9416<br/>Mean Recall: 0.7480</span></pre><p id="a50b" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">正如我们可以从不平衡的数据集预期的那样，<strong class="lt jh">准确性指标得分非常高，但是召回指标得分非常低</strong>(大约0.748)。这意味着模型未能很好地“学习”少数民族类别，因此未能正确预测少数民族类别标签。</p><p id="43fc" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">让我们看看是否可以通过使用SMOTE-Tomek链接来处理不平衡的数据，从而提高模型的性能。</p><pre class="no np nq nr gt ns nn nt nu aw nv bi"><span id="df94" class="kv kw jg nn b gy nw nx l ny nz">## With SMOTE-Tomek Links method<br/># Define model<br/>model=RandomForestClassifier(criterion='entropy')<br/># Define SMOTE-Tomek Links<br/>resample=SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))<br/># Define pipeline<br/>pipeline=Pipeline(steps=[('r', resample), ('m', model)])<br/># Define evaluation procedure (here we use Repeated Stratified K-Fold CV)<br/>cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)<br/># Evaluate model<br/>scoring=['accuracy','precision_macro','recall_macro']<br/>scores = cross_validate(pipeline, X, Y, scoring=scoring, cv=cv, n_jobs=-1)</span><span id="c1f1" class="kv kw jg nn b gy oa nx l ny nz"># summarize performance<br/>print('Mean Accuracy: %.4f' % np.mean(scores['test_accuracy']))<br/>print('Mean Precision: %.4f' % np.mean(scores['test_precision_macro']))<br/>print('Mean Recall: %.4f' % np.mean(scores['test_recall_macro']))</span></pre><p id="e7ed" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">结果如下。</p><pre class="no np nq nr gt ns nn nt nu aw nv bi"><span id="c64f" class="kv kw jg nn b gy nw nx l ny nz">Mean Accuracy: 0.9805<br/>Mean Precision: 0.6499<br/>Mean Recall: 0.8433</span></pre><p id="d841" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated"><strong class="lt jh">准确度和精确度指标可能会下降，但我们可以看到召回指标更高</strong>，这意味着通过使用SMOTE-Tomek链接处理不平衡数据，该模型在正确预测少数类标签方面表现更好。</p><h2 id="7d15" class="kv kw jg bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated"><strong class="ak">实施:电信流失数据集</strong></h2><p id="a728" class="pw-post-body-paragraph lr ls jg lt b lu lv kh lw lx ly kk lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">对于第二个例子，这里我使用来自Kaggle的<a class="ae jd" href="https://www.kaggle.com/mnassrib/telecom-churn-datasets?select=churn-bigml-80.csv" rel="noopener ugc nofollow" target="_blank">电信客户流失数据集</a>。这个数据集中有两个数据文件，但是在本文中，我将使用<code class="fe nk nl nm nn b">churn-bigml-80.csv</code>数据文件。</p><figure class="no np nq nr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ob"><img src="../Images/d0a95dddc89918e87165dbb882618901.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GeyJajtcuIqhekK-_jQIZQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">电信客户流失数据集(图片取自<a class="ae jd" href="https://www.kaggle.com/mnassrib/telecom-churn-datasets" rel="noopener ugc nofollow" target="_blank"> Kaggle </a></p></figure><p id="0cc6" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">首先，我们导入库(就像第一个例子)和数据，如下所示。</p><pre class="no np nq nr gt ns nn nt nu aw nv bi"><span id="afec" class="kv kw jg nn b gy nw nx l ny nz">data=pd.read_csv("churn-bigml-80.csv")<br/>data.head()</span></pre><figure class="no np nq nr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oc"><img src="../Images/ff7e8d50e3c1d17f2d3b708c07394aad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PmUWh84Hzx1idl9x_H-kxA.png"/></div></div></figure><p id="9f96" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">让我们看看数据描述，找出每个变量的类型。</p><pre class="no np nq nr gt ns nn nt nu aw nv bi"><span id="618a" class="kv kw jg nn b gy nw nx l ny nz">&gt; data.info()</span><span id="258d" class="kv kw jg nn b gy oa nx l ny nz">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 2666 entries, 0 to 2665<br/>Data columns (total 20 columns):<br/> #   Column                  Non-Null Count  Dtype  <br/>---  ------                  --------------  -----  <br/> 0   State                   2666 non-null   object <br/> 1   Account length          2666 non-null   int64  <br/> 2   Area code               2666 non-null   int64  <br/> 3   International plan      2666 non-null   object <br/> 4   Voice mail plan         2666 non-null   object <br/> 5   Number vmail messages   2666 non-null   int64  <br/> 6   Total day minutes       2666 non-null   float64<br/> 7   Total day calls         2666 non-null   int64  <br/> 8   Total day charge        2666 non-null   float64<br/> 9   Total eve minutes       2666 non-null   float64<br/> 10  Total eve calls         2666 non-null   int64  <br/> 11  Total eve charge        2666 non-null   float64<br/> 12  Total night minutes     2666 non-null   float64<br/> 13  Total night calls       2666 non-null   int64  <br/> 14  Total night charge      2666 non-null   float64<br/> 15  Total intl minutes      2666 non-null   float64<br/> 16  Total intl calls        2666 non-null   int64  <br/> 17  Total intl charge       2666 non-null   float64<br/> 18  Customer service calls  2666 non-null   int64  <br/> 19  Churn                   2666 non-null   bool   <br/>dtypes: bool(1), float64(8), int64(8), object(3)<br/>memory usage: 398.5+ KB</span></pre><p id="1214" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">然后，我们检查数据中是否存在缺失值，如下所示。</p><pre class="no np nq nr gt ns nn nt nu aw nv bi"><span id="ab30" class="kv kw jg nn b gy nw nx l ny nz">&gt; data.isnull().sum()</span><span id="7964" class="kv kw jg nn b gy oa nx l ny nz">State                     0<br/>Account length            0<br/>Area code                 0<br/>International plan        0<br/>Voice mail plan           0<br/>Number vmail messages     0<br/>Total day minutes         0<br/>Total day calls           0<br/>Total day charge          0<br/>Total eve minutes         0<br/>Total eve calls           0<br/>Total eve charge          0<br/>Total night minutes       0<br/>Total night calls         0<br/>Total night charge        0<br/>Total intl minutes        0<br/>Total intl calls          0<br/>Total intl charge         0<br/>Customer service calls    0<br/>Churn                     0<br/>dtype: int64</span></pre><p id="1183" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">没有缺失值！接下来，我们通过编写如下代码来计算属于<code class="fe nk nl nm nn b">Churn</code>变量中每个类的数据数量。</p><pre class="no np nq nr gt ns nn nt nu aw nv bi"><span id="fbb2" class="kv kw jg nn b gy nw nx l ny nz">&gt; data['Churn'].value_counts()</span><span id="b164" class="kv kw jg nn b gy oa nx l ny nz">False    2278<br/>True      388</span></pre><p id="ee3f" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">数据相当不平衡，其中多数阶级属于<code class="fe nk nl nm nn b">False</code>标签(我们将其标记为0)，少数阶级属于<code class="fe nk nl nm nn b">True</code>标签(我们将其标记为1)。</p><p id="22b1" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">对于下一个预处理步骤，我们删除<code class="fe nk nl nm nn b">State</code>变量(因为它包含了太多的类别)，然后我们重新编码<code class="fe nk nl nm nn b">Churn</code>变量(False=0，True=1)，并通过编写这些代码行来创建虚拟变量。</p><pre class="no np nq nr gt ns nn nt nu aw nv bi"><span id="e05d" class="kv kw jg nn b gy nw nx l ny nz">data=data.drop('State',axis=1)<br/>data['Churn'].replace(to_replace=True, value=1, inplace=True)<br/>data['Churn'].replace(to_replace=False,  value=0, inplace=True)<br/>df_dummies=pd.get_dummies(data)<br/>df_dummies.head()</span><span id="d892" class="kv kw jg nn b gy oa nx l ny nz">#Churn dataset study case<br/>Y_churn=df_dummies['Churn'].values<br/>X_churn=df_dummies.drop('Churn',axis=1)</span></pre><p id="0546" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">数据预处理完成。现在，我们使用与第一个例子相同的方法进行建模。</p><pre class="no np nq nr gt ns nn nt nu aw nv bi"><span id="217b" class="kv kw jg nn b gy nw nx l ny nz">## No Imbalance Handling<br/># Define model<br/>model2_ori=RandomForestClassifier(criterion='entropy')<br/># Define evaluation procedure (here we use Repeated Stratified K-Fold CV)<br/>cv2_ori=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)<br/># Evaluate model<br/>scoring=['accuracy','precision_macro','recall_macro']<br/>scores2_ori = cross_validate(model2_ori, X_churn, Y_churn, scoring=scoring, cv=cv2_ori, n_jobs=-1)</span><span id="780e" class="kv kw jg nn b gy oa nx l ny nz"># summarize performance<br/>print('Mean Accuracy: %.4f' % np.mean(scores2_ori['test_accuracy']))<br/>print('Mean Precision: %.4f' % np.mean(scores2_ori['test_precision_macro']))<br/>print('Mean Recall: %.4f' % np.mean(scores2_ori['test_recall_macro']))</span></pre><p id="cb06" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">如果没有不平衡的数据处理，结果如下。</p><pre class="no np nq nr gt ns nn nt nu aw nv bi"><span id="f275" class="kv kw jg nn b gy nw nx l ny nz">Mean Accuracy: 0.9534<br/>Mean Precision: 0.9503<br/>Mean Recall: 0.8572</span></pre><p id="e75f" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated"><strong class="lt jh">请记住，我们使用的数据是不平衡的，因此我们不能仅仅通过观察精确度指标来简单地说模型性能良好</strong>。尽管准确性指标得分相当高，但召回指标得分仍然不够高，这意味着该模型正在努力正确预测少数类标签(即被重新编码为1的<code class="fe nk nl nm nn b">True</code>标签)。</p><p id="e9a7" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">现在，让我们对数据进行SMOTE-Tomek链接方法，以查看性能改进。</p><pre class="no np nq nr gt ns nn nt nu aw nv bi"><span id="f31e" class="kv kw jg nn b gy nw nx l ny nz">## With SMOTE-Tomek Links method<br/># Define model<br/>model2=RandomForestClassifier(criterion='entropy')<br/># Define SMOTE-Tomek Links<br/>resample2=SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))<br/># Define pipeline<br/>pipeline2=Pipeline(steps=[('r', resample2), ('m', model2)])<br/># Define evaluation procedure (here we use Repeated Stratified K-Fold CV)<br/>cv2=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)<br/># Evaluate model<br/>scoring=['accuracy','precision_macro','recall_macro']<br/>scores2 = cross_validate(pipeline2, X_churn, Y_churn, scoring=scoring, cv=cv2, n_jobs=-1)</span><span id="31f5" class="kv kw jg nn b gy oa nx l ny nz"># summarize performance<br/>print('Mean Accuracy: %.4f' % np.mean(scores2['test_accuracy']))<br/>print('Mean Precision: %.4f' % np.mean(scores2['test_precision_macro']))<br/>print('Mean Recall: %.4f' % np.mean(scores2['test_recall_macro']))</span></pre><p id="03be" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">结果如下。</p><pre class="no np nq nr gt ns nn nt nu aw nv bi"><span id="57d3" class="kv kw jg nn b gy nw nx l ny nz">Mean Accuracy: 0.9449<br/>Mean Precision: 0.8981<br/>Mean Recall: 0.8768</span></pre><p id="916e" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">准确度和精确度分数可能会稍微降低，但是召回分数会增加！这意味着该模型能够更好地正确预测该流失数据集中的少数类标签。</p><h2 id="0230" class="kv kw jg bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated"><strong class="ak">结论</strong></h2><p id="9763" class="pw-post-body-paragraph lr ls jg lt b lu lv kh lw lx ly kk lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">就是这样！现在，您将了解如何在Python中使用SMOTE-Tomek Links方法来提高不平衡数据集中分类模型的性能。像往常一样，如果您有任何问题，请随时提问和/或讨论！</p><p id="d0c9" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">我的下一篇文章再见！保持安全，保持健康！</p><h2 id="b65b" class="kv kw jg bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated"><strong class="ak">作者的联系方式</strong></h2><p id="c993" class="pw-post-body-paragraph lr ls jg lt b lu lv kh lw lx ly kk lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">领英:<a class="ae jd" href="https://www.linkedin.com/in/raden-aurelius-andhika-viadinugroho-b84b19163/" rel="noopener ugc nofollow" target="_blank">拉登·奥勒留和希卡·维亚迪努格罗霍</a></p><p id="4642" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">中:<a class="ae jd" href="https://medium.com/@radenaurelius" rel="noopener">https://medium.com/@radenaurelius</a></p><h2 id="d299" class="kv kw jg bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">参考</h2><p id="64a2" class="pw-post-body-paragraph lr ls jg lt b lu lv kh lw lx ly kk lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">[1]舒拉、鲍耶、霍尔和凯格尔迈耶(2002年)。<a class="ae jd" href="https://arxiv.org/abs/1106.1813" rel="noopener ugc nofollow" target="_blank"> SMOTE:合成少数过采样技术</a>。<em class="mp">人工智能研究杂志</em>，第16卷，第321–357页。</p><p id="29ce" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">[2]https://www.kaggle.com/mnassrib/telecom-churn-datasets<a class="ae jd" href="https://www.kaggle.com/mnassrib/telecom-churn-datasets" rel="noopener ugc nofollow" target="_blank"/></p><p id="150c" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">[3]托梅克，1976年。<a class="ae jd" href="https://ieeexplore.ieee.org/document/4309452" rel="noopener ugc nofollow" target="_blank">CNN的两次修改</a>。<em class="mp"> IEEE系统、人和控制论汇刊</em>，第6卷，第11期，第769-772页。</p><p id="8058" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">[4]何和马，杨(2013)。<a class="ae jd" href="https://www.wiley.com/en-us/Imbalanced+Learning%3A+Foundations%2C+Algorithms%2C+and+Applications-p-9781118074626" rel="noopener ugc nofollow" target="_blank"> <em class="mp">不平衡学习:基础、算法、应用</em> </a>。第一版。威利。</p><p id="9963" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">[5]曾，m，邹，b，魏，f，刘，x，王，L. (2016)。<a class="ae jd" href="https://ieeexplore.ieee.org/abstract/document/7563084?casa_token=_0SmM6ilaTQAAAAA:sLVb6VptUVi5N8dGd2nMCQuumxpFv0iL66P8gT5Im-xJm58f-OUFMexDf3cEDrSTdPa25RIQuENi" rel="noopener ugc nofollow" target="_blank">结合SMOTE和Tomek links技术对不平衡医疗数据进行有效预测</a>。<em class="mp"> 2016年IEEE在线分析与计算科学国际会议(ICOACS) </em>，第225–228页。</p><p id="6f0f" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">[6] Batista，G. E. A. P. A .，Bazzan，A. L. C .和Monard，M. A. (2003年)。<a class="ae jd" href="http://www.inf.ufrgs.br/maslab/pergamus/pubs/balancing-training-data-for.pdf" rel="noopener ugc nofollow" target="_blank">平衡关键字自动标注的训练数据:案例研究</a>。<em class="mp">第二届巴西生物信息学研讨会会议录</em>，第35-43页。</p><p id="13d4" class="pw-post-body-paragraph lr ls jg lt b lu mk kh lw lx ml kk lz le mm mb mc li mn me mf lm mo mh mi mj ij bi translated">[7]<a class="ae jd" href="https://scikit-learn.org/stable/modules/cross_validation.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/cross _ validation . html</a></p></div></div>    
</body>
</html>