<html>
<head>
<title>How To Do Image Classification The 2021 Way</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何以2021年的方式进行图像分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-do-image-classification-the-2021-way-5962030e48b4?source=collection_archive---------32-----------------------#2021-05-24">https://towardsdatascience.com/how-to-do-image-classification-the-2021-way-5962030e48b4?source=collection_archive---------32-----------------------#2021-05-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e014" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">从型号选择到微调</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9525c35f96e60d4330efce4d18c0f211.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EBTIcrJ8-K2wKwFm"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@grstocks?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> GR Stocks </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="857c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图像分类是计算机视觉中最古老的问题，第一个网络是<a class="ae ky" rel="noopener" target="_blank" href="/alexnet-8b05c5eb88d4"> AlexNet </a>，最新的是<a class="ae ky" href="https://arxiv.org/pdf/2104.00298.pdf" rel="noopener ugc nofollow" target="_blank"> EfficientNetv2 </a>。如今，只要点击一下鼠标，就可以获得所有最先进的模型，测试每一个模型，然后选择最好的一个，就成了一项艰巨的任务。我们将涵盖从型号选择困境到微调狂热的一切。</p><h1 id="be77" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">型号选择</h1><p id="41e2" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">虽然有基于变换器的模型可用，但卷积网络仍然有需求，因为变换器的计算简单，并且它们在图像域中的长期使用已经导致了一些强有力的实践。让我们看看我们唯一的选择。</p><h2 id="8ae6" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">效率网</h2><p id="82bb" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">虽然可以有许多选项(ResNet及其变体等。)，上述模型体系结构与所有其他体系结构不同，因为可以根据您的需要选择各种主干。</p><p id="ce0f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从B0到B7，EfficientNet有8种类型，您可以将其视为超参数。此外，它们在<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>和<a class="ae ky" href="https://github.com/rwightman/pytorch-image-models" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>中均有提供。</p><p id="c53f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">高效网络B3/B4 </strong>是一个很好的起点。</p><p id="0d53" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你有必要的计算，你也可以把这些<strong class="lb iu">主干当作一个超参数</strong>。</p><p id="fc30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除此之外，许多<a class="ae ky" href="https://github.com/mrgloom/Kaggle-Computer-Vision-Competitions-List" rel="noopener ugc nofollow" target="_blank"> Kaggle竞赛</a>已经广泛证明了它们是一个很好的架构。</p><h1 id="147e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">模型微调</h1><p id="d2f1" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">对于微调，应使用以下设置。</p><p id="541c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">学习率</strong> : 3e-5 <br/> <strong class="lb iu">优化器</strong>:亚当<br/> <strong class="lb iu">批量</strong> : 16</p><h2 id="c0de" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">学习率</h2><p id="c94b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">当你微调一个模型时，你不需要很大的学习率。即使这样也会影响表演。3e-5是一个足够低的学习率，可以在微调时给你很好的增益。你也可以看看一个学习率调度器(像<a class="ae ky" href="https://pytorch.org/docs/master/generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html" rel="noopener ugc nofollow" target="_blank">余弦退火和热重启</a>等等。).</p><p id="04db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你仍然不接受这个学习速度，试试使用fastai的<a class="ae ky" href="https://fastai1.fast.ai/callbacks.lr_finder.html" rel="noopener ugc nofollow" target="_blank"> lr_finder </a>功能。</p><h2 id="6ae9" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">【计算机】优化程序</h2><p id="97c5" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">自2014年问世以来，<a class="ae ky" href="https://arxiv.org/abs/1412.6980" rel="noopener ugc nofollow" target="_blank"> Adam </a> optimizer的使用量一直高居榜首。</p><p id="2a5b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还有其他的选择，比如<a class="ae ky" href="https://arxiv.org/abs/1907.08610" rel="noopener ugc nofollow" target="_blank">前瞻亚当</a>、<a class="ae ky" href="https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer" rel="noopener ugc nofollow" target="_blank">游侠</a>、<a class="ae ky" href="https://arxiv.org/abs/2010.01412" rel="noopener ugc nofollow" target="_blank">山姆</a>等等。这将需要你找到新的更好的设置，但上面的那些将在那里工作太漂亮了。</p><h2 id="9cdd" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">批量</h2><p id="aa22" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">由于在EfficientNet和几乎所有其他图像分类模型中使用批处理规范化，使用批处理大小≥ 16对于良好的性能变得必不可少(参见此处的<a class="ae ky" href="https://arxiv.org/pdf/1803.08494.pdf" rel="noopener ugc nofollow" target="_blank"/>)。</p><p id="3aab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于批量，越大越好。虽然，并不是每个人都有这样的计算能力(在一些大型网络中，即使是16个批量也是很困难的)。在这种情况下，尽可能保持较高的批量。</p><h1 id="3f74" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">失败</h1><p id="4819" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">有一件事会彻底改变你的结果，那就是失败。对于图像分类，有哪些选项？<a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy" rel="noopener ugc nofollow" target="_blank">交叉熵</a>是图像分类的首选损失，但它有一个问题。当你有类不平衡时，用交叉熵可能得不到最好的结果。</p><p id="fd2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">几乎总是会收到类别不平衡的数据集，因此，应该使用的损失是<a class="ae ky" href="https://www.tensorflow.org/addons/api_docs/python/tfa/losses/SigmoidFocalCrossEntropy" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">焦点损失</strong> </a>。它有一个超参数<em class="ne"> gamma，</em>，决定对样本数量较少的类的关注程度。</p><h1 id="2a6a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">增大</h1><p id="ccca" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">除了类别不平衡之外，你将面临的另一件事是图像数量的减少(在实际用例中，这将是90%的时间)。为此，你需要考虑增强。毫无疑问，最好的图像增强库是<a class="ae ky" href="https://github.com/albumentations-team/albumentations" rel="noopener ugc nofollow" target="_blank">albuminations</a>。</p><p id="d4ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，在此之前，请对数据中的图像进行广泛的分析，并选择库中可用的最佳增强(有很多！).</p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="7ccc" class="lv lw it bd lx ly nm ma mb mc nn me mf jz no ka mh kc np kd mj kf nq kg ml mm bi translated">结论</h1><p id="1a63" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">计算机视觉领域仍在发展，但随着时间的推移，一些实践已经发展，一些模式已经出现。我根据上面的经验总结了那些模式。希望这有助于快速得到一个好的模型。</p><p id="7451" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">祝一切顺利，神经忍者们。</p></div></div>    
</body>
</html>