<html>
<head>
<title>Zero-Shot Intent Classification with Siamese Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用连体网络的零射击意图分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/zero-shot-intent-classification-with-siamese-networks-35900471c7fd?source=collection_archive---------8-----------------------#2021-09-24">https://towardsdatascience.com/zero-shot-intent-classification-with-siamese-networks-35900471c7fd?source=collection_archive---------8-----------------------#2021-09-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="aa9f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">通过零触发意图分类有效定位域外意图</h2></div><p id="cdd7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">意图识别是面向目标的对话系统的基本任务。意图识别(有时也称为意图检测)是用标签对每个用户话语进行分类的任务，该标签来自预定义的一组标签。</p><p id="0096" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">分类器对标记数据进行训练，并学习区分哪个话语属于哪个类别。如果分类器得到一个看起来不像任何训练发音的发音，有时结果会很尴尬。这就是为什么我们也把<strong class="kh ir">域外</strong>话语归类，它们根本不属于那个域。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/85463ae7578ec64aee82f0055df45c74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CadlfKHwHualA9od3SM-ew.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">分类话语的意图分类器。这里，示例域是机票预订和话语“嘿，兄弟，你是机器人吗？”是一个域外的话语。作者图片</p></figure><p id="43de" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">问题是用户和我们开发者生活在不同的世界里。开发人员希望呆在语义丛林中的安全农场(所谓的域)，但是用户并不十分了解分类器或聊天机器人NLU是如何工作的(他们也不需要了解)。你不能期望用户停留在正确的语义领域，相反，你应该给你的聊天机器人提供处理食物话语的技能。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/9ee835b65ece4f1b9c102845177d8ae6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M2EwPypplfiWR-OcW6NA6A.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">在口语的野性中，你安全的语义农场。你永远不知道什么来自野外！作者图片</p></figure><p id="a131" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我们将讨论如何通过为我们的司机语音助手Chris检测哪些话语属于该领域，哪些话语不属于该领域，来保持我们的领域完好无损。首先，我将介绍克里斯域和话语，然后我们将通过暹罗网络学习文本分类。</p><h2 id="472c" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ko ma mb mc ks md me mf kw mg mh mi mj bi translated">Chris域和数据</h2><p id="e32e" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated"><a class="ae mp" href="https://www.youtube.com/watch?v=Qwnjszu3exY&amp;t=1s" rel="noopener ugc nofollow" target="_blank">克里斯</a>是司机的语音助手。我们的克里斯是司机助理，由<a class="ae mp" href="https://germanautolabs.medium.com/" rel="noopener">德国Autolabs </a>打造。克里斯可以发送/阅读短信、WhatsApp信息、给手机联系人打电话、播放音乐、导航、回复天气查询和闲聊。</p><div class="lc ld le lf gt ab cb"><figure class="mq lg mr ms mt mu mv paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/10c7b5f0cbf478861152471c8393f2dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*iOzkARRlPzrjrfI-tOv8lg.jpeg"/></div></figure><figure class="mq lg mw ms mt mu mv paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><img src="../Images/d16681f13e23ee33bfc9e954ca87ef59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*tWoTI9k6LRnvYLFATcmaag.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk mx di my mz translated">我们的克里斯，在左边。右边是克里斯和他的能力。图片来自德国Autolabs网站。</p></figure></div><p id="0439" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Chris是一个面向任务的对话代理，因此用户的话语通常简明扼要。这些是典型的用户话语:</p><pre class="lc ld le lf gt na nb nc nd aw ne bi"><span id="33c6" class="lr ls iq nb b gy nf ng l nh ni">play music<br/>some music please<br/>stop the music<br/>send a message<br/>send a message to Tess<br/>send a whatsapp<br/>read my messages<br/>do I have any new messages<br/>display the latest message<br/>start the navigation<br/>show navigation<br/>show the map<br/>stop the navigation<br/>nearest gas station<br/>find a parking spot<br/>read it<br/>no cancel<br/>cancel<br/>yes<br/>next<br/>no next<br/>tell me the time<br/>how is the weather today</span></pre><p id="77ad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">意图名由一个子域名和一个动作名组成。以下是一些与上述说法相对应的意图名称:</p><pre class="lc ld le lf gt na nb nc nd aw ne bi"><span id="d54d" class="lr ls iq nb b gy nf ng l nh ni">music.play<br/>music.pause<br/>messages.write<br/>messages.read<br/>navigation.start<br/>navigation.stop<br/>universals.accept<br/>universals.reject<br/>universals.next<br/>misc.time<br/>misc.weather</span></pre><p id="3530" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">域外话语呢？这里也有一些例子:</p><pre class="lc ld le lf gt na nb nc nd aw ne bi"><span id="4516" class="lr ls iq nb b gy nf ng l nh ni">hey siri<br/>launch siri<br/>wake up siri<br/>open my instagram<br/>share my video on instagram<br/>delete my facebook account<br/>play my audibooks<br/>set an alarm<br/>show alarms<br/>please delete all alarms<br/>open the doors</span></pre><p id="e558" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要求一些你的聊天机器人根本不具备的能力，完全是正常用户的行为。例如，克里斯根本不具备打开车门的技能。即使UX团队在每个包装中都包含了关于克里斯技能的指南，用户也可能会跳过阅读😄这就是为什么你的聊天机器人NLU应该随时准备处理大量的域外话语，用户要求他们可以想象你的聊天机器人可以实现的能力，而不是用户手册中写的那些。</p><p id="06fc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">乍一看，简短的话语可能看起来“容易”，但也有一定的挑战。语音识别错误可能会造成困难，尤其是在简短的话语中，因为话语中可能会丢失语义上至关重要的单词(如“播放音乐”中的“播放”)。此外，语音引擎必须在正确的时间开始监听，否则它可能会错过单个单词的简短话语，如“是”、“否”，这些话语对于解析上下文至关重要。在WER方面，只缺少3个字母看起来不像是一个很大的ASR错误，但是如果您的代理多次要求用户批准，这可能会给用户带来挫败感。所有语音机器人都有声学和语义方面的挑战，永远不要低估语音工作的挑战。</p><h2 id="f50c" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ko ma mb mc ks md me mf kw mg mh mi mj bi translated">什么是零拍文本分类？</h2><p id="930e" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">零短文本分类的任务是在一组类别标签上训练分类器，并用分类器在训练集中看不到的类别标签测试分类器。NLP最近的工作集中在更广泛的背景下的零射击学习，零射击学习NLP现在意味着<em class="nj">训练一个模型去做它没有明确训练过的任务。GPT-3是一个零射击学习者，吸引了相当多的注意力。</em></p><p id="0b7b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在零镜头分类中，我们用一些视觉线索或类名向分类器描述一个看不见的类。对于零镜头文本分类，通常使用意图名来描述意图的语义。当我第一次开始做克里斯NLU，数据是为了“通常”的意图分类。然后我开始尝试ood，发现我们的类命名方案<strong class="kh ir">domain . action</strong>(music . play，navigation.start等)的确<em class="nj">非常适合零镜头学习</em>。</p><h2 id="e42e" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ko ma mb mc ks md me mf kw mg mh mi mj bi translated">将标签和话语嵌入同一个空间</h2><p id="8914" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">零镜头文本分类中的一种常见方法是将意图名称和话语嵌入到同一空间中。这样，零拍算法可以通过语义组学习意图名称和话语之间的语义关系，就像我们人类一样。这根本不是一个新的想法，研究人员使用词向量来表示固定维度中的文本和意图名称(例如在<a class="ae mp" href="https://www.esann.org/sites/default/files/proceedings/legacy/es2016-174.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="nj"> Veeranna中)。2016 </em> </a>)。随着变形金刚的发明，密集表示经历了一场革命，现在我们有了更多高质量的句子和单词嵌入。</p><p id="6103" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们的研究中，我们首先使用平均池单词向量来表示话语，然后使用BERT来编码我们的话语以生成话语向量。首先，让我们看看当我们使用单词向量时，意图名称是如何与话语结合在一起的。我们使用100维手套向量。我们通过平均单词的单词向量来为话语生成句子嵌入。为了获得标签的嵌入(例如，music.play)，我们对域(音乐)和动作(播放)的嵌入进行了平均。在为所有话语生成嵌入之后，我们用t-SNE将我们的数据集转换成二维(用于可视化目的)。以下散点图显示了所有数据集话语和意图名称，具有相同意图的话语用相同的颜色着色:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nk"><img src="../Images/6fa074964b070321e3d117b3057e4842.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l27usjTkQrFH_9NKLc_fXw.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">克里斯说，每种颜色都代表一种意图</p></figure><p id="6a8f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是话语和意图名称的对齐方式:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nk"><img src="../Images/79187963b73953e869a5fec0f9a8f7a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ffGcyJmNz81cUeSkSpXhg.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">将意图名称和话语嵌入到同一空间中</p></figure><p id="1cad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们放大一点，我们会看到意图名称和相应的话语确实排列得很好:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nk"><img src="../Images/1746ae451f0177ed47fd5752f6350744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oHQXhjA-y_JKbQ5IE7WxrQ.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">放大上面的图像</p></figure><p id="0960" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据集的话语创建了一个相当漂亮的散点图，没有太多的离群值，相同意图的话语与意图名称组合在一起。</p><p id="9bad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们想用BERT来嵌入话语和意图名称呢？这对表达很有效，但是意图名不是真正的句子和简短的表达。BERT是为完整的句子而训练的，对于像我们的意图名这样的短表达可能不太管用。在这种情况下，我们可以通过BERT为话语创建768维嵌入，通过词向量为意图名称创建100维嵌入。为了将它们嵌入到同一空间中，我们需要计算一个投影矩阵ϕ，将768维话语向量投影到100维意图向量上。因为我们有带注释的数据，我们可以通过回归学习投影矩阵。(尽管包含正则化以防止过度拟合很重要)。然后，我们有一个类似于上面的视觉对齐。</p><p id="15c2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">用于零镜头文本分类的连体网络</strong></p><p id="024e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面的探索性数据分析向我们展示了意图名称和话语之间的语义相似性是非常明显和可学习的。然后，我们可以让一个连体神经网络学习意图名称和话语之间的相似性。</p><p id="37e1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">传统的意图分类器输入话语并生成类别标签。通常我们用LSTM或伯特对话语进行编码，然后将编码后的话语送入密集层，得到一个类别标签:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/4029c1278e5d3f42bc3c347d2e360dd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TKr87tsYqBo0kK2PHVa6OQ.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">传统的意图分类器。图片bu作者</p></figure><p id="5943" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">相反，我们的零触发意图分类器学习标签和话语是否语义相似。我们使用了暹罗网络架构，这对于计算语义相似度非常有用。我们的暹罗网络输入一个意向名称和一个话语；输入相关或不相关时的输出。</p><p id="ce39" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">架构和我在<a class="ae mp" rel="noopener" target="_blank" href="/siamese-nn-recipes-with-keras-72f6a26deb64">上一篇暹罗NN文章</a>中描述的一样。该架构包括</p><ul class=""><li id="593f" class="nl nm iq kh b ki kj kl km ko nn ks no kw np la nq nr ns nt bi translated">编码话语和标签的LSTM/伯特层</li><li id="30d4" class="nl nm iq kh b ki nu kl nv ko nw ks nx kw ny la nq nr ns nt bi translated">随后是距离层以计算话语和标签之间的语义距离</li><li id="0204" class="nl nm iq kh b ki nu kl nv ko nw ks nx kw ny la nq nr ns nt bi translated">最后一个密集层挤压距离矢量到一个二进制值</li></ul><p id="5622" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这种结构仍然是一个文本分类器，但这次输入的数量是2，输出向量的维数只有1。输出是二进制的，0表示标签和话语不相关；1表示话语属于该标签的类别。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/2849f781cdb73cf57d9be684e5c759cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aHWz3tyAskA2D4V6xgSMCw.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">连体零射击意图分类器。作者图片</p></figure><p id="d897" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">只要我们能够为标签提供良好的嵌入，我们就可以向暹罗分类器请求我们想要的任何标签(即使分类器以前从未见过这个标签)。这对于域外的话语来说是非常好的，因为即使你没有任何ood类的标记数据或者只有几个例子，暹罗零镜头分类器仍然可以决定一个话语是与Chris域相关还是与该域不相关。</p><p id="c8d4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">暹罗网络在很长一段时间内被用于语义相似性，然而玩一些技巧可以带我们到一个毫不费力的零射击意图预测模型。有时候想法一直在你眼前，但你得换个角度去看。</p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><p id="a641" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本文中，我们继承了一种全新的方法来解决“传统的”意图分类问题。首先，我们对克里斯的话语进行了语义分组。然后，我们刷新了我们关于暹罗网络的知识。最后，我们看到了如何使用暹罗网络进行零镜头分类。</p><p id="0cc4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我希望所有读者喜欢我们的Chris的能力和数据，并希望在更多的Chris文章中与您见面。在那之前，请继续关注健康的❤️</p><h2 id="7fe6" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ko ma mb mc ks md me mf kw mg mh mi mj bi translated">参考</h2><ul class=""><li id="1650" class="nl nm iq kh b ki mk kl ml ko og ks oh kw oi la nq nr ns nt bi translated">语言模型是很少出手的学习者，【https://arxiv.org/abs/2005.14165 T2】</li><li id="0d7c" class="nl nm iq kh b ki nu kl nv ko nw ks nx kw ny la nq nr ns nt bi translated">预应变变压器在意图分类方面是否稳健？<br/>超范围意图检测评估中缺失的成分<a class="ae mp" href="https://arxiv.org/pdf/2106.04564.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2106.04564.pdf</a></li><li id="2801" class="nl nm iq kh b ki nu kl nv ko nw ks nx kw ny la nq nr ns nt bi translated">检测发给虚拟个人助理的域外话语<a class="ae mp" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2014/09/IS14-Orphan2.pdf" rel="noopener ugc nofollow" target="_blank">https://www . Microsoft . com/en-us/research/WP-content/uploads/2014/09/IS14-orphan 2 . pdf</a></li><li id="8e62" class="nl nm iq kh b ki nu kl nv ko nw ks nx kw ny la nq nr ns nt bi translated">利用语义相似度对文本文档进行多标签零炮<br/>分类，<a class="ae mp" href="https://www.esann.org/sites/default/files/proceedings/legacy/es2016-174.pdf" rel="noopener ugc nofollow" target="_blank">https://www . esann . org/sites/default/files/proceedings/legacy/es 2016-174 . pdf</a></li></ul></div></div>    
</body>
</html>