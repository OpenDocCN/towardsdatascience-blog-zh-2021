<html>
<head>
<title>Configure a CNN Model using Traditional Machine Learning Algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用传统的机器学习算法配置CNN模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/configure-a-cnn-model-using-traditional-machine-learning-algorithms-ac31a11e1c12?source=collection_archive---------21-----------------------#2021-09-29">https://towardsdatascience.com/configure-a-cnn-model-using-traditional-machine-learning-algorithms-ac31a11e1c12?source=collection_archive---------21-----------------------#2021-09-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a94a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">将集成学习算法应用于影像数据集，影像数据集是通过python实现由卷积图层提取的要素</h2></div><pre class="ki kj kk kl gt km kn ko kp aw kq bi"><span id="987b" class="kr ks it kn b gy kt ku l kv kw"><strong class="kn iu"><em class="kx">Table of Contents<br/></em>1. Introduction<br/>2. </strong><a class="ae ky" href="#096c" rel="noopener ugc nofollow"><strong class="kn iu">Layers</strong></a><strong class="kn iu"><br/>2.1. Convolutional Layer<br/>2.2. Pooling Layer<br/>2.3. Dropout Layer<br/>2.4. Flatten Layer<br/>3. </strong><a class="ae ky" href="#5928" rel="noopener ugc nofollow"><strong class="kn iu">Tutorial</strong></a><strong class="kn iu"><br/>3.1. Dense Layer Approach<br/>3.2. Ensemble Learning Approach<br/>4. Results<br/>5. </strong><a class="ae ky" href="#bab4" rel="noopener ugc nofollow"><strong class="kn iu">Discussion</strong></a></span></pre><h1 id="7d0e" class="kz ks it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">1.介绍</h1><p id="7192" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在传统的机器学习应用中，在对数据集应用必要的数据预处理过程之后，它主要被转换成<em class="kx"> (n_samples，n_features) </em>并应用该算法。为了避免过拟合和欠拟合等情况，样本的数量应该很大。为了防止这种情况，或者通过各种方法来扩展图像数据集的图像扩充，或者应用诸如特征提取、特征选择或维数减少的方法。</p><p id="68a5" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">卷积神经网络(CNN)是一种深度学习方法，主要用于图像数据集。它通过用人工神经网络训练模型来用于分类。当我们处理该模型时，给定图像数据集的特征与其结构中的层一起被提取，并且这些获得的特征由诸如密集层的各种层训练。</p><p id="19c1" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">本文包括如何使用集成学习算法对使用卷积层提取特征的图像数据集进行分类。python实现丰富了这项工作。</p><figure class="ki kj kk kl gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi mr"><img src="../Images/61ae54ad7d21d9b1b0e405012b76a5c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*q7RfoBkt-PZ4fFBy"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@yuridfv?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">尤里·赛洛斯</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="096c" class="kz ks it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">2.层</h1><p id="ff97" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">首先，让我们简要了解一下在构建本教程中使用的模型时使用的图层:</p><h2 id="1cff" class="kr ks it bd la nd ne dn le nf ng dp li lz nh ni lk md nj nk lm mh nl nm lo nn bi translated">2.1.卷积层</h2><p id="b748" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">卷积层是卷积神经网络(CNN)的主要构件。它们将像素值作为输入，并执行特征提取。它由过滤器和内核组成。学习是通过从数据集中提取一个子集，然后对其进行过滤和处理来进行的。利用线性乘法来执行这些处理，并且提取关于图像的诸如边缘检测之类的特征。图1显示了由具有不同内核的<em class="kx"> cv2库</em>提供的梯度滤波器的应用。</p><figure class="ki kj kk kl gt ms"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="ki kj kk kl gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi nq"><img src="../Images/e111c4a7a5c38f8692546285b2f680a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BTiHtaosowpz1aBvbT1Y4A.jpeg"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">图一。内核在渐变滤镜中的效果，图片作者</p></figure><p id="8c43" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">如果我们再深入一步，这个过程是如何发生的？如上所述，它是一个简单的数学运算，名为卷积。用数学来说明:</p><p id="3cc3" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">输入= [ 5 10 15 20 25 30]</p><p id="4c9b" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">过滤器= [0 1 0]</p><p id="2eb0" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">输出计算如下:</p><pre class="ki kj kk kl gt km kn ko kp aw kq bi"><span id="07a4" class="kr ks it kn b gy kt ku l kv kw">[5 10 15]  . [0 1 0] = 10<br/>[10 15 20] . [0 1 0] = 15<br/>[15 20 25] . [0 1 0] = 20<br/>[20 25 30] . [0 1 0] = 25</span></pre><p id="1ed2" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">过滤后的矩阵，即<strong class="ls iu">输出为【10 15 20 25】</strong>。这个过程也可以作为2D卷积层多样化。</p><h2 id="f4b8" class="kr ks it bd la nd ne dn le nf ng dp li lz nh ni lk md nj nk lm mh nl nm lo nn bi translated">2.2.汇集层</h2><p id="2197" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">汇集层对卷积层之后获得的矩阵值执行各种操作。平均池取确定的矩阵大小中像素值的平均值，而顾名思义，最大池取最大值。如图2所示，通过使用2x2池，4x4矩阵已经缩小到2x2大小。它概括了特定区域的特征，降低了特征的维数。这样，在模型变得更加通用的同时，避免了<strong class="ls iu">过拟合</strong>。</p><figure class="ki kj kk kl gt ms gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/125256be62eb52c02de7a180857ccc8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*k5wxI8SOJzAfGonAopncqA.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated">图二。最大池(左)和平均池(右)是做什么的？，<a class="ae ky" href="https://www.researchgate.net/figure/Illustration-of-Max-Pooling-and-Average-Pooling-Figure-2-above-shows-an-example-of-max_fig2_333593451" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h2 id="126b" class="kr ks it bd la nd ne dn le nf ng dp li lz nh ni lk md nj nk lm mh nl nm lo nn bi translated">2.3.脱落层</h2><p id="955d" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">用最简单的话来说，它删除了图3中获得的一些特征，也就是说，它导致了信息丢失。如果我们处理128×128×3的RGB图像，并考虑像素是图像数据集的特征，我们将有大约50000个特征。通过申请退学，可以放弃其中的一些功能。这样，也防止了<strong class="ls iu">过拟合</strong>。</p><figure class="ki kj kk kl gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi ns"><img src="../Images/271f29855451434f956c71d7870a3a4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yIGb-kfxCAK0xiXipo6utA.png"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">图3。辍学层是做什么的？，<a class="ae ky" href="https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5" rel="noopener">来源</a></p></figure><h2 id="996f" class="kr ks it bd la nd ne dn le nf ng dp li lz nh ni lk md nj nk lm mh nl nm lo nn bi translated">2.4.展平图层</h2><p id="2787" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">扁平化层用于CNN模型第一部分的最后一层，该模型将矩阵形状从3x3转换为9x1，如图4所示，以便为通过完全连接的层进行分类准备数据集。</p><figure class="ki kj kk kl gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi nt"><img src="../Images/f6020617a353b1b3a6d0a3bf7465e18a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Cb1dzBhciwRi9y1-J6qjQ.png"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">图4。展平图层是做什么的？，<a class="ae ky" href="https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-3-flattening" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><h1 id="5928" class="kz ks it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">3.辅导的</h1><p id="7fba" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在图像的特征之后，使用卷积层提取数据集，这些特征分别由密集层和集成学习算法训练。讨论了实现和结果。</p><blockquote class="nu nv nw"><p id="aad4" class="lq lr kx ls b lt mm ju lv lw mn jx ly nx mo mb mc ny mp mf mg nz mq mj mk ml im bi translated">可以通过<a class="ae ky" href="https://github.com/theibrr/kitchenware" rel="noopener ugc nofollow" target="_blank">链接</a>访问数据集。</p></blockquote><h2 id="37b0" class="kr ks it bd la nd ne dn le nf ng dp li lz nh ni lk md nj nk lm mh nl nm lo nn bi translated">3.1.密集层方法</h2><p id="94b7" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">该数据集由233个样本组成，包含杯子、盘子、碟子，被训练用于分类。首先，使用图像增强过程来扩展数据集。在应用数据预处理过程之后，它被分成训练集和测试集。训练数据集使用如下构建的模型进行训练:</p><figure class="ki kj kk kl gt ms"><div class="bz fp l di"><div class="no np l"/></div></figure><ul class=""><li id="8488" class="oa ob it ls b lt mm lw mn lz oc md od mh oe ml of og oh oi bi translated"><strong class="ls iu"> [1] -图像放大、调整大小和缩放</strong></li></ul><p id="5248" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">预定义的图像增强过程重复15次，并且样本数量增加大约3500。数据集中的所有图像都调整为128 x 128像素，每个像素除以255进行缩放。</p><ul class=""><li id="f99c" class="oa ob it ls b lt mm lw mn lz oc md od mh oe ml of og oh oi bi translated"><strong class="ls iu">【2】-型号</strong></li></ul><p id="de2d" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">CNN模型由两个主要部分组成。使用<code class="fe oj ok ol kn b">‘model’</code>提取特征，它作为第一个组件按顺序构建。由于像素是图像数据集的特征，并且图像的形状是128×128×3，所以特征的总数是49152。输入形状在第一卷积层中定义。在接下来的卷积层中，<code class="fe oj ok ol kn b"> L1 &amp; L2 regularizations</code>被用于防止<strong class="ls iu">过拟合</strong>。<em class="kx">L1&amp;L2正则化的作用是调整权重的重要性，因此可以假设卷积层的正则化参数是层的学习速率。</em>此外，以不同的速率应用<code class="fe oj ok ol kn b">Dropout </code>以防止<strong class="ls iu">过拟合</strong>，最后，使用<code class="fe oj ok ol kn b">Flatten layer</code>将模型的形状转换为(n_samples，n_features)。该模型的概要如图5所示。</p><figure class="ki kj kk kl gt ms gh gi paragraph-image"><div class="gh gi om"><img src="../Images/6902be5d2f6c41c0bb4d10c2856182b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*_6fDaagYPlZ0paH-IDKg-g.png"/></div><p class="mz na gj gh gi nb nc bd b be z dk translated">图5。模型摘要，图片由作者提供</p></figure><p id="3f91" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">查看展平层的输出形状，可以看到，开始时的特征数为49152，使用层后为1728。</p><p id="2dca" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">在模型的第二部分中，在提取特征之后，应用密集层来执行分类过程。最后，通过组合输入(<strong class="ls iu">是提取特征的部分</strong>)和输出(<strong class="ls iu">是进行分类的部分</strong>)来创建“T4”。</p><ul class=""><li id="c479" class="oa ob it ls b lt mm lw mn lz oc md od mh oe ml of og oh oi bi translated"><strong class="ls iu">【3】-模型评估</strong></li></ul><p id="5e8f" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">准备混淆矩阵和测试数据集的分类报告来评估模型。</p><ul class=""><li id="9cca" class="oa ob it ls b lt mm lw mn lz oc md od mh oe ml of og oh oi bi translated"><strong class="ls iu">【4】——模型泛化性能</strong></li></ul><p id="89ed" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">使用google images随机下载了15张杯子和盘子的图像，并用训练好的模型进行预测，以测试模型的泛化性能。</p><h2 id="2244" class="kr ks it bd la nd ne dn le nf ng dp li lz nh ni lk md nj nk lm mh nl nm lo nn bi translated">3.2.集成学习方法</h2><p id="2794" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在引言句中已经提到，机器学习中的数据集是以<em class="kx"> (n_samples，n_features) </em>的格式进行训练的。在这一部分中，应用了集成学习算法，但是可以使用任何分类算法来代替。查看图5中的展平图层，可以看到它被提取为1728个要素。在这一部分中，分类过程使用集成学习算法而不是密集层来完成，如下所示:</p><figure class="ki kj kk kl gt ms"><div class="bz fp l di"><div class="no np l"/></div></figure><ul class=""><li id="82ac" class="oa ob it ls b lt mm lw mn lz oc md od mh oe ml of og oh oi bi translated">[1]-通过CNN模型的第一部分<code class="fe oj ok ol kn b">‘model’</code>预测训练集、测试集和外部测试集，并创建派生数据集。</li><li id="9e0a" class="oa ob it ls b lt on lw oo lz op md oq mh or ml of og oh oi bi translated">[2]-创建包含混淆矩阵结果的函数，以便应用所有算法。</li><li id="cd18" class="oa ob it ls b lt on lw oo lz op md oq mh or ml of og oh oi bi translated">[3]- XGBoost、LGBM、基于直方图的GB、ExtraTree、AdaBoost、Bagging算法在其基础版本中用于分类。</li></ul><h1 id="f7de" class="kz ks it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">4.结果</h1><p id="e349" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">密集层方法的混淆矩阵如图6所示。</p><figure class="ki kj kk kl gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi os"><img src="../Images/cbfff1849bfda02204eb5d458cc4a948.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EVlW66Lx5RNFclsBlDrX3g.png"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">图6。测试集的混淆矩阵(左)，外部测试集的混淆矩阵(右)，图片作者</p></figure><p id="1bc1" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">可以看出，在测试数据集中实现了91%的成功，而在外部测试数据集中获得了13/15的准确性，该外部测试数据集是从不同的源随机生成的，用于模型泛化性能。</p><p id="322c" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">集成学习方法的结果如图7所示。</p><figure class="ki kj kk kl gt ms gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi ot"><img src="../Images/14a9973299ddecfa9157d47baf57c348.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VL4nVMPOdBqHa18batBZAA.png"/></div></div><p class="mz na gj gh gi nb nc bd b be z dk translated">图7。集成学习算法的结果，图片由作者提供</p></figure><p id="a1b3" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">可以看出，尽管测试数据集精度高，但是在外部测试数据集中获得了低精度结果。这表示<strong class="ls iu">过拟合</strong>。</p><h1 id="bab4" class="kz ks it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">5.讨论</h1><p id="6df5" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">由于这项研究主要是关于开发一个CNN模型，它不是集中在集成学习方法。然而，可以看出，尽管没有调整超参数，但是这些方法中的一些，例如XGBoost，具有令人满意的结果。</p><p id="3235" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">有必要了解它是如何工作的，以促进卷积神经网络的应用。本文旨在提供不同的选择和灵活性。有可能提高在集成学习算法中获得的准确性结果，例如使用GridSearch检测超参数的最佳组合或扩展数据集。深度学习中的CNN模型在图像数据集上的效果无可争议地好，但当作为替代方案进行研究时，这种方法甚至可以被评估用于不同的目的。</p></div><div class="ab cl ou ov hx ow" role="separator"><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz"/></div><div class="im in io ip iq"><h2 id="53c6" class="kr ks it bd la nd ne dn le nf ng dp li lz nh ni lk md nj nk lm mh nl nm lo nn bi translated">回到指引点击<a class="ae ky" href="https://ibrahimkovan.medium.com/machine-learning-guideline-959da5c6f73d" rel="noopener">这里</a>。</h2><div class="pb pc gp gr pd pe"><a href="https://ibrahimkovan.medium.com/machine-learning-guideline-959da5c6f73d" rel="noopener follow" target="_blank"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd iu gy z fp pj fr fs pk fu fw is bi translated">机器学习指南</h2><div class="pl l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">所有与机器学习相关的文章</h3></div><div class="pm l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">ibrahimkovan.medium.com</p></div></div><div class="pn l"><div class="po l pp pq pr pn ps mx pe"/></div></div></a></div><div class="pb pc gp gr pd pe"><a rel="noopener follow" target="_blank" href="/comprehensive-guide-for-principal-component-analysis-7bf2b4a048ae"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd iu gy z fp pj fr fs pk fu fw is bi translated">主成分分析综合指南</h2><div class="pl l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">用python实现主成分分析的理论和实践部分</h3></div><div class="pm l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">towardsdatascience.com</p></div></div><div class="pn l"><div class="pt l pp pq pr pn ps mx pe"/></div></div></a></div></div></div>    
</body>
</html>