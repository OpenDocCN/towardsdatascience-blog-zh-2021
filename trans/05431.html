<html>
<head>
<title>Sentiment Analysis using Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用分类的情感分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sentiment-analysis-using-classification-e73da5b4159f?source=collection_archive---------30-----------------------#2021-05-13">https://towardsdatascience.com/sentiment-analysis-using-classification-e73da5b4159f?source=collection_archive---------30-----------------------#2021-05-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8e0d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何根据历史数据计算情感得分</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/af8840dbd44ebf1d3d2fc14bd5666225.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Armq-dUszgJa2BCvXocBpg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">阴阳咖啡由亚历克斯从<a class="ky kz ep" href="https://medium.com/u/2053395ac335?source=post_page-----e73da5b4159f--------------------------------" rel="noopener" target="_blank"> Unsplash </a></p></figure><p id="057c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">情感分析是一种常用的文本分析技术，用于确定文本是正面的、负面的还是中性的。它可以用来了解观众的满意度，也是一个很好的预测功能。如果您有一个标记良好的数据集(带有基本事实情感得分)，您可以考虑使用文本分类来计算情感得分。</p><h2 id="da05" class="lw lx it bd ly lz ma dn mb mc md dp me lj mf mg mh ln mi mj mk lr ml mm mn mo bi translated">使用分类的好处:</h2><ol class=""><li id="7071" class="mp mq it lc b ld mr lg ms lj mt ln mu lr mv lv mw mx my mz bi translated">分类的使用<strong class="lc iu">可以从特定于行业或主题的历史数据</strong>中自动捕获模式。你不需要搜索特定主题的肯定或否定单词列表。</li><li id="741a" class="mp mq it lc b ld na lg nb lj nc ln nd lr ne lv mw mx my mz bi translated">包含不同的词袋计算作为情感分类的特征更加方便，因为您可以在现有的包中直接定义它。像“不好”和“不喜欢”这样的否定短语是可以捕捉到的，但是你自己很难捕捉到所有这些短语。</li><li id="2742" class="mp mq it lc b ld na lg nb lj nc ln nd lr ne lv mw mx my mz bi translated">有很多现有的分类算法供你选择。最佳拟合模型的潜力很大。</li></ol><blockquote class="nf"><p id="6da2" class="ng nh it bd ni nj nk nl nm nn no lv dk translated">唯一的缺点是:你需要有标签数据！</p></blockquote><h1 id="717c" class="np lx it bd ly nq nr ns mb nt nu nv me jz nw ka mh kc nx kd mk kf ny kg mn nz bi translated">资料组</h1><p id="00a6" class="pw-post-body-paragraph la lb it lc b ld mr ju lf lg ms jx li lj oa ll lm ln ob lp lq lr oc lt lu lv im bi translated">我们使用的数据是Yelp标记的数据集，来自<a class="ae od" href="https://www.kaggle.com/ilhamfp31/yelp-review-dataset" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>。第一列是评论文本，第二列是情感分数的基本事实(1是负面情感，2是正面情感)</p><p id="1949" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">首先，让我们将数据集分成训练集和测试集(您可以根据您拥有的数据量来决定test_size)。如果你有一个足够大的数据集，你可以选择降低测试集的比例。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="5fb5" class="lw lx it of b gy oj ok l ol om">from sklearn.model_selection import train_test_split<br/>Y=sample_new['rating']<br/>X=sample_new['review']<br/>X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)</span></pre><h1 id="50ce" class="np lx it bd ly nq nr ns mb nt nu nv me jz on ka mh kc oo kd mk kf op kg mn nz bi translated">数据预处理</h1><p id="0b7e" class="pw-post-body-paragraph la lb it lc b ld mr ju lf lg ms jx li lj oa ll lm ln ob lp lq lr oc lt lu lv im bi translated">这里我们使用了两个sklearn包:</p><ol class=""><li id="7579" class="mp mq it lc b ld le lg lh lj oq ln or lr os lv mw mx my mz bi translated"><a class="ae od" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">计数矢量器</strong> </a>:将文本转换成令牌计数矩阵。令牌可以是单个单词或2-gram或3-gram短语。它还允许您在参数中指定n_gram范围、停用词移除等。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/6ce3da8e6a0f42289b3dd6f18e001902.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cmBN-hO1_dVThPaHn8mMqA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">CountVectorizer(单个单词标记)后的两个评论句子示例</p></figure><p id="7547" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">2.<a class="ae od" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu"> TfidfTransformer </strong> </a>:这里我们需要先了解一下TF-IDF。TF-IDF全称是‘词频-逆文档频’。术语频率是指单词或短语在整个文本中出现的频率。然而，如果一个术语出现得太频繁，那么它传达的有用信息就少了，TF-IDF计算使用对数函数<strong class="lc iu">缩小出现得太频繁的术语</strong>。你也可以选择只使用词频来代替。</p><blockquote class="nf"><p id="d532" class="ng nh it bd ni nj ou ov ow ox oy lv dk translated">TF-IDF(术语，文档)=术语频率(术语，文档)*日志(文档总数/(文档频率+ 1))</p></blockquote><p id="2af0" class="pw-post-body-paragraph la lb it lc b ld oz ju lf lg pa jx li lj pb ll lm ln pc lp lq lr pd lt lu lv im bi translated">例如，数据科学文章通常包含“数据”一词。但是，它通常不会告诉你文章的观点(只是一个笼统的词)。TF-IDF transformer基本上<strong class="lc iu">把字数矩阵转换成频率矩阵</strong>。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="6006" class="lw lx it of b gy oj ok l ol om">from sklearn.feature_extraction.text import CountVectorizer<br/>vectorize = CountVectorizer(ngram_range=(1,2))<br/>X_train_counts=vectorize.fit_transform(X_train)</span><span id="e0d3" class="lw lx it of b gy pe ok l ol om">from sklearn.feature_extraction.text import TfidfTransformer<br/>tfidf_transformer = TfidfTransformer()<br/>X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)<br/>X_train_tfidf.shape</span><span id="4bb4" class="lw lx it of b gy pe ok l ol om">#(24000, 44563)</span></pre><p id="c57e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这里，我在ngram_range参数中将标记指定为单个单词或2-gram单词(可以根据需要将(1，2)改为n_gram)，最后输出频率矩阵作为分类的特征。</p><h1 id="ec85" class="np lx it bd ly nq nr ns mb nt nu nv me jz on ka mh kc oo kd mk kf op kg mn nz bi translated">分类模型和评估</h1><blockquote class="pf pg ph"><p id="b51b" class="la lb pi lc b ld le ju lf lg lh jx li pj lk ll lm pk lo lp lq pl ls lt lu lv im bi translated">最后，建模部分</p></blockquote><p id="abed" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">对于使用什么没有限制，您可以对整个数据集进行采样，并查看哪个模型在准确性或其他评估指标方面最适合该样本。你可以在这里<a class="ae od" rel="noopener" target="_blank" href="/top-5-metrics-for-evaluating-classification-model-83ede24c7584">参考</a>如何评估你的分类模型。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="75bd" class="lw lx it of b gy oj ok l ol om">from sklearn.linear_model import LogisticRegression<br/>lr=LogisticRegression().fit(X_train_tfidf, Y_train)</span><span id="eb70" class="lw lx it of b gy pe ok l ol om">X_test_count=vectorize.transform(X_test)<br/>X_test_tfidf=tfidf_transformer.transform(X_test_count)predicted=lr.predict(X_test_tfidf)</span><span id="5eaa" class="lw lx it of b gy pe ok l ol om">#evaluate accuracy<br/>np.mean(predicted == Y_test)<br/>#0.89883</span></pre><p id="8ba9" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">逻辑回归给出了几乎90%的准确率</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="a5f5" class="lw lx it of b gy oj ok l ol om">from sklearn import svm<br/>from sklearn.pipeline import Pipeline</span><span id="85f0" class="lw lx it of b gy pe ok l ol om">text_svm = Pipeline([<br/>     ('vectorize', CountVectorizer()),<br/>     ('tfidf', TfidfTransformer()),<br/>     ('svm', svm.SVC()),<br/> ])</span><span id="6c2d" class="lw lx it of b gy pe ok l ol om">text_svm.fit(X_train,Y_train)<br/>predicted=text_svm.predict(X_test)<br/>np.mean(predicted==Y_test)<br/>#0.9</span></pre><p id="807e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这里我使用了sklearn包管道将所有进程组合在一起。支持向量机精确地给出90%的准确度。</p><pre class="kj kk kl km gt oe of og oh aw oi bi"><span id="5279" class="lw lx it of b gy oj ok l ol om">from sklearn.neural_network import MLPClassifier<br/>text_nn = Pipeline([<br/>     ('vectorize', CountVectorizer()),<br/>     ('tfidf', TfidfTransformer()),<br/>     ('nn', MLPClassifier(solver='lbfgs', alpha=1e-5,<br/>                     hidden_layer_sizes=(5, 2), random_state=1)),<br/> ])</span><span id="aa36" class="lw lx it of b gy pe ok l ol om">text_nn.fit(X_train,Y_train)<br/>predicted=text_nn.predict(X_test)<br/>np.mean(predicted==Y_test)<br/>#0.88167</span></pre><p id="f5d8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">深度学习MLP分类器可以达到88%左右</p><h1 id="1c8b" class="np lx it bd ly nq nr ns mb nt nu nv me jz on ka mh kc oo kd mk kf op kg mn nz bi translated">进一步改进</h1><ol class=""><li id="0753" class="mp mq it lc b ld mr lg ms lj mt ln mu lr mv lv mw mx my mz bi translated"><strong class="lc iu">count vectorizer</strong>的参数调整:n_gram_range、最大/最小文档频率等参数，用于检索分类的理想频率得分。这需要对数据集有很好的理解，也需要一些反复试验来达到理想的输出</li><li id="9490" class="mp mq it lc b ld na lg nb lj nc ln nd lr ne lv mw mx my mz bi translated"><strong class="lc iu">分类模型的参数调整</strong>:您可以使用grid_search或random search之类的搜索方法，在准确性或其他指标方面找到最佳的参数集。这将导致整个过程运行更长时间。</li><li id="7890" class="mp mq it lc b ld na lg nb lj nc ln nd lr ne lv mw mx my mz bi translated"><strong class="lc iu">分类模型评估:</strong>评估多个指标的性能，如召回率、精确度，而不仅仅是准确度</li></ol><h1 id="4539" class="np lx it bd ly nq nr ns mb nt nu nv me jz on ka mh kc oo kd mk kf op kg mn nz bi translated">结论</h1><p id="4266" class="pw-post-body-paragraph la lb it lc b ld mr ju lf lg ms jx li lj oa ll lm ln ob lp lq lr oc lt lu lv im bi translated">数据量对于分类性能非常重要。如果没有足够大的数据集，不要让模型太复杂，因为有<strong class="lc iu">过度拟合</strong>的风险。此外，对数据的初步理解很重要，在做所有这些工作之前，你应该拿出一些样本文本来更多地了解数据的模式。</p><p id="2afb" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">最后，如果你没有带标签的数据，想看看如何通过计算正面/负面词汇来计算情感得分，你可以参考我下面的另一篇文章。</p><div class="pm pn gp gr po pp"><a rel="noopener follow" target="_blank" href="/design-your-own-sentiment-score-e524308cf787"><div class="pq ab fo"><div class="pr ab ps cl cj pt"><h2 class="bd iu gy z fp pu fr fs pv fu fw is bi translated">设计你自己的情感分数</h2><div class="pw l"><h3 class="bd b gy z fp pu fr fs pv fu fw dk translated">熊猫的情感分析</h3></div><div class="px l"><p class="bd b dl z fp pu fr fs pv fu fw dk translated">towardsdatascience.com</p></div></div><div class="py l"><div class="pz l qa qb qc py qd ks pp"/></div></div></a></div></div></div>    
</body>
</html>