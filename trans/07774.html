<html>
<head>
<title>Getting started with Azure Data Explorer and Azure Synapse Analytics for Big Data processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">开始使用Azure Data Explorer和Azure Synapse Analytics进行大数据处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-started-with-azure-data-explorer-and-azure-synapse-analytics-for-big-data-processing-25500821e370?source=collection_archive---------12-----------------------#2021-07-16">https://towardsdatascience.com/getting-started-with-azure-data-explorer-and-azure-synapse-analytics-for-big-data-processing-25500821e370?source=collection_archive---------12-----------------------#2021-07-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="22f7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">通过实际例子，了解如何利用这些服务之间的集成，通过Apache Spark处理数据</h2></div><p id="50c3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://docs.microsoft.com/azure/data-explorer/data-explorer-overview?WT.mc_id=data-21329-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Data Explorer </a>是一种完全托管的数据分析服务，可以处理来自任何数据源的大量不同数据，如网站、应用程序、物联网设备等。Azure Data Explorer使获取这些数据变得简单，并使您能够在几秒钟内对数据进行复杂的即席查询。它可以在几分钟内快速扩展到万亿字节的数据，允许快速迭代数据探索，以发现相关的见解。它已经通过<a class="ae lb" href="https://github.com/Azure/azure-kusto-spark" rel="noopener ugc nofollow" target="_blank">数据源和数据接收器连接器</a>与Apache Spark work集成，用于为近实时数据处理、数据存档、机器学习等解决方案提供动力。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/a5f65c59f33eb6fc0f719d019291517f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m8ZtDaguIjXwLJz5a92T4w.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">面向大数据工作负载的Azure Data Explorer</p></figure><p id="3d3c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">得益于对该解决方案的扩展，Azure Data Explorer可作为Azure Synapse Analytics中的链接服务，允许Azure Data Explorer和Azure Synapse中的Apache Spark池之间的无缝集成。</p><p id="6fd1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://docs.microsoft.com/azure/synapse-analytics/overview-what-is?WT.mc_id=data-21329-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Synapse </a>汇集了企业数据仓库中使用的SQL技术、用于大数据的Spark技术、用于数据集成和ETL/ELT的管道，以及与Power BI、CosmosDB和AzureML等其他Azure服务的深度集成。</p><p id="a53c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇博文是一个入门指南，展示了Azure Data Explorer和Azure Synapse之间的集成。它包括:</p><ul class=""><li id="e8bb" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated">如何使用Spark和Azure Synapse处理Azure Data Explorer中的现有数据？</li><li id="7b01" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">使用Spark处理流和批处理数据，并将其写回Azure data explore。</li></ul><blockquote class="mg mh mi"><p id="0e21" class="kf kg mj kh b ki kj jr kk kl km ju kn mk kp kq kr ml kt ku kv mm kx ky kz la ij bi translated"><em class="iq">笔记本在本次GitHub repo中有售—</em><a class="ae lb" href="https://github.com/abhirockzz/synapse-azure-data-explorer-101" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://GitHub . com/abhirockzz/synapse-azure-data-explorer-101</em></a></p></blockquote></div><div class="ab cl mn mo hu mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ij ik il im in"><p id="fdb9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要学习，你需要的只是一个Azure账户(你可以<a class="ae lb" href="https://azure.microsoft.com/free/?WT.mc_id=data-21329-abhishgu" rel="noopener ugc nofollow" target="_blank">免费获得一个</a>)。一旦你准备好了，就进入下一部分吧！</p><h1 id="5992" class="mu mv iq bd mw mx my mz na nb nc nd ne jw nf jx ng jz nh ka ni kc nj kd nk nl bi translated">初始设置和配置</h1><p id="1b50" class="pw-post-body-paragraph kf kg iq kh b ki nm jr kk kl nn ju kn ko no kq kr ks np ku kv kw nq ky kz la ij bi translated">首先创建一个<a class="ae lb" href="https://docs.microsoft.com/azure/synapse-analytics/quickstart-create-workspace?WT.mc_id=data-21329-abhishgu" rel="noopener ugc nofollow" target="_blank"> Azure Synapse workspace </a>以及一个<a class="ae lb" href="https://docs.microsoft.com/azure/synapse-analytics/quickstart-create-apache-spark-pool-portal?WT.mc_id=data-21329-abhishgu" rel="noopener ugc nofollow" target="_blank"> Apache Spark pool </a>。然后，<a class="ae lb" href="https://docs.microsoft.com/azure/data-explorer/create-cluster-database-portal?WT.mc_id=data-21329-abhishgu" rel="noopener ugc nofollow" target="_blank">创建一个Azure Data Explorer集群和数据库</a></p><h2 id="5de1" class="nr mv iq bd mw ns nt dn na nu nv dp ne ko nw nx ng ks ny nz ni kw oa ob nk oc bi translated">调整摄取策略</h2><p id="4d4f" class="pw-post-body-paragraph kf kg iq kh b ki nm jr kk kl nn ju kn ko no kq kr ks np ku kv kw nq ky kz la ij bi translated">在摄取过程中，Azure Data Explorer试图通过在等待摄取时将小的入口数据块批处理在一起来优化吞吐量，这由<a class="ae lb" href="https://docs.microsoft.com/azure/data-explorer/kusto/management/batchingpolicy?WT.mc_id=data-21329-abhishgu" rel="noopener ugc nofollow" target="_blank">摄取批处理策略</a>控制。默认策略值为:最大延迟时间为5分钟，1000个项目，批处理的总大小为1G。这意味着从触发数据接收到准备好进行查询之间有一定的延迟。好的一面是，该策略可以根据需要进行微调。</p><p id="c6a7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">出于演示的目的，我们专注于让我们的数据尽快可供查询。因此，您应该使用<code class="fe od oe of og b">30</code>秒的<code class="fe od oe of og b">MaximumBatchingTimeSpan</code>值来更新策略</p><pre class="ld le lf lg gt oh og oi oj aw ok bi"><span id="f6d2" class="nr mv iq og b gy ol om l on oo">.alter database adxdb policy ingestionbatching @'{"MaximumBatchingTimeSpan": "00:00:30"}'</span></pre><blockquote class="mg mh mi"><p id="7587" class="kf kg mj kh b ki kj jr kk kl km ju kn mk kp kq kr ml kt ku kv mm kx ky kz la ij bi translated">将此策略设置为非常小的值会增加成本并降低性能，这只是为了演示</p></blockquote><h2 id="db59" class="nr mv iq bd mw ns nt dn na nu nv dp ne ko nw nx ng ks ny nz ni kw oa ob nk oc bi translated">从Synapse连接到Azure数据浏览器</h2><p id="d448" class="pw-post-body-paragraph kf kg iq kh b ki nm jr kk kl nn ju kn ko no kq kr ks np ku kv kw nq ky kz la ij bi translated">在Azure Synapse Analytics中，<strong class="kh ir">链接服务</strong>是您定义与其他服务的连接信息的地方。您可以使用Azure Synapse分析工作区为Azure Data Explorer <a class="ae lb" href="https://docs.microsoft.com/en-us/azure/synapse-analytics/quickstart-connect-azure-data-explorer?WT.mc_id=data-21329-abhishgu#connect-an-azure-data-explorer-database-to-an-azure-synapse-workspace" rel="noopener ugc nofollow" target="_blank">创建链接服务。</a></p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi op"><img src="../Images/a97097ea3f32a5b628c7c26fa1dd7519.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PlkbGOWqXee8hiQlLsuN9w.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">创建链接服务(按作者分类的图像)</p></figure><blockquote class="mg mh mi"><p id="8210" class="kf kg mj kh b ki kj jr kk kl km ju kn mk kp kq kr ml kt ku kv mm kx ky kz la ij bi translated">与服务主体相反，托管身份正被用作<strong class="kh ir">身份验证方法</strong></p></blockquote><p id="eb4c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">创建链接服务后，它将显示在列表中:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi oq"><img src="../Images/a718be3e2d6188e64f878026056c65f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3GXcH6rj83vBgwU1F_hkcg.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">Azure Data Explorer链接服务(图片由作者提供)</p></figure><p id="65a4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好了，你都准备好了！</p><p id="c2f7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你已经在使用Azure Data Explorer，很可能你已经有了大量的数据，等待处理！所以让我们从探索这方面开始。</p></div><div class="ab cl mn mo hu mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ij ik il im in"><h1 id="53aa" class="mu mv iq bd mw mx or mz na nb os nd ne jw ot jx ng jz ou ka ni kc ov kd nk nl bi translated">在Azure Data Explorer中处理现有数据</h1><p id="1333" class="pw-post-body-paragraph kf kg iq kh b ki nm jr kk kl nn ju kn ko no kq kr ks np ku kv kw nq ky kz la ij bi translated">数据接收是Azure Data Explorer等大数据分析服务的关键组件。难怪，它支持多种方式<a class="ae lb" href="https://docs.microsoft.com/azure/data-explorer/ingest-data-overview?WT.mc_id=data-21329-abhishgu#ingestion-methods-and-tools" rel="noopener ugc nofollow" target="_blank">来从各种来源获取数据。虽然对摄取技术和选项进行了详细的讨论，但是欢迎您在文档中阅读。</a></p><p id="240d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了节省时间，让我们手动<a class="ae lb" href="https://docs.microsoft.com/azure/data-explorer/ingest-sample-data?WT.mc_id=data-21329-abhishgu" rel="noopener ugc nofollow" target="_blank">摄取数据</a>。不要让“手动”这个词误导你。相当简单快捷！</p><p id="7916" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先在数据库中创建一个表(姑且称之为<code class="fe od oe of og b">StormEvents_1</code>):</p><pre class="ld le lf lg gt oh og oi oj aw ok bi"><span id="87a7" class="nr mv iq og b gy ol om l on oo">.create table StormEvents_1 (StartTime: datetime, EndTime: datetime, EpisodeId: int, EventId: int, State: string, EventType: string, InjuriesDirect: int, InjuriesIndirect: int, DeathsDirect: int, DeathsIndirect: int, DamageProperty: int, DamageCrops: int, Source: string, BeginLocation: string, EndLocation: string, BeginLat: real, BeginLon: real, EndLat: real, EndLon: real, EpisodeNarrative: string, EventNarrative: string, StormSummary: dynamic)</span></pre><p id="bc6d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">…并将CSV数据接收到表格中(直接从Blob存储中):</p><pre class="ld le lf lg gt oh og oi oj aw ok bi"><span id="3cd6" class="nr mv iq og b gy ol om l on oo">.ingest into table StormEvents_1 'https://kustosamplefiles.blob.core.windows.net/samplefiles/StormEvents.csv?sv=2019-12-12&amp;ss=b&amp;srt=o&amp;sp=r&amp;se=2022-09-05T02:23:52Z&amp;st=2020-09-04T18:23:52Z&amp;spr=https&amp;sig=VrOfQMT1gUrHltJ8uhjYcCequEcfhjyyMX%2FSc3xsCy4%3D' with (ignoreFirstRecord=true)</span></pre><blockquote class="mg mh mi"><p id="0447" class="kf kg mj kh b ki kj jr kk kl km ju kn mk kp kq kr ml kt ku kv mm kx ky kz la ij bi translated"><em class="iq">如果你觉得这个技术有用，我鼓励你也试试</em> <a class="ae lb" href="https://docs.microsoft.com/azure/data-explorer/one-click-ingestion-new-table?WT.mc_id=data-21329-abhishgu" rel="noopener ugc nofollow" target="_blank"> <em class="iq">一键摄取</em> </a> <em class="iq">！</em></p></blockquote><p id="7574" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">消化可能需要一分钟左右的时间。确认数据是否可用，并执行简单的查询:</p><pre class="ld le lf lg gt oh og oi oj aw ok bi"><span id="e8be" class="nr mv iq og b gy ol om l on oo">.show ingestion failures</span><span id="97b3" class="nr mv iq og b gy ow om l on oo">StormEvents_1| count <br/>StormEvents_1| take 5 </span><span id="3e4f" class="nr mv iq og b gy ow om l on oo">StormEvents_1| take 5 | project StartTime, EndTime, State, EventType, DamageProperty, Source</span></pre><p id="521c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe od oe of og b">StormEvents_1</code>表提供了一些关于美国发生的风暴的信息。看起来是这样的:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ox"><img src="../Images/0ccd230ed18f78ea6e87aa5dca512783.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NwtzNxOOZxjgRSgxrXC4tA.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated"><code class="fe od oe of og b">Azure Data Explorer table data </code>(图片作者提供)</p></figure><p id="e773" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于后续步骤，您可以将代码直接粘贴到Azure Synapse Analytics 中的<a class="ae lb" href="https://docs.microsoft.com/azure/synapse-analytics/spark/apache-spark-development-using-notebooks?tabs=classical&amp;WT.mc_id=data-21329-abhishgu" rel="noopener ugc nofollow" target="_blank"> Synapse Studio笔记本中，或者将</a><a class="ae lb" href="https://github.com/abhirockzz/synapse-azure-data-explorer-101/blob/master/notebooks/synapse-adx-read.ipynb" rel="noopener ugc nofollow" target="_blank">该笔记本</a>导入到工作区中。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/a6de2e355e342b28fe6b45f7045b8b52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/0*LbNkxzgRrJq0Xzz1.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">Azure Synapse工作空间笔记本(图片由作者提供)</p></figure><p id="b883" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从简单的事情开始:</p><pre class="ld le lf lg gt oh og oi oj aw ok bi"><span id="c590" class="nr mv iq og b gy ol om l on oo">kustoDf  = spark.read \<br/>            .format("com.microsoft.kusto.spark.synapse.datasource") \<br/>            .option("spark.synapse.linkedService", "adx") \<br/>            .option("kustoDatabase", "adxdb") \<br/>            .option("kustoQuery", "StormEvents_1 | take 10") \<br/>            .load()</span><span id="090b" class="nr mv iq og b gy ow om l on oo">display(kustoDf)</span></pre><p id="905a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了从Azure Data Explorer中读取数据，我们需要使用<code class="fe od oe of og b">kustoQuery</code>选项指定查询。在这种情况下，我们只是执行<code class="fe od oe of og b">StormEvents_1 | take 10</code>来验证数据。</p><p id="d100" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这次让我们尝试另一个Kusto查询:</p><pre class="ld le lf lg gt oh og oi oj aw ok bi"><span id="f7c6" class="nr mv iq og b gy ol om l on oo">filtered_df = spark.read \<br/>.format("com.microsoft.kusto.spark.synapse.datasource") \<br/>.option("spark.synapse.linkedService", "AzureDataExplorer1") \<br/>.option("kustoDatabase", "mydb") \<br/>.option("kustoQuery", "StormEvents_1 | where DamageProperty &gt; 0 and DeathsDirect &gt; 0 | project EventId, State, StartTime, EndTime, EventType, DamageProperty, DeathsDirect, Source") \<br/>.load()</span><span id="132b" class="nr mv iq og b gy ow om l on oo">filtered_df.createOrReplaceTempView("storm_dataset")</span></pre><p id="1261" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这将把所有记录读入到一个<code class="fe od oe of og b">DataFrame</code>中，选择相关的列并过滤数据。例如，我们排除了没有任何财产损失或死亡的事件。最后，我们创建一个临时视图(<code class="fe od oe of og b">storm_dataset</code>)，以便使用Apache Spark SQL执行进一步的数据探索。</p><p id="bd40" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在此之前，让我们使用<code class="fe od oe of og b">Seaborn</code>(一个Python数据可视化库)来绘制一个简单的条形图:</p><pre class="ld le lf lg gt oh og oi oj aw ok bi"><span id="a148" class="nr mv iq og b gy ol om l on oo">import seaborn as sns<br/>import matplotlib.pyplot as plt</span><span id="af19" class="nr mv iq og b gy ow om l on oo">filtered_df = filtered_df.toPandas()</span><span id="6b81" class="nr mv iq og b gy ow om l on oo">ax = sns.barplot(x="DeathsDirect", y="EventType",data=filtered_df)<br/>ax.set_title('deaths per event type')<br/>ax.set_xlabel('Deaths#')<br/>ax.set_ylabel('Event Type')<br/>plt.show()</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi oz"><img src="../Images/daac706ccfbb727fd2ac078716271445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uoltf1pn-vRjzAIyetZSqw.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">Seaborn情节(图片由作者提供)</p></figure><p id="5c72" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是一个基于临时视图的Spark SQL示例。</p><pre class="ld le lf lg gt oh og oi oj aw ok bi"><span id="29f6" class="nr mv iq og b gy ol om l on oo">%%sql</span><span id="1384" class="nr mv iq og b gy ow om l on oo">SELECT EventType, AVG(DamageProperty) AS avg_property_damage<br/>FROM storm_dataset <br/>GROUP BY EventType<br/>ORDER BY avg_property_damage DESC</span></pre><p id="ed6e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们计算了每种事件类型(雪崩、冰暴等)造成的平均损失。).下面的输出是柱形图的形式(但也有其他选项):</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi pa"><img src="../Images/d8bb11b2e9ab0a498a5b4b2b697b6e99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DClI194213XeVjhNjg4o-A.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">图表输出(图片由作者提供)</p></figure><p id="ba3c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是上面的一个小变化，我们找出每个州的最大死亡人数。</p><pre class="ld le lf lg gt oh og oi oj aw ok bi"><span id="c97b" class="nr mv iq og b gy ol om l on oo">%%sql</span><span id="952f" class="nr mv iq og b gy ow om l on oo">SELECT <br/>    State<br/>    , MAX(DeathsDirect) AS deaths<br/>FROM storm_dataset <br/>GROUP BY State<br/>ORDER BY deaths DESC</span></pre><p id="2b35" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这次还有一个饼状图输出:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi pb"><img src="../Images/3e128a7a5b5243be5f02230e848e70f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WkODgEM2Q9ENgwhfhc2g2A.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">饼图输出(图片由作者提供)</p></figure><p id="8f5f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，您知道了如何通过使用Azure Synapse中的Apache Spark池进行处理，从Azure Data Explorer中的现有数据集中提取见解。</p></div><div class="ab cl mn mo hu mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ij ik il im in"><h1 id="01fa" class="mu mv iq bd mw mx or mz na nb os nd ne jw ot jx ng jz ou ka ni kc ov kd nk nl bi translated">处理数据并将数据写入Azure Data Explorer</h1><p id="37f5" class="pw-post-body-paragraph kf kg iq kh b ki nm jr kk kl nn ju kn ko no kq kr ks np ku kv kw nq ky kz la ij bi translated">本节将介绍如何使用Spark(准确地说是Synapse Spark Pools)处理数据，并将其写入Azure Data Explorer以供进一步分析。</p><p id="37a8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先创建另一个表<code class="fe od oe of og b">StormEvents_2</code></p><pre class="ld le lf lg gt oh og oi oj aw ok bi"><span id="d3c9" class="nr mv iq og b gy ol om l on oo">.create table StormEvents_2 (StartTime: datetime, EndTime: datetime, EpisodeId: int, EventId: int, State: string, EventType: string, InjuriesDirect: int, InjuriesIndirect: int, DeathsDirect: int, DeathsIndirect: int, DamageProperty: int, DamageCrops: int, Source: string, BeginLocation: string, EndLocation: string, BeginLat: real, BeginLon: real, EndLat: real, EndLon: real, EpisodeNarrative: string, EventNarrative: string, StormSummary: dynamic)</span></pre><p id="f4c4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用现有的CSV数据。这与我们之前在Azure Data Explorer中获取的数据相同。但是，这一次，我们将把它下载到我们的本地机器，并上传到与Azure Synapse workspace关联的ADLS Gen2帐户。</p><p id="7fa3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从下载该文件开始:</p><pre class="ld le lf lg gt oh og oi oj aw ok bi"><span id="a369" class="nr mv iq og b gy ol om l on oo">curl -o StormEvents.csv "https://kustosamplefiles.blob.core.windows.net/samplefiles/StormEvents.csv?sv=2019-12-12&amp;ss=b&amp;srt=o&amp;sp=r&amp;se=2022-09-05T02:23:52Z&amp;st=2020-09-04T18:23:52Z&amp;spr=https&amp;sig=VrOfQMT1gUrHltJ8uhjYcCequEcfhjyyMX%2FSc3xsCy4%3D"</span></pre><p id="e431" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用工作区将其上传到ADLS文件系统:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi pc"><img src="../Images/32a989d8ffdaf52bb42761b90b0e517e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yCsKVXJkGFrUR7ivTUOqrQ.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">将文件上传到Azure数据湖存储(图片由作者提供)</p></figure><blockquote class="mg mh mi"><p id="aa75" class="kf kg mj kh b ki kj jr kk kl km ju kn mk kp kq kr ml kt ku kv mm kx ky kz la ij bi translated"><em class="iq">对于后续步骤，您可以将代码直接粘贴到Azure Synapse Analytics</em><em class="iq">中的</em> <a class="ae lb" href="https://docs.microsoft.com/azure/synapse-analytics/spark/apache-spark-development-using-notebooks?tabs=classical&amp;WT.mc_id=data-21329-abhishgu" rel="noopener ugc nofollow" target="_blank"> <em class="iq"> Synapse Studio笔记本中，或者将</em> </a><a class="ae lb" href="https://github.com/abhirockzz/synapse-azure-data-explorer-101/blob/master/notebooks/synapse-adx-write-batch.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="iq">该笔记本</em> </a> <em class="iq">导入到工作区中。</em></p></blockquote><p id="5124" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将数据集从ADLS Gen2加载到一个<code class="fe od oe of og b">DataFrame</code>:</p><pre class="ld le lf lg gt oh og oi oj aw ok bi"><span id="688e" class="nr mv iq og b gy ol om l on oo">events = (spark.read<br/>                .csv("/StormEvents.csv", header=True, inferSchema='true')<br/>              )</span></pre><p id="b6ba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用Apache Spark应用一些基本的<em class="mj">过滤</em>——忽略包含空数据的行，删除我们不需要处理的列，过滤没有任何属性损坏的行。</p><pre class="ld le lf lg gt oh og oi oj aw ok bi"><span id="f3fd" class="nr mv iq og b gy ol om l on oo">events_filtered = events.dropna() \<br/>                        .drop('StormSummary', 'EndLat','EndLon','BeginLat','BeginLon') \<br/>                        .filter((events.DamageProperty &gt; 0))</span><span id="e342" class="nr mv iq og b gy ow om l on oo">print(events_filtered.count())<br/>display(events_filtered.take(10))</span></pre><p id="e7b1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，将<code class="fe od oe of og b">DataFrame</code>写入Azure数据浏览器:</p><pre class="ld le lf lg gt oh og oi oj aw ok bi"><span id="394b" class="nr mv iq og b gy ol om l on oo">events_filtered.write \<br/>    .format("com.microsoft.kusto.spark.synapse.datasource") \<br/>    .option("spark.synapse.linkedService", "adx") \<br/>    .option("kustoDatabase", "adxdb") \<br/>    .option("kustoTable", "StormEvents_2") \<br/>    .option("tableCreateOptions","FailIfNotExist") \<br/>    .mode("Append") \<br/>    .save()</span></pre><blockquote class="mg mh mi"><p id="ca23" class="kf kg mj kh b ki kj jr kk kl km ju kn mk kp kq kr ml kt ku kv mm kx ky kz la ij bi translated">请注意，我们使用了<code class="fe od oe of og b">FailIfNotExist</code>，这意味着如果在请求的集群和数据库中没有找到该表，操作将会失败。<br/>另一个选项是<code class="fe od oe of og b">CreateIfNotExist</code> —如果在请求的集群和数据库中找不到该表，将创建该表，其模式与正在写入的数据帧相匹配。</p><p id="ea8e" class="kf kg mj kh b ki kj jr kk kl km ju kn mk kp kq kr ml kt ku kv mm kx ky kz la ij bi translated">更多信息请参考<a class="ae lb" href="https://github.com/Azure/azure-kusto-spark/blob/master/docs/KustoSink.md#supported-options" rel="noopener ugc nofollow" target="_blank">https://github . com/Azure/Azure-kusto-spark/blob/master/docs/kustosink . MD # supported-options</a></p></blockquote><p id="8fce" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">给它一分钟让数据被写入。然后你就可以随心所欲地执行Azure Data Explorer查询了！尝试以下内容:</p><pre class="ld le lf lg gt oh og oi oj aw ok bi"><span id="5d8a" class="nr mv iq og b gy ol om l on oo">.show ingestion failures</span><span id="6e27" class="nr mv iq og b gy ow om l on oo">StormEvents_2| take 10</span><span id="0de3" class="nr mv iq og b gy ow om l on oo">StormEvents_2<br/>| summarize event_count=count() by bin(StartTime, 1d)<br/>| render timechart</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi pd"><img src="../Images/c2b8a4207f511610e528e8facc99f24c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4hxQUAAsvKcoioAY1qylog.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">时间图输出(图片由作者提供)</p></figure><p id="1cf1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您刚刚执行的只是典型的基于批处理的数据处理设置的一瞥。但是情况并不总是这样！</p></div><div class="ab cl mn mo hu mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ij ik il im in"><h1 id="a275" class="mu mv iq bd mw mx or mz na nb os nd ne jw ot jx ng jz ou ka ni kc ov kd nk nl bi translated">快速回顾</h1><p id="3241" class="pw-post-body-paragraph kf kg iq kh b ki nm jr kk kl nn ju kn ko no kq kr ks np ku kv kw nq ky kz la ij bi translated">在这篇博文中，你学到了:</p><ul class=""><li id="3e81" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated">如何<strong class="kh ir">设置和配置</strong> Azure Synapse和Azure Data Explorer(包括安全访问)。</li><li id="8cc1" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated"><strong class="kh ir">如何充分利用Azure Data Explorer中的现有数据</strong>并使用Azure Synapse中的Apache Spark pools对其进行处理。</li><li id="bbb1" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated"><strong class="kh ir">如何处理来自外部来源的数据</strong>并将结果写回Azure Data Explorer以供进一步分析。</li></ul><h1 id="a96d" class="mu mv iq bd mw mx my mz na nb nc nd ne jw nf jx ng jz nh ka ni kc nj kd nk nl bi translated">总结一下！</h1><p id="0aee" class="pw-post-body-paragraph kf kg iq kh b ki nm jr kk kl nn ju kn ko no kq kr ks np ku kv kw nq ky kz la ij bi translated">这些简单的例子可以帮助你开始。但是，Apache Spark SQL、<a class="ae lb" href="https://docs.microsoft.com/azure/synapse-analytics/spark/apache-spark-version-support?WT.mc_id=data-17928-abhishgu#python-libraries" rel="noopener ugc nofollow" target="_blank"> Python </a>和<a class="ae lb" href="https://docs.microsoft.com/azure/synapse-analytics/spark/apache-spark-version-support?WT.mc_id=data-17928-abhishgu#scala-and-java-libraries" rel="noopener ugc nofollow" target="_blank"> Scala/Java </a>库的全部功能都可供您使用。如果我不提及Synapse SQL Pools(有<a class="ae lb" href="https://docs.microsoft.com/azure/synapse-analytics/sql/on-demand-workspace-overview?WT.mc_id=data-17928-abhishgu" rel="noopener ugc nofollow" target="_blank">无服务器</a>和<a class="ae lb" href="https://docs.microsoft.com/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-overview-what-is?toc=/azure/synapse-analytics/toc.json&amp;bc=/azure/synapse-analytics/breadcrumb/toc.json&amp;WT.mc_id=data-17928-abhishgu" rel="noopener ugc nofollow" target="_blank">专用</a>模式)将是我的失职，它允许通过T-SQL进行数据访问，并为广泛的商业智能、专用查询工具和流行的驱动程序提供了可能性。</p><p id="efc1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">🙏🏻感谢<a class="ae lb" href="https://www.linkedin.com/in/manoj-b-raheja/" rel="noopener ugc nofollow" target="_blank"> Manoj Raheja </a>和<a class="ae lb" href="https://twitter.com/AdiPolak?" rel="noopener ugc nofollow" target="_blank"> Adi Polak </a>的评论和反馈！🙏🏻</p></div></div>    
</body>
</html>