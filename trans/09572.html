<html>
<head>
<title>Understanding ROC Curves with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python理解ROC曲线</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-roc-curves-c7f0b52e931e?source=collection_archive---------7-----------------------#2021-09-06">https://towardsdatascience.com/understanding-roc-curves-c7f0b52e931e?source=collection_archive---------7-----------------------#2021-09-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/b9d2d7673d62a458bfd6f48e82e65868.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tMEVBx5yM7n9Jljq"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">艾萨克·史密斯在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="fb13" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">用Python构建接收机工作特性曲线的基本直觉</h2></div><p id="cbce" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你谷歌:“ROC曲线机器学习”，你会得到这样一个维基百科的答案:</p><blockquote class="lu lv lw"><p id="856e" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated">受试者操作特征曲线，或ROC曲线，是一种图示，说明了二元分类器系统在其辨别阈值变化时的诊断能力</p></blockquote><p id="235f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另一个常见的描述是ROC曲线<em class="lx">反映了跨不同分类阈值</em>的模型的敏感性。当我开始研究机器学习时，这些定义总是让我感到困惑。</p><p id="e427" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这篇文章中，我将分享我是如何学会理清自己“初学者般”的困惑，并对ROC曲线形成足够好的直觉的。T9】</p></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><h1 id="6e51" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">ROC曲线到底是什么？</h1><p id="21ed" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">理解ROC曲线的一种方式是<strong class="la jk"> <em class="lx">它描述了模型的灵敏度(真阳性率或TPR)与其特异性(关于假阳性率描述:1-FPR) </em> </strong>。</p><p id="30bd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们理清这里的每个概念。</p><p id="77c6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">TPR被称为模型的<em class="lx">敏感度</em>，是“阳性”类的正确分类除以数据集中所有可用阳性类的比率，数学上:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/82ad6642fb67fea3a307948e7f5112ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:340/format:webp/1*K7Lr_aSDFikhwlB59SGMIA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="12cf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">虽然FPR是假阳性(误分类为阳性的预测数)与所有可用阴性类别之间的比率，但在数学上:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/0dcca49ec591f65b5d513cd322e0c127.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/format:webp/1*WdKJ417DHPBb2r-obCwNxA.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="d48f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">T19】</strong></p></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><h1 id="de53" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">将问题与阈值分数分离</h1><p id="22a2" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">一开始，暗示我的直觉是要把握门槛分数的作用。一个很好的起点是建立一个心理图景:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div class="ab gu cl nl"><img src="../Images/f04e3c36e3e879aec9b0315e42fd4316.png" data-original-src="https://miro.medium.com/v2/format:webp/1*m8AChVCxrhpN78AC5h-duw.png"/></div></figure><p id="b874" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过这种经典的可视化，人们可以了解到第一直觉，即<strong class="la jk"> <em class="lx">理想的模型是具有尽可能高的真阳性率同时保持尽可能低的假阳性率的模型。</em> </strong></p><p id="535d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">阈值对应于某个值T(例如0和1之间的值),该值用作分类器的决策边界，并且它影响TPR和FPR之间的折衷。</p><p id="5f9a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们写一些代码来获得所有这些组件的可视化。</p></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><h1 id="d62d" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">可视化ROC曲线</h1><p id="40d7" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">实现这一点的步骤如下:</p><ol class=""><li id="bff5" class="nm nn jj la b lb lc le lf lh no ll np lp nq lt nr ns nt nu bi translated"><strong class="la jk">导入我们的依赖关系</strong></li><li id="d7a5" class="nm nn jj la b lb nv le nw lh nx ll ny lp nz lt nr ns nt nu bi translated"><strong class="la jk">用</strong> <code class="fe oa ob oc od b"><strong class="la jk">drawdata</strong></code> <strong class="la jk">包给Jupyter笔记本</strong>画一些假数据</li><li id="3558" class="nm nn jj la b lb nv le nw lh nx ll ny lp nz lt nr ns nt nu bi translated"><strong class="la jk">导入假数据到熊猫数据框</strong></li><li id="7729" class="nm nn jj la b lb nv le nw lh nx ll ny lp nz lt nr ns nt nu bi translated"><strong class="la jk">对数据拟合逻辑回归模型</strong></li><li id="53c2" class="nm nn jj la b lb nv le nw lh nx ll ny lp nz lt nr ns nt nu bi translated"><strong class="la jk">以概率值的形式获得逻辑回归模型的预测</strong></li><li id="f255" class="nm nn jj la b lb nv le nw lh nx ll ny lp nz lt nr ns nt nu bi translated"><strong class="la jk">设置不同的阈值分数</strong></li><li id="535e" class="nm nn jj la b lb nv le nw lh nx ll ny lp nz lt nr ns nt nu bi translated"><strong class="la jk">可视化roc曲线图</strong></li><li id="516d" class="nm nn jj la b lb nv le nw lh nx ll ny lp nz lt nr ns nt nu bi translated"><strong class="la jk">得出一些最终结论</strong></li></ol><h2 id="8cd3" class="oe mj jj bd mk of og dn mo oh oi dp ms lh oj ok mu ll ol om mw lp on oo my op bi translated">1.导入我们的依赖性</h2><pre class="ng nh ni nj gt oq od or os aw ot bi"><span id="b773" class="oe mj jj od b gy ou ov l ow ox">from drawdata import draw_scatter<br/>import pandas as pd<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.metrics import accuracy_score, precision_recall_curve,precision_score, plot_roc_curve</span></pre><h2 id="ad92" class="oe mj jj bd mk of og dn mo oh oi dp ms lh oj ok mu ll ol om mw lp on oo my op bi translated">2.用Jupyter笔记本的<code class="fe oa ob oc od b">drawdata</code>包画一些假数据</h2><pre class="ng nh ni nj gt oq od or os aw ot bi"><span id="f92c" class="oe mj jj od b gy ou ov l ow ox">draw_scatter()</span></pre><p id="756e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/37229254af5f66eecc37fbbe2e30017d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Inro2rHu_hHaFPb7aK5hSw.png"/></div></div></figure><h2 id="39b2" class="oe mj jj bd mk of og dn mo oh oi dp ms lh oj ok mu ll ol om mw lp on oo my op bi translated"><strong class="ak"> 3。将假数据导入熊猫数据框</strong></h2><pre class="ng nh ni nj gt oq od or os aw ot bi"><span id="e3eb" class="oe mj jj od b gy ou ov l ow ox">df = pd.read_csv("./data.csv")</span></pre><h2 id="31ec" class="oe mj jj bd mk of og dn mo oh oi dp ms lh oj ok mu ll ol om mw lp on oo my op bi translated">4.根据数据拟合逻辑回归模型</h2><pre class="ng nh ni nj gt oq od or os aw ot bi"><span id="5f01" class="oe mj jj od b gy ou ov l ow ox">def get_fp_tp(y, proba, threshold):<br/>    """Return the number of false positives and true positives."""<br/>    # source: https://towardsdatascience.com/roc-curve-explained-50acab4f7bd8<br/>    # Classify into classes<br/>    pred = pd.Series(np.where(proba&gt;=threshold, 1, 0), <br/>                     dtype='category')<br/>    pred.cat.set_categories([0,1], inplace=True)<br/>    # Create confusion matrix<br/>    confusion_matrix = pred.groupby([y, pred]).size().unstack()\<br/>                           .rename(columns={0: 'pred_0', <br/>                                            1: 'pred_1'}, <br/>                                   index={0: 'actual_0', <br/>                                          1: 'actual_1'})<br/>    false_positives = confusion_matrix.loc['actual_0', 'pred_1']<br/>    true_positives = confusion_matrix.loc['actual_1', 'pred_1']<br/>    return false_positives, true_positives<br/><br/># train test split on the fake generated dataset<br/>X = df[["x", "y"]].values<br/>Y = df["z"].values<br/>X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)<br/>y_test = np.array([1 if p=="a" else 0 for p in y_test])<br/>y_train = np.array([1 if p=="a" else 0 for p in y_train])<br/><br/># create the model<br/>lgr = LogisticRegression()<br/>lgr.fit(X_train, y_train)</span></pre><h2 id="e377" class="oe mj jj bd mk of og dn mo oh oi dp ms lh oj ok mu ll ol om mw lp on oo my op bi translated">5.以概率值的形式获得逻辑回归模型的预测</h2><pre class="ng nh ni nj gt oq od or os aw ot bi"><span id="9bc4" class="oe mj jj od b gy ou ov l ow ox">y_hat = lgr.predict_proba(X_test)[:,1]</span></pre><h2 id="4f72" class="oe mj jj bd mk of og dn mo oh oi dp ms lh oj ok mu ll ol om mw lp on oo my op bi translated">6.设置不同的阈值分数</h2><pre class="ng nh ni nj gt oq od or os aw ot bi"><span id="ecf1" class="oe mj jj od b gy ou ov l ow ox">thresholds = np.linspace(0,1,100)</span></pre><h2 id="74a3" class="oe mj jj bd mk of og dn mo oh oi dp ms lh oj ok mu ll ol om mw lp on oo my op bi translated">7.可视化roc曲线图</h2><pre class="ng nh ni nj gt oq od or os aw ot bi"><span id="4da1" class="oe mj jj od b gy ou ov l ow ox"># defining fpr and tpr<br/>tpr = []<br/>fpr = []<br/># defining positives and negatives<br/>positives = np.sum(y_test==1)<br/>negatives = np.sum(y_test==0)<br/><br/># looping over threshold scores and getting the number of false positives and true positives<br/>for th in thresholds:<br/>    fp,tp = get_fp_tp(y_test, y_hat, th)<br/>    tpr.append(tp/positives)<br/>    fpr.append(fp/negatives)<br/>    <br/>plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Random', alpha=.8)<br/>plt.plot(fpr,tpr, label="ROC Curve",color="blue")<br/>plt.text(0.5, 0.5, "varying threshold scores (0-1)", rotation=0, size=12,ha="center", va="center",bbox=dict(boxstyle="rarrow"))<br/>plt.xlabel("False Positve Rate")<br/>plt.ylabel("True Positive Rate")<br/>plt.legend()<br/>plt.show()</span></pre><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div class="ab gu cl nl"><img src="../Images/6aad8736cf6b2b952ed1092fe6201582.png" data-original-src="https://miro.medium.com/v2/format:webp/1*JDbGfPsR9kFMNYY4m2RpEA.png"/></div></figure><h2 id="108f" class="oe mj jj bd mk of og dn mo oh oi dp ms lh oj ok mu ll ol om mw lp on oo my op bi translated">8.得出一些最终结论</h2><p id="b1a0" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">通过改变阈值分数，我们可以得到增加的真阳性率和假阳性率。<strong class="la jk"> <em class="lx">一个好的模型是阈值分数使真阳性率尽可能接近1，同时使假阳性率尽可能低。</em> </strong></p><p id="79ff" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是，我们如何选择最佳的分类阈值呢？</p><p id="0d08" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">一个简单的方法是取真阳性率和假阴性率之和最大的一个(1- FPR)。</strong></p><p id="e7a0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另一个标准可以是简单地<strong class="la jk">选择离你的ROC空间左上角最近的点。</strong>然而，这意味着真阳性率和真阴性率具有相同的权重(<a class="ae jg" href="https://stats.stackexchange.com/questions/123124/how-to-determine-the-optimal-threshold-for-a-classifier-and-generate-roc-curve#:~:text=A simple method is to,thresholds like financial costs, etc.&amp;text=Choose the point closest to,corner of your ROC space." rel="noopener ugc nofollow" target="_blank">来源</a>)，这在癌症分类等情况下不一定成立，因为假阳性的负面影响大于真阳性的影响。</p></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><h1 id="3ad4" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">关于ROC曲线的最后思考</h1><p id="f8b3" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">我认为，从长远来看，花一些时间来消化评估指标对您的机器学习之旅非常有益。在本文中，您了解了:</p><ul class=""><li id="3356" class="nm nn jj la b lb lc le lf lh no ll np lp nq lt oz ns nt nu bi translated">关于ROC曲线如何工作的基本直觉</li><li id="cfa3" class="nm nn jj la b lb nv le nw lh nx ll ny lp nz lt oz ns nt nu bi translated">分类阈值如何影响模型的敏感性和特异性之间的关系</li><li id="9296" class="nm nn jj la b lb nv le nw lh nx ll ny lp nz lt oz ns nt nu bi translated">关于如何使用ROC曲线设置最佳分类阈值的直觉</li></ul></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><p id="7f64" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您想了解更多关于Python的机器学习知识，请查看以下课程:</p><blockquote class="lu lv lw"><p id="e55f" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated">这些是附属链接，如果你使用它们，我会得到一小笔佣金，干杯！:)</p></blockquote><ul class=""><li id="f836" class="nm nn jj la b lb lc le lf lh no ll np lp nq lt oz ns nt nu bi translated"><a class="ae jg" href="http://seekoapp.io/61356d316220de00093c300e" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk">机器学习A-Z:动手Python &amp; R在数据科学</strong> </a></li><li id="22f1" class="nm nn jj la b lb nv le nw lh nx ll ny lp nz lt oz ns nt nu bi translated"><a class="ae jg" href="http://seekoapp.io/61356d346220de00093c3010" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk">用于数据科学和机器学习的Python训练营</strong> </a></li></ul></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><p id="cc09" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你喜欢这篇文章，请在<a class="ae jg" href="https://lucas-soares.medium.com/" rel="noopener"> Medium </a>、<a class="ae jg" href="https://lucas-soares.medium.com/subscribe" rel="noopener">上关注我，订阅我的简讯</a>，在<a class="ae jg" href="https://twitter.com/LucasEnkrateia" rel="noopener ugc nofollow" target="_blank"> Twitter </a>、<a class="ae jg" href="https://www.linkedin.com/in/lucas-soares-969044167/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>、<a class="ae jg" href="https://www.instagram.com/theaugmentedself/" rel="noopener ugc nofollow" target="_blank"> Instagram </a>或<a class="ae jg" href="https://lucas-soares.medium.com/membership" rel="noopener"> join Medium </a>上与我联系！谢谢，下次再见！:)</p></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><h1 id="07e2" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">参考</h1><ul class=""><li id="c33c" class="nm nn jj la b lb na le nb lh pa ll pb lp pc lt oz ns nt nu bi translated"><a class="ae jg" href="http://www0.cs.ucl.ac.uk/staff/W.Langdon/roc/" rel="noopener ugc nofollow" target="_blank">ROC曲线超赞教程</a></li><li id="7297" class="nm nn jj la b lb nv le nw lh nx ll ny lp nz lt oz ns nt nu bi translated"><a class="ae jg" href="https://stats.stackexchange.com/questions/123124/how-to-determine-the-optimal-threshold-for-a-classifier-and-generate-roc-curve" rel="noopener ugc nofollow" target="_blank">在ROC曲线上堆叠交换螺纹</a></li><li id="500c" class="nm nn jj la b lb nv le nw lh nx ll ny lp nz lt oz ns nt nu bi translated"><a class="ae jg" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener ugc nofollow" target="_blank">维基百科页面上的ROC曲线</a></li><li id="8297" class="nm nn jj la b lb nv le nw lh nx ll ny lp nz lt oz ns nt nu bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/roc-curve-explained-50acab4f7bd8">工整文章由</a> <a class="ae jg" href="https://medium.com/u/5bca2b935223" rel="noopener"> Zolzaya Luvsandorj </a>讲述巨蟒的巨鸟曲线</li></ul></div></div>    
</body>
</html>