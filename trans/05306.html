<html>
<head>
<title>Automatic Dendrogram Cut</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动树状图切割</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automatic-dendrogram-cut-e019202e59a7?source=collection_archive---------25-----------------------#2021-05-10">https://towardsdatascience.com/automatic-dendrogram-cut-e019202e59a7?source=collection_archive---------25-----------------------#2021-05-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8d10" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">实践中打包贝叶斯</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/46a1dd8acb98937c24d74bd5cfd7039f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CF2Kla3s9z0zWLwk"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/@kazuend?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> kazuend </a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="e5df" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">聚类分析是一种探索数据结构的有用技术。在众多算法中，凝聚聚类是一种简单而有用的方法，它通过逐步链接最相似的对，直到所有数据都链接在一起，从而自下而上地建立聚类层次。通过将层次结构表示为树状图，它有助于我们深入了解数据的分布和结构。尽管很有见地，但有时我们可能更希望在实际应用中使用扁平化的表示，结果却是一个关于如何切割树状图的问题。在本文中，我将向您展示我们如何在特定的标准下，最优地将树状图切割成小块，而不是沿着特定的阈值简单地直接切割。</p><h1 id="8be3" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">切割树状图的最佳方式</h1><p id="9450" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">简而言之，我们的目标是将树状图切割成k个不相交的子树，使得一些选择的损失达到最小。损失/选择标准是自由的，一个可能的选择是类内平方和(WCSS)，这是k均值聚类旨在最小化的目标函数。有了标准，下一个问题是，我们如何去做？列举所有的可能性肯定有用，但那样会太累。一个聪明的解决方法是探索最优子结构并执行动态规划。简而言之，为了最优地将整棵树切割成k个子树，这相当于找到最优的kₗ和kᵣ，我们需要从根的左右分支获得子树的数量，使得kₗ + kᵣ = k。对于每个可能的(kₗ，kᵣ)对，我们需要将左右分支切割成kₗ和kᵣ子树，这与我们切割整棵树的问题完全相同。因此，我们可以递归地划分问题，直到树状图的叶子。要了解清楚的细节，这里有戈蒂埃·马蒂<a class="ae kv" href="https://gmarti.gitlab.io/ml/2017/05/12/cut-a-dendrogram.html" rel="noopener ugc nofollow" target="_blank">的一个很棒的帖子</a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/33184bf121b70953bf0f308206f151f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*Xyjs32N3GMD6sVuBH37qfQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">简单的三类数据集。</p></figure><div class="kg kh ki kj gt ab cb"><figure class="mq kk mr ms mt mu mv paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/c64b4ee13730f0c0a35cd17ffcaa24b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*YpPs-oJJJ305P-h6VDfGHw.png"/></div></figure><figure class="mq kk mw ms mt mu mv paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/7839c3e358effc8949997048de819e64.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*8LPYOUOPpPohoCMAkcrAyA.png"/></div></figure><figure class="mq kk mx ms mt mu mv paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/fc6504cd36539ec20e842c4c8f18dfa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*wA4Fa_llPBzLMqjwNxTdvw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk my di mz na translated">平均法树状图。这三种分别是最佳的2切、3切和4切。</p></figure></div><h1 id="f0f5" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">选择要切割树状图的聚类数</h1><p id="9b9c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们已经学习了如何最优地将一个树状图切割成k块，现在我们需要确定我们需要多少个聚类。确定k无疑是我们在进行聚类分析时面临的最困难的问题，特别是当我们希望以数据驱动的方式自动确定k时。在rest内容中，我将介绍一个强大但不太为人所知的框架，称为PAC贝叶斯学习，用于k选择问题。</p><h2 id="87e6" class="nb lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">什么是PAC贝叶斯？</h2><p id="b451" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">可能近似正确，又名PAC，是一个通过构建过度误差的上限来量化可学习性的框架，过度误差是样本内误差和样本外误差(泛化误差)之间的差异。PAC Bayesian扩展了这个框架，它通过引入假设的先验分布来表达关于假设的某种信念，就像我们在Bayesian学习中所做的那样。</p><h2 id="0c61" class="nb lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">它是如何工作的？</h2><p id="14fb" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">关于PAC贝叶斯界的形式其实有很多种，下面我将介绍最基本的(我认为)形式。在贝叶斯设置中，人们通常使用模型证据作为度量来评估模型的性能，并从中选择最佳的一个。它被表述为</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/fdc1075d4c850977b87a2c9630e1e148.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*iyUcDN7-Rdl0VaQM6kOoEg.png"/></div></figure><p id="157c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中D是观测数据，M是模型，θ是模型参数，p(θ|M)是θ的先验分布，p(D|M，θ)是在模型配置为θ的情况下观测到D的可能性。</p><p id="b973" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了评估证据，我们需要计算积分，这有时是棘手的。因此，我们求助于优化它的下界，证据下界(ELBO):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/43a69368a79c2251ff509035273c38e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jiUCopJJd271plyimVBiQQ.png"/></div></div></figure><p id="5961" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于所有可能的q，当q等于后验p(θ|D，M)时，等式成立。因此，给定一组模型，我们可以尝试优化ELBO，并选择最大的ELBO作为最终选择。这个框架是独立的，有很强的理论支持，但有很大的限制，因为我们需要给出有效的概率度量来量化可能性——它当然不适用于我们的树图切割问题。概括的一种方法是将对数似然替换为任意损失函数，得到</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/db8015785f8bcafe54e51fe91561a1a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*3-m_GzhhF6E6Ck5LrTaqKQ.png"/></div></figure><p id="03d8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过一些代数运算，它等价于求的最小值</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/2ce98875e6413ddaca786a3d48a89b86.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*yb7QP35P-jYlg4JXrE9Eig.png"/></div></figure><p id="96da" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为我们有一个单一的切割，而不是对每个k的所有可能性的分布，它进一步退化为</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/bbf50e0d713eba925e31ff07e02838e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*_FoGy92aR3i5HmySg7Clrw.png"/></div></figure><p id="f501" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中前一项是由最优切割产生的总wcs，Zᵏ代表每个观察值的聚类标签。现在，我们只需要指定Zᵏ的先验分布来完成最后一个谜题。一个合理的选择将是中国餐馆过程，一个众所周知的非参数贝叶斯文献中的分布，用于描述聚类标签的分布。它可以通过以下方式进行累积评估</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/9348666031c81ad832dfd28a6b8341f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*KLIY2FugokKROBBBD7oMNg.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/42adf18195d6571766767582c582675e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AM6E-hClD8OY0m601ppJIg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">不同的k与PAC贝叶斯正则化项的损失，λ=0.2，α=1</p></figure><h2 id="85dc" class="nb lt iq bd lu nc nd dn ly ne nf dp mc lf ng nh me lj ni nj mg ln nk nl mi nm bi translated">地毯下的污垢</h2><p id="26c6" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在玩机器学习的时候，我们都知道没有免费的午餐。一个适用于所有数据集的通用λ是不存在的，我们不可避免地要动手寻找最适合数据集的λ。尽管如此，我们至少在系统地解决问题。</p><h1 id="4a29" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">最后的话</h1><p id="1a0f" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">PAC Bayesian是一个强大的、强有力的理论支持框架，用于研究模型的泛化能力，甚至用于过参数化的神经网络。在本文中，我简单地应用了基本形式来解决从一组最优树图切割中选择k的问题，这只是其威力的冰山一角。我希望它能对每个对此感兴趣的人有所帮助和启发。</p><p id="12fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">模拟:<a class="ae kv" href="https://github.com/jerrylin0809/pac-bayesian-dendrogram-cut" rel="noopener ugc nofollow" target="_blank">https://github.com/jerrylin0809/pac-bayesian-dendrogram-cut</a></p></div></div>    
</body>
</html>