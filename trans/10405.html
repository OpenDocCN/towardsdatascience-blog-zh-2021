<html>
<head>
<title>Containerizing Huggingface Transformers for GPU inference with Docker and FastAPI on AWS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过AWS上的Docker和FastAPI实现GPU推理的容器化Huggingface转换器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/containerizing-huggingface-transformers-for-gpu-inference-with-docker-and-fastapi-on-aws-d4a83edede2f?source=collection_archive---------18-----------------------#2021-10-04">https://towardsdatascience.com/containerizing-huggingface-transformers-for-gpu-inference-with-docker-and-fastapi-on-aws-d4a83edede2f?source=collection_archive---------18-----------------------#2021-10-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c8a9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为GPU上的总结任务创建docker容器</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/93d8d0980a477de7bdd6c5637c99773e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4eaVCIX8-4adYqInC5sJug.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者使用来自Canva.com的免费图片</p></figure><p id="9788" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在docker容器中使用<strong class="la iu"> GPU并不简单。容器和主机上的<strong class="la iu"> CUDA和CuDNN驱动程序</strong>之间不应该有任何不匹配，以实现无缝通信。</strong></p><p id="9510" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">理想的方法是在您的docker中使用<strong class="la iu">NVIDIA container toolkit image</strong>，它支持自动识别您的基本机器上的GPU驱动程序，并在Docker容器运行时将这些相同的驱动程序传递到您的Docker容器。在roboflow 团队的这篇<a class="ae lu" rel="noopener" target="_blank" href="/how-to-properly-use-the-gpu-within-a-docker-container-4c699c78c6d1">精彩文章中，你可以读到更多关于在GPU 中使用<strong class="la iu"> Docker的内容。</strong></a></p><p id="7a1d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们将看到如何使用Docker和FastAPI将来自HuggingFace transformers的<strong class="la iu">摘要算法</strong>封装成用于<strong class="la iu"> GPU推理</strong>的容器，并将其部署在一台AWS EC2机器上。如果您想要更多的可伸缩性，您可以使用相同的docker容器来部署容器编排服务，如AWS提供的<strong class="la iu"> ECS </strong>。</p><h2 id="bed2" class="lv lw it bd lx ly lz dn ma mb mc dp md lh me mf mg ll mh mi mj lp mk ml mm mn bi translated">Youtube视频</h2><p id="fb00" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">如果你想看视频，这里有-</p><p id="e838" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae lu" href="https://www.youtube.com/watch?v=I3kkQVNuXyc" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=I3kkQVNuXyc</a></p><h1 id="7013" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">汇总代码</h1><p id="5e2a" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">首先，我们将使用HuggingFace transformers为摘要器编写代码。你可以看看这个<a class="ae lu" href="https://colab.research.google.com/drive/1I60y-8Hu_8gw6B80zovGJfvV-LgVD6G8?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> Colab笔记本</strong> </a> <strong class="la iu"> </strong>自己运行一下看看总结。</p><p id="ca05" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">总结的基本代码如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="b129" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上述代码的输出是我们传递给它的文本的摘要-</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="2a17" class="lv lw it nh b gy nl nm l nn no"><strong class="nh iu">Elon Musk has shown again he can influence the digital currency market with just his tweets. The SpaceX CEO has in recent months often tweeted in support of Dogecoin, but rarely for Bitcoin. In a recent tweet, Musk put out a statement from Tesla that it was concerned about the rapidly increasing use of fossil fuels. A day later he again tweeted saying, To be clear, I strongly believe in crypto but it can't drive a massive increase in fossil fuel use, especially coal. Following the two distinct statements from him, the world's largest cryptocurrency hit a two-month low.</strong></span></pre><p id="6de5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们将看到在AWS EC2机器上将它作为API进行封装和部署的步骤。</p><h1 id="c024" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">集装箱化代码</h1><p id="9d62" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">在这个<a class="ae lu" href="https://github.com/ramsrigouthamg/ramsrigouthamg-GPU_Docker_Deployment_HuggingFace_Summarization" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> Github repo </strong> </a>中提供了为上述摘要算法创建GPU docker容器所需的所有代码。</p><h1 id="60fc" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">启动AWS EC2 GPU机器来服务API</h1><p id="532b" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">我们将从基础AMI映像(深度学习基础AMI (Ubuntu 18.04)版本42.0)启动一台EC2 GPU机器(g4dn.xlarge)，创建docker映像，并运行该映像以在同一台机器上提供用于摘要的API。</p><p id="c19a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">步骤1: </strong>登录AWS控制台，进入EC2仪表板。</p><p id="73b3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">步骤2: </strong>进入仪表板后，点击右上角的<strong class="la iu">“启动实例”</strong>。</p><p id="6b62" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">第三步:</strong>现在我们被要求选择一个AMI。在搜索栏输入<strong class="la iu">“深度学习基础AMI”</strong>。我们没有自己安装CUDA、CuDNN和Docker(这很难),而是选择亚马逊机器映像(AMI ),它已经为我们预装了所有东西。</p><p id="2337" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从返回的选项中选择<strong class="la iu">“深度学习基础AMI (Ubuntu 18.04)版本42.0”</strong>。您可以相应地选择任何更新的映像，与我们docker文件中提到的基础映像中使用的CUDA和CuDNN库版本相匹配。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/cf5a843db37052c6c247c14d5b7a5155.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*umQEpk5_IKewnnTv8i3FMg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自作者AWS帐户的快照</p></figure><p id="5d53" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">步骤4: </strong>在下一个屏幕中选择实例类型。选择<strong class="la iu">“g4dn”</strong>并从选项中选择g4dn.xlarge并继续。请注意，如果您以前没有使用过此GPU，您需要在AWS中提出限额增加请求，以将此GPU分配到您的帐户所在区域。</p><p id="8223" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为什么是G4实例类型？这是可用的AWS实例中最具成本效益的选项。点击阅读更多关于在AWS上选择合适GPU的信息<a class="ae lu" rel="noopener" target="_blank" href="/choosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86">。</a></p><p id="340b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后单击“配置实例详细信息”</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/909d063f24e7a58821426854934954c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l2CEsRGWJAVnVVYUJKSK-Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自作者AWS帐户的快照</p></figure><p id="3339" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">第5步:</strong>保留所有默认设置，然后单击“添加存储”。在“添加存储”部分，记住将根卷大小更改为120 (GiB)等。我们需要这样做，因为我们的docker图像和其他必要的配置需要大量的空间。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/23592b2944c714852d14c523f718475b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ti48A6qi1iQRlcA7ET3AOg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自作者AWS帐户的快照</p></figure><p id="3bb0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">第6步:</strong>接下来点击“添加标签”。这里没什么可改变的。<br/>接下来点击“配置安全组”并点击“添加规则”来添加端口<strong class="la iu"> 80 </strong>的自定义TCP，其来源可以来自任何地方。这将使我们能够在默认端口80上托管API，并从任何地方访问API。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/68a50f8e16474dc24ede8569a9dc186d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v6yDIVpn1aeFAuYpGVS79A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自作者AWS帐户的快照</p></figure><p id="2eaa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">第7步:</strong>接下来点击“审核并启动”，点击“启动”。创建“新的密钥对”或使用现有的密钥对。这用于SSH，如果您在Windows上或从命令行，可以通过Putty等工具连接到EC2机器。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/d5719af329d7ebf16fa6497067b76827.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qSM_YoTiwZusykbPhD3ZWg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自作者AWS帐户的快照</p></figure><p id="25aa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">步骤8: 一旦EC2机器准备就绪，您就可以通过任何SSH客户端连接到它。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/d286333f15ae666a74938b4f778556a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zBmb1wnscs2BlTidTqUuWg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自作者AWS帐户的快照</p></figure><p id="63e4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">步骤9: </strong>一旦你通过SSH进入EC2机器，运行“git clone<a class="ae lu" href="https://github.com/ramsrigouthamg/GPU_Docker_Deployment_HuggingFace_Summarization.git" rel="noopener ugc nofollow" target="_blank">https://github . com/ramsrigouthamg/GPU _ Docker _ Deployment _ HuggingFace _ summary . git</a>”来克隆包含Docker文件的存储库，以将来自hugging face的摘要算法容器化。</p><p id="091b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">第十步:</strong> CD到“GPU _ Docker _ Deployment _ hugging face _ summary”文件夹，依次运行以下命令。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="fce6" class="lv lw it nh b gy nl nm l nn no"><strong class="nh iu">pip3 install transformers==4.6.1<br/>pip3 install torch==1.9.0<br/>python3 download_HF_Question_Generation_summarization.py</strong></span></pre><p id="3034" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们从HuggingFace本地下载摘要模型，并将其打包在docker容器中，而不是每次下载时都将代码放在容器中。</p><p id="64e5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">步骤11: </strong>完成上一步后，使用以下命令构建docker映像</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="9ffc" class="lv lw it nh b gy nl nm l nn no"><strong class="nh iu">docker build -t summarization .</strong></span></pre><p id="73f3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">建立映像需要一些时间，所以请耐心等待。</p><p id="2b8f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">第12步:</strong>一旦构建了映像，使用以下命令运行容器—</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="040a" class="lv lw it nh b gy nl nm l nn no"><strong class="nh iu">docker run -p 80:80 --gpus all summarization</strong></span></pre><p id="81ae" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一旦一切准备就绪，只需在浏览器中访问EC2机器的基本URL，您应该会看到一条“hello world”消息。</p><p id="a31f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">ec2–18–189–32–8.us-east-2.compute.amazonaws.com</p><p id="56a2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">接下来，通过像<a class="ae lu" href="https://www.postman.com/" rel="noopener ugc nofollow" target="_blank"> Postman </a>这样的工具测试摘要API。您可以传入任何文本，并获得它的摘要版本。记住传递<strong class="la iu">文本</strong>以及<strong class="la iu">最小_长度</strong>和<strong class="la iu">最大_长度</strong>参数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/8867787b5a65fed74fe2fcef259d9f57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cPSa_KjVTvRKcg-Pv0DOYA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者快照</p></figure><p id="b17f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您想无限期地运行API，请使用控制台应用程序，如<a class="ae lu" href="https://linuxize.com/post/how-to-use-linux-screen/" rel="noopener ugc nofollow" target="_blank"> Screen </a>，这样即使您关闭连接，API也会继续运行。</p><h1 id="7784" class="mt lw it bd lx mu mv mw ma mx my mz md jz na ka mg kc nb kd mj kf nc kg mm nd bi translated">创建GPU Docker的代码</h1><p id="9494" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">将我们在开头展示的Colab笔记本转换成由FastAPI托管的API的主要代码如下所示</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="53d5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">用于从基础Nvidia映像创建GPU docker的docker文件如下所示</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="3815" class="lv lw it nh b gy nl nm l nn no"><strong class="nh iu">FROM nvidia/cuda:11.0-cudnn8-runtime-ubuntu18.04</strong></span><span id="ad96" class="lv lw it nh b gy nw nm l nn no"><strong class="nh iu">#set up environment<br/>RUN apt-get update &amp;&amp; apt-get install --no-install-recommends --no-install-suggests -y curl<br/>RUN apt-get install unzip<br/>RUN apt-get -y install python3<br/>RUN apt-get -y install python3-pip</strong></span><span id="07b5" class="lv lw it nh b gy nw nm l nn no"><strong class="nh iu"># Copy our application code<br/>WORKDIR /var/app</strong></span><span id="4ad7" class="lv lw it nh b gy nw nm l nn no"><strong class="nh iu"># . Here means current directory.<br/>COPY . .</strong></span><span id="5c08" class="lv lw it nh b gy nw nm l nn no"><strong class="nh iu">RUN pip3 install --no-cache-dir -r requirements.txt</strong></span><span id="6f63" class="lv lw it nh b gy nw nm l nn no"><strong class="nh iu">ENV LC_ALL=C.UTF-8<br/>ENV LANG=C.UTF-8</strong></span><span id="9ea1" class="lv lw it nh b gy nw nm l nn no"><strong class="nh iu">EXPOSE 80</strong></span><span id="2f05" class="lv lw it nh b gy nw nm l nn no"><strong class="nh iu"># Start the app<br/>CMD ["gunicorn", "-b", "0.0.0.0:80","app:app","--workers","1","-k","uvicorn.workers.UvicornWorker"]</strong></span></pre><p id="1133" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是requirements.txt文件</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="50bd" class="lv lw it nh b gy nl nm l nn no"><strong class="nh iu">pydantic==1.8.2<br/>uvicorn==0.14.0<br/>gunicorn==20.0.4<br/>fastapi==0.67.0<br/>torch==1.9.0<br/>sentencepiece==0.1.82<br/>transformers==4.6.1</strong></span></pre><p id="0bd2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">点记:</strong></p><p id="0de2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您想要确定，请确保您创建的docker映像(NVIDIA container toolkit基本映像)中的驱动程序(CUDA和CuDNN版本)与运行容器映像的主机中的GPU驱动程序匹配(或兼容)。在AWS中，您可以选择一台主机作为AMI，它与您用来创建docker映像的NVIDIA container toolkit映像兼容(请记住在您的docker文件中使用NVIDIA/cuda:11.0-cud nn8-runtime-Ubuntu 18.04)。</p><p id="b7ad" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以使用GPU兼容的Amazon机器映像(AMI)作为主机映像，在ECS等容器编排服务上可伸缩地部署API</p></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><p id="5116" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">祝NLP探索愉快，如果你喜欢它的内容，请随时在Twitter上找到我。</p><p id="2942" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你想学习使用变形金刚的现代自然语言处理，看看我的课程<a class="ae lu" href="https://www.udemy.com/course/question-generation-using-natural-language-processing/?referralCode=C8EA86A28F5398CBF763" rel="noopener ugc nofollow" target="_blank">使用自然语言处理的问题生成</a></p></div></div>    
</body>
</html>