<html>
<head>
<title>How to extract tables from PDF using Python Pandas and tabula-py</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Python熊猫和tabula-py从PDF中提取表格</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-extract-tables-from-pdf-using-python-pandas-and-tabula-py-c65e43bd754?source=collection_archive---------4-----------------------#2021-03-25">https://towardsdatascience.com/how-to-extract-tables-from-pdf-using-python-pandas-and-tabula-py-c65e43bd754?source=collection_archive---------4-----------------------#2021-03-25</a></blockquote><div><div class="fc ik il im in io"/><div class="ip iq ir is it"><h2 id="d4db" class="iu iv iw bd b dl ix iy iz ja jb jc dk jd translated" aria-label="kicker paragraph">数据收集</h2><div class=""/><div class=""><h2 id="c0a9" class="pw-subtitle-paragraph kc jf iw bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">一个从PDF中提取重复表格的快捷脚本</h2></div><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ku"><img src="../Images/20111d82a70569db09cdbcc8176e9347.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gvuWgn50Mg3ZBwvKe0Mx8g.jpeg"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">图片来自<a class="ae lk" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=336704" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae lk" href="https://pixabay.com/photos/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=336704" rel="noopener ugc nofollow" target="_blank">免费照片</a></p></figure><p id="2a7a" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">这篇教程是我上一篇文章的改进，在那篇文章中，我在没有Python <code class="fe mh mi mj mk b">pandas</code>的情况下提取了多个表。在本教程中，我将使用与我上一篇文章中相同的PDF文件，不同之处在于我使用Python <code class="fe mh mi mj mk b">pandas</code>处理提取的表格。</p><p id="23b3" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">本教程的代码可以从<a class="ae lk" href="https://github.com/alod83/data-science/tree/master/DataCollection/PDF" rel="noopener ugc nofollow" target="_blank">我的Github库</a>下载。</p><p id="b50b" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">几乎所有被分析的<a class="ae lk" href="https://www.epicentro.iss.it/coronavirus/bollettino/Bolletino-sorveglianza-integrata-COVID-19_17-marzo-2021_appendix.pdf" rel="noopener ugc nofollow" target="_blank"> PDF文件</a>的页面都具有以下结构:</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ml"><img src="../Images/d26a44ac4fdfb4023455a8861f8a7691.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7KSPhFebsl5hLa5XuwO8zg.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="8159" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在页面的右上角有意大利地区的名称，而在页面的右下角有一个表格。</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ml"><img src="../Images/94c62517e1faa496bd418b3d91c0bfca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-vqAjnXfv9wBEuZ2KrfRrQ.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="cc80" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我想提取所有页面的区域名称和表格。我需要提取两个表格的边界框。测量边距的完整程序在<a class="ae lk" href="https://medium.com/analytics-vidhya/how-to-extract-multiple-tables-from-a-pdf-through-python-and-tabula-py-6f642a9ee673" rel="noopener">我的上一篇文章</a>的<em class="mm">定义边距</em>一节中有说明。</p><p id="e293" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">该脚本实现了以下步骤:</p><ul class=""><li id="8b0a" class="mn mo iw ln b lo lp lr ls lu mp ly mq mc mr mg ms mt mu mv bi translated">定义边界框，它通过一个如下形状的列表来表示:<code class="fe mh mi mj mk b">[top,left,bottom,width]</code>。边界框内的数据用厘米表示。它们必须转换成PDF点，因为<code class="fe mh mi mj mk b">tabula-py</code>需要这种格式。我们设定转换因子<code class="fe mh mi mj mk b">fc = 28.28</code>。</li><li id="8e1f" class="mn mo iw ln b lo mw lr mx lu my ly mz mc na mg ms mt mu mv bi translated">使用<code class="fe mh mi mj mk b">read_pdf()</code>功能提取数据</li><li id="49d3" class="mn mo iw ln b lo mw lr mx lu my ly mz mc na mg ms mt mu mv bi translated">将数据保存到<code class="fe mh mi mj mk b">pandas</code>数据帧。</li></ul><p id="2447" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在这个例子中，我们扫描pdf两次:第一次提取地区名称，第二次提取表格。因此，我们需要定义两个边界框。</p><h1 id="e96a" class="nb nc iw bd nd ne nf ng nh ni nj nk nl kl nm km nn ko no kp np kr nq ks nr ns bi translated">提取区域名称</h1><p id="dc6b" class="pw-post-body-paragraph ll lm iw ln b lo nt kg lq lr nu kj lt lu nv lw lx ly nw ma mb mc nx me mf mg ip bi translated">首先，我定义边界框来提取区域:</p><pre class="kv kw kx ky gu ny mk nz oa aw ob bi"><span id="2d30" class="oc nc iw mk b gz od oe l of og">box = [1.5, 22,3.8,26.741]<br/>fc = 28.28<br/>         <br/>for i in range(0, len(box)):<br/>    box[i] *= fc</span></pre><p id="47df" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">然后，导入<code class="fe mh mi mj mk b">tabula-py</code>库，我们定义必须从中提取信息的页面列表，以及文件名。</p><pre class="kv kw kx ky gu ny mk nz oa aw ob bi"><span id="fc0c" class="oc nc iw mk b gz od oe l of og">import tabula as tb</span><span id="52f1" class="oc nc iw mk b gz oh oe l of og">pages = [3,5,6,8,9,10,12,14,16,18,22,24,26,28,30,32,34,36,38,40]<br/>file = “source/Bolletino-sorveglianza-integrata-COVID-19_17-marzo-2020_appendix.pdf”</span></pre><p id="17c0" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在我可以从pdf中读取地区列表。我使用了<code class="fe mh mi mj mk b">read_pdf()</code>函数，我们将输出格式设置为<code class="fe mh mi mj mk b">json</code>。</p><pre class="kv kw kx ky gu ny mk nz oa aw ob bi"><span id="e261" class="oc nc iw mk b gz od oe l of og">regions_raw = tb.read_pdf(file, pages=pages,area=[box],output_format="json")</span></pre><p id="8d1b" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我注意到生成的输出非常复杂。然而，通用结构在位置<code class="fe mh mi mj mk b">regions_raw[i]['data'][0][0]['text']</code>包含第I个区域的区域名称。通过循环进入<code class="fe mh mi mj mk b">region_raw</code>列表，我建立了一个包含所有地区的列表。</p><pre class="kv kw kx ky gu ny mk nz oa aw ob bi"><span id="9959" class="oc nc iw mk b gz od oe l of og">regions = []<br/>for i in range(0,len(regions_raw)):<br/>    regions.append(regions_raw[i]['data'][0][0]['text'])</span></pre><h1 id="4d6f" class="nb nc iw bd nd ne nf ng nh ni nj nk nl kl nm km nn ko no kp np kr nq ks nr ns bi translated">提取第一页的表格(皮德蒙特地区)</h1><p id="965c" class="pw-post-body-paragraph ll lm iw ln b lo nt kg lq lr nu kj lt lu nv lw lx ly nw ma mb mc nx me mf mg ip bi translated">我定义了边界框，我们将转换因子<code class="fe mh mi mj mk b">fc</code>的每个值相乘。为了理解这个机制是如何工作的，首先，我提取第一页的表格，然后我们推广到所有的页面。在此示例中，第一页对应于第3页。</p><pre class="kv kw kx ky gu ny mk nz oa aw ob bi"><span id="39cd" class="oc nc iw mk b gz od oe l of og">box = [8,10,25,26]<br/>for i in range(0, len(box)):<br/>    box[i] *= fc</span></pre><p id="43a3" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在我可以看pdf了。在这种情况下，我将<code class="fe mh mi mj mk b">output_format</code>设置为<code class="fe mh mi mj mk b">DataFrame</code>。结果存储在<code class="fe mh mi mj mk b">tl</code>中，这是一个列表。我可以简单地用<code class="fe mh mi mj mk b">tl[0]</code>把它转换成数据帧。</p><pre class="kv kw kx ky gu ny mk nz oa aw ob bi"><span id="731b" class="oc nc iw mk b gz od oe l of og">page = 3<br/>tl = tb.read_pdf(file, pages=page,area=[box],output_format="dataframe", stream=True)<br/>df = tl[0]<br/>df.head()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div class="gi gj oi"><img src="../Images/206617108a7c9447e9ae663349d42938.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*8I58BrjRxRQw3o6aQtCiFA.png"/></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="fa9a" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我注意到列名是错误的。另外，前三排都是错的。出于这个原因，我可以使用dataframe函数<code class="fe mh mi mj mk b">rename()</code>来重命名列名。</p><pre class="kv kw kx ky gu ny mk nz oa aw ob bi"><span id="1c32" class="oc nc iw mk b gz od oe l of og">df.rename(columns={ df.columns[0]: "Fascia d'età" , df.columns[1]: "Casi"}, inplace = True)<br/>df.head()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div class="gi gj oj"><img src="../Images/e5d4c9d9743771f23db1e5367305e934.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*XxelsbcYP7DA5a20ZE8Y1Q.png"/></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="736a" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在我可以使用<code class="fe mh mi mj mk b">dropna()</code>函数删除前两行。</p><pre class="kv kw kx ky gu ny mk nz oa aw ob bi"><span id="6fae" class="oc nc iw mk b gz od oe l of og">df = df.dropna()<br/>df.head()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div class="gi gj ok"><img src="../Images/9102dbf2c6cd6b807e3e63ee893e4152.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*Cro0ssRJWxiw9EXdCwvKAQ.png"/></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="b8df" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我可以通过选择不包含该值的所有行来删除新的第一行。</p><pre class="kv kw kx ky gu ny mk nz oa aw ob bi"><span id="f9fe" class="oc nc iw mk b gz od oe l of og">df = df[df["Fascia d'età"] != "Fascia d'età"]<br/>df.head(8)</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div class="gi gj ol"><img src="../Images/d790bfc4c2c61a624a5402175c2473d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*7ZMYHoUqUJFkgRzjrru08g.png"/></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="2cca" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在我向<code class="fe mh mi mj mk b">df</code>添加一个新列，称为<code class="fe mh mi mj mk b">Regione</code>，它包含地区名称。我扫描<code class="fe mh mi mj mk b">pages</code>列表来提取当前区域的索引。</p><pre class="kv kw kx ky gu ny mk nz oa aw ob bi"><span id="297c" class="oc nc iw mk b gz od oe l of og">region_column = []<br/>for i in range(0, len(df)):<br/>    index = pages.index(page)<br/>    region_column.append(regions[index])</span><span id="60d8" class="oc nc iw mk b gz oh oe l of og">df['Regione'] = region_column<br/>df.head()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div class="gi gj om"><img src="../Images/003c5817c48ff575c104194958e5f6aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*HY6HCOGGHvlsFc1E48nYMg.png"/></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><h1 id="0222" class="nb nc iw bd nd ne nf ng nh ni nj nk nl kl nm km nn ko no kp np kr nq ks nr ns bi translated">提取所有页面</h1><p id="fc3c" class="pw-post-body-paragraph ll lm iw ln b lo nt kg lq lr nu kj lt lu nv lw lx ly nw ma mb mc nx me mf mg ip bi translated">现在我可以概括前面的代码来提取所有页面的表格。首先，我构建了一个空的<code class="fe mh mi mj mk b">DataFrame</code>，它将包含所有区域的值。我将使用<code class="fe mh mi mj mk b">pd.concat()</code>函数连接所有页面的所有表格。我扫描了包含在<code class="fe mh mi mj mk b">pages</code>列表中的所有页面。</p><pre class="kv kw kx ky gu ny mk nz oa aw ob bi"><span id="e538" class="oc nc iw mk b gz od oe l of og">import pandas as pd<br/>df = pd.DataFrame()<br/>for page in pages:<br/>    <br/>    index = pages.index(page)<br/>    region = regions[index]<br/>    print(region)<br/>    <br/>    tl = tb.read_pdf(file, pages=page,area=[box],output_format="dataframe", stream=True)<br/>    <br/>    dft = tl[0]<br/>    dft.rename(columns={ dft.columns[0]: "Fascia d'età", dft.columns[1]: "Casi"}, inplace = True)<br/>    <br/>    region_column = []<br/>    for i in range(0, len(dft)):<br/>        region_column.append(region)<br/>    dft['Regione'] = region_column<br/>    <br/>    df = pd.concat([df, dft])</span></pre><p id="4fb1" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">与前面的情况类似，我丢弃了所有错误的记录。</p><pre class="kv kw kx ky gu ny mk nz oa aw ob bi"><span id="7bf5" class="oc nc iw mk b gz od oe l of og">df.dropna(inplace=True)<br/>df = df[df["Fascia d'età"] != "Fascia d'età"]</span></pre><h1 id="873b" class="nb nc iw bd nd ne nf ng nh ni nj nk nl kl nm km nn ko no kp np kr nq ks nr ns bi translated">将结果保存到CSV</h1><p id="d191" class="pw-post-body-paragraph ll lm iw ln b lo nt kg lq lr nu kj lt lu nv lw lx ly nw ma mb mc nx me mf mg ip bi translated">现在，我可以将结果保存为csv文件。</p><pre class="kv kw kx ky gu ny mk nz oa aw ob bi"><span id="6c49" class="oc nc iw mk b gz od oe l of og">df.to_csv('output.csv')</span></pre><h1 id="21fd" class="nb nc iw bd nd ne nf ng nh ni nj nk nl kl nm km nn ko no kp np kr nq ks nr ns bi translated">摘要</h1><p id="dd3d" class="pw-post-body-paragraph ll lm iw ln b lo nt kg lq lr nu kj lt lu nv lw lx ly nw ma mb mc nx me mf mg ip bi translated">在本教程中，我演示了如何将多个PDF表格转换成一个单独的<code class="fe mh mi mj mk b">pandas</code> <code class="fe mh mi mj mk b">DataFrame</code>并将其导出为一个CSV文件。</p><p id="4c53" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">该过程包括三个步骤:定义边界框，通过<code class="fe mh mi mj mk b">tabula-py</code>库提取表格，并将它们导出到一个CSV文件。</p><p id="9963" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">如果你想了解我的研究和其他活动的最新情况，你可以在<a class="ae lk" href="https://twitter.com/alod83" rel="noopener ugc nofollow" target="_blank"> Twitter </a>、<a class="ae lk" href="https://www.youtube.com/channel/UC4O8-FtQqGIsgDW_ytXIWOg?view_as=subscriber" rel="noopener ugc nofollow" target="_blank"> Youtube </a>和<a class="ae lk" href="https://github.com/alod83" rel="noopener ugc nofollow" target="_blank"> Github </a>上关注我。</p><h1 id="016e" class="nb nc iw bd nd ne nf ng nh ni nj nk nl kl nm km nn ko no kp np kr nq ks nr ns bi translated">相关文章</h1><div class="on oo gq gs op oq"><a href="https://medium.com/analytics-vidhya/how-to-extract-multiple-tables-from-a-pdf-through-python-and-tabula-py-6f642a9ee673" rel="noopener follow" target="_blank"><div class="or ab fp"><div class="os ab ot cl cj ou"><h2 class="bd jg gz z fq ov fs ft ow fv fx jf bi translated">如何通过python和tabula-py从PDF中提取多个表格</h2><div class="ox l"><h3 class="bd b gz z fq ov fs ft ow fv fx dk translated">通常情况下，您的数据可能不是CSV或JSON格式，但它们包含在一个PDF文件中，格式为…</h3></div><div class="oy l"><p class="bd b dl z fq ov fs ft ow fv fx dk translated">medium.com</p></div></div><div class="oz l"><div class="pa l pb pc pd oz pe le oq"/></div></div></a></div><div class="on oo gq gs op oq"><a href="https://alod83.medium.com/how-to-extract-data-from-a-search-engine-through-python-and-selenium-35dfe6b20db" rel="noopener follow" target="_blank"><div class="or ab fp"><div class="os ab ot cl cj ou"><h2 class="bd jg gz z fq ov fs ft ow fv fx jf bi translated">如何通过python和selenium从搜索引擎中提取数据</h2><div class="ox l"><h3 class="bd b gz z fq ov fs ft ow fv fx dk translated">在本教程中，我将解释如何通过编写一个简单的python脚本从搜索引擎中提取结构化数据…</h3></div><div class="oy l"><p class="bd b dl z fq ov fs ft ow fv fx dk translated">alod83.medium.com</p></div></div><div class="oz l"><div class="pf l pb pc pd oz pe le oq"/></div></div></a></div><div class="on oo gq gs op oq"><a rel="noopener follow" target="_blank" href="/dataset-manipulation-with-open-refine-a5043b7294a7"><div class="or ab fp"><div class="os ab ot cl cj ou"><h2 class="bd jg gz z fq ov fs ft ow fv fx jf bi translated">使用Open Refine操作数据集</h2><div class="ox l"><h3 class="bd b gz z fq ov fs ft ow fv fx dk translated">Open Refine是一个用于清理、转换和丰富数据集的web应用程序。它可以在下载…</h3></div><div class="oy l"><p class="bd b dl z fq ov fs ft ow fv fx dk translated">towardsdatascience.com</p></div></div><div class="oz l"><div class="pg l pb pc pd oz pe le oq"/></div></div></a></div><h1 id="188f" class="nb nc iw bd nd ne nf ng nh ni nj nk nl kl nm km nn ko no kp np kr nq ks nr ns bi translated">新到中？您可以每月订阅几美元，并解锁无限的文章— <a class="ae lk" href="https://alod83.medium.com/membership" rel="noopener">单击此处</a>。</h1></div></div>    
</body>
</html>