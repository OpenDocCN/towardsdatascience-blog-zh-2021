<html>
<head>
<title>20x times faster K-Means Clustering with Faiss</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Faiss的K均值聚类速度提高了20倍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/20x-times-faster-k-means-clustering-with-faiss-5e1681fa2654?source=collection_archive---------15-----------------------#2021-06-25">https://towardsdatascience.com/20x-times-faster-k-means-clustering-with-faiss-5e1681fa2654?source=collection_archive---------15-----------------------#2021-06-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="44dd" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Scikit-learn和Faiss k-Means实现之间的基准时间比较</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/98a2001eebb3d37c41446f83a5f8c6f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Col4uoSbDSoCZ6lK7-8MoQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://pixabay.com/users/anncapictures-1564471/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=2678544" rel="noopener ugc nofollow" target="_blank"> anncapictures </a>来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=2678544" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="c48b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">k-Means聚类是一种基于质心的无监督聚类方法。该技术将数据点聚类成k个聚类或组，每个聚类或组具有几乎相等的数据点分布。每个聚类由其质心表示。</p><p id="0b62" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于一组n个数据点，k-means算法(也称为劳埃德算法)进行优化，以最小化簇内距离并最大化簇间距离。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/9b29f591d856d7b82b6f110eafb28885.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*LWTWFM1QtmBaaMR8qblADg.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)、簇间和簇内距离</p></figure><blockquote class="lw lx ly"><p id="8f18" class="kz la lz lb b lc ld ju le lf lg jx lh ma lj lk ll mb ln lo lp mc lr ls lt lu im bi translated">阅读<a class="ae ky" rel="noopener" target="_blank" href="/understanding-k-means-k-means-and-k-medoids-clustering-algorithms-ad9c9fbf47ca">这篇文章</a>，深入了解k-Means、k-Means++和k-Medoids算法。</p></blockquote><p id="6965" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据<a class="ae ky" href="https://en.wikipedia.org/wiki/K-means_clustering#Complexity" rel="noopener ugc nofollow" target="_blank">维基百科</a>，劳氏算法的运行时间为<code class="fe md me mf mg b"><strong class="lb iu">O(nkdi)</strong></code>，其中:</p><pre class="kj kk kl km gt mh mg mi mj aw mk bi"><span id="6ef9" class="ml mm it mg b gy mn mo l mp mq"><strong class="mg iu">n</strong> is the number of instances in the dataset<em class="lz"><br/></em><strong class="mg iu"><em class="lz">d</em></strong><em class="lz"> </em>is the dimensionality of the vector<br/><strong class="mg iu">k</strong> the number of clusters<br/><strong class="mg iu">i</strong> the number of iterations needed until convergence</span></pre><p id="9982" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Scikit-learn软件包附带了k-Means聚类算法的实现，根据scikit-learn文档，实现k-Means算法的平均时间复杂度为<code class="fe md me mf mg b"><strong class="lb iu">O(nki)</strong></code> <strong class="lb iu"> </strong>。</p><p id="a760" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在一般实践中，k-Means聚类算法是最快的聚类算法之一。当涉及到集群时，大规模数据集scikit-learn包需要大量时间来实现算法。本文将讨论使用Faiss库实现k-Means，并比较算法训练和预测的基准时间数。</p><h1 id="c16a" class="mr mm it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">Faiss:</h1><p id="fd4c" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated"><a class="ae ky" href="https://github.com/facebookresearch/faiss/wiki" rel="noopener ugc nofollow" target="_blank"> Faiss </a>是由<a class="ae ky" href="https://ai.facebook.com/" rel="noopener ugc nofollow" target="_blank">脸书人工智能研究院</a>开发的开源Python包，用于高效的相似性搜索和密集向量的聚类。Fiass可以为任何大小的数据集实现算法，包括那些无法放入RAM的数据集。Faiss是用C++编写的，带有完整的Python包装器。Faiss还附带了评估模型性能和进一步调整模型的实现。</p><h1 id="e614" class="mr mm it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">Scikit-learn vs Faiss:</h1><p id="0903" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">Scikit-learn是一个流行的开源Python包，它实现了各种有监督和无监督的机器学习算法。必须需要调整两个模型的超参数来训练特定的模型。k-Means聚类的超参数包括聚类的数量、重新开始的次数(每次都从其他初始猜测开始)和最大迭代次数。</p><p id="4330" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">k-Means的核心包括搜索最近的邻居，特别是最近的质心，用于训练和预测。Faiss提出了最近邻搜索算法的优化实现。这就是Faiss实现比scikit-learn相对更快的地方。Faiss利用GPU支持和C++实现来加快算法的实现。</p><h2 id="ecaa" class="ml mm it bd ms nn no dn mw np nq dp na li nr ns nc lm nt nu ne lq nv nw ng nx bi translated">使用Scikit-learn实现Faiss:</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><h1 id="5e67" class="mr mm it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">基准时间比较:</h1><blockquote class="lw lx ly"><p id="a110" class="kz la lz lb b lc ld ju le lf lg jx lh ma lj lk ll mb ln lo lp mc lr ls lt lu im bi translated">系统配置:英特尔I7(第七代)，16GB内存</p><p id="736e" class="kz la lz lb b lc ld ju le lf lg jx lh ma lj lk ll mb ln lo lp mc lr ls lt lu im bi translated">下面提到的所有数据集都可以从<a class="ae ky" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/7c8c386010ac6eefdfa444dc918fc25a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i2ag0MH06Na-EmfyS8j7ow.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，用于训练k均值模型的基准时间比较</p></figure><p id="5eb5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">观察上面为各种数据集计算的时间数，scikit-learn k-Means模型的性能优于Faiss的实现。对于大规模数据集，Faiss是明显的赢家。k-Means用Faiss实现几乎比scikit-learn的<strong class="lb iu"> <em class="lz">快20x倍</em> </strong>。然而，如果使用GPU支持，对于大规模数据集，Faiss的性能将进一步提高。</p><h1 id="3212" class="mr mm it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">结论:</h1><p id="3bdc" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">在本文中，我们讨论了使用Faiss包实现k-Means聚类算法。通过观察上面的基准时间比较，我们可以得出结论，对于大规模数据集，Faiss的性能远远优于scikit-learn实现。与scikit-learn相比，k-Means聚类模型的预测时间针对Faiss进行了优化。</p><blockquote class="lw lx ly"><p id="a4f5" class="kz la lz lb b lc ld ju le lf lg jx lh ma lj lk ll mb ln lo lp mc lr ls lt lu im bi translated">阅读下面提到的文章，深入了解聚类算法:</p></blockquote><ul class=""><li id="b307" class="ob oc it lb b lc ld lf lg li od lm oe lq of lu og oh oi oj bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/understanding-k-means-k-means-and-k-medoids-clustering-algorithms-ad9c9fbf47ca">了解K-Means、K-Means++和K-Medoids聚类算法</a></li><li id="09c5" class="ob oc it lb b lc ok lf ol li om lm on lq oo lu og oh oi oj bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/how-to-improve-the-interpretability-of-k-means-clustering-algorithm-3cf0fd0943ba">如何提高k-Means聚类算法的可解释性</a></li><li id="b0a9" class="ob oc it lb b lc ok lf ol li om lm on lq oo lu og oh oi oj bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/fuzzy-c-means-clustering-is-it-better-than-k-means-clustering-448a0aba1ee7">模糊C均值聚类——比K均值聚类好吗？</a></li></ul><h1 id="f51f" class="mr mm it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">参考资料:</h1><p id="2599" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">[1] Faiss文档:<a class="ae ky" href="https://github.com/facebookresearch/faiss" rel="noopener ugc nofollow" target="_blank">https://github.com/facebookresearch/faiss</a></p><blockquote class="op"><p id="550f" class="oq or it bd os ot ou ov ow ox oy lu dk translated">感谢您的阅读</p></blockquote></div></div>    
</body>
</html>