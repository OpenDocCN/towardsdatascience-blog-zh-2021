<html>
<head>
<title>Tips &amp; Tricks: Augmenting Data For NLP Tasks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">提示和技巧:为NLP任务增加数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tips-tricks-augmenting-data-for-nlp-tasks-983e33ad55a7?source=collection_archive---------22-----------------------#2021-04-23">https://towardsdatascience.com/tips-tricks-augmenting-data-for-nlp-tasks-983e33ad55a7?source=collection_archive---------22-----------------------#2021-04-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="ba1a" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/nlpnotes" rel="noopener" target="_blank">自然语言处理笔记</a></h2><div class=""/><div class=""><h2 id="1689" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">扩大NLP数据集的方法</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/6fc84b70e432dc358c6379970203cab1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*j-LKAv5C3z6HnbnV"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@nampoh?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马克西姆·霍普曼</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="dfc2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一般机器学习或自然语言处理管道的开始——在业务问题被确定之后很久——由数据获取阶段组成。在数据采集阶段，从业人员面临的挑战是识别测量现实世界物理条件的采样信号，以便将这些数据转换为计算机可以使用的数字数值。</p><p id="b2b0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果数据随时可用，那么可以跳过这一步——现实世界中很少出现这种情况。如果我们要执行一个NLP项目，我们必须知道一套技术来改进我们的数据集，以满足我们的期望要求。技术的全部范围超出了本文的范围，但是感兴趣的读者可以钻研一下<a class="ae lh" rel="noopener" target="_blank" href="/always-remember-data-comes-before-the-science-681389992082"> <em class="me">永远记住数据先于科学</em> </a>。</p><div class="mf mg gp gr mh mi"><a rel="noopener follow" target="_blank" href="/always-remember-data-comes-before-the-science-681389992082"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jd gy z fp mn fr fs mo fu fw jc bi translated">永远记住数据先于科学</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">获取数据的不同方法</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="ms l mt mu mv mr mw lb mi"/></div></div></a></div><h2 id="40e8" class="mx my it bd mz na nb dn nc nd ne dp nf lr ng nh ni lv nj nk nl lz nm nn no iz bi translated">数据扩充简介</h2><p id="3cd2" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">深度学习模型的预测精度与训练模型所需的数据量有关系。可以肯定地说，对于无监督的深度学习任务，预测精度主要受两个因素的影响；</p><ul class=""><li id="6734" class="nu nv it lk b ll lm lo lp lr nw lv nx lz ny md nz oa ob oc bi translated">可用于训练模型的数据量</li><li id="1d0b" class="nu nv it lk b ll od lo oe lr of lv og lz oh md nz oa ob oc bi translated">训练数据的多样性</li></ul><p id="06fc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果我们希望在解决复杂的NLP任务时达到高性能水平，深度学习通常是首选解决方案。然而，要学习一个可以准确地将输入映射到输出的函数，通常需要我们建立一个具有大量隐藏神经元的非常强大的网络。</p><div class="mf mg gp gr mh mi"><a rel="noopener follow" target="_blank" href="/deep-learning-may-not-be-the-silver-bullet-for-all-nlp-tasks-just-yet-7e83405b8359"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jd gy z fp mn fr fs mo fu fw jc bi translated">深度学习可能还不是所有NLP任务的银弹</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">为什么你仍然应该学习启发式和基于规则的方法</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="oi l mt mu mv mr mw lb mi"/></div></div></a></div><p id="1214" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">随着我们增加隐藏神经元的数量，我们也增加了可训练参数的数量，因此，如果我们希望我们的模型有效地学习，那么我们拥有大量数据是很重要的。</p><blockquote class="oj ok ol"><p id="9ec9" class="li lj me lk b ll lm kd ln lo lp kg lq om ls lt lu on lw lx ly oo ma mb mc md im bi translated"><strong class="lk jd">注意</strong>:我们可以说模型中可学习参数的数量与训练模型所需的数据量成正比。</p></blockquote><p id="7312" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">如果我们没有足够的数据怎么办？</strong></p><p id="925c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">问得好。数据扩充是我们可以用来增加数据集的众多解决方案之一。从本质上讲，数据扩充由各种技术组成，可用于增加我们数据集中的数据量，方法是添加我们已经拥有的数据的稍微修改的副本，或者通过从我们现有的数据创建新的合成数据-我们使用我们的数据来生成更多的数据。</p><p id="022a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些小技巧听起来可能很疯狂，但它们在实践中往往非常有效。数据扩充技术的一些优点是:</p><ul class=""><li id="da25" class="nu nv it lk b ll lm lo lp lr nw lv nx lz ny md nz oa ob oc bi translated">实现速度比允许我们增加数据集的其他技术快得多</li><li id="d155" class="nu nv it lk b ll od lo oe lr of lv og lz oh md nz oa ob oc bi translated">作为一种正则化形式，帮助我们在训练模型时减少过度拟合</li></ul><p id="eb12" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于希望探索更多实践方法的好奇读者，您可能希望深入了解以下资源；</p><p id="edbf" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://arxiv.org/abs/1901.11196" rel="noopener ugc nofollow" target="_blank">简单的数据扩充</a></p><p id="4285" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://github.com/albumentations-team/albumentations" rel="noopener ugc nofollow" target="_blank"> NLP蛋白沉淀</a></p><p id="93f8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://github.com/makcedward/nlpaug" rel="noopener ugc nofollow" target="_blank">NLP 8月</a></p><h2 id="c625" class="mx my it bd mz na nb dn nc nd ne dp nf lr ng nh ni lv nj nk nl lz nm nn no iz bi translated">同义词替换</h2><p id="011b" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">为了执行同义词替换，我们在句子中随机选择非停用词的单词，例如，所有以“s”开头的单词。然后，我们利用这些单词和工具，比如Wordnet中的Sysnets，用它的同义词替换这个单词。</p><h2 id="37aa" class="mx my it bd mz na nb dn nc nd ne dp nf lr ng nh ni lv nj nk nl lz nm nn no iz bi translated">回译</h2><p id="e582" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">想象我们有一个用英语写的句子。这个想法是把这个句子传递给一个翻译系统，这样这个系统就可以把它翻译成另一种语言，比如法语。通过我们的法语翻译，我们用它将句子翻译回英语——下面的GIF展示了一个使用谷歌翻译的很好的演示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi op"><img src="../Images/2d658e1209ff54e9f496e197e3cc3d3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*zAVCNGLDvlCvh0m593VWJA.gif"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者Gif</p></figure><p id="d17f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你可能会注意到，开头的句子写的是“<em class="me">我没有时间给你</em>”，翻译成法语就是“<em class="me">我没有时间为你准备</em>”。当我们把法语翻译成英语时，返回的英语句子写着“<em class="me">我没有时间给你</em>”。虽然这些句子具有完全相同的意思，但所用单词的细微差异使我们能够以一种非常有创意的方式添加到我们的数据集。</p><h2 id="1be1" class="mx my it bd mz na nb dn nc nd ne dp nf lr ng nh ni lv nj nk nl lz nm nn no iz bi translated">二元翻转</h2><p id="f2cf" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">要做二元模型翻转，我们首先要把句子分成二元模型。然后，我们随机选择一些二元模型，然后翻转它们——例如，如果一个二元模型是“<em class="me">我有</em>”，我们将翻转它，使它变成“<em class="me">我有</em>”。</p><h2 id="fa25" class="mx my it bd mz na nb dn nc nd ne dp nf lr ng nh ni lv nj nk nl lz nm nn no iz bi translated">替换实体</h2><p id="49d1" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">这个技巧类似于同义词替换，也很有趣；为了扩大我们的数据集，我们可以简单地用同一实体类别中的另一个实体替换现有的实体。例如，我们可以把一个地方的名字替换成另一个地方的名字——“我住在伦敦”将变成“我住在纽约”。</p><h2 id="8e75" class="mx my it bd mz na nb dn nc nd ne dp nf lr ng nh ni lv nj nk nl lz nm nn no iz bi translated">添加噪声</h2><p id="21fb" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">根据数据的来源，我们的数据集中可能会有一些拼写错误。例如，Twitter上的人们在创建推文时倾向于使用更加非正式的语气。在这种情况下，我们可以向我们的数据中添加噪声，以便通过在句子中随机选择一个单词，并用另一个更接近实际单词的实际拼写的单词来替换它，来训练一个更健壮的模型。</p><h2 id="a3f0" class="mx my it bd mz na nb dn nc nd ne dp nf lr ng nh ni lv nj nk nl lz nm nn no iz bi translated">包裹</h2><p id="dc85" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">数据扩充是一种快速有效的增加训练数据集大小的技术。在本文中，我们介绍了可以用于自然语言处理任务的各种类型的数据扩充技术。同样重要的是要注意，为了使这些技术有效地工作，我们需要有一个初始的干净数据集来开始，不管它有多大。</p><p id="4d53" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">感谢您的阅读！</p><p id="6370" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在LinkedIn和T2 Twitter上与我保持联系，了解我关于数据科学、人工智能和自由职业的最新消息。</p><h2 id="7e77" class="mx my it bd mz na nb dn nc nd ne dp nf lr ng nh ni lv nj nk nl lz nm nn no iz bi translated">相关文章</h2><div class="mf mg gp gr mh mi"><a rel="noopener follow" target="_blank" href="/deep-learning-may-not-be-the-silver-bullet-for-all-nlp-tasks-just-yet-7e83405b8359"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jd gy z fp mn fr fs mo fu fw jc bi translated">深度学习可能还不是所有NLP任务的银弹</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">为什么你仍然应该学习启发式和基于规则的方法</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="oi l mt mu mv mr mw lb mi"/></div></div></a></div><div class="mf mg gp gr mh mi"><a rel="noopener follow" target="_blank" href="/never-forget-these-8-nlp-terms-a9716b4cccda"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jd gy z fp mn fr fs mo fu fw jc bi translated">永远不要忘记这8个NLP术语</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">所有NLP爱好者都应该知道术语</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="oq l mt mu mv mr mw lb mi"/></div></div></a></div><div class="mf mg gp gr mh mi"><a rel="noopener follow" target="_blank" href="/a-guide-to-encoding-text-in-python-ef783e50f09e"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jd gy z fp mn fr fs mo fu fw jc bi translated">Python文本编码指南</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">教计算机理解人类语言</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="or l mt mu mv mr mw lb mi"/></div></div></a></div><div class="mf mg gp gr mh mi"><a rel="noopener follow" target="_blank" href="/a-guide-to-cleaning-text-in-python-943356ac86ca"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd jd gy z fp mn fr fs mo fu fw jc bi translated">Python文本清理指南</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">为机器阅读准备自然语言</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="os l mt mu mv mr mw lb mi"/></div></div></a></div></div></div>    
</body>
</html>