<html>
<head>
<title>A Machine Learning Algorithm for Predicting Outcomes of MLB Games</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测MLB游戏结果的机器学习算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-machine-learning-algorithm-for-predicting-outcomes-of-mlb-games-fa17710f3c04?source=collection_archive---------7-----------------------#2021-10-06">https://towardsdatascience.com/a-machine-learning-algorithm-for-predicting-outcomes-of-mlb-games-fa17710f3c04?source=collection_archive---------7-----------------------#2021-10-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="460f" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="e9b3" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">机器学习方法能提供超越大众智慧的增量信息优势吗？</h2></div><p id="b51c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="lk">我的大部分代码都可以在GitHub上的</em> <a class="ae ll" href="https://github.com/GarretNourse/Machine-Learning-Predict-MLB-Games" rel="noopener ugc nofollow" target="_blank"> <em class="lk">这里</em> </a> <em class="lk">供读者细读。本文的第一部分介绍了机器学习的几个关键概念元素，而后半部分则侧重于算法方法论。</em></p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lm"><img src="../Images/568fe02bbe7390dd74b7318fd2ac7dbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cKiLom7N6gOlIUg8ku0lIQ.jpeg"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">unsplash.com</p></figure><p id="558a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">原始数据不受认知偏见的影响——没有人类的情感和倾向。在这一理念的指导下，比利·比恩的2001 Oakland As为渴望获得冠军的球会设计了一个新的统计蓝图，并催化了一场数据分析革命，这场革命像野火一样蔓延到职业体育的各个方面。正如比恩发现的那样，棒球的丰富数据非常适合预测分析。我选择探索的问题是利用机器学习来预测单个游戏的结果。我的最终逻辑回归和随机森林模型达到了现有科学文献中较高水平的测试精度，并在两年的测试期内超过了拉斯维加斯的博彩赔率。我的结果证实了投注赔率是高效的；然而，我的发现也表明，机器学习方法可能会提供超越大众智慧的增量信息优势，从长远来看，这可能会转化为有意义的见解。我的模型还揭示了团队投球的重要性，即一个团队牛棚的力量比其进攻的质量更能表明其获胜的能力。总的来说，从我的算法中得出的基本方法和见解可能对职业棒球大联盟前台办公室或各种其他体育分析实体的战略决策有用。</p><p id="240a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了构建数据集，我采用了网络搜集来汇总baseball-reference.com 20年的常规赛数据，总共大约48，000场比赛，并搜集了每场比赛的击球和投球统计数据，以计算诸如上垒率(OBP)、每局保送和击球(WHIP)以及平均得分(ERA)等指标。与现有的文献不同，我还包括了每场比赛开始前投手们整个赛季的表现。这是一个计算密集型过程，但在我看来，这是我的模型的一个关键优势，因为它提供了一个有意义的变量，与其他要素具有较低的多重共线性。此外，我推导出了一种方法，通过检查每场比赛失分的分布来衡量一支球队的一致性。我的模型中其他值得注意的特性是比尔·詹姆斯的毕达哥拉斯期望和Log5指标，它们分别根据球队以前的得分和胜率来评估球队。我还在我的分析中包含了双重标题，回想起来，这可能不值得增加编程负担。为了避免疑问，我获得了baseball-reference.com的许可来收集它的数据。</p><p id="c6b8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">任何一场MLB游戏的结果都充满了变数和纯粹的运气——在某种意义上与抛硬币有相似之处。现存最好的科学文献(<a class="ae ll" href="https://beta.vu.nl/nl/Images/werkstuk-elfrink_tcm235-888205.pdf" rel="noopener ugc nofollow" target="_blank">埃尔夫林克</a>、<a class="ae ll" href="https://www.researchgate.net/publication/311862823_Predicting_Win-Loss_outcomes_in_MLB_regular_season_games_-_A_comparative_study_using_data_mining_methods" rel="noopener ugc nofollow" target="_blank">瓦莱罗</a>、<a class="ae ll" href="http://cs229.stanford.edu/proj2013/JiaWongZeng-PredictingTheMajorLeagueBaseballSeason.pdf" rel="noopener ugc nofollow" target="_blank">贾</a>等。)产生了57–59.5%范围内的准确度水平。从表面上看，这似乎很平常；然而，就我们的问题而言，这已经很不错了。作为参考，拉斯维加斯博彩赔率——通常被认为是职业体育运动最佳预测指标的晴雨表——在过去六年中的准确率仅为58.2%(使用covers.com的数据计算)。达到比共识高百分之一的精度水平可能会被证明是非常有价值的。我的逻辑回归和随机森林模型分别实现了58.9%和59.6%的独立分类准确率，后者在2018年和2019年的赛季中略高于拉斯维加斯的博彩赔率0.2%。当将投注赔率作为额外的输入变量纳入模型本身时，组合随机森林模型的准确率达到61.1%，比2019年的投注赔率高出0.8%。逻辑回归算法在同一时期达到了60.5%。注意:出于我们的目的，我简单地将准确度定义为被算法h:1/m⋅σ(h(xᵢ)=f(xᵢ)).正确分类的点的百分比</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><p id="fa76" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">机器学习是对预测算法的研究，这些算法在从数据中学习时会自动改进。第一步是选择一个假设类(一族分类器)。例如，如果我们试图根据鳄梨的颜色和硬度来预测它的味道，一个可能的假设类可能是欧几里得平面上封闭矩形的特征函数族:{ f(x；y) ∈ [x₁，y₁] × [x₂，y₂]}，我们的算法将“学习”这个类，以找到具有硬度和颜色的最佳上下边界的矩形。换句话说，这种算法将根据过去对鳄梨质量进行最准确分类的一系列硬度和颜色来预测新鳄梨的质量。直觉上，我们的目标是最小化错误分类鳄梨的概率，即我们的分类器的真实误差。当然，准确的潜在概率分布永远不可能精确知道，因为我们不可能得到世界上的每一个鳄梨。然而，我们的算法在样本数据中误分类的点的百分比，称为经验误差，可以作为所需真实误差的代理。在这个样本数据上实现最小误差的分类器被称为经验风险最小化器(ERM)。</p><p id="b101" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">ERM是一种自然的逻辑方法，但我们必须小心过度拟合——我们的算法在训练数据上表现得非常好，但在预测新的、看不见的数据时表现不佳。例如，可以将n-1次多项式拟合到n个数据点，这将完美地预测我们的训练数据中的每个点，但泛化能力很差。另一方面，拟合不足是指使用的模型对于数据来说不够复杂，例如对存在二次关系的数据集应用线性回归。众所周知的偏差-方差权衡，这种选择平衡模型的简单性和准确性的假设类以便很好地推广到看不见的数据的概念是机器学习的一个重要原则。</p><p id="7c9f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">衡量模型预测能力的最佳方式是从一开始就留出一部分数据并隐藏起来，不让分析人员看到。然后，我们根据未隐藏的数据(称为训练数据)训练我们的模型，并随后根据测试数据进行预测，以模拟现实世界的场景。最终，我们希望我们的模型在训练和测试数据上的准确性大致相等。不成比例的高训练与测试精度表明过度拟合。针对手头的问题，我拿出了2018和19赛季作为测试数据，大概4800场，在2000到17赛季的基础上训练模型。我选择训练和测试数据截止点是为了避免使用从尚未发生的游戏中提取的信息来预测未来，这种现象称为数据泄漏。最后一点:预测棒球比赛的结果是一个二元分类问题，即主队是赢还是输。</p><h2 id="6463" class="mj mk iq bd ml mm mn dn mo mp mq dp mr kx ms mt mu lb mv mw mx lf my mz na iw bi translated"><strong class="ak">特色工程</strong></h2><p id="1f4a" class="pw-post-body-paragraph ko kp iq kq b kr nb ka kt ku nc kd kw kx nd kz la lb ne ld le lf nf lh li lj ij bi translated">数据提取过程是计算密集型的，并且通常在编程上是严格的。例如，检索和计算每场比赛前先发投手的个人年龄需要大约20个小时。尽管如此，获取大量数据通常非常有帮助，因为我们的训练数据将更好地反映真实的底层分布，而经验误差(假设我们没有过度拟合)应该更好地反映真实误差。我通过特征工程添加的第一个指标是比尔·詹姆斯的毕达哥拉斯预期，这是一个win%的代理，它代表了一个球队在那个赛季的总得分与失分之比。毕达哥拉斯期望=(得分得分)/[(得分得分得分)+(允许得分)]。<a class="ae ll" href="https://content.iospress.com/download/journal-of-sports-analytics/jsa0018?id=journal-of-sports-analytics%2Fjsa0018" rel="noopener ugc nofollow" target="_blank">杰伊·休曼通过回溯测试发现</a>最佳指数应该是1.83，而不是2。我运行了这两种方法，将指数参数设置为1.83产生了与目标变量更高的相关性，所以我选择使用1.83。</p><p id="7d0d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我添加的下一个功能是Log5:p(j beats k)=(Pⱼ-(pⱼ⋅Pₖ))/(pⱼ+pₖ-(2⋅pⱼ⋅pₖ)其中pⱼ是j队赢的游戏的百分比，pₖ是我的k队赢的游戏的百分比。log5公式非常直观。详细解释请看詹姆斯解说<a class="ae ll" href="https://www.billjamesonline.com/the_log5_method_etc_etc_etc_/" rel="noopener ugc nofollow" target="_blank">此处</a>。实质上，他推导出了A队和B队胜率之间的巧妙数学关系，以确定A队获胜的概率。此外，我在每场比赛前计算了每支球队的OBP、SLG、ERA、FIP和WHIP指标，还包括每项指标的3天、5天、7天、… 15天平均值。为了平衡准确性和与其他功能的低多重共线性，我最终决定采用10天跟踪平均值来捕捉团队的短期表现。这些10天的跟踪指标被认为是球队整个赛季指标的补充。我还添加了物理学家<a class="ae ll" href="https://www.researchgate.net/publication/266473425_Beyond_Pythagorean_expectation_How_run_distributions_affect_win_percentage" rel="noopener ugc nofollow" target="_blank">克里·惠斯南特的公式</a>。Whisnant开始创建一个衡量标准，也考虑到了球队得分的一致性。他发现击球率较高的球队通常得分分布较窄。尽管Whisnant的公式在我的模型中的预测能力低于PE或Log5，但它仍然与目标变量有着有意义的相关性，这让我想到了捕捉团队一致性的各种其他方法。</p><p id="274e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">与<a class="ae ll" href="https://blogs.fangraphs.com/does-consistent-play-help-a-team-win/" rel="noopener ugc nofollow" target="_blank">比尔·佩蒂的发现</a>一致，我的结果表明，一个团队让步的一致性比得分的一致性更重要(与目标变量的相关性更高)。然而，仅仅找到得分和失分的标准偏差本身并不是有用的度量，因为，当然，一个队得分不能少于零分，所以一个队得分的分布在零处被切断。换句话说，得分低的团队比得分高的团队有更低的标准差，部分原因是因为他们得分低。我想只分离和提取一个团队的一致性，不管它实际得分多少，以便比较苹果。</p><p id="5359" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我的解决方法是这样的:我取了过去20年来每支球队失球次数的平均值以及失球次数的标准差，并对过去20个赛季的所有30支球队都这样做了。然后，我对这600个数据点拟合了一个线性回归模型，创建了一个函数，其输入是每场比赛的平均失球次数，其输出是失球次数的标准差。换句话说，这个函数提供了一个团队的标准偏差“应该”基于其平均值的基线。得分跑垒。标准偏差低于基线的团队更加一致，反之亦然。对于每场比赛，我计算了两个队的基线，并从中减去每个队失球的实际标准差。然后，我从B队的人数中减去A队的人数，以衡量A队相对于B队的一致性，较高的值表明主队(A队)比B队更一致。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ng"><img src="../Images/7c725b2b6714e8baf693bc31a4bbb049.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WpYNMJwtntlFBlJrMHklSA.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">平均值。每场比赛的失分相对于平均值的标准差有所下降。2000-2019年每场比赛失球数(图片由作者提供)</p></figure><p id="599b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如上所述，残差之间没有可辨别的模式，因此异方差不是问题。残差也呈现出均值为零的正态分布。这些都是执行线性回归的必要属性。</p><h2 id="9724" class="mj mk iq bd ml mm mn dn mo mp mq dp mr kx ms mt mu lb mv mw mx lf my mz na iw bi translated"><strong class="ak">探索性数据分析</strong></h2><p id="26ce" class="pw-post-body-paragraph ko kp iq kq b kr nb ka kt ku nc kd kw kx nd kz la lb ne ld le lf nf lh li lj ij bi translated">在选择正确的特征输入模型时，我们希望捕获与目标变量最相关的输入变量。然而，我们也希望避免冗余或无关变量会削弱我们的模型效力的情况。让许多相似的特征给我们相同的信息是不可取的。换句话说，我们希望输入要素具有较低的多重共线性。下面是变量的相关热图。除了log5和Whisnant之外的所有指标都表示为主队和客场队之间的差异(δ<strong class="kq ja">)</strong>。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi nh"><img src="../Images/68f10f2f37b301a8bf1a8633c47a5e8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_YW2YhHpnfpBDCHUGRqbtQ.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">相关热图(图片由作者提供)</p></figure><p id="f1df" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如上所述，毕达哥拉斯期望(δPE)和Log5与我们的目标变量具有最高的相关性。团队投球指标似乎是第二有价值的，其中WHIP最有价值，这表明不允许保送和安打(OBP的理论相反)是球队赢得比赛的最重要的考虑因素。先发投手自责分率的差异(SP _ ERA)也有很好的特性:与其他特征的多重共线性低，以及与我们的目标变量的一些有意义的相关性。从逻辑上来说，这是有道理的，因为一个特定的先发投手的质量应该在很大程度上独立于一个球队的进攻或牛棚的其他人的质量，应该对比赛的结果产生实质性的影响。10天跟踪δPE、δOBP、SLG和WHIP也很有帮助，因为它们可以作为团队短期表现的代理，并且与其他变量的多重共线性较低。鉴于ERA与WHIP和WHIP的高度相关性，我选择从模型的最终输入变量中忽略ERA。然而，由于我有数万个数据点和不到15个特征，我选择保留所有其他特征。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ni"><img src="../Images/2fbd106e45d39270fe2c6691cbfb0c77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3dLhDgmYYL55NveRnsvI8Q.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">(图片由作者提供)</p></figure><p id="2d2f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">以上是一些关键变量的分布。正如您所看到的，它们看起来是正态分布的，这在开发模型时会很有帮助。</p><h2 id="ce3c" class="mj mk iq bd ml mm mn dn mo mp mq dp mr kx ms mt mu lb mv mw mx lf my mz na iw bi translated"><strong class="ak">逻辑回归模型</strong></h2><p id="3a11" class="pw-post-body-paragraph ko kp iq kq b kr nb ka kt ku nc kd kw kx nd kz la lb ne ld le lf nf lh li lj ij bi translated">逻辑回归使用logit函数，即众所周知的sigmoid函数的逆函数，从输入变量的线性组合中获得离散输出。我们使用简单线性回归的等式，并将其设置为等于我们事件的对数概率:β₁x+β₀ = log[P/(1-P)]。求解p得到1/(1+eᶻ)其中z = β₁x+β₀.注意:我们取赔率的对数，以便获得围绕原点对称的范围。在潜在的logit曲线族(假设类)中，我们的算法选择最大化观察样本的可能性的曲线。</p><p id="ab5d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了更好地理解最大似然，考虑一个简单直观的例子:假设我们有一个包含三个球的盒子，每个球可以是绿色或蓝色。假设我们从盒子里拿两个球，它们都是绿色的。我们对第三个球的颜色的最佳猜测应该是什么？嗯，有两种可能的选择，因为我们已经看到了两个绿色的球，要么是θ₁:盒子里有三个绿色的球，要么是θ₂:盒子里有两个绿色和一个蓝色的球。鉴于盒子里有三个绿色球，观察到我们的两个绿色球样本的几率显然是100%: P(S|θ₁) = 1。对于第二种情况，假设盒子里实际上有两个绿色球和一个蓝色球，选择两个绿色球的概率是P(S|θ₂) = ⅔ ⋅ = ⅓.很明显，1 &gt; ⅓，所以我们的“最佳猜测”——最大化观察样本可能性的选择——是三个绿球。我们的逻辑回归模型以这种方式运行，选择logit曲线，在给定该曲线参数的情况下，使观察到每个数据点的概率的乘积最大化:arg max[π(P(Xi |θ))]。这就是它“学习”假设类的方式。</p><p id="e221" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">一种称为正则化的方法通过在大系数的损失函数中添加惩罚来防止我们的模型过度拟合。通过惩罚模型中增加的复杂性，我们可以防止过度拟合。为了找到最佳的正则化常数，我使用了k重交叉验证。K-fold验证非常聪明和直观。首先，我们将训练数据分成k个折叠，并将第一个折叠作为我们的验证数据集。然后，我们在其他k-1个折叠上训练该模型，并在第一个折叠上测试它。我们对k个折叠中的每一个重复这个过程，最后平均所有的测试折叠精度水平，以达到模型的更精确的整体精度。在我的模型中，我使用k-fold验证进行超参数调整，每次修改模型时都执行k-fold，以便找到最佳参数。在逻辑回归的情况下，我遍历0到1之间的正则化常数，并在k倍中选择平均精度最高的常数。K-folds验证对于随机森林模型非常有用，因为它有更多的模型参数。</p><p id="3dc4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在2000年至2017年赛季进行训练后，逻辑回归算法在2018年至2019年赛季进行测试时，准确率达到了58.9%，而同期拉斯维加斯博彩赔率的准确率为59.4%(从covers.com刮来)。然后，我选择将博彩赔率作为输入特性之一合并到我的模型中。这种组合的逻辑回归模型在2019赛季达到了60.5%的准确率，略高于博彩赔率60.3%的独立准确率。我只能获得追溯到2014年的博彩赔率，所以为了保存足够大部分的数据用于训练集，我只在测试期间使用了一个赛季，而不是两个赛季。</p><h2 id="12aa" class="mj mk iq bd ml mm mn dn mo mp mq dp mr kx ms mt mu lb mv mw mx lf my mz na iw bi translated"><strong class="ak">随机森林算法</strong></h2><p id="8d30" class="pw-post-body-paragraph ko kp iq kq b kr nb ka kt ku nc kd kw kx nd kz la lb ne ld le lf nf lh li lj ij bi translated">随机森林算法基于决策树的概念。我们所有人每天都在使用决策树；它们仅仅是一系列逻辑的“如果-否则”问题，以最终得出结论。决策树从根节点开始，接着是分支节点和叶节点。为了确定根节点使用什么值，该算法选择最能分离数据的变量。这通常是用基尼系数来计算的。在我们的鳄梨例子中，如果颜色具有最低的基尼杂质(如果大多数绿色鳄梨味道不好，大多数黑色鳄梨味道好)，那么逻辑上根节点的第一个if-else语句应该是:鳄梨是绿色的吗？直觉上，这是有意义的，因为如果我们知道颜色是区分好的和坏的鳄梨的最好方法，这应该是我们问的第一个问题。在根节点之后，我们将有两条边指向另外两个节点；这一次我们可能会问鳄梨是高于还是低于一定的硬度，基于这一点，我们可以将其分为味道好还是不好。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi nj"><img src="../Images/62f93dba61e16cbaba26300b80814d73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xeFw6dY8cDgZWQRq_FTwVg.jpeg"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">unsplash.com</p></figure><p id="bef6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">单个决策树通常容易过度拟合，并且不能很好地推广到新数据，因为复杂性在每个新节点都会显著增加。一个巧妙的方法来避免这个问题，但保留了决策树的理想属性是随机森林。由许多决策树(称为集合)组成的随机森林通过称为bagging或bootstrapping的过程从数据集中随机选择样本(替换)，以形成每棵树的新训练集。它还将每棵树限制为N个特征的随机子集。实践表明，<strong class="kq ja"> √ </strong> N通常是为每棵树随机选择的最佳特征数。每个人都在他们自己的引导数据集上接受训练，树的联合体，所有不同的结构，最终投票决定是否将数据点分类为1或0。获得最多投票的输出成为算法的预测。随机森林的美妙之处在于，许多不相关的树将共同产生一个较低方差的一致估计，最终比任何单独的决策树更高的真实准确性。</p><p id="9e1f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">一旦组合，随机森林算法可以通过改变其参数进行微调，以找到最准确的模型，不会过拟合或欠拟合。这一步被称为超参数调整，是一个优化问题，以确定最大深度、树的数量、每棵树的最大特征等的最佳组合。我使用嵌套for循环来生成许多不同的参数组合，并且每次都运行k重验证，为我的最终模型选择在k重中产生最高平均精度水平的组合。最佳的最大深度和最大特征分别是5和4。在2018年至2019年赛季，随机森林模型在逻辑回归模型的基础上进行改进，达到了59.6%的准确率，而博彩赔率的准确率为59.4%。当将博彩赔率作为模型本身的输入变量时，随机森林算法在2019年赛季取得了61.1%的准确率，而拉斯维加斯的赔率为60.3%。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/042bc286f661fa67c30c751898ac1ca4.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*T5s0_Zuif1LrrnU95-aIaA.png"/></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">(图片由作者提供)</p></figure><p id="4daa" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下面是随机森林模型和虚拟决策树分类器的特征重要性图表。比尔·詹姆斯的毕达哥拉斯预期显然是最有价值的特征，它重申了一个不言自明的概念，即要赢得比赛，你必须得分比你承认的多。一个更有启发性的观点是，在得分和胜率之后，投球是胜率最重要的决定因素。贪婪的全垒打和强大的进攻能力经常得到大多数媒体和球迷的关注，但也许前台应该更关心投资他们的牛棚。尽管在探索性数据分析中OBP和SLG与目标变量的相关性更高，但SP _ ERA的重要性如此之高，这一事实进一步强调了这一概念。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi nl"><img src="../Images/34d9ba734c858f1af677571804448421.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*clK7WfNiZqQew7DdKx-dDw.png"/></div></div><p class="ly lz gj gh gi ma mb bd b be z dk translated">(图片由作者提供)</p></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><p id="f586" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">最后，我要感谢Guillermo Reyes博士(机器学习的数学教授)和James Faghmous博士(Python中应用机器学习的教授),感谢他们这学期让我着迷于机器学习，并在我整个过程的每一步提供了宝贵的建议。</p></div></div>    
</body>
</html>