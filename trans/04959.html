<html>
<head>
<title>A Peek at Data Sampling Methods</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据采样方法管窥</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-peek-at-data-sampling-methods-5d7199c8aab8?source=collection_archive---------20-----------------------#2021-04-30">https://towardsdatascience.com/a-peek-at-data-sampling-methods-5d7199c8aab8?source=collection_archive---------20-----------------------#2021-04-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9d4c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">确保你从数据中得出有效的结论</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/87dddf2907ffbaa78919d4e912919660.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*P0XtndB9Nl3EBvV8"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@nci?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">国家癌症研究所</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="016c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">抽样偏差是现实世界中最常见的偏差类型之一。当用于训练模型的数据不能反映模型在生产时将接收的样本的分布时，就会出现这种情况。</p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/tackling-different-types-of-bias-in-data-projects-29e326660639"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">处理数据项目中不同类型的偏差</h2><div class="mf l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mg l"><div class="mh l mi mj mk mg ml ks ly"/></div></div></a></div><p id="bca8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一般来说，每当我们从事机器学习项目时，对将在生产环境中观察到的数据中各种属性的真实比例进行正确的研究是至关重要的。</p><p id="6dea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，当我们实际处理一个问题并且数据集非常大时，处理整个数据集通常是不实际的，也没有必要，除非您希望在处理转换和特征工程发生时等待数小时。</p><p id="3e8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个更有效的策略是，从你的数据中抽取一个足够有用的样本来学习有价值的见解，这个策略仍然允许你从你的结果中得出有效的结论。这种技术被称为<em class="mm">数据采样</em>。</p><h1 id="554f" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">什么是数据采样？</h1><p id="db9d" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">我们将来自较大人群的观察结果子集称为<strong class="lb iu">样本</strong>。<strong class="lb iu">然而，取样</strong>是指我们的研究将从中收集数据的观察组。因此，数据采样可以定义为从业者用来选择代表较大总体的观察值子集的技术。</p><p id="5dc6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通常，与数据打交道的人(即数据科学家、数据分析师等。)使用数据采样技术将大型数据集减少到更小、更易管理的数据量，而不牺牲其洞察力的准确性。</p><p id="f938" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有两种主要的数据采样策略:</p><ul class=""><li id="19b7" class="nk nl it lb b lc ld lf lg li nm lm nn lq no lu np nq nr ns bi translated"><strong class="lb iu">概率抽样</strong>涉及随机选择。数据中的所有观察值都有机会被选择，因此可以对整个群体进行强有力的统计推断。</li><li id="386c" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><strong class="lb iu">非概率抽样</strong>不涉及随机选择。相反，它是基于方便或其他标准。因此，无论构建了多少个样本，一些观察值都没有机会被选中。</li></ul><p id="f59b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">非概率抽样方法的一个主要缺陷是它们包括非代表性的样本，并且重要的观察值可能被排除在样本之外。因此，通常建议首先考虑概率抽样方法，这也是我在本文剩余部分只关注这种抽样方法的原因。</p><h1 id="8183" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">概率抽样方法</h1><p id="0495" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">如前所述，我们通常在因为数据太大以及其他原因(如时间、成本等)而无法研究整个人群的情况下利用数据采样方法。).</p><p id="7a18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个演示中，我们将使用我用Python创建的合成数据——参见下面的代码。</p><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="43c4" class="od mo it nz b gy oe of l og oh">import numpy as np<br/>import pandas as pd</span><span id="ee68" class="od mo it nz b gy oi of l og oh"># create synthetic data<br/>id = np.arange(0, 10).tolist()<br/>distance = np.round(np.random.normal(loc=100, scale =5, size=len(id)), 2)</span><span id="a644" class="od mo it nz b gy oi of l og oh"># convert to pandas dataframe<br/>data = {"id":id, "distance": distance}<br/>df = pd.DataFrame(data=data)</span><span id="4ed1" class="od mo it nz b gy oi of l og oh">df</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/124ed2c74aea1fdfb240261e8aa629b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*hlBMM9UexNzxgSdgTZGAQA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h2 id="abd8" class="od mo it bd mp ok ol dn mt om on dp mx li oo op mz lm oq or nb lq os ot nd ou bi translated">简单随机抽样</h2><p id="0159" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">最直接的数据采样方法是简单的随机采样。本质上，子集是由从一个更大的集合中完全随机选择的观察值构成的；每个观察值都有相同的机会从较大的集合中被选中。</p><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="0ea8" class="od mo it nz b gy oe of l og oh"># simple sampling example<br/>simple_random_sample = df.sample(n=5, random_state=24)<br/>simple_random_sample</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/620a7ab74ab3eace5cdb1acc895d2fb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*11IOO_Pq0UjsgHkqXbhjAg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="275c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简单随机抽样极其简单，易于实现。另一方面，我们仍有可能在样本数据中引入偏差。例如，考虑一个事件，其中我们有一个带有不平衡标签的大型数据集。通过执行简单的随机抽样，我们可能会意外地无法捕捉到足够多的样本来代表少数群体——如果我们能捕捉到任何一个的话。</p><h2 id="b67d" class="od mo it bd mp ok ol dn mt om on dp mx li oo op mz lm oq or nb lq os ot nd ou bi translated">间隔抽样</h2><p id="57ad" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">间隔抽样是一种技术，它通过定期从较大的集合中选择观测值来创建子集。例如，我们可以决定从更大的集合中选择每31个观察值。</p><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="1fce" class="od mo it nz b gy oe of l og oh"># interval sampling example<br/>idx = np.arange(0, len(df), step=2)<br/>interval_sample = df.iloc[idx]<br/>interval_sample</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/e62ff434cbddcbd1a3a3a476b6732c89.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*UCS64FzxM5KQM9-aW41kZw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="69eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果观察值是随机的，那么间隔抽样通常会比简单的随机抽样返回更好的样本。然而，如果在我们的数据中有周期性或重复的模式，那么间隔抽样是非常不合适的。</p><h2 id="8adc" class="od mo it bd mp ok ol dn mt om on dp mx li oo op mz lm oq or nb lq os ot nd ou bi translated">分层抽样</h2><p id="2f57" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">分层随机抽样将较大的数据集分成称为分层的组。从这些组中，我们随机选择我们想要创建新子集的观察值。从每个阶层中选择的例子的数量与阶层的大小成比例。</p><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="dcda" class="od mo it nz b gy oe of l og oh">from sklearn.model_selection import StratifiedKFold</span><span id="860b" class="od mo it nz b gy oi of l og oh"># dividing the data into groups<br/>df["strata"] = np.repeat([1, 2], len(df)/2).tolist()</span><span id="d813" class="od mo it nz b gy oi of l og oh"># instantiating stratified sampling<br/>stratified = StratifiedKFold(n_splits=2)1q<br/>for x, y in stratified.split(df, df["strata"]):<br/>    stratified_random_sample = df.iloc[x]</span><span id="f2ef" class="od mo it nz b gy oi of l og oh">stratified_random_sample</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/d9881e68d30cc12e3665a7c9c3496b85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*_JYVw0ZpuGNR_3s3VQsEEQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="2804" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种抽样策略倾向于通过减少我们引入的偏倚来提高样本的代表性；在最坏的情况下，我们得到的样本质量不会比简单的随机抽样差。另一方面，定义地层可能是一项困难的任务，因为它需要对数据的属性有很好的了解。这也是目前最慢的方法。</p><h2 id="6bc2" class="od mo it bd mp ok ol dn mt om on dp mx li oo op mz lm oq or nb lq os ot nd ou bi translated">巢式抽样法</h2><p id="155d" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">当我们不知道如何定义数据的层次时，整群随机抽样是一个很好的选择。在决定了我们希望我们的数据具有的聚类数之后，我们将较大的集合分成这些较小的聚类，然后从它们当中随机选择以形成一个样本。</p><pre class="kj kk kl km gt ny nz oa ob aw oc bi"><span id="e636" class="od mo it nz b gy oe of l og oh"># cluster sampling example</span><span id="19b0" class="od mo it nz b gy oi of l og oh"># removing the strata<br/>df.drop("strata", axis=1, inplace=True)</span><span id="d7ab" class="od mo it nz b gy oi of l og oh"># Divide the units into 5 clusters of equal size<br/>df['cluster_id'] = np.repeat([range(1,6)], len(df)/5)</span><span id="b728" class="od mo it nz b gy oi of l og oh"># Append the indexes from the clusters that meet the criteria<br/>idx = []</span><span id="ce84" class="od mo it nz b gy oi of l og oh"># add all observations with an even cluster_id to idx<br/>for i in range(0, len(df)):<br/>    if df['cluster_id'].iloc[i] % 2 == 0:<br/>        idx.append(i)</span><span id="df58" class="od mo it nz b gy oi of l og oh">cluster_random_sample = df.iloc[idx]<br/>cluster_random_sample</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/16d1ca8af88d866aee9e88e23ef78f51.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*b2qwq4bkwScT6oXjfbLjXw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="840b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">整群抽样比其他概率抽样方法更节省时间和成本。但是，很难确保您的分类代表更大的集合，因此，与简单随机抽样等其他方法相比，它通常提供的统计确定性更低。</p><h1 id="1d57" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">最后一个音符</h1><p id="c7c9" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">在处理大型数据集时，数据采样是一种有效的技术。通过利用数据采样技术，我们可以对较大集合中较小的、更容易管理的子集进行采样，以执行我们的分析和建模，同时确保我们仍然可以从该子集得出有效的结论。在本文中，我们讨论了执行数据采样的两种主要方法，为什么从概率采样技术开始可能更好，并在python中实现了4种概率采样技术。</p><p id="92f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的阅读！</p><p id="f4de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你喜欢这篇文章，请通过订阅我的<strong class="lb iu"/><a class="ae ky" href="https://mailchi.mp/ef1f7700a873/sign-up" rel="noopener ugc nofollow" target="_blank">每周简讯</a>与我联系。不要错过我写的关于人工智能、数据科学和自由职业的帖子。</p><h2 id="7b95" class="od mo it bd mp ok ol dn mt om on dp mx li oo op mz lm oq or nb lq os ot nd ou bi translated">相关文章</h2><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/cross-validation-c4fae714f1c5"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">交叉验证</h2><div class="oz l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">验证机器学习模型的性能</h3></div><div class="mf l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mg l"><div class="pa l mi mj mk mg ml ks ly"/></div></div></a></div><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/7-common-gotchas-of-data-projects-62e8646552f2"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">数据项目的7个常见问题</h2><div class="mf l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mg l"><div class="pb l mi mj mk mg ml ks ly"/></div></div></a></div><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/always-remember-data-comes-before-the-science-681389992082"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">永远记住数据先于科学</h2><div class="oz l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">获取数据的不同方法</h3></div><div class="mf l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mg l"><div class="pc l mi mj mk mg ml ks ly"/></div></div></a></div></div></div>    
</body>
</html>