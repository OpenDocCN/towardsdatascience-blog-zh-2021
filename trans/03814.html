<html>
<head>
<title>LSTM Framework For Univariate Time-Series Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">单变量时间序列预测的LSTM框架</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lstm-framework-for-univariate-time-series-prediction-d9e7252699e?source=collection_archive---------0-----------------------#2021-03-30">https://towardsdatascience.com/lstm-framework-for-univariate-time-series-prediction-d9e7252699e?source=collection_archive---------0-----------------------#2021-03-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1a8a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">完整的代码模板和演练</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/543320e891f48f9a0027c5542c9ac622.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1BQawDwiMyzUITjUlXeE3Q.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd kv">鸣谢:</strong> <a class="ae kw" href="https://unsplash.com/@marcojodoin" rel="noopener ugc nofollow" target="_blank"> <strong class="bd kv">马克·乔多因</strong> </a></p></figure><p id="e6cb" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">LSTM方法虽然是在90年代后期引入的，但直到最近才成为一种可行的、强有力的预测技术。像ARIMA和HWES这样的经典预测方法仍然很受欢迎和强大，但它们缺乏像LSTM这样的基于记忆的模型所提供的整体概括能力。</p><p id="fab3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">本文的主要目标是引导您构建一个工作的LSTM模型。然而，虽然本文的目标不一定是比较新的和经典的建模技术，但我将在结论中讨论经典的和基于RNN的技术的一些优点和缺点。</p><p id="baea" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">下面提供了完整代码。假设您已经导入了数据集和必要的类，那么结果应该是完全可再现的。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="fd16" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">什么是LSTMs？</h1><p id="ac8f" class="pw-post-body-paragraph kx ky iq kz b la ms jr lc ld mt ju lf lg mu li lj lk mv lm ln lo mw lq lr ls ij bi translated">LSTM(长短期记忆)是一种基于递归神经网络(RNN)的架构，广泛用于自然语言处理和时间序列预测。Brandon Rohrer的视频提供了一个很好的、直观的介绍。</p><p id="1c9a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">LSTM纠正了递归神经网络的一个大问题:短期记忆。使用一系列“门”，每个门都有自己的RNN，LSTM根据概率模型设法保留、忘记或忽略数据点。</p><p id="12a2" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">LSTMs也有助于解决爆炸和消失梯度问题。简单地说，这些问题是神经网络训练时反复调整权重的结果。随着历元的重复，梯度变得更大或更小，并且随着每次调整，网络的梯度更容易在两个方向上复合。这种混合要么使梯度过大，要么过小。虽然爆炸和消失的梯度是使用传统RNN的巨大缺点，LSTM建筑严重缓解这些问题。</p><p id="97a3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">做出预测后，它会反馈到模型中，以预测序列中的下一个值。每次预测都会给模型带来一些误差。为了避免爆发梯度，在门进入和输出之前，通过(通常)sigmoid &amp; tanh激活函数“挤压”值。下面是LSTM建筑的示意图:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/5a883575b52dbe3d3bbcfe933188328e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ujYN_Jpow9k2LCoK.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">LSTM建筑。图片来自<a class="ae kw" href="https://en.wikipedia.org/wiki/Long_short-term_memory#/media/File:LSTM_cell.svg" rel="noopener ugc nofollow" target="_blank">维基百科</a>下<a class="ae kw" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0 </a>许可。</p></figure></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="8d61" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated"><strong class="ak">TL；博士——给我代码</strong></h1><h2 id="0b62" class="my mb iq bd mc mz na dn mg nb nc dp mk lg nd ne mm lk nf ng mo lo nh ni mq nj bi translated">执行脚本</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="f892" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">数据操作方法</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="a2de" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">时间序列方法</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="7156" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir"> LSTM战法</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div></figure></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="1d8f" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">代码和数据演练—数据准备</h1><p id="d8e8" class="pw-post-body-paragraph kx ky iq kz b la ms jr lc ld mt ju lf lg mu li lj lk mv lm ln lo mw lq lr ls ij bi translated">数据为2010年至今的美欧汇率，未经季节调整。你可以从圣路易斯美联储<a class="ae kw" href="https://fred.stlouisfed.org/series/DEXUSEU" rel="noopener ugc nofollow" target="_blank">这里</a>提取数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/70492bca7f6b3e0d246a63a0f4d15961.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*jAyycPWvC8mQ2fhfOlGdgQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据</p></figure><p id="5cfd" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在建立模型之前，我们创建一个序列并检查平稳性。虽然平稳性不是LSTM的明确假设，但它确实对控制误差有很大帮助。非平稳序列将在预测中引入更多误差，并迫使误差更快地复合。</p><p id="a271" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们过滤掉一个“序列长度”的数据点，供以后验证。在这种情况下，60分。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/d5b97e852eb16323faa5d7bfe2ad54f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*MQdhucg9A4FYe4tUMUFqgg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">我们的迪基-富勒—显示了平稳性</p></figure><p id="2e8e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">LSTM所需的数据格式是三维的，具有移动窗口。</p><ul class=""><li id="0d0e" class="no np iq kz b la lb ld le lg nq lk nr lo ns ls nt nu nv nw bi translated">因此，第一个数据点将是前60天的数据。</li><li id="d3e4" class="no np iq kz b la nx ld ny lg nz lk oa lo ob ls nt nu nv nw bi translated">第二个数据点是前61天的数据，但不包括第一天。</li><li id="9741" class="no np iq kz b la nx ld ny lg nz lk oa lo ob ls nt nu nv nw bi translated">第三个数据点是前62天的数据，但不包括第一天和第二天。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/aa43309773a98f85c6677e8cc65fa847.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*5myR0DUG4Dg2c0UqXY5DQw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">我们的培训数据框架</p></figure><p id="34e5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">准备的最后一个主要步骤是扩展数据。这里我们使用一个简单的最小最大值定标器。我们这部分代码的序列长度是60天。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/8f82d71884eeaf1b8f6ea8cdab1928ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*eTqZfbP112qINju4RMHSBg.png"/></div></figure><h1 id="3961" class="ma mb iq bd mc md oe mf mg mh of mj mk jw og jx mm jz oh ka mo kc oi kd mq mr bi translated">代码演练—构建LSTM</h1><p id="6b96" class="pw-post-body-paragraph kx ky iq kz b la ms jr lc ld mt ju lf lg mu li lj lk mv lm ln lo mw lq lr ls ij bi translated">分析的下一部分在代码方面非常简单。我们首先创建一个学习率调度器。该调度器将监控验证损失，并在平稳期修改学习率。</p><p id="5b00" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们创建了一个方法来重置所有的权重，以防我们想要用不同的参数重新训练(这个方法在我的代码中没有使用，但是如果你需要的话，它就在那里)。</p><p id="161b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">然后，我们构建一个具有2层的LSTM，每层具有100个节点，并构建一个具有sigmoid激活的输出函数。</p><p id="4a61" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">历史对象存储历元上的模型损失，其可以被绘制以评估在训练过程中是否需要调整。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/58dddf90009df7f692af8ee7bfb04ba1.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*GgD-S9tbhSDRMqwxgSd01g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按历元的模型损失</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/88a4db95019b2582d64036808e92dba1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*HssCWptilW2SU3XUDscYVg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">代码片段</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/978a98f9abbc4b46d6f6ca98e7d6e915.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*VJxkvpRhZkkfBzsBePLTVg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">训练模型</p></figure></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="7f25" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">代码演练—预测未来</h1><p id="771f" class="pw-post-body-paragraph kx ky iq kz b la ms jr lc ld mt ju lf lg mu li lj lk mv lm ln lo mw lq lr ls ij bi translated">提供的类允许我们测试模型的准确性和预测未来。</p><p id="6dfa" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">下面的方法根据我们之前搁置的验证数据框架来测试我们的模型。结果很有希望。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/a70e471017de6d482960b9a0eb6b24f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*virHeWJVeVqmOiGczm7wUA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">我们的比较法</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/58e9f55b9b54d228715db65eadb589ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*b6d82dCfENfpnDGBTf3O2w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">我们的比较</p></figure><p id="5b53" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如果我们对准确性感到满意，我们就可以预测未来。下面是一个LSTM预测的快速演示。您可以看到在每个时间点模型中引入了一些误差，但是由于每个数据点都是一系列历史点，因此误差会减少。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/15cdb6dccd7f64eeae71a190309c17f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*iM-6lIm9hOxknR6ykqVd9w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">网络将预测反馈到模型中</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/8fbd6e45a7ac3c803ba0b597a3064bfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z5y04la32bFMPc6aW9LtHg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">反转最小最大值并预测</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/f27b36dc65103b011ad806bb37890de7.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*2GCfRYyVvEyXFY04X6AXXQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">预测点(橙色)</p></figure></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="fc66" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">结论</h1><p id="83fb" class="pw-post-body-paragraph kx ky iq kz b la ms jr lc ld mt ju lf lg mu li lj lk mv lm ln lo mw lq lr ls ij bi translated">因为这篇文章主要是关于建立一个LSTM，所以我没有讨论使用LSTM相对于传统方法的优点和缺点。我想在这个结论中提供一些指导:</p><p id="03a6" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">非技术考虑</strong></p><ol class=""><li id="2248" class="no np iq kz b la lb ld le lg nq lk nr lo ns ls or nu nv nw bi translated">权衡使用复杂模型和简单模型的成本和收益是非常重要的。稍微提高一下准确度可能不值得花费时间、精力和损失LSTMs引入的可解释性。</li><li id="b21d" class="no np iq kz b la nx ld ny lg nz lk oa lo ob ls or nu nv nw bi translated">如果时间序列预测很容易，股票市场就解决了！无论我们的模型有多好，所有时间序列数据中都有一个固有的噪声元素，我们无法捕捉到。</li><li id="64af" class="no np iq kz b la nx ld ny lg nz lk oa lo ob ls or nu nv nw bi translated">不要忽视直觉。时间序列模型隐含地假设以前的时间段决定将来的时间段。情况可能并不总是如此。如果你的结果在直觉上没有意义，不要害怕抛弃模型！</li></ol><p id="438d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">技术考虑因素</strong></p><ol class=""><li id="9cef" class="no np iq kz b la lb ld le lg nq lk nr lo ns ls or nu nv nw bi translated">ARIMA(以及一般基于MA的模型)是为时间序列数据设计的，而RNN模型是为序列数据设计的。由于这种区别，很难建立基于RNN的现成模型。</li><li id="1ca7" class="no np iq kz b la nx ld ny lg nz lk oa lo ob ls or nu nv nw bi translated">ARIMA模型是高度参数化的，因此，它们不能很好地概括。对新数据集使用参数化ARIMA可能不会返回准确的结果。基于RNN的模型是非参数的，更具普遍性。</li><li id="fc71" class="no np iq kz b la nx ld ny lg nz lk oa lo ob ls or nu nv nw bi translated">根据窗口大小、数据和期望的预测时间，LSTM模型在计算上可能<em class="os">非常</em>昂贵。有时候，没有强大的云计算，它们是不可行的。</li><li id="25f7" class="no np iq kz b la nx ld ny lg nz lk oa lo ob ls or nu nv nw bi translated">最好有一个“无技能”模型来比较结果。一个好的开始是将模型结果与预测期间内每个时间步长(水平线)的【仅T4】平均值的模型进行比较。</li></ol></div></div>    
</body>
</html>