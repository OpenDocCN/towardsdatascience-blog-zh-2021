<html>
<head>
<title>Layer conductance from scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从零开始的层电导</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/layer-conductance-from-scratch-df53005e08b8?source=collection_archive---------26-----------------------#2021-10-21">https://towardsdatascience.com/layer-conductance-from-scratch-df53005e08b8?source=collection_archive---------26-----------------------#2021-10-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f8a4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">理解神经网络中隐藏单元的重要性</h2></div><p id="988d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是关于深度神经网络中使用集成梯度和相关技术的可解释性的文章的第二部分。</p><h2 id="f5ea" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">介绍</h2><p id="161b" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">在<a class="ae lz" rel="noopener" target="_blank" href="/integrated-gradients-from-scratch-b46311e4ab4">上一篇文章</a>中，我们已经看到了如何使用综合梯度计算特征属性，它显示为从基线到特征值的线性路径上梯度的简单平均值。但是，如果我们想测量特定层中神经元的重要性，而不是测量某个特征的重要性，会怎么样呢？为此，我们需要看看层的电导。</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h2 id="1a75" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">解释电导</h2><p id="6234" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">电导是基于积分梯度的，我们在本系列的第一部分已经讨论过。提醒一下，我们将积分梯度定义为:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/018edccc02ae80973c48672f1364c348.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*-9AbogK0kIB71lxiZUyy_Q.png"/></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">Ref:深度网络的公理化归属(【https://arxiv.org/abs/1703.01365】T2</p></figure><p id="89c6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了计算层的电导，我们需要通过链规则分解积分梯度，如下所示:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/6ec749f19b50f1381b298fe75fab9fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*jQfklYB7s0jxAyK3QpD7fg.png"/></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">Ref:神经元有多重要？(【https://arxiv.org/abs/1805.12233】T4)</p></figure><p id="cfcc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们也可以将其近似为:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/4f9ffb62a3a495db4c16adab1fff781e.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*qLm0dWzhzqeMP9I8eyYt1A.png"/></div><p class="mp mq gj gh gi mr ms bd b be z dk translated">作者图片</p></figure></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h2 id="ee89" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">履行</h2><blockquote class="mv mw mx"><p id="c1a7" class="kf kg my kh b ki kj jr kk kl km ju kn mz kp kq kr na kt ku kv nb kx ky kz la ij bi translated">注意:我们将使用本系列第一部分中的相同模型和数据。</p></blockquote><p id="81a4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了计算层电导，我们采用与综合梯度相同的策略——因为模型是饱和的，为了看到有意义的梯度，我们需要从基线到输入捕捉它们。下面我们计算<em class="my">网</em>模型中<em class="my"> sigmoid1 </em>层的电导:</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="6648" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了计算导数<em class="my"> dydx_i </em>我们需要使用一个向后的钩子(我个人发现这个教程有助于理解py torch<a class="ae lz" href="https://www.youtube.com/watch?v=syLFCVYua6Q" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=syLFCVYua6Q</a>中的钩子)覆盖向后的梯度直到层<em class="my"> y </em>然后从那里继续向后传播。</p><p id="46e3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以手动计算<em class="my"> dydx_i </em>进行反向传播，而不是使用<em class="my">亲笔签名的</em>:</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="83ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">偏导数<em class="my"> dfdy_i </em>不需要钩子——我们简单地计算输出相对于<em class="my"> sigmoid </em>层的导数。</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h2 id="87c9" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">结论</h2><p id="7b82" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">希望你发现这个系列有助于通过代码更好地理解集成梯度和层电导是如何实现的。使用原始公式计算电导非常慢，并且在tensorflow中首次实现时没有很好地缩放，因此提出了另一个计算效率更高的公式，您可以在这里熟悉<a class="ae lz" href="https://arxiv.org/pdf/1807.09946.pdf" rel="noopener ugc nofollow" target="_blank"/>。</p><h2 id="d372" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">参考</h2><p id="4b3d" class="pw-post-body-paragraph kf kg iq kh b ki lu jr kk kl lv ju kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">[1]https://arxiv.org/pdf/1805.12233.pdf<a class="ae lz" href="https://arxiv.org/pdf/1805.12233.pdf" rel="noopener ugc nofollow" target="_blank"/></p><p id="888c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2]https://captum.ai/tutorials/Titanic_Basic_Interpret<a class="ae lz" href="https://captum.ai/tutorials/Titanic_Basic_Interpret" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>