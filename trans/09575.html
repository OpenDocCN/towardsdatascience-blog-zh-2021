<html>
<head>
<title>A Practical Introduction to Grid Search, Random Search, and Bayes Search</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">网格搜索、随机搜索和贝叶斯搜索的实用介绍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-practical-introduction-to-grid-search-random-search-and-bayes-search-d5580b1d941d?source=collection_archive---------10-----------------------#2021-09-06">https://towardsdatascience.com/a-practical-introduction-to-grid-search-random-search-and-bayes-search-d5580b1d941d?source=collection_archive---------10-----------------------#2021-09-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cead" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在机器学习中有效使用超参数调整的实践教程</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1c5ad7ebf8a86f262a1d1e7a34c76aff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f6BjxxKkPLuup2y1Xbdk7A.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@louishansel?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">路易斯·汉瑟</a>在<a class="ae ky" href="https://unsplash.com/s/photos/adjust?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="a6f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在机器学习中，超参数是指无法从数据中学习到，需要在训练前提供的参数。机器学习模型的性能在很大程度上依赖于找到最优的超参数集。</p><p id="7891" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">超参数调整基本上是指调整模型的超参数，这基本上是一个长度过程。在本文中，您将学习3种最流行的超参数调优技术:<strong class="lb iu">网格搜索</strong>、<strong class="lb iu">随机搜索</strong>和<strong class="lb iu">贝叶斯搜索</strong>。这篇文章的结构如下:</p><ol class=""><li id="060f" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">获取和准备数据</li><li id="beff" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">网格搜索</li><li id="3bd3" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">随机搜索</li><li id="fe02" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">贝叶斯搜索</li><li id="a0a4" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">结论</li></ol><blockquote class="mj"><p id="92b8" class="mk ml it bd mm mn mo mp mq mr ms lu dk translated">请查看<a class="ae ky" href="https://github.com/BindiChen/machine-learning/blob/master/traditional-machine-learning/005-grid-search-vs-random-search-vs-bayes-search/gridsearch-vs-randomsearch-vs-bayessearch.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>获取源代码。更多教程可以从<a class="ae ky" href="https://github.com/BindiChen/machine-learning" rel="noopener ugc nofollow" target="_blank"> Github Repo </a>获得。</p></blockquote></div><div class="ab cl mt mu hx mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="im in io ip iq"><h1 id="7b3d" class="na nb it bd nc nd ne nf ng nh ni nj nk jz nl ka nm kc nn kd no kf np kg nq nr bi translated">1.获取和准备数据</h1><p id="7206" class="pw-post-body-paragraph kz la it lb b lc ns ju le lf nt jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">为了进行演示，我们将使用来自<a class="ae ky" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> Scikit Learn </a>的内置乳腺癌数据来训练一个<strong class="lb iu">支持向量分类器</strong> (SVC)。我们可以用<code class="fe nx ny nz oa b">load_breast_cancer</code>函数得到数据:</p><pre class="kj kk kl km gt ob oa oc od aw oe bi"><span id="9a98" class="of nb it oa b gy og oh l oi oj">from sklearn.datasets import <strong class="oa iu">load_breast_cancer</strong></span><span id="3b44" class="of nb it oa b gy ok oh l oi oj"><strong class="oa iu">cancer = load_breast_cancer()</strong></span></pre><p id="fc3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们为特性和目标标签创建<code class="fe nx ny nz oa b">df_X</code>和<code class="fe nx ny nz oa b">df_y</code>，如下所示:</p><pre class="kj kk kl km gt ob oa oc od aw oe bi"><span id="ec87" class="of nb it oa b gy og oh l oi oj"># Features<br/>df_X = pd.DataFrame(cancer['data'], columns=cancer['feature_names'])</span><span id="9d74" class="of nb it oa b gy ok oh l oi oj"># Target label<br/>df_y = pd.DataFrame(cancer['target'], columns=['Cancer'])</span></pre><p id="f111" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另外，如果你想了解更多关于数据集的信息，你可以运行<code class="fe nx ny nz oa b">print(cancer['DESCR'])</code>来打印出概要和特性信息。</p><p id="c352" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，让我们使用<code class="fe nx ny nz oa b">training_test_split()</code>将数据集分成训练集(70%)和测试集(30%):</p><pre class="kj kk kl km gt ob oa oc od aw oe bi"><span id="5933" class="of nb it oa b gy og oh l oi oj"># Train test split<br/>from sklearn.model_selection import train_test_split<br/>import numpy as np</span><span id="efba" class="of nb it oa b gy ok oh l oi oj">X_train, X_test, y_train, y_test = train_test_split(df_X, np.ravel(df_y), test_size=0.3)</span></pre><p id="683b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将训练一个<strong class="lb iu">支持向量分类器</strong> (SVC)模型。正则化参数<code class="fe nx ny nz oa b">C</code>和核系数<code class="fe nx ny nz oa b">gamma</code>是SVC中两个最重要的超参数:</p><ul class=""><li id="194d" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ol mb mc md bi translated">正则化参数<code class="fe nx ny nz oa b">C</code>决定正则化的强度。</li><li id="afd7" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ol mb mc md bi translated">内核系数<code class="fe nx ny nz oa b">gamma</code>控制内核的宽度。SVC默认使用<strong class="lb iu">径向基函数(RBF) </strong>核(也称为<strong class="lb iu">高斯核</strong>)。</li></ul><p id="1ac0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将在下面的教程中调整这两个参数。</p><h1 id="175d" class="na nb it bd nc nd om nf ng nh on nj nk jz oo ka nm kc op kd no kf oq kg nq nr bi translated">2.网格搜索</h1><p id="662c" class="pw-post-body-paragraph kz la it lb b lc ns ju le lf nt jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">很难找到<code class="fe nx ny nz oa b">C</code>和<code class="fe nx ny nz oa b">gamma</code>的最佳值。最简单的解决方案是尝试多种组合，看看哪种效果最好。这种创建参数“网格”并尝试所有可能组合的想法被称为<strong class="lb iu">网格搜索。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/2adcf646015206cfbce424e2d92a7ddd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*MuLiH0VHtlt6Lx0WpG-Bpw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">网格搜索——尝试所有可能的组合(图片由作者提供)</p></figure><p id="d57a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法很常见，Scikit-learn在<code class="fe nx ny nz oa b">GridSearchCV</code>中内置了这种功能。CV代表交叉验证，这是另一种评估和改进我们的机器学习模型的技术。</p><p id="1d97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nx ny nz oa b">GridSearchCV</code>采用描述应该尝试的参数的字典和要训练的模型。参数网格被定义为一个字典，其中键是参数，值是要测试的设置。让我们首先定义我们的候选人<code class="fe nx ny nz oa b">C</code>和<code class="fe nx ny nz oa b">gamma</code>如下:</p><pre class="kj kk kl km gt ob oa oc od aw oe bi"><span id="ac43" class="of nb it oa b gy og oh l oi oj">param_grid = { <br/>  'C': [0.1, 1, 10, 100, 1000], <br/>  'gamma': [1, 0.1, 0.01, 0.001, 0.0001]<br/>}</span></pre><p id="ef15" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们创建一个<code class="fe nx ny nz oa b">GridSearchCV</code>对象，并使其适合训练数据。</p><pre class="kj kk kl km gt ob oa oc od aw oe bi"><span id="12e5" class="of nb it oa b gy og oh l oi oj">from sklearn.model_selection import GridSearchCV<br/>from sklearn.svm import SVC</span><span id="5279" class="of nb it oa b gy ok oh l oi oj">grid = <strong class="oa iu">GridSearchCV(SVC(), param_grid, refit=True, verbose=3)</strong><br/>grid.<strong class="oa iu">fit(X_train,y_train)</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/ef168f72452a35174f8827e5a6cbf228.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RT2tMqMeLV8bTjswFQ9yVQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="8cb5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦训练完成，我们可以检查<code class="fe nx ny nz oa b">GridSearchCV</code>在<code class="fe nx ny nz oa b">best_params_</code>属性中找到的最佳参数，以及<code class="fe nx ny nz oa b">best_estimator_</code>属性中的最佳估计器:</p><pre class="kj kk kl km gt ob oa oc od aw oe bi"><span id="5157" class="of nb it oa b gy og oh l oi oj"># Find the best paramters<br/>&gt;&gt;&gt; <strong class="oa iu">grid.best_params_</strong></span><span id="2c73" class="of nb it oa b gy ok oh l oi oj">{'C': 1, 'gamma': 0.0001}</span><span id="92a6" class="of nb it oa b gy ok oh l oi oj"># Find the best estimator<br/>&gt;&gt;&gt; <strong class="oa iu">grid.best_estimator_</strong></span><span id="7dd7" class="of nb it oa b gy ok oh l oi oj">SVC(C=1, gamma=0.0001)</span></pre><p id="6c15" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，利用这个网格模型，使用测试集创建一些预测，并为它们创建分类报告和混淆矩阵。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/656a89056789ed96ddb33f69d947c642.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nD1eAUER93F_-nmnYFxblA.png"/></div></div></figure><h1 id="36f3" class="na nb it bd nc nd om nf ng nh on nj nk jz oo ka nm kc op kd no kf oq kg nq nr bi translated">3.随机搜索</h1><p id="a82d" class="pw-post-body-paragraph kz la it lb b lc ns ju le lf nt jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">网格搜索尝试超参数的所有组合，因此增加了计算的时间复杂度，并且可能导致不可行的计算成本。提供了一个更便宜的选择，<strong class="lb iu">随机搜索</strong>只测试你选择的元组。超参数值的选择是完全随机的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/295939108c9bdad73549f365a6ea7feb.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*5SX-RFgQNUVO5z47eq2Vgg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">随机搜索尝试随机组合(作者图片)</p></figure><p id="82d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法也很常见，Scikit-learn在<code class="fe nx ny nz oa b">RandomizedSearchCV</code>中内置了这种功能。函数API和<code class="fe nx ny nz oa b">GridSearchCV</code>很像。</p><p id="101b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们指定参数<code class="fe nx ny nz oa b">C</code> &amp; <code class="fe nx ny nz oa b">gamma</code>和样本分布如下:</p><pre class="kj kk kl km gt ob oa oc od aw oe bi"><span id="1d43" class="of nb it oa b gy og oh l oi oj">import scipy.stats as stats<br/>from sklearn.utils.fixes import loguniform</span><span id="acf1" class="of nb it oa b gy ok oh l oi oj"># Specify parameters and distributions to sample from<br/>param_dist = {<br/>  'C': <strong class="oa iu">stats.uniform(0.1, 1e4)</strong>,<br/>  'gamma': <strong class="oa iu">loguniform(1e-6, 1e+1)</strong>,<br/>}</span></pre><p id="b14e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们用参数<code class="fe nx ny nz oa b">n_iter_search</code>创建一个<code class="fe nx ny nz oa b">RandomizedSearchCV</code>对象，并使其适合训练数据。</p><pre class="kj kk kl km gt ob oa oc od aw oe bi"><span id="1cd5" class="of nb it oa b gy og oh l oi oj"><strong class="oa iu">n_iter_search = 20</strong><br/>random_search = <strong class="oa iu">RandomizedSearchCV</strong>(<br/>    SVC(), <br/>    param_distributions=param_dist,<br/>    <strong class="oa iu">n_iter=n_iter_search, </strong><br/>    refit=True,<br/>    verbose=3<br/>)<br/><strong class="oa iu">random_search.fit(X_train, y_train)</strong></span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/89339a1c2b0eee6deba8839254e3c6cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Iiia5moyodCdclfDK5bo2A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">RandomizedSearchCV fit()输出示例(图片由作者提供)</p></figure><p id="a6e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">类似地，一旦训练完成，我们可以检查由<code class="fe nx ny nz oa b">best_params_</code>属性中的<code class="fe nx ny nz oa b">RandomizedSearchCV</code>找到的最佳参数，以及在<code class="fe nx ny nz oa b">best_estimator_</code>属性中的最佳估计器:</p><pre class="kj kk kl km gt ob oa oc od aw oe bi"><span id="aadc" class="of nb it oa b gy og oh l oi oj">&gt;&gt;&gt; <strong class="oa iu">random_search.best_params_</strong></span><span id="6c21" class="of nb it oa b gy ok oh l oi oj">{'C': 559.3412579902997, 'gamma': 0.00022332416796205752}</span><span id="5d0d" class="of nb it oa b gy ok oh l oi oj">&gt;&gt;&gt; <strong class="oa iu">random_search.best_estimator_</strong></span><span id="6155" class="of nb it oa b gy ok oh l oi oj">SVC(C=559.3412579902997, gamma=0.00022332416796205752)</span></pre><p id="0ef2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们采用随机搜索模型，使用测试集创建一些预测，并为它们创建分类报告和混淆矩阵。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/2a55f8a8c7b07c4cd766c0ff634d3016.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vW3VIWshwkOLcKdwgwUPwA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">预测随机搜索并创建报告(图片由作者提供)</p></figure><h1 id="2a0d" class="na nb it bd nc nd om nf ng nh on nj nk jz oo ka nm kc op kd no kf oq kg nq nr bi translated">4.贝叶斯搜索</h1><p id="2e68" class="pw-post-body-paragraph kz la it lb b lc ns ju le lf nt jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">贝叶斯搜索使用贝叶斯优化技术来模拟搜索空间，以尽快达到优化的参数值。它利用搜索空间的结构来优化搜索时间。贝叶斯搜索方法使用过去的评估结果对最有可能给出更好结果的新候选人进行采样(如下图所示)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/b6c83db87cd1db22fa2c273b446887cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*g2E6yf3I4YwEVsK8JuEgNQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">贝叶斯搜索(作者图片)</p></figure><p id="b4c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://pypi.org/project/scikit-optimize/" rel="noopener ugc nofollow" target="_blank"> Scikit-Optimize </a>库附带BayesSearchCV实现。</p><p id="966a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们如下指定参数<code class="fe nx ny nz oa b">C</code> &amp; <code class="fe nx ny nz oa b">gamma</code>和样本分布:</p><pre class="kj kk kl km gt ob oa oc od aw oe bi"><span id="44f1" class="of nb it oa b gy og oh l oi oj">from skopt import BayesSearchCV<br/># parameter ranges are specified by one of below<br/>from skopt.space import Real, Categorical, Integer</span><span id="6d84" class="of nb it oa b gy ok oh l oi oj">search_spaces = {<br/>  'C': <strong class="oa iu">Real(0.1, 1e+4)</strong>,<br/>  'gamma': <strong class="oa iu">Real(1e-6, 1e+1, 'log-uniform')</strong>,<br/>}</span></pre><p id="2ccd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们用参数<code class="fe nx ny nz oa b">n_iter_search</code>创建一个<code class="fe nx ny nz oa b">BayesSearchCV</code>对象，并使其适合训练数据。</p><pre class="kj kk kl km gt ob oa oc od aw oe bi"><span id="1d59" class="of nb it oa b gy og oh l oi oj">n_iter_search = 20<br/>bayes_search = BayesSearchCV(<br/>    SVC(), <br/>    search_spaces, <br/>    n_iter=n_iter_search, <br/>    cv=5,<br/>    verbose=3<br/>)<br/>bayes_search.fit(X_train, y_train)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/381661ae9cbe9f7ffefebe2b6df4ed8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zt9IbUl31HAsQY1NFKctbw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="b7cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">类似地，一旦训练完成，我们可以检查<code class="fe nx ny nz oa b">BayesSearchCV</code>在<code class="fe nx ny nz oa b">best_params_</code>属性中找到的最佳参数，以及<code class="fe nx ny nz oa b">best_estimator_</code>属性中的最佳估计器:</p><pre class="kj kk kl km gt ob oa oc od aw oe bi"><span id="fc91" class="of nb it oa b gy og oh l oi oj">&gt;&gt;&gt; <strong class="oa iu">bayes_search.best_params_</strong></span><span id="99f9" class="of nb it oa b gy ok oh l oi oj">OrderedDict([('C', 0.25624177419852506), ('gamma', 0.00016576008531229226)])</span><span id="64c2" class="of nb it oa b gy ok oh l oi oj">&gt;&gt;&gt; <strong class="oa iu">bayes_search.best_estimator_</strong></span><span id="7009" class="of nb it oa b gy ok oh l oi oj">SVC(C=0.25624177419852506, gamma=0.00016576008531229226)</span></pre><p id="9ae3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们采用贝叶斯搜索模型，使用测试集创建一些预测，并为它们创建分类报告和混淆矩阵。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/612fc39e18c9c7ba819f376c9b8494e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qEnMqQGydo4iao5zfI8xcQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h1 id="30eb" class="na nb it bd nc nd om nf ng nh on nj nk jz oo ka nm kc op kd no kf oq kg nq nr bi translated">5.结论</h1><p id="ea8d" class="pw-post-body-paragraph kz la it lb b lc ns ju le lf nt jx lh li nu lk ll lm nv lo lp lq nw ls lt lu im bi translated">在本文中，我们讨论了3种最流行的超参数优化技术，这些技术用于获得优化的超参数集，从而训练一个健壮的机器学习模型。</p><p id="35c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一般来说，如果组合的数量足够有限，我们可以使用<strong class="lb iu">网格搜索</strong>技术。但是当组合的数量增加时，我们应该尝试<strong class="lb iu">随机搜索</strong>或<strong class="lb iu">贝叶斯搜索</strong>，因为它们计算量不大。</p><p id="166a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">希望这篇文章能帮助你节省学习机器学习的时间。我建议你去看看他们的APIs，2]并了解你可以做的其他事情。</p><p id="4bda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读。请查看<a class="ae ky" href="https://github.com/BindiChen/machine-learning/blob/master/traditional-machine-learning/005-grid-search-vs-random-search-vs-bayes-search/gridsearch-vs-randomsearch-vs-bayessearch.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>获取源代码，如果您对机器学习的实用方面感兴趣，请继续关注。</p><p id="7fb4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">参考文献:</strong></p><ul class=""><li id="53a1" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ol mb mc md bi translated">[1]sci kit-Learn docs:<a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-Learn . org/stable/auto _ examples/model _ selection/plot _ randomized _ search . html</a></li><li id="b448" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ol mb mc md bi translated">[2]sci kit-Optimize docs:<a class="ae ky" href="https://scikit-optimize.github.io/stable/modules/generated/skopt.BayesSearchCV.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-Optimize . github . io/stable/modules/generated/skopt。BayesSearchCV.html</a></li></ul></div></div>    
</body>
</html>