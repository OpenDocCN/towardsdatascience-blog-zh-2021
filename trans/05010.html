<html>
<head>
<title>Does Machine Learning know when I’m scared? Anomaly detection in wearable health data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习知道我什么时候害怕吗？可穿戴健康数据中的异常检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/does-machine-learning-know-when-im-scared-anomaly-detection-in-wearable-health-data-72f537dd4370?source=collection_archive---------20-----------------------#2021-05-02">https://towardsdatascience.com/does-machine-learning-know-when-im-scared-anomaly-detection-in-wearable-health-data-72f537dd4370?source=collection_archive---------20-----------------------#2021-05-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a3a7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利用真实的Fitbit测量在Keras中构建自动编码器的机会。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1015df959ef6566b55c9b46ed4a3ca3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m9zX3GyK0ZJu6lhiFS1wtw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="a685" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi lr translated">像Fitbit这样的可耳听健康设备提供了大量关于我们健身和日常活动的信息。这提供了一个<strong class="kx ir">处理大型数据集的绝佳机会</strong>，其中个人信息可用于更深入地了解实际现实世界的机器学习应用，而不仅仅是像<a class="ae ma" href="https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones" rel="noopener ugc nofollow" target="_blank">人类活动识别</a>数据集这样的例子。</p><p id="0c6b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本文中使用的数据集来自我的个人<a class="ae ma" href="https://www.fitbit.com/global/us/home" rel="noopener ugc nofollow" target="_blank"> Fitbit </a>设备，其中的卡路里和心率数据被记录为近三周的时间序列。目标是使用Keras建立和使用自动编码器模型<strong class="kx ir">来识别基于心率和卡路里随时间变化的异常</strong>。</p><h1 id="4c2a" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated"><strong class="ak">工作总结:</strong></h1><p id="0c08" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">我们将开始加载数据集，并查看心率和卡路里在我们的样本期间如何变化。</p><p id="6bfd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们还将检查包含异常的数据集，以帮助我们了解潜在的异常可能是什么样子。一旦我们开始评估模型的性能，这将变得非常有用。</p><p id="8fef" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">数据将被清理、缩放和整形，以与我们的autoencoder模型兼容。</p><p id="291c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的模型将被建立和评估，以确定预测误差，这将在以后被用来确定是否存在异常。</p><p id="2e35" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，我们将研究检测到的异常现象，试图解开它们可能发生的原因。</p><h1 id="de74" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated"><strong class="ak">加载和可视化:</strong></h1><p id="0af4" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">数据集是从我的个人Fitbit账户下载的，文件以JSON格式导出。关于下载自己数据的信息可以在<a class="ae ma" href="https://help.fitbit.com/articles/en_US/Help_article/1133.htm" rel="noopener ugc nofollow" target="_blank">这里</a>找到。在导入所有相关模块后，我们可以使用Pandas加载这些文件来生成心率和卡路里的数据帧，它们都是时间序列数据:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="27f6" class="nd mc iq mz b gy ne nf l ng nh">#Importing the relevant modules<br/>import glob<br/>import numpy<br/>import os<br/>import pandas as pd<br/>import numpy as np<br/>import seaborn as sns; sns.set()<br/>import matplotlib.pyplot as plt<br/>from tensorflow import keras<br/>from sklearn.preprocessing import MinMaxScaler<br/>sns.set_palette(“hls”, 2)</span><span id="5960" class="nd mc iq mz b gy ni nf l ng nh">#Loading in the heart rate and calories data<br/>heart = pd.DataFrame()<br/>calories = pd.DataFrame()<br/>datasets = [‘heart_rate-2021–03-*.json’, ‘calories-2021–02-*.json’]<br/>for datatype in datasets:<br/>    file_list=[]<br/>    path = ‘/Physical Activity/’<br/>    os.chdir(path)<br/>    for file in glob.glob(datatype):<br/>        file_list.append(file)<br/>    dfs = []<br/>    for file in file_list:<br/>        data = pd.read_json(path + file)<br/>        print(‘Reading: ‘ + str(file))<br/>        dfs.append(data)<br/>    concatenated = pd.concat(dfs, ignore_index=True)<br/>    concatenated[“value”] = concatenated[“value”].apply(str)<br/>    if concatenated[‘value’].str.contains(“bpm”).any():<br/>        heart = pd.concat([heart, concatenated], axis = 1)<br/>    else:<br/>        calories = pd.concat([calories, concatenated], axis = 1)</span></pre><p id="5f57" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们看一下数据，看看我们可能需要做什么样的清洁:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="081e" class="nd mc iq mz b gy ne nf l ng nh">print(heart.head(5))<br/>print(calories.head(5))</span><span id="b1d8" class="nd mc iq mz b gy ni nf l ng nh">dateTime value<br/>0 2021–03–08 21:00:07 {‘bpm’: 57, ‘confidence’: 3}<br/>1 2021–03–08 21:00:17 {‘bpm’: 56, ‘confidence’: 3}<br/>2 2021–03–08 21:00:32 {‘bpm’: 56, ‘confidence’: 3}<br/>3 2021–03–08 21:00:42 {‘bpm’: 57, ‘confidence’: 3}<br/>4 2021–03–08 21:00:57 {‘bpm’: 58, ‘confidence’: 3}</span><span id="0091" class="nd mc iq mz b gy ni nf l ng nh">dateTime value<br/>0 2021–02–18 00:00:00 1.19<br/>1 2021–02–18 00:01:00 1.19<br/>2 2021–02–18 00:02:00 1.19<br/>3 2021–02–18 00:03:00 1.19<br/>4 2021–02–18 00:04:00 1.19</span></pre><p id="4392" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">心率以每分钟心跳数(BPM)来衡量，并以10-15秒的不规则间隔进行采样。卡路里数据测量使用的卡路里量，这是使用一个人的<a class="ae ma" href="https://help.fitbit.com/articles/en_US/Help_article/1141.htm#:~:text=How%20does%20my%20Fitbit%20device%20calculate%20calories%20burned%3F,to%20estimate%20your%20calories%20burned." rel="noopener ugc nofollow" target="_blank">基础代谢率(BMR)和活动率</a>的组合来计算的。我们可以改变心率数据的采样频率，以便两个数据集都记录每分钟的观察值。值列也应该删除文本，以便作为浮点数读取:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="7efd" class="nd mc iq mz b gy ne nf l ng nh">#Cleaning the training data<br/>heart = heart.sort_values(by="dateTime")<br/>heart = heart.set_index('dateTime')<br/>heart["value"] = heart["value"].apply(str)<br/>heart["value"] = heart["value"].str.split("{'bpm':").str[1]<br/>heart["value"] = heart["value"].str.split(",").str[0]<br/>heart["value"] = heart["value"].astype(int)<br/>heart = heart.resample('1Min').mean()<br/>heart['value'] = heart['value'].round(0)<br/>calories = calories.sort_values(by="dateTime")<br/>calories["value"] = calories["value"].astype(float)<br/>calories.columns = ['time', 'value']<br/>calories = calories.set_index('time')</span></pre><p id="f4cc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，我们可以将心率和卡路里合并在一起，创建一个涵盖样本期的时间序列数据的单一数据框架。创建一个包含覆盖我们的采样周期的DateTimeIndex的空DataFrame会使事情变得更加方便:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="2e87" class="nd mc iq mz b gy ne nf l ng nh">#Merge the datasets together<br/>empty = pd.DataFrame(pd.date_range(start='2021-03-01', end='2021-03-20', freq='1min'))<br/>empty.columns = ['datetimeindex']<br/>empty = empty.set_index('datetimeindex')<br/>from functools import reduce<br/>df = reduce(lambda left,right: pd.merge(left,right,left_index=True, right_index=True), [heart, calories, empty])<br/>df.columns = ['Heart Rate (BPM)', 'Calories Used']<br/>df = df.dropna()</span></pre><p id="1967" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的训练数据将来自连续的样本期。测试数据大约来自我们样本中间的一天，因此我们可以假设影响心率和卡路里数据的条件有一定的连续性:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="728a" class="nd mc iq mz b gy ne nf l ng nh">#Splitting the test day<br/>df_test = df.loc[(df.index &gt; '2021-03-12 00:00:00') &amp; (df.index &lt;= '2021-03-12 23:59:59')]<br/>df = df.loc[(df.index &lt; '2021-03-12 00:00:00') | (df.index &gt; '2021-03-12 23:59:59')]</span></pre><p id="4afd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们现在处于最终可视化Fitbit数据的阶段，将从训练数据开始。训练数据中的差距代表我们之前提取的测试日:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="cc0f" class="nd mc iq mz b gy ne nf l ng nh">#Visualising training and testing data<br/>datasets = [df, df_test]<br/>for dfs in datasets:<br/>    fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(12,6))<br/>    axs[0].plot(dfs['Heart Rate (BPM)'])<br/>    axs[1].plot(dfs['Calories Used'])<br/>    plt.setp(axs[0].get_xticklabels(), visible=False)<br/>    axs[0].tick_params(axis='x', rotation=70)<br/>    axs[1].tick_params(axis='x', rotation=70)<br/>    axs[0].set(ylabel='Heart Rate (BPM)')<br/>    axs[1].set(ylabel= 'Calories Used', xlabel="Date")<br/>    plt.tight_layout()<br/>    plt.show</span></pre><p id="12e5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后来点图！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/0acfde02e23a0a6fd4d46e3e5b17eb07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R_oZFUYb4ND1PSBxlSkMbg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">一段时间内心率和消耗卡路里的训练数据集</p></figure><p id="c036" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">数据集显示了心率和卡路里循环趋势；两个数据集都在早上增加，在白天保持相当稳定，然后在晚上逐渐减少。这是一个预期的趋势，因为它与起床、白天工作、晚上睡觉前放松相关。</p><p id="1db2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">转到将用于验证是否检测到异常的测试数据集。这些数据涵盖了一天的时间，我们可以根据我们在培训数据中看到的内容来猜测潜在的异常情况:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/fa1291be010e297f06c660ba66b5d06b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fbW42m4JEes46kISt8wcxA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">一段时间内心率和消耗卡路里的测试数据集</p></figure><p id="2757" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有趣的是，这一天的测试数据有两个峰值，心率在下午显著增加，这与卡路里的增加无关。这表明心率的<strong class="kx ir">增加可能与锻炼的变化</strong>无关。处理个人数据的额外好处是我知道这一天发生了什么；去医院一趟。作为一个不太喜欢去医院的人，我的Fitbit清楚地捕捉到了我的紧张情绪，这使它成为我们稍后将试图识别的异常现象的一个极好的例子。</p><p id="5a4d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以在心率和卡路里之间做一个简单的相关矩阵，看看它们之间的关系:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="2ae5" class="nd mc iq mz b gy ne nf l ng nh">#Make a correlation coefficient<br/>print(df.corr())</span><span id="d471" class="nd mc iq mz b gy ni nf l ng nh">                 Heart Rate (BPM)  Calories Used<br/>Heart Rate (BPM)     1.000000       0.102251<br/>Calories Used        0.102251       1.000000</span></pre><p id="8356" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">心率和消耗的卡路里之间有一个略微正相关的关系。根据Fitbit的<a class="ae ma" href="https://help.fitbit.com/articles/en_US/Help_article/1141.htm#:~:text=How%20does%20my%20Fitbit%20device%20calculate%20calories%20burned?,to%20estimate%20your%20calories%20burned." rel="noopener ugc nofollow" target="_blank">文档</a>关于卡路里的计算方式，心率影响卡路里的计算方式，因此我们观察到的正相关是可以预期的。</p><h1 id="bc29" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated"><strong class="ak">预处理:</strong></h1><p id="f524" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">回到代码，我们现在需要调整我们的数据，以便我们可以减少训练数据中任何离群值的影响，这些离群值可能会妨碍模型检测异常的能力。我们将使用MinMaxScaler，因为这将使心率和卡路里数据在0和1之间变化，这在我们稍后计算预测误差时非常重要。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="b81d" class="nd mc iq mz b gy ne nf l ng nh">#Scale the data<br/>scaler = MinMaxScaler()<br/>scaler = scaler.fit(df)<br/>scale_train = pd.DataFrame(scaler.transform(df))<br/>scale_test = pd.DataFrame(scaler.transform(df_test))</span></pre><p id="dbec" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在数据已经被缩放，我们需要<strong class="kx ir">重塑</strong>以兼容我们的自动编码器模型。我们模型的输入将是一个三维数组，其形状取决于样本的数量、序列的长度和特征的数量。我们将使用30个时间步长(也称为半小时时间间隔)的序列，因为我们假设异常是短暂的。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="f5fa" class="nd mc iq mz b gy ne nf l ng nh"># reshape to [samples, time_steps, n_features]<br/>def create_dataset(X, y, time_steps=1):<br/>    Xs, ys = [], []<br/>    for i in range(len(X) - time_steps):<br/>        v = X.iloc[i:(i + time_steps)].values<br/>        Xs.append(v)<br/>        ys.append(y.iloc[i + time_steps])<br/>    return np.array(Xs), np.array(ys)</span><span id="29a4" class="nd mc iq mz b gy ni nf l ng nh">time_steps = 30<br/>X_train, y_train = create_dataset(scale_train, scale_train, time_steps)<br/>X_test, y_test = create_dataset(scale_test, scale_test, time_steps)<br/>print(X_train.shape, y_train.shape)</span></pre><p id="b649" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这将生成一个形状为(23333，30，2) (23333，2)的训练和测试集。</p><h1 id="6f65" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated"><strong class="ak">模型构建:</strong></h1><p id="7467" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">我们的数据已经成功整形，现在可以构建我们的autoencoder了。本文不会深入讨论自动编码器和LSTMs的细节，但是我强烈建议查看以下信息:</p><div class="nk nl gp gr nm nn"><a rel="noopener follow" target="_blank" href="/anomaly-detection-using-autoencoders-5b032178a1ea"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd ir gy z fp ns fr fs nt fu fw ip bi translated">使用自动编码器的异常检测</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">使用TensorFlow中的自动编码器执行欺诈检测</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">towardsdatascience.com</p></div></div><div class="nw l"><div class="nx l ny nz oa nw ob kp nn"/></div></div></a></div><div class="nk nl gp gr nm nn"><a rel="noopener follow" target="_blank" href="/lstm-for-time-series-prediction-de8aeb26f2ca"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd ir gy z fp ns fr fs nt fu fw ip bi translated">时间序列预测的LSTM</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">用PyTorch训练长短期记忆神经网络并预测比特币交易数据</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">towardsdatascience.com</p></div></div><div class="nw l"><div class="oc l ny nz oa nw ob kp nn"/></div></div></a></div><p id="57ec" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">自动编码器将由分成编码器和解码器的LSTM层组成。首先，模型会将数据的输入序列编码成其关键特征的<strong class="kx ir">简化表示，然后解码器会学习如何将该简化表示转换回其原始输入状态。使用自动编码器方法允许我们<strong class="kx ir">在数据集</strong>内创建“正常”特征的表示。因此，当输入异常序列时，模型将不能重建其简化表示，这将导致较高的模型误差。</strong></p><p id="2446" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于我们的输入使用两个特征，来自组合预测的误差(即来自心率和卡路里序列重建的误差)将被用作我们检测异常的方法。</p><p id="549a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的模型架构在编码器和解码器中使用多个LSTM层，由RepeatVector层分隔，repeat vector层重复由最后一个编码器LSTM层给出的简化表示。在解码器末端的最终时间分配将输入重建回其原始形状。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="a368" class="nd mc iq mz b gy ne nf l ng nh">#model building<br/>model = keras.Sequential()<br/>model.add(keras.layers.LSTM(256, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True, name='encoder_1'))<br/>model.add(keras.layers.Dropout(rate=0.2))<br/>model.add(keras.layers.LSTM(128, return_sequences=True, name='encoder_2'))<br/>model.add(keras.layers.Dropout(rate=0.2))<br/>model.add(keras.layers.LSTM(64, return_sequences=False, name='encoder_3'))<br/>model.add(keras.layers.RepeatVector(n=X_train.shape[1], name='encoder_decoder'))<br/>model.add(keras.layers.LSTM(64, return_sequences=True, name='decoder_1'))<br/>model.add(keras.layers.Dropout(rate=0.2))<br/>model.add(keras.layers.LSTM(128, return_sequences=True, name='decoder_2'))<br/>model.add(keras.layers.Dropout(rate=0.2))<br/>model.add(keras.layers.LSTM(256, return_sequences=True, name='decoder_3'))<br/>model.add(keras.layers.TimeDistributed(keras.layers.Dense(units=X_train.shape[2])))<br/>model.compile(loss='mae', optimizer='adam')<br/>model.summary()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/018237ee9bc62e6a60a4ccf47606362b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uv-WlhcCAfJKOJOfD8fcdQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">模型摘要</p></figure><p id="eec0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该模型将使用Adam优化器，并测量平均误差损失。我们将使模型适合我们的训练数据；<em class="oe">注意，在拟合我们的模型</em>时，训练数据同时用于输入和标签。256的批量将用于25个时期的训练持续时间。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="1994" class="nd mc iq mz b gy ne nf l ng nh">#fitting on training data<br/>history = model.fit(X_train, X_train, epochs=25, batch_size=256,<br/>                    validation_split=0.1,verbose=1,shuffle=False)<br/>#plotting loss<br/>fig=plt.figure()<br/>plt.plot(history.history['loss'], label='Training loss')<br/>plt.plot(history.history['val_loss'], label='Validation loss')<br/>plt.ylabel('Loss')<br/>plt.xlabel('No. Epochs')<br/>plt.legend()<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/1c75d8db70f9e3e20e79c432b39951ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dc7JkYVrZsOxx475IYl60A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">培训期间的培训和验证损失</p></figure><p id="e17d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们现在将使用训练数据和预测之间的MAE来显示损失的分布，这将作为我们定义<strong class="kx ir">异常</strong>的方式。MAE是根据心率和卡路里数据的组合按时间步长计算的。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="aa00" class="nd mc iq mz b gy ne nf l ng nh">#predicting on test data<br/>X_pred = model.predict(X_train)<br/>X_pred_2d = pd.DataFrame(X_pred[:,0,:]).astype(float)<br/>X_pred_2d.columns = ['HR Pred', 'Calories Pred']<br/>X_train_2d = pd.DataFrame(X_train[:,0,:]).astype(float)<br/>X_train_2d.columns = ['HR Test', 'Calories Test']</span><span id="86ce" class="nd mc iq mz b gy ni nf l ng nh">#Plot the test data together<br/>fig, axs = plt.subplots(4, figsize=(12,6))<br/>axs[0].plot(X_pred_2d['HR Pred'])<br/>axs[1].plot(X_train_2d['HR Test'])<br/>axs[2].plot(X_pred_2d['Calories Pred'])<br/>axs[3].plot(X_train_2d['Calories Test'])<br/>plt.setp(axs[0].get_xticklabels(), visible=False)<br/>plt.setp(axs[1].get_xticklabels(), visible=False)<br/>plt.setp(axs[2].get_xticklabels(), visible=False)<br/>axs[0].tick_params(axis='x', rotation=70)<br/>axs[1].tick_params(axis='x', rotation=70)<br/>axs[0].set(ylabel= 'HR Prediction')<br/>axs[1].set(ylabel= 'HR Training')<br/>axs[2].set(ylabel= 'Calories Prediction')<br/>axs[3].set(ylabel= 'Calories Training', xlabel= 'Time Step (per minute)')<br/>plt.tight_layout()</span><span id="c609" class="nd mc iq mz b gy ni nf l ng nh">#calculate error<br/>predictions = pd.concat([X_pred_2d['HR Pred'], X_pred_2d['Calories Pred']], axis = 1)<br/>train_inputs = pd.concat([X_train_2d['HR Test'], X_train_2d['Calories Test']], axis = 1)anomaly = pd.DataFrame(np.abs(predictions.values - train_inputs.values))<br/>anomaly = anomaly.mean(axis=1)</span><span id="80d5" class="nd mc iq mz b gy ni nf l ng nh">ax = sns.distplot(anomaly, bins=50, kde = True)<br/>ax.set_title('Training Data Loss Distribution')<br/>ax.set_xlabel('Loss')<br/>ax.set_ylabel('Frequency')<br/>fig = ax.get_figure()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/36e4e1949c485f065d46981f0c20546c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7joOnXOedsTz5ROJDptmzw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">训练数据丢失分布</p></figure><p id="60ee" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在查看损失分布后，我们可以看到存在具有较高损失值的长尾，这表明模型难以重建输入序列的时间。为了定义用于判断预测是否异常的损失阈值，我们将在第99百分位的<strong class="kx ir">找到训练数据中的损失。</strong></p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="1cb0" class="nd mc iq mz b gy ne nf l ng nh">thres = round(numpy.quantile(anomaly, 0.99),3)<br/>print('99th percentile loss value from training: ' + str(thres))</span><span id="7791" class="nd mc iq mz b gy ni nf l ng nh">99th percentile loss value from training: 0.177</span></pre><h1 id="7f59" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated"><strong class="ak">预测:</strong></h1><p id="2f0b" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">现在我们已经建立了模型，并且<strong class="kx ir">定义了0.177 </strong>的损失阈值，我们可以继续测试我们的模型，看看它是否能够检测到我们之前在测试数据中发现的异常。我们将重新使用我们的模型和先前重新整形的测试数据，并重复相同的过程来计算预测损失。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="7c39" class="nd mc iq mz b gy ne nf l ng nh">#Predicting<br/>X_pred = model.predict(X_test)<br/>X_pred = pd.DataFrame(X_pred[:,0,:]).astype(float)<br/>X_pred.columns = ['HR Pred', 'Calories Pred']<br/>X_test_data = pd.DataFrame(X_test[:,0,:]).astype(float)<br/>X_test_data.columns = ['HR Test', 'Calories Test']</span></pre><p id="1ec9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们使用先前定义的损失阈值作为将数据点定义为异常的分界点。为了更好地可视化我们的异常点，我们将异常列与原始测试数据集相结合，以帮助将事情放入上下文中。</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="ec28" class="nd mc iq mz b gy ne nf l ng nh">difference = pd.DataFrame(np.abs(X_pred.values - X_test_data.values))<br/>difference['mae loss'] = difference.mean(axis=1)<br/>difference['threshold'] = thres<br/>difference['anomaly'] = difference['mae loss'] &gt; difference['threshold']<br/>difference['index'] = difference.index</span><span id="2130" class="nd mc iq mz b gy ni nf l ng nh">X_pred['index'] = X_pred.index<br/>X_test_data['index'] = X_test_data.index<br/>X_test_data = X_test_data.join(difference['anomaly'])</span></pre><p id="7ea7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用之前制作的定标器可以将心率和卡路里数据恢复到原始刻度，这将有助于我们更好地理解我们的结果:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="339f" class="nd mc iq mz b gy ne nf l ng nh">X_test_data_original = pd.DataFrame(scaler.inverse_transform(X_test_data[['HR Test','Calories Test']]))<br/>X_test_data = pd.concat([X_test_data, X_test_data_original], axis = 1)<br/>X_test_data.columns = ['HR Test', 'Calories Test', 'Index', 'Anomaly', 'Heart Rate (BPM)', 'Calories Used']</span></pre><p id="f954" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们最后的步骤将集中在可视化的预测结果。我们将从绘制每个数据点的平均损失开始，根据是否发现异常进行颜色编码:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="a478" class="nd mc iq mz b gy ne nf l ng nh">plt = sns.lmplot(x='index', y='mae loss', data=difference, <br/>           fit_reg=False, hue='anomaly', scatter_kws={"s": 10}, legend=True, legend_out=False, height=5, aspect=2)<br/>plt.set(xlabel='Time Steps (per minute)', ylabel='MAE Loss')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi og"><img src="../Images/c1dc4c546935d638ec81546f7a0be740.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qjyD4O7PWU-Ft9ODp8yVBQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">一段时间内的预测平均绝对误差</p></figure><p id="e0db" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如我们所见，我们之前定义的异常截止点已用于<strong class="kx ir">检测异常数据点</strong>。</p><p id="6b90" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我们的测试数据中查看模型损失在一天中的分布，很明显，在清晨发生异常的可能性极小，因为数据点在500分钟以下(也就是上午08:30)的损失一直很低。这是有道理的，因为我睡着了，显然不会在半夜去健身房。</p><p id="016f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，在一天的其余时间里，情况略有不同，损失分布变得更大，一些数据点被标记为异常。下午(也就是720-1140分钟)损失的更大分布可能归因于我下午时间表的变化。</p><p id="536c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">异常点分布在多个时间间隔中。为了理解这些异常事件发生的原因，我们可以看看心率和卡路里数据集:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="3493" class="nd mc iq mz b gy ne nf l ng nh">plt = sns.lmplot(x ='Index', y='Heart Rate (BPM)', scatter_kws={"s": 10}, data=X_test_data, <br/>           fit_reg=False, hue='Anomaly', legend=True, legend_out=False, height=5, aspect=2)<br/>plt.set(xlabel='Time Steps (per minute)', ylabel='Heart Rate (BPM)')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/fbfdfd6b88b8fbb7ba19ac16004ccfb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vXRmpEDDf1WnnM3kbJ1jMQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由检测到的异常着色的心率测试数据集</p></figure><p id="53aa" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">心率数据已通过在之前的损失图中检测到的异常进行了颜色编码。我们可以看到，明显的异常是当我的心率异常高时，达到每分钟140次以上，在800-1000分钟之间形成两个峰值。这与我之前提到的去医院的时间非常吻合。</p><p id="f112" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有趣的是，我们可以看到异常也发生在正常心率期间(基于相邻的心率值)。我们的模型使用了心率和卡路里，这表明这些异常可能与消耗的卡路里有关。我们需要研究卡路里数据以获得更多信息:</p><pre class="kg kh ki kj gt my mz na nb aw nc bi"><span id="e1a9" class="nd mc iq mz b gy ne nf l ng nh">plt = sns.lmplot(x ='Index', y='Calories Used', scatter_kws={"s": 10}, data=X_test_data, <br/>           fit_reg=False, hue='Anomaly', legend=True, legend_out=False, height=5, aspect=2)<br/>plt.set(xlabel='Time Steps (per minute)', ylabel='Calories Used')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi og"><img src="../Images/b312ae10805ffdcf1a2057622953af76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cdtBFhfRn4HyreexGug3iA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用的卡路里测试数据集通过检测到的异常进行着色</p></figure><p id="859a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的卡路里数据显示，在峰值期间检测到异常，通常超过每分钟6卡路里，这可能是在我走路的时候。当我们观察与高卡路里相关的异常时，我们看到它们发生在心率被认为正常的时候。这种关系，<strong class="kx ir">高卡路里但平均心率</strong>，可以被认为是异常的，因为通常大多数卡路里将在心率较高时被使用(心率和卡路里之间的正相关性也支持这一点)。</p><p id="efc5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当心率高而卡路里数据低时，观察到相反的关系，表明心率高是由于与身体活动无关的原因。<strong class="kx ir">由于这是我自己的数据，我知道下午我去了医院，由于害怕打针，我的心率非常高。这是异常现象的一个很好的例子，也是我选择这一天作为测试数据集的原因。</strong></p><h1 id="93f0" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated"><strong class="ak">结论:</strong></h1><p id="8fb6" class="pw-post-body-paragraph kv kw iq kx b ky mt jr la lb mu ju ld le mv lg lh li mw lk ll lm mx lo lp lq ij bi translated">我们已经学会了如何<strong class="kx ir">使用LSTM网络</strong>开发一个自动编码器模型来检测健康时间序列数据中的异常。我们使用我们的模型来学习什么被认为是正常行为，并使用它来<strong class="kx ir">检测潜在异常</strong>。该模型在一天的异常数据上进行了测试，并正确识别了心率和卡路里之间的一些有趣趋势，这些趋势与自发散步和去医院的可怕旅程有关！</p><p id="8eb5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这个项目有望突出处理个人数据的乐趣，让我们将模型结果解释到比一些经典的现成数据集更高的水平。感谢阅读！</p></div></div>    
</body>
</html>