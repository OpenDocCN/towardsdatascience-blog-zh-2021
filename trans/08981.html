<html>
<head>
<title>Behind the scenes on the Fast Random Projection algorithm for generating graph embeddings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成图嵌入的快速随机投影算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/behind-the-scenes-on-the-fast-random-projection-algorithm-for-generating-graph-embeddings-efb1db0895?source=collection_archive---------3-----------------------#2021-08-19">https://towardsdatascience.com/behind-the-scenes-on-the-fast-random-projection-algorithm-for-generating-graph-embeddings-efb1db0895?source=collection_archive---------3-----------------------#2021-08-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="d14b" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/thoughts-and-theory" rel="noopener" target="_blank">思想和理论</a></h2><div class=""/><div class=""><h2 id="acde" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">FastRP及其超参数的详细研究</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/c3a3955378833a613f85a4ce19e547da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OrfSxf9bo8jfxi41"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@crissyjarvis?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">克里斯·贾维斯</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="6020" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">绝大多数数据科学和机器学习模型依赖于创建一个向量，或者嵌入你的数据。这些嵌入中的一些自然地创造了它们自己。例如，对于按列组织的数字数据，我们可以把与每一行相关的值看作一个向量。在更复杂的情况下，如自然语言处理，我们必须通过各种不同的方法从单词中生成这些嵌入，如<a class="ae le" href="https://en.wikipedia.org/wiki/One-hot" rel="noopener ugc nofollow" target="_blank">一键编码</a>、<a class="ae le" href="https://en.wikipedia.org/wiki/N-gram#Skip-gram" rel="noopener ugc nofollow" target="_blank">跳格法</a>，如<a class="ae le" href="https://en.wikipedia.org/wiki/Word2vec" rel="noopener ugc nofollow" target="_blank"> word2vec </a>等。这些向量然后被用作要被建模的数据的表示。</p><p id="8422" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">很容易将嵌入理解为独立的实体，其中一行的数据不会影响下一行。然而，对于网络图就不一样了。这个域中的数据点是相互关联的，它们之间的关系与单个数据点一样重要。因此，有必要找到一种方法，将图中的节点转换为嵌入，同时还保留这些节点与其邻居的关系(即上下文)。</p><p id="6b65" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我最初发布了一篇关于如何开始使用图嵌入的博文。这个帖子可以在<a class="ae le" href="https://dev.neo4j.com/intro_graph_emb_tds" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><div class="mb mc gp gr md me"><a rel="noopener follow" target="_blank" href="/getting-started-with-graph-embeddings-2f06030e97ae"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ja gy z fp mj fr fs mk fu fw iz bi translated">图形嵌入入门</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">使用Neo4j图形数据科学库的机器学习管道的第一步</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">towardsdatascience.com</p></div></div><div class="mn l"><div class="mo l mp mq mr mn ms ky me"/></div></div></a></div><p id="4eca" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">还有一个由<a class="mt mu ep" href="https://medium.com/u/57f13c0ea39a?source=post_page-----efb1db0895--------------------------------" rel="noopener" target="_blank"> Tomaz Bratanic </a>写的很棒的帖子，展示了FastRP在节点分类任务中的使用，可以在这里找到<a class="ae le" href="https://dev.neo4j.com/fastrp_nc" rel="noopener ugc nofollow" target="_blank">。</a></p><div class="mb mc gp gr md me"><a rel="noopener follow" target="_blank" href="/twitchverse-using-fastrp-embeddings-for-a-node-classification-task-bb8d34aa690"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ja gy z fp mj fr fs mk fu fw iz bi translated">Twitchverse:为节点分类任务使用FastRP嵌入</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">通过使用FastRP嵌入算法提取关系值，为下游节点生成特征…</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">towardsdatascience.com</p></div></div><div class="mn l"><div class="mv l mp mq mr mn ms ky me"/></div></div></a></div><p id="0d56" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这篇特别的文章建立在上面的以及我的前一篇文章的基础上，在那篇文章中，我展示了使用Streamlit创建一个仪表板，以及如何修改Neo4j生成的图形嵌入超参数。这是为FastRP和node2vec图嵌入算法创建的。我通过<a class="ae le" href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" rel="noopener ugc nofollow" target="_blank"> t-SNE </a>提供了一种二维可视化嵌入的方法。</p><p id="009d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这篇文章中，我们将探讨其中一种嵌入算法FastRP的原因和方法，另一篇文章的目标是如何优化这些超参数。</p><div class="mb mc gp gr md me"><a rel="noopener follow" target="_blank" href="/visualizing-graph-embeddings-with-t-sne-in-python-10227e7876aa"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ja gy z fp mj fr fs mk fu fw iz bi translated">用Python中的t-SNE可视化图形嵌入</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">如何定性评估Neo4j图嵌入</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">towardsdatascience.com</p></div></div><div class="mn l"><div class="mw l mp mq mr mn ms ky me"/></div></div></a></div><p id="0ed1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">此外，这篇文章与托马兹·布拉塔尼克的文章<a class="ae le" href="https://dev.neo4j.com/bratanic_node2vec" rel="noopener ugc nofollow" target="_blank">“理解Node2Vec算法的完全指南”是平行的</a></p><div class="mb mc gp gr md me"><a rel="noopener follow" target="_blank" href="/complete-guide-to-understanding-node2vec-algorithm-4e9a35e5d147"><div class="mf ab fo"><div class="mg ab mh cl cj mi"><h2 class="bd ja gy z fp mj fr fs mk fu fw iz bi translated">理解Node2Vec算法的完整指南</h2><div class="ml l"><h3 class="bd b gy z fp mj fr fs mk fu fw dk translated">理解node2vec算法及其超参数的深入指南</h3></div><div class="mm l"><p class="bd b dl z fp mj fr fs mk fu fw dk translated">towardsdatascience.com</p></div></div><div class="mn l"><div class="mx l mp mq mr mn ms ky me"/></div></div></a></div><h2 id="7770" class="my mz iq bd na nb nc dn nd ne nf dp ng lo nh ni nj ls nk nl nm lw nn no np iw bi translated">警告！</h2><p id="787f" class="pw-post-body-paragraph lf lg iq lh b li nq ka lk ll nr kd ln lo ns lq lr ls nt lu lv lw nu ly lz ma ij bi translated">数学就要来了！如果你从未尝试过在介质上正确渲染数学，那就不好看了！我会尽我所能…</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nv"><img src="../Images/658858435fed5d8b11923f39ec30a457.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OYBlEJVgQvPz-Ilk"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@thisisengineering?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">this engineering RAEng</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><h1 id="003d" class="nw mz iq bd na nx ny nz nd oa ob oc ng kf od kg nj ki oe kj nm kl of km np og bi translated">FastRP的起源:Johnson-Lindenstrauss引理</h1><p id="14dc" class="pw-post-body-paragraph lf lg iq lh b li nq ka lk ll nr kd ln lo ns lq lr ls nt lu lv lw nu ly lz ma ij bi translated">FastRP算法是由H. Chen等人创建的。al，这个你可以在<a class="ae le" href="https://arxiv.org/abs/1908.11512" rel="noopener ugc nofollow" target="_blank">原论文</a>里详细读到。我真的推荐那篇文章，因为我会大量引用它。因为它背后的数学是<a class="ae le" href="https://neo4j.com/docs/graph-data-science/current/algorithms/fastrp/" rel="noopener ugc nofollow" target="_blank"> Neo4j FastRP算法</a>的基础(甚至包括变量名)，我们需要花一点时间来讨论这个数学。不要担心…我希望不要让它变得太糟糕，我对你充满信心，亲爱的读者，你会度过难关的！</p><p id="0d1f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">约翰逊-林登斯特拉斯引理，也称为JL引理，是FastRP算法的数学核心。简而言之，它说如果向量空间中的点具有足够高的维数，那么它们可以以近似保持点之间距离的方式被投影到合适的低维空间中。如果你仔细想想，这真的是大多数降维方法的根源。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oh"><img src="../Images/4547b66a7ccc8eafdd776a61a665cf0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dG5OhXg1HUCMj7rWFOxhoA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">降维基础(图片由作者提供)</p></figure><p id="00ec" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">所以是的，我们正试图从<em class="oi">p</em>-维空间到<em class="oi">d</em>-维空间，其中<em class="oi"> d &lt; p </em>。给定这两个点<em class="oi"> xᵢ </em>和<em class="oi">xⱼ</em>，我们想要创建一些映射，<em class="oi">ψ</em>，它从高维空间转换到低维空间，同时理想地近似保持这两个点之间的距离。这实质上意味着我们要求解下面的等式:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oj"><img src="../Images/003381eb5652ff7acdb61e33166ab50b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OSVl8mfxov17mSYJHHLazg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">降维解决方案(图片由作者提供)</p></figure><p id="50a7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们的目标是让ϵ尽可能小。这个等式成立的事实就是JL引理。</p><p id="e554" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这里真正的诀窍是理解<em class="oi">ψ</em>应该是什么。D. Achlioptas发现(并在本文中描述)你可以通过使用一个简单的二进制抛硬币，一个随机数，获得数据库友好的随机投影(实际上，这是论文的标题)。陈等。al用这个想法实现了一个随机投影矩阵，<em class="oi"> R </em>，这将是我们最终给出的映射的要点</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/f475ef01908a76da793424ed5830117a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t9RXuPU6t8DQSaTK4Y_vkg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">随机投影矩阵(图片作者提供)</p></figure><p id="b3ef" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">事实上，李等人<a class="ae le" href="https://doi.org/10.1145/1150402.1150436" rel="noopener ugc nofollow" target="_blank">曾报道过</a>只要<em class="oi"> R </em>的均值为零，那么点与点之间的两两距离就保持不变——这就是降维的目的。此外，李表明<em class="oi"> s </em>可被选择为与图中边数的平方根一样高，<em class="oi"> s = sqrt(m)，</em>假设下游矩阵(见下文)可被认为非常稀疏。<em class="oi"> </em>有趣的是，使用这个随机投影矩阵实际上可以比高斯随机投影快上<em class="oi"> sqrt(m)。</em>然而，根据矩阵的稀疏性，在最初的Achlioptas论文中发现选择<em class="oi"> s = 3 </em>是足够的。</p><h1 id="f946" class="nw mz iq bd na nx ny nz nd oa ob oc ng kf od kg nj ki oe kj nm kl of km np og bi translated">那么这和图表有什么关系呢？？？</h1><p id="7a66" class="pw-post-body-paragraph lf lg iq lh b li nq ka lk ll nr kd ln lo ns lq lr ls nt lu lv lw nu ly lz ma ij bi translated">我很高兴你问了！是的，所以我们有这个矩阵可以随机化东西。很明显，我们想把它应用到其他矩阵中。但是我们有什么矩阵和图有关系呢？</p><p id="6e13" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">邻接矩阵是一个很好的开始！实际上，我们将通过创建转移矩阵<em class="oi"> A </em>来对其进行一点改进，如<em class="oi"> A = D⁻ S </em>其中<em class="oi"> S </em>是邻接矩阵，<em class="oi"> D </em>是图的度矩阵(给出每个节点度的对角矩阵)。让我们快速地将它们可视化，因为这将使后续矩阵的维度更加清晰。假设我们有一个加权的有向图，如下所示</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/c94dd0b762935f499c12ddd35fe90f6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*Qsv3p_ySw7WUlnkXZhgVLA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">样本加权有向图(图片由<a class="mt mu ep" href="https://medium.com/u/57f13c0ea39a?source=post_page-----efb1db0895--------------------------------" rel="noopener" target="_blank"> Tomaz Bratanic </a>提供，经许可使用)</p></figure><p id="395f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">(注意，我们也可以用未加权和/或无向图来做这件事，但我想我会展示最复杂的例子。)因此，根据上面的图，我们将得到邻接矩阵，如下所示</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi om"><img src="../Images/b84026e892a17eb0031dfe60e25dbfae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*55uGn10mbiExJt5nPmI83A.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">加权有向图的邻接矩阵(图片由作者提供)</p></figure><p id="35fc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们还可以建立度矩阵:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi on"><img src="../Images/fa7d5e728e919918d44a4af0fb24d4eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j2JsJHZq5nd_8A_00ZKJEQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">上述加权有向图的度矩阵(图片由作者提供)</p></figure><p id="253d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">因此，我们可以通过以下方式构建转移矩阵</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oo"><img src="../Images/e01ac3230169808cd2d8a863aed94c05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Krx97f9HswYLDQMYMSsDxw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">上述加权有向图的转移矩阵(图片由作者提供)</p></figure><p id="c7b6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">注意，上面的每个矩阵都是一个正方形，<em class="oi">n×n</em>矩阵，其中<em class="oi"> n </em>是图中节点的数量。</p><p id="d018" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在我们开始进入FastRP算法的Neo4j实现实际使用的符号！这里是我们开始进入这些超参数的地方。</p><p id="7f6b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">像任何嵌入的创建一样，在我们做有趣的事情之前，我们想考虑标准化我们的数据。记住，我们的一些节点可能有很高的相对度。因此，我们将创建一个归一化矩阵(对角线在<em class="oi"> n </em>中),由下式给出</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi op"><img src="../Images/c1e4a329dfbd81634a9ef64fdf47e4df.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*cINdPzQHo_0TQTZsyeMx2w.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">归一化矩阵(图片由作者提供)</p></figure><p id="575d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">其中<em class="oi"> β </em>是归一化强度，<em class="oi"> m </em>是边的数量，<em class="oi"> dⱼ </em>是第<em class="oi"> j </em>个节点的度数。所以当<em class="oi"> β </em>趋于无穷大时，我们可以得到</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/b374d7d7350070d851cdaf0a95725fc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*L1lt3o55ihLbzX1D3bOrpg.png"/></div></figure><p id="446b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们思考一下这实际上意味着什么，特别是当我们将这个归一化矩阵应用于转移矩阵时。假设我们有<em class="oi"> A的<em class="oi"> k- </em>次方(</em>，即我们用<em class="oi"> </em>本身<em class="oi"> k </em>乘以<em class="oi"> ) </em>乘以<em class="oi"> A </em>。<strong class="lh ja"><em class="oi">aᵏ的第ij个条目，是随机游走正好k步从I到达j的概率！</em> </strong></p><p id="7780" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">是的，这是粗体和斜体，因为它真的很重要。FastRP只是由这个抛硬币随机发生器控制的随机行走！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi or"><img src="../Images/6f36b9a3504985aec133e9fb07f1072b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6yYW1t68YcS2ZAPX"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@cgbriggs19?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">克里斯·布里格斯</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="ac96" class="nw mz iq bd na nx ny nz nd oa ob oc ng kf od kg nj ki oe kj nm kl of km np og bi translated">所以现在我们知道了…</h1><p id="ec68" class="pw-post-body-paragraph lf lg iq lh b li nq ka lk ll nr kd ln lo ns lq lr ls nt lu lv lw nu ly lz ma ij bi translated">我们现在把<em class="oi"> A </em>换一种形式，这样计算效率更高，然后我们就准备写出实际的FastRP算法是什么了。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi os"><img src="../Images/04ba93ace75a6d9d973c5106163bcfa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*3qwqYkfEKa6OJvEGabgNdw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">再生Aᵏ(图片由作者提供)</p></figure><p id="dcca" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在是开始FastRP的时候了！</p><p id="df84" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">给定我们的图转移矩阵<em class="oi"> A </em>，嵌入维数<em class="oi"> d </em>，归一化强度<em class="oi"> β </em>，以及一些迭代权重<em class="oi"> α₁ … αₖ </em>(稍后将详细介绍这些)，步骤如下:</p><ol class=""><li id="0fee" class="ot ou iq lh b li lj ll lm lo ov ls ow lw ox ma oy oz pa pb bi translated">产生<em class="oi"> Rᵢⱼ </em>随机投影矩阵</li><li id="531f" class="ot ou iq lh b li pc ll pd lo pe ls pf lw pg ma oy oz pa pb bi translated">计算矩阵嵌入的第一次迭代为<em class="oi"> N₁ = A ⋅ L ⋅ R </em></li><li id="4e64" class="ot ou iq lh b li pc ll pd lo pe ls pf lw pg ma oy oz pa pb bi translated">计算<em class="oi"> i = 2时<em class="oi"> N </em>的后续值..节点数</em>为<em class="oi"> Nᵢ ←一个⋅ Nᵢ₋₁ </em></li><li id="451f" class="ot ou iq lh b li pc ll pd lo pe ls pf lw pg ma oy oz pa pb bi translated">计算<em class="oi"> N </em>的所有值的加权和</li></ol><p id="cc22" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这里的最终结果是我们得到了<em class="oi">(n×n)⋅(n×n)</em>的矩阵乘法，这导致<em class="oi"> N </em>具有维度<em class="oi"> (n × d) </em>，这正是我们想要的(每个<em class="oi"> n </em>节点有一个<em class="oi"> d </em>维度嵌入)。</p><p id="1336" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果我们在LR引理的背景下考虑这个问题，回想一下<em class="oi">ψ</em>是把我们从ℝᵖ带到ℝᵈ.的东西因此，如果我们认为<em class="oi"> N = A ⋅ L ⋅ R </em>，这就意味着<em class="oi">ψ= l⋅r</em>。</p><h2 id="3ec0" class="my mz iq bd na nb nc dn nd ne nf dp ng lo nh ni nj ls nk nl nm lw nn no np iw bi translated">重量，重量，更多重量</h2><p id="1b6f" class="pw-post-body-paragraph lf lg iq lh b li nq ka lk ll nr kd ln lo ns lq lr ls nt lu lv lw nu ly lz ma ij bi translated">是的，我们在上面的<em class="oi"> α </em>值中有另一组权重。这些是为每个<em class="oi"> Nᵢ </em>计算的迭代权重，它们需要自己的解释。</p><p id="4976" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">很明显，这些权重将控制上述每一步对最终节点嵌入的相对影响。对于1次迭代，我们将只获得基于每个节点的第一个邻居的嵌入，这不是很有用。因此，例如，假设我们有4次迭代(即<em class="oi"> k = 4 </em>)。这到底意味着什么？我们之前说过(上面粗体斜体部分)Aᵏ 的第<em class="oi"> ij </em>项表示从<em class="oi"> j </em>到达<em class="oi"> i </em>的概率正好是4步。如果在5步之前概率为零，那么<em class="oi"> Aᵢⱼ </em>为零。换句话说，在<em class="oi"> k = 4 </em>的情况下，我们不能随机跳到图中的一个节点，也就是说，5跳或更多跳。因此<em class="oi"> k </em>告诉我们，我们在嵌入中包含了节点周围的多少局部邻域。然后，我们可以将上面的每个随机投影步骤加权为</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ph"><img src="../Images/c63d13f929cd01f785305cdcb6483c01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UhCuUC-3KCQlmnnLgd-S6g.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">FastRP嵌入的最终计算(图片由作者提供)</p></figure><p id="e4a5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">实际上，如果我们只关注任何给定节点的近邻，那么嵌入效果不会很好。因此，忽略那些小的k值甚至是值得的。事实上，这正是作者们最初所做的。他们观察到嵌入在<em class="oi"> k = 4 </em>并且仅使用<em class="oi"> A </em>和<em class="oi"> A⁴ </em>的情况下是很好的。所以基于此，他们设定了权重<em class="oi"> (α₁，α₂，α₃) = (0，0，1) </em>。在原始论文中，他们然后通过参数化调整<em class="oi"> α₄ </em>和<em class="oi"> β </em>来优化他们的嵌入，给定一个期望值<em class="oi"> d </em>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pi"><img src="../Images/af41a3b48e78c3ad594fc9f3d323d279.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IkPmfElm-elC6sRZ"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@tonny_tran?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Tony Tran </a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="642f" class="nw mz iq bd na nx ny nz nd oa ob oc ng kf od kg nj ki oe kj nm kl of km np og bi translated">哇！太多了！真的值得吗？？？</h1><p id="8d2f" class="pw-post-body-paragraph lf lg iq lh b li nq ka lk ll nr kd ln lo ns lq lr ls nt lu lv lw nu ly lz ma ij bi translated">TL；是的博士！</p><p id="bfc2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">该算法既快速又简单。例如，作者报告说，使用WWW-200k数据集，FastRP进行嵌入的CPU时间是136.0秒，而node2vec用了63.8天<em class="oi"/>！当与node2vec和另一种流行的嵌入算法DeepWalk进行比较时，他们观察到嵌入产生的节点分类结果至少一样准确，如果不是更准确的话！还有很多其他的图形嵌入算法，但是FastRP的一个优点是它非常简单。它也很容易扩展，允许您合并图的附加信息，如单个节点的属性，以进一步增强您的嵌入。</p><p id="85ba" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">和任何图嵌入算法一样，所谓“魔鬼”就在细节中。如何设置每个超参数将取决于您的图表本身，并且需要相当多的实验。这将是未来博客文章的主题。敬请期待！</p><p id="18f7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="oi">特别感谢</em><a class="mt mu ep" href="https://medium.com/u/57f13c0ea39a?source=post_page-----efb1db0895--------------------------------" rel="noopener" target="_blank"><em class="oi">Tomaz Bratanic</em></a><em class="oi">和</em><a class="mt mu ep" href="https://medium.com/u/3865848842f9?source=post_page-----efb1db0895--------------------------------" rel="noopener" target="_blank"><em class="oi">Michael Hunger</em></a><em class="oi">对本帖的建议和点评。</em></p><h1 id="ce06" class="nw mz iq bd na nx ny nz nd oa ob oc ng kf od kg nj ki oe kj nm kl of km np og bi translated">参考</h1><ul class=""><li id="44a2" class="ot ou iq lh b li nq ll nr lo pj ls pk lw pl ma pm oz pa pb bi translated">CJ Sullivan，<a class="ae le" href="https://dev.neo4j.com/intro_graph_emb_tds" rel="noopener ugc nofollow" target="_blank">“图形嵌入入门”</a> (2021)</li><li id="c202" class="ot ou iq lh b li pc ll pd lo pe ls pf lw pg ma pm oz pa pb bi translated">Tomaz Bratanic，"<a class="ae le" href="https://dev.neo4j.com/fastrp_nc" rel="noopener ugc nofollow" target="_blank"> Twitchverse:为节点分类任务使用FastRP嵌入</a>"(2021)</li><li id="04ad" class="ot ou iq lh b li pc ll pd lo pe ls pf lw pg ma pm oz pa pb bi translated">CJ Sullivan " <a class="ae le" href="https://dev.neo4j.com/tds_streamlit_embeddings" rel="noopener ugc nofollow" target="_blank">用t-SNE和Python可视化图形嵌入</a>(2021)</li><li id="9c99" class="ot ou iq lh b li pc ll pd lo pe ls pf lw pg ma pm oz pa pb bi translated">托马兹·布拉塔尼克，<a class="ae le" href="https://dev.neo4j.com/bratanic_node2vec" rel="noopener ugc nofollow" target="_blank">《理解Node2Vec算法完全指南》</a> (2021)</li><li id="916b" class="ot ou iq lh b li pc ll pd lo pe ls pf lw pg ma pm oz pa pb bi translated">H.Chen，S.F. Sultan，Y. Tian，M. Chen，S. Skiena，<a class="ae le" href="https://doi.org/10.1145/3357384.3357879" rel="noopener ugc nofollow" target="_blank">“通过非常稀疏的随机投影实现快速准确的网络嵌入”，</a> CIKM '19:第28届ACM信息与知识管理国际会议论文集(2019)</li><li id="d06a" class="ot ou iq lh b li pc ll pd lo pe ls pf lw pg ma pm oz pa pb bi translated">D.Achlioptas，“<a class="ae le" href="https://www.sciencedirect.com/science/article/pii/S0022000003000254" rel="noopener ugc nofollow" target="_blank">数据库友好的随机预测:约翰逊-林登施特劳斯与二进制硬币</a>，”计算机系统与科学杂志(2003)</li><li id="1dc1" class="ot ou iq lh b li pc ll pd lo pe ls pf lw pg ma pm oz pa pb bi translated">页（page的缩写）李，T.J. Hastie，K.W. Church，“<a class="ae le" href="https://doi.org/10.1145/1150402.1150436" rel="noopener ugc nofollow" target="_blank">非常稀疏随机投影</a>”，06:第12届ACM SIGKDD知识发现与数据挖掘国际会议论文集(2006)</li></ul></div></div>    
</body>
</html>