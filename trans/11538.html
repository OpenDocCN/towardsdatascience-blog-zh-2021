<html>
<head>
<title>Building Your First Network in PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 PyTorch 建立您的第一个网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/all-you-need-to-know-about-pytorch-a0ba3af897fa?source=collection_archive---------16-----------------------#2021-11-14">https://towardsdatascience.com/all-you-need-to-know-about-pytorch-a0ba3af897fa?source=collection_archive---------16-----------------------#2021-11-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="047b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">启动你深度学习生涯的总结。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/03f7403d7aed867aaf84f4b9193eb09f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_i0NwskCbOCnXtTp"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae ky" href="https://unsplash.com/@max_duz?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Max Duzij </a>拍照</p></figure><p id="b79b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">开始一个深度学习项目，听起来很吓人，很难？我已经通读了关于神经网络的文章，上过课，看过视频，但是我如何开始编程呢？我们都经历过那个阶段，这就是为什么我写这篇文章来告诉你开始 PyTorch 模型训练项目的一切(或者至少是我知道的大部分事情)。</p><p id="7944" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">指南以自下而上的方式呈现。我将首先描述对训练深度网络很重要的各个组件，然后提供如何将所有组件组合在一起进行训练和测试的示例。</p><p id="9f66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">边注:</em></p><p id="1b0e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文章是将 ML 中的理论知识直接转化为代码的桥梁。假设有先验的 ML 知识。</p><p id="1454" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">我的项目主要在计算机视觉领域，所以我发现 PyTorch 中最有用的功能也偏向于图像方面的应用。</em></p><h1 id="d093" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">目录</h1><p id="1b12" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><strong class="lb iu"> </strong> <a class="ae ky" href="#d093" rel="noopener ugc nofollow"> <strong class="lb iu">目录</strong> </a> <br/> <strong class="lb iu"> </strong> <a class="ae ky" href="#b6a4" rel="noopener ugc nofollow"> <strong class="lb iu">导入</strong></a><br/><strong class="lb iu"/><a class="ae ky" href="#4e1f" rel="noopener ugc nofollow"><strong class="lb iu">网络组件</strong> </a> <br/> ∘ <a class="ae ky" href="#c4c8" rel="noopener ugc nofollow">全连通层</a> <br/> ∘ <a class="ae ky" href="#98fb" rel="noopener ugc nofollow">卷积族</a> <br/> ∘ <a class="ae ky" href="#ab9a" rel="noopener ugc nofollow">递归网络</a> <br/> ∘ <a class="ae ky" href="#af15" rel="noopener ugc nofollow">激活功能</a> <br/> <strong class="lb iu"> <a class="ae ky" href="#4607" rel="noopener ugc nofollow"> <strong class="lb iu">结合一切</strong> </a> <br/> ∘ <a class="ae ky" href="#66a8" rel="noopener ugc nofollow">导入 PyTorch </a> <br/> ∘ <a class="ae ky" href="#1aa7" rel="noopener ugc nofollow">创建网络</a> <br/> ∘ <a class="ae ky" href="#f3ee" rel="noopener ugc nofollow">创建数据集和数据加载器</a> <br/> ∘ <a class="ae ky" href="#93fb" rel="noopener ugc nofollow">初始化网络、优化器和调度器</a> <br/> ∘ <a class="ae ky" href="#3ddc" rel="noopener ugc nofollow">培训、评估和保存</a> <br/> <strong class="lb iu"/></strong></p><h1 id="b6a4" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">导入</h1><p id="298d" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">PyTorch 有很多相关的库，这里我列出了执行下面所有操作的基本库:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="dae9" class="my lx it mu b gy mz na l nb nc">import torch<br/>import torch.nn as nn<br/>import torch.optim as optim<br/>import torch.utils.data<br/>from torch.utils.data import Dataset, DataLoader<br/>import torchvision</span></pre><p id="f022" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有的代码将基于上述的进口，所以请注意所有的名称别名由' as '创建。</p><h1 id="4e1f" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">网络组件</h1><p id="495b" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">让我们从 PyTorch 中训练网络的最重要的方面开始，设计网络本身。深度网络可以由各种类型的层组成，这里我列出了一些最常用的层类型。</p><h2 id="c4c8" class="my lx it bd ly nd ne dn mc nf ng dp mg li nh ni mi lm nj nk mk lq nl nm mm nn bi translated">完全连接的层</h2><p id="d6bc" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这是最传统的神经网络的主要组成部分，也在今天的大多数模型中使用。它可以通过以下方式创建:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="9089" class="my lx it mu b gy mz na l nb nc">nn.Linear(input_size, output_size, ...)</span></pre><p id="5ff7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">输入 _ 大小</em>和<em class="lv">输出 _ 大小</em>本质上是进出该层的通道数量。</p><h2 id="98fb" class="my lx it bd ly nd ne dn mc nf ng dp mg li nh ni mi lm nj nk mk lq nl nm mm nn bi translated"><strong class="ak">卷积家族</strong></h2><p id="e59e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><strong class="lb iu">回旋</strong></p><p id="1138" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">围绕计算机视觉/图像的任务通常由卷积神经网络(CNN)处理。与正常的全连接层不同，CNN 由卷积构建，卷积可以通过以下方式创建:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="d19b" class="my lx it mu b gy mz na l nb nc">nn.Conv2D(input_size, output_size, kernel, stride, padding, ...)<br/>nn.ConvTranspose2D(input_size, output_size, kernel, stride, ...)</span></pre><p id="60e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv"> nn。Conv2D() </em>本质上是一个 2D 卷积，带有创建它所需的参数(例如，输入和输出通道大小、内核、步幅、填充)。PyTorch 还提供 1D 和 3D 卷积，具体取决于您查看的是一维数据还是 3D 表示。</p><p id="bd44" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要执行反卷积(主要用于网络的解码阶段)，请使用<em class="lv"> nn。ConvTranspose2D() </em>。通过简单地将 2D 改变为 1D 或 3D，再次支持一至三维。</p><p id="aae4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">联营</strong></p><p id="99af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">卷积通常与池化图层成对出现，以改变输出要素地图的大小。最常用的汇集方法包括:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="99c7" class="my lx it mu b gy mz na l nb nc">nn.MaxPool2d(kernel_size, stride, padding, ...)<br/>nn.AvgPool2d(kernel_size, stride, padding, ...)</span></pre><p id="d460" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">指的是最大和平均池。如果你很懒于计算，只想得到一个目标尺寸，你也可以选择:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="f1d3" class="my lx it mu b gy mz na l nb nc">nn.AdaptiveAvgPool2d(output_size)</span></pre><p id="516c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将自动确定应如何进行池化，以便以您想要的大小输出要素。</p><p id="e11c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">批量标准化</strong></p><p id="c13c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">想要执行批量标准化吗？PyTorch 也为你解决了:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="d99c" class="my lx it mu b gy mz na l nb nc">nn.BatchNorm2d(num_features, ......)</span></pre><p id="f93b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在卷积层之后直接应用它</p><h2 id="ab9a" class="my lx it bd ly nd ne dn mc nf ng dp mg li nh ni mi lm nj nk mk lq nl nm mm nn bi translated">循环网络</h2><p id="12a9" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">如果你更喜欢自然语言处理或时间序列数据分析，你可能会遇到比 CNN 更多的递归网络。以下是 PyTorch 支持的更著名的循环网络类型列表:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="4f0f" class="my lx it mu b gy mz na l nb nc">nn.RNN(...)<br/>nn.GRU(...)<br/>nn.LSTM(...)</span></pre><p id="e974" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以关注一些详细的博客。有大量的变化(单向或双向)，有大量的在线资源供你研究。</p><h2 id="af15" class="my lx it bd ly nd ne dn mc nf ng dp mg li nh ni mi lm nj nk mk lq nl nm mm nn bi translated">激活功能</h2><p id="7c7e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">对于要学习的网络，你需要在每一层之后应用激活函数。一些常用的激活，如 sigmoid、ReLU 或 LeakyReLU，可通过以下方式创建:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="1e01" class="my lx it mu b gy mz na l nb nc">nn.Sigmoid()<br/>nn.ReLU()<br/>nn.LeakyReLU()</span></pre><p id="9156" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，sigmoid 函数存在梯度消失的问题，因此它通常用于最终输出图层，以在 0 和 1 之间进行预测，而在其他地方则不进行预测。LeakyReLU 通常性能更好，但也比计算 ReLU 慢。</p><p id="ecec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样重要的是不要将两个激活函数堆叠在一起。这将使你的网络几乎无法学习，你将花费大量时间调试它！</p><h1 id="bc01" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">损失函数</h1><p id="1b55" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">一些最常用的损失(例如，MSE 损失、二元交叉熵、kl 散度)可通过以下方法计算:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="c7cd" class="my lx it mu b gy mz na l nb nc">nn.MSELoss()<br/>nn.BCELoss()<br/>nn.KLDivLoss()</span></pre><h1 id="0899" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">乐观主义者</h1><p id="f5c6" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为了配合损失函数，下面是 PyTorch 提供的几种最广泛使用的优化器:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="068e" class="my lx it mu b gy mz na l nb nc">optim.Adam(model.parameters, lr, ...)<br/>optim.SGD(model.parameters, lr, momentum, ...)</span></pre><p id="9cdd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可能还需要一个学习率计划程序，当你的训练似乎达到平稳状态时，学习率会降低。这可以通过以下方式实现:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="0638" class="my lx it mu b gy mz na l nb nc">optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode, patience, ...)</span></pre><h1 id="4ecb" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">设置 GPU</h1><p id="e3e6" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">深度模型计算量很大。非常贵。如果你有 GPU，建议对他们进行培训。有几种方法可以使用 PyTorch 将你的网络、张量和其他东西放到 GPU 上:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="2853" class="my lx it mu b gy mz na l nb nc"># 1<br/>device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')<br/>tensor = tensor.to(device)</span><span id="2c52" class="my lx it mu b gy no na l nb nc"># 2<br/>tensor = tensor.cuda()</span></pre><p id="2899" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更明智的方法是第一种方法，因为第二种方法假设 GPU 可用，并且在没有 GPU 的设备上中断。</p><p id="5eff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当您有多个 GPU 时，您也可以使用:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="71f3" class="my lx it mu b gy mz na l nb nc">network = nn.DataParallel(network).cuda()</span></pre><p id="6eb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将网络分布到多个 GPU 上进行并行计算。</p><h1 id="4607" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结合一切</h1><p id="f0b7" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">每个模型都是不同的，但在如何创建和训练它们方面，它们或多或少都有相似的结构。以下是整个过程的大致轮廓:</p><h2 id="66a8" class="my lx it bd ly nd ne dn mc nf ng dp mg li nh ni mi lm nj nk mk lq nl nm mm nn bi translated">进口 PyTorch</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="1aa7" class="my lx it bd ly nd ne dn mc nf ng dp mg li nh ni mi lm nj nk mk lq nl nm mm nn bi translated">创建网络</h2><p id="559c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这是您收集所有网络组件来编写模型的部分。将输入输入网络时，您需要初始化所需的一切:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="f3ee" class="my lx it bd ly nd ne dn mc nf ng dp mg li nh ni mi lm nj nk mk lq nl nm mm nn bi translated">创建数据集和数据加载器</h2><p id="1d66" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们必须处理数据，这样我们就可以迭代地从数据集中获取批量数据，并将其输入神经网络:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="93fb" class="my lx it bd ly nd ne dn mc nf ng dp mg li nh ni mi lm nj nk mk lq nl nm mm nn bi translated">初始化网络、优化器和调度器</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="3ddc" class="my lx it bd ly nd ne dn mc nf ng dp mg li nh ni mi lm nj nk mk lq nl nm mm nn bi translated">培训、评估和储蓄</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="84f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就在那里！模型可以变化，训练方法可以不同，可视化可以应用，损失可以是许多奇怪组件的组合，但最终它将基于这样一个简单的主干。关于实际网络的例子，请随意在这里<a class="ae ky" rel="noopener" target="_blank" href="/building-a-gan-with-pytorch-237b4b07ca9a"><strong class="lb iu"/></a>或者在这里 找到<a class="ae ky" rel="noopener" target="_blank" href="/building-a-convolutional-vae-in-pytorch-a0f54c947f71"> <strong class="lb iu">。</strong></a></p><h1 id="ac7e" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">预训练模型</h1><p id="162e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">如果您想使用一些成熟的架构，而不是设计自己的架构，PyTorch 也能满足您的要求:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="9085" class="my lx it mu b gy mz na l nb nc">torchvision.models.resnet50(pretrained=True)</span></pre><p id="b00c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">预训练权重将加载到您的模型中，您可以继续在自己的数据集上对其进行微调。</p><h1 id="c84e" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">其他有趣的 PyTorch 函数</h1><p id="2530" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">以下是我在深入学习的过程中发现的一些有用的功能:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="b612" class="my lx it mu b gy mz na l nb nc">torch.ge(input, constant)</span></pre><p id="fd71" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果值&gt;常数，则将整个输入张量转换为 1，否则转换为 0。适用于计算交集和并集之类的东西。</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="04e9" class="my lx it mu b gy mz na l nb nc">torch.topk(input, k)</span></pre><p id="7d11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从输入张量中查找前 k 个值。输出将是前 k 个值及其相应索引的元组。</p></div><div class="ab cl nr ns hx nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="im in io ip iq"><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="66d4" class="my lx it mu b gy mz na l nb nc">torch.stack(list)</span></pre><p id="f3d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将长度为 n 的张量列表转换为大小为 n 的张量。</p><h1 id="75b3" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结束注释</h1><p id="6903" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">所以你有它。关于如何开始你的第一个深度学习项目的简单、全面的指南。希望这有所帮助，你的网络工作！</p><p id="35cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">感谢您坚持到现在</em>🙏<em class="lv">！</em> <em class="lv">我会在计算机视觉/深度学习的不同领域发布更多内容，所以</em> <a class="ae ky" href="https://taying-cheng.medium.com/membership" rel="noopener"> <em class="lv">加入并订阅</em> </a> <em class="lv">如果你有兴趣了解更多！</em></p></div></div>    
</body>
</html>