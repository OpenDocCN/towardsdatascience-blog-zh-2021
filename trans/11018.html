<html>
<head>
<title>Residual, BottleNeck, Inverted Residual, Linear BottleNeck, MBConv Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">残差、瓶颈、反向残差、线性瓶颈、MBConv解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/residual-bottleneck-inverted-residual-linear-bottleneck-mbconv-explained-89d7b7e7c6bc?source=collection_archive---------6-----------------------#2021-10-27">https://towardsdatascience.com/residual-bottleneck-inverted-residual-linear-bottleneck-mbconv-explained-89d7b7e7c6bc?source=collection_archive---------6-----------------------#2021-10-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d1ca" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><em class="ki">py torch中的那些+实现是什么鬼</em></h2></div><p id="5234" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><em class="lf">嘿，我在</em><a class="ae lg" href="https://www.linkedin.com/in/francesco-saverio-zuppichini-94659a150/" rel="noopener ugc nofollow" target="_blank"><em class="lf">LinkedIn</em></a><em class="lf">过来打个招呼👋</em></p><p id="612b" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">这里有一个互动版本<a class="ae lg" href="https://github.com/FrancescoSaverioZuppichini/BottleNeck-InvertedResidual-FusedMBConv-in-PyTorch/blob/main/README.ipynb" rel="noopener ugc nofollow" target="_blank">可用</a></p><p id="9661" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated"><strong class="kl iu">所有这些模块都已经在我的</strong> <a class="ae lg" href="https://github.com/FrancescoSaverioZuppichini/glasses" rel="noopener ugc nofollow" target="_blank"> <strong class="kl iu">眼镜</strong> </a>库中实现了</p><p id="294f" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">在现代深度学习中记录名字很难。今天我们将看到现代CNN架构中使用的不同模块，如ResNet、MobileNet、EfficientNet，以及它们在PyTorch中的实现！</p><p id="018a" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">在我们做任何事情之前，让我们创建一个通用的conv-规范-行为层</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="lm ln l"/></div></figure><pre class="lh li lj lk gt lo lp lq lr aw ls bi"><span id="f913" class="lt lu it lp b gy lv lw l lx ly">torch.Size([1, 64, 56, 56])</span></pre><h1 id="ffab" class="lz lu it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">剩余连接</h1><p id="94ab" class="pw-post-body-paragraph kj kk it kl b km mq ju ko kp mr jx kr ks ms ku kv kw mt ky kz la mu lc ld le im bi translated">在<a class="ae lg" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> <em class="lf">中提出的ResNet中使用了残差连接，用于图像识别</em> </a>的深度残差学习，让我们也引用Schmidhuber实验室在<a class="ae lg" href="https://arxiv.org/abs/1505.00387" rel="noopener ugc nofollow" target="_blank"> <em class="lf">高速公路网</em> </a>上的工作。这个想法是将你的输入添加到你的输出中。下面的图片可以帮助你把它形象化。但是，我的意思是它只是一个<code class="fe mv mw mx lp b">+</code>操作符。残差运算提高了梯度跨乘数层传播的能力，从而允许有效地训练超过100层的网络。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi my"><img src="../Images/878ed80be897819637d974ec80b963eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*nHAXtGbv16HmVuk0sAnPnA.png"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">作者图片</p></figure><p id="eb3a" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">在PyTorch中，我们可以很容易地创建一个<code class="fe mv mw mx lp b">ResidualAdd</code>层</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="lm ln l"/></div></figure><h2 id="b55d" class="lt lu it bd ma nf ng dn me nh ni dp mi ks nj nk mk kw nl nm mm la nn no mo np bi translated">捷径</h2><p id="bf36" class="pw-post-body-paragraph kj kk it kl b km mq ju ko kp mr jx kr ks ms ku kv kw mt ky kz la mu lc ld le im bi translated">有时你的残差没有相同的输出维数，所以我们不能把它们相加。我们可以使用快捷方式中的conv(带+的黑色箭头)来投影输入，以匹配输出的特征</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="lm ln l"/></div></figure><h1 id="c7eb" class="lz lu it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">瓶颈块</h1><p id="a151" class="pw-post-body-paragraph kj kk it kl b km mq ju ko kp mr jx kr ks ms ku kv kw mt ky kz la mu lc ld le im bi translated"><a class="ae lg" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> <em class="lf">中还引入了瓶颈块，用于图像识别的深度残差学习</em> </a>。瓶颈模块接受大小为<code class="fe mv mw mx lp b">BxCxHxW</code>的输入，它首先使用廉价的<code class="fe mv mw mx lp b">1x1 conv</code>将其减少到<code class="fe mv mw mx lp b">BxC/rxHxW</code>，然后应用<code class="fe mv mw mx lp b">3x3 conv</code>，最后再次使用<code class="fe mv mw mx lp b">1x1 conv</code>将输出重新映射到与输入相同的特征维度<code class="fe mv mw mx lp b">BxCxHxW</code>。这比用三个<code class="fe mv mw mx lp b">3x3 convs</code>要快。由于投入首先减少，这就是我们称之为“瓶颈”的原因。下图显示了模块，我们在最初的实现中使用了<code class="fe mv mw mx lp b">r=4</code></p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/7f5ecd7317edf47dda05c68e84f4b4a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*5r-VHLTI6gSQACAQhz_nOA.png"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">作者图片</p></figure><p id="a4b8" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">前两次转换之后是batchnorm和非线性激活，而最后一次非线性是在加法之后应用的。在PyTorch</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="lm ln l"/></div></figure><p id="2276" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">注意，只有当输入和输出特性不同时，我们才应用<code class="fe mv mw mx lp b">shortcut</code>。</p><p id="138e" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">实际上，当我们希望降低空间维度时，在中间卷积中使用<code class="fe mv mw mx lp b">stride=2</code>。</p><h1 id="d0cc" class="lz lu it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">线性瓶颈</h1><p id="5145" class="pw-post-body-paragraph kj kk it kl b km mq ju ko kp mr jx kr ks ms ku kv kw mt ky kz la mu lc ld le im bi translated">在<a class="ae lg" href="https://arxiv.org/abs/1801.04381" rel="noopener ugc nofollow" target="_blank"> MobileNetV2中引入了线性瓶颈:反向残差和线性瓶颈</a>。线性瓶颈块是没有最后激活的瓶颈块。在论文的第3.2节中，他们详细讨论了为什么在输出之前存在非线性会损害性能。简而言之，非线性函数line ReLU会将所有内容&lt;设置为0，从而破坏信息。他们根据经验证明，当输入通道少于输出通道时，情况确实如此。所以，去掉瓶颈中的<code class="fe mv mw mx lp b">nn.ReLU</code>，你就有了。</p><h1 id="9418" class="lz lu it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">反向残差</h1><p id="dc8c" class="pw-post-body-paragraph kj kk it kl b km mq ju ko kp mr jx kr ks ms ku kv kw mt ky kz la mu lc ld le im bi translated">在<a class="ae lg" href="https://arxiv.org/abs/1801.04381" rel="noopener ugc nofollow" target="_blank"> MobileNetV2:反向残差和线性瓶颈</a>中再次引入了反向残差。反向残差块是反向瓶颈层。他们使用第一个conv扩展功能，而不是减少功能。下面的图像应该可以清楚地说明这一点</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/d98392c1b73d04ebf7f32806ac21af8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*hq62bMEMgvBgU_f8cW7jbw.png"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">作者图片</p></figure><p id="45b3" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">所以我们从<code class="fe mv mw mx lp b">BxCxHxW</code>到-&gt;<code class="fe mv mw mx lp b">BxCexHxW</code>-&gt;-&gt;<code class="fe mv mw mx lp b">BxCxHxW</code>，其中<code class="fe mv mw mx lp b">e</code>是<em class="lf">膨胀比</em>并设置为<code class="fe mv mw mx lp b">4</code>。它们不是像正常瓶颈阻塞那样变宽- &gt;变窄- &gt;变宽，而是相反，变窄- &gt;变宽- &gt;变窄。在PyTorch中，这是微不足道的</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="lm ln l"/></div></figure><p id="0e39" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">在<code class="fe mv mw mx lp b">MobileNet</code>中，剩余连接仅在输入和输出特征匹配时应用，不要问我为什么，如果你知道，请评论:)所以你应该这样做</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="lm ln l"/></div></figure><h1 id="e332" class="lz lu it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">MBConv</h1><p id="aa71" class="pw-post-body-paragraph kj kk it kl b km mq ju ko kp mr jx kr ks ms ku kv kw mt ky kz la mu lc ld le im bi translated">所以在MobileNetV2之后，它的构建模块被称为<code class="fe mv mw mx lp b">MBConv</code>。<code class="fe mv mw mx lp b">MBConv</code>是具有深度方向可分离卷积的反向线性瓶颈层。</p><h1 id="2b51" class="lz lu it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">深度方向可分离卷积</h1><p id="b5a8" class="pw-post-body-paragraph kj kk it kl b km mq ju ko kp mr jx kr ks ms ku kv kw mt ky kz la mu lc ld le im bi translated">深度方向可分离卷积采用一种技巧，将一个正常的3×3 conv分成两个卷积，以减少参数的数量。第一种方法将单个3×3滤波器应用于每个输入通道，另一种方法将1×1滤波器应用于所有通道。如果你做你的比赛，这和做一个正常的3x3 conv是一样的，但是你保存参数。</p><p id="d5af" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">这也有点愚蠢，因为在我们现有的硬件上，它比普通的3x3要慢得多。</p><p id="a34e" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">下图展示了这个想法</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/f533f546d6e74e72aac65b840ddcd117.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*3QCAqJBdVVED3MvSX26JtA.png"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">作者图片</p></figure><p id="0683" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">通道中的不同颜色表示每个通道应用一个单独的滤镜</p><p id="dc8f" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">在PyTorch:</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="lm ln l"/></div></figure><p id="4c15" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">第一个卷积通常称为<code class="fe mv mw mx lp b">depth</code>，而第二个卷积称为<code class="fe mv mw mx lp b">point</code>。让我们数一数参数</p><pre class="lh li lj lk gt lo lp lq lr aw ls bi"><span id="6077" class="lt lu it lp b gy lv lw l lx ly">sum(p.numel() for p in DepthWiseSeparableConv(32, 64).parameters() if p.requires_grad) </span></pre><p id="adef" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">出局:<code class="fe mv mw mx lp b">2432</code></p><p id="da7e" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">让我们来看一个普通的Conv2d</p><pre class="lh li lj lk gt lo lp lq lr aw ls bi"><span id="93a6" class="lt lu it lp b gy lv lw l lx ly">sum(p.numel() for p in nn.Conv2d(32, 64, kernel_size=3).parameters() if p.requires_grad)</span></pre><p id="58e1" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">出局:<code class="fe mv mw mx lp b">18496</code></p><p id="7068" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">这是一个很大的区别</p><h1 id="6aaf" class="lz lu it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">获取MBConv</h1><p id="1200" class="pw-post-body-paragraph kj kk it kl b km mq ju ko kp mr jx kr ks ms ku kv kw mt ky kz la mu lc ld le im bi translated">让我们创建一个完整的MBConv。有几个MBConv的重要细节，归一化适用于深度和点卷积，非线性仅适用于深度卷积(记住线性瓶颈)。应用的ReLU6非线性。把所有东西放在一起</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="lm ln l"/></div></figure><p id="9561" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">在<a class="ae lg" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank"> EfficientNet </a>中使用了该模块的稍加修改的版本，带有<a class="ae lg" href="https://arxiv.org/abs/1709.01507" rel="noopener ugc nofollow" target="_blank">挤压和激励</a>。</p><h1 id="94a1" class="lz lu it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">融合反转残差(融合MBConv)</h1><p id="4f57" class="pw-post-body-paragraph kj kk it kl b km mq ju ko kp mr jx kr ks ms ku kv kw mt ky kz la mu lc ld le im bi translated">融合反向残差在<a class="ae lg" href="https://arxiv.org/abs/2104.00298" rel="noopener ugc nofollow" target="_blank"> EfficientNetV2:更小的模型和更快的训练</a>中引入，以使MBConv更快。所以基本上，由于深度方向的回旋很慢，他们将第一个和第二个conv融合成一个3×3的conv(3.2节)。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/82c406fd1e2760842b441a882c7a9e7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*E-nz4PeBIZchsGfPyykz5g.png"/></div><p class="nb nc gj gh gi nd ne bd b be z dk translated">作者图片</p></figure><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="lm ln l"/></div></figure><h1 id="e838" class="lz lu it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">结论</h1><p id="f53e" class="pw-post-body-paragraph kj kk it kl b km mq ju ko kp mr jx kr ks ms ku kv kw mt ky kz la mu lc ld le im bi translated">现在你应该知道所有这些块之间的区别和它们背后的推理了！我强烈推荐阅读与他们相关的论文，你不会错的。</p><p id="942a" class="pw-post-body-paragraph kj kk it kl b km kn ju ko kp kq jx kr ks kt ku kv kw kx ky kz la lb lc ld le im bi translated">关于ResNet更详细的指南，请查看<a class="ae lg" rel="noopener" target="_blank" href="/residual-network-implementing-resnet-a7da63c7b278">剩余网络:在Pytorch中实现ResNet</a></p></div></div>    
</body>
</html>