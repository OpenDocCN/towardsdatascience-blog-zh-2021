<html>
<head>
<title>Overview Of 4 Model Validation Approaches to Mitigate Overfitting Problem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">缓解过拟合问题的4种模型验证方法概述</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/overview-of-4-model-validation-approaches-to-mitigate-overfitting-problem-6d2eecdf8053?source=collection_archive---------24-----------------------#2021-04-23">https://towardsdatascience.com/overview-of-4-model-validation-approaches-to-mitigate-overfitting-problem-6d2eecdf8053?source=collection_archive---------24-----------------------#2021-04-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f043" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">本文是一篇<strong class="ak"> <em class="ki">全面概述</em> </strong>的四(4)个模型验证策略以构建健壮的模型</h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/da251fd8a531ac33376e4df5a8d44968.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZE0WURJsWJ40ckw2.jpg"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">图片由<a class="ae kz" href="https://pixabay.com/users/jackmac34-483877/" rel="noopener ugc nofollow" target="_blank">杰奎琳·马库</a>提供，来自<a class="ae kz" href="https://pixabay.com/photos/tampons-authorization-validation-1143489/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><h1 id="83b8" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">为什么模型验证很重要</h1><p id="307b" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">未经验证而训练的模型可能会过度拟合测试数据。如果我们只处理两组数据，即训练和测试数据，这种情况很可能发生。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi mo"><img src="../Images/7f42425d9cfc15f50d885ffe1433d21d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*njs9HPXEXGAuW6ZjjMhThA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">(图片由作者提供)</p></figure><p id="d573" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">为了减少测试数据的过度拟合，您将需要验证。在本文的其余部分，我们将讨论不同的验证方法，从单一交叉验证(最不健壮)到k重交叉验证的不同变体(更健壮)。</p><h1 id="c9f2" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">单一交叉验证</h1><p id="6432" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">这是您可以执行的最简单的验证方法。它涉及到三组数据的使用:训练数据<strong class="lu iu">、<strong class="lu iu">验证数据</strong>和<strong class="lu iu">测试数据。</strong>典型的划分是80%用于培训，10%用于验证，10%用于测试。</strong></p><p id="21b2" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated"><strong class="lu iu">如果y </strong>你有<strong class="lu iu"> <em class="mu"> N </em> </strong>个候选模型(<strong class="lu iu"> <em class="mu"> N </em> </strong>在下图的例子中是4)，这些模型将使用训练数据进行训练，并使用验证数据进行评估。评估的过程是超参数调整。一旦找到可能的最佳模型，它将在测试数据上运行，以便了解它在现实世界中的表现。总的来说，我们有<strong class="lu iu"> <em class="mu"> N个训练过程</em></strong><strong class="lu iu"><em class="mu">N个验证过程</em></strong><strong class="lu iu"><em class="mu">只有1个测试过程</em> </strong>。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi mv"><img src="../Images/66adc3db3bd30db40a1c25cff3b11ff0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GTj5MaQ0RdmA9h5pWm5XqQ.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">(图片由作者提供)</p></figure><p id="1646" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">这种方法的问题是，在拆分之后，验证集中的数据将永远不会用于训练模型。此外，由于训练和验证分割的随机性，您可能会选择一个恰好给出非常差的结果，或者可能给出很好的结果的分割。我们将看到如何应用更健壮的技术来缓解这些问题。</p><h1 id="e750" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">K重交叉验证的不同变体</h1><p id="02b5" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">对于每个候选模型，这些方法包括使用训练数据的不同子集重复训练和验证。这是一个非常稳健的数据，不会浪费数据，因为每个观察值都用于训练和验证。使用这种方法与<strong class="lu iu"> <em class="mu"> N </em> </strong>候选模型和<em class="mu"> K </em> 折叠，你将运行<strong class="lu iu"> <em class="mu"> NxK训练</em> </strong>和<strong class="lu iu"> <em class="mu"> N个验证过程</em> </strong>，但是<strong class="lu iu"> <em class="mu">只有1个测试过程</em> </strong>。</p><h2 id="fb92" class="mw lb it bd lc mx my dn lg mz na dp lk mb nb nc lm mf nd ne lo mj nf ng lq nh bi translated">遗漏一个交叉验证</h2><p id="0def" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">假设您有一个大小为<strong class="lu iu"> <em class="mu"> N </em> </strong>的训练数据，当使用这种方法时，您首先保持第一个观察值，在剩余的<strong class="lu iu"> <em class="mu"> N-1 </em> </strong>观察值上训练您的模型，并在保持观察值上评估它。然后，维持第二次观察，在<strong class="lu iu"> <em class="mu"> N-1 </em> </strong>剩余观察上训练模型，并在维持(第二次观察)上评估模型。同样的过程也适用于第三次观察，以此类推。在这个过程的最后，你将对每个观测值进行一次精确的测量，并将得到<strong class="lu iu"> <em class="mu"> N </em> </strong>的评估值。最终的评估指标是<strong class="lu iu"> <em class="mu"> N </em> </strong>值的平均值。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi ni"><img src="../Images/493a036baa37bef38669904430dc7ecf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gaU2Ei275QbH3rKKAQBaiQ.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">(图片由作者提供)</p></figure><p id="cb31" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">这种技术的好处是，它确保每一个观察结果都用于培训和评估。然而，这可能非常耗时且计算量大，因为只有一个模型被训练<strong class="lu iu"> <em class="mu"> N </em> </strong>次。此外，如果您有<strong class="lu iu"> <em class="mu"> M </em> </strong>个候选模型，则每个模型都将在所有这些分割上进行训练和验证，这将增加很多计算时间。</p><h2 id="b4fd" class="mw lb it bd lc mx my dn lg mz na dp lk mb nb nc lm mf nd ne lo mj nf ng lq nh bi translated">k重交叉验证</h2><p id="4794" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">这种方法类似于省去一个交叉验证，但是在模型性能方面，极大地改进了计算时间，而没有损失太多。它不是一次只保留一个观察值，而是将训练数据拆分成相等数量的数据(称为折叠)。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nj"><img src="../Images/7b585b1736689aa9361ec0dbefe5196e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NeoZSZfbH99MiG5TG6CsYg.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">(图片由作者提供)</p></figure><p id="2673" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">训练数据被分成5个相同大小的不同数据，在本例中，我们执行5重交叉验证。在每次迭代中，模型在4/5的数据上进行训练，在剩下的1/5的数据上进行验证</p><ul class=""><li id="b803" class="nk nl it lu b lv mp ly mq mb nm mf nn mj no mn np nq nr ns bi translated">从分割1开始，折叠1至4用于训练模型，折叠5用于验证模型。</li><li id="4b3c" class="nk nl it lu b lv nt ly nu mb nv mf nw mj nx mn np nq nr ns bi translated">从分割2开始，折叠1至3和5用于训练模型，折叠4用于验证模型。</li><li id="edfd" class="nk nl it lu b lv nt ly nu mb nv mf nw mj nx mn np nq nr ns bi translated">执行相同的过程直到分割5，并且这适用于所有模型。</li></ul><p id="2c81" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">数据中的每个观察值用于验证一次，单个模型的整体性能通过平均所有分割的所有性能获得。在所有模型的训练结束时，最好的模型是具有最高性能值(最低误差值)的模型。然后对测试数据运行最佳模型，以获得对未知数据的性能评估。</p><p id="7c82" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">K-folds改进了留一交叉验证，但是在将训练数据分成不同的folds时，它们都没有考虑到类/标签，这可能是一个缺点，因为一些标签可能在一些folds中不被表示。</p><h2 id="f17d" class="mw lb it bd lc mx my dn lg mz na dp lk mb nb nc lm mf nd ne lo mj nf ng lq nh bi translated">分层K重交叉验证</h2><p id="988e" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">这种方法在分割成折叠时考虑训练数据的标签/类别，并确保每个折叠具有不同类别的表示。假设原始数据被分类为“疟疾”和“疟疾”，每个文件夹将具有整个数据中存在的“疟疾”或“非疟疾”的近似代表性混合。</p><p id="2c29" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">假设训练数据有100个观测值，80个“疟疾”，20个“非疟疾”。如果您决定应用10倍验证，每个折叠将有大约8个“疟疾”和2个“非疟疾”</p><h1 id="4109" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">文章结尾</h1><p id="3c70" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">我希望您喜欢这篇文章。如果您有任何问题或意见，我将很高兴欢迎他们进行进一步的讨论。如需进一步阅读，请随时查阅以下链接:</p><p id="e1a5" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated"><a class="ae kz" href="https://scikit-learn.org/stable/modules/cross_validation.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/cross _ validation . html</a></p><p id="12ba" class="pw-post-body-paragraph ls lt it lu b lv mp ju lx ly mq jx ma mb mr md me mf ms mh mi mj mt ml mm mn im bi translated">再见🏃🏾</p></div></div>    
</body>
</html>