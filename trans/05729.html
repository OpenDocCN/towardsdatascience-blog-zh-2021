<html>
<head>
<title>Neural Networks for Real-Time Audio: Stateful LSTM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于实时音频的神经网络:状态LSTM</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-networks-for-real-time-audio-stateful-lstm-b534babeae5d?source=collection_archive---------11-----------------------#2021-05-22">https://towardsdatascience.com/neural-networks-for-real-time-audio-stateful-lstm-b534babeae5d?source=collection_archive---------11-----------------------#2021-05-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/bc96cb7fbaad04cf422664e655fbdaee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4-CIGWNOpBxPBBdrrdzZsQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><div class=""/><div class=""><h2 id="58bd" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">这是关于使用神经网络进行实时音频的五部分系列的第四部分。上一篇关于无状态LSTMs的文章，点击 <a class="ae kv" rel="noopener" target="_blank" href="/neural-networks-for-real-time-audio-stateless-lstm-97ecd1e590b8"> <em class="ku">这里</em> </a> <em class="ku">。</em></h2></div><p id="a5a2" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将为最后一个神经网络模型重新访问LSTM。这次我们将使用<em class="ls">状态</em>版本，并利用其循环内部状态来模拟Blackstar HT40吉他放大器。</p><p id="22f9" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">快速复习；LSTMs(长短期记忆)是一种递归神经网络，通常用于文本到语音或自然语言处理等任务。它们有一个循环状态，每次通过网络输入新数据时都会更新。这样，LSTM就有了记忆。在本文中，我们将使用论文“<em class="ls">具有深度学习的实时吉他放大器仿真</em>”中提出的LSTM模型。</p><h1 id="c3c4" class="lt lu jf bd lv lw lx ly lz ma mb mc md kl me km mf ko mg kp mh kr mi ks mj mk bi translated">概观</h1><p id="7f55" class="pw-post-body-paragraph kw kx jf ky b kz ml kg lb lc mm kj le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">使用有状态LSTM允许我们简化前一篇文章中的整个网络结构。我们不会使用两个一维卷积层或数据预处理。这里我们需要的是LSTM层，然后是致密层。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mq"><img src="../Images/906684194c60665a45f63e1fb55901de.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*5lwN2HUCUNzBtZtE9PzsUw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图1:一般网络架构(图片由作者提供)</p></figure><p id="e0e5" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">单个音频样本被馈送到网络，并且单个样本被预测。由于关于过去信号的必要信息存储在LSTM循环状态中，因此不需要样本范围。</p><p id="6905" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">需要注意的是，会执行一个跳过连接，其中输入样本值会添加到输出值中。这样，网络只需学习输出和输入之间的差异。这种技术在amp仿真论文中有定义。</p><h1 id="4717" class="lt lu jf bd lv lw lx ly lz ma mb mc md kl me km mf ko mg kp mh kr mi ks mj mk bi translated">PyTorch培训</h1><p id="99fc" class="pw-post-body-paragraph kw kx jf ky b kz ml kg lb lc mm kj le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">PyTorch培训的示例代码来自Github上的<a class="ae kv" href="https://github.com/Alec-Wright/Automated-GuitarAmpModelling" rel="noopener ugc nofollow" target="_blank">自动吉他建模</a>项目。这个项目不包含许可证文件(在撰写本文时)，所以我不会在这里显示代码，但是您可以在Github上查看完整的Python代码。我使用了在<a class="ae kv" href="https://github.com/Alec-Wright/CoreAudioML/blob/823a4727f4578aa434e715eae302e0e930576074/networks.py" rel="noopener ugc nofollow" target="_blank"> networks.py </a>文件中定义的“SimpleRNN”模型。这包括在amp仿真白皮书中描述的LSTM网络的实施。</p><p id="6c61" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在之前的文章中，我们在25%的增益下使用了Blackstar HT40放大器的过驱通道。有状态LSTM的初始测试进行得非常顺利，所以我决定将增益提高到100%，看看网络能处理多少。我用我的Fender Telecaster和HT40做了一个新的记录。HT40再次采用舒尔SM57动圈话筒。</p><p id="6a67" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我使用了Focusrite Scarlett 2i2音频接口和运行在Windows 10上的Reaper DAW(数字音频工作站)。录音设置使用吉他的信号分离器，一个信号进入音频接口的通道1，麦克风输出进入通道2。这样，两个轨道可以同时记录，两个信号之间的延迟最小。LSTM模型对两个信号之间的任何时移都非常敏感。</p><p id="91de" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我把录音笔记本电脑和音频接口从扩音器上移开，以减少电子干扰产生的噪音。下图左侧的踏板仅用于信号分离踏板。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/8e74777543a80f9d3a7175c3d338784e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HLC1g_gZRDLiqOYrId6cLQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">录制设置(图片由作者提供)</p></figure><p id="7faa" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">放大器周围的区域被噪声抑制器(我只是用毯子)包围，以减少录音时的回声。尽可能消除房间混响以提高训练的准确性是很重要的。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/1d17abf5485741de2541b32478a49bad.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*u8cobgBf1Bm1fWWk7nFfgw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">麦克风黑星HT40放大器(图片由作者提供)</p></figure><p id="7291" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">培训是通过在<a class="ae kv" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>上运行PyTorch代码完成的，这是一个基于浏览器的选项，用于在云中运行python代码。该网站甚至允许您免费访问GPU和TPU，但有一些限制。使用GPU运行时，我能够在大约40分钟内训练HT40模型。</p><p id="776b" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于网络大小，amp仿真纸测试了LSTM隐藏大小值32、64和96。网络越大，它能够学习的信号就越复杂，但这是以处理速度为代价的。我发现20的隐藏大小完全能够再现我录制的声音，同时提高实时性能。</p><p id="4139" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">HT40放大器在100%增益时的损耗值为0.069。训练代码使用一种称为“自适应学习率”的技术，这种技术可以在整个训练过程中降低训练的积极性。您可以将此视为随着模型越来越接近目标而对其进行微调。</p><p id="1d92" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下是我的Fender Telecaster的输入录音示例:</p><figure class="mr ms mt mu gt is"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="6366" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是Blackstar HT40在100%增益下的样本:</p><figure class="mr ms mt mu gt is"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="0207" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是PyTorch对同一样本的预测:</p><figure class="mr ms mt mu gt is"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="57d8" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们比较实际信号和预测信号，我们可以看到音频的幅度和特征非常接近。下面的图是使用Matplotlib绘制的，Matplotlib是一个用python创建图表的库。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mz"><img src="../Images/d5629f4737811a400fb646dd296c54b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v4Qu_ZHu1HfvbQr38n-84Q.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图2:100%增益(损耗0.069)下HT40放大器的实际信号与预测信号</p></figure><h1 id="414f" class="lt lu jf bd lv lw lx ly lz ma mb mc md kl me km mf ko mg kp mh kr mi ks mj mk bi translated">模型转换</h1><p id="d9bc" class="pw-post-body-paragraph kw kx jf ky b kz ml kg lb lc mm kj le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在实时使用经过训练的模型之前，该模型必须被转换成用于加载到插件中的格式。<a class="ae kv" href="https://github.com/Alec-Wright/Automated-GuitarAmpModelling" rel="noopener ugc nofollow" target="_blank">Automated-guitar amp modeling</a>项目自动将模型状态数据导出到一个json文件中。json文件包含有关图层的信息，如LSTM隐藏单元的数量和输入/输出大小。大部分数据来自LSTM层和密集层的训练权重和偏差。权重和偏差是将被实时代码使用的值的数组。</p><h1 id="5113" class="lt lu jf bd lv lw lx ly lz ma mb mc md kl me km mf ko mg kp mh kr mi ks mj mk bi translated">实时实现</h1><p id="cae3" class="pw-post-body-paragraph kw kx jf ky b kz ml kg lb lc mm kj le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">下面给出了使用<a class="ae kv" href="https://github.com/dpilger26/NumCpp" rel="noopener ugc nofollow" target="_blank"> Numcpp </a>进行矩阵计算的实时实现的示例代码。使用<a class="ae kv" href="https://juce.com/" rel="noopener ugc nofollow" target="_blank"> JUCE框架</a>的完整插件实现还没有发布，但是我会在这篇文章公开后更新它。</p><p id="355c" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是LSTM/致密层推断的主要处理方法。对于缓冲器中的每个音频样本，<code class="fe na nb nc nd b">lstm_layer()</code>和<code class="fe na nb nc nd b">dense_layer()</code>被处理。对于跳过连接，输入样本被添加回网络的输出中。</p><figure class="mr ms mt mu gt is"><div class="bz fp l di"><div class="ne my l"/></div></figure><p id="d7f2" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是LSTM层，由amp仿真论文提出的算法实现。“c_t”和“h_t”(单元格和隐藏状态)是基于LSTM层隐藏大小“HS”为每个索引计算的。基于对准确性和实时性能的测试，我使用了20的隐藏大小。</p><figure class="mr ms mt mu gt is"><div class="bz fp l di"><div class="ne my l"/></div></figure><p id="acf4" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">密集层将LSTM输出减少到一个音频样本。密集图层只是LSTM输出和训练密集图层权重加上偏差值的点积。</p><figure class="mr ms mt mu gt is"><div class="bz fp l di"><div class="ne my l"/></div></figure><p id="1d5b" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些计算在音频中每秒重复44100次。其他数码效果可以添加在LSTM模型之前或之后，如均衡或混响。多个模型可用于覆盖特定设置的范围，如<em class="ls">增益</em>。在amp仿真论文中，他们使用参数调节对多个音频样本训练单个模型，每个样本具有不同的增益设置。然后，该模型可以覆盖给定旋钮设置的整个参数空间。</p><p id="504e" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">注:音频中除了44.1kHz以外的其他采样率也很常见，比如48kHz甚至96kHz。网络将以更高的采样率运行，但需要更多的测试来确定这对音频的影响。可能是因为训练数据是44.1kHz，这是唯一可以准确预测的速率。采样速率转换器可能是解决不同输入采样速率的解决方案。</em></p><p id="1383" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">amp仿真论文提到，未来的工作可能包括实现<em class="ls">抗锯齿</em>以进一步改善仿真声音。在录制的音频中会出现混叠现象，非线性函数产生的高次谐波会反射回较低的频率，在音频中产生不希望的失真。关于反走样技术的详细解释，请查看<a class="ae kv" href="https://jatinchowdhury18.medium.com/practical-considerations-for-antiderivative-anti-aliasing-d5847167f510" rel="noopener">这篇文章</a>。</p><h1 id="55f2" class="lt lu jf bd lv lw lx ly lz ma mb mc md kl me km mf ko mg kp mh kr mi ks mj mk bi translated">表演</h1><p id="a0e2" class="pw-post-body-paragraph kw kx jf ky b kz ml kg lb lc mm kj le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在三种不同的神经网络模型中，我发现有状态LSTM在以实时速度再现一系列吉他放大器和踏板方面是最成功的。它能够处理高增益，如这里使用的HT40，和干净的声音。适中的训练时间胜过了WaveNet模型，代码的简单性使其优于前一篇文章中的conv1d层+无状态LSTM。</p><p id="bc7e" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">注:amp仿真论文定义了另一个RNN模型，GRU(门控循环单元)。这包含在</em><a class="ae kv" href="https://github.com/Alec-Wright/Automated-GuitarAmpModelling" rel="noopener ugc nofollow" target="_blank"><em class="ls">Automated-guitar amp modeling</em></a><em class="ls">代码中，与LSTM的预成型类似。该论文指出，GRU运行速度稍快，但可能无法像LSTM一样处理各种声音。</em></p><p id="70e4" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是一个用JUCE框架构建的插件的视频演示，该插件在几个经过训练的模型上运行有状态LSTM推理:</p><figure class="mr ms mt mu gt is"><div class="bz fp l di"><div class="nf my l"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者提供的视频</p></figure><p id="790e" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们现在已经介绍了三种不同的神经网络架构，以及它们在c++中使用JUCE框架的实时实现。</p><p id="ee7c" class="pw-post-body-paragraph kw kx jf ky b kz la kg lb lc ld kj le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢您的阅读！在最后一篇文章中，我们将<strong class="ky jg">使用有状态LSTM模型和<a class="ae kv" href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/" rel="noopener ugc nofollow" target="_blank"> <strong class="ky jg">树莓派</strong> </a>构建一个吉他踏板</strong>。</p><div class="ip iq gp gr ir ng"><a href="https://link.medium.com/m1n9gMXd9gb" rel="noopener follow" target="_blank"><div class="nh ab fo"><div class="ni ab nj cl cj nk"><h2 class="bd jg gy z fp nl fr fs nm fu fw je bi translated">实时音频的神经网络:树莓皮吉他踏板</h2><div class="nn l"><h3 class="bd b gy z fp nl fr fs nm fu fw dk translated">这是关于使用神经网络进行实时音频的五部分系列的最后一部分。对于上一篇关于有状态的文章…</h3></div><div class="no l"><p class="bd b dl z fp nl fr fs nm fu fw dk translated">link.medium.com</p></div></div><div class="np l"><div class="nq l nr ns nt np nu ix ng"/></div></div></a></div><ol class=""><li id="73ca" class="nv nw jf ky b kz la lc ld lf nx lj ny ln nz lr oa ob oc od bi translated">Alec Wright等人《深度学习的实时吉他放大器仿真》<em class="ls">应用科学</em> 10，第3期(2020): 766。</li></ol></div></div>    
</body>
</html>