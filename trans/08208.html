<html>
<head>
<title>Supervised vs Unsupervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">监督与非监督学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/supervised-vs-unsupervised-learning-bf2eab13f288?source=collection_archive---------5-----------------------#2021-07-28">https://towardsdatascience.com/supervised-vs-unsupervised-learning-bf2eab13f288?source=collection_archive---------5-----------------------#2021-07-28</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="bc24" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">讨论机器学习中<strong class="ak">监督学习、</strong>无监督学习和半监督学习的主要区别</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/aa01f3d6150b5e60472b97b2fe00e136.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8irf8y-s_TmtuoxyTIPWrA.jpeg"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">由<a class="ae kz" href="https://unsplash.com/@skraidantisdrambliukas?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Gert RDA valasevi it</a>在<a class="ae kz" href="https://unsplash.com/s/photos/artificial-intelligence?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="9209" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated"><strong class="ak">简介</strong></h2><p id="4654" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">在机器学习领域，有两种基本的学习类型，即<strong class="ly iv">监督的</strong>和<strong class="ly iv">非监督的</strong>方法。现在，根据我们想要解决的问题、我们需要回答的问题以及我们可以访问的数据，我们需要选择合适的<em class="mp">学习</em>算法。</p><p id="9311" class="pw-post-body-paragraph lw lx iu ly b lz mq jv mb mc mr jy me lj ms mg mh ln mt mj mk lr mu mm mn mo in bi translated">因此，整个学习过程依赖于对上述问题的回答。鉴于这些答案可能会有所不同，在选择特定的学习算法之前，我们首先需要明确什么样的学习类型适合我们试图解决的问题的性质。</p></div><div class="ab cl mv mw hy mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="in io ip iq ir"><h2 id="16fb" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">监督学习</h2><p id="52d8" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">在监督学习中，感兴趣的数据集包含解释变量(也称为<strong class="ly iv">输入</strong>或<strong class="ly iv">特征</strong>)以及目标响应(也称为<strong class="ly iv">输出</strong> <strong class="ly iv">标签</strong>)。这种算法试图学习一个函数，该函数以某种方式近似特征值和标签之间的关系，它能够很好地将<strong class="ly iv">推广到</strong>新的看不见的数据。</p><p id="4abd" class="pw-post-body-paragraph lw lx iu ly b lz mq jv mb mc mr jy me lj ms mg mh ln mt mj mk lr mu mm mn mo in bi translated">换句话说，监督学习算法将训练样本的输入特征与相应的输出标签相关联，以便它们能够对所有可能的输入执行足够好的<strong class="ly iv">预测</strong>。这种学习方法也被称为<strong class="ly iv">从范例中学习</strong>。</p><p id="19f7" class="pw-post-body-paragraph lw lx iu ly b lz mq jv mb mc mr jy me lj ms mg mh ln mt mj mk lr mu mm mn mo in bi translated">需要监督学习方法的问题可以进一步分组为<strong class="ly iv"> <em class="mp">分类</em> </strong>和<strong class="ly iv"> <em class="mp">回归</em> </strong>问题。前者是输出变量(标签)对应一个类别时；例如垃圾邮件与业余电子邮件，而后者是当输出变量是一个真实值时；例如距离或价格。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nc"><img src="../Images/9cfaba8af6fce6b907cf864a7a640a2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GuTebs5FGn_UmtbvH1H3sg.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">监督学习-来源:<a class="ae kz" href="https://medium.com/@gmyrianthous" rel="noopener">作者</a></p></figure><p id="8260" class="pw-post-body-paragraph lw lx iu ly b lz mq jv mb mc mr jy me lj ms mg mh ln mt mj mk lr mu mm mn mo in bi translated">监督学习算法的一些例子包括<em class="mp">线性回归、随机森林、决策树和支持向量机。</em></p></div><div class="ab cl mv mw hy mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="in io ip iq ir"><h2 id="3d16" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">无监督学习</h2><p id="642b" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">另一方面，无监督学习适用于需要算法来识别和提取输入之间的相似性的问题，以便可以将相似的输入分类到一起。与监督学习相反，当<strong class="ly iv">输出变量</strong>(即<strong class="ly iv">标签</strong>)是<strong class="ly iv">而不是</strong> <strong class="ly iv">时，非监督学习方法是合适的，前提是</strong>。</p><p id="7702" class="pw-post-body-paragraph lw lx iu ly b lz mq jv mb mc mr jy me lj ms mg mh ln mt mj mk lr mu mm mn mo in bi translated">无监督学习方法的两种基本类型是<strong class="ly iv">聚类</strong>和<strong class="ly iv">密度估计</strong>。前者(可能是最常用的)涉及需要将数据分组到特定类别(称为集群)的问题，而后者涉及汇总数据的分布。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nc"><img src="../Images/b9d598f24b2195cacadd9af16105a525.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eMukSDUWbbfFeMgqlTR39g.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">无监督学习—来源:<a class="ae kz" href="https://gmyrianthous.medium.com/" rel="noopener">作者</a></p></figure><p id="c1e5" class="pw-post-body-paragraph lw lx iu ly b lz mq jv mb mc mr jy me lj ms mg mh ln mt mj mk lr mu mm mn mo in bi translated">无监督学习算法的一些例子包括K-均值聚类、主成分分析和分层聚类。</p></div><div class="ab cl mv mw hy mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="in io ip iq ir"><h2 id="13b3" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">半监督学习</h2><p id="f204" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">现在还有另一种称为<strong class="ly iv">半监督</strong>的学习类型，当我们<strong class="ly iv">没有训练数据集</strong>中所有例子的目标标签时，它就派上了用场。因此，这类问题需要监督和非监督学习技术的混合。</p><p id="1b74" class="pw-post-body-paragraph lw lx iu ly b lz mq jv mb mc mr jy me lj ms mg mh ln mt mj mk lr mu mm mn mo in bi translated">需要这种方法的一个非常常见的问题是图像分类或对象检测。通常，包含图像的数据集可能仅具有所包括的示例子集的标签，而其余的则根本没有标签。</p></div><div class="ab cl mv mw hy mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="in io ip iq ir"><h2 id="deb2" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">最后的想法</h2><p id="8a45" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">在今天的文章中，我们讨论了两种基本的机器学习方法之间的主要区别，即监督学习和非监督学习。</p><p id="b658" class="pw-post-body-paragraph lw lx iu ly b lz mq jv mb mc mr jy me lj ms mg mh ln mt mj mk lr mu mm mn mo in bi translated">总之，当可用的数据集包含每个示例的特征和正确标签时，监督学习方法是有用的。当我们想要对感兴趣的数据进行某种预测时，例如对一封电子邮件是否是垃圾邮件进行分类，这样的方法非常有用。另一方面，当我们无法访问输出标签并且需要将数据分类(或聚类)到组中时，无监督学习方法就派上了用场。</p><p id="fee0" class="pw-post-body-paragraph lw lx iu ly b lz mq jv mb mc mr jy me lj ms mg mh ln mt mj mk lr mu mm mn mo in bi translated">同样重要的是要提到，在机器学习的背景下，这些并不是唯一的学习方法。其他一些类型包括强化学习和进化学习，这些都超出了本文的范围。</p></div><div class="ab cl mv mw hy mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="in io ip iq ir"><div class="kk kl km kn gu nd"><a rel="noopener follow" target="_blank" href="/feature-scaling-and-normalisation-in-a-nutshell-5319af86f89b"><div class="ne ab fp"><div class="nf ab ng cl cj nh"><h2 class="bd iv gz z fq ni fs ft nj fv fx it bi translated">简而言之，特征缩放和标准化</h2><div class="nk l"><h3 class="bd b gz z fq ni fs ft nj fv fx dk translated">为什么、如何以及何时调整要素的比例</h3></div><div class="nl l"><p class="bd b dl z fq ni fs ft nj fv fx dk translated">towardsdatascience.com</p></div></div><div class="nm l"><div class="nn l no np nq nm nr kt nd"/></div></div></a></div><div class="ns nt gq gs nu nd"><a rel="noopener follow" target="_blank" href="/fit-vs-predict-vs-fit-predict-in-python-scikit-learn-f15a34a8d39f"><div class="ne ab fp"><div class="nf ab ng cl cj nh"><h2 class="bd iv gz z fq ni fs ft nj fv fx it bi translated">Python scikit中的fit()vs predict()vs fit _ predict()-learn</h2><div class="nk l"><h3 class="bd b gz z fq ni fs ft nj fv fx dk translated">sklearn中的fit，predict和fit_predict方法有什么区别</h3></div><div class="nl l"><p class="bd b dl z fq ni fs ft nj fv fx dk translated">towardsdatascience.com</p></div></div><div class="nm l"><div class="nv l no np nq nm nr kt nd"/></div></div></a></div><div class="ns nt gq gs nu nd"><a href="https://medium.com/geekculture/fit-vs-transform-vs-fit-transform-in-python-scikit-learn-2623d5a691e3" rel="noopener follow" target="_blank"><div class="ne ab fp"><div class="nf ab ng cl cj nh"><h2 class="bd iv gz z fq ni fs ft nj fv fx it bi translated">Python scikit中的fit()vs transform()vs fit _ transform()，了解</h2><div class="nk l"><h3 class="bd b gz z fq ni fs ft nj fv fx dk translated">sklearn中的fit，transform和fit_transform方法有什么区别</h3></div><div class="nl l"><p class="bd b dl z fq ni fs ft nj fv fx dk translated">medium.com</p></div></div><div class="nm l"><div class="nw l no np nq nm nr kt nd"/></div></div></a></div></div></div>    
</body>
</html>