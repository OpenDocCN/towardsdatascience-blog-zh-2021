<html>
<head>
<title>PyTorch Ignite Tutorial— Classifying Tiny ImageNet with EfficientNet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch Ignite教程—使用高效网络对微型图像网络进行分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pytorch-ignite-classifying-tiny-imagenet-with-efficientnet-e5b1768e5e8f?source=collection_archive---------6-----------------------#2021-08-22">https://towardsdatascience.com/pytorch-ignite-classifying-tiny-imagenet-with-efficientnet-e5b1768e5e8f?source=collection_archive---------6-----------------------#2021-08-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="d826" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="b2fe" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">使用PyTorch <strong class="ak"> Ignite </strong>简化您的PyTorch深度学习实施的分步指南</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/e6e9b87214a58e55c89b1746d6b74c22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NV-eQixykg6akrET"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@olgabast?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Olga Bast </a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="2d76" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"> PyTorch </strong>是一个强大的深度学习框架，已经被科技巨头采用，如<a class="ae lh" href="https://analyticsindiamag.com/tesla-pytorch-self-driving-computer-vision-karpathy-elon-musk-ai/" rel="noopener ugc nofollow" target="_blank">特斯拉</a>、<a class="ae lh" href="https://openai.com/blog/openai-pytorch/" rel="noopener ugc nofollow" target="_blank"> OpenAI </a>和<a class="ae lh" href="https://visualstudiomagazine.com/articles/2021/06/03/pytorch-enterprise.aspx" rel="noopener ugc nofollow" target="_blank">微软</a>用于关键的研究和生产工作负载。</p><p id="fe39" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">它的开源特性意味着PyTorch的功能也可以被公众所利用。</p><p id="5813" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">深度学习实现的一个问题是，代码可能会快速增长，变得重复和过于冗长。这引发了<a class="ae lh" href="https://en.wikipedia.org/wiki/High-_and_low-level" rel="noopener ugc nofollow" target="_blank">高级</a>库的创建，以简化这些PyTorch代码，其中之一就是<a class="ae lh" href="https://pytorch.org/ignite" rel="noopener ugc nofollow" target="_blank"> PyTorch Ignite </a>。</p><p id="f6cd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">本文就如何使用<strong class="lk jd"> PyTorch Ignite </strong>来简化PyTorch中深度学习模型的开发提供了一个解释清楚的演练。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="2187" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">内容</h2><blockquote class="nd ne nf"><p id="51d3" class="li lj ng lk b ll lm kd ln lo lp kg lq nh ls lt lu ni lw lx ly nj ma mb mc md im bi translated"><strong class="lk jd"><em class="it">(1)</em></strong><a class="ae lh" href="#9c28" rel="noopener ugc nofollow"><em class="it">关于PyTorch点燃</em></a><em class="it"><br/></em><strong class="lk jd"><em class="it">(2)</em></strong><a class="ae lh" href="#4195" rel="noopener ugc nofollow"><em class="it">分步实施</em></a><em class="it"><br/></em><strong class="lk jd"><em class="it">(3)</em></strong><a class="ae lh" href="#312b" rel="noopener ugc nofollow"><em class="it">把东西包起来</em> </a></p></blockquote></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="9c28" class="nk mm it bd mn nl nm nn mq no np nq mt ki nr kj mw kl ns km mz ko nt kp nc nu bi translated">关于PyTorch Ignite</h1><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nv"><img src="../Images/ee7b2ef71447c326e73d742ceee5246b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vn1tTF_Lh_4LUwpHX-33tw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">在<a class="ae lh" href="https://github.com/pytorch/ignite/blob/master/LICENSE" rel="noopener ugc nofollow" target="_blank"> BSD 3条款许可</a>下使用的图像</p></figure><p id="9b68" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">PyTorch Ignite 是一个高级库，可以灵活透明地帮助训练和评估PyTorch中的神经网络。</p><p id="af59" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">它减少了构建深度学习模型所需的代码量，同时保持了简单性和最大程度的控制。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nw"><img src="../Images/8a073756cf5fd837d5665815627c5512.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HkqFbtgRfIS-Idut.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><strong class="bd nx"> PyTorch </strong> <strong class="bd nx">点燃</strong>代码(<strong class="bd nx">左</strong> ) vs纯PyTorch代码(<strong class="bd nx">右</strong> ) |图片在<a class="ae lh" href="https://github.com/pytorch/ignite/blob/master/LICENSE" rel="noopener ugc nofollow" target="_blank"> BSD三条款许可下使用</a></p></figure><p id="2630" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">上图展示了PyTorch Ignite将纯PyTorch代码压缩到更简洁的程度。</p><p id="c86f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">除了消除低级代码，PyTorch Ignite还提供了对度量评估、实验管理和模型调试的实用支持。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="4195" class="nk mm it bd mn nl nm nn mq no np nq mt ki nr kj mw kl ns km mz ko nt kp nc nu bi translated">逐步实施</h1><p id="3b5d" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">本教程的演示任务是在<strong class="lk jd"> Tiny ImageNet </strong>数据集上建立一个图像分类深度学习模型。</p><p id="7636" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">Tiny ImageNet是著名的<a class="ae lh" href="https://image-net.org/challenges/LSVRC" rel="noopener ugc nofollow" target="_blank"> ImageNet大规模视觉识别挑战赛</a> (ILSVRC)中ImageNet数据集的子集。</p><p id="576a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">数据集包含100，000张缩小到64×64彩色图像的<strong class="lk jd"> 200类</strong>(每类500张)图像。每个类有500幅训练图像、50幅验证图像和50幅测试图像。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi od"><img src="../Images/9ddcb4e85bfb10e458d84189166fc262.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aUUdX780G2k5fAyoMVRUKQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">来自微型ImageNet数据集的样本图像|作者提供的图像</p></figure><p id="f666" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们详细介绍使用PyTorch和Ignite尽可能准确地对这些图像进行分类的步骤。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="9c25" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">步骤1 —初始设置</h2><p id="68fa" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">我们将使用<a class="ae lh" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>，因为它提供对GPU的免费访问，我们可以随时使用。请随时跟随本<a class="ae lh" href="https://colab.research.google.com/drive/15eS8Evij9iYBcj-OrOfg7c2iRA56FTZZ?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">完成演示的Colab笔记本</strong> </a> <strong class="lk jd">。</strong></p><p id="0729" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">确保您已经将Colab运行时设置为<strong class="lk jd"> GPU </strong>。完成后，执行以下步骤作为初始设置的一部分:</p><ol class=""><li id="07f4" class="oe of it lk b ll lm lo lp lr og lv oh lz oi md oj ok ol om bi translated"><strong class="lk jd">安装</strong>和<strong class="lk jd">导入</strong>必要的Python库</li></ol><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="c7ca" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">2.<strong class="lk jd">定义</strong> GPU对PyTorch的支持(即使用<a class="ae lh" href="https://blogs.nvidia.com/blog/2012/09/10/what-is-cuda-2/" rel="noopener ugc nofollow" target="_blank"> CUDA </a>)。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="d3c7" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">步骤2 —下载微型ImageNet数据集</h2><p id="06cb" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">有两种方法下载微型ImageNet数据集，即:</p><ul class=""><li id="1a5a" class="oe of it lk b ll lm lo lp lr og lv oh lz oi md op ok ol om bi translated">用<a class="ae lh" href="https://pypi.org/project/opendatasets/" rel="noopener ugc nofollow" target="_blank"><em class="ng">open datasets</em></a><em class="ng"/>库直接从Kaggle下载</li><li id="ea5a" class="oe of it lk b ll oq lo or lr os lv ot lz ou md op ok ol om bi translated">使用GNU <a class="ae lh" href="https://www.gnu.org/software/wget/" rel="noopener ugc nofollow" target="_blank"> <em class="ng"> wget </em> </a>包从斯坦福官方网站下载</li></ul><p id="fd61" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于这个项目，我使用<em class="ng"> wget </em>来检索原始数据集(在一个zip文件中)。下载后，我们可以解压缩zip文件，并为提取的图像设置各自的文件夹路径。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="afab" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果操作正确，您应该会看到文件夹出现在Colab侧边栏上:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ov"><img src="../Images/3e7c8e8b8abe5d64fe16d7360c30ab9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ckWn4JtTd6kGw5k5d44tLQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="7fca" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">步骤3 —设置助手功能</h2><p id="1beb" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">我们定义辅助函数是为了让我们以后的生活更轻松。创建了两组功能，它们是:</p><ul class=""><li id="7de8" class="oe of it lk b ll lm lo lp lr og lv oh lz oi md op ok ol om bi translated"><strong class="lk jd">显示单个或一批样本图像</strong></li></ul><p id="5434" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这使我们能够可视化我们正在处理的图像的随机子集。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure><ul class=""><li id="4eaa" class="oe of it lk b ll lm lo lp lr og lv oh lz oi md op ok ol om bi translated"><strong class="lk jd">为图像数据集创建数据加载器</strong></li></ul><p id="e410" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">数据加载器的工作是从数据集生成小批量数据，让我们可以灵活地选择不同的采样策略和批量大小。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="2936" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在上面的代码中，我们使用了来自<em class="ng"> torchvision.datasets </em>的<code class="fe ow ox oy oz b">ImageFolder</code>函数来生成数据集。为了使<code class="fe ow ox oy oz b">ImageFolder</code>工作，训练和验证文件夹中的图像必须按照以下结构排列:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pa"><img src="../Images/30b45339cf5c4326484ab0f4a9c61759.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PDEjJ51ugPf29X3kw8XXFQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图像数据的预期文件夹结构:<em class="pb">根/标签/文件名</em> |作者图像</p></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="8a48" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">步骤4-组织验证数据文件夹</h2><p id="e6e1" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">您会注意到培训文件夹符合<strong class="lk jd">步骤3 </strong>中<code class="fe ow ox oy oz b">ImageLoader</code>所需的结构，但是<strong class="lk jd">验证文件夹不符合。</strong></p><p id="701b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">验证文件夹中的图像都保存在一个文件夹中，因此我们需要根据它们的标签将它们重新组织到子文件夹中。</p><p id="8d80" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">验证文件夹包含一个<strong class="lk jd"><em class="ng">val _ annotations . txt</em></strong>文件，该文件由六个制表符分隔的列组成:文件名、类标签和边界框的细节(x，y坐标、高度、宽度)。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pc"><img src="../Images/9c2f13d79bf4fb0a29066173a7ccae23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OhbJEgbizRCU0Em0X03eeA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">val_annotations.txt文件中的数据|作者图片</p></figure><p id="28c7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们提取前两列，将成对的文件名和相应的类标签保存在字典中。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pc"><img src="../Images/3f65601cfc77f78bf12ea0bf7b0fb308.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-mYotc8XkXWNqXr0jYN03g.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">每个验证图像的相应标签|按作者分类的图像</p></figure><p id="a14f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">要了解每个类标签的含义，可以阅读<em class="ng"> words.txt </em>文件。例如:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/a0efc3d94e577db834f3496d785c0bc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*f-1Uzw1qHkq9uv2Fioy4Rw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">相应类别标签代码的标签描述符示例|作者图片</p></figure><p id="20ff" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">之后，我们执行文件夹路径重组:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="3017" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">步骤5 —定义图像预处理转换</h2><p id="f0de" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">所有预训练的Torchvision模型都希望输入图像以相同的方式归一化(作为预处理要求的一部分)。</p><p id="b820" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">它要求这些图像为shape (3 x H x W)的3通道RGB格式，其中H(高)和W(宽)至少为<strong class="lk jd"> 224像素</strong>。</p><p id="15b9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后需要根据<strong class="lk jd"> (0.485，0.456，0.406) </strong>的<strong class="lk jd">均值</strong>值和<strong class="lk jd"> (0.229，0.224，0.225) </strong>的<strong class="lk jd">标准差</strong>值对像素值进行归一化。</p><p id="bb21" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">除此之外，我们可以引入各种变换(例如，中心裁剪、随机翻转等。)来<a class="ae lh" rel="noopener" target="_blank" href="/top-python-libraries-for-image-augmentation-in-computer-vision-2566bed0533e">扩充</a>图像数据集并提高模型性能。</p><p id="62ba" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将这些转换放在一个<em class="ng"> Torchvision </em> <code class="fe ow ox oy oz b">Compose</code>包装器中，将它们链接在一起。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="9b03" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">步骤6-创建数据加载器</h2><p id="9f68" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">我们在<strong class="lk jd">步骤3 </strong>中描述了数据加载器的概念，并为设置数据加载器创建了一个帮助函数。是时候通过为<strong class="lk jd">训练集和</strong>验证集创建数据加载器来很好地利用这个函数了。</p><p id="dbb0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们在<strong class="lk jd">步骤5 </strong>中指定转换步骤，并定义<strong class="lk jd"> 64 </strong>的批量。这意味着DataLoader每次被调用时将推出64个图像。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="2e61" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">步骤7 —定义模型架构</h2><p id="1581" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">火炬视觉<a class="ae lh" href="https://pytorch.org/vision/stable/models.html" rel="noopener ugc nofollow" target="_blank">模型子包</a> <code class="fe ow ox oy oz b">torchvision.models</code>包含了大量预先训练好的模型供我们使用。这包括流行的架构，如ResNet-18、VGG16、GoogLeNet和ResNeXt-50。</p><p id="aa3f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将为这个项目做一些不同的事情，在Torchvision模型的默认列表中选择一个<strong class="lk jd">而不是</strong>的预训练模型。特别是，我们将使用<strong class="lk jd"> EfficientNet </strong>。</p><p id="0f7e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">EfficientNet是Google在2019年开发的卷积神经网络架构和缩放方法。它超越了最先进的精度，效率提高了10倍(即更小、更快)。</p><p id="81f6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下图说明了EfficientNet ( <em class="ng">红线</em>)在准确性(在ImageNet上)和计算资源方面如何优于其他架构。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pe"><img src="../Images/2a1b533e90d6196ae848b1f139fec77a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DYlFKrfTeaxi7PXdaBbZFQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">在<a class="ae lh" href="https://github.com/lukemelas/EfficientNet-PyTorch/blob/master/LICENSE" rel="noopener ugc nofollow" target="_blank"> Apache 2.0许可下使用的图像</a></p></figure><p id="f46d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">不同版本的EfficientNet (b0到b7)基于模型参数的数量而有所不同。参数数量越多，精度越高，但代价是训练时间越长。</p><p id="897a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本教程中，我们将使用高效网络的PyTorch实现来建立一个<strong class="lk jd">高效网络-B3 </strong>架构。我选择<strong class="lk jd"> B3 </strong>是因为它在准确性和训练时间之间提供了一个很好的平衡。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="a82f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">更新的EfficientNet v2的PyTorch实现即将推出，请继续关注<a class="ae lh" href="https://github.com/lukemelas/EfficientNet-PyTorch" rel="noopener ugc nofollow" target="_blank">GitHub repo</a>的最新更新。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="7740" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">步骤8-定义损失函数、超参数和优化器</h2><p id="66cf" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">最适合图像分类任务的损失函数是<strong class="lk jd">分类交叉熵损失</strong>。</p><p id="ff34" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将使用一组模型参数的基线值，例如学习率、时期数、日志记录频率和优化器类型。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="53c5" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">步骤9-实例化教练引擎</h2><p id="51d6" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">Ignite框架的主要本质是<code class="fe ow ox oy oz b"><strong class="lk jd">Engine</strong></code>类，它对输入数据执行处理功能并返回输出。</p><p id="c5aa" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">当我们创建一个<strong class="lk jd">训练器引擎</strong>时，我们正在初始化一个类，该类将被重复调用，以根据数据加载器生成的批量数据训练模型。</p><p id="82b6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">PyTorch Ignite自带内置助手函数，只需单行代码即可创建训练器引擎。对于我们的监督图像分类用例，我们利用了<code class="fe ow ox oy oz b">create_supervised_trainer</code>函数。</p><p id="abc0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些引擎还允许我们附加有用的<a class="ae lh" href="https://pytorch.org/ignite/handlers.html" rel="noopener ugc nofollow" target="_blank">事件处理程序</a>，比如监控训练的进度条。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="676c" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">步骤10 —定义评估指标</h2><p id="6190" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">用于图像分类模型评估的<a class="ae lh" href="https://pytorch.org/ignite/metrics.html" rel="noopener ugc nofollow" target="_blank">度量</a>是<strong class="lk jd">准确度</strong>(用于我们解释模型的性能)和<strong class="lk jd">交叉熵损失</strong>(用于模型迭代改进)。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="92d3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在将指标附加到引擎之前，您也可以创建自己的自定义指标。例如，<strong class="lk jd"> F1分数</strong>可以从默认精度和召回指标中通过算术方法得出:</p><pre class="ks kt ku kv gt pf oz pg ph aw pi bi"><span id="ef2c" class="ml mm it oz b gy pj pk l pl pm"><strong class="oz jd">from</strong> ignite.metrics <strong class="oz jd">import</strong> <strong class="oz jd">Precision,</strong> <strong class="oz jd">Recall</strong><br/><br/><strong class="oz jd">precision</strong> <strong class="oz jd">=</strong> <strong class="oz jd">Precision(average=False)</strong><br/><strong class="oz jd">recall</strong> <strong class="oz jd">=</strong> <strong class="oz jd">Recall(average=False)</strong><br/><strong class="oz jd">F1</strong> <strong class="oz jd">=</strong> <strong class="oz jd">(precision</strong> <strong class="oz jd">*</strong> <strong class="oz jd">recall</strong> <strong class="oz jd">*</strong> 2 <strong class="oz jd">/</strong> <strong class="oz jd">(precision</strong> <strong class="oz jd">+</strong> <strong class="oz jd">recall)).mean()</strong></span><span id="2dc0" class="ml mm it oz b gy pn pk l pl pm"><strong class="oz jd">F1.attach(engine,</strong> "F1"<strong class="oz jd">)</strong></span></pre></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="bd3f" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">步骤11-实例化评估引擎</h2><p id="2644" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">在定义评估指标之后，我们可以初始化评估器引擎来<strong class="lk jd">评估</strong>模型性能。<strong class="lk jd">评估引擎</strong>将把模型和评估指标(来自<strong class="lk jd">步骤10 </strong>)作为参数。</p><p id="34c5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们为训练集定义了一个评估器引擎，为验证集定义了一个单独的评估器引擎。这是因为他们在整个模型训练过程中的角色不同。</p><p id="0f6a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">验证评估器将用于保存基于验证指标的最佳模型，而训练评估器将只记录训练集中的指标。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="540c" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">步骤12—创建事件处理程序</h2><p id="c9d2" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">为了提高<code class="fe ow ox oy oz b"><a class="ae lh" href="https://pytorch.org/ignite/generated/ignite.engine.engine.Engine.html#ignite.engine.engine.Engine" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd">Engine</strong></a></code>的<strong class="lk jd">和</strong>的灵活性，引入了一个事件系统，以便于在训练运行的每一步进行事件互动，例如:</p><ul class=""><li id="6bed" class="oe of it lk b ll lm lo lp lr og lv oh lz oi md op ok ol om bi translated">发动机启动/完成</li><li id="933f" class="oe of it lk b ll oq lo or lr os lv ot lz ou md op ok ol om bi translated">纪元开始/完成</li><li id="b260" class="oe of it lk b ll oq lo or lr os lv ot lz ou md op ok ol om bi translated">批量迭代开始/完成</li></ul><p id="60e8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在decorators的帮助下，我们可以创建被称为<strong class="lk jd">事件处理程序</strong>的定制代码。事件处理程序是在特定事件发生时执行的函数。例如，我们可以在每次迭代(<code class="fe ow ox oy oz b">Events.ITERATION_COMPLETED</code>)和时期(<code class="fe ow ox oy oz b">Events.EPOCH_COMPLETED</code>)完成时记录度量。</p><p id="f30a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">此外，我们想要一个<a class="ae lh" href="https://pytorch.org/ignite/generated/ignite.handlers.checkpoint.Checkpoint.html#ignite.handlers.checkpoint.Checkpoint" rel="noopener ugc nofollow" target="_blank">检查点</a>处理程序来保存我们最好的模型(如<a class="ae lh" href="https://pytorch.org/tutorials/beginner/saving_loading_models.html" rel="noopener ugc nofollow" target="_blank">)。pt文件</a>)基于验证准确度。这可以通过<a class="ae lh" href="https://pytorch.org/ignite/_modules/ignite/contrib/engines/common.html" rel="noopener ugc nofollow" target="_blank">公共</a>模块中的辅助方法<code class="fe ow ox oy oz b">save_best_model_by_val_score</code>轻松完成。</p><p id="059a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在伴随每个事件的函数中，您会注意到我们使用了在前面的步骤中已经构建好的变量和引擎。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="fc3b" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">步骤13 —设置Tensorboard</h2><p id="cff2" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated"><a class="ae lh" href="https://www.tensorflow.org/tensorboard/" rel="noopener ugc nofollow" target="_blank"> Tensorboard </a>作为机器学习实验的一部分，是一个跟踪和可视化指标(如损失和准确性)的有用工具包。</p><p id="bc6a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">PyTorch与Tensorboard集成在一起，因此我们可以从创建一个<a class="ae lh" href="https://pytorch.org/ignite/generated/ignite.contrib.handlers.tensorboard_logger.html" rel="noopener ugc nofollow" target="_blank"> Tensorboard logger </a>处理程序并指定存储日志的目录开始。</p><p id="a947" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">初始化Tensorboard logger后，我们可以附加输出处理程序来指定事件和相应的度量，以保存供以后可视化。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="33ce" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">虽然我们在这里使用Tensorboard，但我们可以轻松地使用其他流行的日志工具，如Weights and Biases、ClearML和MLflow。查看<a class="ae lh" href="https://pytorch.org/ignite/_modules/ignite/contrib/engines/common.html" rel="noopener ugc nofollow" target="_blank">通用模块文档</a>了解更多信息。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="024f" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">步骤14-开始模型训练</h2><p id="a7de" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">我们终于到了可以开始实际模型训练的阶段了。我们通过让<strong class="lk jd">训练器引擎</strong>在训练集数据加载器上运行来做到这一点。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="43ec" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这是Colab中第一个训练纪元的样子:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi po"><img src="../Images/00cae005749238e9ba020fae7db6bd08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zHoBP_LNH-77j7PNKruRsw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="8214" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">仅用一个纪元，B3效率网就已经取得了令人印象深刻的验证准确度<strong class="lk jd"> 61.1% </strong>。</p><p id="6854" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">训练完成后，我们可以运行以下代码来获得验证集的最终评估指标:</p><pre class="ks kt ku kv gt pf oz pg ph aw pi bi"><span id="e3cf" class="ml mm it oz b gy pj pk l pl pm">print(evaluator.state.metrics)</span></pre><p id="b5f9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">三个时期后得到的最终准确率得分为<strong class="lk jd"> 66.57% </strong>。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="3f45" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">步骤15 —在Colab中查看Tensorboard</h2><p id="4804" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">我们调用一组神奇的命令来加载Colab笔记本中的Tensorboard。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="0127" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">执行上述命令后，Colab笔记本中将加载以下Tensorboard接口。这个可视化仪表板为我们提供了从训练运行中获得的指标信息。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pp"><img src="../Images/d10df83d2ec5c28f435d140b507c602a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0bb24r2yJWjKi2h_HHxzfQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">Tensorboard截图|图片作者</p></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="312b" class="nk mm it bd mn nl nm nn mq no np nq mt ki nr kj mw kl ns km mz ko nt kp nc nu bi translated">包装东西</h1><p id="6b24" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">在本教程中，我们介绍了利用Ignite框架的灵活性和简单性来构建PyTorch深度学习模型的步骤。</p><p id="4885" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">PyTorch Ignite具有许多其他功能来满足更复杂的神经网络设计的需求，因此可以随意浏览<a class="ae lh" href="https://pytorch.org/ignite/index.html" rel="noopener ugc nofollow" target="_blank">文档</a>和<a class="ae lh" href="https://pytorch.org/ignite/examples.html" rel="noopener ugc nofollow" target="_blank">示例笔记本</a>。</p><p id="c596" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">例如，代替先前使用的静态学习率，我们可以结合一个<a class="ae lh" href="https://pytorch.org/ignite/generated/ignite.handlers.param_scheduler.LRScheduler.html" rel="noopener ugc nofollow" target="_blank">学习率调度器(LRScheduler)处理程序</a>到<strong class="lk jd"> </strong>在训练期间调整学习率值。灵活性也意味着我们可以在设置中包含其他算法，如<a class="ae lh" href="https://github.com/pytorch/ignite/blob/master/examples/notebooks/FastaiLRFinder_MNIST.ipynb" rel="noopener ugc nofollow" target="_blank"> FastAI的学习率查找器</a>。</p><p id="8406" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">项目链接</strong></p><ul class=""><li id="07b2" class="oe of it lk b ll lm lo lp lr og lv oh lz oi md op ok ol om bi translated"><a class="ae lh" href="https://github.com/kennethleungty/PyTorch-Tiny-ImageNet-Classification" rel="noopener ugc nofollow" target="_blank"> GitHub回购</a></li><li id="fd4d" class="oe of it lk b ll oq lo or lr os lv ot lz ou md op ok ol om bi translated"><a class="ae lh" href="https://colab.research.google.com/drive/1HWfA_JrjoehfZ1zP60MWKo85fBeKccRg?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab笔记本</a></li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pq"><img src="../Images/3334c9b87ed9bcfa76a2da7cda0441b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qIXfVYBJFjL8KY8c"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@acharki95?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">阿齐兹·阿查基</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h2 id="d9c0" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">在你走之前</h2><p id="0ba3" class="pw-post-body-paragraph li lj it lk b ll ny kd ln lo nz kg lq lr oa lt lu lv ob lx ly lz oc mb mc md im bi translated">欢迎您<strong class="lk jd">加入我的数据科学学习之旅</strong>。跟随这个<a class="ae lh" href="https://kennethleungty.medium.com/" rel="noopener">媒体</a>页面并查看我的<a class="ae lh" href="https://github.com/kennethleungty" rel="noopener ugc nofollow" target="_blank"> GitHub </a>以了解实用和教育数据科学内容。同时，祝你考试顺利！</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="2bfd" class="ml mm it bd mn mo mp dn mq mr ms dp mt lr mu mv mw lv mx my mz lz na nb nc iz bi translated">参考</h2><ul class=""><li id="9fc1" class="oe of it lk b ll ny lo nz lr pr lv ps lz pt md op ok ol om bi translated"><a class="ae lh" href="https://github.com/pytorch/ignite" rel="noopener ugc nofollow" target="_blank"> PyTorch点燃GitHub </a></li><li id="8bce" class="oe of it lk b ll oq lo or lr os lv ot lz ou md op ok ol om bi translated"><a class="ae lh" href="https://pytorch.org/ignite/index.html" rel="noopener ugc nofollow" target="_blank"> PyTorch点火文档</a></li><li id="e6f1" class="oe of it lk b ll oq lo or lr os lv ot lz ou md op ok ol om bi translated"><a class="ae lh" href="https://github.com/lukemelas/EfficientNet-PyTorch" rel="noopener ugc nofollow" target="_blank">efficient net-py torch GitHub</a></li></ul></div></div>    
</body>
</html>