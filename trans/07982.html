<html>
<head>
<title>Outlier Detection in Regression Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回归分析中的异常值检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/outlier-detection-in-regression-using-cooks-distance-f5e4954461a0?source=collection_archive---------5-----------------------#2021-07-22">https://towardsdatascience.com/outlier-detection-in-regression-using-cooks-distance-f5e4954461a0?source=collection_archive---------5-----------------------#2021-07-22</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="3465" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">在Scikit-Learn和Statsmodel中使用Cook距离进行回归异常值检测</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/c572dd723005faadef605a96457d97e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k4eloRqNC_w2OQ5ZHUWgBA.jpeg"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">图片来自<a class="ae kz" href="https://unsplash.com/photos/vHnVew5foFU" rel="noopener ugc nofollow" target="_blank"> unsplash </a></p></figure><blockquote class="la lb lc"><p id="fad4" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated"><strong class="lg iv">简介</strong></p></blockquote><p id="c904" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">异常值是指数据集中不符合正态分布的异常值，有可能严重扭曲任何回归模型。因此，必须小心处理异常值，以便从数据中获得正确的见解。通常，从现实世界中收集的数据由几个要素的几个观测值组成，许多值可能放置错误，或者可能只是数据处理的产物。无论异常值的原因是什么，都必须对异常值进行分析，并验证它们是真实的。如果离群值是真实的，可以将这些离群值带入回归模型，或者简单地删除它们，以创建更好的回归模型。</p><blockquote class="la lb lc"><p id="7ce2" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated">资料组</p></blockquote><p id="1fdb" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">为了用python实现，我将使用Scikit-Learn的线性回归和Statsmodel的OLS方法来拟合房价数据。为了简单起见，这里所有的特征数据都是数字。我将使用下一篇文章中使用的相同的房价数据。</p><div class="md me gq gs mf mg"><a href="https://medium.com/geekculture/feature-selection-in-large-datasets-fc27a7e8e388" rel="noopener follow" target="_blank"><div class="mh ab fp"><div class="mi ab mj cl cj mk"><h2 class="bd iv gz z fq ml fs ft mm fv fx it bi translated">大型数据集中的特征选择</h2><div class="mn l"><h3 class="bd b gz z fq ml fs ft mm fv fx dk translated">使用Shapash和Scikit-Learn的SelectKBest</h3></div><div class="mo l"><p class="bd b dl z fq ml fs ft mm fv fx dk translated">medium.com</p></div></div><div class="mp l"><div class="mq l mr ms mt mp mu kt mg"/></div></div></a></div><p id="f848" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">我将从房价的线性回归模型开始，从数据集中选择几个数字预测值。预测值为“总体质量”、“GrLivArea”、“TotalBsmtSF”、“YearBuilt”、“FullBath”、“HalfBath”、“GarageArea”，目标为“销售价格”。这些功能的相应描述如下。</p><pre class="kk kl km kn gu mv mw mx my aw mz bi"><span id="1235" class="na nb iu mw b gz nc nd l ne nf">'OverallQual': 'Overall material and finish of the house'<br/>'GrLivArea': 'Ground living area square feet'<br/>'TotalBsmtSF': 'Total square feet of basement area<br/>'YearBuilt': 'Original construction date'<br/>'FullBath': 'Full bathrooms above grade'<br/>'HalfBath': 'Half baths above grade'<br/>'GarageArea': 'Size of garage in square feet'<br/></span></pre><p id="1448" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">我还有另一篇异常值检测文章，特别关注基于IQR、汉佩尔和DBSCAN方法的数值异常值。</p><div class="md me gq gs mf mg"><a rel="noopener follow" target="_blank" href="/practical-implementation-of-outlier-detection-in-python-90680453b3ce"><div class="mh ab fp"><div class="mi ab mj cl cj mk"><h2 class="bd iv gz z fq ml fs ft mm fv fx it bi translated">异常检测在python中的实际实现</h2><div class="mn l"><h3 class="bd b gz z fq ml fs ft mm fv fx dk translated">IQR、汉佩尔和DBSCAN法</h3></div><div class="mo l"><p class="bd b dl z fq ml fs ft mm fv fx dk translated">towardsdatascience.com</p></div></div><div class="mp l"><div class="ng l mr ms mt mp mu kt mg"/></div></div></a></div><p id="38a7" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">在这里，文章将具体到回归模型和使用库克距离的方法来检测异常值。</p><blockquote class="la lb lc"><p id="3639" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated"><strong class="lg iv"> Scikit-Learn和Statsmodel </strong></p></blockquote><p id="949e" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">我们有兴趣调查Scikit-Learn和Statsmodel之间的拟合质量。首先，Scikit-Learn的线性回归模型适用于预测值和目标变量。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nh ni l"/></div></figure><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nh ni l"/></div></figure><p id="f9b3" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">通过该模型获得的R平方值是0.7672，这基本上表明大约。数据集中76%的方差是由我们选择的预测因子解释的。</p><p id="08c0" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">当切换到Statsmodel时，R平方值仍然非常相似，为0.767，用户也可以选择调整后的R平方，它不会改变mich，这种情况下表示非常适合最初选择的特性。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nh ni l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nj"><img src="../Images/c17115ef51f960de4005ccc790552da7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vs8dygkK7yERfkxMaijgsw.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><blockquote class="la lb lc"><p id="de11" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated"><strong class="lg iv">异常值分析</strong></p></blockquote><p id="30ba" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">Statmodel的OLSinfluence提供了一种快速的方法来衡量每个观察的影响。当数据绘制在箱线图中时，对数据进行一般异常值分析，高于或低于四分位数间距(IQR)1.5倍的点被标记为异常值。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nk"><img src="../Images/c9224524bcf35e81c4a37b5f4bfe4093.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/0*k51IjrpSfRjAqsS2.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">图片来自<a class="ae kz" href="https://www.simplypsychology.org/boxplots.html" rel="noopener ugc nofollow" target="_blank">simplypsychology.org</a></p></figure><p id="07f7" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">这些异常值有时非常高或非常低，可以形成局部聚类。如果我们选择传统的箱线图，这些局部聚类被识别为异常值。像DBSCAN这样的其他方法可以有效地识别这些极值点，并且可以将这些极值点合并到分析中，因为它遵循基于密度的算法。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nl"><img src="../Images/6a9fbd73831a47435f1343961ae46122.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/0*51W1KpSNW-gGovcd.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="18cb" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">然而，在回归中，标准化残差是异常值的指标。它用标准误差来衡量数据点离回归线有多远。我们将把这个残差用于同一个数据集。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nh ni l"/></div></figure><p id="52bc" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">在这里，我们可以看到回归线上最有影响力的数据点，它基本上是一个奇点，具有控制模型的最高能力。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nm"><img src="../Images/350ecc69c65b3ccc5e1adce365221751.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*9Q6klMZvrYVgoLksxNbd0A.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="598f" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">根据具体情况，人们可以选择保留或放弃。在下面的代码块中，我们可以画出所有点的影响。当使用plotly express绘图时，只需将鼠标悬停在异常值上，就可以更容易地识别异常值。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nh ni l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nn"><img src="../Images/b79cf9b3fa81a6a6f3d0cd01c0720962.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TA-j1CDk4ZL94Wv1sC3Y3A.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="ce93" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">X轴代表数据点的帽值。多元线性回归表示如下</p><blockquote class="no"><p id="3547" class="np nq iu bd nr ns nt nu nv nw nx lz dk translated">Y = HX</p></blockquote><p id="b6eb" class="pw-post-body-paragraph ld le iu lg b lh ny jv lj lk nz jy lm ma oa lp lq mb ob lt lu mc oc lx ly lz in bi translated">其中Y是以X为预测值的结果。H是帽子矩阵，帽子值是H矩阵的对角分量。y轴代表标准化残差。很明显，最右边的点是具有非常高的hat值的异常值。悬停数据可以被修改以显示关于它的更多信息。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj od"><img src="../Images/4403cc44625c08e16d2fc6b5e4282829.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-_x6YDwPE39pX327hgsQKw.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="a91c" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">在这一点上，我们将引入库克距离，这是一个衡量数据点影响的指标。Cook的距离是杠杆(Wiki定义:在统计学中，特别是在回归分析中，杠杆是一种衡量一个观察值的独立变量值与另一个观察值的距离)和残差大小的组合。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nh ni l"/></div></figure><p id="bfa2" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">当以这种方式绘制时，单个点的影响如此之大，以至于所有其他点的贡献几乎不明显。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj oe"><img src="../Images/45132f2483b88f985e2c51decd2d776f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3HHON7ZuDqOJQixmDQroSA.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="49aa" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">我们需要扩大厨师的距离来注意其他人。当缩放50倍时，其他的点就成了大图。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj of"><img src="../Images/444e2917022feea01476caed47bd41af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h3xGJ9jeEKOaG6YXygliPA.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><blockquote class="la lb lc"><p id="d078" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated"><strong class="lg iv">绘制库克的距离</strong></p></blockquote><p id="037f" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">库克距离是数据点的导数，并且会因样本而异。下面的块以容易识别的方式绘制了Cook的距离，以检测异常值。这里，我们选择将Id放在X轴上。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nh ni l"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj og"><img src="../Images/1675aaec39b605ca985d64e39573c0d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IDxhACSGGDwnQ5bndcx-Gg.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="fbeb" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">在这种情况下，可以放弃那个最有影响的点，并继续回归模型，因为它具有如此大的扭曲模型的能力。</p><blockquote class="la lb lc"><p id="bec1" class="ld le lf lg b lh li jv lj lk ll jy lm ln lo lp lq lr ls lt lu lv lw lx ly lz in bi translated"><strong class="lg iv">结论</strong></p></blockquote><p id="1e1b" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated">在本文中，我们演示了如何使用Scikit-Learn和Stasmodel来评估回归模型。稍后使用Stasmodel，基于Cook的距离检测异常值。由于人为错误，真实世界的数据可能有几个异常值，或者可能作为分析的产物生成。根据具体情况，数据分析师/科学家可能会选择保留或删除异常值。</p><p id="d8ae" class="pw-post-body-paragraph ld le iu lg b lh li jv lj lk ll jy lm ma lo lp lq mb ls lt lu mc lw lx ly lz in bi translated"><a class="ae kz" href="https://mdsohelmahmood.github.io/2021/07/21/Cook's-Distance.html" rel="noopener ugc nofollow" target="_blank"> Github页面</a></p></div></div>    
</body>
</html>