<html>
<head>
<title>Bias vs Variance Trade-off — Clearly Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">偏差与方差的权衡——解释清楚</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bias-vs-variance-trade-off-clearly-explained-3becf5454b30?source=collection_archive---------22-----------------------#2021-04-14">https://towardsdatascience.com/bias-vs-variance-trade-off-clearly-explained-3becf5454b30?source=collection_archive---------22-----------------------#2021-04-14</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="56d1" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">偏差与方差，过度拟合与欠拟合</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/15c02319397217126fcb4886c59807e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V1heK5LOK8znRNnva6HFLg.jpeg"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">照片由<a class="ae kz" href="https://www.pexels.com/photo/illustration-of-woman-analyzing-financial-line-graphic-6289065/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的Gabby K 拍摄</p></figure><h1 id="d09d" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">为什么我们需要偏差-方差权衡</h1><p id="abd7" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">在机器学习中，我们收集数据，并使用训练数据建立模型。我们将该模型应用于该模型未见过的测试数据，并进行预测。我们的主要目的是减少预测误差。</p><p id="f6ed" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">我们通过最小化训练误差来建立模型，但是我们更关心测试误差/预测误差。预测误差取决于偏差和方差。</p><p id="fdea" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">以下情况需要偏差-方差权衡。</p><ol class=""><li id="d22a" class="mt mu iu lu b lv mo ly mp mb mv mf mw mj mx mn my mz na nb bi translated">为了克服欠配合和过配合情况</li><li id="4ef9" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">预测的一致性。</li></ol><p id="7548" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">让我们在本文中详细了解偏差-方差权衡背后的概念。</p><h1 id="7a8b" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">模型结构</h1><p id="a26d" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">在进行偏差-方差权衡之前，让我们看看当我们增加模型复杂性时，训练误差和预测误差有什么不同。</p><p id="218f" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">假设，我们有这样的数据点。我们必须找到X和y之间的关系。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nh"><img src="../Images/32be6d9c33bd9deadaf5d5346b211c57.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*6lf5wWRSY4FICF6nknzk8g.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="8988" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">X和Y之间的真关系或真函数表示为<strong class="lu iv"> f(X) </strong>。这个功能未知。</p><p id="3823" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv"> Y=f(X)+ε </strong></p><p id="d094" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">现在，我们必须建立一个模型来描述X和y之间的关系。</p><p id="b599" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">输入→模型→输出</strong></p><p id="39fe" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">学习算法:</strong>学习算法将接受输入并返回一个描述X和y之间关系的函数。</p><p id="baf7" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">输入→学习算法→ f̂(X) </strong></p><p id="bb2f" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">示例:在线性回归中，学习算法是梯度下降法，它根据成本函数OLS(最小二乘法)找到最佳拟合线。</p><p id="aef6" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">假设给定一个数据集，我们把它分成训练数据和测试数据。</p><p id="33eb" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">训练数据—使用训练数据<br/>测试数据构建模型—使用选择的模型预测输出。</p><p id="d6b7" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">现在，让我们考虑基于训练数据构建的4个模型。</strong></p><p id="e6d7" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">在所有的模型中，我们都在假设y和x的关系。</p><ol class=""><li id="8c8f" class="mt mu iu lu b lv mo ly mp mb mv mf mw mj mx mn my mz na nb bi translated"><strong class="lu iv">简单模型→1度→ y=f̂(x) = w0 +w1x </strong></li></ol><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ni"><img src="../Images/21777720745d20a967f9e758dccadacc.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*BmGlbNsVLaKaYpcTCCWlNQ.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="275a" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">在这个简单的模型中，拟合线远离数据点，因此拟合误差/训练误差会很高。</p><h2 id="7f03" class="nj lb iu bd lc nk nl dn lg nm nn dp lk mb no np lm mf nq nr lo mj ns nt lq nu bi translated">2.二次多项式</h2><p id="105e" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated"><strong class="lu iv"> y=f̂(x) = w0 +w1x + w2x </strong></p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nv"><img src="../Images/7ab33dcce05ba34b0459b0e48abb58dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*Y6i1KZF7vgtoNmOjfBXQ9Q.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="bb80" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv"> 3。五次多项式</strong></p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nw"><img src="../Images/abe5da7f5207e22dd2837592a4258693.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*YRlLla9-0ay2M6zAIzVUKw.png"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nx"><img src="../Images/8ab7f99c3b19662e54abe95d8fcfecf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*wBAkgdtbSYqgaqjjc8eVBQ.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="8d21" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv"> 4。复杂模型→20度</strong></p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ny"><img src="../Images/90daf93a35d61d335151778fb85687b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*60dG_7nAlYkElX4cbCNwaQ.png"/></div></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nz"><img src="../Images/c1397bca10ebd6183f0b968604b6eddb.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*pw2-5j38Vzoa2485Lc0npg.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="15d2" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">这里，在这个复杂的模型中，拟合的曲线穿过所有的数据点，因此拟合误差/训练误差将接近于零。这个模型试图将数据和噪音一起记忆下来，而不是将其一般化。因此，这个模型在看不见的测试数据/验证数据上表现不好。这种情况被称为<strong class="lu iv">过度拟合。</strong></p><p id="c648" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">现在，如果我们使用这4个模型对验证数据进行预测，我们将得到不同的预测误差。</p><p id="e7f3" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">现在绘制训练误差和预测误差与模型复杂性(在我们的例子中，多项式的次数)的关系</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj oa"><img src="../Images/4ed100a058a81dae116dacf6f3e7f02f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*_lraOL1dkDaS9khjiizjKA.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="dc11" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">从上面的图表中，我们可以看到，随着模型复杂度的增加[1度、2度、5度、20度]，训练误差趋于减小。</p><p id="accd" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">但预测误差在一定程度上减小，当模型变得更复杂时，预测误差会增大。</p><p id="c3b9" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">在训练误差和预测误差之间存在权衡。在两条曲线的末端，一端有高偏差，另一端有高方差。因此，在偏差和方差之间存在一个折衷，以实现理想的模型复杂性。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj ob"><img src="../Images/34c1aad2f4d46e2d6ef32066a499359c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YyN1E-XDhcm-PxCIjpclVQ.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure></div><div class="ab cl oc od hy oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="in io ip iq ir"><h1 id="a2b9" class="la lb iu bd lc ld oj lf lg lh ok lj lk ka ol kb lm kd om ke lo kg on kh lq lr bi translated">什么是偏差-方差权衡？</h1><h1 id="393d" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated"><strong class="ak">偏向</strong></h1><p id="becc" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">假设f(x)是真实模型，<strong class="lu iv"> </strong> f̂(x)是模型的估计值，那么</p><p id="2c23" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">)= bias(f̂(x)</strong></p><p id="309c" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">偏差告诉我们期望值和真实函数之间的差异。</p><p id="7feb" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">E[f̂(x)] →模型的期望值。</p><h2 id="cc72" class="nj lb iu bd lc nk nl dn lg nm nn dp lk mb no np lm mf nq nr lo mj ns nt lq nu bi translated">如何计算模型的期望值？</h2><p id="26f0" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">我们建立模型(<strong class="lu iv">)</strong>)使用相同的形式(例如。多项式次数1)在从训练数据中抽取的不同随机样本上。然后我们将计算所有函数的期望值，记为<strong class="lu iv">e[f̂(x)】</strong>。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj oo"><img src="../Images/e92ad0984cbce5e64f6449290483e888.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*68pmGntgdBF5yoHtd3hiMQ.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="6e76" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">在上图中，橙色拟合曲线是对从训练数据中抽取的不同随机样本执行的所有复杂模型(度数=20)的平均值。</p><p id="eafe" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">在上图中，绿色拟合线是对从训练数据中抽取的不同随机样本执行的所有简单模型(度数=1)的平均值。</p><p id="1545" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">从上面的图中，我们可以看到简单模型有很高的偏差。因为平均函数离真实函数很远。</p><p id="97d0" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">复杂模型具有较低的偏差。它们完全符合数据。</p><h1 id="a733" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">差异</h1><p id="17ef" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">方差告诉我们一个f̂(x与E(f̂(x)).模型的期望值有多大的不同</p><p id="2f6c" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">variance(f̂(x))= e[(f̂(x)]-e[f̂(x)]]</strong></p><p id="ada5" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">因此，对于复杂的模型，方差往往更高，因为训练样本中的微小变化将导致不同的f̂(x).因为复杂的模型，把数据点背下来。</p><p id="ddec" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">对于简单的模型，在f̂(x不会有太大的区别)，如果我们稍微改变一下训练样本。简单的模型概括了这种模式。</p><p id="1cbf" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">所以，根据偏差和方差，我们可以说，</p><blockquote class="op oq or"><p id="8871" class="ls lt os lu b lv mo jv lx ly mp jy ma ot mq md me ou mr mh mi ov ms ml mm mn in bi translated">简单模型可能具有高偏差和低方差。<br/>复杂模型可能具有低偏差和高方差</p></blockquote><p id="349d" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">偏差和方差之间有一个权衡，因为两者都会导致误差。</p></div><div class="ab cl oc od hy oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="in io ip iq ir"><h1 id="fc2f" class="la lb iu bd lc ld oj lf lg lh ok lj lk ka ol kb lm kd om ke lo kg on kh lq lr bi translated">预期预测误差</h1><p id="ce2d" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">预期预测误差取决于三个误差</p><ol class=""><li id="5adf" class="mt mu iu lu b lv mo ly mp mb mv mf mw mj mx mn my mz na nb bi translated">偏见</li><li id="4c92" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">差异</li><li id="f200" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">噪声(不可约误差)</li></ol><h1 id="5a30" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">预期预测误差公式</h1><p id="17e9" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated"><em class="os"> EPE=偏差+方差+不可约误差</em></p><p id="419f" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">使用模型f̂(x)，我们预测不在训练数据中的新数据点(x，y)的值。</p><p id="798d" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">那么期望的均方误差将是</p><p id="f063" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">EPE =E[(y-f̂(x) ]</p><p id="7aa9" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">从EPE公式中，我们知道误差取决于偏差和方差。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj ob"><img src="../Images/34c1aad2f4d46e2d6ef32066a499359c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YyN1E-XDhcm-PxCIjpclVQ.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="3335" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">所以，从上面的情节来看</p><ol class=""><li id="4282" class="mt mu iu lu b lv mo ly mp mb mv mf mw mj mx mn my mz na nb bi translated">当偏差高时，预测误差高。</li><li id="1636" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn my mz na nb bi translated">当方差高时，预测误差高。</li></ol><ul class=""><li id="c5cd" class="mt mu iu lu b lv mo ly mp mb mv mf mw mj mx mn ow mz na nb bi translated">一次多项式→训练误差和预测误差高→ <strong class="lu iv">欠拟合</strong></li><li id="1726" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn ow mz na nb bi translated">2次多项式→训练误差和预测误差高→拟合不足</li><li id="69c7" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn ow mz na nb bi translated">5次多项式→训练误差较小，并且训练误差和预测误差之间的差异较小。→ <strong class="lu iv">最佳拟合</strong></li><li id="38cd" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn ow mz na nb bi translated">20次多项式→训练误差较小，预测误差很大<strong class="lu iv">→过拟合</strong></li></ul><h1 id="14cb" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">关键要点</h1><ul class=""><li id="82d9" class="mt mu iu lu b lv lw ly lz mb ox mf oy mj oz mn ow mz na nb bi translated">简单模型可能具有高偏差和低方差。</li><li id="0a08" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn ow mz na nb bi translated">简单的模型会更加通用，有时会显得不够合适。</li><li id="cfd9" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn ow mz na nb bi translated">复杂模型可能具有高方差和低偏差。</li><li id="b58e" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn ow mz na nb bi translated">复杂的模型会记住数据，并且倾向于过度拟合。</li><li id="cecd" class="mt mu iu lu b lv nc ly nd mb ne mf nf mj ng mn ow mz na nb bi translated">最佳拟合模型将具有低偏差和低方差。</li></ul></div><div class="ab cl oc od hy oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="in io ip iq ir"><p id="7e42" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">感谢阅读，我希望你们都喜欢它。</p><p id="5bfe" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><em class="os">如果你喜欢看我的更多教程，就关注我的</em> <a class="ae kz" href="https://medium.com/@IndhumathyChelliah" rel="noopener"> <strong class="lu iv"> <em class="os">中</em> </strong> </a>，<a class="ae kz" href="https://www.linkedin.com/in/indhumathy-chelliah/" rel="noopener ugc nofollow" target="_blank"><strong class="lu iv"><em class="os">LinkedIn</em></strong></a><strong class="lu iv"><em class="os">，</em> </strong> <a class="ae kz" href="https://twitter.com/IndhuChelliah" rel="noopener ugc nofollow" target="_blank"> <strong class="lu iv"> <em class="os">推特</em> </strong> </a> <strong class="lu iv"> <em class="os">。</em> </strong></p><p id="feec" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><em class="os">点击这里成为中等会员:</em><a class="ae kz" href="https://indhumathychelliah.medium.com/membership" rel="noopener"><em class="os">https://indhumathychelliah.medium.com/membership</em></a></p></div></div>    
</body>
</html>