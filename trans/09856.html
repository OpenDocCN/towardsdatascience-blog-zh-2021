<html>
<head>
<title>Use Case: Classifying Fruit</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用例:水果分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/use-case-classifying-fruit-1a0ae4da3c5e?source=collection_archive---------28-----------------------#2021-09-15">https://towardsdatascience.com/use-case-classifying-fruit-1a0ae4da3c5e?source=collection_archive---------28-----------------------#2021-09-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ec31" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">图像识别模型能理解新鲜农产品的奇特之处吗？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/aadaa967493607c4f6a7777a33a4304a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mEUIy1jGA_RG97s-Zbt0OQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片<a class="ae kv" href="https://unsplash.com/photos/CR28Ot0ckaE" rel="noopener ugc nofollow" target="_blank">来源</a>。</p></figure><p id="99a6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">供应链中水果和蔬菜等易腐食品的处理可能涉及许多过程，如分拣、称重和识别过期产品。传统上，这些过程是手工完成的，但随着技术的进步，自动化程度越来越高。现在，工业物联网(IIoT)和ML等领域在供应链中发挥着越来越重要的作用，行业参与者可以利用图像识别等技术来帮助对产品进行分类，在边缘做出决策，并优化他们的运营。</p><p id="251e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">像这样的垂直市场对ML来说是一个很好的测试。举个例子，像水果和蔬菜这样的食物。每个标本的大小、形状和特征都各不相同，而照明等环境因素都增加了图像处理训练数据的复杂性。</p><p id="fac9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">谢天谢地，在感知力实验室，我们从不在挑战面前退缩。因此，我们在<a class="ae kv" href="https://www.perceptilabs.com/" rel="noopener ugc nofollow" target="_blank">感知实验室</a>中建立了一个图像识别模型，看看它能否通过分析图像来识别不同类型的水果。</p><p id="80a9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有了足够高的准确性，像这样的模型可能会帮助农民、批发商和超市自动化供应链中负责管理和处理这些产品的不同流程。让我们看看进展如何。</p><p id="f867" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">数据集</strong></p><p id="bf2e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了训练我们的模型，我们使用了来自<a class="ae kv" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上的<a class="ae kv" href="https://www.kaggle.com/moltean/fruits" rel="noopener ugc nofollow" target="_blank"> Fruits 360 </a>数据集的图像，这些图像最初是使用视频捕获获得的，如这里的<a class="ae kv" href="https://www.youtube.com/watch?v=_HFKJ144JuU" rel="noopener ugc nofollow" target="_blank">所示</a>。</p><p id="5b45" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据集包含超过90，000种颜色。jpg图像分为131类，代表不同类型的水果。使用6500多张图像的子集，我们使用PerceptiLabs的<a class="ae kv" href="https://docs.perceptilabs.com/perceptilabs/references/ui-overview/data-wizard" rel="noopener ugc nofollow" target="_blank">数据向导</a>中的预处理选项将每张图像的大小调整为224x224像素。图1显示了该数据集中的一些苹果图片示例:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/3e1e86fc8f047c82d0ce0e4ed0e8569a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7iZNu6jw6AMvb5tj"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="lt">图1:来自数据集的图像示例—图像</em> <a class="ae kv" href="http://www.perceptilabs.com" rel="noopener ugc nofollow" target="_blank"> <em class="lt">来源</em> </a> <em class="lt">。</em></p></figure><p id="690d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了将分类映射到图像，我们创建了一个. csv文件，将每个图像文件与适当的水果分类标签相关联，以便通过PerceptiLabs的<a class="ae kv" href="https://docs.perceptilabs.com/perceptilabs/references/ui-overview/data-wizard" rel="noopener ugc nofollow" target="_blank">数据向导</a>加载数据。下面是一个部分的例子。csv文件看起来:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lu"><img src="../Images/7ebbceb999a89491aa50bae193a4501d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UxW_AuSLhKygke8o3fuzkA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="lt">的例子。csv文件，用于将数据加载到将图像文件映射到其关联标签的PerceptiLabs中。</em></p></figure><p id="d18b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们已经将图像数据和这个CSV文件在<a class="ae kv" href="https://github.com/PerceptiLabs/Fruit-Classification" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上进行实验。</p><p id="436e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">型号汇总</strong></p><p id="6825" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的模型只使用了一个<a class="ae kv" href="https://docs.perceptilabs.com/perceptilabs/references/components" rel="noopener ugc nofollow" target="_blank">组件</a>:</p><p id="e61b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">组件1: <a class="ae kv" href="https://keras.io/api/applications/vgg/" rel="noopener ugc nofollow" target="_blank"> VGG16 </a></p><p id="e16f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们采用的VGG16模型是具有16层的神经网络架构，其中13层是卷积层，其余三层是密集层。图2显示了感知实验室中模型的拓扑结构:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/ef84e123f3da3bb884079b627e5adb9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NajtKvn7IVITvwaB"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="lt">图2:感知实验室中模型的拓扑结构—图片</em> <a class="ae kv" href="http://www.perceptilabs.com" rel="noopener ugc nofollow" target="_blank"> <em class="lt">来源</em> </a> <em class="lt">。</em></p></figure><p id="b5dc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">训练和结果</strong></p><p id="2f5f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">我们用32个</strong>批量5个历元训练模型，使用<a class="ae kv" href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/#:~:text=Adam%20is%20a%20replacement%20optimization,sparse%20gradients%20on%20noisy%20problems." rel="noopener ugc nofollow" target="_blank"> ADAM </a>优化器，学习率0.001，交叉熵<a class="ae kv" href="https://blog.perceptilabs.com/choosing-and-customizing-loss-functions-for-image-processing/" rel="noopener ugc nofollow" target="_blank">损失</a>函数。使用大约74分44秒的训练时间，<strong class="ky ir">我们能够实现99.82%的训练准确率、99.54%的验证准确率和99.6%的测试准确率。全球培训损失为0.19%，全球验证损失为0.14%。</strong></p><p id="0b09" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图3显示了训练期间PerceptiLabs的统计视图:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/4dc73a6644451f1b5a90a518c6ad9dce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sAJLXERmZBhTRFZO"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="lt">图3:训练时PerceptiLabs的统计视图。训练损失和精度分别显示在左上角和右上角，右下角可以看到渐变—图片</em> <a class="ae kv" href="http://www.perceptilabs.com" rel="noopener ugc nofollow" target="_blank"> <em class="lt">来源</em> </a> <em class="lt">。</em></p></figure><p id="5a31" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，我们可以看到验证和训练损失随着时间的推移逐渐下降，两者的曲线非常相似。验证和训练准确性的曲线也反映了彼此的形状，并在稳定在略低于1.0之前的前三个时期上升。</p><p id="82a9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图4显示了模型的分类标签度量表测试结果和混淆矩阵:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/3b0aeb4a3c8c811ba071721a630c6353.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MZHuq3i6yKLcl0pe"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="lt">图4:模型的分类标签度量和混淆矩阵—图像</em> <a class="ae kv" href="http://www.perceptilabs.com" rel="noopener ugc nofollow" target="_blank"> <em class="lt">来源</em> </a> <em class="lt">。</em></p></figure><p id="6ea8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">混淆矩阵表明，模型正确地测试了几乎所有的样本(即，只有少数假阳性或假阴性)。Labels Metrics表通过显示以下各项的高(标准化)值来证实这一点:<strong class="ky ir">分类准确度</strong>(每个类别的准确度对所有类别进行平均)<strong class="ky ir">前K个分类准确度</strong>(前K个预测类别中正确类别的频率)<strong class="ky ir">精确度</strong>(正面预测的准确度)，以及<strong class="ky ir">召回</strong>(找到的正面的百分比(即，没有被错误分类为负面而不是正面)。</p><p id="18e3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">垂直应用</strong></p><p id="4cdd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">像这样的模型可以用于水果的收集、分类和分配。例如，该模型可用于分析通过相机获取的照片或视频帧，以分析传送带上不同种类的苹果，从而帮助对它们进行分类。该模型本身也可以用作<a class="ae kv" href="https://blog.perceptilabs.com/when-to-use-transfer-learning-in-image-processing/" rel="noopener ugc nofollow" target="_blank">迁移学习</a>的基础，以创建用于对其他类型的食品、材料或产品进行分类的模型。</p><p id="fe87" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">总结</strong></p><p id="ad0b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此使用案例展示了如何构建图像识别模型来支持整合了IIoT和/或ML的供应链流程。如果你想建立一个类似这样的深度学习模型，<a class="ae kv" href="https://docs.perceptilabs.com/perceptilabs/getting-started/quickstart-guide" rel="noopener ugc nofollow" target="_blank">运行PerceptiLabs </a>并从<a class="ae kv" href="https://github.com/PerceptiLabs/Fruit-Classification" rel="noopener ugc nofollow" target="_blank"> GitHub </a>中抓取一份我们预处理过的数据集。</p><p id="588b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Mihai Oltean，水果360数据集:<em class="lv">包含水果和蔬菜的图像数据集</em>，2020，<a class="ae kv" href="http://kaggle.com/" rel="noopener ugc nofollow" target="_blank">Kaggle.com</a>，2020.05.18.0，<a class="ae kv" href="https://www.kaggle.com/moltean/fruits" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/moltean/fruits</a>，麻省理工学院许可证</p></div></div>    
</body>
</html>