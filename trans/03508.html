<html>
<head>
<title>Measure Text Weight using TF-IDF in Python and scikit-learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python和scikit-learn中的TF-IDF测量文本重量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/measure-text-weight-using-tf-idf-in-python-plain-code-and-scikit-learn-50cb1e4375ad?source=collection_archive---------8-----------------------#2021-03-21">https://towardsdatascience.com/measure-text-weight-using-tf-idf-in-python-plain-code-and-scikit-learn-50cb1e4375ad?source=collection_archive---------8-----------------------#2021-03-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0bc8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我们如何使用TF-IDF为文本数据赋予权重，并找出为什么scikit-learn的结果与教科书中的公式不同</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b91e67b222cf3f36c29e8dd7a0de19c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KAj8uwgQpEM1ovBiLwKO2A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我的儿子安德鲁·朱，查尔斯的乐高积木</p></figure><p id="1860" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在处理文本数据时，我们希望衡量一个单词对全文集合中的一个文档的重要性。一个最直观的解决方法就是计算单词的出现次数，越高越好。但是简单地计算字数会导致有利于长文档/文章的结果。毕竟，较长的文档包含更多的单词。</p><p id="8eea" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们需要另一种解决方案，能够恰当地衡量一个单词在整个上下文中的重要性。<strong class="la iu"> TF-IDF </strong>是有效的解决方案之一。也是像谷歌这样的现代搜索引擎的支柱。</p><p id="c48a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> TF-IDF </strong>的核心思想是，解决方案不仅衡量词频，还衡量单词在整个上下文中的重要性。</p><p id="f5e3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，像“是”、“the”、“and”这样的词几乎出现在每个文档中，<strong class="la iu"> TF-IDF </strong>会降低那些常见词的权重，增加那些真正重要的词的权重。</p><h2 id="b728" class="lu lv it bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">TF-IDF公式</h2><p id="08f1" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">假设我们有一个巨大的Python文本数据库，其中包含三个文档:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="cb2b" class="lu lv it mu b gy my mz l na nb">text_db = ['problem of evil',<br/>           'evil queen',<br/>           'horizon problem']</span></pre><p id="7eff" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以使用这个公式来计算某个文档中某个单词的TF-IDF值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/ea6f11a0f45abcfe4ad25424092f3f25.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*HJkavKQKMHUlK3rB05q-ug.png"/></div></figure><p id="1840" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> TF_w，d </strong>代表某个<strong class="la iu"> d </strong>文件中<strong class="la iu"> w </strong> ord的<strong class="la iu"> T </strong> erm <strong class="la iu"> F </strong>频率:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/5af8e894aae885b18708a28666e2c624.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*okmLT1Xj43zWSh0de01kSw.png"/></div></div></figure><p id="cc8e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">而日志部分:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/231c35e1b2a1bc428b9d0c6deaa9df1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:348/format:webp/1*9vcL31tWYYfSgi02VG21IQ.png"/></div></figure><p id="e7d5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">代表<strong class="la iu">I</strong>v<strong class="la iu">D</strong>文件<strong class="la iu"> F </strong>频率。这里的<strong class="la iu">反转</strong>表示该部分将反转词频值，从而给那些频繁使用的词一些低值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/146b57f8266077eebeb87585ba6ab068.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*kG96mOswL1ewP840i2bJDg.png"/></div></figure><p id="8122" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，您总共有100个文档，其中10个包含关键字。那么IDF部分就会是log(D _ all/D _ w)= log(100/10)= log(10)= 2.3(e基数)。如对数曲线所示，关键词在整体上下文中显示的位置越低，产生的IDF值就越高。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/535f2889ab23f170650d3a56d8229412.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/0*gQgibkNBcVAGBW8n.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae nh" href="https://en.wikipedia.org/wiki/Logarithm" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Logarithm</a></p></figure><h2 id="ef2b" class="lu lv it bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">手动计算关键字“evil”的TF-IDF值</h2><p id="4122" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">比方说，我们想获得文档1中关键字<strong class="la iu"> evil </strong>的TF-IDF值(“邪恶的问题”)。</p><p id="8348" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">应该很容易看到<strong class="la iu">恶</strong>出现1次，一共3个字；数据库中的3个文档，其中2个包含<strong class="la iu"> evil </strong>关键字。所以，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/0b1510485ecd57ada8622a3b043aa76c.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*mwSE2N-IVtpoVhiZQkjbLA.png"/></div></figure><p id="38ae" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们一起得到了结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/8db34285e9a1ea570acfa3533c78cdc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*We9jmowfA5OdqKWTk2U9SQ.png"/></div></figure><p id="aca8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在Python中</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="83af" class="lu lv it mu b gy my mz l na nb">import math<br/>tf_1_evil       = 1/3<br/>D_all           = 3<br/>D_evil          = 2<br/>tf_idf_evil     = tf_1_evil * math.log(D_all/D_evil)<br/>print(tf_idf_evil)</span></pre><p id="de93" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">打印结果:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="804f" class="lu lv it mu b gy my mz l na nb">0.135</span></pre><h2 id="1cc4" class="lu lv it bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">通过scikit-learn计算TF-IDF</h2><p id="4ccb" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">Scikit-learn提供了一种快速计算TF-IDF矩阵便捷方法。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="6a62" class="lu lv it mu b gy my mz l na nb">import pandas as pd <br/>from sklearn.feature_extraction.text import TfidfVectorizer<br/>vec = TfidfVectorizer()<br/>text_db = ['problem of evil',<br/>          'evil queen',<br/>          'horizon problem']<br/>tf_idf =  <!-- -->vec<!-- -->.fit_transform(text_db)<br/>print(pd.DataFrame(tf_idf.toarray(), columns=vec.get_feature_names()))</span></pre><p id="6c42" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">结果。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="59bb" class="lu lv it mu b gy my mz l na nb">   evil   horizon        of   problem     queen<br/>0  <strong class="mu iu">0.517856</strong>  0.000000  0.680919  0.517856  0.000000<br/>1  0.605349  0.000000  0.000000  0.000000  0.795961<br/>2  0.000000  0.795961  0.000000  0.605349  0.000000</span></pre><p id="1388" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">等等，你可能会问，安德鲁，你在跟我开玩笑吗？文件1的<strong class="la iu">恶</strong> TF-IDF值(索引显示为0)为<code class="fe nk nl nm mu b">0.517856</code>。这里出了什么问题？</p><h2 id="fcc3" class="lu lv it bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">与scikit-learn <code class="fe nk nl nm mu b">TfidfVectorizer</code>实施的区别</h2><p id="fda1" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">scikit-learn的<code class="fe nk nl nm mu b">TfidfVectorizer</code>的实现有两个不同之处，使得结果不同于大多数教科书中存在的上述公式，你的教授告诉过你。</p><p id="b051" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，sklearn使用不同版本的<strong class="la iu"> IDF </strong>公式，将<strong class="la iu"> 1s </strong>添加到分子和分母，以避免被零除的情况。<strong class="la iu"> TF </strong>不变。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/f29749c9cd73bd22fbbae14ec9d4682b.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*ckcDta2x-ZskdzvG0gjD-A.png"/></div></figure><p id="5c1c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其次，sklearn在文档级用欧氏范数平滑TF-IDF结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/10784273da6ad61f58b26e922c1ab0de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*nQVx6kHQRgz5B2-7TrI3LA.png"/></div></figure><p id="87f8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在计算第一个文档中的<strong class="la iu">恶</strong>值的情况下(“恶的问题”)，公式为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/8ad1811148dc0f57f922b53e8b2f3530.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*R3AGedZ__S7i0Hs6YqolIA.png"/></div></div></figure><p id="30ce" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们重塑Python代码，以反映上述两个变化:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="46cc" class="lu lv it mu b gy my mz l na nb">import math<br/>tf_1_problem    = 1/3<br/>tf_1_of         = 1/3<br/>tf_1_evil       = 1/3<br/>D_all           = 3<br/>d_problem       = 2<br/>d_of            = 1<br/>d_evil          = 2<br/>tf_idf_problem= tf_1_problem * (math.log((D_all+1)/(d_problem+1))+1)<br/>tf_idf_of       = tf_1_of * (math.log((D_all+1)/(d_of+1))+1)<br/>tf_idf_evil     = tf_1_evil * (math.log((D_all+1)/(d_evil+1))+1)<br/>denominator     = math.sqrt(tf_idf_problem**2 <br/>                            + tf_idf_of**2 + tf_idf_evil**2)<br/>result = tf_idf_evil/denominator<br/>print("evil result:",result)</span></pre><p id="8b09" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">邪恶的TF-IDF值<strong class="la iu">与scikit-learn产生的值</strong>完全相同。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="257c" class="lu lv it mu b gy my mz l na nb">evil result: 0.517856</span></pre><h2 id="6faf" class="lu lv it bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">链接和书籍</h2><ul class=""><li id="740c" class="nq nr it la b lb mn le mo lh ns ll nt lp nu lt nv nw nx ny bi translated">术语特异性的统计解释及其在检索中的应用，</li></ul><p id="6569" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">琼斯在1972年首次提出了TF-IDF的概念。</p><ul class=""><li id="e280" class="nq nr it la b lb lc le lf lh nz ll oa lp ob lt nv nw nx ny bi translated"><a class="ae nh" href="https://jakevdp.github.io/PythonDataScienceHandbook/05.04-feature-engineering.html" rel="noopener ugc nofollow" target="_blank"> Python数据科学手册——特征工程</a>作者杰克·范德普拉斯<br/><a class="ae nh" href="https://jakevdp.github.io/PythonDataScienceHandbook/05.04-feature-engineering.html" rel="noopener ugc nofollow" target="_blank">https://jakevdp . github . io/Python datascience Handbook/05.04——特征工程. html </a></li></ul><p id="9584" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Jake在“特征工程”一章中简要介绍了TF-IDF，他没有深入研究TF-IDF的用法，但他提供了使用scikit-learn计算TF-IDF值的最佳Python代码。本文中使用的包含3个文档的示例文本数据库来自这本书。</p><ul class=""><li id="c2c0" class="nq nr it la b lb lc le lf lh nz ll oa lp ob lt nv nw nx ny bi"><a class="ae nh" href="https://book.douban.com/subject/10750155/" rel="noopener ugc nofollow" target="_blank">数学之美</a> by Wu Jun <a class="ae nh" href="https://book.douban.com/subject/10750155/" rel="noopener ugc nofollow" target="_blank">https://book.douban.com/subject/10750155/</a></li></ul><p id="0f13" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本书由前谷歌研究员、前腾讯副总裁吴军博士用中文撰写。这本书对TF-IDF算法做了很好的介绍。</p><ul class=""><li id="80c7" class="nq nr it la b lb lc le lf lh nz ll oa lp ob lt nv nw nx ny bi translated"><a class="ae nh" rel="noopener" target="_blank" href="/how-sklearns-tf-idf-is-different-from-the-standard-tf-idf-275fa582e73d"> "Sklearn的TF-IDF" vs "Standard TF-IDF" </a>作者siva kar Sivarajah<br/><a class="ae nh" rel="noopener" target="_blank" href="/how-sklearns-tf-idf-is-different-from-the-standard-tf-idf-275fa582e73d">https://towardsdatascience . com/how-sk learns-TF-IDF-is-different-from-the-the-Standard-TF-IDF-275 fa 582 e73d</a></li></ul><p id="32c9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">多亏了Sivakar，这篇文章展示了在scikit-learn from传统教科书中TF-IDF实现的不同之处。</p></div><div class="ab cl oc od hx oe" role="separator"><span class="of bw bk og oh oi"/><span class="of bw bk og oh oi"/><span class="of bw bk og oh"/></div><div class="im in io ip iq"><p id="d61b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Medium不支持LaTex或数学公式输入。把那些数学公式放在一篇文章里是很痛苦的，即使使用复制的图片看起来也很糟糕。在这里，我以纯HTML格式将内容放在一起。</p><p id="761f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae nh" href="http://zhusd.com/understand_tfidf_in_python" rel="noopener ugc nofollow" target="_blank">http://zhusd.com/understand_tfidf_in_python</a></p><p id="aa6c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你看到什么，欢迎评论并纠正我。谢谢你阅读它。</p></div></div>    
</body>
</html>