<html>
<head>
<title>How to Use Variance Thresholding For Robust Feature Selection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用方差阈值进行鲁棒特征选择</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-use-variance-thresholding-for-robust-feature-selection-a4503f2b5c3f?source=collection_archive---------2-----------------------#2021-04-10">https://towardsdatascience.com/how-to-use-variance-thresholding-for-robust-feature-selection-a4503f2b5c3f?source=collection_archive---------2-----------------------#2021-04-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bc5f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">即使删除50个功能，也能获得相同的性能</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6c2bb47454f7eb7abedaaf34b1bc3fa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YVWtZaJADGY5zwDd4UQunw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">照片由</strong> <a class="ae kz" href="https://www.pexels.com/@billelmoula?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> <strong class="bd ky">比勒</strong> </a> <strong class="bd ky">上</strong> <a class="ae kz" href="https://www.pexels.com/photo/black-and-teal-mountain-540518/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> <strong class="bd ky">像素</strong> </a></p></figure><h2 id="ddd1" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">方差阈值特征选择简介</h2><p id="05da" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">如今，数据集拥有数百甚至数千个要素是很常见的。从表面上看，这似乎是一件好事——更多的特性提供了关于每个样本的更多信息。但通常情况下，这些额外的功能并不能提供太多的价值，而且会带来不必要的复杂性。</p><p id="0bda" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">机器学习的最大挑战是通过使用尽可能少的特征来创建具有强大预测能力的模型。但是考虑到当今数据集的庞大规模，很容易忽略哪些特征重要，哪些不重要。</p><p id="b303" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">这就是为什么在ML领域需要学习一整套技能— <strong class="ly iu">特征选择</strong>。特征选择是选择最重要特征的子集，同时试图保留尽可能多的信息的过程。</p><p id="9cce" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">举个例子，假设我们有一个身体测量的数据集，比如体重、身高、身体质量指数等。基本的特征选择技术应该能够通过发现身体质量指数可以用体重和身高来表示而去掉身体质量指数。</p><p id="e409" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">在本文中，我们将探讨一种这样的特征选择技术，称为方差阈值。这种技术是一种快速和轻量级的方法，用于消除方差非常低的特征，即没有太多有用信息的特征。</p><div class="mu mv gp gr mw mx"><a href="https://ibexorigin.medium.com/membership" rel="noopener follow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">通过我的推荐链接加入Medium-BEXGBoost</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">获得独家访问我的所有⚡premium⚡内容和所有媒体没有限制。支持我的工作，给我买一个…</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">ibexorigin.medium.com</p></div></div><div class="ng l"><div class="nh l ni nj nk ng nl ks mx"/></div></div></a></div><p id="536e" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">获得由强大的AI-Alpha信号选择和总结的最佳和最新的ML和AI论文:</p><div class="mu mv gp gr mw mx"><a href="https://alphasignal.ai/?referrer=Bex" rel="noopener  ugc nofollow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">阿尔法信号|机器学习的极品。艾总结的。</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">留在循环中，不用花无数时间浏览下一个突破；我们的算法识别…</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">alphasignal.ai</p></div></div><div class="ng l"><div class="nm l ni nj nk ng nl ks mx"/></div></div></a></div></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="f1bc" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">关于方差的一个注记</h2><p id="ef5b" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">对于那些不熟悉的人来说，<em class="nu">方差</em>顾名思义，表示单个度量中分布的可变性。它显示了分布是如何展开的，并显示了与平均值的平均平方距离:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl nv"><img src="../Images/c145b6e4527a82777052a6d2bcae47c2.png" data-original-src="https://miro.medium.com/v2/format:webp/1*c-VM3QCk-WrHg62q1eE_ug.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="d768" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">显然，值越大的分布产生的方差越大，因为每个差值都是平方的。但是我们在ML中关心的主要事情是分布实际上包含有用的信息。例如，考虑这样的分布:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="b9a3" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">用Numpy计算方差向我们展示了这个分布的方差为零，或者说完全没有用。使用零方差特征只会增加模型的复杂性，而不会增加其预测能力。再考虑一个:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="322e" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">同样，这个几乎是由一个常数组成的。除了少数例外，围绕单个常数的分布也是无用的。换句话说，任何方差接近于0的特性或分布都应该被丢弃。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="9236" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">如何使用Scikit-learn的变量阈值估计器</h2><p id="b10a" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">手动计算方差并设定阈值可能需要大量的工作。幸运的是，Scikit-learn提供了<code class="fe ny nz oa ob b">VarianceThreshold</code>估算器，它可以为我们做所有的工作。只要超过一个临界值，低于该临界值的所有要素都将被丢弃。</p><p id="ce30" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">为了演示<code class="fe ny nz oa ob b">VarianceThreshold</code>，我们将使用<a class="ae kz" href="https://www.kaggle.com/seshadrikolluri/ansur-ii" rel="noopener ugc nofollow" target="_blank">Ansur数据集</a>。这个数据集以各种可以想象的方式记录了人体的尺寸。男性和女性数据集包含近6000名(4000名男性，2000名女性)美国陆军人员的108个特征或测量值。我们将关注男性数据集:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl nv"><img src="../Images/0db2f3f2ddb6fa71560515587d95db3a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*lA-Pz7UdZZeZhDk7Wy02yg.png"/></div></figure><p id="9e4b" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">首先，让我们去掉零方差的特征。我们将从<code class="fe ny nz oa ob b">sklearn.feature_selection</code>进口<code class="fe ny nz oa ob b">VarianceThreshold</code>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="77ef" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">我们初始化它就像任何其他Scikit-learn估计器一样。阈值的默认值始终为0。此外，估计器显然只对数字数据起作用，如果数据帧中存在分类特征，就会产生错误。这就是为什么现在我们将数字特征划分到另一个数据帧中的原因:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="eed1" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">所以，我们有98个数字特征。现在让我们将估计值与数据进行拟合，并获得结果:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="8ca2" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">直接调用<code class="fe ny nz oa ob b">fit_transform</code>将把数据帧作为一个<code class="fe ny nz oa ob b">numpy</code>数组返回，去掉一些特性。但是有时，我们不希望结果是这种格式，因为列名会被删除。考虑替代方案:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="3773" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">首先，我们将估计器与数据进行拟合，并调用它的<code class="fe ny nz oa ob b">get_support()</code>方法。它为没有被删除的列返回一个带有<code class="fe ny nz oa ob b">True</code>值的布尔掩码。然后，我们可以使用此掩码来划分数据帧的子集，如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="d4e9" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">让我们检查数据帧的形状，看看是否有任何常量列:</p><pre class="kj kk kl km gt oc ob od oe aw of bi"><span id="321b" class="la lb it ob b gy og oh l oi oj">&gt;&gt;&gt; ansur_male_num.shape</span><span id="694f" class="la lb it ob b gy ok oh l oi oj">(4082, 98)</span></pre><p id="95a1" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">不，我们仍然有相同数量的功能。现在，让我们去掉方差接近于0的特性:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="bff2" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">当<code class="fe ny nz oa ob b">threshold</code>为1时，只有1个特性被删除。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="c922" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">使用特征标准化进行更公平的方差比较</h2><p id="8f76" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">通常，比较一个特性与另一个特性的差异是不公平的。原因是随着分布中的值变大，方差呈指数增长。换句话说，方差不会在同一个尺度上。考虑这个例子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/a0494824a45a5a1f0d989a3a1785fc1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*QezNsmH18r4yhCaSH3cPRA.png"/></div></figure><p id="e1b4" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">上述特征都有不同的中位数、四分位数和范围-完全不同的分布。我们无法将这些特征相互比较。</p><p id="c953" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">我们可以使用的一种方法是通过将所有特征除以它们的平均值来归一化它们:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl nv"><img src="../Images/1d8de9af8dca96994017dc599a9b48b3.png" data-original-src="https://miro.medium.com/v2/format:webp/1*oFET8orbi2SDZrM1qsTuJg.png"/></div></figure><p id="cbd6" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">这种方法确保所有方差都在相同的范围内:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="380c" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">现在，我们可以使用阈值较低的估计值，如0.005或0.003:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="82c4" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">如您所见，我们能够从数据集中删除50个要素。现在，让我们通过放弃这么多特性来测试我们是否做了正确的事情。</p><p id="9f9a" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">我们将通过训练两个RandomForestRegressor来预测一个人的体重(以磅为单位)来检查这一点:第一个在最终的要素选择数据集上，第二个在完整的仅包含数字要素的数据集上。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="ba85" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">训练和测试分数都显示了一个真正的高性能，而没有过度拟合。现在，让我们在全数字数据集上训练相同的模型:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="438f" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">如你所见，即使去掉50个特性，我们也能构建一个非常强大的模型。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><h2 id="2d31" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">结论</h2><p id="1420" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">尽管方差阈值化是一种简单的方法，但在执行特征选择时，它可以走很长的路。但是，请记住，这种技术没有考虑特征之间的关系或特征与目标之间的联系。因此，要像使用RandomForestRegressor一样，反复检查使用VT是否带来了性能提升，或者至少降低了模型的复杂性。</p><p id="23ff" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">此外，查看Scikit-learn关于特性选择的<a class="ae kz" href="https://scikit-learn.org/stable/modules/feature_selection.html#variance-threshold" rel="noopener ugc nofollow" target="_blank">官方用户指南</a>——在那里，您可以了解如何在<a class="ae kz" rel="noopener" target="_blank" href="/how-to-use-sklearn-pipelines-for-ridiculously-neat-code-a61ab66ca90d">管道实例</a>中插入VT估算器。该指南还包含其他特征选择技术的信息。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="583b" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">如果你不知道接下来要读什么，这里，我为你挑选了一些:</p><p id="8252" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/beginners-guide-to-xgboost-for-classification-problems-50f75aac5390">https://towards data science . com/beginners-guide-to-xgboost-for-class ification-problems-50 f 75 AAC 5390</a></p><p id="3500" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/11-times-faster-hyperparameter-tuning-with-halvinggridsearch-232ed0160155">https://towards data science . com/11-times-faster-hyperparameter-tuning-with-halvinggridsearch-232 ed 0160155</a></p><p id="1cb3" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/intro-to-scikit-learns-k-nearest-neighbors-classifier-and-regressor-4228d8d1cba6">https://towards data science . com/intro-to-sci kit-learns-k-nearest-neighbors-classifier-and-regressor-4228 D8 D1 CBA 6</a></p></div></div>    
</body>
</html>