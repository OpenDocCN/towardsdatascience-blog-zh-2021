<html>
<head>
<title>The Machine Learning Web — Pose and Actions Estimator — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习网络——姿态和动作估计器——第1部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-machine-learning-web-pose-and-actions-estimator-3203a0cf5f60?source=collection_archive---------9-----------------------#2021-07-09">https://towardsdatascience.com/the-machine-learning-web-pose-and-actions-estimator-3203a0cf5f60?source=collection_archive---------9-----------------------#2021-07-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="bb13" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">实时姿态估计web应用程序</h2></div><p id="30e8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我想我们都同意2020年是疯狂的一年。为了保持头脑清醒，我决定恢复一个老项目，这个项目是我很久以前和<a class="lb lc ep" href="https://medium.com/u/4a54c45de2a6?source=post_page-----3203a0cf5f60--------------------------------" rel="noopener" target="_blank"> Omer Mintz </a>一起使用PoseNet进行姿态估计的。</p><p id="8d5d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在恢复这个项目时，我想实现的目标变得很清楚:一个姿势和动作估计web应用程序，它依赖于机器学习能力来“学习”新动作，而不牺牲性能。</p><p id="9fe5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">结果呢？嗯，你可以<a class="ae ld" href="https://boostup-app.herokuapp.com/" rel="noopener ugc nofollow" target="_blank">看到自己</a>。</p><p id="89d7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">代码也在这个<a class="ae ld" href="https://github.com/o-b-one/pose-estimator" rel="noopener ugc nofollow" target="_blank"> Git仓库</a>上共享。</p><h1 id="5e0b" class="le lf iq bd lg lh li lj lk ll lm ln lo jw lp jx lq jz lr ka ls kc lt kd lu lv bi translated">TL；速度三角形定位法(dead reckoning)</h1><p id="c3fd" class="pw-post-body-paragraph kf kg iq kh b ki lw jr kk kl lx ju kn ko ly kq kr ks lz ku kv kw ma ky kz la ij bi translated">我们使用由PoseNet预训练模型提供的数据输出，并应用一些数据工程。借助于一些数据探索，我们发现KNN机器算法可以很好地对结果进行分类。最终结果——一个评估参与者正在进行的锻炼的系统。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h1 id="6526" class="le lf iq bd lg lh mi lj lk ll mj ln lo jw mk jx lq jz ml ka ls kc mm kd lu lv bi translated">目标</h1><ul class=""><li id="ac83" class="mn mo iq kh b ki lw kl lx ko mp ks mq kw mr la ms mt mu mv bi translated">一个web应用程序，知道如何估计参与者发现什么姿势(站，蹲，俯卧撑)。</li><li id="a5ad" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">计算参与者重复做了多少次。</li><li id="7694" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">高性能-渲染周期之间的延迟应该最小。<br/>应用程序的交互性不应受到影响。</li><li id="e658" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">易于扩展——可以学习新的动作，只需很少的改动</li><li id="a47f" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">文本到语音转换—附加功能</li></ul><h1 id="2108" class="le lf iq bd lg lh li lj lk ll lm ln lo jw lp jx lq jz lr ka ls kc lt kd lu lv bi translated">堆栈</h1><ul class=""><li id="4019" class="mn mo iq kh b ki lw kl lx ko mp ks mq kw mr la ms mt mu mv bi translated">使用TensorFlow和NumPy的Python我们需要一种应用ed a和训练模型的方法。</li><li id="8382" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">React —用于渲染和交互式web应用程序。</li><li id="4283" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">张量流。JS—在浏览器上运行训练好的模型和ML算法。</li><li id="fd84" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">画布—图像渲染和修改。</li><li id="9692" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">Web Workers—为了提高性能，以免主线程过载。</li></ul><p id="d882" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了进行姿态检测，我使用了基于RestNet50架构的预训练模型<a class="ae ld" href="https://www.tensorflow.org/lite/examples/pose_estimation/overview" rel="noopener ugc nofollow" target="_blank"> PoseNet </a>。</p><p id="144a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个预先训练好的模型允许我们从图像中捕捉人的部分，稍后，它将被用于估计动作。</p><h1 id="16df" class="le lf iq bd lg lh li lj lk ll lm ln lo jw lp jx lq jz lr ka ls kc lt kd lu lv bi translated">波塞尼特</h1><p id="348c" class="pw-post-body-paragraph kf kg iq kh b ki lw jr kk kl lx ju kn ko ly kq kr ks lz ku kv kw ma ky kz la ij bi translated">PoseNet是在计算机视觉下建立的用于姿势估计的预训练模型。<br/>pose net模型检测图像和视频中的人物，并提供确定在帧中发现的人的不同部分的能力。</p><p id="0a6d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">PoseNet库处理以下内容:</p><ul class=""><li id="fb81" class="mn mo iq kh b ki kj kl km ko nb ks nc kw nd la ms mt mu mv bi translated">数据预处理(裁剪和调整大小，缩放像素值)</li><li id="4dcb" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">使用TensorFlow对给定数据应用模型。</li><li id="de57" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">从结果中解码关键点。</li><li id="d80d" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">计算每个部分和整个姿势的置信度得分。</li></ul><h2 id="fabe" class="ne lf iq bd lg nf ng dn lk nh ni dp lo ko nj nk lq ks nl nm ls kw nn no lu np bi translated">输入</h2><p id="5335" class="pw-post-body-paragraph kf kg iq kh b ki lw jr kk kl lx ju kn ko ly kq kr ks lz ku kv kw ma ky kz la ij bi translated">PoseNet模型将经过处理的摄像机图像作为输入。<br/>为了更好的性能，我们将使用224 X 224像素的帧，这将允许我们处理和处理更少的数据。</p><p id="1afc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="nq">提醒PoseNet库将应用另一个大小调整(如前一节所述)。</em></p><h2 id="55a8" class="ne lf iq bd lg nf ng dn lk nh ni dp lo ko nj nk lq ks nl nm ls kw nn no lu np bi translated">输出</h2><p id="f92f" class="pw-post-body-paragraph kf kg iq kh b ki lw jr kk kl lx ju kn ko ly kq kr ks lz ku kv kw ma ky kz la ij bi translated">具有以下内容的对象:</p><ol class=""><li id="8fa2" class="mn mo iq kh b ki kj kl km ko nb ks nc kw nd la nr mt mu mv bi translated">分数——姿势的总体置信度分数</li><li id="91d1" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la nr mt mu mv bi translated">关键点—17个元素的列表，每个元素确定不同关键点(零件)的结果，这些关键点由x和y位置、零件名称和分数标识</li></ol><pre class="ns nt nu nv gt nw nx ny nz aw oa bi"><span id="105a" class="ne lf iq nx b gy ob oc l od oe">{<br/>  score: float;<br/>  keypoints: Array&lt;{ // Array of the 17 keypoints identified<br/>    position: {x: float, y: float};<br/>    part: EBodyParts; // the keys of the enum<br/>    score: float;<br/>  }&gt;<br/>}</span><span id="f4e8" class="ne lf iq nx b gy of oc l od oe">enum EBodyParts {<br/>  nose,<br/>  leftEye,<br/>  rightEye,<br/>  leftEar,<br/>  rightEar,<br/>  leftShoulder,<br/>  rightShoulder,<br/>  leftElbow,<br/>  rightElbow,<br/>  leftWrist,<br/>  rightWrist,<br/>  leftHip,<br/>  rightHip,<br/>  leftKnee,<br/>  rightKnee,<br/>  leftAnkle,<br/>  rightAnkle<br/>}</span></pre><h2 id="d7d6" class="ne lf iq bd lg nf ng dn lk nh ni dp lo ko nj nk lq ks nl nm ls kw nn no lu np bi translated">配置</h2><p id="2e8b" class="pw-post-body-paragraph kf kg iq kh b ki lw jr kk kl lx ju kn ko ly kq kr ks lz ku kv kw ma ky kz la ij bi translated">我为PoseNet使用的配置是</p><pre class="ns nt nu nv gt nw nx ny nz aw oa bi"><span id="c7bc" class="ne lf iq nx b gy ob oc l od oe">architecture: 'ResNet50'<br/>outputStride: 16<br/>quantBytes: 4<br/>inputResolution: {width: 224, height: 224}</span></pre><ul class=""><li id="9d83" class="mn mo iq kh b ki kj kl km ko nb ks nc kw nd la ms mt mu mv bi translated">架构— ResNet50或MobileNet v1</li><li id="b67f" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">输出步幅—输出步幅决定了我们相对于输入图像大小缩小输出的程度。它影响层的大小和模型输出。输出跨度越大，网络和输出中各层的分辨率越小，相应地其精度也越低。在该实现中，输出步幅可以具有8、16或32的值。换句话说，输出步幅为32时，性能最快，但精度最低；输出步幅为8时，精度最高，但性能最慢。我的配置中的<br/><code class="fe og oh oi nx b">Resolution = ((InputImageSize - 1) / OutputStride) + 1<br/></code><code class="fe og oh oi nx b">Resolution = ((224- 1) / 16) + 1 = 14.9375</code></li></ul><figure class="ns nt nu nv gt ok gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/7fece75a61085df9d501e6db752eca5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/0*n5wZnADL_ZqKjFIt.png"/></div></figure><h2 id="2c25" class="ne lf iq bd lg nf ng dn lk nh ni dp lo ko nj nk lq ks nl nm ls kw nn no lu np bi translated">ResNet50</h2><p id="d568" class="pw-post-body-paragraph kf kg iq kh b ki lw jr kk kl lx ju kn ko ly kq kr ks lz ku kv kw ma ky kz la ij bi translated">PoseNet允许我们使用两种模型架构之一:</p><ol class=""><li id="ae76" class="mn mo iq kh b ki kj kl km ko nb ks nc kw nd la nr mt mu mv bi translated">Mobilenet v1</li><li id="0ffc" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la nr mt mu mv bi translated">ResNet50</li></ol><p id="7f06" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">PoseNet官方文档提到，Mobilenet v1比ResNet50架构更小更快，精度更低，resnet 50架构更大更慢，但精度更高。</p><p id="77a7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了更好地理解这两篇文章之间的区别，我强烈建议回顾这两篇文章:</p><ul class=""><li id="a1d3" class="mn mo iq kh b ki kj kl km ko nb ks nc kw nd la ms mt mu mv bi translated"><a class="ae ld" href="https://iq.opengenus.org/mobilenet-architecture/" rel="noopener ugc nofollow" target="_blank">移动互联网V1架构</a></li><li id="59e0" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated"><a class="ae ld" href="https://iq.opengenus.org/resnet50-architecture/" rel="noopener ugc nofollow" target="_blank"> ResNet50架构</a></li></ul><h1 id="0f58" class="le lf iq bd lg lh li lj lk ll lm ln lo jw lp jx lq jz lr ka ls kc lt kd lu lv bi translated">从姿势到动作</h1><p id="cb27" class="pw-post-body-paragraph kf kg iq kh b ki lw jr kk kl lx ju kn ko ly kq kr ks lz ku kv kw ma ky kz la ij bi translated">为了将这些关键点(X和Y坐标)转化为行动，我们将需要在这里应用更多的统计能力，因此，我决定使用聚类算法。更准确地说，是KNN算法</p><h2 id="f33a" class="ne lf iq bd lg nf ng dn lk nh ni dp lo ko nj nk lq ks nl nm ls kw nn no lu np bi translated">数据</h2><p id="b164" class="pw-post-body-paragraph kf kg iq kh b ki lw jr kk kl lx ju kn ko ly kq kr ks lz ku kv kw ma ky kz la ij bi translated"><em class="nq">“信息是21世纪的石油，分析是内燃机。”SVP高德纳公司的彼得·桑德加德在2011年说道。</em></p><p id="7544" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们被数据平台所包围。<br/>数据就躺在那里，等着我们去拾起、清理和使用。</p><p id="8e16" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当然，这个“捡起来”和“清理掉”的任务并不那么简单，工程师和数据科学努力获取好的数据来训练他们的模型。<br/>我喜欢把它比作使用金属探测器的沙滩寻宝；你周围有许多金属物品，但在极少数情况下，你会发现一个真正的宝藏。</p><p id="6b13" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我的海滩是youtube。更具体地说，youtube上的个人训练视频，你可以和教练一起用同样的姿势训练。如此多的姿势，现在所需要的就是将视频分解成帧，并将它们分类成正确的姿势(例如，站立、蹲下、俯卧撑、下推)</p><p id="de82" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了将视频分解成帧，我使用了以下简单的python代码:</p><pre class="ns nt nu nv gt nw nx ny nz aw oa bi"><span id="5c03" class="ne lf iq nx b gy ob oc l od oe">import os<br/>import cv2</span><span id="d84d" class="ne lf iq nx b gy of oc l od oe">def video_to_frames(video_path: str, destination: str):<br/>    if not os.path.exists(os.path.join(os.getcwd(),'output')):<br/>        os.mkdir(os.path.join(os.getcwd(),'output'))<br/>    if not os.path.exists(destination):<br/>        os.mkdir(destination)</span><span id="41e7" class="ne lf iq nx b gy of oc l od oe">    vid = cv2.VideoCapture(file_path)<br/>    success,image = vid.read() # read the first image<br/>    count = 0<br/>    while success: # in case there are more images - proceed<br/>        cv2.imwrite(os.path.join(destination,f'frame{count}.jpg'), image) # write the image to the destination directory<br/>        success,image = vid.read() # read the next image<br/>        count += 1</span></pre><p id="52b2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们提取帧之后，我们可以做一些分类工作。这项工作主要要求我们将文件移动到姿势的正确目录中——是“蹲”还是“站”的姿势。</p><p id="5a50" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们已经完全准备好了我们的训练集，是时候训练我们的模型了。</p><p id="92f2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对图像进行分类后，我们现在可以继续进行模型训练阶段。但是首先，我们需要考虑如何处理这些数据。</p><p id="264c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们知道我们有一个分类问题，我们有一组想要输出到单个类的要素。</p><p id="31fa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些选项包括:</p><ol class=""><li id="c20c" class="mn mo iq kh b ki kj kl km ko nb ks nc kw nd la nr mt mu mv bi translated">深度学习分类:<br/>使用深度学习进行分类是现在的趋势，我们可以设置训练-测试集来识别姿势。像YOLO模型这样的东西可以帮助我们识别图像是蹲下、站立、俯卧撑，例如<br/>这里的主要问题是，它需要我们大量的图像来训练，非常高的计算能力，并且可能会导致我们的预测置信度较低(对于F1 &amp;的准确性分数)。</li><li id="31c7" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la nr mt mu mv bi translated">PoseNet结果之上的机器学习聚类算法:<br/>我们已经有了一个非常坚实的模型来识别参与者的不同身体部位。在这种情况下，我们可以获取一个图像，并将其转换为表格模型，但身体部位的X和Y位置并不那么有用，但它仍然是一个开始。</li></ol><p id="157b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将进行第二种选择。<br/>现在我们需要为聚类算法准备我们的特征。这意味着，我们需要角度，而不是用不同身体部位的X和Y位置。<br/>这需要将基本的三角学公式从我的脑海中唤醒:</p><ul class=""><li id="c570" class="mn mo iq kh b ki kj kl km ko nb ks nc kw nd la ms mt mu mv bi translated">将x和y点转换为线条</li></ul><figure class="ns nt nu nv gt ok gh gi paragraph-image"><div role="button" tabindex="0" class="oo op di oq bf or"><div class="gh gi on"><img src="../Images/be5082aaffb74101e88afb238f2095bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wepqA6H4kfQeQuCgEjWqKA.png"/></div></div></figure><ul class=""><li id="9723" class="mn mo iq kh b ki kj kl km ko nb ks nc kw nd la ms mt mu mv bi translated">计算线的顶角:</li></ul><p id="d93b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">左腋窝角</strong> —利用左肩、左肘、左臀<br/> <strong class="kh ir">右腋窝角</strong> —利用右肩、右肘、右臀<br/> <strong class="kh ir">左肩角</strong> —利用左肩、右肩、左臀<br/> <strong class="kh ir">右肩角</strong> —利用右肩、左肩、右臀<br/> <strong class="kh ir">左肘角</strong> —利用左肘、左肩、 和左腕<br/> <strong class="kh ir">右肘角度</strong> —利用右肘、右肩、右腕<br/> <strong class="kh ir">左臀角度</strong> —利用左臀、右臀、左肩<br/> <strong class="kh ir">右臀角度</strong> —利用右臀、左臀、右肩<br/> <strong class="kh ir">左腹股沟角度</strong> —利用左臀、左膝、左脚踝<br/> <strong class="kh ir">右腹股沟角度</strong> —利用右臀、右 右脚踝<br/> <strong class="kh ir">左膝盖角度</strong> —使用左膝盖、左脚踝和左臀部，<br/> <strong class="kh ir">右脚踝角度</strong> —使用右膝盖、右脚踝和右臀部</p><figure class="ns nt nu nv gt ok gh gi paragraph-image"><div role="button" tabindex="0" class="oo op di oq bf or"><div class="gh gi os"><img src="../Images/f226ff5e3a17bb810f654e7a7f8a2cac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nicECo1u__YLs_RvEea1QA.png"/></div></div></figure><ul class=""><li id="a05a" class="mn mo iq kh b ki kj kl km ko nb ks nc kw nd la ms mt mu mv bi translated">以弧度计算一个人姿势的斜率，这将有助于我们识别这个人是处于垂直位置还是水平位置。</li></ul><figure class="ns nt nu nv gt ok gh gi paragraph-image"><div role="button" tabindex="0" class="oo op di oq bf or"><div class="gh gi ot"><img src="../Images/913e187d476c17aa15f015a2fb496a67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y6kQwo1MRosj4gYsxATbJw.png"/></div></div><p class="ou ov gj gh gi ow ox bd b be z dk translated">最小斜率(斜率1，斜率2)被发现可以识别人的真实状态——整个身体的斜率，而不仅仅是身体的一部分</p></figure><p id="b55d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这使得我们能够得到这个数据集。</p><h2 id="e631" class="ne lf iq bd lg nf ng dn lk nh ni dp lo ko nj nk lq ks nl nm ls kw nn no lu np bi translated">培训</h2><p id="1508" class="pw-post-body-paragraph kf kg iq kh b ki lw jr kk kl lx ju kn ko ly kq kr ks lz ku kv kw ma ky kz la ij bi translated">在我们准备好数据集后，我们可以使用PCA进行一些分析，以获得主成分的可视化，这将有助于我们更加确定分类过程的成功率，并确定哪种算法最适合。</p><p id="e0ca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里是PCA 的<a class="ae ld" href="https://colab.research.google.com/drive/1LXxPzKJ37bA4Ptdb0Re-OGrqnX9ePGqN" rel="noopener ugc nofollow" target="_blank"> google colab项目，感谢</a><a class="lb lc ep" href="https://medium.com/u/940dad46ae8f?source=post_page-----3203a0cf5f60--------------------------------" rel="noopener" target="_blank"> Ethel V </a>帮助设置和微调功能。</p><figure class="ns nt nu nv gt ok gh gi paragraph-image"><div role="button" tabindex="0" class="oo op di oq bf or"><div class="gh gi oy"><img src="../Images/aafc1be3eaf73e66ae4e2d1e53524d80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zVT4e5VurofWnetJ0Gc-Lw.png"/></div></div></figure><p id="6c11" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们所看到的，集群是非常明显的分类(除了蹲和站在有一些工作要做的地方)。<br/>我决定和KNN一起去应用分类。</p><p id="4758" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">KNN-k-最近邻，一种适用于分类和回归问题的监督统计算法，用于机器学习。</p><h2 id="85f6" class="ne lf iq bd lg nf ng dn lk nh ni dp lo ko nj nk lq ks nl nm ls kw nn no lu np bi translated">KNN流</h2><ol class=""><li id="811f" class="mn mo iq kh b ki lw kl lx ko mp ks mq kw mr la nr mt mu mv bi translated">加载数据并初始化K个邻居</li><li id="8309" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la nr mt mu mv bi translated">对于数据中的每个示例:</li></ol><ul class=""><li id="a7f7" class="mn mo iq kh b ki kj kl km ko nb ks nc kw nd la ms mt mu mv bi translated">计算数据集中的当前记录与查询示例之间的距离。</li><li id="485d" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">将示例的距离和索引添加到集合中</li></ul><p id="236c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">3.按距离从小到大对距离和索引集合进行排序。</p><p id="586c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">4.从排序的集合中挑选前K个条目</p><p id="8694" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">6.获取所选K个条目的标签</p><p id="8a17" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">7.结果:</p><ul class=""><li id="414b" class="mn mo iq kh b ki kj kl km ko nb ks nc kw nd la ms mt mu mv bi translated">在回归的情况下—返回K个标签的平均值。</li><li id="4bbf" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">在分类的情况下—返回K标签的模式。</li></ul><p id="46a0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">KNN符合我们的感谢:</p><ul class=""><li id="2fcd" class="mn mo iq kh b ki kj kl km ko nb ks nc kw nd la ms mt mu mv bi translated">清晰的类别分组——在大多数情况下，我们可以很容易地识别类别组。</li><li id="77c6" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">一些异常值需要更复杂的处理——KNN比其他分类算法(如SVM)更好地处理更复杂的数据结构，尤其是非线性的数据结构。</li><li id="599d" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">我们数据集中的少量记录—基于神经网络的解决方案将需要</li><li id="4cd5" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated">计算复杂性——与神经网络相比，KNN在训练/评估时间上需要更少的计算能力。<br/>此外，由于我们可以选择的类数量很少，数据集中只有几百条记录，因此我们的性能不会大幅下降。</li></ul><h2 id="721d" class="ne lf iq bd lg nf ng dn lk nh ni dp lo ko nj nk lq ks nl nm ls kw nn no lu np bi translated">使用案例</h2><p id="ec82" class="pw-post-body-paragraph kf kg iq kh b ki lw jr kk kl lx ju kn ko ly kq kr ks lz ku kv kw ma ky kz la ij bi translated">使用KNN，我们将使用角度和斜率对正确的动作进行分类。<br/>稍后，通过web应用程序，我们将使用不同的动作组合来确定参与者进行的练习。</p><p id="0b1b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将在下一章回顾这一点以及更多。</p><p id="ac4d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">希望你喜欢这篇文章，敬请关注😊</p><h2 id="67a8" class="ne lf iq bd lg nf ng dn lk nh ni dp lo ko nj nk lq ks nl nm ls kw nn no lu np bi translated">链接</h2><ul class=""><li id="eb49" class="mn mo iq kh b ki lw kl lx ko mp ks mq kw mr la ms mt mu mv bi translated"><a class="ae ld" href="https://boostup-app.herokuapp.com/" rel="noopener ugc nofollow" target="_blank">演示应用</a></li><li id="3366" class="mn mo iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated"><a class="ae ld" href="https://github.com/o-b-one/pose-estimator" rel="noopener ugc nofollow" target="_blank"> Git仓库</a></li></ul></div></div>    
</body>
</html>