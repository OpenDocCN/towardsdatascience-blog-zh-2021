<html>
<head>
<title>RFM Segmentation in E-Commerce</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">电子商务中的RFM细分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/rfm-segmentation-in-e-commerce-e0209ce8fcf6?source=collection_archive---------13-----------------------#2021-05-14">https://towardsdatascience.com/rfm-segmentation-in-e-commerce-e0209ce8fcf6?source=collection_archive---------13-----------------------#2021-05-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/ccb4ee13349dbff52a9d563d35e48856.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w8mMLXQ8HaI-aon_HSlOEg.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">照片来自<a class="ae jd" href="http://pixabay.com" rel="noopener ugc nofollow" target="_blank">pixabay.com</a></p></figure><div class=""/><div class=""><h2 id="0fbc" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">实用的RFM教程，包含详细的数据预处理步骤和业务操作项</h2></div><p id="d178" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi lr translated"><span class="l ls lt lu bm lv lw lx ly lz di">如果</span>你是一名对无监督学习的商业应用——尤其是聚类——感兴趣的数据从业者，你应该熟悉RFM分割。</p><p id="5914" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">RFM细分是一种众所周知的基于三个用户特征的用户细分策略:</p><ol class=""><li id="6dc9" class="ma mb jg kx b ky kz lb lc le mc li md lm me lq mf mg mh mi bi translated">Recency (R):用户最近一次交易是什么时候？</li><li id="099e" class="ma mb jg kx b ky mj lb mk le ml li mm lm mn lq mf mg mh mi bi translated">频率(F):客户多久交易一次？</li><li id="676c" class="ma mb jg kx b ky mj lb mk le ml li mm lm mn lq mf mg mh mi bi translated">货币(M):用户的交易规模是多少？</li></ol><p id="38cf" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以使用这种技术来更深入地了解我们的用户群，让我们能够提出(更重要的是，回答)以下重要问题:</p><ul class=""><li id="8833" class="ma mb jg kx b ky kz lb lc le mc li md lm me lq mo mg mh mi bi translated">我们为用户提供了多少种不同的RFM细分市场？每个细分市场有哪些独特的高级特征？(通过回答这些问题，我们可以确定可用于最大化每个细分市场收入的业务杠杆)</li><li id="5c21" class="ma mb jg kx b ky mj lb mk le ml li mm lm mn lq mo mg mh mi bi translated">每个RFM片段的百分比是多少？(回答这个问题有助于判断机会)</li></ul><p id="bb02" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">鉴于这种方法明显的潜在好处，在互联网上有大量关于RFM分割的资源也就不足为奇了。也就是说，我似乎找不到一个关于如何创建RFM分割的好教程。我的结果表明，教程要么</p><ol class=""><li id="2ba8" class="ma mb jg kx b ky kz lb lc le mc li md lm me lq mf mg mh mi bi translated">提供的数据预处理措施不充分，无法真正适用于真实的业务环境。</li><li id="61aa" class="ma mb jg kx b ky mj lb mk le ml li mm lm mn lq mf mg mh mi bi translated">或者，没有对收集的细分市场进行适当的业务分析，导致没有可操作的步骤来跟进这项工作(我认为这应该是构建RFM细分市场的首要目标)</li></ol><p id="3886" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">考虑到这一点，我决定写这篇教程。将涵盖以下主题:</p><ul class=""><li id="3048" class="ma mb jg kx b ky kz lb lc le mc li md lm me lq mo mg mh mi bi translated">具有现实(商业)考虑的详细数据预处理</li><li id="1ee9" class="ma mb jg kx b ky mj lb mk le ml li mm lm mn lq mo mg mh mi bi translated">进行K-均值聚类(RFM分段的引擎)的最佳实践，包括特征标准化和确定最佳K(聚类/分段的数量)。</li><li id="2a37" class="ma mb jg kx b ky mj lb mk le ml li mm lm mn lq mo mg mh mi bi translated">对收集的RFM细分市场进行实际分析，以便我们能够采取适当的业务行动，以及后续行动的机会大小。</li></ul><p id="6256" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们开始旅行吧，别再废话了！</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="2d4c" class="mw mx jg bd my mz na nb nc nd ne nf ng km nh kn ni kp nj kq nk ks nl kt nm nn bi translated">数据</h1><p id="3d34" class="pw-post-body-paragraph kv kw jg kx b ky no kh la lb np kk ld le nq lg lh li nr lk ll lm ns lo lp lq ij bi translated">本文中使用的数据是一个电子商务数据集，可通过<a class="ae jd" href="https://www.kaggle.com/carrie1/ecommerce-data" rel="noopener ugc nofollow" target="_blank">这个链接</a>在Kaggle获得。数据集是交易数据，包含一家英国零售商在2011年的交易。</p><h1 id="9ef1" class="mw mx jg bd my mz nt nb nc nd nu nf ng km nv kn ni kp nw kq nk ks nx kt nm nn bi translated">数据预处理</h1><p id="505e" class="pw-post-body-paragraph kv kw jg kx b ky no kh la lb np kk ld le nq lg lh li nr lk ll lm ns lo lp lq ij bi translated"><strong class="kx jh">导入数据</strong></p><p id="1945" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的旅程从导入数据开始。</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="035f" class="oh mx jg od b gy oi oj l ok ol"># import data<br/>import pandas as pd</span><span id="0518" class="oh mx jg od b gy om oj l ok ol">raw_data = pd.read_csv('data.csv')<br/>raw_data.head()</span></pre><figure class="ny nz oa ob gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi on"><img src="../Images/b9238592f3ed291d8643cab78e276b4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J1UvCNKBAI6LDQA-BcjYJQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">raw_data.head()</p></figure><p id="a465" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以看到数据有八列，但是我们在后面的练习中将只使用其中的一个子集。</p><p id="3318" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">基础数据清理</strong></p><p id="5f90" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">原来，数据在某些列上包含空行，以及重复的行。在这一步，我们想摆脱他们。</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="2a6b" class="oh mx jg od b gy oi oj l ok ol"># check NA/NULL<br/>raw_data.isna().sum()</span></pre><figure class="ny nz oa ob gt is gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/39da4af6453cc476e2029f8240c4ab50.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*drMHl2FQ9CQyIovJQGA32A.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">我们确实在一些列上有空行</p></figure><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="ea97" class="oh mx jg od b gy oi oj l ok ol"># remove NULL<br/>raw_data = raw_data.dropna(axis = 0, how = 'any')</span><span id="07c3" class="oh mx jg od b gy om oj l ok ol"># check duplicates<br/>raw_data.duplicated().sum() # 5225 duplicated rows detected</span><span id="887e" class="oh mx jg od b gy om oj l ok ol"># drop duplicates<br/>raw_data = raw_data.drop_duplicates(ignore_index = True)</span></pre><p id="6247" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">特征工程</strong></p><p id="db2f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这一步至关重要，因为我们开始将原始数据转换为具有适当格式的数据，以供即将到来的聚类算法使用。为此，我们将采取以下措施:</p><ol class=""><li id="06e6" class="ma mb jg kx b ky kz lb lc le mc li md lm me lq mf mg mh mi bi translated">将<code class="fe op oq or od b">InvoiceDate</code>列转换为方便的日期时间格式</li><li id="b0d4" class="ma mb jg kx b ky mj lb mk le ml li mm lm mn lq mf mg mh mi bi translated">通过将<code class="fe op oq or od b">Quantity</code>和<code class="fe op oq or od b">Unitprice</code>相乘来创建<code class="fe op oq or od b">trx_amount</code>列</li><li id="8136" class="ma mb jg kx b ky mj lb mk le ml li mm lm mn lq mf mg mh mi bi translated">将<code class="fe op oq or od b">CustomerID</code>列转换为整数格式</li></ol><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="a7aa" class="oh mx jg od b gy oi oj l ok ol"># convert datetime column format<br/>raw_data.InvoiceDate = pd.to_datetime(raw_data.InvoiceDate)</span><span id="86c1" class="oh mx jg od b gy om oj l ok ol"># create trx_amount col<br/>raw_data['TrxAmount'] = raw_data.Quantity * raw_data.UnitPrice</span><span id="7c42" class="oh mx jg od b gy om oj l ok ol"># include only positive TrxAmount values(exclude credit)<br/>raw_data = raw_data[raw_data['TrxAmount'] &gt; 0]</span><span id="f702" class="oh mx jg od b gy om oj l ok ol"># cast CustomerID column to integer<br/>raw_data.CustomerID = raw_data.CustomerID.astype('int')</span></pre><p id="9634" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有了从上面的代码片段中获得的最新的<code class="fe op oq or od b">raw_data</code>数据帧格式，我们就可以为RFM分割构建一个新的数据帧了。dataframe的关键字是<code class="fe op oq or od b">CustomerID</code>，有三列特性:最近、频率和货币。</p><p id="2c56" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，我们讨论第一个特性:最近性，我认为就所需的预处理而言，这是三个特性中最复杂的。我们将从下面的代码开始。</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="0f09" class="oh mx jg od b gy oi oj l ok ol"># recency (r) df<br/>data_r = raw_data[['InvoiceDate','CustomerID']].groupby('CustomerID')['InvoiceDate'].agg('max').reset_index()</span><span id="4b54" class="oh mx jg od b gy om oj l ok ol">data_r.head()</span></pre><figure class="ny nz oa ob gt is gh gi paragraph-image"><div class="gh gi os"><img src="../Images/02e3158cdf6ff42203b03911b996199a.png" data-original-src="https://miro.medium.com/v2/resize:fit:420/format:webp/1*qbXFcB_klrxY7WBOPAVcMg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">初始最近数据帧:data_r.head()</p></figure><p id="0e4a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将用户最近度定义为自从用户进行最后一次交易已经过去了多长时间(以月为单位)。在这点上，我们首先需要确定我们用于向后计算月份的当前时间参考:我们将它设置为<code class="fe op oq or od b">InvoiceData</code>列的最近值。</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="eed5" class="oh mx jg od b gy oi oj l ok ol"># current time reference<br/>cur_time = data_r.InvoiceDate.max()</span><span id="cbed" class="oh mx jg od b gy om oj l ok ol"># month diff function<br/>def month_diff(cur_time, datetime_val): <br/>    return 12 * (cur_time.year - datetime_val.year) + (cur_time.month - datetime_val.month)</span><span id="b546" class="oh mx jg od b gy om oj l ok ol"># recency month<br/>data_r['Recency'] = data_r.InvoiceDate.apply(lambda datetime_val: month_diff(cur_time, datetime_val))</span></pre><p id="2dd2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其次，如果客户最近一次交易发生在6个月或更久之前，我们会认为他/她绝对是被激怒了，因此，如果交易时间超过6个月，我们就没有兴趣对最近交易值进行编码，因为我们不再拥有有意义的额外信息。换句话说，最近值必须限制在最长6个月。</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="a06b" class="oh mx jg od b gy oi oj l ok ol"># clip max at 6 months backward<br/>data_r.Recency = data_r.Recency.clip(lower = None, upper = 6)</span><span id="7cce" class="oh mx jg od b gy om oj l ok ol"># drop InvoiceDate column<br/>data_r = data_r.drop('InvoiceDate', axis = 1)</span><span id="6174" class="oh mx jg od b gy om oj l ok ol"># head<br/>data_r.head()</span></pre><figure class="ny nz oa ob gt is gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/e4ade73e986b1ea56238be72bfdeb14a.png" data-original-src="https://miro.medium.com/v2/resize:fit:308/format:webp/1*3pdladP0rwmqfKvwDM6Syw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">已处理的最近数据帧:data_r.head()</p></figure><p id="ae6a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们结束了最近的事。现在我们将创建频率和货币特征。因为我们只想要最有意义(非过时)的信息，所以在构建频率和货币特征时，我们只考虑过去6个月的交易:</p><ul class=""><li id="ea6d" class="ma mb jg kx b ky kz lb lc le mc li md lm me lq mo mg mh mi bi translated">频率:用户在前六个月完成的交易次数。</li><li id="390b" class="ma mb jg kx b ky mj lb mk le ml li mm lm mn lq mo mg mh mi bi translated">货币:用户在过去六个月的平均交易规模</li></ul><p id="249c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">值得注意的是，从计算的角度来看，这个时间段约束也是有利的。假设你在亚马逊工作，创建RFM细分市场。如果您不限制时间窗口，您将最终使用他们超过二十年的事务日志数据(这在大小上可能太大了)。</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="9831" class="oh mx jg od b gy oi oj l ok ol"># frequency &amp; monetary(fm) df only w.r.t. last 6 months data<br/>EARLIEST_DATE = pd.to_datetime('2011-06-09')<br/>data_fm = raw_data[raw_data.InvoiceDate &gt;= EARLIEST_DATE]<br/>data_fm = data_fm[['InvoiceNo','CustomerID','TrxAmount']]</span><span id="0387" class="oh mx jg od b gy om oj l ok ol">data_fm = data_fm.groupby('CustomerID')[['InvoiceNo','TrxAmount']].agg({'InvoiceNo':'nunique', 'TrxAmount':'mean'}).reset_index()<br/>data_fm = data_fm.rename(columns = {'InvoiceNo':'Frequency', 'TrxAmount':'Monetary'})<br/>data_fm.Monetary = data_fm.Monetary.round(2)<br/>data_fm.head()</span></pre><figure class="ny nz oa ob gt is gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/ef181c828fa33b81df2465159de4a45a.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*eLY7jEeYDRMt7i7H8NNoPQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">频率-货币数据框架:data_fm.head()</p></figure><p id="779c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，我们将近期数据框架(<code class="fe op oq or od b">data_r</code>)与频率&amp;货币数据框架(<code class="fe op oq or od b">data_fm</code>)结合起来，得到我们的最终数据！</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="437e" class="oh mx jg od b gy oi oj l ok ol"># join to have the final data df<br/>data = data_r.merge(data_fm, on = 'CustomerID', how = 'left')<br/>data = data.fillna(0)<br/>data.head()</span></pre><figure class="ny nz oa ob gt is gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/d23f967ad324a69fea0b2c15ecf19633.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/1*2LWEs7H08OZKp3YBwdrE6A.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">最终数据:data.head()</p></figure><h1 id="566f" class="mw mx jg bd my mz nt nb nc nd nu nf ng km nv kn ni kp nw kq nk ks nx kt nm nn bi translated">基于K均值聚类的RFM分割</h1><p id="136e" class="pw-post-body-paragraph kv kw jg kx b ky no kh la lb np kk ld le nq lg lh li nr lk ll lm ns lo lp lq ij bi translated"><strong class="kx jh">标准化栏目</strong></p><p id="b63d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这一步在很多教程中经常被跳过。然而，最佳实践是标准化R-F-M特征，特别是因为货币函数具有货币的度量，这意味着标度与其他特征有很大不同。通过将其标准化，我们确保K-means算法不会高估这个货币函数(即，将它视为比其他特征更重要的特征)。</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="3273" class="oh mx jg od b gy oi oj l ok ol">from sklearn.preprocessing import StandardScaler</span><span id="3678" class="oh mx jg od b gy om oj l ok ol"># feature columns<br/>feature_cols = ['Recency','Frequency','Monetary']</span><span id="4168" class="oh mx jg od b gy om oj l ok ol"># standardized df for training<br/>standardized_data = data.copy()</span><span id="678f" class="oh mx jg od b gy om oj l ok ol"># standardization<br/>scaler = StandardScaler()<br/>scaler.fit(data[feature_cols])<br/>standardized_features = scaler.transform(data[feature_cols])<br/>standardized_data[feature_cols] = standardized_features</span></pre><p id="4874" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">肘法</strong></p><p id="7482" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如你所知，K-means算法中的K(聚类数)是一个超参数。因此，我们必须提前仔细选择它。肘法是最佳选择K的一种常用方法:我们绘制各种K值的误差平方和(SSE ),并选择SSE下降斜率在该值前后显著变化的K值。</p><p id="3d89" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于那些不熟悉SSE的人来说，术语“误差”指的是数据点与其质心之间的偏差/距离。因此SSE是所有数据点的这种平方误差的数量。同样值得注意的是，SSE值总是随着K的增加而减小。</p><p id="a9b2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了继续，我们用十个不同的K(1，2，…，10)拟合K-means算法十次，并保存每个收敛模型的SSE(注意SSE存储在<code class="fe op oq or od b">inertia_</code>属性中)。</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="a198" class="oh mx jg od b gy oi oj l ok ol"># fit K-means clustering on various Ks<br/>from sklearn.cluster import KMeans</span><span id="39ce" class="oh mx jg od b gy om oj l ok ol">kmeans_kwargs = {<br/>    "init" : "random",<br/>    "n_init" : 10<br/>}</span><span id="bbe7" class="oh mx jg od b gy om oj l ok ol">sse = []<br/>for k in range(1,11):<br/>    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)<br/>    kmeans.fit(standardized_data[feature_cols])<br/>    sse.append(kmeans.inertia_)</span></pre><p id="ce86" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们把肘法形象化！</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="b536" class="oh mx jg od b gy oi oj l ok ol"># Elbow method plot<br/>import matplotlib.pyplot as plt</span><span id="c71f" class="oh mx jg od b gy om oj l ok ol">plt.figure(figsize = (12,8))<br/>plt.plot(range(1,11), sse)<br/>plt.xticks(range(1,11))<br/>plt.xlabel("Number of Clusters")<br/>plt.ylabel("Sum of Squared Error")<br/>plt.show()</span></pre><figure class="ny nz oa ob gt is gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/adc0f0376e0458dcabe7ac65771efc0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*Gk0FdM9imSGLL6zeB4bYpA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">不同数量聚类的误差平方和</p></figure><p id="6e21" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">看上面的图，很明显我们可以选择K= 3:观察在这个特定的K值之前和之后斜率的巨大差异。</p><p id="c2a3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">拟合K-表示使用最优K </strong></p><p id="4055" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在知道最佳K是3之后，我们使用这个K值再次拟合算法。</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="edf2" class="oh mx jg od b gy oi oj l ok ol">kmeans_kwargs = {<br/>    "init" : "random",<br/>    "n_init" : 10<br/>}</span><span id="8b60" class="oh mx jg od b gy om oj l ok ol"># run kmeans with the optimal k<br/>kmeans = KMeans(n_clusters=3, **kmeans_kwargs)<br/>kmeans.fit(standardized_data[feature_cols])<br/>data['cluster'] = kmeans.labels_<br/>data.head()</span></pre><figure class="ny nz oa ob gt is gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/9906fb4333aba66ab730308e68f5091d.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*pAHzJVlUBrv6Oz2b4yVD3g.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">具有从K-means算法获得的聚类数的数据</p></figure><h1 id="44c3" class="mw mx jg bd my mz nt nb nc nd nu nf ng km nv kn ni kp nw kq nk ks nx kt nm nn bi translated">结果分析</h1><p id="1b6b" class="pw-post-body-paragraph kv kw jg kx b ky no kh la lb np kk ld le nq lg lh li nr lk ll lm ns lo lp lq ij bi translated">我们的工作还没有结束。我们必须在群集被收集后对其进行解释。为此，我们可以通过显示R-F-M形心值以及每个集群中的用户数量来总结所获得的集群。</p><p id="a330" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为什么是质心值？因为我们可以认为这些值是每个获得的聚类的代表。因此，我们可以使用这些值从相应的用户方面(R/F/M)来解释属于特定集群的用户的整体行为/特征。</p><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="5794" class="oh mx jg od b gy oi oj l ok ol"># look at the centroids per cluster<br/>centroid_df = data.groupby('cluster')[['Recency', 'Frequency', 'Monetary','CustomerID']].agg({'Recency': 'mean', 'Frequency': 'mean', 'Monetary':'mean','CustomerID':'nunique'}).reset_index()<br/>centroid_df = centroid_df.rename(columns = {'CustomerID':'NumBuyers'})<br/>centroid_df</span></pre><figure class="ny nz oa ob gt is gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/7389ef8d9b5a947c973be3477d99d68e.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*PnyI3ExfNOeMtCez_4undw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">获得的聚类:质心细节和聚类大小</p></figure><p id="87f8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">根据上表，我们有三个用户群/细分市场:</p><ol class=""><li id="ec9a" class="ma mb jg kx b ky kz lb lc le mc li md lm me lq mf mg mh mi bi translated"><strong class="kx jh">集群0:我们的顶级用户群。</strong>此类别的用户是最近/当前的定期购买者(最近购买率低，频率高)。他们最近的一次交易也就在几天前，之前半年的交易频率是26次。不幸的是，他们为数不多(66个用户，相当于所有用户群的1.5%)。</li><li id="0a13" class="ma mb jg kx b ky mj lb mk le ml li mm lm mn lq mf mg mh mi bi translated">第一类:我们被搅动的用户群。这一类别的用户是我们选择退出的客户(最近率高<em class="oz">【注意这是一件坏事】</em>，频率低)。他们上一次交易是五个多月前，之前半年只有0或1次交易！不幸的是，他们也很多(1364个用户，相当于所有用户群的31.5%)。</li><li id="216a" class="ma mb jg kx b ky mj lb mk le ml li mm lm mn lq mf mg mh mi bi translated"><strong class="kx jh">集群2:我们的休闲用户群。</strong>这一类别的用户是我们的常客(无论是最近的还是频繁的)。他们最近的交易发生在最近两个月内，在之前的六个月内交易频率高达三次。众所周知，他们是我们用户群中最大的一部分(2908个用户，相当于所有用户群的67%)</li></ol><pre class="ny nz oa ob gt oc od oe of aw og bi"><span id="9ae2" class="oh mx jg od b gy oi oj l ok ol"># give high-level name for each cluster<br/>centroid_df.pop('cluster')</span><span id="372b" class="oh mx jg od b gy om oj l ok ol">cluster_names = ['Top Buyers','Churned Buyers','Casual Buyers']<br/>centroid_df['ClusterName'] = cluster_names</span><span id="bae8" class="oh mx jg od b gy om oj l ok ol">centroid_df</span></pre><figure class="ny nz oa ob gt is gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/1958b014d13ae42dd5fb099628974e95.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*VTP_s2xPMaDSMtBe4_VAig.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">获得了具有高级名称的集群</p></figure><p id="5655" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">可操作的步骤</strong></p><p id="de41" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将根据对上述集群的了解，为每个集群创建一个定制的推广策略，如下所示:</p><ul class=""><li id="c422" class="ma mb jg kx b ky kz lb lc le mc li md lm me lq mo mg mh mi bi translated">顶级买家:没有必要用优惠券/促销活动来压倒他们(这为我们省钱)，但我们可以优化/利用某种忠诚度积分来留住他们。</li><li id="3f5c" class="ma mb jg kx b ky mj lb mk le ml li mm lm mn lq mo mg mh mi bi translated"><strong class="kx jh">临时买家:</strong>我们需要提高这一细分市场的频率和货币价值。我们可以通过提供返现形式的优惠券来实现这一点(以实现重复购买)，并具有较高的资格门槛(例如，优惠券仅对至少50英镑的交易金额有效)。</li><li id="9cea" class="ma mb jg kx b ky mj lb mk le ml li mm lm mn lq mo mg mh mi bi translated">被搅动的买家:我们的首要任务是让他们在被搅动一段时间后再次与我们交易。为了鼓励他们这样做，我们可以提供一两张大额福利券。这与持续不断的推送通知密切相关。</li></ul><h1 id="3613" class="mw mx jg bd my mz nt nb nc nd nu nf ng km nv kn ni kp nw kq nk ks nx kt nm nn bi translated">总结和结论</h1><p id="2be7" class="pw-post-body-paragraph kv kw jg kx b ky no kh la lb np kk ld le nq lg lh li nr lk ll lm ns lo lp lq ij bi translated">祝贺你读到这里！👏</p><p id="f1b8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这篇博客中，我们通过一步一步的Python教程，以端到端的方式在电子商务环境中执行了RFM分割！我们首先执行彻底的数据预处理，然后适当地拟合K-means算法(结合特征标准化和肘方法)。最后，我们解释了由此产生的细分市场，以便为每个细分市场制定个性化的推广计划。</p><p id="bf75" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">啊，对了，对于那些喜欢GitHub界面的人来说，完整的笔记本可以在我的GitHub repo <a class="ae jd" href="https://github.com/pararawendy/RFM-in-ecommerce" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="3305" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我希望这篇文章对你即将到来的RFM细分项目/任务有所帮助！总而言之，感谢阅读，大家在<a class="ae jd" href="https://www.linkedin.com/in/pararawendy-indarjo/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上和我连线吧！👋</p></div></div>    
</body>
</html>