<html>
<head>
<title>Dynamic Topic Modeling with BERTopic</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于BERTopic的动态主题建模</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dynamic-topic-modeling-with-bertopic-e5857e29f872?source=collection_archive---------0-----------------------#2021-10-03">https://towardsdatascience.com/dynamic-topic-modeling-with-bertopic-e5857e29f872?source=collection_archive---------0-----------------------#2021-10-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5eb8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">消化摘要:用主题建模对我的兴趣进行逆向工程(第3部分)</h2></div><p id="4f73" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是一个由三部分组成的调查的最后一篇文章，通过一种叫做主题建模的NLP技术来更好地理解我的媒体建议阅读。在本文中，我将介绍我认为是当今该领域中最强大的主题建模算法:<code class="fe le lf lg lh b"><strong class="kk iu">BERTopic</strong></code>。我还将尝试说明时间感知的交互式可视化如何能够包含大量信息，而不需要在粒度级别上手动检查任何文档或主题。</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi li"><img src="../Images/40f6b0a18c2bc421c7e892f0cd2e1503.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gm_Qm2oIrLF5sID3EHqVxQ.png"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">来自<a class="ae ly" href="https://www.pexels.com/photo/comfortable-chair-near-round-table-with-newspaper-and-tea-set-3837464/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的<a class="ae ly" href="https://www.pexels.com/@ekrulila?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Ekrulila </a>的照片</p></figure><p id="a5c2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">动态主题建模，或监控每个主题的结构如何随时间演变的能力，是理解大型语料库的强大而复杂的方法。我这篇文章的主要目的是强调BERTopic的功能，并与之前讨论的wordclouds的痛点进行对比。我希望证明主题建模对于非技术人员来说是可以理解的，并且抵制文字云对NLP空间的诱惑是值得的。声明:我很抱歉制造了文字云来检查我正在处理的任何语料库，但我希望发现更多信息和数学基础的替代方法。</p><h2 id="7fda" class="lz ma it bd mb mc md dn me mf mg dp mh kr mi mj mk kv ml mm mn kz mo mp mq mr bi translated">为什么是BERTopic？</h2><blockquote class="ms mt mu"><p id="d130" class="ki kj mv kk b kl km ju kn ko kp jx kq mw ks kt ku mx kw kx ky my la lb lc ld im bi translated">BERTopic是一种主题建模技术，它利用BERT嵌入和c-TF-IDF来创建密集的集群，允许轻松解释主题，同时保留主题描述中的重要单词。</p></blockquote><p id="38aa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这本书是由马腾·格罗登赫斯特在2020年写的，从那以后一直在稳步发展。BERTopic的两个最大优势可以说是其直接开箱即用的可用性和其新颖的交互式可视化方法。对模型已经学习的主题有一个总体的了解，允许我们对模型的质量和语料库中封装的最值得注意的主题产生一个内部的感知。</p><h2 id="05b4" class="lz ma it bd mb mc md dn me mf mg dp mh kr mi mj mk kv ml mm mn kz mo mp mq mr bi translated">装置</h2><p id="9518" class="pw-post-body-paragraph ki kj it kk b kl mz ju kn ko na jx kq kr nb kt ku kv nc kx ky kz nd lb lc ld im bi translated">软件包可以通过<a class="ae ly" href="https://pypi.org/project/bertopic/" rel="noopener ugc nofollow" target="_blank"> pypi </a>安装:</p><pre class="lj lk ll lm gt ne lh nf ng aw nh bi"><span id="f334" class="lz ma it lh b gy ni nj l nk nl">pip install bertopic</span></pre><p id="8fa2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您预计您的项目将使用BERTopic包中包含的可视化选项，请按如下方式安装它:</p><pre class="lj lk ll lm gt ne lh nf ng aw nh bi"><span id="d383" class="lz ma it lh b gy ni nj l nk nl">pip install bertopic[visualization]</span></pre><h2 id="45d4" class="lz ma it bd mb mc md dn me mf mg dp mh kr mi mj mk kv ml mm mn kz mo mp mq mr bi translated">三个主要算法组件</h2><ul class=""><li id="f0ea" class="nm nn it kk b kl mz ko na kr no kv np kz nq ld nr ns nt nu bi translated"><strong class="kk iu">嵌入文档</strong>:用<code class="fe le lf lg lh b">Sentence Transformers</code>提取文档嵌入。由于我们正在处理的数据是文章标题，我们将需要获得句子嵌入，BERTopic让我们通过使用其默认的句子转换器模型<code class="fe le lf lg lh b">paraphrase-MiniLM-L6-v2</code>方便地做到这一点。</li><li id="24c1" class="nm nn it kk b kl nv ko nw kr nx kv ny kz nz ld nr ns nt nu bi translated"><strong class="kk iu">聚类文档</strong>:用<code class="fe le lf lg lh b">UMAP</code>(减少嵌入的维度)和<code class="fe le lf lg lh b">HDBSCAN</code> <strong class="kk iu"> </strong>(识别和聚类语义相似的文档)创建相似文档的组</li><li id="2660" class="nm nn it kk b kl nv ko nw kr nx kv ny kz nz ld nr ns nt nu bi translated"><strong class="kk iu">创建主题表示</strong>:用<code class="fe le lf lg lh b">c-TF-IDF</code> <strong class="kk iu"> </strong>(基于类别的词频，逆文档频率)提取和缩减主题。如果您首先不熟悉TF-IDF，那么为了大致理解这里发生的事情，您只需要知道一件事:它允许通过计算一个单词在给定文档中的频率来比较文档之间单词的重要性，还允许测量该单词在整个语料库中的流行程度。现在，如果我们将单个簇中的所有文档视为单个文档，然后执行TF-IDF，结果将是簇中单词的重要性分数。在一个聚类中，越重要的单词越能代表该主题。因此，我们可以为每个主题获取基于关键字的描述！当涉及到从任何无监督聚类技术产生的分组中推断含义时，这是非常强大的。</li></ul><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi oa"><img src="../Images/b36b19a4926a36bc5fb784b8c7262864.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZenmRM4OGFSZn9tSEiBb4w.png"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated"><code class="fe le lf lg lh b">Image made by author using excalidraw | c-TF-IDF formula: the </code>针对每个类别<code class="fe le lf lg lh b">i</code>提取每个单词t的频率，并除以单词总数<code class="fe le lf lg lh b">w</code>。每个类别的平均单词数<code class="fe le lf lg lh b">m</code>除以所有n个类别中单词的总频率<code class="fe le lf lg lh b">t </code>。</p></figure><p id="7fe6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有关这三个算法步骤的更多信息和理论支持，请查阅<a class="ae ly" href="https://maartengr.github.io/BERTopic/tutorial/algorithm/algorithm.html" rel="noopener ugc nofollow" target="_blank">作者综合指南</a>进行深入解释。</p><h2 id="5a63" class="lz ma it bd mb mc md dn me mf mg dp mh kr mi mj mk kv ml mm mn kz mo mp mq mr bi translated">构建基本的BERT主题模型</h2><p id="2635" class="pw-post-body-paragraph ki kj it kk b kl mz ju kn ko na jx kq kr nb kt ku kv nc kx ky kz nd lb lc ld im bi translated">要在Python中创建一个<code class="fe le lf lg lh b">BERTopic</code>对象并转移到有趣的东西(动态主题建模)上，我们只需要预处理过的文档列表。用<code class="fe le lf lg lh b">pd.read_csv()</code>加载数据后，我们可以编写一些lambda apply函数来预处理我们的文本数据:</p><pre class="lj lk ll lm gt ne lh nf ng aw nh bi"><span id="fb98" class="lz ma it lh b gy ni nj l nk nl">df.text = df.apply(lambda row: re.sub(r"http\S+", "", row.text).lower(), 1)</span><span id="c44a" class="lz ma it lh b gy ob nj l nk nl">df.text = df.apply(lambda row: " ".join(filter(lambda x:x[0]!="@", row.text.split())), 1)</span><span id="4c03" class="lz ma it lh b gy ob nj l nk nl">df.text = df.apply(lambda row: " ".join(re.sub("[^a-zA-Z]+", " ", row.text).split()), 1)</span></pre><p id="af8c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">…或者，如果已经清理过了，我们可以准备两个变量。最关键的变量显然是我们的文档列表，我们称之为<code class="fe le lf lg lh b">titles</code>。其次，我们需要一个与每个文档相对应的日期列表，这样我们就可以深入了解我们的主题是如何随着时间的推移而变化的。</p><pre class="lj lk ll lm gt ne lh nf ng aw nh bi"><span id="3776" class="lz ma it lh b gy ni nj l nk nl">titles = df.text.to_list()<br/>dates = df['date'].apply(lambda x: pd.Timestamp(x)).to_list()</span></pre><p id="1589" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，让我们创建我们的主题模型！</p><pre class="lj lk ll lm gt ne lh nf ng aw nh bi"><span id="7cd6" class="lz ma it lh b gy ni nj l nk nl">from bertopic import BERTopic</span><span id="8098" class="lz ma it lh b gy ob nj l nk nl">topic_model = BERTopic(min_topic_size=70, n_gram_range=(1,3), verbose=True)</span><span id="233c" class="lz ma it lh b gy ob nj l nk nl">topics, _ = topic_model.fit_transform(titles)</span></pre><p id="f21c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以根据分配给每个主题的主题数量提取最大的十个主题，还可以预览我们主题的基于关键字的“名称”，如前所述:</p><pre class="lj lk ll lm gt ne lh nf ng aw nh bi"><span id="d665" class="lz ma it lh b gy ni nj l nk nl">freq = topic_model.get_topic_info()<br/>freq.head(10)</span></pre><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi oc"><img src="../Images/24ede1c211569b9e2c8e5696ab3443bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EqL5p5J7mVJwqEqO31C2ZA.png"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">作者图片</p></figure><p id="bee4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意，在上述数据帧中，主题-1表示由异常值文档组成的主题，这些异常值文档通常被忽略，因为术语在整个语料库中具有相对较高的流行度，因此对任何内聚主题或主题的特异性较低。</p><p id="4bed" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们还可以看看构成感兴趣的特定主题的术语:</p><pre class="lj lk ll lm gt ne lh nf ng aw nh bi"><span id="5f3a" class="lz ma it lh b gy ni nj l nk nl">topic_nr = freq.iloc[6]["Topic"] # select a frequent topic<br/>topic_model.get_topic(topic_nr)</span></pre><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi od"><img src="../Images/e1b9a9ccf320e797d82d68dc11e570ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_9JGKoQ9zEEGR5MOpuYEEw.png"/></div></div><p class="lu lv gj gh gi lw lx bd b be z dk translated">作者图片</p></figure><p id="fce3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太好了！所有我们<em class="mv">最不</em>喜欢的单词都属于话题5。我们可以看到，前三个词是“冠状病毒”、“covid”和“疫情”，但还有一个n-gram也进入了这10个特定主题的术语:“covid疫苗”，这是一个具有更多积极内涵的术语，所以看看“疫苗”一词在哪个时间点开始更频繁地出现在文章标题中会很有趣。</p><h2 id="3506" class="lz ma it bd mb mc md dn me mf mg dp mh kr mi mj mk kv ml mm mn kz mo mp mq mr bi translated">交互式可视化</h2><p id="f63b" class="pw-post-body-paragraph ki kj it kk b kl mz ju kn ko na jx kq kr nb kt ku kv nc kx ky kz nd lb lc ld im bi translated">这种技术的最大优点是能够可视化我们的主题模型，告诉我们足够多的数据，而不需要研究原始文本本身。</p><p id="d655" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您还记得我以前的主题建模文章，标题为“<a class="ae ly" rel="noopener" target="_blank" href="/nlp-preprocessing-and-latent-dirichlet-allocation-lda-topic-modeling-with-gensim-713d516c6c7d?source=user_profile---------0----------------------------"> NLP预处理和使用Gensim </a>的潜在Dirichlet分配(LDA)主题建模”，有一个名为<code class="fe le lf lg lh b">pyLDAvis</code>的Python可视化包，它使用户能够生成交互式子图，描述2D平面上主题之间的距离以及主题内前30个最相关和最显著的术语。BERTopic有自己的主题间距离图实现，它包括一个悬停工具提示，显示指定给特定主题的文档数量以及该主题中最常用的前5个术语。生成以下可视化效果所需的代码行非常简单:</p><pre class="lj lk ll lm gt ne lh nf ng aw nh bi"><span id="da8a" class="lz ma it lh b gy ni nj l nk nl">topic_model.visualize_topics()</span></pre><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/2f72ff6fe3792e96a2fbdb2bd7e51f46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*RMzkbRWum6Kghew3pP7NVQ.gif"/></div></figure><p id="5db8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面的主题间距离图描述了15个主题中的五个主要主题组。最接近x轴的集群属于Python的一般主题，基于我的中等兴趣和搜索历史，这具有直观的意义。左下方的集群由机器学习、深度学习、数据科学、技术设计等领域兴趣组成。被吸引到左上角的是关于NLP、情感分析和Twitter数据的文章。尽管事实上这些可以被标记为我的另一个兴趣领域，我假设它们占据了2D平面的不同区域，因为我在我的高级顶点项目中对这些主题进行了更深入更细致的研究。我认为，靠近y轴的中间底部区域的集群的特点是技术含量较少，主题行遵循模板“作为软件工程师避免精疲力尽的10个技巧”或“我从100天内写100篇中型文章中学到的东西”。在我看来，这些文章处于生产力技巧和自我发展智慧的交汇点。他们并不总是教我新的东西，但当我每天早上阅读《媒介文摘》时，他们无疑会激励我。最后，最右边的主题簇代表了不属于技术领域的主题的大杂烩，但是对于在媒体上消费全面的文章选择来说仍然是重要的。</p><p id="7d95" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，最吸引人的是关于时间的动态主题建模！在下面的视频中，我们可以观察到从2020年初到现在，我的建议媒体文章(标题)语料库中十个最流行的主题的频率。</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/8658794bc43090dbc3a103e3cec65acb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*v6HwLE9GwaXDEw9bfR4-Pw.gif"/></div></figure><p id="819b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以观察到，数据科学(<code class="fe le lf lg lh b">topic 5</code>)和开发/编码(<code class="fe le lf lg lh b">topic 9</code>)是我近两年来的一贯兴趣。有趣的是，React apps ( <code class="fe le lf lg lh b">topic 6</code>)是我在2020年10月和11月广泛阅读的东西，但我的这种兴趣很快就消退了。你可能想知道这背后的故事？嗯，我正在为一个前端开发面试临时抱佛脚，对此我感到毫无准备。有趣的事实:灵媒教会了我几乎所有关于反应的知识。我们可以注意到，NLP主题(<code class="fe le lf lg lh b">topic 8</code>)的频率在2020年夏天和2021年6月左右达到峰值，当我反思我在那些时间从事的工作时，这很有意义。新冠肺炎(<code class="fe le lf lg lh b">topic 2</code>)在2020年3月到5月的频率达到峰值，我认为这说明了一切…继续前进。百花香主题(<code class="fe le lf lg lh b">topic 0</code>)在2020年初出现频率最高，但在当年晚些时候逐渐减少。我想当我被困在家里的时候，我读了更多的非技术内容，而我现在主要是为了技术目的查阅中型文章。</p><p id="14b2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在不进行更多个人反思的情况下，我希望您能够理解动态主题建模的强大之处。在任何时间点将鼠标悬停在我们的主题频率线图上会显示不同的主题关键词，从而可以分析主题如何随着时间的推移而演变。</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/866cd02c94f6e433247708bb148e60c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*0DhKd27H7aatNIGopWq_2g.gif"/></div></figure><p id="7566" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然我简要地展示了如何访问属于特定主题的热门关键词及其重要性分数，但是我们也可以将这些术语和分数可视化为条形图。</p><p id="3639" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的伯托皮综合之旅到此结束！我希望您已经了解了一两件关于动态主题建模的事情，并且能够明白为什么我认为这个主题建模Python包超越了这个领域中的其他包和技术。再次对BERTopic的作者Maarten Grootendorst大声疾呼，感谢他实现并开源了这个令人敬畏的代码。</p><h2 id="614d" class="lz ma it bd mb mc md dn me mf mg dp mh kr mi mj mk kv ml mm mn kz mo mp mq mr bi translated">总结和简化应用程序</h2><p id="59ca" class="pw-post-body-paragraph ki kj it kk b kl mz ju kn ko na jx kq kr nb kt ku kv nc kx ky kz nd lb lc ld im bi translated">如果您想尝试一下动态主题建模，我已经编写了一个小的Streamlit应用程序，它允许您导入一个包含日期和文档的CSV文件，您可以从中构建主题模型。然后，它创建一个BERTopic模型，并在应用程序中嵌入一些交互式可视化。我希望你喜欢并可以尽情地玩这个应用程序。我开发这款应用的动机如下:</p><ol class=""><li id="0deb" class="nm nn it kk b kl km ko kp kr of kv og kz oh ld oi ns nt nu bi translated">让主题建模更具交互性和趣味性，远离令人生畏的技术性NLP子域</li><li id="93cb" class="nm nn it kk b kl nv ko nw kr nx kv ny kz nz ld oi ns nt nu bi translated">让不太懂技术的人也能理解这个主题，他们可能也想有机会更好地理解给定文本语料库中的主题</li></ol><p id="dc8d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此处可访问该应用:<a class="ae ly" href="https://share.streamlit.io/sejaldua/digesting-the-digest/main/bertopic_app.py" rel="noopener ugc nofollow" target="_blank">https://share . streamlit . io/sejaldua/digesting-the-digest/main/ber topic _ app . py</a></p><p id="cead" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">和往常一样，我把我的源代码放在一个公共的GitHub库中:</p><div class="oj ok gp gr ol om"><a href="https://github.com/sejaldua/digesting-the-digest" rel="noopener  ugc nofollow" target="_blank"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">GitHub-sejaldua/digesting-the-digest:使用Gmail API对我推荐的媒体进行主题建模…</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">使用Gmail API对我推荐的媒体进行主题建模</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">github.com</p></div></div><div class="ov l"><div class="ow l ox oy oz ov pa ls om"/></div></div></a></div><h2 id="ec1e" class="lz ma it bd mb mc md dn me mf mg dp mh kr mi mj mk kv ml mm mn kz mo mp mq mr bi translated">参考</h2><div class="oj ok gp gr ol om"><a href="https://github.com/MaartenGr/BERTopic" rel="noopener  ugc nofollow" target="_blank"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">GitHub - MaartenGr/BERTopic:利用BERT和c-TF-IDF创建易于解释的主题。</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">BERTopic是一种主题建模技术，它利用了🤗变压器和c-TF-IDF创建密集的集群，允许…</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">github.com</p></div></div><div class="ov l"><div class="pb l ox oy oz ov pa ls om"/></div></div></a></div><div class="oj ok gp gr ol om"><a href="https://reposhub.com/python/natural-language-processing/MaartenGr-BERTopic.html" rel="noopener  ugc nofollow" target="_blank"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">利用BERT和基于类的TF-IDF创建易于解释的主题。-自然语言…</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">BERTopic是一种主题建模技术，它利用BERT嵌入和c-TF-IDF来创建密集的集群，从而允许…</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">reposhub.com</p></div></div><div class="ov l"><div class="pc l ox oy oz ov pa ls om"/></div></div></a></div><div class="oj ok gp gr ol om"><a rel="noopener follow" target="_blank" href="/interactive-topic-modeling-with-bertopic-1ea55e7d73d8"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">用BERTopic进行交互式主题建模</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">使用BERTopic进行主题建模的深入指南</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">towardsdatascience.com</p></div></div><div class="ov l"><div class="pd l ox oy oz ov pa ls om"/></div></div></a></div></div></div>    
</body>
</html>