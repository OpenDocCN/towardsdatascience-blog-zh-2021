<html>
<head>
<title>Train, Bus, or Plane? Predictive Classification of Points of Interest Using Visit and Popularity Metrics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">火车、公共汽车还是飞机？使用访问和流行度度量对兴趣点进行预测分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/poi-classification-using-visit-and-popularity-metrics-part-1-ae5e94f92077?source=collection_archive---------33-----------------------#2021-06-27">https://towardsdatascience.com/poi-classification-using-visit-and-popularity-metrics-part-1-ae5e94f92077?source=collection_archive---------33-----------------------#2021-06-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8f75" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用地理空间要素对公交车站、火车站或机场等位置进行分类</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c592c983f6acc0818803eb97ecdc65dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xmO0nQVwm4axxd0bOtQmKw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由安妮·斯普拉特和昂斯普拉什拍摄</p></figure><p id="ef92" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文旨在展示如何使用来自<a class="ae kv" href="https://www.safegraph.com/" rel="noopener ugc nofollow" target="_blank"> SafeGraph </a>的适用真实世界数据集，通过监督机器学习进行基本分类。SafeGraph是一家数据提供商，为数百家企业和类别提供POI数据。它向<a class="ae kv" href="https://www.safegraph.com/academics" rel="noopener ugc nofollow" target="_blank">的学者</a>免费提供数据。对于这个项目，我选择使用SafeGraph模式数据，以便将记录分类为各种POI。模式数据的模式可以在这里找到:<a class="ae kv" href="https://docs.safegraph.com/v4.0/docs/places-schema#section-patterns" rel="noopener ugc nofollow" target="_blank">模式信息</a></p><p id="8772" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从商店里众多可供选择的类别中，这个项目着重于不同运输服务的分类。为此项目选择的类别有:</p><ul class=""><li id="766f" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">公共汽车和其他车辆运输系统</li><li id="e0c3" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">铁路运输</li><li id="797d" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">其他机场运营</li></ul><p id="5cc1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些类别中的每一个都与火车站、汽车站和机场数据的POI数据相关联。</p><p id="4143" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文是使用这些数据的三部分系列文章的第一部分:</p><ul class=""><li id="130a" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">使用safegraph数据和sklearn分类器进行POI分类</li><li id="76ac" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">使用PCA和交叉验证的模型调整</li><li id="c8dc" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">使用spark深度学习分类器的兴趣点分类</li><li id="592a" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">单一NAICS代码内的POI分类(快餐店分类)</li></ul></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mn"><img src="../Images/436c516d572949c0349239cee6adfbd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A2WgatjinWOcm9xzA3AxFw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来自<a class="ae kv" href="https://unsplash.com/@markusspiske" rel="noopener ugc nofollow" target="_blank"> Markus Spiske </a>和Unsplash</p></figure><p id="7ec1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是为这个项目编写的代码的快照和代码过程的简要描述。这个项目代码的链接可以在这里找到:<a class="ae kv" href="https://colab.research.google.com/drive/13Nzf0HhnP8UnsrCYeunXlha72LFBLH1W?usp=sharing" rel="noopener ugc nofollow" target="_blank">笔记本链接</a></p><p id="d2ff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">第1部分:依赖关系</strong></p><p id="063f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下是该项目的依赖项。我们这个项目需要的包是P <strong class="ky ir">和as </strong>，<strong class="ky ir"> NumPy </strong>，<strong class="ky ir"> Seaborn </strong>，M <strong class="ky ir"> atplotlib </strong>，P <strong class="ky ir"> yspark </strong></p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="5121" class="mt mu iq mp b gy mv mw l mx my">import pandas as pd</span><span id="0cf5" class="mt mu iq mp b gy mz mw l mx my">import numpy as np</span><span id="992a" class="mt mu iq mp b gy mz mw l mx my">import seaborn as sns</span><span id="4559" class="mt mu iq mp b gy mz mw l mx my">import matplotlib.pyplot as pltx</span><span id="88e6" class="mt mu iq mp b gy mz mw l mx my">from sklearn.metrics import plot_confusion_matrix</span></pre><p id="9a78" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi">— —</p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="ff1f" class="mt mu iq mp b gy mv mw l mx my">!apt-get install openjdk-8-jdk-headless -qq &gt; /dev/null</span><span id="9b23" class="mt mu iq mp b gy mz mw l mx my">!wget -q <a class="ae kv" href="https://www-us.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz" rel="noopener ugc nofollow" target="_blank">https://www-us.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz</a></span><span id="d004" class="mt mu iq mp b gy mz mw l mx my">!tar xf spark-3.1.2-bin-hadoop2.7.tgz</span><span id="90ce" class="mt mu iq mp b gy mz mw l mx my">!pip install -q findspark</span><span id="c3e8" class="mt mu iq mp b gy mz mw l mx my">!pip install pyspark</span></pre><p id="858e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi">— —</p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="3afc" class="mt mu iq mp b gy mv mw l mx my">import findspark</span><span id="ac51" class="mt mu iq mp b gy mz mw l mx my">findspark.init(“/content/spark-3.1.2-bin-hadoop2.7”)</span><span id="4c96" class="mt mu iq mp b gy mz mw l mx my">from pyspark.sql import SparkSession</span><span id="b633" class="mt mu iq mp b gy mz mw l mx my">spark = SparkSession.builder.master(“local[*]”).getOrCreate()</span></pre><p id="28d9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">第二部分:数据加载</strong></p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="f445" class="mt mu iq mp b gy mv mw l mx my">from pydrive.auth import GoogleAuth</span><span id="2c91" class="mt mu iq mp b gy mz mw l mx my">from pydrive.drive import GoogleDrive</span><span id="5167" class="mt mu iq mp b gy mz mw l mx my">from google.colab import auth</span><span id="f0fb" class="mt mu iq mp b gy mz mw l mx my">from oauth2client.client import GoogleCredentials<br/></span><span id="e2ba" class="mt mu iq mp b gy mz mw l mx my">auth.authenticate_user()</span><span id="1474" class="mt mu iq mp b gy mz mw l mx my">gauth = GoogleAuth()</span><span id="d760" class="mt mu iq mp b gy mz mw l mx my">gauth.credentials = GoogleCredentials.get_application_default()</span><span id="e128" class="mt mu iq mp b gy mz mw l mx my">drive = GoogleDrive(gauth)</span><span id="a147" class="mt mu iq mp b gy mz mw l mx my">def pd_read_csv_drive(id, drive, dtype=None):</span><span id="43ba" class="mt mu iq mp b gy mz mw l mx my">    downloaded = drive.CreateFile({‘id’:id})</span><span id="00ff" class="mt mu iq mp b gy mz mw l mx my">    downloaded.GetContentFile(‘Filename.csv’)</span><span id="a15d" class="mt mu iq mp b gy mz mw l mx my">    return(pd.read_csv(‘Filename.csv’,dtype=dtype))</span><span id="a1eb" class="mt mu iq mp b gy mz mw l mx my">def get_drive_id(filename):</span><span id="2f1b" class="mt mu iq mp b gy mz mw l mx my">    drive_ids = {‘patterns’ : ‘1ReqpLgv50_3mCvZuKLlMdHxwfCPIHmqz’}</span><span id="0278" class="mt mu iq mp b gy mz mw l mx my">    return(drive_ids[filename])</span><span id="33bb" class="mt mu iq mp b gy mz mw l mx my">transportation_df = pd_read_csv_drive(get_drive_id(‘patterns’), drive=drive)</span><span id="0595" class="mt mu iq mp b gy mz mw l mx my">transportation_df.head(3)</span></pre><p id="0685" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出如下所示(点击图片查看详情):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/a0303d523cc3fa8e171f46ea49d2b8ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-33hQq_oUhWAjrPtq6Oh2g.png"/></div></div></figure><p id="45d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下表是2018年12月上述三个兴趣点类别的模式数据。选择这个特殊的月份是因为公共交通在假日季节更有可能被利用——从而为每个记录显示更清晰的受欢迎程度和游客指标。</p><p id="edfb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将用作分类模型特征的一些列是:</p><ul class=""><li id="ea02" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir"> raw_visit_counts — </strong>在日期范围内，我们的面板中对此兴趣点的访问次数。</li><li id="5165" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir"> raw_visitor_counts — </strong>在日期范围内，来自我们面板的访问该兴趣点的独立访问者的数量。</li><li id="6440" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">每日访问次数— </strong>在所覆盖的时间段内，每天(当地时间)访问兴趣点的次数。</li><li id="c5f2" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir"> distance_from_home — </strong>访客(我们已确定其住所的访客)离家的中间距离，以米为单位。</li><li id="ef91" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">中值停留时间— </strong>中值最小停留时间，以分钟为单位。</li><li id="eb0f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">bucked _ dwell _ times—</strong>关键字是分钟范围，值是在该持续时间内的访问次数</li><li id="b8f8" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir"> popularity_by_hour — </strong>将一天中的某个小时映射到当地时间日期范围内每小时的访问量。数组中的第一个元素对应于从午夜到凌晨1点的时间</li><li id="1762" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir"> popularity_by_day — </strong>将一周中的某一天映射到日期范围内每天(当地时间)的访问次数</li><li id="874c" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir"> device_type — </strong>使用android和ios访问兴趣点的人数。仅显示至少包含2个设备的设备类型，包含少于5个设备的任何类别都报告为4</li></ul></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="fca4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">第3节:数据清理</strong></p><p id="943b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一步是删除不必要的列。</p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="3dab" class="mt mu iq mp b gy mv mw l mx my">transportation_df = transportation_df.drop([‘parent_safegraph_place_id’,’placekey’,’safegraph_place_id’,’parent_placekey’,’parent_placekey’,’safegraph_brand_ids’,’brands’, ‘poi_cbg’], axis = 1)</span><span id="62e7" class="mt mu iq mp b gy mz mw l mx my">transportation_df.head(3)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/5ff401af81e59f92313c5630f45d9319.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gls6JGP48SD8FQsIknS_nQ.png"/></div></div></figure><p id="a40c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里我们将<strong class="ky ir">parent _ safe graph _ place _ id</strong>、<strong class="ky ir"> placekey </strong>、<strong class="ky ir"> parent_placekey </strong>、<strong class="ky ir"> safegraph_brand_ids </strong>、<strong class="ky ir"> brands </strong>、<strong class="ky ir"> poi_cbg </strong>。这些列与标识符、品牌、人口普查区块组和位置键相关。这些列与这个特定项目的范围无关，因此我们将它们删除。</p><p id="0064" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">#创建基础事实类列(帮助函数)</p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="d8bf" class="mt mu iq mp b gy mv mw l mx my">def class_definer(record):</span><span id="652e" class="mt mu iq mp b gy mz mw l mx my">    fixed_record = record.lower()</span><span id="7822" class="mt mu iq mp b gy mz mw l mx my">    if(‘bus’ in fixed_record):</span><span id="dcff" class="mt mu iq mp b gy mz mw l mx my">        return ‘Bus’</span><span id="f436" class="mt mu iq mp b gy mz mw l mx my">    elif(‘airport’ in fixed_record):</span><span id="b34b" class="mt mu iq mp b gy mz mw l mx my">        return ‘Airport’</span><span id="1e60" class="mt mu iq mp b gy mz mw l mx my">    elif(‘train’ in fixed_record):</span><span id="9c70" class="mt mu iq mp b gy mz mw l mx my">        return ‘Train’</span><span id="9ece" class="mt mu iq mp b gy mz mw l mx my">    elif(‘metro’ in fixed_record):</span><span id="5edd" class="mt mu iq mp b gy mz mw l mx my">        return ‘Train’</span><span id="e868" class="mt mu iq mp b gy mz mw l mx my">    elif(‘transport’ in fixed_record):</span><span id="e5d7" class="mt mu iq mp b gy mz mw l mx my">        return ‘Bus’</span><span id="3a88" class="mt mu iq mp b gy mz mw l mx my">    elif(‘amtrak’ in fixed_record):</span><span id="e532" class="mt mu iq mp b gy mz mw l mx my">        return ‘Train’</span><span id="022b" class="mt mu iq mp b gy mz mw l mx my">    elif(‘bart’ in fixed_record):</span><span id="bb99" class="mt mu iq mp b gy mz mw l mx my">        return ‘Train’</span><span id="7f7f" class="mt mu iq mp b gy mz mw l mx my">    elif(‘cta’ in fixed_record):</span><span id="94b1" class="mt mu iq mp b gy mz mw l mx my">        return ‘Train’</span><span id="d98d" class="mt mu iq mp b gy mz mw l mx my">    elif(‘mta’ in fixed_record):</span><span id="6ca8" class="mt mu iq mp b gy mz mw l mx my">        return ‘Train’</span><span id="3630" class="mt mu iq mp b gy mz mw l mx my">    elif(‘transit’ in fixed_record):</span><span id="1e55" class="mt mu iq mp b gy mz mw l mx my">        return ‘Bus’</span><span id="7587" class="mt mu iq mp b gy mz mw l mx my">    elif(‘mbta’ in fixed_record):</span><span id="eec7" class="mt mu iq mp b gy mz mw l mx my">        return ‘Train’</span><span id="959a" class="mt mu iq mp b gy mz mw l mx my">    elif(‘station’ in fixed_record):</span><span id="e517" class="mt mu iq mp b gy mz mw l mx my">        return ‘Train’</span><span id="3756" class="mt mu iq mp b gy mz mw l mx my">    elif(‘railway’ in fixed_record):</span><span id="3ea1" class="mt mu iq mp b gy mz mw l mx my">        return ‘Train’</span><span id="a48a" class="mt mu iq mp b gy mz mw l mx my">    else:</span><span id="6a5d" class="mt mu iq mp b gy mz mw l mx my">        return ‘Unknown’</span><span id="4551" class="mt mu iq mp b gy mz mw l mx my">transportation_df['Class'] = transportation_df['location_name'].transform(lambda x: class_definer(x))</span><span id="78b6" class="mt mu iq mp b gy mz mw l mx my">transportation_df.head(3)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/2288a80a49057bf8de43829117661987.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O4-B7uA25gEDqrJj1WWW-Q.png"/></div></div></figure><p id="6bfb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些代码片段试图创建一个类列来建立监督学习算法(如分类)所需的基础事实。用于此项目的数据带有一些警告，尤其是公交车站数据。NAICS公交车站类别包括“公交车站和其他交通服务”。该类别尤其包含多个项目，如公交车站、卡车租赁和游艇服务。因此，为了删除不相关的记录，使用了上面的函数。</p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="27c5" class="mt mu iq mp b gy mv mw l mx my">transportation_df = transportation_df[transportation_df[‘Class’] != ‘Unknown’].dropna()</span><span id="16b1" class="mt mu iq mp b gy mz mw l mx my">transportation_df.head(3)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/437dcc80036b0962fc62aa400d3eb0a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nZeMEmmSnpxNHG2JXURqTA.png"/></div></div></figure><p id="8592" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些未知的列代表了汽车运输记录，这些记录与模式数据中的公共汽车数据一起出现。我们可以放弃这些记录，因为它们并不完全符合公共汽车服务的概念——更倾向于卡车服务、游艇租赁和其他远离公共汽车服务概念的交通服务。</p><p id="0ff0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，数据被正确格式化，并且有一个可用于分类算法的类列。下一步是格式化数据帧，使所有的特征都能用于分类算法。这个过程需要水平扩展列，例如<strong class="ky ir">按天访问</strong>列和<strong class="ky ir">按小时流行度</strong>列。这些需要水平展开的列中，有些是数组的列，有些是JSON的列。我们将首先研究JSON列的水平扩展:</p><p id="18be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为此，我们将使用pyspark，特别是from_json表达式来水平展开列。为此，我们必须首先将pandas数据帧转换为Spark数据帧。</p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="d4ec" class="mt mu iq mp b gy mv mw l mx my">transportation_df = spark.createDataFrame(transportation_df)</span><span id="efe2" class="mt mu iq mp b gy mz mw l mx my">transportation_df.show(2)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/c40204623d7792fae25cdd04324a25dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R6jrSjLSjL_1EKTWVKIEWA.png"/></div></div></figure><p id="97e8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">既然数据在Spark数据框架中，我们需要为需要展开的JSON字符串列创建一个模式。这些模式将显示JSON字符串展开时产生的唯一列，以及与该列相关联的数据类型，使用该模式我们可以展开JSON字符串列。</p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="6d4d" class="mt mu iq mp b gy mv mw l mx my">#Horizontal Explosion of JSON columns using Pyspark</span><span id="293f" class="mt mu iq mp b gy mz mw l mx my">from pyspark.sql.functions import from_json,expr</span><span id="396a" class="mt mu iq mp b gy mz mw l mx my">from pyspark.sql.types import StructType, StructField, StringType, ArrayType, IntegerType</span><span id="09cf" class="mt mu iq mp b gy mz mw l mx my">day_schema = StructType(</span><span id="ba6d" class="mt mu iq mp b gy mz mw l mx my">  [</span><span id="3fea" class="mt mu iq mp b gy mz mw l mx my">     StructField(‘Monday’, IntegerType(),True),</span><span id="4480" class="mt mu iq mp b gy mz mw l mx my">     StructField(‘Tuesday’, IntegerType(),True),</span><span id="652a" class="mt mu iq mp b gy mz mw l mx my">     StructField(‘Wednesday’, IntegerType(),True),</span><span id="8fe3" class="mt mu iq mp b gy mz mw l mx my">     StructField(‘Thursday’, IntegerType(),True),</span><span id="30c1" class="mt mu iq mp b gy mz mw l mx my">     StructField(‘Friday’, IntegerType(),True),</span><span id="4dab" class="mt mu iq mp b gy mz mw l mx my">     StructField(‘Saturday’, IntegerType(),True),</span><span id="6c46" class="mt mu iq mp b gy mz mw l mx my">     StructField(‘Sunday’, IntegerType(),True)</span><span id="ae95" class="mt mu iq mp b gy mz mw l mx my">  ]</span><span id="2b40" class="mt mu iq mp b gy mz mw l mx my">)</span><span id="74f6" class="mt mu iq mp b gy mz mw l mx my">device_schema = StructType(</span><span id="39b0" class="mt mu iq mp b gy mz mw l mx my">  [</span><span id="a58f" class="mt mu iq mp b gy mz mw l mx my">     StructField(‘android’, IntegerType(),True),</span><span id="a257" class="mt mu iq mp b gy mz mw l mx my">     StructField(‘ios’, IntegerType(),True)</span><span id="2a68" class="mt mu iq mp b gy mz mw l mx my">  ]</span><span id="5ec0" class="mt mu iq mp b gy mz mw l mx my">)</span><span id="23a4" class="mt mu iq mp b gy mz mw l mx my">bucketedDT_schema = StructType(</span><span id="6a64" class="mt mu iq mp b gy mz mw l mx my">  [</span><span id="0cd6" class="mt mu iq mp b gy mz mw l mx my">    StructField(‘&lt;5’,IntegerType(),True),</span><span id="8ace" class="mt mu iq mp b gy mz mw l mx my">    StructField(‘5–10’,IntegerType(),True),</span><span id="acc0" class="mt mu iq mp b gy mz mw l mx my">    StructField(‘11–20’,IntegerType(),True),</span><span id="779f" class="mt mu iq mp b gy mz mw l mx my">    StructField(‘21–60’,IntegerType(),True),</span><span id="3b47" class="mt mu iq mp b gy mz mw l mx my">    StructField(‘61–120’,IntegerType(),True),</span><span id="bf5c" class="mt mu iq mp b gy mz mw l mx my">    StructField(‘121–240’,IntegerType(),True),</span><span id="e5ef" class="mt mu iq mp b gy mz mw l mx my">    StructField(‘&gt;240’,IntegerType(),True)</span><span id="b089" class="mt mu iq mp b gy mz mw l mx my">  ]</span><span id="0022" class="mt mu iq mp b gy mz mw l mx my">)</span><span id="dd07" class="mt mu iq mp b gy mz mw l mx my">transportation_df = transportation_df.withColumn(‘popularity_by_day’, from_json(‘popularity_by_day’, day_schema)).withColumn(‘device_type’, from_json(‘device_type’, device_schema)).withColumn(‘bucketed_dwell_times’,from_json(‘bucketed_dwell_times’,bucketedDT_schema)).select(‘location_name’,’raw_visit_counts’,’raw_visitor_counts’,’visits_by_day’,‘distance_from_home’,’median_dwell’,‘bucketed_dwell_times.*’,’popularity_by_hour’,’popularity_by_day.*’,‘device_type.*’,’Class’)</span><span id="a63f" class="mt mu iq mp b gy mz mw l mx my">transportation_df = transportation_df.toPandas()</span><span id="3a69" class="mt mu iq mp b gy mz mw l mx my">transportation_df.head(3)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/d36a6ee3b36f833b532f5427900fcb06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JRNCzmsRswKYMVAWqeAthA.png"/></div></div></figure><p id="a4d5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在JSON字符串已经展开，我们可以展开数组列了。由于这在pandas中很容易做到，我们可以将数据帧转换回Pandas数据帧。数组列的扩展要求用数组填充列，而不是像数组一样格式化的字符串列。Safegraph模式数据使这些列成为字符串而不是数组，因此第一步是将字符串转换为数组。这可以使用ast包中的literal_eval函数来完成。从这里，我们可以获取位于每个索引中的单个值，并将它们分解到单独的列中。</p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="2751" class="mt mu iq mp b gy mv mw l mx my">from ast import literal_eval</span><span id="6b35" class="mt mu iq mp b gy mz mw l mx my">transportation_df[‘popularity_by_hour’] = transportation_df[‘popularity_by_hour’].transform(lambda x: literal_eval(x))</span><span id="8783" class="mt mu iq mp b gy mz mw l mx my">pops = [‘popularity_’ + str(i) for i in range(1,25)]</span><span id="6bcd" class="mt mu iq mp b gy mz mw l mx my">transportation_df[pops] = pd.DataFrame(transportation_df.popularity_by_hour.to_list(), index=transportation_df.index)</span><span id="a267" class="mt mu iq mp b gy mz mw l mx my">transportation_df = transportation_df.drop([‘popularity_by_hour’], axis = 1)</span><span id="7cf3" class="mt mu iq mp b gy mz mw l mx my">transportation_df = transportation_df.reindex()</span><span id="b2f1" class="mt mu iq mp b gy mz mw l mx my">transportation_df.drop(‘visits_by_day’, axis=1, inplace=True)</span><span id="3e19" class="mt mu iq mp b gy mz mw l mx my">transportation_df.head(3)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/ad95111c2b6b2d4a9f370526ccc5ac2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IJupWY-tgZS8HVtcWfGsMA.png"/></div></div></figure><p id="e768" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们需要做的数据清理的最后一部分是使用Sklearn LabelEncoder函数将类函数转换为分类模型的数值。</p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="5637" class="mt mu iq mp b gy mv mw l mx my">from sklearn import preprocessing</span><span id="7bca" class="mt mu iq mp b gy mz mw l mx my">le = preprocessing.LabelEncoder()</span><span id="fd6e" class="mt mu iq mp b gy mz mw l mx my">le.fit(transportation_df[‘Class’])</span><span id="441d" class="mt mu iq mp b gy mz mw l mx my">transportation_df[‘Class’] = le.transform(transportation_df[‘Class’])</span><span id="45cd" class="mt mu iq mp b gy mz mw l mx my">transportation_df.head(3)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/382027760702b6531c4009a913d73b7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JvT-enO7xJ2xHee-LjF68g.png"/></div></div></figure></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="d2c1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">第四节:分类</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/dc1bb90774943b5274f1af6c2da88266.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P3WFK0x8rKzCuMClaaDGWw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图像来自<a class="ae kv" href="https://unsplash.com/@umby" rel="noopener ugc nofollow" target="_blank">翁贝托</a>和Unsplash</p></figure><p id="e7be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为有3个唯一的类，我们需要使用一个多类分类器。我们将尝试高斯朴素贝叶斯、决策树和K近邻分类器。首先，我们必须将数据分成测试集和训练集。</p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="3381" class="mt mu iq mp b gy mv mw l mx my">from sklearn.metrics import confusion_matrix</span><span id="34b5" class="mt mu iq mp b gy mz mw l mx my">from sklearn.model_selection import train_test_split</span><span id="9a7b" class="mt mu iq mp b gy mz mw l mx my">x_cols = []</span><span id="596b" class="mt mu iq mp b gy mz mw l mx my">for item in list(transportation_df.columns):</span><span id="22c2" class="mt mu iq mp b gy mz mw l mx my">if(item != ‘Class’ and item != ‘location_name’):</span><span id="7aca" class="mt mu iq mp b gy mz mw l mx my">x_cols.append(item)</span><span id="708d" class="mt mu iq mp b gy mz mw l mx my">X = transportation_df[x_cols]</span><span id="5874" class="mt mu iq mp b gy mz mw l mx my">y = transportation_df[‘Class’]</span><span id="89ad" class="mt mu iq mp b gy mz mw l mx my">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)</span></pre><p id="1b3c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">高斯朴素贝叶斯分类器:</strong></p><p id="98fa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里有一些关于朴素贝叶斯分类器功能的背景知识:<a class="ae kv" rel="noopener" target="_blank" href="/naive-bayes-classifier-81d512f50a7c">高斯朴素贝叶斯</a></p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="8417" class="mt mu iq mp b gy mv mw l mx my">from sklearn.naive_bayes import GaussianNB</span><span id="5b36" class="mt mu iq mp b gy mz mw l mx my">gnb = GaussianNB().fit(X_train, y_train)</span><span id="5094" class="mt mu iq mp b gy mz mw l mx my">gnb_predictions = gnb.predict(X_test)</span><span id="4f6b" class="mt mu iq mp b gy mz mw l mx my">gnb_predictions</span><span id="0e62" class="mt mu iq mp b gy mz mw l mx my">accuracy = gnb.score(X_test, y_test)</span><span id="cc1a" class="mt mu iq mp b gy mz mw l mx my">print(accuracy)<br/>confusion_matrix(y_test, gnb_predictions)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/56bebed0b4d730dff8a851df7e4fddac.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*jtvuE8cBNrA6ZCxu49jWzA.png"/></div></figure><p id="5291" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们使用热图来可视化结果</p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="0690" class="mt mu iq mp b gy mv mw l mx my">plot_confusion_matrix(gnb, X_test, y_test, normalize=’true’, values_format = ‘.3f’, display_labels=[‘Airport’,’Bus’,’Train’])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/db7c6dac232f437b32566fbcd460d4fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RWMeONVxPTDJLiU59U73cQ.png"/></div></div></figure><p id="5eab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">黄色表示高发，紫色表示低发。我们的“正确”预测显示在从左上角到右下角的对角线上。</p><p id="7520" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">理想情况下，我们会在对角线上看到黄色，在其他地方看到紫色。</p><p id="79df" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这表明高斯朴素贝叶斯在分类这个特定数据集方面做得不太好。这可能是由于分类器单独考虑每个特征，而没有考虑它们的相关性(因此分类器是“幼稚的”)。当要素具有高相关系数时(如该特定数据集，其中许多要素从一列展开并彼此直接相关),这将使分类器难以正常工作。</p><p id="b35d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该模型的精度约为26%。热点图显示，许多实际上是机场的值被错误分类为火车站。同样可以说，真正的汽车站被错误地归类为火车站。这表明大多数记录实际上被归类为火车站。</p><p id="e8c3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">决策树:</strong></p><p id="e2f4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里有一些关于决策树分类器功能的背景知识:<a class="ae kv" href="https://medium.com/swlh/decision-tree-classification-de64fc4d5aac" rel="noopener">决策树</a></p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="6436" class="mt mu iq mp b gy mv mw l mx my">from sklearn.tree import DecisionTreeClassifier</span><span id="233c" class="mt mu iq mp b gy mz mw l mx my">dtree_model = DecisionTreeClassifier(max_depth = 3).fit(X_train, y_train)</span><span id="b6aa" class="mt mu iq mp b gy mz mw l mx my">dtree_predictions = dtree_model.predict(X_test)</span><span id="c0b6" class="mt mu iq mp b gy mz mw l mx my">dtree_model.score(X_test,y_test)</span><span id="87e2" class="mt mu iq mp b gy mz mw l mx my">confusion_matrix(y_test, dtree_predictions)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/656c3ec81cb59c271913d28920d557ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*KWHnvWCB0diZOyaFdEPPuA.png"/></div></figure><p id="bc1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用热图可视化结果</p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="6f02" class="mt mu iq mp b gy mv mw l mx my">plot_confusion_matrix(dtree_model, X_test, y_test, normalize=’true’, values_format = ‘.3f’, display_labels=[‘Airport’,’Bus’,’Train’])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/21b1bcf4430b01ef533e050ebf2f010c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tVn9OhQRO2sCLicITs-uxA.png"/></div></div></figure><p id="9358" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由此可见，决策树模型的表现要比朴素贝叶斯好得多，准确率达到75%。考虑到这是一个多类分类器，这个精度是相当不错的。</p><p id="c810" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">分类器似乎在正确分类机场方面做得非常好，准确率约为91.7%，表明考虑了数据各种特征之间相关性的模型可以很好地对机场数据进行正确分类。公交车站记录就不一样了，因为没有一个真正的公交车站记录被归类为公交车站。火车站数据似乎表现稍好，将大约55.3%的真实火车站数据分类为火车站。关于这个特定模型的预测，一个有趣的观察是，没有一个记录被归类为公交车站——无论是正确的还是不正确的。这可能是由于与火车站和机场记录相比，汽车站记录的数量较少，以及决策树算法的性质。决策树算法在使用非常平衡的数据时表现非常好，但在不平衡的数据上表现不如我们这里的情况。</p><p id="16b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">K-最近邻:</strong></p><p id="de51" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里有一些关于KNN分类器功能的背景知识:<a class="ae kv" href="https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/" rel="noopener ugc nofollow" target="_blank"> KNN </a></p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="c6ba" class="mt mu iq mp b gy mv mw l mx my">from sklearn.neighbors import KNeighborsClassifier</span><span id="5d65" class="mt mu iq mp b gy mz mw l mx my">knn = KNeighborsClassifier(n_neighbors = 22).fit(X_train, y_train)</span><span id="c69f" class="mt mu iq mp b gy mz mw l mx my">accuracy = knn.score(X_test, y_test)</span><span id="fc4f" class="mt mu iq mp b gy mz mw l mx my">knn_predictions = knn.predict(X_test)</span><span id="15d8" class="mt mu iq mp b gy mz mw l mx my">confusion_matrix(y_test, knn_predictions)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/cbe42211af9d8edd084b7525191f750b.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*AeHg_BtkNEidxMjFOpeYLw.png"/></div></figure><p id="498b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用热图可视化结果</p><pre class="kg kh ki kj gt mo mp mq mr aw ms bi"><span id="be37" class="mt mu iq mp b gy mv mw l mx my">plot_confusion_matrix(knn, X_test, y_test, normalize=’true’, values_format = ‘.3f’, display_labels=[‘Airport’,’Bus’,’Train’])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/67a70119023fe9b5ecf3114343b7944d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ekoAGZ6I_fnxkWe59uU9Jg.png"/></div></div></figure><p id="4b2f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该分类器的准确率约为68.0%。该分类器在对机场记录进行正确分类方面做得非常好，准确率约为93.7%。正确分类的公交车站的数量不再是0，但仍然很低，这也可以归因于不平衡的数据。与决策树模型相比，该分类器在列车分类方面表现稍差，仅将大约18.3%的真实火车站预测为火车站。</p><p id="940d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">结论:</strong></p><p id="370d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该项目向我们介绍了基于SafeGraph模式访问数据的POI类别分类。我们的算法在对机场、火车站和公交车站进行分类方面取得了一些成功，所有这些都基于停留时间、游客离家的距离、一天中每个小时的受欢迎程度以及一周中每一天的受欢迎程度。</p><p id="1384" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该系列的下一篇文章(链接即将发布！)将通过调整我们的模型和进行主成分分析来增加我们的分类器的复杂性和能力。</p><p id="ca93" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="np">提问？</em> </strong></p><p id="b0bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我邀请你在<a class="ae kv" href="https://www.safegraph.com/academics" rel="noopener ugc nofollow" target="_blank"> SafeGraph社区</a>的<strong class="ky ir"> #safegraphdata </strong>频道问他们，这是一个面向数据爱好者的免费Slack社区。获得支持、共享您的工作或与GIS社区中的其他人联系。通过SafeGraph社区，学者们可以免费访问美国、英国和加拿大700多万家企业的数据。</p></div></div>    
</body>
</html>