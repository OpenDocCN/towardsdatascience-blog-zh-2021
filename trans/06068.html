<html>
<head>
<title>How to Annotate PDFs and Scanned Images with UBIAI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用UBIAI注释pdf和扫描图像</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-annotate-pdfs-and-scanned-images-for-nlp-applications-f7b7b1db5c4a?source=collection_archive---------20-----------------------#2021-05-31">https://towardsdatascience.com/how-to-annotate-pdfs-and-scanned-images-for-nlp-applications-f7b7b1db5c4a?source=collection_archive---------20-----------------------#2021-05-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a78e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用OCR技术</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a337cfcd6322b3dec0ffcfb4bcac9b0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GqE_ib0K9pur8wo51xdz8g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自<a class="ae ky" href="https://www.pexels.com/photo/photo-of-person-taking-down-notes-7319070/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的<a class="ae ky" href="https://www.pexels.com/@cottonbro?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> cottonbro </a>摄影</p></figure><h1 id="04e4" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="31a2" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">无论是收据、合同、财务文件还是发票等。自动化信息检索将帮助您以极小的成本提高业务效率和生产率。然而，如果没有<strong class="lt iu">的文字注释</strong>，这一惊人的壮举是不可能实现的。虽然诸如NER或关系提取等NLP任务已广泛用于非结构化文本中的信息检索，但分析诸如发票、收据和合同等结构化文档是一项更复杂的工作。</p><p id="3764" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">首先，我们想要提取的实体(如价格、卖家、税收等)没有太多的语义上下文。)可用于训练NLP模型。第二，从一张发票到另一张发票，文档布局经常改变；这将导致传统的自然语言处理任务，如NER，在结构化文档中表现不佳。也就是说，结构化文本(如发票)包含丰富的实体空间信息。该空间信息可用于创建2d位置嵌入，其表示标记在文档内的相对位置。最近，微软发布了一个新的模型<a class="ae ky" href="https://arxiv.org/pdf/1912.13318.pdf" rel="noopener ugc nofollow" target="_blank"> LayoutLM </a>来联合建模扫描文档图像中文本和布局信息之间的交互。他们在几个下游任务中取得了新的最先进的结果，包括表单理解(从70.72到79.27)、收据理解(从94.02到95.24)和文档图像分类(从93.07到94.42)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/87e6839a8ffab1b2b32c2ee955c8103a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*AbQ3rkfAWRZltPECe1ngrw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LayoutLM位置嵌入架构</p></figure><h1 id="8d96" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">扫描图像和PDF注释</h1><p id="84d2" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了对定制发票的layoutLM模型进行微调，我们需要为模型提供带注释的数据，这些数据包含每个标记的边界框坐标以及标记之间的链接(请参见教程<a class="ae ky" href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForTokenClassification_on_FUNSD.ipynb#scrollTo=DTFnEZagQm4v" rel="noopener ugc nofollow" target="_blank">这里的</a>以对FUNSD数据进行微调):</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="9c78" class="my la it mu b gy mz na l nb nc">{<br/>"box": [76,129,118,139],</span><span id="a1f5" class="my la it mu b gy nd na l nb nc">"text": "Brand:",</span><span id="7f12" class="my la it mu b gy nd na l nb nc">"label": "question",</span><span id="cb07" class="my la it mu b gy nd na l nb nc">"words": [</span><span id="d722" class="my la it mu b gy nd na l nb nc">{</span><span id="599d" class="my la it mu b gy nd na l nb nc">"box": [76,129,118,139],</span><span id="63d5" class="my la it mu b gy nd na l nb nc">"text": "Brand:"}],</span><span id="fe8a" class="my la it mu b gy nd na l nb nc">"linking": [[0,2]],</span><span id="1fc6" class="my la it mu b gy nd na l nb nc">"id": 0}]}</span></pre><p id="92ac" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因为大多数收据和发票都是扫描或PDF格式的，所以我们需要找到一种能够直接在原生PDF和图像上进行OCR解析和注释的注释工具。不幸的是，大多数支持OCR注释的注释工具要么过于昂贵，要么不完整，因为您必须在注释之前在外部执行OCR步骤。</p><p id="7dc5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这就是为什么在<a class="ae ky" href="https://ubiai.tools" rel="noopener ugc nofollow" target="_blank"> UBIAI </a>上，我们开发了一个端到端的解决方案，可以直接在原生pdf、扫描图像或来自您手机的图像上进行注释，而不会丢失任何文档布局信息。这对于文本序列和空间信息同等重要的发票提取非常有用。你所要做的就是直接上传你的PDF、JPG或PNG文件，然后开始注释。使用AWS Textract最先进的OCR技术，UBIAI将解析您的文档，并提取所有标记及其边界框。只需突出显示原始文档(右侧面板)或已解析文本(左侧面板)上的标记，并分配一个标签。除了实体标注，还可以进行关系标注和文档分类标注。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/057c9835ceaf62a0337c9c897fadeba7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TWpHkAlBlWXwbWkaAeHHNA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">UBIAI OCR注释接口</p></figure><p id="bfd6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">注释多个单词也很容易。只需在你想要选择的单词周围创建一个框架，它们就会自动得到注释(见下文)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/362d799b6aca9d1e8dbbe9aa8fccf26a.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/1*WFkAkVupwFjgs5wEK-lyLQ.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">带框架选择的OCR注释</p></figure><h1 id="40d6" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">发票预注释</h1><p id="323f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">此外，您可以使用字典、正则表达式(例如查找日期、电子邮件、姓名等)预先注释您的发票。)或者是预先训练好的ML模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/9d4ff9f0906d6da8cf76564ad00d2f08.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*5wldsBAp1lnERQNhxqXL0Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">正则表达式输入</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/3fe9a2b548f9ef5da827dee4c0945f46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9CuKKM_OcxCyQa_3R6gYdw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用正则表达式预先标注日期</p></figure><h1 id="9daf" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">注释导出</h1><p id="67f6" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">完成注释后，只需以JSON格式导出带注释的文档:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/9f3e8d158f2287bd3f81cbac2c3f290a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZJP_7S-TMcyzHa0n-AZreA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">JSON格式的注释导出</p></figure><h1 id="2ad3" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="4659" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">UBIAI的OCR标注，通过提供一个简单易用、准确的标注接口，让你训练NLP模型的摩擦更小。您不必担心使用外部API预处理图像或添加规则来预先注释文档。只需上传您的文档，添加注释，然后导出即可。在下一部分中，我们将展示如何在您自己的发票识别数据集上微调layoutLM模型，敬请关注！</p><p id="d185" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你想为你的结构化文本训练一个自然语言处理模型，请访问<a class="ae ky" href="https://ubiai.tools" rel="noopener ugc nofollow" target="_blank">https://ubai . tools</a>或者发邮件给我们安排一个演示！</p><p id="dcd1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在推特上关注我们<a class="ae ky" href="https://twitter.com/UBIAI5" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>