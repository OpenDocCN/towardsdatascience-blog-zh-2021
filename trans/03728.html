<html>
<head>
<title>Automate your Feature Selection Workflow in one line of Python code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在一行Python代码中实现要素选择工作流的自动化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automate-your-feature-selection-workflow-in-one-line-of-python-code-3d4f23b7e2c4?source=collection_archive---------9-----------------------#2021-03-27">https://towardsdatascience.com/automate-your-feature-selection-workflow-in-one-line-of-python-code-3d4f23b7e2c4?source=collection_archive---------9-----------------------#2021-03-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="84ee" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用Featurewiz快速选择特征</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f9a7791db9600fea7b83f79ae501df13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KpE02GeePZNCsL9E_KYSSA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://pixabay.com/users/qimono-1962238/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=1690423" rel="noopener ugc nofollow" target="_blank">阿雷克索查</a>来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=1690423" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a></p></figure><p id="4b3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就实例数量而言，更多的训练数据会产生更好的数据科学模型，但这不适用于特征数量。真实世界的数据集有许多要素，其中一些对于训练稳健的数据科学模型非常有用，而其他一些则是会影响模型性能的冗余要素。</p><p id="9a72" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特征选择是数据科学模型开发工作流的一个重要元素。选择所有可能的特征组合是多项式解决方案。数据科学家使用各种特征选择技术和技巧来移除冗余特征。</p><blockquote class="lv lw lx"><p id="4a84" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">阅读<a class="ae ky" rel="noopener" target="_blank" href="/top-7-feature-selection-techniques-in-machine-learning-94e08730cd09">这篇文章</a>，了解<a class="ae ky" rel="noopener" target="_blank" href="/top-7-feature-selection-techniques-in-machine-learning-94e08730cd09"> 7个特征选择技巧</a>。</p></blockquote><p id="a187" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将重点介绍如何使用开源Python包Featurewiz实现特征选择工作流的自动化。</p><h1 id="3920" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">Featurewiz:</h1><p id="e95e" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated"><strong class="lb iu"> Featurewiz </strong>是一个开源库，用于从数据集中创建和选择最佳特征，这些特征可进一步用于训练稳健的数据科学模型。Featurewiz还提供了功能工程功能。只需点击一下代码，它就可以创建数百个新功能。Featurewiz API有一个参数<code class="fe mz na nb nc b"><strong class="lb iu">‘feature_engg’</strong></code>，可以设置为<code class="fe mz na nb nc b"><strong class="lb iu">‘interactions’</strong></code>、<code class="fe mz na nb nc b"><strong class="lb iu">‘group by’</strong></code>、<code class="fe mz na nb nc b"><strong class="lb iu">‘target’</strong></code>，它会一口气创建上百个特性。</p><p id="96f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">功能工程或创建新功能不仅仅是featurewiz的功能。它可以减少特征的数量，并选择最佳的特征集合来训练鲁棒的模型。</p><h2 id="8150" class="nd md it bd me ne nf dn mi ng nh dp mm li ni nj mo lm nk nl mq lq nm nn ms no bi translated">Featurewiz是如何工作的？</h2><p id="2731" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">Featurewiz使用两种算法从数据集中选择最佳要素。</p><ul class=""><li id="318e" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu nu nv nw nx bi translated">苏洛夫</li><li id="1ba2" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu nu nv nw nx bi translated">递归XGBoost</li></ul><h2 id="9079" class="nd md it bd me ne nf dn mi ng nh dp mm li ni nj mo lm nk nl mq lq nm nn ms no bi translated">苏洛夫:</h2><p id="48a7" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">SULOV代表<strong class="lb iu"> <em class="ly">搜索不相关的变量列表</em> </strong>，非常类似于<a class="ae ky" href="https://en.wikipedia.org/wiki/Minimum_redundancy_feature_selection" rel="noopener ugc nofollow" target="_blank"> mRMR算法</a>。SULOV算法遵循的步骤如下:</p><ol class=""><li id="082e" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu od nv nw nx bi translated">计算所有超过阈值的相关变量对。</li><li id="4c80" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu od nv nw nx bi translated">相对于目标变量计算MIS(交互信息得分)。</li><li id="2ba3" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu od nv nw nx bi translated">比较每一对相关变量，并移除具有低MIS的特征。</li><li id="8207" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu od nv nw nx bi translated">其余特征具有高的MIS和低的相关性。</li></ol><h2 id="6c5f" class="nd md it bd me ne nf dn mi ng nh dp mm li ni nj mo lm nk nl mq lq nm nn ms no bi translated">递归XGBoost:</h2><p id="a110" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">在SULOV算法选择具有高MIS和对数相关性的最佳特征集之后，使用重复XGBoost算法来计算剩余变量中的最佳特征。步骤如下:</p><ol class=""><li id="eee5" class="np nq it lb b lc ld lf lg li nr lm ns lq nt lu od nv nw nx bi translated">为剩余的要素集构建数据集，并将其分为训练和验证两部分。</li><li id="48c6" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu od nv nw nx bi translated">使用验证计算列车上的前10个特征。</li><li id="d8f9" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu od nv nw nx bi translated">每次使用不同的功能集重复步骤1和2。</li><li id="daee" class="np nq it lb b lc ny lf nz li oa lm ob lq oc lu od nv nw nx bi translated">组合所有10个特征的集合，并对它们进行去重复，这将产生最佳的特征集合。</li></ol><p id="c4db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Featurewiz使用上面讨论的两种算法来寻找最佳的特征集，该特征集可以进一步用于训练健壮的机器学习模型。</p><h1 id="dd62" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">安装和使用:</h1><p id="49bb" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">Featurewiz可以使用Pypl安装</p><pre class="kj kk kl km gt oe nc of og aw oh bi"><span id="bebb" class="nd md it nc b gy oi oj l ok ol"><strong class="nc iu">pip install featurewiz</strong></span></pre><p id="f643" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">安装后，可以导入featurewiz:</p><pre class="kj kk kl km gt oe nc of og aw oh bi"><span id="64e6" class="nd md it nc b gy oi oj l ok ol"><strong class="nc iu">from featurewiz import featurewiz</strong></span></pre><p id="7228" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，开发人员只需要编写一行代码，就可以从数据集中获得最佳的功能集。</p><pre class="kj kk kl km gt oe nc of og aw oh bi"><span id="1ca6" class="nd md it nc b gy oi oj l ok ol"><strong class="nc iu">out1, out2 = featurewiz(dataname, target, corr_limit=0.7, verbose=0,   sep=",", header=0, test_data="", feature_engg="", category_encoders="")</strong></span></pre><p id="797a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Featurewiz不仅可以处理具有一个目标变量的数据集，还可以处理具有多标签目标变量的数据集。从featurewiz返回的数据框包含最佳的要素集，可用于模型训练。开发者不需要指定问题的类型，如果是回归或分类，特性可以自动决定它。</p><h1 id="9b34" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">结论:</h1><p id="d340" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">在本文中，我们讨论了一个开源库featurewiz，它可以自动选择数据集的特性。除了功能选择，featurewiz还具有执行功能工程和生成数百个功能的能力，只需点击一下代码。<br/> Featurewiz使用两种算法(SULOV和递归XGBoost)来选择最佳的特性集。Featurewiz只需点击一行代码即可完成整个功能选择，从而加快了数据科学家的工作流程。数据科学家可以使用几种特性选择技术来筛选出最佳特性，您可以在下面提到的文章中阅读其中的7种特性选择技术。</p><div class="om on gp gr oo op"><a rel="noopener follow" target="_blank" href="/top-7-feature-selection-techniques-in-machine-learning-94e08730cd09"><div class="oq ab fo"><div class="or ab os cl cj ot"><h2 class="bd iu gy z fp ou fr fs ov fu fw is bi translated">机器学习中的7大特征选择技术</h2><div class="ow l"><h3 class="bd b gy z fp ou fr fs ov fu fw dk translated">选择最佳功能的流行策略</h3></div><div class="ox l"><p class="bd b dl z fp ou fr fs ov fu fw dk translated">towardsdatascience.com</p></div></div><div class="oy l"><div class="oz l pa pb pc oy pd ks op"/></div></div></a></div><h1 id="33f3" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">参考资料:</h1><p id="e8d7" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">[1] Featurewiz GitHub回购:<a class="ae ky" href="https://github.com/AutoViML/featurewiz" rel="noopener ugc nofollow" target="_blank">https://github.com/AutoViML/featurewiz</a></p><blockquote class="pe"><p id="6ad8" class="pf pg it bd ph pi pj pk pl pm pn lu dk translated">感谢您的阅读</p></blockquote></div></div>    
</body>
</html>