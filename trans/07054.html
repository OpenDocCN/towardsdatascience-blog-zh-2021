<html>
<head>
<title>Boosting performance by combining trees with GLM: A benchmarking analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过将树与GLM结合来提高绩效:基准分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/boosting-performance-by-combining-trees-with-glm-a-benchmarking-analysis-1840cac91cb1?source=collection_archive---------16-----------------------#2021-06-26">https://towardsdatascience.com/boosting-performance-by-combining-trees-with-glm-a-benchmarking-analysis-1840cac91cb1?source=collection_archive---------16-----------------------#2021-06-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/6b6ff59b126b6cb5a661590737d852ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LOtE9dfHescrvuTZ"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">西蒙·伯杰在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="a821" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">通过将树和GLM结合起来，可以获得多大的改进，它与加法模型相比如何？</h2></div><p id="f624" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">统计建模的一个常见缺陷是确保建模方法适合数据结构。像逻辑回归这样的线性模型假设预测事件的可能性和独立变量之间存在线性关系。在最近研究这个话题时，我看到了<a class="ae jd" href="https://stackoverflow.com/questions/41692017/decision-trees-combined-with-logistic-regression" rel="noopener ugc nofollow" target="_blank">这篇关于StackExchange的</a>文章，讨论了使用浅层决策树作为逻辑回归的特征工程步骤。简而言之，这种策略试图通过使用树作为特征工程步骤来处理非线性数据，以将其转换为虚拟变量，然后可以在逻辑回归规范中使用。</p><p id="6aae" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在研究了这个策略之后，我的印象是执行这个介绍性的步骤可能会引入降低模型灵活性的缺点，同时提供模型结果的边际增加。转换数据以消除非线性，或者在模型的规格中说明非线性，可能更有用。然而，我很惊讶地看到，没有多少文章或帖子将其与其他方法进行比较！</p><p id="7fdb" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了了解决策树结合逻辑回归(树+GLM)的表现，我在三个数据集上测试了该方法，并根据标准逻辑回归和广义加法模型(GAM)对结果进行了基准测试，以了解这两种方法之间是否存在一致的性能差异。</p><h1 id="715f" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">树+ GLM方法论</h1><p id="87d9" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">逻辑回归和决策树通常是最先介绍的两种分类模型。每个都有自己的陷阱。回归模型假设因变量可以用一组应用于自变量的线性函数来解释，并具有以下形式的方程:</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/4560210d5edf467103940189f3d7f1b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:264/0*NANTB-pQD9svLu7z"/></div></figure><p id="c3db" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">决策树不对变量的分布做出假设，它们只是根据基尼系数等标准在决策树中创建一个新的分支。但是，决策树容易过度拟合，并且对于训练数据的变化可能不稳定。</p><p id="c2be" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下图说明了一元模型中因变量范围内的线性回归和决策树模型的结果:</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mt"><img src="../Images/6eacb772dcf7cfd21db83b13adaabc88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vpJeQA1fzQXH_46sedACLQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="9cb5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从上面的图表中，我们可以看到，与线性回归模型生成的平滑函数相比，决策树的预测是不连续的。虽然这对于简单的线性数据是有问题的，但是决策树策略以非线性方式改变的能力为其在非线性数据上的使用提供了理由。</p><p id="c934" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了试图弥补这两种方法的缺点，一些来源建议使用决策树作为中间步骤，这有助于消除模型中潜在的非线性。最简单的过程如下:</p><ol class=""><li id="9df0" class="mu mv jg kx b ky kz lb lc le mw li mx lm my lq mz na nb nc bi translated">为训练数据X拟合一个浅层决策树T(X)。该树将有N个终端节点。</li><li id="4f31" class="mu mv jg kx b ky nd lb ne le nf li ng lm nh lq mz na nb nc bi translated">表示为C_n的n个分类变量作为特征包含在逻辑回归规范中。</li><li id="afbb" class="mu mv jg kx b ky nd lb ne le nf li ng lm nh lq mz na nb nc bi translated">使用修改的数据集拟合逻辑回归。</li></ol><p id="19a3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有两种简单的方法来处理数据中的非线性。第一种选择是对原始数据使用一些其他转换步骤，使其与因变量成线性关系。不过，这种策略并不总是一种选择，其适当性因领域而异。消除它的第二种方法是将模型规范改为可以处理非线性数据的方法。</p><h1 id="b296" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">广义可加模型</h1><p id="0345" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">有几种方法可以用来处理非线性数据，但我选择的是广义加法模型。广义加性模型是由Trevor Hastie和Robert Tibshirani在“<a class="ae jd" href="https://web.stanford.edu/~hastie/Papers/gam.pdf" rel="noopener ugc nofollow" target="_blank">广义加性模型</a>”中提出的一个框架。作者接着写了统计学习的<a class="ae jd" href="https://web.stanford.edu/~hastie/ElemStatLearn/" rel="noopener ugc nofollow" target="_blank">元素</a>，这是我第一次遇到它。</p><p id="a9a5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">它采用了逻辑回归所基于的广义线性模型的概念，放松了线性基函数的假设。在逻辑回归规范的情况下，逻辑回归的GAM等价于:</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/cbb9534150dcb23a2b539c7d8c6f1146.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/0*sBbbab_63FTO2TS5"/></div></figure><p id="4180" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这种情况下，上面的符号替代</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/93670b2f51bea8b59aeae091320e56e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:74/0*j26g4MLbaBfY6w7V"/></div></figure><p id="f857" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/914c44f123c7375c12a2a51a0b42616e.png" data-original-src="https://miro.medium.com/v2/resize:fit:28/0*TpRGH_5Qzn0fRvmv"/></div></figure><p id="29ee" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在原始的逻辑回归方程中。这是因为我们已经将对每个因变量进行操作这一术语改为任意平滑函数。或者，我们可以将逻辑回归模型视为加法模型，其中:</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/e2bd185946943e1b2becea012f95c70c.png" data-original-src="https://miro.medium.com/v2/resize:fit:180/0*RXNoBbYVGbZ-MORw"/></div></figure><p id="009e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于某些回归系数</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/a0ff2ba1a7b58289956d3d748cb0a112.png" data-original-src="https://miro.medium.com/v2/resize:fit:24/0*-uZfsq8jqB8FAohA"/></div></figure><p id="e3c5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">很明显，这为我们如何处理我们正在建模的变量提供了额外的灵活性，因此我们将在我们的数值实验中使用该规范作为tree+logistic回归规范的挑战者。</p><h1 id="70e7" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">数据</h1><p id="0025" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">本文中使用了三组数据进行比较，它们是:</p><ol class=""><li id="2fe4" class="mu mv jg kx b ky kz lb lc le mw li mx lm my lq mz na nb nc bi translated">合成数据集—包含10，000个观察值的人工数据集，包括线性和非线性变量。</li><li id="0715" class="mu mv jg kx b ky nd lb ne le nf li ng lm nh lq mz na nb nc bi translated">银行数据—由银行活动生成的数据集。这里使用的数据实际上是由Andrzej Szymanski博士整理和格式化的，他写了一篇关于使用决策树进行逻辑回归的文章。我想包括这个，因为它可以提供一个有价值的比较，结果已经产生了。原始数据来自<a class="ae jd" href="https://github.com/AndrzejSzymanski/TDS/blob/master/banking.csv" rel="noopener ugc nofollow" target="_blank"> Andrzej的</a> GitHub。</li><li id="ef99" class="mu mv jg kx b ky nd lb ne le nf li ng lm nh lq mz na nb nc bi translated">成人数据—用于尝试预测收入是否超过50，000美元/年的人口普查数据。它可以在UCI机器学习库<a class="ae jd" href="https://archive.ics.uci.edu/ml/datasets/adult" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</li></ol><p id="fae8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在下面的代码块中，我们收集了将在我们的三个测试中使用的数据，并对其进行了检查。我们首先生成合成数据，然后下载并格式化银行和成人数据集。在此之后，我们执行一些数据清理步骤，以确保我们使用的变量不被表示为字符。最后，我们将数据分为训练和测试数据:</p><pre class="mp mq mr ms gt nn no np nq aw nr bi"><span id="98b2" class="ns ls jg no b gy nt nu l nv nw">rm(list = ls())<br/>library(pacman)<br/>p_load(data.table,caret,ggplot2,plotly,mgcv,rpart,magrittr,precrec,MLmetrics,partykit,gam,rmarkdown,knitr,broom,rpart.plot,reactable)<br/>set.seed(13)<br/>with.nonlinear &lt;- data.table(twoClassSim(10000,<br/>                                         linearVars = 6,ordinal = F ) )<br/>data.list &lt;- list("Synthetic" = with.nonlinear,<br/>                  "Banking" =  fread("<a class="ae jd" href="https://raw.githubusercontent.com/AndrzejSzymanski/TDS-LR-DT/master/banking_cleansed.csv" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/AndrzejSzymanski/TDS-LR-DT/master/banking_cleansed.csv</a>")  ,<br/>                  "Adult" = fread("<a class="ae jd" href="https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data" rel="noopener ugc nofollow" target="_blank">https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data</a>")  )<br/>names(data.list[[3]]) &lt;- c("age","workclass","fnlwgt","education","education-num","marital-status","occupation", "relationship", "race","sex","capital-gain","capital-loss","hours-per-week","native-country","Income-class")<br/># Change variables to factors for banking data-set<br/>banking.names.for.factors &lt;- names(data.list$Banking)[apply(data.list$Banking,MARGIN = 2, function(x){length(unique(x))})==2]<br/>data.list$Banking[,<br/>                  names(data.list$Banking)[apply(data.list$Banking,MARGIN = 2, function(x){<br/>                    length(unique(x))})==2] := lapply(X = .SD,FUN = factor),<br/>                  .SDcols = banking.names.for.factors]<br/># Change variables to factors for Adult data-set:<br/>adult.names.for.factors &lt;- names(data.list$Adult)[sapply(X = 1:ncol(data.list$Adult),function(x){is.character( data.list$Adult[[x]]  )})]<br/>data.list$Adult[,names(data.list$Adult)[sapply(X = 1:ncol(data.list$Adult),<br/>                                               function(x){is.character( data.list$Adult[[x]]  )})]:= lapply(X = .SD,FUN = factor),<br/>                .SDcols = adult.names.for.factors]<br/>data.list$Adult[,names(data.list$Adult)[sapply(X = 1:ncol(data.list$Adult),<br/>                                               function(x){is.integer( data.list$Adult[[x]]  )})]:= lapply(X = .SD,FUN = as.numeric ),<br/>                .SDcols = names(data.list$Adult)[sapply(X = 1:ncol(data.list$Adult),<br/>                                                        function(x){is.integer( data.list$Adult[[x]]  )})]]<br/>training.data &lt;- list()<br/>test.data &lt;- list()<br/>for( i in 1:length(data.list)){<br/>  train_inds &lt;- sample(x = 1:nrow(data.list[[i]]) ,size = .8*nrow(data.list[[i]]))<br/>  training.data[[i]] &lt;- data.list[[i]][train_inds]<br/>  test.data[[i]] &lt;-   data.list[[i]][-train_inds]  }<br/>names(training.data)&lt;- names(data.list)<br/>names(test.data)&lt;- names(data.list)</span></pre><p id="92df" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在进行我们的基准分析之前，了解哪些变量与因变量有非线性关系是有用的。一个简单而直观的方法是绘制因变量和自变量之间的关系图，看看从视觉上看非线性关系是否明显。在这里的实现中，我使用一个GAM和一个变量来描述两个变量之间关系的大致形状。您可以在下面看到使用图表评估非线性的实现:</p><pre class="mp mq mr ms gt nn no np nq aw nr bi"><span id="0c44" class="ns ls jg no b gy nt nu l nv nw">nonlinear.viz &lt;- function(dt,dep.var,indep.var,bins = 100){<br/>  dt$y &lt;- as.numeric(as.character(dt$y))<br/>  return.plot &lt;- ggplot(dt, <br/>                        aes_string( x = indep.var,y = dep.var) ) + stat_smooth(method = "gam", <br/>                                                                               method.args = list(family = "binomial"),) + theme_bw() + theme(axis.title = element_text(size = 16),axis.text = element_text(size = 11),plot.title = element_text(size = 20)   ) +ylab(indep.var)+<br/>    xlab(dep.var)+<br/>    ggtitle(paste("Relationship between ",dep.var," and ", indep.var,sep = ""))<br/>  return(return.plot)}</span><span id="e43f" class="ns ls jg no b gy nx nu l nv nw">training.data$Synthetic[,Class := ifelse(Class == "Class1", 1,0)]<br/>test.data$Synthetic[,Class := ifelse(Class == "Class1", 1,0)]<br/>training.data$Adult[,"Class" := ifelse(`Income-class` == "&gt;50K", 1,0)]<br/>test.data$Adult[,"Class" := ifelse(`Income-class` == "&gt;50K", 1,0)]<br/>synthetic.plot &lt;- lapply(X = names(training.data$Synthetic)[names(training.data$Synthetic)!="Class"],<br/>                         function(x){nonlinear.viz(dt = training.data$Synthetic,dep.var = "Class",x)})<br/>banking.plot &lt;- lapply(X = c("age","previous","euribor3m","cons_conf_idx","cons_price_idx","nr_employed", "emp_var_rate"   ,   "pdays"),<br/>                       function(x){nonlinear.viz(dt = training.data$Banking,dep.var = "y",x)})<br/>names(training.data$Adult) &lt;- gsub(names(training.data$Adult),pattern = "-",replacement = "_")<br/>names(test.data$Adult) &lt;- names(training.data$Adult)<br/>adult.plot &lt;- lapply(X = c("age","education_num","capital_gain","capital_loss","hours_per_week"),<br/>                     function(x){nonlinear.viz(dt = training.data$Adult,<br/>                                               dep.var = "Class",x )})</span></pre><p id="4444" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">上面的代码将为<em class="ny">所有</em>变量关系生成图表。为了简洁起见，我在下面的章节中只关注非线性数据:</p><p id="c59b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">合成数据集</strong></p><p id="bd81" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">正在使用的合成数据集是从caret库中的<a class="ae jd" href="https://rdrr.io/cran/caret/man/twoClassSim.html" rel="noopener ugc nofollow" target="_blank"> twoClassSim </a>函数生成的。这个函数很简单:数据集是由一个二元结果和一组线性相关或非线性相关的变量生成的。这个数据集对我们的测试很有用，因为它允许我们比较算法，而不需要关心关于问题领域的信息。下表总结了变量之间的关系:</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nz"><img src="../Images/ca80835faf487fa4bd340bb31d9edba1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*evr-a-FVwf2O9QvgnaBYDw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="c00e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我使用以下公式绘制了合成数据的非线性变量与数据集中类的可能性的关系:</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/f7180030a30dd9700183525c75423645.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*RD21UfcDm9n0zc0cJJdAzA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="3ddb" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以看到变量是我们所期望的:在所有情况下，在实例是正类的可能性和负类的可能性之间通常存在负的非线性关系。</p><p id="6aa7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">银行数据集</strong></p><p id="c7be" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">银行数据集包含27个独立变量。其中，7个变量是连续变量，其余的是二元变量。该特性与因变量的关系如下表所示:</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ob"><img src="../Images/4c9256072dbb742481fb43fe1f7cd889.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q92HjtDmcC51E8Ykl8k43g.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="23f7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">与合成数据一样，我也制作了一组图表，显示连续特征变量和因变量(在本例中为y)之间的关系:</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oc"><img src="../Images/ef5c00fee28d626fb988290ceeef849c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oA25ItOBEv-hCvmkTac7pA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="84dd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以看到，在上面的每个示例图表中，因变量和自变量之间存在明显的非线性关系，使用线性基函数很难补偿这种关系。</p><p id="0770" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">成人数据集</strong></p><p id="d521" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">与银行数据集一样，成人数据集有许多变量，这些变量是二元变量以及一组连续变量(在本例中是五个)。下表对它们进行了总结:</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nz"><img src="../Images/18d75031b02dac3f30668b93b873112a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f5wOTfjsX17_mFEvWrTqug.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="75cc" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我还制作了下图，展示了每个变量和因变量之间的关系:</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi od"><img src="../Images/0f300ed66f358fb7497c5c9058ff85eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6wUd1-Dt35XUq909UCv39g.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="667c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">连续自变量和因变量之间的关系类似于银行数据集。唯一的例外是education_num变量，它表示在校的年数。我们可以看到，它有一个明显的积极的关系，可能是近似的线性函数，尽管凹度。</p><h2 id="885f" class="ns ls jg bd lt oe of dn lx og oh dp mb le oi oj md li ok ol mf lm om on mh oo bi translated">数据平衡</h2><p id="33a9" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">在拟合和试验模型之前，检查数据集中类之间的平衡是有帮助的。数据中的类别不平衡会引入偏差，这可能需要使用重采样技术来解决。</p><p id="d09c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将使用下面显示的代码来调查这种不平衡:</p><pre class="mp mq mr ms gt nn no np nq aw nr bi"><span id="3c83" class="ns ls jg no b gy nt nu l nv nw">sum.func &lt;- function(x,col,model.name){ <br/>  dims &lt;- data.table( "Measure" = c("Observations","Factors")  , "Count" = dim(x))<br/>  factors &lt;- data.table( "Minority Class Percent",  min(x[,.N,by = col]$N)/sum(x[,.N,by = col]$N)  )<br/>  names(factors) &lt;- c("Measure","Count")<br/>  for.return &lt;- data.table(rbind(dims,factors)   )<br/>  names(for.return)[2] &lt;- model.name<br/>  # factors$Measure &lt;- paste("Class = ",factors$Measure,sep = "")<br/>  return(  for.return    )  }<br/>dep.vars &lt;- c("Class", "y", "Income_class")</span><span id="8206" class="ns ls jg no b gy nx nu l nv nw">summaries &lt;- lapply(X = 1:length(training.data),<br/>                    FUN = function(x){sum.func(training.data[[x]], dep.vars[x] ,<br/>                                               model.name = names(training.data)[x])   })<br/>summaries[[1]]$Banking &lt;- summaries[[2]]$Banking<br/>summaries[[1]]$Adult &lt;- summaries[[3]]$Adult<br/>kable(summaries[[1]],digits = 3)</span></pre><p id="0e8e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我对表格的结果进行了格式化，以显示与下面数据集的其余部分相比，因变量的少数类的大小。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi op"><img src="../Images/6f52974ebe0956c472fd2eeaad074b12.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*5_iHlV5PX4cUgB0y_UdLaQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="7819" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从上表中我们可以看出，银行和成人数据集在预测类别上存在明显的不平衡。为了纠正这一点，我们将使用合成少数过采样技术并查看结果。</p><p id="ebd3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">快速注意:SMOTE步骤可能需要一些时间。</p><pre class="mp mq mr ms gt nn no np nq aw nr bi"><span id="43c0" class="ns ls jg no b gy nt nu l nv nw">banking.smote &lt;- RSBID::SMOTE_NC(data = training.data$Banking , outcome = "y" )<br/>adult.smote &lt;- RSBID::SMOTE_NC(data = training.data$Adult, outcome = "Income_class" )</span><span id="c6f3" class="ns ls jg no b gy nx nu l nv nw">p_load(data.table,rmarkdown,knitr)<br/>resampled_data &lt;- list(training.data$Synthetic,banking.smote,adult.smote)<br/>dep.vars &lt;- c("Class", "y", "Income_class")<br/>names(resampled_data) &lt;- names(training.data)<br/>summaries &lt;- lapply(X = 1:length(training.data),<br/>                    FUN = function(x){sum.func(resampled_data[[x]], <br/>                                               dep.vars[x] ,<br/>                                               model.name = names(training.data)[x])   })<br/>summaries[[1]]$Banking &lt;- summaries[[2]]$Banking<br/>summaries[[1]]$Adult &lt;- summaries[[3]]$Adult<br/>kable(summaries[[1]],digits = 3)</span></pre><figure class="mp mq mr ms gt is gh gi paragraph-image"><div class="gh gi op"><img src="../Images/8c2a61bdfea37759ab174c0e525e1283.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*N9Cs98iVKZ9Wb5LgWRug0w.png"/></div></figure><h1 id="1a1f" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">构建决策树</h1><p id="0f21" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">我们首先构建简单的决策树，作为原始分类变量的因子<em class="ny">而不是</em>。这些树必须很小，以避免过度生长。我已经使用最大深度为2、3和4的树测试了模型，并基于其在ROC和PR AUC中提高的准确性，选择在每个模型中使用最大深度为4的树。在下面的代码块中，CART决策树与叶节点预测相匹配，然后用于在数据中创建新的因子变量。之后，新数据用于拟合逻辑回归模型。</p><p id="cd5e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们首先拟合初始决策树(另一个注意:我用深度和其他细节的几次迭代测试了这个。以下选项似乎表现最佳):</p><pre class="mp mq mr ms gt nn no np nq aw nr bi"><span id="e404" class="ns ls jg no b gy nt nu l nv nw">synthetic.tree.2 &lt;- rpart(data = training.data$Synthetic,<br/>                          formula = Class~Linear1+Linear2+Linear3+Linear4+Linear5+Linear6+Nonlinear1 +Nonlinear2 +Nonlinear3,<br/>                          control = rpart.control(  maxdepth = 4 ))<br/>banking.tree.3 &lt;- rpart(data = banking.smote,<br/>                        formula = y~.-V1, control = rpart.control(  maxdepth = 4)  )<br/>adult.tree.3 &lt;- rpart(data = adult.smote,<br/>                      formula = Class~age+workclass+fnlwgt+education+education_num +marital_status+occupation+relationship+race+sex+capital_gain +  capital_loss + hours_per_week+ native_country,<br/>                      control = rpart.control(  maxdepth = 4))</span><span id="f700" class="ns ls jg no b gy nx nu l nv nw">synth.models &lt;- list(synthetic.tree.2)<br/>banking.models &lt;- list(banking.tree.3)<br/>adult.models &lt;- list(adult.tree.3)</span><span id="cc0e" class="ns ls jg no b gy nx nu l nv nw">tree.to.feature &lt;- function(tree.model,dt){<br/>  require(partykit)<br/>  tree_labels &lt;- factor( predict(as.party(tree.model), dt ,type = "node") )<br/>  return(tree_labels)}</span></pre><p id="5650" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，我们将这些结果用于拟合逻辑回归模型:</p><pre class="mp mq mr ms gt nn no np nq aw nr bi"><span id="4983" class="ns ls jg no b gy nt nu l nv nw">synth.train.preds &lt;- lapply(X = synth.models,FUN = function(x){   tree.to.feature(tree.model = x,dt = training.data$Synthetic)  }) %&gt;% data.frame<br/>banking.train.preds &lt;-lapply(X = banking.models,FUN = function(x){   tree.to.feature(tree.model = x,dt = training.data$Banking)  }) %&gt;% data.frame<br/>adult.train.preds &lt;-lapply(X = adult.models,FUN = function(x){   tree.to.feature(tree.model = x,dt = training.data$Adult)  }) %&gt;% data.frame<br/>names(synth.train.preds) &lt;- c("three.nodes")<br/>names(banking.train.preds) &lt;- c("four.nodes")<br/>names(adult.train.preds) &lt;- c("four.nodes")<br/>training.data$Synthetic &lt;- cbind( training.data$Synthetic,synth.train.preds )<br/>training.data$Banking &lt;- cbind(training.data$Banking ,banking.train.preds )<br/>training.data$Adult &lt;- cbind(training.data$Adult ,adult.train.preds )<br/>synth.model.three.deep&lt;- glm(formula = Class~Linear1+Linear2+Linear3+Linear4+Linear5+Linear6+Nonlinear1 +Nonlinear2 +Nonlinear3 + three.nodes,family = "binomial",data = training.data$Synthetic)<br/>banking.mode.four.deep &lt;- glm(formula = y~.-V1 ,family = "binomial",data = training.data$Banking)<br/>adult.mode.four.deep &lt;- glm(formula = Class~age+workclass+fnlwgt+education+education_num +marital_status+occupation+relationship+race+sex+capital_gain +  capital_loss + hours_per_week+ native_country + four.nodes,<br/>                            family = "binomial",<br/>                            data = training.data$Adult)</span></pre><p id="6e54" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，我们拟合了GAM和GLM模型，我们将使用这两个模型对GAM树模型结果进行基准测试:</p><pre class="mp mq mr ms gt nn no np nq aw nr bi"><span id="73be" class="ns ls jg no b gy nt nu l nv nw"># Create GAM models and the GLM models:<br/>synth.gam &lt;- gam(data = training.data$Synthetic,formula = Class~s(Linear1)+s(Linear2)+s(Linear3)+s(Linear4)+s(Linear5)+s(Linear6)+s(Nonlinear1) +s(Nonlinear2) +s(Nonlinear3),family = binomial)</span><span id="87ab" class="ns ls jg no b gy nx nu l nv nw">banking.gam &lt;- gam(formula = y~s(age)+s(previous)+s(euribor3m)+s(cons_conf_idx)+s(cons_price_idx)+s(nr_employed)+s(emp_var_rate)+s(pdays)+`job_blue-collar`+<br/>                     job_management+`job_other 1`+`job_other 2`+job_services+job_technician+marital_married+marital_single+ education_high.school+education_professional.course+education_university.degree+education_unknown+default_unknown+housing_unknown+<br/>                     housing_yes+loan_unknown+loan_yes+poutcome_nonexistent+poutcome_success,family = "binomial",data = training.data$Banking)</span><span id="18dd" class="ns ls jg no b gy nx nu l nv nw">adult.gam &lt;- gam(formula = Class~s(age)+(workclass)+s(fnlwgt)+(education)+s(education_num) +(marital_status)+(occupation)+(relationship)+(race)+(sex)+s(capital_gain) +  s(capital_loss) + s(hours_per_week)+ (native_country),<br/>                 family = "binomial",<br/>                 data = training.data$Adult)<br/># Create GLM Models</span><span id="5891" class="ns ls jg no b gy nx nu l nv nw">synth.model.glm&lt;- glm(formula = Class~Linear1+Linear2+Linear3+Linear4+Linear5+Linear6+Nonlinear1 +Nonlinear2 +Nonlinear3 ,family = "binomial",data = training.data$Synthetic)</span><span id="bd10" class="ns ls jg no b gy nx nu l nv nw">banking.mode.glm &lt;- glm(formula = y~.-V1-four.nodes ,family = "binomial",data = training.data$Banking)</span><span id="c3d9" class="ns ls jg no b gy nx nu l nv nw">adult.mode.glm &lt;- glm(formula = Class~age+workclass+fnlwgt+education+education_num +marital_status+occupation+relationship+race+sex+capital_gain +  capital_loss + hours_per_week+ native_country ,<br/>                      family = "binomial",<br/>                      data = training.data$Adult)Finally, we fit the GAM and GLM models which we will be using to benchmark the GLM+Tree model results:</span><span id="5103" class="ns ls jg no b gy nx nu l nv nw"><em class="ny"># Create GAM models and the GLM models:</em><br/>synth.gam <strong class="no jh">&lt;-</strong> gam(data <strong class="no jh">=</strong> training.data<strong class="no jh">$</strong>Synthetic,formula <strong class="no jh">=</strong> Class<strong class="no jh">~</strong>s(Linear1)<strong class="no jh">+</strong>s(Linear2)<strong class="no jh">+</strong>s(Linear3)<strong class="no jh">+</strong>s(Linear4)<strong class="no jh">+</strong>s(Linear5)<strong class="no jh">+</strong>s(Linear6)<strong class="no jh">+</strong>s(Nonlinear1) <strong class="no jh">+</strong>s(Nonlinear2) <strong class="no jh">+</strong>s(Nonlinear3),family <strong class="no jh">=</strong> binomial)<br/><br/>banking.gam <strong class="no jh">&lt;-</strong> gam(formula <strong class="no jh">=</strong> y<strong class="no jh">~</strong>s(age)<strong class="no jh">+</strong>s(previous)<strong class="no jh">+</strong>s(euribor3m)<strong class="no jh">+</strong>s(cons_conf_idx)<strong class="no jh">+</strong>s(cons_price_idx)<strong class="no jh">+</strong>s(nr_employed)<strong class="no jh">+</strong>s(emp_var_rate)<strong class="no jh">+</strong>s(pdays)<strong class="no jh">+</strong>`job_blue-collar`<strong class="no jh">+</strong><br/>                     job_management<strong class="no jh">+</strong>`job_other 1`<strong class="no jh">+</strong>`job_other 2`<strong class="no jh">+</strong>job_services<strong class="no jh">+</strong>job_technician<strong class="no jh">+</strong>marital_married<strong class="no jh">+</strong>marital_single<strong class="no jh">+</strong> education_high.school<strong class="no jh">+</strong>education_professional.course<strong class="no jh">+</strong>education_university.degree<strong class="no jh">+</strong>education_unknown<strong class="no jh">+</strong>default_unknown<strong class="no jh">+</strong>housing_unknown<strong class="no jh">+</strong><br/>                     housing_yes<strong class="no jh">+</strong>loan_unknown<strong class="no jh">+</strong>loan_yes<strong class="no jh">+</strong>poutcome_nonexistent<strong class="no jh">+</strong>poutcome_success,family <strong class="no jh">=</strong> "binomial",data <strong class="no jh">=</strong> training.data<strong class="no jh">$</strong>Banking)<br/><br/>adult.gam <strong class="no jh">&lt;-</strong> gam(formula <strong class="no jh">=</strong> Class<strong class="no jh">~</strong>s(age)<strong class="no jh">+</strong>(workclass)<strong class="no jh">+</strong>s(fnlwgt)<strong class="no jh">+</strong>(education)<strong class="no jh">+</strong>s(education_num) <strong class="no jh">+</strong>(marital_status)<strong class="no jh">+</strong>(occupation)<strong class="no jh">+</strong>(relationship)<strong class="no jh">+</strong>(race)<strong class="no jh">+</strong>(sex)<strong class="no jh">+</strong>s(capital_gain) <strong class="no jh">+</strong>  s(capital_loss) <strong class="no jh">+</strong> s(hours_per_week)<strong class="no jh">+</strong> (native_country),<br/>                           family <strong class="no jh">=</strong> "binomial",<br/>                           data <strong class="no jh">=</strong> training.data<strong class="no jh">$</strong>Adult)<br/><em class="ny"># Create GLM Models</em><br/><br/>synth.model.glm<strong class="no jh">&lt;-</strong> glm(formula <strong class="no jh">=</strong> Class<strong class="no jh">~</strong>Linear1<strong class="no jh">+</strong>Linear2<strong class="no jh">+</strong>Linear3<strong class="no jh">+</strong>Linear4<strong class="no jh">+</strong>Linear5<strong class="no jh">+</strong>Linear6<strong class="no jh">+</strong>Nonlinear1 <strong class="no jh">+</strong>Nonlinear2 <strong class="no jh">+</strong>Nonlinear3 ,family <strong class="no jh">=</strong> "binomial",data <strong class="no jh">=</strong> training.data<strong class="no jh">$</strong>Synthetic)<br/><br/>banking.mode.glm <strong class="no jh">&lt;-</strong> glm(formula <strong class="no jh">=</strong> y<strong class="no jh">~</strong>.<strong class="no jh">-</strong>V1<strong class="no jh">-</strong>four.nodes ,family <strong class="no jh">=</strong> "binomial",data <strong class="no jh">=</strong> training.data<strong class="no jh">$</strong>Banking)<br/><br/>adult.mode.glm <strong class="no jh">&lt;-</strong> glm(formula <strong class="no jh">=</strong> Class<strong class="no jh">~</strong>age<strong class="no jh">+</strong>workclass<strong class="no jh">+</strong>fnlwgt<strong class="no jh">+</strong>education<strong class="no jh">+</strong>education_num <strong class="no jh">+</strong>marital_status<strong class="no jh">+</strong>occupation<strong class="no jh">+</strong>relationship<strong class="no jh">+</strong>race<strong class="no jh">+</strong>sex<strong class="no jh">+</strong>capital_gain <strong class="no jh">+</strong>  capital_loss <strong class="no jh">+</strong> hours_per_week<strong class="no jh">+</strong> native_country ,<br/>                           family <strong class="no jh">=</strong> "binomial",<br/>                           data <strong class="no jh">=</strong> training.data<strong class="no jh">$</strong>Adult)</span></pre><h1 id="52db" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">模型检验</h1><p id="36da" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">既然我们已经拟合了模型，我们可以比较它们的结果。为此，我将依赖ROC AUC和PR AUC。评估结果的代码如下所示:</p><pre class="mp mq mr ms gt nn no np nq aw nr bi"><span id="558d" class="ns ls jg no b gy nt nu l nv nw">synth.test.preds &lt;- lapply(X = synth.models,FUN = function(x){  <br/>  tree.to.feature(tree.model = x,dt = test.data$Synthetic)  }) %&gt;% data.frame<br/>banking.test.preds &lt;-lapply(X = banking.models,FUN = function(x){ <br/>  tree.to.feature(tree.model = x,dt = test.data$Banking)  }) %&gt;% data.frame<br/>adult.test.preds &lt;- lapply(X = adult.models,FUN = function(x){ <br/>  tree.to.feature(tree.model = x,dt = test.data$Adult)  }) %&gt;% data.frame<br/>names(synth.test.preds) &lt;- c( "three.nodes")<br/>names(banking.test.preds) &lt;- c( "four.nodes")<br/>names(adult.test.preds) &lt;- c( "four.nodes")<br/>test.data$Synthetic &lt;- cbind( test.data$Synthetic,synth.test.preds )<br/>test.data$Banking &lt;- cbind(test.data$Banking ,banking.test.preds )<br/>test.data$Adult &lt;- cbind(test.data$Adult ,adult.test.preds )<br/>training.for.mmdata &lt;- data.frame(predict(banking.mode.glm,newdata = training.data$Banking, type = "response" ),<br/>                                  predict(banking.mode.four.deep, newdata = training.data$Banking,type = "response" ),<br/>                                  predict(banking.gam,newdata = training.data$Banking, type = "response" )  ) <br/>training.mdat &lt;- mmdata(scores = training.for.mmdata,labels = training.data$Banking$y,<br/>                        modnames = c("Logistic Regression", "Tree w/ GLM", "GAM"))<br/>testing.for.mmdata &lt;- data.frame(predict(synth.model.glm,newdata = test.data$Synthetic, type = "response" ),<br/>                                 predict(synth.model.three.deep, newdata = test.data$Synthetic,type = "response" ),<br/>                                 predict(synth.gam,newdata = test.data$Synthetic, type = "response" )  ) <br/>testing_mdat &lt;- mmdata(scores = testing.for.mmdata,labels = test.data$Synthetic$Class,<br/>                       modnames = c("Logistic Regression", "Tree w/ GLM", "GAM"))<br/>training_ROC &lt;- autoplot(evalmod(training.mdat),curvetype = c("ROC"))+theme(legend.position = "bottom") +ggtitle("ROC Curve - Training Data")<br/>training_PR &lt;- autoplot(evalmod(training.mdat),curvetype = c("PR"))+theme(legend.position = "bottom") +ggtitle("PR Curve - Training Data")<br/>testing_ROC &lt;- autoplot(evalmod(testing_mdat),curvetype = c("ROC"))+theme(legend.position = "bottom") +ggtitle("ROC Curve - Testing Data")<br/>testing_PR &lt;- autoplot(evalmod(testing_mdat),curvetype = c("PR"))+theme(legend.position = "bottom") +ggtitle("PR Curve - Testing Data")</span></pre><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oq"><img src="../Images/d5f97ed0a8ceda425bd0df50f2e7da88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8Zud1mUf6rhlg1G89bmnXw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi or"><img src="../Images/4db612ba709a101edab7067dbfbfefe6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vO25TP86HtmjhJ0f40g88A.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi os"><img src="../Images/095c49955f4d79983f4c2b36ca5c2ab6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6a9ZYPit__EbIEiJ7aRPIw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="9a6d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">每个模型在训练和测试数据集上都表现良好，当切换到样本外数据时，模型精度几乎没有下降。在所有情况下，使用决策树作为特性工程步骤都会对性能指标有一点改进。我们还看到，在所有情况下，GAM模型优于任何一个模型。</p><p id="f987" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在一些情况下，GAM比GAM树模型的表现好得多，比GAM树模型比逻辑回归模型的表现好得多。由此，我们可以看到，在模型规范中包含非线性数据的结构而不是转换它，可以在所有情况下提高性能。这一点很重要，因为使用GAM还消除了对模型的潜在决策树的调查和比较。</p><h1 id="309f" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">结论:</h1><p id="e450" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">我比较了处理非线性数据的两种不同方法的结果。第一种是使用决策树模型作为特征工程步骤来创建一组一次性编码器，然后在逻辑回归模型中使用。第二种方法是广义的附加模型，它将数据的潜在非线性纳入模型规范。这消除了因变量和自变量之间线性关系的假设。这两种方法在三个数据集上进行了比较，以查看它们的性能是否有一致的差异。测试表明，GAM在各个方面都优于GAM树模型。两个模型都优于简单的逻辑回归模型。</p><p id="91d0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">GAMs优于树+GLM模型的事实是重要的，因为它还消除了特征工程步骤和关于用于生成处理变量的树的深度的模糊性。</p><h1 id="ee62" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">参考资料:</h1><p id="a344" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">[1] T. Hastie，R. Tibshirani，J. Friedman，<a class="ae jd" href="https://web.stanford.edu/~hastie/ElemStatLearn/" rel="noopener ugc nofollow" target="_blank">统计学习的要素</a> (2009)</p><p id="6f60" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[2] T. Hastie，R. Tibshirani，<a class="ae jd" href="https://web.stanford.edu/~hastie/Papers/gam.pdf" rel="noopener ugc nofollow" target="_blank">广义加法模型</a>，统计科学(1986)</p><p id="127e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[3]Syzmanski，Andrzej，<a class="ae jd" rel="noopener" target="_blank" href="/combining-logistic-regression-and-decision-tree-1adec36a4b3f">结合逻辑回归和决策树</a>，走向数据科学(2020)</p></div></div>    
</body>
</html>