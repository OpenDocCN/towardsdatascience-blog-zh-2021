<html>
<head>
<title>Learning to hash</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">学习散列</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learning-to-hash-36367b9814f1?source=collection_archive---------13-----------------------#2021-10-21">https://towardsdatascience.com/learning-to-hash-36367b9814f1?source=collection_archive---------13-----------------------#2021-10-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/02ef98f56f82fd079d71177419965663.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_eBFW6OcEUObwrq9XPHcJg.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">将书籍摆放到书架的不同位置。照片由<a class="ae jd" href="https://unsplash.com/@sigmund?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">西格蒙德</a>在<a class="ae jd" href="https://unsplash.com/s/photos/encyclopedia?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h2 id="557d" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/tips-and-tricks" rel="noopener" target="_blank">小窍门</a></h2><div class=""/><div class=""><h2 id="2214" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">如何设计应用于快速检索任务的数据表示技术</h2></div><p id="0186" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">哈希是数据管理中最基本的操作之一。它允许使用少量内存快速检索数据项。哈希也是一种基本的算法操作，具有严格理解的理论属性。事实上，所有高级编程语言都提供了用于在哈希表中添加和检索项目的库。</p><p id="c6fd" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">最近，散列法已经成为一种强大的相似性搜索工具。这里的目标不是精确检索，而是快速检测彼此相似的对象。例如，对于不同的相似性概念，同一物品的不同图像应该具有相似的散列码，并且我们应该能够快速搜索这种相似的散列码。</p><p id="2175" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">最近的一个研究趋势是设计特定于数据的散列函数。不同于传统的散列算法，其中散列函数是通用的并且不依赖于底层数据分布，<em class="ma">学习散列</em>方法基于这样的前提，即可以通过发现数据中的隐藏模式来设计最佳散列函数。</p><p id="3a33" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在这篇文章中，我将讨论设计特定于数据的散列函数及其应用的机器学习技术。</p><h1 id="320c" class="mb mc jg bd md me mf mg mh mi mj mk ml kv mm kw mn ky mo kz mp lb mq lc mr ms bi translated">数据分布散列法</h1><p id="22e4" class="pw-post-body-paragraph le lf jg lg b lh mt kq lj lk mu kt lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">这是标准的散列法，例如Python中的字典，我们在其中存储键、值对。这些键被映射到唯一的散列码，如果一个键出现在我们的散列表或字典中，我们可以在常量时间内进行检索。</p><h2 id="cd74" class="my mc jg bd md mz na dn mh nb nc dp ml ln nd ne mn lr nf ng mp lv nh ni mr jm bi translated">数据独立(传统)散列法</h2><p id="5023" class="pw-post-body-paragraph le lf jg lg b lh mt kq lj lk mu kt lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">我们假设项目或密钥由整数表示。(不可变的数据类型，如字符串、浮点或元组，可以表示为整数。)</p><p id="17ca" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">标准的散列方法是将项目x映射到f(x ),其中f(x)只能取m个不同值中的一个。重要的是f(x)值尽可能随机，即我们想要的</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/666869698605d037a1216623a2158453.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*2EjQ4UQSN7dV6TmegPW1Jg.png"/></div></figure><p id="50e9" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这样，我们就不太可能发生<em class="ma">碰撞</em>，i <em class="ma">。</em> e，f(x)=f(y)。通常通过创建一个列表来处理冲突，该列表包含散列到给定地址的所有项目。如果列表太长，检索会变得很慢，因为我们需要遍历列表。</p><p id="708c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了避免冲突，哈希函数应该是独立的:</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi no"><img src="../Images/5cf0c294ef4ebdc89b9367e114578f25.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*sY45vJfWGHfj_Ly21-3ltA.png"/></div></figure><p id="767d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对于所有输入，0 ≤ i，j ≤ m-1。</p><p id="e30c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">上述条件被称为<em class="ma">双向独立性</em>，因为我们只考虑成对输入项的独立性。如果我们有三个项目，我们将有3个方面的独立性，一般来说，k个方面的独立性。k越高，函数越随机。</p><p id="ffab" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对散列函数的一个主要要求是它们可以被有效地评估。一个典型的例子是线性散列函数，如</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi np"><img src="../Images/9e207234364ffb8bdde60b59fef97fe7.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*iN0puApF4KHwOwlwkzeQlg.png"/></div></figure><p id="e555" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">其中<em class="ma"> a </em>和<em class="ma"> b </em>为随机选取的素数。可以证明这个函数是双向独立的。诸如高阶多项式的更复杂的函数产生k &gt; 2的k方向独立性。代价是更复杂的函数计算起来也更慢。我参考<a class="ae jd" href="https://www.cs.cmu.edu/afs/cs/project/pscico-guyb/realworld/www/slidesF15/hashing.pdf" rel="noopener ugc nofollow" target="_blank">这些课堂讲稿</a>来了解更多关于散列的细节。</p><h2 id="f0d7" class="my mc jg bd md mz na dn mh nb nc dp ml ln nd ne mn lr nf ng mp lv nh ni mr jm bi translated">使用机器学习的数据相关散列</h2><p id="5149" class="pw-post-body-paragraph le lf jg lg b lh mt kq lj lk mu kt lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">在数据无关哈希中，为了避免很多冲突，我们需要一个“足够随机”的哈希函数和足够大的哈希表容量m，参数m取决于数据中唯一项的数量。最先进的方法实现了恒定的检索时间结果，使用</p><p id="1f59" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><em class="ma">m = 2 *唯一项目数</em>。</p><p id="322d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">然而，想象一下我们的数据是从具有已知参数的正态分布生成的特殊情况，假设平均值为0，标准偏差为1。那么我们实际上不需要随机分配物品。我们可以简单地创建覆盖不同时间间隔的存储桶。我们需要在0附近有许多短的间隔，但是我们离0越远，间隔应该变得越大。显然，在区间[0，0.1]中我们会有很多值，但几乎没有大于10的值。</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/e1641d74f4afbde9a2296c57726b54a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*ZIXtpHLFJ6VG2j-fGNRV7g.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图一。x轴上的标签给出了散列值的容器。图片作者。</p></figure><p id="e877" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这是将机器学习方法应用于哈希的直觉。通过了解数据的分布，我们可以以最佳方式将物品分配到箱中。这是数据独立哈希无法实现的。</p><p id="4848" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">2017年，谷歌的研究人员因声称他们能够改进最著名的哈希算法而成为头条新闻[2]。</p><h1 id="08ed" class="mb mc jg bd md me mf mg mh mi mj mk ml kv mm kw mn ky mo kz mp lb mq lc mr ms bi translated">相似性保持散列</h1><h2 id="43a9" class="my mc jg bd md mz na dn mh nb nc dp ml ln nd ne mn lr nf ng mp lv nh ni mr jm bi translated">数据独立方法</h2><p id="bdfe" class="pw-post-body-paragraph le lf jg lg b lh mt kq lj lk mu kt lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">已经设计了不同的方法，使得对于不同的相似性概念，散列码保持对象之间的相似性。位置敏感哈希(LSH)是一系列哈希算法，保留对象之间的不同度量，如欧几里德距离或集合重叠。让我们考虑一个估算矢量间夹角的具体例子。</p><p id="db19" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">假设我们的输入数据是d维向量。我们选择k个随机d维向量w_i，其中每个条目选自标准正态分布N(0，1)。</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/c7a85705cb8ab935fc22cf15beb9c79a.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*6B86S4CtoYRqmzj16yZ5ng.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图二。绿色向量是分离超平面。图片作者。</p></figure><p id="24f8" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">随机向量被堆叠成矩阵w。散列码然后被计算为</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/8abdf17f0dc5f78842176f3a4368cb33.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*n7kWTcI6uMhJF1fuOic75Q.png"/></div></figure><p id="a24d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">上面说我们计算x和每个随机向量w的内积，并把符号作为哈希码。你可以把每个d维随机向量想象成d维空间中的一个随机超平面。符号表示向量x位于超平面的每一边。参见图2中的二维示例。因此，如果两个向量之间的角度很小，它们很可能在超平面的同一侧，即它们将有很大的重叠。LSH的主要结果是</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nt"><img src="../Images/55a918970d094a1ac09436a34d6a68c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*eIWGVbnt2iyna7Q6ryXUwA.png"/></div></div></figure><p id="5997" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">其中θ(x，y)表示矢量x和y之间的角度。</p><h2 id="0f25" class="my mc jg bd md mz na dn mh nb nc dp ml ln nd ne mn lr nf ng mp lv nh ni mr jm bi translated">为什么是位向量？</h2><p id="d645" class="pw-post-body-paragraph le lf jg lg b lh mt kq lj lk mu kt lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">目标是创建由单个比特组成的散列码。位向量非常紧凑，因此即使是大型数据集也可以在主存中处理。此外，位向量的算术运算非常高效。对位向量的相似性穷举搜索比对具有连续值的向量的穷举搜索更有效。原因是位向量可以在快速CPU缓存中加载和处理。因此，通过对两个比特向量进行XOR(计算相同比特的数量)来代替一般向量的向量内积u^T*v，产生了显著的计算优势。</p><h2 id="e44d" class="my mc jg bd md mz na dn mh nb nc dp ml ln nd ne mn lr nf ng mp lv nh ni mr jm bi translated">用于相似性搜索的无监督哈希学习</h2><p id="2952" class="pw-post-body-paragraph le lf jg lg b lh mt kq lj lk mu kt lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">最初提出的算法之一是基于<a class="ae jd" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank"> PCA分解</a>。我们找到协方差矩阵中方差最大的k个方向</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/93545edecab2781581cf0f26251f4aa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:368/format:webp/1*-raGhgTHe8SvFYV_5Yjbjg.png"/></div></figure><p id="d564" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">然后我们使用d-乘以-k的投影矩阵W，将数据X投影到<em class="ma"> k ≤ d </em>个主特征向量上，即对应于<em class="ma"> k </em>个最大特征值的特征向量:</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/fe9c49b6a897d870ca47995fd63c6e1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*Qke8Wvng3PF1S7oTP260oA.png"/></div></figure><p id="da68" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">注意它成立:</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/a62dc0ece8dfc3e5c446962ab1d8279e.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*dBErNFM860ufnJB0_BGrLw.png"/></div></figure><p id="6f30" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在上面的λ是由最大特征值组成的对角k乘k矩阵，W包含相应的特征向量。</p><p id="3757" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">哈希码计算如下</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/ccb0a83dc849f0898a71997c39ab5a9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*INiZY6Ba0YrmUlJECydiAQ.png"/></div></figure><p id="1904" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">一个明显的缺点是，这样所有方向都被平等对待。但我们需要更加关注方差较高的方向。研究人员提出了不同的技术，将更多的比特分配给方差较大的方向。</p><h2 id="08ba" class="my mc jg bd md mz na dn mh nb nc dp ml ln nd ne mn lr nf ng mp lv nh ni mr jm bi translated">监督学习散列相似性搜索</h2><p id="cab4" class="pw-post-body-paragraph le lf jg lg b lh mt kq lj lk mu kt lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">这是一个我们已经标记了数据的设置。例如，用不同类别标记的n个图像的数据库。在这里，我们可以创建图像之间的相似性得分，并将它们存储在n乘n矩阵S中。例如，条目S_{i，j}表示两幅图像基于它们的标签有多相似，例如两组标签之间的Jaccard相似性。(当然，相似性是一个非常通用的概念，不同的度量是可能的。)</p><p id="45f3" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们要求条目S_{i，j}是介于-1和1之间的值，因此对于具有[0，1]中的值的相似性度量sim(i，j ),我们设置</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/d47c8d0dbd554a891c0e21b029cc3f2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*FscoyQi6-uIZjvK8BEWn5g.png"/></div></figure><p id="bc91" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">目标是解决下面的优化问题。</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/f06032192b9d395b715fd0960a0a32af.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*TPYhSBZbpM15-D_IradShg.png"/></div></figure><p id="7ff7" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">矩阵B包含n个对象的散列码。请注意，我们将相似性矩阵乘以k，因为BB^T中的值介于-k和k之间。在上面的内容中，下标f表示矩阵的Frobenius范数:</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/0ec3d970969f90d506123d06dbd709bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*MDtQaFMcArclx6_oQg_Wtg.png"/></div></figure><p id="14e6" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">上面的优化问题很难解决，因为我们要求B中的值要么是-1，要么是1。放松版由下式给出</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/0079f94b020fe79a1781b42989032fbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*XvTjyQbMKne7eRGmWZDnrw.png"/></div></figure><p id="38b2" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">然后，通过取b中每个条目的符号，将解转换为位向量。</p><h2 id="4caf" class="my mc jg bd md mz na dn mh nb nc dp ml ln nd ne mn lr nf ng mp lv nh ni mr jm bi translated">学习排名</h2><p id="e0ac" class="pw-post-body-paragraph le lf jg lg b lh mt kq lj lk mu kt lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">另一个被广泛研究的问题是可以用来保持元素秩的散列码的设计。设置如下。对于查询q，有一个按降序排序的相关性分数列表</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/6bb33e3ecb0cd41d4ecfc3abc22037e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:346/format:webp/1*mndkXGOiD3WWxPuQ4vYqjw.png"/></div></figure><p id="626a" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">项目I的等级由下式给出</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/4021f063a2e6205fec999fdea7b10a78.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*3phNuJmSahA_ZCU3CwwN5w.png"/></div></figure><p id="4640" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们用来自{-1，1}的条目来定义两个二元向量之间的距离:</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/e036cbcba30ce797a46f68bb0421c7de.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*0W89CfPylPsbFiJZTurD1w.png"/></div></figure><p id="db75" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">设<em class="ma"> I </em>为二元指示函数，使得I(E) = 1当且仅当事件E为真。使用距离函数和二进制码的排序可以写成</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi od"><img src="../Images/c714990c182fc864abd578df967ca26e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F2T7NUSPWC2fRE7oDh5tXA.png"/></div></div></figure><p id="e6bd" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">然而，该指标导致了一个难以优化的问题。因此，我们使用sigmoid函数将其替换为概率表达式:</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/10a62158fe510634c3a5fe8b619c48a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*vnp9dYHQ-nzHmqEKvacoTA.png"/></div></figure><p id="be3c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了学习二元向量，我们使用一个带有可学习参数的矩阵。</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi of"><img src="../Images/134682c33e9caff1c28ac5e7c16054d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*Oh9kHbDSjd4TlHYSvKRwLA.png"/></div></figure><p id="7f6c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">然而，使用符号函数又会导致一个难以优化的问题。因此，我们去掉符号，得到下面的概率表达式</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div class="gh gi og"><img src="../Images/ebc5e14ddbc5de6c7ffb7e65ed7c444d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*f3QQjmIUPnv_QKKTQK31oQ.png"/></div></figure><p id="75cb" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这可以用于排名的表达式中，即</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oh"><img src="../Images/46317e86b516cfebb55cea5c41d9043e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GzX9uZhDb_jW0EoF8j21Yw.png"/></div></div></figure><p id="d12f" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">一旦我们有了一个学习排名参数的表达式，我们就可以将其插入到一个损失函数中，如<a class="ae jd" href="https://en.wikipedia.org/wiki/Discounted_cumulative_gain" rel="noopener ugc nofollow" target="_blank">归一化贴现累积收益(NDCG) </a>。我请读者查阅[4]以了解更多细节。</p><h1 id="b092" class="mb mc jg bd md me mf mg mh mi mj mk ml kv mm kw mn ky mo kz mp lb mq lc mr ms bi translated">讨论</h1><p id="68d5" class="pw-post-body-paragraph le lf jg lg b lh mt kq lj lk mu kt lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">人们应该永远记住，学习散列函数是一个机器学习问题。因此，它带来了机器学习的优点和缺点。它可能会导致卓越的性能和接近最佳的散列码。而且，获得散列码可能很慢，容易出错，并且容易过度拟合。学习哈希代码时，建议使用具有众所周知的属性的数据独立哈希函数作为基线。事实上，像<a class="ae jd" href="https://en.wikipedia.org/wiki/Cuckoo_hashing" rel="noopener ugc nofollow" target="_blank">布谷鸟哈希</a>这样的高级数据独立哈希方法可以获得与【2】中报告的结果相当的结果。</p></div><div class="ab cl oi oj hu ok" role="separator"><span class="ol bw bk om on oo"/><span class="ol bw bk om on oo"/><span class="ol bw bk om on"/></div><div class="ij ik il im in"><h2 id="cae6" class="my mc jg bd md mz na dn mh nb nc dp ml ln nd ne mn lr nf ng mp lv nh ni mr jm bi translated">参考</h2><p id="49b5" class="pw-post-body-paragraph le lf jg lg b lh mt kq lj lk mu kt lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">[1]学习大数据哈希:教程。李武军。在<a class="ae jd" href="https://cs.nju.edu.cn/lwj/slides/L2H.pdf" rel="noopener ugc nofollow" target="_blank">https://cs.nju.edu.cn/lwj/slides/L2H.pdf</a>上市</p><p id="69b3" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[2]学习指数结构的情况。蒂姆·菲利普·克拉斯卡，亚历克斯·比特尔，埃德·h·齐，杰弗里·迪恩，尼奥科利斯·波利佐蒂斯。在<a class="ae jd" href="https://arxiv.org/pdf/1712.01208.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1712.01208.pdf</a>有售</p><p id="8922" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[3]一个关于学习Hash的调查。王京东，，宋京宽，Nicu Sebe和沈。IEEE模式分析与机器智能汇刊(TPAMI) 2017。可在<a class="ae jd" href="https://arxiv.org/abs/1606.00185" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1606.00185</a>买到</p><p id="107e" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[4]用于快速相似性搜索的排序保持散列法。王启帆、张志伟和洛斯。IJCAI 2015。地点:【https://www.ijcai.org/Proceedings/15/Papers/549.pdf T2】</p></div></div>    
</body>
</html>