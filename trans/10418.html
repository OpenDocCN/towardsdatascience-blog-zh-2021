<html>
<head>
<title>PubSub to BigQuery: How to Build a Data Pipeline Using Dataflow, Apache Beam, and Java</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从PubSub到BigQuery:如何使用数据流、Apache Beam和Java构建数据管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pubsub-to-bigquery-how-to-build-a-data-pipeline-using-dataflow-apache-beam-and-java-afdeb8e711c2?source=collection_archive---------31-----------------------#2021-10-04">https://towardsdatascience.com/pubsub-to-bigquery-how-to-build-a-data-pipeline-using-dataflow-apache-beam-and-java-afdeb8e711c2?source=collection_archive---------31-----------------------#2021-10-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="374c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解如何在GCP创建数据管道</h2></div><p id="1014" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我最近参与了一个项目，该项目要求我从Google PubSub收集数据，并将其加载到不同的BigQuery表中。在这个过程中，我面临了许多挑战，所以我想分享一下我在谷歌云平台中构建完整数据管道的经验。</p><h1 id="4f7e" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated"><strong class="ak">问题陈述</strong></h1><p id="7557" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">假设我们在GCP的项目中有一个从后端向PubSub发送各种事件的库应用程序。事件是应用程序的任何用户迭代。仅为了演示，我们希望收集以下事件:</p><ul class=""><li id="38a0" class="ly lz iq kh b ki kj kl km ko ma ks mb kw mc la md me mf mg bi translated"><strong class="kh ir"> detailed_view </strong>，当用户打开一个有图书详情的页面时</li><li id="2773" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la md me mf mg bi translated"><strong class="kh ir">搜索</strong>，当用户搜索一本书时</li><li id="3470" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la md me mf mg bi translated">当用户将某本书添加为收藏时</li></ul><p id="4345" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每种事件类型都有不同的结构，应该保存到BigQuery中单独的表中，以便进一步分析。我们得到JSON格式的事件，JSON中的<em class="mm"> event_type </em>参数定义了事件需要写入的表。</p><p id="5ef7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">详细_查看</strong>事件示例:</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="2b97" class="mw lc iq ms b gy mx my l mz na">{“event_type”: “detailed_view”,</span><span id="b9e5" class="mw lc iq ms b gy nb my l mz na">“time”: “2021–08–01”,</span><span id="15ba" class="mw lc iq ms b gy nb my l mz na">“visitor_id”: “bdd6a03a-390a-4e76-b098-b74ea385228e”,</span><span id="450a" class="mw lc iq ms b gy nb my l mz na">“book”: {“id”: “1231234”}</span><span id="850a" class="mw lc iq ms b gy nb my l mz na">}</span></pre><p id="889a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">搜索</strong>事件示例:</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="a979" class="mw lc iq ms b gy mx my l mz na">{“event_type”: “search”,</span><span id="b83f" class="mw lc iq ms b gy nb my l mz na">“time”: “2021–08–01”,</span><span id="12ee" class="mw lc iq ms b gy nb my l mz na">“visitor_id”: “bdd6a03a-390a-4e76-b098-b74ea385228e”,</span><span id="4448" class="mw lc iq ms b gy nb my l mz na">“search_query”: “War and Peace”</span><span id="5cb1" class="mw lc iq ms b gy nb my l mz na">}</span></pre><p id="6688" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">添加到收藏夹</strong>事件示例:</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="d3a0" class="mw lc iq ms b gy mx my l mz na">{“event_type”: “add_to_favorite”,</span><span id="57a8" class="mw lc iq ms b gy nb my l mz na">“time”: “2021–08–01”,</span><span id="d8c4" class="mw lc iq ms b gy nb my l mz na">“visitor_id”: “bdd6a03a-390a-4e76-b098-b74ea385228e”,</span><span id="c12a" class="mw lc iq ms b gy nb my l mz na">“book”: {“id”: “1231234”},</span><span id="4b66" class="mw lc iq ms b gy nb my l mz na">“rating”: 5</span><span id="c523" class="mw lc iq ms b gy nb my l mz na">}</span></pre><p id="d924" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我总结了下图的问题。</p><figure class="mn mo mp mq gt nd gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi nc"><img src="../Images/327650ef3d744a9a624a09a0047eff7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V85oHGRtIMteIiaUx4S9PA.png"/></div></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">管道架构(图片由作者提供)</p></figure><p id="6e4e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，你可以看到黑盒将为我们做所有的魔术，我们不需要做任何事情。</p><p id="d6be" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">开个玩笑，真希望能这么简单。</p><p id="c32d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可能会说，好吧，太好了，但是如果数据突然以不同的结构出现或者出现在一个损坏的JSON中，该怎么办呢？我们都知道数据工程师的生活充满了痛苦和不断变化的数据结构。如果有人在没有任何通知的情况下从后端更改了模式，该怎么办？我们如何识别它是否发生过？我们如何在不停止管道的情况下保持和保存这样的数据，直到应用了某种修复？</p><p id="d521" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我们需要一个解决方案，它可以根据特定条件将输出数据流并行存储到不同的数据存储中，并且能够收集由于某种原因无法进入BigQuery的行。所以解决方案是<a class="ae no" href="https://cloud.google.com/dataflow" rel="noopener ugc nofollow" target="_blank"> Dataflow </a>，这是谷歌基于Apache Beam的完全托管的数据处理服务。它提供了所有需要的功能，以及无服务器方法和水平可扩展性。你可以阅读Apache Beam <a class="ae no" href="https://beam.apache.org/documentation/" rel="noopener ugc nofollow" target="_blank">文档</a>了解更多细节。</p><p id="c55b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我想提及三个基本概念:</p><ol class=""><li id="997b" class="ly lz iq kh b ki kj kl km ko ma ks mb kw mc la np me mf mg bi translated">这是一个开源模型，用于创建批处理和流数据并行处理管道，可以在不同的运行程序上执行，如Dataflow或Apache Spark。</li><li id="cb7d" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la np me mf mg bi translated">Apache Beam主要由p集合和p变换组成。PCollection是一个无序的、分布式的、不可变的数据集。PTransforms是对作为数据管道阶段的PCollections的操作。Apache Beam允许对PTransforms的输入和输出进行分支数据处理。</li><li id="befe" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la np me mf mg bi translated">p集合可以是有界的(固定大小的数据集)或无界的(无限大小的数据集)。如果从PubSub读取数据，那么您的PCollection是无限的。</li></ol><p id="2371" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下图中，你可以看到最终的管道架构。</p><figure class="mn mo mp mq gt nd gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi nq"><img src="../Images/eab46a918c91ae1353c6df27f2536da1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0exdR4SjX44UZuw7nFFZXA.png"/></div></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">管道架构(图片由作者提供)</p></figure><p id="9a55" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">既然我们已经对数据管道有了一个概念，现在是时候让它发挥作用了。如上图所示，我们在中间有一个数据流作业，包括以下步骤:</p><ol class=""><li id="5e3f" class="ly lz iq kh b ki kj kl km ko ma ks mb kw mc la np me mf mg bi translated">不断地从应用程序后端发布的PubSub中读取JSON事件。</li><li id="de6a" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la np me mf mg bi translated">在PTransform中处理JSON事件。</li><li id="dd9e" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la np me mf mg bi translated">将它们加载到BigQuery。目的地根据JSON事件中的event_type字段而不同。</li><li id="3edb" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la np me mf mg bi translated">收集所有插入失败的行，并将它们上传到云存储桶。</li><li id="c9f3" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la np me mf mg bi translated">统计所有“好”数据和“坏”数据，并以指标形式呈现出来</li></ol></div><div class="ab cl nr ns hu nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="ij ik il im in"><h1 id="ba5e" class="lb lc iq bd ld le ny lg lh li nz lk ll jw oa jx ln jz ob ka lp kc oc kd lr ls bi translated">流模式还是批处理模式？</h1><p id="22a9" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">在将数据导入BigQuery之前，我们需要选择适合自己的模式。数据可以在<em class="mm">批处理</em>模式下作为大块数据加载，也可以在<em class="mm">流</em>模式下加载，这意味着实时批处理更小，但价格更高。</p><p id="15bd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如何做出选择？</p><p id="94bb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">BigQuery使用<a class="ae no" href="https://cloud.google.com/bigquery/docs/loading-data" rel="noopener ugc nofollow" target="_blank">加载作业</a>来接收数据。对于这个过程，谷歌有<a class="ae no" href="https://cloud.google.com/bigquery/quotas#load_jobs" rel="noopener ugc nofollow" target="_blank">配额</a>，这是选择摄取方法时必须考虑的。</p><ol class=""><li id="e943" class="ly lz iq kh b ki kj kl km ko ma ks mb kw mc la np me mf mg bi translated">您的项目每天可以对每个表进行多达1，500次操作(如加载、复制、查询),包括目标表每天失败的作业。</li><li id="087a" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la np me mf mg bi translated">您的项目每天可以运行多达100，000个装载作业。失败的加载作业计入此限制。</li><li id="bcf3" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la np me mf mg bi translated">总请求负载必须小于10MB。</li></ol><p id="319b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一个需要考虑的重要事情是Apache Beam的行为，即将<strong class="kh ir">批处理模式</strong>中的<strong class="kh ir">无界数据</strong>加载到BigQuery中。如果这样的加载失败，那么Apache Beam将重试1000次。你可以从它们的源代码<a class="ae no" href="https://github.com/apache/beam/blob/e76b4db30a90d8f351e807cb247a707e7a3c566c/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.java" rel="noopener ugc nofollow" target="_blank">代码</a>本身看到证明:</p><figure class="mn mo mp mq gt nd"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="fab4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">没有参数可以更改这个默认值，因此这意味着如果您每天至少两次对同一个表进行两次错误加载，您将会超出加载作业配额:</p><p id="494f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">1 * 1000次重试+ 1 * 1000次重试= 2000次重试&gt; 1500次配额</p><p id="536a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于项目级别100，不正确的负载总数将超过定额。</p><p id="d6bf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我看来，如果你使用具有无界数据的数据流(像PubSub ),并且你的管道在生产中是高度加载的，并且使用许多表，那么使用流模式是更安全的，尽管更昂贵。否则，如果达到了该表的作业配额，那么该表的所有其他作业(如查询或复制)将在一天内无法进行。如果达到项目的作业配额，所有表的所有作业都将被阻塞。</p><p id="935c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当然，您可以在接收数据之前检查所有结构和类型，但这也不能保证管道的安全。</p><p id="7b65" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，在本教程中，我将向您展示如何在流模式下加载数据。</p></div><div class="ab cl nr ns hu nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="ij ik il im in"><h1 id="482f" class="lb lc iq bd ld le ny lg lh li nz lk ll jw oa jx ln jz ob ka lp kc oc kd lr ls bi translated">设置您的本地机器</h1><ol class=""><li id="9883" class="ly lz iq kh b ki lt kl lu ko of ks og kw oh la np me mf mg bi translated">阿帕奇光束需要<a class="ae no" href="https://www.oracle.com/java/technologies/javase/javase8-archive-downloads.html" rel="noopener ugc nofollow" target="_blank"> JDK </a> (Java SE 8 (8u202及更早)。不要忘记设置<a class="ae no" href="https://docs.oracle.com/cd/E19182-01/821-0917/inst_jdk_javahome_t/index.html" rel="noopener ugc nofollow" target="_blank"> JAVA_HOME </a>环境变量。</li><li id="7be9" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la np me mf mg bi translated">本教程的所有代码甚至更多都可以在我的<a class="ae no" href="https://github.com/olgazju/blog_pubsub_to_bigquery_dataflow_pipeline" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。</li><li id="5c38" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la np me mf mg bi translated">你可以安装IntelliJ，但是为了简单起见，我将使用命令行。</li></ol><h1 id="f5ba" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">设置Google云</h1><h2 id="8440" class="mw lc iq bd ld oi oj dn lh ok ol dp ll ko om on ln ks oo op lp kw oq or lr os bi translated">1.项目</h2><p id="48de" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">如果没有，在谷歌云平台中创建一个<a class="ae no" href="https://cloud.google.com/resource-manager/docs/creating-managing-projects#console" rel="noopener ugc nofollow" target="_blank">项目</a>。将<a class="ae no" href="https://cloud.google.com/billing/docs/how-to/modify-project" rel="noopener ugc nofollow" target="_blank">计费账户</a>与您的项目链接，如果它没有链接的话。</p><h2 id="2527" class="mw lc iq bd ld oi oj dn lh ok ol dp ll ko om on ln ks oo op lp kw oq or lr os bi translated">2.服务帐户</h2><p id="ef1d" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">在云控制台中，转到<a class="ae no" href="https://console.cloud.google.com/iam-admin/serviceaccounts" rel="noopener ugc nofollow" target="_blank">服务帐户页面</a>。选择您的项目并点击<em class="mm">创建服务帐户</em>。然后你会被要求提供细节。</p><figure class="mn mo mp mq gt nd gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi ot"><img src="../Images/bc0e9b1496596d0904c14945ba4a9b6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SjaEiAoX9I_jQWmQEuvoDQ.png"/></div></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">服务帐户详细信息</p></figure><p id="8503" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">授予此服务帐户我们数据管道所需的以下权限:</p><ul class=""><li id="e29e" class="ly lz iq kh b ki kj kl km ko ma ks mb kw mc la md me mf mg bi translated">云数据流服务代理</li><li id="cfeb" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la md me mf mg bi translated">数据流管理(用于创建作业)</li><li id="447e" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la md me mf mg bi translated">数据流工作者</li><li id="3141" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la md me mf mg bi translated">BigQuery管理员</li><li id="d219" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la md me mf mg bi translated">发布/订阅用户</li><li id="9da1" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la md me mf mg bi translated">存储对象管理</li></ul><p id="4c53" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了简单起见，我采用了管理员角色，但是您可以使用更精确的角色，例如BigQuery数据集级访问和特定于存储的存储桶访问。</p><figure class="mn mo mp mq gt nd gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi ou"><img src="../Images/a94027cf8daeae43509ea1dd8a9ceeb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q7kYnFXaux4_g1VgqbWJhQ.png"/></div></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">服务帐户角色</p></figure><p id="bffb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，您应该创建并下载SA的JSON密钥。在“服务帐户”页面上:</p><ul class=""><li id="b5f8" class="ly lz iq kh b ki kj kl km ko ma ks mb kw mc la md me mf mg bi translated">点击<em class="mm">按键选项卡</em></li><li id="80d6" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la md me mf mg bi translated">点击<em class="mm">添加键</em>下拉菜单</li><li id="fcf5" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la md me mf mg bi translated">选择<em class="mm">创建新键</em></li><li id="227f" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la md me mf mg bi translated">选择JSON作为键类型</li><li id="6ae3" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la md me mf mg bi translated">点击<em class="mm">创建</em></li></ul><p id="eca3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">点击<em class="mm">创建</em>在您的计算机上下载JSON格式的服务帐户密钥文件。</p><p id="cc76" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以将SA密钥文件的路径添加到GOOGLE_APPLICATION_CREDENTIALS环境变量中。</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="157d" class="mw lc iq ms b gy mx my l mz na">export GOOGLE_APPLICATION_CREDENTIALS=&lt;path to sa file&gt;</span></pre><h2 id="6308" class="mw lc iq bd ld oi oj dn lh ok ol dp ll ko om on ln ks oo op lp kw oq or lr os bi translated">3.数据流API</h2><p id="6a9e" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">在云控制台启用<a class="ae no" href="https://console.cloud.google.com/marketplace/product/google/dataflow.googleapis.com" rel="noopener ugc nofollow" target="_blank">数据流API </a></p><h2 id="ef25" class="mw lc iq bd ld oi oj dn lh ok ol dp ll ko om on ln ks oo op lp kw oq or lr os bi translated">4.私人谷歌访问</h2><p id="d123" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">数据流工人要求<a class="ae no" href="https://cloud.google.com/vpc/docs/configure-private-google-access#configuring_access_to_google_services_from_internal_ips" rel="noopener ugc nofollow" target="_blank">私人谷歌访问</a>你所在地区的网络。进入<a class="ae no" href="https://console.cloud.google.com/networking/networks/list" rel="noopener ugc nofollow" target="_blank"> VPC网络</a>页面，选择您的网络和地区，点击【编辑】选择上的<strong class="kh ir"> <em class="mm">进行私人谷歌访问，然后<em class="mm">保存</em>。</em></strong></p><figure class="mn mo mp mq gt nd gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi ov"><img src="../Images/013dbb892c1b139ee492bc5c1b52226b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AGv5cqh8T6w2QH6VSQ-9Nw.png"/></div></div></figure><h2 id="f407" class="mw lc iq bd ld oi oj dn lh ok ol dp ll ko om on ln ks oo op lp kw oq or lr os bi translated">5.公共订阅</h2><p id="bacd" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">创建一个<a class="ae no" href="https://cloud.google.com/pubsub/docs/admin" rel="noopener ugc nofollow" target="_blank"> PubSub </a>主题和一个“拉”订阅:在我们的例子中是<em class="mm"> library_app_topic </em>和<em class="mm">library _ app _ subscription</em>。</p><figure class="mn mo mp mq gt nd gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi ow"><img src="../Images/22d9c460b0b9cd9c7dc7cc4a03248314.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uE_HLuvdWRWBB2BE57RNBQ.png"/></div></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">创建订阅</p></figure><h2 id="3bcf" class="mw lc iq bd ld oi oj dn lh ok ol dp ll ko om on ln ks oo op lp kw oq or lr os bi translated">6.云存储</h2><p id="7453" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">在云控制台<a class="ae no" href="https://console.cloud.google.com/storage/browser" rel="noopener ugc nofollow" target="_blank">中创建</a><em class="mm">library _ app _ bucket</em>云存储bucket，里面还有另外三个:<em class="mm"> tmp </em>、<em class="mm"> staging </em>和<em class="mm"> errors </em>。Dataflow将使用此存储桶进行部署，并保存未在BQ中接收的数据。</p><figure class="mn mo mp mq gt nd gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi ox"><img src="../Images/a4ed1666f59dfb2d73ac8f493772dcaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m9Mozsm0VQ4hZ1huXlq9oA.png"/></div></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">创建存储桶</p></figure><h2 id="1499" class="mw lc iq bd ld oi oj dn lh ok ol dp ll ko om on ln ks oo op lp kw oq or lr os bi translated">7.BigQuery</h2><p id="9fb3" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">我将展示如何创建<em class="mm"> detailed_view </em>表，以便您可以轻松地对其他表重复相同的过程。<br/>在<a class="ae no" href="https://console.cloud.google.com/bigquery" rel="noopener ugc nofollow" target="_blank"> BigQuery </a>中，在美国位置创建<em class="mm"> library_app_dataset </em>，因为我们将在这个位置运行我们的数据流作业。然后从数据集中点击<em class="mm">添加表格</em>。</p><figure class="mn mo mp mq gt nd gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi oy"><img src="../Images/3595f74b2d145fbd06da70698c55a7f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eJUvbGLYpJFwLhCeOlP_mg.png"/></div></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">在BigQuery中创建一个表</p></figure><p id="7fc4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">选择源作为<em class="mm">空表</em>。在表名字段中写下<em class="mm"> detailed_view </em>，然后点击<em class="mm">编辑为模式部分下的文本</em>。<br/>在下面插入这个JSON，点击<em class="mm">创建表格</em>按钮。</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="0330" class="mw lc iq ms b gy mx my l mz na">[<br/>  {<br/>    "mode": "NULLABLE",<br/>    "name": "event_type",<br/>    "type": "STRING"<br/>  },<br/>  {<br/>    "mode": "NULLABLE",<br/>    "name": "time",<br/>    "type": "STRING"<br/>  },<br/>  {<br/>    "mode": "NULLABLE",<br/>    "name": "visitor_id",<br/>    "type": "STRING"<br/>  },<br/>  {<br/>      "fields": [<br/>        {<br/>          "mode": "NULLABLE",<br/>          "name": "id",<br/>          "type": "STRING"<br/>        }<br/>    ],<br/>    "mode": "NULLABLE",<br/>    "name": "book",<br/>    "type": "RECORD"<br/>  }<br/>]</span></pre><p id="1eb6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以在我的GitHub <a class="ae no" href="https://github.com/olgazju/blog_pubsub_to_bigquery_dataflow_pipeline/tree/main/bq_schemas" rel="noopener ugc nofollow" target="_blank">存储库</a>中找到所有表的所有模式。</p><p id="f2f0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，在对<em class="mm"> search </em>和<em class="mm"> add_to_favorite </em>表重复所有步骤后，您应该会在BigQuery中的<em class="mm"> library_app_dataset </em>数据集下看到它们。</p></div><div class="ab cl nr ns hu nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="ij ik il im in"><h1 id="5666" class="lb lc iq bd ld le ny lg lh li nz lk ll jw oa jx ln jz ob ka lp kc oc kd lr ls bi translated">让我们编码</h1><p id="5cfe" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">你可以在我的<a class="ae no" href="https://github.com/olgazju/blog_pubsub_to_bigquery_dataflow_pipeline" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到所有代码。克隆它然后运行。/gradlew build。不要忘记为您的SA设置带有JSON键的GOOGLE_APPLICATION_CREDENTIALS环境变量。</p><p id="124b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里我将只解释管道代码。</p><p id="574f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们需要从Apache Beam创建一个管道对象，该对象将包含所有数据和数据处理步骤。要配置数据管道选项，您可以创建自己的类(在我们的示例中为MyOptions ),该类扩展了DataflowPipelineOptions和DirectOptions类。您可以从命令行使用这些选项来设置资源，例如，发布订阅名称和其他参数。</p><figure class="mn mo mp mq gt nd"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="4156" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后我们从PubSub订阅中读取无界数据。Apache Beam中有一个PubsubIO类，为云发布/订阅流提供预先编写的PTransforms。</p><figure class="mn mo mp mq gt nd"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="11e3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我们有了数据流管道中的第一步—<strong class="kh ir">readpublibsubscription</strong>。</p><p id="537a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后我们需要检查JSON是否正确:让我们编写自定义的PTransform，然后在管道代码中使用它作为<strong class="kh ir"> TransformToBQ </strong>步骤。</p><p id="2afa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在Apache Beam的ParDo和DoFn PTransforms的帮助下，我们用processElement函数扩展并覆盖了PTransform类。这个函数用JSON获取一个字符串，然后在SUCCESS_TAG和<a class="ae no" href="https://beam.apache.org/documentation/programming-guide/#additional-outputs" rel="noopener ugc nofollow" target="_blank"> side output </a> FAILURE_TAG下产生主输出。</p><p id="4167" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">SUCCESS_TAG包括通过所有检查并成功转换为<a class="ae no" href="https://developers.google.com/resources/api-libraries/documentation/bigquery/v2/java/latest/com/google/api/services/bigquery/model/TableRow.html?is-external=true" rel="noopener ugc nofollow" target="_blank"> TableRow </a>对象的消息。</p><p id="3464" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">FAILURE_TAG表示一个键值变量，其中键是故障类型:</p><ul class=""><li id="f53a" class="ly lz iq kh b ki kj kl km ko ma ks mb kw mc la md me mf mg bi translated">“TooBigRow”，大于10Mb的JSON消息(这是有效负载大小的一个限额。我们不想被这些信息所困)</li><li id="5617" class="ly lz iq kh b ki mh kl mi ko mj ks mk kw ml la md me mf mg bi translated">“JsonParseError”，在JSON解析期间导致各种错误的JSON消息</li></ul><p id="af03" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以添加更多的副输出，并将IOException拆分为更详细的异常。</p><figure class="mn mo mp mq gt nd"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="633b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后我们收集成功处理的数据，并在Apache Beam的BigQueryIO类的帮助下将其流式传输到BigQuery中，<strong class="kh ir">WriteSuccessfulRecordsToBQ</strong>步骤。</p><p id="36b8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mm">用方法(BigQueryIO。</em>定义流模式。</p><p id="db76" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mm"> skipInvalidRows </em>表示如果一组数据中存在无效行，则跳过它们，不要使所有数据组失败。这仅在流模式下有效。</p><p id="3a41" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在摄取过程中，我们从<em class="mm"> event_type </em>字段的行中获取目标表的动态定义。</p><figure class="mn mo mp mq gt nd"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="89a9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mm"> withExtendedErrorInfo </em>允许我们将所有失败的插入保存在一个单独的PCollection中，并在<strong class="kh ir"> MapFailedInserts </strong>步骤中定义错误。</p><figure class="mn mo mp mq gt nd"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="73a9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下面的代码中，我们从FAILURE_TAG PCollection和failedInserts中获取所有数据，然后<a class="ae no" href="https://beam.apache.org/documentation/transforms/python/other/flatten/" rel="noopener ugc nofollow" target="_blank">将其合并到一个PCollection中。<br/>展平后，我们需要应用</a><a class="ae no" href="https://beam.apache.org/documentation/programming-guide/#windowing" rel="noopener ugc nofollow" target="_blank">窗口</a>和<a class="ae no" href="https://beam.apache.org/documentation/programming-guide/#triggers" rel="noopener ugc nofollow" target="_blank">触发器</a>在<strong class="kh ir">窗口错误</strong>步骤中创建某个时间间隔的数据块，并在<strong class="kh ir"> WriteErrorsToGCS </strong>步骤中将其作为一个文件写入云存储桶。因为在这种情况下我们不关心数据的顺序，所以我们可以使用GlobalWindows。</p><figure class="mn mo mp mq gt nd"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="49c0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后运行管道。</p><figure class="mn mo mp mq gt nd"><div class="bz fp l di"><div class="od oe l"/></div></figure></div><div class="ab cl nr ns hu nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="ij ik il im in"><h1 id="f878" class="lb lc iq bd ld le ny lg lh li nz lk ll jw oa jx ln jz ob ka lp kc oc kd lr ls bi translated">添加指标</h1><p id="6c6d" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">作为管道的结果，我们在BigQuery中拥有所有“好的”数据，在bucket中拥有所有“坏的”数据。让我们创建一些<a class="ae no" href="https://beam.apache.org/documentation/programming-guide/#metrics" rel="noopener ugc nofollow" target="_blank">指标</a>。我们将使用Apache Beam中的计数器度量类。</p><figure class="mn mo mp mq gt nd"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="8990" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，您可以简单地在特定位置对每个指标使用inc()操作，然后在数据流作业中查看这些指标。<br/>例如，让我们计算一下管道中有多少失败的插入。取<em class="mm">failed inserts</em>p collection并应用metric . failed insertmessages . Inc()；对于processElement中的每个元素。因此，failedInsertMessages包含当前失败的插入次数。</p><figure class="mn mo mp mq gt nd"><div class="bz fp l di"><div class="od oe l"/></div></figure></div><div class="ab cl nr ns hu nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="ij ik il im in"><h1 id="daa2" class="lb lc iq bd ld le ny lg lh li nz lk ll jw oa jx ln jz ob ka lp kc oc kd lr ls bi translated">在本地计算机上运行管道</h1><p id="4a45" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">一旦你设置了环境和GOOGLE_APPLICATION_CREDENTIALS变量，并且有了你的代码，你就可以在本地机器上用<a class="ae no" href="https://beam.apache.org/documentation/runners/direct/" rel="noopener ugc nofollow" target="_blank"> DirectRunner </a>首先运行管道。</p><p id="2610" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">转到gradlew文件所在的文件夹，首先构建代码</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="f71e" class="mw lc iq ms b gy mx my l mz na">./gradlew build</span></pre><p id="f676" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后用这个命令运行它(不要忘记写下你的项目名而不是<project_name>):</project_name></p><figure class="mn mo mp mq gt nd"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="7518" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果一切正常，您将在命令行中看到以下几行:</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="d885" class="mw lc iq ms b gy mx my l mz na">&lt;==========---&gt; 80% EXECUTING [3m 15s]<br/>&gt; :app:run</span></pre><p id="d227" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如你所见，代码的编写提供了在不同的GCP项目中使用BigQuery、PubSub和Dataflow的可能性。</p></div><div class="ab cl nr ns hu nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="ij ik il im in"><h1 id="1156" class="lb lc iq bd ld le ny lg lh li nz lk ll jw oa jx ln jz ob ka lp kc oc kd lr ls bi translated">在数据流上运行管道</h1><p id="85ea" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">用DirectRunner检查我们的管道后，我们可以用<a class="ae no" href="https://beam.apache.org/documentation/runners/dataflow" rel="noopener ugc nofollow" target="_blank"> DataflowRunner </a>在数据流中运行它。这与上一段中的命令几乎相同，但是runner参数是DataflowRunner(不要忘记写下您的项目名称，而不是&lt; project_name &gt;)。</p><p id="d1df" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">参数<em class="mm">enablestreamingine</em>允许使用<a class="ae no" href="https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#benefits-of-streaming-engine" rel="noopener ugc nofollow" target="_blank">流媒体引擎</a>。数据流的流媒体引擎将管道执行从工作虚拟机中移出，并移入数据流服务后端，这意味着消耗的CPU和其他资源更少。</p><p id="e5d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在自动缩放期间，数据流会自动选择运行您的作业所需的工作实例的适当数量，参数<em class="mm"> maxNumWorkers </em>会限制这个数量。</p><p id="0461" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">参数<em class="mm"> usePublicIps=false </em>意味着出于安全原因，您的数据流实例将没有公共IP。</p><figure class="mn mo mp mq gt nd"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="2154" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据流的部署需要时间。最后你会看到如何取消工作的信息。</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="5891" class="mw lc iq ms b gy mx my l mz na">17663 [main] INFO org.apache.beam.runners.dataflow.DataflowRunner - To cancel the job using the 'gcloud' tool, run:&gt; gcloud dataflow jobs --project=&lt;your_project&gt; cancel --region=us-central1 2021-09-23_04_34_38-9136796642874199393</span></pre><p id="2130" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在云控制台中，转到<a class="ae no" href="https://console.cloud.google.com/dataflow/jobs" rel="noopener ugc nofollow" target="_blank">数据流作业页面</a>并查看您的数据流作业。您应该会在名称附近看到一个绿色圆圈，表示作业正在成功运行。</p><p id="931d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您不打算使用该作业，请不要忘记将其取消。</p><h1 id="3fc3" class="lb lc iq bd ld le lf lg lh li lj lk ll jw lm jx ln jz lo ka lp kc lq kd lr ls bi translated">测试管道并检查指标</h1><p id="397c" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">让我们向PubSub主题发布一些“好”数据。在云控制台中打开PubSub <a class="ae no" href="https://console.cloud.google.com/cloudpubsub/topic/list" rel="noopener ugc nofollow" target="_blank">页面</a>，选择我们的主题，然后点击发布消息。</p><figure class="mn mo mp mq gt nd gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi oz"><img src="../Images/934062b481174e4441add68f5ea91df9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fd86tLxbwpYvoGHzvaopUQ.png"/></div></div></figure><p id="8d93" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将下面这个JSON插入到<em class="mm">消息体</em>部分，点击<em class="mm">发布</em>按钮</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="273c" class="mw lc iq ms b gy mx my l mz na">{"event_type": "search",<br/>"time": "2021-08-01",<br/>"visitor_id": "bdd6a03a-390a-4e76-b098-b74ea385228e",<br/>"search_query": "War and Peace"<br/>}</span></pre><p id="492a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后转到<a class="ae no" href="https://console.cloud.google.com/bigquery" rel="noopener ugc nofollow" target="_blank">大查询页面</a>并检查<em class="mm">搜索</em>表中的数据。</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="019f" class="mw lc iq ms b gy mx my l mz na">SELECT * FROM `library_app_dataset.search`</span></pre><p id="113d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">查询结果中有我们的“战争与和平”事件。</p><figure class="mn mo mp mq gt nd gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi pa"><img src="../Images/c0a2d24dd958af36feb9539d7c0ff467.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2arZs8WkeBY9EKeNyogFcw.png"/></div></div></figure><p id="9c89" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以从我的<a class="ae no" href="https://github.com/olgazju/blog_pubsub_to_bigquery_dataflow_pipeline/tree/main/data" rel="noopener ugc nofollow" target="_blank"> GitHub </a>中尝试更多的测试数据。</p><p id="d4b2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们检查一下我们的管道如何处理“坏”数据。</p><h2 id="f885" class="mw lc iq bd ld oi oj dn lh ok ol dp ll ko om on ln ks oo op lp kw oq or lr os bi translated">JSON中断</h2><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="d8e2" class="mw lc iq ms b gy mx my l mz na">{"event_type": <br/> "add_to_favorite","time": <br/>}</span></pre><p id="a284" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以这个JSON坏了，它应该在一分钟内出现在<em class="mm">错误</em>桶中，其名称采用下一种格式:</p><p id="0fcf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">library _ app _ bucket/errors/JsonParseError/2021–09–23/error-13:10:09–0/1</p><p id="7e3f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您下载这个文件，您将会看到它包含了我们损坏的JSON</p><h2 id="d250" class="mw lc iq bd ld oi oj dn lh ok ol dp ll ko om on ln ks oo op lp kw oq or lr os bi translated">错误的模式</h2><p id="a112" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">让我们以add_to_favorite事件为例，将评级从数字更改为某个字符串，并将其推送到主题。</p><pre class="mn mo mp mq gt mr ms mt mu aw mv bi"><span id="0099" class="mw lc iq ms b gy mx my l mz na">{"event_type": "add_to_favorite",<br/>"time": "2021-08-01",<br/>"visitor_id": "bdd6a03a-390a-4e76-b098-b74ea385228e",<br/>"book": {"id": "1231234"},<br/>"rating": "this is a string"<br/>}</span></pre><p id="40d7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，由于类型不兼容，这个JSON不能被BQ接收，我们很快就会在错误桶中看到它，格式如下:</p><p id="9626" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">library _ app _ bucket/errors/failed inserts/2021–09–23/error-13:19:47–0/1</p><p id="fc18" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您打开该文件，您可以检查是否存在与我们推送至PubSub主题相同的JSON。</p></div><div class="ab cl nr ns hu nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="ij ik il im in"><h1 id="0103" class="lb lc iq bd ld le ny lg lh li nz lk ll jw oa jx ln jz ob ka lp kc oc kd lr ls bi translated">是时候检查我们的指标了</h1><p id="b377" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">在数据流中运行管道并在PubSub中获得第一条消息后，您可以在谷歌云控制台中打开数据流作业页面，并在作业信息下看到一个新的“自定义计数器”部分。在下图中，您可以看到PubSub中有三条消息，其中两条已成功处理，但其中一条在接收过程中失败。我们看到一条无法解析的消息。</p><figure class="mn mo mp mq gt nd gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi pb"><img src="../Images/01d879cd11a3c0c2632a478c787b51c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fhMZM6bb0BC692QLPncKag.png"/></div></div><p class="nk nl gj gh gi nm nn bd b be z dk translated">韵律学</p></figure></div><div class="ab cl nr ns hu nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="ij ik il im in"><h1 id="4073" class="lb lc iq bd ld le ny lg lh li nz lk ll jw oa jx ln jz ob ka lp kc oc kd lr ls bi translated">结论</h1><p id="2592" class="pw-post-body-paragraph kf kg iq kh b ki lt jr kk kl lu ju kn ko lv kq kr ks lw ku kv kw lx ky kz la ij bi translated">总之，现在您已经知道如何将数据流用于典型的ETL数据管道，您还可以更深入地研究Apache Beam世界。在本教程中，除了保存“坏”数据之外，我们没有处理太多的“坏”数据，但是添加一些机制用于进一步处理是可能的。<br/>就这些，感谢阅读。<br/>你可以在<a class="ae no" href="https://twitter.com/olgazju_dev" rel="noopener ugc nofollow" target="_blank"> Twitter </a>和<a class="ae no" href="https://www.linkedin.com/in/olgabraginskaya/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上关注我。</p></div></div>    
</body>
</html>