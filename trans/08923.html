<html>
<head>
<title>Using Python to Get and Store Federal Economic Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python获取和存储联邦经济数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-python-to-get-and-store-federal-economic-data-11444317ecfb?source=collection_archive---------22-----------------------#2021-08-17">https://towardsdatascience.com/using-python-to-get-and-store-federal-economic-data-11444317ecfb?source=collection_archive---------22-----------------------#2021-08-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cb1d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">从数据获取流程的一些最初步骤开始数据之旅。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6378f66ece8e1a4295e3ec29ee4050e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JKGvdaUn4kjoe9-CjcdMNA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">关于金钱的数据——还有比这更好的吗？来自<a class="ae ky" href="https://www.pexels.com/photo/eagle-printed-on-bill-of-america-4386151/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的<a class="ae ky" href="https://www.pexels.com/@karolina-grabowska?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Karolina Grabowska </a>摄影</p></figure><p id="44d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在每个分析师的一生中，都会有这样一个时刻，他们必须获取、处理和存储数据，以便获得分析阶段所需的数据。可悲的是，并不是所有的东西都是干净的，都是从股票数据集中打包出来的。如果你不是一个有经验的数据工程师或不习惯ETL过程，这可能是一个挑战，并提出一些你必须解决的概念问题。</p><p id="721e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我想，既然我经历了这个过程，而且记忆犹新，我会写一篇文章，希望能帮助那些面临挑战的人。我要警告你，这不是高质量的代码。它在我的情况下是有效的，但却被展示出来，毫无保留。我做了很少的清理或优化，所以请记住这一点。</p><p id="0833" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们跳进来。</p><h1 id="c6bd" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">要求</h1><p id="10e4" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">根据它需要什么，我把它保持得非常简单:</p><p id="abf9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">— Python(我用的是3.9，因为它在我的开发工作站上运行)</p><p id="5a8d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">—熊猫</p><p id="4842" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">— psycopg2(用于数据库访问的Python库)</p><p id="2a7d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">— Datapungi_fed(该库允许轻松访问美联储数据库)</p><p id="053b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">— PostgreSQL(我目前使用的是版本13，但几乎任何最新版本都适用于我们在这里做的事情)</p><p id="5957" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一点也不难。</p><p id="acc2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意:对于这些数据，您需要向美联储注册以获得API密钥。这些在https://research.stlouisfed.org/docs/api/api_key.html<a class="ae ky" href="https://research.stlouisfed.org/docs/api/api_key.html" rel="noopener ugc nofollow" target="_blank">有售</a></p><h1 id="4b6e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据</h1><p id="8c62" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">首先说一下我们会收到的数据。</p><p id="0307" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">美联储维护着一个庞大的数据库，其中包含各种经济数据集，分布在众多数据库中。几乎所有这些都是时间序列集，根据各种报告标识符以日期和数据的形式出现。</p><p id="79d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于使用的简要说明:美联储使数据集可用于个人、非商业用途，因此您可以按照自己选择的长度进行构建和分析。但是，如果你想通读所有的条款和条件，这里有法律常见问题的链接:<a class="ae ky" href="https://fred.stlouisfed.org/legal/" rel="noopener ugc nofollow" target="_blank">https://fred.stlouisfed.org/legal/</a></p><p id="4a1e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">datapungi_fed库简化了实际检索过程，并处理了所有繁重的工作。我们简单地通过名字调用一个报告，然后库返回给我们一个系列，我们可以使用pandas来操作。</p><p id="a287" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我发现在我的日常使用中，我对API的使用超过了我真正喜欢的程度。我想确保A)我将我的API访问限制在可接受的数量。毕竟，我是一个有礼貌的数据收集者。b)我希望数据更接近我的最终目的地，并防止出现连接问题、服务器维护问题和其他连接问题。我还希望能够在必要时进行更多的后端处理，并减轻前端的负担。因为这个原因，我把这个放进了数据库。</p><p id="1602" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我想从美联储获取的另一个数据是发布的每日报告列表。这有点不同，合并了一行，包含ID、开始和结束日期、报告名称、链接、新闻发布标志和注释。</p><p id="f5b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这第二次拉进了一些数据净化，以使它正确加载，但我们也将解决这个问题。</p><h1 id="a637" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据库ˌ资料库</h1><p id="ff4c" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我为数据库创建的简单模式由四个表组成:</p><ol class=""><li id="0fe0" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">美联储_报告</li><li id="cc1b" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">美联储_报告_tmp</li><li id="398e" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">美联储_释放</li><li id="2235" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">美联储_发布_tmp</li></ol><p id="912a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">普通表和_tmp表本质上都是彼此的副本。它们的作用是在_tmp表中对数据库进行初始插入，然后只将新数据复制到主表中，此时_tmp表被清空。</p><p id="3aff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">表1和表2的结构是:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="e704" class="nl lw it nh b gy nm nn l no np">CREATE TABLE public.fed_reports (<br/>  report_date DATE NOT NULL,<br/>  data NUMERIC NOT NULL,<br/>  report_name VARCHAR NOT NULL,<br/>  hash VARCHAR NOT NULL PRIMARY KEY<br/>);</span></pre><p id="9bf8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">类似地，表3和表4的结构是:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="b446" class="nl lw it nh b gy nm nn l no np">CREATE TABLE public.fed_reports (<br/>  release_date DATE NOT NULL,<br/>  report_name VARCHAR NOT NULL,<br/>  report_link VARCHAR NOT NULL,<br/>  notes VARCHAR NOT NULL,<br/>  hash VARCHAR NOT NULL PRIMARY KEY<br/>);</span></pre><p id="6d4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这为流程中不同点的数据提供了四个容器。现在，我们需要一些方法来确保事情能够正常进行。</p><p id="a633" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">前两个函数用于为_tmp表的内容分配一个哈希值。执行此操作是因为我只想要新数据。通过对内容进行散列，我为每一行定义了一个惟一的键，这给了我在插入时匹配的内容。当我进入实际的检索代码时，我将进一步讨论这个问题，所以请耐心等待。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="4e10" class="nl lw it nh b gy nm nn l no np">CREATE OR REPLACE FUNCTION public.rehash_fed_reports()<br/>  RETURNS integer<br/>  LANGUAGE 'plpgsql'<br/>  VOLATILE<br/>  PARALLEL UNSAFE<br/>  COST 100</span><span id="f1e8" class="nl lw it nh b gy nq nn l no np">AS $BODY$<br/>    begin<br/>      UPDATE fed_reports_tmp<br/>      SET hash = md5(<br/>        cast(report_date as VARCHAR) ||<br/>        cast(data as VARCHAR) ||<br/>        cast(report_name as VARCHAR)<br/>      )</span><span id="6dee" class="nl lw it nh b gy nq nn l no np">    return 0;<br/>  end;<br/>  $BODY$;</span><span id="ba41" class="nl lw it nh b gy nq nn l no np">CREATE OR REPLACE FUNCTION public.rehash_fed_releases()<br/>  RETURNS integer<br/>  LANGUAGE 'plpgsql'<br/>  VOLATILE<br/>  PARALLEL UNSAFE<br/>  COST 100</span><span id="0f3a" class="nl lw it nh b gy nq nn l no np">AS $BODY$<br/>  begin<br/>    UPDATE fed_releases<br/>    SET = md5(<br/>      cast(release_date as VARCHAR) ||<br/>      cast(report_name as VARCHAR) ||<br/>      cast(report_link as VARCHAR) ||<br/>      cast(notes as VARCHAR)<br/>    )</span><span id="9917" class="nl lw it nh b gy nq nn l no np">    return 0;<br/>  end;<br/>  $BODY$;</span></pre><p id="5348" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这两种功能基本相似。它们对表中的行执行定义的更新，并返回一个整数0。没有真正的错误检查或任何其他容错，因为如果他们的过程失败，函数将返回一个错误，事务将默认回滚。它使这个应用程序变得简单。</p><p id="e279" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意，为了使用md5函数，我将所有数据转换成文本格式，并将结果连接起来。只要始终使用相同的方法，这就不是问题。</p><p id="6a91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我定义了一个函数来执行数据移动。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="aea7" class="nl lw it nh b gy nm nn l no np">CREATE OR REPLACE FUNCTION public.fed_report_update()<br/>  RETURNS integer<br/>  LANGUAGE 'plpgsql'<br/>  VOLATILE<br/>  PARALLEL UNSAFE<br/>  COST 100</span><span id="3275" class="nl lw it nh b gy nq nn l no np">AS $BODY$<br/>  begin<br/>  <br/>    INSERT INTO fed_releases (<br/>      release_date, <br/>      report_name, <br/>      report_link, <br/>      notes, <br/>      hash)<br/>    SELECT * FROM <br/>      fed_releases_tmp <br/>    WHERE <br/>      hash NOT IN (<br/>        SELECT hash FROM fed_releases<br/>    );<br/>  <br/>    INSERT INTO <br/>      fed_reports (<br/>        report_date, <br/>        data, <br/>        report_name, <br/>        hash)<br/>    SELECT * FROM <br/>      fed_reports_tmp <br/>    WHERE <br/>      hash NOT IN (<br/>        SELECT hash FROM fed_reports);</span><span id="64d0" class="nl lw it nh b gy nq nn l no np">return 0;<br/>    end;<br/>  $BODY$;</span></pre><p id="1b2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个函数只使用INSERT INTO语句根据子选择的结果执行插入。在本例中，我从each _tmp表中选择主表中不存在散列的所有内容。这确保了只添加新数据。</p><p id="f4a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者，我可以每次只删除主表中的数据，然后重新插入所有数据，而不需要所有的散列步骤，但是在发布报告的情况下，我想要一个每日历史记录，并且我不能再次获得该数据，所以这是必要的。如果我只为一个人做，为什么不使用复制粘贴的魔法，为两个人都做呢？</p><p id="d096" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我唯一没有放在这里的是清除_tmp表的函数。我将它们打包到一些其他的进程中，作为更大的应用程序的一部分，但是给定代码示例，您应该能够自己轻松地完成这些工作。</p><p id="d3c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是数据库。很简单，对吧？</p><h1 id="0371" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">检索代码</h1><p id="0a03" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在我们开始有趣的部分python代码。</p><p id="dbbd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">出于几个原因，这不是一个完整的脚本，因为有些东西在我自己的代码中是不相关的(我太懒了，不会为本文重写一个工作模板)，但没有什么重要的东西会被遗漏。但是，如果你被卡住了，就留下你的评论，我会试着给你一个答案——不像一些作者，我会检查并试着回复。</p><p id="b5ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们做重要的事情:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="45ae" class="nl lw it nh b gy nm nn l no np">import pandas as pd<br/>import datapungi_fed as dpf</span><span id="4951" class="nl lw it nh b gy nq nn l no np">data = dpf.data("put your API code here")</span><span id="b506" class="nl lw it nh b gy nq nn l no np"># Note: please change your database, username &amp; password as per your own values<br/>conn_params_dic = {<br/>  "host": "address of database",<br/>  "database": "name of database",<br/>  "user": "user of database",<br/>  "password": "password of database"<br/>}</span></pre><p id="9e39" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经做了两件事:1)我们为API键设置了一个变量，2)为数据库定义了一个连接字符串。这两者都允许访问我们需要的两个外部资源。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="7bb2" class="nl lw it nh b gy nm nn l no np">def get_report(report_name):<br/>  try:<br/>    df = data.series(report_name)<br/>    df.rename(columns={report_name: 'data'}, inplace=True)<br/>    df['report'] = report_name<br/>    df.reset_index(drop=False, inplace=True)<br/>  except:<br/>    df = pd.DataFrame(columns = ['date', 'data', 'report'])<br/>    print(report_name + ' Empty Set')<br/>  return df</span></pre><p id="4f8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我创建了一个快速实用函数，它将一个报告名称作为输入，并使用创建的数据对象来检索报告，该报告以一系列名为date和report_name的列作为列。因为我将所有的报告存储在一个带有报告名称标识符的大表中，所以我想保持一致，所以我将report_name列重命名为“data”。然后，我创建“report”列来保存名称，并删除索引，默认情况下是日期。</p><p id="6430" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就把所有的东西都放到了正确的格式中。</p><p id="9c57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果有一个空报告(这种情况时有发生),我只需返回一个带有标题的空数据帧并打印一个警告。</p><p id="553c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">准备工作结束后，让我们先做例外，也就是发布的报告，并把它们处理掉。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="90b0" class="nl lw it nh b gy nm nn l no np">released = data.releases()</span><span id="150a" class="nl lw it nh b gy nq nn l no np">released.drop(columns=['id', 'realtime_end', 'press_release'], inplace = True)</span><span id="e1bf" class="nl lw it nh b gy nq nn l no np">released.rename(columns={'realtime_start': 'Date'}, inplace=True)<br/>released.rename(columns={'name': 'Report Name'}, inplace=True)<br/>released.rename(columns={'link': 'Link'}, inplace=True)<br/>released.rename(columns={'notes': 'Notes'}, inplace=True)</span><span id="f224" class="nl lw it nh b gy nq nn l no np">released['Report Name'] = released['Report Name'].str.replace(r'"', '')<br/>released['Report Name'] = released['Report Name'].str.replace(r',', '')<br/>released['Link'] = released['Link'].str.replace(r'"', '')<br/>released['Link'] = released['Link'].str.replace(r',', '')<br/>released['Notes'] = released['Notes'].str.replace(r'"', '')<br/>released['Notes'] = released['Notes'].str.replace(r',', '')<br/>released['Notes'] = released['Notes'].str.replace(r'\n', '')<br/>released['Notes'] = released['Notes'].str.replace(r'\r', '')<br/>released['Notes'] = released['Notes'].str.replace(r'\\', '')</span><span id="bb44" class="nl lw it nh b gy nq nn l no np">released['hash'] = released.apply(lambda x: hash(tuple(x)), axis=1)</span></pre><p id="509d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一段可怕的代码，但是完成了工作。如果我更有雄心，或者这不仅仅是一个一次性的，我可能会做更多的事情来将其容器化，使其更便于携带，但它就是这样。</p><p id="83ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我们获取新的报告发布(目的地为fed_releases表)。这存储在“发布”中。接下来，我删除了对我不重要的列，比如ID、realtime_end和press_release。</p><p id="5eb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我重命名剩余的列。这并不是绝对必要的，而是作为我使用这些数据的一种方法的延续，所以它被留在了这个过程中。</p><p id="ad2c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，需要清理内容。对这些数据没有太多的关注，所以会有很多错误的格式出现。一些简单的替换就可以解决问题。</p><p id="f0f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为在使用COPY命令将数据复制到数据库之前，首先要将数据移动到CSV中，所以大多数问题都与转换有关。我们删除了逗号、引号、反斜杠字符，当然还有换行符。任何这些都会很快破坏你的一天，并导致一些非常无用的错误信息。</p><p id="3d89" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后一步是使用python散列库进行散列。</p><p id="352b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，Brad，我们刚刚在上一节中讲述了使用md5函数对数据库中的数据进行哈希运算的整个过程，这是怎么回事呢？</p><p id="3f50" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简短的回答是，有时候，这个实例中python散列函数的结果是不一致的。我发现欺骗给我带来了痛苦，所以这是一次学习的经历。</p><p id="c2b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我把这个留在这里是有原因的。我的表上的哈希值被定义为主键。我可以放弃它，使字段为空，或者我可以做一些其他的工作，但是我意识到在导入后用一个新的散列来更新这些值要简单得多。我选择了最省力的方法。如果你想继续下去，你可能会有更好的结果，但我知道我目前的设置是可靠的。</p><p id="7151" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">跳过这一步，我们现在准备进行第一次插入。我倾向于使用我为此定义的一些其他函数，但我也将它们放在这里供您参考:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="e00a" class="nl lw it nh b gy nm nn l no np">conn = dbf.connect(conn_params_dic)<br/>conn.autocommit = True<br/>dbf.copy_from_dataFile(conn, released, 'fed_releases_tmp')</span></pre><p id="f799" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">dbf引用的是我拥有的一个单独的模块，它只包含我使用的数据库函数。我有连接函数和复制数据文件函数。以下是这些函数供参考:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="df8a" class="nl lw it nh b gy nm nn l no np">def connect(conn_params_dic):<br/>  conn = None<br/>  try:<br/>    conn = psycopg2.connect(**conn_params_dic)<br/>    if debug == 1:<br/>      print("Connection successful..................")<br/>  except OperationalError as err:<br/>    show_psycopg2_exception(err)<br/>    # set the connection to 'None' in case of error<br/>    conn = None<br/>  return conn</span><span id="d98f" class="nl lw it nh b gy nq nn l no np">def copy_from_dataFile(conn, df, table):<br/>  tmp_df = "/tmp/insert_data.csv"<br/>  df.to_csv(tmp_df, header=False, index=False)<br/>  f = open(tmp_df, 'r')<br/>  cursor = conn.cursor()<br/>  try:<br/>    cursor.copy_from(f, table, sep=",")<br/>    conn.commit()<br/>    print("Data inserted successfully....")<br/>    cursor.close()<br/>  except (Exception, psycopg2.DatabaseError) as error:<br/>    os.remove(tmp_df)<br/>    # pass exception to function<br/>    show_psycopg2_exception(error)<br/>    cursor.close()<br/>  os.remove(tmp_df)</span></pre><p id="a117" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，还使用这两个函数:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="56cd" class="nl lw it nh b gy nm nn l no np">def show_psycopg2_exception(err):<br/>  # get details about the exception<br/>  err_type, err_obj, traceback = sys.exc_info()<br/>  line_n = traceback.tb_lineno<br/>  print("\npsycopg2 ERROR:", err, "on line number:", line_n)<br/>  print("psycopg2 traceback:", traceback, "-- type:", err_type)<br/>  print("\nextensions.Diagnostics:", err.diag)<br/>  print("pgerror:", err.pgerror)<br/>  print("pgcode:", err.pgcode, "\n")</span><span id="5359" class="nl lw it nh b gy nq nn l no np">def query_return(query):<br/>  conn = connect(conn_params_dic)<br/>  try:<br/>    query_1 = pd.read_sql_query(query, conn)<br/>    df = pd.DataFrame(query_1)<br/>  except (Exception, psycopg2.Error) as error:<br/>    print("Error while fetching data from PostgreSQL", error)<br/>  finally:<br/>    if conn:<br/>      conn.close()<br/>  return df</span></pre><p id="4109" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总的来说，这些函数允许建立psycopg2连接、通过copy命令插入数据、处理异常和进行选择查询。</p><p id="b27a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些可以合并到您的主获取文件中，或者像我所做的那样，放在一个单独的模块中进行访问。这完全取决于您构建应用程序的内容和方式。</p><h1 id="163b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">中途总结</h1><p id="c488" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">哇，我们已经谈了很多了。让我们先喘口气，回顾一下。</p><p id="3777" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经创建了数据库，并设置了保存数据的模式。我们定义了在后端操作数据的函数，并处理所有数据，因此我们有增量更新。</p><p id="8e36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的数据获取过程中，我们已经从美联储建立了到数据库和API的连接。我们已经获得了新发布报告的列表，对它们进行了不良字符处理，并运行了将它们插入数据库的函数。</p><p id="5d59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，您的fed_releases_tmp表应该已经塞满了准备处理的新报告。</p><p id="7ee7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们进入这个旅程的最后一部分，使用一个报告标识符列表来获取实际的时间序列报告数据，将它们插入到数据库中，然后完成，只留下填充的主表。</p><h1 id="d624" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">检索代码第2部分</h1><p id="ee04" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我们的下一步是定义我们想要的报告列表。确定你感兴趣的是你的事，你需要花一些时间在https://fred.stlouisfed.org/浏览他们的报告清单，以确定你想要什么。但是，一旦你有了这份清单，你的生活将会更加充实，有最新的经济数据可以戳戳戳，直到你心满意足。</p><p id="ed6f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是我的清单的一部分:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="1559" class="nl lw it nh b gy nm nn l no np">report_list = [<br/>  'WM1NS', # M1 Supply<br/>  'WM2NS', # M2 Supply<br/>  'ICSA', # Unemployment<br/>  'CCSA', # Continued Unemployment<br/>  'JTSJOL', # Job Openings: Total Nonfarm<br/>  'PAYEMS', # Non-Farm Employment<br/>  'RSXFS', # Retail Sales<br/>  'TCU', # Capacity Utilization<br/>  'UMCSENT', # Consumer Sentiment Index<br/>  'BUSINV', # Business Inventories<br/>  'INDPRO', # Industrial Production Index<br/>  'GACDFSA066MSFRBPHI', # Philidelphia Fed Manufacturing Index<br/>  'GACDISA066MSFRBNY', # Empire State Manufacturing Index<br/>  'BACTSAMFRBDAL', # Current General Business Activity; Diffusion Index for Texas<br/>  'IR', # Import Price Index<br/>  'IQ', # Export Price Index<br/>  'PPIACO', # Producer Price Index - all<br/>  'CPIAUCSL', # Consumer Price Index - all<br/>  'CPILFESL', # Consumer Price Index (Core)<br/>  'MICH', # University of Michigan: Inflation Expectation<br/>  'CSCICP03USM665S', # Consumer Opinion Surveys: Confidence Indicators: Composite Indicators: OECD Indicator for the United States<br/>]</span></pre><p id="3150" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显然，这是所有的地图，但显示了很多共同的经济指标。但是，我们需要处理这个:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="3d1a" class="nl lw it nh b gy nm nn l no np"># Pull all the reports into a big honking dataframe<br/>all_rep = []<br/>for i in report_list:<br/>  df1 = get_report(i)<br/>  all_rep.append(df1)</span><span id="1b6a" class="nl lw it nh b gy nq nn l no np">df = pd.concat(all_rep)<br/>df['hash'] = df.apply(lambda x: hash(tuple(x)), axis=1)</span></pre><p id="8f1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">非常简单，我创建all_rep列表作为一个空的占位符。从那里，我读取我的report_list列表，并为每个报告调用get_report函数，将结果放入df1。我取结果并将df1附加到all_rep。</p><p id="b839" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我做了最后的连接，然后将结果数据散列到一个名为“hash”的新列中。参见我之前对这个问题的讨论。</p><p id="967d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们有了可以输入到函数中并插入的最终系列:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="f030" class="nl lw it nh b gy nm nn l no np">conn = dbf.connect(conn_params_dic)<br/>  conn.autocommit = True<br/>  dbf.copy_from_dataFile(conn, df, 'fed_reports_tmp')</span></pre><p id="4b50" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这与我们对美联储新闻稿所做的一样。</p><p id="9311" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">至此，我们应该已经填充了两个_tmp表，并准备好进行处理。</p><p id="59a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将引导我们进入最后一步:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="4ca6" class="nl lw it nh b gy nm nn l no np"># Final Cleanup</span><span id="69e1" class="nl lw it nh b gy nq nn l no np">try:<br/>  cursor = conn.cursor()<br/>  query = "SELECT rehash_fed_reports_tmp()"<br/>  cursor.execute(query)<br/>  return_val = cursor.fetchall()<br/>  conn.commit()</span><span id="c023" class="nl lw it nh b gy nq nn l no np">  cursor = conn.cursor()<br/>  query = "SELECT rehash_fed_releases_tmp()"<br/>  cursor.execute(query)<br/>  return_val = cursor.fetchall()<br/>  conn.commit()</span><span id="872c" class="nl lw it nh b gy nq nn l no np">  cursor = conn.cursor()<br/>  query = "SELECT fed_report_update()"<br/>  cursor.execute(query)<br/>  return_val = cursor.fetchall()<br/>  conn.commit()</span><span id="d6bc" class="nl lw it nh b gy nq nn l no np">  cursor = conn.cursor()<br/>  query = "SELECT symbol_cleanup()"<br/>  cursor.execute(query)<br/>  return_val = cursor.fetchall()<br/>  conn.commit()</span><span id="006f" class="nl lw it nh b gy nq nn l no np">  print("Records updated and cleaned up.......")</span><span id="8f2d" class="nl lw it nh b gy nq nn l no np">except (Exception, dbf.psycopg2.Error) as error:<br/>  print("Error while fetching data from PostgreSQL", error)</span><span id="0c67" class="nl lw it nh b gy nq nn l no np">finally:<br/>  # closing database connection.<br/>  if conn:<br/>    cursor.close()<br/>    conn.close()<br/>    print("PostgreSQL connection is closed")</span></pre><p id="886b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这一步中，我们执行最后的select语句来运行我们之前定义的函数。前两个重写了_tmp表。第三个函数从_tmp表中更新主表。最后一个函数清除_tmp表，并为下一次运行做好准备。</p><p id="1343" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后的过程只是关闭我们的数据库连接，并通过一些友好的消息退出，让我们知道一切正常。</p><h1 id="f6d3" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">行程安排</h1><p id="d7c1" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我的最后一点是运行这个无人值守。为此，我有一个基本的cron条目，它在工作日每6小时运行一次该进程:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="f586" class="nl lw it nh b gy nm nn l no np">* */6 * * 1-5 /Library/Frameworks/Python.framework/Versions/3.9/bin/python3 ./data_miners/pull_fed_data.py 2&gt;&amp;1</span></pre><h1 id="23e2" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="a221" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">很难说是写整个过程还是这篇解释过程的文章花了更长的时间。这并不是说这篇文章花了很多时间，而是说一旦你掌握了节奏，获取数据、清理数据并将其放入数据库进行分析就相当容易了。</p><p id="507b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我鼓励完成这些类型的流程。最好的老师是逆境和排除错误。这在哪里可以改进？您看到了哪些错误？你有更好的解决办法吗？</p><p id="f65a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，在数据科学和数据分析的世界里，获取数据只是第一步。以这篇文章为指导，你现在有一大堆热门的相关时间序列数据可以利用。你会用它做什么？</p></div></div>    
</body>
</html>