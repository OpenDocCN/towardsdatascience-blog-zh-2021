<html>
<head>
<title>Overview of Albumentations: Open-source library for advanced image augmentations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">相册概述:用于高级图像增强的开源库</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/overview-of-albumentations-open-source-library-for-advanced-image-augmentations-c821a025c2ca?source=collection_archive---------31-----------------------#2021-07-01">https://towardsdatascience.com/overview-of-albumentations-open-source-library-for-advanced-image-augmentations-c821a025c2ca?source=collection_archive---------31-----------------------#2021-07-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="c24f" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="1be6" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated"><em class="ko">带有关于增强和集成PyTorch和Tensorflow管道的代码片段</em>。</h2></div><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/21263b74461383e34477b912aed4c249.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9t26IX1_ssk4WCr8"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">作者图片</p></figure><p id="6f3c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">原生PyTorch和TensorFlow增强器有一个很大的缺点，它们不能同时增强图像及其分段遮罩、边界框或关键点位置。所以有两个选择——要么自己写函数，要么用第三方库。两个我都试过了，第二个选择更好🙂</p><h1 id="718c" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">为什么是白蛋白？</h1><p id="e258" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated"><a class="ae my" href="https://albumentations.ai/" rel="noopener ugc nofollow" target="_blank">albuminations</a>是我尝试过的第一个图书馆，我一直坚持着，因为:</p><ul class=""><li id="bced" class="mz na iq lh b li lj ll lm lo nb ls nc lw nd ma ne nf ng nh bi translated">它是开源的，</li><li id="792b" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">直觉，</li><li id="1d17" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">快，</li><li id="42e6" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">拥有超过60种不同的增强功能，</li><li id="ff11" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">证据充分，</li><li id="1eb5" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">最重要的是，可以同时增强图像及其分段遮罩、边界框或关键点位置。</li></ul><p id="634d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">还有两个类似的库——<a class="ae my" href="https://github.com/aleju/imgaug" rel="noopener ugc nofollow" target="_blank">img aug</a>和<a class="ae my" href="https://github.com/mdbloice/Augmentor" rel="noopener ugc nofollow" target="_blank"> Augmentor </a>。不幸的是，我不能提供任何比较，因为我还没有尝试过。直到现在，白蛋白已经足够了。</p><h1 id="9026" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">简短教程</h1><p id="6daa" class="pw-post-body-paragraph lf lg iq lh b li mt ka lk ll mu kd ln lo mv lq lr ls mw lu lv lw mx ly lz ma ij bi translated">在这个简短的教程中，我将展示如何用几行代码轻松地增强图像以用于分割和对象检测任务。</p><p id="7898" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果你想跟随这个教程:</p><ol class=""><li id="2067" class="mz na iq lh b li lj ll lm lo nb ls nc lw nd ma nn nf ng nh bi translated"><a class="ae my" href="https://albumentations.ai/docs/getting_started/installation/" rel="noopener ugc nofollow" target="_blank">安装抛光垫</a>。我真的建议检查你是否有最新的版本，因为旧的版本可能会有问题。我用的是1.0.0版本，运行良好。</li><li id="e359" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma nn nf ng nh bi translated">下载标签如下的测试图像。这只是来自<a class="ae my" href="https://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> COCO数据集</a>的随机图像。我稍微修改了一下，然后按照相册要求的格式保存了下来。该库接受NumPy数组形式的图像、NumPy数组形式的分段遮罩和列表形式的边界框。</li></ol><p id="b0ae" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这里下载<a class="ae my" href="https://notrocketscience.blog/wp-content/uploads/2021/07/image_data.pickle.zip" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="ce84" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们加载图像、它的二进制像素分割蒙版和一个边界框。边界框被定义为4元素列表— [x_min，y_min，width，height]。</p><pre class="kq kr ks kt gt no np nq nr aw ns bi"><span id="21f4" class="nt mc iq np b gy nu nv l nw nx">import pickle <br/>import numpy as np <br/>import matplotlib.pyplot as plt <br/>import matplotlib.patches as patches</span><span id="ba6a" class="nt mc iq np b gy ny nv l nw nx"># load data<br/>with open("image_data.pickle", "rb") as handle:<br/>    image_data = pickle.load(handle)</span><span id="7474" class="nt mc iq np b gy ny nv l nw nx">image = image_data["image"]<br/>mask = image_data["mask"]<br/>bbox = image_data["bbox_coco"]</span><span id="3e5a" class="nt mc iq np b gy ny nv l nw nx"># visualize data<br/>fig, ax = plt.subplots(1, 2, figsize=(12, 5))<br/>ax[0].imshow(image)<br/>ax[0].set_title("Image")<br/>ax[1].imshow(image)<br/>bbox_rect = patches.Rectangle(<br/>    bbox[:2], bbox[2], bbox[3], linewidth=2, edgecolor="r", facecolor="none"<br/>)<br/>ax[1].add_patch(bbox_rect)<br/>ax[1].imshow(mask, alpha=0.3, cmap="gray_r")<br/>ax[1].set_title("Image + BBox + Mask")<br/>plt.show()</span></pre></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><p id="6f84" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在加载并可视化图像后，您应该会看到:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi og"><img src="../Images/bce9b7579ec1a252be6c3a17ef2f298d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dd1wfqpL2vkCVKjdBmtOAg.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="ko">图像。运行图像及其标签可视化代码时的输出。分割遮罩被可视化为透明的黑白图像(1为黑色，“马”)。作者图片</em></p></figure><p id="13b6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">用于分割的掩模增强</strong>。现在我们可以从白蛋白开始。这里的转换定义非常类似于PyTorch和TensorFlow (Keras API):</p><ul class=""><li id="32ce" class="mz na iq lh b li lj ll lm lo nb ls nc lw nd ma ne nf ng nh bi translated">通过使用Compose对象组合几个扩充来定义转换。</li><li id="6510" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">每个增强都有参数“p ”,即要应用的概率，此外还有特定于增强的参数，如RandomCrop的“width”和“height”。</li><li id="43dc" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">使用定义的变换作为函数来增加图像及其遮罩。这个函数返回一个包含关键字“图像”和“遮罩”的字典。</li></ul><p id="928b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下面是如何用随机256×256裁剪(总是)和水平翻转(仅在50%的情况下)来增加图像(及其遮罩)的代码。</p><pre class="kq kr ks kt gt no np nq nr aw ns bi"><span id="722a" class="nt mc iq np b gy nu nv l nw nx">import albumentations as A</span><span id="9c7a" class="nt mc iq np b gy ny nv l nw nx"># define agumentation<br/>transform = A.Compose([<br/>    A.RandomCrop(width=256, height=256, p=1),<br/>    A.HorizontalFlip(p=0.5),<br/>])</span><span id="8bce" class="nt mc iq np b gy ny nv l nw nx"># augment and visualize images<br/>fig, ax = plt.subplots(2, 3, figsize=(15, 10))<br/>for i in range(6):<br/>    <strong class="np ja">transformed = transform(image=image, mask=mask)</strong><br/>    ax[i // 3, i % 3].imshow(transformed["image"])<br/>    ax[i // 3, i % 3].imshow(transformed["mask"], alpha=0.3, cmap="gray_r")<br/>plt.show()</span></pre><p id="f0ed" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">结果，你应该得到这样的东西。您的增强图像会有所不同，因为白蛋白会产生随机转换。关于面罩增大的详细教程，请参考<a class="ae my" href="https://albumentations.ai/docs/getting_started/mask_augmentation/" rel="noopener ugc nofollow" target="_blank">原始文档</a>。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oh"><img src="../Images/8592dd00b29005ad0f687d93264de275.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ddgJ9keaFErj-28aRForQg.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="ko">形象。运行用于同时增强图像和遮罩的代码时的输出。</em> <br/> <em class="ko">分割蒙版被可视化为透明的黑白图像(1为黑色，‘马’)。作者图片</em></p></figure><p id="35aa" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">用于对象检测的包围盒增强</strong>。然而，它类似于分段遮罩的增强:</p><ul class=""><li id="a6b3" class="mz na iq lh b li lj ll lm lo nb ls nc lw nd ma ne nf ng nh bi translated">此外，定义“bbox_params ”,其中指定边界框的格式和边界框类的参数。“coco”表示COCO数据集格式的边界框— [x_min，y_min，width，height]。参数“bbox_classes”将在后面用于传递边界框的类。</li><li id="65ce" class="mz na iq lh b li ni ll nj lo nk ls nl lw nm ma ne nf ng nh bi translated">` transform '接受边界框作为列表的列表。此外，即使图像中只有一个边界框，它也需要边界框类(作为列表)。</li></ul><p id="f1e4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">下面是对图像及其边界框同时进行RandomCrop和HorizonalFrip的代码。</p><pre class="kq kr ks kt gt no np nq nr aw ns bi"><span id="04e2" class="nt mc iq np b gy nu nv l nw nx"># define augmentation <br/>transform = A.Compose([<br/>     A.RandomCrop(width=256, height=256, p=1),<br/>     A.HorizontalFlip(p=0.5), <br/>], <strong class="np ja">bbox_params=A.BboxParams(format='coco', label_fields=["bbox_classes"])</strong>)</span><span id="754a" class="nt mc iq np b gy ny nv l nw nx"># augment and visualize <br/>bboxes = [bbox]<br/>bbox_classes = ["horse"]</span><span id="1bd6" class="nt mc iq np b gy ny nv l nw nx">fig, ax = plt.subplots(2, 3, figsize=(15, 10))<br/>for i in range(6):<br/><strong class="np ja">    transformed = transform(<br/>        image=image, <br/>        bboxes=bboxes, <br/>        bbox_classes=bbox_classes<br/>    )</strong><br/>    ax[i // 3, i % 3].imshow(transformed["image"])<br/>    trans_bbox = transformed["bboxes"][0]<br/>    bbox_rect = patches.Rectangle(<br/>        trans_bbox[:2],<br/>        trans_bbox[2],<br/>        trans_bbox[3],<br/>        linewidth=2,<br/>        edgecolor="r",<br/>        facecolor="none",<br/>    )<br/>    ax[i // 3, i % 3].add_patch(bbox_rect)<br/>plt.show()</span></pre><p id="8287" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这是结果。如果您需要一些特定的边界框扩充，请参考<a class="ae my" href="https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/" rel="noopener ugc nofollow" target="_blank">原始文档</a>。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oi"><img src="../Images/6f94382d4be24eb6ce0197a21b65d9f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L8big8pMw2OdSi0aa5DcWQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="ko">图像。运行同步图像<br/>和边界框扩充代码时的输出。作者图片</em></p></figure><p id="05bd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">多个目标的同时增强。除了允许同时<a class="ae my" href="https://albumentations.ai/docs/getting_started/mask_augmentation/" rel="noopener ugc nofollow" target="_blank">增加几个遮罩</a>或<a class="ae my" href="https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/" rel="noopener ugc nofollow" target="_blank">几个边界框</a>之外，Albumentations还有一个功能可以同时增加不同类型的标签，例如，一个遮罩和一个边界框。</p><p id="8760" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当调用“转换”时，简单地给它你所拥有的一切:</p><pre class="kq kr ks kt gt no np nq nr aw ns bi"><span id="8818" class="nt mc iq np b gy nu nv l nw nx"># define augmentation <br/>transform = A.Compose([<br/>     A.RandomCrop(width=256, height=256, p=1),<br/>     A.HorizontalFlip(p=0.5), <br/>], bbox_params=A.BboxParams(format='coco', label_fields=["bbox_classes"]))</span><span id="5f4f" class="nt mc iq np b gy ny nv l nw nx"># augment and visualize <br/>bboxes = [bbox]<br/>bbox_classes = ["horse"]</span><span id="4111" class="nt mc iq np b gy ny nv l nw nx">fig, ax = plt.subplots(2, 3, figsize=(15, 10))<br/>for i in range(6):<br/>    <strong class="np ja">transformed = transform(<br/>        image=image, <br/>        mask=mask, <br/>        bboxes=bboxes, <br/>        bbox_classes=bbox_classes<br/>    )</strong><br/>    ax[i // 3, i % 3].imshow(transformed["image"])<br/>    trans_bbox = transformed["bboxes"][0]<br/>    bbox_rect = patches.Rectangle(<br/>        trans_bbox[:2],<br/>        trans_bbox[2],<br/>        trans_bbox[3],<br/>        linewidth=2,<br/>        edgecolor="r",<br/>        facecolor="none",<br/>    )<br/>    ax[i // 3, i % 3].add_patch(bbox_rect)<br/>    ax[i // 3, i % 3].imshow(transformed["mask"], alpha=0.3, cmap="gray_r")<br/>plt.show()</span></pre><p id="1cbc" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">您的结果将如下图所示。这里是关于那个的<a class="ae my" href="https://albumentations.ai/docs/getting_started/simultaneous_augmentation/" rel="noopener ugc nofollow" target="_blank">更详细的文档。</a></p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/d656fb341376a0e8147db8852fa04b65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wCEsbvSVK7xDq0GWjQ-SHQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated"><em class="ko">形象。运行同步图像、分割遮罩、<br/>和边界框增强代码时的输出。分割蒙版被可视化为透明的<br/>黑白图像(1为黑色，‘马’)。作者图片</em></p></figure><p id="828a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">还有更多。</strong>albuminations有更多可用的功能，例如对<a class="ae my" href="https://albumentations.ai/docs/getting_started/keypoints_augmentation/" rel="noopener ugc nofollow" target="_blank">关键点</a>和<a class="ae my" href="https://albumentations.ai/docs/autoalbument/" rel="noopener ugc nofollow" target="_blank">自动增强</a>的增强。它包括大约60种不同的增强类型，字面意思是你需要的任何任务。</p><p id="d001" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">最有可能的是，你将使用白蛋白作为PyTorch或TensorFlow培训管道的一部分，所以我将简要描述如何做。</p><p id="d167" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">PyTorch 。当<a class="ae my" href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files" rel="noopener ugc nofollow" target="_blank">创建自定义数据集</a>时，在` __init__ '函数中定义Albumentations转换，并在` __getitem__ '函数中调用它。PyTorch模型要求输入数据是张量，所以确保在定义“transform”时将“ToTensorV2”作为最后一步添加(这是一个来自Albumentations教程之一的技巧)。</p><pre class="kq kr ks kt gt no np nq nr aw ns bi"><span id="c09b" class="nt mc iq np b gy nu nv l nw nx">from torch.utils.data import Dataset<br/>from albumentations.pytorch import ToTensorV2</span><span id="5662" class="nt mc iq np b gy ny nv l nw nx">class CustomDataset(Dataset):<br/>    def __init__(self, images, masks):<br/>        self.images = images  # assume it's a list of numpy images<br/>        self.masks = masks  # assume it's a list of numpy masks<br/>        <strong class="np ja">self.transform = A.Compose([<br/>            A.RandomCrop(width=256, height=256, p=1),<br/>            A.HorizontalFlip(p=0.5),<br/>            ToTensorV2,<br/>        ])</strong></span><span id="4200" class="nt mc iq np b gy ny nv l nw nx">    def __len__(self):<br/>        return len(self.images)</span><span id="2354" class="nt mc iq np b gy ny nv l nw nx">    def __getitem__(self, idx):<br/>        """Returns a single sample"""<br/>        image = self.images[idx]<br/>        mask = self.masks[idx]<br/>        <strong class="np ja">transformed = self.transform(image=image, mask=mask)<br/>        transformed_image = transformed["image"]<br/>        transformed_mask = transformed["mask"]</strong><br/>        return transformed_image, transformed_mask</span></pre><p id="738b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja"> TensorFlow </strong> (Keras API)也允许创建<a class="ae my" href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence" rel="noopener ugc nofollow" target="_blank">自定义数据集</a>，类似于PyTorch。因此，在“__init__”函数中定义Albumentations转换，并在“__getitem__”函数中调用它。很简单，不是吗？</p><pre class="kq kr ks kt gt no np nq nr aw ns bi"><span id="e476" class="nt mc iq np b gy nu nv l nw nx">from tensorflow import keras</span><span id="bc29" class="nt mc iq np b gy ny nv l nw nx">class CustomDataset(keras.utils.Sequence):<br/>    def __init__(self, images, masks):<br/>        self.images = images<br/>        self.masks = masks<br/>        self.batch_size = 1<br/>        self.img_size = (256, 256)<br/>        <strong class="np ja">self.transform = A.Compose([<br/>            A.RandomCrop(width=256, height=256, p=1), <br/>            A.HorizontalFlip(p=0.5),<br/>        ])</strong></span><span id="fcb0" class="nt mc iq np b gy ny nv l nw nx">    def __len__(self):<br/>        return len(self.images) // self.batch_size</span><span id="91c8" class="nt mc iq np b gy ny nv l nw nx">    def __getitem__(self, idx):<br/>        """Returns a batch of samples"""<br/>        i = idx * self.batch_size<br/>        batch_images = self.images[i : i + self.batch_size]<br/>        batch_masks = self.masks[i : i + self.batch_size]<br/>        batch_images_stacked = np.zeros(<br/>            (self.batch_size,) + self.img_size + (3,), dtype="uint8"<br/>        )<br/>        batch_masks_stacked = np.zeros(<br/>            (self.batch_size,) + self.img_size, dtype="float32"<br/>        )<br/>        for i in range(len(batch_images)):<br/>            <strong class="np ja">transformed = self.transform(<br/>                image=batch_images[i], <br/>                mask=batch_masks[i]<br/>            )<br/>            batch_images_stacked[i] = transformed["image"]<br/>            batch_masks_stacked[i] = transformed["mask"]</strong><br/>        return batch_images_stacked, batch_masks_stacked</span></pre><p id="18e2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">就是这样！希望这篇教程鼓励你下次在做分割、物体检测或关键点定位任务时尝试Albumentations。如果有，请告诉我！</p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><p id="ec3b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="oj">原载于</em><a class="ae my" href="https://notrocketscience.blog/" rel="noopener ugc nofollow" target="_blank"><em class="oj">notrocketseconomy . blog</em></a></p><p id="d62e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="oj">如果你想阅读更多类似的教程，可以订阅我的博客“非火箭科学”——</em><a class="ae my" href="https://t.me/notrocketscienceblog" rel="noopener ugc nofollow" target="_blank"><em class="oj">电报</em> </a> <em class="oj">和</em> <a class="ae my" href="https://twitter.com/nRocketScience" rel="noopener ugc nofollow" target="_blank"> <em class="oj">推特</em> </a> <em class="oj">。</em></p></div></div>    
</body>
</html>