<html>
<head>
<title>Explainable AI (XAI) — A guide to 7 Packages in Python to Explain Your Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可解释的人工智能(XAI)——用Python写的7个包来解释你的模型的指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/explainable-ai-xai-a-guide-to-7-packages-in-python-to-explain-your-models-932967f0634b?source=collection_archive---------0-----------------------#2021-06-03">https://towardsdatascience.com/explainable-ai-xai-a-guide-to-7-packages-in-python-to-explain-your-models-932967f0634b?source=collection_archive---------0-----------------------#2021-06-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4c75" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">介绍各种框架和web应用程序，解释和说明Python中的机器学习(ML)模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/89afc203043da03354170d364460c5c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jOLuU80kQhSjfJOm"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">凯文·Ku在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="c35e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在过去的几年里，可解释的人工智能已经取得了重大进展。将这些黑盒模型转换成透明和可解释的算法的追求已经在学术界和商界获得了牵引力。许多文章、出版物和开源贡献现在使得解密这些复杂的模型变得容易，并把它们变成<em class="lv">白盒</em>，特别是对于商业用户、经理和领域专家。今天涉及生产ML模型的分析项目将这种可解释的人工智能作为交付的关键组件，以支持用户对可理解性和透明性的需求。</p><h1 id="4ceb" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">不久之前</h1><p id="45fe" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在<a class="ae ky" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> SHAP </a>和<a class="ae ky" href="https://github.com/marcotcr/lime" rel="noopener ugc nofollow" target="_blank">时间</a>等方法流行起来之前，标准模型解释(在全球层面上)具有一定的可解释性，包括可变重要性(基于ML算法的不同方法)、<a class="ae ky" href="https://scikit-learn.org/stable/modules/tree.html" rel="noopener ugc nofollow" target="_blank">决策树</a>、<a class="ae ky" href="https://scikit-learn.org/stable/modules/partial_dependence.html" rel="noopener ugc nofollow" target="_blank">部分依赖图(PDP)、个体条件期望图(ICE) </a>和经典回归系数等方法。在我们获得安慰和信任之前，人类需要了解事物是如何运作的。更高的模型复杂性导致更少的可解释性，这种经典的权衡现在已经得到控制。这些新的方法应用了诸如创建复制模型的方法，这些方法在局部范围内模拟原始模型的行为，并有助于解释某种预测是如何做出的。</p><h1 id="7c6b" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">XAI新时代</h1><p id="5f10" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">虽然近年来开发了许多包/方法，但本文旨在简要介绍Python XAI版中一些流行的包/框架，包括它们的基本特性和规范。下面还提供了代码片段示例和可视化效果，以提供输出的要点。请注意，这些包具有不同的依赖性，可能会在Python环境中产生冲突。建议设置不同的环境来运行这些代码，避免版本冲突。还要注意，我并不提倡这里的任何包，下面的一些评论是我基于使用和经验的个人意见。由于本文仅提供了一个介绍性的概述，因此每一节都提供了多个参考资料和文章链接，以供进一步阅读。</p><p id="81f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我们将使用<a class="ae ky" href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29" rel="noopener ugc nofollow" target="_blank">乳腺癌数据集</a>作为一个例子来描述来自各种包的一些输出。在该数据集中，从乳腺肿块细针抽吸(FNA)的数字化图像中计算特征。它们描述了图像中出现的细胞核的特征。任务是进行二元分类预测。</p><p id="3144" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们开始吧！</p><p id="33fe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们设置数据集。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/b6e2c6393a19abfe88038a417f05dd86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ci26R6L0S31hyhm3ab8TYw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</p></figure><p id="73bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们构建一个基本的<a class="ae ky" href="https://xgboost.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> Xgboost模型</a>，我们将在各个包中使用它。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/0f2612fcab4564f9245ef55c33ccc30c.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*zzizrSu-HkcCky5IsHSvug.png"/></div></figure><p id="850e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们开始分析来分解这个模型，并使它的运行变得透明。</p><h1 id="74c6" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated"><strong class="ak"> <em class="mx"> 1。SHAP </em> </strong></h1><p id="7dab" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">今天最流行的方法之一，SHAP (SHapley附加解释)是一种基于博弈论的方法来解释任何ML模型的输出。它将最优信用分配与使用博弈论及其相关扩展的经典Shapley值的本地解释联系起来。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/6bec1565f512b76e37d10f63d2cb712c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*r_ttYkwEzj4T9wQUeKYOhg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:SHAP Github页面</p></figure><p id="0c37" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SHAP帮助你理解影响的大小(条形的长度)和方向(颜色)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/e0561cba062505a2eb99a2e866cffe6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*6W7H1H00zhEixkygziH4-g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:SHAP Github</p></figure><p id="908f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SHAP是一个模型不可知的框架。关于方法论的更多细节可以在他们的第<a class="ae ky" href="https://shap.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">页</a>和论文中找到，比如由<a class="ae ky" href="https://papers.nips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf" rel="noopener ugc nofollow" target="_blank">伦德伯格和李</a>撰写的论文。Ula La Paris的另一篇理解数学的好文章是一个面向例子的解释，可以在这里阅读<a class="ae ky" rel="noopener" target="_blank" href="/shap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30"/>。这个包现在很容易成为最受欢迎的选择之一，在过去几年中，它在模型可解释性的各个方面都有直观和引人入胜的可视化。下面给出了一些可视化效果，以及生成这些效果的代码。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/eddaee1726f11c27060dfa3171aa6705.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7kJKWlTgAqzmDl4gYYZRFA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="9c7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于数据科学家来说，这是一个很好的起点。围绕使用这些值来生成更吸引人的可视化和洞察力的创造性方面在于数据科学家。下面的文章就是一个例子。</p><div class="na nb gp gr nc nd"><a href="https://medium.com/swlh/push-the-limits-of-explainability-an-ultimate-guide-to-shap-library-a110af566a02" rel="noopener follow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd iu gy z fp ni fr fs nj fu fw is bi translated">推动可解释性的极限——SHAP图书馆终极指南</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">本文是关于python SHAP库的高级和鲜为人知的特性的指南。它是基于一个例子…</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">medium.com</p></div></div><div class="nm l"><div class="nn l no np nq nm nr ks nd"/></div></div></a></div><p id="c242" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个包充当了许多基于仪表板和应用程序的框架的基础，这些框架将在本文后面介绍。</p></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><h1 id="d6e4" class="lw lx it bd ly lz nz mb mc md oa mf mg jz ob ka mi kc oc kd mk kf od kg mm mn bi translated">2.石灰</h1><p id="57cc" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">Lime是第一个在可解释性领域流行起来的技术之一。Lime代表本地可解释的模型不可知解释。本<a class="ae ky" href="https://arxiv.org/abs/1602.04938" rel="noopener ugc nofollow" target="_blank">论文</a>涵盖了Lime背后的方法论。目前，Lime有助于解释表格数据、图像和文本分类器的预测。</p><p id="0e03" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Lime基本上试图通过创建局部代理模型来给出模型行为的局部线性近似，该局部代理模型被训练来局部模拟ML模型的预测。虽然全球重要性显示了对整个数据集的平均影响，但每个变量可能以不同方式影响局部观察。这个代理模型可以是从GLMs到决策树的任何东西，它试图理解局部重要性可能如何不同。Christoph Molnar在<a class="ae ky" href="https://christophm.github.io/interpretable-ml-book/lime.html" rel="noopener ugc nofollow" target="_blank"> interpretable-ml-book </a>中提到的一般框架是:</p><ul class=""><li id="9117" class="oe of it lb b lc ld lf lg li og lm oh lq oi lu oj ok ol om bi translated">选择您感兴趣的实例，您希望了解其黑盒预测的解释</li><li id="8ee6" class="oe of it lb b lc on lf oo li op lm oq lq or lu oj ok ol om bi translated">扰动数据集并获得这些新点的黑盒预测</li><li id="89fa" class="oe of it lb b lc on lf oo li op lm oq lq or lu oj ok ol om bi translated">根据新样本与感兴趣的实例的接近程度对其进行加权</li><li id="0558" class="oe of it lb b lc on lf oo li op lm oq lq or lu oj ok ol om bi translated">在具有变化的数据集上训练加权的、可解释的模型</li><li id="1693" class="oe of it lb b lc on lf oo li op lm oq lq or lu oj ok ol om bi translated">通过解释本地模型来解释预测</li></ul><p id="a63e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是石灰有一定的局限性，应该谨慎使用(更多细节请参考本文<a class="ae ky" rel="noopener" target="_blank" href="/whats-wrong-with-lime-86b335f34612">文章</a>)。这篇<a class="ae ky" rel="noopener" target="_blank" href="/explaining-machine-learning-classifiers-with-lime-def5adaacfea">文章</a>为想要深入研究石灰的人提供了有趣的实验和进一步的参考。</p><p id="e108" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的数据集上，我们解释观察79。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/8a3b2cdc8e485697d7ef1c658ce49c28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DQviH2GSRXHk2_BI3CaUzg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><h1 id="4a32" class="lw lx it bd ly lz nz mb mc md oa mf mg jz ob ka mi kc oc kd mk kf od kg mm mn bi translated">3.沙帕什</h1><p id="ca94" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">交互性和引人入胜的视觉效果是传达数据故事、见解和模型结果的关键。将这些编译到笔记本或网络应用程序中代表了商业和数据科学家/分析师应该如何呈现AI/ML成果并与之交互的理想方式。<a class="ae ky" href="https://shapash.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">沙帕什</a>朝那个方向迈出了一步。这是一个由法国保险公司MAIF的数据科学家构建的Python库。这个软件包围绕SHAP/莱姆可解释性编译了各种可视化，并发布了一个易于使用的交互式仪表板作为一个web应用程序。</p><p id="28a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它使用Shap或Lime后端来计算贡献。Shapash 依靠不同的必要步骤来构建一个ML模型，以使结果可以理解。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/1d81f7bb4dd35e269c8b451f47fee3f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IREnNqlYZq3hsDtM.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:shapash</p></figure><p id="0cae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它适用于回归、二元分类或多类问题，并与许多模型兼容:<em class="lv"> Catboost </em>、<em class="lv"> Xgboost </em>、<em class="lv"> LightGBM </em>、<em class="lv"> Sklearn Ensemble </em>、<em class="lv">线性模型</em>和<em class="lv"> SVM </em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/dd73b1ef6445d01c233fcdbea73f2b80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/0*0_x8NkaKiwyEARCc.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:shapash</p></figure><p id="0dc8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的数据集和相关代码的一些可视化分享如下。我们继续使用我们的<em class="lv"> Xgboost </em>模型作为与这个包兼容的例子。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/5203a74155ca5287b0d2b9b7286eebda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QQw0matgFtK27T7mbHDnJA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="9517" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Shapash最近还在软件包中添加了报告和文档功能，这将在本文<a class="ae ky" rel="noopener" target="_blank" href="/shapash-1-3-2-announcing-new-features-for-more-auditable-ai-64a6db71c919">的</a>中详细介绍。这个包越来越受欢迎，被许多媒体文章和YouTube视频所覆盖。</p></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><h1 id="9bcd" class="lw lx it bd ly lz nz mb mc md oa mf mg jz ob ka mi kc oc kd mk kf od kg mm mn bi translated">4.解释器仪表板</h1><p id="a68b" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">由Oege Dijk 构建的ExplainerDashboard是一个广泛的、引人入胜的交互式仪表板库，用于解释各种频谱和方法中的ML模型。与Shapash相比，这要详细得多，即不仅限于SHAP或石灰。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/6ddc2b5f51cdf5a2a0ce4dc5a8798b9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uZvg5fVLP6Gy40mr.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://explainerdashboard.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> Explainerdashboard </a></p></figure><p id="bfa3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个仪表板涵盖了ML可解释性的各个方面，例如:</p><ul class=""><li id="026f" class="oe of it lb b lc ld lf lg li og lm oh lq oi lu oj ok ol om bi translated">特征重要性</li><li id="d24d" class="oe of it lb b lc on lf oo li op lm oq lq or lu oj ok ol om bi translated">度量和评估</li><li id="9c28" class="oe of it lb b lc on lf oo li op lm oq lq or lu oj ok ol om bi translated">局部预测可解释性</li><li id="51c8" class="oe of it lb b lc on lf oo li op lm oq lq or lu oj ok ol om bi translated">如果分析呢</li><li id="3b43" class="oe of it lb b lc on lf oo li op lm oq lq or lu oj ok ol om bi translated">决策树</li><li id="c1e9" class="oe of it lb b lc on lf oo li op lm oq lq or lu oj ok ol om bi translated">功能依赖关系</li><li id="b927" class="oe of it lb b lc on lf oo li op lm oq lq or lu oj ok ol om bi translated">相互作用</li></ul><p id="0a06" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作者撰写的一篇中型文章详细介绍了软件包和各种输出。</p><div class="na nb gp gr nc nd"><a href="https://medium.com/value-stream-design/making-ml-transparent-and-explainable-with-explainerdashboard-49953ae743dd" rel="noopener follow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd iu gy z fp ni fr fs nj fu fw is bi translated">用explainerdashboard让ML变得透明和可解释</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">世界正在越来越多的领域迅速采用越来越多的机器学习解决方案，包括一些严重…</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">medium.com</p></div></div><div class="nm l"><div class="ow l no np nq nm nr ks nd"/></div></div></a></div><p id="599f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还有作者的<a class="ae ky" href="https://www.youtube.com/watch?v=1nMlfrDvwc8" rel="noopener ugc nofollow" target="_blank"> PyData GLobal 2020 talk </a>。</p><p id="deb2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然这个包有许多可视化和输出。这个仪表板可能会有各种各样的组件，但它是模块化的，允许在创建自己喜欢的仪表板版本时有很大的灵活性和定制性。还有内联解释器来查看单个组件。下面是一些例子，后面是代码。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/c8c136932016d0a440b6b961b84d2dd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1J69GhTB54y9FAgOdsRR4g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="f8aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以用下面的一行代码创建预构建的仪表板。您可以根据需要切换和打开/关闭各种选项卡。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/0922ac93518efe5480c49d2e084090b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zMCCpk7jicRHeQxHLnnEsg.png"/></div></div></figure><p id="7f89" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于这个包的更详细的指南可以在Ravi的这篇文章中找到。</p><div class="na nb gp gr nc nd"><a href="https://medium.com/analytics-vidhya/explainer-dashboard-build-interactive-dashboards-for-machine-learning-models-fda63e0eab9" rel="noopener follow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd iu gy z fp ni fr fs nj fu fw is bi translated">解释器仪表板-为机器学习模型构建交互式仪表板</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">Python包来快速构建一个交互式仪表盘，解释适合的机器学习的内部工作原理…</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">medium.com</p></div></div><div class="nm l"><div class="oz l no np nq nm nr ks nd"/></div></div></a></div></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><h1 id="0129" class="lw lx it bd ly lz nz mb mc md oa mf mg jz ob ka mi kc oc kd mk kf od kg mm mn bi translated">5.Dalex</h1><p id="ea67" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><a class="ae ky" href="https://github.com/ModelOriented/DrWhy/blob/master/README.md" rel="noopener ugc nofollow" target="_blank"> DrWhy的一部分。AI </a>，<a class="ae ky" href="https://github.com/ModelOriented/DALEX" rel="noopener ugc nofollow" target="_blank"> Dalex </a>是一个流行的库，它提供了各种ML框架的包装器。然后可以研究这些包装器，并与一组本地和全局解释器进行比较。</p><p id="3267" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这本<a class="ae ky" href="https://ema.drwhy.ai/" rel="noopener ugc nofollow" target="_blank">电子书</a>解释了Dalex的哲学和方法论细节。它涵盖了模型可解释性的各个方面，如下图所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/318137e23ec6b0e5bafc26399b70bbb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JeD8apOZ5KhdshYd.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图像来源于<a class="ae ky" href="https://github.com/ModelOriented/DALEX" rel="noopener ugc nofollow" target="_blank"> DALEX </a></p></figure><p id="847b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Python和R版本的软件包涵盖了可变重要性、PDP和ALE图、分解图和SHAP瀑布图。它还包含一个用Python包装的原生SHAP包。这个包可以和各种ML框架一起工作，比如<code class="fe pb pc pd pe b">scikit-learn</code>、<code class="fe pb pc pd pe b">keras</code>、<code class="fe pb pc pd pe b">H2O</code>、<code class="fe pb pc pd pe b">tidymodels</code>、<code class="fe pb pc pd pe b">xgboost</code>、<code class="fe pb pc pd pe b">mlr</code>或者<code class="fe pb pc pd pe b">mlr3.</code></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/f4b73ea2a86c92493f952659ddf0e04a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*Z0Ej-7PvlinVj2-OBPcTdg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图像来源<a class="ae ky" href="https://ema.drwhy.ai/" rel="noopener ugc nofollow" target="_blank">解释性模型分析</a></p></figure><p id="757d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">电子书中介绍了故障和实时方法，在此<a class="ae ky" href="https://www.researchgate.net/publication/324246426_Explanations_of_Model_Predictions_with_live_and_breakDown_Packages" rel="noopener ugc nofollow" target="_blank">文章中进一步解释了</a>是此软件包的独特之处。这不同于通常的SHAP法和石灰法。这个包是为数不多的几个也有<a class="ae ky" href="https://fairmlbook.org/" rel="noopener ugc nofollow" target="_blank">公平</a>模块的包之一。笔记本示例可在<a class="ae ky" href="https://dalex.drwhy.ai/python-dalex-fairness.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到。一些模块如<a class="ae ky" href="https://ema.drwhy.ai/ceterisParibus.html" rel="noopener ugc nofollow" target="_blank">其他条件不变</a>有一些吸引人的视觉效果，如下图所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/dbf7298a236c5b3fb4e78e2dc6f5a230.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*exixF91UoIl_A6NegRO9yQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图像来源<a class="ae ky" href="https://ema.drwhy.ai/" rel="noopener ugc nofollow" target="_blank">解释性模型分析</a>，泰坦尼克号数据集</p></figure><p id="e63d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的数据集上使用这个包，我们用下面给出的代码片段生成了一些视觉效果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/1171982bf816b9286c4ee4d984a4d762.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2oitOaxl60W5hU5-r4dYUw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</p></figure><p id="edfd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有的情节都是互动的，与Plotly有一个整洁的集成，可以很容易地保存。Dalex也不会落在仪表板空间的后面。<a class="ae ky" href="https://arena.drwhy.ai/docs/" rel="noopener ugc nofollow" target="_blank"> Arena </a>是Dalex的交互式拖拽仪表盘。视觉效果相当不错，界面也很整洁。下面是我们数据集中的一张快照，您可以从中一窥仪表盘。代码片段只有几行，如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/d87732d07c8f1336a0d5ff3b631c8e53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GmWec4h5Uy3mAja9qnB97g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><h1 id="a0fc" class="lw lx it bd ly lz nz mb mc md oa mf mg jz ob ka mi kc oc kd mk kf od kg mm mn bi translated">6.可解释的增压机(EBM)</h1><p id="2c57" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这是街区里新来的孩子。由<a class="ae ky" href="https://interpret.ml/" rel="noopener ugc nofollow" target="_blank"> Interpret ML </a>创建，Interpret是微软的一个开源包，它有一个“玻璃盒子”模型模块，可以解释。这并不意味着性能上的损失，因为EBM在一些<a class="ae ky" href="https://github.com/interpretml/interpret/" rel="noopener ugc nofollow" target="_blank">数据集</a>中表现出与其他增强方法相当的性能。</p><p id="17e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基于<a class="ae ky" href="https://en.wikipedia.org/wiki/Additive_model#:~:text=In%20statistics%2C%20an%20additive%20model,class%20of%20nonparametric%20regression%20models." rel="noopener ugc nofollow" target="_blank">加性模型</a>的思想，这种方法改变了训练过程，从训练所有特征的决策树到一次一个特征的决策树。以小深度和增强方式为每个特征构建多个树。基于其所有树的求和，我们可以用输出变量来估计输入变量的函数(<em class="lv"> f) </em>。这里有一些作者<a class="ae ky" href="https://youtu.be/MREiHgHgl0k" rel="noopener ugc nofollow" target="_blank">的好视频</a>。论文也可以在<a class="ae ky" href="https://arxiv.org/pdf/1909.09223.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>获取。每个特征对最终预测的贡献可以通过其<em class="lv"> f </em>来理解。由于EBM是一个附加模型，每个特征以模块化的方式对预测做出贡献，这使得推理每个特征对预测的贡献变得容易。</p><p id="36b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">代码架构非常简单。下面这张来自官方<a class="ae ky" href="https://arxiv.org/pdf/1909.09223.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>的图片给了我们一瞥。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/f1b792675aea54636d2ea21a1a288223.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BSLmLXnGlgXLfeWA_F_9BA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:由<a class="ae ky" href="https://arxiv.org/pdf/1909.09223.pdf" rel="noopener ugc nofollow" target="_blank">解读ML </a></p></figure><p id="6d72" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了玻璃盒模型，人们还可以使用通常的SHAP，石灰，PDP和包装的灵敏度组件。这个也兼容<code class="fe pb pc pd pe b">scikit-learn</code>。这篇Medium <a class="ae ky" rel="noopener" target="_blank" href="/interpretml-analysis-of-svm-and-xgboost-models-e68062f7299f">文章</a>为<em class="lv"> SVM </em>和<em class="lv"> Xgboost </em>提供了一个很好的使用这个包的例子。这个包还允许您将各种交互式小部件编译成一个简洁的仪表板。在他们的github <a class="ae ky" href="https://github.com/interpretml/interpret/" rel="noopener ugc nofollow" target="_blank">页面</a>中有很多例子。然而，我发现这个包仍然处于早期阶段，并且在一般的东西上是有限的，例如，模型度量等等。相对于其他软件包，可视化效果也没有那么吸引人。然而，这种方法有望获得相当的性能。</p><p id="5951" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的数据集上，下面给出了一些可视化和代码。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/1c91d7f9550a6ac015cf52d01cc47f8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wJ4NIDpRKTtmE6XOYy2tnw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</p></figure><p id="d68f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些都可以打包到一个仪表板中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/8a7a40a32f43906c4e755fc0e6a76011.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-jterGsvkIUh6ot-7g5O-w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><h1 id="f294" class="lw lx it bd ly lz nz mb mc md oa mf mg jz ob ka mi kc oc kd mk kf od kg mm mn bi translated">7.ELI5</h1><p id="199d" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">ELI5是麻省理工学院的另一个可解释性包，支持ML框架和包，如<em class="lv"> Scikit-learn、Keras、Xgboost、</em>等。有了统一的API，跨包和框架比较模型变得更加容易。还有许多其他组件，如<a class="ae ky" href="https://eli5.readthedocs.io/en/latest/tutorials/black-box-text-classifiers.html" rel="noopener ugc nofollow" target="_blank">文本解释器</a>，它使用Lime算法和<a class="ae ky" href="https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html" rel="noopener ugc nofollow" target="_blank">置换重要性</a>。这个包巧妙地将解释分为两个部分:</p><ol class=""><li id="acb1" class="oe of it lb b lc ld lf lg li og lm oh lq oi lu pm ok ol om bi translated">Global是<code class="fe pb pc pd pe b"><a class="ae ky" href="https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_weights" rel="noopener ugc nofollow" target="_blank">show_weights(</a>)</code>，您可以在其中提供所需的参数，以指定您希望看到的全局重要性类型(例如，“增益”、“重量”、“增益”、“覆盖”、“总增益”、“总覆盖”)</li><li id="906f" class="oe of it lb b lc on lf oo li op lm oq lq or lu pm ok ol om bi translated"><code class="fe pb pc pd pe b"><a class="ae ky" href="https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_prediction" rel="noopener ugc nofollow" target="_blank">eli5.show_prediction()</a></code>给出了局部水平解释，解释了局部水平预测</li></ol><p id="8479" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其他函数如<code class="fe pb pc pd pe b"><a class="ae ky" href="https://eli5.readthedocs.io/en/latest/autodocs/formatters.html#module-eli5.formatters" rel="noopener ugc nofollow" target="_blank">eli5.formatters</a></code>可以用来获取HTML、文本、JSON或PIL图像等。解释的表示。</p><p id="6f7c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在这个包里找不到引人入胜的视觉效果。跨各种ML包/框架的统一平台是它的主要亮点。下面给出了一些输出和代码片段。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pn"><img src="../Images/48564a23d11269828a614b4bee23c99a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cYl2tqPNn8tbNGKDsmE7WQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:作者</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><h1 id="1af6" class="lw lx it bd ly lz nz mb mc md oa mf mg jz ob ka mi kc oc kd mk kf od kg mm mn bi translated"><strong class="ak"> 8。这还不是全部！</strong></h1><p id="c80a" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">虽然这篇文章涵盖了使你的模型透明和可解释的最流行的选项，但还有其他可以进一步探索的包，如涵盖一些不同方法的<a class="ae ky" href="https://github.com/SeldonIO/alibi" rel="noopener ugc nofollow" target="_blank"> Alibi </a>，如<a class="ae ky" href="https://docs.seldon.io/projects/alibi/en/latest/methods/Anchors.html" rel="noopener ugc nofollow" target="_blank"> Anchors </a>。<a class="ae ky" href="https://github.com/oracle/Skater" rel="noopener ugc nofollow" target="_blank"> Skater </a>是另一个软件包，它以一个酸橙叉开始，但后来作为一个独立的框架爆发。还有其他一些有趣的项目值得探索，比如IBM的<a class="ae ky" href="https://github.com/EthicalML/xai" rel="noopener ugc nofollow" target="_blank"> EhticalML </a>、<a class="ae ky" href="https://pypi.org/project/aix360/" rel="noopener ugc nofollow" target="_blank"> Aix360 </a>、ML的<a class="ae ky" href="https://github.com/interpretml/DiCE" rel="noopener ugc nofollow" target="_blank">多样性反事实解释(DiCE) </a>，它来自于我们上面为EBMs介绍的interpret ML。Ai 等。对于那里的R爱好者来说，在文章<a class="ae ky" href="http://xai-tools.drwhy.ai/" rel="noopener ugc nofollow" target="_blank"> <em class="lv">可解释人工智能的R包景观</em> </a>中可以找到XAI上类似的精选包列表。</p><h1 id="7cc9" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结论</h1><p id="481f" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这一研究领域和开源贡献正在快速发展，这与解释、调试和验证我们的模型决策是多么重要是一致的，特别是当实际的人工智能模型部署呈上升趋势时，以及这些算法在我们的日常生活中变得多么有影响力。上述软件包只是一个起点，可供数据科学家、工程师和分析师进一步利用和构建。这将提高对基于人工智能的解决方案的信任，从而加快其采用。</p></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><p id="3d22" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">参考文献:</em> </strong></p><p id="0ead" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[1]<a class="ae ky" href="https://towardsdatascience.com/tagged/xai" rel="noopener" target="_blank">https://towardsdatascience.com/tagged/xai</a></p><p id="08c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2]<a class="ae ky" rel="noopener" target="_blank" href="/unboxing-the-black-box-using-lime-5c9756366faf">https://towards data science . com/unbox-the-black-box-using-lime-5c 9756366 faf</a></p><p id="c599" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[3]<a class="ae ky" href="https://www.kdnuggets.com/2021/04/shapash-machine-learning-models-understandable.html" rel="noopener ugc nofollow" target="_blank">https://www . kdnugges . com/2021/04/shapash-machine-learning-models-understand . html</a></p><p id="49d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[<a class="ae ky" href="https://medium.com/swlh/push-the-limits-of-explainability-an-ultimate-guide-to-shap-library-a110af566a02" rel="noopener">4]https://medium . com/swlh/push-the-limits-of-explability-an-ultimate-guide-to-shap-library-a 110 af 566 a 02</a></p><p id="380b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">【https://pypi.org/project/explainerdashboard/ T2】</p><p id="522b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[6]<a class="ae ky" href="https://medium.com/value-stream-design/making-ml-transparent-and-explainable-with-explainerdashboard-49953ae743dd" rel="noopener">https://medium . com/value-stream-design/making-ml-transparent-and-explain-with-explainer dashboard-49953 AE 743 DD</a></p><p id="155b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[7]<a class="ae ky" href="https://medium.com/swlh/push-the-limits-of-explainability-an-ultimate-guide-to-shap-library-a110af566a02" rel="noopener">https://medium . com/swlh/push-the-limits-of-explability-an-ultimate-guide-to-shap-library-a 110 af 566 a 02</a></p><p id="bfa8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://dalex.drwhy.ai/python-dalex-xgboost.html" rel="noopener ugc nofollow" target="_blank">https://dalex.drwhy.ai/python-dalex-xgboost.html</a></p><p id="4a3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[9]<a class="ae ky" href="https://uc-r.github.io/dalex" rel="noopener ugc nofollow" target="_blank">https://uc-r.github.io/dalex</a></p><p id="66e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[10]<a class="ae ky" rel="noopener" target="_blank" href="/decrypting-your-machine-learning-model-using-lime-5adc035109b5">https://towards data science . com/decrypting-your-machine-learning-model-using-lime-5 ADC 035109 b5</a></p><p id="ae24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[11]<a class="ae ky" rel="noopener" target="_blank" href="/explaining-machine-learning-classifiers-with-lime-def5adaacfea">https://towards data science . com/explaining-machine-learning-classifiers-with-lime-def 5 adaacfea</a></p><p id="3f48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[12]<a class="ae ky" rel="noopener" target="_blank" href="/whats-wrong-with-lime-86b335f34612">https://towards data science . com/whats-错在哪里-lime-86b335f34612 </a></p><p id="67dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[13]<a class="ae ky" rel="noopener" target="_blank" href="/the-explainable-boosting-machine-f24152509ebb">https://towards data science . com/the-explaible-boosting-machine-f 24152509 ebb</a></p><p id="5278" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[14]<a class="ae ky" rel="noopener" target="_blank" href="/interpretml-analysis-of-svm-and-xgboost-models-e68062f7299f">https://towards data science . com/interpret ml-analysis-of-SVM-and-xgboost-models-e 68062 f 7299 f</a></p><p id="e204" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[15]<a class="ae ky" href="https://www.analyticsvidhya.com/blog/2020/11/demystifying-model-interpretation-using-eli5/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2020/11/demystifying-model-interpretation-using-Eli 5/</a></p><p id="0c28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[16]<a class="ae ky" href="https://eli5.readthedocs.io/en/latest/overview.html#features" rel="noopener ugc nofollow" target="_blank">https://Eli 5 . readthe docs . io/en/latest/overview . html #特性</a></p><p id="0b08" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[17]<a class="ae ky" href="https://medium.com/analytics-vidhya/why-should-i-trust-your-model-bdda6be94c6f" rel="noopener">https://medium . com/analytics-vid hya/why-should-I-trust-your-model-bdda 6 be 94 c6f</a></p><p id="fcd4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[18]<a class="ae ky" rel="noopener" target="_blank" href="/explainable-artificial-intelligence-part-3-hands-on-machine-learning-model-interpretation-e8ebe5afc608">https://towards data science . com/explaible-artificial-intelligence-part-3-hands-on-machine-learning-model-interpretation-E8 ebe 5 AFC 608</a></p><p id="4d1e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[19]https://awesomeopensource.com/projects/xai?categoryPage=7<a class="ae ky" href="https://awesomeopensource.com/projects/xai?categoryPage=7" rel="noopener ugc nofollow" target="_blank"/></p><p id="f925" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">【http://xai-tools.drwhy.ai/ 20】<a class="ae ky" href="http://xai-tools.drwhy.ai/" rel="noopener ugc nofollow" target="_blank"/></p><p id="b3a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[21]<a class="ae ky" href="https://medium.com/analytics-vidhya/explainer-dashboard-build-interactive-dashboards-for-machine-learning-models-fda63e0eab9" rel="noopener">https://medium . com/analytics-vid hya/explainer-dashboard-build-interactive-dashboards-for-machine-learning-models-FDA 63 E0 eab 9</a></p></div></div>    
</body>
</html>