<html>
<head>
<title>How Do You Implement AdaBoost with Python?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用Python实现AdaBoost？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-do-you-implement-adaboost-with-python-a76427b0fa7a?source=collection_archive---------15-----------------------#2021-10-22">https://towardsdatascience.com/how-do-you-implement-adaboost-with-python-a76427b0fa7a?source=collection_archive---------15-----------------------#2021-10-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="fd39" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">助推技术</h2><div class=""/><div class=""><h2 id="1b3f" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">机器学习中的助推算法——第二部分</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/8cf414e88740b9516c2b2bc59b19694c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4kkYLLbafl1zpFh_Yq7xhA.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@johnprice?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">约翰·普莱斯</a>在<a class="ae lh" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="1aab" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们继续机器学习系列文章中<strong class="lk jd">提升算法的<a class="ae lh" rel="noopener" target="_blank" href="/introduction-to-boosted-trees-2692b6653b53">第1部分</a>。看过<a class="ae lh" rel="noopener" target="_blank" href="/introduction-to-boosted-trees-2692b6653b53">第一部</a>吗？它向您简要介绍了boosting以及一些关键技术术语的定义，这些术语对于理解今天的内容非常重要。</strong></p><p id="2d79" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">今天，我们将学习最流行的增强算法之一:AdaBoost(自适应增强)。更多的重点将放在算法的实现部分，在以下主题。</p><ul class=""><li id="e496" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">sci kit-AdaBoost的学习类</li><li id="bc44" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">在葡萄酒数据上训练和评估AdaBoost分类模型</li><li id="1f94" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">将AdaBoost模型与决策树残肢进行比较</li><li id="a2b9" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">AdaBoost中的重要超参数</li><li id="f04b" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">测量超参数的效果<strong class="lk jd"> <em class="ms"> n_estimators </em> </strong></li><li id="7bc7" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">测量超参数<strong class="lk jd">的效果<em class="ms">学习_速率</em> </strong></li><li id="feab" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">使用网格搜索找到最佳超参数值</li></ul><p id="8dec" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">所有代码示例都将作为GitHub gists包含在内，以便您可以轻松地使用它们！在本文的最后，您将能够在具有最佳超参数值的给定数据集上实现AdaBoost算法。</p><p id="1410" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们开始吧！</p><h1 id="1947" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">sci kit-AdaBoost的学习类</h1><p id="4b10" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">AdaBoost的Python实现由两个Scikit-learn类完成:<a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd">AdaBoostClassifier()</strong></a>用于分类(二进制和多类)，以及<a class="ae lh" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd">AdaBoostRegressor()</strong></a>用于回归。导入惯例是:</p><pre class="ks kt ku kv gt nq nr ns nt aw nu bi"><span id="e6eb" class="nv mu it nr b gy nw nx l ny nz">from sklearn.ensemble import AdaBoostClassifier</span><span id="9d5d" class="nv mu it nr b gy oa nx l ny nz">from sklearn.ensemble import AdaBoostRegressor</span></pre><h1 id="8250" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">创建决策树树桩模型</h1><p id="9e97" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">通过用<strong class="lk jd"> max_depth=1 </strong>提前停止树的生长，我们将在葡萄酒数据上构建一个决策树桩。这是为了比较决策树桩和AdaBoost模型。我们也使用这个树桩模型作为AdaBoost的基础学习器。</p><p id="60dc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面的Python代码在Wine数据上创建了一个决策树，并评估了它的性能。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ob oc l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">基于葡萄酒数据的决策树树桩模型</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi od"><img src="../Images/c5ca3015cb80ce9d2d23ecba4bf339c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*KO3EvKBIi_T_lT9AQjgeHg.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="2f23" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">模型的性能很差。这并不奇怪，因为我们<em class="ms">通过设置<strong class="lk jd"> max_depth=1 </strong>来严格</em>调节树的生长。</p><h1 id="c6c8" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">创建AdaBoost分类模型</h1><p id="3f6f" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">现在，我们将在葡萄酒数据上构建一个AdaBoost分类模型。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ob oc l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">基于葡萄酒数据的AdaBoost分类模型</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/0361c7208db483424ad36ce191cbbc5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*613xTID5pufH2hheZB5mZA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="4371" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">哦那个分数！与决策树残肢相比，AdaBoost模型表现得非常好。</p><h1 id="e95b" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">AdaBoost中的重要超参数</h1><p id="1414" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">以下是<strong class="lk jd"> AdaBoostClassifier() </strong>和<strong class="lk jd"> AdaBoostRegressor() </strong>中最重要的超参数。</p><ul class=""><li id="5681" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated"><strong class="lk jd"> base_estimator: </strong>这是AdaBoost算法中使用的基本学习器。默认的也是最常见的学习者是我们前面讨论过的决策树stump(max _ depth = 1的决策树)。</li><li id="7c0f" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated"><strong class="lk jd"> n_estimators: </strong>顺序训练的估计器(模型)的最大数量。默认值为50。我们将很快测量这个超参数的影响。</li><li id="8659" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated"><strong class="lk jd"> learning_rate: </strong>确定在增强过程中应用于每个估计器的权重。默认值为1。较小的值(如0.05、0.1)会强制算法训练较慢，但具有高性能分数。我们将很快测量这个超参数的影响。</li></ul><h1 id="f4fa" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">测量效果<strong class="ak"> <em class="of"> n_estimators </em> </strong></h1><p id="cbe8" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">我们将通过将超参数<strong class="lk jd"> n_estimators </strong>的值从2变化到100来手动测量其效果，并绘制AdaBoost模型给出的测试分数。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ob oc l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">n _估计量的影响</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi og"><img src="../Images/70c8cb3b0798fce86fe807174fe15817.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*Y_taHs3WnsFFRQxddYVhWw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="e9da" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在大约30次估计之后，我们之前获得的准确度分数恒定在0.972。您可以使用30以上的任何整数。但是请记住，如果您增加该值，该算法将需要很长时间进行训练。因此，在这种情况下，最好使用默认值50。</p><h1 id="172b" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated"><strong class="ak">衡量效果<em class="of">学习_速率</em> </strong></h1><p id="472c" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">我们将通过从0.1到1改变超参数<strong class="lk jd"> learning_rate </strong>的值来手动测量其效果，并绘制AdaBoost模型给出的测试分数。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ob oc l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">学习率的影响</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/87cced0df7dfba18fed3624f81eef4e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*wU1CmcqH7JCAWpN5J6HtPw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="728d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">最高精度为0.4、0.5、0.7和0.8。我们在上面的模型中使用了0.5。</p><p id="4ee7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">两种测量都是手动完成的。有一种更简单的方法来找到<strong class="lk jd"> n_estimators </strong>和<strong class="lk jd"> learning_rate </strong>的最优值。</p><h1 id="71e4" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">使用网格搜索找到最佳超参数值</h1><p id="d0e6" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">这里，我们通过使用<a class="ae lh" rel="noopener" target="_blank" href="/python-implementation-of-grid-search-and-random-search-for-hyperparameter-optimization-2d6a82ebf75c"> <strong class="lk jd">网格搜索</strong> </a>，同时自动调整(找到最佳值)两个超参数<em class="ms"/>。相比之下，在前面的步骤中，我们一次调优一个超参数。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ob oc l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">执行网格搜索</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oi"><img src="../Images/63a1b0f0f37bac901f84e2897cfda162.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uJJH20yo6JdnuVULfbjTsw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">(图片由作者提供)</p></figure><p id="32d6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们可以使用这些值来获得AdaBoost模型的最高精度。给出相同精度的一些其他可能的组合是:</p><ul class=""><li id="05c8" class="me mf it lk b ll lm lo lp lr mg lv mh lz mi md mj mk ml mm bi translated">学习率=0.5，n个估计值=50</li><li id="0453" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">学习率=0.8，n个估计值=50</li><li id="5919" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">学习率=0.8，n个估计值=100</li><li id="6206" class="me mf it lk b ll mn lo mo lr mp lv mq lz mr md mj mk ml mm bi translated">学习率=0.4，n个估计值=50</li></ul><h1 id="1ab7" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">摘要</h1><p id="45a1" class="pw-post-body-paragraph li lj it lk b ll nl kd ln lo nm kg lq lr nn lt lu lv no lx ly lz np mb mc md im bi translated">用Python构建AdaBoost模型非常简单。你所要做的就是确定你想要解决的问题类型(回归/分类)并选择Scikit-learn中提供的合适的AdaBoost类。然而，超参数调整过程是一个真正的挑战。你需要做一些可视化，为超参数调整做并行计算。实际上，您将创建数千个模型。幸运的是，我们可以使用本文中讨论的高级方法来自动化调优过程。</p><p id="f80d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">模型的输出很大程度上受随机数据分割的影响。根据在<strong class="lk jd"> random_state </strong>中指定的整数，您可能会得到不同的准确度分数。总是建议指定一个整数，以便在不同的执行中获得静态结果。</p><p id="3fdb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">与决策树和随机森林等其他基于树的方法相比，AdaBoost等boosting算法的性能非常好。这是因为考虑到前几轮初始树产生的误差，升压中的树被顺序训练。</p><p id="4b31" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在<a class="ae lh" rel="noopener" target="_blank" href="/under-the-hood-of-gradient-boosting-and-its-python-implementation-99cc63efd24d">第三部</a>中，我们将讨论<strong class="lk jd">梯度增强</strong>，另一种流行的增强算法。下一个故事再见。祝大家学习愉快！</p></div><div class="ab cl oj ok hx ol" role="separator"><span class="om bw bk on oo op"/><span class="om bw bk on oo op"/><span class="om bw bk on oo"/></div><div class="im in io ip iq"><p id="14de" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我的读者可以通过下面的链接注册成为会员，以获得我写的每个故事的全部信息，我将收到你的一部分会员费。</p><div class="oq or gp gr os ot"><a href="https://rukshanpramoditha.medium.com/membership" rel="noopener follow" target="_blank"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd jd gy z fp oy fr fs oz fu fw jc bi translated">通过我的推荐链接加入Medium</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">rukshanpramoditha.medium.com</p></div></div><div class="pc l"><div class="pd l pe pf pg pc ph lb ot"/></div></div></a></div><p id="b591" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">非常感谢你一直以来的支持！</p><p id="2587" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">特别感谢Unsplash上的<strong class="lk jd">约翰·普莱斯</strong>，<strong class="lk jd"> </strong>为我提供了这篇文章的精美封面图片。</p><p id="1d1e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="pi pj ep" href="https://medium.com/u/f90a3bb1d400?source=post_page-----a76427b0fa7a--------------------------------" rel="noopener" target="_blank">鲁克山普拉莫迪塔</a><br/><strong class="lk jd">2021–10–22</strong></p></div></div>    
</body>
</html>