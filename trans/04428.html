<html>
<head>
<title>Creating a simple machine learning demo with GradioML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用GradioML创建一个简单的机器学习演示</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/creating-a-simple-image-classification-machine-learning-demo-with-gradioml-361a245d7b50?source=collection_archive---------7-----------------------#2021-04-15">https://towardsdatascience.com/creating-a-simple-image-classification-machine-learning-demo-with-gradioml-361a245d7b50?source=collection_archive---------7-----------------------#2021-04-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4e23" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">只需几行代码就可以在功能性用户界面中部署模型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/edbd9d22b19814dc3aee385ee5c08c2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gfs0Yw5TO4MO6Bzh_M6gFg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="d433" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">部署机器学习模型有时是数据科学中被忽视的一个方面。许多分析专业人员将大部分注意力集中在理论和应用上，以构建能够解决问题和满足目标的模型。这在项目的研究或原型阶段都是完全没问题的。但是，为了与其他职业的利益相关者或合作者分享这项工作，为这些用户和观众开发某种应用程序会很好。</p><p id="e919" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，部署这些模型的任务并不总是那么简单。要完成这项工作，还需要掌握许多额外的技能和工具。传统上，机器学习工程师和DevOps专家等专家与数据科学家合作，将这些模型投入生产。</p><p id="7777" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有时，一个简单的用户界面演示可以完成传达机器学习模型内容的工作，而不是全力以赴进行部署。在寻找可以帮助构建这个的工具时，我偶然发现了<strong class="kx ir"> GradioML </strong>，一个符合这种描述的开源工具。</p><p id="8e8d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> Gradio是一个软件包，允许用户用几行代码创建简单的网络应用。</strong>它的基本用途与Streamlight和Flask相同，但使用起来更简单。许多类型的网络界面工具可以选择，包括画板，文本框，文件上传按钮，网络摄像头等。使用这些工具接收各种类型的数据作为输入，可以很容易地演示分类和回归等机器学习任务。(参考工具见<a class="ae lr" href="https://www.gradio.app/" rel="noopener ugc nofollow" target="_blank">官网</a>及其<a class="ae lr" href="https://github.com/gradio-app/gradio" rel="noopener ugc nofollow" target="_blank"> Github页面</a>)</p><p id="8c74" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本演练中，我们将快速创建一个猫/狗图像分类模型，并部署一个简单的Gradio演示程序，我们可以在其中上传新图像以进行分类预测。该模型将是一个简单的Keras <strong class="kx ir">卷积神经网络(CNN) </strong>，它将在作为特征的猫和狗的图像上进行训练，并将它们的类名作为标签。</p><p id="d379" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有关Jupyter笔记本的完整代码，请参考<a class="ae lr" href="https://github.com/DavidYoo912/cat_dog_classification/blob/main/cat_dog_image_classification.ipynb" rel="noopener ugc nofollow" target="_blank">此链接</a></p><h1 id="5739" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">必需品；要素</h1><p id="34b1" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">首先我们安装Gradio</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="3f2d" class="mu lt iq mq b gy mv mw l mx my">pip install gradio</span></pre><p id="b893" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，我们导入依赖项。我们需要的一些工具将用于<strong class="kx ir">数值计算</strong>(Numpy)<strong class="kx ir">可视化/绘图</strong>(Matplotlib)<strong class="kx ir">图像数据争论</strong>(cv2)<strong class="kx ir">深度学习</strong> (Tensorflow，Keras)，当然还有<strong class="kx ir">构建web界面</strong> (Gradio)</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="5f28" class="mu lt iq mq b gy mv mw l mx my">import numpy as np<br/>import pandas as pd</span><span id="23d8" class="mu lt iq mq b gy mz mw l mx my">import matplotlib.pyplot as plt<br/>import os<br/>import cv2</span><span id="cabe" class="mu lt iq mq b gy mz mw l mx my">from sklearn.model_selection import train_test_split<br/>from sklearn import metrics</span><span id="84fb" class="mu lt iq mq b gy mz mw l mx my">import tensorflow as tf<br/>from tensorflow import keras<br/>from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D</span><span id="f4bf" class="mu lt iq mq b gy mz mw l mx my">import gradio<br/>import gradio as gr<br/></span></pre><h1 id="016a" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">浏览和组织数据</h1><p id="2c12" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">然后我们看一下我们的数据。猫/狗图像来自发布在<a class="ae lr" href="https://www.kaggle.com/dbtjdals/cat-dog-classification" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>中的数据集来源。我们将检查第一张图片</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="d286" class="mu lt iq mq b gy mv mw l mx my">DATADIR = os.path.abspath(os.getcwd()) + '/PetImages'</span><span id="46bf" class="mu lt iq mq b gy mz mw l mx my">path = os.path.join(DATADIR, category)    #path to cats or dogs dir<br/>first_img_path = os.listdir(path)[0]<br/>img_array = cv2.imread(os.path.join(path, first_img_path), cv2.IMREAD_GRAYSCALE)<br/>plt.imshow(img_array, cmap = "gray")<br/>plt.show()</span><span id="df62" class="mu lt iq mq b gy mz mw l mx my">#show image shape<br/>print('The image shape is {}'.format(img_array.shape))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/7abc29841151d56efca0704b61b507f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*8pZVzm-0rmxd4-_f-FFGhw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="448e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因为这个练习是针对一个简单的CNN模型，我们将调整所有图像的大小为shape (100，100 ),并将它们的颜色改为灰度。</p><p id="51ca" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">要素和标注也将被分离并分别添加到列表X和y中</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="786e" class="mu lt iq mq b gy mv mw l mx my">#create create array of data<br/>data = []<br/>def create_data():<br/>    for category in CATEGORIES:<br/>        path = os.path.join(DATADIR, category)  <br/>        class_num = CATEGORIES.index(category)    <br/>        for img in os.listdir(path):<br/>            try: <br/>                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)<br/>                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))</span><span id="1146" class="mu lt iq mq b gy mz mw l mx my">data.append([new_array, class_num])<br/>            except Exception as e:<br/>                pass<br/>create_data()</span><span id="c227" class="mu lt iq mq b gy mz mw l mx my">#randomly shuffle the images<br/>random.shuffle(data)</span><span id="b60a" class="mu lt iq mq b gy mz mw l mx my">#separate features and labels<br/>X = []<br/>y = []</span><span id="d129" class="mu lt iq mq b gy mz mw l mx my">for features, label in data:<br/>    X.append(features)<br/>    y.append(label)</span><span id="505d" class="mu lt iq mq b gy mz mw l mx my">#neural network takes in a numpy array as the features and labels so convert from list to array and change shape<br/>X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)<br/>y = np.array(y)</span></pre><p id="b259" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">调整后的特征图像示例如下所示</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="f334" class="mu lt iq mq b gy mv mw l mx my">#show first feature image X<br/>first_feature = X[0]<br/>plt.imshow(first_feature, cmap = 'gray')<br/>print('The image shape is {}'.format(first_feature.shape))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/4fd62181353feac6977097f217ff99f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/format:webp/1*xAEwrKR1ao7Wz3ZUdW7Quw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="debf" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，我们归一化图像以确保每个像素具有相似的数据分布(在训练卷积神经网络模型时允许更快的收敛)</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="46b8" class="mu lt iq mq b gy mv mw l mx my">#normalize images<br/>X = X/255.0</span></pre><h1 id="6884" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">建模</h1><p id="25e3" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">这里我们将训练(70%)和测试(30%)数据分开。总共会有17462个训练数据和7484个测试数据。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="2625" class="mu lt iq mq b gy mv mw l mx my">#separate training and test data<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)</span><span id="80ee" class="mu lt iq mq b gy mz mw l mx my">print('the shape of training features is {}'.format(X_train.shape))<br/>print('the shape of training labels is {}'.format(y_train.shape))</span><span id="d46b" class="mu lt iq mq b gy mz mw l mx my">print('the shape of test features is {}'.format(X_test.shape))<br/>print('the shape of test labels is {}'.format(y_test.shape))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/18116b1e34fe8d25ff1473774a9e7acd.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*JeOBXHHQYHCBz_fgq8me0A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="cad2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们现在创建我们的卷积神经网络(CNN)模型。它将由多个卷积层、最大池层和下降层组成。卷积层中的所有激活函数将是relu，而输出密集层的激活函数将是softmax。</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="fdc5" class="mu lt iq mq b gy mv mw l mx my">#create model<br/>model = Sequential()</span><span id="2b46" class="mu lt iq mq b gy mz mw l mx my">model.add(Conv2D(64, (3,3), activation = 'relu'))<br/>model.add(MaxPooling2D(2,2))<br/>model.add(Dropout(0.1))</span><span id="8972" class="mu lt iq mq b gy mz mw l mx my">model.add(Conv2D(64, (3,3), activation = 'relu'))<br/>model.add(MaxPooling2D(2,2))<br/>model.add(Dropout(0.2))</span><span id="45d3" class="mu lt iq mq b gy mz mw l mx my">model.add(Conv2D(64, (3,3), activation = 'relu'))<br/>model.add(MaxPooling2D(2,2))<br/>model.add(Dropout(0.2))</span><span id="fcde" class="mu lt iq mq b gy mz mw l mx my">model.add(Flatten())</span><span id="b818" class="mu lt iq mq b gy mz mw l mx my">model.add(Dense(128, input_shape = X.shape[1:], activation = 'relu'))</span><span id="ef59" class="mu lt iq mq b gy mz mw l mx my">#output layer<br/>model.add(Dense(2, activation = 'softmax'))</span></pre><p id="1206" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用以下参数编译模型:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="cd22" class="mu lt iq mq b gy mv mw l mx my">#compile the model<br/>model.compile(loss="sparse_categorical_crossentropy",<br/>             optimizer="adam",<br/>             metrics=['accuracy'])</span></pre><p id="751e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用5个时期和0.1的验证分割来训练模型</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="dfaf" class="mu lt iq mq b gy mv mw l mx my">#fit model<br/>history = model.fit(X_train, y_train, epochs=5, validation_split=0.1)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/8bd02114d040c5f7a7003730fd8f54d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mqf7Ql1Q8U5uUNZ6MGesfg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">用5个时期训练模型:作者的图像</p></figure><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="6263" class="mu lt iq mq b gy mv mw l mx my">#show learning curves<br/>#mean training loss and accuracy measured over each epoch<br/>#mean validation loss and accuracy measured at the end of each epoch</span><span id="a271" class="mu lt iq mq b gy mz mw l mx my">pd.DataFrame(history.history).plot(figsize=(8,5))<br/>plt.grid(True)<br/>plt.gca().set_ylim(0,1) # set the vertical range to [0-1]<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/cfdae56cae872a62a987d175c267e323.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*a2DJIa76HzUNJtushWfduw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">学习曲线；培训与验证:作者提供的图片</p></figure><p id="ec49" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该模型似乎没有过度拟合训练数据，因为在训练和验证准确性/损失之间没有相当大的差距。验证精度略高于使用脱落图层时可能出现的训练精度。</p><p id="e217" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们预测测试数据的类别，并比较我们的准确度</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="e2e0" class="mu lt iq mq b gy mv mw l mx my">#use predict_classes() to find the class with the highest probability<br/>y_pred = model.predict_classes(X_test)</span><span id="41a9" class="mu lt iq mq b gy mz mw l mx my">print("Performance Summary of Sequential Neural Network on test data:")</span><span id="256b" class="mu lt iq mq b gy mz mw l mx my">#show classification report<br/>print(metrics.classification_report(y_test, y_pred))</span><span id="6abd" class="mu lt iq mq b gy mz mw l mx my">#show confusion matrix<br/>print(metrics.confusion_matrix(y_test, y_pred))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/e4959ae1dc11d4d662b731717087650a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*DTc3l1Y4QWXo9-ADf7z1ig.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">分类报告和混淆矩阵:作者图片</p></figure><p id="d32f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">虽然不令人惊讶，但在测试数据的83%的总体准确率下，这是一个相当不错的模型</p><p id="8eb3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以快速浏览前5个正确和不正确的分类</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="dc90" class="mu lt iq mq b gy mv mw l mx my">#show first 5 correctly identified test images with predicted labels and probabilities<br/>fig, ax = plt.subplots(1,5,figsize=(20,20))</span><span id="d1ac" class="mu lt iq mq b gy mz mw l mx my">class_names = ["Dog", "Cat"]</span><span id="4208" class="mu lt iq mq b gy mz mw l mx my">for i, correct_idx in enumerate(correct_indices[:5]):<br/>    ax[i].imshow(X_test[correct_idx].reshape(100,100),cmap='gray')<br/>    ax[i].set_title("{} with probabililty of {}%".format(class_names[y_pred[correct_idx]], int(max(y_proba[correct_idx]</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/ae3c6d675ccf5076d4c37435f7cafa0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pYhGcCgVkEPpQe770ae_EA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">前5张正确识别的图片:作者图片</p></figure><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="7361" class="mu lt iq mq b gy mv mw l mx my">#show first 5 incorrectly identified test images with predicted labels and probabilities<br/>fig, ax = plt.subplots(1,5,figsize=(20,20))</span><span id="57f3" class="mu lt iq mq b gy mz mw l mx my">for i, incorrect_idx in enumerate(incorrect_indices[:5]):<br/>    ax[i].imshow(X_test[incorrect_idx].reshape(100,100),cmap='gray')<br/>    ax[i].set_title("{} with probabililty of {}%".format(class_names[y_pred[incorrect_idx]], int(max(y_proba[incorrect_idx])*100)))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/76ef26c26b3105b6aebfb4b34f4f2f02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vcgJISEVasYrQTXGoWxKwg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">前5张识别错误的图片:作者图片</p></figure><p id="7235" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有趣的是，该模型已经正确识别了一些甚至人类都难以看到的图像。但是，它也错误地识别了一些明显的猫和狗的图片。</p><h1 id="cd6b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">使用Gradio的模型演示</h1><p id="85b4" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">最后，我们准备使用Gradio来创建我们模型的演示。同样，目的是使用该模型在新上传的输入图像上预测猫或狗类别</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="1001" class="mu lt iq mq b gy mv mw l mx my">#create a function to make predictions<br/>#return a dictionary of labels and probabilities<br/>def cat_or_dog(img):<br/>    img = img.reshape(1, 100, 100, 1)<br/>    prediction = model.predict(img).tolist()[0]<br/>    class_names = ["Dog", "Cat"]<br/>    return {class_names[i]: prediction[i] for i in range(2)}</span><span id="f75f" class="mu lt iq mq b gy mz mw l mx my">#set the user uploaded image as the input array<br/>#match same shape as the input shape in the model<br/>im = gradio.inputs.Image(shape=(100, 100), image_mode='L', invert_colors=False, source="upload")</span><span id="f8e4" class="mu lt iq mq b gy mz mw l mx my">#setup the interface<br/>iface = gr.Interface(<br/>    fn = cat_or_dog, <br/>    inputs = im, <br/>    outputs = gradio.outputs.Label(),<br/>)</span><span id="459c" class="mu lt iq mq b gy mz mw l mx my">iface.launch(share=True)</span></pre><p id="7a95" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这段代码中发生了以下情况:</p><ol class=""><li id="6b76" class="ni nj iq kx b ky kz lb lc le nk li nl lm nm lq nn no np nq bi translated">我们首先创建一个名为cat_or_dog()的函数，它将一个图像数组作为输入，利用模型进行预测，并返回一个字典，其中每个类名作为键，其各自的概率作为值(例如{Dog: 0.6，Cat: 0.4})</li><li id="1995" class="ni nj iq kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">设置输入上传:转换输入图像以匹配模型被训练的输入形状，在我们的例子中是(100，100)。我们还将源设置为“上传”，这样我们就可以将自己的图像上传到Gradio中</li><li id="c22f" class="ni nj iq kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">编译接口；利用我们在上面创建的cat_or_dog()函数，将input设置为输入上传器，并允许Gradio返回类及其概率作为输出</li></ol><p id="0b75" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">结果显示在下面的gif中:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/3b1191282865754dd8cd8f82ad66169a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/1*-454eOc1-Cjac7JQ79Jd_Q.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Gradio图像分类演示:按作者分类的图像</p></figure><p id="63d4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">用户可以轻松地从本地拖放或上传图像，并单击“提交”以显示模型分类的输出。概率较高的类别(猫或狗)将显示为最终预测。</p><h1 id="5cc5" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="899b" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">在本练习中，使用CNN构建了一个影像分类模型，并使用一个名为GradioML的工具将其部署为一个简单的演示。然而，Gradio可以用于更多的任务，如回归/数值预测和自然语言处理。Gradio具有适合这些任务的各种界面选项，是一种可以作为呈现快速机器学习演示的快速高效解决方案的工具。</p></div></div>    
</body>
</html>