<html>
<head>
<title>Implementing Transfer Learning from RGB to Multi-channel Imagery</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实现从RGB到多通道图像的迁移学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-transfer-learning-from-rgb-to-multi-channel-imagery-f87924679166?source=collection_archive---------10-----------------------#2021-03-23">https://towardsdatascience.com/implementing-transfer-learning-from-rgb-to-multi-channel-imagery-f87924679166?source=collection_archive---------10-----------------------#2021-03-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3eb3" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用ResNet50主干+金字塔池的语义分割</h2></div><h1 id="f1e7" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">介绍</h1><p id="2bf9" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">最近，我有幸有机会与<a class="ae lt" href="https://omdena.com/" rel="noopener ugc nofollow" target="_blank"> Omdena </a>和<a class="ae lt" href="https://weedbot.eu/" rel="noopener ugc nofollow" target="_blank"> WeedBot </a>合作参加了一个计算机视觉挑战赛，这是一个受影响驱动的初创公司，开发了一种激光除草机械，让农民可以用激光束找到并清除杂草。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi lu"><img src="../Images/fe54b1424b3ee328dfd0457ce1dce7d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*erz7j5nQ6yeo9QBd8x2_lg.jpeg"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">照片由<a class="ae lt" href="https://unsplash.com/@gunnarridder?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">贡纳尔·里德斯特伦</a>在<a class="ae lt" href="/s/photos/computer-library?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="c29f" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">我们探索了作物与杂草分类的图像分割技术，并探索了语义和实例分割方法。在本文中，我们将探索在项目的语义分割部分中实现的两个不同的概念——</p><h1 id="2ff8" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated"><strong class="ak">多通道输入的迁移学习</strong></h1><h2 id="f7b2" class="mp kg iq bd kh mq mr dn kl ms mt dp kp lg mu mv kr lk mw mx kt lo my mz kv na bi translated">什么是迁移学习？</h2><blockquote class="nb"><p id="7d70" class="nc nd iq bd ne nf ng nh ni nj nk ls dk translated">迁移学习是一种机器学习技术，用于在新问题上重用预先训练好的模型。</p></blockquote><p id="8be7" class="pw-post-body-paragraph kx ky iq kz b la nl jr lc ld nm ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">在迁移学习中，机器利用从不同任务中获得的知识，通过为新的但相关的任务从新样本中提取有用的特征来提高泛化能力。</p><p id="7bf7" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">例如，在训练一个分类器来预测狗的品种时，人们可以使用在训练中获得的知识来区分一般的动物。</p><h2 id="e438" class="mp kg iq bd kh mq mr dn kl ms mt dp kp lg mu mv kr lk mw mx kt lo my mz kv na bi translated">优势</h2><p id="0983" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">使用迁移学习有很多好处。好处是它节省时间，提供更好的性能，并且需要更少的数据。</p><p id="fe72" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">自然语言处理和计算机视觉问题的深度学习模型通常需要大量数据供模型学习。这可能既耗时又昂贵，并且可能是个人和小组织采用机器学习的巨大障碍。</p><p id="c997" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">迁移学习减少了这一障碍，它允许一个人采用一个已经训练好的模型，并将其应用于一个不同但相关的问题。因为模型是预先训练的，这意味着我们不是完全从零开始训练，而是利用模型已经学到的东西。</p><p id="8ea5" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">为挑战提供的是分辨率为3008x3008的775幅图像。鉴于图片数量较少，迁移学习似乎是一个很好的探索途径。</p><p id="dae1" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">公开可用的是在公开可用的数据集上训练的开源模型，例如ResNet、AlexNet、VGG等等。两个这样的常见数据集是<a class="ae lt" href="http://image-net.org/about" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>和<a class="ae lt" href="https://cocodataset.org/" rel="noopener ugc nofollow" target="_blank"> Coco </a>数据集。这些数据集分别由超过14M和330K的图像组成。</p><h2 id="4051" class="mp kg iq bd kh mq mr dn kl ms mt dp kp lg mu mv kr lk mw mx kt lo my mz kv na bi translated">从RGB到多通道</h2><p id="e0cd" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们的研究提出了三种方法，可以用来将3个通道上训练的模型转换为更多的通道。这些方法跨越不同的复杂程度。我们将简要讨论这些方法—</p><ul class=""><li id="bd0b" class="nq nr iq kz b la mk ld ml lg ns lk nt lo nu ls nv nw nx ny bi translated">一种方法是简单地扩展权重维度以考虑额外的通道数量，并随机初始化这些值。</li><li id="b4e0" class="nq nr iq kz b la nz ld oa lg ob lk oc lo od ls nv nw nx ny bi translated">第二种方法与第一种类似，只是我们不是用随机初始化的值来填充这些值，而是用其他值的平均值来填充。我们在一篇科学论文中发现了这种方法，该论文描述这种方法比第一种方法更有效。这是我们将在本文中探索的方法。</li><li id="538e" class="nq nr iq kz b la nz ld oa lg ob lk oc lo od ls nv nw nx ny bi translated">理论上，最终方法应该提供最佳性能。然而，就训练时间而言，这种方法需要更长的时间。这种方法表明，前面讨论的方法会偏向于前三个通道，因为这是预训练模型最初训练的内容。相反，这种方法提出的是，我们创建第二个并行网络，对剩余的通道执行特征提取，然后将输出与原始预训练模型的输出连接起来。以这种方式，第二模型学习特定于附加通道的表示，并且我们仍然利用按原样使用预先训练的模型。这种方法将在另一篇文章中探讨。</li></ul><h2 id="f0ff" class="mp kg iq bd kh mq mr dn kl ms mt dp kp lg mu mv kr lk mw mx kt lo my mz kv na bi translated">ResNet50主干和15通道图像</h2><p id="b856" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">为此问题选择的主干模型是ResNet50。ResNet50是“残差网络”的缩写，是一个50层深度卷积神经网络，利用残差学习。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi oe"><img src="../Images/6b0a00d9ea403ebc68de28d833fbeb7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bFKsSm7FUG3oMKN1"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">resnet50架构</p></figure><p id="35be" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">值得一提的是，使用预训练模型的一个特征是，模型期望新任务的输入维度与其预训练的旧任务的输入维度相同。</p><p id="6963" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">resnet50模型在高度和宽度为224x224的输入维度上进行预训练，RGB有3个通道。</p><p id="aab1" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">对于这个分割任务，我们使用了许多特征生成技术，在原始的3通道RGB图像上增加了额外的12通道。有关如何生成额外通道的更多信息，请参阅本文。</p><p id="4efc" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">当时的挑战是获得预训练的resnet50模型，以480x400的新图像尺寸作为输入，第三维具有15个通道。</p><p id="9bb7" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">我们将做一个代码演练，看看这是如何实现的。首先，我们使用Keras下载并导入resnet50模型—</p><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="513d" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">在这里，我们指定希望下载imagenet的预训练权重。通常，在迁移学习中，我们会排除最后一层，用对新任务更具体的层来代替它。设置“include_top=False”允许我们排除最后一层。如果我们用预先训练好的模型进行推理，而不是实现迁移学习，那么这个应该设置为真。</p><p id="ae81" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">此时，我们需要将分辨率(高度和宽度)从224x224更改为480x400，并将通道数量从3更改为15。因为更改输入的高度和宽度不会影响权重的尺寸，所以更改起来更简单。</p><p id="543d" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">另一方面，改变输入通道的数量确实会影响权重的维数。让我们更详细地研究一下这个问题。</p><p id="1244" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">出于比较目的，我们将使用修改后的uNet架构，我们可以通过首先改变高度-宽度，然后改变通道数量，来比较224x224x3输入和480x400x15输入的模型概要。</p><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="lv lw lx ly gt oh oi oj ok aw ol bi"><span id="5c2b" class="mp kg iq oi b gy om on l oo op">semantic_segmentation(224, 224, 3).summary()</span></pre><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi oq"><img src="../Images/e9d5794f917cff6868fc496e5f31e79d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GNbNdOsPDbXqNen0HY-UQg.png"/></div></div></figure><pre class="lv lw lx ly gt oh oi oj ok aw ol bi"><span id="1159" class="mp kg iq oi b gy om on l oo op">semantic_segmentation(400, 480, 3).summary()</span></pre><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi or"><img src="../Images/7fe0019102398ffd688034ea7de95ce6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UEVGfFqny0Txo6e97lqXLg.png"/></div></div></figure><p id="eedc" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">我们注意到参数的总数保持不变。这证实了输入的高度和宽度不会影响重量尺寸。现在，让我们来看看改变频道的数量—</p><pre class="lv lw lx ly gt oh oi oj ok aw ol bi"><span id="bc75" class="mp kg iq oi b gy om on l oo op">semantic_segmentation(400, 480, 15).summary()</span></pre><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi os"><img src="../Images/39e189173f38d456cdfcdd68205fc6e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a1rUk6IBBqUqxSVmQJo6cA.png"/></div></div></figure><p id="7ec4" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">我们注意到参数的数量从18，515增加到20，243。我们还注意到，这仅仅是因为第一卷积层的参数从448增加到2176，而后续层的参数数量保持不变。</p><p id="f72f" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">无需在Keras中进行尝试，通过回忆卷积层的权重维度由滤波器的高度和宽度、输入深度和输出深度决定，就可以从理论上确认这一点。图像的高度和宽度与此无关。</p><p id="c9af" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">更改输入维度的第一步涉及复制模型的配置信息。这为我们提供了字典格式的模型组成。我们可以通过更改输入维度来编辑这个字典，并使用编辑过的配置字典创建一个新模型—</p><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="be5e" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">我们现在已经创建了一个与ResNet50具有相同网络结构的新模型。值得注意的是，这不会自动复制resnet50模型的重量，这是这样做的主要目的。</p><p id="5137" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">为此，我们需要遍历resnet50模型和新创建的模型的层，并复制权重。</p><p id="cd9c" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">然而，我们会遇到一个问题，因为尺寸不匹配。我们之前证实了改变通道的数量会影响权重的维度。为了解决这个问题，我们扩展了权重维度，以更准确地表示通道的增加，并复制权重的平均值。这是按如下方式完成的—</p><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="b45e" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">这负责语义分割模型的ResNet50主干。</p><h1 id="54bc" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">金字塔池模块</h1><p id="91a7" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在另一篇<a class="ae lt" href="https://medium.com/omdena/deep-learning-pipeline-for-image-segmentation-laser-weed-removal-3a7b21aebcba" rel="noopener">文章</a>中，我讨论了在探索语义分割时，我们分成多个团队来探索不同的分割模型。在探索PSPNet的时候，我们注意到虽然这个模型不完全准确，但是它产生了平滑的分段。</p><p id="d425" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">我们推测这可能是模型利用金字塔池模块的结果。为了最终的模型。我们决定将它与resnet50一起用作主干。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/0c4e9d8ae7982eb37c16bf905907fa16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/0*SjQESsMuzHGkJnp5"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">金字塔池模块</p></figure><p id="bd26" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">金字塔池通过观察整个要素地图以及不同位置的子区域来工作。池内核覆盖图像的全部、一半、1/4和1/8，并被融合为全局先验。然后，这与来自主干的原始特征图相结合。</p><h2 id="1c56" class="mp kg iq bd kh mq mr dn kl ms mt dp kp lg mu mv kr lk mw mx kt lo my mz kv na bi translated">跟随这个<a class="ae lt" href="https://colab.research.google.com/drive/1n5an_9zvWSirvx9KLTx06WXvFIZodxDA?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab笔记本</a>。</h2><h1 id="fd9f" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">参考</h1><p id="b0e3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">林T，梅尔M，贝隆吉S，布尔德夫L，吉尔希克R，海斯J，佩罗娜P，拉玛南D，兹尼克L，多尔P 2014微软可可:背景中的共同对象【https://arxiv.org/abs/1405.0312<a class="ae lt" href="https://arxiv.org/abs/1405.0312" rel="noopener ugc nofollow" target="_blank"/></p><p id="dae7" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated"><a class="ae lt" href="https://ieeexplore.ieee.org/author/38307037500" rel="noopener ugc nofollow" target="_blank">甲等</a>；<a class="ae lt" href="https://ieeexplore.ieee.org/author/38277671200" rel="noopener ugc nofollow" target="_blank">魏东</a>；<a class="ae lt" href="https://ieeexplore.ieee.org/author/37547163200" rel="noopener ugc nofollow" target="_blank">理查德·索彻</a>；<a class="ae lt" href="https://ieeexplore.ieee.org/author/38273260200" rel="noopener ugc nofollow" target="_blank">李——</a>；<a class="ae lt" href="https://ieeexplore.ieee.org/author/37277619300" rel="noopener ugc nofollow" target="_blank">李凯</a>；https://ieeexplore.ieee.org/document/5206848<a class="ae lt" href="https://ieeexplore.ieee.org/document/5206848" rel="noopener ugc nofollow" target="_blank">李菲菲</a> 2009 ImageNet:一个大规模分层图像数据库</p><p id="1d3e" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">Donges N 2019什么是迁移学习？探索流行的深度学习方法<a class="ae lt" href="https://builtin.com/data-science/transfer-learning" rel="noopener ugc nofollow" target="_blank">https://builtin.com/data-science/transfer-learning</a></p><p id="0f1e" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">何K，张X，任S，孙J 2015用于图像识别的深度残差学习<a class="ae lt" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1512.03385.pdf</a></p><p id="3a56" class="pw-post-body-paragraph kx ky iq kz b la mk jr lc ld ml ju lf lg mm li lj lk mn lm ln lo mo lq lr ls ij bi translated">赵等人2016传销资金池模块<a class="ae lt" href="https://arxiv.org/abs/1612.01105v2" rel="noopener ugc nofollow" target="_blank">、</a></p></div></div>    
</body>
</html>