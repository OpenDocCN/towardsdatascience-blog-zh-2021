<html>
<head>
<title>Customize Airflow Container with Hadoop Based Components</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用基于Hadoop的组件定制气流容器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/customize-airflow-container-with-hadoop-based-components-127e89763c21?source=collection_archive---------29-----------------------#2021-05-04">https://towardsdatascience.com/customize-airflow-container-with-hadoop-based-components-127e89763c21?source=collection_archive---------29-----------------------#2021-05-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0600" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在为您的用例构建或修改docker映像时，您需要知道什么</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2e3944647dd55cb9868a9df21e0e13a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*S2hTiSKzCqWP-rhs"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@drewjohncollins?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">德鲁·科林斯</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><h1 id="dabc" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="7bdd" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">最近，我一直致力于建立一个数据管道，将数据从关系数据库管理系统(RDBMS)传输到Hadoop生态系统(HDFS)。在有限的时间资源下，我必须在七天内从头开始完成数据管道。此外，我得到的建议是，它应该在三天内完成整个事情。</p><p id="0662" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">当时，我对Hadoop生态系统配置和docker几乎一无所知。我知道什么是分布式系统的概念，但是我自己配置它几乎是不可能的。更容易被之前没有经历过的事情吓到。我想这是很正常的事情。</p><h2 id="d32c" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">要求</h2><p id="241c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我深吸了一口气，通读了他们给出的所有业务和技术要求，这些都是对数据管道的要求。</p><ul class=""><li id="15c3" class="ne nf it lt b lu mn lx mo ma ng me nh mi ni mm nj nk nl nm bi translated">使用广泛的数据框架(如Apache Spark、Apache Sqoop或其他大数据框架)构建数据管道。</li><li id="1f9d" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">用Apache气流编排数据管道。</li><li id="eb31" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">为附加的特别查询传递所有业务需求。</li><li id="f4f0" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">使其易于使用Docker或Kubernetes进行部署。</li></ul><h2 id="9fd1" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">我有多少知识</h2><p id="7e94" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">总之下面是我接这个项目之前的经历。</p><ul class=""><li id="7cd7" class="ne nf it lt b lu mn lx mo ma ng me nh mi ni mm nj nk nl nm bi translated">听说过dockerization这个概念，但从来没用过。幸运的是，<a class="ae ky" href="https://docs.docker.com/get-started/" rel="noopener ugc nofollow" target="_blank">的docker教程</a>相当精湛。半天之内很容易就能跟上并适应这个项目。</li><li id="4085" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">对于编排部分，幸运的是，我刚刚从Udacity 获得了<a class="ae ky" href="https://www.udacity.com/course/data-engineer-nanodegree--nd027?utm_source=gsem_brand&amp;utm_medium=ads_r&amp;utm_campaign=8305564469_c&amp;utm_term=84142984263&amp;utm_keyword=data%20engineering%20nanodegree_e&amp;gclid=Cj0KCQjwvr6EBhDOARIsAPpqUPGoCNmgqGdrI3SfFCl9KymbPmE3Qyur0NMN2hoGfAZ5fmsBl3ITm4kaAjZxEALw_wcB" rel="noopener ugc nofollow" target="_blank">数据工程Nanodegree，所以我熟悉气流以及如何作为初学者使用它。如果你对这门课程感兴趣，可以在我的GitHub </a>上查看<a class="ae ky" href="https://github.com/Pathairush/data_engineering" rel="noopener ugc nofollow" target="_blank">项目内容和我的评论。</a></li><li id="f5f6" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm nj nk nl nm bi translated">关于Apache Spark，我对pyspark比较熟悉，之前在我的数据分析项目中使用过。对于其他像Sqoop和Hive这样的组件，我要做在职学习，达到他们的技术要求。</li></ul><p id="00ca" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在项目开始时，我乐观地认为我可以在规定的时间内完成这件事，但现实生活并不像我想象的那么容易。</p><h1 id="db7f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">你将面临的问题</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/c07aedd1b98059a82c85eeeecf0a84d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*o1KD9drxfwowtECe"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@officestock?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">塞巴斯蒂安·赫尔曼</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="8581" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">发展环境</h2><p id="f535" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">当我在Udacity参加课程时，他们为我配置了所有的开发环境。我可以直接把代码写到提供的IDE上，专心使用Spark或者Airflow之类的工具。</p><p id="a907" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">不幸的是，对于这个项目，我必须自己复制那些环境。首先，我尝试在我的计算机的虚拟环境中安装每个组件。但是我认为不可能将这个项目转移到具有这些复杂依赖关系的另一个实例中。</p><p id="2406" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">那是码头工人来救我的地方。我们可以用docker构建和封装所有的依赖关系和配置，并轻松地将其转移到另一个实例中。</p><p id="b2ee" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">构建开发环境可以像输入<code class="fe nu nv nw nx b">docker compose up -d</code>命令一样简单。配置被放在一个单独的<code class="fe nu nv nw nx b">yaml</code>文件中，以便在开发环境中轻松地添加、修改或删除组件。</p><h2 id="e953" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">然而，困难的部分是连接docker内部的所有东西</h2><p id="e1cd" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">当我提到技术需求时，数据管道应该由Spark、Sqoop或其他框架等大数据框架组成。</p><p id="453c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这意味着您必须在同一个docker环境中拥有airflow、spark集群、hive集群和sqoop集群，并通过docker网络将它们连接起来。</p><p id="0990" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">Airflow为您提供了很大的灵活性，可以与提供商的运营商协调spark、hive或sqoop工作。<strong class="lt iu"> <em class="nt">但是您必须先在airflow docker中安装所有这些组件才能激活此功能。</em>T13】</strong></p><p id="bb03" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然而，当我转移这个项目时，我对修改docker容器和配置Hadoop组件的了解有限。我通过艰难地将工作从气流容器提交给其他组件来解决这个问题。</p><h2 id="46a8" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">简单介绍一下我当时的选择</h2><p id="be14" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这里有三种方法将作业从气流提交到另一个容器</p><ol class=""><li id="7c37" class="ne nf it lt b lu mn lx mo ma ng me nh mi ni mm ny nk nl nm bi translated">在Apache airflow中与<a class="ae ky" href="https://airflow.apache.org/docs/apache-airflow-providers/index.html" rel="noopener ugc nofollow" target="_blank">提供商的运营商</a>一起提交。这是配置airflow DAGs并将任务提交给另一个实例的最推荐方式。</li><li id="dc43" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm ny nk nl nm bi translated">用<code class="fe nu nv nw nx b">SSHOperator</code>提交。这意味着您将airflow to SSH告知另一个实例，并从本地环境运行该命令。对于这种方法，目标实例或集群应该安装SSH组件来访问另一个位置。</li><li id="0ecb" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm ny nk nl nm bi translated">用<code class="fe nu nv nw nx b">BASHOperator</code>提交。我转移项目时就是这么做的。要创建您的airflow实例，可以访问<code class="fe nu nv nw nx b">docker exec</code>命令，从本地airflow环境提交作业到另一个实例，不需要SSH。</li></ol><p id="64c8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在我看来，当时我会选择第一选择和第二选择。</p><blockquote class="nz oa ob"><p id="899c" class="lr ls nt lt b lu mn ju lw lx mo jx lz oc mp mc md od mq mg mh oe mr mk ml mm im bi translated">不幸的是，我从docker hub中提取的docker映像没有安装我想要构建数据管道的所有东西，我无法在7天内将所有东西分类。</p></blockquote><p id="a1da" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">所以我只能选择第三种。这是我心中的一个结，当我有时间的时候，我会重新讨论这个问题，并使它按照我的预期工作。</p><h2 id="09bd" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">这就是为什么我一直写到现在。</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/0a21ec2a707c79003f7c0a4f5edfd7ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yNyTG1vEgLeJ4oYk"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">保罗·埃施-洛朗在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="654e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">今天，在我花了一些时间学习和重新学习docker配置之后。我来这里是为了给你们提供一个定制docker容器的实现来达到你们的目的。在我的例子中，要创建一个基于气流的组件，docker可以将任务提交给另一个Hadoop组件。</p><blockquote class="nz oa ob"><p id="5503" class="lr ls nt lt b lu mn ju lw lx mo jx lz oc mp mc md od mq mg mh oe mr mk ml mm im bi translated">你可以在我的GitHub 上找到所有的源代码<a class="ae ky" href="https://github.com/Pathairush/airflow-hive-spark-sqoop" rel="noopener ugc nofollow" target="_blank">。</a></p></blockquote><p id="5b50" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于实现，本博客不会一行一行地介绍代码，但<strong class="lt iu"> <em class="nt">会重点介绍您应该关注的基本部分，以及配置这些内容以使其适用于您的用例</em> </strong>的附加材料。我会告诉你将来可能会面临的问题，并处理它，而不是马上解决它。</p><h1 id="a519" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">让我们从基于Hadoop的组件开始。</h1><p id="a979" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这里我们将安装以下组件<a class="ae ky" href="https://hadoop.apache.org/" rel="noopener ugc nofollow" target="_blank"> Hadoop </a>、<a class="ae ky" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>、<a class="ae ky" href="https://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html" rel="noopener ugc nofollow" target="_blank"> Apache Sqoop </a>和<a class="ae ky" href="https://hive.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Hive。</a></p><p id="dcee" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">你可以在上面提到的Github的一个<code class="fe nu nv nw nx b">/docker/hadoop</code>文件夹中找到安装部分的源代码。</p><p id="45ef" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">要构建任何docker映像，您需要一个<code class="fe nu nv nw nx b">dockerfile</code>库来配置安装在docker中的所有必要的东西。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="og oh l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Hadoop docker文件示例。作者要点。</p></figure><p id="af58" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">通常，docker文件将以<code class="fe nu nv nw nx b">FROM</code>语句开始。这个模式是你应该彻底理解的第一部分。</p><h2 id="2a4c" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">这一部分最重要的是</h2><p id="5577" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">有一个<a class="ae ky" href="https://hub.docker.com/" rel="noopener ugc nofollow" target="_blank"> docker hub </a>，在那里你可以找到很多来自可靠来源的有用的构建图像。为了利用创建的图像的力量，你可以把它放在<code class="fe nu nv nw nx b">FROM</code>语句中，作为你的docker图像的基础。这里我使用<code class="fe nu nv nw nx b">python:3.6-stretch</code>图像作为构建我的自定义图像的基础。</p><p id="0ded" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你查看docker hub中的python库，你会发现docker hub内部有很多<code class="fe nu nv nw nx b">tags</code>。每个标签指的是构建映像的版本。</p><p id="0567" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">例如，这里的单词<code class="fe nu nv nw nx b">stretch</code>意味着这个映像的底层OS版本是Debian 9。如果你浏览到docker hub，看到一个类似<code class="fe nu nv nw nx b">buster</code>的标签，这意味着这个映像是从Debian 10构建的。</p><blockquote class="nz oa ob"><p id="7f06" class="lr ls nt lt b lu mn ju lw lx mo jx lz oc mp mc md od mq mg mh oe mr mk ml mm im bi translated"><strong class="lt iu">了解每个标签的不同细节是这里的重点。</strong></p></blockquote><p id="f966" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因为无论您稍后安装什么，都将取决于您之前构建的基础映像。我选择<code class="fe nu nv nw nx b">python:3.6-stretch</code>的原因是它与我们需要安装的<code class="fe nu nv nw nx b">JAVA8</code>兼容，这样我们就可以使用Hadoop组件。</p><p id="2171" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">开始用的时候只选择最新的，不知道后面会有很多依赖问题。这是我犯的一个巨大的错误。</p><p id="6cec" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于docker文件的其他部分，都是关于运行<code class="fe nu nv nw nx b">bash</code>命令来安装东西。例如，您可以使用<code class="fe nu nv nw nx b">RUN</code>命令顺序安装Hadoop组件。您可以使用<code class="fe nu nv nw nx b">ENV</code>命令设置docker中使用的环境变量。还会有其他有用的命令，比如<code class="fe nu nv nw nx b">ADD</code>和<code class="fe nu nv nw nx b">COPY</code>。您可以参考本文件了解更多详情。</p><h2 id="3f66" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">开始前</h2><p id="d10b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了节省您的时间，我建议您在构建任何映像之前研究每个组件的兼容性。例如，您应该知道哪个Hive版本与Hadoop 3.2.1版本兼容。在制作映像之前列出所有的依赖项将为您节省大量时间。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/21d92aedc5d96d8d06de94b9ba93434c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g1ElmJG4ltO6rmpHZDsEHg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">范例配置单元要求:作者截图。</p></figure><h2 id="66cb" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">有用的资源</h2><p id="d037" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对于安装指南，我认为有两个资源非常重要</p><ol class=""><li id="6202" class="ne nf it lt b lu mn lx mo ma ng me nh mi ni mm ny nk nl nm bi translated">第一个资源是每个组件的官方网站。官方文档将告诉您如何完整地构建每个部分，但它没有涵盖您在安装过程中可能面临的所有边缘情况。</li><li id="0f1b" class="ne nf it lt b lu nn lx no ma np me nq mi nr mm ny nk nl nm bi translated">第二个源是GitHub源，用于构建与您的用例相似的映像。这是一种更简单的方法，从经过良好测试的代码中寻找，并根据您的工作调整它们构建图像的方式。例如，当我安装Hadoop组件时，我会参考来自<a class="ae ky" href="https://github.com/pavank/docker-bigdata-cluster" rel="noopener ugc nofollow" target="_blank"> pavank的GitHub </a>和<a class="ae ky" href="https://github.com/cordon-thiago/airflow-spark" rel="noopener ugc nofollow" target="_blank"> cordon-thiago的GitHub </a>的模式。感谢您的巨大贡献。</li></ol><h2 id="586a" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">分步解决</h2><p id="ffb9" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">您可以尝试一个接一个地构建组件，然后在最后将它们合并到一个docker文件中。该过程将帮助您确保您的问题仅出在集成部分，而不是安装部分。</p><p id="5b0c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这部分会花很多时间来来回回把所有的问题整理出来。一旦你成功建立了docker形象，不要太早庆祝。您将需要测试docker镜像中的命令行是否如您所期望的那样工作。</p><h2 id="0838" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">要记住的事情</h2><p id="ef9d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">请记住，我们稍后将使用这个基于图像来构建一个气流容器。此外，我需要你知道，使气流容器使用Hadoop组件不同于配置Hadoop集群。</p><p id="4150" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">假设您想要创建一个spark集群或hive集群来处理数据。将有一个额外的配置要做。例如，如果您想创建一个spark集群，您需要提供至少三个容器:一个spark主容器和两个spark工作容器。dockerfile配置将不同于我们在这里为气流容器安装的配置。</p><p id="a07a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">维奥拉。现在，我们已经在docker映像中安装了所有的Hadoop组件。我们可以在以后安装气流组件时参考它。干得好，伙计们。</p><h1 id="678a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">让我们安装气流。</h1><p id="a6f0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">docker的好处是，你可以基于另一个图像构建一个图像。这种能力使得基于图像可以被重用用于许多不同的目的。</p><p id="4613" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们将使用最近构建的基于Hadoop的容器来安装额外的气流组件。</p><blockquote class="nz oa ob"><p id="7918" class="lr ls nt lt b lu mn ju lw lx mo jx lz oc mp mc md od mq mg mh oe mr mk ml mm im bi translated">这听起来很无聊，但基本概念是一样的。</p></blockquote><p id="4897" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">你可以在上面提到的Github的一个<code class="fe nu nv nw nx b">/docker/airflow</code>文件夹中找到安装部分的源代码。</p><p id="5d98" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在这里，我遵循从<a class="ae ky" href="https://github.com/puckel/docker-airflow" rel="noopener ugc nofollow" target="_blank">帕克尔的气流docker </a>安装气流的模式。这是一个气流容器，从docker hub拉起超过1000万次。拉取请求的数量似乎是构建气流图像的可靠来源。</p><h2 id="8c76" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">理解底层的依赖关系是你所需要的</h2><p id="783f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如果你还记得这一点，我之前提到过我们构建的底层图像。你会发现puckel的原始docker图像是从<code class="fe nu nv nw nx b">python:3.7-slim-buster</code>开始构建的，但我们将其改为<code class="fe nu nv nw nx b">python:3.6-stretch</code>。</p><p id="56be" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这是我们修改气流运行的底层操作系统的地方。</p><p id="e76f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">有了这个小变化，我要说当时很多麻烦都找上我了。问题可能来自任何来源。<code class="fe nu nv nw nx b">apt-get</code>、<code class="fe nu nv nw nx b">pip</code>或者<code class="fe nu nv nw nx b">airflow</code>本身。</p><p id="30c3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">简而言之，我花了整整两天的时间来解决所有的依赖问题。它花费的时间比我想象的要多得多，我敢打赌，对任何人来说，这都是一个非常烦人的过程。</p><h2 id="128d" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">反复试验</h2><p id="e225" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">一些问题可以通过更多的<code class="fe nu nv nw nx b">apt-get</code>或<code class="fe nu nv nw nx b">pip</code>安装来解决，但是对于一些问题，您可能需要重新考虑您构建的底层映像是否需要改变。这里没有快速的胜利。</p><p id="6161" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">即使我可以构建docker映像，有时，airflow webserver也无法在容器内运行，并永远在重启循环中继续。</p><p id="67c4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">大量的谷歌搜索和StackOverflow是现在唯一能救你的东西。我花很多时间一个一个解决问题。</p><p id="fddc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我完全理解为什么很多更新的工具不会在技术发布的第一天到来。气流版本的微小变化可能会无缘无故地毁掉一切。</p><p id="4fa2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最终，努力是有回报的。我们得到了一个包含基于Hadoop的组件的气流容器。要跳过所有这些过程，您可以从我的docker hub中提取图像。但是我鼓励你从头开始构建这个图像。</p><h2 id="b48b" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">至少你学到了一些新东西。</h2><p id="cb18" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">它可以帮助你学习很多重要的东西，并让你有能力在未来解决问题，而不是等待别人为你更新图像。</p><p id="7d31" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">你将有权添加或删除你想要的东西，使你的docker图像更容易操作和维护。</p><h2 id="7381" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">下一步是什么</h2><p id="f09b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">下一个任务是将构建的映像插入到数据管道项目中。不幸的是，数据管道仍在审查过程中，我认为它仍然不能与大家分享。</p><p id="9287" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">所以，我们稍微等一下，我会写一下把这个docker镜像拿来做一个数据管道的过程。</p><h1 id="efbc" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">最终想法</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/cacc45d9d25449bf196d8c40d2b551db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*f2UmrwXNf3zPh3qu"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">路易斯·汉瑟在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="c9ee" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我承认，当你设计一个新项目的原型时，docker让你的生活变得更加容易。但是当你必须生产它的时候。会有很多你必须知道的检查清单。依赖问题是其中最主要的问题。</p><p id="a791" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">docker的另一个好处是，你把一切都写成代码；因此，您可以为新的底层计算机架构快速构建docker映像，并使用Git命令更改配置和保存每个版本。</p><p id="cb2a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我鼓励每个人都使用docker，而不是在虚拟环境中安装许多东西，并产生一个可重复的问题。</p><p id="d468" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">要将环境或数据管道从一个实例迁移到另一个实例，或者使其可再现，需要许多技术和最佳实践来使其尽可能平稳。这个领域有很多东西要学。</p><p id="dfb9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在我看来，当你是一名数据科学家或数据分析师时，拥有这些技能是非常令人印象深刻的。我们通常会忽略这些东西，更多地关注我们的Jupyter笔记本。这项技能将拓展你的专业知识，帮助你独立完成更令人兴奋的项目。</p><h2 id="8b7a" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">帕泰鲁什·西达</h2><p id="2827" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu"> <em class="nt">如果你喜欢这篇文章，并希望看到更多这样的东西。</em> </strong></p><ul class=""><li id="a03b" class="ne nf it lt b lu mn lx mo ma ng me nh mi ni mm nj nk nl nm bi translated">在<a class="ae ky" href="http://padpathairush.medium.com" rel="noopener">媒</a>上关注我，或者在<a class="ae ky" href="https://www.linkedin.com/in/pathairush-seeda-b7a62ab6/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上联系我。</li></ul></div></div>    
</body>
</html>