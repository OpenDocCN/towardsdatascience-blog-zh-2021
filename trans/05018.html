<html>
<head>
<title>Logit — Global and Local Interpretability in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">logit——Python中的全局和局部可解释性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/logit-global-and-local-interpretability-in-python-f554acb541e4?source=collection_archive---------28-----------------------#2021-05-02">https://towardsdatascience.com/logit-global-and-local-interpretability-in-python-f554acb541e4?source=collection_archive---------28-----------------------#2021-05-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/ad745f13ff520437d3367d4e1df2388c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TLqyK6v3THcJuZlk"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">托拜厄斯·凯勒在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="6487" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">介绍</h1><p id="6437" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">Logit模型是一种回归技术，在给定预测值的情况下，对二元目标的对数概率进行建模。它的简单性(与Xgboost这样的锤子相比)使得解释它的决策非常方便。我们探索视觉上解释<strong class="ld ir">“模型如何做出决定？”的技术</strong> on <strong class="ld ir">全局</strong>(用于建模所取的所有数据)和<strong class="ld ir"> local </strong>(特定数据点)设置。本文灵感来源于<a class="ae kc" href="https://christophm.github.io/interpretable-ml-book/" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir">可解释性机器学习</strong> </a> <strong class="ld ir">这本书。</strong></p><h1 id="3768" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">数据和问题陈述</h1><p id="593c" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">数据可以在<a class="ae kc" href="https://www.kaggle.com/c/churn-modelling/data" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir">这里</strong> </a>找到，来自一家跨国电信公司。该数据是个人级别的，具有关于地理位置、个人信息(年龄/性别)和基于客户特征的信用评级的特征。目标是一个bool，它告诉我们一个特定的客户是否从那个公司(flag=1)流失了(<strong class="ld ir">【Exited】</strong>)。</p><p id="9aa3" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">我们使用Logit模型将客户分为流失客户和非流失客户。本<a class="ae kc" href="https://colab.research.google.com/drive/12GwHg7wqxHvtE20V7h4tcxGTrWHf8Cvu?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir">笔记本</strong> </a>有特征选择、拟合优度和解释的实现。这里我们只关注模型的决策。</p><p id="008d" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">综上所述，问题陈述是关于预测流失事件的<strong class="ld ir"> log odds </strong>。</p><h2 id="2041" class="me ke iq bd kf mf mg dn kj mh mi dp kn lm mj mk kr lq ml mm kv lu mn mo kz mp bi translated">读取数据</h2><p id="8829" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">假设csv文件位于项目根目录中</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="e9fb" class="me ke iq mv b gy mz na l nb nc">df = pd.read_csv("Churn_Modelling.csv",index_col=["RowNumber","CustomerId","Surname"])</span><span id="25e1" class="me ke iq mv b gy nd na l nb nc">df.head()</span></pre><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ne"><img src="../Images/04ffadcb3c281a03ddd6072ad9ad92ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*frMAAO0qk1qJccauTHu3SQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">数据(图片来源-作者)</p></figure><h1 id="b6d3" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">用于建模的特征</h1><p id="a913" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们使用以下特征进行建模:</p><ul class=""><li id="ae9a" class="nf ng iq ld b le lz li ma lm nh lq ni lu nj ly nk nl nm nn bi translated">年龄(顾客的年龄)</li><li id="d7df" class="nf ng iq ld b le no li np lm nq lq nr lu ns ly nk nl nm nn bi translated">地理位置(客户所在地-法国、德国或西班牙)</li><li id="ea1a" class="nf ng iq ld b le no li np lm nq lq nr lu ns ly nk nl nm nn bi translated">性别</li><li id="79c2" class="nf ng iq ld b le no li np lm nq lq nr lu ns ly nk nl nm nn bi translated">HasCrCard(客户是否有信用卡)</li></ul><p id="4aed" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">已经使用视觉分析完成了特征的选择。然而，我们可以使用诸如方差膨胀因子、皮尔逊/卡方/方差分析等技术。例如，从下图中我们可以看到，与西班牙和法国相比，德国有更大比例的客户曾有过不愉快经历。因此，将它作为一个特征将使我们的模型成为一个很好的预测器。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nt"><img src="../Images/cf36e4186b62e0abd551b61f86abeafb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Vk5NuMfb6bdFgAx-HypQA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">数据分析- <strong class="bd nu">年龄</strong>(图片来源-作者)</p></figure><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nv"><img src="../Images/4b4bda4515edec5d4cc4ec06b2b45ca2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bfLkPY9yeG-HilsyUWTqxw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">数据分析- <strong class="bd nu">地理</strong>(图片来源-作者)</p></figure><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nw"><img src="../Images/91e249d48283f2cad7dfa389641d2200.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5f7gwHH1-BgGHLao5afC7w.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">数据分析- <strong class="bd nu">性别</strong>(图片来源-作者)</p></figure><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="55bf" class="me ke iq mv b gy mz na l nb nc">#Selecting features for the Logit Model<br/>categorical_cols = ["Geography", "Gender",  "HasCrCard",]<br/>non_categorical_cols = ["Age"]</span></pre><h2 id="3a47" class="me ke iq bd kf mf mg dn kj mh mi dp kn lm mj mk kr lq ml mm kv lu mn mo kz mp bi translated">拟合模型</h2><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="8086" class="me ke iq mv b gy mz na l nb nc">#Creating the Formula<br/>formula = "Exited"+"~"+"+".join(non_categorical_cols)+"+"+\<br/>"+".join([f"C({each_categorcial_col})" for each_categorcial_col\in categorical_cols]) + "-" + "1"</span><span id="f616" class="me ke iq mv b gy nd na l nb nc">#Fitting the Model<br/>logitfit = logit(formula = str(formula),data = df).fit()</span></pre><h1 id="dffa" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">解释</h1><p id="3e0e" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">现在我们解释模型，为此我们需要首先获得必要的参数。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="f5b1" class="me ke iq mv b gy mz na l nb nc">#Extracting Logit's coefficients and sorting them.<br/>logit_coeffs = logitfit.summary2().tables[1]<br/>logit_coeffs = logit_coeffs.reindex(logit_coeffs["Coef."].abs().sort_values().index)</span></pre><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/c79b0cba4519620fc3dccde8324111ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*easUqJgwSWByNto-lCDp8w.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">置信度系数(图片来源-作者)</p></figure><h2 id="afb8" class="me ke iq bd kf mf mg dn kj mh mi dp kn lm mj mk kr lq ml mm kv lu mn mo kz mp bi translated">权重图(全局特征重要性)</h2><p id="57ac" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们采用Logit模型的系数，并观察它们的相对重要性。系数的值越多(无论是正的还是负的)，它们在预测流失类别的对数概率中的影响就越大。这个图是在<strong class="ld ir">全球</strong>范围内，这意味着它是在所有数据点上计算的。</p><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="ny nz l"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">特征重要性(图片来源-作者)</p></figure><p id="c471" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">从该图中，我们推断出<strong class="ld ir">年龄</strong>是唯一一个其值增加会导致平均流失事件的对数几率增加的特征。</p><h2 id="e7aa" class="me ke iq bd kf mf mg dn kj mh mi dp kn lm mj mk kr lq ml mm kv lu mn mo kz mp bi translated">重量图(重要特征)</h2><p id="aaa9" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">上面的图显示了系数的点估计，为了显示系数的重要性，我们使用下面的权重图。这考虑了<strong class="ld ir">标准误差</strong>，并绘制了重量估计值的<strong class="ld ir"> 95%置信区间</strong>。这也是针对所有数据点绘制的。</p><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="ny nz l"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">重要性权重图(图片来源-作者)</p></figure><p id="2334" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">我们可以通过目测推断出特征<strong class="ld ir"> HasCrCard </strong>在统计上<strong class="ld ir">不</strong>显著。这是因为<strong class="ld ir">的重量估计值的95%置信区间经过了<strong class="ld ir"> 0 </strong>。</strong></p><h2 id="1782" class="me ke iq bd kf mf mg dn kj mh mi dp kn lm mj mk kr lq ml mm kv lu mn mo kz mp bi translated">效果图</h2><p id="738a" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在权重图中，我们有一个困惑，估计的尺度各不相同。更可靠的方法是将每个特征的权重与其对应的实际特征值相乘，这将为我们提供Logit权重对数据的<strong class="ld ir">实际影响</strong>。实际效果将<strong class="ld ir">而不是</strong>变化，不像重量图。</p><p id="9d3a" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">为了计算这一点，我们需要使我们的数据虚拟编码w.r.t the Logit。</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="c1d7" class="me ke iq mv b gy mz na l nb nc">#Create Dummies of Categorical Variables<br/>dummy_encoded_df = pd.get_dummies(df[non_categorical_cols+categorical_cols],\columns=["Geography"])</span><span id="a31c" class="me ke iq mv b gy nd na l nb nc">#Order the columns in order to multiply with weights<br/>dummy_encoded_df = dummy_encoded_df[["HasCrCard", "Age",\ "Gender","Geography_Germany", "Geography_Spain",\ "Geography_France",]]</span><span id="fb47" class="me ke iq mv b gy nd na l nb nc">dummy_encoded_df["Gender"] = dummy_encoded_df["Gender"].map({"Female":0, "Male":1})</span><span id="f393" class="me ke iq mv b gy nd na l nb nc">dummy_encoded_df.head()</span></pre><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oa"><img src="../Images/e99d7bfa36849c8eb2e22a220a791e14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SNZObX1aK2Cqx5LZgmgjmQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">虚拟编码数据(图片来源-作者)</p></figure><p id="9f1a" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><strong class="ld ir">计算实际效果:</strong></p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="847f" class="me ke iq mv b gy mz na l nb nc"># Multiply Dummy Encoded data with actual weights from Logit<br/>effects = dummy_encoded_df * logit_coeffs['Coef.'].to_numpy()<br/>effects.head()</span></pre><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ob"><img src="../Images/37cbcb09558f050882f0abf48c7cb8d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c5vIMvv-_Rk5dP_Q8o1N3A.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">实际效果(图片来源-作者)</p></figure><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="oc nz l"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">效果图(图片来源-作者)</p></figure><p id="244a" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">特征<strong class="ld ir">年龄</strong>和<strong class="ld ir">地理</strong>当然对流失预测的对数几率有很大影响。</p><h2 id="9e47" class="me ke iq bd kf mf mg dn kj mh mi dp kn lm mj mk kr lq ml mm kv lu mn mo kz mp bi translated">局部可解释性</h2><p id="2a09" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">为了解释单个数据点，我们将单个数据点的效果(显示为<strong class="ld ir">红点</strong>)叠加在效果图上。这有助于我们推断回归计算中单个数据点的影响。</p><ol class=""><li id="c20d" class="nf ng iq ld b le lz li ma lm nh lq ni lu nj ly od nl nm nn bi translated">这里我们考虑一个客户，他的预测对数概率是<strong class="ld ir">大于</strong>0.5。</li></ol><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oe"><img src="../Images/88218a08d732eb1461e286a3816293ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dchLTJPmQ2a1gNPA934Scg.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">预测对数概率比<strong class="bd nu"> 0.5 </strong>多<strong class="bd nu">的客户(图片来源-作者)</strong></p></figure><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="oc nz l"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">以上数据点的局部效果(图片来源-作者)</p></figure><p id="914c" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">让我们考虑上面的红点，它标记了数据点的个体效应。在这种情况下，<strong class="ld ir">年龄</strong>对对数赔率计算有重大影响，这抵消了<strong class="ld ir">地理位置</strong>和<strong class="ld ir">性别</strong>(具有<strong class="ld ir">负</strong>影响)的组合影响，并将对数赔率值拖至<strong class="ld ir">大于<strong class="ld ir"> 0.5 </strong>。</strong></p><p id="37c6" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">这与数据分布是一致的，正如我们在上面的方框图中看到的那样，与那些没有频繁购买的客户相比，频繁购买的客户的平均年龄更高。</p><p id="6d0e" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">2.接下来，我们考虑一个客户，其预测对数概率比<strong class="ld ir"> 0.5 </strong>小<strong class="ld ir">。</strong></p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/42ceef9cfb9438070822dbb03da473e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TE93ViYCyt5o5HKCDH5g8A.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">预测对数概率比<strong class="bd nu"> 0.5 </strong>小<strong class="bd nu">的客户(图片来源-作者)</strong></p></figure><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="oc nz l"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">以上数据点的局部效果(图片来源-作者)</p></figure><p id="3255" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">让我们考虑上面的红点，它标记了数据点的个体效应。在这种情况下，客户身在<strong class="ld ir">法国</strong>，是一名<strong class="ld ir">男性</strong>且年龄为<strong class="ld ir"> 31 </strong>的事实使得对数几率<strong class="ld ir">大大小于<strong class="ld ir"> 0.5 </strong>。地理和性别效应将它拖向负值，甚至年龄效应也拖向年龄效应分布的左尾(<strong class="ld ir">&lt;25%平铺</strong>)。</strong></p><p id="ed35" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">这与数据分布非常同步。法国客户的流失率最低，年龄较低的客户平均流失率也较低。</p></div><div class="ab cl og oh hu oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="ij ik il im in"><p id="0a4e" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">感谢你的阅读！</p><h1 id="5518" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">参考</h1><p id="fa4f" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><code class="fe on oo op mv b">Molnar, Christoph. "Interpretable machine learning. A Guide for Making Black Box Models Explainable", 2019. <a class="ae kc" href="https://christophm.github.io/interpretable-ml-book/." rel="noopener ugc nofollow" target="_blank">https://christophm.github.io/interpretable-ml-book/.</a></code></p><p id="d4bf" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated"><a class="ae kc" href="https://colab.research.google.com/drive/12GwHg7wqxHvtE20V7h4tcxGTrWHf8Cvu?usp=sharing" rel="noopener ugc nofollow" target="_blank"><strong class="ld ir">Colab上的笔记本全代码</strong> </a></p></div></div>    
</body>
</html>