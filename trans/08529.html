<html>
<head>
<title>Increasing Model Reliability: Model Selection — Cross-Validation —</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">增加模型可靠性:模型选择——交叉验证——</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/increasing-model-reliability-model-selection-cross-validation-1ce0bf506cd?source=collection_archive---------18-----------------------#2021-08-06">https://towardsdatascience.com/increasing-model-reliability-model-selection-cross-validation-1ce0bf506cd?source=collection_archive---------18-----------------------#2021-08-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="baaa" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在一个视图中使用python实现来增加结果可靠性的模型选择/类型</h2></div><p id="50a7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">至关重要的是，机器学习中准备的模型为外部数据集提供可靠的结果，即泛化。在数据集的一部分被保留作为测试并且模型被训练之后，从测试数据获得的准确度在测试数据中可能是高的，而对于外部数据是非常低的。例如，如果在带有x，y，z标签的数据集中只选择带有x标签的数据作为随机选择的测试数据集，这实际上只给出了x标签的准确性，而不是模型，但这可能不会被开发人员注意到。这个模型不是一般化的，肯定是一个不理想的情况。本文包含不同的配置，从中可以选择训练数据和测试数据，以增加模型结果的可靠性。这些方法对于模型正确响应开放世界的项目是必不可少的。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="d457" class="ln lo it lj b gy lp lq l lr ls"><strong class="lj iu">Table of Contents</strong> <br/><strong class="lj iu">1.</strong> Train Test Split<br/><strong class="lj iu">2.</strong> Cross Validation<br/><strong class="lj iu">2.1.</strong> KFold Cross Validation<br/><strong class="lj iu">2.2.</strong> Stratified KFold Cross Validation<br/><strong class="lj iu">2.3.</strong> LeaveOneOut Cross Validation<br/><strong class="lj iu">2.4.</strong> Repeated KFold Cross Validation<br/><strong class="lj iu">2.5.</strong> ShuffleSplit Cross Validation<br/><strong class="lj iu">2.6.</strong> Group KFold Cross Validation</span></pre><figure class="le lf lg lh gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lt"><img src="../Images/2d28851226473d81c5e8cb617d343222.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aqbd8Mzrln81HXHf"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图片由<a class="ae mf" href="https://unsplash.com/@siamialtrice_?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">暹罗谭</a>在<a class="ae mf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="dd29" class="mg lo it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">1.列车测试分离</h1><p id="dc0c" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">在机器学习应用中，用数据集训练模型。通过这种训练，模型学习特征和输出(目标)之间的关系。然后，使用相同格式的另一个数据集评估模型的准确性。训练测试分离以用户选择的速率将数据分离成训练数据和测试数据。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="e16b" class="ln lo it lj b gy lp lq l lr ls">IN[1]<br/>from sklearn.datasets import load_iris<br/>from sklearn.model_selection import train_test_split<br/>iris = load_iris()<br/>x_train,x_test,y_train,y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=2021)<br/>print("shape of x_train",x_train.shape)<br/>print("shape of x_test",x_test.shape)<br/><strong class="lj iu">OUT[1]<br/>shape of x_train (120, 4)<br/>shape of x_test (30, 4)</strong></span></pre><p id="d22d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如OUT[1]所示，数据集分为20%的测试数据和80%的训练数据。</p><h1 id="ebae" class="mg lo it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">2.交叉验证</h1><p id="43ae" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">虽然用<em class="nc"> train_test_split </em>分离模型看起来很有用，但是从测试数据集得到的准确率可能并不能反映真实情况。例如，当我们用<em class="nc"> train_test_split </em>随机分离包含A、B、C标签的数据集时，可以将包含A、B标签的数据分离为train，将所有C标签分离为test。在这种情况下，训练数据和测试数据之间存在差异，这对于模型的成功会产生误导。因此，当将数据集分成训练数据和测试数据时，使用不同的方法。现在让我们检查基于统计数据的交叉验证的类型，并使用scikit learn库轻松实现。</p><h2 id="030e" class="ln lo it bd mh nd ne dn ml nf ng dp mp kr nh ni mr kv nj nk mt kz nl nm mv nn bi translated">2.1.交叉验证</h2><p id="5315" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">数据集被分成用户选择的数(k)。该模型被分割为多个部分，每个部分被称为折叠，并且在每个分割中不同的折叠被用作测试数据集。例如，如果一个包含150个数据的数据集被设置为k=3，那么模型会给出3个精度值，而不同的1/3部分(0–50、50–100、100–150)会被用来测试每个精度。剩余的2/3部分用于每次迭代中的训练。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="62a0" class="ln lo it lj b gy lp lq l lr ls">IN[2]<br/>heart_dataset=pd.read_csv('heart.csv')<br/>heart_data   =heart_dataset.drop('output',axis=1)<br/>heart_target =heart_dataset['output']<br/>rb=RobustScaler()<br/>heart_robust=rb.fit_transform(heart_data)</span><span id="93b7" class="ln lo it lj b gy no lq l lr ls">IN[3]<br/>kf = KFold(n_splits=5)<br/>i=1<br/>for train_data,test_data in kf.split(X=heart_data, y=heart_target):<br/>    print('iteration',i)<br/>    print(train_data[:10],"length:", len(train_data))<br/>    print(test_data[:10],"length:", len(test_data))<br/>    print("**********************************")<br/>    i +=1<br/><strong class="lj iu">OUT[3]<br/>iteration 1<br/>[61 62 63 64 65 66 67 68 69 70] train_length: 242<br/>[0 1 2 3 4 5 6 7 8 9] test_length: 61<br/>**********************************<br/>iteration 2<br/>[0 1 2 3 4 5 6 7 8 9] train_length: 242<br/>[61 62 63 64 65 66 67 68 69 70] test_length: 61<br/>**********************************<br/>iteration 3<br/>[0 1 2 3 4 5 6 7 8 9] train_length: 242<br/>[122 123 124 125 126 127 128 129 130 131] test_length: 61<br/>**********************************<br/>iteration 4<br/>[0 1 2 3 4 5 6 7 8 9] train_length: 243<br/>[183 184 185 186 187 188 189 190 191 192] test_length: 60<br/>**********************************<br/>iteration 5<br/>[0 1 2 3 4 5 6 7 8 9] train_length: 243<br/>[243 244 245 246 247 248 249 250 251 252] test_length: 60<br/>**********************************</strong></span></pre><p id="e45d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">心脏病数据集由14列和303行组成。所有特征值都是数字，因此应用了<em class="nc">鲁棒定标器</em>。数据集的输出由0和1组成。OUT[3]显示了每个分割中测试和训练数据的前10个数据。可以看出，来自第一次分割的测试数据从数据集的第一个数据开始；第二次分割的测试数据从61开始。数据；第三次分割的测试数据从122开始。数据；来自数据的测试数据第四次分割从数据183.data开始，最后一次分割从数据243开始。数据</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="6aa5" class="ln lo it lj b gy lp lq l lr ls">IN[4]<br/>scores=cross_val_score(LogisticRegression(),heart_robust,heart_target,cv=5)<br/>print(scores)<br/>print("mean accuracy:",scores.mean())<br/><strong class="lj iu">OUT[4]<br/>[0.83606557 0.86885246 0.83606557 0.86666667 0.76666667]<br/>mean accuracy: 0.8348633879781422</strong></span></pre><p id="9b06" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">303个数字数据的心脏病数据集已经用k=5的逻辑回归分裂了5次。每个分割的逻辑回归准确度分别为[0.83606557 0.86885246 0.83606557 0.86666670.7666667]。</p><p id="54a5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> KFold交叉验证与Shuffle </strong></p><p id="6cc5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在k倍交叉验证中，数据集被按顺序分成k个值。当KFold选项中的<em class="nc">洗牌</em>和<em class="nc"> random_state </em>值被设置时，数据被随机选择:</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="007d" class="ln lo it lj b gy lp lq l lr ls">IN[5]<br/>kfs = KFold(n_splits=5, shuffle=True, random_state=2021)<br/>scores_shuffle=cross_val_score(LogisticRegression(),heart_robust,heart_target,cv=kfs)<br/>print(scores_shuffle)<br/>print("mean accuracy:",scores_shuffle.mean())<br/><strong class="lj iu">OUT[5]<br/>[0.83606557 0.78688525 0.78688525 0.85       0.83333333]<br/>mean accuracy: 0.8186338797814209</strong></span></pre><h2 id="0737" class="ln lo it bd mh nd ne dn ml nf ng dp mp kr nh ni mr kv nj nk mt kz nl nm mv nn bi translated">2.2.分层交叉验证</h2><p id="145c" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">数据集被分成用户选择的数字(k)部分。与KFold不同的是，每个目标也是由k进行拆分和合并的，比如我们考虑iris数据集(前50个数据iris setosa50-100朵杂色鸢尾，100-150朵海滨鸢尾)并通过选择k值5:</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="3389" class="ln lo it lj b gy lp lq l lr ls">IN[6]<br/>iris_dataset=pd.read_csv('iris.csv')<br/>iris_data   =iris_dataset.drop('Species',axis=1)<br/>iris_data   =iris_data.drop(['Id'],axis=1)<br/>iris_target =iris_dataset['Species']</span><span id="34a5" class="ln lo it lj b gy no lq l lr ls">IN[7]<br/>skf = StratifiedKFold(n_splits=5)<br/>i=1<br/>for train_data,test_data in skf.split(X=iris_data, y=iris_target):<br/>    print('iteration',i)<br/>    print(test_data,"length", len(test_data))<br/>    print("**********************************")<br/>    i +=1<br/><strong class="lj iu">OUT[7]<br/>iteration 1<br/>[  0   1   2   3   4   5   6   7   8   9  50  51  52  53  54  55  56  57 58  59 100 101 102 103 104 105 106 107 108 109] length 30<br/>**********************************<br/>iteration 2<br/>[ 10  11  12  13  14  15  16  17  18  19  60  61  62  63  64  65  66  67 68  69 110 111 112 113 114 115 116 117 118 119] length 30<br/>**********************************<br/>iteration 3<br/>[ 20  21  22  23  24  25  26  27  28  29  70  71  72  73  74  75  76  77 78  79 120 121 122 123 124 125 126 127 128 129] length 30<br/>**********************************<br/>iteration 4<br/>[ 30  31  32  33  34  35  36  37  38  39  80  81  82  83  84  85  86  87 88  89 130 131 132 133 134 135 136 137 138 139] length 30<br/>**********************************<br/>iteration 5<br/>[ 40  41  42  43  44  45  46  47  48  49  90  91  92  93  94  95  96  97 98  99 140 141 142 143 144 145 146 147 148 149] length 30<br/>**********************************</strong></span></pre><p id="4093" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当分析测试数据集时，每个目标的前10个数据(0–10；50–60;100–110 ),第二次迭代中每个目标的第二个1/5切片(20–30；60- 70;110–120)等等。每次迭代中的剩余数据用于训练，并且线性回归用于每次迭代中的训练数据，自然地，获得了5个不同的精度。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="5073" class="ln lo it lj b gy lp lq l lr ls">IN[8]<br/>lr=LogisticRegression()<br/>le=LabelEncoder()<br/>iris_labels=le.fit_transform(iris_target)<br/>rb=RobustScaler()<br/>iris_robust=rb.fit_transform(iris_data)<br/>iris_robust=pd.DataFrame(iris_robust)</span><span id="fafd" class="ln lo it lj b gy no lq l lr ls">IN[9]<br/>scores_skf = []<br/>i = 1<br/>for train_set, test_set in skf.split(X=iris_robust, y=iris_labels):<br/>    lr.fit(iris_robust.loc[train_set], iris_labels[train_set])<br/>    sco = lr.score(iris_robust.loc[test_set], iris_labels[test_set])<br/>    scores_skf.append(sco)<br/>    i += 1<br/>print(scores_skf)<br/>print("mean accuracy:",sum(scores_skf) / len(scores_skf))<br/><strong class="lj iu">OUT[9]</strong><br/><strong class="lj iu">[0.9, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667]<br/>mean accuracy: 0.9400000000000001</strong></span></pre><p id="013f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于<em class="nc"> "'numpy.ndarray '对象没有属性' loc'" </em>，<em class="nc"> iris_robust </em>的numpy数组被转换为pandas DataFrame。</p><p id="2eb9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">分层KFold交叉验证可以轻松实现，如Scikit learn中的<em class="nc"> cross_val_score </em>所示。</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="00df" class="ln lo it lj b gy lp lq l lr ls">IN[10]<br/>score_skf=cross_val_score(lr,iris_robust,iris_labels,cv=skf)<br/>print(score_skf)<br/>print("mean accuracy:",score_skf.mean())<br/><strong class="lj iu">OUT[10]<br/>[0.9        0.96666667 0.93333333 0.93333333 0.96666667]<br/>mean accuracy: 0.9400000000000001</strong></span></pre><p id="430f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">两个结果是一样的。</p><blockquote class="np nq nr"><p id="9759" class="ki kj nc kk b kl km ju kn ko kp jx kq ns ks kt ku nt kw kx ky nu la lb lc ld im bi translated">由于iris数据集中的目标值相等(50–50–50 ),因此每个目标值的位置相等。但是，如果数据集中的标注比例不同，则每个折叠都将以此比例包含数据。例如，如果label-x有100个数据，label-y有900个数据，则每个文件夹将包含90% label-y数据和10% label-x数据。</p><p id="2aaf" class="ki kj nc kk b kl km ju kn ko kp jx kq ns ks kt ku nt kw kx ky nu la lb lc ld im bi translated">查看scikit learn的<a class="ae mf" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html" rel="noopener ugc nofollow" target="_blank">网站</a>中的split方法，看到y值应该是(n_samples，)，所以设计为用标签编码器运行，而不是OneHotEncoder。</p></blockquote><h2 id="2720" class="ln lo it bd mh nd ne dn ml nf ng dp mp kr nh ni mr kv nj nk mt kz nl nm mv nn bi translated">2.3.LeaveOneOut交叉验证</h2><p id="002a" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">每个数据被认为是一个折叠，所以k的值等于数据的数量。每个数据被逐一分离，并用剩余的数据训练模型。用训练好的模型测试分离的数据。如果我们考虑虹膜数据集:</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="cece" class="ln lo it lj b gy lp lq l lr ls">IN[11]<br/>loo = cross_val_score(estimator=LogisticRegression(), X=iris_robust, y=iris_labels,<br/>                               scoring='accuracy', cv=LeaveOneOut())</span><span id="fff9" class="ln lo it lj b gy no lq l lr ls">print(loo,"len of loo=",len(loo))<br/>print("mean accuracy:",loo.mean())<br/><strong class="lj iu">OUT[11]<br/>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] len of loo= 150<br/>mean accuracy: 0.9466666666666667</strong></span></pre><p id="6bd1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">可以看出，由150个数据集组成的虹膜数据集用<em class="nc"> LeaveOneOut </em>建模，并应用逻辑回归。每个数据都是分开的，并用剩余的数据训练模型。总的来说，该模型已经训练了150次，并且做出了150个预测(针对每个数据)。全部取平均值。</p><figure class="le lf lg lh gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nv"><img src="../Images/d61efa4caa7c829bf504301ecd94717b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kGWBgPdwOGolw70i"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">照片由<a class="ae mf" href="https://unsplash.com/@briansuman?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">布莱恩·苏曼</a>在<a class="ae mf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h2 id="43b0" class="ln lo it bd mh nd ne dn ml nf ng dp mp kr nh ni mr kv nj nk mt kz nl nm mv nn bi translated">2.4.重复KFold交叉验证</h2><p id="e60d" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">根据用户选择的值，重复k倍交叉验证的次数。对于虹膜数据集:</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="ee5c" class="ln lo it lj b gy lp lq l lr ls">IN[12]<br/>rkf = cross_val_score(estimator=LogisticRegression(), X=iris_robust, y=iris_labels, scoring='accuracy', cv=RepeatedKFold(n_splits=5, n_repeats=5))<br/>print("accuracy:", rkf)<br/>print("mean accuracy",rkf.mean())<br/><strong class="lj iu">OUT[12]<br/>accuracy: <br/>[0.96666667 0.9       0.93333333 0.93333333 0.93333333 0.9<br/> 0.93333333 1.         0.96666667 0.96666667 0.86666667 0.96666667<br/> 0.96666667 0.96666667 1.         0.96666667 0.9        1.<br/> 0.93333333 0.93333333 0.86666667 0.96666667 1.         0.9<br/> 0.96666667]<br/>mean accuracy 0.9453333333333331</strong></span></pre><p id="8a29" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据集被分成5部分，算法被拟合5次。结果，获得了25个精度值。</p><p id="d426" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于分层折叠，也可以这样做:</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="4e9a" class="ln lo it lj b gy lp lq l lr ls">IN[13]<br/>rskf = cross_val_score(estimator=LogisticRegression(), X=iris_robust, y=iris_labels, scoring='accuracy', cv=RepeatedStratifiedKFold(n_splits=5, n_repeats=5))<br/>print("accuracy", rskf)<br/>print("mean accuracy",rskf.mean())<br/><strong class="lj iu">OUT[13]<br/>accuracy<br/>[0.96666667 0.9        0.96666667 0.96666667 0.96666667 0.9<br/> 0.96666667 0.96666667 0.9        0.96666667 0.96666667 0.96666667<br/> 0.9        0.96666667 0.96666667 0.9        0.93333333 1.<br/> 0.96666667 0.96666667 0.96666667 0.93333333 1.         0.9<br/> 0.93333333]<br/>mean accuracy 0.9493333333333333</strong></span></pre><h2 id="4061" class="ln lo it bd mh nd ne dn ml nf ng dp mp kr nh ni mr kv nj nk mt kz nl nm mv nn bi translated">2.5.洗牌分割交叉验证</h2><p id="7961" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">使用<em class="nc"> n_splits </em>设置数据集的迭代次数，并以用户指定的比率为每次分割随机选择训练和测试数据:</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="da8c" class="ln lo it lj b gy lp lq l lr ls">IN[14]<br/>shuffle_split = ShuffleSplit(test_size=.4, train_size=.5, n_splits=10)<br/>scores_ss = cross_val_score(LogisticRegression(), iris_robust, iris_labels, cv=shuffle_split)<br/>print("Accuracy",scores_ss)<br/>print("mean accuracy:",scores_ss.mean())<br/><strong class="lj iu">OUT[14]<br/>Accuracy<br/>[0.9        0.93333333 0.88333333 0.9        0.95       0.95<br/> 0.93333333 0.91666667 0.95       0.95      ]<br/>mean accuracy: 0.9266666666666665</strong></span></pre><p id="f7a3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于分层洗牌拆分，可以进行相同的过程:</p><pre class="le lf lg lh gt li lj lk ll aw lm bi"><span id="4506" class="ln lo it lj b gy lp lq l lr ls">IN[15]<br/>shuffle_sfs=StratifiedShuffleSplit(test_size=.4, train_size=.5, n_splits=10)<br/>scores_sfs = cross_val_score(LogisticRegression(), iris_robust, iris_labels, cv=shuffle_sfs)<br/>print("Accuracy",scores_sfs)<br/>print("mean accuracy:",scores_sfs.mean())<br/><strong class="lj iu">OUT[15]<br/>Accuracy<br/>[0.88333333 0.93333333 0.93333333 0.93333333 0.91666667 0.96666667<br/> 0.96666667 0.96666667 0.88333333 0.9       ]<br/>mean accuracy: 0.9283333333333333</strong></span></pre><h2 id="8b5d" class="ln lo it bd mh nd ne dn ml nf ng dp mp kr nh ni mr kv nj nk mt kz nl nm mv nn bi translated">2.6.集团交叉验证</h2><p id="2167" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">当从同一个对象接收到多个数据时使用。例如，在医学数据中，为了模型的泛化，最好在训练数据集中具有来自同一患者的多个图像。为了实现这一点，可以使用<em class="nc"> GroupKFold </em>，它接受一个组数组作为参数，我们可以用它来指示图像中的人是谁。这里的组数组指定了在创建训练集和测试集时不应拆分的数据组，并且不应与类标签混淆。使用GroupKFold，该组或者在训练集上，或者在测试集上。</p><h2 id="4147" class="ln lo it bd mh nd ne dn ml nf ng dp mp kr nh ni mr kv nj nk mt kz nl nm mv nn bi translated">回到指南点击<a class="ae mf" href="https://ibrahimkovan.medium.com/machine-learning-guideline-959da5c6f73d" rel="noopener">此处</a>。</h2><div class="nw nx gp gr ny nz"><a href="https://ibrahimkovan.medium.com/machine-learning-guideline-959da5c6f73d" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd iu gy z fp oe fr fs of fu fw is bi translated">机器学习指南</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">本文旨在准备一个机器学习数据库，以便在一个视图中显示所有的机器学习标题。这个…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">ibrahimkovan.medium.com</p></div></div><div class="oi l"><div class="oj l ok ol om oi on lz nz"/></div></div></a></div></div></div>    
</body>
</html>