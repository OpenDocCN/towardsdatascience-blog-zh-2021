<html>
<head>
<title>Do You Read Excel Files with Python? There is a 1000x Faster Way.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python读Excel文件吗？有一个快1000倍的方法。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/read-excel-files-with-python-1000x-faster-407d07ad0ed8?source=collection_archive---------0-----------------------#2021-07-03">https://towardsdatascience.com/read-excel-files-with-python-1000x-faster-407d07ad0ed8?source=collection_archive---------0-----------------------#2021-07-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="0a7b" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><div class=""><h2 id="bcb8" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">在本文中，我将向您展示用Python加载数据的五种方法。实现了3个数量级的加速。</h2></div><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi gj"><img src="../Images/515f80f66eaef203466b272077e69778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OWlt7BQBEGHNNtLp.jpg"/></div></div><p class="lc ld gj gh gi le lf bd b be z dk translated">来源:https://www.hippopx.com/<a class="ae lg" href="https://www.hippopx.com/" rel="noopener ugc nofollow" target="_blank">，公共领域</a></p></figure><p id="91b5" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">作为一名Python用户，我使用excel文件加载/存储数据，因为商务人士喜欢以excel或csv格式共享数据。不幸的是，Python处理Excel文件特别慢。</p><p id="9159" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在本文中，我将向您展示用Python加载数据的五种方法。最终，我们将实现3个数量级的加速。会快如闪电。</p><blockquote class="md me mf"><p id="0ea5" class="lh li mg lj b lk ll kd lm ln lo kg lp mh lr ls lt mi lv lw lx mj lz ma mb mc im bi translated"><em class="it">编辑(18/07/2021):我找到了一种方法，可以让进程</em> <strong class="lj jd"> <em class="it">快5倍</em> </strong> <em class="it">(结果加速了5000倍)。我在文末补充了一下作为加分项。</em></p></blockquote><h1 id="dccd" class="mk ml it bd mm mn mo mp mq mr ms mt mu ki mv kj mw kl mx km my ko mz kp na nb bi translated">实验装置</h1><p id="5aba" class="pw-post-body-paragraph lh li it lj b lk nc kd lm ln nd kg lp lq ne ls lt lu nf lw lx ly ng ma mb mc im bi translated">假设我们要加载10个20000行25列的Excel文件(总共大约70MB)。这是一个典型的案例，您希望将事务性数据从ERP (SAP)加载到Python来执行一些分析。</p><p id="ae6c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">让我们填充这个虚拟数据并导入所需的库(我们将在本文后面讨论pickle和joblib)。</p><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="nh ni l"/></div></figure><pre class="kr ks kt ku gt nj nk nl nm aw nn bi"><span id="b287" class="no ml it nk b gy np nq l nr ns">import pandas as pd<br/>import numpy as np<br/>from joblib import Parallel, delayed<br/>import time</span><span id="bbd9" class="no ml it nk b gy nt nq l nr ns">for file_number in range(10):<br/> values = np.random.uniform(size=(20000,25))<br/> pd.DataFrame(values).to_csv(f”Dummy {file_number}.csv”)<br/> pd.DataFrame(values).to_excel(f”Dummy {file_number}.xlsx”)<br/> pd.DataFrame(values).to_pickle(f”Dummy {file_number}.pickle”)</span></pre><h1 id="d922" class="mk ml it bd mm mn mo mp mq mr ms mt mu ki mv kj mw kl mx km my ko mz kp na nb bi translated">在Python中加载数据的5种方法</h1><h1 id="278b" class="mk ml it bd mm mn mo mp mq mr ms mt mu ki mv kj mw kl mx km my ko mz kp na nb bi translated">想法1:用Python加载一个Excel文件</h1><p id="ea89" class="pw-post-body-paragraph lh li it lj b lk nc kd lm ln nd kg lp lq ne ls lt lu nf lw lx ly ng ma mb mc im bi translated">让我们从加载这些文件的简单方法开始。我们将创建第一个Pandas数据框架，然后将每个Excel文件追加到其中。</p><pre class="kr ks kt ku gt nj nk nl nm aw nn bi"><span id="9e4b" class="no ml it nk b gy np nq l nr ns">start = time.time()<br/>df = pd.read_excel(“Dummy 0.xlsx”)<br/>for file_number in range(1,10):<br/> df.append(pd.read_excel(f”Dummy {file_number}.xlsx”))<br/>end = time.time()<br/>print(“Excel:”, end — start)</span><span id="8461" class="no ml it nk b gy nt nq l nr ns">&gt;&gt; Excel: 53.4</span></pre><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="nh ni l"/></div><p class="lc ld gj gh gi le lf bd b be z dk translated">用Python导入Excel文件的简单方法。</p></figure><p id="f2ae" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">运行大约需要50秒。相当慢。</p><h1 id="32bb" class="mk ml it bd mm mn mo mp mq mr ms mt mu ki mv kj mw kl mx km my ko mz kp na nb bi translated">想法2:使用CSV而不是Excel文件</h1><p id="201d" class="pw-post-body-paragraph lh li it lj b lk nc kd lm ln nd kg lp lq ne ls lt lu nf lw lx ly ng ma mb mc im bi translated">现在让我们假设我们将这些文件保存为。csv(而不是。xlsx)从我们的ERP/System/SAP。</p><pre class="kr ks kt ku gt nj nk nl nm aw nn bi"><span id="de9c" class="no ml it nk b gy np nq l nr ns">start = time.time()<br/>df = pd.read_csv(“Dummy 0.csv”)<br/>for file_number in range(1,10):<br/> df.append(pd.read_csv(f”Dummy {file_number}.csv”))<br/>end = time.time()<br/>print(“CSV:”, end — start)</span><span id="4e98" class="no ml it nk b gy nt nq l nr ns">&gt;&gt; CSV: 0.632</span></pre><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="nh ni l"/></div><p class="lc ld gj gh gi le lf bd b be z dk translated">用Python导入csv文件比Excel文件快100倍。</p></figure><p id="38bc" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们现在可以在0.63秒内加载这些文件。快了将近10倍！</p><p id="ec7c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd"> Python加载CSV文件比Excel文件快100倍。使用CSV。</strong></p><p id="bcee" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">缺点</strong> : csv文件几乎总是大于。xlsx文件。在这个例子中。csv文件为9.5MB，而。xlsx都是6.4MB。</p><h1 id="340f" class="mk ml it bd mm mn mo mp mq mr ms mt mu ki mv kj mw kl mx km my ko mz kp na nb bi translated">想法3:更聪明的熊猫数据框架创建</h1><p id="2103" class="pw-post-body-paragraph lh li it lj b lk nc kd lm ln nd kg lp lq ne ls lt lu nf lw lx ly ng ma mb mc im bi translated">我们可以通过改变创建熊猫数据框架的方式来加快我们的进程。不是将每个文件附加到现有的数据帧，</p><ol class=""><li id="07be" class="nu nv it lj b lk ll ln lo lq nw lu nx ly ny mc nz oa ob oc bi translated">我们在一个列表中独立加载每个数据帧。</li><li id="cde4" class="nu nv it lj b lk od ln oe lq of lu og ly oh mc nz oa ob oc bi translated">然后将整个列表连接到一个数据帧中。</li></ol><pre class="kr ks kt ku gt nj nk nl nm aw nn bi"><span id="91d2" class="no ml it nk b gy np nq l nr ns">start = time.time()<br/>df = []<br/>for file_number in range(10):<br/> temp = pd.read_csv(f”Dummy {file_number}.csv”)<br/> df.append(temp)<br/>df = pd.concat(df, ignore_index=True)<br/>end = time.time()<br/>print(“CSV2:”, end — start)</span><span id="2c34" class="no ml it nk b gy nt nq l nr ns">&gt;&gt; CSV2: 0.619</span></pre><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="nh ni l"/></div><p class="lc ld gj gh gi le lf bd b be z dk translated">用Python导入csv文件的更智能的方法</p></figure><p id="2cee" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们把时间减少了百分之几。根据我的经验，当你处理更大的数据帧(df &gt;&gt; 100MB)时，这个技巧会变得有用。</p><h1 id="ebba" class="mk ml it bd mm mn mo mp mq mr ms mt mu ki mv kj mw kl mx km my ko mz kp na nb bi translated">想法4:用Joblib并行化CSV导入</h1><p id="c2a3" class="pw-post-body-paragraph lh li it lj b lk nc kd lm ln nd kg lp lq ne ls lt lu nf lw lx ly ng ma mb mc im bi translated">我们想用Python加载10个文件。与其一个接一个地加载每个文件<strong class="lj jd"/>，为什么不同时并行地加载它们呢？</p><p id="84c2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以使用<a class="ae lg" href="https://joblib.readthedocs.io/en/latest/parallel.html" rel="noopener ugc nofollow" target="_blank"> joblib </a>轻松做到这一点。</p><pre class="kr ks kt ku gt nj nk nl nm aw nn bi"><span id="d032" class="no ml it nk b gy np nq l nr ns">start = time.time()<br/>def loop(file_number):<br/> return pd.read_csv(f”Dummy {file_number}.csv”)<br/>df = Parallel(n_jobs=-1, verbose=10)(delayed(loop)(file_number) for file_number in range(10))<br/>df = pd.concat(df, ignore_index=True)<br/>end = time.time()<br/>print(“CSV//:”, end — start)</span><span id="4cd1" class="no ml it nk b gy nt nq l nr ns">&gt;&gt; CSV//: 0.386</span></pre><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="nh ni l"/></div><p class="lc ld gj gh gi le lf bd b be z dk translated">使用Joblib并行导入Python中的CSV文件。</p></figure><p id="7bda" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这几乎是单核版本的两倍。然而，一般来说，不要指望使用8个内核就能让你的处理速度提高8倍(在这里，我在Mac Air上使用8个内核，使用新的M1芯片，获得了2倍的速度提升)。</p><h2 id="b6dc" class="no ml it bd mm oi oj dn mq ok ol dp mu lq om on mw lu oo op my ly oq or na iz bi translated">用Joblib在Python中实现简单的并行化</h2><p id="7710" class="pw-post-body-paragraph lh li it lj b lk nc kd lm ln nd kg lp lq ne ls lt lu nf lw lx ly ng ma mb mc im bi translated"><a class="ae lg" href="https://joblib.readthedocs.io/en/latest/parallel.html" rel="noopener ugc nofollow" target="_blank"> Joblib </a>是一个简单的Python库，允许你在//中运行一个函数。在实践中，joblib作为一个列表理解。只是每次迭代由不同的线程执行。这里有一个例子。</p><pre class="kr ks kt ku gt nj nk nl nm aw nn bi"><span id="1c5c" class="no ml it nk b gy np nq l nr ns">def loop(file_number):<br/> return pd.read_csv(f”Dummy {file_number}.csv”)<br/>df = Parallel(n_jobs=-1, verbose=10)(delayed(loop)(file_number) for file_number in range(10))</span><span id="5697" class="no ml it nk b gy nt nq l nr ns">#equivalent to<br/>df = [loop(file_number) for file_number in range(10)]</span></pre><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="nh ni l"/></div><p class="lc ld gj gh gi le lf bd b be z dk translated">像智能列表理解一样思考joblib。</p></figure><h1 id="8362" class="mk ml it bd mm mn mo mp mq mr ms mt mu ki mv kj mw kl mx km my ko mz kp na nb bi translated">想法5:使用Pickle文件</h1><p id="5c20" class="pw-post-body-paragraph lh li it lj b lk nc kd lm ln nd kg lp lq ne ls lt lu nf lw lx ly ng ma mb mc im bi translated">将数据存储在pickle文件(Python使用的一种特定格式)中可以(快得多)而不是。csv文件。</p><p id="6648" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><strong class="lj jd">缺点</strong>:你将无法手动打开一个pickle文件并查看其中的内容。</p><pre class="kr ks kt ku gt nj nk nl nm aw nn bi"><span id="5087" class="no ml it nk b gy np nq l nr ns">start = time.time()<br/>def loop(file_number):<br/> return pd.read_pickle(f”Dummy {file_number}.pickle”)<br/>df = Parallel(n_jobs=-1, verbose=10)(delayed(loop)(file_number) for file_number in range(10))<br/>df = pd.concat(df, ignore_index=True)<br/>end = time.time()<br/>print(“Pickle//:”, end — start)</span><span id="21be" class="no ml it nk b gy nt nq l nr ns">&gt;&gt; Pickle//: 0.072</span></pre><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="ed99" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们刚刚削减了80%的运行时间！</p><p id="843a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">一般来说，处理pickle文件比处理csv文件要快得多。但是，另一方面，pickles文件通常在您的驱动器上占用更多的空间(不是在这个特定的例子中)。</p><p id="67ee" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">实际上，您将无法直接在pickle文件中从系统中提取数据。</p><p id="5a6f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我建议在以下两种情况下使用泡菜:</p><ol class=""><li id="51b2" class="nu nv it lj b lk ll ln lo lq nw lu nx ly ny mc nz oa ob oc bi translated">您想要保存来自Python进程之一的数据(并且不打算在Excel上打开它)以便稍后/在另一个进程中使用。将数据框保存为泡菜，而不是。战斗支援车</li><li id="c68c" class="nu nv it lj b lk od ln oe lq of lu og ly oh mc nz oa ob oc bi translated">您需要多次重新加载相同的文件。第一次打开文件时，将其保存为pickle，以便下次能够直接加载pickle版本。<br/>示例:假设您使用事务性月度数据(每个月您加载一个新月份的数据)。您可以将所有历史数据保存为。pickle并且，每次你收到一个新文件，你可以把它作为一个. csv文件加载一次，然后下一次把它作为一个. pickle文件保存。</li></ol><h1 id="60bc" class="mk ml it bd mm mn mo mp mq mr ms mt mu ki mv kj mw kl mx km my ko mz kp na nb bi translated">好处:并行加载Excel文件</h1><p id="5e75" class="pw-post-body-paragraph lh li it lj b lk nc kd lm ln nd kg lp lq ne ls lt lu nf lw lx ly ng ma mb mc im bi translated">假设您收到了excel文件，并且您没有其他选择，只能按原样加载它们。您还可以使用joblib对此进行并行处理。与上面的pickle代码相比，我们<strong class="lj jd">只需要</strong>更新循环函数。</p><pre class="kr ks kt ku gt nj nk nl nm aw nn bi"><span id="e54a" class="no ml it nk b gy np nq l nr ns">start = time.time()<br/>def loop(file_number):<br/>    return pd.read_excel(f"Dummy {file_number}.xlsx")<br/>df = Parallel(n_jobs=-1, verbose=10)(delayed(loop)(file_number) for file_number in range(10))<br/>df = pd.concat(df, ignore_index=True)<br/>end = time.time()<br/>print("Excel//:", end - start)</span><span id="20a4" class="no ml it nk b gy nt nq l nr ns">&gt;&gt; 13.45</span></pre><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="nh ni l"/></div><p class="lc ld gj gh gi le lf bd b be z dk translated">如何在Python中使用并行化加载excel文件？</p></figure><p id="3cd2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以将加载时间减少70%(从50秒减少到13秒)。</p><p id="6e6e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">您还可以使用这个循环动态创建pickle文件。这样，下次你加载这些文件时，你就能达到闪电般的加载速度。</p><pre class="kr ks kt ku gt nj nk nl nm aw nn bi"><span id="d95f" class="no ml it nk b gy np nq l nr ns">def loop(file_number):<br/>    temp = pd.read_excel(f"Dummy {file_number}.xlsx")<br/>    temp.to_pickle(f"Dummy {file_number}.pickle")<br/>    return temp</span></pre><h1 id="9010" class="mk ml it bd mm mn mo mp mq mr ms mt mu ki mv kj mw kl mx km my ko mz kp na nb bi translated">概述</h1><p id="596f" class="pw-post-body-paragraph lh li it lj b lk nc kd lm ln nd kg lp lq ne ls lt lu nf lw lx ly ng ma mb mc im bi translated">通过并行加载pickle文件，我们将加载时间从50秒减少到不到十分之一秒。</p><ul class=""><li id="07e5" class="nu nv it lj b lk ll ln lo lq nw lu nx ly ny mc os oa ob oc bi translated">Excel: 50秒</li><li id="4aed" class="nu nv it lj b lk od ln oe lq of lu og ly oh mc os oa ob oc bi translated">CSV: 0.63秒</li><li id="7bb5" class="nu nv it lj b lk od ln oe lq of lu og ly oh mc os oa ob oc bi translated">更智能的CSV: 0.62秒</li><li id="7764" class="nu nv it lj b lk od ln oe lq of lu og ly oh mc os oa ob oc bi translated">//: 0.34秒内CSV</li><li id="2cd7" class="nu nv it lj b lk od ln oe lq of lu og ly oh mc os oa ob oc bi translated">//: 0.07秒</li><li id="9930" class="nu nv it lj b lk od ln oe lq of lu og ly oh mc os oa ob oc bi translated">//: 13.5秒</li></ul><h1 id="81b3" class="mk ml it bd mm mn mo mp mq mr ms mt mu ki mv kj mw kl mx km my ko mz kp na nb bi translated">好处2:并行速度提高4倍</h1><p id="7c9b" class="pw-post-body-paragraph lh li it lj b lk nc kd lm ln nd kg lp lq ne ls lt lu nf lw lx ly ng ma mb mc im bi translated">Joblib允许更改并行化后端以消除一些开销。你可以通过给<em class="mg"> prefer="threads" </em>到<em class="mg"> Parallel </em>来做到这一点。</p><figure class="kr ks kt ku gt kv"><div class="bz fp l di"><div class="nh ni l"/></div><p class="lc ld gj gh gi le lf bd b be z dk translated">使用prefer="threads "将允许您更快地运行流程。</p></figure><p id="b514" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们获得了大约0.0096秒的速度(2021 MacBook Air运行了50多次)。</p><p id="34ba" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">将prefer="threads "与CSV和Excel并行化一起使用会产生以下结果。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/ba85958cf0ef3047d597b187ff104c2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*53XgCiv-51IK7GVzZstKqQ.png"/></div></figure><p id="aff8" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">正如你所看到的，使用“线程”后端在读取Excel文件时会导致更差的分数。但是对于pickles来说性能惊人(逐个加载Excel文件需要50秒，而在//中加载读取pickles文件的数据只需要0.01秒)。</p></div><div class="ab cl ou ov hx ow" role="separator"><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz"/></div><div class="im in io ip iq"><h2 id="1486" class="no ml it bd mm oi oj dn mq ok ol dp mu lq om on mw lu oo op my ly oq or na iz bi translated">👉<a class="ae lg" href="https://www.linkedin.com/in/vandeputnicolas/" rel="noopener ugc nofollow" target="_blank">让我们在LinkedIn上联系吧！</a></h2><h1 id="d600" class="mk ml it bd mm mn mo mp mq mr ms mt mu ki mv kj mw kl mx km my ko mz kp na nb bi translated">关于作者</h1><p id="f68e" class="pw-post-body-paragraph lh li it lj b lk nc kd lm ln nd kg lp lq ne ls lt lu nf lw lx ly ng ma mb mc im bi pb translated">icolas Vandeput是一名供应链数据科学家，擅长需求预测和库存优化。他在2016年创立了他的咨询公司<a class="ae lg" href="http://www.supchains.com/" rel="noopener ugc nofollow" target="_blank"> SupChains </a>，并在2018年共同创立了<a class="ae lg" href="https://bit.ly/3ozydFN" rel="noopener ugc nofollow" target="_blank"> SKU科学</a>——一个快速、简单、实惠的需求预测平台。尼古拉斯对教育充满热情，他既是一个狂热的学习者，也喜欢在大学教学:自2014年以来，他一直在比利时布鲁塞尔为硕士学生教授预测和库存优化。自2020年以来，他还在法国巴黎的CentraleSupelec教授这两门课程。他于2018年出版了<a class="ae lg" href="https://www.amazon.com/Data-Science-Supply-Chain-Forecasting/dp/3110671107" rel="noopener ugc nofollow" target="_blank"> <em class="mg">供应链预测的数据科学</em></a>(2021年第2版)和2020年出版了<a class="ae lg" href="https://www.amazon.com/Inventory-Optimization-Simulations-Nicolas-Vandeput/dp/3110673916" rel="noopener ugc nofollow" target="_blank"> <em class="mg">库存优化:模型与模拟</em> </a>。</p><figure class="kr ks kt ku gt kv gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi pk"><img src="../Images/c41de08f0cf4d975881aee57c407363c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7iiuhN5jer1qCQOcREqNcg.jpeg"/></div></div></figure></div></div>    
</body>
</html>