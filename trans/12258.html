<html>
<head>
<title>Schemafull streaming data processing in ML pipelines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ML流水线中的Schemafull流数据处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-kafka-with-avro-in-python-da85b3e0f966?source=collection_archive---------18-----------------------#2021-12-13">https://towardsdatascience.com/using-kafka-with-avro-in-python-da85b3e0f966?source=collection_archive---------18-----------------------#2021-12-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="20c0" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用带有AVRO和模式注册的Kafka，使容器化的Python流数据管道利用模式进行数据验证</h2></div><h1 id="8775" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">介绍</h1><p id="1bc0" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在我以前的一篇关于机器学习管道的文章中，消息队列被认为是HTTP客户端-服务器架构的一种替代方式，这是现今服务于ML模型的最常见的方式。</p><p id="c3b7" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">提醒一下，在ML管道中使用像<a class="ae lt" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Kafka </a>这样的队列有以下优点:</p><ul class=""><li id="19b7" class="lz ma iq kz b la lu ld lv lg mb lk mc lo md ls me mf mg mh bi translated">输入数据生产者和数据处理器(Kafka术语中的消费者)解耦的自然异步处理，即消费数据的ML推理/训练服务的失败不会导致HTTP超时、数据丢失和数据生产者的失败，而只会导致延迟处理</li><li id="4684" class="lz ma iq kz b la mi ld mj lg mk lk ml lo mm ls me mf mg mh bi translated">更好地利用CPU/GPU相关任务的计算资源，例如ML推断/训练:<br/> - <a class="ae lt" href="https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/innovate/best-practices/ml-deployment-inference#batch-inference" rel="noopener ugc nofollow" target="_blank">批量推断</a>通常效率更高，因为ML模型不需要为每个预测预热和拆除<br/> -如果传入数据不规则到达，队列会平滑负载，而HTTP服务器会在负载高峰期间不堪重负，并在安静期间空闲</li><li id="dc18" class="lz ma iq kz b la mi ld mj lg mk lk ml lo mm ls me mf mg mh bi translated">提高吞吐量。然而，值得一提的是，当推理延迟至关重要时，队列并不完美。在这些情况下，轮询间隔非常短的Kafka消费者(这消除了以前的一些优势)或HTTP ML模型服务器仍然是可行的选择。</li></ul><p id="3be1" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">建议读者在阅读本文之前先熟悉Apache Kafka和Docker(包括docker-compose)。Confluent有一个<a class="ae lt" href="https://docs.confluent.io/platform/current/kafka/introduction.html" rel="noopener ugc nofollow" target="_blank">不错的介绍卡夫卡的页面</a>。<a class="ae lt" href="https://docs.docker.com/compose/" rel="noopener ugc nofollow" target="_blank"> Docker docs </a>也很棒。</p><h1 id="bf90" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">为什么要使用模式？</h1><p id="1a94" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">大多数关于如何使用Kafka，尤其是Python的教程都展示了生成和使用无模式JSON字符串的例子。尽管运行这些示例很容易，但它们并不太适合生产使用。我们来看看为什么。</p><h2 id="1696" class="mn kg iq bd kh mo mp dn kl mq mr dp kp lg ms mt kr lk mu mv kt lo mw mx kv my bi translated">无模式方法的缺点</h2><ul class=""><li id="f330" class="lz ma iq kz b la lb ld le lg mz lk na lo nb ls me mf mg mh bi translated">生产者不能强制其发布到主题的数据格式(字段集),这可能导致消费者端的不兼容和运行时错误。当然，它可以在代码中处理，但这会使代码更加复杂，因此容易出错，需要更多的维护。</li><li id="2c2e" class="lz ma iq kz b la mi ld mj lg mk lk ml lo mm ls me mf mg mh bi translated">数据格式演化没有约束，因此生产者可以潜在地切换到新的模式，而不需要消费者期望的字段，这可能再次导致运行时错误(有关详细信息，请参见下一节)</li><li id="febf" class="lz ma iq kz b la mi ld mj lg mk lk ml lo mm ls me mf mg mh bi translated">JSON格式的数据包括每个消息的字段名，这使得它在存储空间方面效率很低</li></ul><p id="8297" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">Schemafull消息解决了这些问题，但是，它的代价是更复杂的基础设施，并且需要对模式演化非常小心。</p><h2 id="6ffd" class="mn kg iq bd kh mo mp dn kl mq mr dp kp lg ms mt kr lk mu mv kt lo mw mx kv my bi translated">AVRO图式及其演变</h2><p id="3ba0" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Kafka支持<a class="ae lt" href="https://avro.apache.org/" rel="noopener ugc nofollow" target="_blank"> AVRO </a>、<a class="ae lt" href="https://developers.google.com/protocol-buffers/" rel="noopener ugc nofollow" target="_blank"> Protobuf </a>和<a class="ae lt" href="https://json-schema.org/" rel="noopener ugc nofollow" target="_blank"> JSON-schema </a>(这仍然存在JSON数据格式非二进制且在存储方面不是很高效的缺点)。我们将在文章的代码中使用AVRO，因为这似乎是卡夫卡最常见的模式格式。</p><p id="9941" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">一旦定义，模式通常不能随意更改。提到的一个例子是字段删除或重命名。这个潜在的问题可以通过将字段定义为<code class="fe nc nd ne nf b">nullable</code>并使用<code class="fe nc nd ne nf b">default</code>值来解决，因此如果字段变得过时，生成器只需停止填充它，同时它仍保留在模式的新更新版本中:</p><pre class="ng nh ni nj gt nk nf nl nm aw nn bi"><span id="3414" class="mn kg iq nf b gy no np l nq nr">{"name": "value", "type": ["null", "double"], "default": null}</span></pre><p id="cd3e" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">其他模式进化考虑在<a class="ae lt" href="https://avro.apache.org/docs/current/spec.html" rel="noopener ugc nofollow" target="_blank"> AVRO规范</a>中有描述。</p><h1 id="6bf4" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">演示设置</h1><p id="a738" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这个库有一个Python AVRO消费者和生产者的基本例子:</p><div class="ns nt gp gr nu nv"><a href="https://github.com/isenilov/python-kafka" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd ir gy z fp oa fr fs ob fu fw ip bi translated">GitHub - isenilov/python-kafka</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">运行所有服务:docker-compose-f docker-compose . YAML up-build-d附加到应用程序的日志…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">github.com</p></div></div><div class="oe l"><div class="of l og oh oi oe oj ok nv"/></div></div></a></div><p id="1025" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">让我们回顾一下它所包含的服务，查看<code class="fe nc nd ne nf b">docker-compose.yaml</code>的<code class="fe nc nd ne nf b">services</code>部分</p><h2 id="699d" class="mn kg iq bd kh mo mp dn kl mq mr dp kp lg ms mt kr lk mu mv kt lo mw mx kv my bi translated">动物园管理员</h2><p id="c180" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><a class="ae lt" href="https://zookeeper.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache ZooKeeper </a>由Kafka用于在一个集中的位置维护配置，并且是Kafka集群工作的先决条件。消费者和生产者通常不与它直接交互，所以我们在这里省略了它的详细描述。</p><h2 id="debb" class="mn kg iq bd kh mo mp dn kl mq mr dp kp lg ms mt kr lk mu mv kt lo mw mx kv my bi translated">图式注册表</h2><figure class="ng nh ni nj gt om gh gi paragraph-image"><div role="button" tabindex="0" class="on oo di op bf oq"><div class="gh gi ol"><img src="../Images/f778cb448bd8d3eed52a24f5aaf90bde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ciiDGn3WCvX1vGS0.png"/></div></div><p class="os ot gj gh gi ou ov bd b be z dk translated"><em class="ow">用于存储和检索模式的汇合模式注册表(</em> <a class="ae lt" href="https://docs.confluent.io/platform/current/schema-registry/index.html" rel="noopener ugc nofollow" target="_blank"> <em class="ow">来源</em> </a> <em class="ow"> ) </em></p></figure><p id="419b" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated"><a class="ae lt" href="https://docs.confluent.io/platform/current/schema-registry/index.html" rel="noopener ugc nofollow" target="_blank">汇合模式注册中心</a>是一个用于存储和检索模式的服务。显然，人们可以使用Kafka，而不仅仅是拥有模式和应用程序代码，但是模式注册中心确保了所有消费者和生产者的版本化模式的单一真实来源，排除了这些消费者和生产者之间模式偏差的可能性。</p><p id="e1d5" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">注册表既有RESTful API，也有由<a class="ae lt" href="https://github.com/confluentinc/confluent-kafka-python" rel="noopener ugc nofollow" target="_blank"> confluent-kafka-client </a>提供的本地支持，这实际上是在Python中使用kafka的标准。</p><p id="67e4" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">可以通过HTTP请求注册模式，如下所示:</p><pre class="ng nh ni nj gt nk nf nl nm aw nn bi"><span id="9d78" class="mn kg iq nf b gy no np l nq nr">SCHEMA=$(sed 's/"/\\"/g' &lt; ./Message.avsc)<br/><br/>curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \<br/>  --data "{\"schema\":\"${SCHEMA//$'\n'}\"}" \<br/>  http://&lt;registry_host&gt;:&lt;registry_port&gt;/subjects/&lt;name&gt;/versions</span></pre><p id="1d33" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">它应该返回模式注册的id(版本):<code class="fe nc nd ne nf b">{“id”:1}</code></p><p id="6256" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">使用Python代码中的模式可以通过从前面提到的客户端实例化<code class="fe nc nd ne nf b">AvroSerializer</code>和<code class="fe nc nd ne nf b">AvroDeserializer</code>来完成。</p><h2 id="5ac8" class="mn kg iq bd kh mo mp dn kl mq mr dp kp lg ms mt kr lk mu mv kt lo mw mx kv my bi translated">卡夫卡</h2><p id="cbe5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><a class="ae lt" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Kafka </a>集群本身使用来自汇合的<a class="ae lt" href="https://hub.docker.com/r/confluentinc/cp-kafka/" rel="noopener ugc nofollow" target="_blank"> Docker映像运行，该映像具有其运行所需的一切。<br/>它有许多配置选项，但我们仅限于基本的工作选项，例如，<code class="fe nc nd ne nf b">PLAINTEXT</code>协议不执行任何加密。</a></p><h2 id="08a7" class="mn kg iq bd kh mo mp dn kl mq mr dp kp lg ms mt kr lk mu mv kt lo mw mx kv my bi translated">init-卡夫卡</h2><p id="2cdd" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这是Kafka的一个短暂实例，仅用于创建我们计划在使用<code class="fe nc nd ne nf b">kafka-topics</code> CLI的演示中使用的主题:</p><pre class="ng nh ni nj gt nk nf nl nm aw nn bi"><span id="c150" class="mn kg iq nf b gy no np l nq nr">kafka-topics --create --if-not-exists --topic Test.Topic --bootstrap-server kafka:29092 --replication-factor 1 --partitions 1</span></pre><p id="66a6" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">为了简单起见，将<code class="fe nc nd ne nf b">replication-factor</code>和<code class="fe nc nd ne nf b">partitions</code>选项设置为1。参考<a class="ae lt" href="https://kafka.apache.org/documentation/" rel="noopener ugc nofollow" target="_blank"> Kafka文档</a>了解更多关于这些和更多其他选项的细节。</p><h2 id="d4f5" class="mn kg iq bd kh mo mp dn kl mq mr dp kp lg ms mt kr lk mu mv kt lo mw mx kv my bi translated">工人</h2><p id="4f62" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这是消费和生产应用程序本身。为了简单起见，消费者和生产者都在<code class="fe nc nd ne nf b">__main__.py</code>中。代码大部分是不言自明的，所以让我们只看它的一些重要部分。</p><p id="a010" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated"><strong class="kz ir">生产者配置:</strong></p><pre class="ng nh ni nj gt nk nf nl nm aw nn bi"><span id="21c0" class="mn kg iq nf b gy no np l nq nr">"value.serializer": AvroSerializer(schema_str=Message.schema,<br/>schema_registry_client=schema_registry_client, to_dict=todict)</span></pre><p id="0876" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated"><code class="fe nc nd ne nf b">schema_str=Message.schema</code> — producer需要传递一个模式，这里我们传递包含该模式的生成的Python类的属性。模式将在<code class="fe nc nd ne nf b">schema_registry_client</code>中上传和注册。</p><p id="1ddd" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated"><code class="fe nc nd ne nf b">to_dict=todict</code> —这必须是将消息对象转换为Python字典的可调用对象。我们使用来自生成代码的<code class="fe nc nd ne nf b">helpers.py</code>的<code class="fe nc nd ne nf b">todict</code>方法。</p><p id="9d48" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated"><strong class="kz ir">消费者配置:</strong></p><pre class="ng nh ni nj gt nk nf nl nm aw nn bi"><span id="0bf5" class="mn kg iq nf b gy no np l nq nr">"value.deserializer": AvroDeserializer(schema_str=None, schema_registry_client=schema_registry_client,<br/>from_dict=lambda obj, _: Message(obj))</span></pre><p id="47ff" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">这里我们不传递模式，所以<code class="fe nc nd ne nf b">schema_registry_client</code>将从模式注册中心获取它。<br/> <code class="fe nc nd ne nf b">from_dict=lambda obj, _: Message(obj)</code> —将字典转换为消息对象的相反操作。这里我们需要做一点修改，因为反序列化器将context作为第二个参数传递给callable(我们忽略了它)，但是生成的类构造函数只接受字典。</p><pre class="ng nh ni nj gt nk nf nl nm aw nn bi"><span id="b7a8" class="mn kg iq nf b gy no np l nq nr">"group.id": "test_group"</span></pre><p id="a689" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated"><code class="fe nc nd ne nf b">“group.id”</code>。这允许共享相同消费者组ID的多个消费者(读取具有数据处理应用程序的多个容器以进行水平缩放)轮流消费消息，因为他们共享<a class="ae lt" href="https://docs.confluent.io/platform/current/clients/consumer.html#offset-management" rel="noopener ugc nofollow" target="_blank"> Kafka偏移量</a>。同时，如果需要将这些消息用于其他目的，例如，在线测试一个实验性的ML模型，可以通过使用新的<code class="fe nc nd ne nf b">group.id</code>部署这个实验组来完成，从而避免与主要的产品结构混淆。</p><h1 id="cd50" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">运行演示</h1><p id="9cf1" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">存储库的<code class="fe nc nd ne nf b">README.md</code>有使用<code class="fe nc nd ne nf b">docker-compose</code>运行所有服务的指令。执行这些命令应该会在stdout中产生类似这样的结果:</p><pre class="ng nh ni nj gt nk nf nl nm aw nn bi"><span id="44a6" class="mn kg iq nf b gy no np l nq nr">worker_1  | Waiting for schema registry to be available<br/>worker_1  | Producing message to topic 'Test.Topic'<br/>worker_1  | Produced message: {'timestamp': 1639304378, 'data': {'count': 10, 'value': 100.0}}<br/>worker_1  | <br/>worker_1  | Flushing records...<br/>worker_1  | Consumed message: {'timestamp': 1639304378, 'data': {'count': 10, 'value': 100.0}}</span></pre><p id="93d4" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">这意味着生产和消费是成功执行的。</p><p id="9c07" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">我们打印消费的消息:</p><pre class="ng nh ni nj gt nk nf nl nm aw nn bi"><span id="5ce9" class="mn kg iq nf b gy no np l nq nr">if message is not None:<br/>    print(f"Consumed message: {message.dict()}")</span></pre><p id="8d6f" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">但是，这是推理代码通常随后将结果预测发布到另一个主题、将它们保存到数据库或在下游API调用中使用它们的地方。</p><h1 id="0674" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">监视</h1><p id="8eee" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">一般来说，对Kafka消费ML服务的监控类似于在<a class="ae lt" rel="noopener" target="_blank" href="/complete-machine-learning-pipeline-for-nlp-tasks-f39f8b395c0d">NLP任务的完整机器学习管道</a>文章中所描述的。</p><p id="8c32" class="pw-post-body-paragraph kx ky iq kz b la lu jr lc ld lv ju lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">然而，推断时间可以(并且可能应该)伴随着消费者滞后，这表明消费者落后于公布的数据多少。如果增长，通常意味着消费者群体必须扩大。当使用基于<code class="fe nc nd ne nf b"><a class="ae lt" href="https://github.com/edenhill/librdkafka#language-bindings" rel="noopener ugc nofollow" target="_blank">librdkafka</a></code> <a class="ae lt" href="https://github.com/edenhill/librdkafka#language-bindings" rel="noopener ugc nofollow" target="_blank">的</a>客户端时，如本例中使用的<code class="fe nc nd ne nf b">confluent-kafka-python</code>，可以使用<code class="fe nc nd ne nf b">librdkafka</code>返回的<a class="ae lt" href="https://github.com/edenhill/librdkafka/blob/master/STATISTICS.md" rel="noopener ugc nofollow" target="_blank">统计数据</a>来获得消费者滞后，如<a class="ae lt" href="https://github.com/confluentinc/confluent-kafka-python/issues/670" rel="noopener ugc nofollow" target="_blank">本期</a>所述。</p><h1 id="325b" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">结论</h1><p id="e988" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">本文展示了为什么在Kafka中使用模式可能是一个好主意，以及如何使用Python(ML服务的首选语言)来实现它。一如既往，如果您对内容有任何问题或建议，请随时通过LinkedIn联系我。</p></div></div>    
</body>
</html>