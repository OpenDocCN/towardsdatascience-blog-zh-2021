<html>
<head>
<title>Announcing YOLTv4: Improved Satellite Imagery Object Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">宣布YOLTv4:改进的卫星图像目标探测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/announcing-yoltv4-improved-satellite-imagery-object-detection-f5091e913fad?source=collection_archive---------10-----------------------#2021-04-27">https://towardsdatascience.com/announcing-yoltv4-improved-satellite-imagery-object-detection-f5091e913fad?source=collection_archive---------10-----------------------#2021-04-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/f4010154d8a1e61cc4119859cca16a18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I5x4dVSdLmZ50iEHkkRAqw.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="e5e1" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">将高级目标探测扩展到任意大的卫星图像</h2></div><p id="3e30" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><em class="lm">前言:虽然</em> <a class="ae ln" href="http://7sux*GCLNtH%25N3mF" rel="noopener ugc nofollow" target="_blank"> <em class="lm"> CosmiQ作品</em> </a> <em class="lm">(及其相关博客:</em><a class="ae ln" href="https://medium.com/the-downlinq" rel="noopener"><em class="lm">The DownLinQ</em></a><em class="lm">)不幸被关闭，但在地理空间分析领域仍有许多工作要做。因此，这篇博客详细描述了IQT在业余时间独立完成的</em><a class="ae ln" href="https://www.iqt.org" rel="noopener ugc nofollow" target="_blank"><em class="lm"/></a><em class="lm">工作。</em></p><p id="1abb" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在之前的一些博客[如<a class="ae ln" href="https://medium.com/the-downlinq/you-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-38dad1cf7571" rel="noopener"> 1 </a>、<a class="ae ln" href="https://medium.com/the-downlinq/car-localization-and-counting-with-overhead-imagery-an-interactive-exploration-9d5a029a596b" rel="noopener"> 2 </a>、<a class="ae ln" href="https://medium.com/the-downlinq/simrdwn-adapting-multiple-object-detection-frameworks-for-satellite-imagery-applications-991dbf3d022b" rel="noopener"> 3 </a> ]和学术论文[如<a class="ae ln" href="https://arxiv.org/abs/1805.09512" rel="noopener ugc nofollow" target="_blank"> 4 </a>、<a class="ae ln" href="https://arxiv.org/abs/1809.09978" rel="noopener ugc nofollow" target="_blank"> 5 </a>、<a class="ae ln" href="https://arxiv.org/abs/1812.04098" rel="noopener ugc nofollow" target="_blank"> 6 </a> ]中，我们已经展示了采用<a class="ae ln" href="https://pjreddie.com/darknet/yolo/" rel="noopener ugc nofollow" target="_blank"> YOLO </a>探测卫星图像中的物体的惊人功效。回想一下，YOLO是一个领先的深度学习对象检测框架，旨在检测图像中的对象。YOLO最大限度地利用了几千像素大小的图像，这对于处理超过1亿像素的大规模卫星图像来说太小了。因此，我们构建了<a class="ae ln" href="https://github.com/avanetten/yolt" rel="noopener ugc nofollow" target="_blank"> YOLT </a>(并用<a class="ae ln" href="https://github.com/avanetten/simrdwn" rel="noopener ugc nofollow" target="_blank"> SIMRDWN </a>扩展了YOLT)来优化这个任意大尺寸卫星图像的目标检测框架。</p><p id="574e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们现在很高兴地宣布，一个更快、性能更好的改进版本<a class="ae ln" href="http://www.apple.com" rel="noopener ugc nofollow" target="_blank"> YOLTv4 </a>已经发布。代码在github.com/avanetten/yoltv4的<a class="ae ln" href="https://github.com/avanetten/yoltv4" rel="noopener ugc nofollow" target="_blank">开源。在下面的小节中，我们将详细介绍这个新的存储库，并提供示例结果。</a></p><p id="ef88" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc"> 1。简介</strong></p><p id="46d0" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">YOLTv4旨在快速检测航空或卫星图像中任意大图像的对象，这些图像远远超过深度学习对象检测框架通常摄取的约600×600像素大小。这个库建立在AlexeyAB的<a class="ae ln" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank"> YOLOv4 </a>实现的令人印象深刻的工作之上，与YOLOv3(在SIMRDWN中实现)相比，它提高了速度和检测性能。我们用YOLOv4代替YOLOv5，因为YOLOv4得到了YOLO原创者的认可，而YOLOv5没有；此外，YOLOv4似乎具有优越的性能。</p><p id="2689" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">因此，YOLTv4将令人印象深刻的YOLOv4主干与SIMRDWN的预处理和后处理脚本结合起来，创建了一个改进的、轻量级的替代SIMRDWN。回想一下，SIMRDWN允许用户从众多主干中进行选择(例如，YOLO、固态硬盘、fast-RCNN等。).虽然这种灵活性非常有用，但它确实扩大了代码库；此外，多项研究[ <a class="ae ln" href="https://arxiv.org/abs/1809.09978" rel="noopener ugc nofollow" target="_blank"> 5 </a>，<a class="ae ln" href="https://arxiv.org/abs/1812.04098" rel="noopener ugc nofollow" target="_blank"> 6 </a> ]表明，YOLO骨干网在卫星图像目标检测方面优于其他方法。因此，在YOLTv4中，我们选择构建一个更简单的代码库，并且只关注YOLOv4的主干。</p><p id="9f43" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">下面，我们提供了如何使用开源<a class="ae ln" href="https://registry.opendata.aws/rareplanes/" rel="noopener ugc nofollow" target="_blank">稀有面</a>数据集的例子。</p><h2 id="2da5" class="lo lp jb bd lq lr ls dn lt lu lv dp lw kz lx ly lz ld ma mb mc lh md me mf mg bi translated"><strong class="ak"> 2。运行YOLTv4 </strong></h2><p id="41a9" class="pw-post-body-paragraph kq kr jb ks b kt mh kc kv kw mi kf ky kz mj lb lc ld mk lf lg lh ml lj lk ll ij bi translated">在本节中，我们将演示如何使用稀疏飞机数据集来训练和测试YOLTv4，以定位飞机。</p><p id="9e99" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc"> 2.1。安装</strong></p><p id="9450" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">YOLTv4构建为在支持GPU的机器上的docker容器中执行。docker命令使用CUDA 9.2、python 3.6和conda创建Ubuntu 16.04映像。</p><ol class=""><li id="35e7" class="mm mn jb ks b kt ku kw kx kz mo ld mp lh mq ll mr ms mt mu bi translated">克隆这个库(例如克隆到<em class="lm"> /yoltv4/ </em>)。</li><li id="b625" class="mm mn jb ks b kt mv kw mw kz mx ld my lh mz ll mr ms mt mu bi translated">将模型重量下载到<em class="lm"> yoltv4/darknet/weights(如见:</em><a class="ae ln" href="https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137" rel="noopener ugc nofollow" target="_blank">https://github . com/AlexeyAB/dark net/releases/download/dark net _ yolo _ v3 _ optimal/yolov 4 . conv . 137</a>)。</li><li id="9c8f" class="mm mn jb ks b kt mv kw mw kz mx ld my lh mz ll mr ms mt mu bi translated">安装<a class="ae ln" href="https://github.com/NVIDIA/nvidia-docker" rel="noopener ugc nofollow" target="_blank"> nvidia-docker </a>。</li><li id="dd56" class="mm mn jb ks b kt mv kw mw kz mx ld my lh mz ll mr ms mt mu bi translated">构建docker文件。<code class="fe na nb nc nd b">nvidia-docker build -t yoltv4_image /yoltv4/docker</code></li><li id="4ef4" class="mm mn jb ks b kt mv kw mw kz mx ld my lh mz ll mr ms mt mu bi translated">旋转对接容器(选项见<a class="ae ln" href="https://docs.docker.com/engine/reference/commandline/run/" rel="noopener ugc nofollow" target="_blank">对接文件</a>)。<code class="fe na nb nc nd b">nvidia-docker run -it -v /yoltv4:/yoltv4 -ti — ipc=host — name yoltv4_gpu0 yoltv4_image</code></li><li id="6898" class="mm mn jb ks b kt mv kw mw kz mx ld my lh mz ll mr ms mt mu bi translated">编译Darknet C程序。先在<em class="lm">/yoltv 4/darknet/Makefile</em>中设置GPU=1 CUDNN=1，CUDNN_HALF=1，OPENCV=1，然后:<br/> <code class="fe na nb nc nd b">cd /yoltv4/darknet <br/> make</code></li></ol><p id="8d76" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc"> 2.2。列车</strong></p><p id="ddff" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc"> A .准备数据</strong></p><ol class=""><li id="aeee" class="mm mn jb ks b kt ku kw kx kz mo ld mp lh mq ll mr ms mt mu bi translated">制作YOLO图像和标签(详见<em class="lm">yoltv 4/notebooks/prep _ data . ipynb</em>)。</li><li id="7cc4" class="mm mn jb ks b kt mv kw mw kz mx ld my lh mz ll mr ms mt mu bi translated">创建一个列出训练图像的txt文件。</li><li id="f6b6" class="mm mn jb ks b kt mv kw mw kz mx ld my lh mz ll mr ms mt mu bi translated">创建文件obj.names文件，每个所需的对象名称各占一行。</li><li id="e5c4" class="mm mn jb ks b kt mv kw mw kz mx ld my lh mz ll mr ms mt mu bi translated">在包含必要文件的目录<em class="lm"> yoltv4/darknet/data </em>中创建文件obj.data。例如<em class="lm">/yoltv 4/darknet/data/rare planes _ train . data:<br/></em>classes = 30<br/>train =/local _ data/cosm IQ/wdata/rare planes/train/txt<br/>valid =/local _ data/cosm IQ/wdata/rare planes/train/txt/valid . txt<br/>names =/yoltv 4/darknet/data/rare planes . name<br/>backup = backup</li><li id="ee55" class="mm mn jb ks b kt mv kw mw kz mx ld my lh mz ll mr ms mt mu bi translated">准备配置文件。<br/>参见此处的说明<a class="ae ln" href="https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects" rel="noopener ugc nofollow" target="_blank"/>，或者调整<em class="lm">/yoltv 4/darknet/CFG/yoltv 4 _ rare planes . CFG</em>。</li></ol><p id="85e0" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc"> B .执行培训</strong></p><ol class=""><li id="2e07" class="mm mn jb ks b kt ku kw kx kz mo ld mp lh mq ll mr ms mt mu bi translated">执行。<br/> <code class="fe na nb nc nd b">cd /yoltv4/darknet <br/> time ./darknet detector train data/rareplanes_train.data cfg/yoltv4_rareplanes.cfg weights/yolov4.conv.137 -dont_show -mjpeg_port 8090 -map</code></li><li id="ec33" class="mm mn jb ks b kt mv kw mw kz mx ld my lh mz ll mr ms mt mu bi translated">审查进度(见下图1):</li></ol><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/3675482727193244b3843380e9649596.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*seThoyeviSb6Mje4z-R7Yw.png"/></div></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">图一。YOLTv4训练进度(保存为<em class="nn">/yolt v4/darknet/chart _ yolt v4 _ rare planes . png</em>)</p></figure><p id="75b9" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc"> 2.3。测试</strong></p><p id="d90c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc"> A .准备数据</strong></p><ol class=""><li id="8291" class="mm mn jb ks b kt ku kw kx kz mo ld mp lh mq ll mr ms mt mu bi translated">制作切片图像(详见<em class="lm">yoltv 4/notebooks/prep _ data . ipynb</em>)。</li><li id="cc28" class="mm mn jb ks b kt mv kw mw kz mx ld my lh mz ll mr ms mt mu bi translated">创建一个列出训练图像的txt文件。</li><li id="edcd" class="mm mn jb ks b kt mv kw mw kz mx ld my lh mz ll mr ms mt mu bi translated">在包含必要文件的目录<em class="lm"> yoltv4/darknet/data </em>中创建文件obj.data。例如<em class="lm">/yoltv 4/darknet/data/rare planes _ test . data:</em><br/>classes = 30<br/>train =<br/>valid =/local _ data/cosm IQ/wdata/rare planes/test/txt/test . txt<br/>names =/yoltv 4/darknet/data/rare planes . name<br/>backup = backup/</li></ol><p id="6a8b" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc"> B .执行测试</strong></p><ol class=""><li id="2f19" class="mm mn jb ks b kt ku kw kx kz mo ld mp lh mq ll mr ms mt mu bi translated">执行(在特斯拉P100上以每秒80帧以上的速度进行):<br/> <code class="fe na nb nc nd b">cd /yoltv4/darknet</code></li><li id="f117" class="mm mn jb ks b kt mv kw mw kz mx ld my lh mz ll mr ms mt mu bi translated"><code class="fe na nb nc nd b">time ./darknet detector valid data/rareplanes_test.data cfg/yoltv4_rareplanes.cfg backup/ yoltv4_rareplanes_best.weights</code></li><li id="47fb" class="mm mn jb ks b kt mv kw mw kz mx ld my lh mz ll mr ms mt mu bi translated">后处理检测，将图像拼接在一起，并制作绘图:</li></ol><pre class="nf ng nh ni gt no nd np nq aw nr bi"><span id="cd16" class="lo lp jb nd b gy ns nt l nu nv">time python /yoltv4/yoltv4/post_process.py \<br/> — pred_dir=/yoltv4/darknet/results/rareplanes_preds_v0/orig_txt/ \<br/> — raw_im_dir=/local_data/cosmiq/wdata/rareplanes/test/images/ \<br/> — sliced_im_dir= /local_data/cosmiq/wdata/rareplanes/test/yoltv4/images_slice/ \<br/> — out_dir= /yoltv4/darknet/results/rareplanes_preds_v0 \<br/> — detection_thresh=0.25 \<br/> — slice_size=416 \<br/> — n_plots=8</span></pre><h2 id="4b24" class="lo lp jb bd lq lr ls dn lt lu lv dp lw kz lx ly lz ld ma mb mc lh md me mf mg bi translated"><strong class="ak"> 3。输出</strong></h2><p id="2d50" class="pw-post-body-paragraph kq kr jb ks b kt mh kc kv kw mi kf ky kz mj lb lc ld mk lf lg lh ml lj lk ll ij bi translated">输出将类似于下图。</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nw"><img src="../Images/806ec45b59643830f330ab383acf3a9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lsRQt1rAFKWJ6CuL2QBJ_g.jpeg"/></div></div></figure><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nx"><img src="../Images/5b6202faa60c2cdfa9335d1c1e74c143.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gTIn45ctKwzkry4MGZmGWg.jpeg"/></div></div></figure><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ny"><img src="../Images/19609f1dfe54db9b42eefd21fd82d19b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sB029RovCkRKQgt5ae6_2Q.jpeg"/></div></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">图二。从开源的<a class="ae ln" href="https://registry.opendata.aws/rareplanes/" rel="noopener ugc nofollow" target="_blank">稀有飞机</a>数据集中检测到飞机。</p></figure><h2 id="c4ed" class="lo lp jb bd lq lr ls dn lt lu lv dp lw kz lx ly lz ld ma mb mc lh md me mf mg bi translated"><strong class="ak"> 4。结论</strong></h2><p id="daf2" class="pw-post-body-paragraph kq kr jb ks b kt mh kc kv kw mi kf ky kz mj lb lc ld mk lf lg lh ml lj lk ll ij bi translated">YOLTv4是高性能和相当迅速的。在单个特斯拉P100 GPU上，即使在最高分辨率的30厘米卫星图像上，推理也能以每秒约2平方公里的速度进行。以这种速度，一个简单的4-gpu集群可以近乎实时地处理整个<a class="ae ln" href="http://www.apple.com" rel="noopener ugc nofollow" target="_blank"> WorldView-3 </a>收集。所以，请随意旋转<a class="ae ln" href="https://github.com/CosmiQ/yoltv4" rel="noopener ugc nofollow" target="_blank">代码</a>来寻找<a class="ae ln" href="https://medium.com/the-downlinq/car-localization-and-counting-with-overhead-imagery-an-interactive-exploration-9d5a029a596b" rel="noopener">汽车</a>、<a class="ae ln" href="https://medium.com/the-downlinq/yolt-arxiv-paper-and-code-release-8b30d40d095b" rel="noopener">船只</a>、<a class="ae ln" href="https://medium.com/the-downlinq/you-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-34f72f659588" rel="noopener">基础设施项目</a>、<a class="ae ln" href="https://medium.com/the-downlinq/simrdwn-adapting-multiple-object-detection-frameworks-for-satellite-imagery-applications-991dbf3d022b" rel="noopener">飞机</a>、<a class="ae ln" href="https://medium.com/the-downlinq/building-extraction-with-yolt2-and-spacenet-data-a926f9ffac4f" rel="noopener">建筑</a>，或者任何你感兴趣的东西。</p></div></div>    
</body>
</html>