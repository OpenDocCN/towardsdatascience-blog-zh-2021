<html>
<head>
<title>Hyperopt Tutorial: Optimise Your Hyperparameter Tuning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">远视教程:优化您的超参数调谐</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/optimise-your-hyperparameter-tuning-with-hyperopt-861573239eb5?source=collection_archive---------8-----------------------#2021-11-05">https://towardsdatascience.com/optimise-your-hyperparameter-tuning-with-hyperopt-861573239eb5?source=collection_archive---------8-----------------------#2021-11-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="14c8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 Hyperopt 的贝叶斯超参数调整的简单解释和实现</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/164b0d53f6ffe5f26482c2f4d3b84a80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DJ9cEqxOM-J665e5"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">约书亚·阿拉贡在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="6a2c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="cd33" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">超参数调整</strong> </a>是数据科学和机器学习工作流的一个重要组成部分，因为它可以挤压模型所能提供的最佳性能。因此，您选择执行超参数调整的方法非常重要。<strong class="lt iu">网格搜索</strong>是穷尽式的，而<strong class="lt iu">随机搜索</strong>是完全随机的，因此可能会错过最重要的值。但是，通过<strong class="lt iu">hyperpt</strong>包有一个更好的方法！</p><p id="a006" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> Hyperopt </strong>是一个开源的超参数调整库，它使用<strong class="lt iu">贝叶斯</strong>方法来寻找超参数的最佳值。我不打算深入这个贝叶斯方法如何工作的理论细节，主要是因为它需要另一整篇文章来充分解释！然而，感兴趣的读者可以在这里查看文档<a class="ae ky" href="http://hyperopt.github.io/hyperopt/" rel="noopener ugc nofollow" target="_blank"><strong class="lt iu"/></a><strong class="lt iu"/>，如果你感兴趣的话，还有几篇关于这个主题的研究论文。</p><p id="7283" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在本文中，我们将把一个<strong class="lt iu"> RandomForestClassifier </strong>模型拟合到 Kaggle 提供的<a class="ae ky" href="https://www.kaggle.com/adityakadiwal/water-potability" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">水质</strong> </a> (CC0 域)数据集。然后，我们将使用<strong class="lt iu">hyperpt 调整模型的超参数。</strong></p><h2 id="df5f" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">符合简单模型</h2><p id="598c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">首先，我们读入数据，并为我们的训练集拟合一个简单的<strong class="lt iu"> RandomForestClassifier </strong>模型:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="6332" class="ms la it nf b gy nj nk l nl nm"># read in packages<br/>import matplotlib.pyplot as plt<br/>import pandas as pd<br/>import numpy as np<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.metrics import accuracy_score</span><span id="7732" class="ms la it nf b gy nn nk l nl nm"># read in the data and info<br/>data = pd.read_csv('../input/water-potability/water_potability.csv')</span><span id="f628" class="ms la it nf b gy nn nk l nl nm"># remove missing values<br/>data = data.dropna()</span><span id="fa70" class="ms la it nf b gy nn nk l nl nm"># split to train and test<br/>X = data.drop(['Potability'], axis = 1)<br/>y = data['Potability']<br/>x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=200)</span><span id="7784" class="ms la it nf b gy nn nk l nl nm"># build the model<br/>model = RandomForestClassifier(n_estimators=300, max_features='sqrt', random_state=42)<br/>model.fit(x_train, y_train)<br/>y_pred = model.predict(x_test)</span><span id="1d7e" class="ms la it nf b gy nn nk l nl nm"># print out the score accuracy<br/>print("Accuracy:", accuracy_score(y_test, y_pred))</span></pre><p id="5a24" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">运行上面的代码会产生 67.24% 的精确度。这是可以的，但我们可以通过超参数调整来改善这一点！</p><h2 id="411c" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">设置 Hyperopt</h2><p id="7760" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">要使用 Hyperopt，我们需要为我们的模型指定四个关键要素:</p><ol class=""><li id="4cc6" class="no np it lt b lu mn lx mo ma nq me nr mi ns mm nt nu nv nw bi translated"><strong class="lt iu">目标函数| </strong>这将返回我们希望在计算过程中最小化的值。在我们的例子中，它是“accuracy_score”函数。</li><li id="6e61" class="no np it lt b lu nx lx ny ma nz me oa mi ob mm nt nu nv nw bi translated"><strong class="lt iu">搜索空间| </strong>这定义了给定超参数的取值范围。这可以是整数、浮点数或字符串，我们将在本文后面看到。</li><li id="2c20" class="no np it lt b lu nx lx ny ma nz me oa mi ob mm nt nu nv nw bi translated"><strong class="lt iu">调优算法| </strong>在 Hyperopt 中，有两种主要的超参数搜索算法:随机搜索和 Parzen 估计器树(贝叶斯)。在本例中，我们将使用后者，因为它已知会产生最佳结果。</li><li id="2762" class="no np it lt b lu nx lx ny ma nz me oa mi ob mm nt nu nv nw bi translated"><strong class="lt iu">评估| </strong>这是指训练模型的不同超参数实例的数量。建议这是搜索空间中定义的超参数数量的 10-30 倍，以优化性能和计算时间。</li></ol><p id="4fc4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在下一节中，我们将展示一个示例，说明如何为我们上面创建的简单随机森林模型实现上述步骤。</p><h2 id="a5bb" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">具有一个超参数的远视</h2><p id="fc2e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本例中，我们将只调整一个超参数，即<strong class="lt iu">‘n _ estimators’</strong></p><p id="8c4b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在 Hyperopt 中首次阅读:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="f4e8" class="ms la it nf b gy nj nk l nl nm"># read in hyperopt values<br/>from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK</span></pre><p id="b2cc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在我们定义我们的目标函数。这将只是“n_estimators”的一个函数，它将返回从<strong class="lt iu">“accuracy _ score”</strong>函数推断出的<strong class="lt iu">减去精度</strong>。我们取负值精度的原因是因为<strong class="lt iu"> Hyperopt 的目标是最小化目标</strong>，因此我们的精度需要为负，我们可以在最后使其为正。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="159e" class="ms la it nf b gy nj nk l nl nm"># define the function we want to minimise<br/>def objective(n_estimators):<br/>    model = RandomForestClassifier(n_estimators=n_estimators,<br/>                                   max_features='sqrt',<br/>                                   random_state=42)</span><span id="e9c1" class="ms la it nf b gy nn nk l nl nm">    model.fit(x_train, y_train)<br/>    y_pred = model.predict(x_test)<br/>    accuracy = accuracy_score(y_test, y_pred)<br/>    return {'loss': -accuracy, 'status': STATUS_OK}</span></pre><p id="c521" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">定义‘n _ estimators’的搜索空间:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="42a6" class="ms la it nf b gy nj nk l nl nm"># define the values to search over for n_estimators<br/>search_space = hp.randint('n_estimators', 200, 1000)</span></pre><p id="c1bb" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这里，<strong class="lt iu"> 'hp.randint' </strong>在给定的范围内给' n_estimators '分配一个随机整数，在这种情况下是 200 到 1000。</p><p id="703f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">指定算法:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="4518" class="ms la it nf b gy nj nk l nl nm"># set the hyperparam tuning algorithm<br/>algorithm=tpe.suggest</span></pre><p id="3da4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这意味着 Hyperopt 将使用“<strong class="lt iu">Parzen 估计器树”(tpe) </strong>，这是一种贝叶斯方法。</p><p id="485c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最后，我们使用<strong class="lt iu">‘fmin’</strong>函数将它结合起来。‘<strong class="lt iu">fn’</strong>功能目标是最小化分配给它的功能，这是上面定义的目标。另外，<strong class="lt iu">‘max _ evals’</strong>指的是我们要测试的不同超参数的数量，这里我任意设置为 200。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="f1db" class="ms la it nf b gy nj nk l nl nm">best_params = fmin(<br/>  fn=objective,<br/>  space=search_space,<br/>  algo=algorithm,<br/>  max_evals=200)</span></pre><p id="842e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">生成的代码块的输出如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/16a484d8033bd4b94816ce112c7e9c84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*305CUk2ChHJSX1wEn2v89Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="13dd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们看到我们的准确率提高到了 68.5% ！然后我们可以调用<strong class="lt iu">‘best _ params’</strong>来找到产生该模型的‘n _ estimators’的相应值:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="0bc4" class="ms la it nf b gy nj nk l nl nm">print(best_params)</span></pre><p id="76ec" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">输出是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/7a2324d1d053eb2bed6803ea008d9b1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:346/format:webp/1*lc34Ads1RwXZFR3mRswOOw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><h2 id="7870" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">调整多个超参数</h2><p id="2c38" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">使用与上面相同的想法，我们可以将<strong class="lt iu">多个参数</strong>作为字典传递到目标函数中。下面的代码块显示了这一点的实现:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="3bd8" class="ms la it nf b gy nj nk l nl nm"># redefine the function usng a wider range of hyperparameters<br/>def objective(search_space):<br/>    model = RandomForestClassifier(**search_space, random_state=42)<br/>    model.fit(x_train, y_train)<br/>    y_pred = model.predict(x_test)<br/>    accuracy = accuracy_score(y_test, y_pred)<br/>    return {'loss': -accuracy, 'status': STATUS_OK}</span><span id="58e1" class="ms la it nf b gy nn nk l nl nm"># new search space<br/>search_space={'n_estimators':hp.randint('n_estimators',200,1000),<br/>              <br/>              'max_depth': hp.randint('max_depth',10,200),           <br/>            <br/>            'min_samples_split':hp.uniform('min_samples_split',0,1),   </span><span id="8713" class="ms la it nf b gy nn nk l nl nm">             'min_samples_leaf':hp.randint('min_samples_leaf',1,10),<br/>              <br/>               'criterion':hp.choice('criterion'['gini','entropy']),<br/>                <br/>           'max_features':hp.choice('max_features',['sqrt', 'log2']) }</span><span id="a7a2" class="ms la it nf b gy nn nk l nl nm"># implement Hyperopt<br/>best_params = fmin(<br/>  fn=objective,<br/>  space=search_space,<br/>  algo=algorithm,<br/>  max_evals=200)</span></pre><p id="ec34" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> <em class="oe">注意|</em></strong><em class="oe">* * search _ space 意味着我们在这个字典中读入键值对作为 RandomForestClassifier 类内部的参数。</em></p><p id="3d25" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在这个搜索空间中，除了<strong class="lt iu">‘HP . randint’</strong>之外，我们还使用了<strong class="lt iu">‘HP . uniform’</strong>和’<strong class="lt iu">HP . choice .’</strong>前者选择指定范围内的任意浮点数，后者从指定字符串中选择一个值。</p><p id="5814" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">该计算的输出是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/c98bf00801832ef6ba455d251e279235.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*mpfeF03pe44FrEv_Hax3tw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="34a2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">精确度提高到了 69.5%！</p><p id="fadd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然后我们可以调用<strong class="lt iu">‘space _ evals’</strong>函数来输出我们模型的最佳超参数。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="5e5f" class="ms la it nf b gy nj nk l nl nm">space_eval(search_space, best_params)</span></pre><p id="59a5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">输出是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/16cd894f84758411d89070701db105c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*gCe4iklbVd8Hq3b07SBPKQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="fe20" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> <em class="oe">注意</em> </strong> <em class="oe"> |如果你不使用‘space _ eval’而只是打印字典，它只会给你分类特征的索引，而不是它们的实际名称。</em></p><p id="0077" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们走吧！我们刚刚使用 Hyperopt 调整了我们的模型，一点也不困难！</p></div><div class="ab cl oh oi hx oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="im in io ip iq"><p id="23bb" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">希望你喜欢这篇关于如何简单实现 Hyperopt 的文章！</p><blockquote class="oo op oq"><p id="4263" class="lr ls oe lt b lu mn ju lw lx mo jx lz or mp mc md os mq mg mh ot mr mk ml mm im bi translated">另一个简洁的特性是，Hyperopt 允许您使用<strong class="lt iu">分布式计算</strong>，我将在另一篇文章中介绍这个特性。这意味着，如果您有<strong class="lt iu">个多核</strong>或者在<strong class="lt iu">外部计算集群</strong>上运行模型，您可以<strong class="lt iu">运行多个具有不同超参数<strong class="lt iu">的模型</strong>。<strong class="lt iu"> </strong>这种方法极大地优化了你的计算时间，这在对非常大的数据集进行训练时非常有用。</strong></p></blockquote><p id="608b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果您想查看撰写本文时使用的完整代码，可以在下面找到:</p><div class="ou ov gp gr ow ox"><a href="https://github.com/egorhowell/Medium-Articles/blob/main/Data%20Science%20Basics/Hyperparameter_Tuning_With_Hyperopt.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">Medium-Articles/Hyperparameter _ Tuning _ With _ hyper opt . ipynb at main egorhowell/Medium-Articles</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">我在我的媒体博客/文章中使用的代码。通过创建一个关于…的帐户，为 egorhowell/Medium-Articles 的开发做出贡献</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">github.com</p></div></div><div class="pg l"><div class="ph l pi pj pk pg pl ks ox"/></div></div></a></div><p id="87c6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我还创建了一个更新版本(2022 年 9 月)，您可以在这里找到:</p><div class="ou ov gp gr ow ox"><a href="https://github.com/egorhowell/Medium-Articles/blob/main/Data%20Science%20Basics/Hyperparameter_Tuning_With_Hyperopt_V2.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">Medium-Articles/Hyperparameter _ Tuning _ With _ Hyperopt _ v2 . ipynb at main egorhowell/Medium-Articles</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">我在我的媒体博客/文章中使用的代码。通过创建一个关于…的帐户，为 egorhowell/Medium-Articles 的开发做出贡献</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">github.com</p></div></div><div class="pg l"><div class="pm l pi pj pk pg pl ks ox"/></div></div></a></div><h1 id="03d6" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">和我联系！</h1><ul class=""><li id="ca40" class="no np it lt b lu lv lx ly ma pn me po mi pp mm pq nu nv nw bi translated">要在媒体上阅读无限的故事，请务必在这里注册！T37<em class="oe">T39】💜</em></li><li id="9786" class="no np it lt b lu nx lx ny ma nz me oa mi ob mm pq nu nv nw bi translated"><a class="ae ky" href="/subscribe/@egorhowell" rel="noopener ugc nofollow" target="_blank"> <em class="oe">在我发布注册邮件通知时获取更新！</em> </a> <em class="oe"> </em>😀</li><li id="b8dc" class="no np it lt b lu nx lx ny ma nz me oa mi ob mm pq nu nv nw bi translated"><a class="ae ky" href="https://www.linkedin.com/in/egor-howell-092a721b3/" rel="noopener ugc nofollow" target="_blank"><em class="oe">LinkedIn</em></a><em class="oe"/>👔</li><li id="a7a0" class="no np it lt b lu nx lx ny ma nz me oa mi ob mm pq nu nv nw bi translated"><a class="ae ky" href="https://twitter.com/EgorHowell" rel="noopener ugc nofollow" target="_blank"> <em class="oe">碎碎念</em> </a> <em class="oe"> </em> 🖊</li><li id="fb18" class="no np it lt b lu nx lx ny ma nz me oa mi ob mm pq nu nv nw bi translated"><a class="ae ky" href="https://github.com/egorhowell" rel="noopener ugc nofollow" target="_blank"><em class="oe">github</em></a><em class="oe"/>🖥</li><li id="87b0" class="no np it lt b lu nx lx ny ma nz me oa mi ob mm pq nu nv nw bi translated"><a class="ae ky" href="https://www.kaggle.com/egorphysics" rel="noopener ugc nofollow" target="_blank"><em class="oe"/></a><em class="oe"/>🏅</li></ul><blockquote class="oo op oq"><p id="a510" class="lr ls oe lt b lu mn ju lw lx mo jx lz or mp mc md os mq mg mh ot mr mk ml mm im bi translated">(所有表情符号都是由<a class="ae ky" href="https://openmoji.org/" rel="noopener ugc nofollow" target="_blank"> OpenMoji </a>设计的——开源的表情符号和图标项目。执照:<a class="ae ky" href="https://creativecommons.org/licenses/by-sa/4.0/#" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0 </a></p></blockquote></div></div>    
</body>
</html>