<html>
<head>
<title>Several Model Validation Techniques in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的几种模型验证技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/several-model-validation-techniques-in-python-1cab3b75e7f1?source=collection_archive---------17-----------------------#2021-03-18">https://towardsdatascience.com/several-model-validation-techniques-in-python-1cab3b75e7f1?source=collection_archive---------17-----------------------#2021-03-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f10f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">四种流行的交叉验证技术的综合指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/516a8968222038dbaa123c789734af17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h4-AxScdzGJoq5xBet4lqQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">karlyukav创作的男子照片—<a class="ae ky" href="http://www.freepik.com" rel="noopener ugc nofollow" target="_blank">www.freepik.com</a></p></figure><p id="f5b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我想写这篇文章，因为我认为很多人倾向于忽略机器学习的验证和测试阶段。类似于实验设计，花足够的时间和使用正确的技术来验证你的ML模型是很重要的。模型验证远远不止train_test_split()，如果你继续读下去很快就会发现！</p><h1 id="db86" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">但是首先，什么是模型验证？</h1><p id="324e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">模型验证是一种检查模型的预测与现实有多接近的方法。同样，模型验证意味着计算您正在训练的模型的准确性(或评估的度量)。</p><p id="c3cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有几种不同的方法可以用来验证您的ML模型，我们将在下面深入探讨:</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="20bf" class="lv lw it bd lx ly mz ma mb mc na me mf jz nb ka mh kc nc kd mj kf nd kg ml mm bi translated">1.使用Gradio进行模型验证</h1><p id="f14c" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">虽然这不一定是一种技术，但我认为这是一个额外的收获，因为它可以作为几乎任何您创建的ML模型的额外的验证步骤。</p><p id="dce6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">大约一个月前，我遇到了Gradio，我一直是它的大力支持者，这是理所当然的。它非常有用，原因有很多，包括能够用您自己的输入来验证和测试您的模型。</p><p id="1672" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我发现Gradio在验证我的模型时非常有用，原因如下:</p><ol class=""><li id="60c8" class="ne nf it lb b lc ld lf lg li ng lm nh lq ni lu nj nk nl nm bi translated">它允许我交互式地测试模型的不同输入。</li><li id="4827" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu nj nk nl nm bi translated">它允许我从领域用户和领域专家(他们可能不是编码人员)那里得到反馈</li><li id="c3a1" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu nj nk nl nm bi translated">它需要3行代码来实现，并且可以通过公共链接轻松分发。</li></ol><p id="0a8c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种类型的“验证”是我经常在以下验证技术之上做的事情…</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="f9fd" class="lv lw it bd lx ly mz ma mb mc na me mf jz nb ka mh kc nc kd mj kf nd kg ml mm bi translated">2.培训/验证/测试分割</h1><p id="84d9" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这种方法是模型验证中最常用的。这里，模型的数据集分为训练、验证和测试样本。所有这些集合定义如下:</p><p id="69c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">训练集:</strong>模型训练的数据集。所有的学习都发生在这组数据上。</p><p id="662f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">验证集:</strong>该数据集用于调整从数据集训练的模型。这里，这也是选择最终模型来使用测试集进行测试的时候。</p><p id="8a3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">测试集:</strong>根据测试集测试模型的概化能力。这是评估的最后阶段，因为它给出了模型是否准备好用于实际应用的信号。</p><p id="62a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该方法的目标是检查新数据的模型行为。数据集被分成不同的百分比，这主要取决于您的项目和您拥有的资源数量。</p><p id="65fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图清楚地展示了这个例子。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/6e415657b28fc6961f326ea984c596bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*XjqJL-4fsYRmu5VkJIrWXg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者创建的图像</p></figure><p id="591c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下python代码实现了此方法。<strong class="lb iu">训练</strong>、<strong class="lb iu">验证</strong>和<strong class="lb iu">测试</strong>集合将分别占总数据集的60%、20%和20%；</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="f55e" class="ny lw it nu b gy nz oa l ob oc">from sklearn.model_selection import train_test_split</span><span id="7ac6" class="ny lw it nu b gy od oa l ob oc">X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=1)</span><span id="8014" class="ny lw it nu b gy od oa l ob oc">X_train, X_val, y_train, y_val = train_test_split( X_train, y_train, test_size=0.25, random_state=1)</span></pre><p id="e817" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法并不适用于每种情况，它有优点也有缺点。</p><h2 id="ac80" class="ny lw it bd lx oe of dn mb og oh dp mf li oi oj mh lm ok ol mj lq om on ml oo bi translated">优点:</h2><ul class=""><li id="8cfd" class="ne nf it lb b lc mn lf mo li op lm oq lq or lu os nk nl nm bi translated">实现起来非常简单。</li><li id="f84a" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu os nk nl nm bi translated">与其他方法相比，执行速度相对较快。</li></ul><h2 id="5e83" class="ny lw it bd lx oe of dn mb og oh dp mf li oi oj mh lm ok ol mj lq om on ml oo bi translated">缺点:</h2><ul class=""><li id="f4f8" class="ne nf it lb b lc mn lf mo li op lm oq lq or lu os nk nl nm bi translated">对于小数据集的模型，如果每个数据集中没有足够的数据点，这种方法会降低精度。</li><li id="9964" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu os nk nl nm bi translated">对于准确的评估指标，分割应该是随机的，否则会变得不准确。</li><li id="a953" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu os nk nl nm bi translated">它会导致模型过度适应验证集。</li></ul></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="28a0" class="lv lw it bd lx ly mz ma mb mc na me mf jz nb ka mh kc nc kd mj kf nd kg ml mm bi translated">3.k<strong class="ak">-折叠交叉验证</strong></h1><p id="72ff" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">K-fold交叉验证解决了训练/测试分离的所有问题。使用K折叠交叉验证，数据集被分成K个折叠或部分，每个折叠被用作某个位置的测试集。</p><p id="47ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，假设有一个4重交叉验证集-有四重，模型将被测试四次，其中每个重用作测试集，其他重用作训练集。然后，模型的最终评价就是简单的所有k次测试的平均值。下图清晰地展示了这一过程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/cb04367545a65c728e98e73e7e0c4595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7X50kKyMej4KTsBg6dtYtA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者创建的图像</p></figure><p id="054b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是如何用Python实现大小为5的折叠:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="d3a2" class="ny lw it nu b gy nz oa l ob oc">from sklearn.datasets import load_iris<br/>import pandas as pd<br/>from sklearn.model_selection import KFold<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.metrics import accuracy_score</span><span id="4585" class="ny lw it nu b gy od oa l ob oc">data = load_iris(as_frame = True)<br/>df = data.frame<br/>X = df.iloc[:,:-1]<br/>y = df.iloc[:,-1]</span><span id="dcf8" class="ny lw it nu b gy od oa l ob oc">kf = KFold(n_splits=5, random_state=None)<br/>model = LogisticRegression(solver= ‘liblinear’)</span><span id="327f" class="ny lw it nu b gy od oa l ob oc">acc_score = []</span><span id="932a" class="ny lw it nu b gy od oa l ob oc">for train_index , test_index in kf.split(X):<br/>   X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]<br/>   y_train , y_test = y[train_index] , y[test_index]</span><span id="f730" class="ny lw it nu b gy od oa l ob oc">   model.fit(X_train,y_train)<br/>   pred_values = model.predict(X_test)</span><span id="6a6a" class="ny lw it nu b gy od oa l ob oc">   acc = accuracy_score(pred_values , y_test)<br/>   acc_score.append(acc)</span><span id="59d4" class="ny lw it nu b gy od oa l ob oc">avg_acc_score = sum(acc_score)/k</span><span id="636c" class="ny lw it nu b gy od oa l ob oc">print(‘accuracy of each fold — {}’.format(acc_score))<br/>print(‘Avg accuracy : {}’.format(avg_acc_score))</span></pre><p id="6c5d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法有以下优点和缺点:</p><h2 id="e128" class="ny lw it bd lx oe of dn mb og oh dp mf li oi oj mh lm ok ol mj lq om on ml oo bi translated">优点:</h2><ul class=""><li id="5039" class="ne nf it lb b lc mn lf mo li op lm oq lq or lu os nk nl nm bi translated">这种方法生成的评估指标更加真实。</li><li id="68dd" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu os nk nl nm bi translated">很大程度上解决了过拟合问题。</li><li id="05ba" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu os nk nl nm bi translated">这导致偏差减小。</li></ul><h2 id="6c88" class="ny lw it bd lx oe of dn mb og oh dp mf li oi oj mh lm ok ol mj lq om on ml oo bi translated">缺点:</h2><ul class=""><li id="8d32" class="ne nf it lb b lc mn lf mo li op lm oq lq or lu os nk nl nm bi translated">因为需要做更多的计算，所以需要大量的计算能力。</li><li id="a5d1" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu os nk nl nm bi translated">同样，所需的时间也更长。</li></ul></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="89c1" class="lv lw it bd lx ly mz ma mb mc na me mf jz nb ka mh kc nc kd mj kf nd kg ml mm bi translated">4.<strong class="ak">留一交叉验证</strong></h1><p id="c8ad" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">留一法是K折叠验证的一种特殊情况，在这种情况下，训练集将所有实例减去数据集的一个数据点，而测试集将剩余的观察结果留在外面。假设我们有一个M个实例的数据集，训练集是M-1，测试集是1。</p><p id="e1a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这解释了这种方法的名称。在LOOCV，K=N，其中为数据集中的每个实例创建并评估一个模型。由于每一个瞬间都被用于该过程，这消除了对数据采样的需要。</p><p id="4ee9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它的python实现如下所示:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="65de" class="ny lw it nu b gy nz oa l ob oc">from sklearn.datasets import make_blobs<br/>from sklearn.model_selection import LeaveOneOut<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.metrics import accuracy_score</span><span id="f4dd" class="ny lw it nu b gy od oa l ob oc"><strong class="nu iu"># create dataset</strong><br/>X, y = make_blobs(n_samples=100, random_state=1)</span><span id="76a6" class="ny lw it nu b gy od oa l ob oc"><strong class="nu iu"># create loocv procedure</strong><br/>cv = LeaveOneOut()</span><span id="9e8f" class="ny lw it nu b gy od oa l ob oc"><strong class="nu iu"># enumerate splits</strong><br/>y_true, y_pred = list(), list()<br/>for train_ix, test_ix in cv.split(X):<br/><strong class="nu iu">   # split data<br/>   </strong>X_train, X_test = X[train_ix, :], X[test_ix, :]<br/>   y_train, y_test = y[train_ix], y[test_ix]<br/>   <strong class="nu iu"># fit model<br/>   </strong>model = RandomForestClassifier(random_state=1)<br/>   model.fit(X_train, y_train)<br/>   <strong class="nu iu"># evaluate model<br/>   </strong>yhat = model.predict(X_test)<br/>   <strong class="nu iu"># store<br/>   </strong>y_true.append(y_test[0]) <br/>   y_pred.append(yhat[0])</span><span id="e535" class="ny lw it nu b gy od oa l ob oc"><strong class="nu iu"># calculate accuracy</strong><br/>acc = accuracy_score(y_true, y_pred)<br/>print('Accuracy: %.3f' % acc)</span></pre><p id="bb66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">优点:</p><ul class=""><li id="bef8" class="ne nf it lb b lc ld lf lg li ng lm nh lq ni lu os nk nl nm bi translated">通过省去一个交叉验证，可以生成高度准确和无偏的模型。</li><li id="9f9a" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu os nk nl nm bi translated">我们不必把数据分成随机样本。</li><li id="3dda" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu os nk nl nm bi translated">它非常适合较小的数据集。</li></ul><p id="ef41" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">缺点:</p><ul class=""><li id="4f68" class="ne nf it lb b lc ld lf lg li ng lm nh lq ni lu os nk nl nm bi translated">这是k-folds交叉验证计算量最大的版本，因为模型需要拟合M次。</li><li id="7876" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu os nk nl nm bi translated">它不适合较大的数据集。</li><li id="2a78" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu os nk nl nm bi translated">均方差会因测试数据的单一瞬间而变化，这会导致更高的可变性(高方差)</li></ul></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><h1 id="ec0d" class="lv lw it bd lx ly mz ma mb mc na me mf jz nb ka mh kc nc kd mj kf nd kg ml mm bi translated">4.分层K倍交叉验证</h1><p id="6e9a" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">分层k-fold方法是主要用于分类问题的简单k-交叉验证的扩展。这种方法中的分裂不像k交叉验证那样是随机的。分层确保每个折叠都代表数据的所有层次，具体来说，它旨在确保每个测试折叠中每个类都得到同等的代表。</p><p id="b480" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们以一个简单的分类问题为例，其中我们的机器学习模型从图像中识别出一只猫或一只狗。如果我们有一个数据集，其中70%的图片是猫，另外30%是狗，在分层的k折叠中，我们将为每个折叠保持70/30的比例。</p><p id="f51b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们有较小的数据集并且我们必须保持类比率时，这种技术是理想的。有时，数据会过采样或欠采样，以符合要求的标准。</p><p id="e6df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">python实现的工作方式如下。Sklearn为我们提供了StratifiedKFold函数。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="a86e" class="ny lw it nu b gy nz oa l ob oc">import numpy as np<br/>from sklearn.model_selection import StratifiedKFold</span><span id="3194" class="ny lw it nu b gy od oa l ob oc">X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])<br/>y = np.array([0, 0, 1, 1])</span><span id="8319" class="ny lw it nu b gy od oa l ob oc">skf = StratifiedKFold(n_splits=2)<br/>skf.get_n_splits(X, y)</span><span id="f7cf" class="ny lw it nu b gy od oa l ob oc">print(skf)</span><span id="04c7" class="ny lw it nu b gy od oa l ob oc">for train_index, test_index in skf.split(X, y):<br/>   print(“TRAIN:”, train_index, “TEST:”, test_index)<br/>   X_train, X_test = X[train_index], X[test_index]<br/>   y_train, y_test = y[train_index], y[test_index]</span></pre><p id="f60f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法的利弊如下:</p><h2 id="82bd" class="ny lw it bd lx oe of dn mb og oh dp mf li oi oj mh lm ok ol mj lq om on ml oo bi translated">优点:</h2><ul class=""><li id="7af5" class="ne nf it lb b lc mn lf mo li op lm oq lq or lu os nk nl nm bi translated">它适用于具有少量训练样本和不平衡数据的数据集。</li><li id="e77f" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu os nk nl nm bi translated">阶级比例保持不变。</li></ul><h2 id="0c14" class="ny lw it bd lx oe of dn mb og oh dp mf li oi oj mh lm ok ol mj lq om on ml oo bi translated">缺点:</h2><ul class=""><li id="3a01" class="ne nf it lb b lc mn lf mo li op lm oq lq or lu os nk nl nm bi translated">这不是回归问题的理想方法。</li><li id="87bc" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu os nk nl nm bi translated">它努力处理更大的数据集以获得最佳结果。</li></ul><h1 id="41d7" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">感谢阅读！</h1><p id="2208" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在本文中，我们看到了不同的模型验证技术，每种技术都服务于不同的目的，并且最适合不同的场景。在使用这些验证技术之前，请始终考虑您的计算资源、时间限制和您试图解决的问题类型。</p><p id="a731" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一如既往，我祝你学习一切顺利！:)</p><p id="6d39" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不确定接下来要读什么？我为你挑选了另一篇文章:</p><div class="ou ov gp gr ow ox"><a rel="noopener follow" target="_blank" href="/all-machine-learning-algorithms-you-should-know-in-2021-2e357dd494c7"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">2021年你应该知道的所有机器学习算法</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">最流行的机器学习模型的直观解释</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">towardsdatascience.com</p></div></div><div class="pg l"><div class="ph l pi pj pk pg pl ks ox"/></div></div></a></div><p id="dd65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">又一个！</strong></p><div class="ou ov gp gr ow ox"><a rel="noopener follow" target="_blank" href="/a-complete-52-week-curriculum-to-become-a-data-scientist-in-2021-2b5fc77bd160"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">2021年成为数据科学家的完整52周课程</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">连续52周，每周学点东西！</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">towardsdatascience.com</p></div></div><div class="pg l"><div class="pm l pi pj pk pg pl ks ox"/></div></div></a></div><h1 id="9628" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">特伦斯·申</h1><ul class=""><li id="8bee" class="ne nf it lb b lc mn lf mo li op lm oq lq or lu os nk nl nm bi translated"><strong class="lb iu"> <em class="pn">如果你喜欢这个，</em> </strong> <a class="ae ky" href="https://medium.com/@terenceshin" rel="noopener"> <strong class="lb iu"> <em class="pn">跟我上媒</em> </strong> </a> <strong class="lb iu"> <em class="pn">了解更多</em> </strong></li><li id="8929" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu os nk nl nm bi translated"><strong class="lb iu"> <em class="pn">有兴趣合作吗？让我们连线上</em></strong><a class="ae ky" href="https://www.linkedin.com/in/terenceshin/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="pn">LinkedIn</em></strong></a></li><li id="45f9" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu os nk nl nm bi translated"><strong class="lb iu"> <em class="pn">报名我的邮箱列表</em> </strong> <a class="ae ky" href="https://forms.gle/tprRyQxDC5UjhXpN6" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="pn">这里</em> </strong> </a> <strong class="lb iu"> <em class="pn">！</em>T41】</strong></li></ul></div></div>    
</body>
</html>