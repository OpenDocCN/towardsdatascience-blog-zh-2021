<html>
<head>
<title>Bird Song Classification using Siamese Networks and Dilated Convolutions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用暹罗网络和扩张卷积进行鸟鸣分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bird-song-classification-using-siamese-networks-and-dilated-convolutions-3b38a115bc1?source=collection_archive---------15-----------------------#2021-07-04">https://towardsdatascience.com/bird-song-classification-using-siamese-networks-and-dilated-convolutions-3b38a115bc1?source=collection_archive---------15-----------------------#2021-07-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/f6f85054f83077c9e4eef26deac3eaed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pht8ej7XEuIJgaPkBOTIWw.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><a class="ae kc" href="https://unsplash.com/photos/_oNISBwMTwo" rel="noopener ugc nofollow" target="_blank">Glen Carrie通过Unsplash拍摄的图像</a></p></figure><h1 id="e695" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">介绍</h1><p id="1886" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi lz translated">T2:声学在研究环境方面非常有用。它已经被用于跟踪潜艇和鲸鱼很长时间了。鸟类对塑造我们身边的植物有很大帮助。<strong class="ld ir">识别鸟鸣对于自动监测野生动物和研究鸟类的行为非常重要</strong>。它可以帮助追踪鸟类而不打扰它们。我们还可以知道在某个特定的地方存在着哪些鸟类。它能给我们一些关于它们迁移模式的信息。每种鸟都有它们独特的声音。它们用不同长度和复杂程度的歌声来吸引配偶，警告其他鸟类附近的危险，并标记它们的领地。鸣禽可以根据地理位置有不同的方言。但是非鸣禽发出的声音不会因为地理位置而有太大变化。使用深度学习方法，我们可以很容易地根据鸟类的叫声和歌声对它们进行分类。我们可以使用任何神经网络框架，如CNN、暹罗网络、WaveNets等。为了这个任务。</p><h1 id="41b7" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">问题陈述</h1><p id="feee" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="ld ir">目标</strong>:我们想根据不同鸟类的鸣叫声样本对它们进行分类。我们可以提取音频样本的频谱图，并使用它们作为分类的特征。在这个实验中，我们将使用Kaggle上的英国鸟鸣数据集。数据集在<strong class="ld ir">数据描述</strong>部分描述。</p><h1 id="326d" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">暹罗网络和膨胀卷积的快速介绍</h1><h2 id="0909" class="mi ke iq bd kf mj mk dn kj ml mm dp kn lm mn mo kr lq mp mq kv lu mr ms kz mt bi translated">暹罗网络</h2><p id="8dd3" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">之前写过一篇<a class="ae kc" rel="noopener" target="_blank" href="/siamese-networks-introduction-and-implementation-2140e3443dee">暹罗网</a>的文章。可以去查一下，深入了解一下它的工作和为它使用的损耗函数。该文章中还提供了代码。但是，我在这里给大家总结一下暹罗网。</p><p id="cceb" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated"><strong class="ld ir">连体网络是一类包含一个或多个相同网络的神经网络。</strong>我们向这些网络提供一对输入。每个网络计算一个输入的要素。然后，使用特征的差或点积来计算特征的相似性。对于相同的类输入对，目标输出是1，而对于不同的类输入对，输出是0。记住，两个网络有相同的参数和权重。如果不是，那他们就不是暹罗人。</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/bebea07bb051b1f60a3d188bf57016e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VZmcV7vo9m1H1lGdK6x6IQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">暹罗网络基本结构</p></figure><p id="c0ee" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">不同的损失函数可用于连体网络。</p><ol class=""><li id="4564" class="ne nf iq ld b le mu li mv lm ng lq nh lu ni ly nj nk nl nm bi translated"><strong class="ld ir">对比损失</strong>:在对比损失中，取一对输入。对于相同的类对，它们之间的距离较小。对于不同的对，距离更多。尽管二进制交叉熵似乎是我们问题的完美损失函数，对比损失在区分图像对方面做得更好。对比损失，<strong class="ld ir"><em class="nn">L</em></strong><em class="nn">=</em><strong class="ld ir"><em class="nn">Y * D+(1-Y)* max(margin—D，0) </em> </strong></li><li id="7fe6" class="ne nf iq ld b le no li np lm nq lq nr lu ns ly nj nk nl nm bi translated"><strong class="ld ir">三重丢失</strong>:三重丢失是Google在2015年推出的人脸识别。这里，模型有三个输入——锚、积极和消极。锚点是一个参考输入。实际输入与锚输入属于同一类别。负输入属于锚类之外的随机类。我们必须最小化锚和阳性样本之间的距离，同时最大化锚和阴性样本之间的距离。</li></ol><p id="0c11" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">我们将在实验中使用三重态损失。</p><h2 id="7166" class="mi ke iq bd kf mj mk dn kj ml mm dp kn lm mn mo kr lq mp mq kv lu mr ms kz mt bi translated">扩张的回旋</h2><blockquote class="nt nu nv"><p id="07fa" class="lb lc nn ld b le mu lg lh li mv lk ll nw mw lo lp nx mx ls lt ny my lw lx ly ij bi translated">膨胀卷积是一种卷积，它通过在内核元素之间插入孔洞来“膨胀”内核。它们也被称为atrous卷积。</p></blockquote><p id="e31c" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">扩展卷积的概念来自于小波分解，其中母小波被不同的尺度缩放或扩展以捕获不同的频率。</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nz"><img src="../Images/7b167e729e4253d8c652e3407cfb5f83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TAJzjy7-uZe3LhejzRm5mg.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">(a)标准3×3内核，(b)膨胀因子为2的内核，(c)膨胀因子为4的内核。来源<a class="ae kc" href="https://arxiv.org/pdf/1511.07122v3.pdf" rel="noopener ugc nofollow" target="_blank">原论文</a></p></figure><p id="c536" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">扩张卷积以相同的计算和存储成本增加了感受野，并且不损失分辨率。它可以用相同数量的参数从整个输入中捕获上下文。</p><p id="057a" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">这是Sik-Ho Tsang写的一篇关于<a class="ae kc" rel="noopener" target="_blank" href="/review-dilated-convolution-semantic-segmentation-9d5a5bd768f5">膨胀的脑回</a>的好文章。</p><h1 id="1d44" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">数据描述</h1><p id="c28b" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在这个实验中，我们使用了Kaggle上的英国鸟鸣数据集。这是从<a class="ae kc" href="https://www.xeno-canto.org/" rel="noopener ugc nofollow" target="_blank"> Xeno Canto </a>数据收集中收集的一个小子集，形成了英国88种鸟类的平衡数据集。</p><p id="9502" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">这里我们只对9种鸟类进行分类:<strong class="ld ir">加拿大鹅</strong><strong class="ld ir">腐尸鸦</strong><strong class="ld ir">煤山雀</strong><strong class="ld ir">普通乌鸫</strong><strong class="ld ir">普通燕雀</strong><strong class="ld ir">普通红雀</strong><strong class="ld ir">普通朱雀</strong><strong class="ld ir">普通黑水鸡</strong><strong class="ld ir">普通夜莺</strong>。</p><p id="702a" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">在这个数据集中，每只鸟的样本都很少。音频样本大约有40-60秒长。其中一些有点吵，有时背景中还有其他的鸟。从具有50%重叠的每个样本中提取2秒钟的剪辑，以创建新样本。这将为训练神经网络创建足够数量的样本。数据分为60%用于训练，40%用于测试。</p><h1 id="405c" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">履行</h1><h2 id="96d6" class="mi ke iq bd kf mj mk dn kj ml mm dp kn lm mn mo kr lq mp mq kv lu mr ms kz mt bi translated">特征抽出</h2><p id="50d2" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="ld ir"><em class="nn">Librosa</em></strong>python中的库用于音乐和音频分析。我们可以读取音频文件，并用它提取频谱图。</p><p id="b138" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated"><strong class="ld ir">第一步:</strong>使用<strong class="ld ir"> <em class="nn"> librosa </em>读取音频文件。</strong>将-1和1之间的时间序列归一化。</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="1f6a" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated"><strong class="ld ir">步骤2: </strong>去除音频中的静音。</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="4e90" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated"><strong class="ld ir">步骤3: </strong>将每个音频文件分割成2秒长的片段，重叠50%。</p><p id="1e0b" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated"><strong class="ld ir">第四步:</strong>将数据分为训练和测试。60%用于培训，40%用于测试。</p><p id="0619" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated"><strong class="ld ir">步骤5: </strong>从样品中提取光谱图。一个过滤器被应用到频谱图中，以获得一个在<strong class="ld ir">1千赫</strong>和<strong class="ld ir">8千赫</strong>之间的频率范围，因为大多数鸟鸣声的频率都在这个范围内。现在，标准化所有的光谱图(你也可以在0到1之间标准化它们)。这里，每个声谱图的形状是163×345。</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oc"><img src="../Images/fc6df3a79d73b9413fc5dd173b7eddc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*juVYxoJZH8xbyHUO39FbjQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">常见乌鸫鸣声的样本声谱图</p></figure><p id="c26e" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated"><strong class="ld ir">第六步:</strong>为暹罗网络生成正负样本对。</p><p id="2367" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">首先，生成正对。</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="6283" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">现在，生成负的类对。</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="d85f" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">您可以使用下面的函数生成正对和负对。它以:<strong class="ld ir"> <em class="nn">输入特征、目标类别标签、从每个类别中取出的随机数的数目、</em> </strong>和<strong class="ld ir"> <em class="nn">正对的数目作为输入。</em> </strong>返回锚点、阳性和阴性样本。</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="f841" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">现在，数据已准备好用于暹罗网络。</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="7044" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">我们有3种类型的输入:锚、阳性和阴性样本。每个输入的形状是:(10800 x 345 x 163)。</p><p id="a36d" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">现在，我们需要建立一个神经网络。</p><h2 id="e4ee" class="mi ke iq bd kf mj mk dn kj ml mm dp kn lm mn mo kr lq mp mq kv lu mr ms kz mt bi translated">建立神经网络</h2><p id="3355" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">编码器模型包含8个1-D卷积层，具有指数增长的膨胀因子。之后，应用1D卷积层来减少特征的数量。最后，应用全局最大池1D层。每一层后应用一个<strong class="ld ir">批量标准化</strong>层。除了最后一层，所有层都有一个'<strong class="ld ir"><em class="nn">【reLu】</em></strong>'激活。在最后一层应用'<strong class="ld ir"><em class="nn"/></strong>'激活。在最后一层，我们得到一个32维向量作为输出。</p><p id="406a" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">创建了该编码器模型的三个实例。它们代表锚定输入、积极输入和消极输入。所有三个32维特征向量被连接成一个96维向量。这个连接的向量被视为输出。正如您在下面的代码中看到的，函数<strong class="ld ir"> <em class="nn"> triplet_loss </em> </strong>获取输出，再次分离3个嵌入，并计算损失。</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="7eb0" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">下面你可以看到模型的代码。</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="2ee6" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">以下是编码器型号摘要:</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi od"><img src="../Images/59f3c25d5a9bb03b392a49f808316b32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TZ40kSrR_4snSbP6IWYCrw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">编码器型号摘要</p></figure><figure class="na nb nc nd gt jr gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/0997467693df3f35336fc3f0ba1cbcac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*wE6j2uUGJqrN0D9Es07EaA.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">编码器模型架构</p></figure><p id="8d5a" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">现在我们有了一个完整的暹罗网络。</p><h2 id="d78e" class="mi ke iq bd kf mj mk dn kj ml mm dp kn lm mn mo kr lq mp mq kv lu mr ms kz mt bi translated">训练模型</h2><p id="8385" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们现在可以拟合模型了。模型的目标输出是虚拟输出。这是因为我们没有将模型的输出与目标输出进行比较。相反，我们只是最小化相同类嵌入之间的距离，并推开不同类嵌入。</p><p id="f8cb" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">我们的锚定样本、正样本和负样本的输入大小是:(10800 x 345 x 163)。批量大小设置为256。由于批量标准化，该模型仅在30个时期内收敛。如果你愿意，你可以训练更长时间。</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><h2 id="3107" class="mi ke iq bd kf mj mk dn kj ml mm dp kn lm mn mo kr lq mp mq kv lu mr ms kz mt bi translated">结果</h2><p id="1932" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">该模型在训练集上的准确率为<strong class="ld ir"> 98.1% </strong>，在测试数据集上的准确率为<strong class="ld ir"> 97.3% </strong>。</p><figure class="na nb nc nd gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="08a4" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">以下是测试数据集的标准化混淆矩阵:</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oc"><img src="../Images/1d4193154ae8bbc0b35c6269062d4536.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c3LuXWSt_vmz-GQjS99F_g.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">测试数据集的混淆矩阵</p></figure><p id="c777" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">以下是嵌入的相似性矩阵:</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/7de2aec54dc412afe6d1d73daef68531.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lvMIx2vIkheaLE_ZSrLopg.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">测试数据集嵌入的相似性矩阵</p></figure><p id="87ca" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">下面是对测试数据集嵌入应用PCA后的散点图。所有的班级之间有很好的区分。并且，除了几个样本，所有的类都聚集在一起。</p><figure class="na nb nc nd gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi og"><img src="../Images/02701fc2049e74d86762581d8aaf66a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ba0K1-eLCSqtrCGweu67IA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">应用PCA后测试数据集嵌入的散点图</p></figure><h1 id="53ad" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">要点</h1><ol class=""><li id="b251" class="ne nf iq ld b le lf li lj lm oh lq oi lu oj ly nj nk nl nm bi translated">这里光谱图被用作特征。也可以使用Mel光谱图。</li><li id="30b2" class="ne nf iq ld b le no li np lm nq lq nr lu ns ly nj nk nl nm bi translated">音频的小波变换也可以作为特征。</li><li id="002d" class="ne nf iq ld b le no li np lm nq lq nr lu ns ly nj nk nl nm bi translated">可以用更长的框架尺寸进行实验。过长的帧尺寸会使模型过拟合，并降低整体性能。</li><li id="b937" class="ne nf iq ld b le no li np lm nq lq nr lu ns ly nj nk nl nm bi translated">批处理规范化层起着非常重要的作用。它使训练期间的小批量标准化，并解决了<strong class="ld ir">内部协变量移位</strong>的问题。它使训练更快，模型变得更健壮。我强烈推荐在你的模型中使用这个。</li><li id="e24a" class="ne nf iq ld b le no li np lm nq lq nr lu ns ly nj nk nl nm bi translated">如果你想对更多种类的鸟类进行分类，模型的集合肯定会进一步提高精确度。</li></ol><h1 id="8953" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">结论</h1><p id="05a5" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">暹罗网络成功地根据鸟类的叫声对它们进行了分类，准确率高达97%。连体网络将分类问题转化为相似性问题。它们也可以使用更少的样本，因为我们生成的是成对的样本。具有扩展的1-D卷积的模型以及批量标准化层收敛得非常快。</p><p id="8afd" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated"><strong class="ld ir">这里是这个项目的GitHub库。</strong></p><div class="ok ol gp gr om on"><a href="https://github.com/AdityaDutt/Bird-Song-Classification" rel="noopener  ugc nofollow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd ir gy z fp os fr fs ot fu fw ip bi translated">AdityaDutt/鸟鸣-分类</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">我们想根据不同鸟类的声音样本对它们进行分类。我们提取了音频的频谱图…</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">github.com</p></div></div><div class="ow l"><div class="ox l oy oz pa ow pb jw on"/></div></div></a></div><h1 id="01d5" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">未来的实验想法</h1><p id="f664" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">这个模型可以扩展到对50或100多只鸟进行分类。我对鸟类了解不多，因为这不是我的研究领域，但我非常好奇，想知道我们是否可以根据鸟类的叫声来识别不同的地理位置。这是因为鸣禽的方言随着地理位置的变化而变化。<strong class="ld ir">这里是一个</strong> <a class="ae kc" href="https://github.com/AgaMiko/bird-recognition-review" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir"> GitHub </strong> </a> <strong class="ld ir">储存库，其中包含了与鸟类</strong>相关的数据集列表。Xeno-canto网站收录了世界各地的鸟鸣。它有不同国家、物种等的数据。您可以从这里为自己的项目选择一个数据集。</p><p id="2c1f" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">请记住，您可以将该模型用于类似的基于音频的任务，如说话者分类、情感检测等。</p><p id="8093" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated"><strong class="ld ir"> <em class="nn">非常感谢您的阅读！我希望它有帮助。</em>T13】🐧</strong></p><p id="b059" class="pw-post-body-paragraph lb lc iq ld b le mu lg lh li mv lk ll lm mw lo lp lq mx ls lt lu my lw lx ly ij bi translated">如果你想合作一个项目，或者需要一些关于你的项目的想法，请随时联系我。</p><h1 id="e681" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">参考</h1><div class="ok ol gp gr om on"><a href="https://arxiv.org/abs/1609.03499" rel="noopener  ugc nofollow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd ir gy z fp os fr fs ot fu fw ip bi translated">WaveNet:原始音频的生成模型</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">本文介绍了WaveNet，一种用于生成原始音频波形的深度神经网络。该模型完全…</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">arxiv.org</p></div></div><div class="ow l"><div class="pc l oy oz pa ow pb jw on"/></div></div></a></div><div class="ok ol gp gr om on"><a href="https://arxiv.org/abs/1511.07122v3" rel="noopener  ugc nofollow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd ir gy z fp os fr fs ot fu fw ip bi translated">基于扩张卷积的多尺度上下文聚合</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">语义分割的最新模型是基于卷积网络的改编，卷积网络具有…</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">arxiv.org</p></div></div><div class="ow l"><div class="pd l oy oz pa ow pb jw on"/></div></div></a></div><div class="ok ol gp gr om on"><a rel="noopener follow" target="_blank" href="/review-dilated-convolution-semantic-segmentation-9d5a5bd768f5"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd ir gy z fp os fr fs ot fu fw ip bi translated">综述:扩展网络—扩展卷积(语义分割)</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">又名“atrous卷积”、“algorithme à trous”和“hole algorithm”</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">towardsdatascience.com</p></div></div><div class="ow l"><div class="pe l oy oz pa ow pb jw on"/></div></div></a></div><div class="ok ol gp gr om on"><a href="https://www.kaggle.com/rtatman/british-birdsong-dataset" rel="noopener  ugc nofollow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd ir gy z fp os fr fs ot fu fw ip bi translated">英国鸟鸣数据集</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">88个物种的264个记录</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">www.kaggle.com</p></div></div><div class="ow l"><div class="pf l oy oz pa ow pb jw on"/></div></div></a></div><div class="ok ol gp gr om on"><a href="https://paperswithcode.com/method/siamese-network" rel="noopener  ugc nofollow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd ir gy z fp os fr fs ot fu fw ip bi translated">论文用代码暹罗网讲解</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">一个连体网络由两个网络组成，它们接受不同的输入，但在节点处通过能量函数连接在一起</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">paperswithcode.com</p></div></div></div></a></div><div class="ok ol gp gr om on"><a href="https://github.com/AgaMiko/bird-recognition-review" rel="noopener  ugc nofollow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd ir gy z fp os fr fs ot fu fw ip bi translated">AgaMiko/bird-识别-回顾</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">一个有用的资源列表，在鸟的声音识别-鸟的歌声和叫声中，你可以随时向⭐️…提出请求</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">github.com</p></div></div><div class="ow l"><div class="pg l oy oz pa ow pb jw on"/></div></div></a></div><div class="ok ol gp gr om on"><a href="https://arxiv.org/abs/1502.03167" rel="noopener  ugc nofollow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd ir gy z fp os fr fs ot fu fw ip bi translated">批量标准化:通过减少内部协变量转移加速深度网络训练</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">训练深度神经网络是复杂的，因为每层输入的分布在训练过程中会发生变化</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">arxiv.org</p></div></div><div class="ow l"><div class="ph l oy oz pa ow pb jw on"/></div></div></a></div><div class="ok ol gp gr om on"><a href="https://machinelearningmastery.com/how-to-accelerate-learning-of-deep-neural-networks-with-batch-normalization/" rel="noopener  ugc nofollow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd ir gy z fp os fr fs ot fu fw ip bi translated">如何用批量归一化加速深度神经网络的学习-机器学习…</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">批量标准化是一种技术，旨在自动标准化深度学习层的输入…</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">machinelearningmastery.com</p></div></div><div class="ow l"><div class="pi l oy oz pa ow pb jw on"/></div></div></a></div><div class="ok ol gp gr om on"><a href="https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/" rel="noopener  ugc nofollow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd ir gy z fp os fr fs ot fu fw ip bi translated">深度神经网络批量规范化的简明介绍——机器学习掌握</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">训练具有数十层的深度神经网络具有挑战性，因为它们可能对初始随机权重敏感…</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">machinelearningmastery.com</p></div></div><div class="ow l"><div class="pj l oy oz pa ow pb jw on"/></div></div></a></div><div class="ok ol gp gr om on"><a href="https://www.xeno-canto.org/" rel="noopener  ugc nofollow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd ir gy z fp os fr fs ot fu fw ip bi translated">异种唱法</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">一篇关于R包莺的论文刚刚出现。Marcelo Arayas和Grace Smith解释了该软件包如何用于…</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">www.xeno-canto.org</p></div></div><div class="ow l"><div class="pk l oy oz pa ow pb jw on"/></div></div></a></div></div></div>    
</body>
</html>